O avanço na tecnologia de fabricação de circuitos integrados permite obter transistores cada vez menores, tornando possível o desenvolvimento de sistemas completos num único chip (System-on-Chip SoC).
Muitas aplicações requerem SoCs com vários processadores para poder suprir seus requisitos de desempenho.
Um SoC que contém diversos elementos de processamento (Processing Element -- PEs) é chamado de MPSoC.
Um MPSoC pode ser classificado em homogêneo, quando todos seus PEs são iguais;
Ou heterogêneo, quando seus PEs são diferentes.
Como infraestrutura de comunicação, o MPSoC pode utilizar NoCs como forma de interconectar os PEs.
O uso de NoCs deve- se a suas vantagens em relação a barramentos, entre as quais maior escalabilidade e paralelismo na comunicação.
Um dos principais problemas relativos ao projeto de MPSoCs é a definição de qual dos PEs do sistema será responsável por a execução de cada tarefa de uma aplicação.
Este problema é chamado de mapeamento de tarefas.
O mapeamento pode ser classificado em estático, que ocorre em tempo de projeto, ou em dinâmico que ocorre em tempo de execução.
A abordagem de mapeamento dinâmico requer primeiramente o mapeamento de tarefas iniciais de uma aplicação (que não dependem de nenhuma outra tarefa) das aplicações, sendo que as outras tarefas são mapeadas dinamicamente quando solicitadas.
Também se pode classificar o mapeamento quanto a o número de tarefas que executam num PE do sistema.
O mapeamento é dito monotarefa, quando apenas uma tarefa é executada por PE, e multitarefa, quando múltiplas tarefas podem ser executadas num mesmo PE.
Este trabalho propõe novas heurísticas de mapeamento dinâmico monotarefa e multitarefa, visando à redução de energia de comunicação.
Resultados são avaliados através do MPSoC HeMPS, que executa códigos de aplicações geradas a partir de um ambiente de simulação baseado em modelos.
Estas heurísticas são comparadas com heurísticas de mapeamento apresentadas na literatura, apresentando uma redução média de energia de comunicação nos cenários avaliados de até 9,8% na abordagem monotarefa e 18,6% na multitarefa.
Este trabalho também avalia a inserção dinâmica de carga no sistema, utilizando para isto a implementação de uma heurística de mapeamento dinâmico de tarefas iniciais.
Esta heurística é uma contribuição inovadora, visto que uma abordagem parecida não é encontrada em nenhum outro trabalho da literatura.
Palavras-Chave: Mapeamento dinâmico de tarefas, NoC, SoC, MPSoC.
O avanço na tecnologia de fabricação de circuitos integrados permite obter transistores cada vez menores.
Isto torna possível o desenvolvimento de sistemas completos num único chip, chamados de System-on-a-Chip (SoC).
Um SoC é um circuito integrado que implementa a maioria ou todas as funções de um sistema eletrônico completo.
Os componentes que são agregados num SoC variam de acordo com sua aplicação.
Em geral um SoC pode conter memória, processadores de diversos tipos, lógica especializada, interfaces de comunicação, e outras funções digitais e analógicas.
Muitas aplicações requerem SoCs com vários processadores para poder suprir seus requisitos de desempenho.
Um SoC que contém diversos elementos de processamento (PEs, em inglês, processing element) é chamado de MPSoC.
PE, no escopo deste trabalho, é sinônimo de processadores.
Em a prática, a maioria dos SoCs são MPSoCs pois é muito difícil desenvolver um sistema complexo num chip sem utilizar múltiplas CPUs.
Os MPSoCs já estão presentes em várias implementações comercias, sendo amplamente utilizados na área de redes, telecomunicação, processamento de sinais, multimídia, entre outras.
Uma aplicação, para que seja executada em paralelo nos diversos recursos (PEs) de um MPSoC, é decomposta em tarefas.
Define- se tarefa como um conjunto de instruções e dados, com informações necessárias à sua correta execução num dado elemento de processamento.
Essas tarefas podem ser executadas de forma independente ou então ter dependência uma das outras, onde uma tarefa pode precisar de dados pré-processados por outra tarefa ou então realizar troca de dados durante as execuções das mesmas.
Um dos principais problemas relativos à execução paralela das tarefas de uma aplicação é a definição de em qual dos PEs do sistema cada tarefa será executada.
Este problema é chamado de mapeamento de tarefas.
MPSoCs Sistemas multiprocessados em chips (MPSoC, do inglês Multiprocessor System--onChip) são arquiteturas personalizadas que fazem um balanço entre as restrições da tecnologia VLSI, com os requisitos da aplicação.
O MPSoC está se tornando um estilo de projeto cada vez mais utilizado por reduzir o tempo em o qual os produtos chegam ao mercado, maximizar a reutilização de projetos, simplificar o processo de verificação (devido a a existência de módulos replicados) e proporcionar flexibilidade e programabilidade para reuso de plataformas complexas depois de fabricadas.
Quando os PEs de um MPSoC são iguais, diz- se que este é um MPSoC homogêneo.
Já, quando utiliza diferentes elementos de processamento (GPPs, DSPs, etc) diz- se que é um MPSoC heterogêneo.
Um MPSoC homogêneo facilita o desenvolvimento de software e o mapeamento da aplicação na sua arquitetura, porém o uso de uma arquitetura heterogênea pode melhorar o desempenho da aplicação.
Esta melhora de desempenho em arquiteturas heterogêneas se deve principalmente ao fato de que nestas arquiteturas há a possibilidade de utilização de um módulo dedicado para cada uma das necessidades de uma aplicação.
Um tópico importante relativo aos MPSoCs é a infraestrutura de comunicação utilizada para interconectar os elementos de processamento.
Entre os meios de interconexão num MPSoC pode- se citar:
Mapeamento de Tarefas O ato de escolher o melhor PE do MPSoC para alocar uma tarefa é denominado de mapeamento de tarefas.
Em alguns trabalhos como o mapeamento é chamado de alocação de tarefas.
A o escolher o melhor recurso para se mapear uma tarefa deve- se buscar atender os requisitos do sistema.
Por exemplo, o consumo de energia torna- se importante em dispositivos portáteis.
Por outro lado, o atendimento dos prazos (em inglês, deadlines) das tarefas é fundamental em sistemas com restrições de tempo real.
Assim, decisões de mapeamento podem influenciar drasticamente o desempenho do sistema.
Em este trabalho é proposta a classificação do mapeamento de acordo com quatro critérios:
O momento em que é executado, o número de tarefas por PE, a entidade que controla o mapeamento;
E a arquitetura alvo.
Considerando o momento em que o mapeamento é executado, as seguintes abordagens podem ser utilizadas:
Por outro lado, a aplicação pode levar mais tempo para iniciar a sua execução se não houver disponibilidade de recursos suficientes quando ela for solicitada.
Considerando o número de tarefas mapeadas por PE, as seguintes abordagens podem ser utilizadas:
O mapeamento dinâmico requer uma entidade responsável por mapear as tarefas em tempo de execução.
Tal controle pode ser:
Apesar de a maior escalabilidade, um gargalo persiste:
O acesso ao repositório de tarefas, caso este seja global para o sistema.
Finalmente, o mapeamento pode ser classificado de acordo com a arquitetura do sistema:
Antes do mapeamento, um processo de binding (do inglês, ligação) é executado, definindo em qual (is) PE (s) uma tarefa pode executar, limitando a escolha do mapeamento para esta tarefa.
Outro ponto importante relacionado ao mapeamento de tarefas é quanto a a função custo utilizada.
Como dito anteriormente, na realização do mapeamento de tarefas buscase uma otimização de desempenho a fim de atender requisitos do sistema.
Para isto, uma função custo é utilizada para avaliar qual PE do sistema é o melhor para se mapear determinada tarefa.
Esta função custo leva em conta métricas de desempenho como energia consumida, latência, vazão, ocupação de PEs, ocupação de canais de comunicação.
Estas métricas podem ser combinadas, buscando otimizações multiobjetivo.
É também importante mencionar que existe certa confusão de conceitos entre mapeamento de tarefas e migração de tarefas na literatura.
A migração de tarefas é o ato de transferir uma tarefa já mapeada de um processador para outro.
Já, o mapeamento de tarefas define o posicionamento inicial de uma dada tarefa.
Uma vez que essa tarefa está sendo executada, seu desempenho pode se degradar devido, por exemplo, a sobrecarga de processamento do PE onde esta está executando.
A migração de tarefas, assim, permite:
Além disso, a migração de tarefas requer a definição de pontos de migração, salvamento de contexto, restauração do contexto, entre outras ações não incluídas no mapeamento tarefa.
Objetivos Os objetivos do presente trabalho se dividem em estratégicos e específicos.
Entre os objetivos estratégicos cita- se:
Domínio da tecnologia de projeto de sistemas multiprocessados em chip (MPSoC);
Domínio da tecnologia de redes intra-chip (NoC);
Domínio de técnicas de mapeamento de tarefas.
Específicos: Inserção de heurísticas de mapeamento na plataforma HeMPS.
Aplicar as heurísticas de mapeamento dinâmico de tarefas desenvolvido em na plataforma HeMPS.
Avaliar estas heurísticas no MPSoC HeMPS com o objetivo de otimizar- las.
Integração da infraestrutura de monitoramento com as heurísticas de mapeamento.
Integrar heurísticas de mapeamento com a infraestrutura de monitoramento proposta por.
O monitoramento tem como função propiciar informações do sistema em tempo de execução para que estas heurísticas tomem decisões de mapeamento.
Geração de códigos de aplicações para plataforma HeMPS.
Geração de código de aplicações em linguagem C para a plataforma HeMPS.
Estes códigos são utilizados na realização da experimentação das heurísticas de mapeamento implementadas.
Implementação de novas heurísticas de mapeamento.
Propor novas heurísticas de mapeamento priorizando o mapeamento multitarefa.
Estas heurísticas têm como meta principal de otimização a redução de energia consumida na comunicação.
Comparação das políticas de mapeamento de tarefas.
Definir qual das políticas é mais eficiente, e quais as vantagens e limitações de cada uma.
Inserção dinâmica de aplicações na plataforma HeMPS.
Agregar suporte à inserção de aplicações durante o tempo de execução na plataforma HeMPS.
Estrutura do Documento O restante deste documento é organizado como segue.
Em o Capítulo 2 são apresentados trabalhos relacionados, primeiramente mostrando o estado da arte em mapeamento dinâmico de tarefas e após apresentando os trabalhos que serão utilizados como referência.
Em o Capítulo 2.3, é apresentada a plataforma MPSoC de referência deste trabalho, abordando sua arquitetura e sistema operacional.
Em o Capítulo 4 são apresentadas as novas heurísticas de mapeamento propostas por este trabalho.
O uma discussão dos mesmos.
O Capítulo 6 apresenta modificações na plataforma de referência deste trabalho com o propósito de agregar suporte à inserção de aplicações durante o tempo de execução.
Em o Capítulo 7 são apresentados as conclusões e trabalhos futuros.
E, por fim, no Capítulo 0 são apresentadas as referências bibliográficas deste trabalho.
Este Capítulo apresenta inicialmente as abordagens de mapeamento utilizadas como referência neste trabalho, as quais servirão como base de comparação em resultados experimentais.
A abordagem proposta por, apresentada na Seção 2.2, são utilizadas como referência de mapeamento dinâmico.
Em a sequência são apresentados, na Seção 2.3, trabalhos relacionados ao mapeamento dinâmico de tarefas.
Estes trabalhos são classificados de acordo com a taxonomia proposta anteriormente, sendo comparados ao presente trabalho.
A classificação das heurísticas de mapeamento proposta neste trabalho incluem:
Algoritmo de Mapeamento Estático de Referência Marcon et al.
Propõem uma comparação entre algoritmos de mapeamento estático de tarefas visando baixo consumo de energia.
Os algoritmos utilizam um modelo de comunicação com pesos (CWM, em inglês CommunicationWeighted Model) para produzir um conjunto experimentos representando padrões de comunicação de aplicações.
A estrutura básica utilizada para representar uma aplicação é um grafo de comunicação com pesos (CWG, em inglês Communication--Weighted Graph).
Este é um grafo dirigido, onde conjunto de vértices representa os núcleos da aplicação, e o conjunto de arestas representa as comunicações entre cada par de núcleos.
Uma ferramenta chamada CAFES (em inglês, Communication Analysis For Embedded Systems) foi desenvolvida para a avaliação das estratégias de mapeamento em diferentes topologias de infraestrutura de comunicação.
Além disso, o CAFES permite a comparação e inclusão de modelos, gerar e simular aplicações para avaliar o seu comportamento e estimar o tempo e consumo de energia devido a a comunicação.
Cinco algoritmos de mapeamento são avaliados:
Busca exaustiva (ES, em inglês Exaustive Search), dois algoritmos estocásticos (simulated annealing (SA) e tabu search (Ts)) e duas heurísticas greedy:
Largest Communication First (LCF, do inglês maior comunicação primeiro) e Incremental (GI).
Em este trabalho o algoritmo Simulated Annealing é utilizado como referência com o objetivo de comparar as heurísticas de mapeamento aqui propostas com um algoritmo de mapeamento estático.
A escolha deste algoritmo se deve ao fato de ser utilizado em vários trabalhos como.
Além disso, a disponibilidade da ferramenta gráfica CAFES para o mapeamento de tarefas contribuiu para a escolha do trabalho como base das comparações.
O SA é um algoritmo estocástico que tem como base dois laços aninhados.
O laço mais externo gera um mapeamento inicial criado a partir de trocas aleatórias de vários módulos.
O laço interno realiza um refinamento do mapeamento inicial, escolhendo aleatoriamente um par de módulos a serem trocados de posição, gerando um novo mapeamento.
As trocas respeitam um parâmetro de controle, chamado temperatura.
Este parâmetro permite trocas mesmo quando se obtém soluções piores dentro de uma faixa aceitável.
A solução buscada quando de o mapeamento dos módulos é uma distribuição que resulte num menor consumo de energia.
A temperatura é decrementada a cada iteração do laço interno restringindo, assim, cada vez mais as trocas do mapeamento.
O melhor mapeamento encontrado a cada interação do laço interno é comparado a um mapeamento chamado global que armazena a melhor distribuição encontrada durante a execução do SA.
Se encontrado um mapeamento com melhor resultado de consumo de energia quando comparado ao mapeamento global, este se torna o novo mapeamento global.
Heurísticas de Mapeamento Dinâmico de Referência Em esta Seção são apresentadas as heurísticas de mapeamento dinâmico propostas comparação nos resultados experimentais, principalmente devido a o acesso a uma descrição detalhada destas heurísticas.
Assim, na Seção 2.2.1, é mostrada como é feita a modelagem das aplicações utilizada no trabalho.
Depois, na Seção 2.2.2, é apresentado como é feito o mapeamento da tarefa inicial de uma aplicação.
Por último, na Seção 2.2.3 são mostradas as heurísticas de mapeamento dinâmico.
A abordagem utilizada para a modelagem de aplicações no trabalho é representada por um grafo dirigido, em que os vértices representam tarefas e as arestas representam comunicações entre tarefas da aplicação.
A Figura 1 mostra um exemplo de uma aplicação modelada de acordo com esta abordagem.
Vértices representados por círculos com linhas duplas se referem a tarefas iniciais da aplicação e os demais vértices são tarefas de hardware e de software.
Há apenas uma tarefa inicial por aplicação que é iniciada logo que a aplicação é disparada por o usuário.
As arestas do grafo possuem pesos referentes ao volume e as taxas de comunicação entre as tarefas, em ambos os sentidos.
Uma aresta define, assim, um par de tarefas mestre-escravo em que a tarefa chamada mestre precisa solicitar o mapeamento da sua tarefa escrava antes da comunicação propriamente dita ser realizada.
Cada aresta possui transmissão de dados entre as tarefas no sentido mestre-escrava ms e escrava-mestre sm.
A abordagem de mapeamento de tarefas iniciais adotada no trabalho define posições fixas e distantes umas das outras para o mapeamento das tarefas iniciais de cada aplicação.
Isto propicia que cada aplicação ocupe uma região diferente do MPSoC, reduzindo o número de canais compartilhados por comunicações de aplicações diferentes.
Esta abordagem é denominada clusterização, pois simula a divisão do MPSoC em regiões (em inglês, clusters).
Vale ressaltar que o termo clusterização utilizado no trabalho difere da denominação utilizada para designar o agrupamento de tarefas num mesmo PE utilizado no mapeamento multitarefa.
Um cluster tem limites virtuais, sendo que uma aplicação pode utilizar recursos que ultrapassem os limites de um cluster para mapear suas tarefas.
De essa forma, o limite para mapear as tarefas de uma aplicação é função apenas da demanda da aplicação e da disponibilidade de recursos no MPSoC.
Entretanto, o número de aplicações simultâneas é limitado por o número de recursos dedicados a receber tarefas iniciais da aplicação.
Em a Figura 2, apresenta- se um exemplo MPSoC 6x6 particionado em 4 clusters.
Os PEs em destaque são aqueles reservados para o mapeamento das tarefas iniciais das aplicações.
Eles são posicionados preferencialmente no centro do cluster gerado por o particionamento.
Assim deve- se reduzir a sobreposição entre as tarefas de aplicações diferentes.
Em o caso deste MPSoC, é permitida a execução simultânea de 4 aplicações.
Em esta Seção são apresentadas as heurísticas de mapeamento proposta por Carvalho et al.
Que serão utilizadas como referência no presente trabalho.
Vale ressaltar que antes de executar estas heurísticas é verificado se há recursos disponíveis no sistema para mapear a tarefa requisitada.
Somente caso exista recursos disponíveis estas heurísticas são executadas.
Caso contrário, a tarefa requisitada é escalonada para ser mapeada em outro momento.
A forma com que isto é realizado não está no enfoque deste trabalho.
O algoritmo First Free (FF) seleciona o primeiro recurso livre para mapear uma nova tarefa.
A escolha deste recurso é diretamente relacionada ao caminho de procura usado na heurística que, no trabalho, é apresentado na Figura 3.
Este caminho se dá a partir de a esquerda para direita, buscando coluna por coluna, de baixo para cima.
O pseudocódigo desta heurística é mostrado na Figura 4, mostrando a simplicidade de seu algoritmo.
O algoritmo inicia analisando- se cada PE pi do sistema na ordem do caminho apresentado na Figura 3.
Para cada PE é verificado se ele está livre (linha 3).
Em caso afirmativo, este PE é o escolhido para o mapeamento, sendo terminada a execução do algoritmo (linha 4).
Caso contrário, prossegue- se a busca por um PE livre.
Esta heurística gera soluções não otimizadas, pois seu critério de mapeamento é extremamente simples, demandando um tempo de execução pequeno em relação a outras heurísticas que serão apresentados a seguir.
A heurística Nearest Neighbor (NN) considera apenas a proximidade de um recurso disponível para mapear a tarefa solicitada.
A procura por um recurso livre se dá a partir de a posição da tarefa mestre (i.
E. A tarefa que solicitou o mapeamento), conforme ilustrado na Figura 5.
A partir de esta posição é seguido um caminho circular, onde os vizinhos são testados de acordo com o número de hops (NH) necessários para a comunicação.
Assim, primeiramente são verificados os vizinhos localizados a um hop de distância da tarefa mestre.
Em este caso, quando um primeiro recurso livre é encontrado, é em ele que será mapeada a nova tarefa.
Caso não sejam encontrados recursos livres a um hop de distância, são testados os vizinhos localizados a dois hops de distância, depois com três hops e assim por diante, até chegarmos aos limites da NoC.
O caminho de procura da heurística NN também pode ser visto na Figura 5.
A heurística Best Neighbor (BN) combina estratégias da heurística PL (Path Load), detalhada a seguir, e NN.
A BN tem como principal objetivo a redução de congestionamentos na comunicantes.
A heurística PL percorre todos os PEs disponíveis do sistema, calculando o somatório de ocupação dos canais do caminho de comunicação entre a tarefa mestre (que solicita o mapeamento) e cada possível PE que está sendo testado para mapear a tarefa solicitada.
A nova tarefa é mapeada no primeiro PE que obtiver o menor custo de comunicação.
O maior problema desta heurística é o fato de ser exaustiva, podendo comprometer o tempo de execução de sistemas maiores.
Para resolver isso, foi proposta a heurística BN que utiliza a mesma função custo da PL (somatório da ocupação dos canais), porém com um diferente caminho de procura para encontrar um PE para mapear a tarefa requisitada.
O caminho de procura utilizado na BN é o mesmo da NN, porém não é selecionado o primeiro vizinho livre como em NN.
Em vez de isto, quando há mais de um nodo livre num anel de verificação, ou seja, com o mesmo número de hops de distância da tarefa mestre, o BN avalia e seleciona o melhor de eles de acordo com o cálculo da carga do caminho utilizado no algoritmo PL.
Vale ressaltar que para a obtenção de dados para o cálculo da função custo utilizada nas heurísticas PL e BN, é necessária a utilização de uma infraestrutura de monitoramento do sistema.
Em este caso, o monitoramento tem a função de recolher informações de volume de comunicação que está passando por os canais da rede.
Em a Figura 7 é mostrado um pseudocódigo descrevendo o comportamento do algoritmo da heurística BN.
Este algoritmo é praticamente igual ao da heurística NN, porém é inserida a função custo do PL.
De essa forma, como entrada para o algoritmo temse também o PE pm onde está mapeada a tarefa mestre.
E como saída espera- se um PE pi para se mapear a tarefa requisitada.
O algoritmo começa verificando os vizinhos mais próximos da tarefa mestre, atribuindo, assim, à variável dist o valor de 1 hop de distância.
Se nenhum mapeamento viável for encontrado durante essa iteração, a distância é incrementada, testando um novo grupo de vizinhos.
Para isto, em cada iteração da estrutura Enquanto, a função vizinhos (dist, pm) retorna a lista de todos PEs que estão a dist hops de distância do PE pm (PE da tarefa mestre).
Cada PE nesta lista é avaliado, sendo verificado primeiramente se este PE está livre ou em uso (linha 7).
Depois, caso estiver livre, é calculado o custo de mapeamento para este PE como proposto em PL.
O cálculo do custo está compreendido entre as linhas 10 e 12 do algoritmo.
Para isto, primeiro obtém- se a lista de canais que compõem a comunicação entre pm e pi (PE testado no momento), utilizando- se a função caminho_ roteamento (pi, pm) (linha 9).
Esta função retorna uma lista de canais conforme o algoritmo de roteamento utilizado.
A variável custo_ caminho é o custo de caminho obtido através da soma dos pesos (ocupação) de todos os canais da lista de canais.
Se o custo de caminho obtido for menor que o obtido anteriormente, a variável menor_ custo é atualizada, e é feito o mesmo para a variável melhor_ pe.
Finalmente, tendo- se obtido um PE, o algoritmo termina e é retornado o melhor PE para se mapear a tarefa requisitada.
As heurísticas NN e BN são estendidas para suportar mapeamento multitarefa em.
Para isto, o caminho de procura destas heurísticas é modificado, verificando primeiramente a possibilidade de mapear a tarefa solicitada juntamente no PE da tarefa que a solicitou.
Em a Figura 8, pode- se ver o pseudocódigo da heurística NN multitarefa.
A única modificação realizada é que se inicia o caminho de procura com o número de hops igual a zero, ou seja, no PE que solicitou a tarefa a ser mapeada, como se pode ver na linha 1.
O mapeamento multitarefa limita o número máximo de tarefas que podem ser mapeadas num mesmo PE.
Isto porque cada PE acessa uma memória de tamanho fixo, dividida em páginas.
Em cada uma destas páginas, que também têm um tamanho fixo, pode- se alocar uma tarefa.
Assim, a função estado (pi) (linha 6) retorna que um PE está livre, se ele tem páginas livres de memória para poder se alocar uma nova tarefa.
No caso de a heurística BN, são realizadas as mesmas modificações feitas para NN, visto que, como mencionado, BN utiliza o mesmo caminho de procura da heurística NN.
As heurísticas de referência aqui apresentadas foram avaliadas em, onde foram feitas comparações em relação a a carga dos canais, ocupação da rede, latência de pacotes, tempo de execução, complexidade dos algoritmos e número de hops.
Para avaliação das técnicas de mapeamento foi utilizado um ambiente de simulação que utiliza uma NoC descrita em VHDL RTL, enquanto os PEs são descritos em SystemC TLM.
A NoC utilizada possui topologia malha 2D com o algoritmo de roteamento XY.
Primeiramente é feita uma comparação entre as heurísticas de mapeamento dinâmico.
Para isto, é utilizado um MPSoC heterogêneo de tamanho 8x8, executando três cenários de teste que variam o tipo de aplicação (i.
e pipeline, árvore e genéricas), o número de tarefas de uma aplicação, a taxa de injeção de dados, e o tipo de recursos do sistema.
A heurística FF foi utilizada como referência de pior caso.
Em a Tabela 1, é mostrado um resumo dos resultados obtidos por Carvalho normalizados em relação a a heurística FF.
Observa- se que as heurísticas dinâmicas NN/ PL/ BN geram resultados médios similares.
Em a presente Dissertação são utilizadas as heurísticas de mapeamento dinâmico NN e BN como referência, dado que o tempo de execução para a heurística PL é superior às demais (complexidade O (x3)).
Além disso, a NN é utilizada como referência por ser utilizada como heurística de comparação em diversos trabalhos.
O Autor também avalia o custo do mapeamento dinâmico frente a o mapeamento estático.
Para isto são comparadas as heurísticas dinâmicas PL e BN com os algoritmos estáticos SA e Tabu Search (Ts).
A comparação foi realizada através de uma aplicação executando num MPSoC homogêneo de dimensões 5x4.
Os resultados obtidos neste teste são ilustrados na Tabela 2, normalizados de acordo com os resultados do algoritmo SA, utilizado como referência de mapeamento estático na presente Dissertação.
PL e BN apresentam respectivamente 4 e 3% de aumento do tempo de execução em relação a o algoritmo SA, mostrando o baixo impacto das heurísticas de mapeamento dinâmico no tempo total de execução.
A energia consumida na comunicação, PL e BN apresentam 38% mais consumo comparado ao SA.
Smit et al.[
SMI05] propõem um método iterativo hierárquico para o mapeamento de aplicações com reserva de recursos em SoCs heterogêneos, baseados em NoC.
O método visa reduzir o consumo de energia aliado à manutenção da Qualidade de Serviço primeiramente cada tarefa é atribuída a um tipo de recurso do sistema (e.
G. FPGA, DSP), de acordo com seus requisitos de desempenho.
Depois, cada tarefa é mapeada a um dos recursos disponíveis daquele tipo, procurando- se minimizar a distância entre tarefas comunicantes.
A o final, o mapeamento resultante é verificado, e caso não atenda as necessidades da aplicação, uma nova iteração é necessária.
Um único experimento que propõe o mapeamento de uma aplicação de 13 tarefas num SoC de dimensão 4x4 é utilizado para a avaliação do método proposto, que é comparado com outros dois métodos de mapeamento.
O primeiro método de comparação é o exaustivo, executado por 10 horas até encontrar a solução ótima.
Já, o segundo é o algoritmo minWeight apresentado em.
Como resultado, o algoritmo minWeight apresentou uma solução 5% pior comparada ao método exaustivo, o que é considerado bom por os Autores, porém segundo os mesmos este algoritmo apresenta baixa escalabilidade e flexibilidade.
Já o método iterativo hierárquico atinge a mesma solução do método exaustivo (solução ótima) com apenas três iterações, ou seja, em muito menos tempo, tornando- se, segundo os Autores, um método promissor a ser explorado em demais experimentos.
Ngouanga et al.
Apresentam uma heurística de Força Direcionada para o mapeamento de tarefas num MPSoC homogêneo, baseado em NoC.
A heurística seleciona o posicionamento para uma nova tarefa de acordo com uma força atrativa proporcional ao volume de comunicação e a distância entre as tarefas.
Os autores também avaliam o algoritmo Simulated Annealing (SA).
Os resultados mostram que a heurística de Força Direcionada é mais rápida quando comparada ao SA (uma ordem de grandeza), porém o número de iterações utilizado por o SA não é mencionado.
A distância média total do caminho de comunicação entre tarefas é equivalente em ambos os algoritmos.
Hölzenspies et al.
Investigam técnicas de mapeamento com requisitos de tempo real, considerando aplicações de streaming mapeadas em MPSoCs heterogêneos.
Para isto, é proposto um método para estimar o desempenho do mapeamento destas aplicações.
Segundo os Autores, o desempenho das aplicações executando num MPSoC é influenciado, entre outros fatores, por a organização de memória dos PEs, as frequências de relógio dos PEs e a NoC.
Por este motivo, métricas relativas à arquitetura de hardware utilizada (i.
e vazão, latência e energia) são integradas aos modelos de desempenho das aplicações em tempo de projeto.
Os recursos do MPSoC são gerenciados por um sistema operacional (SO) que utiliza estas informações coletadas sobre a aplicação e a arquitetura com o objetivo de satisfazer os requisitos de QoS, otimizar o uso de recursos e minimizar o consumo de energia.
Durante a execução, o SO determina quando a ferramenta de mapeamento é chamada e, quando uma aplicação deve ser migrada para executar mais eficientemente.
Esse trabalho concentra- se nos métodos de estimativa de desempenho de uma aplicação.
Já em, o processo de mapeamento é mais bem detalhado, utilizando uma abordagem de mapeamento iterativo hierárquico como em.
O processo de mapeamento utiliza os modelos de desempenho das aplicações propostos no trabalho anterior aqui relatado.
Em o trabalho, o algoritmo de mapeamento é executado sobre um processador ARM que leva 4ms para apresentar uma solução de mapeamento adequada.
Os Autores não fornecem comparações com outros métodos.
Chou e Marculescu apresentam uma estratégia incremental para mapeamento de tarefas em MPSoCs homogêneos baseados em NoC.
Os PEs conectados à NoC têm vários níveis de tensão, enquanto que a própria rede (incluindo canais, roteadores, etc) tem seu domínio de frequência e tensão próprio.
Um gerente global é responsável por encontrar uma área contígua para mapear uma aplicação, bem como para definir a posição das tarefas dentro de esta área.
Segundo os Autores, esta estratégia evita a fragmentação do sistema e tem como objetivo minimizar o consumo de energia de comunicação.
Em, os Autores estendem o trabalho para considerar também um modelo de comportamento do usuário no mapeamento das tarefas.
O comportamento do usuário alimenta um perfil de operação da aplicação, que contém dados sobre sua periodicidade e volume de dados transferidos entre suas tarefas.
Duas estratégias de mapeamento são investigadas.
A primeira de elas consiste no método adotado no trabalho anterior.
A outra estratégia define um formato de região para uma dada aplicação, e realiza transformações geométricas (como rotações) se necessário, para em seguida mapear a aplicação no MPSoC.
Para aplicações reais, considerando as informações do comportamento do usuário, os Autores obtiveram em torno de 60% de redução no consumo de energia em relação a um cenário de distribuição aleatória.
Al Faruque et al.
Propõem um esquema de mapeamento distribuído baseados em agentes.
O esquema proposto divide o sistema em clusters virtuais.
Um agente de cluster (Ca, em inglês cluster agent) é responsável por todas as operações de mapeamento dentro de um cluster.
Agentes globais (Ga, em inglês global agent) armazenam informações sobre todos os clusters da NoC e usam uma política de negociação com os CAs, a fim de definir em qual cluster será mapeada uma dada aplicação.
Um Ga, primeiramente, tenta encontrar um cluster apropriado para mapear uma aplicação;
Se nenhum cluster apropriado é encontrado, o Ga tenta usar a migração de tarefas para tornar um cluster apropriado para o mapeamento;
Enfim, se nenhum cluster apropriado e nenhum cluster candidato para migração de tarefas forem encontrados, então o conceito de re-clusterização (os clusters do sistema são definidos novamente) é utilizado.
O esquema de mapeamento distribuído proposto gera 10,7 vezes menor tráfego de monitoramento em comparação a um esquema centralizado para uma rede de dimensão 64x64.
Além disso, atinge um esforço de mapeamento 7,1 vezes menor em relação a a heurística Nearest Neighbor, proposta em, numa NoC de dimensão 64x32.
A forma em que é modelada a arquitetura de referência utilizada para a avaliação do trabalho não é mencionada.
Um melhor detalhamento da arquitetura se faz necessário, visto que dependendo da modelagem desta arquitetura a avaliação de desempenho pode ser imprecisa.
Mehran et al.
Apresentam um algoritmo de mapeamento dinâmico espiral (DSM, do inglês Dynamic Spiral Mapping), para mapear de forma otimizada os núcleos numa rede malha 2D.
O que se pretende no trabalho é otimizar o tempo de reconfiguração, ou seja, o tempo necessário para uma aplicação reorganizar a configuração atual de tarefas numa nova.
São apresentadas duas abordagens baseadas no DSM:
O FDSM (do inglês, Full Dynamic Spiral Mapping), mapeamento dinâmico espiral completo;
E o PSDM (do inglês, Partial Dynamic Spiral Mapping), mapeamento dinâmico espiral parcial.
O DSM é baseado em sua versão estática:
O SSM (do inglês, Static Spiral Mapping), que também é utilizado no processo de mapeamento proposto.
Em o algoritmo de mapeamento em espiral as tarefas com grande transferência de dados entre si são dispostas o mais próximo possível umas das outras, sendo que as tarefas com maior prioridade são mapeadas espiralmente do centro para a borda da rede.
O processo de mapeamento começa com a utilização do SSM no préprocessamento.
Depois, durante o tempo de execução, uma das duas abordagens baseadas no DSM é utilizada.
Em o FDSM, a cada vez que o grafo de aplicação é modificado, é parada a execução da aplicação e executado novamente o SSM para reconfigurar todas as tarefas da aplicação.
Já no caso de o PDSM, a reconfiguração é parcial, onde apenas tarefas necessárias são reconfiguradas.
Segundo os Autores, a vantagem do PDSM é poupar tempo de reconfiguração na rede, enquanto a desvantagem é que esta abordagem pode não gerar um mapeamento otimizado.
Os resultados experimentais mostraram que o PDSM apresentou vantagens na redução do tempo de configuração em 82% dos casos em comparação ao FDSM, com redução entre 5% e 28% no tempo para mapear a aplicação.
Carvalho et al.
Apresentam heurísticas de mapeamento que visam a redução do congestionamento em MPSoCs baseadas em NoC.
As heurísticas tentam reduzir o congestionamento da rede, aproximando tarefas comunicantes e reduzindo a carga do caminho de comunicação entre tarefas.
Segundo os autores, o custo das heurísticas de mapeamento dinâmico, em relação a o mapeamento estático, é de 10% na ocupação de canal, de 8,5% em latência, 3,5% em tempo de execução total e 15,5% no consumo de energia de comunicação.
Eles argumentam que é um overhead aceitável, considerando as vantagens oferecidas por o mapeamento dinâmico.
Entre estas vantagens podem ser apontadas:
Sistemas menores podem ser utilizados, já que apenas as tarefas a serem executadas são obrigadas a serem mapeadas no sistema, o número de tarefas pode ser superior aos recursos do sistema disponíveis, a inclusão de novas aplicações em tempo de execução estende a usabilidade do MPSoC.
A Seção Singh et al.
Estendem nas heurísticas de mapeamento dinâmico NN e BN propostas por Carvalho et al.
Para suportarem um mapeamento multitarefa.
Outra técnica de agrupamento é proposta em, também procurando maximizar o número de tarefas comunicantes num mesmo PE.
Esta técnica verifica as tarefas anteriormente mapeadas num dado PE para se tomar a decisão de mapeamento de uma tarefa solicitada neste PE:
Se a tarefa solicitada se comunica com alguma tarefa previamente mapeada neste PE, ela é mapeada, se não, então outro PE é verificado.
Além disso, uma tarefa pode ser mapeada num PE que não contenha nenhuma tarefa mapeada previamente.
Os Autores citam que em alguns casos, pode ocorrer o fato de um PE receber apenas uma tarefa, subutilizando os recursos do sistema.
Isto pode acontecer, por exemplo, no caso a seguir:
É solicitado o mapeamento de uma tarefa t1;
somente a tarefa t2 se comunica com t1;
e t2 está mapeada num PE que não pode mais receber tarefas.
Em este caso, segundo a técnica proposta, t1 só pode ser mapeada num PE pi onde não esteja mapeada nenhuma outra tarefa.
Desta forma, t1 será única em pi e, como não possui outras tarefas comunicantes, nenhuma outra tarefa poderá ser mapeada neste PE.
Outro problema que pode ocorrer e que não está detalhado no trabalho, é a questão de que algumas tarefas podem demorar para serem mapeadas.
Isto pode acontecer quando ocorrer o caso do exemplo anterior e não houver nenhum PE disponível que esteja completamente sem tarefas.
Assim, a tarefa solicitada terá de esperar até que algum PE assuma esta condição (não ter nenhuma tarefa mapeada) ou então que seja liberada uma posição de mapeamento num PE que conter sua tarefa comunicante.
Esta abordagem de clustering, em comparação com uma abordagem não-clustering, melhora em média 15% a ocupação dos canais e consumo de energia, com algumas melhorias na latência de pacotes e tempo de execução.
Wildermann et al.
Avaliam os benefícios do uso de uma heurística de mapeamento que visa a redução de energia aliada a manutenção de desempenho.
Esta heurística foi validada utilizando aplicações mestre/ escravo executando num MPSoC homogêneo baseado em NoC.
O ambiente de simulação (baseado em SystemC) pode criar ou excluir dinamicamente tarefas para uma aplicação, durante a simulação, emulando uma carga de trabalho dinâmico.
A heurística inclui uma métrica de proximidade de tarefas inspirada em regras conhecidas a partir de autômatos celulares, o que permite diminuir a sobrecarga de comunicação produzida por aplicações dinâmicas.
Os experimentos realizados avaliam a heurística proposta quanto a o overhead de comunicação na rede, o tempo médio relativo de processamento das aplicações e o deadline de uma aplicação.
O overhead de comunicação na rede é utilizado como indicador de energia consumida e o tempo relativo de processamento de uma aplicação é calculado dividindo- se a latência por o deadline de uma aplicação.
O primeiro experimento utiliza o mapeando aplicações sintéticas mapeadas numa NoC de dimensões 9x9.
Já o segundo experimento considera o mapeamento de uma aplicação de processamento de imagem adaptativo numa NoC 7x7.
Resultados mostram que a heurística NN, utilizada para comparação com a heurística proposta, apresenta o mais baixo overhead de comunicação da rede em ambos os experimentos, porém apresenta o pior resultado em relação a o tempo médio relativo de processamento no primeiro experimento e não cumpre o deadline da aplicação do segundo experimento.
Já a heurística proposta obtém o melhor compromisso entre as métricas avaliadas em ambos os experimentos.
Schranzhofer et al.
Propõem uma técnica de mapeamento dinâmico baseada em templates pré-computados de mapeamento (definidos em tempo de projeto).
Um gerente monitora o sistema em tempo de execução e escolhe o template précomputado apropriado.
Em comparação com abordagens de mapeamento estático, os resultados obtidos por os autores mostram que é possível alcançar uma redução média no consumo de energia entre 40 e 45%, sendo que o overhead introduzido para armazenar os templates de mapeamento é menor que 1 KB.
A Tabela 3 apresenta os trabalhos relacionados classificados de acordo com a taxonomia proposta de mapeamento para as heurísticas de mapeamento dinâmico, além de o objetivo de otimização destes trabalhos.
A Tabela revela duas características comuns na maioria das propostas:
Controle centralizado e mapeamento monotarefa.
Mesmo o controle centralizado não sendo escalável, esta é a estratégia adotada na maioria dos trabalhos.
O único trabalho que apresenta um controle distribuído é a proposta de Al Faruque et al.,
usando uma NoC com dimensão de até 64x64.
Este trabalho, como dito anteriormente, não define como é modelada a arquitetura de referência utilizada no trabalho.
NoCs de grandes dimensões, como a utilizada neste trabalho, requerem um grande tempo de simulação no caso de uso de uma modelagem de baixo nível.
No caso de uso de uma modelagem abstrata, a avaliação de desempenho pode tornar- se imprecisa.
Além disso, a definição de quando um controle centralizado se torna um gargalo, requerendo um controle distribuído, é uma questão em aberto na literatura.
Em os trabalhos revisados, as heurísticas de mapeamento são avaliadas em NoCs com topologia malha, com dimensões inferiores ou iguais a 8x8.
Em o presente trabalho é utilizada uma arquitetura com controle centralizado.
O uso de um controle distribuído é tema para trabalhos futuros.
A maioria dos trabalhos, excetuando- se Singh, utiliza mapeamento monotarefa, atribuindo apenas uma tarefa para cada PE.
Em um ambiente contendo processadores com sistema operacional multitarefa, a utilização de uma abordagem monotarefa subutiliza o uso do sistema.
Além disso, a utilização de uma abordagem multitarefa, com múltiplas tarefas executando simultaneamente num mesmo PE, reduz a comunicação no meio de interconexão do sistema, reduzindo a energia consumida na comunicação.
Para comprovar isto, neste trabalho são feitas comparações entre as abordagens mono e multitarefa.
O desafio para mapear várias tarefas em tempo de execução num mesmo processador é a forma de agrupar- las, uma vez que as abordagens de agrupamento (em inglês, clustering) exigem uma visão global da aplicação para um aumento no desempenho do mapeamento, como será mostrado neste trabalho.
Outra observação diz respeito à reserva de recursos.
Alguns trabalhos descrevem a reserva de recursos conforme o número de tarefas, definindo, por exemplo, templates de mapeamento pré-computados para cada aplicação.
Considerando que nem todas as tarefas sejam executadas simultaneamente, uma reserva de recursos para todas as tarefas da aplicação pode subutilizar o MPSoC, assim como exigir sistemas maiores.
Além disso, a reserva de recursos pode aumentar o tempo total de execução, visto que uma aplicação pode esperar até que haja recursos disponíveis para que todas suas tarefas sejam mapeadas.
O mapeamento dinâmico sem reservas usa os recursos do sistema quando são efetivamente necessários.
Por este motivo, o mapeamento sem reservas de recursos é utilizado neste trabalho.
A maioria dos trabalhos revisados utiliza modelos abstratos do sistema.
Como dito anteriormente, modelos abstratos como TLM permitem simulações mais rápidas, mas não permitem uma avaliação precisa de desempenho (tempo de execução, latência, consumo de energia).
Por outro lado, a modelagem RTL com precisão de ciclos de relógio fornece resultados mais precisos, porém com um longo tempo de simulação.
Alguns trabalhos, como, adotam um modelo misto, com PEs descritos em SystemC TLM e a NoC em VHDL RTL.
O presente trabalho adota esta modelagem mista, tendo por objetivo obter resultados rapidamente, com a precisão de um modelo totalmente descrito em RTL.
Por fim, o objetivo de otimização buscado por cada um dos trabalhos é variado, dependendo de restrições do sistema utilizado.
Este trabalho tem como meta de otimização a redução de energia consumida na comunicação.
Esta métrica foi escolhida devido a o fato que em dispositivos móveis o baixo consumo de energia é primordial.
Assim, este trabalho busca avançar o estado-da-arte em mapeamento dinâmico, e disponibiliza para a academia uma estrutura para avaliar os diferentes aspectos dos projetos MPSoCs.
O principal avanço deste trabalho é em relação a a implementação de heurísticas de mapeamento multitarefa, avaliadas em apenas um dos trabalhos apresentados.
O presente trabalho também mostra as vantagens de uma abordagem multitarefa comparado a uma monotarefa, principalmente na questão do consumo de energia consumida na comunicação.
Em este Capítulo é apresentado o MPSoC homogêneo HeMPS, utilizado como plataforma de referência deste trabalho.
Em esta plataforma é que são integradas as heurísticas de mapeamento dinâmico de tarefas desenvolvidas.
Assim, na Seção 3.1 são abordados aspectos da arquitetura e uma ferramenta utilizada para geração da plataforma.
Depois, na Seção 3.2, é abordada a infraestrutura de software, sendo explicado o microkernel que é executado nos processadores da plataforma.
Em a Seção 3.3 é apresentado como as aplicações são descritas para poderem ser executadas neste MPSoC.
Este Capítulo, além de apresentar a plataforma de referência, também apresenta duas contribuições da presente Dissertação.
A primeira compreende a integração das heurísticas propostas por Carvalho na plataforma de referência, o que exigiu a compreensão do hardware e do software da mesma (Seção 3.2.6).
A segunda contribuição corresponde à geração de código sintético para aplicações a serem executadas na plataforma, a partir de diagramas de sequência UML.
Arquitetura e ferramenta de apoio à geração da plataforma Os principais componentes do MPSoC HeMPS são os elementos de processamento, denominados Plasma-IP, que são interconectados por a NoC Hermes, utilizada como infraestrutura de comunicação.
Além disso, tem- se uma memória externa, chamada de repositório de tarefas.
Em a Figura 10 é ilustrada uma instância do MPSoC HeMPS utilizando a NoC Hermes de dimensão 2x3 interconectando os PlasmasIP.
Os elementos de processamento do MPSoC HeMPS, chamados Plasma-IP, são subdivididos em:
Mestre, chamado de Plasma-IP MP, responsável por a gerência dos recursos do sistema;
E escravos, chamados de Plasma-IP SL.
O MPSoC HeMPS tem uma gerência de recursos centralizada, contendo apenas um Plasma-IP MP.
Os componentes do Plasma-IP compreendem:
Além disso, o processador ainda oferece suporte a linguagem C e tratamento de interrupções.
O Plasma do MPSoC HeMPS possui algumas modificações em relação a o Plasma original, como por exemplo, a criação do mecanismo de interrupção, exclusão de módulos e inclusão de novos registradores mapeados em memória.
Plasma. No caso de os Plasma-IP SL, a memória é dividida em páginas de tamanho fixo onde é feita a alocação de tarefas.
É importante dizer que uma tarefa utiliza apenas uma página de memória.
A interconexão dos elementos de processamento do MPSoC HeMPS é realizada através da NoC Hermes.
Esta NoC é parametrizável e possui topologia malha 2D.
O mecanismo de comunicação é realizado por chaveamento de pacotes, utilizando modo de roteamento wormhole, em o qual um pacote é transmitido entre os roteadores em flits.
Os roteadores da NoC possuem buffers de entrada, uma lógica de controle compartilhada por todas as portas do roteador, um crossbar interno e até cinco portas bidirecionais.
Estas portas são:
East, West, North, South e Local.
A porta Local estabelece a comunicação entre o roteador e seu núcleo local, sendo as demais portas utilizadas para ligar o roteador aos roteadores vizinhos.
A arbitragem utilizada por o roteador da NoC Hermes é Round-Robin.
Essa política utiliza um esquema de prioridades dinâmicas, proporcionando um serviço mais justo que a prioridade estática.
Cada roteador possui um endereço único na rede.
Este endereço é expresso nas coordenadas XY, onde X representa a posição horizontal e Y, a posição vertical do roteador na rede, sendo a posição 00 no canto inferior esquerdo.
O algoritmo de roteamento utilizado é o XY, que envia os pacotes na rede primeiramente horizontalmente até chegar à posição de X do roteador destino, e depois percorre verticalmente, até encontrar o roteador destino.
O MPSoC HeMPS assume que todas as aplicações são modeladas através de um grafo de tarefas, em que somente as tarefas iniciais são carregadas no sistema no momento da inicialização do mesmo.
As demais tarefas são inseridas dinamicamente no sistema em função de as requisições de comunicação e dos recursos disponíveis.
O repositório de tarefas é uma memória externa que contém o código-objeto de todas as tarefas que executarão no sistema.
O Plasma-IP MP é o único a ter acesso ao repositório de tarefas e é responsável por alocar as tarefas em Os SL.
Todas as tarefas contidas no repositório são armazenadas em tempo de projeto, no momento da geração da plataforma.
Em a Figura 11 pode ser visto o formato do repositório de tarefas, onde cada posição é uma palavra de 32 bits.
Em a primeira posição deste repositório é armazenado o número total de tarefas do sistema.
Depois, o repositório se divide em duas seções:
Uma área contendo um cabeçalho para cada tarefa e uma área de dados contendo os códigosobjeto das tarefas.
Tanto os cabeçalhos, como os códigos-objeto são ordenados do menor ao maior identificador único de uma tarefa.
O cabeçalho de uma tarefa contém:
O ordenamento das tarefas e o tamanho fixo do cabeçalho de uma tarefa permitem o fácil acesso às informações de uma tarefa por o microkernel do Plasma-IP MP.
Este acesso é realizado através da obtenção do endereço de memória onde está contido o cabeçalho de uma tarefa, a partir de a Equação 1: End Mem (Id) 1 (tam cabeçalho Em esta equação, deseja- se encontrar o endereço de memória de uma tarefa com identificador Id..
Para isso, soma- se 1 (referente a a posição contendo o tamanho total de tarefas) com a multiplicação do Id por o tamanho do cabeçalho de uma tarefa tamcabeçalho.
Por exemplo, o cabeçalho da tarefa 5 estará no endereço 21).
Assim, acessando- se a posição 21 do repositório, pode- se obter as informações da tarefa, como o endereço inicial de memória onde está alocado seu código-objeto.
Repositório de Tarefas Total de Tarefas Tarefa 0 tamanho processador endereço inicial do cód..
Obj. Tarefa N tamanho processador endereço inicial do cód..
Obj. Este trabalho utiliza a infraestrutura de monitoramento proposta por Marczak.
Esta infraestrutura serve como base para algumas heurísticas de mapeamento que foram implementadas (i.
e BN multitarefa).
Esta infraestrutura de monitoramento analisa o desempenho da NoC Hermes através de monitores inseridos nas portas de entrada dos roteadores da rede.
Estes monitores têm por finalidade contar a quantidade de flits que passam por cada porta numa determinada janela de tempo.
De essa forma, este monitoramento indica a vazão em cada porta de entrada e permite, assim, determinar a carga da rede.
As informações geradas por cada monitor são enviadas a um módulo gerador de pacotes de controle (GPC).
Este módulo tem por finalidade enviar periodicamente pacotes de controle a um sistema de controle de monitoramento (MSA-Monitoring Service Access Point), onde as informações de todos os monitores são coletadas e utilizadas para a tomada de ações de controle do sistema.
A estrutura do roteador da NoC Hermes contendo monitores nas portas dos roteadores e o módulo gerador de pacotes pode ser visto na Figura 12.
Como há somente uma rede como infraestrutura de comunicação, pode- se ver também que são utilizados multiplexadores para que sejam transmitidos dados provenientes do IP (PE), ou seja, das aplicações, ou dados de monitoramento provindos do GPC.
O módulo gerador de pacotes recebe as informações sobre o tráfego provindo das cinco portas dos roteadores, encapsulando- as num pacote como o visto na Figura 13.
Este pacote tem um tamanho total de 10 flits, sendo quatro para o cabeçalho (header) e seis para o corpo de dados (payload).
Para compor o cabeçalho do pacote tem- se o campo target, em que é determinado o destino do pacote;
O campo size, que possui o tamanho total do corpo de dados do pacote e os campos serviceH e serviceL que possuem a parte alta e a parte baixa da palavra que identifica o serviço de monitoramento no microkernel do Plasma-IP MP.
Este serviço é denominado MONITORING_ PACKET, como será visto na Seção 3.2.3.
Já para os seis campos que compõem o corpo de dados tem- se:
Source, que identifica qual é o roteador gerador do pacote de controle e peast, pwest, pnorth, psouth e plocal, que contém a informação da quantidade de flits que passaram por as portas leste, oeste, norte, sul e local do roteador gerador do pacote de controle.
Estes pacotes são enviados de maneira periódica por cada roteador ao Plasma-IP MP, sendo este período uma janela de tempo que é definida por o projetista da rede.
A infraestrutura de monitoramento criada está inserida no microkernel do Plasma-IP MP do MPSoC HeMPS, que é o responsável por o MSA.
O microkernel trata o monitoramento como um serviço que recebe e identifica pacotes de controle, coletando seus dados e os armazenando em estruturas de dados.
Estas estruturas são compostas por cinco matrizes, uma para cada porta dos roteadores da NoC.
Cada posição das matrizes contém o volume de comunicação, em número de flits, que passa por aquela porta do roteador.
Estas matrizes são utilizadas como suporte às heurísticas de mapeamento BN mono e multitarefa, fornecendo a carga nos canais da rede.
Um ambiente automatizado, denominado HeMPS Generator, é responsável pala a geração da plataforma HeMPS.
A Figura 14 apresenta a interface gráfica principal do HeMPS Generator.
Em a tela principal do ambiente pode- se personalizar a geração da plataforma.
Primeiramente, o número de processadores da plataforma pode ser definido através dos parâmetros X e Y, os quais também representam cada uma das dimensões da rede malha utilizada.
Depois, pode- se definir o tamanho de cada página de memória assim como o tamanho total de memória, sendo que através de uma função destes dois parâmetros é definido o número máximo de tarefas executadas por os PEs escravos.
Além disso, para permitir a exploração mais rápida do espaço de projeto, processadores e memórias locais podem ser modelados usando ISS (em inglês, Instrution Set Simulator) e modelos C/ SystemC respectivamente.
Também foi inserido no contexto deste trabalho, a possibilidade de escolher qual das heurísticas de mapeamento dinâmico será utilizada.
Em o lado esquerdo da tela principal da ferramenta pode- se ver um painel contendo as aplicações adicionadas ao sistema, subdivididas por as suas tarefas.
Uma nova aplicação pode ser tanto adicionada ou removida utilizando os botões Add application e Delete application.
O mapeamento estático das tarefas pode ser feito facilmente apenas arrastando cada tarefa ao processador escravo desejado.
Já as tarefas contidas no processador mestre corresponderão ao repositório de tarefas do sistema e serão mapeadas dinamicamente.
A alocação das tarefas pode ser zerada através do botão Reset Allocation.
O botão Generate realiza a integração software-- hardware do sistema através da geração de códigos-objeto.
Esta ação gera os mickokernels para os PEs escravos e mestre, e o repositório de tarefas contendo o cabeçalho e o código-objeto de todas as tarefas.
Após essa geração, pode- se simular o sistema através de uma simulador RTL, como o ModelSim.
Por fim, o botão Debug abre uma janela onde podem ser vistas as mensagens de depuração de cada PE.
Microkernel Cada um dos processadores do sistema executa um microkernel.
Enquanto o microkernel do Plasma-IP SL tem como funções principais o suporte a serviços de execução multitarefa e comunicação entre tarefas, o Plasma-IP MP executa um microkernel que contém funções de gerência dos recursos do sistema, como por exemplo, o mapeamento de tarefas.
O microkernel do Plasma-IP MP é alocado inteiramente em sua memória privada.
Já os Plasma-IP SL têm sua memória divida em páginas de tamanho fixo.
Em a primeira página é alocado o microkernel e nas demais são alocados código-objeto das tarefas que estão executando neste PE.
O tamanho de cada página pode ser parametrizado de acordo com o tamanho da memória disponível.
O microkernel possui estruturas de dados para o controle de tarefas.
Para o gerenciamento de execução das tarefas há estruturas chamadas TCBs (Task Control Block) para cada uma das tarefas.
Uma TCB contém, entre outros dados, os valores dos registradores do Plasma que são usados para salvamento e recuperação de contexto de execução das tarefas.
Além disso, outras estruturas são utilizadas para guardar a localização das tarefas no sistema, para armazenar a ocupação dos PEs do sistema e requisições de serviços ainda não atendidas.
A estrutura do microkernel em níveis pode ser vista na Figura 15.
Em o primeiro nível está o serviço de inicialização do sistema (boot) onde são inicializados os ponteiros para dados globais e para pilha, a seção de dados estáticos e as estruturas de dados para gerenciamento das tarefas.
Além disso, após a inicialização, o serviço de boot aciona o escalonador de tarefas nos processadores escravos.
Acima de o boot, no Nível 2, encontram- se os drivers de comunicação.
Por fim, o Nível 3 é composto por os serviços de tratamento de interrupções, escalonamento, comunicação entre tarefas e chamadas de sistema.
Em este trabalho se dará enfoque nos níveis 2 e 3 do microkernel, pois são diretamente relacionados com o fluxo de mapeamento de tarefas utilizado.
Assim, na Seção 3.2.1 são apresentados os drivers comunicação.
A seguir, na Seção 3.2.2 são apresentadas as chamadas de sistema.
Depois, na Seção 3.2.3 é mostrado o tratamento de interrupções de hardware, seguido por o escalonamento (Seção 3.2.4) e comunicação entre tarefas, descrita na Seção 3.2.5.
Por fim é explicado o fluxo de mapeamento do microkernel (Seção 3.2.6), além de como é feita a inclusão de novas heurísticas de mapeamento.
Os drivers de comunicação são responsáveis por a comunicação entre os processadores do sistema e os módulos de hardware que compõe o Plasma-IP.
As DMA com a função de realizar leituras e escritas na memória.
Além disso, através da transmissão de blocos de memória através da NoC.
Estes drivers de comunicação são acessados utilizando o espaço de endereçamento do microkernel.
Chamadas de sistema (do inglês, system calls) são interrupções geradas por o software que requisitam um dado serviço ao sistema operacional.
Em o MPSoC HeMPS, as chamadas de sistema são utilizadas principalmente para prover comunicação entre tarefas e depuração, estando implementadas no microkernel do Plasma-IP SL.
Para o tratamento da comunicação entre tarefas são utilizadas as rotinas das primitivas responsável por a comunicação com o mundo externo.
Além disso, para a depuração tarefa terminou sua execução e não deve mais ser escalonada para execução.
Quando, durante a execução, uma tarefa utiliza uma destas chamadas de sistema, o Plasma-IP SL executa um salto de posição de memória para o microkernel, onde está contido o tratamento da chamada.
Antes disso, é feito salvamento do contexto da tarefa para posterior prosseguimento de sua execução.
O tratamento de interrupções só ocorre no Plasma-IP-SL, em que duas interrupções de hardware são implementadas.
A primeira sinaliza a recepção de um pacote de rede proveniente da Ni.
Já a segunda, sinaliza o fim de um timeslice (tempo pré-determinado) de execução utilizado por uma tarefa no escalonamento.
Antes do tratamento destas interrupções é feito o salvamento e recuperação de contexto das tarefas que estão executando no momento.
Para o tratamento da interrupção de timeslice é utilizada a rotina do escalonador, que define outra tarefa, se disponível, para executar no sistema.
Este escalonador utiliza o algoritmo Round Robin.
Os pacotes que trafegam na NoC contém em seus cabeçalhos a definição dos serviços que serão tratados por o microkernel.
Assim, quando um pacote é recebido, a suas informações para o tratamento daquele serviço.
Em o tratamento dos serviços, pode ser necessária a montagem e envio de novos pacotes, assim como a leitura da memória explicados anteriormente.
Estes serviços são detalhados a seguir:
Message_ request:
Um pacote do serviço de MESSAGE_ REQUEST é enviado por uma tarefa para realizar a requisição de uma mensagem a uma tarefa que está alocada em outro PE do sistema.
Message_ delivery:
Um pacote do serviço de MESSAGE_ DELIVERY contém a mensagem a ser entregue que foi requisitada por um pacote de TASK_ ALLOCATION:
Um pacote do serviço de TASK_ ALLOCATION é utilizado para a alocação de uma tarefa solicitada em determinado PE da rede.
TASK_ ALLOCATED:
É utilizado para informar que uma determinada tarefa foi alocada no sistema.
TASK_ REQUEST:
É utilizado para solicitar o mapeamento de uma tarefa.
Caso a tarefa solicitada já esteja mapeada, um pacote de resposta de LOCATION_ REQUEST é enviado à tarefa solicitante contendo a localização da tarefa solicitada.
TASK_ TERMINATED:
É utilizado para avisar que uma tarefa terminou sua execução.
TASK_ DEALLOCATED:
É utilizado para avisar que a tarefa terminou sua execução e pode ser liberada.
Location_ request:
É utilizado para requisitar e responder a localização de uma determinada tarefa.
Monitoring_ packet:
É um pacote utilizado por a infraestrutura de monitoramento para que sejam enviadas informações sobre o estado do sistema para o Plasma-IP MP.
Debug_ message:
É um pacote utilizado por os Plasma-IP SL para o envio de mensagens de depuração ao Plasma-IP MP, que a partir de estas mensagens gera um arquivo externo contendo o log de simulação chamado de output_ master.
Quando o microkernel do Plasma-IP MP recebe um pacote de serviço, e este não pode ser tratado no momento, a requisição do serviço é guardada numa estrutura de dados para ser tratada num momento posterior.
Um exemplo disto é uma requisição do tipo TASK_ REQUEST, onde está se solicitando o mapeamento de uma tarefa.
Caso não houver processadores disponíveis para o mapeamento no momento da solicitação, esta solicitação é armazenada numa estrutura de dados e é tratada num momento posterior.
É importante mencionar que pacotes que trafegam no sistema têm um tamanho máximo definido para o seu corpo de dados.
Assim, quando uma mensagem maior que o tamanho definido precisa ser enviada, esta mensagem é dividida em vários pacotes.
O escalonamento de tarefas implementado no microkernel do Plasma-IP SL é preemptivo e sem prioridades.
A política de escalonamento utiliza o algoritmo Round Robin.
Este algoritmo primeiramente define uma unidade de tempo chamada timeslice (do inglês, fatia de tempo).
Todas as tarefas são colocadas numa lista circular a qual é percorrida, alocando um timeslice de execução do processador para cada tarefa.
Quando termina o timeslice de uma tarefa e esta não é finalizada, esta tarefa é colocada no fim da fila de escalonamento e a primeira da fila é escalonada.
Sempre que uma tarefa é escalonada, um contador implementado em hardware é inicializado para o controle do timeslice.
Quando o timeslice é finalizado, é feito o salvamento de contexto da tarefa que está executando e uma interrupção é ativada para que o escalonador possa definir a nova tarefa a executar.
Para a execução desta nova tarefa é feita a restauração do contexto da mesma.
A comunicação entre tarefas no sistema é realizada através de trocas de mensagens que ocorre através de pipes.
Um pipe é uma área de memória reservada para a troca de mensagens que pertence ao mickrokernel.
Em esta área são armazenadas todas as mensagens das tarefas que executam num determinado PE.
As mensagens são armazenadas de forma ordenada, e consumidas de acordo com a mesma ordem.
Considere a Figura 16 que ilustra o processo de troca de mensagens no MPSoC HeMPS.
Quando a tarefa t1 deseja enviar uma mensagem msg à tarefa t2, é utilizada a pipe do Processador 1 onde está a tarefa t1.
Além disso, se a tarefa t2 ainda não estiver Plasma-IP MP, solicitando o mapeamento da tarefa t2.
Quando o Plasma-IP MP recebe este pacote, é realizado o fluxo de mapeamento mostrado na Figura 17, que será explicado na Seção a seguir.
Quando a tarefa t2 deseja receber msg de t1, é utilizada a primitiva Receive(&amp; msg, situações diferentes:
Processador 1 Processador 2 t1 Processador 1 t2 Send(&amp; msg, t2);
Receive; T3 Processador 2 t1 t2 Send(&amp; msg, t2);
A o receber uma solicitação de mapeamento através de um pacote TASK_ REQUEST, o microkernel do Plasma-IP MP executa o fluxo apresentado na Figura O primeiro passo do fluxo de mapeamento é o recebimento e identificação do pacote de TASK_ REQUEST.
Este pacote contém em seu payload informações referentes ao PE e Id da tarefa que solicitou o mapeamento, e o Id da tarefa a ser mapeada.
A seguir é verificado se a tarefa solicitada já está mapeada.
Caso estiver termina- se o fluxo, sendo enviado um pacote de TASK_ ALLOCATED endereçado ao PE que requisitou o mapeamento da tarefa.
Caso contrário, prossegue- se o fluxo.
Request task ti Sim ti já está mapeada?
Não Envia um pacote de com a localização de ti Não Há PEs disponíveis no sistema?
O fluxo prossegue verificando se há PEs disponíveis no sistema para o mapeamento da nova tarefa.
Em caso negativo, a tarefa é escalonada para ser mapeada em outro momento (este escalonamento está fora de o contexto do presente trabalho).
Em caso afirmativo, é utilizada uma heurística de mapeamento para encontrar um PE para mapear a tarefa solicitada.
O MPSoC HeMPS, antes da realização deste trabalho utilizava a heurística FF para o mapeamento de tarefas.
Como já explicado, esta heurística é extremamente simples e não provê um mapeamento otimizado.
A ausência de um método de mapeamento otimizado na HeMPS devia- se ao fato que o desenvolvimento da plataforma ocorreu em paralelo com o desenvolvimento das políticas propostas por Carvalho.
Tal limitação é explorada como motivação principal deste trabalho, que num primeiro momento integrou as heurísticas propostas de Carvalho no microkernel, e depois propôs novas heurísticas provendo suporte a mapeamento multitarefa.
A integração das heurísticas propostas por Carvalho no microkernel do Plasma-IP MP é a primeira contribuição do presente trabalho.
Para isto, foi necessária a compreensão do fluxo de mapeamento mostrado nesta Seção.
As heurísticas de mapeamento são, assim como o microkernel, descritas em linguagem C e inseridas no fluxo como uma rotina que é chamada passando- se por parâmetro a posição do PE que solicita o mapeamento da nova tarefa.
Procurou- se descrever o código visando um menor tempo de computação possível, pois esta computação pode influenciar no tempo total de execução das aplicações.
Estas heurísticas foram incluídas no microkernel conforme apresentado na Seção 2.2.
Além disso, para a heurística BN, foi necessária a utilização da infraestrutura de monitoramento, como explicado anteriormente.
Após a definição do PE a ser mapeada a tarefa através da heurística de mapeamento, o Plasma-IP MP configura o seu módulo de DMA, que acessa o repositório de tarefas e transmite o código-objeto da tarefa para o Plasma-IP SL escolhido.
Para isto é utilizado um pacote de TASK_ ALLOCATION.
Depois de mapeada a tarefa, um pacote de TASK_ ALLOCATED é enviado por o Plasma-IP MP para o PE que requisitou o mapeamento da tarefa e para o da tarefa mapeada, com o objetivo de eles atualizarem a localização desta nova tarefa.
Aplicações do Usuário As aplicações de usuário utilizadas na HeMPS são descritas em código C e se respectivamente, o envio e recebimento de mensagens entre tarefas, além de as primitiva mesmo nome.
Em a Figura 18 (a) pode- se ver o código em linguagem C da tarefa A da aplicação representada por o grafo da Figura 18 (b).
Este grafo representa uma aplicação com 4 tarefas transmitindo mensagens entre si.
Cada mensagem possui o volume de comunicação a ser transferido em número flits.
O código possui uma estrutura de dados do tipo Mensagem (linha 4) que contém o tamanho (volume de comunicação) e os dados da mensagem m1 a ser enviada por a tarefa A. Em a linha 14 é definido o tamanho desta mensagem com valor 30, de acordo com o grafo da aplicação.
Depois, no bloco entre as linhas 15 e 17 os dados desta mensagem são preenchidos.
Entre as linhas 19 e 22, esta mensagem é enviada por 10 iterações através da primitiva de comunicação Send.
Esta primitiva tem como parâmetros a mensagem a ser enviada, ou seja, uma estrutura de dados do tipo Mensagem e a tarefa destino desta mensagem (C).
Além disso, nas linhas 11 e 25, são enviadas mensagens de depuração ao Plasma-IP MP, informando depuração contendo a contagem de ciclos de relógio no momento de início e fim da tarefa.
Quando é usada a primitiva Echo (msg) com uma mensagem de depuração msg, a chamada de sistema de mesmo nome monta um pacote de Debug_ MESSAGE com msg endereçado ao Plasma-IP MP.
Echo (&quot;Tarefa A iniciada.&quot;);
Send; A segunda contribuição deste trabalho se refere à geração automática de códigos em linguagem C de aplicações para a plataforma HeMPS.
Isto foi feito devido a a falta de aplicações para serem utilizadas nos cenários de testes de avaliação das técnicas de mapeamento.
Assim, foi utilizado o modelo de aplicações utilizado no trabalho proposto por Ost em.
O Autor propõe um fluxo de projeto semi-automático baseado em modelos que permitem uma rápida análise de métricas de desempenho e diferentes alternativas de projeto de MPSoCs homogêneos baseados em NoC.
Para isto, são utilizados modelos de NoCs e aplicações, descritos através do ambiente Ptolemy II.
A utilização desta abordagem para a geração de códigos se deve principalmente ao fato do Autor já possuir várias aplicações reais modeladas.
Além disso, a utilização desta abordagem tem em vista uma futura integração das heurísticas de mapeamento do presente trabalho nos modelos abstratos de plataforma propostos por o Autor, o que possibilitará uma avaliação destas heurísticas em MPSoCs maiores, o que torna- se inviável no presente trabalho devido a o grande tempo de simulação.
O Ptolemy II é um ambiente de código aberto, desenvolvido na universidade de Berkeley, que consiste de um conjunto de pacotes Java que permitem a modelagem, simulação e projeto de sistemas concorrentes.
Este ambiente dispõe de uma interface gráfica, chamada Vergil, a qual permite a construção de modelos a partir de uma biblioteca de componentes característicos de uma modelagem orientada a atores.
A orientação a atores foi inicialmente, proposta como um modelo matemático de computação concorrente e, posteriormente, como um modelo de concorrência.
Os principais componentes dessa abordagem são atores e diretores.
Um diretor é responsável por comandar um conjunto de atores, definindo quando cada um deve agir e como são conectados entre si.
Já atores, são elementos concorrentes que se comunicam entre si, processando dados disponíveis em suas portas de entrada e os disponibilizando na porta de saída.
Usando idéias de orientação a atores e o ambiente Ptolemy II, modelos de aplicação executáveis foram criados, onde padrões de comunicação da aplicação são descritos a partir de diagramas de sequência UML.
Um diagrama de sequência representa uma sucessão de eventos entre objetos de um sistema, procurando fornecer uma ordenação temporal a estes eventos.
Para a representação de cada objeto utilizam- se linhas de vida (do inglês, lifeline), que são linhas verticais que representam tempo de vida de um objeto do sistema.
Já os eventos, são representados por uma flecha que sai de uma linha de vida em direção a outra, indicando uma troca de mensagens entre objetos.
Em este contexto, uma aplicação é representada no diagrama de sequência de maneira que cada linha de vida representa uma tarefa da aplicação e cada evento pode ser visto como uma mensagem entre tarefas.
As linhas de vida também denotam o sequenciamento de mensagens de uma aplicação, sendo que mensagens mais abaixo numa linha de vida acontecem depois das mensagens mais acima.
A Figura 20 apresenta um exemplo de um diagrama de uma aplicação, denominada communication, com quatro tarefas:
A, B, C e D. As tarefas iniciais desta aplicação são A e B. Essas tarefas iniciam sua execução enviando mensagens para a tarefa C, que por sua vez, envia cada mensagem recebida à tarefa D. A abordagem adotada permite ao projetista caracterizar uma dada aplicação através de uma série de parâmetros, apresentados a seguir, os quais são utilizados para a geração de códigos (em linguagem C) de aplicações executáveis na plataforma HeMPS.
Estes parâmetros são definidos através da interface gráfica do ambiente Ptolemy II.
A obtenção destes parâmetros, assim como a geração do código para as aplicações são obtidos através de um arquivo Java que rege a execução dos modelos propostos durante a simulação.
De essa forma, quando é iniciada a simulação de uma aplicação sobre uma dada plataforma, automaticamente estes códigos são gerados.
Os parâmetros obtidos a partir de o código Java são:
Ordem das mensagens de uma tarefa, volume de comunicação transmitido por cada mensagem (tamanho de uma mensagem em flits) e (iii) número de iterações que uma aplicação executará (e.
g Utilizando como exemplo a aplicação modelada através do diagrama de sequência da Figura 20, a geração do código em linguagem C para a tarefa A procede da seguinte forma, considerando:
Que o tamanho máximo do corpo de dados de um pacote a ser trafegado na rede tem valor 100 flits;
A ordem das mensagens da tarefa A é m1, m4 e m5;
o volume de comunicação de cada mensagem é 300 flits para m1, 200 flits para m4;
e 80 flits para m5;
a aplicação é executada por 10 iterações.
O código sintético gerado para a tarefa A desta aplicação é apresentado na Figura 21.
Send(&amp; m, D);
For; A geração inicia através da definição das bibliotecas utilizadas no código e uma estrutura do tipo Mensagem, utilizada para o armazenamento das mensagens recebidas (linhas 6-35).
Esta rotina, primeiramente contém declaração de variáveis auxiliares utilizadas.
Para a depuração do código são inseridas várias mensagens no código.
Estas mensagens obedecem a um formato que é utilizado para a interpretação das mesmas através de uma ferramenta que analisa o arquivo de log gerado na simulação.
Em a linha 10 e 33, podem- se ver mensagens que indicam, respectivamente, o início e o fim da tarefa.
Em as linhas 19 e 27, pode ser vista uma mensagem que indica o envio de dados, já na linha 23, o recebimento.
As mensagens de depuração de envio e recebimento contêm também informações de identificação de uma mensagem, além de o volume de comunicação enviado.
Por fim, na linha 28 é visto uma mensagem que indica o fim de uma iteração de execução da tarefa, contém o número da iteração que terminou.
Além disso, todas as mensagens possuem informação da A descrição da comunicação da tarefa acontece dentro de o laço for que indica o número de iterações que a aplicação será executada.
O número de iterações é obtido através do modelo da aplicação e inserido dentro de o laço for.
Dentro deste laço, primeiramente é visto o preenchimento do corpo de dados das mensagens a com números repetidos do valor da iteração corrente.
Isto facilita a depuração por formas de onda, onde se pode verificar de qual iteração pertence determinada mensagem.
A seguir, tem- se o bloco principal da comunicação da tarefa A. Em as linhas 17 a 18, é descrito o envio da mensagem m1 para a tarefa C. Para isto, primeiro define- se o tamanho do corpo de dados da mensagem.
Como o tamanho de m1 excede o valor máximo suportado por o pacote, define- se o tamanho com este valor máximo que é 100.
Assim, para o envio de m1 é necessário o envio de 3 pacotes de 100 flits.
Para pacotes, contendo mensagens de tamanho 100.
Uma situação parecida acontece com o recebimento da mensagem m4, que possui tamanho 200.
É utilizado um laço que recebe dois pacotes de tamanho 100 (linha 22).
Já no caso de a mensagem m5 (linhas 25 a 27), o caso é diferente.
Esta tarefa tem tamanho de 80 flits que é menor ao máximo permitido por pacote.
Assim, primeiramente define- se o tamanho da mensagem Para finalizar, nas linhas 16, 20 e 24 são inseridos comentários utilizados na extração das dependências das tarefas feita por a ferramenta HeMPS Generator, que será explicada na Seção 4.2.
Uma observação importante se refere ao tempo de computação de cada tarefa ainda não estar descrito no modelo, que é um dos trabalhos futuros do Autor.
Por o fato de não ser modelado ainda o tempo de computação, o código gerado descreve somente a comunicação de uma tarefa com as demais tarefas de uma aplicação, emulando um tempo arbitrário de computação que separa uma iteração de outra.
Este Capítulo apresenta as novas heurísticas de mapeamento dinâmico, que se configuram nas principais contribuições do presente trabalho.
Assim, a Seção 4.1, apresenta o mapeamento de tarefas iniciais de uma aplicação, passo inicial para a realização do mapeamento dinâmico de tarefas.
Depois, a Seção 4.2, apresenta como é realizada a extração de dependência e volume de comunicação entre as tarefas, que são utilizados na implementação das novas heurísticas propostas.
A seguir, a Seção 4.3, apresenta heurísticas de mapeamento monotarefa buscando otimizar as heurísticas propostas por Carvalho.
E por fim, a Seção 4.4, propõe heurísticas visando o mapeamento multitarefa.
Mapeamento das Tarefas Iniciais da Aplicação Poucas referências são encontradas na literatura, ao conhecimento do Autor, sobre o mapeamento de tarefas iniciais, as quais incluem Carvalho e Singh, que utilizam a mesma abordagem.
Esta abordagem leva em conta a divisão do MPSoC em clusters, também utilizada neste trabalho, porém se difere em dois pontos deste trabalho.
Primeiro porque é considerado que uma aplicação pode possuir mais de uma tarefa inicial, ao contrário de a abordagem de Singh e Carvalho, que considerava apenas uma tarefa inicial.
Segundo, porque é considerado que as tarefas iniciais podem ter dependências entre si num momento futuro, assim deve- se considerar essa possível dependência no momento do mapeamento.
Levando em consideração estes dois pontos, o mapeamento de tarefas iniciais é feito estaticamente por o projetista, de forma manual, através do conhecimento prévio do grafo das aplicações.
Extração de Dependência de Tarefas As heurísticas desenvolvidas por Carvalho em não levam em conta todas as dependências entre tarefas para a realização do mapeamento de tarefas.
Somente é observada a posição da tarefa a ser mapeada em relação a a tarefa que requisitou o seu mapeamento, excluindo- se as outras que também interagem com a mesma.
Assim, o mapeamento obtido não é otimizado devido a caminhos de comunicação não considerados durante o mapeamento.
Para resolver este problema, este trabalho otimiza estas heurísticas, considerando dependências múltiplas no momento de realização do mapeamento.
A aplicação MPEG tem SDRAM e SRAM2 como tarefas iniciais.
Em a figura pode- se observar que no total de doze tarefas, têm- se cinco que tem mais de uma dependência de comunicação.
Um exemplo é a tarefa UPSAMP2 que é dependente de duas tarefas:
SDRAM e SRAM2.
No caso de as heurísticas NN e BN, supondo que SDRAM, por exemplo, solicite o mapeamento de UPSAMP2, o mapeamento considerará somente a localização da primeira tarefa no momento do mapeamento, desconsiderando a posição de SRAM2 que também é uma tarefa dependente.
Assim, as otimizações empregadas propõem que, no momento da escolha de mapeamento da tarefa UPSAMP2, busque aproximar esta tarefa de todas suas dependentes de comunicação, ou seja, as tarefas SDRAM e SRAM2.
Vale ressaltar que pode ocorrer o fato de nem todas as tarefas serem mapeadas próximas as suas dependências, pois estas dependências podem não estar ainda mapeadas.
A aplicação MPEG representada por o diagrama de sequência da Figura 22 também pode ser representada na forma de um grafo.
Apresentado na Figura 23, porém sem mostrar as dependências entre as tarefas.
Em este grafo os vértices representam tarefas e arestas representam a comunicação entre as tarefas.
Em cada aresta pode- se ver um valor que denota o volume de comunicação transferido entre as tarefas em número de flits.
A direção desta comunicação é mostrada através de flechas que apontam para a tarefa que está recebendo o volume de dados.
As informações relativas às dependências de comunicação entre as tarefas, assim como o volume de comunicação, devem ser conhecidos no momento do mapeamento.
Para obtenção destas informações, o presente trabalho utiliza a ferramenta HeMPS Generator.
Esta ferramenta analisa o código em linguagem C que descreve cada tarefa das aplicações presentes no sistema.
Este código possui um tag colocado como comentário, no momento da geração do código, da seguinte forma:
Assim, quando o código de uma tarefa ti é analisado, ao se encontrar uma linha no &quot;com volume de comunicação «Esta informação e de todas as outras tarefas são coletadas e armazenadas num arquivo de header, criado por a ferramenta HeMPS Generator no momento da geração da plataforma.
Este arquivo possui uma função que é utilizada para o preenchimento de uma estrutura de dados presente no microkernel, em tempo de execução.
Esta estrutura de dados é consultada no momento do mapeamento, para a escolha de um PE para mapear uma tarefa.
É importante mencionar que através do ambiente Ptolemy II, onde foram modeladas as aplicações (diagrama de sequência), também seria possível a extração das dependências, assim como a geração do arquivo de header.
Porém, a estratégia de inserir comentários no código C para a extração das dependências possibilita que o projetista gere códigos de aplicação de forma manual, sem depender do ambiente Ptolemy II.
Mapeamento Monotarefa com Dependências Múltiplas Em esta Seção são apresentadas as heurísticas monotarefa que buscam otimizar o trabalho de Carvalho, utilizando o conceito de dependências múltiplas.
As heurísticas propostas são Dependences Neighborhood (do inglês, vizinhança de dependências) que tem uma variante, a heurística Low Energy Consumption ­ Dependences Neighborhood (do inglês, baixo consumo de energia -- vizinhança de dependências).
A heurística Dependences Neighborhood (DN) utiliza apenas uma função de custo:
A proximidade, em número de hops.
Diferentemente das heurísticas NN e BN, que mapeiam a tarefa solicitada o mais próximo possível da tarefa que a solicitou, a DN considera o conceito de dependências múltiplas apresentado anteriormente, mapeando a tarefa solicitada o mais próximo possível das tarefas com que ela se comunica que já estão mapeadas.
Esta heurística utiliza dois caminhos de procura diferentes:
Um para quando se tem apenas uma tarefa dependente daquela que se quer mapear, e outro para quando se tem dependências múltiplas.
No caso de existir apenas uma tarefa dependente utiliza- se o mesmo caminho de procura utilizado em NN, procurando a partir de a tarefa que requisitou o mapeamento primeiramente nos vizinhos a um hop de distância, depois dois hops, e assim progressivamente.
No caso de dependências, utiliza- se primeiramente a busca dentro de um quadrado envolvente entre as tarefas dependentes da tarefa solicitada.
Caso não seja encontrado nenhum PE livre, procura- se nas primeiras linhas e colunas que circundam o quadrado envolvente e segue- se progressivamente até os limites da rede.
Um exemplo deste caminho de procura pode ser visto na Figura 24, onde se deseja mapear uma tarefa que já possui duas tarefas dependentes mapeadas:
A e B. Assim, primeiramente são avaliados os PEs que estão dentro de o quadrado envolvente entre A e B. Não encontrando PEs livres, o caminho prossegue avaliando os PEs quadriculados que circundam o quadrado envolvente.
Por último, caso ainda não sejam encontrados PEs livres, são avaliados os PEs pontilhados.
Considere a aplicação da Figura 25 (a), contendo quatro tarefas, onde A e B são as tarefas iniciais e se comunicam com a tarefa C. Em um dado momento o mapeamento da tarefa C é solicitado por a primeira tarefa que deseja se comunicar com ela, por exemplo, a tarefa A. Em este caso, como a tarefa C possui duas tarefas comunicantes já mapeadas, o espaço de busca por um PE para mapear- la corresponde ao quadrado envolvente definido por a posição das tarefas A e B (Figura 25 (b)).
Com isto, buscará- se- mapear a Tarefa C o mais próximo possível das Tarefas A e B. Assim, avaliam- se os PEs livres dentro de o quadrado envolvente calculando- se o somatório das distâncias em hops até A e B, utilizando o roteamento XY.
Em este caso, todos estes PEs possuem um somatório de distâncias igual a 3: PEs 22 e 31 estão a um hop de distância de A e dois de B;
E os PE 21 e 12 estão a um hop de B e dois de A. De essa forma, o primeiro PE encontrado com este somatório é o escolhido, que no caso foi o PE 12.
Note que a tarefa D ainda não está mapeada, uma vez que depende da tarefa C. A Figura 26 apresenta o pseudocódigo do algoritmo DN.
A heurística tem como entrada uma tarefa ti a ser mapeada.
Cada tarefa ti possui conjunto Cti contendo suas tarefas comunicantes.
O algoritmo começa obtendo as tarefas que se comunicam com ti que já estão mapeadas, colocando- as na lista_ de_ dependentes (linha 2).
Esta lista é testada para ver qual dos caminhos de procura será utilizado no algoritmo:
No caso de o algoritmo agir como a NN, obtém- se o PE da única tarefa dependente contida na lista_ de_ dependentes e a partir de isso começa- se a busca nos vizinhos distantes a um hop deste PE e assim progressivamente.
No caso de múltiplas dependências, primeiramente obtém- se a área do quadrado envolvente através da lista_ de_ dependentes (linha 22).
Depois, todos os PEs dentro de esta área são armazenados na lista_ de_ PEs (linha 25).
Para cada PE pi nesta lista é calculado o somatório da distância em hops até cada uma das tarefas dependentes di.
Entre os PEs livres analisados, é retornado para o mapeamento aquele que obtiver um menor somatório (linha 45).
Caso nenhum PE livre seja encontrado neste quadrado envolvente, este é aumentado, como explicado anteriormente, e assim progressivamente até se chegar aos limites da rede.
A heurística Low Energy Consumption ­ Dependences Neighborhood (LEC-DN) é baseada na heurística DN e tem como principal objetivo a redução na energia de comunicação.
Diferentemente da heurística DN, a heurística LEC-DN emprega uma função custo que considera dois critérios:
Proximidade, em número de hops, e o volume de comunicação entre tarefas.
O segundo critério é usado quando uma determinada tarefa se comunica com pelo menos duas tarefas mapeadas.
Em esta situação, a nova tarefa é mapeada o mais próximo de a tarefa com maior volume de comunicação.
Esta heurística, assim como a DN, utiliza dois caminhos de procura para selecionar um PE para mapear a tarefa selecionada.
No caso de haver apenas uma tarefa dependente, a LEC-DN se comporta como a NN.
Já no caso de haver múltiplas dependências, a procura dentro de o quadrado envolvente é utilizada selecionando o PE que proporcione um menor consumo de energia de entre os demais.
Para isto, é utilizado o consumida na comunicação para transmitir um bit por uma distância de nhops, utilizando a Equação 2.
E bit n hops* E Sbit* E Lbit onde:
ESbit, ELbit e nhops representam o consumo de energia num roteador, nos fios de interconexão e o número de roteadores por onde o bit passou.
O valor de nhops é obtido a partir de o critério de proximidade em número de hops apresentado anteriormente.
Já o volume de comunicação é utilizado para indicar o número de bits transmitidos.
Por fim, os valores de ESbit e ELbit são obtidos a partir de o modelo de energia proposto em.
Vale ressaltar que é considerada uma NoC malha homogênea, sendo que a energia consumida para a transferência de um bit por cada roteador da rede é a mesma.
A Figura 27 mostra o pseudocódigo da heurística LEC-DN.
Este pseudocódigo é praticamente igual ao da heurística DN, com a principal diferença que a métrica principal utilizada agora é o consumo de energia na comunicação, utilizada no caso de a tarefa solicitada ter mais de uma dependência de comunicação já mapeada.
Assim, são analisados todos os PEs dentro de um quadrado envolvente, como na heurística DN, porém para cada um de eles é calculado o somatório de energia consumida na transferência de dados para cada uma das tarefas que se comunicam com a tarefa solicitada.
Este somatório pode ser visto na linha 31 do código, onde é acumulada a energia consumida que é calculada simplesmente através da multiplicação da distância até uma tarefa comunicante e o volume de comunicação transferido.
Para explicar melhor a heurística, será utilizada a mesma aplicação utilizada no exemplo heurística DN, vista no grafo da Figura 28 (a).
O grafo desta aplicação possui agora o volume de comunicação transferido entre as tarefas, denotado ao lado de cada aresta.
De a mesma forma que o exemplo anterior, esta aplicação possui as tarefas iniciais A e B que se comunicam com a tarefa C. A tarefa C é solicitada, utilizando- se assim a heurística LEC-DN para escolher um PE para mapear- la.
Como a tarefa C possui duas tarefas comunicantes já mapeadas (A e B), se utiliza como espaço de busca o quadrado envolvente entre estas tarefas.
Assim, cada PE deste quadrado será analisado, calculando- se o somatório da energia consumida usada na comunicação até as tarefas A e B. O PE escolhido é o 22), pois foi o primeiro PE encontrado que apresenta uma menor energia de comunicação consumida:
Está a um hop de distância de A que envia 150 flits a C;
Está a dois hops de distância de B que envia 100 flits a C;
Totalizando numa energia consumida com peso 350.
O PE 31 também tem um peso de consumo de energia de 350 e poderia ser escolhido.
Já os PEs 12, que foi o escolhido por a heurística DN, e 21 apresentam um peso de 400.
Pode- se perceber que a tarefa C será mapeada mais próxima da tarefa A, uma vez que de acordo com o grafo de aplicação, o volume de comunicação em A C é maior que em B C. Mapeamento Multitarefa com Dependências Múltiplas Em esta Seção são apresentadas as heurísticas de mapeamento dinâmico multitarefa propostas neste trabalho.
Primeiramente é apresentada a heurística LEC-DN-MT, uma extensão para multitarefa da heurística LEC-DN apresentada anteriormente.
Depois, é apresentada a heurística PREMAP-DN, uma otimização da heurística LEC-DN com a utilização do método de agrupamento PREMAP.
A heurística LEC-DN foi estendida para multitarefa, sendo chamada de LEC-DN-MT (Low Energy Consumption ­ Dependeces Neighborhood -- Multitask).
Para suportar um mapeamento multitarefa, a heurística LEC-DN foi modificada da mesma forma que ocorreu nas versões de NN e BN multitarefa.
De essa forma, a procura por um PE para mapear uma tarefa solicitada agora inclui também a possibilidade do mapeamento desta tarefa no mesmo PE de suas comunicantes.
Para isto, a única mudança no pseudocódigo da heurística LEC-DN, da Figura 27 ocorre na linha 6 onde o valor de dist começa em zero.
Além disso, o conceito de PE livre se estende para considerar a abordagem multitarefa, onde livre é sinônimo de páginas livres para realizar o mapeamento de uma nova tarefa.
A heurística PREMAP-DN (PREMAP -- Dependeces Neighborhood) otimiza o mapeamento multitarefa, integrando a heurística LEC-DN-MT com o método de agrupamento PREMAP.
Este método tenta suprir a maior restrição de uma abordagem de mapeamento dinâmico de tarefas sem reserva de recursos, que é a ausência de uma visão (conhecimento) global de aplicação.
Em esta abordagem de mapeamento, as tarefas são mapeadas quando são solicitadas por uma de suas tarefas comunicantes.
De essa forma, esta abordagem de mapeamento só vem a ter conhecimento de uma tarefa quando é solicitado o seu mapeamento.
Em outras palavras, esta abordagem tem como restrição a ordem de solicitação das tarefas para realizar o mapeamento, o que interfere diretamente na qualidade de mapeamento.
O método de agrupamento busca otimizar o mapeamento, proporcionando uma visão mais ampla da aplicação.
Uma melhor explicação sobre a interferência de uma visão global da aplicação no momento do mapeamento é apresentada na Seção 5.3.3, onde é comparado o algoritmo de mapeamento estático SA que tem visão global da aplicação, com as heurísticas de mapeamento dinâmico monotarefa apresentadas anteriormente.
Esta Seção primeiramente apresenta o método PREMAP que visa agrupar um conjunto de tarefas comunicantes num mesmo PE.
Depois, mostra a integração do PREMAP com a heurística LEC-DN-MT, assim como o novo fluxo de mapeamento utilizado.
O objetivo do método PREMAP, como dito anteriormente, é agrupar um conjunto de tarefas comunicantes num mesmo PE.
Este método é executado sempre quando uma tarefa nova é mapeada num novo PE (que não continha tarefas anteriormente).
A idéia principal deste método é de reservar um lugar para o mapeamento de uma tarefa, possibilitando que ela esteja o mais próximo possível de suas tarefas comunicantes.
Para isto, este método utiliza uma estrutura de dados que será apresentada a seguir, que possibilita uma visão mais ampla da aplicação.
É importante ressaltar que uma tarefa é dita premapeada, quando ela possui uma posição de mapeamento reservada dentro de um PE.
Esta reserva não indica que este método necessita de uma reserva de recursos para o mapeamento de uma aplicação inteira, visto que esta reserva só é utilizada para priorizar que tarefas comunicantes sejam mapeadas num mesmo PE.
Quando o sistema é iniciado, as tarefas iniciais são mapeadas, de acordo com sua posição definida em tempo de projeto.
Em o exemplo, a tarefa inicial tA é mapeada no PE Assim, este método analisa cada tarefa tj do conjunto C (tA) verificando se tj não se comunica com nenhuma tarefa com um volume de comunicação maior do que o volume e tC são aquelas que se comunicam com um maior volume com tA, visto que só se comunicam com tA, elas são premapeadas junto a tarefa A no PE 01.
Em um momento posterior, depois do mapeamento da tarefa inicial, tB e tC são solicitadas a serem mapeadas.
Como elas já estavam premapeadas, elas são efetivamente mapeadas no PE 01 (através da transmissão de seus códigos-objeto).
Caso não estivessem premapeadas, uma heurística de mapeamento seria executada para encontrar um PE para mapear- las, no caso a heurística LEC-DN-MT.
Em seguida solicita- se o mapeamento de tD.
Como esta tarefa não foi premapeada, a heurística LEC-DN-MT é utilizada e escolhe o PE 00 para mapear tD.
Como tD &quot;abriu «um novo PE (o PE não possuía tarefas anteriormente), o método PREMAP é executado avaliando- se o grupo C (tD) para premapeada é tE, por ser a primeira tarefa do conjunto C (tD).
Para isto, é verificado em C (tE) se há uma tarefa que se comunique com tE com um maior volume de comunicação do que tD.
Como o volume de comunicação em tEtG é superior ao volume de comunicação tEtD, tE não é premapeada no mesmo PE de tD.
Em seguida tA deveria ser analisada, mas como já está mapeada, prossegue- se analisando tF.
Como o volume de comunicação de tFtD é superior ao de tEtF, tF é premapeada junto a tD.
Assim, terminase a execução do PREMAP para o PE 00 com duas tarefas:
TD mapeada e tF premapeada.
Ainda sobra uma posição para o mapeamento de uma tarefa no PE 00, que pode ser utilizado por a heurística de mapeamento.
A Figura 30 mostra a implementação do método PREMAP, que busca tarefas comunicantes de ti a serem premapeadas no PE pi.
O método começa atribuindo a nC (ti) o conjunto de tarefas não mapeadas que se comunicam com ti, ordenadas do maior ao menor volume de comunicação (linha 2).
O próximo passo avalia cada tarefa di de nC (ti), para escolher quais tarefas serão premapeadas em pi.
Esta avaliação acontece enquanto pi possuir um número de tarefas mapeadas/ premapedas menor que Tarefas_ por_ PE (o número máximo de tarefas suportadas por um PE), ou se todas as tarefas possíveis em nC (ti) já foram avaliadas.
Para cada tarefa di, a primeira tarefa hi da sua LTC C (di) é obtida (linha 7).
Depois, é verificado se hi é igual a ti para verificar se di se comunica com o maior volume com ti.
Em caso afirmativo, di é premapeada em pi, incrementando também o número de tarefas mapeadas ou premapeadas em pi.
Caso contrário, a próxima tarefa da LTC C (di), se disponível, é avaliada.
É importante mencionar que verificar se uma tarefa comunicante de ti se comunica com ti com o maior volume de comunicação é extremamente simples.
Basta verificar se ti é a igual à primeira tarefa da LTC de sua tarefa comunicante.
A heurística PREMAP-DN é a combinação do método PREMAP e a heurística LECDN-MT através da integração de ambos no fluxo de mapeamento do microkernel do Plasma-IP MP, como pode ser visto na Figura 31.
Quando uma tarefa ti é solicitada a ser mapeada por um Plasma-IP SL, uma mensagem de REQUEST_ TASK é enviada ao Plasma-IP MP, que ao receber- la, começa a executar o fluxo de mapeamento.
Assim, primeiramente, é verificado se existe algum recurso disponível no sistema.
Se não houver recursos disponíveis, a tarefa é escalonada para ser mapeada mais tarde.
Caso contrário, o fluxo de mapeamento prossegue para a próxima etapa.
Request task ti Não Escalona ti para ser mapeada posteriormente Há PEs disponíveis no sistema?
Sim Sim Envia um pacote de com a localização de ti já está mapeada?
Não Sim ti já está premapeada?
Não Executa heurística de mapeamento Mapeia ti no PE onde está premapeada Mapeia ti no PE pi escolhida por a heurística Envia um pacote de com a localização de ti Não Apenas ti está mapeada em pi?
O próximo passo verifica se ti já está mapeada.
Caso estiver, envia- se para o PE de quem solicitou ti um pacote de TASK_ ALLOCATED informando a localização de ti.
Caso a tarefa não esteja mapeada, verifica- se se ti já está premapeada.
Em caso afirmativo, a tarefa é efetivamente mapeada no PE onde estava premapeada, caso contrário, a heurística de mapeamento LEC-DN-MT é executada.
Esta heurística retorna o PE pi onde ti é mapeada.
Depois do mapeamento, mensagens de TASK_ ALLOCATED para informar a localização de ti são enviadas à pi e ao PE da tarefa que requisitou ti.
Além disso, é verificado se pi tem apenas uma tarefa mapeada, o que significa que contém apenas a tarefa ti.
Se for verdade, a heurística PREMAP é chamada para avaliar tarefas que se comuniquem com ti a serem premapeadas em pi e o fluxo é finalizado.
Este Capítulo avalia as heurísticas de mapeamento propostas frente a vários cenários de teste e diversas aplicações.
As três métricas avaliadas incluem:
Energia consumida na comunicação, somatório da distância em hops entre tarefas comunicantes e tempo total de execução das aplicações mapeadas.
Estes cenários, bem como as aplicações utilizadas são descritas na Seção 5.1.
Depois, a Seção 5.2 avalia a definição da janela de envio de pacotes usada na infraestrutura monitoramento, visto que esta infraestrutura é utilizada nas heurísticas BN monotarefa e multitarefa.
Por fim, apresenta- se a avaliação das heurísticas que é dividida entre a avaliação das heurísticas monotarefa, apresentada na Seção 5.3, e das heurísticas multitarefa, apresentada na Seção 5.4.
Cenários de Teste Para a realização dos cenários de teste foi utilizado como plataforma o MPSoC HeMPS configurado como segue:
NoC malha 2 D, algoritmo de roteamento XY, tamanho do flit de 16 bits, pacotes com tamanho 128 flits e controle de fluxo baseado em créditos.
O MPSoC é dimensionado da seguinte forma:
7x6 para a realização de testes de mapeamento monotarefa e 3x5 para o mapeamento multitarefa.
Considerando- se até 3 tarefas mapeadas por processador, o mapeamento multitarefa pode mapear até 42 tarefas, enquanto o monotarefa pode mapear até 41 tarefas.
De essa forma, as configurações de sistema escolhidas proporcionam praticamente um mesmo número de tarefas executando simultaneamente.
Assim, pode- se realizar uma comparação justa entre as abordagens de mapeamento multitarefa e monotarefa.
O modelo de consumo de energia foi calibrado usando a tecnologia CMOS de 65 nm com tensão de alimentação de 1,0 V da St/IBM, adotando estratégia de clock-- gating, e uma freqüência de 100 MHz de relógio.
Este modelo de energia foi utilizado para a obtenção de valores de energia consumida nos canais e roteadores da NoC.
Estes valores foram inseridos na Equação 2, apresentada anteriormente, para o cálculo da energia de comunicação consumida.
Além disso, a fim de avaliar a heurística BN, tanto em sua versão mono como multitarefa, a infraestrutura de monitoramento, apresentada na Seção 3.1.4, foi utilizada.
Aplicações reais e sintéticas modeladas em código C, contendo a descrição da comunicação entre as tarefas, são utilizadas.
Os códigos destas aplicações foram gerados a partir de os diagramas de sequência e o ambiente Ptolemy II, como foi descrito anteriormente.
As aplicações, assim como o seu comportamento de comunicação, são descritos a seguir:
MPEG-4: É um padrão utilizado para compressão de dados digitais de áudio e vídeo, definido por o Moving Picture Experts Group (MPEG).
Em este trabalho, é utilizada uma aplicação que contém 12 tarefas simulando a iteração entre os módulos de hardware de um decodificador do padrão MPEG-4.
Esta aplicação contém, como característica relevante, um alto grau de comunicações:
Duas das 12 tarefas estão ligadas a até 7 outras tarefas.
O grafo desta aplicação é ilustrado por a Figura 32.
VOPD: É uma aplicação que simula a iteração entre os módulos de hardware de um decodificador VOP (do inglês, Video Object Plane Decoder ou VOPD) através de 12 tarefas e um formato de fluxo de dados.
Esta aplicação tem duas tarefas iniciais:
ARM e VLD, que iniciam suas execuções paralelamente.
O comportamento desta aplicação pode ser mais bem avaliado através da Figura 33.
Aplicação Veicular: Aplicação de controle veicular modelada com 10 tarefas.
Esta tarefa contém um alto nível de dependência de comunicação entre tarefas, sendo também transferido um alto volume de dados entre as tarefas.
Além disso, há várias comunicações paralelas.
O grafo desta aplicação pode ser visto na Figura 34.
Circuito: Aplicação sintética de 4 tarefas, que apresenta comportamento de fluxo de dados.
O grafo desta aplicação é mostrado na Figura 35.
Segmentação de Imagem:
Aplicação de segmentação de imagem contendo 6 tarefas.
Contém comunicações paralelas.
O grafo desta aplicação é ilustrado na Figura 36.
Hipotética: Aplicação sintética contendo 6 tarefas.
A Figura 37 apresenta o grafo desta aplicação.
Os cenários de teste utilizados são mostrados a seguir:
A. MPEG-4, VOPD, Aplicação Veicular e Circuito;
B. MPEG-4, VOPD, Segmentação de Imagem é Hipotética;
C. MPEG-4 e VOPD;
D. MPEG-4, Aplicação Veicular e Circuito;
E. MPEG-4, MWD e VOPD.
Os cenários A, B e E, contêm 38, 36 e 36 tarefas, respectivamente.
Estes cenários correspondem a uma ocupação do MPSoC igual a 93% (cenário A) e 86% (cenário B e E).
Estes 2 cenários testam as heurísticas de mapeamento dinâmico num pior caso, uma vez que o espaço de busca é drasticamente reduzido quando quase todas as tarefas já estão mapeadas.
Os cenários C e D contêm 24 e 26 tarefas, respectivamente, permitindo avaliar as heurísticas de mapeamento quando o espaço de busca não é restrito.
Em estes cenários as aplicações executam por 10 iterações, sendo que entre cada iteração há um intervalo de aproximadamente 28 mil ciclos de relógio nas tarefas inicias da aplicação, simulando, por exemplo, o intervalo entre a decodificação de frames por uma aplicação.
O objetivo da execução das aplicações por várias iterações é que haja iterações em que a execução da aplicação não sofra interferência dos pacotes de mapeamento que trafegam na rede, permitindo uma melhor avaliação da comunicação das aplicações.
O valor de 10 iterações foi escolhido arbitrariamente.
As métricas de desempenho avaliadas são descritas a seguir:
Tempo total de execução:
É o tempo até que todas as tarefas das aplicações terminem de executar as 10 iterações definidas nos casos de teste.
Como explicado anteriormente, o tempo de computação não está presente nos códigos da aplicação, assim, o tempo total de execução mostra o tempo necessário para que todas as comunicações entre tarefas sejam realizadas.
Somatório da distância em hops entre tarefas comunicantes:
Um menor somatório de número de hops indica a utilização de caminhos curtos na comunicação entre tarefas, tornando este critério uma estimativa do congestionamento e ocupação da rede.
Caminhos longos de comunicação aumentam a utilização dos canais da rede e a probabilidade de ocorrência de congestionamentos.
Energia consumida na comunicação:
Energia consumida para a transmissão de dados por a NoC.
Para isto, é levada em consideração a energia consumida para transmitir cada bit por os roteadores e canais da rede.
Definição da Janela de Envio de Pacotes de Monitoramento Como mencionado anteriormente, a infraestrutura de monitoramento apresentada na Seção 3.1.4 é utilizada nas heurísticas BN monotarefa e multitarefa para prover informações do sistema em tempo de execução que serão utilizadas na escolha do mapeamento.
Uma das questões a serem definidas na utilização desta infraestrutura, é a definição da janela de tempo, isto é, o intervalo de tempo em que os pacotes de monitoramento serão enviados ao Plasma-IP MP.
Diversos cenários de teste foram utilizados para o dimensionamento desta janela, porém neste trabalho para fins de simplificação, serão mostrados apenas os casos extremos:
O pior caso obtido e o melhor.
Estes dois casos são suficientes para mostrar que um mau dimensionamento da janela de tempo pode interferir diretamente no desempenho do mapeamento.
Assim, para a avaliação da janela de tempo, foi utilizado como base o cenário C, apresentado anteriormente.
Este cenário é executado no MPSoC HeMPS com dimensão 3x5, utilizando a heurística de mapeamento BN multitarefa.
A janela de tempo foi variada em dois valores:
10 mil ciclos de relógio e 70 mil ciclos de relógio.
As três métricas de desempenho apresentadas anteriormente são utilizadas para avaliação dos dois casos.
Observa- se por a tabela que a diferença é significativa quanto a o tempo total de execução.
A utilização de uma janela de tempo de 10 mil ciclos de relógio apresenta um aumento de 732% em relação a a utilização de uma janela de 70 mil ciclos de relógio.
Isto deve- se ao fato de que a janela de tempo de 10 mil ciclos produz 7 vezes mais tráfego de pacotes de monitoramento na rede, com maior carga de processamento no MSA.
Com isso, pode- se deduzir que o aumento no tempo total de execução é proporcional à redução da janela de tempo, ou seja, como mostrado, diminuindo- se 7 vezes o tamanho da janela, observa- se um aumento de 7 vezes no tempo de execução.
Outra explicação para este aumento, deve- se ao fato do envio destes pacotes ser realizado compartilhadamente com o envio de pacotes de dados, através de um multiplexador na porta local de cada roteador da NoC.
Assim, os pacotes de monitoramento podem causar um atraso no envio de pacotes de dados, aumentando ainda mais o tempo total de execução do sistema.
Além disso, o dimensionamento da janela de tempo em 10 mil ciclos de relógio apresentou um aumento de 49,6% de energia consumida na comunicação em relação a a janela dimensionada em 70 mil ciclos.
Isto pode ser explicado por um mapeamento diferente em ambos os casos, visto que o mapeamento é influenciado diretamente por o tráfego de pacotes na rede.
Isto se deve ao fato do tráfego poder mudar a ordem em que a solicitação de uma tarefa chega ao Plasma-IP MP, devido a canais congestionados, mudando o mapeamento como um todo.
Assim, não se pode afirmar que o aumento da janela de tempo tem influência na redução de energia de comunicação para os pacotes de dados, visto que a ordem de solicitação das tarefas que resulta num melhor consumo de energia pode acontecer num dimensionamento de janela de tempo desconhecido.
Por outro lado, no consumo de energia de comunicação avaliado, não foram levados em conta a energia consumida no envio de pacotes de monitoramento.
Assim, pode se afirmar que quanto menor a janela de tempo, maior a energia consumida na transferência de pacotes de monitoramento, visto que há um aumento no volume destes pacotes, como foi mostrado anteriormente.
Desta forma, adota- se uma janela de tempo de 70 mil ciclos de relógio para a avaliação das heurísticas de mapeamento que necessitam de monitoramento da rede.
A utilização desta janela propiciou às heurísticas BN (mono e multitarefa), a obtenção de um tempo de execução igual ou melhor que as outras heurísticas sem monitoramento, como será mostrado a seguir.
Avaliação das Heurísticas de Mapeamento Dinâmico Monotarefa Esta Seção avalia as heurísticas de mapeamento monototarefa, considerando os 5 cenários apresentados.
As heurísticas avaliadas nos cenários de teste são NN, BN, DN e LEC-DN.
Além disso, com o objetivo de comparar a abordagem de mapeamento dinâmico com a estática, o algoritmo SA é utilizado.
A avaliação dos cenários de teste é dividida por cada métrica de desempenho:
Tempo total de execução, na Seção 5.3.1;
somatório de número de hops, na Seção 5.3.2;
e energia consumida na comunicação, na Seção 5.3.3.
Por fim, são feitas considerações sobre as heurísticas considerando todas as métricas avaliadas, na Seção 5.3.4.
A Tabela 5 apresenta os resultados experimentais obtidos na avaliação dos cenários de teste em relação a o tempo total de execução das tarefas, em milhões de ciclos de relógio.
O melhor resultado para cada cenário de teste está destacado na tabela.
Através da análise dos resultados mostrados na tabela, verifica- se que a heurística LEC-DN é a que obtém um maior tempo total de execução médio.
Esta heurística obtém, em relação a a SA, NN, BN e DN, um aumento no tempo total de execução médio para todos os casos de aproximadamente 2%, 1,6%, 3,6% e 0,3%, respectivamente.
Este aumento no tempo de execução se deve ao maior tempo de computação utilizado por a heurística, que ao contrário de as heurísticas NN e BN, considera mais de uma dependência de comunicação de uma tarefa.
A heurística DN, que também considera mais de uma dependência de comunicação de uma tarefa no momento de mapeamento obtém resultado similar ao LEC-DN.
Já, a heurística BN é aquela que apresenta uma maior redução no tempo total de execução.
Esta redução é de 1,7%, 1,8%, 2,8% e 3,1% comparado à SA, NN, DN e LECDN.
Esta redução se deve principalmente ao fato desta heurística ter como objetivo principal a redução de congestionamento na rede.
De essa forma, ela procura reduzir a carga na rede e assim, proporciona um menor tempo de comunicação.
Lembrando que o tempo total de execução avaliado considera apenas a comunicação entre tarefas.
O algoritmo SA apresenta uma maior variação do tempo total de execução entre todos os casos.
Este algoritmo apresenta o menor tempo nos casos B e C, porém também apresenta o maior tempo total de execução em comparação às heurísticas avaliadas nos casos A e D. Como este algoritmo é aplicado em tempo de projeto, todas as aplicações são mapeadas conjuntamente no início da execução do sistema, causando uma sobrecarga no tráfego na rede devido a os pacotes de mapeamento.
Este comportamento também seria observado em outros algoritmos realizados em tempo de projeto, como Taboo Search.
Em os casos A e D soma- se a esta sobrecarga, o grande volume de dados transferidos, principalmente por a aplicação veicular, o que explica o maior tempo de execução nestes casos.
Já nos casos B e C, a transferência de dados entre as tarefas é menor, obtendo- se assim uma menor sobrecarga na rede e por consequência um menor tempo de execução.
A Tabela 6 mostra a avaliação dos casos teste em relação a o somatório da distância em hops entre tarefas comunicantes, com destaque ao melhor resultado para cada caso.
Pode- se notar por estes resultados destacados que a heurística DN é a que obtém os menores valores para a métrica avaliada.
Isto pode ser explicado, tendo em vista que a redução da distância em hops entre tarefas comunicantes é o principal objetivo desta heurística.
Esta redução é de 15,4%, 9%, 9,6% e 3,8% respectivamente para SA, NN, BN e LEC-DN.
A Tabela 7 ilustra os resultados experimentais obtidos quanto a a energia consumida na comunicação, para os cenários de teste avaliados.
Em destaque estão os resultados com melhor desempenho para cada caso.
De entre as heurísticas de mapeamento dinâmico, a heurística LEC-DN é que obtém os melhores resultados.
Esta heurística obtém uma redução média de energia consumida na comunicação de 9,8%, 9,6% e 4,8% em relação a a NN, BN e DN, respectivamente.
Estes bons resultados obtidos por a heurística LEC-DN são consequência da consideração do volume de comunicação no momento do mapeamento.
As demais heurísticas consideram apenas a proximidade em hops entre as tarefas comunicantes.
O custo, em energia de comunicação, do mapeamento dinâmico comparado ao estático é de 19%, 18%, 12% e 6% para as heurísticas NN, BN, DN e LEC-DN, respectivamente.
Mostra- se assim que houve uma significativa otimização no mapeamento dinâmico, reduzindo o custo deste frente a a abordagem estática para apenas O algoritmo SA apresenta o menor consumo de energia devido a o fato de avaliar um número maior de alternativas de mapeamento do que as heurísticas dinâmicas.
O SA consegue isto, pois seu tempo de execução não compromete o tempo total de execução do sistema, visto que é executado em tempo de projeto.
Além disso, o algoritmo SA realiza o mapeamento de todas as tarefas da aplicação ao mesmo tempo, enquanto as heurísticas dinâmicas realizam o mapeamento de acordo com solicitações que ocorrem a partir de o mapeamento das tarefas iniciais de uma aplicação.
De essa forma, as heurísticas dinâmicas têm como restrição a ordem de solicitação das tarefas para realizar o mapeamento, o que interfere diretamente na qualidade de mapeamento.
Já, o algoritmo SA não possui esta restrição.
Para melhor exemplificar a diferença entre o algoritmo SA e as heurísticas de mapeamento dinâmico considere o exemplo de mapeamento da Figura 39.
Em o exemplo, supõe- se o mapeamento da aplicação do grafo da Figura 39 (a) num MPSoC de dimensões 2x3, como ilustrado na Figura 39 (b).
Esta aplicação possui 6 tarefas, sendo A a tarefa inicial mapeada no PE 01.
A tarefa A possui 4 tarefas comunicantes:
B, C, D e F. Em o caso de uma das heurísticas de mapeamento dinâmico, o mapeamento das demais tarefas será feito no momento em que forem solicitadas.
Assim, supõe- se que primeiramente A solicita o mapeamento da tarefa B, que é mapeada através de uma heurística num dos PEs que estão a 1 hop da tarefa A (PEs mais próximos de A), como por exemplo, no PE 00.
Depois são solicitadas em sequência, as tarefas C e D, que são mapeadas respectivamente nos PEs 02 e 11, ambos a 1 hop de distância de A. A tarefa F, também comunicante com A, só será mapeada depois do mapeamento da tarefa E, como pode ser visto no grafo da aplicação.
Supõe- se o mapeamento final das tarefas como ilustrado na Figura 39 (b).
O que se pode notar é que o mapeamento não foi otimizado, pois a tarefa F está mais distante de A, porém esta é a tarefa que se comunica com A com uma maior transferência de dados.
Isto ocorre, pois as heurísticas dinâmicas não têm o conhecimento da existência desta tarefa até que ela seja solicitada.
Isto não ocorre no algoritmo SA, pois este tem uma visão geral de todas as tarefas a serem mapeadas, conseguindo aproximar da tarefa A, as tarefas com que ela se comunica com maior volume de dados.
Assim, na Figura 39 (c), é mostrado um possível mapeamento otimizado para a aplicação.
Pode- se notar que as tarefas que mais se comunicam com A (F, D e C) estão mais próximas a ela.
Através da análise dos resultados apresentados, conclui- se que entre as heurísticas de mapeamento dinâmico a que apresenta um melhor compromisso entre as métricas de desempenho é a LEC-DN.
Em relação a as demais heurísticas, a LEC-DN obtém resultados expressivos na redução de energia de comunicação, conseguindo reduzir até 23,7% num dos casos de teste (no caso D, em comparação à NN).
Esta vantagem é obtida ao custo de um aumento do tempo total de execução médio de 3,6% comparado às outras heurísticas, o que é considerado aceitável frente a o ganho na redução de energia.
As heurísticas NN e BN, apesar de apresentarem um menor tempo total de execução, não obtêm uma redução tão efetiva de energia de comunicação.
No caso de a heurística BN, agrava- se o fato devido a a utilização da infraestrutura de monitoramento para a coleta de informações para a realização do mapeamento.
Além de o consumo de energia utilizado para o funcionamento desta infraestrutura, também se deve constar o consumo na transmissão de pacotes de monitoramento por a rede.
Pacotes estes que não são levados em conta nos resultados experimentais apresentados.
Outro fator negativo no uso do monitoramento é o aumento de área da NoC.
Por fim, o algoritmo SA mesmo gerando os melhores resultados em relação a a energia consumida de comunicação, não suporta cenários de carga dinâmica de trabalho, dado seu alto tempo de execução.
O uso de um algoritmo SA num cenário dinâmico, com poucas iterações (para reduzir seu tempo de execução), conduziria a resultados não otimizados.
Vale ressaltar que as heurísticas que apresentam um menor somatório da distância em hops, não apresentam obrigatoriamente um menor consumo de energia de comunicação, pois não consideram o volume de comunicação.
Isto pode ser observado através dos resultados obtidos por a heurística DN que apresenta uma redução de respectivamente 15,4% e 3,8% em relação a a SA e LEC-DN, porém tem um aumento de energia na comunicação de 12,2% e 5,2% em relação a estas duas técnicas, respectivamente.
Avaliação das Heurísticas de Mapeamento Dinâmico Multitarefa Esta Seção apresenta a avaliação das heurísticas de mapeamento multitarefa.
Os cenários de teste utilizam um MPSoC com dimensão 3x5, permitindo a execução de até 42 tarefas simultâneas, considerando até 3 tarefas por PE.
As heurísticas avaliadas são NN e BN multitarefa, LEC-DN-MT e PREMAP-DN.
Além disso, para comparação das abordagens mono e multitarefa é usada também a heurística LEC-DN, para a qual são utilizados os resultados apresentados anteriormente, utilizando um MPSoC de dimensões 7x6.
A heurística LEC-DN é utilizada, pois obteve os melhores resultados em redução de energia de comunicação entre as heurísticas monotarefa.
Assim como na avaliação entre as heurísticas monotarefa, esta Seção é dividida por a avaliação de cada métrica de desempenho:
Tempo total de execução, na Seção comunicação, na Seção 5.4.3.
A o final, na Seção 5.4.4, são feitas considerações sobre as heurísticas avaliadas.
A Tabela 8 apresenta os resultados relativos ao tempo total de execução para cada cenário, em milhões de ciclos de relógio, destacando- se o melhor resultado para cada caso.
Em estes cenários de teste o tempo total de execução para os cenários B/ C/ E é dominado por o tempo de execução de aplicações MPEG e VOPD, enquanto os cenários A/ D são dominadas por a aplicação veicular.
Primeiramente é feita uma comparação entre as abordagens mono e multitarefa.
Através desta comparação nota- se que a sobrecarga média do tempo total de execução em relação a a heurística monotarefa LEC-DN é de 14%, 13%, 16% e 19%, para as heurísticas NN, BN, LEC-DN-MT e PREMAP-DN, respectivamente.
Esta sobrecarga no tempo de execução nas heurísticas multitarefa se deve principalmente ao compartilhamento do tempo de execução entre as tarefas executando num mesmo processador, definido por fatias de tempo no algoritmo de escalonamento utilizado.
Assim, durante uma fatia de tempo de execução do processador, uma tarefa pode ficar um longo período em estado de repouso sem executar esperando o recebimento de uma determinada mensagem.
Isto acarreta num desperdício de tempo de execução, pois quando esta tarefa se torna ociosa, uma nova tarefa poderia assumir a execução.
Além disso, vale relembrar que as heurísticas multitarefa estão executando num MPSoC de dimensão menor que a heurística monotarefa (dimensão 3x5 contra 7x6).
De essa forma, com a utilização de um MPSoC de tamanho menor, o tempo de execução pode aumentar devido a maior probabilidade de existir congestionamentos na rede.
Isto acontece, pois o mesmo número de tarefas da avaliação monotarefa agora compartilham um número reduzido de canais da rede neste MPSoC menor.
Por estes motivos, pode- se dizer que a sobrecarga no tempo de execução é relativamente baixa comparado à abordagem monotarefa, considerando que a abordagem de mapeamento multitarefa permite com que diversas tarefas executem num mesmo processador, possibilitando o uso de MPSoCs menores e o aumento da utilização dos processadores.
Agora, comparando somente as heurísticas multitarefa, pode- se perceber que a heurística que apresenta o menor tempo de execução varia de caso a caso.
A heurística PREMAP-DN é a que tem o maior tempo de execução entre todos os casos, apresentando um aumento médio de aproximadamente 4%, 4,9% e 2,7% em relação a a NN, BN e LEC-DN-MT, respectivamente.
Isto pode ser explicado por o fato do maior tempo de computação utilizado por a heurística PREMAP-DN, que combina a heurística LEC-DNMT com o método PREMAP.
Este aumento é baixo, considerando as vantagens desta heurística que serão apresentadas nas Seções a seguir.
Já, a heurística BN é a que obtém o menor tempo total de execução entre as demais.
Esta heurística obtém uma redução no tempo de execução em média de 0,6%, 1,9% e 4,3%, em comparação à NN, LEC-DN-MT e PREMAP-DN.
Os motivos para esta redução foram explicados anteriormente, na avaliação do tempo total de execução para a abordagem de mapeamento monotarefa.
A Tabela 9 apresenta os resultados obtidos em relação a o somatório da distância em hops entre tarefas comunicantes, sendo destacado o melhor resultado em cada caso.
Primeiramente, pode- se ver que a utilização de uma abordagem multitarefa reduz em média 45% o somatório da distância em hops em relação a a abordagem monotarefa.
Em a abordagem multitarefa a distância entre tarefas comunicantes pode ser de 0 hops, nos casos em que estas tarefas estão alocadas num mesmo PE.
De essa forma o tráfego de comunicação destas tarefas não passa por a rede, sendo internas aos PEs.
Com isto, o consumo de energia na comunicação é reduzido numa abordagem multitarefa, como será mostrado na Seção a seguir.
É a BN, sendo melhor em 80% dos casos.
Esta heurística consegue uma redução de 11%, 8,6% e 10,3% em relação a a NN, LEC-DN-MT e PREMAP-DN, respectivamente.
Isto se deve ao fato da heurística BN ter como objetivo principal de otimização a redução do congestionamento na rede, podendo avaliar em tempo de execução a carga nos canais da rede para realizar o mapeamento.
Este não é o objetivo principal das heurísticas propostas neste trabalho.
A avaliação da energia consumida na comunicação entre tarefas do sistema é o principal objetivo de otimização das heurísticas propostas neste trabalho.
Assim, a avaliação desta métrica de desempenho se torna fundamental para o cumprimento dos objetivos do trabalho proposto.
Em a Tabela 10 são mostrados os resultados obtidos em relação a a energia consumida na comunicação para cada cenário de teste, onde os melhores resultados são destacados.
A comparação entre a heurística monotarefa com as multitarefa demonstra uma clara redução de energia na comunicação na abordagem multitarefa.
Em a Figura 40 podem- se observar os resultados desta redução nas heurísticas multitarefa comparativamente a heurística LEC-DN.
Esta redução chega a uma média de 56% em todos os casos de teste.
Isto se deve, principalmente por a redução de tráfego na rede causado por o mapeamento de várias tarefas num mesmo PE, como explicado anteriormente.
Entre as heurísticas multitarefa, a PREMAP-DN obtém uma redução de energia de comunicação em 80% dos casos.
Comparativamente às outras heurísticas, esta redução é de respectivamente 18,6%, 14,3% e 18,8% para NN, BN e LEC-DN-MT.
Esta redução é maior se desconsiderarmos o caso B, onde PREMAP-DN foi superada por NN e LEC-DNMT.
Desconsiderando o caso B, a redução atinge 28,8%, 13,8% e 26,3% comparado à NN, BN e LEC-DN-MT respectivamente.
A explicação por o resultado obtido por a heurística PREMAP-DN no caso B, deve- se principalmente ao mapeamento da aplicação VOPD que possui um baixo índice de dependências e um baixo volume de comunicação transferido entre tarefas.
Esta aplicação também está presente nos casos A, C e E. Em os casos A e E, a redução de energia de comunicação nas demais aplicações mapeadas compensa um maior consumo obtido por a aplicação VOPD.
Já no caso C, como há um espaço de busca menos restrito, o mapeamento da aplicação VOPD consegue um baixo consumo de energia comparando- se aos outros cenários.
Assim, pode- se avaliar que a heurística PREMAP-DN apresenta um melhor comportamento na redução de energia para o caso do mapeamento de aplicações que possuem um alto grau de dependências e alto volume de comunicação transferido entre tarefas.
Além disso, um espaço de busca maior, ou seja, uma rede com menor taxa de ocupação dos PEs também leva esta heurística à obtenção de resultados melhores.
Isto pode ser comprovado em dois cenários de teste:
Um ponto importante a se ressaltar se refere à heurística LEC-DN-MT, que não obteve os resultados esperados.
Isto se deve a dois fatos principais.
O primeiro é devido a o fato das heurísticas NN e BN terem seu comportamento otimizado devido a a abordagem de mapeamento multitarefa.
Estas heurísticas, na abordagem monotarefa não conseguiam mapear as tarefas de um conjunto de tarefas comunicantes próximas as outras, devido a o seu comportamento de considerar somente o par de tarefas mestre/ escravo na escolha do mapeamento.
Em o caso, da abordagem multitarefa, como pode- se alocar mais de uma tarefa por PE e tem- se um tamanho de rede reduzido, as tarefas comunicantes acabam ficando mais próximas, otimizando essas heurísticas (NN e BN).
O segundo fato se deve ao comportamento da heurística LEC-DN-MT, que tem tendência a mapear uma tarefa próxima à sua comunicante que transfira o maior volume de dados.
Isto pode causar um espalhamento de tarefas nos nodos na rede, podendo muitas vezes ser escolhido um novo nodo ao invés de o mapeamento de uma tarefa num PE que contenha uma tarefa comunicante já mapeada, o que não ocorre nas heurísticas NN e BN.
Além disso, a heurística LEC-DN-MT não leva em conta a possível existência de uma tarefa que se comunique com um maior volume de dados com àquela solicitada do que as atuais tarefas já mapeadas, o que é otimizado por a heurística PREMAP-DN.
Entre as heurísticas avaliadas, a que apresenta um melhor desempenho em relação a todas as métricas de desempenho é a PREMAP-DN.
Esta heurística foi a que obteve um melhor compromisso entre os critérios avaliados, tendo destaque a redução de energia na comunicação que atinge até 55% em comparação com as demais heurísticas.
O tempo total de execução é baixo, obtendo um aumento médio de 4,9% em relação a a heurística BN, que obteve os melhores resultados.
Já em relação a o somatório da distância em hops, esta heurística apresenta um aumento de 12,5% e 2%, respectivamente, em relação a BN e LEC-DN-MT.
Porém consegue reduzir 3,8% em relação a a NN.
A heurística BN, que é a melhor em duas das métricas de desempenho avaliadas (i.
e tempo total de execução e somatório da distância em hops) é desconsiderada por dois motivos principais.
Primeiro, pois aumentou a energia consumida na comunicação média em aproximadamente 19,7%, comparado às outras heurísticas.
O segundo, e mais importante, é o fato da necessidade da heurística BN de utilizar uma infraestrutura de monitoramento para a obtenção dos resultados de mapeamento.
Esta infraestrutura de monitoramento, como dito anteriormente, acarreta em área adicional ao circuito integrado e um consumo maior de energia para seu funcionamento.
Além disso, para a obtenção de dados do monitoramento, pacotes provenientes de todos os PEs do sistema devem ser transferidos por a rede a cada intervalo de tempo definido por o projetista.
Estes pacotes não são levados em conta nos resultados apresentados, o que pode acarretar num consumo ainda maior de energia para a transferência destes pacotes.
Durante o desenvolvimento das heurísticas de mapeamento, verificou- se uma lacuna no MPSoC HeMPS.
Esta lacuna se refere à impossibilidade de inserir novas aplicações em tempo de execução neste MPSoC.
Todas as aplicações a serem executadas neste MPSoC eram definidas em tempo de projeto.
Para isto, a ferramenta HeMPS Generator era utilizada, compilando códigos-objeto de tarefas e, depois, gerando o repositório de tarefas.
Este repositório possuía um tamanho fixo igual à soma do tamanho do cabeçalho de cada uma das tarefas e de seus respectivos códigos-objeto, impossibilitando a inserção de novas aplicações no sistema.
A inserção de novas aplicações no sistema é uma das grandes vantagens da utilização de uma abordagem de mapeamento dinâmico em relação a uma abordagem estática.
O mapeamento dinâmico consegue lidar com a chegada de uma nova tarefa em tempo de execução, determinando um melhor PE para alocar- la.
Porém, um ponto crucial no mapeamento de uma aplicação é o mapeamento de suas tarefas iniciais.
É a partir de a alocação das tarefas iniciais que as demais tarefas da aplicação serão mapeadas no sistema, assim, pode- se dizer que este mapeamento influência diretamente no desempenho do mapeamento global da aplicação.
Este Capítulo apresenta outra contribuição deste trabalho que é a inserção de novas aplicações em tempo de execução, ou seja, inserção de carga dinâmica no sistema.
Isto é realizado durante a simulação do sistema utilizado neste trabalho, possibilitando uma melhor avaliação das heurísticas de mapeamento propostas.
Três pontos devem ser considerados para a simulação de inserção de carga dinâmica no sistema:
Geração de novos repositórios de tarefas -- Seção 6.1;
a criação de um serviço de mapeamento de novas aplicações -- Seção 6.2;
uma heurística de mapeamento das tarefas iniciais, discutida na Seção 6.3.
Por fim, na Seção 6.4, são apresentados experimentos mostrando as influências da inserção dinâmica de carga no mapeamento das tarefas.
Geração de Repositórios de Tarefas Como explicado anteriormente, o repositório de tarefas presente no MPSoC HeMPS não propiciava a inserção de novas aplicações no sistema durante o tempo de execução.
O formato do repositório é praticamente o mesmo do anterior, porém com a inserção de um espaço para que sejam armazenadas novas tarefas (em azul), posicionado entre os cabeçalhos (em amarelo) e os dados das tarefas (em verde).
Para a inserção deste espaço, é definido em tempo de projeto, um tamanho máximo para o repositório.
Este tamanho é a restrição para a inserção de novas tarefas, visto que posições ocupadas por uma tarefa não podem ser reutilizadas.
O armazenamento dos códigos-objeto é feito dos endereços mais altos para os mais baixos, como numa estrutura de pilha.
Assim, quando uma nova tarefa é inserida no repositório, seu código-objeto é armazenado nos endereços anteriores a última tarefa inserida.
A inserção de uma nova aplicação no sistema, e por sua vez no repositório de tarefas apresentado anteriormente, requer a transmissão de repositórios parciais à plataforma HeMPS.
Os repositórios parciais contêm somente as tarefas da nova aplicação.
Este repositório possui o formato ilustrado na Figura 42.
O formato utilizado é praticamente igual ao do repositório de tarefas anterior, apenas com a exclusão no cabeçalho do campo indicativo ao mapeamento das tarefas.
A geração de um repositório parcial é realizada através de uma ferramenta, onde é definida para qual aplicação quer se gerar este repositório.
Esta ferramenta primeiramente compila os códigos C das tarefas da aplicação gerando seus códigos-objeto, que serão incluídos no repositório.
Depois, são gerados os identificadores de cada tarefa.
Estes identificadores iniciam sua contagem a partir de o número total de tarefas já contidas no repositório de tarefas, no momento quando se deseja inserir a nova aplicação.
Isto é realizado para se manter a sequencialidade destes identificadores.
Por fim, a ferramenta monta o cabeçalho de cada tarefa, contendo também o endereço inicial do seu códigoobjeto no repositório parcial.
Serviço de Mapeamento Dinâmico de Novas Aplicações A inserção de novas aplicações no sistema em tempo de execução requer primeiramente a inserção das tarefas da nova aplicação no repositório de tarefas.
Para isto, o ambiente de simulação transmite ao repositório de tarefas o repositório parcial, contendo as tarefas desta nova aplicação.
Esta inserção no repositório de tarefas é feita sem a interferência da HeMPS.
Não há conflitos de acesso ao repositório de tarefas, uma vez que a HeMPS utiliza este repositório como uma memória ROM (apenas leitura).
Esta inserção se dá num tempo definido, por enquanto manualmente, por o projetista no arquivo de test bench de simulação do sistema.
Uma vez realizada a inserção do repositório parcial no repositório de tarefas, um sinal é ativado no test bench indicando que repositório de tarefas foi alterado.
A partir deste sinal é iniciado o processo de mapeamento da nova aplicação no sistema.
Para isto, basta o mapeamento das tarefas iniciais desta nova aplicação, que também são definidas, por enquanto manualmente, no test bench.
Este mapeamento é realizado através de um novo serviço implementado no microkernel do Plasma-IP MP.
Para a implementação do novo serviço de mapeamento dinâmico de novas aplicações, foram incluídos dois novos registradores mapeados em memória:
REQ_ TASK e ACK_ TASK, indicando respectivamente a requisição e confirmação do mapeamento de uma nova tarefa (no caso uma tarefa inicial da nova aplicação).
O registrador REQ_ TASK utiliza o bit 31 para alertar que uma nova tarefa deve ser mapeada, enquanto os bits de 0 a 30 contêm o identificador desta tarefa.
Já o registrador ACK_ TASK seta todos os bits em, 1 quando mapeamento de uma tarefa é confirmado.
Assim, o test bench, ao ativar o sinal de alteração do repositório de tarefas, inicia um protocolo de mapeamento de cada uma das tarefas iniciais da nova aplicação.
Supondo a inserção de uma nova aplicação no sistema que tem duas tarefas iniciais de identificadores 8 e 9, o protocolo de mapeamento com a utilização dos dois novos registradores é apresentado a seguir:
REQ_ TASK e ACK_ TASK iniciam em zero;
Para a requisição do mapeamento da primeira tarefa inicial de identificador 8, REQ_ TASK tem seu valor alterado para &quot;0x8000008».
O microkernel do Plasma-IP MP quando verifica que o bit 31 do registrador REQ_ TASK está em &quot;1», lê os demais bits deste registrador para obter o identificador da tarefa a ser mapeada.
É verificado se há PEs disponíveis para mapear esta tarefa.
Caso houver, prossegue- se para o próximo passo.
Caso contrário, REQ_ TASK permanece com o seu valor, requisitando esta tarefa até que um PE se torne livre.
Quando isto acontecer, prossegue- se para o próximo passo.
É verificado se esta tarefa já foi mapeada.
Caso não tenha sido, uma heurística de mapeamento de tarefas iniciais será utilizada para a definição de um PE para mapear esta tarefa.
Esta heurística será explicada na Seção a seguir.
Definido o PE para mapear a tarefa, são utilizados serviços do microkernel já existentes, como TASK_ ALLOCATION para realizar o mapeamento.
Depois disto, prossegue- se para o próximo passo.
Caso esta tarefa já tenha sido mapeada, somente prossegue- se para o próximo passo.
O registrador ACK_ TASK tem o seu valor alterado para &quot;0 xFFFFFFFF», confirmando que a tarefa já está mapeada.
Através da confirmação de ACK_ TASK, a requisição de REQ_ TASK é finalizada e este registrador é zerado.
A o notar que REQ_ TASK está zerado, ACK_ TASK também é zerado.
Para o mapeamento da segunda tarefa inicial, de identificador 9, REQ_ TASK tem seu valor alterado para &quot;0x8000009 «e o protocolo dos passos 3 a 8 é novamente realizado.
Heurística de Mapeamento de Tarefas Iniciais O mapeamento de uma tarefa inicial, como enfatizado neste trabalho, influência diretamente no desempenho do mapeamento das demais tarefas de sua aplicação.
Uma heurística para realizar automaticamente o mapeamento destas tarefas em tempo de execução é uma lacuna no estado-da-arte de mapeamento de dinâmico de tarefas, não sendo abordada em nenhum dos trabalhos revisados.
Assim, este trabalho propõe uma heurística simples para este mapeamento.
A heurística proposta tem por objetivo principal encontrar uma área no sistema onde se tenha o maior número de PEs livres.
Para isto, a heurística avalia todos os PEs livres no sistema, contando quantos outros PEs livres estão em seu entorno dentro de uma distância de 2 hops.
Este valor de distância é parametrizável, podendo ser alterado dependendo do tamanho da rede utilizada.
Resultados Experimentais Em esta seção é feita uma avaliação de inserção dinâmica de carga no sistema.
Esta avaliação tem por objetivo apenas demonstrar que dependendo da inserção de uma nova aplicação no sistema, muda- se o desempenho obtido por o mapeamento.
Além disso, é mostrada a influência do mapeamento das tarefas iniciais no mapeamento global de sua aplicação.
A inserção de carga dinâmica no sistema, por enquanto, não possibilita a avaliação das heurísticas que consideram dependências múltiplas de tarefas.
Isto se deve ao fato das informações relativas às dependências de comunicação e o volume transferido, ainda não estarem armazenadas nos repositórios parciais de uma aplicação.
Isto será realizado em trabalhos futuros.
Assim, para a avaliação da inserção de carga dinâmica no sistema, será utilizada a heurística NN multitarefa.
Esta heurística será avaliada sobre o cenário C, utilizado anteriormente.
Este cenário possui 2 aplicações:
MPEG-4 e VOPD.
Em este cenário, que tem tempo médio de simulação de 22ms nos casos analisados, é inserida a aplicação MWD em 3 tempos diferentes da simulação:
500 us de simulação, 8ms e 16ms. A inserção desta nova aplicação no cenário C resulta ao final do mapeamento da aplicação MWD no cenário E (MPEG-4, VOPD e MWD).
Em o cenário E as tarefas iniciais das 3 aplicações são mapeadas em tempo de projeto, considerando a técnica de mapeamento de tarefas iniciais apresentada na Seção 4.1.
A Tabela 11 apresenta os resultados obtidos na avaliação da inserção da aplicação MWD no Cenário C nos 3 tempos de simulação previamente definidos, mais os resultados do cenário E. As métricas avaliadas são tempo total de execução em ciclos de relógio, somatório da distância em hops entre tarefas comunicantes e energia consumida na comunicação (em nJ).
Lembrando que esta avaliação foi realizada utilizando o MPSoC HeMPS com dimensão 3x5.
Através dos resultados apresentados na Tabela 11 nota- se a diferença no desempenho do sistema, dependendo do momento em que a nova aplicação é inserida no sistema.
A diferença no tempo total de execução não é expressiva, sendo que a maior variação ocorre nos casos onde a inserção da aplicação é feita aos 8 e 16ms. O caso onde a inserção é realizada aos 16ms apresenta aproximadamente 4% de aumento no tempo de execução em relação a o cenário onde esta inserção é realizada aos 8ms. Quando a inserção é feita aos 16ms, a redução em número de hops é de 19,4%, 35,9% e 10,7% em comparação à inserção em tempo de projeto, em 500 us e em 8ms, respectivamente.
Para melhor explicar o motivo desta redução, considere a Figura 43, que mostra a disposição das tarefas de cada cenário apresentado, no momento de inserção da tarefa inicial In da aplicação MWD.
Observa- se por a figura que quando a inserção é realizada aos 16ms, há um menor número de tarefas mapeadas no entorno de onde a tarefa In foi mapeada (a aplicação VOPD inclusive já terminou sua execução).
Isto possibilita maiores alternativas de mapeamento, facilitando a aproximação de tarefas comunicantes da aplicação.
Isto também serve de explicação para o fato do cenário de mapeamento da aplicação em tempo de projeto apresentar um aumento do número de hops de 24% em comparação ao cenário onde a inserção da aplicação é feita aos 16ms. Outra explicação para isto é que no cenário em que o mapeamento é feito em tempo de projeto, todas as aplicações do sistema estão concorrendo para mapear suas tarefas ao mesmo tempo, o que não ocorre aos 16ms. Observar a inserção da aplicação MWD no tempo 8ms. Em este momento todas as tarefas das aplicações MPEG-4 e VOPD já estão mapeadas e em execução.
Assim, o mapeamento da aplicação MWD não disputa o mapeamento com outras tarefas, gerando melhores resultados em todos os parâmetros avaliados.
A energia consumida na comunicação é outra métrica que apresenta grande variação entre os cenários de teste.
Em a avaliação deste critério, a inserção da aplicação aos 16ms apresenta o menor consumo de energia, que pode ser explicado por os mesmos motivos de sua redução no número de hops.
A inserção da aplicação aos 16ms proporcionou uma redução na energia consumida na comunicação de 20,4%, 44,6% e 1,2% em relação a a inserção em tempo de projeto, em 500 us e em 8ms. Agora, para a avaliação da heurística de mapeamento de tarefas iniciais, é feita a comparação do cenário onde a inserção é realizada aos 500 us, que utiliza esta heurística, com o cenário onde o mapeamento da aplicação é realizado em tempo de projeto, utilizando o mapeamento apresentado na Seção 4.1 baseado na distribuição das tarefas iniciais em regiões do MPSoC.
Uma comparação entre estes dois cenários foi escolhida, pois ambos apresentam condições de mapeamento semelhantes, onde todas as aplicações são inseridas no início da execução do sistema e concorrem para escolha de um PE para mapear suas tarefas.
O somatório do número de hops e a energia refletem na principal diferença entre estes dois cenários.
O mapeamento em tempo de projeto obteve uma redução de 20,5%, no número de hops, e 30,4% na energia consumida na comunicação, em relação a a inserção aos 500 us.
Isto mostra a efetividade do mapeamento de tarefas iniciais baseado na distribuição das tarefas iniciais em regiões do MPSoC, comparado com a heurística de mapeamento de tarefas inicias proposta.
Este resultado negativo em 500 us deve- se ao fato que as demais aplicações ainda estavam sendo mapeadas, havendo disputa por PEs.
Entretanto, uma vez que o sistema já se encontra com suas aplicações mapeadas ou terminando a execução de determinadas aplicações, a heurística de mapeamento de tarefas iniciais proposta é efetiva, resultando no mapeamento da nova aplicação numa área contígua.
Vale ressaltar que não há outra heurística com esta função apresentada na literatura.
Apenas o trabalho de Wildermann et al.
Apresenta uma abordagem de inserção de carga dinâmica.
Porém, esta abordagem utiliza a criação ou exclusão de tarefas de uma aplicação já existente no sistema para geração de uma carga dinâmica, não havendo Um problema relativo à inserção de carga dinâmica no sistema é a fragmentação apresentada no mapeamento, onde tarefas de aplicações diferentes se misturam.
Para mostrar este comportamento, foi realizado um teste através da inserção da aplicação VOPD no cenário D, apresentado no Capítulo anterior, aos 500 us de execução.
Um MPSoC de dimensão 3x5 foi utilizado, realizando- se o mapeamento através da heurística NN multitarefa.
A distribuição final das tarefas no sistema pode ser visto através da Figura e que as aplicações não estão mapeadas em bloco.
Isto prejudica no desempenho do mapeamento, afastando pares de tarefas comunicantes, podendo aumentar o tráfego no sistema, e consequentemente, a energia consumida na comunicação.
Circuito; Em vermelho, a VOPD;
Em amarelo, a Aplicação Veicular;
Em verde, a MPEG-4;
e em preto, o processador mestre do sistema.
Para resolver este problema, uma das possibilidades é a utilização da técnica de migração de tarefas.
Como explicado anteriormente, esta técnica propicia a migração de uma tarefa de um PE para outro em tempo de execução, visando à otimização no sistema.
No caso de a fragmentação, a migração se faria útil para aproximar tarefas comunicantes, migrando uma tarefa que se comunica com outra de um PE distante para um mais próximo.
Uma avaliação sobre a técnica de migração de tarefas será feita em trabalhos futuros, procurando também definir quando e se ela é realmente necessária.
A presente Dissertação abordou o tema de mapeamento dinâmico de tarefas para MPSoCs homogêneos.
O presente trabalho propôs uma taxonomia para o mapeamento de tarefas, avaliando as lacunas presentes no estado-da-arte.
Identificou- se que a minimização da energia consumida na comunicação e o mapeamento multitarefa eram temas inovadores, desenvolvendo- se assim contribuições nestas áreas.
Desta forma, as contribuições desta Dissertação podem ser resumidas nos seguintes temas:
Geração Automática de Códigos de Aplicações para o MPSoC HeMPS.
Para a avaliação das heurísticas de mapeamento propostas neste trabalho, observou- se a necessidade do uso de aplicações a serem executadas no MPSoC HeMPS para a obtenção de resultados experimentais.
Este MPSoC possuía poucas aplicações implementadas, que possuíam uma baixa complexidade e comportamentos de comunicação similares.
De essa forma, uma geração de códigos automáticos de aplicações foi desenvolvida neste trabalho.
A geração destes códigos é realizada através do modelo de aplicações proposto por, onde estas aplicações são modeladas em diagramas de sequência no ambiente de simulação Ptlolemy II.
Assim, foram gerados códigos para um conjunto de 7 aplicações reais ou sintéticas com diferentes comportamentos de iteração entre suas tarefas.
Implementação de Heurísticas de Mapeamento de Referência no MPSoC HeMPS:
As heurísticas de mapeamento NN e BN, propostas por Carvalho, foram inseridas no microkernel do Plasma-IP MP do MPSoC HeMPS.
A seguir, a extensão das heurísticas NN e BN para multitarefa, propostas por Singh, foram inseridas.
Estas heurísticas foram utilizadas como referência para a avaliação das heurísticas de mapeamento monotarefa e multitarefa propostas neste trabalho.
Além disso, a inserção destas novas heurísticas permitiu a avaliação das mesmas num MPSoC real, com NoC descrita em VHDL RTL e processadores descritos em SystemC com precisão de ciclos de relógio.
Integração e Avaliação do Monitoramento do Sistema para utilização no Mapeamento de Tarefas:
Para a implementação da heurística BN, tanto nas versões mono e multitarefa se fez necessária a utilização de uma infraestrutura de monitoramento.
Esta infraestrutura propiciou a coleta de informações relativas à carga nos canais da rede, utilizada nesta heurística.
Isto permitiu uma melhor avaliação de utilização desta infraestrutura.
Implementação de Novas Heurísticas de Mapeamento Dinâmico Monotarefa:
Duas novas heurísticas de mapeamento monotarefa foram propostas neste trabalho:
DN e LEC-DN.
Estas heurísticas têm como principal objetivo, a redução de energia consumida na comunicação entre tarefas.
Para isto, estas heurísticas consideram no momento do mapeamento todas as dependências de comunicação da tarefa a ser mapeada, além de o volume de dados transferido.
Com isto, as heurísticas NN e BN foram otimizadas, obtendo- se uma redução de energia consumida na comunicação Esta redução, obtida por a heurística proposta LEC-DN, é de aproximadamente 9,8% e 9,6% em relação a a NN e BN, respectivamente.
Implementação de Novas Heurísticas de Mapeamento Dinâmico Multitarefa:
A proposição de novas heurísticas de mapeamento dinâmico multitarefa buscou avançar o estado- da arte nesta abordagem de mapeamento, visto que apenas um Autor nova abordagem para a realização do agrupamento (em inglês, clustering) de tarefas a serem mapeadas num único PE.
Esta nova abordagem, comparada a trabalhos anteriores na literatura, proporciona uma visão mais ampla do comportamento da aplicação, através da extração de informações de dependência de comunicação entre tarefas e seu volume transferido.
Isto mostrou trazer benefícios quanto a o desempenho do mapeamento, principalmente em relação a a redução de energia consumida na comunicação.
A heurística PREMAP-DN obteve uma redução de energia consumida na comunicação de 18,6% e 14,3%, quando comparado às heurísticas NN e BN multitarefa, respectivamente.
Avaliação de Heurísticas de Mapeamento: Uma avaliação das heurísticas de mapeamento foi realizada neste trabalho comportando três métricas de desempenho:
Tempo total de execução, somatório da distância em hops entre tarefas comunicantes e energia consumida na comunicação.
O mapeamento dinâmico resulta num baixo custo de tempo de execução e energia quando comparado ao mapeamento estático, além de permitir a inserção de carga no sistema em tempo de execução.
Mostrou- se também que a utilização de um mapeamento dinâmico multitarefa frente a um monotarefa possibilita uma redução no consumo de energia com a utilização de MPSoCs de menor dimensão e com menor tráfego de comunicação por a NoC.
Resultados mostram uma redução de energia consumida na comunicação média de 56% entre os cenários de teste avaliados para uma abordagem multitarefa em relação a uma monotarefa.
Inserção Dinâmica de Carga no MPSoC HeMPS:
A inserção dinâmica de carga no MPSoC HeMPS proporciona avaliar uma das principais vantagens da abordagem de mapeamento dinâmico frente a o estático.
Para isto, foi necessária a alteração do formato do repositório de tarefas do sistema e a criação de repositórios parciais, contendo as tarefas da nova aplicação a ser inserida.
Além disso, foi necessária a criação de um serviço de mapeamento das tarefas iniciais das aplicações a serem inseridas, o que tornou necessária a implementação de uma heurística de mapeamento destas tarefas iniciais.
Esta heurística é uma contribuição inovadora neste trabalho.
As contribuições apresentadas neste trabalho foram enviadas para conferências pelo meio de dois aprovados.
Iscas, 2011, Rio de Diversos trabalhos futuros podem dar continuidade a presente Dissertação.
Estes trabalhos futuros incluem:
Implementação de um MPSoC com controle distribuído.
Este MPSoC seria dividido em regiões, que possuem um agente controlador que é responsável por o mapeamento no interior daquela região.
A partir de esta implementação, desenvolver novas heurísticas para esta arquitetura e avaliar- las.
Além disso, proporcionar a avaliação de quando é necessária a utilização de um sistema de controle distribuído frente a um sistema de controle centralizado.
Otimização da infraestrutura de monitoramento proposta por, visando a redução no tráfego de pacotes de monitoramento no sistema.
Para isto, pode- se utilizar uma infraestrutura de monitoramento distribuído.
Integração das heurísticas de mapeamento propostas neste trabalho no ambiente de simulação baseado em modelos proposto por.
Esta integração proporcionará a avaliação das heurísticas em MPSoCs maiores, devido a menores tempos de execução, e com a possibilidade de avaliação de outras métricas de Consideração do tempo de processamento utilizado por cada tarefa de uma aplicação nas heurísticas de mapeamento.
Isto tornará possível uma melhor distribuição de carga entre os PEs do sistema, evitando sobrecargas de processamento.
Proposição de técnicas de migração de tarefas visando uma otimização de visem uma melhor distribuição de carga entre os processadores do sistema e uma maior aproximação entre pares de tarefas comunicantes de uma aplicação.
Com isto, também busca- se reduzir a fragmentação de tarefas no sistema.
Otimização do método de inserção de carga dinâmica no MPSoC HeMPS, inserindo informações relativas ao comportamento de uma aplicação no repositório de tarefas do sistema.
Entre estas informações citam- se as dependências de comunicação entre tarefas, assim como, o volume de dados transferidos.
Estas informações são utilizadas por, entre outras, as heurísticas LEC-DN e PREMAP-DN, propostas neste trabalho.
De essa forma, será possível a avaliação de todas as heurísticas apresentadas neste trabalho em relação a a inserção de novas aplicações no sistema em tempo de execução.
