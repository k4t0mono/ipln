A comunicação entre dispositivos localizados em lugares geograficamente distantes é de grande importância e, nesse cenário, as plataformas orbitais exercem um papel fundamental.
Interligar sistemas de transmissão de imagens, sistemas de telefonia, internet, monitoramento dos ambientes terrestres, são alguns dos exemplos dos benefícios que são obtidos nas aplicações das plataformas orbitais.
A Unidade de Telecomando e Telemetria (UTMC), presente nas plataformas orbitais, é utilizada tanto no controle quanto na aquisição de dados de seus instrumentos.
O módulo da UTMC representa uma peça fundamental para que os satélites em órbita comportem- se da maneira esperada.
Operar corretamente num ambiente hostil, como o espaço, é um desafio que requer a aplicação de técnicas de tolerância a falhas que garantam o correto funcionamento do satélite durante todo o período da missão em a qual está inserido.
A implementação dessas técnicas demanda a aplicação de diversos métodos de desenvolvimento para FPGAs, bem como a correta validação do seu funcionamento em condições adversas.
Assim, este trabalho tem como objetivos:
analisar os aspectos de confiabilidade existentes no projeto do protótipo da UTMC;
determinar as melhores técnicas de tolerância a falhas a ser aplicadas ao projeto; (
iii) e determinar quais são os aspectos mais importantes na implementação dessas técnicas em FPGA.
Palavras Chave: Satélites, Confiabilidade, Tolerância a Falhas, FPGA, VHDL, IP Core.
Cada vez mais a comunicação vem sendo considerada um elemento essencial na sociedade moderna e plataformas orbitais são fundamentais para interligar sistemas distribuídos geograficamente.
Além disso, a rotina diária das pessoas depende dos recursos disponibilizados por esses equipamentos, uma vez que sistemas como os de telefonia e de transmissão de imagem para televisão necessitam das plataformas orbitais.
De essa forma, o correto funcionamento desses equipamentos é essencial uma vez que esses sistemas são largamente utilizados em todo o mundo.
Dentro desse contexto, é necessário salientar a importância de métodos capazes de aumentar o grau de confiabilidade das plataformas orbitais, garantindo que possam operar corretamente por o período mínimo estipulado por uma determinada missão e sem atividade de manutenção.
Em um ambiente tão hostil como o espaço, isso só é possível caso o projeto do sistema desenvolvido reduza o efeito das falhas através da aplicação de uma proteção ou escudo anti-radiação, ou seja, através da utilização de componentes resistentes à radiação.
Além disso, o projeto do sistema deve contemplar partes do circuito com grande grau de confiabilidade através da aplicação de técnicas de tolerância a falhas, permitindo que o sistema opere continuamente mesmo na existência de falhas.
A pesquisa proposta e desenvolvida neste trabalho ocorre dentro de o projeto da UTMC (Unidade de Telemetria e Telecomando) desenvolvido na PUCRS.
O projeto da UTMC consiste, basicamente, na pesquisa e desenvolvimento dos módulos para uso em computadores de bordo (On Board Computer, OBC) de plataformas orbitais.
Baseado em dispositivos de hardware do tipo FPGA (Field Programmable Gate Array), a UTMC é responsável por executar as funções do fluxo de recebimento de Tc (Telecomando) e de envio de Tm (Telemetria) para a base terrestre, seguindo as recomendações do CCSDS (Consultative Committee for Space Data Systems).
O CCSDS é uma organização oficialmente estabelecida por as principais agências espaciais mundiais ligadas aos seguintes países:
EUA, Canadá, Alemanha, Japão, Unido, França, Europa, Rússia, Itália e Brasil.
Esse comitê reúne- se periodicamente para discutir problemas comuns, ocorridos em sistemas de comunicação, e formular soluções técnicas seguras para esses problemas.
A principal atividade dos membros do CCSDS consiste na escrita e manutenção da documentação relativa às recomendações.
Uma vez que a participação no CCSDS é completamente voluntária, os resultados das ações tomadas por o comitê são designadas recomendações e não são consideradas obrigatórias em qualquer agência espacial.
Independentemente do tipo de aplicação, satélites são formados, basicamente, por dois sistemas distintos:
A plataforma orbital e a carga útil (payload).
A plataforma orbital é responsável por executar funções tais como:
Alimentação, controle de temperatura, controle de atitude1, controle de órbita, leitura de Tm e execução de Tc.
Por outro lado, a carga útil é a razão de ser do satélite, carregando sistemas dependentes de cada missão, tais como:
Sistemas de telecomunicação, experimentos científicos, sistemas de monitoração ambiental, telescópios, entre outros.
As diferentes tarefas designadas para cada um dos sistemas refletem na escolha do tipo de componente que será utilizado na sua composição.
Em a plataforma orbital, por exemplo, confiabilidade é um requisito obrigatório, uma vez que o não funcionamento do módulo da UTMC resulta no fim da missão, devido a a perda de contato ou à impossibilidade de reposicionar o veículo espacial.
Já na carga útil, esse tipo de situação não compromete a missão como um todo, visto que a carga útil é composta por diversos equipamentos e transmissores e uma única falha num desses dispositivos não impede seu funcionamento.
De essa forma, requisitos referentes à confiabilidade devem ser balanceados com os demais requerimentos do projeto, tais como:
Peso mínimo, ocupação de espaço e consumo de energia, sendo combinados com o grau máximo de confiabilidade total do sistema e oferecendo imunidade aos efeitos da radiação existentes no espaço.
Em o projeto de plataformas orbitais, proteger os circuitos eletrônicos contra os efeitos da radiação é imperativo, a fim de evitar uma alteração lógica temporária no Ci (Circuito Integrado).
Entre esses efeitos de radiação, destacam- se os SEE (Single Event Effects), que ocorrem quando uma partícula carregada (tipicamente um próton, nêutron ou íon carregado) colide com os átomos do silício, transferindo energia elétrica para o componente eletrônico, afetando principalmente as memórias do tipo RAM e FPGAs SRAM, ocasionando diferentes tipos de falhas, brevemente descritas a seguir:
Seu (Single Event Upset) é uma mudança transiente do estado de um único bit no Ci e pode ser corrigida com a atualização do bit alterado;
A atitude de um satélite é a sua orientação no espaço.
O controle de atitude é responsável por estabilizar o satélite e orientar- lo para direções desejadas durante a missão, apesar de existirem pertubações externas atuando no sistema.
SHE (Single Hard Error) é um Seu que gerou uma falha permanente no Ci como, por exemplo, 1 bit de memória que mantém o mesmo valor binário em 1, mesmo quando o seu valor deveria ser 0;
SEL (Single Event Latchup) é a condição que causa uma alteração no funcionamento do Ci através da passagem de alta corrente, ou seja, um curto circuito.
O SEL tem grande possibilidade de gerar uma falha permanente no Ci, sendo necessário reduzir ou desligar sua alimentação a fim de evitar danos permanentes.
Adicionalmente, sistemas espaciais incluem uma grande variedade de componentes digitais e analógicos que são potencialmente sensíveis à radiação e que devem ser protegidos ou, pelo menos, qualificados para operar no espaço.
Além disso, fatores como:
Variações na temperatura ou na tensão de alimentação, interferências eletromagnéticas ­ EMI (Eletromagnetic Interferences) e, em especial, a radiação solar e cósmica, podem afetar o comportamento normal de um circuito, gerando uma falha.
Em esse contexto, o avanço da tecnologia tem provocado um aumento significativo da sensibilidade dos CIs a esses fatores.
Devido a o contínuo avanço tecnológico no processo de fabricação dos componentes semicondutores, que permite a produção de CIs mais densos, com transistores menores e de baixíssimo consumo, possibilita que pequenas quantidades de radiação alterem os valores lógicos desses CIs, aumentando a incidência de falhas.
De esse modo, a utilização desse tipo de tecnologia no ambiente espacial aumenta a probabilidade da ocorrência de SEEs e, com o objetivo de combater esses efeitos, diversas técnicas de tolerância a falhas devem ser aplicadas ao projeto da Além disso, segundo Normand, fatores como a grande redução tanto do tamanho dos dispositivos quanto na sua fonte de alimentação e o aumento na velocidade de operação, reduzem significativamente a margem de tolerância a ruídos que os CIs suportam, chegando a um nível em o qual será impossível construir CIs livres desses efeitos.&amp;&amp;&amp;
Consequentemente, tolerância a falhas não é uma questão exclusiva dos projetos de dispositivos espaciais e aparece, também, como uma preocupação nos produtos das próximas gerações tecnológicas, que devem lidar com erros mesmo em ambiente terrestre, devido a as consequências negativas que o avanço da tecnologia deve trazer.
Motivação Apesar do Brasil fazer parte do CCSDS, por intermédio da AEB (Agência Espacial Brasileira), os projetos desenvolvidos por o INPE (Instituto Nacional de Pesquisas Espaciais) ainda não utilizam o padrão CCSDS, o que dificulta a interoperabilidade com missões espaciais de outras agências.
Além disso, o principal problema na não adoção do CCSDS por parte de as missões brasileiras é justamente a dificuldade para se reaproveitar os módulos de comunicação de satélites em diferentes missões espaciais.
A partir de a implantação do padrão CCSDS nas missões da AEB realizadas por o INPE, será possível reaproveitar módulos em diversas missões e, também, implementar mecanismos para troca de informações com estações de outras agências que adotam o mesmo padrão.
Ainda, enquanto que os FPGAs eram utilizados, em sua grande maioria, nas aplicações de prototipação, emulação de sistemas lógicos, e em situações com um volume de demanda extremamente baixo, atualmente, esses equipamentos são empregados em aplicações com um alto volume de demanda.
Além disso, os FPGAs também são utilizados em aplicações espaciais como, por exemplo, nas missões da NASA (&quot;National Aeronautics and Space Administration) Mars Pathfinder , lançada em 1996 «e &quot;Phoenix te o Mars , lançada em 2008», que utilizaram FPGAs Actel para alguns de seus serviços.
Diferente de aplicações ordinárias, essas aplicações críticas de missão espacial costumam ser extremamente exigentes quanto a a confiabilidade dos sistemas utilizados.
Assim, existe um grande interesse em melhorar o grau de confiabilidade desses sistemas utilizando recursos de tolerância a falhas.
FPGAs são extremamente populares em soluções de projeto devido a sua grande flexibilidade e capacidade de reconfiguração, que reduz o tempo de desenvolvimento como um todo.
Assim sendo, tornam- se, também, atrativas para soluções espaciais, pois agregam diversos benefícios para o projeto em termos de alta densidade lógica, alto desempenho, baixo tempo de verificação e reprojeto, baixo custo das ferramentas de desenvolvimento e rápida adaptação às alterações do projeto durante o período de desenvolvimento.
Infelizmente, a tecnologia atual faz com que os FPGAs sejam menos confiáveis, visto que seus fabricantes estão seguindo o mesmo caminho da indústria de semicondutores, utilizando dispositivos cada vez menores e mais densos.
A utilização de tecnologias de 50 nm para 35 nm e menores, resulta em sistemas mais sensíveis a efeitos eletromagnéticos.
Com a redução do tamanho dos transistores, a quantidade de energia necessária para alterar o seu estado é cada vez menor, fazendo com que os componentes sejam mais suscetíveis às partículas de radiação existentes no espaço.
Ao mesmo tempo, os fabricantes de FPGAs estão produzindo chips cada vez maiores, aumentando a quantidade de portas lógicas existentes no circuito.
Chips maiores possuem uma grande superfície para ser atingida por partículas gamma, aumentando a oportunidade de falhas geradas por radiação.
Assim, uma das principais motivações do presente projeto reside na importância de a aplicação das recomendações CCSDS em projetos desenvolvidos por o INPE, aliado aos potenciais benefícios que a utilização de FPGA para aplicações espaciais podem trazer ao projeto.
Considerando que essa ainda não é a realidade no Brasil, é dentro desse contexto que o presente trabalho está integrado.
Objetivos do Trabalho O objetivo principal deste trabalho consiste em analisar os aspectos de confiabilidade existentes no projeto do protótipo da UTMC e determinar quais as melhores técnicas de tolerância a falhas que podem ser aplicadas ao projeto.
Além disso, deseja- se fazer uma análise dos recursos de confiabilidade existentes no desenvolvimento do projeto.
Ainda, pretende-se determinar qual a melhor técnica de tolerância a falhas a ser empregada nos dispositivos FPGAs antifuse utilizados no projeto, considerando entre as possibilidades:
Redundância de informação, redundância de hardware, redundância temporal, entre outras.
Os objetivos específicos estão em diversas áreas de conhecimento e consistem em:
Aprender conceitos relacionados ao desenvolvimento de sistemas embarcados para aplicações espaciais;
Descrever as adversidades na implementação dos recursos presente no protótipo da UTMC;
Determinar os pontos de falhas de desenvolvimento do projeto.
Organização do Texto O presente trabalho está organizado como segue.
O próximo capítulo apresenta os conceitos de confiabilidade e tolerância a falhas necessários para a compreensão das técnicas implementadas durante o desenvolvimento do trabalho.
Em o Capitulo 3 é feito um estudo do estado da arte acerca de técnicas de tolerância a falhas para dispositivos do tipo FPGA, utilizados em aplicações espaciais.
O Capitulo 4 apresenta uma análise do módulo da UTMC, com suas características e funcionalidades, seguido do Capitulo 5 que contém a descrição completa da técnica de TMR para a UTMC.
Em o Capitulo 6 é apresentada a descrição da técnica de dupla redundância, utilizada como alternativa à técnica de TMR.
Já o Capitulo 7 apresenta os resultados e avaliações das técnicas desenvolvidas, levando em consideração parâmetros como índice de confiabilidade, consumo de área além de descrever as limitações enfrentadas ao longo de a implementação.
Finalmente, o Capitulo 8 encerra este trabalho com as conclusões e direções para trabalhos futuros.
Este Capítulo aborda os conceitos e técnicas aplicadas ao desenvolvimento e análise de sistemas tolerantes a falhas.
Um sistema é considerado tolerante a falhas se o comportamento do sistema, na ocorrência de falhas de um de seus componentes, estiver consistente conforme as especificações.
Assim, itens como conceituação, diferenciação entre falha, erro e defeito bem como requisitos de técnicas tolerantes a falhas são apresentados ao longo deste capítulo.
Ainda, uma fundamentação teórica acerca de confiabilidade envolvendo projetos espaciais é abordada e sua importância para o presente trabalho, discutida.
De acordo com Laprie, a tolerância a falhas constitui- se de um conjunto de técnicas que tem por objetivo o fornecimento de um serviço que atenda às definições do sistema sem a ocorrência de falhas.
As falhas podem ter sua origem tanto em software como em hardware, sendo prejudiciais em ambos os casos.
Assim, existem técnicas de tolerância a falhas que podem ser implementadas em ambos os níveis.
Embora existam várias definições sobre confiabilidade, neste trabalho será considerada a seguinte:
&quot;confiabilidade é a probabilidade de que um item desempenhe a sua função pretendida sem falhar, sob determinadas condições especificadas e por um determinado período de tempo especificado».
Portanto, confiabilidade não é apenas a probabilidade de um item não falhar, mas também o estudo de todos os fatores que contribuem para a ocorrência da falha.
É importante frisar que esse conceito de tolerância a falhas pode ser aplicado tanto em sistemas de uso específico em plataformas orbitais quanto em sistemas de propósito geral.
Com relação a sistemas que exigem alta confiabilidade ou alta disponibilidade, apenas a prevenção e a remoção de falhas não são suficientes, o que gera a necessidade da aplicação de técnicas de tolerância a falhas na construção do sistema.
Essas técnicas garantem o funcionamento correto do sistema mesmo na ocorrência de falhas e são baseadas em redundância, exigindo componentes adicionais ou algoritmos especiais.
Além disso, a utilização de técnicas de tolerância a falhas não dispensa outras técnicas como as de prevenção e remoção de falhas.
Ainda, destaca- se que sistemas construídos com componentes frágeis e técnicas inadequadas de projeto não podem ser considerados confiáveis somente em função de a aplicação de tolerância a falhas, ou seja, a utilização de componentes com alto grau de confiabilidade além de técnicas adequadas ao projeto é fundamental.
Em os últimos cinquenta anos muitas técnicas foram desenvolvidas para se atingir os diversos requisitos de um sistema confiável.
Tais técnicas podem ser agrupadas, basicamente, em:·
prevenção de falhas (fault prevention), que impede a ocorrência ou a introdução de falhas.
Em esse contexto, estão envolvidas a seleção de metodologias de projeto e de tecnologias adequadas para os seus componentes;·
tolerância a falhas (fault tolerance), que provê o serviço esperado mesmo na presença de falhas no sistema.
A tolerância a falhas é baseada em diversas técnicas referentes às falhas, tais como:
Seu mascaramento, sua detecção, sua localização, seu confinamento, sua recuperação e seu tratamento;·
remoção de falhas (fault removal), que verifica a presença de falhas no sistema, tanto na etapa de desenvolvimento ou durante a execução do mesmo, e;·
previsão de falhas (fault forecasting), que traz estimativas sobre a presença de falhas além de tentar prever futuras ocorrências de falhas apontando ainda possíveis consequências das falhas apresentadas.
Basicamente, a prevenção de falhas e a tolerância a falhas objetivam fornecer um serviço confiável, enquanto que a remoção de falhas e a previsão de falhas objetivam alcançar a qualidade do sistema permitindo que se confie, justificadamente, que os serviços oferecidos serão executados corretamente.
Por definição, um sistema tolerante a falhas deve funcionar corretamente mesmo na ocorrência de erros em alguns de seus componentes e, para isso, são necessários que elementos redundantes façam parte do sistema.
Apesar disso, apenas a utilização de redundância por si só não é suficiente.
Em geral, a causa dominante de falha em sistemas com alta confiabilidade não está relacionada com a falta de recursos, mas sim com falhas na detecção e contenção dos erros em elementos que apresentam mau funcionamento, até mesmo antes da falha causar um mau funcionamento no sistema como um todo.
Ao longo de o desenvolvimento do sistema é importante que seja feita a definição de quais são os módulos que podem apresentar falhas.
Após essa etapa, deve- se compreender as causas dessas falhas, para que se possa, então, prevenir- las e evitar- las.
Além disso, é importante que se estude e que se analise tanto o meio interno quanto o externo onde os módulos estarão funcionando, diminuindo, assim, o impacto das falhas originadas por os elementos que não pertencem ao sistema.
A o se trabalhar num ambiente como o espacial, onde as condições de funcionamento são extremas, deve- se considerar, ainda, as alterações que as funcionalidades dos CIs podem sofrer devido a os efeitos da radiação, sendo necessária a atribuição de confiabilidade às aplicações de ordem críticas do sistema frente a esses efeitos.
O processo para desenvolver um circuito tolerante a falha implica na localização das áreas mais sensíveis do sistema e inserir em elas estruturas que sejam tolerantes a falhas.
Em o que tange às técnicas de tolerância a falhas, pode- se dizer que existem aquelas que consistem em soluções tecnológicas ou em técnicas baseadas em projeto.
As soluções tecnológicas são as que prevêem modificações do processo de fabricação, com o objetivo de que o circuito fabricado seja menos sensível aos efeitos provocados por a radiação, diminuindo a taxa de falhas ou até mesmo eliminando por completo alguns desses efeitos.
Existem tecnologias robustas frente a a radiação que são utilizadas em partes críticas de aplicações espaciais.
Essas tecnologias, denominadas de radiation-hard ou rad-hard, garantem a tolerância a falhas por doses de radiação e têm uma sensibilidade menor às falhas SEL, que podem causar falhas permanentes no circuito ou até sua destruição total.
Por outro lado, existe uma grande variedade de técnicas que se aplicam no nível sistêmico ou de transferência de registros e consistem em inserir redundância na informação armazenada, tanto no nível de hardware, de software, de tempo ou de informação.
Essas técnicas podem ser aplicadas por o projetista nas primeiras etapas do ciclo de desenvolvimento do projeto, sendo consideradas soluções de baixo custo e estão detalhadas nas próximas seções.
Falha -- Erro -- Defeito Em a literatura, vários são os autores que têm detalhado tanto a nomenclatura quanto os conceitos básicos da área de tolerância a falhas.
Os conceitos apresentados são os empregados por grande parte da comunidade nacional e foram derivados dos trabalhos de Laprie e Anderson e Lee.
Em sistemas computacionais, tipicamente, o atendimento correto de sua especificação é o que determina seu sucesso.
Em esse contexto, três conceitos são fundamentais:
Em geral, a definição de falha é intuitivamente associada a componentes físicos.
No entanto, essa é uma noção restritiva.
A seguir, são listados dois exemplos práticos de falha-erro- defeito que ocorrem tipicamente:
O engano de um programador é uma falha;
A conseqüência é um erro latente no software escrito.
A ativação do erro é causada por a utilização do módulo defeituoso e é nesse momento que o erro torna- se efetivo.
Quando isso ocorre e dados errados são fornecidos por o sistema, acontece um defeito, e, Ima interação inadequada homem-máquina, realizada de forma intencional ou não, por um operador durante a operação do sistema é uma falha;
Os dados alterados resultantes constituem- se um erro.
Em esse contexto, é importante destacar que falhas são inevitáveis.
Componentes físicos envelhecem e sofrem com interferências externas, seja ambientais ou humanas.
Os projetos de software e hardware são vítimas de sua alta complexidade e da fragilidade humana em trabalhar com grande volume de detalhes ou com deficiências de especificação.
Adicionalmente, pode- se classificar as falhas em dois tipos principais:·
naturais, que podem ser permanentes ou temporárias.
Normalmente, ocorrem por desgaste natural dos equipamentos e sua incidência pode ser minimizada, porém, dificilmente eliminada, e;·
humanas, que podem ser do tipo de projeto ou de iteração.
As de projeto podem ocorrer em qualquer etapa durante sua criação ou manutenção.
Já as falhas de interação podem ser intencionais ou não intencionais e constituem- se em violações dos procedimentos de operação do sistema.
Segundo, as principais causas de falhas são:
Problemas de especificação, problemas de implementação, componentes defeituosos, imperfeições da manufatura e fadiga dos componentes físicos.
Além disso, distúrbios externos como radiação, interferência eletromagnética, variações ambientais (pressão, temperatura, umidade) e problemas de operação também são considerados grandes causadores de falhas.
A duração de uma falha está relacionada com o fato de ser transiente ou permanente.
Falhas transientes ocorrem somente por um dado período de tempo, menor que um tempo máximo pré-determinado, e então desaparecem.
Essas falhas surgem de uma combinação de fenômenos locais, como descargas estáticas e surtos de tensão, e fenômenos globais, como radiação, características da fonte de potência, e projeto mecânico.
Quando uma falha transiente ocorre de um modo intermitente, é então chamada de falha intermitente, que usualmente resultam de operações marginais ou instáveis.
Qualquer falha que persista após o tempo máximo referido acima é chamada de falha permanente.
Requisitos de Tolerância a Falhas Para alcançar o atributo de tolerância a falhas num sistema, além de suprir os requisitos de funcionalidade e de desempenho do projeto, deve- se atender requisitos adicionais.
Os requisitos mais importantes estão brevemente descritos a seguir:·
Dependability ­ o termo dependability agrega os conceitos de confiabilidade, disponibilidade, segurança, testabilidade e desempenho.
É a qualidade do serviço prestado por um sistema particular.
Confiabilidade, disponibilidade, testabilidade e desempenho são utilizados para se determinar a quantidade de dependability do sistema;·
confiabilidade, que é a capacidade de atender a especificação, dentro de as condições definidas, durante certo período de funcionamento.
Assim, é a probabilidade de tempo que o sistema irá operar corretamente;·
disponibilidade, que é a probabilidade do sistema estar funcionando normalmente num dado instante de tempo;·
segurança de funcionamento, que é a probabilidade do sistema de estar ou operacional e executar sua função corretamente ou de descontinuar suas funções de forma a não provocar dano a outros sistemas ou pessoas que de ele dependem;·
testabilidade, que é a capacidade de testar certos atributos internos;·
desempenho, conceito relacionado à queda de desempenho provocado por as falhas;·
Maintainability ou seja, a facilidade de realizar a manutenção do sistema.
Pode, também, ser considerada como a probabilidade que um sistema com defeitos tem de ser restaurado a um estado operacional dentro de um período determinado.
Restauração envolve a localização do problema, o reparo físico e a colocação em operação.
Medidas de Confiabilidade Desde que, por definição, um sistema tolerante a falhas deve funcionar corretamente mesmo na ocorrência de defeitos em alguns de seus componentes, são necessários que elementos redundantes façam parte do sistema.
Porém, apenas redundância não é suficiente.
A causa dominante de falha em sistemas com alta confiabilidade não está relacionada à falta de recursos, e sim a falhas na detecção e contenção de erros em elementos com mau funcionamento, antes mesmo da falha causar um mau funcionamento no sistema completo.
Durante o desenvolvimento do sistema é importante definir os módulos que podem apresentar falhas.
Depois de identificar esses elementos com potencialidade de falha, deve- se compreender as causas dessas falhas, de forma a prevenir e evitar- las.
É importante estudar e analisar o meio interno e externo onde os módulos estarão funcionando, diminuindo o impacto das falhas originadas por elementos que não pertencem ao sistema.
Índices de Confiabilidade Um fator fundamental para o sucesso de um projeto tolerante a falhas é a concordância dos parâmetros de confiabilidade com os requisitos de confiabilidade especificados no projeto.
Para tanto, é necessário utilizar uma métrica capaz de quantificar esses parâmetros através da representação de um valor numérico que permita a obtenção de informações, tais como:·
descobrir se um sistema alcança os níveis de confiabilidade necessários para a aplicação real;·
comparar confiabilidade de sistemas distintos, e;·
analisar o efeito de diferentes técnicas de tolerância a falhas ou a combinação de diversas técnicas num mesmo circuito.
Em esse contexto, há várias medidas de confiabilidade, além de a probabilidade do produto ou componente operar com sucesso sem falhar.
Entre estas medidas mais comuns pode- se citar:·
confiança, é uma medida que indica por quanto tempo um determinado componente ou sistema pode ser considerado confiável para desempenhar satisfatoriamente sua função.
É normalmente expressada em unidades de tempo, como anos;·
MTTF (Mean Time Te o Failure), o tempo médio até a ocorrerência da primeira falha para itens irreparáveis.
É considerado um parâmetro comum para itens que são irreparáveis, ou seja, possuem uma vida limitada ou são sujeitos a desgaste mecânico sem condições de reparo.
Para itens reparáveis pode ser utilizado para planejar a manutenção, nesse caso é o tempo médio para a falha ocorrer;·
MTBF (Mean Time Between Failure), o tempo médio entre falhas.
É a medida de confiabilidade mais popular para itens reparáveis.
É utilizada para itens que irão falhar com certeza e devem ser reparados antes do desgaste, e;·
MTTR (Mean Time Te o Repair), o tempo médio para realizar o reparo.
Representa o grau de dificuldade para detectar uma falha e o grau de dificuldade para realizar o reparo, e;·
taxa de falha é o número médio de falhas de um grupo de itens (população), esperado por um dado período de tempo em operação.
Essa medida normalmente é utilizada para definir a confiabilidade de componentes individuais, ao invés de produtos constituídos de várias partes.
Uma taxa de falha normalmente depende de três fatores, projeto, qualidade da manufatura e nível de estresse aplicado ao componente.
Tratando- se de uma aplicação espacial, o reparo é considerado algo impossível, então o índice de confiança do FPGA deve ser adequado com o requisito da missão.
Uma missão pode ter um prazo médio entre 5 e 10 anos de duração, e o FPGA deve resistir a todos os efeitos de perturbação existentes no espaço durante todo esse tempo.
Cálculo da Estimativa de Confiabilidade O cálculo da estimativa de confiabilidade de um elemento inicia- se com a definição sobre a probabilidade desse elemento falhar no decorrer de o tempo, ou seja, a taxa de falha do elemento, ou de elementos pertencentes ao um único sistema, no decorrer de o tempo.
Se P (t) é a probabilidade de um elemento ainda estar funcionando num determinado Simplificando, obtém- se o resultado na equação:
A ocorrência de falhas na fase inicial normalmente é caracterizada por a utilização de componentes inadequados, imperfeições na fabricação, erros de projeto ou defeitos na instalação.
A ocorrência de falhas na fase de &quot;vida normal «depende da aleatoriedade das condições de uso do material.
Por fim, a ocorrência de falhas na fase de desgaste depende da idade do componente ou do desgaste físico do material gerado por longos períodos de utilização.
Para elementos eletrônicos, que possuem uma metodologia de fabricação consolidada, garantindo assim que aqueles elementos que poderiam gerar falhas na fase de &quot;mortalidade infantil «são identificados e substituídos por o fabricante, considera- se o simplificação da equação resulta na equação:
Conforme explicado anteriormente, o índice de confiabilidade de um elemento é definido por uma distribuição exponencial.
Alguns modelos de índice de confiabilidade obtêm uma maior abrangência de equação:
A partir de a equação, o índice de confiabilidade é definido por a distribuição de Weibull.
Se $= 1, a distribuição de Weibull é reduzida à uma distribuição exponencial.
Se 1, a taxa de falhas é inicialmente rápida e subsequentemente lenta, aproximando- se do fenômeno de mortalidade infantil.
Similarmente, se\&gt; 1, a taxa de falhas aumenta com o tempo, caracterizando elementos que geram falhas por desgaste.
O MTBF é normalmente utilizado para caracterizar o índice de confiabilidade de um elemento ou sistema.
O MTBF é derivado da função da confiabilidade e pode ser simplificado para valores de $= 1, sendo simplesmente o inverso da taxa de falhas de um elemento.
A equação do MTBF simplificada é apresentada na equação:
A aplicação dessas equações para estimar o índice de confiabilidade de um sistema, leva em consideração o tempo de utilização do sistema em questão.
Para equipamentos eletrônicos leva- se em consideração se o mesmo encontra- se energizado.
É importante fazer essa distinção visto que elementos que não estão constantemente energizados devem utilizar um fator de correção, chamado de fator de dormência, para determinar corretamente o índice de falha.
Em o presente trabalho será considerado que todo e qualquer elemento analisado está constantemente energizado e em condições de operação normais.
Efeitos da Radiação em Sistemas Aeroespaciais Fatores ambientais tais como variações na temperatura, variações na tensão de alimentação, interferências eletromagnéticas, e em especial a radiação cósmica, podem afetar o comportamento normal de um circuito, gerando uma falha.
A radiação cósmica consiste numa série de partículas carregadas (prótons, partículas alfa, íons pesados como os núcleos de ferro) e ondas de altas energias provenientes do espaço.
Trata- se de uma radiação ionizante, o que significa que interagem com o material ao colidirem com a superfície do Ci, pois possuem energia suficiente para causar a perda de elétrons dos átomos, ionizando as moléculas do Ci.
Além de alterar temporariamente a estrutura da matéria, outro efeito possível é o deslocamento dos átomos de sua posição original, modificando assim as propriedades da matéria, danificando permanentemente o Ci.
Devido a a natureza ionizante da radiação cósmica, quando esta radiação incide sobre um semicondutor, gera uma descarga elétrica.
O campo elétrico dos circuitos reconhece esses valores de carga e criam um pulso de corrente semelhante ao funcionamento dos transistores, o que pode causar um mau funcionamento do circuito.
Dentro de o fluxo de radiação cósmica que atinge a superfície terrestre, os nêutrons são os componentes mais numerosos.
Os nêutrons são partículas sem carga que não geram diretamente a ionização de um material, tais como os circuitos integrados feitos de silício, porém devido a a sua massa, esses geram íons de alta energia que provocam o aparecimento de cargas elétricas, que resultam num pulso de corrente no circuito.
Por isso, aplicações espaciais são as mais suscetíveis a esse tipo de problema, pois operam expostas às radiações cósmicas, sem a proteção da atmosfera terrestre.
No entanto, devido a as características da tecnologia de hoje, essa radiação também afeta os circuitos digitais que estão na terra, colocando em risco o funcionamento de aplicações críticas, como as de automação, medicina e aviação.
O efeito da radiação sobre a tecnologia atual é um fator que deve ser resolvido com a aplicação de técnicas de tolerância a falhas.
A o se trabalhar num ambiente como o espacial, onde as condições de funcionamento são extremas, deve- se considerar as alterações que as funcionalidades dos CIs podem sofrer devido a os efeitos da radiação, sendo necessária a atribuição de confiabilidade às aplicações de ordem críticas do sistema frente a esses efeitos.
O processo para desenvolver um circuito tolerante a falha implica na localização das áreas mais sensíveis do sistema e inserir em elas estruturas que sejam tolerantes a falhas.
Redundância Redundância é a palavra chave em tolerância a falhas e sua história é quase tão antiga quanto a dos computadores.
Todas as técnicas de tolerância a falhas envolvem alguma forma de redundância e elas estão tão intimamente relacionadas que é comum utilizar o termo sistema redundante para designar um sistema tolerante a falhas.
Assim, a redundância para tolerância a falhas pode aparecer de várias formas, e estão detalhadas nas próximas seções.
Redundância de informação é provida por códigos de correção de erros, como ECC (Error Correcting Code) ou códigos de detecção de erros EDC (Error Detection Codes).
Uma vez que a codificação da informação implica no aumento do número de bits e os bits adicionais não aumentam a capacidade de representação de dados do código, é possível perceber a razão da codificação também ser considerada uma forma de redundância.
Entre as diversas técnicas de redundância de informação posso citar:
Códigos de paridade, códigos m-de-n* (m- of- n*), soma de comprovação (checksum), códigos de Berger, códigos corretores de erros de Hamming, etc..
A redundância temporal é responsável por repetir a computação ao longo de o tempo.
Em esse caso, a redundância é implementada através da repetição de operações e normalmente é utilizada para detectar falhas transientes, tais como os bits flips gerados por os Seus (Single Event Upset).
Assim, a re-execução de instruções, segmentos de programas ou programas inteiros, bem como o re-envio de mensagens podem ser considerados exemplos dessa técnica.
A vantagem desse tipo de técnica é que se evita o custo da utilização de um hardware adicional, aumentando o tempo necessário para realizar uma computação, sendo empregada em sistemas onde tempo não é crítico ou onde o processador trabalha com ociosidade.
Usualmente essa técnica é aplicada para detecção de falhas transientes e permanentes da seguinte maneira:·
detecção de falhas transientes:
Repetindo a computação, resultados diferentes são uma forte indicação de uma falha transitória.
Essa estratégia não é adequada para falhas permanentes, porque os resultados repetidos nesse caso serão iguais, e;·
detecção de falhas permanentes:
Repete- se a computação com dados codificados e decodifica- se o resultado antes da comparação com o resultado anterior.
Essa estratégia provoca a manifestação de falhas permanentes.
A redundância de hardware está baseada na replicação de blocos lógicos dos circuitos.
Esses componentes realizam a mesma tarefa de forma que, se um módulo falhar, é possível que se detecte e se corrija a falha.
A redundância em hardware pode ser classificada em passiva, ativa e híbrida, sendo que cada uma dessas classificações está brevemente descrita a seguir.
Em a redundância de hardware passiva os elementos redundantes são usados para mascarar falhas e todos os elementos executam a mesma tarefa sendo que o resultado é determinado por votação.
Entre as redundâncias que atuam dessa forma pode- se citar:
TMR (triple modular redundancy) e NMR (N-Modular Redundancy).
A TMR, redundância modular tripla, é uma das técnicas mais conhecidas de tolerância a falhas e é capaz de mascarar a falha num componente de hardware triplicando o componente e votando entre as saídas para que o resultado possa ser determinado.
Essa votação pode ser feita tanto por hardware quanto por software.
Em esse caso, o elemento votador é considerado um ponto de falha no sistema.
Apesar de simples, o votador, por estar em série com os módulos de hardware e ter a responsabilidade de fornecer o resultado, é o ponto crítico de falhas no esquema TMR.
Se o votador apresentar baixa confiabilidade, todo o esquema vai ser frágil, tão frágil como o votador.
De entre as soluções para contornar a fragilidade do votador podem ser citadas:·
construir o votador com componentes de alta confiabilidade;·
triplicar o votador, e;·
realizar a votação por software.
TMR apresenta uma confiabilidade maior que um sistema de um único componente até a ocorrência da primeira falha permanente.
Depois disso, perde a capacidade de mascarar falhas e vai apresentar uma confiabilidade menor que um sistema de um único componente.
Com o tempo, quando aumenta a probabilidade de componentes falharem (ou seja, aumenta a taxa de defeitos) TMR apresenta uma confiabilidade pior do que um sistema não redundante.
TMR é ideal então para períodos não muito longos de missão e suporta uma falha permanente apenas, sendo ideal para falhas temporárias, uma de cada vez.
Já a redundância modular múltipla, NMR, é a generalização do conceito de TMR.
Ou seja, TMR é um caso especial de NMR.
O computador de bordo do Space Shuttle é um exemplo de NMR, com n igual a 4 e votação por software.
Em a redundância dinâmica ou ativa, a tolerância a falhas é provida por o emprego das técnicas de detecção, localização e recuperação de falhas.
Em esse caso, a redundância empregada não é capaz de prover mascaramento.
Em contraste com a redundância estática, nessa técnica, os módulos redundantes existem num modo de espera (stand-by) e podem substituir um módulo falho, de forma automática ou manual, por o módulo reserva selecionado, que pode estar ativo (hot standby) ou passivo (cold stand-by).
Em esse caso, a falha deve ser primeiramente detectada, uma vez que não é mascarada.
Os métodos híbridos combinam técnicas passivas e ativas, sendo que o custo em hardware é o maior entre os três métodos.
Um exemplo desse tipo de técnica é a aplicação da TMR, técnica passiva, juntamente com módulos de reposição, técnica ativa.
Em essa técnica híbrida a saída do votador mascara a falha e é utilizada para identificar se existe um modulo em falha além de ativar a reposição por outro módulo funcional.
Uma flexibilidade maior é proporcionada nas técnicas de redundância de software, além disso, nenhuma modificação no hardware é requerida.
A simples replicação de componentes idênticos é uma estratégia inútil em software.
Componentes idênticos de software vão apresentar erros idênticos.
Assim não basta copiar um programa e executar- lo em paralelo ou executar o mesmo programa duas vezes.
Para a obtenção de tolerância a falhas em software, uma possibilidade é a utilização de programação com n versões ou diversitária como técnica de redundância.
Enquanto pode ser provado formalmente que a redundância de elementos de hardware aumenta a confiabilidade do sistema, tal prova não existe para a diversidade em software.
Vários fatores influenciam a eficácia da programação diversitária:
As equipes podem trocar algoritmos entre si, os membros das equipes podem, por formação, tender a adotar os mesmos métodos de desenvolvimento, ou as equipes podem buscar suporte nas mesmas fontes.
Qualquer uma dessas correlações imprevisíveis constitui- se uma fonte potencial de erros.
Técnicas de confiabilidade existentes na UTMC O projeto da UTMC possui diversas técnicas que aumentam significativamente o índice de confiabilidade do sistema.
Entre as técnicas aplicadas no projeto podem ser citadas tanto as de codificação dos dados recebidos e enviados como, também, as de validação dos frames recebidos através do controle de sequência do protocolo de comunicação ­FARM (Frame Acceptance and Reporting Mechanism).
Entre os codificadores encontram- se os códigos corretores de erro RS (ReedSolomon) e BCH (Bose-Chaudhuri-Hocquenghem).
Essas classes de código utilizam o conceito de corpos finitos e seus algoritmos funcionam, basicamente, através de cálculos sobre polinômios.
Em o contexto de aplicações espaciais, os códigos RS e BCH são algoritmos amplamente utilizados, e servem para assegurar que a transmissão de pacotes entre uma plataforma orbital e uma estação terrestre seja recuperada mesmo na ocorrência de pacotes corrompidos.
Já com relação a a validação dos frames de telemetria enviados da UTMC, é importante destacar que podem ser classificados, quanto a o tipo de codificação utilizada, em:
Sem codificação, codificado com RS, codificado com Convolucional ou codificado com RS e Convolucional.
Apenas um tipo de codificação pode ser aplicado em cada missão, ou seja, não é alterado o tipo de codificação durante a vida útil da plataforma orbital.
Em adição a esses métodos de detecção e correção de erro, existem os CRC (Cyclic Redundancy Check) presentes nos próprios frames de envio e recebimento.
Ainda, além de o controle de erro através de dados codificados, existe a redundância dos canais de recebimento de dados e do próprio FPGA que contém a UTMC.
A seguir apresenta- se uma breve descrição de cada uma dessas técnicas.
Todo telecomando recebido na UTMC está no formato de bloco de código BCH.
O bloco de código BCH contém uma estrutura de dados de tamanho fixo de 64 bits, sendo que são 56 bits de dados, 7 bits de paridade e 1 bit de preenchimento.
Os 56 bits de dados codificados em BCH são separados em bytes de informação.
Através dessa estrutura é possível detectar e corrigir até 1 bit em erro em cada bloco de código BCH.
Códigos Reed--Solomon são blocos de códigos lineares não binários capazes de recuperar erros aleatórios tão bem quanto erros em rajada.
A codificação RS é precedida de uma sequência de 32 bytes para sincronismo entre diferentes frames de telemetria, sendo que essa marca de sincronismo não é codificada.
Cada frame é separado e embaralhado em 5 subframes de 223 bytes utilizando a técnica de entrelaçamento (interleaving), onde cada subframe possui 32 bytes de paridade, gerando o total de 160 bytes de paridade para os 1115 bytes de telemetria.
A técnica de interleaving permite que erros em rajadas sejam corrigidos, visto que os bytes de paridades são atribuídos aos bytes embaralhados.
Sendo assim, se existir um erro em rajada, este estará presente &quot;desmontado «em pedaços em cada um dos 5 subframes embaralhados.
A capacidade de correção do RS é de 16 símbolos em erro dentro de o frame de telemetria e, considerando que cada símbolo é composto por 8 bits, tem- se um total de 128 bits em erro que podem ser corrigidos, mesmo estando em rajada.
A grande vantagem da codificação convolucional é sua simples implementação e baixíssima ocupação de área no FPGA.
Cada símbolo codificado do Convolucional contém 1/2 bit de dado, ou seja, essa codificação duplica a quantidade de bits enviados para a estação terrestre.
Diferente do RS, a marca de sincronismo na codificação Convolucional é codificada para envio, o que não inviabiliza a sua detecção na estação terrestre.
Basicamente, os códigos de blocos processam a informação bloco por bloco, tratando cada bloco de bits de informação de forma independente com relação a outro bloco, por exemplo, a codificação BCH e RS.
Ao contrário de códigos de blocos, a saída de um codificador convolucional depende não somente da informação de entrada, mas também das entradas e saídas anteriores da forma bloco a bloco ou bit a bit.
Dentro de os fluxos de telecomando e telemetria, a detecção de erro concorrente é feita através da implementação de uma assinatura CRC de 16 bits.
Em ambos os fluxos existem dois CRCs que são adicionados aos dados recebidos e enviados através da UTMC.
Existem duas assinaturas CRCs em cada um dos fluxos da UTMC.
Em o fluxo de telecomando, os pacotes contêm CRC bem como os frames de transferência, o mesmo acontece no fluxo de telemetria, pacotes e frames de transferência contêm CRC.
Resumidamente, pode- se dizer que os CRCs estão inseridos entre diferentes níveis de abstração dos dados, permitindo que erros sejam detectados nos dados contidos no protocolo de comunicação da UTMC ou no pacote de informação pertencente ao OBC.
O projeto da UTMC contém todo hardware duplicado, ou seja, para cada elemento de hardware no módulo da UTMC existe outro elemento redundante e independente.
Em o módulo da UTMC existem dois FPGAs, um principal e outro redundante.
Cada FPGA possui uma fonte de alimentação individual e independente.
Para analisar os recursos de redundância do módulo da UTMC, primeiramente é feita uma análise das redundâncias existentes numa única UTMC, em seguida é feita uma análise do funcionamento de ambas UTMCs funcionando em paralelo dentro de o módulo.
Em uma única UTMC o recebimento e envio de dados ocorre da seguinte maneira:*
Os TCs são recebidos na UTMC através das entradas seriais principal (P) e redundante (R), e são enviados para o OBC1 e OBC2 através das duas seriais redundantes;*
A leitura de Tc pode ser realizada em ambas seriais, livre de prioridade, desde que exista dado disponível na serial.
Porém, a recepção real de telecomandos é realizada numa única serial, desde que a mesma esteja ativa.
Se ambas seriais enviarem dados simultaneamente, a leitura ocorre na serial principal.
O mesmo ocorre para a recepção de TMs oriundas dos OBCs;*
O envio de TCs para os OBCs é realizado simultâneamente em ambas seriais;*
Os TCs diretos são enviados diretamente para os instrumentos da plataforma orbital, sem passar por nenhum dos OBCs, e;*
O envio de telemetria ocorre através de uma única serial.
Em a visão do módulo da UTMC, considerando o funcionamento simultâneo de ambas UTMCs, o funcionamento da redundância pode ser descrito da seguinte maneira:*
O recebimento e tratamento dos TCs é realizado em ambas UTMCs simultaneamente.
O mesmo ocorre para o recebimento e tratamento de Tm;*
O envio de TCs para os OBCs ocorre simultaneamente em ambas seriais de ambas UTMCs;*
O envio de TCDs acontece simultaneamente em ambas UTMCs, porém somente um é enviado aos instrumentos.
Essa seleção acontece no módulo da UTMC através de um MUX de seleção.
Este pode ser considerado um ponto único de falha do sistema, e;*
Ambas UTMCs enviam dados de Tm simultaneamente e constantemente para a estação terrestre.
O controle de seleção que define qual UTMC está operando corretamente, é realizado na base terrestre através da leitura dos canais de telemetria principal e redundante.
Toda redundância de hardware existente no módulo da UTMC funciona passivamente, ou seja, todos os módulos executam a mesma tarefa e a seleção de resposta é feita por elementos externos.
Em este capítulo são analisados os trabalhos que possuem relação com o estudo proposto.
Para tanto, efetuou- se uma revisão bibliográfica de forma a descrever outras pesquisas cujos objetivos focam a área de aplicações espaciais, desenvolvimento de sistemas tolerantes a falhas em FPGAs, análise das tecnologias atuais para sistemas espaciais e técnicas de correção e detecção de erros em FPGA.
O trabalho de mestrado do Almeida, realizado no âmbito do projeto PUC&amp; SAT e orientado por o professor orientador deste trabalho, destina- se, também, à pesquisa espacial no contexto de Tc e Tm para plataformas orbitais.
O principal objetivo do trabalho consiste em investigar técnicas para o projeto de hardware para a codificação de telemetria utilizando os algoritmos de codificação e de correção de erros.
A ênfase dessa pesquisa deu- se na codificação de Tm e decodificação de Tc, sendo que o trabalho apresenta o projeto de um SoC (System-on-Chip) para codificação de telemetria e codificação/ decodificação de telecomando CCSDS utilizando, respectivamente, os algoritmos de correção de erros RS e BCH, ambos descritos na linguagem VHDL.
Os códigos corretores de erros BCH são utilizados para atividades de correção de telecomandos corrompidos durante o processo de transmissão de dados provenientes da estação terrestre para a plataforma orbital, enquanto que os códigos RS são utilizados na codificação dos dados de telemetria enviados para a estação terrestre.
O trabalho de Kastensmidt apresenta a combinação das técnicas de concorrente CED (Concurrent Error Detection) num multiplicador de 8 bits e num filtro digital de 8 bits para FPGAs SRAM.
O objetivo desse trabalho é alcançar um nível de tolerância a falhas próximo de aquele obtido com a aplicação da técnica de TMR.
Os resultados obtidos apresentam uma redução no consumo e área do FPGA, embora o tempo de resposta na saída do circuito tenha tido um acréscimo de, aproximadamente, 25% quando comparado ao circuito sem redundância, o que pode ser um problema em sistemas que necessitam de uma resposta mais rápida do circuito.
Os testes apresentados baseiam- se em diversos tipos de CED com o propósito de analisar a eficiência de diversas técnicas e comparar os resultados.
Os resultados apresentam um índice de detecção de falhas próximo a o da técnica de TMR.
Entre outras técnicas disponíveis na literatura, a técnica de assinatura de CRC no circuito do FPGA combinado com a técnica de TMR é apresentada por Castro.
Esse método valida a saída do sistema através da votação dos módulos replicados utilizando como critério uma assinatura CRC armazenada na memória do FPGA.
No caso de alteração de uma assinatura, o sistema detecta a falha e seleciona o valor correto de saída através dos votadores do TMR.
O CRC pode ser aplicado por camadas no sistema, gerando diversas palavras de verificação ou pode ser aplicado apenas à resposta final do sistema.
A vantagem da aplicação por camadas é a possibilidade de identificar o bloco defeituoso do sistema, o que permite a aplicação de outra técnica de correção de erro no bloco afetado.
A pesquisa apresentada por Pratt demonstra a eficiência de uma abordagem seletiva para proteger o FPGA contra os efeitos gerados por os Seus.
Através da técnica que permite definir quais elementos são essenciais dentro de o circuito do FPGA, é possível selecionar quais pontos do circuito devem ser protegidos.
O objetivo principal do artigo é aplicar a técnica de TMR somente em pontos do circuito que podem gerar falhas permanentes no sistema.
Com essa abordagem é possível reduzir consideravelmente o custo em termos de área e consumo do circuito do FPGA, ao mesmo tempo em que se obtém um nível de tolerância a falhas próximo a a aplicação do TMR completo no circuito.
A aplicação da técnica é feita através da análise do nível de disponibilidade a ser alcançado no circuito, onde o tempo médio entre falhas MTBF é uma análise fundamental para a aplicação dessa técnica.
Quanto maior o MTBF menos TMR é aplicado ao circuito e, por consequência, gera- se uma maior economia de recursos do FPGA, sendo que o oposto ocorre se o MTBF é pequeno, pois mais TMR deve ser aplicado no circuito, gerando uma economia de recursos menor.
A ocorrência de eventuais falhas transientes é aceitável se o circuito não exige um alto índice de disponibilidade, o que permite ao projetista proteger somente os pontos de maior ocorrência de falhas.
Os resultados apresentados indicam que a aplicação seletiva da técnica de TMR no circuito representa uma melhora no consumo e redução na área ocupada do FPGA.
Em a prática, o projetista pode equilibrar o nível de consumo com o nível de tolerância a falhas do sistema, selecionando um sistema mais econômico ou mais robusto.
Entre as diversas técnicas propostas para tolerância a falhas em circuitos de FPGA, a TMR é comumente utilizada, tendo como resultados um nível de remoção de falhas de até 99% num circuito de FPGA.
O trabalho proposto por Rollins apresenta a eficácia dessa técnica através de diversas variações de sua implementação.
Seu objetivo é avaliar a eficiência e o custo em termos de consumo, área e velocidade da técnica TMR e suas variações para aplicações em FPGA, utilizando como exemplo um contador de 8 bits sob a influência de diversas falhas.
É demonstrada a aplicação da técnica TMR com apenas um votador, três votadores e três votadores com realimentação da saída.
Os resultados obtidos ilustram que a escolha do tipo de técnica TMR é importante para o projeto de um circuito em FPGA, visto que as variações de consumo e eficiência a tolerância a falhas do circuito são diretamente dependentes do modelo de TMR utilizado.
A pesquisa apresentada por Fay apresenta a utilização de FPGAs SRAM em aplicações espaciais.
A utilização de reconfiguração parcial do FPGA, quando um erro no circuito do FPGA é identificado, é a técnica utilizada nesse artigo.
Além de aplicações não essenciais para a funcionalidade do satélite, tais quais processamento de imagem ou processamento de sinais, o artigo propõe a utilização de FPGA SRAM para aplicações de controle de atitude e telemetria.
Os resultados apresentados ilustram a vulnerabilidade do FPGA SRAM e justificam que em aplicações essenciais para o funcionamento da plataforma orbital, esse tipo de arquitetura ainda não é ideal.
O estudo apresentado por Kastensmidt aplica redundância na área de memória que contém a tabela de roteamento do FPGA SRAM.
O objetivo é solucionar os casos de erro que a técnica de TMR não consegue.
Como a técnica de TMR triplica toda a lógica combinacional e sequencial do FPGA, a possibilidade de um Seu afetar dois caminhos do TMR existe, o que invalidaria a saída do sistema.
Através da caracterização da matriz do FPGA é possível fazer a inserção de falhas em pontos específicos do FPGA.
Esse método de inserção de falhas permite que alterações em bits específicos do bitstream do FPGA sejam avaliadas e analisadas.
Depois que diversos casos de inserção de falhas são realizados é possível identificar aqueles que invalidam a saída da técnica TMR, sendo esses bits de roteamento duplicados, removendo falhas específicas da técnica TMR.
Podem ser necessárias algumas iterações até que o sistema não apresente falhas.
Essa técnica é interessante, pois detecta casos de falhas específicos na utilização de TMR no FPGA, podendo ser aplicada em FPGAs antifuse a fim de obter um índice ainda maior de confiabilidade do sistema.
Uma análise de diversos CED é realizada por Mitra, cujo objetivo é avaliar o custo em área comparado com o nível de proteção obtido em cada uma das técnicas de CEDs.
Entre as técnicas de CEDs citadas no artigo, são testados os métodos de detecção de erro por controle de paridade de 1 bit, controle de paridade com diversos bits, duplicação do circuito, Berger Codes e Bose-Lin codes.
Todos os métodos foram testados em diversos circuitos com diferentes finalidades.
O trabalho de Vinci faz uma análise sobre as características e requisitos de um satélite universitário desenvolvido no Ita, chamado de ITASAT, com foco nos aspectos de tolerância a falhas e confiabilidade do computador de bordo deste satélite.
É realizada uma quantificação dos índices de confiabilidade dos subsistemas do ITASAT, bem como a estimativa de vida útil e cálculos dos níveis de confiabilidade nesse satélite.
Uma análise comparativa entre os diferentes níveis de confiabilidade para o computador de bordo com e sem redundância é apresentada, observando- se um aumento significativo dos índices de confiabilidade para o cenário com hardware redundante ativo.
O estudo apresentado por O'Neill faz uma análise comparativa entre as tecnologias de FPGA SRAM, FPGA antifuse e ASIC.
Todas as vantagens e desvantagens de cada umas dessas tecnologias são apresentadas e toda a análise é realizada tendo como alvo aplicações espaciais.
As análises realizadas são bem realistas e práticas, sendo que o autor conclui que o FPGA antifuse é a melhor opção em termos de custo e desempenho para as aplicações espaciais.
Com relação a os FPGAs antifuse, pode- se destacar os trabalhos de Greene e de Roy, que explicam o funcionamento dos FPGAs antifuse e apresentam uma breve descrição da tecnologia em termos de roteamento do circuito, características de um projeto para FPGA antifuse, programação, teste e identificação de falhas em FPGAs antifuse já gravadas.
Ainda, o trabalho de McCollum apresenta uma análise da tecnologia e dos métodos de testes e validação desses FPGAs.
Os FPGAs apresentados nesse artigo são do fabricante Actel, que produz FPGAs antifuse para aplicações espaciais e militares há mais de 20 anos, sendo utilizadas em diversas missões espaciais da NASA.
O processo de fabricação e os métodos de tolerância a falhas contidos nesses FPGAs são apresentados junto com alguns exemplos de codificação VHDL para essa tecnologia.
Finalmente, o trabalho de Jong Wang apresenta diversos modelos de FPGAs antifuse bem como a tecnologia de fabricação e a quantidade total de radiação suportada por cada um desses modelos.
Todos os modelos de FPGAs analisados no artigo pertencem ao fabricante Actel.
Com o objetivo de facilitar a compreensão deste trabalho, é necessário que se faça uma análise das características presentes no módulo da UTMC, cujo protótipo possui recursos para implementar o protocolo de comunicação entre a plataforma orbital e a estação terrestre de acordo com o padrão ESA/ CCSDS.
A idéia básica do projeto da UTMC é permitir que, a partir de uma estação terrestre, telecomandos sejam recebidos na plataforma orbital, enviados para o OBC e que respostas sobre as condições atuais da espaçonave, na forma de telemetria contínua, sejam retransmitidas.
A UTMC é a interface de comunicação, implementada num único FPGA, entre o TT&amp; C (Telemetry Tracking and Control), localizado numa estação terrestre e o Computador de Bordo OBC da plataforma orbital.
O fluxo de telecomando e telemetria possui suas funcionalidades implementadas num FPGA da Actel ProAsic3e, modelo que permite a futura migração da lógica desenvolvida para um FPGA antifuse da Actel.
O módulo da UTMC possui duas UTMCs, portanto dois FPGAs, com o fluxo de telecomando e telemetria, denominados, respectivamente, de unidade principal (UTMC-P) e de unidade redundante (UTMC-R).
A comunicação de entrada e saída da UTMC é realizada através de portas seriais síncronas no padrão RS422.
O fluxo de telecomando utiliza uma serial de 4 kHz para o recebimento dos dados provenientes da estação terrestre, sendo que no protótipo esses dados vêm do TT&amp; C, equipamento localizado na estação terrestre, e outra serial de 4 kHz para envio dos telecomandos para o OBC.
O fluxo de telemetria utiliza uma serial de 650 kHz para o recebimento dos dados oriundos do OBC e outra serial de 650 kHz para envio de telemetria para o TT&amp; C. O FPGA utiliza uma frequência de operação (clock) de 13 MHz, que é utilizado no projeto síncrono e na geração dos clocks de envio das seriais síncronas.
Todas as seriais de entrada da UTMC são redundantes e independentes e, sendo assim, cada um dos fluxos da UTMC possui duas entradas seriais redundantes e independentes.
A Figura 3 apresenta os principais sinais de entrada e de saída dessas unidades.
Todo o envio e captura de dados para o protótipo da UTMC foi realizado através de um software desenvolvido na linguagem de programação gráfica LabView (Laboratory Virtual Instrument Engineering Workbench).
De essa forma, foi possível desenvolver e validar as funcionalidades do fluxo de Tc e Tm existente no FPGA utilizando a placa serial síncrona existente dentro de um microcomputador conectado à FPGA.
O software implementado em LabView foi um projeto desenvolvido em paralelo ao projeto da UTMC e de propriedade da empresa AEL Aeroeletrônica.
Fluxo de Telecomando (Tc) Antes de enviar os dados para a plataforma orbital, os bytes de informação são encapsulados de acordo com as recomendações do padrão ESA/ CCSDS.
Os dados dos telecomandos são inseridos em quatro níveis de encapsulamento distintos:
Pacotes de Tc, frames de transferência, codeblocks e CLTU (Communications Link Transmission Unit).
A Figura 5 apresenta o fluxo de geração de CLTUs considerado no projeto da UTMC desde a criação de um pacote de Tc até a criação da CLTU.
Em esse fluxo, pode- se observar que uma CLTU encapsula uma sequência de BCH codeblocks, sendo que os codeblocks representam um ou mais frames de transferência.
Assim, na estação terrestre, TCs são inseridos dentro de pacotes de Tc, que por sua vez são colocados na área de dados dos frames de transferência (visualizado no item 2 na Figura 5).
Os frames de transferência são transformados numa sequência codificada de BCH codeblocks, inserida dentro de uma CLTU (exibido no item 3 na Figura 5 -- Fluxo de encapsulamento de Tc e geração de CLTU As CLTUs geradas na estação terrestre por o controle da missão são então enviadas para a plataforma orbital.
O recebimento de dados oriundos da estação terrestre é de responsabilidade do fluxo de telecomando.
Os dados são enviados para a plataforma orbital no formato de CLTUs.
A camada de codificação recebe continuamente CLTUs, decodifica os blocos de dados BCH existentes dentro de a CLTU e encaminha os dados decodificados para a camada de transferência.
Essa camada agrupa os dados recebidos da camada de codificação e monta os frames de transferência.
Para cada frame de transferência montado, o mecanismo de aceitação do FARM valida o frame e autoriza ou nega o envio de seu conteúdo para a camada de empacotamento ou para o OBC da plataforma orbital.
Quando o frame de transferência carrega um telecomando direto, esse é enviado para a camada de empacotamento.
Se este for um telecomando roteado, deve então ser enviado para o OBC da plataforma orbital.
A camada de empacotamento recebe os dados oriundos do frame de transferência e monta um pacote de telecomando.
O conteúdo desse pacote é enviado para a CPDU (Command Pulse Distribution Unit) que se encarrega de executar os telecomandos diretos.
O tamanho mínimo de um frame de transferência é de oito bytes:
Cinco bytes do cabeçalho primário (primary header), um byte de informação de controle e dois bytes de controle de erros.
O tamanho máximo de um frame de transferência, conforme essa Em a Figura 5 está representado o encapsulamento em frames de transferência dos três tipos possíveis de pacotes considerados na UTMC, ou seja, TCD (telecomandos diretos), TCR (telecomandos roteados) e dados de controle para o FARM (com tamanho total de um ou três bytes).
É importante notar nessa mesma figura que o tamanho máximo definido para os TCDs e TCRs é de 240 bytes, visando uma melhor adaptação ao tamanho máximo de 256 bytes para o frame de transferência definido na norma da ESA.
A partir de o frame de transferência são gerados tantos codeblocks quantos forem necessários para representar todo o frame.
Cada codeblock possui 64 bits.
Caso o tamanho do frame não seja exatamente equivalente ao dos codeblocks, bits de preenchimento devem ser utilizados apenas no último codeblock.
Já no projeto da UTMC, foi definido que uma CLTU poderá conter apenas um frame de transferência e, apesar de essa definição, a implementação VHDL foi realizada de forma a processar CLTUs com mais de um frame.
Caso isso ocorra, os frames deverão estar organizados de forma contígua e qualquer preenchimento necessário deverá ser realizado no último codeblock de cada frame de transferência.
Em a Figura 6, estão representadas as camadas do fluxo de Tc implementadas em VHDL.
Em o lado esquerdo dessa figura estão representados os formatos dos dados que trafegam entre as camadas.
Assim, o bloco VHDL representando na parte inferior da figura é a camada de codificação, que recebe, serialmente, bits oriundos do módulo de telecomunicação da plataforma orbital através do sinal de entrada identificado como CLTU.
CLTUs entram na camada de codificação, que implementa em VHDL o algoritmo de decodificação BCH, fornecendo codeblocks de 56 bits para a camada de transferência.
Em essa camada, o FARM realiza uma análise nos codeblocks, gerando CLCWs (Command Link Control Words) com informações de telemetria para o fluxo de Tm.
Essa camada também é responsável por identificar se o Tc recebido é do tipo roteado (TCR) ou direto (TCD).
Os pacotes de TCRs são enviados diretamente para o OBC que possui uma camada de empacotamento implementada em software, responsável por desempacotar os TCRs.
Essa implementação está fora de o contexto do presente trabalho.
Os TCDs por sua vez são desempacotados por a camada de empacotamento implementada em VHDL e presente no FPGA e os comandos resultantes são, então, enviados para a CPDU, que se encarrega de distribuir- los diretamente aos instrumentos da plataforma orbital, sem passar por o OBC.
O serviço básico fornecido por a camada de codificação de Tc é garantir a entrega confiável de TCs do meio físico para os subsistemas de bordo do satélite.
A camada de codificação recebe continuamente bits do mundo exterior (de um pino do FPGA) sempre que o sinal de habilitação (enable) da comunicação serial estiver com o valor lógico zero.
Quando a sequência de início de uma CLTU é identificada, os BCH codeblocks são armazenados em memória até que uma sequência de fim de CLTU seja recebida.
A sequência de início de CLTU é utilizada como uma forma de sincronização do decodificador com os BCH codeblocks e, segundo, está definida como EB90H, sendo composta por os 16 bits conforme exibido na Figura 7, onde o bit mais significativo (MSB) é o primeiro a ser transmitido.
A sequência de fim de CLTU possui 64 bits e é construída de forma a não ser corrigível por o decodificador BCH além de delimitar o final da CLTU e terminar o processo de decodificação.
O comprimento dessa sequência deve ser o mesmo de um codeblock, ou seja, 64 bits.
O padrão de construção da sequência de fim é uma série de bytes no formato 01010101, terminando com um bit 1.
A sequência de fim de CLTU está representada na Figura 8.
Cada BCH codeblock, como apresentado na Figura 9, é composto por um campo com 56 bits de dados, um campo com 7 bits de paridade e um bit de preenchimento.
Esse bit de preenchimento é necessário de forma a completar o total de 64 bits de um BCH codeblock.
A camada de codificação é descrita por duas FSM (Finite State Machine).
A FSM responsável por o recebimento serial da camada física, utiliza o clock externo de 4 kHz para suas transições.
Os bits recebidos por essa FSM são armazenados num buffer de entrada de 64 bits.
Em paralelo ao recebimento, um circuito identificador de sequência de início de CLTU habilita a FSM responsável por a decodificação dos dados contidos no buffer de entrada sempre que uma sequência de início for encontrada.
Essa FSM, responsável por a decodificação dos dados de entrada, utiliza uma frequência de operação de 13 MHz.
O funcionamento da camada de codificação depende da existência de uma CLTU válida cuja condição consiste no seguinte:·
identificação de uma sequência de início válida com até um bit em erro;·
a ocorrência de até um bit em erro corrigível no codeblock, e;·
enquanto não for identificada uma sequência de fim válida.
Enquanto a CLTU for válida, estarão sendo realizados os processos de recebimento e decodificação de dados.
Caso contrário, uma sequência de idle (idle sequence), indicando &quot;ociosidade «é recebida.
O tamanho mínimo de uma sequência desse tipo é de oito bits, não possuindo um tamanho máximo.
Já o padrão utilizado para essa sequência consiste nuns e zeros alternados, sempre iniciando em zero.
A camada de transferência é responsável por receber frames de transferência da camada de codificação, validar- los utilizando o FARM e disponibilizar seu conteúdo (pacotes de Tc) para a camada de empacotamento (no caso de TCDs), ou para o OBC (no caso de TCRs).
Os frames de transferência são enviados por a camada de codificação para a camada de transferência em blocos de 56 bits (BCH codeblock decodificado).
O cabeçalho de um frame de transferência possui 5 bytes.
Sempre que for iniciada a recepção de um novo frame de transferência, uma verificação de CRC é realizada utilizando o campo FEC (Frame Error Control), apresentado na Figura 10.
Se não existirem erros é então verificado se os 5 bytes iniciais dos 56 bits recebidos formam um cabeçalho válido de um frame de transferência.
Quando um primeiro bloco de informação é recebido da camada de codificação, a camada de transferência grava em memória os bytes de dados deste primeiro bloco e permanece recebendo e gravando os novos blocos até que o frame de transferência seja recebido por completo.
A camada de transferência utiliza o valor do campo tamanho do frame para identificar o tamanho total do frame e determinar a quantidade de blocos de informação a serem recebidos da camada de codificação para que possa montar um frame de transferência completo.
Lembrando que para a UTMC, uma CLTU conterá apenas um frame de transferência que, por sua vez, conterá um ou mais pacotes de Tc.
Assim, é importante destacar que após a recepção de um cabeçalho válido, todos os blocos de informação seguintes (56 bits cada) pertencerão à mesma CLTU (consequentemente, ao mesmo frame de transferência).
Concluída a recepção do frame de transferência (controlada por o campo tamanho do frame), um ou mais pacotes de dados ou controle estarão prontos para processamento.
No caso de pacotes de dados, os mesmos estarão disponíveis numa posição de memória.
A principal função do FARM é validar frames de transferência, sendo acionado sempre que um frame completo é recebido.
Essa validação consiste na verificação do conteúdo dos campos do cabeçalho do frame de transferência, e, principalmente, na análise do número de sequência do frame recebido.
Outra verificação importante, realizada por o FARM, consiste no conteúdo do campo Id do Canal Virtual VCID (Virtual Channel Identification) do cabeçalho do frame listado na Figura 10 O INPE definiu que a UTMC deverá tratar dois canais virtuais:
Canal virtual 0 e canal virtual 1.
Pacotes com TCDs são recebidos por o canal virtual 0 e o campo VCID do cabeçalho do frame de transferência contém o valor 0 (zero).
Pacotes com TCRs são recebidos por o canal virtual 1 e o campo VCID do cabeçalho do frame de transferência contém o valor 1 (um).
Frames que não são aceitos por o mecanismo de validação do FARM são rejeitados e descartados por a camada de transferência.
A condição de aceitação ou rejeição de um frame é reportada para a telemetria através de mensagens CLCWs.
A CLCW é uma mensagem de controle enviada constantemente para a estação terrestre que contém os valores atuais das variáveis de controle do FARM.
A camada de empacotamento realiza a validação dos pacotes de TCDs a serem enviados para a CPDU.
As atividades desempenhadas por a camada de empacotamento são as seguintes:·
enviar para a CPDU o conteúdo dos pacotes de TCDs recebidos da camada de transferência, e;·
realizar a validação dos TCDs e o envio de pacotes de confirmação para o fluxo de telemetria.
Se existir algum TCD inválido, uma resposta negativa (NACK) é enviada para a telemetria, caso contrário uma resposta positiva (ACK) é enviada.
É importante ressaltar que a camada de empacotamento da UTMC recebe apenas pacotes com TCDs, uma vez que os pacotes com TCRs são enviados por a camada de transferência diretamente para o OBC.
A Figura 11 apresenta o formato de pacotes de TCDs, com o detalhamento dos campos do cabeçalho do pacote.
A validação do pacote consiste em verificar se no vetor de 16 instrumentos apenas um pulso está ligado num determinado instante, ou seja, impossibilitando que mais de um instrumento receba um pulso ao mesmo tempo.
Caso essa validação seja positiva, a camada gera uma confirmação (ACK) de quatro bytes, que é composta por o cabeçalho do pacote de Tc, sem os dois bytes do campo tamanho do pacote.
Porém, caso a validação seja negativa, um identificador de erro é anexado ao último byte do cabeçalho, também sem os dois bytes do campo tamanho do pacote, formando assim o NACK.
A CPDU é responsável por receber TCDs da camada de empacotamento e enviálos para os instrumentos.
Os bits de um TCD são codificados em forma de pulsos e enviados de forma paralela para os instrumentos.
Esse módulo é responsável, também, por garantir a duração de 13ms de um pulso enviado a um instrumento.
Fluxo de Telemetria (Tm) O objetivo final do fluxo de telemetria é possibilitar que os diversos processos dos diversos instrumentos existentes na plataforma orbital possam disponibilizar seus dados para o segmento terrestre.
Esses instrumentos podem ser compostos, por exemplo, por sensores para aquisição de dados da carga útil, estado atual dos subsistemas da plataforma orbital, confirmação do processamento de requisições, entre outros.
Assim sendo, é possível fazer com que o sistema de bordo da plataforma orbital transmita unidades de dados sobre um canal de comunicação espaço-terra, resultando na recepção dos dados por parte de o sistema terrestre.
O fluxo de Tm recebe os dados de Tm da unidade de processamento em operação (OBC principal ou OBC redundante) através de uma das duas entradas seriais síncronas independentes e redundantes, conforme ilustra a Figura 13, e os encaminha ao sistema de telecomunicação (subsistema TT&amp; C) por RF (Radio Frequência) para que sejam enviados para a Terra.
Em essa figura, pode- se observar que os módulos que compõem o Subsistema TT&amp; C possuem a informação:
Ou Equipamento de Teste.
No caso de os testes para validação da UTMC, foi utilizado um PC equipado com uma placa serial síncrona conectada a UTMC (e não um módulo de comunicação RF) de forma a realizar a homologação do sistema conforme solicitado por o INPE.
Ainda, é importante notar que a UTMC possui o sinal de saída duplicado externamente, onde uma saída de Tm é enviada para o subsistema TT&amp; C principal e outra para a Tm do subsistema TT&amp; C redundante.
O fluxo de Tm envia dados de telemetria constantemente para a estação terrestre.
Se nenhuma informação de telemetria é enviada para o fluxo de Tm, então frames de idle são transmitidos para a estação terrestre em conjunto com mensagens CLCW.
A relação entre as diferentes camadas do fluxo de Tm está representada detalhadamente na Figura 12, sendo que no lado direito da figura está representada a estrutura dos dados que transitam entre as camadas.
O processo encarregado de receber os pacotes de Tm oriundos do OBC não é considerado uma camada dentro de o fluxo de Tm visto que possui a única e exclusiva função de armazenar os pacotes de Tm e enviar para a camada de transferência.
Em o fluxo de Tm, a camada de empacotamento fornece a entrega fim-a-fim das unidades de dados de aplicação enquanto que a camada de transferência provê transferência confiável de pacotes.
Em essa camada, os pacotes são organizados numa estrutura (frame de transferência) que favorece seu transporte através de canais de comunicação da plataforma orbital para a estação terrestre.
Em a camada de codificação, o frame de transferência é preparado de forma a ser protegido contra erros ocasionados durante o processo de transmissão através de um canal de comunicação sujeito a ruídos.
A descrição de cada camada do fluxo de Tm é descrita a seguir.
Em a UTMC, a grande maioria dos pacotes é montada no OBC, uma vez que a maior parte das funcionalidades da camada de empacotamento não se encontra na UTMC.
A única situação onde um pacote é construído na UTMC, e não no OBC, diz respeito aos pacotes de confirmação de recebimento de TCD (pacotes de ACK e NACK gerados no fluxo de Tc).
Esses pacotes são gerados sempre que um TCD é identificado no fluxo de Tc.
Assim, quando existe um pacote pronto, seja originado no OBC ou na camada de empacotamento, o mesmo é enviado para a camada de transferência.
Em a UTMC os pacotes de Tm possuem um tamanho máximo pré-definido por o INPE de 1097 bytes.
A Figura 14 identifica o conteúdo dos pacotes de Tm.
É importante ressaltar que a quantidade de dados presentes no campo de dados do pacote de Tm é variável embora o tamanho total do pacote não deva ultrapassar o limite máximo de 1097 bytes.
A camada de transferência é responsável por prover uma estrutura para o transporte confiável de pacotes através de um link de comunicação entre a plataforma orbital e a estação terrestre.
Os pacotes recebidos da camada de empacotamento, ou do OBC, são encapsulados num frame de transferência que é repassado para a camada de codificação.
A camada de codificação é responsável por proteger os frames contra erros ocasionados durante o processo de transmissão.
Os frames de transferência de Tm devem possuir um tamanho fixo a ser definido para cada missão.
Esse tamanho precisa ser especificado no segmento terrestre como um parâmetro da missão.
No caso de a UTMC os frames de transferência possuem um tamanho fixo de 1115 bytes.
Esse é o tamanho padrão para suporte entre agências que utilizam o A Figura 15 apresenta o formato do frame de transferência de Tm, considerando a situação do tamanho fixo para o frame de 1115 bytes.
Em esse caso, considerou- se um frame de transferência contendo um cabeçalho, o OCF (CLCW e CRC) e apenas um pacote de Tm, sendo que esse pacote possui o tamanho máximo de 1103 bytes definido para a UTMC.
É importante ressaltar que pacotes menores de Tm podem ser transmitidos.
Em esse caso, o sistema de controle na estação terrestre poderá extrair os pacotes de Tm do frame, a partir de o campo Tamanho existente no cabeçalho de cada pacote, juntamente com informações existentes no campo Status dos dados do cabeçalho do frame.
Com isso, é possível saber onde termina cada pacote existente no frame.
Em esse caso, para pacotes de Tm com menos de 1103 bytes, o restante da área de dados do frame é preenchida com um pacote único de idle (com cabeçalho), contendo o valor 55H repetido tantas vezes quanto necessário, até preencher os 1103 bytes do campo de dados do pacote de Tm.
A camada de codificação recebe como entrada os frames da camada de transferência.
Esses frames podem ser codificados de acordo com uma das opções previstas no projeto:·
codificação Reed Solomon (RS);·
codificação Convolucional;·
codificação Reed Solomon (RS) e convolucional, e;·
nenhuma codificação.
Atualmente, são gerados quatro arquivos de configuração (bitstreams) para a UTMC, um para cada tipo de codificação.
Uma vez definida a estratégia de codificação a ser utilizada na missão, o bitstream equivalente é utilizado para configuração dos FPGAs principal e redundante, sendo que essa configuração não poderá mais ser alterada.
Os detalhes de implementação envolvendo cada um dos algoritmos de codificação aplicado nessa camada não são apresentados neste trabalho, visto que os mesmos foram desenvolvidos em projetos anteriores.
O formato dos dados de saída da camada de codificação é denominado de CADU (Channel Access Data Unit).
O CADU é composto por o frame de transferência com uma marca de sincronização de 4 bytes inserida no início de cada transmissão.
A versão da camada de codificação sem dados codificados apenas insere a marca de sincronização em cada frame de transferência lido da memória e disponibiliza os dados para envio para a estação terrestre.
A versão com codificação RS adiciona, além de a marca de sincronismo, um conjunto de 160 bytes na parte final do CADU, realizando, também, a codificação dos dados do frame de transferência.
A versão com codificação convolucional também adiciona a marca de sincronismo, executando a codificação completa de toda a CADU, incluindo a marca de sincronismo.
Através da aplicação dos diversos conceitos introduzidos neste trabalho, é possível aumentar consideravelmente o nível atual de confiabilidade da UTMC.
Pode- se classificar a técnica atual utilizada no UTMC como sendo de redundância de informação, conforme explicado ao longo de o texto.
Apesar de fundamental, somente essa abordagem de tolerância a falhas não garante o funcionamento dos módulos por longos períodos de utilização, os quais podem chegar a dez anos.
O desenvolvimento de um sistema que seja completamente tolerante a falhas é bastante custoso em vários aspectos, tais como:
Complexidade, consumo de energia e área de ocupação do FPGA.
Especialmente em razão desses motivos, objetivou- se, neste trabalho, remover todo ponto único de falha que possa existir no sistema, considerando como ponto único de falha os itens de I/ O (Input/ Output), clock, reset, registradores e caminhos lógicos.
Atualmente, as técnicas mais empregadas para detecção e correção de erros em FPGAs são, basicamente, aquelas baseadas em TMR combinada com atualização (refresh) de memória.
O refresh da área de dados do FPGA permite que o sistema recupere bits de memória atingidos por Seus sem interromper seu funcionamento normal.
É importante observar a necessidade de configurar a taxa de atualização utilizada no refresh, com o intuito de não permitir que dois Seus ocorram na mesma palavra e num único ciclo de operação do refresh, o que impossibilitaria a correção dos bits afetados.
De essa forma, a taxa de atualização deve condizer com a incidência de Seus no FPGA.
Adicionalmente, implementar circuitos com a técnica de redundância parcial em tecnologias do tipo ASIC ou Antifuse, significa criar uma proteção limitada aos registradores da área de dados do FPGA, protegendo o sistema somente contra os Seus.
Considerando que os caminhos lógicos (roteamento) entre os registradores do FPGA são estruturas fixas (hard-- wired), sem portas lógicas reconfiguráveis, essa abordagem é adequada para a proteção contra Seus, porém, ainda podem existir vulnerabilidades no circuito para falhas do tipo SEL.
Em tecnologias vulneráveis a SEL, uma maior proteção contra perturbações externas pode ser alcançada através da aplicação de redundância total no projeto do circuito.
Finalmente, é possível afirmar que a utilização da técnica de TMR na UTMC é uma solução atrativa, pois através dessa técnica é possível a obtenção de uma total redundância de hardware, incluindo os circuitos combinacionais e sequenciais, o roteamento e os recursos de entrada e saída.
Implementação de TMR A correta implementação da técnica de TMR depende do tipo de estrutura de dado que se pretende proteger.
As lógicas aplicáveis em FPGA podem ser agrupadas em quatro grupos distintos:
Entrada/ saída, e;
Recursos específicos do FPGA, tais como block RAM e DLLs.
Visto que lógicas do tipo máquina de estado são, por definição, estados dependentes, é fundamental que a votação por TMR seja aplicada internamente no módulo ao invés de aplicar- la no módulo como um todo.
Um exemplo que se enquadra nessa definição é o contador de um bit, descrito a seguir.
O contador de um bit carrega o valor contrário ao valor contido no seu estado anterior.
Apesar de a saída do contador de um bit ser meramente uma alternância entre os valores lógicos 0 (zero) e 1 (um), é provável que existam outros circuitos que dependam da correta sincronização do contador de um bit.
A ocorrência de um Seu no contador pode quebrar a correta alternância dos valores lógicos de saída.
Apesar de um Seu afetar apenas um único bit, após a sua ocorrência, o sincronismo é perdido e o contador, a partir de aquele momento, encontra- se num estado errôneo e fora de sequência por tempo indeterminado até que algum circuito o reinicialize.
Se esse tipo de circuito é replicado com três versões redundantes, onde a saída é escolhida por um votador de maioria, o votador é capaz de, então, mascarar a falha de um dos caminhos redundantes.
Esse circuito fornece o valor correto na saída mesmo na ocorrência de um Seu.
Contudo, um dos caminhos redundantes continuará fora de sincronia em relação a os outros.
Se outro caminho redundante for afetado por um Seu, a saída do votador estará, então, permanentemente incorreta.
Com dois caminhos redundantes incorretos, a saída do votador também estará incorreta, sem possibilidade de recuperação ao estado correto de funcionamento, até que o circuito seja reinicializado.
Para possibilitar que o circuito possa se recuperar de forma autônoma, sem a necessidade de reinicialização, cada caminho redundante precisa incorporar a saída do votador no valor de realimentação da entrada do contador.
A saída do votador fornece o valor correto na realimentação do contador, corrigindo o erro gerado por Seu.
Para eliminar qualquer ponto único de falha, o votador de maioria também é triplicado.
Todo Seu é filtrado no circuito em cada ciclo de clock, permitindo que o circuito se recupere autonomamente antes que outro Seu ocorra.
Portanto, o conceito básico na construção de TMR, para lógicas de máquinas de estado, consiste em:
Triplicar todo o circuito e inserir um votador de maioria em cada saída registrada ou caminho de realimentação.
O uso de três votadores de maioria, redundantes, elimina todos os pontos únicos de falha, além de fornecer as três saídas redundantes para as três entradas do próximo módulo.
O votador pode sofrer perturbações por Seus e, por esse motivo, o votador também deve ser triplicado, eliminando o ponto único de falha na votação.
A Figura 16 ilustra o circuito do votador de maioria para o exemplo do contador de um bit.
A Figura 17 exibe um exemplo generalizado do TMR com três votadores por maioria.
Essa é uma solução possível para a lógica com realimentação descrita anteriormente.
Ainda utilizando o exemplo exibido na Figura 17, para que ocorra uma falha neste circuito é necessário que múltiplas perturbações ocorram.
É importante ressaltar que esse circuito é completamente imune a Seus de ocorrência única, desde que essas perturbações ocorram em padrões específicos de tempo e frequência, tolerados por o circuito.
A probabilidade da ocorrência de múltiplas perturbações, fora de os padrões normais de acontecimento, não é um ponto de preocupação no projeto, visto que o aumento de confiabilidade fornecido por a técnica é considerado somente quando um caminho lógico ou votador, entre os três existentes, sofrem a perturbação.
Se dois ou mais módulos redundantes estiverem em estados errôneos devido a a ocorrência de múltiplas perturbações, então o correto funcionamento do circuito está comprometido.
Considerando que erros na saída do circuito devem ocorrer, não por falhas nos votadores, mas sim, por múltiplas perturbações nos módulos redundantes, pode- se afirmar que o método de votação apresentado atende aos níveis de confiabilidade requisitados.
Portanto, para aumentar ainda mais o nível de confiabilidade de todo o sistema da UTMC, o foco está na análise dos dados gerados em cada um dos módulos redundantes.
O principal objetivo da técnica TMR é a remoção de todo e qualquer ponto único de falha no sistema, iniciando- se por os pinos de entrada do FPGA.
Caso uma única entrada esteja conectada nos três blocos lógicos redundantes, então, na ocorrência de uma falha na entrada do sistema, a mesma seria replicada para todos os módulos redundantes, impossibilitando a detecção e mascaramento do erro.
Portanto, cada módulo redundante do projeto que utiliza valores de entrada do FPGA deve ter seu próprio conjunto individual de entradas.
Por consequência, se uma das entradas sofrer uma falha, somente um dos módulos redundantes será afetado.
Em esse caso, as saídas de uma implementação TMR são o ponto chave dessa estratégia.
Visto que a implementação completa da técnica de TMR gera a triplicação de todos os caminhos lógicos, deve- se aplicar, fundamentalmente, um método capaz de trazer esses três caminhos lógicos de volta para somente um caminho lógico, de maneira tal que não seja criado um ponto único de falha.
Isso é possível através da aplicação de seleção de saída em esquemas de TMR com três votadores.
A seleção de saída do TMR é construída com votadores de minoria combinados com 3-s tate buffers de saída (TRIBUFF).
O sinal de saída de cada caminho lógico redundante do TMR passa por um 3-s tate buffer que, posteriormente, é conectado diretamente ao pino de saída do FPGA, conforme ilustra a Figura 18.
O sinal de habilitação de cada TRIBUFF é controlado por um circuito votador de minoria.
O votador de minoria indica quando o caminho em questão (caminho primário P) está em concordância com algum dos outros dois caminhos redundantes.
Se o caminho primário possui o mesmo valor que algum dos caminhos redundantes, então o caminho primário faz parte da maioria.
Se o caminho primário não possui o mesmo valor que nenhum dos dois caminhos redundantes, então o caminho primário faz parte da minoria.
Externamente aos pinos do FPGA, as três saídas são interligadas diretamente no circuito da placa.
Essa estrutura não causa nenhum tipo de estado transiente controverso, visto que somente as saídas que concordam entre si são diretamente conectadas.
A grande vantagem deste método é que nenhum circuito adicional, externo ao FPGA, é necessário para unificar as três saídas do TMR, como seria no caso de a utilização de três FPGAs independentes em oposto a redundância interna numa única FPGA.
A próxima seção apresenta a solução TMR desenvolvida na UTMC para alcançar os índices de confiabilidades necessários ao projeto.
TMR no módulo da UTMC A aplicação de TMR no módulo da UTMC segue o exemplo do contador de um bit apresentado na seção anterior.
Dentro de as camadas dos fluxos de Tc e Tm, a implementação do TMR foi realizada individualmente em cada conjunto de máquinas de estados, registradores e lógicas de seleção.
A simples replicação de cada um dos fluxos de Tc e Tm não foi aplicada, por se tratar de um método que não permite a recuperação autônoma do módulo a partir de a ocorrência de Seus, conforme previamente explicado.
A alimentação dos dados de entrada, para cada um dos caminhos lógicos replicados na UTMC, deve ter sua origem, obrigatoriamente, em diferentes pinos do FPGA.
A triplicação completa do TMR implica na utilização de fontes de clocks independentes para cada caminho redundante, visto que somente uma única fonte de clock para todo o sistema de TMR pode ser considerada como um ponto único de falha, já que a ocorrência de Seus na árvore de clock afetaria todos os módulos redundantes.
No entanto, além de a impossibilidade de se triplicar os pinos de entrada e saída, não é possível utilizar domínios de clocks independentes no circuito da UTMC e, portanto, foi utilizada somente uma única fonte de clock para todos os módulos redundantes.
Por se tratar de um protótipo, modificações no circuito que permitam o mapeamento de três pinos de entrada no FPGA são possíveis e necessárias, caso se deseje eliminar esse ponto único de falha.
A seguir, encontra- se a explicação de como foi implementado o TMR na camada de codificação da UTMC, método este que foi utilizado em todas as outras camadas.
Como contadores, as máquinas de estados geram um laço de realimentação registrado que deve ser replicado e votado a fim de assegurar tolerância a falhas contra os efeitos de Seus.
A implementação de TMR para esse tipo de circuito não é trivial, mas a sua correta aplicação garante sua efetividade contra os efeitos de Seus.
O funcionamento da FSM da camada de codificação é o de mais baixa complexidade dentro de o projeto da UTMC sendo ideal para exemplificar a aplicação da técnica de TMR.
Conforme explicado na Seção 4.1.1, a camada de codificação do fluxo de Tc possui duas máquinas de estados responsáveis por o recebimento e decodificação dos dados oriundos da camada física.
O diagrama ilustrado na Figura 21 exibe a máquina de estados de decodificação, que é detalhada a seguir.
A FSM da Camada de Codificação do fluxo de Tc possui oito estados:
Idle, receive no contexto das funções da camada de codificação, descritas anteriormente.
A FSM permanece no estado idle até que o sinal CLTU_ ok receba o valor 1, passando, então, para o estado receive_ next.
Em esse estado, o buffer de 63 bits é preenchido serialmente com o conteúdo do BCH codeblock, avançando para o estado start quando o buffer estiver preenchido ou retornando para estado idle se o sinal CLTU_ ok receber o valor 0.
Os estados start, exec e exec_ tmp são encarregados de decodificar os BCH codeblocks existentes na CLTU e corrigir até um bit em erro, se necessário.
Esses estados são executados sequencialmente em três ciclos de clocks.
O estado ready verifica se o codeblock decodificado é válido para envio e, na ausência de algum erro não corrigível, o codeblock é considerado válido e pronto para envio;
Caso contrário, o estado de erro é acionado.
Em o estado send, o conteúdo do BCH codeblock é disponibilizado para a camada de transferência, permanecendo até o recebimento do sinal de acknowledge, provido da camada de transferência.
O tipo de codificação utilizado para a implementação em VHDL da FSM é um ponto importante para a aplicação do TMR.
Foi selecionado o tipo de codificação gray code, visto que a codificação simbólica não serve para a implementação de FSM com TMR, porque os votadores de maioria devem ser inseridos em cada caminho de realimentação dos estados.
Portanto, a codificação da máquina de estados deve ser explícita, conforme pode ser observado na Tabela 2, que representa os estados codificados da FSM da camada de codificação.
A interface da camada de codificação foi modificada para receber os dados redundantes oriundos da triplicação do caminho de entrada.
Os sinais de saída foram alterados para o envio redundante triplo, realizado para a camada de transferência.
A partir de essa modificação, existem três versões de cada sinal de entrada e saída.
Internamente, existem três fluxos redundantes da camada de codificação, interligados por votadores responsáveis por decidir qual o próximo estado da FSM.
O registrador de cada estado forma uma lógica em laço.
Esse é, então, o ponto de inserção do votador de maioria ao aplicar a redundância tripla no circuito.
Em o projeto do VHDL, os estados das FSMs são decodificados em estruturas de seleção (switches) que determinam o estado atual da FSM e, por consequência, os valores dos sinais de saída do módulo ao qual pertencem, neste exemplo, das saídas da camada de codificação.
O sistema de votação utiliza um votador para cada bit do registrador de estado.
Considerando que são utilizados 3 (três) bits no registrador de estado e que são três caminhos redundantes, o sistema como um todo utiliza 9 votadores.
A votação é realizada a partir de a seleção entre a maior ocorrência do bit entre os três caminhos redundantes.
O esquema apresentado na Figura 22 permite a correção de qualquer bit em erro, bem como a recuperação autônoma do sistema na incidência de algum Seu.
Já na Figura 23, pode- se observar a implementação da TMR completa na UTMC.
Esta é uma representação estrutural do TMR, visto que a implementação correta é realizada dentro de os fluxos de Tc e Tm.
Confiabilidade na memória do FPGA Os módulos de memória do FPGA requerem recursos especiais de redundância para fornecer altos índices de confiabilidade.
Os modelos de FPGAs da família RTAX-S/ SL da Actel, utilizados no projeto da UTMC, possuem recursos para proteger os módulos de memória SRAM contra os efeitos da radiação oriunda do espaço através de um módulo IP (Intellectual Property) conhecido como EDAC (Error Detection and Correction).
Esses modelos de FPGA foram escolhidos visto que o fabricante é conhecido por desenvolver FPGAs antifuse para aplicações espaciais.
Os módulos EDAC RAM da Actel utilizam as técnicas de TMR e refresh dentro de o módulo IP.
Com a utilização das ferramentas de desenvolvimento da Actel, todos os registradores são protegidos por empregarem a técnica de TMR com votador único na saída do circuito, permitindo que Seus sejam tolerados automaticamente, sem a necessidade do projetista desenvolver uma técnica separada para proteção da memória.
Esse recurso agrega ainda mais confiabilidade ao projeto.
Finalmente, um processo de codificação e decodificação dos dados é realizado a cada acesso de leitura ou escrita na memória.
Para cada palavra escrita é associado um conjunto de bits de paridade, permitindo que 1 bit em erro seja corrigido ou dois bits em erro sejam identificados durante um processo de leitura ou de refresh.
O conteúdo da memória é verificado periodicamente através da utilização do decodificador do módulo EDAC, permitindo que alguns bits em erro sejam corrigidos ou identificados.
A implementação do TMR completo no projeto aumenta consideravelmente a complexidade dos módulos internos, além de causar acréscimos no consumo de área, de potência e na quantidade de pinos do FPGA.
A fim de reduzir estes custos, foi desenvolvida uma alternativa tão eficiente quanto o TMR, capaz de apresentar altos índices de confiabilidade com custos reduzidos.
A técnica de duplicação com comparação esses requisitos, sendo, então, escolhida para ser aplicada no projeto da UTMC.
As técnicas de redundância temporal e DWC são capazes de detectar erros.
Sua combinação resulta na capacidade de, além de detectar a existência de um erro, identificar, também, o módulo redundante onde a falha causadora do erro esta localizada.
Para realizar a implementação da técnica de DWC combinada com redundância temporal deve- se duplicar a lógica do circuito utilizando um TMR reduzido.
Além disso, é necessário adicionar uma lógica que execute duas vezes os comandos enviados para a UTMC, onde cada execução é realizada em tempos e em caminhos diferentes.
A aplicação de detecção de erro concorrente CED (Concurrent Error Detection) baseada em redundância temporal, combinada com a redundância de hardware em FPGA é uma solução eficiente para detecção e votação de Seus, embora existam dois problemas que devem, mandatoriamente, ser solucionados:
O diagrama exibido na Figura 24 permite uma melhor compreensão do funcionamento dessa técnica.
Em esse caso, durante a primeira execução do comando no tempo t0 (tempo inicial), o comando é executado no fluxo normal de operação e o resultado é armazenado para comparação futura.
Durante a segunda execução, no tempo t0+ d (tempo inicial acrescentado de um intervalo de atraso d), os dados de entrada percorrem o fluxo de execução redundante, a fim de alterar o caminho lógico e permitir, por comparação, a detecção de algum erro durante a execução do comando.
Em ambos os fluxos de Tc e Tm é inserido um módulo CED capaz de detectar e reportar a ocorrência de erros.
Se, ao término do processamento dos dados, o CED identificar a ocorrência de um erro em algum dos módulos, automaticamente o bloco comparador descarta o valor errado e utiliza o outro caminho redundante como resposta do sistema.
Se ambos os módulos apresentarem erro ou se as saídas não concordarem num único valor, então o sinal de erro é acionado.
Através desse sinal é possível, por exemplo, acionar a UTMC redundante existente na plataforma orbital.
Atualmente no projeto da UTMC não existe a seleção automática entre os módulos principal e redundante, visto que não existem recursos capazes de detectar se o módulo esta em estado de erro.
A implementação do sinal de erro, conforme descrito anteriormente, é uma contribuição importante para o projeto da UTMC, visto que este foi um recurso solicitado por o INPE que não foi atendido dentro de o escopo do projeto da Implementação de DWC combinada com CED na UTMC A implementação de DWC no módulo da UTMC enfrenta as mesmas limitações em termos de recursos do FPGA na versão atual do projeto.
Não é possível se utilizar duas fontes de clock independentes ou duplicar os pinos de entrada e saída, conforme explicado anteriormente.
Portanto, o mesmo método de divisão do sinal de entrada foi aplicado, também, para o DWC.
A implementação do DWC apresenta uma menor complexidade quando comparada a aplicação da técnica de TMR na UTMC.
A duplicação dos fluxos de Tc e Tm é realizada integralmente, sem alterar as estruturas internas dos blocos lógicos.
Além disso, os caminhos redundantes não sofreram nenhuma alteração interna nos fluxos de Tc e Tm, sendo que a única alteração necessária é a inserção do módulo CED nas duas versões redundantes.
O módulo CED é uma assinatura CRC de 16 bits em conformidade com as recomendações do CCSDS inserida entre as camadas dos fluxos de Tc e Tm.
O cálculo do CRC utiliza o gerador polinomial apresentado na equação a seguir:
O CRC utilizado é inicializado com o valor 0 xFFFF, ou seja, inicialmente assume esse valor e é recalculado serialmente para cada novo bit recebido.
Em a implementação VHDL o valor atual do CRC é registrado e para cada bit recebido, uma lógica combinacional calcula o próximo CRC a partir de o valor atual e do novo bit recebido.
Essa lógica é implementada em forma de função, utilizando, basicamente, deslocamento de bits com algumas operações XOR.
A Figura 25 apresenta o CRC-16, onde se pode observar que, para cada bit na entrada µi, o valor do CRC é atualizado através dessa função.
A seguir descreve- se como o CED, dentro de os fluxos de Tc e Tm da UTMC, foi implementado.
A implementação do CED é realizada entre as camadas dos fluxos de Tc e Tm.
Conhecendo a funcionalidade de cada uma das camadas dos fluxos de Tc e Tm, é possível calcular um CRC para todo dado de entrada da camada e comparar com a assinatura gerada na saída dessa mesma camada.
Já que o fluxo de Tc pode ser descrito, de forma resumida, como sendo um mecanismo capaz de receber um conjunto de dados separados em codeblocks, frames de transferência e pacotes de Tc, isso torna possível a geração de uma assinatura CRC em cada camada do fluxo de Tc.
Isso é viável uma vez que todo dado de entrada da camada será reenviado para a camada seqüente após ser submetido ao processo de validação daquela camada.
Em essa figura, pode- se observar que a camada de codificação inicia o processo de recebimento dos dados oriundos da CLTU, sinalizando o bloco CED1 que iniciou o processo de recebimento.
A partir desse momento, o CED1 está sincronizado com a camada de codificação e a criação da assinatura CRC para os dados de entrada dessa camada acontece simultaneamente ao recebimento dos dados seriais.
O bloco CED1 não utiliza os bits de paridade para criar o CRC, visto que somente o conteúdo dos codeblocks é enviado para a camada de transferência. (
ver capítulo 4 para detalhes de formação das estruturas de dados do fluxo de Tc).
Então, após receber e decodificar os dados, a camada de codificação envia os codeblocks para a camada de transferência, onde o bloco CED1 gera outra assinatura CRC.
Em seguida, o CED1 informa ao bloco de controle de CED acerca de a existência de erros nos dados enviados por a camada de codificação e, na inexistência de qualquer erro, nenhum dado é enviado para o controle de CED.
O mesmo processo de geração de assinatura acontece nos dados da camada de transferência embora somente o conteúdo do frame dessa camada seja empregado.
O bloco CED2 descarta o cabeçalho e o FEC do frame de transferência para gerar a assinatura CRC.
Diferentemente das outras camadas, a camada de transferência pode enviar dados para a camada de empacotamento, OBC ou FARM.
O bloco CED2 identifica qual sinal de saída da interface será utilizado na transmissão dos dados e gera a segunda assinatura da camada de transferência.
Após a comparação, o bloco CED2 informa ao controle de CED sobre a ocorrência de erros.
O bloco CED3 é encarregado de verificar os dados da camada de empacotamento.
Somente o conteúdo do pacote de TCD é utilizado nesta verificação, sendo que os dados de cabeçalho e CRC do cabeçalho são descartados.
O processo repete- se para a camada CPDU onde uma verificação direta do conteúdo dos TCD é realizada.
O controle de CED mantém o sinal de erro desabilitado até a ocorrência de um erro que seja oriundo de algum dos blocos CED1, CED2, CED3 ou CED4.
É importante salientar que a ocorrência de um erro não invalida permanentemente o fluxo de Tc em questão, mas indica a ocorrência de um Seu durante a execução do fluxo de Tc.
A implementação do CED no fluxo de Tm segue a mesma lógica aplicada no CED do fluxo de Tc.
A principal diferença, porém, consiste no fato de que o fluxo de Tm não remove os dados entre as suas camadas, visto que o objetivo final da Tm é gerar pacotes para a estação terrestre.
Portanto, a cada transferência de dados entre as camadas, adiciona- se bytes de cabeçalho e CRC.
A aplicação do CED no fluxo de Tm é apresentada na Figura 27.
Não existe CED dedicado na camada de codificação da Tm, visto que os dados que entram são alterados por os codificadores RS e Convolucional.
Qualquer tentativa de se inserir um controle de erro nesses blocos de codificação limita- se à replicação dos codificadores.
Essa solução foi descartada por não ir ao encontro de os objetivos de redução máxima do aumento do uso de área do FPGA na aplicação de técnicas de redundância.
Os dados recebidos do OBC encontram- se, inicialmente, no formato de pacotes, sendo que a única função da camada de recepção de pacotes é fazer o controle de seu armazenamento em buffers de memória.
Existem três buffers de memória gerenciados por essa camada, sendo imprescindível garantir a integridade do conteúdo armazenado em memória.
A camada de recepção de pacotes informa para o CED1 qual o buffer responsável por armazenar o pacote de Tm atual.
De a mesma forma, o CED1 armazena três CRCs distintos, um para cada buffer de memória.
Após a liberação da camada de transferência para recebimento de um novo pacote, o CED1 recebe a informação da camada de recepção de pacotes sobre qual o buffer de memória que está sendo utilizado.
O bloco CED1 gera um novo CRC a partir de os dados que foram enviados para a camada de transferência e compara a assinatura gerada no envio com a assinatura de recebimento.
Em a ocorrência de erros, o controle de CED é reportado.
A camada de empacotamento gera pacotes de ACK e NACK, portanto as assinaturas para esses pacotes já são previamente conhecidas por o CED2.
Sua única função é, então, verificar qual tipo de pacote está sendo enviado para a camada de empacotamento e realizar uma comparação dos dados da saída dessa mesma camada de empacotamento.
Tanto o início quanto o término de cada transmissão de dados para a camada de transferência é sinalizado por a camada de empacotamento para o bloco CED2.
Já a camada de transferência está constantemente enviando frames de telemetria com a palavra CLCW no final de cada frame.
Então, para a detecção de erros na camada de transferência, dois cenários devem ser analisados.
Primeiro, a UTMC pode estar ociosa e, portanto, enviando somente frames idle com o valor do campo do CLCW.
Em esse caso, o CED3 faz a verificação do CRC gerado com o conteúdo do CLCW combinado com o CRC gerado para um frame idle.
Segundo, pode existir algum pacote sendo tratado na camada de transferência e, portanto, o CED3 faz a geração de CRC do conteúdo desse pacote combinado com o CLCW.
DWC Combinado com CED na UTMC A redundância temporal na UTMC, seguindo a estratégia de redundância temporal apresentado no início deste capítulo, possibilita a execução dos fluxos de Tc e Tm em intervalos de tempo diferentes para cada fluxo redundante.
Em um dos caminhos redundantes, o recebimento e execução acontecem sem nenhuma interferência embora no outro caminho redundante existam buffers de armazenamento que atrasam a execução dos comandos.
O recebimento de Tc é realizado por a serial de 4 kHz, o que pode ser considerado extremamente lento se comparado com a velocidade de envio da Tm.
Para cada bit recebido por esta serial, são gastos 1625 pulsos de clock do FPGA, o que equivale a um tempo de espera de aproximadamente 125,12 µs.
Esse é o atraso aplicado para o recebimento dos dados de Tc e Tm, através de um buffer de 11 bits inserido na entrada do módulo.
Apesar de os módulos redundantes estarem fora de sincronia, é importante salientar que a sincronia entre os fluxos de Tc e Tm de um mesmo módulo é mantida, visto que o atraso inserido é o mesmo para ambos os fluxos.
Conforme apresentado na Figura 28, o módulo sync é responsável por a sincronização entre os módulos redundantes, que é realizada através de um buffer de saída, também de 11 bits, que armazena os dados, atrasando o envio dos fluxos de Tc e Tm.
A comparação dos dados de saída é realizada após a verificação da existência ou não de alguma falha num dos módulos redundantes.
Se ambos os módulos não apresentarem falha, então o circuito comparador constata a igualdade entre os dois módulos.
Se os dados entre os dois módulos redundantes divergirem, o sinal de erro é habilitado, constatando um erro de operação no circuito do FPGA.
O mesmo acontece caso os módulos redundantes apresentem erros de CED.
A arquitetura topo (top) da UTMC é apresentada na Figura 28.
Este capítulo apresenta os resultados obtidos no presente trabalho, levando em conta as técnicas empregadas e descritas previamente.
Destaca- se o acréscimo de área, a comparação entre as técnicas apresentadas e a descrição das principais dificuldades e problemas enfrentados durante a implementação do projeto.
Dificuldades Enfrentadas Durante a Implementação do VHDL Durante o desenvolvimento do projeto VHDL da UTMC, diversos problemas, principalmente de origem técnica, foram enfrentados.
A seguir, uma detalhada descrição desses percalços é feita.
O sistema como um todo foi desenvolvido a partir de alguns requisitos fornecidos por o INPE, e listados a seguir.·
Direção de comunicação do TT&amp; C para UTMC.
A UTMC deverá possuir dois canais independentes de entrada de TCs.·
Direção de comunicação da UTMC para OBC.
A UTMC deverá possuir dois canais independentes de saída de TCRs.·
Direção de comunicação da OBC para UTMC.
A UTMC deverá possuir dois canais independentes de entrada de TMs.
A UTMC deverá receber dados de Tm da UPC (principal ou redundante).·
Direção de comunicação da UTMC para TT&amp; C. A UTMC deverá possuir dois canais independentes de saída de TMs.
Esses requisitos do INPE resultaram num projeto VHDL da UTMC com sete domínios de clock:·
Duas entradas de dados de Tc, clocks independentes, de 4 kbps cada (CLTUs);·
Uma saída de Tc de 4 kbps duplicada para envio para os OBCs (TCRs);·
Duas entradas de dados de Tm, clocks independentes, de 650 kbps cada (Tm);·
Uma saída de Tm de 650 kbps, duplicada para envio para as duas TT&amp; Cs· Um clock global de 13 MHz usado em todos os componentes, e para geração dos clocks de transmissão de dados das seriais síncronas, garantindo as taxas de 4 kbps e 650 kbps.
Esses diferentes domínios de clock, resultaram numa maior complexidade na implementação do VHDL, ocasionando diversos problemas de instabilidade.
Inúmeras vezes os testes realizados em FPGA apresentaram respostas erradas, incluindo, até mesmo, o travamento completo do circuito do FPGA.
Muito tempo foi empregado para que se identificasse, isolasse e tratasse os sinais causadores dessas instabilidades.
Além disso, um estudo detalhado sobre técnicas diversas de implementação de circuitos para de módulos que já estavam devidamente protegidos, levando a alterações na implementação realizada para resolver o problema da metaestabilidade.
Registradores em dispositivos digitais, como os FPGAs, têm os requisitos mínimos de tempo bem definidos, de forma que cada registrador capture corretamente o dado de entrada e produza um sinal de saída.
Para garantir a correta funcionalidade, a entrada do registrador deve estar estável por um período mínimo de tempo antes que ocorra o evento de subida da borda do clock (denominado de tempo de setup) e por um período mínimo de tempo após esse evento (conhecido como tempo de hold).
Além disso, a saída do registrador somente está disponível para leitura após um determinado tempo t (clock-- tooutput delay).
Caso o sinal de entrada do registrador viole algum desses tempos (setup ou hold), a saída do registrador pode entrar em estado denominado de metaestável.
Em um estado assim, a saída do registrador oscila entre um valor alto e baixo durante um certo período de tempo, ou seja, a saída do registrador estará disponível após o tempo especificado por t..
A violação dos tempos de setup e hold ocorre se a transição do dado A ocorrer muito próxima à borda ativa do clock B. Entre as consequências da metaestabilidade podem ser citadas:·
a instabilidade presente no sinal pode alimentar diversas áreas do circuito, o que pode gerar um alto consumo de corrente;·
a ocorrência de diferentes leituras do sinal em partes distintas do circuito, levando o circuito para um estado desconhecido e imprevisto, e;·
O fato do tempo t de estabilização do sinal poder ser maior que o previsto, gerando um tempo maior de propagação do sinal e, por consequência, a geração de problemas de sincronismo em todo o circuito.
A solução do problema de metaestabilidade é alcançada através da inclusão de estruturas conhecidas como &quot;sincronizadores», ao longo de o domínio de clock de destino.
Os sincronizadores fornecem tempo suficiente para a oscilação do sinal de saída do registrador estabilizar, garantindo que o sinal de entrada obtido no domínio de destino esteja estável.
A Figura 30 ilustra um sincronizador utilizando dois registradores no domínio de destino.
Essa solução representa um uso maior de recursos do FPGA, porém apresenta a vantagem de resultar num circuito mais estável, reduzindo drasticamente os problemas enfrentados durante a etapa de testes e depuração.
O segundo flip-flop impede que a instabilidade venha a ser transmitida para o destino, e no segundo pulso de clock é garantido que o sinal a ser transmitido está estabilizado.
A Figura 31 mostra a solução adotada nos módulos da UTMC sujeitos a diferentes domínios de clock.
Esses módulos são aqueles descritos no início dessa seção, ou seja, os que possuem algum tipo de interface com os módulos de comunicação via serial síncrona.
Conforme apresentado na Figura 31, foram incluídos dois registradores em cada uma das entradas das FSMs dos módulos de comunicação.
Assim, na Figura 31 quando a FSM TX, sujeita a um domínio de clock, envia um sinal de controle para a FSM RX, sujeita a outro domínio de clock, a metaestabilidade é controlada por a FSM RX ao utilizar seu mesmo clock nos dois registradores de sincronização de entrada.
A utilização do sincronizador entre diferentes domínios de clock só deve ser feita aos sinais de controle entre os diferentes domínios.
Isso significa que caso seja necessário realizar a transferência de um barramento de dados entre os diferentes domínios, deve- se registrar somente os sinais de controle responsáveis por assinalar a disponibilidade do dado no domínio de destino.
Isso é possível já que se o sinal de controle já tiver sua saída estável devido a o atraso de tempo inserido por o sincronizador, o dado controlado também terá a saída estável, pois também sofreu o mesmo atraso no que diz respeito ao domínio de destino, conforme indicado por os módulos &quot;E «na Figura 31 O reset, a exemplo do exposto na seção anterior, também pode levar o sistema a um estado de metaestabilidade.
De essa forma, se faz necessário algum tipo de sincronismo entre o reset e o clock utilizado em cada componente, de forma a garantir que todo o sistema possua um estado inicial bem definido.
A temporização apropriada do sinal de reset em todos os flip-flops é alcançada ao sincronizar esse sinal com o sinal de clock usado nos flip-flops.
Porém, com um clock global de 13 MHz e com os demais clocks dos módulos de comunicação serial funcionando a velocidades bastante inferiores, essas diferenças podem levar a situações onde os módulos mais lentos poderão permanecer por um período considerável com valores indeterminados em seus registradores.
Uma solução para esse problema é a utilização de resets assíncronos.
O inconveniente dessa estratégia está no momento em que o reset é removido assincronamente.
Em esse instante poderão ocorrer violações dos tempos de setup ou hold, devido a a remoção do reset num momento muito próximo de uma borda de clock, levando o sistema a uma possível metaestabilidade.
A utilização de resets assíncronos requer a aplicação de técnicas especificas a fim de evitar problemas de metaestabilidade.
O grande problema com resets assíncronos consiste na remoção do reset.
A o retirar o sistema do estado de reset de forma assíncrona, o circuito pode entrar em estado metaestável.
A remoção do reset pode gerar dois problemas:·
violação do tempo de setup ou hold, devido a ocorrência muito próxima a uma borda de clock, e;·
a remoção do reset pode acontecer em ciclos de clock diferentes para elementos sequenciais, devido a o tempo de propagação do sinal de reset para alguns registradores.
De essa forma, ao se utilizar resets assíncronos é importante sincronizar o evento de remoção do reset com o clock do sistema.
A Figura 32.
Apresenta a solução utilizada no sistema de reset da UTMC.
A ativação do reset acontece assincronamente, embora sua remoção aconteça de forma síncrona através da inserção de dois flip-flops que funcionam como sincronizadores.
São necessários, então, dois flip-flops para que se possa remover qualquer metaestabilidade gerada por a remoção assíncrona do reset.
Essa abordagem permite a implementação assíncrona do reset em todo o sistema, sem gerar os problemas que uma implementação sem o circuito sincronizador teria.
O VHDL da UTMC foi implementado seguindo essa abordagem que, por sua vez, também é sugerida por a ESA Inferência de memória A o se utilizar uma ferramenta de síntese existem, basicamente, duas formas de usar a RAM interna de um FPGA, por meio de &quot;inferência «ou &quot;instanciação».
A o confiar na habilidade de uma ferramenta de síntese para inferência de RAM automaticamente a partir de o fonte VHDL, a princípio, o projetista ganha em portabilidade e independência quanto a ferramenta de síntese utilizada.
Por outro lado, ao se utilizar instâncias de núcleos de propriedade intelectual num projeto, obtém- se uma utilização mais eficiente dos recursos de memória RAM do FPGA em questão, além de um maior controle sobre os detalhes de funcionamento da memória utilizada.
Porém, perde- se em portabilidade uma vez que um determinado IP core pode ter sido desenvolvido para um determinado dispositivo de uma determinada família de FPGAs e, ao se migrar o projeto para outra tecnologia será necessário a utilização de outro IP core.
O fluxo de Tc da UTMC foi inicialmente desenvolvido e prototipado num FPGA Virtex II Para o da Xilinx, e o código VHDL foi escrito visando portabilidade e de forma a utilizar as facilidades de inferência de memória das ferramentas de síntese.
A ferramenta de síntese utilizada, Synplify v. 9.4A1 da Synplicity, inferiu corretamente os blocos de memória RAM para o FPGA da Xilinx.
Porém, ao migrar o código VHDL para o FPGA da Actel, requisito de projeto do INPE, a ferramenta Synplify não inferiu corretamente a memória RAM.
A ferramenta gerou otimizações de forma diferente do que havia ocorrido na síntese para o FPGA da Xilinx, resultando em problemas para acesso aos sinais de entrada/ saída da memória RAM gerada.
Para os recursos de RAM disponíveis no FPGA ProASIC3e da Actel a ferramenta de síntese inferia sempre blocos de RAM de 512x18 bits, deixando alguns sinais de entrada e saída inativos.
Chegou- se a conclusão que seria necessário alterar o controlador de memória de forma que a memória inferida por o Synplify fosse acessada corretamente, ou que o Synplify inferisse a RAM utilizando o outro tipo de bloco de RAM disponível no ProASIC3e.
De essa forma, a principal vantagem da inferência automática de RAM deixou de existir, pois passou a ser necessário alterar o fonte VHDL de acordo com as exigências da tecnologia alvo e da ferramenta de síntese usada.
Por essa razão, e por a falta de controlabilidade sobre a RAM inferida por o Synplify, optou- se no projeto da UTMC por instanciar um IP core da Actel para implementação da memória RAM.
Esse componente da UTMC passou a ser dependente da tecnologia alvo, porém com melhor desempenho e maior controlabilidade e usabilidade.
Além disso, IP cores de memória são facilmente encontrados para as diversas tecnologias de FPGAs disponíveis.
Depuração do código Para validar o funcionamento da UTMC em hardware, utilizou- se um software desenvolvido em LabView para realizar o envio e captura dos dados de entrada e saída da UTMC.
Por se tratar de um software não validado, não foi possível garantir que determinado problema encontrado na UTMC tinha sua origem no projeto VHDL.
Ambos os projetos, UTMC em VHDL e software do LabView, foram validados simultaneamente, um em relação a o outro, o que representou um tempo demasiado do desenvolvimento, dificultando o diagnóstico e análise de eventuais problemas (bugs) na UTMC.
Ainda, durante a fase de testes da UTMC, o fato do hardware onde a UTMC estava inserida não ter sido validado também pode ser considerado um empecilho.
Em diversos momentos ao longo de a implementação do projeto, falhas de hardware foram encontradas, acrescentando ainda mais problemas e aumentando ainda mais o já restrito tempo de desenvolvimento.
Simulação e Síntese Em essa seção são apresentados resultados obtidos a partir de atividades de simulação e síntese do código VHDL da UTMC.
As simulações foram realizadas com a ferramenta ModelSim e a síntese com a ferramenta Synplify, ambas instaladas como parte do ambiente de desenvolvimento Libero v 8.4 da Actel.
Em a Figura 33 é apresentado o diagrama de formas de onda do fluxo de processamento de um TCD.
Inicialmente, as CLTUs são recebidas via serial síncrona e armazenadas num buffer, formando os codeblocks conforme pode ser observar no sinal data_ o da Figura 33.
A seguir, a partir de os codeblocks recebidos, a camada de transferência monta um frame de transferência e armazena na memória interna do FPGA, conforme pode ser observado nos sinais mem_ data_ i e mem_ addr_ o.
Em a camada de empacotamento, o pacote é extraído do frame de transferência utilizando- se as informações contidas nos sinais pac_ id_ o (número do canal virtual do frame), pac_ size_ o (tamanho do pacote) e pac_ addr_ o (endereço de início do frame na memória.
O cabeçalho do pacote é extraído e o pacote enviado para a CPDU (TCD) ou para o OBC (TCR).
O sinal ack_ o poderá então indicar que o TCD está correto gerando um ACK, ou que ocorreu um problema.
Em esse caso uma informação de erro é concatenada ao cabeçalho e o ack_ o indica um NACK.
Finalmente, se foi gerado um ACK, o sinal instruments_ o informa aos instrumentos qual pulso deve ser acionado, permanecendo ativo por 13 ms..
O diagrama de forma de onda apresentado na Figura 33 representam fielmente o funcionamento das FSMs para o fluxo de Tc, descrito no Capítulo 4.
De essa forma, não se faz necessário incluir nesse documento os diagramas de todas as simulações realizadas.
Após verificada a correta funcionalidade dos fluxos de Tc e Tm na etapa inicial de simulação, o código é sintetizado com a ferramenta Synplify.
Essa primeira etapa de síntese visa realizar uma análise da temporização do circuito gerado.
A síntese é executada e uma nova simulação é realizada considerando a funcionalidade do circuito juntamente com restrições temporais.
Em essa segunda etapa de simulação é verificado se a implementação a nível de portas lógicas atende os requisitos temporais estabelecidos para o projeto.
A o analisar o relatório gerado por a ferramenta de síntese é possível verificar se o tempo desejado menos o tempo obtido (slack $= required time ­ arrival time) foi alcançado.
Se essa diferença (slack) não foi alcançada, então é necessário alterar o código VHDL de forma a melhorar a temporização.
Em a Tabela 3 -- Relatório de temporização para versão sem codificação da UTMC é apresentado o relatório de temporização gerado por a ferramenta de síntese para a versão sem codificação. Conforme
pode- se observar nessa tabela, a ferramenta inferiu corretamente os sete domínios de clock discutidos anteriormente, e alcançou todos as restrições temporais impostas.
Notar também na Tabela 3 as restrições de clock listadas na coluna &quot;Requested Frequency», e os resultados alcançados na coluna &quot;Estimated Frequency».
A coluna &quot;Slack «mostra resultados positivos em todas as linhas (todos os domínios de clock), confirmando que a diferença entre os tempos de chegada desejado e o obtido foi alcançada.
Total path delay (propagation time+ setup) of 11.939 is 5.921 (49.6%) logic and 6.018 (50.4%) route.
Onde: System Outra informação importante obtida a partir de a síntese diz respeito à área do FPGA ocupada em termos de elementos programáveis (ou configuráveis).
Os FPGAs ProAsic3e da Actel possuem cinco tipos de elementos programáveis:
&quot;Versa Tiles&quot;;
FlashROM; SRAM/ FIFO;
PLLs; E I/O. Esses elementos compõem, de acordo com a nomenclatura da Actel, o equivale a cerca de 1.500.000 de &quot;system gates».
Os &quot;Versa Tiles «são os elementos centrais para realização de funções lógicas nos FPGAs flash da Actel.
Esses elementos podem ser configurados de forma a implementar look-up tables (LUTs) de três entradas, latch com clear ou set, flip-flop D com clear ou set, ou flip-flop D com enable, clear ou set.
Em o FPGA ProAsic3e utilizado na implementação da UTMC existem disponíveis 38.400 &quot;Versa Tiles».
O ProASIC 3e da Actel possui 60 blocos de memória RAM, e diversas possibilidades de configurações, porém nas bibliotecas estão disponíveis apenas as macros RAM4 K9 bits e a RAM512 x18 bits.
A capacidade máxima de armazenamento da memória disponível é de 276.480 bits, ao se considerar uma configuração onde cada bloco possui 256 posições de 18 bits cada posição.
A listagem a seguir foi extraída do mesmo relatório de síntese utilizado na discussão sobre temporização da Tabela 3, porém considerando a ocupação de área do FPGA por os recursos configuráveis brevemente introduzidos.
Assim, a síntese da versão da UTMC sem codificação, resultou numa ocupação de 36% dos &quot;Versa Tiles «disponíveis, ou seja, 13.992 de um total de 38.400.
Notar que para efeito de &quot;Versa Tiles», foram removidos todos os elementos com uma contagem inferior a 200 unidades, porém mantendo- se todos os flip-flops gerados.
Notar a forte utilização de portas NOR e OR por parte de a ferramenta de síntese.
A opção por instanciar o IP core de memória resultou numa ocupação total de 18 blocos de RAM, representando 30% do total disponível no dispositivo.
Os resultados de síntese são listados apenas para ilustrar a taxa de ocupação do FPGA utilizado e a temporização obtida.
Não foi realizado um estudo comparativo com outras tecnologias e fabricantes, uma vez que no momento não existe um interesse por parte de o usuário final (INPE) na utilização da UTMC em outros dispositivos.
Por fim, o Anexo A deste trabalho apresenta a plataforma em a qual foi desenvolvida a UTMC principal e redundante.
Em o presente trabalho foi realizado um estudo sobre os aspectos de confiabilidade do protótipo da Unidade de Telemetria e Telecomando (UTMC) desenvolvido para o INPE.
Esse projeto foi concebido ao nível de pesquisa universitária sendo os resultados iniciais entregues ao INPE, que contratou duas empresas para realizar o acabamento do produto.
A entrega do produto foi realizada em Agosto de 2009, porém algumas questões relacionadas à confiabilidade do sistema ficaram sem respostas.
O estudo realizado durante o curso de mestrado determinou não apenas as técnicas de confiabilidade mais adequadas para responder às questões do INPE, mas também alternativas de implementação.
A pesquisa partiu da investigação e proposta de um sistema baseado na abordagem TMR tradicional, que comprovadamente garante a recuperação automática do sistema na ocorrência de falhas resultantes dos efeitos da radiação espacial.
Apesar de eficiente para cobertura das falhas consideradas, a abordagem TMR resulta numa taxa excessiva de ocupação dos FPGAs.
Outro problema do TMR diz respeito ao consumo de energia devido a a triplicação de todo o hardware envolvido.
Além disso, o TMR proposto inicialmente para atender aos requisitos de confiabilidade definidos para o projeto, apresentou uma complexidade considerável, uma vez que a triplicação foi realizada a nível de componentes do sistema (ex..
Contadores, registradores), e não a nível de módulos completos de telemetria e telecomando.
Considerando- se os ótimos resultados a nível de confiabilidade, e os resultados desfavoráveis ao nível de ocupação de área, complexidade do circuito e consumo de energia, os estudos foram direcionados para busca por melhoria nesses últimos sem perda nos níveis de confiabilidade desejados.
Essa tarefa foi dificultada, entre outros, devido a característica assíncrona do circuito da UTMC.
Considerando- se os diversos domínios de clock existentes, foi necessário realizar um projeto cuidadoso de forma a garantir o sincronismo entre os diversos domínios de clock, não apenas ao nível de sinal de relógio, mas também ao nível de sinais de reset.
Concluída a definição das estratégias para sincronismo dos diversos domínios de clock e sinais de reset, foi realizada uma análise dos pontos críticos de falhas considerando os circuitos combinacionais e seqüenciais da UTMC.
A partir de essa análise foi possível determinar se as técnicas de tolerância a falhas propostas são adequadas, ou se poderão vir a representar novos pontos de falhas.
Foi então definida uma solução simplificada para introduzir tolerância a falhas no projeto, com índices aceitáveis de confiabilidade, baixa complexidade de implementação, e redução considerável na área ocupada e consumo de energia ao se comparar com a abordagem TMR inicial.
Além disso, as implementações de ambas técnicas propostas possuem capacidade para sinalização de erro na UTMC.
Essa foi uma das questões levantadas por engenheiros espaciais do INPE, que sentiram a necessidade do chaveamento automático da UTMC principal para a redundante em caso de falha, porém no projeto entregue não existia essa capacidade de identificação de erro.
Um trabalho futuro consiste em realizar a implementação da técnica nas camadas de codificação, no lugar da replicação completa do fluxo de Tc e Tm.
Além disso, será necessária a realização de testes exaustivos por intermédio de injeção de falhas.
