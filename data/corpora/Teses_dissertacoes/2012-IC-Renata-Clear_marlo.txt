O ambiente competitivo se tornou, nas ultimas décadas, mais dinâmico graças às tecnologias de informação e comunicação e à globalização.
O gestor, assim, precisa estar sempre bem informado sobre o panorama competitivo antes de tomar decisões estratégicas.
Em essa direção, a Inteligência Competitiva (IC) surge como uma disciplina que pretende sistematizar a obtenção e análise de informações do ambiente competitivo com função de auxiliar a tomada de decisão.
Há entretanto uma quantidade crescente de informação sendo produzida e disponibilizada em meios como a Internet e mídias tradicionais, as quais se tornam de difícil manejo.
Associado a isso, os gestores sofrem ainda com restrições temporais para responder ao estímulo do mercado e manteremse competitivos.
De essa forma, é necessário manter uma equipe de monitoramento constante do ambiente competitivo para que se possa lidar com a quantidade de informação proveniente de diversas fontes.
Acreditamos que a aplicação de técnicas de Análise de Texto podem auxiliar nas diversas fases do processo de IC.
O presente trabalho apresenta uma proposta de utilização de tais técnicas para auxiliar o processo de Inteligência Competitiva.
Discutimos aqui a utilização de um método de Análise de Sentimentos aliado ao Reconhecimento de Entidades Nomeadas em textos provenientes de mídias sociais -- particularmente o Twitter -- que permitam analisar as atitudes do mercado consumidor quanto a uma determinada marca.
São apresentados ainda o sistema desenvolvido, as avaliações realizadas e as conclusões que tiramos.
Palavras-chave: Análise de Sentimentos;
Entidades Nomeadas; Twitter;
Língua Portuguesa. Marcas, Branding e WOM Twitter Em este capítulo apresentamos a motivação, o contexto, o objetivo e a organização deste trabalho.
Motivação e Contexto do Trabalho Levy argumenta que, após a Segunda Guerra Mundial, a informação e o conhecimento tornaram- se a principal fonte de produção de riquezas, tornando- se os bens econômicos primordiais.
Em esse contexto, na sociedade em rede, pode- se entender a atividade econômica como um processo de Inteligência Coletiva, onde mesmo o consumo é atividade produtora, construindo informação.
Aquele autor, em, estabelece como uma característica fundamental da Inteligência Coletiva a passagem de uma mídia de massa em a qual poucos têm a capacidade de produzir informação, enquanto muitos atuam como meros consumidores, para um paradigma em que todos participam consumindo e produzindo informação.
A interconexão em rede potencializa a troca incessante e bilateral de informações, transformando o receptor passivo em produtor de conteúdo, caracterizando a criação dos new media (novas mídias, em português), em contraste ao mass media (mídias de massa, ou mídias massivas em português).
A esse novo tipo de mídia, em que muitos produzem para muitos, chama- se Mídia Social.
As mídias sociais apresentam- se de várias formas:
Listas de discussão, blogosfera, sites de redes sociais, entre outros.
Dourado considera que as mídias sociais representam uma transformação na mediação da informação ao eliminar o papel do intermediário no esquema comunicacional das empresas com seus clientes.
A comunicação direta com os clientes permite saber o perfil de seu consumidor, assim como ter acesso à sua opinião a fim de oferecer os produtos e serviços por eles demandados.
Diante de mercados extremamente dinâmicos e complexos, devido a o desenvolvimento tecnológico e a globalização, tomar decisões estratégicas numa empresa tornou- se uma atividade cercada de incertezas.
Para garantir que uma decisão seja a mais apropriada, dado o panorama competitivo, o gestor deve estar muito bem informado sobre o ambiente interno e externo da companhia.
De fato, Porter defende que, para definir a estratégia competitiva da empresa, um ponto fundamental é a análise detalhada do ambiente competitivo em que a empresa se situa.
Para formalizar as práticas de monitoramento e análise do ambiente competitivo surge a disciplina da Inteligência Competitiva.
Dada esta necessidade de se analisar o ambiente competitivo, a fim de se tomar decisões estratégicas e operacionais, e a centralidade do papel da marca entre os ativos da empresa para se alcançar uma vantagem competitiva sustentável, o monitoramento de marcas é uma importante tarefa a ser realizada dentro desse processo.
A informação disponível nas diversas mídias é então de extrema importância para uma organização situar- se no panorama competitivo.
Toda essa informação produzida e disponibilizada em meios como a Internet e mídias tradicionais são, entretanto, de difícil manejo.
A especial dificuldade de tratar- las deriva do fato que as mesmas se encontram em formas não estruturadas ou semi-estruturadas, como em texto e páginas de Internet.
Uma vez que a quantidade de informação disponível sobre o mercado cresceu sobremaneira por os novos recursos de indexação e distribuição de informações, é necessário utilizar- se técnicas de acesso e manipulação desses dados e informações, a fim de se poder analisar- los de forma consistente.
Devido a a natureza não estruturada dos dados, o tratamento computacional desses é de difícil realização.
Em esse contexto, o papel das tecnologias de informação e, em particular, da Análise de Texto (do inglês Text Analytics), área que procura extrair informação a partir de coleções textuais, são de fundamental importância para auxiliar tal processo.
Nossa convicção é que a aplicação de técnicas de Análise de Texto pode auxiliar o processo de Inteligência Competitiva.
Acreditamos que utilizando a Análise de Sentimentos -- o processo de identificar (ou extrair) emoções, opiniões ou pontos de vista automaticamente -- podemos auxiliar o processo de monitoramento da marca, ao se minerar as Mídias Sociais -- em especial ao Twitter, desde que tal análise seja feita num nível adequado.
Esse monitoramento já é, de fato, realizado em diversas empresas, entretanto é ainda feito de forma manual ou semi-automatizada.
Não encontramos uma ferramenta que realize a tarefa pretendida numa profundidade que consideramos adequada para a análise, i.
e a identificação de opinião a um nível de entidade.
Propomos com esse trabalho não somente identificar uma opinião expressa em texto, mas também relacionar- la com a entidade à qual ela se direciona.
Escolhemos tal nível de análise devido a a centralidade do papel da marca no panorama competitivo a ser analisado e da precariedade das ferramentas atualmente disponíveis para identificar a correta referência de uma opinião.
A marca representa, como Aaker salienta, o principal ativo da empresa e precisa de grande manutenção.
Posta essa necessidade, acreditamos que a correta identificação da referência de uma opinião tem particular importância nesse panorama, uma vez que expõe diretamente a atitude do consumidor quanto a a marca da corporação -- ou de suas concorrentes.
Objetivo do Trabalho Aplicar um método de análise de sentimentos focado em entidades para monitoramento de marcas ao minerar uma base de textos de uma mídia social -- o Twitter -- e avaliar- lo a partir de a implementação de um sistema para a língua portuguesa.
Organização da Dissertação O restante do trabalho está organizado como segue:
Em o Capítulo 2, a fundamentação teórica é apresentada;
Em o Capítulo 3, discutimos os trabalhos relacionados ao nosso e as semelhanças e diferenças entre eles.
Em o Capítulo 4, apresentamos nossa estratégia para a resolução do problema, no Capítulo 5 são apresentados os resultados obtidos e, por fim, no Capítulo 6 apresentamos nossas considerações finais.
Dada a importância do tema e apesentada a motivação do nosso trabalho, passamos então a apresentar a base teórica que utilizamos para entender (e atacar) o problema proposto.
Em este capítulo, então, introduzimos a fundamentação teórica do nosso trabalho explicitando os principais conceitos e técnicas utilizadas posteriormente.
Inteligência Competitiva e monitoramento de marcas em Mídias Sociais A Inteligência Competitiva (IC) é definida em como o processo de monitorar o ambiente competitivo.
Ela permite a profissionais tomarem decisões embasadas em informações atualizadas do ambiente externo e interno da organização.
Para Oliveira, o objetivo da IC é prover informações estratégicas para reduzir a incerteza associada a uma decisão.
Gomes e Braga a definem como a permanente avaliação do ambiente competitivo e dos recursos de que se dispõe.
Para esses autores, os objetivos da IC são antecipar mudanças ambientais, descobrir potenciais novos concorrentes, antecipar ações da concorrência e auxiliar aquisições e fusões.
Fuld, por sua vez, define a inteligência competitiva como informação analisada que fornece insights e vantagem.
Pode- se então definir a Inteligência Competitiva como uma estratégia de monitorar o ambiente competitivo de uma determinada organização com finalidade de auxiliar a tomada de decisão estratégica ou tática.
Ela tentar formalizar o processo de aquisição, análise e disseminação do conhecimento sobre o mercado em que a organização está inserida, possibilitando, aos gestores, a tomada de decisão informada.
O processo de inteligência é um processo sistemático e formalizado de se obter informações e analisar- las para gerar inteligência competitiva.
Gomes e Braga estabelecem um modelo de Inteligência Competitiva com cinco passos, baseando- se no modelo tradicional de IC de Herring:·
Identificação das necessidades de informação:
Etapa em que se definem as necessidades ou requisitos de informação necessários, assim como as questões estratégicas que devem ser respondidas;·
Coleta das informações:
Fase em que se identificam e classificam as fontes de informação e se realiza a coleta, propriamente dita.
Cada fonte de informação é classificada em relação a a natureza, à origem e, principalmente, à confiabilidade;·
Análise das informações:
Etapa em que &quot;o analista transforma as informações coletadas em avaliação significativa, completa e confiável».
O objetivo da análise é responder às questões estratégicas levantadas na primeira fase do processo de inteligência;·
Disseminação: Envolve a entrega dos resultados da análise aos tomadores de decisão;·
Avaliação: Fase de auto-análise do processo de inteligência, em a qual se reflete sobre as fases realizadas e seu andamento, assim como sobre a usabilidade dos resultados para a organização.
Este trabalho propõe a aplicação de técnicas de Processamento de Linguagem Natural (PLN) para a fase de análise, com foco em identificação de opinião para entidades nomeadas.
Dito isso, deixamos claro que o planejamento e coleta devem ter sido realizados e, portanto, sabe- se o que analisar e possui- se os dados para tal análise.
Em a fase de análise, os dados e informações serão organizados, estruturados e analisados para permitir a geração de insights competitivos e relações entre os dados até então não conhecidas, que ajudarão posteriormente no processo de tomada de decisão.
Mídias sociais são as formas de nova mídia caracterizadas por o Socialcast, i.
e o paradigma em que muitos transmitem informação para muitos, em oposição às mídias tradicionais, ou de massa, em que um transmite para muitos.
Kaplan e Haenlein as definem como &quot;um grupo de aplicações baseadas na Internet construídas sobre as fundações ideológicas e técnicas da Web 2.0, que permite a criação e troca de conteúdo gerado por o usuário «(tradução nossa).
Essa característica das mídias sociais -- a saber, o conteúdo ser produzido por os usuários -- é justamente o que permite explorar essas novas mídias e configurar um novo espaço de comunicação para uma empresa ou organização, não mais centrada em falar para seu mercado, mas numa interação dialógica, onde se pode escutar diretamente esse mercado.
Isso as torna um instrumento potencializador de Inteligência Coletiva pois permitem a interação social dos indivíduos em rede, trocando informação de forma dialógica e instantânea, não limitados por as restrições geográficas.
Elas apresentam- se de várias formas:
Listas de discussão, blogosfera, sites de redes de sociais, entre outros.
Dourado considera que as mídias sociais representam uma transformação na mediação da informação ao eliminar o papel do intermediário no esquema comunicacional das empresas com seus clientes.
A comunicação direta com os clientes permite saber o perfil de seu consumidor, assim como ter acesso à sua opinião a fim de oferecer os produtos e serviços por eles demandados.
Em esse trabalho a autora discute novos modelos de negócio focando os Social Media.
Para Kaplan e Haenlein, a entrada nesse espaço por parte de as empresas envolve novas formas de pensar, mas possui grande eficiência a um baixo custo para o contato com o usuário final, sendo assim importante para empresas grandes e pequenas.
Os autores dão um conjunto de conselhos para as empresas que desejem utilizar mídias sociais.
Para Pompéia, a inserção de uma marca nas mídias sociais não está sob o controle da organização a qual pertence, mas, antes, depende de seus clientes.
A autora argumenta que na política do Socialcasting, que caracteriza as mídias sociais, é importante para as empresas procurar relacionamento, interação com seus clientes, não audiência.
Fica clara a necessidade de planejamento e de análise da imagem da empresa e da marca para criar seu plano de comunicação.
É patente o locus privilegiado que as mídias sociais têm na vida das pessoas, em particular no contexto brasileiro, onde informações que tornam- se populares nesse tipo de mídia chegaram a migrar para as ditas mídias tradicionais4.
Por esse motivo entender o comportamento dos usuários dessas mídias, i.
e entender o próprio funcionamento da mídia e como ela é significada por os usuários, é um importante passo para uma organização poder inserir- se na mesma.
Em esse contexto, os estudos sobre a adoção de diversas mídias sociais no contexto do usuário brasileiro tornam- se de especial importância e são tratados a seguir.
Em diferentes estudos, o comportamento do usuário brasileiro foi mapeado em diferentes plataformas da Internet, como a blogosfera, Orkut5 e Twitter6.
Uma importante descoberta desses estudos diz respeito à apropriação que o usuário brasileiro faz dessas ferramentas na manutenção da sua rede social e construção do que os autores chamam de capital social -- o capital associado ao pertencimento de uma coletividade.
É de se notar que as plataformas sociais na Web possuem características distintas e formas de apropriação distintas.
Algumas possuem um perfil mais informacional, no sentido que os usuários se apropriam desta ferramenta no intuito de produzir e transmitir informação aos outros, enquanto outras possuem um perfil mais relacional, onde o foco do usuário é estabelecer relações entre si.
Ferramentas como o Orkut, por exemplo, possuem um perfil mais relacional, onde os usuários procuram adquirir capital social relacional e cognitivo, ou seja capital social relacionado às ligações sociais da rede.
Tais características no perfil de interação de uma determinada rede são importantes pois auxiliam a decidir qual tipo de inserção uma determinada organização deve ter na mesma e quais informações podem ser mineradas para conseguir vantagem competitiva.
Uma mídia altamente informacional, com bastante ligações fracas, pode ser utilizada para conseguir informação sobre o perfil ou a satisfação dos clientes, por exemplo.
O Twitter é uma ferramenta de microblog lançada no final de 2006 em a qual os usuários publicam mensagens com tamanho limitado de até 140 caracteres.
A importância do Twitter se dá por o seu crescimento mundial nos últimos anos atingindo a marca de mais de 200.000.000 usuários em 2011 4 Exemplo é o caso da estudante Luiza Rabello (a Luiza que estava no Canadá), entre outros, que tornou- se sucesso em mídias como o Twitter e o Youtube e a mesma tornou- se uma espécie de celebridade instantânea, participando de com cerca de 150.000.000 atualizações diárias7.
Os usuários nessa rede constroem ligações unilaterais com outros (que podem ou não ser retribuídas) -- às quais se chama 'seguir'.
Tais ligações são importantes pois uma vez construídas, aquele que &quot;segue «passa a receber as mensagens publicadas por aquele &quot;seguido».
Ou seja, construir ligações, i.
e &quot;seguir usuários», aumentam a quantidade de informação na sua rede social.
A uma mensagem do Twitter chamamos &quot;tweet «(do inglês, significando chilrear).
Um tweet pode conter diversos símbolos importantes no contexto da rede que conotam os sentimentos ou atitudes do usuário, suas relações com os outros usuários da ferramenta ou meta-informação associada a esse tweet.
Um exemplo desses símbolos, importante para o nosso estudo, é o emoticon.
Um emoticon é uma representação gráfica de uma emoção através de caracteres (como um sorriso:) &quot;conotando felicidade, ou:( «conotando tristeza).
Outros importantes exemplos são as hashtags -- palavras iniciadas por'&amp;' -- que provêm meta-informação sobre o tweet.
Um tweet pode ser direcionado a um usuário ou mencionar- lo utilizando seu nome da rede (chamado de Twitter name ou username e iniciado por o caractere@), o qual o usuário receberá em na página de seu perfil na ferramenta.
De acordo com, numa avaliação manual do conteúdo dos tweets -- uma atualização de status do usuário --, o usuário brasileiro apropria- se da ferramenta muito mais para transmitir informação que engajar em conversas -- cerca de 62% dos tweets possuem conteúdo informacional contra cerca de 48% conversacional, com 10% dos textos possuindo ambos os perfis, i.
e informacional e conversacional.
De os textos com perfil informacional, cerca de 25% possuem conteúdo opinativo, i.
e em o qual o usuário explicita uma opinião ou sentimento.
Caracterizando assim o Twitter como uma mídia de cunho mais informacional.
Dada importância e o crescimento do Twitter entre os sites de redes sociais e o alto índice de informação opinativa que é publicada no mesmo, acreditamos que o Twitter fornece um interessante objeto de estudo, enquanto fonte de dados para os métodos propostos nesse trabalho.
Adicionalmente, os textos provenientes de mídias com limitação de caracteres, como o Twitter, possuem características únicas -- como um estilo de escrita muito informal e com muitas abreviações- que foram ainda pouco exploradas, principalmente na língua portuguesa.
De o ponto de vista prático, a adoção do Twitter como objeto de estudo se deu também pois, atualmente, muitas empresas passaram a utilizar essa ferramenta como um meio oficial de interação com seus clientes e de análise de seu mercado consumidor -- e do seu posicionamento estratégico.
Acreditamos, assim, que as soluções propostas nesse trabalho vêm para auxiliar esse novo ator dentro de o processo de inteligência da empresa -- o analista de redes sociais -- a minerar uma quantidade cada vez maior e de mais difícil manejo.
Para Aaker, uma marca é um nome ou símbolo que identifica os bens ou serviços de um vendedor e o distingue dos seus concorrentes, tendo papel de sinalizar a origem do produto e, portanto, sua qualidade.
O autor argumenta que no marketing moderno a criação e, principalmente, a diferenciação da marca têm sido pontos principais.
Isso se dá pois a diferenciação da marca é um importante ativo da empresa que identifica qualidade ou atribui valor simbólico ao produto ou serviço, propiciando assim uma diferenciação vertical à empresa, i.
e uma vantagem competitiva sustentável.
Assim como os ativos tangíveis da empresa, entretanto, uma marca deve também ser gerenciada e passar por manutenção, para evitar que as associações feitas à ela não se deteriorem.
Um ponto importante para medir a lealdade do mercado consumidor à marca é a satisfação e insatisfação quanto a o produto/ serviço e do sentimento associado à marca.
Em esse contexto, o conceito de word-of-- mouth (WOM) -- que pode ser entendido como &quot;marketing boca-a-boca em Português, definido como «comunicação interpessoal entre consumidores a respeito de uma organização ou produto &quot;ou ainda «mensagem sobre uma organização ou produtos/ serviços de ela transmitido de pessoa a pessoa -- encaixa- se como o tipo de informação que procuramos para analisar a opinião do mercado quanto a uma marca.
Richins Consideram que o WON negativo pode ter sérias consequências para uma empresa e que esse tipo de propaganda pode ter mais efeito que uma campanha de marketing tradicional.
Charlett Argumentam que o WOM é virtualmente invisível para as organizações, pois as taxas de reclamação recebidas por a empresa não representam a quantidade de insatisfações dos consumidores, uma vez que menos de um terço do consumidor comum reclama diretamente à empresa.
Jansen Discutem a importância de WOM na internet e analisam a utilização do Twitter como fonte de WOM eletrônico.
Essas fontes são importantes pois podem exploradas por a organização para descobrir a opinião do mercado quanto a seu produto ou serviço e o sentimento associado à sua marca.
Uma empresa que detecte uma insatisfação pode assim agir para aumentar a confiança na marca e a satisfação associada a ela.
As mídias sociais são ambientes naturais, nesse contexto, para uma organização buscar a satisfação de seus consumidores.
De fato, é isso que Pompéia defende ao declarar que a empresa deve escutar os consumidores dentro de as mídias sociais.
Note, porém que essa é uma tarefa difícil se considerarmos a quantidade de meios a se procurar e o volume de dados a se analisar diariamente.
Acreditamos que a aplicação da Análise de Texto pode auxiliar esse processo nas empresas, diminuindo a quantidade de análise necessária e o tempo despendido em ela.
De fato, Jansen Exploram a utilização da técnica de Análise de Sentimentos no Twitter para detecção de WOM.
Análise de Sentimentos ou Mineração de Opinião A Análise de Sentimentos ou Mineração de Opinião, que está inserida no tópico de análise de subjetividade, corresponde ao problema de identificar (ou extrair) emoções, opiniões ou pontos de vista em textos e vem recebendo bastante atenção nos últimos anos devido a a potencial aplicabilidade de tais métodos, de acordo com Wilson, Akkaya, Liu entre outros.
Alguns teóricos identificam a atividade de análise de sentimentos com o que pode ser chamado de classificação de sentimentos, ou classificação de polaridade dos sentimentos (positivo, negativo, neutro, etc.), como exposto na definição de Liu.
Entretanto, os estudos de análise de sentimentos não se resumem à classificação de sentimentos.
Exemplos de trabalhos que transpõem a classificação são os de detecção de subjetividade, ou seja se uma determinada parte de um texto ou discurso possui conteúdo opinativo, como o trabalho de Pang e Lee;
Identificação de intensidade de emoções e flames 8, como Wilson;
O problema de análise de sentimentos diferencia- se da classificação de tópicos e mostra- se difícil de tratar com as técnicas clássicas para essa área, utilizando técnicas como bag-of-- words somente, como exposto em.
Diversos sistemas propostos utilizam somente informação lexical, como, ou podem utilizar informações como a morfológica, como, ou ainda sintática, e.
g As soluções de análise de sentimentos foram aplicadas, na literatura, a diversos problemas:
Desde mineração de opiniões sobre um determinado produto em blogs e fóruns;
Análise automática de resenhas de filmes em sítios como IMbB9;
De resenhas de produtos em sítios como o Amazon10;
Até auxílio a Sistemas de respostas a perguntas e extração de informação.
A noção de sentimento ou opinião trabalhada por a Análise de Sentimentos é diversa e tem ligação com a terminologia utilizada por os pesquisadores para delimitar a área.
Para Wiebe e seu grupo, a análise de sentimentos lida com a detecção dos estados privados, ou estados internos que não podem ser observados por outros.
O conceito de sentimento para esses autores está então associado à noção de estado privado, ou de estado interno do autor, de acordo com a definição de Banfield.
Roman apresenta diversas definições para sentimentos e emoções, com origem nos campos da psicologia e neurobiologia para sentimentos.
Em elas pode- se distinguir emoções de sentimentos, sendo as segundas as justaposições das alterações no estado corpóreo justaposto à imagem mental 8 &quot;Mensagens «&quot;inflamadas «com conteúdo ofensivo.
Liu, por outro lado, define uma opinião consistindo de uma atitude -- expressa através de um determinado termo polarizado -- associada a um aspecto -- ou atributo -- de uma entidade por um indivíduo.
Uma opinião é então, por natureza, relacional, pessoal e explícita.
O autor lança mão do conceito de emoção como &quot;sentimentos e pensamentos subjetivos «11 para embasar sua noção relacional de opinião.
De entre as opiniões, para Liu, distinguem- se dois tipos:
As diretas e as comparativas.
As diretas associam diretamente uma emoção ou atitude a um atributo de uma entidade;
As comparativas, por outro lado, &quot;expressam uma relação de similaridades e diferenças entre dois ou mais objetos e as preferências do autor».
Outra importante distinção que este autor faz é de opinião explícita e implícita.
A primeira envolve a expressão de uma opinião através de uma sentença subjetiva, i.
e através da expressão de emoções.
A segunda, por sua vez, envolve a emoção implicada por uma sentença objetiva.
A opinião implícita envolve, então, um tratamento também extra-linguístico e contextual -- ao necessitar identificar que um determinado evento ou fato é indesejável.
Em esse trabalho, seguimos a trilha de e identificamos sentimentos e opiniões com qualquer declaração de avaliação sobre um objeto ou entidade.
Note então que nossa definição de opinião ou sentimento -- diz respeito a contextos avaliativos explícitos.
Um importante recurso para a Mineração de Opinião são os Léxicos de Opinião, que consistem de listas de palavras ou expressões anotadas com informação de polaridade das mesmas.
Tais recursos são utilizados em diversos métodos da literatura e para a implementação de um método de Análise de Sentimentos numa língua, são de grande ajuda.
Trabalhos sobre a determinação da orientação semântica de palavras ou termos usualmente recaem sobre três métodos:
Os baseados em grandes corpora, os baseados em recursos lexicais como dicionários ou thesauri -- e os baseados em multi-língua ou tradução.
Os primeiros utilizam relações encontradas ente palavras e expressões presentes nos corpora para determinar sua polaridade.
Trabalhos como caem nessa categoria.
Sua vantagem reside na possibilidade de identificar expressões multi-palavras opinativas como &quot;pé no saco», expressões com polaridade adquirida por uso social e não necessariamente listados em recursos lexicográficos como &quot;fantástico».
Os resultados, entretanto, refletem diretamente a natureza do corpus utilizado e, portanto, diferentes sentidos para um palavra ou expressão pode não ser capturados e a abrangência desse léxico pode ser diminuta.
Tais métodos também requerem uma grande quantidade de processamento.
A segunda abordagem explora as relações semânticas presentes em recursos lexicais como thesauri e dicionários.
Representante distinto desses métodos é o trabalho de Kamps Que usa a 11 &quot;Emotions are our».
WordNet para identificar a polaridade de adjetivos ou o de Esuli Que utiliza dicionários, entre outros.
A vantagem de tais métodos está na possibilidade de explorar relações semânticas, manualmente codificadas e avaliadas, existentes entre as palavras e por a grande cobertura do léxico da língua em questão.
Entretanto, tais métodos só capturam o significado lexicográfico das palavras e não são capazes de descobrir gírias ou expressões multi-palavras.
Finalmente, os métodos multi-língua e baseados em tradução exploram recursos lexicais já disponíveis para outras línguas, como o inglês, para a criação de um tal recurso para a língua alvo.
Sua vantagem reside no fato de algumas línguas não possuírem recursos linguísticos construídos que permitam a utilização de outros métodos, mas devem lidar com a complexidade envolvida na tradução entre duas línguas diferentes.
Exemplo desse método é o trabalho de Mihalcea Que utiliza um dicionário bilíngue e um léxico de opiniões do inglês para gerar um léxico de opiniões para o romeno.
Métodos focados numa análise de sentimentos mais granular -- seja a nível de sentença ou de sintagma ou expressão -- sugiram na literatura por a sua importância para aplicação em outros métodos como sumarização de opiniões, perguntas e respostas ou visando melhorar os resultados de métodos documentais -- por exemplo, faz classificação de subjetividade em sentenças para sumarizar o texto e, posteriormente, realizar a classificação de polaridade, com resultados equiparáveis aos métodos usando o texto completo.&amp;&amp;&amp;
Diversos métodos foram utilizados para resolver o problema de identificar a polaridade associada a uma sentença ou expressão.
Trabalhos como utilizam aprendizagem de máquina para determinar a polaridade associada a um sintagma (phrase em inglês).
Outros trabalhos utilizam regras ou heurísticas para determinar a polaridade do sentimento associado a uma sentença ou suas partes.
Trabalhos como aplicam diretamente a soma algébrica das polaridades das palavras Trabalhos como utilizam- se de heurísticas ao explorar regras sintáticas, semânticas e discursivas manualmente codificadas.
Outros, como utilizam uma abordagem baseada na semântica composicional, traduzindo a estrutura sintática das sentenças em formas semânticas e utilizando essas últimas para determinar a polaridade através de relações como composição, reforço, contradição, etc..
Choi e Cardie mostraram que um tratamento mais apurado da negação tem grande impacto num método granular de análise de sentimentos, em contraste à modesta melhora na performance vista num nível documental.
Em, Wiegand Discutem que isso se dá, pois, num nível documental, a informação geralmente é redundante e mesmo em métodos simples como bagof-- words a polaridade geral do texto pode ser alcançada por outros itens.
Em esse contexto, é importante mencionar a dificuldade em se tratar a negação no Português Brasileiro.
Nossa língua, diferente de grande parte das demais, possui três formas de negação verbal, a saber:
Uma canônica, pré-verbal, em que a partícula negativa vem antes do verbo como em &quot;eu não quero dormir!»
e duas não canônicas, uma pós-verbal, em que a partícula de negação localiza- se após o verbo como em &quot;quero dormir não!»,
e uma dupla, em a qual o verbo é cercado por duas partículas de negação, uma antes e uma após ele, como em &quot;não quero dormir não!».
Todas as três formas possuem o mesmo significado, de acordo com Schwenter, e não ocorre o cancelamento da negação no caso de a negação dupla.
As regras usualmente associadas à negação devem então ser avaliadas para o caso do Português Brasileiro para se aplicar propriamente esses métodos à nossa língua.
Alguns trabalhos mais recentes tem como foco o problema de determinar a opinião associada a uma certa entidade ou atributo de uma entidade.
Exemplos de trabalhos com esse enfoque são.
Eles procuram identificar o referente de uma determinada opinião, ou seja, a entidade à qual a opinião se refere, estabelecendo quais os fatores importantes para tal avaliação, ou seja quais atributos da mesma estão sendo julgados.
Para esclarecer, num contexto de resenhas de filmes (ou produtos) é comum aparecer uma avaliação como a seguinte:
&quot;Um dos filmes mais importantes da história do cinema.
Cesare é um personagem que consegue passar uma forte impressão sem sequer abrir a boca durante todo o filme.
Seu olhar é congelante, seus movimentos frios.
Embora tenha personagens notáveis, o maior marco do filme foi ter inaugurado no cinema o movimento conhecido como &quot;Expressionismo Alemão «Outra característica marcante do filme é sua excitante trilha sonora.»
Em uma mesma resenha aparecem avaliações sobre o filme, sobre a trilha sonora e sobre uma personagem em particular.
Tais avaliações podem variar em intensidade e polaridade, o que levaria a erros se tratadas de forma homogênea.
Em casos de avaliação de produtos, um usuário pode valorizar mais uma característica do produto que outro.
Há assim a necessidade de se identificar as entidades (ou características) às quais uma sentença subjetiva se refere e associar a avaliação àquela.
O método utilizado para relacionar uma entidade mencionada no texto com a opinião associada a ela varia bastante na literatura.
Trabalhos como consideram o escopo de uma expressão avaliativa como uma janela de tamanho pré-definido -- quantidade de palavras, uma sentença completa, etc. -- e sua polaridade é associada a toda entidade presente nessa janela.
Outros, como, utilizam regras pré-definidas ou recursos como a FrameNet explorando a estrutura sintática ou discursiva do texto para determinar o referente de uma dada expressão opinativa.
Outros ainda, como utilizam um método baseado em aprendizagem de máquina para realizar a associação -- estratégias fortemente relacionadas com resolução anafórica -- i.
e identificação de refentes de anáforas.
Devido a as apropriações realizadas da ferramenta no Brasil e no mundo, o Twitter vem sendo bastante explorado tanto no campo da antropologia da rede e netnografia (e.
g) quanto na análise de mercado por empresas.
Jansen, por exemplo, discutem o Twitter como um importante recurso para empresas reconhecerem a resposta do mercado consumidor.
O autor sugere e avalia aplicação de Mineração de Opinião para monitoramento de marcas no Twitter, entretanto a ferramenta relatada por o autor não foi encontrada para uso ou descrita na literatura.
Em o campo da Análise de Sentimentos, entretanto, essa é uma fonte de dados ainda pouco explorada -- possivelmente devido a sua recente popularidade.
Muito recentemente trabalhos focados em Mineração de Opinião no Twitter vêm surgindo na literatura.
Trabalhos tratando de Análise de Sentimentos em dados do Twitter usualmente recaem na aplicação de métodos de aprendizagem de máquina, usando uma abordagem bag-of-- words ou explorando n-gramas, como.
Outros atributos -- baseados em anotação POS (do inglês Part-ofSeech) e padrões textuais ou padrões conversacionais -- são explorados em trabalhos como.
Para treino usualmente utiliza- se uma grande quantidade de tweets -- em alguns casos centenas de milhares de exemplos.
Tais métodos exploram a possibilidade de se construir automaticamente corpora de tweets.
Esse é um importante tópico ao se tratar do Twitter, pois, diferente de outros tipos de texto, não existe ainda uma base anotada que possa ser utilizada como benchmark para essa tarefa.
Muitos dos trabalhos sobre análise de sentimentos em tweets utilizam- se de marcações feitas por os usuários -- próprias dessa mídia -- como emoticons e hashtags.
Outra possível abordagem é a utilização de serviços de crowdsourcing, como o Amazon Mechanical Turk 12, para anotar o sentimento associado ao texto.
Reconhecimento de Entidades Nomeadas O Reconhecimento de Entidades Nomeadas (REN ou NER, do inglês Named Entity Recognition) é um problema proposto na ocasião da sexta Message Understanding Conference (MUC-6) e corresponde a identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas.
Santos e Cardoso explicitam que esta tarefa é um primeiro passo na análise semântica de um texto.
Mazur e Dale afirmam que o problema de reconhecimento de entidades nomeadas já está bem posicionado, tendo recebido bastante atenção da comunidade acadêmica, com técnicas do estado-da-arte obtendo alta performance.
De fato, Nadeau e Sekine analisando as tendências na área em 15 anos de desenvolvimento toma um conjunto de 100 artigos escritos em língua inglesa publicados nas maiores conferências da área, um número expressivo, considerando que somente a partir de 1996 com a ocorrência da MUC-6 as publicações tratando de entidades nomeadas cresceram.
É patente que os sistemas de REN passaram, nos últimos anos, a utilizar técnicas de aprendizagem de máquina tornando esse método o principal na área, em contraste com os primeiros sistemas propostos para tal problema que utilizavam regras manualmente codificadas e heurísticas.
O reconhecimento de entidades nomeadas, assim como outros problemas de reconhecimento de pedaços do discurso, como a tarefa de identificação de sintagmas nominais, recentemente vem sendo codificado como uma tarefa de descoberta sequencial de etiquetas.
Existem diferentes formas de se codificar essa tarefa como uma etiquetamento sequencial, as mais populares são a codificação Bio e a Bilou.
Em a etiquetação Bio (em inglês Begin, Inside, Outside ou Início, Dentro, Fora) marca- se uma determinada palavra num texto como estando no início (B) de uma entidade nomeada, dentro de uma, ou não pertencendo a uma entidade nomeada (O).
O esquema de anotação Bilou (do inglês Begin, Inside, Last, Outside, Unit, ou Início, Dentro, Fim, Fora, Unitário) acrescenta ainda as etiquetas para a última palavra de uma entidade nomeada (L) e para entidades constituídas por uma só palavra (U).
Pode- se ainda acrescer a esse esquema uma anotação quanto a o tipo de entidade criando as etiquetas B-PERSON, I-PERSON, B-LOC, I-LOC, etc..
Ratinov e Roth em seus experimentos, destacam que o esquema Bilou foi mais eficiente -- proporcionando melhores resultados -- uma vez que representa uma codificação mais granular das informações.
Técnicas computacionais usualmente associadas à utilização dessa codificação são classificadores baseados em probabilidade como o classificador CRF (Conditional Random Fields).
Os mesmos autores ainda destacam a importância de se utilizar informação não-local, i.
e fora de o simples escopo do texto ou da sentença, para garantir melhores resultados.
Além de o reconhecimento de entidades nomeadas, uma importante tarefa associada é a categorização das mesmas, i.
e a classificação desses nomes em categorias semânticas pré-especificadas, tarefa essa já especificada desde a realização da MUC-6.
Em o âmbito do Português Brasileiro (PTBr) diversos sistemas foram propostos e avaliados para a solução de tais problemas, por a ocasião do HAREM -- uma avaliação conjunta para o reconhecimento de entidades mencionadas.
Em essa avaliação, o sistema Palavra-NER, proposto por Bick, tirou a melhor colocação.
Bick e Santos discutem que existem duas formas de se realizar a categorização de entidades nomeadas (mencionadas, na terminologia de Santos) baseados nas estratégias para lidar com a vagueza e a metonímia (figura de linguagem em que uma expressão é utilizada para referir outro referente relacionado), como na expressão a seguir: --
Vai querer o que, Paraíba?
Paraíba, nesse contexto, não se refere ao estado brasileiro da Paraíba, mas sim a uma pessoa (provavelmente proveniente desse estado).
As duas formas que ambos discutem são:
A lexemática, ou &quot;forma antes da função», e funcional, ou &quot;função antes da forma».
A primeira consiste em tomar como o padrão o sentido canônico, lexicográfico, ou seja o sentido presente nos dicionários.
A segunda forma, leva em consideração o sentido no contexto.
Para o problema de identificação e classificação de ENs, mais de uma conferência visando a avaliação de sistemas foi realizada.
De entre elas, é importante, no nosso contexto, citar três:
A MUC, a ACE e o HAREM.
A Message Understanding Conference (MUC) foi a primeira conferência a propor a tarefa de reconhecimento de entidades nomeadas.
Em as definições da MUC-6, o REN é classificado como &quot;uma tarefa de uso prático, largamente independente de domínio e que poderia ser realizada automaticamente num futuro próximo «e corresponde à tarefa de &quot;identificar os nomes de todas as pessoas, organizações e lugares geográficos nos textos «(tradução nossa).
As categorias semânticas dessa tarefa, descritas em, eram a ENAMEX (entity name expression, em português expressão de nome de entidade), a NUMEX (numeric expression, em português expressão numérica), e a TIMEX (time expression, em português expressão temporal) que por sua vez eram subdivididas em Person (Pessoa), Organization (Organização) e LOCATION (Lugar), para ENAMEX, e Money (Dinheiro) e PERCENT (Porcentagem).
Nota- se que, devido a o escopo de reconhecimento limitado, aquelas entidades nomeadas que não pudessem ser classificadas entre essas categorias não deviam ser identificadas, i.
e a MUC preocupava- se somente com um subconjunto das entidades presentes nos textos.
A ACE -- Automatic Content Extraction -- é um conjunto de avaliações com objetivo de &quot;desenvolver tecnologias de entendimento da linguagem humana que provejam detecção automática e reconhecimento de informações-chave sobre entidades do mundo real, relações e eventos em textos de linguagem fonte e converter- los para uma forma estruturada».
Em termos gerais, o ACE tem como objetivos atacar os mesmos problemas que a MUC.
A principal diferença entre as duas avaliações é que as tarefas do ACE são mais ambiciosas que da avaliação anterior.
Por instância, o ACE define uma tarefa de reconhecimento de entidades, mas diferentemente da conferência que a precedeu, o ACE não se limita a entidades nomeadas, mas trata também de descrições de entidades e de pronomes.
Além disso, definiu- se uma nova tarefa:
Detecção de relações entre entidades.
De fato, essa atividade já existia na MUC, entretanto de forma mais limitada, com a detecção de co-referências.
Exemplos de relações entre entidades são as de co-referência, i.
e duas entidades denotam o mesmo objeto (e.
g Carmem Miranda e Pequena Notável), as de Parte-TODO, onde uma entidade é parte de outra (e.
g Rio Grande do Sul é parte do Brasil), etc..
As categorias de entidades no ACE são:
FAC (Facility, em português infraestrutura), GPE (GeoPolitical Entity, em português entidade geo-política), LOC (Location, em português localidade), Per (Person, em português pessoa), ORG (Organization, em português organização).
Semelhantemente à MUC, no ACE as entidades que não pudessem ser classificadas numa das categorias previamente listadas não deveriam ser reconhecidas.
O HAREM -- uma avaliação conjunta para o reconhecimento de entidades mencionadas -- é, como expresso no próprio nome uma avaliação conjunta para o problema das entidades nomeadas em língua portuguesa.
Sobre a terminologia, Santos e Cardoso explicitam que &quot;entidades mencionadas «é uma tradução do termo named entities em inglês, mesmo termo de a qual se deriva &quot;entidades nomeadas «utilizadas nesse trabalho.
A diferença do HAREM para as outras avaliações conjuntas vistas, além de ser específica para a língua portuguesa, é o interesse em todos os nomes próprios, não somente naqueles com classes pré-definidas, e por sua abordagem funcional do problema, como já discutido anteriormente.
O HAREM possui 9 categorias, subdivididas ainda em 41 subcategorias, de modo que serão listadas aqui somente suas categorias iniciais:
Pessoa, Organização, Tempo, Acontecimento, Coisa, Local, Obra, Abstração e Valor.
Todas as entidades nomeadas detectadas que não se enquadrem em qualquer das categorias deve ser classificada como Variado.
Em a segunda edição do evento, chamada Segundo HAREM, acresceu- se à avaliação a tarefa de reconhecimento de relações semânticas entre entidades.
Alguns trabalhos em Mineração de Opinião focada em entidades e atributos utilizam entidades nomeadas para identificar a referência de uma dada opinião.
Diferentes métodos são explorados nesses trabalhos, assemelhando- se pouco aos métodos usuais para REN.
Ding Utilizam regras de associação sequenciais (através de sequential pattern mining) para identificação de entidades.
Li Exploram Conjuntos Bayesianos para decidir se uma dada palavra marcada como nome próprio ou nome próprio plural é uma entidade nomeada.
Recentemente, alguns trabalhos tomam como enfoque a identificação de entidades em textos do Twitter.
Esses textos, como já discutido, impõem certa dificuldade em seu processamento e os métodos já aplicados em outros tipos de texto podem não funcionar muito bem para eles.
Locke mostra que um anotador do estado-da-arte, o Stanford NER, tem sua performance bastante reduzida quando aplicado aos textos do Twitter.
Uma dificuldade imposta por tais mensagens aos identificadores de entidades nomeadas reside no tamanho dos textos -- limitados por 140 caracteres, o que, em geral, resume- se a pouco mais que uma sentença.
Textos tão curtos oferecem pouca informação contextual que pode ser utilizada para a identificação das entidades.
Além disso, características muito importantes para identificação de nomes próprios em texto -- como a capitalização -- não são consistentemente seguidas em meios como o Twitter.
É muito comum a subcapitalização -- em a qual palavra alguma é capitalizada no texto e a supercapitalização -- em que várias ou todas as palavras são capitalizadas, em geral procurando denotar intensidade.
Assim, geralmente, os métodos devem ser adaptados para esse meio.
Tais trabalhos, em geral, utilizam técnicas do estado- da arte associadas a estratégias de otimização, como heurísticas de pre-processamento ou métodos semi-supervisionados que exploram a grande quantidade de dados não-anotados disponíveis.
Dado o contexto geral das áreas de estudo que nos interessam nesse trabalho, passamos a analisar aqueles trabalhos de alguma forma relacionados com o que descrevemos nessa dissertação.
De essa forma, nesse capítulo apresentamos os trabalhos relacionados ao nosso estudo, de acordo com cada método utilizado no processo, discutindo decisões de construção que tomamos para o nosso método.
Tal análise se dará em duas frontes:
Análise de Sentimentos e Reconhecimento de Entidades Nomeadas. Assim o fazemos pois cada um desses problemas já foi extensamente estudado na literatura e a análise de cada problema separadamente nos permite entender melhor o problema total ao qual nos atemos.
Análise de Sentimentos São vastos os trabalhos na área de Análise de Sentimentos que povoam a literatura mais recente em Processamento de Linguagens Naturais.
Diversos eventos têm colocado esse problema como uma trilha de pesquisa em sua programação, mostrando a relevância de ele para a área.
Dentro de a miríade de métodos e enfoques existentes, nosso corte reside nos trabalhos que enfocam no processamento de dados do Twitter ou que identificam a entidade à qual é dirigida uma opinião.
Portanto, dividimos essa seção em duas partes:
Uma sobre os métodos de As focados em entidades, para apresentar os métodos de associação entidade-opinião investigados na literatura e outra tratando da Análise de Sentimentos em tweets.
Como já explanado, as técnicas aplicadas para relacionar uma entidade mencionada num determinado texto com a opinião associada a ela variam bastante na literatura.
Trabalhos como consideram o escopo de uma expressão avaliativa como uma janela de tamanho pré-definido -- quantidade de palavras, uma sentença completa, etc. -- e sua polaridade é associada a toda entidade presente nessa janela.
Tal estratégia é mais simplista, e admite implicitamente que qualquer entidade que apareça num contexto avaliativo está sendo avaliada.
Isso não é necessariamente verdade, uma vez que tal entidade pode estar somente fracamente relacionada ao objeto de avaliação como no caso de a sentença abaixo:
&quot;fui com meus irmãos e etc sair pra comer né, ai meu irmão levou o ipad de ele e eu fiquei jogando angry birds enquanto eles conversavam, Amei «(sic) Em esta sentença, a expressão &quot;Amei «expressa uma opinião positiva sobre a entidade &quot;angry birds «-- um jogo disponível para diversos dispositivos móveis como o Ipad, mencionado na sentença.
Apesar de a entidade &quot;ipad «ser relacionada com a entidade avaliada, a opinião expressa não relacionase com esta primeira, logo, como pode ser visto, tal estratégia pode gerar vários erros.
De fato, essa estratégia é a utilizada por a maioria das ferramentas comerciais avaliadas por nós, levando- as a uma grande imprecisão.
Outros trabalhos, como, utilizam regras pré-definidas ou recursos como a FrameNet -- explorando a estrutura sintática ou discursiva do texto -- para determinar o referente de uma dada expressão opinativa.
Apesar de interessante, estratégias que utilizam informação linguística mais profunda -- tal como a sintaxe ou a estrutura discursiva do texto -- são dificilmente adaptáveis ao Twitter, sem que haja uma grande simplificação, uma vez que anotar tais informações seria bastante difícil, postas as características do texto.
Os trabalhos de Ding São os que parecem melhor se adaptar ao nosso caso, por também trabalharem com textos com bastante ruído os autores mineram fóruns de discussão sobre produtos -- e por basearem- se em regras manualmente construídas explorando informação morfológica e pseudo-sintática.
Outros ainda, como utilizam um método baseado em aprendizagem de máquina para realizar a associação.
Tais técnicas assemelham- se às utilizadas no problema de resolução de correferências nominais -- de fato, utiliza um sistema de resolução de correferências para identificar a referência de uma dada opinião e explora atributos comumente usados em sistemas de resolução de anáforas para reconhecer a referência de uma opinião.
Alguns trabalhos recentes dedicam- se ao problema de Análise de Sentimentos com um enfoque num gênero textual específico:
As mensagens do Twitter.
Entre eles, podemos listar os abaixo discutidos.
Go Usam unigramas e bigramas como atributos, modelando a negação como um atributo binário, indicando a presença/ ausência de um negador na sentença.
Os autores comparam dois classificadores (Naïve Bayes e Máxima Entropia) para predizer a polaridade das mensagens.
Pak e Paroubek treinam um classificador multinomial Naïve Bayes usando n-gramas e anotação POS como atributos -- usando o TreeTagger para anotar os textos.
A negação é tratada com uma inversão de polaridade dentro de uma janela pre-definida de três palavras -- da imediatamente anterior à expressão de negação, à imediatamente posterior.
Bifet e Frank usam unigramas como atributos de classificação e comparam três diferentes classificadores.
Os autores argumentam que como os dados do Twitter possuem uma característica de stream -- dispersos ao longo de o tempo -- a métrica de acurácia é inadequada para avaliação dos resultados de classificadores sobre esses dados.
Propõem então a utilização da estatística Kappa sobre uma janela deslizante de textos em períodos de tempo, o que permitiria uma caracterização melhor do desempenho dos classificadores em relação a o sentimento dos textos dentro de aquele spam temporal.
Davidov Exploram o uso de hashtags e emoticons como rótulos de sentimentos -- i.
e como os sentimentos que o sistema utilizará para classificar os tweets -- e treinam um classificador KNN (do inglês K Nearest Neighbors, K vizinhos mais próximos) usando n-gramas e atributos baseados em padrões.
Koulompis Usam uma abordagem similar, entretanto realizam a classificação para as polaridades do sentimento expresso no texto, i.
e classificam- no como positivo, neutro ou negativo.
Barbosa e Feng usam anotação POS, presença de maiúsculas nas palavras, emoticons, pontuação e atributos específicos do Twitter como presença de links no tweet, Twitter names e marcadores RT -- marcadores que indicam que a mensagem está sendo retransmitida, i.
e que a mesma é de autoria de outrem.
A classificação é realizada em dois passos:
Em o primeiro eles classificam os textos como subjetivos ou objetivos, i.
e conotando um sentimento ou não;
Em o segundo passo os tweets classificados como subjetivos são classificados de acordo com a polaridade do sentimento transmitido.
Os autores utilizam um classificador SVM (do inglês Support Vector Machines, máquinas de vetor de suporte) para ambas as etapas.
Esses trabalhos tratam de classificar um determinado texto do Twitter quanto a o sentimento transmitido.
Nosso enfoque, entretanto é classificar o sentimento associado a uma determinada Jansen Usam uma aplicação comercial -- atualmente indisponível -- para realizar a análise de sentimentos associados a uma marca no Twitter, possibilitando assim a detecção de WOM no Twitter.
O trabalho de Silva Descreve a construção de uma ferramenta que utiliza análise de sentimentos para descobrir as opiniões associadas aos candidatos da eleição presidencial portuguesa expressas no Twitter.
Eles utilizam uma estratégia baseada em léxico combinado com regras lexicosintáticas para identificar e compor os sentimentos e atribuir a referência a uma determinada opinião.
Para o Português ainda, Silva Utilizam o conceito de viés do autor quanto a um tópico e, assim, classificar uma opinião sobre o mesmo em tweets.
Os autores trabalham no domínio da política e de esportes.
Calais Guerra et al, por sua vez, utilizam regras de associação -- numa estratégia similar à de -- para classificar tweets quanto a polaridade.
Os autores aplicam sua técnica para detecção de casos de dengue no Brasil, mas não avaliam a performance do seu método.
Acreditamos que -- apesar de tratarem problemas, de certa forma, similares ao nosso -- tais estratégias não são adequadas pois não se aplicam ao caso que estudamos -- viés faz sentido no domínio de política ou em contextos em que há uma grande polaridade entre duas entidades, mas não se adéqua, em nossa opinião, à analise de mercado que procura diferentes opiniões sobre um produto ou marca -- e por o baixo nível de granularidade em que se analisam as opiniões.
Em este trabalho, dadas as características do texto do Twitter e as ferramentas disponíveis, tomamos uma estratégia de mineração baseada em léxico e de associação baseada nos métodos de resolução de co-referência.
Nosso trabalho é inspirado por os trabalhos de Silva E Ding, apesar destes autores utilizarem regras manualmente codificadas.
Acreditamos que, dadas as poucas informações linguísticas de que dispomos, uma estratégia que explore o aprendizado automático pode extrapolar informações dos dados que seriam dificilmente codificadas em regras pré-estabelecidas.
Apresentamos, na Tabela 3.1, uma comparação entre os trabalhos relacionados baseada no tipo de técnica de As usada, o tratamento da negação, se utilizou método de aprendizado automático para determinação da polaridade, a profundidade de análise, tipo de texto (ou mídia) tratado e método de atribuição de referência.
De entre os trabalhos que consideramos mais relacionados com o nosso, fazemos ainda uma comparação em relação a a adequação às características desejáveis para tratar o problema que nós propusemos.
Podemos ver na Tabela 3.2 que os outros trabalhos não se adequam completamente ao problema proposto, seja por se basear em regras específicas para determinados domínios, por não ter sido aplicado para o Português ou por tratar o fenômeno num nível de análise que consideramos inadequado, como já discutido.
Trabalhos sobre Reconhecimento de Entidades Nomeadas são diversos na literatura.
Para o caso da língua portuguesa, os participantes do HAREM são de especial importância.
Tais métodos, entretanto, são pouco indicados no nosso caso específico por a natureza dos textos do Twitter.
O Palavras-NER -- sistema que recebeu o primeiro lugar na trilha geral da primeira edição do HAREM conseguiu identificar menos de 20% das entidades mencionadas no Twitter num conjunto de cerca de 50 textos dessa fonte anotados com ele.
Por tal motivo concentramos nossa discussão nos trabalhos sobre Reconhecimento de Entidades Nomeadas focados no contexto do Twitter.
Locke investiga a tarefa de REN em textos do Twitter aplicando um classificador treinado em textos jornalísticos -- provenientes do corpus provido para treino na tarefa de REN do CoNLL2003.
O sistema -- baseado em SVM -- teve baixa performance nos textos do Twitter, com medida F1 inferior a 40%.
Os tweets utilizados para a avaliação foram manualmente anotados de acordo com os padrões do CoNLL-2003.
O trabalho de Ritter Utiliza uma estratégia baseada em agrupamento de palavras para realizar normalização lexical no Twitter e atributos morfossintáticos para treinar um reconhecedor de entidades nomeadas baseado no algoritmo CRF.
Esses autores tratam a identificação e a classificação como tarefas separadas, aplicando um classificador LabelledLDA para esta última.
Os autores alcançam uma marca de 67% de medida F para o reconhecimento e 66% para a classificação com a sua estratégia -- sobre um conjunto de 800 tweets.
Finin Propõem a utilização de serviços de crowdsourcing -- como o Amazon Mechanical Turk, já citado anteriormente -- para criar um recurso dourado com anotação de entidades nomeadas ponderada entre a precisão (P) e a abrangência (R) dada por F $= (1+ 2)· (2 P· R.
Tomando $= 1 temos a medida F1 com mesmo peso para Precisão e Abrangência.
Tabela 3.2 ­ Trabalhos de As diretamente relacionados ao nosso Específico Específico para o Independente de Trabalho Método de SA a língua Twitter domínio tuguesa Ding Sub-- sentencial Não Não Jansen Sentencial Sim Sim Não Silva Sub-- sentencial Sim Não Sim Nosso trabalho Sub-sentencial Sim Sim Sim para por- em dados do Twitter.
Tal recurso foi, posteriormente, utilizado para treinar o Stanford NER, um identificador de entidades nomeadas baseado no algoritmo CRF de aprendizagem automática.
O autor avalia a qualidade da anotação e sua relação com a métrica de qualidade provida por o serviço de anotação (WorkerRank) utilizando diversas métricas, mostrando que não necessariamente tais métricas estão relacionadas.
O trabalho de Ferragina e Scaiella é, de certa forma, relacionado à tarefa proposta.
Os autores propõem um sistema que anota textos do Twitter com ligações para verbetes da Wikipédia.
A identificação de Entidades Nomeadas pode ser então realizada limitando- se os verbetes àqueles descrevendo entidades das categorias semânticas desejadas.
A anotação é realizada a partir de métricas de grau de relação de uma âncora -- um segmento de texto -- com os verbetes da enciclopédia.
Liu Utilizam uma estratégia semi-supervisionada e classificadores KNN e CRF para identificar as entidades em textos do Twitter.
Os classificadores utilizam um conjunto diferente de atributos em seu treinamento, numa estratégia de co-training, levando em consideração informações locais, dadas por a vizinhança da palavra a ser anotada, e não-locais, através do uso de um gazeteer.
O sistema atinge bons resultados, acima de os sistemas construídos para outros gêneros textuais quando aplicados nos textos provenientes do Twitter.
Os autores utilizam como conjunto de anotação a estratégia Bilou juntamente com as categorias semânticas PERSON (Pessoa), ORGANIZATION (Organização) e LOCATION (Local).
Apresentamos, na Tabela 3.3, uma comparação entre os trabalhos relacionados e o nosso trabalho, baseado no tipo de técnica de REN usada, os atributos analisados e tipo de texto (ou mídia) com o qual o sistema foi treinado.
Note que, apesar de apresentarmos os valores de medida F alcançados por os métodos, tal medida não pode ser tomada como base de comparação, uma vez que os experimentos foram realizados com bases diferentes e mesmo considerando conjuntos diferentes de categorias ou esquemas de segmentação de entidades.
Em particular, os trabalhos de Finin Seção 4.3).
A segunda fase consiste de uma anotação morfológica das palavras com um etiquetador morfológico (POS Tagger).
Para essa tarefa escolhemos o tagger de Brill[ 9], que já foi implementado e treinado para o Português.
Após esse passo, passamos para as fases de identificação de entidades (c..
F. Seção 4.5) e Mineração de Opinião (c..
F. Seção 4.4) realizadas paralelamente.
Optamos por identificar essas informações separadamente pois acreditamos que um considerável esforço de pesquisa já foi realizado para resolver- los podendo- se assim aproveitar os métodos já estudados na literatura e combinar- los, no lugar de desenvolver um único método que ataque ambos os problemas conjuntamente.
Por fim, segue a etapa resolução de referência das opiniões que consiste de estabelecer o relacionamento entre opiniões e entidades, que implementa o processo de extração de opiniões ao relacionar com uma dada entidade a opinião associada a ela num dado texto, gerando assim triplas Entidade, Opinião, T exto\&gt;.
Construção do Léxico Um importante recurso para a realização da Análise de Sentimentos é um léxico de opiniões, sua importância reside em facilmente aumentar a abrangência da identificação de expressões opinativas e fornecer pistas para identificar novas, além de poder ser utilizado na identificação da polaridade das mesmas.
Não fomos capazes de encontrar para o Português Brasileiro um recurso desses que fosse independente de domínio.
De fato, o único léxico de opiniões encontrado foi o SentiLex criado para o Português Europeu e específico ao domínio de julgamentos sociais, ou seja, sobre pessoas.
Uma parte do trabalho então dedicou- se à construção de um tal léxico.
Utilizando as técnicas baseada em corpora de Turney, baseada em recursos lexicais de Kamps E uma variação da técnica de Mihalcea Construímos um léxico de 7077 expressões para o Português Brasileiro, anotado com a polaridade das mesmas.
Como recursos para a construção desse léxico, utilizamos um corpus de resenhas de filme, criado por nós, o Thesaurus Eletrônico do Português e o léxico de opiniões construído por Liu para o inglês1.
A o utilizar métodos diferentes e explorar vários recursos, acreditamos que pode- se melhorar os resultados ao combinar as melhores características para superar as desvantagens de cada método.
Assim, ao integrar, por exemplo, um método baseado em corpus com um método baseado em thesaurus consegue- se explorar tanto as associações semânticas manualmente codificadas do segundo recurso, com as conotações sociais e termos multi-palavras que podem ser extraídos com o primeiro método.
A construção do léxico e sua avaliação, realizadas como parte integrante da pesquisa realizada nessa dissertação, foram publicadas no STIL 2011.
O léxico resultante foi, posteriormente, estendido utilizando um corpus maior gerando um léxico com mais de 10.000 termos polarizados.
Posteriormente, construímos ainda um dicionário de emoticons e hashtags que denotem opinião.
1 Disponível Hashtags são usualmente utilizadas como meta-informação nos tweets, seja para expressar uma informação pragmática em forma textual, como ironia, ou avaliação (e.
g as hastags&amp; not,&amp; win,&amp; fail), ou para classificar- los quanto a tópico (e.
g&amp; google,&amp; android, etc.).
Aquelas que expressam informações pragmática são de especial interesse e foram bastante exploradas por nós (c..
F. Seção 4.4) para, por exemplo, construir o corpus.
As outras entretanto, também fornecem informações importantes pois a identificação de um tópico é uma importante pista para o método quanto a a polaridade do tweet -- de acordo com a polaridade média daquele tópico num certo período de tempo relevante.
Note que essa polaridade associada ao tópico é intrinsecamente temporal e, portanto, o dicionário de hashtags deve ser construído dentro de limites temporais rígidos, i.
e deve ser renovado, ou reconstruído após uma certa quantidade de tempo.
Por sorte, pode- se fazer- lo de forma automática.
Nos utilizamos nesse trabalho das etiquetas de avaliação(&amp; win e&amp; fail) para identificar a polaridade dos tweets e uma métrica de polaridade -- variando entre 1 e 1 -- baseando- nos no trabalho de Turney.
Assim, aplica- se o método de Turney -- centrando as buscas no Twitter com a TwitterAPI -- utilizando as etiquetas&amp; win e&amp; fail para identificar os tweets polarizados.
De a mesma forma, a polaridade dos emoticons pode ser automaticamente calculada.
Pré-processamento lexical e morfológico Em estudos iniciais, dado um corpus de 6129 tweets extraídos durante cerca de três dias utilizando a engine de busca do Twitter usando a hashtag&amp; fato ­ um meme da comunidade de usuários do Brasil ­ contendo 113341 palavras excluindo- se hashtags e menções a outros usuários -- de as quais 13210, cerca de 11%, não estão presentes no léxico do português DELAF com 880.000 palavras flexionadas.
Desenvolvemos então um conjunto de heurísticas para normalizar tais textos quanto a grafia.
A variação de grafia mais comum identificada nos textos é a repetição de vogais -- utilizada para conotar intensidade.
Essa variação pode ser facilmente corrigida através de expressões regulares simples.
Outro caso comum foi a variação por similaridade fonética, ou seja quando o autor troca letras ou conjunções de letras que denotam fonemas parecidos intencionalmente ou não -- como trocas de letras como's` e 'ç', ou mesmo de escritas socialmente demarcadas ou típicas de grupos e socioletos próprios da Internet, como a grafia &quot;molier «para a palavra &quot;mulher «ou &quot;naum «para &quot;não».
Tal variação foi tratada utilizando- se uma variação do algoritmo Metaphone adaptado para o Português Brasileiro.
Outra fonte comum de variação envolve a utilização de abreviações de palavras ou expressões.
Essas abreviações são -- ou parecem ser -- em muitos casos aleatórias ou pouco estruturadas, como para as grafias &quot;vdd «para &quot;verdade «ou &quot;lol «para &quot;laughing out loud «(&quot;rindo alto «ou &quot;rindo muito», em inglês).
Um caso específico de variação percebida é a tendência de omissão de vogais para reduzir o tamanho do texto.
Assim, palavras como &quot;saudade «são grafadas como 'sdd' 2.
A heurística proposta para esses casos é uma comparação entre palavras considerando somente suas consoantes.
Essa heurística deve ser utilizada com cautela por sua alta taxa de erros, e.
g &quot;naum «e &quot;nome «são consideradas similares por ela.
Só a aplicamos no caso em que a palavra não identificada não possui vogais.
Outras variantes não contempladas ainda incluem palavras de outros idiomas que aparecem nos textos, algo que não pretendemos tratar.
Após normalizados, os textos são morfossintaticamente anotados utilizando etiquetador morfossintático baseado em transformações de Brill do NLTK3.
Como não possuímos um conjunto de tweets morfossintaticamente anotados em Português, não podemos avaliar a acurácia de tal anotador, entretanto, para textos jornalísticos -- do corpus MacMorpho4 -- o etiquetador possui acurácia de 91% -- um índice baixo para o estado da arte.
Outros etiquetadores do NLTK foram testados, entretanto nenhum atingiu um resultado satisfatório.
Análise de Sentimentos Para a identificação de opiniões expressas em texto, utilizamos um método baseado em léxico e marcadores do Twitter -- com hashtags e emoticons.
Nossos experimentos iniciais exploraram as possibilidades de aplicação de diferentes métodos considerando sua complexidade.
Avaliamos desde a aplicação do léxico, numa estratégia comumente usada na literatura para a As documental -- a saber a soma algébrica das polaridades das expressões encontradas nos tweets -- até investigando o papel da negação, numa forma mais aproximada dos métodos específicos para As sentencial e do impacto do pré-processamento nessa tarefa.
O resultado desses testes iniciais será publicado no PROPOR 2012.
De entre as variações estudadas, estão duas diferentes modelagens para o escopo da negação, baseadas numa janela de tamanho pré-definido.
O escopo da negação tem forte ligação com o contexto sintático e discursivo em que aparece, entretanto tais informações são indisponíveis para o nosso sistema.
Testamos então dois tipos de escopo mais simples para modelagem do efeito da negação em sentenças -- a saber, uma negação com escopo em toda a sentença, já que o termo de negação não necessariamente deve aparecer adjacente à locução negada, e uma negação baseada na vizinhança, já que mais usualmente o termo da negação está na adjacência da locução negada.
A modelagem da negação teve pouco impacto nos nossos testes (c..
F. Capítulo 5), entretanto decidimos nos ater à modelagem baseada em vizinhança por acreditarmos que modela melhor o comportamento &quot;padrão».
O algoritmo de Análise de Sentimento funciona da seguinte forma:
Para cada palavra no tweet se palavra está marcada com polaridade no léxico fonética.
Utilizamos esse conjunto para identificar os termos polarizados da sentença -- para os quais a referência da opinião será posteriormente inferida.
Note que a modelagem da negação apresentada contempla a possibilidade da dupla negação, pois não multiplica a quantidade de termos negativos no contexto do termo polarizado.
Reconhecimento de Entidades Escolhemos, de entre os métodos propostos na literatura de REN, utilizar a etiquetamento sequencial para resolver o Reconhecimento de Entidades Nomeadas, seguindo a proposta de.
Para implementar tal método, utilizamos a linguagem de programação Python e a biblioteca de processamento de linguagem natural NLTK -- que por sua vez utiliza a implementação de CRFs da toolkit Mallet5.
O classificador CRF utilizado foi treinado utilizando atributos léxicos, morfológicos e baseados em gazeteers, mas devido a particularidades da interface do classificador no NLTK, outras informações contextuais sugeridas em não puderam ser implementadas.
A principal de tais limitações foi a restrição do contexto a ser analisado à sentença sendo anotado no momento.
Tal restrição impede a aquisição das informações contextuais, que servem como um histórico das decisões feitas anteriormente.
Os dados anotados utilizados durante o treino são constituídos de 1000 tweets, coletados usando a Twitter API buscando textos em Português usando as expressões &quot;Google»,&quot;&amp; Cielo &quot;e «máquina cielo».
A escolha de tais expressões se deu devido a o enfoque do trabalho -- i.
e a utilização de Análise de Texto com finalidade de auxiliar o monitoramento de marca na Internet -- escolhendo nomes de empresas -- Cielo e Google.
Tais textos foram pré-processados usando as heurísticas descritas na Seção 4.3 e morfossintaticamente anotados.
Inicialmente, considerou- se implementar o método explorado por Liu, um método semi-supervisionado baseado em co-training.
Tal escolha se deve ao fato que utilizando um método semi-supervisionado, somente uma pequena quantidade de dados anotados e uma grande quantidade de dados brutos são necessários para o treino.
Como dados brutos -- i.
e não anotados -- são fáceis de se conseguir utilizando a API do Twitter, precisaríamos então anotar somente uma quantidade pequena de tweets, tornando essa estratégia bastante atraente, dado que a anotação é bastante laboriosa.
Essa estrategia mostrou- se infrutífera, entretanto, pois a interface do NLTK não nos fornecia informações essenciais para implementar o algoritmo proposto por -- o valor da verossimilhança (likelihood, em inglês) de uma determinada sequência de etiquetas dado o modelo estimado.
Uma outra implementação de CRFs foi testada, entretanto a mesma comportou- se pobremente -- com valores muito abaixo de os conseguidos com a implementação do Mallet, o que nos levou a questionar a correteza desta implementação.
Seguindo o trabalho de Ratinov e Roth, optou- se por utilizar a codificação Bilou (Begin, Inside, Last, Outside, Unit) que representa a informação de uma palavra pertencer a uma entidade nomeada de acordo com sua posição nesta entidade -- no início do nome de uma entidade com mais de uma palavra (B), no meio de o nome de uma entidade com mais de uma palavra (I), no final do nome de uma entidade com mais de uma palavra (L), não ocorre numa entidade nomeada (O) e é o nome simples de uma entidade (U).&amp;&amp;&amp;
A o optarmos por a implementação do classificador CRF do NLTK (que utiliza o Mallet) podemos excluir a correta implementação do algoritmo como fator de bloqueio de nossos experimentos -- uma vez que o mesmo já foi amplamente utilizado e testado na comunidade.
Acreditamos que -- apesar de reduzir a flexibilidade na construção do reconhecedor proposto -- um método supervisionado baseado em CRF, dados os esforços de preprocessamento e o treinamento em dados provenientes do Twitter -- e não em textos de outro gênero -- nos fornece um bom modelo para Reconhecimento de Entidades Nomeadas no Twitter para o Português.
Identificação de referência Para a identificação de referência da opinião utilizamos um método de aprendizagem de máquina sobre um conjunto de atributos similar a.
Os autores utilizam atributos bastante utilizados em reconhecimento automático de correferência nominal para identificar a referência de uma opinião como concordância de gênero e numero, atributos posicionais da opinião e do candidato, etc..
O método foi implementado na linguagem de programação Python utilizando a biblioteca SciKpara aprendizagem de máquina.
Utilizamos, como algoritmo de aprendizagem de máquina, a implementação do SciKits de uma máquina de vetor de suporte (SVM).
Como atributos fornecidos ao algoritmo de aprendizagem utilizamos:·
Distância entre o termo polarizado (termo que expressa opinião) e a entidade nomeada candidata a referência, calculado como a diferença entre o índice da posição de início do nome da entidade na sentença e do termo polarizado;·
Valor absoluto da distância entre o termo polarizado e a entidade nomeada candidata a referência;·
Índice da posição de início do nome da entidade na sentença;·
Índice da posição de início do termo polarizado na sentença;·
Quantidade de entidades na sentença· Tamanho da sentença;·
Razão entre o índice da posição de início do nome da entidade na sentença e o tamanho da sentença -- ou fator de centralidade da entidade nomeada;·
Razão entre o índice da posição de início da expressão polarizada e o tamanho da sentença ou fator de centralidade da expressão polarizada;·
Razão entre a distância entre o termo polarizado e o candidato e o tamanho da sentença -- ou distância suavizada;
A escolha do SVM como método de aprendizagem se deu, em grande parte, por sua baixa sensitividade a desbalanciamento entre classes, uma vez que existem muito mais casos negativos de referência entre termos polarizados e entidades que positivos.
Em esse capítulo discutimos o processo de avaliação dos métodos propostos no Capítulo 4, assim como os dados construídos e utilizados para tanto, além de apresentar os resultados de tal avaliação.
Construção e Anotação do corpus de teste Como recurso para avaliar o desempenho do sistema como um todo -- e das técnicas individuais escolhidas -- anotamos um conjunto de 1000 textos extraídos do Twitter contendo as palavras &quot;google», &quot;ipad «ou &quot;nokia», obtidos utilizando- se a API do Twitter procurando por textos em língua portuguesa contendo tais expressões.
Tal conjunto de tweets compõe o corpus TwitterSentiment de mensagens do Twitter anotadas com sentimento para o Português.
A escolha das expressões foi feita com foco nos objetivos do trabalho -- uma vez que nosso interesse é aplicar Análise de Sentimentos para auxiliar um processo de Inteligência Competitiva.
Escolhemos então empresas e produtos da área de tecnologia e comunicação por serem frequentemente citados na mídia escolhida.
A anotação de tais textos se deu em duas partes:
A anotação de entidades e a anotação de opinião e referências.
Os 1000 textos foram separados em três partes para garantir uma maior agilidade na anotação.
Cada parte continha 400 textos, com 100 desses em comum entre os três conjuntos.
Três anotadores anotaram uma das partes cada e o conjunto de 100 textos em comum serve para podermos calcular o grau de concordância entre tais anotações.
A anotação foi realizada num ciclo, seguindo as regras no Apêndice A. Tabela 5.1 ­ Interpretação de Altman para a estatística Kappa como medida de concordância.
Intervalo de valores Interpretação Concordância fraca 0, 2 a 0, 4 Alguma concordância 0, 4 a 0, 6 Concordância moderada 0, 6 a 0, 8 Boa concordância 0, 8 a 1 Concordância excelente Como pode- se ver na Tabela 5.2, a anotação de entidades nomeadas obteve uma concordância excelente.
1. Os anotadores marcaram entre 5 (Anotador 2) e 8 (Anotador 3) termos polarizados referindose a uma entidade nomeada;
Menos dois anotadores, a referência e a polaridade foram igualmente identificadas.
Acreditamos que a anotação possui concordância aceitável para o problema proposto, apesar de os poucos casos anotados no conjunto de controle não nos permitir avalitar quantitativamente sua qualidade.
Análise de Sentimentos A avaliação do método de Análise de Sentimentos se deu em duas partes.
A primeira consiste na avaliação do método para a classificação sentencial quanto a a polaridade, i.
e classificar uma dada sentença como positiva ou negativa.
A segunda parte, consiste na identificação de opiniões relacionadas a entidades e, portanto, sub-sentencial, pois envolve descobrir quais partes da sentença se referem a quias entidades mencionadas.
A avaliação se deu assim para primeiramente podermos avaliar a qualidade do método de classificação de sentimentos em relação a os outros da literatura, posto que a maioria dos que trabalham com o Twitter fazem a classificação de uma sentença e não focada em entidade.
A segunda avaliação nos permite, então, analisar a performance do método no nível de granularidade requerido por a nossa proposta.
Uma vez que o corpus TwitterSentiment -- descrito na Seção 5.1 -- não possui informação de polaridade a nível de sentença, foi necessário utilizarmos outro recurso para realizar esta etapa de avaliação.
Construímos, então, um conjunto de 1700 tweets em língua portuguesa divididos entre as classes Positivo e Negativo -- 850 para cada classe -- representando a polaridade associada ao sentimento transmitido por o texto.
Os textos foram coletados automaticamente utilizando a Twitter API, buscando por as hashtags&amp; win e&amp; fail, comumente utilizadas para expressar aprovação e reprovação, respectivamente, por os usuários da comunidade brasileira.
Para seleção de língua, utilizamos o parâmetro lang da API selecionando o valor 'pt'.
Os rótulos de sentimentos estão associados às hashtags, de acordo com o sentimento conotado por as mesmas.
Assim, todo texto contendo a&amp; win é classificado como possuindo um sentimento positivo, assim como todo aquele contendo&amp; fail é classificado como possuindo um sentimento negativo.
Tweets contendo ambas as hashtags foram descartados do conjunto.
Para avaliar o método de classificação de tweets, identificamos a polaridade dos termos que conotam sentimentos, usando o método descrito na Seção 4.4, e selecionamos a classe mais frequente no mesmo (ou, equivalentemente, realizamos a soma algébrica das polaridades).
Aqueles textos que possuíam mais termos positivos que negativos são, assim, classificados como conotando um sentimento positivo;
Aqueles com mais termos negativos que positivos conotando sentimento negativo e aqueles com a mesma quantidade de termos positivos e negativos ou em os quais nenhum termo polarizado foi reconhecido, classificou- se como tendo não tendo polaridade ou com polaridade neutra.
O resultado da aplicação do método de mineração pode ser visualizado na Tabela 5.3.
Note que os resultados estão aquém de os métodos do estado da arte na área -- os principais trabalhos citados no Capítulo 3, que possuem uma medida F entre 60% e 70% para o caso do Twitter.
O principal fator de impacto é ainda a abrangência do método, pois métodos baseados em dicionários são bastante rígidos.
Além de as deficiências do método em si, percebemos, com a análise dos erros que um agravante nos resultados foi a constituição do corpus.
A o analisar os tweets usados para avaliar o método percebeu- se que 15% dos textos estavam na língua espanhola -- como o exemplo abaixo -- o que nos fez perceber que o reconhecimento de língua da API do Twitter não é perfeito.
&quot;em o me traje el cargador&amp; fail «Além disso, muitos dos tweets são essencialmente sentenças com informações factuais com meta-informação de opinião expressa por as hashtags&amp; win ou&amp; fail -- que foram excluídas do léxico nesse experimento.
A opinião é, então, expressa por as hashtags que usamos para construir o corpus.
Excluindo- as, as opiniões desses tweets poderiam ser classificadas como opiniões implícitas -- na terminologia de Liu -- um tipo de opinião que não nos propomos a tratar.
Um exemplo desse tipo de tweet pode ser visto abaixo:
&quot;comprei um pingo d'ouro ofereci pra todo mundo e ninguém quis&amp; win «Além disso, descobrimos que cerca de 2% dos tweets do corpus são SPAM que utilizam a hashtag&amp; fail como abaixo:
&quot;hora certa 18:10 em brasilia&amp; time&amp; fail&amp; horacerta visite agora nosso chat Para avaliar o método sub-sentencial de Mineração de Opinião, utilizamos o corpus TwitterSentiment -- manualmente anotado como discutido acima.
De os 1000 tweets anotados do corpus TwitterSentiment, nós selecionamos todas as expressões opinativas anotadas nos textos, totalizando 130 exemplos.
Para cada expressão, consultou- se a sua presença no léxico de opiniões OpLexicon.
Se o léxico contiver a expressão anotada, as polaridades da anotação e do léxico são comparados, caso contrário, o método classifica a expressão como não-opinativa.
O resultado da identificação de polaridade pode ser visualizado na Tabela 5.4.
Nota- se que, apesar de a precisão do nosso método comparável com métodos mais robustos, como o Twittómetro.
A abrangência, entretanto, ainda é bastante reduzida.
Não é grande surpresa, por tratar- se de um método baseado em dicionários.
Alguns dos problemas observados resultam do escopo limitado das expressões do OpLexicon -- em geral constituídas por palavras ou bigramas -- e pelo modo de comparação -- baseado na presença de a expressão completa no léxico.
De esse modo, expressões como &quot;rápido e eficiente «não são marcadas como positivas, apesar de ambos os adjetivos da expressão estarem marcados com polaridade positiva no léxico.
Um método de composição de opiniões poderia ser utilizado para lidar com essas expressões complexas, outras como &quot;O que seria de nós «sem «são, entretanto, mais difíceis e acreditamos que somente através da extensão do léxico poderemos identificar e tratar tais opiniões.
Outro caso muito comum foi o uso de expressões muito particulares de contexto, de região ou do autor como nas expressões &quot;tá dando águia «que expressa uma opinião negativa quanto a entidade &quot;Tweetdeck «na sentença abaixo.
&quot;Tweetdeck tá dando águia aqui no linux:
P embaralhando as letras nas colunas:
P&amp; fail &quot;ou ainda, «expressando uma opinião positiva em relação a a entidade &quot;Cristovão Colombo «na sentença «Qual o melhor navegador?
() Firefox.
() google Chrome.
() Internet Explorer.
Cristóvão Colombo. «Acreditamos também que a associação de nosso método com a aplicação de regras sintáticas -- ou pseudo-sintáticas -- ou ainda um método de aprendizagem pode melhorar esses resultados, aprendendo contextos indicadores de opinião e a compor tais opiniões parciais na expressão opinativa.
Reconhecimento de Entidades Nomeadas Utilizamos para o treino do Reconhecedor de Entidades Nomeadas um conjunto de 900 tweets que foi manualmente anotado por somente um anotador, seguindo as mesmas estratégias de anotação para entidades da Seção 5.1.
Esses dados foram coletados usando a TwitterAPI buscando tweets em língua portuguesa contendo as expressões &quot;google «ou &quot;cielo».
O conjunto de textos possui 1459 entidades nomeadas, sendo, de entre elas, 99 constituídas por mais de uma palavra.
Avaliou- se o método discutido no Capítulo 4, inicialmente, utilizando validação cruzada com cinco camadas obteve- se o resultado mostrado na Tabela 5.5.
Note que os baixos índices para a etiqueta &quot;I «(Inside) refletem sua infrequência nos dados apenas 53 casos de EN constituída de 3 ou mais palavras, e.
g &quot;Google Adwords Express».
Devido a anotação ter sido realizada por somente um anotador -- sendo assim sujeita a muito viés -- e querendo investigar o papel da mudança do domínio dos textos na performance do reconhecedor, utilizamos o TwitterSentiment como conjunto de testes no reconhecedor treinado com os dados de desenvolvimento, discutidos anteriormente.
A comparação foi feita da seguinte maneira:
A anotação de entidades do TwitterSentiment foi inicialmente convertida para o esquema de anotação Bilou -- ignorando as classificação das entidades entre os tipos Pessoa, ORG, Produto e LOC;
Os textos -- sem a anotação convertida -- foram anotados por o sistema de reconhecimento de entidades treinado com os mesmos dados discutidos na Tabela 5.5;
as etiquetas emitidas por o sistema para cada palavra foi, então, comparada à etiqueta obtida da anotação manual, obtendo os valores mostrados na Tabela 5.6.
Evidenciamos assim que, como esperado, a mudança de domínio parece ter impacto significativo no reconhecimento de entidades multi-palavras.
Um problema percebido ao se reconhecer entidades com mais de uma palavra reside, principalmente, nos textos referentes à entidade &quot;Google «e seus produtos (cerca de um terço do corpus).
A principal dificuldade para tal caso é que a palavra &quot;google «aparece muito frequentemente como uma entidade unitária -- referindo- se comumente à empresa ou à página de busca -- ou como o início de uma entidade composta -- como em &quot;Google Adsense», &quot;Google Search», Google Docs», etc -- em contextos muito similares.
Além disso, essas palavras -- &quot;Search», &quot;Docs», etc. -- aparecem frequentemente nos textos também como entidades unitárias -- e dada a alta ocorrência da palavra &quot;Google «como uma entidade unitária em particular -- o reconhecedor tende a classificar tais entidades multipalavras (e.
g &quot;Google Docs&quot;) como uma sequência de duas entidades unitárias, ocasionando grande erro.
Reconhecimento de Referências em Análise de Sentimentos Para analisar a performance do resolvedor de referência utilizamos o corpus TwitterSentiment, manualmente anotado quanto a as Entidades Nomeadas e às opiniões que as referenciam.
Fizemos duas avaliações do método:
Uma considerando a perfeita identificação das entidades e das expressões opinativas, para avaliar o método de resolução sem influência dos erros causados por os outros dois, e uma seguindo o framework estabelecido no capítulo anterior, para analisar a performance do método proposto como um todo.
A anotação de opinião é relativamente infrequente nos textos, dado que em 1000 textos anotados, somente 130 anotações de opinião foram feitas.
Com elas, utilizamos validação cruzada em 10 camadas no método de resolução, obtendo a matriz de confusão ilustrada na Tabela 5.7.!!
Muito massa!!!»
Um atributo que é muito importante no modelo treinado parece ser a distância entre a expressão e sua referência.
De fato, muitos dos casos expressão-entidade que o sistema classifica como não relacionados estão separados por uma grande quantidade de caracteres, como no exemplo abaixo.
Outros, mais frequentes, em os quais o sistema classifica como relacionados quando a expressão e o candidato a referência estão próximos.
&quot;Extamente. RT@ USER:
Maldito 11.10 bom&amp; fail», Expressão:
&quot;Maldito», &quot;Candidato&quot;:
&quot;linux», Resposta:
False De fato, o sistema tende a associar a opinião com a entidade mais próxima em posição anterior à expressão, como é o caso de.
Note que, apesar de a identificação de referência possuir uma medida F bastante baixa, percebe- se que muitos dos erros foram cometidos por a quantidade de termos polarizados encontrados na etapa de Análise de Sentimentos.
Como a quantidade de termos polarizados referindo- se a uma entidade é extremamente mais infrequente que aqueles que não se referem -- e no conjunto de treino aqueles que não se referiam a entidade alguma não foram marcados -- há uma tendência natural do classificador relacionar mais pares termo-entidade, causando a baixa precisão.
Um exemplo desse tipo de fenômeno pode ser visto abaixo, em o qual o autor identifica seu estado privado em relação a um evento, mas não expressa uma avaliação da entidade mencionada no texto:
&quot;pense me uma pessoa feliz pq finalmente consegui instalar o drive do moden no linux&amp; win «Perceba ainda que a abrangência do reconhecimento de referências é alta, o que indica que o sistema, em geral, identifica as opiniões verdadeiras.
Como a precisão dos casos de não referência é quase perfeita -- 0,99 -- e levando em consideração que, dentro de o processo de inteligência, o analista necessariamente precisará estudar os resultados do método para identificar inteligência, nosso método potencialmente reduz seu trabalho manual, sem esconder informação relevante para a sua análise.
Considerações Finais Este trabalho apresentou um conjunto de métodos visando auxiliar a aplicação processos de Inteligência Competitiva através da aplicação de técnicas de Análise Automática de Texto, Processamento de Linguagem Natural e Extração de Informações.
A principal construção desse trabalho é um método sub-sentencial de Análise de Sentimentos focado em entidades para os textos do Twitter a partir de as seguintes tarefas:
Análise de Sentimentos (As), Reconhecimento de Entidades Nomeadas (REN) e Reconhecimento de Referência de Opiniões.
Nosso trabalho surge da necessidade de ferramentas de auxílio para análise da resposta do mercado consumidor a um dado produto ou marca explorando o conteúdo das mídias sociais e da constatação que as ferramentas de Análise de Sentimentos atualmente disponíveis não tratam satisfatoriamente o problema da identificação de referência da opinião.
Os resultados obtidos através das avaliações feitas no Capítulo 5, apesar de poderem ainda ser melhorados, considerando o foco do trabalho e o panorama atual das ferramentas para tanto, avaliamos que nossos resultados são satisfatórios e mostram a viabilidade do método aqui proposto.
Consideramos ainda que nosso estudo foi, como um todo, satisfatório como um estudo inicial a diferentes problemas ainda inexplorados ou pouco explorados para a língua portuguesa e a quantidade de recursos gerados e de métodos testados para esses problemas.
Atingimos nesse trabalho diversos problemas como a Análise de Sentimentos sentencial e subsentencial em dados do Twitter, para o qual atingimos uma performance de cerca de 0,5 e medida F para o caso sentencial e cerca de 0,3 para o caso sub-sentencial -- inerentemente mais difícil.
Além disso, produzimos um reconhecedor de entidades nomeadas especializado para os textos do Twitter em Português, atingindo uma performance de 0,70 de medida F para entidades de nomes simples.
Por fim, desenvolvemos ainda um método de detecção de referências de opiniões a entidades mencionadas em texto -- com medida F de 0,70 -- além de um léxico e um recurso dourado de análise de sentimentos sub-sentencial com textos provenientes do Twitter para a língua portuguesa.
Nosso trabalho apresenta um avanço às estratégias apresentadas em que utiliza um método sentencial de Análise de Sentimentos e não detecta quais entidades estão sendo mencionadas num tweet.
Assemelha- se bastante ao trabalho de Silva Que utiliza padrões lexicossintáticos para detectar opinião (sub-sentencial) no domínio da política e ao de Ding Que analisa fóruns online sobre produtos.
Diferentemente do primeiro, o nosso não se baseia num domínio específico e, diferentemente do trabalho de Ding, nós utilizamos o Twitter como fonte -- muito mais ruidosa -- e analisamos a nível de entidade, não de atributo, o que, cremos, possibilita avanços mais significativos em performance, que um nível tão granular quanto o proposto por esses autores.
Consideramos que a Análise de Texto é uma importante área com vasta aplicação a problemas reais e com resultados práticos para serem aplicados no mercado.
Esse trabalho coloca- se como um exemplo para a aplicação dos métodos que compõem tal área à Análise de Mercado e Inteligência Competitiva.
Contribuições Em essa seção relacionamos algumas das contribuições deste trabalho ao contexto acadêmico.
São elas:·
Contribuições principais ­ Método de Análise de Sentimentos Subsentencial focado em entidades para o Twitter;·
Recursos ­ Léxico de Sentimentos independente de domínio para o Português Brasileiro;
Nomeadas: CineCorpus, TwittEntity e TwitterSentiment;·
Artigos e Trabalhos Relacionados STIL-2011 em Cuiabá contendo sobre a criação do léxico de sentimentos -- correspondendo ao trabalho de final de 2010 e início de 2011.
Propor 2012 contendo os resultados dos experimentos de classificação de sentimentos no Twitter, correspondendo ao trabalho do primeiro semestre de 2011 ­ Experimentos diversos com membros do laboratório e colaboradores externos que geraram mais 2 artigos publicados com temas relacionados.
Trabalhos Futuros Listamos aqui algumas das ideias que surgiram durante o trabalho e que não puderam ser realizadas que, pretende-se, tornem- se trabalhos futuros.
Pretendemos, primeiramente, melhorar o método de Análise de Sentimentos utilizando informação pseudo-sintática e discursiva além de experimentarmos uma estratégia que combine o método baseado em léxico e heurísticas -- tais quais a de -- e um algoritmo de aprendizagem de máquina.
É interessante também implementar o método de baseado em co-training para Reconhecimento de Entidades Nomeadas utilizando uma implementação diferente do classificador CRF para Python.
Já que com esse método pode- se especializar o reconhecedor para diversos domínios sem necessariamente precisarmos anotar uma grande quantidade de tweets de treino.
Por fim, acreditamos que o método de resolução de referência pode ser ainda mais poderoso se combinado com ontologias de domínio, ao permitir mapear não somente a entidade a que a opinião se refere, mas também quais de seus atributos estão sendo avaliados.
