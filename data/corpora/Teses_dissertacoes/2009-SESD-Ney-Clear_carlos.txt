A grande quantidade de funcionalidades integradas aos equipamentos digitais atuais, como telefones celulares, handhelds, consoles de jogos e smart phones, vem criando diversos desafios a serem superados por os projetistas destes sistemas.
Entre estes desafios pode- se citar o aumento do desempenho e a flexibilidade, a diminuição da potência consumida e a redução de custos.
As atuais tendências para desenvolvimento de sistemas complexos apontam para o uso de sistemas multiprocessados integrados num único chip (do inglês, Multiprocessor Systems-on-Chip -- MPSoCs).
MPSoCs são considerados uma solução apropriada para a realização de sistemas eletrônicos digitais de alta complexidade.
A alta capacidade de computação paralela sozinha justifica tal afirmativa.
Para utilizar eficientemente o grande número de recursos existentes em MPSoCs se faz necessária a exploração do espaço de projeto em alto nível de abstração, de forma a avaliar diferentes alternativas de implementação em tempo adequado de desenvolvimento.
Diversos são os esforços realizados tanto por a academia quanto por a indústria para superar os desafios inerentes ao desenvolvimento de tais sistemas.
Entre as propostas consideradas para superar os desafios a maioria capitaliza no uso de duas técnicas:
O aumento do reuso de módulos IP e o aumento do nível de abstração em que se faz a captura inicial do projeto.
O uso de MPSoCs é uma forma natural de aumentar o reuso de hardware e software.
O presente trabalho aborda a modelagem de MPSoCs endereçando a segunda destas técnicas:
Aumento de abstração na captura do projeto do sistema.
Disponibiliza- se um modelo funcional em alto nível de abstração do hardware do sistema multiprocessado HeMPS, desenvolvido no ambiente comercial System Studio da empresa Synopsys.
A modelagem abstrata proposta propicia acelerar o tempo de simulação do sistema e permite flexibilidade aumentada na exploração do espaço de projeto de aplicações sobre o sistema HeMPS.
O modelo gerado inclui múltiplas instâncias de um processador RISC, o Plasma, e uma rede de comunicação intrachip, Hermes, e módulos de hardware acessórios.
O processador é modelado a partir de um simulador do conjunto de instruções, e a rede é descrita no nível de abstração de transação.
A modelagem inclui também parte de um núcleo de sistema operacional multitarefa executando sobre os processadores do sistema HeMPS.
Resultados iniciais mostram um ganho de até três ordens de magnitude em termos de tempo de simulação, para o processador do sistema, quando comparado à simulação RTL deste.
Palavras Chave: Modelagem abstrata, MPSoC, multiprocessamento, multitarefa, NoC.
Com o desenvolvimento da tecnologia, sobretudo a digital, uma vasta quantidade e variedade de sistemas tecnológicos têm invadido nosso cotidiano.
Muitos equipamentos fazem uso de alta tecnologia como meio de viabilizar o seu funcionamento.
As funcionalidades oferecidas por os equipamentos digitais vêm evoluindo rapidamente.
Um claro exemplo é o telefone celular, cuja principal característica, permitir a realização de chamadas telefônicas de forma móvel, alia- se a outros recursos incorporados ao aparelho, como agenda e calculadora, acesso à Internet, etc, tornando- se cada vez mais partes essenciais deste tipo de telefone.
A grande quantidade de funcionalidades integradas a equipamentos digitais atuais gera constantes desafios a serem superados por os projetistas.
Entre os vários desafios que se apresentam como críticos ao projetar novos sistemas, cinco são freqüentemente destacados:
Gerenciar o aumento do desempenho e flexibilidade;
Manter a confiabilidade do sistema;
Aperfeiçoar o uso da área de silício;
Gerenciar a crescente complexidade de projeto;
Evitar o aumento ou, se possível, reduzir o tempo necessário para projeto e verificação do sistema visando:
O acréscimo de complexidade tipicamente aumenta a demanda de tempo para o desenvolvimento de novos produtos.
Por outro lado, as pressões de mercado estão forçando a diminuição deste tempo para dispositivos mais complexos, atingindo- se o conhecido problema da lacuna de produtividade em projeto (do inglês design productivity gap).
A lacuna de produtividade ocorre devido a a exigência de aumento da capacidade de produção não acompanhada por a capacidade de projetistas em aproveitar os recursos das tecnologias frente a o avanço destas, a qual imprime circuitos integrados cada vez mais densos.
Duas maneiras fundamentais para atender os desafios citados são o aumento da reutilização maciça de hardware e software de componentes, durante o projeto de sistemas embarcados complexos, e uso de sistemas multiprocessados num único chip (MPSoC).
MPSoCs têm sido crescentemente considerados como a solução mais apropriada para a realização de sistemas eletrônicos digitais de alta complexidade.
Porém, para que estes sistemas sejam viáveis precisam ser projetados, simulados e verificados, devendo operar conforme a sua especificação de requisitos.
Atualmente, o paradigma de projeto mais empregado baseia- se na captura de descrições de sistemas no nível de abstração de transferência entre registradores (do inglês, Register Transfer Level ou RTL).
Entretanto, o projeto partindo de descrições RTL não oferece suporte adequado para o desenvolvimento de sistemas muito complexos Outra maneira de enfrentar os desafios citados anteriormente vem sendo proposta tanto na indústria quanto na academia, como forma de dar suporte à superação dos desafios existentes.
Basicamente esta maneira pode ser resumida conforme afirmam Cai e Gajski:
O nível de abstração deve ser elevado acima de o RTL como forma de manter a produtividade no desenvolvimento de projetos e tratar a crescente complexidade de SoCs e MPSoCs, levando a ganhos de produtividade de várias ordens de grandeza, em termos, por exemplo, de tempo de simulação.
O presente trabalho aborda a modelagem abstrata de MPSoCs como forma de aumentar o desempenho do processo de validação por simulação de sistemas multiprocessados.
Isto é obtido utilizando- se de um nível de abstração localizado acima de o RTL, aplicado a cada componente modelado do MPSoC.
O processo de modelagem abstrata é restrito aqui sobre tudo ao hardware de um MPSoC específico, denominado HeMPS.
Outra restrição imposta ao trabalho é o uso de uma ferramenta de modelagem comercial específica, o ambiente System Studio da Synopsys.
A justificativa para uso deste ambiente de desenvolvimento se dá por a sua disponibilidade e relativa facilidade para realizar a captura e modelagem abstrata dos componentes considerados fazendo uso da linguagem SystemC.
Motivação Entre as motivações do presente trabalho destaca- se:
O presente trabalho tem por principal objetivo disponibilizar uma descrição executável contendo módulos compatíveis com o hardware do sistema HeMPS, descritos em níveis de abstração mais elevados que o RTL.
A descrição executável resultante deste trabalho tem como fim ser um modelo que permite o desenvolvimento e teste de software escrito para a arquitetura HeMPS de forma mais eficiente.
Modelo conceitual A Figura 1 apresenta o modelo conceitual utilizado como base para este trabalho.
Ela mostra o diagrama de blocos do sistema HeMPS, um MPSoC composto de elementos homogêneos de processamento, infra-estrutura de interconexão baseada numa NoC e um repositório de tarefas contendo aplicações que são distribuídas por o processador mestre (MP) aos processadores escravos (SL).
O elemento de processamento do sistema HeMPS, Plasma-IP SL, por sua vez, inclui um processador, uma memória local, um controlador de acesso direto a memória e uma interface com a NoC.
O software aqui considerado pode ser definido em duas classes:
O sistema operacional executado em cada processador, microkernel, e o conjunto de tarefas a serem executas de forma distribuída nos processadores escravos, contidas inicialmente no Repositório de Tarefas.
Conforme já mencionado, o objetivo deste trabalho prioriza a modelagem do hardware do sistema HeMPS.
Entretanto, com o intuito de gerar um modelo capaz de executar ao menos parte do microkernel, os módulos produzidos foram validados através do uso do próprio software do sistema.
Repositório de Tarefas.
Objetivos Esta Seção apresenta os objetivos do presente trabalho.
Inicialmente são apresentados os objetivos estratégicos:
Para alcançar os objetivos estratégicos, propõem- se os seguintes objetivos específicos:
Organização do documento O restante desta dissertação está organizado conforme descrito a seguir.
São abordados trabalhos que realizam a modelagem tanto de elementos de comunicação como elementos de processamento.
São apresentados os dois principais formatos usados para modelagem de sistemas e uma introdução às principais características do ambiente gráfico da ferramenta.
A partir de o capítulo 4 inicia- se a apresentação do processo de modelagem dos três principais módulos do sistema HeMPS.
Em este Capítulo apresenta- se a modelagem do subsistema de processamento (Plasma).
O Capítulo introduz as características do ISS, utilizado como base para a modelagem e apresenta as fases de integração e modelagem executadas para gerar o elemento de processamento.
Por fim, o Capítulo 9 apresenta as conclusões do presente trabalho e sugestões de trabalhos futuros.
Embora muito seja comentado no meio industrial e na academia sobre a modelagem abstrata de sistemas e apesar de a disponibilidade de ferramentas comerciais poderosas dando suporte a este tipo de modelagem, não é tarefa simples obter informações sobre fluxos baseados na captura de projeto em alto nível de abstração.
Esta Seção apresenta alguns trabalhos encontrados na literatura sobre o tema.
Revisão de trabalhos prévios Kogel e Bussaglia propõem uma metodologia para realizar a exploração arquitetural de sistemas computacionais descritos em SystemC fazendo uso do ambiente System Studio.
O principal objetivo perseguido por os Autores é definir uma arquitetura de sistema que permita oferecer desempenho, flexibilidade e baixo consumo de potência, e que atenda às especificações de áreas de aplicação tais como comunicação wireless, redes de computadores e processamento de dados multimídia.
Os Autores consideram dois domínios durante o fluxo de projeto:
Especificação e implementação.
Eles propõem também a consideração de um domínio intermediário, denominado nível de sistema (do inglês System Level).
Em o domínio de especificação, os requisitos são estabelecidos e as funcionalidades necessárias definidas, gerando um documento de especificação do sistema.
Inicia- se por os procedimentos de captura e particionamento das funcionalidades, com o objetivo de gerar o modelo funcional do sistema.
O próximo passo é gerar o modelo abstrato da arquitetura a partir de o modelo funcional.
A fim de permitir a captura das funcionalidades e definir o mapeamento da arquitetura abstrata, estas funcionalidades são particionadas em módulos SystemC.
Para imprimir maior rigor metodológico, alguns critérios são usados na definição do mapeamento, incluindo a avaliação da troca de informações entre módulos e a análise de localidade de algoritmos.
Como resultado é gerado um modelo mapeado para a arquitetura num nível de abstração superior ao RTL, porém mais detalhado que a especificação original.
O domínio de implementação objetiva elaborar a arquitetura de hardware, conciliando restrições tais como consumo, área do circuito e velocidade.
A partir de aí segue- se fluxo convencional de desenvolvimento.
Os Autores demonstraram a possibilidade do uso de metodologias de projeto em nível de sistema (em inglês System Level Design ou SLD) no desenvolvimento de SoCs, aplicando- as via uso de ferramentas comerciais, no caso o System Studio.
Os resultados finais demonstram a redução de linhas de código escritas e aumento do desempenho da simulação em cerca de duas ordens de magnitude quando comparado a uma captura a partir de descrição RTL.
Jang Apresentam uma metodologia de modelagem de SoCs em alto nível de abstração, que permite projetar, verificar e validar sistemas complexos, além de possibilitar a exploração da arquitetura.
O modelo abstrato criado baseou- se num modelo RTL já implementado e sintetizado, em o qual foi detectado baixo desempenho na comunicação.
A implementação abstrata foi desenvolvida com precisão próxima ao modelo RTL existente e comparada a última.
O desenvolvimento, verificação, validação e posterior exploração da arquitetura foram realizadas através do uso do ambiente System Studio.
Módulos de processamento baseados no processador ARM e no barramento AMBA foram providos por a biblioteca DesignWare.
Os projetistas que desenvolveram a versão RTL também implementaram a versão abstrata do sistema.
A modelagem se baseou no SoC S3 C2510, que corresponde a um microcontrolador de rede para sistemas baseados no padrão Ethernet, desenvolvido por a empresa Samsung, eliminando os módulos não diretamente relacionados à funções de tradução de endereços de rede (em inglês Network Address Translation ou NAT).
Os módulos foram projetados usando modelos arquiteturais (SystemC) com metodologia de modelagem Tl.
Também foram testados quanto a a funcionalidade, a partir de a execução de aplicações simples.
O mesmo modelo abstrato, além de permitir verificar a fonte relacionada ao baixo desempenho detectado na versão RTL, permitiu aos projetistas realizarem testes considerando diferentes variações da arquitetura via simulação.
O modelo de alto nível disponibilizou aos projetistas uma plataforma básica para ser usada no desenvolvimento e avaliação de futuros produtos.
Permitiu avaliar problemas ocorridos na versão RTL previamente sintetizada e atingiu velocidades de simulação superior a uma centenas de vezes se comparado à simulação da versão RTL.
Benini Propõem um ambiente para exploração e simulação de MPSoCs baseado em SystemC 1.0.2, denominado MPARM.
O ambiente contém seis componentes:
Modelos de processador ARM, modelos de barramentos AMBA, modelos de memória, suporte à programação paralela, sistema operacional uCLinux e ferramentas para desenvolvimento em linguagem C (Gnu toolchain).
Outra característica do ambiente é o encapsulamento de um ISS ARM desenvolvido em linguagem C+, fazendo uso de um wrapper SystemC.
Segundo os autores o ambiente permite a exploração de diferentes arquiteturas de hardware e a análise de padrões de interação entre processadores, meios de armazenamento compartilhados e meios de comunicação.
Segundo os Autores, isto permite definir métricas de desempenho, como média de ciclos de espera por o barramento de acordo com o tamanho da cache, como esclarecem os resultados apresentados no artigo.
Beltrame Propõem uma plataforma de alto nível para modelagem e simulação de MPSoCs baseada em SystemC-TL e Python, denominada ReSP.
Conforme os Autores, a integração da linguagem Python junto à biblioteca SystemC aumenta a capacidade de modelagem e simulação.
Os mesmos Autores apresentam numa evolução desse trabalho, uma metodologia para exploração de espaço de projeto em alto nível de abstração de plataformas reconfiguráveis.
Esta metodologia utiliza a plataforma ReSP estendida para trabalhar com arquiteturas dinamicamente reconfiguráveis de modo a gerar um perfil da aplicação.
A partir deste perfil as rotinas de maior custo computacional, como laços aninhados, são identificadas e migradas para hardware de forma dinâmica.
A arquitetura sobre a qual a metodologia é aplicada é composta por seis componentes:
Quatro processadores ARM, um FPGA, dois bancos de memórias RAM, um mecanismo de configuração (do inglês Configuration Engine, CE), (v) um gerenciador de configuração (do inglês Reconfiguration Manager, RM) responsável por interceptar as requisições das funcionalidades implementadas em hardware e desviar- las para o CE, e um barramento de comunicação.
Nikolov Apresentam uma plataforma composta por a ferramenta ESPAM (do inglês, Embedded System--level Platform Synthesis and Application Mapping) conjuntamente ao fluxo de projeto ilustrado na Figura 2 para automatizar a programação, implementação e o projeto de MPSoCs.
Essa plataforma recebe como entrada especificações em alto nível de abstração e gera uma plataforma MPSoC especificada em VHDL sintetizável, além de realizar o mapeamento da aplicação C/ C+ sobre os processadores da plataforma.
Segundo os autores, esta metodologia permite ao projetista desenvolver um sistema multiprocessado em menos tempo, reduzindo portanto a lacuna de produtividade de projeto.
A ferramenta ESPAM recebe três tipos de especificações como entrada:
Especificação de plataforma:
Descreve a topologia de uma plataforma multiprocessada em a qual a comunicação ocorre através de canais FIFO;
A plataforma foi validada através do desenvolvimento e programação de sistemas multiprocessados que executam as aplicações Sobel, DWT e M-JPEG considerando uma imagem de 128x128 pixels.
Para as aplicações Sobel e o DWT foram utilizados três processadores Microblaze e para a M-JPEG quatro processadores, conectados por uma rede ponto a ponto.
Os sistemas multiprocessados foram comparados com um sistema monoprocessado usando Microblaze ou PowerPC, indicando ganhos de desempenho da ordem de 2,2 vezes para Sobel, 2,1 para DWT e 3,75 vezes para M-JPEG.
Moreno Adotam três níveis de abstração para projetos de MPSoCs, quais sejam:
Arquitetura do sistema (do inglês System Architecture, SA), arquitetura virtual (do inglês Virtual Architecture, VA) e preciso em nível de transação (do inglês Transaction Accurate, Te a).
De os três níveis, nos níveis VA e Te a propõem- se a exploração da arquitetura do MPSoC, tendo sido ali que os autores descreveram modelos de NoC, os quais foram inseridos no fluxo de projeto MPSoC baseado no ambiente Simulink.
Os modelos de NoC propostos permitem avaliar o desempenho da arquitetura de comunicação através da variação de parâmetros durante a simulação do sistema e inserir definições abstratas de uma NoC no fluxo de projeto proposto originalmente em.
A tarefa básica para integrar os modelos NoC ao fluxo de projeto MPSoC é a modelagem do sistema.
Esta fase é composta de três passos:
A inserção dos modelos de NoCs no fluxo de projeto MPSoC permitiu a exploração da arquitetura da NoC e também estimar características relacionadas à implementação, além de permitir obter informações importantes para a tomada de decisão sobre o desenvolvimento da arquitetura de comunicação do sistema a partir de os modelos propostos.
Ost Apresentam uma técnica para avaliação de características de MPSoCs com comunicação baseada em NoCs, reduzindo o tempo de simulação a partir de o aumento do nível de abstração em que o sistema é descrito, mantendo precisão a nível de ciclo de relógio.
Os Autores propõem uma técnica de abstração dos dados do pacote, denominada PAT (do inglês Payload Abstraction Technique), que permite avaliar o desempenho sob o ponto de vista da latência e vazão, a partir de o uso de simulação e métodos analíticos.
PAT permite obter resultados relativamente precisos mantendo alto nível de abstração, enquanto reduz o tempo total de simulação, devido a o uso de um número menor de eventos de comunicação obtida a partir de a abstração dos dados do pacote.
Em este trabalho, a NoC Hermes é modelada usando dois componentes:
Controle e buffer:
Controle é responsável por a arbitragem da porta de entrada e o roteamento por o repasse de dados;
Buffer é uma estrutura de memória do tipo FIFO, modelada com o uso de máquinas de estado finitas, que controlam o fluxo de dados.
Também permite avaliar latência e vazão aproximadamente 2.3 vezes mais rápido quando comparado ao modelo de referência, RTL.
Questões relativas a congestionamento de tráfego não foram observadas, podendo gerar algum impacto sobre os resultados.
Indrusiak Apresentam uma abordagem para dar suporte à exploração do espaço de projeto de arquiteturas de interconexão usando NoCs.
Os Autores visam criar modelos abstratos de NoCs e definir níveis de abstração adequados acima de o nível RTL.
A idéia básica é partir de um modelo NoC RTL e gerar um modelo orientado a atores por a análise de interações, cujo o espaço de projeto será validado e explorado de forma a chegar a um modelo RTL otimizado em relação a o primeiro.
Dois aspectos foram considerados importantes na criação de NoCs abstratas:
Abstração estrutural e comportamental.
A abstração estrutural compreende como os subsistemas são divididos e a abstração comportamental envolve como e quando os subsistemas atualizam seu estado interno e interagem concorrentemente com outros subsistemas.
Duas etapas básicas são desenvolvidas:
Modelagem dos atores e análise baseada em interconexão.
A modelagem dos atores separa a funcionalidade, representada por os atores, da comunicação entre componentes, formalizada como comunicam através de tokens de dados, e são gerenciados por um diretor.
A análise baseada em interações é usada para abstrair interconexões da NoC RTL, formalizadas através de diagramas de seqüência (Ds) UML.
Estes descrevem todas as transações ocorridas e definem a ordem parcial entre mensagens, desconsiderando tempo e concorrência.
Esta abordagem facilita a exploração do espaço de projeto, permitindo ao projetista analisar diferentes alternativas para interconexão do sistema de forma interativa, visando atender adequadamente requisitos como desempenho, área utilizada e consumo de potência.
A partir de uma especificação abstrata que descreve as funcionalidades do sistema, o projetista pode gerar modelos Tl do projeto sucessivos em direção a níveis de abstração mais baixos, para tanto o fluxo usa modelos de componentes do repositório da ferramenta.
Conforme o projetista gera novos modelos menos abstratos é possível tomar novas decisões, que serão integradas ao modelo recém gerado, a partir de o modelo anterior.
Após gerar os modelos, implementa- se componentes de hardware e software e cria- se descrições em Verilog no nível RTL.
Este Capítulo introduz os trabalhos relacionados que foram considerados e/ ou utilizados para o desenvolvimento abordado nos Capítulos seguintes.
O Capítulo desenvolve- se em quatro Seções.
A primeira aborda o sistema empregado como ponto de partida do trabalho, a plataforma multiprocessada HeMPS.
Em seguida, as Seções 3.2 e 3.3 discutem os dois principais componentes da plataforma HeMPS, a rede intrachip Hermes e o processador Plasma, uma implementação da arquitetura RISC MIPS-I.
Finalmente, a Seção 3.4 discute a ferramenta de modelagem escolhida para uso neste trabalho, o ambiente CoCentric System Studio da Synopsys Sistema multiprocessado HeMPS O sistema HeMPS é uma infra-estrutura de hardware e software que permite a implementação de MPSoCs.
HeMPS usa o processador Plasma como elemento de processamento do sistema multiprocessado e baseia sua comunicação na infraestrutura de comunicação intrachip Hermes.
O sistema HeMPS emprega multiprocessamento homogêneo e possui uma arquitetura de sistema baseada no paradigma mestre-escravo.
A infra-estrutura de hardware presente no sistema HeMPS é composta basicamente por três módulos:
Hermes, que habilitam a comunicação entre os vários elementos de processamento;
Uma instância de sistema que mostra a estrutura básica de hardware da HeMPS aparece na Figura 4.
Em a Figura 5 podem ser observados os quatro componentes básicos do módulo:
CPU: Denominado MLite, é um processador baseado na arquitetura RISC MIPS-I de 32 bits, discutido na Seção 3.3;
RAM: Corresponde à memória principal local do processador.
Em esta memória são armazenados tanto o código das tarefas locais como os seus dados;
Network Interface: Trata- se da interface de rede, responsável por permitir a comunicação bidirecional entre processador e uma rede externa a este.
Foi desenvolvido para dar suporte à comunicação do Plasma com a rede Hermes e vice-versa;
DMA: É o módulo de acesso direto à memória (do inglês, direct memory access).
O DMA permite aumentar o desempenho no sistema, uma vez que gerência a transferência de grandes blocos de dados entre memória e rede de forma independente do processador.
Com relação a o projeto Plasma original o módulo Plasma usado no sistema HeMPS sofreu alterações a fim de adequar este projeto às necessidades do sistema.
Entre as mudanças destaca- se a inserção do módulo DMA, a inserção da interface de rede Ni e do repositório de tarefas Mem Ext.
Mais detalhes da implementação do hardware do sistema HeMPS podem ser encontrados em, sobretudo no Capítulo 4 desta dissertação.
A infra-estrutura de software existente no sistema HeMPS compreende dois grupos básicos de programas:
Microkernel e tarefas.
O microkernel por sua vez possui duas versões, uma destinada à execução no processador mestre e outra que executa nos processadores escravos.
As tarefas correspondem às aplicações a serem executadas em cada processador escravo, visto que na versão da HeMPS usada aqui o mestre não executa tarefas, apenas o microkernel.
Sinteticamente, a versão mestre do microkernel realiza as seguintes tarefas:
Executa o processo de inicialização (boot) onde todas as estruturas de dados necessárias são criadas e atribuídas;
Realiza a distribuição das tarefas a serem executadas de forma estática ou dinâmica;
Controla o escalonamento das tarefas em execução;
Implementa a comunicação entre os processadores, tanto no nível do microkernel (sistema) quanto no das tarefas; (
v) operacionaliza o tratamento de interrupções tanto de software como de hardware.
A Figura 7 introduz a estrutura em camadas composta de três níveis adotada na arquitetura do microkernel juntamente à função executada por cada nível.
Infra-estrutura de comunicação intrachip Hermes A infra-estrutura de comunicação intrachip Hermes foi desenvolvida no grupo de pesquisa do autor, o Grupo de Apoio ao Projeto de Hardware (GAPH).
O objetivo principal foi atingir largura de banda superior, quando comparada a arquiteturas de comunicação intrachip tradicionais, baseadas em barramento.
Um conjunto de modelos VHDL parametrizáveis foi desenvolvido para dar suporte à infra-estrutura Hermes.
Através do emprego da ferramenta Atlas é possível implementar diversas arquiteturas de comunicação a partir destes modelos.
A infraestrutura de comunicação gerada a partir de os modelos utiliza chaveamento por pacotes onde as mensagens a serem transmitidas são encapsuladas em pacotes roteados de forma individual e continua entre os nodos da rede, sem o estabelecimento prévio de um caminho.
Este mecanismo de comunicação requer o uso de um modo de roteamento para definir como os pacotes devem se mover entre os roteadores.
O modo de roteamento adotado para a comunicação é o wormhole.
O roteamento de pacotes é implementado a partir de o algoritmo XY distribuído, mas existem outras estratégias disponíveis na ferramenta Atlas.
O pacote é dividido em flits, unidades de controle de fluxo utilizadas para sincronizar a transferência de dados.
Apenas os dois flits iniciais possuem informações de roteamento, os flits restantes compõem o conteúdo da mensagem e seguem o caminho determinado por o algoritmo de roteamento escolhido.
A NoC Hermes possui uma topologia regular malha 2D direta, que habilita a implementação do algoritmo de roteamento escolhido, a distribuição dos nodos de comunicação e a inserção de núcleos IP.
Uma instância de rede Hermes ilustrando a topologia pode ser vista na Figura 8.
XY. Assim, 21 indica o roteador localizado na terceira coluna (abscissas) e segunda linha (ordenadas).
Os retângulos N representam os núcleos IP conectados a cada roteador.
O componente básico da infra-estrutura Hermes é o roteador, com estrutura apresentada na Figura 9.
O roteador Hermes possui cinco portas bidirecionais que se conectam com até quatro outros roteadores vizinhos e com um núcleo IP.
O roteador usa armazenamento de dados na entrada e possui lógica de arbitragem interna.
O roteamento é determinístico, distribuído e pode usar caminho mínimo e não mínimo entre origem e destino.
Uma lógica de controle centralizada (Cl na Figura) implementa arbitragem de acesso à lógica de roteamento e o próprio roteamento.
O roteador Hermes contém três estruturas fundamentais:
Cinco portas de conexão (N, S, E, W e L):
Cada porta é composta por dois canais, um de entrada e outro de saída, e um elemento de armazenamento na entrada.
São responsáveis por o controle do recebimento e envio de dados que chegam ao roteador, tanto através de roteadores vizinhos como do núcleo IP local; (
target); O segundo carrega o tamanho da área de dados (size);
A partir de o terceiro flit são enviados os dados (payload).
Seqüência de envio Conteúdo n-1 Destino Tamanho Dado 1 Dado tam-1 Dado tam Estes pacotes são compostos de duas partes:
Cabeçalho (header) e carga útil (payload).
Estes por sua vez são transmitidos por a rede em unidades denominadas flits.
Existem três diferentes tipos de flits:
Destino (target), tamanho (size) e carga útil (payload), os quais são enviados nesta mesma seqüência conforme a Tabela.
A NoC Hermes foi desenvolvida originalmente via descrições RTL.
Ela foi descrita em VHDL e validada por simulação funcional, sendo posteriormente sintetizada com sucesso em FPGAs.
O protocolo de comunicação foi baseado no modelo de referência OSI, usando como de hábito apenas um subconjunto das camadas deste modelo:
Físico, enlace, rede e transporte.
Basicamente cada camada provê, respectivamente, as seguintes funcionalidades:
A NoC Hermes implementa roteadores compostos por cinco portas de comunicação bidirecionais que podem estar conectadas a até cinco dispositivos periféricos, dependendo de qual posição ocupa na topologia.
O caso em que todas as portas são usadas caracteriza- se quando o roteador se encontra inserido no interior da rede, ou seja, não ocupa nenhuma posição de borda quando algumas portas estarão desconectadas.
Por exemplo, na Figura 8 o roteador 11 possui todas as portas conectadas enquanto o roteador 22 possui duas portas não utilizadas (N e E).
A Figura 10 apresenta a janela inicial da ferramenta gráfica para geração automática da infra-estrutura de rede Hermes denominada Atlas, que comporta quatro setores:
Geração da NoC a partir de a ferramenta NoCGen, geração do tráfego, simulação e avaliação.
Estes quatro setores são alcançados a partir de a janela inicial da ferramenta, conforme pode ser observado na Figura 10.
A ferramenta aceita em cada setor certa quantidade de parametrização, permitindo definir características como:
Largura de banda, profundidade de armazenamento de dados na entrada e número de canais virtuais.
O setor de geração de tráfego produz dados para serem injetados na rede, o que permite avaliar diferentes cenários de tráfego.
Em a simulação, os dados gerados são injetados na NoC e a funcionalidade de comunicação é simulada entre os roteadores, conforme o cenário previamente definido.
Em o último setor, avaliação, é possível analisar diversos aspectos de desempenho a partir de gráficos, tabelas, mapas e relatórios gerados automaticamente por a ferramenta, auxiliando a compreensão dos resultados gerados.
Outro trabalho, desenvolvido no grupo do Autor foi a implementação de um modelo em nível de abstração superior em relação a a Hermes RTL, o chamado nível de transação (Tl).
Esta versão foi proposta por Moreno em e utilizou a linguagem SystemC, tendo como objetivo principal disponibilizar uma representação comportamental mais abstrata da rede Hermes.
Em este trabalho, consideraram- se modelos abstratos aqueles desenvolvidos, observando- se menor nível de detalhamento relativo ao existente no nível de transferência entre registradores (RTL).
O modelo abstrato desenvolvido permite a detecção de possíveis erros de projetos em estágios iniciais de desenvolvimento além de prover modelos executáveis completos para a validação da comunicação em SoCs que fazem uso de NoCs como infra-estrutura básica para comunicação.
As características básicas apresentadas na Seção 3.2.1 foram mantidas.
Assim, a compatibilidade entre versões pode ser mantida em vários aspectos.
Os quatro níveis da pilha de protocolos foram mantidos, bem como o tipo de chaveamento (por pacotes) o modo de chaveamento (wormhole) e o algoritmo de roteamento (distribuído, XY).
O roteador contém os mesmos elementos da definição original:
Portas bidirecionais de entrada e saída, área de armazenamento e lógica de controle que constitui um canal de comunicação entre as portas.
Embora esta versão mantenha os componentes básicos da especificação RTL, seguindo a especificação geral definida para este nível, algumas alterações foram realizadas, incluindo que:
A Figura 11 detalha a estrutura interna do roteador implementada neste modelo abstrato.
Mais detalhes podem ser obtidos em e no Capítulo 4 desta dissertação.
Arquitetura MIPS-I de processadores de propósito geral Em o início dos anos 80, as Universidades de Berkeley e Stanford eram alguns dos centos acadêmicos que pesquisavam formas de produzir processadores que atingissem alto desempenho a partir de a execução de instruções simples, porém a freqüências de relógio elevadas.
O paradigma resultante tornou- se conhecido por o acrônimo RISC (do inglês, Reduced Instruction Set Computer).
Um dos resultados deste trabalho foi a Pipeline Stages).
Com o intuito de permitir um melhor entendimento da arquitetura MIPS, apresenta- se a seguir um breve relato da evolução e das características básicas dos principais processadores produzidos com base nesta arquitetura.
As características apresentadas não exaurem todo o desenvolvimento desta família de arquiteturas.
Foram intencionalmente omitidos muitos dos modelos mais recentes, bem como características mais avançadas, uma vez que não são necessários aos objetivos pretendidos e raramente são incluídas em versões embarcadas deste processador.
O conjunto de instruções MIPS foi desenvolvido inicialmente como um projeto acadêmico na Universidade de Stanford através de um grupo de pesquisadores liderado por professor John Hennessy a partir de 1981.
Este projeto se tornou um dos principais precursores da tecnologia RISC.
A arquitetura do conjunto de instruções (em inglês tamanho.
Conforme, esta característica permitiu que seus conceitos fossem assimilados mais facilmente se comparado a arquiteturas irregulares.
Em 1984, foi fundada a empresa MIPS Computer Systems, Inc..
Cujo objetivo foi comercializar a tecnologia desenvolvida no meio acadêmico.
O primeiro processador MIPS comercial lançado foi o modelo R2000 lançado em (em inglês, Memory Management Unit, MMU).
Em 1987 tornou- se disponível o coprocessador aritmético R2010, disponibilizando capacidade superior de cálculos em relação a a versão inicial.
Em 1988 foi lançada uma nova versão de processador, o R3000.
O modelo incorporava duas memórias cache de 32 KB, uma para dados e outra para instruções.
Logo se tornou disponível o co-processador aritmético para esta versão, o R3010.
De o ponto de vista dos programadores este processador era quase idêntico ao anterior, permitindo que o novo modelo pudesse ser rapidamente utilizado.
Entre as versões derivadas do R3000, seguiram os modelos R3400 e R3500 produzidos por as empresas PACEMIPS e IDT, respectivamente.
Estas versões incluíam o co-processador R3010 no mesmo chip.
Outro modelo, o R3900 introduzido por a Toshiba, tornou- se um dos primeiros processadores destinados ao uso em handhelds baseados no Windows CE.
O Mongoose, desenvolvido por a empresa Synova, Inc..
Para o Centro de Vôos Espaciais Goddard da NASA, disponibilizou uma versão expandida do R3000, com o R3010 já incorporado.
Esta versão foi usada em aplicações espaciais empregando métodos de fabricação resistentes à radiação como forma de tornar seus componentes eletrônicos utilizáveis fora de a atmosfera terrestre.
Em 1990 a empresa Bipolar Integrated Technology (Bit, Inc) produziu o modelo R6000, que incluía suporte para uso do ECL (do inglês Extensible Computer Language), linguagem de programação extensível desenvolvida na Universidade de Harvard.
Possuía uma arquitetura de cache com tecnologia Translation Lookaside Buffer (TLB) diferente dos outros modelos da arquitetura MIPS, tendo sido pouco usado.
Em 1991 foi lançada a série R4000 que ampliou o conjunto de instruções para uma arquitetura de 64 bits e a inserção de uma unidade de tratamento de ponto flutuante cache de dados e instruções para 8 KB cada uma, a fim de atingir maior velocidade de relógio.
Em este mesmo ano a Silicon Graphics, Inc. (SGI) adquiriu a MIPS Computer Systems, criando a MIPS Technology, Inc. (MTI), uma divisão da SGI existente até hoje.
Em o início dos anos 90 alguns desenvolvedores de sistemas embarcados, como a Sony, a SGI e a Cisco começam a utilizar processadores MIPS em seus sistemas, tais como dispositivos de rede, vídeo games, PDAs, modems a cabo e DSL, TV digital e roteadores.
A Quantum Effect Devices (QED) desenvolveu o modelo R4650 usado em seu set-top box WebTV.
Os modelos R4600 e R4700 foram usados em roteadores Cisco e nas estações de trabalho Indy de baixo custo da SGI, que posteriormente passaram a usar o modelo R5000, uma vez que sua FPU era mais eficiente que a existente no R4000.
Em 1994 o R4400 ampliou a memória cache para 16 KB e suporte para maior quantidade memória cache nível 2.
Em este mesmo ano foi lançado o R8000, primeira versão superescalar do processador MIPS, executando duas instruções inteiras ou de ponto flutuante e duas instruções para operações em memória por ciclo de relógio.
Em 1995 foi lançado o modelo R10000, mais rápido que o R8000, dispondo de memória cache de 32 KB, tecnologia superescalar e principalmente dispondo da capacidade de execução de instruções fora de ordem.
O R12000 e R14000, lançados respectivamente em 1998 e 2001, basearam- se no R10000, caracterizando- se por menor uso de área de silício e freqüências de relógio mais elevadas.
O último modelo tem suporte para tecnologia de memórias DDR-SDRAM.
Por fim, em 1999 a arquitetura MIPS foi licenciada sob dois grupos básicos:
MIPS32, baseado na ISA MIPS-II com características do MIPS-III, IV e V e MIPS64 baseado no MIPS V. A partir de aí estas duas denominações passaram a caracterizar os futuros de processadores MIPS, desenvolvidos por a MTI ou sob licença desta.
As versões iniciais de processadores MIPS usavam arquitetura de 32 bits, como o R2000 e o R3000.
Versões posteriores passaram a empregar arquitetura de 64 bits com a introdução do R4000.
Durante a evolução da família de processadores diversas revisões do conjunto de instruções (ISA) MIPS foram realizadas, incluindo MIPS-I, MIPS-II, MIPSIII, MIPS-IV, MIPS-V, MIPS32 e MIPS64.
As duas últimas revisões são as especificações atualmente disponíveis para 32 e 64 bits respectivamente.
Todas as revisões são retroativamente compatíveis.
Os primeiros quatro conjuntos de instruções foram introduzidos nos seguintes processadores:
MIPS-I: Modelos R2000 e R3000;
MIPS-II: Modelo R6000;
MIPS-III: Modelo R4000;
MIPS-IV: Modelos R8000 e R10000.
A primeira arquitetura de conjunto de instruções, denominada MIPS-I, foi implementada nos processadores R2000 e R3000.
O conjunto de instruções MIPS-II foi introduzido a partir de o modelo R6000, adicionando instruções como load linked e store conditional, usadas para realizar operações do tipo read-- modify-write de forma atômica e suporte a operações load/ store de 64 bits.
A revisão MIPS-III foi introduzida em 1991 com a arquitetura R4000.
Disponibilizava instruções de 64 bits com inteiros (e registradores de mesma largura de palavra) e uma instrução de raiz quadrada em ponto flutuante.
A ISA MIPS-IV, implementada inicialmente no modelo R8000, adicionou instruções de transferência condicionais e uma instrução de raiz quadrada inversa em ponto flutuante.
A arquitetura MIPS-V foi introduzido em 1994 por a SGI, porém nunca foi realmente utilizada por nenhum processador MIPS.
MIPS32 e MIPS64 foram definições criadas por a SGI em 1999 com o objetivo de melhorar a coerências das definições da arquitetura, além de inserir novas características, principalmente a de tornar o desenvolvimento mais fácil e fornecer melhor suporte à criação de ferramentas de desenvolvimento em ambas as plataformas de 32 e 64 bits.
MIPS32 é um subconjunto de 32 bits da ISA MIPS64, sendo esta última uma extensão da MIPS-V..
MIPS32 e MIPS64 versão 2.0 são extensões opcionais DSP-ASE (do inglês Application Specific Extensions) usadas para aceleração de processamento multimídia como de áudio e de vídeo.
A opção por o uso da ISA baseada em MIPS-I se deu por a decisão de projeto adotada para o sistema HeMPS, a qual selecionou o projeto Plasma como seu elemento de processamento.
Os conceitos básicos relacionados à arquitetura MIPS-I podem ser resumidos por as seguintes características:
MIPS-I dá suporte ao uso de implementações do tipo delayed branch, onde a próxima instrução sempre é executada antes de um desvio condicional.
Assim, a instrução que segue pode ser uma instrução sem efeito (NOP), inserida automaticamente ou a instrução anterior deslocada para após a instrução de desvio.
O conjunto de registradores da arquitetura MIPS-I é constituído por três grupos de registradores de 32 bits distintos:
32 para propósito geral, numerados de 0 a 31, dois para operações de multiplicação e divisão (HI e Lo) e (iii) um contador de programa (PC).
Todos os registradores de propósito geral podem ser usados como fonte ou destino de dados para instruções lógico-aritméticas, acesso à memória e controle de fluxo.
A única exceção é o registrador 0 (zero), não alterável, que possui seu valor fixado em zero por o hardware.
Portanto, operações de leitura deste registrador sempre retornam valor zero e as de escrita são ignoradas, sendo o valor escrito descartado.
O conjunto de instruções MIPS-I divide- se em três formatos básicos, conforme descrito na Tabela 2: As características de cada formato podem ser resumidas como segue.
Instruções com formato R (register):
Inclui instruções lógicas e aritméticas com três registradores, inclusive multiplicação e divisão, instruções de deslocamento de bits, desvio baseados em registrador e instruções de exceções syscall e break.
O campo funct atua como um campo adicional de 6 bits para identificação da instrução.
O campo shamt é usado para indicar a quantidade de bits a ser deslocada em instruções de deslocamento de bits.
Os registradores rs e rt são usados como origem de dados e rd como destino do resultado da operação;
Este valor é acrescentado de 2 bits à esquerda, equivalente a uma multiplicação por 4 devido a o uso de alinhamento de todo programa em endereço múltiplo de quatro.
Isto gera um endereço de 28 bits, que é então concatenando com os 4 bits superiores do PC, ou seja, addr-26 indica o deslocamento em quantidade de palavras não de bytes dentro de a página de memória (de 256 Mbytes) onde se encontra a instrução seguinte à instrução de desvio.
Além de a classificação das instruções MIPS-I quanto a o formato, também se pode dividir o conjunto de instruções quanto a a funcionalidade das instruções.
Existem três classes de instruções, conforme este critério:
Embora os 32 registradores de propósito geral possam ser usados indistintamente para qualquer objetivo, existe uma convenção para uso destes registradores em programação, com o objetivo de padronizar o desenvolvimento de software básico, como montadores, compiladores e carregadores.
Esta convenção é mostrada na Tabela 3.
Estas convenções obviamente não implicam a existência de qualquer estrutura no hardware que as dê suporte a elas.
Usado para acesso à variáveis estáticas ou &quot;extern «(global pointer) Ponteiro para área de pilha (stack pointer) Ponteiro para área de frame (frame pointer) ou registrador adicional para valor preservado (saved) A Tabela 4 reapresenta a convenção para os registradores de propósito geral sob outro formato.
A arquitetura pipeline de cinco estágios pressuposta como natural para a implementação do hardware de um processador MIPS inclui:
Id ­ estágio de decodificação (instruction decode):
Realiza a decodificação da instrução e a leitura dos operandos fonte do banco de registradores;
EX ­ estágio de execução (execution):
Realiza a execução da instrução ou o cálculo de endereço, quando aplicável;
MEM ­ estágio de acesso à memória (memory access):
Realiza o acesso à memória externa;
Wb ­ estágio de escrita do resultado (write back):
Escrita do resultado no banco de registradores.
Para efeito ilustrativo, a Figura 12 apresenta um diagrama esquemático simplificado de um pipeline típico do MIPS, conforme empregado para dispositivos como os MIPS R2000 e R3000.
O projeto Plasma está disponível no Opencores, tendo sido desenvolvido originalmente por Steve Rhoads, baseado nas informações disponíveis no livro de Kane e Heinrich.
Este projeto consiste de uma implementação compatível, embora não completamente, com o modelo R3000 do MIPS, juntamente com uma infra-estrutura de processamento contendo periféricos de apoio, sendo o processador denominado MLite.
O processador MLite executa todas as instruções da arquitetura do conjunto de instruções (ISA) MIPS-I, com exceção das instruções para cálculo de ponto flutuante, uma vez que o módulo co-processador aritmético não está presente no projeto.
As instruções para acesso não alinhado à memória não estão disponíveis no MLite, devido a restrições de uso, pois foram patenteadas por a MIPS Computer Systems em 1986, patente cuja validade é de 20 anos.
O Plasma foi descrito em linguagem de descrição de hardware VHDL contendo os seguintes periféricos, considerando a versão 3.5, a mais recente até o momento da escrita deste documento:
MAC Ethernet; Interface Flash.
Este projeto foi sintetizado em dispositivos FPGA Xilinx Spartan-3 XC3 S200, Spartan-3E XC3 S500 e Altera EP20 K200 EFC484- 2 X. O processador MLite permite executar código nativo da arquitetura MIPS-I gerado a partir de compiladores como Gnu-GCC, tanto em ambiente Linux como MS--Windows.
O diagrama de blocos do processador é apresentado na Figura 13, onde podem ser vistos seus principais blocos funcionais:
O processador MLite foi implementado com um pipeline diferente do padrão adotado na arquitetura MIPS, e possui duas formas de execução:
Uma com dois e outra com três estágios de pipeline, configurável no código VHDL.
Além de os estágios citados, existe outro adicional, usado para operações de leitura e escrita em memória.
Esta implementação difere da definição original do MIPS, uma vez que a organização de memória segue o modelo Von Neumann e não Harvard, como a maioria das implementações do MIPS.
O projeto disponibiliza também um simulador do conjunto de instruções (em inglês Instruction Set Simulator, ISS) escrito em linguagem C. Este simulador permite executar o conjunto de instruções da arquitetura MIPS-I, exceto as já citadas instruções de acesso não alinhado à memória e instruções para cálculo com ponto flutuante.
O simulador é invocado via linha de comando e permite executar programas em formato core dump, ou seja, uma imagem binária do código objeto.
Synopsys System Studio ­ ferramenta de modelagem de sistemas Monografia anterior do Autor, tem como tema um estudo da ferramenta comercial System Studio da empresa Synopsys Inc, conhecida anteriormente como CoCentric System Studio (CCSS).
Conforme o fabricante introduz em seu sítio na internet, esta ferramenta se destina ao desenvolvimento e análise de projetos eletrônicos descritos a nível de sistema (do inglês Electronic System Level, ESL), baseado em modelos e usados na elaboraçào de produtos como telefones sem fio e móveis, modem a cabo e DSL e codecs multimídia.
Segundo a companhia, mais de 50% dos telefones móveis produzidos utilizam algoritmos desenvolvidos no ambiente System Studio.
A ferramenta permite a captura, modelagem e simulação de algoritmos, tanto para software como para hardware em múltiplos níveis de abstração, que podem coexistir e interagir num único espaço de projeto, o que habilita implementar o conceito de cosimulação de hardware e software na prática.
A estrutura do ambiente System Studio pode ser utilizada para o desenvolvimento a captura e a simulação através de ferramentas, metodologias e bibliotecas específicas, que facilitam a implementação de modelos em diversos níveis de abstração e detalhamento.
System Studio permite o reuso de componentes previamente desenvolvidos, além de possuir uma grande quantidade de módulos disponíveis em sua biblioteca de componentes.
A modelagem e simulação permitem descrever software e hardware através da combinação de diversas técnicas e ferramentas que compõem o ambiente de projeto, incluindo:
Um núcleo de simulação, suporte à biblioteca SystemC, controle de fluxo de projeto, construção de protótipos virtuais e exploração arquitetural.
System Studio está dividido em dois domínios principais, cada um refletindo o objetivo principal de projeto a que cada domínio dá suporte:
O domínio algorítmico descreve a funcionalidade de um sistema em nível não temporizado ou implicitamente temporizado.
Os projetos são capturados usando uma combinação de fluxo de dados (do inglês Data Flow, DF) e FSMs hierárquicas estendidas.
Detalhes como precisão em nível de ciclo de relógio e sinais de inicialização (em inglês reset) não são capturados, permitindo que um processo de modelagem mais simples, aumentando a velocidade de simulação e evitando que o projeto sofra restrições demasiadas nas suas fases iniciais.
O domínio arquitetural, baseado em descrições SystemC, captura a arquitetura de um sistema em vários níveis de abstração e granularidade.
Isto habilita prover uma visão global da arquitetura em termos de processadores, memórias, barramentos e componentes específicos para uma dada aplicação (em inglês, Application Specific Integrated Circuits, ASICs).
Além de isto, é possível descrever a arquitetura individual dos componentes existentes sob o aspecto de o fluxo de controle (em inglês Control Flow, Cf) e DF.
Os modelos permitem expressar variações no nível de abstração desde níveis muito altos, apropriados para análise em estágios iniciais do projeto, até modelos de hardware precisos em nível de ciclo de relógio e de pinos.
O ambiente System Studio habilita o desenvolvimento integrado de abordagens arquiteturais e algorítmicas num mesmo espaço de projeto.
O projeto algorítmico, cujo fluxo é ilustrado na Figura 14, consiste de esboços de algoritmos não temporizados ou implicitamente temporizados em vários níveis de precisão, representações de ponto flutuante ou ponto fixo e outros formatos abstratos.
System Studio provê suporte a uma semântica gráfica de captura para grafos de fluxo de dados (em inglês Data Flow Graphs, DFGs) e FSMs.
Em os modelos algorítmicos, a comunicação é modelada através de conexões ponto a ponto entre blocos.
Algoritmos são modelados por a combinação de código e processamento de sinais expressos através do fluxo de dados e FSMs.
Tais implementações ocorrem por o uso de DFGs, implementados sobre modelos DF, para representar fluxo de dados e por o uso de grafos de fluxo de controle (do inglês Control Flow Graphs, CFGs), implementados em modelos OR, para representar fluxo de controle.
Outros dois modelos existentes, And e GATED, são derivações hierárquicas dos modelos anteriores.
Eles podem, portanto, conter tanto DFGs como CFGs.
OR é um modelo usado para fluxo de controle (CFG) que permite especificar um diagrama de transição de estados em o qual as instâncias existentes representam os estados contendo transições entre si;
And é um modelo hierárquico também usado para controle de fluxo, porém possui a capacidade de modelar concorrência, através múltiplas instâncias de CFGs denominadas páginas;
GATED é um modelo hierárquico usado para controle de fluxo.
Ele consiste, porém de uma ou duas páginas e uma condição de gating, que controla qual página deve ser executada e qual deve ser suspensa.
O uso de hierarquia admite a modelagem de projetos complexos.
DFGs de nível superior podem conter, em níveis de hierarquia inferiores, outros DFGs e/ ou CFGs.
Implementações CFG podem conter estados atômicos ou hierárquicos.
Os hierárquicos por sua vez podem conter DFGs ou outros CFGs.
A Figura 15 apresenta o fluxo de projeto arquitetural do ambiente System Studio.
Este tipo de projeto permite verificar software e hardware de forma concomitante, projetar plataformas e explorar arquiteturas a partir de seus componentes básicos tais como elementos de processamento, de interconexão, de armazenamento e periféricos.
System Studio dá suporte à modelagem em Tl, ou seja, à exploração de arquiteturas onde um conjunto de elementos se comunicarem através de canais abstratos.
O uso de modelagem Tl permite aumentar a velocidade das simulações quando comparado a simulações RTL tradicionais, o que reduz o tempo de validação e, portanto, o tempo de desenvolvimento do projeto.
O desenvolvimento de software pode se beneficiar do uso de modelos Tl, uma vez que modelos funcionais podem estar disponíveis em estágios iniciais do desenvolvimento, permitindo que o software da plataforma possa ser desenvolvido e testado mais cedo.
A arquitetura é criada habitualmente fazendo- se uso da linguagem SystemC, embora existam outras possibilidades como C e C+.
Isto leva a uma descrição completa da modelagem em nível de código fonte dentro de o System Studio.
Também podem ser importados códigos previamente desenvolvidos.
Em ambos os casos, cada módulo possuirá uma representação gráfica, que poderá ser utilizada na criação de modelos hierárquicos, compondo novos módulos mais complexos de maneira relativamente simples e rápida.
Existem basicamente dois tipos de modelos usados em projetos arquiteturais:
Modelos primitivos e modelos hierárquicos.
Modelos primitivos são implementados em linguagem SystemC e se caracterizam por ser o modelo de mais baixo nível hierárquico, ou seja, não permite que outros modelos sejam instanciados dentro de um modelo primitivo.
Modelos hierárquicos também são implementados em SystemC, mas permitem que outros modelos, tanto primitivos como hierárquicos, possam ser instanciados dentro deste modelo.
É possível criar estruturas com níveis arbitrários de hierarquia, onde cada modelo é percebido por os modelos que o contêm como uma caixa preta funcional acessível através de sua interface.
Devido a a disponibilidade de descrições de partida em SystemC como o modelo da rede Hermes descrito na Seção 3.2.3, a escolha para a modelagem do hardware proposto neste trabalho recai naturalmente sobre o domínio arquitetural da ferramenta System Studio.
A janela principal da interface gráfica do ambiente System Studio é dividida em cinco áreas principais, conforme pode ser visualizado na Figura 16.
Cada área possui um propósito específico conforme sintetizado a seguir:
Barras de Menu e Ferramentas: Permite executar as ações disponíveis no System Studio sobre arquivos, bibliotecas, modelos, simulações, etc..
A barra de ferramentas è composta de cinco grupos conforme segue:
Janela Área de Trabalho:
Pode conter uma ou mais bibliotecas, dentro de as quais podem existir coleções de modelos ou outras bibliotecas aninhadas, representadas por uma estrutura de árvore expansível em níveis hierárquicos.
Possui quatro seções, cada uma agrupando facilidades distintas.
Apresenta a visualização das bibliotecas e módulos, possuindo duas molduras:
Hierárquica: Provê uma exibição tipo árvore expansível em níveis, que apresenta a distribuição hierárquica dos objetos disponíveis no projeto;
Modelos: Apresentam uma lista dos objetos, normalmente modelos, inseridos na estrutura hierárquica selecionada na moldura hierárquica.
Janela Área de Projeto: Local onde os modelos são desenvolvidos, com visualização gráfica ou textual dos objetos instanciados.
É dividida em três abas interligadas logicamente:
Visualização de interface, visualização de implementação e visualização de símbolos;
Janela de Mensagens:
Apresenta mensagens retornadas por ações realizadas por o System Studio, agrupadas em páginas separadas de acordo com a atividade realizada;
Barra de Status: Apresenta informações sobre o estado atual das ferramentas.
Possui basicamente três abas distintas:
Registro de mensagens, com informações gerais sobre a execução de ações System Studio;
Verificação do projeto com informações sobre processo de verificação sintática de código dos objetos;
Geração de código, com informações sobre a geração e compilação do código fonte dos objetos.
Adicionalmente, criam- se aqui abas para saídas geradas por simulações em execução.
O processo de modelagem e integração do processador MLite ao ambiente System Studio se deu por o uso do ISS disponibilizado junto ao projeto Opencores.
Para tal, duas opções de ISS foram consideradas como base para nortear desenvolvimento:
O ISS Plasma desenvolvido disponível no projeto Plasma do Opencores e o ISS gerado a partir de o uso da linguagem para descrição de arquiteturas ArchC.
A opção finalmente adotada pra o presente trabalho foi o emprego do ISS do Plasma.
Entre os principais motivos que levaram a sua escolha estão:
Maior facilidade em relação a a análise do código fonte, escrito em C e facilidade de acesso a informações a respeito de o projeto, obtidas tanto a partir de a documentação como junto ao seu Autor.
Características do simulador Plasma (projeto Opencores) O ISS Plasma é um simulador comportamental do processador MLite escrito em linguagem C, cujo código ocupa um único arquivo, formado por diversas funções.
Além de a função principal (main), outras sete funções realizam as funcionalidades essenciais à execução do código de máquina MIPS-I..
Adicionalmente, cinco funções dão suporte ao uso de memória cache.
Considerando que o núcleo IP do sistema HeMPS não faz uso deste tipo de memória, esta parte do código não foi considerada na atividade de modelagem e integração do ISS no ambiente System Studio, não sendo portanto abordada neste trabalho.
Os parágrafos seguintes apresentam uma visão geral do ISS Plasma e das características operacionais realizadas por as diversas funções do simulador.
O estado do processador, incluindo o conteúdo dos registradores de propósito geral e o valor do contador de programa, é mantido numa estrutura de dados global e algumas variáveis adicionais declaradas no programa.
Entre os campos da estrutura de dados destacam- se os seguintes:
R: Vetor composto por 32 elementos do tipo long.
Cada elemento do vetor representa um dos 32 registradores de propósito geral;
PC, PC_ NEXT, EPC:
Variáveis do tipo long relacionadas a registradores para endereçamento de instruções.
Os dois primeiros indicam os endereços da instrução que atualmente está em execução e da próxima instrução, respectivamente.
O EPC é utilizado quando de a ocorrência de exceções, indicando o endereço da instrução seguinte ao ponto onde foi gerada a exceção;
HI e Lo:
Variáveis do tipo unsigned long que representam registradores usados os cálculos aritméticos envolvendo multiplicação ou divisão;*
mem: Ponteiro para um vetor do tipo char que representa a memória principal.
Seu tamanho é definido a partir de uma constante contida no código fonte;
MBytes mas pode ser alterado, a partir de uma constante inserida no código.
A estrutura de dados é inicializada com zeros tanto nos registradores como na região alocada para conter a memória principal.
A partir de um arquivo definido como argumento na linha de comando, carrega o código de máquina a ser executado na região destinada à memória.
A mesma função main atribui ao PC o valor inicial 0 (zero).
Finalmente, ela invoca a função de o_ debug para dar continuidade ao processo de execução do código via simulação;
Adicionalmente, outras duas funções são invocadas por a função cycle, mem_ read e mem_ write.
A função mem_ read permite realizar operações de leitura de dados da memória principal.
A função mem_ write realiza operações de escrita de dados nesta memória.
Ambas as funções permitem realizar operações utilizando palavra (32 bits), meia palavra ou byte, conforme a instrução utilizada, por exemplo lh (load half word) determina a leitura de uma meia palavra.
Integração e modelagem do processador Plasma Em a versão atual do sistema HeMPS RTL, além de o processador Plasma outros módulos de apoio estão presentes, como o controlador de acesso direto á memória e a interface de rede, compondo uma infra-estrutura de processamento Plasma, semelhante à versão original do projeto Plasma, porém diferente daquela apresentada na seção 3.3.2.
Assim, a partir deste ponto o termo Plasma será considerado como a infra-estrutura de processamento em a qual está inserido um elemento de processamento denominado MLite.
A infra-estrutura de processamento Plasma do sistema HeMPS RTL é composta por cinco módulos:
Processador MLite, a memória principal, a unidade de comunicação serial UART (do inglês, universal asynchronous receiver-transmitter), a interface com a rede (Ni) e o controlador de acesso direto a memória (DMA).
Os dois últimos módulos foram acrescidos para atender a requisitos de comunicação do sistema, bem como habilitar o uso de uma rede intrachip e a recepção de código para carga no processador através desta rede.
O Plasma abstrato desenvolvido neste trabalho é constituído por sete módulos.
Embora todos estes façam parte da infra-estrutura Plasma, esta Seção irá tratar apenas do processador MLite e da memória principal, denominada RAM.
O critério para tal abordagem se deve ao fato de que os demais módulos estão fortemente relacionados à rede de comunicação, sendo então abordados na Seção 6.2 que trata da modelagem de módulos complementares do sistema HeMPS.
O processo de modelagem ocorreu em três etapas:
Primeira Etapa:
Integração e modelagem do ISS no ambiente System Studio, com objetivo de gerar um modelo abstrato executável do processador neste ambiente.
Este primeiro módulo, MLite, foi desenvolvido com base no ISS Plasma;
Esta separação foi necessária para permitir que se faça acesso à memória de forma independente, uma vez que tanto o processador MLite como o controlador DMA podem ser mestres da memória;
A idéia inicial para integração do ISS no ambiente System Studio foi criar um módulo empacotador (do inglês, wrapper module) que funcionaria como interface para integrar diretamente o código C do ISS.
Entretanto devido a questões técnicas relativas ao ambiente System Studio e à natureza interativa do simulador esta abordagem não se mostrou viável.
Assim, para realizar a integração do código C do ISS e gerar um modelo funcional abstrato do processador MLite foram necessários diversos procedimentos de alteração do código do ISS, conforme descreve- se a seguir.
As definições básicas do código, tais como diretivas, macros, constantes e estrutura de dados foram separadas num arquivo de cabeçalho, servindo como base para todas as instâncias de módulos Plasma.
O código necessário para executar a funcionalidade do processador foi inserido num módulo baseado num modelo arquitetural primitivo SystemC.
Este código está contido em dois arquivos, cabeçalho e implementação, contendo uma combinação de código C e SystemC.
O arquivo cabeçalho(_ h) contém as definições de classe, a declaração e atribuição de portas SystemC, os parâmetros do sistema, o construtor e o protótipo das funções e processos.
O arquivo de implementação(_ cpp) contém o código C e SystemC que definem o comportamento do simulador.
Este modelo primitivo do processador MLite, ilustrado na Figura 17, possui apenas duas portas SystemC em sua interface:
Data_ in e data_ out, implementadas como estruturas de comunicação do tipo FIFO.
A primeira permite a entrada de dados a partir de módulos externos e a segunda envia dados para os módulos externos.
Estas portas compreendem canais de comunicação dedicados, permitindo o fluxo de entrada e saída de dados do processador.
Em esta fase, foram definidos seis parâmetros para a chamada do ISS, usados para repassar informações necessárias à geração do código a ser simulado, além de permitir definir características relativas ao processo de simulação, conforme segue:
Quando falso indica formato little endian;
Decode_ only:
Valor lógico, quando verdadeiro indica que o simulador deve apenas realizar a decodificação do código de máquina e mostrar a versão modificada do código de montagem.
Quando falso procede à execução normal da simulação;
As funcionalidades gerais do código C original do ISS foram mantidas.
Entretanto, foram necessárias adequações que exigiram diversas mudanças no código original.
A maioria das funções foi modificada a fim de adequar- las à metodologia de desenvolvimento do ambiente System Studio As funções referentes ao tratamento de memória cache foram retiradas, uma vez que não são utilizadas na plataforma HeMPS.
Criou- se um processo SystemC que substitui as funções main e de o_ debug originais, de forma a retirar a característica interativa via linha de comando e criar um perfil de código compatível com a execução do ambiente.
Também é incluído uma nova função para dar suporte ao processo inicial da simulação e alterou- se o código de forma a garantir que apenas as instruções da ISA MIPS-I sejam reconhecidas e executadas, além de dar suportar apenas às instruções aritméticas e lógicas destinadas às operações com inteiros.
De forma a permitir o controle do término da simulação a partir de o código fonte, foi implementado um comportamento especifico para a instrução break, a qual causa o término da simulação ao ser identificada.
Isto permite ao desenvolvedor de software encerrar a simulação por o simples fato de inserir esta instrução no seu código de montagem.
Embora a Etapa 1 tenha produzido um modelo funcional válido do processador MLite, observou- se que este modelo não seria adequado ao uso no sistema HeMPS, uma vez que a memória foi embutida como interna ao modelo, o que impede seu uso por o módulo de DMA.
Caso a memória permanecesse dentro de o módulo do processador, além de dificultar o seu acesso também tornaria o modelo conceitualmente diferente da implementação original do Plasma no sistema HeMPS.
Desta forma a Etapa 2 teve como principal objetivo realizar as adequações necessárias no módulo MLite e a criação de um módulo adicional para conter a memória principal, RAM.
A Etapa 1 serviu contudo à validação inicial da integração do ISS Plasma ao ambiente System Studio.
A Figura 18 mostra a representação esquemática do módulo Plasma contendo o processador MLite, a memória RAM e o canal hierárquico que provê comunicação entre os dois módulos.
Canais hierárquicos são uma estrutura de programa que pode conter outras estruturas SystemC embutidas, não se limitando apenas a um simples mecanismo de comunicação.
Este tipo de canal oferece um método mais poderoso para modelar estruturas de comunicação complexas, devido a a disponibilização de métodos virtuais implementados dentro de o canal e invocados por os módulos que a este se ligam.
Os módulos Mlite e RAM são interconectados por um canal hierárquico, que é composto de portas e interfaces SystemC.
O canal pode ser visto no centro da Figura 18.
Este canal hierárquico possui vários métodos SystemC utilizados para dar suporte ao fluxo de dados entre o processador MLite e a memória RAM.
A separação da memória e do processador exigiu a alteração da estrutura de dados que mantém o estado do processador, a recodificação de partes do código fonte e a criação de um canal hierárquico SystemC que define a interface entre os módulos.
A estrutura de dados foi subdividida, ficando parte contida no módulo MLite, que manteve apenas informações relativas ao processador, como:
Banco de registradores de propósito geral, registradores PC e PC NEXT e algumas variáveis de controle.
A outra parte da estrutura ficou no módulo RAM que basicamente manteve o vetor de bytes correspondente à memória e sua informação de endianismo.
O módulo MLite é implementado basicamente a partir de um processo e três funções de apoio.
O processo de o_ iss controla a execução de cada instrução que é efetivamente realizada por a função cycle.
Esta função realiza a busca, decodificação e execução de cada instrução.
Ela é apoiada por duas outras funções, mem_ write e mem_ read, que realizam os acessos à memória, que ocorrem através de chamadas de métodos contidos na interface.
O protocolo usado nas operações de leitura e escrita segue o paradigma &quot;requisição/ reconhecimento «(em inglês request/ acknowledge) de forma bloqueante, ou seja, a operação de requisição invoca o serviço desejado e aguarda que o reconhecimento ocorra, o que indica o fim da execução daquele serviço.
O canal hierárquico implementa os métodos invocados por o processador e por a memória, métodos que efetivamente criam o mecanismo &quot;requisição/ reconhecimento».
Existem três grupos de métodos a serem usados:
O primeiro é empregado no momento da carga do código objeto, enquanto os outros dois são usados por as operações de leitura e escrita sobre memória, respectivamente.
Cada processador mestre ou escravo do sistema HeMPS possui sua própria memória principal onde é armazenado o código de suas tarefas e o microkernel.
Um requisito existente no sistema é o suporte ao mecanismo de paginação de memória.
Este mecanismo permite a execução de múltiplas tarefas compartilhando a mesma memória, porém em páginas distintas.
Em o Plasma original um endereço de memória é composto de 13 bits, o que permite um espaço de endereçamento de apenas 8 Kbytes.
Em a plataforma HeMPS, o endereçamento de memória principal foi estendido em 3 bits possibilitando uma capacidade total de 64 KBytes.
Um destes bits é usado para ampliar o espaço endereçável para 16 KB e os outros dois são usados como um seletor de página de memória permitindo endereçar até 4 páginas.
Este mecanismo permite que os 64 KBytes de memória endereçáveis sejam seccionados em 4 páginas de memória de 16 Kbytes utilizado para armazenar o endereço da página ativa que concatenado aos demais quatorze bits de endereço compõem o endereço físico de memória.
A memória principal corresponde ao módulo RAM é o qual possui uma estrutura de dados contendo três variáveis:
Uma variável tipo ponteiro para char usada para endereçar o início da memória, uma variável tipo long, que contém o tamanho do código de máquina carregado na primeira página, destinada ao microkernel e uma variável tipo long usada para indicar o formato de armazenamento dos dados, sendo 0 usado para big endian e 1 para little endian.
Ainda existem três parâmetros usados para caracterizar a RAM:
O construtor do módulo instanciado cria um vetor que representa a memória, conforme o número de páginas definido por o parâmetro mem_ pages.
Adicionalmente, seleciona- se o microkernel a ser carregado, a partir de o arquivo kernel_ master.
Txt caso seja o processador mestre da HeMPS ou a partir de o arquivo kernel_ slave.
Txt caso o processador seja do tipo escravo, ambos gerados por a ferramenta HeMPS Editor.
HeMPS Editor é uma ferramenta de software destinada a automatizar diversos passos do fluxo de projeto para o sistema HeMPS, permitindo personalizar várias características da configuração da plataforma.
Mais detalhes podem ser encontrados em.
Existem quatro processos responsáveis por a funcionalidade da memória:
Load_ code:
Processo responsável por selecionar e carregar código de máquina do microkernel a ser executado no processador, de acordo com o seu tipo, mestre ou escravo;
De forma a garantir eficácia aos processos que dão suporte às operações em memória, ou seja, assegurar que a carga na memória do código de máquina ocorra antes que qualquer requisição à memória seja feita por o processador (cpu) ou DMA, é necessário que o processo load_ code seja executado antes da ocorrência de qualquer Introdução modelagem da infra-estrutura de comunicação implementada neste trabalho, foi realizada a partir de a versão abstrata escrita em SystemC por Moreno e descrita em, conforme introduziu a Seção 3.2.3.&amp;&amp;&amp; Esta modelagem foi implementada a partir de uma hierarquia de módulos funcionais estruturada em camadas.
A camada mais interna é composta apenas de modelos arquiteturais (ver Seção 3.4.3) primitivos do System Studio, escritos em SystemC.
As demais camadas são compostas de modelos arquiteturais hierárquicos System Studio introduzidos na mesma Seção e escritos em SystemC.
Os dados enviados por a rede são transmitidos como unidades de comunicação denominadas flits, cujo tamanho foi definido em 16 bits seguindo o padrão adotado na plataforma HeMPS, embora possa assumir outros valores conforme a necessidades.
A parametrização dos modelos não é, entretanto endereçada neste trabalho.
Modelagem hierárquica dos módulos da Hermes O componente fundamental mais importante da rede Hermes é o roteador, aqui denominado router.
Este componente é construído como um módulo hierárquico SystemC, em o qual são instanciados cinco módulos do tipo portas de comunicação.
Estas portas, conforme discutido na Seção 3.2.1, controlam o recebimento e envio de dados que chegam ao roteador, e um módulo para a lógica de controle, também introduzida na mesma Seção.
As portas para comunicação são denominadas door e a lógica de controle é denominada intraRouterChl.
Toda a comunicação que flui por a rede passa por roteadores.
O fluxo de pacotes entra através de uma das cinco portas de entrada, é processado no interior do roteador e sai através de uma das portas de saída.
Cada transferência é controlada por um árbitro e por o algoritmo de roteamento.
O roteador não possui nenhuma descrição algorítmica, servindo apenas como uma estrutura hierárquica que permite interconectar portas de comunicação (de entrada e de saída) e a lógica de controle.
A Figura 19 mostra a representação esquemática do roteador conforme aparece na janela gráfica do System Studio.
Em ela podem ser vistas as cinco instâncias das portas de comunicação e uma instância da lógica de controle (interRouter) ao centro.
Localizados nas extremidades da Figura, existem dez retângulos menores que estabelecem a interconexão entre as portas systemC do módulo hierárquico router às portas SystemC dos módulos portas de comunicação instanciados no interior deste.
Em o System Studio estas interconexões são chamadas pseudo-portas systemC, pois estabelecem a interconexão através de ponteiros que relacionam a porta systemC do módulo hierárquico com a porta systemC do módulo embutido.
O módulo intraRouterChl é um canal hierárquico que interconecta portas de comunicação.
Toda transferência interna de dados passa por este canal.
O módulo é composto de um árbitro, que controla o acesso das portas de entrada ao roteamento, que estabelece a interconexão interna entre pares de portas.
O roteamento elege por qual caminho (porta) o dado recebido por o roteador deve sair, além de realizar o controle de fluxo da transferência entre portas.
É possível ocorrer transferências em paralelo, desde que usando pares distintos de portas para comunicação entrada-saída.
Devido a esta característica se faz necessário uma identificação das portas envolvidas, de forma a evitar possíveis colisões.
Conforme introduzido na Seção 3.2.1, cada porta do roteador possui uma identificação:
EAST, WEST, NORTH, SOUTH E Local, as quais são representadas internamente por valores numéricos, respectivamente de 0 a 4.
A Figura 20 mostra a representação esquemática de uma instância do módulo intraRouterChl.
A parte central da figura representa o módulo, com a funcionalidade descrita anteriormente.
O símbolo círculo com seta dentro representa uma porta de interface, por a qual as portas SystemC das portas de comunicação se vinculam à lógica de controle;
Os componentes periféricos da Figura representam as portas de comunicação.
A porta de interface é na prática um ponteiro para função que permite acesso a métodos virtuais implementados no módulo intraRouter.
As portas para comunicação são denominadas door e são implementadas como módulos hierárquicos.
Um módulo door é o componente fundamental para apoiar o fluxo de entrada e saída de dados dentro de um roteador.
Através do módulo door é possível receber dados que chegam ao roteador e enviar- los em direção a o seu destino.
A Figura 21 mostra a representações esquemáticas deste módulo.
Em o exemplo da Figura este aparece instanciado no ambiente System Studio como uma porta oeste do roteador.
A parte esquerda da Figura mostra duas pseudo-portas conectadas às duas portas SystemC do módulo exemplo (inPortW-inPort e outPortW-outPort) usadas para realizar a comunicação com portas de roteadores vizinhos.
A parte direita mostra duas outras portas, inFromInternal e outToInternal, usadas para realizar a comunicação com a parte interna do roteador, a lógica de controle.
Semelhante ao roteador, o módulo door não possui nenhuma descrição algorítmica, servindo como estrutura hierárquica que interconecta portas SystemC do módulo router à lógica de controle interna.
O nível mais interno da hierarquia do roteador é composto por dois módulos primitivos:
InDoor e outDoor.
Ambos estão inseridos dentro de o módulo hierárquico door.
Estes módulos implementam o mecanismo que dá suporte à transferência de dados que chegam a uma porta de entrada do roteador.
Este último deve encaminhar estes dados à lógica de controle que os enviará a uma porta de saída.
Para permitir este fluxo de dados, os módulos citados realizam chamadas de métodos virtuais que residem dentro de o módulo lógica de controle.
A Figura 22 mostra a representação esquemática destes dois módulos fundamentais:
A o centro se encontra o retângulo chanfrado que representa o código systemC que contém a funcionalidade e à esquerda e à direita as pseudo-portas usadas para interconectar portas systemC destes módulos com o módulo hierárquico onde serão inseridos.
O módulo inDoor, item (a) da Figura 22, corresponde ao componente envolvido no fluxo de entrada de dados do roteador, e contém duas portas SystemC (inPort e internalPort) descritas a seguir vinculadas a duas interfaces intoRouterIf e outToInternalIf,:
O módulo outDoor, item (b) da Figura 22, corresponde ao componente envolvido no fluxo de saída de dados do roteador, e contém duas portas SystemC (outPort e internalPort) descritas a seguir vinculadas a duas interfaces outFromRouterIf e inFromInternalIf:
O módulo interRouterChl representa um canal hierárquico entre módulos roteadores, que implementa o mecanismo de interconexão entre portas para comunicação entre roteadores ou de um roteador com um núcleo IP.
Este módulo estabelece a estratégia de controle do fluxo através da rede.
Toda a transferência de dados entre roteadores na rede e entre roteador e módulo IP local é gerenciada por o módulo interRouterChl.
Ou seja, este componente corresponde a um canal hierárquico que realiza a interconexão entre portas para comunicação de roteadores vizinhos ou entre roteador e núcleo IP.
A Figura 23 mostra a representação esquemática do módulo interRouterChl.
Este módulo interconecta dois roteadores através de suas portas leste e oeste.
A funcionalidade ocorre por a chamada de métodos virtuais implementados no canal hierárquico realizados por as portas de interface do roteador.
Este módulo implementa os métodos virtuais definidos nas interfaces intoRouterIf e outFromRouterIf, que realizam o controle de envio e confirmação de recebimento dos dados transmitidos entre nodos da rede.
Assim, estes permitem o fluxo de dados entre as portas dos roteadores e núcleos Uma vez descritos todos os módulos componentes do roteador, é possível construir uma rede Hermes.
Para gerar uma rede Hermes, utilizam- se dois módulos básicos:
Router e interRouterChl, instanciados dentro de um módulo hierárquico que dará origem a uma instância particular da rede Hermes.
A quantidade de módulos router e sua disposição define as dimensões da rede.
A quantidade de módulos interRouterChl é estabelecida conforme o número de pares de portas de comunicação a serem interconectadas e portas não utilizadas.
A Figura 24 mostra a representação esquemática do System Studio de uma rede cuja dimensão é 2x2, que contém quatro roteadores.
Em esta Figura pode- se visualizar os dois tipos de módulo básico, além de as pseudoportas usadas para interconectar as portas de comunicação de IP local de cada roteador às portas para comunicação do módulo hierárquico onde estes módulos básicos estão inseridos.
O todo corresponde à rede intra-chip, conforme segue:
&quot;fechar «as conexões das portas de comunicação não utilizadas (periféricas);
Esta internconexão é necessária uma vez que nos roteadores existem métodos virtuais declarados os quais estão implementados no módulo interRouterChl;
SystemC da porta de comunicação às portas SystemC do módulo hierárquico de nível imediatamente superior, a rede Hermes.
Para completar a construção da rede Hermes basta inserir o módulo hierárquico noc_ 2x2 dentro de outro módulo hierárquico e interconectar as portas para comunicação dos núcleos IP a canais hierárquicos interRouterChl devido a o uso de métodos virtuais, conforme já explicado anteriormente.
A Figura 26 apresenta a representação esquemática da rede 2x2 juntamente com os canais hierárquicos.
A rede intra-chip HERMES 2 x2 está representada por o retângulo chanfrados maior, os retângulos menores representam os módulos interRouterChl por os quais os núcleos IP locais podem ser conectados.
De acordo com o terceiro objetivo específico descrito na Seção 1.3, este trabalho propõe a geração de um modelo do hardware do sistema HeMPS em alto nível de abstração.
Conforme introduzido na Seção 3.1, já existem implementações do sistema HeMPS realizadas por o GAPH.
Contudo estas implementações foram desenvolvidas em RTL, ou seja, abaixo de o nível de abstração pretendido.
Esta Seção se destina a apresentar o processo de modelagem do hardware do sistema HeMPS desenvolvido no contexto deste trabalho.
O software do sistema HeMPS, e mais especificamente seu microkernel, não faz parte dos objetivos de modelagem propostos deste trabalho.
Entretanto, para permitir uma melhor compreensão do processo de modelagem do hardware, bem como para dar suporte à validação da funcionalidade do modelo desenvolvido, o microkernel existente será explorado na próxima seção, porém em nível substancialmente superficial.
Maiores detalhes do mesmo podem ser obtidos em.
Também, o objetivo de validar o modelo abstrato da HeMPS necessitou que uma parte do microkernel fosse agregado ao primeiro, gerando uma validação parcial também do software da HeMPS em alto nível de abstração, conforme será descrito na Seção 7.4.
Componentes de software Basicamente, o software da plataforma HeMPS pode ser dividido em duas classes:
O microkernel, que corresponde ao sistema operacional;
E tarefas, que compõem as aplicações.
Ambos as classes são executadas nos processadores da HeMPS.
O sistema operacional da plataforma HeMPS, denominado microkernel, foi desenvolvido considerando- se duas classes de aplicações:
Uma destinada a ser executada exclusivamente no processador mestre, e outra a ser executada nos demais processadores do sistema, os escravos.
A associação de cada tipo de microkernel com cada um dos processadores ocorre automaticamente pala ferramenta HeMPS Editor, em tempo de projeto.
Considerando que a estratégia de paginação foi adotada para mapeamento de memória no sistema HeMPS, destina- se a página 0 (zero) de memória para a execução do microkernel.
Uma vez que este pode ser maior que o espaço de uma página, como ocorre no caso de o microkernel escravo, pode ser reservada mais de uma página para sua execução, estendendo- se até a página 1 (um).
O gerenciamento da página ativa (segmento de código selecionado para execução) é realizado por o próprio microkernel, a partir de um registrador de controle, denominado PAGE.
O escalonamento de tarefas é preemptivo, fazendo uso de um algoritmo round robin como estratégia de eleição da página a ser executada e por conseqüência do segmento de código (microkernel ou tarefa) a ser executado.
As tarefas executam segundo o paradigma de fatias fixas de tempo (em inglês, time slices), onde cada tarefa executa por um tempo fixo antes de concorrer a um novo processo de escalonamento.
Uma vez que o paradigma de acesso à memória adotado segue o padrão Norma (do inglês, no remote memory access) a comunicação entre processadores ocorre exclusivamente através de troca de mensagens, fazendo uso de serviços de comunicação, conforme será detalhado na Seção 6.2.2.3.
Mensagens são escritas e lidas numa área de memória local denominada pipe, mantida por o microkernel e considerada um canal de comunicação entre tarefas.
Em a prática, um pipe é uma estrutura de dados contendo um registro para cada mensagem, este último composto por informações de controle e por a mensagem em si.
Caso a comunicação ocorra entre tarefas localizadas num mesmo processador, o processamento se restringe ao uso do pipe, não sendo necessário o uso de serviços especiais do microkernel.
Por conseguinte, este tipo de troca de mensagens prescinde do processo de geração de pacotes para realizar a comunicação entre processadores distintos.
Durante a fase inicial (em inglês, boot), o sistema operacional do processador mestre começa criando estruturas de dados.
Estas estruturas são usadas para:
As operações básicas realizadas por o microkernel mestre são as seguintes:
Atribuição inicial de valores às estruturas de controle, conforme definido em tempo de projeto na ferramenta HeMPS Editor;
Quando ocorrer alguma interrupção, a tarefa ociosa é interrompida e inicia- se o tratamento daquela interrupção.
O restante do código existente no microkernel dá suporte às interrupções, tratando serviços de requisição dinâmica de tarefas, controle de término de execução de tarefa e dar suporte a mensagens de depuração do sistema.
Não existe interrupção de software no processador mestre, uma vez que nenhuma tarefa lá executa, apenas o microkernel mestre.
Durante a fase inicial, o microkernel do processador escravo cria uma estrutura do tipo fila circular, denominada ni_ queue, utilizada para armazenamento temporário de mensagens a serem enviadas quando a interface com a rede estiver indisponível.
A partir de um tipo definido por o usuário, denominado TCB (abreviatura do inglês Task Control Block), são criadas várias outras estruturas para o controle de execução das tarefas.
Estas estruturas mantêm o contexto das tarefas a serem executadas, como o valor do contador de programa (em inglês Program Counter ou PC), o endereço inicial em memória e o estado de execução (ou seja, o conteúdo do Banco de Registradores, do EPC, etc.).
As operações realizadas na fase inicial por o microkernel escravo podem ser resumidas nas seguintes ações:
A rotina Os_ Init executa as seguintes ações:
Atribui- se valores iniciais às estruturas de controle tipo TCB.
Estas são:
Em cada processador, após o escalonamento, uma tarefa entrará em execução.
O escalonamento ocorre ao final de cada fatia de tempo, segundo o já mencionado algoritmo round robin.
Cada tarefa é suspensa quando de a ocorrência de uma interrupção, que pode ser de software ou de hardware.
Em este momento, a rotina específica para cada tipo de interrupção será invocada.
No caso de interrupção de hardware, chama- se a rotina específica para um dado dispositivo, sendo a tarefa em execução suspensa.
Posteriormente ao tratamento da interrupção, esta retoma à execução, a não ser que a interrupção tenha sido gerada por motivo de término da sua fatia de tempo.
Interrupções de software são geradas para dar suporte à troca de mensagens entre tarefas (macros ReadPipe e WritePipe).
Interrupções de hardware são geradas:
Interrupções de hardware suspendem a execução da tarefa atualmente em execução, a qual pode ser ter oportunamente retomada sua execução.
Em a plataforma HeMPS tarefas correspondem a trechos de programas escritos por o usuário em linguagem C. Estas tarefas são criadas para serem executadas nos processadores escravos, podendo existir tantas tarefas executando simultaneamente quantas páginas disponíveis existirem em cada processador.
As tarefas podem ser designadas diretamente para um determinado processador, de forma estática, ou podem permanecer sem associação específica, sendo alocadas de forma dinâmica ao serem invocadas por alguma outra tarefa, devido a a execução de uma macro WritePipe.
Em este caso tarefas são executadas sob demanda.
A definição de qual tarefa será alocada de forma estática ou dinâmica é decidida em tempo de projeto através da ferramenta HeMPS editor.
Quando atribuídas a um processador escravo serão alocadas estaticamente, quando restarem atribuídas ao processador mestre (esta é a situação inicial de qualquer tarefa na ferramenta HeMPS Editor) serão alocadas dinamicamente.
Conforme mencionado anteriormente, a comunicação entre tarefas ocorre por meio de mensagens, fazendo- se uso de um canal de comunicação (o pipe).
Para dar suporte à comunicação, tarefas executam macros WritePipe, para enviar uma mensagem a um destino e ReadPipe para ler uma mensagem enviada por uma origem.
Adicionalmente, tarefas podem executar duas outras macros:
GetTick, que retorna o número de ciclos de relógios executados, contabilizados desde o primeiro ciclo gerado e Echo, que é definida como serviço de depuração, tendo como efeito o envio da uma mensagem para o módulo UART do processador mestre.
Considerando que este trabalho realiza a modelagem em alto nível de abstração, detalhes como operação por ciclo de relógio não estão presentes.
Em a modelagem realizada a macro GetTick foi modificada para retornar o número de instruções executadas desde o início do processamento, contabilizando todas as instruções executadas, não apenas das tarefas, mas também do microkernel e de tarefas idle.
Desta forma, esta medida serve como parâmetro para aproximar uma métrica de tempo.
Em a organização Plasma, devido a o uso de pipeline, a vazão de instruções por ciclo de relógio é igual a um, com exceção das instruções load e store que consomem 2 ciclos e das instruções de multiplicação e divisão que consomem 32 ciclos, quando não estiver ativada a otimização de cálculo no hardware.
Componentes de hardware complementares ao módulo Plasma Além de os modelos abstratos desenvolvidos para o processador Plasma, introduzidos na Seção 4.2, foram desenvolvidos outros cinco módulos complementares para completar o modelo do processador da plataforma HeMPS.
Estes módulos podem ser divididos em dois grupos.
O primeiro é composto por os módulos de armazenamento desenvolvidos para dar suporte ao repositório de tarefas e por os registradores usados para controle ou estado.
O segundo grupo é composto por os três módulos usados para dar suporte à comunicação.
As duas Seções a seguir apresentam a modelagem dos componentes destes grupos.
Existem três classes de dispositivos de armazenamento a serem consideradas no módulo Plasma:
Memória principal (RAM), memória externa (MEM_ EXT) e o coprocessador 0 (CP0).
A Figura 27 mostra a representação esquemática do módulo Plasma, contendo estes dispositivos.
Em a Figura podem ser visualizados quatro módulos:
O processador MLite, a memória interna RAM;
A memória externa MemExt, que corresponde ao repositório de tarefas, e o co-processador 0, CP0, que contêm registradores de controle do Plasma.
Os dois primeiros já foram abordados nas seções 4.2.
Todos os quatro módulos são interconectados através de um canal hierárquico de comunicação, que aparece na parte inferior da Figura.
O módulo MEM_ EXT implementa a memória externa (secundária).
Esta memória tem por função armazenar tarefas que deverão ser distribuídas e executadas nos diversos processadores do sistema.
Ou seja, constitui o repositório de tarefas a distribuir nos respectivos elementos de processamento, onde serão alocadas nas páginas da memória principal do processador.
A gerência da página a ser considerada é responsabilidade do microkernel.
Em a versão RTL da HeMPS a memória externa é implementada a partir de um arquivo VHDL, gerado por a ferramenta HeMPS Editor, que descreve a imagem de memória contendo um cabeçalho e o código das tarefas.
Considerando que as tarefas a serem executadas são definidas em tempo de projeto, a ferramenta HeMPS Editor gera um arquivo cabeçalho C (com extensão_ h).
Este arquivo contém chamadas de função e respectivos parâmetros, em número necessário para realizar a carga de todas as tarefas previamente armazenadas no repositório.
Também se gera um arquivo compatível com a imagem de memória, denominado repository.
Txt. Este arquivo contém a representação hexadecimal, em formato texto, de todas as tarefas, estando dividido em duas partes:
Cabeçalho e código.
A Tabela 6 apresenta a organização dos dados do repositório.
Para interpretar esta Tabela lembra- se que a memória do MIPS é endereçada a byte.
O cabeçalho é composto de três campos de 32 bits para cada tarefa, e é replicado para cada tarefa.
A interpretação de cada palavra (32 bits) do cabeçalho é:
identificação numérica da tarefa, tamanho do código de máquina da tarefa, em número de palavras e endereço inicial da tarefa no repositório, onde o código desta inicia (offset).
Após os cabeçalhos, segue- se a região onde são armazenados os códigos de máquina de cada tarefa, na mesma ordem dos cabeçalhos.
Esta memória ocupa o segmento de endereços que inicia em 0x1000000 e vai até 0x1FFFFFFF.
Assim, o dado armazenado no índice 0 da Tabela acima ocupa o endereço 0x10000000.
Toda operação realizada sobre esta faixa de endereços é dirigida ao módulo O conteúdo desta memória é previamente definido (em tempo de projeto) e não muda ao longo de a execução de aplicações na plataforma HeMPS.
Logo, apenas a operação de leitura é necessária.
Existem três processos que implementam a funcionalidade do repositório:
DMA executa a transferência do código de máquina de cada tarefa a ser enviada para a rede.
A arquitetura MIPS dá suporte nativo a até quatro co-processadores.
O coprocessador 0 é conhecido como o co-processador de controle, sendo implementado em praticamente toda versão do MIPS com maior ou menor funcionalidade.
Este módulo desempenha duas funções principais para a CPU:
Gerenciar a memória virtual do sistema e controlar o processamento de exceções.
Embora no Plasma a entidade co-processador 0 não exista explicitamente, considera- se aqui a modelagem de um módulo específico para representar a funcionalidade do CP0.
O critério usado para esta abordagem baseia- se no agrupamento de registradores usados para controle num local específico, semelhante ao que ocorre na definição da arquitetura Dentro de o CP0, podem existir até 32 registradores para propósitos específicos.
Em o sistema HeMPS são usados três destes apenas:
Sr: Registrador de estado (status).
Quando ativado, indica que o processador irá tratar interrupções ocorridas.
Quando desativado (com valor 0), o processador ignora interrupções;
EPC: Registrador contador de programa de exceção (exception PC).
Armazena o endereço da instrução seguinte àquela onde uma exceção foi gerada.
Usado para permitir o tratamento de exceções e posteriormente permitir o retorno ao fluxo de execução anterior à ocorrência da exceção;
PAGE: Implementado no contexto da plataforma HeMPS.
Armazena o endereço inicial da página de memória.
Usado para compor o endereço físico de acesso à memória.
Além de os registradores acima, foram inseridos mais quatro registradores neste módulo.
O critério para estes registradores estarem localizados no CP0 foi a natureza de seu conteúdo.
Como estes registradores são usados para propósitos específicos (controle), o módulo CP0 é o local mais lógico para estarem localizados.
A lista abaixo introduz estes registradores:
Porém, o objetivo deste registrador é permitir ao processador controlar quais interrupções irá tratar, ou seja, o processador pode, via software, decidir que interrupções serão verificadas escrevendo neste registrador.
As interrupções a serem tratadas serão cuja operação lógica E (And) entre os bits respectivos dos registradores irq_ mask e irq_ status produzir o valor 1;
time_ slice:
Registrador para contagem da fatia de tempo.
Em a implementação RTL do sistema HeMPS este registrador é incrementado a cada ciclo de relógio.
A o atingir o valor 16384 é gerada uma interrupção de hardware, de forma que o microkernel possa assumir o controle do processador e escalonar uma nova tarefa a ser executada, zerando então este registrador para iniciar uma nova contagem.
Como a implementação desenvolvida neste trabalho é em alto nível de abstração, este valor é incrementado não a cada ciclo de relógio, mas sim a cada instrução executada, uma vez que a modelagem aqui considerada não contabiliza ciclos de relógio.
Existem três dispositivos que dão suporte à comunicação ao processador Plasma na plataforma HeMPS.
A Figura 28 mostra a representação esquemática parcial do módulo Plasma onde ocorrem estes dispositivos A controladora UART originalmente realiza a comunicação com um dispositivo serial, sendo aqui considerada como um console de comunicação com o ambiente System Studio.
A interface de rede (em inglês Network Interface ou Ni) atua como meio de interconexão entre a rede Hermes e os componentes internos do Plasma.
O controlador de DMA realiza a transferência de dados entre a rede e a memória interna do Plasma, sem necessidade de interação do processador durante todo o processo.
Todos os quatro módulos são interconectados através de um canal hierárquico de comunicação (na Figura denominado CommChl).
O módulo UART é utilizado no sistema HeMPS basicamente para apresentar massagens de depuração enviadas por os processadores escravos.
Em o contexto deste trabalho, as mensagens geradas por o módulo UART são apresentadas na janela de console do System Studio.
A UART é constituída por dois processos, com duas portas SystemC para escrita e leitura em o/ do módulo.
O processo write_ service constitui o serviço de escrita no módulo.
Mensagens de depuração recebidas por o processador mestre são redirecionadas para a saída padrão.
O segundo processo, read_ service, permite receber valores do console, normalmente via teclado, e enviar- los ao processador.
Este último serviço não é utilizado por nenhuma função desempenhada por o microkernel ou por o hardware.
Entretanto esta função foi implementada, prevendo algum tipo de interatividade que possa vir a ser necessária durante a simulação do modelo abstrato.
A Figura 29 apresenta uma ampliação da representação esquemática do módulo UART.
Em esta Figura pode- se observar a UART como um retângulo chanfrado, as duas portas SystemC para uso em entrada e saída de dados e a conexão destas portas as interfaces do canal de comunicação, o que permite a integração do módulo ao restante do modelo Plasma.
Como o módulo UART opera com largura de dados de 8 bits (um byte) os dados a serem enviados ou eventualmente recebidos estão limitados a este tamanho, em cada operação.
O módulo DMA tem a função de realizar a transferência de tarefas armazenadas em memória externa (no caso de a HeMPS no repositório de tarefas) a partir de o processador mestre e enviar- las à rede, conforme distribuição de tarefas especificada em tempo de projeto na ferramenta HeMPS Editor.
Complementarmente, nos processadores escravos, o DMA tem a função de receber o código objeto das tarefas e transferir- lo para uma página livre de memória.
O controle de páginas livres em cada processador escravo é realizado de forma centralizada por o microkernel mestre.
Para realizar transferências, o DMA é programado por o processador através de um mecanismo de escrita em registradores mapeados em memória.
Em a versão HeMPS considerada neste trabalho, de agosto de 2008, existem cinco registradores mapeados em memória, descritos a seguir:
DMA_ SIZE:
Mapeado no endereço 0x20000200.
A função deste registrador é permitir ao microkernel, tanto do processador mestre como do escravo, informar ao DMA o tamanho do código que deverá ser transferido, da memória externa para a rede ou da rede para uma página da memória principal;
DMA_ ADDRESS:
Corresponde ao endereço 0x20000210.
A função deste registrador é informar ao DMA o endereço a partir de o qual deverá iniciar a transferência de dados.
Em o processador mestre, corresponde ao endereço inicial da tarefa, na memória externa, a ser lida e enviada para o processador destino.
Em o processador escravo indica o endereço a partir de o qual o código deve ser armazenado na memória principal;
DMA_ OP:
Corresponde ao endereço 0x20000220.
Este registrador tem como função indicar ao DMA em que sentido se dá a operação de transferência do código, podendo ser:
Origem o repositório de tarefas e destino a rede ou a rede como origem e como destino a memória local;
DMA_ START:
Corresponde ao endereço 0x20000230.
Escrita neste registrador permite ao processador sinalizar o início da transferência.
A partir de uma escrita neste registrador o DMA passa a realizar a transferência do código no sentido previamente definido no registrador DMA_ OP, liberando o processador para executar outra atividade.
A o final da transferência, o DMA gera uma interrupção de hardware para indicar ao processador que a tarefa foi concluída;
DMA_ ACK:
Corresponde ao endereço 0x20000240.
A função deste registrador é receber a confirmação de término da transferência conforme reconhecida por o processador.
Ou seja, assegura- se ao DMA que o processador reconheceu e tratou a interrupção gerada.
Em a prática, esta ação faz com que o DMA desative a interrupção gerada anteriormente.
Os cinco registradores descritos acima estabelecem o protocolo de comunicação entre processador e DMA.
A Figura 30 mostra a reapresentação esquemática do módulo DMA.
Em ela pode ser visto o módulo DMA, representado por o retângulo chanfrado, além de quatro portas SystemC usadas no fluxo de entrada e saída de dados, representadas por os quadrados contendo setas duplas, e a conexão destas portas às portas do canal de comunicação que habilita a integração do módulo ao restante do sistema Plasma.
As duas portas mais à esquerda destinam- se à comunicação com o processador, uma para escrita e outra para leitura.
Embora o processador apenas escreva no DMA, foi disponibilizado suporte à leitura, possibilitando implementar esta operação de forma relativamente fácil caso seja necessário no futuro.
As duas portas mais à direita destinam- se a operações de escrita e leitura do DMA sobre as memórias local e externa.
As operações atualmente implementadas são apenas leitura da memória externa e escrita na memória local.
O funcionamento do DMA pode ser dividido em três fases:
Programação, operação e finalização.
Para funcionar, o DMA precisa ser previamente programado por o processador.
A fim de dar suporte a esta funcionalidade, foram implementadas duas funções e um processo.
O processo, cpu_ write_ service, habilita o serviço de escrita do processador no DMA.
Existe suporte para escrita nos cinco registradores acima mencionados.
Em a primeira fase, programação, realizam- se operações de escrita por o processador (mestre ou escravo) nos três primeiros registradores do DMA (tamanho, endereço e operação), armazenando os valores recebidos localmente em cada operação de escrita.
Em a segunda fase, operação, ocorre a escrita no quarto registrador (iniciar), o que causa a chamada de uma das duas funções de apoio, dependendo do código da operação recebida.
Ocorrendo o código for 0, será chamada a função transfer_ from_ mem, que realiza a transferência do código de máquina da tarefa, a partir de a memória externa (repositório), para o módulo interface de rede (Ni).
Se a operação for 1, será chamada a função transfer_ te o_ mem, que realiza a operação inversa:
Receber, da interface de rede, o código da tarefa e escrever- lo na memória principal.
Uma vez invocada uma das funções, aquela permanecerá em execução até a transferência de todo o código, em paralelo com o processador.
Em a última fase, finalização, é gerada (registrada) uma interrupção do DMA no registrador irq_ status, localizado no módulo CP0, assim que ocorrer o término da transferência dos dados.
Esta interrupção será desativada por o módulo DMA quando o processador sinalizar o reconhecimento da interrupção através da escrita no quinto registrador, finalizando então a operação de DMA.
O sistema HeMPS é composto basicamente por dois componentes de hardware:
Elementos de processamento e a rede de comunicação.
O elemento de processamento é implementado por o módulo Plasma, inserido como um núcleo IP.
A rede de comunicação é a rede Hermes, a infra-estrutura de comunicação.
Para que os processadores possam se comunicar é necessário um módulo que permita que os dois elementos possam ser interconectados.
Este módulo deve servir de interface entre os dois processadores.
O módulo que implementa esta interface é o módulo denominado Ni (do inglês Network Interface).
O objetivo deste módulo é prover um fluxo de comunicação entre processador e rede e vice-versa.
A Ni realiza o envio e recebimento dos dados, tanto para o processador como para o DMA.
Adicionalmente a Ni informa ao processador qual a localização deste na rede, através de seu endereço de rede.
De forma a permitir um melhor entendimento das funções que a Ni implementa, segue uma breve descrição de como funciona o mecanismo de comunicação por mensagens.
Conforme mencionado anteriormente, a comunicação entre os processadores ocorre por meio de mensagens.
Para serem transmitidas estas mensagens devem ser embutidas numa unidade de comunicação denominada pacote.
Cada pacote que trafega na rede Hermes possui três campos distintos:
Header (cabeçalho):
Contém o endereço de rede do processador destino do pacote;
O campo de carga útil, por sua vez, é subdividido, no contexto específico da plataforma HeMPS, em duas partes:
Código de serviço e parâmetros.
O código de serviço indica a ação que se deseja executar, os parâmetros correspondem às informações complementares ao serviço.
Em o sistema HeMPS existem atualmente dez serviços disponíveis, resumidos a seguir:
MESSAGE_ REQUEST -- Serviço usado para requisitar a leitura de uma mensagem entre processadores escravos, caracterizado por uma leitura em tarefa remota.
A execução deste serviço é disparada por a chamada da macro ReadPipe;
MESSAGE_ DELIVERY -- Serviço usado como resposta a uma requisição de leitura de mensagem (MESSAGE_ REQUEST).
Ele transporta a mensagem em si;
MESSAGE_ UNAVAILABLE -- Serviço usado como reposta a uma requisição de leitura de mensagem, indicando que a mensagem solicitada não existe;
TASK_ ALLOCATION -- Serviço usado para requisitar a alocação estática de uma tarefa num processador escravo.
O serviço transporta o código da tarefa;
ALLOCATED_ TASK -- Serviço usado para informar aos processadores escravos que uma nova tarefa foi alocada;
REQUEST_ TASK -- Serviço usado para requisitar a alocação dinâmica de uma tarefa.
Gerado em duas situações:
A o executar a macro WritePipe e, tendo sido finalizada a alocação estática, caso a tarefa alvo ainda não tenha sido alocada e ao receber a confirmação de conclusão de alocação estática (FINISHED_ ALLOCATION), quando existirem requisições de leitura pendentes para uma tarefa alocada no processador alvo;
TERMINATED_ TASK -- Serviço usado para informar ao processador mestre o término da execução de uma tarefa.
O mestre informará o término aos demais processadores (via o serviço DEALLOCATED_ TASK), que irão atualizar suas tabelas de tarefas existentes respectivas;
DEALLOCATED_ TASK -- Serviço usado por o processador mestre para informar os demais processadores que uma tarefa não existe mais (finalizou).
Uma tarefa finaliza quando a função main encerra, momento em que será executada a instrução syscall com parâmetro zero, gerando o retorno ao código bootTask.
Asm que chamou a tarefa;
FINISHED_ ALLOCATION -- Serviço usado informar aos processadores escravos que a alocação de tarefas estáticas foi concluída;
Debug -- Serviço usado para envio de mensagens de depuração ao processador mestre, o qual envia esta mensagem para o seu módulo UART.
O software do sistema HeMPS, e mais especificamente seu microkernel, não fazem parte dos objetivos de modelagem propostos deste trabalho.
Entretanto, para permitir uma melhor compreensão do processo de modelagem do hardware, bem como para dar suporte à validação da funcionalidade do modelo desenvolvido, o microkernel existente será explorado na Seção 6.2.3, ainda que de forma superficial.
Maiores detalhes sobre o mesmo podem ser obtidos em.
Também, o objetivo de validar o modelo abstrato da HeMPS necessitou que uma parte do microkernel fosse agregado ao modelo, gerando uma validação parcial também do software da HeMPS em alto nível de abstração, conforme será descrito na Seção 7.4.
Como introduzido na Seção 6.1.1, a comunicação entre processadores é feita através de mensagens, via um canal de comunicação denominado pipe.
O microkernel faz acesso a pipes para armazenar ou recuperar mensagens, via as funções WritePipe e ReadPipe.
Isto vale tanto para tarefas locais quanto remotas.
Em a versão atual do sistema HeMPS, o serviço 30 (MESSAGE_ UNAVAILABLE) não é gerado.
Quando uma leitura de mensagem numa tarefa remota é requisitada é gerado um pacote contendo o serviço MESSAGE_ REQUEST.
A tarefa será alterada para o estado de espera (waiting), sendo reativada quando o serviço MESSAGE_ DELIVERY for recebido, contendo a identificação da tarefa relativa à mensagem aguardada.
A Figura 31 apresenta os seis protocolos usados por os serviços contidos nas mensagens usadas para a comunicação entre tarefas de processadores distintos.
O item (a) apresenta o protocolo usado para a alocação estática de tarefas, que ocorre durante o processo de boot do sistema.
Para cada tarefa, é gerado e enviado um pacote de serviço 40, contendo o código de máquina da tarefa.
Concluída a alocação, outro pacote de serviço 50 é gerado e enviado para cada escravo, menos para aquele onde a tarefa foi alocada.
O item (b) apresenta o protocolo usado para a alocação dinâmica de tarefas, que ocorre sob demanda.
Quando uma requisição para alocação de tarefa é gerada, um pacote de serviço 60 e a identificação da tarefa são enviados ao processador mestre.
Como resposta, processo semelhante à alocação estática é executado.
O item (c) apresenta o protocolo usado para indicar o término da alocação momento podem ocorrer alocações dinâmicas devido a requisições de mensagem pendentes, geradas para tarefas que ainda não haviam sido alocadas quando de a geração da requisição.
O item (d) apresenta o protocolo usado para realizar a comunicação entre tarefas, via troca de mensagens.
Um pacote contendo o serviço 10 e a identificação da tarefa onde a mensagem deve ser obtida é enviado ao alvo (processador escravo).
Em o alvo, um pacote contendo o serviço 20 e a mensagem previamente disponibilizada por a macro WritePipe são enviados ao requisitante.
O item (e) apresenta o protocolo usado para informar o término da execução de uma tarefa.
Em o processador escravo onde a tarefa em execução terminou é gerado um pacote, contendo a identificação da tarefa concluída, sendo este enviado ao processador mestre.
O mestre por sua vez, gera outro pacote de serviço 80, contendo a identificação da tarefa que terminou e o envia a todos os processadores escravos, menos ao solicitante (onde a tarefa finalizou).
O item (f) apresenta o protocolo usado para mensagens de depuração.
Quando uma tarefa enviar uma mensagem de depuração, correspondente à função Echo, esta mensagem será enviada para o processador mestre, juntamente com a identificação da tarefa, sendo posteriormente repassada para o módulo UART do processador mestre.
De forma a permitir a localização facilitada do local onde os serviços são gerados e tratados no microkernel, a Tabela 7 apresenta a correlação entre os serviços de comunicação existentes no sistema HeMPS e as funções relativas a eles, indicando:
Onde um serviço é gerado e em que local o serviço é tratado, considerando também as duas classes de processadores (mestre/ escravo).
Tratado identifica onde o pacote é recebido e tratado.
Cód é o código numérico hexadecimal do serviço.
Função é o nome da rotina que processa o pacote.
Plasma). Interrupções são geradas apenas quando o buffer estiver cheio, ou quando se detecta o fim de um pacote recebido da rede.
Assim, esta abordagem gera número reduzido de interrupções.
Os dois registradores, data_ in e data_ out, são definidos em SystemC a partir de o uso de uma estrutura do tipo union.
Esta estratégia foi escolhida para dar suporte à forma como os dados devem ser recebidos da rede ou enviados para esta:
Eles são recebidos na forma de flits e armazenados como palavras;
São armazenados como palavras e enviados como flits.
O tratamento dos flits segue sempre o seguinte padrão:
O primeiro flit é armazenado ou retirado da parte alta da palavra e o segundo flit é armazenado ou retirado da parte baixa da palavra.
A estrutura union permite atender este mecanismo de forma simples, da seguinte maneira:
Uma palavra recebida do Plasma é armazenada no registrador data_ out numa única operação e enviada em duas etapas, parte alta e após a parte baixa;
Dois flits são recebidos da rede e armazenados em duas operações:
O primeiro flit é colocado na parte alta do registrador data_ in e o segundo flit é colocado na parte baixa, sendo então transferido o seu conteúdo para o buffer de entrada (dataBuff) como uma palavra.
A Figura 33 apresenta:
A estrutura, a declaração e a atribuição referente a o registrador data_ in, para o caso de recebimento de dados provindos da rede.
LSB (low), noc_ Data_ In.
Read (data_ in-\&gt; flit);
A Figura 34 mostra a representação esquemática do módulo Ni.
Em esta Figura podem ser visualizados:
O módulo Ni ao centro, representado por o retângulo chanfrado;
A funcionalidade do módulo Ni é composta de quatro processos, divididos em três grupos, conforme especificado a seguir:
O processo plasma_ write_ service recebe uma palavra enviada por o processador MLite ou por o DMA e a armazena no registrador data_ out..
Em a seqüência são transmitidos para a rede dois flits, primeiro a parte alta do registrador e logo após a parte baixa.
O processo noc_ read_ service recebe dois flits da rede e armazena- os na parte alta e parte baixa, respectivamente, do registrador data_ in.
Logo após, os flits recebidos são transferidos para dataBuff como uma palavra.
O processo plasma_ read_ service, por sua vez, retira do buffer a palavra armazenada e a envia para o processador MLite ou módulo DMA.
Por fim, o processo noc_ intr_ service controla a geração de interrupção, de forma a sinalizar ao processador que trate os dados chegando por a rede.
Uma vez introduzidos os componentes que constituem o sistema HeMPS, é possível apresentar a modelagem completa deste.
O módulo HeMPS é composto por três componentes:
Rede intrachip, núcleo IP e canais de interconexão.
A Figura 35 apresenta a distribuição hierárquica dos módulos existentes no modelo abstrato da HeMPS.
Em a Figura os retângulos com linhas duplas representam módulos hierárquicos, os retângulos com linhas simples representam módulos primitivos e os retângulos com linhas pontilhadas representam canais hierárquicos SystemC.
Em a parte superior da hierarquia está o módulo HeMPS, que corresponde à entidade topo de toda a hierarquia.
Em o nível abaixo estão os três módulos fundamentais que compõem o sistema:
PlasmaP, Hermes e interRouterChl.
O módulo plasmaP é o elemento de processamento do sistema, composto por sete módulos primitivos e um canal hierárquico.
O módulo Hermes é o elemento de comunicação do sistema, sendo composto por roteadores e canais de interconexão.
Em o nível inferior a este se encontra o módulo router, que corresponde ao elemento de roteamento, composto por portas de comunicação e canais hierárquicos.
Em o nível seguinte aparece o módulo door que implementa os fluxos de comunicação dentro de o roteador.
Door é composto por dois módulos primitivos, representando as portas de entrada e de saída, que efetivamente implementam cada fluxo de dados em alguma direção.
A Figura 36 mostra a representação esquemática de uma instância do sistema HeMPS no ambiente System Studio, contendo uma rede HERMES 2 x2 e quatro processadores Plasma.
A o centro está localizada a rede Hermes.
Em as extremidades estão localizados quatro módulos processadores Plasma.
Um de eles é o mestre, identificado por um círculo ao centro, e os demais são escravos, identificados por quadrados no centro do retângulo chanfrado.
Entre a rede e os processadores existem canais de interconexão:
Existem diversos parâmetros que devem ser configurados para que o sistema possa funcionar adequadamente.
As funções cycle, mem_ read e mem_ write foram ampliadas no módulo MLite para dar suporte ao acesso a dispositivos externos mapeados em memória,.
O acesso foi implementado através de chamadas de métodos dos canais de comunicação.
Introdução A validação dos diversos modelos abstratos apresentados anteriormente constitui uma etapa importante deste trabalho.
Este Capítulo apresenta os procedimentos adotados para validar os modelos propostos e para avaliar os resultados obtidos a partir de a simulação dos modelos.
As Seções a seguir apresentam o processo de validação do módulo Plasma na Seção 7.2, da NoC Hermes na Seção 7.3 e do sistema multiprocessado HeMPS na Seção 7.4.
Por fim, a Seção 7.5 apresenta resultados preliminares obtidos por a simulação do modelo abstrato do processador Plasma.
Validação do módulo Plasma Esta Seção está subdividida em duas partes.
A primeira apresenta a validação considerando o módulo processador MLite.
A segunda parte apresenta a validação do processador considerando a memória como um componente separado.
Em o módulo Plasma, existem outros cinco componentes além de o processador e da memória.
Considerando que estes componentes se destinam ao suporte do funcionamento do Plasma no escopo do sistema HeMPS, a validação destes componentes será apresentada somente na Seção 7.4.
A validação do módulo MLite foi realizada a partir de a simulação de aplicações de software compiladas para a arquitetura MIPS-I e executadas sobre dois cenários, ambos implementados no ambiente System Studio.
O primeiro cenário, mostrado na Figura 37, executa a simulação sobre um único processador, denominado mlite1.
O objetivo deste cenário foi validar a funcionalidade do módulo quanto a a execução de código de máquina.
C1 e C2 são canais de comunicação usados para interligar os módulos.
M1 representa a instância do processador MLite e data_ in e data_ out são portas SystemC de entrada e saída.
M2 constitui um módulo destinado a registrar os valores produzidos e enviados por M1 de forma a comparar- los com os valores previstos.
Ambos os módulos são instanciados dentro de um módulo hierárquico.
Em o cenário da Figura 37, o módulo M1 executa aplicações do tipo produtor/ consumidor.
Dados são gerados em M1 e consumidos e registrados por M2.
A porta SystemC C1 não é utilizada neste cenário.
Duas aplicações foram executadas sobre o modelo monoprocessado:
Um gerador seqüencial de inteiros:
Esta aplicação simples teve por objetivo a validação inicial do módulo.
Trata- se de um contador que gera números inteiros de 32 bits de forma crescente e decrescente.
Cada valor gerado é enviado por o canal C2 e registrado por M2;
um algoritmo de ordenação tipo bubble sort:
Esta aplicação teve por objetivo realizar um processamento mais exigente em termos de uso de recursos e tempo de simulação, se comparado ao gerador de inteiros.
Inicialmente, atribui- se uma seqüência de valores decrescentes a um vetor de inteiros, cujo tamanho é parametrizável no código C. Cada valor do vetor é enviado por o canal C2 e registrado por M2.
O vetor é então ordenado em ordem inversa e seus valores novamente enviados e registrados por M2.
Esta aplicação foi executada considerando diversas variações, tanto no tamanho do vetor quanto no número de ordenações executadas.
O segundo cenário, mostrado na Figura 38, usa duas instâncias do modelo abstrato do processador.
Este cenário tem por objetivo testar a comunicação entre processadores, funcionalidade posteriormente utilizada quando um número maior de instâncias é inserido no sistema HeMPS.
C1, C2 e C3 representam os canais de comunicação, M1 e M2 representam instâncias dos processadores MLite e M3 o modelo destinado a registrar os valores recebidos de M2.
Todos os módulos são instanciados dentro de um módulo hierárquico.
M1 executa uma aplicação do tipo produtor/ consumidor e M2 executa uma aplicação do tipo consumidor.
Os dados produzidos em M1 são consumidos por M2, que então os envia a M3 para serem mostrados.
Sobre este cenário foi executada uma aplicação gerador/ consumidor seqüencial de inteiros.
Esta aplicação teve como objetivo criar um fluxo de comunicação entre dois módulos distintos do processador, aspecto fundamental para validar a comunicação entre processadores.
Compreende dois programas executados em paralelo nos dois processadores:
Um produtor e um consumidor.
O produtor, executado em M1, gera números inteiros de 32 bits de forma crescente e decrescente e os envia ao segundo programa através do canal C2.
Os valores recebidos por M2 são repassados por este processador ao módulo M3 onde são registrados por a aplicação consumidora que executa neste módulo.
A validação do módulo de memória foi realizada executando os mesmos programas da versão com um processador.
Este terceiro cenário pode ser visto na representação esquemática já introduzida na seção 4.2.2, Figura 18.
O principal objetivo desta validação foi garantir que a execução do código fosse realizada corretamente, fazendo uso do módulo de memória externa ao processador conectado ao último através de um canal de comunicação.
Validação da infra-estrutura de comunicação Hermes A validação do módulo Hermes foi realizada através da inserção de módulos do tipo produtor/ consumidor nas portas locais dos roteadores.
A Figura 39 mostra a representação esquemática de uma rede HERMES 2 x2, juntamente a quatro módulos produtores e quatro consumidores conectados às portas locais de cada roteador através de canais hierárquicos.
A o centro da Figura encontra- se a rede Hermes, com 4 roteadores.
Em as extremidades estão os pares de módulos produtor/ consumidor interligados à rede através de canais hierárquicos.
Cada módulo produtor monta um pacote contendo dados de teste e envia estes a cada consumidor localizado em outro ponto da rede.
Cada módulo consumidor por sua vez recebe e registra os pacotes enviados por os demais produtores.
Este mecanismo permite gerar um cenário de comunicação onde cada produtor envia pacotes de dados para todos os demais consumidores e cada consumidor recebe pacotes de todos os produtores, garantindo com isto a validação da comunicação entre todos os roteadores existentes na rede.
Validação do sistema multiprocessado HeMPS Duas abordagens foram consideradas para realizar a validação do sistema HeMPS.
A primeira é através da escrita de trechos de código especificamente criados para validar partes ou conjuntos de partes do sistema.
A segunda é através do uso do próprio microkernel, usado como software de validação dos diversos módulos do sistema.
A escolha final recaiu sobre o uso do microkernel.
Os principais motivos que determinaram esta escolha foram:
HeMPS; A possibilidade de validar o modelo abstrato desenvolvido neste trabalho, a partir de software já validado previamente;
O processo de validação da versão abstrata do sistema HeMPS foi realizado em duas etapas, descritas nas Seções a seguir.
A primeira etapa tem por objetivo realizar a validação da funcionalidade dos submódulos do elemento de processamento Plasma.
Executa- se a fase inicial do microkernel (boot), tanto para o processador mestre como para os escravos.
Também considera- se uma aplicação exemplo compondo o repositório de tarefas, consistindo de um conjunto de quatro tarefas numeradas de 0 a 3.
A alocação das tarefas foi realizada de forma estática como segue:
Tarefa 0 no processador 10, tarefa 1 no processador 11, tarefa 2 no processador 20 e tarefa 3 no processador 21.
O processador 01 executa o microkernel mestre e o processador 00 não é usado.
A Tabela 9 apresenta o resumo das operações executadas por o microkernel mestre durante o boot, sob a forma de uma lista de tarefas.
Esta etapa de validação executa com sucesso todas as operações desta tabela, com exceção da operação 11, uma vez que o objetivo foi validar o processo de boot e não a execução de tarefas em si.
Atribui o valor zero para toda a área de memória que contém dados estáticos.
Boot. S Invoca a execução da função principal, main.
Ajusta os valores iniciais dos registradores de pilha fp e sp, e do registrador que aponta para a área de dados estáticos, gp.
Atribui valores iniciais às estruturas de dados:
Free_ pages, task_ locations e processors.
Invoca a execução da função InitializeProcessors, que registra o número (endereço) dos processadores na estrutura processors.
Para cada tarefa existente, invoca a execução da função InitializeTasks, que kernel_ c registra a identificação da tarefa e o endereço de rede do processador onde esta será executada na estrutura task_ locations.
Invoca a execução da função TaskAllocation que, para cada registro existente em task_ locations (uma tarefa), envia ao processador alvo da tarefa um pacote kernel_ c contendo o serviço 40 e o código objeto da tarefa via o driver DRV_ AllocationTask (boot_ s).
Adicionalmente envia aos demais processadores um pacote contendo o serviço 50 junto à identificação e endereço do processador da tarefa alocada.
Invoca a execução do driver DRV_ FinishedAllocation, que envia um pacote kernel_ c contendo o serviço 90 para cada processador escravo existente, indicando o fim da alocação estática de tarefas.
Invoca a execução da função Os_ InterruptMaskSet, que insere o bit referente a a kernel_ c interrupção da Ni no registrador máscara de interrupção, irq_ mask do módulo CP0.
Invoca a execução da função Os_ AsmInterruptEnable, que ativa o registrador Sr kernel_ c do módulo CP0, indicando que o processador mestre está apto a tratar interrupções.
Inicia a execução de um laço sem conteúdo e condição de parada, correspondendo à tarefa ociosa (idle task).
Para facilitar a análise e validação do processador mestre, a simulação é dividida em duas partes.
Em a primeira parte, o módulo Plasma mestre executa dois procedimentos:
A Figura 40 apresenta o processo de registro da captura gerada por a primeira parte da simulação, que corresponde aos dois procedimentos citados.
Em a parte superior da Figura pode ser vista a indicação de início da simulação.
Logo a seguir observa- se a saída gerada por o módulo MEM_ EXT, onde se mostra os três campos do cabeçalho de cada tarefa:
Identificação, tamanho e endereço inicial do código de máquina.
Embora o espaço de endereçamento deste módulo esteja entre 0x10000000 e 0x1 f, o endereçamento local inicia na posição de memória 0x00000000.
Por exemplo, o endereço 0x00000030 hachurado na Figura 40 indica o início do código de máquina das tarefas, logo após o seu cabeçalho.
Isto se deve ao fato de que internamente ao receber um acesso ao endereço 0x10000030, deste será subtraído 0x10000000, gerando o endereço local usado na estrutura de memória do módulo MEM_ EXT.
Em a parte inferior pode ser vista a confirmação da carga de 1108 palavras a partir de o arquivo repository.
Txt, imagem da memória externa (repositório), indicando as quatro tarefas da aplicação selecionada.
Em a seqüência nota- se a carga de 1483 palavras referente a o código de máquina do microkernel mestre.
Concluída a primeira parte da simulação, inicia- se a segunda parte onde o processador MLite passa a executar o microkernel mestre.
Em este momento, começa o processamento das operações listadas na Tabela 9.
A execução das operações 7 e 8 em particular geraram grande fluxo de dados a partir de o processador mestre, correspondendo à distribuição das tarefas para os processadores escravos.
O fluxo de dados produzido é registrado de forma a comparar os dados enviados com os valores previstos, o que permite validar a execução a segunda parte da simulação.
A Figura 41 e a Figura 42 apresentam a captura do fluxo de dados gerado por as operações 7 e 8, respectivamente.
Para facilitar a compreensão do fluxo gerado, a Tabela 10 e a Tabela 11 apresentam respectivamente uma descrição dos conteúdos gerados por as operações 7 e Cada uma das Tabelas possui 3 colunas:
A primeira indica a linha ou linhas correspondentes da Figura 41 ou da Figura 42;
a segunda coluna indica o valor ou valores assumidos para cada flit representado em hexadecimal;
A terceira coluna introduz um comentário sobre o significado do flit ou flits referenciados.
Reticências indicam a existência de uma seqüência contendo mais de dois de flits.
Em a Figura 41 e na Figura 42 reticências indicam uma seqüência de flits omitidos;
Os números de linhas não correspondem à seqüência de flits enviados, mas sim à seqüência de linhas apresentadas nas Figuras.
Header (target):
Identificação do processador alvo, para onde será enviado o pacote neste caso para o processador escravo de número 10.
Header (size):
Quantidade de flits a serem enviados no campo payload, resultado de:
6+ code size, (tamanho do cabeçalho)+ (tamanho do código objeto x 2).
Payload (service):
Código do serviço para alocação estática de tarefa.
Payload (task id):
Identificação da tarefa que está sendo enviada para alocação, neste caso a tarefa de número 0 (zero).
Últimos dois flits do payload (task code) da última tarefa enviada para alocação, no caso a 3.
Header: Target e size do pacote gerado depois de finalizado o envio de cada tarefa para alocação, neste caso para a última tarefa.
Payload (service):
Serviço usado para informar que uma tarefa foi alocada num 0 e 50 processador escravo.
Este pacote é enviado por o processador mestre a todos os processadores escravos, menos àquele onde a tarefa foi alocada, para que a tabela local de tarefas alocadas de cada processador seja atualizada.
Payload: Indica em que processador a tarefa foi alocada, no caso o 21.
Payload: Indica o número da tarefa que foi alocada, no caso a 3.
O mesmo conteúdo das linhas 19 a 22, porém enviado para o processador 20 A Figura 42 apresenta o fluxo de dados gerado por a operação 8 e a Tabela 11 a descrição dos dados deste fluxo.
Header (target):
Identificação do processador alvo para onde será enviado o 10 e 2 pacote, neste caso para o processador escravo de número 10 Header (size):
Quantidade de flits a serem enviados no campo payload.
Payload (service):
Serviço usado para informar o fim da alocação estática de tarefas.
Fim do processo de simulação da primeira fase de simulação.
Tempo consumido e utilização da CPU por a simulação nesta etapa.
A Tabela 12 apresenta o resumo das operações executadas por o microkernel escravo durante o boot, sob a forma de uma lista de tarefas.
Atribui o valor zero para toda a área de memória que contém dados estáticos.
Boot. S Invoca a execução da função principal, main.
Ajusta os valores iniciais dos registradores de pilha fp e sp, e do registrador que aponta para a área de dados estático, gp.
Invoca a execução da função ASM_ SetInterruptEnable (boot_ s), que desativa kernel_ c no registrador Sr do módulo CP0, indicando que o processador não irá tratar interrupções.
Invoca a execução da função Ni_ Init (ni_ c), que atribui zeros a duas variáveis de controle.
Invoca a execução da função Os_ Init, que realiza as seguintes funções:
Obtém os endereços dos registradores gp e sp e os armazena na estrutura system_ tcb;
Invoca a execução da função ASM_ RunSchedulerTask (boot_ s) passando como parâmetro o ponteiro current (endereço da tarefa Idle), que realiza o seguinte:
Todas as operações da Tabela 12 são executadas com sucesso nesta etapa de validação, exceto a operação 7, uma vez que o objetivo é validar o processo de boot e não a execução das tarefas.
Para facilitar a análise e validação do processador escravo, a simulação foi dividida em duas partes.
Em a primeira parte da simulação o processador mestre executa o procedimento load_ code, implementado no módulo RAM que carrega o microkernel escravo na memória principal;
A Figura 43 apresenta o registro da primeira parte da simulação, que corresponde ao procedimento citado acima.
Em a parte superior da Figura pode ser vista a indicação de início da simulação.
Logo a seguir, observa- se a saída gerada por o módulo RAM, indicando a carga de 4680 palavras, referente a o código de máquina do microkernel escravo.
A carga do repositório de tarefas não é executada por nenhum processador escravo, uma vez que apenas o mestre tem acesso a este repositório.
Concluída a primeira parte da simulação, inicia- se a segunda parte, onde os processadores escravo passam a executar o microkernel escravo.
Em este momento, iniciase o processamento das operações da Tabela 12.
A execução destas operações não gera fluxo de dados do processador escravo para a NoC, apenas processamento local.
Concluída a execução de todas as operações, a simulação termina, o que pode ser notado no destaque da parte inferior da Figura 43.
Por fim, a última linha apresenta o tempo consumido e a utilização de CPU por esta etapa da simulação.
Esta Seção apresentou o processo de validação do módulo HeMPS, considerando tanto o processador mestre como os processadores escravo juntamente com trechos do microkernel relacionado a cada um de eles.
Esta primeira fase de validação permitiu verificar a funcionalidade de seis dos sete módulos existentes no módulo Plasma.
A exceção foi o módulo UART, que é usado apenas quando uma tarefa num dos processadores escravos envia uma mensagem de depuração ao mestre.
A Figura 44 apresenta a representação esquemática dos módulos mestre e escravo usados para a primeira etapa da validação.
O módulo mestre está conectado a um módulo Loger usado para gerar o registro (log) do fluxo de dados que seria enviado à NoC Hermes.
A segunda etapa de validação tem por objetivo simular a funcionalidade da infraestrutura de rede Hermes em conjunto com os elementos de processamento Plasma.
Esta etapa é executada fazendo uso de parte do microkernel, o mesmo usado na fase anterior, incluindo também a mesma aplicação de teste escrita para ser usada como repositório de tarefas.
A Figura 45 mostra a estrutura geral do modelo usado nesta etapa.
Resultados quantitativos preliminares Foram realizadas diversas simulações do modelo abstrato do Plasma, a fim de comparar- lo à descrição RTL existente do Plasma.
O desempenho foi medido considerando o tempo total consumido para realizar uma simulação completa.
Uma simulação completa é aquela que executa todos os procedimentos de uma aplicação.
O final da execução do código e conseqüentemente da simulação ocorre quando uma instrução break é reconhecida.
As Figura 46 e Figura 47 mostram gráficos comparativos de simulações executadas respectivamente a partir de a versão RTL do projeto Plasma e da versão abstrata produzida no escopo deste trabalho.
Simulações dos modelos Abstratos x RTL:
Tempo Abstr.
ISS e um modelo RTL.
Simulação abstrata realizada no ambiente System Studio, e simulação RTL realizada no ambiente Modelsim da Mentor.
Simulações dos modelos Abstratos x RTL:
Ocupação da CPU Tempo Abstr.
Tempo RTL CPU Abstr.
Os recursos computacionais usados nas simulações são:
Sistema operacional Red Hat Enterprise Linux Ws release 4;
Hardware: Processador Intel Xeon 3.80 GHz e memória RAM DDR2 4 GBytes;
Ferramentas de software:
Synopsys CoCentric System Studio e Mentor ModelSim.
A partir de os gráficos, pode- se concluir que o tempo de simulação no modelo abstrato permaneceu relativamente estável em todas as simulações.
O mesmo não ocorreu com a simulação do modelo RTL, o que já era esperado.
Em o melhor caso, vetor com 10 elementos, o tempo de simulação do modelo RTL foi 12 vezes maior que o modelo abstrato, chegando a ser 3698 vezes maior para o pior caso, o vetor de 800 elementos.
Outro aspecto a ser destacado é o nível de ocupação que a simulação gerou sobre o ambiente hospedeiro.
A maior taxa ocorrida para o modelo abstrato foi de aproximadamente 13% contra uma taxa próxima a 100% exigida por a simulação RTL.
O menor tempo de simulação e menor uso da CPU se deram por o aumento do nível de abstração, ao custo da perda de detalhes existentes na descrição RTL.
Para os estágios inicias da exploração da arquitetura e para o desenvolvimento antecipado do software do sistema, o modelo abstrato é claramente mais apropriado.
Conclusões e contribuições A principal contribuição do presente trabalho foi disponibilizar um modelo funcional parametrizável, descrito em alto nível de abstração, do hardware do sistema multiprocessado HeMPS existente no grupo de pesquisa do autor.
O modelo foi desenvolvido fazendo uso do ambiente comercial para desenvolvimento de sistemas System Studio da Synopsys.
Este ambiente permite realizar, com relativa facilidade, a simulação comportamental do sistema de referência, a partir de o modelo capturado via descrições arquiteturais implementados em linguagem SystemC, o que insere maior produtividade na fase inicial de projeto.
Os dois componentes básicos do sistema, o elemento de processamento e a rede intrachip, foram modelados e integrados, sendo usados para o processo de validação do sistema HeMPS.
Parte do software básico da HeMPS foi usado para validar o modelo desenvolvido.
O Plasma modelado neste trabalho compreende efetivamente uma infra-estrutura de processamento composta por:
Processador MLite, interface de rede, controlador de acesso direto à memória, memória principal e co-processador de controle.
Todos os módulos que compõem o processador foram implementados e testados, restando apenas alguns ajustes e validações a serem realizadas no módulo interface de rede com relação a o tratamento de interrupções.
A infra-estrutura de rede Hermes foi integrada e validada mediante a criação de um cenário contendo pares produtor-consumidor em cada nodo da rede, os quais injetaram dados originados e destinados a todos os roteadores existentes, para configurações de rede 2x2 e 3x3.
Os resultados obtidos com a simulação são considerados promissores.
Por exemplo, a simulação do módulo Plasma descrita neste trabalho chegou a atingir ganhos de desempenho em termos de tempo de simulação na faixa de três ordens de magnitude em relação a um modelo RTL clássico do mesmo processador.
Quanto a o modelo como um todo, pretende-se atingir a validação completa por a execução total do software do sistema, compreendendo microkernel e tarefas da aplicação.
Em o escopo deste trabalho, foi considerado o processo inicial do sistema operacional (boot), como critério para realizar a validação do modelo abstrato.
Trabalhos futuros A seguir apresentam- se algumas propostas para trabalhos futuros a realizar:
Explorar possibilidades de generalização dos modelos desenvolvidos.
Esta generalização poderá permitir a geração automática de modelos a partir de parametrizações dos modelos abstratos criados, além de permitir variar cenários da arquitetura a partir de parametrizações.
Explorar a possibilidade de implementação de MPSoCs contendo elementos de processamento heterogêneos.
Explorar formas de realizar mapeamento e migração de tarefas, de maneira a flexibilizar o modelo abstrato desenvolvido.
Explorar a modelagem mista de componentes, com relação a o nível de abstração.
Esta abordagem pode levar a definir cenários mais adequados a cada etapa do desenvolvimento para diferentes variações da arquitetura.
A idéia é fazer evoluir cada um dos modelos não temporizados de módulos desenvolvidos aqui para modelos parcialmente temporizados, precisos em nível de ciclos e combinações destes tipos de modelos para as principais partes do sistema HeMPS.
