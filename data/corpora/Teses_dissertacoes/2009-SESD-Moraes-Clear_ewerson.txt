MPSoCs são sistemas multiprocessados integrados na forma de um SoC.
Eles são tendência no projeto de circuitos VLSI, pois minimizam a crise de produtividade de projeto, representada por o descompasso entre a capacidade da tecnologia do silício e a capacidade atual de projeto de SoCs.
Cita- se como exemplo de MPSoCs os propostos por a Intel e por a Tilera, compostos respectivamente por 80 e 64 núcleos de processamento.
MPSoCs podem empregar NoCs para integrar diversos processadores, memórias, bem como núcleos de hardware específicos.
O uso de NoCs deve- se a suas vantagens em relação a barramentos, entre as quais maior escalabilidade e paralelismo na comunicação.
A arquitetura alvo do presente trabalho consiste num MPSoC heterogêneo, com utilização de NoC como meio interconexão entre os elementos de processamento, suportando a execução de tarefas de hardware via lógica reconfigurável, e a execução de tarefas de software via processadores.
Um dos processadores da arquitetura alvo, denominado processador gerente, é responsável por:
Gerência da ocupação dos recursos do sistema, escalonamento, mapeamento, e configuração de tarefas.
O mapeamento de tarefas define a posição de uma dada tarefa no sistema.
A maioria dos trabalhos encontrados na literatura propõe técnicas de mapeamento estático, definido em tempo de projeto, em o qual todas as tarefas de uma dada aplicação são mapeadas simultaneamente.
Este mapeamento estático não é adequado para cenários com carga dinâmica de tarefas.
Dado que aplicações executando num MPSoC podem possuir um número variável de tarefas, e que tal número pode exceder os recursos disponíveis, é necessário realizar o mapeamento de tarefas em tempo de execução, mapeamento este denominado de mapeamento dinâmico.
O presente trabalho investiga o desempenho de heurísticas para mapeamento dinâmico de tarefas, com o objetivo de minimizar congestionamentos em NoCs.
As tarefas são mapeadas sob demanda, de acordo com as requisições de comunicação e com a ocupação dos canais da NoC.
Os algoritmos implementados aplicam estratégias gulosas, onde as tarefas são mapeadas uma por vez.
Para isso, a decisão é baseada na informação local da aplicação, apenas relacionada à tarefa requisitada.
O algoritmo utilizado como referência nos experimentos mapeia uma dada tarefa no primeiro recurso livre encontrado.
Quatro heurísticas congestionaware são propostas.
Através de experimentos realizados com base na modelagem do sistema no nível RTL, pode- se observar redução de 31% na carga nos canais da NoC, de 15% na latência média, e de até 87% no nível médio de congestionamento.
Tais resultados demonstram a eficiência das heurísticas propostas.
Palavras-Chave: Mapeamento dinâmico de tarefas, NoC, SoC, MPSoC.
Inventado nos Laboratórios da Bell Telephone em dezembro de 1947, o transistor é componente fundamental da microeletrônica.
A o passar do tempo, a evolução da tecnologia submicrônica permite reduzir consideravelmente as dimensões dos transistores.
Com isso, a indústria de semicondutores pode produzir circuitos integrados (CIs) mais complexos e de alto desempenho, a um custo relativamente baixo.
A ITRS prevê que circuitos integrados fabricados na próxima década terão dezenas de bilhões de transistores, com dimensão em torno de 50 nm e freqüência de operação acima de 10 Ghz.
De aí surge um importante desafio relacionado à capacidade de fazer uso eficiente dessa tecnologia.
A dificuldade em manter a produtividade de acordo com a crescente complexidade dos sistemas evidência a crise de produtividade de projeto, que representa justamente o espaço entre a tecnologia do silício e a capacidade de projeto de CIs.
A Figura 1.1 demonstra o crescimento exponencial do número de transistores por Ci desde a introdução dos computadores pessoais, em 1981.
Enquanto a produtividade cresce 21% Espaço Complexidade (transistores por Ci) 58% ao ano 21% ao ano Produtividade (transistores por funcionário-mês) ao ano, a complexidade apresenta um crescimento quase três vezes superior, de 58%.
Como o fator humano também influi na crise, surge como tendência o emprego de grupos grandes em projetos modulares, onde equipes menores desenvolvem partes do projeto de forma distribuída e paralela, de acordo com o conceito de divisão e conquista.
A crise também demanda o contínuo melhoramento dos métodos de projeto, que devem empregar níveis de abstração cada vez mais altos, bem como uma maior automação, através de ferramentas de CAD mais poderosas.
Uma solução apontada para reduzir da crise de projeto consiste no desenvolvimento de sistemas complexos integrados num único circuito.
Tal estratégia de integração recebe o nome de SoC (do inglês, System-on-Chip).
Sua primeira vantagem diz respeito ao desempenho do sistema com relação a o tempo de execução.
As comunicações entre os componentes do SoC podem ocorrer mais rapidamente em comparação à estratégia convencional, pois eles se encontram todos no mesmo circuito.
A principal vantagem do emprego de SoC é o tempo reduzido de projeto, contribuição considerável para a redução da crise de projeto.
Geralmente, o projeto de SoC é baseado no reuso de núcleos de hardware (do inglês, Intellectual Property Cores ou IPs).
Como os IPs são módulos préprojetados e pré-validados, a técnica de reuso pode garantir um tempo menor para o produto chegar ao mercado, fator imprescindível no cenário competitivo atual.
Em geral, o aumento da complexidade das aplicações demanda maior capacidade de processamento.
Tal fato impulsiona o desenvolvimento de sistemas computacionais composto por vários processadores, outrora implementados na forma de clusters (Agregados de computadores), agora implementados na forma de um SoC.
Em o domínio dos clusters, obtêm- se ganho de desempenho através da conexão de vários computadores por meio de redes rápidas de comunicação.
As aplicações são então paralelizadas para executar nos vários processadores que compõem arquitetura.
MPSoCs (do inglês, Multi-Processor System-on-Chip) são sistemas multiprocessados implementados na forma de um SoC.
Em geral, eles são compostos por vários elementos de processamento, memórias e núcleos de hardware específicos.
Todos esses componentes são conectados por meio de uma infra-estrutura de comunicação, a qual requer flexibilidade para suportar a conexão de muitos e diversificados elementos de processamento.
Não só o projeto de sistemas complexos, tais como MPSoCs, requer atenção.
Adicionalmente, o suporte à operação consiste num assunto não menos complicado e igualmente relevante.
Dois tópicos importantes em MPSoCs dizem respeito à sua infraestrutura de comunicação intrachip e à gerência dos recursos do sistema.
O desempenho da infra-estrutura de comunicação reflete diretamente no desempenho do sistema.
Com isso, torna- se imprescindível que tal infra-estrutura suporte taxas consideráveis de comunicações, e alto paralelismo.
Além disso, o crescimento do número de elementos processadores nos sistemas exige o emprego de infra-estruturas mais escaláveis.
Porém, pode- se afirmar que estratégias tradicionais de comunicação, tais como barramento e ponto- aponto não são escaláveis o suficiente para as futuras arquiteturas.
As redes intrachip (do inglês, Networks-on-Chip ou simplesmente NoCs) consistem numa nova abordagem de comunicação, baseada no reuso de conceitos bem conhecidos de redes de computadores no domínio intrachip.
De forma simplificada, uma aplicação é um conjunto de tarefas.
Cada uma destas é responsável por executar parte da funcionalidade da aplicação, e em geral comunicam- se entre si para troca de dados.
Em sistemas complexos, as tarefas podem executar no mesmo ou em diferentes elementos de processamento.
Adicionalmente, diversas aplicações podem executar em paralelo.
Muitas aplicações que executam em MPSoCs (Em o domínio de multimídia e redes) apresentam uma carga dinâmica de tarefas.
Isso implica um número variável de tarefas executando em paralelo, podendo o número necessário exceder os recursos disponíveis no MPSoC.
De aí surge a necessidade de controle da operação e dos recursos do sistema, incluindo o gerenciamento dinâmico da carga das tarefas, que corresponde às funções de escalonamento e mapeamento.
O escalonador de tarefas é responsável por determinar a ordem em a qual as tarefas serão carregadas para execução num dado elemento de processamento do MPSoC.
Após decidir qual tarefa, é preciso decidir em qual posição ela deve ser carregada.
Basicamente, esse é o objetivo do mapeamento de tarefas.
Essa operação exige o controle total da ocupação dos recursos do sistema (Elementos de processamento, memória, canais da NoC, etc), sob o risco de fazer mal uso dos recursos do MPSoC.
De entre os assuntos que envolvem o suporte operacional para um MPSoC, o mapeamento de tarefas desperta interesse, pois pode influenciar no desempenho do sistema, seja no tempo de execução das aplicações, seja na dissipação de potência.
A continuidade desse Capítulo introduz em maiores detalhes a abordagem de rede intrachip como uma alternativa de conexão.
A seguir, na Seção 1.2 discutese conceitos básicos de MPSoC, incluindo a motivação para seu estudo.
A Seção 1.3 introduz e define de forma sucinta o problema de mapeamento de tarefas.
O final do Capítulo dedica- se à apresentação dos objetivos do trabalho e à organização dos Capítulos que compõem a presente Tese.
No que diz respeito a sua estrutura, uma rede intrachip é composta basicamente por um conjunto de roteadores e canais de comunicação que interconectam os núcleos de um sistema integrado).
Sua funcionalidade é suportar a comunicação entre tais núcleos, que ocorre através da troca de mensagens geralmente transmitidas na forma de pacotes ao longo de a rede.
A flexibilidade da NoC deve permitir a cone-xão de núcleos de diferentes naturezas, GPPs, memórias, dispositivos de entrada/ saída ou ainda IPs específicos.
Além disso, cada um de eles pode ter características próprias de voltagem, freqüência de operação e/ ou tecnologia.
Importantes conceitos herdados da área de redes computadores são aplicados no nível intrachip.
Uma NoC pode ser caracterizada por sua topologia e por os mecanismos de comunicação adotados.
A topologia corresponde à organização dos seus roteadores de acordo com um grafo, onde os roteadores são representados por os vértices, e os canais por as arestas.
As topologias mais comuns são malha e toro), principalmente por serem regulares e planares, portanto mais facilmente implementadas em circuitos 2D.
Os mecanismos de comunicação de uma rede definem a forma como os pacotes trafegam através de ela.
O controle de fluxo lida com a alocação dos recursos (Buffers e canais) necessários para um pacote avançar por a rede.
Exemplos são controle de fluxo baseado em créditos ou baseado num protocolo de handshake.
O algoritmo de roteamento define o caminho a ser utilizado por uma mensagem para atingir o seu destino.
Alguns exemplos de roteamento são xy, west-- first, negative-first, de entre outros.
A política de arbitragem é responsável por resolver os conflitos internos na rede, quando duas ou mais mensagens competem por um mesmo recurso (buffer ou canal de saída).
Ela pode ser baseada, por exemplo, em prioridades.
O mecanismo de chaveamento define como uma dada mensagem é transferida da entrada de um roteador para um de seus canais de saída (circuito ou pacote).
A memorização determina o esquema de filas utilizado para armazenar as mensagens.
Como exemplo, pode ser utilizado buffers nas entradas, nas saídas ou em ambos os tipos de portas dos roteadores.
Como mencionado anteriormente, o emprego de NoCs é imprescindível frente a as limitações impostas por os barramentos, relativas à baixa escalabilidade e ao pouco paralelismo suportado na comunicação.
Adicionalmente, as redes podem suportar o paradigma Globalmente Assíncrono Localmente Síncrono ou GALS.
O aumento da freqüência de operação dos circuitos faz com que o atraso de propagação dos sinais exceda o período de relógio.
O paradigma GALS promete amenizar tal problema, decompon- do o sistema num conjunto de núcleos síncronos que interagem de uma maneira assíncrona.
Por tudo isso, o emprego de NoC é tendência conforme atesta o grande volume de trabalhos recentemente publicados nessa área.
MPSoCs são arquiteturas que buscam um compromisso entre restrições da tecnologia VLSI e as necessidades da aplicação.
Eles representam tendência no cenário atual das pesquisas.
Grande parte desse interesse deve- se ao fato do MPSoC representar uma evolução do conceito de SoC, beneficiando- se do reuso no projeto.
Além disso, MPSoCs apresentam um conceito simples para obter alto desempenho, o uso de várias unidades de processamento em paralelo.
Esse conceito foi empregado já em 1976 por o processador vetorial Cray-1, evoluiu até as primeiras máquinas agregadas (Projeto Beowulf Dual e quad core).
O gráfico esboçado na Figura 1.3 demonstra o crescimento do número de núcleos nos processadores nas últimas décadas, com destaque para o período posterior ao ano de 2005, quando o crescimento é acentuado e surgem implementações com mais de 16 núcleos.
Sob o ponto de vista do multiprocessamento, um MPSoC é dito homogêneo quando os elementos processadores que o compõem são todos da mesma natureza.
Por exemplo, um sistema composto por processadores idênticos que permitem exclusivamente a execução de tarefas de software compiladas para tal arquitetura de processador.
De outra forma, quando o MPSoC possui elementos de processamento diferentes (GPPs, DSPs, etc) ele é dito heterogêneo.
Em esse caso as tarefas também serão de naturezas distintas.
Enquanto MPSoCs homogêneos tendem a simplificar a aplicação de técnicas como migração de tarefas, MPSoCs heterogêneos podem suportar uma variedade maior de aplicações.
Para garantir qualidade e desempenho, um decodificador de TV digital, por exemplo, deve ser heterogêneo o suficiente para integrar processadores (RISC), núcleos de hardware dedicados (Upsampler) e memórias (SDRAM).
Além disso, cada um desses componentes possui diferentes funcionalidades, tamanhos e necessidades de comunicação, o que demonstra a complexidade desses sistemas.
MPSoCs podem ainda empregar lógica reconfigurável.
Essa tecnologia emerge no projeto de CIs, pois sugere ao hardware flexibilidade similar ao software, permitindo a carga de tarefas de hardware no sistema até mesmo em tempo de execução.
Reconfiguração dinâmica é a técnica que permite modificar o comportamento do hardware.
Além disso, a implementação de funcionalidades de uma aplicação através de tarefas de hardware pode representar um ganho significativo de desempenho, sem, no entanto comprometer a área do circuito.
Essa prática é denominada hardware virtual.
Atualmente foram produzidos MPSoCs com tamanhos significativos, como os propostos por a Intel e por a Tilera.
O primeiro de eles é composto por 80 núcleos de processamento idênticos, enquanto o outro por 64 núcleos também idênticos.
No que diz respeito à comunicação, ambos MPSoCs citados empregam NoCs com topologia malha.
Além de o proeminente ganho de desempenho, o estudo de MPSoCs também interessa porque renova a pesquisa em áreas clássicas da ciência da computação.
Ele remete o pesquisador a tópicos relacionados a sistemas operacionais, processamento paralelo, redes de computadores, microeletrônica, de entre outros.
O desenvolvimento e a implementação de um MPSoC é um processo bastante complexo que exige vasto conhecimento em todas essas áreas.
O gerenciamento dinâmico dos recursos do MPSoC é crucial para o uso efetivo de todo o poder de processamento disponibilizado por essa tecnologia.
Definido de maneira informal, o mapeamento de tarefas consiste na escolha da melhor posição para uma dada tarefa.
Em sistemas heterogêneos, antes do mapeamento propriamente dito é necessário realizar um passo de ligação (do inglês, binding), responsável por assegurar a atribuição das tarefas apenas aos elementos de processamento adequados.
Por exemplo, num MPSoC composto por processadores e lógica reconfigurável, as tarefas de hardware só podem ser carregadas na lógica reconfigurável embarcada.
O problema de mapeamento é similar ao problema de atribuição quadrática (do inglês, quadratic assignment problem ou QAP).
O QAP é um dos problemas fundamentais de otimização combinatória, sendo um problema Np-completo, ou seja, não existe uma solução para resolver- lo em tempo polinomial.
De essa forma, para pequenas instâncias do problema, Mapeamento de tarefas numa NoC de dimensões 2x2, o tempo para encontrar a melhor solução usando métodos exaustivos deve ser relativamente baixo, enquanto que para uma NoC 5x5 o tempo pode ser inaceitável.
É importante citar aqui que algumas das arquiteturas propostas por a Intel e por a Tilera possuem redes de dimensões 8x8 e 8x10, respectivamente.
De essa forma, torna- se obrigatório o emprego de heurísticas para resolução do problema de mapeamento.
Algumas das principais heurísticas adotadas são baseadas em algoritmos genéticos, Simulated Annealing ou Tabu Search.
Com relação a o instante da decisão, o mapeamento é dito estático quando definido em tempo de síntese ou projeto, enquanto que o mapeamento dinâmico é aquele determinado em tempo de execução, em função de parâmetros tais como carga do sistema, estado de congestionamento na interface de comunicação dos roteadores, por exemplo.
A operação de mapeamento pode empregar diferentes critérios para otimização e diferentes funções custo.
No que diz respeito à função custo adotada, pode- se considerar a fragmentação resultante do sistema, a dissipação de potência, e ainda a ocupação dos canais.
Em sistemas com restrições de tempo real, o atendimento dos deadlines das tarefas ganha importância na tomada da decisão.
Para o caso onde as aplicações apresentam necessidades específicas de comunicação, o gerenciamento da ocupação dos canais é crucial para manutenção da qualidade de serviço da rede.
Geralmente a qualidade de serviço (QoS) de uma dada rede diz respeito à largura de banda disponibilizada para uma dada aplicação.
Já no caso de dispositivos portáteis, o consumo de energia deve representar a principal função.
A maioria dos trabalhos encontrados na literatura propõe soluções para mapeamento estático de tarefas, mas recentemente alguns trabalhos começam a investigar também o mapeamento dinâmico de tarefas.
Dois trabalhos sobre mapeamento estático evidenciam- se por investigar algoritmos de mapeamento que consideram a energia consumida por o sistema, técnicas geralmente denominadas Power ou Energy--aware.
São eles os trabalhos de Hu e Marculescu e Marcon e outros.
Os Autores destes trabalhos buscam reduzir a energia consumida do sistema relativa à comunicação.
No caso de aplicações de comunicação intensiva, tais como aplicações de fluxo de dados, a manutenção da ocupação da infra-estrutura de comunicação é fundamental.
A ocorrência de congestionamentos pode acarretar problemas na transmissão de vídeo e áudio, por exemplo.
Para essa classe de aplicações, os métodos congestion-- aware são empregados.
Eles visam uma ocupação inteligente do meio de comunicação, evitando ou ao menos reduzindo os congestionamentos.
Para isso, o mapeamento congestion-- aware, aplicado sobre uma NoC, considera a ocupação de cada um dos canais da rede.
Como tal estratégia diminui a ocupação dos canais da rede, pode- se estimar que o tempo total de execução do sistema também será reduzido.
Adicionalmente, tal mapeamento deve contribuir também para redução da energia consumida, isso porque assim como em e, aqui congestionamentos são evitados através da diminuição do número de saltos que os pacotes percorrem entre sua fonte e destino.
Entretanto, essa possível redução de energia é apenas um efeito colateral do mapeamento congestion-- aware.
A estratégia de migração de tarefas também tem sido aplicada em MPSoCs para otimizar o desempenho em tempo de execução.
Essa estratégia, muito utilizada no domínio de aplicações paralelas, visa realocar uma dada tarefa ou quando um gargalo de desempenho é identificado, ou para distribuir de maneira mais uniforme a carga de trabalho entre os elementos de processamento do sistema.
Em muitos trabalhos o termo escalonamento é substituído por o termo mapeamento temporal.
Enquanto isso, o mapeamento espacial aqui tratado, recebe o nome de mapeamento, posicionamento ou ligação.
Para evitar confusão, no presente trabalho são mantidos os termos escalonamento para referenciar o mapeamento temporal, e apenas mapeamento quando se tratar de mapeamento espacial de tarefas.
A originalidade do trabalho consiste na proposta de uma abordagem de mapeamento que visa preencher a lacuna identificada entre as estratégias estáticas de mapeamento e as pesquisas sobre migração de tarefas.
As primeiras geralmente aplicam heurísticas complexas de mapeamento, que, no entanto não se adéquam à natureza dinâmica das aplicações.
De outro lado, embora apliquem estratégias dinâmicas, os estudos sobre migração refletem ainda passos iniciais, que em geral focam detalhes como salvamento de contexto e pontos de migração, sem qualquer ênfase nas heurísticas de mapeamento.
De entre os objetivos estratégicos do presente trabalho encontram- se:
Dominar a tecnologia de projeto de MPSoCs;
Revisar o problema de mapeamento dinâmico de tarefas;
Dominar e avaliar as heurísticas empregadas para resolver esse problema;
Adequar o problema à natureza de MPSoCs baseados em NoC;
Propor heurísticas de mapeamento adequadas a estes MPSoCs;
Avaliar tais heurísticas.
Os objetivos específicos desse trabalho são:
Propor um MPSoC factível de implementação;
Definir sua organização (Seus componentes básicos);
Definir sua arquitetura (Interface com as aplicações);
Modelar seu comportamento para verificar sistemas maiores;
Propor e avaliar um mapeamento unificado para tarefas de naturezas distintas.
O presente trabalho investiga o desempenho de seis algoritmos de mapeamento em MPSoCs baseados em NoC, considerando cenários com carga dinâmica de tarefas.
O principal objetivo consiste em minimizar os congestionamentos na rede, através da otimização da ocupação dos seus canais.
Os resultados são obtidos a partir de simulações do sistema composto por uma NoC descrita em VHDL, onde os recursos (Elementos de processamento) são simulados através de threads SystemC.
A avaliação de cada um dos algoritmos implementados considera as seguintes métricas:
tempo de execução total do sistema;
Ocupação dos canais da NoC;
Nível de congestionamento na rede;
Latência dos pacotes transmitidos;
E tempo de mapeamento.
O presente documento encontra- se organizado em sete capítulos.
Em este primeiro apresentou- se a introdução ao assunto incluindo os conceitos de NoC, MPSoC e o problema de mapeamento a ser atacado.
Além disso, os objetivos e a motivação do trabalho proposto foram discutidos.
Em o Capítulo 2, primeiramente apresenta- se um resumo do estado da arte em organizações de MPSoCs propostas, em ambos os domínios acadêmico e industrial.
Em a seqüência, apresenta- se um resumo dos trabalhos relacionados ao mapeamento de tarefas, estático e dinâmico.
Além disso, trabalhos sobre a técnica de migração de tarefas também são abordados.
A o final de cada Seção, um quadro comparativo é apresentado.
Em o Capítulo 4, apresenta- se a principal contribuição do presente trabalho.
Ele propõe um conjunto de seis algoritmos para mapeamento dinâmico de tarefas, incluindo dois algoritmos de referência, sem avaliação de quaisquer funções custo, e outras quatro heurísticas ditas congestion-- aware.
Heurísticas congestion-- aware avaliam a ocupação dos canais da rede na sua tomada de decisão.
Os Capítulos 5 e 6 dedicam- se aos experimentos realizados.
Em o Capítulo 5, cada um dos algoritmos de mapeamento implementado é avaliado com relação a o desempenho da NoC.
As simulações realizadas são baseadas numa plataforma descrita em nível RTL e simulada utilizando ModelSim 6.4 da Mentor Graphics.
Ela é composta por a NoC descrita em VHDL e elementos de processamento descritos em SystemC.
Três cenários de simulações são considerados.
Cada um de eles visa a investigação de aplicações sintéticas com características de conectividade de tarefas e fluxo de dados diferentes.
A o final do documento, o Apêndice A apresenta uma descrição mais detalhada dos gráficos de aplicações empregados nos cenários dos experimentos, bem como os mapeamentos obtidos através da ferramenta CAFES, apresentada em.
Cada vez mais, observa- se como tendência a pesquisa na área de MPSoCs.
Um dos catalisadores desse fenômeno refere- se às aplicações que demandam maior poder computacional.
Além disso, o compromisso entre o custo de projeto de um MPSoC e seu potencial ganho de desempenho é outro atrativo.
O projeto pode beneficiar- se das técnicas de reuso, e a tecnologia do silício suporta a concepção de circuitos cada vez mais complexos.
O conceito é simples, a área de silício disponível é preenchida com módulos replicados.
Contudo, a realização demanda grande esforço da comunidade científica na busca de melhores métodos de projeto e infra-estruturas para suporte operacional mais eficaz.
O presente Capítulo apresenta propostas de organizações para MPSoCs encontradas na literatura.
Em a seqüência, a Seção 2.2 apresenta uma revisão dos trabalhos sobre mapeamento, abrangendo ambas as abordagens, estática e dinâmica (Subseção 2.2.2).
A o final de cada uma das Seções, apresenta- se considerações sobre os trabalhos revisados, incluindo tabelas que facilitam a comparação entre os mesmos.
A migração de tarefas também está inclusa na discussão (Seção 2.3).
Como será apresentado abaixo, existem na literatura tanto propostas acadêmicas de organizações de MPSoCs, quanto produtos baseados nesta tecnologia, de entre eles.
Lin e outros apresentam um MPSoC homogêneo, cuja infra-estrutura de comunicação consiste numa NoC malha.
O MPSoC proposto é composto por processadores e roteadores.
Cada processador possui sua própria memória local, e está conectado a um roteador da NoC.
Os roteadores empregam arbitragem round-robin, chaveamento de circuitos e usam a técnica de canais virtuais.
Em os experimentos realizados, foi empregada uma NoC com dimensões 4x4.
Os elementos de processamento foram substituídos por geradores aleatórios de tráfego.
O trabalho de Lin está focado na investigação de estratégias para mapeamento estático de tarefas, conforme discutido adiante, na Subseção Woszezenki propõe um MPSoC homogêneo, e um conjunto de ferramentas que permitem a geração do sistema, sua simulação e avaliação de resultados.
O MPSoC proposto é composto por um conjunto de processadores, conectados através da NoC Hermes.
Os processadores do MPSoC proposto são baseados numa versão modificada do processador Plasma.
Cada um de eles possui memória local de 64 Kbytes, dividida em 4 páginas:
Uma de elas dedicada ao µkernel desenvolvido e as demais para tarefas (Processadores multitarefa).
Um dos processadores do sistema (Plasma MP) é dedicado a realizar operações de controle (Figura 2.1).
Uma unidade DMA é usada para acelerar a alocação das tarefas.
Este trabalho fornece suporte à alocação dinâmica de tarefas, entretanto nenhuma heurística é investigada.
Saint-Jean e outros empregam um MPSoC homogêneo, que permite o emprego de técnicas para balanceamento de carga.
O MPSoC proposto possui processadores conectados via NoC (Figura 2.2).
Alguns dos processadores do sistema também estão conectados a um barramento, através de o qual se comunicam com os demais componentes do MPSoC (Computador hospedeiro, periféricos, etc).
Cada processador executa um sistema operacional que permite processamento multitarefa.
A NoC empregada é derivada da Hermes.
Em, um MPSoC 2x3 é implementado numa única plataforma de prototipação, ao passo que em e são usadas 9 e 16 plataformas, respectivamente, cada uma contendo um par roteador mais processador.
O PC102 é um MPSoC comercial proposto para aplicação em redes sem fio.
Ele é baseado na arquitetura picoArray (Figura 2.3), onde os processadores são interconectados através de barramentos picoBus (32 bits) e chaves programáveis.
O PC102 possui ao todo 322 processadores, organizados na forma de uma matriz.
Cada processador executa um único processo, e possui suas próprias memórias de dados e instruções.
A infra-estrutura de comunicação adotada possui largura de banda interna de 3.3 Tbits/ s, operando a uma freqüência de 160 MHz.
As comunicações se dão através de sinais de sincronização e dados transmitidos de acordo com um protocolo TDM.
Em, a IBM apresenta o MPSoC heterogêneo CELL, que visa a execução de diversas aplicações, incluindo processamento científico e multimídia.
Seu primeiro alvo foi o videogame PlayStation3.
Conforme a Figura 2.4, o CELL consiste de um processador de 64 bits (PPE), oito processadores aceleradores (SPEs), um controlador de memória, um barramento de interconexão, memória e interfaces de E/ S, tudo integrado na forma de um SoC.
Operando a 3.3 GHz, seu pico de desempenho teórico é 204.8 Gflop/ s para precisão simples e 14.6 Gflop/ s para precisão dupla.
O PPE executa o sistema operacional que coordena todo o sistema.
A interface de conexão (EIB) possui 4 anéis para transmissão de dados, e uma rede com topologia estrela que transporta instruções.
O CELL conta com um ambiente open source para o desenvolvimento de aplicações.
O MPSoC Am2045 é composto por processadores RISC de 32 bits.
Seu projeto visa substituir processadores embarcados, DSPs e FPGAs em aplicações que exigem alto desempenho no processamento de sinais digitais (Codificação e decodificação H. 264).
O Am2045 consiste numa matriz de brics 5x9 (Figura 2.5).
Cada um de eles possui oito núcleos processadores e 8 KB de memória local.
Ao todo são 360 processadores e 585 KB de memória.
Além disso, estão disponíveis controladores de memória DDR2, controlador PCI, 128 portas de E/ S, interface serial para memória flash, e interface JTAG para depuração.
O Ci integra 117 milhões de transistores, fabricado com tecnologia proprietária por o ambiente de desenvolvimento disponível para o Am2045.
Sr ­ Processador RISC SRD ­ Processador RISC com DSP Cluster com 4 núcleos processadores, 4 memórias locais, suas interconexões e estruturas de controle.
A Intel apresenta um MPSoC com 80 elementos de processamento conectados via NoC.
A NoC apresenta topologia malha, e interfaces assíncronas.
O sistema opera com freqüência de 4 GHz.
Cada PE possui duas unidades independentes de ponto flutuante de precisão simples (FPMAC), memória de instruções (IMEM), e memória de dados (DMEM).
O roteador na NoC apresenta chaveamento wormhole e dois canais físicos para transmissão de pacotes.
O MPSoC alcança o pico de desempenho de 1.0 Tflops à 1V e 1.28 Tflops à 1.2 V. O consumo de potência estimado é de 98W à 1V e 181W à 1.2 V. A Tilera apresenta o Tile64, um MPSoC composto por 64 PEs idênticos, conectados via NoC malha iMESH (Figura 2.7).
Seu propósito inclui aplicações de rede, vídeo digital e telecomunicação.
Além de o processador, cada núcleo possui memórias cache L1 e L2.
O Tile64 também possui quatro controladores DDR2;
interfaces MAC e PCI.
Cada PE pode executar seu próprio SO Linux.
PEs operam numa freqüência entre 500 MHz e 866 MHz com consumo de potência entre 15 e 22W a 700 MHz.
Para economizar energia, um dado PE pode entrar no modo sleep quando estiver ocioso.
A programação de aplicativos para o Tile64 pode ser realizada através do Multicore Development Environment (MDE), um ambiente que além de a descrição de código em C, permite ainda simulação, análise de desempenho e depuração.
Em geral, as propostas tanto acadêmicas quanto comerciais são baseadas em MPSoCs homogêneos.
Não existe um padrão para organizações para MPSoC, logo cada pesquisa acaba especificando a arquitetura que melhor lhe convém.
Com relação a a infraestrutura de comunicação, a maioria dos trabalhos investigados adota NoCs com topologias mais simples (Malha) e algoritmos determinísticos de roteamento.
O CELL apresenta- se como exceção visto que adota uma arquitetura de conexão hibrida composta por uma NoC de topologia anel para transmissão de dados, e outra com topologia estrela para instruções.
Além disso, o CELL apresenta- se na forma de um MPSoC heterogêneo.
A Tabela 2.1 abaixo apresenta um resumo comparativo entre as principais características dos MPSoCs comerciais revisados na presente Seção.
Fabricante Am2045 Tile64 Elemento de Processamento Freqüência de Operação Desempenho Homogêneo Híbrida (barramentos picoBus conectados por chaves) Monotarefa 150 MHz Heterogêneo Híbrida (NoC Anel+ NoC estrela) 1 de 64 bits+ 8 aceleradores 204 GFlops/ s Ambric Homogêneo NoC malha RISC 32bits 333 MHz 1 Trilhão de operações por segundo (Tops) Homogêneo NoC malha 2 unidades de ponto Flutuante 4 GHz Tilera Número de PEs Intel Infra--estrutura de comunicação Multiprocessamento picoChip Nome Homogêneo NoC malha (Tilera's iMesh) 3-way VLIW MIPS 866 MHz 443 bilhões de operações por segundo (BOPS) Geralmente, o mapeamento de tarefas é realizado em duas etapas.&amp;&amp;&amp;
A primeira de elas tem como principal função encontrar todas as possíveis posições onde uma dada tarefa pode ser inserida.
Esta operação invariavelmente se vale da informação sobre a ocupação atual do sistema.
Portanto, nota- se a necessidade de manter armazenada informação sobre quais recursos estão vazios e quais estão ocupados.
Tal informação deve ser constantemente atualizada, seja quando uma tarefa deixa o sistema, ou porque uma nova tarefa foi mapeada.
Em a segunda fase do processo de mapeamento, a função principal é encontrar de entre as possíveis posições obtidas na fase anterior, qual de elas é a melhor.
A tomada dessa decisão pode considerar diferentes critérios inclusive valendo- se do conceito de qualidade de serviço (QoS).
Além de a carga dos processadores, pode- se também considerar o meio de comunicação e a energia consumida.
Conforme apresentado no primeiro Capítulo, de acordo com o instante em o qual a decisão é tomada, o mapeamento pode ser classificado como estático ou dinâmico.
A presente Seção revisa os trabalhos relacionados ao mapeamento estático de tarefas, ou seja, aquele definido ainda em tempo de projeto, com base em estimativas do comportamento das aplicações que devem executar na plataforma alvo.
Mihal e Keutzer propõem a modelagem de aplicações concorrentes em MPSoCs heterogêneos.
Segundo os Autores, a solução desse problema relaciona- se principalmente à modelagem da concorrência da aplicação que implica na captura formal da comunicação em modelos computacionais.
A abordagem proposta parte de uma aplicação descrita em alto nível, a qual é particionada manualmente em tarefas.
O particionamento associa as tarefas da aplicação a PEs (Ligação).
Em etapas posteriores, realiza- se o mapeamento dos PEs na arquitetura alvo.
O trabalho não investiga heurísticas para mapeamento, mas evidência a importância de uma arquitetura que provê comunicação em camadas, e acaba por sugerir o uso de NoCs.
Wu e outros apresentam um algoritmo genético para solucionar o problema de mapeamento de tarefas.
Sua implementação é otimizada para explorar técnicas de variação dinâmica de voltagem, visando reduzir o consumo de energia do sistema.
O modelo de aplicação adotado baseia- se num grafo de tarefas denominado CTG.
Os Autores obtêm uma redução de até 51% no consumo de energia quando aplicam variação dinâmica de voltagem juntamente ao mapeamento.
Lei e Kumar também apresentam um algoritmo genético para mapeamento de aplicações.
Uma aplicação é descrita na forma de um grafo de tarefas, gerado com o auxilio da ferramenta TGFF.
A arquitetura é representada por uma NoC malha, a qual conecta um conjunto heterogêneo de PEs.
O objetivo do algoritmo proposto consiste em minimizar o tempo de execução da aplicação.
Para isso, modelos de atraso de comunicação são empregados na estimativa do tempo de execução.
Os resultados comparam apenas o desempenho do algoritmo proposto de acordo com diferentes parâmetros de entrada, de entre eles:
A aplicação, dimensões da NoC, tamanho da população e o número de gerações do algoritmo.
Rhee e outros investigam o mapeamento de tarefas com o objetivo de reduzir o número de saltos dos pacotes na NoC e a ocupação dos canais.
Uma aplicação é modelada como um grafo que representa a comunicação entre as tarefas através do volume de dados a serem transmitidos, e da largura de banda necessária.
A arquitetura é re-presentada por uma NoC malha com roteamento xy wormhole.
Os PEs são idênticos.
A principal contribuição do trabalho consiste numa abordagem de mapeamento onde os roteadores da NoC podem conter vários núcleos/ tarefas.
Segundo os Autores, ela permite até 81,2% de redução de energia consumida, em comparação à estratégia convencional, a qual permite o mapeamento de apenas um núcleo por roteador.
Hu e Marculescu investigam o mapeamento das tarefas em sistemas baseados em NoC.
A aplicação é modelada por um grafo denominado APCG.
Esta abordagem é baseada em modelos de comunicação com pesos, onde o peso do canal de comunicação corresponde à quantidade de bits transmitidos através de ele.
Os Autores demonstram a possibilidade de redução de 60% no consumo de energia, comparado a soluções ad hoc.
Em, estende- se a abordagem anterior, considerando como restrição a largura de banda máxima de cada canal da NoC para o escalonamento de tarefas.
Os Autores introduzem um modelo que captura a comunicação (Volume em bits) e a computação, baseado num grafo de comunicação de tarefas CTG, o qual contém o tempo de execução de cada tarefa, seu consumo de energia, e deadline.
Em os experimentos o gerador aleatório de grafos TGFF é empregado.
Comparados ao escalonamento Early Deadline First (EDF), o algoritmo proposto apresenta um consumo de energia 44% melhor.
Murali e De Micheli realizam o mapeamento de tarefas em NoCs de acordo com a largura de banda de comunicação.
A aplicação é representada por um grafo de núcleos.
A ferramenta NMAP proposta permite selecionar a topologia da NoC (malha ou torus), e a estratégia de roteamento (caminho mínimo único ou múltiplos caminhos com divisão de tráfego).
Em, a ferramenta SUNMAP proposta possui uma biblioteca maior de topologias, mas o tipo de roteamento é fixado para caminho mínimo.
A função custo considera a média de atraso de comunicação, e os consumos de área e energia.
Em, adiciona- se à ferramenta a capacidade de realizar posicionamento físico.
Através do método Tabu Search (Ts), o mapeamento visa otimizar o uso da largura de banda.
Comparado a solução ad hoc, foram obtidas soluções 5 vezes melhores para largura de banda.
Em, o mapeamento é realizado para um conjunto de aplicações alvo.
A solução escolhida é aquela que melhor apresenta- se para todo conjunto.
Conforme, essa abordagem resulta em NoCs muito grandes, além de funcionar apenas para aplicações com padrões de tráfego similares.
Em, mantém- se uma estrutura para cada aplicação alvo, e avalia- se independentemente o mapeamento.
Manolache e outros investigam o mapeamento de tarefas numa NoC com garantia de latência.
A arquitetura é modelada através de uma matriz 2D de PEs homogêneos.
Uma tarefa é representada por sua periodicidade, seu tempo de execução e deadline.
Uma dada aplicação é descrita por um conjunto de tarefas, através de um grafo.
Os experimentos são baseados numa NoC com dimensões 4x4.
A melhor solução é encontrada através da técnica Tabu Search.
A garantia de latência é atingida porque tanto a posição das tarefas quando o roteamento dos pacotes são definidos em tempo de projeto.
Além disso, varias cópias de cada mensagem são enviadas.
Trata- se de uma solução limitada.
A duplicação de mensagens permite tolerância a falhas, no caso de perda de mensagens.
Entretanto, essa estratégia pode sobrecarregar a rede, já que duplica o tráfego.
Lin e outros tratam o mapeamento de tarefas num MPSoC homogêneo, baseado numa NoC malha.
A aplicação é representada por um grafo de tarefas, com informação sobre o volume de comunicação.
O algoritmo proposto é composto de 4 fases:
Um mapeamento é realizado de forma que as tarefas fiquem o mais perto possível;
Conexões são estabelecidas (Chaveamento de circuito);
através de simulação obtémse um perfil da operação do sistema;
E calcula- se a contenção da rede e o sistema é realimentado.
Tal procedimento é repetido até que o resultado apresente o desempenho desejado.
O mapeamento utiliza o algoritmo Simulated Annealing (SA).
Sua função custo considera a distância entre as tarefas, a ocupação dos canais e o volume de comunicação.
Os experimentos são baseados em grafos de aplicações gerados no TGFF.
Os resultados apresentam 20% de redução no tempo total de execução da aplicação, comparada a alternativa que não considera a comunicação e os efeitos de contenção.
Srinivasan e Chatha, além de a largura de banda, consideram também a latência resultante como restrição no mapeamento.
Uma dada aplicação é modelada por um grafo composto por vértices que representam núcleos ou memórias;
E por arestas que indicam a largura de banda e latência necessárias para cada comunicação.
A NoC possui topologia malha, e cada roteador possui atributos tais como:
Larguras máximas de banda suportadas, energia consumida em cada porta.
A solução implementada baseia- se no algoritmo Árvore de Corte (do inglês, Cutting Tree), que recursivamente divide o grafo da aplicação horizontalmente e verticalmente, até que a partição gere um vértice para cada roteador da NoC.
Alguns dos grafos usados nos experimentos baseiam- se em aplicações reais (MPEG, MP3, H. 263, VOPD, MWD).
Os resultados obtidos demonstram que o algoritmo proposto possui complexidade inferior ao proposto em.
Entretanto, os resultados são equivalentes quando a latência não é tomada como restrição.
Marcon e outros investigam o mapeamento de tarefas numa NoC malha.
A proposta baseia- se no modelo CDM que representa a dependência entre os pacotes.
Esse trabalho manipula três grafos.
O grafo CWG é composto por um conjunto de tarefas e as respectivas comunicações (volume de dados).
O grafo CDG contém informação sobre todos os pacotes transmitidos e sua ordenação.
O grafo CRG mantém informação sobre a topologia da NoC.
Comparado à, o algoritmo proposto apresenta re-dução de 21% na energia consumida, e de 42% no tempo de execução da aplicação.
Em, a modelagem evolui com a proposta do modelo CDCM, que captura o tempo de computação de cada tarefa, além de o volume de comunicação.
O grafo CDCG é composto por um conjunto de pacotes transmitidos.
A descrição de cada um de eles contém informação sobre seu instante de envio.
Comparado à, o algoritmo proposto apresentou redução de 20% na energia consumida e de 40% no tempo de execução da aplicação.
Em, apresenta- se uma avaliação mais completa de heurísticas para mapeamento.
Em os trabalhos anteriores, os Autores empregaram a técnica SA e o método exaustivo.
Agora, o método Tabu Search e dois métodos gulosos são também avaliados.
O algoritmo Greedy Incremental (GI) apresentou bons resultados, enquanto o algoritmo Largest Communication First (LCF) combinado com estratégias estocásticas apresentou o melhor compromisso entre tempo de execução e economia de energia.
Orsila e outros modelam uma dada aplicação através de um grafo, com informação sobre a dependência entre as tarefas, seu tempo de computação e o volume de comunicação.
Sua arquitetura reflete um sistema homogêneo.
Os Autores propõem um algoritmo híbrido em contraproposta ao método SA puro.
Eles combinam SA para otimizações globais e Migração de Grupo para otimizações locais.
Seu sistema é simulado num cluster.
A proposta resulta num ganho de 8,3% no tempo de execução.
Em, os Autores propõem um método automático de seleção de parâmetros para o algoritmo SA, visando diminuir o esforço de otimização.
Em, apresenta- se uma junção dos dois trabalhos anteriores, adicionando a avaliação da memória consumida por os algoritmos.
Os resultados são comparados com algoritmos SA, Migração de Grupo e mapeamento aleatório.
SA apresenta- se como melhor alternativa.
Ruggiero e outros empregam um MPSoC homogêneo composto por processadores ARM7, interconectados via barramento AMBA.
Cada processador tem uma memória local e pode acessar memórias remotas.
O sistema operacional de tempo real utilizado é o RTEMS.
As aplicações são modeladas como um grafo de tarefas, executadas na forma de um pipeline.
O mapeamento de tarefas é dividido num processo de duas etapas, incluindo mapeamento e escalonamento.
O mapeamento emprega o modelo de programação linear (ILP), enquanto o escalonamento emprega o modelo de programação por restrições (CLP).
O objetivo do mapeamento é reduzir o tráfego no barramento.
Sua abordagem demonstra maior eficiência computacional comparada às abordagens puramente ILP ou puramente CLP.
Saeidi, Mehan e outros propõem a ferramenta SMAP, baseada no ambiente Matlab, para o mapeamento de tarefas numa NoC malha.
As funções custo adotadas consideram a distância em hops entre tarefas comunicantes, e a ocupação dos canais da NoC.
As aplicações são modeladas através de um grafo de tarefas, o qual informa a dependência entre as tarefas e a largura de banda necessária para as comunicações.
O algoritmo de mapeamento Spiral proposto mapeia as tarefas na forma de um espiral.
Em os experimentos são utilizadas tarefas sintéticas geradas aleatoriamente.
As NoCs usadas possuem algoritmo de roteamento xy, e dimensões que variam entre 3x3 e 6x6.
Comparado a um algoritmo genético e outro aleatório, o Spiral apresenta respectivamente 8 e 10% de ganho na energia consumida na comunicação.
Uma parte dos trabalhos revisados aborda sistemas homogêneos onde todas as tarefas são da mesma natureza.
Alguns Autores apresentam soluções para mapeamento genérico de núcleos (ou tarefa de hardware) no sistema, enquanto outros mapeiam tarefas de software em MPSoCs.
Existem também pesquisas que visam o mapeamento em sistemas heterogêneos.
De entre as características empregadas nas funções custo, pode- se listar:
Fragmentação, largura de banda de comunicação, energia consumida na comunicação, proximidade entre as tarefas comunicantes.
Isso denota a diversidade de trabalhos na área.
Em a Tabela 2.2 (na próxima página) apresenta- se um quadro comparativo com um resumo das principais características dos trabalhos que investigam o mapeamento estático de tarefas.
As propostas revisadas apresentam estratégias estáticas de mapeamento de tarefas.
Tal abordagem é aceitável somente para arquiteturas cuja proposta seja executar um conjunto limitado e predefinido de tarefas que compõem aplicações especificas.
Em sistemas dinâmicos, o comportamento ou não pode ser predito, ou a predição será bastante imprecisa.
Em esse caso, para aplicações com comportamento dinâmico, a validade das estratégias estáticas é comprometida, pois estas invariavelmente necessitam de relativo conhecimento sobre o comportamento da aplicação.
Kim e outros consideram um ambiente heterogêneo, em o qual tarefas chegam aleatoriamente, e possuem diferentes prioridades e deadlines.
Em são comparadas oito heurísticas para mapeamento, incluindo duas heurísticas gulosas;
Uma baseada em look-up table, de entre outras.
Após a validação sobre diferentes cenários, os Autores concluem que com relação a os dealines, heurísticas gulosas apresentam melhor desempenho.
Contudo, se o tempo de mapeamento é importante, então técnicas look-up table são recomendadas.
Em, os Autores admitem os mesmos modelos de tarefa e ambiente, agora considerando o consumo de energia como alvo.
Sete heurísticas são avaliadas, algumas de elas diferentes das tratadas anteriormente.
A heurística gulosa ainda apresentou o melhor resultado, mas num tempo maior.
Os Autores não definem adequadamente a arquitetura alvo, e não consideram o tempo de mapeamento.
Autores Mihal e Keutzer Wu Lei e Kumar Rhee et al;
Hu e Marculescu Modelo de arquitetura Infra-estrutura de comunicação Algoritmo Modelo de aplicação Métrica Observações Heterogênea Barramento Modelo alto-nível para uma ferramenta tipo Ptolemy Trabalho centrado na modelagem da concorrência de aplicações.
Heterogênea Barramento Genético Tempo de execução e energia dissipada Energia consumida Trata escalonamento e mapeamento de tarefas aliados a estratégias de variação dinâmica de voltagem.
Heterogênea NoC malha Genético Volume de comunicação Tempo total de execução Apresenta uma ferramenta para mapeamento e uma modelagem dos atrasos do sistema.
Volume de dados e largura de banda necessária Número de saltos dos pacotes e ocupação dos canais Mapeamento de núcleos na NoC.
Roteadores podem conter vários núcleos.
Divisão e conquista Volume de comunicação, comunicação e computação Comunicações (Energia) Mapeamento dos núcleos de uma aplicação em NoCs.
Homogênea NoC malha Tabu Search Periodicidade, tempo de execução e deadline Energia e garantia de latência Mapeamento integrado de Tarefas e comunicações, aliado a duplicação de mensagens.
Homogênea NoC malha SA e Divisão e Conquista Volume de comunicação Homogênea NoC malha ou torus Tabu Search Largura de banda de comunicação necessária Largura de banda, atraso de comunicação, área e energia Ferramenta permite selecionar a topologia, selecionar tipos de roteamento, mapear os núcleos e realizar floor planning.
Homogênea NoC malha Força bruta, SA tabu search e métodos gulosos Dependências e volume de comunicação;
Computações e temporização das mensagens.
Comunicações (Energia) e Tempo de execução Mapeamento de núcleos numa NoC.
Homogênea Barramento ou NoC SA para otimizações globais e migração de grupo para locais Dependências, computação;
E volume de comunicação Tempo de execução Sistema descrito em phyton e simulado num cluster Homogênea NoC malha Cutting tree Largura de banda e latência necessárias Largura de banda e latência resultante Mapeamento de núcleos na NoC.
Mapeamento integrado de tarefas e de comunicações Barramento Programação linear inteira Grafo de tarefas no estilo pipeline Tráfego no barramento Processadores executam o SO RTEMS.
Problemas de mapeamento e escalonamento são tratados juntos.
NoC malha Spiral Grafo de tarefas (largura de banda) Proximidade e ocupação dos canais Proposta da ferramenta SMAP baseada no Matlab Homogênea Homogênea Manolache Lin Murali e De Micheli Marcon NoC malha (roteamento xy) NoC malha Orsila Srinivasan e Chatha Ruggiero Homogênea (processadores Saeidi Mehran Homogênea Comunicações (Latência e tempo de execução) O algoritmo proposto é baseado num perfil de operação.
Smit e outros apresentam um método iterativo hierárquico para o mapeamento de aplicações em SoCs heterogêneos, baseados em NoC.
Uma aplicação é representada por um conjunto de tarefas e suas respectivas comunicações.
Em o método proposto, primeiramente cada tarefa é atribuída a um tipo de recurso do sistema (FPGA, DSP, ARM), de acordo com suas restrições de desempenho.
Em seguida, cada tarefa é atribuída a um recurso específico.
Todas as tarefas são rearranjadas visando diminuir a distância entre tarefas comunicantes.
A o final, o mapeamento resultante é verificado, e caso não atenda as necessidades da aplicação, uma nova iteração é necessária.
Os experimentos ba- seiam- se no mapeamento de uma aplicação com 13 tarefas sobre um SoC 4x4.
Além de o proposto, outros dois métodos de mapeamento são avaliados de acordo com a ocupação da NoC, e tempo de execução da aplicação.
O primeiro de eles é o método exaustivo, executado por 10 horas até encontrar a melhor solução.
O segundo é o algoritmo minWeight apresentado em.
O método iterativo encontrou sua melhor solução (idêntica à do exaustivo) em apenas três iterações, ao passo que minWeight apresentou uma solução 5% pior comparada ao método exaustivo.
Segundo os Autores, minWeight possui baixas escalabilidade e flexibilidade para a inclusão de restrições.
Ngouanga e outros pesquisam o mapeamento de tarefas num MPSoC homogêneo, composto por PEs conectadas via NoC.
Três tipos de PEs são definidos:
Mestre, escravos e interface de E/ S. O PE mestre é responsável por o mapeamento de tarefas.
Cada PE é monotarefa e possui um µkernel, modelado através de redes de Petri.
Nenhuma informação sobre o mapeamento existe a priori, o mapeamento é realizado de acordo com padrões de localidade tal como compartilhamento de canais de comunicação.
Os Autores investigam dois algoritmos para mapeamento dinâmico:
SA e Força Direcionada.
O último seleciona a posição para a nova tarefa de acordo com uma força de atração proporcional ao volume de comunicação e a distância entre tarefas.
Os Autores não demonstram preocupação com o atraso da heurística de mapeamento empregada sob a justificativa de que o tempo de processamento da tarefa deve tornar- lo insignificante.
O algoritmo Força Direcionada executou num tempo uma ordem de grandeza menor que SA, embora o caminho médio entre duas tarefas seja equivalente em ambos os algoritmos.
Em os resultados, é possível identificar que quanto maior o sistema (número de PEs), melhor tende a ser os resultados das heurísticas comparados a um mapeamento aleatório.
Wronski e outros avaliam dois algoritmos bin packing para mapeamento de tarefas num MPSoC baseado em NoC.
São eles:
Best Fit (BF) e Worst Fit (WF).
Uma ferramenta descrita em SystemC simula o comportamento dinâmico do MPSoC e estima a energia consumida por o sistema, de acordo com o mapeamento da aplicação.
Os roteadores da NoC são descritos no nível RTL.
A estimativa de consumo de energia de cada tarefa é baseada num parâmetro aleatório, que representa o número de chaveamentos por ciclo de relógio.
Cada tarefa é então representada por o seu pior tempo de execução e por seu número de chaveamentos.
A energia consumida por a NoC relativa à comunicação é obtida através da biblioteca Orion.
Em os experimentos realizados, foram analisados casos onde: (
a) todas as aplicações executam num único processador, (b) cada processador executa uma aplicação e, (c) cada processador executa uma única tarefa.
As aplicações foram geradas a partir de um gerador de grafos TGFF.
Os Autores concluem que estratégias de mapeamento podem resultar em tempos de execução muito semelhantes e ainda apresentarem consumos de energia muito diferentes.
Em, as heu-rísticas são combinadas com a estratégia de Clusterização Linear (Cl) proposta, que une as tarefas com alto nível de comunicação no mesmo PE.
A combinação WF+ CL apresenta redução significativa, entre 80 e 100%, nas violações do deadline das tarefas.
Entretanto, a avaliação de energia consumida aponta para BF como melhor solução.
Hölzenspies e outros investigam métodos para estimar o desempenho do mapeamento de aplicações de fluxo de dados, em MPSoCs baseados em NoC.
Uma aplicação é modelada por um grafo de tarefas, onde os vértices são as tarefas e as arestas representam FIFOs.
A comunicação, por sua vez, é representada por o envio de tokens através das arestas do grafo.
Em o trabalho proposto, os recursos do MPSoC são gerenciados por um sistema operacional que executa num dos processadores do MPSoC.
Seu alvo consiste em minimizar o consumo de energia.
Para isso, o SO usa informações coletadas em tempo de projeto sobre a aplicação (Latência necessária e throughput), e sobre a arquitetura (Número de processadores).
Em tempo de execução, o SO determina quando o mapeamento deve ser realizado, e se o mesmo deve ser validado.
Esse trabalho concentra- se nos métodos de estimativa, tendo por base um exemplo simples de aplicação, composta apenas por 3 tarefas que se comunicam na forma de um pipeline.
Em, os Autores apresentam em maiores detalhes o processo de mapeamento (Iterativo hierárquico).
Os mesmo modelos e aplicações são adotados.
O algoritmo executado sobre um processador ARM levou 4ms para apresentar uma solução de mapeamento adequada.
Os Autores não fornecem comparações com outros métodos.
Chou e Marculescu apresentam uma estratégia incremental para mapeamento de tarefas em MPSoCs homogêneos.
Os processadores do sistema são interconectados por uma NoC malha com roteamento xy.
Ela possui caminhos de dados e controle distintos.
Os processadores podem executar em dois níveis de voltagem distintos.
As aplicações são representadas por grafos de tarefas, com informação do volume de dados transmitidos e largura de banda necessária para cada comunicação.
O processador gerente é responsável por encontrar uma área contigua no MPSoC onde caiba a aplicação a ser mapeada, e por definir a posição das tarefas dentro de esta área.
Essa estratégia evita a fragmentação do sistema.
Os experimentos empregam um MPSoC 7x7, e aplicações sintéticas geradas no TGFF, compostas por 5 a 10 tarefas cada.
Comparado à solução exaustiva, o método proposto apresentou penalidade de 21% no consumo de energia.
Entretanto, seu tempo de execução é em torno de 40 µs, ao passo que o método exaustivo necessita de 26 horas para um MPSoC com 13 PEs.
Comparado a um mapeamento aleatório, o método proposto apresenta 45% de redução no consumo de energia.
Em, os Autores estendem o trabalho para considerar também um modelo de comportamento do usuário no mapeamento das tarefas.
O comportamento do usuário alimenta um perfil de operação da aplicação, que contém dados sobre sua periodicidade e volume de dados comunicados en-tre suas tarefas.
Duas estratégias de mapeamento são investigadas.
A primeira de elas consiste no método adotado no trabalho anterior.
A outra estratégia define um formato de região para uma dada aplicação, e realiza transformações geométricas de rotações se necessário, para em seguida mapear a aplicação no MPSoC.
A proposta apresenta penalidade de 10 e 60% na energia consumida, comparado aos métodos exaustivo e aleatório, respectivamente.
Tempos de mapeamento medidos para grafos de aplicações reais (telecomunicação, redes, automação e automotivas) são na rodem de 47 µs.
Mehran e outros investigam o desempenho do mapeamento de tarefas numa NoC malha, com dimensões 4x4.
Esse trabalho apresenta uma evolução do proposto em.
De acordo com os Autores, as tarefas de uma dada aplicação com comportamento dinâmico podem ser necessárias em diferentes instantes.
Assim, quando uma nova tarefa é necessária, ou uma tarefa termina sua execução, um novo mapeamento da aplicação pode ser necessário.
Para isso, os Autores propõem duas alternativas que consistem no mapeamento total ou parcial da aplicação.
Ambas empregam o algoritmo Spiral, primeiramente proposto em.
Os experimentos realizados empregam 10 aplicações sintéticas, com número de tarefas entre 9 e 25, num total de 100 cenários.
Os resultados obtidos demonstram que o mapeamento parcial apresenta o melhor resultado em 82% dos experimentos, com redução entre 5 e 28% no tempo para mapear a aplicação.
Faruque e outros apresentam uma solução para mapear tarefas em MPSoCs heterogêneos baseados em NoC malha.
Sua principal contribuição diz respeito a um método de mapeamento distribuído baseado em agentes, em contraproposta ao método que emprega um único processador como gerente centralizado.
O MPSoC é dividido em clusters virtuais.
Cada um de eles possui um agente local responsável por mapear tarefas em seu interior.
Agentes globais decidem em qual cluster as tarefas serão mapeadas.
Assim, o processo de mapeamento reside na negociação entre agentes locais e globais.
Além disso, o monitoramento dos recursos é distribuído entre os agentes locais.
A modelagem das aplicações se dá através de um grafo de tarefas, o qual informa as dependências e as comunicações (largura de banda necessária) entre tarefas.
Cada aplicação é mapeada por completo por o agente local, segundo o algoritmo estático apresentado em.
Os experimentos realizados comparam a estratégia proposta a alguns dos algoritmos aqui propostos (NN, MACL e PL discutidos no Capítulo 4), previamente publicados em.
A partir de MPSoCs com dimensões 12x12, o método distribuído apresenta melhores resultados, em contraproposta ao centralizado.
Para um MPSoC 32x64 o esforço de mapeamento é 7 vezes menor, e o volume de dados monitorados transmitidos através da NoC é 10 vezes menor.
Esses resultados são facilmente justificados, pois a proposta permite paralelismo no mapeamento de aplicações caso sejam requisitadas simultaneamente.
Entretanto dentro de uma mesma aplicação as tarefas ainda são mapeadas uma por vez.
A Tabela 2.3 apresenta um quadro comparativo com as principais características de cada um dos trabalhos revisados sobre mapeamento dinâmico.
A última linha da Tabela adianta algumas características do trabalho aqui proposto.
Como pode ser notado, surgiram muitos trabalhos nos últimos dois anos sobre mapeamento dinâmico.
Alguns trabalhos revisados revisitam estratégias estáticas de mapeamento, sem qualquer preocupação com o tempo de mapeamento, assumido como insignificante.
A maioria dos trabalhos trata o mapeamento da aplicação por completo.
No que diz respeito à arquitetura admitida por os Autores, existem tanto trabalhos sobre MPSoCs homogêneos, quanto heterogêneos, em proporção similar.
O uso de NoCs acontece em todos os trabalhos revisados.
O gerenciamento de recurso, na maioria dos trabalhos revisados, é baseado numa estratégia centralizada.
Como exceção, sugere o gerenciamento é distribuído.
Tal proposta é importante à medida que cresce as dimensões dos MPSoCs (32x32), conforme comprovado por o próprio Autor.
Autores Kim Smit Ngouanga Wronski Brião Modelo de arquitetura Infra-estrutura de comunicação Algoritmo Modelo de Aplicação Métrica Observações Heterogênea Guloso, look-up table, etc Conjunto de tarefas com prioridades e deadlines Deadlines e energia consumida Arquitetura não definida.
Várias heurísticas são avaliadas.
Heterogênea NoC Iterativo Hierarquico Grafo de tarefas com volume de comunicação Ocupação da NoC e Tempo de Execução Comparações com métodos exaustivo e aleatório.
Homogênea NoC (similar à Hermes) SA e força direcionada Grafo de tarefas com volume de comunicação Tempo de Comunicação Atraso de mapeamento é considerado insignificante.
Replicação de tarefas.
Homogênea NoC (Xpipes) Cl+ BF e Cl+ WF Pior tempo de execução e número de chaveamentos Energia consumida e deadlines Simulador em SystemC com roteador em nível RTL.
Homogênea NoC Iterativo Hierárquico Grafo de tarefas com volume de comunicação Energia consumida Estimativa de desempenho do mapeamento.
Estudos de casos com poucas tarefas.
Homogênea (s voltagens) NoC Seleção de área+ Mapeamento Grafo de tarefas com volume de comunicação e largura de banda necessária Energia consumida e Fragmentação do sistema Mapeamento em dois estágios:
Seleciona uma área contigua e mapeia as tarefas nessa área.
Homogênea NoC Spiral Tempo de mapeamento Mapeamento total ou parcial da aplicação quando uma nova tarefa da aplicação chega.
Heterogênea NoC Agentes distribuídos Grafo de tarefas com volume de comunicação e largura de banda necessária Tempo de mapeamento Gerenciamento distribuído do sistema.
Mapeamentos em paralelo.
Comparações com NN, MACL e PL.
Heterogênea NoC (Hermes) Grafo de tarefas com volume de comunicação e largura de banda necessária Ocupação da NoC Tarefas e Controlador em SystemC e NoC em VHDL.
Hölzenspies Chou e Marculescu Mehran Faruque Proposta Migração consiste na transferência de tarefas em tempo de execução entre diferentes máquinas.
Anteriormente, o interesse em migração de tarefas se deu no domínio da computação paralela.
O estudo de MPSoCs traz a migração novamente à pauta.
Ela pode ser empregada para obter distribuição de carga dinâmica e assegurar tolerância a falhas.
Além disso, quando um gargalo de desempenho é encontrado, a migração pode maximizar a economia de energia, gerenciar a temperatura do Ci, de entre outros.
Uma migração exige a interrupção da execução da tarefa no PE fonte, e o salvamento de contexto para que o mesmo seja retomado quando a tarefa reiniciar no PE destino.
O processo que garante que uma dada tarefa possa continuar sua execução no destino denomina- se relocação.
Em o caso onde os PEs fonte e destino são arquiteturas diferentes, o relocador seleciona o código objeto da tarefa compilado/ sintetizado para o PE destino, e ainda se encarregar de carregar o contexto salvo neste PE.
Outra estratégia empregada em tempo de execução é a replicação de tarefas, que visa evitar gargalos na computação/ comunicação.
Diferentemente da migração, na replicação, a tarefa continua executando no PE fonte.
Kalte e Porrmann propõem dois métodos para salvamento de contexto para sistemas reconfiguráveis, denominados shutdown process e readback.
O trabalho de Kalte é fundamentado no processo de relocação de tarefas.
Em e, apresenta- se dois módulos para relocação de módulos de hardware em FPGAs comerciais.
Nollet e outros apresentam um método para migrar tarefas entre os domínios hardware e software.
A decisão do instante da migração é tomada em função de o desempenho da aplicação.
O método proposto emprega pontos de migração para definir quando uma dada tarefa pode ser migrada.
A plataforma GECKO, composta por um PDA e um FPGA, foi desenvolvida para validar a estratégia proposta.
Bertozzi e outros empregam checkpoints para definir quando uma dada tarefa deve ser migrada.
Um middleware implementado no µClinux permite migrações em pontos específicos, representados por checkpoints, inseridos manualmente no código da tarefa por o programador do sistema.
Para avaliar o desempenho do sistema e os custos da migração, diversos testes foram feitos, e sua viabilidade foi comprovada.
Streichert e outros propõem um algoritmo que visa otimizar o mapeamento tarefas.
Quando um nodo da rede falha, as tarefas que estavam neste nodo são remapeadas, réplicas se tornam tarefas principais, e novas rotas para comunicação são estabelecidas.
Esse passo é denominado reparação rápida.
Em seguida, no passo de otimização, um novo mapeamento é encontrado a fim de minimizar o tráfego de dados na rede.
Götz e outros também investigam migração entre domínios de software e hardware.
Segundo os Autores, a principal dificuldade é a diferença entre paradigmas seqüencial versus espacial.
A computação de uma tarefa é representada como um grafo de transição de estados, onde estado representam blocos de computação.
Cada transição de estado representa um possível ponto de migração.
Este define um ponto de encontro entre o código compilado para o processador e sua versão sintetizada para FPGA.
Sassatelli e outros exploram a adaptabilidade em MPSoCs.
Esse trabalho é centrado no processo de replicação de tarefas, realizado quando um gargalo de desempenho é encontrado.
A adaptação do sistema é baseada em monitores que coletam informações dos processadores, em tempo de execução.
Segundo os Autores, o ganho de desempenho da aplicação é superior ao atraso causado na replicação.
Em, a API desenvolvida no trabalho anterior foi compatibilizada com o padrão MPI.
Os experimentos baseiam- se num sistema composto por 16 FPGAs, conectados segundo uma topologia malha.
Farag e outros apresentam o processo de migração como uma estratégia para desfragmentar o dispositivo, otimizando a utilização da área.
O sistema é modelado na forma de uma matriz 2 D, sem considerar a infra-estrutura de comunicação.
Quando uma dada tarefa não pode ser mapeada porque existe área livre suficiente, mas ela está fragmentada, a migração das tarefas é realizada, a fim de tornar a área livre contigua.
Barcelos e outros investigam o impacto da organização de memória no atraso da migração de tarefas.
Segundo os Autores, a estratégia distribuída requer muita memória, ao passo que a compartilhada apresenta um excessivo atraso na migração.
Um modelo híbrido de organização de memória é proposto.
Comparado às estratégias compartilhada e distribuída, ele reduz em 24% e 10% o consumo de energia, respectivamente.
Brião e outros investigam o impacto da migração em aplicações soft realtime.
Em o trabalho, o atraso decorrente da migração corresponde ao tempo de transmissão do código e dos dados.
O tempo para leitura da memória é desprezado.
Após avaliar aplicações sintéticas e também um benchmark de telecomunicação, os Autores concluem que a migração pode ser aplicada para garantir o deadline de aplicações soft real-time.
Os trabalhos de migração investigados em geral indicam pontos específicos para migrar tarefas.
Além disso, o processo de salvamento de contexto também desperta interesse.
Aplicações embarcadas possuem restrições de tempo real, e a migração transparente de tarefas pode causar violações na temporização do sistema em virtude de o atraso inserido.
Em adição, tarefas podem migrar com muita freqüência entre PEs do MPSoC, reduzindo a capacidade de predizer o tempo de execução do sistema.
Por tudo isso, técnicas menos transparentes e mais controláveis de migração podem ser necessárias neste contexto, tal como migração controlada por o usuário ou por a aplicação.
Em a revisão realizada, os Autores na sua maioria optam por mecanismos menos transparentes.
Os esforços para avaliar a validade do emprego da estratégia de migração encontram- se em estágio inicial.
Alguns trabalhos estendem o conceito de migração para duplicação de tarefas, que pode visar tolerância a falhas, ou garantir o desempenho das aplicações.
Alguns trabalhos investigam métodos para reduzir a energia consumida durante uma migração, enquanto outros visam comprovar a viabilidade do emprego de migração em aplicações de tempo real.
A Tabela 2.4 apresenta um quadro comparativo com um resumo das características dos trabalhos sobre migração de tarefas, aqui revisados.
Modelo de arquitetura Salvamento de contexto Instante de migração Métrica Observações HW controlador Barramento Área reconfigurável (Homogênea) Shutdown process ou readback Fragmentação do dispositivo Trabalho baseado na relocação de tarefas usando o módulo Replica.
Barramento (Homogênea) Pontos de Migração Largura de banda ocupada e Tempo de execução Migração entre HW e SW de acordo com requisitos de desempenho.
Processadores ARMv7 conectados via barramento (Homogênea) Controlada por o usuário e através de mensagens.
Checkpoints inseridos manualmente no código Balanceamento de carga Suporte implementado na forma de um middleware para uClinux que permite migrações Rede de sensores, atuadores e controladores (processador+ FPGA) Defeitos Tráfego de dados Migra tarefas de nodos defeituosos em dois passos:
Processador PPC Barramento HW auxiliar (FPGA) Serviços do SO:
Ponto de migração Migração entre HW e SW.
Processadores Plasma NoC (Homogênea) Replicação realizada num gargalo de desempenho Tempo de execução Trabalho centrado no processo de replicação de tarefas.
Matriz 2D (Homogênea) Se nova tarefa necessita ser mapeada mas o dispositivo está fragmentado Fragmentação do dispositivo Migração empregada para desfragmentar o sistema.
Barcelos Brião MPSoC baseado em NoC (Homogênea) Energia consumida na migração do código Investiga impacto da organização de memória, e da migração em sistemas de tempo real.
O desenvolvimento de um MPSoC apresenta muitos graus de liberdade ao projetista.
De entre eles encontram- se:
O número e a natureza dos elementos de processamento;
A infra-estrutura de comunicação;
A organização de memória;
E os mecanismos de controle da operação do sistema.
Com relação a a natureza dos PEs, MPSoCs homogêneos são mais adequados para o uso de técnicas de migração e replicação de tarefas, ao passo que os heterogêneos tendem a suportar uma maior variedade de aplicações.
Além disso, o uso de IPs específicos pode prover maior desempenho a MPSoCs heterogêneos.
Enquanto a natureza dos PEs é função do domínio de aplicação alvo, o número de PEs a serem empregados no sistema deve considerar também a quantidade de lógica disponibilizada por a tecnologia atual.
No que diz respeito à infra-estrutura de comunicação, NoCs dominam devido a sua maior escalabilidade comparado a barramentos e conexões ponto-a-ponto dedicadas.
Barramentos em geral suportam a comunicação em sistemas com até poucas dezenas de módulos, enquanto as NoCs podem suportar centenas.
Além disso, o paralelismo na comunicação é outro fator atrativo de NoCs.
Um barramento suporta apenas uma comunicação por vez.
O emprego de uma hierarquia de barramentos permite paralelismo na comunicação quando elas ocorrem em graus diferentes da hierarquia.
Entretanto, as comunicações entre os módulos de graus diferentes ainda limitam o paralelismo na comunicação.
Com relação a a organização de memória empregada, segundo, uma organização hibrida de memórias distribuídas e centralizadas representa a melhor alternativa para reduzir o tempo de migração de tarefas.
Em geral, estratégias centralizadas de memória conduzem a gargalos de comunicação, enquanto as distribuídas sugerem maior complexidade de gerenciamento.
Os mecanismos usados para controle da operação do sistema são também importantes.
Esses podem ser baseados no reuso de um SO conhecido (Linux);
Em a personalização do SO para o sistema alvo;
Ou até mesmo no desenvolvimento de um SO novo.
Este pode valer- se até mesmo de complementos implementados em hardware para aumento do desempenho.
Os métodos adotados para controle do consumo de energia também ganham importância, sobretudo no domínio de aplicações sem fio.
De entre eles, pode- se citar o emprego de estratégias para variação dinâmica de voltagem e clock gating.
Modelos de programação e concorrência do sistema são relevantes.
A programação em sistemas paralelos, tal como clusters, há muito exige grande esforço do meio acadêmico na busca de melhores modelos de programação.
Agora, parte desses trabalhos necessita ser adequada ao novo cenário imposto por os MPSoCs.
Em a Seção 3.1, apresenta- se a organização proposta para o MPSoC alvo da pesquisa em mapeamento de tarefas.
A Seção 3.2, por sua vez, apresenta o modelo de aplicação adotado.
Em a Seção 3.3, apresenta- se a infra-estrutura de comunicação adotada.
O protocolo definido para comunicação entre as tarefas e o controle do sistema é discutido na Seção Seção 3.7 apresenta- se as três estratégias de modelagem de sistema investigadas.
Motivado por a afirmação acima, a organização de MPSoC adotada neste trabalho é um MPSoC heterogêneo, composto por um conjunto de elementos de processamento (PEs) conectados através de uma NoC.
A heterogeneidade do MPSoC consiste na natureza mista dos PEs, os quais suportam a execução de tarefas de software (via instruction set processors ­ ISPs) e tarefas de hardware (via IPs dedicados ou lógica reconfigurável embarcada ­ RL).
O uso de lógica reconfigurável permite a carga de tarefas de hardware no sistema em tempo de execução, usando a estratégia de reconfiguração dinâmica.
A Figura 3.1 ilustra a organização genérica do MPSoC proposto.
Quando o MPSoC inicia sua execução, somente tarefas inicialmente necessárias são alocadas no sistema.
Novas tarefas são alocadas quando uma dada tarefa necessita se comunicar com tarefas ainda não alocadas.
De essa forma, ao longo de o tempo, o número de tarefas alocadas no MP-SoC varia, e os recursos disponíveis podem ser insuficientes para suportar a execução de todas as tarefas necessárias.
Com a finalidade de controlar a operação do sistema, um dos processadores do MPSoC é reservado, denominado processador gerente (MP ­ Manager Processor).
De entre as tarefas de controle atribuídas ao MP, encontram- se:
Controle de recursos:
Responsável por manter informação atualizada sobre o estado de ocupação dos recursos do sistema, incluindo principalmente os elementos de processamento, e os canais da NoC.
Como será apresentado adiante, no presente trabalho o controle de recursos é baseado num esquema de monitoramento distribuído, que captura a ocupação dos recursos e envia tal informação ao processador gerente.
Esse, por sua vez, armazena tal informação num conjunto de matrizes de ocupação de recursos.
Escalonamento de tarefas:
Responsável por determinar a ordem (temporal) em a qual as aplicações e suas respectivas tarefas serão executadas.
O escalonamento de tarefas não faz parte do escopo desse trabalho.
Ele é baseado numa estratégia de filas, sem considerar políticas de preempção.
São implementadas três filas, uma para cada tipo de tarefa possível (Hardware, software e inicial).
Uma dada tarefa é inserida numa dada fila se não existem recursos do seu tipo disponíveis, e ela deve aguardar nesta fila até que esta condição mude.
Ligação de tarefas:
Precede o mapeamento de tarefas em sistemas heterogêneos.
Ela é responsável por assegurar a correta alocação de tarefas aos recursos do sistema, como por exemplo, atribuição de tarefas de software a processadores, e atribuição de tarefas de hardware à lógica configurável embarcada.
No caso de MPSoCs homogêneos, essa operação inexiste.
Mapeamento de tarefas:
Consiste na definição do posicionamento (espacial) de cada uma das tarefas no sistema.
A estratégia proposta neste trabalho é descrita em detalhes no próximo Capítulo.
Ela vale- se de informação sobre a ocupação dos canais da NoC para definir um mapeamento que reduz os congestionamentos.
Migração de tarefas:
Responsável por a modificação do posicionamento das tarefas alocadas no sistema, de acordo com diferentes objetivos, tais como balanceamento de carga e redução da potência dissipada.
Tal como o escalonamento, a migração de tarefas também não faz parte do escopo do trabalho proposto.
Configuração de tarefas:
Operação de carga das tarefas nos recursos do sistema.
No caso de tarefas de hardware, a configuração consiste no envio dos bits de configuração (bitstream) para a lógica configurável embarcada.
O bitstream atribui determinado comportamento ao hardware reconfigurável.
No caso de tarefas de software, a configuração consiste no envio e gravação de códigos objeto de uma dada tarefa na memória do processador alvo.
O controle de configuração não faz parte do escopo do trabalho.
Ele é simulado com base em experimentos prévios que permitem estimar os atrasos de configuração O processador MP define uma abordagem centralizada de gerenciamento, que pode apresentar problemas relativos à escalabilidade, conforme mencionado em.
Além disso, o gerenciamento centralizado sofre com o problema de ponto de falha único, e pode transformar o gerente num gargalo do sistema, visto que todo o tráfego de pacotes de controle envolve o roteador em o qual o MP foi alocado.
Assim, o estudo de técnicas distribuídas de controle necessita ser investigado à medida que cresce o número de PEs num MPSoC.
Conforme, resultados prévios apresentado em, para MPSoCs com dimensões 32x32, estratégias de gerenciamento distribuído otimizam o desempenho do sistema com relação a o tempo de mapeamento.
Como nos experimentos realizados, apresentados mais adiante, foram simulados MPSoC com dimensões até 8x8, o emprego de uma estratégia de controle distribuído não se fez necessário.
Além disso, a maioria dos trabalhos revisados considera a implementação ou simulação de MPSoCs ainda menores Antes de discutir em maiores detalhes o comportamento do sistema, é importante definir a modelagem adotada para a representação das aplicações.
Em o estudo sobre MPSoCs, em geral aplicações são modeladas através de grafos.
Hu e Marculescu e Lin e outros empregam grafos, onde vértices representam tarefas, e pesos atribuídos às arestas representam o volume de dados transmitidos entre as tarefas conectadas.
Marcon e outros usam dois grafos, o primeiro com informação sobre a dependência e o volume de comunicação entre as tarefas, e o segundo que contém a ordenação dos pacotes.
Em, os Autores apresentam um modelo mais detalhado que também considera os tempos de computação das tarefas.
Além de o volume de dados, Rhee e outros consideram a largura de banda necessária para as comunicações, enquanto Srinivasan e Chatha consideram tanto a largura de banda quanto a latência necessárias para a transmissão dos pacotes através da NoC.
Em o presente trabalho, uma dada aplicação é representada por um grafo dirigido, como esboçado na Figura 3.2.
Em este grafo, vértices representam tarefas, e arestas indicam as comunicações realizadas entre as tarefas das aplicações.
Os vértices representados por círculos com linha dupla referem- se às tarefas iniciais das aplicações.
Cada aplicação possui apenas uma dada tarefa inicial, a qual é iniciada tão logo a aplicação seja disparada por o usuário.
Os demais vértices indicam tarefas de software e de hardware, representadas por os círculos claros e escuros, respectivamente.
As arestas entre as tarefas possuem pesos referentes ao volume e taxas de comunicação entre as tarefas, em ambos os sentidos.
Cada aresta define assim, um par de tarefas mestre-escravo, onde a tarefa denominada mestre necessita quais definem o volume V e a taxa R de transmissão de dados entre as tarefas no sentido mestre-escrava ms e escrava-mestre sm.
Em a implementação do MPSoC os processadores executam apenas um vértice de uma dada aplicação por vez.
Essa abordagem conduz à modelagem de processadores monotarefa.
Contudo, cada vértice do grafo pode representar não só uma única tarefa, mas sim um conjunto de tarefas.
A operação de particionamento, realizada em tempo de projeto, é responsável por dividir uma dada aplicação, num conjunto de tarefas.
Em geral, cada conjunto é definido de maneira a otimizar o uso dos recursos da plataforma alvo.
Logo, é possível também admitir que cada PE pode executar um conjunto de tarefas, segundo um modelo multitarefa.
O presente trabalho está focado no domínio de aplicações de fluxo de dados, tais como processamento para transmissão sem fio de sinais de áudio e vídeo, e processamento multimídia.
Aplicações neste domínio são caracterizadas por um processamento local simples, porém realizado sobre uma grande quantidade de dados.
Além disso, faz- se necessária a garantia de desempenho na transmissão dos dados, tanto quanto no processamento dos mesmos.
Em esse caso, o emprego de técnicas de controle de desempenho do sistema para garantia dos serviços é obrigatório, sobretudo aquelas que visam evitar congestionamentos na NoC.
Em esta Seção, discute- se a infra-estrutura de comunicação empregada no MPSoC alvo.
Foi definido o emprego de uma infra-estrutura baseada em NoC devido a fatores de escalabilidade e paralelismo, corroborado por o fato de que a maioria dos trabalhos investigados adotou tal abordagem.
A experiência do grupo GAPH na área de NoCs contribuiu significativamente para o emprego da Hermes.
Além disso, ela disponibiliza um conjunto de ferramentas que permite sua geração de acordo com diferentes parametrizações;
Geração de cenários de tráfego;
Simulação e prototipação do sistema;
E avaliações da latência dos pacotes e dissipação de potência.
De entre as parametrizações possíveis constam as dimensões da NoC, o algoritmo de roteamento, o controle de fluxo, o tamanho dos buffers, e a largura de flit.
O roteador da Hermes é ilustrado na Figura 3.3.
Ele possui cinco portas, quatro de elas são conectadas aos roteadores vizinhos, formando uma topologia malha 2D.
A outra porta, denominada local, é conecta ao elemento de processamento, ou IP.
Cada enlace entre os roteadores da NoC possui dois canais de 16 bits de comunicação, um em cada um dos sentidos, permitindo a transmissão bidirecional simultânea entre os roteadores.
Outros parâmetros adotados são:
Chaveamento de pacotes wormhole;
Buffers de entrada;
O protocolo de comunicação proposto baseia- se no uso de quatro tipos de pacotes, de acordo com a Figura 3.4.
Para facilitar o entendimento, a NoC não é representada na figura, embora todos os pacotes sejam transmitidos através de ela.
Três pacotes, ditos de controle são empregados na comunicação entre as tarefas e o processador gerente MP.
São eles:
REQUEST, RELEASE e NOTIFY.
A comunicação entre duas tarefas se dá através de pacotes do tipo General.
O pacote REQUEST informa ao MP o identificador de uma nova tarefa a ser inserida no sistema, e os respectivos volume e taxas de comunicação.
Esse pacote é usado para a requisição de uma dada tarefa, tal como seu nome indica.
O pacote de RELEASE, por sua vez, informa ao MP que um determinado PE teve sua tarefa concluída, liberando tal recurso para que outra tarefa seja em ele alocada.
Dois pacotes de controle do tipo NOTIFY são enviados por o MP após o mapeamento de uma dada tarefa, um para cada tarefa envolvida na comunicação (Escrava recém mapeada e sua mestre).
Esses pacotes informam os endereços das tarefas a fim de possibilitar a correta transmissão dos pacotes.
Vistos os conceitos de aplicação e o protocolo definido para comunicação entre as tarefas, o comportamento genérico de uma dada tarefa é discutido agora.
Ele compreende sete passos.
São eles:
A Figura 3.5 apresenta um diagrama de interação entre as tarefas de uma dada aplicação alvo, de acordo com os passos anteriores.
Considerando as comunicações entre as tarefas t0, t2 e t3 do grafo alvo em destaque na figura, cada um dos 7 passos é indicado tendo t2 como tarefa de referência.
Em o passo 1, t2 aguarda até receber o pacote NOTIFY a partir de MP com o endereço da sua mestre t0.
Em o passo 2, t2 recebe os pacotes General enviados por t0.
Em seguida, t2 requisita sua escrava t3 ao MP, no passo 3.
Após o mapeamento de t3, MP envia à t2 o endereço da escrava mapeada através de um pacote NOTIFY, recebido por t2 no passo 4.
Após o término da comunicação com t3, t2 envia o pacote RELEASE para MP no passo 5.
Em o passo 6, t2 realiza seu processamento, e no passo 7 ela en- via os devidos resultados a sua mestre t0.
Embora as comunicações entre t0 e suas escravas t1 e t2 tenham sido apresentadas separadamente na Figura 3.5, elas podem ocorrer simultaneamente, dependendo diretamente de como a tarefa foi programada.
Aqui, elas foram apresentadas assim, sem qualquer concorrência, apenas com o objetivo de facilitar o entendimento do comportamento da tarefa de referência t2.
A representação dos recursos inclui os elementos de processamento e os canais da NoC.
Alguns trabalhos encontrados na literatura tratam o problema de mapeamento genericamente, sem considerar a infra-estrutura de comunicação.
Em esses trabalhos, os PEs são modelados através de matrizes 2 D, com a, ou inteiros positivos.
O emprego de valores inteiros pode reduzir o tempo de procura de recurso livre, mas demanda mais memória, comparado aos valores em, e árvores em.
Em geral, o uso de matrizes tende a apresentar um tempo maior de busca em comparação às listas encadeadas.
Contudo, as listas requerem um tempo maior para manutenção devido a sua complexidade.
Em o presente trabalho, a representação dos recursos, incluindo os elementos de processamento e os canais da NoC, é baseada num conjunto de cinco matrizes.
Adotando- se um MPSoC com n colunas e m linhas, tem- se então as seguintes matrizes:
Um dado elemento de processamento é representado por PEij, onde i e j referemse a coluna e linha em que o elemento encontra- se na matriz PE, respectivamente, conforme a distribuição apresentada na Figura 3.6.
A informação armazenada em PEij contém seu tipo (Inicial, hardware ou software) e seu estado (Livre ou ocupado).
Os enlaces da NoC são compostos por um par de canais unidirecionais, com sentidos opostos.
Os canais da NoC são representados por quatro matrizes:
Canais para leste (East Channels -- ECij);
Canais para oeste (West Channels -- WCij);
Canais para norte (North Channels -- NCij);
E canais para sul (South Channels -- SCij), onde i e j possuem o mesmo significado usado na representação da matriz PE.
Cada elemento das matrizes de canais informa o percentual de ocupação da largura de banda disponível.
Monitoramento é um assunto importante em NoCs, pois permite capturar informações sobre o desempenho do sistema em tempo de execução.
Por exemplo, Marescaux e outros empregam fios de controle (separados da NoC) para enviar informações sobre congestionamentos ao PE fonte do tráfego, permitindo que este ajuste sua taxa de injeção de pacotes.
Enquanto isso, e empregam a mesma rede para transmissão de pacotes de dados e controle.
Em, os Autores usam uma ferramenta denominada Model Predictive Controller, a qual obtém informação sobre o estado de congestionamento da rede através de monitores distribuídos sobre a NoC.
Ciordas e outros propõem um serviço de monitoramento genérico, com monitores anexos aos roteadores da NoC ou às interfaces de rede.
O processador gerente MP realiza o mapeamento das tarefas de acordo com a ocupação dos PEs e dos canais da NoC.
Cada matriz de recurso necessita então ser atualizada em tempo de execução para prover ao MP uma informação precisa sobre a ocupação dos recursos.
A estimativa da carga dos canais e de congestionamentos pode basear- se em dois diferentes métodos (Figura 3.7).
O primeiro de eles, empregado em, monitora os pacotes de REQUEST e RELEASE recebidos por o MP.
Esta abordagem requer o uso de um único monitor, anexo à porta local do roteador conectado ao MP.
De essa forma, cada canal tem sua ocupação atualizada a partir de as taxas informadas em pacotes REQUEST.
De acordo com o algoritmo de roteamento (nesse caso o xy), a ocupação dos canais é devidamente incrementada com as taxas informadas.
O processo inverso é realizado quando o monitor captura um pacote RELEASE.
Essa estratégia reflete um esquema de monitoramento centralizado (lado esquerdo da Figura 3.7), onde o desempenho do mapeamento está diretamente relacionado às taxas estimadas, enviadas ao MP.
Conforme esboçado na parte direita da Figura 3.7, a segunda abordagem de monitoramento investigada insere um monitor em cada uma das portas dos roteadores da NoC.
Este monitoramento distribuído permite medir o tráfego real em cada canal da NoC.
Assim como em e, aqui também a informação capturada por os monitores é enviada através da mesma rede de comunicação de dados.
Diferentemente da abor dagem centralizada, a distribuída é independente do algoritmo de roteamento adotado.
Além disso, ela suporta algoritmos não determinísticos.
Entretanto, além de consumir área adicional, os monitores distribuídos também aumentam a dissipação de potência.
Durante o desenvolvimento desse trabalho, três abordagens diferentes foram empregadas para modelagem do sistema.
São elas baseadas em:
POSIX Threads; SystemC_ threads no nível TLM;
E System_ Cthreads e VHDL em nível RTL.
A seguir cada uma de elas é introduzida.
A primeira modelagem realizada visou uma implementação simplificada do sistema, a fim de validar a proposta do estudo sobre mapeamento dinâmico de tarefas.
Ela é baseada em Pthreads (POSIX Threads).
Cada uma das tarefas é representada por uma dada thread.
Existem três tipos de tarefas no sistema:
Tarefas de software que executam em processadores, tarefas de hardware que executam em áreas reconfiguráveis, e tarefas fixas que executam em recursos fixos no sistema (Memórias e interfaces de E/ S).
As últimas, por serem fixas, não necessitam ser mapeadas em tempo de execução.
A NoC, por sua vez, é modelada como uma matriz de buffers e quatro matrizes de canais, as quais mantém informação sobre a ocupação da largura de banda.
Nenhum atraso é considerado na transmissão, visto que os pacotes não são transferidos através de enlaces, eles são gravados diretamente nos buffers.
Para suportar a execução de todas as tarefas, os recursos do sistema podem ser de hardware, software ou fixos.
Eles são representados por seu tipo e posição, dada por as coordenadas da matriz de recursos.
Cada recurso é associado a um dado buffer de entrada através dos seus índices na matriz.
O processo de mapeamento refere- se à atribuição de um recurso a uma dada tarefa, a qual pode ler os pacotes endereçados a ela a partir de o buffer associado a esse recurso.
Todas as escrita e leitura nos buffers são realizadas com base em um mutex, que assegura o acesso individual e atômico.
Dois algoritmos de mapeamento foram implementados.
O primeiro, denominado First Free, posiciona a tarefa na primeira posição livre, de acordo com seu tipo, sem considerar qualquer função custo.
O segundo algoritmo emprega uma função custo que avalia o somatório da ocupação dos canais da NoC.
Os algoritmos de mapeamento implementados são discutidos em maiores detalhes no próximo Capítulo.
Os experimentos validam a técnica de mapeamento baseada na ocupação de canais, bem como a estratégia de clusterização.
A dificuldade nessa modelagem refere- se às medições de tempo (De mapeamento, de execução das tarefas), impossibilitadas já que o programador não tem acesso a informações de troca de contexto (controlado por o SO) entre as threads executadas.
Adicionalmente, as instruções disponíveis para medições de tempo possuem precisão na ordem de msegundos apenas, Ferramentas tipo GProf que permitem obter um relatório detalhado da execução das funções do programa após sua execução.
Assim, as medições são imprecisas nessa modelagem.
A segunda modelagem realizada foi baseada em SystemC_ Threads, portanto em nível transacional TLM, onde o conceito de relógio de operação não é adotado.
O objetivo dessa modelagem consiste numa avaliação mais completa dos possíveis ganhos das heurísticas de mapeamento congestion-- aware, em sistemas heterogêneos.
Para isso, na avaliação, considera- se além de a ocupação dos canais da NoC, o tempo total de execução das aplicações simuladas.
Usando a biblioteca SystemC o programador pode controlar a troca de contexto entre as SystemC_ Threads.
Os recursos são representados por uma matriz de ocupação.
Cada um de eles possui um buffer de entrada associado.
A NoC em si é representada por:
Uma função que estima o atraso dos pacotes;
Um conjunto de buffers;
E matrizes que armazenam a ocupação de cada um dos seus canais.
Os canais em si não existem.
Quando uma tarefa deseja se comunicar com outra, ela grava os pacotes diretamente no buffer da tarefa destino da comunicação, assim como na modelagem anterior.
Entretanto, o pacote será disponibilizado para a tarefa destino somente após o atraso calculado, tendo por base a ocupação dos canais usados na transmissão e o número de hops necessários.
Portanto, essa modelagem permite estimar a degradação no desempenho das aplicações relativa ao nível de congestionamento no sistema.
O processo de mapeamento consiste em atribuir a uma dada tarefa o endereço do buffer de o qual ele deve ler seus pacotes.
A avaliação do sistema compreende a execução de um conjunto de simulações cujos resultados permitem comparações entre diferentes estratégias de mapeamento, discutidas em detalhes no próximo Capítulo.
De entre as funções custo adotadas constam as ocupações máximas e médias dos canais da NoC.
Em os experimentos realizados o tempo de mapeamento é considerado.
A terceira modelagem é baseada em SystemC_ Cthreads e VHDL, em nível RTL.
Ela permite avaliações no nível de ciclo de relógio de operação.
Seu objetivo consiste em obter avaliações precisas das heurísticas de mapeamento investigadas.
A modelagem RTL é a principal modelagem do trabalho aqui proposto.
Por isso, os resultados apresentados bem como os algoritmos implementados são todos discutidos tendo por base tal abordagem.
Além disso, os modelos de aplicação e recursos apresentados anteriormente também fazem referência a ela.
Em as modelagens anteriores, cada tarefa do sistema era representada por sua própria thread.
Em a modelagem RTL, uma abordagem diferente é adotada, onde cada PE é modelado por uma thread.
Eles são emulados por módulos descritos em SystemC, conectados as portas locais dos roteadores da NoC descrita em VHDL.
Esses módulos reproduzem o comportamento padrão de uma dada tarefa (Figura 3.5).
Esse comportamento é parametrizado em tempo de execução por um dado arquivo de configuração, o qual contém informação sobre os volumes e as taxas de comunicação, bem como sobre as topologias das aplicações simuladas.
De essa forma, cada tarefa é descrita por seu arquivo.
As avaliações são mais completas e precisas na modelagem RTL.
De entre os parâmetros de desempenho investigadas, além de o tempo de execução e a ocupação dos canais, encontram- se o nível de congestionamento do sistema, as latências dos pacotes, e a energia consumida durante a operação do sistema.
Como nessa abordagem a NoC é completamente modelada, é possível avaliar também o emprego de monitores distribuídos, além de o monitoramento dos pacotes de REQUEST e RELEASE apenas.
A Tabela 3.1 apresenta um quadro comparativo entra as três modelagens investigadas no presente trabalho.
Como mencionado anteriormente, o mapeamento é a operação que define o posicionamento das tarefas nos recursos do sistema.&amp;&amp;&amp;
A posição de uma dada tarefa pode interferir diretamente no desempenho do sistema, afetando, por exemplo, parâmetros como energia consumida, congestionamento da interface interna de comunicação e tempo total de execução das aplicações.
Em o domínio de aplicações que apresentam uma carga dinâmica de tarefas, o uso de estratégias estáticas de mapeamento não é adequado.
Em esse caso, estratégias dinâmicas de mapeamento necessitam ser empregadas a partir de o constante monitoramento dos recursos do sistema para otimizar o uso dos mesmos e ainda garantir um bom desempenho.
Em geral, no mapeamento estático de tarefas o tempo para definir o mapeamento não é tão importante quando comparado a um cenário onde as tarefas necessitam ser mapeadas em tempo de execução.
Em cenários dinâmicos, o tempo de mapeamento ganha importância, visto que exerce influência direta sobre o desempenho do sistema.
Em esse caso, o emprego de uma solução força bruta para o problema de mapeamento também não é indicado, pois tal problema é conhecido como um problema de atribuição Np-completo.
De fato, até mesmo em tempo de projeto a solução força bruta pode ser proibitiva, visto que o aumento nas dimensões do MPSoC leva a um crescimento exponencial no tempo para computar a solução.
Assim, surge a necessidade do estudo de heurísticas para o mapeamento de tarefas, que podem apresentar boas soluções de mapeamento, muitas vezes próximas da melhor solução, e que consomem um tempo reduzido para sua execução mesmo para instâncias maiores do problema.
Conforme a revisão apresentada no Capítulo 2, a maioria das pesquisas em mapeamento de tarefas investiga estratégias estáticas de mapeamento.
Entretanto, o mapeamento dinâmico começa a ser pesquisado.
Em sua maioria, os Autores desconsideram o atraso de mapeamento, e investigam o mapeamento dinâmico de tarefas baseado nas mesmas estratégias antes adotadas em tempo de projeto, diferentemente do trabalho aqui proposto, que aplica algoritmos gulosos para o mapeamento de tarefas.
Em a operação do MPSoC proposto no Capítulo 3, inicialmente somente as tarefas de controle do MP estão alocadas no sistema.
Novas aplicações (Tarefas iniciais) são disparadas por o usuário, e mapeadas por o MP.
As demais tarefas do sistema são alocadas quando uma dada tarefa tenta se comunicar com uma tarefa ainda não alocada no sistema.
Ou seja, as tarefas são mapeadas individualmente, sob demanda das aplicações.
Mapear todas as tarefas de uma dada aplicação de uma única vez deve apresentar uma melhor solução de mapeamento, visto que tal abordagem vale- se do conhecimento global da aplicação, incluindo a topologia de seu grafo de representação.
No entanto, num cenário dinâmico, não é possível estimar precisamente quando cada tarefa será necessária.
Assim, mapeando toda a aplicação, possivelmente, algumas de suas tarefas irão ocupar os recursos do sistema sem no entanto estar executando.
Essa abordagem pode resultar numa subutilização dos recursos do sistema.
Ainda, se não existem recursos livres suficientes para as tarefas de uma aplicação, a mesma não será mapeada, problema que não pode ser amenizado se as tarefas de uma dada aplicação são mapeadas independentemente.
Em esse Capítulo discute- se o mapeamento dinâmico de tarefas, organizado como segue.
Em a Seção 4.1, apresenta- se formalmente o problema de mapeamento, bem como a função custo adotada, que considera a ocupação dos canais da NoC com o objetivo de reduzir possíveis congestionamentos.
Em a Seção 4.2, apresenta- se a estratégia de clusterização adotada para o mapeamento das tarefas iniciais das aplicações.
A Seção 4.3 discute dois métodos de mapeamento usados como referências para avaliação das quatro heurísticas aqui propostas, apresentadas na Seção 4.4.
Em o final do Capítulo, a Seção 4.5 discute a implementação de cada algoritmo, assim como sua complexidade.
Anteriormente neste documento, os componentes da operação de mapeamento foram definidos informalmente, incluindo as descrições de tarefa, aplicação e arquitetura alvo.
Tais definições foram importantes para auxiliar no entendimento dos trabalhos revisados e da proposta em si.
Contudo, a definição do problema de mapeamento exige conhecimento aprofundado desses e de outros componentes, como apresentado a seguir.
Definição 1.
Tarefa: Uma tarefa T é uma tripla T $= (Tid, Tex, Tti), onde Tid é o identificador da tarefa;
Tex é o tempo de execução da tarefa, e Tti Conforme esta definição, os tipos de tarefa estão relacionados à arquitetura dos elementos de processamento para a qual ela foi compilada.
No caso de um MPSoC homogêneo, por exemplo, todas as tarefas são do mesmo tipo porque só existe um tipo de ele-mento de processamento em o qual elas podem executar.
Em o presente trabalho, como o MPSoC é heterogêneo, uma dada tarefa pode ter um entre três tipos, de acordo com a natureza da sua implementação.
São eles:
Software, hardware e inicial.
As tarefas de software são aquelas que devem executar nos processadores do MPSoC, ao passo que tarefas de hardware são configuradas na lógica configurável embarcada.
Uma tarefa inicial é um caso especial de uma tarefa de software.
Como o próprio nome indica, uma tarefa inicial é a primeira a ser executada, quando uma dada aplicação é disparada por o usuário.
No caso de um MPSoC com outros tipos de elementos de processamento, o conjunto de tipos possível deve ser alterado, portanto.
Definição 2.
Comunicação: Uma comunicação Cms entre um par de tarefas m e s é uma quadrupla Cms $= (Vms, Rms, Vsm, Rsm), onde Vms é volu- me de dados enviados por a tarefa m para a tarefa s, segundo a taxa de trans-missão Rms, enquanto Vsm e Rsm possuem os mesmos significados respectivos para o sentido oposto de comunicação (de s para m).
O volume V é o número de flits enviados, ao passo que a taxa R é o percentual de ocupação da largura de banda disponível.
Definição 3.
Grafo de Aplicação:
Um grafo de aplicação APG é um grafo dirigido APG $= (St, SC) onde St é conjunto de vértices que representa o conjunto de tarefas que compõem a aplicação;
E SC é o conjunto de arestas que descreve as comunicações entre tarefas.
As arestas são definidas através de um par ordenado (s, m), onde s é a tarefa fonte e m é a tarefa destino da comunicação.
A topologia do grafo define a interdependência entre as tarefas da aplicação.
Cada par de tarefas conectadas é denominado par de tarefas comunicantes, onde o sentido da aresta de conexão determina a ordem parcial de alocação das tarefas no sistema.
A aresta dirigida indica que sua tarefa fonte necessita requisitar o mapeamento da tarefa destino, antes de iniciar a comunicação propriamente dita.
Assim, a tarefa fonte recebe a denominação de mestre, ao passo que a tarefa destino é dita escrava na comunicação, formando um par de tarefas mestre-escravo.
Em o presente trabalho, toda e qualquer aplicação pode conter apenas uma única tarefa inicial.
Este pressuposto é adotado em concordância com a estratégia de clusterização, explicada em maiores detalhes a seguir, na Seção 4.2.
Definição 4.
Elemento de Processamento:
Um elemento de processamento PE é uma quintupla PE $= (PEid;
PEad; PEti;
PEuse; St), onde:
PEid é o identificador do elemento de processamento;
PEad é o seu endereço para Assim como no caso de as tarefas, PEs podem ser classificados num de três tipos:
PEs podem conter apenas uma tarefa.
Então, o valor de ocupação indica um entre dois estados possíveis:
Ocupado ou livre.
Além disso, o conjunto de tarefas St mapeadas no PE será composto por uma ou nenhuma tarefa.
Definição 5.
Canal de Comunicação: Um canal de comunicação C é um con-junto de sinais/ fios que transmitem dados e controles entre dois elementos de processamento.
Ele é uma dupla C $= (Cw, Cuse), onde Cw é a largura em bits do canal, incluindo dados e controles;
E Cuse é o percentual de uso da largura de banda disponível para transmissão de dados apenas.
Definição 6.
Enlace de Comunicação:
Um enlace de comunicação L é uma Em o presente trabalho, assume- se que cada enlace de comunicação possui apenas um par de canais de comunicação que permitem a transmissão bidirecional simultânea (do inglês, fullduplex) de dados entre os PEs conectados.
Definição 7.
Grafo do MPSoC:
Um grafo de MPSoC é um grafo GMPSoC $= L\&gt; onde PE é o conjunto de vértices representando o conjunto dos elementos de processamento do MPSoC, e L é o conjunto de arestas que representa os enlaces que interconectam os PEs.
PEs de um dado MPSoC recebem tarefas que são mapeadas para execução.
Além de elementos de processamento programáveis/ configuráveis que recebem tarefas, PEs podem ser IPs fixos que executam operações específicas, Controle de E/ S e armazenamento de dados (Memórias embarcadas).
Contudo, quando uma dada tarefa necessita se comunicar com um desses IPs fixos, a comunicação segue o mesmo protocolo definido no Capítulo anterior.
A diferença nesse caso consiste no fato de que a operação de mapeamento não será realizada para IPs fixos.
Em o presente trabalho, MPSoCs são representados por GMPSoCs de topologia malha, onde cada PE é composto não só por o elemento de processamento em si, mas também por a lógica que o interconecta aos enlaces de comunicação.
Enlaces são dispostos nas direções horizontal e vertical de acordo com os eixos x e y num sistema de coordenadas cartesianas.
Um roteador é representado por o seu algoritmo de roteamento.
Aqui o algoritmo de roteamento xy é adotado, onde os pacotes são transmitidos entre fonte e destino, primeiro com deslocamentos na direção horizontal x, seguidos de deslocamentos na direção vertical y.
Definição 8.
A a PE, que associa tarefas do domínio T à elementos de processamento do contra-domínio PE.
Em esse caso, denota- se por f (tx) o elemento de processamento pey que a função f associa ao elemento tx:
Em esse trabalho, assume- se que as tarefas são mapeadas individualmente.
As entradas da função de mapeamento tratada incluem a tarefa a ser mapeada, e a arquitetura alvo.
A tarefa é descrita por o seu tipo, suas taxas e volumes de comunicação, e ainda por a posição da sua tarefa mestre.
A arquitetura é descrita de acordo com a Definição 7, ou seja, por a sua topologia, tipos e posição de cada PE, e ainda por a ocupação dos canais de comunicação.
A saída da função de mapeamento constitui- se de uma dada posição, ou seja, um dado PE, em o qual a tarefa deve executar.
O problema de mapeamento consiste em encontrar um mapeamento para a tarefa que ao mesmo tempo respeite as restrições e atenda aos requisitos do sistema.
Restrições são informações que delimitam o sistema.
Exemplos comuns compreendem a largura máxima de transmissão de dados, e o consumo máximo de energia.
Requisitos são informações desejadas para os sistemas.
Exemplos são baixo consumo de energia ou área reduzida.
O requisito principal adotado aqui consiste em minimizar os congestionamentos nos enlaces do MPSoC.
Com a redução dos congestionamentos, espera- se indiretamente minimizar o tempo de execução das tarefas, e ainda otimizar seu consumo de energia.
Como em geral mais de um mapeamento é possível no sistema, faz- se necessária a elaboração de funções custo para avaliar a qualidade de um dado mapeamento de acordo com um dado critério.
Através das funções custo pode- se escolher qual de entre as possíveis soluções será a escolhida.
Funções custo podem considerar mais de uma métrica.
Nos presente trabalho, apenas a ocupação dos canais é considerada.
Para avaliar ocupação dos canais resultantes de um dado mapeamento, três funções custo são adotadas:
Ocupação máxima dos canais;
Ocupação média dos canais;
E Ocupação dos canais do caminho de comunicação.
De acordo com a Definição 7, a partir de um dado GMPSoC pode- se obter o conjunto L de todo os seus enlaces.
Cada um desses é composto por um conjunto de canais conforme a Definição 6.
Logo, o conjunto de todos os canais do MPSoC pode ser representado por a união de todos os conjuntos de canais Lsc referentes a cada um dos enlaces do MPSoC.
Cada canal, por sua vez, possui informação sobre sua ocupação, representada por Cuse, o percentual de uso da largura de banda disponível.
A função custo ocupação máxima dos canais representada por max (M, ts, tm, pek) simula o mapeamento da tarefa ts, solicitada por sua mestre tm, no elemento de processamento pek do MPSoC M, e retorna o maior percentual de uso da largura de banda disponível Cuse entre todos os canais de M. Assim, essa função retorna os picos de ocupação dos canais, que denotam possíveis congestionamentos na comunicação.
Se o pico de ocupação apresenta um valor baixo, então pode- se concluir que não existe congestionamento no sistema.
À medida que esse valor se aproxima da taxa máxima de transmissão suportada, a probabilidade de acontecerem congestionamentos aumenta, até o pico ultrapassar o limite, configurando- se uma situação de congestionamento.
A função custo ocupação média dos canais representada por avg (M, ts, tm, pek), assim como a função max, simula o mapeamento da tarefa ts, solicitada por sua mestre tm, no elemento de processamento pek de M. Entretanto, avg retorna a média do percentual de uso da largura de banda Cuse para todos os canais de M. Assim, médias baixas podem ser obtidas ou quando poucos canais são usados, ou ainda se os canais usados são pouco ocupados.
Em a primeira situação onde poucos canais são usados, uma média baixa não significa que não existam congestionamentos no sistema, visto que os valores altos de ocupa-ção serão diluídos por a operação de cálculo da média.
Em o caso onde a média de ocupação é alta, então pode- se deduzir que existe um ou mais congestionamentos no sistema.
A função média visa, sobretudo, uma distribuição uniforme na ocupação dos canais.
A terceira função custo adotada é a ocupação dos canais do caminho de comunicação.
Representada por sum (M, ts, tm, pek), ela simula o mapeamento da tarefa ts, solicitada por sua mestre tm, no elemento de processamento pek do MPSoC M. Como resultado, a função retorna o somatório dos percentuais de uso da largura de banda Cuse, considerando apenas os canais que fazem parte do caminho de comunicação entre as tarefas ts e tm, denotado por CP (ts, tm).
Tal caminho pode ser definido como segue.
Definição 9.
Segmento de Caminho de Comunicação: Um segmento de direção e o mesmo sentido, utilizados na comunicação entre duas tarefas fonte e destino, conforme o algoritmo de roteamento.
Existem segmentos de caminho para cada direção:
Leste (PSEC), Oeste (PSWC), Norte (PSNC) e Sul (PSSC).
Definição 10.
Caminho de Comunicação: Um dado caminho de comunicação Em esse trabalho, todas as comunicações entre as tarefas se dão através de um dado caminho de comunicação.
Ele é formado por quatro segmentos de caminho, cada um em sua direção.
Os canais pertencentes a cada segmento são determinados de acordo com a posição das tarefas comunicantes e com o algoritmo de roteamento xy adotado.
Assim, caso as tarefas sejam alocadas na mesma coluna de recursos então os segmentos de caminho na direção horizontal serão conjuntos vazios.
O mesmo acontece para os segmentos verticais se as tarefas estiverem alocadas na mesma linha de PEs.
Dadas duas tarefas, Te a e Tb, a Equação 4.1 representa o caminho de comunicação CP (TA, TB) entre tais tarefas, onde PSEC (Te a, TB) é o segmento de caminho composto por os canais da matriz de canais para o Leste (Figura 3.6).
PSWC (TA, TB), PSNC (Te a, TB) e PSSC (TA, TB) possuem significado similar.
Ainda é importante notar que um dado caminho de comunicação contempla ambos os sentidos de transmissão.
A Figura 4.1 apresenta um exemplo de definição de um caminho de comunicação entre duas tarefas Te A e Tb, de acordo com o algoritmo de roteamento xy.
A estratégia empregada para definir o mapeamento de tarefas iniciais das aplicações apresenta um grande impacto no desempenho do mapeamento da aplicação como um todo.
Duas estratégias podem ser empregadas nesse caso.
A primeira de elas realiza o mapeamento de tarefas iniciais sem qualquer critério.
Como tarefas iniciais de aplicações diferentes podem ser mapeadas perto umas das outras, o mapeamento das demais tarefas de uma dada aplicação pode ser prejudicado com relação a o distanciamento entre as tarefas comunicantes.
Os recursos ao redor de as tarefas iniciais estarão possivelmente todos ocupados, e as aplicações estarão inteiramente misturadas e distribuídas sobre o MPSoC, causando assim uma utilização não otimizada dos canais e, possivelmente congestionamento na NoC.
Uma segunda estratégia, adotada no presente trabalho, define posições fixas, e distantes umas das outras para o mapeamento de tarefas iniciais.
Assim, no mapeamento das aplicações, cada uma de elas deve ocupar uma região diferente do MPSoC, reduzindo o número de canais compartilhados por comunicações de aplicações diferentes.
Essa estratégia recebe aqui o nome de clusterização, pois simula a divisão do MPSoC em clusters.
As aplicações podem ocupar recursos além de aqueles disponibilizados por um dado cluster, visto que seus limites são virtuais apenas.
Ou seja, o limite para mapear uma aplicação completa é função apenas da demanda da aplicação e da disponibilidade de recursos no MPSoC.
Entretanto, o número de aplicações simultâneas é limitado por o número de recursos dedicados a receber tarefas iniciais das aplicações.
Em a Figura 4.2, apresenta- se um exemplo MPSoC 6x6 particionado em 4 clusters.
Os PEs em destaque são aqueles reservados para o mapeamento das tarefas iniciais das aplicações.
Eles são posicionados preferencialmente no centro do cluster gerado por o particionamento.
Assim deve- se reduzir a sobreposição entre as tarefas de aplicações diferentes.
A Figura 4.3 apresenta um exemplo do emprego das duas estratégias para o mapeamento de tarefas iniciais das aplicações, e seus efeitos sobre uma dada comunicação.
As tarefas são representadas por círculos, onde AiTj refere- se a tarefa j da aplicação i.
O algoritmo de roteamento xy é adotado na definição das rotas dos pacotes que compõem as comunicações.
Em (a), as tarefas iniciais de quatro aplicações (A0 T0, A1 T0, A2 T0 e A3 T0) foram posicionadas como vizinhas.
Em virtude de a ordem do mapeamento e do mapeamento inicial empregado (Sem qualquer critério), a comunicação entre as tarefas A0 T0 e A0 T2 deve ocupar seis canais da NoC.
Em a mesma Figura, em (b), quando as tarefas iniciais estão posicionadas distantes de acordo com a estratégia clusterização, apenas dois canais da NoC são necessários para a comunicação entre as mesmas tarefas.
Dois métodos de mapeamento de tarefas que não possuem função custo de congestionamento são empregados no presente trabalho, são eles:
First Free e Nearest Neighbor.
O algoritmo de mapeamento de tarefas First Free (FF) seleciona o primeiro recurso livre capaz de suportar a execução da tarefa a ser mapeada, de acordo com os tipos de recursos e tarefas, sem considerar métricas de desempenho.
A procura por o alvo inicia por o recurso R00, no canto inferior esquerdo do MPSoC, e caminha por os recursos coluna a coluna, sempre no sentido ascendente (veja Figura 4.4).
O algoritmo FF deve apresentar resultados ruins de mapeamento com relação a a ocupação dos canais.
Entretanto, seu tempo de execução deve ser muito pequeno em comparação as demais heurísticas, apresentadas adiante.
O resultado de FF não necessariamente representa o pior mapeamento possível, visto que mapeamentos realizados de maneira aleatória, como os usados nas comparações realizadas em, devem apresentar soluções ainda piores.
No entanto, o mapeamento aleatório não é considerado aqui.
Assim como FF, o algoritmo Nearest Neighbor (NN) também não considera os congestionamentos quando decide o mapeamento de uma dada tarefa.
Contudo, a definição do seu caminho de procura privilegia a proximidade entre as tarefas comunicantes, durante o processo de mapeamento.
Para isso, conforme a Figura 4.5, NN inicia sua procura por um recurso livre, a partir de o recurso onde a tarefa que solicitou (Mestre) o mapeamento da escrava encontra- se alocada.
A procura segue um caminho circular, onde os vizinhos são testados de acordo com o número de saltos (hops) necessários para a comunicação.
Ou seja, testa- se os vizinhos com 1 hop de distância, depois os vizinhos com 2 hops, e assim por diante, variando o número de hops (NH na Figura 4.5) até os limites do MPSoC.
A procura termina assim que o primeiro vizinho livre, capaz de suportar o tipo da tarefa a ser executada, for encontrado.
Esse algoritmo apresenta o mesmo objetivo do mapeamento de Força Direcionada apresentado em, ou seja, posicionar as tarefas comunicantes tão próximas quanto possível.
Estima- se que esta estratégia resulte numa boa ocupação dos canais, mesmo que nenhuma métrica direta de congestionamento seja empregada como função custo.
Além disso, o tempo de procura deve ser baixo, a exemplo do tempo de mapeamento apresentado por First Free.
O caminhamento apresentado na Figura 4.5 assemelha- se ao apresentado por o algoritmo Spiral proposto em.
A diferença esta na origem, que aqui não consiste numa posição fixa como no trabalho citado, onde uma única aplicação é mapeada por completo.
Ambas as estratégias foram propostas ao mesmo tempo, no entanto sem qualquer interação entre os grupos de pesquisas.
Em essa Seção, apresenta- se quatro heurísticas para o mapeamento dinâmico de tarefas.
Elas são ditas congestion-- aware visto que visam reduzir os congestionamentos na infra-estrutura de comunicação.
Para isso, avaliam constantemente a ocupação dos canais da NoC durante o processo de mapeamento.
O primeiro algoritmo de mapeamento congestion-- aware aqui proposto denomina- se Minimum Maximum Channel Load (MMCL).
Esse algoritmo avalia todos os possíveis mapeamentos para cada um das tarefas a serem mapeadas no sistema.
Sua função custo baseia- se na ocupação máxima dos canais da NoC.
De entre os possíveis mapeamentos, MMCL irá selecionar aquele que apresentar o mínimo máximo de ocupação dos canais.
De essa forma, estima- se que a abordagem adotada por MMCL possa reduzir a ocorrência de picos de ocupações nos canais, os quais indicam possíveis congestionamentos.
As equações a seguir consideram um MPSoC com dimensões lx e ly, onde lx corresponde ao seu número de colunas e ly ao número de linhas.
Para cada mapeamento k, as taxas de comunicação entre as tarefas mestre (solicitante) e escrava (solicitada), Rms e Rsm (para ambos os sentidos de comunicação) são adicionadas à ocupação dos canais que pertence ao caminho de comunicação (Figura 4.1).
Após a avaliação da nova ocupação dos canais, de acordo com as Equações 4.2 à 4.5, a ocupação máxima de cada conjunto de canais é calculada, dadas as matrizes de canais.
Em a Equação 4.2, MaxREC (k) representa o máximo local obtido a partir de a ocupação REC dos canais que pertencem a matriz de canais para Leste.
MaxRWC (k), MaxRNC (k) e MaxRSC (k) seguem o mesmo raciocínio para os sentidos, Oeste, Norte e Sul, respectivamente.
A Equação 4.6 permite calcular o máximo global a partir de os máximos locais anteriormente computados, para cada mapeamento k, resultando num custo CMMCL (k).
() $= max (), (), () Finalmente, de entre os kP possíveis mapeamentos, o selecionado segundo o algoritmo MMCL será aquele com custo menor, ou seja, com o mínimo máximo computado, conforme a Equação 4.7.
A segunda heurística congestion-- aware proposta para o mapeamento dinâmico de tarefas, denominada Minimum Average Channel Load (MACL), visa reduzir a ocupação média dos canais da NoC.
MACL é muito semelhante ao algoritmo MMCL.
Por substituir a função máximo por a função média, MACL deve reduzir não apenas picos de ocupação, bem como deve distribuir de forma mais homogênea a ocupação dos canais da NoC.
O algoritmo MACL também avalia o posicionamento da tarefa a ser mapeada em cada posição k de entre as kP possíveis posições.
Para cada matriz de canais, a ocupação média local AvgREC (k) é calculada, conforme as Equações 4.8 à 4.11.
A partir de os valores para ocupação média local, o custo CMACL (k) do mapeamento k que representa sua ocupação media global pode ser obtida utilizando a Equação 4.12.
Conforme a Equação 4.13, o mapeamento selecionado será aquele que apresentar o custo mínimo, ou a mínima média entre todos os kP possíveis mapeamentos.
Além de o tempo elevado para o mapeamento, as heurísticas exaustivas MMCL e MACL apresentam ainda outros possíveis problemas.
Em MMCL, ao computar cada um dos possíveis mapeamentos, a adição das taxas aos canais da NoC pode não representar um acréscimo ao máximo calculado.
Assim, para todos os casos o custo CMMCL calculado pode ser o mesmo, e a posição selecionada pode não representar a melhor solução.
Conforme a Figura 4.6, em (a) apresenta- se a ocupação dos canais da NoC no instante em que a tarefa Te a requisita ao MP a tarefa Tb, com taxas de transmissão ms e mr iguais a 30 e 33.
MMCL deve encontrar a melhor posição de entre o dois nodos livres.
Em ambas as alternativas (b) e (c), os custos CMMCL calculados resultam em 90% porque em nenhum dos casos a adição das taxas de comunicação entre Te a e Tb interferem no canal que possui a máxima ocupação.
Em esse caso a escolha pode ser aleatória, e a alternativa (c) pode ser selecionada mesmo causando outro pico de ocupação dos canais.
A heurística MACL também pode ser comprometida, pois o uso da média como métrica pode não apresenta a melhor solução para mapeamento.
Isso ocorre porque a opção que utiliza poucos canais muito ocupados pode resultar numa média menor quando comparada a opções que usam muitos canais pouco ocupados.
Entretanto, futuramente no sistema, a escolha da última alternativa deve acarretar em maiores congestionamentos a medida que as comunicações entre as tarefas começam a compartilhar uma quantia maior de canais.
Conforme a Figura 4.7, em (a) apresenta- se a ocupação dos canais da NoC no instante em que a tarefa Te a requisita ao MP a tarefa Tb.
MACL deve encontrar a melhor posição de entre as duas possíveis (b) e (c).
A alternativa (a) deve ser escolhida porque apresenta a menor média CMACL, entretanto ela deve causar congestionamentos porque um dos canais tem ocupação 131%.
Enquanto isso, a alternativa (b) embora resulte numa média maior, apresenta uma distribuição mais justa quanto a a ocupação dos canais.
Como o tempo necessário para realizar o mapeamento pode ser proibitivo nas heurísticas que consideram todos os canais da NoC, tais como MMCL e MACL, o algoritmo Path Load (PL) é proposto.
Ele considera somente os canais que serão usados por a tarefa que está sendo mapeada, ou seja, aqueles que compõem seu caminho de comunicação.
Contudo ainda todos os possíveis mapeamentos são avaliados.
O mapeamento segundo o método PL computa a soma local SumREC (k) das ocupações dos canais para cada uma das matrizes, de acordo com as Equações 4.14 à 4.17.
Entretanto, tais somas consideram apenas os canais que compõem o caminho de comunicação entre as tarefas mestre e escrava.
A partir de as somas locais, o custo CPL (k) que representa a soma global é calculado através da Equação 4.18, para um dado mapeamento k.
Finalmente, o mapeamento selecionado é aquele que apresenta a menor soma global, conforme a Equação 4.19.
() $= min (), 0 Apresentado o método PL, pode- se retornar àquelas situações onde as heurísticas MMCL e MACL apresentam falhas.
Em a primeira de elas, ilustrada na Figura 4.6, o custo CPL computado para alternativa (b) e (c) são 78 e 148, respectivamente.
De essa forma, na heurística PL, a alternativa (b) será escolhida, diferentemente da heurística MMCL onde essa escolha poderia ser aleatória já que os dois casos apresentaram custos CMMCL idênticos.
Em seguida, no caso apresentado na Figura 4.7, os novos custos calculados de acordo coma heurística PL são CPL (b) $= 169 e CPL (c) $= 104.
Logo, PL seleciona a alternativa (c), que não causaria congestionamento, ao contrário de o resultado proposto quando a heurística MACL foi empregada.
Em essa Seção, discute- se os algoritmos de mapeamento propostos.
Contudo, antes da execução do mapeamento em si, duas operações importantes são realizadas no sistema implementado.
A primeira de elas testa todos os elementos de processamento para verificar se a tarefa solicitada já não se encontra alocada no sistema.
Em caso positivo, ela pode ser reutilizada, ou seja, torna- se desnecessário o passo de mapeamento e apenas seu endereço é enviado à tarefa mestre.
Além disso, o reuso evita que mais de uma instância de uma dada tarefa seja alocada no sistema.
Entretanto, se for interessante que várias instâncias executem em paralelo, então o programador pode replicar a tarefa e atribuir a elas identificadores diferentes.
Em o Algoritmo 4.1, apresentado abaixo, o bloco Enquanto na linha 4 realiza o teste para reuso.
Adicionalmente, antes de mapear a tarefa faz- se necessário verificar se existem recursos disponíveis.
Em caso positivo, o mapeamento pode seguir normalmente.
De o contrário, a tarefa necessita ser escalonada.
Conforme mencionado anteriormente, a estratégia de escalonamento implementada baseia- se num conjunto de três filas, uma para cada tipo de tarefa, sem política de preempção.
Em o Algoritmo 4.1, o bloco SE na linha 10 verifica a disponibilidade de recursos e escalona da tarefa se necessário.
Enquanto (PE NumeroDePEs) Faça Escalona (tarefa) Em contraproposta às estratégias que mapeiam simultaneamente todas as tarefas de uma dada aplicação, as heurísticas aqui apresentadas são algoritmos do tipo guloso, os quais realizam o mapeamento de uma única tarefa por vez.
Assim pode- se obter soluções de mapeamento próximas à melhor solução num tempo reduzido.
De outro lado, a alternativa que mapeia aplicações por inteiro baseia- se numa estratégia combinatória, a qual avalia todos os possíveis mapeamentos para todas as tarefas.
Em geral, os resultados providos por essa abordagem são melhores, ao custo de um maior tempo de execução.
Em a análise da complexidade dos algoritmos implementados admite- se um MPSoC com topologia malha, e com dimensões x e y.
Além disso, outros parâmetros devem ser conhecidos para um melhor entendimento da complexidade dos algoritmos, visto que influenciam no número de iterações realizadas nos algoritmos discutidos a seguir.
O primeiro de eles corresponde ao número total de elementos de processamento que compõem um MPSoC, dado por o produto apresentado na Equação 4.20.
O segundo parâmetro diz respeito ao número total de canais que compõem o MPSoC.
Dado um MPSoC malha com dimensões x e y, o número total de canais pode ser obtido a partir de a Equação 4.21.
O terceiro parâmetro para o cálculo da complexidade dos algoritmos é a distância máxima entre duas tarefas.
De acordo com o algoritmo de roteamento xy adotado, podese inferir que o número máximo de hops entre duas tarefas é dado por a Equação 4.22, que refere- se ao caso onde as tarefas comunicantes estão posicionadas nos recursos extremos opostos do MPSoC.
Como exemplo, pode- se citar a comunicação entre duas tarefas alocadas nos elementos PE0, 0 (Canto inferior esquerdoCanto superior direito).
O quarto parâmetro empregado diz respeito ao número máximo de vizinhos com a mesma distância de uma dada tarefa.
Dado um MPSoC com dimensões x e y, o número máximo de vizinhos pode ser obtido a partir de a Equação 4.23.
O resultado desta equação trata- se de um valor aproximado, onde o erro é de dois vizinhos a mais ou a menos.
Contudo, no caso onde x $= y, o valor resultante expressa o valor exato.
O método mais simples implementado para o mapeamento de tarefas é apresentado no Algoritmo 4.2.
Para realizar o mapeamento de acordo com o método First Free, é necessário percorrer os elementos de processamento, e tão logo um recurso livre e compatível (De o mesmo tipo da tarefa) seja encontrado, ele deve ser retornado.
Considerando o Algoritmo 4.2, pode- se observar que o laço Enquanto da linha 4 é, no pior caso, executado para todos os PEs do MPSoC.
Generalizando para um MPSoC com dimensões idênticas (X $= y), então x2 iterações serão realizadas conforme representado abaixo.
Tal fato confere complexidade quadrática O (x2) ao algoritmo FF.
Enquanto (PE NumeroDePEs) Faça A segunda estratégia para mapeamento empregada como referência é apresentada que gera uma lista com todos vizinhos da tarefa mestre que estão numa mesma distância (mesmo número de hops).
O teste para encontrar um mapeamento possível, nesse caso o primeiro vizinho mais próximo, é idêntico ao FF.
Entretanto, a lista de vizinhos, gerada a cada bloco Para, permite o andamento circular conforme a Figura 4.4.
Em o Algoritmo 4.3, o bloco Enquanto (na linha 4) pode ser executado até o número máximo de hops (Equação 4.22), enquanto o bloco Para aninhado (na linha 10) pode ser executado até o número máximo de vizinhos possíveis (Equação 4.23).
Assim o número máximo de iterações do algoritmo NN pode ser obtido através do produto entre estes dois parâmetros, como apresentado abaixo.
Generalizando para o caso de um MPSoC com dimensões iguais, NN apresenta complexidade O (x2).
Para (PE na ListaDeVizinhos) NumeroHOPs $= NumeroHOPs+ 1 A primeira heurística congestion-- aware aqui proposta, Minimum Maximum Channel Load tem sua descrição apresentada no Algoritmo 4.4.
Como pode ser visto, para cada possível mapeamento a função CalculaCaminhoDeComunicação retorna o caminho entre as tarefas envolvidas na comunicação.
Em seguida, somente os canais que fazem parte desse caminho são atualizados através da função AtualizaCanal (C, T).
Esta considera as taxas de comunicação passadas como parâmetro.
Seguindo, a maior ocupação de entre todos os canais é obtida.
O último bloco SE seleciona o mapeamento com mínimo máximo.
Em o Algoritmo 4.4, o bloco Enquanto (na linha 5) pode ser executado para todos os elementos de processamento, de acordo com a Equação 4.20.
Enquanto isso, o bloco aninhado é executado para todos os canais do MPSoC de acordo com a Equação 4.21.
O número máximo de iterações realizadas por o algoritmo MMCL pode ser obtido através do produto entre estes dois parâmetros, como apresentado a seguir.
Adicionalmente, generalizando para o caso onde o MPSoC possui ambas as dimensões iguais (X $= y), o algoritmo MMCL apresenta complexidade O (x4).
Ocupacão Como pode ser notado, os Algoritmos 4.4 e 4.5 são bastante semelhantes.
Em a heurística Minimum Average Channel Load, ao invés de considerar o máximo na ocupação dos canais, considera- se a média.
Por isso, MACL (Algoritmo 4.5) acumula a ocupação de todos os canais da NoC para cada possível mapeamento, e em seguida calcula a media (na linha 19).
Em o último bloco SE, o mapeamento que apresentou menor média é selecionado.
Assim como no caso de MMCL, o algoritmo proposto para a heurística MACL também apresenta complexidade O (x4), visto que ambos apresentam os mesmos blocos aninhados, como os mesmo números de iterações para o pior caso.
Ocupacão MEDIAtmp $= Ocupacao/ NumeroDeCanais O Algoritmo 4.6 representa a heurística Path Load.
Em o bloco Para da linha 14 pode- se notar que apenas os canais que compõem o caminho de comunicação são considerados.
Para cada um de eles, o mapeamento é emulado através da função AtualizaCanal (C, T), e a ocupação resultante é acumulada na linha 16 do algoritmo.
O mapeamento selecionado será aquele que apresentar o menor somatório da ocupação dos canais, conforme o último bloco SE.
Em a linha 5, o bloco Enquanto pode ser executado, no pior caso, para todos os elementos de processamento do MPSoC.
O bloco Para aninhado, por sua vez, será executado no pior caso para o maior caminho de comunicação possível.
Esse é dado por a Equação 4.22, que indica a distância máxima entre duas tarefas num MPSoC malha, de acordo com o algoritmo de roteamento xy.
Sendo assim, o número máximo de iterações realizadas por PL pode ser obtido como apresentado abaixo.
Veja que o algoritmo PL apresenta uma complexidade O (x3), intermediária àquelas apresentadas por os algoritmos NN e MACL/ MMCL, respectivamente O (x2) e O (x4).
Enquanto (PE NumeroDePEs) Faça Ocupacão $= 0 CP $= AtualizaCanal (Canal, Taxa) Ocupacão $= Ocupacão+ Canal.
Ocupacão O Algoritmo 4.7 descreve a heurística Best Neighbor.
Em esse caso, conforme a linha 9, o somatório da ocupação dos canais do caminho de comunicação é computado apenas vez que uma nova iteração faz- se necessária.
Assim como em NN, é a lista de vizinhos que permite o andamento circular na procura de uma posição para a tarefa.
Em a linha 5 do algoritmo, o bloco Enquanto pode ser executado no pior caso para todas as distâncias possíveis, dada por a Equação 4.21.
O bloco Para é executado para a lista de vizinhos cujo valor máximo é representado por a Equação 4.23.
O bloco da linha 18 é executado apenas uma única vez, e por isso é desconsiderado no cálcu- lo do número de iterações máximo a serem realizadas por BN.
Veja abaixo que BN e NN apresentam a mesma complexidade O (x2).
Ocupacão $= 0 CP $= AtualizaCanal (Canal, Taxa) Ocupacão $= Ocupacão+ Canal.
Ocupacão PEAlvo $= PE SE Então Retorna (PEAlvo) NumeroHOPs $= NumeroHOPs+ 1 A Tabela 4.1 apresenta um quadro comparativo entre os algoritmos de mapeamento aqui propostos e implementados.
Todos eles são empregados para o mapeamento individual das tarefas de acordo com uma visão local da aplicação, que inclui apenas a informação sobre a comunicação entre as tarefas solicitada e solicitante.
Com relação a a NoC, as heurísticas MACL e MMCL valem- se da visão global da ocupação de todos os canais, enquanto PL e BN atém- se apenas ao caminho de comunicação refletindo uma visão local, portanto.
No caso de a visão sobre os PEs, de entre os algoritmos congestion-- aware, apenas BN pode não avaliar todos os possíveis mapeamentos (Visão parcial), a exemplo do que deve acontecer quando os algoritmos de referência NN e FF são utilizados.
Algoritmo simples, que emprega apenas testes e nenhuma função custo.
X e Y são as dimensões do MPSoC.
Em o cálculo das complexidades assume- se x $= y.
Quando existem muitas alternativas de mapeamento o tempo de procura é maior para as heurísticas MACL, MMCL e PL.
No caso de NN, FF e BN o tempo de procura está mais relacionado com a distância do recurso livre.
Em o caso em que o método FF é empregado, quanto mais a direita e acima estiver situado o primeiro recurso livre, maior será o tempo de procura, independentemente de quantos recursos estão livres.
No caso de NN e BN, maior será o tempo de procura quando maior for o número de hops de distância entre o recurso livre e a posição da tarefa solicitante.
Vistos os detalhes sobre a arquitetura alvo, bem como os algoritmos de mapeamento propostos, pode- se prosseguir aos Capítulos 5 e 6.
Estes apresentam cada um dos experimentos realizados, além de discutir os resultados obtidos a partir de as simulações.
Os experimentos realizados são divididos em duas partes.
A primeira de elas, apresentado no presente Capítulo, visa a comparação entre as heurísticas de mapeamento congestion-- aware propostas (MMCL, MACL, PL e BN) frente a os algoritmos de referência FF e BN.
Ao contrário de os propostos, os algoritmos First Free e Nearest Neighbor não possuem função custo de congestionamento para a definição do mapeamento de uma dada tarefa.
Estes foram implementados justamente para seu emprego como referência nas avaliações.
A segunda parte de experimentos é apresentada no próximo Capítulo.
Ela visa a comparação entre as heurísticas propostas, com mapeamento tarefa a tarefa, e heurísticas globais, onde todas as tarefas de uma dada aplicação são mapeadas simultaneamente.
Antes da discussão dos experimentos, faz- se necessária a apresentação da arquitetura alvo, válida para as duas partes de experimentos.
Ela discute ambas as modelagens, da NoC descrita em VHDL, e dos elementos de processamento descritos em SystemC.
As co-simulações realizadas são baseadas no simulador ModelSim SE 6.
4 da Mentor Graphics Corporation.
O relógio de operação adotado opera segundo uma freqüência fixada em 100 MHz.
O MPSoC adotado possui topologia malha conforme a infra-estrutura de comunicação empregada.
A NoC Hermes foi escolhida principalmente devido a disponibilidade de ferramentas para sua geração, síntese, geração de tráfego, simulação e avaliação.
De entre as funcionalidades da ferramenta Atlas, principalmente a geração (Maia) foi utilizada aqui.
Através de ela foi possível obter a descrição VHDL da NoC em nível RTL.
De entre os parâmetros adotados para a NoC encontram- se:
Chaveamento de pacotes wormhole;
Buffers de entrada nos roteadores;
Controle de fluxo handshake;
E roteamento segundo o algoritmo xy.
O algoritmo de roteamento guia as heurísticas de mapeamento propostas, as quais consideram a ocupação dos canais que serão utilizados (Definidos com base no algoritmo de roteamento) por a tarefa requisitada, para cada possível mapeamento.
O controle de fluxo define quantos ciclos de relógio são necessários para transmitir um dado flit entre dois roteadores da NoC.
O protocolo de handshake foi adotado em virtude de a sua simplicidade.
Contudo, ele suporta apenas a transmissão de um flit a cada dois ciclos de relógio, limitando a largura de banda máxima disponível a 50% da capacidade real de um dado canal.
O comportamento do MP pode ser representado por as três etapas seguintes:
Etapa 1.
Captura do Pacote:
Em a primeira etapa, quando um dado pacote é recebido por a UDP, seus atributos são capturados.
Os pacotes recebidos podem ser do tipo ou RELEASE.
De entre os principais atributos dos pacotes constam o identi-ficador do PE, o tipo do pacote e os identificadores das tarefas envolvidas na comunicação (Mestre e escrava).
Etapa 2.
Decodificação do Pacote e Escalonamento: Em a segunda etapa, ainda na UDP, o pacote é decodificado.
Se tratando de um pacote REQUEST, o identificador da tarefa requisitada deve ser então inserido na fila de escalonamento adequada (i.
Etapa 3.
Mapeamento da Tarefa:
A terceira etapa dedica- se ao mapeamento da ta refa.
Para isso, verifica- se a existência de tarefas em cada uma das filas.
De acordo com a Figura 5.3, se a tarefa lida da fila encontrar- se já mapeada no sistema, apenas os pacotes NOTIFYs são enviados.
Com isso, os atrasos de mapeamento e configuração são eliminados.
Caso contrário, deve- se verificar se existem recursos compatíveis livres.
Em caso negativo, a tarefa continua na fila de escalonamento.
De outra forma, a heurística de mapeamento é utilizada para selecionar um dos recursos livres para alocar a tarefa.
Em a seqüência, a tarefa é configurada nesse recurso.
Após sua configuração, ela deve ser inicializada.
Início Leitura da Fila de Escalonamento Mapeada? Sim Envia pacotes NOTIFYs e Retira Tarefa da Fila Não Continua na Fila de Escalonamento Não Recursos Livres?
A PEthread implementa o comportamento genérico de uma dada tarefa, de acordo com o protocolo de comunicação definido na Seção 3.4.
A fim de permitir um comportamento especifico para cada uma das tarefas a executar no MPSoC, a PEthread é parametrizada por um dado arquivo de configuração.
Esse arquivo informa detalhes sobre cada tarefa, incluindo:
Tempo de execução;
Com quais outras tarefas ela se comunica;
Quais os volumes de comunicação, e ainda as respectivas taxas.
Assim, de acordo com a tarefa (Arquivo de configuração) atribuída a um dado PE (PEthread), diferentes tráfegos (Taxas de injeção e destinos) serão gerados.
Um período de amostragem -- SP foi definido para a geração de pacotes na PEthread.
A cada período de amostragem, um determinado número de flits é gerado, de forma a atender as taxas e volumes contidos no arquivo de configuração.
Por exemplo, assumindo um período de amostragem SP $= 100 ciclos de relógio.
Se a tarefa ta comunica- se com as tarefas tb e tc, segundo taxas de envio 7% e 25%, respectivamente, então a geração de tráfego segue o diagrama de tempo da Figura 5.4.
Deve- se notar que a geração dos flits a uma taxa tx consome 2 tx ciclos de relógio, devido a a utilização do protocolo handshake.
SPm+ 1 SPm+ 2 SPn+ 1 SPn+ 2 SP $= 100 ciclos 86 ciclos Início da comunicação entre ta e tb.
Início da comunicação entre ta e tc.
Término da comunicação entre ta e tb.
Em o inicio do diagrama da Figura 5.4, acontece apenas a comunicação entre ta e tb.
Em seguida, entre SPm e SPn, a cada período:
Um pacote com 7 flits é enviado para tb;
Um pacote com 25 flits é enviado para tc;
E no tempo restante o PE recebe pacotes de entrada ou processa os dados recebidos.
Como cada flit requer dois ciclos de relógio para ser transmitido, o período &quot;ocioso «será, nesse caso, de 36 ciclos de relógio.
O tempo de processamento da tarefa está implícito, durante o tempo em que a tarefa não se encontra comunicando.
Esse procedimento se repete até que o volume de dados seja completamente gerado e transmitido aos respectivos destinos.
Quando ta termina os dados a serem enviados para tb (em SPn), são produzidos apenas os 25 flits para tc a cada SP, com o tempo ocioso de 50 ciclos de relógio.
Em o exemplo da Figura 5.4, o período de amostragem de 100 ciclos de relógio foi adotado para facilitar a conversão das taxas em número de flits.
Entretanto, nos experi-mentos foram utilizados períodos na ordem de 10.000 ciclos de relógio, em o qual uma taxa de envio de 24% implica na transmissão de pacotes de 2400 flits a cada SP.
A estratégia empregada para a geração de pacotes nas PEthread segue uma distribuição temporal Pareto On-Off.
De entre as características importantes a serem discutidas sobre o cenário da simulação constam a modelagem do MPSoC, bem como as aplicações utilizadas.
O MPSoC heterogêneo modelado nesse primeiro grupo de experimentos possui 8 colunas e 8 linhas de elementos de processamento (Figura 5.5).
Em as avaliações, o emprego de MPSoCs menores pode comprometer os resultados visto que existem poucas possibilidades de mapeamento.
Assim, provavelmente os resultados serão muito próximos, independentemente do algoritmo empregado para definir o mapeamento das tarefas.
A disposição dos PEs da Figura 5.5 busca distribuir uniformemente os PEs sobre a área do MPSoCs, de acordo com seu tipo.
Ao todo, são 64 PEs, sendo 16 dedicados à execução de tarefas de hardware, e 47 PEs que suportam a execução de tarefas de software.
Um dos PEs é reservado para as funcionalidades do processador gerente.
De entre os 47 PEs de software, alguns são reservados ao mapeamento de tarefas iniciais das aplicações.
A quantia desses recursos foi variada entre 9 e 15, indicando um paralelismo na execução de até 15 aplicações simultâneas.
Três cenários de aplicações sintéticas são considerados nesse primeiro grupo de experimentos.
De entre eles constam as simulações das seguintes aplicações:
Pipeline: Composto por 20 aplicações idênticas com grafo cuja topo-Cenário A. Rms foram variadas entre 5% e 30% da largura de banda disponível nas seis no sentido da aresta de acordo com um volume de 600 pacotes transmitidos a uma taxa de Rms%;
E uma comunicação no sentido oposto como volume de 10 pacotes transmitidos a uma taxa de 5% da largura de banda.
Árvore: Composto por 20 aplicações idênticas cujos grafos apresen-Cenário B. Geral:
Composto por 20 aplicações diferentes, com grafos de topolo Cenário C. TGFF 1.
Em esses experimentos, foram utilizados grafos compostos por 5 a 10 vértices, e com taxas de injeção escolhidas aleatoriamente entre 5 e 30% da largura de banda disponível.
Cada um dos grafos gerados pode ser visto na Figura 5.8.
Task Graph For Free ou simplesmente TGFF é uma ferramenta que permite a geração automática de um conjunto de grafos.
Para isso ela baseia- se num conjunto de parâmetros, incluindo os números mínimo e máximo de vértices, e o intervalo para variação dos pesos nas arestas.
O TGFF foi empregado em alguns dos trabalhos sobre mapeamento de tarefas revisados no Capítulo 2, de entre eles.
Em esta primeira etapa de experimentos, os parâmetros de desempenho empregados incluem:
Ocupação dos canais da NoC;
Latência dos pacotes;
Nível de congestionamento na NoC;
E tempo de execução total do sistema.
A carga dos canais é o primeiro parâmetro de desempenho investigado.
Ela representa o estado de ocupação da NoC.
Em os experimentos, toda informação sobre a ocupação dos canais foi obtida através de monitores distribuídos, inseridos em cada uma das portas de saída dos roteadores da NoC.
Em as simulações, ambos os esquemas de monitores (Os gráficos da Figura 5.9 apresentam a ocupação dos canais da NoC ao longo de o tempo de simulação, para cada um dos algoritmos de mapeamento implementado.
Os dois valores plotados representam a média (linha mais escura) e o pico de ocupação dos canais (possíveis congestionamentos).
A cada período de amostragem uma amostra de ocupação é plotada.
Ela é medida como uma porcentagem da largura de banda disponível.
O andamento do tempo de simulação se dá em milhões de ciclos de relógio (MCCs).
A Figura 5.9 diz respeito às simulações do Cenário C, composto por grafos de aplicações gerados a partir de a ferramenta TGFF.
O algoritmo FF apresentou a pior solução em termos de ocupação dos canais.
Enquanto isso, os algoritmos BN, NN e PL apresentam as melhores soluções, as quais resultam numa baixa media de ocupação, e poucas saturações de canais, ou seja, poucos picos de ocupação maiores que 50% da largura de banda disponível.
A complexidade dos algoritmos MMCL e MACL penaliza seus tempos de execução, o que pode ser observado nos gráficos destas heurísticas que gastam maior tempo para executar todas as 20 aplicações.
A avaliação das heurísticas apenas baseada nos gráficos da Figura 5.9 não permite precisão, visto que ela depende dos critérios adotados por o observador, e ainda corresponde às medições obtidas de um único cenário.
Uma avaliação mais completa é apresentada no gráfico da Figura 6.1, que considera todos os cenários simulados.
Em os Cenários A e B deste gráfico é possível verificar que a ocupação média dos canais da NoC cresce à me-Média de Ocupação do Canais(% largura de banda disponível) dida que a taxa de injeção aumenta.
Além disso, com relação a o resultado apresentado quando o algoritmo FF é empregado, todos os demais algoritmos implementados reduzem a ocupação média.
Conforme a média geral de todas as simulações, MMCL e MACL reduzem a ocupação dos canais em aproximadamente 14% (em comparação a FF).
Esse resultado é bom, mas pior que o obtido quando NN, um algoritmo que não considera a ocupação dos canais é usado.
Enquanto isso, Best Neighbor apresenta resultados semelhantes aos obtidos por Nearest Neighbor, com ganhos na ordem de 29% comparados a First Free.
A heurística PL, por sua vez, tem os melhores resultados nas simulações.
De acordo com a média geral, PL apresenta um ganho de 31% na ocupação dos canais quando comparada a FF.
Seu resultado é em média 2% melhor que aquele obtido por NN.
Avali- ando apenas o Cenário C, quando Path Load é empregado, pode- se observar um ganho de 48% relativo à FF, e até 6,5% relativo à NN.
Além de a média, o desvio padrão na ocupação também é importante.
Ele indica a distribuição do tráfego na NoC.
Em esse caso, valores baixos representam uma distribuição homogênea de tráfego, enquanto valores altos sugerem que alguns canais possuem cargas altas, enquanto outros não estão sendo usados.
Para os três cenários simulados (Figura relação ao algoritmo FF.
Novamente, NN, PL e BN foram os algoritmos com melhores resultados.
Ainda assim, PL apresentou um menor desvio padrão na ocupação dos canais, em média 22% melhor que o apresentado por FF.
Comparado ao NN, PL apresenta uma ganho de 2,5%.
Em os experimentos do Cenário C, o ganho de Path Load atinge redução de Desvio Padrão de Ocupação(% largura de banda disponível) 28% em relação a o resultado apresentado por First Free.
O segundo parâmetro de desempenho empregado na avaliação das heurísticas é a latência dos pacotes transmitidos durante a simulação.
A latência de um dado pacote é uma função da distância entre os recursos em os quais as tarefas comunicantes estão mapeadas e, além disso, depende da ocupação dos canais por os quais o pacote é transmitido.
Quando muitos pacotes tentam compartilhar os mesmo canais da NoC, há tendência de que congestionamentos ocorram, aumentando a latência.
Em o presente trabalho, as medições de latência são realizadas durante a simulação.
Ela é dada em número de ciclos de relógio contados desde o envio do pacote em sua origem, até o seu recebimento no destino.
Para isso, no envio do pacote, o instante de envio (Timestamp) é inserido numa dada posição do pacote.
Quando o pacote chega ao seu destino, este valor é então capturado e subtraído do instante atual obtido a partir de uma variável global que mantém informação do número de ciclos de relógios simulados.
A Tabela 5.1 apresenta os valores capturados para a latência média dos pacotes transmitidos em cada uma das simulações.
Em a maioria de elas, Path Load apresenta o melhor resultado, embora muito próximo de aqueles apresentados por os algoritmos NN e BN.
A última linha da Tabela apresenta o ganho de cada uma das heurísticas compara ao algoritmo FF, calculado através da média de todos os experimentos.
Os algoritmos MMCL e MACL apresentam redução de aproximadamente 6% e 8%, respectivamente no tempo para transmitir os pacotes.
Enquanto isso, os demais algoritmos obtêm resultados mais significativos.
NN, BN permitem redução nas latências na ordem de 15%, sendo que PL mais uma vez apresenta os melhores resultados.
Taxas Ganho relativo ao FF (Gene) Ganho Global relativo ao FF Cenários A. 20 aplicações com grafo Pipeline Ganho relativo ao FF (PIPE) B. 20 aplicações com grafo Árvore Ganho relativo ao FF (TREE) 20 Aplicações do TGFF Os resultados apresentados são relevantes, pois a latência consiste num parâmetro que exerce grande influência sobre o desempenho de sistemas com requisitos de qualidade de serviço (QoS).
Congestionamentos em sistemas dessa natureza podem acarretar na perda de pacotes, inaceitável em aplicações com deadlines estritos (De tempo real).
Tratando- se de heurísticas ditas congestion-- aware, faz- se necessário avaliar o nível de congestionamento resultante no sistema.
Os experimentos anteriores demonstraram reduções significativas na ocupação dos canais, principalmente quando as heurísticas PL e BN são empregadas, representando um ganho aproximado de 31% relativo ao algoritmo FF.
Essa redução da ocupação acabou por se refletir sobre a latência dos pacotes, que também apresentou ganhos significativos, na ordem de 15%, como pode ser observado.
Em o presente trabalho, duas métricas relativas ao nível de congestionamento no sistema são empregadas.
A primeira de elas mede o número de congestionamentos detectados ao longo de a simulação, ou seja, o número de canais saturados.
O emprego dos monitores distribuídos foi imprescindível para esse tipo de medição.
Os monitores detectam quando um determinado flit não pode ser enviado, identificando uma situação de congestionamento.
Em esse caso, o uso dos monitores ganhou um significado similar ao definido por Marescaux, van den Brand e Ciordas, em os quais essas estruturas tem seu emprego fundamentado na descoberta de situações de congestionamento para posterior adequação de tráfego.
O gráfico da Figura 5.12 apresenta o número total de congestionamentos detectados durante cada uma das simulações.
Conforme o gráfico, pode- se notar que houve uma redução significativa no número de congestionamentos.
Considerando a média de todos os experimentos, quando Minimum Average Channel Load e Minimum Maximum Channel Load são empregados, pode- se obter 38% e 45% de redução no número de congestionamentos apresentados por FF.
NN e BN, por sua vez, permitem uma redução de aproximadamente 70%, enquanto PL reduz em 77% os congestionamentos.
Analisando apenas o Cenário C, a heurística PL permite a obtenção de resultados ainda melhores, com um ganho de 89% no número de congestionamentos comparado ao algoritmo FF, resultando num ganho de até 40% relativo ao NN.
O segundo parâmetro de desempenho relativo ao nível de congestionamento mede o tempo perdido durante os congestionamentos.
Esta nova métrica visa avaliar o tempo perdido, dada a detecção de uma situação de congestionamento.
Em suma, enquanto o primeiro parâmetro apresentado responsabiliza- se por identificar quando ocorrem congestionamentos, esse segundo parâmetro conta quando tempo cada flit teve de esperar até poder ser transmitido através da NoC.
Em a Figura 5.13, o tempo perdido é quantificado em número de ciclos de relógio de operação, contados desde o instante em que um flit foi impedido de transmissão até o instante em que ele foi efetivamente inserido na NoC.
Com exceção do algoritmo FF, todos os demais apresentaram um aumento nos congestionamentos à medida que a taxa de injeção cresce.
Tomando a média de todos os 3 cenários foi possível alcançar uma redução de até 50% quando as heurísticas MMCL e MACL são empregadas, comparando ao algoritmo de referência First Free.
No caso de NN e BN o ganho relativo é de até 82%.
A heurística Path Load apresenta um ganho relativo ao FF na ordem de 87%, e ainda com 30% de ganho comparado ao algoritmo Nearest Neighbor.
Considerando apena os resultados do Cenário C, onde as aplicações são bastante diversificadas quanto a a topologia, volumes e taxas de transmissão, o algoritmo congestion-- aware Path Load permite reduzir o número de congestionamentos em 92%.
Os resultados de latência e congestionamentos são significativos.
À medida que a ocupação dos canais da NoC foi reduzida, os pacotes podem ter menor latência de transmissão, e ainda os congestionamentos na rede podem ser reduzidos em até 90% como visto, cumprindo com o objetivo das heurísticas congestion-- aware.
Em a presente Seção, discute- se o tempo total de execução de cada um dos experimentos.
O objetivo aqui consiste em medir o impacto do emprego da heurística de mapeamento no tempo total de execução do sistema.
Para essa avaliação, o volume de dados transmitidos nas simulações foi multiplicado 10 vezes.
Em os experimentos anteriores, houve uma grande penalidade no tempo de execução devido a a complexidade das heurísticas de mapeamento.
Contudo, conforme apresentado na Tabela 5.2, pode- se perceber que à me- dida que o volume de dados aumenta, o atraso inserido por as heurísticas pode ser amortizado.
Além disso, à medida que a taxa é aumentada, o tempo de execução total do experimento é reduzido.
Isso acontece porque o volume de dados é conservado nos experimentos de cada cenário, apenas a taxa é alterada.
Como os tempos de computação das heurísticas MACL e MMCL são grandes, nos experimentos, o tempo total de execução apresentados quando essas heurísticas são empregadas foi ainda maior que o apresentado por FF.
Contudo, o tempo de execução sofre em média uma penalidade de 0,3% para MMCL, e de 0,08% para o emprego de MACL.
Taxas Cenários A. 20 aplicações com grafo Pipeline B. 20 aplicações com grafo Árvore 20 Aplicações do TGFF Ganho Global relativo ao FF No caso de os demais algoritmos, foi possível obter uma redução no tempo total de execução.
Em a média de todas as simulações, as heurísticas PL e BN apresentam uma redução de aproximadamente 1% no tempo de execução, enquanto NN permite 1,7% de ganho comparado ao First Free.
Em o Cenário C, o desempenho da heurística BN é melhor que as demais.
Enquanto PL e NN apresentam respectivamente tempos de execução 2,4% e 3,5% menores que aquele apresentado por FF, Best Neighbor resulta numa redução de 4,1%.
A expectativa de que a redução dos congestionamentos implicasse na redução do tempo total de execução do sistema não se confirmou conforme esperado, visto que redução na ordem de 90% nos congestionamento, ainda assim permite que o tempo de execução seja penalizado.
Em as primeiras simulações, a penalidade no tempo execução é em média de 8,8% para o algoritmo PL, e de 2,5% quando BN é empregado.
Quando o volume de dados transmitidos nas simulações foi aumentado em 10 vezes, para o caso de BN o tempo de execução apresentado foi em 0,8% melhor que observado para FF.
A heurística PL, por sua vez, apresentou um ganho de 1,13%, também comparado aquele obtido por FF.
Assim, pode- se estimar que para volumes maiores a penalidade em termos de tempo de execução, e o tempo para mapear as tarefas será amortizada, de forma que a redução nos congestionamentos permita reduções significativas relativas ao tempo de execução.
O tempo de execução das heurísticas foi medido durante o processamento dos algoritmos através da execução da função 10 mil vezes consecutivas.
Isso foi necessário porque as operações do sistema disponíveis para medição de tempo não fornecem a precisão necessária.
Assim, executando por várias vezes o tempo médio de execução pode ser calculado com a precisão desejada.
O atraso para configuração das tarefas foi baseado nos trabalhos de Möller e outros.
Em esses trabalhos, os Autores investigam o problema de configuração dinâmica e parcial de módulos de hardware em sistemas que adotam NoCs como meio de comunicação.
Esta etapa, que contou com a colaboração do Autor da Tese, foi essencial para o passo seguinte de modelagem do MPSoC.
A Tabela 5.4 apresenta um resumo dos resultados obtidos normalizados em função de o algoritmo FF, considerando a média da simulação para os três cenários implementados.
Pode- se notar que a heurística PL apresenta os melhores resultados na maioria dos os parâmetros avaliados, com exceção do tempo de execução total, onde NN se destaca.
No entanto, PL apresenta um tempo de execução muito próximo de aquele apresentado por NN, visto que seu tempo médio para mapeamento de tarefa é de 500 ciclos de relógio, um tempo 33 vezes maior que o necessário por o algoritmo NN.
Os resultados apresentados apontam para uma redução significativa de quase 90% nos congestionamentos, de 31% na ocupação dos canais da NoC, e de 15% na latência dos pacotes.
Parâmetros de Desempenho Ocupação dos Canais (Média) Ocupação dos Canais (Desvio Padrão) Latência dos Pacotes (Média) Latência dos Pacotes (Desvio Padrão) Congestionamentos (Canais saturados) Congestionamentos (Tempo perdido) Tempo Total de Execução Tempo Total de Execução Além de o tempo de execução das heurísticas, outro fator que pode ter influenciado nos resultados de tempo total de execução diz respeito à modelagem adotada para as aplicações.
Vale aqui ressaltar que as operações de escrita e leitura das tarefas foram ambas implementadas como não-bloqueantes.
Se o recebimento das mensagens é não-bloqueante, então o efeito de um congestionamento sobre o tempo de execução das tarefas é menor que no caso onde a tarefa fica bloqueada esperando para enviar um dado pacote.
O mesmo acontece no caso de um recebimento de um pacote.
Infelizmente, essa possível falha foi detectada apenas ao final do trabalho.
Sendo assim, o emprego de comunicações bloqueantes é uma sugestão de trabalho futuro para a obtenção de melhores resultados.
Além de os experimentos apresentados anteriormente, outras variações foram realizadas.
A primeira de elas aumenta o número de recursos dedicados ao mapeamento de tarefas iniciais das aplicações de 9 para 15 PEs iniciais.
Conforme os resultados obtidos, o desempenho de todas as heurísticas piorou aproximadamente 40%.
Em termos de ocupação média dos canais, os algoritmos NN, PL e BN apresentam ganhos com relação a FF de 15%, 14% e 16% respectivamente.
A diferença entre os novos valores e os atuais pode ser obtida através da comparação com os valores relacionados na Tabela 5.4.
O ganho em termos de o desvio padrão na ocupação é de aproximadamente 9%, enquanto que a latência dos pacotes apresenta em média um ganho de 10% comparado ao FF.
O nível de congestionamento também sofreu impacto semelhante, com redução de desempenho de 80% para 50% no número de canais saturados, e de 70% para 60% em termos de tempo perdido em congestionamentos.
No caso de as simulações com 15 aplicações simultâneas executando sobre o MPSoC, os ganhos relativos a todos os parâmetros investigados são menores.
Isso ocorre porque quanto mais aplicações compartilham o MPSoC, maior a tendência de que tais aplicações fiquem espalhadas sobre sua superfície.
Assim sendo, independentemente do algoritmo empregado no mapeamento, se as possibilidades de mapeamento são reduzidas, então provavelmente os resultados obtidos serão similares.
Uma alternativa para melhorar um dado mapeamento das tarefas em tempo de execução consiste no emprego da estratégia de migração das tarefas.
Em um determinado momento o mapeamento de uma dada tarefa não pode ser otimizado, por exemplo, porque só resta um recurso livre, e este se encontra distante da posição onde a tarefa mestre está alocada.
Se algum tempo depois, um recurso mais próximo for liberado, a técnica de migração pode ser empregada para (re) mapear a tarefa que estava distante, neste novo recurso (mais próximo).
Uma segunda variação dos experimentos investiga o emprego das informações obtidas por os monitores distribuídos na decisão de mapeamento.
A expectativa de obter melhor desempenho não se confirmou.
Em os experimentos, os resultados alternam valores melhores e piores que os obtidos nas simulações baseadas no esquema de monitor centralizado.
Além disso, as variações entre os dois resultados foram mínimas.
Uma causa identificada para tal comportamento consiste na modelagem das aplicações.
Cada uma de elas gera o tráfego a partir de os parâmetros de volume e taxa passados nos arquivos de configuração (modelagem RTL na Seção 3.7.3).
Esse tráfego pode ser dito &quot;bem comportado «porque representa exatamente as taxas e volumes passados nos arquivos.
Assim, a ocupação medida nos monitores distribuídos é muito próxima daquela que foi passada nos pacotes REQUEST, a partir de os quais o monitor centralizado estima a ocupação dos canais.
Um possível experimento que pode resultar numa melhor avaliação do uso dos monitores distribuídos consiste em inserir constantes de erro nas taxas informadas por as aplicações.
Assim, os valores informados não seriam exatos e as medições dos monitores distribuídos seriam mais precisas que aquelas estimadas por o monitor centralizado.
Esse experimento, no entanto, não foi realizado devido a o tempo restrito para defesa da tese.
Assim sendo, sua realização torna- se uma sugestão para trabalho futuro.
A segunda parte dos experimentos realizados é discutida no presente Capítulo.
Seu objetivo consiste em avaliar o desempenho dos algoritmos aqui implementados frente a a estratégia global.
Em o presente trabalho as tarefas são mapeadas uma por vez, refletindo uma abordagem gulosa, enquanto no mapeamento global todas as tarefas de uma dada aplicação são mapeadas de uma única vez.
Enquanto algoritmos gulosos consideram apenas informação local sobre a comunicação entre as tarefas escrava (solicitada) e mestre (solicitante), a abordagem global vale- se de informação relativa a todas as comunicações da aplicação, incluindo a topologia do grafo que a representa.
De essa forma, o mapeamento global deve apresentar melhor desempenho em termos de ocupação dos canais, latência dos pacotes e congestionamentos na rede.
Por outro lado, a abordagem gulosa deve consumir menor tempo de execução, tornando- se mais adequada para cenários dinâmicos.
Em esse Capítulo, investiga- se quais as penalidades relativas ao emprego da estratégia gulosa.
Para isso, o desempenho das duas heurísticas que apresentaram melhores resultados nos experimentos anteriores (PL e BN) é comparado a outros dois algoritmos implementados por Marcon e outros em.
Em este trabalho, o mapeamento das tarefas é feito de acordo com o modelo de mapeamento global discutido acima.
Conforme a revisão do Capítulo 2, os Autores de pesquisam o mapeamento estático de tarefas numa NoC.
Trata- se de um trabalho amplamente divulgado conforme as publicações realizadas.
Sua principal contribuição consiste na modelagem do consumo de energia da NoC relativo ao volume de comunicação da aplicação, e ao mapeamento definido para suas tarefas.
Além disso, a disponibilidade da ferramenta gráfica CAFES para o mapeamento de tarefas contribuiu para a escolha do trabalho como base das comparações.
O mapeamento realizado nas duas pesquisas visa diferentes parâmetros de desempenho.
Enquanto Marcon e outros investigam métodos de mapeamento a fim de reduzir o consumo de energia do sistema como um todo, aqui os congestionamentos no sis-tema são tidos como alvo.
Como o volume de dados gerados por as aplicações não são determinados por o MPSoC, a redução do volume transmitido deve implicar a redução da distância (Hops) entre as tarefas comunicantes.
Em ambos os trabalhos, portanto, a estratégia adotada para reduzir tanto a energia consumida na comunicação quanto os congestionamentos na NoC passa por a redução da distância entre as tarefas comunicantes.
Para comparar as estratégias de mapeamento é necessário portar o mapeamento realizado através do CAFES, para a plataforma de simulação aqui proposta.
A estratégia adotada no presente trabalho baseia- se num arquivo de mapeamento que informa ao processador gerente, durante a simulação, o mapeamento de cada uma das tarefas obtido no CAFES.
Os parâmetros de desempenho empregados nesse grupo de experimentos incluem além de aqueles utilizados nos experimentos anteriores, a energia total consumida na execução do sistema, obtida através das estimativas realizadas por a ferramenta CAFES.
A arquitetura alvo desse segundo grupo de experimentos é a mesma descrita na avaliação apresentada no Capítulo anterior.
Como dito, dois algoritmos proposto em são utilizados aqui.
O primeiro de eles, baseado no algoritmo Simulated Annealing (SA), utiliza dois laços aninhados.
O laço externo implementa uma técnica de busca global, enquanto o interno realiza o refinamento local.
Este otimiza o mapeamento inicial provido por o laço externo.
Para isso, o laço interno troca o mapeamento de duas tarefas escolhidas aleatoriamente, e computa o valor da energia consumida resultante.
Os melhores valores são anotados.
O laço externo aplica a troca do mapeamento de vários módulos aleatório de uma só vez.
O segundo algoritmo é baseado no método Tabu Search (Ts).
Este também possui dois laços aninhados.
O laço interno procura pares de tarefas cuja troca de posição resulta numa menor energia consumida.
Para isso, uma lista de possíveis trocas é gerada, sem entradas replicadas.
As trocas são selecionadas aleatoriamente da lista, e aquelas que causam uma redução na energia são anotadas.
A partir de essas trocas é criada uma lista denominada lista tabu, a qual é utilizada para atualizar o mapeamento atual.
Ambos os algoritmos Ts e SA baseiam- se num mapeamento inicial (semente), gerado aleatoriamente.
Eles tentam melhorar o resultado (energia consumida) através de trocas aleatórias das posições iniciais das tarefas.
A qualidade da semente deve influenciar na qualidade do resultado obtido, e no tempo necessário para obter a solução.
A condição de parada depende de uma temperatura.
Esta assume inicialmente um valor elevado, e após um número determinado de iterações é gradualmente diminuída.
Assim, a chance de que seja selecionada uma solução num mínimo local é reduzida.
O método termina quando a temperatura estiver próxima de zero e nenhuma solução melhor for encontrada.
Duas restrições são impostas aos experimentos para suportar a comparação com a proposta de Marcon.
Primeiramente, o MPSoC necessita ser homogêneo, ou seja, cada tarefa pode ser mapeada em qualquer elemento de processamento do sistema.
Em o trabalho de Marcon foi investigado o mapeamento de núcleos IPs numa NoC onde, cada um dos recursos representa um tile, o qual suporta o mapeamento de qualquer IP.
Além disso, o número de IPs deve ser no máximo igual ao número de recursos disponíveis para mapeamento, visto que a natureza estática da solução de Marcon permite um mapeamento único das tarefas.
Quatro aplicações foram utilizadas como base para a geração dos grafos de aplicação empregados nos experimentos.
Esta estratégia visa aproximar os cenários de simulação a um cenário real, onde as aplicações possuem topologias e também taxas aproximadas as de aplicações reais.
De entre elas constam três aplicações de vídeo:
Decodificadores MPEG-4 e VOP, MWD;
E a Integral de Romberg.
Além de essas, foram usadas nos experimentos outros 4 grafos selecionados do Cenário C.
O MPEG-4 é um padrão utilizado para compressão de dados digitais de áudio e vídeo.
Ele foi definido por o Moving Picture Experts Group (ou simplesmente MPEG), em, de entre outros.
Conforme Murali e De Micheli, o grande volume de dados dessa aplicação pode ultrapassar a largura de banda disponível, tornando necessária a distribuição do tráfego através de diferentes caminhos.
Ao lado de cada grafo das Figuras, uma lista de comunicações é apresentada, onde cada uma das linhas representa uma dada aresta do grafo.
A interpretação das linhas F indica uma comunicação entre as tarefas F e D (Fonte e destino), com volume V e taxa T de transmissão, em ambos os sentidos dados por os índices FD e DF (Fonte para destino e destino para fonte).
Conforme apresentado na Seção 3.2, a qual discute a representação das aplicações, as comunicações podem ocorrer nos dois sentidos.
Em esse caso, a indicação das arestas apenas informa qual a ordem parcial de mapeamento no sistema, em outras palavras, ela informa quem é a tarefa mestre da comunicação.
A segunda aplicação modelada, o decodificador VOP (do inglês, Video Object Plane Decoder ou VOPD) apresenta um alto nível de paralelismo entre suas tarefas.
O decodificador requer alto desempenho e uma grande largura de banda para transmissões de vídeo em alta definição (HD).
O grafo da Figura 6.2 representa a aplicação do decodificar VOP, composta por 13 tarefas.
Esta aplicação foi empregada em vários trabalhos sobre mapeamento de tarefa, incluindo e.
A aplicação denominada Multi--Window Display (ou MWD) tem seu grafo exposto na Figura 6.3.
Ele é composto por 12 vértices (ou tarefas).
As taxas e volumes adotados são apresentados na listagem ao lado de o grafo.
Esta aplicação foi empregada nos estudos de caso dos trabalhos apresentados por Jalabert, Bertozzi e outros.
Contudo, nenhuma descrição da aplicação de suas tarefas foi encontrada nesses trabalhos ou mesmo em outros da literatura revisada.
Romberg é um método baseado em aproximações sucessivas empregado no cálculo da integral de uma dada função.
Conforme o grafo da Figura 6.4, a implementação desta aplicação sugere um fluxo de dados no formato de um triângulo retângulo.
Embora um grafo com 10 tarefas seja adotado, o número de linhas empregadas no cálculo da Integral de Romberg (ou simplesmente RBERG) pode ser variado de acordo com a precisão desejada.
Essa aplicação foi utilizada em.
A modelagem do MPSoC alvo foi a mesma utilizada nos experimentos anteriores.
Contudo, os recursos de software foram substituídos por recursos de hardware já que a estratégia de Marcon suporta apenas modelos onde todos os recursos são da mesma natureza.
Um fator que permite a plena portabilidade dos estudos realizados por Marcon, incluindo sua modelagem de energia consumida consiste na NoC empregada.
Tanto o trabalho aqui proposto, quanto o apresentado por Marcon empregam a NoC Hermes.
Dois cenários de experimentos foram investigados.
São eles:
Cenário D. MPSoC 5x4:
Em este primeiro cenário foi empregado um MPSoC ho-mogêneo com dimensões reduzidas, o qual suporta apenas o mapeamento individual das aplicações estudadas.
Assim, pode- se avaliar os mapeamentos de acordo com a aplicação a ser mapeada, investigando qual o impacto no nível de conectividade das tarefas sobre o mapeamento, e ainda se os algoritmos gulosos apresentam resultados satisfatórios frente àqueles apresentado quando a ferramenta CAFES é usada.
Cenário E. MPSoC 9x9:
Em este cenário foi utilizado um MPSoC grande o sufici-ente para suportar o mapeamento de todos os 8 grafos de aplicações que compõem o experimento.
Assim, espera- se avaliar como se dá o compartilhamento de recursos do MPSoC por várias aplicações, sendo utilizadas as heurísticas gulosas aqui propostas, bem como as apresentadas por Marcon.
Em essa Seção, discute- se os resultados dos experimentos realizados segundo os Cenários D e E. Para a avaliação da ocupação dos canais (Seção 6.3.2), da latência dos pacotes (Seção 6.3.3), do nível de congestionamento (Seção 6.3.4) e do tempo de execução (Seção trabalho, baseado na NoC descrita em VHDL e nos PEs descritos em SystemC.
A o final, na Seção 6.3.7, apresenta- se um sumário dos resultados obtidos, bem como algumas considerações relevantes.
Em os experimentos do Cenário D, o mapeamento das tarefas segundo os algoritmos investigados resulta nas distribuições de tarefas exposta na Figura 6.5, onde Ti faz referência a tarefa i da aplicação.
Em a Figura, cada mapeamento possui um determinado número total de hops, dado por o somatório das distâncias entre cada par de tarefas comunicantes.
Cada distância é calculada conforme a posição das tarefas, baseando- se no algoritmo de roteamento xy.
Por exemplo, para a comunicação entre as tarefas T0 e T1 da aplicação RBERG mapeada segundo o algoritmo Tabu Search, são necessários:
2 hops para a comunicação no sentido T 0-T1 (Leste em x e norte em y);
E=2  hops para a comunicação no sentido oposto (Oeste em x e sul em y).
Em o total são necessários 4 hops, portanto.
O mapeamento resultante para as heurísticas PL e BN foram idênticos para as quatro aplicações utilizadas.
Comparando o número de hops necessários para realizar todas as comunicações, para todas as quatro aplicações o algoritmo Simulated Annealing apresentou o melhor resultado, seguido das heurísticas congestion-- aware PL e BN.
O pior desempenho foi anotado por o algoritmo Tabu Search no que diz respeito ao número de hops resultantes.
As heurísticas propostas obtiveram seu pior resultado para o mapeamento da aplicação MPEG-4, a qual possui uma tarefa que centraliza várias comunicações, ou seja, conectada a diversas outras tarefas.
Esse caso expõe uma desvantagem no emprego de algoritmos gulosos.
A visão local empregada por essa técnica não permite identificar que a tarefa T1 necessita ser mapeada numa posição central para que seja possível a alocação das suas escravas ao seu redor.
O mesmo não acontece com o algoritmo SA, que possui conhecimento completo da topologia da aplicação.
A avaliação dos algoritmos apenas por o número hops resultante não permite afirmar que um dado mapeamento será o melhor ou pior que outro em termos de congestionamentos ou energia consumida.
No caso de o congestionamento é preciso avaliar se as ta refas mapeadas mais próximas são realmente aquelas que demandam maior taxa de comunicação.
No caso de a energia, ao invés de a taxa, o volume de comunicação ganha importância.
Portanto, faz- se necessária uma avaliação mais aprofundada dos resultados, conforme apresentado a seguir.
O resultado da ocupação dos canais, incluindo a média e o desvio padrão, para cada um dos algoritmos é apresentado nos gráficos da Figura 6.6.
Embora os mapeamentos resultantes para o emprego de Path Load e Best Neighbor sejam idênticos (Figura 6.5), os valores obtidos para a ocupação dos canais não são os mesmos.
Isso ocorre porque para cada heurística o tempo de mapeamento é diferente.
Assim para a simulação relativa a cada algoritmo, num determinado instante idêntico para ambas as simulações, as tarefas alocadas no sistema não são necessariamente as mesmas.
Pode- se notar na Figura 6.6, que embora o algoritmo Simulated Annealing implementado por Marcon (MSA) tenha resultado num número de hops menor para todas as aplicações, apenas para a MPEG-4 ele obteve o melhor desempenho para a ocupação dos canais, mesmo assim com pouca vantagem relativa aos demais algoritmos.
Provavelmente, tal efeito ocorreu porque apenas nessa aplicação o algoritmo mSA teve um resultado muito melhor que os demais algoritmos.
Em a aplicação da Integral de Romberg, os algoritmos gulosos PL e BN apresentaram melhores resultados.
O algoritmo Tabu Search implementado por Marcon (MTS) apresentou a menor ocupação dos canais nas aplicações MWD e VOPD, mesmo resultando num maior número de hops para tais aplicações.
Os algoritmos Path Load e Best Neighbor não apresentaram bons resultados para a aplicação VOPD.
Como pode ser visto na Figura 6.5, o mapeamento da tarefa T7 da aplicação VOPD não foi boa, porque os algoritmos gulosos realizaram a decisão com o conhecimento apenas da comunicação entre T7 e T5, sem conhecer a relação dessa tarefa com as tarefas T6 e T8.
Logo em seguida, a tarefa T7 requisita a tarefa T8, que será reusada, pois já se encontra alocada no MPSoC (se anteriormente requisitada por T2), numa posição distante de T7.
Em os gráficos da Figura 6.7, apresenta- se a latência dos pacotes de acordo com os mapeamentos obtidos para cada um dos algoritmos.
A primeira constatação a ser realizada é a de que todos os algoritmos apresentaram resultados muitos semelhantes.
Isso era esperado porque o MPSoC modelado neste experimento possui tamanho reduzido, limitando as distâncias entre as tarefas.
Em esse caso, mesmo que o mapeamento realizado não seja o mais inteligente, as tarefas não serão mapeadas muito distantes da sua mestre.
Em os gráficos ainda é possível notar que a aplicação RBERG resultou nas maiores médias de latência.
Este efeito acontece porque tal aplicação possui um alto grau de conectividade entre suas tarefas.
Todas as suas tarefas estão conectadas a pelo menos outras duas tarefas, sendo que a tarefa T5 (Figura 6.4), por exemplo, está conectada a seis tarefas.
Com isso, a ocupação dos canais é alta, influindo diretamente sobre a latência dos pacotes.
Com relação a os desvios na latência, a aplicação VOPD apresenta os piores resultados de entre as aplicações investigadas.
Como o desvio padrão alto não foi detectado apenas para o caso onde as heurísticas gulosas são aplicadas, então a causa desse efeito não pode ser atribuída ao mapeamento da tarefa T7.
Assim sendo, este resultado deve ter sua justificativa baseada na natureza da aplicação, seja por a topologia do seu grafo ou por as taxas e volumes aplicados.
Os gráficos da Figura 6.8 apresentam o nível de congestionamento na NoC, obtido para cada algoritmo investigado, incluindo o número de canais saturados e o tempo perdido durante todos os congestionamentos detectados.
Em geral, os algoritmos mSA e mTS apresentaram melhores resultados de latência, embora não sejam congestion-- aware.
De entre todas as aplicações, MPEG foi aquela com maiores valores de congestionamento.
Uma possível justificativa para isso consiste no alto grau de conectividade da tarefa T1 da aplicação.
Além disso, MPEG apresenta a maior diferença de resultados entre as heurísticas propostas PL/ BN e os algoritmos propostos por Marcon.
A provável causa é também a tarefa T1.
Quando ela é requisitada, o algoritmo guloso proposto define seu mapeamento baseado na comunicação entre ela e sua mestre, no caso a tarefas T0.
Assim, quando a tarefas T1 começa a requisitar suas escravas, faltam posições ao seu redor para posicionamento de todas as suas sete escravas.
Aqui, discute- se o tempo total para execução de cada uma das aplicações, conforme o mapeamento resultante para cada um dos algoritmos investigados.
Os valores plotados no gráfico da Figura 6.9 demonstram que os tempos de execução foram equivalentes para os diferentes mapeamentos realizados.
Cabe ressaltar que o mapeamento realizado segundo os algoritmos de Marcon foi aplicado nas simulações em tempo de projeto, ou seja, quando a simulação do ambiente utiliza ou o algoritmo mSA ou mTS, nenhum atraso é considerado para o mapeamento da tarefa, tanto para o seu mapeamento quanto a sua configuração.
Enquanto isso, no caso de as heurísticas gulosas, o mapeamento e configuração de uma tarefa consomem tempo.
Por exemplo, o algoritmo BN gasta em média 1.100 ciclos de relógio no mapeamento de uma única tarefa, sendo 100 ciclos para o mapeamento e 1.000 para a sua configuração no sistema (ver Tabela 5.3).
A presente seção discute a energia total consumida na NoC relativa às comunicações dado o mapeamento das tarefas.
A estratégia adotada para estimativa da energia é baseada na ferramenta CAFES.
Para isso, os mapeamentos resultantes das heurísticas Path Load e Best Neighbor foram anotados e aplicados na ferramenta CAFES.
O modelo adotado para representação das comunicações é o CWM (ou Communicating Weighted Model).
A discussão do modelo de energia adotado é apresentada a seguir, de maneira simplificada.
Para maiores detalhes remete- se o leitor à.
Dada a transmissão de um bit através da NoC, a energia dinâmica consumida para tal transmissão pode ser calculada através da Equação 6.1.
O consumo total é composto por o conjunto de três parcelas de energia, referentes à energia ERbit consumida para roteamento do bit;
A energia ELbit consumida por a sua transmissão através de um dado enlace da NoC;
E a energia ECbit da transmissão no enlace local, entre PE e roteador.
A energia de roteamento ERbit pode ser decomposta na energia consumida para seu armazenamento no buffer interno do roteador EBbit, e na energia consumida no seu chaveamento ESbit para a porta de destino.
A energia ELbit para transmissão através do enlace também pode ser decomposta em duas parcelas, uma primeira relativa à transmissão através de enlaces horizontais (ELHbit), e a segunda relativa aos verticais (ELVbit).
Seguindo o exemplo de, para simplificar a modelagem, pode- se assumir uma NoC quadrada onde ambas as parcelas são idênticas, ou seja, ELVbit $= ELHbit.
Além disso, a energia consumida no enlace local também é assumida como insignificante.
Dadas as afirmações anteriores, a energia consumida na transmissão de um bit entre duas tarefas mapeadas nos recursos Ri e Rj se dá através da Equação 6.2.
Em essa equação, NR representa o número de roteadores intermediários necessários para a transmissão.
Ele indica a distância entre as tarefas, definida por as suas posições e ainda por o algoritmo de roteamento adotado por a NoC.
Em geral, a comunicação entre duas tarefas contém vários bits.
Para obter a energia total da comunicação EAB entre duas tarefas Te a e Tb, a Equação 6.3 multiplica a energia de transmissão de um único bit por o volume total de bits VAB a serem transmitidos entre tais tarefas.
Por fim, para obter a energia dinâmica total relativa às comunicações entre todas as tarefas do sistema é necessário aplicar o somatório da energia para cada par de tarefas comunicantes, de acordo com Equação 6.4.
Em essa equação, CT representa o conjunto de todas as tarefas que compõem o sistema.
Esse conjunto contém informação sobre os volumes de comunicação.
Vista a modelagem de energia consumida, seguem os resultados.
A Figura 6.10 apresenta os valores de energia consumida na comunicação resultante para os mapeamentos obtidos a partir de o emprego de cada algoritmo investigado.
Conforme esperado, o desempenho do algoritmo mSA é o melhor.
Contudo, com exceção da aplicação MPEG-4, as demais heurísticas congestion-- aware apresentaram resultados bons, muito próximos daqueles obtidos por mSA e mTS.
Em as aplicações RBERG e MWD, as heurísticas gulosas apresentaram resultados melhores que os obtidos com o algoritmo mTS.
No caso de a aplicação MPEG-4, o resultado das heurísticas propostas foi aproximadamente 40% pior.
Como mencionado anteriormente, o problema ocorrido no caso de as heurísticas gulosas foi o mapeamento da tarefa T1 da aplicação MPEG-4.
Como pode ser notado, seu efeito foi exercido em todos os parâmetros de desempenho investigados.
A Tabela 6.1 apresenta para cada uma das heurísticas, o resultado obtido normalizado em função de o algoritmo mSA, o qual apresentou, em média, a melhor solução.
Em duas métricas importantes, latência dos pacotes e tempo de execução, as heurísticas propostas apresentaram uma perda mínima de desempenho na ordem de 1% e 4%, respectivamente.
O tempo de execução é penalizado por o tempo gasto por os algoritmos de mapeamento, já que no emprego de mSA e mTS não foram inseridos quaisquer atrasos.
Parâmetros de Desempenho mSA mTS Ocupação dos Canais (Média) Ocupação dos Canais (Desvio Padrão) Latência dos Pacotes (Média) Latência dos Pacotes (Desvio Padrão) Congestionamentos (Canais saturados) Congestionamentos (Tempo perdido) Número de hops Total Tempo Total de Execução Energia Consumida na Comunicação (CAFES) Com relação a o nível de congestionamento, PL e BN sofreram uma penalidade relativamente alta, na ordem de até 45% no número de canais saturados, e de até 66% no tempo perdido devido a congestionamentos.&amp;&amp;&amp;
Este resultado não reflete o esperado, já que as heurísticas propostas são orientadas ao congestionamento.
Uma possível causa para esse efeito reside na estratégia gulosa, que se vale de informação parcial para o mapeamento das tarefas, uma a uma.
Por outro lado, como esperado as heurísticas propostas por Marcon, apresentam os melhores resultados em termos de energia consumida na comunicação.
Em este parâmetro, PL e BN apresentam um consumo de energia 38% pior que o apresentado por mSA.
O valor calculado para ambas as heurísticas é idêntico porque a estimativa de energia é realizada por a ferramenta CAFES em seu modelo CWM, que estima a energia com base no mapeamento das tarefas, sem considerar a natureza dinâmica das aplicações.
O emprego de um mapeamento global de aplicações pode comprometer o desempenho de sistemas dinâmicos, devido a sua complexidade.
Além disso, ele exige um número de recursos livres suficiente para mapear toda a aplicação.
Enquanto isso, as heurísticas propostas são rápidas, e ainda permitem que uma aplicação seja mapeada parcialmente, mesmo que ainda não existam recursos para todas as suas tarefas.
Adicionalmente, as tarefas da aplicação podem começar a executar, até mesmo antes do mapeamento completo da aplicação.
Em esse último caso, apenas as tarefas que necessitam executar num dado instante estarão mapeadas no MPSoC, evitando assim desperdício de recursos.
Os valores obtidos levam ao questionamento de qual estratégia poderia ser empregada para reduzir os congestionamentos no sistema, se as heurísticas congestion-- aware não forem efetivas para um determinado caso.
Uma alternativa sugere o uso da técnica de migração de tarefas.
Tal estratégia é muito empregada visando a distribuição de carga nos processadores do sistema.
No entanto, seu emprego pode ser adaptado para um cenário em o qual a migração das tarefas é realizada para corrigir o mapeamento de uma dada tarefa, quando é detectado que sua posição está gerando congestionamentos no sistema.
Como a migração de tarefas não faz parte do escopo do presente trabalho, uma sugestão para trabalhos futuros consiste na investigação do emprego desta técnica.
O Cenário E investiga o desempenho dos algoritmos quando um MPSoC maior é empregado.
Agora, os recursos devem ser compartilhados por mais de uma aplicação.
Além de as aplicações utilizadas nos experimentos do Cenário D (MPEG-4, MWD, RBERG e VOPD), aqui outras quatro aplicações sintéticas do Cenário C (Figura 5.8) são empregadas para que o número total de tarefas esgote os recursos disponíveis.
Os diagramas expostos na Figura 6.11 representam cada um dos mapeamentos obtidos para as 8 aplicações.
No caso de o mapeamento obtido por as heurísticas gulosas, o número de hops resultantes foi menor que o obtido por os algoritmos estocásticos.
Os resultados indicam uma redução de 20 saltos (hops) com relação a o mapeamento obtido através do algoritmo mTS, e de até 190 saltos comparado ao mapeamento de mSA.
O algoritmo mSA apresentou os melhores resultados nos experimentos do Cenário D, mas agora, quando o MPSoC necessita ser compartilhado, o desempenho foi o pior de todos, pelo menos em termos de número total de hops.
Logicamente, assim com nos experimentos anteriores, outras métricas necessitam ser avaliadas para permitir conclusões mais precisas do desempenho dos algoritmos.
Essas serão discutidas mais adiante no texto.
A o analisar separadamente cada mapa de tarefas da Figura 6.11, pode- se perceber que no mapeamento resultante de mSA, os blocos contínuos são menores que nos demais mapeamentos.
Esses blocos agrupam tarefas de uma mesma aplicação.
Quando maiores os blocos, significa que as tarefas de uma mesma aplicação estão mais próximas, e ainda que as comunicações entre as tarefas de aplicações diferentes irão compartilhar menos canais.
Isso possivelmente levará a uma redução significativa nos congestionamentos resultantes no sistema, conforme discutido na Seção 4.2 deste documento.
O mapeamento mSA possui blocos pequenos, e apenas duas aplicações foram mapeadas na forma de um único bloco (A3 e A6).
No caso de o mapeamento mTS, o tamanho dos blocos aumentou, mas ainda apenas duas aplicações foram mapeadas num bloco contínuo (A5 e A7).
Para o mapeamento BN, apenas a aplicação A7 encontra- se num bloco contínuo.
Em esse mapeamento pode- se perceber um triangulo retângulo.
Ele indica que o recurso sob o triangulo foi reusado durante a simulação.
Em um dado instante, naquele recurso foi mapeada uma tarefas da aplicação A5, e em outro fora mapeada uma tarefa da aplicação A2.
Em o mapeamento PL, são dois os triângulos, nesse caso compartilhados por tarefas das aplicações A3 e A5.
Quando as tarefas da aplicação A3 estão mapeadas forma- se um bloco contínuo, o mesmo acontece para a aplicação A5.
Assim, PL permite o mapeamento de 5 aplicações num bloco contínuo (A3, A4, A5, A6 e A7).
Em a Figura 6.11, existem blocos sem nenhum identificador, esses são blocos não utilizados.
No caso de os mapeamentos mSA e mTS apenas num recurso nenhuma tarefa é alocada.
Em o mapeamento BN, dois recursos não receberam tarefas, mas um de eles foi utilizado para o mapeamento do processador gerente MP.
No caso de o algoritmo PL, são dois os recursos livres, e ainda um recurso dedicado ao MP.
A Tabela 6.2 apresenta o resumo de todos os parâmetros de desempenho investigados, para os algoritmos empregados sobre o Cenário E. Os valores da tabela estão normalizados em função de os apresentados por o algoritmo mTS.
Veja que para a maioria dos parâmetros os melhores resultados foram obtidos a partir de o emprego do algoritmo mTS.
Em termos de ocupação dos canais e latência dos pacotes, os resultados do mapeamento PL são próximos daqueles obtidos com mTS.
Enquanto isso, para o caso dos algoritmos BN e mSA, os resultados são ainda piores que os apresentados por PL.
Parâmetros de Desempenho mSA mTS Ocupação dos Canais (Média) Ocupação dos Canais (Desvio Padrão) Latência dos Pacotes (Média) Latência dos Pacotes (Desvio Padrão) Congestionamentos (Canais saturados) Congestionamentos (Tempo perdido) Número de hops Total Tempo Total de Execução Energia Consumida na Comunicação (CAFES) A avaliação dos congestionamentos apresenta ainda melhores resultados para o algoritmo mTS, com uma redução acima de 90% no nível de congestionamento obtido por a heurística congestion-- aware PL.&amp;&amp;&amp;
Esse efeito se da devido a abordagem de visão local adotadas nos algoritmos gulosos.
Entretanto, não era esperada uma diferença tão grande nos resultados para congestionamentos.
Com relação a o tempo de execução, conforme esperado, os algoritmos gulosos apresentaram tempos maiores de execução para o sistema completo.
É importante relembrar que também nesses experimentos os atrasos de mapeamento e configuração são considerados em PL e BN, enquanto que em mSA e mTS eles são nulos.
Assim sendo, uma penalidade de 4% no tempo de execução dos algoritmos gulosos não é significativa, visto que os tempos de mapeamento para mSA e mTS devem ser grandes, embora não tenham sido medidos no presente trabalho.
Essa medição exige uma manipulação de código fonte da ferramenta CAFES, atividade que se encontra fora de o escopo do trabalho.
Em termos de energia consumida na comunicação, os algoritmos energy-- aware não apresentaram resultados semelhantes.
Enquanto mTS apresentou um valor baixo para consumo de energia, mSA apresentou o pior resultado.
Deve- se lembrar que nos experimentos do Cenário D, o algoritmo mSA apresentou os melhores resultados, mas no Cenário E seus resultados foram os piores de entre os quatro mapeamentos obtidos.
A vantagem do método guloso é que ele deve consumir um tempo menor para seu processamento.
Entretanto, seu resultado pode ser pior porque a decisão tomada para o mapeamento de uma dada tarefa deve ser a melhor dada uma visão local da aplicação.
Em o futuro dessa aplicação, talvez essa decisão implique no mau mapeamento da próxima tarefa requisitada.
Por exemplo, quando uma tarefa possui duas escravas e ela solicita primeiramente a escrava com quem necessita se comunicar &quot;menos», então pode acontecer do melhor recurso ser alocado para essa primeira tarefa solicitada, restando um recurso &quot;pior «para a segunda escrava.
No caso de o mapeamento global da aplicação, provavelmente este problema não ocorreria.
Mesmo existindo o problema da visão local, os resultados obtidos para os algoritmos gulosos foram próximos daqueles apresentados quando os algoritmos mSA e mTS são empregados, em alguns casos são até melhores como pode ser visto no Cenário E. Como os algoritmos propostos por Marcon são baseados em sementes geradas aleatoriamente e ainda em parâmetros de temperatura que determinam quando o mapeamento satisfatório é encontrado, pode ser que os parâmetros do algoritmo mSA não sejam os mais adequados para o Cenário E, mas sim para o Cenário D. O caso do algoritmo mTS deve ser exatamente o contrário, sendo que seus parâmetros sejam mais adequados para o último cenário.
Entretanto não foi possível a investigação do efeito dos parâmetros sobre os resultados dos algoritmos, pois tais parâmetros não estão acessíveis na interface da ferramenta CAFES.
Em o presente Capítulo, primeiramente apresenta- se uma relação das contribuições do trabalho, na Seção 7.1.
Em seguida, apresenta- se um conjunto de conclusões (Seção De entre as contribuições do trabalho constam:
Revisão do estado da arte ­ A primeira contribuição do trabalho consiste na investigação do estado da arte relacionado a MPSoCs.
Para isso, são discutidas algumas propostas de MPSoCs comerciais e acadêmicos.
No que diz respeito ao alvo desta pesquisa, o mapeamento de tarefas, são investigadas tanto abordagens estáticas (mapeamento definido em tempo de projeto), quando dinâmicas (mapeamento definido em tempo de execução), conforme apresentado no Capítulo 2.
Modelo de MPSoC ­ A segunda contribuição consiste na modelagem de uma organização de MPSoC heterogêneo baseado em NoC.
Este suporta a execução tanto de tarefas de software, quando de tarefas de hardware.
Enquanto as primeiras são mapeadas em processadores anexos aos roteadores da NoC, as tarefas de hardware podem ser carregadas em áreas configuráveis (FPGAs) embarcadas no sistema.
De entre os processadores do sistema, um foi selecionado para realizar tarefas de controle, tais como escalonamento, mapeamento e configuração de tarefas, e ainda a manutenção de estruturas que mantêm informação sobre a ocupação dos recursos (NoC e PEs) do sistema.
Essa parte do trabalho compõe o Capítulo 3.
A modelagem apresentada baseia- se no nível RTL, com a descrição VHDL da NoC Hermes, e com os elementos de processamento representados por threads descritas em SystemC.
Modelo de aplicação ­ A terceira contribuição consiste na modelagem das aplicações.
Conforme o Capítulo 3, uma dada aplicação é representada aqui através de um grafo, que indica seu conjunto de tarefas, e as conexões entre as mesmas.
Cada conexão contém informação sobre os volumes e taxas de comunicação entre as tarefas conectadas.
Tais valores expressam estimativas, em as quais os algoritmos de mapeamento propostos baseiam sua decisão.
Completando a descrição do sistema, foi definido o protocolo de comunicação entre as tarefas, baseado principalmente nos pacotes de controle, enviados ao processador gerente para requisitar uma dada tarefa, ou para liberar determinado PE.
Proposta de heurísticas congestion-- aware ­ A principal contribuição do trabalho consiste na proposta de quatro heurísticas para o mapeamento de tarefas.
Tal mapeamento é realizado em tempo de execução, sob demanda da aplicação.
Os algoritmos implementados baseiam- se na ocupação dos canais da NoC para decidir o melhor mapeamento para a tarefa.
De essa forma, tais heurísticas visam reduzir o nível de congestionamento na NoC, assim evitando perda de desempenho nas aplicações.
De entre as heurísticas propostas no Capítulo 4, constam:
MMCL, MACL, PL e BN.
MMCL emprega como função custo a ocupação máxima em todos os canais da NoC, enquanto MACL avalia a ocupação média para todos os canais.
PL e BN são heurísticas que avaliam a ocupação apenas considerando os canais que pertencem ao caminho de comunicação entre as tarefas mestre (que solicitou) e escrava (solicitada).
Uso de monitores ­ O emprego de monitores nos canais da NoC foi outra contribuição do trabalho.
Esses módulos, inseridos nas portas dos roteadores da NoC, permitem a medição da ocupação real dos canais da NoC, em tempo de execução.
Além disso, os monitores são empregados nas avaliações relacionadas à ocupação dos canais da NoC, e ainda na medição do nível de congestionamentos no sistema.
Estudo da complexidade dos algoritmos ­ Foi apresentado um estudo da complexidade dos algoritmos implementados, que permitem obter uma estimativa da curva de crescimento do tempo para obter um dado mapeamento, de acordo com o algoritmo implementado e com as dimensões do MPSoC alvo.
Avaliação das heurísticas ­ A avaliação das heurísticas apresentada no Capítulo 5 é outra contribuição.
Ela permite a comparação entre os algoritmos implementados.
Para isso, são considerados parâmetros de desempenho que incluem a ocupação dos canais da NoC, a latência resultante dos pacotes transmitidos, o nível de congestionamento na NoC e o tempo total de execução do sistema.
Em a segunda parte da avaliação (Capítulo 6), investiga- se o emprego dos algoritmos propostos, os quais aplicam uma abordagem gulosa (mapeiam uma tarefa por vez), frente os algoritmos que mapeiam a aplicação completa.
Publicações ­ O desenvolvimento do trabalho resultou nas publicações listadas abaixo.
De entre elas, as três primeiras relativas ao trabalho realizado logo no início do Doutorado, cujo objetivo consiste em investigar o comportamento de sistemas dinâmica e parcialmente configuráveis.
As três seguintes apresentam a modelagem TLM desenvolvida, enquanto o último trabalho discute a modelagem RTL do MPSoC proposto.
Outras submissões estão previstas ao final da escrita do volume.
No que diz respeito ao cenário atual em MPSoCs, pode- se concluir que, em geral, as propostas tanto acadêmicas quanto industriais são baseadas em MPSoCs homogêneos.
Estes são mais adequados para operações de migração de tarefas, por exemplo.
Contudo, o emprego de MPSoCs heterogêneos torna- se importante para suportar uma grande variedade de aplicações de um dado domínio.
Com relação a a infra-estrutura de comunicação, a maioria dos trabalhos investigados adota NoCs.
Seu emprego torna- se imprescindível em CIs de grande porte frente a as limitações impostas por os barramentos, principalmente relativas à baixa escalabilidade e ao pouco paralelismo suportado na comunicação.
Hoje, existem alguns MPSoCs industriais, como os propostos por a Intel, por a Tilera, a arquitetura picoArray, e o processador CELL da IBM.
Por exemplo, os MPSoCs da Intel e da Tilera possuem 80 e 64 núcleos de processamento, respectivamente.
Certamente, o desenvolvimento e a implementação de um sistema dessa complexidade consiste num processo bastante desafiador.
Além disso, o gerenciamento dinâmico dos recursos de um MPSoC também é crucial, visto que deve permitir o uso efetivo de todo o poder de processamento disponibilizado.
A maioria desses MPSoCs grandes (De a Intel e da Tilera), ainda não chegou ao consumidor.
Talvez uma possível causa para tal efeito seja a falta de gerenciamento eficiente para tais sistemas, ou falta de modelos de programação adequados, de entre outras.
De fato na literatura revisada, para o caso do MPSoC Intel, o mapeamento de tarefas é realizado manualmente nos estudos de caso apresentados.
Isso evidência a necessidade de pesquisas na área de gerenciamento dinâmico de MPSoCs.
O trabalho proposto foi desenvolvido no sentido de contribuir com o gerenciamento dinâmico de sistemas MPSoCs.
Uma de entre as operações importantes é o mapeamento de tarefas.
Em a maioria dos trabalhos encontrados na literatura propõe- se soluções para o mapeamento estático de tarefas, mas recentemente, alguns trabalhos começam a investigar também o mapeamento dinâmico.
Enquanto as estratégias estáticas não são adequadas para o emprego em cenários onde a carga das aplicações e suas tarefas é dinâmica, as pesquisas em mapeamento dinâmico ainda refletem seus passos iniciais.
Em o presente trabalho, foram propostas e avaliadas quatro heurísticas de mapeamento ditas congestion-- aware.
Em aplicações de comunicação intensiva, tais como aplicações de fluxo de dados, a manutenção da ocupação da infra-estrutura de comunicação é fundamental.
A ocorrência de congestionamentos pode acarretar problemas na transmissão de vídeo e áudio, por exemplo.
Para essa classe de aplicações os métodos congestionaware são aplicáveis.
As heurísticas propostas atendem ao compromisso de redução de congestionamento versus tempo total de execução.
Os mapeamentos congestion-- aware propostos reduzem de forma efetiva os parâmetros congestionamento, ocupação dos canais e latência dos pacotes, frente a a implementação de referência (FF).
Um breve resumo aponta para uma redução média de quase 90% nos congestionamentos, de 31% na ocupação dos canais da NoC, e de 15% na latência dos pacotes.
Com relação a o tempo de execução total do sistema, no primeiro momento as heurísticas PL e BN apresentaram uma penalidade na ordem de 8% e 2%, respectivamente.
Quando o volume de dados transmitidos nas simulações foi multiplicado 10 vezes, os resultados para as mesmas heurísticas apresentaram um ganho de 1,3% no tempo de execução.
Assim, pode- se estimar que para grandes volumes de dados o tempo de execução será ainda menor.
Ou seja, atrasos inseridos por a operação de mapeamento, bem como por a configuração, devem se tornar insignificantes.
Volumes maiores de dados não foram simulados devido a o tempo excessivo para execução das simulações.
Em a segunda avaliação realizada, a estratégia gulosa foi posta à prova.
Em esse caso a expectativa era de que o resultado dos algoritmos gulosos fosse pior que aquele obtido quando o mapeamento global da aplicação fosse empregado.
O mapeamento global é baseado no conhecimento de toda a aplicação, incluindo sua topologia e volumes de comunicação.
Enquanto isso, os algoritmos implementados apenas baseiam- se na informação local sobre as comunicações da tarefa a ser mapeada.
De fato, os resultados obtidos na estratégia gulosa são inferiores, contudo a diferença entre os resultados foi pequena, ao contrário de o esperado.
Assim sendo, o emprego da estratégia gulosa é indicado, ao passo que pode reduzir o tempo de mapeamento, e ainda suporta uma baixa penalidade comparada ao desempenho da estratégia global.
O emprego de algoritmos como Simulated Annealing e Tabu Search provavelmente deve resultar em tempos proibitivos de mapeamento, dado um cenário dinâmico.
Como mencionado, o mapeamento congestion-- aware é baseado na taxa de comunicação entre as tarefas.
Enquanto isso, no trabalho de Marcon usado como referência, o volume de comunicação é considerado.
Possivelmente, uma forma de otimizar as heurísticas propostas consiste em considerar ambos, o volume e a taxa de comunicação durante a decisão de mapeamento.
A taxa de comunicação influi nos congestionamento e também na dissipação de potência, enquanto o volume por sua vez, é importante porque está diretamente relacionado à energia consumida.
Baixa dissipação de potência e consumo de energia são importantes requisitos para sistemas portáteis, mas no caso de sistemas MPSoC esses parâmetros também devem receber atenção, visto que sistemas com alta densidade há uma tendência a um grande consumo de energia.
No que diz respeito ao monitoramento, não foi possível comprovar a efetividade no emprego dos monitores distribuídos.
Como mencionado anteriormente, para o caso onde as estimativas das taxas de comunicação são precisas, o uso do monitor centralizado será satisfatório.
Entretanto, se a estimativa não é precisa ou ainda se não existe estimativa, o uso dos monitores distribuídos é obrigatório.
Logicamente, antes do emprego dos monitores distribuídos, faz- se necessária uma investigação mais aprofundada.
São importantes informações relativas ao seu consumo de energia, seu consumo de área, entre outras.
Em esse caso, é importante realizar compromissos com relação a o custo para obter uma medição precisa da ocupação dos canais da NoC.
Uma alternativa que se vislumbra para reduzir esse fator custo-desempenho consiste em atribuir outras funcionalidades aos monitores, Controle de clock gating, variação dinâmica de voltagem e freqüência, etc..
Outra questão importante a ser citada é o fato do MPSoC modelado aplicar a mesma rede para transmissão de pacotes de dados e pacotes de controle.
Esse fato pode estimular questionamentos sobre a influência do tráfego de controle sobre os congestionamentos no sistema.
Em o cenário idealizado, acredita- se que essa possibilidade seja mínima, visto que os pacotes de controle possuem tamanho pequeno, na ordem de 10 flits apenas.
Enquanto isso, os pacotes de dados devem conter algumas centenas de flits.
Além disso, acredita- se que o tempo de processamento e de comunicação de cada tarefa mapeada no sistema é relativamente alto, de forma que o tráfego de pacotes de controle será esporádico.
Ainda, o fato do emprego de um processador gerente único (Centralizado) pode levar a outro questionamento, sobre a possibilidade deste tornar- se um gargalo no sistema.
Também para esta questão, pode- se justificar a estratégia centralizada devido a o pequeno fluxo de pacotes de controle esperado.
Em se tratando de um MPSoC com monitoramento distribuído, os pacotes de controle com informação da ocupação dos canais também podem vir a contribuir pra aumentar o congestionamento no sistema.
Para evitar esse problema é importante definir de forma adequada o período de amostragem para captura de dados e geração de pacotes.
Se esse período for reduzido, logicamente o volume de dados gerados e transmitidos será grande.
Em essa Seção apresenta- se um conjunto de sugestões para trabalhos futuros.
A primeira sugestão para trabalho futuro consiste na otimização da modelagem do sistema.
Algumas das possíveis melhorias são:
Ajustar as heurísticas de mapeamento para utilizar uma função custo multiobjetivo, que considere além de a ocupação dos canais, também o volume de dados comunicados, ou os deadlines das tarefas para o caso de aplicações de tempo real.
Adequar a modelagem dos elementos de processamento para que seja considerada o execução de múltiplas tarefas num dado recurso, de acordo com um modelo de processadores multitarefa.
Em esse caso, o mapeamento deve considerar também a ocupação dos processadores.
Logo, surge a necessidade da avaliação da relação custo-desempenho em mapear duas ou mais tarefas comunicantes num mesmo processador, ou mapear- las em processadores distintos.
Em o primeiro caso provavelmente a comunicação entre as tarefas será mais eficiente, visto que não envolve a NoC.
Por outro lado, o mapeamento no mesmo processador implica o compartilhamento do mesmo por várias tarefas, o que pode vir a comprometer o desempenho de uma dada tarefa em termos de processamento.
A segunda sugestão de trabalho consiste na modelagem e avaliação completa do consumo de energia no sistema, bem como da dissipação de potência.
O emprego de estratégias de variação dinâmica de voltagem e freqüência, bem como clock gating é atrativo para emprego em MPSoCs que contêm muito núcleos, visto que sua heterogeneidade deve permitir que cada um de eles opere de acordo com características diferentes de voltagem e freqüência.
A modelagem de aplicações para MPSoCs é complicada, visto que tais sistemas, em geral, visam um domínio vasto de aplicações.
Em esse caso, o emprego de aplicações sintéticas geradas a partir de a ferramenta TGFF parece satisfatório, já que podem ser obtidas aplicações com grafos bem variados e com taxas de transmissão distintas.
Mas, além disso, o emprego de aplicações reais e de benchmarks faz- se necessário.
Aqui, apenas quatro aplicações reais foram usadas.
Assim sendo, é sugestão para trabalhos futuros a investigação de outras aplicações que podem ser adaptadas para execução no sistema.
Adicionalmente, é necessária a avaliação do mapeamento proposto, conforme o emprego de possíveis benchmarks, a serem investigados.
Uma última sugestão para trabalho futuro é o desenvolvimento de uma ferramenta para automatizar a geração dos cenários de teste (Características do MPSoC e da aplicações), a simulação do MPSoC de acordo com as heurísticas, e a avaliação dos resultados.
Além disso, a ferramenta deve permitir que o usuário adicione seus próprios algoritmos para o mapeamento de tarefas.
Enquanto a ferramenta não é disponibilizada, o acesso aos códigos fonte e maiores esclarecimentos podem ser obtidos diretamente com o Autor.
