Avaliação de desempenho através de benchmarks é uma das principais abordagens para medir o desempenho de um sistema.
No entanto, é importante analisar partes de um sistema antes mesmo de sua implementação.
Isto pode ser feito através de uma descrição analítica do sistema.
Além disso, através do uso de um modelo analítico é possível medir não só índices de desempenho como também índices de confiabilidade do sistema.
Esta dissertação apresenta um modelo genérico do escalonador e do gerente de memória do Linux descrito em Redes de Autômatos Estocásticos (SAN).
SAN e utilizada para descrever o comportamento de processos e processadores no sistema.
Com relação a os índices de confiabilidade, falhas são introduzidas nos processadores para que seja possível avaliar o comportamento do sistema na presença de estas falhas.
Palavras Chave: Modelagem Estocas ica, Escalonamento, Sistemas Operacionais, Linux.
Mesmo com o recente crescimento nas áreas de grids e clusters, sistemas com memória compartilhada ai11da são necessários para a execução e/ ou resolução de certas aplicações.
Estas aplicações necessitam de um sistema operacional escalavel que proveja um ambiente onde estas possam ser executadas de forma eficiente.
Para avaliar a eficiência de um sistema, normalmente são utilizados benchmarksl para medir o desempenho do mesmo.
Um benchmark pode medir uma ou até mesmo varias características de um sistema existente.
A escolha do benchmark depende justamente das características que se deseja verificar no sistema.
Apesar de o uso de benchmarks ser bastante difundido, esta e outras técnicas de monitoração de sistemas não são muito flexíveis como ferramenta de analise.
Em diversas situações se faz necessário modificar a configuração do sistema a fim de verificar seu novo comportamento.
Esta reconfiguração pode ser uma tarefa complexa e cara, e se os resultados obtidos não corresponderem ao esperado, muito esforço sera desperdiçado.
Uma solução para este problema é a construção de um modelo teórico (analítico) do sistema que se deseja avaliar, sendo possível analisar diversas configurações sem um custo muito elevado.
É claro que uma abordagem como esta possui algumas desvantagens:
Como um modelo é uma abstração de uma realidade, o grau de confiabilidade dos resultados tende a ser menor.
Lsto acontece pois modelar um sistema real de forma completa é normalmente inviável devido a o seu tamanho, então algumas siinplificações se fazem necessarias.
É importante salientar que mesmo utilizando esta abordagem, o uso de benchmarks pode ser bastante útil no que diz respeito à captura de parametros que serão utilizados no modelo desenvolvido.
Além disso, utilizando- se um modelo analítico e possível verificar outros tipos de índices, como por exemplo, índices de performabilidade (performability) Performabilidade se refere a verificar o comportamento de um sistema na presença de falhas.
Índices de desempenho e confiabilidade podem ser produzidos através de diferentes modelos e ferramentas.
Em modelos simples, que descrevem partes do sistema que esta sendo avaliado, utiliza- se normalmente modelos baseados em Cadeias de Markov, como por exemplo, Redes de Filas de Espera.
Para sistemas que apresentam caracteristicas modulares pode- se utilizar Stochastic Activity Networks, Stochastic Automata Networks e Petri Nets, que também são baseados em Cadeias de markov.
Em este trabalho sera utilizado o formalismo de Redes de Autômatos Estocásticos (SAN) para a Construção de um modelo do escalonador do Linux na sua Versão 2.6.11, bem como algumas caracteristicas referentes ao gerente de memória do mesmo.
Escolheu- se SAN pois, como sera mostrado no decorrer de esta dissertação, este formalismo se mostra bastante atrativo para a construção de modelos de sistemas que apresentam um comportamento paralelo com algum tipo de interação entre seus módulos.
É importante salientar também que SAN prove um algoritmo numérico eficiente para soluções estacionarias e transientes.
Diversos trabalhos relacionados ao uso de SAN para modelagem de sistemas já foram desenvolvidos, por exemplo, para modelar arquiteturas de clusters (barramento, anel e torus), onde o comportamento dessas diferentes arquiteturas e diversos indices de desempenho puderam ser obtidos (probabilidade do nodo estar ocioso ou a probabilidade do nodo estar mandando alguma mensagem, por exemplo).
Estas informações são bastante úteis, pois pode- se verificar alguns parâmetros que possam não estar satisfazendo o usuário do sistema.
De esse modo, a partir de o modelo, pode- se analisar maneiras de corrigir tais parâmetros no sistema real.
Outro exemplo de utilização de SAN pode ser encontrado em, onde geradores de casos de teste de software são modelados.
O emprego de SAN neste trabalho foi bastante interessante, visto que a complexidade das aplicações que são desenvolvidas nos dias de hoje e cada vez maior e a utilização de formalismos não modulares dificultaria e, muitas Vezes, não resolveria o problema em questão.
SAN também pode ser utilizada para modelar sistemas tolerante a falhas Em este trabalho o mecanismo DMI (Dependable Multiparty Interaction) de tolerância a falhas e utilizado.
Obter a solução estacionaria de um sistema significa obter a descrição de seu comportamento após um tempo de operação suficientemente longo para que todas as situações transitórias já tenham ocorrido.
Obter a solução transiente de um sistema significa obter a descrição de seu comportamento após um deter minado período de tempo.
O trabalho mostra como unir as características de uma DMI com a capacidade de avaliação de desempenho de SAN.
Com esta abordagem e possível determinar como esta o comportamento das DMIs num sistema.
Pode se verificar, por exemplo, se muitas exceções do sistema não estão sendo tratadas.
Estas informações são muito relevantes, pois pode ser muito complicado verificar tais índices diretamente no sistema real.
Além disso, SAN já foi utilizada para modelar interação entre agentes.
O trabalho mostra que verificar o comportamento de agentes e uma tarefa complexa, então foi utilizado um modelo matemático para tal.
SAN se adaptou bem ao problema proposto e, a partir de os modelos, alguns resultados significativos foram verificados.
Tambem já foram desenvolvidos trabalhos que envolvessem a modelagem de protocolos utilizados na Internet.
Em, por exemplo, é avaliado o desempenho de um protocolo chamado MIR (Mobile IP Reservation Protocol) que e utilizado na Internet e que provê qualidade de serviço garantido a terminais móveis.
Como avaliar o desempenho deste tipo de protocolo na própria Internet pode ser muito custoso devido a as inúmeras variaveis que o sistema apresenta, um modelo analítico pode ser utilizado para avaliar o mesmo.
SAN foi utilizada justamente por prover modularidade, adaptando- se bem ao problema.
Podemos citar também um exemplo em o qual um modelo SAN é construído para avaliar o desempenho de redes wireless.
Em este mesmo trabalho é apresentada uma ferramenta, XSan, que é baseada em Redes de Autômatos Estocásticos.
Esta ferramenta possui uma interface gráfica, que e utilizada para construir os modelos SAN.
Esta dissertação esta organizada da seguinte forma:
O Capítulo 2 descreve o que e como é possível avaliar o desempenho de um sistema.
Em este mesmo capítulo diversos formalismos que poderiam ser utilizados para modelar o estudo de caso proposto são descritos e diversos exemplos de utilização dos formalismos são mostrados.
Além disso, é apresentado o conceito de performabilidade, que será utilizado para o cálculo de alguns índices de desempenho.
Em o Capítulo 3 o estudo de caso proposto é apresentado.
As principais questões que serão modeladas referentes ao escalonador e ao gerente de memória do Linux são mostradas.
Em o Capitulo 4 é apresentado como o estudo de caso foi modelado utilizando o formalismo SAN.
Todas as caracteristicas de modelagem referentes tanto ao escalonador quanto a o gerente de memória são descritas em detalhes.
O Capítulo õ apresenta os indices de desempenho obtidos através do modelo proposto, bem como uma analise sobre esses resultados.
Finalmente, no Capítulo 6 são apresentadas as conclusões do presente trabalho e avalia- se possíveis trabalhos futuros.
Referencial Teórico Aplicações paralelas e distribuídas são compostas de diferentes atividades concorrentes, padrões de comunicação e sincronismo entre essas tarefas.
Em princípio, elas oferecem boas perspectivas no que diz respeito a obtenção de um melhor desempenho.
Porem, o desenvolvimento destes tipos de aplicações é bastante Complexo.
Isto faz com que o projetista do sistema tenha interesse em utilizar ferramentas que minimizem o custo e o tempo do projeto do sistema, além de dar alguma perspectiva em relação a o comportamento que o sistema possa vir a ter.
Técnicas de avaliação de desempenho de sistemas permitem a avaliação de determinado sistema mesmo antes de sua implementação física Existem diferentes tecnicas de avaliação de desempenho de sistemas, as quais são tradicio nalmente divididas em tres abordagens distintas:
Monitoração Esta técnica, como o próprio nome sugere, consiste na observação (monitoração) de sistemas reais.
De entre as técnicas citadas, esta e a que propicia maior fidelidade dos índices obtidos, pois não é feita nenhuma abstração (modelagem) do sistema em questão.
Porém, há algumas desvantagens visíveis desta abordagem, como por exemplo, a necessidade da existência física do sistema a ser avaliado.
Isto pode gerar problemas em relação a o custo e ao tempo, pois o sistema implementado pode não satisfazer as necessidades, tendo que ser abandonado.
Uma outra desvantagem é a questão da amostragem.
É necessário que se faça o uso correto de técnicas de estatística para que os dados recolhidos tenham validade.
Esta abordagem consiste em construir um modelo que simule o funcionamento do sistema a ser avaliado.
Este modelo deve descrever as características funcionais do sistema eIn uma escala adequada de tempo.
Este modelo deve conter os detalhes importantes referentes ao sistema, mas não a sua totalidade.
Em outras palavras, ha um certo nível de abstração.
Contudo, deve- se salientar que esta abstração não deve acarretar na inclusão de erros no modelo nem mesmo na exclusão de características importantes Comparativamente a monitoração, a simulação costuma ser menos dispendiosa e consumir menos tempo para que os índices sejam calculados, permitindo que sejam feitos quantos experimentos forem necessários.
Porem, por se tratar de uma abstração da realidade, a fidelidade das medidas tende a ser menor na simulação se compararmos com a monitoração.
Alem disso, da mesma forma que na monitoração, a quantidade e representatividade das amostras consideradas e muito importante para a obtenção de resultados corretos.
Esta tecnica de avaliação de desempenho, assim como a simulação, tambem se baseia no desenvolvimento de um modelo do sistema real, porem com um 11 ível de abstração mais alto.
Em este caso, o modelo e puramente matemático.
Em este tipo de modelo, o funcionamento do sistema real e reduzido a relações matemáticas.
De essa forma, o sistema e descrito em termos de um conjunto de estados em que o mesmo pode se encontrar e de transições estoc icas entre esses estados (uma transição estocástica e aquela cuja ocorrência e descrita por uma variável aleatória).
Uma vantagem desta tecnica em relação as outras descritas e que não ha a necessidade de se preocupar com um conjunto específico de amostras de funcionamento do sistema para a obtenção dos índices de desempenho.
Todavia, desenvolver modelos analíticos e geralmente mais complexo do que desenvolver modelos de simulação.
Modelos analíticos podem ser determinístieos ou estocásticos.
Em um modelo determinístieo, todos os parametros do sistema são previamente determinados.
Ja num modelo estocástico, o comportamento do sistema e analisado probabilistiçamente, ou seja, os parâmetros do sistema são descritos por variaveis aleatórias, com distribuições de probabilidade convenientes Um problema da modelagem analítica e que, em casos complexos, não se consegue obter uma resolução analítica, mas sim uma resolução numérica.
Em alguns casos, a complexidade Computacional do modelo pode tornar a resolução muito custosa, as vezes mais dispendiosa do que uma resolução igualmente aceitável em simulação.
Em foram estudados diversos formalismos de modelagem de sistemas.
Todos os formalismos estudados fazem parte da abordagem de metodos analíticos para avaliação de desempenho de sistemas.
Todos baseiam- se em Cadeias de Markov (Cm).
Uma Cm descreve o funcionamento de um sistema generico como um conjunto de estados que se alternam segundo probabilidades (ou taxas) definidas por leis exponenciais.
Uma vez definida a Cm correspondente a um modelo, a obtenção dos resultados estacionarios do sistema modelado consiste na solução de um sistema de equações lineares.
O tamanho desse sistema linear e igual ao número de estados da Cm, Em as próximas seções serão descritos os formalismos estudados em para a (tonstrução de modelos estocásticos.
Para melhor entendimento dos formalismos, um pequeno exemplo sera utilizado.
Este exemplo compreende uma modelagem do funcionamento de um disco rígido.
O disco pode estar em pleno funcionamento, pode estar funcionando parcialmente ou pode estar em reparo.
Mais detalhes sobre falhas em discos rígidos podem ser encontradas em É importante salientar que o exemplo proposto e bastante simples e naturalmente não representa a realidade de forma completa.
A ideia principal do exemplo e mostrar as diferentes características dos formalismos para que seja possível determinar vantagens e desvantagens de cada um.
O formalismo de Cadeias de Markov (Cm) e um formalismo matemático para modelagem de sistemas.
Através do uso de formalismo de Cm, é possível descrever o funcionamento de um sistema utilizando um conjunto de estados e transições entre esses estados.
As transições entre os estados são modeladas por um processo estocástico de tempo contínuo ou discreto definidos por distribuições exponenciais ou geométricas respectivamente.
Um modelo descrito por o formalismo de Cm pode ser interpretado como uma máquina de estados, onde os nodos da mesma representam os estados e os arcos representam as transições entre os estados do modelo em Cm.
Um modelo descrito por o formalismo de Cm pode ser classificado de acordo com a sua escala de tempo:
Cadeias de MlITÍCDU à escala de Tempo Contínua (CTMC -- Continuous Time Mar/ cm¡ Chains);
Cadeias de Mar/ wo à escala de Tempo Discreta (DTMC -- Discrete Time Markov Chaims).
Os modelos em CTMC diferem dos modelos ern DTMC basicamente por suas transições entre os estados poderem ocorrer em qualquer instante de tempo e não em pontos discretos de tempo.
Uma CTMC é um processo de estados em tempo contínuo que possui as seguintes proprie dades:
O tempo que o processo fica num estado z'antes de ir para outro estado segue uma distribuição exponencial com taxa Ti;
Quando o processo Vai do estado i para o estado j, isso ocorre com probabilidade, t'É j.
A Figura 2.1 apresenta o modelo em CTMC do exernplo proposto.
Em este modelo não é possível saber em que estado o modelo se encontra.
O que podemos saber e que, por exemplo, se o modelo se encontra no estado UT, as transições t1 e t4 estão aptas a ocorrerem.
Redes de Petri (RP) é uma ferramenta matemática e gráfica que possui diversas aplicações, Com RPS, descreve- se e estuda- se sistemas que são caracterizados por serem concorrentes, assincronos, distribuídos, paralelos, não-determinístitzos e/ ou estocásticos.
Como ferramenta gráfica, RP pode ser utilizado como um visualizador do comportamento de um sistema.
Alem disso, marcas (tokens) são utilizadas para simular atividades concorrentes do sistema.
Uma RP e um tipo de grafo bipartido que possui um estado inicial Ã/ IU.
Alem disso, este grafo e composto por dois tipos de nodos:
Lugar e transição.
Arcos conectam lugares a transições e vice-versa.
Graficamente, lugares são representados por Círculos e transições por barras.
Os arcos são rotulados com um peso k.
Um taken determina um valor para um lugar.
Quando uma transição e finalizada o modelo remove um taken de cada lugar que esta diretamente conectado a entrada da atividade e adiciona um taken em cada lugar diretamente conectado com a saída de uma atividade.
Em resumo, pode- se dizer que RP:
Onde: SAN são uma extensão de Redes de Petri.
Esse modelo possui as primitivas atividades, lugares, input gates e output gates.
Ha dois tipos de atividades:
Temporal e instantânea.
A duração de uma atividade temporal representa o atraso que afeta a habilidade do sistema de executar certa função.
Como pode ser visto na Figura 2.3, atividades temporais são representadas por figuras ovais bem estreitas.
Lugares representam o estado do sistema e podem conter tokeus.
Em a Figura 2.3, UT, UP e R são lugares.
O ponto preto dentro de UT e um taken.
Quando uma atividade é finalizada o modelo remove um token de cada lugar que esta diretamente conectado a entrada da atividade e adiciona um taken em cada lugar diretamente conectado com a saída de uma atividade.
Input gates e output gates fornecem uma grande flexibilidade no que diz respeito a definição de regras de permissão e termino para as atividades.
Input gates possuem predicados de permissão e funções, enquanto output gates só possuem funções.
Um predicado de permissão, que pode ser verdadeiro ou falso, junto com as entradas dos lugares, controla a permissão de uma atividade de executar ou não.
Uma função descreve uma ação que ocorre quando uma atividade é finalizada.
Uma atividade esta apta a disparar se ha pelo menos um tokeu em cada lugar diretamente conectado a ela e se o predicado associado a cada input gate e verdadeiro.
Output gates são conectados diretamente a lugares e especificam a ação a ser tomada quando uma atividade e finalizada.
A Figura 2.3 possui apenas output gates.
Atividades instantâneas (representadas por barras pretas) representam atividades do sistema que são executadas num tempo desprezível, relativo as variaveis de performabilidade em ques tão.
Esse tipo de atividade não e usado no exemplo.
Casos associados com atividades (casos também não estão sendo usados neste exemplo, porem são representados por círculos pequenos no lado de uma atividade) representam incertezas sobre o que acontece quando uma atividade e finalizada.
Em relação a especificação de variaveis em SAN*, o formalismo utilizado e uma extensão de modelos de recompensa.
Modelos tradicionais de recompensa consistem de três componentes:
A estrutura de recompensa consiste tipicamente de dois tipos:
Taxa de impulso:
Associada a cada mudança de estado;
Taxa de recompensa:
Associada com o tempo gasto num estado.
Estas ideia podem ser naturalmente associadas a SANs*, determinando taxas de impulso para as atividades finalizarem e taxas de recompensa para alguns tokens num lugar.
Pode- se, então, definir variaveis de desempenho, confiabilidade e performabilidade em termos de estas taxas de recompensa.
As categorias de variáveis possíveis de se definir em SANs são:
Instant-of-time: Representa o estado da SAN* num tempo t ou num estado sólido;
InteTUal-of-tirne: Representa a taxa de recompensa acumulada obtida da execução da SAN* durante um intervalo de tempo,· time-average interval-of-time:
Representa uma media da taxa de recompensa acumulada obtida da execução da SAN* durante um intervalo de tempo.
Estas variaveis, juntamente com as estruturas de recompensa possibilitam representar muitas medidas, como por exemplo, utilização de processador, produtividade, performabilidade, entre outras.
SAN é um formalismo para modelagem de sistemas com grande espaço de estados e que possuem entradas e saídas discretas.
O estado intemo em que o sistema se encontra sumariza as informações sobre entradas anteriores e indica o que e necessário para determinar o comportamento do sistema para as entradas seguintes.
Logo, um autômato estocásticol pode ser descrito como um conjunto&amp; mito de estados e um conjunto;
Imita de transições entre esses estados.
Um sistema em SAN e descrito como um conjunto de subsistemas, onde cada subsistema e modelado como um autômato estocástico.
A interação entre esses subsistemas é descrita através das regras estabelecidas entre os estados intemos de cada autômato.
Assim, este formalismo é particularmente interessante para a modelagem de sistemas distribuídos, ou de qualquer sistema que possua unidades independentes que podem vir a interagir entre si, pois oferece uma modularidade na construção do modelo que facilita seu desenvolvimento e compreensão.
O formalismo de Redes de Autômatos Estocásticos pode ser utilizado tanto para modelos em escala discreta de tempo (quando se utiliza probabilidades de ocorrência) quanto para modelos em escala contínua de tempo (quando se utiliza taxas de ocorrência).
O modelo que sera descrito neste trabalho estara em escala contínua de tempo, pois entre dois instantes de tempo o sistema pode executar diversas atividades que não seriam percebidas por o modelo.
De essa forma, analisar o sistema continuamente no tempo parece ser mais adequado.
Um autômato pode ser descrito como um conjunto de estados (representados por círculos) e um conjunto de transições entre esses estados (representadas por arcos).
As transições são responsaveis por a mudança de um estado local para outro.
O estado local do sistema modelado em SAN é o estado individual de cada autômato do modelo.
O estado global do mesmo é definido por a combinação dos estados locais de todos os autômatos que compõem o modelo.
A mudança do estado global do sistema ocorre por a mudança do estado local de qualquer autômato do modelo.
Cada transição possui pelo menos um evento associado a ela para que possa ser disparada.
Evento e a entidade do modelo responsavel por a ocorrência de uma transição, mudando o estado global do modelo.
Uma transição pode ter um ou mais eventos associados a mesma e dispara?
O autômato A1 possui os estados UT, UP e R. O autômato A2 possui os estados F (funcionando) e R (em reparo).
Quando o disco passa do estado UT para o estado UP ou do estado UP para o estado UT, estes eventos não alteram o automato A2, pois o disco permanece funcionando.
Em o momento que o estado de A1 passa de UT ou UP para R (sz) ou de R para UT, o automato A2 tambem é afetado.
Apesar de o exemplo ser bastante simples, é possível mostrar o que este formalismo permite.
Separando o sistema a ser modelado em módulos, facilita bastante quando de a modelagem do mesmo.
É importante ressaltar que o autômato Ag foi construído apenas por questões didáticas, para mostrar a modularidade e outras caracterís cas do formalismo, como por exemplo, os eventos sincronizant s.
Como foi citado anteriormente, cada transição possui um ou mais eventos associados a ela.
Cada evento deve possuir uma taxa de ocorrência (ver Figura 2.4) associada ao mesmo.
O valor dessas taxas pode ser tanto uma constante quanto um valor funcional.
Taxas funcionais assumem valores diferentes conforme os estados dos autômatos do sistema num determinado momento.
Como pode ser observado na tabela da Figura 2.4, o evento s;
Possui uma função f4 associada a sua taxa de ocorrência.
Esta função e definida como:
T5 se autômato A1 esta no estado UT;
T5 se autômato A1 está no estado UP.
Além disso, SAN possui outros dois tipos de funções que são necessárias para a resolução do modelo:
Função de Atingibílidade e Funções de Integração. A Função de Atingibilidade define quais são os estados atingíveis do modelo.
Esta função e definida usando- se as mesmas regras adotadas para a definição de taxas e probabilidades funcionais.
Para facilitar o entendimento desta função, apresenta- se um modelo de Compartilhamento de recursos, Em este exemplo, temos N clientes disputando R recursos.
Este sistema pode ser modelado em SAN utilizando- se um autômato com dois estados para cada cliente.
Um dos estados representa a utilização do recurso por o cliente, enquanto o outro estado representa que o cliente não esta utilizando o recurso (estado O).
A Figura 2.5 apresenta este modelo.
Se o número de recursos for menor que o número de clientes, o estado global onde todos os clientes estão utilizando o recurso não pode ser atingido, pois isto não estaria representando a realidade do modelo.
Tais estados globais são chamados estados matmgívcis e devem ser eliminados do modelo através da função de atingibilidade.
Em este caso, a função de atingibilidade do modelo descrito acima seria:
Note que o somatório dos clientes que estão de posse de algum recurso deve ser menor que a quantidade total de recursos disponíveis no sistema.
As Funções de Integração servem para se obter os resultados numéricos sobre o modelo.
Em outras palavras, elas avaliam qual a probabilidade do modelo encontrar- se num determinado estado após ele ser executado.
Com isso, pode- se compor funções de integração que levem em conta a probabilidade do modelo se encontrar num determinado conjunto de estados, podendo se obter os índices de desempenho e confiabilidade do modelo.
Um exemplo deste tipo de função, levando- se eIn conta o exemplo de compartilhamento de recursos acima descrito, pode ser dado por a função f abaixo, onde se deseja descobrir a probabilidade de um determinado autômato AW não estar utilizando o recurso, em outras palavras, a probabilidade de ele estar no estado Dik).
Trabalhar simultaneamente com desempenho e confiabilidade em sistemas computacionais foi uma necessidade que surgiu em meados da década de 70, Mais especificamente, surgiu como conseqüência de projetos, como por exemplo, o Prime (desenvolvido na Universidade da Califórnia, Berkley), em os quais os sistemas apresentavam queda de desempenho (degradable systems) nã presença de falhas.
Historicamente, a distinção entre desempenho e confiabilidade foi muito útil no desenvolvimento de tecnicas de avaliação adaptadas para cada situação.
Além disso, cada um desses conceitos passou a ser estudado separadamente, sem ter algum tipo de relação.
Entretanto, se utilizados separadamente para avaliar sistemas, algumas restrições devem ser levadas em conta.
Por exemplo, supondo que a capacidade de um sistema de servir é binaria (o sistema esta &quot;ativo «ou &quot;inativolÚ e alguma operação e feita quando o sistema esta «ativo».
Em este caso, a qualidade da entrega do serviço, quando ativo, tem relação com o desempenho.
Ja a capacidade do sistema de permanecer ativo (sem defeitos) tem relação com a confiabilidade.
Podemos perceber, neste exemplo, que falhas não afetam a qualidade do serviço (quando o sistema esta ativo).
Reciprocamente, o desempenho não afeta na perda da corretude do serviço e não afeta a confiabilidade.
Portanto, pode- se avaliar o desempenho e a confiabilidade de um sistema separadamente.
Geralmente, entretanto, avaliar separadamente o desempenho e a confiabilidade de um sistema pode ser mais complicado, principalmente se o desempenho do mesmo degrada na presença de falhas.
Isso pode ocorrer, por exemplo, quando uma falha no sistema faz com que a qualidade da entrega de um serviço seja menor, mesmo que satisfatória.
Essa degradação pode ocorrer devido a falhas, devido a muita demanda computacional associada com defeitos de processamento ou pode ser (tonseqüência de ações como reconfigurações do sistema ou reparos.
Pode- se perceber que havendo sistemas onde o desempenho pode diminuir (degradable systems ou gracefully degrading systems) uma classificação binária para o sistema (ativo ou inativo) é muito simples.
Então, um sistema deve poder ser representado por diversos estados, mostrando as diversas possibilidades de falhas no sistema.
Após alguns trabalhos relacionados ao assunto, chegou- se ao conceito de performabilidade (performability) e a um framework para modelar e avaliar a performabilidade de um sistema.
Performabilidade se refere a uma classe de medidas (probabilísticas) que quantificam a capacidade de um sistema operar na presença de falhas.
O framework proposto por é um modelo genérico para analise de performabilidade.
A partir de ele, diversos trabalhos foram realizados no que diz respeito ao desenvolvimento de algoritmos e tecnicas para calcular a performabilidade de sistemas.
De entre esses trabalhos podemos citar, onde um framework para analise de performabilidade em modelos de recompensa (reward) e apresentado.
Em resumo, este framework define que para cada estado i do modelo, 11H13.
Taxa de recompensa r, é associada.
Assim, se o modelo gasta 7', unidades de tempo no estado i, então m, é a recompensa acumulada no estado z'.
Se o modelo descreve um sistema no estado estacionário, a performabilidade pode ser definida por:
Se a analise desejada for transiente, ou seja, durante um determinado período de tempo, a performabilidade pode ser definida por:
Esta e uma das formas de se medir performabilidade de sistemas.
E importante salientar que a performabilidade de um sistema pode ser analisada de diversas maneiras.
Em algumas situações, pode não fazer sentido atribuir taxas de recompensas aos estados do modelo.
De essa forma, pode ser feita uma analise do sistema observando seu desempenho em diferentes situações onde falhas podem ocorrer.
Mais detalhes sobre o framework e outros aspectos referentes às medidas de performabilidade (incluindo explicações detalhadas a respeito de as fórmulas apresentadas) podem ser encontradas em.
Como foi mencionado na introdução deste trabalho, o uso do formalismo de Redes de Autômatos Estocásticos pode ser aplicado e utilizado em diversas áreas da Ciencia da Computação devido a sua estrutura modular.
Esta estrutura facilita, em muitos casos, a modelagem de sistemas que possuem subsistemas que trabalham independentemente (eventos locais), mas que podem vir a interagir entre si (eventos sincronizantes).
Alem disso, o formalismo SAN provê o uso de taxas funcionais.
Este tipo de taxa e uma primitiva muito poderosa, pois permite descrever comportamentos complexos de uma forma bem compacta Apesar de a modelagem de sistemas ser bastante facilitada com as primitivas do formalismo SAN, e importante salientar que outros formalismos que possuem estruturas diferentes também podem ser empregados, como Redes de Petri Estocásticas e Redes de Atividades Estocásticas.
O formalismo de Redes de Autômatos Estocásticos foi escolhido para ser utilizado na modelagem do estudo de caso proposto neste trabalho pois suas características se adaptam bem ao problema proposto.
Este formalismo prove uma modularidade que os outros formalismos não possuem e o estudo de caso possui exatamente esta característica:
Ele pode ser visualizado como diversos subsistemas que são independentes, mas que podem interagir entre si.
No caso de o escalonador do Linux, os processadores trabalham de forma independente, ou seja, cada um é responsavel por executar seus respectivos processos.
Porem, como será.
Explicado no proximo capítulo, ha situações o11de processos devem ser migrados de um processador para outro.
Em este caso, os processadores interagem para que esta migração ocorra.
Sistema Operacional Linux Em este capítulo sera descrito o funcionamento do escalonador do Linux em sua versão 2.6.11, que e o estudo de caso da presente dissertação.
Será dada uma Visão geral do mesmo e serão apresentadas suas principais características e conceitos, os quais foram utilizados para a construção do modelo analítico proposto.
Tambem sera descrito parte do funcionamento do gerente de memória do Linux, pois o escalonador necessita conhecer diversas funções que são de responsabilidade do gerente de memória, como por exemplo, alocação de memória.
Alem disso, serão apresentadas propostas de alteração do funcionamento de algumas características do Linux.
De um modo geral, uma máquina multiprocessada pode ser classificada em Uma (Uniform M emory Access) ou Em uma (Non-Uniform Memory Access).
Máquinas Uma são máquinas multiprocessadas onde cada processador acessa a memória num tempo médio constante.
Máquinas NUNIA são organizadas em nodos.
Cada nodo possui um conjunto de processadores e uma parte da memória principal.
A distância entre esses nodos é diferente, o que gera diferentes tempos de acesso a memória.
A Figura 3.1 mostra um exemplo de máquina Em uma com oito processadores agrupados em quatro nodos.
Um sistema que possui recursos compartilhados necessita de uma política que defina quem pode utilizar determinado recurso e por quanto tempo.
Em um sistema operacional, o escalonador de processos e responsavel por controlar o uso dos diversos processadores do sistema por os diferentes processos existentes.
Apesar de estar sendo bastante estudado nos últimos anos, o escalonamento em máquinas multiprocessadas ainda apresenta alguns desafios.
O sistema operacional Linux possui um algoritmo de escalonamento para máquinas multiprocessadas.
Desde a versão 2.5, o escalonador do Linux chama- se O, pois todas suas rotinas executam num tempo constante, não importando o número de processadores no sistema As versões do Linux ate a 2.4 possuíam apenas uma fila de processos para todo o sistema, enquanto que o escalonador O possui uma fila de processos (chamada runqueue) para cada processador do sistema.
A rimqueue e uma estrutura de dados que mantem os processos de um determinado processador.
De essa forma, um processo esta associado a uma e somente uma rimqucue e o escalonador executa de forma independente em cada processador do sistema.
Quando um processo e inserido numa runqueue, ele ira executar somente no processador associado a esta runqueue.
Essa propriedade é chamada de afinidade de processador.
Ja que o processo executa num mesmo processador, os dados deste processo podem ficar na memória cache, fazendo com que o sistema não necessite buscar dados na memória principal a todo momento.
Como o acesso à memória cache e mais rapido do que o acesso a memória principal, a afinidade de processador melhora o desempenho do sistema.
Alem dessas características, o escalonador do Linux e preemptivo e trabalha com filas de prioridades dinamicas.
Isto significa que cada processo possui uma prioridade associada, que pode mudar durante seu tempo de vida.
Processos com mais alta prioridade têm a preferência do escalonador para executar.
De essa forma, o sistema calcula a prioridade dos processos de acordo com sua taxa de utilização da CPU.
De acordo com essa taxa, os processos podem ser classificados como I/ O-bozmd ou CPU-bound.
Processos I/ O-bound, os quais executam muitas operações de entrada e saída, possuem prioridade mais alta do que processos CPU-bound, os quais tendem a executar por mais tempo.
A fatia de tempo (timeslice), que e o tempo que o processo tem para executar a cada vez que ganha o processador, também e dinamica e é calculada baseada na prioridade do processo.
Quanto maior a prioridade de um processo, maior será sua fatia de tenipo.
Apesar de o Linux não ser um sistema operacional de tempo real, ele prove algumas políticas de escalonamento para este tipo de processo.
O Linux possibilita que tarefas com privilégios de superusuário sejam definidas como de tempo real, porem sem oferecer quaisquer garantias em relação a quando essas tarefas terminarão sua execução.
Processos de tempo real têm sempre prioridades maiores que todos os outros processos do sistema, ou seja, enquanto houver processos de tempo real para serem executados, nenhum outro processo podera ocupar a CPU.
Para estes tipos de processos, o escalonador tenta respeitar os deadlines das aplicações tanto quanto for possivel.
Para isso, além de a alta prioridade que esses processos recebem, o Linux oferece atribui fatias de tempo aos processos, os quais não serão preemptados, deixando o processador somente quando bloqueiam, liberam explicitamente ou quando terminam sua execução.
A política SCHED_ RR e idêntica a SCHED_ FIFO, exceto por o fato de utilizar fatias de tempo.
Logo, processos S CHED_ RR são preemptaveis (por outros processos de tempo real).
A partir de a versão 2.5 do escalonador, cada runqaeae possui dois arrays de prioridades, um de processos ativos e outro de processos crpirados.
Um processo é inserido no array de processos ativos quando é criado e quando é migrado de/ para outro processador.
Em o momento em que um processo termina de executar a sua fatia de tempo, o processo é preemptado, sua prioridade e fatia de tempo são recalculadas e o processo é inserido no array de processos expirados, de onde não pode ser escalonado.
Então, quando todos os processos do array de ativos esgotareni suas respectivas fatias de tempo, todos os processos estarão no array de expirados.
Como esses arrays de prioridades são referenciados por a runqueue por dois ponteiros (um para cada array), quando o array de processos ativos fica vazio, os ponteiros são trocados, ou seja, o array de processos expirados passa a ser o de processos ativos e vice-versa.
Em este momento, todos os processos poderão ser escalonados novamente.
Em o momento em que um processo troca de processador, seja por qualquer motivo, possivelmente seus respectivos dados não estarão na memória cache desse novo processador, ou seja, deverão ser lidos da memória principal.
Normalmente, cada vez que um processo troca de processador, essa busca na memória principal será necessaria, o que e muito custoso para o sistema.
De esse modo, como foi mencionado anteriormente, manter o processo no mesmo processador diminui a necessidade de acessar a memória principal, melhorando o desempenho do sistema.
Alem disso, no momento em que um processo escreve um dado na cache de um determinado processador, todas as demais Coches que contêm aquele dado serão invalidadas.
Quando LlIIl sistema operacional implementa este tipo de política, diz- se que ele oferece afinidade de processador.
Como foi dito anteriormente, o grande benefício oferecido por a afinidade de processador e o ganho de desempenho por acessar dados que estão na memória cache.
O escalonador O provê afinidade de processador;
Como na criação de um processo o mesmo é inserido numa runqueue, este processo só sera escalonado para o processador associado a esta runqueue.
De esse modo, só irá ocorrer migração de processos caso seja necessário executar o algoritmo de balanceamento de carga no sistema, para evitar que processadores fiquem sobrecarregados enquanto outros estejam ociosos.
Quando um processo e criado, ele é inserido na mesma runqueue e possui a mesma prioridade do processo que o criou (processo pai).
A fatia de tempo do processo pai é dividida igualmente entre ele e o novo processo.
No entanto, se processos forem inseridos sempre na mesma fila, o processador pode ficar sobrecarregado.
Para que isto não ocorra, o escalonador do Linux possui um algoritmo de balanceamento de carga.
Este algoritmo tenta manter a carga do sistema distribuída entre os processadores.
Para tal, o balanceador de carga migra processos de um processador mais carregado para outro com menos processos para executar.
Em máquinas SMP, migrar processos de um processador sobrecarregado para um processador menos carregado e simples.
Ja que a distancia entre processadores e memória e sempre igual, migrar processos de um processador para outro, em geral, não piora o desempenho do processo.
Ja em máquinas Em uma, migrar processos de um processador para outro no mesmo nodo e melhor do que migrar para um processador de outro nodo, pois a latência de acesso à memória e menor.
O algoritmo de balanceamento de carga do Linux utiliza uma estrutura chamada rsched_ domain para efetuar o balanceamento Basicamente, um sched_ domain (domínio de escalonamento) contem grupos de processadores que definem o escopo do balanceamento de carga para este domínio.
Os domínios de escalonamento são organizados hierarquicarnente, tentando- se representar a topologia do sistema.
A Figura 3.3 apresenta os domínios de escalonamento de CPUs criados para uma máquina Em uma com\&gt; osta por dois nodos, cada uma contendo quatro processadores.
Os domínios no nível mais baixo representam os nodos do sistema.
Estes domínios são chamados de domínios de CPU, pois os processos podem migrar apenas entre processadores, não entre nodos.
O domínio no nível mais alto representa o sistema completo e é chamado de domínio de nado, pois processos podem ser movidos de um nodo para outro.
O balanceador de carga do Linux executa periodicamente ou quando de a ocorrência de alguns eventos.
Os principais eventos que podem causar a execução do balancemento de carga são:
O balanceamento de carga é executado entre processadores de um mesmo domínio de escalonamento.
Como o algoritmo deve ser executado num processador, o balanceamento ocorrerá nos dominios de escalonamento que contém este processador.
A primeira tarefa do balanceador e encontrar o processador mais ocupado do seu dominio e verificar se ha desbalanceamento com o processador corrente.
A diferença entre as cargas dos processadores determina se lia desbalanceamento ou não.
Esta diferença e definida para cada domínio de escalonamento.
Se houve um desbalanceamento, processos são movidos do processador mais carregado para o processador corrente ate que as cargas estejam balanceadas.
A escolha dos processos que serão migrados segue as seguintes regras:
Processos que estão na fila dos processos expirados tem preferência, pois estão a mais tempo sem executar.
Isto significa que provavelmente seus dados não se encontram mais na memória cache.
Alem disso, para que um processo seja migrado, as seguintes premissas devem ser satisfeitas:
O processo não pode estar em execução;
O processo não pode estar impedido de executar no processador destino devido a afinidade de processador;
Os dados do processo não podem estar na cache do processador ha um pequeno intervalo de tempo, pois isso significa que foram lidos da memória lia pouco tempo e portanto tem grande chance de ainda estarem válidos,· processos de maior prioridade tem preferência na migração, já que precisam executar mais rapidamente.
Este algoritmo de balanceamento de carga e uma parte do escalonador 0 e seu objetivo e manter a carga do sistema de todos os processadores o mais balanceada possível, minimizando o tempo medio de execucão dos processos.
Como foi mencionado na Seção 3.1.3, os domínios de escalonamento servem para representar a topologia da máquina, possibilitando urn balanceamento que mantém os processos o rnais perto possível de suas áreas de memória.
No entanto, o Linux implementa no máximo dois níveis de escalonamento, independentemente da topologia da máquina.
Isso significa que se uma máquina possuir mais do que dois níveis de acesso à memória, o algoritmo responsável por montar a hierarquia de domínios de escalonamento irá construir apenas dois níveis, não representado a realidade da máquina.
De essa forma, em e apresentado uma proposta de alteração na criação da hierarquia de domínios de escalonamento, onde modifica- se a função que constrói os dominios de escalonamento, para que seja possível construir uma hierarquia genérica, com n níveis, de acordo com a topologia da máquina.
Com essa proposta, pretende-se garantir um balanceamento de carga mais eficiente, onde os processos fiquem o mais perto possível de suas áreas de memória não importando a topologia que a máquina possa ter.
Detalhes sobre esta proposta podem ser encontrados em.
Em uma máquina Em uma, diferentemente de uma máquina Uma, é necessário que o sistema de gerência de memória feito por o sistema operacional tenha urn tratamento diferente em relação a a forma de alocação de memória, a fim de aproveitar melhor as características deste tipo de máquina, obtendo- se um ganho r1o desempenho.
De este modo, e necessário que haja urn conjunto de políticas para que, através de elas, seja provida uma base para a melhoria do desempenho do sistema.
As políticas que ditam as regras para a alocação de memória têm o objetivo de deixar o processo no nodo onde o tempo de acesso a seus dados seja o menor possível.
Nota- se aqui, uma dependência entre o gerente de memória e o escalonador de processos, já que este último &quot;escolhe «o processador onde o processo irá executar, e o gerente de memória &quot;escolhe «onde o processo ficará alocado.
Isso Levando-se em conta procedimentos comuns em sistemas operacionais, como balancemento de carga e swap, pode- se verificar que um processo pode executar em diferentes processadores ern espaços de tempo diferentes, bem como este pode nem sempre ficar na memória, pois pode ser movido para o dispositivo de swap.
Estes são apenas alguns aspectos relevantes em relação as políticas a serem utilizadas durante a gerência de memória numa máquina Em uma.
A seguir, serão apresentadas algumas questões importantes referentes a essas políticas.
Criação do Processo:
Esta e uma questão relativamente simples.
Quando um processo é criado, é interessante que o gerente de memória aloque espaço para ele no bloco de memória do próprio nodo onde ele foi criado.
De essa forma o processo podera ser executado no menor tempo possível, caso não se leve em conta a possibilidade de haver migração do processo para um processador ein outro nodo do sistema.
Balanceamento de Carga:
Esta questão é um pouco mais complicada e já foi parcialmente discutida na Seção 3.1.3.
Quando um sistema possui mais de um processador, o escalonador deve saber como distribuir os processos entre os processadores a fim de deixas- los ocupados de forma igualitária.
De essa forma, o escalonador pode migrar processos de um processador para outro quando verificar que um determinado processador está sobrecarregado e outro estiver livre, por exemplo.
Este procedimento é chamado de balanceamento de carga e é implementado por o sistema operacional Linux.
Durante este procedimento, o escalonador pode colocar um processo que inicialmente executava num nodo m num outro nodo NZ.
Porem, o processo continuará no mesmo espaço de memória M1 onde foi inicialmente alocado.
Isto pode causar um ônus ao desempenho do sistema, já que o tempo de acesso de um processador ein Ni a M1 possivelmente é menor do que de um processador em N2 a M1.
Assim, o balanceamento gerou um ganho ao distribuir melhor o trabalho entre dois processadores, porém gerou o ônus do tempo de acesso a memória do processo que foi migrado.
Em este caso, pode ser interessante que juntamente com a migração do processo para um outro processador, que o espaço onde o processo esta alocado também seja migrado para um espaço de memória mais próximo de o processador para onde o processo foi movido,· Swap:
Outra questão importante diz respeito ao uso de swap.
Em este caso, o sistema necessita mais memória do que a disponível e é necessário mover algumas páginas da memória (swap out) para o dispositivo de swap.
Quando as páginas que forem movidas voltarem a memória principal (sofrerem swap m), pode ser que o processo associado a elas tenha migrado para outro processador, então possivelmente sera vantajoso não colocas- las de volta no banco de memória onde estavam previamente, e sim no banco de memória mais próximo de o processador para onde o processo foi movido.
Pode também haver o caso onde um banco de memória esta mais próximo de o dispositivo de swap e, portanto, durante o swap ln devesse sempre ser alocada memória neste banco e carregar ali as páginas vindas do swap.
Em este caso, para melhorar ainda mais o desempenho, possivelmente seria melhor sempre escalonar processos que sofrem swap no processador mais próximo deste banco de memória.
Existem duas abordagens de programação em arquiteturas Em uma.
A primeira diz que o sistema operacional deve tomar conta de todos os detalhes da arquitetura e esconder as peculiariedades do hardware no kernel permitindo que as aplicações do espaço do usuário enxerguem o sistema como uma máquina SMP.
É assim que o Linux trabalha, tendo um escalonador e um gerente de memória &quot;inteligentes», capazes de tomar determinadas decisões baseados no hardware em que estão executando (estas características são lidas das tabelas ACPl).
Normalmente, o Linux aloca memória para um processo no nodo local, ou seja, no nodo onde o processo está executando.
A memória é logicamente organizada para que a alocação seja feita conforme a tecnica round robin, começando sempre no nodo local.
O kernel 2.6 usa o algoritmo LRU (least reference used) para o gerenciamento de páginas, o11de cada nodo aplica este algoritmo para o seu banco de memória.
A segunda forma de lidar com programação Em uma e prover o maximo de detalhe possível sobre o sistema e deixar que as aplicações explorem o hardware como elas acharem adequado.
Para isso existe uma biblioteca que permite esse tipo de manipulação, a Em uma API.
Muitas aplicações, principalmente as grandes, com muitas threads, 11 ão conseguem explorar completamente uma máquina Em uma com o escalonador e o gerente de memória padrão.
Por exemplo, um programa que usa uma grande espaço compartilhado de memória e diversas threads.
Para este exemplo, uma thread inicial geraria muitos page faalts já que esta faria toda alocação de memória e inicialização das outras threads.
Em este caso, o comportamento padrão do Linux fara com que o banco de memória onde a thread inicial esta executando seja o usado para alocar estas páginas resultantes dos page faults.
Em seguida, ao se inicializarem as outras threads, estas seriam espalhadas entre os processadores por o escalonador que fara o balanceamento de carga.
Assim, as threads terão sempre que acessar a memória do processo inicial, pois a alocação de memória do programa foi feita no banco desse nodo.
Este não e o melhor Comportamento quando se analisa o desempenho do sistema, pois, neste caso, poderia ser mais interessante manter as threads no nodo onde seus dados estão alocados.
A NUNIA API e as chamadas de sistema de afinidade para o escalonador permitem que a aplicação especifique políticas de como deve ser gerenciada a memória e as threads da aplicação.
A API Em uma do Linux não implementa migração de páginas entre nodos.
Ela apenas gerência a alocação quando uma página e alocada pela primeira vez ou quando uma página é realoçada depois do swapping.
De essa forma, essa característica pode ser interessante de ser avaliada, ou seja, pode- se verificar se a migração das páginas de um processo juntamente com o próprio processo, quando este migra para um outro nodo, geraria um ganho no desempenho.
Em esta seção serão abordadas duas propostas para a migração de páginas.
A primeira proposta considera a possibilidade de migrar toda a memória do processo juntamente com o mesmo quando este migra de nodo.
Geralmente processos são migrados quando um processador fica ocioso ou quando há um desbalanceamento entre processadores.
De essa forma, esta estrategia tende a gerar queda no desempenho do sistema.
O problema dessa abordagem esta no overhead adicionado ao sistema com relação a o barramento, isto e, mover as páginas de um nodo para outro pode causar um atraso na execução do processo, pois este deve esperar que todas suas páginas sejam migradas.
O algoritmo referente a esta proposta pode ser descrito da seguinte forma:
O algoritmo de balanceamento de Carga seleciona o processo a ser migrado e o processador destino;
Um espaço de memória adequado e alocado no nodo destino;
Ocorre a cópia do espaço de endereçamento do banco de memória origem para o banco de memória destino;
A área de memória que estava alocada para o processo no banco de memória origem e liberada.
Apesar de a migração de todo o espaço de endereçamento do processo juntamente com o próprio processo poder melhorar o desempenho do sistema, se o processo migrar muitas vezes durante seu tempo de vida, o desempenho do sistema pode decair.
A segunda proposta para migração de páginas considera a mesma estrategia usada por o sistema de memória virtual do Linux no momento que ocorre swap para o disco.
A abordagem consiste da marcação das páginas como se elas não estivessem na memória (swap out) e quando um page fault é gerado, é verificado se este page fault foi originado devido a um processo que foi migrado ou por um processo que realmente possui páginas no disco.
No caso de ser gerado por um processo que foi migrado, o sistema moveria estas páginas do nodo remoto para o nodo local.
Em outras palavras, ocorreria migração sob demanda.
O algoritmo referente a esta proposta pode ser descrito da seguinte forma:
O algoritmo de balanceamento de carga seleciona o processo a ser migrado e o processador destino;
Para cada acesso a memória em o qual o processo não encontra os dados no banco de memória destino:
Em uma primeira analise, a segunda proposta parece ser mais atraente, pois parece ser melhor trazer as páginas a medida que o processo as necessita do que trazer toda a área de memória do processo.
Por outro lado, a complexidade da i mplementação da segunda proposta tende a ser maior tambem.
Alem disso, se uma máquina possuir varios nodos, a área de memória do processo pode acabar ficando fragmentada entre os diversos nodos.
É importante salientar que estas abordagens levam em conta apenas os processos que não possuem dependência de dados ou código com outros processos.
Para os processos que possuem algum tipo de dependência de dados ou código, ainda não ha uma proposta elaborada.
Esta seção apresentou algumas das principais características do sistema operacional Linux na sua versão 2.6.11.
As alterações efetuadas a partir de a versão 2.5 trouxeram um grande ganho de desempenho ao sistema, especialmente para máquinas multiprocessadas.
Como pode- se notar, numa máquina Em uma há uma estreita relação entre o escalonador de processos e o gerente de memória.
Saber explorar de forma correta esta relação pode trazer ganhos significativos de desempenho do sistema.
Um fato interessante e que o mesmo problema que há em relação a os diferentes tempos de acesso à memória pode haver com o gerente de entrada e saída (I/ O).
Caso este se encontre mais próximo de um determinado nodo, haVera diferentes tempos de acesso ao dispositivo.
Então, dependendo da iteratividade do processo, pode valer a pena manter- lo no nodo onde se encontra o dispositivo de entrada e saída.
Em a próxima seção sera apresentado como algumas das características do Linux mostradas nesta seção foram modeladas utilizado o formalismo de Redes de Autômatos Estocásticos, descrito na Seção 2.
Um trabalho descrevendo a modelagem do escalonador e apresentando os respectivos índices de desempenho já foi desenvolvido.
Em relação a o gerente de memória, um outro trabalho foi submetido para uma importante conferência internacional.
Modelo SAN do Escalonador do Linux Como mencionado no início desta dissertação, o uso de benchmarks pode ser bastante útil para medir caracteristicas de sistemas muito complexos, como por exemplo, o algoritmo de escalonamento do Linux.
Porém pode ser bastante custoso modificar um sistema como esse para Verificar certos índices de desempenho e perceber que esses índices não apresentam os resultados esperados.
De essa forma, um modelo analítico pode ser usado para descrever e avaliar esse tipo de sistema.
Caso os índices de desempenho do modelo do sistema modificado apresentem melhora em relação a os índices do modelo do sistema antes das modificações, então a implementação das alterações no sistema real podem ser realizadas com certa garantia.
Em este capítulo sera descrito como o algoritmo de escalonamento do Linux e algumas características do gerente de memória podem ser modelados utilizando o formalismo SAN.
A abordagem modular oferecida por esse formalismo é bastante atrativa quando se deseja modelar sistemas que possuem comportamento paralelo, como no caso de o algoritmo de escalonamento do Linux.
A principal idéia do modelo proposto e a modelagem do comportamento de apenas um processo no sistema, porém considerando a influência que outros processos possam vir a ter sobre o mesmo.
O modelo proposto e composto por P processadores e por um processo.
Para a análise de as (taracterísticas do gerente de memória, alguns autômatos auxiliares, que serão explicados no decorrer deste capítulo, foram adicionados ao modelo.
De essa forma, ha um autômato que representa o comportamento do processo modelado nos diversos processadores do sistema.
Logo, o tamanho deste autômato depende do número de processadores no sistema.
O processo pode se encontrar num determinado estado referente a um determinado processador, como por exemplo, estar na fila de processos prontos ou estar executando neste processador.
Ja os processadores são representados por diversos autômatos independentes.
Cada processador pode estar executando qualquer processo ou o processo que foi modelado.
Alem disso;
Os processadores podem estar executando o algoritmo de balanceamento de carga e ate mesmo podem se encontrar num estado de erro;
Para fins de verificação do comportamento do sistema na presença de falhas.
Em as próximas seções serão apresentados em detalhes os modelos desenvolvidos;
Bem como a parametrização dos mesmos;
Ou seja; O modo como foi feita a atribuição das taxas aos eventos dos modelos.
Esta seção lista todos os possiveis eventos que modificam os estados dos autômatos;
Onde i representa o i-esimo processador:
Sia; O processo ira executar operações de entrada e saída;
Fio; O processo terminou de executar operações de entrada e saída e foi inserido na fila de processos prontos;
Se¡ -- o processo foi escalonado;
Fts; O processo terminou sua fatia de tempo;
R; -- o processo foi &quot;movido «para a fila de prontos;
Fe¡ -- o processo terminou sua execução;
Mpei¡ -- o processo estava na fila de expirados e foi migrado para o j-ésimo processador através do balanceamento de carga periódico;
Miei¡ -- o processo estava na fila de expirados e foi migrado para o j-esimo processador através do balanceamento de carga quando o último estava ocioso;
Mpfi¡ -- o processo estava na fila de ativos e foi migrado para o j-ésimo processador através do balanceamento de carga periódico;
Mm¡ -- o processo estava na fila de ativos e foi migrado para o j-esimo processador através do balanceamento de carga quando o último estava ocioso;
Cp¡ -- o i-ésimo processador falhou;
Mam -- outros processos foram migrados para o i-esimo processador quando o mesmo estava ocioso;
Sp¡ -- o balanceamento de carga periódico e executado;
Fpi -- outros processos foram migrados para o i-ésimo processador quando o balanceamento periódico foi executado;
Tdi -- o escalonador não encontrou um processo para escalonar e ficou ocioso;
Sm -- o escalonador escolheu outro processo para executar;
Fm -- algum processo terminou sua fatia de tempo ou sua execução.
A Figura 4.1 apresenta o modelo SAN de um processo numa máquina com 2 processadores e sua tabela de eventos.
O autômato Processo e composto por os seguinte estados:
Ri, representando que o processo esta na fila de ativos (pronto para ser escalonado);
Epw, representando que o processo esta na fila de expirados (acabou sua fatia de tempo e esta esperando para &quot;voltar «para a fila de ativos);
Emid, representando que o processo esta executando;
10m, representando a situação em que o processo esta esperando por alguma operação de entrada e saída;
En, representando que o processo terminou sua execução e não faz mais parte do sistema.
É importante salientar que a Figura 4.1 mostra o comportamento do processo num sistema com apenas dois processadores (Pa) e Pim).
Isto foi feito apenas para efeito de simplificação, de modo que a figura fosse apresentada de uma forma clara.
Para representar um sistema com mais processadores e necessário replicar os estados Ri», 10 a), Emil) e Epil) e as transições correspondentes.
O modelo proposto permite que o processo possa ser configurado das mais diversas maneiras.
Caso deseja- se que o processo seja I/ O-bound, por exemplo, basta ajustar as taxas de maneira correta.
Em este caso, a taxa da transição de Ezm para 10 V) será maior do que a taxa da transição de Exam para Epm pois o processo tenderá a executar mais operações de entrada e saída.
Como um processo I/ O-bound recebe uma prioridade maior do que um processo CPU-bound, a taxa de transição de Rm para Exa) sera maior, ou seja, ele Vai executar mais constantemente.
Alem de definir tipos de processos (CPU-bound, I/ O-bound e processos de tempo real), também e possível definir a prioridade do processo.
Com isso, pode- se analisar diversas configurações que um processo no Linux pode possuir.
Estas questões serão explicadas mais detalhadamente na Seção 4.5.1.
Como foi descrito anteriormente, o conjunto de estados Rm,[ Om, Earl «e Epli) são incluídos no modelo para cada processador no sistema.
Apesar de haver apenas uma fila para operações de entrada e saída no Linux, e necessário que exista um estado IOM para cada processador modelado mesmo sabendo que ele representa exatamente a mesma situaçao.
Se o antômato Processo tivesse apenas um estado global IO, seria impossível saber em qual fila o processo deve ser inserido após executar suas operações de entrada e saída.
Como foi mencionado no Capítulo 3, o Linux oferece algumas políticas de escalonamento para processos de tempo real (SCHED_ FIFO e SCHED_ RR) apesar de não ser um sistema operacional de tempo real.
Processos de tempo real que utilizam a política SCHED_ RR são similares a processos I/ O-bound ou CPU-bound, porém possuem sempre uma maior prioridade.
Então, o modelo apresentado na Figura 4.1 tambem pode ser utilizado para descrever processos de tempo real que possuem a política SCHED_ RR.
Processos de tempo real que utilizam a política SCHED_ FIFO não são preemptados, ou seja, deixam o processador somente quando bloqueiam, liberam explicitamente ou quando terminam sua execução.
O modelo descrito na Figura 4.1 possui a transição ftsi, a qual representa a preempção do processo.
Por esse motivo, este modelo só pode ser utilizado para representar esse tipo de processo de tempo real caso as taxas relativas à preempção do processo e as transições que saem do estado Epi «sejam iguais a 0.
Mesmo assim, foi construído um modelo específico para Verificar processos de tempo real com a política SCHED_ FIFO (Figura 4.2).
A Figura 4.3 apresenta o modelo SAN de dois processadores e sua tabela de eventos.
Um processador pode se encontrar nos seguintes estados:[
Bm, representando que o processador está.
No caso de um processo de tempo rea1 que utiliza a política SCHED_ FIFO (ver Figura 4.2), os estados dos autômatos dos processadores permanecem inalterados.
A unica diferença e que deve- se eliminar os eventos que não fazem parte das características deste tipo de processo, i.
e, mpeij, miei¡ e ftsi.
É importante lembrar que caso deseja- se modelar um sistema numa máquina Em uma, a latência de memória é diferente para cada nodo.
Em o modelo, a latência de memória é representada por o evento fc.
Este evento pode possuir valores diferentes para cada processador modelado.
Então, e possível representar diferentes tempos de acesso à memória.
Como um processo pode ser migrado de um processador para outro e como é possível distinguir a latência de memória para cada nodo, e possível verificar se vale a pena ou não migrar um processo de um nodo para outro.
Se um processador esta ocioso e outro esta sobrecarregado, parece ser melhor migrar processos mesmo que eles demorem mais para acessar seus dados da memória.
Em relação a os índices de performabilidade, foi incluído o estado Erll) para representar um erro no processador.
Em o modelo não e especificado que tipo de erro ocorre, mas o importante é que quando o processador vai para este estado, significa que ele não está mais funcionando (estado absorvente).
Em o caso, o sistema deve perceber isto e continuar funcionando normalmente.
O objetivo é verificar o comportamento do sistema na presença de falhas (performabilitg).
Uma conseqüência desta abordagem e que não é possível encontrar uma solução estacionaria para o problema, já que ha um estado absorvente.
O Processo tambem possui esta característica.
Uma vez que o processo termina sua execução, ele vai para o estado En, de onde não sai mais.
Uma possível alternativa para isto é supor que o processador pode ser consertado, voltando a funcionar normalmente e o processo poderia começar sua execução rlovamente.
Uma outra alternativa seria o sistema identificar a falha e mover o processo para um processador ativo.
Esta seção apresenta como foi feita a atribuição de valores para as taxas dos eventos do modelo.
Alguns parametros foram obtidos através de bcnchmarks, enquanto outros são variaveis ou constantes do proprio Linux, como por exemplo, a fatia de tempo que um processo possui para executar.
O benchmark utilizado foi o LNIBench, executado num ltanium2 com 4 processadores e num Hp Superdome com 12 processadores.
A versão do kernel utilizada foi a 2.6.11 (com o patch para ia64).
Além disso, outro patch foi utilizado, o qual acrescenta informações extras sobre o escalonamento dos processos no diretório/ pmo Utilizando tanto o LNIBench quanto os patches acima mencionados, os seguintes Valores foram atribuídos aos eventos (todas as taxas são dadas em milisegundos):
Rftsl e rfní:
Em o Linux, o tinzcslicc varia de 10 ate 300 ms..
De acordo com o tipo do processo, o timexslice e diferente.
Em os modelos utilizados neste trabalho, e assumido que um processo I/ O-bound possui timeslice igual a 200 ms e um processo CPU-bound possui timeslice igual a 100 ms;
Psp¡ É.
O intervalo padrão de balanceamento na versão 2.6.11 do Linux e 200 ms..
Este foi o valor utilizado nos modelos deste trabalho, porém seria interessante alterar este valor a fim de avaliar como o sistema iria se comportar;
Rsm: Rsaf.
Considerando 1 ins para o Linux escalonar um processo (valor obtido através de benchmark).
Como, as vezes, o proce so modelado e selecionado para executar e outras Vezes outros processos são selecionados, esta taxa depende de rsel.
Considerando 0.8 ms o tempo para executar o algoritmo de balanceamento de carga (valor obtido através de benchmark).
Quando este algoritmo é executado não significa que ocorreu uma migração.
A migração ocorre apenas se o sistema não esta balanceado;
Rmprij, mm», rmpei] e nueva OIT* Considerando N o número de processos e Np o número de processadores no sistema.
Cabe salientar que é assumido que há 50 processos por processador;
O processo modelado precisa esperar que todos os outros processos que ainda possuem timeslice terminem suas fatias de tempo para que ele seja movido para a fila de processos prontos (estado Rm).
Além disso, outras taxas são dadas de acordo com as características que se deseja verificar:
Tsw¡ Esta taxa precisa ser maior que pftsl se o processo e I/ O bound, caso contrário o processo e CPU-bound;
Rfwl: Em praticamente todos os modelos, foi considerado que uma operação de entrada e saída demora 1 segundo para ser efetuada;
Rm: De acordo com o tipo de processo, a chance de ele executar (sua prioridade) varia.
Alem disso, é necessário definir quantos processos no sistema possuem prioridade maior, menor e igual a prioridade do processo modelado.
O cálculo desta taxa será explicado em detalhes na Seção 4.5.1;
rap¡. Esta taxa e utilizada para testes de performabilidade, ou seja, quando deseja- se analisar o comportamento do sistema quando um ou mais processadores falham;
Para definir as taxas rss, e rs», e rlecessario saber primeiramente quantos processos possuem prioridade maior, igual ou menor do que o processo modelado.
Supondo y 2 processos com maior prioridade, ac:
Processos com igual prioridade e 2:
Processos com menor prioridade.
Como o processo modelado possui prioridade maior que qualquer processo z, então podemos descartar esta variavel.
Por definicão a probabilidade dos processos se encontrarem na fila de processos prontos (Rad) e de 50%.
Como os processos y sempre executam antes do processo modelado, então não pode haver nenhum de eles na fila de processos prontos para que o processo modelado possa executar.
Em outras palavras, a probabilidade de não haver ninguém na fila de prontos é?
Ainda deve- se levar em conta os processos que possuem a mesma prioridade do que o processo modelado, ou seja, deve- se saber qual a chance do processo ser escolhido entre todos de mesma prioridade.
Isto e definido da seguinte forma:
A probabilidade de haver apenas o processo modelado na fila Ri «e (O, 5) e a chance de ele ganhar o processador é 1;
A probabilidade de haver 1 processo além de o processo modelado na fila Ri «é (O, 5) 2 e a chance de ele ganhar o processador e à;
A probabilidade de haver 2 processos além de o processo modelado na fila Ra) é (0,5) 3 e a chance de ele ganhar o processador é (33,3%),· Ate a probabilidade de todos os processos estarem na fila Rm ser «e a chance de ele ganhar o processador ser E;
Fazendo o somatório ponderado de todas essas chances do processo modelado ganhar o processador, chega- se aproximadamente à Então, a taxa me, pode ser definida como (O, 5) y 1 Como foi mencionado anteriormente, rs», 2 1 -- 11,61;
Em relação a o gerente de memória, o que sera analisado é o comportamento do processo quando ele migra de nodo.
Como foi explicado no Capítulo 3, a distância entre os nodos gera diferentes tempos de acesso a memória para os processos.
Além disso, duas propostas para a migração de páginas foram descritas (Seção 3.2.3).
Para a primeira proposta, onde o objetivo é mover toda a área de mernória do processo juntamente com o mesmo, foi criado um autômato adicional responsavel por contar quantas vezes o processo migrou de nodo no sistema (Figura 4.4).
Corn isso e possível saber qual o impacto que o tempo de transferência da área de memória do processo tera sobre o tempo de execução do mesmo.
Isso é feito adicionando- se esse tempo de transferência a taxa de termino do processo (rm).
Note que os eventos associados as transições do autômato são apenas aqueles contador avança uma posição.
Além disso, é importante ressaltar que como não é possível criar um contador infinito, e necessário limitar o tamanho do autômato (JV).
O autômato deve ter um tamanho tal que não influencie no resultado da análise, ou seja, a probabilidade do autômato se encontrar no final do contador deve ser bastante pequena.
Em relação a segunda proposta, onde o objetivo e mover as páginas sob demanda, ou seja, à medida que o processo necessita das mesmas, dois antômatos foram adicionados ao modelo (Figura 4.5).
A idéia da abordagem utilizada e a de mover porcentagens da área de memória do processo.
Em a Figura 4.5, o antômato PercentageMemory representa esta idéia.
Inicialmente, como o processo e toda a área de memória do mesmo se encontra no mesmo nodo, o autômato PercentageMemory deve estar no estado 100, ou seja, o processo tem acesso a 100% da sua área de memória no nodo onde se encontra.
Quando o processo migrar de nodo, o autômato PercentageMemory estará no estado 0, pois o processo tem 0% da sua área de memória no nodo para o qual o processo foi migrado.
A partir desse momento, quando o processo for executar, e necessário que parte de sua área de memória seja migrada para o nodo onde ele se encontra.
É neste instante que ocorre a interação com o autômato CounterSlice.
Para cada porcentagem de memória que e migrada, o autômato CounterSlice avança uma posição, ou seja, este autôrnato é responsavel por guardar quantas &quot;porções «de memoria já foram migradas entre nodos.
Em o momento que toda a memoria do processo for migrada o autômato CounterSlice se mantern no rnesmo estado, pois não esta ocorrendo migração de páginas.
De essa forma, e possível saber qual o impacto que a migração dessas &quot;porções «de memória tern sobre o tempo de execução do processo.
Assim como na primeira proposta, o gasto com a transferência e adicionado a taxa 1 «fel.
Vale lembrar que mesmo após atingir o estado 100, o processo pode ser migrado novamente, tendo que voltar a migrar &quot;porções «de memória para o nodo onde se encontra.
Em esse momento, o autômato CounterSlice volta a contabilizar a quantidade de &quot;porções «que foram migradas.
Outra questão importante é que o processo não precisa ter 100% de sua área de memória no nodo onde se encontra para terminar sua execução.
Pode ocorrer a situação onde ha a necessidade de migrar apenas 25% da área de memória pois, ao ser migrado novamente, o processo só usa uma fatia de tempo e termina, por exemplo.
É importante salientar que na Figura 4.5 esta sendo modelado que a &quot;porção «de mernória que sera migrada representa à da área de memória do mesmo.
Este autômato pode ser remodelado para representar &quot;porções «menores ou maiores de memória.
Em este (zapítulo foi apresentado o modelo analítico proposto para a analise de algumas características do sistema operacional Linux utilizando o formalismo de Redes Autômatos Estocásticos.
Pode- se notar que o formalismo se adaptou bem ao problema, ou seja, a modularidade provida por SAN facilitou a modelagem do sisterna.
É importante ressaltar que o tamanho do espaço de estados global e motivo por o qual existe apenas um processo modelado e não diversos processos.
A ferramenta PEPS (ver Apêndice A), a qual foi utilizada para extrair os índices de desempenho e confiabilidade, resolve sistemas com no maximo 60 milhões de estados globais aproximadamente.
Caso fossern modelados diversos processos com os diversos processadores, incluindo os autômatos auxiliares para a analise do gerente de memória, o conjunto de estados globais ultrapassaria o tamanho máximo que a ferramenta suporta, impossibilitando efetuar as analises.
Índices de Desempenho e Confiabilidade Em este capítulo serão apresentados os resultados obtidos através dos modelos analíticos propostos, bem como de simplificações feitas nos modelos, os quais serão explicadas na próxima seção.
A principal ideia é aplicar os modelos para máquinas Em uma a fim de obter alguns índices de desempenho.
Além disso, serão analisadas situações com as configurações atuais do Linux e com algumas novas propostas, com o intuito de obter índices de desempenho que possam vir a contribuir com futuras alterações no Linux.
O modelo proposto no Capítulo 4 e uma abordagem genérica que descreve parte do algoritmo de escalonamento do Linux e características do gerente de memória do mesmo.
Dependendo do tamanho do sistema que se deseja modelar, o conjunto dos estados globais pode ser bastante grande.
No entanto, e possível desenvolver modelos menos complexos, os quais podem ser resolvidos mais facilmente, baseados no modelo genérico.
Então, e possível obter índices específicos de desempenho e confiabilidade de uma maneira mais direta.
Por exemplo, para obter informações sobre migração de processos do tipo quanto tempo demora para o processo nzigrar pela primeira vez, é possível adaptar o modelo generico.
Em o modelo genérico o conjunto de estados RVAlm Em a Figura 5.1, o estado Ã/ Iw representa que o Processo migrou do processador 1 para o processador 2.
Note que os eventos sincronizantes do modelo genérico min;
E mpng passam a ser um único evento local (mrlg).
Analogamente, os eventos TÍLÍ6] 2 e mpeg passam a ser outro evento local (meu).
De essa forma, esses eventos sicronizantes também não aparecem no novo autômato do processador (Figura 5.2).
Essas modificações ocorreram pois, como mencionado anteriormente, não e necessário modelar o sistema completo dependendo da situação que se deseja analisar.
E importante ressaltar que se houverem outros processadores no sistema, não ha a necessidade de adicionar novos estados para representar os novos processadores caso as taxas de migração para todos os processadores forem iguais.
No caso de haver diferentes taxas de migração, um estado deve ser criado para cada processador que possua taxa de migração diferente.
Note que essa nova abordagem reduziu o número de estados do modelo.
Em o modelo genérico o autômato Processo possui (Mn P)+ 1 estados e os autômatos dos processadores possuem 64.
Em esta seção, serão apresentados os resultados numéricos obtidos para os modelos propostos nesta dissertação.
Os resultados dos modelos foram obtidos utilizando a ferramenta PEPS executada numa máquina Intel Xeon 2.2 GHz sobre o Linux Redhat 9.
Primeiramente, os resultados que serão apresentados ate a Seção 5.2.5 foram obtidos a partir de uma máquina NUNIA com 4 processadores, organizada em 4 nodos e 2 níveis de acesso à memória.
Cada nodo é composto por apenas um processador.
Um processo executa 25% 1 mais lento num processador (nodo) em o qual o processo não foi inicialmente criado.
Esta perda de desempenho ocorre por o fato do processo gastar tempo para acessar seus dados, os quais estão na área de memória do nodo onde o processo foi criado.
A Figura 5.3 ilustra esta máquina.
O Linux criara, para esta máquina, a hierarquia de dominios de escalonamento apresentada na Figura 5.4.
Um outro fator importante é que se assume que o processo modelado foi criado no processador 1.
Logo, se ele for migrado para um processador em outro nodo, havera uma queda de desempenho devido a o aumento no tempo gasto por o processo para acessar seus dados na memória.
A primeira analise diz respeito ao comportamento de um processador no sistema.
Para este teste apenas o autômato do processador (Figura 4.3) foi utilizado, pois deseja- se saber apenas índices referentes ao mesmo.
De essa forma, uma analise estacionaria foi feita sobre o modelo a fim de descobrir qual a probabilidade do processador se encontrar em cada um dos seus respectivos estados.
A Tabela 5.1 apresenta os índices de desempenho quando o processo &quot;modelado «é CPU-bound, enquanto que a Tabela 5.2 apresenta os índices de desempenho quando o processo &quot;modelado «e I/ O-bound.
CPU-bound, tem maior prioridade e tívneslice, portanto tendem, numa análise estacionária, a Consumir mais tempo de CPU.
Além disso, pode- se perceber que na maior parte do tempo o processador está executando algum processo (EN+ É claro que isso ocorre pois nesta análise o processador praticamente não fica ocioso (IB).
É possível executar outros testes onde possa haver uma maior possibilidade do processador se encontrar ocioso.
Em esta analise, os modelos apresentados nas Figuras 5.1 e 5.2 foram utilizados.
Com estes modelos é possível saber quanto tempo demora para o processo migrar pela primeira vez ou a probabilidade do processo terminar no processador onde foi criado sem ser migrado para nenhuma outra CPU, por exemplo.
A Figura 5.5 apresenta a probabilidade de um processo CPU-bound e de um processo I/ Obound migrarem pela primeira vez.
Processos I/ O-bound executam mais operações de entrada e saída (estado IO), enquanto processos CPU-bound executam suas fatias de tempo e vão para a fila de processos expirados mais frequentemente (estado Ep).
Como mencionado no Capítulo 3, processos que estão na fila de processos expirados têm mais chance de serem escolhidos para migrarem do que outros processos.
Por outro lado, processos I/ O-bound possuem maior prioridade e maior fatia de tempo.
De essa forma, inicialmente um processo I/ O-bound pode ter mais chance de migrar por o fato de ganhar o processador mais freqüentemente.
Porem, a medida que o tempo passa, um processo I/ O-bound tende a estar mais tempo executando operações de entrada e saída (estado IO).
Este comportamento pode ser observado na Figura 5.5.
Como um processo I/ O-bound gasta mais tempo executando operações de entrada e saída e conseqüentemente fica menos tempo da fila de processos expirados, ele tende a demorar mais para ser migrado para outro processador.
Isso ocorre pois um processo I/ O-baund fica pouco tempo I/ Orbound (baixa prioridade) 4-I/ O-bnund (ana prioridade) «x.
Se a chance do processo migrar fosse alta, este mesmo processo teria mais chance de migrar, diminuindo sua probabilidade de terminar no processador o11de foi criado.
A Figura 5.7 apresenta a mesma ideia do gráfico da Figura 5.6, porém avaliando um processo CPU-bound.
Note que o Comportamento é bastante similar, ou seja, o processo de mais alta prioridade possui maior probabilidade de terminar no processador onde foi criado.
Em a Seção 3.1.1 foram descritas as políticas de escalonamento do sistema operacional Linux.
Como foi mencionado neste trabalho, o Linux não é um sistema operacional de tempo real, porém ele provê algumas políticas de escalonamento para esse tipo de processo:
SCHED_ FIFO e SCHED_ RR.
Em a Seção 4.2.1, apresenta- se o modelo para representar um processo de tempo real que utiliza a política SCHED_ FIFO.
Para a política SCHED_ RR é utilizado o modelo generico descrito na Seção 4.2.
A Figura 5.8 apresenta os resultados destes tipos de processos.
Além de os processos de tempo real, foi adicionado ao grafico o desempenho de um processo CPU-bound;
Isso foi feito para ressaltar o Comportamento dos processos de tempo real.
Como pode ser observado, os processos de tempo real tem mais chance de terminar do que o processo CPU-bound.
Esse fato pode ser observado naturalmente, visto que processos de tempo real possuem a prioridade mais alta entre os processos.
Como um processo que possui a política SCHED_ RR possui fatias de tempo, ou seja, ele perde o processador periodicamente, seu desempenho é inferior a um processo com as mesmas características porem, que trabalhe com a politica SCHED_ FIFO.
Este último não possui fatias de tempo, logo não pode ser preemptado.
Ele só libera a CPU quando bloqueia, libera explicitamente o processador ou quando termina sua execução.
É importante ressaltar que os tres processos analisados possuem exatamente as mesmas caracteristicas, ou seja, tem a mesma probabilidade de executarem operações de entrada e saída, a mesma probabilidade de terminarem, etc..
A diferença entre eles esta na política de escalona mento utilizada e em suas prioridades de execução.
Sabe- se que no algoritmo de balanceamento de carga do Linux uma vez que um processo é migrado de um nodo para outro, não existe esforço algum para trazer este processo de volta ao nodo de origem.
Em máquinas Em uma, é interessante manter os processos nos nodos onde suas áreas de memória foram alocadas para não haver perda de desempenho.
Muitos pesquisadores tem focado bastante nesta questão, e alguns patches especificos para máquinas NUNIA buscam melhorar a afinidade de nodo oferecida por o Linux.
Um desses patches, por exemplo, acrescenta na estrutura que representa os processos um campo chamado node, que indica onde esta alocada a memória daquele processo.
De essa forma, caso o processo seja migrado para outro nodo, ele sera atraído de volta para o nodo inicial por o balanceador de carga A mesma ideia foi realizada no modelo analítico, onde o processo, após migrar para outro nodo, sera atraído novamente para o nodo de origem.
A Figura 5.9 apresenta o resultado desta avaliação.
A o final de 30 segundos de execução, o processo que possui afinidade de nodo tem aproximadamente 2% a mais de chance de terminar sua execução do que o processo que executa normalmente, sem afinidade de nodo.
Em uma primeira analise, este ganho pode parecer pequeno, mas deve- se notar que foi analisada a probabilidade de término em apenas 30 segundos.
O grafico apresenta uma tendência a aumentar essa diferença a Inedida que o tempo passa.
Obviamente essa diferença cresce até certo ponto, pois em algum instante os dois processos terão 100% de chance de terminar, não havendo diferença entre eles.
Porem, o importante e perceber que a abordagem proposta por pode trazer um ganho no desempenho.
Além disso, é importante ressaltar que um processo não migra muitas vezes num sistema real.
Caso um processo migrasse diversas vezes durante seu tempo de execução, a diferença de desempenho poderia ser bem mais significativa.
Como foi mencionado no Capítulo 2, performabilidade e a capacidade de um sistema operar na presença de falhas.
Para verificar tal característica, foram introduzidas falhas nos processadores modelados.
As falhas modeladas foram as seguintes:
Todos os processadores estão funcionando (K O);
O processador 1 falha;
Um processador falha;
Os processadores 1 e 2 falham (K 2);
Os processadores 1, 2 e 3 falham (K 3);
Os processadores 2, 3 e 4 falham (K 3*).
A Figura 5.10 apresenta a probabilidade de termino de um processo r1as diferentes configurações de falhas citadas.
Como foi dito no começo deste capítulo, é assumido que o processo foi criado no processador 1.
Também foi mencionado que o processo executa 25% mais lento nos processadores 2, 3 e 4 em comparação ao processador 1 por causa de as diferentes distâncias a memória.
Quando um processador falha, caso o processo modelado estiver neste processador, ele sera migrado para outro processador.
Esta situação teve que ser modelada, caso contrario o processo não executaria mais, impossibilitando a analise.
Pode- se perceber que para K 2 0, K 2 1* e K 2 2* o desempenho do processo se comporta de maneira bastante similar.
Em estes casos, o processador 1 não falha, por isso o desempenho do processo não deveria se comportar de maneira diferente.
Ja no Caso K $= 3*, ha LlIIl pequena queda no desempenho.
Isso pode ter ocorrido por o fato de haver apenas 1 processador funcionando no sistema.
De essa forma, o processo não tem chance de migrar para nenhuma outra CPU.
Para os casos K 2 1, K 2 2 e K 2 3 nota- se uma queda gradual no desempenho.
Como nestes casos o processador l sempre falha, o desempenho do processo tende a decair pois, como o processo foi criado no processador 1, no caso de ocorrer uma migração o tempo para o processo acessar sua área de memória sera maior, causando um queda no desempenho.
É importante salientar que esta se assumindo falha apenas eni um ou mais processadores.
Memória, barramento e outros componentes do sistema continuam a funcionar em qualquer situação.
A idéia de falhar um processador está servindo basicamente para forçar o processo a ser migrado para outro processador, fazendo com que ele tenha que acessar sua área de memória de uma distancia maior.
Como foi mencionado no início deste capítulo, a principal ideia e aplicar o modelo para diferentes máquinas Em uma.
A Figura 5.11 apresenta uma máquina que sera utilizada para comparar o atual algoritmo de balanceamento de carga do Linux com a estrategia que foi descrita na Seção 3.1.4.
Esta máquina possui quatro nodos e três 11 íveis de acesso a memória.
Como pode ser observado na Figura 5.11, não esta definida a quantidade de processadores por nodo.
Em a verdade, uma pequena alteração foi feita no modelo utilizado para esta analise.
Cada processador sera analisado como se fosse um nodo do sistema, ou seja, cada processador representará vários processadores do mesmo nodo.
De essa forma, pode ocorrer migração de um processador para ele mesmo, representando que o processo migrou para algum processador do mesmo nodo.
Quando ocorrer uma migração entre processadores diferentes, isto indica que um processo migrou de um nodo para outro.
Essa alteração reduz significativamente o número de estados globais do modelo.
Linux e com o algoritmo proposto em, onde o Linux levaria em conta os diversos níveis de acesso a memória para criar a hierarquia de domínio de escalonamento ade uada.
A Figura 5.12 apresenta o desempenho de um processo executando quando o Linux reconhece apenas dois níveis de acesso a memória (3 níveis de acesso à memória -- 2 sched domains) e quando o Linux reconhece a topologia real da maquina (3 níveis de acesso à memória -- 3 sched domains).
Note que a nova abordagem apresenta um melhor desempenho do tempo que o processo executa.
Isto ocorre pois quanto mais tempo o processo demorar para terminar, maior a chance de ele ser migrado de um nodo para o outro.
Quando uma migração ocorre, o atual algoritmo do Linux não considera as diferentes distâncias entre os diferentes nodos.
De essa forma, o processo pode levar mais tempo para terminar caso seja movido para um nodo mais distante.
Para que fosse possível verificar se a nova estratégia de balanceamento de carga iria melhorar o desempenho em máquinas com diversos níveis de acesso a memória, a mesma analise foi feita para outras duas máquinas Em uma:
A4 níveis de acesso à memória -- 2 sched domains e quando o Linux reconhece a topologia real da máquina (4 níveis de acesso à memória -- 4 sched do mains).
Se compararmos com o primeiro exemplo, o desempenho neste caso e melhor.
Como ha mais níveis de acesso a memória, ha uma maior chance do processo ser migrado para um nodo mais distante no atual algoritmo do Linux do que na abordagem proposta.
B6 níveis de acesso à memória -- 2.
Sched domains) e quando o Linux reconhece a topologia real da máquina (6 níveis de acesso à memória -- 6 sched domains).
Em este caso, o desempenho e ainda melhor do que nos outros dois casos.
Em este exemplo ha dois níveis de acesso a memória a mais de o que o caso anterior.
De essa forma, a chance de um processo ser migrado para um nodo distante e ainda maior.
Esta seção tem como foco analisar as propostas de alteração no gerente de memória que foram apresentadas na Seção 3.2.3.
Para esta analise, alguns novos autômatos foram modelados, como mostrado na Seção 4.6.
Em esta analise foi utilizada uma máquina Em uma com apenas dois nodos e dois níveis de acesso a memória.
De a mesma forma que a analise feita sobre a nova abordagem na hierarquia de domínios de escalonamento, cada processador sera analisado como se fosse um nodo do sistema, ou seja, cada processador representará varios processadores do mesmo nodo.
Assim, pode ocorrer migração de um processador para ele mesmo, representando que o processo migrou para algum processador do mesmo nodo.
Quando ocorrer uma migração entre processadores diferentes, significa que um processo migrou de um nodo para outro.
Como esta analise tratará de movimentação de memória entre os nodos, foram testadas diversas configurações (tamanhos de áreas de memória) a fim de verificar a probabilidade de termino dos processos em diversas situações.
Para todos os testes que foram efetuados, a situação onde ocorre migração de parte ou de toda a área de memória do processo apresenta melhor resultado do caso onde o processo executa com a atual configuração do Linux.
A Figura 5.15 apresenta a probabilidade de termino de processos de diferentes tamanhos e que possuem o mesmo comportamento.
Em esta analise foi verificada a abordagem onde todas as páginas do processo são rnigradas quando ocorre a migração entre nodo.
O grafico da direita mostra em detalhes os últimos 10 segundos de execução do grafico da esquerda.
Pode- se observar que a medida que o tamanho do processo aumenta, sua probabilidade de término diminui.
Isto ocorre devido a o custo de transferência das páginas de um nodo para outro.
Obviamente, quanto maior o tamanho do processo, mais tempo demora para suas páginas serem migradas.
A Figura 5.17 apresenta a probabilidade de término de um processo em tres situações:
Migração total do processo;
Migração sob demanda com fatia de tamanho 4 (25% da me mória);
Migração sob demanda com fatia de tamanho 10.
O grafico da direita mostra em detalhes os últimos 10 segundos de execução do grafico da esquerda.
O processo que executa com a abordagem de migração total das páginas apresenta um de sempenho pior do que os processos que executam com a abordagem de migração sob demanda.
Este resultado é bastante aceitável, uma vez que migrar todas as páginas de um processo e mais custoso do que migrar apenas aquelas páginas as quais o processo necessita.
Em relação a os processos que utilizam a abordagem de migração sol) demanda, pode- se notar que dividindo o processo em fatias menores, o desempenho aumenta.
Lsto ocorre pois e menos Custoso transferir pedaços menores da memória do que pedaços maiores.
Alem disso, a principal idéia dessa abordagem é a de transferir apenas as páginas que o processo necessita (sob demanda).
De essa forma, num sistema real, o tamanho da fatia poderia ser defirlido como o tamanho de uma migracãoxoval T 54MB 4?
Atlas 54 MB m &quot;ams sem mtgração Tempo «sem uma página de memória.
Tempo «sem ser melhor migrar o processo mesmo tendo que arcar com o custo de transferência de páginas.
Em esta seção, diversos indices de desempenho referentes ao escalonador e ao gerente de memória do Linux foram apresentados, bem como uma analise dos mesmos.
Alguns destes índices já foram utilizados como base para a modificação de algoritmos do Linux, como por exemplo, os índices referentes ao comportamento do processo no atual algoritmo de balanceamento de carga e no novo algoritmo proposto.
É importante salientar que os modelos analisados possuem praticamente as mesmas características em relação a o número de processos no sistema, tempo de execução dos processos, prioridade dos processos.
Logo, variar esses parametros a fim de verificar outras configurações do sistema seria bastante válido.
Pode- se variar, por exemplo, o número de processos no sistema, variar o tempo de execução dos processos ou ainda variar o intervalo de balanceamento de carga.
Alem disso, os tempos utilizados para a verificação dos modelos, como por exemplo, 100 segundos para os modelos referentes ao gerente de memória, foram definidos de acordo com a capacidade de processamento que a ferramenta PEPS permitia.
Houve um caso específico onde a ferramenta demorou aproximadamente 50 dias para resolver o modelo.
Cabe ressaltar que foi desenvolvido um trabalho comparando os modelos analíticos com modelos simulados do escalonador do Linux Os modelos simulados também apresentaram melhora de desempenho quando e comparada a versão atual do Linux com a versão modificada, Além disso, um trabalho específico do modelo do escalonador e outro específico do gerente de memória tambem foram desenvolvidos.
Conclusão Esta dissertação apresentou um modelo analítico do escalonador do Linux, bem como de algumas (taraeterísticas do gerente de memória do mesmo.
O principal objetivo deste trabalho foi o de mostrar que a utilização de modelos analíticos pode ajudar a responder diversas questões referentes ao sistema que esta sendo avaliado.
Por exemplo, verificar se uma modificação em algum algoritmo poderia ser implementada na pratica ou não.
O presente trabalho faz parte do projeto de pesquisa PeSO, onde o objetivo é estudar o Linux em máquinas Em uma, tornando o sistema operacional mais escalavel.
Os modelos apresentados auxiliaram na analise das propostas de modificações referentes ao balanceamento de carga e ao gerente de memória do Linux.
Além disso, diversos outros indices de desempenho foram analisados, como por exemplo, índices de performabiliclade.
Para que fosse possível modelar o paralelismo existente no sistema, foi utilizado um formalismo que permite modelar tal característica.
Diversos formalismos foram estudados para descrever o comportamento do Linux, sendo que SAN demonstrou ser o formalismo mais atrativo para este problema.
O uso de SAN tomou bastante clara a modelagem do comportamento paralelo, através de eventos sincronizantes e funções.
Isto não significa que outros formalismos como SPN, por exemplo, não pudessem ser utilizados.
A escolha do formalismo depende da adaptação do mesmo ao problema, alem da familiarização do modelador com o formalismo.
A partir de os resultados obtidos dos modelos, foi implementada uma nova versão do algoritmo de balanceamento de carga do Linux, o qual leva em conta os diversos níveis de acesso à memória que uma máquina possa possuir.
Em relação a o gerente de memória, ainda não foi implementada nenhuma nova versão de seu algoritmo no Linux, porem um trabalho analisando analiticamente as novas propostas de sua implementação já foi submetido para uma conferência internacional.
Ha ainda diversas questões que não foram abordadas na presente dissertação.
Com isso, vislumbram- se alguns trabalhos futuros.
Primeiramente, seria interessante comparar os resultados obtidos através dos modelos analíticos com resultados obtidos através de benchmarks específicos aplicados a nova versão do algoritmo de balanceamento de carga proposto.
Com isso, seria possível verificar os pontos onde o modelo se aproxima e os pontos onde o modelo se difere do sistema real.
A mesma ideia e valida para as propostas relativas ao gerente de memória.
Caso alguma dessas propostas ou ambas venham a ser implementadas, é importante comparar os resultados dos modelos com os resultados obtidos sob o sistema real.
Uma outra questão importante, e que não foi levada em conta nos modelos, é a memória cache.
Quando um processo vai executar pela primeira vez, seus dados são lidos da memória principal e são colocados na memória cache.
O tempo gasto com essa cópia não esta contemplado nos modelos.
Alem disso, quando um processo migra de processador este procedimento deve ser repetido, ou seja, seus dados devem ser copiados para a memória cache.
Os modelos assumem que o processo possui uma probabilidade ac de terminar no nodo N] e uma probabilidade y de terminar no nodo NZ Isto e feito para modelar os diferentes tempos de acesso a memória que um processo tera de acordo com o nodo onde se encontra.
Alem disso, a questão comentada na Seção 3.3 sobre o gerente de entrada e saida tambem não foi abordada.
Assumiu- se nos modelos que os processos gastam exatamente o mesmo tempo executando operações de entrada e saída estando em qualquer nodo do sistema.
Poderia ser interessante avaliar o desempenho do sistema assumindo que o dispositivo de entrada e saída se encontra em determinado nodo, gerando diferentes tempos de acesso ao mesmo.
De essa forma, para um processo que gasta muito tempo executando operações de entrada e saída, poderia ser mais vantajoso mantes- lo no nodo onde o dispositivo de entrada e saida se encontra, mesmo tendo que arcar com o aumento no tempo de acesso à memória.
Todas as avaliações efetuadas no presente trabalho possuem praticamente as mesmas características em relação a o número de processos no sistema, tempo de execução dos processos, prioridade dos processos.
De essa forma, seria interessante variar esses parametros a fim de verificar outras configurações que o sistema possa possuir.
Por exemplo, pode- se variar o número de processos no sistema, variar o tempo de execução dos processos e variar o intervalo de balance amento de carga.
Uma das principais contribuições deste trabalho pode ser vista como uma primeira tentativa de descrever analiticamente, utilizando SAN, uma realidade tão complexa e extrair índices de desempenho e confiabilidade.
Mesmo assim, os índices obtidos já fornecem informações bastante significativas e promissoras sobre o Comportamento do Linux, visando possíveis modificações en1 vista de um melhor desempenho do sistema.
