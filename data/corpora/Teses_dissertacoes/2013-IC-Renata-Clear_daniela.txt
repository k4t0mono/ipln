Muitas tarefas de Processamento da Linguagem Natural envolvem a previsão de um grande número de variáveis, as quais dependem umas das outras.
Métodos de predição estruturada são, essencialmente, uma combinação de classificação e de modelagem baseada em grafo.
Eles unem a competência dos métodos de classificação com a capacidade desse tipo modelagem reproduzir, compactamente, dados multivariados.
Os métodos de classificação realizam a predição usando um grande conjunto de features como entrada.
Conditional Random Fields (CRF) é um método probabilístico de predição estruturada e tem sido amplamente aplicado em diversas áreas, tais como processamento da linguagem natural, incluindo o Reconhecimento de Entidades Nomeadas (REN), visão computacional e bioinformática.
Sendo assim, neste trabalho é proposta a aplicação do CRF para o REN em textos da Língua Portuguesa e, sequencialmente, avaliar o seu desempenho com base no corpus do HAREM.
Finalmente, testes comparativos da abordagem determinada versus a similar da literatura foram realizados, ilustrando a competitividade e eficácia do sistema proposto.
Palavras-chave: Reconhecimento de Entidades Nomeadas, Conditional Random Fields, Processamento da Linguagem Natural, Língua Portuguesa.
A Extração da Informação (Ei) é uma importante tarefa na mineração de texto e tem sido amplamente estudada em várias áreas de pesquisa, incluindo o processamento da linguagem natural, recuperação de informação e mineração de dados na Web.
O Reconhecimento de Entidades Nomeadas (REN) é uma tarefa primordial na área de Ei, juntamente com a extração de relação entre Entidades Nomeadas (EN).
Segundo Nadeau, os termos que apresentam um ou mais designadores rígidos, num determinado texto, por exemplo, substantivos próprios, tais como nomes de pessoas, organizações e entidades locais definem as EN.
Dentro desse contexto, o REN em textos tem sido amplamente estudado por meio de métodos como aprendizagem supervisionada para classificar entidades do tipo pessoa, lugar e organização em textos ou, ainda, doenças e genes nos resumos das áreas médicas e biológicas.
Existem vários sistemas comerciais de REN, tais como AeroText, Rosette Entity Extractor (REX), ClearForest, Inxight, PalyAnalyst, e SRA NetOwl.
Tais sistemas utilizam um número significativo de regras hand- coded, que permitem obter um desempenho limitado, apenas aplicado a alguns de tipos de entidades sobre corpora de domínio restrito, como por exemplo, textos de notícias.
Esses métodos dependem de recursos caros e extensos para a etiquetagem manual, a qual realiza a identificação das entidades.
Dentro de a tarefa do REN, constata- se que a necessidade de segmentar e rotular sequências surge por diferentes problemas em vários campos da ciência.
Os modelos de Markov e as gramáticas estocásticas são largamente utilizados e baseiam- se em modelos probabilísticos para resolver tais problemas.
Em biologia computacional, por exemplo, esses modelos têm sido aplicados com sucesso para alinhar sequências biológicas, onde sequências homólogas, para uma conhecida família evolutiva, são identificadas e, posteriormente, é realizada uma análise da estrutura secundária de RNA.
Em Linguística Computacional e em Ciência da Computação, os Modelos de Markov e as gramáticas estocásticas têm sido aplicados para uma ampla variedade de problemas em processamento do discurso e do texto, incluindo segmentação tópica, etiquetagem, extração de informação e desambiguidade sintática.
Os Modelos de Markov de Máxima Entropia (MEMMs) são modelos de uma sequência probabilística condicional que atingem todas as vantagens acima.
Em os MEMMs, cada estado inicial tem um modelo exponencial que captura as características de observação como entrada e as saídas, uma distribuição sobre os próximos estados possíveis.
Estes modelos exponenciais são treinados por um método apropriado de dimensionamento iterativo no framework de máxima entropia.
Resultados experimentais publicados, anteriormente, mostram que o MMEMs aumentam a abrangência e duplicam a precisão relativa para os Modelos de Markov Ocultos em tarefas de segmentação.
MEMMs e outros modelos de estados finitos não geradores, baseados em classificadores do próximo estado (next-state classifiers), tais como os modelos de Markov discriminativos, compartilham uma fraqueza conhecida como o problema do viés dos rótulos (label bias problem):
As transições que deixam um estado competem apenas umas contra as outras, ao invés de competir contra todas as outras transições do modelo.
Em termos probabilísticos, as pontuações das transições são probabilidades condicionais dos próximos estados possíveis, dado um estado corrente e a sequência de observação.
Esta normalização por estado de pontuação de transição implica uma &quot;conservação da pontuação em conjunto «através de o qual todo o conjunto que chega a um estado deve ser distribuído entre os estados sucessores possíveis.
Em este contexto, surge o modelo denominado Conditional Random Fields (CRF), um framework de modelagem de sequência de dados que tem todas as vantagens dos MEMM, mas também resolve o problema do viés dos rótulos de uma maneira fundamentada.
A diferença crítica entre CRF e MMEM é que o MMEM utiliza modelos exponenciais por estados para as probabilidades condicionais dos próximos estados, dado o estado atual.
Já o CRF tem um modelo exponencial único para uma probabilidade conjunta de uma sequência de entrada de rótulos, dado uma sequência de observação.
Portanto, as influências das diferentes características em estados distintos podem ser tratadas independentemente umas das outras.
O CRF pode também ser entendido como um modelo de estado finito com probabilidades de transição não normalizadas.
Além disso, o CRF especifica uma distribuição probabilística bem definida sobre os possíveis rótulos, preparado por uma máxima verossimilhança.
CRF generaliza, facilmente, para as semelhanças das gramáticas estocásticas livres de contexto, que podem ser úteis em problemas tais como predição de estrutura secundária de RNA e o processamento de linguagem natural.
O termo chamado &quot;entidade», hoje amplamente utilizado em Processamento de Linguagem Natural, foi cunhado para a Sixth Message Understanding Conference (MUC6).
Em aquele momento, a MUC estava focada nas tarefas de Extração de Informação (IE), em as quais informações sobre atividades de empresas e relacionadas à defesa são extraídas a partir de textos não estruturados, tais como artigos de jornal.
Kripke afirma que a palavra &quot;Nome», na expressão Entidade Nomeada, tem como objetivo restringir a tarefa de que somente essas entidades, as quais podem estar relacionadas a um ou vários designadores rígidos, representam o referente.
Por exemplo, a empresa automotiva criada por Henry Ford em 1903 é referida como Ford ou Ford Motor Company.
Em a definição da tarefa, verifica- se a importância de se reconhecer as unidades de informação, expressões numéricas e expressões de porcentagem_ como exemplo de unidades de informação destacam- se os nomes de pessoas, organizações e nomes de locais;
Já as expressões numéricas são do tipo data, hora e dinheiro.
Identificar as referências a estas entidades, no texto, foi reconhecido como uma das subtarefas importantes de Extração da Informação e foi chamada de Classification and Recognition of Named Entities (RENC).
Lafferty et al.
Determinaram um modelo matemático probabilístico que descreve dois procedimentos de treino aplicando CRF.
O modelo apresenta o algoritmo de estimativa de parâmetros iterativos para CRF e, posteriormente, este é comparado com o desempenho dos modelos resultantes para os Modelos Ocultos de Markov e os Modelos de Markov de Máxima Entropia em dados sintéticos e em linguagem natural.
Os autores desse artigo expõem resultados experimentais e dados sintetizados mostrando que o CRF resolve a versão clássica do problema de viés do rótulo.
Mais significativamente, eles demonstraram que o desempenho do CRF é melhor que o desempenho dos modelos HMM e MMEM quando a distribuição dos dados tem dependências de ordem superior ao modelo.
Esses dados são confirmados através de resultados satisfatórios e, as vantagens reavidas dos modelos condicionais, a partir de avaliações dos HMM, MEMM e CRF com estrutura de estado idêntica às tarefas de etiquetar parte do discurso.
Os resultados da Conferência Internacional de Aprendizado de Máquina de outros trabalhos sobre Conditional Random Fields,, indicam que o algoritmo de CRF apresenta um dos melhores desempenhos para o REN_ com isto, esta dissertação tem como motivação o fato de:
O REN ter sido pouco explorado utilizando o método de aprendizagem supervisionada CRF para a língua portuguesa;
Não existir proposta de REN aplicando o CRF para identificar as EN e classificar- las de acordo com as dez categorias dos textos da conferência do HAREM.
O corpus do HAREM é considerado a principal referência na área de PLN, e caracteriza- se por ter um conjunto de textos anotados e validados por humanos (Coleção Dourada), o que facilita a avaliação do método em estudo;
E o método de CRF pode ajudar a identificar um maior número de EN, o que poderá ser verificado por meio de a comparação com outros sistemas.
O objetivo geral do trabalho é aplicar CRF para a tarefa de REN em corpus da língua portuguesa e avaliar comparativamente com outros sistemas que realizam REN, tendo como base o corpus do HAREM.
Para que o objetivo geral seja alcançado, a seguir serão apresentados os objetivos específicos:
Aprofundar o estudo teórico sobre CRF e sobre REN;
Verificar quais são as outras técnicas citadas na literatura para o REN;
Realizar um estudo sobre as features referenciadas em trabalhos literários para a área de extração da informação, a fim de gerar um modelo de CRF;
Aplicar o modelo de CRF gerado;
Avaliar a técnica de CRF para o REN;
Comparar os resultados obtidos após aplicar CRF, no corpus do HAREM, com outros métodos existentes, na literatura, que realizam REN Apresentaremos, no Capítulo 2, uma revisão dos trabalhos relacionados à pesquisa proposta e a aplicabilidade do CRF no reconhecimento de Entidades Nomeadas.
O modelagem do sistema, implementação e o processo de avaliação.
Os resultados obtidos com a avaliação dos testes bem como a análise de erros serão descritas no Capítulo 4.
Por fim, no Capítulo 5, serão apresentadas as considerações finais e trabalhos futuros.
Extração de informações (Ei) é a tarefa de encontrar informações estruturadas a partir de textos não estruturados ou semi-estruturados.
Já a tarefa de REN consiste em identificar entidades nomeadas, na sua maioria nomes próprios, a partir de textos de forma livre e classificar- las dentro de um conjunto de tipos de categorias pré-definidas, tais como pessoa, organização e localização.
O REN em textos que abordam os mais variados domínios, além de a extração de relações entre EN, é uma das tarefas primordiais dentro de a área de Ei.
Inicialmente, soluções para o REN dependem de padrões de regras trabalhadas manualmente, pois exigem experiência humana além de um trabalho intenso para a criação de tais padrões.
Adicionalmente, a criação de sistemas tem o objetivo de aprender automaticamente esses padrões de dados etiquetados.
Os Modelos de Markov Ocultos, modelos de Máxima Entropia e modelos de Markov de Máxima Entropia e são formalismos estatísticos de aprendizagem de máquina que realizam o REN.
Outros trabalhos sobre REN utilizam modelos matemáticos probabilísticos, denominados CRF, e, o qual é o formalismo desenvolvido nesta dissertação.
Em este capítulo serão apresentados os assuntos que se relacionam com o tema proposto.
Dentro de a pesquisa realizada, destacam- se fontes bastante referenciadas na literatura, além de outras atuais, descritas a seguir.
O trabalho de descreve uma nova abordagem do reconhecimento de Entidades Nomeadas Chinesas baseado em Conditional Random Fields.
Em a abordagem proposta, a estrutura do modelo foi desenhada com a forma de cascata, e o resultado é passado para um modelo principal onde se aplicará, a partir desse modelo, o reconhecimento de entidades como, por exemplo, nomes de pessoas e de organizações.
Ratinov e Roth investigaram a aplicação do Reconhecimento de Entidades Nomeadas a partir de a necessidade de usar o conhecimento prévio e decisões não locais para a identificação de tais entidades nomeadas num texto.
O artigo em apresenta a segunda edição de uma conferência que avalia sistemas, os quais aplicam REN para o português, o Segundo HAREM.
Especificamente, este trabalho aborda a trilha ReRelEN, que trata a detecção de relações semânticas entre Entidades Nomeadas.
A tarefa de atribuir uma sequência de rótulos para um grupo de sequências de observação surge em diferentes áreas, incluindo bioinformática, linguística computacional e reconhecimento da fala.
Por exemplo, considere a tarefa de processamento da linguagem natural de rotular as palavras constituintes de uma sentença.
Em esta tarefa, cada palavra é marcada com um rótulo que indica a sua etiquetagem morfológica adequada, como por exemplo, a indicação se a palavra em foco é um artigo ou uma preposição, resultando assim num texto anotado.
Um dos métodos mais comuns para a realização de tais tarefas de etiquetagem e de segmentação é a de empregar os Modelos de Markov Ocultos (HMM) ou o estado finito automático e probabilístico para identificar a maioria das sequências de rótulos nas palavras, mais facilmente, dada uma sentença.
Os HMM são uma forma de modelos generativos, que definem um conjunto de distribuição probabilística p (X, Y) onde X e Y são variáveis aleatórias, respectivamente, classificando uma sequência de observação e suas sequências de rótulos correspondentes.
A fim de definir uma distribuição conjunta desta natureza, os modelos geradores devem enumerar todas as possíveis sequências de observação.
Esta é uma tarefa que, para a maioria dos domínios, é intratável, a menos que os elementos de observação sejam representados como unidades isoladas, independente de outros elementos numa sequência de observação.
Mais precisamente, o elemento de observação, em algum dado instante, só pode diretamente depender do estado, ou rótulo, naquele momento.
Isto é um pressuposto necessário para um conjunto de dados um pouco simples, contudo a maioria das sequências de observação de palavras é melhor representada por várias características interagindo e por a longa distância de dependência entre os elementos de observação.
Esta é uma questão de representação de entre a maioria dos problemas fundamentais quando se rotula dados sequenciais.
Um modelo que suporte inferência tratável é necessário, no entanto, um modelo que represente os dados sem fazer suposições de independência injustificáveis também é desejável.
Uma maneira de satisfazer ambos os critérios é utilizar um modelo que defina uma probabilidade condicional p (Y| x) sobre uma sequência de rótulos, dada uma sequência de observação particular x, ao invés de uma distribuição conjunta sobre o rótulo e as sequências de observação.
Os modelos condicionais são usados para etiquetar uma nova sequência de observação x, selecionando a sequência de rótulo y que aumente a probabilidade condicional p (y| x).
A natureza condicional de tais modelos significa que nenhum esforço é desperdiçado em modelar as observações, e é livre de ter que fazer suposições de independências injustificadas sobre essas sequências.
Arbitrariamente, atributos de dados de observação podem ser capturados por o modelo, sem o modelador ter que preocupar- se sobre como esses atributos são relatados.
Conditional Random Fields (CRF), segundo Lafferty et al.
Em, é um modelo matemático probabilístico que tem o objetivo de etiquetar e segmentar dados sequenciais, baseados numa abordagem condicional descrita no parágrafo anterior.
O CRF é uma forma de modelo gráfico não direcionado que define uma única distribuição logaritmicamente linear sobre sequências de rótulos, dada uma sequência de observação particular.
A vantagem primária dos modelos de CRF sobre os modelos de Markov Ocultos é a sua natureza condicional, pois resulta no abrandamento de pressupostos independentes, necessários para os modelos HMM, a fim de assegurar uma inferência tratável.
Adicionalmente, os modelos de CRF evitam o problema de viés do rótulo, uma fraqueza exibida por os Modelos de Markov de Máxima Entropia e outros modelos de Markov condicionais baseados em modelos gráficos direcionados.
O CRFs supera ambos os modelos MEMM e HMM em número de tarefas de etiquetagem dada uma sequência de palavras.
Em, os autores definiram X como sendo uma variável aleatória sobre uma sequência de dados para serem etiquetados, Y como uma variável aleatória sobre uma sequência de etiquetas correspondentes.
As sequências X e Y podem ser representadas da seguinte forma respectivamente:
X $= e Y $ .
Todos os Yi componentes de Y são assumidos para variar ao longo de um alfabeto Y de rótulos finitos.
Por exemplo, X pode variar mais sobre sentenças de linguagem natural e Y variar sobre os rótulos de parte do discurso daquelas sentenças, sendo Y o conjunto de possíveis rótulos de parte do discurso.
As variáveis aleatórias X e Y são distribuídas conjuntamente, mas num quadro discriminativo, foi construído um modelo condicional p (Y| X) de observações pariadas e de sequências de rótulos.
Em função de as condições acima, surge a seguinte definição:
Seja G $= (V, E) um grafo tal que Y $= (Yv) v V de maneira que Y é indexado para os vértices de G. Então (X, Y) é um conditional random field, em casos, em os quais, condicionadas sobre X, as variáveis aleatórias Yv obedecerem propriedade de Markov com relação a o grafo:
Se o grafo G $= (V, E) de Y é uma árvore (de os quais uma cadeia é o exemplo mais simples), seus subgrafos de G são as arestas e os vértices.
Portanto, por o teorema fundamental dos campos aleatórios, a distribuição conjunta sobre a sequência de rótulo Y dado a X tem a forma onde x é uma sequência de dados, y uma sequência de rótulos e y| s é o conjunto de componentes de y associado com os vértices num subgrafo S. Assume-se que as features fk e gk são dadas e fixadas.
Por exemplo, uma feature de vértice Booleano gk pode ser verdadeira se a palavra Xi é uma letra maiúscula e a tag Yi é um nome próprio.
Sejam os seguintes parâmetros representados por os dados de treino função Objetiva para com distribuição empírica, então a de verossimilhança logarítmica é:
Embora isso englobe modelos semelhantes ao HMM, a classe dos Conditional Random Fields é muito mais expressiva, porque permite dependências arbitrárias sobre a sequência de observação.
Além disso, as características não precisam especificar completamente um estado ou uma observação.
De esse modo, espera- se que o modelo possa ser estimado a partir de menos dados de treino.
Pode- se assumir, neste caso, que as dependências de Y, condicionadas sobre X, formam uma cadeia.
Para uma estrutura em cadeia, a probabilidade condicional de uma sequência de rótulos pode ser expressa, concisamente, em forma de matriz.
Suponha que é um CRF dado por.
Para cada posição i numa sequência x de observação, é definida a variável aleatória da matriz| Y| x| Y| por através da fórmula:
A o simplificar algumas expressões, adicionam- se os estados, inicial e final, representados por:
Usando a função dada em, a probabilidade condicional de uma sequência de rótulo y é escrita conforme a notação abaixo:
As dependências de Y condicionadas sobre X formam uma cadeia linear, conforme a Figura 2.1.
Assim, para as formulações de cadeia linear de CRF convencional, uma cadeia de Markov de primeira ordem e unidimensional é assumida para representar as dependências entre as variáveis de etiquetas previstas, enquanto nenhuma dependência temporal é imposta entre as variáveis observadas.
Fonte: Lafferty, John;
McCallum, Andrew;
Pereira, Fernando.
Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.
Dando continuidade a pesquisa, tem- se como um dos propósitos deste estudo, aplicar CRF para o Reconhecimento de Entidades Nomeadas.
Portanto, a próxima seção apresenta uma descrição pormenorizada sobre REN.
Entidades Nomeadas (EN) compreendem- se como termos que apresentam um ou mais designadores rígidos, num determinado texto.
Alguns dos tipos mais comuns de entidades são substantivos próprios, tais como nomes de pessoas, organizações e entidades locais;
Temporais como datas, tempo, dia, ano e mês;
Entidades numéricas, tais como medições, percentagens e valores monetários.
Entidades de domínio numerosas e entidades de aplicações específicas não são consideradas como entidades nomeadas, como:
Peças e tipos de defeitos no setor de manufatura ou nomes de doenças e sintomas no setor da saúde.
O Reconhecimento de Entidades Nomeadas (REN) define- se como uma tarefa cujo objetivo é identificar as entidades nomeadas bem como sua posterior classificação, atribuindo uma categoria semântica para essas entidades.
Segundo Sureka et al.
As três principais abordagens para extração de entidades nomeadas são:
Sistemas baseados em regras, sistemas baseado em aprendizado de máquina e abordagens híbridas.
Sistemas baseados em regras, também conhecidos como sistemas baseados no conhecimento, consistem em definir heurísticas na forma de expressões regulares ou padrões linguísticos.
Um exemplo de uma regra ou heurística pode ser a presença de palavras como &quot;Incorporated», &quot;Corporation», &quot;Limited», entre outros, indicando a presença e terminar com um&quot;_ com», ou&quot;_ org &quot;ou&quot;_ edu «um endereço de e-mail.
Sistema baseados em regras também fazem o uso de dicionários ou léxicos que contêm, comumente, a ocorrência de termos ou palavras &quot;trigger».
Tais léxicos aumentam a precisão e o recall do sistema e.
Conforme Chatzis e Demiris, durante os últimos anos temos assistido a uma explosão de vantagens nos modelos de Conditional Random Fields, à medida que tais modelos conseguem alcançar uma previsão de desempenho excelente numa variedade de cenários.
Sendo assim, uma das abordagens de maior sucesso para o problema de predição de saída estruturada, com aplicações bem sucedidas, inclui o processamento de texto, a área da bioinformática e o processamento da linguagem natural.
A seguir serão apresentadas três conferências:
O MUC, ACE e o HAREM, as quais tratam da avaliação conjunta de sistemas de Reconhecimento de Entidades Nomeadas.
A Avaliação Conjunta consiste de uma atividade em a qual participam vários sistemas e tem como objetivo aprimorar o estado da arte da área, proporcionando pesquisas nas áreas julgadas necessárias, de acordo com a tarefa em questão.
Tais sistemas são avaliados e comparados quando executam uma mesma tarefa e seus resultados são, principalmente, recursos de avaliação que serão reutilizados como testes em outras pesquisas.
As conferências destinadas à avaliação de sistemas inteligentes, demonstraram uma importante ajuda no avanço da área de Processamento da Linguagem Natural, pois envolvem tarefas distintas na compreensão da língua.
Conferências que tratam tarefas de reconhecimento de entidades nomeadas e a identificação de relações entre estas entidades são apresentadas a seguir.
A conferência Message Understanding Conference (MUC) foi a primeira conferência que tratou a avaliação do Reconhecimento de Entidades Nomeadas.
Em o ano de 1987 foi realizada a sua primeira edição e teve como objetivo o desenvolvimento de uma avaliação conjunta na área de Extração de Informação (IE).
Em 1995, ocorreu a sexta edição do MUC, onde teve início a avaliação do REN para a língua inglesa.
Esta edição teve a sua peculiaridade em relação a outras edições, pois, as edições anteriores consideravam o Reconhecimento de Entidades Nomeadas como sendo uma parte da tarefa de Extração da Informação.
Em o Message Understanding Conference, o Reconhecimento de Entidades Nomeadas consistiu em anotar as entidades nomeadas em três tipos de categorias:
Enamex, Timex e Numex, as quais são descritas a seguir.
A categoria Enamex é formada por nomes próprios definidos por os tipos Pessoa, Organização e Local.
Por exemplo, nomes de pessoa ou de família, organização empresarial, organização não governamental, nomes de locais politicamente ou geograficamente definidos, entre outros.
A categoria Timex é uma expressão de tempo dividida em Data e Hora.
A data é uma expressão completa ou parcial em a qual se refere ao ano, mês ou dia.
O Time definese por uma expressão referente a o tempo, como o horário, por exemplo.
O Numex é uma expressão numérica formada por expressões denominadas Money (expressão monetária) e Percent (representando a porcentagem).
A sétima edição do MUC criou a tarefa de identificação de relações entre as categorias, chamada de Template Relation (TR).
Esta tarefa realiza a extração de fatos bem determinados em textos jornalísticos da língua inglesa.
Ainda nesta versão do MUC, as relações envolvendo a categoria Organização foram determinadas como funcionário_ de, produto_ de e localização_ de.
Automatic Content Extraction (ACE) foi a conferência que surgiu após o MUC-7.
A ACE teve início em 1999 com um estudo piloto para a língua inglesa, cujo objetivo foi verificar quais tarefas de Extração de Informação seriam avaliadas.
A ACE, no período de 2000 a 2001, realizou o Reconhecimento de Entidades Nomeadas por meio de a identificação e da classificação de entidades e das expressões anafóricas.
Tais expressões abrangeram, além de nomes próprios, descrições ou pronomes.
Esse processo foi determinado para as línguas inglesa e chinesa e denominou- se Entity Detection and Tracking (EDT).
O sistema de reconhecimento de relações caracterizou os anos de 2002 a 2003, iniciou- se o tratamento de relações para a língua árabe e, na sequência, em 2004, houve o reconhecimento de eventos.
O EDT contemplou, além de os tipos de categorias mencionadas no MUC, os tipos Facility e Geographical-Political Entity1 (GPE).
O primeiro tipo Facility expressa as categorias armas, veículos ou instalações, por exemplo, aeroporto.
Já o segundo, GPE, representa a supercategoria de Organização e Local, por exemplo, país.
A Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas, cuja sigla é denominada HAREM, é um evento de avaliação conjunta da língua portuguesa, com o objetivo de realizar a avaliação de sistemas reconhecedores de entidades mencionadas criadas por a Linguateca,.
O HAREM utiliza o termo Entidade Mencionada para designar nomes próprios, os quais são referenciados num texto.
Salienta- se que a expressão Entidade Mencionada tem a mesma denominação que o termo, utilizado no ACE, designado por Entidade Nomeada (Named Entities).
Em este trabalho será adotada a nomenclatura Entidades Nomeadas (EN -- Named Entities), como é proposto na conferência do ACE, o qual inclui na sua análise os substantivos comuns e sintagmas nominais relacionados aos nomes próprios identificados.
Todavia, os termos Em e REN são utilizados aqui sem diferenciar EN ou Em, assim como REN de REM.
A metodologia do HAREM é formada por:
Especificar as tarefas que serão avaliadas, -- definir as diretivas de etiquetagem e -- estabelecer a criação das coleções de textos.
Entre os eventos do HAREM destacam- se:
O primeiro HAREM decorrido no ano de 2004 e o Segundo HAREM, em 2008.
A coleção do Primeiro HAREM 2, dentro de uma estimativa de seu tamanho, é formada por 466355 palavras, abrangendo os mais variados tipos de textos, destacando- se os:
Jornalísticos, literários, políticos, textos da web e textos transcritos de entrevistas.
Já a Coleção Dourada do Primeiro HAREM compõe- se de 89241 palavras, sendo que dentro deste grupo houve o reconhecimento de 3851 entidades nomeadas.
Content Extraction 2008.
Evaluation Plan. Ago, 2008.
O primeiro HAREM apresenta dois aspectos fundamentais utilizados na avaliação de REN:
As tarefas de classificar e identificar uma expressão como entidade nomeada ligada ao seu uso no contexto, não estando dependentes, por exemplo, de dicionários, almanaques bem como ontologias;
E 2) aceita- se atribuir mais de uma classificação a uma mesma entidade nomeada, caso o contexto, em que essa se encontra, não possibilite escolher uma de elas somente.
A avaliação conjunta que o HAREM realiza é feita através da comparação do desempenho dos sistemas de vários grupos.
Estes grupos realizam a referida avaliação utilizando um conjunto de recursos em comum e uma métrica estabelecida por meio de um consenso.
O evento do Segundo HAREM possui uma coleção composta por 1040 documentos, sendo que, dentro deste grupo, encontram- se 129 documentos constituintes da coleção Dourada (CD).
Os documentos da coleção do Segundo HAREM foram selecionados respeitando as seguintes condições:
Deveria conter igualmente, na coleção, o português de Portugal e o do Brasil;
Em os documentos deveriam estar presentes distintos gêneros e registros textuais, 3) esta coleção deveria conter algum material já usado no Primeiro HAREM, a fim de que, posteriormente, fosse possível comparar a performance dos sistemas nesses documentos e em outras avaliações.
O Segundo HAREM manteve o modelo semântico do primeiro HAREM assim como o modelo de avaliação.
Esta segunda edição do HAREM, além de realizar uma avaliação mais justa dos sistemas, incluiu:
A tarefa de reconhecer e normalizar expressões classificadas como Tempo e o reconhecimento de relações semânticas entre as entidades nomeadas, ou seja, a criação da pista de ReRelEN.
A coleção Dourada é um subconjunto da coleção do Segundo HAREM, sendo essa utilizada para tarefa de avaliação dos sistemas que tratam REN.
Primeiramente, o mesmo conjunto de textos da CD foi anotado por duas anotadoras com o auxílio da ferramenta Etiquet (H) AREM.
Posteriormente, as anotações foram comparadas, com o auxílio do programa Alinhador e discutidas por as anotadoras, sendo que, em alguns casos, por toda a organização até que se chegasse a uma consensual anotação.
Em outra etapa, as anotadoras analisaram diferentes textos da CD.
Após a conclusão do processo de anotação da CD como um todo, ocorreu a revisão dos textos de um modo geral de toda a CD e um revisão detalhada das EN por categoria, considerando sempre o contexto de o qual faziam parte as Entidades Nomeadas.
A anotação e revisão da CD encontraram 7836 entidades nomeadas, repartidas nas várias categorias do HAREM.
A categoria Pessoa foi a mais frequente na CD e sequencialmente, fizeram- se presentes as categorias Local, Tempo e Organização.
Posteriormente, as Em sofreram uma identificação e classificação por todos os participantes do evento, onde esses obedeceram ao grupo de diretivas e usaram as categorias e os tipos conforme a Tabela 2.1.
2.4 Sistemas de Reconhecimento de Entidades Nomeadas para a Língua Portuguesa Em esta subseção é apresentada uma breve descrição de alguns sistemas que tratam sobre o Reconhecimento de Entidades Nomeadas para o português, bem como a extração de relações semânticas entre as ENs para esse mesmo idioma.
Os trabalhos para a língua portuguesa que realizam REN e fazem a identificação das relações entre as Entidades Nomeadas surgiram a partir de o HAREM.
Existe uma comunidade aplicada no Reconhecimento de Entidades Nomeadas e a tarefas ligadas ao português, relata Cristina Mota e colegas em.
De entre os sistemas que serão apresentados a seguir, apenas o sistema HENDRIX não participou do Segundo HAREM, o qual será abordado na seção 2.5.
A descrição detalhada dos demais sistemas encontra- se no livro do Segundo HAREM.
O sistema Priberam ao HAREM é baseado num léxico com classificação morfossintática e semântica.
Cada entrada do léxico, corresponde a uma ligação a um ou mais níveis de uma ontologia multilíngue, podendo corresponder a um ou mais sentidos, os quais possuem diferentes valores morfológicos e semânticos.
Para a construção do sistema foram utilizadas regras contextuais, as quais atribuem ou alteram valores morfológicos e semânticos a partes do texto isoladas ou a sequências de unidades.
Tais regras contextuais realizam, por exemplo, a criação de:
Locuções por meio de a combinação de sequências de palavras;
Categorias gramaticais e combinações de listas de palavras, chamadas de &quot;constantes», formadas por categorias ou palavras únicas.
As regras para a tarefa de REN consideram as sequências de nomes próprios, separadas ou não por algumas preposições e o contexto em que as Entidades Mencionadas são encontradas.
Por exemplo, uma Em &quot;João Pedro», classificada como Pessoa, poderá ser classificada como Organização se esta for precedida por uma expressão como &quot;instituto».
Fez- se necessário a criação de regras para a classificação de Em das categorias Coisa, Abstração, Acontecimento e Obra.
Já a classificação das categorias Pessoa, Local, Organização, Valor, Tempo já tinha sido tratada por o sistema automático de perguntas e respostas antes da participação no Segundo HAREM_ complementando as ferramentas necessárias para a construção do Priberam ao HAREM, os autores ainda criaram:
Novas constantes para a classificação contextual das Em.
Para tal, utilizou- se a ontologia desenvolvida por a Priberam, permitindo uma extração de nomes relacionados com os tipos e subtipos a serem implementados de uma maneira mais detalhada, e b) um filtro que determinasse as correspondências entre as categorias e valores originais do sistema e os do HAREM.
Este filtro consulta um ficheiro XML de fácil modificação para que, quando for preciso, o texto seja etiquetado com novas categorias e valores semânticos.
A Priberam cumpriu seus objetivos para conferência do Segundo HAREM, uma vez que tratou da identificação e da classificação das Entidades Nomeadas, quer a nível de correção sintática, quer a nível de sistemas de perguntas e respostas ou ainda para motores de busca.
Em função de a afirmação anterior, constatou- se que os resultados foram animadores, pois o sistema Priberam identificou corretamente 72,29% das Entidades Mencionadas, considerando como referência a Coleção Dourada do Segundo O sistema R3M realiza o REN para as categorias pessoas, organizações e locais.
A opção por essas três categorias deve- se ao fato de que essas, de uma forma geral, têm sido estudadas mais amplamente dentro de a área de extração da informação e porque os desenvolvedores do R3M não tiveram disponibilidade de dedicar mais tempo a esse sistema.
Mesmo assim, o R3M foi projetado de modo que permita estender- se ao reconhecimento de outras categorias, assim como incluir o reconhecimento de relações de Em.
Esse sistema é uma reimplementação do sistema criado por Mota, apresentando várias melhorias.
O R3M aplica aprendizagem semi-supervisionada, utilizando um algoritmo de cotraining para inferir regras de classificação.
A escolha do algoritmo de co-training deve- se ao fato de que este tem grande probabilidade de obter bons resultados de classificação que se aproximam dos 80% de accuracy, usando um número muito reduzido de exemplos previamente anotados.
Principais características do R3M:
Sistema modular sequencial, separado em duas fases:
Fase de identificação de entidades mencionadas e de classificação;
Etapa de treino a fim de aprender regras de classificação com base num algoritmo de co-treino;
Etapa de teste que usa as regras aprendidas para classificar entidades em novos textos, produzindo um texto final anotado.
Além disso, as duas fases acima possuem módulos de identificação de entidades, contextos e extração de features.
O módulo de identificação tem a função de reconhecer candidatos a entidades e o contexto em que este se encontra em textos não anotados, tanto numa fase de treino como numa fase de teste_ como resultado, o referido módulo produz uma lista de pares formados por entidade e contexto.
Em a fase de detecção do contexto da Em, os candidatos a Entidades Mencionadas são identificados junto do seu respectivo contexto e são definidos por um grupo pequeno de regras pertencentes a este contexto.
Para esta etapa, faz- se necessário rotular as sentenças por meio de o treinamento do etiquetador morfossintático do Jet, baseado nos textos do Floresta Sintática.
Já a extração de características faz a análise da lista de pares entidade-contexto e cria uma nova lista.
As características da entidade consideradas são:
A entidade propriamente dita;
Cada constituinte individualmente, com exceção dos elementos de ligação;
A entidade possui somente letras maiúsculas e por fim, o comprimento da entidade.
Para esta última característica condiciona- se que entidades com mais de cinco constituintes fiquem todas de comprimento seis.
O módulo de classificação rotula os pares de vectores de características alcançados por o módulo de extração de características.
Tal módulo utiliza um conjunto de regras que são concluídas por um algoritmo de co-training.
Foi empregada a categoria Outra, embora esta não exista no grupo de categorias da avaliação, cuja finalidade é guardar as entidades que não pertencem a nenhuma das categorias:
Pessoa, Organização e Local.
O módulo de propagação produz a anotação final do texto e será aplicado quando ocorrer a fase de teste.
Ele tem como objetivo reconhecer as entidades que não estão nos contextos relacionados com as regras de detecção do contexto da Em, citadas anteriormente, mas que podem ser idênticas às entidades já reconhecidas por o sistema e que têm uma classificação associada a ele.
Esse processo faz com que aumente a abrangência do sistema, pois permite a classificação de entidades que não foram classificadas por o módulo de classificação, devido a a falta de contexto.
A precisão, contudo, pode ser diminuída, porque o módulo de propagação se limita, apenas, a escolher a classificação mais frequente.
Os autores alcançaram sucesso ao aplicar a estratégia proposta para o problema de Reconhecimento de Entidades Nomeadas em texto da língua portuguesa, uma vez que obtiveram um anotador de entidades em texto e não apenas um classificador de listas de entidades.
O sistema chamado REMBRANDT -- Reconhecimento de ENs Baseado em Relações e Análise Detalhada do Texto consiste num sistema que reconhece todo tipo de entidades nomeadas e detecta as relações entre entidades para textos da língua portuguesa, justificando a sua participação na trilha de ReRelEN, no Segundo HAREM.
Este sistema utiliza a Wikipédia como base de conhecimento a fim de classificar as Entidades Nomeadas, além de um conjunto de regras gramaticais para extrair o seu significado por meio de indicações internas e externas de elas.
Tais regras são compreendidas como padrões, os quais indicam se há Entidades Nomeadas nas sentenças.
O REMBRANDT surgiu da necessidade de se criar um sistema de marcação de textos que indique as EN relacionadas a locais geográficos de uma forma semântica, como por exemplo, países, rios, universidades, monumentos ou sede de organizações.
Um dos obstáculos encontrados para o desenvolvimento eficiente desta ferramenta é a desambiguação de sentidos, pois os nomes geográficos podem ser aplicados em vários contextos, entre eles, nomes de pessoas, entidades geográficas de tipos diferentes, por exemplo, Cuba significa um país e uma cidade portuguesa.
A base para a criação do REMBRANDT foi parte do sistema Palavras_ REN, o qual identifica EN baseando- se no analisador morfossintático Palavras para criar regras que exploram sinais de Em nos textos.
O funcionamento do REMBRANDT divide- se em três fases primordiais:
O reconhecimento de expressões numéricas e geração de candidatas a EN;
Classificação de EN e 3) Repescagem de EN sem classificação.
Os documentos são trabalhados um a um com processos de anotação sucessivos até a sua versão final, de modo que as Em detectadas adquirem um histórico de todas as suas alterações, desde a sua primeira identificação no texto até a sua última alteração.
Em relação a os demais sistemas, o REMBRANDT obteve o segundo lugar na sua participação no Segundo HAREM, obtendo os melhores resultados para as categorias:
Pessoa, Local, Valor, Organização e Obra.
O sistema Sei-Geo, participante também da trilha de ReRelEN do Segundo HAREM, tem o objetivo de fazer o Reconhecimento de Entidades Mencionadas classificando a categoria Local e suas relações.
De entre as características que compõem o Sei-Geo destacam- se:
Incorporação na arquitetura global do sistema GKBGeographic Knowlegde Base, o qual estabelece o gerenciamento de conhecimento geográfico 3; --
possui dois módulos básicos:
O extrator e anotador de informações geográficas e o integrador de conhecimento geográfico;
Trabalha com as Geo-ontologias, que exploram as relações entre locais identificados em textos a partir de relações presentes na ontologia.
Destaca- se que para o bom desenvolvimento do Sei-Geo, o domínio Organização ajudou significativamente, no reconhecimento de relações de Entidades Mencionadas, pois, nos textos, Locais estão localizados próximos a Organizações.
Quanto a os resultados obtidos por o sistema, o SEI­Geo alcançou o melhor resultado comparado aos demais sistemas participantes no Segundo HAREM, salientando- se na identificação da relação de Inclusão.
O sistema CaGE trata do problema do reconhecimento e desambiguação de nomes de locais, pois esta é uma tarefa muito importante na geo-codificação de documentos textuais.
O objetivo principal do sistema CaGE é atribuir a área geográfica e o âmbito temporal aos documentos de modo geral, combinando a informação diferente extraída do texto.
O CaGe participou do Primeiro HAREM e no Mini-HAREM com o objetivo de avaliar o seu desempenho em ambientes selecionados para o REM, classificando- as com a categoria Local.
Já no Segundo HAREM, esse sistema avaliou o processo de REM nas categorias Pessoa, Organização e Tempo, além de o reconhecimento e classificação da categoria Local considerando os tipos e subtipos dessas entidades.
O CaGe caracteriza- se por ser um método híbrido utilizando dicionários e regras de desambiguação.
As referências geográficas são, muitas vezes, ambíguas com relação a as entidades de outras categorias, por exemplo, a entidade Mariana que refere- se ao nome de uma Localidade, pode também indicar o nome de uma Pessoa.
A solução proposta por o CaGe para o problema de REM está no uso de métodos de aprendizagem automática, porém para as tarefas de desambiguação completa de entidades geográficas, faz- se necessário o uso de um almanaque geográfico.
Isso porque as referências devem estar relacionadas a uma representação única para o conceito geográfico, por exemplo, coordenadas de latitude e longitude ou identificadores no almanaque geográfico.
Um dicionário, contendo nomes de entidades, que trata exceções para entidades geográficas é outra ferramenta que auxilia o funcionamento do CaGE.
É utilizado como complemento do sistema em questão um almanaque mais específico para desambiguação completa das Em, correspondendo a locais ou a períodos temporais, o qual faz parte do projeto DIGMAP.
Quatro etapas resumem uma sequência de operações de processamento que compõem o algoritmo do sistema:
Identificação inicial das Em;
Classificação das entidades mencionadas e tratamento da ambiguidade;
Desambiguação completa de entidades geográficas e temporais;
Atribuição de âmbitos geográficos e temporais aos documentos.
O resultado das quatro etapas, anteriores, mostra que o sistema CaGE além de reconhecer e classificar entidades mencionadas em textos, desambigua as entidades correspondentes à referências geográficas ou temporais.
Conclui- se que este sistema obteve resultados moderados, embora os dicionários, aqui apresentados, tenham abrangido dois milhões de nomes diferentes, as regras e deduções abordadas por o CaGE necessitam de alguma melhoria.
Cláudia Freitas e colegas em concluíram que, no processo de avaliação dos sistemas apresentados, apenas os sistemas Priberam e REMBRANDT_ 4 reconheceram o conjunto completo das categorias, tipos e subtipos.
Entre os sistemas que utilizaram da Coleção Dourada do Segundo HAREM, apenas o R3M adotou uma abordagem de aprendizagem de máquina, especificamente, o co-training.
Os outros sistemas basearam- se em regras manualmente codificadas em combinação com recursos externos como dicionários, gazetteers e ontologias.
Dois de eles, o REMBRANDT e o REMMA fizeram uso da enciclopédia Wikipedia para o Português, de diferentes maneiras.
Isso evidência que a comunidade dedicada a REN em Português não adotou técnicas de aprendizado de máquina, ao contrário de a situação para o Inglês.
Em geral, o melhor desempenho, no Segundo HAREM, foi aquele obtido por o sistema Priberam, atuação muito próxima ao melhor funcionamento de REMBRANDT.
Isto quer dizer que o primeiro utiliza uma ontologia multilíngue combinada com regras contextuais léxico-semânticas, enquanto o segundo explora a Wikipedia como fonte de conhecimento, associado com regras gramaticais que descrevem evidências internas e externas sobre as entidades nomeadas.
A comparação entre os demais sistemas participantes do Segundo HAREM não é tão simples, porque eles participaram em cenários seletivos diferentes, como, por exemplo, o sistema Sei-Geo, que aplicou somente Inclusão para a extração de Entidades Nomeadas.
A avaliação por cenários seletivos só fornece uma avaliação completamente justa no caso em que o cenário de avaliação está contido nos cenários de participação, caso contrário, os sistemas que correspondem exatamente ao cenário de avaliação podem ter uma ligeira vantagem.
Existem ainda outros sistemas que tratam de REN para o português, tais como o REMMA e o Reconhecimento de Entidades Nomeadas com o XIP.
Suxiang apresenta uma nova abordagem para o reconhecimento de entidades nomeadas chinesas baseadas no modelo CRF, o qual possui a forma de cascata.
Para o cumprimento deste propósito foi realizada a extração de uma entidade candidata do tipo pessoa e outra do tipo local.
A entidade candidata será inserida dentro de um modelo estatístico para decidir se é algum tipo de entidade ou não, uma vez que a ambiguidade de segmentação da palavra na língua chinesa sempre existe.
Quando há o reconhecimento de nome próprio, alguns padrões são propostos para o tipo de modelo diferente de ambiguidade de segmentação, e algumas etiquetas são usados para expressar regras específicas de caracteres chineses em nomes de pessoas.
Conforme, sete padrões para o reconhecimento de nome de pessoa foram elaborados da seguinte forma:
As duas primeiras regras não são ambíguas, enquanto as outras modelam algumas possíveis ambiguidades em nome de pessoa Chinesa causadas por segmentadores de palavras.
Serão apresentados três dos sete padrões para demonstrar que cada idioma tem a sua particularidade, utilizando exemplos da língua portuguesa.
Os demais padrões encontram- se em.
Foram coletados nomes de pessoas candidatas baseados nos padrões de feature acima.
Além disso, os caracteres ou palavras anteriores e posteriores do nome de pessoa candidato também foram utilizados.
Em este trabalho, foi implementado o reconhecimento do nome pessoal chinês e traduziu- se o nome pessoal separadamente.
Estes dois tipos de nomes são muito diferentes num texto chinês, mas, às vezes, deve- se ter atenção especial para distinguir- los.
Alguns nomes pessoais traduzidos sempre incluem sobrenomes chineses, que são pistas importantes para o modelo de reconhecer nomes chineses de pessoas e nomes estrangeiros de pessoas.
Em este caso, um pedaço do nome de pessoa traduzido pode, muitas vezes, ser reconhecido como um nome da pessoa chinês.
O modelo procura caracteres chineses que sejam anteriores e posteriores, no contexto, a fim de encontrar alguns outros caracteres chineses que sejam nome pessoal chinês ou o nome pessoal estrangeiro.
De acordo com os resultados coletados, o modelo irá escolher o modelo pessoal chinês ou modelo pessoal de tradução para identificar o nome pessoal candidato.
Experiências mostram que esse método é promissor, o recall e a precisão tiveram melhoras.
Foi determinada uma função de confiança para uma sequência de caracteres, para ajudar o modelo a estimar a probabilidade de uma determinada palavra ser um nome de pessoa.
Por exemplo, seja f a probabilidade de Ci, fiM a probabilidade de C1, fnE a probabilidade de Cn.
Então a função de confiança é:
Esta função é incluída no quadro do CRF como uma feature.
Em este modelo, o reconhecimento de nomes de locais é semelhante a nomes de pessoas.
A diferença entre eles é a direção da busca quando se coleta uma entidade candidata.
Os modelos de CRF e a função de confiança são também utilizados para reconhecer o nome de um local.
A função de confiança para nome de locais é representada por a equação:
Foram estabelecidas, por exemplo, features para nomes de pessoa Chinês, nome de locais.
As features designadas para nomes de pessoa Chinês foram:
Informação do contexto, sobrenome, o primeiro nome, o último nome, o contexto semântico, a probabilidade de um sobrenome, a probabilidade de ocorrer um determinado nome e a função de confiança.
Já as features dos nomes de locais eram:
A informação do contexto, a probabilidade de um caractere ocorrer e a função de confiança.
O método para o reconhecimento de organização é diferente para o reconhecimento de pessoa e de localização.
Estabeleceu- se um modelo para reconhecimento da organização, de modo que a estrutura para esse apresenta- se na forma de cascata.
Os resultados para o reconhecimento de local e de pessoa são repassados ao modelo, onde supõem- se que a decisão para o reconhecimento de nomes de organizações seja complicado.
O modelo pró-processado segmentará o texto chinês numa sequência de palavras.
O único passo em relação a a língua chinesa é a segmentação da palavra.
A segmentação é um estágio especial para as línguas orientais, por exemplo, as línguas Chinesa, Japonesa e Coreana.
Isso porque aquelas línguas são formadas por uma sequência de caracteres sem os delimitadores da palavra.
Em esse processo de segmentação, nomes de pessoas e nomes de locais serão reconhecido antes do reconhecimento de uma organização numa sequência de palavras.
Esse passo é muito importante e a arquitetura em cascata mostra a ordem de reconhecimento de diferentes tipos de entidades, por exemplo, um nome de organização, se a local não tiver sido reconhecido com antecedência, esta organização não será reconhecida com sucesso.
Por conseguinte, os reconhecimentos do nome de pessoa e do nome de uma localização, estão num estado muito importante.
Foram, finalmente, extraídas algumas features importantes para gerar o vetor de features e enviar- los a um classificador.
Foram estabelecidos quatro rótulos BILO, que significam:
B: A primeira palavra da organização I:
A palavra do meio da organização L:
A última palavra da organização O:
Uma palavra independente Para realizar a tarefa de classificação do rótulo BILO, utilizou- se o CRF que pertence a uma feature baseada em aprendizado de máquina.
A seleção das features foram apresentadas da seguinte forma:
Feature inicial;
Feature da palavra entidade, ou seja, se a palavra é um entidade do tipo pessoa, local ou organização, o valor da feature é 1, caso contrário é 0;
A palavra tem o rótulo B. Se a palavra satisfaz esta feature, o valor é 1;
A palavra tem rótulo I. Se a palavra satisfaz esta feature, o valor é 1;
A feature de probabilidade:
A probabilidade da palavra vir a ser uma organização;
Feature de sufixo:
A feature pode ser utilizada para decidir se a palavra tem um sufixo que antecede uma palavra do tipo organização;
Feature de bigrama, por exemplo, W 0 W+ 1 e Feature de trigrama, como W 0 W+ 1 W+ 2.
Conforme apresentado, o autor propôs o reconhecimento de entidades nomeadas chinesas aplicando o modelo Conditional Random Fields utilizando uma estrutura em cascata.
Ao mesmo tempo, foi estabelecida uma ordem de combinação baseada em regras e método estatístico, onde as funções de feature probabilística são usadas em vez de as funções de features binárias.
Foram exploradas várias novas features e os resultados mostram que o modelo de CRF proposto, combinado com os novos elementos acima trouxeram melhoras significativas.
Batista, em, elaborou um sistema, cujo acrônimo é Hendrix -- Entity Name Desambiguator and Recognizer for Information Extraction -- com o propósito de extrair entidades geográficas de documentos em português e produzir o seu resumo geográfico.
O processo dividiu- se em três partes:
1ª) Reconhecer Entidades Geográficas num documento:
Utilizando um modelo condicional (CRF), a fim de extrair de documentos nomes de entidades com significado geográfico, como por exemplo, nomes de ruas, rios, serras, entre outros;
Três módulos principais compõem o HENDRIX:
Primeiro, um módulo baseado no CRF, implementado por a ferramenta Minorthird, para extrair nomes de entidades geográficas, um segundo módulo, denominado Paredes, o qual foi criado para análise e referenciação dos nomes das entidades encontradas por o Minorthird e um terceiro, o PAGE, que faz a extração de Em num grande corpora junto com o HENDRIX.
As Coleções Douradas do HAREM I e do Mini-HAREM foram os recursos utilizados para criar o modelo baseado em CRF para a obtenção dos nomes de entidades geográficas e, posteriormente, possibilitar a comparação do modelo de reconhecimento de entidades geográficas com outros sistemas existentes.
Tais entidades foram classificadas como Local e ainda, receberam outra categorização em subtipos:
Físico, Humano ou Virtual.
Antes de gerar o CRF, foi realizada a etapa de etiquetagem, com a anotação de POS das entidades envolvidas.
Os termos etiquetados foram ainda classificados em quatro categorias:
Begin (termo inicial de uma entidade que será extraída), End (termo final de uma entidade que será extraída), Continue (termo que faz parte de uma entidade a ser extraída e que não é o inicial nem o final), Unique (um único termo que constitui a entidade a ser extraída) e Neg (o termo não se enquadra em nenhuma das categorias anteriores).
Foi possível comparar as métricas de Precisão, Abrangência e Medida-F com outros sistemas que tiveram uma participação na avalição seletiva apenas na categoria Local no Segundo HAREM.
Verificou- se que sistemas como REMBRANDT, Sei-Geo e SeRELep tiveram desempenho superior comparado com o modelo de CRF.
Os resultados sugerem que gerando melhores funções de features, na fase de aprendizagem, seja por meio de a Coleção Dourada ou através da codificação manual, os resultados poderão melhorar no que se refere à Precisão e Abrangência.
Em o período de teste, a Coleção Dourada, foi modificada de modo que mantivesse, apenas, as anotações para entidades geográficas.
No entanto, os testes mostraram que, por exemplo, quando o modelo extrai a entidade &quot;Portugal», ele a identifica sempre como uma entidade geográfica, quando este pode se referir a um termo não geográfico (como, no texto, fazer alusão ao governo de Portugal), elevando assim o número de falsos positivos.
O HENDRIX participou do evento de avaliação de sistemas de perguntas e respostas, O GikiCLEF, na edição de 2009.
Seu objetivo é fazer a avaliação de sistemas que utilizam a Wikipedia para buscar documentos que contém a resposta a uma determinada pergunta ou uma informação necessária.
Um único modelo de CRF foi desenvolvido para a participação neste evento, a fim de reconhecer além de lugares, organizações, eventos e pessoas_ compuseram a fase de treino do modelo as CD do Primeiro HAREM e do evento do Mini-HAREM.
Já a fase de teste foi formada, somente, por a CD do Segundo HAREM, alcançando 64% de Precisão e 45% de Abrangência.
Em relação a os resultados, percebe- se que o desempenho para a categoria Local diminuiu e muitas entidades foram corretamente identificadas, porém classificadas com a categoria errada.
Conforme, conclui- se, então, que deveria ter sido treinado um modelo independente para cada uma das categorias e, consequentemente, originado resultados mais satisfatórios.
O capítulo descreve todo o sistema proposto desde o pré-processamento dos textos, o modelo gerado por o CRF para o reconhecimento das entidades nomeadas até o método de avaliação empregado.
O objetivo é realizar REN aplicando o método CRF e, sequencialmente, fazer uma avaliação do seu desempenho com base no corpus do HAREM.
A descrição do processo de avaliação, bem como a sua finalidade, serão abordadas na Seção 3.3.
O NERP-CRF é o nome atribuído para o sistema desenvolvido com o propósito de realizar duas funções:
A identificação de ENs e a classificação dessas com base nas dez categorias do HAREM:
Abstração, Acontecimento, Coisa, Local, Obra, Organização, Pessoa, Tempo, Valor e Outro.
Esse sistema teve como base o trabalho de Marlo Souza A elaboração do modelo consiste em duas etapas:
Treino e teste.
De essa forma, o corpus é dividido num conjunto de textos para treino (Figura 3.2) e um conjunto de textos para teste.
O corpus trabalhado nesse processo refere- se às Coleções Douradas do Primeiro e do Segundo HAREM descrito na Seção 2.3.3.
Estes corpora foram escolhidos, primeiramente, por serem a principal referência na área, sendo utilizados por a maioria dos trabalhos relacionados ao REN, e devido a o fato de eles disponibilizarem um conjunto de textos anotados e validados por humanos (Coleção Dourada), o que facilita a avaliação do método em estudo.
Os textos, utilizados como entrada, estão no formato XML com a marcação das entidades e sofreram dois procedimentos, os quais pertencem ao pré-processamento do sistema:
Primeiro, a etiquetagem de cada palavra por meio de o Part-of-Speech (POS) tagging e segundo, a segmentação em sentenças a fim de que a complexidade seja menor ao aplicar o algoritmo de CRF nos textos de entrada.
O exemplo, de acordo com a sentença retirada da CD do Segundo HAREM, ilustra esses procedimentos iniciais:
Após a conclusão da etiquetagem POS e da segmentação das sentenças, determinou- se como as EN seriam identificadas.
Para tal, foi feito um estudo de duas notações citadas na literatura:
Bio e Bilou.
A primeira possui o seguinte significado:
B (Begin) significa a primeira palavra da EN;
I (Inside) uma ou mais palavras que se localizam entre as entidades e O (Outside) a palavra não é uma EN.
Já a segunda notação, tem a mesma descrição do Bio, acrescentando- se as seguintes particularidades:
L (Last) a última palavra reconhecida como EN e U (Unit) quando a EN for uma única palavra.
Salienta- se que I (Inside), na notação Bilou, encontra- se entre Begin e Last.
Optou- se por utilizar, para o presente trabalho, a notação Bilou por dois motivos:
Testes aplicados sob a CD do Segundo HAREM, empregando ambas notações, demonstraram que a notação Bilou supera a Bio, conforme os resultados apresentados na Seção 4.
Resultados. Isso porque o Bilou facilita o processo de classificação feito por o sistema desenvolvido por possuir mais duas identificações:
L (Last) e U (Unit);
E (ii) Ratinov e Roth em também fizeram testes com as duas notações, concluindo também com os seus resultados obtidos que, apesar de o formalismo Bio ser amplamente adotado, o Bilou o supera significativamente.
Após a identificação das EN por meio de o Bilou, foi gerado o vetor de features.
Tal vetor corresponde aos dados de entrada que serão aplicados ao sistema de aprendizado do CRF.
As features têm o objetivo de caracterizar todas as palavras do corpus escolhido para este processo, direcionando o CRF na identificação e na classificação das ENs.
A seguir, a lista das features criadas:`
tag': A etiqueta POS tagging de cada palavra de acordo com a sua classe gramatical;`
word': A própria palavra, ignorando letras maiúsculas e minúsculas;`
prevW': A palavra anterior, ignorando letras maiúsculas e minúsculas;`
prevT': A classe gramatical da palavra anterior;`
prevCap': Se a palavra anterior for totalmente formada por letras minúsculas, formada por letras minúsculas e maiúsculas ou totalmente formada por letras maiúsculas;`
prev2W': Igual a feature 3, porém considerando a palavra que está na posição p-2;
7)` prev2T':
O mesmo que a feature 4, considerando a palavra que está na posição p-2;
8)` prev2Cap':
Igual a feature 5, porém considerando a palavra que está na posição p-2;
9)` nextW':
A palavra subsequente àquela que está sendo analisada, ignorando maiúsculas e minúsculas;
Dois vetores são considerados como entrada para o CRF:
Primeiro, o vetor contendo a etiquetagem POS, as categorias estabelecidas por a Conferência do HAREM e a notação Bilou (Figura 3.4) e segundo, o vetor de features.
Para um melhor entendimento das features apresentadas anteriormente, a Figura 3.5 ilustra a 1ª e a 3ª features, para mesma sentença anterior.
Em o final deste trabalho, localizam- se todas as features aplicadas no CRF (Apêndice A) e um exemplo de vetor completo de entrada para o sistema com todas essas features (Apêndice B).
Uma matriz é gerada, a partir de o vetor de features, dado como entrada do sistema, para produzir o modelo CRF.
Esse modelo corresponde a uma matriz de pesos que indica os pesos sobre o valor de cada feature, cujo objetivo é informar, conforme a Figura 3.5, quantas palavras, por exemplo, serão classificadas como U e são artigos na posição p-1.
Baseado na condição anterior, o algoritmo resulta num valor de peso para o atributo p1.
Consequentemente, toda vez que uma palavra for etiquetada como um artigo e estiver na posição p-1, o algoritmo atribuirá a ela, por exemplo, um peso no valor de 0,1.
Os pesos formadores da matriz do CRF estão entre 0 e 1, pois valores probabilísticos ficam compreendidos dentro desse intervalo numérico.
A etapa de teste utiliza o mesmo vetor de features da etapa de treino como vetor de entrada.
O modelo de CRF gerado, na etapa de treino, é aplicado no corpus de teste, a fim de que se possa avaliar o seu desempenho, de acordo com a Figura 3.6.
A Seção seguinte descreverá a implementação para a modelagem proposta.
Para melhor compreensão de como o NERP-CRF foi executado, serão apresentados exemplos de entradas e saídas em cada um de eles, durante o cumprimento do sistema.
A implementação é caracterizada por o uso de ferramentas com a finalidade de:
Segmentar os textos em sentenças, para que a complexidade seja menor ao aplicar o algoritmo de CRF nos textos de entrada;
Etiquetar as sentenças através do Part-ofSpeech a fim de identificar morfologicamente cada palavra dos textos, auxiliando o CRF na classificação das EN;
Criar as features;
E 4) gerar o modelo de CRF conforme explicado na Seção 2.1.
O pré-processamento do sistema NERP-CRF é formado por a segmentação dos textos e etiquetagem (POS tagging) das palavras (Figura 3.7).
Para o desenvolvimento dos procedimentos anteriores foi utilizada a biblioteca OpenNLP4, implementada na linguagem de programação Java, pois ela possui vários recursos bem estruturados para PLN, como esses aplicados no pré-processamento.
O sistema NERP-CRF tem como entrada o corpus préprocessado e foi desenvolvido em Python, uma vez que essa linguagem de programação apresenta sintaxe clara, concisa e elegante, facilitando a manutenção do código.
Em a etapa de treino, o NERP-CRF transforma o corpus pré-processado em:
Um vetor e uma função de tradução.
Tal vetor é formado por a etiquetagem POS tagging e por a notação Bilou.
A função de tradução utiliza os dados extraídos do vetor de entrada para criar o vetor de features o qual vai caracterizar as sentenças formadoras desse vetor.
A biblioteca NLTK, escrita na linguagem Python, foi utilizada para criar o vetor POS+ Bilou e a função de tradução (vetor de features).
Já a biblioteca Mallet (versão 0.4), escrita na linguagem Java, foi utilizada na implementação do CRF, que irá gerar o modelo de CRF baseado nas features determinadas como uma das entradas do NERP-CRF.
Optou- se por trabalhar com o Mallet, porque esse possui recursos que facilitam a extração de informação e a criação de aplicações de aprendizado de máquina para textos.
Em a etapa de teste, um conjunto de textos é enviado ao NERP-CRF.
O referido sistema cria o vetor POS e a função de tradução;
Envia esses vetores para o modelo de CRF gerado que, por sua vez, treina e classifica as EN do corpus trabalhado.
Por fim são apresentadas aos usuários do sistema as EN extraídas e as métricas precisão e abrangência.
Em suma, o NERP-CRF permite que as ENs dos textos de entrada sejam categorizadas e que os resultados finais sejam expostos, de modo que se possam comparar os textos anotados manualmente e os textos anotados por o sistema.
Etapa de Treino Corpus de treino Préinput processado (Open NLP) Gera o modelo (Mallet) 1) vetor POS+ Bilou;
Função de Tradução:
Vetor de features.
Etapa de Teste Utiliza o modelo Corpus de Teste Préprocessado.
Identifica e gerado.
Classifica 1) Vetor de POS;
Vetor de features.
Apresenta Entidades Extraídas apresenta Métricas:
Com base na implementação descrita, três testes diferentes foram estabelecidos para aplicar o CRF.
Obedeceu- se a mesma modelagem do sistema, conforme a seção A sentença &quot;Os EUA ganharam um interesse acrescido por as armas não letais após a sua desastrosa missão pacificadora na Somália», exemplifica as entradas e as saídas aplicadas na implementação desse trabalho bem como os procedimentos realizados, a seguir pormenorizados.
Em a etapa de treino são utilizados dois vetores:
O primeiro vetor é constituído de:
Etiquetagem POS tagging de cada palavra do texto, -- notação Bilou em cada palavra do texto e -- a categorização das EN identificadas por o Bilou.
Esse experimento empregou cinco das dez categorias consideradas por a Conferência do HAREM:
Pessoa, Local, Tempo, Organização e Obra.
Inicialmente, optouse por trabalhar somente com as cinco categorias anteriores, pois essas são as mais frequentes encontradas nas CD do HAREM e além disso, tinha- se o propósito de se verificar o comportamento do modelo de CRF proposto para o corpus em questão.
Já o segundo vetor é formado por um conjunto de features, as quais foram determinadas para esse trabalho na Seção 3.2.
A entrada para o CRF, nessa etapa, para esse sistema, consiste:
De o primeiro vetor mencionado anteriormente e -- de uma função de tradução.
Em a etapa de treino, os dois vetores de entrada, Figuras 3.10 e 3.11, utilizados para gerar o modelo CRF, são apresentados a seguir.
O vetor de features completo encontrase no final dessa dissertação (Apêndice C).
Após a introdução dos vetores de entrada, no sistema, foi gerado o modelo de CRF de acordo com as features apresentadas por a Seção 3.2.
Em a etapa de teste, o vetor de entrada é formado por os:
Vetor de etiquetagem de cada palavra do texto por meio de o POS taggin (Figura por o mesmo vetor de features aplicado, na etapa de treino, de acordo com a Figura Já o vetor de saída da etapa de teste possui o seguinte formato:
O «Teste 1 utilizou a CD do Segundo HAREM, composta por 129 textos, e gera um modelo de CRF que faz a classificação de cinco categorias:
Acontecimento, Local, Pessoa, Obra e Organização.
O intuito de realizar um experimento com essas distinções deve- se ao fato de verificar qual a melhor notação a ser utilizada aplicando o CRF:
Bio ou O «Teste 2 também utilizou a CD do Segundo HAREM para treinar e testar o modelo de CRF, o qual faz a classificação de dez categorias:
Abstração, Acontecimento, Coisa, Local, Obra, Organização, Pessoa, Tempo, Valor e Outro.
A finalidade de executar esse experimento foi para realizar a avaliação dos resultados obtidos por o CRF com os outros sistemas participantes do Segundo HAREM, podendo assim comparar tais resultados.
Já o «Teste 3 caracteriza- se por trabalhar com a CD do Primeiro HAREM para treino, em a qual abrange 129 textos e a CD do Segundo HAREM para teste formada por mais 129 textos.
O novo corpus recebe a classificação do CRF abordando as dez categorias do HAREM, citadas em o «Experimento 2.
Essa terceira estrutura foi arquitetada com o objetivo de verificar o desempenho do CRF num maior número de textos.
Os vetores de entrada e saída, tanto nas etapas de treino quanto nas etapas de teste para os &quot;Experimentos 2 e 3 possuem a mesma estrutura de o «Experimento 1 exemplificado anteriormente.
As duas diferenças dos dois últimos experimentos em relação a o primeiro é que:
O CRF para esses textos considerou todas as categorias do HAREM para classificar cada EN e 2) as features referentes as posições vazias, na sentença, de acordo com a janela considerada, em relação a posições anteriores e posteriores à palavra em questão, receberam o valor nulo.
Por exemplo, considerando a sentença «Os EUA ganharam um valores de suas features serão nulos, uma vez que não há nenhuma palavra duas posições anteriores a ela na sentença.
Logo, o vetor de features para a palavra EUA, o qual aborda essa particularidade, possui o formato apresentado na Figura 3.14: Resumidamente, a implementação é apresentada contendo as suas características mais relevantes.
NERP-CRF é o sistema desenvolvido em Python neste trabalho de mestrado.
A implementação que envolveu todo o processo proposto é formada por uma combinação de ferramentas associadas a uma implementação mais específica desenvolvida nessa pesquisa.
O modelo do NERP-CRF foi gerado empregando as seguintes ferramentas:
A biblioteca OpenNLP5 em Java, para a etiquetagem e divisão dos textos em sentença, utilizando a técnica do Part-of-Speech (POS) tagging e notação Bilou na identificação das ENs, na etapa do pré-processamento;
A biblioteca NLTK, escrita na linguagem Python, foi utilizada para criar dois vetores de entrada para o sistema;
A biblioteca Mallet, escrita em Java, para a implementação do modelo.
A aplicação do sistema é dividida em duas etapas:
Treino e teste.
Em a etapa de treino, a biblioteca NLTK transformou o corpus pré-processado em dois vetores considerados como entrada para o sistema.
O primeiro contendo a etiquetagem POS, as categorias estabelecidas por a Conferência do HAREM e a notação Bilou.
O segundo definindo as features.
Este vetor foi gerado com o objetivo de caracterizar todas as palavras do corpus a fim de orientar o NERP-CRF na identificação e na classificação das ENs.
A biblioteca Mallet, foi utilizada na implementação do NERP-CRF gerando o modelo de CRF baseado nas features determinadas como uma das entradas do sistema.
Em a etapa de teste, a biblioteca Mallet foi aplicada com o objetivo de treinar o modelo, a partir de um outro conjunto de textos diferente do utilizado na etapa de treino.
Novamente nessa etapa o sistema cria o vetor POS e juntamente com o vetor de features identifica e classifica as ENs.
A avaliação tem por objetivo comparar o NERP-CRF com os outros sistemas que fizeram REN utilizando o corpus da CD do Segundo HAREM.
Para alcançarmos uma avaliação precisa, estudou- se de que maneira os resultados seriam avaliados e que ferramenta seria utilizada para gerar os mesmos.
A avalição foi feita quantitativamente após o desenvolvimento do sistema NERP-CRF, a qual restringiu- se à tarefa de reconhecimento e classificação das EN.
A metodologia de avaliação descreve esses estudos feitos bem como as medidas utilizadas para avaliar o nosso sistema.
O processo de avaliação aborda de que maneira a metodologia pesquisada foi aplicada nos três experimentos concluídos.
A elaboração do processo de avaliação implicou no conhecimento do CrossValidation, do SAHARA, bem como do estudo do corpus de referência HAREM.
A seguir, cada um de eles é descrito de acordo com a ordem de aplicabilidade nesse trabalho.
Os corpora utilizados neste trabalho são os do Primeiro e do Segundo HAREM, apresentados na seção 2.3.3.
Estes corpora foram escolhidos, primeiramente, por ser a principal referência na área, empregados por a maioria dos trabalhos relacionados ao REN, e por o fato do HAREM estar disponível aos usuários, caracterizando- se por ser um conjunto de textos anotados e validados por humanos (Coleção Dourada), o que facilita a avaliação do método em estudo.
Em os três testes realizados, utilizou- se a Coleção Dourada do Segundo HAREM, como o corpus de teste, para validar o modelo de CRF gerado, uma vez que se optou por avaliar esses textos por meio de a ferramenta SAHARA6, a qual é executada em textos que possuem o formato, apenas, do Segundo HAREM Posteriormente, optou- se por trabalhar com o corpus do Primeiro HAREM para treino e o do Segundo HAREM para teste, pois assim o CRF pode ser aplicado num maior número de textos:
De 129 alterou- se para 258 textos na sua totalidade.
Para ambos os experimentos, a modelagem do sistema foi a mesma, conforme explanado na seção 3.1.
Cross-validation foi a técnica empregada para validar os dados obtidos a partir de o modelo treinado no corpus do HAREM.
Segundo, Cross-validation ou Validaçãocruzada é uma técnica ou um estimador de validação de dados que realiza a média de várias estimativas de maneira segura, ou seja, os dados que foram validados são autênticos, eficazes e correspondem a diferentes divisões dos textos.
Kohavi em afirma que a estimativa da validação cruzada é um número randômico que depende da divisão dos dados de entrada em folds, ou seja, iterações.
A Validação-cruzada completa é a média de todas as possibilidades para a escolha de instâncias m/ k por m, mas ela é geralmente muito cara.
Isso significa que apesar de apresentar uma investigação completa sobre a variação do modelo em relação a os dados utilizados, este método possui um alto custo computacional, sendo indicado para situações onde poucos dados estão disponíveis.
O Cross-validation caracteriza- se por ser um estimador intermediário entre Holdout e do Leave-one- out, descritos posteriormente.
O método Holdout tem a função de dividir o conjunto total de dados em dois subconjuntos:
Um para treinamento e outro para teste.
O subconjunto de treinamento faz a estimativa ou cálculo dos parâmetros, já o de teste realiza a validação dos dados.
A proporção usual para divisão dos dados é dois terços para treinamento e um terço dos dados para teste, contudo o conjunto de dados pode ser separado em quantidades de proporções diferentes ou iguais.
Depois de ocorrido o particionamento, o modelo é gerado, os dados de teste são aplicados e é estimado o erro de predição.
Indica- se a utilização desse método quando for empregada uma grande quantidade de dados, pois se o conjunto de dados for pequeno, o erro estimado na predição poderá ter como resultado muita variação.
Existem alguns casos especiais de Cross-validation como:
O método K-fold e o Leave-one- out..
O método K-fold fundamenta- se em dividir o conjunto de dados total em x subconjuntos de tamanhos iguais.
Após esse particionamento um subconjunto é utilizado para treino e o restante para teste, calculando por fim, a acurácia do modelo gerado.
É realizado n vezes esse processo, chamado de folds ou iterações, de modo que se combinem todos os subconjuntos criados, alternado os de treino com o de teste.
Em o momento em se findam as iterações, calcula- se a taxa de erro` err (h)' de um classificador` h'encontrados por meio de a equação:
Dado` n'o número de atributos, a taxa de erro compara o texto original classificado com a etiqueta atribuída por o sistema classificador criado.
O operador| E| retornará 1 se a expressão E for considerada verdadeira, caso contrário retornará zero.
De essa forma, obtém- se a medida mais confiável sobre a competência do modelo de representar o processo gerador dos dados.
Já o método Leave-one- out envolve o uso de uma amostra original onde, a partir de ela ocorre a divisão dos dados numa amostra de validação e amostras de treinamento.
Esse processo é repetido de modo que a cada observação na amostra, os dados de validação são utilizados uma única vez.
É o mesmo procedimento que ocorre no método K-fold com k sendo igual ao número de observações na amostra original.
Dada uma amostra de tamanho` n', o erro na amostragem consiste na soma dos erros em cada iteração divido por` n'.
Leave-one- out é computacionalmente caro porque requer muitas repetições de treinamento e é usado, com frequência, em amostras pequenas.
Além de a técnica de validação Cross Validation, também foi utilizado o SAHARA, ferramenta que automaticamente avalia os resultados dos textos da CD do Segundo HAREM.
Através do SAHARA é possível fazer a comparação entre os sistemas participantes do Segundo HAREM com outros sistemas que realizam REN, desde que estes trabalhem com textos que estejam no mesmo formato dos textos da CD do Segundo HAREM, condição imposta por o SAHARA para se utilizar essa ferramenta.
Esse avaliador está disponível na Web por o site da Linguateca7 e facilita a avaliação dos sistemas que fazem o REN, pois o usuário não necessita executar comandos próprios dos programas de avaliação para obter os resultados referentes ao desempenho do sistema a ser avaliado.
O processo de avaliação feito por o SAHARA é formado por três fases:
Validação do sistema a ser avaliado de acordo com o formato do Segundo -- configuração do tipo de avaliação, isto é, a escolha dos cenários, o modo de avaliação e as coleções que serão trabalhadas e -- a exibição dos resultados formada por tabelas e gráficos, os quais identificam o desempenho do sistema.
Findada a apresentação dos resultados, o SAHARA faz a verificação da existência de resultados oficiais os quais possam ser comparáveis com a avalição executada, ou seja, se os sistemas participantes do Segundo HAREM foram avaliados de acordo com o mesmo cenário e modo de avaliação utilizando a mesma CD.
Os resultados oficiais, caso esses sejam considerados, são exibidos no formato de um gráfico-resumo o qual apresenta também a melhor saída para os três melhores sistemas.
Em esta sub-seção serão apresentadas duas avaliações do modelo gerado por o CRF, utilizando a CD do Segundo HAREM:
Primeiro os resultados obtidos por o Cross Validation e, segundo os valores oriundos do SAHARA.
Os dados repassados aos dois avaliadores resultam nas métricas de Precisão, Abrangência e Medida-F. De acordo com as diretivas do SAHARA, as medidas de avaliação obedecem as seguintes condições mencionadas a seguir.
A Precisão corresponde à medida de a qualidade do sistema em termos de resposta e mede a proporção de respostas corretas dadas todas as respostas fornecidas por o sistema, ou seja:
Total de EN corretamente classificadas por o NERP-CRF Precisão $= Total de EN classificadas por o CRF A Abrangência mede a quantidade de EN classificadas corretamente em relação a o universo das EN identificadas por a Coleção Dourada (CD) do Segundo HAREM.
Total de EN corretamente classificadas por o NERP-CRF Abrangência $= Total de EN classificadas por a CD A Medida F combina as métricas de precisão e de abrangência de acordo com a fórmula:
Medida-F $= (Precisão+ Abrangência) O processo de avaliação determinado é caracterizado por o uso de uma técnica de validação e de uma ferramenta, a seguir apresentadas:
A avaliação do desempenho do modelo treinado para o «testes 2 utilizou a técnica de Cross Validation, com cinco repetições (5 ­ fold cross validation).
Trabalhouse com 5 folds porque foi empregado uma pequena quantidade de textos, 129, para os testes iniciais.
Dado o conjunto de textos da CD do Segundo HAREM, utilizou- se a cada fold, 80% do conjunto de textos para treino e 20% para teste, de modo que a cada repetição do Cross Validation, não se empregasse o mesmo conjunto de teste das folds anteriores e assim, não reduzisse, significativamente, o número de casos para teste.
A CD é um subconjunto da coleção do Segundo HAREM, organizado por a Linguateca 8.
Tal subconjunto é formado por 129 documentos e seus textos foram anotados por humanos.
O &quot;teste 3 «considerou um fold Cross-validation para que também fosse possível utilizar o SAHARA como ferramenta de avaliação.
Para isso aplicou- se a CD do Primeiro HAREM como conjunto de treino e a CD do Segundo HAREM para ser o conjunto de teste, uma vez que o SAHARA exige que, para se trabalhar com essa ferramenta, os textos estejam no formato desse conjunto de textos utilizados para teste.
A ferramenta SAHARA9 foi empregada para fazer a comparação dos resultados obtidos por o NERP-CRF com os sistemas participantes do Segundo HAREM_ como o principal objetivo dessa dissertação é realizar a avaliação do NERP-CRF, o SAHARA é o sistema de avaliação adequado para essa finalidade.
Logo os três testes, detalhados na Seção 3.2, utilizaram a ferramenta mencionada e a CD do Segundo HAREM como corpus de teste.
Os resultados apresentados por o NERP-CRF identificam cada EN por meio de a notação Bilou e as classificam considerando o corpus das CD do Primeiro e do Seguno HAREM.
A difícil missão de identificar possíveis falhas nos procedimentos pode ser feita de forma automatizada por meio de técnicas de PLN como técnicas de aprendizado de máquina.
Aplicações que se beneficiam de tal suporte podem ser aplicadas em textos dos mais diversos domínios.
Seguindo a metodologia adotada, verifica- se que o sistema desenvolvido apresentou os melhores resultados de Precisão quando comparado com outros sistemas, os quais adotaram os mesmos recursos.
Os resultados estão organizados e serão apresentados de acordo com os três testes pormenorizados na Seção 3.2, os quais podem ser sintetizados da seguinte forma:
O` Teste 1' utilizou a CD do Segundo HAREM, cujo objetivo é definir qual a notação que será utilizada para gerar o modelo de CRF:
Bio ou Bilou.
O` Teste 2' também utilizou a CD do Segundo HAREM para treinar e testar o modelo de CRF, o qual faz a classificação de dez categorias:
Abstração, Acontecimento, Coisa, Local, Obra, Organização, Pessoa, Tempo, Valor e Outro.
Já o` Teste 3' caracteriza- se por trabalhar com a CD do Primeiro HAREM para treino e a CD do Segundo HAREM para teste.
O novo corpus recebe a classificação do CRF abordando as dez categorias, citadas em o` Teste 2'.
Os primeiros resultados para esse trabalho foram gerados com o objetivo de verificar qual a melhor notação a ser utilizada por o NERP-CRF.
A Tabela 4.1 apresenta os resultados da identificação das EN por meio de a notação Bio.
Já a Tabela 4.2 classificada cada EN por meio de a mesma notação.
A Tabela 4.3 exibe os valores de identificação de cada EN utilizando a notação Bilou e a apresentação dos resultados por categorias, considerando a mesma notação, é descrita por a Tabela 4.4.
Devido a os melhores resultados obtidos na tabela de categorias com o Bilou (Tabela 4.4), essa foi a notação adotada para os próximos testes.
Acreditamos que por essa notação ter uma maior granularidade, ela facilita o processo de classificação feito por o NERP-CRF, por possuir mais duas identificações:
L (Last) e U (Unit).
A técnica de Cross Validation avalia a classificação Bilou de cada palavra do texto e a categorização das EN, apresentadas por as Tabelas de Confusão a seguir.
O Teste 2 foi executado sobre o corpus da CD do Segundo HAREM, contendo 129 textos, incluindo 670.610 palavras.
Esse procedimento resultou em 7.610 EN identificadas por o NERP-CRF num valor máximo de 17.767 EN identificadas por humanos nessa mesma De acordo com a Tabela 4.5 (Tabela de Confusão da classificação Bilou), observa- se que os valores de F-Measure aproximam 80% para as categorias B L e U. O menor F foi para I, que deve obedecer à condição de que a palavra esteja localizada entre B (Begin) e L (Last).
Contudo, como esta situação é menos frequente, houve poucos exemplos para treino do CRF para essa categoria.
A categoria O (Outside) possui alto F porque a maioria das palavras do texto recebe esse tipo de notação.
De acordo com Tabela 4.6, a categoria Tempo foi a que obteve a melhor Precisão, 83,99% e também um bom resultado de Abrangência, 68,05%.
Consequentemente, foi o melhor resultado de F-Measure classificado por esse sistema, alcançando 75,18%.
Podese constatar, nessa mesma Tabela, que 372 EN foram classificadas como Pessoa, ao passo que deveriam ser classificadas por o NERP-CRF como Organização.
A explicação para esse fato foi a falta de contexto existente no corpus, a qual não auxiliou o NERPCRF na classificação correta da categoria Organização.
Tabela 4.6: Classificação das Em do NERP-CRF em o` Teste 2'.
Rec Prec F--Measure O` Teste 3' teve como base de treino a CD do Primeiro HAREM e como base de validação o corpus do Segundo HAREM.
Os dois conjuntos somam 258 textos e aproximadamente 804.179 palavras.
A Tabela 4.7, sobre a classificação Bilou, mostra que os valores de F-Measure ficam em torno de 65% e 70%_ como esperado, os valores ficam um pouco abaixo de o Teste 2, baseado em Cross Validation sobre uma única base.
Quanto a classificação das EN, em o` Teste 3', pode- se constatar que a categoria Valor obteve o melhor resultado de F-Measure, 66%.
Já o pior resultado classificado por o NERP-CRF foi para a categoria Coisa com F-Measure de 3%.
A diferença dos resultados originados por as métricas entre os` Testes 2 e 3' deve- se à diferença da distribuição das categorias da Primeira para a Segunda CD do HAREM.
Algumas categorias ocorreram mais vezes na primeira CD e menos na segunda CD, influenciando no treinamento do CRF.
A comparação dos resultados do NERP-CRF com os sistemas que participaram da Conferência do Segundo HAREM foram obtidos por meio de o SAHARA, o qual determinou as métricas Precisão, Abrangência e Medida-F a cada um de eles nas tarefas de reconhecimento e classificação de EN.
O NERP-CRF, em o` Teste 2', apresentou os melhores resultados para as medidas de Precisão e Medida-F em relação a os outros sistemas.
O` Teste 3' caracterizou a Precisão de 80,77% como o melhor resultado do NERPCRF (Figura 4.2).
A Medida-F ocupou a terceira posição em relação a os sistemas em comparação, 48,43%.
Essa última métrica não alcançou a melhor posição como em o` Teste 2' devido a uma baixa Abrangência de classificação, 33,74%.
A desigualdade dos resultados entre os dois testes ocorreu, principalmente, por dois motivos:
A mudança do corpus de treino e de validação além de o número reduzido de exemplos para determinadas categorias, por exemplo, Coisa, Abstração.
Isso faz com que o CRF treine menos com essas categorias e gere um modelo menos abrangente para elas.
Em este cenário, consideram- se os nossos resultados muito positivos, principalmente no que tange ao valor de Precisão alcançado por o NERP-CRF_ com base em uma análise nos textos utilizados como entrada para testar o NERPCRF, constata- se que o sistema, tanto para o` Teste 2 'quanto para o` Teste 3', não identificou determinadas EN ou não as identificou corretamente por os seguintes motivos:
Má formatação de alguns textos, como por exemplo, falta de pontuação;
Erros referentes a anotação do POS tagger;
Erros de delimitação da entidade, isto é, a EN &quot;Ministério da Cultura», por exemplo, foi marcada por a CD como B I L, no entanto o CRF a identificou como B I U;
Os erros de classificação das EN ocorreram por os seguintes motivos -- a não identificação correta das EN por o Bilou e, consequentemente, a classificação errada dessa mesma entidade;
EN representadas por siglas;
Palavra estrangeira;
A categoria Tempo é difícil de classificar, pois esse tipo de EN pode não iniciar com letra maiúscula e assim, fica mais difícil para o sistema aprender essa particularidade.
Além disso, a referida categoria segue um padrão bem rígido de sintaxe como número\&gt; de número\&gt;, indicando data, ou até mesmo outras palavras indicativas de tempo como desde, enquanto e quando.
Pouco contexto para classificar corretamente certas EN, por exemplo, a categoria Abstração tem muito pouca exemplificação na CD e são ENs que não seguem padrão algum como o caso de categoria Tempo que segue uma sintaxe própria;
E as preposições, por exemplo &quot;de», são comuns tanto fora como dentro de uma EN, e muitas vezes o classificador não a identifica com I. As três sentenças seguintes apresentam algumas situações dos erros ocorridos de acordo com os motivos já discriminados.
Relatam- se exemplos mais detalhados e completos, referentes a análise de erros, no anexo IV.
Sentença 1: &quot;Avanços na área de radares e de comunicação Radio Frequency continuaram através das décadas de 50 e 60.»
Erro de classificação, pois o NERP-CRF deveria ter classificado a entidade Radio Frequency como Coisa e não como Pessoa.
Sentença 2: &quot;O parto ocorreu no quarto andar esquerdo do nº 4 do Largo de São Carlos, em frente de a ópera de Lisboa, Teatro de São Carlos «Erro de classificação, ou seja, o sistema classificaria corretamente a EN grifada se a considerasse como Local.
Sentença 3: A as\ adv, O-OUT\&gt; vinte\ num, O-OUT\&gt; três\ num, O-OUT\&gt; minutos\ n, O-OUT\&gt; horas\ n, I-TEMPO\&gt; de a\ v-pcp, I-TEMPO\&gt; e\ conj-c, I-TEMPO\&gt; tarde\ adv, I-TEMPO\&gt; de\ prp, B-TEMPO\&gt; 13 de\ prp, I-TEMPO\&gt; Junho\ n, I-TEMPO\&gt; de\ prp, ITEMPO\&gt; 1888 nascia em Lisboa, capital portuguesa, Fernando Pessoa.
O NERP-CRF não identificou parte da EN em negrito e consequentemente, não a classificou corretamente.
Em este capítulo serão apresentadas as conclusões e as contribuições científicas alcançadas nessa dissertação.
Bem como, serão apresentados também os trabalhos futuros os quais poderão complementar essa dissertação de mestrado no processo de identificação e classificação de EN por meio de o CRF.
O principal objetivo dessa dissertação foi a aplicação do CRF para a tarefa de REN em corpus da língua portuguesa e a avaliação comparativa com outros sistemas que realizam REN, tendo como base o corpus do HAREM.
Para isso, efetuou- se, inicialmente, um estudo teórico sobre CRF para REN.
Após a conclusão desta fundamentação teórica, apresentou- se o modelo gerado por a técnica de aprendizagem automática, CRF, bem como os testes executados aplicando esse modelo em textos do Português.
A literatura tem apresentado a aplicação do formalismo matemático probabilístico denominado CRF para essa tarefa.
Tal formalismo vem crescendo em importância, por ser um modelo gráfico não direcionado que define uma única distribuição logaritmicamente linear, sobre sequências de etiquetas, dada uma sequência de observação particular.
Adicionalmente, o CRF evita o problema de viés dos rótulos, uma fraqueza exibida por os MEMM e outros modelos de Markov condicionais baseados em modelos gráficos direcionados, onde os vértices são os estados e as arestas são as probabilidades de transição entre esses estados.
CRF oferece uma combinação única de propriedades:
Modelos treinados para etiquetar e segmentar sequências;
Combinação por arbitrariedade, características de observação aglomeradas, decodificação treinamento eficiente baseado em programação dinâmica e estimativa de parâmetro garantida para encontrar o ótimo global.
Sua principal limitação corrente é a lenta convergência do algoritmo de treino em relação a os MEMMs, por exemplo, para que o treino sobre os dados completamente observados seja muito eficiente.
Em a próxima seção destacamos as principais contribuições obtidas por a pesquisa.
O NERP-CRF foi o sistema desenvolvido neste trabalho para realizar duas funções:
A identificação de ENs e a classificação dessas com base nas dez categorias do HAREM:
Abstração, Acontecimento, Coisa, Local, Obra, Organização, Pessoa, Tempo, Valor e Outro.
Dois testes foram realizados.
Um dos testes utilizou a CD do Segundo HAREM para treino e teste, obtendo Precisão de 83,48% e Medida-F de 57,92%.
Tais resultados são os melhores quando comparados com os outros sistemas participantes do Segundo O outro empregou a CD do Primeiro HAREM para treinar o modelo de CRF e a CD do Segundo HAREM para testar o mesmo modelo gerado.
Em esse caso as métricas obtidas foram:
80,77% de Precisão e 48,43% de Medida-F. A Precisão também foi o melhor resultado quando comparado com os outros sistemas.
Já a Medida-F apresentou o terceiro melhor resultado, ficando abaixo de os sistemas Priberam e Rembrandt, que apresentaram maior abrangência.
De acordo com os dois testes desenvolvidos neste trabalho, verificou- se que o CRF é um modelo que produziu o efeito significativo esperado com base nos excelentes resultados apresentados, face a a concorrência com os outros sistemas os quais ele foi avaliado.
O objetivo foi alcançado e o modelo proposto, baseado em CRF bem como no conjunto de features estabelecidas, gerou um sistema eficaz, competitivo, sendo ainda passível de fácil adaptação e modificação.
Esse sistema obteve resultados melhores quando comparados com sistemas avaliados no mesmo corpus, apresentando a melhor pontuação de Precisão, até agora, para o conjunto de dados do corpus do HAREM.
Pode- se citar, de entre as contribuições científicas dessa dissertação, o processo de identificação e classificação de EN por meio de o método supervisionado denominado CRF para o corpus do HAREM.
Até então, não há nenhum trabalho que apresente exatamente essa proposta para o referido corpora.
Uma vez que os métodos encontrados, na literatura, aplicaram nos textos do HAREM heurísticas para identificar e classificar as EN considerando as dez categorias estabelecidas por essa conferência.
Os trabalhos futuros dessa dissertação determinam- se em duas abordagens de pesquisa:
Algoritmos de indução de features e classificação de EN consideradas ambíguas.
Um aspecto atraente do CRF é que esse pode implementar, eficientemente, a seleção de features e de algoritmos de indução de features.
Isto quer dizer que ao invés de especificar antecipadamente quais features serão utilizadas, pode- se iniciar a partir de regras que geram features e avaliam o benefício dessas geradas automaticamente sobre os dados.
Em particular, os algoritmos de indução de features apresentados em podem ser aplicados para adaptar- se à técnicas de programação dinâmica de Outra abordagem de pesquisa futura é a classificação correta de uma mesma EN apresentada de formas diferentes, por exemplo:
A EN Pontifícia Universidade Católica do Rio Grande do Sul pode receber a mesma classificação ou ser categorizada como Organização e Local dependendo do contexto em a qual essa entidade está inserida.
Isso implica que o REN é caracterizado por tornar as decisões interdependentes complexas, as quais exigem grande quantidade de conhecimento prévio e a aplicação de decisões não locais para essa EN receber classificações diferentes.
Outra situação que pode ocorrer é quando as EN Pontifícia Universidade Católica do Rio Grande do Sul e PUCRS são a mesma entidade e, portanto, devem receber a mesma classificação.
As soluções para a correta categorização de EN nesse caso pode ser a aplicabilidade de recursos externos como, por exemplo, Correferência e o emprego de Gazetters.
