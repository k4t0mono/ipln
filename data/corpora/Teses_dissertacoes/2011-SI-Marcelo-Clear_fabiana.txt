As ontologias possibilitam o formalismo semântico e permitem o desenvolvimento de aplicações utilizando- as como base de conhecimento, fornecendo assim melhor representação dos dados.
Esta dissertação propõe uma abordagem para solucionar os três principais desafios da utilização de ontologias em Engenharia de Software:
Possibilitar a modelagem do conhecimento dispersa nos artefatos de software;
Viabilizar a criação da ontologia de modo semi-automático, em contrapartida ao oneroso processo de criação manual;
E trazer maior formalismo ao processo de desenvolvimento de software, uma vez que a ontologia é processável por máquina.
Para a definição da abordagem utilizou- se das áreas de conhecimento existentes, como a aplicação de um conjunto de técnicas de Processamento da Linguagem Natural para identificar e extrair as informações relevantes contidas nos detalhamentos de casos de uso.
Sendo assim, tornou- se possível a geração da ontologia inicial, a partir de o mapeamento do diagrama de classes que descreve o modelo de domínio do software, e seu posterior refinamento, através do detalhamento dos casos de uso.
O resultado final é um conjunto de tuplas extraídas a partir de a descrição detalhada dos casos de uso.
Através da inspeção manual é gerada uma ontologia refinada de modo semi-automático, minimizando, com isto, a intervenção humana na construção da ontologia.
Por fim, a ontologia final descreve a solução de software proposta, possibilitando o melhor entendimento dos conceitos relacionados à solução que está sendo construída.
Palavras-chave: Ontologia;
Engenharia de Software (ES);
Processo Racional Unificado (RUP).
A ontologia exerce o papel de apoiar a atividade de compartilhar o conhecimento de um determinado domínio.
Um conceito de uma ontologia pode ser definido como o significado semântico de um termo num determinado domínio.
Um domínio é caracterizado por um conjunto de propriedades que o descrevem (uma área do conhecimento).
O conhecimento do domínio é representado através de um formalismo declarativo, refletido num vocabulário.
Gruber define a ontologia como uma especificação explícita de uma conceituação.
As ontologias possibilitam o formalismo semântico e permitem o desenvolvimento de aplicações utilizando- as como base de representação do conhecimento.
São utilizadas com a finalidade de permitir a interoperabilidade entre aplicações, disponibilizando conceitos comuns e formais do domínio.
Sua finalidade é caracterizar uma conceituação, limitando as interpretações possíveis e estabelecendo um consenso sobre o conhecimento por ela representado.
As ontologias também podem revelar- se muito úteis quando utilizadas com a finalidade de explicitar formalmente a semântica dos artefatos durante o processo de desenvolvimento de software.
Abaixo encontram- se listadas algumas das vantagens de utilizar ontologias no processo de desenvolvimento de software,:
Permitir compartilhamento do entendimento comum das informações.
Possibilitar a reutilização do conhecimento do domínio.
Explicitar as informações do domínio, através do entendimento e atualização dos dados.
Fornecer a formalização dos termos, descrevendo o domínio.
Embora a utilização de ontologias para o apoio ao processo de desenvolvimento de software traga muitos benefícios por proporcionar a formalização do conhecimento, o processo de criação manual da ontologia é definido por Maedche e Staab como &quot;uma tarefa tediosa que pode facilmente resultar num gargalo na aquisição do conhecimento».
A Aprendizagem de Ontologia (do termo inglês Ontology Learning, inicialmente definido por Maedche e Staab) é descrita como uma atividade que envolve diferentes áreas de pesquisa, sob a perspectiva de um processo de aquisição e definição de um modelo de domínio a partir de diferentes tipos de dados.
A A o pode ser definida como &quot;um suporte semi-automático ou automático para construção de ontologias».
Em a literatura, de entre as áreas de pesquisa, é encontrada a utilização de algoritmos de aprendizagem de máquina, Processamento da Linguagem Natural (PLN), Mineração de Dados e Recuperação de Informações a partir de bases textuais, com a finalidade de auxiliar na aquisição do conhecimento relacionado à aprendizagem de ontologias.
Este trabalho apresenta uma abordagem que utiliza técnicas de PLN existentes para viabilizar a criação e o refinamento de ontologias que expressem o conhecimento contido nas descrições detalhadas de casos de uso, geradas no processo de desenvolvimento de software.
A ontologia inicial é gerada a partir de o mapeamento do modelo de domínio descrito através do diagrama de classes.
O refinamento e enriquecimento da ontologia inicial utilizaram- se da aplicação de um conjunto de técnicas de PLN para identificar e extrair as informações relevantes contidas nos detalhamentos de casos de uso que descrevem a aplicação em desenvolvimento.
Através da utilização destas técnicas, tornou- se possível a identificação de novos relacionamentos e conceitos, resultando numa ontologia final, gerada e refinada de modo semi-automático, minimizando com isto a necessidade de intervenção humana na construção de ontologias para o apoio ao processo de desenvolvimento de software.
Definição do Problema Em a literatura, referente a a Inteligência Artificial (Ia), encontra- se diversas propostas para auxiliar o processo de geração automática de uma ontologia.
Em o contexto de Engenharia de Software (ES), a proposta é utilizar o conhecimento contido nas descrições detalhadas de casos de uso, que descrevem os requisitos do sistema de software em construção, para enriquecer e refinar ontologias que representem a semântica do problema.
Os casos de uso contêm requisitos que descrevem as funções e restrições de um sistema de software.
Casos de uso são comumente utilizados para elicitação de requisitos de software e são descritos em linguagem natural.
A interpretação e recuperação das informações contidas nestas descrições detalhadas não são triviais, embora exista grande riqueza de informações nestes documentos.
Questão de Pesquisa Com a finalidade de propor uma solução ao problema, surge a questão de pesquisa:
&quot;Como criar e refinar uma ontologia de forma semi-automática a partir de o diagrama de classes que descreve o modelo de domínio e da descrição detalhada dos casos de uso gerados no processo de desenvolvimento de software?».
Objetivos Maedche e Staab definem a construção de uma ontologia como &quot;uma tarefa tediosa que pode facilmente resultar num gargalo na aquisição do conhecimento», representando um processo manual oneroso.
Observando a definição dos autores da área, os objetivos deste trabalho incluem:
Facilitar o trabalho de criação, refinamento e enriquecimento da ontologia;
Garantir o mapeamento do conhecimento de modo mais abrangente.
Desenvolver uma abordagem para realizar a identificação de conceitos e relacionamentos da ontologia;
Trazer maior formalismo ao processo de desenvolvimento de software, pois através da linguagem OWL que descreve a ontologia, é possível o processamento por máquina.
Estrutura da dissertação O texto está dividido em 7 Capítulos.
Em o Capítulo 2, encontra- se descrita a fundamentação teórica necessária para compreensão do contexto em que está inserido este trabalho.
O Capítulo 3 descreve os trabalhos relacionados a esta pesquisa e apresenta as considerações sobre cada trabalho.
O Capítulo 4 apresenta as etapas da abordagem definida neste trabalho.
O Capítulo 5 apresenta a ferramenta desenvolvida para apoiar a abordagem proposta neste trabalho.
Esse Capítulo também inclui o diagrama de classes, contendo as principais classes da ferramenta para melhor entendimento.
O Capítulo 6 descreve dois exemplos de utilização da abordagem, para dois sistemas descritos na literatura, os resultados obtidos e as considerações finais sobre os resultados.
Em esse Capítulo também é apresentada a avaliação da abordagem através da aplicação de uma survey, respondida por 10 participantes.
Por fim, o Capítulo 7 apresenta sugestões de trabalhos futuros e a conclusão final desta pesquisa.
Este Capítulo apresenta a fundamentação teórica necessária para entendimento deste trabalho.
O Capítulo inicia com a definição do termo ontologia, contextualizando os principais conceitos da área.
Apresenta ainda a revisão teórica das áreas de Aprendizagem de Ontologia e Evolução da Ontologia (termos traduzidos de Ontology Learning e Ontology Evolution respectivamente).
Para o entendimento destas áreas de estudo, estão contextualizadas as várias técnicas listadas na literatura que viabilizam a A o.
Por fim, encontra- se descrito resumidamente o Rational Process Unified (RUP), contexto que está inserido esta pesquisa.
Ontologia O termo grego ontologia advém da filosofia e significa o &quot;conhecimento do ser».
As ontologias são modelos sobre vocabulários e seus significados, definidos explicitamente, expressivamente e semanticamente, possibilitando a interpretação por máquina.
Fornecem um modelo explícito para estruturação de conceitos e representação de suas relações.
Em Ia, a representação de conceitos e relacionamentos desempenha papel fundamental na gestão do conhecimento, pois fornecem um modelo de representação para solucionar problemas decorrentes da incapacidade das máquinas de compreender a Linguagem Natural (LN).
Em o contexto da computação, uma das definições mais citadas é fornecida por Gruber, onde:
&quot;Ontologia é uma especificação explícita de uma conceituação».
Uma definição formal para ontologia é especificada por uma estrutura conforme apresenta a Figura 1.
A estrutura apresentada por Cimiano define:
O identificador C para conceitos, R relações, A atributos e T tipos de dados;
C, representa a hierarquia ou taxonomia de conceitos;
Representa a assinatura da relação, que corresponde ao relacionamento entre dois conjuntos de conceitos C, o domínio e o range;
R, representa a hierarquia das relações;
Representa a assinatura dos atributos, que corresponde ao relacionamento entre os conjuntos C e T. As ontologias descrevem alguns componentes como classes, indivíduos, atributos e relacionamentos.
As classes representam conceitos do domínio (ou parte do mundo), e podem estar organizadas hierarquicamente, contendo outras subclasses.
Elas descrevem um grupo de indivíduos que compartilham propriedades.
Os conceitos são representados por termos que descrevem a sua semântica num determinado domínio.
Os indivíduos representam os objetos, e são instâncias das classes e propriedades.
Os relacionamentos ou relações são responsáveis por a criação da taxonomia hierárquica da ontologia, estabelecendo uma estrutura de árvore onde descrevem a relação entre objetos.
Eles descrevem a semântica do domínio, representando a relação de inclusão (é superclasse ou subclasse de), ou descrevem outros relacionamentos específicos do domínio modelado, refinando a semântica da ontologia.
Como exemplo, é possível citar:
&quot;Java «um tipo de &quot;Linguagem_ Orientada_ a_ Objetos «que um tipo de &quot;Linguagem_ de_ Programação».
Os atributos são as descrições dos objetos, possuindo um nome e valor.
Em o exemplo do objeto Java, um atributo válido é a versão.
O compartilhamento das informações é muito difícil, à medida que são comumente utilizados diferentes conceitos para um mesmo domínio, o que dificulta o reuso da informação.
Em Ia, o conceito de ontologia está relacionado à especificação de conceitos, definindo termos e relacionamentos entre eles.
Em a computação, a formalização do conhecimento, tornando- o acessível através da ontologia, possibilita o compartilhamento, utilização e reutilização da informação em ela contida, entre sistemas e indivíduos.
As ontologias possibilitam formalismo semântico permitem desenvolvimento de aplicações utilizando- as como base de conhecimento e fornecendo melhor representação dos dados.
São utilizadas com a finalidade de permitir a interoperabilidade entre aplicações, disponibilizando conceitos comuns e formais do domínio.
Em o contexto de ES, as ontologias podem ser importantes aliadas para explicitar formalmente a semântica dos artefatos durante o processo de desenvolvimento de software, servindo como base de conhecimento da aplicação.
Elas podem também ser utilizadas para explicitar decisões durante o processo de desenvolvimento de software.
Péres apresenta a representação do conhecimento através de ontologias aplicadas em diversos domínios, entre eles:
Comércio eletrônico (e-commerce);
Medicina; Engenharia;
Gestão de conhecimento.
O processo de desenvolvimento de uma ontologia envolve a escolha da linguagem de representação que será utilizada.
A descrição das ontologias é realizada por meio de linguagens baseadas na lógica, consistentes e que suportam a representação de conhecimento.
Em a literatura encontram- se descritas várias linguagens de marcação para representação da ontologia, conforme apresentado abaixo SHOE (Simple Html Ontology Extension):
Primeira linguagem de marcação para ontologias.
A linguagem é uma extensão do Html e combina frames e regras.
Posteriormente a linguagem foi adaptada para o XML.
XOL (XML-based Ontology exchange Language):
Linguagem de marcação que estende o XML e apresenta um subgrupo do protocolo OKBC (Open Knowledge Base Connectivity).
Description Framework): Description Framework Schema):
Oil (Ontology Interchange Language):
Linguagem baseada na XOL que estende uma estrutura básica para possibilitar a captura de uma lógica de descrição.
DAML-OIL (Darpa Agent Markup Language):
Linguagem desenvolvida como uma extensão do XML e RDFS.
OWL (Ontology Web Language):
Linguagem que deriva e substitui a Atualmente, a linguagem comumente utilizada é a OWL.
A linguagem OWL é atualmente indicada por a W3C por adicionar maior vocabulário para a descrição de classes e propriedades como, por exemplo, as relações de disjunção e cardinalidade entre as classes.
A seguir, apresenta- se uma breve descrição das áreas de aprendizagem de ontologia (A o) e evolução da ontologia (EO).
Aprendizagem de Ontologia (A o) A aprendizagem de ontologia (A o), assim como qualquer outra aprendizagem, só é útil e possível se motivada por o contexto e necessidades dos indivíduos.
A A o é a área de conhecimento relacionada à necessidade da ontologia em aprender novos conceitos durante o decorrer do tempo.
Para que o conhecimento possua sentido, ele deve estar organizado de modo estruturado.
A aprendizagem de novos conceitos relevantes é necessária devido a alterações num domínio.
A aprendizagem de ontologia inclui as seguintes tarefas:
Aquisição de terminologia relevante;
Identificação de termos que são sinônimos e variações lingüísticas;
Formação de conceitos;
Organização hierárquica do conhecimento (taxonomia das classes);
Aprendizagem de relacionamentos entre conceitos, propriedades ou atributos, conforme domínio de conhecimento da ontologia;
Organização hierárquica dos relacionamentos);
Instanciação dos axiomas;
Definição de axiomas gerais.
A extração de termos durante a aprendizagem da ontologia é fundamental.
A etapa consiste na identificação de um conjunto de termos relevantes para o domínio.
Após a identificação dos termos, a etapa de reconhecimento de sinônimos consiste na tarefa de reconhecer palavras que representam os mesmos conceitos no domínio.
A formação de conceitos a partir de os termos relevantes consiste na definição intencional e extensão dos conceitos.
Posteriormente, a etapa de hierarquia de conceitos prevê a definição hierárquica de um determinado conjunto de conceitos.
A aprendizagem de relacionamentos envolve a tarefa de identificar as relações entre os conceitos no domínio apropriado, mesmo não havendo relações taxonômicas.
A próxima etapa é denominada de hierarquia de relações e determina a ordem entre os relacionamentos.
A tarefa de esquemas de axiomas refere- se à identificação de conceitos, relações ou pares de conceitos aplicados ao sistema que devem ser instâncias de axiomas.
Os axiomas gerais correspondem à aprendizagem de axiomas e não apenas as instanciações.
Maedche propõe a aprendizagem de ontologia como um processo orientado que inclui as fases de importação, extração, corte e refinamento.
A Figura 3 apresenta o ciclo da aprendizagem de ontologia.
A fase de importação sugere a reutilização ou a fusão de ontologias existentes ou a definição de regras de mapeamento entre estas estruturas conceituais.
A extração de modelos corresponde à maior fase e refere- se à aprendizagem através da identificação de vários tipos de dados relevantes.
Ela corresponde à inclusão de novos domínios ou a manutenção e atualização da ontologia.
Em a fase de corte, a ontologia resultante das fases de importação, reutilização e extração, sofre a &quot;supressão «dos novos conceitos, com a finalidade de representar melhor o domínio.
A última fase corresponde ao refinamento com menor granularidade da ontologia.
Maedche relata a realização da validação da ontologia resultante do processo de aprendizagem a partir de a cobertura dos conceitos, obtida no domínio da aplicação alvo A aprendizagem da ontologia inclui várias técnicas:
Técnicas de aprendizagem de máquina;
Mineração de dados;
Processamento da Linguagem Natural (PLN).
O entendimento dos formalismos e técnicas disponíveis é necessário para aplicação destas durante o processo de A o.
A aprendizagem da ontologia inclui várias técnicas.
A técnica relevante para a criação da abordagem apresentada neste trabalho, de acordo com o domínio desta pesquisa, é a utilização do PLN no processamento dos documentos gerados durante o desenvolvimento de software para posterior identificação de termos relevantes e candidatos a conceitos na geração e refinamento da ontologia.
A seguir estão descritas cada uma destas técnicas.
Aprendizagem de Máquina A aprendizagem de máquina pode ser definida como o reconhecimento e detecção de padrões dentro de um conjunto de dados.
O reconhecimento de padrões pode ser utilizado para descrever os dados ou realizar previsões.
A aprendizagem de máquina supervisionada é comumente utilizada para predizer categorias.
Existem algoritmos de aprendizagem que possibilitam a construção de um modelo para grupos de treino.
A classificação é uma tarefa supervisionada, onde os dados de treinamento são marcados.
O resultado são conjuntos de dados treinados e classificados.
Os algoritmos de classificação possuem diferentes paradigmas.
Alguns destes paradigmas são apresentados abaixo:
Redes neuronais:
Rede de neurônios interconectados, formando um sistema dinâmico, onde o novo estado é função do estado anterior.
Uma rede neural pode ser formalizada matematicamente, independente da topologia modelada.
Árvores de decisão:
Construída de forma iterativa, cada etapa executa um algoritmo de aprendizado responsável por criar um novo &quot;ramo «para cada valor possível, onde um dos elementos restantes é escolhido.
Classificadores Bayesianos: Modelagem estatística baseada no teorema de Bayes.
O aprendizado é realizado através de modelos probabilísticos, onde assume a hipótese de que todos os elementos são independentes e possuem a mesma relevância Métodos de aplicação de aprendizagem de máquina em grandes bases de dados são chamados de mineração de dados.
A seguir apresenta- se uma breve descrição sobre a área de estudo de mineração de dados.
Mineração de Dados A mineração de dados é uma etapa da área de Descoberta de Conhecimento em Banco de Dados (Knowledge Discovery from Data -- KDD).
Refere- se à extração ou mineração de conhecimento numa grande base de dados.
A descoberta de conhecimento (KDD) compreende as seguintes etapas:
Limpeza dos dados:
A etapa consiste na remoção de ruídos e dados inconsistentes;
Integração dos dados:
A etapa consiste na combinação de múltiplas fontes de dados;
Seleção dos dados:
A etapa consiste na seleção dos dados relevantes do Banco de Dados (BD);
Transformação dos dados:
A etapa consiste na transformação ou consolidação dos dados de modo apropriado à realização da mineração;
Mineração dos dados:
Processo de métodos inteligentes que são aplicados de modo a extrair padrões de dados;
Avaliação de padrões:
A etapa consiste na identificação de padrões que representam o conhecimento de interesse.
Apresentação do conhecimento:
O processo de descoberta de conhecimento numa grande base de dados não é trivial, pois envolve uma seqüência de passos conforme descritos acima.
A validade das informações extraídas é outro importante aspecto a ser considerado.
A identificação de padrões potencialmente úteis nos dados também está relacionada a esta área de estudo.
A mineração de dados utiliza algoritmos desenvolvidos nas áreas de pesquisa em Ia, no que tange a área de estudo em aprendizagem de máquina.
Possui também algoritmos na área de pesquisa em banco de dados, à medida que manipula dados volumosos, e por fim na área de estatística, no que diz respeito à validação e avaliação dos resultados obtidos após execução.
Processamento da Linguagem Natural -- PLN A linguagem natural (LN) constitui o primeiro meio com que os indivíduos se comunicam, questionam, expressam desejos, crenças e atitudes.
De modo geral, a LN apresenta as seguintes entidades:
Verbos: Descrevem eventos, estados, ações, crenças ou atitudes numa sentença;
Nomes próprios: Representam nomes individuais;
Nomes: Representam classes, tipicamente pessoas, animais ou coisas;
Adjetivos: Representam o valor dos atributos das classes e modificam os nomes;
Advérbios: Representam a descrição da forma e modificam o verbo;
Frases Preposicionais: Representam a condição no tempo/ espaço.
O PLN consiste na aplicação seqüencial da análise das diferentes atividades apresentadas abaixo:
Pré-processamento: Envolvem as etapas de tokenização, normalização, POS (Part-of-Speech), stemming, reconhecimento de entidades nomeadas (reconhecimento de nomes de entidades) e resolução de co-referência (tipo simples de co-referência, relacionada a nomes de entidades).
A tokenização consiste na detecção dos limites das palavras na sentença.
A normalização consiste na transformação num formato padrão.
A POS é a tarefa de atribuir a cada token a correspondência de parte de um discurso.
O stemming é aplicado em etapas de normalização e mapeamento de variações morfológicas.
Análise sintática:
Compreende técnicas de agrupamento de palavras e dependência gramatical para aumentar o significado sintático.
Análise semântica:
Consiste na análise do significado semântico.
Interpretação contextual:
Consiste na interpretação do contexto, ou seja, o significado relacionado à intenção do texto.
O processo de extração de informações em bases textuais possui basicamente duas partes:
A etapa de extração de fatos individuais através da análise local do texto e a etapa de integração dos fatos, produzindo novos ou maiores fatos, através de inferência.
Evolução de Ontologia (EO) Ao longo de o tempo, são necessárias mudanças no domínio da aplicação ou nas necessidades do usuário do sistema, resultando na evolução da ontologia.
Existe uma crescente necessidade de definição de um método de manutenção de ontologias, tornando- se um campo interessante a ser pesquisado.
A Evolução da Ontologia (EO) pode ser definida como a adaptação temporal da ontologia de acordo com o surgimento das mudanças, propagando as alterações de modo consistente a todos os artefatos dependentes.
Para que seja possível a evolução, é necessária a aprendizagem de novos conceitos ao longo de o tempo.
A EO compreende nove atividades:
Mapeamento de ontologias, morfismo, alinhamento, para permitir a interoperabilidade;
Articulação, tradução, evolução, controle de versão, para garantir a coerência mediante as alterações da ontologia;
Integração e fusão, para unificar os conceitos e relacionamentos da ontologia original com a finalidade de compreender as necessidades do domínio.
A evolução da ontologia consiste em sofrer modificações ao longo de um determinado período de tempo, visando à manutenção do conhecimento.
Essas alterações podem ocasionar mudanças no vocabulário e terminologias ou em possíveis relações com outras ontologias.
O processo de EO pode ocasionar problemas, como a geração de inconsistência entre os relacionamentos da ontologia.
Para que um sistema de EO seja eficiente, é necessário definir um método para possibilitar ao usuário expressar seu pedido de mudança e o modo como a mudança solicitada pode ser realizada.
Com isto, a EO prevê um conjunto de atividades técnicas e gerenciais.
Stojanovic adapta da terminologia utilizada na área de banco de dados dois conceitos importantes:
Sistema de gestão de ontologia:
Envolve um conjunto de métodos e técnicas necessárias para criar, modificar, definir versões, consultar e armazenar ontologias.
Modificação da ontologia:
Consiste em alterar a ontologia sem levar em consideração as consistências necessárias.
Alguns interesses devem ser preservados durante a EO.
Chen descreve a EO com as finalidades listadas abaixo:
Identificar as mudanças de conceitos, papéis e indivíduos ao longo de o tempo;
Definir novos conceitos e relacionamentos e a compatibilidade com a ontologia atualizada;
Descartar conceitos antigos e avaliar potenciais impactos nas ontologias e nas aplicações envolvidas.
De acordo com Stojanovic o processo de EO prevê seis fases:
Alteração de captura da informação, alteração de representação, alteração da semântica, alteração de implementação, alteração de propagação e alteração da validação.
O controle de versões durante o processo de EO é um importante método de acompanhamento da ontologia.
A identificação e o controle das novas versões podem ser realizados através das técnicas de detecção da diferença estrutural, conceitual ou do conjunto de transformações.
Gestão da EO O ambiente empresarial evolui de modo dinâmico e contínuo.
As modificações estão relacionadas à necessidade de alterações do domínio da aplicação e na adição de funcionalidades ao aplicativo.
Stojanovic apresenta três razões básicas para modificar um sistema:
O ambiente de domínio do sistema pode sofrer modificações e invalidar o conhecimento em determinadas áreas ou necessitar adicionar funcionalidades ao passar dos anos.
Os processos internos sofrem reengenharia constante com a finalidade de obter melhor desempenho, exigindo adaptações do sistema e conseqüentemente da base de ontologia.
Os usuários do sistema solicitam modificações para corresponder as suas exigências, justificando a adaptação do sistema à atualidade.
Eles podem ser classificados como usuários finais, que utilizam aplicativos desenvolvidos com uma base ontológica, ou engenheiros de ontologia, que são responsáveis por o desenvolvimento e alteração da ontologia.
O desenvolvimento de uma ontologia pode ser considerado um processo dinâmico, pois começa a partir de uma ontologia inicial bruta, e posteriormente deve ser revista e refinada em seus detalhes, gerando uma ontologia final que satisfaça as necessidades previstas.
Acima, estão descritas as alterações que ocorrerão possivelmente num sistema, e para que uma ontologia possa servir de base para este sistema, o conhecimento que existe mapeado em ela deverá ser adaptado (aprendendo novos conceitos) e evoluir de acordo com o sistema, para não tornar- se obsoleta.
Problemas poderão advir da EO, em conseqüência de as alterações, tornando importante a definição de uma metodologia e ferramentas adequadas para auxiliar na realização desta tarefa.
Stojanovic identifica dois desafios serem compreendidos numa ferramenta que auxilie na execução automática da EO:
Complexidade: Uma ontologia pode possuir relacionamentos, o que pode significar em modificações cumulativas.
Dependência: Uma ontologia pode possuir outras ontologias de base, o que significa que a alteração de uma ontologia pode resultar na necessidade de modificação das suas ontologias base.
Rational Unified Process -- RUP Um processo pode ser definido como um conjunto de passos ordenados com intuito de atingir uma meta.
O RUP busca a utilização de algumas das melhores práticas de desenvolvimento, atribuindo tarefas e responsabilidades numa empresa de desenvolvimento de software, visando à produção de software com qualidade.
O RUP está definido como um processo iterativo, enfatizando a construção de modelos definidos na UML, e disponibilizando a representação semântica do software que está sendo desenvolvido.
Ele é composto por ciclos, onde a conclusão de cada ciclo é realizada na passagem por as fases e resulta numa versão do produto.
Cada fase no ciclo de vida de desenvolvimento do software é o período de tempo entre dois marcos de progresso do processo.
Em uma fase ocorrem várias e sucessivas iterações que passam por o fluxo do processo.
Cada iteração corresponde a um ciclo completo de desenvolvimento.
A Figura 4 apresenta o ciclo de vida de desenvolvimento de software.
Durante a fase de concepção, o foco está na captação de requisitos de alto nível, na compreensão do problema e no plano do projeto inicial.
Durante a fase de elaboração, o foco está na análise do domínio do problema, definição da arquitetura do sistema e no desenvolvimento do plano do projeto.
Durante a fase de construção, o foco é a implementação do sistema e no teste do software.
Já a última fase é a transição, que se caracteriza por a entrega do produto ao usuário.
O RUP define nove disciplinas.
Durante a modelagem de negócio, a estrutura e a dinâmica da empresa são identificadas.
O fluxo de trabalho de requisitos descreve os requisitos, identificando as necessidades de usuários e clientes.
A análise e projeto refinam os requisitos do fluxo de trabalho anterior, contribuindo para a definição de várias visões da arquitetura.
A disciplina de implementação é responsável por planejar as integrações do sistema, implementar os subsistemas, testar as implementações e integrar- las.
O teste define os casos de testes, procedimentos e medidas para acompanhamento dos erros.
Em esta disciplina, os testes são realizados exaustivamente e os resultados obtidos são analisados em cada teste executado, em comparação aos requisitos definidos por clientes e usuários.
A disciplina de entrega compreende o treinamento do usuário final, notas de versão ou outras necessidades relacionadas à entrega do produto.
O gerenciamento da configuração é responsável por o controle das modificações e manutenção da integridade dos artefatos do projeto.
A disciplina de gerenciamento de projeto descreve as estratégias para o trabalho de modo iterativo.
E por último, a disciplina denominada ambiente compreende a infra-estrutura necessária para tornar possível o desenvolvimento do sistema.
A abordagem descrita neste trabalho propõe a criação da ontologia inicial a partir de o modelo de domínio representado através do diagrama de classes.
Posteriormente, propõe o refinamento da ontologia inicial realizado de modo semi-automatizado através da leitura e interpretação dos detalhamentos de casos de uso que descrevem os requisitos do sistema, presentes na disciplina de requisitos do RUP.
Portanto, a abordagem desenvolvida propõe a utilização da ontologia como forma de manter e formalizar o conhecimento, viabilizando a sua criação e refinamento de forma semiautomática, utilizando- se do diagrama de classes e descrições detalhadas de casos de uso, artefatos gerados no RUP.
Tecnologias Utilizadas Para implementação da ferramenta de apoio a abordagem proposta neste trabalho, foi necessária a utilização de tecnologias existentes para viabilizar a geração e refinamento da ontologia durante o desenvolvimento de software.
Tendo visto o estado da arte em Ia, no que diz respeito aos principais conceitos que tangem o Processamento da Linguagem Natural, foi pesquisado um parser e algoritmos para auxiliar nas atividades propostas na abordagem.
Abaixo está detalhado o analisador utilizado, e outras tecnologias necessárias para a implementação da abordagem proposta neste trabalho.
Stanford Parser Um parser de linguagem natural é um programa analisador de linguagem natural, responsável por analisar a estrutura gramatical das sentenças organizadas em orações O Stanford parser é um pacote implementado em linguagem de programação Java disponível atualmente para a versão JDK 1.
5 ou posterior.
O parser foi desenvolvido para a análise de dependências lexicais de frases e fornece como saída as relações gramaticais estruturadas em forma de árvore.
O Stanford POS-Tagger apresenta a proposta de retornar as dependências gramaticais através da representação de uma rede de dependência, apresentando aproximadamente 97,24% de acurácia sobre a classificação do texto marcado.
O analisador Stanford permite a entrada de textos simples, fornecendo como saída a marcação de partes do discurso, uma estrutura de árvore ou as relações de dependência gramatical.
Para a frase &quot;I am testing the program.»,
a saída gerada por o parser será um texto marcado conforme apresenta a Figura 5.
O retorno do Stanford POS-Tagger à análise do texto é apresentado com algumas siglas, conforme descrição abaixo:
Outras formas de abreviação serão apresentadas por o parser de acordo com o texto analisado.
Adjetivos, preposições, advérbios, entre outros também são identificados por o Stanford POS-Tagger e representados através de siglas que estão descritas conforme artigo e documentação disponível na ferramenta.
O Stanford parser realiza a análise das sentenças e apresenta uma estrutura de árvore conforme apresenta a Figura 6.
Para a análise da sentença exemplo, a representação das dependências gramaticais está apresentada conforme segue:
De acordo com a análise da sentença exemplo, tem- se a estrutura identificada por o Stanford parser:
I, sujeito da sentença (quem realiza a ação);
Am, verbo da sentença;
WordNet A WordNet é um grande banco de dados lexicais para o idioma inglês, criado por o Departamento de Ciência da Computação da Universidade de Princeton.
A WordNet distingue substantivos, verbos, adjetivos e advérbios por possuírem regras gramaticais distintas, e estabelece as relações léxico-semânticas e semânticoconceituais entre as palavras.
As palavras são agrupadas em conjuntos de sinônimos denominados synsets, cada um representando um conceito distinto.
Os synsets podem conter ou um grupo de palavras sinônimas ou seqüências de palavras que co-ocorrem e formam um significado específico.
Um exemplo de saída da WordNet para a palavra &quot;sale «é apresentado na Figura 8.
Uma palavra pode ter mais de um sentido, sendo denominada de polissêmica ou compartilhar o mesmo sentido comum com outra palavra, sendo um sinônimo.
As variações nas relações semânticas estão incorporadas na WordNet e estão descritas como ponteiros entre as palavras e os sentidos da palavra.
Abaixo estão listadas as relações semânticas:
Sinonímia: Relação de base da WordNet, uma vez que está organizada em conjuntos de sinônimos (synsets) para representar o sentido das palavras;
Antonímia: Representa o sentido oposto das palavras e é importante na organização de adjetivos e advérbios;
Hiperonímia: Palavras que representam o sentido de um todo (significado abrangente) ­ super-nome;
Hiponímia: É oposto da hiperonímia e representa o sentido de parte ou item de um todo (significado mais específico) ­ sub-nome.
As relações de hiperonímia e hiponímia possibilitam a organização hierárquica dos significados dos substantivos, pois geralmente para cada hipônimo, existe apenas um hiperônimo;
Holonímia: Representa a relação de inclusão entre duas palavras, onde denota o todo -- nome completo;
Meronímia: É o oposto de holonímia e representa a relação de parte de um todo ­ parte do nome.
As relações de holonímia e meronímia se distinguem das relações de hiperonímia e hiponímia por não haver transferência de propriedades semânticas, não estabelecendo o significado de &quot;é um subtipo de «(hierarquia);
Troponímia: Representa a relação de sentido de parte ou item de um todo (significado mais específico) para verbos -- nome da forma;
Acarretamento: Representa a relação de acarretamento entre verbos, onde a verdade de uma sentença implica na verdade de outra.
Para que as frases tenham sentido, elas são compostas de palavras significativas Em a identificação do sentido das palavras, a WordNet observa as categorias sintáticas (substantivo, adjetivo, advérbio e verbo) e as relações semânticas, estabelecidas de acordo com o contexto que estão inseridas.
A utilização da WordNet neste projeto de pesquisa é importante durante as fases de geração e refinamento da ontologia inicial, auxiliando na identificação de conceitos a partir de termos extraído dos documentos do processo de desenvolvimento de software.
De acordo com Guarino a utilização da WordNet é de grande ajuda para a construção de ontologias, por permitir a generalidade, identificar ambigüidades e diferenças sutis, e garantir a legibilidade.
Em a literatura, são encontrados trabalhos que sugerem a utilização da ontologia para o apoio às atividades de desenvolvimento de software.
As ontologias desenvolvidas no domínio de ES geralmente são aplicadas com a finalidade de solucionar problemas decorrentes da existência de ambigüidade durante o processo de desenvolvimento de software.
A proposta desenvolvida em utiliza uma ontologia de componentes de software.
O autor relata a necessidade de modificação dos dados do projeto periodicamente, com a finalidade de representar o progresso e alterações no desenvolvimento do projeto, mudança nos requisitos, adição de funcionalidades, melhorias incrementais e re-configuração.
A ontologia é gerada com a finalidade de solucionar o problema da dificuldade de compreensão dos serviços de um componente, sua utilização e suas pré-condições e pós-condições operacionais.
O autor prevê a criação de uma ontologia que envolve o conhecimento genérico de componentes de software em ES e a modelagem de sub-ontologias que expressam as necessidades específicas do projeto.
Para criação da ontologia, a abordagem sugere o framework Jena e o formato OWL para representar o conhecimento.
O trabalho de Wongthongthaml et al.
Apresenta uma comparação entre a modelagem de ontologias e o modelo de orientação a objetos (UML).
A proposta retrata a transformação de um conjunto de conceitos de ES numa ontologia no domínio de ES.
Em cada projeto, haverá dados particulares modelados na ontologia.
Toda a equipe de desenvolvimento pode, através da ontologia, consultar a semântica dos dados do projeto, e através deste conhecimento modelado, levantar questões de debate, analisar problemas, propor revisões ou novas soluções de software.
O autor propõe a geração de uma ontologia através da similaridade do conceito de classes e suas relações existentes em diagramas de classes.
A abordagem apresenta notações gráficas para representar uma ontologia.
Em outro trabalho publicado por Wongthongthaml et al.,
a utilização de ontologias é apresentada com a finalidade de capturar e organizar o conhecimento de um determinado domínio, e facilitar a comunicação num projeto de ES.
As informações mapeadas em conceitos e relacionamentos da ontologia restringem as informações, possibilitando a utilização e manutenção do conhecimento sobre o projeto.
O autor propõe novamente uma ontologia de ES genérica e uma metodologia de criação de instâncias com informações específicas do projeto a partir de documentos UML, mas não apresenta um software para automação do processo.
Em é sugerido como trabalho futuro um processo para obtenção de conhecimento e viabilização da criação de instâncias da ontologia automaticamente, a partir de os dados contidos nos documentos de software.
O trabalho apresentado por Nicola et al.
Propõe uma metodologia para construção de ontologias derivada do Processo Unificado (UP), amplamente aceito na comunidade de ES.
O autor denominou a metodologia de UPON e justifica a necessidade da utilização de uma metodologia para geração de ontologias para auxiliar a tarefa de modelagem das ontologias executada por os engenheiros de ontologia.
O trabalho apresenta a metodologia de construção de ontologias seguindo os princípios subjacentes e as fases básicas do UP.
O UPON apresenta os objetivos de reduzir o tempo e o custo da construção de ontologias, melhorar a qualidade, e disponibilizar a busca semântica das informações para os usuários da ontologia.
A captura dos requisitos na metodologia UPON consiste na especificação das necessidades semânticas modeladas na ontologia de acordo com a visão do usuário.
A atividade necessita da interação dos analistas (que vão efetuar a modelagem do sistema), dos engenheiros do conhecimento e dos usuários da aplicação.
Nicola et al.
Sugerem as diretrizes a seguir (tarefas dos engenheiros de conhecimento e especialistas de domínio):
O engenheiro de ontologias tem como principal contribuição para a metodologia a modelagem conceitual.
A análise conceitual consiste no refinamento da ontologia gerada a partir de o cumprimento das tarefas anteriormente descritas.
Nicola et al.
Relatam ainda que, embora existam métodos de aprendizagem de ontologias, ainda persiste a necessidade de validação manual da ontologia construída, o que gera um esforço significativo.
Em este sentido, a metodologia proposta por Nicola et al.
Apóia o engenheiro de ontologias nesta tarefa.
O trabalho sugere como posterior etapa a automação da metodologia.
Considerações sobre os trabalhos relacionados Em este Capítulo estão descritos quatro trabalhos que utilizam ontologias em ES.
O primeiro trabalho necessita da utilização de uma ontologia inicial genérica de componente de software para após instanciar sub-ontologias que modelam o domínio específico.
Em e os autores propõe uma ontologia que modela o domínio de ES e apresentam uma metodologia para instanciação dos conceitos relativos ao projeto a partir de documentos UML.
Esta é a grande diferença destes trabalhos com a abordagem proposta nesta dissertação, pois de acordo com os autores, uma ontologia genérica inicial sempre é necessária, enquanto que na abordagem deste trabalho (apoiada por a ferramenta OntSoft) a ontologia inicial é gerada, refinada e enriquecida durante a engenharia de requisitos no processo de desenvolvimento de software.
A abordagem apresentada em sugere um processo para construção de ontologias com base no UP.
A grande diferença do trabalho de Nicola et al.
Para a abordagem desenvolvida e descrita nesta dissertação é que o foco deste trabalho está na automação do processo de construção de ontologias inserido no contexto do RUP de desenvolvimento de software.
Em contrapartida, Nicola et al.
Apresentam um processo para construção de ontologias, visando o apoio aos engenheiros de ontologias na tarefa de acelerar a consolidação e avaliação da ontologia gerada automaticamente ou auxiliar a construção de ontologias de domínio úteis e eficazes modeladas manualmente através da utilização de uma metodologia.
Embora existam algumas semelhanças entre os trabalhos apresentados neste exatamente no foco desta dissertação.
Apesar de isto, um acordo entre as abordagens apresentadas nos trabalhos e a abordagem definida nesta dissertação é a utilização da linguagem OWL, recomendada por a W3C, para descrição da ontologia construída.
O objetivo da abordagem apresentada neste trabalho é possibilitar a representação do conhecimento contido no modelo de domínio e nos detalhamentos de casos de uso de software, através de ontologias.
Para isto, está previsto a captura e codificação do conhecimento de forma semi-automatizada, através da identificação de conceitos e relacionamentos, facilitando o trabalho de criação e refinamento da ontologia.
A utilização de ontologias no RUP de desenvolvimento de software pode trazer muitos benefícios, por proporcionar a formalização do conhecimento, possibilitando o melhor entendimento dos conceitos relacionados à solução de software no decorrer de o seu desenvolvimento.
De acordo com, as ontologias podem auxiliar o desenvolvimento de software.
Porém, o processo de geração e manutenção de ontologias não é trivial.
A criação de uma ontologia envolve o profundo conhecimento do domínio que está sendo modelado.
A abordagem deste trabalho propõe a aplicação de técnicas de Ia para viabilizar a criação e aprendizagem da ontologia.
A ontologia é gerada a partir de o diagrama de classes que descreve o modelo de domínio e, por fim, enriquecida e refinada a partir de as descrições detalhadas de casos de uso, possibilitando com isto a representação do conhecimento, e permitindo a identificação dos artefatos relacionados semanticamente.
A criação desta abordagem visa viabilizar o processo oneroso de criação da ontologia, e permitir o refinamento da ontologia proposta, representando com menor granularidade os conceitos relevantes do domínio da aplicação de software em desenvolvimento.
A Figura 9 apresenta a abordagem dividida em duas fases.
A primeira fase corresponde à geração da ontologia inicial e a segunda fase refere- se ao refinamento e enriquecimento da ontologia inicial.
As fases da abordagem estão detalhadas a seguir.
Criação da Ontologia Inicial Para a criação da ontologia inicial, está previsto o mapeamento das informações contidas no modelo de domínio para uma ontologia.
O modelo de domínio está descrito como um diagrama de classes definido na UML (Unified Modeling Language) que modela a estrutura geral do problema.
O modelo de domínio retrata o cenário geral do sistema, visando à descrição do problema que o software pretende solucionar.
Para entendimento desta abordagem, a Figura 10 apresenta o diagrama de classes que define o modelo de domínio da aplicação ProxGer apresentada como exemplo de uso no Capítulo 6 desta dissertação.
A partir de o diagrama de classes é possível modelar a ontologia inicial da aplicação.
Um diagrama de classes da UML pode ser representado por um arquivo XMI e interpretado através de um parser desenvolvido para interpretação de arquivos XML.
Um trecho do arquivo XMI que representa o diagrama de classes da Figura 10 é apresentado na Figura 11.
A extração da ontologia inicial parte da simplificação da definição formal da que define classes, relacionamentos e atributos.
De acordo com o modelo de domínio apresentado na Figura 6, podem- se extrair os seguintes conjuntos:
Diary_ Book, Sale_ Line_ Item, Store, Product_ Catalog, Item, Sale, Product_ Specification, Payment, Customer, Considerando ainda o sistema ProxGer, é possível identificar os R (Records-sale-on-) $= (Cashier, POST).
Através da extração destas informações, a ontologia inicial é gerada.
Para criação e alteração da ontologia, é utilizado o framework Jena, desenvolvido em linguagem de programação Java, por disponibilizar um ambiente de programação e um mecanismo de inferência baseado em regras.
A linguagem utilizada para geração da ontologia inicial é o OWL (indicação da W3C conforme apresenta o Capítulo 2).
A modelagem de uma ontologia a partir de o modelo de domínio descrito num diagrama de classes está previsto no trabalho desenvolvido em Noll e serve de insumo para esta pesquisa.
Refinamento da Ontologia O refinamento da ontologia está previsto na abordagem como uma seqüência de passos para extração de informações relevantes identificadas a partir de os documentos que descrevem o modelo de domínio da aplicação e documentos que descrevem os detalhamentos de casos de uso gerados durante a disciplina de requisitos descrita no Durante a disciplina de requisitos, são expressos os requisitos funcionais (necessidades de usuários e clientes) através do modelo de casos de uso.
Um caso de uso descreve o comportamento do sistema, podendo conter diferentes sequências de comportamento.
Em a UML, um caso de uso está definido como um conjunto de seqüências de ações executadas por o sistema com a finalidade de produzir um resultado observável por um ator.
A fase de concepção do desenvolvimento de software inclui a identificação dos casos de uso mais importantes, delimitando o domínio do sistema.
Em a fase de elaboração, os casos de uso são especificados com melhor detalhamento.
Durante a fase de construção, as iterações estão voltadas para a construção do software, e para isto são identificados os requisitos restantes que devem ser implementados.
A última fase do ciclo de vida de desenvolvimento inclui a captura dos requisitos, caso haja alguma alteração ou implementação adicional do sistema.
A forma mais simples de descrição de um caso de uso envolve a identificação dos tipos de interação e os atores envolvidos.
Um detalhamento de caso de uso aceito por o RUP possui os seguintes campos:
Identificação: Nome do caso de uso;
Atores: Nome dos atores.
Um ator representa um conjunto de papéis que desempenha ao interagir com o caso de uso;
Pré-condições: Definição das condições prévias para a execução do caso de uso (opcional);
Pós-condições: Definição das condições posteriores à execução do caso de uso (opcional);
Fluxo Básico: Seqüência típica de eventos definida na ação do ator e resposta do sistema;
Fluxo Alternativo: Seqüência alternativa em resposta à ação de um ator.
Pode não existir ocorrências de fluxo alternativo num determinado caso de uso.
Tabela 1 -- Exemplo de detalhamento de caso de uso adaptado de[ LAR07].
Use Case UC1:
Process Sale Primary Actor:
Cashier Stakeholders and Interests:
Cashier: Wants accurate, fast entry, and no payment errors, as cash drawer short ages are deducted from his/ her salary.
Salesperson: Wants sales.
Company: Wants to accurately record transactions and satisfy customer interests.
Wants to ensure that Payment Authorization Service payment receivables are components (e.
g, remote credit validation) are unavailable.
Wants automatic and fast Manager:
Wants to be able to quickly perform override operations, and easily debug Cashier problems.
Government Tax Agencies:
Want to collect tax from every sale.
May be multiple agencies, such as national, state, and county.
Payment Authorization Service: Wants to receive digital authorization requests in the correct format and protocol.
Wants to accurately account for their payables to the store.
Preconditions: Cashier is identified and authenticated.
Post conditions: Sale is saved.
Tax is correctly calculated.
Accounting and Inventory are updated.
Commissions recorded. Receipt is generated.
Payment authorization are recorded.
Basic Flow: Total.
Extensions or Alternative Flows:
A. At any time, Manager requests an override operation:
Observando a descrição de um caso de uso qualquer, é possível identificar certa estrutura na sua descrição.
Ao contrário de um texto qualquer, o detalhamento segue uma estrutura conforme ilustrou a Tabela 1.
Os casos de uso tornaram- se fundamentais para a descrição de modelos de sistemas.
O detalhamento de caso de uso traz informações importantes, como os requisitos essenciais que o software em desenvolvimento deverá contemplar.
Estas informações estão descritas em Linguagem Natural (LN), o que pode resultar em ambigüidade de interpretação, característica da linguagem livre.
Para possibilitar a extração das informações relevantes descritas em LN, a abordagem está dividida em etapas.
A primeira etapa do processo de refinamento da ontologia consiste em identificar as informações relevantes contidas na descrição do caso de uso.
Estas informações, posteriormente, poderão ser categorizadas em conceitos e relacionamentos.
Para isto, estão previstas as seguintes atividades:
Stanford POS-tagger na ferramenta desenvolvida para apoio a esta abordagem (conforme apresenta o da ocorrência de período composto.
Para gerar as tuplas, algumas regras implementam novamente o parser para identificar o sujeito, ou utilizam da base de dados lexical disponível através do WordNet.
Maiores detalhes sobre a criação das regras são descritos na seção 4.2.1.
Sendo assim, ao executar o Stanford POS-Tagger no caso de uso de exemplo acima, tem- se a seguinte saída conforme apresenta a Figura 13.
O POS-tagging é responsável por a categorização sintática das palavras de um texto.
A análise da frase através da utilização do Stanford parser permite a identificação do sujeito da oração.
Sendo assim, a aplicação do parser no trecho do detalhamento de caso de uso apresentado na Tabela 1 resulta no arquivo conforme apresenta a Figura 14.
Assim, para o refinamento da ontologia inicial, duas importantes informações são obtidas a partir de o detalhamento de caso de uso:
Identificação da categoria gramatical de cada palavra e reconhecimento do sujeito de cada frase.
A Figura 15 apresenta um trecho do detalhamento de caso de uso e as informações identificadas através do POS-tagger e do parser Stanford.
A partir de a identificação destas estruturas, é possível a indução de uma série de relacionamentos e conceitos candidatos a refinar a ontologia.
Considerando o exemplo do trecho do detalhamento de caso de uso, é possível identificar alguns relacionamentos.
R (enters) $= (cashier, item).
De acordo com o exemplo, é possível observar os substantivos (NN) como prováveis conceitos, identificando domínio e range respectivamente, e o verbo (VB) aparecendo como a relação que os une, porque os verbos tendem as ser modelados como relações.
A identificação dos conceitos e relacionamentos ocorre a partir de o mapeamento de regras que prevêem a estrutura gramatical das frases e sugere tuplas para refinar e enriquecer a ontologia inicial.
A seguir está detalhada a criação das regras utilizadas neste trabalho.
Definição das regras Com a finalidade de possibilitar a geração das tuplas de refinamento da ontologia inicial, foi necessário estabelecer regras sobre as orações que descrevem os casos de uso.
As regras têm a finalidade de identificar conceitos e relacionamentos que possibilitem o refinamento da ontologia inicial.
Elas retornam tuplas descritas na estrutura ­, onde:
O conceito_ 1 identificado sugere um possível conceito existente na ontologia inicial ou sugere a criação de um novo conceito na ontologia, enriquecendo o conhecimento do domínio o qual representa.
O relacionamento identificado sugere um relacionamento entre dois conceitos;
O conceito_ 2 sugere um possível conceito anteriormente modelado na ontologia inicial (existente no modelo de domínio da aplicação) ou sugere a criação de um novo conceito na ontologia.
O detalhamento textual do caso de uso process sale foi utilizado como modelo para definição das regras iniciais da abordagem.
O processo inicial de criação das regras foi realizado contemplando as seguintes etapas:
Processamento do detalhamento de caso de uso por o POS-tagger Stanford, retornando como saída o texto etiquetado;
Processamento do detalhamento de caso de uso por o parser Stanford, retornando o texto marcado em sujeito (de entre outras informações que não apresentam interesse no contexto desta abordagem);
Identificação das estruturas nome+ verbo+ nome inicialmente;
Considerações das estruturas gramaticais:
Adjetivo, advérbio, verbo modal e preposições que interferem na semântica dos substantivos e verbos;
Tratamento dos sinais de pontuação:
Ocorrência de dois pontos e vírgula;
Tratamento das conjunções coordenativas (CC) and e or;
Identificação das regras que necessitam utilizar a informação de sujeito da oração informada através do parser;
Identificação da estrutura gramatical nome+ verbo na terceira pessoa do tempo verbal presente, e chamada da WordNet para substituição do verbo para o modo infinitivo;
Generalização das regras através da definição de zero ou mais ocorrências das estruturas gramaticais:
Preposição (In), determinante (DT), te o (Te o) e presença de números cardinais (CD).
A realização da identificação e formação das regras (expressões regulares) é responsável por gerar as tuplas de refinamento e enriquecimento da ontologia inicial.
A geração das regras deste trabalho levou em consideração a estrutura gramatical da língua inglesa.
A sintaxe é o estudo da combinação de palavras geridas por um conjunto de regras responsáveis por a construção de frases na linguagem natural.
As orações em língua inglesa dividem- se em sujeito e predicado, e podem ser formadas por períodos simples e compostos.
O sujeito pode ser um nome ou um pronome.
Um predicado exprime a noção de estado ou movimento do sujeito.
Um período simples é encontrado no detalhamento de caso de uso do autor «Larman:
Cashier starts a new sale.»
Onde a oração apresenta a estrutura:
&quot;Cashier&quot;: Sujeito da oração.
&quot;starts a new sale&quot;:
Predicado da oração.
A frase é um período simples por possuir apenas um único sujeito e um único predicado.
A o unirmos mais de um predicado na oração, tem- se um período composto.
Os períodos compostos são identificados através do símbolo de pontuação vírgula ou da conjunção e (classe gramatical).
As orações abaixo extraídas do detalhamento de caso de uso denominado Process Sale apresentam exemplos de períodos compostos.
&quot;Cashier tells Customer the total, and asks for payment.»
&quot;Customer pays and System handles payment.»
Em a primeira oração, o substantivo (ou nome) Cashier é o sujeito dos dois predicados:
Tells Customer the total e asks for payment.
Já a segunda frase apresenta dois sujeitos, o sujeito Customer para o primeiro predicado, e o sujeito System para o segundo predicado.
Durante a criação das regras que interpretam e geram tuplas para sugestão de refinamento da ontologia, estas duas estruturas simples de frases devem estar contempladas:
Para a primeira frase, a solução encontrada é quebrar a frase na vírgula, separando o processamento das duas orações.
Para isto, a abordagem prevê a etapa de pré-processamento das frases, antes de aplicar- las alguma regra.
Sendo assim, a primeira frase do exemplo anterior &quot;Cashier tells Customer the total, and asks for payment «gera duas orações:
Cashier tells Customer ­ primeira oração, que apresenta a estrutura sujeito Cashier e predicado tells Customer.
Cashier asks for payment ­ segunda oração, onde o sujeito da oração anterior escreve o sujeito da segunda oração.
Para formar esta oração, foi necessário aplicar o tagger Stanford parser para identificar o sujeito, e formar a segunda oração estruturada em forma de sujeito e predicado.
Sendo assim, a etapa de pré-processamento foi necessária para transformar os períodos compostos em períodos simples, e no exemplo anterior, para estruturar a frase em oração, com sujeito e predicado, foi necessário o processamento da frase por o parser para identificar o sujeito.
Em a outra frase utilizada para exemplificar o período composto &quot;Customer pays «não foi necessário o pré-processamento, pois a estrutura foi prevista através de regras, onde a conjunção coordenativa and (representada por o POS-tagger como CC ­ Coordinating conjunction) declara a possibilidade de após a primeira oração, existir uma segunda oração.
No caso de o exemplo escolhido, a segunda oração que forma o período possui o sujeito explícito, não sendo necessário submeter à frase ao processamento do parser para identificar o sujeito.
Sendo assim, seguindo a de período composto neste trabalho formam as seguintes tuplas:
R (tells) $= (Cashier, Customer) ­ representado na aplicação de apoio à abordagem com notação (Cashier, tells, Customer_ total);
R (asks_ for) $= (Cashier, payment) ­ representado na aplicação de apoio à abordagem com notação (Cashier, asks_ for, payment);
R (de o) $= (Customer, pays) ­ representado na aplicação de apoio à abordagem com notação (Customer, do, pays);
R (handles) $= (System, payment) ­ representado na aplicação de apoio à abordagem com notação (System, handles, payment).
A estruturação das regras também contou com outra importante consideração da análise gramatical.
Um verbo pode ou não vir acompanhado de um advérbio (que modifica o verbo, adjetivo ou advérbio) e um substantivo pode ou não vir acompanhado de um adjetivo (modificador do nome).
Sendo assim, as classes gramaticais advérbio e adjetivo etiquetadas por o parser Stanford POS-tagger como Rb e JJ respectivamente, são consideradas diferencialmente nas regras.
Os advérbios podem concatenar- se ao verbo ou ao nome, conforme posição que se encontra na oração.
Para isto, durante a programação das regras foi estabelecida a seguinte estrutura:
Se o advérbio (Rb) encontra- se posicionado antes do verbo (VB), concatena- se com o verbo ao formar a tupla.
Se o advérbio (Rb) encontra- se posicionado após a ocorrência do verbo (VB) na oração, concatena- se com o nome (NN) mais próximo de o verbo, para formar a tupla.
Se o advérbio (Rb) encontra- se posicionado antes da ocorrência do adjetivo (JJ) na oração, concatena- se com o adjetivo (JJ) para formar a tupla.
Um exemplo da ocorrência do advérbio (Rb) no caso de uso process sale extraído de Larman, é apresentado logo abaixo:
A oração &quot;Tax is correctly calculated.»,
após processada por o parser Stanford POS-Tagger retorna a estrutura anotada Tax_ NNP is_ VBZ correctly_ RB calculated_ VBN, formando tupla (Tax, is, correctly_ calculated) onde, Tax representa um conceito na ontologia, correctly_ calculated outro conceito na ontologia e is o relacionamento entre os conceitos.
A classe gramatical adjetivo, por sua vez, caracteriza um substantivo ou nome, designando- o características como modo ou estado.
Para representar esta classe na ontologia, as regras prevêem o relacionamento can_ be quando de a ocorrência do adjetivo antes do substantivo na oração.
Um exemplo da ocorrência do adjetivo (JJ) no caso de uso process sale extraído de Larman, é apresentado logo abaixo:
A oração &quot;Cashier starts a new sale.»,
após processada por o parser Stanford POS-Tagger retorna a estrutura anotada Cashier_ NN starts_ VBZ a_ DT new_ JJ sale_ NN, formando as tuplas (Cashier, starts, sale) e (sale, can_ be, new), onde Cashier representa um conceito na ontologia, sale outro conceito na ontologia e starts o relacionamento entre os conceitos.
Sendo new pertencente à classe adjetivo, cria- se outro relacionamento que apresenta o estado do conceito sale, que pode estar caracterizado como new.
A motivação do uso de can_ be está no fato de que em outro ponto da descrição pode haver outro adjetivo modificando o mesmo substantivo.
De essa forma, optou- se por não denominar diretamento o relacionamento como is.
A classe gramatical da preposição «te o (Te o), entre verbos também deverá ser mantida na descrição do nome do relacionamento.
Assim, para a sentença &quot;Government Tax Agencies Want to collect tax from every sale», a tupla resultante será\&gt; As regras ainda apresentam algumas considerações especiais, principalmente para as ocorrências das preposições ou conjunções identificadas por o parser através da etiqueta In.
Em os exemplos abaixo (frase extraída de Larman):
&quot;Cashier asks for payment.»
Quando identificada a existência de In após o verbo, e In etiqueta as preposições from ou for, concatena- se o from ou o for com o verbo, formando as tuplas que segue:
O existencial there também necessita de tratamento especial.
Convencionou- se na abordagem que ao identificar a etiqueta EX, será criada a tupla conforme segue:
Para a frase &quot;There are product», a tupla retornada por a aplicação de apoio à abordagem é (System, has, product_ rebates), onde o existencial there (EX) é substituído por System e o verbo are por has.
Para as frases que apresentam a estrutura NN (nome)+ VBN (verbo na forma nominal -- particípio), a regra para identificar a tupla resultante desta formação envia o verbo nominal para a WordNet que retorna o verbo no infinitivo, resultando na tupla conforme exemplo abaixo:
&quot;Commissions recorded», resulta na tupla (Commissions, do, record).
Porém, para as ocorrências de frases estruturadas com nome+ verbo+ nome (se existir)+ forma nominal verbal particípio (NN+ VB+ VBN), o verbo nominal concatena com o nome (se existir), ou representa sozinho um conceito (range) na tupla formada.
A frase &quot;Salesperson wants», resulta na tupla e apresenta o verbo nominal particípio &quot;updated «concatenado com as demais ocorrências nominais.
Os verbos na forma nominal gerúndio indicam uma ação que está sendo realizada (em andamento) e tiveram a sua ocorrência tratada diferentemente nas regras.
Assim, convencionou- se que para as frases estruturadas na forma nome+ verbo+ nome+ verbo nominal gerúndio (NN+ VB+ NN+ VBG), o verbo nominal concatena com o nome mais próximo.
Para exemplificar esta estrutura de frase, é encontrada na descrição detalhada do caso de uso process sale a sentença:
&quot;System detects anomalies preventing recovery «Onde:
Esta sentença, após processada por a regra adequada, concatena a ocorrência do verbo no gerúndio &quot;preventing «com as ocorrências nominais (anterior e/ ou posterior), resultando na tupla\&gt; Durante a criação das regras, verificou- se a necessidade de tratar as frases que terminam com a seqüência gramatical preposição+ nome (In+ NN) ou Te o+ nome (Te o+ NN) diferentes na formação do conceito da tupla gerada, evitando a formação de n-gramas desnecessariamente.
Sendo assim, para a sentença original «Cashier cancels System $= nome (NN).
A tupla resultante é (Cashier, cancels, sale), onde:
Sale $= conceito (range).
Em este exemplo, portanto, &quot;on System «são desconsiderados na definição da abordagem para formação da tupla, por não acrescentar informação relevante para a ontologia.
Outro exemplo é a frase &quot;System signals error te o Cashier», onde:
Cashier $= nome próprio (NNP).
A tupla resultante do processamento desta sentença é (System, signals, error), onde:
Em este outro exemplo, as palavras &quot;te o Cashier «não foram consideradas na tupla resultante, por pertencerem à classe gramatical preposição (para) e nome próprio respectivamente.
Erros de classificação gramatical foram identificados na etiquetagem do parser Stanford POS-Tagger, o que acarretou em problemas na criação das tuplas.
Um exemplo que ocorreu comumente no processamento do caso de uso process sale é o reconhecimento do verbo como NNS (substantivo no plural).
A oração &quot;System records sale», extraída de Larman, depois de anotada por o parser Stanford POS-Tagger, classifica a palavra records na classe gramatical substantivo no plural (NNS).
Embora seja possível classificar a palavra como um substantivo, ela pertence à classe gramatical verbo no contexto em que está inserida.
Para estas estruturas, onde o parser identifica um ou mais substantivos seguidos de um NNS e de um ou vários substantivos (NN+ NNS+ NN), a abordagem classifica o NNS como sendo o relacionamento entre os conceitos.
As tuplas formadas neste caso, para a frase de exemplo proposta são, respectivamente, (System, records, sale_ line_ item) (System, presents, item_ description).
Pré-processamento das sentenças A etapa de pré-processamento prevê a realização da limpeza das sentenças.
A limpeza consiste na remoção dos caracteres que possuem classes gramaticais que não são de interesse para leitura da regra que irá gerar a tupla.
As classes gramaticais que são eliminadas durante o pré-processamento estão listadas a seguir:
PP e POS (possessive pronoun):
Pronomes possessivos não são considerados nas regras, de modo que a etapa de pré-processamento elimina da sentença a ocorrência desta classe gramatical.
PDT (determiner pronoun):
Determinantes (como por exemplo, meu, minha, este, esta) não são considerados nas regras.
PRP (personal pronoun):
Pronomes pessoais são desconsiderados caso ocorram na sentença.
Símbolos»,&amp;,»,`': Os símbolos como o dólar, Sharp, aspas duplas e aspas simples também são tratados antes das regras, e eliminados da sentença antes do processamento.
Ls (list item maker) e SYM (symbol mathematical/ scientific):
Os símbolos de marcação são eliminados por não representar relevância na formação das tuplas.
WDT (which determiner):
Removido determinante which antes do processamento por as regras por não possuir importância para formação das tuplas.
WP (which pronoun) e WP ( possessive which pronoun):
Removido which pronome antes do processamento da frase por as regras por não possuir importância para formação das tuplas.
WRB (which adverb):
Removido também o which (pertencente à classe gramatical advérbio) antes do processamento da frase por as regras por não possuir importância para formação das tuplas.
Colon (punctuation):
Removida a ocorrência do sinal de pontuação dois pontos na sentença.
Em a etapa de pré-processamento também convencionou- se desconsiderar o texto existente entre parênteses, por geralmente tratar- se de exemplos e não possuir importância para a geração das tuplas.
Sendo assim, a sentença abaixo:
&quot;Customer tells Cashier they have a tax-exempt status (e.
g, seniors, native peoples).»
Após pré-processada, retorna a frase assim:
&quot;Customer tells Cashier they have a tax-exempt status.»
Somente após a etapa de pré-processamento, onde as frases são reescritas, é que serão submetidas ao processamento das regras.
A formação das sentenças do campo stakeholders da descrição do caso de uso apresenta uma característica particular, pois descrevem o sujeito seguido do sinal de pontuação dois pontos, e as frases subseqüentes iniciando com um verbo.
Por causa de esta estrutura de frase foi necessário estabelecer um tratamento diferenciado, reescrevendo as frases com o sujeito, cada vez que a frase iniciar com um verbo.
Um exemplo desta estrutura está exemplificado na Figura a seguir:
O próximo Capítulo apresenta a ferramenta de apoio à abordagem deste trabalho.
A ferramenta OntSoft é um aplicativo de apoio à abordagem proposta.
Seu código foi escrito em linguagem de programação Java, e integra recursos como o parser POSTagger e o tagger de Stanford, o tesauro WordNet, e a biblioteca Jena, para apoio ao processo de criação e refinamento da ontologia em linguagem OWL.
Ferramenta OntSoft A ferramenta de apoio à abordagem proposta neste trabalho propõe o processamento do texto de entrada, que descreve o detalhamento de casos de uso, resultando num conjunto de saída que representa a tupla (conceito, relacionamento, conceito) que tem o objetivo de refinar e enriquecer a ontologia inicial.
Funcionamento do OntSoft A ferramenta OntSoft funciona de acordo com o esquema apresentado na Figura como entrada um arquivo texto (que descreve detalhamento de casos de uso);
Arquitetura do OntSoft Para desenvolver a ferramenta, foi necessária a implementação de um conjunto de classes.
A Figura 18 apresenta o diagrama de classes da aplicação OntSoft.
As principais classes que constituem o aplicativo OntSoft encontram- se listadas abaixo:
OntSoft: Classe responsável por a leitura do arquivo do detalhamento de caso de uso;
Tagger: Classe responsável por as anotações lingüísticas do arquivo;
Document: Classe responsável por separar as anotações lingüísticas do parser (classe gramatical) do texto (token);
Preprocessing: O módulo de pré-processo encontra- se detalhado na próxima subseção, e no diagrama de classes está descrito por a classe preprocessing, responsável por preparar a sentença antes de ser &quot;casada «com as expressões regulares que definem cada regra;
Rules Interpreter: Classe responsável por verificar se a sentença &quot;casa «(classe Matcher) com alguma expressão regular definida no arquivo em formato de texto denominado rules.
Tuple Builder: Classe que contém as seqüências de caracteres válidos (etiquetas do parser).
Exemplo: &quot;JJ «para adjetivo, &quot;VB «para verbo e etc..
São aceitos e lidos por o programa;
Builders: Representa todas as classes que implementam as regras definidas no arquivo de regras chamado rules.
A saída destas classes é uma ou mais tuplas referentes ao processamento da sentença.
WordNet: O pacote WordNet contém as classes que realizam a chamada para o banco de dados lexical.
Para exemplificar o fluxo de funcionamento da ferramenta OntSoft, para a sentença &quot;Commissions recorded.»,
a classe OntSoft lê o arquivo de entrada (detalhamento do caso de uso), realiza a leitura da sentença e encaminha ao Stanford POS-Tagguer que retorna o texto assim anotado:
&quot;Commissions_ NNS recorded_ VBN. .».
A sentença anotada é enviada para as classes Document e Token, onde são separadas as anotações em valores e tipos.
Em este exemlo, os valores seriam strings contendo as palavras commissions e recorded, e os tipos (classe gramatical que pertence cada palavra) NNS e VBN.
A classe RulesInterpreter é chamada e então é enviada para a classe Preprocessing que realiza a limpeza e re-escrita da sentença (se necessário) e depois é identificada a regra que &quot;casa «com a sentença.
A regra identificada por a classe RuleFileItem é instanciada (cada classe implementa uma única regra da lista) prevê a estrutura NN+ VBN para este exemplo.
Esta regra identifica a estrutura gramatical da sentença através da classe TupleBuilder.
A regra deste exemplo ainda chama a WordNet, que retorna o verbo no infinitivo record, e então a tupla (commissions, do, record) é retornada do processamento.
O fluxo de funcionamento para a sentença de exemplo &quot;System signals error and rejects entry.»
apresenta a diferença da regra que &quot;casa «com a sentença prever a existência da conjunção coordenativa and.
Em este exemplo, como o sujeito da frase é o mesmo para os dois períodos, a classe Tagger é chamada com a finalidade de identificar o sujeito.
Com isto, as tuplas são retornadas: (system, signals, error) e (system, rejects, entry).
Outros exemplos ainda necessitam que o sujeito seja identificado durante o préprocessamento, e então para a sentença de exemplo «Cashier restarts System, logs in, Tagger para identificar o sujeito e formar as sentenças:
&quot;Cashier restarts System.»,
retornada da classe Preprocessing é &quot;casada «com a sua respectiva regra e retornam as seguintes tuplas:
O sistema PDV ProxGer foi utilizado como modelo tanto para criação quanto para teste das regras de geração das tuplas a partir de o texto de entrada.
Para teste destas regras também foram utilizadas as descrições detalhadas de casos de uso do sistema Time Card.
Foram utilizados apenas os detalhamentos de casos de uso destes dois sistemas devido a o fato de existir grande dificuldade de encontrar exemplos completos de sistemas em domínio público.
Em este Capítulo, encontram- se detalhados os dois sistemas, as ontologias que representam o modelo de domínio das aplicações, os termos mais freqüentes extraídos a partir de as descrições de casos de uso e a análise sobre a survey aplicada nesta pesquisa.
Visão Geral do Sistema ProxGer (extraído de Larman) Um sistema PDV é uma aplicação de computador utilizada para registrar vendas e gerenciar pagamentos.
Consiste num sistema tipicamente utilizado em lojas de departamento e inclui componentes de hardware, como um leitor de código de barras, e um software para rodar o sistema.
Tem interfaces com várias aplicações de serviços, como, por exemplo, uma aplicação de cálculo de impostos e uma aplicação de controle de estoque.
Esses sistemas devem ser relativamente tolerantes a falhas, ou seja, mesmo que os serviços remotos fiquem temporariamente não disponíveis (como, por exemplo, o controle de estoque), eles devem ser capazes de capturar as vendas e tratar pelo menos os pagamentos em dinheiro.
Um sistema PDV deve dar suporte de forma incremental a múltiplos e variados terminais e interfaces no lado do cliente.
Ontologia que representa o Modelo de Domínio do sistema ProxGer A ontologia a seguir foi modelada a partir de o Modelo de Domínio do sistema PDV ProxGer.
Apenas para facilitar a leitura, as tuplas abaixo descrevem os relacionamentos laterais da Figura 19: Tabela 2 ­ Lista inicial de conceitos e relacionamentos ­ Sistema PDV Conceitos Relacionamentos Sale Captured-on Contained-in Sales_ LineItem Contains Product_ Catalog Describes Product_ Specification Initiated-by Item Logs--completed Customer Payd-by Diary_ Book Records-sale-of Payment Records--sales-on Cashier Stocks Store Used-by A geração das regras levou em consideração o modelo de estrutura de frase escrito por Larman e definido no detalhamento de caso de uso denominado process sale.
O detalhamento do caso de uso está descrito no Anexo A, conforme formatação lida por a ferramenta de apoio à abordagem proposta neste trabalho.
O processamento do detalhamento de caso de uso process sale gera um conjunto de tuplas que descrevem a estrutura (conceito, relacionamento, conceito).
Portanto, as tuplas identificadas sugerem conceitos e relacionamentos a partir de termos extraídos do texto descrito em linguagem natural.
Em a verdade, estes termos sugerem conceitos que poderão existir na ontologia final.
Os termos identificados podem ser classificados em uni gramas, bi gramas, tri gramas e n gramas, de acordo com o número de seqüência de palavras que os formam.
Sendo assim, abaixo está relacionada uma lista com exemplos de termos candidatos a conceitos que aparecem com maior número de ocorrências nas tuplas geradas (conceito, relacionamento, conceito) extraídos da descrição detalhada de caso de uso process sale.
Também está relacionada o número de vezes que estes termos candidatos a conceitos aparecem nas tuplas e se o termo é um conceito pertencente à ontologia inicial, de acordo com sua classificação:
Uni gramas, bi gramas, tri gramas ou n gramas (mais de 3 palavras).
Os termos bi gramas, tri gramas e n gramas algumas vezes apresentam uma de suas palavras como conceitos mapeados na ontologia inicial.
Quando isto ocorre, na Tabela 3 a informação da coluna correspondente é apontada com o valor &quot;sim «e ao lado o nome do conceito correspondente é discriminado.
O processamento do detalhamento de caso de uso resultou ainda na identificação de tuplas repetidas.
Isto ocorreu por motivo de a repetição de frases no fluxo de extensão ou devido a os tratamentos especiais previstos nas regras gerarem, determinadas vezes, tuplas iguais a outras existentes.
A fim de exemplificar, para as sentenças existentes em process sale, &quot;System signals error te o Cashier «e &quot;System signals error «o resultado do processamento das regras gera a mesma tupla (System, signals, error).
Isto ocorre devido a o fato da oração &quot;System signals error te o Cashier «entrar na regra especial que desconsidera a terminação final da frase:
Preposição «to seguida de um nome (Te o+ NN).
A lista das tuplas repetidas encontra- se no Apêndice A desta dissertação.
O número total de sentenças do detalhamento de caso de uso process sale é 150 frases.
As 150 sentenças geram, ao reescrever períodos compostos em períodos simples, 144 sentenças que são processadas por as regras e formam tuplas.
As sentenças definidas no detalhamento de caso de uso como o exemplo&quot;* b.
At any time, System fails:»
não são lidas por as regras e consequentemente não geram tuplas.
Este exemplo explica o porquê da abordagem processar através das regras menos sentenças do que as existentes na descrição detalhada.
Em o Apêndice A encontram- se listadas todas as sentenças que não são processadas por as regras.
A quantidade total de tuplas identificadas a partir de o processamento das sentenças através das regras é 218, sendo que 195 tuplas são distintas.
De entre as 150 sentenças existentes no arquivo, 22 destas não são lidas por nenhuma expressão regular que implementa as regras propostas neste trabalho.
A Tabela 4 apresenta esta análise.
Visão Geral do Sistema Time Card (extraído de) O Sistema Time Card é um sistema de cartão ponto e prevê a utilização do aplicativo para gravar as horas faturáveis e não-faturáveis realizadas por os funcionários de uma empresa.
O sistema tem como requisito inicial o acesso ao aplicativo tanto no escritório quanto em casa.
O sistema prevê a criação de um usuário e senha para cada funcionário, solicitando a mudança da senha na primeira vez que o usuário &quot;logar «no sistema.
Ontologia que representa o Modelo de Domínio do Sistema Time Card A ontologia a seguir foi modelada a partir de o Modelo de Domínio do Sistema Time Card. Apenas para facilitar a leitura, as tuplas abaixo descrevem os relacionamentos laterais da Figura 21: A seção a seguir apresenta a lista dos termos com maior número de ocorrência nas tuplas, candidatos a conceitos da ontologia.
Extração de termos ­ Sistema Time Card A ontologia inicial que descreve o modelo de domínio da aplicação Time Card apresenta os conceitos e relacionamentos, conforme listado na Tabela 5.
São seis descrições de casos de uso referentes ao sistema Time Card. no Anexo A, encontram- se detalhados estes casos de uso.
Os detalhamentos de caso de uso do sistema Time Card geraram menos tuplas que a descrição detalhada do caso de uso process sale.
Isto ocorreu porque a estrutura das sentenças do caso de uso utilizado para gerar as regras é diferente da estrutura de frases utilizadas para detalhar o sistema Time Card. Um exemplo bastante perceptível à primeira vista é que o autor dos casos de uso utilizados para teste utilizou- se muito da classe gramatical dos verbos modais, e também iniciou geralmente as frases do fluxo principal, alternativo e extensão com o determinante &quot;the».
Os detalhamentos do sistema Time Card foram utilizados para testar as expressões regulares que implementam as regras desenvolvidas utilizando de modelo o sistema de PDV ProxGer.
Através do processamento dos seis detalhamentos de casos de uso que descrevem o sistema Time Card foi extraído tuplas com a finalidade de refinar a ontologia inicial do sistema.
A Tabela 6 apresenta alguns dos termos com maior número de ocorrência nas tuplas identificadas, organizados em uni gramas, bi gramas, tri gramas e n gramas.
O número total de sentenças dos seis detalhamentos de casos de uso do sistema Time Card é 143 sentenças, e se encontram assim distribuídas:
Caso de uso change password:
Possui 21 sentenças;
Caso de uso create charge code:
Possui 27 sentenças;
Caso de uso create employee:
Possui 20 sentenças;
Caso de uso export time entries:
Possui 18 sentenças;
Caso de uso login:
Possui 20 sentenças;
Caso de uso record time:
Possui 37 sentenças.
As 143 sentenças após processadas geram 131 tuplas.
De as 129 tuplas identificadas, 23 destas são duplicadas gerando, portanto, um total de 106 tuplas distintas.
Esta análise desconsidera sentenças duplicadas em cada detalhamento de caso de uso.
As sentenças duplicadas comumente ocorrem nos fluxos alternativos e nos fluxos de exceção.
A subseção a seguir apresenta a ontologia refinada, considerando os resultados obtidos através da survey (detalhes sobre a análise da survey encontram- se disponíveis na subseção 6.4).
Ontologia Final ­ Time Card A ontologia final, gerada a partir de os seis detalhamentos de casos de uso que descrevem o sistema Time Card está representada na Figura 22.
A ontologia foi modelada considerando as tuplas avaliadas na survey (conforme apresenta a subseção por pelo menos 60% dos participantes da pesquisa.
Considerações As descrições detalhadas dos casos de uso dos sistemas utilizados apresentam aproximadamente o mesmo número total de sentenças.
Enquanto o detalhamento de caso de uso process sale que descreve o sistema de PDV ProxGer possui 150 sentenças e produz 195 tuplas distintas, o sistema Time Card está descrito por 143 sentenças, gerando 106 tuplas distintas.
Isto ocorre porque o sistema PDV foi utilizado como modelo para gerar as expressões regulares que implementam as regras, enquanto que o sistema Time Card foi utilizado para verificar a aplicação das regras em outra descrição de caso de uso, com suas características e peculiaridades descritivas próprias.
As descrições detalhadas dos casos de uso do sistema Time Card, para os campos de fluxo principal e alternativo ou exceção foram escritas muitas vezes utilizando a voz passiva.
É importante salientar que qualquer passo do fluxo, escrito em voz passiva está mal formado, por suprimir informações importantes como o que, quem, onde e quando especificamente.
Já os fluxos do sistema de PDV ProxGer foi escrito por o autor na voz ativa, o que contribuiu para a interpretação das sentenças por as regras, gerando a identificação de um número maior de tuplas.
Alguns dos termos que apresentam maior freqüência na formação das tuplas foram indicados como conceitos relevantes por os participantes da survey.
A Tabela a seguir apresenta estes termos que pertencem à ontologia final, refinada de acordo com as respostas obtidas a partir de a aplicação da survey (informações detalhadas sobre a suvey encontram- se no item 6.4).
Embora alguns termos com maior taxa de ocorrência nas tuplas tenham sido identificados como conceitos relevantes nas tuplas analisadas por os participantes da survey, não é possível apontas- los como relevantes.
Isto ocorre porque a maior parte dos termos com maior taxa de ocorrência nas tuplas não foi identificada por os participantes da survey como conceitos pertencentes às tuplas relevantes para o refinamento e enriquecimento da ontologia final.
Esta análise indica que, a partir de os exemplos de uso utilizados neste trabalho, a utilização do cálculo da ocorrência dos termos na formação das tuplas não determina a sua relevância para o refinamento da ontologia.
Pesquisa Empírica Um estudo empírico é o ato ou operação com a finalidade de descobrir algo novo ou estudar uma hipótese que envolve a pesquisa, coleta e análise de dados para determinar a significância dos dados.
Isto envolve estratégias de pesquisa, estudos qualitativos, análises, entre outros.
A primeira etapa da pesquisa envolve a coleta e análise dos dados originais.
Em a literatura estão descritos vários tipos de pesquisa empírica.
Os objetivos, propriedades ou resultados almejados podem determinar o tipo mais adequado.
Em este trabalho, a estratégia empírica utilizada para análise dos resultados foi a survey, e está descrita neste Capítulo.
Survey Uma pesquisa investiga as relações e resultados.
A survey é um instrumento de coleta de informações, com a finalidade de descrever, comparar ou explicar o conhecimento, atitudes e comportamento.
Não existem variáveis nesta abordagem.
O objetivo da survey é produzir descrições estatísticas quantitativas ou numéricas a respeito de o estudo, analisar os dados a partir de perguntas e respostas de uma amostra da população ou servir como um estudo preliminar de uma pesquisa posteriormente aprofundada.
Utiliza- se surveys em ES para coleta de um conjunto de dados de um evento ocorrido para uma população específica, ou para determinar técnicas ou relacionamentos, possibilitando o levantamento do número de variáveis a serem analisadas.
A coleta de dados preliminares pode ser através do método qualitativo ou quantitativo.
O método qualitativo coleta os dados em formato de textos, imagens ou sons e a análise ocorre independente de medições precisas.
Já o método quantitativo coleta os dados numéricos e aplica estatísticas para analisar- los.
São utilizados dados quantitativos para medir um aspecto particular num processo.
A survey deste trabalho foi aplicada para preenchimento de 10 participantes, com a finalidade de avaliar os resultados obtidos a partir de a extração automática de tuplas dos detalhamentos de casos de uso que descrevem os dois sistemas utilizados como exemplo de uso.
Para o sistema ProxGer não foi considerado o campo de fluxo alternativo para análise, devido a o grande número de sentenças e tuplas geradas, o que acarretaria num tempo muito alto para a realização da survey.
O preenchimento da survey durou, em média, 1 hora e seguiu o seguinte procedimento por os participantes da pesquisa:
As respostas de cada participante estão descritas no Apêndice C deste documento.
De acordo com as respostas obtidas a partir de a aplicação da survey, foi possível analisar a razão das tuplas relevantes em relação a o total identificado.
A Tabela 9 apresenta a freqüência de acerto da ferramenta para cada detalhamento de caso de uso dos exemplos de uso, considerando como válida as tuplas que possuem relevância para pelo menos 6 participantes da pesquisa.
Considerando a Tabela 9, é possível verificar que as tuplas identificadas a partir de a descrição detalhada de caso de uso process sale apresentou maior freqüência de aprovação se comparado com a freqüência de acerto obtida dos seis detalhamentos de casos de uso que descrevem o sistema Time Card. O sistema Time Card apresenta uma média de acerto de 24%, em contrapartida ao índice de 50% obtidos da análise dos resultados das respostas da survey.
Como anteriormente referenciado, qualquer passo do fluxo de detalhamento de caso de uso, quando escrito em voz passiva, está mal formado.
Como os detalhamentos de casos de uso do sistema Time Card muitas vezes estavam descritos em voz passiva, dificultou a identificação e a formação das tuplas.
Isto acarretou no menor índice de acerto determinado por a relevância de cada tupla, de acordo com a percepção dos participantes da survey.
De as 28 tuplas identificadas como relevantes na análise do sistema ProxGer para pelo menos 6 participantes da pesquisa, a regra que apresenta maior freqüência é a regra que interpreta a estrutura de frase nome (s)+ verbo (s)+ (adjetivo opcional) nome (s).
Embora existam 6 ocorrências de aceitação de tuplas formadas por a mesma regra, isto equivale a apenas 21% da amostra, o que não caracteriza melhor formação de uma regra.
O mesmo ocorre com as tuplas indicadas com maior relevância por os participantes da pesquisa para o sistema Time Card, pois foram formadas por regras diversas.
De as 28 tuplas identificadas como relevantes para o sistema ProxGer, duas de elas possuem 100% de relevância e 21% das tuplas possuem 90% de relevância de acordo com as respostas obtidas através da survey.
De as tuplas identificadas relevantes a partir de os detalhamentos de casos de uso do sistema Time Card, 4 de elas foram consideradas 100% relevantes.
De o total de tuplas geradas automaticamente, para o sistema ProxGer apenas 1 tupla foi considerada irrelevante.
Já para o sistema Time Card, 7 tuplas foram consideradas irrelevantes.
As tuplas que possuem o relacionamento can_ be, formadas a partir de a identificação de um adjetivo que qualifica um substantivo, denotam (de acordo com esta abordagem) um estado que o conceito pode ou não apresentar.
Para exemplificar, a tupla (sale, can_ be, new) determina que uma venda possa ser uma nova venda, embora o conceito venda não represente necessariamente uma nova venda.
De as 8 tuplas que sugerem o relacionamento can_ be para o refinamento do sistema ProxGer, apenas 1 destas tuplas foi considerada relevante.
Para o sistema Time Card também foi identificado apenas 1 tupla relevante que representa o relacionamento can_ be, apesar de serem sugeridas 25 tuplas com este relacionamento.
Muitos conceitos e relacionamentos novos foram identificados nas tuplas consideradas relevantes.
Portanto, é possível concluir que através da abordagem descrita neste trabalho (apoiada por a ferramenta OntSoft) foi possível enriquecer a ontologia inicial, através da identificação automática de novas tuplas que representam os conceitos e relacionamentos relevantes para a solução de software em desenvolvimento.
Assim, com a utilização da ferramenta de apoio OntSoft, foi possível desonerar o processo de criação da ontologia, apresentando um bom resultado para os exemplos de uso.
Para o sistema ProxGer, através da aplicação da survey foram identificados 86% de novos conceitos relevantes, que não existiam na ontologia inicial.
Todos os relacionamentos identificados para refinar e enriquecer a ontologia não existiam na ontologia inicial do sistema ProxGer.
Para o sistema Time Card, foram identificados 80% de novos conceitos, ou seja, dos conceitos identificados como relevantes, 80% de eles não estavam mapeados na ontologia inicial.
Todos os relacionamentos identificados para refinar e enriquecer a ontologia, também não constava na ontologia inicial.
As tuplas que foram identificadas não sofreram nenhum tipo de análise de relevância automática antes da validação humana realizada através da survey.
Algum critério, como o estudo de um &quot;ponto de corte», seria muito útil e interessante se fosse aplicado antes da sugestão da tupla para o usuário final realizar a validação, pois traria a melhoria da taxa de acertos.
Embora seja possível e importante a melhoria da taxa de acerto, os resultados obtidos através da abordagem proposta podem ser considerados satisfatórios a partir de a análise da aplicação da survey.
Isto ocorre porque a abordagem alcançou o objetivo principal de auxiliar o refinamento da ontologia, minimizando a intervenção humana para a sua construção.
A extração de termos conceitualmente relevantes num determinado domínio a partir de um corpus em linguagem natural não é um processo simples.
A linguagem natural, por ser suscetível a erros e ambigüidades, dificulta o processamento e a interpretação do texto.
Termos compostos, que correspondem a mais de duas unidades lexicais (tratados no texto como termos n gramas) representam outra dificuldade para extração automática.
A identificação de um ou mais termos possíveis candidatos a conceitos, assim como a definição de uma métrica que defina quando um ou n termos representam semanticamente um conceito para o domínio da aplicação proposta não é trivial.
Em este trabalho a extração dos termos e relacionamentos foi realizada através de uma abordagem lingüística.
A abordagem lingüística utiliza- se de anotações lingüísticas, ou seja, identificação dos termos a partir de suas características morfológicas, sintáticas e semânticas.
Em o domínio de ES, o objetivo é extrair tuplas que expressem o relacionamento entre conceitos com a finalidade de refinar e enriquecer uma ontologia inicial, muito útil por servir de modelo para os demais relacionamentos posteriormente identificados, modelada a partir de a definição de um Modelo de Domínio.
A extração destas tuplas ocorreu a partir de a descrição detalhada de casos de uso.
Os detalhamentos de casos de uso geralmente não possuem volume de texto relativamente grande para aplicar técnicas estatísticas.
Embora não possua grande volume de informação textual, os detalhamentos de casos de uso são escritos de forma estruturada, seguindo templates que especificam campos para nome, fluxo principal, alternativo entre outros.
Se por um lado um texto escrito em linguagem natural apresenta problemas inerentes à linguagem livre, pode- se afirmar que um texto escrito na seção do fluxo principal de um caso de uso descreve uma ação.
Esta característica torna o problema de extração de conceitos e relacionamentos um pouco mais viável se comparado à extração de termos em textos livres.
A extração da estrutura (conceito, relacionamento, conceito) teve a finalidade de enriquecer e refinar a ontologia inicial.
No entanto, o processo de aprendizagem da ontologia envolve o cumprimento das atividades de aquisição de terminologia, identificação dos termos que são sinônimos, formação de conceitos, taxonomia do conhecimento, aprendizagem de relacionamentos entre conceitos, propriedades ou atributos, taxonomia dos relacionamentos, instanciação e definição dos axiomas.
Maedche apresenta a aprendizagem da ontologia como um processo que envolve a definição de regras ou reutilização de uma ontologia, inclusão ou manutenção de novos domínios, corte de conceitos irrelevantes (com a finalidade de representar melhor o domínio) e refinamento da ontologia.
De acordo com o Cimiano, para que o processo de aprendizagem da ontologia esteja completo é necessária a satisfação de todas as atividades descritas.
Em este trabalho, a abordagem previu a geração de uma ontologia inicial, modelada a partir de o diagrama de classes que descreve o modelo de domínio.
Imediatamente após, a abordagem propôs o refinamento e enriquecimento através da descrição textual dos detalhamentos de casos de uso que detalham a aplicação de software.
A partir de as informações que servem de insumo, foi possível a identificação de conceitos e relacionamentos, porém, a relevância destes conceitos e relacionamentos, a identificação de instancias e axiomas (regras que são sempre verdadeiras) não são satisfeitas na abordagem apresentada neste trabalho.
Uma survey foi aplicada nesta pesquisa com a finalidade de avaliar as tuplas geradas automaticamente por a ferramenta.
A abordagem descrita neste trabalho ainda necessita da validação humana para indicação da relevância dos conceitos e relacionamentos propostos para o refinamento da ontologia.
Embora ainda persista a necessidade da intervenção humana para o refinamento da ontologia, é possível afirmar que a abordagem alcançou resultados satisfatórios, pois através da análise da survey, foi identificado 50% de acerto para as tuplas sugeridas para o refinamento da ontologia inicial do exemplo de uso do sistema ProxGer.
Uma limitação apresentada neste trabalho é a necessidade do modelo de domínio e dos detalhamentos de casos de uso estar escrito em língua inglesa.
Trabalhos Futuros Para continuidade deste trabalho é sugerido o estudo aprofundado da aplicação de técnicas estatísticas combinadas, para estabelecer uma métrica de relevância para as tuplas geradas.
Para a utilização das técnicas estatísticas, é possível realizar a análise sobre toda documentação e outros diagramas do sistema.
Em o trabalho de é sugerido o cálculo da freqüência relativa dos termos, realizado através da divisão do número de vezes que o termo é extraído por o número total de ocorrências do termo.
A autora ainda sugere um ponto de corte entre 5% e 10%.
Para os exemplos de uso utilizados nesta dissertação, foi observado que a frequência da ocorrência dos termos não determina a relevância do mapeamento destes termos em conceitos na ontologia que descreve a solução de software.
Identificar uma medida de relevância é necessário para minimizar a taxa de erros da abordagem apresentada neste trabalho.
Testes exaustivos, aplicados em diferentes descrições detalhadas de casos de uso, de diversas modelagens de sistemas, é um trabalho interessante de ser realizado.
A dificuldade em executar testes com outros exemplos está no fato de não existirem muitos exemplos completos de modelagem de sistemas na literatura para realização dos testes.
Outro trabalho interessante, e talvez a maior lacuna a ser preenchida na viabilização da automação da geração de ontologias no processo de desenvolvimento, é a identificação da relevância dos relacionamentos importantes dentro de o domínio da aplicação modelada, e que devem fazer parte da ontologia que descreve o sistema em desenvolvimento.
Para que isto seja possível, um estudo sobre a possibilidade de se estabelecer um modelo único de descrição de caso de uso também é válido.
O autor Somé afirma a necessidade de expressar restrições de seqüência nos casos de uso.
A importante contribuição do autor é a proposta de uma definição da semântica formal para a representação formal dos casos de uso (instruções sobre a forma da linguagem natural) e a definição da estrutura (seções) do documento.
Esta pesquisa ainda comporta muitos estudos, como a generalização desta abordagem para a língua portuguesa, com a criação de novas regras que possibilitem a identificação de tuplas, considerando as categorias morfossintáticas pertinentes à linguagem.
Por fim, através da abordagem proposta nesta dissertação, tornou- se viável a construção e o refinamento da ontologia que descreve o sistema de software em construção, possibilitando a aquisição e o compartilhamento do conhecimento através da utilização de ontologias no desenvolvimento de software.
