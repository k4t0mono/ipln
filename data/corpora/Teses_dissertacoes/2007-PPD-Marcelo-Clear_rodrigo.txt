A rastreabilidade se refere à habilidade de relacionar informações numa cadeia de processo.
Este trabalho apresenta uma proposta de rastreabilidade por a integração de ontologias no Processo Unificado.
Sugere- se a criação de uma ontologia a partir de a modelagem de domínio, durante as etapas iniciais do Processo Unificado.
Com o desenvolvimento desta ontologia, viabiliza- se a rastreabilidade baseada em conceitos durante o ciclo de vida do software.
Esta abordagem permite a integração de diferentes modelos de um sistema de informação, incluindo negócios, requisitos, análise e projeto, numa granularidade mais específica do que as convencionais abordagens de rastreabilidade baseadas em requisitos.
Para apoiar os projetistas na criação da ontologia e no relacionamento dos artefatos, foi desenvolvida uma ferramenta para rastreabilidade semântica chamada ONTrace (Ontological Tracing), comprovando a viabilidade da proposta.
Para a avaliação da proposta, foi desenvolvido um experimento para caracterizar a precisão e o esforço relacionados com a rastreabilidade apoiada por conceitos e por requisitos.
Palavras-Chave: Rastreabilidade, Modelagem do Conhecimento, Ontologia, Processo Unificado.
O processo de desenvolvimento de software compreende a criação de diferentes modelos.
Modelos representam uma abstração da realidade e podem ser utilizados para visualizar e controlar uma arquitetura, avaliando os riscos e identificando oportunidades.
Durante a Engenharia de Software, modelos são desenvolvidos em diferentes perspectivas e níveis de abstrações.
Estas perspectivas nem sempre são integradas, porém tendem a ser complementares, variando de acordo com sua especificidade.
Cada modelo está relacionado a conceitos do mundo real.
Estes conceitos podem ser representados por uma ontologia, isto é, um modelo que especifica os termos que descrevem e representam o conhecimento sobre um domínio de informação.
Este trabalho sugere o uso de ontologias para apoiar o processo de desenvolvimento de software, particularmente o Processo Unificado.
O objetivo é integrar as diferentes visões que modelam o sistema, relativas a negócios, requisitos e análise e projeto.
Utilizando ontologias, permitese relacionar estas visões, mapeando- as com os conceitos que representam o domínio.
Muito do esforço relativo à construção de ontologias corresponde à delimitação do escopo, explicitação do domínio e modelagem conceitual.
Durante as etapas iniciais do Processo Unificado, os esforços correspondem a aspectos relacionados, como a modelagem de negócio e de domínio.
É com base nesta premissa que se sugere a integração de ontologias no Processo Unificado, aproveitando o esforço despendido durante a engenharia de software para a construção da ontologia.
Com esta integração, consegue- se explicitar os conceitos do domínio num formalismo lógico, não previsto por o Processo Unificado.
Em este contexto, será apresentada uma abordagem sistemática para a engenharia de ontologias, compilando as boas práticas encontradas na literatura e as integrando no Processo Unificado.
De acordo com o Ontology Driven Architecture, definido por a, alguns dos benefícios obtidos por a integração de ontologias nas práticas de Engenharia de Software são:
Apoiar à modelagem de domínio e sua integração em diferentes fases do ciclo de vida do software;
Reduzir as inconsistências entre os diferentes artefatos gerados no processo de desenvolvimento, devido principalmente as múltiplas perspectivas dos stakeholders;
Apoiar a rastreabilidade entre estes artefatos, visando à melhoria da qualidade dos sistemas de informação através da análise de impacto, manutenções e evoluções, reuso de componentes, inspeção e compreensão do sistema.
Com o desenvolvimento de uma ontologia que represente o modelo de domínio de um sistema, possibilita- se a rastreabilidade ontológica (ou semântica), isto é, a possibilidade de relacionar os conceitos da ontologia com os artefatos gerados no processo de desenvolvimento.
Para comprovar a viabilidade da proposta, foi projetada e desenvolvida uma funcionalidade integrada a uma ferramenta de modelagem.
Esta funcionalidade permite a geração de uma ontologia a partir de a modelagem de domínio, definida através de um diagrama de classes UML.
Além disso, esta funcionalidade permite a recuperação dos elos de rastreabilidade definidos, utilizando um motor de inferência.
Para avaliar os benefícios da rastreabilidade ontológica e sua capacidade de indexar os artefatos, foi desenvolvido um experimento.
O objetivo deste estudo é caracterizar relações de precisão e esforço entre a rastreabilidade indexada por conceitos da ontologia e a tradicional rastreabilidade indexada por requisitos.
Existem diversas propostas para construção de ontologias apresentadas na literatura, integradas ou não ao processo de desenvolvimento de software.
A criação de uma ontologia específica, que represente o modelo conceitual de um sistema de informação, pode proporcionar ganhos efetivos durante o desenvolvimento de software, integrando as diferentes visões que modelam um sistema.
Em este sentido, emerge a questão de pesquisa deste estudo:
&quot;É viável e interessante a rastreabilidade ontológica dos artefatos envolvidos com o processo de desenvolvimento de software através do mapeamento do conhecimento numa ontologia?».
Uma vez definida a questão de pesquisa, definiu- se o objetivo geral e os objetivos específicos deste trabalho.
Prover a rastreabilidade ontológica entre os artefatos produzidos durante o ciclo de vida do software através da integração de ontologias no Processo Unificado.
Os objetivos definidos neste trabalho incluem:
Avaliar as propostas de engenharia de ontologias encontradas na literatura, visando identificar padrões e melhores práticas;
Integrar os padrões e as boas práticas identificados anteriormente no Processo Unificado.
Esta integração visa estabelecer a sistemática para construção de uma ontologia coerente com o domínio da aplicação;
Avaliar algumas propostas de classificação dos elos de rastreabilidade;
Propor uma estrutura ontológica que permita à geração e recuperação dos elos de rastreabilidade;
Avaliar a viabilidade da proposta apresentada;
Comparar, num estudo experimental, a proposta de rastreabilidade ontológica com relação a tradicional proposta de rastreabilidade indexada por requisitos.
Para possibilitar a rastreabilidade ontológica sobre o Processo Unificado, inicialmente foi realizada uma análise de padrões e boas práticas de nove propostas de engenharia de ontologias.
O objetivo foi proporcionar o embasamento necessário para construção de ontologias que mapeiem corretamente o domínio da aplicação.
A Seção 2.4 apresenta a análise das propostas estudadas, compilando- as numa seqüência de passos.
A partir destes passos, a Seção 3.3 apresenta uma proposta de integração de ontologias no Processo Unificado, sugerindo a criação de uma nova disciplina, chamada de Modelagem de Ontologia.
A disciplina sugerida é definida em três principais atividades.
Como resultado de uma destas atividades, obtém- se um artefato que corresponde à ontologia de domínio.
Esta ontologia é gerada a partir de o mapeamento de um artefato chamado Modelo de Domínio (Md), proposto por o Processo Unificado, com base nas guias definidas por a para conversão de modelo UML em modelo ontológico.
Possuindo uma ontologia integrada ao processo de desenvolvimento, viabiliza- se a rastreabilidade semântica.
A Seção 4.2 apresenta a estrutura que possibilita a rastreabilidade ontológica entre os artefatos envolvidos com processo de desenvolvimento.
Para verificar a viabilidade da proposta, o Capítulo 5 apresenta a implementação da ferramenta que mapeia o Modelo de Domínio numa ontologia e permite a criação dos elos de rastreabilidade, mapeando os conceitos da ontologia com os elementos de um modelo UML.
Esta ferramenta também proporciona a aquisição dos elos de rastreabilidade previamente estabelecidos, utilizando um motor de inferência.
Para avaliação da rastreabilidade, a Seção 5.2 apresenta um experimento que objetiva comparar a precisão e o esforço da rastreabilidade indexada por conceitos da ontologia com a tradicional proposta de rastreabilidade indexada por requisitos.
Este trabalho está estruturado em cinco partes:
Fundamentação teórica sobre ontologias e suas engenharias;
Proposta de integração de ontologias ao Processo Unificado;
Proposta de rastreabilidade ontológica;
Análise de viabilidade de ambas as propostas;
Estudo experimental sobre a rastreabilidade ontológica.
Unificado. Inicialmente, a Engenharia de Software é relacionada com a engenharia de ontologia, com o objetivo de identificar oportunidades.
Posteriormente, sugere- se uma nova disciplina no Processo Unificado visando esta integração.
Em seguida, é realizado um estudo comparando a disciplina sugerida com a proposta de, para avaliação de metodologias de engenharia de ontologias.
Por fim, são apresentados alguns trabalhos relacionados.
Engenharia de Software Experimental e.
É apresentado o referencial teórico do processo de experimentação e, por fim, o estudo experimental.
Este capítulo fornece uma visão geral sobre ontologias, apresentando os seus principais conceitos.
Inicia- se com uma revisão sobre suas definições, visando discutir e clarificar como o conhecimento pode ser organizado e estruturado por uma ontologia.
Para organizar o conhecimento, é necessária uma linguagem declarativa e, para este fim, foi desenvolvido um estudo sobre a linguagem de manipulação de ontologias OWL.
Por fim, desenvolveu- se a análise de algumas propostas de engenharia de ontologias, visando identificar as melhores práticas para apoiar uma proposta de integração de ontologias no Processo Unificado.
O termo &quot;ontologia «surgiu na filosofia através de Aristóteles e significa &quot;uma explicação sistemática da existência», isto é, a definição de um domínio do conhecimento num nível genérico, utilizada para especificar o que existe ou o que se pode dizer sobre o mundo.
Em Ciência da Computação, ontologias representam à aquisição do conhecimento a partir de dados semi-estruturados utilizando um conjunto de métodos, técnicas ou processos automáticos ou semi-automáticos.
Dentro de Ciência da Computação, o termo &quot;ontologia «teve sua origem na comunidade de Inteligência Artificial.
Segundo Thomas Gruber, em, aquilo que existe é aquilo que pode ser representado.
Quando o conhecimento sobre um domínio é especificado numa linguagem declarativa, o conjunto de objetos que pode ser representado é denominado universo de discurso.
Pode- se descrever uma ontologia de um programa por a definição de um conjunto representacional de termos.
As definições associam os nomes de entidades do universo de discurso (como classes, relacionamentos, funções ou outros objetos) com um texto que descreve o que os nomes significam e com os axiomas formais, que tanto restringem a interpretação destes termos quanto a boa formação no seu uso.
Ontologias são utilizadas para definir os termos usados para descrever e representar um domínio de informação.
Entende- se por domínio de informação uma específica área de conhecimento.
Para tanto, ontologias incluem definições de conceitos e seus relacionamentos, tornando assim o conhecimento compartilhado e, de certa forma, reusável.
Gruber, em, define ontologias como uma &quot;especificação explícita de uma conceituação».
Uma conceituação é uma abstração simplificada da realidade que se deseja representar, isto é, um conjunto de objetos, restrições, relacionamentos e entidades que se assumem necessárias em alguma área de aplicação.
A conceituação de Gruber foi modificada por Borst, em, definindo ontologias como uma &quot;especificação formal de uma conceituação compartilhada».
Esta definição enfatiza o fato que deve haver um acordo na conceituação do que é especificado.
Para se descrever uma ontologia, Maedche propõe, em, uma estrutura C e R são dois conjuntos disjuntos formados por conceitos e relacionamentos, respectivamente;
Hc representa a taxonomia da ontologia, isto é, a hierarquia dos conceitos e relacionamentos;
A o representa o conjunto de axiomas da ontologia.
As ontologias vêm sendo utilizadas para descrever artefatos com diferentes níveis de estruturas.
Estes níveis variam desde simples taxonomias, schemas para metadados até teorias lógicas.
Usualmente, elas são expressas em linguagens lógicas para que possam ser consistentes o suficiente para a extração do conhecimento.
A linguagem OWL (Web Ontology Language) é parcialmente mapeada através de lógica descritiva, que é um subconjunto da lógica de predicados, tornando possível um eficiente apoio lógico.
Por apoio lógico, define- se o processamento do conteúdo da informação ao invés de sua simples apresentação.
Para se definir e manipular ontologias, sugere- se a utilização de linguagens que suportem estruturas para representação do conhecimento.
Esta representação é realizada através da descrição formal de um conjunto de termos sobre um domínio específico.
A definição de uma linguagem é necessária para a representação e descrição formal da estrutura que especifica uma conceituação.
Um termo que possui determinado significado pode variar sua semântica conforme o contexto empregado.
Para solucionar este problema de ambigüidade e propor uma estrutura formal para a representação do conhecimento, surgiram algumas propostas de linguagens, como:
KIF: Knowledge Interchange Format;
XOL: XML-based Ontology Exchange Language;
Oil: Ontology Inference Layer;
RDF: Resource Definition Framework;
SHOE: Simple Html Ontology Extensions;
DAML: DARPA Agent Markup Language;
OWL: Web Ontology Language.
Será desenvolvido nesta seção um estudo sobre a linguagem de definição e manipulação de ontologias chamada OWL.
A linguagem OWL foi recomendada por a em fevereiro de 2004 como linguagem para manipulação de ontologias e seu diferencial é a capacidade de processamento semântico através de inferência.
Antoniou estabelece, em, três requisitos para a definição de linguagens lógicas:
Sintaxe bem definida:
A importância desta sintaxe é clara e justificada por as linguagens de programação, pois é uma condição necessária para o processamento computacional;
Semântica formal:
Descreve precisamente o significado sobre um conhecimento.
O termo &quot;precisamente «significa que não estão associadas intuições subjetivas ou abertas a diferentes interpretações entre diferentes pessoas (ou máquinas).
Esta semântica formal é estabelecida, por exemplo, através de uma lógica matemática que descreve:
A é subclasse de uma classe B, então é possível inferir que x também é instância da classe B;
Apoio lógico:
A semântica formal é seu pré-requisito, pois as derivações, como descritas anteriormente, podem ser realizadas automaticamente sem a intervenção humana.
Estas verificações realizam a consistência ontológica e do conhecimento, os relacionamentos entre as classes e a classificação automática de suas instâncias.
Uma semântica formal e o seu apoio lógico são geralmente providos através do mapeamento de uma linguagem ontológica num formalismo.
Estes requisitos foram a base para uma divisão da linguagem OWL em três sublinguagens:
OWL Full, OWL Dl e OWL Lite.
A linguagem OWL é construída sobre RDF e RDF Schema e baseada na sintaxe XML.
O modelo básico de dados do RDF, e herdado por OWL, é definido através de:
Recurso (resource):
Qualquer entidade referenciada através de um URI (Universal Resource Identifier);
Propriedade (property):
Representam recursos, características que representam recursos ou relacionamento entre recursos;
Declaração (statement):
Corresponde a uma propriedade ou valor dessa propriedade associada a um recurso específico.
Uma declaração é dividida em três partes:
Sujeito (recurso), predicado (propriedade do recurso) e objeto (valor da propriedade).
Para se estruturar um documento OWL, define- se em alto nível:
Classes: Conjunto de instâncias com características comuns.
Propriedades: O Tipos (datatype properties):
Identificam os valores primitivos das o Objetos (object properties):
Representam o vínculo de duas instâncias, isto é, seus relacionamentos.
Adicionando valores a uma propriedade, consequentemente, se adiciona valores a uma segunda.
parte-de. Indivíduos:
Representam os objetos num domínio, isto é, instâncias específicas.
Verifica- se aqui que dois nomes podem representar o mesmo objeto no mundo real.
A estruturação da linguagem OWL é pertinente no que tange a forma com a qual o conhecimento pode ser representado.
Porém, apenas o entendimento da linguagem não é suficiente para estruturar o conhecimento, pois o mapeamento dos conceitos do mundo real numa estrutura formal requer uma abordagem sistemática, assim como o desenvolvimento de software.
Em este contexto, diversos autores, de entre eles, e, descrevem uma abordagem chamada Engenharia Ontológica.
Em a próxima seção, será apresentada a análise de algumas abordagens para construção de ontologias encontradas na literatura, visando extrair as melhores práticas.
A literatura fornece algumas abordagens sistemáticas para o desenvolvimento de ontologias.
A construção de ontologias compreende um conjunto de técnicas e atividades necessárias para o desenvolvimento de um modelo lógico que represente determinado universo de discurso.
É interessante a análise dessas propostas para extração dos principais aspectos necessários para apoiar o desenvolvimento de ontologias integrado ao Processo Unificado.
O processo de criação de ontologias pode seguir padrões não lineares.
Cada equipe de desenvolvimento pode possuir seu conjunto de princípios, critérios de projeto e fases a seguir.
A ausência de guias e métodos para estruturar a construção de ontologias pode gerar inconsistência entre as necessidades dos usuários e o modelo ontológico.
A seguir, serão analisadas algumas das propostas encontradas na literatura.
A metodologia proposta em foi construída baseada no desenvolvimento do projeto da Enterprise Ontology e descreve as seguintes etapas para o desenvolvimento de ontologias:
Identificação do propósito e escopo:
Define o nível de formalidade em que a ontologia será descrita e representa uma especificação do intervalo de informação que caracteriza esta ontologia.
Sugere- se utilizar Cenários Motivacionais (descrições de problemas) e Questões de Competência Informal (representação informal dos cenários utilizando a ontologia).
Pode ser utilizada uma técnica como brainstorming para mapear os conceitos relevantes e descartar conceitos irrelevantes e sinônimos;
Formalização: Corresponde à criação do código com suas definições formais e os termos axiomáticos, definidos na especificação da ontologia.
Esta etapa compreende:
Captura da ontologia:
Identificação dos conceitos e relacionamentos relevantes para ontologia;
Codificação: Mapeamento do conhecimento adquirido nas etapas anteriores numa linguagem formal;
Integração de ontologias existentes:
Reutilização de um domínio pertinente ao contexto em questão.
Avaliação formal:
Consiste na verificação da consistência, completude e a não redundância do modelo.
Ela pode ser executada avaliando o propósito ou as questões de competência definidas anteriormente.
Documentação: Representa a documentação do desenvolvimento da ontologia;
Grüninger e Fox propõem numa metodologia baseada na experiência de desenvolvimento da ontologia do projeto TOVE (Toronto Virtual Enterprise).
Esta metodologia descreve um domínio de processos de negócio e a modelagem de atividades com o uso de ontologias, permitindo construir um modelo lógico a partir de cenários informais expressos em linguagem natural.
As seguintes etapas são propostas nesta metodologia:
Captura de cenários motivacionais:
O ponto de partida desta metodologia estabelece um conjunto de problemas encontrados num domínio específico, expresso geralmente em linguagem natural.
Formulação de questões de competência informal:
Define os requisitos da ontologia baseados nos cenários motivacionais.
As questões de competência representam perguntas que devem ser respondidas por a ontologia.
Esta etapa é responsável por a validação dos cenários obtidos no estágio anterior;
Especificação da terminologia da ontologia numa linguagem formal:
Corresponde a formalização das classes, atributos e relacionamentos da ontologia;
Formulação das questões de competência formal:
Os requisitos da ontologia são formalizados numa linguagem declarativa;
Especificações dos axiomas:
Definição dos axiomas que especificam ou restringem os termos da ontologia, expressos em lógica de primeira ordem.
Estes axiomas são orientados por as questões de competência formal;
Verificação da completude da ontologia:
Corresponde a etapa de avaliação das questões de competência da ontologia, verificando se a mesma está completa em relação a sua especificação.
O framework Methontology, proposto por Fernández-López em, sugere um ciclo de vida e um processo de desenvolvimento para ontologias baseado na evolução de protótipos.
O ciclo de vida compreende a especificação, conceituação, formalização, integração e implementação da ontologia.
As fases do framework são:
Planejamento: Tem por objetivo identificar e organizar as tarefas e recursos que deverão ser executados ao longo de o ciclo de vida ontológico;
Especificação: Esta fase identifica o propósito da ontologia, incluindo seus usuários, cenários de uso, o grau de formalidade necessário, etc..
Além disso, esta fase se preocupa com a definição do escopo da ontologia, incluindo o conjunto representacional dos termos, suas características e granularidades.
O resultado desta fase é um documento em linguagem natural que representa a ontologia;
Aquisição do Conhecimento:
Esta fase é executada concomitantemente com a fase.
Trata- se de uma elicitação não-prescritiva do conhecimento através de discussões que englobam entrevistas com especialistas do domínio e análise de textos.
É sugerido o uso de técnicas de aquisição de conhecimento de sistemas baseados em conhecimento;
Conceituação: Compreende a identificação informal dos termos do domínio que correspondem a conceitos, instâncias, verbos relacionais ou propriedades.
Como resultado desta fase, obtém- se um modelo conceitual que descreve o problema e sua solução;
Formalização: Esta fase tem por objetivo mapear o conhecimento estruturado na fase num modelo formal semi-computável, isto é, que não é processável diretamente por um computador;
Integração: Visando obter uniformidade entre ontologias, esta fase corresponde à verificação da possibilidade de incorporar outras ontologias.
Esta fase é aplicável apenas quando se deseja reutilizar ontologias existentes;
Implementação: É a atividade que visa à formalização da ontologia numa linguagem computável;
Avaliação: O framework Methontology enfatiza esta fase.
Um conjunto de guias é fornecido para avaliar se a ontologia está incompleta, inconsistente ou redundante;
Documentação: Representa uma relação de documentos obtidos como resultado das demais atividades.
Esta fase é especialmente importante quando se deseja reutilizar ou compartilhar a ontologia com outras existentes.
Manutenção: Esta fase é executada após o término do desenvolvimento da ontologia, caso seja necessária alguma manutenção.
É apresentado no ambiente para construção de ontologias que utiliza o framework descrito, chamado Ode (Ontology Design Environment).
Seu objetivo é apoiar os engenheiros durante o processo de desenvolvimento e o ciclo de vida da ontologia, automatizando e integrando cada fase descrita.
Falbo e Rocha apresentam numa abordagem sistemática para o desenvolvimento de ontologias.
Basicamente esta proposta consiste em:
Identificar o propósito e a especificação dos requisitos da ontologia:
A primeira atividade a ser executada é a identificação do propósito e dos usos da ontologia, isto é, sua competência.
Falbo sugere a utilização de cenários motivacionais para ontologia.
Captura da ontologia:
Capturar a conceituação do domínio com base na competência da ontologia.
Em este ponto, devem ser identificados e organizados os conceitos, relações, propriedades e axiomas relevantes do domínio.
São sugeridos alguns critérios para o projeto da ontologia:
Clareza, coerência e um mínimo de compromisso ontológico;
Formalização: Tem como objetivo representar a conceituação numa linguagem formal, definida sob lógica de primeira ordem, para representar suas estruturas de maneira precisa e não ambígua.
Integração com outras ontologias:
Caso seja necessário integrar a ontologia em desenvolvimento com outra já existente, sugere- se realizar- la durante os passos de captura e formalização.
Avaliação: O objetivo é verificar se a ontologia em desenvolvimento está de acordo com os requisitos especificados.
Sugere- se utilizar as questões de competências definidas anteriormente por o especialista de domínio para a avaliação do modelo lógico;
Documentação: Sugere- se desenvolver uma documentação que englobe o processo descrito, incluindo os propósitos, requisitos e cenários motivacionais, descrição informal e formal da conceituação e o critério de projeto adotado.
O guia de Noy e McGuinness foi resultado da experiência adquirida durante a utilização das ferramentas Protégé, Ontolingua e Chimaera como ambientes de edição de ontologia.
Segundo, não existe um método mais adequado para a construção de ontologias, pois sempre existem alternativas viáveis.
A escolha da solução sempre vai depender da aplicação que se tem em mente, do escopo da ontologia e de possíveis integrações.
Logo, o objetivo de sua proposta não é definir uma metodologia, mas sim um guia para o desenvolvimento de ontologias.
O processo proposto é iterativo e possui sete passos:
Determinar o domínio e o escopo da ontologia:
Neste passo, o objetivo é restringir o escopo da ontologia, definindo qual seu uso e as questões de competência que devem ser respondidas;
Considerar o reuso de ontologias existentes:
O objetivo é limitar esforços por a integração de ontologias existentes ou manutenção de domínios que já possuem ontologias definidas;
Listar os termos importantes da ontologia:
Sugere- se desenvolver uma listagem dos conceitos relevantes do domínio, suas propriedades e seus relacionamentos, além de suas respectivas descrições;
Definir as classes e suas hierarquias:
É definido um conjunto de guias em o qual são abordadas questões importantes para o desenvolvimento de ontologias, tais como a organização taxonômica, adição de novos recursos na ontologia, etc..
Definir as propriedades das classes:
Os termos descritos no Passo 3 que não se tornaram classes, deverão ser mapeados em propriedades;
Definir as facetas das propriedades:
Definem- se aqui as facetas das propriedades, tais como cardinalidade, intervalo de valores, restrições, etc..
Criar instâncias:
O objetivo é a criação de instâncias de classe e seus valores, definindo uma declaração do tipo sujeito ­ predicado ­ objeto.
A proposta de Holsapple e Joshi define cinco possíveis abordagens para o projeto de ontologias:
Inspiração: Consiste no projeto de uma ontologia baseado na imaginação e criatividade;
Indução: Consiste no projeto baseado na observação, investigação e análise de casos específicos;
Dedução: Sugere- se o projeto a partir de a adoção de alguns princípios gerais para um caso específico;
Síntese: O projeto de uma nova ontologia é resultado de uma compilação de uma série de outras ontologias;
Colaboração: Consiste no desenvolvimento a partir de o esforço comum.
A abordagem colaborativa sugerida por os autores é estruturada em quatro fases:
Preparar: Em esta primeira fase, são definidos os critérios de projeto da ontologia e a definição de seu escopo;
Ancorar: É desenvolvida uma ontologia preliminar para &quot;ancorar «o projeto, servindo como base para colaboração dos interessados no desenvolvimento da ontologia;
Melhoria repetitiva e iterativa:
O objetivo é a convergência de diferentes visões sobre o modelo preliminar da ontologia para sua consolidação;
Aplicação: Em esta fase ocorre a demonstração da utilidade da ontologia a partir de sua aplicação.
A metodologia On-To--Knowledge, proposta em, tem o objetivo de introduzir e manter aplicações de gestão do conhecimento baseadas em ontologias.
Para isso, propõem- se as seguintes atividades:
Meta-processo de conhecimento, que compreende:
Estudo de viabilidade;
Iniciação; Refinamento;
Avaliação; Aplicação;
Evolução. Criação do conhecimento e/ ou importação de documentos e metadados;
Captura do conhecimento;
Recuperação; Acesso;
Utilização do conhecimento.
O Knowledge Unified Process (KUP) é uma proposta de Orleans e Lucena que objetiva unificar diversas propostas existentes na academia e na indústria para a construção de ontologias.
O processo foi inspirado no Processo Unificado e é estruturado num ciclo de vida iterativo e incremental, orientado a casos de uso e centrado na arquitetura, porém com o foco específico em ontologias.
O processo é dividido em 3 fases e 9 disciplinas.
As fases são organizadas por iterações que correspondem a entregas bem definidas.
As fases propostas são:
Concepção: ênfase no escopo da ontologia;
Construção: ênfase no projeto, implementação e aplicação da ontologia;
Evolução: Integração de novos conceitos sobre a ontologia;
As disciplinas envolvidas com o processo constituem:
Instanciação e Customização do KUP:
Definir quais fases, disciplinas, papéis, atividades e artefatos farão parte do projeto em desenvolvimento;
Análise de Viabilidade:
Permitir a prévia identificação de possíveis oportunidades ou riscos que podem influenciar o projeto;
Análise de Requisitos:
Levantar iterativamente os requisitos que a ontologia deve atender;
Projeto: Corresponde a geração da ontologia em linguagem formal ou num modelo conceitual que permita sua implementação;
Implementação: Transformação da representação conceitual ou formal numa linguagem de implementação;
Implantação: Corresponde à aplicação da ontologia desenvolvida e sua integração com as aplicações identificadas nas fases iniciais de projeto;
Gerência do Projeto: Por ser um processo iterativo e incremental, esta disciplina é constante durante todo o ciclo de desenvolvimento da ontologia e corresponde a gerência e configuração, documentação e treinamento.
Processos de Suporte e Integralização: Ambos os processos foram definidos como trabalho futuro e correspondem aos processos de pós-desenvolvimento;
O modelo de processo Helix-Spindle, proposto em, sugere a utilização de uma abordagem teórica e prática para o desenvolvimento de ontologias, ao invés de seguir exclusivamente uma destas abordagens.
O princípio teórico e dedutivo especifica a ontologia numa forma executável enquanto o princípio prático realiza sua validação.
O processo Helix-Spindle é baseado num modelo de processo capturado a partir de três grandes fases, motivadas por a noção de um desenvolvimento incremental e de sucessivos refinamentos de versões de ontologias geradas.
Conseqüentemente, consegue- se desenvolver ontologias, aumentando o nível de formalidade.
As três fases do modelo de processo são:
Concepção: Representação informal da ontologia como, por exemplo, de maneira textual;
UML ou Ontolingua;
Naur Form (BNF) ou lógica de predicados.
Todas as três fases consistem na construção da ontologia através de uma abordagem teórica.
A ontologia resultante de cada fase é testada de forma empírica.
Este capítulo procurou apresentar a definição de ontologias no contexto da Ciência da Computação, visando estruturar uma descrição e um entendimento comuns.
Para estruturar o conhecimento expresso numa ontologia, é necessária a análise de linguagens lógicas.
Para tanto, foi apresentado um estudo sobre OWL, visando analisar a forma em a qual o conhecimento pode ser organizado numa linguagem declarativa.
A importância desta análise é válida para identificar as estruturas lógicas que mapeiam um modelo conceitual.
O estudo de uma linguagem lógica não é suficiente para o desenvolvimento de uma ontologia coerente com o domínio.
Para tanto, foram avaliadas algumas propostas relacionadas à construção de ontologias, analisando as diferentes sistemáticas de desenvolvimento.
O objetivo do estudo é identificar padrões e boas práticas que apóiem a criação de ontologias integradas ao processo de desenvolvimento de software.
Uma primeira observação com relação a a construção de ontologias diz respeito aos métodos utilizados para o desenvolvimento das propostas que, em sua maioria, foram empíricos.
Este tipo de abordagem implica que a ontologia gerada a partir de determinada metodologia possa apresentar diferentes graus de abstração e detalhamento se comparada à outra.
Isso se deve à ênfase dada por diferentes autores em diferentes etapas do processo de desenvolvimento.
Frente a as propostas apresentadas, percebe- se também uma convergência de pontos estruturais.
É observado um certo padrão interativo para o desenvolvimento de ontologias, que incluem os seguintes passos:
Definição do escopo da ontologia;
Aquisição e explicitação dos conceitos do domínio (modelo conceitual);
Formalização dos conceitos (modelo formal);
Integração, se necessário, com ontologias existentes;
Definição de axiomas;
Validação. Outra questão pertinente diz respeito à ênfase que determinadas propostas dão para alguns passos em detrimento de outros.
Mesmo observando este fato, todas as propostas indicam que os seis passos são necessários.
Por fim, pode- se notar que muito do esforço empregado na construção de uma ontologia está relacionado com a compreensão do domínio e com sua conceituação.
Durante as fases iniciais do Processo Unificado, os esforços se concentram em aspectos semelhantes, como a modelagem de negócios e a definição do domínio.
Ainda que preocupado com a definição do domínio, o processo de desenvolvimento tradicional não utiliza linguagens lógicas para representar formalmente uma conceituação.
Frente a os resultados obtidos por a análise de diferentes propostas de construção de ontologias, sugere- se a elaboração de uma abordagem que consiga integrar, dentro de o tradicional processo de desenvolvimento de software, um modelo lógico que relacione os conceitos do domínio do problema com a arquitetura da solução.
Como resultado desta integração, objetiva- se uma sinergia entre os modelos.
Este capítulo apresenta um paralelo entre Engenharia de Software e a construção de ontologias.
Além disso, é apresentada uma proposta de integração de ontologias no Processo Unificado.
O objetivo desta comparação é identificar oportunidades que permitam uma cooperação entre as comunidades de engenharia de software e de engenharia do conhecimento, possibilitando a inclusão de um modelo conceitual expresso através de uma ontologia no processo de desenvolvimento de software.
Em este capítulo, será proposta a criação de uma nova disciplina no Processo Unificado para construção de ontologias.
Com isso, consegue- se o apoio necessário para a proposta de rastreabilidade ontológica.
Serão descritas as atividades relacionadas com esta nova disciplina, criando um elo com as propostas para construção de ontologias estudas.
Por fim, serão apresentados alguns trabalhos relacionados e algumas considerações.
Como ontologias surgiram na comunidade de Inteligência Artificial, pode existir uma crença de que seu desenvolvimento necessite de uma revolucionária metodologia ou tecnologia.
Em a verdade, ontologia é um conceito baseado em entidades e seus relacionamentos.
Em muitos casos, pode- se criar uma ontologia a partir de uma metodologia de Engenharia de Software, recuperando suas entidades a partir de, por exemplo, diagramas de classes, modelos entidade-relacionamento ou uma análise estruturada de um sistema Mesmo que a engenharia de ontologias e a Engenharia de Software concentrem esforços no mapeamento de conceitos e tradução entre modelos, existem algumas diferenças entre as duas abordagens.
A complexidade relacionada a um modelo lógico é diferente da relacionada a um modelo orientado a objeto (OO).
Por exemplo, a definição da lógica de predicados implica que os relacionamentos entre os conceitos sejam considerados elementos de primeira ordem, o que não ocorre num paradigma OO (como o modelo de classes não estereotipado), em a qual os relacionamentos são subordinados aos conceitos das classes.
Logo, não é possível mapear um modelo ontológico completo, com todas as restrições lógicas, num diagrama de classes OO.
Isso de deve porque estas representações OO apenas capturam a taxonomia dos conceitos e seus relacionamentos, e não as regras lógicas que uma ontologia define.
Outro ponto pertinente é relacionado com a tendência de desenvolvimento de ontologias contextualizadas, apoiadas por a proposta da Web Semântica.
A Web Semântica, idealizada por Tim Berners-Lee, descreve uma rede que interligue semanticamente os conteúdos publicados na Web.
A idéia desta rede é que os conteúdos não sejam compreensíveis apenas por os humanos, mas também por o processamento computacional utilizando, por exemplo, ontologias e agentes de software.
Segundo Tim Berners-Lee, a Web Semântica não é uma Web alternativa, mas uma extensão da atual, onde a informação é recuperada através de uma semântica bem definida, habilitando uma cooperação entre trabalho humano e computacional.
Ela é baseada numa estrutura descentralizada, onde agentes de software possam migrar num ambiente de diversas estruturas, compreendendo e realizando tarefas sofisticadas para os usuários através da valoração semântica destes conteúdos.
Conforme observado em, a Web Semântica será formada por &quot;ilhas de conhecimento», isto é, ontologias específicas para alguma aplicação que geram interoperabilidade com outras ontologias para recuperação semântica do conhecimento.
Diante de esta tendência de descentralização, é interessante observar formas para construção de ontologias no processo de desenvolvimento de software, habilitando assim a modelagem semântica de sistemas de informação específicos.
O processo de desenvolvimento de software define o ciclo de vida de um produto de software.
Entende- se por ciclo de vida, todas as atividades envolvidas com o produto, desde o levantamento de suas necessidades até o desenvolvimento, teste e manutenção.
O Processo Unificado é um exemplo de um processo de desenvolvimento bem sucedido.
Ele organiza o desenvolvimento de software em quatro diferentes fases:
Iniciação, elaboração, construção e transição.
Cada fase pode suportar diversas iterações e, por sua vez, cada iteração é categorizada em nove disciplinas:
Modelagem de negócio, requisitos, análise e projeto, implementação, teste, implantação, gerência de mudanças e configuração, gerência de projetos e ambiente.
A Figura 3.1 apresenta a arquitetura geral do Processo Unificado.
Durante a disciplina de Modelagem de Negócios, o Processo Unificado sugere o desenvolvimento de uma representação de conceitos do mundo real, chamado de Modelo de Domínio.
O Modelo de Domínio descreve os conceitos do domínio e seus relacionamentos, utilizando a sintaxe UML do diagrama de classes.
É importante lembrar que o objetivo deste modelo é entender o contexto do sistema, e não especificar a arquitetura de uma possível solução.
Portanto, deve- se desenvolver- lo num alto nível de abstração e relativamente independente da solução considerada.
O Modelo de Domínio descreve apenas os conceitos mais significativos do sistema.
Os demais conceitos podem ser listados num pequeno glossário do domínio.
O objetivo do glossário e do modelo é o auxílio na elaboração de uma conceituação compartilhada entre os envolvidos com a definição e o desenvolvimento do sistema.
Além de a conceituação compartilhada, o modelo auxilia na identificação de possíveis ambigüidades que possam existir entre os vários subdomínios.
A análise do Modelo de Domínio permite observar sua similaridade com ontologias:
Ambos especificam os conceitos e seus relacionamentos no contexto do domínio de discurso.
O Modelo de Domínio representa o domínio da aplicação usando uma visão de negócios e não uma visão arquitetural, com o objetivo de compreender o contexto do sistema e compartilhar essa conceituação entre os stakeholders.
Ontologias também podem ser utilizadas para representar uma conceituação compartilhada entre os stakeholders, representando um domínio de aplicação numa perspectiva de negócios.
Após a contextualização do domínio do problema, é preciso capturar as necessidades dos stakeholders para definição do sistema.
É durante a disciplina de Requisitos que o time compreende as necessidades dos usuários, obtendo as características e restrições do sistema a partir de o especialista de domínio.
Para se desenvolver uma ontologia consistente, é necessário obter o conhecimento explícito sobre o domínio.
Utilizando o Modelo de Domínio como entrada, é possível criar uma ontologia e refinar- la usando a especificação de requisitos.
Este refinamento deve identificar os conceitos, organizar a taxonomia e definir as regras lógicas que definem o domínio do problema.
Após a especificação dos requisitos, o software será modelado e sua arquitetura definida na disciplina de Análise e Projeto.
O uso de ontologias nas fases anteriores do processo de desenvolvimento permite uma rastreabilidade semântica entre os conceitos do domínio e os elementos arquiteturais derivados desse domínio.
Para permitir a rastreabilidade semântica, este trabalho propõe a integração de ontologias no Processo Unificado.
O Processo Unificado foi escolhido por a sua boa aceitação na comunidade acadêmica e industrial.
Utilizando ontologias, é possível gerar elos de rastreabilidade entre o Modelo de Domínio, Especificação de Requisitos de Software, Modelos.
Além disso, é possível obter relacionamentos implícitos e cognitivos entre os artefatos do sistema, utilizando inferências sobre a ontologia.
A presente proposta sugere a integração de ontologias no Processo Unificado de forma não intrusiva, visto que não são sugeridas modificações nas demais disciplinas existentes.
A idéia básica é criar uma nova disciplina, chamada Modelagem do Conhecimento, para desenvolvimento de um modelo lógico que represente os conceitos do domínio do problema.
Utilizando este modelo, será possível relacionar toda a especificação dos componentes de software com os conceitos da ontologia, possibilitando a rastreabilidade ontológica.
A proposta de criação de uma nova disciplina no Processo Unificado visa à modelagem do conhecimento relativo ao domínio do problema.
Para tanto, é necessário uma adaptação no Processo Unificado.
Definiu- se a ontologia como sendo o único artefato produzido durante a modelagem do conhecimento.
Para sua construção, esta disciplina inclui algumas das boas práticas identificadas na literatura, agora integradas ao desenvolvimento de um sistema de informação.
Todas as propostas de construção de ontologias analisadas possuem como objetivo a engenharia de um modelo lógico para determinado domínio, independente da engenharia de um software específico.
Para a definição do processo que descreve a disciplina, será utilizada a notação do meta-modelo SPEM (Software Process Engineering Metamodel).
O Quadro 3.1 representa os elementos utilizados para este fim e seus significados.
Quadro 3.1 -- Notação utilizada para definição do processo.
Elemento Ícone proposto por o SPEM Elemento Artefatos Papéis Atividades Pacote de Processo Fases Ícone proposto por o SPEM Processo Iterações Serão utilizados alguns dos artefatos do Processo Unificado como entrada para esta disciplina.
Suas atividades estão definidas conforme os passos identificados na Seção 2.4, que compreendem:
Definição do escopo da ontologia;
Aquisição e explicitação dos conceitos do domínio (modelo conceitual);
Formalização dos conceitos (modelo formal);
Integração, se necessário, com ontologias existentes;
Definição de axiomas;
Validação. A disciplina proposta está estruturada em três principais atividades:
Projeto: Ocorre durante a fase inicial do processo, executando os passos 1, 2 e 3.
Esta atividade recebe como entrada o artefato chamado Modelo de Domínio, proposto durante a disciplina de Modelagem de Negócios, para definir o conhecimento através do escopo da ontologia e da explicitação de seus conceitos e relacionamentos.
Como resultado, é possível formalizar uma ontologia preliminar, utilizando uma tradução automática deste modelo.
Posteriormente, é possível refinar o conhecimento expresso através da ontologia de acordo com os artefatos produzidos;
Manutenção: A o terminar a atividade de projeto, inicia- se a manutenção do conhecimento, executando os passos 4 e 5.
O objetivo é refinar a ontologia previamente gerada, adequando às estruturas lógicas que tanto definem quanto restringem o domínio.
Também é possível a integração, se necessário, a ontologias existentes.
Durante esta etapa, são definidos os axiomas do modelo lógico.
Os conceitos da ontologia são refinados à medida que os documentos de Especificação de Requisitos, Modelo evoluam, pois é possível que surjam novos conceitos e relacionamentos ao longo de o ciclo de vida do software;
Validação: A validação do conhecimento é constante durante todo o processo de desenvolvimento, conforme o passo 6.
Em as próximas seções, serão detalhadas as atividades apresentadas.
Para melhor compreender a disciplina, foi elaborado um diagrama que representa o workflow das atividades envolvidas com a proposta, representado por a Figura 3.2.
Unificado. É possível perceber que as atividades da modelagem do conhecimento iniciam após o início da disciplina de Modelagem de Negócios e tem seu ponto de maior esforço durante a transição entre a fase de Iniciação e a de Elaboração.
É nesta fase que os projetistas já possuem um bom entendimento do domínio do problema e são capazes de representar o conhecimento envolvido com o software em desenvolvimento.
Durante o desenvolvimento de software, é necessária a manutenção da ontologia, a qual garante a integridade dos novos conhecimentos obtidos durante o detalhamento de sua arquitetura.
A seguir, apresentaremos em detalhes as atividades da disciplina de Modelagem do Conhecimento.
Foi identificado que, durante a disciplina de Modelagem de Negócios, o Processo Unificado sugere o desenvolvimento de um artefato chamado Modelo de Domínio, que é uma representação conceitual do universo que se deseja modelar.
Devido a sua similaridade com ontologias, o mesmo será utilizado como insumo para a atividade de projeto.
A partir de o Modelo de Domínio, gerado durante a disciplina de Modelagem de Negócios, é definida uma versão preliminar da ontologia.
Esta versão possui a mesma expressividade conceitual que o Modelo de Domínio, porém organizado num formalismo lógico.
Em este formalismo, ocorre a delimitação do escopo e a explicitação dos conceitos do domínio, além de os relacionamentos taxonômicos e não taxonômicos.
Adicionalmente, esta versão da ontologia é refinada durante a disciplina de Análise de Requisitos, visando à manutenção de sua integridade caso surjam novos conhecimentos sobre o domínio.
De a mesma forma, sugere- se a atualização do Modelo de Domínio para manter sua integridade com o modelo de conhecimento expresso através da ontologia.
De acordo com, existem três principais razões para que ontologias falhem na representação do conhecimento:
O seu desenvolvimento não está vinculado a aplicações do mundo real, a sua estrutura contém o reuso de ontologias de domínios diferentes e o seu desenvolvimento compreende uma mera taxonomia de conceitos, que falha na captura das regras de inferência que representam o conhecimento tácito da aplicação.
É durante a engenharia de requisitos que se obtém o conhecimento sobre o domínio da aplicação e as necessidades dos stakeholders.
Assim, os motivos de falha propostos por podem ser minimizados com um processo de engenharia de requisitos de qualidade, pois o software a ser construído está relacionado com uma aplicação do mundo real, onde se propõe a criação de uma ontologia específica e contextualizada.
Em esta etapa de desenvolvimento de software, os conceitos relacionados ao domínio da aplicação são declarados explicitamente por os stakeholders, sugerindo assim que as regras de inferência estejam de acordo com as características do sistema.
Adicionalmente, as regras de negócios estabelecidas na especificação de requisitos e demais artefatos poderiam ser representadas por regras não taxonômicas da ontologia.
Existem algumas propostas, tais como e, para explicitação dos conceitos referentes aos requisitos do sistema com o objetivo de compartilhar e reusar o conhecimento sobre o domínio da aplicação.
Os autores sugerem a criação de um léxico a partir de a especificação de requisitos e sua tradução para uma ontologia.
Uma atividade importante durante a etapa de projeto é o refinamento do modelo conceitual.
Para tanto, será seguida uma proposta semelhante à metodologia On--ToKnowledge.
Após definida a versão preliminar da ontologia e a Especificação de Requisitos, é interessante percorrer este último e verificar se todos os termos relevantes estão explicitados na ontologia.
Feito isso, este procedimento deve ser repetido avaliando a organização taxonômica (generalização e especialização) entre os conceitos.
Por fim, é necessário avaliar os relacionamentos não taxonômicos, tais como os atributos e os relacionamentos entre os conceitos.
Apoiando a presente proposta, também sugere a formalização dos conceitos da ontologia utilizando a linguagem UML como uma etapa intermediária da engenharia ontológica.
Segundo, a formalização tem por objetivo transformar o conhecimento estruturado na atividade de conceituação num modelo formal semicomputável.
Existe uma proposta do Ontology Working Group da OMG para definição de ontologias utilizando o chamado Ontology Definition Meta--Model (ODM).
Portanto, também é possível especificar o Modelo de Domínio através desta proposta que estende a UML.
Após definido e validado o Modelo de Domínio, é realizada a extração automática de uma versão preliminar da ontologia.
Esta versão é definida através do mapeamento de algumas estruturas, tais como classes, atributos, associações e generalizações em UML para estruturas com a mesma semântica em OWL.
Será adotada esta linguagem devido a sua recomendação por a, cabendo ao desenvolvedor definir qual das três de suas sublinguagens utilizar (Lite, Dl ou Full).
O Quadro 3.2 apresenta o guia de mapeamento das estruturas.
Quadro 3.2 ­ Mapeamento entre estruturas UML e OWL.
Classe OWL Class Datatype Property Atributos· Domínio:
Classe Pai· Imagem:
Tipo XSD definido por o XML Schema.
Object Property· Domínio:
Classe da associação inicial.·
Imagem: Classe da associação final.·
Restrições: Associações Se associação inicial e final é navegável, a propriedade é simétrica.
Se a multiplicidade das duas associações é igual, cria- se uma restrição de cardinalidade, senão cria restrições de cardinalidade mínima e máxima.
Generalização Define relacionamento taxonômico entre as classes.
Foi utilizada a proposta ODM da como base para definir o guia de mapeamento.
O documento ODM define as equivalências entre classes, atributos, associações, generalizações e restrições.
Para exemplificar, a Figura 3.4 apresenta um cenário de uma estrutura UML.
A estrutura ontológica derivada da Figura 3.4 corresponde a:
Três OWL Classes:
Pessoa, Funcionário e Cliente;
Um Datatype Property chamado nome, que possui como domínio a OWL Class Pessoa e como imagem o seu tipo XSD definido por o XML Schema:
Um Object Property chamado recuperarInformação, que possui com domínio a OWL Class Funcionário e como imagem a OWL Class Cliente.
Uma estrutura taxonômica, organizando as OWL Classes Cliente e Funcionário como subclasse de OWL Class Pessoa.
Conforme já apresentado, não é possível o mapeamento completo de um modelo ontológico num modelo de classes OO devido a a falta de apoio destes modelos para representação de regras lógicas.
No entanto, o oposto não é verdade.
É possível mapear um modelo de classes num modelo lógico e, posteriormente, adicionar as regras necessárias para a definição do domínio.
A Figura 3.5 apresenta o modelo de processo relacionado à atividade de projeto.
A presente proposta inclui um novo papel no Processo Unificado, chamado Engenheiro do Conhecimento, que indica o responsável por executar as atividades relacionadas à disciplina de Modelagem do Conhecimento.
O engenheiro do conhecimento recebe como entrada o Modelo de Domínio para extração da ontologia.
Após, os novos conhecimentos obtidos a partir de a Especificação de Requisitos devem ser formalizados na ontologia, refinando os conceitos e as definições de propriedades taxonômicas e não-taxonômicas, como object properties e datatype properties.
Terminada a atividade de projeto, tem- se como novo artefato a ontologia que será refinada de acordo com os novos conhecimentos obtidos nas próximas etapas do ciclo de vida do software.
A atividade de projeto não produz uma versão da ontologia que define o conhecimento completo sobre o domínio, pois este modelo não consegue mapear automaticamente a maioria das regras lógicas necessárias para restringir o conhecimento.
Para resolver este problema, é possível refinar a ontologia utilizando ferramentas específicas para sua manipulação, como, por exemplo, o Protégé.
O refinamento da ontologia pode ser realizado utilizando à mesma abordagem da fase anterior, baseada na metodologia On--ToKnowledge.
O objetivo deste refinamento é formalizar o conhecimento adicional adquirido ao longo de o processo de desenvolvimento, expressando- o através de regras lógicas sobre a ontologia e novos conceitos e relacionamentos.
Como exemplo de regras lógicas, tem- se conjunções, disjunções, quantificação universal e existencial, negações, restrições de número, entre outros.
O principal objetivo desta fase é gerar os elos de rastreabilidade entre os artefatos desenvolvidos durante o projeto de software (Especificação de Requisitos, Modelo e de Projeto) com os conceitos que compõem a ontologia.
Adicionalmente, o processo proposto irá refinar ao modelo ontológico para manutenção de sua integridade, adaptando- o com a evolução projeto.
Durante o processo de desenvolvimento, todos os artefatos gerados e seus componentes poderão ser mapeados através dos conceitos da ontologia, gerando, assim, os elos de rastreabilidade.
Desta forma, consegue- se uma gestão integrada do conhecimento sobre os conceitos externos a arquitetura do sistema com as estruturas e processos do projeto de software.
Posteriormente, será apresentada a forma como estes elos de rastreabilidade foram estruturados.
A Figura 3.6 representa os processos relacionados à atividade de Manutenção da disciplina de Modelagem do Conhecimento.
De a mesma forma que na fase de Projeto, o ator engenheiro do conhecimento será o responsável por a coordenação das atividades desta fase.
Ele receberá como entrada a Especificação de Requisitos, o Modelo de Análise, o Modelo de Projeto e a Ontologia.
Esta última sofrerá freqüentes atualizações para manutenção de sua integridade ao longo de o processo de desenvolvimento.
As principais atividades desta fase são:
Esta atividade corresponde à constante avaliação do conhecimento sobre o domínio do problema.
O especialista do domínio é responsável por avaliar a integridade, completude e corretude deste conhecimento, definido por o engenheiro do conhecimento e expresso através da ontologia, de forma análoga à idéia de gestão de conhecimento coorporativo.
Propõe- se utilizar uma abordagem semelhante às propostas On-To--Knowledge e Helix-Spindle, em que se verifica a consistência do modelo lógico a cada nova iteração do ciclo de desenvolvimento da ontologia.
Esta validação deve ser executada utilizando uma abordagem indutiva e pragmática.
Assim, garante- se uma adequada, consistente e coerente representação do vocabulário para a modelagem do domínio.
Este processo propõe três tipos de validação para cada etapa do desenvolvimento da ontologia, sendo eles:
Teste Unitário, de Integração e de Aceitação.
Os dois primeiros devem ser executados por o engenheiro do conhecimento e o último deve ser executado por agentes de softwares ou outras aplicações que utilizem à ontologia.
Fernández López desenvolveu num estudo para avaliar diversas metodologias de engenharia ontológica encontradas na literatura.
Para tanto, o autor define uma série de critérios:
C1: Herança da engenharia do conhecimento:
Considerando a influência da tradicional engenharia do conhecimento na metodologia em questão;
C2: Detalhamento da metodologia:
Consideração de quais atividades e técnicas propostas por a metodologia são especificadas;
C3: Recomendação por a formalização do conhecimento:
Consideração sobre formalismos lógicos, frames, etc..
C4: Estratégia para construção de ontologias:
Discussão da estratégia adotada:
Dependente da aplicação, semi-dependente de aplicação ou independente de aplicação;
C5: Estratégia para identificação dos conceitos:
Definição de estratégias, partindo de uma abordagem mais abstrata para uma mais concreta (top-down), da mais concreta para mais abstrata (bottom-up) ou da mais relevante para mais abstrata ou mais concreta (middle-out);
C6: Recomendação do ciclo de vida:
Avaliação se a metodologia propõe um ciclo de vida implícito ou explícito para ontologia;
C7: Diferenças entre a metodologia e o padrão IEEE 1074- 1995:
Comparação da metodologia com o padrão da IEEE para descrição do processo de desenvolvimento de software;
C8: Técnicas recomendadas:
Especificação de quando técnicas particulares são propostas para serem executadas ao longo de a metodologia;
C9: Definição das ontologias que foram desenvolvidas utilizando a metodologia em questão e quais sistemas foram construídos utilizando esta ontologia:
Descrição das ontologias e dos sistemas que as utilizam.
O objetivo desta seção não é realizar uma validação da presente proposta, mas apenas comparar- la aos critérios identificados por Fernández López.
Com relação a os critérios estabelecidos, a proposta apresenta:
C1: Embora não esteja relacionada diretamente com a engenharia do conhecimento, nossa proposta sugere a utilização de uma técnica para modelagem do conhecimento que claramente identifica a aquisição, codificação e avaliação da ontologia;
C2: Nossa metodologia especifica exatamente quais as atividades envolvidas com a engenharia ontológica, identificando responsáveis por sua execução.
Adicionalmente, foram referenciadas diversas técnicas de outras metodologias que podem ser integradas a nossa proposta;
C3: A ontologia é formalizada desde suas etapas iniciais.
Durante a fase inicial, a versão preliminar da ontologia é mapeada numa estrutura orientada a objetos (Modelo de Domínio), definindo apenas os conceitos e suas propriedades taxonômicas e não-taxonômicas.
Durante a fase de manutenção, a ontologia é formalizada numa linguagem (OWL) e todas as regras lógicas são implementadas;
C4: A nossa proposta sugere um forte acoplamento da ontologia com o sistema de informação durante seu processo de desenvolvimento, isto é, dependente da aplicação;
C5: É sugerida a utilização da abordagem top-down, isto é, a identificação de conceitos a partir de uma perspectiva mais abstrata e semi-formal para uma mais concreta e formal.
A técnica para identificação dos conceitos sugerida é semelhante à metodologia On-To--Knowledge;
C6: Nossa proposta sugere um ciclo de vida explícito para ontologia, definindo as atividades relacionadas desde sua concepção, projeto, manutenção e avaliação;
C7: Por ser sugerida como uma disciplina integrada ao Processo Unificado, nossa proposta está relacionada ao padrão da IEEE.
C8: Durante a especificação das atividades relacionadas com a engenharia ontológica, são sugeridas diversas técnicas e questões de competência como, por exemplo, a vinculação aos cenários motivacionais propostos por;
C9: Nossa proposta possui apenas uma ontologia desenvolvida visando sua avaliação.
Por ser uma proposta desenvolvida no escopo de uma dissertação de mestrado, sugere- se sua aplicação em domínios diferentes para trabalhos futuros.
Guarino, em, afirma que todo o sistema de informação possui sua própria ontologia.
A questão discutida por o autor compreende o papel que uma explícita ontologia pode exercer durante o desenvolvimento de software, em a qual ela guia a arquitetura utilizando como perspectiva central o domínio do problema.
Frente a esta tendência, são encontradas na literatura diversas propostas que sugerem a integração de Engenharia de Software e ontologias.
A vem apoiando uma proposta chamada de Ontology Driven Architectures (ODA), que corresponde à aplicação dos benefícios das linguagens para representação do conhecimento nas práticas de Engenharia de Software.
O objetivo desta integração é entusiasmar os engenheiros de software com a tecnologia da Web Semântica, encorajando uma colaboração mútua entre as duas comunidades.
Para exemplificar, a OMG vem desenvolvendo a iniciativa MDA (Model Driven Architecture) para utilizar os modelos não apenas com propósitos de projeto e manutenção, mas como a base para a geração de artefatos executáveis.
O ODM provê a extensão do MDA, habilitando a representação de vocabulários do domínio de forma não ambígua e provendo consistência e validação aos modelos de projeto, utilizando ontologias.
Em esta seção serão apresentadas algumas propostas que sugerem a integração de ontologias com o processo de desenvolvimento de software.
Inicialmente, serão apresentados alguns trabalhos desenvolvidos na comunidade científica e, posteriormente, algumas ferramentas que apóiam esta abordagem na indústria.
A proposta desenvolvida em consiste na construção de ambientes de software orientados a domínio, isto é, apoiar o desenvolvimento de software com base no conhecimento do domínio.
Os autores definem como requisitos para a proposta:
É necessária a investigação do domínio durante o desenvolvimento utilizando algum nível de formalização;
Permitir ao desenvolvedor trabalhar diretamente com o domínio do problema;
Apoiar a identificação, acesso e uso de objetos do conhecimento do domínio;
Apoiar o trabalho colaborativo entre usuários (ou especialistas) do domínio e desenvolvedores dado que, com o conhecimento do domínio integrado no ambiente de desenvolvimento, o trabalho com os usuários pode ser mais fácil utilizando um vocabulário comum.
De forma geral, a proposta consiste em mapear o conhecimento do domínio e permitir seu acesso durante o processo de desenvolvimento de software.
Os autores sugerem uma nova sub-atividade no processo de desenvolvimento, chamada &quot;investigação do domínio», semelhante à modelagem de negócios do Processo Unificado.
Para especificar o domínio, é sugerido o uso de ontologias.
A partir de a ontologia de domínio, é sugerida a derivação de algumas entidades arquiteturais, tais como modelagem de dados e objetos.
A proposta da estação Taba se relaciona com o nosso trabalho através da criação da sub-atividade necessária à vinculação do modelo conceitual com as demais etapas do desenvolvimento de software.
Em nossa proposta, é sugerida a integração de ontologias no Processo Unificado por a criação de uma nova disciplina, visando apoiar o processo de desenvolvimento e não na geração da arquitetura da solução por a derivação do modelo lógico.
Nossa proposta enfatiza o desenvolvimento de uma ontologia utilizando a linguagem sugerida por a, através do mapeamento do Modelo de Domínio numa ontologia, utilizando como guia a proposta definida por o.
Adicionalmente, é apresentado um processo detalhado para a criação da ontologia, baseado em diversas propostas de engenharia ontológica bem aceitas na literatura, definindo assim todas as entidades e regras lógicas que compõem a ontologia.
Falbo, em, apresenta Ode (Ontology--based software Development Environment), um ambiente para desenvolvimento de software baseado em ontologias.
Ode possui como base quatro distintas ontologias para processo, qualidade, artefatos e riscos de software com o objetivo de estruturar o ambiente e a infra-estrutura da ferramenta.
A proposta consiste na derivação sistemática de infra-estruturas de objetos a partir de ontologias, isto é, a derivação dos conceitos da ontologia num modelo de objetos.
São definidos três níveis para manter a amarração semântica entre os objetos de Nível ontológico (ontologia):
É responsável por a descrição da ontologia propriamente dita, isto é, o modelo conceitual que especifica o domínio da aplicação;
Meta-nível (conhecimento):
Representa a derivação das classes e instâncias do nível ontológico, descrevendo o conhecimento do ambiente e do domínio da aplicação;
Nível base (controle):
Define as classes responsáveis por a implementação das aplicações no contexto do ambiente, sob a perspectiva da arquitetura do software.
Estas classes são derivadas da ontologia base.
A proposta do autor consiste numa nova abordagem para o desenvolvimento de software, baseada na evolução de uma ontologia que especifica um modelo conceitual até a arquitetura que implementa o software.
A proposta é semelhante à Estação Taba, porém com maior ênfase na construção de ontologias e na sistemática na derivação do sistema de informação.
A proposta sugerida por Falbo é alternativa ao Processo Unificado, divergindo da apresentada neste trabalho.
A nossa proposta consiste na integração de ontologias ao Processo Unificado, aproveitando o esforço da aquisição do conhecimento do domínio e provendo os benefícios que uma linguagem lógica oferece para apoiar o ciclo de vida do software.
Oberle, em, sugere o desenvolvimento e gerenciamento de componentes de software num servidor de aplicação baseado em ontologias, isto é, a utilização de ontologias para mapear a descrição de componentes de software num servidor de aplicação.
A idéia compreende em carregar os meta-dados semânticos e a ontologia num motor de inferência e realizar a recuperação de componentes a partir de suas descrições.
Para a descrição de um componente utilizando ontologias, é necessário o conhecimento implícito do domínio do problema que o componente de software implementa.
A abordagem proposta por o autor não apresenta como este conhecimento é evoluído numa arquitetura, apenas sugere como aproveitar a oportunidade da descrição do componente no contexto de um servidor de aplicação.
Nossa proposta é complementar a de, visto que se preocupa com o ciclo de vida completo para construção do componente e sua ontologia associada.
De a mesma forma que é observada uma tendência na comunidade científica para integrar ontologias ao desenvolvimento de software, a comunidade industrial também vem apoiando esta idéia.
A IBM vem participando ativamente no desenvolvimento da proposta ODM do e apresenta o IBM Integrated Ontology Development Toolkit.
Esta ferramenta é integrada ao Eclipse e apóia a transformação de ontologia em outros modelos orientados a objeto, além de a manipulação de modelos lógicos, como OWL e RDF.
Apesar de o suporte para o mapeamento da ontologia em outros modelos, esta ferramenta não provê o apoio a rastreabilidade e a integração dos conceitos do domínio com todos os elementos UML do projeto de software, apresentado em nossa proposta.
Existem propostas de ferramentas exclusivas para manipulação de ontologias, como Protégé, OILEd e OntoEdit, porém não serão apresentados detalhes neste trabalho.
O foco aqui é apresentar ferramentas que integrem ontologias com a Engenharia de Software, e não exclusivamente uma das vertentes.
Apesar de algumas diferenças entre o paradigma orientado a objetos e o ontológico, neste trabalho é sugerida uma sinergia entre suas engenharias, apoiando a proposta de integração de ontologias no Processo Unificado.
O objetivo desta integração não é sugerir uma proposta inovadora para construção de ontologias, mas sim aproveitar os esforços despendidos durante o processo de desenvolvimento de software na construção de ontologias.
Além disso, nossa proposta tem como base diversas metodologias de engenharia ontológica aceitas na comunidade científica, integrando suas sistemáticas e boas práticas.
Conforme já apresentado, muito do esforço relativo à construção de ontologias está relacionado com a identificação do propósito, explicitação do domínio, delimitação do escopo e modelagem conceitual.
Os esforços iniciais do Processo Unificado compreendem aspectos relacionados a estes, onde os stakeholders realizam a compreensão do domínio e a modelagem de negócios.
É com base nesta premissa que nossa proposta se apóia.
Por essa integração, muito do esforço despendido com a engenharia ontológica pode ser salvo através de uma Engenharia de Software com qualidade.
Para exemplificar, toma- se como exemplo os cenários motivacionais proposto por e apoiados por, e.
Estes cenários podem corresponder a casos de uso do processo de desenvolvimento de software que, sob uma perspectiva de negócios, estabelecem um conjunto de problemas que devem ser resolvidos através de uma modelagem conceitual.
Adicionalmente, devido a a similaridade entre o modelo ontológico e o modelo de domínio, é possível formalizar uma estrutura que representa as bases da ontologia.
Por outro lado, integrando ontologias ao desenvolvimento de software, se possibilita uma gestão integrada dos conceitos do problema com as diversas visões que compõem um sistema de informação, incluindo uma perspectiva de negócios, requisitos, análise e projeto.
Por gestão integrada, compreende- se o relacionamento dos conceitos do sistema com a arquitetura que especifica sua solução, visando recuperar elos de rastreabilidade que representam o conhecimento tácito obtido durante o processo de desenvolvimento.
Posteriormente, será apresentada a proposta de estruturação e recuperação destes elos.
A rastreabilidade é a capacidade de inter-relacionar e recuperar entidades que se identificam durante um processo.
Em o processo de desenvolvimento, o termo rastreabilidade diz respeito ao relacionamento entre os requisitos do software com as necessidades dos usuários e as entidades que compõem a solução computacional.
Utilizando ontologias, é possível relacionar os conceitos pertinentes às necessidades dos usuários com os artefatos desenvolvidos durante o processo de desenvolvimento.
Este capítulo apresenta algumas dimensões para classificação de elos de rastreabilidade e uma proposta para estruturar estes elos, utilizando um modelo lógico.
O objetivo é a redução da granularidade destes elos, de requisitos para conceitos, visando recuperar informações mais apuradas.
Para verificar a viabilidade e aplicabilidade da proposta descrita, é necessário o desenvolvimento de uma ferramenta que apóie tanto a engenharia do conhecimento quanto a Engenharia de Software.
De posse de uma ontologia integrada ao processo de desenvolvimento, torna- se possível a proposta de rastreabilidade indexada por conceitos.
Este capítulo adicionalmente apresenta a ferramenta desenvolvida para automatizar a rastreabilidade ontológica ao longo de o ciclo de vida de um sistema de informação.
Um ponto fundamental para rastreabilidade consiste em perceber um sistema de informação como um conjunto de documentos e artefatos, que descrevem o software em diferentes níveis de abstração, e não apenas como uma implementação.
Em este contexto, define rastreabilidade como a habilidade de relacionar os itens dependentes dentro de um modelo e seus correspondentes em diferentes modelos.
De acordo com, rastreabilidade é uma propriedade de um sistema e um fator de qualidade que corresponde ao entendimento do software e ao acompanhamento da documentação de seus modelos.
Rastreabilidade, numa perspectiva mais ampla, corresponde à habilidade de relacionar e entender completamente o processo de desenvolvimento e seus artefatos.
A rastreabilidade pode prover um importante apoio para o desenvolvimento de software e sua manutenção, apoiando tanto uma evolução top-down quanto bottom-up.
Permite- se uma compreensão do sistema, apoiando mudanças para sua manutenção, incluindo análise de impacto e reuso de softwares existentes.
Adicionalmente, esta técnica provê um apoio essencial para o entendimento da organização estrutural entre os requisitos e seus artefatos derivados.
O grau de rastreabilidade pode ser obtido em diferentes níveis, desde uma convenção para nomes de documentos até elos de rastreabilidade explícitos, que relacionam itens de modelos.
Dentro de esta última perspectiva, existem diferentes dimensões que podem ser avaliadas para classificar os relacionamentos entre os modelos.
A rastreabilidade possui diversas classificações bem aceitas na literatura para avaliar a qualidade e o alcance dos relacionamentos.
A idéia desta seção é introduzir aspectos específicos de rastreabilidade para conduzir nosso estudo, identificando oportunidades que qualifiquem a rastreabilidade semântica.
A primeira dimensão de rastreabilidade diz respeito à interconexão dos itens relativos aos modelos.
Em esta perspectiva, apresenta as seguintes métricas:
Rastreabilidade Vertical:
Os itens relacionados pertencem ao mesmo artefato;
Rastreabilidade Horizontal: Os itens relacionados pertencem a artefatos diferentes.
Ambos os tipos de rastreabilidade são necessários para compreender um conjunto completo de relacionamentos pertinentes a uma análise de impacto, por exemplo.
Adicionalmente, esta divisão permite uma visão para o processo de manutenção de um conjunto de artefatos e seus respectivos ciclos de vida.
Para o mapeamento, tanto vertical quanto horizontal, a autora sugere o uso de grafos, onde um conjunto de objetos corresponde aos nodos e os relacionamentos correspondem a arestas.
É sugerida uma modularização entre requisitos, projeto, código e teste que estruturam uma organização vertical de seus componentes, e estes componentes se relacionam horizontalmente com os demais módulos.
A Figura 4.1 apresenta a proposta de organização horizontal entre componentes de software.
Um termo mais comum para rastreabilidade é apresentado como Rastreabilidade de Requisitos, que corresponde à habilidade de relacionar requisitos específicos com suas implementações.
Em esta perspectiva, Gotel e Finkelstein, apresentam uma divisão de rastreabilidade em duas principais dimensões:
Pré-Rastreabilidade: Capacidade de rastrear, a partir de os requisitos, as necessidades dos usuários;
Pós-rastreabilidade: Capacidade de recuperar como cada requisito é implementado.
De entre estas duas classificações, Finkelstein argumenta sobre a dificuldade da prérastreabilidade, devido a as inconsistências características das fases iniciais de entendimento do domínio e elicitação de requisitos.
Lindvall, em, nos apresenta duas classificações para rastreabilidade levando em conta o tipo de relacionamento entre os elementos, que são:
Relacionamento Explícito:
Representa a capacidade de recuperar relacionamentos entre dois modelos utilizando elos previamente definidos;
Relacionamento Implícito: Em oposição ao relacionamento explícito, representam associações organizadas por convenções como, por exemplo, padronização para nomes de entidades.
Uma abordagem explorada por diz respeito a relações obtidas através de sintaxe e semântica dos modelos, que consistem:
Relacionamentos Estruturais:
Corresponde a rastreabilidade associada a uma dependência sintática entre alguns artefatos, originadas a partir de o código fonte;
Relacionamentos Cognitivos: Dizem respeito aos elos de rastreabilidade obtidos através da semântica do conhecimento, associadas às decisões de projeto.
Frente a estas quatro propostas apresentadas, o Quadro 4.1 apresenta uma categorização das dimensões.
Posteriormente, estas categorias serão utilizadas para classificar a rastreabilidade semântica.
Quadro 4.1 ­ Dimensões de Rastreabilidade.
Dimensão Categoria Vertical Pré-Rastreabilidade Explícitos Estruturais Horizontal Pós-rastreabilidade Implícitos Cognitivos De acordo com, a rastreabilidade impõe o chamado de Princípio de Circularidade, isto é, é possível rastrear apenas aquilo que foi registrado e é possível registrar apenas aquilo que se percebe um rastro.
Para a modelagem da rastreabilidade, são necessários três aspectos:
Definição: Corresponde à especificação dos rastros;
Produção: Corresponde à captura dos rastros, através de um registro explícito do relacionamento entre os itens;
Extração dos elos:
Corresponde a recuperação dos relacionamentos registrados.
A utilização de matriz de rastreabilidade para indexar requisitos aos demais componentes de software é uma técnica bastante aceita.
Uma matriz de rastreabilidade é uma tabela que correlaciona itens de projeto entre si para manutenção da completude de seus relacionamentos.
Diversas ferramentas provêem uma automação na elaboração desta matriz, conforme verificado em.
A estrutura básica de uma matriz de rastreabilidade consiste numa organização dos requisitos em colunas e uma lista de artefatos em linhas.
Para cada registro de associação entre os requisitos e os artefatos, é registrada a associação na célula correspondente da matriz.
Em o capítulo anterior, foi apresentada uma proposta de processo para a construção de uma ontologia relativa a um sistema de informação.
Em este processo, foram explicitamente definidos todos os conceitos e seus relacionamentos, incluindo propriedades taxonômicas e não-taxonômicas.
Entretanto, o principal objetivo de se desenvolver uma ontologia é a possibilidade de relacionar todos os artefatos e seus elementos aos conceitos da ontologia durante o processo de desenvolvimento de software.
Utilizando ontologias, torna- se possível a recuperação de elos de rastreabilidade implícitos e cognitivos, utilizando um motor de inferência.
Para permitir um mapeamento conceito-artefato, é proposta uma estrutura ontológica organizada sobre um conceito chamado ONTraceBasis.
O conceito ONTraceBasis é um recurso que sustenta os mecanismos que provêem a rastreabilidade ontológica entre os artefatos.
Sobre este conceito estão estruturados outros dois:
Artifacts: É uma classe que representa uma instância de um elemento UML, tal como um caso de uso, classes em diagrama de classes, etc., geradas durante a modelagem do software.
Este artefato é caracterizado por duas propriedades do tipo datatype:
UML, definida por a classe Artifacts, aos conceitos da ontologia, representados por classes OWL;
Model: Definiu todos os tipos previstos por a UML.
Estes tipos estão definidos dentro de esta estrutura ontológica.
A classe Model organiza hierarquicamente os tipos conforme área, visão, diagramas e conceitos.
O relacionamento dos artefatos com seus respectivos tipos é importante para filtros de consulta, retornando apenas elementos como, por exemplo, casos de uso ou classes.
O Anexo A apresenta os componentes UML definidos por o autor.
A estrutura de rastreabilidade é incluída na ontologia gerada a partir de o modelo de domínio e, para cada elo de rastreabilidade, é criado ou atualizado uma instância do recurso Artifacts.
Estas instâncias estão relacionadas a conceitos da ontologia que serão utilizados como índice para recuperação de elos de rastreabilidade.
A Figura 4.2 apresenta um exemplo de estrutura instanciada, utilizando a notação provida por a para representação de ontologias.
A Figura 4.2 exemplifica um elo de rastreabilidade entre o caso de uso &quot;UC01 ­ Manter Funcionário «e o conceito da ontologia &quot;Funcionário «através da propriedade &quot;ontraceRecover».
Adicionalmente, este elo especifica que este indivíduo é do tipo &quot;UseCase», que é um dos tipos definidos por a taxonomia estabelecida sobre a classe &quot;Model».
Para cada estrutura do modelo que se deseja indexar por a ontologia, é gerado um novo indivíduo no modelo lógico que o relaciona a um ou mais conceitos.
Para exemplificar a sistemática da proposta, será apresentado um exemplo extraído de um cenário de loja virtual.
Supondo que:
O caso de uso &quot;Manter Cliente «esteja relacionado ao conceito da ontologia &quot;Cliente&quot;;
O caso de uso &quot;Registro de Compra «esteja relacionado aos conceitos da ontologia &quot;Funcionário», &quot;Produto «e &quot;Cliente».
A Figura 4.3 apresenta o cenário relacionando o diagrama de casos de uso com os conceitos da ontologia, expressos em OWL.
Então é possível dizer que os casos de uso &quot;Manter Cliente «e &quot;Registro de Compra «estão relacionados diretamente através do conceito &quot;Cliente».
Em o mesmo exemplo, supondo o conceito &quot;Funcionário «se relacione com o conceito &quot;Cliente «através de uma propriedade chamada &quot;recuperaInformacao».
Sabendo que o caso de uso &quot;Manter Funcionário «está relacionado com o conceito da ontologia &quot;Funcionário».
Com esta configuração, ilustrada por a Figura 4.4, é possível inferir uma nova informação sobre os artefatos:
O caso de uso &quot;Manter Cliente «está relacionado ao caso de uso &quot;Manter Funcionário «porque os conceitos da ontologia que relacionam ambos estão associados através de uma propriedade.
Esta propriedade indica que um item conceitual é relacionado a outro e que os elementos associados podem exercer impacto um sobre o outro.
Resumindo, diante de a configuração:
O caso de uso &quot;Manter Cliente «está relacionado ao conceito da ontologia &quot;Cliente&quot;;
O caso de uso &quot;Manter Funcionário «está relacionado ao conceito da ontologia &quot;Funcionário&quot;;
O conceito &quot;Funcionário «está relacionado com o conceito &quot;Cliente «através de uma propriedade chamada &quot;recuperaInformacao».
É possível dizer que o caso de uso &quot;Manter Cliente «está relacionado ao caso de uso &quot;Manter Funcionário».
Esta relação é indireta e pode ser recuperada através de regras de inferência, justificando o uso de ontologias para rastreabilidade.
Utilizando esta abordagem, é possível relacionar o sistema inteiro (modelos e seus elementos) aos conceitos da ontologia e recuperar- los através de relacionamentos diretos e indiretos.
Nossa proposta consiste na elaboração de um grafo de rastreabilidade que não relacione apenas os elementos arquiteturais com os requisitos, mas sim com os conceitos que definem o domínio do problema.
A idéia da utilização de grafos para este fim também é sugerida por.
A idéia de rastreabilidade compreende a possibilidade de criar indivíduos da ontologia que relacionem as visões de negócios, análise e projeto do sistema com os conceitos da ontologia.
Para suportar o processo de modelagem do conhecimento e a capacidade de aquisição dos elos de rastreabilidade do projeto de software, foi desenvolvido um protótipo para automatizar a proposta, que será apresentado no próximo capítulo.
De entre as propostas apresentadas para classificações de rastreabilidade, foram apresentadas quatro dimensões que definem tipos de rastros entre os artefatos.
Utilizando um grafo que relacione conceitos de uma ontologia com artefatos do sistema, as seguintes dimensões foram caracterizadas:
Rastreabilidade Vertical:
É possível indexar elementos do mesmo artefato a diferentes conceitos da ontologia;
Rastreabilidade Horizontal: É possível indexar elementos de diferentes artefatos a diferentes conceitos da ontologia;
Pré-Rastreabilidade: As necessidades dos usuários estão mapeadas em conceitos do domínio através da ontologia, portanto não é necessário fazer a regressão de requisitos para estes conceitos;
Pós-rastreabilidade: É possível recuperar como cada conceito foi implementado através de sua correta indexação;
Relacionamentos Explícitos: É possível recuperar relacionamentos através dos indivíduos da ontologia que representam explicitamente os elos;
Relacionamentos Implícitos: Através de convenções, é possível a recuperação de relacionamentos implícitos.
Adicionalmente, a ontologia apresenta regras de inferências que mapeiam o domínio, possibilitando a recuperação de relacionamentos implícitos, tais como transitividade, equivalência, consistência, classificação, etc., utilizando um motor de inferência;
Relacionamentos Estruturais: A dependência estrutural entre os elementos do modelo é mapeada numa taxonomia na ontologia, que indexa os itens de projeto.
Para exemplificar, a alteração numa superclasse UML pode impactar suas subclasses.
A estrutura UML é mapeada em conceitos organizados hierarquicamente na ontologia, e o impacto pode ser obtido através da recuperação dos relacionamentos indiretos apresentados na Seção 4.2;
Relacionamentos Cognitivos: Ontologias especificam explicitamente a semântica de um domínio, correspondendo ao conhecimento do problema.
A o se indexar os elementos de projeto aos conceitos, e estes conceitos estando organizados sobre regras lógicas, é possível recuperar relacionamentos cognitivos.
Esta abordagem não suporta relacionamento de decisões de projeto aos conceitos, apenas estruturas que modelam o sistema de informação.
Com a proposta de rastreabilidade ontológica, é possível cobrir todas as dimensões apresentadas.
Em a próxima seção, será apresentada uma ferramenta que apóia nossa proposta e, no capítulo seguinte, um estudo que a avalia experimentalmente.
Para a integração de um modelo lógico a um ambiente de modelagem de sistemas, foi identificada a necessidade de ampliar as funcionalidades das tradicionais ferramentas Case (Computer-Aided Software Engineering).
Inicialmente, foi desenvolvido um levantamento das ferramentas open-source de modelagem, identificando como as mais populares:
ArgoUML; Bouml;
ESS-Model; Fujaba;
Umbrello UML Modeler.
Após a análise de aspectos como popularidade, eficiência, estabilidade e qualidade do código fonte, optou- se por o ArgoUML como ferramenta padrão.
Paralelamente a avaliação das ferramentas, uma análise de viabilidade inicial foi desenvolvida para proposta de rastreabilidade ontológica.
Inicialmente, a análise de viabilidade foi desenvolvida com o objetivo de validar a recuperação de elos de rastreabilidade entre conceitos da ontologia e os itens do projeto de software.
Para tanto, a análise foi estruturada em quatro etapas:
Definição de um sistema de informação;
Construção da ontologia;
Criação dos elos de rastreabilidade;
Recuperação destes elos.
Para exemplificar nossa proposta, foi escolhido um sistema modelado e desenvolvido por alunos da graduação durante uma disciplina da Faculdade de Informática da PUCRS no domínio de uma academia desportiva.
O objetivo desta escolha é a utilização de um sistema elaborado por projetistas independentes, que não possuem conhecimento desta proposta.
Após a escolha do sistema, foi gerada uma ontologia utilizando o Protégé.
Esta ontologia foi extraída a partir de o Modelo de Domínio, utilizando o critério de mapeamento expresso no Quadro 3.2.
A estrutura de rastreabilidade proposta na Seção 4.2 também foi adicionada ao modelo lógico, possibilitando a rastreabilidade semântica.
Com a ontologia desenvolvida, foi possível a criação de indivíduos que representam elos de rastreabilidade.
Para cada elemento UML do sistema modelado, foi desenvolvido um novo indivíduo na ontologia que indica o seu tipo e o relaciona aos conceitos pertinentes.
A atividade final da análise de viabilidade foi à utilização de um motor de inferência para manipulação da ontologia e realização de consulta sobre as declarações.
Utilizando o framework Jena, foi possível a recuperação dos elos entre os diversos componentes do sistema.
Foi desenvolvida uma aplicação que realiza a seguinte sistemática:
Recuperar um conjunto de conceitos primários que se relacionam com determinado artefato do sistema, sabendo que um artefato pode possuir mais de um conceito associado;
Para cada conceito primário, recuperar o conjunto de artefatos que se relacionam com este conceito.
Para cada conceito primário, recuperar o conjunto de conceitos secundários, isto é, aqueles conceitos que estão relacionados com cada conceito primário;
Para cada conceito secundário, recuperar o conjunto de artefatos que se relacionam a este conceito.
As atividades relacionadas com a recuperação do relacionamento artefatoconceito-artefato estão representadas por o diagrama de atividades expresso na Figura 4.5.
A análise de viabilidade foi desenvolvida como uma aplicação Web, chamada de ONTrace (Ontological Tracing), e sua interface é apresentada na Figura 4.6.
Depois de verificada a viabilidade da solução, a próxima etapa consistiu na evolução de uma ferramenta de modelagem para suportar nossa proposta.
ArgoUML+ ONTrace corresponde a uma ferramenta de modelagem com apoio à rastreabilidade ontológica.
Conforme apresentado, após a análise de diversas ferramentas para modelagem, optou- se por desenvolver novas funcionalidades sobre o ArgoUML.
A Figura 4.7 apresenta a interface da ferramenta ArgoUML+ ONTrace.
A arquitetura da funcionalidade desenvolvida é apresentada por o diagrama de classes, definido por a Figura 4.8.
Existem três classes de interface:
DialogGenerateOntology: Responsável por a geração da ontologia a partir de um diagrama de classes;
TabOntology: Responsável por apresentar os recursos da ontologia, que podem ser associados aos elementos UML do projeto de software DialogOntrace:
Responsável por a recuperação dos elos de rastreabilidade.
A classe OntologyPersister é responsável por a tradução de um diagrama de classes em UML para um modelo lógico em OWL, realizando a persistência da ontologia.
Esta classe cria uma nova instância da classe OntModel, pertencente à API (Application Programming Interface) do Jena, que manipula as informações da ontologia expressa em A classe Ontrace é responsável por a inferência sobre a ontologia, recuperando os elos de rastreabilidade.
Ela recupera informações de relacionamentos diretos (conjunto primário de artefatos) ou indiretos (conjunto secundário de artefatos), utilizando um modelo de inferência pertencente ao Jena e chamado de InfModel.
Para a geração automática da ontologia, a partir de um diagrama de classes, é realizado o mapeamento apresentado no Quadro 3.2.
A Figura 4.9 representa a interface para geração da ontologia, em o qual o usuário seleciona no menu superior (&quot;Ontology&quot;) a opção &quot;Generate OWL «e escolhe, entre todos os diagramas de classes do projeto, qual representa o Modelo de Domínio.
Esta etapa corresponde à transição da atividade de Projeto para Manutenção da disciplina de Modelagem do Conhecimento.
DialogGenerateOntology e realizado por a classe OntologyPersister, que cria um novo modelo ontológico (OntModel).
O procedimento de geração do modelo consiste em percorrer o diagrama de classes, identificando suas classes, associações e generalizações para geração das primitivas equivalentes em OWL.
Por fim, é realizada a persistência do modelo no projeto em execução.
A Figura 4.10 ilustra o diagrama de colaboração que representa o processo de geração da ontologia.
A ontologia pode ser exportada e importada do ArgoUML+ ONTrace a qualquer momento, em conformidade com a atividade de Manutenção.
Em o menu superior da ferramenta, chamado &quot;Ontology», existe a opção &quot;Export ontology «e &quot;Import OWL ONTrace ontology», conforme ilustração da Figura 4.11.
O objetivo deste procedimento é refinar a ontologia para representar todas as restrições que especificam o domínio.
A ontologia exportada pode ser editada utilizando ferramentas específicas para manipulação de ontologia, como o Protégé.
Posteriormente, é possível realizar a importação da ontologia editada.
Após a geração da ontologia, um painel na parte inferior da ferramenta, apresentado na Figura 4.12, é preenchido com todos os recursos da ontologia, que incluem:
Classes OWL;
Propriedades do tipo DataType;
Propriedades do tipo Object.
Assim, é possível relacionar cada elemento arquitetural com os recursos da ontologia, apenas clicando num checkbox.
O processo para atualização de um indivíduo está expresso no diagrama de colaboração da Figura 4.13 e é realizado por a classe TabOntology.
Esta classe cria um novo indivíduo (elemento UML) e o vincula a uma propriedade que o relaciona aos conceitos definidos na ontologia, utilizando para isso a classe OntModel.
Caso já exista o indivíduo no modelo lógico, o procedimento corresponde à atualização de seus conceitos.
Para se recuperar os elos de rastreabilidade, o usuário pode realizar uma consulta sobre a ontologia, utilizando um motor de inferência.
Esta funcionalidade recupera os elementos relacionados por o mesmo conceito (relacionamento direto) e por conceitos associados (relacionamento indireto).
A Figura 4.14 apresenta a interface por a qual é realizada recuperação dos elos de rastreabilidade.
O nível de encadeamento para recuperação dos conceitos relacionados pode ser variado, isto é, o número de relacionamentos conceito-conceito observados para recuperação de artefatos é configurável.
Em nosso estudo, foi trabalhado apenas com o nível dois:
Conceito que se relaciona com outro conceito.
A Figura 4.15 apresenta o diagrama de colaboração que estrutura a recuperação dos elos, realizada por a classe de interface DialogOntrace.
Esta, por sua vez, através da classe de negócios Ontrace, cria um novo modelo de inferência (InfModel) e realiza as consultas para artefatos indexados por o mesmo conceito e por conceitos relacionados.
Os cenários apresentados demonstram o funcionamento da ferramenta, permitindo uma avaliação de sua usabilidade no processo de desenvolvimento de software.
Para exemplificar o uso da ferramenta associada à modelagem do conhecimento, iremos utilizar um sistema modelado e desenvolvido por alunos de graduação da faculdade de Ciência da Computação da PUCRS.
O domínio do sistema consiste numa academia desportiva, chamada isGym.
Utilizaremos a mesma modelagem para a avaliação da proposta, presente no próximo capítulo.
Durante a modelagem de negócio, o Processo Unificado sugere o desenvolvimento de um artefato chamado Modelo de Domínio, que representa a modelagem conceitual do universo de discurso.
O modelo de domínio, apresentado na Figura 4.16, é utilizado como entrada para a modelagem do conhecimento.
Após a maturação deste modelo, é realizada a extração automática da ontologia utilizando a interface apresentada na Figura 4.9.
Após esta extração, todos os conceitos relacionados com o domínio são apresentados num painel na parte inferior da ferramenta, conforme a Figura 4.12.
Em conformidade com atividade de Projeto e Manutenção da disciplina proposta, a ontologia pode ser exportada para uma ferramenta de edição de ontologias, como o.
Após a definição dos elos de rastreabilidade entre os elementos do projeto de software, é possível a recuperação destes relacionamentos através da interface apresentada por a Figura 4.14.
Até o presente capítulo, foram sistematicamente apresentadas as etapas envolvidas com a proposta de integração de ontologias no processo de desenvolvimento.
Em os capítulos iniciais, foi realizado um estudo sobre ontologias e aspectos relacionados, identificando suas estruturas, linguagens e propostas para desenvolvimento.
Com base nestas propostas, foi sugerida a integração de ontologias no Processo Unificado, visando aproveitar os esforços de modelagem de negócio e entendimento do domínio, comum a ambos.
Com o desenvolvimento de uma ontologia que representa a modelagem conceitual de um sistema, se torna possível a rastreabilidade dos artefatos envolvidos com o seu desenvolvimento.
Esta estrutura é apresentada no presente capítulo, consistindo numa rastreabilidade apoiada por conceitos.
Utilizando a proposta de indexação por conceitos, sugere- se um aumento da quantidade de relacionamentos entre os artefatos se comparada a requisitos, o que implica numa apuração maior dos elos.
Isto é verificado pois um requisito é composto por um ou mais conceitos do domínio, então a granularidade dos elos envolvidos com os conceitos tende a ser menor se comparada a requisitos.
Em contrapartida, aumentando o número de índices, aumenta- se o trabalho envolvido com a atividade de definir os rastros.
Serão apresentados estudos que avaliem estas dimensões nos capítulos posteriores.
O objetivo deste estudo é realizar uma medição das variáveis que definem a rastreabilidade indexadas por conceitos e por requisitos, verificando os benefícios da presente contribuição.
Adicionalmente, será apresentado um experimento realizado utilizando técnicas de Engenharia de Software Experimental e.
A presente proposta apresenta duas perspectivas para sua avaliação.
A primeira está relacionada com a necessidade de desenvolver um produto de software que comprove a viabilidade da integração de ontologias no Processo Unificado, apresentada no capítulo anterior.
A segunda perspectiva está relacionada com o processo de utilização da proposta e seus benefícios.
Para se avaliar um processo, é necessário que pessoas o utilizem.
Em este contexto, estudos experimentais são determinantes para uma boa avaliação, provendo uma disciplinada, sistemática, quantificada e controlada forma de avaliar as atividades desenvolvidas por humanos.
Existe uma discussão na comunidade de Engenharia de Software sobre sua consideração como engenharia ou ciência.
Esta discussão é devido a o seu caráter multidisciplinar que correlaciona questões técnicas, tais como linguagens de programação, sistemas operacionais, sintaxe e semântica, com questões sociais e psicológicas, característica da engenharia e da produção.
Para avaliação de processo onde o fator humano é considerado, a literatura prove algumas abordagens baseadas numa estratégia experimental.
Em, as seguintes abordagens são definidas para avaliação de processos, produtos e recursos:
Análise das características:
É a mais simples e corresponde a uma abordagem subjetiva, utilizada para atribuir um valor e classificar os atributos de vários métodos, visando decidir qual utilizar.
Esta abordagem corresponde a um estudo em retrospectiva e é útil para estreitar o leque de opções a serem escolhidas, porém não avalia o comportamento em termos de causa e efeito;
Pesquisa de opinião (survey):
É um estudo em retrospectiva que visa documentar as relações e os resultados de certa situação.
Durante a realização da pesquisa, registram- se as informações sobre uma situação, comparando- as com informações semelhantes.
Não ocorre à manipulação de variáveis neste estudo;
Estudo de Caso: Ao contrário de as anteriores, esta abordagem define previamente o que se deseja investigar, identificando os principais fatores que possam afetar o resultado de uma atividade.
Após sua execução, é realizada a documentação de suas entradas, restrições, recursos e saídas.
Esta abordagem é utilizada principalmente para observar projetos ou atividades, sem muito controle sobre o objeto de estudo;
Experimento: Representam o tipo de estudo mais controlado, geralmente realizado em laboratórios.
Em esta abordagem, os valores das variáveis independentes (entradas do processo de experimentação) são manipulados para se observar as mudanças nos valores das variáveis dependentes (saídas do processo de experimentação).
A o término da execução do experimento, os resultados são analisados, interpretados, apresentados e, por fim, empacotados.
Em, é observado que as diferenças entre os métodos de pesquisa são refletidas em suas escalas.
Por sua natureza, como os experimentos requerem bastante controle, eles tendem a ser pequenos, envolvendo um reduzido número de pessoas ou eventos.
Pode- se pensar em experimentos como &quot;pesquisas num ambiente restrito».
Os estudos de caso geralmente abordam um projeto típico em vez de tentar obter informações sobre todos os possíveis casos;
Eles podem ser considerados como &quot;pesquisas num ambiente típico».
O objetivo de nosso trabalho consiste em investigar métodos alternativos para rastreabilidade, identificando relações como &quot;melhor do que «ou &quot;mais preciso que».
É possível, assim, isolar as variáveis que determinam esta relatividade do resto do processo e manipular- las, avaliando os resultados a partir de os tipos de combinações possíveis.
Para isso, torna- se necessário um controle sobre as variáveis independentes do experimento.
Frente a as observações aqui apresentadas, optou- se por a utilização de um experimento para avaliação de nossa proposta.
Devido a o experimento ser puramente quantitativo, é necessário uma abordagem adicional para a avaliação qualitativa.
Para este fim, será utilizada a pesquisa de opinião integrada ao experimento.
O processo de experimentação requer um preparo para conduzir e analisar corretamente o objeto de estudo.
Este esforço representa seu maior benefício:
A capacidade de controlar as variáveis relacionadas às entradas do exercício, permitindo a geração de conclusões significativas para o experimento.
Em a presente avaliação, faz- se necessário o controle dos indivíduos que estarão aplicando a proposta de rastreabilidade, utilizando tanto o método indexado por conceitos quanto por requisitos.
Para conduzir o experimento, será utilizado como guia as propostas de e, de maneira complementar.
A avaliação do experimento será apoiada por e.
O processo de experimentação adotado compreende os seguintes passos:
Definição: Corresponde à definição clara das hipóteses e dos objetivos a partir de o problema a ser resolvido.
É proposto um framework para suas constituintes, que compreende:
Objeto de estudo, propósito, foco na qualidade, perspectiva e contexto;
Planejamento: Corresponde a fundamentação do experimento, onde seu contexto é explicitado em detalhes.
Este passo compreende a formalização da hipótese nula (hipótese fundamental em a qual o experimento objetiva rejeitar em favor de as demais) e das alternativas (demais hipóteses que o experimento visa apoiar), determinação das variáveis independentes e dependentes, seleção dos participantes, preparação conceitual da experimentação e a consideração sobre a validade do experimento;
Execução: Este passo compreende a preparação, execução e validação dos dados.
É durante esta etapa que ocorre a interação humana, sendo necessário preparar os participantes sob o ponto de vista moral e metodológico, evitando assim resultados errôneos ou desinteressados.
Análise e Interpretação:
Com a entrada de dados no passo anterior, é possível a análise e interpretação do experimento.
Para tanto, ocorre à compreensão dos dados e a verificação das hipóteses utilizando estatística descritiva, possibilitando assim conclusões sobre a validade do experimento;
Empacotamento: Este passo compreende a documentação dos resultados e a estruturação do experimento, visando possibilitar sua replicação.
É importante esclarecer que um experimento nunca irá proporcionar uma resposta final para uma questão, porém uma resposta específica para uma determinada configuração.
O empacotamento é importante para que o experimento seja replicado em circunstâncias diversas, provendo um conhecimento adicional sobre os conceitos estudados.
Em as próximas seções, serão detalhados os passos para condução do experimento.
A fase de definição corresponde à fundamentação dos objetivos do experimento e a definição de seu escopo, identificando os objetos e os grupos de estudo envolvidos.
Será utilizada à abordagem de chamada Goal Question Metric (GQM), que corresponde a uma medição para melhoria de processo de software dirigida por objetivos.
Esta abordagem parte da definição dos objetivos (nível conceitual) para o estabelecimento de questões (nível operacional), que tentam caracterizar o processo em termos de métricas (nível quantitativo).
Para que o processo de experimentação seja bem sucedido, é necessário um planejamento de todas as atividades envolvidas.
A fase de planejamento pode ser dividida em sete passos:
Seleção do contexto:
Com base em sua definição, este passo seleciona o ambiente em o qual o experimento será executado;
Formulação das hipóteses:
Um experimento é normalmente formulado através de hipóteses, que representam a base para a análise estatística.
Seleção das variáveis:
Este passo compreende a definição das variáveis independentes e dependentes do experimento, isto é, as entradas e saídas do processo que será observado;
Seleção dos indivíduos:
Esta atividade se relacionada com a generalização dos resultados do experimento, com o objetivo de definir um conjunto representativo de indivíduos;
Projeto: Determina a forma em a qual o experimento será conduzido, incluindo seus objetos e seus participantes.
A escolha do projeto correto é crucial para a validade das conclusões;
Instrumentação: Representa a implementação prática, fornecendo os meios de como conduzir e monitorar o experimento;
Análise da Validade:
Realiza a avaliação dos resultados do experimento.
Esta análise inclui a validade interna e externa, além de a validade de sua construção e de sua conclusão.
O contexto é composto por as condições em a qual o experimento será executado.
A seleção adotada contempla as seguintes dimensões:
Processo: In-vitro ou In vivo:
O primeiro corresponde à experimentação controlada num laboratório e o segundo num projeto real;
Participantes: Alunos ou Profissionais:
Define os indivíduos que farão parte do experimento;
Realidade: O Problema desenvolvido em sala de aula ou Problema real:
Define o tamanho do problema que será estudado;
Generalidade: O Específico ou Geral:
Apresenta o escopo da validade do experimento, em âmbito específico e contextualizado ou em todo o domínio da Engenharia de Software;
A formulação das hipóteses corresponde à definição formal sobre o que se pretende com o experimento.
Conforme já apresentado, a hipótese fundamental se chama Hipótese Nula e representa a não ocorrência da relação de causa e de efeito do experimento, ou seja, a não derivação de seus objetivos.
Portanto, o objetivo do experimento é rejeitar- la em prol de uma ou mais hipóteses alternativas.
A escolha das variáveis para o experimento não é uma tarefa trivial e geralmente requer certo conhecimento sobre o domínio do problema.
É necessário que as variáveis independentes (entrada da experimentação) sejam controladas e que exerçam alguma influência sobre as variáveis dependentes (saída da experimentação).
Um experimento compreende observações sobre a alteração de uma ou mais variáveis independentes, também chamadas de fatores.
Durante o estudo, é definido um fator e as demais variáveis independentes são fixadas.
Isso é necessário para saber qual fator é responsável por o fenômeno observado, também chamado de tratamento.
Os tratamentos são aplicados para a combinação de indivíduos e objetos.
Para exemplificar em termos práticos, pode- se considerar um objeto como o conjunto de artefatos recuperados por a rastreabilidade indexada por requisitos ou por conceitos.
Os indivíduos podem ser representados por os participantes que definem os elos de rastreabilidade e a aquisição do conjunto de artefatos rastreados.
Ambos, indivíduos e objetos, são variáveis independentes do experimento.
Um experimento é estruturado através de testes, onde a combinação de tratamentos, indivíduos e objetos são avaliados.
A seleção dos indivíduos é particularmente importante para a geração de resultados relevantes durante o experimento.
Para tanto, é necessário escolher uma população representativa.
Para se obter conclusões significativas num experimento, é necessário recuperar cuidadosamente os dados e aplicar métodos de análise estatística.
O projeto do experimento corresponde à forma em a qual todas as atividades serão planejadas e conduzidas para obtenção destas conclusões.
O experimento consiste numa série de testes sobre os tratamentos de variáveis independentes.
A atenção nesta fase de projeto consiste em identificar o número de vezes que os testes serão executados para que se torne visível os efeitos dos tratamentos sobre as variáveis.
A literatura provê alguns princípios genéricos para o projeto do experimento:
Aleatoriedade: Este princípio estabelece uma ordem aleatória para a alocação de indivíduos e objetos;
Obstrução: Este princípio é estabelecido por a premissa de que algumas vezes um fator de probabilidade possa exercer algum efeito indesejável sobre o resultado do experimento.
Caso o fator do efeito seja visível, é possível utilizar uma técnica que o bloqueie, aumentando assim a precisão dos resultados;
Balanceamento: Este princípio estabelece que cada tratamento sobre as variáveis possua o mesmo número de indivíduos.
Em a maioria dos experimentos, são formuladas hipóteses e é definido um método para analisar- las estatisticamente.
Existem duas abordagens para sua execução, que são:
Projeto completamente aleatório:
Consiste em avaliar cada instância do fator aleatoriamente entre os dois tratamentos, isto é, cada instância será aplicada em apenas um dos tratamentos, definido aleatoriamente.
Sugerese que exista um balanceamento na distribuição dos tratamentos entre os fatores;
Projeto de comparação pareado:
Consiste em avaliar todas as instâncias do fator com os dois tratamentos.
O objetivo é aumentar a precisão do experimento através do pareamento do objeto experimentado.
Esta abordagem demanda um cuidado extra sobre o efeito da ordem do experimento.
Sugere- se a utilização de escolha aleatória e balanceada para a execução do fator sobre os tratamentos.
Durante o projeto, define- se a tabela de contingência que representam a distribuição do fator sobre os tratamentos, definindo se o projeto será aleatório ou pareado.
Conforme o projeto escolhido, existem testes específicos para a avaliação das hipóteses.
O objetivo da instrumentação é proporcionar os meios para condução do experimento e sua análise.
Sugerem- se as seguintes definições de instrumentos:
Objetos: Os objetos podem ser, por exemplo, documentos de especificação ou código fonte;
Guias: São especialmente úteis para apoiar os participantes no experimento e incluem, por exemplo, descrição de processos, tutoriais e checklists;
Métricas: São obtidas no experimento através da coleta de dados, normalmente através de entrevistas ou formulários preenchidos por os participantes.
Um ponto crítico durante o experimento é a análise de sua validade.
Sugere- se que esta preocupação ocorra desde o seu planejamento, prevendo algumas questões sobre a avaliação do experimento.
A literatura sugere quatro tipos de validação dos resultados.
Validade interna:
Está validade define se o relacionamento observado entre o tratamento e o resultado é casual e não resultado de algum fator não previsto.
A atenção principal é dada aos participantes durante a condução do experimento;
Validade externa:
Esta validade sugere a generalização dos resultados obtidos durante o experimento em práticas industriais.
É avaliada a representatividade dos participantes com relação a o público alvo;
Validade de construção:
A validade de construção avalia a relação de causa e efeito em a qual o experimento é idealizado.
A atenção desta validade se concentra em mapear a teoria, que motiva o experimento, nos indivíduos.
A o término, são observados os efeitos da experimentação;
Validade da conclusão:
Esta validade corresponde à capacidade de chegar a uma conclusão correta a respeito de os tratamentos e dos resultados do experimento.
Para tanto, é necessário escolher os testes estatísticos, os participantes e a confiabilidade das medidas e da implementação dos tratamentos.
A execução compreende a etapa operacional da experimentação, onde ocorre o envolvimento direto dos participantes.
Ainda que o experimento seja perfeitamente planejado e os dados coletados sejam analisados com os métodos mais apropriados, o resultado será inválido se os indivíduos não se engajarem de maneira séria com o experimento.
A execução do experimento compreende três passos:
Preparação: Corresponde a escolha dos participantes e dos materiais preparados para a experimentação;
Execução: É quando os participantes executam as tarefas do experimento, de acordo com os diferentes tratamentos previstos;
Validação dos dados:
Corresponde a validação dos dados coletados após a execução do experimento.
Existem alguns preparativos que devem ser cautelosamente analisados antes da execução do experimento.
Dois pontos são avaliados nesta etapa:
Prover a informação aos participantes e preparar os materiais necessários ao experimento, tal como formulários e ferramentas.
A execução de um experimento pode se dar de diferentes formas.
Sua duração é variável e pode ocorrer num período de tempo curto, em o qual o responsável está presente em todos os detalhes da execução.
Outra perspectiva é quando o tempo é longo, tornando inviável o responsável participar de cada detalhe da execução do experimento.
Após a coleta de dados, é necessário verificar se os dados são razoáveis e se foram coletados corretamente.
Isso lida com aspectos específicos, como o entendimento dos participantes sobre os formulários e seu correto preenchimento, com a seriedade em que os participantes conduziram o experimento, com a remoção de dados a partir de a análise, etc..
É importante revisar se o experimento foi conduzido conforme o planejado e, para cada erro percebido, os dados devem ser considerados inválidos.
Após a coleta de dados experimentais gerados na fase anterior, é necessário extrair conclusões.
Para se recuperar conclusões válidas, é necessário interpretar os dados experimentais.
A primeira observação sobre os dados brutos obtidos no experimento diz respeito à medida de suas escalas.
As escalas determinam quais operações que podem ser executadas sobre os valores das variáveis.
A literatura define os seguintes tipos de escalas:
Nominal: Representam diferentes valores que não possuem interpretação numérica nem ordenação;
Ordinal: Representam diferentes valores que podem ser ordenados, porém não possuem uma representação numérica;
Intervalar: Representam diferentes valores que podem ser ordenados e a distância entre os números possui a mesma interpretação;
Razão: Representam diferentes valores que podem ser ordenados e a distância e razão entre os mesmos pode ser interpretada.
Após a análise das medidas das escalas para as variáveis, é importante avaliar a apresentação e o processamento numérico dos dados obtidos através da estatística descritiva.
Posteriormente, sugere- se a eliminação de distorções que comprometam a validade das conclusões.
Por fim, é realizado o teste das hipóteses para extração das conclusões do experimento.
A estatística descritiva lida com a apresentação e o processamento numérico de um conjunto de dados.
Para este fim, sugere- se representar graficamente estes dados para identificação de alguns aspectos interessantes, como os indicadores de medidas.
O objetivo da estatística descritiva é analisar a distribuição geral de um conjunto de dados.
Esta etapa deve ser executada antes da validação das hipóteses para compreender a natureza dos dados e identificar os dados anormais ou os valores extremos (outliers).
Com relação a o teste das hipóteses, existem duas formas:
Paramétricos: Utilizam formas fechadas, derivadas de propriedades de distribuições de freqüências conhecidas e exigem que os dados possuam normalidade e homocedasticidade;
Não-Paramétricos: Devem ser usados quando os dados não atendem os requisitos de normalidade e de homocedasticidade.
Esta abordagem utiliza rankings de valores observados como parâmetro ao invés de os valores propriamente ditos.
A escolha do teste das hipóteses adequado demanda a análise de dois requisitos:
Normalidade e da homocedasticidade.
Em este contexto, apresentamos:
Normalidade: Os valores tendem a se concentrar próximos de uma média, e quanto maior a distância dessa média, menor a freqüência das observações;
Homocedasticidade: Implica numa variância constante entre o conjunto de dados que serão testados.
Depois de avaliada a normalidade e a homocedasticidade, sugerem- se dois tipos de teste de acordo com os supostos paramétricos, num projeto com um fator e dois tratamentos:
Teste T:
Este teste é utilizado para comparar duas médias a partir de uma hipótese nula.
Esta hipótese pressupõe que não existem diferenças significativas entre dois grupos;
Mann--Whitney: Este teste serve para provar se dois grupos independentes procedem da mesma população.
Após a análise e interpretação, sugere- se o empacotamento do experimento devido a a sua necessidade de replicação.
A o executar o experimento em contextos distintos, possibilita- se a aquisição de novos conhecimentos a respeito de os conceitos estudados.
Para isso, é importante documentar os diversos aspectos relacionados com o experimento, entre eles:
Comunidade: Apresenta os pesquisadores e participantes relacionados com o experimento, além de os interessados que possam aproveitar os resultados obtidos;
Organização: Apresenta o planejamento, projeto e demais informações referentes à preparação, diretrizes, execução e instrumentação do experimento;
Artefatos: Apresenta os artefatos definidos durante a instrumentação do experimento;
Resultados: Incluem a descrição detalhada dos resultados recebidos, com os dados brutos, refinados (por a eliminação dos outliers) e analisados.
Os dados analisados são utilizados para testar as hipóteses e fazer as conclusões sobre o experimento.
O empacotamento do experimento proposto está documentado na Seção 5.2, onde estarão presentes todas as informações necessárias para a sua replicação.
Foi utilizada a abordagem GQM para a definição do estudo, estabelecendo o objetivo global, os objetivos de estudo e de medição.
Por fim, serão apresentadas as questões e suas métricas.
Comparar, no Processo Unificado, a precisão e o esforço da rastreabilidade de artefatos indexada por conceitos da ontologia com relação a tradicional proposta de indexação por requisitos.
Comparar, no Processo Unificado, a rastreabilidade de artefatos indexada por requisitos com a indexada por conceitos, Com o propósito de caracterizar o tempo despendido no uso e os elementos recuperados por cada uma das abordagens, Com foco no esforço e na precisão, Sob o ponto de vista do arquiteto de software, Em o contexto de manutenção de um sistema de informação desenvolvido por estudantes (toy example) no domínio de uma academia desportiva.
Em uma manutenção de um sistema de informação, caracterizar:
Qual o esforço (medido em minutos por cada participante) necessário para indexação dos artefatos utilizando a rastreabilidade apoiada por requisitos e por conceitos; Qual
a precisão definida através da completude e corretude dos artefatos recuperados através da rastreabilidade indexada por requisitos e por conceitos, com relação a os artefatos que realmente se relacionam no sistema.
O esforço para definição dos elos de rastreabilidade indexados por conceitos é igual ao esforço para definição dos elos indexados por requisitos?
A precisão na recuperação de artefatos utilizando a rastreabilidade indexada por requisitos é igual à precisão utilizando a rastreabilidade indexada por conceitos?
A métrica associada à Questão 1 corresponde ao esforço medido por a relação do tempo gasto em minutos por cada participante durante a definição dos elos de rastreabilidade em cada abordagem.
A métrica relacionada à Questão 2 corresponde à precisão dos elos de rastreabilidade de cada abordagem, com relação a a completude e corretude dos artefatos recuperados.
Por precisão, foi definido em nosso estudo como sendo a razão entre o conjunto correto de artefatos recuperados e o conjunto total de artefatos relacionados.
O conjunto correto recuperado por determinada técnica compreende a intersecção entre o conjunto total de artefatos recuperados por esta técnica e o conjunto ideal, que representa o relacionamento real entre os artefatos (gabarito).
O conjunto ideal será definido por um especialista através da inspeção do sistema.
O conjunto total de artefatos relacionados é a união entre o conjunto de artefatos recuperados com o conjunto ideal.
O cálculo da precisão se dá por:
Onde: R:
Conjunto de artefatos recuperados utilizando determinada técnica;
I: Conjunto ideal de artefatos relacionados (gabarito);
Para a condução do experimento de rastreabilidade, foi escolhido o contexto de uma universidade.
Embora diversos autores argumentem sobre a necessidade de conduzir experimentos em ambientes realistas, semelhantes aos encontrados na indústria, essa abordagem demanda riscos e custos não previstos no escopo desta dissertação de mestrado.
Dentro de as dimensões apresentadas, caracterizam- se:
Processo: Será utilizada à abordagem In-vitro, em a qual o conjunto de participantes executará o experimento num ambiente controlado.
Este experimento não se dará durante o desenvolvimento de software industrial, isto é, ele será off-line;
Participantes: O experimento será conduzido por alunos de graduação e pós-graduação da Faculdade de Informática da PUCRS;
Realidade: O problema estudado será de sala de aula (toy example) e corresponde a um sistema modelado e desenvolvido por alunos da graduação, durante uma disciplina da Faculdade de Informática da PUCRS, no domínio de uma academia desportiva.
O objetivo desta escolha é a utilização de um sistema que se aproxime do real e que foi desenvolvido sem a intervenção do pesquisador;
Generalidade: O experimento é específico e com validade apenas no escopo do presente estudo.
Em o presente experimento, duas hipóteses foram definidas informalmente:
Conforme apresentado na Seção 4.1.1.5, a rastreabilidade impõe o chamado Princípio de Circularidade.
Para a aquisição dos elos de rastreabilidade, é necessário um esforço para definir- los.
Sugere- se que o esforço gasto com a definição dos elos utilizando requisitos seja igual à definição dos elos utilizando conceitos da ontologia.
Esta hipótese mapeia a Questão 1, definida na Seção 5.2.1.4;
Sugere- se que a rastreabilidade indexada por requisitos recupera o mesmo conjunto de artefatos que a indexada por conceitos de uma ontologia, com relação a o conjunto ideal de artefatos relacionados.
Esta hipótese mapeia a Questão 2, definida na Seção 5.2.1.4.
Com base na definição informal, viabiliza- se a formalização das hipóteses e a definição de suas medidas para avaliação.
Hipótese Nula, H0:
O esforço envolvido com a definição dos elos de rastreabilidade utilizando requisitos é igual ao esforço envolvido utilizando conceitos da ontologia.
Medidas: O esforço será avaliado por o tempo gasto em minutos com a definição dos elos de rastreabilidade em cada abordagem, isto é, a diferença entre o tempo final e o tempo inicial de cada abordagem, onde:
Treq: Representa a variação de tempo gasto em minutos para indexação utilizando requisitos;
Tconc: Representa a variação de tempo gasto em minutos para indexação utilizando conceitos;
H0: Treq $= tconc Hipótese Alternativa, H1:
O esforço envolvido com a definição dos elos de rastreabilidade utilizando conceitos é maior do que o esforço envolvido utilizando requisitos da ontologia.
H1: Tconc\&gt; treq Hipótese Alternativa, H2:
O esforço envolvido com a definição dos elos de rastreabilidade utilizando requisitos é maior do que o esforço envolvido utilizando conceitos da ontologia.
H2: Treq\&gt; tconc Hipótese Nula, H0:
A precisão na aquisição dos elos de rastreabilidade indexados por requisitos é igual a dos elos indexados por conceitos.
Medidas: Conforme apresentado na Seção 5.2.1.5, a precisão será avaliada por a relação entre o conjunto correto de artefatos recuperados e o conjunto total, onde:
Preq: Precisão associada à rastreabilidade indexada por requisitos;
Pconc: Precisão associada à rastreabilidade indexada por conceitos;
H0: Preq $= Pconc Hipótese Alternativa, H1:
A precisão na aquisição dos elos de rastreabilidade indexados por requisitos é maior do que os elos indexados por conceitos.
H1: Preq\&gt; Pconc Hipótese Alternativa, H2:
A precisão na aquisição dos elos de rastreabilidade indexados por conceitos é maior do que os elos indexados por requisitos.
H2: Pconc\&gt; Preq Assumiram-se como variáveis independentes:
Experiência do time de manutenção;
Técnica para definição dos elos de rastreabilidade;
Assumiram- se como variáveis dependentes:
Esforço para a definição dos elos de rastreabilidade;
Precisão através do número de artefatos recuperados utilizando determinada técnica com relação a o conjunto total de artefatos.
Conforme já apresentado, a população definida para o experimento é formada por alunos do curso de graduação e pós-graduação da Faculdade de Informática da PUCRS.
Será um total de doze alunos, sendo:
Seis alunos da graduação;
Seis alunos da pós-graduação.
Não será utilizada uma amostragem probabilística para seleção dos indivíduos, mas uma amostragem não probabilística:
Amostragem por conveniência:
Serão escolhidas as pessoas mais convenientes para o experimento;
Amostragem por quota:
Esta abordagem implica na escolha de indivíduos de diferentes populações, no caso, graduação e pós-graduação.
Pressupõe- se que a experiência com a modelagem de sistemas e com o processo de desenvolvimento entre estas duas populações seja diferente.
De entre os princípios genéricos para o projeto do experimento, caracterizamos:
Aleatoriedade: A aleatoriedade será utilizada para definir quais participantes irão executar cada abordagem de rastreabilidade (requisito ou conceito);
Obstrução: Durante a experimentação, muitos dos participantes não possuem o mesmo nível de experiência acadêmica e profissional.
Para minimizar o efeito da experiência sobre o experimento, os indivíduos foram selecionados utilizando o critério de quota e conveniência;
Balanceamento: Este princípio será utilizado em nosso experimento para que cada proposta de rastreabilidade seja executada por a mesma quantidade de participantes.
Para cada hipótese, serão utilizadas as seguintes notações:
µreq Rastreabilidade indexada por requisitos;
Rastreabilidade indexada por conceitos.
O tipo de projeto apresentado procura investigar se µconc possui o mesmo esforço e precisão que µreq.
Para este fim, será utilizada uma abordagem chamada um fator com dois tratamentos.
O fator, neste experimento, consiste na técnica que será utilizada e os tratamentos consistem na rastreabilidade indexada por conceitos e por requisitos.
Com relação a as abordagens apresentadas no referencial teórico, é possível escolher tanto o projeto pareado quanto o aleatório, porém a complexidade associada ao primeiro é maior do que o segundo.
Caso se opte por um projeto pareado no contexto deste experimento, é interessante considerar um novo tratamento que represente a experiência dos participantes na execução dos demais tratamentos.
Adicionalmente, o ganho com relação a o grau de liberdade entre as duas abordagens não apresenta significante diferença.
Por motivos de projeto e complexidade, não utilizaremos o projeto pareado descrito, mas sim o projeto completamente aleatório, onde cada participante executará apenas uma abordagem definida aleatoriamente.
A Tabela 5.1 é chamada de tabela de contingência e representa a distribuição do fator sobre os dois tratamentos.
A Tabela 5.1 representa a forma em a qual o experimento será executado.
Percebe- se que a ordem foi definida de forma aleatória e balanceada entre os fatores.
Para a realização dos testes das hipóteses, num contexto de um fator e dois tratamentos aleatórios, a literatura sugere o teste de significância chamado Teste T para duas amostras independentes, caso seja realizado um teste paramétrico, ou Mann--Whitney, caso o teste seja não-paramétrico.
A definição do teste a ser aplicado ocorrerá após a análise da normalidade (através do teste de Shapiro-Wilk) e variância dos dados obtidos por a execução do experimento (Teste de Levene).
Em o presente experimento, será utilizado:
Objetos: A modelagem UML de um diagrama de classes de projeto de um sistema de informação em o qual deverão ser definidos os elos de rastreabilidade, a descrição dos casos de uso e o Modelo de Domínio.
Para o estabelecimento dos elos de rastreabilidade, será fornecido o apoio ferramental para cada abordagem:
Guias: Será fornecido um treinamento para os participantes, apresentando as duas abordagens de rastreabilidade, o contexto do experimento e a motivação da equipe.
Também será fornecido um documento sobre como proceder durante o experimento;
Métricas: Os dados serão recuperados através de formulários preenchido por os participantes, com base na ferramenta ArgoUML e na matriz definida no MS Excel.
Serão avaliados alguns critérios, tais como:
Histórico: A data de aplicação do experimento será criteriosamente definida, evitando períodos em os quais os participantes possam sofrer influências externas;
Maturação: Durante o treinamento, serão utilizadas técnicas de motivação para incentivar positivamente os participantes;
Seleção dos grupos:
Será utilizada uma abordagem para nivelar o conhecimento dos participantes através de um treinamento sobre as técnicas.
A execução das atividades será individual;
Difusão: Durante o treinamento, será desenvolvida uma motivação que não incentive interação entre os participantes.
Adicionalmente, haverá um policiamento durante a experimentação para evitar este tipo de interação;
Para esta avaliação, será adotada a interação da seleção, ou seja, os participantes que foram selecionados possuem um perfil apto aos tratamentos do experimento, apresentando, em sua maioria, conhecimento prévio sobre processo de desenvolvimento de software e modelagem de sistemas, além de experiência em indústria.
Durante nosso experimento, serão avaliados:
Inadequada explicação pré-operacional:
Adivinhação de hipóteses:
Devido a o fato dos participantes serem humanos, é possível sua interação com o experimento, sugerindo novas hipóteses e exercitando a criatividade.
É importante manter o foco no estudo planejado;
Expectativas do condutor do experimento:
A o se conduzir um experimento, o responsável pode exercer influências sobre as variáveis envolvidas e sobre o material elaborado.
Durante a presente proposta, todo o material utilizado será previamente avaliado por outro responsável.
Serão avaliadas as seguintes perspectivas:
Manipulação dos dados:
Como os dados resultantes do experimento serão manipulados por o pesquisador, é possível que os mesmos sofram algumas variações, tal como o coeficiente de significância para validação dos resultados;
Confiabilidade das medidas:
Esta perspectiva sugere que medidas subjetivas possam ser influenciadas por o pesquisador.
Em nossa proposta, as medidas foram objetivamente definidas, não dependendo do critério humano;
Confiabilidade na implementação dos tratamentos:
Consiste no risco em que diferentes participantes possam implementar de forma distinta os processos estabelecidos por o experimento.
Este risco não será evitado em nosso estudo, visto que não se pode interferir no caráter subjetivo de indexação dos artefatos.
Possivelmente, diferentes participantes definirão elos de rastreabilidade distintos;
Configurações do ambiente do experimento:
Consiste nas interferências externas do ambiente que podem influenciar os resultados durante a execução do experimento.
O experimento será executado num laboratório isolado, onde será proibida a interação externa como celulares, saídas, etc.;
Heterogeneidade aleatória dos participantes:
A escolha de diferentes participantes com diferentes experiências pode exercer um risco na variação dos resultados.
Para preparar a execução do experimento, atentou- se para:
Consenso com o experimento:
De acordo com, se os participantes não concordam com os objetivos da pesquisa ou não tem conhecimento sobre o experimento, corre- se o risco de que sua participação não ocorra em encontro aos objetivos.
Durante a experimentação, a preparação dos participantes deverá fornecer o embasamento necessário sobre o experimento, clarificando quais os objetivos e metas almejadas;
Resultados sensitivos:
É possível que o resultado obtido por o experimento se influencie por questões pessoais, como a sensibilidade dos participantes por estarem sendo avaliados.
Será adotada uma postura de anonimato dos participantes em toda a descrição da experimentação.
Com relação a a instrumentação, todas as variáveis e os recursos foram criteriosamente estabelecidos antes da execução do experimento.
Foi apresentado um treinamento específico para cada grupo (rastreabilidade indexada por conceitos e por requisitos), contextualizando os objetivos, a técnica, a motivação e o procedimento técnico para condução do experimento.
O treinamento de ambos os grupos foi compilado no Apêndice A. Adicionalmente, para apoiar os participantes em suas tarefas foi fornecido um tutorial sobre como executar as atividades para a rastreabilidade indexada por conceitos (Apêndice B) e por requisitos (Apêndice C).
Os próprios participantes foram responsáveis por a coleta dos dados, utilizando um formulário para preenchimento dos resultados, conforme Apêndice D. Outro critério a ser considerado é a questão do anonimato, onde os nomes dos participantes não serão registrados.
A presente proposta estrutura o experimento num curto período de tempo, em a qual o pesquisador estará envolvido em todos os detalhes da execução.
Durante a execução, será definida a coleta dos dados e o ambiente em o qual ocorrerá o experimento.
A coleta de dados será de responsabilidade dos participantes, através do preenchimento de formulários.
Esta opção é justificada, pois o pesquisador não poderá se envolver na definição dos dados resultados do experimento.
Durante a execução do experimento, o responsável estará à disposição dos participantes para o esclarecimento das dúvidas que surgirem ao longo de o processo.
A primeira análise apresentada diz respeito à classificação das escalas das variáveis definidas no experimento, apresentada no Quadro 5.1.
Com esta classificação, é possível determinar as operações que podem ser aplicadas sobre as variáveis.
Quadro 5.1 ­ Escalas das variáveis Variáveis Dependentes Independentes Nome Tempo Precisão Técnica de rastreabilidade Escala Razão Razão Nominal O experimento obteve como resultado os dados apresentados na Tabela 5.2.
A Figura 5.3 representa o gráfico de barras com a precisão dos artefatos recuperados por os participantes.
Conforme apresentado, as variáveis dependentes estão caracterizadas na escala razão, o que permite o calculo da normalidade e homocedasticidade, necessária para definir o tipo de teste das hipóteses (paramétrico ou não-paramétrico).
Conforme definido no projeto do experimento, o padrão para tipo de teste previsto é o Teste T para duas amostras independentes, caso o teste empregado seja paramétrico, ou Mann--Whitney, caso seja não paramétrico.
Nossa avaliação será executada para as hipóteses:
Esforço e precisão.
Para cada hipótese, os dados serão caracterizados, visualizando tendências centrais e dispersões.
Posteriormente, sugere- se a eliminação de dados anormais ou incertos, que distorcem a integridade da conclusão, através da redução do intervalo de dados.
Por último, será realizado o teste das hipóteses que compreende a avaliação estatística dos dados até certo nível de significância.
O nível de significância adotado (p- value) para todos os testes é de 5%.
O pvalue compreende o menor nível de significância com que se pode rejeitar a hipótese nula.
Uma análise inicial da distribuição é eficiente para avaliar o comportamento das amostras.
Utilizaremos o gráfico de dispersão boxplot, apresentado na Figura 5.4, para identificação dos outliers.
Conforme apresentado na Figura 5.4, a variável esforço possui outliers moderados, com exceção do participante R05.
Um possível motivo para a ocorrência do outlier R05 é o fator de experiência sobre o processo de desenvolvimento e modelagem de sistemas.
Por decisão de projeto, o valor deste participante será eliminado da amostra visando evitar distorções.
Outra observação sobre o gráfico de dispersão é a pequena variabilidade entre as duas amostras.
A próxima etapa consiste em identificar se os dados seguem uma distribuição normal.
Para se avaliar a normalidade, é definida uma hipótese nula e uma hipótese alternativa, conforme:
H0: A distribuição é normal;
H1: A distribuição não é normal.
Existem duas formas para se avaliar a distribuição normal dos dados, que compreendem o Teste de Kolmogorov--Smirnov e o Teste de Shapiro-Wilk.
O primeiro é utilizado para identificar a normalidade em variáveis com pelo menos 30 valores e o segundo em variáveis com menos de 50 valores.
A Tabela 5.3 apresenta os testes de normalidades para a amostra utilizando o Teste de Shapiro-Wilk.
Com base na Tabela 5.3, observa- se que a significância dos dados do teste de Shapiro-Wilk é superior, em ambas as amostras (conceito e requisito), ao nível de significância definido.
Com esta informação, não há indícios para rejeitar a hipótese nula sobre a distribuição da normalidade, conseguindo assim o primeiro requisito para utilização de teste paramétrico para duas amostras independentes.
O segundo requisito requer a análise da homocedasticidade, tornando necessário analisar a variância das duas amostras.
Com este objetivo, definem- se duas hipóteses:
H0: As variâncias são iguais;
H1: As variâncias não são iguais.
O teste da hipótese acima é realizado com a significância obtida diretamente através do Teste de Levene.
O Teste de Levene é usado para testar se k amostras têm a mesma variância.
A Tabela 5.4 apresenta os resultados obtidos para este teste.
Com base na Tabela 5.4, verifica- se que o nível de significância para variâncias iguais é superior ao nível de significância definido.
Com esta informação, não se consegue rejeitar a hipótese nula para variâncias, conseguindo o segundo requisito para utilização do teste paramétrico.
Conforme definido no planejamento do projeto do experimento, o teste indicado para avaliação das hipóteses é o Teste T para duas amostras independentes.
Consegue- se validar sua utilização por ser um teste paramétrico, em o qual seus requisitos foram explicitamente atendidos.
Com base na declaração das hipóteses, tem- se:
H0: µreq $= µconc H1:
µconc\&gt; µreq H2:
µreq\&gt; µconc O critério para rejeição de H0 em favor de H1 é:
H1: (µconc\&gt; µreq):
Rejeita- se H0 se t0\&gt; t, n+ m-2, onde t0:
É o valor t obtido através da aplicação do Teste T. O Teste T para duas amostras independentes foi aplicado neste contexto e o resultado está apresentado na Tabela 5.5.
Com base na Tabela 5.5, obtemos o valor de t0 e, com base no Anexo D, obtemos o valor de t, n+ m-2 ($= 2,26).
Como t0 t, n+ m-2, então não se consegue rejeitar a hipótese nula a um nível de significância de 5% em favor de H1:
µconc\&gt; µreq.
Com base na Tabela 5.6, obtemos o valor de t0 e o valor de t, n+ m-2 ($= 2,26).
Como t0\&gt; t, n+ m-2, consegue- se rejeitar a hipótese nula a um nível de significância de 5% em favor de H2:
µreq\&gt; µconc.
Por as análises apresentadas, pode- se concluir que existe diferença estatisticamente significativa em relação a o esforço na definição dos elos de rastreabilidade utilizando conceitos e utilizando requisitos.
O esforço necessário para indexação dos requisitos é maior do que dos conceitos.
De a mesma forma que na análise da primeira hipótese, utilizaremos o gráfico de dispersão boxplot para identificação dos outliers, apresentado na Figura 5.5.
Tabela 5.7 ­ Média e desvio padrão para a variável precisão. Abordagem Conceitos Requisitos Média Desvio Padrão Por critério de projeto, estabeleceu- se que os valores extremos que não atingirem a média com mais de dois desvios padrões, serão removidos da amostra.
Em este contexto, apenas o participante C04 foi eliminado do conjunto de dados.
Os demais outliers não foram considerados críticos para a validade das conclusões.
A próxima etapa consiste em identificar se os dados seguem uma distribuição normal.
Definem- se assim as hipóteses:
H0: A distribuição é normal;
H1: A distribuição não é normal.
Com base na Tabela 5.8, observa- se que a significância dos dados do teste de Shapiro-Wilk é inferior, na abordagem por requisitos, ao nível de significância definido.
Sendo assim, há indícios para rejeitar a hipótese nula e, consequentemente, não se pode aplicar um teste paramétrico para avaliação das hipóteses.
Optou- se por aplicar o teste Mann--Whitney, para duas amostras independentes, por se tratar de uma alternativa nãoparamétrica para o Teste T. O teste de Mann--Whitney para duas amostras independentes é utilizado para comprovar se as diferenças entre as médias observadas nos dois grupos independentes são estatisticamente significativas.
Com base na declaração das hipóteses, sugere- se:
H0: Não há diferença entre as médias (µreq $= µconc) H1:
Há diferença entre as médias (µreq µconc) O resultado do teste Mann--Whitney foi aplicado sobre as amostras e está apresentado na Tabela 5.9.
Como o grau de significação associado (Sig.
Assimpt.) é 0,003 e é menor que a significância assumida de 0,005, deve- se rejeitar H0.
Frente a os resultados apresentados para a variável precisão, existe diferença de média entre a rastreabilidade apoiada por requisitos e por conceitos.
Por a análise estatística dos dados, consegue- se recuperar duas informações:
A distribuição da precisão não é normal, o que implica na execução de testes não paramétricos;
Utilizando o teste Mann--Whitney, conseguiu- se verificar que existem diferenças entre as médias das duas amostras µreq e µconc.
Utilizando o teste de Mann--Whitney, conseguiu- se apenas rejeitar a hipótese nula, porém não foi possível avaliar as hipóteses alternativas, pois não é possível extrair relações de &quot;maior do que «com o teste aplicado.
Porém, sugere- se comparar a análise descritiva das médias da amostra conforme a Tabela 5.10.
Comparando as médias apresentadas, e com base nas médias das duas abordagens, observa- se que a precisão na aquisição dos elos de rastreabilidade por conceitos é maior do que por requisitos.
Conforme verificado no referencial teórico deste capítulo, um experimento é responsável apenas por uma avaliação quantitativa.
Para a análise qualitativa das duas abordagens de rastreabilidade, foi desenvolvida uma pesquisa de opinião integrada ao experimento.
A o término da execução, cada participante respondeu um questionário conforme Apêndice E. Como critério de resposta, foi utilizado a escala Likert de 5 pontos para o grau de satisfação.
Os objetivos almejados com a pesquisa foram apresentar a opinião dos participantes quanto a a usabilidade, utilidade e esforço necessários em cada abordagem.
Em uma primeira análise, explicitamos a média aritmética das questões em cada uma das abordagens, apresentada na Tabela 5.12.
É possível observar que a média para todas as questões numa abordagem por conceitos é maior do que por requisitos.
Por termos utilizado uma escala de Likert variando de 1 a 5, com grau de satisfação progressiva, verificou- se que a avaliação qualitativa da proposta de rastreabilidade ontológica foi superior, em termos gerais, a rastreabilidade por requisitos.
Este capítulo apresentou uma avaliação quantitativa e qualitativa da proposta de rastreabilidade ontológica, utilizando um estudo experimental e uma pesquisa de opinião.
O objetivo foi verificar a aplicabilidade e a relevância da proposta quando comparada a tradicional forma de indexação de artefatos por requisitos.
É importante clarificar que os resultados obtidos através da experimentação não são generalizáveis para todo o processo de desenvolvimento de software.
O contexto escolhido para o experimento é relativo à rastreabilidade de classes de projeto indexadas por requisitos e por conceitos da ontologia, durante a manutenção do sistema no domínio de uma academia desportiva.
Durante a indexação por requisitos, o esforço para definição dos elos de rastreabilidade correspondeu percorrer a descrição dos casos de uso e identificar as classes de projeto associadas o cada caso de uso.
Durante a definição dos elos a partir de conceitos, o esforço compreendeu a observação da modelagem conceitual do sistema, através do Modelo de Domínio e da ontologia, relacionando cada classe ao seu respectivo conceito.
Os dados relativos ao esforço obtiveram uma distribuição normal com uma diferença estatisticamente insignificante entre suas variâncias (homocedasticidade).
Diante de esta circunstância, foi executado o Teste T (paramétrico) e se verificou a validade da hipótese alternativa que estabelece que o esforço relativo à indexação das classes de projeto por os conceitos do domínio é menor do que a indexação por a especificação dos casos de uso.
A precisão apresentou um fenômeno distinto do esforço, onde a amostra não apresentou uma distribuição normal, impossibilitando a utilização do Teste T. O teste MannWhitney foi à escolha definida para avaliação das hipóteses.
Este teste apenas informa se dois grupos independentes procedem da mesma população.
O resultado foi que existem diferenças entre as médias das duas amostras de requisitos e conceitos.
Em este contexto, não foi possível avaliar estatisticamente as hipóteses alternativas e se optou por comparar a análise descritiva das médias.
Após comparar as médias, verificou- se que a precisão na recuperação da indexação por conceitos é maior que por requisitos.
Durante a análise da precisão, os resultados indicaram um fenômeno bastante positivo para a indexação por conceitos em comparação com a indexação por requisitos.
A razão deste fenômeno pode ser que, por a redução da granularidade dos elementos que indexam os itens de projeto, de requisitos para conceitos, obtiveram- se elos mais apurados.
Este fenômeno é explicado porque um requisito pode englobar mais de uma classe, por exemplo.
A o se recuperar as classes indexadas por requisitos, corre- se o risco de recuperar outras classes que não se relacionam diretamente com a consultada, isto é, falsos positivos e falsos negativos.
É possível também que o resultado seja reflexo de um planejamento e treinamento não balanceados ou inadequados de ambas as propostas de rastreabilidade, gerando como conseqüência o efeito chamado Experiência de Hawthorne.
Este efeito é observado numa experimentação como conseqüência da percepção dos participantes sobre a abordagem e não por a abordagem em si.
É possível que os participantes induzissem que a abordagem por conceitos seja mais eficiente que por requisitos e distorcessem a realidade.
Para aumentar o conhecimento sobre o esforço e precisão em diferentes contextos, definindo a validade da experimentação, sugere- se replicações do experimento em modelos distintos e mais realistas, indexando diferentes estruturas que não apenas as classes de projeto.
Sugere- se avaliar, por exemplo, diagramas de atividades, seqüência, componente, implantação, etc..
Além disso, é interessante sua replicação em elementos rastreáveis com uma granularidade mais específica, relacionando, por exemplo, atributos, métodos, associações, interações, objetos, etc..
Generalizando o experimento, possibilita- se a extração de novas informações sobre a proposta em diferentes perspectivas do processo de desenvolvimento.
Este trabalho apresentou uma proposta para rastreabilidade ontológica sobre o Processo Unificado.
Esta proposta sugere a integração de ontologias no ciclo de vida do software.
Com esta integração, viabilizou- se a rastreabilidade semântica com a definição e a aquisição dos relacionamentos entre conceitos e artefatos.
Foi verificada a viabilidade das propostas através da modelagem e implementação de uma ferramenta.
Posteriormente, foi caracterizada a rastreabilidade apoiada por conceitos e requisitos, utilizando técnicas de Engenharia de Software Experimental.
A proposta de rastreabilidade ontológica foi aceita em dois congressos internacionais:
Process». Esta publicação foi aceita como full paper.
&quot;Seoul (Korea )) , em março de 2007 , sob o título de Enhancing Traceability using». Esta publicação foi aceita como short paper;
Este trabalho procurou contribuir para o estado da arte sobre a rastreabilidade de artefatos durante ciclo de vida do software, abrangendo os seguintes tópicos:
Identificação de padrões e boas práticas para construção de ontologias;
Definição de uma disciplina para modelagem do conhecimento integrada ao Processo Unificado;
Revisão sobre as classificações dos elos de rastreabilidade;
Definição de uma estrutura ontológica para geração e aquisição dos elos de rastreabilidade;
Modelagem e implementação de uma ferramenta que integre ontologias no tradicional processo de desenvolvimento de software, permitindo a modelagem do conhecimento e a rastreabilidade semântica;
Definição de um experimento para avaliação da proposta de rastreabilidade ontológica com relação a tradicional proposta de rastreabilidade indexada por requisitos.
Estas contribuições motivam futuros pesquisadores em explorar os benefícios da utilização de linguagens para representação do conhecimento, tal como OWL, na Engenharia de Software.
Com o objetivo de incentivar trabalhos futuros e apresentar as limitações deste trabalho, sugere- se:
Aplicação da metodologia para geração de aplicações na Web Semântica;
Definição mais precisa sobre a atividade de manutenção da disciplina de Modelagem do Conhecimento, abordando a integração de ferramentas específicas para manipulação de ontologias.
Sugere- se também a extensão em detalhes da atividade de avaliação;
Evolução do protótipo, visando adaptar uma ferramenta de modelagem que esteja em conformidade com UML 2.
0. Devido a limitações do ArgoUML, o protótipo atual está de acordo com variando, por exemplo, a modelagem do sistema, os elementos rastreáveis e a etapa do processo de desenvolvimento;
Aplicação da proposta na indústria.
Finalmente, o avanço na pesquisa sobre linguagens para representação do conhecimento e seu relacionamento com a Engenharia de Software pode indicar novas melhorias na proposta de rastreabilidade ontológica não citadas neste trabalho.
