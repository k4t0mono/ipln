As comunidades surdas, atualmente, utilizam largamente os recursos computacionais disponíveis, principalmente para comunicação e busca de informações, através da Internet.
A fim de aumentar a atuação das pessoas surdas nos contextos social, profissional e acadêmico, faz- se necessário que as funcionalidades das ferramentas computacionais disponíveis sejam projetadas e desenvolvidas de maneira a facilitar a interação do usuário surdo.
Uma das funcionalidades mais importantes dentro de um aplicativo é o sistema de ajuda, cuja função é explicitar todas as características do mesmo, tais como o conjunto de funcionalidades e as diferentes possibilidades de acesso destas através da interface.
Entretanto, em grande parte, os sistemas de ajuda estão modelados de forma a apresentar o conteúdo em grandes concentrações de texto, estáticos, com interação possível apenas através de hyperlinks de referência, o que é pouco atraente para os usuários em geral.
Esse fato se agrava ainda mais com o usuário surdo, que não tem um domínio completo da sintaxe da língua escrita ouvinte, usada por a sociedade em a qual ele está inserido.
Em esse sentido, esse trabalho aborda a criação de um método para o desenvolvimento de sistemas de ajuda com alto grau de interatividade.
Essa interatividade caracteriza- se por uma interface provida de um agente conversacional, considerando questões de acessibilidade no que se refere aos tópicos do sistema de ajuda, direcionada a um público alvo específico:
Usuários surdos.
O desenvolvimento desse agente de ajuda segue um conjunto de diretrizes que garantem aspectos realistas e de interação agradável por parte de agentes conversacionais, além de facilitar o acesso para o usuário surdo quanto a o uso do sistema de ajuda.
Isso significa tornar efetiva a interação do usuário surdo junto ao aplicativo, oferecendo a ele condições de compreender o funcionamento do sistema ao invés de um processo de tentativa e erro para cada interação.
Palavras-Chave: IHC, sistemas de ajuda, agentes conversacionais, acessibilidade, usuários surdos.
Os aplicativos computacionais, atualmente, são uma constante na vida da maioria da população, que de eles necessita para realizar as suas tarefas cotidianas, quer seja digitando um trabalho acadêmico, pagando faturas no site do banco, ou conversando com diversas outras pessoas ao redor de o mundo.
As grandes organizações, também, já não podem prescindir do uso dos sistemas computacionais, sob pena de serem ultrapassados por seus concorrentes, que utilizam a tecnologia para prever tendências de mercado, otimizar o fluxo de trabalho da empresa e dos funcionários, entre outras coisas.
Dentro deste contexto, deve- se notar que, ao mesmo tempo em que muitas barreiras estão sendo vencidas com a popularização dos computadores e o advento da Internet, como a distância e a facilidade de acesso às informações, muitas vezes as pessoas com necessidades especiais não são consideradas quando são criadas as interfaces e funcionalidades dos aplicativos, ou mesmo de páginas Web.
As pessoas surdas, especialmente, têm muita dificuldade em seu dia-a-dia, por que a acessibilidade dos lugares, serviços e produtos para eles não é, em geral, pensada.
Em uma sociedade onde uma língua oral-escrita é a utilizada por a maioria, uma língua viso-gestual é utilizada apenas na comunicação dos surdos.
As ferramentas computacionais não são exceção a esse padrão:
Em sua grande maioria, estas ferramentas são desenvolvidas para pessoas que tenham como língua materna alguma língua oral-escrita, apresentando as suas interfaces na modalidade escrita da mesma.
A apresentação das interfaces em línguas orais limita o total aproveitamento das funcionalidades por parte de os usuários surdos, visto que a sua língua materna é de natureza viso-gestual, não tendo conexões sintáticas com a língua usada por a parcela ouvinte da população.
Em esse âmbito, os sistemas de ajuda (help) disponíveis nas ferramentas computacionais, se concebidos e desenvolvidos para atender às necessidades desse grupo de usuários, constituem- se numa categoria de funcionalidades de grande importância para a melhoria da interação com uma ferramenta computacional.
Os sistemas de ajuda são uma classe de funcionalidades que procura responder, com abrangência variável, as dúvidas dos usuários, surgidas quando de a sua interação com o aplicativo abordado por o mesmo.
Willis afirma que, quando um usuário não está familiarizado com um determinado aplicativo computacional, é o sistema de ajuda que o fará adquirir o conhecimento e as habilidades necessárias para operar- lo de forma eficaz.
Um sistema de ajuda eficiente auxilia o usuário na execução das suas tarefas junto à ferramenta, o que faz com que ele apresente uma maior produtividade em suas atividades, além de aumentar a sua satisfação ao realizar- las.
Também, as interrupções no ritmo de trabalho, para buscar informações sobre um dado aplicativo ­ através de consultas a colegas, fóruns ou sítios de pesquisa, meios em os quais a informação buscada não é o foco principal serão menos freqüentes.
Apesar de sua potencialidade, os sistemas de ajuda são pouco utilizados.
Uma das razões que podem ser apontadas é o fato de que os sistemas de ajuda são geralmente protelados para os últimos momentos do ciclo de desenvolvimento do aplicativo, por serem considerados por os designers do sistema pouco importantes, em relação a as outras funcionalidades.
Isso faz com que pouca atenção seja dispensada à criação do sistema de ajuda, resultando em desatenções e omissões no desenvolvimento do mesmo.
Em segundo lugar, os sistemas de ajuda tradicionais não costumam oferecer muitas alternativas de interação, esta comumente se resumindo à navegação por uma estrutura de documentos, os quais estão ligados entre si (hiperlinks), mas que não apresentam nenhum fator social que torne a interação mais amigável.
Em Shechtman, afirma- se que as pessoas têm dificuldade de manter uma comunicação interpessoal com um sistema computacional que se comporta de maneira linear durante todo o tempo, independente do estado da interlocução.
Em adição a isso, Willis afirma que não é natural para uma pessoa ficar consultando uma grande quantidade de texto para localizar uma solução pontual para a sua dúvida.
Logo, os sistemas de ajuda se tornam ineficientes devido a a natureza de sua interação.
Em terceiro lugar, a elaboração da questão do usuário não se dá num só estágio, isto é, faz- se necessário que haja um refinamento da pergunta, por meio de uma interação com o usuário, a qual culminará na resposta mais adequada à questão formulada.
Sistemas de ajuda tradicionais não contemplam isso, visto que a interação do usuário com o sistema, em geral, fica restrita a uma consulta a tópicos, ou no máximo a uma lista de questões previamente respondidas.
Se essas dificuldades são encontradas diariamente por usuários ouvintes, a questão se torna ainda mais complicada quando o usuário é surdo.
Os sistemas de ajuda são escritos, via de regra, em línguas oral-escritas, não sendo previsto nenhum elemento facilitador de seu uso para pessoas surdas, o que dificulta que elas se apropriem destes ­ e das ferramentas a eles associadas -- completamente.
Para fazer com que o surdo se aproprie desse sistema de ajuda, e utilize- o efetivamente, é necessário que o designer esteja atento à efetividade da interação, à modelagem e simplificação dos tópicos, e à inserção de expressões compreensíveis para o usuário surdo, mesmo que estas sejam expressas numa língua oral-escrita.
Em este contexto, é apresentado aqui um método para a criação de sistemas de ajuda voltados para as necessidades dos usuários surdos.
O foco deste método é a utilização de um agente conversacional como interface entre o usuário e o sistema de ajuda.
Justifica- se a utilização de um agente conversacional para ajuda, quando se pensa em que ele proporciona uma interação similar a um diálogo, que, segundo Willis é uma forma natural dos seres humanos buscarem informações.
Ademais, os agentes conversacionais de ajuda, desde que bem projetados, permitem que o usuário elabore as questões à sua maneira, dando a ele a chance de se expressar naturalmente, em vez de navegar por tópicos nem sempre claros para ele.
Assim, os agentes de ajuda podem oferecer várias vantagens em relação a os sistemas tradicionais, como:
Possibilidade de perguntar sobre os tópicos em linguagem natural, estruturação do conteúdo em tópicos pontuais e restritos às dúvidas do usuário, e possibilidade de aumentar a empatia e a confiança de um usuário através da emulação de personalidade, de forma realista e coerente (persona).
Para o desenvolvimento do agente de ajuda para surdos, o método descrito neste trabalho tem por objetivo modelar as consultas e tópicos de acordo com as necessidades do grupo de usuários-alvo.
Ainda, este método contempla a criação de uma persona realista e amigável, para a interação com o usuário surdo, deixando- o à vontade e receptivo para as sugestões dadas por o sistema de ajuda.
Além de a apresentação do referencial teórico pesquisado e da descrição do método, mostra- se uma aplicação deste método, junto à adolescentes surdos, estudantes numa escola especial, e os resultados aferidos das atividades com eles realizadas.
Assim, o presente trabalho terá a seguinte estrutura:
Em o capítulo 2, serão apresentados os agentes conversacionais, e algumas de suas aplicações.
Em o capítulo 3, serão mostradas as línguas de sinais, e suas particularidades em relação a as línguas ouvintes.
Em o capítulo 4, será discutido o método para o desenvolvimento de agentes de ajuda para surdos.
Em o capítulo 5, serão apresentados os trabalhos relacionados ao método criado.
Em o capítulo 6, serão mostradas as atividades que foram conduzidas para a aplicação do método junto a uma turma de estudantes surdos.
Finalmente, no capítulo 7, serão apresentadas as considerações finais sobre o trabalho, as dificuldades encontradas e os trabalhos futuros.
Essas características, ou propriedades dos ambientes, podem ser descritas da seguinte forma:
Acessibilidade: Um ambiente é dito acessível quando o agente pode obter dados e informações completos acerca de o estado do mesmo;
Conforme a complexidade do ambiente em o qual o agente está imerso, é menor a acessibilidade deste.
Um ambiente que não permita uma leitura completa de seus estados é dito inacessível.
Determinismo: Um ambiente determinístico é aquele em que cada ação perpetrada por o agente resultará num efeito previamente conhecido, não havendo incerteza quanto a a transição de estado do ambiente, dada uma determinada ação por parte de o agente.
Um ambiente que não contemple essa característica é dito não-determinístico.
Dinamismo: Um ambiente dinâmico é aquele em que as mudanças em seu estado não dependem apenas da ação do agente sobre ele, isto é, o agente não tem controle total sobre o estado do mesmo.
Note- se que existe uma íntima ligação entre o fato de um ambiente ser não-determinístico e ser dinâmico.
Um ambiente que dependa completamente das ações do agente para modificar o seu estado é dito estático.
Discretização: Um ambiente é dito discreto se existe um número finito de ações e estados no mesmo;
Caso isso não ocorra, é dito que o ambiente é contínuo.
Por sua vez, cada agente possui um conjunto de características, ou propriedades.
As principais características, que são listadas em Wooldridge, são:
Autonomia, habilidade social, reatividade e pró-atividade, sendo que:
Autonomia: É a capacidade do agente atuar sem intervenção humana direta na execução de suas atividades.
Habilidade social:
É a capacidade do agente atuar em colaboração com outros agentes e com seres humanos através de alguma linguagem para comunicação.
Reatividade: É a capacidade do agente em perceber as condições do ambiente em que está inserido, podendo reagir a essas condições, a fim de mudar- las.
Pró-atividade: É a capacidade do agente em apresentar a reatividade de forma autônoma, com o intuito de alcançar as metas para ele preestabelecidas.
Um agente também pode apresentar características como mobilidade (capacidade de um agente se mover numa rede) e benevolência (um agente não terá objetivos conflitantes com outros agentes imersos no mesmo ambiente, sempre procurando fazer o que lhe foi solicitado), de entre outras.
O emprego de agentes é indicado principalmente para a automação de tarefas repetitivas, que exigiriam um esforço muito grande por parte de o operador humano, caso estivesse sendo usado um aplicativo comum, sem atributos que permitissem a sua independência operacional.
Também, segundo Néri, o uso de agentes pode ser efetuado em todas as áreas onde seja útil a aplicação de um comportamento personalizado, executado de forma contínua e autônoma, ou em situações de simulação em condições extremas (por exemplo, em simulações de emergência quanto a um incêndio), em as quais o emprego de sujeitos humanos seria pouco elucidativo ou teria alto risco para o mesmo.
A seguir, será vista uma taxonomia para classificação de agentes, a fim de explanar as diferentes características que os agentes computacionais podem admitir.
Após, os agentes conversacionais serão apresentados, apresentando- se as suas funcionalidades e características próprias.
Existem muitas taxonomias para a classificação de agentes, como as apresentadas por Nwana, Moraes e Wooldridge.
Após análise das referidas taxonomias, optou- se por adotar a taxonomia apresentada por Moraes, visto que ela não apresenta ambigüidades em relação a classificação das agentes, sendo mais simples do que as outras taxonomias citadas.
Em esta taxonomia, os agentes são classificados em três grandes categorias:
Agentes cognitivos, agentes reativos e agentes de software.
Os agentes cognitivos se caracterizam por ter uma visão global do ambiente em o qual os mesmos estão inseridos, podendo, assim, efetuar inferências acerca de o estado do ambiente.
Isto equivale a dizer que o agente possui um conhecimento, mesmo que limitado, do ambiente.
Esse conhecimento não se restringe ao estado atual do ambiente;
De fato, o agente armazena os estados anteriores, bem como as ações que ele executou, a fim de obter embasamento factual para as inferências, as quais lhe dirão as ações que deverá tomar, a fim de alcançar os objetivos a ele inerentes.
Os agentes reativos, por sua vez, não possuem a capacidade de realizar inferências acerca de o estado do ambiente em o qual os mesmos se encontram imersos, nem de armazenar os estados anteriores e as ações efetuadas, como acontecia com os agentes cognitivos.
Assim, os agentes reativos reagem às mudanças no estado atual do ambiente, tomando um rumo de ação em conformidade com essas mudanças.
Esses agentes são, comumente, sistemas computacionais mais simples que os agentes cognitivos, não conseguindo realizar uma tarefa que tenha um grau mais acentuado de complexidade.
Porém, a associação de vários desses, em regime colaborativo, pode resolver problemas mais complexos, o que torna a utilização de eles viável em diversas aplicações.
Por último, há os agentes de software, que têm por finalidade básica trocar informações e serviços com outros sistemas e com os usuários.
Esses agentes realizam tarefas operacionais e auxiliares dentro de os ambientes em os quais estão inseridos.
Esses agentes são usados em aplicações simples, tais como:
Pesquisa e filtragem de dados e informações em redes locais e globais;
Análise de informações, provenientes de diversas fontes;
Recebimento e seleção de mensagens eletrônicas em geral;
Monitoramento de ambientes computacionais, e de seus usuários;
Uma das modalidades de agentes que pode ser classificada como agentes de software, por sua interação direta com o usuário, é a de agentes conversacionais.
Como eles são o foco do trabalho aqui descrito, serão apresentados ­ em maior detalhe -- na próxima seção.
Define- se agente conversacional como todo o sistema computacional capaz de interagir com o usuário ou com outra entidade em linguagem natural através de troca de mensagens, em modalidade escrita, falada ou gestual, buscando ao máximo a precisão léxica, semântica e sintática.
Dentro deste contexto, pode- se afirmar que o agente conversacional usa como entrada as expressões-chaves retiradas das interlocuções do usuário (ou seja, o usuário é seu ambiente), e retorna sentenças em linguagem natural, &quot;agindo «sobre o usuário à medida que ele provoca o diálogo.
Tomando o conceito de Shoham, pode- se dizer que um agente conversacional será mais efetivo em suas atribuições principais se os seus componentes mentais (crenças, capacidades, escolhas e compromissos) forem coerentes, emulando um ser humano e formando o que pode ser chamado de persona.
Esses componentes são indissociáveis das interlocuções do agente conversacional, e se manifestam através destas.
Os agentes conversacionais podem se apresentar e interagir com o usuário de diversas maneiras.
Muitos agentes conversacionais apresentam a habilidade de se comunicar com o usuário em linguagem natural por meio de mensagens escritas, como numa sala de batepapo.
Tal modalidade de agente conversacional é denominada chatterbot e um de seus exemplos mais famosos é o chatterbot Eliza.
Eliza foi desenvolvido com o intuito de emular um psiquiatra humano (da escola rogeriana) no trato com pessoas portadoras de desordens psíquicas.
Outros exemplos de chatterbots incluem o projeto Alice e os chatterbots SeteZoom e Ed.
A conversação da Alice foi desenvolvida numa linguagem de marcação de diálogos em linguagem natural, denominada AIML (Artificial Intelligence Markup Language), sendo este um chatterbot bastante completo, que serviu como base para o desenvolvimento de muitos outros chatterbots.
A chatterbot SeteZoom foi concebida como sendo uma modelo de personalidade despojada e atrevida, segundo os seus criadores, tendo a função de interagir, como uma atendente virtual, com os usuários que navegam por o sítio da Unilever.
O chatterbot Ed (figura 2.3), por sua vez, foi criado para servir como atendente virtual junto ao sítio da Petrobrás, e sua personalidade e visual foram concebidos para ganhar a simpatia do público infanto-juvenil.
Sua principal atribuição é unir entretenimento à educação ambiental, visto que o mesmo fala com seu público-alvo sobre diversos assuntos voltados para esse tema, como meio-ambiente, gás natural, dicas de economia, qualidade do ar, biocombustíveis, programas educacionais e fontes alternativas de energia.
Os agentes conversacionais, em suas diversas modalidades, podem ser utilizados para aumentar a interação dos usuários com as ferramentas-alvo.
A fim de que essa interação seja a mais proveitosa possível, faz- se necessário que o agente conversacional tenha uma personalidade e interlocuções realistas e agradáveis, do ponto de vista do usuário.
A o assumir uma forma de comunicação mais próxima do coloquial e uma persona com características humanas, um agente conversacional se torna muito mais atraente e assimilável para o usuário do que uma linha de comando ou mesmo um sistema de navegação tradicional, composto apenas de texto estático e hyperlinks.
Além disso, as pessoas têm a tendência natural de se envolver e projetar confiança em seres que tenham padrões de comportamento e de comunicação similares aos dos humanos.
Um exemplo disto pode ser visto em Weizenbaum, citado por Güzeldere:
Uma moça começou a interagir com o chatterbot Eliza, sabedora do fato de que este era um software, e acabou por confiar problemas e segredos íntimos a ele, do mesmo modo que ela faria com um profissional de Psicologia.
Essa confiança projetada nos agentes conversacionais os torna úteis como mediadores entre o aplicativo propriamente dito e o usuário, fazendo com que os mesmos venham a considerar as sugestões que o agente conversacional faça.
Isto se faz importante quando o objetivo do agente conversacional é transmitir conhecimento acerca de algum domínio, visto que é fundamental que o receptor deste conhecimento (no caso, o usuário) venha a confiar no conteúdo passado por o transmissor (o agente conversacional).
Segundo Bickmore, pode- se habilitar um agente para a interação conversacional com seres humanos, desde que este seja projetado para mostrar inteligência social e habilidades de comunicação, a fim de expressar essa inteligência.
Isso demanda que a persona do agente esteja não apenas coerente com o que se poderia esperar de um ser humano, mas também de acordo com o que seria esperado de uma pessoa que estivesse desempenhando um papel similar, no domínio onde ele está inserido.
Por exemplo, um agente conversacional que preste serviços de informação a um órgão do Judiciário deve apresentar um comportamento mais introspectivo, sem comentários espirituosos, dado que este personifica um funcionário de tal órgão, em o qual é recomendado o máximo de decoro e sobriedade possível, segundo Nascimento.
Já num ambiente mais flexível, como num sistema de apoio pedagógico, é indicado que o agente conversacional seja o mais amistoso possível, a fim de criar uma empatia entre ele e o usuário, como acontece com os agentes pedagógicos.
Os surdos, a partir de sua primeira infância, recebem como meio de expressão uma das diversas línguas viso- gestuais existentes, as quais variam de país para país, ou mesmo de região para região, formando dialetos peculiares às mesmas.
Podem ser citados, como exemplos de línguas gestuais, a ASL (American Sign Language), a qual é adotada nos Estados Unidos da América, e a Libras (Língua Brasileira de Sinais), a qual é adotada no Brasil.
Cada uma dessas línguas viso- gestuais, segundo Stumpf, é uma língua completa no ponto de vista da Lingüística, e o surdo deve aprender uma destas, a fim de que desenvolva plenamente as suas capacidades cognitivas.
Assim sendo, a pessoa surda aprende a expressar suas idéias e a representar o mundo dentro desse paradigma lingüístico, que, de maneira alguma, é menos expressivo, mas que propicia formações sintáticas bastante diferentes daquelas encontradas nas línguas oral-escritas.
Segundo Quadros, os surdos são, de fato, minorias lingüísticas dentro de seus países de origem.
E, como toda a minoria lingüística, os surdos têm direito à educação e expressão em suas próprias línguas viso- gestuais.
Assim sendo, muitos países garantiram esses direitos a seus cidadãos surdos, sendo um de eles o Brasil, através da Lei nº 10.436, de 24 de abril de 2002, que regulamentou o uso da Libras e o permitiu em todo o território nacional.
De uma forma geral, as línguas viso-gestuais substituem os sons presentes nas línguas oral-escritas por gestos, os quais compõem os sinais que são utilizados para comunicação entre as pessoas surdas.
Quanto a a estrutura, essas línguas são compostas por níveis lingüísticos variados, tais como:
Fonologia, morfologia, sintaxe e semântica.
De a mesma forma que nas línguas oral-escritas existem palavras, nas línguas viso- gestuais também existem itens lexicais, que recebem o nome de sinais, diferenciando- se das palavras por pertencerem à modalidade viso-gestual, e serem realizados num espaço de enunciação.
Em a Libras, assim como em outras línguas viso- gestuais até agora estudadas por os lingüistas, o espaço de enunciação é uma área que contém todos os pontos, dentro de o raio de alcance das mãos, em que os sinais são realizados.
Assim como as línguas orais, as línguas viso- gestuais também são formadas por unidades mínimas (ou quiremas).
Tais unidades mínimas, como os seus correspondentes orais, não guardam significação isoladamente.
A sua execução simultânea, no entanto, confere ao sinal um significado (isto é, torna- o um morfema), desde que este seja previamente convencionado dentro de o contexto da língua corrente.
Os fonemas em línguas oral-escritas, por sua vez, adquirem significado por concatenação (Figura 3.1).
Ainda segundo Quadros, há dois parâmetros auxiliares que dão informações adicionais ao sinal:
Orientação da mão:
A orientação da mão não foi um parâmetro inicialmente considerado nas pesquisas.
Porém Battison, citado por Quadros, mostra que é necessária a adoção deste parâmetro, visto que há sinais que se diferenciam apenas por a orientação da mão;
Expressões não-manuais:
As expressões não-manuais são utilizadas para marcar afirmação ou negação, interrogação, grau, entre outros aspectos.
As línguas de sinais foram, pela primeira vez, analisadas sob o prisma da Lingüística em Stokoe.
Antes, as línguas viso-gestuais eram consideradas como simples linguagens1, destituídas de qualquer valor lingüístico.
A visão oralista foi, durante muito tempo, preponderante.
Isso levou ao tratamento do surdo como uma pessoa doente, e da surdez como um defeito a ser corrigido.
Forçou- se, nesse contexto, a pessoa surda a se adaptar às modalidades de comunicação dos ouvintes, através da fonoaudiologia e da educação com uso exclusivo de línguas oral-escritas.
Por causa de isso, o uso de línguas de sinais foi abolido nas escolas de educação especial, por ocasião de o II Congresso Sobre a Instrução de Surdos (comumente conhecido como Congresso de Milão), em 1880.
Este congresso reforçou a idéia de que uma língua viso-gestual não possuía uma estrutura gramatical válida, possuindo uma natureza icônica, incapaz de transmitir idéias abstratas, não possibilitando a reflexão e o pensamento abstrato do aluno surdo.
Essa preponderância da visão do surdo enquanto portador de uma deficiência levou a vários preconceitos por parte de os especialistas e da população em geral, conforme segue:
As línguas viso-gestuais seriam uma mistura de pantomima e gesticulação icônica, sendo incapaz de transmitir conceitos abstratos.
Segundo Karlberg, linguagem é a faculdade mental que distingue os humanos de outras espécies animais e que possibilita nossos modos específicos de pensamento, conhecimento e interação com os semelhantes, enquanto a língua é um sistema lingüístico necessário ao exercício da linguagem na interlocução ou como instrumento de o qual a linguagem se utiliza na comunicação.
Existiria uma língua viso-gestual universal, que é compreendida e usada por todos os surdos, que não teria modificações significativas por fatores geográficos e históricos (ou seja, não evoluiria).
Haveria uma falha na organização gramatical das línguas viso-gestuais;
Esta gramática seria uma adaptação imperfeita da sua suposta contraparte na língua oral-escrita.
As línguas viso-gestuais seriam sistemas de comunicação restritos e superficiais, com estética, poder de expressão e conteúdo lingüístico inferior ao apresentado por as línguas oral-escritas.
As línguas de sinais derivariam da comunicação gestual espontânea dos ouvintes.
As línguas gestuais não constituiriam um sistema lingüístico com representação hemisférica.
As línguas gestuais, por serem organizadas espacialmente, estariam representadas no hemisfério direito, sendo este responsável por o processamento de informação espacial.
A afirmação não encontra espaço na evolução que as línguas viso- gestuais apresentam, como qualquer língua viva.
Apenas um exemplo:
A representação gestual, atual, do conceito Mulher, em Libras, é dada por a mão direita cerrada, com o polegar em riste, passando paralelo à face, da altura da orelha até o queixo, o que não deixa entrever qualquer resquício de iconicidade neste sinal.
Porém há algum tempo atrás, este conceito era representado por a mão direita cerrada, polegar em riste, mas descrevendo uma espiral em sentido horário, paralelamente à face (por causa de um dos cortes de cabelo femininos mais populares à época, que tinha uma mecha justamente nessa região).
Assim pode- se constatar que uma língua viso-espacial pode, sim, apresentar evolução, passando de uma fase icônica à outra, mais concisa e rápida, num processo semelhante ao das línguas oral-escritas.
Em relação a a afirmação, deve ser lembrado que existem várias línguas de sinais ao redor de o mundo, como a Libras, a ASL e a BSL (British Sign Language).
Estas línguas não guardam semelhanças significativas entre si, de forma que os interlocutores de uma não conseguem compreender os interlocutores da outra.
Como foi dito anteriormente, a existência de uma língua universal implicaria numa anulação de sua evolução, por fatores geográficos e históricos.
Porém, é sabido que existem variações dialetais nas línguas visogestuais, como em qualquer língua viva.
Em a Libras, por exemplo, existe variação no sinal que representa o conceito Pai em regiões diferentes do Brasil.
O sinal Pai, no Rio Grande do Sul, é executado com a mão cerrada, dedo indicador dobrado, tocando por duas vezes no nariz do interlocutor, enquanto no Sudeste o sinal é composto por a combinação dos sinais Homem e Bênção.
Em relação a a afirmação, a inexatidão da mesma é mostrada por o trabalho desenvolvido por William Stokoe, que conduziu sua pesquisa em torno de a afirmação das línguas viso- gestuais como portadoras de regras gramaticais definidas, validáveis segundo a Lingüística.
Dentro de essa perspectiva, Stokoe verificou a validade da ASL através de uma notação criada por ele próprio utilizando letras do alfabeto latino para representar as posições das mãos, e alguns sinais auxiliares sobrescritos e subscritos para indicar movimentos.
A o final das pesquisas, Stokoe concluiu que as línguas viso- gestuais possuem elementos análogos aos apresentados por as línguas ouvintes, sendo estas, portanto, línguas no sentido estrito do termo, e não simples sistemas icônicos e falhos de representação da realidade concreta.
Em relação a a afirmação, pode se dizer que as línguas viso- gestuais são línguas no sentido estrito do termo, conforme foi mostrado por Stokoe.
Se elas são línguas, e estão em uso corrente por as comunidades surdas do mundo inteiro, elas também são sujeitas à inserção de expressões idiomáticas e neologismos por parte de os seus usuários, bem como de alterações de seus próprios vocábulos.
Um exemplo disto, dentro de o caso de alteração de vocábulos, é a modificação do morfema Mulher em Libras, anteriormente citado, onde um morfema passou de uma representação icônica para outra, mais concisa, em que não se percebe nenhuma iconicidade.
Também, o morfema Azul, em Libras, sofreu uma alteração significativa com o passar do tempo, como pode ser notado na figura 3.3.
Ainda em relação a a afirmação, nota- se que as línguas viso- gestuais, como a Libras, apresentam sutilezas de linguagem tais como trocadilhos, piadas, poesias, entre outros, conforme as pesquisas realizadas por Kilma e Bellugi, citadas por Quadros.
As línguas viso-gestuais possuem em si todo o poder de expressão de uma língua oralescrita, estando a diferença apenas na maneira como esse poder se manifesta, através do movimento ou de outros recursos lingüísticos.
Em relação a a afirmação, deve ser observado que a iconicidade de uma língua gestual se perde com a sua evolução.
Assim, não se pode dizer que ela deriva da comunicação gestual espontânea dos ouvintes, que se prende justamente à semiótica dos gestos daí derivados, a fim de se tornar compreensível para todos.
Para refutar de vez essa assertiva, basta constatar que a grande maioria dos ouvintes não consegue compreender um diálogo travado em qualquer das línguas gestuais.
Ora, se essas línguas derivassem de pantomima ou da comunicação gestual e espontânea dos ouvintes, esta seria vagamente compreensível ao interlocutor ouvinte.
Por último, em relação a a afirmação, deve ser salientar que, apesar de as línguas gestuais utilizarem mecanismos espaciais, elas são processadas no hemisfério esquerdo, de forma análoga às línguas faladas, segundo pesquisas conduzidas por Bellugi e Klima, citados por Quadros.
A seguir, será discutida a Libras ­ Língua Brasileira de Sinais, e serão brevemente abordados os seus aspectos de formação dos sinais, para após entrar nos aspectos gramaticais da língua, em relação a a sua sintaxe e às suas estruturas frasais.
Em o Brasil, a Libras é a língua mais utilizada por as comunidades surdas, tendo adquirido status de língua oficial em 2002.
Em o referido ano a Libras passou a ser reconhecida como meio legal de comunicação e expressão entre as comunidades de pessoas surdas.
A Libras tem origem na Língua de Sinais Francesa, e, como as demais línguas visogestuais, possui todos os níveis lingüísticos, a saber:
Nível fonológico, morfológico, sintático e semântico, os quais fazem uma língua adquirir esse status (ser uma língua e não uma linguagem) no sentido estrito.
Como qualquer língua viso-gestual, a Libras não é uma língua universal, possuindo suas particularidades sintáticas.
Há duas maneiras distintas de se representar uma palavra em Libras:
Uma destas é através do chamado alfabeto manual, o qual se constitui de vinte e seis sinais, que representam as 26 letras do alfabeto latino (figura 3.4).
É possível reproduzir as palavras da língua portuguesa para o alfabeto manual;
Porém, fazer isso seria como passar um texto em português, escrito com o alfabeto latino, para o alfabeto grego;
Não alteraria a morfologia da palavra, isto é, não faria com que ela fosse automaticamente passada para a língua grega.
Assim acontece com o alfabeto manual, que serve para verificação, questionamento ou veiculação da ortografia de uma palavra em Português.
Um exemplo básico que pode ser dado da utilidade do alfabeto manual em Libras é a utilização de ele para a compreensão de algum sinal desconhecido por um ouvinte.
Por exemplo, na situação a seguir2, um ouvinte pergunta para um interlocutor surdo, em Libras, qual a palavra correspondente ao sinal em questão:
Tu-GOSTAR-CAFÉ (Tu gostas de café?)
Aqui, é utilizada a notação para a marcação de sinais em Libras corrente nos trabalhos de Quadros, a qual pode ser vista em Quadros, Quadros e Quadros.
Esta notação também é utilizada por o INES, conforme constante do seu site Web O-QUE Isto, Café (O que significa este sinal, Café?)
C-A-F-E3 OK (Ah, ok!)
Há também casos em que a repetição de um dado morfema ou composição de dois ou mais destes pode dar origem a um novo sinal.
Por exemplo, o quirema Cadeira é derivado do quirema Sentar através do movimento repetido de este (Figura 3.5) e Igreja é formado por a composição dos morfemas Casa e Cruz.
Há três modos na consecução do movimento de um sinal que alteram o seu significado, os quais se denominam pontual, continuativo e iterativo.
O aspecto pontual se caracteriza por se referir a uma ação ou evento ocorrido e terminado em algum ponto bem definido no passado.
O aspecto continuativo se refere a uma ação que tem uma continuidade no tempo, e o aspecto iterativo refere- se a uma ação ou evento que se repete por diversas vezes consecutivas.
Em a figura 3.6, à esquerda, o quirema Falar está sendo usado num aspecto pontual, como na frase João-FALAR-MARIA (João falou com Maria), enquanto à direita existe uma mudança apenas no movimento do quirema, sendo este usado num aspecto continuativo, como na frase JOAO-FALAR-SEM- (João falou sem parar com Maria).
Utilização de datilologia para &quot;soletrar «a palavra café.
As línguas viso-gestuais guardam significativas diferenças semânticas entre elas e suas correspondentes línguas oral-escritas, como já foi dito anteriormente.
Em conformidade com isso, há diferenças entre o sistema gramatical da Língua Portuguesa e o da Libras.
Pode ser tomado, como exemplo, a classe gramatical artigo.
Esta classe existe na Língua Portuguesa, tendo duas subclasses:
Artigos definidos e indefinidos, ao passo que na Libras não existe esta classe gramatical.
Ainda, na Língua Portuguesa, a classe gramatical pronome pode ser flexionada quanto a o número em singular e plural.
Em a Libras, por sua vez, os pronomes podem ser flexionados em singular, dual (duas pessoas), trial (três pessoas), quatrial (quatro pessoas) e plural (várias pessoas).
Também, a utilização de verbos de ligação é rara em Libras, bem como o uso de preposições e conjunções, segundo Felipe, citado por Quadros.
No tocante a a estrutura sintática, ainda conforme Felipe, citado por Quadros, a Libras tem por principal formação sintática Sujeito ­ Verbo ­ Objeto (ou SVO), como nos exemplos abaixo:
João Amar Ela Maria. (
João ama Maria.)
Maria Gostar Ele João. (
Maria gosta de João.)
Porém, conforme Quadros, a formação sintática pode variar, podendo se configurar como Objeto-SUJEITO-VERBO (OSV) ou mesmo Sujeito-VERBOOBJETO (SVO).
Em esse contexto, a estrutura SVO pode ser abandonada, devido a não existência de um objeto na frase, ou mesmo por o fato do sujeito estar implícito, num processo similar à elipse no Português.
Isto pode ser observado nos exemplos adiante:
Ele-ELA-SAIR (Ele e ela saíram.).
Não-ENXERGAR-TU (Eu não te enxergo.).
Também, dentro de a Libras, pode haver uma alteração na construção da frase, repetindo o pronome interrogativo ou mesmo um verbo, a fim de que o sinal adquira destaque na frase.
Este processo denomina- se focalização, e está representado por as frases abaixo:
Quem Gostar João Quem (Quem gosta do João?).
O Que João Comprar O que (O que João comprou?).
Eu Adorar Doce Adorar (Eu adoro doce.).
Ontem João Comprar Carro Ontem (Ontem João comprou um carro.).
O processo de focalização de um sinal é acompanhado sempre de algum tipo de expressão facial, de acordo com o tipo de sentença proferido, e permanece após o sinal ter sido executado.
Como pode ser visto, a estrutura sintática da Libras é diversa da estrutura sintática do Português, com o qual ela divide espaço no cotidiano das pessoas surdas.
Tal diferença na gramática, aliada ao fato de que os surdos necessitam, em seu dia a dia, ler e escrever em Português continuamente, costuma acarretar problemas, principalmente em suas produções textuais.
Em este capítulo, serão mostradas pesquisas existentes no contexto deste trabalho, o qual propõe um método para desenvolvimento de agentes de ajuda para usuários surdos.
Em este âmbito serão apresentados exemplos de aplicativos que existem para essa classe de usuários, de agentes conversacionais, e suas características e, por último, se dará uma breve visão sobre os trabalhos existentes em sistemas de ajuda, em relação a os estudos e metodologias para o desenvolvimento e avaliação destes.
Os usuários surdos, como foi visto anteriormente, têm uma dificuldade muito grande em utilizar os aplicativos comumente desenvolvidos, visto que eles se destinam à parcela majoritária da população, que é ouvinte.
Porém, muitos aplicativos são desenvolvidos especialmente para essas pessoas, considerando as suas necessidades especiais.
Aplicativos educacionais são um dos principais focos de desenvolvimento, nesse contexto.
Um exemplo de aplicativo educacional desenvolvido para usuários surdos é o CopyCat, que é um jogo voltado para o auxílio no aprendizado de ASL (American Sign Language) junto a crianças surdas.
Este aplicativo possui um sistema de reconhecimento de sinais, os quais são utilizados para passar comandos ao personagem do jogo;
Esses comandos são em ASL, permitindo que o usuário desenvolva a sua proficiência nesta língua.
Outro aplicativo desta classe é o LODE (LOgic based e-tool for DEaf children), o qual tem como objetivo desenvolver a capacidade da criança surda na leitura da língua oral escrita, através do desenvolvimento do raciocínio temporal em cima de histórias escritas, apresentadas por a ferramenta.
Em Campos é apresentado um pacote de aplicativos voltados para o auxílio na educação de pessoas surdas, denominado pacote SIGN.
O propósito deste pacote de aplicativos é proporcionar um ambiente bilíngüe (Português-LIBRAS) para comunicação e aprendizado, voltado para a educação especial.
Inicialmente o pacote foi composto de três aplicativos:
SIGNED (editor de texto), SIGNSIM (ferramenta de tradução PortuguêsLIBRAS) e SIGNTALK (ferramenta para comunicação síncrona ­ chat).
Após, a esse pacote de aplicativos, foram acrescentados o SIGNHTML (editor de páginas Web com suporte a sinais) e o SIGNHQ (sistema para a criação de histórias em quadrinhos).
Por último, em Campos é apresentado o SignWebEdit, o qual é um editor de textos colaborativo online, o qual tem por diferenciais o suporte à escrita de línguas visogestuais, através da notação SignWriting.
Em relação a o SignWriting foram desenvolvidos alguns editores de texto exclusivos para esta forma de notação, sendo um de eles o SignWriter, o qual foi o primeiro editor de textos voltado para o usuário surdo.
Desenvolvido originalmente para rodar em MSDOS, o seu grande diferencial, em relação a outros editores de texto em línguas gestuais, é que o mesmo oferece suporte para padrões diversos de teclado.
Atualmente, uma nova versão do SignWriter foi desenvolvida, com o nome de SignWriter Java 1.5/ Swing, a qual roda em diversas plataformas.
O SWEdit é outro editor de textos que utiliza a notação SignWriting.
Ele permite, além de as funcionalidades normais, a inclusão de textos em línguas ouvintes, figuras e imagens, drag&amp; drop entre diferentes programas, salvar e carregar arquivos no formato SWML (SignWriting Markup Language), entre outros recursos.
Apresenta uma base de dados expansível, através de um editor de sinais denominado AlfaEdit, que permite importar os sinais em variados formatos, além de permitir a criação e edição dos mesmos na própria ferramenta.
Os agentes conversacionais são, conforme foi visto anteriormente, uma alternativa para o desenvolvimento de interfaces.
Através do diálogo em linguagem natural, adequadamente projetado, vencem- se as barreiras naturais que o usuário tem com a tecnologia, possibilitando que o mesmo possa requisitar as funcionalidades do aplicativo com o seu paradigma usual de comunicação, não havendo, daí, maiores necessidades de aprender comandos, posicionamento de itens no menu ou mesmo de função de botões nas barras de ferramentas.
Isto faz com que os agentes conversacionais sejam usados em aplicações para atendimento de clientes, ensino e aprendizagem, entre outros.
Primeiramente deve ser citada a criação do AIML (Artificial Intelligence Markup Language) e do chatterbot Alice.
O Projeto ALICE foi a base de outros chatterbots, desenvolvidos tanto no contexto acadêmico quanto no comercial, visto que a tecnologia utilizada na confecção do mesmo (o AIML, que será abordado posteriormente) é flexível e de fácil implementação, permitindo que a atenção dos desenvolvedores de chatterbots se volte para a modelagem lógica dos diálogos dos mesmos.
Em a área pedagógica, os agentes conversacionais têm sido muito utilizados.
Um exemplo de agente que é utilizado dentro de um contexto educacional é o Fred que é dedicado a um único domínio, bastante específico (História ­ Missões Jesuíticas).
Como características gerais, Fred pode se expressar em linguagem natural para o aluno, demonstrando as suas reações emocionais (tristeza, raiva, alegria, etc.), através de seu avatar em 2D (estilo cartoon).
Também, apresentado em Leonhardt, é mostrado o chatterbot Elektra, que foi concebido para responder perguntas sobre Física, aumentando- se a sua base de conhecimentos, mais tarde, para redes de computadores.
O chatterbot Elektra foi totalmente desenvolvido em AIML, tendo uma interface bastante similar à de uma sala de chat.
Outro exemplo é o trabalho apresentado em Carvalho, onde um agente conversacional é utilizado como interface de comando para um sistema de segurança e gerência de redes, denominado MAST (Mobile Agents Security Tool).
Em este sistema, o gerente da rede solicita as funcionalidades aos agentes móveis em linguagem natural, através de uma interface integrada a um sistema de IRC (Internet Relay Chat).
Em relação a os ECA's (Embodied Conversational Agents), podem ser citados como exemplos o Rea (Real Statement Agent), o qual simula uma corretora de imóveis, e Baldi, o qual é um ECA cujos diálogos, feitos através de voz sintetizada, podem ser adaptados a diversas bases de conhecimentos e diversas línguas, bastando para isso a troca dos mecanismos TTS (text to speech) e a regulagem dos fonemas da língua inserida, através de uma interface simples.
O grande problema desta classe de agentes conversacionais é a despesa decorrente da instalação de uma interface multimodal, que exige periféricos caros, como câmeras, sensores e microfones.
Tal fato não ocorre no desenvolvimento de chatterbots, os quais são, via de regra, simples de serem implementados e de serem interpretados por parsers que podem ser encontrados na Internet tanto para ambientes offline, como o Chatterbeans e o Program D, quanto para ambientes online, de os quais o exemplo mais conhecido e utilizado é o serviço de hospedagem PandoraBots.
Em relação a os agentes conversacionais diretamente voltados para os usuários surdos, não foi achada, até o momento, nenhuma referência ou trabalho efetuado neste contexto.
Em relação a os sistemas de ajuda, podem ser citados alguns trabalhos que serviram de embasamento para o método aqui apresentado.
Primeiramente, há os trabalhos apresentados por Silveira et al.,
os quais tratam da metacomunicação entre designer e usuário, no uso de sistemas de ajuda, fornecendo ferramentas epistêmicas ao designer para que este possa explorar melhor o poder de expressão deste sistema, explicitando os tópicos do mesmo de forma mais adequada para a consulta do usuário.
As quebras de comunicação que podem ocorrer entre o sistema e o usuário são indicadas, nesses trabalhos, por expressões que são facilmente identificáveis por o usuário, no momento da utilização do aplicativo.
Estas expressões ­ como &quot;O que é isso?»
usada quando o usuário desconhece uma determinada funcionalidade do aplicativo, ou &quot;E agora?», utilizada por o usuário quando ele não sabe qual o próximo passo a ser realizado para a execução de uma tarefa no aplicativo ­ pretendem não apenas facilitar que o usuário melhor consiga explicitar a sua dúvida, mas, também, auxiliar na construção do conteúdo da ajuda, como base para estruturação do mesmo.
A idéia é permitir, ao uso de cada expressão, o acesso a informações resumidas e focadas na quebra em questão e a possibilidade de aprofundamento das informações recebidas, por meio de ligações sucessivas, que fazem com que o usuário tome posse de novas informações, sempre em pequenas porções (ou camadas), de acordo com a sua necessidade.
Também, em Farkas, mostra- se como construir uma documentação minimalista, por o uso de divisões dos tópicos em subestruturas simples e atômicas (chunks), para diminuir o esforço cognitivo do usuário.
É mostrado nesse trabalho, também, que os sistemas de ajuda tradicionais contemplam apenas o aspecto procedimental (representados na taxonomia anterior por as interjeições &quot;O que é isso?»
e &quot;Como eu faço isso?», não havendo nenhuma informação adicional em relação a o contexto da tarefa que o usuário está executando, o que é importante para auxílio dos usuários inexperientes, que não têm nenhuma experiência com o aplicativo, fato gerador de um alto nível de estresse.
Outro exemplo é o trabalho apresentado por Willis, que indica que os sistemas de ajuda, em seus formatos usuais, não são otimizados para a maneira com a qual um ser humano procuraria auxílio na consecução de uma dada tarefa, visto que falta uma maior consideração com os aspectos cognitivo e social desta interação.
Em relação a os agentes assistentes de ajuda, pode ser citado o assistente de ajuda animado do MS Word, surgido a partir de a versão 97.
O agente de ajuda do Word pode tanto oferecer sugestões espontaneamente (isto é, ajuda contextual) quanto ser consultado por o usuário, em linguagem natural.
As respostas dadas por o assistente são curtas, de fácil compreensão e com links para informações adicionais.
Conforme Willis, um dos grandes problemas dos sistemas de ajuda é o fato de que eles não são projetados de uma forma em que a consulta se torne uma atividade natural para o usuário.
Isto equivale a dizer que os designers do sistema de ajuda não consideram, ao desenvolver o mesmo, os comportamentos naturais de um ser humano ao procurar por uma dada informação.
Em Shechtman, afirma- se que as pessoas têm dificuldade de manter uma comunicação interpessoal com um sistema computacional que se comporta de maneira linear durante todo o tempo, independente do estado da interlocução.
Por causa de isto, acredita- se necessário aproximar a interface do sistema de ajuda de um comportamento mais humano, a fim de diminuir o esforço cognitivo, bem como o estresse causado por a busca de alguma informação dentro de o sistema de ajuda.
Assim, a fim de tornar a interação com o sistema de ajuda uma experiência mais agradável, é interessante que esta seja aproximada, da forma mais fiel possível, do diálogo entre duas pessoas, a fim de prover o mesmo de &quot;ilusão de vida».
Isto pressupõe a emulação de uma personalidade humana, que esteja inserida num contexto social e tenha reações às entradas do usuário que emulem o comportamento humano.
Em este sentido, os agentes conversacionais podem ser utilizados como agentes de interface, mediando o processo de transmissão dos tópicos do sistema de ajuda, entre o aplicativo computacional e o usuário.
Para os usuários surdos, é importante que esse agente possa processar de forma correta as dúvidas dos usuários, expressas através das suas interlocuções.
A o retornar uma resposta para os questionamentos dos usuários, também, é interessante que ele apresente os tópicos de uma maneira simplificada, ao contrário de os sistemas de ajuda tradicionais, que apresentam os tópicos de maneira extensa, o que acaba dificultando a leitura para o usuário surdo, que não tem o português como sua língua materna.
Em o intuito de simplificar esta comunicação e obtenção da ajuda, o agente poderia considerar as diferenças que os usuários surdos têm ao pesquisar e consultar um sistema de ajuda, principalmente no que diz respeito à forma de se expressarem perante uma situação de dúvida.
Como já foi dito, os surdos, ao escreverem em Português, apresentam uma forma diferenciada de sintaxe em suas construções frasais.
Essa forma diferenciada deve ser contemplada no momento da modelagem dos diálogos do agente, a fim de que o mesmo consiga compreender as dúvidas do usuário e responder de forma adequada.
Além de isto, a modalidade da interface do agente conversacional a ser produzido deve ser algo com que os usuários já estejam familiarizados, visto que deve se priorizar o conhecimento adquirido dos usuários, no uso de aplicativos computacionais.
Em este sentido, deve- se notar que há uma aceitação bastante grande do uso de aplicativos de mensagens síncronas (como o MSN Messenger, por exemplo) entre as comunidades surdas, para comunicação entre seus pares.
Também, dentro deste escopo, existem indicadores de que as pessoas surdas utilizam o serviço de SMS (mensagens de celular) regularmente.
Como exemplo, podem ser citados os dados apresentados por Costa et al.,
onde foi constatado que cerca de 60% dos surdos do Distrito Federal utiliza o serviço de SMS como o seu principal meio de comunicação.
Isto significa que as pessoas surdas costumam se utilizar de serviços de mensagens e conversação em geral, sendo uma prática que não oferece grandes dificuldades, quando realizada entre eles.
Visto que esse tipo de troca de mensagens é similar ao feito através de um chatterbot, o uso desta modalidade de agente conversacional se mostra uma possibilidade atraente, como modalidade de interface a ser adotada neste método.
Além de apresentar uma modalidade de interação bem mais interessante que a navegação num sistema de ajuda tradicional, com texto extenso e de difícil apreensão para o surdo, o formato de diálogo e a caracterização do chatterbot como uma entidade crível e similar ao ser humano colaboram para que a interação se torne mais agradável.
O agente de ajuda deve responder ao usuário de uma forma compreensível, tanto em relação a a clareza dos tópicos apresentados, conforme discutido na seção anterior, quanto em relação a os termos utilizados dentro de o contexto do aplicativo (que nem sempre são coincidentes com os termos usados por os usuários ouvintes).
Para conseguir ajustar essa comunicação entre o usuário e o sistema de ajuda, é necessário mapear o domínio da aplicação segundo as particularidades de comunicação dos surdos, a fim de que o agente possa ser modelado para compreender as elocuções dos surdos, nas modalidades contempladas.
Também, é necessário modelar os tópicos do sistema de forma a que eles se tornem compreensíveis por o usuário.
Em este âmbito, são adequadas a simplificação e atomização dos tópicos, simplificação do vocabulário utilizado, adaptação dos termos de domínio para o léxico próprio do grupo de usuários surdos considerado.
Contemplando os aspectos mencionados, é presentemente apresentado um método para a construção de um agente conversacional de ajuda, em formato de um chatterbot, para usuários surdos.
O método proposto é composto por três fases distintas:
Levantamento do perfil do usuário surdo (Fase A), desenvolvimento do agente conversacional de ajuda (Fase B) e validação do agente junto aos usuários (Fase C), os quais serão descritos em detalhe a seguir.
Para o desenvolvimento de um agente conversacional que seja adequado às necessidades de interlocução dos usuários surdos, é necessário que exista inicialmente um levantamento do perfil destes, em relação a o aplicativo para o qual o sistema de ajuda está sendo desenvolvido.
Dentro deste levantamento, são propostos dois momentos distintos:
Elicitações com os designers do aplicativo:
Deve- se aferir junto dos designers do aplicativo qual é o público-alvo que eles pretendem atingir com o seu produto.
Dependendo do público-alvo, a modelagem do agente conversacional, no que diz respeito a sua persona, deverá ser condizente com a faixa de usuários a ser atingida.
Também a terminologia comum, em língua oral-escrita, do domínio a ser abordado por o aplicativo deve ser vista nessas elicitações iniciais, a fim de selecionar e adaptálas ao perfil de interlocução do usuário surdo, que será aferido num momento posterior.
Caso não haja possibilidade de contatar os designers do aplicativo, faz- se necessário recorrer a outros expedientes para a obtenção de informações.
A fonte preferencial, neste caso, é o sistema de ajuda preexistente (em formato tradicional) no aplicativo, caso ele já tenha chegado ao término da fase de desenvolvimento, e o agente conversacional seja uma nova versão do sistema existente, com foco nos usuários surdos.
Elicitações com os potenciais usuários:
Após a identificação dos potenciais usuários, no passo anterior, devem- se realizar elicitações com eles, para aferir aspectos referentes às suas interlocuções, a fim de modelar a base de conhecimento conforme o seu dialeto e conhecimentos particulares.
São investigados, neste momento, dois aspectos distintos:
As estruturas frasais utilizadas por os usuários surdos daquela comunidade, quando perguntam sobre algum tópico.
No caso de a sociedade brasileira, devem ser aferidas quais são as expressões em Libras que indicam dúvida ou interrogação.
Esse levantamento pode ser utilizado, mais tarde, para o desenvolvimento de sistemas de ajuda de outros aplicativos, de domínios distintos, desde que os grupos de usuários a serem considerados possuam características similares ao grupo que gerou a elicitação inicial.
As expressões utilizadas por os usuários surdos daquela comunidade, relacionadas com o domínio do aplicativo em questão.
Este levantamento será utilizado somente no domínio do aplicativo em questão, não sendo válido para aplicativos de outros domínios.
Para a construção do agente de ajuda, é necessário que se tenha pleno conhecimento do aplicativo, a fim de que este sistema seja completo, contemplando todos os detalhes da ferramenta computacional abordada.
Também, devem ser utilizadas as informações adquiridas na primeira fase deste método, para adaptar o conteúdo e a interface às particularidades dos grupos de potenciais usuários.
Assim, podem ser indicados quatro momentos dentro de esta fase:
Criação dos tópicos do agente ­ nessa fase é feita a seleção dos tópicos a serem desenvolvidos.
A documentação gerada na fase de desenvolvimento é analisada, junto com a equipe de design, para que os tópicos possam ser identificados e o seu conteúdo-base, elaborado.
Em esse contexto, podem ser analisados modelos de IHC, diagramas UML, versões preexistentes do sistema de ajuda e/ ou manuais, entre outros.
Com essa análise, espera- se cobrir todas as funcionalidades do aplicativo, e criar os tópicos da forma mais completa possível.
Adaptação das elocuções ­ nesta fase, os tópicos do sistema de ajuda são adaptados, levando em conta os termos aferidos na primeira fase (levantamento do perfil do usuário surdo) para a adaptação dos termos técnicos e da linguagem utilizada no sistema de ajuda para as expressões utilizadas por o usuário surdo, tanto num contexto geral de consulta (expressões de dúvida) quanto de um contexto específico (termos relacionados ao domínio do aplicativo).
Divisão dos tópicos em unidades menores ­ os tópicos dos sistemas de ajuda são, em geral, extensos e difíceis de serem acompanhados por os usuários.
Além disso, os sistemas de ajuda, em geral, contemplam somente o aspecto funcional do mesmo, deixando de lado outros aspectos, como finalidade da funcionalidade dentro de o contexto da tarefa (Para que serve isto?)
ou acompanhamento do andamento da funcionalidade (Onde eu estava?
E agora?).
Para esses tópicos ficarem mais fáceis de serem acompanhados, devem ser divididos em subtópicos, cada um com um passo simples de ser conduzido.
Modelagem da persona do agente conversacional ­ conforme o perfil levantado por a equipe de desenvolvimento do agente de ajuda junto aos designers do aplicativo, serão desenvolvidas as características para a persona do agente conversacional.
Aqui, serão elaborados alguns itens componentes do banco de diálogos do agente, a fim de tornálo uma entidade crível (como história de vida, reações a determinados temas, etc.);
Estes componentes serão fundamentais para uma segunda adaptação das elocuções do agente de ajuda, a qual será feita no momento seguinte.
Adaptação das elocuções (2ª parte) ­ neste momento, será feita a criação de novos diálogos, que reflitam a persona do agente, bem como a adaptação dos tópicos anteriormente elaborados para alinhamento com esta.
Após essa fase, haverá um protótipo de agente de ajuda, pronto para ser usado junto ao aplicativo que por ele é abordado.
Então, na próxima fase, deve- se buscar junto aos usuários subsídios para verificar se todos os aspectos do agente foram corretamente projetados e executados.
Para tal, devem ser conduzidos testes com os usuários-alvos;
Esta fase será descrita no próximo tópico.
A fim de avaliar o agente e verificar a sua efetividade junto aos usuários surdos são previstos, nesta fase, algumas atividades com o mesmo.
Para isto devem- se ter bem claros quais são os objetos de avaliação.
Assim, serão dois os aspectos avaliados no agente de ajuda:
Diálogos do agente de ajuda ­ os diálogos do agente de ajuda devem ser avaliados junto aos usuários surdos quanto a alguns fatores:
Clareza sintática ­ os tópicos devem estar numa linguagem acessível para o usuário, sendo eficazes para a solução de seus problemas.
Para isso, deve- se aferir se as expressões coletadas na Fase A (levantamento do perfil do usuário surdo) estão corretas, ou são suficientes.
Caso elas sejam, passase para o próximo momento dos testes.
Senão, devem ser feitas novas elicitações com o usuário (Fase A_ 1) para, após outra coleta de expressões, serem executados ajustes adicionais nos diálogos do agente de ajuda (B_ 2).
Clareza semântica ­ os tópicos devem estar claros, precisos e simples;
Deve- se ter levado em consideração a divisão do mesmo em subtópicos atômicos (isto é, cada subtópico correspondendo a uma única ação dentro de a interface do aplicativo) a fim de tornar a assimilação dos conceitos mais efetiva.
Caso seja detectado que um subtópico não foi corretamente dimensionado, volta- se ao passo B_ 5 (adaptação das elocuções ­ 2ª parte) para efetuar as devidas correções.
Persona do agente de ajuda ­ a persona do agente de ajuda, no contexto deste trabalho, é de fundamental importância para que os usuários surdos venham a aceitar o agente enquanto interface, interagindo sem reservas com este e aumentando o grau de confiança no aplicativo.
Dois aspectos devem ser considerados, no contexto da persona do agente de ajuda:
Aceitação da persona ­ será avaliado o conforto e a aceitação dos usuários surdos em relação a a persona do agente de ajuda.
Caso os usuários não se mostrem satisfeitos, e acusem desconforto ou estresse no trato com a persona do agente de ajuda, retorna- se ao item A. 4 (Modelagem da persona do agente conversacional), a fim de identificar os problemas na modelagem da mesma.
Realismo da persona ­ é avaliado, junto aos usuários, se as interlocuções do agente correspondem a uma persona realista, que dê ao usuário o que é chamado de &quot;ilusão de vida».
Caso haja algum aspecto da interlocução que não esteja de acordo com a persona do agente de ajuda, então se retorna para o item A. 5 (Adaptação das elocuções -- 2ª parte).
O método proposto foi utilizado através da construção de um protótipo de agente de ajuda para usuários surdos.
Em a condução desta aplicação foi utilizada uma metodologia qualitativa para a aferição e análise dos resultados, visto que o grupo de usuários-alvo desse método é bastante restrito, a saber, pessoas surdas.
Assim, o objetivo não é conseguir dados discretizáveis, mas aferir a opinião dos usuários a respeito de o agente de ajuda produzido, e recolher subsídios para a melhoria do método e do agente, principalmente em relação a a apresentação do conteúdo e à linguagem utilizada.
Como esses dados são bastante subjetivos, e, conforme mencionado, o número de usuários é restrito, a metodologia qualitativa se mostrava mais adequada para este contexto.
Durante a realização desta pesquisa foram promovidos oito encontros entre o pesquisador e os usuários, sempre acompanhados da professora-intérprete, para fins de tradução dos diálogos.
Os primeiros quatro encontros foram promovidos numa tentativa de familiarização dos usuários com o pesquisador e com as atividades a serem executadas.
Esse passo foi necessário por causa de a renitência dos usuários em aceitar a execução de atividades junto a um pesquisador ouvinte, que não os conhecia e que, na visão de eles, veio para &quot;julgar «a sua maneira de se comunicarem na forma escrita.
Após ter sido vencida essa barreira inicial, foram conduzidos mais quatro encontros, sendo um para o levantamento do perfil do usuário e os outros três para a avaliação do agente de ajuda gerado por o método, conforme será detalhado numa seção posterior.
A seguir, são descritas as atividades realizadas na aplicação do método proposto, através do detalhamento de cada uma de suas fases.
Em esta fase, são previstos dois momentos distintos:
A elicitação com os designers do aplicativo, a fim de obter dos mesmos o domínio do aplicativo, e a elicitação com os usuários (Fase A_ 2), a fim de conhecer as expressões interrogativas e de domínio do aplicativo por eles utilizadas.
Além disso, notou- se que os usuários, ao construir as frases no diálogo, utilizam os verbos escritos em três flexões diferentes:
Infinitivo (como em &quot;Como botar amigo? «(Usuário 5), presente -- primeira pessoa do singular (como em &quot;Não eu gosto só inter». (
Usuário 3) e presente -- terceira pessoa do singular (como em &quot;eu ficou bate papo «(Usuário 2).
O aparecimento do verbo num destes tempos varia de usuário para usuário, visto que eles não flexionam o verbo conforme o sujeito da ação.
Em o exemplo dado acima, podem ser vistos ver os caracteres&quot;* «(asterisco) e « «(sublinhado) atuando como wildcards.
De fato, estes são os caracteres coringa permitidos por o AIML, e podem ser substituídos por qualquer seqüência de caracteres.
Em o caso, esse trecho de código devolve a resposta &quot;Tell me about».
para qualquer frase que contenha a palavra &quot;mother «(mãe), estando a palavra chave prefixada, infixada e pós-fixada dentro de as expressões de avaliação (tag assim como sozinha.
A AIML é considerada uma linguagem de marcação de fácil utilização com eficiência comprovada, por ter uma estrutura bastante simples do ponto de vista computacional, porém com desempenho superior ao das duas outras gerações de linguagens de marcação de diálogos.
Em relação a o parser utilizado, foi escolhido o interpretador gratuito disponibilizado por o site Pandorabots, que hospeda chatterbots desenvolvidos em AIML e oferece alguns serviços para a criação otimizada de agentes conversacionais.
Provisoriamente, o agente foi batizado como &quot;Micro, o Robô de Ajuda do MSN», tendo um avatar (foto do personagem) em formato cartoon.
O formato da interface é similar às salas de bate-papo atuais, simplificada apenas a uma caixa de texto, acima de a área de diálogo (Figura 6.5).
Apesar de o desenvolvimento inicial ter sido baseado apenas na primeira fase da elicitação, o mesmo se tornou contínuo e iterativo, conforme a fase de testes com os usuários acontecia.
Isto se deve ao fato de que alguns ajustes tiveram de ser feitos, em relação a as respostas (correspondentes aos tópicos do sistema de ajuda) do agente conversacional.
Por isso, pode- se dizer que as duas fases foram executadas em paralelo.
Em essa primeira fase do desenvolvimento do agente conversacional, os tópicos foram retirados diretamente do sistema de ajuda original do MSN Messenger, e modelados para a linguagem AIML.
Uma adaptação inicial foi feita em torno desses tópicos, levando em conta o léxico particular dos usuários surdos, aferido na primeira fase do método (Tabela 6.2).
Nota- se, pois, que o protótipo foi desenvolvido com atenção aos modelos de elocução próprios dos surdos, em qualquer estágio de aprendizado da língua oral-escrita.
Assim como na Libras, também na interação com o agente os surdos escrevem, muitas vezes, as frases em formações diferentes da SVO (Sujeito-Verbo-Objeto), como na frase dita por o Usuário 5 &quot;por que trista (sic) tu «(Por que tu estás triste?),
utilizada por um dos usuários ao conversar com o pesquisador, na fase de elicitação do usuário.
Após o desenvolvimento do primeiro protótipo, fez- se uma avaliação prévia do agente, buscando, ao mesmo tempo, subsídios para resolver as lacunas de comunicação nas respostas do mesmo.
Para a etapa de validação do método, foi solicitado aos usuários, um a um, que executassem algumas atividades junto ao MSN Messenger.
Para solucionar as dúvidas que eles por acaso tivessem na execução das atividades, eles interagiam com o protótipo de agente de ajuda conversacional criado na fase anterior.
Os usuários foram observados, e seus diálogos com o agente de ajuda foram registrados, para posterior análise e execução de modificações no mesmo.
As atividades foram as seguintes:
O usuário deverá formatar a fonte de conversação do MSN Messenger para:
Fonte: Times New Roman (Itálico) Tamanho:
16 Cor:
Vermelho b.
O usuário deverá trocar a sua imagem de exibição no MSN Messenger para outra, que estará disponível em Os usuários tentaram executar as atividades com o auxílio do protótipo do agente de ajuda gerado, mas algumas respostas apresentadas por o agente não eram totalmente compreendidas por os usuários.
Quando questionados, os usuários surdos apontaram a complexidade da resposta dada por o agente como o principal problema (Usuário 2: &quot;Português «difícil», Usuário 6: &quot;Entender difícil muito&quot;) visto que o nível do Português usado nas frases tornava- as muito difíceis de serem interpretadas por os usuários.
Assim, foram apontadas, por os usuários, duas medidas a serem adotadas para melhoria do agente de ajuda:
Inclusão de screenshots da interface, para localização das funcionalidades.
Simplificação do Português utilizado, para sua melhor compreensão por parte de o usuário.
Após, foram aferidas as impressões da professora-intérprete, que apontou mais duas medidas para a melhoria do agente de ajuda:
Destacamento dos termos-chave do tópico em cor diferente, para chamar a atenção do usuário.
Divisão do tópico em unidades menores, seqüenciais, conforme já preconizado por Farkas.
Terminada a primeira iteração dos testes, passou- se à segunda iteração do desenvolvimento do agente de ajuda.
Após, submeteu- se novamente o agente à avaliação dos usuários, a fim de avaliar se as modificações efetuadas surtiram algum efeito.
Em a segunda iteração, uma metodologia semelhante à da iteração anterior foi utilizada:
Uma série de atividades foi proposta aos usuários, sendo que eles poderiam utilizar o agente de ajuda para tirar as suas dúvidas quanto a a utilização do aplicativo.
Enquanto os testes eram feitos, o pesquisador e a professora-intérprete observavam o comportamento do aluno e suas interlocuções.
A o final das atividades, um questionário (Apêndice C) foi respondido por os participantes, para aferir o que ainda precisava ser feito para melhorar o método e o agente de ajuda, e questionar a necessidade da inclusão de uma persona no agente conversacional.
As atividades executadas foram as seguintes:
O usuário deverá trocar a sua imagem de exibição no MSN Messenger para outra, que estará disponível em b.
O usuário deverá a inserção de um novo emoticon no MSN Messenger, que estará disponível em Os usuários, ao interagirem com o agente de ajuda para realizar as atividades, tiveram uma maior compreensão em relação a as respostas dadas por ele.
Disseram que o texto estava mais simples e fácil (&quot;simples «(Usuário 2), &quot;mais fácil «(Usuário 1), mas que ainda precisava de uma simplificação adicional em relação a o Português utilizado nas respostas do agente de ajuda.
A divisão do texto em tópicos menores também foi bem aceita por os usuários, e foi apontada por dois destes como uma melhoria adequada às respostas do agente de ajuda.
Contudo, apenas um usuário conseguiu achar por si os links com os screenshots, o que mostrou a ineficiência desta forma de acesso à informação.
A professora-intérprete, ao final das atividades com o agente, mostrou para os usuários que não haviam percebido os links a sua localização e funcionalidade.
Assim, todos tiveram oportunidade de ver os screenshots, constatando em unanimidade a sua valia para a localização das funcionalidades dentro de a interface.
Considerando isto, os usuários sugeriram as seguintes modificações no agente de ajuda:
Ao invés de os screenshots serem acessíveis por meio de um link textual, utilizar uma miniatura ou parte da figura, com a informação mais importante à mostra.
Caso seja necessário ampliar, para que o usuário se localize melhor, o link para a figura no tamanho original e completa estará disponível.
Simplificar o texto ainda mais, deixando- o num Português conciso.
Quanto a a inclusão de uma persona no agente de ajuda, os usuários foram questionados a respeito e indicaram, por unanimidade, que gostariam de poder interagir mais com o agente, entrando em outros assuntos que não só as dúvidas surgidas do uso de algum aplicativo.
Em relação a a persona que seria utilizada, 4 (quatro) usuários disseram que gostariam de que a aparência e identidade do agente fosse mantida (Micro, o Robô), enquanto 2 (dois) disseram que gostariam que o agente tivesse a aparência e o comportamento de um jovem de sua faixa etária.
Aferidos os subsídios que surgiram na segunda validação, novamente se passou ao desenvolvimento do agente de ajuda, desta vez voltados para a inclusão de novos tópicos, referentes à persona do mesmo.
Assim, alguns módulos de conversação geral foram incluídos, a maioria por sugestão dos usuários na fase anterior:
Amizade, futebol, estudos, internet e surdos.
Além disso, foram acrescentados alguns módulos de conversação para cumprimentos em geral, como saudações e agradecimentos, para imprimir uma maior naturalidade às conversações, e um módulo de identificação, sobre a persona adotada por o chatterbot, que acabou continuando, por escolha dos usuários, como &quot;Micro, o Robô de Ajuda do MSN».
Cuidou- se que as respostas fossem randômicas para cada tópico abordado, e que houvesse uma continuidade na conversação.
Usuário 3: Oi Micro:
Oi! Meu nome é Micro!
Posso ajudar você a usar o MSN?
Usuário 3: Foto troca quero Micro:
Para trocar a sua foto no MSN:
Clique com o botão esquerdo do mouse onde aparece o seu nome, no MSN.
Depois, clique em &quot;Alterar Imagem de Exibição».
Vai abrir um lugar para você escolher a foto que quiser.
Clique na foto que você quer com o mouse, e depois, clique no botão &quot;OK».
Usuário 3: Obrigado Micro:
De nada, você merece!
Após, passou- se para a terceira e última iteração de validação do agente de ajuda.
Em a terceira iteração do agente de ajuda, foram dois os objetivos principais:
Primeiro, ver se os screenshots inclusos no corpo de texto do tópico seriam mais eficazes para localizar o usuário em relação a a posição da funcionalidade na interface.
Segundo, e principalmente, verificar se a inclusão de uma persona no agente de ajuda tornaria a interação mais agradável para os usuários surdos ou se tornaria a mesma irritante, penosa ou mesmo se suscitaria distrações indesejadas.
A fim de verificar tais fatores, foi usada exatamente a mesma metodologia da segunda iteração, isto é:
Observação dos usuários a utilizar o agente de ajuda, quando de a execução de atividades específicas, junto da professora-intérprete.
Em seguida, a aplicação de um novo questionário (Apêndice D), o qual é interpretado junto ao usuário por a professora.
As atividades executadas foram as seguintes:
O usuário deverá trocar a sua imagem de exibição no MSN Messenger para outra, que estará disponível em\&gt; b.
O usuário deve acionar a sua câmera, a fim de exibir as suas imagens para seu interlocutor.
Assim, os usuários interagiram com o sistema de ajuda da seguinte maneira:
Cada um de eles teve algum tempo (em média 5 minutos) para experimentar os diálogos da persona do agente de ajuda (figura 6.9).
Após, foram feitas as atividades propostas, numa média de 15 minutos para cada usuário, para fins de observação.
Por último, foi respondido o questionário, com o auxílio da professora-intérprete.
Em a observação feita, notou- se que os usuários tiveram uma melhor impressão do agente de ajuda, resultando numa interação muito mais proveitosa com ele.
Os assuntos cobertos por a persona do agente de ajuda agradaram aos usuários, sendo que todos eles, durante a interação, disseram que o robô era mais natural, parecendo uma pessoa.
As atividades, dessa vez, não apresentaram nenhuma dificuldade para os usuários, que aprovaram, unânimes, o uso dos screenshots no meio de o texto, sendo mais fácil para eles localizar as funcionalidades.
A sua satisfação foi refletida em suas respostas ao questionário.
Quando questionados a respeito de o quão agradável havia sido a sua interação com o agente de ajuda, todos responderam que tinha sido &quot;muito bom «ou &quot;legal».
A possibilidade de diálogo natural com o agente foi muito apreciada:
&quot;agora muito bom, parecer falar pessoa verdade», &quot;robô muito legal, eu passar madrugada falando com robô».
Os usuários, ao interagirem com o agente de ajuda para realizar as atividades, tiveram uma ótima compreensão às respostas dadas por o agente.
Disseram que o texto estava num nível adequado e, associados às ajudas visuais dos screenshots, deram uma perfeita compreensão de como acionar as funcionalidades.
O método foi bem sucedido, no âmbito de criar um agente de ajuda para usuários surdos, levando em conta as suas particularidades de elocução.
Porém, alguns aspectos devem ser considerados, no fechamento desse capítulo.
Em o princípio, pensava- se em aplicar o método linearmente, isto é, uma fase após a outra, sem interpolação das mesmas.
Porém, nas fases de avaliação do agente de ajuda, começaram a surgir subsídios importantes para o desenvolvimento do mesmo, como as expressões próprias do domínio (as quais não foram passíveis de serem capturadas na fase de elicitação dos usuários), e mesmo as sugestões de inclusão de screenshots para a localização das funcionalidades.
Assim, as fases de desenvolvimento e avaliação do agente acabaram ocorrendo concomitantemente.
Ademais, não foi previsto no método um período para ambientação dos usuários surdos, já que os mesmos mostraram- se resistentes à idéia de mostrar as suas produções textuais em Português, inicialmente.
Foi necessário muito tempo junto dos usuários, para ganhar a sua confiança e fazer com que eles deixassem de enxergar a pesquisa como uma &quot;intrusão do mundo ouvinte «no cotidiano de eles.
Essa fase deve ser acrescentada ao método, numa versão futura.
Dentro deste âmbito, as fases do método ficariam assim descritas:
Fase de adaptação dos usuários à convivência com o pesquisador:
Em essa fase, os usuários surdos tomam conhecimento do objetivo do agente de ajuda, de como ele poderá ajudar- los a cumprir as suas tarefas no âmbito daquele aplicativo, entre outras coisas.
Fase de levantamento do perfil do usuário surdo:
Em essa fase, em a qual não houve modificações, são levantadas as informações necessárias para que o agente possa suprir as necessidades especiais dos usuários surdos, referentes à sua comunicação e ao seu conforto em utilizar o sistema de ajuda.
Aqui são capturadas as Os aplicativos computacionais se tornaram ferramentas do cotidiano da maioria das pessoas, atualmente.
Em as atividades domésticas, acadêmicas ou profissionais, eles estão presentes, e quem não possui, por qualquer motivo, o domínio sobre essas ferramentas, acaba por se tornar obsoleto e pode ser facilmente suplantado por um concorrente que tenha o conhecimento destas.
Mas, diante desse panorama, muitas pessoas acabam por não ter acesso aos aplicativos computacionais, por variados motivos.
Um dos motivos para esse fenômeno é a falta de acessibilidade dessas ferramentas, para pessoas que tenham necessidades especiais.
Desta feita, muitas pessoas acabam por não utilizar os aplicativos para as suas atividades, ou utilizam de maneira pouco produtiva.
De as pessoas com necessidades especiais, os surdos são um dos grupos prejudicados com a falta de acessibilidade desses aplicativos, porque as interfaces destes são concebidas para pessoas ouvintes, e modeladas com a língua oral-escrita dos mesmos.
Não há uma maior preocupação em conceber interfaces que comportem línguas viso- gestuais.
As notações escritas para tais línguas existem, mas não alcançaram, ainda, a grande maioria das pessoas surdas.
De fato, em todos os contextos, os surdos continuam a se utilizar das línguas oral-escritas, ao registrar as suas produções textuais.
Por causa de isto, os surdos lidam com um obstáculo, cada vez que interagem com um aplicativo, por que são obrigados a ler e raciocinar através de uma língua que não é a sua materna, e que não pertence sequer ao mesmo paradigma da língua apresentada na interface.
Em esse contexto, os sistemas de ajuda podem ser de grande valia para o aumento da usabilidade e da acessibilidade de uma ferramenta computacional.
O sistema de ajuda é a funcionalidade que está mais próxima do pensamento e da concepção da interface promovidos por os designers da interface, visto que ali tudo é explicado diretamente em linguagem natural, sem metáforas ou ícones.
Podendo- se facilitar a transmissão dos tópicos do sistema de ajuda para o usuário surdo, ele teria condições de aumentar o seu desempenho e a sua satisfação, porque compreenderia todos os aspectos da interface.
