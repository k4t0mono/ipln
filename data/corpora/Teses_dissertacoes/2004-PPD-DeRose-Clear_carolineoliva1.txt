Processamento paralelo pode ser um forte aliado na obtenção de animações em menor tempo ou na melhoria de qualidade das imagens geradas através de simulação de sistemas de partículas, devido a a natureza paralela das partículas.
Este trabalho descreve o modelo cujo intuito é auxiliar os usuários na utilização de máquinas agregadas, especialmente heterogêneas, no processo de criação de simulações com diversos sistemas de partículas.
O modelo é destinado à simulação de partículas independentes e provê mecanismos de balanceamento de carga dinâmicos.
A validação do modelo é feita através da comparação de resultados (tempo para obtenção das imagens) extraídos de execuções seqüenciais e paralelas de uma biblioteca implementada sobre o mesmo.
Fenômenos como fumaça, vapor, neblina, poeira e vento compõem a percepção visual diária dos seres vivos dotados de visão e podem aumentar significativamente o realismo de imagens artificiais.
Quanto mais simples estes fenômenos, mais complexa e difícil é a simulação dos mesmos.
O estágio tecnológico atual, tanto dos equipamentos como das aplicações, viabiliza a construção de aplicações gráficas outrora impraticáveis.
No entanto, a combinação de diversas técnicas, a expansão no volume de dados a serem representados e a necessidade de interação entre os objetos podem resultar em longas horas de espera por o resultado final.
Sistemas de partículas podem ser considerados como uma técnica geral dentro de o campo da computação gráfica, capaz de criar uma grande variedade de efeitos e objetos disformes, tais como água, fumaça, grama, nuvens, de entre outros.
Estes efeitos ocorrem em decorrência de uma série de aspectos físicos, que se considerados em sua totalidade podem implicar em alto poder computacional.
Com a popularização de redes de conexão rápida, torna- se possível distribuir o volume de dados a serem processados entre diversas máquinas e, com isso, aumentar as chances de obtenção de melhor desempenho das aplicações.
Atualmente, encontram- se disponíveis sistemas de alto desempenho que abrangem desde processadores fortemente acoplados, denominados Massively Parallel Processors, até simples redes de computadores.
A exploração de computação paralela e características de arquiteturas de 64 bits pode possibilitar a redução do tempo de obtenção ou aumento do realismo físico e detalhamento gráfico das imagens em animações através de sistemas de partículas.
Porém, programas paralelos são caracterizados por diferentes atividades concorrentes, comunicação e sincronização entre atividades e processos executados em diversas máquinas, tornando a programação paralela uma tarefa difícil.
Visando facilitar a utilização de arquiteturas de alto desempenho, este trabalho descreve um modelo para realização de simulação de partículas em máquinas agregadas, ou clusters, heterogêneas, embora não exista impedimento de utilização do mesmo em sistemas homogêneos.
Os tópicos a seguir apresentam uma rápida introdução às máquinas agregadas, os objetivos visados por este trabalho e a organização do restante do documento.
Um sistema computacional de alto desempenho baseado na replicação eficiente de componentes &quot;de prateleira «tem a razão custo/ desempenho melhor do que sistemas como, por exemplo, supercomputadores.
A replicação dos componentes permite que um sistema seja incrementado, ou atualizado, à medida que exista demanda por parte de as aplicações, evitando assim, a subutilização do mesmo.
Além destes fatores, também é possível utilizar os sistemas em áreas não relacionadas à computação gráfica, ao contrário de os supercomputadores, que na maioria são destinados para um tipo específico de aplicação.
Conceitualmente, uma máquina agregada é uma coleção de computadores (máquinas pessoais, estações de trabalho ou servidores), chamados nós, fisicamente interconectados por uma rede local ou uma rede de alto desempenho.
As aplicações são disparadas a partir de uma máquina hospedeira, que pode pertencer ou não ao agregado.
Os nós normalmente não possuem periféricos acoplados, pois são utilizados exclusivamente para obtenção de alto desempenho na maioria das vezes.
Uma importante característica dessas máquinas é o fato de não possuírem memória compartilhada, uma vez que são construídas a partir de a replicação de toda a arquitetura convencional, e não apenas da replicação do processador como ocorre nas demais arquiteturas multiprocessadas.
Essas máquinas são classificadas como multicomputadores do tipo Norma (Non-Remote Memory Access), pois não é possível a utilização de variáveis compartilhadas entre os nós neste ambiente.
A conexão entre os nós do agregado pode ser feita através da utilização de rede padrão (e.
g Ethernet, Fast-Ethernet), ou através de redes de baixa latência, tais como Myrinet e SCI (Scalable Coherent Interface).
Segundo, as máquinas agregadas apresentam ótima relação custo/ benefício, apresentando um dos menores custos por Mflop/ s (milhões de instruções de ponto flutuante por segundo) entre as arquiteturas paralelas, alto grau de configurabilidade e baixo custo de manutenção.
No entanto, a programação de máquinas Norma torna- se complexa, pois transfere para o programador a tarefa de manipular, eficientemente, múltiplos processadores que compartilham dados através de uma rede de comunicação.
Outro fator que dificulta a utilização de máquinas agregadas é o crescente aumento no número de agregados heterogêneos, isto é, agregados compostos por nós de diferentes tipos (arquitetura, velocidade, quantidade de memória, etc).
Embora sejam alternativas atrativas, permitindo atualizações ao agregado sem a necessidade de abandono do equipamento antigo, a utilização destas máquinas implica num maior controle da aplicação por parte de o programador, para que as diferenças entre as capacidades de processamento dos nós sejam compensadas.
Máquinas agregadas compostas por estações de trabalho SMP (symmetric multiprocessor), interconectadas por redes chaveadas de alto desempenho, estão se tornando uma alternativa atrativa para a execução de aplicações de alta demanda computacional.
Este tipo de máquina paralela é, normalmente, assumido como sendo homogêneo.
No entanto, por razões tecnológicas e financeiras, as atualizações feitas sobre uma máquina agregada inicialmente homogênea podem resultar numa máquina heterogênea que abrange diversas tecnologias, inclusive nós não SMP.
Este é o caso do agregado Amazônia, existente no Centro de Pesquisa em Alto Desempenho (CPAD), localizado na Pontifícia Universidade Católica do Rio Grande do Sul (PUCRS).
Este agregado foi utilizado nos testes de validação do modelo desenvolvido e será detalhado ao longo deste documento.
A qualidade gráfica e o realismo físico de uma simulação podem ser limitados por o fator tempo, conforme a disponibilidade de equipamentos para realização dos cálculos necessários.
Em muitos casos, o animador é obrigado a reduzir o realismo em detrimento de o detalhamento gráfico, ou vice-versa.
À medida que ocorre redução do realismo físico em favor de o tempo de obtenção das imagens, as simulações passam a ser aproximações da realidade que representam, partindo de configurações iniciais específicas, aplicadas por o animador sobre grupos de partículas.
Ao longo de a simulação, as partículas sofrem alterações com base em suas configurações, porém estas modificações não determinam o comportamento de partículas vizinhas, devido a a redução de cálculos de aspectos como colisões entre as partículas.
É comum encontrar em animações somente testes de colisão entre partículas com alguns poucos objetos estáticos, externos ao sistema de partículas.
Devido a a natureza paralela das partículas, as mesmas são apropriadas para a computação paralela e distribuída.
A divisão do volume a ser calculado e a possibilidade de processamento simultâneo das partes permitem a redução do tempo de obtenção das animações ou aumento do realismo e detalhamento gráfico.
As modernas arquiteturas de 64 bits como Itaniums, por exemplo, permitem a expansão do espaço de endereçamento, maior precisão e rapidez nos cálculos com ponto flutuantes e aumento na vazão dos dados entre o processador e a memória.
Em o passado recente, máquinas agregadas formadas por computadores pessoais de prateleira ganharam grande importância no campo da computação gráfica.
À medida que cresce a disponibilidade deste tipo de arquitetura, torna- se interessante a formulação de modelos que auxiliem na utilização deste tipo de equipamento.
O objetivo deste trabalho é facilitar a utilização de máquinas agregadas heterogêneas em animações por sistemas de partículas através da descrição de um modelo paralelo para desenvolvimento de aplicações, dada à tendência de aumento da disponibilidade deste tipo de equipamento e ao fato de que, normalmente, os usuários que mais se beneficiam do uso deste poder de processamento não possuem conhecimentos específicos na área.
O modelo tem por objetivo a obtenção de melhores resultados nas simulações em relação a a questão comportamental das partículas, bem como ganho de desempenho na obtenção das imagens.
Além de a divisão do problema em fatias que possam ser processadas paralelamente, o modelo também trata questões provenientes da diferença de capacidade de processamento através da utilização de mecanismos de balanceamento de carga.
Embora o modelo não defina os mecanismos a serem adotados quando houver interesse em se detectar colisão entre as partículas, o mesmo estabelece regras de partição do espaço que permitem que os cálculos necessários em tal procedimento sejam efetuados de forma eficiente.
O modelo não propõe novos algoritmos a serem utilizados em sistemas de partículas e, também, não deve servir como base de algoritmos de geração de efeitos, bem como algoritmos relacionados à representação gráfica das partículas (cor, transparência, etc).
Este documento está organizado em sete capítulos.
O segundo capítulo apresenta os fatores principais em animações por sistemas de partículas.
O terceiro descreve algumas soluções disponíveis relacionadas à simulação paralela de sistemas de partículas.
O quarto detalha o modelo desenvolvido, enquanto o quinto apresenta a biblioteca desenvolvida para validação do modelo.
Em o sexto capítulo são apresentados os resultados de testes efetuados com a biblioteca sobre o agregado Amazônia, anteriormente mencionado.
Em o sétimo e último capítulo são apresentadas as conclusões provenientes do trabalho, bem como idéias para trabalhos futuros.
Quando perguntado a respeito de a cena de maior dificuldade de obtenção do filme Shrek, Jeffrey Katzenberg, produtor do filme e chefe da DreamWorks SKG, deu a seguinte declaração:
&quot;derramar leite num copo».
A citação acima ilustra a necessidade de simulação e obtenção de imagens foto realistas, especialmente em casos de comportamento tridimensional complexo.
A modelagem de fenômenos tais como nuvens, fumaça, água e fogo através das técnicas de síntese de imagens por computador tem- se mostrado uma tarefa difícil.
Estes &quot;objetos disformes «não têm superfícies bem definidas, lisas e lustras;
Ao contrário, são irregulares, complexas e mal formadas.
Seus movimentos não podem ser descritos através das transformações comuns em computação gráfica.
Outra razão para a busca por outras formas de modelagem de objetos e seus comportamentos decorre do fato de objetos naturais exibirem uma imensa variedade de formas irregulares e variações em seus detalhes, contrastando com objetos fabricados por o homem.
A utilização de modelos estocásticos permite a representação desta variedade em imagens sintéticas e sistemas de partículas são apropriados para a construção de modelos não deterministas.
Através do uso de partículas também é possível modelar objetos bem e mal definidos e criar efeitos como motion blur (falta de clareza na imagem).
Este capítulo descreve, de forma sucinta, os conceitos relativos aos sistemas de partículas, classificações, propriedades e operações aplicadas sobre os mesmos.
Um sistema de partículas é um conjunto de partículas momentâneas que em conjunto podem representar objetos sem fronteiras delimitadas (gases) e objetos dinâmicos (árvores).
Dentro de um período de tempo ou tempo de vida das partículas, as mesmas são geradas no sistema, movidas e modificadas e, por último, removidas do sistema.
Cada partícula tem suas características como cor e posição e é passível de sofrer alterações em seus atributos com o passar do tempo.
Uma simulação baseada em sistemas de partículas pode ser composta por diversos sistemas de partículas.
Esses sistemas permitem a criação de estruturas e movimentos complexos, a partir de descrições abstratas relativamente breves, e a produção de efeitos dificilmente alcançados através de objetos tradicionais compostos de superfícies e animados através de movimentos não processuais.
Dependendo da aplicação alvo, as partículas podem ser independentes, interdependentes ou, ainda, interdependentes e hierarquizadas.
Inicialmente, sistemas de partículas foram propostos por William T. Reeves em como uma maneira de modelar chamas e outros objetos que não possuíam fronteiras delimitadas.
O método original era baseado em processos estocásticos, onde cada partícula era independente e movia- se conforme suas características, sobre a influência de campos de força e limites.
Reeves partiu da hipótese da inexistência de interação entre as partículas de um sistema.
Sistemas de partículas estruturados usados para modelar objetos como árvores e grama também foram descritos em, estipulando relações entre as partículas tornando- as interdependentes.
Karl Sims estendeu o trabalho de Reeves e permitiu que partículas independentes interagissem com o ambiente permitindo a recriação de cascatas, por exemplo.
Os métodos propostos até então modelavam os objetos em relação a o volume dos mesmos.
A partir de 1992, sistemas de partículas orientados passaram a modelar objetos em relação a suas superfícies, uma vez que os métodos baseados em splines e superfícies deformáveis necessitam que as superfícies sejam compostas de partes distintas.
Os métodos baseados em partículas permitem a junção e separação de superfícies sem a necessidade de intervenção manual ou nova parametrização.
Durante a evolução das técnicas utilizadas em sistemas de partículas, foram agregadas idéias provenientes de estudos de dinâmica molecular para permitir a modelagem de líquidos e sólidos, mecânica de fluídos e outras equações físicas tais como as equações de Navier--Stokes e Euler, para a modelagem de fenômenos gasosos como fumaça, vapor, neblina e poeira.
Em anexo, no final deste documento, são apresentados alguns exemplos de imagens obtidas a partir de a utilização de sistemas de partículas (Apêndice A).
As seções seguintes apresentam características gerais de sistemas de partículas e o processo de simulação e obtenção das imagens.
Cada partícula dentro de um sistema tem seus próprios parâmetros que influenciam significativamente nas propriedades das mesmas.
Em geral, um sistema de partículas e suas partículas têm parâmetros similares, mas com valores diferentes.
Para cada nova partícula gerada, o sistema deve determinar valor para propriedades da mesma.
A seguir são listadas algumas propriedades importantes:
Posição inicial (incluindo a orientação no espaço tridimensional e a localização central em x, y e z);
Movimentação inicial (incluindo velocidade, rotação, aceleração, etc);
Cor inicial (RGBT ­ Red Green Blue Transparência);
Forma (ponto, linha, esfera, cubo, retângulo, etc);
Volume; Tempo de vida (somente aplicável às partículas);
Posição da &quot;parte frontal «e da &quot;parte traseira «(somente aplicável às partículas).
A posição, forma e tamanho de um sistema de partículas determinam a posição inicial aleatória das partículas e suas faixas de movimentação.
Em um sistema esférico, as partículas se movem em direção a o mundo exterior, distanciando- se do centro do sistema de partículas.
Em sistemas circulares ou retangulares, as partículas movem- se para cima a partir de o plano x-y, mas podem desviar- se da vertical conforme um ângulo de &quot;ejeção «(outro parâmetro possível).
A Figura 1 ilustra este sistema de partícula.
A movimentação da partícula está restrita dentro de a faixa associada ao seu sistema de partículas.
A forma de um sistema de partículas pode ser um ponto, uma linha, um segmento, uma esfera, uma caixa ou um cilindro.
O movimento de um sistema de partículas é afetado por forças internas e externas, e os resultados de rotações e acelerações das partículas como um todo.
O sistema de partículas pode mudar sua forma, tamanho, cor ou outros atributos à medida que se desenvolve.
O tempo de vida de uma partícula define quantas fatias de tempo (quadros) a partícula permanecerá ativa no sistema.
Uma partícula tem ambas as posições frontal (cabeça) e traseira (cauda).
A cabeça é geralmente animada e a cauda segue a movimentação para a criação do efeito de motion blur, ao custo de tempos mais longos para geração das imagens.
As operações de animação sobre partículas podem tanto iniciar ou alterar a posição e a velocidade das partículas.
Em uma simulação puramente física, os valores seriam primeiramente iniciados e, então, para cada intervalo de tempo t, a velocidade seria alterada por acelerações externas tais como gravidade e, finalmente, a posição seria alterada.
No entanto, para movimentação controlada cinematicamente, a posição pode ser definida diretamente, independente do estado anterior ou da velocidade.
Às vezes também pode ser útil definir posições relativas a posições prévias, ou alterar a velocidade através de outros meios além de a aplicação de aceleração translacional.
Em geral, sistemas de partículas são primeiramente iniciados e a cada nova partícula são atribuídos valores para as suas propriedades.
Depois da etapa inicial, para cada quadro da animação, alguns dos parâmetros das partículas são atualizados utilizando uma base de regras, e as partículas resultantes são geradas graficamente.
O Algoritmo 1 apresenta o esboço de um possível laço de simulação geral para sistemas de partículas.
Algoritmo 1: Possível laço de simulação de um sistema de partículas.
1 Gerar e Iniciar partículas Selecionar um subconjunto de partículas Efetuar as operações para partículas do subconjunto Atualizar as posições usando as velocidades Gerar a prévia ou o quadro final Simulações mais complexas podem prover etapas de operações de reflexões (devoluções) de partículas mediante colisão tanto com objetos externos ao sistema, como com outras partículas.
Também podem apresentar estágios para geração de motion blur.
Os sistemas de partículas são classificados em três categorias, estocásticos, estruturados ou orientados.
As classificações são detalhadas nos tópicos a seguir.
Os sistemas estocásticos são apropriados para as simulações onde a cor e a transparência são o foco principal, onde as partículas são independentes umas das outras.
Como exemplo de utilização destes sistemas têm- se as simulações de fogo, fogos de artifício, fumaça, vapor, paredes de água, explosões, etc..
Os sistemas de partículas que modelam objetos como árvores e grama são estruturados (obedecem a uma hierarquia) e, conseqüentemente, as partículas não são independentes.
Cada árvore, por exemplo, é desenhada como um conjunto de segmentos de linhas, e possivelmente pequenos círculos, que constituem seus galhos e folhas.
Muitas relações complexas existem entre as partículas que representam os galhos e as folhas da árvore, uma vez que juntas devem formar um objeto tridimensional coerente Ainda assim, mecanismos estocásticos podem ser utilizados durante os processos de geração de sistemas de partículas estruturados.
No caso de o exemplo anterior, árvores, um processo aleatório poderia indicar as localizações dos galhos no tronco principal, dos sub-galhos e das folhas.
Se a intenção for gerar uma floresta, o processo aleatório pode criar uma base de dados de localização dar árvores e a classificação das mesmas (e.
g araucária, flamboaiã).
Outros parâmetros de controle, tais como a grossura dos galhos, são necessários para que as árvores tornem- se realistas.
Em o caso específico citado, o parâmetro poderia ser reduzido à medida que os galhos se distanciam do tronco da árvore.
Enquanto que sistemas de partículas são muito mais flexíveis do que superfícies deformáveis em relação a a organização das partículas em formas e topologias arbitrárias, na ausência de forças e limites externos, os sistemas de partículas tridimensionais apresentam a desvantagem de tendência de se organizarem para comporem sólidos, ao invés de superfícies.
A superfície da água, por exemplo, é sempre suave e bem definida, não importando a distorção que o volume de água possa estar sofrendo.
Os sistemas orientados buscam por maneiras de forçar as partículas a comporem superfícies, preferencialmente com ligações suaves entre as partículas.
Em alguns casos, são utilizadas combinações de métodos com o intuito de alcançar a aparência realista dos efeitos que se deseja gerar.
Em simulações de água, por exemplo, a superfície é modelada tanto por equações que definem as áreas bem comportadas, como por partículas para geração de gotas e turbulência na água.
Em muitos casos ocorre a sobreposição das duas técnicas, onde a equação limita o volume e as partículas permitem a geração de superfícies onduladas.
O método básico utilizado para desenhar os sistemas de partículas trata cada partícula como uma fonte de luz.
Cada partícula adiciona um pouco de luz ao pixel (picture element) que está cobrindo com atenuação da intensidade à medida que se distancia do observador.
Uma partícula atrás de outra partícula não é ocultada, ao contrário, também participa na coloração do pixel.
Algumas técnicas tratam o volume de visualização na forma de uma pirâmide, onde à medida que a imagem se distância do observador o nível de detalhe para sua representação pode ser reduzido, reduzindo a quantidade de memória e tempo necessário para gerar a imagem.
Ao dispor de equipamento gráfico avançado com funções para mapeamento de texturas e transparências, é possível gerar imagens com texturas e transparências complexas e alcançar resultados mais realistas e em tempo real.
A obtenção de imagens através de partículas ainda apresenta alguns problemas em relação a a aparência granular das imagens, ao invés de detalhes suavizados.
As funções de mapeamento de textura possibilitam gerar imagens de fogo e explosão, por exemplo, mais realistas, uma vez que texturas reais podem ser aplicadas aos efeitos.
Efeitos motion blur podem ser obtidos através de manchas lineares aplicadas a cada partícula independentemente.
O sistema de animação estabelece os valores da cabeça e da cauda de cada uma das partículas, apropriados para a velocidade do obturador desejado.
O mecanismo que gera as imagens produz uma faixa borrada para cada uma das partículas, interpolando os valores de cor e opacidade entre a cabeça e a cauda da partícula.
Outros atributos, como raio da partícula na cabeça e na cauda, também podem ser interpolados permitindo a geração de formas como cometas, fagulhas ou gotas de água.
A Figura 2 exemplifica este efeito.
Métodos que utilizam partículas para modelar superfícies tendem a construir triângulos a partir de o posicionamento das mesmas, para obtenção de superfícies mais realistas, possibilitando a aplicação de técnicas tais como Gourard e Phong sobre os triângulos.
Em simulações de líquidos, surgem algumas dificuldades quando objetos imersos são iluminados por superfícies refratárias complexas, fazendo com que o problema do transporte de luz seja difícil de ser resolvido.
A maioria dos sistemas para gerar as imagens negligência este tipo de iluminação e manipula este efeito através de aproximações.
No entanto, como a água e seus efeitos de iluminação são bem familiares, estas aproximações falham em tentar alcançar realismo.
Existem vários algoritmos de geração de imagens que podem tratar os caminhos de transporte de iluminação de forma apropriada, porém o custo computacional destas técnicas pode impedir a geração de certas imagens em tempo real.
Exemplos destes métodos são path tracing (rastreio de caminho), path tracing bidirecional e Metropolis Light Transport.
Durante a revisão bibliográfica para elaboração do modelo proposto, foram encontradas inúmeras aplicações que simulam sistemas de partículas, porém de forma seqüencial, pois normalmente as versões paralelas são proprietárias e a documentação das mesmas não se encontra disponível.
Constatou- se que muitos modelos foram construídos para tratar especificamente um efeito, ou uma classe de efeitos como fumaça, nevoeiro e nuvens, uma vez que o comportamento das partículas é bastante parecido.
A primeira aplicação encontrada, de Karl Sims, foi desenvolvida para ser executada num supercomputador para paralelismo de dados, chamado Connection Machine Cm-2, composto de 4000 a 64000 processadores, cada um com 32 Kbytes de memória e hardware para operações de ponto flutuante.
Cada um dos processadores recebe um conjunto de partículas sobre as quais são aplicadas as operações.
A aplicação apresenta um número pequeno de efeitos pré-definidos, não existe comunicação entre os processos com exceção da comunicação para a geração da imagem, ou seja, os processos se comunicam para determinar a cor de cada um dos pixels da imagem.
A aplicação permite a detecção de colisão com objetos sólidos, porém segundo o autor, os métodos utilizados são ineficientes.
Nenhum mecanismo de balanceamento de carga entre os processadores é utilizado.
As demais soluções paralelas encontradas serão apresentadas nos próximos itens.
A biblioteca desenvolvida por David K. McAllister, chamada Particle System API (Application Program Interface), será descrita com maior grau de detalhamento, pois a mesma foi escolhida como base para implementação e validação do modelo desenvolvido, detalhado no próximo capítulo.
Tecidos podem ser modelados como uma rede de partículas interconectadas.
Milhares de partículas são tipicamente necessárias para a composição de um pedaço de pano.
Um dos grandes desafios para a simulação de tecidos é obter interatividade (25 quadros por segundo), pois a mesma necessita de uma grande quantidade de tempo computacional e memória.
Uma das soluções é a utilização de máquinas agregadas.
Em, os autores descrevem duas possíveis estratégias para simulação de tecidos em máquinas agregadas, ambas utilizando a interface de programação paralela Athapascan, descrita em, (baseada em memória compartilhada).
A primeira estratégia divide o espaço em blocos, atribuindo cada bloco a um processador.
Em esta estratégia, as partículas não estão presas ao processador.
A segunda estratégia divide as partículas em blocos, associando cada bloco a um processador.
Desta forma, a quantidade de partículas nos processadores é a mesma para todos, permitindo que os autores assumam que o tempo computacional é o mesmo para todos os processos.
A primeira estratégia permite a execução de simulações onde a localidade dos dados é um fator importante nos cálculos de interação entre as partículas.
No entanto, em tecidos, a conexão entre as partículas permanece inalterada durante a simulação, ou seja, não ocorre perda de informação através da divisão das partículas em blocos, porém torna- se necessária a utilização de estruturas de dados para controle das ligações entre os diversos blocos de partículas.
Com base na utilização da segunda estratégia, os autores apresentam os métodos utilizados para obtenção do posicionamento, velocidade e aceleração das partículas a cada quadro da animação, a partir de a interação de cada partícula com suas vizinhas.
Os resultados do experimento, até o momento somente validado numa máquina multiprocessada (compartilhamento de memória entre os processadores), demonstram que o tempo de execução não depende somente da quantidade de processadores, mas também do tamanho dos blocos.
Quanto menores forem os blocos, maior necessidade de comunicação entre os processos para troca de informação a respeito de as alterações sofridas por as partículas que se conectam com outras, pertencentes a outros blocos.
O experimento ainda não foi validado numa máquina agregada, objetivo inicial do mesmo.
Dinâmica Molecular (DM) refere- se às técnicas computacionais aplicadas em simulações de partículas utilizadas para representar átomos ou moléculas.
Muitas áreas utilizam DM, tais como nanotecnologia, bioquímica, biologia molecular, entre outras.
Simulações de DM são computacionalmente pesadas, devido a o número de partículas e ao passo da simulação (escala de movimentação das partículas).
Em é apresentado um mecanismo paralelo para simulações gráficas interativas de Dinâmica Molecular.
O mecanismo usa MPI (Message Passing Interface) para comunicação entre os diversos processos, e a interação com o usuário acontece no processo mestre.
O mecanismo utiliza decomposição espacial das partículas, e os processos apenas comunicam- se com os seus vizinhos imediatos.
Em uma simulação bidimensional, por exemplo, os processes apenas comunicam- se com o processo vizinho à esquerda e à direita, uma vez que o espaço é dividido apenas num eixo.
Isto melhora o desempenho em arquiteturas com alta latência, como é o caso de máquinas agregadas.
O experimento foi testado em dois agregados:
Máquinas AMD Athlon XP2000 1,67 GHz conectadas por rede Fast Ethernet;
Máquinas Dual Pentium III Xeon 1,26 GHz conectadas por rede Gigabit Ethernet.
Os resultados para o primeiro tipo de máquinas demonstram ganho de desempenho médio de 1,61, 2,73 e 4,24, para dois, quatro e oito nós respectivamente.
O ganho não aumenta com o aumento do número de partículas a serem simuladas.
Os tempos de execução para o segundo agregado foram um pouco mais elevados, porém o speed-up demonstra a conveniência da utilização de uma rede de alta velocidade para este tipo de simulação.
Novamente, o ganho de desempenho manteve- se aproximadamente o mesmo com o aumento do número de partículas.
Simulação de interação entre partículas sólidas tais como grãos de areia são genericamente conhecidas como Simulações de Elementos Discretos.
Tais simulações são amplamente utilizadas quando modelos contínuos mais simples são inadequados e é necessário simular o sistema ao nível de partículas individuais.
A forma utilizada na simulação destes elementos é muito parecida à utilizada em simulações de dinâmica molecular, pois existem diversas partículas, relativamente estacionárias, e o tempo gasto para calcular as forças entre as partículas domina a simulação.
Em é apresentada uma solução híbrida para a simulação de elementos discretos que utiliza troca de mensagem e memória compartilhada.
O domínio é dividido em diversos blocos, e a cada processador é atribuído um conjunto de blocos.
A paralelização em relação a a memória compartilhada ocorre ao nível dos laços de execuções sobre as partículas de cada um dos blocos.
Valores globais como energia são primeiramente obtidos em paralelo dentro de um bloco, somados com os valores dos demais blocos pertencentes ao mesmo processador e, então, acumulados através dos processos por chamadas MPI coletivas.
O balanceamento de carga ocorre através da redistribuição de blocos, uma vez que os processos podem ter quantidades diferentes de blocos.
Os experimentos com a aplicação foram feitos numa máquina agregada composta por cinco nós Compaq ES40 SMP.
Os resultados obtidos demonstram que execuções MPI puras são mais eficientes do que a estratégia híbrida.
A palavra simulação refere- se a qualquer método analítico destinado a imitar um sistema real, especialmente quando outras análises são matematicamente muito complexas ou difíceis de reproduzir.
Simulações de Monte Carlo (MC) possibilitam uma melhor modelagem de certos sistemas através da geração aleatória contínua de valores para variáveis desconhecidas.
Estas simulações receberam este nome em função de Monte Carlo, ou Mônaco, onde as atrações principais são jogos que apresentam comportamento aleatório.
Para cada uma das variáveis desconhecidas são definidos possíveis valores através de uma distribuição probabilística.
A simulação calcula diversos cenários do modelo através de variações nos valores das variáveis desconhecidas.
É de conhecimento geral o fato de que a versatilidade e exatidão das simulações de MC são computacionalmente caras em função de seus requisitos.
Para garantir os resultados numéricos obtidos através das simulações, grandes quantidades de partículas devem ser simuladas.
Em, os autores apresentam o processo utilizado na paralelização do pacote PENELOPE, com o objetivo de aumentar a eficiência das simulações de MC em aplicações médicas.
O pacote foi paralelizado aplicando- se o modelo SPMD (Single Program Multiple Data), ou seja, todos os processos envolvidos executam a mesma operação, porém sobre um conjunto de dados diferentes.
A diferença básica em relação a as simulações anteriormente descritas é o fato de que cada processo tem uma seqüência única de números aleatórios, aspecto crítico do processo de paralelização.
Este novo gerador de números aleatórios deve ser capaz de produzir uma seqüência de números aleatórios independente, distribuídos uniformemente de forma que as diversas seqüências em uso não estejam correlacionadas.
Os processos no novo pacote comunicam- se através de funções MPI, e os resultados obtidos a partir deste novo pacote apresentam ganho de desempenho de 240,25 para 256 processadores, resultado este próximo a o ideal.
Em simulações paralelas, um passo inicial importante é a divisão do problema a ser resolvido entre os processadores.
O objetivo é designar trabalho aos processadores de forma proporcional a sua capacidade de processamento, visando minimizar o tempo de execução da aplicação.
Em aplicações com estruturas de dados simples, o volume de trabalho pode ser dividido em blocos de tamanho proporcionais aos processadores em utilização, e cada bloco deve ser designado ao seu respectivo processador.
Porém, em certas aplicações onde a carga em cada processador e a localidade geométrica dos objetos se alteram à medida que a simulação ocorre, uma divisão inicialmente balanceada com custos baixos de comunicação pode se tornar desbalanceada ou ter taxas inaceitáveis de troca de informações entre os diversos processos.
Em simulações de partículas onde as mesmas são interconectadas ou em situações onde se deseja utilizar métodos de detecção de colisão, a redistribuição dinâmica das partículas com o intuito de manutenção da localidade geométricas das mesmas pode reduzir os custos de comunicação e melhorar o desempenho das simulações.
Em, os autores apresentam um método de divisão do espaço simulado em sub-espaços, onde o problema é decomposto em tarefas com base em sua estrutura fixa, ao longo de a cadeia molecular.
Para preservar a localização dos espaços, é atribuído um posicionamento para cada uma das tarefas, de acordo com a topologia.
O objetivo, então, é balancear a quantidade de trabalho designada para cada processador, designando apenas sub-espaços contíguos a um processador, com blocos sucessivos designados a processadores sucessivos.
Após a designação dos sub-espaços aos processadores, a carga durante a execução da aplicação é balanceada através do algoritmo Positional Scan Load Balancing (PSLB).
A cada etapa da simulação ocorre a verificação da carga em todos os processadores e, havendo diferença entre vizinhos que justifique a migração dos dados, parte da carga do processo sobrecarregado é enviada ao vizinho, obedecendo a topologia das informações sendo migradas.
A estratégia de balanceamento foi validade num supercomputador Cray T3D (memória distribuída).
O speed-up em relação a a execução da mesma aplicação sobre a mesma máquina, porém sem redistribuição de carga, foi de 1,38.
Em também é apresentado um mecanismo de balanceamento que mantém a localização dos dados, porém a divisão do espaço não tem que ser necessariamente feita ao longo de a cadeia (ou eixo do espaço tridimensional).
Desta forma, cada processo pode ter mais do que dois vizinhos.
Para cada processador, é feita a verificação da melhor opção de balanceamento, isto é, qual redistribuição de carga resultará em maior ganho de desempenho.
Uma vez que o espaço pode ser dividido em mais de uma dimensão, o método apresenta algumas restrições em relação a os tamanhos dos blocos aceitos, pois durante o balanceamento, além de as partículas serem enviadas a outro processo, também ocorre alteração nas dimensões das áreas de cada um dos processos.
Esta restrição nos tamanhos de áreas aceitáveis faz com que nem sempre seja possível redistribuir a carga.
Os testes com este mecanismo de balanceamento foram feitos, somente, num supercomputador IBM SP2 composto por 28 nós.
Embora esta máquina suporte o compartilhamento de memória entre os nós, o mecanismo de redistribuição de carga foi implementado usando MPI.
Os melhores resultados ocorreram através da utilização de todos os processadores.
Conforme a distribuição da carga entre os processos, foi possível alcançar speed-up entre 1,6 e 4,4 através do balanceamento da carga.
Esta biblioteca disponibiliza uma série de ações que combinadas geram efeitos elaborados e a possibilidade de existência de mais de um sistema de partículas.
A biblioteca oferece mecanismos para evitar que as partículas colidam com objetos sólidos externos ao sistema, porém não existe detecção de colisão entre as partículas.
Em relação a a possibilidade de execução paralela das aplicações desenvolvidas sobre a biblioteca, constatou- se que, quando executada em máquinas com memória compartilhada, a biblioteca não oferece nenhum mecanismo de controle de acesso exclusivo aos dados que estão sendo alterados.
Desta forma, um processo pode estar atualizando a posição da partícula enquanto um outro pode estar utilizando seu antigo valor para um determinado cálculo.
Em a versão destinada aos processadores geométricos paralelos da PixelFlow, a biblioteca destina um subconjunto de sistemas ou partículas para um determinado processador, e a geração da imagem é feita diretamente por o processador.
A biblioteca apresenta alguns outros problemas tais como testes errôneos de limites de vetores fazendo com que constantemente a aplicação seja abortada.
Também apresenta problemas em relação a a alocação de memória, pois como a mesma não ocorre de forma dinâmica, na maior das vezes desperdiça- se memória.
A biblioteca baseia- se na existência dos seguintes objetos:
Partículas; Sistemas de Partículas;
Ações; Lista de Ações;
Ambiente; Domínios.
Os objetos serão descritos nos próximos tópicos.
Cada partícula que compõe um sistema possui as seguintes propriedades.
Posição da parte frontal da partícula;
Posição auxiliar;
Tamanho da partícula;
Cor (RBGT);
Dois vetores de velocidade;
Idade da partícula.
Cada um dos componentes acima corresponde a um vetor de três posições (todos os valores representados através de ponto flutuante).
As exceções são a propriedade cor, que é um vetor de quatro posições (valores em ponto flutuante), e a idade, que se trata apenas de um valor, também em ponto flutuante.
A posição auxiliar, raramente usada, normalmente representa uma posição de destino da partícula.
O segundo campo de velocidade normalmente armazena a antiga velocidade da partícula para cálculos de orientações a partir de sua curvatura instantânea (cálculo da normal).
A biblioteca trata todas as partículas como esferas, embora possa representar graficamente linhas utilizando as posições frontal e auxiliar, para criar efeitos como chuva.
Um sistema de partícula possui as seguintes propriedades:
Quantidade de partículas existentes;
Máximo de partículas permitidas para o sistema;
Quantidade de partículas alocadas;
Lista com as partículas existentes.
Em a criação de um sistema, é informada a quantidade máxima de partículas que o mesmo pode conter.
Ocorre, então, o retorno do identificador do mesmo para que o usuário possa determinar o sistema corrente.
A quantidade máxima de partículas pode ser alterada no decorrer de a execução.
Inicialmente o sistema aloca espaço para o máximo de partículas que o mesmo pode ter.
Em o momento em que ocorre diminuição do máximo de partículas suportadas por o sistema, verifica- se se o novo máximo é inferior ao número de partículas alocadas e, em caso afirmativo, a memória alocada excedente é liberada, porém pode ocorrer perda no aspecto gráfico do sistema uma vez que algumas partículas deixam de existir. Quanto
uma partícula morre (sai do sistema), a contagem de partículas existentes é diminuída numa unidade.
Sempre que a contagem for inferior à quantidade de partículas alocadas, o sistema utiliza a posição de uma partícula morta para armazenar os dados da nova partícula, não tendo assim que alocar mais memória.
As tentativas de adicionar partículas a um sistema que tenha alcançado seu máximo permitido são ignoradas.
Todas as partículas de um sistema são regidas por as mesmas forças.
Embora possam existir diversos sistemas concomitantes no ambiente simulado, todas as funções são aplicadas somente ao sistema corrente, definido por o usuário.
As ações são responsáveis por modificar os atributos das partículas pertencentes ao sistema de partículas corrente.
A maior parte das ações procura simular forças físicas tais como gravidade.
Outras ações geram novas partículas dentro de o sistema, enquanto que outras eliminam partículas que tenham ultrapassado seu tempo de vida.
As ações foram criadas de forma a serem blocos de construção para a criação de efeitos especiais mais elaborados.
Cada ação é aplicada a todas as partículas do sistema corrente.
Uma vez que cada efeito é composto de três a oito ações, o processo pode ser mais demorado do que uma única passagem de uma ação que combine os efeitos, mas as aplicações individuais permitem a construção de diversas combinações em qualquer ordem desejada.
O Algoritmo 2 exemplifica a utilização de algumas ações.
Algoritmo 2: Exemplo de utilização de ações da biblioteca.
SistemaCorrente $= posição GeraPartículas MovePartículas EliminaPartículas Desenha Sistema de Partículas Algumas outras ações disponíveis são cor alvo, tamanho alvo, velocidade alvo, redemoinho, entre outras.
A biblioteca original disponibiliza 27 ações, com possibilidade de acréscimo de novas ações.
As ações podem ser agrupadas em listas de ações, que encapsulam todas as operações necessárias para produzir um efeito em particular.
Estas listas provêem abstração de efeitos, ou seja, uma vez criado, o efeito pode ser utilizado posteriormente utilizando- se apenas o seu identificador.
Uma das mais importantes ações da biblioteca é a ação de criação de partículas.
As novas partículas devem receber uma cor, uma velocidade, um tamanho e uma idade inicial.
Para evitar a passagem de todos esses parâmetros na chamada da função de geração e para aumentar a flexibilidade da biblioteca, as propriedades acima são armazenadas no ambiente (ou contexto da biblioteca).
Todas as ações que necessitam destes parâmetros utilizam o último valor armazenado no ambiente, que também armazena as listas de ações e os sistemas de partículas existentes.
Muitos efeitos de partículas requerem que o valor inicialmente atribuído a uma ou mais de suas propriedades varie, porém os valores armazenados no ambiente são constantes.
Para lidar com esta e outras questões, a biblioteca introduz o conceito de domínio.
Domínios provêem um mecanismo uniforme para a especificação de um conjunto de três valores.
A função de determinação de cor através de domínio, por exemplo, gera os três componentes da cor de forma aleatória, mas dentro de os limites impostos por o usuário através dos parâmetros utilizados para a criação do domínio.
Os domínios também são usados em algumas ações tais como a geração das partículas, onde uma nova partícula é criada numa posição aleatória dentro de uma região determinada por o domínio.
A ação de eliminação remove as partículas que entram ou saem de um domínio.
Os domínios possuem diversas formas, em sua maioria tridimensionais, tais como, esferas, cubos, cilindros, cones, etc..
A análise das soluções disponíveis encontradas durante a revisão bibliográfica deste trabalho conduziu as seguintes constatações:
A aplicação de Karl Sims e uma das versões da biblioteca Particle System API são destinadas a execução em equipamentos específicos, Cm-2 e PixelFlow respectivamente.
A outra versão da biblioteca Particle System API e o procedimento para simulação de tecidos são voltados para máquinas SMP.
Ambas aplicações não provêem mecanismos para comunicação entre processos de diferentes nós, requisito fundamental para utilização em máquinas agregadas.
Algumas soluções tratam categorias específicas como, por exemplo, simulações de Monte Carlo.
As soluções mais genéricas que foram encontradas, para simulações de dinâmica molecular e elementos discretos, não prevêem a utilização de máquinas heterogêneas.
Ambos os métodos de balanceamento de carga só foram validados em supercomputadores (processadores homogêneos).
O desempenho dos mesmos num agregado heterogêneo é desconhecido.
Não foram encontradas soluções que permitam a simulação de diversos efeitos e que, paralelamente, possam utilizar de forma eficiente o poder computacional oferecido por as máquinas agregadas, quer estas sejam homogêneas ou heterogêneas.
Estas deficiências motivaram o desenvolvimento de um modelo paralelo para simulação de partículas independentes em máquinas agregadas heterogêneas.
O novo modelo utiliza troca de mensagens para comunicação entre os diversos processos e apresenta mecanismo de balanceamento de carga dinâmico baseados nas soluções apresentadas para melhor exploração do poder computacional disponível.
O modelo será descrito em detalhes no quarto capítulo.
O modelo desenvolvido destina- se à simulação de sistemas de partículas estocásticos, onde uma partícula é totalmente independente das outras.
A única interação prevista para as partículas é a possibilidade de detecção de colisão entre as mesmas.
O modelo pode ser tanto utilizado para simulações bidimensionais como tridimensionais, a diferença está nos dados em relação a as partículas e aos sistemas que devem ser armazenados.
Em o desenvolvimento do modelo foi utilizado o paradigma de programação paralela denominado Fases Paralelas.
Conforme este paradigma, a aplicação consiste num número de etapas, cada uma dividida em duas fases:
Uma fase de computação, quando os diversos processos processam, de forma independente, seus dados locais, seguida de uma fase de interação, quando os processos executam uma ou mais operações de interação síncrona, tais como barreiras ou operações bloqueantes.
Uma vez que o modelo é voltado para simulações em máquinas heterogêneas e devido a a constante alteração nos dados processados (inclusão, deslocamento e remoção de partículas), é necessária a utilização de mecanismos de balanceamento de carga.
Soluções de balanceamento estático, no entanto, não garantem distribuição proporcional das partículas entre os diversos processos à medida que a simulação evolui.
Com base nestes fatores, optou- se por a inclusão de mecanismos de balanceamento de carga dinâmico no modelo.
O mecanismo adotado deve ser rápido o suficiente para garantir que o tempo utilizado no balanceamento da carga não exceda o tempo de execução da aplicação em estado desbalanceado.
O modelo adota uma estratégia de balanceamento local, com um gerenciador centralizado, pois um processo só pode enviar ou receber partículas de seus processos vizinhos durante o procedimento de balanceamento.
Isto se deve à necessidade de preservação da localidade dos dados, pois o usuário pode pretender incluir detecção de colisão entre partículas e quanto mais próximas estas estiverem de suas vizinhas, menor será a necessidade de comunicação entre os processos.
Os tópicos a seguir descrevem cada um dos componentes existentes no modelo e, posteriormente, o procedimento utilizado na simulação dos sistemas de partículas.
O modelo é composto por processos, partículas, sistemas de partículas, faixas de domínio e ações sobre partículas.
Cada um destes componentes será descrito nos itens a seguir.
O modelo é destinado às máquinas agregadas, com utilização do paradigma de programação paralela baseado na troca de mensagens, possivelmente o paradigma mais amplamente utilizado.
Aplicações que utilizam esta técnica estão subdivididas em processos, onde cada um gerência seus dados locais.
Cada processo é identificado por um nome e envia e recebe mensagens dos demais processos pertencentes à aplicação.
Os processos podem estar em diferentes máquinas e comunicam- se por uma rede de interconexão, ou seja, existe um canal de comunicação implícito para cada par de processos (cada processo pode comunicar- se com qualquer outro).
O modelo de troca de mensagens não impede a criação dinâmica de processos, a execução de múltiplos processos por processador ou a execução de tarefas diferentes por processos diferentes.
Porém, a maioria dos sistemas que utiliza a troca de mensagens cria um número fixo de processos que executam a mesma tarefa e não permitem a criação ou extinção de processos durante a execução.
Estes sistemas são conhecidos como SPMD (single program multiple data), pois executam as mesmas tarefas, porém sobre dados diferentes.
O modelo apresenta três tipos de processos, os calculadores, o gerente e o gerador de imagens.
O processo gerente é responsável por criar as partículas novas e gerenciar o balanceamento de carga entre os processos calculadores.
O processo gerador de imagens coleta as partículas provenientes dos calculadores e gera os quadros da animação.
Os processos calculadores são responsáveis por o processamento dos efeitos aplicados sobre as partículas, deslocamentos e detecção de colisão (conforme procedimento adotado por o usuário).
Todos os processos no modelo têm conhecimento das informações gerais necessárias para a simulação.
O único conjunto de dados de conhecimento exclusivo de cada processo são as partículas.
Desta forma, todos os sistemas de partículas sendo simulados existem em todos os processos, no entanto, cada processo gerência apenas as partículas que a ele foram designadas.
Conforme mencionado anteriormente, existem propriedades básicas em relação a as partículas que são sempre necessárias, independente do tipo de animação que se pretende efetuar sobre as partículas.
As propriedades básicas, conforme o número de dimensões desejadas, são:
Posição da partícula no plano ou no espaço (x, y ou x, y, z);
Orientação no plano ou espaço (x, y ou x, y, z);
Idade da partícula;
Velocidade de deslocamento.
No entanto, utilizando- se apenas as propriedades acima não é possível simular alterações de tamanho, forma e cor da partícula durante seu tempo de vida.
Independentemente das características armazenadas, o funcionamento do modelo ocorre da mesma forma.
Um detalhe importante a ser ressaltado é que o modelo aqui descrito não necessita que cada partícula pertencente a um sistema tenha um identificador único, desde que partículas de sistemas diferentes sejam armazenadas em estruturas diferentes.
Em casos de simulações com grande número de partículas, armazenar informações desnecessárias pode impedir a simulação em função de questões de memória.
Em princípio, um sistema de partículas tem os mesmos parâmetros utilizados na criação de suas partículas, com exceção do tempo de vida.
No entanto, estas propriedades não alteram o estado do sistema, servem apenas para determinar os valores iniciais das propriedades das partículas.
Novamente, a importância das propriedades é dada por o tipo de sistema a ser simulado e não influência no comportamento do modelo.
Conforme a forma de armazenamento dos sistemas de partículas na memória, pode ser necessário fornecer um identificador único para cada sistema, para garantir que as partículas que se deslocarem entre os processos permaneçam no mesmo sistema de origem.
Caso os sistemas sejam armazenados na forma de vetor, a posição no vetor serve como identificador do sistema, pois a criação dos mesmos ocorre na mesma ordem para todos os sistemas.
Visando a possibilidade de detecção de colisão entre partículas numa simulação e redução do número de testes necessários, o espaço simulado é divido em faixas de domínio, ao longo de um dos eixos do plano ou do espaço.
Cada sistema de partícula tem suas próprias faixas de domínio, ou seja, cada sistema é dividido em n fatias, sendo n o número de processos calculadores.
A Figura 3 mostra uma possível divisão do espaço em seis faixas de domínio.
Conforme representado na Figura 3, cada faixa é associada a um processo calculador, de forma seqüencial, ou seja, o primeiro processo é responsável por a primeira faixa, a segunda por a segunda e assim por diante.
Este processo é repetido para cada um dos sistemas de partículas simulados.
Todos os processos conhecem as dimensões das faixas dos demais processos, desta forma sabem para onde devem enviar a partícula caso seja necessário detectar colisão.
Caso não ocorresse a divisão do espaço em faixas de domínio, haveria a necessidade de se efetuar o teste de colisão com todas as partículas, pertencentes a todos os processos, pois não haveria garantia de que partículas próximas se encontrassem no mesmo processo.
Outra razão para o conhecimento global das faixas de domínio é o fato de que as partículas podem se deslocar entre as faixas de domínio, evitando que uma partícula tenha que ser enviada a todos os processos para identificação da nova faixa de domínio.
As faixas de domínio podem sofrer alterações em suas dimensões durante o decorrer da simulação.
Isto ocorre em decorrência do balanceamento de carga efetuado entre os processos.
Uma vez que pode ser necessário mover partículas de um processo para outro, buscando equilibrar a quantidade de trabalho em cada processo, torna- se necessário alterar as dimensões, pois um processo só armazena as partículas que pertençam a sua faixa de domínio.
O modelo estipula regras de comportamento apenas para ações que criam e deslocam partículas, uma vez que estas ações alteram a distribuição espacial das partículas.
Ações que modificam propriedades das partículas, sem alterarem seu posicionamento podem ser aplicadas sobre as partículas a qualquer instante da simulação, pois as alterações nas propriedades não necessitam ser repassadas aos demais processos.
Uma vez que o modelo não tem por objetivo servir como base de efeitos que possam ser operados sobre as partículas, os mesmos não serão descritos.
Todas as partículas são criadas por o mesmo processo e enviadas aos demais conforme a faixa de domínio associada a cada processo, conforme descrição anterior.
A o final de cada quadro da animação, é necessário verificar se as partículas pertencentes ao processo permanecem dentro de a faixa de domínio do mesmo, caso contrário devem ser enviadas aos respectivos processos calculadores.
Conforme o método de detecção de colisão escolhido por o usuário, as partículas que trocam de faixa de domínio podem ser deslocadas de um processo ao outro durante o processo de cálculo e validação da posição.
Desta forma, não há a necessidade de envio de partículas aos outros processos ao final de cada quadro da animação, pois as mesmas já se encontrarão dentro de a faixa de domínio do processo correto.
O modelo possibilita a simulação de diversos sistemas de partículas simultâneos.
Para cada um destes sistemas são mantidas informações em relação a as faixas de domínio, quantidade de partículas e tempo de processamento das ações sobre as partículas.
Para facilitar a compreensão, primeiramente será descrito o processo para obtenção de diversos quadros de animação de um único sistema de partículas.
A Figura 4 mostra este processo.
Os processos são disparados e o sistema de partícula é criado.
Em a sua criação, o espaço a ser simulado por o sistema é dividido em n faixas de domínios, conforme anteriormente mencionado, e todos os processos armazenam localmente a informação a respeito de todas as faixas de domínios.
Após a criação, dá- se início ao laço de processamento das ações sobre o sistema, conforme o Algoritmo 3.
Algoritmo 3: Laço de processamento de um sistema de partículas no modelo.
Configuração do sistema de Partículas Criação de x partículas Simulação da ação da gravidade sobre as partículas Eliminação de partículas que estiverem abaixo de a posição (x, y, z) Devolução de partículas que colidirem com o objeto obj Movimentação das partículas Obtenção da imagem das partículas quadros $= quadros+ 1 Todos os processos executam todas as ações acima, na mesma ordem, porém de forma diferente.
A configuração do sistema, que não necessariamente deve estar dentro de o laço (pode- se querer alterar o comportamento do sistema a cada novo quadro da animação), é um exemplo de ação que não é executada por o gerador de imagens.
O &quot;esqueleto externo «da animação é o mesmo para todos os processos para facilitar o desenvolvimento da animação, porém é dado tratamento diferente à ação na hora de sua execução.
Caso o usuário tivesse optado por não utilizar o mecanismo de balanceamento de carga, seria necessário incluir uma etapa de sincronização entre os processos.
Em o modelo com balanceamento de carga ativado, a sincronização ocorre através da troca de informações em relação a as novas faixas de domínio.
Se o mecanismo estiver desabilitado, a imagem gerada poderia estar incompleta, pois não haveria garantia de que o processo gerador de imagens recebeu partículas provenientes de todos os processos.
Caso um dos processos fosse mais rápido, o mesmo poderia enviar duas vezes suas partículas para a geração da imagem, finalizando o quadro no lugar de um processo mais lento.
A sincronização entre os processos, neste caso, pode ser feita entre qualquer etapa do modelo.
Os tópicos a seguir detalham as demais ações do exemplo de simulação anterior.
Durante a etapa, ou ação, de criação das partículas, o processo gerente gera a quantidade de partículas indicadas na função, posicionando as mesmas conforme o comportamento estipulado para o sistema de partículas, como por exemplo, lançando- as para cima com o intuito de criar uma explosão.
Após a criação de cada uma das partículas, verifica- se em qual faixa de domínio a mesma deve ser inserida, armazenando- a numa estrutura destinada a tal faixa, para posterior envio aos processos calculadores.
Após ter finalizado a operação de geração para o quadro corrente da animação, o gerente envia as partículas armazenadas nas estruturas de cada uma das faixas ao devido processo, informando o término da transmissão aos processos calculadores.
Os processos calculadores aguardam o recebimento das partículas de sua faixa, para darem início às demais ações sobre as partículas.
É imprescindível que estes processos recebam notificação do término do envio, caso contrário ficarão bloqueados na ação de criação e impedirão o processamento do próximo quadro da animação.
Em o Algoritmo 4 tem- se o funcionamento básico desta etapa do modelo:
Algoritmo 4: Funcionamento da ação de criação de partículas.
Conforme o exemplo de simulação anterior, ações como simulação do efeito de gravidade sobre as partículas, eliminação de partículas que tenham ultrapassado um determinado limite ou devolução de partículas que tenham colidido com um objeto externo ao sistema, não alteram o posicionamento da partícula.
Estas ações apenas modificam propriedades utilizadas por a ação de movimentação, descrita na seqüência, ou, então, removem partículas das estruturas onde estão armazenadas.
Desta forma, não existe necessidade de interação entre os processos durante a execução destas ações.
Somente os processos calculadores executam funções nestas ações, enquanto os demais processos avançam na simulação.
A ação de devolução de uma partícula, por exemplo, faz com que, uma vez detectada uma possível colisão, a orientação de movimentação da partícula seja alterada, passando a apontar na direção da reflexão.
Em o processo de movimentação da partícula, ao invés de transladar a partícula em direção a o sólido, o procedimento irá simular a devolução ocasionada por um choque.
A ação de simulação da gravidade faz com que gradativamente a orientação da partícula aponte para baixo no espaço simulado.
Durante a execução das ações que alteram o posicionamento das partículas também não há necessidade de comunicação entre os processos.
Porém, ao deslocar uma partícula, cada um dos processos calculadores deve verificar se a mesma movimentou- se para fora de a faixa de domínio sob seu controle.
Caso isto tenha ocorrido, o processo deve armazenar a partícula numa estrutura, para posterior troca de partículas com os demais processos calculadores, e deve remover a partícula da estrutura em a qual a mesma se encontra.
Armazenando a partícula em outra estrutura, evita- se que todas as partículas tenham que ser percorridas para identificação daquelas que devam ser enviadas aos outros processos calculadores, economizando desta forma tempo de processamento.
No entanto, a utilização de mais de uma estrutura requer um maior controle sobre o processamento, pois esta estrutura adicional deve ser processada por todas as ações, inclusive por aquelas que só alteram as propriedades das partículas, mencionadas anteriormente.
Novamente, somente os processos calculadores executam as funções referentes ao deslocamento das partículas, enquanto os demais avançam na simulação.
É na ação de obtenção do quadro da animação que ocorre a troca de partículas entre processos devido a a ultrapassagem das faixas de domínio, balanceamento de carga entre os processos e efetiva obtenção do quadro da animação.
Desta forma, todos os processos participam desta etapa da simulação.
Inicialmente, ocorre a troca de partículas entre os processos calculadores, com o intuito de que cada processo gerencie, no restante do processamento, somente as partículas que pertencem a sua faixa de domínio.
O Algoritmo 5 apresenta os passos seguidos para troca de partículas entre os processos calculadores:
Algoritmo 5: Procedimento para troca de partículas entre processos.
Para cada processo faça Se processo $= identificador do processo corrente Se destino diferente de processo Se estrutura estiver vazia Informe ao destino o final da transmissão Divida a estrutura em blocos Para cada bloco último faça Envie bloco com cont.
De a transm.
Envie bloco (último) com final da transm.
Senão Receba bloco de partículas Para cada partícula recebida faça Armazene a partícula Elimine as partículas das estruturas de troca Feita a troca de partículas entre os processos calculadores, os mesmos devem informar ao processo gerente informações referentes à carga e ao tempo de processamento do sistema de partículas.
Estas informações são:
Quantidade de partículas sob controle do processo (desconsideradas as partículas enviadas aos outros processos por troca de faixa de domínio);
Tempo de processamento das partículas;
Medida de comparação de desempenho das máquinas utilizadas.
Optou- se por a utilização destas informações apenas, mas nada impede a adição de outros critérios para avaliação da carga de cada um dos processos.
O tempo é medido a partir de a execução da primeira ação de um dos quadros da animação.
A cada ação, a variável que armazena o tempo final deve ser atualizada, pois não é possível prever qual será a última ação a ser executada sobre as partículas.
O tempo obtido refere- se ao cálculo de todas as partículas que pertencem ao processo no quadro em processamento, no entanto, o processo pode ter ganhado ou perdido partículas devido a a troca de faixas de domínio.
Tem- se que, então, calcular o tempo de forma a deixar- lo proporcional as partículas que passam a pertencer ao processo após o remanejo.
Enquanto que o processo gerente avalia o balanceamento, conforme descrição a seguir, os processos calculadores enviam as partículas ao processo gerador de imagens, novamente fracionando o conjunto de partículas em blocos e enviando informações referentes à continuação ou término do envio das partículas.
À medida que o gerador de imagens recebe as partículas, o mesmo efetua as ações necessárias para obtenção do quadro da animação, quer a imagem seja gerada na tela ou em arquivo.
É responsabilidade do gerador desenhar os demais objetos não pertencentes ao sistema de partículas, mas existentes na simulação.
Após receber a informação referente a a carga de cada um dos processos calculadores, o gerente avalia o balanceamento para cada par de processos vizinhos, ou seja, ocorre a análise do balanceamento entre os processos x e x+ 1, x+ 1 e x+ 2, x+ 2 e x+ 3 e assim por diante.
Em uma mesma etapa de redistribuição de carga, havendo necessidade de balancear a carga entre os processos x e x+ 1, não será feita a análise das cargas para o par x+ 1 e x+ 2.
O próximo par de processos analisados, ainda para a mesma etapa, será x+ 2 e x+ 3.
Isto se deve aos seguintes fatores:
O balanceamento somente ocorre entre vizinhos, devido a as faixas de domínio;
Cada processo somente envia ou recebe partículas, nunca ambas as O balanceamento ocorre somente entre dois processos, ou seja, o processo x, por exemplo, não recebe partículas dos processos x-1 e x+ 1, para, Para evitar que o mecanismo de balanceamento de carga efetue troca de partículas sempre entre os mesmos pares de processos, a cada execução da avaliação de carga ocorre a variação do identificador do processo inicial.
Desta forma, em algumas execuções os primeiros processos a serem comparados são aqueles cujos identificadores são 1 e 2;
em outras execuções a comparação inicia por o par composto por os processos 2 e 3.
Com base em um valor de diferença de tempo estipulado, inicia- se o processo de comparação entre as cargas dos processos.
O par de processos que apresentar diferença de tempo de processamento maior que o valor estipulado deverá ter suas cargas balanceadas.
Em o balanceamento, a capacidade de processamento dos dois processos (medida de desempenho dos nós) é somada e normalizada, conforme demonstrado por as fórmulas 1, 2 e 3.
Em as fórmulas acima, A e B são os identificadores dos processos envolvidos no balanceamento.
A carga de ambos os processos é somada e o resultado é dividido entre eles de forma proporcional a sua capacidade de processamento (fórmulas números 2 e 3).
A nova carga é comparada com a antiga, desta forma é possível estabelecer quem deve &quot;doar «partículas no processo de balanceamento.
Conforme a quantidade de partículas a serem transmitidas, pode não ser interessante efetuar o balanceamento, pois o custo da comunicação entre os processos pode piorar o desempenho da aplicação.
O Algoritmo 6 ilustra o procedimento seguido para determinação dos pares no balanceamento e respectivas cargas.
Algoritmo 6: Determinação dos pares no balanceamento e respectivas cargas.
Após definição dos pares no balanceamento, o gerente envia a todos os processos calculadores as ordens de balanceamento, informando para cada processo a quantidade de partículas que serão movimentadas, o vizinho com o qual a troca deve ser feita e qual a função do processo no balanceamento (doador ou receptor de partículas).
Caso o processo calculador não deva participar no balanceamento o mesmo deve ser informado a este respeito, para que possa dar continuidade ao processo de simulação.
Tendo recebido as informações para o balanceamento, o processo doador de partículas deve, então, selecionar as partículas que serão doadas.
O processo não pode simplesmente retirar a quantidade de partículas definidas por o gerente, pois é necessário que as partículas continuem a obedecer as faixas de domínio.
É necessário ordenar as partículas conforme o eixo escolhido para determinação das faixas de domínio.
Se o processo receptor estiver à esquerda, supondo ordenação por o eixo x, devem ser doadas as partículas com os menores valores de x, caso contrário, devem ser doadas as partículas com os maiores valores de x.
A partir de a ordenação e seleção das partículas, torna- se possível estipular os novos limites das faixas de domínio de ambos os processos envolvidos no balanceamento, pois os limites devem ser deslocados para a posição em x indicada por a maior partícula a ser doada (vizinho à esquerda) ou por a menor partícula a ser doada (vizinho à direita).
A ordenação e seleção devem levar em consideração a possibilidade de existência de duas ou mais partículas com valores iguais na dimensão de corte das faixas, pois as mesmas devem permanecer juntas após o balanceamento, uma vez que pertencem à mesma faixa de domínio.
Tendo determinado as novas dimensões para sua faixa de domínio, os processos doadores de partículas repassam ao gerente as novas dimensões.
O gerente redefine as faixas de domínio de todos os processos, atualiza as informações locais referentes às faixas e transmite os novos valores a todos os processos calculadores, para que estes também possam atualizar suas informações.
Somente após terem recebido as novas dimensões das faixas de todos os processos é que ocorre efetivamente o balanceamento dos dados entre os pares determinados por o gerente.
Os processos que não devem enviar nem receber partículas dão início ao processamento do próximo quadro da animação.
Os demais aguardam o término do envio e recebimento das partículas para darem continuidade ao processo de simulação.
O processo de simulação de dois ou mais sistemas de partículas segue os mesmos passos anteriormente apresentados, caso cada sistema seja analisado individualmente.
A diferença existe quando a simulação é visualizada como um todo, pois existem diferentes formas de combinar o processamento de mais de um sistema.
Conforme a forma utilizada, o processamento pode ser mais ou menos eficiente.
Uma primeira forma de combinação de dois ou mais sistemas seria tratar- los de forma seqüencial.
O Algoritmo 7 demonstra esta combinação.
Esta combinação não propicia o melhor desempenho possível, pois o tratamento dos sistemas ocorre de forma seqüencial, ainda que as partículas possam ser processadas por mais de um processo calculador.
Em o Algoritmo 7, o processo gerente deve esperar que os calculadores terminem o processo de balanceamento para então criar novas partículas do próximo sistema e enviar- lhes.
Se por acaso, não for necessário balancear a carga entre os processos calculadores, os mesmos deverão aguardar que o processo gerente termine de gerar novas partículas.
Algoritmo 7: &quot;Simulação «&quot;seqüencial «de dois ou mais sistemas.
Sistema Ativo $= 1 Configurar Sistema de Partículas Criar x partículas Simular ação da gravidade sobre as partículas Eliminar partículas que estiverem abaixo de a posição (x, y, z) Rebater partículas que colidirem com o objeto obj Mover partículas Desenhar partículas Sistema Ativo $= 2 Configurar Sistema de Partículas Criar x partículas Simular ação da gravidade sobre as partículas Eliminar partículas que estiverem abaixo de a posição (x, y, z) Rebater partículas que colidirem com o objeto obj Mover partículas Desenhar partículas Número de quadros $= Número de quadros+ 1 Uma outra forma de combinação, possivelmente a mais eficiente, intercala o processamento dos sistemas, conforme exemplificado no Algoritmo 8.&amp;&amp;&amp; Algoritmo 8: &quot;Simulação «&quot;intercalada «de dois ou mais sistemas.
A partir de esta outra combinação, enquanto os processos calculadores estão aplicando ações sobre as partículas, o gerente pode antecipar a criação de partículas do próximo sistema na seqüência da simulação.
Quando os processos calculadores iniciarem o processamento do próximo sistema de partículas, as partículas já estarão disponíveis.
Um detalhe importante a ser salientado em simulações com mais de um sistema de partículas é o fato de que não se pode atribuir o processamento de um determinado sistema a um processo específico.
Isto ocorre em função de as regras de comunicação entre os processos, pois caso um único processo seja responsável por um sistema, o mesmo aguardará o término da troca de partículas com os vizinhos, porém os vizinhos não foram informados da existência do sistema em questão.
Outro detalhe importante diz respeito à criação dinâmica de sistemas durante o processo de simulação.
Os sistemas podem ser criados a qualquer momento da simulação, desde que, novamente, todos os processos tomem conhecimento da criação do sistema.
O mesmo vale para remoção de sistemas da simulação.
Como já fora mencionado anteriormente neste documento, uma das questões levadas em consideração durante o desenvolvimento do modelo paralelo foi a possibilidade de inclusão de técnicas de detecção de colisão entre as partículas.
Os testes que devem ser efetuadas em função de a utilização destes métodos são de fácil adaptação no modelo, caso o usuário deseje apenas efetuar- los com as partículas pertencentes ao mesmo processo.
No entanto, se for necessário comparar partículas de diferentes processos, será necessária a criação de uma outra linha de execução paralela em cada processo para possibilitar o recebimento de ordens de detecção simultaneamente ao processamento das partículas locais.
Torna- se necessária a inclusão de controle sobre o acesso às partículas (seção crítica), como forma de garantia dos dados armazenados.
O controle sobre a seção crítica, de certa forma, atribui características de acesso seqüencial aos dados por ambas as linhas de execução, o que pode reduzir o desempenho geral do modelo.
Para diminuir o acesso seqüencial às partículas, deve- se subdividir a faixa de domínio de um sistema em diversas sub-faixas, e aplicar os controles de seção crítica para cada uma das faixas de forma individual.
Desta forma, ambas as linhas de execução podem ter acesso concomitante a diferentes áreas da faixa de domínio de um processo.
A estratégia de utilização de sub-faixas beneficia os procedimentos de detecção de colisão efetuados somente com partículas vizinhas.
Em casos onde a área de detecção for mais abrangente, a repartição das faixas de domínio pode não influenciar no ganho de desempenho da aplicação.
Para a validação do modelo proposto neste trabalho, utilizou- se como base a biblioteca desenvolvida por David K. McAllister, descrita anteriormente neste documento.
Embora a biblioteca apresente os problemas já mencionados, os objetivos e restrições aplicados no desenvolvimento da mesma justificam a escolha desta biblioteca como base para a validação do modelo.
A biblioteca original foi projetada de forma a permitir que aplicações de tempo real pudessem incluir sistemas de partículas dinamicamente, necessitando que os cálculos sobre as partículas fossem computados de forma eficiente para garantir que a CPU (Central Processing Unit) tivesse tempo suficiente para efetuar os demais cálculos envolvidos em cada quadro da animação.
Outra vantagem da biblioteca é a sua flexibilidade, permitindo que o usuário crie seus próprios efeitos, por isso a biblioteca apresenta blocos de códigos simples, tais como gravidade ou reflexão, ao invés de efeitos complexos como chafariz e bando de pássaros.
Outra razão para a escolha é o fato de que a exatidão numérica da simulação é escalável e modificável através da aplicação sobre ela desenvolvida, pois a biblioteca destina- se tanto à geração de imagens de animações de qualidade onde o fator tempo não é o aspecto mais importante e, também, à criação de efeitos especiais em tempo real em aplicações que já apresentam intensa utilização do poder computacional.
A alteração da precisão também permite a criação de diferentes efeitos.
A questão da obtenção das imagens em tempo real a partir de a implementação do modelo sobre esta biblioteca está diretamente relacionada ao número de partículas sendo simuladas.
Outro fator determinante no tempo de obtenção das imagens é o mecanismo de detecção de colisão entre as partículas, adotado por o usuário no desenvolvimento das aplicações.
A implementação do modelo sobre esta biblioteca também busca evitar que o usuário interessado em efetuar simulações com sistemas de partículas em máquinas agregadas tenha que ter conhecimento dos mecanismos de programação paralela.
Desta forma, além de encapsular as questões relativas às partículas, a nova biblioteca também encapsula todas as funções da interface de troca de mensagens, de forma a permitir que o usuário construa e simule o seu cenário de sistemas de partículas numa máquina agregada da mesma forma como faria numa única estação de trabalho.
Para facilitar o desenvolvimento dos novos métodos oferecidos por a biblioteca paralela, a biblioteca original foi totalmente reescrita, utilizando- se a linguagem e programação C+.
Os problemas de controle de limites foram corrigidos e o código foi totalmente reestruturado para facilitar o processo de aplicação do modelo sobre a biblioteca.
Durante a reestruturação, procurou- se manter compatibilidade com as aplicações já construídas sobre a mesma, mantendo- se todas as chamadas da biblioteca original inalteradas.
Os problemas de acesso à seção crítica também foram corrigidos, pois o usuário pode precisar incluir threads para adaptação dos mecanismos de detecção de colisão.
É possível habilitar e desabilitar a utilização dos mecanismos de controle de acesso à seção crítica, pois, na ausência de necessidade dos mesmos, é mais interessante descartar os testes para obtenção de melhor desempenho.
Inicialmente, os sistemas não possuem nenhuma partícula, nem mesmo espaço alocado para as mesmas.
Esta é uma diferença relevante entre a nova biblioteca e a utilizada como base.
Ao invés de alocar espaço para todas as partículas que o sistema pode conter, a alocação ocorre de forma dinâmica, à medida que for necessário.
Porém, para agilizar o processo de alocação, ao invés de alocar espaço para a partícula que está sendo criada, a biblioteca aloca um bloco de partículas, com base na quantidade máxima de partículas permitida para o sistema, evitando desta forma a necessidade de copiar toda a lista de partículas a cada nova partícula.
Optou- se por a alocação dinâmica, pois como existem outros sistemas de partículas sendo simulados, os mesmos podem necessitar do espaço que estava sendo de certa forma desperdiçado.
Também, constatou- se que ao se criar um sistema, nem sempre se tem idéia da quantidade de partículas que realmente existirão no mesmo, pois às vezes o tempo de vida da partícula é curto, fazendo com que boa parte da memória antes alocada obrigatoriamente permaneça inutilizada durante a simulação.
A biblioteca original utiliza a API OpenGL, para obtenção dos quadros da animação.
Optou- se por a continuidade da utilização desta API por a ampla gama de funções disponibilizadas e por satisfazer as necessidades para validação do modelo.
Em a implementação da nova biblioteca também foi utilizada a API MPI para comunicação entre os processos.
Como um dos intuitos da nova biblioteca é evitar que o usuário tenha que controlar a execução de cada um dos processos disparados na máquina agregada, foi necessário assumir a utilização da biblioteca GLUT (OpenGL Utility Toolkit) para criação de janelas.
Uma vez que apenas um dos processos é responsável por gerar as imagens, somente este processo deve gerenciar as janelas.
Ao invés de o usuário utilizar as funções disponibilizadas por a GLUT, o mesmo deve passar a utilizar as funções fornecidas por a biblioteca quando desejar executar sua aplicação numa máquina agregada.
Estas funções permitirão que somente o processo gerador de imagens manipule as janelas, utilizando internamente as chamadas da GLUT.
No entanto, nem todas as chamadas de funções da GLUT foram substituídas, pois não houve necessidade durante o processo de validação do modelo.
Embora a GLUT tenha sido estabelecida como padrão para a biblioteca, nada impede a utilização de outra biblioteca.
A escolha da GLUT ocorreu em decorrência de sua facilidade de utilização e por satisfazer as necessidades originadas no processo de validação do modelo.
A Tabela 1 apresenta as funções da GLUT que foram substituídas e suas respectivas substitutas.
Foi necessário, também, substituir a chamada à função glClear da API OpenGL para evitar problemas decorrentes da inexistência das janelas em todos os processos.
A nova função passa a ser denominada pglPS_ Clear.
Novamente, as chamadas são utilizadas internamente por a biblioteca, quando o processo executando a função for o gerador de imagens.
Em cada uma das novas funções ocorre a verificação do tipo de processo que a está executando.
O processo apropriado executa a chamada original da GLUT ou da API OpenGL, e os demais processos são desviados para a próxima instrução designada por o usuário.
A Implementação 1 apresenta o novo comportamento atribuído à função de indicação do processo a ser executado quando o sistema encontra- se em estado ocioso, denominada pglPS_ IdleFunction.
Implementação 1: A Implementação 2 apresenta o funcionamento da função pglPS_ MainLoop, que utiliza o ponteiro para uma função, idle_ function, introduzido na Implementação 1.
Em o processo gerente, a função ociosa é automaticamente ativada por glutMainLoop.
Porém, em função de a inexistência de janelas nos demais processos, não é possível utilizar glutMainLoop, tornando- se necessária a execução da função ociosa dentro de um laço de repetição.
Implementação 2: Função pglPS_ MainLoop.
Quando o usuário acessa a função pglPS_ Init, ocorrem, além de a chamada apropriada à glutInit, a criação dos processos e criação dos tipos utilizados nas mensagens através de chamadas MPI e configuração das faixas de domínio iniciais.
A maior parte das funções disponibilizadas por a biblioteca base passou a ter dois comportamentos, um quando executadas seqüencialmente e outro quando executadas sobre a máquina agregada.
Foi possível, desta forma, manter compatibilidade com a biblioteca original.
Devido a a possibilidade de partículas de um mesmo sistema estarem sendo processadas por mais de um processo simultaneamente, operações da biblioteca original que manipulavam partículas interdependentes foram desabilitadas na versão paralela da nova biblioteca.
Isto se deve ao fato do modelo desenvolvido não prover uma forma de ordenação dos diversos segmentos em os quais o sistema de partículas foi quebrado.
Para tais operações, uma partícula necessitaria saber quais são suas partículas antecessora e sucessora na lista de partículas, criando vínculos inexistentes neste modelo.
Além de a alteração das funções mencionadas, foi necessário incluir uma função para finalização dos processos, que deve ser executada por todos os processos paralelos antes da execução da função de saída efetiva do programa.
Esta função foi nomeada pglPS_ End.
Houve a inclusão das faixas de domínio e as estruturas que armazenam as partículas foram modificadas devido a as trocas de partículas entre os processos tanto por troca de faixas de domínio como por questões de balanceamento de carga.
Estas alterações são detalhadas nos tópicos a seguir.
Como mencionado anteriormente, cada processo armazena localmente as informações a respeito de todas as faixas de domínio existentes na simulação.
Para a validação do modelo optou- se por a utilização do eixo x para a criação das faixas, mas nada impede a determinação de diferentes eixos de cortes para sistemas diferentes, de acordo com o comportamento das partículas pertencentes aos mesmos.
Inicialmente, o espaço é dividido em n faixas, sendo n o número de processos calculadores.
A dimensão de abrangência do eixo x pode ser definida por um valor padrão, que pode ser o limite de representação numérica permitido por o tipo de variável utilizada, ou definida por o usuário antes da criação dos sistemas de partículas.
Quanto mais aproximada for a dimensão estabelecida para o eixo x da dimensão em x utilizada na simulação, mais rapidamente ocorrerá o equilíbrio de cargas entre os processos.
Dependendo da quantidade de processos calculadores e distanciamento das faixas da região onde as partículas estão sendo simuladas, alguns processos podem permanecer ociosos durante os primeiros quadros da animação.
As faixas de domínio são armazenadas num vetor, onde cada posição do mesmo guarda a dimensão esquerda e direita da faixa do processo calculador identificado por a posição do vetor.
Não haveria a necessidade de armazenagem de ambos os valores, uma vez que uma faixa inicia onde a outra termina.
Porém, é mais fácil acessar ambas as dimensões com um identificador de posição no vetor, ao invés de controlar qual a posição no vetor deve ser acessada.
Em o processo de validação, foi estipulado que, para que uma partícula pertença a uma determinada faixa de domínio, o valor de sua coordenada em x deve ser maior ou igual à dimensão esquerda da faixa e menor que a dimensão direita.
A biblioteca original utiliza um único vetor para armazenar as partículas pertencentes a um sistema de partículas.
Foi necessário alterar esta estrutura para aumentar a eficácia das operações de comunicação entre os diversos processos.
Os itens a seguir detalham os dados armazenados e as novas estruturas utilizadas.
Devido a a restrição das formas das partículas que podem ser representadas através da biblioteca (pontos ou esferas) e à distribuição das mesmas por o espaço tridimensional, seguem os dados armazenados para cada partícula:
Posição; Tamanho;
Posição Auxiliar; Velocidade;
Velocidade Auxiliar; Cor;
Transparência; Idade.
Não seria necessário utilizar todas estas propriedades durante o processo de validação do modelo, porém optou- se por manter os dados utilizados na biblioteca original.
Com exceção da transparência e da idade da partícula, que são representados através de um único valor em ponto flutuante, as demais propriedade são representadas através de vetores (x, y, z), onde em cada posição do vetor tem- se um valor também em ponto flutuante.
Tem- se, desta forma, um total de 20 variáveis representadas através de valores em ponto flutuantes.
A quantidade de memória ocupada por uma partícula é proporcional à precisão utilizada na representação dos dados.
Se for adotada precisão de 32 bits, uma partícula no sistema ocupa 80 bytes de memória.
A posição auxiliar permite a criação de efeitos de motion blur, uma vez que armazena a mais recente posição da partícula, enquanto que a velocidade auxiliar é utilizada nos cálculos da normal e bi-normal, necessários para a correta movimentação das partículas.
Os sistemas de partículas são armazenados em vetores.
A posição no vetor serve como identificador do sistema, uma vez que todos os processos criam os sistemas na mesma ordem, não havendo necessidade de armazenamento de outra informação.
Este identificador é utilizado na definição do sistema ativo.
Em os processos calculadores, os sistemas de partículas armazenam informações a respeito de a quantidade de partículas existentes localmente, as faixas de domínio em utilização no sistema, bem como as próprias partículas.
Primeiramente, a faixa de domínio é dividida em 10 sub-faixas.
São, então, criados dois vetores, A e B, divididos em 12 sub-vetores, um sub-vetor para cada subfaixa e os dois restantes para armazenar partículas que se deslocaram para a direita ou esquerda do domínio.
A Figura 5 exemplifica um destes vetores.
Optou- se por a utilização dos diversos sub-vetores para aceleração do processo de balanceamento de carga e envio de partículas aos outros processos.
A o final da execução de todas as ações e início do processo de obtenção das imagens, algumas partículas são trocadas entre os processos.
Caso todas as partículas tivessem sido armazenadas num único vetor, seria necessário vasculhar todas as partículas em busca daquelas que devem ser enviadas aos demais processos.
Durante o processo de balanceamento de carga, a divisão em sub-vetores reduz a quantidade de partículas que devem ser ordenadas para identificação das novas dimensões das faixas de domínio.
A o iniciar o processo de deslocamento das partículas por o espaço simulado, as mesmas se encontram todas no vetor A. Os sub-vetores extremos do vetor A podem estar vazios ou ocupados.
Este fator depende da existência ou não de ações de movimentação anteriores no mesmo quadro da animação.
Para cada partícula sobre a qual for aplicado deslocamento, ocorre a verificação da nova coordenada x da partícula.
Se o valor permanecer dentro de a sub-faixa original, a partícula permanece armazenada no vetor A, caso contrário passará a ser armazenada na respectiva sub-faixa do vetor B. Finalizado o processamento da ação de deslocamento, todas as partículas que se encontram no vetor B são novamente movidas para o vetor A. Existe a necessidade de utilização de dois vetores devido a o processamento seqüencial das partículas.
Se, caso uma partícula pertencente ao segundo sub-vetor de A tivesse que ser movida para o quarto sub-vetor, a partícula seria novamente deslocada quando o laço de processamento chegasse ao quarto sub-vetor, causando erros na simulação.
O sistema de partículas armazena a quantidade total de partículas armazenadas no sistema, bem como a quantidade de partículas em cada um dos subvetores.
Existe ainda um terceiro vetor C, presente nos processos calculadores, também dividido em n sub-vetores, onde n é o número de processos calculadores.
Cada sub-vetor armazena as partículas que se encontram dentro de a faixa de domínio do processo indicado por a posição no vetor.
Este vetor é utilizado durante os processos de trocas de partículas entre os processos, ou seja, as partículas que se encontram nas extremidades dos sub-vetor de A são distribuídas neste vetor C durante a função de obtenção das imagens e enviadas aos respectivos processos.
Este vetor C também armazena partículas a serem enviadas durante o processo de balanceamento, posteriormente descrito neste documento.
Em o processo gerente, o sistema de partículas armazena as partículas durante o processo de criação das mesmas, liberando a memória ocupada após ter- las enviado aos processos calculadores.
Os sub-vetores são, neste tipo de processo, relacionadas as faixas de domínio de cada processo calculador, sendo que os dois sub-vetores extremos não são utilizados.
O processo gerador de imagens não armazena partículas, pois as mesmas são automaticamente processadas à medida que são recebidas.
Além de a inclusão das novas funções já mencionadas, houve necessidade de modificação das demais funções para comportarem as novas estruturas de dados.
Ao invés de as funções percorrerem um único vetor, elas passam agora a percorrer diversos vetores, ou seja, houve modificação no controle do laço de execução.
Paralelamente a estas alterações, foi necessário alterar o comportamento das funções responsáveis por a criação, movimentação e obtenção da imagem final, para comportar as imposições do modelo.
Os itens a seguir detalham as alterações sobre as funções.
A ação de criação de partículas passa a ter três comportamentos, um para cada tipo de processo.
O processo gerente, da mesma forma como ocorre na biblioteca original, cria as partículas.
No entanto, ao invés de armazenar- las num único vetor, passa a armazenar as partículas nos sub-vetores, descritos anteriormente, conforme a faixa de domínio à qual a nova partícula pertence.
Após ter criado todas as partículas para o quadro da animação, quantidade esta estipulada por a aplicação do usuário, o gerente envia, para cada um dos processos, as devidas partículas.
Assim como no modelo, as partículas são divididas em blocos.
A cada bloco enviado, o gerente também envia notificação de continuação ou término do envio das partículas.
A quantidade de partículas enviadas por bloco depende da eficiência da tecnologia de rede utilizada nas simulações.
Após ter enviado as partículas, o gerente remove todas as informações armazenadas, liberando espaço para as próximas partículas a serem criadas, e sai da ação.
Os processos calculadores aguardam o início do recebimento das partículas para, então adicionar as partículas ao conjunto local.
Uma vez recebida a sinalização de término de envio, esses processos saem da ação de criação de partículas.
O processo gerador não executa nenhuma instrução existente nesta ação.
Como forma de redução das informações transmitidas, não é necessário transmitir os três valores que armazenam a velocidade auxiliar, pois esta informação ainda não foi preenchida com dados válidos.
Desta forma, são economizados 12 bytes a cada partícula transmitida, em caso de utilização de precisão de 32 bits.
As ações Move, RandomDisplacement, Restore e Vortex tiveram que ser modificadas para permitirem a alteração de sub-vetor após determinação da nova posição da partícula.
Ao invés de tornarem a armazenar a partícula no sub-vetor original, estas ações passam a comparar o novo valor da coordenada x da partícula com as dimensões estipuladas para cada um dos sub-vetores.
Havendo troca de faixa, a partícula é removida do vetor A e armazenada no vetor B, na devida posição.
É nesta função que foram embutidos os demais mecanismos de interação entre processos previstos no modelo, conforme a Figura 6.
Os processos já foram detalhados na descrição do modelo.
No entanto, alguns detalhes de implementação devem ser comentados.
Em a fase de troca de partículas entre os processos calculadores, somente as partículas que estão nas extremidades do vetor de partículas A (primeiro e último subvetor) é que são processadas, pois somente estas partículas terão deixado a faixa de domínio do processo em o qual estão sendo manipuladas.
Como medida de comparação de desempenho entre os diversos nós da simulação, foi utilizado o tempo de execução da aplicação seqüencial em cada um dos tipos de nós disponíveis.
Os tempos foram normalizados e a cada tipo de nó foi atribuído um valor de desempenho conforme a fórmula número 4.
Após receberem as ordens de balanceamento, os processos calculadores que irão doar partículas no processo de balanceamento devem coletar a quantidade informada por o processo gerente.
Uma vez que as partículas estão armazenadas em diversos vetores, não há a necessidade de ordenar todas as partículas, conforme mencionado anteriormente.
Primeiramente, deve ser identificado o vetor limite, ou seja, o vetor até o qual o processo de balanceamento deverá utilizar.
Supondo que o processo deva enviar 200 partículas para o vizinho à esquerda, é necessário identificar a partir de qual vetor esta quantidade está satisfeita.
A Figura 7 mostra uma possível distribuição de partículas nos sub-vetores e a identificação do vetor limite para 200 partículas, considerando balanceamento com o vizinho à esquerda.
Uma vez que já ocorreu o envio das partículas que se encontravam fora de faixa de domínio estipulada para o processo, os sub-vetores das extremidades encontram- se vazios, conforme demonstrado na Figura 7.
A identificação do vetor limite ocorre através da contabilização dos totais de partículas armazenadas em cada um dos sub-vetores.
Para balanceamento com o vizinho à esquerda, a contabilização deve ser em ordem crescente, do menor identificador de sub-vetor, ao maior.
Quando a contabilização atingir a quantidade de partículas a serem doadas (ou ultrapassar), terá sido identificado o vetor limite.
Em a Figura 7, contabilizando- se 50, 78, 60 e 45 tem- se um total de 233 partículas, valor superior à quantidade estipulada para o balanceamento.
O vetor limite indica que todas as partículas armazenadas nos vetores inferiores ao vetor limite (balanceamento à esquerda) devem ser enviadas ao vizinho no final do processo de balanceamento.
Para as partículas armazenadas no vetor limite existem duas opções:
Se a contabilização for igual à quantidade de partículas necessárias, todas as partículas do vetor limite devem ser enviadas, e a dimensão direita do vetor passa a ser a nova dimensão da faixa de domínio do processo, posteriormente informada ao gerente;
Se a contabilização ultrapassar a quantidade, é necessário ordenar as partículas em ordem crescente para que a quantia excedente (no final da ordenação) permaneça armazenada na faixa de domínio.
A nova dimensão da faixa passa a ser o valor da coordenada x da primeira partícula da ordenação a permanecer dentro de a faixa de domínio do processo.
As mesmas regras são aplicadas para balanceamento com o vizinho à direita, porém a contabilização das partículas ocorre da direita para a esquerda e as partículas pertencentes ao vetor limite são ordenadas de forma decrescente.
A diferença em relação a a ordenação deve- se simplesmente ao fato de que é mais rápido remover partículas que estão no final do vetor do que partículas que estão no início, pois esta última forma implicaria em movimentação dos dados para preenchimento das posições livres do vetor.
O algoritmo utilizado na ordenação das partículas é o quicksort, cujo pior tempo de execução é (n²) para um vetor de n partículas.
Apesar de o seu pior tempo de execução ser lento, quicksort é normalmente a escolha prática melhor por ser notoriamente eficiente na média, uma vez que seu tempo de execução esperado é (n log n).
Após a definição das novas faixas de domínio, seguindo os passos determinados no modelo, cada processo calculador que deve doar partículas envia para o gerente as novas informações a respeito de suas dimensões.
O gerente recebe as informações dos calculadores, atualiza as suas faixas de domínio locais e envia todas as novas faixas para todos os calculadores.
Estes, ao receberam, também atualizam as faixas locais e tornam a recalcular as sub-faixas de sua faixa de domínio.
Em a próxima ação de movimentação de partículas, as sub-faixas já devem estar determinadas.
O balanceamento das cargas ocorre logo após a atualização das dimensões, conforme descrito no modelo.
A Figura 8 demonstra a alteração nas faixas de domínios dos processos em função de a aplicação de sucessivas redistribuições de carga entre os mesmos.
A Figura 8 exemplifica o processo de simulação de um chafariz, executado por seis processos calculadores.
O estado inicial das faixas é representado na Figura 8 A, onde todas as faixas de domínio têm o mesmo tamanho.
Com o decorrer da simulação, as faixas se deslocam no eixo de divisão.
Uma vez que o modelo destina- se às máquinas agregadas heterogêneas, a quantidade de partículas em cada faixa pode não ser a mesma, pois, durante o processo de balanceamento busca- se equilíbrio de tempo de processamento.
Pode- se observar através da Figura 8 que ocorre a preservação da localidade geométrica dos dados.
É importante salientar que as faixas de domínio dizem respeito somente a um sistema de partículas, ou seja, cada sistema tem suas próprias faixas de domínio.
O código utilizado na animação do chafariz da Figura 8 se encontra no Apêndice B deste documento, juntamente com um manual resumido para compilação e utilização da biblioteca paralela.
Para análise do ganho de desempenho em função de a utilização de programação paralela em animações por sistemas de partículas, foram desenvolvidas duas aplicações utilizando- se a biblioteca descrita no capítulo anterior.
Ambas as aplicações apresentam o mesmo número de partículas e aproximadamente a mesma quantidade de trabalho aplicado sobre as partículas por meio de as ações definidas para a simulação.
A diferença entre ambas reside no comportamento atribuído às partículas, ou seja, a forma de deslocamento das partículas por o espaço simulado ocorre de forma diferente.
O intuito desta diferença é permitir avaliar o impacto do aumento da comunicação entre os processos no desempenho do modelo.
Os testes com as aplicações foram feitos no agregado Amazônia, localizado no Centro de Pesquisas em Alto Desempenho (CPAD) da PUC-RS.
O agregado é composto por os seguintes nós:
III de 550 MHz, 256 Mbytes de memória RAM (Random Access Memory);
8 nós Hp NetServer E800:
Dois processadores Pentium III de 1 GHz, 256 Mbytes de memória RAM;
Ao todo são 26 nós, interconectados por uma rede Myrinet e uma rede FastEthernet chaveada.
O acesso ao agregado ocorre através de uma máquina hospedeira externa.
Cada experimento foi executado dez vezes e os números apresentados neste capítulo representam a média das dez execuções.
Em o Apêndice C deste documento, podem ser visualizados alguns quadros da simulação de ambas as aplicações aqui descritas.
A primeira aplicação destina- se à simulação de flocos de neve, enquanto a segunda, à animação de chafarizes.
As aplicações serão detalhadas separadamente nos próximos tópicos, juntamente com a apresentação dos resultados provenientes de suas execuções.
A o final do capítulo será feita comparação entre os resultados de ambas as aplicações.
Em esta aplicação, a cada quadro da animação são geradas novas partículas, aplicado efeito da gravidade, detecção de colisão com o solo (reflexão da partícula) e remoção de gotas ou flocos que tenham atingido o limite de tempo de vida para eles estipulado.
O Algoritmo 9 demonstra as ações executadas em cada quadro da animação.
Algoritmo 9: Ações da animação de neve.
Em esta aplicação, as partículas tendem a não trocarem de faixa de domínio constantemente, pois os parâmetros utilizados nas funções caracterizam um deslocamento vertical, com leve deslocamento lateral.
Foram simulados oito sistemas de partículas, cada um com quatrocentas mil partículas.
Todos os sistemas estavam localizados na mesma posição do espaço.
A razão para divisão em oito sistemas deve- se ao fato da utilização desta mesma quantidade na outra aplicação, a ser descrita posteriormente.
Desta forma tem- se uma comparação mais justa entre as simulações.
Em cada simulação foram criados 250 quadros de animação, com mil partículas sendo criadas a cada quadro por sistema.
Em média, numa execução que utiliza dezesseis processos, ao final de cada quadro da animação, cada processo tem 560 partículas pertencentes aos demais processos, que, para o conjunto total de processos, correspondem a aproximadamente 613 Kbytes de dados a serem trocados.
Primeiramente, foram obtidos os tempos de execução da aplicação seqüencial.
A Tabela 2 apresenta os tempos médios de execução em cada um dos tipos de máquinas que compõe o agregado Amazônia.
A utilização de dois compiladores deve- se ao fato da biblioteca GM, usada para transmissão de dados via rede Myrinet, somente estar disponível para utilização com o compilador GCC no ambiente disponibilizado por o CPAD.
Por outro lado, o compilador da Intel otimiza muito mais a aplicação para os tipos de máquinas usados, possibilitando ganho de desempenho quando a rede Fast-Ethernet é utilizada.
A rede Myrinet, em função de as versões de software disponíveis, não funciona em ambientes heterogêneos compostos de diferentes arquiteturas.
Em testes efetuados no CPAD, esta rede não apresentou bom desempenho de comunicação entre as máquinas Itaniums II tendo sido, então, removida de tais máquinas.
Desta forma, não foi possível efetuar testes usando todos os nós do agregado juntamente com a utilização desta rede.
Como já foi mencionado anteriormente, os experimentos feitos com esta tecnologia de rede foram compilados utilizando- se o compilador GCC.
Os primeiros testes foram feitos com a utilização de mecanismos de balanceamento de carga estático (BCE), ou seja, não ocorre alteração nos tamanhos das faixas de domínio durante a execução da aplicação.
Primeiramente, a aplicação foi testada supondo inexistência de limite de espaço, ou seja, o espaço simulado iria de menos infinito a mais infinito.
Optou- se por não limitar o espaço por ser este o comportamento da biblioteca OpenGL.
Os resultados destas execuções, para os nós conectados por Myrinet, são apresentados na Tabela 3.
O cálculo do speed-up é obtido através da divisão do tempo de execução da aplicação seqüencial utilizando GCC numa máquina E800, por o tempo de execução Processos por Nó paralelo obtido, uma vez que este nó apresenta o melhor desempenho para este compilador.
Conforme os dados apresentados na Tabela 3, é possível perceber que a execução de três processos paralelos em nós diferentes resultou em tempo de processamento maior que o obtido através da execução seqüencial da simulação.
Embora a criação e o processamento das partículas ocorram em processos diferentes, esta divisão de trabalho não é suficiente para compensar os custos de comunicação, pois o processo de criação das partículas é relativamente rápido em comparação ao tempo gasto com as demais ações aplicadas sobre todas as partículas sendo simuladas.
O desempenho é ainda pior quando os três processos são executados na mesma máquina, possivelmente devido a o acesso seqüencial ao meio de comunicação.
Através da Tabela 3 também foi possível notar que ambos os tipos de máquinas apresenta queda significante de desempenho quando utilizada quantidade superior a dois processos por nó.
O fato de não ter ocorrido ganho de desempenho com número de processos maior do que quatro deve- se ao fato de que apenas dois processos calculadores estão efetivamente processando partículas.
Uma vez que o espaço, teoricamente infinito, mas por questões práticas limitado entre os valores 10000 e 10000 para o eixo x, é dividido igualmente entre os processos, no mínimo um e no máximo dois processos recebem partículas, pois os sistema de partículas está sendo simulado entre as coordenadas 10 e 10 do eixo x.
A mesma aplicação, quando executada em dezesseis nós, sendo oito E800 e oito E60, demora 820 segundos e 832 segundos, para dezesseis e trinta e dois processos respectivamente, ou seja, o tempo de execução é dado por as máquinas mais lentas e, com o aumento do número de processos, ocorre aumento na comunicação entre os mesmos, implicando em perda de desempenho.
Limitando o espaço simulado às dimensões utilizadas na simulação, ainda utilizando BCE, têm- se os tempos de execução e speed-ups apresentados na Tabela 4.
A limitação do espaço permite redução de até 84% do tempo de execução da aplicação, conforme os dados presentes na Tabela 4.
Ainda assim, quando executada em dezesseis nós, oito de cada tipo, o melhor tempo de execução que pode ser obtido continua sendo estabelecido por as máquinas mais lentas.
Os tempos médios de execução da aplicação em tais máquinas, usando BCE e limitação de espaço, foram 342 segundos e 238 segundos, para dezesseis e trinta e dois processos respectivamente.
Novamente, os tempos foram mais altos do que aqueles obtidos através da execução da aplicação em configurações homogêneas, porém apresenta ganho de desempenho com o aumento do número de processos.
Foram efetuados diversos testes utilizando balanceamento de carga dinâmico (BCD), com e sem limitação do espaço simulado.
Constatou- se, durante os experimentos, que os melhores resultados ocorrem quando a diferença de tempo entre os processos que ativa o balanceamento é maior ou igual a 1 segundo.
A Tabela 5 apresenta os tempos de execução utilizando BCD e espaço ilimitado, enquanto a Tabela 6 apresenta os resultados com limitação do espaço.
Tabela 6: Simulação de neve usando rede Myrinet e BCD, com espaço limitado.
Nós Tempo 813s 569s 455s 386s 340s 224s Speed-Up Nós Tempo 4587s 321s 258s 220s 194s 126s Speed-up Embora os resultados apresentados na Tabela 5 não sejam melhores que aqueles apresentados na Tabela 4, se comparados com os resultados obtidos através da utilização de BCE sem limitação do espaço (Tabela 3), é possível verificar que ocorreu ganho de desempenho em função de a distribuição da carga entre os processos.
Os testes utilizando combinações heterogêneas apresentaram, no máximo, desempenho igual a execuções sem a utilização das máquinas mais lentas, considerando utilização de todas as máquinas E800 disponíveis.
Em os testes com BCD e espaço ilimitado, os melhores tempos obtidos foram de 241 segundos e 235 segundos, para dezesseis e trinta e dois processos respectivamente, utilizando oito máquinas de cada tipo.
A limitação do espaço reduziu os tempos para 137 segundos e 148 segundos, para a mesma quantidade de processos e máquinas citados anteriormente.
As máquinas E60 podem contribuir para ganho de desempenho quando o usuário dispõe de no máximo seis máquinas E800.
Em estas situações, a adição dos nós mais lentos contribui para a obtenção de melhores resultados, desde que se utilize o mecanismo de BCD, caso contrário, as máquinas lentas determinarão o tempo de execução da aplicação.
Novamente, a limitação do espaço simulado agiliza o processo de convergência de carga entre os processos.
Testes efetuados com quatro nós de cada tipo resultaram em tempos de execução equivalentes a 290 e 274 segundos, para oito e dezesseis processos respectivamente.
O speed-up para esses casos foi de 2,76 e 2,93, sendo superior aquele obtido através da utilização de apenas quatro nós E800.
Durante os experimentos com esta tecnologia de rede, aplicou- se a mesma seqüência de testes apresentados no tópico anterior.
No entanto, o cálculo do speed-up proveniente da utilização de rede Fast-Ethernet foi feito utilizando o tempo de execução seqüencial da aplicação numa máquina Itanium II, com a utilização do compilador da Intel, já que esta apresenta o melhor desempenho do conjunto.
Os resultados provenientes das execuções da aplicação sem limitação de espaço e utilizando BCE são demonstrados nas Tabela 7 e Tabela 8.
Novamente, conforme os dados apresentados na Tabela 7, pode- se perceber que a não utilização de BCD e ausência de limitação do espaço simulado faz com que o desempenho obtido por o método paralelo seja pior do que os resultados seqüenciais.
O fato do speed-up estar sendo calculado utilizando o tempo de execução seqüencial numa máquina Itanium II também é um agravante, caso contrário as execuções para número de processos par em máquinas E800 também apresentariam ganho de desempenho em relação a a execução seqüencial neste tipo de máquina.
A Tabela 8, por outro lado, mostra que a divisão dos cálculos entre as duas máquinas Itanium II disponíveis no agregado Amazônia resulta em ganho de desempenho, com redução de até 42% do tempo.
Uma vez que as máquinas foram analisadas separadamente, não foi possível obter o tempo de execução para dois processos, pois a quantidade mínima de processos aceita por o modelo é três.
Tabela 8: Simulação de neve usando rede Fast-Ethernet, BCE, e espaço infinito em Itaniums.
Nós Itanium II Tempo 333s 385s 396s Speed-Up Não foram feitos testes combinando tipos de máquinas, pois conforme mencionado anteriormente, o tempo de execução com a utilização de BCE e espaço ilimitado depende da máquina mais lenta, o que não resultaria em melhores tempos de execução.
Os tempos de execução apresentados nas Tabela 9 e Tabela 10 não apresentam o mesmo ganho de desempenho dos experimentos feitos com rede Myrinet, o que demonstra a importância de uma rede de alto desempenho em simulações que utilizam o modelo descrito neste documento.
Mesmo que o speed-up dos experimentos em redes Myrinet tivesse usado como base o tempo de execução seqüencial em nós Itanium, ainda assim o speed-up para oito máquinas E800 com 16 processos teria sido de 4,7, valor este superior aos 2,65 alcançados por as mesmas máquinas utilizando rede Fast-Ethernet.
O comportamento dos testes feitos nas duas máquinas Itanium II, conforme dados apresentados na Tabela 10, era esperado, se comparado ao resultados da Tabela 8.
Embora a quantidade de trabalho a ser processado por os seis processos continue o mesmo, existe uma taxa maior de comunicação entre os processos, pois agora passam a existir 4 faixas de domínio sendo efetivamente utilizadas, contra duas do experimento anterior.
Os resultados de execuções paralelas com utilização de BCD e espaço finito são apresentados na Tabela 11.
Assim como observado para rede Myrinet, os resultados da Tabela 11 demonstram que o mecanismo de BCD não contribui para obtenção de melhores resultados de aplicações onde é possível delimitar o espaço simulado, quando estas são simuladas em máquinas homogêneas.
Foram realizados alguns testes com configurações heterogêneas.
Os resultados dos experimentos são apresentados na Tabela 12.
Os tempos de execução apresentados na Tabela 12 mostram que, para este tipo de tecnologia de rede, a participação das máquinas mais lentas, E60, pode contribuir para obtenção de melhores desempenhos.
Assim como pode ser observado para redes Myrinet, a participação de máquinas E60 só se justifica quanto não existe disponibilidade de execução da simulação nos oito nós E800.
2 nós E800+ 2 nós Itanium II 4 processos 2 nós E800+ 2 nós Itanium II 6 processos 4 nós E800+ 2 nós Itanium II 10 processos 6 nós E800+ 2 nós Itanium II 14 processos 7 nós E800+ 2 nós Itanium II 16 processos 8 nós E800+ 2 nós Itanium II 18 processos 8 nós E800+ 2 nós Itanium II 20 processos Tempo 427s 388s 242s 287s 218s 185s 205s 223s 241s 259s 276s 324s Speed-Up O gráfico da Figura 11 ilustra o comportamento do speed-up mediante utilização de nós E800 e Itanium nas simulações de neve realizadas com rede FastEthernet, usando BCD e limitação do espaço simulado.&amp;&amp;&amp;
O número de processos corresponde aos dados apresentados na Tabela 12.
O melhor índice de desempenho obtido para os experimentos ocorreu através da combinação de dois nós E800 e dois nós Itanium II, conforme a sexta linha da Tabela 12.
Em este experimento, foram executados dois processos em cada um dos nós E800, porém apenas um processo calculador por nó, e mais dois processos calculadores nos dois nós Itanium II.
As medidas de comparação de desempenho entre as máquinas utilizadas nesta simulação foram 1 e 1,4, atribuídas aos nós E800 e Itanium respectivamente.
Esta medida indica que, para cada partícula processada por um dos processadores de um nó E800, o Itanium II tem poder computacional para processar 1,4 partículas.
Esperava- se que, com o aumento da disponibilidade de poder computacional, houvesse compensação do tempo gasto na comunicação entre os processos, resultando em aumento de speed-up, porém o comportamento observado na Figura 11 rejeita esta hipótese.
Os efeitos aplicados sobre as partículas nesta simulação são basicamente os mesmos utilizados na animação de neve, conforme demonstrado no Algoritmo 10.
Algoritmo 10: Ações da animação de chafarizes.
1 Criação 2 Gravidade 3 Aceleração 4 Reflexão 5 Eliminação 6 Movimentação A diferença básica em relação a a simulação anterior é a inclusão do efeito da gravidade sobre as partículas, pois as mesmas podem se deslocar tanto para cima, quanto para baixo na simulação.
A diferença essencial na questão comportamental das partículas dá- se em virtude de a movimentação horizontal das mesmas, implicando em constante troca de faixas de domínio.
Novamente foram simulados oito sistemas de partículas, cada um com quatrocentas mil partículas, porém os sistemas não se encontram na mesma posição do espaço.
Desta forma pode- se avaliar o comportamento do mecanismo de balanceamento de carga em aplicações onde a delimitação do espaço simulado não é uma tarefa simples.
Assim como no experimento anterior, os tempos de execução dizem respeito à obtenção de 250 quadros de animação, com mil partículas por sistema sendo criadas a cada quadro.
Em média numa execução que utiliza dezesseis processos, ao final de cada quadro da animação, cada processo tem 4000 partículas pertencentes aos demais processos, que, para o conjunto total de processos, correspondem a aproximadamente 4375 Kbytes de dados a serem trocados.
Primeiramente, foram obtidos os tempos de execução da aplicação seqüencial.
A Tabela 13 apresenta os tempos médios de execução em cada um dos tipos de máquinas que compõe o agregado Amazônia.
Os primeiros testes foram feitos com a utilização de mecanismos de balanceamento de carga estático (BCE), seguindo a ordem dos testes feitos com a simulação de neve.
Primeiramente, a aplicação foi testada supondo inexistência de limite de espaço.
Os resultados destas execuções, para os nós conectados por Myrinet, são apresentados na Tabela 14.
O cálculo do speed-up é novamente feito utilizando- se o tempo de execução seqüencial numa máquina E800 com compilador GCC.
Em contraste à aplicação anterior, a simulação paralela dos chafarizes com a utilização de mais de um processo calculador, sem delimitação do espaço simulado e com BCE não apresentou nenhum ganho de desempenho.
Isto se deve a distribuição não uniforme das partículas, fazendo com que o tempo de simulação dos 250 quadros seja dado por o processo mais sobrecarregado.
Limitando o espaço simulado às dimensões utilizadas na simulação, ainda utilizando BCE, têm- se os tempos de execução e speed-ups apresentados na Tabela 15.
Os dados apresentados na Tabela 15 demonstram ganho de desempenho em função de a limitação do espaço simulado, porém os ganhos são bem inferiores àqueles apresentados por a simulação de neve utilizando a mesma tecnologia de rede e mesma forma de balanceamento de dados.
Dando seqüência aos testes, as Tabela 16 e Tabela 17 apresentam os resultados obtidos através da utilização de BCD na simulação dos chafarizes.
Tabela 17: Simulação de chafarizes usando rede Myrinet e BCD, com espaço limitado.
Nós Tempo 1016s 867s 741s 655s 574s 401s Speed-Up Nós Tempo 638s 537s 462s 401s 355s 248s Speed-up A Tabela 16 demonstra que o mecanismo de BCD pode possibilitar a redução dos tempos de execução de aplicações com dados distribuídos irregularmente.
O ganho de desempenho pode ser ainda maior se houver limitação do espaço simulado, mesmo que esta limitação não represente exatamente a porção utilizada do espaço, conforme resultados demonstrados na Tabela 17.
Devido a o aumento de comunicação entre os processos, tanto em função de as partículas que trocam de faixa de domínio, como das partículas que devem ser balanceadas, não foi possível obter ganho de desempenho igual ao alcançado com a aplicação que simula flocos de neve.
Ao contrário de o comportamento observado para a outra aplicação, a utilização de 16 nós, oito do tipo E800 e oito E60, resultou em redução dos tempos de execução.
Os tempos obtidos foram 259 segundos e 221 segundos, para dezesseis e trinta e dois processos respectivamente, com speed-ups de 3,66 e 4,28.
O acréscimo de poder computacional compensa parte da perda de desempenho em função de o aumento de comunicação.
É possível que a presença de um número maior de processadores e, conseqüentemente de processos, distribua melhor a utilização do meio de comunicação, permitindo ganho de desempenho.
Os experimentos utilizando redes Fast-Ethernet não apresentaram ganho de desempenho que justifique a utilização de máquinas agregadas, excetuando- se os experimentos heterogêneos apresentados na Tabela 18.
Possivelmente, os resultados ruins são em decorrência da alta dependência nos meios de comunicação nesta aplicação, uma vez que ocorre uma troca maior de partículas entre os processos.
2 nós E800+ 2 nós Itanium II 4 processos 2 nós E800+ 2 nós Itanium II 6 processos 4 nós E800+ 2 nós Itanium II 6 processos Tempo 529s 512s 587s Speed-Up O cálculo do speed-up foi feito utilizando o tempo de execução da simulação seqüencial numa máquina Itanium, tempo este equivalente a 645 segundos, conforme a Tabela 13.
Os resultados das simulações de ambas as aplicações levam as seguintes considerações:
A utilização de BCE em distribuições regulares ou irregulares e sem redução do espaço simulado resulta em perda de desempenho da aplicação, pois, excetuando- se as ocasiões onde as partículas estão localizadas ao longo de a extensão do eixo x, existe grande chance de que os processadores permaneçam ociosos durante a simulação, uma vez que não existem partículas pertencentes a sua faixa de domínio.
O aumento no número de processos implica em aumento de comunicação, mesmo que somente para sincronização entre os processos.
Sendo assim, os processos ociosos tendem a aumentar o tempo de simulação;
Havendo distribuição de carga uniforme e sendo possível delimitar o espaço simulado, o uso de BCD faz- se necessário somente em agregados heterogêneos.
Em agregados homogêneos, caso o espaço delimitado tenha as mesmas fronteiras que os sistemas de partículas em simulação, o equilíbrio entre as cargas dos processos ocorre de forma natural, pois cada processo terá recebido uma fatia do espaço com quantidade de partículas aproximada à de seus vizinhos;
Havendo distribuição irregular de carga, o uso de BCD se faz necessário também em agregados homogêneos, pois não existe garantia de que as quantidades iniciais de partículas atribuídas aos processos permaneçam inalteradas durante a simulação.
Porém, para que ocorra ganho de desempenho com a utilização deste mecanismo, é necessária a utilização de redes de alto desempenho ou, então, máquinas cujo poder computacional compense as perdas causadas por a intensa comunicação entre os processos.
O modelo não apresentou desempenho satisfatório quando utilizado em aplicações irregulares, executadas utilizando BCD e redes Fast-Ethernet, possivelmente em função de o volume de dados que são trocados entre os processos a cada quadro da animação.
Em estas aplicações, existe intensa comunicação para envio e recebimento de partículas que trocam de faixas de domínio.
Este fato pode ser observado mesmo quando a simulação utiliza rede Myrinet, pois o melhor tempo obtido para a animação de chafarizes foi, aproximadamente, o dobro do tempo necessário para a animação de neve.
Além de a troca de partículas em função de deslocamento entre as faixas, existe também custo de comunicação em função de o balanceamento das cargas.
Para as situações restantes, o ganho de desempenho justifica a utilização de máquinas agregadas, pois foi possível reduzir o tempo de execução da primeira aplicação em até 84% usando rede Myrinet e, em até 68% usando Fast-Ethernet.
A segunda aplicação apresentou redução de até 66% do seu tempo de execução com a utilização de dezesseis nós e rede Myrinet.
A seguir, são apresentados alguns gráficos de comparação de desempenho entre as aplicações e entre as tecnologias de rede utilizadas no processo de validação do modelo.
O gráfico apresentado na Figura 12 ilustra a perda de desempenho em aplicações com dados regulares com a adição de máquinas mais lentas.
Em contraste, a adição de tais máquinas possibilita redução de tempo em casos de dados irregulares, conforme demonstrado por o speed-up obtido nos processos de simulação de chafarizes.
O gráfico da Figura 13 compara os speed-ups obtidos através da utilização de nós E800 e Itanium, com utilização de rede Fast-Ethernet.
São apresentados somente as três combinações que resultaram nos três melhores índices de desempenho.
Comparando todos os experimentos, tanto para simulação de neve como de chafarizes, os melhores tempos foram sempre obtidos com utilização da rede Myrinet, independentemente da forma de distribuição dos dados.
A utilização de nós Itanium somente reduziu o tempo de obtenção das imagens quando comparado com as demais simulações que utilizam rede Fast-Ethernet, uma vez que os melhores tempos de execução de ambos os experimentos são alcançados somente mediante utilização destes nós, porém com participação de máquinas E800.
Este trabalho descreveu um modelo para geração de animações por sistemas de partículas em máquinas agregadas heterogêneas, embora o modelo descrito também possa ser utilizado em agregados homogêneos sem necessidade de alteração.
O modelo, prevendo a possibilidade de inclusão de métodos de detecção de colisão entre as partículas, preserva a localidade geométrica das partículas quando estas são enviadas a outros processos.
Também, em função de a decomposição espacial do espaço simulado, o modelo utiliza mecanismos de balanceamento de carga dinâmico que mantém as partículas próximas de suas vizinhas.
A forma como o modelo foi construído permite ao usuário utilizar balanceamento de carga estático, bastando que o mesmo delimite o espaço da simulação para que possam ser atribuídas áreas com trabalho a ser realizado a todos os processos.
Com o intuito de validar o modelo, foi desenvolvida uma biblioteca paralela para animações por sistema de partículas que permite a criação de inúmeros sistemas concomitantes, bem como a criação de diversos efeitos a serem aplicados sobre as partículas, a partir de blocos de efeitos simplificados.
Os experimentos feitos com a biblioteca demonstram que a mesma permite a obtenção de ganho de desempenho, mesmo em aplicações com dados irregulares, desde que haja disponibilidade de utilização de redes de alto desempenho ou, então, de máquinas cujo poder computacional é capaz de compensar os custos de comunicação.
Infelizmente, o desempenho do modelo em simulações com dados irregulares e com utilização de redes Fast-Ethernet não atendeu às expectativas.
Também não foi possível testar a heterogeneidade total da máquina agregada Amazônia utilizando rede de alto desempenho em função de as restrições impostas por a biblioteca GM.
Os resultados obtidos utilizando- se BCD apontam para ganhos de desempenho superiores caso fosse possível mesclar nós Itanium II e E800, juntamente com a utilização da rede Myrinet.
As máquinas Itanium II não apresentaram o desempenho esperado, sendo que o tempo de execução de aplicações nestas máquinas só é melhor que o tempo das demais quando o código da aplicação é gerado através do compilador Intel.
Embora tenham podido processar, em média, 40% a mais de partículas que as máquinas E800, o desempenho dessas máquinas deixou a desejar.
É importante salientar que os experimentos foram executados em estações de trabalho Hp zx2000, máquinas que já não são mais produzidas.
Espera- se que a utilização de equipamentos mais modernos, como servidores Hp Integrity rx2600, possibilite ganhos de desempenho mais satisfatórios.
Os resultados deste trabalho serão publicados nos anais do 6o Workshop on Parallel and Distributed Scientific and Engineering Computing Visando a obtenção de melhores resultados, tanto em relação a a questão comportamental das partículas como em relação a o tempo de obtenção das animações, seguem abaixo algumas propostas para trabalhos futuros:
Utilização de mecanismos para geração remota de imagens, tais como WireGL ou Pomegranate, uma vez que o tempo de envio de todas as partículas para o gerador de imagens representa um gargalo no sistema (o tempo para obtenção das imagens após recebimento das partículas tem pequena participação no tempo total da animações);
Inclusão de mecanismos que possibilitem interconectar partículas, permitindo desta forma a simulação de tecidos, por exemplo;
Descentralização da gerência do mecanismo de balanceamento de carga, visando menor necessidade de sincronismo entre os processos e, como conseqüência, redução do tempo de obtenção dos quadros da animação.
Validação do modelo utilizando os cinco novos nós SMP Itanium II que, no momento, encontram- se em fase de instalação no agregado Amazônia.
