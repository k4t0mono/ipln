Esta dissertação de mestrado apresenta um ambiente de suporte a cooperação entre instituições de pesquisa da área de Otimização Combinatorial.
Esse ambiente é definido por a arquitetura InterCOD.
A arquitetura InterCOD possibilita que essas instituições cooperem de maneira descentralizada e autônoma, suportando a heterogeneidade entre elas.
A arquitetura emprega o conceito de centros de otimização.
Os centros de otimização organizam, agrupam e disponibilizam os serviços a serem compartilhados entre a comunidade científica da área.
Utiliza- se a Internet para a troca de informações entre os centros de otimização.
O conjunto de centros, quando interligados, recebe o nome de federação.
Entende- se por autonomia o controle de cada instituição sobre a sua participação na federação.
Elas devem ter controle sobre o compartilhamento dos seus recursos, ou seja, escolher quando participar da federação.
Quando conectadas, recebem e enviam requisições aos demais centros de otimização.
Quando não conectadas, operam somente com os serviços do seu centro de otimização.
Um protótipo foi desenvolvido para a arquitetura InterCOD.
Ele teve por objetivo validar as idéias propostas por esse trabalho.
Em o desenvolvimento desse protótipo foi utilizado Java/ RMI.
O crescimento da utilização da Internet é um fato.
Cada vez mais a grande rede vem sendo utilizada para os mais diversos fins, tanto no meio comercial, como no meio acadêmico.
Entre os avanços proporcionados por a disseminação na utilização da Internet pode- se citar a possibilidade de integrar sistemas de uma forma ágil e barata.
A integração entre sistemas tende a evitar a duplicação de esforços, pois facilita a disponibilização de serviços compartilhados entre equipes distantes, auxiliando a troca de experiências entre elas.
Porém, muitas vezes, apenas disponibilizar serviços não é suficiente.
Prover ambientes distribuídos na Internet que agrupem e facilitem o acesso a estes serviços é importante, em certas áreas, pode- se dizer, fundamental.
Logo, busca- se desenvolver ambientes que facilitem a cooperação entre essas equipes.
A área de otimização combinatorial é uma área de pesquisa que desenvolve algoritmos para os problemas de otimização combinatorial.
O problema do caixeiro viajante e o problema de alocação de recursos são alguns dos problemas mais conhecidos, estudados por a comunidade de otimização.
Esta área apresenta algumas características que justificam a investigação de mecanismos de distribuição que permitam a criação de um ambiente que suporte a cooperação:
Apresenta algoritmos legados com estruturas muito semelhantes, passíveis de serem disponibilizados, proporcionando reutilização de código;
Grande parte dos algoritmos de otimização conhecidos, freqüentemente, tomam muitos ciclos de tempo do processador (processos CPU-bound).
A distribuição destes processos aliada a uma política de balanceamento de cargas possibilitaria que os processos mais pesados fossem executados em nodos com maior capacidade de processamento;
Necessidade de comparação de resultados na investigação de novos algoritmos de otimização.
É comum os pesquisadores da área compararem resultados obtidos em seus esforços de pesquisa com resultados já validados por a comunidade científica.
Logo, a criação de um ambiente distribuído que permita aumentar a disponibilidade dos algoritmos de otimização justifica- se.
Em o projeto de Centros de Otimização Distribuídos (PeCOD), em andamento na Universidade Federal de Santa Maria e Pontifícia Universidade Católica do Rio Grande do Sul, investigam- se mecanismos de distribuição que permitirão criar um ambiente que suporte a cooperação entre os pesquisadores da área de otimização.
A definição de um ambiente distribuído que busque atingir essa cooperação tem que lidar com problemas inerentes aos sistemas distribuídos, tais como:
Desta forma, o presente trabalho tem por finalidade descrever uma arquitetura distribuída que suporte o ambiente de cooperação objetivado por o PeCOD.
Essa arquitetura distribuída, denominada de InterCOD -- Uma Arquitetura Distribuída de Suporte à Centros de Otimização Cooperantes na Internet foi concebida para trabalhar no ambiente Internet, sendo que propósito inicial de suportar cooperação entre instituições (eventualmente distantes) na área de otimização combinatorial foi alcançado, considerando os problemas acima citados.
A arquitetura InterCOD investiga a possibilidade de distribuição de algoritmos que resolvam o Problema do Caixeiro Viajante Simétrico, sendo que este é um dos problemas na área de otimização.
A escolha desse problema justifica- se porque segundo Junger esse é um dos problemas mais estudados na área, além de o fato de muitos dos problemas de otimização conhecidos poderem ser reduzidos a ele.
A arquitetura suporta entidades autônomas cooperantes que agrupam e disponibilizam os algoritmos de otimização como serviços aos usuários.
Os usuários podem requisitar esses serviços através da Internet.
A cooperação entre as entidades autônomas caracteriza- se por o compartilhamento de serviços (implementações de algoritmos de otimização e dados de entrada) entre elas.
Cabe salientar que os algoritmos de otimização disponibilizados por uma das entidades podem ser utilizados por outras entidades remotas.
Um protótipo para a arquitetura distribuída InterCOD foi desenvolvido.
Esse protótipo teve como propósito a validação e verificação das funcionalidades descritas nesse trabalho.
É importante ressaltar que aspectos ligados ao balanceamento de carga e tolerância a falhas foram tópicos pouco explorados no trabalho.
Idealmente, supõe- se um ambiente sem falhas de processamento e comunicação e evita- se o comprometimento de completeza com estes assuntos.
A apresentação da dissertação está organizada da seguinte forma:
Em o Capítulo 2 são apresentados aspectos dos problemas de otimização combinatorial.
São definidos conceitos utilizados na área, os quais facilitam a compreensão de nomenclaturas usadas no decorrer de o texto.
Em o Capítulo 3 realiza- se uma breve comparação entre duas arquiteturas de objetos distribuídos, CORBA e RMI.
A abstração apresentada por essas arquiteturas para a troca de mensagens entre objetos em máquinas remotas motivou a utilização de uma destas arquiteturas.
A codificação torna- se mais simples, pois a comunicação entre os objetos é abstraída por essas arquiteturas.
A escolha da arquitetura de suporte utilizada para a implementação do protótipo é justificada por a análise das vantagens e desvantagens obtidas na comparação.
Em o Capítulo 4 a arquitetura distribuída InterCOD é descrita integralmente.
São apresentados os módulos que compõem a arquitetura e os mecanismos de comunicação adotados entre eles.
Em o princípio do Capítulo são apresentados dois trabalhos relacionados, os quais também promovem a criação de um ambiente de cooperação distribuído para o mesmo fim.
Em o Capítulo 5 são apresentados os aspectos da implementação do protótipo, destacando o diagrama de classes da arquitetura, por exemplo.
Em o Capítulo 6 são apresentados os resultados obtidos com a modelagem e implementação da arquitetura InterCOD, ressaltando- se as extensões que este trabalho pode oferecer.
Por último, as referências bibliográficas são apresentadas.
A otimização combinatorial ganhou força a partir de a sua aplicação em Pesquisa Operacional, a qual propõe- se a resolver problemas através de um enfoque racional da estrutura de cada problema.
A otimização combinatorial representa o estudo matemático que busca encontrar uma solução razoável que minimize ou maximize uma função objetivo num conjunto combinatorial discreto de soluções possíveis.
Existem muitos tipos de problemas classificados como combinatoriais, como por exemplo:
O problema de escalonamento de tarefas a processadores, mais conhecido como problema de scheduling, o problema de alocação de recursos, chamado de problema de assignment, o problema de alocação de ítens num dado recipiente, chamado de problema da mochila, e o problema do caixeiro viajante que trata o problema de minimização de distâncias num ciclo hamiltoniano.
Todos estes problemas são classificados por a teoria da complexidade computacional, a qual contribui na área de otimização combinatorial fornecendo métodos rigorosos de avaliação de algoritmos e classificando problemas.
Segundo a teoria da complexidade computacional os problemas de otimização são classificados segundo a sua complexidade em P, Np, Np-hard e Np-completo.
Os problemas pertencentes à classe P são ditos tratáveis computacionalmente, já os demais são considerados intratáveis.
Entende- se por intratáveis os problemas que nem sempre possuem algoritmos eficientes para a sua resolução em tempos de processamento polinomiais.
Um algoritmo é dito determinístico se, a cada passo do seu fluxo de controle, o próximo passo é único.
Em os algoritmos não-determinísticos o próximo passo é escolhido aleatoriamente entre um número fixo de possibilidades e o fluxo do algoritmo converge conforme os resultados intermediários obtidos durante o processamento.
Os problemas de otimização combinatorial são constituídos por um ou mais algoritmos de otimização e por uma ou mais instâncias de dados.
A classificação mais ampla para os métodos de resolução de problemas de otimização divide- os em métodos exatos e métodos heurísticos.
Os algoritmos exatos possuem a característica de atingirem soluções ótimas, mas em tempos de processamento exponenciais para problemas de grandes dimensões.
Como na área de otimização combinatorial a maioria dos problemas reais encontrados podem ser considerados Algoritmos de otimização e métodos de resolução são usados como sinônimos.
Logo os esforços de pesquisa na área investigam métodos com o objetivo de encontrar soluções para problemas combinatoriais reais em tempos de processamento polinomiais.
Estes métodos recebem o nome de métodos heurísticos.
Os algoritmos heurísticos atingem boas soluções, não necessariamente ótimas, e evitam a explosão combinatorial de possibilidades, permitindo a resolução de problemas de otimização reais em tempos de processamento polinomiais.
Segundo Newell, os métodos heurísticos são definidos como processos que podem solucionar um determinado problema.
De este modo, heurísticas tem ganho muita importância para solucionar problemas reais de consideráveis dimensões em tempos de processamento razoáveis.
Entretanto a qualidade das soluções obtidas através de heurísticas clássicas não são completamente satisfatórias para todos os problemas numa determinada classe de problema considerada.
São exemplos de heurísticas encontradas:
Coloração de grafos, caixeiro viajante, mochila, e partição de números.
Em geral, as heurísticas são desenvolvidas para problemas específicos, não havendo praticamente, procedimentos de uso geral.
As instâncias de dados são estruturas de dados padronizadas por a comunidade científica que servem como entrada de dados para os métodos de resolução descritos no item 2.1.1.
Um exemplo destas padronizações é Travelling Salesman Problem Library (TSPLIB) que define a entrada de dados para os problemas do caixeiro viajante.
Problema do Caixeiro Viajante Simétrico Em o protótipo, foram considerados os algoritmos que resolvem o problema do caixeiro viajante simétrico.
Portanto, comenta- se a seguir, as principais características deste problema.
O objetivo de discutir as propriedades deste problema é possibilitar ao leitor uma melhor compreensão dos termos da área de otimização.
O problema do caixeiro viajante simétrico (PCVS) trata de um problema de minimização de distância.
Dados um conjunto de Q cidades, a distância entre cada uma de elas e uma cidade como ponto de partida, o algoritmo para este problema deve percorrer todas as outras cidades, passando por todas elas uma única vez e retornar ao ponto de partida.
O objetivo do algoritmo é minimizar a distância total percorrida.
Ele é dito simétrico quando a distância para ir de uma cidade L até a uma cidade M é a mesma da cidade M à cidade L, e assimétrico quando esta relação não for preservada.
A Figura 1 apresenta um conjunto com 12 cidades e uma possível rota para percorrer- las.
Em este caso trata- se de um PCVS, pois todas as distâncias entre as cidades respeitam a relação de igualdade na ida e na volta.
Segundo Junger, o problema do caixeiro viajante está incluído entre os mais difíceis problemas de otimização a serem resolvidos, porém por se tratar de um problema clássico da área de otimização combinatorial, muitas heurísticas disponíveis apresentam boas soluções para o problema.
As heurísticas que resolvem o PCVS podem ser classificadas em construtivas, de melhoramento e metaheurísticas.
As heurísticas construtivas adicionam componentes individuais (nós, arcos, variáveis, etc) passo a passo até que uma solução para o problema seja gerada.
As heurísticas de melhoramento utilizam o resultado obtido por o método construtivo e sucessivamente ao longo de o seu processamento vão excluindo e adicionando novos componentes às soluções intermediárias, com o objetivo de encontrar uma solução de maior qualidade.
A heurística de melhoramento encerra a execução quando nenhuma alteração de melhora pode ser alcançada.
Em este instante diz- se que a heurística de melhoramento atingiu um ótimo local.
Como exemplos de heurísticas construtivas para o PCVS pode- se citar:
A inserção mais barata (IMB), a inserção mais distante (IMD), a inserção mais próxima (IMP) e o vizinho mais próximo (VMP). Enquanto
para as heurísticas de melhoramento pode- se citar:
2-OPT e Lin Kemigham (LK) As entradas de dados para estas heurísticas são padronizados por a TSPLIB.
Os arquivos disponíveis na TSPLIB são constituídos de duas partes, uma de especificações do arquivo e outra que contém os dados de entrada propriamente ditos.
Utilizou- se a instância de dados denominada de GR17 para apresentar as partes componentes de um arquivo padrão usado como entrada de dados:
O nome da instância de dados, o qual é identificado na Figura 2 como GR17;
O tipo do problema ao qual a instância de dados se destina, se PCV ou PCVS por exemplo.
Em a Figura 2 o tipo é identificado por TSP;
TSP vem de Travelling Salesman Problem (ou Problema do Caixeiro Viajante) As informações adicionais da instância de dados define o nome do criador da instância por exemplo ou outras informações;
A dimensão da instância de dados, na Figura 2 determina- se por 17 nodos;
O formato do arquivo, na Figura 2, é matriz superior;
A o final do arquivo, na seção EDGE_ WEIGHTED_ SECTION, são apresentados os dados propriamente ditos da instância de dados, ou seja, os nodos que compõem instância.
A Figura 2 apresenta o arquivo exemplo utilizado nas descrições acima.
Devido a fatores como o barateamento do processamento, a maturidade de tecnologias utilizadas em redes de computadores, necessidade de maior flexibilidade e escalabilidade na infraestrutura computacional, bem como a crescente necessidade de comunicação entre organizações, a atual infra-estrutura de informação predominante é composta por nodos processadores heterogêneos interconectados para a troca de informação.
Em este contexto, as aplicações consequentemente passam a ser compostas por módulos comunicantes dispostos em máquinas remotas.
A interação entre módulos distribuídos pode acontecer mediante a utilização de vários tipos de mecanismos.
Alguns de eles exigem que o desenvolvedor de aplicações trate problemas de localização e se envolva na comunicação entre tais módulos como:
Sockets e Remote Procedure Call).
O trabalho integrado de duas áreas de pesquisa na tecnologia da informação tem suportado o desenvolvimento de aplicações que atendem ao contexto de troca de informações entre nodos heterogêneos.
Ao mesmo tempo tem facilitado as tarefas do desenvolvedor, evitando que o mesmo envolva- se com problemas de localização e comunicação entre os módulos.
As duas áreas de pesquisa são:
Orientação a objetos Sistemas distribuídos O paradigma de orientação a objetos tem causado mudanças significativas na análise, projeto e desenvolvimento de sistemas.
O desenvolvimento de software orientado a objetos tem se acentuado com a promessa de aumento de modularidade, reusabilidade e conseqüente facilidade de construção.
Apesar de as vantagens, a orientação a objetos possui áreas ainda não totalmente exploradas, especialmente na integração com sistemas legados.
O aumento da capacidade de processamento das estações de trabalho acelerou o interesse em adaptar as aplicações de grande porte para estações de trabalho, distribuindo funcionalidades entre estes nodos.
Através dos conceitos definidos por a pesquisa em sistemas distribuídos migra- se de uma infra-estrutura de plataformas homogêneas para outra geograficamente aberta e composta por máquinas heterogêneas.
Este fato contribuiu para uma crescente necessidade de desenvolvimento de software para ambientes distribuídos.
A partir de estas justificativas, testemunhou- se nos últimos anos a fusão da orientação a objetos e sistemas distribuídos.
A fusão permitiu que objetos fossem utilizados em sistemas distribuídos para representarem unidades de distribuição, mobilidade e comunicação.
As arquiteturas de suporte a objetos distribuídos têm como característica básica a facilidade de troca de mensagens entre objetos em máquinas remotas, algumas vezes suportando um conjunto de transparências de distribuição que facilitam a tarefa do desenvolvedor de aplicações distribuídas.
Alguns exemplos de transparências encontradas são:
Transparência de Acesso:
Permite comunicação de objetos escritos em diferentes linguagens de programação, executados em plataformas heterogêneas;
Transparência de Localização: Torna transparente ao desenvolvedor os detalhes de localização de objetos (endereços de rede, portas, etc).
Transparência de Relocação:
Torna transparente ao desenvolvedor o problema da atualização de referências quando objetos utilizados são relocados (mudam de local onde estão executando);
Transparência de Migração: Torna transparente ao desenvolvedor o fato de que o local de execução do objeto pode ser mudado;
Transparência de Persistência: Esconde aspectos de ativação e desativação de objetos, ou seja, os objetos são inicializados sob demanda e desativados quando não são mais necessários, porém o seu estado é mantido de forma persistente;
Transparência de Replicação: Torna transparente a existência de um grupo de objetos comportamentalmente compatíveis.
Objetos podem ser replicados para manter níveis de disponibilidade e desempenho de seu serviço.
Algumas arquiteturas de suporte a objetos distribuídos estão disponíveis em forma de especificação, em forma de produtos, ou ainda como resultado de esforços de pesquisa.
Em este capítulo serão comparadas as propriedades das arquiteturas de suporte a objetos distribuídos Java Remote Method Invocation (RMI) e Commom Object Request Broker Architecture (CORBA).
Serão apresentadas vantagens e desvantagens de cada uma de elas.
Este estudo justificará a escolha de RMI para a implementação do protótipo da arquitetura.
A Arquitetura CORBA Definida por a Object Management Group (OMG), o Object Management Architecture (OMA) tem por objetivo definir padrões mínimos para alcançar interoperabilidade em ambientes heterogêneos.
O OMG é um consórcio de empresas, universidades e centros de pesquisa que buscam a identificação e especificação destes padrões.
O OMA é composto por um modelo de objetos e por um modelo de referências.
O modelo de objetos define padrões para a descrição de objetos distribuídos em ambientes heterogêneos, enquanto o modelo de referências, a interação entre estes objetos.
Em o modelo de objetos definido por o OMA um objeto é uma entidade encapsulada composta por uma identificação imutável e por um conjunto de serviços.
O conjunto de serviços de cada objeto só pode ser acessado por meio de interfaces bem definidas.
A implementação e a localização dos serviços são transparentes ao cliente.
O Object Request Broker (ORB), definido como o principal componente do OMA, é o responsável por facilitar a comunicação entre clientes e objetos.
A especificação CORBA detalha as interfaces e características do componente ORB padronizado por o OMA.
Os outros componentes do OMA são:
Objetos de serviços:
Interfaces de serviços que adicionam mais funcionalidades às funções básicas do ORB.
Por exemplo, um serviço que recupere referências a objetos remotos.
Dois exemplos de serviços definidos por o OMA resolvem este problema:
O serviço de nomes (o qual permite que o cliente recupere a referência a um objeto remoto através do seu nome) e o serviço de trader (onde o cliente recupera a referência através de uma consulta às propriedades do objeto remoto).
O conjunto completo de serviços está definido em;
Facilidades comuns:
Interfaces de serviços orientados a aplicações de usuários finais (end-user applications).
Por exemplo, a facilidade de criar uma ligação entre uma planilha eletrônica e um relatório, definida por o padrão Distributed Document ComponentFacility (DDCF);
Facilidades de domínio:
Interfaces de serviços orientadas a domínios de aplicação específicos.
Por exemplo, alguns exemplos de interfaces de domínios já disponíveis estão ligadas às áreas de telecomunicação, médica e financeira.
O conjunto completo de domínios padronizados por a OMG está definido em.
Em a Figura 3 representa- se os diversos domínios existentes;
Objetos de aplicação:
Interfaces desenvolvidas para uma aplicação específica.
Como a OMG não desenvolve aplicações (mas padrões) estas interfaces não possuem padronização.
Porém, se com o passar do tempo um grupo de serviços sobressair- se em determinado domínio de aplicação, ele pode tornar- se candidato a uma futura padronização da OMG.
A Figura 3 apresenta os componentes do OMA:
Transparência de acesso e localização, conforme definidos Objetos de Aplicação Facilidades de Facilidades de Interfaces de domínio Interfaces de domínio Domínio Domínio Facilidades comuns Object Request Broker Legenda:
A especificação da arquitetura CORBA definida por a OMG possui os seguintes componentes:
ORB Core:
Conforme citado anteriormente, o ORB realiza a passagem de requisições aos objetos e retorno das respostas aos clientes de origem.
A principal característica apresentada por o ORB é a transparência na comunicação entre cliente e objeto requerido;
OMG Interface Definition Language (OMG IDL):
Para que o cliente possa realizar requisições, ele deve conhecer os tipos das operações suportados por o objeto.
A interface do objeto especifica as operações, os tipos suportados e as requisições que podem ser realizadas por o cliente.
A linguagem de interfaces criada por a OMG chamase OMG IDL.
A OMG IDL é uma linguagem apenas declarativa, pois não suporta estruturas de controle;
Repositório de interfaces:
Toda aplicação baseada na arquitetura CORBA necessita de interfaces OMG IDL durante a execução.
O repositório de interfaces permite que o sistema de tipos da interface possa ser conhecido em tempo de execução.
Assim, evitase que a aplicação tenha de ser recompilada a qualquer modificação nos tipos de dados utilizados por a interface;
Stubs e esqueletos:
O Stub é um mecanismo que permite ao cliente realizar a requisição, enquanto o esqueleto é o mecanismo que entrega a requisição ao objeto.
Outra funcionalidade do Stub é armazenar a referência remota ao objeto.
Enviar requisições através dos Stubs e esqueletos denomina- se invocação estática, ou seja, cada aplicação cliente possuirá o seu Stub respectivo, bem como a implementação do objeto, o seu esqueleto;
Interface de invocação dinâmica (dynamic invocation interface ­ DII) e interface de entrega dinâmica (dynamic skeleton interface ­ DSI):
A DII suporta uma requisição Os stubs e os esqueletos são compilados a cada modificação realizada na interface da implementação do objeto.
Adaptador de objetos:
É um componente que converte as requisições da aplicação cliente na interface que verdadeiramente irá requisitar o serviço à implementação do objeto.
É através do adaptador de objetos que a arquitetura CORBA suporta a diversidade de implementações de objetos.
O adaptador de objetos comprova a tentativa da OMG de manter o ORB o mais simplificado possível.
A arquitetura RMI Sistemas distribuídos possuem como característica básica a execução de módulos em diferentes espaços de endereçamento.
Um mecanismo de comunicação básico suportado por a linguagem JavaTM são os sockets.
Porém, conforme citado no princípio do capítulo, os sockets exigem que a aplicação desenvolvida trate aspectos de comunicação e localização entre o cliente e o servidor.
O tratamento destes aspectos pode se tornar muito inconveniente e suscetível a erros.
Outra alternativa citada foi o Remote Procedure Call (RPC).
O RPC é um modelo para distribuição de código procedural, logo não suporta a distribuição de código orientado a objetos.
Em os códigos orientados a objetos muitos dos argumentos e valores de retorno trocados entre os procedimentos são na verdade objetos (ou seja tipos complexos), ao passo que RPC suporta apenas um conjunto limitado de tipos básicos.
Esta limitação impõe que o desenvolvedor lide com problemas de conversão de dados dentro de as aplicações, tarefa igualmente inconveniente e suscetível a erros.
Com o objetivo de disponibilizar um mecanismo mais simples para construção de aplicações distribuídas na linguagem Java, a arquitetura de suporte a objetos distribuídos Java Remote Method Invocation (RMI) é adicionada à mesma.
RMI é uma arquitetura de objetos distribuídos suportada por a Java Virtual Machine (JVM) através da sua Application Programmable Interface (API).
A arquitetura RMI integra à linguagem Java um modelo de objeto distribuído, permitindo que objetos Java que executam em diferentes JVMs requisitem serviços entre si.
O tratamento de conversão de dados e protocolos de comunicação é tratado por a arquitetura de objetos distribuídos e transparente para o programador.
RMI utiliza um mecanismo de comunicação padrão, adotado do RPC, para comunicação entre objetos remotos:
StubV e esqueletos.
O Stub atua no lado cliente da aplicação como um identificador local (surrogate) do objeto remoto.
Já o esqueleto é responsável por a entrega da requisição ao objeto.
As informações trocadas entre o Stub e o esqueleto sempre são entregues ou recebidas através do marshal stream.
O marshal é um stream de dados usado para transportar parâmetros, exceções e erros.
Em a arquitetura RMI o Stub realiza as seguintes operações para que uma aplicação cliente possa requisitar serviços a um objeto:
Inicialização da conexão com a JVM remota que contém o objeto requerido;
Marshalling (escrita e transmissão) dos parâmetros da requisição a JVM remota;
Aguardar por o resultado da requisição disparada, posto que o RMI possui suporte somente para comunicação síncrona;
Unmarshalling (leitura) dos valores ou exceções recebidos;
Retorno do resultado a aplicação cliente.
O esqueleto, ao receber a requisição de um Stub, é responsável por:
Unmarshalling (leitura) dos parâmetros recebidos do Stub;
Invocar a implementação do objeto, realizando a execução do método requisitado com os parâmetros recebidos;
Marshalling (escrita e transmissão) do resultado ao Stub de origem.
Outros componentes da estrutura RMI são a camada de referência remota e a camada de transporte.
A camada de referência remota é a abstração entre as classes Stub/ esqueleto e os protocolos suportados por a camada de suporte.
A comunicação entre a camada de referência remota e a camada de transporte é realizada através de um stream orientado a conexão.
Suporte a replicação de objetos, estratégias para a recuperação a falhas para conexões e persistência de objetos serão adicionadas.
A camada de transporte é responsável por gerenciar a comunicação entre máquinas remotas.
Ela disponibiliza streams que são acessados por a camada de referência remota para enviar e receber dados de máquinas remotas.
O protocolo padrão utilizado é o TCP/ IP.
A camada de transporte ativa as conexões às máquinas remotas, gerência e monitora a conexão, verificando se ela está ativa e aguarda por conexões de outras máquinas.
A camada de transporte pode ser modificada para suportar streams com suporte a criptografia, algoritmos para compressão de dados entre outros aprimoramentos.
Por a independência que existe entre esta camada e a camada de referência remota, os StubV/ esqueletos não necessitam conhecer as modificações ocorridas na camada de transporte.
Segundo Hericko, os critérios que devem ser levados em consideração na comparação entre duas arquiteturas de objetos distribuídos são:
Propriedades apresentadas, maturidade, suporte a aplicações legadas, facilidade de desenvolvimento, desempenho e escalabilidade.
Em este estudo o autor apresenta os seguintes resultados:
Propriedades das arquiteturas:
Por ser uma plataforma de objetos distribuídos completa, com suporte a diferentes linguagens de programação, CORBA apresenta vantagens em comparação a RMI.
Porém, a restrição de RMI suportar apenas a linguagem Java faz com que esta arquitetura suporte algumas vantagens não encontradas na combinação Java/ CORBA;
Maturidade da arquitetura:
A arquitetura CORBA é mais madura que a arquitetura RMI.
Com a primeira versão datada de 1992, CORBA é amplamente utilizada no mercado tecnológico.
A versão atual 3.0 é estável e segura.
RMI, no entanto, foi apresentada em 1998 e o mercado não apresenta aplicações de missões críticas que utilizem a arquitetura.
Conclui- se que CORBA é uma arquitetura mais madura que RMI;
Suporte a aplicações legadas:
Difícil em RMI pois não apresenta mapeamentos para outras linguagens de programação.
A arquitetura CORBA, por outro lado, suporta mapeamentos para diversas linguagens de programação.
Conclui- se que CORBA possui maior suporte a aplicações legadas em comparação a RMI;
Facilidade de desenvolvimento:
Por apresentar uma arquitetura mais completa CORBA exige maior dedicação do programador.
A adição de uma linguagem para definição de interfaces (IDL) e o mapeamento dos tipos de dados entre as linguagens de programação tornam o desenvolvimento de objetos CORBA mais complexo.
Em RMI, as interfaces e as aplicações são escritas em Java, logo não existem mapeamentos entre elas.
Conclui- se que o desenvolvimento na arquitetura RMI é mais simples que na arquitetura CORBA;
Desempenho e escalabilidade:
Foram realizados dois tipos de testes relacionados a desempenho e escalabilidade.
Em o primeiro de eles utilizou- se um cliente e no segundo, múltiplos clientes.
Foram testados todos os tipos de dados simples, inclusive o tipo string.
Segundo o artigo conclui- se que a arquitetura RMI teve desempenho superior à CORBA quando o número de clientes é inferior a quatro clientes.
A partir de quatro clientes simultâneos conectados ao objeto, a arquitetura CORBA teve um desempenho superior a RMI.
Segundo Hericko, o custo para o desenvolvimento de aplicações baseadas na arquitetura CORBA justifica- se para aplicações de larga escala onde o suporte a aplicações legadas é necessário e uma alta carga de clientes é esperada.
A arquitetura RMI, por outro lado, é indicada para aplicações de baixa escala onde o suporte a aplicações legadas podem ser gerenciadas por módulos individuais criados por o próprio programador e a facilidade de programação é mais crítica que o desempenho do sistema.
Segundo Orfali, a facilidade de codificação em RMI está ligada a dois pontos:
A utilização de apenas uma linguagem de programação e a conversão de tipos.
Enquanto em RMI utiliza- se somente a linguagem Java, na arquitetura CORBA o programador necessita utilizar duas linguagens de programação, uma para a codificação das interfaces (OMG IDL) e outra para a codificação dos objetos.
Como conseqüência disso, o programador CORBA lida com o problema da conversão de tipos na passagem de parâmetros entre interfaces e objetos.
Em RMI esta dificuldade não se verifica.
Inicialmente, durante o processo de escolha da arquitetura a ser utilizada na implementação do protótipo pensou- se na utilização da arquitetura CORBA.
O serviço de trader justificava esta escolha.
A possibilidade de pesquisar referências a objetos através das suas propriedades simplificaria muito o trabalho do programador.
Duas implementações da arquitetura CORBA foram testadas:
A implementação da OOC foi testada por oferecer um serviço de trader de domínio público.
Outros serviços de trader teriam de ser adquiridos, sendo esta opção descartada devido a o contexto do projeto;
A implementação Mico foi testada por suportar referências persistentes.
A utilização dessas referências evita que a cada recarga de objetos as referências desses objetos tenham de ser exportadas novamente para o serviço de trader.
No entanto, algumas dificuldades logo foram notadas:
A dificuldade de instalação:
Muito tempo foi utilizado para integrar a linguagem Java com a arquitetura CORBA escolhida;
A necessidade de domínio de mais de uma linguagem, no caso, OMG IDL e Java;
O serviço de trader permite que um cliente recupere referências de objetos através de suas propriedades.
Object Oriented Computing Inc.. Exportar a referência de um objeto significa adicionar- la ao conjunto mantido por o trader.
A distância entre a especificação da OMG e as implementações existentes no mercado:
Em a implementação testada algumas funcionalidades existentes nas especificações não estavam disponíveis.
Alguns serviços que projetavam- se ser aproveitados da arquitetura CORBA, não encontravam- se implementados. Como
exemplo pode- se citar que a implementação CORBA da OOC suportava o serviço de trader, no entanto não suportava referências persistentes.
Já a implementação Mico da arquitetura CORBA suportava referências persistentes, porém não suportava o serviço de trader;
A necessidade do serviço de trader e referências persistentes de objetos na mesma implementação:
Para a utilização do serviço de trader conforme desejado inicialmente, seria necessário que a implementação CORBA escolhida suportasse também referências persistentes.
Os módulos da arquitetura CORBA responsáveis por o suporte desta funcionalidade são o adaptador de objetos básico (Boa) e o repositório de implementações.
No entanto, conforme citado anteriormente, as implementações citadas (OOC e Mico) não suportavam referências persistentes e o serviço de trader simultaneamente.
Uma alternativa seria utilizar o serviço de trader de uma implementação e o suporte a referências persistentes de outra implementação.
Desta forma, seriam disponibilizados serviços com o Mico e as referências persistentes destes objetos exportados ao trader da OOC;
A possibilidade de utilização da solução encontrada:
Em diversas implementações de testes realizadas notou- se que as referências persistentes de objetos de outras implementações CORBA não eram suportados por o serviço de trader da OOC.
Frente a estas dificuldades encontradas, passou- se a investigar a possibilidade da utilização de RMI.
A arquitetura RMI apresentava diversas vantagens sobre a arquitetura CORBA, no âmbito do protótipo a ser desenvolvido:
O suporte à passagem de objetos por valor nos métodos das interfaces RMI;
A utilização da linguagem IDL na arquitetura CORBA exige que o programador preocupe- se com mapeamentos entre tipos de dados, no caso de utilização entre estruturas de dados complexas (structs).
No caso de RMI, por utilizar apenas uma linguagem de programação, esta heterogeneidade entre tipos não se verifica;
A possibilidade de conexão com algoritmos de otimização legados através do JNI ou da classe Runtime da linguagem Java.
Estes algoritmos possuem a vantagem de possuir uma interface simples, a qual recebe dados de entrada, processa e retorna dados de saída.
Os mecanismos disponibilizados por o JNI e por a classe Runtime possibilitam um bom gerenciamento destes processos;
A possibilidade de clonar objetos entre diferentes espaços de endereçamento.
A linguagem Java permite que seus objetos sejam clonados, a arquitetura RMI herda este comportamento;
Java Native Interface A simplicidade de instalação da arquitetura RMI, pois trata- se de um pacote integrado as JVM e de domínio público;
Alta portabilidade;
Suporte a programação concorrente através do mecanismo multithread da linguagem Java, possibilitando que os servidores desenvolvidos possam alocar uma thread para atender a cada requisição de cliente.
Porém, a arquitetura RMI impunha a restrição de suportar somente comunicação síncrona entre módulos.
Enquanto CORBA possuía suporte a comunicação síncrona e assíncrona entre os módulos.
O suporte à comunicação assíncrona em RMI foi um problema a ser resolvido.
Conhecidas as vantagens e desvantagens que cada arquitetura apresentava para a implementação do protótipo da arquitetura InterCOD, optou- se por a utilização da arquitetura de objetos distribuídos RMI.
Apesar de as implementações de domínio público de CORBA apresentarem muitas dificuldades, a utilização da arquitetura CORBA não é descartada.
A utilização de RMI somente se concretizou em função de a simplicidade das interfaces das implementações legadas dos algoritmos de otimização.
Isto levou a possibilidade de implementação, em Java, de módulos capazes de lançar processos de otimização que oferecem os dados de entrada necessários e aguardam por o retorno da resposta.
Caso a comunicação com as implementações de algoritmos legados venha a ser de maior complexidade, requerendo diversos métodos e passagem de diferentes tipos de parâmetros, por exemplo, a utilização de CORBA deve ser considerada.
CORBA apresenta toda uma especificação de mapeamento entre linguagens de programação.
O suporte desta arquitetura a aplicações legadas é muito mais abrangente em comparação a arquitetura RMI.
A Arquitetura Distribuída InterCOD O projeto PeCOD tem por objetivo desenvolver um ambiente integrado para resolução de problemas de otimização combinatorial, disponibilizando seus resultados para a comunidade científica através da Internet.
Baseado na cooperação entre as instituições envolvidas e numa reutilização de código eficiente, o projeto facilita o desenvolvimento de técnicas para solução de problemas combinatoriais, os quais geralmente apresentam estruturas semelhantes.
Para construção deste ambiente integrado são utilizados o paradigma de orientação a objetos e o conceito de distribuição.
O projeto propõe que o ambiente seja composto por centros de otimização, os quais agrupam os serviços a serem compartilhados entre as instituições envolvidas.
Cada instituição ficaria responsável por um ou mais centros de otimização.
Alguns requisitos são definidos por o projeto para a construção do ambiente suportado:
Respeitar a autonomia das organizações, pois diferentes instituições têm diferentes plataformas, políticas na utilização e segurança de seus recursos computacionais;
Permitir e suportar a cooperação entre instituições, permitindo que elas disponibilizem algoritmos de otimização, instância de dados e até recursos de processamento;
Respeitar a heterogeneidade de plataforma entre as instituições;
Promover a reutilização de código na federação;
Suportar a comunicação das entidades através da Internet, para promover a disseminação do uso desta arquitetura;
Baseado nos requisitos básicos citados acima, este trabalho modela uma arquitetura distribuída passível de implementação chamada InterCOD.
Ela define os módulos necessários para atingir os objetivos propostos por o Projeto PeCOD, respeitando a abordagem descentralizada e autônoma entre as instituições.
Dois projetos de pesquisa relacionados com a arquitetura distribuída InterCOD podem ser citados:
NetSolve e NEOS.
Outros trabalhos na área podem ser encontrados em Fourer e Goux.
Em essa pesquisa os autores consideram a utilização dos algoritmos de otimização como recursos disponíveis na Internet e relatam diversos trabalhos em andamento na área.
O ambiente NetSolve foi desenvolvido na Tennesse University em conjunto com Oak Ridge National Laboratory.
O NEOS (Network--Enabled Optimization System Server) e foi desenvolvido por Argonne National Laboratory.
Em estes trabalhos são apresentadas abordagens diferenciadas daquelas adotadas na arquitetura InterCOD.
Enquanto o NetSolve defende uma estrutura hierárquica, o projeto NEOS defende uma estrutura centralizada, onde todos os módulos devem ser cadastrados num servidor Conjunto de dados de entrada para os algoritmos de otimização centralizado.
No caso de a arquitetura InterCOD estas abordagens não se aplicam pois a autonomia entre as instituições deve ser preservada.
A seguir estes trabalhos relacionados são discutidos e, posteriormente, a arquitetura InterCOD é apresentada.
Trabalhos relacionados com a arquitetura InterCOD O ambiente NetSolve, apesar de não considerar especificamente os problemas de otimização combinatorial, suporta a resolução de problemas matemáticos através de uma rede de computadores.
O ambiente disponibilizado pode ser requisitado através de bibliotecas NetSolve (as quais estão disponíveis para C e Fortran), através do MATLAB, ou interativamente através da Internet, via Hyper Text Trasnport Protocol (Http).
A arquitetura proposta por Casanova para o ambiente NetSolve defende uma abordagem hierárquica entre os nodos.
Segundo Casanova, para se atingir uma gerência eficiente dos serviços disponibilizados, é necessária a adoção de uma estrutura que permita a limitação da ação dos usuários e a divida- os em grupos de interesse.
Uma estrutura em árvore (hierárquica) é apontada, onde cada nodo seria responsável por um grupo de interesse.
Porém, a implementação atual apresenta um sistema composto por máquinas conectadas sem qualquer relação hierárquica entre elas.
Esta implementação inicial foi adotada por simplicidade.
O objetivo inicial do projeto foi conceber um ambiente composto por diversos sistemas NetSolve independentes e fisicamente distantes.
Em a implementação atual qualquer usuário em potencial pode requisitar qualquer serviço disponível no ambiente.
A proposta de Casanova é que cada instituição participante do ambiente NetSolve seja um sistema NetSolve independente.
Cada sistema compartilha seus recursos e requisita serviços em outros sistemas distantes.
O conjunto de todos os sistemas independentes NetSolve formariam o ambiente NetSolve desejado.
A comunicação entre sistemas NetSolve é realizada por um módulo de comunicação chamado agente.
Os agentes são responsáveis por receber requisições dos clientes e submeter- las ao servidor apropriado.
Esse servidor é escolhido por o agente com base no tamanho e na natureza do problema a ser resolvido.
Os agentes podem ser replicados em diversos sistemas NetSolve independentes.
O ambiente suporta um mecanismo de balanceamento de carga entre os sistemas NetSolve.
Esse mecanismo considera aspectos de latência de rede entre os hosts envolvidos, complexidade do problema escolhido por o usuário, carga atual e a capacidade de processamento (aspectos de hardware) de cada servidor.
Cada grupo de interesse seria responsável por um problema de otimização, por exemplo.
Um mecanismo para tratamento de erros muito simples é suportado.
O processo em andamento, em caso de falha de comunicação ou falha no servidor, é simplesmente desconsiderado.
O agente é reportado sobre a falha.
Automaticamente ele identifica outro servidor disponível que possa atender o processo e realiza a requisição novamente.
Segundo Casanova, o tratamento de falhas é um tópico que será objeto de trabalhos no futuro.
O Network--Enable Optimization System (NEOS) é um ambiente de cooperação desenvolvido para possibitar a resolução de problemas de otimização através da Internet.
Esse ambiente é composto por dois componentes básicos:
O manual NEOS e o servidor NEOS.
O manual NEOS é um manual online que descreve a teoria sobre área de otimização.
O servidor NEOS é o componente que possibilita o acesso do usuário à biblioteca, a qual recebe o nome de biblioteca de software NEOS.
A estrutura do ambiente definida por o projeto NEOS é centralizada.
Todos os hosts que integram esse ambiente devem ser cadastrados no servidor NEOS.
As requisições de clientes são sempre direcionadas para esse servidor.
Segundo Czyzyk et_ Al, três tipos de requisições são aceitas.
Os usuários podem submeter problemas de otimização ao servidor via e-mail, via Http ou por a ferramenta de submissão disponibilizada.
A o receber essas requisições, o servidor as distribui aos resolvedores de otimização (optimization solvers), os quais são os hosts responsáveis por a execução do algoritmo.
O conjunto de algoritmos disponibilizados por os resolvedores de otimização formam a biblioteca de software NEOS.
Essa biblioteca possui a característica de ser distribuída, pois os resolvedores de otimização são hosts espalhados em diferentes espaços de endereçamento, conectados por a Internet.
A comunicação entre o servidor NEOS e esses resolvedores é baseada em sockets.
As estratégias de balanceamento de carga e tolerância a falhas utilizado por o NEOS está baseado no trabalho de Litzkow.
Esse trabalho define um sistema de alocação de recursos distribuídos que garante ao ambiente NEOS o balanceamento de carga e tolerância a falhas esperados.
Considerando- se os requisitos mencionados no início deste Capítulo descarta- se a possibilidade de uma abordagem hierárquica ou centralizada já que cada instituição deve ter autonomia, seja trabalhando isoladamente ou enquanto utilizando o suporte oferecido por a arquitetura distribuída.
Opta- se, desta forma, por uma abordagem cooperativa e descentralizada.
Cada instituição Entenda- se biblioteca como conjunto de implementações de algoritmos de otimização, disponibilizadas para invocação, rodando no servidor.
Desta forma, a arquitetura proposta deve suportar uma estrutura de centros autônomos que interligados podem cooperar formando uma federação para resolução de problemas de otimização combinatorial.
A decisão de participação ou não numa federação é de autonomia de cada centro.
Logo, um centro de otimização possui políticas de utilização e administrativas associadas.
Estas políticas são determinadas por um gerente humano responsável por o centro de otimização.
A federação se responsabilizaria por a comunicação do cliente com o sistema.
A federação ofereceria transparência de acesso aos processos, ou seja, a execução remota seria transparente para o cliente.
Em este nível de abstração, as entidades da arquitetura InterCOD podem ser definidas como:
Cliente, centro, adminstrador e federação.
A Figura 5 ilustra as entidades citadas, com uma federação composta por dois centros apenas.
O cliente é a entidade responsável por a requisição de serviços à federação.
Os centros são entidades que registram e disponibilizam os serviços.
Quando os centros cooperam (ou federam) dizse que formam uma federação.
Os clientes através do uso de um centro, tem acesso aos serviços da federação em a qual este centro se insere.
Os administradores são entidades humanas responsáveis por a participação dos centros na federação, controlam aspectos de configuração e de permissões nos centros, inclusões e exclusões de serviços.
Os centros de otimização devem ser autônomos, ou seja, podem trabalhar de maneira isolada ou federada.
Quando isolados, os centros só farão ofertas dos serviços locais, quando federados poderão ofertar todos os serviços disponíveis na federação.
A participação dos centros na federação é controlada por o seu respectivo administrador.
Os serviços disponibilizados por os centros de otimização podem ser divididos em algoritmos de otimização e instância de dados.
Cada centro possuirá um cadastro de algoritmos e um cadastro de instâncias de dados.
O cadastramento do conjunto de algoritmos e instâncias de dados de cada centro é responsabilidade do administrador.
Os algoritmos de otimização podem ser legados ou algoritmos que venham a ser desenvolvidos no campo de otimização.
Essa classe de algoritmos normalmente utiliza um conjunto de dados de entrada que é denominada instância de dados por a comunidade científica da área da otimização.
No decorrer de o trabalho, para evitar uma má interpretação do termo devido a proximidade da terminologia usado na área de orientação a objetos, as instâncias de dados serão referenciadas como conjunto de dados de entrada.
Os conjuntos de dados de entrada são arquivos que a comunidade científica disponibiliza para download na Internet.
Os conjuntos de dados usualmente atingem um número elevado de valores de entrada.
Estes valores normalmente são organizados em matrizes com ordens numericamente grandes.
A criação de novos conjuntos de dados é obtida através do processo repetitivo de comparação de resultados entre diversas execuções.
É importante que a arquitetura suporte o armazenamento temporário destes conjuntos de testes, de forma a disponibilizar- los a outros usuários e facilitar os testes de algoritmos.
Por motivos de levantamento de estatísticas os centros de otimização deverão gerenciar as seguintes informações sobre as requisições realizadas:·
controlar o número de requisições realizadas a cada algoritmo:
Este controle tem por finalidade gerar informações para facilitar o gerenciamento dos centros de otimização por os administradores.
Com estas informações o administrador pode avaliar a necessidade de replicar algoritmos de otimização em mais centros ou mesmo mudar algoritmos de centro, a partir de a identificação da sobrecarga em algum nodo de um centro da federação;·
controlar e armazenar o tempo de execução para cada requisição atendida:
Segundo Goldberg, a comparação de tempo entre diversos algoritmos de otimização é importante para destacar diferenças de qualidades entre eles.
Este log armazenará um identificador do algoritmo de otimização, um identificador do conjunto de dados escolhidos e o tempo de execução gasto para a resolução.
As informações armazenadas servirão para comparar o desempenho de cada algoritmo.
Em nível de distribuição a arquitetura InterCOD identificam- se os seguintes requisitos:
Balanceamento de carga nos centros de otimização:
Transparência de acesso aos serviços:
A arquitetura InterCOD suporta comunicação entre objetos escritos em diferentes linguagens de programação.
Como o PeCOD está baseado na reutilização do legado de algoritmos de otimização já existentes em centros de pesquisa e universidades, o protótipo da arquitetura InterCOD utiliza mecanismos de suporte que trate a comunicação entre diferentes linguagens de programação.
Como exemplo de linguagens de programação comumente utilizadas por a comunidade científica para o desenvolvimento de algoritmos de otimização pode- se citar:
C, C+, Fortran e Java;
Heterogeneidade de plataforma:
Os clientes, os centros e os diferentes nodos pertencentes ao um centro poderão trabalhar em diferentes sistemas operacionais e plataformas de hardware.
Apresentadas as entidades em alto nível de abstração e os requisitos necessários, descrevem- se os módulos da arquitetura nesta subseção.
Quatro tipos de módulos foram identificados para a arquitetura:
A Interface de Aplicação, o Gerenciador de Centros, o Gerenciador de Nodos e os Módulos Executores.
A Figura 6 apresenta os módulos de dois centros cooperantes da arquitetura distribuída InterCOD, cada centro atendendo requisições de vários usuários.
Um centro é composto por um Gerenciador de Centro e tantos Gerenciadores de Nodo quantos forem as máquinas executando algoritmos de otimização no centro.
Em cada nodo, um conjunto de diferentes algoritmos de otimização são oferecidos.
Submissão de heurísticas e metaheurísticas GCServiço Busca eescolha dos algoritmos GCGerência de otimização, Cooperação, Administrador Contabilidade Gerenciador deNodo, inclusão edeleção de algoritmos GCServiço Administrador GCCooperação GCGerência GNServiço GNGerência Módulos Executores Legenda:
A seguir são descritos os módulos da arquitetura.
A Interface de Aplicação (Ia) permite que o cliente do sistema realize submissão de Em este texto, os termos Ia e módulo cliente são utilizados como sinônimos.
A Ia apresenta todos os algoritmos e conjuntos de dados disponíveis na federação.
A o cliente cabe escolher o algoritmo e conjunto de dados desejados para a execução.
A execução do algoritmo escolhido acontece de maneira transparente ao usuário, do ponto de vista da localização na federação.
O cliente pode escolher entre o recebimento da solução de forma síncrona ou assíncrona.
Em o recebimento síncrono a Ia permanece conectada, para que o centro possa retornar a solução tão logo o algoritmo encerre a sua execução.
Em o recebimento assíncrono é permitido que o usuário receba a solução por correio eletrônico.
Assim, o usuário pode disparar a execução e desativar a Ia.
Esta opção justifica- se em função de os longos períodos de tempo que alguns algoritmos de otimização podem ocupar no seu processamento.
Escolhidos o algoritmo de otimização, o conjunto de dados e a forma de recebimento da solução, a requisição de execução é repassada ao módulo de Gerenciamento de Centro com a qual a Ia se comunica.
A Ia possui, ainda, uma opção de entrada de novos conjuntos de dados de teste e faz uso de um serviço capaz de armazenar- las no centro de otimização.
Conforme citado nos requisitos da arquitetura, a adição destes conjunto de dados no centro de otimização torna mais prático o trabalho de testes e disponibiliza os conjuntos de dados a outros usuários.
O Gerenciador de Centros (GC) possui funcionalidade para controlar um centro de otimização.
Os centros de otimização englobam um conjunto de nodos não-dedicados exclusivamente à resolução de algoritmos de otimização.
Os GC aceitam submissões de serviços dos seus clientes, bem como submissões de outros GC com os quais cooperam.
Toda a comunicação entre diferentes centros é controlada por o GC, exceto a comunicação entre os administradores de centros.
O GC mantém estruturas de dados para controlar as informações relevantes ao centro:
A tabela de nodos armazena as informações referentes aos nodos disponíveis no centro.
Informações como nome do nodo e endereço IP são suportados.
Sempre nas consultas e requisições aos nodos, o GC fará uso da tabela de nodos;
A tabela de centros mantém informações a respeito de os centros cooperantes.
Centros registrados nesta tabela passam a receber consultas de cargas e solicitações de requisições remotas, ou seja, os serviços locais passam a ser propagados por a federação.
Centros que possuírem a tabela de centros vazia realizarão consultas e requisições somente aos nodos registrados na tabela de nodos local.
Informações como nome do centro e endereço IP são suportados na tabela de centros;
A tabela de requisições armazena informações a respeito de cada processo criado no GC para atender as requisições do cliente.
Processos recebidos por cooperação (criados por centros remotos) não são registrados na tabela, pois os processos possuem um identificador único em toda a federação.
Esta tabela mantém o estado corrente do processo, os três estados possíveis são:
Consultando carga na federação, executando e pronto.
Informações como centro escolhido após a consulta de carga, nome do algoritmo de otimização, nome do conjunto de dados, solução do algoritmo e forma da entrega da solução (síncrona ou assíncrona) devem ser suportados.
A justificativa para o controle destas informações serão discutidas na seção de tratamento de falhas (seção 4.6).
A Figura 7 apresenta as estruturas de dados suportadas por o GC.
GCServiço GCGerência Gerenciador de Centros GCCooperação Banco de conj.
O GC permite que uma base de conjuntos de dados possa ser armazenada no centro de otimização.
Esta base de dados é formada por conjuntos de dados já validados e conjuntos de testes.
Os conjuntos de dados validados são adicionados por o administrador e ficam disponíveis no centro até que o administrador realize a sua exclusão.
Os conjuntos de dados de testes são adicionadas por os clientes e permanecem por um período de tempo determinado por o administrador do centro.
Após este período eles são excluídos da base de dados.
O módulo de gerenciamento de centros oferece a interface de serviço, a interface de cooperação e a interface de gerência.
A interface de serviço, chamada de GCServiço, permite que o módulo cliente requisite a Em este texto, centros cooperantes ou federados são utilizados como sinônimos.
A interface de cooperação, chamada de GCCooperação, possibilita que um centro de otimização requisite serviços em centros federados, registrados na tabela de centros.
Procurar por a menor carga na federação, disparar a execução de um algoritmo num centro selecionado, liberar um nodo bloqueado por o balanceamento de carga e retornar o resultado final são exemplos dos serviços da interface de cooperação do GC.
A interface de gerência, chamada GCGerência, permite que o administrador do centro de otimização modifique as propriedades do centro.
Nodos podem ser adicionados e retirados do centro, centros federados podem ser registrados ou excluídos.
Consultas ao nome do centro e à lista de nodos de um centro de otimização também são suportados.
Cada Gerenciador de Nodo (GN) controla um nodo físico que participa num centro de otimização.
Suporta um serviço de consulta de carga e a execução de um conjunto de Módulos Executores registrados no nodo.
A o receber uma requisição de execução para um algoritmo, procura por o Módulo Executor correspondente, dispara a execução e ao final retorna a solução ao GC.
O GN mantém uma estrutura de dados, a tabela de algoritmos.
Esta tabela associa o nome do algoritmo com as propriedades de cada Módulo Executor registrado.
Estas propriedades são informações necessárias para que a execução do Módulo Executor possa ser efetuada.
Informações como nome do algoritmo, caminho do mesmo no nodo físico (path) e parâmetros de entrada do Módulo Executor devem ser suportadas por a tabela de algoritmos.
O módulo de gerenciamento de nodo oferece duas interfaces:
A interface de serviço e a interface de gerência.
A interface de serviço, chamada GNServiço, permite que o GC faça consultas Em o processo de procura por o nodo com a menor carga acontece uma reserva nos nodos escolhidos de carga ou submeta requisições de execução ao nodo.
A interface de gerência, chamada GNGerência, possibilita que o administrador do centro possa consultar, inserir e deletar os Módulos Executores registrados.
Os Módulos Executores representam as implementações dos algoritmos de otimização, legados ou a serem desenvolvidos.
Estão escritos em diferentes linguagens de programação e são códigos dependentes de hardware e sistema operacional.
São selecionados, registrados e acionados por o administrador do centro, utilizando a interface de gerência do Gerenciador de Nodo em o qual se quer disponibilizar um algoritmo.
Para facilitar a discussão sobre a comunicação entre os módulos será descrito o funcionamento dos quatro serviços disponibilizados por a interface de serviço do módulo de gerenciamento de centros.
Esta interface foi escolhida porque agrupa os serviços com funcionalidades mais complexas da arquitetura distribuída InterCOD.
O usuário pode escolher entre requisições síncronas ou assíncronas.
Em a requisição síncrona o usuário espera por o final da operação, enquanto na requisição assíncrona o usuário recebe o resultado por e-mail.
A busca por a menor carga na federação é igual em ambos os métodos.
Em o processo de busca da menor carga, para cada centro de otimização registrado na tabela de centros, uma thread é iniciada (conforme Figura 6).
Esta thread é responsável por a comunicação com um centro remoto e requisita que o centro remoto consulte em seus nodos a existência do algoritmo de otimização requerido por o cliente.
Em caso afirmativo, o nodo retorna sua carga e registra- se como ocupado, impedindo que receba mais requisições.
A o receber mais requisições a consulta realizada pode- se tornar sem sentido, pois outro processo poderia alocar o nodo e invalidar o resultado da consulta.
No caso de não poder atender a requisição, o nodo retorna um valor inválido e permanece com a marca de desocupado.
O centro de origem, ao receber o resultado das requisições de consulta de carga, compara todas as cargas recebidas e seleciona o centro que apresentar a menor carga.
Os outros centros recebem uma mensagem informando que podem liberar os nodos reservados e não selecionados.
A Figura 9 apresenta o processo de consulta de cargas na federação.
Cliente GCServiço Ger.
Centro 1 thread Requisição GCCooperação Ger.
Centro 2 aos nodos Ger.
Centro 3 thread Ger.
A Figura 10 representa o processamento da requisição após a seleção do centro que apresentou a menor carga.
Se o usuário solicitou o recebimento do resultado síncrono, a thread 1 é bloqueada e aguarda por o término da execução.
A o término da execução ela é liberada e o resultado do algoritmo de otimização entregue ao cliente.
No caso de o recebimento assíncrono, a requisição é passada ao centro responsável por a execução e a thread 1 informa ao cliente que o resultado será enviado para o e-mail informado.
GCServiço GCCooperação Cliente Ger.
A adição de conjuntos de dados de testes é importante pois facilita o trabalho do cliente.
Evita que ele redigite todos os parâmetros de entrada no processo de criação de um novo conjunto de dados.
Através do serviço adicionaInstância o cliente informa o nome do conjunto de dados e os parâmetros de entrada da mesma.
O GC ao receber os parâmetros de entrada direciona- os para um módulo validador de conjunto de dados, desenvolvido por a comunidade científica da área de otimização.
No caso de o conjunto de dados de teste ser validado no referido módulo, o GC armazenão na base de conjuntos de dados do centro e retorna um identificador.
Em caso negativo, o GC informa ao cliente o resultado retornado por o módulo validador de conjunto de dados de teste.
De tempos em tempos verifica- se o período de tempo que estes dados permanecem armazenados na base de conjuntos de dados.
Aqueles que ultrapassam o limite indicado por o administrador do centro são retirados da base.
As requisições de pesquisa de algoritmos e conjuntos de dados aproximam- se muito da consulta de carga nos centros, pois a partir de uma requisição do cliente, todos os centros devem ser consultados a respeito de os serviços disponíveis, ou seja, algoritmos e conjuntos de dados.
Para cada um destes serviços são criadas threads que realizam a consulta nos centros.
Todos os centros registrados na tabela de centros são consultados.
As threads ficam bloqueadas aguardando o término da consulta.
O centro de origem ao receber a lista de serviços remotos agrupa- os num vetor e entrega- o ao cliente.
A Figura 9 pode ser utilizada para representar a consulta descrita.
Uma política para balanceamento de carga na arquitetura InterCOD é importante pois os algoritmos de otimização freqüentemente tomam muitos ciclos de tempo do processador (processos CPU-bound).
A decisão correta sobre em qual nodo disparar a execução de um algoritmo pode ser importante no tempo de resposta.
Logo, estes mecanismos de consulta e manutenção da carga justificam- se.
Os tempos gastos com tais mecanismos justificam- se na medida em que o melhor nodo na federação seja alocado para a execução de um algoritmo de otimização num determinado instante.
Como os algoritmos de otimização são CPU-bound, a política de balanceamento de carga adotada garante que a decisão de onde executar o algoritmo de otimização é feita com base nas informações mais recentes.
Desta forma, a cada requisição realizada as cargas da federação serão consultadas.
Um esquema de reservas é adotado por o centro consultado para garantir a alocação feita por outro centro.
Cada centro que recebe uma consulta de carga, ao identificar o nodo com a menor carga no seu escopo, reserva- o para o processo requerente.
Quando o centro escolhe o local de execução, ele libera os demais centros com nodos reservados.
Caso o centro de origem não responder (solicitando a execução ou liberando o nodo reservado), a reserva expira e o nodo é liberado.
Esta política é adotada para evitar reservas inválidas no caso de falhas no centro de origem ou na comunicação com ele.
Esta política é adotada também considerando- se que as federações terão um número baixo de centros participantes (poucas dezenas, numa estimativa não confirmada por testes).
Caso o número de centros cresça, esta política não oferece boa escalabilidade, e deverá ser revisada.
A política de balanceamento de carga adota que a cada requisição realizada as cargas da federação serão consultadas.
A política garante que a decisão é baseada nos valores correntes de cargas dos centros.
Cada centro que recebe uma consulta de carga, ao identificar o nodo com menor carga no seu escopo reserva- o para o processo requerente.
Se o centro de origem não responder (solicitando a execução ou liberando o nodo reservado), a reserva expira e os nodos são liberados.
Esta política é adotada para evitar reservas inválidas no caso de falhas no centro de origem ou na comunicação com ele.
Segundo Flaviu, para que a arquitetura de um sistema distribuído possa ser definida como tolerante a falhas, ela deve incorporar métodos capazes de assegurar a redundância nos módulos que disponibilizam serviços.
A identificação dos pontos de falhas e o tratamento das relações de dependência entre módulos garantem a correta implementação de cada serviço, suportando sempre um estado confiável para o sistema.
A arquitetura InterCOD, tal como aqui descrita, supõe um ambiente de processamento e comunicação livre de falhas, e concentra- se na definição dos módulos que suportam as funcionalidades necessárias, bem como os aspectos de comunicação e distribuição destes módulos.
No entanto, devido a necessidade de uso do protótipo por o projeto PeCOD para suportar a cooperação entre centros remotos e como na prática o ambiente operacional não é livre de falhas, algumas situações foram consideradas e possíveis formas de contornar- las foram apontadas.
Cabe, no entanto, destacar que as situações consideradas não são resultado de uma análise completa do problema.
No caso de a arquitetura InterCOD, 5 (cinco) situações de falhas são identificadas.
Segundo a classificação proposta por Flaviu estas cinco situações podem ser classificadas em dois tipos de falhas:
A falha por omissão e a falha por mudança de estado.
A falha por omissão caracteriza- se quando um servidor &quot;omite «a resposta para alguma requisição de serviço.
A falha por mudança de estado ocorre quando o servidor responde incorretamente a uma requisição devido a uma transição de estado ocorrida.
Em o estudo realizado verifica- se que estas falhas podem ocorrer nos chamados módulos servidores da arquitetura, ou seja, o gerenciador de centro e o gerenciador de nodo.
A seguir são citadas as cinco situações suscetíveis a falhas na arquitetura InterCOD:
Falha no centro de origem após a consulta carga;
Falha no centro de origem após o término da execução quando o centro remoto tentará enviar o resultado do algoritmo;
Falha no centro eleito com a menor carga, impossibilitando a submissão da execução;
Falha no gerenciador de nodo escolhido por a menor carga;
Falha no centro remoto após a submissão da execução ao gerenciador de nodo eleito com a menor carga;
Estas cinco situações serão descritas adiante na seção 4.6.2, porém, anteriormente, é necessário descrever em detalhes a tabela de requisições, pois ela possui papel importante no tratamento destas falhas.
Uma estrutura de dados muito importante para o controle de falhas na arquitetura é a tabela de requisições, citada no item 4.3.2.
Esta tabela tem a finalidade de armazenar as informações referentes as mudanças de estado de cada processo na federação.
Cada gerenciador de centro possui a sua tabela de requisições, a qual é atualizada a cada mudança de estado nos processos.
As informações suportadas por a tabela são:
Identificação do processo:
Identificador de processo, único no escopo da federação de centros de otimização;
Estado do processo:
Os estados dos processos podem ser:
Consultando carga, executando e pronto;
Centro escolhido após a consulta carga:
Identificador do centro escolhido por a consulta de cargas;
Nome do algoritmo:
Identificador do algoritmo na federação;
Nome do conjunto de dados de entrada:
Identificador dos conjuntos de dados de entrada na federação;
Solução: Resultado do algoritmo;
Opção de recebimento da solução:
Define o recebimento da solução como síncrono ou assíncrono;
Email do usuário:
E-mail do usuário para envio do resultado, no caso de escolha de comunicação assíncrona.
O estado &quot;Consultando «no período de tempo T1 representa um processo recém criado por o sistema.
Processos no estado &quot;Consultando «farão a pesquisa nos centros remotos em busca do nodo que apresentar a menor carga na federação.
Realizada a consulta de carga, o identificador do centro remoto escolhido é armazenado na tabela de requisições e o processo passa ao estado &quot;Executando «no tempo T2.
É iniciada a execução do algoritmo no centro escolhido.
Encerrada a execução, a solução do algoritmo é armazenada na tabela de requisições e o processo passa para o estado &quot;Pronto».
Enviada a solução por comunicação assíncrona ou síncrona ao cliente, o processo é apagado da tabela de requisições no tempo T4.
Com base no exposto acima, nota- se que as informações necessárias para a execução do processo na federação são armazenadas na tabela de requisições.
Por a sua importância o conteúdo da tabela de requisições deve ser sincronizado num meio de armazenamento permanente.
Pois, no caso de falha, seguida do restabelecimento dos gerenciadores de centros, o conteúdo da tabela poderá ser recarregado do meio de armazenamento e os processos pendentes submetidos novamente a federação.
A seguir são descritas as cinco situações suscetíveis a falhas, tratadas na arquitetura InterCOD:·
Falha no centro de origem após a consulta de cargas esta falha ocorre no centro de origem, após o retorno das menores cargas de cada centro remoto.
Realizada a consulta de cargas nos centros da federação, aqueles que possuem o algoritmo pesquisado, realizam uma reserva no nodo.
Com a falha no centro de origem, estes nodos podem permanecer reservados indefinidamente.
Porém, para evitar este erro, os gerenciadores de centro consultam os seus nodos em períodos de tempos determinados pesquisando por reservas com tempo maior que o tempo máximo de reserva configurado por o administrador.
As reservas que apresentarem um tempo maior que o tempo máximo configurado serão canceladas;·
Falha no centro de origem durante a execução no centro remoto:
A o término da execução o centro remoto tenta entregar o resultado ao centro de origem.
Este em razão de a falha ocorrida encontra- se indisponível.
Em a tabela de requisições o processo encontra- se como &quot;Executando».
Duas soluções podem ser usadas para contornar o conseqüente erro: (
a) o centro remoto perderia o resultado obtido e o centro de origem repetiria a execução para os dados existentes na tabela de requisições e (b) onde o centro remoto armazenaria o resultado obtido.
Em este último caso, o centro de origem, já recuperado da falha, identifica na tabela de requisições os processos que se encontravam no estado &quot;Executando».
Seria pesquisado o estado atual destes processos nos centros remotos.
Para aqueles cujo processamento estivesse encerrado, o resultado seria obtido e a tabela de requisições atualizada.
Para aqueles cujo processamento ainda estivesse em andamento, o centro de origem simplesmente aguardaria por o término da execução;·
Falha no centro remoto responsável por a comunicação com o nodo eleito com a menor carga com a indisponibilidade do centro remoto escolhido por a consulta de cargas, torna- se impossível submeter a execução.
Uma possível solução é fazer com que caso o centro escolhido esteja indisponível, o processo de consulta de cargas é repetido em toda federação.
Após a segunda consulta de cargas, o centro de origem identificará se algoritmo escolhido por o usuário pertencia somente ao centro indisponível.
Em caso positivo, o centro de origem deverá enviar uma mensagem ao usuário informando que não poderá executar o algoritmo escolhido.
Caso contrário, o processo é submetido ao novo centro remoto eleito.
Esta solução foi escolhida porque a consulta de cargas é uma operação de curta duração.
Além disso, a realização de uma segunda consulta na federação garante cargas mais atualizadas;·
Falha no gerenciador de nodo durante a execução do processo:
Esta falha implica na perda da execução em andamento.
Por o fato da comunicação entre o centro remoto e o gerenciador de nodo ser síncrona, o centro remoto identifica a falha tão logo esta ocorra no gerenciador de nodo.
Para evitar a ocorrência do erro, o centro remoto envia uma mensagem ao centro de origem informando da impossibilidade de concluir a execução do processo em andamento.
Para tanto é necessária a adição de um novo serviço à Interface de Cooperação.
Este serviço tem a finalidade de informar a falha ao centro de origem e solicitar que o processo seja submetido novamente a federação a partir de a consulta de cargas.
O estado do processo na tabela de requisições teria de ser alterado.
O processo passaria do estado &quot;Executando «para o estado &quot;Consultando «na tabela de requisições do centro de origem;·
Falha no centro remoto após a submissão da execução ao gerenciador de nodo eleito com a menor carga:
Como a comunicação entre os gerenciadores de centro e nodo é síncrona, esta falha implica na perda da execução em andamento.
A solução proposta para evitar a ocorrência do erro nesta situação é a monitoração entre os centros.
A cada período de tempo todos os gerenciadores de centros testariam a disponibilidade com os centros com os quais federam.
A o retorno de Q tentativas inválidas (caso de falha) de um centro remoto, o centro de origem percorreria a tabela de requisições verificando por a pendência de processos no estado &quot;Executando».
Os processos que estivessem em execução no centro remoto onde ocorrera a falha deveriam ter o seu estado modificado para &quot;Consultando «e seriam novamente submetidos a consulta de carga na federação.
Em a implementação realizada, a identificação desta situação é suportada por o mecanismo de comunicação da plataforma de distribuição utilizada Em este capítulo serão descritas as escolhas tecnológicas usadas para o desenvolvimento do protótipo da arquitetura InterCOD.
Pode- se destacar:
Em a implementação do protótipo foi utilizada a linguagem Java, com o objetivo de atender ao requisito de heterogeneidade da arquitetura InterCOD.
Além disso, a linguagem Java apresentou as seguintes facilidades:
A arquitetura de objetos distribuídos escolhida para a implementação foi RMI por razões já destacadas no 3 desta dissertação.
Conforme visto, RMI possui as vantagens de facilidade de aprendizagem e implementação em relação a outra arquitetura abordada.
RMI simplifica o trabalho dos administradores de centros porque elimina a tarefa de instalação de outras ferramentas em separado para suportar a distribuição entre os centros de otimização.
Ao contrário de as outras arquiteturas de objetos distribuídos abordadas, RMI faz parte do Java Development Kit (JDK) a partir de a versão 1.1.4.
O JDK implementa a especificação da Máquina Virtual Java (JVM).
A seguir define- se o diagrama de classes da arquitetura InterCOD.
O diagrama de classes do protótipo baseia- se no estudo descrito na Seção 4.
A partir de os módulos da arquitetura descritos definem- se as classes do protótipo.
A analogia entre os módulos e as classes é direta.
O módulo Interface de Aplicação é modelado por a classe Janela;
O módulo Gerenciador de Centro, por a classe GerCentro;
O módulo Gerenciador de Nodo, por a classe GerNodo;
O módulo Módulos Executores, por a classe Algoritmo.
A classe GerCentro oferece três interfaces RMI:
As interfaces ifcGCUsuário, ifcGCCooperação e ifcGCGerência.
A interface ifcGCUsuário oferece os serviços da classe GerCentro aos clientes do centro.
A interface ifcGCooperação oferece serviços da classe GerCentro aos outros centros de otimização existentes na federação e a interface ifcGCGerência permite que o administrador do centro realize modificações nas propriedades da classe GerCentro.
A classe GerNodo oferece duas interfaces RMI:
As interfaces ifcGNServiço e ifcGNGerência.
A interface ifcGNServiço permite que a classe GerCentro requisite serviços aos objetos da classe GerNodo, enquanto a interface ifcGNGerência possibilita que o administrador altere a tabela de algoritmos dos objetos GerNodo.
As demais classes são:
Centro, nodo, ConjDados.
A Figura 11 apresenta o diagrama de classes para o protótipo InterCOD.
Os objetos da classe Janela disponibilizam uma interface gráfica para os clientes da federação.
Esta interface gráfica que é acessada através de navegadores (browsers) permite que o cliente escolha o algoritmo a ser executado, o conjunto de dados de entrada e visualize a solução retornada por o protótipo.
A integração da interface gráfica do protótipo com os navegadores foi realizada através da herança com a interface Applet da linguagem Java.
A o herdar o comportamento de Applet, é adicionada à classe Janela a funcionalidade de publicar suas propriedades em navegadores.
As propriedades constantes na classe são atributos de tela que permitem o cliente realizar as suas escolhas, realizar a entrada dos parâmetros necessários para executar um algoritmo e receber o resultado.
Os métodos realizam chamadas a interface RMI ifcGCUsuário, com exceção executa todos os comandos pertencentes neste método, é o primeiro da classe a ser executado.
Maiores detalhes sobre a classe Janela e sua integração com a interface Applet serão abordados adiante.
A classe GerCentro modela o Gerenciador de Centros definido na arquitetura distribuída.
Esta classe herda de dizer que esta classe herda o comportamento de um objeto remoto RMI e que seus métodos passam a ser oferecidos como serviços através de interfaces RMI.
Seguindo Figura 7 nota- se que a interface GCServiço publica serviços para os clientes, a interface ifcGCCooperação publica serviços aos gerenciadores de centros remotos e a interface ifcGCGerência disponibiliza serviços para os administradores dos centros.
Ao mesmo tempo nota- se que todos os serviços publicados por estas interfaces são implementados na classe GerCentro.
A tabela de requisições armazena as requisições (processos) em execução no centro.
A tabela de centrosCooperantes guarda o nome e o endereço IP dos centros remotos que aceitam cooperações de requisições.
A tabela de nodos armazena as mesmas informações da tabela de centros para o nodos conhecidos, além de os atributos bloqueio e número do processo que indicam a reserva do nodo.
Estes atributos estão ligados ao balanceamento de carga.
Em o balanceamento de carga estes atributos são usados para reservar o nodo.
Um processo, ao reservar o nodo, indica o seu identificador e bloqueia- o através do atributo bloqueio.
Se bloqueio estiver setado como verdadeiro nenhum outro processo poderá reservar este nodo.
Caso contrário, o nodo estará livre para ser reservado.
Os métodos serão mais discutidos mais adiante nos diagramas de seqüência.
A classe GerNodo modela o Gerenciador de Nodos definido na arquitetura distribuída.
Esta classe também estende objetos RMI remotos, ou seja, ela também herda de java_ Rmi_ Server_ UnicastRemoteObject os seus serviços são publicados por duas interfaces:
A Figura 15 apresenta a interface de gerência e a Figura 16 apresenta a interface de serviço.
NomeAlgoritmo, PathAlgoritmo, ParametrosAlgoritmo);
A tabela de algoritmos registra os módulos executores disponíveis em cada nodo.
As propriedades mantidas para cada algoritmo são:
Nome do algoritmo, caminho para a execução e parâmetros adicionais.
O nome do algoritmo é definido por o administrador e deve ser único no nodo.
O caminho para a execução indica o local de armazenagem do algoritmo dentro de o sistema de arquivos.
Os parâmetros adicionais são utilizados por alguns algoritmos de otimização que necessitam de parâmetros para iniciar a sua execução.
Os métodos das classes GerNodo e Algoritmo serão abordados no diagrama de seqüência.
A linguagem Java, conforme comentado no princípio do capítulo, ofereceu vantagens ao desenvolvimento do protótipo.
Os SDFNDJHV, ou pacotes servem para agrupar classes relacionadas facilitando a reutilização de código por o programador Java, simplificando o trabalho de codificação.
A UML oferece uma abstração que modela em diagramas as relações de dependências entre pacotes.
Em a implementação do protótipo InterCOD, os pacotes da linguagem Java utilizados na implementação do protótipo foram:
GerCentro para criar linhas de execução em paralelo nas consultas remotas.
Este pacote inclui ainda a classe java_ Runtime, a qual foi utilizada nas chamadas aos algoritmos legados;
Os diagramas de seqüência apresentam as interações de objetos em relação a o tempo.
Segundo a UML, estes diagramas detalham a seqüência da troca de mensagens entre objetos.
Os diagramas de seqüência apresentados para o protótipo modelam as requisições de serviços apresentadas no item 4.4 desta dissertação.
Foram escolhidas as requisições aos serviços da interface de usuário (ifcGCUsuário):
Elas foram selecionadas porque são as que exigem o maior número de interações entre os objetos remotos do protótipo.
Como a descrição das interações visa facilitar o entendimento do funcionamento interno do protótipo InterCOD, os serviços mais simples (por exemplo, cadastro de algoritmos) foram desconsiderados.
Em o diagrama de seqüência para a execução de algoritmo serão utilizados dois objetos:
Pucrs e ufsm.
Estes objetos, instâncias da classe GerCentro, representarão os gerenciadores de centros distribuídos na federação.
Os diagramas limitaram- se a dois gerenciadores de centros porque a adição de mais objetos GerCentro não representaria maior semântica ao modelo.
Em o serviço de execução de algoritmo o cliente através da classe Janela seleciona o algoritmo a ser executado, o conjunto de dados de entrada, a forma de recebimento da solução e o seu e-mail.
A comunicação entre Janela e a interface ifcGCUsuário é síncrona.
O método tabela de requisições juntamente com os parâmetros fornecidos.
O estado do processo é &quot;Consultando».
É consultada a tabela de centros cooperantes com o objetivo de distribuir as consultas de cargas aos centros cadastrados.
Um vetor de threads é criado, sendo que para cada centro cadastrado na tabela de centros uma thread é criada para conduzir a consulta de carga.
As threads utilizam a interface ifcGCCooperação para consultar as cargas nos centros remotos.
A comunicação entre a thread e o gerenciador de centro remoto é síncrona.
Em o protótipo, a carga de cada nodo representa o número de processos InterCOD pendentes (em execução) no momento da consulta.
O nodo com menor carga será aquele que apresentar o menor número de processos InterCOD pendentes.
Conhecidas as cargas de vários nodos aptos a executar o pedido, o objeto pucrsGerCentro compara todas as cargas recebidas e escolhe o centro que possuir o nodo com a menor de elas.
Um novo vetor de threads é criado com o objetivo de liberar os nodos reservados, exceto aquele escolhido para a execução.
É criada uma thread para desbloquear cada nodo não selecionado.
As threads informam aos gerenciadores de centros que o nodo reservado para o processo S pode ser liberado.
O gerenciador de centros ao receber a mensagem pesquisa na tabela de nodos por o processo S e libera o nodo reservado.
Este serviço é disponibilizado por a interface Escolhida a menor carga e liberados os nodos reservados segue- se para a execução.
O processo tem o seu estado modificado para &quot;Executando «na tabela de requisições do objeto realiza a execução do algoritmo.
Embora o cliente possa escolher entre a execução do algoritmo de forma síncrona ou gerenciadores de centros envolvidos.
A diferença entre estas formas de comunicação verifica- se somente na entrega da solução ao cliente.
Como RMI não suporta chamadas assíncronas (one-way) entre seus objetos, esta forma de comunicação pode ser alcançada por a utilização de threads.
Em o protótipo, justifica- se a utilização de comunicação assíncrona devido a o alto tempo de processamento que os algoritmos de otimização normalmente ocupam.
Uma falha intermitente de comunicação entre objetos GerCentro síncronos implicaria na perda da execução.
São necessárias duas threads para implementar a comunicação assíncrona entre os objetos GerCentro.
A primeira de elas criada por o construtor da classe GerCentro.
Esta thread acorda- a e informa os dados da requisição (processo, ver classe requisição) e a referência ao centro que aguarda o resultado.
A partir de então não existe mais comunicação aberta entre os objetos pucrsGerCentro e ufsmGerCentro.
A thread ao ser acordada, cria a segunda thread que conduzirá a segunda thread (os dados da requisição e a referência ao objeto pucrsGerCentro).
A primeira thread retorna ao loop e a segunda thread assume a execução.
Com a identificação do processo, recebida da primeira thread, a segunda thread consulta a tabela de nodos com o objetivo de encontrar a referência ao nodo que indicara a menor carga durante a consulta de cargas.
Identificado o nodo é realizada a execução do algoritmo no nodo A integração com os algoritmos de otimização legados foi realizada através da classe processo em separado e controle as suas entradas e saídas através de streams de bytes.
Para iniciar a execução do algoritmo realiza- se download do conjunto de dados escolhido.
Ele é escrito no stream de entrada do processo e aguarda- se por o término da execução do algoritmo.
A o final da execução lê- se o stream de saída do processo, que corresponde a solução do problema.
Finalmente a solução é retornada à segunda thread.
A segunda thread estabelece comunicação com o objeto pucrsGerCentro e retorna a solução ao centro de origem.
O processo tem o seu estado modificado para &quot;Pronto «na tabela de requisições.
O objeto pucrsGerCentro verifica se a entrega da solução deve ser assíncrona (entregue por e-mail) ou síncrona (através da interface gráfica).
Em ambos os casos a execução no objeto pucrsGerCentro permanece em wait aguardando por o notify da segunda thread.
Após o notify o objeto pucrsGerCentro verifica a escolha do cliente e realiza a entrega da solução.
A Figura 18 apresenta o diagrama de seqüência para o serviço de execução de algoritmo.
Centro: Ifc GCCooperacão ufsm:
Ger. O serviço de adição de dados de teste permite que o cliente, através da classe Janela adicione um conjunto de teste temporário no centro de otimização.
A interface RMI ifGCUsuário oferece um serviço de adição de dados de teste, implementado por os objetos da classe GerCentro.
Os objetos GerCentro ao receberem um conjunto de dados de teste sempre realizam a validação dos mesmos.
Os objetos Conversor são responsáveis por a validação.
Se aprovado na validação o conjunto de dados é adicionado ao centro, senão uma mensagem de erro é enviada ao cliente.
A comunicação entre cliente e o gerenciador do centro é síncrona.
A Figura 19 apresenta o diagrama de seqüência para o serviço de adição de conjunto de dados de teste.
Os serviços de pesquisa de algoritmos e conjunto de dados são utilizados na inicialização dos objetos da classe Janela.
Estes serviços pesquisam todos os algoritmos de otimização e conjuntos de dados de entrada disponíveis na federação de centros.
Esta consulta tem por objetivo informar ao cliente a disponibilidade de algoritmos e conjunto de dados no momento da requisição.
A o inicializar a applet, o cliente, transparentemente, realiza a requisição aos serviços de requisição criam um vetor de threads.
Cada thread realiza a consulta de algoritmos aos gerenciadores de centros remotos, listados na tabela de centros.
Cada gerenciador de centro remoto ao receber a requisição cria um vetor de threads que realizam a consulta de algoritmos nos nodos.
Em o gerenciador eliminados (aqueles que possuem mais de uma ocorrência no centro em nodos diferentes) e são threads que consultaram os gerenciadores de centros remotos, elimina os algoritmos duplicados e retorna a lista de algoritmos da federação para o cliente.
GerCentro, igualmente criam um vetor de threads que consultam os centros remotos.
Os centros remotos consultam seus conjuntos de dados de entrada disponíveis e retornam- os.
O objeto GerCentro de origem elimina os nomes duplicados e retorna a lista de conjunto de dados de entrada ao cliente.
O armazenamento dos conjuntos de dados nos centros de otimização será tratado adiante, em item separado, mais detalhadamente.
Em ambos os serviços a comunicação entre os objetos é síncrona.
A Figura 20 apresenta o diagrama de seqüência para os serviços de pesquisa a todos algoritmos e conjunto de dados da federação.
Apesar de tentar- se desenvolver um protótipo facilmente instalável para o administrador de cada centro, duas necessidades de software devem ser destacadas para o funcionamento do protótipo InterCOD:
Text Tranfer Protocol (Http).
Entre as várias restrições impostas às appletV por as especificações da Máquina Virtual Java, uma diz respeito a comunicação remota da applet com outros módulos.
Esta restrição exige que a applet só realize trocas de mensagens com o seu servidor de origem.
No caso de o protótipo InterCOD, como a applet realiza requisições RMI aos serviços do gerenciador de centro através da interface ifcGCUsuário, o processador alocado para ser o gerenciador de centros obrigatoriamente será um servidor Http.
A Figura 21 apresenta um centro de otimização composto por dois gerenciadores de nodos.
Em este caso, foram alocados três processadores.
Um de eles atuando como centro de otimização e servidor Http e outros dois atuando como gerenciadores de nodos.
Não existe restrição no protótipo quanto a alocação de um mesmo processador para o gerenciador de centro e gerenciador de nodo simultaneamente.
Só foram utilizados três processadores na Figura 21 com objetivo de facilitar a visualização dos módulos.
O armazenamento dos arquivos executáveis dos algoritmos legados nos nodos, bem como dos arquivos texto dos conjuntos de dados de entrada nos centros de otimização foi outro problema tratado na implementação do protótipo.
O armazenamento desordenado destes arquivos implicaria em problemas para as consultas das listas de algoritmos e conjunto de dados e para a execução de algoritmos.
A solução encontrada foi criar um diretório raiz para a aplicação InterCOD, onde todos os arquivos pertencentes ao protótipo estão armazenados.
Os subdiretórios seriam:
Classes: Em este diretório seriam armazenados todos os byte codes(.
CLASS) da linguagem Java que implementam os módulos da arquitetura distribuída;
Algoritmo: Os executáveis dos algoritmos legados seriam armazenados neste diretório;
Conjunto de dados:
Em este diretório seriam armazenados os arquivos texto que servem como entrada de dados para os algoritmos legados.
Seria composto por dois subdiretórios:
Um de eles destinado aos conjunto de dados padrões e outro, aos conjunto de dados do usuário.
Os conjuntos de dados padrões são aqueles adicionados por o administrador do centro, enquanto os conjuntos de dados do usuário são temporários, utilizados para teste e adicionados por os próprios usuários.
Em os centros de otimização a estrutura é composta por um diretório para aplicação chamado InterCOD e por dois subdiretórios contendo os conjuntos de dados e as classes.
Este diretório devem ser disposto na raiz do servidor Http para que o seu conteúdo possa ser disponibilizado e publicado.
Em os nodos a estrutura é igualmente composta por um diretório para aplicação InterCOD, porém os dois subdiretórios contém os algoritmos legados e as classes.
Esta padronização facilita a execução dos algoritmos legados, uma vez que todos ficam agrupados no mesmo local dentro de o nodo.
A Figura 22 apresenta as estruturas de diretórios nos centros de otimização (a) e nos nodos (b).
Entre os cinco requisitos básicos propostos na Seção 4, um destaca a necessidade de suportar a comunicação entre os módulos através da Internet.
Para a Interface de Aplicação este requisito representa que qualquer usuário em potencial na Internet possa realizar requisições de serviços aos centros de otimização.
Desta forma, o protótipo deve suportar um elo de ligação entre estas requisições e os seus módulos.
Uma das justificativas para a escolha da linguagem Java no desenvolvimento do protótipo foi a sua facilidade de integração com os navegadores (browsers) através da interface Applet.
Esta interface permite que módulos Java publiquem suas propriedades em navegadores através da herança de seu comportamento.
Assim, o elo de ligação entre os módulos do protótipo e as requisições resolve- se.
Os objetos da classe Janela, por herdar de Applet, podem publicar suas propriedades no navegador e ao mesmo tempo estabelecer comunicação RMI com o gerenciador de centro.
Através das requisições RMI os objetos Janela pesquisam, consultam e inserem informações nos centros de otimização e, em função de a herança, publicam o resultado destas consultas em navegadores.
A seguir serão discutidos os componentes da interface gráfica.
O componente Construção lista os algoritmos de construção disponíveis obter a lista dos algoritmos.
O componente Melhoramento não foi utilizado no protótipo.
O componente Instâncias lista os conjunto de dados de entrada disponíveis nos centros de otimização.
Conforme citado no Capítulo 3 este termo (instância) é utilizado por os pesquisadores da área de otimização para identificar os dados de entrada.
Em esta dissertação o termo instância não foi utilizado para evitar a confusão com Orientação a Objetos.
No entanto, como a interface gráfica tem por objetivo atender aos pesquisadores da área de otimização, o termo instância foi mantido.
O serviço de adição de dados de teste é requisitado através do botão inserir instância no servidor.
Para que dados de teste possam ser adicionados a base de dados dos centros é necessário que um identificador seja informado no campo instância.
O identificador informado é a Uniform Resource Location (URL) que indica a localização do conjunto de dados a ser transferido para a base de conjunto de dados do centro de otimização e retorna a nova URL para a interface gráfica.
A interface gráfica apresenta a URL do arquivo transferido no campo status do Framework.
Encerrada a adição dos dados de teste, o novo arquivo de dados de teste passa a compor a lista de todos os conjuntos de dados da federação.
Assim, para que o cliente possa utilizálo em alguma execução, o conteúdo do componente Instâncias deverá ser atualizado.
A o clicar no botão Executar o cliente inicia a execução do algoritmo escolhido no componente Construção com a entrada de dados escolhida no componente Instâncias.
Porém, anteriormente é necessário indicar a forma de entrega da solução:
Síncrona ou assíncrona.
A o optar por a entrega do solução assíncrona, o cliente informa o seu e-mail no componente
Email e seleciona a opção Receber Resposta por
Email. Em este caso, ao clicar no botão Executar, a interface gráfica apresenta uma mensagem no componente Solução Encontrada confirmando a execução e informando que a solução será enviada por e-mail.
A o optar por a entrega da solução síncrona, o cliente seleciona a opção Esperar Resposta.
Destaca- se que mesmo nesse caso é exigido que o cliente informe o seu e-mail.
Pois no caso de ocorrer qualquer problema de comunicação entre a applet e o centro de otimização a execução iniciada não será perdida e a solução enviada por e-mail.
A o clicar no botão Executar, a interface gráfica aguarda por o término da execução e apresenta o resultado no componente Solução Encontrada.
O serviço da interface de usuário ifGCUsuário utilizado na execução do algoritmo é o Este trabalho apresentou a arquitetura distribuída InterCOD e o protótipo desenvolvido para a mesma.
O ambiente criado promove a cooperação entre pesquisadores da área de Otimização Combinatorial e seus resultados já tem sido apresentados à comunidade científica.
A construção de ambientes de suporte a cooperação é de grande valia, pois facilita a troca de experiências entre grupos de pesquisa.
Em a área de otimização esta afirmação se acentua ainda mais, em função de o método de trabalho normalmente adotado por a comunidade científica da área.
Geralmente, os avanços na área de otimização são atingidos através de freqüentes comparações entre soluções geradas por os algoritmos disponibilizados por diferentes grupos de pesquisa.
Logo, facilitar o acesso a estes legados através da Internet promove o intercâmbio de resultados na área, acelerando o processo de pesquisa.
A descentralização e autonomia dos centros de otimização é outro fato a ser destacado na arquitetura InterCOD.
Os trabalhos relacionados NetSolve e NEOS propunham uma estrutura hierárquica e centralizada para os seus módulos, respectivamente, na definição do seu ambiente de cooperação.
A arquitetura InterCOD propôs uma estrutura descentralizada e autônoma.
A escolha dessa estrutura justifica- se por o fato de respeitar a individualidade de cada instituição envolvida no processo de cooperação.
O protótipo da arquitetura InterCOD demonstrou que é viável agrupar implementações de algoritmos de otimização combinatorial em centros de otimização e disponibilizar- los na Internet, respeitando a autonomia entre as instituições envolvidas.
Apesar de o protótipo suportar apenas os algoritmos para o PCVS, acredita- se que os algoritmos para os demais problemas também possam ser adicionados aos centros de otimização e disponibilizados como serviços através da Internet.
A proposta da dissertação indicava que parte do protótipo seria implementada em CORBA.
Fora escolhida a arquitetura CORBA por a transparência de acesso e por o serviço de trader oferecidos.
No entanto, a utilização de CORBA ofereceu muitas dificuldades para a implementação do protótipo, em especial, com relação a o serviço de trader e referências persistentes de objetos, conforme o item 3.4.
Para o protótipo desenvolvido utilizou- se RMI, porém não descarta- se a utilização de CORBA em trabalhos futuros.
RMI adaptou- se ao projeto porque os algoritmos usados para o PCVS apresentaram uma interface simples de ser gerenciada através da classe java_ Runtime e seus mecanismos.
Porém para outros tipos de algoritmos não testados, disponíveis para outros problemas de otimização, a classe java_ Runtime pode não ser suficiente para efetivar a comunicação com os módulos legados.
Em estes casos, a arquitetura CORBA pode ser considerada.
A utilização da linguagem Java com a arquitetura RMI foi satisfatória, porém com problemas a serem destacados.
A curva de aprendizado e a facilidade de programação são aceitáveis.
Entretanto, a ausência de uma definição formal da linguagem, principalmente nas bibliotecas de suporte a threads, deixa o programador sem o suporte bibliográfico necessário.
Em este aspecto, foi necessário o desenvolvimento de testes que certificassem o funcionamento integrado de RMI com as threads em Java.
Com esses testes pode- se verificar o comportamento do objeto RMI no caso de invocação concorrente de seus métodos.
Nenhuma bibliografia ou especificação definia tal comportamento.
Por os testes realizados com o protótipo concluiu- se que os objetos RMI preservam o mesmo comportamento que objetos não remotos, com relação a a invocação concorrente de métodos e sincronização.
Os trabalhos futuros identificados neste momento, a serem desenvolvidos a partir de a arquitetura InterCOD são:
Automatização das tarefas do administrador do centro de otimização.
Dividindo os usuários em grupos de usuários.
Com isso alguns grupos de usuários poderiam, por exemplo, adicionar algoritmos de otimização nos centros.
Um novo trabalho poderia identificar regras administrativas que pudessem ser adicionadas a arquitetura, facilitando o trabalho do administrador e flexibilizando as tarefas dos usuários, tornando- os mais ativos na estrutura;
Investigação de um serviço de balanceamento de carga para a arquitetura InterCOD, que considere aspectos de hardware e a carga adicionada por outras fontes de carga.
Por exemplo, que considere a capacidade de processamento do processador dos nodos e a carga adicionada por outros processos;
Estudo e adição de tolerância a falhas na arquitetura;
Adição de algoritmos legados para outros problemas de otimização.
Adaptar a arquitetura para que suporte centros de otimização capazes de solucionar diversos tipos de problemas, além de o PCVS;
Identificação da possibilidade de usar os paradigmas de código móvel na arquitetura InterCOD.
O paradigma de código móvel poderia ser adotado nas operações de consulta melhor carga, execução no centro escolhido e retorno da solução ao centro de origem.
A utilização de código móvel na definição destes serviços aparenta ser mais intuitiva que a abordagem atual.
O tratamento de falhas, provavelmente, seria mais simples de implementar com a utilização da ferramenta de persistência para componentes de código móvel;
Adição de funcionalidades à interface gráfica, permitindo o acompanhamento da execução por parte de o usuário e a possibilidade de retirar (abortar) um processo em execução.
