O aumento da complexidade dos sistemas conduz a novos problemas no projeto de MPSoCs, principalmente no que se refere à implementação de RTOS.
Em geral, as implementações convencionais de RTOSs para um MPSoC são baseadas apenas em software.
Para sistemas de tempo real, com tarefas que tenham requisitos de tempo real, onde os deadlines têm ordem de grandeza comparável ao tempo de troca de contexto, as implementações em software não são eficientes.
Com o intuito de melhorar o desempenho e a previsibilidade dos sistemas de tempo real, particionar o sistema operacional torna- se uma abordagem interessante, principalmente tratando- se do projeto de um RTOS capaz de suportar aplicações com deadlines críticos (sistemas hard real-time).
Em este trabalho são avaliados resultados obtidos através da comparação entre três RTOSs distintos: (
i) um implementado totalmente em software, executando sobre um único processador, (ii) um implementado totalmente em software, mas particionado, com o gerenciamento das listas de tarefas e o escalonador executando sobre um processador, e as tarefas sendo executadas sobre outro, e (iii) um particionado em software/ hardware onde parte das funcionalidades (escalonador e gerenciamento das listas de tarefas) foi migrada para o hardware.
Palavras-chave: SoC, FPGA, sistemas operacionais, sistemas embarcados, co-projeto hardware/ software, escalonador Atualmente vem tornando- se cada vez mais comum a presença de sistemas embarcados em muitas atividades cotidianas, e os baixos custos tecnológicos tendem a aumentar essa presença.
Exemplos de tais sistemas são os telefones celulares com agendas e câmeras de vídeo integradas, sistemas autônomos de controle de vôos, computadores portáteis, entre outros.
A utilização de arquiteturas MPSoC (do inglês Multiprocessor Systems-on-Chip) no projeto desses sistemas vem aumentando devido a o fato de oferecerem características desejáveis ao projeto de sistemas embarcados, entre elas desempenho, custo, confiabilidade, consumo de energia e área do sistema.
No entanto, para alcançar todos os benefícios oferecidos por MPSoCs, os projetistas devem possibilitar a adaptabilidade dessas arquiteturas, para que seja possível atender às necessidades de cada uma das aplicações.
Um MPSoC é composto por diversos processadores, módulos de memória e outros núcleos de propriedade intelectual (IP -- do inglês Intellectual Property), onde cada processador executa um conjunto de tarefas, e a comunicação entre os diversos módulos constituintes é realizada através de barramentos ou redes de comunicação intrachip.
Para gerenciar a execução das aplicações e da comunicação, faz- se necessário a utilização de um sistema operacional, que deve ser de tempo real a fim de suportar tarefas com requisitos de tempo real, ou seja, tarefas cuja execução deve respeitar intervalos de tempo pré-definidos.
Segundo Andrews, os sistemas operacionais são responsáveis por fornecer mecanismos de controle e sincronização para modelos de programação de alto nível, bem como um conjunto genérico de interfaces, também conhecidas como Apis (do inglês Application Programming Interfaces), através de as quais os aplicativos podem utilizar as funções do sistema operacional, como por exemplo o gerenciamento de memória, o escalonamento de tarefas, etc..
As Apis facilitam a programação das aplicações, visto que os programadores não necessitam conhecer os protocolos de baixo nível e os requisitos específicos de cada dispositivo.
Entretanto, desenvolver sistemas operacionais de tempo real não é uma tarefa trivial.
A principal preocupação dos projetistas de um RTOS (do inglês Real-Time Operating System) é possibilitar o atendimento dos requisitos de tempo dos sistemas, a fim de garantir o funcionamento correto dos mesmos.
Existem casos onde RTOSs implementados puramente em software não são capazes de atender os deadlines das tarefas, que são os instantes de tempo máximos antes de os quais tarefas de tempo real devem completar sua execução.
Quando uma tarefa não tem sua execução finalizada até seu deadline, caracteriza- se uma perda de deadline, o que não é aceitável em sistemas hard real-time, ou seja, sistemas em os quais a perda de deadlines causa uma catástrofe no ambiente em o qual este está inserido.
O aumento nas perdas de de-adlines pode ser acentuado com a existência de um tempo não desprezível de processamento inerente à execução de funções críticas do sistema operacional, como por exemplo as trocas de contexto e o escalonamento de uma nova tarefa.
Uma proposta para melhorar a precisão dos RTOSs consiste em particionar o sistema operacional, migrando algumas funcionalidades do sistema operacional para um processador dedicado ou, ainda, para o módulo de hardware, a fim de possibilitar a execução das funcionalidades críticas paralelamente às demais.
Segundo Kohout, uma função implementada em hardware possui, em geral, melhor desempenho em relação a sua implementação correspondente em software.
Em hardware é possível explorar o paralelismo entre funções através da utilização de FSMs (do inglês Finite State Machines) e, além disso, implementações em hardware possibilitam a melhoria no desempenho e previsibilidade do sistema, desejáveis para sistemas de tempo real.
No entanto, a complexidade do hardware é bem mais alta que a do software, restringindo seu uso.
Para realizar um particionamento eficaz do sistema operacional e garantir que o mesmo atenda precisamente os requisitos da aplicação, neste trabalho propõe- se a utilização do coprojeto hardware/ software de sistemas.
O co-projeto auxilia na especificação e no projeto de sistemas que contêm componentes de hardware e software e, atualmente, é amplamente utilizado tanto na academia quanto na indústria para o projeto de aplicações/ sistemas embarcados.
A seguir, na Seção 1.1, é apresentado um fluxo de projeto de sistemas embarcados, adotado por o grupo de pesquisa (GAPH -- Grupo de Apoio ao Projeto de Hardware) em o qual o presente trabalho está inserido.
A Figura 1 ilustra o fluxo de projeto de sistemas embarcados, o qual é uma versão reduzida do fluxo proposto por Hessel, que por sua vez foi adaptado do fluxo proposto por a ITRS (do inglês International Technology Roadmap for Semiconductors).
Para este fluxo foram adotados os seguintes níveis de abstração:
Nível funcional, nível Tl (do inglês Transaction Level) e nível RTL (do inglês Register Transfer Level).
O fluxo de projeto inicia no nível de abstração funcional, que corresponde ao nível nãotemporizado proposto por Arnout.
Em este nível, tem- se uma especificação funcional do sistema (modelagem), sem precisão temporal e sem detalhes de implementação, obtida a partir de a análise e especificação dos requisitos do sistema.
De posse do modelo funcional do sistema, é realizada a verificação do mesmo através de técnicas formais, por exemplo.
Após a validação do modelo funcional, segue- se uma etapa de tomada de decisões, onde é atribuído ao sistema um conjunto de restrições de implementação (por exemplo, plataforma alvo), transformando a especificação funcional numa especificação arquitetural, refinando o fluxo para o nível de abstração Tl, que é o nível de transação proposto por Arnout.
Em este nível de abstração, o processo de particionamento do sistema pode ser efetuado mapeando as diferentes partes do sistema (aplicações) em especificações separadas de hardware e software.
Em este ponto do fluxo, a funcionalidade de cada módulo é descrita de forma abstrata, e a comunicação entre os módulos é realizada através de canais de comunicação abstratos.
Aqui, a concepção do sistema subdivide- se nos fluxos de síntese de software e síntese de hardware, sendo que o fluxo de síntese da comunicação também deve ser considerado por o projetista.
Em as diferentes etapas de refinamento do sistema (síntese do hardware, do software e da comunicação) é possível realizar a validação do mesmo através de técnicas de co-simulação.
Os processos de síntese de hardware e da comunicação são iniciados com maior independência do processo de síntese de software, e vice-versa.
Em este trabalho, será dada maior ênfase ao projeto dos módulos de software, os quais, no nível Tl, são compostos por especificações algorítmicas das funcionalidades desempenhadas por o sistema, as quais descrevem, de forma abstrata, as aplicações que constituem o sistema.
A partir de estas especificações, o fluxo de concepção do sistema operacional embarcado pode ser iniciado, assim como o processo de síntese das aplicações, subdividindo o processo de desenvolvimento novamente.
A partir de as especificações algorítmicas, é sintetizado um modelo abstrato de um sistema operacional, composto somente por os serviços necessários às aplicações.
Este modelo é construído a partir de uma biblioteca que possui a implementação Tl de diversos serviços (escalonamento, tratamento de interrupção, comunicação, etc), que mais tarde serão utilizados para a síntese do sistema operacional no nível RTL.
Em este ponto, o sistema operacional é responsável por o gerenciamento da execução das aplicações, possibilitando a elaboração de uma simulação, ainda no nível Tl, para validar o sistema como um todo (sistema operacional em conjunto com as aplicações).
Com base nos resultados obtidos através desta simulação, refinase o fluxo de concepção para o nível RTL, caso os requisitos do sistema sejam atendidos, ou refaz- se o particionamento e a síntese do sistema operacional.
A última etapa do fluxo concentra- se no nível de abstração RTL, o qual apresenta um detalhamento maior da computação e da comunicação dos componentes do sistema.
Além disso, neste nível consideram- se questões de temporização, ou seja, sincronização através de ciclos de clock.
A adaptação de cada serviço do sistema operacional, conforme a arquitetura de hardware alvo, pode ser vista como um exemplo prático do detalhamento do aspecto computacional, enquanto que o detalhamento dos protocolos de comunicação entre os componentes do sistema operacional representa um exemplo do detalhamento no aspecto da comunicação.
O refinamento do sistema do nível Tl para o nível RTL é feito através do emprego de um formato intermediário.
O fluxo ilustrado na Figura 1 não apresenta detalhes referentes a etapa de síntese do RTOS, onde realiza- se o particionamento do sistema operacional.
Portanto, para essa etapa propõe- se a utilização de um outro fluxo, o qual serve para auxiliar na escolha de quais funcionalidades do sistema operacional serão implementadas em hardware ou software, cujo detalhamento é apresentado a seguir.
A Figura 2 apresenta uma proposta de fluxo de co-projeto para a síntese de um RTOS.
Através deste fluxo, é possível validar o particionamento do sistema operacional à medida que o mesmo vai sendo refinado, levando em consideração as necessidades da aplicação.
De essa forma, evita- se que sejam descobertos problemas apenas nas últimas fases do projeto, o que ocasiona uma perda no tempo de projeto, visto que se deve retornar ao ponto inicial do fluxo a fim de realizar um novo particionamento.
À medida que problemas vão sendo detectados, novos particionamentos podem ser realizados, até que o sistema operacional atenda exatamente os requisitos da aplicação.
O ponto de partida do fluxo de projeto consiste numa especificação contendo um conjunto de módulos descritos numa linguagem de programação de alto nível.
Cada um desses módulos contém um conjunto de tarefas, além de a especificação de um RTOS.
Essa especificação é resultado da etapa de síntese de software, ilustrada no fluxo da Figura 1.
A seguir as tarefas e o RTOS são mapeados para processadores-alvos, escolhidos a partir de uma biblioteca de processadores.
Sendo assim, cada processador contém apenas as funcionalidades mínimas necessárias ao RTOS e o conjunto de tarefas a serem executadas.
Em o passo seguinte, baseado em sua própria experiência, o projetista escolhe quais funcionalidades do RTOS serão implementadas em software ou hardware, respeitando os requisitos e as restrições do sistema, além de considerar as características da arquitetura do processador-alvo.
O resultado desse passo consiste num RTOS particionado, onde algumas funcionalidades implementadas em software executam num processador, enquanto que as demais executam sobre outro (co-processador).
Em o fluxo da Figura 2, as tarefas T1 a Tn são executadas num processador-alvo, enquanto as funcionalidades críticas do RTOS são executadas em outro.
Em este ponto do fluxo, o sistema é validado para garantir que o mesmo atende às necessidades da aplicação.
Em caso afirmativo, refina- se o fluxo para a próxima etapa.
Caso contrário, retorna- se à etapa anterior, realizando um novo particionamento.
Após a validação do sistema, as funcionalidades do RTOS que executavam no processador dedicado são implementadas em hardware, excluindo o processador em questão.
Em este ponto realiza- se uma simulação do sistema completo, a fim de garantir que o mesmo atende às necessidades da aplicação.
Se o resultado da simulação for satisfatório, refina- se o fluxo.
Caso contrário, retorna- se à etapa de particionamento, retirando/ adicionando funcionalidades de ambos os lados do fluxo.
O refinamento desta etapa consiste na síntese física do sistema.
Aqui, define- se a plataforma de prototipação e adiciona- se um conjunto de restrições ao sistema, além de mapear os pinos de entrada/ saída, de acordo com a plataforma escolhida.
Esta etapa é responsável por o mapeamento, roteamento e posicionamento da lógica implementada em hardware nos blocos disponíveis na plataforma de prototipação.
De posse do resultado da síntese, parte- se para a última etapa do fluxo, que consiste na prototipação do sistema total (processador+ meio de interconexão+ funcionalidades implementadas em hardware) num FPGA (do inglês Field Programmable Gate Array), o qual consiste num circuito programável composto por um conjunto de células lógicas ou blocos lógicos alocados em forma de uma matriz.
É importante salientar que estas duas últimas etapas do fluxo podem ser alcançadas a partir de o final de qualquer outra etapa.
Devido a o aumento da complexidade e do tamanho dos sistemas, o gerenciamento das tarefas e da comunicação por o sistema operacional naturalmente torna- se mais complicado, e seu impacto no desempenho do sistema torna- se mais significativo.
Segundo Andrews, o hardware pode executar algumas funcionalidades críticas dos RTOSs de forma mais eficiente do que o software.
Portanto, migrar algumas dessas funcionalidades para o hardware apresenta- se como uma abordagem interessante para atender os requisitos das tarefas de tempo real.
Como exemplos de funcionalidades críticas pode- se citar:
Escalonamento de tarefas, gerenciamento de tempo do sistema, tratamento de interrupções e gerenciamento das filas de tarefas.
Essas funções são vitais para o funcionamento correto do sistema operacional e são executadas constantemente e, portanto, sua implementação em software pode ser considerada ineficiente para algumas classes de aplicações.
No caso de arquiteturas com apenas um processador, implementações em software não são capazes de permitir o paralelismo do RTOS, ou seja, cada vez que uma determinada função do sistema operacional tem que executar, as demais não podem executar em paralelo a esta, bem como deve ser interrompida a execução da tarefa que esteja com o controle do processador, o que compromete o desempenho geral do sistema.
A Figura 3 apresenta, a título de ilustração, uma comparação hipotética entre a execução de uma função crítica num sistema operacional particionado (hardware/ software ou software/ software) e num SO (Sistema Operacional) não particionado (software).
Em este exemplo, ilustra- se o comportamento da execução de escalonamento de tarefas em ambos sistemas.
Em a Figura 3 (a), onde o sistema operacional é implementado totalmente em software, sem nenhum tipo de particionamento, a cada intervalo de tempo determinado, o processador é in-t6 t7 t8 t5 t4 t3 t2 t1 uP t9 Ti $= tarefa ti $= tempo Tc $= troca de contexto SO $= sistema operacional uP (a) Sistema operacional implementado totalmente em software sobre um único processador.
Em a Figura 3 (b), o escalonador executa em paralelo com o processador, o que permite que o processador interrompa a execução de uma tarefa apenas quando uma tarefa diferente da atual é escalonada.
Em este caso, o sistema operacional pode ser particionado em software/ hardware ou software/ software.
Para o primeiro tipo de particionamento, pressupõe- se a utilização de um módulo de hardware dedicado, enquanto que no segundo o escalonador será executado sobre um processador dedicado (co-processador).
Particionando o SO, é possível garantir que o processador não gaste tempo com trocas de contexto desnecessárias e, conseqüentemente, atenda um número maior de deadlines.
O objetivo e a principal contribuição do presente trabalho consiste na comparação entre três implementações de modelos de RTOS, compostos por o escalonador, por o gerenciamento das listas de tarefas, por o gerenciamento de tempo do sistema e por o controle das interrupções, a fim de identificar diferentes classes de aplicações onde uma implementação apresenta vantagem sobre a outra.
Para realizar essa comparação foram desenvolvidos três protótipos.
O primeiro protótipo, denominado SoRTS (do inglês Software Real Time Scheduler), implementa um kernel simplificado de um RTOS, totalmente em software, que executa sobre um único processador.
O kernel de um sistema operacional corresponde ao núcleo do mesmo e representa a camada mais baixa de interface com o hardware, sendo responsável por gerenciar os recursos do sistema computacional como um todo.
Além disso, o kernel é responsável por gerenciar a execução das tarefas que compõem a aplicação, o escalonador do sistema, o gerenciamento das listas de tarefas e as trocas de contexto.
Em o segundo protótipo, denominado Co-SoRTS (do inglês Coprocessor Software Real Time Scheduler), o kernel foi particionado em dois módulos de software executando sobre dois processadores.
Um de eles é responsável por a execução do escalonador e gerenciamento das listas de tarefas, e o outro processador é responsável por a execução das tarefas e trocas de contexto.
O último protótipo, denominado HaRTS (do inglês Hardware Real Time Scheduler), também implementa um kernel particionado.
No entanto, o escalonador e o gerenciamento das listas de tarefas foram implementados num módulo de hardware, enquanto que a execução das tarefas e as trocas de contexto foram mantidas em software, sendo executadas por o processador.
O gerenciamento de tempo do sistema foi implementado em hardware nas três abordagens.
Tanto para o HaRTS, como para os demais protótipos, foi utilizado um processador comercial (MicroBlaze) sobre uma placa de prototipação -- VirtexII-ProTM FF896.
Esta abordagem permitiu extrair resultados comparativos de qualidade entre os protótipos, o que consiste numa última contribuição do trabalho.
Este documento está organizado da seguinte forma:
Em o Capítulo 2 é apresentado um referencial teórico, composto por conceitos básicos necessários para a contextualização do trabalho.
Em o Capítulo 3 apresenta- se uma revisão do estado da arte, relacionada ao particionamento em hardware e software de sistemas operacionais.
Em o Capítulo 4 é apresentada a descrição da implementação dos protótipos desenvolvidos para a prova de conceito.
O Capítulo 5 apresenta os experimentos realizados para a validação do trabalho, bem como os resultados obtidos e, finalmente, o Capítulo 6 apresenta as conclusões do trabalho e os trabalhos futuros.
Este capítulo tem por objetivo definir conceitos diretamente relacionados com este trabalho, a fim de contextualizar- lo.
Em a Seção 2.1 são apresentados conceitos relevantes à área de sistemas operacionais, e na Seção 2.2 são apresentados conceitos relacionados a sistemas de tempo real.
Sistemas operacionais são programas intermediários responsáveis por controlar os recursos existentes num computador (processadores, memórias, dispositivos de entrada/ saída, etc), além de fornecerem a base para o desenvolvimento de programas de aplicação.
Além disso, os sistemas operacionais podem ser vistos como uma camada de software que provê um ambiente com uma interface mais simples e conveniente para o usuário.
Os sistemas operacionais dispõem de diversos tipos de serviços, e não há uma convenção universalmente aceita sobre quais são estes serviços.
No entanto, levando em consideração a maioria das implementações de sistemas operacionais existentes, pode-ser dizer que os principais serviços implementados no kernel do sistema operacional são o escalonamento de tarefas, a troca de contexto, a comunicação intertarefas, o tratamento de interrupções e o gerenciamento de memória.
Escalonamento de tarefas:
Este serviço é fundamental em qualquer sistema operacional, pois é necessário para gerenciar a utilização de recursos, bem como a ordem de execução das tarefas constituintes do sistema, o que é realizado de acordo com a política de escalonamento adotada.
Trocas de contexto:
Sempre que uma nova tarefa é escalonada, é necessário realizar uma troca de contexto no sistema, ou seja, o sistema operacional deve salvar as informações da tarefa que está executando e carregar as informações necessárias para a execução da nova tarefa.
As trocas de contexto ocorrem em intervalos de tempo determinados, chamados de time slice.
Comunicação intertarefas:
Este serviço é responsável por o gerenciamento da troca de informações entre tarefas cooperantes, ou seja, tarefas que necessitam dos resultados de outra (s) tarefa (s) durante sua execução.
Essa troca pode ser realizada através de memória compartilhada ou troca de mensagens.
Tratamento de interrupções:
Interrupções são mecanismos através de os quais outros módulos (entrada/ saída, memória) podem interromper o processamento normal do processador, e sempre que isso acontece, o processador deve interromper sua execução e iniciar a execução de uma rotina específica a fim de tratar esta interrupção.
Gerenciamento de memória:
Este serviço consiste na tarefa de conhecer as partes da memória que estão ou não em uso, alocar memória para as tarefas quando necessário e liberar memória quando as mesmas estiverem com sua execução finalizada.
Como um subgrupo dos sistemas operacionais, encontram- se os sistemas operacionais embarcados.
Estes vêm tornando- se bastante populares ultimamente, visto que eles implementam apenas as funcionalidades necessárias à aplicação que será executada.
O tamanho de um sistema operacional embarcado (espaço de memória ocupado) tende a ser menor que o de um sistema operacional convencional.
Isto se dá devido a o fato dos sistemas operacionais embarcados implementarem apenas as funcionalidades necessárias às aplicações gerenciadas por os mesmos.
Assim como os sistemas operacionais convencionais, os sistemas operacionais embarcados oferecem mecanismos de escalonamento, tratamento de interrupções, gerenciamento de memória, entre outros.
Sistemas de tempo real são sistemas computacionais que devem reagir a eventos respeitando restrições de tempo.
Conseqüentemente, o comportamento correto dos mesmos não depende apenas dos resultados da computação, mas também do tempo em que os estes são produzidos.
Como exemplos de sistemas de tempo real pode- se citar:
Sistemas de controle de vôos, sistemas de telecomunicações, sistemas de controle de lançamento de mísseis, entre outros.
Tarefas de tempo real que compõem sistemas de tempo real são caracterizadas por deadlines, que consistem no tempo máximo em o qual as tarefas devem completar sua execução.
Por exemplo, uma tarefa T possui um deadline d..
Isto significa que T tem, no máximo, d unidades de tempo para terminar sua execução.
O fato de existir esse tempo implica que resultados produzidos após o mesmo não só estão atrasados, como podem estar errados, e este cenário caracteriza a perda de um deadline.
Dependendo das conseqüências causadas por a perda de um deadline, os sistemas de tempo real são subdivididos nas duas classes descritas a seguir:
Sistemas soft real-time:
Em este tipo de sistema o alcance de seus deadlines é desejável por questões de desempenho, mas uma perda de um deadline não causa sérias conseqüências ao ambiente, mas prejudica o comportamento do sistema.
Exemplos de sistemas dessa classe são:
Aplicações de áudio e vídeo, sistemas de telecomunicações, entre outros.
Sistemas hard real-time:
Estes sistemas devem atender seus deadlines num grau de flexibilidade próximo a o zero.
A perda de um deadline causa conseqüências catastróficas ao ambiente, podendo envolver vidas humanas.
Exemplos de sistemas dessa classe são:
Controle de lançamento de mísseis, controle de vôo, entre outros.
Para o gerenciamento de tarefas de tempo real, é necessária a utilização de um sistema operacional de tempo real.
Normalmente, as aplicações contêm tanto tarefas com requisitos de tempo real, quanto tarefas sem esses requisitos.
Portanto, os RTOSs devem suportar todos os tipos de tarefas, aplicando estratégias diferentes para o gerenciamento das mesmas.
Tanto os sistemas operacionais convencionais quanto os RTOSs implementam serviços semelhantes para gerenciamento das tarefas.
No entanto, os últimos têm alguns de seus serviços implementados levando em consideração as questões de tempo.
Em muitas aplicações de tempo real, a maioria das tarefas do sistema são periódicas, ou seja, são executadas ciclicamente em taxas de tempo específicas, respeitando o intervalo de tempo (período) pré-definido para sua execução.
O sistema operacional deve garantir que cada tarefa seja ativada regularmente no período apropriado e seja finalizada dentro de seu deadline.
Para melhor ilustrar o funcionamento dos algoritmos de escalonamento, é necessário inserir o conceito de estados da tarefa.
Em qualquer sistema concorrente, ou seja, sistemas onde é possível compartilhar o uso dos recursos de processamento de um computador para suportar o fluxo de execução de dois ou mais programas, existem pelo menos três estados que as tarefas podem assumir:
Executando, pronto e esperando.
Em sistemas de tempo real que suportam a execução de tarefas periódicas, além destes existe o estado parado, possibilitando que uma tarefa que teve sua execução finalizada possa voltar a ser executada quando o tempo do sistema atingir seu novo período, o qual é ajustado sempre que uma tarefa tem sua execução finalizada.
A Figura 4 ilustra o diagrama de transição de estados relativo aos quatro estados citados.
De acordo com o diagrama da Figura 4, os estados das tarefas podem ser atualizados conforme descrito a eguir:
Pronto para Executando:
O estado Pronto é o estado em o qual se encontram as tarefas que estão prontas, mas não podem executar, pois outra tarefa tem o controle do processador.
As tarefas que estão neste estado são mantidas numa fila de tarefas prontas.
Quando o processador está livre, uma tarefa é extraída da fila de tarefas prontas, e seu estado é modificado para Executando;
Executando para Esperando:
Sempre que a tarefa que está com o controle do processador executar uma primitiva de sincronização, esta tem seu estado atualizado de Executando para Esperando, sendo mantida num fila de tarefas esperando até que uma outra tarefa execute um sinal que desbloqueie a tarefa que está na fila;
Esperando para Pronto:
Esta transição ocorre no momento em que uma tarefa da fila de tarefas esperando é desbloqueada;
Executando para Parado:
Esta transição ocorre quando a tarefa tem sua execução finalizada, sendo mantida numa lista de tarefas paradas até que o tempo do sistema atinja o valor de seu novo período, que representa o instante de tempo em que a tarefa pode voltar a ser executada;
Parado para Pronto:
Esta transição ocorre sempre que uma rotina ativada por um Timer verifica que o tempo do sistema atingiu o valor do novo período da tarefa, significando que esta pode voltar a ser executada.
Existem diversas políticas de escalonamento empregadas em sistemas de tempo real.
No entanto, os dois algoritmos mais empregados são o RM (do inglês Rate Monotonic) e o EDF (do inglês Earliest Deadline First), os quais são amplamente conhecidos e exaustivamente analisados e comparados na literatura.
Estas duas políticas de escalonamento são descritas a seguir, nas Seções 2.2.2 e 2.2.3 respectivamente.
O algoritmo RM é uma política de escalonamento que prioriza as tarefas de acordo com seus períodos, ou seja, quanto menor for o período de uma tarefa, mais alta será sua prioridade de execução.
Como os períodos são constantes, este algoritmo é dito de prioridades fixas, ou seja, uma vez assinaladas, as prioridades não mudam com o passar do tempo de execução do sistema.
Além disso, em sistemas que empregam o algoritmo RM, não existe dependência de dados entre as tarefas, o tempo de execução das mesmas é constante e os deadlines são situados no final do período das tarefas.
Este algoritmo apresenta como desvantagem o fato de ser baseado em prioridades estáticas, visto que com isto o sistema fica impossibilitado de utilizar 100% dos ciclos de CPU disponíveis.
A Figura 5 apresenta um exemplo de execução do algoritmo RM.
Em este exemplo considerou- se o período das tarefas igual ao seu deadline.
Em esse exemplo, o sistema operacional gerência a execução de duas tarefas cujos períodos são 5 ms e 10 ms, respectivamente.
Isso significa que T 1 deve terminar sua execução em, no máximo, 5 ms e T2 deve terminar sua execução em, no máximo, 10 ms..
Cada tarefa possui um tempo de duração/ execução associado, que neste caso é de 2 ms para a tarefa T 1 e 3, 5 ms para a tarefa T2.
Portanto, os 2 ms de T1 devem ser distribuídos dentro de o período de 5 ms, bem como os 3, 5 ms de T2 devem ser distribuídos dentro de o período de 10 ms, a fim de garantir o funcionamento correto do sistema.
Em este caso, como a tarefa T1 possui o menor período, esta é a tarefa de maior prioridade no sistema.
Portanto, sempre que esta estiver pronta para executar, esta será escalonada por o algoritmo.
Em intervalos de tempo, arbitrados em 1 ms, um escalonamento é realizado a fim de verificar se uma nova tarefa deve ser executada.
Então, em 1 ms a execução da tarefa T 1 é interrompida, e o algoritmo verifica que esta ainda não terminou sua execução e a escalona novamente.
Em 2 ms o algoritmo verifica que esta terminou sua execução e a coloca na fila de tarefas paradas, para que esta espere o próximo período de execução para poder voltar a executar.
Após, o algoritmo escalona a tarefa T2, que será re-escalonada nos tempos 3 e 4 ms..
Quando o tempo do sistema chega em 5 ms, a tarefa T1 retorna para a fila de prontas para executar, e é escalonada por o algoritmo, já que seu período é menor em relação a o período da tarefa T 2.
Em 7 ms T1 acaba sua execução e, portanto, a tarefa T2 pode voltar a executar.
Sua execução termina no tempo 7, 5 ms, e então esta tarefa é inserida na fila de tarefas paradas até que seu novo período seja alcançado, e esta possa voltar a executar.
O cenário de execução das tarefas se repete como descrito anteriormente a cada novo período das tarefas.
Em esse exemplo, o sistema operacional gerência duas tarefas cujos deadlines são 5 ms e 8 ms, respectivamente.
Cada tarefa possui um tempo de execução associado, que neste exemplo é de 2, 5 ms para T1 e 3, 5 ms para T2.
Portanto, os 2, 5 ms de T1 devem ser distribuídos dentro de o deadline de 5 ms, bem como os 3, 5 ms de T2 devem ser distribuídos dentro de o deadline de 8 ms, a fim de garantir o funcionamento correto do sistema.
Inicialmente a tarefa T1 possui o menor deadline, portanto, esta é a tarefa de maior prioridade no sistema.
No entanto, a prioridade entre as tarefas oscila dinamicamente, de acordo com o menor deadline no intervalo de tempo em que os escalonamentos são realizados.
Para este exemplo, os escalonamentos são realizados a cada 1 ms..
Como pode ser visto na Figura 6, em 1 ms e 2 ms a execução da tarefa T 1 é interrompida, e o algoritmo verifica que esta ainda não terminou sua execução e a escalona novamente.
Em 2, 5 ms esta termina sua execução, sendo inserida na fila de tarefas paradas, esperando o próximo período para poder voltar a executar.
Após, o algoritmo escalona a tarefa T 2, que será re-escalonada nos tempos 3, 4 e 5 ms..
Quando o tempo do sistema chega em 5 ms, a tarefa T1 retorna para a fila de prontas para executar, mas não é escalonada pois seu deadline foi ajustado para 10 ms, sendo maior que o deadline da tarefa T 2.
Portanto, T2 continua sua execução até terminar.
Logo, em 6 ms, T1 volta a executar.
Em o tempo 8 ms, T2 volta para a fila de prontas para executar, mas só será escalonada após o fim da execução da tarefa T1, pois seu deadline foi ajustado para 16 ms, sendo maior que o deadline de T1.
O cenário de execução das tarefas vai sendo alterado de acordo com a evolução do tempo do sistema.
A maioria das implementações de RTOSs existentes para MPSoCs consiste, geralmente, em implementações de sistemas operacionais totalmente em software ou totalmente em hardware.
No entanto, para sistemas cujos deadlines são críticos, soluções em software não apresentam um bom desempenho, da mesma forma que não são capazes de gerenciar tarefas de tempo real eficientemente, além de não serem capazes de garantir os deadlines das tarefas.
Soluções em hardware permitem a implementação do paralelismo entre as funções, aumentando o desempenho quando comparado a implementações em software.
No entanto, seu custo e sua complexidade de programação são muito altos, limitando sua utilização.
Logo, uma abordagem interessante consiste no particionamento hardware/ software do sistema operacional, visando aproveitar os benefícios de ambas soluções citadas acima.
Este capítulo visa apresentar os principais trabalhos relacionados a essa abordagem.
Mooney propõe um framework, chamado (Delta), para permitir uma configurabilidade automática do sistema operacional, a fim de suportar o particionamento hardware/ software do sistema operacional, dirigido por o usuário.
Como parte integrante do framework, foi desenvolvido um kernel multiprocessador, chamado Atalanta.
O kernel fornece as características básicas de um RTOS, incluindo capacidades multitarefa, escalonamento dirigido por eventos e baseado em prioridades, além de comunicação intertarefas e sincronização.
O Atalanta é pequeno, compacto, determinístico e modular, o que, segundo Mooney e Blough, é imprescindível para aplicações SoC, devido a a limitação de espaço.
O framework é limitado, pois gera apenas um sistema operacional, que é replicado sobre cada um dos processadores e, além disso, o projetista é incapaz de controlar o mapeamento das tarefas sobre os processadores alvo.
A Figura 7 ilustra a arquitetura dos SoCs gerados através do framework proposto por Mooney e Blough.
User Interface). Para gerar resultados, Mooney e Blough particionaram o kernel Atalanta, migrando algumas de suas funcionalidades para hardware (unidade de controle de deadlock, cache de bloqueio e gerenciamento de memória).
O sistema operacional particionado foi comparado com o Atalanta (totalmente em software).
Os resultados mostraram uma melhora considerável no desempenho do sistema particionado, chegando a, aproximadamente, 400% no caso de implementar o gerenciamento de memória em hardware e 99% no caso de implementar a unidade de controle de deadlock em hardware.
Segundo Nakano, um RTOS requer que o deadline de cada tarefa seja satisfeito e que as tarefas sejam escalonadas de acordo com suas prioridades.
Para isso, deve possuir um tempo de resposta rápido e deve conseguir garantir o pior caso para o tempo de execução.
O uso de módulos de hardware é capaz de garantir esses requisitos, pois permite a paralelização da execução de funções, melhorando o desempenho do sistema.
Para conseguir alcançar essas características, Nakano Propõem um sistema operacional particionado, chamado STRON (do inglês Silicon The Real-time Operating system Nucleusdo inglês Central Processing Unit) e o STRON-I, que corresponde às funcionalidades do RTOS implementadas em hardware.
O STRON-I implementa flags de eventos, semáforos, a fila controle de tarefas, um controlador dos módulos de hardware, o escalonador e os temporizadores do sistema.
Comparando o sistema operacional particionado com o kernel implementado puramente em software (µITRON), Nakano Verificaram que o primeiro alcançou um desempenho consideravelmente melhor em relação a o segundo, variando de 6 a 50 vezes melhor.
O objetivo do projeto RTFPGA (do inglês Real-Time Field Programmable Gate Array) consiste em minimizar a carga do processamento introduzida por o sistema operacional através da migração de funcionalidades chave do software para o hardware.
O sistema operacional foi particionado, implementando o escalonador e as filas de controle de processos em hardware, e mantendo as demais funcionalidades em software.
Segundo Ortiz, as filas foram implementadas em hardware com o intuito de eliminar a sobrecarga do processador em termos de acesso, manutenção, ordenação e busca nas filas.
Com o particionamento do sistema operacional, o processador somente será interrompido quando realmente for necessária a execução de uma nova tarefa.
A Figura 9 ilustra o diagrama de blocos da arquitetura implementada por Ortiz.
Block RAM, o qual consiste numa memória de 4096 células.
O bloco Utime é responsável por o controle de tempo do sistema, gerando interrupções para o processador quando necessário.
O bloco Queue Minimum implementa o algoritmo EDF utilizado no escalonamento das tarefas, armazenadas na fila implementada no bloco Block RAM.
O bloco Queue Delete é responsável por a exclusão de tarefas da fila, através de uma busca linear por o endereço da tarefa a ser excluído.
Caso o endereço seja encontrado, são enviadas informações ao bloco Memory Manager para que este apague a entrada da fila.
Se o endereço não for encontrado, outras informações são enviadas ao bloco Memory Manager com o intuito de preservar todas as entradas da fila.
Por fim, o bloco FIFO Block RAM corresponde a uma FIFO, que armazena as informações das tarefas escalonadas que serão enviadas à CPU para serem executadas.
Este módulo é necessário já que o hardware escalona tarefas num tempo muito pequeno, impossibilitando a CPU de atender as tarefas no momento exato em que estas são escalonadas.
Ortiz particionou o sistema operacional KURT--Linux (do inglês Kansas University RealTime Linux), a fim de gerar resultados baseados na comparação do desempenho entre o sistema particionado e o KURT--Linux (totalmente em software).
Os resultados mostraram uma melhora no desempenho apenas num cenário onde as tarefas executaram no WCET (do inglês Worst Case Execution Time).
A implementação de escalonadores é um problema enfrentado por os projetistas de MPSoCs, visto que neste tipo de arquitetura existem diversos processadores comunicando- se entre si, além de ser permitida a execução do escalonador e das tarefas em CPUs distintas.
Devido a isto, Cho Propõem a implementação de dois escalonadores estáticos, um centralizado e um distribuído, com o intuito de investigar a sobrecarga no desempenho e na área de silício ocupada por ambos, a fim de verificar as vantagens e desvantagens da utilização de cada um.
Um escalonador centralizado consiste num único escalonador gerenciando a execução das tarefas de todos os elementos de processamento, enquanto que um distribuído consiste em diversos escalonadores locais alocados nos diferentes elementos de processamento, responsáveis por o gerenciamento da execução das tarefas apenas do processador em questão.
A Figura 10 ilustra as arquiteturas-alvo para os dois tipos de escalonadores citados acima.
Em a Figura 10 (a), um escalonador centralizado é responsável por o escalonamento de três tarefas (T1, T2, T3), sendo que as tarefas T1 e T2 executam num processador (P1) e a tarefa T3 executa em outro (P2).
Já na Figura 10 (b), é implementado um escalonador distribuído, com-posto por dois escalonadores locais, executando em dois processadores distintos, gerenciando apenas as tarefas do processador ao qual estão alocados.
Em ambas abordagens os escalonadores implementam a mesma política de escalonamento, no entanto, cada arquitetura apresenta diferentes características, relacionadas à área e ao desempenho.
Segundo Cho, há duas possibilidades de implementação para cada escalonador.
No caso de o escalonador centralizado, este pode ser implementado como um processo executando sobre um processador ou como um bloco de hardware dedicado.
De a mesma forma, os escalonadores locais pertencentes ao modelo distribuído podem ser implementados como processos executando concorrentemente com as tarefas em cada processador, ou como um bloco de hardware dedicado, responsável por o escalonamento das tarefas de um único processador.
Os experimentos realizados comparam desempenho e área ocupada por ambas implementações, e os resultados obtidos mostram que o escalonador a ser utilizado dependerá das necessidades da aplicação, pois o escalonador distribuído apresenta um maior desempenho em relação a o centralizado, entretanto, apresenta maior área de silício.
Segundo Samuelsson, as aplicações de tempo real estão se tornando maiores e mais complexas com o passar dos anos, o que motiva a implementação de funções em hardware para obter ganho no desempenho das mesmas.
Com o intuito de provar essa afirmação, Samuelsson Propõem a implementação em hardware e em software do kernel de um Para realizar as comparações, foi utilizada uma plataforma de hardware chamada Sara (do inglês Scalable Architecture for Real-Time Applications), a qual é dividida em blocos que contêm uma CPU, uma memória RAM (do inglês Random Access Memory) local e I/ O (do inglês Input/ Output), comunicando- se entre si através de um barramento, cujo acesso é controlado por um árbitro.
Esse barramento é conectado a uma memória RAM global, dispositivos de I/ O e uma RTU (do inglês Real-Time Unit), que implementa um RTOS num FPGA, ou seja, em hardware.
A Figura 11 ilustra essa arquitetura.
Para a implementação do kernel em software, o bloco RTU deixa de existir na arquitetura da plataforma Sara, sendo substituído por um programa codificado em C, C+ e assembly, o qual executa concorrentemente com as tarefas sobre uma ou mais CPUs.
Para obter resultados fiéis, o kernel software implementa as mesmas funcionalidades da RTU, ou seja, o escalonador, os métodos de comunicação intertarefas, o controle de semáforos e o gerenciamento de tempo do sistema.
A Tabela 1 apresenta um comparativo entre os diversos trabalhos descritos neste capítulo, listando o kernel utilizado no particionamento do sistema operacional, as funções implementadas em software e hardware, o tipo de comparação realizada e os resultados obtidos.
4 Proposta de modelos de escalonadores para sistemas de tempo real Em este capítulo são apresentados os detalhes da implementação dos protótipos desenvolvidos para a prova de conceito do presente trabalho.
As funcionalidades que compõem esses protótipos são o escalonador, o gerenciamento das listas de tarefas e o gerenciamento de tempo do sistema.
Foram desenvolvidas três implementações de modelos de RTOS:
Um sistema operacional, chamado SoRTS, implementado totalmente em software, que executa sobre um único processador;
Um sistema operacional particionado, chamado Co-SoRTS, implementado totalmente em software, cujas tarefas executam sobre um processador e as funcionalidades do RTOS (escalonador e gerenciamento das filas de tarefas) executam sobre um processador dedicado e um sistema operacional particionado, chamado HaRTS, cujas tarefas executam sobre um processador e as funcionalidades do RTOS, que no Co-SoRTS executam sobre um processador dedicado, foram implementadas em hardware.
Este capítulo é organizado da seguinte forma:
Em a Seção 4.1 é descrito o exemplo utilizado na validação dos sistemas.
A Seção 4.2 apresenta os detalhes de prototipação dos sistemas.
Em a Seção 4.3 é apresentada a arquitetura utilizada na implementação do SoRTS, bem como a descrição de sua implementação.
A Seção 4.4 apresenta a arquitetura utilizada na implementação do Co-SoRTS, além de apresentar a descrição da implementação do mesmo.
Por fim, na Seção 4.5 é apresentada a arquitetura do HaRTS, bem como o detalhamento de sua implementação.
Diferentemente do SoRTS e do Co-SoRTS, além de a política de escalonamento RM, o HaRTS implementa o algoritmo EDF.
Portanto, para a validação deste sistema, além de o cenário ilustrado na Figura 12, utilizou- se o exemplo ilustrado na Figura 13.
Este exemplo considera as mesmas tarefas do exemplo da Figura 12, mas estas são escalonadas conforme mostrado na figura 13, sendo que no eixo horizontal observa- se a execução das tarefas conforme o tempo do sistema avança e, no eixo vertical, representam- se as tarefas que estão sendo executadas.
A execução das tarefas respeita a política de escalonamento EDF, cuja descrição foi apresentada no Capítulo 2.
Os três sistemas (SoRTS, Co-SoRTS e HaRTS) foram validados utilizando uma plataforma de prototipação, descrita na Seção 4.2.
No entanto, a política de escalonamento EDF foi validada apenas em nível de simulação.
A plataforma de prototipação VirtexII-ProTM FF896 foi utilizada na prototipação dos três sistemas.
Essa plataforma contém um FPGA com vários elementos configuráveis e blocos embarcados otimizados para projetos de sistemas de alta densidade e alto desempenho.
Além disso, possui os seguintes componentes:
Até dois processadores PowerPC, de arquitetura RISC (do inglês Reduced Instruction Set Computer);
CLBs (do inglês Configurable Logic Blocks) que fornecem elementos de lógica combinacional e síncrona, incluindo elementos de armazenamento básicos;
Módulos de memória (Block RAMs);
Blocos multiplicadores;
Blocos DCM que fornecem calibragem própria, soluções completamente digitais para compensação no atraso da distribuição do clock e divisão e multiplicação de clock.
Os três sistemas utilizam o processador MicroBlaze, executando na freqüência de 50 MHz, o qual consiste num processador do tipo firm core, cuja arquitetura é RISC.
Segundo Bergamaschi e Cohn, firm cores são fornecidos como um netlist já sintetizado, ou seja, após a síntese lógica e o mapeamento para uma tecnologia.
Estes cores não podem ser re-sintetizados por os usuários, mas seu netlist é fornecido numa HDL (do inglês Hardware Description Language), o qual pode ser simulado e modificado se necessário.
O processador MicroBlaze foi escolhido devido a a sua disponibilidade e facilidade de utilização quando comparado aos demais processadores disponíveis no GAPH.
O MicroBlaze inclui um conjunto de instruções ortogonal, 32 registradores de propósito geral de 32 bits, 2 registradores de propósito específico, também de 32 bits, barramentos separados para instruções e dados (arquitetura Harvard), interfaces de comunicação com a memória externa e uma organização pipeline com três estágios (busca, decodificação e execução).
Para desenvolver sistemas embarcados utilizando o processador em questão, é necessária a utilização de ferramentas específicas (EDK -- do inglês Embedded Development Kit), responsáveis por a customização dos componentes de hardware e software que fazem parte do sistema juntamente com o processador MicroBlaze.
O EDK consiste num ambiente de desenvolvimento chamado XPS (do inglês Xilinx Platform Studio), que inclui utilitários de construção de hardware e software, ferramentas de simulação, de debug e de síntese.
Além disso, o ambiente XPS fornece uma GUI integrada para a criação do arquivo de especificação do software para o sistema embarcado, bem como para a escolha dos componentes de hardware do sistema.
A comunicação entre os sistemas e os blocos de hardware, que implementam funcionalidades necessárias para o funcionamento dos mesmos, é realizada através do barramento OPB (do inglês On-Chip Peripheral Bus).
As próximas seções apresentam os detalhes de implementação e validação dos três sistemas citados no início do capítulo, os quais utilizam a plataforma de prototipação descrita nesta seção.
Em esta seção são apresentadas as características da implementação do modelo de sistema operacional implementado totalmente em software, que executa sobre um único processador.
O SoRTS foi implementado na linguagem de programação C, e consiste basicamente num escalonador que adota a política de escalonamento RM.
O diagrama de blocos da arquitetura utilizada nessa abordagem é apresentado na Figura 14.
A arquitetura é composta de um processador, o qual comunica- se com uma memória local de 64 KB através de dois barramentos (um para dados e outro para instruções), um módulo UART (do inglês Universal Asynchronous Receiver/Transmitter) para a comunicação serial com o computador, um módulo de hardware para o controle de tempo e interrupções e um módulo responsável por a interface de comunicação entre o processador e o módulo de hardware.
A comunicação entre o processador e os demais módulos da arquitetura é realizada através de um barramento.
O módulo Interface de comunicação é gerado automaticamente por a ferramenta EDK, e é responsável por a comunicação entre o software (processador) e o hardware (controle de tempo e interrupções), implementando uma interface que transforma os sinais entre o hardware e o software para o padrão do barramento utilizado (OPB).
Esse módulo contém um número fixo de registradores que podem ser facilmente acessados por o software.
Em este projeto foram utilizados dois registradores:
Um para possibilitar a leitura do tempo do sistema (sinal tempo), e outro para o envio de um sinal de interrupção ao processador (sinal int), ambos controlados por o hardware.
O acesso a esses registradores é realizado através de leituras e escritas dos mesmos, as quais são feitas através de duas funções, disponibilizadas por a ferramenta (EDK), que recebem como parâmetro o endereço do registrador a ser acessado, no caso de leitura e, no caso de escrita, o endereço do registrador destino e o dado a ser escrito.
O módulo Processador é responsável por a execução das tarefas e de um conjunto básico de operações, que representam um sistema operacional.
Sua primeira função é inicializar a memória (módulo Memória) com as tarefas que compõem o sistema.
Cada tarefa é representada por uma estrutura que contém as informações de período, deadline, identificador, tempo de execução e tempo já executado.
A partir de estas informações o sistema está apto a escalonar e executar as tarefas.
O módulo Memória armazena duas estruturas:
Uma lista de tarefas prontas para executar e uma lista de tarefas finalizadas.
Inicialmente, todas as tarefas estão prontas para serem executadas.
Portanto, o módulo Processador preenche a lista de prontas com as informações (identificador, período e deadline) de todas as tarefas do sistema, mantendo a lista ordenada por o menor período.
Para o exemplo da Figura 12, a lista de prontas mantém as tarefas conforme ilustrado na Figura 15.
A primeira posição da lista contém a tarefa de menor período (5 ms), a segunda posição contém a tarefa de período intermediário e a terceira posição contém a tarefa de maior período.
Antes de realizar qualquer escalonamento, o sistema verifica na lista de finalizadas se existem tarefas que podem retornar à lista de prontas.
Para realizar essa operação, o sistema percorre toda a lista e compara o deadline da tarefa com o tempo atual do sistema.
A contagem desse tempo foi implementada em hardware, especificamente no módulo Controle de tempo e interrupções da arquitetura.
Caso o deadline seja menor ou igual ao tempo do sistema, a tarefa pode retornar à lista de prontas.
Para o exemplo da Figura 12, ao final do tempo 2 ms, T 1 tem sua execução finalizada e é armazenada na lista de finalizadas e, no tempo 5 ms ela pode voltar a ser escalonada, já que seu período é 5 ms..
A Figura 16 ilustra o estado das duas filas antes e após a retirada da tarefa T1 da lista de finalizadas.
Como pode ser visto na Figura 16, no tempo 4 ms a lista de prontas contém as tarefas T2 e T3, e a lista de finalizadas contém a tarefa T1.
Em o tempo 5 ms, T1 é retirada da lista de finalizadas e retorna à lista de prontas, ajustando o valor de seu deadline (deadline+ período).
Ainda, antes de realizar um escalonamento, o sistema verifica se ocorreu falha, ou seja, se algum deadline não foi atendido, em alguma das tarefas da lista de prontas.
Para isso, percorrese a lista em questão e compara- se o deadline de cada tarefa com o tempo atual do sistema.
Caso o tempo seja maior ou igual ao deadline, significa que a tarefa falhou e esta deve ser corrigida.
A correção de uma falha consiste em ajustar o deadline, somando- se a ele o período da tarefa.
Em o exemplo da Figura 12, a tarefa T3 falha no tempo 13 ms, pois este é seu deadline e sua execução ainda não foi concluída.
Para corrigir essa falha, o sistema se comporta conforme ilustrado na Figura 17.
Como pode ser visto na Figura 17, antes da tarefa T 3 falhar, este foi ajustado tornando- se 26 ms..
A tarefa permanece na lista de prontas até que sua execução seja finalizada.
Finalmente, para realizar um escalonamento, o sistema deve retirar a tarefa de mais alta prioridade da lista de prontas.
Como a lista é mantida ordenada, a tarefa de maior prioridade é sempre aquela que ocupa a primeira posição da lista.
Se a lista estiver vazia, o sistema tenta escalonar novamente, até que esta contenha pelo menos uma tarefa.
Após o escalonamento, o processador realiza uma troca de contexto e inicia a execução da tarefa.
As trocas de contexto consistem em salvar e recuperar a informação referente a o tempo já executado da tarefa em questão.
Controle de tempo e interrupções.
Sempre que uma interrupção ocorre, o sistema salva o contexto da tarefa que está executando e a insere na lista de prontas.
Em o segundo caso, antes de um novo escalonamento, o sistema insere a tarefa que terminou de executar na lista de finalizadas, onde ela será mantida até que seu próximo período seja alcançado e esta possa voltar a ser escalonada.
A Figura 18 ilustra a ordem de execução das tarefas, para o exemplo da Figura 12, até o tempo 20 ms..
Em sistemas com apenas um processador, o qual é responsável por a execução do SO e das tarefas, para que um escalonamento aconteça é necessário que o processador pare a execução da tarefa e passe o controle ao escalonador.
Em esta implementação, a cada 1 ms o processador interrompe a execução de uma tarefa para escalonar uma nova, mesmo que a tarefa escalonada seja a mesma que está executando.
Conforme apresentado no Capítulo 1, isto pode acarretar em falhas nas tarefas, devido a o tempo gasto com trocas de contexto desnecessárias.
Para possibilitar a visualização do funcionamento do algoritmo, foi necessária a inserção do módulo UART na arquitetura, o qual é responsável por a comunicação entre a plataforma de prototipação e o computador hospedeiro (PC Host) através da porta serial.
Esse módulo gera um atraso na ordem de 3 ms, aproximadamente, para realizar a impressão das informações na tela do computador, sendo inviável sua utilização durante a execução do algoritmo.
Portanto, foi necessária a utilização de vetores para armazenar as informações de validação do sistema, e seus conteúdos foram impressos somente no final da execução do sistema, não comprometendo os resultados obtidos.
Em esta seção são apresentadas as características da implementação do Co-SoRTS, o qual consiste num modelo de RTOS particionado, implementado totalmente em software, cujas funcionalidades (escalonador e gerenciamento das listas de tarefas) executam sobre um processador dedicado.
Assim como o SoRTS, o Co-SoRTS também foi implementado na linguagem de programação C. O algoritmo implementado nessa abordagem mantém as mesmas características do SoRTS, tendo como principal diferença o local de execução do escalonador e do gerenciamento das listas de tarefas, realizada sobre um processador dedicado.
Em esta implementação, as trocas de contexto somente ocorrem no caso de a tarefa escalonada ser diferente da vigente, eliminando o tempo gasto com trocas de contexto desnecessárias.
O diagrama de blocos da arquitetura utilizada nessa abordagem é apresentado na Figura 19.
Co-SoRTS. A arquitetura contém dois processadores, cada um comunicando- se com sua memória local (64 KB) através de barramentos separados para dados e instruções, um módulo UART para comunicação serial com o computador, cuja descrição já foi apresentada na Seção 4.3.3, um módulo de hardware para o controle de tempo e interrupções e um módulo responsável por a interface de comunicação entre o processador e o módulo de hardware.
A comunicação entre os processadores e os demais módulos da arquitetura é realizada através de um barramento.
Assim como no SoRTS, o módulo Interface de comunicação é responsável por a comunicação entre o software e o hardware.
Contudo, neste sistema foram utilizados cinco registradores:
Um para disponibilizar o dado enviado de um processador ao outro (slv_ reg2), dois registradores para implementar o protocolo de comunicação entre os processadores (slv_ reg3 e slv_ reg4), um registrador para possibilitar a leitura do tempo do sistema e um registrador para interromper a execução das tarefas.
Sempre que um processador deseja enviar informações, este escreve a informação a ser enviada no registrador slv_ reg2 do módulo Interface de comunicação, escreve o valor &quot;1 «no registrador slv_ reg3, e fica esperando até que o outro processador avise que recebeu a informação enviada (registrador slv_ reg4).
A troca de mensagens entre as duas CPUs demora, em média, 100 ciclos de clock, considerando o tempo para sincronização e para a escrita/ leitura dos dados que são trocados entre ambas.
O módulo Processador é responsável por a execução das tarefas que compõem o sistema, enquanto o módulo Co-processador executa o escalonador e controla as listas de tarefas, paralelamente ao outro processador.
Inicialmente, o módulo Processador é responsável por a inicialização da memória com as informações das tarefas.
Assim como no SoRTS, cada tarefa é representada por uma estrutura que contém o período, o deadline, o identificador, o tempo de execução e o tempo já executado.
A seguir, esse módulo envia as informações das tarefas para o co-processador, o qual, de posse dessas informações, estará apto a escalonar e controlar as listas de tarefas do sistema.
Antes de realizar qualquer escalonamento, o Co-SoRTS verifica na lista de finalizadas se existem tarefas que podem retornar à lista de prontas.
Para realizar essa operação, o sistema atua da mesma forma que o SoRTS (Seção 4.4).
Para o exemplo da Figura 12, ao final do tempo 2 ms a tarefa T1 termina sua execução e é armazenada na lista de finalizadas e, no tempo 5 ms, ela pode voltar a ser escalonada, retornando à lista de tarefas prontas.
A Figura 21 ilustra o estado das duas filas antes e após a retirada da tarefa T1 da lista de finalizadas.
Como pode ser visto na Figura 21, no tempo 4 ms a lista de prontas contém as tarefas T 2 e T3, e a lista de finalizadas contém a tarefa T1.
Em o tempo 5 ms T1 é retirada da lista de finalizadas e retorna à lista de prontas, ajustando o valor de seu deadline.
Ainda, antes de realizar um escalonamento, o sistema verifica se alguma das tarefas do sistema falhou.
Esta etapa do algoritmo é realizada da mesma que forma que no SoRTS, sendo executada no módulo Co-processador.
Após o ajuste da falha, o módulo Co-processador envia o identificador da tarefa que falhou ao módulo Processador, pois este é o responsável por a computação do número de falhas do sistema.
Em o exemplo da Figura 12, a tarefa T3 falha no tempo 13 ms, já que este é seu deadline e sua execução ainda não foi concluída.
Para corrigir essa falha, o sistema se comporta conforme ilustrado na Figura 22.
Como pode ser visto na Figura 22, assim como no SoRTS, antes da tarefa T3 falhar seu deadline era 13 ms e, após a falha, este foi atualizado através da soma do deadline com o período, tornando- se 26 ms..
A tarefa permanece na lista de prontas até que sua execução seja finalizada.
Finalmente, para realizar um escalonamento, o sistema deve retirar a tarefa de mais alta prioridade da lista de prontas (tarefa na primeira posição da lista).
Assim como no SoRTS, durante a execução de uma tarefa podem ocorrer dois cenários distintos:
A tarefa acaba de executar antes que uma nova tenha sido escalonada;
E uma tarefa de maior prioridade é escalonada antes do término da execução da tarefa vigente.
Em o primeiro caso, o módulo Processador deve enviar um sinal ao módulo Co-processador para que este envie as informações da nova tarefa a ser executada.
A o receber as informações da próxima tarefa, o contexto desta é restaurado, e sua execução é iniciada.
Em o segundo caso, o módulo Co-processador envia o identificador da tarefa escalonada ao módulo Processador e, além disso, envia um sinal informando a existência de uma nova tarefa a ser executada.
O módulo Processador interrompe a execução da tarefa vigente e realiza uma troca de contexto a fim de salvar as informações da tarefa que estava sendo executada e recuperar as informações da nova tarefa.
Essas informações incluem o tempo já executado da tarefa.
É importante ressaltar que uma tarefa somente será enviada no caso de ser diferente daquela que já está executando.
Após o envio do identificador da tarefa ao módulo Processador, o escalonador insere esta na lista de prontas para que ela possa ser novamente escalonada, a menos que o módulo Processador tenha sinalizado a finalização da execução da mesma.
Em esse caso, a tarefa é inserida na lista de finalizadas, onde ela será mantida até que seu próximo período seja alcançado e esta possa voltar a ser escalonada.
Comparando as Figuras 23 e 12, as quais ilustram a ordem de escalonamento e execução das tarefas até o tempo 20 ms, pode- se notar que o algoritmo implementado (Co-SoRTS) apresentou o mesmo comportamento que o exemplo, exceto por pequenos atrasos na finalização da execução das tarefas, causados por o tempo gasto com trocas de contexto, que não foi considerado no exemplo da Figura 12.
Conforme pode ser observado na Figura 23, diferentemente do SoRTS, no Co-SoRTS a interrupção da execução de uma tarefa somente ocorre no caso de uma tarefa diferente da que está executando ser escalonada, eliminando o tempo gasto com trocas de contexto desnecessárias.
Em esta seção são apresentadas as características da implementação do modelo de RTOS particionado, cujas funcionalidades (escalonador e gerenciamento da lista de tarefas) foram migradas para o hardware, mantendo- se a execução e a troca de contexto das tarefas executando sobre um processador.
As funcionalidades que executam sobre o processador (software) foram implementadas na linguagem de programação C, enquanto que foi utilizada a linguagem de programação VHDL (do inglês Very high speed integrated circuit Hardware Description Language) na implementação das funcionalidades em hardware.
Assim como no SoRTS e no Co-SoRTS, o controle de tempo do sistema também foi implementado em hardware a fim de garantir precisão temporal.
A arquitetura empregada é ilustrada na Figura 24, e descrição de seus módulos é apresentada a seguir.
A arquitetura é composta por um processador, o qual comunica- se com uma memória local de 64 KB através de dois barramentos (um para dados e outro para instruções), um módulo UART para a comunicação serial com o computador, cuja descrição já foi apresentada na Seção 4.3.3, um módulo de hardware que implementa o escalonador do sistema, o controle de tempo e interrupções, e a interface de comunicação entre o processador e o escalonador do sistema.
A comunicação entre o processador e os demais módulos da arquitetura é realizada através de um barramento.
O módulo Memória representa o local onde as informações de todas as tarefas gerenciadas por o sistema operacional são armazenadas.
Assim como nos outros dois sistemas implementados, cada tarefa é representada por uma estrutura que contém seu período, seu deadline, seu identificador, seu tempo de execução e a parcela de tempo que já foi executada.
A primeira ação do sistema constitui- se na inicialização do módulo Memória com as informações das tarefas, o que é realizado em software por o módulo Processador.
Após a inicialização da memória, inicia- se o envio das informações das tarefas para o módulo Hardware dedicado, o qual contém a implementação das funcionalidades do RTOS em hardware, bem como a interface de comunicação entre o software e o hardware.
O módulo Processador representa o processador responsável por a execução das funções do sistema operacional (trocas de contexto), bem como dos módulos da aplicação (tarefas gerenciadas por o sistema operacional), ambos implementados em software.
Além disso, esse módulo é responsável por o recebimento/ envio de tarefas de/ para o módulo Hardware dedicado.
Inicialmente, o módulo Processador é responsável por a inicilização da memória, conforme descrito na Seção 4.5.1 e, após a conclusão dessa tarefa, este realiza leituras da memória, a fim de buscar as informações (identificador, deadline e período) de cada tarefa.
De posse dessas informações, o processador as envia ao módulo Hardware dedicado, que as trata de forma apropriada.
A o finalizar esse envio, o módulo Hardware dedicado inicia seu funcionamento, e o módulo Processador está pronto para receber e executar a primeira tarefa escalonada.
Assim como no SoRTS e no Co-SoRTS, durante a execução de uma tarefa podem ocorrer dois cenários distintos:
A tarefa acaba de executar antes que uma nova tenha sido escalonada;
E uma tarefa de maior prioridade é escalonada antes do término da execução da tarefa vigente.
Em o primeiro caso, o módulo Processador deve enviar um sinal ao módulo Hardware dedicado para que este envie as informações da nova tarefa a ser executada.
A o receber as infor-mações da próxima tarefa, o contexto desta é restaurado, e sua execução é iniciada.
Em o segundo caso, o módulo Hardware dedicado fica encarregado de sinalizar ao processador a existência de uma nova tarefa a ser executada através do envio de uma interrupção.
Em este ponto, o Processador salva o contexto da tarefa vigente.
A seguir, o contexto da nova tarefa a ser executada é restaurado e, como no caso anterior, a execução dessa tarefa é iniciada.
O módulo Hardware dedicado implementa a interface entre o software e o hardware, bem como as funcionalidades do RTOS implementadas em hardware (escalonador e gerenciamento das listas de tarefas) e o gerenciamento de tempo do sistema.
A Figura 25 ilustra o diagrama de blocos específico para esse módulo.
Módulo Interface de comunicação Assim como no SoRTS e no Co-SoRTS, o módulo Interface de comunicação é responsável por a comunicação entre o software (processador) e o hardware.
Contudo, diferentemente dos demais, neste sistema foi necessária a utilização de 15 registradores:
Quatro para armazenar as informações (identificador, período, deadline e estado) das tarefas a serem inseridas na lista, um registrador para sinalizar o início e o término do envio das informações das tarefas da memória local do processador para o escalonador (slv_ reg4), dois registradores para implementar o controle do envio dessas informações, um registrador que armazena o identificador da última tarefa escalonada (slv_ reg5), dois registradores para implementar o controle do envio desse identificador ao processador, um registrador que armazena o identificador da última tarefa que falhou (slv_ reg6), dois registradores para implementar o controle do envio desse identificador ao processador, um registrador para possibilitar a leitura do tempo do sistema, um registrador para informar quando uma tarefa que estava executando foi finalizada e, finalmente, um registrador para informar ao processador que o escalonador tratou o caso de finalização da tarefa.&amp;&amp;&amp;
Módulo Controle de tempo Este módulo é responsável por realizar o gerenciamento de tempo do sistema, e consiste num contador incrementado de 1 unidade a cada ciclo de clock.
Como o módulo Hardware dedicado funciona a um clock de 50 MHz, 50000 ciclos de clock correspondem a 1 ms..
Cada vez que o contador chega em 50000 este é reiniciado e o sinal tempo é incrementado de 1 unidade.
Este sinal é utilizado por os módulos Escalonador e Controlador de listas.
Em o primeiro é utilizado em comparações para verificar a ocorrência de falhas (tarefa que não acabou até o seu deadline) e, no segundo, é utilizado em comparações para verificar se uma tarefa finalizada pode voltar a ser escalonada.
Módulos Escalonador e Controlador de listas O módulo Escalonador é responsável por o escalonamento e por o controle de falhas de deadline das tarefas, cujas informações estão armazenadas numa lista implementada no módulo Controlador de listas.
Para o gerenciamento das tarefas, seria necessária a implementação de duas listas.
No entanto, buscando otimização de área de silício, optou- se por a implementação de apenas uma lista, associando um estado a cada tarefa.
Sendo assim, cada vez que as tarefas são escalonadas, finalizadas, ou têm sua execução interrompida, estas não são removidas da lista, apenas seus estados são atualizados de acordo com a ação que ocorreu.
Foram implementadas a política de escalonamento RM e a EDF, e a principal diferença entre elas concentra- se na implementação do módulo Controlador de listas, mais especificamente, nas questões referentes ao acesso e à ordenação da lista de tarefas.
Apesar de a validação ter sido realizada utilizando apenas três tarefas, esta lista foi implementada para conter um número máximo de 16 tarefas.
Para o algoritmo RM, que é baseado em prioridades estáticas, basta que a lista de tarefas seja ordenada uma única vez, no início do processo.
Em esta política, a primeira posição da lista sempre contém a tarefa com o menor período, e esta só não será escalonada se seu estado for diferente de zero.
Já para o algoritmo EDF, que é baseado em prioridades dinâmicas, a lista de tarefas deve ser ordenada antes de cada escalonamento, levando em consideração o menor deadline em relação a o tempo do sistema.
O módulo Escalonador não tem acesso direto à lista de tarefas, sendo este acesso realizado através de requisições de leitura e/ ou escrita ao módulo Controlador de listas.
Inicialmente, a lista encontra- se vazia e, para preencher- la, o módulo Escalonador recebe as informações das tarefas, enviadas por o módulo Processador, e repassa ao módulo Controlador de listas, o qual é implementado como uma FSM ilustrada na Figura 26.
Enquanto o sinal insert contiver o valor 1, o módulo permanece no estado Inserting, inserindo as tarefas na lista.
Assim que o sinal insert for modificado para 0, a FSM passa para o estado Sorting, a fim de ordenar a lista e mantém- se nesse estado enquanto o sinal cont_ sort for menor que o sinal count_ procs (número total de tarefas inseridas na lista).
Quando os dois sinais citados tornam- se idênticos, a FSM passa para o estado Processing, em o qual é realizado todo o controle da lista.
A Figura 27 ilustra o resultado da simulação para a etapa de inserção e ordenação da lista para os algoritmos RM e EDF, considerando os exemplos das Figuras 12 e 13.
Para facilitar a explicação do comportamento dos algoritmos, foram inseridos rótulos, representados por letras e números, em diferentes pontos da Figura 27, os quais são detalhados a seguir.
Processador atribui o valor 1 a esse sinal, o qual permanece com este valor até que o processo de envio das tarefas seja finalizado.
Antes de qualquer escalonamento, o algoritmo deve verificar se alguma das tarefas prontas para executar falhou (não atendeu o deadline), além de verificar se alguma das tarefas em estado 3 (finalizadas) pode retornar para o estado 0 (pronta).
Sempre que ocorre uma falha, o bloco Escalonador sinaliza o Processador, para que este corrija a tarefa que falhou na sua Memória local.
A verificação de falhas é realizada por o bloco Processo Fail, o qual consiste num processo implementado no módulo Escalonador.
A Figura 28 ilustra o resultado da simulação para a etapa de verificação de falhas de ambos algoritmos (RM e EDF), considerando os exemplos das Figuras 12 e 13.
Para facilitar a explicação do comportamento dos algoritmos, foram inseridos rótulos em diferentes pontos da Figura 28, os quais são detalhados a seguir.
O módulo Escalonador envia requisições de leitura ao Controlador de listas, para que este retorne as tarefas que estão prontas para executar.
A o receber a requisição, a lista é percorrida em busca das tarefas que atendem essa condição e, ao encontrar uma, atribui suas informações ao sinal fail e sinaliza o envio dessas informações ao módulo Escalonador através da atribuição do valor 1 ao sinal ackFail.
Em este ponto os sinais reqFail e ackFail voltam ao valor 0, para que uma nova requisição possa ser feita.
Em o tempo 13 ms (sinal tempo), o sinal fail contém as informações da tarefa T 3.
De posse dessas informações, o seu deadline e o tempo atual do sistema são comparados.
Se o deadline for menor ou igual ao tempo, significa que a tarefa falhou.
De a mesma forma que no exemplo das Figuras 12 e 13, T3 falhou.
Para corrigir a falha, o módulo Escalonador envia uma requisição de escrita na lista (reqFail $= 3).
O módulo Controlador de listas recebe a requisição e atualiza o deadline da tarefa, somando ao seu deadline o valor de seu período.
A lista de tarefas tem o deadline de T3 atualizado de 13 ms para 26 ms, mantendo as demais tarefas inalteradas.
O módulo Escalonador atualiza o sinal idFail_ o com o identificador da tarefa que falhou e sinaliza o módulo Processador de que este deve computar uma falha através da atribuição do valor 1 ao sinal sendTaskFail.
Após o recebimento da tarefa, o Processador computa uma falha e atualiza o sinal ackTaskFail com o valor 1, para que o sinal sendTaskFail volte a ser 0 e uma nova tarefa que falhou possa ser enviada.
Após receber o sinal ackTaskFail do módulo Processador, o Escalonador atribui o valor 2 ao sinal reqFail a fim de sinalizar ao módulo Controlador de Listas que os procedimentos de correção da tarefa foram realizados.
Esse módulo, então, atribui o valor 0 ao sinal ackFail, sinalizando ao Escalonador que este pode enviar novas requisições de leitura ao Controlador de listas.
T1. Para facilitar a explicação do comportamento dos algoritmos, foram inseridos rótulos em diferentes pontos da Figura 27, os quais são detalhados a seguir.
A tarefa T1 tem seu estado contendo o valor 1 (executando) e o tempo do sistema (sinal tempo) é 0 ms..
Logo, não é necessária a comparação entre o deadline e o tempo do sistema, já que a tarefa ainda não foi finalizada.
A tarefa T1 ainda tem seu estado contendo o valor 1, mas agora o tempo do sistema (sinal tempo) é 1 ms..
No entanto, esta ainda não foi finalizada não sendo necessária a comparação entre seu deadline e o tempo do sistema.
Aqui a tarefa T1 tem seu estado contendo o valor 3 (finalizada) e o tempo do sistema (sinal tempo) é 2 ms..
Em este caso, compara- se o deadline da tarefa com o tempo atual do sistema.
Se o último for menor ou igual ao primeiro, a tarefa pode voltar a ser escalonada.
No entanto, no tempo 3 ms essa comparação não é verdadeira, o que faz com que a tarefa continue com seu estado contendo o valor 3.
O mesmo acontece nos tempos 3 ms e 4 ms..
A tarefa T1 tem seu estado contendo o valor 3 e o tempo do sistema (sinal tempo) é 5 ms..
Assim como no item anterior, compara- se o deadline da tarefa com o tempo do sistema, verificando que ambos possuem o mesmo valor.
Portanto, o período de T 1 foi alcançado e esta pode voltar a ser escalonada.
Em este ponto atribui- se o valor 1 ao sinal trocaEstado, sinalizando que o Controlador de listas deve atualizar a tarefa em questão na lista de tarefas.
O sinal listaDeTarefas é atualizado, ajustando o deadline da tarefa T 1 (adiciona- se o valor do período da tarefa ao valor de seu deadline) e o estado da mesma.
Como esta é a tarefa de maior prioridade do sistema, a transição do estado de 3 para 0 não é vista na Figura 29, pois 1 ciclo de clock após a transição, a tarefa é escalonada e tem seu estado atualizado para 1 (executando).
Finalmente, o escalonamento das tarefas acontece conforme ilustrado na Figura 30, para o exemplo da Figura 12 (algoritmo RM).
Os blocos da arquitetura responsáveis por o escalonamento das tarefas são o Processo Ready e o Processo Running, e cada um de eles consiste num processo implementado no módulo Escalonador.
Para facilitar a explicação do comportamento do algoritmo, foram inseridos rótulos em diferentes pontos da Figura 27, os quais são detalhados a seguir.
Para escalonar uma tarefa, o módulo Escalonador envia uma requisição de leitura ao bloco Controlador de listas, o que é feito através da atribuição do valor 1 ao sinal reqReady.
Este sinal permanece com esse valor até que o Controlador de listas atribua o valor 1 no sinal ackReady, sinalizando que disponibilizou o identificador da tarefa de maior prioridade no sinal ready.
Além disso, atualiza o estado da tarefa de 0 (pronta) para 1 (executando).
De posse do identificador da tarefa, o módulo Escalonador verifica se este é diferente da última tarefa (lastRunning) enviada ao módulo Processador.
Em caso afirmativo, atualiza o sinal id_ o com o identificador da tarefa.
Após, o sinal lastRunning é atualizado com o valor de ready.
Após atualizar o sinal id_ o, o módulo Escalonador sinaliza o Processador, através do sinal sendTask, avisando que enviou o identificador da próxima tarefa a ser executada.
Assim que o Processador estiver de posse do identificador da tarefa, este atribui o valor 1 ao sinal ackTask.
Em seguida, ambos sendTask e ackTask são atualizados com o valor 0, para que uma nova tarefa possa ser enviada ao módulo Processador.
Antes de um escalonamento, o módulo Escalonador envia uma requisição de escrita ao Controlador de listas (sinal reqRun contendo o valor 3), para que este percorra a lista e, ao encontrar uma tarefa cujo estado contiver o valor 1 (executando), o atualize para 0 (pronta).
No entanto, nem sempre a tarefa que estava executando pode voltar a ser escalonada, o que acontece quando esta tem sua execução finalizada.
Quando uma tarefa termina de executar, o módulo Processador sinaliza o Escalonador através do sinal reqIntProc, ao qual é atribuído o valor 1.
Em este caso, o módulo Escalonador atualiza o sinal reqRun com o valor 1 e o módulo Controlador de listas atualiza o estado da tarefa que estava executando para 3 (finalizada).
Após receber uma requisição, o Controlador de listas atribui o valor 1 ao sinal ackRun, sinalizando que a lista de tarefas foi atualizada e uma nova requisição pode ser enviada.
No caso de finalização de uma tarefa, atribui- se o valor 1 ao sinal ackIntProc, liberando o módulo Processador para a espera da nova tarefa a ser executada.
A seguir, o Escalonador realiza um escalonamento, conforme descrito no item 1.
Escalonador. Antes de cada escalonamento, é necessário que a lista de tarefas seja ordenada por o menor deadline.
No entanto, a ordenação realizada nesta implementação não altera a ordem das tarefas na lista.
Para realizar este procedimento, foram criados três vetores, onde o primeiro contém a metade dos nodos da lista de tarefas, o segundo contém a metade dos nodos do primeiro e o terceiro contém a metade dos nodos do segundo.
Inicialmente, os nodos do sinal listaDeTarefas são comparados dois a dois, ou seja, comparam- se os deadlines do primeiro e do segundo elementos da lista, a seguir comparam- se o terceiro e quarto elementos, e assim por diante.
Os índices da lista que contêm os menores deadlines são armazenados em tasksIndice1.
A próxima etapa do algoritmo consiste na comparação dos deadlines dos nodos da lista de tarefas, cujos índices foram armazenados em tasksIndice1.
O resultado dessa comparação é armazenado em tasksIndice2.
A seguir, comparam- se os deadlines dos nodos da lista de tarefas, cujos índices que contêm o menor deadline foram armazenados em tasksIndice3.
Por fim, comparam- se os deadlines dos nodos &quot;apontados «por o sinal tasksIndice3, resultando no índice da lista de tarefas que contém o menor deadline.
O módulo Controlador de listas envia o identificador dessa tarefa ao Escalonador através do sinal ready.
A o utilizar essa abordagem para buscar a tarefa de menor deadline, garante- se que esse procedimento sempre levará 4 ciclos de clock, diferentemente de um algoritmo de ordenação, cujo tempo varia de acordo com o número de tarefas a serem comparadas.
Para escalonar uma tarefa, o módulo Escalonador envia uma requisição de leitura ao bloco Controlador de listas, o que é feito através da atribuição do valor 1 ao sinal reqReady.
Este sinal permanece com esse valor até que o Controlador de listas atribua o valor 1 no sinal ackReady, sinalizando que disponibilizou o identificador da tarefa de maior prioridade no sinal ready.
Além disso, atualiza o estado da tarefa de 0 (pronta) para 1 (executando).
De posse do identificador da tarefa, o módulo Escalonador verifica se este é diferente da última tarefa (lastRunning) enviada ao módulo Processador.
Em caso afirmativo, atualiza o sinal id_ o com o identificador da tarefa.
Após, o sinal lastRunning é atualizado com o valor de ready.
Após atualizar o sinal id_ o, o módulo Escalonador sinaliza o Processador, através do sinal sendTask, avisando que enviou o identificador da próxima tarefa a ser executada.
Assim que o Processador estiver de posse do identificador da tarefa, este atribui o valor 1 ao sinal ackTask.
Em seguida, ambos sendTask e ackTask são atualizados com o valor 0, para que uma nova tarefa possa ser enviada ao módulo Processador.
Quando uma tarefa termina de executar, o que pode acontecer entre dois escalonamentos, o módulo Processador sinaliza o Escalonador para que este envie a próxima tarefa a ser executada, além de atualizar o estado da tarefa que estava executando.
Para realizar esse procedimento, o Processador atribui o valor 1 ao sinal reqIntProc, e o módulo Escalonador envia uma requisição de escrita ao Controlador de listas.
Este último percorre a lista buscando uma tarefa cujo estado contiver o valor 1 e o atualiza para 3.
Após, o Controlador de listas atribui o valor 1 ao sinal ackRun, sinalizando que atualizou a lista de tarefas.
Em este ponto, atribui- se o valor 1 ao sinal ackIntProc, liberando o módulo Processador para a espera da nova tarefa a ser executada.
A seguir, o Escalonador realiza um escalonamento, conforme descrito no item 1.
É importante salientar que a política de escalonamento EDF não foi prototipada, tendo sua validação realizada apenas em nível de simulação.
No entanto, observando- se os resultados da simulação, verificou- se que o algoritmo se comportou como esperado, respeitando a ordem de escalonamento e execução do exemplo da Figura 13.
Este capítulo apresentou a proposta de implementação de três modelos de sistemas operacionais de tempo real:
SoRTS, Co-SoRTS e HaRTS.
O primeiro foi implementado totalmente em software, executando sobre um único processador.
O segundo também foi implementado totalmente em software, mas particionado, cujas tarefas executam sobre um processador e as funcionalidades do RTOS (escalonador e gerenciamento das filas de tarefas) executam sobre um processador dedicado.
O último também foi particionado, cujas tarefas executam sobre um processador e as funcionalidades do RTOS, que no Co-SoRTS executam sobre um processador dedicado, foram implementadas em hardware.
Os três sistemas implementam a política de escalonamento RM e foram prototipados numa placa VirtexII-ProTM FF896.
Foi utilizado o processador MicroBlaze executando na freqüência de 50 MHz.
Para a validação dos sistemas foi desenvolvido um teste de mesa composto por três tarefas com valores de tempo de execução e período/ deadline arbitrados.
Este teste respeita a política de escalonamento RM.
Os três sistemas mostraram o comportamento esperado, ou seja, idêntico ao teste de mesa.
No entanto, foi observado um número menor de trocas de contexto nos sistemas Co-SoRTS e HaRTS, o que também era esperado, visto que estes executam em paralelo às tarefas, e somente interrompem o processador no caso de uma tarefa diferente daquela que está executando ser escalonada.
Diferentemente do SoRTS e do Co-SoRTS, além de a política RM, o HaRTS implementa a política EDF, a qual foi validada apenas em simulação e apresentou o mesmo comportamento do teste de mesa desenvolvido.
A implementação desta política nos demais sistemas e sua validação são propostas como trabalhos futuros.
O Capítulo 5 mostra comparações mais detalhadas, referentes ao número de trocas de contexto, falhas e utilização de CPU, entre os três sistemas descritos no presente capítulo.
Este capítulo apresenta um estudo de caso para a prova de conceito do presente trabalho.
Foram realizadas comparações referentes a falhas e trocas de contexto entre três distintas implementações de modelos de RTOSs (SoRTS, Co-SoRTS e HaRTS) descritas no Capítulo 4.
A Seção 5.1 descreve o experimento utilizado para realizar essas comparações, na Seção 5.2 são apresentados os resultados obtidos e a Seção 5.3 aborda as conclusões obtidas com a realização do estudo de caso.
O experimento desenvolvido consiste numa aplicação sintética, a qual corresponde a um conjunto de tarefas onde, para cada tarefa, foram estimados um período, um deadline e um tempo médio de execução (ACET -- do inglês Average Case Execution Time).
Normalmente, as tarefas são modeladas através de um BCET (do inglês Best Case Execution Time) e de um WCET, e seus tempos de execução são variáveis dentro de essa faixa de valores.
Sendo assim, seria mais interessante modelar o tempo de execução das tarefas dentro de o intervalo definido por BCET e WCET.
Contudo, para armazenar esses tempos seria necessária a utilização de uma estrutura que referenciasse a tarefa e todos os seus tempos de execução.
No entanto, a utilização de uma estrutura deste tipo necessitaria de uma memória de tamanho maior do que a memória disponível na plataforma de prototipação disponível para implementação dos RTOSs.
Desta forma, optou- se por utilizar o tempo médio de execução das tarefas.
Uma solução possível de ser adotada para o problema de tamanho da memória seria utilizar a memória externa (SDRAM -- do inglês Synchronous Dynamic Random Access Memory).
Todavia, para não gerar um custo adicional de comunicação, esta solução não foi adotada.
A modelagem de tarefas se mostrou bastante eficiente para validar os conceitos propostos neste trabalho, visto que, neste nível de validação do sistema, a computação e a comunicação realizadas por uma tarefa não são relevantes, mas sim o tempo de execução da tarefa.
A Tabela 2 mostra o conjunto de tarefas modeladas para o estudo de caso.
O conjunto é composto por 10 tarefas, cujos tempos, períodos e deadlines variam na ordem de grandeza de milissegundos.
É importante ressaltar que cada tarefa foi modelada mantendo seu período e deadline idênticos.
Os intervalos entre as trocas de contexto foram variados conforme mostrado na primeira coluna da Tabela 3 e, para cada variação, o tempo gasto com trocas de contexto foi variado de 25 em 25 µs, conforme mostrado nas demais colunas da Tabela 3.
É importante ressaltar que o intervalo entre as trocas de contexto foi variado apenas no SoRTS, pois o Co-SoRTS e o HaRTS realizam escalonamentos sucessivos sem necessitar desse intervalo.
Já o tempo gasto com trocas de contexto foi variado nos três sistemas.
A partir de os benchmarks ilustrados na Tabela 3 foram criados cenários para a prova de conceito do presente trabalho, mostrando os casos onde o particionamento do SO apresenta vantagens sobre um sistema operacional implementado totalmente em software e vice-versa.
Os resultados obtidos são discutidos a seguir, na Seção 5.2.
Os resultados apresentados nesta seção correspondem a comparações entre o SoRTS, o CoSoRTS e o HaRTS.
Primeiramente, apresenta- se uma comparação da área de FPGA ocupada.
A seguir, apresenta- se o ganho em relação a o número de trocas de contexto entre os sistemas.
Em um terceiro momento, são discutidas comparações entre o número de falhas dos três sistemas e, por fim, são apresentados resultados referentes ao tempo de utilização da CPU gasto na execução das tarefas.
Para obter estes resultados, cada sistema foi executado durante o tempo de 10 segundos.
O primeiro resultado apresentado consiste na comparação entre a quantidade de área do FPGA ocupada com cada um dos sistemas.
Conforme apresentado no Capítulo 4, o SoRTS, o Co-SoRTS e o HaRTS foram prototipados utilizando a plataforma de prototipação Virtex IIProTM FF896, que disponibiliza um FPGA com 13696 slices as quais são um conjunto de células contíguas que compõem um módulo de hardware.
A Tabela 4 ilustra a quantidade de área do FPGA ocupada na prototipação de cada sistema.
Em relação a a área ocupada, observa- se que o SoRTS apresenta maior vantagem em relação a os demais sistemas, devido a o fato deste ter ocupado menor área do FPGA, assim como o Co-SoRTS apresenta vantagem sobre o HaRTS.
Este resultado independe do número de tarefas, bem como dos tempos de execução, deadlines e período das mesmas.
O HaRTS apresentou maior área em relação a os demais, devido a o fato deste utilizar um número elevado de registradores na implementação de suas máquinas de estados e buffers de armazenamento de informações.
Cabe salientar que é possível otimizar essa implementação, por exemplo, substituindo alguns registradores por Block RAMs disponíveis no FPGA.
Esta e outras otimizações entram como trabalhos futuros, visto que o objetivo do trabalho, o qual era fazer o escalonador implementado em hardware funcionar, foi alcançado.
Após 10 segundos de execução dos três sistemas implementados, para cada um dos benchmarks ilustrados na Tabela 3, foram obtidos valores referentes ao número de trocas de contexto, que são mostrados na Tabela 5, no gráfico da Figura 34 e no gráfico da Figura 35 para o SoRTS, o Co-SoRTS e o HaRTS, respectivamente.
A partir de os valores encontrados, foram traçados gráficos que ilustram o comportamento de cada sistema de acordo com o benchmark empre-gado.
De posse dos números apresentados na Tabela 5, foi traçado o gráfico ilustrado na Figura 33 para o sistema SoRTS.
As curvas ilustram a variação do número de trocas de contexto, relacionando o intervalo de tempo entre estas, representado através do nome da curva, e seus tempos de execução (eixo horizontal).
Através do gráfico da Figura 33, é possível observar que o número de trocas de contexto (eixo vertical) diminui conforme o intervalo entre as trocas de contexto e o tempo destas aumenta.
A diminuição descrita está diretamente relacionada ao aumento do intervalo entre as trocas de contexto.
Quanto maior esse intervalo, o sistema disponibiliza mais tempo para a execução das tarefas antes de um novo escalonamento, dispensando algumas trocas de contexto que seriam necessárias quando o intervalo utilizado é menor o que, conseqüentemente, diminui o número de trocas de contexto.
Por outro lado, quanto maior o tempo gasto com as trocas de contexto, menor é o tempo disponível para executar as tarefas, sendo necessário chavear contexto mais vezes.
Logo, se os benchmarks empregados no estudo de caso considerassem variações apenas no tempo das trocas de contexto, seu número aumentaria ao invés de diminuir.
No entanto, esse aumento apenas é observado em casos onde não ocorrem falhas nas tarefas do sistema.
Nos demais casos, algumas tarefas nem chegam a ser executadas, diminuindo a quantidade de trocas de contexto, criando o cenário que pode ser observado na curva 100 us (Figura 33).
O gráfico ilustrado na Figura 34 mostra o comportamento do número de trocas de contexto realizadas no sistema Co-SoRTS.
As curvas relacionam o número de trocas de contexto (eixo vertical) e seu tempo de execução (eixo horizontal).
Diferentemente do SoRTS, o número de trocas de contexto nesse sistema tende a aumentar conforme o tempo destas aumenta.
Este aumento é observado devido a o fato de que o sistema só realiza trocas de contexto quando a tarefa escalonada é diferente da tarefa que está sendo executada.
Portanto, quanto maior o tempo das trocas de contexto, o sistema disponibiliza um tempo menor para a execução das tarefas, fazendo com que a execução das tarefas seja interrompida mais vezes do que em casos onde o tempo é menor, sendo necessário um número maior de trocas de contexto para finalizar a execução de uma tarefa.
No entanto, sabe- se que em casos onde ocorre um número considerável de falhas no sistema, algumas tarefas não chegam a ser executadas ou, pelo menos, são executadas menos vezes que nos casos onde não ocorrem falhas.
Devido a isso, o contexto das tarefas não é chaveado tanto quanto nos casos onde estas não falham e, conseqüentemente, o número de trocas de contexto diminui.
O gráfico ilustrado na Figura 35 mostra o comportamento do número de trocas de contexto realizadas no sistema HaRTS.
Como no gráfico da Figura 34, a curva representa o relacionamento entre o número de trocas de contexto (eixo vertical) e seu tempo de execução (eixo horizontal).
Assim como no Co-SoRTS, o número de trocas de contexto no HaRTS também tende a aumentar conforme o tempo destas aumenta.
Este aumento é observado devido a o fato de que o sistema só realiza trocas de contexto quando a tarefa escalonada é diferente da tarefa que está sendo executada.
Portanto, quanto maior o tempo das trocas de contexto, o sistema disponibiliza um tempo menor para a execução das tarefas, fazendo com que a execução das tarefas seja interrompida mais vezes do que em casos onde o tempo é menor, sendo necessário um número maior de trocas de contexto para finalizar a execução de uma tarefa.
Assim como no Co-SoRTS, a partir de um determinado ponto podem ocorrer falhas no sistema, o que faz com que algumas tarefas não sejam executadas ou, pelo menos, sejam executadas menos vezes que nos casos onde não ocorrem falhas.
Devido a isso, o contexto das tarefas não é chaveado tanto quanto nos casos onde estas não falham e, conseqüentemente, a quantidade de trocas de contexto é menor em relação a os casos onde não ocorrem falhas.
É importante ressaltar que não foi observado um cenário de ocorrência de falhas para os sistemas Co-SoRTS e HaRTS no estudo de caso apresentado neste trabalho.
A Figura 36 apresenta uma comparação entre os três sistemas, relativa ao comportamento do número de trocas de contexto para cada um de eles.
As curvas ilustram o número de trocas de contexto para o SoRTS, o Co-SoRTS e o HaRTS.
Através do gráfico (Figura 36) pode- se notar que os sistemas particionados apresentam um número de trocas de contexto menor em relação a o SoRTS.
Esse comportamento é observado, porque os sistemas particionados executam o escalonador paralelamente à execução das tarefas, dispensando trocas de contexto a cada escalonamento.
Em o Co-SoRTS e no HaRTS, as trocas de contexto são realizadas somente quando uma tarefa diferente daquela que está sendo executada é escalonada.
Conclui- se, então, que estes dois sistemas apresentam vantagem, relativa ao número de trocas de contexto, sobre o SoRTS.
Conforme mencionado anteriormente, quanto maior o intervalo entre as trocas de contexto, menor é o número das mesmas.
Portanto, para casos onde esse intervalo estiver na ordem de 10000 µs, por exemplo, o número de trocas de contexto no sistema SoRTS tende a ser menor que nos demais e, sendo assim, o Co-SoRTS e o HaRTS não apresentarão vantagens sobre o SoRTS.
Em ambos sistemas, o processador executa as mesmas funcionalidades e, sendo assim, um não deveria apresentar vantagens sobre o outro.
No entanto, no Co-SoRTS, o protocolo de comunicação entre os dois processadores é mais complexo que no HaRTS, gerando uma sobrecarga de comunicação maior.
Portanto, quanto maior o tempo gasto com trocas de contexto, maior é o número de trocas de contexto, e maior é a sobrecarga gerada por a comunicação, a qual é maior no Co-SoRTS.
Conclui- se, então, que em termos de o número de trocas de contexto, o HaRTS apresenta vantagem sobre o Co-SoRTS.
De posse dos números apresentados na Tabela 6, foi traçado o gráfico ilustrado na Figura 38 para o sistema SoRTS.
As curvas ilustram a variação do número de falhas, relacionando o intervalo entre as trocas de contexto, representado através do nome da curva, e seu tempo de execução (eixo horizontal).
Através do gráfico da Figura 38, é possível observar que o número de falhas (eixo vertical) aumenta conforme o intervalo entre as trocas de contexto e o tempo destas aumenta.
Isso acontece devido a o fato do processador gastar muito tempo realizando trocas de contexto, diminuindo o tempo disponível para a execução das tarefas, fazendo com que mais trocas de contexto sejam necessárias para finalizar a execução das tarefas do sistema, o que acaba prejudicando o atendimento do deadline das mesmas.
Se os benchmarks considerassem variações apenas no intervalo entre as trocas de contexto, quanto maior fosse esse intervalo, menor ou, pelo menos, igual seria o número de falhas ocorridas no sistema.
Esse efeito seria observado, pois o sistema disponibilizaria um tempo maior entre as trocas de contexto, permitindo que as tarefas obtivessem o controle do processador por mais tempo, possibilitando a execução de uma parcela maior das mesmas antes de um novo escalonamento.
Este fato faria com que mais tarefas fossem finalizadas em menos tempo, diminuindo o número de falhas.
No entanto, como o tempo das trocas de contexto também é variado, ao aumentar esse tempo, o processador não consegue atender o deadline de todas as tarefas, aumentando o número de falhas.
O gráfico ilustrado na Figura 39 mostra o comportamento do número de falhas ocorridas no sistema Co-SoRTS.
As curvas relacionam o número de falhas de tarefas ocorridas no sistema (eixo vertical) e seu tempo de execução (eixo horizontal).
Para o estudo de caso apresentado neste trabalho, o sistema Co-SoRTS não apresentou falhas.
No entanto, para um estudo de caso diferente (conjunto de tarefas diferente, por exemplo) é provável que ocorram falhas a partir de algum ponto e, nestes casos, quanto maior o tempo gasto em cada troca de contexto, mais trocas de contexto são necessárias para finalizar a execução de uma tarefa.
Isto torna menor o tempo disponível para executar as tarefas, prejudicando o atendimento do deadline de algumas de elas e, conseqüentemente, tendendo a aumentar o número de falhas no sistema.
O gráfico ilustrado na Figura 40 mostra o comportamento do número de falhas ocorridas no sistema HaRTS.
A curva traçada representa o relacionamento entre o número de falhas (eixo vertical) e o tempo das trocas de contexto (eixo horizontal).
Para este sistema, o estudo de caso empregado também não apresentou falhas.
No entanto, assim como no Co-SoRTS, existe uma tendência de que em algum ponto este comece a apresentar falhas e, nestes casos, conforme o tempo das trocas de contexto aumenta, o número de falhas também tende a aumentar.
A seguir é ilustrada uma comparação relativa ao número de falhas ocorridas nos três sistemas.
Essa comparação é apresentada no gráfico da Figura 41, cujas curvas ilustram o número de falhas para o SoRTS, o Co-SoRTS e o HaRTS.
Contudo, é importante ressaltar que, para casos onde o intervalo entre trocas de contexto estiver na ordem de 10000 µs, por exemplo, o número das falhas ocorridas no sistema SoRTS tende a diminuir, aproximando- se dos valores encontrados para os demais sistemas, podendo ser até menor.
Em este caso, o SoRTS apresentaria vantagem sobre o Co-SoRTS e o HaRTS, visto que, por ser implementado em software e empregar uma arquitetura monoprocessadora, a complexidade de sua implementação é menor que as demais.
Apesar de os sistemas particionados não apresentarem falhas, num estudo de caso onde ocorram falhas nas tarefas destes, o HaRTS tende a apresentar um número menor de falhas em relação a o Co-SoRTS a partir de um ponto específico, devido a a complexidade de seu protocolo de comunicação.
Isto, conseqüentemente, torna o HaRTS mais vantajoso.
Em casos onde o Co-SoRTS apresenta menos falhas, este apresenta uma solução mais vantajosa, visto que a complexidade de sua implementação em software é menor que a do HaRTS.
Conclui- se, então, que para o estudo de caso apresentado neste trabalho, o Co-SoRTS apresenta a melhor solução, entre os três sistemas, em relação a o número de falhas.
A última comparação realizada neste estudo de caso consiste no tempo de CPU utilizado na execução de tarefas em cada um dos sistemas.
Após 10 segundos de execução dos três sistemas implementados para cada um dos benchmarks ilustrados na Tabela 3, foram obtidos valores referentes aos tempos gastos efetivamente com execução de tarefas, os quais são mostrados na Tabela 7, no gráfico da Figura 43 e no gráfico da Figura 44 para o SoRTS, o Co-SoRTS e o HaRTS, respectivamente.
A partir de os valores encontrados, foram traçados gráficos que ilustram o comportamento de cada sistema de acordo com o benchmark empregado.
A partir de os números apresentados na Tabela 7, foi traçado o gráfico ilustrado na Figura 42 para o sistema SoRTS.
As curvas ilustram a variação do tempo de ocupação da CPU com execução de tarefas, relacionando o intervalo entre as trocas de contexto, representado através do nome da curva, e seu tempo de execução (eixo horizontal).
O tempo gasto efetivamente com a execução de tarefas está diretamente relacionado ao número de trocas de contexto e falhas do sistema.
Figura 42 ­ Tempo de CPU utilizado na execução das tarefas para o sistema SoRTS após 10 segundos de execução.
A curva 100 us apresenta uma particularidade, mostrando uma utilização de CPU com execução de tarefas igual a zero.
Para esta curva, as tarefas apresentam falhas até mesmo para o primeiro benchmark, tornando o sistema incapaz de executar qualquer tarefa, fazendo com que todas apresentem o número máximo de falhas para o tempo de 10 segundos de execução.
Em estes casos, o sistema fica ocupado realizando apenas trocas de contexto e escalonamentos, não sendo capaz de executar suas tarefas uma única vez.
O gráfico ilustrado na Figura 43 mostra a utilização da CPU para o sistema Co-SoRTS.
As curvas relacionam o tempo de utilização da CPU ocupado efetivamente com execução de tarefas (eixo vertical) e o tempo de execução das trocas de contexto (eixo horizontal).
Para o estudo de caso apresentado neste trabalho, a utilização da CPU mantém- se constante, o que tende a ser diferente em casos onde este sistema apresente falhas.
Em estes casos, a partir de o ponto onde as tarefas começam a apresentar um número considerável de falhas, a utilização da CPU tende a decair, diminuindo conforme as falhas aumentam.
A seguir é ilustrada uma comparação relativa ao tempo de ocupação da CPU com execução de tarefas entre o SoRTS, o Co-SoRTS e o HaRTS.
Essa comparação é apresentada no gráfico da Figura 45, cujas curvas representam o tempo da CPU ocupado, efetivamente, com execução de tarefas para os três sistemas.
Através do gráfico (Figura 45) observa- se que o Co-SoRTS e o HaRTS mantêm a CPU ocupada durante um tempo maior em relação a o SoRTS, pois neste último o número de falhas é alto comparado aos demais sistemas, diminuindo o número de vezes que as tarefas são executadas, devido a o tempo gasto com trocas de contexto.
Logo, quanto maior o número de trocas de contexto, menor será o tempo de CPU gasto com execução de tarefas.
Conclui- se, então, que o Co-SoRTS e o HaRTS apresentam vantagem sobre o SoRTS.
Conforme mencionado anteriormente, para casos onde o intervalo entre trocas de contexto for muito grande, na ordem de 10000 µs, por exemplo, o número de falhas ocorridas no sistema SoRTS tende a diminuir, assim como o número trocas de contexto, aproximando- se dos valores encontrados para os demais sistemas.
Em este caso, o SoRTS tende a ocupar mais tempo de CPU com execução de tarefas em relação a os outros dois sistemas e, portanto, apresentaria vantagem sobre o Co-SoRTS e o HaRTS.
Apesar de os sistemas particionados apresentarem a mesma utilização de CPU com execução de tarefas, num estudo de caso onde ocorram falhas nas tarefas, o HaRTS tende a gastar mais tempo de CPU executando tarefas em relação a o Co-SoRTS, a partir de o ponto onde as falhas começam a ser observadas.
Isto, conseqüentemente, torna o HaRTS mais vantajoso.
Nos demais casos, incluindo o estudo de caso apresentado neste trabalho, o Co-SoRTS apresenta uma solução mais vantajosa, visto que a complexidade de sua implementação é menor que a do HaRTS.
A partir de as comparações realizadas entre o SoRTS, o Co-SoRTS e o HaRTS, verificou- se que a escolha de qual sistema atenderá melhor os requisitos da aplicação depende de alguns fa- tores.
O primeiro de eles consiste no conjunto de tarefas utilizado, ou seja, depende do deadline e do tempo de execução de cada tarefa.
Para o algoritmo RM, por exemplo, tarefas com períodos/ deadlines maiores, tem menor prioridade em relação a as outras e, dependendo do tempo de execução das demais tarefas, sua execução fica prejudicada gerando falhas no sistema.
Além disso, o intervalo entre as trocas de contexto e o tempo gasto com as mesmas também devem ser considerados na escolha do tipo de sistema a ser utilizado.
Através do estudo de caso, verificou- se que quanto maior o intervalo, menor o número de trocas de contexto, o que disponibiliza um tempo maior para a execução das tarefas entre dois escalonamentos e, conseqüentemente, diminui o número de falhas.
Em este caso, intervalos de tempo muito grandes oferecem vantagem ao SoRTS em relação a os demais sistemas, visto que o número de falhas fica próximo ou igual ao do Co-SoRTS e do HaRTS, os quais apresentam uma implementação mais complexa, além de consumirem mais área do FPGA.
Nos demais casos, o HaRTS e o Co-SoRTS apresentam menor número de falhas, apresentando maior vantagem sobre o SoRTS.
O número de trocas de contexto é um fator determinante do número de vezes que as tarefas falham, bem como do tempo que a CPU se mantém ocupada com execução de tarefas.
Quanto maior o tempo de cada troca de contexto, maior é a chance de ocorrerem falhas no sistema e, conseqüentemente, menor é o tempo de CPU gasto com execução de tarefas visto que, conforme o número de falhas aumenta, o número de execuções das tarefas que falharam diminui.
Em o SoRTS são realizados escalonamentos respeitando o intervalo pré-definido entre trocas de contexto.
Contudo, alguns escalonamentos retornam a mesma tarefa que já estava sendo executada, aumentando o número de trocas de contexto com chaveamentos desnecessários, o que faz com que os sistemas Co-SoRTS e HaRTS sejam mais vantajosos em relação a o SoRTS.
Ainda, em casos onde o tempo das trocas de contexto é muito grande, é mais vantajoso utilizar o HaRTS, pois este tende a apresentar menos falhas que o Co-SoRTS, devido a o fato de que este último apresenta um protocolo de comunicação mais complexo, gastando mais tempo na comunicação entre os dois processadores.
O presente trabalho apresentou três implementações de modelos de RTOSs distintas:
SoRTS, Co-SoRTS e HaRTS.
O sistema SoRTS implementa um RTOS simplificado (escalonador e gerenciamento das listas de tarefas) totalmente em software, o qual executa sobre um único processador, realizando escalonamentos num intervalo de tempo pré-definido.
O sistema Co-SoRTS implementa um RTOS idêntico ao SoRTS, exceto por o fato deste ser particionado.
Em este sistema, as tarefas e as trocas de contexto são executadas sobre um processador, e as demais funcionalidades (escalonador e gerenciamento das listas de tarefas) executam sobre um processador dedicado (co-processador).
Assim como o Co-SoRTS, o HaRTS também implementa um RTOS particionado.
No entanto, as funcionalidades que executam sobre o co-processador no Co-SoRTS, foram migradas para hardware.
Foram realizadas comparações entre os três sistemas implementados, a fim de obter resultados referentes aos casos onde a complexidade das implementações em hardware compensam as implementações em software, em função de a sobrecarga do processador com a realização de trocas de contexto e do número de falhas (ocasionadas por o não atendimento de deadlines).
A partir de estas comparações, conclui- se que a escolha de qual sistema atenderá melhor os requisitos da aplicação depende do conjunto de tarefas utilizado, do intervalo entre as trocas de contexto e do tempo gasto com as mesmas.
Tarefas com períodos/ deadlines maiores, tem menor prioridade em relação a as outras e, dependendo do tempo de execução das demais tarefas, sua execução fica prejudicada gerando falhas no sistema.
Em relação a o intervalo entre as trocas de contexto, quanto maior esse intervalo, menor o número de trocas de contexto, disponibilizando um tempo maior para a execução das tarefas entre dois escalonamentos e, conseqüentemente, diminuindo o número de falhas.
Portanto, intervalos de tempo muito grandes oferecem vantagem ao SoRTS em relação a os demais sistemas, visto que o número de falhas fica próximo ou igual ao do Co-SoRTS e do HaRTS, os quais apresentam uma implementação mais complexa.
Em relação a o tempo gasto em cada troca de contexto, quanto maior esse tempo, maior é a chance de ocorrerem falhas no sistema.
Quanto maior o número de falhas, menor é o tempo de CPU utilizado com execução de tarefas, visto que à medida que as tarefas apresentam falhas, estas não executam tanto quanto antes.
Conforme mencionado anteriormente, no SoRTS são realizados escalonamentos respeitando o intervalo pré-definido entre trocas de contexto, e alguns escalonamentos retornam a mesma tarefa que já estava sendo executada, o que gera chaveamentos desnecessários, fazendo com que os sistemas Co-SoRTS e HaRTS sejam mais vantajosos em relação a o SoRTS, devido a o fato de que estes não realizam trocas de contexto desnecessárias.
Ainda, em casos onde o tempo das trocas de contexto é grande, é mais vantajoso utilizar o HaRTS, pois este tende a apresentar menos falhas que o Co-SoRTS, devido a o fato de que este último apresenta um protocolo de comunicação mais complexo, gastando mais tempo na comunicação entre os dois processadores.
Conforme observado nos diagramas de blocos dos sistemas SoRTS, Co-SoRTS e HaRTS, o presente trabalho foi desenvolvido para arquiteturas monoprocessadoras e, portanto, propõe- se, como trabalho futuro, a extensão deste para arquiteturas MPSoC.
Atualmente o sistema utiliza como infra-estrutura de comunicação um barramento, mas futuramente pretende-se migrar para a utilização de uma NoC, a fim de alcançar um melhor desempenho.
De os sistemas implementados, o HaRTS implementa duas políticas de escalonamento.
No entanto, a política EDF não foi prototipada, propondo- se essa atividade como trabalho futuro.
Além disso, para obter resultados comparativos entre os demais sistemas e o HaRTS, propõe- se a futura implementação dessa política no SoRTS e no Co-SoRTS.
Outro trabalho futuro consiste na eliminação/ diminuição da limitação de memória, propondose a utilização de uma memória externa, com mais espaço disponível, a fim de possibilitar a utilização de um número maior de tarefas e permitir a execução dos sistemas por um tempo maior.
No entanto, para realizar essa atividade, é necessária a utilização de um sistema operacional real, que tenha suporte a gerenciamento de memória para controlar eficazmente as transações envolvendo essa memória.
Logo, propõe- se, ainda, a implementação e utilização de um sistema operacional real, bem como de aplicações reais.
Assim, além de permitir o gerenciamento de memória, a interdependência entre tarefas, etc., será possível ter dados reais de execução das tarefas, sem a necessidade de estimativas de tempo de execução, o que tornará os experimentos mais robustos.
