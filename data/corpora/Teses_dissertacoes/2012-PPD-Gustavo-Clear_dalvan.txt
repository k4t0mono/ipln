Este trabalho propôs uma Linguagem Específica de Domínio de Programação Paralela Orientada a Padrões Paralelos (Led-PPOPP).
O principal objetivo é reduzir o esforço e induzir o programador a desenvolver algoritmos paralelos guiando- se através de padrões que são implementados por a interface da linguagem, evitando que ocorram grandes perdas de desempenho nas aplicações.
Anteriormente estudados, os padrões são soluções especializadas e utilizadas para resolver um problema frequente.
Assim, padrões paralelos são descritos num alto nível de abstração para organizar os algoritmos na exploração do paralelismo, podendo ser facilmente interpretados por programadores inexperientes e engenheiros de software.
Como ponto de partida, este trabalho realizou um estudo de caso baseandose no padrão Mestre/ Escravo, focando na paralelização de algoritmos para arquiteturas multi-core.
Através de experimentos para medição de esforço e desempenho, a implementação de estudo de caso foi avaliada obtendo bons resultados.
Os resultados obtidos mostram que houve uma redução no esforço de programação paralela em relação a utilização da biblioteca Pthreads.
Já com relação a o desempenho final das aplicações paralelizadas, foi possível comprovar que a paralelização com Led-PPOPP não acarreta perdas significativas com relação a paralelizações com OpenMP na quase totalidade das aplicações testadas.
Palavras-chave: Programação Paralela Orientada a Padrões Paralelos, Programação Paralela, Linguagem Específica de Domínio.
A indústria de processadores tem aumentado a capacidade computacional em ambientes de (Multiprocessor System-on-Chip).
A maioria de elas, são encontradas nos principais equipamentos ou plataformas computacionais atuais.
Estações de trabalho, servidores, supercomputadores, ou até mesmo sistemas embarcados fazem parte desta exploração de paralelismo para prover maior desempenho em suas respectivas plataformas.
Interfaces de programação paralela estão disponíveis por meio de Bibliotecas e Frameworks, possibilitando uma abstração otimizada de parte dos detalhes que envolvem a exploração de paralelismo.
No entanto, é necessário que o programador entenda da arquitetura alvo para que sejam possíveis maiores níveis de escalabilidade e eficiência.
Igualmente, os ambientes arquiteturais estabelecem diferentes formas e abordagens, desde o controle de acesso a dados, para o nível de memória compartilhada, até a comunicação entre processos, para o nível de memória distribuída.
Normalmente, o paralelismo direciona o programador a usar mecanismos de programação mais complexos e com pouca portabilidade.
Em o contexto multi-core é necessário considerar fatores como:
Metodologias de programação paralela têm sido criadas para facilitar o entendimento e relatar as experiências de programadores na paralelização de algoritmos.
Assim como, também descrevem os padrões paralelos num alto nível, servindo de suporte para estruturar computações de maneira a obter vantagem das arquiteturas.
Isso tende a direcionar o programador a usar soluções especializadas usadas anteriormente na exploração de paralelismo, evitando erros e proporcionando aplicações de alto desempenho.
Motivação Atualmente, em ambientes multitarefa, o Sistema Operacional (SO) é responsável por escalonar os processos nas unidades de processamento, beneficiando- se apenas através da execução paralela ou concorrente das aplicações, pois o código fonte é sequencial.
Em os últimos anos, é notório o aumento da disponibilidade de computadores com alto poder computacional, mas somente uma pequena porcentagem das aplicações que executam em ambientes multi-core consegue obter vantagem do paralelismo disponível,.
Percebe- se que a programação paralela ainda não está tão popular quanto as arquiteturas multicore.
As interfaces de programação paralela ainda não são um atrativo aos programadores, pois exigem um certo esforço no desenvolvimento de softwares e na aprendizagem,.
Portanto, é de suma importância a disponibilidade de soluções que sejam facilmente entendidas entre engenheiros de software e programadores inexperientes, fornecendo:
Uma interface intuitiva, uma garantia de bom desempenho e uma maneira otimizada de explorar o paralelismo disponível.
Este tipo de solução pode ser uma Linguagem Específica de Domínio de programação paralela orientado a padrões, cujo o objetivo é fornecer uma interface de programação que implementa os detalhes que envolvem a exploração de paralelismo da arquitetura alvo (i.
e, sincronização, modelagem e acesso aos dados) e prover aplicações com alto desempenho.
Com isso, a realização deste trabalho torna- se um atrativo para a comunidade científica e aos desenvolvedores de software, pois poderão focar na resolução do problema e reduzir seus esforços para melhor aproveitar os recursos das arquiteturas.
Objetivos O objetivo geral deste trabalho é a proposta, implementação e validação de uma Linguagem Específica de Domínio de programação paralela orientada a padrões paralelos, realizando um estudo de caso com o padrão Mestre/ Escravo em arquiteturas multi-core para reduzir o esforço no desenvolvimento de software paralelo sem comprometer o desempenho das aplicações.
Motivado por o objetivo geral deste trabalho, foram definidos os seguintes objetivos específicos:·
estudar os padrões no contexto de programação paralela;·
estudar as interfaces de programação, principalmente, Linguagens Específicas de Domínio;·
propor uma abordagem de programação paralela para implementar uma Linguagem Específica de Domínio;·
escolher um padrão paralelo para realizar um estudo de caso;·
estudar uma metodologia para avaliação dos resultados e elaborar um planejamento para realizar os experimentos;·
construir a Linguagem Específica de Domínio para programação paralela:
­ criar uma interface para a linguagem;·
realizar experimentos para medir o esforço de programação;·
realizar experimentos para medir o desempenho;·
avaliar os resultados utilizando a metodologia estudada.
O presente trabalho busca resolver as duas seguintes questões de pesquisa:
Hipóteses Informais Este estudo foi motivado com auxilio de hipóteses, as quais foram testadas com a finalidade de aceitar ou rejeitar.
Para isso, formulou- se duas hipóteses neste trabalho.
A tem como objetivo contribuir na resolução da primeira questão de pesquisa e a (HP2) está associada com a segunda questão de pesquisa:·
Para o desenvolvimento de aplicações paralelas é necessário um esforço de programação.
Sugere- se que o esforço de programação utilizando a interface proposta seja menor do que utilizando uma existente.· (
HP2) Em a exploração de paralelismo é importante que as aplicações obtenham desempenho nas arquiteturas paralelas.
Sugere- se que a abordagem proposta não possua uma diferença significativa de desempenho em relação a o uso de uma das abordagens para exploração de paralelismo otimizada.
Etapas da Pesquisa Uma boa pesquisa sempre é acompanhada de um plano bem elaborado.
Para este, foram formuladas 4 etapas (estudo, planejamento, desenvolvimento e avaliação) e representadas no desenho de pesquisa ilustrado na Figura 1.1.
A Etapa-1 teve como objetivo realizar um estudo exploratório.
Em ela foram estudadas as principais interfaces de programação (Capítulo 3) e os padrões usados na programação paralela (Capítulo 2), analisando qualitativamente as suas características e benefícios.
Além disso, estudou- se alguns trabalhos que se correlacionam com o tema de pesquisa proposto a fim de identificar as contribuições deste trabalho em relação a os existentes atualmente (apresentado no Capítulo 4).
Para a Etapa-2 um planejamento de construção e avaliação foi prevista.
Muito mais do que um planejamento, realizou- se um estudo para conhecer as metodologias de avaliação e validação das interfaces de programação.
Isso possibilitou o desenvolvimento do plano de execução da metodologia escolhida, que foi conduzida através de experimentos.
O outro estudo concentrou- se na elaboração de um conceito para desenvolvimento de algoritmos paralelos com intuito de ser implantado na Linguagem Específica de Domínio de Programação Paralela Orientada a Padrões Paralelos (Led-PPOPP), que posteriormente possibilitou projetar a construção de ela.
Em a Etapa-3, concentrou- se a maioria dos esforços para o desenvolvimento desta pesquisa.
Primeiramente, escolheu- se um padrão dos que foram estudos para realizar uma breve implementação com a abordagem PPOPP e OpenMP, apresentada no SA (Seminário de Andamento) conforme está protocolado no sistema de avaliação da dissertação.
Com estes resultados preliminares conseguiu- se demonstrar que o padrão Mestre/ Escravo implementado em memória compartilhada pode fornecer aplicações com bom desempenho e similar em relação a utilização do OpenMP.
Então, o próximo passo foi a construção da Led-PPOPP (Capítulo 5).
Em este processo, foi criada uma interface de programação (Seção 5.2) e um compilador (Seção 5.4) para a linguagem, tarefa esta, que exigiu um estudo aprofundado de DSL, Pthread, implementação de compiladores, linguagem C e do padrão Mestre/ Escravo.
Concluindo a pesquisa, a Etapa-4 tratou da avaliação qualitativa e quantitativa dos resultados.
Além de analisar os resultados (Capítulo 7), esta etapa também contempla a execução dos experimentos controlados e da medição de desempenho.
Em os experimentos controlados foram realizadas a seleção de indivíduos e a aplicação de questionários para a formação de dois grupos, em os quais, para cada um de eles avaliou- se o tempo necessário para o desenvolvimento de uma aplicação com o auxílio de um formulário contendo informações dos resultados obtidos.
No entanto, a medição do desempenho das duas abordagens houve apenas a intervenção do pesquisador, sendo este, o responsável por paralelizar cinco aplicações diferentes usando a Led-PPOPP e comparar- las com as mesmas aplicações paralelizadas utilizando outra abordagem, porém, desenvolvidas por outro profissional da área.
Organização do Trabalho Após a introdução da pesquisa realizada, o Capítulo 2 deste trabalho apresentará o embasamento teórico sobre programação paralela com padrões paralelos, realizando um estudo sobre padrões de projeto, metodologia de programação paralela e os principais padrões paralelos.
Assim como, o código.
Em a sequência, o Capítulo 4 faz um apanhado geral do estado da arte referente as interfaces de programação disponíveis no contexto de arquiteturas multi-core, relacionando- as com a proposta deste trabalho.
A implementação de estudo de caso da Linguagem Específica de Domínio de programação paralela orientada a padrões paralelos proposta é descrita no Capítulo 5, detalhando a abordagem e a interface de programação usando o padrão Mestre/ Escravo.
A seguir, o Capítulo 6 apresenta o planejamento e a execução dos experimentos para medição do esforço de programação paralela e a medição do desempenho obtido na exploração de paralelismo em algumas aplicações de teste.
Finalizando o estudo experimental, o Capítulo 7 descreve os resultados obtidos para os experimentos realizados.
Padrão de projeto é uma solução genérica para resolver problemas encontrados frequentemente na computação num domínio específico.
Foi inicialmente introduzido na Engenharia de Software no cenário de programação orientada a objetos.
Uma das necessidades era estruturar classes em estruturas de dados heterogêneas.
Esta descrição em alto nível possibilita que soluções inteligentes sejam utilizadas por outros desenvolvedores de software,.
Partindo desta premissa de reutilização de soluções inteligentes, metodologias de programação paralela foram propostas no contexto de exploração do paralelismo.
Esta metodologia está dividida em quatro espaços de projeto (Procura da Concorrência, Estrutura de Algoritmo, Estrutura de Apoio e Mecanismos de Implementação) a fim de tornar mais fácil o entendimento do problema a ser resolvido.
Portanto, guiando- se através de uma metodologia de programação paralela é possível obter uma avaliação qualitativa de diferentes padrões paralelos,.
Padrões paralelos definem a estrutura de um programa paralelo num nível mais alto de abstração.
Em o cenário atual, eles são utilizados para modelar algoritmos, cuja a finalidade é de explorar o paralelismo disponível das arquiteturas paralelas.
A abordagem de paralelismo é implementada por meio de padrões que exploram a decomposição de dados e tarefas.
Para tanto, a definição genérica permite que os padrões paralelos sejam implementados num vasto conjunto de aplicações, Padrões de Projeto Segundo, cada padrão é responsável por implementar um problema que precisa ser resolvido frequentemente num determinado ambiente.
Basicamente, o padrão descreve o núcleo de uma solução para este problema, de modo que esta solução possa ser usada várias vezes sem precisar fazer a mesma coisa.
Isso é comum na engenharia de software, onde os problemas frequentes são formalmente documentados e se tornam um padrão para outros que necessitam trabalhar com algo semelhante.
Assim, os desenvolvedores podem basear- se no padrão criado e poupar os esforços para resolver este problema, focando- se apenas em desenvolver a aplicação final.
Com o passar dos anos, a criação de padrões tem sido comum na área de engenharia de software.
Igualmente, outras áreas passaram a investir neste contexto para facilitar e direcionar o desenvolvedor para melhores práticas de programação.
Entretanto, os padrões operam da mesma forma nas diferentes áreas, possuindo um único objetivo, fornecer uma solução para um problema num determinado contexto.
Logo, os padrões devem possuir quatro elementos:·
Nome do Padrão:
O nome do padrão tem por objetivo aumentar o vocabulário do projeto que descreve um problema, suas soluções e consequências numa ou duas palavras.
O nome deve ser bom a fim de facilitar o entendimento do desenvolvedor sobre o comportamento do padrão e como ele é implementado.·
Problema: Usado para descrever quando o padrão é aplicado, explicando o problema e qual é o seu contexto.
As vezes, o problema pode conter uma lista de condições que devem ser realizadas antes de poder aplicar o padrão.·
Solução: Descreve os elementos que compõem o projeto, os relacionamentos, responsabilidades e colaborações.
A solução não descreve um projeto ou uma implementação concreta, pois os padrões são como um template que pode ser aplicado em várias situações diferentes.
Basicamente, a solução do padrão descreve como um problema de projeto é resolvido.·
Consequência: Diz respeito aos resultados de quando o padrão é aplicado.
As consequências do padrão não são tão claras para o projeto de decisão, mesmo assim, são importantes para a avaliação de projeto e para o entendimento dos custos e benefícios na utilização do padrão.
Embora existam algumas variações na definição do conceito de padrões de projeto, é importante adotar uma caracterização clara dos quatro elementos descritos anteriormente obtendo assim uma definição formal utilizável por programadores de diferentes áreas.
Assim, os padrões de projeto (Design Patterns) podem fornecer soluções inteligentes com um alto nível de abstração e guiar os programadores no seu projeto de software.
Metodologia para Programação Paralela Padrões de programação apareceram com o surgimento das primeiras linguagens de programação no fim da década de 60/ início da década de 70.
Os padrões sequenciais são tradicionalmente divididos em dois grupos:
Padrões de controle de fluxo e padrões de gerenciamento de dados.
De entre os padrões de controle de fluxo, destacam- se:
Sequência, seleção, iteração e recursão.
Os padrões de gerenciamento de dados mais usados são:
Leitura de acessos aleatório, alocação de pilha e alocação dinâmica de memória.
Em o contexto de programação paralela, os padrões são descritos ou implementados a partir de uma metodologia.
A metodologia ajuda a explorar várias abordagens para a computação, levando à solução de problemas frequentemente encontrados no desenvolvimento de programas paralelos.
Enfim, auxilia os programadores em seus projetos de software, realizando a paralelização a partir de soluções especializadas na exploração de paralelismo através dos quatro espaços de projeto:
Procura da concorrência, estrutura de algoritmo, estrutura de apoio e mecanismos de implementação.
O desenvolvimento de algoritmos paralelos não é uma tarefa simples e fácil,.
Antes de modelar um algoritmo paralelo, o levantamento da aplicação se faz necessário para identificar o problema a ser resolvido.
Em a sequência, se paralelizar for vantajoso, estuda- se quais padrões paralelos podem ser implementados na aplicação.
Então, o primeiro passo no projeto de algoritmos paralelos é a procura da concorrência numa determinada computação.
A representação deste espaço de projeto está ilustrado na Figura 2.1, onde os padrões estão classificados em três grupos.
O grupo de decomposição tem por objetivo decompor um problema em pequenos fragmentos para que possam ser executados em paralelo ou concorrentemente.
A análise de dependência opera entre si e possivelmente pode revisar a decomposição para encontrar as dependências de uma computação.
E, o grupo de avaliação de projeto direcionam o projeto de algoritmo para uma avaliação (testando qual é a melhor solução a ser aplicada), antes de encaminhar para o próximo espaço de projeto.
Decomposição de Tarefas Em a decomposição de tarefas, o problema é visto como um fluxo de instruções que podem ser quebrados em tarefas que são executadas concorrentemente.
O programador deverá identificar quais são os pontos (que geram tarefas) a serem paralelizados no algoritmo, levando em conta os seguintes aspectos:·
Flexibilidade: Permitir que o número e o tamanho de tarefas possam ser parametrizados para diferentes números de processadores;·
Eficiência: Garantir que não ocorram problemas como, overhead (sobrecarga de trabalho) por o gerenciamento de dependência das tarefas e que o número de tarefas não seja maior que o número de unidades de processamento;·
Simplicidade: Tornar possível a depuração e a manutenção o mais simples possível.
A decomposição de tarefas pode ser usada em aplicações como:
Imagem médica;
Multiplicação de matrizes e dinâmica molecular.
Decomposição de Dados A decomposição de dados foca- se nos dados exigidos por as tarefas e como podem ser decompostos em pedaços separados.
Isso só é eficiente se os pedaços de dados podem operar independentemente.
Algoritmos de decomposição de dados fazem o uso eficiente da memória e (em ambientes com memória distribuída) usam menor largura de banda.
Mas, ocorre maior sobrecarga de comunicação durante a execução de partes concorrentes, sendo também mais complexa a sua decomposição.
Máquinas com arquitetura Em uma (Em o Uniform Memory Access) se mostram vantajosas utilizando esta decomposição de dados.
Em o projeto de algoritmos paralelos, o primeiro passo utilizando esta decomposição é identificar as estruturas de dados definidas por o problema e verificar o que pode ser quebrado em segmentos.
Um exemplo prático para este cenário é a computação baseada em vetores (quebrar em segmentos) e estrutura de dados recursiva (decompor em sub-árvores).
Os seguintes aspectos devem ser fortemente considerados ao utilizar este padrão:·
Flexibilidade: O tamanho e a quantidade dos segmentos de dados devem ser flexíveis a fim de suportar um sistema paralelo amplo, onde a partir de a parametrização define- se a granularidade, podendo variar conforme o hardware utilizado;·
Eficiência: A decomposição torna- se eficiente quando a quantidade de pedaços não causa a sobrecarga no gerenciamento de dependência.
Para tanto, um algoritmo paralelo deve balancear a carga entre as threads ou processos;·
Simplicidade: Decompor dados é complexo, o que torna a depuração difícil.
Esta decomposição geralmente requer um mapeamento global dentro de uma tarefa local, beneficiando- se deste mapeamento abstrato para isolar e testar.
Aplicações como, imagens médicas, multiplicação de matrizes e dinâmica molecular, utilizam frequentemente a decomposição de dado, pois é possível atingir uma granularidade mais fina se comparado com a decomposição de tarefas.
Grupo de Tarefas As abordagens de decomposição de dados e de tarefas são correspondentes ao grupo de tarefa, que descreve a primeira etapa na análise de dependências.
Em um cenário de aplicação é possível dividir- la em vários problemas, para cada um, uma tarefa é usada para resolver- lo.
Por outro lado, é possível criar grupos de tarefas que são agrupados correspondentes a seus devidos problemas.
Isso se torna um benefício na análise de dependência das tarefas, pois o controle passa a ser realizado nos grupos (quando um grupo termina o outro grupo pode começar a ler).
Todavia, se um grupo de tarefas trabalha juntamente a uma estrutura de dados compartilhado, necessita- se de sincronização em todo grupo.
Quando existem restrições entre as tarefas podem ocorrer casos como:
Dependência temporal;
Coleção de tarefas executando ao mesmo tempo e tarefas que podem ser independentes umas das outras dentro de o grupo.
Para identificar as restrições e grupos de tarefas, deve- se olhar primeiramente como o problema original foi decomposto.
Em seguida, verificar se outro grupo compartilha a mesma restrição, identificando as restrições entre os grupos de tarefas.
Ordenação de Tarefas A ordenação de tarefas consiste na segunda etapa de análise de dependências, cujo o objetivo é identificar como os grupos de tarefas podem ser ordenados para atender as restrições entre as tarefas.
Assim como, a ordenação deve ser restrita o suficiente para satisfazer todos os requisitos que resultam num projeto correto.
Em este sentido, a ordenação não deve ser mais restrita que ela precisa ser.
De forma a contribuir na ordenação das restrições, é importante observar a necessidade do dado para um grupo de tarefas antes executar- lo.
Igualmente, também podem ser considerados serviços externos que promovem a ordenação de restrições e identificar quando uma ordenação não existe.
Compartilhamento de Dados Um algoritmo paralelo é composto de:
Uma coleção de tarefas que executam concorrentemente, uma decomposição de dados correspondente a uma solução de tarefas concorrentes e também sobre a dependência entre as tarefas, que devem ser gerenciadas para permitir uma execução segura.
O objetivo desta abordagem é o compartilhamento de dados entre os grupos de tarefas e determinar o acesso de dados compartilhados de maneira correta e eficiente.
Para garantir estes fatores, o algoritmo deve prever questões como:
Condição de corrida, geração de sincronização excessiva e overhead de comunicação (em sistemas distribuídos).
Comumente, os dados são compartilhados entre as tarefas (padrão de decomposição de dados), decompondo os dados em blocos e o compartilhamento de dados é realizado entre estes blocos.
Em a decomposição de tarefas se torna mais complicado, pois é necessário tratar os dados passados dentro ou fora de a tarefa e tratar quando um dado é atualizado no corpo da tarefa.
O programador é responsável por conhecer as formas de uso do compartilhamento de dados, para as quais incluise:
Somente leitura, efetivamente local (operações com matrizes), leitura e escrita, acumulação e múltipla leitura/ somente escrita.
Avaliação de Projeto A avaliação de projeto consiste na última etapa no processo de encontrar concorrência, preparando o programa para o próximo espaço de projeto.
A decomposição do problema original e a análise pode ser realizada com:
Uma decomposição de tarefas que identifica tarefas que podem executar concorrentemente;
Uma decomposição de dados que identifica o local dos dados para cada tarefa;
Uma maneira de agrupamento de tarefas e uma ordenação de grupos para satisfazer restrições temporais que analisam as dependências entre as tarefas.
Baseando- se nestes termos, esta abordagem tem por objetivo encontrar qual é a melhor decomposição do problema para produzir um projeto de ótima qualidade, avaliando três aspectos:·
Adequação para a plataforma alvo:
Para a escolha da plataforma alvo devem ser levados em consideração:
A quantidade de processadores disponíveis, como são compartilhadas as estruturas de dados entre os elementos de processamento, identificar como a arquitetura alvo implica sobre o número de threads ou processos e como as estruturas de dados são compartilhadas entre elas.
Por último, analisar o tempo gasto trabalhando numa tarefa, sendo que o tempo deve ser adequado quando estiver lidando com as dependências;·
Qualidade de projeto:
Em a qualidade de projeto, requer- se que as características da plataforma alvo sejam mantidas, avaliando as dimensões de flexibilidade, eficiência e simplicidade;·
Preparação para a próxima fase de projeto:
O projetista quando se deparar com avaliação deste aspecto deve considerar a regularidade das tarefas e suas dependências de dados, interação entre as tarefas (síncrono ou assíncrono) e se as tarefas estão agrupadas da melhor maneira.
Uma estrutura de algoritmo requer eficiência, simplicidade, portabilidade e escalabilidade.
Porém, estes termos causam conflitos, como por exemplo, eficiência com portabilidade.
Alguns programas necessitam ser escritos com características específicas, o que não torna possível a portabilidade.
A eficiência com a simplicidade também é um caso de conflito, pois geralmente aplica- se o paralelismo de tarefas, necessitando o uso de algoritmos de escalonamento complexos que dificultam o entendimento.
No entanto, um bom projeto de algoritmo deve estabelecer um equilíbrio entre abstração e portabilidade para uma determinada arquitetura.
O princípio de organização implica na concorrência, sendo assim definidos os termos de tarefas, grupos de tarefas e ordenação entre grupos de tarefas.
Para isso, no projeto de algoritmo paralelo usa- se múltiplas estruturas de algoritmos a fim de encontrar um algoritmo estruturado que representa o mapeamento da concorrência dentro de as threads ou processos.
Em consequência, este espaço de projeto é dividido em três grupos (Organização por Tarefas, Decomposição de Dados e Fluxo de Dados) de padrões representados através da Figura 2.2.
Esta separação de grupos de padrões permite uma classificação dos padrões para este espaço de projeto de algoritmos paralelos.
Portanto, o grupo de Organização por Tarefa implementa os padrões que são baseados em tarefas para exploração de paralelismo.
O grupo de Organização por Decomposição de Dados aborda os padrões que se utilizam da concorrência para resolver um problema recursivamente.
E, o grupo de Organização por Fluxo de Dados caracteriza os padrões que definem como o fluxo de dados é apresentado na ordenação em grupo de tarefas.
O espaço de projeto de estruturas de apoio descreve construções ou estruturas de software que comportam os algoritmos paralelos.
Conforme ilustra a Figura 2.3, o espaço de projeto está representado em dois grupos de padrões:
Os que representam a abordagem de estrutura dos programas e os que representam o uso de estrutura de dados.
Nada impede o uso de outro padrão para implementar uma estrutura, como por exemplo, Mestre/ Escravo utilizar Fork/ Join ou SPMD.
Isso significa que estes padrões não representam unicamente uma maneira de estruturar um programa paralelo.
Para um programador MPI (Message Passing Interface), todos os programas de padrões estruturados são derivados do padrão SPMD (Single Program Multiple Data).
Entretanto, para um programador OpenMP (Open MultiProcessor) existe uma enorme diferença entre programas que utilizam identificadores de threads (padrão SPMD) e programas que expressam a concorrência em nível de laço (padrão de paralelismo de laço).
Geralmente todos os programas que utilizam padrões estruturados enfrentam alguns problemas, tais como:·
clareza e abstração:
Refere- se a forma que o algoritmo está escrito no código fonte.
Uma abstração clara é importante para escrever um código corretamente e auxiliar na depuração;·
escalabilidade: Diz respeito a quantidade de processos que um programa paralelo pode eficientemente utilizar.
A o restringir a concorrência disponível no algoritmo, a quantidade de processadores será limitada.
De a mesma forma, o overhead pode contribuir para baixar e limitar a escalabilidade;·
eficiência: Está diretamente relacionada com o desempenho do programa em relação a o programa sequencial;·
sustentabilidade: Concentra- se na facilidade para modificar, depurar e verificar um software e em relação a sua qualidade;·
afinidade do ambiente:
Envolve a relação do programa com o ambiente de programação e com a escolha do hardware;
As próximas seções relatam os três mecanismos de implementação.
Estes, não são considerados padrões, mas fazem parte do projeto de algoritmos paralelos, referindo- se ao gerenciamento de threads ou processos, sincronização e comunicação.
Gerenciamento de Threads e Processos O processo é um objeto que carrega um contexto em algum lugar no sistema, isso inclui memória, registradores e buffers.
Em um sistema, diferentes processos pertencem a diferentes usuários.
Ao contrário, uma Thread é um novo fluxo criado a partir de um processo, podendo compartilhar o mesmo espaço de endereçamento e a comunicação entre as threads pertencer ao mesmo processo.
Processos e threads podem ser criados e destruídos.
Threads são mais simples e não exigem muito poder computacional para serem criadas.
Por outro lado, os processos são mais custosos, pois quando ele é criado, todas as informações necessárias para definir um lugar de atuação no sistema devem ser carregadas.
Interfaces de programação como OpenMP, Pthread, Java e MPI disponibilizam funções de criação de threads e processos, abstraindo grande parte da complexidade em lidar com esta abordagem de programação.
Sincronização Em o gerenciamento de threads e processos, a sincronização ocorre quando se deseja manter uma ordem na execução dos eventos.
As interfaces de programação como OpenMP, Pthread, Java e MPI implementam a sincronização em suas funções, incluindo os seguintes aspectos:·
Sincronização e barreira de memória:
Em o ambiente computacional de memória compartilhada, threads e processos podem executar uma sequência de instruções que são lidas e escritas na memória compartilhada atomicamente.
Também pode ser visto como uma sequência de eventos atômicos, os quais intercalam a partir de diferentes threads ou processos.
As barreiras de memória são usadas na sincronização para garantir que processos ou threads tenham uma visão consistente da memória.
Em o contexto de threads, um programa com várias condições de corrida possivelmente não será vantajoso;·
Barreiras: São o mais alto nível para tratar a sincronização de threads e processos.
As barreiras são usadas para garantir que um conjunto de threads ou processos não proceda antes que todos estejam num determinado ponto;·
Exclusão mútua:
O objetivo é garantir que threads ou processos não interfiram entre si, pois quando os recursos são compartilhados dois ou mais processos ou threads podem tentar atualizar um dado compartilhado, gerando conflitos e inconsistências.
O acesso a seção crítica é controlado usando exclusão mútua, onde uma thread ou processo avança e enquanto isso, os outros ficam esperando até que a seção crítica seja liberada.
Comunicação Para que a troca de informações ocorra entre as threads e processos é necessário a comunicação, que pode ser realizada usando mensagens através de uma rede ou de uma memória.
Uma mensagem pode conter dados sobre a mensagem e outras informações e, ainda, a troca pode ser realizada de duas formas:
De uma origem específica para um destino específico e múltipla troca de mensagens entre processos ou threads numa única comunicação (comunicação coletiva).
Em a comunicação coletiva estão envolvidas diferentes operações, como por exemplo, o mecanismo de broadcast, barreiras e redução.
Esta, consiste em reduzir uma coleção de itens de dados para um único item de dados, para então combinar os itens de dados com uma operação binária, associativa ou comutativa (i.
e, soma, produto, maior elemento, menor elemento, entre outras).
Este capítulo apresentou uma metodologia para programação paralela para projetar algoritmos paralelos e descrever soluções especializadas para exploração de paralelismo.
De o mesmo modo, apresentou- se uma maneira qualitativa de entender o processo que envolve o desenvolvimento de software paralelo através dos espaços de projeto.
A Figura 2.5 ilustra uma visão global da programação paralela utilizando os espaços de projeto e como ocorre a implementação destes padrões.
A exploração de paralelismo com a metodologia para programação paralela começa com o espaço de projeto Procura da Concorrência, estruturando o algoritmo para obter vantagem do potencial de paralelismo que um problema pode oferecer.
Esta primeira etapa, tem por objetivo analisar a computação encontrando possíveis tarefas, compartilhamentos e dados locais.
Logo o próximo passo é estruturar os algoritmos num modelo de processos ou threads, verificando as dependências e os dados compartilhados, para os quais a metodologia descreve as estratégias de implementação.
Com a definição das threads ou processos realizada na Estrutura de Algoritmo, os programadores podem guiar a exploração do paralelismo utilizando os padrões do espaço de projeto de Estruturas de Apoio, sendo descritas as formas para realizar a modelagem da computação anteriormente estruturada.
Contudo, os Mecanismos de Implementação preocupam- se como os padrões de alto nível são mapeados num determinado ambiente de programação.
Padrões de Programação Paralela Um padrão de programação paralela é uma solução genérica para problemas frequentemente encontrados na exploração de paralelismo,.
Igualmente, o seu objetivo é fornecer uma descrição num alto nível de abstração para estruturar a computação obtendo vantagem das arquiteturas paralelas.
Portanto, estes padrões são utilizados na organização de uma computação decomposta em dados ou tarefas, estruturando a execução de forma paralela ou concorrentemente num sistema computacional.
Programas paralelos eficientes e confiáveis podem ser projetados em torno de padrões paralelos.
Estes, enquanto melhoram a produtividade através de padrões específicos, especializados e a fusão entre eles, ao mesmo tempo podem guiar os usuários inexperientes a desenvolver algoritmos eficientes com boa escalabilidade.
Por outro lado, a metodologia de programação paralela direciona o desenvolvimento de software para melhores práticas na exploração do paralelismo.
A experiência em desenvolver programas paralelos mostrava que vários dos problemas eram frequentes.
Isso alavancou o formalismo destas práticas, criando- se padrões de programação paralela.
Mesmo que alguns autores os denominem de modelos ou estratégias de programação paralela, eles são usados com a mesma finalidade, fornecer uma descrição para estruturar programas que obtém vantagem sobre uma arquitetura paralela,.
No entanto, conforme a literatura descreve nas Seções 2.1 e 2.2, o conceito de padrão de programação paralela é mais apropriado para o formalismo de uma solução genérica no projeto de software paralelo,,.
Em as seções 2.3.1 e 2.3.2 são descritos os padrões de programação paralela comumente utilizados e aplicáveis para um vasto conjunto de aplicações.
Vários destes são introduzidos no contexto de arquitetura de memória compartilhada e distribuída.
Por exemplo, quando o padrão Mestre/ Escravo é implementado em ambiente de memória compartilhada, o mestre comunica- se com os escravos através da memória e quando se está num ambiente de memória distribuída, a comunicação é realizada com troca de mensagens.
O propósito geral destes padrões é caracterizado na metodologia de programação paralela (Seção 2.2).
Esta seção apresenta os padrões paralelos que determinam a estrutura algorítmica dos programas.
Padrão de Paralelismo de Tarefas Quando se trata de paralelismo de tarefas, ao desenvolver uma aplicação deve- se observar e analisar como as tarefas são definidas, as dependências entre elas e o escalonamento de elas.
As tarefas, na decomposição de um problema, deveriam existir pelo menos tantas quanto unidades de processamento, de preferência mais, para obter maior flexibilidade no escalonamento.
Também é importante que a computação associada com as tarefas seja larga o suficiente para equilibrar a sobrecarga com o gerenciamento e manipulação de dependências.
Um dos maiores impactos no padrão de paralelismo de tarefas é a dependência, isso envolve questões como o compartilhamento de dados e grupos de tarefas.
Em a maioria dos casos os algoritmos tornam- se mais complexos e perdem eficiência.
Para isso, ao desenvolver um programa, é importante que o programador esteja preocupado com estas questões, procurando remover dependências e separando- as se possível.
O escalonamento parte da ideia de balancear a carga entre os processadores, mantendo um equilíbrio de tarefas entre as threads ou processo.
Esta atribuição de tarefas aos processadores, pode ser realizada estaticamente (determinando no início da computação como e quanto é usado a thread ou processo, e esta se mantem até o fim) ou dinamicamente (variando a distribuição entre as threads ou processos, conforme procede a computação).
Este padrão pode ser usado para explorar o paralelismo de laços for, de preferência, dividindo as interações do laço em tarefas que executam em paralelo.
Entretanto, deve- se tomar cuidado quando existe a dependência entre as tarefas ou se existe uma grande quantidade de elas, pois isso poderá prejudicar o desempenho da aplicação.
Além disso, quando ocorre a replicação de dados entre as tarefas, é necessário um controle maior sobre eles.
Padrão de Divisão e Conquista O padrão D&amp;C (Divide and Conquer) é uma estratégia utilizada em vários algoritmos sequenciais.
Consiste em dividir o problema em subproblemas menores, resolvendo- os independentemente e fundindo todas as subsoluções numa solução para o problema.
Isso é resolvido de forma recursiva, tendo como objetivo explorar a eficiência na resolução de uma determinada computação.
Um exemplo de modelagem usando o padrão D&amp;C é apresentado na Figura 2.6.
Em este padrão, o primeiro passo é dividir o problema em subproblemas.
Em este sentido, o resultado desta modelagem será um grafo de tarefas independentes.
Depois da divisão, ocorre a conquista.
Os resultados retornados do nível abaixo são fundidos e, logo em seguida, devolvidos a um nível acima de o grafo.
Desta forma, as tarefas filhas (F) retornam o resultado para a tarefa pai (P), logo após, estas tarefas devolverão o seu problema resolvido para a raiz (R), que obterá a solução.
Padrão de Decomposição Geométrica Este padrão tem por objetivo realizar a divisão de uma região geométrica em sub regiões geométricas.
Para vetores, esta decomposição pode ser de uma ou mais dimensões, e os sub vetores resultantes são chamados de blocos e denominados de pedaços, as sub estruturas e as sub regiões.
A decomposição de dados em pedaços implica que as operações nas tarefas sejam atualizadas, onde cada tarefa representa a atualização de um pedaço e estas executam concorrentemente.
Em certos casos, alguns pontos necessitam da atualização de outros pedaços, sendo assim, a informação deve ser compartilhada entre os pedaços para completar a atualização.
A maior parte dos problemas que são resolvidos usando o padrão de decomposição geométrica são:
Soluções de equações diferenciais e álgebra linear computacional.
Estes, geralmente implementam rotinas paralelas em suas bibliotecas matemáticas.
Assim como, este padrão pode ser aliado com o padrão de decomposição de tarefas (quando a atualização para cada pedaço é realizada sem dados a partir de os pedaços) e com o D&amp;C (quando a estrutura de dados pode ser distribuída e recursiva).
Padrão de Recursão de Dados Para os problemas de lista, árvores ou grafos, o padrão de recursão de dados é uma boa opção, pois busca o explorar paralelismo decompondo processos ou threads em elementos individuais.
De a mesma maneira, o padrão de D&amp;C também opera usando recursão de dados, mas sem grande potencial de concorrência.
O objetivo deste padrão é reformular estas operações para que o programa possa operar concorrentemente em todos os elementos da estrutura de dados sem perder a forma recursiva de resolver uma computação.
Um dos principais desafios deste padrão é aplicar a mudança do algoritmo original para explorar a concorrência, isso implica que em todos os níveis da estrutura exista concorrência entre os processos.
Para isso, cada nó comunica- se com o raiz ou com o pai de ele.
O padrão de recursão de dados é semelhante ao D&amp;C, porém, acrescenta a concorrência na estrutura de dados.
Padrão Pipeline O padrão pipeline consiste de uma computação baseada em estágios, visto também como uma sequência de dados através de uma sequência de estágios.
Em a definição de estágios de um pipeline, cada processo deve conhecer a quantidade de estágios existentes.
A partir de a contagem do número de elementos, cada estágio saberá o momento de parar e se o dado já foi processado.
Este padrão assume que no pipeline existe:
Um longo fluxo de dados, que toda entrada é processada e cada estágio pode obter uma entrada diferente ao mesmo tempo.
Através da Figura 2.7, é possível observar o funcionamento e o paralelismo fornecido de um pipeline com quatro estágios.
Embora o fluxo seja contínuo e o problema é executado sequencialmente, o paralelismo é obtido através da execução de mais de um estágio.
Basicamente, cada estágio recebe uma entrada, processa e passa o resultado para o próximo estágio até concluir a computação.
Em a estruturação da computação, pode- se usar o Id (Identificador) de cada processo para escolher uma opção, onde cada caso corresponde a um estágio do pipeline (e.
g, processar o resultado).
Os estágios podem ser conectados explicitamente com canais bufferizados, implementando por exemplo, filas compartilhadas entre os que enviam e os que recebem de tarefas.
Padrão de Coordenação Baseada em Eventos Ao contrário de o padrão pipeline, a coordenação baseada em eventos não opera estritamente numa estrutura linear, não possui restrições que um fluxo de dados seja apenas de uma maneira e as iterações são irregulares com intervalos imprevisíveis.
Um exemplo disso é uma garagem de lava-carros.
Esta por sua vez, possui duas máquinas de lavar carro e uma fila de atendimento.
Cada carro poderá ficar um determinado tempo usando o recurso e se ainda a limpeza não for concluída, o carro volta para a fila de atendimento, passando novamente por a máquina de lavar carro e assim sucessivamente, até que o carro esteja limpo.
Os carros que estão na fila ganham o recurso quando a máquina não está ocupada e quando chegou a sua vez.
Para fluxos de dados usa- se eventos, onde cada evento contém uma tarefa que gera o evento e uma tarefa que processa o evento.
Isso porquê, um evento deve ser gerado antes que ele seja processado, definindo a restrição de ordenação entre as tarefas, onde a computação de cada tarefa consiste de processamento de eventos.
Assim sendo, a estrutura básica de cada tarefa consiste em o:
Recebimento de um evento, processamento de ele e possivelmente gerar- lo.
Em a representação do fluxo de evento, estão associados a comunicação e a computação de sobreposição.
De modo geral, a comunicação é assíncrona dos eventos, em a qual, uma tarefa pode criar (enviar) um evento e continuar sem esperar por um destinatário para receber um evento.
Em ambientes de memória distribuída, um evento pode ser representado por uma mensagem enviada assincronamente a partir de a tarefa, gerando o evento para a tarefa que irá processar- lo.
Já em ambientes de memória compartilhada, uma fila pode ser usada para simular a troca de mensagens, onde uma fila pode ser acessada por mais de um tarefa e deve ser implementada de forma a permitir o acesso seguro e concorrente.
Deve- se ter cuidado com problemas de deadlock, escalonamento e alocação de processo (um processo por elemento de processamento) e uma eficiente comunicação de eventos.
Os padrões paralelos de estruturas de apoio são bastante usado para modelar e organizar uma computação decomposta em threads ou processo.
Estes, são abordados no espaço de projeto de Estrutura de Apoio em a metodologia de programação paralela (Seção 2.2).
Padrão SPMD (Single Program, Multiple Data) Em programas que utilizam o padrão SPMD, os processos executam o mesmo programa, onde cada processo tem seu próprio conjunto de dados.
Isso significa que os processos podem seguir caminhos diferentes dentro de um programa.
Devido a sua versatilidade, normalmente este padrão é usado para descrever e estruturar os padrões do espaço de projeto da estrutura de algoritmos paralelos.
Mesmo assim, o padrão SPMD é melhor aplicado quando usado em casos de integração numérica e dinâmica molecular.
Este é constituído por alguns elementos básicos que compõem sua estrutura:·
inicialização;· obtenção de um único identificador;·
execução do mesmo programa em cada processo, usando o identificador único para diferenciar comportamento em diferentes processos;·
dados distribuídos;·
finalização. Padrão Mestre/Escravo O padrão Mestre/ Escarvo é uma solução baseada no paralelismo de tarefas, onde uma tarefa mestre possui instâncias de uma ou mais tarefas escravas.
Conforme o exemplo da Figura 2.8, a tarefa mestre (M) inicializa a computação dividindo- a em tarefas independentes.
Isso resultará num saco de tarefas que são enviadas aos escravos (S) para serem computadas.
A o resolverem a computação os escravos retornam o resultado para o mestre que une os resultados e processa a solução final do problema.
Soluções que possibilitam modelar a computação em tarefas independentes (e.
g, paralelismo de laço) podem apresentar bom desempenho na exploração de paralelismo com este padrão paralelo.
No entanto, para que a implementação apresente bons resultados é preciso dividir o problema adequadamente.
Em o padrão Mestre/ Escravo existe um comunicador global para resolver dependências entre as tarefas e distribuir- las.
Em alguns casos, quando a comunicação é bastante requisitada é comum acontecer uma sobrecarga de comunicação, o que afeta o desempenho do sistema.
A solução para este tipo de problema é aumentar o tamanho das tarefas escravas para diminuir o número de acessos ao saco de tarefas.
Padrão de Paralelismo de Laço O paralelismo de laço tem como propósito encontrar maneiras de explorar o paralelismo através de programas que possuem estruturas baseadas em laços, ou seja, transformar um programa serial, onde o tempo de execução é determinando por um conjunto intensivo de computações baseadas nas interações de laço, executando- as em paralelo com diferentes índices.
Segundo, é particularmente relevante usar o paralelismo de laço para programas OpenMP em computadores com memória compartilhada e problemas que operam em padrões de paralelismo de tarefas e decomposição geométrica.
A implementação deste padrão com OpenMP implica nas seguintes etapas:·
encontrar gargalos:
O programador é quem identifica os laços no código para combinar e encontrar o desempenho necessário de cada subproblema;·
eliminar dependência na interação do laço:
Consiste em eliminar operações de escrita e leitura que provocam uma sessão crítica;·
paralelizar o laço:
Dividir as iterações entre as threads ou processos;·
otimizar o escalonamento do laço:
As iterações devem ser escalonadas em threads ou processos, obtendo o balanceamento de carga;·
mesclar laços:
Um sequência de laços que possuem limites consistentes podem ser mesclados num único laço com iterações mais complexas;·
reunir laços alinhados:
Normalmente é possível reunir laços alinhados num único laço, gerando uma grande combinação de iterações.
Padrão Fork/Join O padrão Fork/ Join é baseado no conceito de processo pai e processos filhos.
Um processo pai pode criar vários processos filho dinamicamente, quando um processo terminar ele executa join e termina, os demais processos filhos continuam sua execução.
Este padrão é usado em exemplos que usam recursividade, como o padrão D&amp;C.
Com o produto da execução do programa o problema é divido em subproblemas e novas tarefas são recursivamente criadas para executar concorrentemente os subproblemas, desta maneira, cada uma destas tarefas pode se tornar um subdivisor.
Quando todas as tarefas foram criadas ao realizar uma divisão elas são finalizada e posteriormente se juntam com a tarefa pai, para então, a tarefa pai continuar a computação.
Parafraseando, o padrão fork/ join é relevante para programas Java executando em computadores com memória compartilhada e para problemas que usam padrões como D&amp;C e Recursão de Dados.
O OpenMP pode ser usado efetivamente com padrões quando o seu ambiente suporta alinhamento de regiões paralelas.
Os problemas que usam o padrão fork/ join possuem o mapeamento de tarefas em threads ou processos de duas maneiras:·
mapeamento direto de tarefa:
Em esse mapeamento existe uma tarefa por processo/ thread.
Para cada nova sub tarefa criada, novas threads/ processos são criados para manipular- las.
Em a maioria dos casos, existe um ponto de sincronização onde a tarefa principal espera por o término das sub tarefas, isto é conhecido como join;·
mapeamento indireto de tarefa:
Em este mapeamento existe uma certa quantidade de threads/ processos trabalhando num conjunto de tarefas.
A ideia é a criação estática de threads ou processos antes de começar as operações de fork/ join.
Então, o mapeamento de tarefas em threads ou processos ocorre dinamicamente usando uma fila de tarefas.
Em este tipo de mapeamento, não é possível que threads ou processos criam e destruam a si mesmos, mas podem simplesmente mapear para tarefas criadas dinamicamente conforme necessitarem.
Em alguns casos, a implementação é complicada e geralmente resultam em programas eficientes com bom balanceamento de carga.
Como exemplo de aplicação que são implementadas com este padrão através do mapeamento direto e indireto de tarefas, tem- se o algoritmo de ordenação de vetores mergesort.
Padrão de Compartilhamento de Dados A manipulação de dados com este padrão é compartilhada normalmente por mais de um processo, onde o compartilhamento de dados implica num conjunto de tarefas operando concorrentemente ou em paralelo.
Além disso, trabalhar com dados compartilhados propicia o programador a cometer erros no projeto de algoritmos paralelos.
Por isso, é importante uma boa abordagem que enfatiza a simplicidade e uma boa abstração, possibilitando que abordagens mais complexas sejam exploradas para obter maior desempenho.
A primeira etapa no projeto do algoritmo é identificar se este padrão é realmente necessário.
Se este é importante, começa- se a definir uma abstração e os tipos de dados, como por exemplo, no padrão de compartilhamento de fila, apenas são incluídas operações de colocar e tirar um elemento na fila quando as operações foram concluídas, para posteriormente incluir novas operações de manipulação na fila compartilhada.
Por outro lado, também é necessário que o algoritmo paralelo implemente um protocolo de controle de concorrência apropriado, considerando:
Um conjunto de operações sem interferência, leitura/ escrita, redução da seção crítica e alinhamento de locks.
Padrão de Compartilhamento de Fila O padrão de compartilhamento de fila tem por objetivo tratar o problema da execução concorrente de threads e processos numa fila compartilhada.
A implementação de algoritmos paralelos requer uma fila que é compartilhada entre processos ou threads.
Uma das situações mais comuns é a necessidade de um fila de tarefas implementada no padrão Mestre/ Escravo.
Para não haver erros na programação é importante prover uma abstração bem clara e tornar a verificação da fila compartilhada simples, identificando se esta está corretamente implementada.
Em determinadas situações, podem ser crescentes as chances de processos e threads permanecerem bloqueados esperando acesso à fila e limitar a concorrência disponível.
É importante destacar que, mantendo uma única fila para sistemas com hierarquia de memória mais complicada (por exemplo, máquinas Em uma e clusters) pode causar overhead na comunicação, no entanto, este problema é resolvido usando filas múltiplas ou distribuídas.
Em a implementação do projeto de uma fila compartilhada, segue- se os mesmos requisitos de projeto de padrão de compartilhamento de dados.
Inicialmente é necessário prover a abstração do tipo de dados, definindo os valores que esta fila pode receber e qual é o conjunto de operações.
Em seguida, deve- se considerar o protocolo de controle de concorrência, começando da maneira mais simples, um num tempo de execução, para então, aplicar os refinamentos direcionando esta metodologia neste padrão.
Padrão de vetor Distribuído O padrão de vetor distribuído é usado frequentemente na computação científica para dividir um determinado vetor de maneira a processar- lo em paralelo entre processos e threads.
Em a maioria da vezes, necessita- se de vetores com grandes proporções para calcular equações diferenciais neste cenário.
A implementação deste padrão se torna interessante quando o algoritmo utiliza o padrão de decomposição geométrica e o programa pode ser estruturado com o padrão SPMD.
Não é necessário especificar a distribuição do array para cada plataforma, entretanto, é importante gerenciar a hierarquia de memória.
Devido a isso, em máquinas Em uma os programas MPI podem ser melhores do que algoritmos similares que implementam multithread para manter páginas de memória próximos aos processadores que irão trabalhar com este array.
Questões como balanceamento de carga, gerenciamento de memória (pode trazer bom desempenho quando feio o uso correto da hierarquia de memória) e abstração (clareza em como os vetores estão divididos entre os processo ou threads e mapeados) podem resultar numa implementação com bons resultados, aproveitando bem os recursos disponíveis.
A abordagem para este padrão é particionar o vetores em blocos e mapear- los em processos ou threads.
Cada processo ou thread tem a mesma quantidade de trabalho e todos as threads ou processos deixam compartilhado um único endereço.
Assim, cada bloco do processo ou thread armazena num vetor local, do mesmo modo, para acessar os elementos do vetor distribuído, utiliza- se os índices no vetor local.
Interfaces de programação são utilizadas para abstrair linhas de código, simplificando o desenvolvimento para uma ampla quantidade de aplicações.
Este capítulo realiza um apanhado geral sobre interfaces tais com:
Bibliotecas, Application Programming Interface (API), framework e Domain Specific Language (DSL).
Biblioteca de Programação Bibliotecas de programação são uma boa alternativa para reutilização de código e redução do esforço na implementação de uma aplicação.
O uso de elas se torna interessante quando um código numa implementação já existe, evitando que ele se repita várias vezes no mesmo código.
Portanto, através de módulos pré-fabricados são disponibilizadas bibliotecas do programa (também chamados de modulo, classe ou biblioteca de código).
Desde que a computação começou, as bibliotecas têm sido criadas, contendo vários módulos reusáveis para diferentes propósitos.
A grande maioria dos programas desenvolvidos em qualquer linguagem de programação importam bibliotecas que fornecem suporte a implementações de baixo nível.
Em geral, elas implementam sub rotinas de aritmética, entrada/ saída e funções do SO, sendo abstraídas por uma função de programação num programa de aplicação.
Em o contexto de programação paralela é comum encontrar bibliotecas para reduzir o esforço no desenvolvimento.
Estas, implementam sub rotinas para exploração de paralelismo e funções do próprio SO.
Isso incluí funções para Para demonstrar o funcionamento desta primit abstrair a troca de mensagens, criação de threads ou processos, sincronização, exclusão mútua, escalonamento e de entre outros.
Em resumo, uma biblioteca sempre está vinculada a uma determinada linguagem de programação, fornecendo funcionalidades para um domínio.
API (Aplication Programming Interface) Uma API define blocos de construção reutilizáveis que permitem modular pequenas funcionalidades incorporadas numa aplicação de usuário final.
Em este contexto, fornecem uma abstração para um problema e especificam como o usuário deve interagir com os componentes de software que implementam a solução do problema.
Para tanto, os componentes são distribuídos em bibliotecas de programação, permitindo várias aplicações os utilizam.
Resumidamente, a API é uma interface bem definida que prove serviços específicos para outros softwares.
Ela pode ser tanto pequena quanto uma única função ou envolver várias classes, métodos, tipos de dados e constantes.
O desenvolvimento de uma API não é muito claro, seu objetivo é fornecer uma interface lógica enquanto também oculta os detalhes de implementação.
Embora os conceitos se relacionam entre biblioteca e API, estas abordagens se diferenciam.
Uma API possui uma interface lógica, para a qual, uma ou mais bibliotecas implementam as sub rotinas.
Em um código de aplicação que instancia Apis é possível que elas realizem a instanciação de outras para resolver um problema.
Assim, a API está uma camada a cima de uma biblioteca.
Framework Framework consiste de uma técnica de reutilização orientada a objeto.
Esta definição diverge entre alguns autores, entretanto, uma definição frequentemente utilizada define que &quot;framework é um projeto reutilizável de todo ou parte de um sistema que é representado por um conjunto de classes abstratas e a maneira como as instâncias interagem».
Por outro lado, definem que &quot;framework é um esqueleto de uma aplicação que pode ser customizada por um desenvolvedor de aplicação».
Ambos os conceitos não se conflitam, pelo contrário, eles se complementam, pois o primeiro descreve a estrutura e o segundo descreve a proposta de eles.
Tipicamente eles são implementados com uma linguagem orientada a objeto.
Cada objeto no framework é descrito por uma classe abstrata.
Uma classe abstrata é uma classe sem instâncias, sendo usada como uma superclasse.
Ainda que, uma classe abstrata sem instâncias pode ser usada como template para criar subclasses ao invés de um template para criar objetos.
Enfim, o framework descreve:
Os objetos, como eles (objetos) interagem, a interface de cada um de eles, o fluxo de controle entre eles e as responsabilidades do sistema também são mapeadas nos objetos.
Com isso, frameworks tiram proveito dos conceitos da linguagem orientada a objeto (i.
e abstração de dados, polimorfismo e herança).
Em um tipo de dado abstrato, uma classe abstrata pode representar uma interface por três, onde uma implementação geralmente podem mudar.
Polimorfismo orientado a objeto permite o desenvolvedor misturar e combinar componentes, permitindo um objeto trocar suas colaborações em tempo de execução e possibilitar a criação de objetos genéricos que podem trabalhar com um intervalo grande de componentes.
E, a Herança facilita a criação de um novo componente,.
A caracterização de um framework é dado por o conceito de inversão de controle, pois o controle do comportamento das classes do framework é gerenciado por ele e não por as classes da aplicação.
Esta arquitetura permite que uma aplicação canônica processe em etapas para ser customizada por objetos manipuladores de evento invocados por o mecanismo de expedição reativa ao framework.
Quando os eventos ocorrem, o framework invoca métodos nos objetos manipuladores pré-registrados, realizando o processamento específico da aplicação dos eventos.
Isso permite que o framework determine qual conjunto de métodos específicos da aplicação são invocados na resposta de um evento externo.
Além de esta característica, são fornecidos benefícios de modularidade, reusabilidade e extensibilidade.
Linguagem Específica de Domínio DSL (Domain Specific Language) é uma linguagem de programação direcionada para um domínio específico.
As linguagens normalmente utilizadas são de propósito geral, como por exemplo C, C+ e Java.
Uma DSL contém sintaxe e semântica no mesmo nível de abstração que o domínio do problema oferece.
Um exemplo no contexto de programação paralela é fornecer uma linguagem para programação paralela para um determinado domínio.
Em este sentido, a DSL é responsável por a abstração dos detalhes do domínio e implementação da linguagem.
O autor de define a DSL como uma linguagem de programação de expressivas limitações focada num domínio.
Categorizando assim, também é possível ter três tipos de DSL:·
DSL externa é uma linguagem separada da linguagem principal da aplicação que trabalha com ela.
Uma DSL externa possui uma sintaxe personalizada e também normalmente utiliza XML (Extensible Markup Language) como sintaxe.
Além disso o texto geralmente é analisado por um código na aplicação do hospedeiro usando técnicas de análise de texto.
Exemplo disso são:
Expressões regulares, SQL (Structured Query Language), Awk e configuração de arquivos· DSL interna é uma maneira de utilizar uma linguagem de propósito geral.
Um texto neste tipo de DSL é validado por a linguagem de propósito geral, mas somente utiliza alguns recursos da linguagem num estilo particular para lidar com um aspecto pequeno de um sistema global.
O resultado deve ser uma linguagem personalizada ao invés de uma linguagem de hospedeiro.·
linguagem de bancada é uma Ide (Integrated Development Environment) especializada para criar DSL.
No entanto, uma linguagem de bancada não serve somente para determinar a estrutura de uma DSL, mas também personalizar o ambiente de edição para as pessoas escreverem o texto da DSL.
A arquitetura básica para a implementação de uma DSL é composta por um processo de análise e geração de código, como ilustrado na Figura 3.1.
O texto na arquitetura refere- se ao programa que é descrito numa linguagem.
O analisador lê o texto e gera um modelo semântico (um modelo de objeto que combina dados e processamento), para que o gerador, a partir de uma determinada técnica de geração de código crie o código alvo para ser interpretado computacionalmente.
Embora existam diferentes tipos de DSL, a arquitetura permanece a mesma para ambos os tipos.
A diferença entre DSL interna e externa está na etapa do analisador (tanto na análise quanto como ela é feita).
Em uma DSL externa existe uma separação clara entre o texto, o analisador e o modelo semântico.
O texto é escrito numa linguagem separada, o analisador lê este texto e preenche o modelo semântico.
Porém, na interna é normal que estas coisas se misturem, pois é possível ter uma chamada explícita de objetos, sendo que o objetivo é fornecer uma interface para atuar como uma linguagem.
Desta forma, o texto executa através da invocação de métodos numa construção de expressões que preenche o modelo semântico.
Em resumo, na DSL interna a análise do texto é realizado por a combinação de análise de linguagem hospedeira e construção de expressões.
Conclusão Este capítulo apresentou um estudo sobre as principais interfaces de programação paralela utilizadas para abstrair detalhes de programação.
Nenhuma das interfaces foram descartadas na implementação de uma abordagem de exploração de paralelismo, porém, não encontrou- se um interface de programação paralela atualmente disponibilizada e caracterizada como uma DSL.
Isso motivou o estudo sobre a implementação e seus benefícios, pois, as demais são frequentemente encontradas neste contexto.
Além de o mais, com uma DSL é possível obter flexibilidade em nível de usuário e de implementação, podendo modelar o comportamento das características de paralelismo num alto nível de abstração, utilizando bibliotecas, Apis ou frameworks.
Também, usando uma interface amigável que envolve fatores como geração e análise de código é possível introduzir o programador a trabalhar com uma determinada abordagem, direcionando o desenvolvimento de software.
A Computação de Alto Desempenho está em busca de novas alternativas para tornar a programação paralela algo comum aos desenvolvedores de software.
Arquiteturas paralelas não são facilmente exploradas.
Pesquisadores têm se preocupado com isso há muito tempo, dedicando seus esforços em fornecer novas soluções e metodologias, com o propósito de abstrair a complexidade em lidar com diferentes tipos de arquiteturas.
O primeiro passo foi a exploração de paralelismo através de interfaces de programação de baixo nível como:
Pthreads, OpenMP (Open Multi--Processing), o TBB (Threading Bulding Blocks), Cilk e SWARM (SoftWare and Algorithms for a objetos, passou- se a criar os frameworks, os mais conhecidos são:
Intel Parallel Studio, Galois e o FastFlow.
Assim, neste capítulo, caracterizou- se as interfaces de programação para exploração de paralelismo de baixo nível na Seção 4.1 e os frameworks na Seção 4.2.
Interfaces de Programação Paralela Esta seção apresenta as principais interfaces de programação paralela para arquiteturas multicore.
Em este contexto estão inseridas bibliotecas, Apis e linguagens, as quais tem por finalidade fornecer uma camada de abstração de desenvolvimento de aplicações paralelas.
Existem várias destas tecnologias representando elas.
Somente as mais populares e conhecidas serão descritas nas subseções a seguir.
Quando se trata de programação paralela no cenário de memória compartilhada, a biblioteca pthread é uma das que lida com paralelismo de mais baixo nível.
Isso porque ao programar é necessário que o programador entenda os conceitos de threads e do SO.
Assim como em sistemas operacionais multitarefa é possível realizar mais de uma coisa concorrentemente executando mais de um processo, um processo pode também fazer o mesmo executando mais de uma thread.
Cada thread é vista como um fluxo de controle que pode executar suas instruções independentemente, sendo que elas podem ser desempenhadas para executar de forma concorrente ou paralela.
O uso da biblioteca tende a proporcionar maior flexibilidade ao programador e resultar em soluções paralelas com maior desempenho.
Em ela são disponibilizadas funções que lidam com a criação, sincronização e escalonamento de threads.
Cabe ao programador implementar estas funções para melhor explorar o paralelismo disponível.
A obtenção de soluções inteligentes dependerá de como o programador fará uso das funções da biblioteca, o uso indevido pode resultar em implementações com grande sobrecarga, exemplo disso é quando as threads compartilham uma mesma região de memória.
O objetivo principal do OpenMP é facilitar o desenvolvimento de software para memória compartilhada.
Não se trata de uma linguagem de programação e sim de uma interface de programação de aplicações.
O OpenMP fornece uma variedade de diretivas de compilação, rotinas de bibliotecas e variáveis de ambiente.
As diretivas podem ser usadas para estender linguagens sequenciais, (por exemplo, Fortran, C e C+) oferecendo construções:
SPMD (Single Program Multiple Data), de tarefas, de trabalho compartilhado e para sincronização.
A sua popularidade atualmente se deve por a simplicidade em implementar o paralelismo de laços e também por a portabilidade oferecida.
Além disso, é enfatizado a programação paralela estruturada, podendo ser utilizado em diferentes plataformas de memória compartilhada.
O modelo de programação é baseado na cooperação de execução simultânea de threads em multiprocessadores ou multi-core.
Para criar e destruir as threads o OpenMP utiliza o padrão Fork-Join.
Assim, num programa OpenMP, uma thread é inicializada e esta executa o programa sequencial até encontrar uma região paralela, somente então a operação fork é realizada implicitamente.
O TBB (Threading Bulding Blocks) é uma abordagem para expressar o paralelismo em C+.
A biblioteca ajuda a melhorar o desempenho de aplicações em arquiteturas multi-core, sendo esta uma abstração de alto nível que é baseada no paralelismo de tarefas, abstraindo detalhes da plataforma e mecanismos de threads para fornecer maior escalabilidade e desempenho.
No entanto, o desenvolver é quem deve encontrar os pontos de paralelismo do algoritmo e o TBB é quem vai fazer o mapeamento das tarefas em threads fornecendo o balanceamento de carga.
Assim como a maioria das interfaces de programação paralela, o TBB também implementa o paralelismo de laços, mecanismos de sincronização, diretivas de escalonamento de threads e alguns padrões paralelos.
Além disso, a TBB permite que outras interfaces que implementam multithread também sejam utilizadas, por exemplo, OpenMP.
Desta forma, o programador pode adicionar diretivas OpenMP no código que instancia os mecanismos do TBB,.
O objetivo é tornar o TBB mais flexível possível ao desenvolver e deixar- lo optar por a melhor solução na sua aplicação.
O Cilk é uma tecnologia e uma linguagem algorítmica de programação multithread criado no A sua filosofia parte do princípio que um programador deve concentrar- se na estruturação do seu programa para expor o paralelismo e explorar a localidade, deixando que o sistema de execução seja responsável por o escalonamento de uma determinada computação.
O sistema de execução é responsável por o balanceamento de carga e também por o protocolo de comunicação.
Diferente das outras interfaces de programação paralela, o sistema de execução do escalonador garante a eficiência e o desempenho dos algoritmos.
A linguagem Cilk é simples.
Ela possui três palavras chave para indicar o paralelismo e a sincronização:
Cilk para declarar funções que podem ser transformadas em threads;
Spawn para chamar funções declaradas com cilk a fim de criar uma nova thread e sync é usado para forçar a sincronização, ou seja, o programador identifica pontos no programa aonde a execução continua somente quando a dependência for resolvida e só assim a próxima instrução é executada.
O Cilk estende a semântica da linguagem C, então se o objetivo é executar o programa num único processador, basta deletar estas palavras chave.
O principal objetivo da SWARM é minimizar o esforço na modificação de códigos sequencias.
Para isso, é importante que o programador tenha a capacidade de identificar rotinas de computação intensiva no programa, o trabalho poderá ser atribuído em cada núcleo usando um algoritmo eficiente para organizar a computação.
As operações que podem ser computadas independentemente, a biblioteca fornece o paralelismo funcional (paralelismo de laços), em o qual, cada thread resolve parte da computação em paralelo.
Frameworks de Programação Paralela Diferente do cenário das ferramentas de interfaces de programação paralela, os Frameworks são caracterizados por a abstração e reutilização de soluções inteligentes (métodos e classes).
Normalmente frameworks de programação paralela fornecem métodos/ classes que implementam o comportamento do paralelismo, sendo, posteriormente, reutilizados em outros tipos de aplicações.
Assim como, metodologias de desenvolvimento de software podem ser facilmente associadas para direcionar o desenvolvedor a obter soluções com alta produtividade.
Nem todos estes conceitos são introduzidos nos frameworks utilizados em programação paralela para ambientes multi-core, no entanto, esta seção busca apresentar- los e caracterizar- los no que se refere a implementação e utilização.
A indústria de processadores também está se preocupando com a exploração de paralelismo disponibilizado em suas arquiteturas multi-core.
Exemplo disso, a Intel está comercializando um framework conhecido como Intel Parallel Studio (IPS).
Este, disponibiliza uma interface intuitiva com depuração otimizada para mecanismos de sincronização a fim de prover maior agilidade na programação para linguagem C+.
A ideia é direcionar o desenvolvedor através de um metodologia de projeto de software.
A metodologia proposta é dividida em quatro fases de projeto:
Para cada uma das fases de projeto o framework fornece uma ferramenta.
A primeira é o &quot;Parallel Advisor», este possui funcionalidades de detecção de conflitos, como por exemplo, condições de corrida e mecanismos de bloqueios (efetua o bloqueio de uma região crítica).
As otimizações no código são realizadas com a ferramenta &quot;Parallel Composer», a qual dispõem de opções avançadas de compilador e bibliotecas, bem como o suporte ao paralelismo simples e complexo (bibliotecas pre-threaded e thread- safe).
Em a fase de verificação é usada a ferramenta &quot;Parallel Inspector», esta tem a finalidade de encontrar problemas com relação a construção do programa (memória e threads) através de uma interface de depuração.
Encerrando o ciclo do framework, o &quot;Parallel Amplifier «ajuda a construir aplicativos de escala multi-core e many-core e garantir o desempenho do aplicativo identificando concorrência, hotspots (unidades do programa que mais consomem tempo) e analisando locks e waits (threads que ficam esperando para continuar a computação).
Um dos recentes trabalhos de pesquisa na comunidade científica é o framework Galois.
Sua proposta é o paralelismo de dados, cujo o foco é operar em códigos irregulares que são organizados em torno de estruturas de dados baseadas em ponteiros, como grafos e árvores.
Os detalhes de paralelismo são resolvidos através da sua biblioteca de programação, a qual utiliza o padrão Worklist, onde um algoritmo interativo obtém trabalho através de uma lista de tarefas.
O algoritmo chega ao final somente quando a lista de tarefas estiver vazia.
Em o Galois, o usuário expressa o algoritmo usando código sequencial Java, mas deve especificar os laços que podem ser paralelizados usando a interface Galois através do foreach.
O código resultante terá a mesmo aspecto semântico de código sequencial, enquanto isso, permite o paralelismo eficiente.
O framework também disponibiliza um conjunto de benchmarks com a finalidade de permitir que possam ser feitas avaliações e comparações de desempenho da aplicação.
Outro recente trabalho de pesquisa é o framework FastFlow.
Seu objetivo é fornecer suporte ao desenvolvimento de aplicações de streaming utilizando mecanismos de sincronização não bloqueantes em plataformas multi-core.
FastFlow fornece uma biblioteca paralela em linguagem C+, sendo que esta implementa o padrão pipeline com filas para um único consumidor e produtor.
Também são tratadas as questões de sincronização e fluxo de dados de um para muitos, muitos para um e muitos para muitos.
O sistema de execução do FastFlow suporta duas camadas com duas características:
Exploração de paralelismo, por exemplo, a criação, destruição e controle do ciclo de vida de diferentes fluxos de controle de memória compartilhada;
Canais de comunicação um para um assíncronos, suportando a sincronização de diferentes fluxos de controle.
Estas características são implementadas em filas SPSC (Single-Producer-Single- Consumer) equipadas com operações push e pop não bloqueantes.
Em esta abordagem, a operação push referente a o produtor sempre lê e escreve usando pwrite (ponteiro corrente), no entanto, a operação push referente a o consumidor somente utiliza o pread (ponteiro chefe) para leitura e escrita.
Isso é difere das outras abordagens, onde produtor e consumidor acessam o mesmo ponteiro corrente e chefe causando inconsistências na memória.
Síntese Em este breve estudo identifica- se o esforço da comunidade para facilitar o desenvolvimento de software paralelo e melhorar a exploração do paralelismo das arquiteturas.
Existe uma diversidade de ferramentas para exploração de paralelismo.
As interfaces de programação paralela (bibliotecas e API's) se aplicam no contexto de flexibilidade para obter soluções de alto desempenho.
Os Frameworks não são tão flexíveis para a exploração de paralelismo, entretanto, têm por objetivo abstrair os detalhes de programação paralela e são frequentemente implementados em linguagens orientadas a objetos, permitindo a reutilização de soluções paralelas anteriormente construídas.
O desafio inicial deste trabalho de pesquisa é aprender com estas abordagens e propor uma maneira de obter as características de flexibilidade, facilidade e alto desempenho numa única solução através de uma DSL.
Nota- se que, DSLs não são encontradas no cenário de interfaces de programação paralela.
Isso se torna um diferencial com relação a proposta de pesquisa deste trabalho, onde o objetivo é prover uma interface orientada a padrões paralelos para um domínio específico, o qual, refere- se a programação paralela em ambientes multi-core.
De modo a complementar o relacionamento entre os trabalhos elencados nesta pesquisa, tabulouse algumas das principais características importantes na exploração de paralelismo em arquiteturas multi-core, ranqueando- as de 0 a 3 estrelas () e associando com a afinidade do trabalho, conforme é expressado na Tabela 4.1.
Através desta representação, buscou- se diferenciar os trabalhos atualmente utilizados, identificando as possíveis contribuições neste cenário para a implementação da Led-PPOPP.
Alguns trabalhos implementam a técnica de paralelismo em fluxo, permitindo que as computações sejam paralelizadas através de estágios num pipeline.
Enquanto isso, outros trabalhos focam no paralelismo incremental, evitando que grandes alterações sejam realizadas num programa sequencial.
Evidentemente, as interfaces que implementam abstração de alto nível proporcionam o paralelismo mais implícito, ocultando os detalhes de programação paralela.
Padrões paralelos são soluções especializadas para estruturar e modelar algoritmos que obtém vantagem sobre as arquiteturas paralelas.
Observa- se que nenhum dos trabalhos implementa uma interface introduzindo este conceito.
Em vista de isso, está se propondo uma DSL que forneça todas as características elencadas através de uma interface que introduza a abordagem de Programação Paralela Orientada a Padrões Paralelos (PPOPP), sendo elaborada e apresentada na Seção 5.1.
A Led-PPOPP é uma Linguagem Específica de Domínio de Programação Paralela Orientada a Padrões Paralelos.
Primeiramente, realizou- se um estudo de caso implementando o padrão Mestre/ Escravo baseado no modelo PPOPP, representado na Figura 5.2 e discutido na Seção 5.1.
De o mesmo modo, suporta o desenvolvimento de programas com a linguagem C e exploração de paralelismo em arquiteturas multi-core.
Esta, por sua vez, dispõe de uma interface de núcleo e subnúcleo do padrão Mestre/ Escravo, onde mecanismos de sincronização e proteção de dados compartilhados também são fornecidos.
A interface (descrita na Seção 5.2) é reconhecida através de um compilador da linguagem, o qual é responsável por a análise e geração de código paralelo (descrito na Seção 5.4).
O compilador é o principal elemento que compõe o projeto de algoritmos paralelos para o ciclo de desenvolvimento ilustrado na Figura 5.1.
Caracterizando- se num ciclo de desenvolvimento de software é possível identificar todo o processo que envolve a criação de soluções paralelas a partir de a Led-PPOPP.
Assim, classificou- se em quatro fases de projeto, verificando separadamente os papeis de cada uma de elas neste ciclo:·
a fase de Código Fonte refere- se ao ambiente de desenvolvimento, onde são utilizados os recursos da linguagem Led-PPOPP para criar uma solução paralela;·
em a Análise do Código é utilizado o compilador da linguagem, em o qual é realizado a análise sintática e semântica do código da solução.·
Geração de Código Paralelo não está explícito ao programador, pois esta fase faz parte do processo de compilação e é realizada automaticamente com base no modelo semântico;·
Execução é a fase onde o programador executa a aplicação e realiza testes para avaliar o funcionamento e o desempenho.
De acordo com a Figura 5.1, o desenvolvimento de software paralelo inicia com a fase de código fonte.
Após concluir a escrita da solução, a fase de análise do código é inicializada com a intervenção do compilador da linguagem.
Se houver algum erro, o compilador efetua um bloqueio, impedindo que a programação avance para a próxima fase, caso contrário, se não foram constatados erros, avança- se para a fase seguinte.
Então, acontece a geração automática do código paralelo, a qual faz parte do processo de compilação.
Com o código binário gerado, o desenvolvedor pode testar (executar) a aplicação.
Se esta não apresentar resultados satisfatórios, novas otimizações no código poderão ser efetuadas, iniciando- se novamente o ciclo de desenvolvimento.
Programação Paralela Orientada a Padrões Paralelos Programação Paralela Orientada a Padrões Paralelos (PPOPP) é uma abordagem que se baseia em soluções inteligentes para exploração de paralelismo.
O objetivo é induzir o programador a desenvolver software com padrões paralelos.
As aplicações que são paralelizadas utilizando este tipo de abordagem podem proporcionar alta produtividade, pois os padrões derivam a partir de aplicações que já foram exploradas no passado.
Como se trata de uma abordagem baseada em padrões conceitualmente definidos, esta pode ser facilmente entendida por desenvolvedores inexperientes e profissionais de diferentes áreas.
A implementação de uma interface ou linguagem de PPOPP é uma maneira de direcionar o desenvolvimento de software nesta linha de raciocínio.
A vantagem está no desenvolvimento, pois o programador ao projetar sua aplicação pode focar na resolução do problema e reduzir seus esforços na paralelização.
Consequentemente, não é necessário conhecer as bibliotecas de programação paralela para explorar o paralelismo das arquiteturas.
A proposta é trabalhar com núcleos de padrões paralelos, definindo- os através de uma função da linguagem e em ela são fornecidos blocos correspondentes ao padrão paralelo da função.
Como é de conhecimento, diferentes tipos de computações podem estar contidas num programa, acredita- se que nem sempre é possível resolver- las com o mesmo padrão paralelo e obter um bom desempenho ao mesmo tempo.
Para isso, está se propondo um modelo com subnúcleos que podem implementar uma diversidade de padrões paralelos e também combinar- los entre si.
Este modelo de programação é ilustrado na Figura 5.2, o qual servirá de base para a construção da Led-PPOPP.
Em este modelo, o núcleo principal pode suportar diferentes padrões, entretanto, apenas um de eles é declarado uma única vez em todo programa, pois trata- se da função principal desta abordagem.
Em uma visão global, a aplicação é paralelizada com blocos de código para efetuar a modelagem da computação.
Os subnúcleos (correspondem a um determinado padrão paralelo disponibilizado por uma função da linguagem), se necessários, podem paralelizar uma computação declarada num bloco de código do núcleo principal.
O objetivo geral é fornecer uma abordagem genérica de PPOPP, sendo esta, composta de vários padrões que exploram o paralelismo em diferentes tipos arquiteturais.
Interface de Programação da Linguagem Em linguagens específicas de domínio uma interface nada mais é do que uma abstração de linguagem expressada num texto com uma gramática mais próxima da realidade humana.
De tal forma, a interface foi definida utilizando palavras do vocabulário inglês (linguagem padrão da computação), atribuindo- se nomes aos núcleos (funções da linguagem), aos blocos de código (blocos pertencentes as funções da linguagem) e para as primitivas.
A Tabela 5.1 descreve a interface de programação da Led-PPOPP.
A interface da Led-PPOPP foi projetada pensando numa possível ampliação de funcionalidades seguindo o princípio de núcleos de padrões paralelos, ou seja, futuramente novos padrões poderão ser implementados sem perder o formato das declarações.
Assim, definiu- se que:
Os núcleos de um padrão devem iniciar com o caractere», os blocos são inicializados com o caractere&quot;@ &quot;e as primitivas com «&amp;».
Para diferenciar o núcleo principal do subnúcleo, as funções de núcleo principal iniciam a construção do nome commain.
Os blocos pertencentes ao núcleo principal devem conter o caractere « «no final do nome, bem como as primitivas pertencentes a ele.
O reconhecimento da interface é realizado através do compilador da linguagem (compilador PPOPP descrito na Seção 5.4) que requer a instanciação da biblioteca ppoppLinux.
H no inicio do script de texto (código fonte).
Como a Led-PPOPP esta associada a linguagem C, esta biblioteca possui suporte a todas bibliotecas desta linguagem, fazendo- se necessário apenas a declaração de ela.
Um exemplo de código é descrito no Algoritmo 5.1, apresentando um esqueleto do núcleo principal com o processo mestre imprimindo uma mensagem na tela logo após as duas threads escravas.
Algoritmo 5.1: Exemplo de código Led-PPOPP 1&amp; include\ ppoppLinux.
H\&gt; &amp; SynchronizeSlaves ;
Esta seção teve como objetivo apresentar a interface e entender como ela é expressada num script de texto, exemplificado através do Algoritmo 5.1.
Para melhor esclarecer o funcionamento da interface da Led-PPOPP, as próximas subseções descreverão a Estrutura da Linguagem (Seção 5.2.4).
Para toda linguagem existe uma maneira de estruturar os algoritmos.
Como descrito anteriormente, a Led-PPOPP baseia- se na abordagem do modelo de PPOPP para o desenvolvimento de aplicações paralelas.
A representação da estrutura de combinações possíveis e mínimas é apresentado na Figura 5.3, através de um modelo estrutural em formato de árvore.
Quando declarado um núcleo principal é necessário no mínimo um bloco Master e um Slave.
Os blocos Slave podem ser declarados dentro ou fora de o bloco Master tantos quantos são necessários.
A mesma regra se aplica para construções de subnúcleos, no entanto, o núcleo principal deve ser declarado uma vez no programa, pois trata- se da função principal da Led-PPOPP.
Em o núcleo principal podem ser declarados subnúcleos, porém, subnúcleos não podem conter subnúcleos, pois eles são o último nível da representação estrutural.
As primitivas de sincronização somente são necessárias quando existirem blocos Slave fora de o bloco Master.
E, a outra primitiva refere- se a proteção de dados, sendo necessária quando um determinado dado é compartilhado entre as tarefas escravas, garantindo que os dados não sofram inconsistências.
Em este breve relato, nota- se que a estrutura da linguagem é bastante flexível, permitindo diversos tipos de combinações de blocos e subnúcleos.
Mas é importante ressaltar que quando declarado um núcleo (núcleo principal ou subnúcleo) o código deve ser especificado dentro de os blocos Master e Slave pertencentes a ele.
Um exemplo de código usando uma construção de subnúcleo para resolver um problema numa função global é apresentado no Algoritmo 5.2.
Em ela, também é possível observar como o código é expressado nas declarações.
Algoritmo 5.2: Exemplo de código Led-PPOPP usando subnúcleo 1&amp; include\ ppoppLinux.
H\&gt; &amp; SynchronizeSlaves;
Em esta seção foram demonstradas as maneiras de se estruturar um código com a Led-PPOPP.
Esta foi a primeira etapa para entender a linguagem como um todo e o quanto ela pode ser flexível.
O próximo passo é entender como os dados são vistos, interpretados e organizados.
Para isso, a próxima seção (Seção 5.2.2) esclarecerá estes detalhes.
A Led-PPOPP permite que diversas combinações sejam expressadas num programa.
O objetivo desta seção é simplificar o entendimento de como os dados devem ser vistos e como eles são tratados.
Antes de tudo, é importante ter a percepção de que os dados declarados dentro de o bloco de código são declarações utilizadas somente por ele (i.
e, variáveis).
E, os dados que são declarado fora de o núcleo principal são os dados globais (acessível para todas as construções da linguagem).
Essa representação é esclarecida com a ajuda do Algoritmo 5.3.
Algoritmo 5.3: Organização dos dados na Led-PPOPP 1&amp; include\ ppoppLinux.
H\&gt; 2 globais\&gt; do bloco Master\&gt; do bloco Slave\&gt; &amp; SynchronizeSlaves ;
A medida que são utilizados os subnúcleos, mais complexa ficará a interpretação dos dados.
Uma boa prática para reduzir esta complexidade é implementar funções específicas globalmente.
Com isso, as construções de subnúcleo não poluem tanto o código do núcleo principal e simplifica a interpretação dos dados.
Outro cuidado a ser tomado na interpretação dos dados está na declaração de blocos Slaves dentro de o bloco Master.
Como dito anteriormente, os dados são localmente usados em seus blocos, no entanto, os que estão contidos no bloco Slave são replicados, se este estiver no bloco Master, uma cópia também é mantida em ele, o qual ajudará na resolução da computação.
Isso implica que o programador deve tomar cuidado na manipulação das variáveis, pois estas não poderão ser iguais em ambos os blocos nesta ocasião.
A próxima seção (Seção 5.2.4) descreve em mais detalhes o comportamento na exploração do paralelismo.
Em ambientes multi-core os dados estão acessíveis ou compartilhados através da memória, isso implica que os processadores podem acessar a mesma região de memória simultaneamente.
Normalmente, nestes ambientes, o uso de mecanismos de bloqueio são necessários para evitar que duas threads/ processos escrevam na mesma região de memória, assim, não ocorrem inconsistências nos dados.
A Led-PPOPP fornece uma primitiva (ProtectData) para assegurar o acesso na memória.
O objetivo é fornecer uma primitiva com uma interface padrão para suportar diferentes mecanismos de sincronização, no caso, utilizou- se o Mutex que é implementado na biblioteca pthread.
Uma demonstração do funcionamento desta primitiva foi ilustrado no Algoritmo 5.4.
Este pseudo código nos apresenta uma simples estrutura com núcleo principal usando um bloco mestre e outro escravo, de o qual, originarão duas threads que dividirão a carga de trabalho entre elas.
Além disso, como o bloco escravo foi declarado fora de o bloco mestre, necessitou- se aplicar a primitiva de sincronização.
Algoritmo 5.4: Exemplo de código Led-PPOPP usando a primitiva de proteção de dados 1&amp; include\ ppoppLinux.
H\&gt; &amp; SynchronizeSlaves ;
A primitiva ProtecData foi utilizada neste exemplo do Algoritmo 5.4 para evitar que a operação de soma sofra inconsistências, pois duas threads escravas estarão compartilhando a mesma variável (total_ pares).
Esta, por sua vez, é apenas uma interface facilitadora da linguagem Led-PPOPP, no caso, usando Mutex o comportamento de ele não se altera nesta linguagem.
Em este sentido, a variável declarada na primitiva é interpretada como sendo global do tipo mutex, possibilitando que esta seja utilizada por as threads escravas.
Um dos maiores desafios na programação paralela é a exploração de paralelismo num alto nível de abstração.
A proposta de trabalhar com padrões paralelos surge como alternativa para fornecer programação guiada através de uma linguagem que os implementa.
Em esta pesquisa, optou- se por a utilização do padrão Mestre/ Escravo, pois ele é facilmente introduzido na maioria das aplicações e obtêm soluções paralelas com alto desempenho na maioria dos casos.
Em a organização dos dados (Seção 5.2.2) foi demonstrado que os dados do bloco Slave são replicados tantas vezes quantas tarefas escravas são criadas a partir de ele.
Se replicas são criadas, como é possível obter desempenho?
Realmente, instruções que não podem ser divididas dificilmente apresentarão desempenho (i.
e, variáveis e funções).
Em este contexto, o uso de subnúcleos nos blocos Slave também apresenta o mesmo problema, isso pode ser visto na Figura 5.5, em a qual está ilustrando duas threads escravas (T2 e T3) processando a mesma computação.
Além disso, o mestre também exemplifica o comportamento da declaração de subnúcleo, processando- o sequencialmente e deixando a cargo de o subnúcleo a exploração do paralelismo.
Como visto anteriormente, algumas construções não fornecem bom desempenho quando não permitem a sua divisão em tarefas, mas isso não impede que o programador implemente construções avançadas para obter maior desempenho.
Uma alternativa é controlar o comportamento da computação que foi declarada no bloco Slave, fazendo com que cada thread escrava processe instruções diferentes ou parte de ela em paralelo e aproveitando- se da maneira que o padrão Mestre/ Escravo trabalha.
Este tipo de implementação requer a comunicação entre as threads escravas e a utilização da primitiva de proteção de dados, a qual é fornecida por a Led-PPOPP.
A maioria das computações estão em torno de laços, muitas de elas exigem muito do processador para resolver um determinado problema.
A grande maioria das bibliotecas de programação paralela possuem suporte ao paralelismo de laços for (por exemplo, OpenMP e TBB), com técnicas de balanceamento de carga e escalonamento otimizado.
No entanto, o paralelismo implementado por estas bibliotecas é realizado com o padrões Fork/ Join, o que inviabiliza a utilização das mesmas na filosofia de programação da Led-PPOPP, fazendo- se necessário um estudo para encontrar a melhor maneira de explorar o paralelismo em laços sem perder a originalidade e o comportamento do padrão Mestre/ Escravo.
Conforme pode ser visto na Figura 5.6, na Led-PPOPP o paralelismo de laços for é abstraído, basta declarar- lo no bloco Slave para que a divisão do processamento aconteça.
No entanto, somente construções simples de laços são possíveis, contendo apenas um parâmetro de inicialização, um de controle e um contador utilizando a mesma variável.
E, a expressão de controle de parada pode ser criada apenas com os operadores lógicos\&gt;,\&gt; $ , e caso estas condições não forem satisfeitas, o compilador da linguagem (Seção 5.4) irá reportar um erro.
Estas restrições também são encontradas nas bibliotecas que suportam o paralelismo de laço, isso porque estruturas complexas de laços não são facilmente paralelizadas.
Esta seção apresentou diferentes formas de implementar o paralelismo e obter soluções paralelas que podem proporcionar alto desempenho através da Led-PPOPP.
Demonstrou- se também que a linguagem não garante que qualquer construção paralela resulte numa solução com alto desempenho, os bons resultados na implementação estarão diretamente ligados a utilização correta das funcionalidades e o quanto a aplicação é adaptável ao padrão Mestre/ Escravo.
Cenário de Implementação Um exemplo prático de implementação da Led-PPOPP está ilustrado na Figura 5.7.
Em ela, o algoritmo de multiplicação de matrizes é exemplificado em três cenários diferentes (Sequencial, LEDPPOPP e Pthread).
O objetivo com estes cenários de implementação é demonstrar um ambiente real de programação, entendendo como um código é criado com esta linguagem específica de domínio e comparando as diferenças em relação a biblioteca Pthread.
Analisando os cenários, nota- se que para paralelizar o algoritmo de multiplicação de matrizes:·
a Led-PPOPP requer poucas modificações no código sequencial;·
a quantidade de código necessário utilizando Led-PPOPP é menor do que em Pthread;·
usando a Led-PPOPP o desenvolvedor não precisa saber como quebrar um problema, pois a linguagem se encarrega de fazer isso;·
a sincronização de threads é necessária em ambas as abordagens.
No entanto, usando a Led-PPOPP isto é abstraído por meio de a primitiva de sincronização de blocos escravos.
Compilador Um compilador tem por objetivo transformar um código fonte de uma representação em outra.
Não existe um formalismo para representar e determinar a construção, mas é possível classificálo em fases no processo de execução.
Mais precisamente, um compilador deve conter uma fase de análise e uma de geração de código, as quais podem ser alimentadas por um tratador de erros e um gerenciador de tabelas e símbolos.
Mantendo- se caracterizadas as duas principais fases, não existe um restrição que impeça de quebrar- las num nível maior de detalhamento.
A implementação é bastante particular do construtor do compilador, este pode tanto personalizar da sua maneira a analise e a geração, quanto usar ferramentas que auxiliam neste processo.
Nomeado como PPOPP é o compilador criado para a Led-PPOPP.
Diferente dos tradicionais compiladores, este tem como objetivo reconhecer e gerar código paralelo orientado ao padrão Mestre/ Escravo para arquiteturas multi-core.
Igualmente, permitir que os algoritmos possam ser escritos com a sintaxe e semântica da linguagem C, sendo reconhecida com o auxilio do compilador GCC (Gnu (General Public License) Compiler Collection) integrado ao compilador PPOPP, para o qual, a sua estrutura pode ser vista através da Figura 5.8.
Desta forma, o programador será induzido desde o inicio a desenvolver algoritmos que exploram o paralelismo utilizando o padrão Mestre/ Escravo.
Portanto, na geração de código ocorre a transformação do código fonte especificado através da Led-PPOPP num código paralelo orientado ao padrão Mestre/ Escravo utilizando a biblioteca «pthread.
H «em linguagem C. Em seguida, este código paralelo é transformado (utilizando o GCC) num programa alvo (código binário), pronto para ser executado no ambiente em que foi gerado.
Atualmente o compilador PPOPP suporta a instalação em plataformas Linux 64/32 bits.
Após a instalação, a compilação é realizada num terminal através do comando ppopp fonte.
C\&gt; onde o primeiro argumento do comando é o programa fonte com extensão».
C «e o segundo é um nome atribuído ao programa alvo, ou seja, o arquivo de saída do compilador.
Fatores Considerados O projeto da Led-PPOPP ambiciona reduzir o esforço de programação paralela e induzir o programador a explorar o paralelismo das arquiteturas multi-core.
A escolha deste tipo de arquitetura paralela se deve por a demanda que o cenário se encontra, sendo bastante comum em estações de trabalho e desktops, entretanto, a maior parte dos aplicativos que executam em elas não obtém vantagem sobre o paralelismo disponível.
A perspectiva é que estas arquiteturas forneçam processadores com centenas de núcleos.
Para isso, é importante que desenvolvedores de diferentes áreas seja induzidos e que as interfaces de programação paralelas abstraem o paralelismo de baixo nível, usando uma abordagem de alto nível a fim de que programadores inexperientes também consigam programar.
Centrando- se neste objetivo, a abordagem PPOPP proposta visa a implementação de vários padrões paralelos e a combinação entre eles.
Entretanto, é preciso ter cautela, porque uma proposta desta magnitude é bastante complexa e custosa.
Em virtude de isso, implementou- se o padrão Mestre/ Escravo, por ser o padrão paralelo mais genérico, simples e conhecido por a grande maioria dos desenvolvedores.
Por outro lado, os relatos demonstram que a utilização deste padrão tende a fornecer aplicações com bom desempenho para uma boa parte dos problemas encontrados na computação.
Mesmo que a prioridade tenha sido diminuir o esforço por meio de a Led-PPOPP, é preciso fornecer uma interface que obtenha vantagem sobre a arquitetura paralela sem grandes perdas de desempenho.
Logo, questões de otimização de desempenho não foram implementadas, como por exemplo, balanceamento e escalonamento.
As threads são simplesmente criadas e sincronizadas no contexto do padrão Mestre/ Escravo e o SO se encarrega de escalonar- las entre os elementos de processamento.
Este capítulo apresenta o planejamento e a execução dos experimentos para validação da LEDPPOPP num estudo de caso com o padrão Mestre/ Escravo.
O objetivo é demonstrar claramente como a metodologia de experimentação foi conduzida na medição do esforço de programação paralela e na medição do desempenho obtido na paralelização.
Tratando- se de objetivos diferentes, estes foram categorizados em duas seções experimentais:
A Seção 6.1 demonstra o processo experimental na medição do esforço e a Seção 6.2 sobre a medição do desempenho.
Experimento para Medição do Esforço de Programação Paralela Em este trabalho de pesquisa, um dos objetivos é reduzir o esforço de programação através da Led-PPOPP.
Experimentos são usados na área da computação quando existe o fator humano na operacionalização com software, sendo este, um método científico aplicado para avaliar os benefícios de determinada abordagem ou teoria relacionada ao software.
Para isso, os experimentos são baseados em hipóteses estatísticas, tratando- se de uma suposição formulada, referindo- se a distribuição da probabilidade de uma ou mais populações.
Em seguida, com os resultados da execução, realiza- se o teste de hipótese, validando- a ou rejeitando- a.
A experimentação é caracterizada num processo com quatro fases (definição, planejamento, execução e avaliação), de as quais, esta seção irá apresentar o planejamento e a execução.
A métrica associada a primeira questão de pesquisa corresponde ao esforço medido por a relação do tempo gasto em minutos por cada participante na paralelização de um algoritmo com a LEDPPOPP e com Pthread.
Para isso, será comparado as médias de tempo dos participantes na paralelização de uma aplicação para cada uma das abordagem.
A análise é realizada usando o teste estatístico de hipótese.
Para este, efetua- se a suposição de uma hipótese nula que será rejeitada ou não, estipulando- se um valor crítico (conjunto de valores que podem rejeitar a hipótese nula).
Como neste experimento deseja- se obter uma confiabilidade de 95%, o nível de significância (probabilidade máxima para rejeitar a hipótese) adotado é de 5% (o mesmo que 0.05), ou seja, para que a hipótese seja rejeitada é necessário que o resultado do nível de significância seja menor que 0.05 (a literatura denominado este valor de p- value).
Esta seção tem por objetivo associar a hipótese informal HP1 com a métrica levantada, formulando uma hipótese formal que guiará a execução deste experimento.
A tradução de uma hipótese informal é traduzida em indicadores numéricos para realizar a verificação estatística de sua validade.
Assim, devido a natureza do teste estatístico, transformou- se a hipótese numa hipótese nula, da seguinte forma:
Em um estudo experimental a causa ou variável independente é o previsor e o efeito ou variável dependente é o resultado.
Esta terminologia em termos de trabalhos transversais, estatisticamente, pode usar uma ou mais variáveis para fazer previsões sobre outros sem a necessidade de implicar a casualidade.
Em este experimento, assumiu- se como variável dependente, o Esforço para paralelizar um algoritmo sequencial.
Como variáveis independentes assumiu- se:
O Conhecimento para realizar o experimento (variável de bloqueio) e as Abordagens utilizadas para paralelizar um algoritmo (Led-PPOPP e Pthread).
A representação das variáveis é ilustrado na Figura 6.1.
Para a condução deste experimento escolheu- se o ambiente de universidade.
O objetivo é avaliar o esforço dos estudantes na programação paralela utilizando as abordagens Led-PPOPP e Pthread.
Desta forma, esta seção demonstra o quão controlado é o experimento e quais são os indícios do ambiente em relação a representatividade dos resultados.
Dentro deste contexto, caracterizam- se:·
processo: Os participantes executaram o experimento num ambiente controlado (laboratório);·
participantes: O experimento foi conduzido com mestrandos e doutorandos do Programa de Pós-graduação em Ciência Computação (PPGCC) da Pontifícia Universidade do Rio Grande do Sul (PUCRS), os quais, como requisito deveriam estar cursando ou já ter cursado a disciplina de Programação Paralela;·
realidade: O problema estudado será um algoritmo conhecido no cenário de programação paralela, o qual será paralelizado por o estudantes durante a disciplina de Programação Paralela do PPGCC.
Esta escolha se deve por a aproximação do ambiente real sem que ocorra a intervenção do pesquisador;·
generalidade: O experimento é específico e só possui validade no escopo desta pesquisa.
Esta seção apresenta os detalhes para seleção dos indivíduos que participarão do experimento.
Como caracterizado anteriormente, escolheu- se a população acadêmica de nível de pós-graduação, pois é necessário que os participantes tenham conhecimento em linguagem C, conhecimentos básicos em modelagem de programas para ambientes multi-core, conhecimento básico nlinu e uma experiência em desenvolvimento de software paralelo.
O objetivo é que o experimento seja executado com programadores da área de processamento paralelo e distribuído.
Para garantir estes requisitos, aplicou- se um questionário de avaliação de conhecimentos dos participantes, podendo ser visto no Apêndice A. 1.
O critério utilizado para a seleção dos indivíduos foi através da conveniência, no caso, todos os que responderam o questionário eram convenientes a realizar o experimento, pois atendiam aos requisitos básicos.
Apesar de os vários requisitos necessários, conseguiu- se selecionar 20 indivíduos aptos.
Os critérios observados para o projeto do experimento foram:·
aleatoriedade: Atribuição do participante ao grupo que pertence (definição de dois grupos, os que usam primeiro Pthread e os que usam primeiro o método proposta);·
balanceamento: Cada abordagem utilizou a mesma quantidade de participantes e com níveis de conhecimento balanceados;·
bloqueio: Somente os indivíduos que atenderam aos requisitos participaram do experimento.
Em esta seção será indicado o tipo de experimento realizado e como foram montadas as unidades experimentais de acordo com os princípios escolhidos (aleatoriedade, balanceamento e bloqueio).
Para isso, definiu- se a seguinte denotação:·
Led-P P OP ms:
Representa a abordagem de programação Led-PPOPP;·
P thread:
Representa a abordagem de programação Pthread;
O projeto apresentado busca investigar se Led-P P OP ms possui o mesmo esforço que P thread.
Para isso, o tipo de experimento utiliza um fator com dois tratamentos pareados.
O fator, neste experimento, consiste no tempo que o participante levou para paralelizar um algoritmo e os tratamentos consistem nas abordagens Led-PPOPP e Pthread.
Desta forma, os participantes desenvolveram a aplicação com as duas abordagens, sendo que a execução foi aleatória e balanceada.
Através do questionário de avaliação de conhecimento, os indivíduos se autoavaliavam escolhendo uma das quatro opções oferecidas (zero, baixo, médio e alto).
A codificação das opções foram traduzidas em unidades numéricas, calculando- se o peso da opção (P O) escolhida para cada questão respondida, utilizando a formula onde P M X é o peso máximo definido, QOP a quantidade de opções pontuáveis (igual a 3 opção pontuáveis) e N O é o nível da opção que está representado na Tabela 6.2.
Esta tabela apresenta também os pesos resultantes para cada uma das opções e utilizados posteriormente na classificação dos níveis de conhecimento dos indivíduos (Tabela 6.4).
Tratando- se de um experimento com amostras pareadas é importante que a distribuição dos participantes esteja balanceada.
Em este sentido, optou- se por a criação de dois grupos com níveis de conhecimento equilibrados.
O processo iniciou- se classificando o conhecimento em razoável, bom, muito bom e ótimo, para os quais, foram determinados o peso máximo de classificação (P M X), utilizando a formula onde o T M A (maior total do conhecimento) e T M E (menor total do conhecimento) são obtidos através do somatório total dos pesos das questões.
O T O (igual a 4) representa o total de opções para definir a classificação do indivíduo e a opção é representada por OP na Tabela 6.3.
Com base no peso máximo de classificação (P M X), estipulou- se os intervalos para cada uma das opções de classificação.
E, utilizando o critério de bloqueio para determinar o peso mínimo aceitável.
Por exemplo, para um indivíduo ter a classificação &quot;Razoável», é necessário que o T ot (somatório total dos pesos das questões da Tabela 6.4) seja maior que 132 e menor ou igual a 257.
T ot\&gt; 257 e T ot\ $= 315 T ot\&gt; 315 e T ot\ $= 374 Ótimo (OP4) T ot\&gt; 374 e T ot\ $= 432 O resultado da classificação do nível de conhecimento é demonstrado na Tabela 6.4.
A maior parte dos indivíduos que participaram do experimento possuíram conhecimento entre ótimo e bom.
De o mesmo modo, identifica- se como é realizada a atribuição dos grupos, onde o nível de conhecimento é organizando de maneira decrescente e os indivíduos são escolhidos alternadamente, mantendo o balanceamento entre os grupos com a mesma quantidade de participantes.
A aleatoriedade no experimento e a eliminação do viés sobre uma determinada abordagem são garantidas através do modelo de execução do experimento ilustrado na Figura 6.2.
Primeiramente, os participantes do Grupo 1 começaram o experimento paralelizando um algoritmo com Led-P P OP ms e num outro dia utilizando a abordagem P thread.
Em o Grupo 2, as abordagens foram executadas inversamente.
O teste de hipótese, num contexto de um fator e dois tratamentos pareados, a literatura sugere o teste de significância denominado de Teste T pareado, caso for realizado um teste paramétrico, ou Wilcoxon, caso o teste não seja paramétrico.
O teste a ser aplicado será definido após a análise da normalidade (teste de Shapiro-Wilk e Kolmogorov--Smimov) e a variância dos dados obtidos por a execução do experimento (Teste de Levene).
Os instrumentos utilizados para realizar este experimento são:·
ambiente: Em a execução do experimento, cada participante utilizou uma máquina com SO Ubuntu Linux, em o qual estavam instalados a Led-PPOPP e a biblioteca Pthreads.
Para realizar o teste de hipótese, utilizou- se a ferramenta SPSS (Statistical Package for the Social Sciences) versão 14.0;·
guias: Os participantes puderam usar somente o material eletrônico fornecido:
Manual de utilização da biblioteca Pthread e da Led-PPOPms (ambos oferecidos apenas em suas execuções), podendo ser visto nos Apêndices A. 3 e A. 4.
Além disso, um código do algoritmo sequencial (Apêndice A. 5) é disponibilizado;·
métricas: Através de um formulário impresso (Apêndice A. 2), os participantes especificaram o horário de inicio e término, relatando também, o desempenho da aplicação paralelizada e a descrição do ambiente de execução.
Em busca de uma definição formal do experimento para com a validade durante a execução, esta seção busca apresentar diferentes tipos de validade, com o propósito de facilitar a replicação e dar maior credibilidade aos resultados obtidos.
Assim, a validade interna do experimento será avaliada por os seguintes critérios:·
histórico: A data do experimento foi definida no período em que os participantes não sofreram influências externas;·
maturação: Para que o interesse na condução do experimento se mantivesse, os participantes foram incentivados de forma positiva;·
seleção: Foi usado o critério de nivelamento dos participantes, formando- se grupos com níveis de conhecimento similares;·
Difusão: Durante a execução do experimento foi observado e evitado que os participantes se interagissem e influenciassem no resultado da pesquisa, restringindo- se o uso de celulares, internet e qualquer outro recurso que não seja a material eletrônico disponibilizado.
Para a validade externa do experimento, adotou- se um critério de escolha dos participantes.
Estes deveriam ter um perfil adequado, tendo conhecimento prévio em:
Linguagem C, modelagem de programas para ambientes multi-core, Linux e experiência em desenvolvimento de software paralelo.
A validade de construção é caracterizada por a avaliação de:·
explicação pré-operacional:
Uma explicação operacional do experimento foi realizada, esclarecendo a condução do experimento e apresentando as abordagens Led-PPOPP e Pthread;·
hipóteses: O experimento é realizado com humanos, isso possibilita que estes interagem com o experimento, podendo surgir novas hipóteses.
Para tanto, foram anotadas as observações para estudos posteriores, mas para este experimento foi mantido o foco;·
expectativas do condutor do experimento:
Antes da realização do experimento, foi realizada uma avaliação de todo material utilizado por um outro responsável (professor orientador), eliminando- se o viés do condutor da pesquisa.
Em a validade da conclusão são avaliados os fatores de:·
manipulação dos dados:
Os resultados dos experimentos foram manipulados por o pesquisador;·
confiabilidade das medidas:
As medidas foram objetivamente definidas;·
confiabilidade na implementação:
Diz respeito as diferentes formas que os participantes podem desenvolver a aplicação.
Em esta pesquisa não são dadas garantias de que o desenvolvimento de uma aplicação seja igual para todos os indivíduos, cada humano tem uma maneira de expressar e operacionalizar.
Entretanto, para que a implementação seja confiável, é necessário que a implementação paralela ofereça desempenho em relação a sequencial;·
configuração do ambiente:
O experimento foi executado num laboratório sem comunicação externa do ambiente (e.
g, celulares, internet, etc).
Apenas foram permitidos o uso de materiais disponibilizados.
Esta seção apresenta uma visão geral de como foi aplicado o experimento, atenuando- se nos seguintes fatores:·
Consenso com o experimento:
Durante o experimento, os participantes tiveram o embasamento necessário sobre o experimento (objetivos e metas).
Todos sabiam do que se tratava e ninguém foi obrigado a participar da pesquisa.·
Resultado sensitivos:
Em este experimento é possível que o resultado obtido influencie por questões de concorrência (i.
e, quem é o mais rápido).
Para isso, foi mantido o anonimato dos participantes na descrição dos resultados dos experimentos.
Antes de executar o experimento, realizou- se um pré-teste, onde aplicou- se o experimento para um indivíduo com características compatíveis, simulando o ambiente experimental.
Isso possibilitou a avaliação da documentação e a projeção aproximada do tempo necessário para executar o experimento, apontando alguns erros no processo experimental planejado, que posteriormente foram corrigidos.
Em o experimento, não estipulou- se um tempo limite para que o participante execute- o, sendo necessário concluir- lo.
Antes de começar o experimento, os participantes tiveram uma explicação geral sobre a abordagem e como deveriam proceder- lo, esta foi em torno de 15 a 20 minutos.
Durante a execução, em caso de dificuldades ou dúvidas, os participantes eram atendidos por o pesquisador, mas somente quando se tratava do processo e não sobre como resolver o problema proposto.
Em a coleta de dados utilizou- se um formulário preenchido por os participantes, para que o pesquisador não se envolva na definição dos resultados do experimento.
Como mediu- se o esforço na paralelização de um algoritmo, o critério avaliado era o tempo, assim, os participantes foram instruídos a começar a contagem do tempo e a execução, somente depois da explicação sob um aviso.
Para verificar se o participante realmente concluiu o experimento, atentou- se para que a versão paralela desenvolvida com uma determinada abordagem, avaliando a obtenção de desempenho e o resultado da computação.
Como garantia, o fomulário (Apêndice A. 2) ofereceu campos para especificar os tempos de execução e a saída do programa.
Experimento para Medição de Desempenho O experimento para medição de desempenho foi planejado usando uma abordagem estatística para validação dos resultados obtidos.
Em este sentido, esta seção apresenta a utilização da abordagem de intervalos de confiança para estimar uma média do tempo de execução (Seção 6.2.3), identificação do tamanho da amostra necessário para estimar uma média de tempo (Seção 6.2.4), os instrumentos utilizados para conduzir o experimento (Seção 6.2.5) e quais foram os aspectos para a execução.
A métrica relacionada com a segunda questão de pesquisa corresponde ao desempenho de uma aplicação paralela desenvolvida com as abordagens Led-PPOPP e OpenMP.
Para isso, será medido o tempo de execução calculando o Speed-Up (fator de aceleração), em o qual são analisados e comparados os ganhos em relação a aplicação sequencial para ambas as abordagens.
O cálculo do fator de aceleração (Sp) de um programa paralelo com tempo de execução paralelo (Tp) se dá por Sp $= Tp onde S representa o Speed-Up, T o Tempo de execução e p a quantidade de processos usados para resolver a computação.
Este conceito de aceleração é usado tanto para uma análise teórica de algoritmos baseados na notação assintótica quanto para avaliação prática dos programas paralelos O experimento de medição de desempenho irá investigar a hipótese informal HP2, associando com a métrica levantada.
Esta hipótese é aceita ou rejeitada com base nos indicadores numéricos dos resultados obtidos na paralelização de alguns algoritmos.
Para isso, será comparado o desempenho (Speed-Up) de 5 algoritmos/ programas paralelizados com a abordagem Led-PPOPP e OpenMP, analisando o comportamento ao executar com 2, 4, 6, 8, 10, 12, 14 e 16 núcleos.
Devido a natureza do experimento (não busca resultados precisos na comparação), a hipótese vai ser aceita ou rejeitada subjetivamente:
Uma estimativa pontual não fornece uma indicação de quanto ela é boa.
Para isso, os estatísticos criaram o intervalo de confiança, que consiste num intervalo de valores, em vez de apenas um único valor.
Com o nível de confiança é possível identificar uma taxa de sucesso de um procedimento experimental para calcular o intervalo de confiança.
Enfim, para este experimento foi usado um nível de confiança de 95%, para o qual, o valor crítico (z/ 2) é 1.96.
Com o desvio padrão conhecido é possível calcular a margem de erro para a média populacional (E), através da seguinte formula:
E $= z/ 2·.
O intervalo de confiança é estimado a partir de a margem de erro (E) calculada sobre a de execuções de um algoritmo, usando a seguinte formula:
O tamanho amostral está relacionado com a quantidade de execuções do algoritmo necessárias para determinar uma média.
Esta estimativa garante maior confiabilidade da média e diminui o tempo gasto em execuções desnecessárias.
Como lidou- se com o desconhecido, uma das alternativas é calcular- lo através de um estudo piloto, com base nos primeiros 31 valores amostrais selecionados aleatoriamente.
Desta forma, para cada algoritmo realizou- se aleatoriamente 40 formula z/ 2 2 n $= onde E é a margem de erro e o z/ 2 é 1.96 para 95% de nível de confiança.
Normalmente, o resultado do cálculo é um número não inteiro, devendo este, usar a regra de arredondamento (arredondando o valor de n para o número inteiro mais próximo).
Em conclusão, para as milhares de execuções possíveis do algoritmo, precisa- se apenas obter uma amostra aleatória de pelo menos n..
Ainda que, será obtido 95% de confiança de que a média de execuções do algoritmo(¯· Ambiente:
Realizou- se a execução do experimento uma máquina do Laboratório de Alto Desempenho (LAD) da PUCRS.
Esta é um Dell PowerEdge R610, possuindo dois processadores Intel Xeon Quad-Core E5520 de 2.27 GHZ com tecnologia Hyper--Threading.
A memória concentra- se numa arquitetura Em uma (Non-Uniform Memory Access), para a qual, cada processador possui 6 Gb.
Um sistema de armazenamento com HD de 146.8 GB, contendo o sistema operacional\&gt;· Recursos:
Foram usado os seguintes benchmarks desenvolvidos em C e paralelizados com OpenMP, disponibilizados por:
O código fonte foi extraído de.
­ Matrix Multiplication (MM):
Programa que cria um problema de multiplicação de matrizes C $= A B, o qual, está disponível em.·
Métricas: A coleta dos dados foi realizada a partir de o log de execução dos algoritmos.
O experimento foi executado levando em consideração os resultados sensitivos.
A execução é realizada por o pesquisador, sendo possível que ele influencie nos resultados.
Para isso, optou- se por usar algoritmos desenvolvidos por outro pesquisador com a abordagem OpenMP, evitando que o desempenho na exploração do paralelismo seja influenciado.
Este experimento consiste na medição de desempenho para identificar e comparar as diferenças entre as abordagens comparadas.
Então, paralelizou- se os mesmos programas de benchmark (Ei_ 2 D, FFT, Md, Mm, PN) atentando- se principalmente no uso das funcionalidade da LEDPPOPP a partir de a versão sequencial dos algoritmos.
Assim, para demonstrar os resultados da implementação desta linguagem, as versões paralelizadas estão anexados no Apêndice A. 6.
Os benchmarks forma executados aleatoriamente, evitando que qualquer influência do ambiente sobre os tempos de execução.
Assim como, os resultados da execução dos programas foram registrados em arquivos de log.
Verificando através destes, se os resultados obtidos eram corretos e, consequentemente, coletou- se o tempo de execução para calcular o fator de aceleração (Speed-Up) dos benchmarks em 2, 4, 6, 8, 10, 12, 14 e 16 núcleos.
Este capítulo apresenta a última etapa do processo de experimentação, realizando a análise e avaliação dos resultados obtidos na execução dos dois experimentos.
A Seção 7.1 discute os resultados obtidos na medição do esforço de programação paralela usando a abordagem Led-PPOPP e Pthread.
Em a sequência, a Seção 7.2 realiza uma avaliação do desempenho medido na paralelização de 5 algoritmos, comparando as diferenças entre a Led-PPOPP e o OpenMP.
Análise e Avaliação da Medição do Esforço de Programação Paralela Conforme o planejamento e a execução do experimento relatado na Seção 6.1, garantiu- se maior confiabilidade na obtenção dos resultados.
Isso porquê, num ambiente controlado é possível restringir fatores que poderiam influenciar e desvirtuar os participantes do foco experimental, simulando um ambiente real de trabalho.
O resultado da medição do esforço é demonstrado na Tabela 7.1.
Em ela, estão descritos:
O tempo que cada indivíduo levou para paralelizar o algoritmo de multiplicação de matrizes, o nível de conhecimento (conhecimento geral) e o peso de conhecimento dos participantes sobre as abordagens.
Nota- se que na classificação dos grupos, o nível de conhecimento ficou equilibrando, evitando que uma das abordagens obtivesse vantagem.
Também, identifica- se que a maioria dos participantes já programou com Pthread, enquanto com Led-PPOPP, nenhum de eles se quer conhecia esta abordagem.
Realmente, os resultados mostraram que o esforço tende a ser menor quando já paralelizada a aplicação com outra abordagem, pois ao utilizar a abordagem posterior, os participantes já conheciam o problema.
Portanto, a criação de grupos executando inversamente o experimento garantiu o balanceamento entre as abordagens, evitando que apenas uma seja beneficiada.
Embora uma abordagem seja beneficiada ao ser desenvolvida posteriormente, a maioria dos participantes obteve menos esforço paralelizando com a Led-PPOPP.
No entanto, encontrou- se uma exceção no experimento, o indivíduo 1 da Tabela 7.1 paralelizou mais rápido o problema com a abordagem Pthread.
Acredita- se que dois fatores contribuíram nesse acontecimento:
O problema já era conhecido para o participante e possuía um conhecimento bastante apurado de Pthread, sendo modesto ao preencher o questionário de avaliação de conhecimento.
Com os resultados obtidos de cada um dos participantes na execução do experimento é possível extrair diversas informações sobre o comportamento na paralelização usando um método estatístico para indicar tendências.
Alguns cálculos exigem a aplicação de formulas complexas, para evitar isso, usou- se a ferramenta SPSS de análise estatística.
Uma análise descritivas dos resultados é ilustrada na Figura 7.1.
A análise descritiva mostrou que em média o tempo gasto com Pthread foi maior do que com a Led-PPOPP, estando 95% confiante que o verdadeiro valor da média numa próxima experimentação com o algoritmo de multiplicação de matrizes, a média ficará entre Conforme foi previsto no planejamento do experimento, no teste da hipótese é preciso verificar se a distribuição dos resultados concentra- se numa curva normal, identificando qual abordagem deve ser utilizada para executar o teste.
A Figura 7.2 demonstra o resultado do teste de normalidade no SPSS, podendo concluir que a distribuição não é normal.
A normalidade é existente quando as abordagens Kolmogorov--Smimov e Shapiro-Wilk possuem o Sig.\&gt;
0.05. Em este experimento, os resultados de Pthread não estão distribuídos normalmente, indicando que o teste de hipótese deve ser realizado usando a abordagem Wilcoxon.
O teste de Wilcoxon baseia- se na comparação das diferenças de scores de duas abordagens, ranqueando- as em ranks positivos e negativos.
Assim, o resultado do cálculo dos ranks é demonstrado na Figura 7.3, obtendo apenas um negativo e 19 favoráveis, tendenciando que o esforço com Pthread foi maior que com Led-PPOPP (b Pthread\&gt; Led_ PPOPP).
Para confirmar se o esforço é significativamente diferente entre as abordagens, é necessário que o nível de significância (Sig.)
seja menor que 0.05.
O cálculo realizado por o SPSS é demonstrado na Figura 7.4, podendo concluir que o esforço é significativamente diferente.
Logo, rejeita- se a hipótese nula e baseando- se no resultado das médias, aceita- se a hipótese alternativa H1, a qual, afirma que o esforço é maior paralelizando com Pthread do que com a Led-PPOPP.
Este experimento demonstrou uma grande vantagem da Led-PPOPP em relação a o esforço na paralelização do algoritmo de multiplicação de matrizes, tendenciando maior facilidade ao utilizar esta abordagem.
Como os participantes não conheciam esta abordagem, mas mesmo assim conseguiram desenvolver- la mais rápido, conclui- se que, a aprendizagem e a programação da aplicação exigiram menos esforços com a Led-PPOPP do que programar tendo um conhecimento básico sobre Pthread.
O objetivo foi disponibilizar uma interface num contexto de alto nível (padrão de programação paralela) facilmente interpretada, utilizando a biblioteca Pthread para explorar o paralelismo da arquitetura.
Isso alavancou a comparação do esforço com esta biblioteca, pois foi possível identificar o quanto a interface da Led-PPOPP reduziu o esforço do programador na paralelização de uma aplicação.
Análise e Avaliação da Medição de Desempenho Em a medição do desempenho são observados o Speed-Up (desempenho) e a eficiência (eficiência da aplicação em relação a o uso dos processadores) que uma aplicação consegue obter na exploração de paralelismo.
Mesmo que o objetivo principal deste trabalho seja diminuir o esforço na programação paralela, é necessário que as aplicações possuam um desempenho aceitável, obtendo vantagem da arquitetura paralela.
Portanto, realizou- se uma avaliação da Led-PPOPP identificando se existem grandes perdas de desempenho em relação a uma abordagem otimizada.
O experimento buscou um nível de confiança de 95% nos resultados obtidos.
Sendo assim, para quantidade de execuções necessárias (n) para estimar a média.
Consequentemente, com as médias efetivas, os intervalos de confiança (para as médias dos tempos de execuções são calculados.
O experimento utilizou 5 aplicações de benchmark paralelizadas com o OpenMP por.
Para a análise do desempenho, optou- se por aplicações com características diferentes e que possibilitam a implementação do padrão Mestre/ Escravo.
Desta forma, definiu- se uma entrada padrão para cada um dos respectivos programas:·
Ei_ 2 D:
Estima uma integral sobre uma área retangular 2D usando a regra de quadrado do produto.
O tamanho da área definido é de nx $= 91768 por ny $= 91768.
Esta aplicação pode ser praticamente toda paralelizada.·
FFT: Este programa realiza uma transformada rápida de Fourier num vetor complexo de dados.
Executando com interações de tamanho nits $= 1000 dividindo este valor por 10 a cada 4 interações até completar ln2_ max $= 25 (log na base 2 de n).
A maior parte da computação é sequencial, sendo pouco paralelizável.·
Md: O programa efetua uma simulação de dinâmica molecular.
Efetuando com np $= 4000 partículas em step_ num $= 4 etapas com tempo de dt $= 0.000100.
Boa parte desta computação pode ser paralelizada.· Mm:
Programa que cria um problema de multiplicação de matrizes densa.
Utilizando matrizes de ordem n $= 1800.
Este programa pode ser praticamente todo paralelizado.·
PN: Programa que encontra os números primos num vetor de 1 até N $= 500000.
O paralelismo não é facilmente explorado nesta aplicação.
Para não influenciar nos resultados, assumiu- se que os benchmarks utilizando a abordagem OpenMP foram implementados da melhor maneira, realizando a experimentação com 2, 4, 6, 8, 10, 12, 14 e 16 núcleos.
Os gráficos da Figura 7.5 demonstram os resultados obtidos de todos os benchmarks.
O FFT teve um Speed-Up e uma eficiência muito abaixo do ideal.
O mesmo acontece com o PN, entretanto, seu desempenho é melhor se comparado com o FFT.
Em relação a os programas Ei_ 2 D, Md e Mm, a curva manteve- se próxima do ideal até 8 núcleos e, posteriormente, observa- se uma queda no desempenho a partir de 10 núcleos.
Acredita- se que o uso de núcleos lógicos afetou o desempenho destes benchmarks, pois após a queda, a curva do Speed-up mantém- se numa curva crescente até 16 núcleos.
Além disso, se utilizadas técnicas de afinidade de memória para melhor explorar a arquitetura Em uma do ambiente experimentado, poderiam ser obtidos melhores resultados para o algoritmo Mm.
Todos os benchmarks foram testados com diferentes granularidades, ajustando o tamanho do grão para obter o melhor desempenho possível.
No caso de o FFT, como dito anteriormente, seu código é pouco paralelizável, identificando que o seu comportamento foi semelhante (baixo desempenho) ao obtido em outros trabalhos, como por exemplo em.
O mesmo acontece com o algoritmo PN, pois o paralelismo não é facilmente explorado.
Em a comparação de desempenho do Ei_ 2 D também é analisado o quão eficiente é o algoritmo na utilização dos recursos de paralelismo da arquitetura.
Normalmente, o tempo de execução de um algoritmo apresenta um comportamento irregular, pois fatores como ambiente de execução e a computação podem influenciar na medição do desempenho.
Para garantir maior confiabilidade dos testes, utilizou- se a abordagem estatística de nível de confiança, conforme descrito na Seção 7.2.
Os resultados do experimento para o Ei_ 2 D estão descritos na Tabela 7.2.
A estimativa do tamanho da amostra necessário (n) para estimar a média do tempo de execução abordou um nível de confiança de 95%, calculado a partir de as 40 primeiras execuções nas versões Led-PPOPP e OpenMP.
A quantidade de execuções realizadas para estimar a média do tempo (Tempo) é representada por N.
Além disso, estão tabulados o Speed-Up, a eficiência e o intervalo de confiança.
Por meio destes testes, pode- se perceber que os algoritmos não possuem o mesmo comportamento em cada um dos conjuntos de núcleos testados, tornando- se necessário estimar o n em execuções.
Os valores descritos na Tabela 7.2 de e E estão relacionados ao que foi obtido com N execuções do Ei_ 2 D para Led-PPOPP e OpenMP.
Em a experimentação da Led-PPOPP realizada foi implementado apenas o núcleo principal com o bloco escravo fora de o bloco mestre (código fonte disponível em), apresentando bons resultados e parecidos aos obtidos com OpenMP.
A versão OpenMP com conjunto de núcleos menores de 8 obteve desempenho e eficiência melhores que a versão paralelizada com a Led-PPOPP.
No entanto, com 14 e 16 núcleos a Led-PPOPP foi melhor.
Mesmo assim, o desempenho esteve aproximado em todos os conjuntos de núcleos testados, conforme pode ser visto no gráfico da Figura 7.6.
A queda provocada no desempenho a partir de 10 núcleos está associada à utilização dos núcleos lógicos do ambiente arquitetural.
Já a vantagem obtida do OpenMP em relação a Led-PPOPP nos primeiros conjuntos de núcleos, pode estar associada à divisão do trabalho, pois não foi implementado um tratamento otimizado para o balanceamento de carga na Led-PPOPP, dividindo o trabalho apenas por a quantidade de escravos.
A implementação paralela do FFT com a Led-PPOPP necessitou o uso de subnúcleos para efetuar a paralelização das rotinas que foram implementadas em funções globais do algoritmo, sendo construções com escravos processando independentemente, ou seja, sem ajuda do Mestre (código fonte disponível em).
Os resultados da paralelização do algoritmo FFT utilizando OpenMP e Led-PPOPP são demonstrados na Tabela 7.3.
Como visto anteriormente na Seção 7.2.1, este algoritmo não é facilmente paralelizado com OpenMP, mostrando resultados ruins a partir de 4 núcleos.
O mesmo aconteceu para a versão com Led-PPOPP, sendo apenas melhor em relação a o OpenMP com 2 núcleos.
A representação gráfica do desempenho obtido pode ser visto na Figura 7.7.
Embora as duas abordagens possuem resultados não satisfatórios, a eficiência na utilização do paralelismo disponível e o desempenho são aproximados para todos os conjuntos de núcleos testados.
O algoritmo Md é quase inteiramente paralelizável.
A versão implementada com Led-PPOPP necessitou o uso de uma construção de subnúcleo, além de o núcleo principal (código fonte disponível em).
Em função de isso, acredita- se os resultados não foram fortemente prejudicados, conforme demonstram os resultados da Tabela 7.4.
Em a versão Led-PPOPP a utilização de núcleos lógicos também prejudicou o desempenho da aplicação, conforme é ilustrado no gráfico da Figura 7.8.
Constatou- se que o desempenho e a eficiência foi melhor utilizando o OpenMP, mas os resultados ficaram aproximados utilizando as duas abordagens.
A paralelização efetuada com a Led-PPOPP também obteve um desempenho satisfatório na aplicação de Mm..
Os resultados são comparados graficamente na Figura 7.9, demonstrando que as medidas de desempenho e eficiência foram aproximadas.
O OpenMP se mostrou mais favorável com 4, 6 e 8 núcleos.
Em o restante, a Led-PPOPP obteve maior vantagem sobre a arquitetura.
Novamente, como aconteceu nos demais algoritmos, o desempenho foi prejudicado por a utilização de núcleos lógicos a partir de 10 núcleos.
A Tabela 7.5 apresenta em mais detalhes os resultados obtidos.
Com a Led-PPOPP, a implementação do Mm foi realizada compartilhando os trabalhos escravos dentro de o bloco mestre (disponível em).
Em teoria, se o trabalho não for balanceado corretamente o desempenho pode ser prejudicado.
Mesmo sem possuir um balanceamento otimizado, a Led-PPOPP se mostrou melhor do que o OpenMP no algoritmos Mm, obtendo o desempenho e a eficiência melhor na maioria dos conjuntos de núcleos testados.
Porém, a execução da versão paralelizada com Led-PPOPP se mostrou mais irregular, sendo necessário uma amostra maior para garantir 95% de confiança.
A maior parte do código da aplicação de PN é sequencial, onde a exploração do paralelismo se torna mais difícil.
Em a paralelização com a Led-PPOPP utilizou- se uma construção simples compartilhando a carga dos escravos com o Mestre (código fonte está disponível em).
Embora os resultados obtidos tenha sido favoráveis para a versão paralela com OpenMP, acredita- se que a implementação com os escravos, compartilhando a carga com o mestre não seja um fator prejudicial na obtenção do desempenho.
Isso porque o desempenho e a eficiência obtidos com as duas abordagens ficaram bem próximos uns dos outros, como pode ser visto na representação gráfica da Figura 7.10.
Em a Tabela 7.6 é possível constatar claramente uma pequena vantagem no desempenho da versão OpenMP em relação a Led-PPOPP a partir de 4 núcleos, bem como a eficiência na utilização dos núcleos.
A diversidade das aplicações possibilitou a utilização das funcionalidades fornecidas de núcleo e subnúcleo do padrão Mestre/ Escravo.
de este modo, as construções utilizando blocos escravos dentro ou fora de o bloco mestre também foram possíveis.
No entanto, a homogeneidade das aplicações em isolar a seção crítica evitou o uso da primitiva de proteção de dados.
Este experimento avaliou e comparou o desempenho e a eficiência das aplicações de benchmark (Ei_ 2 D, FFT, Md, Mm e PN) paralelizadas com a Led-PPOPP.
O objetivo da medição foi analisar se abstração criada consegue explorar o paralelismo sem grandes perdas de desempenho comparado a uma solução otimizada com esta finalidade.
Então, calculou- se os ganhos de desempenho (SpeedUp) obtidos em relação a o OpenMP.
A porcentagem de ganho (G) em relação a o OpenMP é calculada com a seguinte formula:
Sp OpenM P onde Sp Led_ P P OP P é o Speed-Up obtido com a paralelização usando Led-PPOPP e Sp OpenM P é o Speed-Up obtido com a versão OpenMP.
O resultado da diferença de desempenho em relação a o OpenMP é apresentado na Tabela 7.7, apresentando um cenário favorável para o OpenMP na maioria dos casos de testes.
Somente no benchmark Mm a Led-PPOPP obteve alguns resultados favoráveis.
O FFT é um caso isolado, obtendo maior quantidade de situações em que a diferença é significativa entre as abordagens.
Isso acontece porque as medidas de Speed-Up obtidas são baixas, então, qualquer diferença no desempenho representa bastante no cálculo da porcentagem.
Nota- se que as diferenças não foram significativas na maioria dos testes realizados.
Logo, é possível validar a hipótese HP2, pois os resultados demostraram que o desempenho da Led-PPOPP não foi significativamente diferente em relação a o obtido com OpenMP na maior parte das aplicações experimentadas.
Este trabalho apresentou uma proposta de uma Linguagem Específica de Domínio de Programação Paralela Orientada a Padrões Paralelos (Led-PPOPP), realizando um estudo de caso com o padrão Mestre/ Escravo para arquiteturas multi-core.
O primeiro passo foi a construção da interface de programação (interface da linguagem).
Desenvolveu- se então um analisador para detectar erros na declaração das funcionalidades, bem como introduzir os conceitos de núcleo e subnúcleo para o padrão Mestre/ Escravo baseando- se no modelo PPOPP proposto.
Posteriormente, um gerador de código paralelo implementando o comportamento do padrão em linguagem C usando Pthread POSIX fora criado, envolvendo questões de divisão do trabalho e exploração do paralelismo.
O segundo passo foi a validação do estudo de caso para a Led-PPOPP.
Utilizou- se uma metodologia de experimentos para a medição do esforço de programação paralela e para a medição de desempenho, cujo objetivo era reduzir o esforço de programação sem que ocorressem grandes perdas de desempenho.
Em virtude de isso, o esforço foi medido com estudantes, coletando o tempo necessário para paralelizar uma aplicação com as abordagens Pthread e Led-PPOPP.
Por outro lado, na medição de desempenho foram paralelizadas 5 aplicações de benchmark com a Led-PPOPP, para que então, fossem comparadas com as mesmas aplicações utilizando OpenMP.
De esta maneira, as seguintes questões de pesquisa foram respondidas:
Em relação a uma das soluções disponíveis atualmente na programação paralela?
Diante de o impacto no desenvolvimento de software, o objetivo foi identificar se a Led-PPOPP consegue reduzir o esforço de programação paralela em relação a biblioteca Pthread.
Os resultados mostraram que o esforço com Pthread é, em média, maior que 50% para paralelizar o algoritmo de multiplicação de matrizes.
Com isso, a tendência é que desenvolver com Led-PPOPP requer menos esforço do programador do que utilizar Pthread.
Para o impacto no desempenho de uma aplicação, buscou- se verificar se a Led-PPOPP possui uma diferença significativa em relação a o uso do OpenMP.
Os resultados mostraram que nas 5 aplicações de benchmark, na maioria dos casos o desempenho ficou favorável para o OpenMP, mas o desempenho não foi significativamente diferente na maioria dos programas.
Portanto, a tendência é que algoritmos paralelizados com a Led-PPOPP forneçam um desempenho próximo a o esperado com OpenMP.
Mesmo que o desempenho na maior parte das aplicações experimentadas tenha sido favorável ao OpenMP, os objetivos foram alcançados.
O trabalho demonstrou que é possível reduzir o esforço de programação paralela sem comprometer o desempenho das aplicações que utilizam a Led-PPOPP.
A Seção 8.1 descreve as contribuições desta pesquisa e a Seção 8.2 descreve os trabalhos futuros.
Contribuições As principais contribuições deste trabalho são:·
PPOPP. Em esta dissertação criou- se um modelo para programação paralela orientada a padrões paralelos.
A definição conceitual permite que outras interfaces possam utilizar esta abordagem.·
Led-PPOPP. Interface de programação disponível para programação paralela, possibilitando a paralelização de algoritmos em arquiteturas multi-core usando o padrão Mestre/ Escravo.·
A hipótese afirma que programar com a Led-PPOPP reduz o esforço de programação em relação a a biblioteca Pthread.
A hipótese foi comprovada.·
A hipótese afirma que o desempenho da Led-PPOPP não é significativamente diferente em relação a a biblioteca OpenMP.
A hipótese foi comprovada.
Trabalhos Futuros Considerando os benefícios proporcionados neste trabalho, utilizando o modelo de programação PPOPP, identificam- se os seguintes trabalhos futuros:·
Otimizar a exploração do paralelismo da Led-PPOPP, implementando opções de balanceamento de carga e escalonamento;·
Otimizar o analisador de código do compilador da Led-PPOPP, utilizando técnicas de análise de código;·
Comparar o esforço de programação da Led-PPOPP com outras abordagens de programação paralela;·
Comparar o desempenho da Led-PPOPP em outras aplicações e com outras abordagens;·
Medir a complexidade e o desempenho em função de a utilização de subnúcleos de padrões paralelos;·
Implementar outros padrões paralelos na Led-PPOPP (por exemplo, pipeline e divisão e conquista);·
Realizar um estudo para a Led-PPOPP explorando o paralelismo em arquiteturas híbridas.
