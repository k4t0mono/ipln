A Internet tem sido utilizada, desde seu surgimento, para transmissão confiável de dados sem garantias de atraso, variação de atraso ou largura de banda.
Contudo, o tráfego multimídia de aplicações que estão surgindo na Internet possui características e requisitos de QoS (Qualidade de Serviço) diferentes do tráfego convencional de dados discretos (texto e imagens).
Vários abordagens têm sido consideradas para tentar garantir QoS.
Entre essas, o desenvolvimento de aplicações com capacidade de modificar seu comportamento conforme o desempenho oferecido por a rede.
Dentro deste contexto, este trabalho apresenta o desenvolvimento de uma Camada de Adaptação de QoS para incorporar QoS em aplicações multimídia, visando melhorar a qualidade dessas aplicações no cenário de operação atual da Internet.
A Camada possui funções de monitoração de QoS através de pacotes de controle RTCP (Real Time Control Protocol) e adaptação de QoS através da aplicação de políticas adaptativas.
Como resultado, uma Application Programming Interface (API) foi desenvolvida.
Esta API oferece funções para evitar a degradação das mídias que compõe a aplicação multimídia em cenários sem reserva de recursos como a Internet.
Palavras-chave: Aplicações multimídia, Qualidade de Serviço (QoS), Camada de Adaptação de QoS, Monitoração, Adaptação, Internet.
O contínuo crescimento de aplicações multimídia na Internet, as quais transmitem áudio e vídeo, tem despertado interesse não só de pesquisadores, como também de profissionais da área de redes de computadores e usuários em geral.
Entusiasmo esse justificado por a promessa de aplicações de grande utilidade como educação a distância, rádio e TV sob demanda, videoconferências, entre outros.
Aplicações como essas trazem novos requisitos de serviços normalmente expressos como Qualidade de Serviço (QoS).
O conceito de QoS é utilizado para especificar o conjunto de requisitos dessas aplicações através de parâmetros (atraso, variação do atraso, largura de banda e taxa de erros).
Atender a esses requisitos é uma das principais razões de pesquisa na área de Qualidade de Serviço.
Ao longo de os últimos anos, uma quantidade considerável de pesquisas têm sido realizadas em torno de trabalhos relacionados à QoS.
Em a comunidade Internet esforços tem sido realizados para oferecer o modelo de Serviços Integrados (IntServ), o qual estende os reSerVation Protocol, e o modelo de Serviços Diferenciados (DiffServ), em o qual os pacotes que trafegam por um domínio que implementa esta noção recebem tratamento diferenciado de acordo com sua necessidade.
Além disso, protocolos também têm sido desenvolvidos para assegurar serviços multimídia;
Em especial os protocolos Real Time Transport Protocol (RTP), para transporte de dados;
Real Time Control Protocol (RTCP), para controlar informações de feedback dos recebedores dos dados;
Real Time Streaming Protocol (RTSP), para controle durante a transferência de dados com propriedades de tempo real;
Session Initiation Protocol (SIP), para estabelecer, modificar e terminar sessões multimídia interativas entre usuários sobre a Internet.
Em a comunidade acadêmica trabalhos também vêm sendo desenvolvidos para suportar a noção de QoS com ou sem reserva de recursos.
Apesar desses esforços em oferecer garantias de QoS fim-a-fim, buscando melhorar a atual arquitetura Internet, seja estendendo seu modelo incorporando reserva de recursos, oferecendo serviços diferenciados, ou ainda, provendo novos protocolos e novas arquiteturas de comunicação, ainda existem vários problemas que contribuem para que os requisitos de QoS das aplicações multimídia não sejam oferecidos de forma satisfatória.
Exemplos incluem heterogeneidade dos sistemas finais fazendo com que uma mesma aplicação se comporte de maneira diferente dependendo da máquina onde é executada;
Oferecimento de reserva de recurso &quot;tudo ou nada», em o qual, ou os recursos necessários para uma aplicação são oferecidos, ou nada é oferecido;
Probabilidade de reservas não serem suportadas em grandes partes da Internet ainda que por algum tempo;
Reserva de recursos ser cara em termos de troca de mensagens e possuir tarifação agregada.
Uma possibilidade para a aplicação, frente a os aspectos considerados, é ajustar seu funcionamento às condições variáveis que a rede de comunicação de dados oferece, adaptando- se, assim, ao que lhe é oferecido.
Vários trabalhos encontrados na literatura utilizam- se dessa mesma abordagem, como em Bolot, Busse, Hutchison, Marakby, Sisalem, entre outros.
Com isso, a responsabilidade em oferecer QoS para a aplicação multimídia passa a ser, também, do desenvolvedor da mesma.
Isso é uma dificuldade para desenvolvedores de aplicações em QoS são necessárias para ocultar das aplicações a complexidade em administrar e controlar QoS.
Desta forma, o trabalho aqui apresentado visa tratar os novos requisitos das aplicações multimídia em cenário adaptativo, como é o caso da Internet atual.
O objetivo principal é compensar alguns dos efeitos resultantes dos problemas encontrados na Internet relacionados ao suporte de QoS para aplicações multimídia através do desenvolvimento de uma Camada de Adaptação de QoS.
A Camada foi desenvolvida e apresenta como resultado uma API que permite incorporar QoS em aplicações multimídia facilitando, dessa forma, a tarefa do desenvolvedor da aplicação na realização de tal atividade.
A API proporciona interfaces, classes e métodos que permitirão ao desenvolvedor incorporar numa aplicação multimídia funcionalidades de monitoração de QoS do tráfego dos dados, bem como, adaptação da aplicação a qualidade recebida por a rede, fazendo com que esta se ajuste ao seu comportamento.
Normalmente, essas aplicações são chamadas &quot;network-- aware», justamente por o fato de adaptar seu funcionamento as variações de desempenho do ambiente de rede.
Essas funcionalidades também podem ser vistas como um serviço que a Camada de Adaptação de QoS disponibiliza para a Camada de Aplicação da Arquitetura Internet.
Para tanto, a API poderá ser utilizada em aplicações Java que utilizem o protocolo RTP para transporte de seus dados (Real Time Transport Protocol) e RTCP (Real Time Control Protocol) para troca de informações de controle entre fonte e destino, sendo que a utilização desses protocolos é um requisito fundamental para a sua efetiva operação.
Considerou- se em especial comunicação unicast, mas a API pode ser utilizada também para comunicação multicast.
O trabalho aqui apresentado é organizado como segue.
Em o segundo capítulo, conceitos gerais de multimídia, aplicações, características e requisitos do tráfego multimídia são apresentados.
Em o capítulo 3 são descritos os protocolos para o oferecimento de serviços multimídia na Internet;
Protocolos RTP, RTSP e SIP.
Qualidade de Serviço necessária às aplicações multimídia é discutida no próximo capítulo, sendo que, especial ênfase é despendida em demonstrar como QoS pode ser vista de forma diferente por o usuário final, por a aplicação, sistema final e rede de comunicação.
Em o capítulo 5, alguns trabalhos relacionados ao oferecimento de Qualidade de Serviço com e sem reserva de recursos na Internet são explanados.
Em o capítulo 6 a Camada de Adaptação de QoS é apresentada.
Discute- se as principais motivações para seu desenvolvimento e apresenta- se sua arquitetura, seu funcionamento, bem como aspectos de implementação dos módulos pertencentes a Camada de Adaptação de QoS.
A aplicação de validação também é apresentada juntamente com a metodologia de experimentação adotada para validar a API oferecida.
As políticas de adaptação responsáveis por o ajuste de uma aplicação multimídia particular ao comportamento da rede e os resultados dos experimentos realizados se seguem.
Finalmente, algumas considerações finais sobre o trabalho e sobre sua continuidade são explanadas.
Introdução Sistemas multimídia tem revolucionado os atuais estilos de vida, especialmente aqueles aspectos relacionados com a comunicação humana.
Esses sistemas podem criar um mundo eletrônico em que as pessoas podem comprar, trabalhar, ou aprender em casa, assistir programas de vídeo sob demanda, acessar livrarias digitais on-line de um desktop, e assim por diante.
Os avanços tecnológicos nos computadores, redes de alta velocidade, compressão de dados estão acelerando a realização de tais sistemas e também atraindo a atenção da sociedade como um todo, particularmente de pesquisadores no campo da tecnologia da informação.
Integrar diferentes tipos de mídias como texto, áudio e vídeo num vasto domínio de aplicações é uma das principais tendências de nossa época.
Desta forma, este capítulo discute os conceitos de multimídia, algumas aplicações, bem como características e requisitos de tráfego dos diferentes tipos de mídia.
Multimídia Literalmente, multimídia é apenas duas ou mais mídias.
Por exemplo, um livro contém duas mídias:
Texto e imagens (figuras e gráficos).
Quando nos referimos a multimídia, ela geralmente significa a combinação de duas ou mais mídias contínuas, também chamadas mídias dinâmicas ou isócronas.
Em a prática, as duas mídias são geralmente áudio e vídeo, que nada mais é do que som mais o movimento de figuras.
Assim, multimídia denota a ação de tratamento integrado de alguma informação representada como dados de mídia contínuos (tal como áudio e vídeo) tão bem quanto alguma informação codificada como dados de mídia discretos (tal como texto e imagens).
O termo &quot;tratamento «refere- se a ação de captura, processamento, comunicação, apresentação e/ ou armazenamento.
Dados de mídia contínuos ou dependentes do tempo (áudio e vídeo) são aqueles em que o tempo faz parte da semântica da apresentação, ou seja, seus significados dependem da taxa em que são apresentados.
Por exemplo, um vídeo possui uma seqüência de quadros que deve ser apresentado, cada um de eles, com uma certa duração que deve ser preservada para obter uma apresentação com qualidade.
Por outro lado, dados de mídia discretos não possuem esta relação no tempo, sendo que, tradicionalmente são utilizados em documentos impressos.
Contudo, a utilização de mídias discretas (textos e gráficos) ainda governa a computação tradicional, enquanto a integração de mídias contínuas nos ambientes computacionais cria uma nova complexidade quanto a o processamento de seus dados.
Um dos problemas quanto a complexidade no processamento está no tratamento da sincronização entre as mídias, desejada principalmente em aplicações que utilizam- se de áudio e vídeo, e outro é com relação a o grande volume que os dados multimídia possuem.
Uma das soluções utilizadas para minimizar o último problema é o uso das técnicas de compactação de dados que visam reduzir o volume dos dados pois, caso contrário, um grande espaço em disco seria requerido, além de que a largura de banda necessária para a rede transmitir esse tipo de dado não seria suficiente caso técnicas desse tipo não fossem desenvolvidas.
Quanto a sincronização, é desejado que esta seja oferecida por algum mecanismo específico para este fim, principalmente em transmissões de áudio e vídeo.
Em as próximas seções, compactação e sincronização são abordadas mais detalhadamente.
Compactação de dados A transmissão de material multimídia não compactado, normalmente, não é viável devido a o grande volume que estes dados possuem.
Contudo, graças a esforços de pesquisa despendidos em técnicas de compactação, a transmissão de dados de mídia contínuos tornaram- se amplamente possíveis.
Em esta subseção dará- se- uma visão superficial sobre as técnicas de compactação de dados, apesar de sua riqueza, haja vista que o foco principal deste trabalho não diz respeito a este assunto.
Sistemas de compactação exigem dois algoritmos:
Um para a compactação dos dados na origem e outro para descompactação no destino.
Também chamados de algoritmos de codificação e decodificação, respectivamente.
Os algoritmos de codificação e decodificação possuem algumas diferenças para muitas aplicações, por exemplo, um filme só será codificado uma vez (ao ser armazenado num servidor de vídeo), mas será decodificado milhares de vezes (quando for visto por o usuário).
Essa assimetria significa que é aceitável que o algoritmo de codificação seja lento e necessite de componentes de hardware de alto custo, desde que o algoritmo de decodificação seja rápido e não precise de hardware muito caro.
Já em videoconferência, onde os recursos de multimídia são de tempo real, a codificação lenta é inaceitável.
A codificação deve acontecer automaticamente em tempo real.
Portanto, aplicações multimídia em tempo real utilizam diferentes algoritmos ou parâmetros.
Uma segunda assimetria é que o processo de codificação/ decodificação não precisa ser recíproco, ou seja, é aceitável que o sinal do vídeo seja ligeiramente diferente do original depois da codificação e da decodificação.
De essa forma, quando a saída decodificada não é exatamente igual à entrada original, o sistema é dito com perda (lossy) trazendo grandes vantagens com respeito a taxa de compactação possível.
Se a entrada e a saída são iguais, o sistema é dito sem perda (lossless).
Algumas técnicas de compactação produzem fluxos a uma taxa de bits constante, enquanto outras produzem fluxos a uma taxa de bits variável.
Os esquemas de compactação podem ser divididos em duas categorias:
Codificação por entropia e codificação na origem.
Em a codificação por entropia (entropy enconding) as cadeias de bits são tratadas sem levar em consideração seu significado.
É uma técnica sem perda, genérica, e totalmente reversível que pode ser aplicada a todos os dados.
Como uma subdivisão desta, destaca- se a codificação run-length, que é uma das técnicas marcador especial, seguido de um símbolo que identifica a operação, seguido do número de vezes que ela ocorreu.
Como exemplo, considere string Se A for usado como marcador a string codificada passa a ser 310320AA094567 A1134 A0761, onde as partes em negrito da cadeia de bits ilustram o que foi modificado na string.
Em sinais de áudio, o silêncio é quase sempre representado por o processamento (run) de zeros.
Enquanto que em sinais de vídeo, a mesma cor é processada várias vezes em superfícies planas, paredes, cenários com céu.
Em a codificação na origem (source encoding), a qual aproveita as propriedades dos dados para proporcionar maior compactação, os dados originais são processados distinguindo o dado relevante do dado irrelevante.
Depois que os dados irrelevantes forem removidos o dado original é comprimido.
Como exemplos dessa técnica pode- se destacar:
DPCM (Differencial Pulse Code Modulation), DCT (Discrete Cosine Transformation), DWT (Discrete Wavelet Transform).
De entre os vários padrões de compactação de dados encontramos JPEG (Joint Photographic Experts Group) e MPEG (Motion Picture Experts Group).
O primeiro, o padrão JPEG, para compressão de imagens estáticas com tons contínuos (por exemplo, fotografias) foi desenvolvido por especialistas em fotografia que trabalharam em conjunto com sociedades Standard Organization e IEC, sendo definido por o Padrão Internacional 10918.
O segundo padrão, MPEG é utilizado para compressão de vídeos, sendo um padrão internacional desde banda e contém mais redundância do que áudio (som).
O primeiro padrão MPEG que surgiu foi o MPEG-1, utilizado para armazenar filmes em CD-ROM, CD-I e no formato CD-vídeo;
Destina- se a videoconferências.
Outro padrão da família MPEG é o MPEG-2, o qual originalmente foi projetado para comprimir vídeo com qualidade de broadcast numa faixa de 4 à 6 Mbps.
Mais tarde, MPEG-2 foi expandido para suportar mais altas resoluções, incluindo a tecnologia HDTV (High Definition TeleVision).
O padrão MPEG-3 existiu e destinava- se a HDTV, mas foi cancelado e HDTV foi adicionado ao MPEG-2.
Atualmente já existem outros padrões MPEG propostos, como o MPEG-4 utilizado para televisão digital, aplicações gráficas interativas e multimídia interativa.
Sincronização Sincronização multimídia tenta assegurar a ordem temporal desejada entre um conjunto de objetos multimídia em cenário multimídia, o qual denota as semânticas temporais de uma sessão multimídia apud.
Assim, sincronização pode ser vista como a apresentação correta no tempo de dados multimídia (áudio e vídeo) pertencentes a uma aplicação.
Os objetivos de mecanismos de sincronização multimídia são a preservação da continuidade durante a reprodução de pedaços de mídia dentro de uma única mídia contínua, e as dependências temporais desejadas entre múltiplos objetos de dados (as mídias), sendo que interações do usuário são permitidas.
A dependência temporal pode ser explícita e implícita.
Para dependência implícita, a relação do tempo é capturada no tempo de aquisição da mídia.
Um exemplo é a sincronização labial, a qual refere- se aos requisitos de que a voz deve acompanhar o movimento dos lábios de quem está falando.
Dependência explícita significa que a relação do tempo é criada explicitamente.
Um slide com figuras e anotações de texto é um exemplo.
De acordo com a granularidade da sincronização, existem três níveis de sincronização Sincronização Intramedia:
Preserva as relações temporais entre frames consecutivos e a continuidade da reprodução dentro de um único stream de mídia.
Relações temporais definem posições temporais relativas entre e no interior dos componentes de um documento, ou seja, definem sincronização entre eventos de uma apresentação.
Sincronização Intermedia:
Coordena os diferentes streams de mídia de modo a adquirirem as relações temporais desejadas entre eles.
A sincronização intermedia pode, além disso, ser categorizada como sincronização contínua (ou sincronização ao vivo) preservando as relações temporais implícitas, e sincronização dirigida a eventos (ou sincronização sintética), a qual mantém as relações temporais explícitas especificadas.
Sincronização Interparty: Mantém sincronização intermedia e/ ou intramidia entre participantes diferentes em localizações distribuídas.
A distribuição pode ter uma configuração do tipo ponto a multiponto ou multiponto a multiponto.
Exemplos incluem educação a distância (ponto a multiponto) ou vídeoconferência (multiponto a multiponto).
Geralmente, sincronização multimídia pode ser dividida em dois níveis:
Especificação temporal e sincronização temporal.
Especificação temporal é o nível mais alto.
Ele modela as relações temporais entre o conjunto de objetos multimídia abstratos de um cenário de apresentação, onde um objeto abstrato denota uma unidade lógica de dados de mídia, tal como, um objeto vídeo ou um objeto texto.
Sincronização temporal é o nível mais baixo.
Ele traduz a especificação temporal de um cenário apresentacional numa seqüência de apresentações desejada e realiza a reprodução dos dados dentro de o prazo, desconsiderando atrasos indeterminísticos devido a o servidor, ao sistema final, ou ainda a rede de comunicação.
Aplicações multimídia Áudio e vídeo são meios de comunicação entre humanos que utilizam computadores como ferramenta de comunicação e também entre computadores e seus usuários.
Portanto, sistemas multimídia possuem aplicações em várias áreas em as quais áudio e vídeo podem ser integrados.
De entre as várias aplicações multimídia, abaixo algumas são descritas de forma sucinta.
TV Interativa Um importante serviço de TV interativa é o Vídeo sob Demanda (VoD).
Ele oferece um serviço de aluguel de vídeo eletrônico sobre a rede através de o qual o usuário pode selecionar programas de um servidor de vídeo e assistir em sua casa.
O serviço de VoD oferece funções estilo VCR (Video Cassete Recorder) (retrocesso rápido (fast-- forward) e avanço rápido (rewind)) através de as quais o usuário pode interagir com o servidor.
Serviços de TV interativa requerem alta velocidade na transmissão de dados audiovisuais, assim como um certo nível de Qualidade de Serviço.
Oferecer tais requisitos torna- se difícil sobre uma rede de baixa velocidade como a Internet, devido a os serviços do tipo &quot;best-effort», sem garantias de atraso, vazão ou perda de pacotes.
Para implementar serviços interativos, um sistema de VoD contém muitos componentes, os quais são mostrados na Figura 1: O servidor de vídeo, a rede de transporte, uma unidade terminal subscrita e um serviço de gateway.
O servidor de vídeo armazena um grande número de vídeos digitalizados e serve um número considerável de requisições de vídeo simultâneas para o mesmo ou para diferentes usuários.
As funções básicas de um servidor de vídeo incluem manipulação de requisições, acesso randômico, interações usuárias, além de controle de admissão e garantias de QoS.
A rede de transporte transmite os programas de vídeo do servidor para um ou mais usuários.
Ela deve possuir velocidade de transferência suficiente para satisfazer as restrições de tempo real do tráfego de vídeo.
As funções da unidade terminal subscrita incluem recebimento dos fluxos de vídeo de entrada, demodulação, demultiplexação e decodificação de sinais, realizando a conversão do sinal necessária, como por exemplo, a transformação de um sinal digital em analógico para reprodução (playback) no monitor de TV.
O serviço de gateway pode ser integrado com um nodo de acesso ou pode ser um elemento separado na rede.
As principais funções realizadas por um serviço de gateway incluem:
Serviço de diretório;
Mapeamento da identificação do serviço para locação correspondente;
Controle, coordenação e sinalização do estabelecimento de uma sessão multimídia, mantendo- a e desconectando- a;
Administração do sistema, incluindo administração de falhas, configuração, administração de recursos e administração de desempenho.
Telecooperação Telecooperação, também conhecida como Trabalho Cooperativo suportado por Computador (Computer Supported Collaborative Work -- CSCW) ou Groupware, refere- se a um sistema que oferece um espaço de trabalho eletrônico compartilhado para usuários dispersos geograficamente permitindo a comunicação, colaboração e suporte a coordenação.
Os usuários podem trocar mensagens sincronamente ou assincronamente.
Ele permite a cada usuário individual do grupo cooperar em tempos e localizações diferentes.
Compartilhamento de informações é a chave para uma efetiva colaboração.
Com respeito a tempo e taxonomia de espaço, sistemas CSCW podem ser classificados em quatro diferentes interações:
Sincronismo centralizado, sincronismo distribuído, assincronismo centralizado assincronismo distribuído.
Sincronismo assincronismo referem- se às dimensões de tempo, enquanto centralizado e distribuído referem- se as dimensões de espaço.
A Tabela 1 demonstra essa classificação.
Intercâmbio síncrono demanda comunicação em tempo real, e interações distribuídas requerem broadcast ou suporte multicast para grupos distribuídos.
O modo síncrono centralizado requer interação face a face.
Aplicações em reuniões são exemplos.
O modo síncrono distribuído provê interação em tempo real em grupos dispersos em localizações diferentes.
Exemplos incluem rede chat, quadros compartilhados (whiteboard), edição em conjunto em tempo real, conferência multimídia e videophone.
Esse tipo de aplicação é o grande desafio no projeto de sistemas colaborativos em grupo.
O modo assíncrono centralizado refere- se à aquelas atividades que ocupam o mesmo lugar, mas em tempos diferentes.
&quot;Newsgroups «e &quot;bulletin board «são ambos exemplos.
O modo assíncrono distribuído permite a troca de mensagens dentro de o grupo assincronamente, mail eletrônico e mail de voz são exemplos.
Hipertexto é um documento composto de um conjunto de nós ou nodos[ SOA95].
Cada nodo pode conter dados de mídia simples como texto, imagens, vídeo, áudio, ou animação, ou a combinação de dois ou mais tipos de mídias.
Os nodos são interligados por elos definidos por um par de âncoras, e as âncoras podem ser um nó ou uma região dentro de um nó.
O hipertexto incorpora as noções de navegação de maneira a a oferecer uma estrutura e acesso flexível à informações digitais baseadas em computador.
Permite aos usuários obterem informações apenas por o clique numa âncora (uma palavra, sentença, ou um parágrafo ligado a outro documento) dentro de um documento.
Hipermídia acrescenta hipertexto com informações multimídia.
A Figura 2 ilustra uma estrutura típica de documentos hipermídia, em a qual as unidades de informações são armazenadas numa rede de nodos interconectados por links.
Hipermídia permite navegação não seqüencial dentro de um espaço de informação de acordo com as necessidades individuais.
O ator (ou designer do sistema) de hipermídia determina a estrutura e as opções de navegação, e os leitores decidem a ordem de navegação de acordo com seus interesses individuais em tempo de execução.
Algumas aplicações são apropriadas para hipermídia, tal como enciclopédias, dicionários, e outros.
Elas são compostas de um número de unidades independentes que são raramente acessadas seqüencialmente, mas antes por seleção e referência cruzada com outras entidades.
Em a Internet, papers técnicos e relatórios são considerados mais apropriados para leitura linear existindo um aumento na tendência de incluir versões Html com links de hipertexto para facilitar referências.
Um sistema hipermídia pode ser tratado como uma aplicação de sistemas de base de dados porque ele oferece acesso flexível a informações multimídia e um novo método para estruturar e administrar dados.
Ele é diferente, contudo, das noções convencionais de sistemas de base de dados.
Um sistema hipermídia permite ao usuário mais livremente assimilar e explorar informações, enquanto os sistemas de base de dados convencionais possuem estruturas bem definidas e linguagens de manipulação para processamento dos dados.
Outras aplicações Existem inúmeras outras aplicações multimídia que encontramos na Internet.
Um exemplo de elas pode ser encontrado no MBone, ou Multicast Backbone, o qual é uma rede virtual que fica sobre a Internet utilizada para transmissão de televisão e rádio, conferências de áudio e vídeo multicast.
Outras incluem aprendizado a distância, realidade virtual, shoppings interativos, chamadas para conferências de negócios e telefonia na Internet.
Aplicações de entretenimento como jogos interativos, em que vários competidores distantes compartilham a mesma partida, também podem ser citadas.
Características e requisitos do tráfego multimídia Aplicações multimídia possuem várias características e vários requisitos com respeito a os serviços oferecidos à elas por o sistema de comunicação.
Por exemplo, uma aplicação de recuperação de dados (download de um arquivo) possui diferentes necessidades do que uma aplicação conversacional (audioconferência).
O cenário utilizado vai influenciar na demanda da aplicação.
De essa forma, os requisitos das aplicações a respeito de os serviços de comunicação podem ser divididos em requisitos de tráfego e requisitos funcionais.
Os requisitos funcionais dizem respeito à transmissão multicast que utiliza o esquema de comunicação ponto a multiponto ou configuração de comunicação multiponto a multiponto.
Em comunicações ponto a multiponto, por exemplo distribuição de software, um nodo (originador) envia um fluxo de mensagem para o resto do grupo multicast (receptores).
Em comunicações multiponto a multiponto, por exemplo vídeoconferência, cada nodo é envolvido em ambos envio e recebimento de mensagens de outros nodos no grupo.
Os requisitos de tráfego incluem largura de banda, atraso e confiabilidade na transmissão.
Eles dependem do tipo utilizado, número e qualidade do fluxo do dado.
Por exemplo, uma largura de banda de 1,5 Mbps é normalmente requerida para reprodução de vídeo codificado conforme o padrão As características das diversas mídias e seus requisitos de tráfego são descritos abaixo, sendo que o tráfego dos dados, normalmente, é divididos em três classes básicas constante e sua taxa média é igual a sua taxa de pico;
Tráfego em rajada, o qual apresenta taxa de transmissão ao longo de o tempo.
Mídia de texto O tráfego da mídia de texto é do tipo rajada, onde atrasos na transferência podem ser tolerados enquanto perda de dados não.
Vazão média dos dados vai depender da aplicação (correio eletrônico, transferência de arquivos) variando de uns poucos bits por segundo até chegar a algumas dezenas de megabits por segundo.
Atraso máximo na transferência e suas variações não se constituem em problemas para a mídia de texto, já que esta não é sensível a atrasos.
Mídia de imagens O tráfego desse tipo de mídia caracteriza- se por ser em rajadas, com vazões médias de dados que podem chegar a algumas dezenas de megabits por segundo.
Atrasos e suas variações não causam problemas, enquanto perda de dados podem comprometer a imagem final.
Mídia de áudio Uma onda de áudio (som) é uma onda acústica unidimensional (comprimida).
Quando uma onda acústica entra no ouvido, o tímpano vibra, fazendo com que o esqueleto interno do ouvido vibre juntamente com ele, enviando pulsos nervosos para o cérebro.
Esses pulsos são percebidos como som por o ouvinte.
De maneira semelhante, quando uma onda acústica atinge um microfone, o microfone gera um sinal elétrico, representando a amplitude do som como uma função de tempo.
Ondas de áudio podem ser convertidas para a forma digital por um conversor analógico digital ADC (Analog Digital Converter).
O conversor recebe uma voltagem elétrica como entrada e gera um número binário como saída.
De a mesma forma, os sinais de áudio podem ser convertido da forma digital para a analógica através de um conversor digital analógico DAC (Digital Analog Converter).
Som digitalizado pode ser facilmente processado em software.
Dezenas de programas existem para computadores pessoais permitindo aos usuários, registrarem, exibirem, editarem, mixarem, e armazenarem ondas de som de múltiplas fontes.
Atualmente, a maioria das gravações e edições de som são digitais.
O tráfego deste tipo de mídia é caracterizado como contínuo com taxa constante (CBR), e o sinal deve ser reproduzido no destino a uma taxa constante.
Caso não seja utilizada nenhuma técnica de compactação, o tráfego desse tipo de mídia continua sendo do tipo CBR;
E, caso contrário o tráfego se caracteriza como VBR.
No caso de a voz com detecção de silêncio, muitas vezes o tráfego se caracteriza como sendo em rajadas.
Atrasos na transferência dessa mídia são críticos, principalmente em aplicações interativas em tempo real.
Suas variações podem tornar o som incompreensível;
Contudo, perdas, taxas de erros de bits ou pacotes podem ser relativamente altas, devido a o alto grau de redundância dos sinais de áudio.
O único requisito é que os pacotes não sejam muito grandes para não se perder tempo no empacotamento e assim aumentar o atraso de transferência.
A vazão média gerada por a mídia de áudio depende da qualidade do sinal, da codificação utilizada.
Para áudio, codificado como PCM (Pulse Code Modulation), por exemplo, a vazão será de 64 Kbps calculada baseando- se na taxa de amostragem e o número de bits por amostra, com Adaptative Diferential PCM (ADPCM) esta taxa passa a ser de 32 Kbps;
E, com G. 729 a taxa fica em 8 Kbps.
Mídia de vídeo O olho humano possui a propriedade de quando uma imagem é lançada na retina, ela é retida por alguns milisegundos e depois desaparece.
Se uma seqüência de imagens for lançada a uma velocidade de 25 frames por segundo ou mais, o olho não percebe que ele está enxergando uma imagem discreta.
Todos os sistemas de vídeo (por exemplo, a televisão) exploram esse princípio para produzir filmes.
O tráfego da mídia de vídeo se caracteriza como um tráfego contínuo com taxa constante (CBR).
Quando no sinal for realizada alguma técnica de compactação e o tráfego gerado para comunicação se caracterizar como um tráfego com taxas variáveis (VBR), o sinal deve ser reproduzido no destino a uma taxa constante.
O atraso máximo na transferência tem grande importância e a variação do atraso deve ser compensada.
Normalmente, como o vídeo vem acompanhado de áudio, uma vez obedecido os requisitos de atraso deste, estão obedecidos os daquele.
A taxa de erro de bit pode ser maior que a taxa de erro de pacote (perda), uma vez que não haverá problema se um único pixel de uma tela ficar azul em vez de verde, mas o mesmo não é verdadeiro no caso de a perda de um pacote, que poderá apagar um bloco de imagem na tela, por exemplo.
A vazão média gerada por uma fonte de vídeo varia com a qualidade do sinal e os algoritmos de codificação utilizados.
Sistemas de vídeo apresentam informações como uma seqüência de quadros, sendo cada quadro composto por linhas.
Por exemplo, um sistema de distribuição de TV utiliza 486 linhas por quadro a uma taxa de 30 quadros/ segundo.
Se a linha contiver 720 pixels, sendo cada pixel codificado por 24 bits, a vazão deverá ser de 486 multiplicado por 30 quadros/ segundo, multiplicado por 720 pixels, multiplicado por 24 bits/ pixel, o que resulta numa vazão de 252 Mbps.
Os requisitos de tráfego das diversas mídias (Tabela 2) podem ser satisfeitos por o uso de mecanismos para dar suporte as diversas características de tráfego, utilizando- se do mesmo meio físico de transmissão.
Esses mecanismos devem permitir negociar:
O máximo atraso de transferência, a variação máxima de atraso para o atendimento dos requisitos de áudio e vídeo, as taxas de erros de bit e pacotes toleráveis, mecanismos para controle de fluxo e congestionamento, condições para fechamento de uma conexão, caso não seja possível atender a todos os requisitos, entre outros.
Introdução A Internet interconecta redes diferentes que não se comunicavam entre si e cumpre sua tarefa com sucesso.
Redes acadêmicas, particulares e públicas podem ser facilmente integradas a ela.
A rede Internet é baseada no conjunto de protocolos definidos por a Arquitetura TCP/ IP.
Apesar de o IP (Internet Protocol) ser o protocolo da camada de rede que provê o encaminhamento de pacotes IP e o protocolo TCP (Transport Control Protocol) ser o protocolo da camada de transporte que oferece comunicação confiável, o termo TCP/ IP é geralmente usado para denotar o conjunto de protocolos que são utilizados em conjunto com o protocolo IP, como UDP, FTP, Telnet, entre outros.
Originalmente concebida para transmissão confiável de dados com mínima ou nenhuma restrição de atraso, a Internet, oferece um simples modelo de serviço do tipo &quot;best-effort», ou serviço do melhor esforço, onde os dados são transmitidos tão rapidamente quanto possível e a preocupação principal reside em entregar os dados corretamente para a outra entidade participante da comunicação.
Os protocolos TCP/ IP foram projetados para este tipo de tráfego e trabalham muito bem neste contexto.
Uma variedade de aplicações multimídia tem surgido na Internet, como aplicações interativas (conferência de áudio e vídeo, telefonia, ensino a distância) e sob demanda (vídeo e áudio sob demanda), desencadeando uma demanda de tráfego bem mais exigente do que, por exemplo, uma aplicação de FTP para uma simples transferência de arquivo.
Normalmente, aplicações multimídia requerem sincronização para ter uma perfeita inteligibilidade ao usuário final, e podem, geralmente, não utilizar- se da complexidade do TCP para o tráfego do seus dados utilizando uma estrutura de transporte bem mais simples.
Além disso, a maioria dos algoritmos de reprodução, que decodificam as mídias para posterior apresentação, podem tolerar perda de dados muito melhor do que atrasos prolongados causados por retransmissões, não requerendo também transferência com seqüência garantida.
A atual arquitetura Internet não está preparada para o tráfego em tempo real de aplicações multimídia.
Isto justifica- se por causa de significativas perda de pacotes que, normalmente, são causadas por buffers cheios na rota entre fonte e destino;
Grandes atrasos na entrega de cada pacote ao receptor, e suas variações, resultado de diferentes caminhos que pacotes de uma aplicação podem seguir, ora chegando adiantados, ora atrasados.
Além desses fatores, falta de largura de banda necessária às aplicações multimídia também pode ser considerada.
O problema principal deve- se ao fato de que todos os pacotes IP, independentes de qual aplicativo os gerou, são processados da mesma forma.
Uma arquitetura de rede baseada nos protocolos TCP/ IP impõe limitações ao tráfego em tempo real principalmente quando a rede esta congestionada.
O nível de rede (IP) pode, em situação de congestionamento, descartar pacotes sem conhecer qual aplicação os gerou.
Desta forma, neste capítulo, apresenta- se os novos protocolos que já estão sendo utilizados para prover serviços multimídia, já que o tráfego multimídia possui diferentes características e, como conseqüência, requer o uso de protocolos diferentes para oferecer os serviços necessários.
Real Time Transport Protocol O protocolo de transporte em tempo real, conhecido como RTP, é um protocolo que foi projetado para oferecer suporte ao tráfego de aplicações que transmitem dados em tempo real.
Ele normalmente é integrado dentro de a aplicação (modo usuário), não sendo implementado como parte do kernel do sistema operacional.
Definido na RFC 1889, o protocolo RTP é um produto do Grupo de Trabalho de Transporte de Áudio e Vídeo (Audio/ Video Transport Working Group) do IETF (Internet Engineering Task Force).
RTP oferece funções de transporte fim-a-fim para aplicações que transportam dados em tempo real, como áudio e vídeo, sobre redes de serviço unicast ou multicast caracterizando- se como um protocolo não orientado a conexão.
Essas funções incluem identificação do tipo de dado a ser manipulado, numeração de seqüências (sequence numering), timestamp e monitoramento da transmissão de dados.
Embora RTP ofereça transferência fim-a-fim, ele não oferece todas as funcionalidades normalmente encontradas num protocolo de transporte.
Além disso, ele não reserva recursos da rede, não garante Qualidade de Serviço para as aplicações e não promove reordenamento ou retransmissão no caso de perda de pacotes, deixando a aplicação tratar disso.
Normalmente, aplicações multimídia em tempo real não necessitam dos serviços do protocolo TCP, já que podem tolerar perda de dados.
Ao invés de introduzir atrasos com retransmissões, essas aplicações podem utilizar- se de outros protocolos para streaming1 de mídia.
Um protocolo que normalmente é utilizado é o User Datagram Protocol (UDP).
UDP é um protocolo não confiável;
Ele não garante que cada pacote possa alcançar o seu destino.
Também não existe a garantia que os pacotes cheguem na mesma ordem em que foram enviados.
O recebedor tem que estar habilitado a compensar perda de dados, pacotes duplicados, e pacotes que cheguem fora de ordem.
Logo, o padrão Internet para transporte de dados de mídia contínuos é o RTP.
Tipicamente, um pacote UDP pode encapsular um único pacote RTP ou vários pacotes RTP;
E, um pacote RTP pode conter, por exemplo, um único frame de vídeo ou múltiplas samples de áudio.
Outros protocolos de transporte ou rede também podem ser utilizados em conjunto com RTP.
RTP utiliza- se, normalmente, do protocolo UDP para fazer uso dos serviços de multiplexação e checksum.
O protocolo constitui- se de duas partes:
Uma parte de dados (RTP) e uma parte de controle (RTCP).
RTP e RTCP foram projetados para serem independentes das camadas subjacentes de rede e transporte.
Enquanto RTP é responsável por o transporte das mídias contínuas (áudio e vídeo), RTCP fica responsável por o controle das informações de feedback dos recebedores dos dados para todos os membros de um grupo, as quais informam como está a qualidade da recepção dos dados, bem como informações sobre a transferência dos dados, como também suporte a sincronização de diferentes streams de mídia.
A parte de dados (RTP) As aplicações RTP utilizam- se de uma estrutura conhecida como Application Layer Framing (ALF).
Essa estrutura (Figura 3) possui regras básicas, operações, e formato de mensagens, sendo que existem vários padrões diferentes para codificar dados de vídeo, incluindo MPEG, JPEG, e H. 261, tão bem quanto dados de áudio como GSM, G723, entre outros.
RTP oferece uma estrutura apropriada para qualquer um desses métodos de codificação.
Um protocolo completo requer ambos:
Uma estrutura RTP e o formato payload de, por exemplo, MPEG.
Além disso, faz parte da estrutura RTP uma informação de timestamping que permite ao recebedor de um vídeo sincronizar voz e movimento de figuras.
Cada fonte de dado RTP marca cada mensagem com um timestamping indicando quando um evento acontece, dessa forma, o recebedor representa o dado recebido no mesmo tempo Mídias que modificam- se durante o tempo são referenciadas como streaming.
Uma vez que o fluxo da mídia inicia sua transferência existem restrições de entrega que devem ser obedecidas em termos de recebimento e apresentação dos dados.
Sistemas que utilizam RTP podem também agir como translators e mixers.
Ambos localizam- se &quot;em o meio «da rede entre enviadores e receptores, tendo como função processar os pacotes RTP que passam diretamente por eles.
Não são necessários, mas são utilizados para que a rede possa suportar uma aplicação em tempo real.
Translators transformam um formato payload para outro, sendo que o novo formato pode oferecer vídeo com mais baixa qualidade, mas com largura de banda menor.
Em a Figura 4, cada enviador gera 1 Mbps de tráfego de vídeo.
O translator aceita cada stream e converte para 256 Kbps cada.
Mixers realizam um serviço semelhante ao dos translators, mas ao invés de transformar os fluxos da fonte individuais para um formato diferente, eles combinam múltiplos fluxos num preservando o formato original.
Essa abordagem pode ser particularmente utilizada em dados de áudio.
Nem todas as aplicações podem suportar a operação de um mixer (Figura 3).
Fontes de vídeo múltiplas, por exemplo, não podem normalmente ser combinadas numa.
A abordagem trabalha muito bem em conferências de áudio, particularmente conferências com muitos participantes.
A Figura 5 demonstra o cenário de uma audiconferência, onde cada enviador gera 64 Kbps de tráfego de áudio.
O mixer aceita cada stream e combina todos os dois num único stream de 64 Kbps.
Atualmente, várias aplicações RTP tanto experimentais quanto comerciais têm sido implementadas.
Essas aplicações incluem ferramentas de áudio e vídeo, juntamente com ferramentas de diagnóstico e monitores de tráfego.
Muitos usuários já utilizam- nas.
Contudo, a atual arquitetura da Internet não pode ainda suportar a demanda potencial de serviços em tempo real.
Serviços com alta largura de banda utilizando RTP, como vídeo por exemplo, podem potencialmente degradar seriamente a Qualidade de Serviço de outros serviços na rede.
De essa forma, implementadores de aplicações podem se precaver limitando a largura de banda utilizada em suas aplicações.
A parte de controle (RTCP) RTCP é um protocolo para troca de informação de controle entre fontes e destinos.
Ele define cinco diferentes tipos de mensagens:
1) Sender Report (Sr):
Geradas por os usuários que estão enviando as mídias (fontes RTP).
Descrevem a quantidade de dados que está sendo enviada, ou seja, contadores cumulativos de pacotes e bytes enviados, e informações de timestamp que permitem a sincronização entre as diferentes mídias.
2) Receiver Report (RR):
Geradas por os participantes que estão recebendo as mídias (destinos RTP) informando sobre os níveis de qualidade na recepção do fluxo.
O destino recebe, de tempos em tempos, uma descrição do tráfego gerado por o fonte (Sr) e contabiliza os dados recebidos.
Um pacote RR carrega informações sobre a diferença entre o tráfego gerado e o tráfego recebido possibilitando o cálculo do impacto desses dados sobre a rede.
Informações contidas nestes pacotes RTCP RR contém o maior número de seqüência recebido, número de pacote perdidos, atraso e variações de atraso entre pacotes.
A fonte pode ou não alterar suas características de transmissão em função de os relatórios recebidos dos destinos.
3) Source Description (SDES):
São emitidas por fontes visando suprir mais informação sobre as mesmas.
Exemplos incluem CNAME (Canonical Name), um identificador único global semelhante ao formato dos endereço de e-mail.
O CNAME é usado para resolver conflitos no valor SSRC (o enviador original da mensagem) e associar diferentes fluxos de mídia gerados por o mesmo usuário.
Pacotes Source Description também identificam os participantes diretamente por o nome, e-mail e número de telefone, localização geográfica do emissor, aplicação que esta gerando o fluxo e um texto adicional.
Aplicações cliente podem mostrar o nome e informações de e-mail na interface do usuário permitindo aos participantes da sessão conhecerem outros participantes.
Ele também permite aos participantes obterem informações de contato (como e-mail e telefone) para realizarem outras formas de comunicação (como iniciar uma sessão de conferência separado utilizando SIP).
4) Bye:
Permite a uma fonte anunciar que está deixando de participar de uma conferência.
5) Application Specific:
Reservada para características específicas da aplicação.
Projetada para as aplicações criarem novos tipos de mensagens.
Através desses pacotes com informações de controle, RTCP oferece os seguintes serviços:
Monitoração de QoS e Controle de Congestionamento:
Este é a função primária de RTCP.
RTCP provê feedback para uma aplicação sobre a qualidade da recepção dos dados e contém informações necessárias para monitoração de QoS.
As informações de controle são apropriadas para os enviadores dos dados RTP.
Os recebedores podem determinar se um congestionamento está sendo local, regional ou global.
Administradores de rede podem avaliar a performance da rede para distribuição multicast.
Identificação do fonte:
Em pacotes de dados RTP, fontes são identificadas por identificadores gerados aleatoriamente.
Esses identificadores são diferentes para cada mídia particular gerada por o fonte.
Sincronização intermídia:
Pacotes RTCP Sr contém uma identificação de tempo real (NTP Timestamp) e um correspondente timestamp RTP (RTP Timestamp).
Esses dois valores permitem sincronização de diferentes mídias, como por exemplo, sincronização labial de áudio e vídeo.
Escalabilidade das informações de controle:
Pacotes RTCP são enviados periodicamente entre participantes.
Quando o número de participantes aumenta as informações de controle são balanceadas e o tráfego de controle é limitado.
RTCP recebe a designação técnica como um protocolo separado porque as mensagens utilizam uma porta UDP diferente da utilizada por o tráfego RTP.
O valor da porta default RTCP é um número a mais de o que o correspondente tráfego RTP.
Real Time Streaming Protocol O Real Time Streaming Protocol (RTSP) é um protocolo a nível de aplicação para controle na transferência de dados com propriedades de tempo real.
RTSP torna possível a transferência, sob demanda, de dados em tempo real como áudio e vídeo.
Ele serve para estabelecer e controlar um único ou vários streams sincronizados de mídias contínuas pertencentes a uma apresentação.
O conjunto de streams a ser controlado é definido por uma descrição de apresentação (Source Description), normalmente um arquivo, que pode ser obtido por um cliente usando Http ou outro meio como e-mail;
E, pode não necessariamente estar armazenado num servidor de mídia.
Uma descrição de apresentação contém informações sobre um ou mais streams que compõe a apresentação, como endereços de rede e informações sobre o conteúdo da apresentação (assunto, e-mail do responsável por a sessão, tempo da apresentação), além de parâmetros que tornam possível ao cliente escolher a combinação mais apropriada das mídias.
Em a descrição da apresentação, cada stream é individualmente identificado por uma URL RTSP, a qual aponta para um servidor de mídia que trata aquele stream particular e dá um nome ao stream armazenado naquele servidor.
Vários streams (áudio e vídeo) podem ser localizados em servidores diferentes para compartilhamento de carga.
Além disso, a descrição da apresentação também descreve quais métodos de transporte o servidor é capaz de oferecer.
Vários modos de operação são utilizados como unicast e multicast.
Em relação a o funcionamento de RTSP, não existe a noção de uma conexão RTSP;
Ao invés de isso, um servidor mantém uma sessão indicada por um identificador.
Uma sessão RTSP não está ligada à uma conexão a nível de transporte como acontece numa conexão TCP.
Durante uma sessão RTSP, um cliente RTSP pode abrir e fechar conexões de transporte para o servidor emitir requisições RTSP, sendo que, normalmente, o controle RTSP pode acontecer numa conexão TCP enquanto o fluxo de dados via UDP ou RTP;
Mas, a operação de RTSP não depende do mecanismo de transporte utilizado para o transporte das mídias contínuas.
O protocolo suporta as seguintes operações:
Recuperação de mídia de um servidor de mídia, convite de um servidor de mídia para uma conferência (apresentação ou registro de um, ou um subconjunto de mídias da conferência), e adição de mídias a uma apresentação existente. Como
exemplo da utilização de RTSP temos mídia sob demanda (Figura 6).
Em mídia sob demanda, um cliente requisita um filme de um servidor de áudio (áudio_ example_ com) e um servidor de vídeo (vídeo_ example_ com).
A descrição da mídia é armazenada num servidor Web.
O cliente estabelece uma conexão com o servidor Web solicitando o arquivo de descrição da apresentação.
O servidor Web responde com OK e mais informações (tipo de conteúdo a ser apresentado, o endereço onde áudio e vídeo encontram- se).
Logo depois, o cliente envia um comando para o servidor de áudio e para o servidor de vídeo pedindo para iniciar uma sessão (método Setup) e em seguida para inicializar a representação de áudio e vídeo (método PLAY).
Os servidores enviam respostas de OK e em seguida enviam através de RTP ou outro protocolo de transporte áudio e vídeo ao cliente.
Cabe ressaltar que RTCP faz- se presente aqui fornecendo informações de sincronização para o cliente e informações de perda de pacotes para o servidor, entre outras.
Por fim, o cliente solicita aos servidores para liberar recursos através do comando TEARDOWN encerrando a sessão RTSP com uma resposta de OK dos servidores.
Servidor Web s_ D. Já existem implementações de RTSP disponíveis para download na Internet e aplicações diferentes para as quais RTSP é apropriado, como mídia sob demanda.
De entre as áreas de aplicação estão o Rádio na Internet, o controle de dispositivos, além de registro remoto, o qual é apropriado para videoconferência.
Session Initiation Protocol O protocolo de iniciação de sessão é um protocolo de controle (sinalização) da camada de aplicação que pode estabelecer, modificar e terminar sessões multimídia2 ou chamadas3, ou seja, iniciar sessões de comunicação interativa entre usuários.
Exemplos incluem, chat, voz, vídeo, jogos interativos e realidade virtual.
Membros de uma sessão podem comunicar- se via multicast ou uma malha de relações unicast, ou uma combinação dessas.
SIP pode executar sobre os protocolos de transporte UDP ou TCP, mas por default na mesma porta.
Uma sessão multimídia caracteriza- se por um conjunto de enviadores e recebedores de streams, sendo que os streams seguem dos enviadores para os recebedores.
Uma conferência multimídia é um exemplo de uma sessão multimídia.
Uma chamada consiste de todos os participantes numa conferência convidados por uma fonte comum.
SIP é um protocolo cliente servidor, onde requisições são geradas por uma entidade enviadora (o cliente) e enviadas para uma entidade recebedora (o servidor) que as processa.
Ele é muito semelhante ao protocolo Http, onde clientes invocam métodos no servidor.
Requisições e respostas são textuais.
Além disso, o protocolo utiliza muitos dos campos do cabeçalho que são utilizados por o protocolo Http, permitindo reuso de código e simplificando a integração de servidores SIP com servidores Web.
Como um participante da chamada pode, ou gerar, ou receber requisições, SIP torna possível aos sistemas finais utilizarem um protocolo cliente e servidor ao mesmo tempo que contata o usuário quando uma requisição SIP é recebida e retorna resposta ao usuário, responde requisições baseado em interações humanas.
Além disso, as requisições SIP podem passar por servidores Proxy, sendo que cada servidor recebe uma requisição e a envia para o próximo servidor, o qual pode ser outro servidor Proxy ou um USR.
Um servidor pode também agir como um servidor redicionador (um servidor normal que aceita uma requisição SIP, mas não aceita chamadas), informando ao cliente o endereço do próximo servidor, assim o cliente pode contatar com ele diretamente.
Não existe distinção de protocolos entre um servidor Proxy, um servidor redicionador e um USR.
A distinção acontece somente quanto as funções que cada um realiza:
Um servidor Proxy ou redicionador não podem aceitar ou rejeitar uma requisição, enquanto um USR pode.
Um único host pode agir como cliente e servidor ao mesmo tempo.
As chamadas SIP são unicamente identificadas por um identificador (campo do cabeçalho Call-ID das mensagens SIP), o qual é utilizado por todos os participantes da chamada.
Uma conexão SIP é criada por uma requisição Invite e destruída por uma requisição BYE.
Conexões também possuem as seguintes propriedades:
A conexão lógica fonte indica a entidade que está requisitando a conexão (campo From do cabeçalho das mensagens SIP), como Proxyes que podem enviar requisições em benefício de outros usuários.
A conexão lógica destino (campo Te o do cabeçalho das mensagens SIP) descreve a parte com quem o originador quer contactar.
Capacidade de mídias (transportada junto da mensagem SIP como parte do payload) leva as mídias que um participante pode ser capaz de receber e seus atributos.
Atualmente, o Session Description Protocol (SDP) serve para esse propósito, sendo encontrado em mais detalhes na RFC 2327.
A operação mais importante do protocolo de iniciação de sessão é convidar participantes para uma chamada.
Um cliente SIP primeiro obtém um endereço onde o novo participante vai ser contatado, na forma name@ domain.
O cliente então tenta traduzir esse domínio para um endereço IP onde um servidor pode ser encontrado.
Essa tradução é realizada por o DNS.
Uma vez que o endereço IP foi encontrado, o cliente envia uma mensagem Invite utilizando UDP ou TCP.
O servidor que recebe a mensagem pode ser um servidor redicionador ou um servidor Proxy.
Servidores Proxy podem transmitir o convite para múltiplos servidores de uma vez na esperança de contatar o usuário numa das localizações.
Uma vez que o User Agent Server foi contatado, ele envia uma resposta de volta ao cliente.
A resposta possui um código de resposta e uma mensagem de resposta.
Como exemplo da utilização de SIP imagine um cliente A convidando um cliente B para iniciar uma sessão de conferência multimídia na Internet (Figura 7).
O cliente A inicialmente envia uma requisição Invite para B@ exemplo.
Br.. O servidor Proxy, ou algumas vezes o servidor redicionador, recebe a requisição, descobre a localização do usuário B consultando o servidor de nomes e então envia Invite para B, que a partir de agora é considerado o User Agent Server.
Ele responde com OK confirmando que quer participar da conferência e o servidor Proxy de uso dessa informação envia confirmação ao cliente A, o qual responde com ACK confirmando para B que a conferência realmente vai acontecer.
Atualmente o grupo de trabalho IETF que possui a responsabilidade para o futuro desenvolvimento de SIP é o MMUSIC (Multiparty Multimedia Session Control).
Várias implementações também encontram- se disponíveis na Internet utilizando o protocolo.
Introdução Apesar de Qualidade de Serviço não ser um conceito novo, apenas recentemente ela passou a ser investigada mais a fundo, com o surgimento da B-ISDN (Broadband Integrated Services Digital Network) e ATM (Asynchronous Transfer Mode) e de aplicações para as quais Qualidade de Serviço (QoS) é fundamental como aplicações multimídia em tempo real que exigem uma resposta dentro de um certo limite de tempo.
Assim, a necessidade de atender tais aplicações é a principal razão da pesquisa nesta área já que essas estão impondo novos desafios para oferecer a QoS desejada por o usuário.
Desta forma, as próximas seções deste capítulo tentam direcionar o leitor a entender o que vem a ser QoS e como ela pode ser oferecida.
Conceitos de Qualidade de Serviço Para implementar aplicações multimídia em ambientes de redes de computadores é necessário que alguns requisitos básicos sejam atendidos.
Requisitos estes que são, mais freqüentemente, definidos em termos de QoS.
QoS é baseada na idéia de que diferentes aplicações não necessitam do mesmo desempenho de rede e, portanto, deveriam poder especificar seus devidos requisitos de operação.
Diversos parâmetros de QoS podem ser definidos, como por exemplo, largura de banda, variação de atraso, atraso e taxa de perdas.
Atualmente, QoS é um dos conceitos mais confusos e difíceis de definir para aplicações multimídia em redes de computadores.
Não existe uma definição formal ou comum do que é QoS.
Entretanto, um grande número de definições podem ser encontradas na literatura.
Em essas a noção de QoS originalmente serve para descrever certas características técnicas da transmissão dos dados, principalmente dados que não são dependentes do tempo, como dados de mídia discretos (texto e imagens).
Abaixo estão algumas definições utilizadas por os vários órgãos de padronização do mundo das telecomunicações, padrões internacionais e padrões Internet:
O International Telecommunication Union (ITU), refere- se a QoS como &quot;Um conjunto de requisitos de qualidade de comportamento coletivo de um ou mais objetos».
Um número de parâmetros de QoS descrevem rapidez e confiabilidade na transmissão dos dados, por exemplo, vazão, atraso e taxa de erro.
A ATM Lexicon define QoS como &quot;Um termo o qual refere- se a um conjunto de parâmetros de performance ATM que caracteriza o tráfego sobre uma dada conexão virtual».
Parâmetros de QoS aplicam- se principalmente às camadas do protocolo nos níveis mais baixos, não sendo diretamente observáveis ou verificáveis por a aplicação.
Esses parâmetros incluem taxa de células perdidas, taxa de células erradas, taxa de falhas durante a inserção de células na rede, variação do atraso das células, atraso na transferência da célula, e média de atraso na transmissão das células.
Além disso, cinco classes de serviços são definidas em termos de parâmetros de QoS (Constant Bit Rate, rtVariable Bit Rate, nrt- Variable Bit Rate, Available Bit Rate, Unspecified Bit Rate).
O Internet Engineering Task Force tem começado a tratar QoS para ATM através da RFC 1946 (Native ATM Support for ST 2+) e RFC 1932 (IP over ATM:
A Framework Document).
Ambos documentos levam em consideração parâmetros de QoS para aplicações em tempo real e consideram reserva de recursos como meio de oferecer a QoS desejada por as aplicações, sendo definida através de parâmetros.
Além de essas definições, várias outras podem ser encontradas na literatura.
Entre elas:
Um conjunto de parâmetros que define as propriedades do fluxo de dados multimídia;
Uma descrição quantitativa de quaisquer serviços providos por o sistema que satisfazem as necessidades da aplicação, sendo esta descrição expressa como um conjunto de pares de parâmetros.
Por exemplo, probabilidade de perda de pacotes de 10-3, atraso de pacotes de 10-6s. Vogel et al.,
definem QoS para aplicações que comunicam- se em tempo real como o conjunto daquelas características qualitativas e quantitativas de um sistema multimídia distribuído necessárias para obter funcionalidades requeridas de uma aplicação.
Funcionalidades incluem a apresentação de dados multimídia para o usuário, bem como sua satisfação.
Normalmente, a QoS de um dado sistema é expressa como um conjunto de pares de QoS chamados de tuplas.
De acordo com Watson et al.
QoS em termos de rede é um conceito por o qual aplicações podem indicar seus requisitos específicos para a rede antes de iniciar, de fato, a transmissão dos dados.
A QoS requerida por uma aplicação define como a aplicação espera que a rede de comunicação entregue seus dados.
Aplicações na Internet requerem diferentes níveis de QoS e podem ser classificadas como: (
a) sensitivas a atrasos; (
b) sensitivas a confiabilidade;
E (c) sensitivas a atrasos e confiabilidade.
Aplicações sensitivas a atrasos exigem um tempo de resposta limitado.
Se um pacote não for entregue dentro de o prazo, ele é desconsiderado.
Contudo, essas aplicações toleram perda de pacotes e exploram técnicas para compensar a perda dos dados.
Exemplos incluem aplicações multimídia e conferência de áudio e vídeo.
Aplicações sensitivas a confiabilidade requerem entrega confiável de dados para todos os participantes, mesmo que isso signifique atrasos prolongados.
Exemplos incluem distribuição de software e transferência de arquivos.
Aplicações sensitivas a atrasos e confiabilidade requerem entrega confiável de dados para todos os recebedores dentro de um tempo limitado.
Disseminação militar do movimento de tropas em tempo real e imagens de satélite são exemplos de tais aplicações.
Freqüentemente, quando QoS é oferecida através da utilização de reserva de recursos, os parâmetros de QoS são negociados entre o (s) usuário (s) e o Provedor de Serviço.
O serviço em conformidade com a QoS negociada e as características da chamada (tal como taxa média de dados, pico da taxa de dados) é chamado contrato de serviço.
Com a tradução de QoS entre as diferentes camadas do sistema, requisitos de QoS podem ser mapeados em recursos desejados e então administrados para manter a QoS contratada.
Três níveis de garantias de QoS podem ser oferecidas:
Serviço negociado;
Uma vez que os recursos foram alocados, eles não podem ser utilizados por outras aplicações, mesmo quando não estiverem sendo utilizados por esta.
Frente a os conceitos de QoS apresentados, uma definição adotada para utilização neste trabalho é uma junção dos conceitos apresentados em Lia et al e Watson et al.
Por exemplo, atraso é menos importante para aplicações apresentacionais, como Vídeo sob Demanda, do que aplicações conversacionais, como telefonia e videoconferência.
Estrutura de QoS Qualidade de Serviço pode ser descrita sob vários pontos de vista.
Para o usuário final da aplicação QoS representa, por exemplo, a qualidade da imagem em termos de nitidez ou a qualidade de áudio em termos de compreensão.
Para a rede, estas características são traduzidas num conjunto de parâmetros, como largura de banda ou atraso máximo permitido.
Lião et al.
Definem um modelo de QoS considerando quatro camadas conceituais como mostra a Figura 8.
Camada de QoS do usuário:
Em esta camada são descritos os requisitos de percepção dos dados multimídia na interface do usuário.
Em este nível, o resultado de QoS é a qualidade percebida por o usuário, sendo que, normalmente é mensurada de forma qualitativa.
A qualidade percebida é um tanto subjetiva e uma interface apropriada deve ser oferecida para facilitar a escolha dos parâmetros.
A essência desta camada é ocultar, tanto quanto possível, os parâmetros de QoS internos do sistema (freqüentemente sem significado para o usuário) e apresentar, ao invés de isso, exemplos que permitam escolher uma qualidade variável, como imagens de tamanhos diferentes, resolução, tonalidades de cor, ou áudio com qualidade de CD ou telefone.
Em um sistema real as escolhas não são independentes.
Selecionando uma imagem de alta resolução pode resultar num aumento de custo e atraso de transferência.
Além disso, as escolhas de QoS para o usuário dependem de todos os componentes do sistema:
O sistema operacional (falta de capacidade em tempo real pode limitar a precisão de sincronização), o sistema de transporte (um enlace lento pode limitar a vazão) ou a aplicação (a base de dados pode conter somente imagens de baixa qualidade).
Camada de QoS da aplicação:
Em esta camada são descritos os requisitos para a aplicação em termos de qualidade da mídia e relacionamento entre mídias (sincronização intermídia e intramídia).
Escolhas realizadas por o usuário final, na camada de QoS do usuário, são mapeadas num conjunto de parâmetros à nível de aplicação que devem ser satisfeitos a fim de que os parâmetros escolhidos por o usuário sejam atendidos.
Em este nível, os parâmetros são associados a quadros de vídeo (tamanho do quadro, taxa de quadros por segundo) ou samples (taxa de amostragem, bits por sample).
Relacionamento entre as mídia também podem ser especificados.
Como um exemplo de áudio com qualidade de telefone, o mapeamento resultaria numa taxa de amostragem de 8 KHz com 8 bits por sample.
Camada de QoS do sistema:
Em esta camada são descritos requisitos para o sistema final.
Isso como resultado da QoS obtida no nível de aplicação.
Requisitos estes que podem ser especificados em termos de critérios quantitativos e qualitativos.
Critérios quantitativos são aqueles que podem ser avaliados em termos de medidas concretas, como bits por segundo, tempo de processamento de uma tarefa, e tamanho da unidade de dados.
Critérios qualitativos especificam os serviços esperados, como sincronização, mecanismos de escalonamento e recuperação de erros.
Os parâmetros, neste nível, podem ter um grande impacto na qualidade percebida por o usuário.
Por exemplo, a velocidade do barramento e da CPU podem limitar a taxa de frame da apresentação de um vídeo, e uma tela preta e branca não pode mostrar imagens coloridas.
Camada de QoS da rede:
Em esta camada são descritos os requisitos nos serviços de rede (desempenho da rede) estando associados com propriedades de pacotes ou bits, tal como, atraso de pacotes, taxa de bits.
Em este nível, parâmetros fim-a-fim como atraso, variação de atraso e perda de pacotes são especificados.
Para suportar aplicações multimídia, a rede deve satisfazer os requisitos de transmissão dos dados multimídia.
O tráfego de mídia discreta (transferência de arquivos ou recuperação de imagens) requer serviços livres de erros, mas é tolerante a atrasos.
O tráfego de mídia contínua requer tempo real e transmissão em alta velocidade.
Ela é sensitiva a atrasos e suas variações, mas é tolerante a perdas ocasionais de pacotes.
A rede deve suportar os requisitos especificados por a aplicação.
A partir deste ponto, o termo QoS utilizado estará fazendo referência à Qualidade de Serviço da rede, mais especificamente relacionada com o tráfego dos dados como por exemplo, perda de pacotes, variação de atraso e atraso fim-a-fim.
Limitações quanto a o suporte a QoS Em a maioria das arquiteturas de comunicação, a noção de Qualidade de Serviço (QoS) é extremamente limitada.
O Protocolo Internet IPv4 (Internet Protocol) permite somente roteadores.
Em o IPv6, o campo Flow Label ou Traffic Class poderá ser utilizado para um host origem determinar restrições em termos de atraso necessitando, por esta razão, de uma largura de banda reservada para um fluxo de pacotes pertencentes a uma aplicação particular.
Esse fluxo pode ser configurado com antecedência e ter um identificador atribuído a ele.
De essa forma, quando cada pacote passar por o roteador esse verifica qual tratamento especial é necessário.
As arquiteturas existentes são baseadas no modelo de serviço &quot;best-effort».
Elas não foram projetadas para suportar QoS quantitativa, como por exemplo, especificar a quantidade de largura de banda necessária para a transferência de um fluxo de pacotes de áudio durante uma audioconferência, ou então o atraso máximo suportado.
Em a Internet, suporte a transferência de dados de maneira confiável foi o principal objetivo do projeto e QoS foi somente uma consideração que ficou as margens de ele.
Uma maior limitação da maioria das arquiteturas atuais é a natureza estática do oferecimento de serviço.
Em os protocolos OSI, o valor dos parâmetros de QoS permanecem os mesmo durante o tempo de vida de uma conexão;
Uma vez negociado um parâmetro de QoS este não é mais renegociado.
Uma implicação disso é que os usuários não podem dinamicamente ajustar a QoS da conexão sem sofrer uma fase de desconexão e restabelecimento de conexão.
Os usuários não podem voltar a escolher a qualidade de vídeo existente de colorido para monocromático para tornar possível abrir uma conexão de áudio.
Outra implicação é que o Provedor de Serviço está comprometido a oferecer a QoS durante o tempo de vida da conexão.
Se o provedor não estiver capacitado a manter o comprometido, não existe um mecanismo para informar ao usuário e permitir a ele requisitar uma QoS apropriada, embora num nível menor.
A única opção do provedor é unilateralmente fechar a conexão.
Desta forma, alocar recursos suficientes para um número maior de aplicações de maneira a satisfazer seus vários requisitos de qualidade é um dos problemas para a rede de comunicação.
Pode- se dizer então, que o maior desafio da Internet não é necessariamente o aumento da velocidade de comunicação, mas sim sua utilização adequada, garantindo um nível adequado de QoS para o correto funcionamento da aplicação mesmo em condições de congestionamento.
Assim, principalmente em aplicações multimídia, um suporte para assegurar que a QoS contratada possa ser atendida faz- se necessário.
Contudo, a sua efetiva utilização numa rede não é tão trivial.
O primeiro problema a ser considerado é como negociar as condições em que a rede deve operar.
Depois, como garantir que essas condições sejam atingidas e mantidas ao longo de o tempo e que atitude tomar caso isso não seja mais possível.
Assim sendo, devem ser tomadas decisões em relação a a alocação de recursos, recusa de fornecimento do serviço ou aborto de operações (para liberação de recursos ou porque a qualidade oferecida não é aceitável), forma de monitoração dos parâmetros (estatística ou determinística), e possibilidade de renegociação.
Tanto redes ATM quanto a Internet possuem modelos de Qualidade de Serviço.
Em o primeiro temos um contrato entre as partes envolvidas, que define a carga de tráfego, os parâmetros de qualidade especificados por o padrão ATM e o que seria uma perda aceitável de qualidade.
Já para a Internet QoS tem sido amplamente discutida por a comunidade de pesquisa.
Introdução Atualmente, novas arquiteturas estão sendo propostas buscando oferecer o suporte necessário para que as aplicações multimídia tenham seus requisitos de QoS atendidos.
Estas arquiteturas são amplas em escopo e diferem em várias formas, os quais são resultados das diferentes necessidades sentidas por a comunidade de pesquisa.
A mais importante diferença é relatada quanto a especificação de QoS e seus parâmetros.
Atualmente, não existe qualquer padrão internacional ou especificação dominante de parâmetros de QoS da camada de aplicação para a camada de rede.
Em a arquitetura Internet introduzir Qualidade de Serviço tem sido um assunto intensivamente discutido e explanado dentro de a indústria e de comitês de padronização.
Pode- se dizer que poucos grupos de trabalho do IETF têm sido formados para tratar de abordagens relativas à QoS.
Em geral, abordagens de QoS podem ser divididas em duas principais categorias:
Baseadas em fluxo e baseadas em classes;
E, muitas vezes é possível e necessário para a rede possuir ambas, QoS baseada em fluxos, e QoS baseada em classes.
Os dois principais modelos relacionados a essas abordagens de QoS, Modelo de Serviços Integrados e Modelo de Serviços Diferenciados, são descritos de forma mais detalhada nos próximos itens;
E, em seguida, uma arquitetura que estende as funcionalidades ao Modelo de Serviços Integrados é apresentada juntamente com uma nova abordagem relativa à aplicações adaptativas.
Modelo de Serviços Integrados A Internet, como originalmente concebida, oferece somente um único modelo de serviço chamado &quot;best-effort», e consequentemente um único nível de QoS.
Ela não prove garantia de recursos ou medidas de desempenho como por exemplo, atraso máximo, largura de banda mínima apud.
Além disso, a rede não garante entrega de pacotes para seus destinos, nem oferece alocação de recursos especiais para quaisquer pacotes.
Antes de aplicações em tempo real poderem ser amplamente utilizadas, a infraestrutura da Internet deve ser modificada para oferecer suporte de QoS em tempo real;
E, está claro que o modelo de serviço primitivo da Internet é inadequado para essas aplicações.
Desta forma, surge o termo Serviços Integrados (IntServ -- Is), o qual designa uma extensão do modelo de serviço da Internet que inclui além de o serviço &quot;best-effort «outras duas classes de serviço,:
Serviço Garantido:
Oferece um nível garantido de largura de banda, um limite rígido no atraso de pacotes fim-a-fim, e sem perda nas filas de pacotes de um fluxo de dados.
Ele é voltado para aplicações com requisitos restritos de entrega em tempo real, como por exemplo, certas aplicações de áudio e vídeo que são intolerantes a qualquer datagrama chegando depois de seu tempo de reprodução (emulação de circuitos).
Serviço garantido importa- se com o suporte de aplicações que esperam um modelo de entrega semelhante aos tradicionais circuitos de telecomunicações.
Serviço de Carga Controlada: Aproxima- se ao serviço best-effort sobre uma rede não congestionada.
Uma descrição das características do tráfego do fluxo desejando um serviço de carga controlada pode ser submetido ao roteador.
Se o fluxo é aceito para obter um serviço de carga controlada, então o roteador realiza um comprometimento para oferecer ao fluxo um serviço equivalente àquele dito fluxo best-effort numa rede levemente carregada.
A diferença do serviço tradicional best-effort da Internet é que os fluxos de carga controlada não percebem piora quando a carga da rede aumenta.
Isso pode ser verdade indiferente do nível de carga aumentar.
Em contraste, um serviço besteffort pode experimentar um serviço pobre progressivamente (maior atraso e perda) quando a carga da rede aumenta.
O serviço de carga controlada é entendido para aquelas classes de aplicações que podem tolerar uma certa quantidade de perda ou atraso.
Exemplos de aplicações nesta categoria incluem aplicações em tempo real adaptativas.
Algumas considerações foram realizadas quando de o projeto do modelo IntServ.
A primeira consideração é que recursos (largura de banda) devem ser explicitamente administrados para reunir os requisitos das aplicações.
Isto implica que &quot;reserva de recursos «e &quot;controle de admissão «são os blocos principais para o serviço.
Segunda, os roteadores devem estar habilitados a reservar recursos, de modo a prover especial QoS para os fluxos de dados mantendo estados de reserva para cada um.
Outra consideração fundamental é que o modelo IntServ utilize a Internet como uma infra-estrutura comum para suportar ambas comunicações não tempo real e em tempo real.
Baseadas nessas considerações pode- se perceber que uma extensão dos serviços básicos IP incluindo estado adicional por fluxo nos roteadores e um mecanismo de inicialização de reservas explícito faz- se necessário para prover os serviços necessários.
Desta forma, pode- se afirmar que o grupo de trabalho IntServ definiu uma extensão da arquitetura Internet complementando os serviços básicos IP, mas não substituindo- os, tendo como objetivo criar um modelo de referência de componentes para facilitar a transmissão de &quot;flows «4 de tráfego &quot;best-effort «e tráfego em tempo real sobre uma rede IP.
O modelo visa estender a funcionalidade básica dos roteadores para habilitar- los a participar de um rede de Serviços Integrados.
Essa extensão proposta compreende dois elementos:
Uma extensão do modelo de serviço atualmente encontrado, sendo assim referência utilizada na implementação do modelo de Serviços Integrados.
Modelo O modelo de referência para implementar o modelo de Serviços Integrados, o qual é restrito à rede mas aplicável aos sistemas finais também, compreende quatro componentes contidos em hosts e roteadores:
Controle de Admissão:
Realiza uma decisão local de aceitação ou rejeição da requisição de reserva baseada numa comparação dos recursos requisitados e os recursos da rede disponíveis no nodo (roteador).
Assim, ele implementa um algoritmo de controle de admissão para determinar se um novo fluxo pode ser admitido ou não.
Classificador de Pacotes: Inspeciona múltiplos campos em cada pacote de entrada para determinar a classe do pacote e, assim, o nível de serviço a ser concedido para ele.
Escalonador de pacotes:
Aplica um ou mais mecanismos de administração de tráfego, tal como escalonamento de filas avançado (Weighted Fair Queuing5 ou WRQ) para assegurar que o pacote é transmitido dentro de a rede em tempo para satisfazer as restrições de largura de banda e atraso do flow.
Em o contexto do modelo IntServ, um flow define um stream de pacotes com o mesmo endereço fonte e destino e números de porta e, com os mesmo requisitos de QoS.
Weighted Fair Queuing marca pacotes individuais de um fluxo com um timestamp baseado na taxa de chegada ao roteador.
A fila de saída do escalonador é reordenada quando um novo pacote chega, assim pacotes com um tempo menor são transmitidos antes.
Protocolo de reserva:
Necessário para criar e manter um estado de especificação de fluxo nos roteadores ao longo de o caminho do fluxo.
O protocolo escolhido para isso foi o protocolo RSVP, que, devido a a sua importância é apresentado como um item separado.
IntServ foi criado para ajudar a facilitar a transmissão de fluxos de tráfego best-effort e tempo real sobre uma rede IP.
A Figura 9 ilustra os componentes básicos do modelo IntServ.
O protocolo de Reserva de Recursos O protocolo de reserva de recursos (Resource reSerVation Protocol ou RSVP) foi especificado com o intuito de atender ao recente modelo de Serviços Integrados da Internet especifica da rede para um fluxo de pacotes de uma aplicação particular.
RSVP é também utilizado por os roteadores para entregar requisições de QoS para todos os nodos ao longo de o caminho do fluxo e para manter estados para cada fluxo provendo, dessa forma, o serviço requerido.
Requisições RSVP podem geralmente resultar em recursos sendo reservados em cada nodo ao longo de o caminho dos dados.
RSVP é um protocolo simplex;
Ele reserva recursos somente numa direção, tratando origem diferente do destino, sendo que um processo de aplicação pode agir como origem e destino ao mesmo tempo.
Ele opera sobre os protocolos IPv4 ou IPv6, ocupando o lugar de um protocolo de transporte na pilha de protocolos.
Entretanto, ele não transporta o dado da aplicação, sendo apenas um protocolo de controle da Internet, como por exemplo, o IGMP, ICMP ou protocolos de roteamento.
RSVP não é um protocolo de roteamento, mas foi projetado para ser utilizado em conjunto com protocolos de roteamento ponto a ponto ou ponto a multiponto atuais e futuros.
Uma das vantagens do protocolo RSVP é que ele utiliza &quot;soft state «para manter estados de reserva em cada roteador para cada flow:
Reservas são canceladas se elas não forem atualizadas periodicamente.
Isto evita reservas orfãs e permite que reservas adaptemse rapidamente a modificações realizadas nos roteadores, sem envolvimento dos sistemas finais (mudança de caminho).
O termo &quot;soft state «refere- se a «um estado mantido na rede que, quando perdido, pode ser automaticamente reinstalado por o RSVP logo depois disso.
Além disso, o protocolo define como as aplicações realizam reservas e como liberam os recursos uma vez que suas necessidades terminaram.
Para realizar uma reserva de recurso num nodo (host e roteador), o &quot;daemon «RSVP comunica- se com dois módulos de decisão locais, Controle de Admissão e Controle de Política.
O controle de admissão determina se o nodo possui recursos disponíveis o suficiente para suprir a QoS requerida.
O controle de política determina se o usuário possui permissão administrativa para realizar a reserva.
Se uma ou outra saída falhar, o programa RSVP retorna uma notificação de erro para o processo de aplicação que originou a requisição.
Se ambas as saídas obtiveram sucesso, o daemon RSVP envia parâmetros para um Classificador de Pacotes e Escalonador de Pacotes para obter a QoS desejada.
O classificador de pacotes determina a classe de QoS de cada pacote e o escalonador coordena a transmissão dos pacotes para adquirir a QoS prometida para cada stream.
A Figura 10 ilustra o processo de tentativa do protocolo RSVP na reserva de recursos num nodo.
Como já mencionado, RSVP é iniciado por o recebedor e dois tipos de mensagens são usadas para reserva de recursos:
PATH e RESV.
Cada fonte de dado envia uma mensagem PATH, a qual contém uma especificação de fluxo (largura de banda) para o endereço multicast de destino.
Quando um roteador recebe uma mensagem PATH, ele registra as informações relevantes (por exemplo, endereço IP multicast, especificação de fluxo, identificação da fonte, etc).
Como resultado, não somente os recebedores são informados da especificação do fluxo do tráfego do dado, mas os nodos intermediários também obtém a informação do estado PATH.
Baseado nessa informação obtida das mensagens PATH e dos protocolos de mais baixo nível, cada recebedor pode determinar a QoS requisitada e iniciar uma mensagem RESV para reservar recursos específicos ao longo de a rota reservada por a mensagem PATH.
Mensagens PATH são enviadas periodicamente para estabelecer ou atualizar um estado PATH em cada recebedor.
Múltiplos recebedores podem enviar mensagens RESV para a mesma fonte.
Essas mensagens são reunidas (processo de merging) enquanto elas passam por a árvore multicast e somente depois disso são passadas para a fonte.
Recursos podem então ser reservados ao longo de a rota do originador até o recebedor.
Ainda, associada com cada reserva realizada nos roteadores existe um filterspec descrevendo os pacotes para os quais a reserva se aplica, juntamente com uma especificação do fluxo (flowspec).
Ambos filterspec e flowspec são obtidos por o processo de merging aplicado para selecionar mensagens RESV chegando ao roteador.
Atualmente, RSVP possui três diferentes estilos de reserva,:
Fixed Filter (FF), Shared Explicit (SF), Wildcard Filter (WF).
Fixed Filter (FF) indica que uma única reserva pode ser alocada para um simples enviador, a qual pode ser apropriada para uma aplicação de videoconferência requisitando largura de banda mínima e restritos limites em atraso.
O estilo Shared Explicit (SE) torna possível múltiplos enviadores de uma mesma sessão compartilharem uma única reserva.
Por exemplo, 10 pessoas podem participar de uma audioconferência, mas somente uma pode falar de cada vez.
Ao invés de realizar 10 reservas separadas de 64 Kbytes de largura de banda cada, uma única reserva de 64 Kbytes é alocada e compartilhada por todos os enviadores (participantes), sendo utilizada somente por uma pessoa correntemente falando.
Wildcard Filter (WF) permite reserva de recursos para um tipo geral de fluxo, sem identificação de cada enviador;
E, todos os fluxos desse tipo compartilham os recursos reservados.
Normalmente, esse estilo é utilizado por aplicações de audioconferência, como no estilo SE, onde os participantes (especialmente enviadores) naturalmente alternam sua vez de conversar.
Modelo de Serviços Diferenciados A proposta de implementar QoS em redes IP utilizando serviços diferenciados surgiu da necessidade de algo mais simples para obter melhor escalabilidade, diferente do modelo IntServ, em o qual a escalabilidade passa a ser comprometida devido a o grande número de estados por fluxo que o roteador deve manter.
Assim, o objetivo do modelo é o oferecimento de QoS na Internet com escalabilidade, ou seja, sem a necessidade de estado por fluxo e sinalização a cada nó.
A escalabilidade passa a ser obtida através da agregação de fluxos em grandes conjuntos, oferecimento de recursos (sem protocolo de reserva de recursos) para essas agregações e separação de funções para roteadores de borda e de núcleo.
Redes que implementam DiffServ são chamadas Domínios Ds (a Intranet de uma organização ou um Provedor de Serviços) e os roteadores habilitados são chamados nós Ds.
De uma forma geral, a idéia de modelo de Serviços Diferenciados (DiffServ) baseia- se em reserva de recursos para um conjunto de fluxos e não para um único fluxo.
A abordagem utilizada por o DiffServ é para classificar microfluxos6 individuais na extremidade da rede numa das várias classes de serviços (tal como ouro, prata e bronze) e então aplicar um serviço por classe no meio de a rede.
A classificação é realizada no ingresso da rede baseada numa análise de um ou mais campos do pacote.
O pacote é então marcado como pertencente a uma classe de serviço particular e então injetado dentro de a rede.
Os roteadores de núcleo que examinam o pacote observam um campo particular do cabeçalho para determinar como o pacote pode ser tratado (qual fila de transmissão o pacote pode ser colocado).
Para determinar isso a arquitetura DiffServ define vários componentes:
O campo Ds é um bit padrão contido no cabeçalho de cada pacote que denota o serviço (chamado Per-hop Behavior ou PHB) que o pacote pode receber a cada hop enquanto ele Class no IPv6 tem sido redefinidos como campos Ds, respectivamente.
O campo Ds contém 8 bits, 6 de os quais são Ds codepoints (DSCP) e 2 bits que atualmente não estão definidos.
Ds codepoints são utilizados para selecionar um PHB.
O Per-hop Behavior (PHB), ou comportamento por hop, define o serviço que o pacote recebe em cada hop quando ele é enviado através da rede.
Um Behavior Aggregate (BA), ou Ds behavior aggregate, ou comportamento agregado, é um grupo de pacotes com o mesmo DSCP.
Um serviço que o pacote recebe em cada hop é aplicado a cada BA dentro de a rede.
PHB é um comportamento externamente observável em cada nodo que é realizado através de técnicas internas de administração de filas e escalonamento.
Microfluxo é uma única instância de um fluxo de pacotes de aplicação para aplicação, o qual é identificado por o endereço fonte, porta fonte, endereço destino, porta destino e identificação do protocolo.
O roteador de borda é posicionado na extremidade de uma rede que implementa a noção DiffServ.
Esse dispositivo é responsável por a classificação de pacotes, medição, marcação de pacotes e condicionamento de tráfego (policiamento).
Administradores de rede são responsáveis por configurar esse classificador de modo a atender ao usuário externo definindo, assim, os campos a serem examinados em cada pacote e outras ações como por exemplo, o descarte de pacotes que não estão em conformidade com o Token Bucket Filter.
Token buket filter é um mecanismo que caracteriza a carga de tráfego da aplicação recebendo um serviço particular.
Ele pode ser conceitualizado como um balde de profundeza B que é enchido com tokens num taxa de R tokens por segundo.
Quando um pacote chega ao roteador, algum número de tokens (baseado no tamanho do pacote) são subtraídos do balde.
Um token bucket filter permite a um fonte transmitir uma rajada de pacotes igual ao número total de tokens no balde, o qual é menos do que ou igual a B. As funções definidas para o roteador de borda podem ser realizadas num roteador, firewall, ou um host.
Nodos interiores podem ser switches de núcleo ou roteadores que provem o PHB baseado nos bits DSCP contidos no campo Ds.
Normalmente, esses dispositivos empregam uma disciplina de escalonamento e administração de filas para prover o PHB.
Normalmente, quem marca o campo Ds dos pacotes para indicar a necessidade de um serviço com baixo atraso, alta vazão, ou baixa taxa de perdas é o roteador que liga o cliente a rede do Provedor de Serviço.
Se não for ele, quem também pode realizar esta função é a aplicação.
Por marcar os campos Ds dos pacotes diferentemente e tratar os pacotes baseados nos seus campos Ds, várias classes de Serviço Diferenciados podem ser criadas.
Assim, serviços diferenciados é essencialmente um esquema de prioridade.
Para um usuário receber serviços diferenciados do provedor de serviços da Internet o provedor.
Um SLA basicamente especifica as classes de serviço suportadas e a quantidade de tráfego permitida em cada classe.
SLAs estáticos são negociados num período regular (mensalmente ou anualmente).
Usuários com SLAs dinâmicos podem utilizar um protocolo de sinalização (RSVP) para requisitar serviços sob demanda.
Nos ingresso das redes dos Provedores de Serviço, pacotes são classificados, policiados e, possivelmente, modelados (i.
e, atrasado).
A classificação, policiamento e as regras de modelagem usadas nos roteadores de ingresso são derivados dos SLAs.
A quantidade de espaço em buffer necessárias para essas operações é também derivada dos SLAs.
Quando um pacote passa de um domínio para outro, o campo Ds pode ser remarcado como determinado por o contrato de serviço entre os dois domínios.
Utilizando mecanismos de classificação, policiamento, modelagem, e escalonamento muitos serviços podem ser oferecidos, tais como:
Serviço Premium para aplicações requerendo serviço com baixo atraso e baixa variação de atraso.
Serviço Assegurado para as aplicações requisitando melhor confiabilidade do que o serviço best-effort.
Serviço Olympic, o qual provê três tipos de serviço:
Ouro, prata e bronze, com qualidade descrescente.
A figura acima ilustra as funções do modelo DiffServ.
Pacotes entram na rede através de um roteador de ingresso de borda.
Cada pacote passa através de um classificador multifield7 (MF classifier), o qual trabalha com um medidor de tráfego (Traffic meter) para determinar qual a próxima tarefa a ser realizada.
A regra do medidor de tráfego é medir a conformidade dos pacotes com uma configuração de tráfego concordada entre o provedor da rede e o usuário.
Pacotes pertencentes a configuração ou aqueles que estão dentro de os parâmetros da configuração podem ser tratados diferentemente de pacotes não pertencentes a essa.
Os bits Ds codepoints no campo Ds podem então ser marcados e o pacote condicionado (modelado ou descartado) antes de entrar na rede.
Os roteadores de núcleo contém um simples classificador de BA que determina o PHB a ser aplicado ao pacote.
Todos os pacotes pertencentes a um mesmo BA são tratados da mesma forma.
Cabe salientar que dois PHBs já estão sendo amplamente utilizados e têm sido propostos para padronização:
Default (De) é o comum, padronizado por a RFC 1812, o qual oferece encaminhamento best-effort disponível na Internet atual.
Encaminhamento normalmente utilizado para controle de tráfego na rede, tal como, atualização de rotas.
Outro grupo de PHB que também tem sido padronizado chama- se Encaminhamento Assegurado Default (De):
Um pacote de entrada vai para o fim de uma fila que é servida numa ordem FIFO (First In First Out) quando o link de saída está livre.
Assim, se um stream contínuo de pacotes marcados De é enviado para um roteador, os pacotes podem emergir na mesma ordem em que eles entraram.
O comportamento Default foi projetado para aproximar- se ao comportamento best-effort dos roteadores existentes.
Encaminhamento Expresso (EF):
Projetado para suportar baixas perdas, baixo atraso e baixa variação de atraso.
Ele mostra- se como um serviço de linha virtual alugada ponto a ponto (Virtual Leased Line -- VLL) entre pontos finais suportando picos na largura de banda.
Para minimizar variação de atraso e atraso, pacotes devem despender pouco tempo ou nenhum tempo nas filas dos roteadores.
Assim, o comportamento EF requer que o tráfego seja condicionado para conformar a taxa de pico nas bordas, e a rede de roteadores ser configurada, tal que, esta taxa de pico seja menor do que a taxa de saída mínima em cada roteador da rede.
O comportamento EF utiliza um único bit DSCP para O processo de classificar pacotes baseado nos conteúdos de múltiplos campos tal como endereço e destino.
Encaminhamento Assegurado (AF):
O comportamento AF define quatro classes de serviço com cada serviço suportando três níveis de precedência de descarte.
Doze distintas combinações de bit DSCP definem as classes AF e a precedência de descarte dentro de cada classe.
Quando congestionamento acontece num roteador, pacotes com alta precedência de descarte podem ser descartados.
A quarta classe AF não define largura de banda específica ou restrições de atraso.
Arquitetura para Reservas Avançadas A arquitetura encontrada em Berson et al.
Apresenta um Servidor para Reservas Avançadas conhecido como Advance ReServation Server ­ Ars, sendo responsável por assegurar que os recursos requeridos possam estar disponíveis para todos os usuários quando necessário.
Para isso, a reserva de recursos é realizada antecipadamente e armazenada no Ars.
A arquitetura oferece um servidor para cada Sistema Autônomo (SA), em o qual o enviador ou o recebedor registram uma reserva antecipada com o servidor pertencente ao seu As, mantendo a reserva ativa e assegurando que outras possam ser estabelecidas.
Como exemplo, imagine uma aplicação de &quot;reunião virtual», como uma videoconferência, onde o grupo realiza a reserva de recursos antecipadamente, e assim asseguram que a QoS requerida vai estar disponível quando necessário.
A abordagem para reservas avançadas acontece através de uma extensão das mensagens RSVP com um tempo inicial de reserva e duração, buscando assim modificar o estilo de reserva de recursos atualmente encontrado, onde quando uma reserva é estabelecida essa inicia imediatamente e possui uma duração indefinida, ou seja, uma vez que os recursos foram reservados eles são dedicados a aplicação e os estados de reserva são mantidos para a aplicação.
Essa abordagem pode ser aplicada em aplicações multicast e unicast como telefonia na Internet ou monitoração remota.
O esquema de reserva de recursos avançada consiste de duas partes:
1) a reserva de recursos avançada propriamente dita;
2) a utilização dos recursos reservados.
Em o primeiro passo, o cliente específica a requisição, ou seja, ele oferece uma especificação do workload (a quantidade de dados a ser transmitida) e define o início e a duração da reserva.
A segunda fase inicia antes do cliente pretender explorar a reserva.
O cliente contata o provedor para requisitar os recursos reservados previamente e então utiliza- os.
Uma vez que uma sessão é estabelecida, os participantes podem ou terminar antes (da reserva realizada previamente), ou querer estender o tempo.
O primeiro caso é simples;
Recursos podem estar disponíveis para outras aplicações.
Em o segundo caso, se a duração da aplicação vem a ser estendida, o sistema pode não ter a quantidade de recursos necessária para servir a aplicação com a QoS desejada.
Se recursos estiverem disponíveis a aplicação pode estender a reserva prévia, mas se os recursos forem insuficientes, o sistema ainda pode tentar servir a aplicação com um serviço do tipo &quot;best-effort», embora com degradação de QoS.
Contudo, existem três principais preocupações com a utilização do mecanismo para reservas avançadas:
A quantidade de estado nos roteadores pode crescer, mas a arquitetura propõe como solução um Servidor de Reservas Avançadas para cada Sistema Autônomo.
As aplicações enviadoras e receptoras necessitam estar ativas durante o tempo inteiro da reserva avançada, ou seja, durante o intervalo em que a reserva avançada foi realizada e sua efetiva utilização.
Os enviadores e receptores devem ser conhecidos antecipadamente, ou através de algum site listando todos os participantes da sessão, ou o próprio participante pode tornar- se conhecido registrando- se diretamente com o Ars, o que não é um problema.
Alguns benefícios podem ser encontrados quanto a reservas avançadas com QoS como por exemplo, contatar outro Provedor de Serviço para reservar os recursos requeridos se o atual provedor não puder;
Modificar o tempo em que a aplicação vai ser executada;
Aplicações Adaptativas Aplicações adaptativas são chamadas &quot;network-- aware», justamente por o fato de adaptarem seu funcionamento as variações de desempenho do ambiente de rede.
São apropriadas para utilização no ambiente Internet e não requerem nenhum suporte especial da rede como por exemplo, controle de admissão e algum mecanismo para fornecer reserva de recursos.
Existem para unir a diferença entre a realidade da rede e a expectativa da aplicação, isto é, para manipular com as variações de performance oferecendo uma certa qualidade para a aplicação.
Assim, nos próximos parágrafos alguns trabalhos que utilizam esta abordagem são descritos.
Em Busse et al.
É apresentado um mecanismo para ajuste dinâmico dos requisitos de largura de banda para aplicações multimídia.
A aplicação enviadora utiliza mensagens RTCP Receiver Reports (RR) para computar perda de pacotes;
E, baseado nessa métrica, o estado de congestionamento dos recebedores é determinado.
Consequentemente, um ajuste na largura de banda é realizado por meio de um algoritmo específico para este fim.
O mecanismo é utilizado por a ferramenta de videoconferência Vic, e vários experimentos foram realizados na Internet e numa rede ATM local.
Marakby et al.
Descrevem uma arquitetura que torna possível transferência de mídias contínuas sobre a Internet utilizando o protocolo RTP.
Em a abordagem utilizada, existe um controlador de taxa adaptativo que ajuda a reduzir o congestionamento da rede através de informações de feedback do protocolo RTCP, ou seja, a taxa de transmissão dos dados é modificada para que a aplicação se ajuste ao estado corrente da rede.
Uma aplicação multimídia adaptativa foi implementada para transferência de áudio e vídeo digital utilizando a abordagem proposta.
Outros trabalhos também relacionados ao ajuste dinâmico da taxa de envio da aplicação de acordo com o nível de congestionamento observado na rede podem ser como os enviadores podem aumentar sua taxa de envio durante situações em que a rede está levemente carregada, e como reduzir- la durante períodos de carga.
Apresenta- se um algoritmo de ajuste que responde as flutuações da rede relacionadas a largura de banda disponível mantendo baixa a taxa de perdas.
Enquanto que no segundo, uma arquitetura e a implementação de uma aplicação multimídia adaptativa, que inclui o uso do protocolo RTP e seu protocolo de controle associado (RTCP), é discutida.
A aplicação faz uso das informações de feedback RTCP para monitoração de QoS do tráfego na rede.
As informações de feedback são utilizadas por um controlador de taxa adaptativo que é disparado no enviador por o parâmetro de QoS fração de perda de pacotes.
O controlador tem por função ajustar e controlar a taxa de transmissão dos dados para aliviar o problema de congestionamento reagindo dinamicamente às modificações nas condições da rede.
Um &quot;terminal de QoS «para aplicações adaptativas é discutido em Moghe et al.
Os autores esperam que a próxima geração de terminais (redes de computadores, computadores pessoais) suporte sofisticadas aplicações adaptativas, pois alguns terminais possuem poder limitado e o atraso de processamento da aplicação pode ser um componente significativo do atraso fim-a-fim.
Enfatizam que, atualmente, cada aplicação possui um algoritmo de adaptação nativo que opera independente de outras aplicações e de seus algoritmos de adaptação.
Em o trabalho é apresentada uma relação analítica entre feedback da rede e o nível de adaptação da aplicação.
O framework teórico é apropriado para entender a relação e interação entre a aplicação adaptativa, o sistema final e a rede.
Em Bolot é apresentado um mecanismo de feedback que adapta a taxa de saída de codificadores de vídeo (i.
e fontes de tráfego de vídeo) baseado no estado da rede.
Esse mecanismo foi implementado num codificador de vídeo H. 261 para um sistema de videoconferência na Internet desenvolvido por o INRIA (French Institute for Research in Computer Science and Control).
Ele torna possível estabelecer e manter a qualidade da videoconferência quando congestionamentos ocorrem na rede, prevenindo também, que fontes de vídeo inundem os recursos da rede (buffers e links de saída).
A abordagem apresenta duas importantes vantagens.
A primeira vantagem é que facilmente a taxa de saída de um codificador de vídeo, implementado em software, pode ser controlada por o ajuste dos parâmetros internos do codificador.
A segunda é que ela não requer suporte especial da rede tal como, controle de admissão, alocação de recursos, entre outros.
Vega-García et al.
Utilizam um mecanismo de controle semelhante que adapta o processo de codificação e decodificação baseado nas características da rede.
O objetivo é maximizar a qualidade do áudio transferida aos destinos;
E, os autores descrevem e analisam um conjunto de mecanismos de controle.
Eles incluem um mecanismo de controle para variação de atraso e um mecanismo de controle para taxa de erro que são combinados entre si.
Os mecanismos foram implementados e avaliados sobre a Internet e o MBone.
Experiências realizadas demonstraram que é possível manter e estabelecer audioconferências com qualidade razoável frente a eventuais congestionamentos na rede.
Considerações sobre as Arquiteturas O modelo de Serviços Integrados apresenta uma fundamental modificação na atual arquitetura Internet.
Contudo, apresenta problemas:
A quantidade de informações de estado aumenta proporcionalmente com o número de fluxos.
Isto gera um grande overhead de processamento e armazenamento nos roteadores.
Para cada fluxo deve haver sinalização a cada nó (sistema final ou roteador).
A troca de informações de sinalização é muito grande, justamente porque RSVP trabalha com soft state, prejudicando a escalabilidade.
Os requisitos de processamento nos roteadores é grande.
Todos os roteadores devem ter o protocolo RSVP, mecanismos de controle de admissão, classificação multifield (MF), e escalonamento de pacotes.
A abordagem de serviços diferenciados é diferente da abordagem utilizada por o modelo de serviços integrados.
Primeiro, existe um número limitado de classes de serviço indicadas por o campo Ds.
Uma vez que o serviço é alocado por classe, a quantidade de informações de estados é proporcional ao número de classes, apresentando- se assim mais apropriada do que por número de fluxos, ou seja, serviços diferenciados é mais escalável.
Segundo, classificação sofisticada, marcação, policiamento e operações de modelagem são somente necessárias nas bordas da rede.
Roteadores de núcleo do ISP somente necessitam de classificação para fluxos agregados.
Além disso, existe uma outra razão da segunda característica ser interessante para Provedores de Serviço.
Normalmente, redes de provedores consistem de roteadores de borda conectados a usuários e roteadores de núcleo interconectados aos roteadores de borda.
Roteadores de núcleo devem encaminhar pacotes muito rapidamente.
Roteadores de borda, não necessitam encaminhar pacotes muito rapidamente porque os links dos usuários são relativamente lentos.
Assim, eles podem despender mais tempo em classificação sofisticada, policiamento e modelagem.
Roteadores devem encaminhar pacotes rapidamente e realizar classificação sofisticada, policiamento e modelagem.
Roteadores não DiffServ simplesmente ignoram os campos Ds dos pacotes e oferecem um serviço mais simples.
A abordagem utilizada por a Arquitetura para Reservas Avançadas é interessante, entretanto, algumas desvantagens também podem ser encontradas, principalmente, por os Provedores de Serviço que podem não querer suportar esse tipo de mecanismo.
Alguns argumentos utilizados são:
A heterogeneidade das redes, onde diferentes enlaces e sub-redes podem variar sua largura de banda e outros recursos no tempo;
O aumento de overhead para computar a disponibilidade dos recursos que podem ser reservados;
Os estados das informações de reservas que crescem rapidamente;
As trocas dinâmicas de participantes num grupo multicast, considerando que muitos participantes de uma conferência podem juntarse a ela no último minuto, ou ainda durante a transmissão dos dados (no meio de uma reunião).
De essa forma, reserva avançada não se mostra apropriada para esse cenário.
Considerando que a Internet continuará a funcionar por um período considerável sem reserva de recursos em seus roteadores, para um fluxo ou um conjunto de fluxos, a abordagem que traz a possibilidade de aplicações multimídia adaptarem- se ao desempenho variável da rede mostra- se bastante atrativa e interessante, principalmente se considerarmos a Internet atual, uma rede dominada por um tráfego de dados comercial.
Introdução Como pôde- se perceber ao final do capítulo 5 (seção 5.5), várias aplicações vêm utilizando noções de adaptação como um meio de oferecer um nível mínimo de QoS às várias aplicações multimídia.
Isto se deve a vários fatores que contribuem para que aplicações multimídia não tenham seus requisitos de QoS atendidos de forma satisfatória.
Primeiro, a extensão da arquitetura Internet com reserva de recursos não é, no todo, suficiente para resolver as demandas de QoS de aplicações multimídia.
Não raras são as vezes em que os recursos necessários para uma determinada aplicação não podem ser oferecidos, ou porque ultrapassam o máximo do enlace até a máquina receptora, ou porque já houve uma alocação prévia de recursos impossibilitando a nova reserva.
Em resumo, o que a rede dispõe não supre a real necessidade da aplicação.
Quando isso acontece, a aplicação encontra- se frente a uma política &quot;tudo ou nada», ou seja, ou os recursos demandados são oferecidos, ou nada é disponibilizado.
Segundo, a rede Internet é composta por um conjunto de redes utilizando diferentes características de confiabilidade, atraso e vazão, esta variando deste muitos Mbps por segundo até alguns poucos Kbps.
Além disso, as estações conectadas a estas redes também possuem diferentes capacidades de processamento (CPU e barramento).
Essa diferença de capacidade pode exercer grande influência quanto a a percepção do usuário final da aplicação, principalmente se for considerado um cenário de reprodução de mídias contínuas recebidas da rede.
Além disso, com a ampla utilização de aplicações multimídia em tempo real, computadores pessoais estão agora processando áudio e vídeo em adição a suas tarefas mais tradicionais.
Isso tudo pode levar a aplicação multimídia ter um comportamento não previsível dependendo da máquina onde for executada.
Outro fator a ser considerado é que ao construir uma aplicação multimídia sobre a Internet, o desenvolvedor da aplicação pressupõe que a mesma possa ser utilizada a partir de um ponto qualquer desta rede.
De essa forma, existe a necessidade de que mecanismos de adaptação sejam implementados para que a aplicação tenha um bom funcionamento frente a os recursos limitados disponibilizados por a rede ou por a estação onde a aplicação possivelmente vai ser executada.
Finalmente, outro fator que contribui para que as aplicações adaptem- se ao que a rede oferece, é que, apesar de a possibilidade técnica de reserva de recursos (para um fluxo, ou um conjunto de fluxos), devido a a abrangência da Internet num grande número de domínios administrativos, pode- se dizer que muitas partes da rede funcionarão por um tempo considerável sem suporte a reserva de recursos;
Porém, mesmo sendo utilizada em toda a Internet, assume- se que esta reserva tornará- se- cara em termos de troca de mensagens e terá uma tarifação agregada.
Muitos dos usuários finais podem não querer pagar por um serviço melhor contentando- se com o que a rede oferece.
Em cenários onde reserva de recursos não é suportada a degradação da mídia pode acontecer de tal forma que a mesma torne- se incompreensível.
Logo, mecanismos de adaptação devem ser oferecidos evitando tais situações de acontecerem.
Assim, considerando tais aspectos, uma possibilidade para a aplicação é adaptar- se as condições que lhe são oferecidas, principalmente as condições variáveis providas por a rede de comunicação de dados.
Como conseqüência, mecanismos de adaptação devem ser incorporados as soluções encontradas.
Em esse cenário, a responsabilidade em oferecer QoS para a aplicação multimídia permanece também, em grande parte, com o desenvolvedor da mesma.
Entretanto, nenhum suporte genérico é disponibilizado a ele buscando facilitar seu trabalho em oferecer QoS à aplicação.
A implementação de uma aplicação adaptativa particular é uma tarefa complexa para a maioria dos desenvolvedores de aplicações, implicando assim no tratamento de aspectos de comunicação como atraso, perda de pacotes, variação de atraso e vazão.
Detalhes como obtenção e tratamento dos dados obtidos da rede de forma continuada, bem como modificações no comportamento da aplicação ocultando possíveis variações no desempenho de rede são algumas tarefas que fazem parte desse processo e que devem ser consideradas na implementação de tais aplicações.
Isso não é uma tarefa trivial de ser realizada e requer habilidade do programador para tratar de questões desse tipo.
De essa forma, um suporte genérico para a construção de tais aplicações faz- se necessário;
E, de maneira a preencher essa lacuna o trabalho aqui apresentado oferece uma API para auxiliar o desenvolvedor de uma aplicação multimídia qualquer na realização de tal atividade.
Para maiores detalhes, o guia do usuário para utilização da API encontra- se no Anexo deste trabalho.
Qualidade de Serviço.
A Camada é representada como uma camada funcional que trabalha sobre o protocolo para transporte de dados com propriedades de tempo real, RTP.
Funcionalidades como monitoração da Qualidade de Serviço referente a o tráfego dos dados e adaptação da aplicação a qualidade recebida da rede são os serviços disponibilizados por a Camada de Adaptação de QoS à Camada de Aplicação da Arquitetura Internet.
As setas da figura acima representam:
Especificação de valores para os parâmetros de QoS da aplicação;
Fluxo de pacotes de dados RTP (transmissão e recepção);
fluxo de pacotes de controle RCTP (Sender Reports e/ ou Receiver Reports);
notificação sobre estado da rede, mais parâmetros de QoS (nível de rede); (
5) gatilho para execução de a (s) política (s) adaptativa (s).
O mecanismo geral de controle utilizado por a camada resume- se em análise de pacotes RTCP;
Estimativa do estado da rede;
Aplicação de políticas adaptativas em conformidade com o estado corrente da rede e em métricas realizadas com base nos parâmetros de Qualidade de Serviço especificados por a aplicação e obtidos da rede.
Um aspecto importante é como o mecanismo de adaptação escolhido reage às decisões de estimativa do estado da rede.
Essa reação depende das características da aplicação e do próprio controle interno da camada.
Todos os passos, exceto a aplicação de políticas adaptativas, são independentes das características de QoS especificadas.
Monitoração de QoS é o processo de observar eventos relacionados com os requisitos de QoS da aplicação, reportando parâmetros de desempenho da rede e tornando possível identificar seu estado corrente.
Logo, o processo de monitoração possui a responsabilidade de observar ações relacionadas com parâmetros de QoS e enviar mensagens para mecanismos que possam tratar- los.
De essa forma, esse indicará a ocorrência de violações quanto a QoS que está sendo oferecida por a rede.
Normalmente, o processo de monitoração está associado aos protocolos de transporte e é realizado por quem está recebendo os dados.
Assim, o recebedor pode monitorar a QoS e enviar feedback ao emissor sobre a recepção dos dados, informando número de pacotes perdidos, atrasos e suas variações.
Em a Camada de Adaptação de QoS, os parâmetros de QoS considerados são a nível de rede, mais especificamente, parâmetros relacionados com o tráfego dos dados.
Adaptação de QoS Adaptação de QoS é o processo em o qual a aplicação torna- se capaz de ajustar- se às mudanças constantes das condições da rede.
Desta forma, aplicações multimídia necessitam tornarem- se adaptativas perante as variações dinâmicas no desempenho da rede (mudanças constantes na largura de banda oferecida, variação de atraso não uniformes entre cada pacote entregue ao recebedor dos dados, atraso de pacotes fim-a-fim não controlados).
Isso significa que a aplicação deve tolerar flutuações de operação da rede ajustando seu funcionamento ao que lhe é oferecido.
Freqüentemente, o processo de adaptação acontece como resultado de notificações emitidas por mecanismos de monitoração de Qualidade de Serviço.
Esses indicam mudanças no serviço que está sendo oferecido por a rede.
Em aplicações adaptativas não existem protocolo de reserva de recursos, nem contrato de QoS com a rede.
Normalmente, mecanismos de adaptação de QoS possuem um conjunto de políticas adaptativas.
Uma política adaptativa pode ser entendida como um conjunto de estratégias que tentarão assegurar à aplicação que essa terá pelo menos um nível mínimo de QoS.
A regra de adaptação para QoS consiste em realizar ações corretivas baseadas na QoS verificada e nos requisitos de QoS especificados por a aplicação.
Mecanismos de adaptação de QoS são, normalmente, localizados no lado enviador de uma conexão;
Porém não está excluída a possibilidade do mecanismo localizar- se no lado recebedor (ou qualquer um).
Esses, podem ser associados ao transporte dos dados, a aplicação ou ao sistema de sinalização.
Exemplos de mecanismos incluem controle de fluxo (no transporte), adaptação da taxa de codificação de um vídeo MPEG-II (na aplicação) e renegociação de QoS (com sinalização).
Adaptação de QoS, os mecanismos de adaptação estão relacionados ao transporte dos dados e parcialmente a aplicação.
Funcionamento da Camada Em esta seção será explicado o funcionamento dos módulos de monitoração e adaptação constituintes da Camada de Adaptação de QoS.
Em o diagrama de classes UML (Unified Modeling Language ou Linguagem de Modelagem Unificada), representado na Figura 15, os objetos no sistema e os vários tipos de associações estáticas que existem entre eles são ilustrados.
O diagrama é divido em três classes principais que se relacionam com uma interface externa chamada &quot;Sessão RTP Par», a qual é considerada como um componente externo e que não nos interessou modelar seu comportamento.
A primeira classe, monitoração, contém informações referentes às tarefas de monitoração de QoS, entre elas recepção de pacotes RTCP, obtenção de parâmetros de QoS a nível de rede, estimativa de seu estado contemplando informações referentes a atraso, variação de atraso, fração de pacotes perdidos desde o último Sender Report recebido, status da rede e taxa de perdas.
Criada para verificar a qualidade do tráfego da rede possui métodos que detectam a chegada de pacotes de controle RTCP, manipulam as informações contidas em cada report block (seção com informações do recebedor dos dados) do pacote, calculam a taxa de perdas e estimam o estado atual da rede.
Dois outros métodos permitem inserir e retirar políticas de adaptação através da associação utilizar, a qual pode ser usada por a classe Sessão RTP.
A segunda classe, adaptação, possui informações referentes às atividades de adaptação de QoS, sendo a principal de elas a aplicação de políticas adaptativas.
Em a classe adaptação, informações sobre os parâmetros de QoS desejados por a Sessão RTP são contemplados, sendo esses fornecidos através da associação informar parâmetros QoS.
Desta forma, essa classe realiza ações de comparação dos parâmetros de QoS da rede, obtidos através da associação receber parâmetros QoS rede, e QoS da aplicação.
Criada com o intuito de oferecer um nível mínimo de QoS para a aplicação através da aplicação de políticas adaptativas.
Finalmente, a classe Sessão RTP, a qual interage com as outras duas classes principais do sistema informando parâmetros de QoS para a aplicação e utilizando- se da classe monitoração para controle do tráfego dos dados.
Em resumo, uma instância da classe monitoração é utilizada por uma sessão RTP particular, essa última interagindo com uma instância da classe adaptação informando valores para os parâmetros de QoS desejados para a mídia (áudio ou vídeo).
A instância adaptação, por sua vez, interage com a classe monitoração recebendo parâmetros de QoS a nível de rede e comparando- os com os valores recebidos da sessão RTP, testando, dessa forma, se a política pode ser aplicada ou não à sessão em questão.
Optou- se por construir uma classe para cada módulo do sistema para tornar mais clara sua representação.
Módulo de Monitoração O processo de monitoração, que tem por função supervisionar a qualidade da rede, é realizado na medida em que pacotes de controle, RTCP Sender Reports (Sr) ou Receiver Reports (RR), vão sendo recebidos por a aplicação e, ao mesmo tempo detectados por o módulo de monitoração.
O intervalo de chegada dos pacotes de controle pode variar de 5 segundos a 1 minuto (ou mais), dependendo do número de participantes, da largura de banda alocada para o tráfego RTCP e também do tamanho do pacote.
A monitoração do tráfego dos dados, pode ser realizada tanto na aplicação enviadora, quanto na aplicação recebedora dos dados, sendo esta aplicada a cada mídia particular enviada ou recebida.
Em o recebedor, a monitoração é realizada por meio de a análise dos pacotes RTCP Sr, os quais são enviados por o fonte de dados RTP, enquanto que no enviador, a monitoração acontece através da análise dos pacotes RTCP RR enviado (s) por o (s) recebedor (es).
Basicamente, estes dois pacotes de reports, RR e Sr, contêm as mesmas informações;
Entretanto pacotes RTCP Sr contém informações de identificação de quem é o fonte de sincronização, do número de pacotes RTP, número de bytes de dados RTP que o enviador tem transmitido, além de informações temporais que permitem ao cliente sincronizar áudio e vídeo enviados em sessões diferentes.
Todos os pacotes com o mesmo valor de SSRC fazem parte de um mesmo espaço de números de seqüência e timestamp.
Isso faz com que o receptor monte os dados de uma mesma fonte para serem apresentados.
Ainda, cada mídia é levada numa sessão RTP diferente com valores SSRC também divergentes. Conforme
pode- se perceber na Figura 16, o destino, ao receber os dados, realiza estatísticas descrevendo como está a qualidade da recepção, encapsula num pacote chamado RTCP RR, ou seja, report do recebedor, e envia ao emissor.
Esta qualidade da recepção dos dados refere- se a informações que dizem respeito ao número de pacotes perdidos desde o instante inicial da transmissão, fração de pacotes perdidos desde o último report Sr, maior número de seqüência recebido, variação do atraso de chegada no intervalo de recepção de um pacote para outro, atraso desde o último Sr e atraso do último Sr. Quando o emissor for fonte e destino ao mesmo tempo (numa conferência), ele envia junto com o pacote RTCP Sr informações recebidas de cada destino (pacotes RTCP RR).
Essas informações são colocadas em seções chamadas receiver blocks, deste mesmo pacote, permitindo assim ao destino saber como os outros recebedores estão recebendo os dados.
Ainda, através deste pacote, o destino tem acesso as suas próprias informações de feedback enviadas ao fonte dos dados.
Informações como essas são apropriadas para controle de aplicações multimídia adaptativas.
O módulo de monitoração utiliza um mecanismo para tratamento de eventos remotos, os quais podem indicar a chegada de um pacote RTCP Sr, ou RTCP RR.
Assim, quando um pacote desse tipo chega (fonte ou destino dos dados), ele é detectado e tratado por o módulo.
Este tratamento, realizado a cada intervalo de recepção de um pacote de controle RTCP, consiste em:
Em o recebedor, apenas o seu report block é analisado;
Isso justifica- se porque o cliente está interessado somente nas informações que ele enviou ao recebedor de seu report.
No entanto, no lado emissor, todos os report blocks são analisados e, em especial, o parâmetro fração de pacotes perdidos de cada fonte RTCP RR é acumulado para verificar como todos os recebedores estão sentindo a qualidade da rede.
Como o trabalho considera apenas sessões unicast, o emissor somente analisa um report block de cada pacote.
Finalmente, com os parâmetros de QoS a nível de rede obtidos e estimado seu estado, uma notificação contendo essas informações é enviada ao módulo de adaptação de QoS.
Esse último verifica se existe a necessidade de adaptação, e dependendo do caso, aplica a (s) política (s) escolhida (s) por o desenvolvedor da aplicação.
O diagrama de estados representado por a Figura 17 ilustra o comportamento do módulo durante o funcionamento do sistema.
O algoritmo utilizado neste trabalho é baseado na informação fração de pacotes perdidos encontrada em receiver blocks dos pacotes de controle RTCP.
Cabe ressaltar que, normalmente, a infra-estrutura da Internet não oferece às fontes de tráfego informações de feedback sobre o estado da rede de forma explícita.
As informações facilmente disponíveis são informações implícitas como medidas de perdas e/ ou atraso ida e volta.
A) Análise das mensagens RTCP Somente a taxa de perda de pacotes é utilizada para identificar congestionamento na rede.
Em Busse et al.,
uma fórmula para calcular a taxa de perda, suavizar estatísticas e evitar oscilações de QoS é apresentada, e foi adotada para utilização neste trabalho.
Essa fórmula é descrita por a Equação 1.
Equação 1 -- Fórmula para cálculo da taxa de perdas Onde, b $= novo valor referente a fração de perda de pacotes $= fator de suavização que determina o peso que é dado a taxa de perdas anterior A rede é avaliada constantemente por o algoritmo que verifica seu comportamento de acordo com a fração de pacotes perdidos, obtida através do sequence number contido no cabeçalho dos pacotes de dados RTP (no recebedor).
O estado anterior da rede sempre é levado em consideração a cada novo cálculo da taxa de perdas de modo a evitar tomadas de decisões de adaptação não necessárias em períodos curtos de pico da rede.
Também, procurou- se descobrir um valor adequado para.
Primeiro testou- se a fórmula com $= 0,3, a qual resultou numa taxa de perdas muito abaixo de o real percentual de pacotes perdidos na rede, conforme pode ser visualizado no gráfico da Figura 18.
Depois testou- se $= 0,5, o que resultou numa taxa bem próxima da realidade, e finalmente testou- se a fórmula com um $= 0,7, a qual mostrou um percentual acima de a taxa de perdas real da rede.
Logo, o valor de adotado para aplicação na fórmula foi de 0,5.
B) Estimativa do estado da rede baseado em perdas O estado da rede é determinado como carregado, não carregado, congestionado.
Dois limites são utilizados para isso9, ou seja, até 2%, rede não carregada;
De 2% à 4%, rede carregada;
Acima de 4%, rede congestionada.
O processo funciona da seguinte forma, o valor perda de pacotes passa por o filtro e este computa a taxa de perdas de pacotes.
Depois deste cálculo, o estado da rede é determinado.
O processo pode ser visualizado na Figura 21.
Módulo de Adaptação O processo de adaptação, que tem por função adaptar a aplicação ao comportamento variável da rede, recebe uma especificação de QoS fornecida por a aplicação para cada mídia particular (valores limites para atraso, variação de atraso e perda de pacotes), juntamente com a política adaptativa que o sistema pode disparar para execução.
É claro que um limite tolerável para que isso aconteça é dado à cada política particular pertencente ao sistema;
E, após esse limite ser ultrapassado, a política é disparada e sua execução iniciada.
Várias políticas podem ser escolhidas, cada qual com valores para os parâmetros de Qualidade de Serviço diferentes.
Valores aproximados para diferentes tipos de mídias são encontrados em Schulzrinne, e Campbell, os quais serviram como referência de utilização neste trabalho.
A Tabela 3 apresenta esses valores e mais algumas características de áudio e vídeo digitais.
O tipo de adaptação utilizado depende da rede, ou seja, depois do módulo de monitoração receber feedback da mesma, o módulo de adaptação aguarda por uma notificação (via monitoração), a qual inclui o estado corrente da rede e os valores referentes aos parâmetros de qualidade oferecidos por a rede.
Como conseqüência, os valores de QoS especificados por a aplicação são comparados com os valores de QoS da rede e, juntamente com seu estado, uma decisão acerca de a (s) política (s) escolhida (s) é tomada resultando num flag que pode disparar sua execução ou não, conforme resultado de análise.
No caso de flag afirmativo, a política escolhida pode ser aplicada.
Para isso, uma análise adicional é realizada levando em consideração o parâmetro de QoS mais relevante para a política (variação de atraso é o parâmetro avaliado quando o buffer do recebedor pode ser modificado).
Cabe esclarecer que a preocupação com requisitos de QoS à nível de aplicação (e.
G., taxa de frames, tamanho do frame, cor) não foi considerada limitando- se somente a QoS à nível de rede.
O diagrama de estados da Figura 22 descreve de forma mais detalhada o comportamento deste módulo no sistema.
Vários caminhos de adaptabilidade podem ser seguidos, como por exemplo, modificar a taxa de transmissão, modificar a codificação do áudio ou vídeo, modificar o tamanho do frame, modificar de colorido para preto e branco no caso de transmissão de vídeo, entre outros apud.
As políticas escolhidas para implementação, as quais podem ser aplicadas tanto para áudio quanto para vídeo, foram:
1) modificação do tamanho do buffer no recebedor visando compensar a variação de atraso entre os pacotes recebidos;
2) modificação da taxa de transmissão procurando reduzir o congestionamento da rede e melhorar a qualidade da mídia no recebedor.
Cabe salientar que, devido a sua importância, as políticas adaptativas são descritas detalhadamente numa seção separada.
Novas políticas de adaptação também poderão ser criadas por o próprio desenvolvedor da aplicação de acordo com sua necessidade.
Para tal, um modelo (classe) para construção de políticas é oferecido e um conjunto inicial de políticas é colocado a disposição, além de o suporte em tempo de execução (i.
e, monitoração da QoS oferecida por a rede e adaptação da aplicação ao seu comportamento).
Transparência ao desenvolvedor foi um critério obedecido durante o desenvolvimento de cada política de adaptação.
Esta transparência de utilização foi dada por a Camada de Adaptação de QoS.
Em resumo, o desenvolvedor da aplicação não tem consciência de como o mecanismo de controle adaptativo foi implementado abaixo de sua aplicação.
Cenário de Validação A aplicação de validação escolhida para utilizar o conjunto de interfaces, classes e métodos obtidos como resultado de implementação da Camada de Adaptação de QoS foi uma aplicação RTP, mais especificamente, uma sessão multimídia.
A sessão multimídia de testes constitui- se de um Cliente RTP, que recebe dados através da rede, e um Servidor RTP, que transmite dados através da rede.
Ambos utilizam o conceito de sessão RTP para isso.
Uma sessão RTP é uma associação entre um conjunto de participantes (aplicações) comunicando- se com RTP.
Um participante numa sessão pode transmitir streams passiva de dados somente (recebedor somente), ou ambos.
Para cada participante, a sessão é definida por um par particular de endereços de transporte destino (um endereço de rede mais um par de portas RTP e RTCP).
O par de endereços de transporte destino podem ser comuns para todos os participantes, como é o caso de IP multicast, ou podem ser diferentes para cada participante, no caso de endereços de rede unicast individuais, mais um par de portas comuns.
Em uma sessão multimídia, cada mídia é transportada num sessão RTP separada com seus pacotes RTCP próprios.
Por exemplo, se áudio e vídeo são usados num Servidor RTP, uma sessão é usada para transmitir os dados de áudio e outra para transmitir os dados referentes ao vídeo, tendo como vantagem o participante poder escolher a mídia que quer receber.
As múltiplas sessões RTP são distinguidas por os diferentes pares de números de portas e/ ou diferentes endereços multicast.
Servidor RTP Aplicações servidoras RTP transmitem streams de áudio e vídeo capturados ou armazenados através da rede (Figura 23).
Streams podem ser codificados em múltiplos formatos de mídia e enviados em várias sessões RTP com recebedores heterogêneos (uma sessão de conferência).
Entretanto, antes dos streams RTP serem enviados sobre a rede, o formato do dado, durante a fase de processamento, deve ser modificado para um dos formatos de codificação específicos RTP apropriados para transmissão10.
A fase de processamento, considerando um arquivo armazenado em disco, constitui- se de:
Demultiplexar o stream de entrada extraindo as trilhas individuais de áudio e vídeo, como é o caso da maioria dos arquivos QuickTime(.
Mov) que contém ambas, uma trilha de áudio e uma trilha de vídeo;
Codificar a trilha para um formato apropriado para transmissão;
Aplicar efeitos na trilha antes ou depois de sua conversão para novo formato (se desejado).
A aplicação implementada transmite ambos streams de áudio e vídeo ao mesmo tempo.
Funcionalidades de monitoração de tráfego, bem como adaptação da QoS foram acopladas a cada sessão RTP criada para ambos os fluxos de dados.
Para maiores detalhes sobre a utilização dos módulos de monitoração e adaptação de QoS veja seção 6.5.
Cliente RTP Aplicações clientes RTP recebem stream através da rede e para cada novo stream recebido uma sessão RTP é criada.
Os streams RTP recebidos são colocados num buffer para posterior consumo por o Player, o qual tem por função processar o stream de entrada e apresentar- lo em dispositivos de saída (monitores e alto-falantes).
Todos os campos disponíveis do cabeçalho RTP são traduzidos para campos apropriados no Buffer, marker, timestamp e sequence number.
O bit marker é configurado como um flag, marcando o final de um frame para vídeo, ou o início de uma fala para áudio.
Essa tradução permite ao A codificação normal recebe outro nome quando é utilizado dentro de RTP.
Player reconstituir o sinal da mesma forma que ele é gerado no fonte juntamente com o timestamp e o sequence number.
O processo de recepção de um fluxo de streams RTP pode ser visualizado na Figura 24.
A aplicação cliente implementada recebe streams de áudio e vídeo.
As funcionalidades referentes à monitoração de tráfego e adaptação de QoS foram acopladas, em cada sessão RTP criada, aos streams de áudio e vídeo respectivamente.
Para maiores detalhes de utilização dos módulos veja seção 6.5.
Metodologia de experimentação Como parte do cenário de validação e para realizar os experimentos necessários foram construídos dois monitores de tráfego contendo estatísticas globais de transmissão e recepção dos dados.
Os dois monitores foram implementados como threads, as quais em execução têm por função coletar informações da rede em períodos de um segundo, permanecendo ativas durante todo o tempo de vida da sessão RTP em a qual forem utilizadas.
O monitor responsável por as estatísticas de transmissão dos dados apresenta informações referentes ao número total de pacotes RTP, bytes de dados e pacotes de controle RTCP enviados, número de Kbps e Mbps injetados na rede, pacotes e bytes transmitidos a cada segundo, juntamente com o número de bytes presente em cada pacote RTP.
Já o monitor que trata da recepção dos dados disponibiliza informações referentes ao número total de pacotes de dados e controle, bytes, pacotes RTCP, pacotes Sr, taxa de recepção dos dados em unidades de Kbps e Mbps, pacotes e bytes recebidos, bem como o número de bytes de cada pacote recebido.
Os dois monitores foram utilizados para verificar se realmente acontecem modificações no tráfego da rede quando de a execução das políticas de adaptação, especificamente da política responsável por causar modificações no tráfego dos dados.
Também, para causar modificações de tráfego construiu- se um processo responsável por provocar perda de pacotes, já que optou- se por realizar testes numa rede local.
O processo foi implementado como uma thread de recepção e envio de pacotes UDP localizando- se assim entre o servidor RTP e o cliente RTP.
O processo foi implementado com o intuito de demonstrar que as políticas adaptativas oferecidas por a API proposta funcionam.
Os experimentos foram realizados nos Laboratórios de Mestrado e Processamento Paralelo e Distribuído (LPPD) da PUCRS em redes Ethernet locais de 10 MBps.
Funcionalidade oferecida ao desenvolvedor da Aplicação Multimídia O processo de monitoração (thread continuamente ativa) pode ser inicializado quando uma sessão RTP é criada para um fluxo de pacotes RTP tanto na aplicação enviadora ou receptora dos dados (Figura 25 e Figura 26).
RTP é criada Os parâmetros de QoS são configurados por o próprio desenvolvedor da aplicação multimídia levando em consideração os diferentes números de portas em que as mídias são recebidas ou enviadas.
DataSource ds;
Mgr. AddSendStreamListener (this);
Conforme os códigos da Figura 25 e Figura 26 ilustram, cada objeto monitoração (instância da classe monitoração) é criado para um fluxo de dados particular da aplicação, o que eqüivale a dizer que, se a aplicação cliente está recebendo áudio e vídeo ao mesmo tempo, dois objetos monitoração são criados em tempo de execução para monitorar a qualidade do tráfego de cada fluxo.
Além disso, cada objeto vai possuir um vetor de políticas adaptativas que pode ser manipulado por dois métodos que permitem ao desenvolvedor da aplicação inserir ou retirar políticas de ele.
Periodicamente, ou seja, quando um report RTCP é detectado, as políticas contidas no vetor são testadas por este processo, via processo de adaptação, resultando em sua execução ou não, conforme análise descrita na seção 6.3.2 deste mesmo capítulo.
Políticas de Adaptação de QoS Políticas de adaptação são uma forma de modificar o comportamento da aplicação para que esta funcione da melhor maneira possível com os parâmetros de desempenho que a rede pode oferecer.
Tentando- se, desta forma, assegurar à aplicação que esta terá pelo menos um nível mínimo de QoS.
Isso em conformidade com os valores dos parâmetros de qualidade especificados por o desenvolvedor da aplicação.
Esses valores servem como um limitador para que algumas medidas corretivas sejam realizadas.
A seguir, as duas políticas escolhidas para implementação são apresentadas.
Modificar a taxa de transmissão dos dados Perdas excessivas de pacotes, resultado de congestionamento da rede, podem causar significante degradação da qualidade percebida do vídeo decodificado no recebedor, bem como da qualidade de um áudio podendo tornar- lo incompreensível.
Em casos em os quais perdas e atrasos são causados por congestionamento da rede, uma diminuição na taxa dos dados transmitidos pode solucionar o problema de congestionamento da rede.
Além disso, pode ajudar a melhorar a qualidade do sinal decodificado no recebedor, pois menos dados são perdidos durante a transmissão.
Logo, modificar a taxa de transmissão resume- se nos objetivos:
Prevenir que a fonte dos dados inunde os recursos da Internet, o qual pode levar a um serviço não aceitável para todos os usuários da rede;
Evitar que a qualidade da mídia decodificada no recebedor tenha uma significativa degradação na qualidade percebida por o usuário final.
A transmissão não controlada de streams de áudio e vídeo podem facilmente inundar os recursos da Internet e levar a um serviço não aceitável a todos os usuários da rede.
A inclusão de mecanismos de controle em aplicações em tempo real ajudam a evitar que tais situações aconteçam.
Para isso, uma das possibilidades seria modificação da taxa em a qual os pacotes são enviados sobre a rede, ou seja, o número de bytes transmitidos por a rede a cada segundo.
Limitar essa taxa de acordo com a capacidade disponível da rede é o objetivo, pois a capacidade disponível da rede varia com o tempo.
Um caminho que pode ser utilizado para isso é permitir que a fonte dos dados receba feedback sobre a qualidade da recepção dos dados, estime o estado corrente da rede e controle a taxa em a qual os pacotes são enviados através da rede.
Em resumo, causar modificações na carga da rede com base nas condições em que ela se encontrar.
A vantagem desta abordagem é que ela não requer suporte especial da rede, como, por exemplo, controle de admissão e alocação de recursos, podendo ser implementada na Internet atual.
Mecanismos de controle de feedback já são usados na Internet para controlar fontes de tráfego não tempo real.
O melhor exemplo é o protocolo TCP, onde a informação de feedback pacotes perdidos é detectada por timeouts ou múltiplas confirmações de pacotes ao fonte.
O esquema de controle de fluxo utilizado é o esquema da janela dinâmica de Van Jacobson.
Um importante objetivo do TCP e outros mecanismos para tráfego de dados é maximizar a vazão (throughput) e minimizar o atraso de pacote ou perdas, ou equivalentemente, otimizar alguma função de vazão ou atraso.
O protocolo UDP, por outro lado, não realiza nenhum tipo de controle de congestionamento, ou seja, não diminui a taxa de transmissão dos dados frente a um congestionamento na rede, a não ser que as aplicações cuidem disso.
Considerando também o protocolo RTP, que também é responsável por o transporte de dados, verifica- se que esse também não inclui qualquer mecanismo de controle de fluxo dependendo da aplicação para isso.
A abordagem utilizada para modificar a taxa de transmissão durante uma sessão RTP foi alterar o formato do stream durante sua transferência sobre a rede utilizando- se da mesma sessão RTP para tal.
Essa abordagem foi adotada com o intuito de ajudar a minimizar a largura de banda utilizada por a aplicação.
Assim sendo, uma vez que os parâmetros de QoS da rede esperados não são atendidos, a política de adaptação troca o formato do stream que está sendo transmitido por outro de maneira a economizar recursos da rede.
O processo resume- se em, depois de inicializado o envio de um stream particular sobre a rede, através de uma sessão RTP, esse pode ser trocado por outro que consuma menos largura de banda.
Ainda, antes do novo stream ser enviado, durante a fase de processamento, seu formato é modificado para um dos formatos RTP apropriados para transmissão, escolhido de acordo com a vazão requerida do novo formato.
Assim, se o número de bits por segundo do formato escolhido for menor do que o stream atual, o formato é escolhido para realizar a permutação.
Se necessário, esse processo pode acontecer várias vezes durante a transmissão dos dados para o destino, dependendo, é claro, das condições em que a rede se encontrar e do número de formatos disponíveis de vazão inferior ao stream que está sendo enviado.
Dependendo do formato, considerando os que podem ser tratados por o codificador11, a vazão requerida para áudio pode variar de 5,3 ou 6,3 Kbps (áudio g 723/ rtp) à 88 Kbps (dvi/ rtp) ou mais, enquanto que para vídeo a vazão requerida tende a ser maior, normalmente 1 Mbps (jpeg/ rtp) ou mais.
Os valores referentes a vazão requerida para cada um dos formatos a serem modificados são calculados quando de a escolha de um formato mais econômico em termos de &quot;largura de banda «a ser utilizado na execução da política de adaptação.
Ainda, durante essa fase de escolha, a vazão utilizada por o formato atual é obtida e comparada com a vazão necessária para o novo formato e, caso esse último necessite de menos largura de banda é escolhido para ser enviado.
Este processo de escolha é realizado cada vez que o disparo da política de adaptação é realizado.
A política pode ser aplicada várias vezes desde que a vazão do novo stream seja menor do que o atual.
Contudo, para que o processo de execução da política acontecesse da melhor forma possível, vários critérios foram estabelecidos visando não comprometer a qualidade do sinal decodificado no recebedor, entre eles:
Cada codificador possui certos formatos de entrada que ele pode tratar e certos formatos de saída que ele pode gerar.
Em algumas situações, uma série de codificadores pode ser utilizada para converter de um formato para outro.
Os pontos em destaque nos gráficos representam chegada de reports do recebedor, e o intervalo adotado para aplicar a política novamente foi de 19 segundos.
Como conseqüência considerou- se a taxa de perdas do report recebido anteriormente, a qual reflete de forma mais concreta a performance da rede.
Em a implementação da política aqui descrita, o formato do stream é modificado gradativamente de acordo com os formatos com vazão inferior ao stream atual de envio que o codificador pode tratar.
Os experimentos foram realizados somente com arquivos de áudio, pois observou- se que os codificadores de vídeo instalados somente conseguiam manipular um formato de vídeo para transmissão.
O gráfico da Figura 29 ilustra a transmissão de um arquivo de áudio (Jazz3.
Wav) com uma simulação de perda de pacotes em 10%.
Pôde- se claramente perceber que devido a o fator perdas ser elevado a política de adaptação foi aplicada e resultou numa modificação significativa de largura de banda utilizada por a aplicação.
O formato inicial do áudio escolhido para transmissão foi dvi/ rtp, o qual consumiu cerca de 88 Kbps de largura de banda da rede, sendo modificado posteriormente para ULAW/ rtp.
Isso depois do primeiro report do recebedor ter informado perda de pacotes em 10% (tempo 6s de transmissão).
Posteriormente, o áudio foi modificado para dvi/ rtp (32 Kbps) e gsm/ rtp (16 Kbps), tempos 27s e 48s respectivamente.
A transmissão do mesmo arquivo com simulação de perdas variável é ilustrada na Figura 30.
O formato do stream foi modificado duas vezes durante a transmissão;
Em a primeira o stream foi modificado para ULAW/ rtp (64 Kbps) e na segunda para dvi/ rtp (32 Kbps), tempo 10s e 45s respectivamente.
Para melhor demonstrar o funcionamento da política de adaptação em questão, a seguir são ilustradas a transmissão de dois arquivos de áudio com taxa fixa e variável de perdas.
O gráfico representado por a Figura 31 ilustra a transmissão de um arquivo de áudio (Trailer.
Mov) com taxa de perdas em 10%.
A política de adaptação foi aplicada duas vezes (tempo 6s e tempo 32s).
Em a primeira, o formato do stream foi modificado para dvi/ rtp com 32 Kbps de vazão e posteriormente para gsm/ rtp com vazão de 16 Kbps.
O áudio inicial de transmissão possuía formato dvi/ rtp (44 Kbps).
Em a Figura 32, o mesmo arquivo foi transmitido, porém com simulação de perda de pacotes variável, resultando na aplicação da política de adaptação duas vezes.
Os formatos modificados foram os mesmos da transmissão do arquivo (Trailer.
Mov) com percentual de perdas em 10%.
Em a Figura 33, o áudio transmitido inicialmente (Groovy.
Wav) foi dvi/ rtp (88 Kbps), sendo modificado posteriormente para três formatos diferentes.
O primeiro formato modificado foi ULAW/ rtp (64 Kbps) no tempo 4s.
O segundo foi dvi/ rtp (32 Kbps) no tempo 24s, e o último foi gsm/ rtp, tempo 48s.
Em a Figura 34, o mesmo áudio foi transmitido resultando na aplicação da política de adaptação somente duas vezes.
De essa forma, o formato do stream foi modificado para ULAW/ rtp (64 Kbps) na primeira vez e dvi/ rtp (32 Kbps) na segunda, tempo 10s e 45s respectivamente.
Observou- se que, em cenários com perdas de pacotes excessivas, a qualidade da mídia melhorou no recebedor quando a política de adaptação em questão foi aplicada.
O áudio mostrou- se compreensível.
Modificar o tamanho do buffer no recebedor A premissa básica de pacotes de áudio/ vídeo é simples.
Primeiro um sinal analógico é digitalizado numa corrente de bits (convertido do domínio analógico para digital), codificado, fragmentado em pacotes e transmitidos através da rede para um ou mais recebedores.
Em cada recebedor, os pacotes são remontados para recuperar o dado original, entregues para o decodificador de áudio ou vídeo e então apresentados em dispositivos de saída, monitores e alto-falantes.
Normalmente, o processo de manipulação de dados multimídia entre fonte e destino é o mesmo, isto é, codificar para transportar e decodificar para apresentar.
Se a rede fosse eficiente o bastante para entregar cada pacote com um atraso uniforme o sinal recebido seria reconstituído exatamente como ele é no recebedor.
Normalmente, quando o vídeo é gerado no fonte ele é gerado num período padrão, mas com uma taxa de bits variável (isto é, o número de bits/ frame varia de frame para frame).
O mesmo normalmente não acontece com áudio, sendo que as amostras, chamadas samples, são geradas num período padrão, mas com uma taxa de bits constante para cada amostra.
Contudo, porque a rede pode induzir variações arbitrárias na entrega de cada pacote o recebedor pode sentir uma pequena falha ou atraso no sinal reconstituído.
Como conseqüência, por causa de essa variação, pacotes de áudio e vídeo que chegam não podem ser imediatamente apresentados e a periodicidade dos frames precisa ser preservada para apresentação no recebedor.
Para que essa periodicidade seja mantida, a variação de atraso de pacotes precisa ser baixa.
Assim, bufferização no recebedor pode ajudar a remover a variação de atraso de pacotes sentida por o recebedor dos dados.
Desta forma, a política adaptativa em questão está relacionada ao parâmetro de QoS variação do atraso de pacotes e descreve como a modificação do tamanho do buffer no recebedor pode uniformizar o atraso de chegada de pacotes antes da mídia ser apresentada ao usuário final.
Modificação do tamanho do buffer está sendo utilizada como uma medida corretiva para conter essa variação no recebedor dos dados.
Em a API JMF 2.
0, um buffer é introduzido no recebedor (para cada fluxo de dados particular).
Entretanto, o tamanho deste buffer não é modificado em momento algum em que a aplicação está ativa, nem mesmo quando a variação de atraso entre cada pacote entregue ao recebedor é completamente disforme.
Em resumo, o buffer é o mesmo em qualquer situação em que a rede se encontrar.
Quanto a o tamanho do buffer, se os dados excederem seu limite máximo tolerado, o dado no início da fila (dado menos recente) é descartado.
O número de pacotes de áudio ou frames de vídeo bufferizados depende do stream de entrada, ou seja, áudio e vídeo possuem valores default e máximo para o tamanho do buffer.
Em JMF, o tamanho do buffer para áudio e vídeo é definido de acordo com a Tabela 4.
O tamanho deste buffer é especificados em milisegundos.
Para áudio, estes valores (Tabela 4) são traduzidos para um número específico de samples de áudio ou frames baseado no formato do stream de áudio.
Para vídeo, a taxa de frame do stream de entrada não é conhecida por o recebedor.
Em este caso, o recebedor assume uma taxa de 15 fps quando calcula o número de frames de vídeo completos que correspondem ao tamanho máximo do buffer.
Por exemplo, um buffer que contenha 3 frames de vídeo deve ser configurado para 200ms, ou seja, 3 frames de um stream de 15 fps (i.
e, a duração de cada frame por segundo é de 66,66ms).
Pode- se observar que existe uma relação entre o tamanho do buffer e o tempo em que cada dado (pacote) deve ser bufferizado, ou seja, um grande tempo de bufferização implica na necessidade de um tamanho de buffer maior.
Uma pergunta que pode surgir é quanto a o tamanho do buffer.
Como saber que tamanho ele deve possuir?
Se o buffer for pequeno demais, ele esvaziará rapidamente causando interrupção na apresentação dos dados.
Se o buffer for grande, o atraso fim-a-fim pode aumentar.
O tamanho ótimo depende da quantidade de variação de atraso introduzida por a rede, ou seja, uma variação maior resulta num tamanho de buffer maior, enquanto uma variação menor resulta em buffer de tamanho menor.
Como resultado deste processo a qualidade final da aplicação pode ser aumentada.
Em a implementação da política aqui descrita, o tamanho máximo do Buffer é modificado de acordo com as restrições de limite apresentadas na Tabela 4.
Para áudio, o tamanho do buffer pode ser modificado para 500ms, 750ms e 1000ms (máximo).
Para vídeo, o tamanho do buffer pode ser modificado para um tamanho que comporte o armazenamento de 3 fps e 4 fps, ou seja, de duração 200ms e 270ms respectivamente.
A política pode ser disparada para execução depois que todos os parâmetros de qualidade configurados forem desrespeitados, pois os mesmos informam como está a qualidade de recepção dos dados.
Mais precisamente, a política só é executada quando a variação de atraso tiver ultrapassado o valor variação de atraso estabelecido por o desenvolvedor da aplicação.
A Tabela 5 ilustra o resultado da aplicação da política de adaptação que modifica o tamanho do buffer do receptor em conformidade com a qualidade recebida da rede.
O áudio (Jazz3.
Wav) foi recebido por um período de 70 segundos com simulação de perdas em 10%.
As modificações realizadas no transmissor durante o envio do stream sobre a rede podem ser visualizadas na Figura 29.
A Tabela 6 ilustra a modificação do buffer no cliente RTP para uma mídia de vídeo (alaska2.
Avi) com duração de 50 segundos.
Observou- se que quando a política de adaptação em questão foi aplicada em conjunto com a política que modifica a taxa de transmissão (Tabela 5), uma diminuição da interrupção do áudio recebido foi minimizada.
Esta política de adaptação, em particular, foi implementada com o intuito de demonstrar que a Camada de Adaptação de QoS pode também ser utilizada no recebedor dos dados.
Frente a realidade atual do modelo de serviços oferecidos por a Internet, muitas aplicações multimídia que transmitem ou recebem áudio e vídeo necessitam tornarem- se adaptativas às condições que a rede oferece.
Consequentemente, essas aplicações requerem que suporte adicional seja disponibilizado para que obtenham garantias de Qualidade de Serviço (QoS).
Contudo, oferecer garantias de QoS em cenário adaptativo, como a Internet, requer habilidade do desenvolvedor da aplicação para fazer isso e nem sempre ele está preparado para realizar tal tarefa, pois essa implica no tratamento de detalhes de comunicação como atraso, perda de pacotes, variação de atraso e largura de banda utilizada por a aplicação.
De este modo, este trabalho apresentou uma Camada de Adaptação de QoS que possui mecanismos de monitoração e adaptação de QoS.
A monitoração dá- se através da análise dos pacotes RTCP Sender Reports e Receiver Reports, pois ambos permitem monitorar a qualidade da distribuição dos dados.
Adaptação, como segundo mecanismo, fornece meios da aplicação ajustar- se as variações dinâmicas que acontecem na rede de comunicação através de um conjunto de políticas adaptativas, as quais podem ser escolhidas por o desenvolvedor da aplicação.
Contudo, para o efetivo desenvolvimento desses mecanismos alguns aspectos principais foram levados em consideração, como:
A necessidade de obtenção e tratamento contínuo dos dados obtidos da rede;
A necessidade de modificações no comportamento da aplicação segundo análise dos dados coletados;
A necessidade dos dois processos acima acontecerem de maneira concorrente com o envio e a recepção dos dados.
Isso não é uma tarefa fácil de ser realizada, principalmente considerando- se algumas questões, como por exemplo, como obter os dados referentes ao tráfego da rede?
Depois, como tratar esses dados e o que fazer com eles?
Finalmente, como modificar o comportamento da aplicação frente a os dados coletados e analisados?
Questões como essas foram criteriosamente analisadas e observadas para que o trabalho produzisse os resultados esperados.
Uma Interface para Programas de Aplicação (API) foi desenvolvida para oferecer os serviços de monitoração e adaptação de QoS e visa ajudar a tarefa do desenvolvedor de uma aplicação multimídia, escrita na linguagem de programação Java, a incorporar QoS à aplicação.
Ela foi projetada para ser fácil de programar, tornar possível que desenvolvedores implementem aplicações multimídia com suporte à QoS baseadas na API existente e também integrem novas características a estrutura oferecida.
A API oferece uma solução básica para uma classe de problemas em que desenvolvedores podem explorar sua estrutura através da extensão.
Além disso, as funcionalidades oferecidas também podem ser facilmente customizadas.
Um dos maiores desafios encontrados no trabalho foi quanto a escolha das políticas de adaptação, haja vista o grande número que encontra- se na literatura e o grau de dificuldade em implementar- las, principalmente da política relacionada com modificações no tráfego dos dados.
Contudo, esta última foi implementada, testada e os resultados obtidos foram satisfatórios e demonstraram que controlando a vazão requerida por a aplicação o congestionamento da rede pode ser diminuído aumentando a qualidade da mídia entregue ao recebedor.
Em a implementação atual, a política preocupa- se somente em alterar o formato do stream para outro que utilize menos largura de banda.
Isso em conformidade com as condições em que a rede estiver operando.
Como extensão, esta política poderia alterar o formato do stream de envio, se desejado, por outro que viesse a consumir maior largura de banda em situações em as quais a rede não estivesse congestionada.
Finalmente, como continuidade deste trabalho sugere- se estender a Camada de Adaptação de QoS com um módulo adicional de negociação de QoS.
Esse módulo responsabilizaria- se- em tentar oferecer à aplicação uma certa garantia de QoS por meio de a utilização do protocolo RSVP.
Assim, em casos em os quais a largura de banda solicitada não puder ser oferecida, uma renegociação entre a aplicação e a Camada poderia ser realizada de modo a prover uma largura de banda inferior.
Um forte argumento para isso, é o fato que, embora a utilização de um protocolo para reservar recursos, a aplicação ainda pode ficar sem os mesmos, justamente porque concorre com outras aplicações na utilização dos recursos da rede.
Além disso, o fato de utilizar o protocolo RSVP seria uma tentativa de fazer com que os parâmetros de QoS configurados por a aplicação não fossem utilizados somente como um limitador, cujo objetivo é que a aplicação não sofra os efeitos da qualidade do tráfego dos dados provida por a rede, e sim, tentaria assegurar que os parâmetros de QoS fossem respeitados, particularmente o parâmetro largura de banda.
