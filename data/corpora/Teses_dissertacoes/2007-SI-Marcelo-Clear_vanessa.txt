Quando um requisito de mudança é solicitado durante um projeto de manutenção, toda a informação referente a ele deve ser rastreada a fim de que seja possível desenvolver- lo.
Em essa realidade está inserida a análise de impacto de uma mudança que visa, entre outras coisas, estabelecer a probabilidade de impacto que um artefato terá.
O principal objetivo desse trabalho é o desenvolvimento de uma metodologia de análise de impacto de mudança em projetos de manutenção de software.
Para que seja possível realizar- la, é preciso rastrear os artefatos que compõem o sistema.
O rastreamento é realizado por os conceitos da ontologia gerada durante o processo de desenvolvimento de software a partir de o modelo de domínio.
Palavras-chave: Projetos de manutenção de software, análise de impacto, rastreabilidade, ontologia, processo de desenvolvimento de software.
A fase inicial do ciclo de vida de um produto de software é o processo de desenvolvimento, aonde irá se construir o sistema desejado por o cliente.
Quando esta é finalizada, inicia- se a manutenção do produto que, segundo a organização do Workshop de Manutenção de Software Moderna (WMSWM), é a fase do ciclo de vida do software que consome mais recursos, sendo responsável por aproximadamente 90% do custo total deste.
Isso se dá por vários motivos, de entre eles mudanças tecnológicas, alteração de necessidades do usuário e falhas encontradas após sua instalação.
Para tentar manter a qualidade do produto e conseguir estimar o esforço e tempo necessários para realizar uma mudança no software, é preciso que se tenha uma maneira otimizada para descobrir todas as partes do sistema que serão afetadas por a alteração.
Essas podem ser obtidas por um modelo de análise de impacto, que irá determinar de que forma os artefatos são impactos e qual a probabilidade disso ocorrer.
Existem diversas pesquisas nessa área, com propostas que visam encontrar o conjunto de artefatos impactados mais próximo de a realidade, ou seja, encontrar com precisão os elementos que serão efetivamente modificados.
Para que seja possível obter esse conjunto, é necessário possuir um mecanismo de rastreabilidade que suporte a análise de impacto.
Um autor que se destaca em pesquisas nesse sentido é Bohner com diversos artigos e livro publicados.
Ele propôs uma metodologia de análise de impacto, rastreando os artefatos através das ligações entre eles, representadas num grafo de conectividade.
Outro trabalho interessante foi realizado por O'Neal, onde a probabilidade de impacto nos artefatos é determinada e a rastreabilidade é feita através dos requisitos do sistema.
Outro método utilizado para realizar o rastreamento de artefatos faz uso de mecanismos semânticos para tal, visando uma maior assertividade para encontrar o conjunto de elementos que serão alterados.
Através de pesquisa realizada por Noll, notou- se que ontologias poderiam ser integradas ao processo de desenvolvimento de software e, através de seus conceitos, realizar a rastreabilidade semântica dos artefatos.
Uma das contribuições de utilizar ontologia nesse contexto é que esta permite integrar os elementos produzidos, desde a modelagem de negócio, até a análise e projeto.
Considerando- se que o uso desse tipo de rastreabilidade traria ganho para encontrar mais precisamente os artefatos modificados a partir de um requisito de mudança, foi desenvolvida uma metodologia para análise de impacto baseada em ontologias.
Essa é responsável por identificar as alterações que ocorrem na ontologia do sistema e assim mensurar a probabilidade de impacto em cada um dos artefatos.
Para a construção dessa proposta, buscou- se compreender o que são, o que representam e como as ontologias se integram ao processo de desenvolvimento de software.
Pesquisou- se saber também, como é definida a fase de manutenção de um produto, onde diversos requisitos de mudança são solicitados.
Sendo a diferença entre rastreabilidade e análise de impacto bastante tênue, procurou- se estabelecer fortemente as diferenças entre elas.
Ainda como parte do referencial teórico, abordado no capítulo 2, estudou- se a disciplina de Engenharia de Software Experimental com a finalidade de utilizar- la como base para o experimento de validação dessa proposta.
Com a intenção de conhecer quais os mecanismos utilizados para realizar a rastreabilidade de artefatos através da ontologia, foram estudadas a Engenharia Ontológica e a rastreabilidade semântica.
Com o auxilio desse estudo, presente no capítulo 3, foi possível determinar as influências que uma mudança na ontologia do sistema exerce sobre os artefatos relacionados aos conceitos desta.
Surgiu então, a metodologia que será apresentada no capítulo 4 dessa proposta, estabelecendo os passos necessários para realizar- la, cuja principal contribuição é a de possibilitar maior precisão para realizar a análise de impacto de um requisito de mudança.
Para automatizar essa tarefa, foi desenvolvida uma ferramenta onde, uma vez determinada a influência existente entre conceitos, artefatos e tipos de mudança, é possível identificar os elementos com maior probabilidade de serem impactados.
O experimento realizado para validação da metodologia é apresentado no capitulo 5, considerando todos os passos necessários para seu desenvolvimento.
Por fim, são feitas algumas considerações e sugeridos alguns trabalhos futuros.
Esse capítulo descreve o referencial teórico deste trabalho expondo os conhecimentos necessários para entendimento do problema e para a solução.
Primeiramente é preciso saber o que as ontologias representam e qual sua integração com o processo de desenvolvimento de software, sendo aqui utilizado o Rational Unified Process (RUP).
Também é necessário conhecer a fase do ciclo de vida do software caracterizada por projetos de manutenção deste, com relação a a rastreabilidade e ao impacto causado por uma requisição de mudança no sistema.
A Engenharia de Software Experimental é descrita, já que essa tem como objetivo validar propostas da área de engenharia de software através de experimentos.
Um processo de construção de ontologia, no que diz respeito à Ciência da Computação, representa, segundo Gruber, a aquisição do conhecimento a partir de dados semi-estruturados utilizando um conjunto de métodos, técnicas ou processos automáticos ou semi-automáticos.
Esse termo teve origem na computação através da área de Inteligência Artificial, que considera a representação através da ontologia similar a como o conhecimento humano é representado.
Segundo Fensel, ontologias são desenvolvidas para facilitar o compartilhamento e reuso de informações.
Essa facilidade para compartilhamento de informações foi a principal razão para sua utilização.
Afirma- se ainda que a ontologia é mais que um vocabulário padrão e mais do que uma taxonomia, uma vez que assegura que os termos escolhidos são suficientes para especificar e definir conceitos, bem como o relacionamento entre eles, e que inclui a expressão exata do domínio específico do conhecimento.
Gruber definiu ontologia como sendo uma representação formal do conhecimento que é baseada numa conceituação.
Ele afirma que se pode descrever uma ontologia por a definição de um conjunto representacional de termos.
Essa definição compõe- se de associações entre nomes de entidades do universo de discurso, formado por o conjunto de objetos que podem ser representados.
Esse conjunto pode ser composto por classes, relacionamentos ou funções, descritos através de um texto com seus significados, e com axiomas formais, responsáveis por a restrição da interpretação e por a boa formação no uso das associações.
A estrutura de dados de uma ontologia é equivalente a um grafo.
Cada nodo é um conceito que segundo Geller corresponde a palavras ou frases curtas, sendo tipicamente correspondente a substantivos.
Esses conceitos são conectados uns aos outros, sendo o relacionamento mais importante o do tipo É-UM.
Alguns nodos possuem outras informações relacionadas, podendo ser atributos, relacionamentos ou regras.
A figura 1 abaixo exemplifica uma ontologia em termos de conceitos, relacionamento e regras.
Existem duas abordagens para construção de ontologias, no ponto de vista da área de Engenharia de Software:
Uma é a construção de ontologias baseadas nos requisitos do sistema e outra é a construção de uma ontologia para a representação de requisitos.
A primeira é vista como subproduto da atividade de Engenharia de Requisitos.
Felicíssimo defende esta questão por considerar que é durante a especificação dos requisitos do sistema que se delimita o escopo do projeto bem como se define o domínio da aplicação.
Em esta fase, pode- se construir uma ontologia única, formada por a união dos conceitos do problema e da solução, que poderá ser refinada em seguida.
O papel da ontologia, quando utilizada para a representação de requisitos, é de prover a comunicação entre os requisitos através de uma sintaxe e semânticas bem definidas.
Como resultado, tem- se um mecanismo baseado no conhecimento para criação e manutenção de documentos de especificação de requisitos do sistema.
Para obter- se esse mecanismo, utiliza- se lógica de primeira ordem para definir os componentes da ontologia e identificam- se os axiomas envolvidos com os objetos e a sua interação para responder questões de senso comum.
Tendo em vista que a comunicação entre os requisitos é determinada durante o processo de desenvolvimento de software, na próxima seção a integração de ontologias a este é caracterizada.
Um processo de desenvolvimento de software pode ser definido, segundo Sommerville, como um conjunto de atividades e resultados associados que geram um produto de software.
Utilizando o paradigma de orientação a objetos e os conceitos da Unified Modeling Language (UML), foi proposta por Jacobson, Booch e Rumbaugh uma metodologia de desenvolvimento de software unificada, o RUP.
De entre os objetivos do RUP estão o aumento da produtividade e maior qualidade do produto de software produzido.
Para que tais metas sejam alcançadas, ele deve ser configurado para cada empresa ou projeto que desejem utilizar- lo.
Isso é possível uma vez que o RUP pode ser considerado um framework para processos de desenvolvimento de software.
O RUP é dividido em quatro fases distintas, com objetivos específicos:
Concepção (definição do escopo), elaboração (definição da arquitetura), construção (desenvolvimento) e transição (implantação do produto).
Tido como um processo incremental e iterativo, cada uma dessas fases pode suportar uma ou mais iterações.
Cada uma dessas iterações possui fluxos específicos de trabalhos definidos por a metodologia, sendo eles:
Modelagem de negócios, requisitos, análise e projeto, implementação, testes e implantação, que compõem o fluxo de trabalho de engenharia, além de a gerência de projetos, gerência de configuração e mudanças e configuração de ambiente, que fazem parte do fluxo de trabalho de suporte.
A integração de ontologias no processo de desenvolvimento de software foi estudada e proposta por Noll.
Em seu trabalho, ontologias são relacionadas ao modelo de domínio, que está inserido na disciplina de modelagem de negócio do RUP.
Esse modelo descreve os conceitos e relacionamentos relativos a uma área de interesse.
É nesse aspecto que ontologias e modelos de domínio assemelham- se.
É então proposta a geração da ontologia do problema através do modelo de domínio.
Com a ontologia integrada ao processo de desenvolvimento, tem- se uma maneira de conectar semanticamente diversos recursos, utilizando técnicas de inteligência artificial, segundo Kogut.
A o final do processo de desenvolvimento de software obtém- se um produto.
Após este ter sido implantado, é dado início a uma nova fase do ciclo de vida, que é a de manutenção.
Tudo aquilo que foi aprendido e produzido durante o processo de desenvolvimento, é extremamente necessário para que se possa manter- lo.
A seguir, serão abordadas as características de um de projeto de manutenção e conceitos como rastreabilidade e análise de impacto que estão relacionados à maneira como os artefatos gerados durante o projeto podem ser acessados satisfatoriamente.
A manutenção de software pode ser definida como:
&quot;A alteração de um produto de software depois de entregue para corrigir falhas, para melhorar a performance ou outros atributos, ou adaptar o produto para um ambiente diferente», segundo IEEE.
Os projetos de manutenção são classificados em quatro categorias por Pressman:
Preventiva, que busca melhorar a confiabilidade ou manutenções futuras;
Adaptativa, que acompanha as evoluções tecnológicas;
Corretiva, que visa corrigir erros não encontrados na fase de teste, podendo esses ocorrerem na especificação, projeto ou implementação;
E evolutivas que visam continuar satisfazendo as necessidades do usuário.
O padrão homologado por a IEEE para manutenção de software determina as fases que devem ser seguidas para realizar uma alteração no sistema.
Após receber o requisito de mudança, esse deve ser analisado, ter seu projeto desenvolvido, realizar a implementação, fazer o teste de regressão do sistema e o teste de aceitação e por fim, a entrega ao cliente.
A existência de um processo para manutenção de software não significa que essa será menos problemática.
Diversos autores, tais como Bohner, Ajila e Fay, caracterizam a manutenção de software com geralmente sendo cara, difícil e demorada.
Uma das razões para esse tipo de afirmação é a dificuldade de entendimento do negócio e de sua posterior implementação por parte de uma pessoa que não participou do projeto de desenvolvimento.
Mesmo profissionais que participaram do projeto tem dificuldade de recordar alguns detalhes deste ou de sua codificação.
Essa situação é agravada por a falta de documentação ou por a sua não atualização ao longo de o processo de desenvolvimento ou mesmo quando o software já está em manutenção.
Uma outra razão está ligada à quantidade de artefatos do sistema que serão afetados por uma mudança.
Relacionado a esse último motivo, estão as definições de rastreabilidade e de análise de impacto de uma mudança dadas por Bohner.
O primeiro pode ser definido como &quot;a possibilidade de rastreamento entre os artefatos de software e seus componentes que são gerados e modificados durante o ciclo de vida do produto».
Já a análise de impacto pode ser definida como &quot;a identificação das conseqüências de uma alteração ou estimativa do que é necessário para realizar uma mudança».
Esses aspectos serão apresentados a seguir, considerando as mudanças relativas a manutenções corretivas e evolutivas, já que essas geram requisitos de mudança funcionais, que são aqueles que representam as funcionalidades do sistema.
Outras definições de rastreabilidade de requisitos foram dadas por Pearson:
&quot;rastreamento de requisitos é a habilidade de rastrear os requisitos do usuário através do processo de desenvolvimento, desde o levantamento de requisitos até a entrega do produto de software».
Já Gotel e Finkelstein defendem que «o rastreamento de requisitos é a habilidade de descrever e seguir a vida de um requisito, tanto para frente quanto para trás, ou seja, desde a sua origem, passando por a especificação e desenvolvimento, até sua entrega e uso;
Através de períodos de refinamento e iterações em qualquer uma dessas fases».
Através dessas definições, pode- se concordar com Palo, que diz que uma das importâncias de se ter um método para que um requisito seja rastreado é que quando este necessitar de alteração, encontre- se todos os artefatos ligados à ele e que serão afetados por a mudança.
Outra característica importante no rastreamento, é que este pode dar toda a informação sobre as justificativas, decisões importantes e suposições sobre o requisito.
Foi estudado por Castor fatores que justificam a utilização do rastreamento de requisitos.
De entre os mais importantes estão:
A) Qualidade de software:
Uma das definições é dada por Brooks, que diz que a qualidade é a conformidade dos requisitos.
De essa forma, normas tais como Capability Maturity Model for Software (CMM) exigem disciplinas de rastreamento de requisitos.
Em o CMM, esta consta no nível dois de maturidade;
B) Análise de impacto:
No decorrer de o processo de desenvolvimento de software, muitas vezes ocorrem solicitações de mudanças de requisitos.
Com o uso do rastreamento de requisitos é possível verificar quais artefatos serão impactados por a mudança, podendo ser analisado se essa é viável ou não, uma vez que o esforço e tempo para ser realizada podem ser estimados;
C) Manutenção de software:
Tendo em vista os projetos de manutenção de um software, o rastreamento dos artefatos torna- se essencial, uma vez que custos e esforços para efetivar a alteração podem ser determinados com maior precisão.
Sem um método para rastrear os artefatos que serão afetados, são necessários a opinião e conhecimento de projetistas ou programadores, que muitas vezes podem não mais fazer parte da equipe de manutenção do sistema.
Segundo Gotel e Finkelstein, apesar de o número de ferramentas que suportam o rastreamento de requisitos terem aumentado, a teoria necessária para que sejam utilizadas não tem sido amplamente estudadas.
Com isso, a maioria dessas ferramentas descobre e grava a maior quantidade de informação possível sobre o processo de engenharia de requisitos e faz relacionamentos entre essas informações para poder recuperar- las.
O problema, ainda segundo Gotel e Finkelstein, é que isso pode levar a uma dificuldade de usar essa informação, ainda mais se não existir um teste de usabilidade justificado destas, para que os usuários tenham acesso efetivo e satisfatório.
Alguns tipos de rastreabilidade foram estudados por Brooks.
Um requisito pode ser rastreado por a sua direção e evolução, entre outros:
A) Direcional:
Pode ocorrer para a frente «(rastreamento para frente é a habilidade de rastrear um requisito para componentes de projeto ou implementação) ou &quot;para trás «(rastreamento para trás é a habilidade de rastrear um requisito para sua fonte, isto é, para uma pessoa, instituição, lei, argumento).
O primeiro tipo de rastreamento é utilizado quando há necessidade de saber o impacto da alteração.
Já o segundo, é usado quando, dada uma alteração, necessita- se compreender- la desde sua origem;
B) Evolutiva:
Um rastreamento do tipo pré-especificação é utilizado quando, ainda na fase de construção da especificação, é necessário localizar as fontes dos requisitos ou pessoas responsáveis por este.
Um tipo de rastreamento pósespecificação é realizado depois de todos os requisitos do sistema terem sido levantados e é usado, por exemplo, para relacionar todos os planos de testes desenvolvidos para atacar aquele requisito em específico e então determinar se estes também precisam ser modificados.
Ao longo de os anos, foram realizadas pesquisas com o intuito de propor modelos de rastreabilidade de requisitos.
Segundo Brooks, o rastreamento de requisitos tradi-cional consiste em estabelecer relacionamentos bidirecionais entre requisitos e demais artefatos produzidos num processo de desenvolvimento de software.
Podem- se citar como trabalhos relevantes os propostos por Gotel e Finkelstein, Ramesh e Jarke e Toranzo e Castro.
Definindo- se um modelo para rastrear os requisitos ao longo de o processo de desenvolvimento de software, e também na fase de manutenção do produto, é possível determinar o impacto que uma mudança terá no sistema.
Ou seja, é possível determinar previamente todos os artefatos que serão alterados, qual o esforço para esse trabalho e quanto tempo será necessário.
Em a seção seguinte será abordada a disciplina de análise de impacto, visando a diferenciação entre esta e a rastreabilidade.
A diferença entre rastreabilidade e análise de impacto de uma mudança é bastante tênue, mas significativa.
Como foi descrita anteriormente, a rastreabilidade preocupa- se em definir a relação existente entre os artefatos do software.
A análise de impacto, por sua vez, determina quais ações devem ser tomadas para realizar a alteração, podendo estimar quais serão as conseqüências desta.
Apesar de a diferença, ambas as abordagens estão intimamente relacionadas, uma vez que a metodologia utilizada para analisar o impacto é baseada na forma como a rastreabilidade foi construída.
Ajila citou as principais razões para realizar uma análise de impacto:
A) Estimar o custo de uma mudança.
Ou seja, se uma alteração irá afetar várias partes disjuntas do software, talvez seja melhor não realizar- la ou reexaminar- la;
B) Entender a razão e o relacionamento entre o escopo da alteração e a estrutura do sistema.
Ou seja, através do rastreamento dos artefatos que serão afetados, conhecer quais de eles realmente serão modificados e quais têm chances de ser;
C) Gravar o histórico de uma mudança e avaliar se esta foi realizada com qualidade, não comprometendo outras funcionalidades do sistema;
D) Saber em quais partes do software deverá ser realizado teste de regressão, de forma a garantir a qualidade do sistema, principalmente nas seções críticas deste.
A análise de impacto pode ser vista através de dois ângulos, propostos por O'Neal:
Através da abordagem de análise de dependência e da análise de rastreabilidade.
A primeira é a análise do relacionamento entre partes do código fonte, visando descobrir quais partes deste serão afetadas por a alteração.
Essa abordagem permite que as relações sejam estabelecidas ao verificar o código fonte.
A segunda preocupa- se em analisar o relacionamento entre artefatos produzidos nas diversas fases do processo de desenvolvimento do sistema, o que permite uma visão mais ampla do impacto da mudança no sistema como um todo.
Para que seja possível o uso dessa abordagem é necessário que os artefatos tenham sido previamente relacionados.
Diversos autores propuseram modelos para determinar a análise de impacto de uma mudança, que são apresentados na subseção seguinte.
Bohner relatou diversos modelos de manutenção de software, a maioria proposto na década de 80.
Como mais relevantes podem- se citar os de Boehm, que consiste em três fases:
Entender o software, modificar- lo e revalidar- lo.
Parikh enfatiza a identificação dos objetivos antes de entender o software, depois modificar o código e por último validar a alteração.
O modelo de Osborne é focado na gerência das atividades de manutenção embora não proponha métricas para analisar o impacto de uma mudança.
Patkow propôs um modelo focado na identificação e especificação dos requisitos de mudança.
Após a mudança ser compreendida e localizada, são feitos:
O projeto da alteração, implementação e posterior validação do sistema.
A principal característica do modelo é a preocupação com a especificação e localização de onde a mudança deve ser feita.
Lewis e Henry afirmaram a necessidade de coletar métricas ao longo de o desenvolvimento do software para que o produto seja mais manutenível.
De forma genérica, todos os modelos atuais pesquisados trabalham com o fluxo mostrado na figura 2.
Como entrada, tem- se todos os artefatos do ciclo de vida do software, ou seja, todos os artefatos produzidos durante o processo de desenvolvimento mais aqueles que foram incluídos ou alterados durante o projeto de manutenção.
Esses objetos são analisados, de forma a determinar se será afetado ou não por a alteração requerida.
A o final do fluxo, tem- se a lista de todos os artefatos que deverão ser modificados.
Este trabalho detém- se no processo de analisar quais objetos do ciclo de vida do software serão impactados por um requisito de mudança e como esses são encontrados, através da rastreabilidade.
Serão abordados os métodos considerados mais relevantes para a presente proposta.
São eles o de Bohner e o de O'Neal que serão expostos a seguir.
O método de análise de impacto de uma mudança proposto por Bohner tem caráter iterativo.
A figura 3 apresenta o modelo.
O conjunto inicial de impacto (CII) são os primeiros objetos do ciclo de vida do software (OCV) que se supõem serão afetados por a mudança.
Esses normalmente são levanta- dos durante a análise do requisito de mudança.
O conjunto candidato ao impacto (CCI) são os objetos que provavelmente serão afetados por a mudança.
Estes são determinados quando a mudança é rastreada entre os artefatos.
O conjunto real de impacto (Cri) são os OCV's que realmente serão alterados.
Esse processo é considerado iterativo, pois enquanto uma alteração está sendo executada, podem- se encontrar outros objetos que são impactados que não foram previstos anteriormente.
Esses novos objetos impactados formam o conjunto de impactos descobertos (CID), que representa uma sub-estimativa.
Em oposição a este, tem- se o conjunto falso positivo de impacto (CFPI), representando uma super-estimativa.
De posse dessas variáveis, podem- se determinar quais objetos serão alterados, ou seja, o Cri é a soma do CCI, ou os objetos candidatos a alteração, e CID, isto é, os artefatos que foram encontrados posteriormente, menos CFPI, ou seja, os artefatos que inicialmente pensou- se que seriam afetados.
A fórmula 1 mostra como é realizado esse cálculo.
Fórmula 1 ­ Artefatos que serão alterados O objetivo do processo é encontrar o conjunto de objetos CCI, através de técnicas de rastreabilidade manuais ou automáticas, que seja o mais próximo possível do conjunto de artefatos realmente modificados, o Cri.
Bohner distingue o impacto em dois tipos:
Direto e indireto.
Isso porque uma mudança pode ter o efeito de uma onda, afetando objetos que não tem uma ligação direta ou óbvia com a alteração solicitada.
O impacto direto (ou impacto de primeiro nível) ocorre quando o objeto afetado é relacionado a outro diretamente.
Pode ser obtido a partir de um grafo de conectividade de uma matriz de dependência.
O impacto indireto (ou impacto em n-níveis) ocorre quando o objeto afetado está relacionado a um conjunto de dependências.
Esse conjunto é determinado por os n-níveis de relações intermediárias entre os diversos artefatos e o objeto afetado.
Esses objetos podem ser obtidos por um grafo de alcance de uma matriz de dependência.
A figura 4 representa um grafo com relacionamento entre os objetos.
A partir de um grafo como esse, pode- se extrair uma matriz de conectividade, representando quais objetos são diretamente afetados por um artefato.
Por exemplo, o objeto OCV2 tem impacto direto dos objetos OCV1, OCV8 e OCV6, que estão representados por as linhas tracejadas.
Já os objetos OCV3, OCV4 e OCV7 são dependentes de ele, reapresentados por as linhas pontilhadas.
A tabela I apresenta a matriz de conectividade para o grafo da figura.
4. Segundo Bohner[ BOH02], pode- se gerar um grafo de alcance a partir de uma matriz de conectividade, como a mostrada na tabela I, usando algoritmos de fechamento transitivo.
O problema é que, embora um grafo de alcance possa indicar o potencial impacto de um artefato em outro, esse grafo tende a mostrar que todos os objetos estão conectados, direta ou indiretamente.
Por isso, é necessário outro tipo de informação estrutural, como por exemplo, qual o nível de relação entre os objetos.
Observando o grafo da figura 4 pode- se perceber que o OCV1 e OCV8 têm nível três de relação, ou seja, é necessário passar por outros dois objetos (OCV4 e OCV7) e três conectores para se relacionarem.
Com essa relação, o autor afirma que os artefatos que possuem relacionamento direto, potencialmente serão impactados e os artefatos mais distantes provavelmente não sofrerão alteração.
O autor faz distinção entre duas abordagens, uma baseada na estrutura e outra na semântica.
O que foi descrito até aqui faz parte da abordagem estrutural.
Segundo ele, a importância da abordagem semântica se dá com a intenção de aumentar a precisão ao determinar os objetos afetados.
Tendo como base a orientação a objetos e os artefatos produzidos ao longo de o processo de desenvolvimento, o autor sugere que sejam analisados os nomes de cada um desses artefatos e de suas relações.
A técnica proposta por ele extrai os substantivos (dos dados dos objetos) e verbos (de funções e mensagens, por exemplo) para que se obtenha a lista de artefatos candidatos.
Um dos pontos fracos desse método é que quando os nomes dados aos artefatos são ambíguos ou as convenções para esses são fracas, não é possível realizar o rastreamento através da semântica.
Em a proposta de Bohner, não são apresentados resultados que validem o método por ele apresentado.
Sem a validação, não é possível certificar- se de que realmente todos os artefatos impactados por uma mudança são encontrados através desse método.
A metodologia proposta por O'Neal, está inserida no processo de desenvolvimento de software, mais especificamente na disciplina de Engenharia de Requisitos.
Quando existe a solicitação de mudança de um requisito, esse é analisado de forma a estabelecer o impacto nos demais objetos do projeto a ele relacionados.
A metodologia de análise de impacto para requisitos de mudança denominada trace-based Impact Analysis Methodology (TIAM), avalia um conjunto de requisitos de mudança.
A finalidade é prever o efeito que um conjunto de alterações terá em requisitos já estáveis, onde provavelmente o trabalho já esteja finalizado.
Algumas premissas são assumidas:
A) Requisitos funcionais do produto são rastreáveis;
B) É possível fazer a rastreabilidade &quot;para frente», ou seja, a partir de o requisito pode- se chegar a outros artefatos, até, por exemplo, ao código fonte;
C) Todos os artefatos estão disponíveis e estão atualizados;
D) A equipe do projeto ter informado qual é a influência de um artefato sobre outro, bem como a sua complexidade;
E) O processo de desenvolvimento utilizado permita a construção por módulos, dando preferência para um paradigma de orientação a objetos.
O rastreamento entre os objetos é representado por um conjunto denominado por o autor como Work product Requirements trace Model (WoRM), que é composto por outros dois conjuntos:
Work product Information Model (WIM), que contém todos os artefatos produzidos ao longo de o projeto e o Requirements change Information Model (Rim), composto por todos os requisitos de mudança.
Os modelos WIM e Rim relacionam- se, de forma que toda alteração solicitada para um requisito de mudança aponta para o referido requisito.
Por sua vez, o requisito aponta para outro artefato e assim sucessivamente.
A figura 5 demonstra esses relacionamentos:
Os produtos de trabalho, referidos por o autor, possuem alguns atributos externos, que irão auxiliar na determinação do impacto.
Os atributos usados para calcular o peso de cada artefato são:
A complexidade, que mede o grau de dificuldade para desenvolver o objeto;
O conjunto de graus de influências de mudanças e de associações entre artefatos pode ser configurado conforme o projeto e dados históricos da empresa.
Em o exemplo da figura associados valores, também configuráveis.
De posse desses, é calculada a influência de cada arco.
Esta deve ser normalizada quando dois artefatos se ligam a um outro, na figura 6 &quot;Design B «e &quot;Design C «ligam- se a &quot;Source J».
A figura 7 exemplifica as influências normalizadas entre os objetos e o peso de cada artefato do sistema.
De posse dos modelos WIM e Rim, dos pesos dos artefatos e dos valores de influência entre eles, calculam- se as métricas de impacto para cada um dos requisitos de mudança, representando a probabilidade de impacto.
As métricas são então agrupadas em conjuntos conforme a similaridade de impacto, a partir de um grau de similaridade.
Por exemplo, se o ponto de corte de similaridade for de 70%, todos os requisitos de mudança que obtiverem a métrica maior ou igual a esse ponto, formarão um conjunto.
As demais serão armazenadas em outro.
Em de cada um desses conjuntos, as métricas são ordenadas de forma decrescente.
A aplicação da metodologia TIAM caracteriza as mudanças baseadas no nível de impacto de cada uma de elas.
A metodologia de O'Neal é interessante, pois possui mecanismos para determinar os artefatos que são potencialmente afetados por uma mudança.
Além disso, seu uso foi experimentado e validado com alunos de graduação de um curso de engenharia de software da Universidade de Lousiana, Unidos.
O ponto fraco está na rastreabilidade entre os artefatos, uma vez que é estruturalmente realizada e não possui semântica.
O autor também não propõe um método para calcular a influência que um artefato exerce sobre outro, sendo esta atribuída a um especialista, sem parâmetros em os quais possa se basear.
Em a próxima seção, será abordada a Engenharia de Software Experimental.
Tem- se como objetivo apresentar essa linha de pesquisa, que está inserida na engenharia de software, visando sua utilização para, através de um experimento, analisar qual é o impacto de uma mudança rastreada através de conceitos de uma ontologia.
A engenharia de software experimental está inserida na discussão sobre classificar a engenharia de software como ciência ou engenharia.
Segundo Travassos, Gurov e Amaral, essa questão está ligada ao significado que se dá a software, estabelecendo- o como produto ao considerar seu processo de criação, que possui características de produção ou engenharia, ou que pode considerar a necessidade de melhoria contínua da qualidade do processo e do produto, sendo então caracterizado como ciência.
Em Basili, o autor faz uma comparação da engenharia de software com outras áreas, tais como física, medicina e manufaturas.
Segundo ele, as duas primeiras, diferentemente do que acontece com o produto final da engenharia de software, não podem ter a essência de seus produtos alterados, já na manufatura sim.
E, diferente da manufatura, o software é desenvolvido e não produzido, ou seja, o mesmo software não será produzido mais de uma vez da mesma maneira.
Ainda segundo o autor, existem características intrínsecas ao software que o diferem de qualquer outra ciência.
Uma de elas é que mesmo aumentando o nível de abstração, o desenvolvimento de software depende de pessoas, com seus aspectos individuais e criatividades únicas.
Isso implica que um mesmo experimento realizado com grupos distintos de pessoas poderá ter resultados diferentes.
Conforme proposto por Wohlin, Runeson, Host, Ohlsson, Regnell e Wesslen, existem diferentes métodos para experimentos na área de engenharia de software:
Científico, de engenharia, experimental e analítico.
O científico pode ser usado para tentar entender um processo com o intuito, por exemplo, de construir- lo, extraindo do mundo algum modelo que possa explicar o fenômeno e avaliar- lo.
O método de engenharia tem uma abordagem evolutiva, analisando algum modelo existente e modificando- o para tentar melhorar- lo.
O método analítico não precisa de um projeto experimental no sentido estatístico, pois possui uma base analítica para validar a teoria formal sugerida.
O método experimental (de maior importância para o presente trabalho), segundo Travassos, Gurov e Amaral inicia- se com o levantamento de um modelo novo, existente ou não, e estuda o efeito do processo ou produto a partir desse modelo, podendo ser analisado quantitativa ou qualitativamente.
Esse tipo de método tem como base as variáveis, os objetos, os participantes, o contexto do experimento, as hipóteses e o tipo de projeto do experimento.
As variáveis podem ser dependentes, que se referem à saída do processo, ou independentes, que se refere à entrada do processo.
O objeto é usado para verificar a causa e efeito numa teoria e juntamente com o sistema de medição, compõem a instrumentação do experimento.
Os participantes são as pessoas selecionadas para realizar o experimento.
É necessário observar que, para um experimento ser considerado generalizado para uma população alvo, os participantes escolhidos devem ser representativos.
O contexto do experimento refere- se as condições onde este será aplicado, ou seja, se será in-vitro (laboratório) ou in-vivo (projeto real);
Alunos ou profissionais;
Problema de sala de aula (toy example) ou problema real;
Especifico (contexto particular) ou geral (para toda Engenharia de Software).
Talvez o aspecto mais importante do experimento dê- se por a escolha das hipóteses, que são dividas entre a hipótese nula (que é a principal) e as hipóteses alternativas.
A hipótese nula nega o relacionamento estatisticamente significante entre a causa e o efeito.
Sendo assim, o objetivo do experimento é negar- la a favor de uma hipótese alternativa.
Outros aspectos centrais de um experimento correspondem à medição e a validade.
Através de elas, o mapeamento entre o mundo experimental e o mundo formal ou relacional é feito.
A validade diz respeito aos resultados do experimento e pode ser classificada em validade de conclusão, onde se valida o relacionamento entre o tratamento (teste estatístico, escolha dos participantes, confiabilidade da medida) e o resultado do experimento;
Validade interna, se o resultado é causal e não foi manipulado por influência de variáveis não controladas;
A seguir, serão apresentadas as fases necessárias para realização um experimento, propostas por Travassos, Gurov e Amaral:
A) Definição:
O experimento é expresso em termos de problemas e objetivos.
Os objetivos são separados em objetivo global, objetivo da medição e objetivo do estudo.
É sugerido o uso da técnica GQM (Goal, Question, Metric) para determinar os objetivos;
B) Planejamento:
O projeto do experimento é determinado, a instrumentação é considerada e os aspectos da validade do experimento são avaliados.
É preciso realizar a seleção do contexto, formular as hipóteses, selecionar as variáveis, selecionar os participantes, projetar o experimento, fazer a preparação conceitual da instrumentação e fazer a consideração da validade do experimento;
C) Execução:
Os dados são coletados.
Os participantes devem passar por uma preparação antes do inicio da execução.
Também é feita a validação preliminar dos dados;
D) Análise e interpretação:
São realizadas a análise e interpretação dos dados e feita à conclusão sobre a possibilidade de rejeição da hipótese nula.
Os passos que devem ser executados são:
Validação dos dados, estatística descritiva, aplicação do teste estatístico, análise quantitativa e qualitativa e verificação das hipóteses;
E) Apresentação e empacotamento:
Os resultados obtidos são apresentados e empacotados.
O empacotamento é importante, pois é necessária a repetição do experimento, para poder avaliar os resultados comparando- se com o experimento original.
Atualmente, essa fase do experimento não possui normas internacionais aprovadas.
Para viabilizar a análise de impacto de um requisito de mudança é necessário, primeiramente, conhecer o que foi produzido durante o processo de desenvolvimento do software e, principalmente, identificar o tipo de rastreabilidade utilizada.
O conhecimento dos artefatos é necessário tendo em vista que cada um de eles terá uma influência diferente no impacto que será estabelecido.
Uma das premissas básicas para realizar a análise de impacto, é ter a possibilidade de rastrear os artefatos, uma vez que esta irá determinar, a partir de o requisito de mudança, as implicações da alteração.
A proposta de uma metodologia de análise de impacto de mudança, utilizando a rastreabilidade semântica proporcionada por o uso de ontologias, foi construída com base no estudo de outras propostas na área de análise de impacto.
A metodologia de análise de impacto baseada em rastreabilidade, desenvolvida por O'Neal, foi considerada a mais interessante, pois utiliza para relacionar os artefatos a estrutura de um grafo, que também é utilizado para representar uma ontologia.
O modelo de análise de impacto proposto nesse trabalho tem como base um processo de desenvolvimento que utilize a Engenharia Ontológica e construa a rastreabilidade semântica através da ontologia do sistema.
Ainda como premissa para determinar o impacto de um requisito de mudança deve- se estabelecer a influência de um tipo de mudança na ontologia, a influência dos relacionamentos entre os conceitos da ontologia, a influência que um conceito da ontologia exerce sobre um artefato relacionado a ele e a influência do tipo do artefato, no que se refere a diagramas da UML.
Estas influências serão detalhadas nesse capítulo.
O experimento, descrito no Apêndice A, foi aplicado para conhecer de que forma alterações nos artefatos do sistema se refletem na ontologia.
Assim, foi possível perceber dois tipos de influência na ontologia:
A influência por tipo de mudança, que está relacionada a alterações diretamente nos conceitos, e a influência do relacionamento entre os conceitos, que retrata a propagação de uma mudança.
Essas duas influências serão amplamente abordadas a seguir, demonstrando o cálculo do impacto para cada uma e analisando as variáveis que se relacionam a elas.
Além de essas, serão também discutidas algumas variáveis utilizadas por O'Neal em sua metodologia, estabelecendo sua ligação com a presente proposta.
A proposta de Noll estende o RUP para que este passe a integrar em suas disciplinas a Engenharia Ontológica.
Esta nova disciplina é responsável por construir a ontologia e atualizar- la ao longo de o processo de desenvolvimento, visando manter a integridade das informações produzidas durante o projeto.
Baseado em propostas da área de Engenharia Ontológica, o autor propõe atividades que serão realizadas em cada fase da disciplina, a saber Projeto, Manutenção e Validação da ontologia.
Essas atividades são executadas por um ator que também é responsável por os artefatos produzidos e por organizar as iterações.
A tabela II mostra como as atividades são distribuídas nas fases.
Em a fase de Projeto, a ontologia preliminar é gerada.
Utiliza- se para isso o Modelo de Domínio, produzido durante a disciplina de Modelagem de Negócio do RUP.
Em este modelo, os conceitos relevantes a uma área de interesse e seus relacionamentos são descritos.
A fase de Manutenção é caracterizada por o refinamento da ontologia, onde se definem estruturas lógicas para esclarecer o modelo e podem- se integrar ontologias previamente existentes, caso seja identificada essa necessidade.
Os conceitos da ontologia são refinados a medida que artefatos como Especificação de Requisitos, Modelos são desenvolvidos.
A fase de Validação deve ser realizada a cada iteração do ciclo de desenvolvimento com a finalidade de avaliar a integridade, a completude e a corretude da ontologia em relação a o modelo lógico do projeto.
A integração da Engenharia Ontológica com o RUP é dada por a figura 8 onde Noll insere a nova disciplina entre as existentes originalmente.
Segundo ele, o início dessa disciplina ocorre logo após o começo da disciplina de Modelagem de Negócio, pois é em ela que se estabelece, em nível conceitual, o universo de discurso.
Além disso, a maior parte das atividades dessa nova disciplina está concentrada entre as fases de iniciação e de elaboração uma vez que é nesse momento que os conceitos do domínio são definidos.
Para realizar a análise de impacto baseada na rastreabilidade por ontologias é imprescindível que a Engenharia Ontológica faça parte do processo de desenvolvimento.
Com a ontologia sendo gerada, mantida e validada ao longo de o ciclo de vida do projeto, é possível estabelecer elos de rastreabilidade entre os conceitos da ontologia e artefatos produzidos no decorrer de o uso do RUP.
A seção a seguir descreve como é estruturada a rastreabilidade com o uso de ontologia.
Para que seja possível realizar a rastreabilidade ontológica, a proposta de Noll utiliza a ferramenta ONTrace.
Esta permite, através de mecanismos próprios, o rastreamento dos artefatos a partir de a ontologia gerada para representar o domínio do problema.
Existem dois conceitos associados aos recursos do ONTrace:
Model, onde estão definidos todos os tipos previstos na UML;
E artifact, que é um dos elementos produzidos no processo de desenvolvimento de software.
Esse último possui duas propriedades associadas:
Através da ferramenta desenvolvida por Noll é possível associar os conceitos da ontologia gerada aos elementos do modelo.
Concluído esse processo de associa-ção entre conceitos e artefatos, pode- se buscar o conjunto de elementos que estão relacionados a um mesmo conceito, possibilitando o conhecimento de todos os artefatos que serão impactados por uma alteração.
Utilizando o exemplo dado por o autor, o caso de uso &quot;Registrar compra», pode estar associado a conceitos como &quot;cliente», &quot;compra», &quot;produto».
Outro caso de uso, &quot;Cadastrar cliente», relaciona- se com o conceito &quot;cliente».
Tem- se então um relacionamento entre os casos de uso indexados por o conceito &quot;cliente».
O rastreamento de artefatos pode ocorrer em outros níveis, além de o relacionamento direto apresentado no exemplo anterior.
Se conceitos da ontologia possuírem, por exemplo, relacionamentos não taxonômicos, os artefatos associados a esses conceitos podem se relacionar.
Supondo que o caso de uso &quot;Cadastrar funcionário «esteja associado ao conceito &quot;funcionário», e o caso de uso &quot;Cadastrar cliente «esteja associado ao conceito &quot;cliente», se os conceitos &quot;funcionário «e &quot;cliente «estiverem relacionados por uma propriedade, talvez um caso de uso seja afetado por uma mudança no outro.
Em as seções seguintes, serão estabelecidas as influências que elementos da ontologia possuem, dependendo do tipo de mudança, relacionamento e artefatos associados.
Em a metodologia TIAM de análise de impacto, a complexidade é uma das variáveis utilizadas para determinar o peso de um artefato.
Um dos objetivos de mensurar- la é associar ao cálculo da probabilidade de impacto a dificuldade de manter o artefato, em termos, por exemplo, de estimativas de tempo, custo e esforço para realizar o requisito de mudança.
As seções seguintes expõem como a complexidade de artefatos pode ser estabelecida e são citadas outras formas de determinar- la, além de os modelos de custos propostos por Boehm, cujo uso é sugerido por O'Neal.
A intenção é demonstrar como essa variável é empregada em cada uma das propostas, na metodologia TIAM e na análise de impacto baseada em ontologias, e distinguir o seu uso em cada uma de elas.
A complexidade de artefatos é definida ou estimada por o uso de métricas.
Existem diversas propostas de métricas na bibliografia e o uso de cada uma de elas está ligado a qual foi o processo de desenvolvimento usado no projeto, o paradigma de programação e a arquitetura do software utilizada, de entre outros fatores.
Além disso, há a diferenciação entre métricas de processo e de produto.
Em o contexto dessa pesquisa é interessante verificar quais são as métricas utilizadas para produto de software, estabelecendo prioritariamente métricas para o paradigma de orientação a objetos relacionados a diagramas da UML.
A o final dessa subseção, será analisado o uso da complexidade de artefatos na proposta de análise de impacto baseada em ontologias.
Em esses mais de trinta anos de pesquisa na área de métricas, a importância do desenvolvimento de projetos de software teve um crescimento bastante acentuado.
O aumento dessa importância faz com que haja mais requisitos intrínsecos ao projeto.
Desta forma, é necessário que exista um controle mais preciso tanto no processo de desenvolvimento quanto no produto a ser entregue.
Isso se faz necessário, pois a maioria dos projetos atrasa, estouram o orçamento ou não possuem a qualidade desejada por o cliente.
Uma forma de evitar ou reduzir esse tipo de problema é conseguir estimar corretamente as variáveis envolvidas, tais como custo, esforço e prazo necessários para o desenvolvimento do projeto.
O processo de medição de software traz benefícios como modelar e entender o processo de desenvolvimento e o produto gerado, ajudar na gerência do projeto de software e melhorar- lo.
Dentro de esta realidade, a área de métricas de software, que é a medida quantitativa de atributos específicos do desenvolvimento de software, tem sugerido meios capazes de atingir os objetivos desejados.
Scotto classificou os tipos de métricas em métricas de processo, de produto e de recursos.
O foco das métricas de produto está nas características do software em relação a a qualidade de entrega.
Segundo Sommerville, medidas como tamanho e complexidade ciclomática não são facilmente relacionadas com atributos de qualidade, tais como a facilidade de compreensão e manutenção, isto porque estão intimamente relacionadas com o processo de desenvolvimento e com a tecnologia aplicada.
Uma forma de relacionar tais medidas e atributos à realidade do projeto que está sendo desenvolvido é coletar essas métricas e comparar os dados históricos dentro, por exemplo, de uma fábrica de software, procurando uma relação entre elas.
Sommerville propôs a classificação das métricas de produto em dinâmicas e estáticas.
A primeira é relacionada diretamente à qualidade e são coletadas por medições realizadas por um programa em execução.
Esse tipo de métrica pretende avaliar a eficiência e a confiabilidade de um programa.
Já as métricas estáticas são medidas por representações do sistema, ou seja, por o projeto, programa ou documentação, tendo uma relação indireta com atributos de qualidade.
Essas métricas ajudam a medir atributos como a complexidade, a facilidade de compreensão e manutenção do software.
Outra proposta de classificação de métricas de produto foi dada por Mills, que as separou em métricas de produto por tamanho, complexidade e qualidade.
A medida por tamanho está diretamente relacionada ao produto e processo por meio de o qual este foi desenvolvido;
A medida por complexidade tem relação com o gerenciamento do processo de desenvolvimento;
E a medida por qualidade que mensura características como a corretividade, confiabilidade e manutenibilidade, sendo essas as mais estudadas dentro de um tópico onde não existe consenso numa única métrica para todos os itens de qualidade.
Além de as classificações apresentadas, pode- se ainda classificar as métricas de produto em métricas orientadas a objetos.
Pesquisas nesse sentido iniciaram na década de 90, sendo que algumas foram derivadas das métricas mais antigas, baseadas em programação estruturada, embora outras sejam exclusivas do paradigma de orientação a objetos.
Dentro de essas pesquisas, os métodos propostos por Lorenz em 1993 e por Chidamber e Kemerer em 1994, são bastante referenciados.
A primeira proposta é composta de um conjunto de onze métricas orientadas a objetos (OO).
A segunda, também conhecida como métricas CK, possui um conjunto de seis métricas, voltadas para o projeto e complexidade.
Essa proposta, de entre outras, serviu como base para as atuais métricas orientadas a objetos que utilizam diagramas da UML, segundo Kim.
As métricas para esses diagramas serão apresentadas na seção seguinte.
Desde a sua criação, a UML vem sendo largamente utilizada no processo de desenvolvimento de softwares orientados a objetos.
Segundo Kim, uma vez que o número de artefatos produzidos utilizando a UML aumentou, existe a necessidade de mensurar as características desses objetos.
Com isso, é possível obter uma noção exata, por exemplo, da complexidade do projeto já nas primeiras fases deste, que é o momento onde se começa a criação dos modelos UML.
Uma das vantagens apontadas por McQuillan, é de que, com o uso dessas métricas, a qualidade do software pode ser estimada ainda nas fases iniciais do ciclo de vida, onde o custo de se fazer uma mudança ainda não é alto.
Durante a pesquisa de trabalhos nesta área, não foi encontrado um modelo único de métricas para artefatos da UML.
Cada proposta utiliza as métricas dentro de o seu próprio modelo, com o objetivo de propor resultados mais precisos.
Outra característica, segundo Genero, é que a maioria das propostas trabalha com os diagramas estruturais, principalmente com o diagrama de classes.
Tendo em vista essa realidade, será apresentada a seguir uma métrica de complexidade para esse diagrama.
Dentro de o estudo de métricas orientadas a objetos, a complexidade dos diagramas estruturais são os que possuem mais pesquisa, segundo Genero.
Trabalhos propostos por Chidamberer e Kemerer, as métricas CK, por Lorenz, por Marchesi e por Fenton, de entre outros, estão relacionados a esse diagrama.
A proposta de Carbone, denominada Fast &amp; &amp; Serious, propõe métricas para determinar a complexidade do diagrama de classes, ou somente de uma classe, já que considera esse artefato o mais importante da modelagem orientada a objetos.
O método é composto por seis passos, sendo alguns opcionais, como mostra a tabela III.
Calcular a complexidade de cada classe (CP) pertencente ao diagrama de classes que está sendo analisado.
Avaliar o Cps para o diagrama de casos de uso.
Avaliar o Cps para os diagramas de seqüência e de colaboração.
Avaliar o Cps para o diagrama de estados.
Somar os Cps encontrados nos passos 2, 3, 4 e 5, obtendo o número de SLOC de todo o sistema.
Os passos que estão sinalizados na tabela III com(*) não são obrigatórios.
O primeiro passo determina qual método será utilizado, através da média da métrica do percentual de métodos com assinatura (PMS).
Se o PMS for maior do que 70% é usado o método Fast, senão é usado o método Serious.
A seguir, será apresentado apenas o método Fast, descrevendo o segundo passo da tabela III, pois a finalidade é conhecer como se determina a complexidade das classes de um diagrama de classes.
Atributos complexos desenvolvidos e testados, como atributos em pacotes pré-definidos.
Atributos complexos de uma classe não desenvolvida e não testada.
Peso numAtrib (c) SP (c) Peso (ListAtrib) i 1 Fórmula 2 ­ Cálculo do número de Pontos por Estado Após o cálculo de SP, os métodos são classificados em Triviais, que são métodos que possuem ao menos 80% de atributos do tipo leve e não tem atributos do tipo importado na sua assinatura, ou em Substanciais, que são os métodos que não foram classificados como triviais.
Em o método Fast, que é o único que está sendo abordado nesse trabalho, todos os métodos são classificados como substanciais com um atributo do tipo importado.
Caso o método Serious fosse aplicado, cada método da classe deveria ser classificado conforme os critérios apresentados.
A complexidade do método é dada por a fórmula 3, onde numLA, numHA e nu-mIA são os números de atributos leves, pesados ou importados na assinatura do método, respectivamente.
A variável T significa que o método é trivial e S, que é substancial Cm (m) numLA numHA numIA Fórmula 3 ­ Cálculo da Complexidade do Método Em seguida, o Ponto por Comportamento (BP) é calculado para a classe, conforme a fórmula 4, onde numAss é o número de associações da classe e numMet é o número de métodos da classe.
BP (c) 1 numAss (c) Cm (mi) i 1 Fórmula 4 ­ Cálculo dos Pontos por Comportamento Por fim, é calculado, para cada classe, o Ponto por Classe (CP), que é a estimativa da complexidade desta, apresentada na fórmula 5.
CP (c) 2 SP (c) 3 BP (c) Fórmula 5 ­ Cálculo dos Pontos por Classe Com esta estimativa é possível prever quando uma classe é mais complexa do que outra, caracterizando, possivelmente, uma maior dificuldade de manutenção das classes mais complexas.
Um exemplo de aplicação desse método será dado na seção seguinte.
Para utilizar a metodologia TIAM, o peso do artefato é uma das informações utilizadas para conhecer a métrica de impacto do requisito de mudança.
Essa métrica possibilita que sejam determinadas outras estimativas com a finalidade de prever o que é necessário para efetuar cada alteração solicitada.
O peso do artefato é então dado por a fórmula 6, que além de a complexidade do artefato (c (n)), relaciona o esforço (e (n)), que mensura o tempo necessário para produzir o artefa- to, e a fase (p (n)) em a qual este está inserido, considerando que quanto mais adiantada for a fase, maior o esforço para alteração.
Fórmula 6 ­ Cálculo do peso do artefato Os níveis e valores relacionados às variáveis de complexidade, fase e esforço são determinados por os desenvolvedores durante o processo de desenvolvimento.
A variável e (n) é determinada por o esforço em horas necessárias para desenvolver um artefato e é mensurada em homem-hora.
A complexidade e a fase devem ser classificadas em diferentes níveis.
Para exemplo para o cálculo do peso de um artefato.
Usando os conjuntos de complexidade e fases acima propostos, pode- se determinar que o peso do artefato &quot;Autor «é de w (n) $= 0,45, considerando que o artefato tem complexidade baixa (c (a) $= 0,3), que o esforço de desenvolvimento é de 30 min (e (a) $= 0,5) e que está presente na fase de projeto (p (a) $= 3).
Para o artefato &quot;Livro», o peso correspondente é de w (n) $= 0,9, pois o seu tempo de desenvolvimento, incluindo implementação do método, é de 2h (e (l) $= 2), com complexidade baixa (c (l) $= 0,3) e também pertencente à fase de projeto (p (l) $= 3).
Posteriormente, esses valores serão usados juntamente com a influência da relação entre os artefatos para determinar a métrica de impacto.
Em o âmbito da presente pesquisa, interessa descobrir quais artefatos serão afetados usando a probabilidade de impacto em cada um de eles.
Em esta realidade, a variável fase não é utilizada, uma vez que esta se refere as fases do processo de desenvolvimento e não a um projeto de manutenção.
As variáveis de complexidade e esforço de cada artefato não determinam uma maior ou menor probabilidade de impacto, como é o objetivo, já que elas estão relacionadas à dificuldade de manter- lo.
Utilizando o mesmo diagrama de classes da figura 10, com o uso do método Fast &amp; &amp; Serious, pode- se determinar a complexidade das classes.
A figura 11 mostra a aplicação do método para calcular a complexidade destas.
Tem- se então que a complexidade da classe &quot;Autor «é de CP (a) $= 13 e da classe &quot;Livro «é de CP (l) $= 17, sendo esta última mais complexa do que a primeira.
Um exemplo de um requisito de mudança para o domínio desse problema poderia ser o apresentado na figura 12.
O resultado dessa alteração no diagrama de classes do projeto possivelmente seria o representado na figura 13.
Percebe- se então que, embora a classe &quot;Livro «seja efetivamente mais complexa que a classe &quot;Autor», esse não foi um fator determinante para considerar o impacto do requisito de mudança.
A metodologia TIAM utiliza fatores de influência nos elos que inter-relacionam o requisito de mudança e os diversos artefatos produzidos durante o projeto.
Quem classifica a influência é o desenvolvedor, durante o processo de desenvolvimento.
Os níveis de influência e seus respectivos valores podem ser escolhidos conforme a característica de cada projeto e por o histórico de projetos da empresa.
Uma vez escolhidos os níveis e valores atribuídos aos arcos entre os artefatos, o grau de influência deve ser normalizado, a fim de que, se vários artefatos estiverem relacionados a um único outro, a soma das influências de cada elo seja igual a 1, ou 100%.
A figura 14 apresenta um exemplo do uso dessas influências.
A metodologia TIAM proposta por O'Neal serve como base para a proposta da análise de impacto através da rastreabilidade por ontologias.
Isso porque, considerando que uma ontologia tem representação equivalente a um grafo e que a rastreabilidade semântica em ela relaciona conceitos a artefatos, pode- se assumir que existe uma influência específica do arco que liga o conceito ao artefato.
A figura 16 representa graficamente essa relação, usando como exemplo os artefatos do grafo de relacionamento da figura 15.
O grau de influência de cada relacionamento depende do tipo de artefato ao qual o conceito está ligado.
Embora o conjunto de níveis de influência e seus valores possam ser Cada um dos conceitos, que estiver relacionado a um artefato, deve ter a variável Influência do conceito no artefato (Ic) informada, dentro de a escala sugerida.
A tabela V apresenta um guideline para ajudar nessa classificação, que é baseado em características do tipo do artefato.
Os diagramas da UML presentes na tabela V e que são referenciados nesse trabalho foram escolhidos, pois são suportados por a ferramenta ArgoUML, em a qual o aplicativo ONTrace foi desenvolvido como um plug-in.
Atualmente, só os objetos do ciclo de vida do software que foram modelados nesse sistema têm a possibilidade de serem rastreados.
Três dos diagramas que podem ser modelados e rastreados por a ferramenta de modelagem citada e que não estão presentes no guideline proposto são:
O Diagrama de Casos de Uso, o Diagrama de Classes e o Diagrama de Implantação.
O primeiro diagrama não consta na classificação da influência do conceito no artefato, pois se preferiu trabalhar somente com a descrição do caso de uso ao invés de o relacionamento entre eles, uma vez que é no detalhamento deste que se encontram as informações comportamentais do sistema.
De forma análoga, foram consideradas apenas as classes, pois assim é possível ter conhecimento exato de quais de elas serão impactadas por um requisito de mudança, considerando que o Diagrama de Classes é muito abrangente, pois vários conceitos poder ser relacionados a ele.
Já o último diagrama relatado não está abordado no guideline por dar a visão organizacional do hardware do sistema, que está fora de o escopo dessa pesquisa.
O conceito é referenciado na pré ou pósO conceito é referenciado no condições e/ ou fluxos alternativo e de fluxo principal exceção Classe associativa quando uma das Possui o mesmo nome do conclasses ligadas a ela tem o mesmo nome ceito do conceito Está presente nas mensagens entre os O conceito é um objeto objetos O conceito está presente nos estados dos O conceito está presente nos fluxos alternativos e de exceções estados do fluxo básico O conceito está presente nas atividades O conceito está presente nas dos fluxos alternativos e de exceções atividades do fluxo básico Está presente nas mensagens entre os O conceito é um objeto objetos Os critérios de influência dos artefatos utilizados para construção do guideline foram determinados segundo estudo de cada um dos diagramas da UML.&amp;&amp;&amp;
Por exemplo, quando se descreve um Caso de Uso (UC), o fluxo principal deste é obrigatório, sendo opcionais o fluxo alternativo e pré ou pós-condições.
Assim, infere- se que quando o conceito estiver presente no fluxo principal, a Influência do concenito no artefato (Ic) é forte, caso esteja apenas no fluxo alternativo ou na pré ou pós-condições é fraco.
Futuramente, este guideline pode ser revisto através de experimentos, podendo, inclusive, abranger todos os diagramas da UML.
Considerando o conceito &quot;Autor «associado à classe &quot;Autor «da figura 17, a influência que o primeiro exerce sobre o seguindo é de Ic $= Forte, utilizando o critério presente na tabela V. Já o diagrama de atividades relacionado ao mesmo conceito possui Ic $= Fraco.
A influência do conceito no artefato não deve ser normalizada quando dois conceitos diferentes estiverem relacionados ao mesmo artefato.
Isso não é necessário, pois a influência é máxima para cada par conceito-artefato individualmente e não se considerado o conjunto de todos os conceitos que se ligam ao mesmo artefato.
Diagramas da UML podem ser classificados em modelos estáticos, dinâmicos e funcionais.
Os modelos estáticos mostram a estrutura do sistema e as suas funcionalidades.
Os modelos dinâmicos mostram as interações que o sistema suporta.
Esses detalham a interação entre os diagramas estruturais, fornecendo uma representação mais clara do comportamento do sistema.
Os modelos funcionais mostram a organização em seu sistema dos componentes executáveis.
Esses distinguem a localização física de execução entre os componentes e os nós de armazenamento com os que eles podem interagir.
Eles são produzidos no início da fase de desenvolvimento do sistema e são atualizados durante o projeto para indicar a arquitetura física pretendida.
É importante diferenciar o tipo de diagrama, pois, dependendo do tipo de mudança, os artefatos são influenciados de forma diferente, com relação a a sua classificação.
Quando há alteração de regras de negócio, os diagramas dinâmicos são os mais afetados.
Quando a mudança é referente a a estrutura dos artefatos, os diagramas estáticos têm maior probabilidade de impacto.
Em o experimento que foi realizado e que serviu para identificação das hipóteses, não foi possível detectar a influência nos diagramas funcionais, pois esses não fizeram parte do estudo.
Sendo assim, a influência referente a esse tipo de diagrama será determinada como irrelevante, para qualquer tipo de mudança, sendo proposto seu estudo como trabalho futuro.
A Influência do tipo de diagrama (Id) é dada por o conjunto das classificações dos dado conforme o tipo de mudança e será determinado na seção seguinte.
Para cada artefato associado a um conceito, deve- se classificar o tipo de diagrama a que pertence, conforme a tabela VI.
Um requisito de mudança pode afetar de diferentes formas o produto ao qual é relacionado durante o projeto de manutenção deste.
Considerando- se que durante o processo de desenvolvimento foi incluída a disciplina de Engenharia Ontológica, as alterações requisitadas podem ser identificadas na ontologia.
Através do experimento, detalhado no Apêndice A, percebeu- se ser de grande influência as mudanças de regra de negócio, que estão relacionadas ao significado dos conceitos da ontologia, e as mudanças no relacionamento dos conceitos, que engloba a inclusão ou alteração destes, alterando estruturalmente a ontologia.
A variável Influência da mudança (Im) deve ser determinada para, juntamente com a Influência do conceito no artefato (Ic) e a Influência do tipo de diagrama (Id), medir o Impacto em o artefato por a mudança (Iam (x, y), que é calculado através da fórmula 8, onde x é o conceito do tipo class e y é o artefato.
Iam (x, y) $= Im x Ic x Id Fórmula 8 ­ Cálculo do Impacto em o artefato por a mudança (Iam (x, y) vez que a influência do tipo de diagrama depende do tipo de mudança ocorrida, os valores dos Quando uma regra de negócio já existente é alterada ou quando uma nova regra é associada a um conceito, o significado deste pode ser alterado.
Isso significa que poderá haver mais restrições nas propriedades da ontologia ou que o domínio do conceito poderá ser alterado, por exemplo.
Em o código Web Ontology Language (OWL) presente na figura 18, tem- se a restrição allValuesFrom, que restringe os valores da propriedade da classe a que está associada.
Ou seja, todos os membros da classe que possuírem a propriedade devem pertencer ao tipo de recurso indicado na cláusula.
Em o exemplo significa que toda instância da classe &quot;Casal», se tiver filhos, estes devem pertencer a classe &quot;filhoNatural».
Um requisito de mudança poderia alterar a obrigatoriedade de que os filhos do casal pertençam a classe de &quot;filhoNatural», podendo ser &quot;filhosAdotivos».
Quando conceitos são incluídos ou alterados numa ontologia, o relacionamento entre eles pode ser afetado.
Em uma inclusão, provavelmente um novo elo de ligação entre conceitos será necessário.
Em uma alteração, a própria ligação entre eles pode ser modificada.
Em essas situações se está alterando estruturalmente o relacionamento entre os conceitos.
Assim, o Quando um conceito é alterado, está se modificando a propriedade do tipo range de um conceito do tipo dataTypeProperty.
Essa mudança tem grande influência sobre artefatos relacionados diretamente a esse conceito.
A figura 19 mostra uma sub ontologia para o domínio de livros, destacando o relacionamento do conceito &quot;ISBN «com o seu tipo de dado.
A inclusão de um conceito pode ser de dois tipos:
A associação de um novo conceito do tipo dataTypeProperty a um já existente do tipo class, e a inclusão de um conceito do tipo class, com seus dataTypeProperty associados e objectProperty relacionados.
A seguir, cada uma dessas inclusões será detalhada.
A inclusão de um conceito do tipo dataTypeProperty irá acrescentar uma nova propriedade ao conceito do tipo class ao qual se relacionar.
Essa situação pode ser verificada analisando o exemplo da figura 22 que é a representação de parte do modelo de domínio de livros, apresentado anteriormente na figura 10.
A ontologia equivalente a esse modelo é mostrada na figura 23.
A influência desse tipo de mudança foi percebida durante o experimento relatado no Apêndice A. A inclusão de um novo conceito do tipo dataTypeProperty caracterizou- se por afetar fortemente os artefatos ligados ao conceito do tipo class ao qual o primeiro se relaciona.
Durante o experimento, não houve nenhum requisito de mudança que propiciasse a inclusão de um novo conceito do tipo class.
Estudando a estrutura ontológica percebe- se que quando conceitos desse tipo são incluídos, há uma nova associação com outros conceitos da ontologia.
Essa associação é possibilitada por o uso de conceitos do tipo objectProperty.
Em esse caso, o impacto é calculado para os artefatos que estão relacionados ao conceito ao qual o novo conceito se liga.
Para exemplificar essa situação, o requisito de mudança da figura 25 é aplicado ao modelo de domínio de livros, representado na figura 22.
A alteração na ontologia está representada na figura 26, onde estão destacados os novos conceitos incluídos.
Em o exemplo, o novo conceito do tipo class &quot;Livraria «é ligado ao conceito do tipo class &quot;Livro», anteriormente existente, através do novo conceito do tipo objectProperty &quot;ehVendido».
Como na ontologia original do domínio de livros não existe o conceito &quot;Livraria», conseqüentemente não há artefatos rastreados para esse conceito.
Assim, a análise de impacto dessa mudança deve ser feita rastreando- se os artefatos que estão associados ao conceito &quot;Livro», através da influência do relacionamento entre conceitos, apresentado a seguir.
Sendo a ontologia equivalente a um grafo, é possível percorrer seus nodos, ou conceitos, a partir de critérios pré-estabelecidos.
Em o contexto da rastreabilidade semântica, essa característica é útil, pois permite encontrar os artefatos indiretamente afetados, a partir de o relacionamento entre conceitos.
A metodologia aqui proposta sugere o uso de algoritmos de radicalização (ou de stemming) para língua portuguesa, como forma de identificar a relação sintática existente entre os conceitos que se relacionam.
Este é utilizado para determinar o peso relativo ao conceito do tipo objectProperty que liga outros dois conceitos do tipo class.
Em a seção seguinte, será abordada a área em a qual esse método está inserido, bem como a forma de utilizar- lo.
O Processamento de Linguagem Natural (PLN) é usado, segundo Dias, para descrever a função de softwares ou de componentes de hardware num sistema computacional que analisam ou sintetizam linguagem falada ou escrita.
Segundo Gonzalez, aspectos da comunicação humana como sons, palavras, sentenças e discursos, considerando formatos e referências, estruturas e significados, contextos e usos são tratados computacionalmente.
O autor estabelece níveis de entendimento para esses aspectos:
A) Fonético e fonológico:
Que trabalham o relacionamento das palavras com os seus sons;
B) Morfológico:
Abrange a construção das palavras a partir de as unidades de significado primitivas e sua classificação em categorias morfológicas;
C) Sintático:
Aborda o relacionamento das palavras entre si e como as frases podem ser partes de outras, construindo sentenças;
D) Semântico:
Estuda o relacionamento das palavras com seus significados e como eles são combinados para formar os significados das sentenças;
E) Pragmático:
Abrange o uso de frases e sentenças em diferentes contextos, afetando o significado.
Em o contexto da presente proposta, cabe analisar os níveis morfossintático e semântico.
Ambos serão brevemente detalhados a seguir, citando as técnicas utilizadas para extrair informações de cada um desses processamentos.
Segundo Dias, fazem parte do processamento morfossintático, a análise morfológica e a análise sintática.
Ambas preocupam- se com a constituição das palavras e de seus grupos, que é o que forma os elementos de expressão de um língua.
A morfologia está ligada a estrutura da palavra e a classificação dessas.
Por outro lado, a análise sintática preocupa- se com o agrupamento de palavras, verificando a formação de frases.
Inserido na análise morfológica encontra- se a conflação, que é o ato de fusão ou combinação para igualar variantes morfológicas de palavras.
Segundo Gonzalez os principais métodos de conflação são o de radicalização e o de lematização.
O método de radicalização é relevante, dentro de a proposta de análise de impacto, pois combina as formas diferentes de uma palavra numa representação comum, o radical.
Esse método pode ser utilizado para determinar a similaridade entre os conceitos da ontologia, através de algoritmos de radicalização.
Esses algoritmos permitem comparar palavras que são basicamente iguais, mas que sem a radicalização são palavras distintas.
Em a figura 27, é mostrado um exemplo de aplicação dessa técnica.
As palavras &quot;Livro «e &quot;Livraria «são reduzidas a um mesmo radical, identificando que há uma relação entre elas.
Livro Livraria Radical:
LivrFigura 27 ­ Exemplo de radicalização de palavras.
Em a metodologia de análise de impacto, se for possível reduzir os conceitos ao mesmo radical, então a influência do relacionamento entre esses dois conceitos é alto, caso A ligação entre os conceitos &quot;Livro «e &quot;Livraria «é dada por o conceito &quot;ehVendido», como visto na figura 28, onde estão destacados os conceitos do tipo objectProperty.
Em esse caso, a Influência do relacionamento seria:
Ir $= alto.
Isso significa que um requisito de mudança que afete os artefatos ligados a um desses conceitos tem grande probabilidade de impactar os artefatos do outro.
Já o conceito &quot;ehEscrito «tem influência Ir $= baixo, pois os conceitos relacionados a &quot;Autor «e &quot;Livro «não podem ser reduzidos ao mesmo radical.
Embora a extração de um radical comum entre dois termos seja capaz de estabelecer um relacionamento entre eles, este está restrito à morfologia das palavras.
Uma maneira mais precisa determinar a influência de um relacionamento seria usar estruturas semânticas para tal.
Em a seção seguinte será brevemente detalhada a estrutura de tesauro.
A semântica tem relação com o significado das palavras ou do conjunto de elas.
Segundo Dias, o processamento semântico é considerado um dos grandes desafios do PLN, pois se vincula a morfologia e a estrutura sintática juntamente com informações pragmáticas.
O significado de conjuntos de palavras pode ser obtido utilizando estruturas como um tesauro, cuja definição dada por Corrêa é de um agrupamento de palavras, ou radicais de palavras em certas categorias de assunto chamadas de &quot;classes conceituais».
Uma das vantagens de usar- lo é a possibilidade de se ter um vocabulário controlado para pesquisa.
Os objetivos elencados por Salton para a criação de um tesauro são:
A) A padronização das palavras-chave que foram encontradas, ou seja, fornecer um vocabulário padrão para indexação e pesquisa;
B) Ajudar os usuários na localização de termos para a formulação de consultas e;
C) Fornecer hierarquias de classes que permitem ampliar e limitar as consultas de acordo com as necessidades do usuário.
A forma mais simples de estruturar um tesauro é ter uma lista de palavras (conceitos) importantes para um domínio de conhecimento e, para cada palavra dessa lista, um conjunto de palavras relacionadas.
As palavras relacionadas são variações derivadas de um relacionamento sinônimo.
A representação, segundo Corrêa, pode ser feita através de um grafo, onde cada nodo representa um termo que está ligado a outros termos e aos arcos são atribuídos pesos.
Os pesos são importantes para poder determinar a similaridade entre termos de um documento.
A figura 29 representa um tesauro.
Em um tesauro palavras sintaticamente distintas, mas com semântica equivalente podem ser relacionadas.
Em o exemplo da figura 29, os termos &quot;casa «e &quot;apartamento «têm significados iguais, no contexto de moradia, mas são sintaticamente diferentes.
Em o contexto de análise de impacto, uma melhoria na proposta aqui descrita seria usar estrutura de tesauro, ao invés de algoritmos de radicalização, para determinar a influência do relacionamento entre conceitos da ontologia.
Assim, termos relacionados a um mesmo domínio poderiam ser identificados, mesmo que tenham formação morfológica distintas.
De essa forma, a precisão da influência entre os conceitos seria maior, possibilitando determinar mais precisamente a probabilidade de impacto de uma mudança em diversos níveis de caminhamento na ontologia.
A seguir, será apresentado o cálculo da influência do relacionamento entre conceitos, utilizando o processo de radicalização de palavras, como visto anteriormente.
O uso de uma estrutura como tesauro deverá ser verificada em trabalhos futuros.
Em a ontologia, a propriedade objectProperty tem o papel de relacionar conceitos do tipo class.
A figura 28 destaca essa propriedade.
Assim, podemos perceber que, se uma alteração for realizada no conceito &quot;Autor», os artefatos ligados ao conceito &quot;Livro «podem ser rastreados, uma vez que os dois estão relacionados através do conceito &quot;ehEscrito».
Se ocorrer uma mudança em &quot;Livro», essa pode afetar os artefatos relacionados ao conceito &quot;Livraria», já que esses estão ligados por o conceito &quot;ehVendido».
Assim, a rastreabilidade pode ser realizada em níveis.
Em a metodologia de análise de impacto aqui proposta, o rastreamento de conceitos é realizado somente na ontologia do sistema após os conceitos do requisito de mudança serem identificados em ela.
Em o capitulo 4, esse assunto será amplamente abordado.
Associado a cada conceito do tipo objectProperty tem- se a influência que este exerce sob os conceitos aos quais se relaciona.
Esta influência é importante uma vez que irá auxiliar na determinação de em quantos níveis é interessante percorrer a ontologia.
Se não houver um critério para determinar o nível máximo de rastreabilidade, é provável que todos os artefatos do projeto sejam encontrados, uma vez que todos os conceitos estão relacionados de alguma forma.
Para iniciar o caminhamento na ontologia, sugere- se rastrear a partir de o conceito que teve maior número de mudanças, seja estrutural ou semântica.
Deve- se encontrar o conceito onde se iniciará o percurso de busca, somando todos os valores de Impacto em o artefato por a mudança (Iam (x, y) que foram encontrados para cada um dos artefatos relacionados aos conceito.
Aquele conceito que possuir o maior Impacto acumulado (Ia (x)), será o ponto inicial de caminhamento no grafo, apresentado na fórmula 9 onde x é o conceito, n é o número de artefatos ligados ao conceito e y é o artefato.
Ia (x) Iam (x, y) x 1 Fórmula 9 ­ Cálculo do Impacto acumulado (Ia (x)) A figura 30 mostra a aplicação da fórmula 9, supondo valores para artefatos ligados aos conceitos &quot;Livraria», &quot;Livro «e &quot;Autor».
Com o resultado, o conceito a partir de o qual se iniciará o caminhamento é o conceito &quot;Livraria».
Para estabelecer a Propagação do impacto (Pi), os diversos fatores de Influência do relacionamento (Ir (z)) devem ser multiplicados, como mostra a fórmula 10, onde z representa o conceito do tipo objectProperty, conforme os conceitos são percorridos.
A sugestão dessa a metodologia é que o nível de impacto para parada do percurso seja fixado em 70%.
Sendo menor do que esse valor não é mais recomendável continuar a rastreabilidade, pois a tendência é que os artefatos não sejam afetados por a alteração do requisito de mudança.
Pi Fórmula 10 ­ Cálculo da Propagação do impacto (Pi) Todos os conceitos do tipo objectProperty que estiverem relacionados ao conceito com maior Ia devem ser analisados para que o Impacto em o artefato por o relacionamento (Iar (x, y) seja calculado.
Essa variável irá determinar a probabilidade de alteração no artefato, através da fórmula 11, onde x é o conceito do tipo class e y é o artefato.
Em ela, Pi representa a propagação de influência que o conceito recebeu até o momento no caminho percorrido no grafo.
Os valores que devem ser atribuídos aos elementos da variável Id são os mesmos utilizados para mudanças de regras de negócio, isso porque supostamente as alterações desse tipo têm maior propagação do que mudanças estruturais.
Iar (x, y) Pi Ic Id Fórmula 11 ­ Cálculo do Impacto em o artefato por o relacionamento (Iar (x, y).
Usando os elementos da figura 28, tem- se que o conceito do tipo class &quot;Livraria «está ligado ao conceito do tipo objectProperty &quot;ehVendido «que por sua vez está ligado ao conceito do tipo class &quot;Livro».
Considerando que os artefatos do conceito &quot;Livraria «foram os que mais sofreram alterações, os artefatos do conceito &quot;Livro «têm probabilidade de serem impactados.
O calculo dessa probabilidade é mostrada na figura 31.
Nota- se que Pi é igual a Ir (ehVendido), isso porque os conceitos estão diretamente ligados.
Uma vez que o conceito &quot;Livro «tem probabilidade de ser impactado e este se relaciona com o conceito do tipo class &quot;Autor «através do conceito do tipo objectProperty &quot;ehEscrito», os artefatos relacionados ao conceito &quot;Autor «podem ser também impactados por a mudança.
Calcula- se então a Propagação do impacto (Pi) e as probabilidades correspondentes para cada artefato, como mostra a figura 32.
De essa forma, estamos percorrendo a ontologia em três níveis.
Em o exemplo, utilizou- se um critério de parada de 40% com o único objetivo de demonstrar o cálculo em níveis, mesmo sabendo que não é esse o fator recomendado por a metodologia aqui apresentada.
Em esse caso específico, quando Pi 0,4, o caminhamento no grafo deve ser descontinuado.
Por exemplo, se o conceito &quot;Autor «estivesse ligado a um outro conceito e o Ir entre eles fosse baixo, o valor de Pi passaria a ser de 0,225, tornando assim não interessante o rastreamentos dos artefatos ligados a esse último conceito.
Após o detalhamento de todas as influências e variáveis necessárias para que a metodologia seja aplicada, o próximo capítulo apresentará os passos que devem ser realizados para que a análise de impacto de um requisito de mudança seja estabelecida.
A metodologia de análise de impacto baseada na rastreabilidade por ontologias avalia cada requisito de mudança de software separadamente.
Esses requisitos são analisados no contexto de projetos de manutenção de um produto, sendo que devem ser referentes a alterações funcionais no software.
Por a aplicação da metodologia, os artefatos com maior probabilidade de serem afetados por a mudança são identificados.
A metodologia de análise de impacto de mudanças baseada na rastreabilidade por ontologias é composta por quatro passos:
Gerar a ontologia do requisito de mudança, identificar os conceitos da ontologia de mudança na ontologia do sistema, rastrear os artefatos impactados e listar, ordenados decrescentemente, os artefatos impactados.
A figura 33 mostra graficamente como esses passos são encadeados.
Listagem ordenada das probabilidades de impacto O primeiro passo para gerar a ontologia do requisito de mudança é, a partir de um requisito de mudança, construir o modelo conceitual deste.
Essa construção deve ser feita utilizando o dicionário de dados do sistema, que é definido como &quot;um depósito central que descreve e define o significado de toda a informação usada na construção de um sistema», dado por Oliveira.
Este artefato tem como objetivo, uniformizar a nomenclatura dos termos que serão usados na modelagem do requisito de mudança.
Por exemplo, se no sistema é usado o termo &quot;docente», não deve ser usado na modelagem do requisito de mudança o termo &quot;professor».
A figura 34 mostra esse processo.
Após o modelo conceitual ter sido criado, pode- se gerar a ontologia referente a ele.
Sugere- se o uso da ferramenta ONTrace da mesma forma como a ontologia do sistema é construída.
A figura 35 apresenta esse passo.
A ontologia do requisito de mudança contém os conceitos existentes na ontologia do sistema, sendo um sub-conjunto deste.
A intersecção entre as ontologias é formada por os conceitos que são comuns as duas e que serão analisados para identificar o impacto da mudança.
Não é possível realizar a análise de impacto se os conjuntos forem disjuntos, pois nesse caso, não havendo nenhum conceito em comum, não há como realizar a rastreabilidade dos artefatos, o que impede a medição do impacto.
A próxima fase da metodologia é responsável por identificar os conceitos da ontologia do requisito de mudança na ontologia do sistema, que formam o conjunto comum às duas, representado na figura 36.
A segunda fase da metodologia é identificar, na ontologia do sistema, os conceitos que foram modelados no requisito de mudança.
Esse passo é necessário uma vez que a rastreabilidade entre conceito e artefato foi realizada na ontologia do sistema.
A figura 37 apresenta esse passo.
O processo de identificação deve ser realizado de forma a encontrar o tipo de mudança que está ocorrendo, explicitada na seção 3.6.
Eventualmente, alguns conceitos da ontologia do requisito de mudança não serão encontrados na ontologia do sistema, o que caracteri-za uma inclusão.
Em outros casos, podem- se encontrar conceitos que estão sendo alterados, e, também, conceitos que foram apenas modelados sem sofrer nenhum tipo de alteração.
Em a figura 38, tem- se a representação de um conceito do tipo dataTypeProperty sendo incluído, que é &quot;taxaGordura».
Os conceitos &quot;dataAvaliação «e &quot;FichaBiométrica», que estão destacados, foram identificados na ontologia do sistema.
A figura 39 apresenta um conceito que está sendo alterado.
Em a ontologia referente a o requisito de mudança, o range do conceito &quot;Meta», em destaque, é &quot;int».
Em a ontologia do sistema, esse mesmo conceito tem range &quot;string».
Os conceitos que são identificados na ontologia do sistema, mas que não sofrem alterações estruturais, tais como inclusão ou alteração de conceitos, podem ter alterações semânticas, ou seja, uma regra de negócio associada ao conceito pode ser alterada ou incluída.
Em esse caso, o responsável por fazer a análise da mudança deve indicar que o conceito é afetado dessa forma.
Em a figura 40, o conceito &quot;Cliente «foi identificado na ontologia do sistema, e este pode ser afetado ou não por uma regra de negócio constante no requisito de mudança.
A não existência de um conceito na ontologia do requisito de mudança, do tipo class ou dataTypeProperty, não caracteriza que esse conceito está sendo excluído da ontolo-gia do sistema.
Essa situação deverá ser tratada em trabalhos futuros por apresentar complexidade superior à inclusão ou alteração de conceitos.
Outra identificação que pode ser feita é quanto a os relacionamentos existentes entre conceitos.
Esses relacionamentos permitem encontrar artefatos em n-níveis.
O conceito da ontologia do sistema que mais sofreu mudanças, seja de inclusão de conceitos ou de alteração destes, será o ponto inicial de pesquisa, como visto no capítulo anterior.
A partir desse ponto, o conceito do tipo objectProperty relacionado a ele é encontrado e inicia- se então o percurso por o encadeamento de conceitos.
Um conceito do tipo objectProperty é responsável por relacionar outros dois conceitos do tipo class.
A figura 41 apresenta esse tipo de relacionamento, onde se pode determinar, como exemplo, que o conceito de partida seja o conceito &quot;Mensalidade», pois foi o mais afetado por mudanças.
Após a identificação dos conceitos na ontologia do sistema, os artefatos relacionados a este podem ser rastreados.
Os artefatos são rastreados conforme a relação e o tipo de mudança, e a esta é atribuída uma Influência da mudança (Im).
Esse tipo de relacionamento é usado para rastrear os artefatos em apenas um nível, ou seja, que estão ligados diretamente aos conceitos.
O cálculo do impacto deve ser realizado para cada um dos artefatos e é determinado por a fórmula 8.
A figura 42 abaixo mostra, genericamente, como é dada a relação entre um conceito extraído da ontologia do sistema e artefatos rastreados a partir de ele.
Em o exemplo, o conceito &quot;Mensalidade «foi identificado como existente na ontologia do sistema.
A esse conceito, foram ligados os artefatos do tipo caso de uso &quot;UC-GerarMensalidade «e do tipo classe &quot;CMensalidade».
Para realizar a rastreabilidade nesse tipo de relação, é importante distinguir se a alteração é referente a regras de negócio ou a relacionamentos, o que muda estruturalmente a ontologia.
Esses tipos de mudança têm influência alta, mas são diferenciados na maneira como o artefato é impactado, dependendo do tipo de diagrama da UML a que pertencem.
Além disso, as alterações estruturais podem ser identificadas automaticamente, pois há a inclusão de um novo conceito ou a alteração de algum já existente.
Independe se o requisito de mudança afeta estruturalmente ou semanticamente a ontologia, os tipos de conceitos que se relacionam diretamente a artefatos são os do tipo dataTypeProperty e do tipo class.
Pode- se estabelecer então, a relação dataTypePropertyArtefato e class-Artefato.
Ambas serão detalhadas a seguir.
Em esse caso, os artefatos são relacionados diretamente ao conceito do tipo dataTypeProperty.
Podem ser rastreadas as alterações semânticas e estruturais.
Essa última ocorre quando há mudança do tipo de range do conceito.
A figura 43 mostra essa rastreabilidade.
Em ela, a Influência da mudança (Im) está classificada como alta conforme explicação constante na seção 3.6.
O artefato &quot;CFichaBiométrica «ligado ao conceito &quot;Meta», teve a Influência do conceito no artefato (Ic) determinada como sendo forte.
Uma vez que uma classe pertence ao diagrama de classes e, a Influência do tipo de diagrama (Id) foi dada como estática.
Seguindo o exemplo, o Impacto no artefato por a mudança (Iam (x, y) no artefato pode ser calculado como mostra a figura 44.
Os valores dos elementos do conjunto representacional de Id são dados conforme o tipo de mudança, se de regra de negócio ou de relacionamentos na ontologia, sendo, nesse exemplo, o segundo.
Os artefatos são diretamente ligados a um conceito do tipo class.
Assim como ocorre na relação dataTypeProperty-- Artefato, mudanças semânticas ou estruturais podem ser identificadas.
Essa última ocorre quando um novo conceito do tipo dataTypeProperty é associado a um conceito do tipo class.
É necessário diferenciar os conceitos que estão sendo afetados por o requisito de mudança, estruturalmente ou semanticamente, dos conceitos que foram identificados na ontologia do sistema, mas que não sofrem nenhuma alteração.
Em o primeiro caso, a influência por o tipo de mudança é alta e no segundo é baixa.
Mesmo que Influência da mudança (Im) seja baixa, é interessante rastrear os artefatos relacionados a este conceito, uma vez que ele apareceu no requisito de mudança.
Através da análise da variável Iam (x, y), será possível determinar a probabilidade de impacto no artefato.
A figura 45 representa a inclusão de um conceito, classificada como alteração estrutural, cuja Influência da mudança (Im) é tida como alta.
Os conceitos que estão destacados são os conceitos que foram identificados no passo anterior, de identificação de conceitos.
Em o exemplo, o conceito &quot;dataAvaliação «está sendo associado ao conceito &quot;FichaBiométrica».
Esse último, por sua vez, está associado a artefatos, com sua Influência do conceito no artefato (Ic) sendo determinada para cada um de eles.
É também identificado individualmente o tipo de diagrama a que o artefato pertence, utilizando a tabela VI, e estabelecendo a Influência do tipo de diagrama (Id).
AtividadeB AtividadeC O impacto é calculado para cada artefato que for rastreado.
A figura 46 mostra o cálculo da variável impacto para o artefato &quot;UC-ManterFicha».
Os valores dos elementos dos conjuntos Im e Ic são os mesmos da figura 44.
Quando existir alteração semântica, essa deve ser indicada.
A partir de então, os artefatos relacionados ao conceito podem ser analisados quanto a o impacto da mudança.
A figura 47 mostra um exemplo quando o conceito &quot;Mensalidade «está relacionado a alterações em regras de negócio.
Para realizar o cálculo desse tipo de mudança, os conjuntos de valores de Im e Ic são iguais aos apresentados na figura 44.
Especificamente nesse caso, os valores dos elementos do conjunto do tipo de diagrama são diferentes.
A figura 48 mostra o cálculo do artefato do tipo caso de uso &quot;UC-GerarMensalidade».
A figura 49 destaca um conceito presente na ontologia de requisito de mudança e que foi identificado na ontologia do sistema, mas que não sofre alterações estruturais ou se- mânticas.
Apesar disso, o impacto nos artefatos pode ser avaliado, embora se considere que existe uma baixa probabilidade de serem afetados.
O cálculo das probabilidades de impacto nos artefatos ligados no conceito &quot;Cliente «é demonstrado na figura 50, referente a o artefato &quot;C-Cliente».
Consideram- se os valores dos elementos do conjunto de influência do tipo de diagrama como se a alteração fosse de regra de negócio.
Isso porque se infere que, se a mudança fosse estrutural, essa seria identificada ao comparar a ontologia do requisito de mudança e a ontologia do sistema.
Os valores dos elementos dos conjuntos Im, Ic e Id são os mesmos da figura 48.
Associado ao conceito do tipo objectProperty, tem- se a Influência do relacionamento (Ir), determinada por um algoritmo de stemming, conforme apresentado na seção caso, de rastrear as mudanças semânticas ou estruturais a que o conceito foi submetido e sim a propagação do impacto nos conceitos.
A figura 51 apresenta os artefatos que são encontrados num rastreamento de dois níveis e a relação entre os conceitos.
Considerando- se que no enésimo nível de busca na ontologia todos os artefatos do sistema serão rastreados, pois isso implica num percurso completo no grafo da ontologia, deve- se estabelecer um nível máximo de busca de conceitos nesta.
A fórmula 9 calcula a Propagação do impacto (Pi).
A partir de o resultado dessa propagação, devem ser rastreados todos os artefatos que estão relacionados a conceitos do tipo class e que estiverem relacionados por conceitos do tipo objectProperty, respeitando o critério de parada.
A figura 52 apresenta uma relação conceito-conceito.
O primeiro passo para analisar o impacto que se propaga entre os conceitos é determinar qual de eles foi afetado com maior número de mudanças, ou seja, Impacto Acumulado (Ia (x)), dado por a fórmula 10.
Os conceitos que serão analisados para ter essa variável calculada serão todos aqueles que foram identificados na ontologia do sistema a partir de a ontologia do requisito de mudança.
A figura 53 estabelece os valores do Impacto em o artefato por a mudança (Iam (x, y), para os conceitos e calcula o Ia (x), considerando as alterações analisadas anteriormente nas figuras 47 e 49.
O próximo passo é iniciar o caminhamento no grafo da ontologia a partir de o conceito &quot;Mensalidade «que teve maior Impacto acumulado (Ia (x)).
Em o exemplo da figura 52, onde é mostrada parcialmente uma ontologia, o único conceito que pode ser relacionado é &quot;Cliente».
Conforme determinado por o algoritmo de radicalização, a Influência do relacionamento (Ir) entre os dois conceitos é baixa.
Em esse exemplo, a Propagação do impacto (Pi) é igual a Ir, pois só existe um conceito do tipo objectProperty capaz de estabelecer relacionamentos entre dois outros conceitos.
Como a metodologia sugere que o critério de parada seja maior do que 70%, nesse caso não é indicado que se rastreie os artefatos do conceito &quot;Cliente», já que Pi $= 0,5, ou seja, tem probabilidade de impacto de 50%, sendo menor do que o critério estabelecido.
O último passo da metodologia é fornecer a lista de artefatos que tem mais probabilidade de impacto.
Após ter sido calculado o impacto do artefato, seja por o tipo de mudança ou por o relacionamento entre conceitos, um valor é atribuído a cada um de eles.
Como mostrado na figura 51, um mesmo artefato pode estar relacionado a mais de um conceito, no exemplo, o caso de uso &quot;UC-GerarMensalidade».
Isso significa que durante o rastreamento, um mesmo artefato pode ter sido encontrado mais de uma vez e, conseqüentemente, ter o impacto calculado cada uma de elas.
Os impactos calculados para um mesmo artefato devem ser somados.
Após a soma dos valores de impacto dos artefatos que se repetiram, armazenada na variável Probabilidade acumulada (Pa (y)), onde y é o artefato, é calculado o Percentual de probabilidade de impacto (Ppi (y)) para cada um de eles.
O cálculo é dado por a fórmula 12, onde a porcentagem dos demais artefatos é normalizada a partir de o maior Pa (y).
A o final, é fornecido o conjunto ordenado de forma decrescente de Ppi (y) dos artefatos rastreados.
Pa (y) 100 Ppi (y) max (Pa (y)) Fórmula 12 ­ Cálculo do Percentual de probabilidade de impacto do artefato (Ppi (y)).
Para determinar os artefatos com a maior probabilidade de impacto, é calculada a média ponderada em relação a todos aqueles que foram rastreados.
Todos os artefatos que tiverem sua Probabilidade acumulada (Pa (y)) maior do que a média ponderada, irão formar o conjunto dos elementos que mais provavelmente serão alterados.
A fórmula 13 mostra como se calcula essa média, onde x é o número de artefatos que obtiveram a mesma Pa (y).
Pa y1.
X1 Pa y 2.
X=2  Pa y1 Pa y 2 Pa y 3.
X3 Pa y 3 (Pa yi xi) i 1 Pa yi i 1 Fórmula 13 ­ Cálculo da média ponderada.
Para auxiliar na aplicação da metodologia, foi proposta e desenvolvida uma ferramenta chamada ONTImpact.
Essa será descrita a seguir.
Com o objetivo de calcular automaticamente o impacto que os artefatos sofrem ao serem alterados por um requisito de mudança, uma ferramenta foi desenvolvida usando a tecnologia Java.
A esse aplicativo foi dado o nome de ONTImpact, que armazena as influências dos artefatos e conceitos, compara as ontologias do requisito de mudança e do sistema e calcula o impacto nos objetos rastreados.
Para armazenar as influências que o conceito exerce sobre o artefato e o tipo de diagrama ao qual este pertence, a ontologia do sistema gerada por a ferramenta ONTrace é carregada no ONTImpact.
Para que seja possível carregar os conceitos por tipos que os representam, é feita uma consulta no Jena.
A figura 54 mostra um exemplo dessa seleção.
Em uma janela, são apresentados os conceitos do tipo class e dataTypeProperty bem como os artefatos que foram ligados a eles.
A esses objetos, é possível associar a Influ-ência do conceito no artefato (Ic) e a Influência do tipo de diagrama (Id).
A primeira pode ser classificada em:
Fraca, moderada e forte e é armazenada ao conceito artifact da ontologia, utilizando a propriedade ontImpactConceptInfluence.
A segunda é escolhida entre estático, dinâmico e funcional, também relacionada ao conceito artifact e utilizando a propriedade ontImpactDiagramInfluence.
A figura 55 mostra essa interface.
Em uma segunda janela, são apresentados os conceitos do tipo objectProperty, juntamente com os conceitos do tipo class aos quais se relaciona A esses conceitos, é atribuída a Influência do relacionamento (Ir), calculada a partir de um algoritmo de radicalização que compara os conceitos ligados a ele com as propriedades range e domain.
Essa influência é então classificada em baixa ou alta e armazenada no conceito artifact na propriedade ontImpactRelationshipInfluence.
A figura 56 apresenta essa tela.
Após todas as influências terem sido atribuídas, faz- se necessário também, que o usuário do sistema informe se o conceito está tendo alguma regra de negócio associada a ele alterada.
A figura 57 mostra esse procedimento.
Somente os conceitos presentes na árvore de &quot;Tipo de Mudança «podem ter essa variável setada.
Essa informação é armazenada numa variável que será utilizada no último passo da metodologia e é essencial para que a análise de impacto seja realizada com precisão.
Para que se faça a comparação das ontologias, o código eXtensible Markup Language (XML) da ontologia do requisito de mudança é carregado na ferramenta e é comparado com o código XML da ontologia do sistema.
São então identificados os conceitos que são comuns as duas ontologias bem como os conceitos que estão sendo inseridos ou alterados.
A figura 58 mostra a comparação entre dois códigos XML e mostra os elementos comuns identificados.
Em o exemplo, pode- se notar que o conceito &quot;possuemGeradas», do tipo objectProperty, e os conceitos do tipo class &quot;Mensalidade «e &quot;Cliente «são comum as duas ontologias.
A última tarefa da ferramenta é realizar a análise de impacto, calculando a probabilidade de cada um dos artefatos relacionados aos conceitos serem impactados.
Para isso, o usuário deve escolher entre analisar o impacto verificando as mudanças estruturais ou semânticas identificadas na ontologia ou percorrendo ela por o relacionamento entre os conceitos.
A figura 59 mostra o atalho para esse procedimento.
Com base nos valores dos elementos dos conjuntos de influência, são calculados o Impacto em o artefato por a mudança (Iam (x, y) ou o Impacto do Artefato por o Relacionamento (Iar (x, y), dependendo do tipo de análise de impacto escolhida.
A o final, é apresentada uma tabela com todos os artefatos rastreados e a probabilidade de impacto para cada um de eles.
O exemplo de aplicação da metodologia será apresentado utilizando o projeto IsGym, de controle de uma academia de ginástica, desenvolvido numa disciplina do curso de graduação em Sistemas de Informação da Faculdade de Informática da Pontifícia Universidade Católica do Rio Grande do Sul.
Esse mesmo projeto foi aplicado num experimento inicial dessa metodologia, que está descrito no Apêndice A, e serviu como insumo das hipóteses identificadas.
O sistema IsGym foi escolhido pois possui algumas premissas básicas necessárias para o desenvolvimento desse trabalho.
De entre elas está o fato de seus autores não estarem relacionados a esse estudo, ou seja, o projeto foi construído sem que seus dados fossem direcionados a resultados específicos para serem utilizados na rastreabilidade e análise de impacto.
Além disso, ele foi completamente modelado seguindo o processo unificado, facilitando a abordagem aqui proposta, e teve uma implementação consistente.
O sistema IsGym foi desenvolvido com a finalidade de integrar todas as funcionalidades administrativas de uma academia num único sistema de informação.
Ele mantém cadastros de clientes, funcionários, fornecedores, recursos e utilização destes, assim como as fichas de acompanhamento das avaliações (biometria) e atividades dos alunos.
Foi utilizada a tecnologia JavaServer Pages (JSP) com conexão ao banco de dados MS-Access para desenvolver- lo e a modelagem de requisitos e funcionalidades foi feita no Rational Rose.
Abaixo estão relacionados o dicionário de dados do sistema, o modelo conceitual construído baseado no requisito de mudança e a ontologia gerada a partir deste.
O requisito de mudança, presente na figura 60, foi escolhido por incluir novos conceitos na ontologia original do sistema e alterar uma regra de negócio associada a um conceito previamente existente.
Em ele estão destacados os conceitos que são relevantes para analisar o problema.
Com o intuito de aumentar o número de freqüentadores da academia, a GymJoe decidiu dar desconto para os alunos que atingirem suas metas de treinamento.
É feita uma avaliação inicial do aluno.
Após o resultado dessa, o aluno informa qual o percentual de taxa de gordura que deseja atingir nos próximos 6 meses, sendo essa a sua meta.
A o final desse período, uma nova avaliação é realizada e o instrutor verifica se o aluno atingiu seu objetivo.
Os descontos são dados seguindo os critérios:
Os conceitos presentes no requisito de mudança devem ser verificados no dicionário de dados do sistema para garantir a uniformidade entre as nomenclaturas.
Em a figura 61 estão reproduzidos os trechos importantes para esse exemplo.
Nome: Cliente;
Tipo: Classe;
Descrição: Descreve os dados cadastrais do cliente da academia;
Pseudônimos: Aluno;
Especificação: Comentários:
A classe está presente no modelo de domínio e no diagrama de classes.
Nome: FichaBiometrica;
Tipo: Classe;
Descrição: Descreve os dados da avaliação do cliente;
Pseudônimos: Avaliação;
Especificação: Comentários:
A classe está presente no modelo de domínio e no diagrama de classes.
Nome: Mensalidade;
Tipo: Classe;
Descrição: Possui atributos necessários para gerar a mensalidade;
Pseudônimos: Fatura, boleto bancário;
Especificação: Comentários:
A classe está presente no modelo de domínio e no diagrama de classes.
Nome: Funcionário;
Tipo: Classe;
Descrição: Descreve os dados cadastrais dos funcionários;
Pseudônimos: Professor, instrutor;
Especificação: Comentários:
A classe está presente no modelo de domínio e no diagrama de classes.
Nome: Meta;
Tipo: Atributo da classe FichaBiometrica;
Descrição: Descreve o objetivo do cliente freqüentar a academia;
Pseudônimos: Objetivo;
Comentários: A classe FichaBiometrica está presente no modelo de domínio e no diagrama de classes.
Nome: TaxaDeGordura;
Tipo: Atributo da classe FichaBiometrica;
Descrição: O percentual de gordura do cliente quando avaliado;
Pseudônimos: Índice de gordura;
Comentários: A classe FichaBiometrica está presente no modelo de domínio e no diagrama de classes.
Após a verificação dos termos, o modelo conceitual do requisito de mudança pode ser construído.
Em a figura 62 está o modelo conceitual que representa o requisito de mudança.
De posse do modelo conceitual, é possível gerar a ontologia do requisito de mudança através da ferramenta ONTrace.
Esta gera um código em XML, apresentado na figura 63, que é importante para identificação dos conceitos por a ferramenta que realiza a análise de impacto.
A ontologia graficamente é representada por a figura 64.
Com a ontologia gerada, pode- se passar para o próximo passo, que é de identificação dos conceitos na ontologia do sistema.
A comparação entre as ontologias do sistema é feita automaticamente a partir de as representações XML da ontologia do requisito de mudança e da ontologia do sistema.
A figura 65 representa graficamente os conceitos que são identificados na ontologia do sistema.
Esta está representada parcialmente, apenas os conceitos do tipo class são identificados e os demais conceitos associados a este estão sendo mostrados.
Foram identificadas três solicitações de alteração estrutural.
Uma de alteração de um dataTypeProperty e duas de inclusão de dataTypeProperty.
A primeira é a alteração do tipo do conceito &quot;meta «ligado ao conceito &quot;FichaBiométrica».
A figura 66 mostra essa alteração.
A segunda é a inclusão do conceito &quot;dataAvaliação «relacionado ao conceito &quot;FichaBiometrica «e do conceito &quot;desconto «ligado ao conceito &quot;Mensalidade».
As figuras 67 e 68, respectivamente, apresentam essas mudanças.
Houve também uma alteração de regra de negócio associada ao conceito &quot;Mensalidade», pois a forma de calcular a mensalidade foi alterada.
Em esse caso, deve ser atribuída ao conceito a informação de que existe essa alteração, uma vez que não há como identificar- la por a comparação das ontologias.
A figura 69 mostra a identificação dessa alteração.
Os artefatos que foram rastreados para cada um dos conceitos identificados foram baseados na rastreabilidade feita por um especialista na ferramenta ONTrace.
Primeiramente, serão rastreados e terão o impacto analisado os artefatos ligados a conceitos que sofreram alterações estruturais.
Em seguida o mesmo ocorrerá para os que tiveram alteração de regra de negócio.
Esses conceitos foram descritos na seção anterior.
Por último, os conceitos que foram identificados, mas que não estão relacionados a nenhum desses dois tipos de mudança, serão analisados.
Será considerado, para esse projeto, que o conjunto utilizado para classificar os Os artefatos rastreados para o tipo de mudança de alteração do conceito do tipo dataTypeProperty é dado por a figura 70.
Em a figura 71 é calculado o impacto do artefato, através da fórmula 8.
Para esse mesmo conceito, existem mudanças na regra de negócio associada a ele.
Os artefatos rastreados são os mesmos da figura 74, embora o cálculo do impacto seja diferente, pois os valores da variável Id mudam em decorrência do tipo de mudança.
Em a figura 76 é calculado o impacto do artefato, através da fórmula 8.
Os artefatos que foram identificados na ontologia do sistema a partir de a ontologia do requisito de mudança, mas que não sofrem nenhum tipo de alteração, seja estrutural ou semântica, também são calculados.
A finalidade é identificar a probabilidade de impacto, mesmo que pequena, dos artefatos que estão relacionados a esses conceitos.
Outra motivação é que um artefato pode ser encontrado novamente e então ter seus impactos somados.
A figura 77 mostra os artefatos relacionados ao conceito &quot;Cliente».
Em a figura 78 é calculado o impacto do artefato, através da fórmula 8.
A figura 79 mostra os artefatos relacionados ao conceito &quot;Funcionário».
Em a figura 80 é calculado o impacto do artefato, através da fórmula 8.
O último passo é somar os valores obtidos ao calcular o impacto de cada artefato rastreado listar- los em ordem decrescente.
A tabela VII mostra a probabilidade de impacto.
Em a tabela VII foram destacados os artefatos que tem maior probabilidade de impacto.
Esse conjunto de artefatos com maior probabilidade de impacto é formado por aqueles que tiverem a Probabilidade acumulada (Pa (y)) maior do que a média ponderada calculada para todos os elementos rastreados.
A figura 81 apresenta sua aplicação nesse exemplo.
Nota- se que a classe &quot;FichaBiométrica», que atingiu o maior impacto acumulado foi considerada como o artefato que com certeza seria impactado, isto é, probabilidade de 100%.
A probabilidade dos demais artefatos foi calculada dentro de essa escala.
Os resultados aqui apresentados podem ser verificados no experimento constante no Apêndice A, onde se comprova que os objetos mais atingidos estão entre os identificados por a metodologia de análise de impacto baseada em ontologia.
Para o sistema IsGym, não é possível aplicar a influência do relacionamento entre conceitos, pois com o uso do algoritmo de radicalização, todos os relacionamentos entre conceitos são baixos.
Em esse quesito, o sistema deveria ter sido desenvolvido com maior preocupação na denominação dos conceitos.
Esse capítulo apresenta a validação da proposta de metodologia de análise de impacto baseada na rastreabilidade ontológica.
Para realizar- la, foi utilizada a Engenharia de Software Experimental.
Igualmente ao primeiro experimento realizado, que auxiliou na definição dessa proposta, o sistema de software utilizado no experimento de validação da metodologia é o IsGym.
Este é amplamente apresentado no Apêndice A. Foram utilizados também os mesmos requisitos de mudança usados no primeiro experimento, mostrados nas figuras 98 e 99.
Isso foi possível, pois os participantes de um e outro experimento são diferentes.
É importante destacar que esse experimento, no que diz respeito ao sistema de software utilizado, bem como alguns pontos do planejamento e seleção de participantes foi feito em conjunto ao experimento de validação da proposta de rastreabilidade ontológica.
Sendo assim, algumas características de ambos os experimentos serão as mesmas ou semelhantes.
A seguir, serão apresentados os passos necessários para se construir e validar um experimento, como consta no referencial teórico desse trabalho.
Para estabelecer os objetivos desse estudo, foi utilizada a técnica GQM proposta por Basili.
Em essa etapa, é necessário apresentar as questões que serão avaliadas e as métricas que serão utilizadas para medir- las.
Avaliar a precisão da análise de impacto baseada na rastreabilidade indexada por conceitos da ontologia com relação a a proposta de análise de impacto baseada na rastreabilidade indexada por requisitos.
Comparar a metodologia de análise de impacto baseada em rastreabilidade indexada por conceitos e por requisitos, Com o propósito de caracterizar, com base em um requisito de mudança, a de probabilidade de alteração de artefatos e o conjunto de artefatos realmente modificados, Com foco na precisão, Sob o ponto de vista do analista de software, Em o contexto de manutenção de um sistema de informação no domínio de academia desportiva, desenvolvido por estudantes durante uma disciplina da Faculdade de Informática da PUCRS.&amp;&amp;&amp;
Qual a precisão, indicada por a intersecção entre o conjunto de artefatos previstos para alteração e os realmente alterados, das abordagens de análise de impacto baseada em ontologias e baseada em requisitos.
A precisão do conjunto dos artefatos com maior probabilidade de impacto encontrada através da análise de impacto baseada na rastreabilidade através de requisitos é igual a precisão do conjunto dos artefatos com maior probabilidade de impacto encontrada através da análise de impacto baseada na rastreabilidade ontológica?
A métrica utilizada para responder a questão estabelecida corresponde à precisão de cada uma das abordagens, com relação a a completude e corretude das previsões de alteração de artefatos em relação a os artefatos que foram realmente modificados.
Por precisão, nesse experimento, considera- se a razão entre o conjunto de artefatos previstos e modificados e o conjunto total de artefatos previstos e modificados.
O conjunto de artefatos previstos e modificados é composto por o conjunto dos artefatos com maior probabilidade de impacto, estabelecidos através da aplicação de cada uma das metodologias de análise de impacto, interseccionados com o conjunto dos artefatos realmente modificados.
O conjunto total de artefatos previstos ou modificados é composto por de todos os artefatos que tiveram previsão de impacto, e por todos os artefatos que foram realmente modificados.
O cálculo da precisão está representado na fórmula 14.
Fórmula 14 ­ Cálculo da variável Precisão.
Onde: M:
Conjunto de artefatos modificados;
Pb: Conjunto de artefatos previstos por determinada metodologia de análise de impacto;
O projeto do experimento é determinado, a instrumentação é considerada e os aspectos da validade do experimento são avaliados.
Realiza- se a seleção do contexto, formulamse as hipóteses, selecionam- se as variáveis e os participantes, projeta- se o experimento, realiza- se a preparação conceitual da instrumentação e considera- se a validade do experimento.
Para a condução do experimento de análise de impacto, foi escolhido o contexto de uma universidade e não de um ambiente realista, pois esse é mais arriscado e envolve custos não previstos nesse experimento.
Também fazem parte do contexto:
A) Processo:
Será utilizada à abordagem In-vitro, em a qual o conjunto de participantes executará o experimento num ambiente controlado.
Este experimento não se dará durante o desenvolvimento de software industrial, isto é, ele será off-line;
B) Participantes:
O experimento será conduzido por alunos de graduação e pósgraduação da Faculdade de Informática da PUCRS;
C) Realidade:
O problema estudado será de sala de aula (toy example) e corresponde a um sistema modelado e desenvolvido por alunos da graduação, durante uma disciplina da Faculdade de Informática da PUCRS, no domínio de uma academia desportiva.
O objetivo desta escolha é a utilização de um sistema que se aproxime do real e que foi desenvolvido sem a intervenção do pesquisador;
D) Generalidade:
O experimento é específico e com validade apenas no escopo do presente estudo.
Para o experimento, foi definida informalmente a hipótese:
Sugere- se que a análise de impacto baseada na rastreabilidade por requisitos prevê o mesmo conjunto de artefatos que a análise de impacto baseada por conceitos de uma ontologia, com relação a o conjunto realmente modificado.
A formalização das hipóteses e a definição de suas medidas se dão por:
Hipótese Nula, H0:
A precisão na previsão de artefatos impactados por uma mudança obtidos por a análise de impacto baseada na rastreabilidade por requisitos é igual a análise de impacto baseada na rastreabilidade por conceitos da ontologia.
H1: Pair\&gt; Paic d..
Hipótese Alternativa, H2:
A precisão na previsão dos artefatos obtidos por a análise de impacto baseada na rastreabilidade por conceitos da ontologia é maior do que a da análise de impacto baseada na rastreabilidade por requisitos.
H2: Paic\&gt; Pair As variáveis independentes servem como entrada para o experimento, enquanto as dependentes se referem à saída.
Assumiram- se como variáveis independentes:
A) Experiência do time de manutenção;
B) Metodologia de análise de impacto.
Assume- se como variável dependente:
A população definida para o experimento é formada por alunos do curso de graduação e pós-graduação da Faculdade de Informática da PUCRS, totalizando doze alunos.
Não será utilizada uma amostragem probabilística para seleção dos indivíduos, mas sim uma amostragem não probabilística:
A) Amostragem por conveniência:
Serão escolhidas as pessoas mais convenientes para o experimento.
Caracteriza a forma de condução do experimento, decidindo, por exemplo, a alocação dos participantes.
De entre os princípios genéricos para o projeto do experimento, caracteriza- se:
A) Aleatoriedade:
A aleatoriedade será utilizada para definir quais participantes irão executar cada metodologia de análise de impacto (baseada na rastreabilidade através de requisito ou conceito);
B) Obstrução:
Durante a experimentação, muitos dos participantes não possuem o mesmo nível de experiência acadêmica e profissional.
Para minimizar o efeito da experiência sobre o experimento, os indivíduos foram selecionados utilizando o critério de quota e conveniência;
C) Balanceamento:
Este princípio será utilizado no experimento para que cada proposta de análise de impacto seja executada por a mesma quantidade de participantes.
Para a hipótese que será validada, serão utilizadas as seguintes notações:
Air Análise de impacto baseada na rastreabilidade por requisitos;
Análise de impacto baseada na rastreabilidade por conceitos.
Esse experimento investiga se a precisão de air é igual a precisão de aic.
A abordagem conhecida como um fator com dois tratamentos.
Em esse caso, o fator refere- se ao time de manutenção, ou seja, aos participantes do experimento e os tratamentos são as metodologias de análise de impacto que estão sendo comparadas, a baseada em rastreabilidade por requisitos e por conceitos.
Optou- se por conduzir o projeto do experimento, no que diz respeito a execução desse, utilizando uma abordagem completamente aleatória para escolha de quais participantes iriam executar uma ou outra metodologia.
Essa decisão foi tomada, pois se cada participante fizesse uso das duas metodologias, os resultados quando a segunda metodologia fosse utilizada seriam prejudicados, uma vez que a pessoa já teria um conhecimento prévio do sistema e do requisito de mudança que estaria sendo proposto.
A tabela VIII, chamada de tabela de contingência, mostra com os fatores (participantes) foram divididos para executar os dois tratamentos (metodologias).
Para verificar a hipótese, alguns testes de significância são sugeridos na literatura.
O Teste T é usado para realizar um teste paramétrico com duas amostras independentes.
Já o teste Mann--Whitney é usado caso o teste seja não-paramétrico.
Dependendo da normalidade e variância dos dados obtidos na execução, será escolhido um ou outro teste.
Para realizar o experimento, será utilizado:
A) Objetos:
A descrição do sistema de informação IsGym, sua modelagem UML do diagrama de classes de projeto, a descrição dos casos de uso e o Modelo de Domínio, além de dois requisitos de mudança.
Para auxiliar na análise de impacto, será fornecida para cada abordagem uma planilha onde deverão se determinadas as variáveis usadas para calcular o conjunto de artefatos com maior probabilidade de impacto para cada metodologia, e serem informados os artefatos que foram modificados;
B) Guias:
Será fornecido um treinamento para os participantes, apresentando as duas metodologias de análise de impacto, o contexto do experimento e a motivação da equipe.
Também será fornecido um tutorial sobre como proceder durante o experimento;
C) Métricas:
Os dados serão recuperados através da planilha preenchida por os participantes e das alterações feitas diretamente no diagrama de classes do sistema, utilizando para isso a ferramenta ArgoUML.
Os resultados devem ser válidos para a população a qual os participantes fazem parte.
São definidas as validades interna, externa, construção e conclusão.
Serão avaliados alguns critérios, tais como:
A) Histórico:
A data de aplicação do experimento será criteriosamente definida, evitando períodos em os quais os participantes possam sofrer influências externas;
B) Maturação:
Durante o treinamento, serão utilizadas técnicas de motivação para incentivar positivamente os participantes;
C) Seleção dos grupos:
Será utilizada uma abordagem para nivelar o conhecimento dos participantes através de um treinamento sobre as metodologias.
A execução das atividades será individual;
D) Difusão:
Durante o treinamento, será desenvolvida uma motivação que não incentive interação entre os participantes.
Adicionalmente, haverá um policiamento durante a experimentação para evitar este tipo de interação.
Para esta avaliação, será adotada a interação da seleção, ou seja, os participantes que foram selecionados possuem um perfil apto aos tratamentos do experimento, apresentando, em sua maioria, conhecimento prévio sobre processo de desenvolvimento de software e modelagem de sistemas, além de experiência em indústria.
Durante o experimento, serão avaliados:
A) Inadequada explicação pré-operacional:
Consiste na explicação operacional do experimento, visando mostrar como a metodologia é aplicada;
B) Adivinhação de hipóteses:
Devido a o fato dos participantes serem humanos, é possível sua interação com o experimento, sugerindo novas hipóteses e exercitando a criatividade.
É importante manter o foco no estudo planejado;
C) Expectativas do condutor do experimento:
A o se conduzir um experimento, o responsável pode exercer influências sobre as variáveis envolvidas e sobre o material elaborado.
Durante a presente proposta, todo o material utilizado será previamente avaliado por outro responsável.
A validade de conclusão segue as perspectivas:
A) Manipulação dos dados:
Como os dados resultantes do experimento serão manipulados por o pesquisador, é possível que os mesmos sofram algumas variações, tal como o coeficiente de significância para validação dos resultados;
B) Confiabilidade das medidas:
Sugere que medidas subjetivas possam ser influenciadas por o pesquisador.
Essa perspectiva será minimizada já que as medidas foram definidas sem dependência do critério humano;
C) Confiabilidade na implementação dos tratamentos:
Consiste no risco em que diferentes participantes possam implementar de forma distinta os processos estabelecidos por o experimento.
Este risco não será evitado, uma vez que a determinação das variáveis das metodologias de análise de impacto comparadas é subjetiva e dependente da interpretação de cada participante no experimento, assim como a modelagem de cada requisito de mudança propostos.
Com isso, os participantes poderão prever e modificar artefatos diferentes;
D) Configurações do ambiente do experimento:
Consiste nas interferências externas do ambiente que podem influenciar os resultados durante a execução do experimento.
O experimento será executado num laboratório isolado, onde será proibida a interação externa como celulares, saídas, etc.;
E) Heterogeneidade aleatória dos participantes:
A escolha de diferentes participantes com diferentes experiências pode exercer um risco na variação dos resultados.
Os dados são coletados e é feita a validação preliminar destes.
Foram analisadas algumas características intrínsecas à execução:
A) Consenso com o experimento:
Se os participantes não concordam com os objetivos da pesquisa ou não tem conhecimento sobre o experimento, corre- se o risco de que sua participação não ocorra em encontro aos objetivos.
Durante a experimentação, a preparação dos participantes deverá fornecer o embasamento necessário sobre o experimento, clarificando quais os objetivos e metas almejadas;
B) Resultados sensitivos:
É possível que o resultado obtido por o experimento se influencie por questões pessoais, como a sensibilidade dos participantes por estarem sendo avaliados.
Será adotada uma postura de anonimato dos participantes em toda a descrição da experimentação.
O primeiro passo para execução do experimento foi a apresentação de um treinamento específico para cada grupo, demonstrando cada uma das metodologias de análise de impacto.
Em esse mesmo momento, foram explanados os objetivos, a técnica, a motivação e o procedimento técnico para condução do experimento.
Após, os participantes receberam a instrumentação prevista, fazendo parte dessa um tutorial contendo o passo-a-passo para a execução das atividades.
Os participantes do experimento foram responsáveis por a coleta dos dados, preenchendo a planilha que foi disponibilizada.
Todo esse material está presente no Apêndice A execução do experimento para cada metodologia foi feita em turnos diferentes, sem tempo determinado para o término das atividades.
O pesquisador esteve presente durante toda a duração do experimento a fim de para conduzir- lo, ficando a disposição para esclarecimento de eventuais dúvidas, embora sem interferência nos dados que estavam sendo coletados.
Em ambas as metodologias, a base é a rastreabilidade dos artefatos, seja através de casos de uso ou de conceitos da ontologia.
De essa forma, para cada uma de elas foi fornecido o gabarito da rastreabilidade, ou seja, para a metodologia de análise de impacto baseada na rastreabilidade por requisitos, foram disponibilizadas todas as classes que se associam a um caso de uso.
Para a metodologia de análise de impacto baseada na rastreabilidade por conceitos, foram fornecidas as classes indexadas por conceitos.
A partir de essas informações e, após o entendimento do requisito de mudança proposto, os participantes foram capazes de identificar a qual caso de uso ou conceito o requisito de mudança se referia.
Após foi possível determinar os valores das variáveis necessárias para cada metodologia, obtendo assim o conjunto de artefatos com maior probabilidade de impacto.
O último passo era realizar efetivamente a manutenção no diagrama de classes.
Primeiramente devem ser analisadas as escalas das variáveis, a fim de determinar às operações que podem ser realizas em cada uma de elas.
A tabela IX apresenta essas escalas.
O experimento obteve como resultado os dados apresentados na tabela X, onde os participantes que realizaram a metodologia de análise de impacto baseada em ontologia foram representados por &quot;C0x «e o que utilizaram a metodologia baseada em requisitos foram classificados por &quot;R0x».
Para cada requisito de mudança proposto e alterado por o participante foi calculada a Precisão, através da fórmula 14.
O valor apresentado na tabela X corresponde a média da Precisão obtida por cada participante, em relação a os requisitos de mudanças propostos.
A variável precisão está caracterizada na escala razão.
Isso permite o cálculo da normalidade e homocedasticidade, necessária para definir o tipo de teste das hipóteses (paramétrico ou não-paramétrico).
Conforme definido no projeto do experimento, o padrão para tipo de teste previsto é o Teste T para duas amostras independentes, caso o teste empregado seja paramétrico, ou Mann--Whitney, caso seja não paramétrico.
Para avaliar a precisão, os dados tabulados durante o experimento serão caracterizados com o objetivo de visualizar tendências centrais e dispersões.
Os dados que forem determinados como anormais ou incertos devem ser eliminados através da redução do intervalo de dados, pois esses distorcem a integridade da conclusão do experimento.
Por último, será realizado o teste das hipóteses que compreende a avaliação estatística dos dados até certo nível de significância.
O nível de significância adotado (p- value) para todos os testes é de 5%.
O p- value compreende o menor nível de significância com que se pode rejeitar a hipótese nula.
Para iniciar a validação da hipótese, é verificada a distribuição dos dados coletados.
Para isso, é gerado o gráfico de dispersão boxplot para a identificação dos outliers.
A figura 84 apresenta o gráfico.
Como verificado na figura 84, a variável precisão possui outliers moderados, sendo assim, nenhum participante será extraído da amostra, já que não há risco de haver distorção.
Pode- se notar no gráfico, previamente, que a dispersão é maior quando utilizada a análise de impacto baseada na rastreabilidade por conceitos, embora a mediana da variável precisão esteja perto de 100%.
Os resultados para a análise de impacto baseada na rastreabilidade por requisitos são mais uniformes, mas menos precisos.
A próxima etapa consiste em identificar se os dados seguem uma distribuição normal.
Para se avaliar a normalidade, é definida uma hipótese nula e uma hipótese alternativa, conforme:
A) H0:
A distribuição é normal;
B) H1:
A distribuição não é normal.
Existem duas formas para se avaliar a distribuição normal dos dados, que compreendem o Teste de Kolmogorov--Smirnov e o Teste de Shapiro-Wilk.
O primeiro é utilizado para identificar a normalidade em variáveis com pelo menos 30 valores e o segundo em variáveis com menos de 50 valores.
A tabela XI apresenta os testes de normalidades para a amostra utilizando o Teste de Shapiro-Wilk.
Com base na tabela XI, observa- se que a significância dos dados do Teste de Shapiro-Wilk é superior, em ambas as amostras (análise de impacto baseada na rastreabilidade por conceito e análise de impacto baseada na rastreabilidade por conceito), ao nível de significância definido (0,05 ou 5%).
Com esta informação, não há indícios para rejeitar a hipótese nula sobre a distribuição da normalidade, conseguindo assim o primeiro requisito para utilização de teste paramétrico para duas amostras independentes.
O segundo requisito requer a análise da homocedasticidade, tornando necessário analisar a variância das duas amostras.
Com este objetivo, definem- se duas hipóteses:
A) H0:
As variâncias são iguais;
B) H1:
As variâncias não são iguais.
Com base na tabela XII, verifica- se que o nível de significância para variâncias iguais é inferior ao nível de significância definido.
Com esta informação, pode- se rejeitar a hipótese nula para variâncias, não sendo mais possível utilizar o teste paramétrico.
O próximo passo é utilizar o Teste de Mann--Whitney, para duas amostras independentes, por se tratar de uma alternativa não-paramétrica para o Teste T. O Teste de Mann--Whitney para duas amostras independentes é utilizado para comprovar se as diferenças entre as médias observadas nos dois grupos independentes são estatisticamente significativas.
Com base na declaração das hipóteses, sugere- se:
Como o grau de significação associado (Sig.
Assimpt.) é 0,019 e é menor que a significância assumida de 0,05, deve- se rejeitar H0.
Com a rejeição desta, comprova- se a hipótese H1, que afirma que há diferença entre as médias, ou seja, existe diferença de média entre a análise de impacto baseada na rastreabilidade por conceitos e na análise de impacto baseada na rastreabilidade por requisitos.
Por a análise estatística dos dados, consegue- se recuperar duas informações:
A) A distribuição da precisão não é normal, o que implica na execução de testes não paramétricos;
B) Utilizando o Teste de Mann--Whitney, conseguiu- se verificar que existem diferenças entre as médias das duas amostras air e aic.
Utilizando o Teste de Mann--Whitney, conseguiu- se apenas rejeitar a hipótese nula, porém não foi possível validar as hipóteses alternativas, pois não é possível extrair relações de &quot;maior do que «com o teste aplicado.
Porém, sugere- se comparar a análise descritiva das médias da amostra, conforme a tabela XIV.
Observando as médias da variável precisão para cada uma das metodologias, pode- se verificar que, em média, a precisão da análise de impacto por conceitos é maior do que a precisão da análise de impacto por requisitos.
Através do experimento foi possível avaliar quantitativamente as metodologias de análise de impacto.
Para realizar a análise qualitativa, os participantes responderam um questionário ao término de suas atividades, conforme apresentado ao final desse apêndice.
Como critério de resposta, foi utilizada a escala Likert que possui cinco pontos para o grau de satisfação, O objetivo de usar essa pesquisa de opinião era conhecer a percepção dos participantes quanto a usabilidade, utilidade e esforço para usar as diferentes metodologias.
As cinco questões propostas podem ser verificadas no Apêndice B. Os dados brutos obtidos como resultados estão apresentados na tabela XV, onde o participante identificado como &quot;R0x «é referente a abordagem de análise de impacto baseada na rastreabilidade por requisitos e o participante &quot;C0x «é referente a abordagem ontológica.
Análise de Impacto por Requisitos 3,0 3,0 3,0 2,5 Análise de Impacto por Conceitos 4,0 4,5 3,3 3,7 4,2 Comparando- se as médias obtidas para cada uma das abordagens, pode- se perceber que as médias obtidas por a metodologia de análise de impacto baseada na rastreabilidade por conceitos foi maior para todas as questões.
Verifica- se então que qualitativamente essa metodologia é melhor do que a metodologia de análise de impacto por requisitos, para esse conjunto de participantes.
Em este capítulo foram apresentadas as avaliações quantitativas, através do uso da Engenharia de Software Experimental, e qualitativa, através de uma pesquisa de opinião.
A intenção era comparar as metodologias de análise de impacto baseada por conceitos e por requisitos, sendo esta última proposta por O'Neal.
O experimento fez uso da rastreabilidade ontológica, que está inserida dentro de um processo de desenvolvimento específico, o que não possibilita que essa experimentação seja generalizável a outros processos.
Quanto a o contexto, foi analisado o impacto dos requisitos de mudança somente nas classes de projetos e as modificações foram solicitadas apenas no diagrama de classes.
Decidiu- se restringir o experimento por questões de tempo para execução e escolheu- se esse artefato por representar as alterações estruturais no sistema.
Com os dados fornecidos por os participantes, foi possível avaliar a variável precisão, a partir de a qual seria feita a comparação das metodologias.
Com a análise inicial da variável, percebeu- se que essa não apresentou uma distribuição normal das suas médias.
Por esse motivo, usou- se o teste Mann--Whitney para avaliar as hipóteses.
Esse teste comprova se as diferenças entre as médias observadas em dois grupos independentes são estatisticamente significativas, mas não estabelece se um grupo é superior ao outro.
Uma vez que a aplicação do teste comprovou que as médias eram diferentes, foi necessário utilizar a análise descritiva das médias de cada metodologia e comparar- las.
Assim, verificou- se que a metodologia de análise de impacto baseada na rastreabilidade por conceitos tem uma precisão maior na determinação do conjunto de artefatos que serão impactados.
A última fase da experimentação é a Apresentação e Empacotamento do que foi realizado no experimento para que esse possa ser repetido.
Sendo assim, é interessante a repetição deste para outros artefatos de software, tais como a descrição dos casos de uso, diagramas de atividades, de seqüência, ou quaisquer outros que se considerar relevante.
A variável de precisão poderá ser analisada em outros contextos, possibilitando um maior conhecimento de como a metodologia de análise de impacto baseada na rastreabilidade por conceitos se comporta em universos distintos de projetos de manutenção e de participantes.
O objetivo dessa pesquisa era desenvolver uma metodologia de análise de impacto que fosse capaz de determinar com maior precisão os artefatos impactados por um requisito de mudança.
Para tanto, buscou- se utilizar um tipo de rastreabilidade de artefatos que fizesse uso de semântica para tal.
Isso porque se inferiu que a assertividade dos elementos rastreados que seriam afetados por uma alteração fosse maior.
Encontrou- se então, na pesquisa que vinha sendo realizada por Noll, a integração de ontologias ao processo de desenvolvimento de software, onde uma das principais vantagens é a possibilidade de rastreamento dos artefatos.
Com essa realidade, decidiu- se propor uma metodologia de análise de impacto baseada na rastreabilidade através de ontologias.
Para isso foi preciso conhecer como uma ontologia é estruturada, quais são seus elementos e como estes se relacionam.
Igualmente foi necessário buscar na literatura outras propostas de análise de impacto, com a finalidade de encontrar os pontos fortes e fracos dessas, procurando determinar exatamente onde o uso da rastreabilidade semântica seria vantajoso.
Após o estudo desses e outros assuntos, iniciou- se o trabalho em direção a construção e estruturação da metodologia.
Observou- se que não existiam na literatura trabalhos correlacionados que relacionassem modificações nos conceitos da ontologia a alterações sofridas por artefatos produzidos ao longo de o desenvolvimento de software.
Assim, foi necessário realizar um experimento exploratório para que se conhecesse como alterações na ontologia se refletiriam nos artefatos relacionados aos seus conceitos.
A o analisar os resultados do experimento, foi possível determinar algumas influências, referentes a tipos de mudança e de relacionamento entre conceitos da ontologia.
Percebeu- se que a mudança pode ser estrutural ou relacionada a regras de negócio e que cada uma de elas afeta diferentemente os artefatos que são rastreados, dependendo da classificação do tipo de diagrama.
Além disso, pode- se notar que artefatos que não estavam diretamente relacionados a um conceito poderiam ser afetados, uma vez que os conceitos da ontologia se relacionam e uma alteração num de eles pode comprometer, de alguma forma, os outros aos quais está ligado.
Para que o cálculo das probabilidades de impacto nos artefatos pudesse ser determinado, tem- se como premissa que essas variáveis sejam informadas na ontologia do sistema.
A primeira fase da metodologia é analisar o requisito de mudança e, após este ser modelado conceitualmente, gerar uma ontologia referente a esse requisito.
De essa forma, as duas ontologias, a do requisito de mudança e a do sistema, podem ser comparadas a fim de identificar os conceitos comuns as duas e saber, estruturalmente, quais estão sendo afetados e de que maneira.
Com essas duas fases concluídas, podem- se rastrear os artefatos que estão relacionados aos conceitos que foram identificados.
O último passo é calcular o impacto para todos os artefatos que foram encontrados, determinando assim, o conjunto dos artefatos com maior probabilidade de impacto.
Além de o uso de ontologias para determinar o impacto de um requisito de mudança, outra contribuição dessa proposta foi o desenvolvimento da ferramenta ONTImpact.
Com ela é possível informar as influências aos conceitos da ontologia, comparar- las e realizar automaticamente os cálculos necessários, informando ao final os artefatos com maior probabilidade de serem modificados.
Alguns trabalhos futuros podem ser propostos para solucionar certas limitações dessa metodologia.
Um de eles é pesquisar a possibilidade de se identificar, também automaticamente, as alterações de regras de negócio, uma vez que hoje o usuário deve informar- la.
Outro item que pode ser melhorado é inserir o uso de tesauros, realizando uma análise semântica dos conceitos e não morfossintática como é feita através de algoritmos de radicalização de palavras.
Visando a evolução da metodologia, futuramente pode ser estudada uma forma de, utilizando as disciplinas de análise de impacto e rastreabilidade, garantir que a ontologia original do sistema em manutenção seja atualizada após a execução do requisito de mudança solicitado.
Seria interessante também que essa metodologia, e sua ferramenta, fossem aplicadas numa empresa, com um sistema efetivamente em manutenção.
Desta forma, poderia- se estabelecer o uso real e prático do que foi proposto neste trabalho.
No que se refere as mudanças na estrutura da ontologia, deveriam ser analisadas as exclusões de conceitos e relacionamentos.
Provavelmente, essas mudanças também exerceriam influência em artefatos relacionados a esses conceitos ou em outros a eles relacionados.
Quanto a ferramenta, suas funcionalidades poderiam ser adicionadas ao aplicativo ONTrace, proposto por Noll, já que as pesquisas de rastreabilidade ontológica, feita por ele, e a de análise de impacto, constante nesse trabalho, estão integradas.
De essa forma, o usuário que queira calcular o impacto de uma mudança poderia realizar todas suas atividades num só sistema.
