Esta dissertação objetiva a apresentação de um estudo sobre a aplicabilidade do paradigma Multiagente ao problema da rotulação de textos em Linguagem Natural.
Este trabalho relaciona- se com as áreas de Lingüística Computacional e Inteligência Artificial Distribuída, através do estudo de aspectos lingüísticos e computacionais com o intuito de propor uma abordagem não seqüencial ao problema da rotulação de textos.
O Processamento da Linguagem Natural e em especial o Processamento Baseado em Corpus, sub-áreas da Inteligência Artificial estudam fenômenos lingüísticos sob a ótica da Computação e muito têm apoiado a solução de problemas da comunicação Homem X Máquina.
Os sistemas Multiagentes, modelo já consolidado na Inteligência Artificial Distribuída, atualmente muito têm sido estudados para aplicação aos problemas do Processamento da Linguagem Natural.
Nosso trabalho propõe o uso do paradigma multiagente na rotulação de corpora.
É apresentada uma proposta de arquitetura distribuída onde cada agente atua sobre um corpus de estilo específico.
A arquitetura proposta foi implementada e está sendo testada com um conjunto inicial de textos.
Desde os primórdios da computação, o Homem precisou &quot;aprender «a linguagem dos computadores, códigos binários, fórmulas matemáticas, linguagem gráfica.
Hoje, o grande desafio é transformar essa comunicação no mais natural possível.
A idéia do Processamento da Linguagem Natural é realizar um tratamento sistemático da Linguagem Natural, com o objetivo dos computadores entenderem a nossa linguagem.
Em a atual fase de desenvolvimento da Informática, um dos principais desafios é diminuir os problemas de interação dos computadores com os usuários.
A Inteligência Artificial e o Processamento da Linguagem Natural (PLN) pesquisam em diversas frentes formas de minimizar esses problemas.
A área é atuante e fecunda.
Sistemas de computação inteligente, sistemas automáticos de tradução, sistemas de análise de textos, sistemas de instrução assistida por computador e consultas a Base de Dados em Linguagem Natural, são alguns exemplos.
O Processamento baseado em Corpus é uma abordagem que emprega heurísticas para a extração de conhecimento lingüístico e usa técnicas estocásticas em grandes volumes de dados textuais (escritos ou falados), disponíveis para o processamento informatizado, possibilitando a aprendizagem através de exemplos ocorridos naturalmente na língua usada.
O presente trabalho, está inserido no contexto do Projeto NALAMAS onde são estudados os Sistemas Multiagentes no contexto do Processamento da Linguagem Natural (mais precisamente no que concerne à interpretação de textos em português).
Vários trabalhos emergiram deste projeto e outros tantos estão a caminho.
Em este trabalho foi estudada a aplicabilidade de aprendizado em sistemas Multiagentes no Processamento da Linguagem Natural dentro desse projeto.
Especificamente, apresentamos uma proposta de arquitetura Multiagente, onde cada agente atua sobre um corpus específico a fim de gerar um conjunto de HMM (Hidden Markov Model) para rotulação (um genérico e outros específicos).
O Processamento da Linguagem Natural (PLN), sub-área da Inteligência Artificial, é o encontro de duas áreas com enfoques distintos e problemas semelhantes.
Por um lado a Computação necessita de interfaces mais naturais e por outro a Lingüística precisa dos métodos computacionais para desenvolver suas teorias.
Os desafios não são poucos, os conceitos ainda não estão unificados, mas os avanços tem sido notados.
Desde o século XIX, lingüistas pesquisam o chamado enfoque matemático a ser aplicado à linguagem natural;
Em a década de 50, John Backus, com trabalhos em linguagens artificiais, e Noam Chomsky, com a redefinição da lingüistica em bases mais formais, impuseram à área um grande avanço.
O tratamento das bases de dados textuais que suportam o acervo de conhecimento da Humanidade, expressos em linguagem natural, a recuperação de informações, as interfaces Homem-Máquina, traduções automáticas, a compreensão e geração de linguagem são determinantes à evolução do PLN.
A Inteligência Artificial Distribuída e os Sistemas Multiagentes obtiveram um acentuado crescimento de importância como modelo na Ciência da Computação, bem como em outras ciências:
Lingüistica, Lógica Matemática, Teoria da Organização, Biologia, Sociologia e Psicologia.
Isso demonstra o forte entrelaçamento da Inteligência Artificial Distribuída com disciplinas de outras áreas.
O interesse por a Inteligência Artificial Distribuída advém da grande ênfase no entendimento da cooperação e organização de grupos e sociedades de agentes que são naturalmente atividades sociais (sentido humano), apoiando atividades complexas, interdisciplinares e distribuídas (lógica e geograficamente).
Tais atividades incluem:
Simulação de capacidades inteligentes, raciocínio, comunicação em linguagem natural e aprendizagem.
A Inteligência Artificial Distribuída (IAD) tornou- se nos últimos anos um domínio de pesquisa muito promissor. Enquanto
estudos clássicos de Inteligência Artificial (Ia) tomam como modelo de inteligência o comportamento individual humano, cuja ênfase é colocada em representação de conhecimento e métodos de inferência, o modelo de inteligência utilizada em IAD é baseada no comportamento social, sendo a ênfase colocada em ações e interações entre agentes.
Os métodos de Aprendizagem Automática (Machine Learning) desempenham um papel muito importante na área da Inteligência Artificial.
Em os dias de hoje, Resolução de Problemas, Prova de Teoremas, Processamento da Linguagem Natural, Robótica e Sistemas Especialistas são sub áreas que utilizam tais métodos.
A habilidade de aprender, de adaptar- se, de modificar o comportamento é um componente inalienável da inteligência humana.
Como poderemos construir artefatos verdadeiramente inteligentes, capazes de auto aprimoramento?
Considerações filosóficas à parte, a área da Aprendizagem Automática tem obtido grandes progressos.
Indução em árvores de decisão aplicadas à automação industrial, modelos de Markov escondidos aplicados ao reconhecimento da fala são alguns exemplos.
Vamos considerar aprendizagem como mudanças adaptáveis no sistema, no sentido de que o permitam, da próxima vez, realizar a mesma tarefa ou tarefas do mesmo grupo com mais eficiência e eficácia.
Atualmente podemos agrupar em cinco os paradigmas de Aprendizagem Automática:
Aprendizagem Indutiva (Inductive Learning),· Aprendizagem Analítica (Analytic Learning),· Aprendizagem por Reforço (Reinforcement Learning),· Algoritmos Genéticos (Genetic Algorithms) e· Métodos de Aprendizagem Conexionistas (Connectionist Learning Methods).
Grandes esforços, com relativo sucesso, tem- se alcançado com abordagens híbridas, unindo métodos de mais de um paradigma.
Este trabalho tem por objetivo geral apresentar uma investigação realizada sobre o uso do modelo Multiagente sobre o Processamento da Linguagem Natural, através de uma arquitetura distribuída de agentes rotuladores que maximizem os resultados das abordagens seqüenciais.
O conhecimento lingüístico extraído de um corpus pode ser:
Específico a esse corpus, genérico a um grupo de corpora com textos de procedência similar ou de validade para toda a língua tratada.
O processamento de vários corpora pode trazer informações sobre os níveis de especificidade/ generalidade das categorias gramaticais extraídas.
Nossa proposta é uma arquitetura de sistema multiagente para rotular textos, onde múltiplos agentes rotuladores trocam informações durante as fases de treinamento e marcação.
Esta arquitetura é composta por um conjunto de rotuladores especializados em domínios específicos (ou estilos de textos) e um rotulador genérico para evitar redundâncias.
As vantagens esperadas dessa abordagem são:
Aumento de precisão da marcação com um conjunto menor de exemplos para o treinamento devido a o enfoque em domínios específicos de estilos de textos e melhor performance de treinamento devido a o uso de paralelismo.
Em o capítulo 2 apresentamos o Embasamento Teórico nas três áreas estudadas:
Processamento da Linguagem Natural, Processamento baseado em corpus e Sistemas Multiagentes.
Também apresentamos uma visão sobre o problema da rotulação de corpus.
Em o capítulo 3 apresentamos a Arquitetura do nosso sistema, trabalhos correlatos, o modelo dos agentes proposto e a camada de cooperação entre os agentes da sociedade.
Em o capítulo 4 apresentamos aspectos da implementação do protótipo do sistema proposto.
Em o capítulo 5 apresentamos nossas conclusões e trabalhos futuros a serem desenvolvidos após a conclusão do nosso curso.
O Processamento da Linguagem Natural (PLN), sub-área da Inteligência Artificial, é o encontro de duas áreas com enfoques distintos e problemas semelhantes.
Por um lado a Computação necessita de interfaces mais naturais e por outro a Lingüística precisa dos métodos computacionais para desenvolver suas teorias.
A Lingüística Computacional emerge como ciência com grande ênfase interdisciplinar.
Os desafios não são poucos, os conceitos ainda não estão unificados, mas os avanços tem sido notados.
Desde o século XIX, lingüistas pesquisam o chamado enfoque matemático a ser aplicado à linguagem natural;
Em a década de 50, John Backus, com trabalhos em linguagens artificiais, e Noam Chomsky, com a redefinição da lingüística em bases mais formais, impuseram à área um grande avanço.
O tratamento das bases de dados textuais que suportam o acervo de conhecimento da Humanidade, expressos em linguagem natural, a recuperação de informações, as interfaces Homem-Máquina, traduções automáticas, a compreensão e geração de linguagem são determinantes à evolução do PLN.
De o ponto de vista da Computação, o Processamento da Linguagem Natural, pode ser sintetizado em:
A linguagem natural, em contrapartida à linguagem artificial ou formal, é algo já existente que tem como objetivo a interação interpessoal.
Já as linguagens artificiais (FORTRAN, COBOL, C) tem um propósito específico e são mais restritivas.
As diferenças básicas entre elas são mostradas na Tabela 2.1: Chomsky redefiniu a lingüística sobre bases mais formais.
Em o núcleo dessa redefinição está a distinção entre performance e competência.
A performance ocupa- se do desempenho da linguagem falada, com sua interpretação, intervalos, mudanças de direção, maneirismo, erros gramaticais.
Esse tipo de comportamento da linguagem é que ele chamou de performance lingüística.
A habilidade de julgar a gramaticalidade de frases e sentenças, Chomsky chamou de competência lingüística, nosso conhecimento implícito da gramaticalidade de nossa linguagem natural.
Uma abordagem científica da linguagem, segundo Chomsky, envolve tanto esclarecimentos da performance quanto da competência lingüística.
Há de se mencionar nesse ponto que o PLN trata somente da linguagem como representação simbólica da língua, a qual envolve fatores mais abrangentes tais como:
Hábitos, cultura, gestos, conhecimentos e crenças.
Sintaxe: Descrição de como as palavras (ou parte de elas) combinam- se para formar sentenças.
Gramática: Ampliação do conceito de sintaxe, também descreve sons (fonologia) e significado (semântica).
Gramática Gerativa: Relacionada a sintaxe, é capaz de gerar todas as sentenças gramaticalmente corretas e nenhuma não gramatical de uma linguagem.
Com ela não podemos entender uma linguagem natural, pois não descreve o significado das sentenças.
Semântica: É o estudo da representação dos significados das sentenças, estágio seguinte à saída da Gramática Gerativa.
O tratamento computacional da linguagem natural envolve vários domínios de processamento:
Domínio léxico-morfológico, sintático e semântico-pragmático[ De LIMA96], nas próximas seções discorreremos sobre cada um de eles.
O léxico ou dicionário, é a estrutura de dados que acompanha o processamento da análise e geração da linguagem natural, armazena as palavras e associa a elas informações relevantes.
Sucintamente pode ser definido como uma lista de palavras com suas categorias gramaticais, classes sintáticas, informações semânticas.
Um dicionário de formas contem a estrutura completa das palavras.
É utilizado para o reconhecimento das palavras, sem a preocupação do tratamento lingüístico.
Um dicionário de bases contem apenas morfemas (partes das palavras, as palavras.
Em essa estrutura, normalmente existe uma maior organização e condensação.
Em o domínio léxico-morfológico o tratamento é realizado sobre as palavras de uma sentença e obtém as diferentes categorias de cada palavra e outras informações disponíveis no léxico.
A quantidade de informações para cada entrada do léxico é proporcional à riqueza da análise léxico-morfológica.
Para os mesmos tipos de palavras (categorias gramaticais), existem registros que caracterizam o comportamento de um subconjunto de vocábulos da linguagem.
A morfologia estuda o tratamento da estrutura das palavras (forma, flexões, classificação) em relação a cada tipo de palavra.
Um fenômeno muito estudado, que ocorre nesse domínio, é a ambigüidade léxica.
Quando a mesma palavra pode ter mais de uma representação ou situa- se em diferentes categorias gramaticais, dizemos que ocorre uma ambigüidade léxica.
O exemplo abaixo descreve esse fenômeno:
Maria ocupou a casa.
A -- pode ser:
Algumas implementações de analisadores léxico-morfológicos citadas por Agustini são:
Autômatos finitos acíclicos minimizados de Lucchesi e Kowaltowski· PC-KIMO -- dicionário de bases de Karp[ KARP92[ e· Analisador do Projeto Lexis baseado em Árvore TRIE.
A sintaxe estuda a disposição das palavras para formação da estrutura da sentença.
O parser é um programa que, a partir de uma gramática, um léxico e um texto, determina quais construções estão de acordo com as regras gramaticais e gera a descrição da estrutura.
Se a sentença for ambígua, o parser descreve todas as estruturas possíveis para a sentença.
A estrutura de um parser é mostrada na figura 2.1.
Cada uma dessas estruturas hierárquicas de informações é chamada de árvore de derivação;
Em a sua construção é feita a verificação da adequação das seqüências de palavras ou termos que compõem a frase, período ou oração, às regras de formação impostas por a linguagem, tais como:
Concordância nominal e/ ou verbal;
Regência nominal e/ ou verbal;
Posicionamento dos termos na frase.
Léxico estrutura da sentença (sem ambigüidade) parser gramática todas as estruturas (se ambígüas) texto léxico-morf.
De a decomposição realizada por o analisador sintático surgem elementos funcionais da oração, denominados sintagmas (unidades sintáticas):
Termos essenciais (sujeito e predicado), termos integrantes (complementos verbal e nominal) e termos acessórios (adjunto adverbial, adjunto adnominal e aposto).
A análise sintática do período deve considerar também o tipo de período (simples ou composto), sua composição (por subordinação, por coordenação) e a classificação das orações (absolutas, principal, coordenada ou subordinada).
Com esse fim o analisador sintático utiliza dois componentes:
1 -- uma representação gramatical onde estão declarados os fatos sintáticos da linguagem, as estruturas de composição dos sintagmas;
Formalmente, uma linguagem é um conjunto de sentenças, onde cada sentença é a concatenação de um ou mais símbolos (palavras) do vocabulário desta linguagem.
Uma gramática é uma especificação finita deste conjunto.
As gramáticas regulares são bem simples e de fácil reconhecimento, porém têm um poder de expressão limitado para o Processamento da Linguagem Natural.
As gramáticas livres do contexto são mais poderosas e permitem a representação de linguagens mais complexas.
Têm como desvantagem a dificuldade em expressar dependência simples tal como concordância entre verbo e sintagma nominal.
Gramáticas sensíveis ao contexto permitem gerar uma classe bastante complexa de linguagens, podendo resolver os problemas de dependência citado anteriormente.
Seu inconveniente é a questão do reconhecimento.
O problema de decidir se uma sentença pertence a uma gramática sensível ao contexto é uma função exponencial sobre tamanho da sentença, tornando seu custo computacional proibitivo.
Atualmente a tendência é a utilização de gramáticas meio sensíveis ao contexto, um modelo que situa- se num nível intermediário entre as gramáticas livres do contexto e as sensíveis ao contexto.
Esse paradigma alia uma boa capacidade de representação e um modelo computacional viável.
Grammar (DCG) que é disponível em PROLOG.
Com essa notação podemos definir gramáticas livre do contexto para analisar sentenças (parsing) A semântica estuda o significado das palavras nas sentenças, relaciona uma seqüência de marcadores lingüísticos a uma representação interna que expresse o sentido dessa seqüência.
A pragmática, por sua vez, aborda as várias funções em as quais o ambiente de uma sentença é importante para determinar sua correta interpretação.
Em o Processamento da Linguagem Natural, o problema semântico é crítico e deve ser tratado em todos os aspectos do processamento da linguagem.
Em o domínio léxico-morfológico, a categorização gramatical das palavras provê um tratamento semântico inicial.
Em o domínio sintático, a dependência (concordância verbal, por exemplo), ao ser tratada gramaticalmente, com formalismos mais complexos, impõe restrições semânticas para determinar se uma sentença é bem formada ou não.
Em esse aspecto, a análise sintática/ semântica da linguagem natural é semelhante à analise da linguagem de programação (linguagem artificial) onde a sintaxe é uma expressão da forma das sentenças válidas, e a semântica invalida construções bem formadas mas sem sentido.
O processamento da associação de uma ou mais representações semânticas às árvores de derivação, denominado análise semântica, pode ocorrer à medida que estas árvores vão sendo produzidas, ou pode ser feita em etapa posterior.
Há tendência de resolução da análise sintática e da análise semântica em cooperação.
Por exemplo, a sentença:
João comprou um Fusca.
Ele gosta de carros.
Enquanto a análise semântica se restringe a lidar com os significados das sentenças a partir de os significados de suas partes, a pragmática preocupa- se com a interpretação do todo, que não é somente a união das partes.
É necessária a resolução de fenômenos de referência, tais como anáforas e elipses.
Uma dada estrutura pode não acrescentar nada de interesse à interpretação da sentença, enquanto outra estrutura, como um comentário irônico, pode ter significado diferente do textualmente expresso.
Embora existam trabalhos que obtiveram êxito em diversas frentes do PLN (tradução automática, correção de textos, consultas bibliográficas, formalismos para representação, etc), a interpretação e o processamento automático do conhecimento disponível em linguagem natural ainda é um problema sem solução completa O alto grau de inter-relacionamento entre os domínios lingüísticos, a tentativa de manipular a linguagem natural de forma irrestrita e ilimitada contribuem com a complexidade da área.
O emprego de heurísticas para a escolha de alternativas para a análise sintática, tem sido muito utilizado.
Uma dessas abordagens, o processamento baseado em corpus, usa técnicas baseadas na Teoria da Probabilidade.
Em os últimos anos, grandes bases de dados textuais (Brown Corpus, Folha de São Paulo, AP News, Wall Street Journal) tornaram- se disponíveis para o Processamento da Linguagem Natural.
Em essas bases são encontrados vários milhões de palavras que podem ser processadas automaticamente.
Os primeiros esforços da utilização de métodos empíricos e estatísticos no processamento da linguagem, datam da década de 1950.
A célebre frase &quot;You shall a word by the company it keeps «já bem demonstrava essa abordagem.
Em o final dos anos 50 e início dos 60, por diversos motivos, entre os quais a crítica de Chomsky ao uso de n-gramas em estruturas sintáticas e a crítica de Minsky e Papert às Redes Neuronais no artigo Perceptron[ MINSKY69 apud CHUR93], a utilização dos métodos estatísticos entraram em desuso.
Em a década de 1990, novamente surgiram pesquisas nesse sentido, motivadas principalmente por a disponibilização de grandes volumes de dados para a computação, e a melhoria tecnológica dos equipamentos no que se refere ao poder de processamento e ao seu baixo custo.
Um dos maiores atrativos das abordagens baseadas em estatística é a habilidade da efetiva aprendizagem de parâmetros a partir de o processamento do corpus.
Esses algoritmos começam com uma estimativa inicial das probabilidades e então processam o corpus para calcular a melhor estimativa, repetindo o procedimento até que não hajam mais melhorias.
A técnica garante a convergência, embora não necessariamente descubra um valor ótimo.
A abordagem puramente baseada em conhecimento emula conhecimento da fala humana usando técnicas oriundas dos Sistemas Especialistas.
Sistemas baseados exclusivamente em regras têm obtido sucesso limitado.
Muitos dos sistemas bem sucedidos atuais, usam a abordagem estocástica.
Um corpus é uma coleção de peças (pedaços, fragmentos) da linguagem que são selecionados e ordenados de acordo com um critério lingüístico explícito para ser usado como um exemplo da linguagem.
O critério lingüístico pode ser externo (quando diz respeito aos participantes, a ocasião, classe social ou a função comunicativa das peças da linguagem) ou interno (quando está relacionado à ocorrência de padrões da linguagem dentro de as peças da linguagem).
De o The Oxford Companion to the English Language, ed McArthur &amp; McArthur 1992, também obtemos:
Corpus Uma coleção de textos, especialmente se completo e auto-contido.
Em a Lingüística e Lexicografia, um corpo de textos, expressões orais, ou outras espécies consideradas mais ou menos representativas da linguagem, e usualmente armazenados em base de dados eletrônica.
Atualmente, os corpora computacionais podem armazenar muitos milhões de palavras correntes, cujas características podem ser analisadas por meio de rótulos (rótulos de identificação e classificação associadas as palavras e outras formações do texto) e o uso de concordancing programs.
A utilização de corpus é feita para o estudo do conhecimento de uma linguagem através de exemplos ocorridos naturalmente da linguagem usada.
Ainda podemos citar como usos:
Processamento da Linguagem Natural sobre uma amostragem representativa do tipo de textos que o sistema espera processar;
Para criar grandes léxicos num dado domínio.
Aplicações lingüísticas:
Pesquisa na aquisição da primeira/ segunda língua,· ensino/ aprendizagem:
Linguagem para propósito específico (corpora jornalístico, corpora com textos científicos) para preparar listas de vocábulos baseados em itens lexicais de alta freqüência;
Descobrir fatos sobre a linguagem.
As vantagens da utilização dos corpora eletrônicos são:
Acessibilidade; Velocidade· exatidão/ fidelidade.
Basicamente os corpora podem ser simples (plain) ou anotados (annotated).
Em o corpus simples, não são adicionadas ao texto informações a seu respeito;
Já nos anotados, podem ser juntadas ao texto outras informações, tais como:
Categoria léxica, estrutura sintática, informações do discurso, etc..
Os corpora anotados também são chamados de rotulados ou etiquetados.
Não há consenso na comunidade científica sobre a maneira de como projetar um corpus, mas os seguintes aspectos devem ser considerados:
A que usuário se destina o corpus?
Qual é o propósito do corpus?
Quantas informações são necessárias?
O corpus deve ser montado por amostragem ou exaustão?
Algumas questões metodológicas no uso do corpus:
O corpus é suficientemente grande para representar a questão?
O corpus é representativo?
Quais são as amostras produzidas?
A transcrição ou rotulação é confiável?
Em o projeto de um corpus é necessário dimensionar o tamanho e a diversificação dos textos que este terá e o balanceamento.
Devemos construir um corpus tão grande quanto possível, ou balancear as informações conforme nossa necessidade de representação.
Os pesquisadores que advogam por grandes corpus, argumentam que o tamanho compensa uma possível carência de diversidade.
O reflorescimento recente do empirismo no Processamento da Linguagem Natural foi impulsionado por três desenvolvimentos:
Os computadores, de baixo custo, estão muito mais poderosos e facilmente disponíveis;
Os dados podem ser obtidos de maneira fácil, rápida e em grande volume;
E talvez o mais importante, devido a diferenças políticas e mudanças econômicas ao redor de o mundo, é dada grande ênfase em nossos dias à &quot;disponibilização «(deliverable) e avaliação.
Os esforços em organizar coleções de dados (Data Collection) tem relativo sucesso em responder às pressões na distribuição de massivas quantidades de dados.
A partir de a necessidade de grandes quantidade de textos (corpus) marcados, muitos esforços tem sido despendidos na criação de programas que executem essa tarefa (rotulação).
A rotulação ou marcação (part-of-speech tagging) é o processo usado para assinalar as categorias gramaticais a cada palavra num corpus.
Essa é uma tarefa muito importante no moderno Processamento da Linguagem Natural e em information retrieval.
A marcação é feita com base no contexto em que a palavra ocorre na sentença.
Algumas palavras, fora de o contexto da sentença possuem mais de uma categoria gramatical (ambigüidade lexical).
Em a tabela 2.2 podemos ver um exemplo.
Em a marcação de um corpus a resolução das ambiguidades lexicais é o maior problema.
Em foi feito um levantamento no &quot;Treebank corpus «com um milhão de palavras onde foram encontradas 50% de palavras não ambíguas, 25% com dois rótulos e os restantes 25% com três ou mais rótulos.
O que demonstra a complexidade do problema.
Considerando que uma certa palavra pode ser classificada com mais de um rótulo (por exemplo:
As palavras casa e amo podem ser substantivos ou verbos), abstrai- se o conceito de classe de ambigüidade.
A classe substantivo_ verbo é o conjunto de todas as palavras que podem ser substantivo ou verbo.
A vantagem da utilização este conceito é o menor número de parâmetros a serem estimados no modelo utilizado.
Em o Brown Corpus de 50 mil palavras são usadas apenas 4 centenas de classes de ambigüidades.
Um conjunto de rótulos ou etiquetas (tag) muito usado para a Língua Inglesa é o Penn Treebank Tag Set, mostrado na tabela 2.3.
Em geral os rotuladores são construídos segundo duas abordagens principais:
Métodos estatísticos (baseado em modelos probabilísticos) e Modelos baseados em regras.
Os rotuladores estatísticos analisam os textos segundo um enfoque empírico, independente do domínio ou da linguagem, através de técnicas de construção automática de regras inferidas a partir de um corpus de treinamento e não requerem supervisão humana.
O rotulador adquire seu conhecimento baseado em padrões existentes em corpora.
Os rotuladores baseados em regras lingüisticas[ BRIL93 e VOUT95 apud VILL95] são criados segundo os conhecimentos de lingüistas sobre os modelos e sintagmas da linguagem, gerando uma gramática.
O trabalho é manual, altamente dependente do domínio e específico de uma dada língua, tornando- o muito dispendioso.
Normalmente é utilizada programação simbólica para construir um rotulador baseado em regras.
Uma abordagem mista descreve um rotulador baseado em regras obtidas por processos estatísticos.
O sistema é composto de dois rotuladores, o primeiro cria um dicionário com a categoria mais provável de cada palavra, sem considerar o contexto sentencial.
Para as palavras desconhecidas existem um conjunto de regras de alto nível, tais como &quot;palavra iniciada com maiúscula é um substantivo comum», &quot;palavra terminada com` ing' é um verbo&quot;).
O segundo rotulador infere automaticamente regras a partir de o contexto do corpus de treinamento marcado comparando com a marcação feita por o primeiro rotulador.
Em ambas as abordagens, o tamanho do corpus de treinamento precisa ser bastante grande para obter- se uma razoável precisão na rotulação.
A precisão dos rotuladores é calculada de duas formas:
Quantidade de palavras rotuladas corretamente sobre a quantidade total de palavras do corpus ou quantidade de sentenças rotuladas corretamente sobre o total de sentenças do corpus.
É de se notar que o segundo critério é bem mais rígido do que o primeiro.
O funcionamento do rotulador estatístico pode ser dividido em 3 etapas:
Em a etapa de treinamento o sistema &quot;aprende «com um corpus já marcado.
A precisão na marcação de textos dos rotuladores estatísticos é proporcional ao número de exemplos de entrada na fase de treinamento (corpus marcado) e dependente do tipo desse corpus.
Com o aumento do volume da entrada, a quantidade de informações mantidas por o rotulador também aumenta, tornando- o computacionalmente menos eficiente.
O formalismo normalmente usado na implementação da fase de treinamento é o HMM (Hidden Markov Model).
Esse modelo é uma máquina de estados finitos que possibilita regular transições entre estados e controlar a emissão de sinais de saída.
Este modelo apresenta a vantagem de executar a aprendizagem de forma automática, independente de domínio, conjunto de rótulos e linguagem.
Um HMM é definido como uma tupla onde:
S é o conjunto de estados;
W é conjunto de símbolos.
T é o conjunto das transições.
Para a construção do HMM, o rotulador estatístico assume que:
Os estados são os rótulos (S);
Em a figura 2.2 é mostrado um esquema de um HMM com 2 estados, 2 símbolos e as probabilidades associadas a cada transição.
O modelo de n-gramas usa o conceito de contexto ou vizinhança para resolver o problema da ambigüidade.
Em as sentenças:
A ameixa está madura.
O rótulo adequado para a palavra a é artigo;
Vou ofereces- la a um amigo.
O rótulo da palavra a é preposição, levando- se em conta sua vizinhaça (verbo).
O modelo de n-grama define, para cada palavra na sentença, que se analise n-1 palavras vizinhas.
Em geral os modelos mais utilizados são os bigramas que analisam a palavra precedente e trigramas que analisam as duas palavras anteriores. Quanto mais
palavras forem analisadas maior será a precisão dos resultados e também maior o custo de processamento.
Em a fase de treinamento o rotulador recebe um corpus marcado e estima os parâmetros do HMM através de algoritmos de Freqüência Relativa e ForwardBackward.
Depois de construído o HMM e estimados os seus parâmetros, o rotulador está pronto para executar a marcação das palavras nas sentenças.
Em a fase de teste são processados textos com marcação já conhecida a fim de analisar os resultados e caso necessário fazer os ajustes.
Em a fase de marcação é utilizado o algoritmo de Viterbi para descobrir a seqüência mais provável de rótulos para uma dada sentença.
Segundo Biber, os principais usos das técnicas estatísticas no Processamento da Linguagem Natural são:
Gramaticais -- prover descrições gramaticais de características lingüísticas particulares;
Rotulação probabilística e Parsing;
Lexicografia -- uso e significado das palavras e padrões lexicais.
E ainda, prevê como futuras pesquisas e aplicações:
Predição automática de Registros de Categoria e· Comparação inter-lingüística;
Informações (Information Retrieval) e Tradução Automática (Machine Translation).
A Inteligência Artificial Distribuída e os Sistemas Multiagente obtiveram um acentuado crescimento de importância como modelo na Ciência da Computação, bem como em outras ciências, tais como:
Lingüistica, Lógica Matemática, Teoria da Organização, Biologia, Sociologia e Psicologia.
Isso demostra o forte entrelaçamento da Inteligência Artificial Distribuída com disciplinas de outras áreas.
O interesse por a Inteligência Artificial Distribuída advém da grande ênfase no entendimento da cooperação e organização de grupos e sociedades de agentes que são naturalmente atividades sociais (sentido humano), apoiando atividades complexas, interdisciplinares e distribuídas (lógica e geograficamente).
Tais atividades incluem:
Simulação de capacidades inteligentes, raciocínio, comunicação em linguagem natural e aprendizado.
A Inteligência Artificial Distribuída (IAD) é uma subárea da Inteligência Artificial.
O enfoque da IAD está nos aspectos de interação, cooperação e no fluxo de conhecimento entre unidades logicamente distintas.
A IAD caracteriza- se como um outro paradigma, onde o comportamento inteligente é visto como resultado das interações entre agentes.
A metáfora utilizada em Ia clássica é basicamente de origem psicológica, enquanto aquela utilizada em de natureza sociológica/ etológica.
A Inteligência Artificial Distribuída, tradicionalmente é dividida em subáreas, caracterizadas por a abordagem na definição dos agentes e sociedades:
DPS (Distributed Problem--Solving) e Mas (Multi-Agent Systems).
DPS (Distributed Problem--Solving) -- A Resolução Distribuída de Problemas considera que o trabalho de resolver um problema particular pode ser dividido entre um número de módulos que cooperam para dividir e compartilhar conhecimento sobre o problema e sobre o desenvolvimento da solução.
Todas as interações (cooperação, coordenação) estratégicas são incorporadas como parte integral do sistema.
Mas (Multi-Agent Systems) -- Os Sistemas Multiagentes dizem respeito à coordenação de um comportamento inteligente entre uma coleção de agentes (normalmente já existentes) com os quais podem coordenar seus conhecimentos, objetivos, capacidades e planos com o intuito de resolver um problema ou tomar uma ação.
Bond sugere três classes de objetos de estudo para a IAD:
Sistemas naturais· ciência da engenharia· coordenação homem-máquina O estudo de problemas sob o enfoque de sistemas naturais faz- nos entender estratégias e representações que pessoas usam para coordenar suas atividades, da mesma maneira que cientistas cognitivos investigam cognição individual em pessoas.
Esse enfoque inclui a modelagem em computadores e simulação de atividades coordenadas por pessoas.
A ciência da engenharia investiga como construir funcionalmente, automaticamente e coordenadamente resolvedores de problemas para aplicações específicas.
Em muitos casos o problema da coordenação deve ser simplificado usando protocolos padrões de comunicação.
A coordenação homem-máquina deve ser útil na análise e desenvolvimento de conjuntos de pessoas e máquinas trabalhando juntas de forma coordenada.
Em esse campo pesquisadores produzem trabalhos e práticas na área de trabalho cooperativo apoiado por computador (CSCW -- computer-supported cooperative work) e automação de escritórios.
O amplo espectro da Inteligência Artificial Distribuída, faz Moulin sugerir diferentes perspectivas para o estudo da área:
Perspectiva do agente, do grupo, enfoques específicos e perspectivas do projetista (figura 2.3).
As tentativas de definir agentes são tão embaraçosas quanto as tentativas de definir Inteligência Artificial.
O termo agente é usado largamente por muitos pesquisadores em distintos enfoques.
Wooldridge nos propõe dois usos do termo agente:
Noção fraca de agente agente é usado para denotar hardware ou programas de computador que possuem as seguintes propriedades:
Autonomia: Agentes trabalham sem a intervenção humana e tem algum tipo de controle sobre suas ações e estados internos;
Capacidade social:
Agentes interagem com outros agentes (e possivelmente com humanos) através de algum tipo de protocolo;
Reatividade: Agentes percebem seu ambiente e respondem dentro de um determinado tempo à mudanças que ocorrem;
Proatividade: Agentes não só respondem ao ambiente, mas também são capazes de possuir comportamento no sentido de atingir um objetivo tomando iniciativas.
Noção forte de agente Para muitos pesquisadores de I. A. O termo agente tem um significado mais forte que o dado por o esquema descrito acima.
Esses pesquisadores entendem agente como sendo um sistema de computação que, além de aquelas propriedades, possui características humanas, tais como conhecimento, crença, intenção e obrigações (estados mentais).
Correa define:
&quot;Os agentes são entidades que funcionam continuamente e de forma autônoma num ambiente em o qual existem outros processos e agentes, a esses conjuntos de agentes chamamos de sociedade».
Boissier e Demazeau definem agente como a entidade que atua num mundo de acordo com seus objetivos e estado corrente de conhecimento.
O agente pode ser dividido em duas partes.
A primeira é estática e define a arquitetura do agente, comumente denominada representação do conhecimento.
A segunda parte é composta dos métodos de processamento que constituem o processo dinâmico do agente.
Existem várias maneiras de tipificar agentes:
Móvel -- tem capacidade de mover- se no ambiente.
Estático -- não tem a capacidade de mover- se no ambiente.
Reativo -- o agente apenas responde a estímulos do ambiente.
Deliberativo -- o agente é capaz de raciocinar, planejar, negociar suas ações para atingir suas metas Para Moulin existem três categorias de agentes:
Reativo -- Esse tipo de agente reage a mudanças no ambiente ou através de mensagens com outros agentes, não é capaz de raciocinar ou ter intenções, manipular objetivos, suas ações são ativadas através de gatilhos ou um plano esteriotipado.
Intencional -- O agente intencional é capaz de raciocinar sobre intenções, crenças para criar planos de ações e executar- las segundo esses planos.
Social -- O agente social, além de as capacidades racionais, possui modelos explícitos dos outros agentes.
O agente precisa manter e atualizar essas informações para suas tomadas de decisão e criação de planos.
O nível de complexidade organizacional dos agentes sociais é mais sofisticado que as demais categorias de agentes.
Os comportamentos dos agentes em relação a outros agentes, a fim de atingir os objetivos do sistema, segundo Demazeau, podem ser classificados como:
Coabitação: O agente obtém sucesso na execução da tarefa e é capaz de executar- la sozinho.
Esse ponto de vista é equivalente à Ia Clássica onde ambientes eram planejados como mono-agente.
Cooperação: Com o intuito de realizar uma tarefa o agente procura auxílio de outros agentes pois ele não é capaz de executar a tarefa sozinho, ou porque outros agenteS são capazes de realizar a tarefa de modo mais eficiente.
Colaboração: Alguns objetivos globais relacionados com todos os agentes podem ser realizados individualmente por vários agentes.
O problema consiste em eleger um dos agentes que irá realizar a tarefa.
A redundância das capacidades desses agentes contribui para a robustez do sistema.
Distribuição: Finalmente alguns objetivos globais só podem ser realizados por vários agentes agindo coletivamente.
O principal problema relaciona- se com a divisão do trabalho total e a distribuição para os agentes cooperativos;
Esse tipo de comportamento incrementa a eficácia total do sistema e pode ser observado em sistemas da IAD.
Outra maneira de classificar agentes, apresentada por Nwana, identifica os atributos mínimos que um agente deve possuir:
Autonomia, aprendizado e cooperação.
Autonomia refere- se ao princípio que o agente tem de agir sem interferência humana, Aprendizado à capacidade do agente incorporar novos conhecimentos com a interação com outros agentes e o ambiente e Cooperação a capacidade social de múltiplos agentes trabalharem para um objetivo comum.
Usando essas três características mínimas, derivamos quatro tipos de agentes (figura 2.4):
Agente Colaborativo -- tem ênfase na colaboração e autonomia;
Agente Aprendizado colaborativo -- tem ênfase na colaboração e aprendizado;
Agente Interface -- tem ênfase no aprendizado e autonomia;
Agente Esperto -- contempla equilibradamente as três características.
Um agente com ênfase em duas características, não implica na ausência da terceira (Agente Colaborativo, com ênfase em colaboração e autonomia não implica que nunca aprenda).
Com a intenção de descrever um agente genérico, Demazeau define as caraterísticas mínimas para as interações num mundo multiagente.
Todo agente precisa ter uma representação do conhecimento do mundo ou do problema a ser resolvido, representação essa que pode ser implícita ou explicita.
O conhecimento é adquirido através de percepção ou comunicação com outros agentes.
Sempre é possível abstrair objetivos das observações do comportamento de agentes.
Esses objetivos não precisam existir explicitamente dentro de os agentes.
A partir de conhecimentos e objetivos, agentes podem obter um considerável conjunto de possíveis soluções ou planos para atingir as metas.
Um agente não precisa ser capaz de produzir todas as soluções possíveis mas somente uma parte dessas de acordo com suas capacidades de raciocínio.
Quando várias possibilidades de solução ou planos são potencialmente aplicáveis, a decisão precisa ser feita sob o ponto de vista do agente.
Isso é o que chamamos de decisão do agente.
Capacidades de Decisão Brooks, a despeito de a maioria dos pesquisadores que vêem a Ia como uma questão de representação do conhecimento, propôs uma inteligência sem representação.
Em os Laboratórios do MIT, foram construídos robôs onde o sistema de inteligência é decomposto em produtores de atividades independentes e paralelos e em que toda a interface com o mundo é feita através de percepção e ação.
Esses robôs implementam uma arquitetura abstrata chamada &quot;subsumption architecture «a qual personifica as idéias fundamentais da decomposição em camadas de tarefas adquirindo comportamento e incremental composição através da depuração do mundo real.
Para Shoham um agente é uma entidade cujo estado é visto como componentes mentais tais como crenças, capacidades, escolha compromissos.
Os estados mentais podem ser classificados em atitudes:
Crença informacionais conhecimento motivacionais desejo inteção obrigação comprometimento escolha Muitos pesquisadores buscam inspiração para seus trabalhos de Sistemas Multiagentes nas sociedades humanas e na ciência organizacional.
Stanford usa uma metáfora da organização humana para definir uma arquitetura multiagente Inicialmente, vamos distinguir a diferença entre estrutura e organização Estrutura é o modelo informacional e controle de relacionamentos existentes entre agentes e a distribuição das capacidades de resolver problemas.
Sob esse aspecto, os agentes devem possuir:
Cobertura -- toda porção do problema necessariamente precisa ter pelo menos um agente com capacidade de resolves- la.
Conectividade -- agentes precisam interagir de maneira que permitam a cobertura das atividades a serem desenvolvidas e integração numa solução global.
Capacidade -- cobertura e conectividade precisam ser atingíveis através de comunicação e limitação de recursos computacionais, a fim de assegurar as especificações do sistema.
A estrutura precisa definir papéis e relacionamentos para satisfazer esses condições.
A organização é definida como um conjunto de agentes com mútuos comprometimentos, comprometimentos globais, mútuos desejos e eventualmente intenções conjuntas quando esses agentes atuam juntos para atingir objetivos.
As noções de crença, intenção e comprometimento são oriundos do grau de cooperação existente entre os agentes e do espectro das estratégias de comunicação que são oferecidas ao agente para trocarem de estados mentais.
A estrutura difere da organização, basicamente, porque a estrutura é estática e a organização é dinâmica.
Werner desenvolveu a unificação da teoria da comunicação, cooperação e estrutura social como fundamento para o projeto de sistemas de agentes que comportam- se como uma unidade social ou grupo.
Sua proposta formaliza a descrição de agentes com estados intencionais e mensagens lingüísticas para efetuar o planejamento dos processos.
Essa proposta justifica a ação social cooperativa, porque agentes com estados intencionais são mutuamente modificados por intercâmbio comunicativo.
Wooldridge, citando Maes, define uma arquitetura de agente como:
&quot;uma metodologia particular para construção de agentes.
Especificando como, o agente pode ser decomposto na construção num conjunto de componentes modulares e como esses módulos precisam interagir.
O conjunto total e suas interações tem que prover as respostas para a questão de como monitorar os dados e o corrente estado interno dos agentes determinando as ações e futuros estados internos dos agentes.
A arquitetura encorpara técnicas e algoritmos que suportam essa metodologia.»
Wooldridge classifica as arquiteturas de sociedades como:
Deliberativas -- contém uma representação explícita, um modelo simbólico do mundo, e as decisões são tomadas via lógica racional, baseada em padrões comparativos e manipulação simbólica.
Reativas -- não incluem nenhum tipo de modelo central de palavra simbólica e não usa raciocínio simbólico complexo.
Híbridas -- são sociedades heterogêneas com agentes reativos e deliberativos.
Normalmente essas sociedades são compostas de sub-sistemas em que os agentes deliberativos são encarregados de manter o modelo de representação simbólico do mundo, desenvolver planos e tomar decisões;
E os agentes reativos são capazes de reagir a eventos que ocorrem no ambiente sem chegar a aplicar raciocínio complexo.
A maioria dos pesquisadores aborda o problema sob o enfoque deliberativo (Abordagem Clássica).
IRMA (Intelligent Resource Boubded Machine Architecture) é uma arquitetura desenvolvida por Bratmam.
Essa arquitetura tem quatro estruturas de dados principais:
Uma biblioteca de planos e representações explicitas de crenças, desejos e intenções;
Um mecanismo de inferência para raciocinar sobre o ambiente;
Um analisador de meios e fins para determinar quais planos podem ser usados para atingir as intenções dos agentes;
Um analisador de oportunidades que monitora o ambiente com o intuito de determinar futuras opções para os agentes;
Um filtro de processos;
E um deliberador de processos.
O filtro de processos é responsável por a determinação do sub-conjunto de agentes com potencial corrente de ação que tem características de ser consistente com as intenções correntes dos agentes.
A arquitetura Reativa (Abordagem Alternativa) tem como exemplo a proposta de Brooks chamada subsumption architecture que preconiza um comportamento inteligente sem uma representação explícita e sem raciocínio abstrato do tipo proposto por a Ia simbólica.
&quot;Inteligência é uma característica emergente de determinados sistemas complexos», afirma Brooks.
Um dos componentes fundamentais das interações nas sociedades é a comunicação entre agentes, a qual pode ser feita de modo direto ou indireto.
As arquiteturas de quadro-negro (blackboard) e aquelas baseadas em troca de mensagens são exemplos típicos.
O sistema de quadro-negro oferece aos agentes uma estrutura de dados que pode ser escrita ou lida por o grupo sob um critério de escalonamento.
Não há comunicação direta entre agentes, todas as interações são feitas através do quadronegro.
Em as sociedades baseadas em troca de mensagens, os agentes comunicamse diretamente, cada agente possui uma representação dos outros agentes (capacidades, objetivos, conhecimentos e crença).
A regulamentação desse tipo de comunicação é mais complexa do que a de quadro-negro;
Existem protocolos que regem essas interações.
Outras maneiras de classificar as sociedades nos são apresentadas por Oliveira:
Homogêneas, quando os agentes são todos do mesmo tipo ou heterogêneas, caso contrário;
Fechadas, quando os agentes são fixos, ou abertas, quando há possibilidade de migração (entrada/ saída de agentes);
Baseada em leis (regras explícitas de comportamento, válidas para toda a sociedade, geralmente representadas à parte) ou não.
Além de a estrutura e organização, outros conceitos importantes para a compreensão de sistemas multiagentes são:
Coordenação, cooperação, negociação, comportamento coerente e planejamento.
São tarefas básicas de coordenação de um grupo de agentes, a alocação dos recursos, normalmente escassos;
Comunicação de resultados intermediários;
Mercados são outra forma de organização de grupos baseada em mútuos ajustamentos, onde cada agente controla os recursos escassos, com o intuito de atingir o objetivo comum.
Recursos valorados são intercambiados, com ou sem preços explícitos.
Uma vez o contrato feito, existe um acordo em que cada comprador torna- se o supervisor do fornecimento.
&quot;Cooperação é quando agentes autônomos esforçam- se para alcançar um objetivo social;
Cooperação é necessária para que a ação dos agentes seja coordenada.».
Cooperação implica em comunicação e maiores taxas de realização de tarefas paralelas, maior número de tarefas compartilhando recursos e de tarefas executadas, diminuindo as tentativas de agentes fazerem as mesmas atividades, diminuindo também a interferência entre tarefas, evitando interações prejudiciais.
Mecanismos de negociação são usados para coordenar grupos de agentes;
A negociação é o processo de melhorar os acordos (reduzindo inconsistências e incertezas) em pontos de vista comum ou planos através de trocas de informações relevantes.
Assumindo que o grupo de agentes é cooperante, o problema é saber que agentes podem alcançar um comportamento coerente ou coerência global, ou seja quais ações de agentes fazem sentido em relação os objetivos comuns ao grupo como um todo.
O planejamento das atividades dos agentes num grupo, com explícita divisão de tarefas, propicia o aumento do comportamento coerente melhorando a coordenação para atingir os objetivos comuns.
Técnicas como planejamento centralizado de múltiplos agentes, plano de reconciliamento, análise organizacional, e apropriado controle de transferências baseados em raciocínio sobre o a solução local do problema, são maneiras que auxiliam o alinhamento das atividades dos agentes depois da discussão de inferências das conseqüências da execução das tarefas numa certa ordem.
As atividades de coordenação, cooperação, planejamento, negociação e comportamento coerente estão baseadas nas interações entre os agentes.
As interações são geralmente governadas por protocolos que são coleções de regras que controlam as trocas entre os agentes.
Os protocolos são essenciais para os sistemas multiagentes porque habilitam os agentes a interagirem de um modo organizado.
A Teoria dos Atos da Fala, embasa alguns dos principais protocolos de comunicação entre agentes.
Essa teoria apresenta, basicamente, o papel da linguagem como ação.
Três ações podem ser identificadas no ato de fala:
Baseado nessa teoria foi definida a linguagem de comunicação e protocolo KQML (Knowledge Query Manipulation Language) que tem sido usada como padrão de fato em sistemas multiagentes.
O conhecimento lingüístico extraído de um corpus pode ser:
Específico a esse corpus, genérico a um grupo de corpora com textos de procedência similar ou de validade para toda a língua tratada.
O processamento de vários corpora pode trazer informações sobre os níveis de especificidade/ generalidade das categorias gramaticais extraídas.
Em as abordagens estudadas (métodos estatísticos e baseado em regras), o tamanho do corpus de treinamento precisa ser suficientemente grande para atingir precisão razoável.
A utilização de um só corpus de treinamento implica na perda de informações dependentes de domínio ­ algumas palavras podem ter usos específicos dependendo do tipo ou estilo do texto.
Essas considerações motivam a aplicação de processamento distribuído sobre corpora de diferentes estilos de texto.
Uma forma natural de viabilizar esta aplicação é o uso de Sistemas Multiagente.
Assim, nossa proposta é uma arquitetura de sistema multiagente para rotular textos, onde múltiplos agentes rotuladores trocam informações durante as fases de treinamento e marcação.
Esta arquitetura é composta por um conjunto de rotuladores especializados em domínios específicos (ou estilos de textos) e um rotulador genérico para evitar redundâncias.
As vantagens esperadas dessa abordagem são:
Aumento de precisão da marcação com um conjunto menor de exemplos para o treinamento, maior velocidade de processamento na fase de treinamento devido a o paralelismo da arquitetura e melhor performance de marcação devido a a separação dos modelos, conforme veremos mais adiante.
Com o intuito de situar o presente trabalho com o estado atual da pesquisa nos meios acadêmicos e científicos foi feita uma procura bibliográfica e na Www.
Poucos trabalhos envolvendo rotulação em ambientes Multiagente foram encontrados e em especial destacamos as seguintes propostas.
Considerando o excessivo custo para prover grandes quantidades de exemplos marcados para o treinamento em tarefas de aprendizagem, Dagan e Engelson propuseram o &quot;Committee--based sampling».
Esse método automático reduz o custo de treinamento por aprendizagem ativa (active learning) em o qual o processo de aprendizagem tem algum controle sobre a escolha dos exemplos que são marcados e usados no treinamento.
A seleção de amostras diminui a quantidade de entradas aumentando o grau de representatividade.
Em o &quot;Committee--based sampling «o processo de aprendizagem recebe como entrada exemplos não marcados e decide para qual de eles solicita marcação ou não.
É construído um comitê de classificação baseado no conjunto de treinamento corrente.
Cada membro do comitê então classifica exemplos candidatos e avalia a informaticidade do exemplo para mensurar o grau de discrepância entre diversos modelos de variáveis dos membros.
O exemplo é selecionado por rotulação probabilística.
Esse modelo foi aplicado no aprendizado de um rotulador estatístico HMM e obteve melhoria de performance, melhor velocidade de execução e manteve a precisão mesmo usando um conjunto de treinamento menor.
Também encontramos outro trabalho na área do PLN com arquitetura Multiagente onde um conjunto de agentes interagem com o objetivo de extrair informações de textos livres para abastecer uma base de conhecimentos.
A arquitetura do sistema (chamado HelpDesk) é composta por quatro agentes:
Base de conhecimentos, Contador de palavras, Rotulador e Interface especialista.
O primeiro trabalho, embora tenha um objetivo semelhante a um dos nossos objetivos (melhorar o desempenho de rotulação), não contempla a abordagem Multiagente.
O segundo trabalho é baseado no paradigma Multiagente, porém a tarefa de rotulação, diferentemente do nosso trabalho, é feita só por um processo de forma isolada e independente dos demais agentes da sociedade.
Nenhum dos dois trabalhos contempla uma separação dos textos em domínios específicos (estilo do texto).
O nosso faz essa divisão para explorar as vantagens do paralelismo.
A arquitetura da sociedade é composta de um agente genérico e um conjunto de agentes específicos.
O processo é dividido em duas fases:
Treinamento e Marcação.
Em a fase de Treinamento o sistema adquire através de corpora de diferentes estilos o conhecimento necessário a fase de Marcação.
A fase de Marcação é de menor complexidade que a fase de Treinamento e passaremos a descrever- la, sucintamente, a seguir.
Em a fase de marcação a sentença a ser rotulada e o seu estilo de texto são passados ao agente genérico que faz uma marcação preliminar, segundo seus conhecimentos (categorias morfo- sintáticas comuns a qualquer estilo de texto).
Após essa etapa a sentença pode ser encaminhada ao agente correspondente a um estilo do texto e a marcação será completada.
Em a fase de treinamento cada agente específico toma como entrada um corpus marcado com a finalidade de adquirir conhecimentos sobre a categoria morfo- sintática de cada palavra desses corpora.
O conhecimento dos agentes é moldado sobre HMM e os protocolos de comunicação entre eles foram formalizados numa linguagem inspirada no KQML (seção 4.).
Em a fase de treinamento do sistema (figura 3.2), os agentes adquirem seus conhecimentos para aplicação na fase de marcação.
A cada agente específico é submetido um corpus de um dado estilo de texto.
De forma cooperativa, interagindo com os demais agentes da sociedade, cada agente cria seu HMM somente com padrões lingüisticos específicos do estilo processado.
Cabe ao agente genérico criar o HMM com os padrões comuns a todos os estilos de texto considerados.
Considerando a descrição de agente genérico de Demazeau (ver seção O conhecimento dos agentes é representado por os Modelos de Markov que são adquiridos, principalmente na fase de treinamento, a partir de os corpora específicos e para o agente genérico por a interação com os demais agentes.
O rotulador escolhido foi o Rotulador Estatístico desenvolvido na Universidade Nova Lisboa (ULN) descrito por, que foi agentificado para ser membro da sociedade através de uma camada de cooperação que possibilita a troca de informações na fase de treinamento.
O Rotulador Estatístico da UNL é composto basicamente por três módulos:
O classificador, o construtor do HMM e o módulo Viterbi.
O módulo classificador a partir de um corpus de treinamento, previamente marcado, cria o dicionário e um arquivo com as classes de ambigüidade e rótulos existentes.
O dicionário reúne as palavras do corpus de treinamento com todas as categorias gramaticais a elas associadas.
A partir desse módulo o sistema não trabalha mais com as palavras do corpus de treinamento e sim com as seqüências formadas por as classes de ambigüidade das palavras.
O construtor do HMM gera o modelo de Markov usando os bi-gramas e freqüências relativas a partir de as classes de ambigüidades criadas por o classificador.
De essa forma o modelo é formado por as seqüências recebidas do módulo de classificação (rótulos e classes de ambigüidade) acrescido do rótulo escolhido de entre os listados na respectiva classe de ambigüidade e a probabilidade estimada para esse rótulo.
A probabilidade estimada é calculada usando- se o algoritmo de Freqüência Relativa substituindo as palavras por suas classes de ambigüidades e usando a probabilidade contextual.
SWi. Ci| ti-1) onde:
W é a seqüência de palavras, T é a seqüência de rótulos, ci é a classe de ambigüidade, ti é o rótulo da palavra e ti-1 é o rótulo da palavra anterior.
A fórmula da probabilidade contextual é dada por:
P $= onde:
O módulo Viterbi descobre a seqüência de rótulos mais provável de um corpus a partir de o modelo HMM gerado por o construtor.
Em a figura 3.3 podemos visualizar a arquitetura do rotulador nas fases de treinamento e teste.
O objetivo da sociedade é na fase de treinamento adquirir conhecimentos e na etapa de marcação, rotular de forma precisa e utilizando recursos computacionais razoáveis.
Considerando que cada agente tem como objetivo rotular uma sentença de forma mais precisa possível e consumir a menor quantidade de recursos computacional, para aumentar a precisão é necessário a maior quantidade de informações possíveis aumentando também demanda de recursos computacionais.
Aparentemente, os agentes têm objetivos que são antagônicos.
Em a negociação entre os agentes para decidir se uma informação é específica ou genérica, balanço (equilíbrio) entre precisão demanda de recursos computacionais será buscado.
A comunicação dos agentes é feita com o ambiente externo através da leitura dos corpora de treinamento e das sentenças a serem rotuladas na fase de marcação e internamente entre os agentes através de protocolos de troca de mensagens num formato KQML.
O raciocínio social dos agentes é representado nos protocolos de negociação que decidem a especificidade (ou genericidade) dos conhecimentos adquiridos.
O conhecimento social é representado por as descrições externas que cada agente têm dos demais agentes, cada agente sabe identificar cada um dos membros da sociedade.
O agente genérico também conhece o estilo de texto que cada agente específico usou para o seu treinamento.
As ações dos agentes são a rotulação das sentenças dadas como entrada, a atualização de seus módulos e as comunicações entre eles.
Com o objetivo de realizar as tarefas de comunicação, raciocínio social e controle, o rotulador agentificado é &quot;envolto «num módulo que denominamos de Camada de Cooperação.
A Camada de Cooperação dá aos agentes capacidades de autonomia e mecanismos necessários à realização de tarefas conjuntas e cooperativas.
Essa camada implementa as interações de negociação e troca de mensagens entre os agentes da sociedade nas fases de treinamento e marcação do sistema.
Os protocolos de troca de mensagens entre os agentes implementam as interações entre os membros da sociedade.
Foram definidos os seguintes tipos de mensagens:
Com essa mensagem o agente é introduzido na sociedade e identifica- se (tipo de corpus).
O agente notifica sua saída da sociedade.
Quando um agente específico obtiver uma seqüência (rótulo anterior, classe de ambigüidade e rótulo) com probabilidade estimada superior a um patamar prédefinido, essa seqüência e a probabilidade estimada são enviadas ao Agente Genérico.
O Agente Genérico envia aos Agentes Específicos mensagem avisando que uma dada seqüência tornou- se genérica e deve ser eliminada dos modelos dos Agentes Específicos.
Quando um Agente Específico não tiver mais informações a serem enviadas ao Agente Genérico esse envia uma mensagem ao Agente Genérico indicando fim das informações.
Quando o Agente Genérico não tiver mais informações a serem enviadas aos Agentes ele envia uma mensagem aos Agentes Específicos indicando fim das informações.
Em esse ponto o Agente Genérico elimina de seu modelo as informações enviadas por os Agentes Específicos que não tornaram- se genéricas.
Com o intuito de implementar o raciocínio social entre os agentes do sistema, foram definidas trocas de mensagens e protocolos que são acionados por a camada de cooperação de cada agente da sociedade.
Inicialmente cada agente se apresenta à sociedade identificando- se e informando o estilo de corpus que processa.
A partir de o início do processamento dos corpora por os Agentes Específicos, as seqüências que obtiverem probabilidade estimada superior ao patamar definido são enviadas ao Agente Genérico.
Após a recepção de seqüências idênticas de todos os Agentes Específicos, o Agente Genérico calcula a probabilidade estimada média, armazena essas informações em seu modelo e envia mensagem aos Agentes Específicos avisando que a seqüência foi considerada genérica e esses devem eliminar- la de seus modelos.
Processo de tomada de decisão Através desse processo a sociedade toma a decisão de tornar a seqüência genérica ou manter- la específica a cada agente.
Se todos os agentes específicos enviarem a mesma seqüência ao Agente Genérico, esse calcula uma probabilidade estimada média, armazena essa seqüência e envia ao Agentes Específicos uma mensagem para que esses eliminem de seus modelos a seqüência que agora é genérica.
A probabilidade estimada média é calculada de forma ponderada em relação a as quantidades de palavras de cada corpus de treinamento.
De essa maneira os corpora maiores serão representados de maneira mais relevante nessa média.
A probabilidade estimada média é calculada por a seguinte fórmula:
Em a fase de marcação o agente genérico usa a probabilidade estimada média para pré-rotular os textos recebidos antes de enviar ao agente específico correspondente ao estilo de texto que irá completar a rotulação.
Quando os Agentes Específicos atingirem o fim dos dados de seus corpora, esses enviam mensagem ao Agente Genérico avisando esse evento.
O Agente Genérico, após receber de todos os Agentes Específicos a mensagem de fim de dados, envia a esses mensagem de fim de processo.
Essas interações podem ser visualizadas através do diagrama da figura 3.5.
O diagrama segue o modelo de cenários utilizado na metodologia OMT.
Agente Específico Agente Genérico apresentação seqüência+ prob.
Est.. A seguir descreveremos um exemplo das interações entre os agentes a fim de melhor ilustrar o comportamento dos agentes na sociedade.
Após as apresentações de cada agente à sociedade, os Agentes Específicos iniciam o envio ao Agente Genérico das seqüências que atingiram o patamar estabelecido.
AgentLingSend emissor, receptor, tipo de performativa, força ilocucionária (não utilizada) e corpo da mensagem.
Com essa mensagem um Agente Específico envia ao Agente Genérico a seqüência ARTI_ PREP, SUBS_ ADJE_ VERB, SUBS, 0.89 que representa a existência de uma classe de ambigüidade SUBS_ ADJE_ VERB, precedida de uma classe de ambigüidade ARTI_ PREP com probabilidade estimada de 0.89, ou seja existe a probabilidade de 89% de que uma palavra que tenha como rótulos possíveis SUBS_ ADJE_ VERB se precedida por uma palavra com rótulo ARTI_ PREP seja um SUBS.
Digamos que os outros dois agentes Específicos da sociedade enviem respectivamente as seguintes mensagens:
AgentLingSend (&quot;ESPECIFICO_ 2», &quot;Generico», ASKONE, NULL, &quot;I_ Know&quot;) AgentLingSend (&quot;ESPECIFICO_ 3», &quot;Generico», ASKONE, NULL, &quot;I_ Know&quot;) Com a recepção dessas mensagens o Agente Genérico detecta que recebeu a mesma seqüência (ARTI_ PREP, SUBS_ ADJE_ VERB, SUBS) de todos os Agentes Específicos, estando apto a calcular a probabilidade estimada média segundo a 4300 e 5700 palavras a probabilidade estimada média é igual a:
A seguir o Agente Genérico envia para cada Agente Específico a mensagem que indica que a seqüência (ARTI_ PREP, SUBS_ ADJE_ VERB, SUBS) foi considerada genérica.
AgentLingSend&quot;) A o receber essa mensagem os agentes Específicos eliminam de seus modelos as informações sobre essa seqüência.
Quando o agente específico não tiver mais dados a enviar ao genérico esse envia a mensagem de fim de dados.
AgentLingSend&quot;) O processamento é encerrado depois que o Agente Genérico recebe a mensagem de fim de dados de todos os Agentes Específicos e envia a mensagem de fim de processo a todos os Agentes Específicos».
AgentLingSend&quot;) O protótipo de implementação foi desenvolvido em linguagem C+ para máquinas Unix com sistema operacional Solaris no ambiente MASENV que utiliza os classes de objetos do DPSK+ P. Em o desenvolvimento da implementação foram usadas as mesmas ferramentas e ambiente de execução utilizados no Projeto NALAMAS (seção 2.4.3).
O DSPK+ P é uma biblioteca de classes que usa uma estrutura de dados de propósito geral para construir objetos compartilhados (classes e instâncias).
Essa estrutura de dados é composta por um nome da classe (string) mais um conjunto de facetas (slots), contendo pares de atributos-valor e definida por a classe C+ DPSK_ OBJECT.
Essa classe provê a construção básica para a interface C+ do DPSK+ P. A base estrutural da interface C+ é composta por:
Slots formam o fundamento para objetos locais, objetos locais formam o fundamento para objetos compartilhados e lockers (transações) que suportam classes e instâncias recuperáveis.
O MASENV (Multi Agent Software ENVironment) é uma camada sobre o DPSK+ P que permite gerir a comunicação por mensagens entre diferentes processos denominados agentes.
Esses agentes são conectados entre si de maneira a formar uma rede (malha) denominada sociedade.
De o ponto de vista do usuário, o MASENV apresenta- se como uma biblioteca de funções que permitem:
Colocar um agente na sociedade.
Enviar mensagens a outros agentes da sociedade.
Receber mensagens provenientes de outros agentes da sociedade.
Obter informações sobre a sociedade e sobre os agentes que a constituem.
A estrutura interna do MASENV é realizada de tal sorte que os usuários não vêem os tipos de dados que descrevem as mensagens e os agentes.
Internamente, MASENV é composto de várias classes DPSK+ P como também do servidor, assegurando a comunicação entre os diferentes agentes.
MASENV utiliza a arquitetura de particionamento de memória do DPSK+ P para efetuar as trocas de mensagens entre os agentes.
As funções permitem manipular os dados que compõem cada uma das duas classes que são contidas nos programas denominados server.
O servidor mbox_ server ocupa- se da classe dos agentes e o servidor message_ server ocupase das mensagens.
As classes contém os dados necessários à representação de cada entidade e a lista das funções destinadas a manipular esses dados.
Os servidores são os programas que executam e contém as funções definidas sobres as classes.
O DPSK+ P provê um Name Server e o Transaction Manager e o MASENV é executado sobre esse ambiente, mas o usuário não precisa preocupar- se com esse aspecto, pois todos os procedimentos necessários a inicialização estão contidos num arquivo para lançar o MASENV na máquina.
Esse arquivo chama- se Os rotuladores estatísticos tem a característica de trabalharem com qualquer conjunto de rótulos e para qualquer língua.
Para o nosso trabalho definimos o conjunto de rótulos mostrado na tabela 4.1.
O conjunto de rótulos usados foi definido intencionalmente com poucas categorias gramaticais;
Foram usadas somente as categorias básicas sem subdivisões.
Isto foi feito porque o presente trabalho visa demostrar as vantagens de uso de uma arquitetura multiagente e usa um rotulador estatístico já testado que pode trabalhar com qualquer conjunto de rótulos estabelecido e usado no corpus de treinamento.
Também foi necessário definir um outro conjunto com rótulos para pontuação e outros caracteres que, embora não sejam categorias gramaticais, são necessários a execução do rotulador.
Esse conjunto é mostrado na tabela 4.2.
Em a avaliação da arquitetura foram usados três corpora de treinamento, cada um com um tipo de texto:
Estes corpora foram escolhidos a fim de ressaltar as diferenças de estilo existentes entre eles, pois são textos escritos em diferentes épocas e com diferentes graus de formalismo.
A preparação dos corpora usados no treinamento e teste do sistema seguiu os mesmos procedimentos necessários à execução do rotulador da UNL, definidos por Villavicencio.
Basicamente o pré-processamento dos corpora é feito em 3 etapas:
Retirada das frases sem estrutura sintática (títulos, cabeçalhos, caracteres de controle, etc);
Transformar as letras maiúsculas em minúsculas e Utilização exclusiva do ponto final para delimitação da extensão da sentença.
Uma quarta tarefa, não mencionada por Villavicencio também se fez necessária a fim de separar algumas contrações da língua portuguesa que agregam mais de uma categoria gramatical.
A tabela 4.3 mostra as conversões feitas.
A preparação dos corpora foi feita em parte automaticamente e o restante manualmente.
Com ferramentas já existentes do projeto NALAMAS foram executados os três primeiros passos definidos por Villavicencio.
Esse processo rotulou os textos (com ambigüidade) segundo um dicionário existente na ferramenta, cerca de 45% das palavras dos textos não estavam catalogadas no dicionário e foram rotuladas como &quot;desconhecidas».
O restante da preparação (desambigüação e rotulação das palavras desconhecidas) foi realizado manualmente.
Toda a preparação foi feita com apoio de uma especialista da área da Lingüistica.
Os corpora foram submetidos a uma análise estatística com o objetivo de mostrar as diferenças nas seqüências de rótulos encontrados em cada estilo de texto.
Em as tabelas 4.4, 4.5 e 4.6 apresentamos o resultado dessa estatística para cada corpus usado.
Em a tabela 4.7 apresentamos um resumo das 3 tabelas a fim de demonstrar que certas seqüências de rótulos tem probabilidade muito parecidas nos 3 corpora e outras bem diferente, demonstrando que certas seqüências são genéricas aos corpora usados e outras específicas a certo estilo de texto.
Este trabalho apresentou uma proposta de arquitetura distribuída para a rotulação de corpora através do paradigma Multiagente.
A necessidade de grandes volumes de corpora rotulados é fundamental no Processamento da Linguagem Natural e muitos são os esforços dispensados a sua obtenção.
Em os últimos anos trabalhos aplicando o paradigma Multiagente emergiram em diversas áreas e no Processamento da Linguagem Natural obtiveram sucesso.
A partir de essas constatações estudamos o modelo Multiagente, o Processamento da Linguagem Natural em geral e em especial o Processamento baseado em Corpus e rotuladores.
A nossa proposta visa contribuir tanto com o Processamento da Linguagem Natural no que diz respeito à eficiência e focalização do problema da rotulação como também aos sistemas Multiagente apresentando uma proposta de arquitetura distribuída de agentes rotuladores.
O protótipo do sistema foi implementado usando as mesmas ferramentas e ambiente dos trabalhos do projeto NALAMAS visando sua futura integração.
Este trabalho resultou numa proposta de arquitetura Multiagente implementada e em teste com um conjunto inicial de textos.
Essa arquitetura é genérica, podendo ser usada para rotular textos de outras línguas além de o Português.
A abordagem utilizada também é independente do rotulador usado, podendo ser aplicada a outros rotuladores estatísticos.
A modelagem da implementação permite o aproveitamento da camada de cooperação dos agentes e com alguma adaptação de código usar um outro rotulador.
Uma limitação do sistema é a impossibilidade da negociação entre os agentes realizar- se simultaneamente à aprendizagem de cada corpus.
Devido a as características do rotulador usado isso não foi possível.
A implementação desta característica tornaria o sistema mais complexo, devido a a necessidade de sincronização;
No entanto, acreditamos que poderia haver um ganho de performance.
As características de Estados Mentais dos agentes não foram modeladas formalmente no presente trabalho.
Acreditamos que, em virtude de a simplicidade do processo de negociação, tais características não seriam necessárias.
Em continuidade a esse trabalho, pretendemos realizar mais testes com o protótipo desenvolvido a fim de obter medidas de comparação da performance da arquitetura em relação a o próprio rotulador agentificado como com outros rotuladores.
As medidas de comparação devem ser, tanto em termos de eficiência de rotulação (palavras rotuladas corretamente por o total de palavras) como de recursos computacionais despendidos.
Outro trabalho futuro certamente será aprimorar o protótipo implementado.
O reconhecimento do estilo de texto a ser rotulado é uma característica desejável do sistema.
Implementar a integração de nossa arquitetura com a Sociedade de Agentes Lingüísticos também é um trabalho a ser realizado.
Aprimorar o processo de negociação e tornar- lo simultâneo ao processo de construção dos modelos de cada agente específico é um trabalho que acreditamos poderá enriquecer nossa abordagem.
