Com o progresso da tecnologia, a quantidade de informação disponível em formato digital tem aumentado rapidamente.
Esse aumento se reflete na crescente importância de sistemas de Recuperação de Informações (Ri) eficientes, obtendo as informações corretas quando requisitadas por os usuários.
Tesauros podem ser associados a sistemas de Ri, permitindo que o sistema realize consultas não apenas por o termo-chave, mas também por termos relacionados, obtendo documentos relacionados, que antes não eram recuperados.
A criação manual, processo longo e oneroso que dava origem aos primeiros tesauros, passa a ser realizada automaticamente, através de diferentes métodos e processos disponíveis atualmente.
Com esta motivação, este trabalho propõe estudar três processos de construção automática de tesauros.
Um método utiliza técnicas estatísticas para a identificação dos melhores termos relacionados.
Outro método utiliza conhecimento sintático, sendo necessário extrair, além de as categorias gramaticais de cada termo, as relações que um verbo tem com seu sujeito ou objeto.
O último método faz a utilização de conhecimento sintático e de conhecimento semântico dos termos, identificando relações que não são aparentes.
Para isso, esse último método utiliza uma adaptação da técnica de Análise Semântica Latente.
Foram desenvolvidos estes três métodos de geração tesauros a partir de documentos do domínio de privacidade de dados.
Os resultados foram aplicados a um sistema de Ri, permitindo a avaliação por especialistas do domínio.
Como conclusão, observamos que, em determinados casos, é melhor a aplicação de técnicas que não utilizem conhecimento semântico dos termos, obtendo melhores resultados com métodos que utilizam apenas o conhecimento sintático dos mesmos.
Palavras-chave: Tesauro, Construção de tesauro, Construção automática de tesauro.
Com o avanço da tecnologia, a quantidade de informação disponível em formato eletrônico tem aumentado significativamente.
Com isso, a área de Recuperação de Informações (Ri) baseada em conteúdo tem se tornado uma importante área de pesquisa.
Através de técnicas variadas, a área de Ri busca encontrar o conteúdo relevante que responda a uma consulta de um usuário, por exemplo.
Devido a a existência da sinonímia entre termos e devido a a habilidade das pessoas para descrever a mesma ideia de diferentes maneiras, a Ri torna- se pouco eficiente caso uma busca seja realizada utilizando apenas o termo procurado.
Para maior eficácia na Ri, pode ser feita a associação de termos semelhantes, ou seja, termos semanticamente relacionados ao termo-chave que está sendo procurado.
Um tesauro é um conjunto de termos que são associados a termos-chave de acordo com sua similaridade semântica.
Por o fato de um tesauro se basear na identificação de termos semanticamente similares a um termo-chave, ele pode ser utilizado na Ri, associando aos termos procurados outros termos semanticamente similares, e recuperando não só os documentos que contêm o termo específico, mas também outros documentos relacionados.
Inicialmente a construção de tesauros era feita manualmente.
Porém a construção manual de tesauros exige muito tempo e este recurso é de difícil manutenção.
Por outro lado, o aumento da disponibilidade de textos em formato digital pode permitir a criação automática de tesauros a partir de uma coleção de documentos.
Métodos para a criação automática de tesauros vêm há muito tempo sendo estudados, alguns utilizando apenas técnicas estatísticas, outros utilizando conhecimento morfológico e sintático, outros utilizando, além de conhecimento morfológico e sintático, também conhecimento semântico para a identificação dos termos semelhantes.
Métodos mais recentes têm utilizado o grande volume de dados textuais disponíveis na internet para a criação de tesauros e outros métodos, ainda, utilizam o aprendizado de máquina para a melhor identificação dos termos semelhantes.
Embora diversos métodos tenham sido propostos, ainda é uma tarefa difícil fazer a geração automática de um tesauro de forma que se encontrem os termos que melhor cubram o escopo da coleção.
Esta dissertação de mestrado propõe uma análise comparativa entre técnicas de construção automática de tesauros a partir de textos.
Esta é a motivação principal deste trabalho, cujo contexto e escopo são apresentados nas próximas seções.
Atualmente empresas têm demonstrado grande interesse na criação de sistemas para o gerenciamento de políticas de privacidade.
Estes sistemas ajudam o projetista a descobrir os devidos cuidados que devem ser tomados em relação a a privacidade de dados, quando novos projetos são criados.
Para ajudar um projetista os sistemas utilizam uma base de conhecimento contendo leis, normas, regulamentos etc..
Relacionados à privacidade de dados que são consultados, conforme as descrições de um determinado projeto.
Embora estas bases de conhecimento sejam criadas manualmente por especialistas, elas têm difícil manutenção quando alguma lei, norma ou regulamento é modificado.
Para identificar quais partes da base de conhecimento são afetadas quando ocorre uma destas mudanças, um sistema de Ri pode ser disponibilizado, recuperando documentos de acordo com os termos-chave especificados.
De essa forma, caso uma lei que descreve, por exemplo, como serão tratadas informações que podem identificar uma pessoa (do inglês, &quot;Personal Identifiable Information&quot;) seja modificada, o sistema de Ri é capaz de recuperar todos os documentos em que este termo aparece.
Embora o sistema recupere documentos contendo o termo específico, ele não recupera todos os documentos a respeito de as informações que podem identificar uma pessoa, pois em muitos documentos esse tema é tratado por outros termos, como, por exemplo, &quot;personal information», &quot;personal data «ou até mesmo o acrônimo &quot;PII».
Para fazer a identificação dos termos similares a um termo-chave, deve ser introduzido um tesauro no sistema de Ri, de forma que, quando o sistema recuperar documentos, ele obtenha não só documentos que tenham o termo-chave associado, como também documentos que tenham associados os termos semanticamente relacionados.
O projeto de pesquisa onde este trabalho de mestrado se insere, é denominado Privacy/ APAO, e conduzido através de uma parceria PUCRS/ HP no período de Março de 2009 à Dezembro de 2010.
Nossa questão de pesquisa se refere aos processos de criação automática de tesauro, procedendo a uma análise e avaliação de métodos encontrados na literatura.
Após revisão bibliográfica minuciosa, foram escolhidos os métodos de Kaji, Grefenstette e Yang e Powers.
Assim, apresentamos e comparamos três métodos de construção, sendo um método baseado em técnicas estatísticas, um método baseado em análise de informação morfológica e sintática do corpus e um método que utiliza, além informação morfológica e sintática do corpus, a aplicação de uma adaptação da técnica de Análise Semântica Latente (do inglês, Latent Semantic Analysis -- LSA).
Métodos mais recentes, como os descritos no trabalho de Li E no trabalho de Xu e Yu, tendem a fazer a geração automática do tesauro utilizando o aprendizado de máquina, porém esse tipo de técnica não será abordado no presente trabalho por não dispormos de um corpus de treino.
Os resultados de cada um dos três métodos de geração automática de tesauros foram inseridos num sistema de Ri, permitindo assim uma avaliação dos resultados, que é discutida ao final deste volume.
O restante do texto da dissertação está organizado da seguinte forma.
O Capítulo 2 apresenta a fundamentação teórica deste trabalho, descrevendo conceitos e definições referentes ao modo como são realizadas as construções de tesauros e suas avaliações, bem como uma breve explicação sobre conceitos de Análise Semântica Latente, que é aplicada num dos métodos de construção automática de tesauros.
Trabalhos relacionados à construção de tesauros por métodos estatísticos, sintáticos e com a utilização de LSA são apresentados no Capítulo 3.
Os recursos utilizados, ferramentas utilizadas e a aplicação desenvolvida para a construção de tesauros são apresentados no Capítulo 4.
O processo de escolha dos termos para avaliação, a aplicação da ferramenta num sistema de Ri, e o processo de avaliação podem ser vistos no Capítulo 5.
Em o Capítulo 6 são apresentados e discutidos os resultados obtidos por a avaliação com especialistas de domínio.
Finalmente, o documento é encerrado no Capítulo 7, onde são apresentadas as considerações do trabalho e introduzidas sugestões de trabalhos futuros.
Segundo Knapp em, o termo &quot;tesauro «tem origem da palavra latina thesaurus e da palavra grega thesaurós, e significando tesouro ou depósito.
A partir de o século XVIII passou a ter o significado de &quot;depósito de conhecimento «como um dicionário ou enciclopédia.
O termo tesauro tem sido usado durante muitos séculos para designar léxico ou tesouro de palavras.
Por tesouro de palavras não se entende apenas quantidade de palavras, mas sim riqueza de conceitos e relações semânticas que devem existir entre elas.
Uma das primeiras obras a incluir o termo no seu título foi Thesaurus linguae Romanae et Britannicae de autoria de Thomas Cooper, publicada em 1565.
Porém a palavra popularizou- se a partir de a publicação de Peter Mark Roget chamada classificar e organizar os termos de forma a facilitar a expressão das ideias.
Assim, essa publicação passa a organizar as palavras não mais em ordem alfabética, mas sim por as ideias que elas expressam.
Segundo Campos e Gomes, em 1950, Hans Peter Luhn, do centro de pesquisa da IBM nos Estados Unidos, percebeu que para encontrar a palavra/ ideia mais adequada a uma recuperação de informação, não adiantava apenas ter uma lista de palavras em ordem alfabética.
Era necessário utilizar uma estrutura mais complexa, onde as palavras deveriam ter referências cruzadas de forma a evidenciar quais ideias estavam interconectadas.
Deu o nome de thesaurus a esta nova lista, influenciado por o trabalho de Roget, que, em seu dicionário analógico, o define da seguinte forma:
&quot;a revisão de um catálogo de palavras de significado análogo vai sugerir, com frequência, por associação, outras sucessões de pensamentos».
Ainda segundo Campos e Gomes, isso fez com que fosse criado um novo tipo de linguagem documentária, conhecido como tesauro de recuperação de informação, que veio para auxiliar sistemas que utilizavam um único termo (unitermo).
Outras listas de termos que continham algumas relações entre eles também passaram a se chamar tesauros.
Com o advento da internet, os tesauros têm sido utilizados para recuperar documentos que o usuário necessita.
Pois, assim como o tesauro ajuda um bibliotecário a encontrar documentos através de palavras-chave, ele também auxilia um usuário de sistemas de informação a encontrar os documentos que necessita.
Uma das primeiras conceituações de tesauro foi dada por a Unesco (United Nations Educational, Scientific and Cultural Organization) na década de 70 e caracteriza tesauro para a área de ciência da informação, organizando essa caracterização em dois aspectos de forma que pudesse atender tanto a área de elaboração de tesauro quanto a a área de recuperação de informação.
Um desses aspectos é expresso de acordo com a estrutura do tesauro:
Descreve o tesauro como um vocabulário controlado e dinâmico de termos relacionados semântica e genericamente, cobrindo um domínio específico do conhecimento.
O outro aspecto se volta a um tesauro quanto a sua função, definindo- o como um dispositivo de controle terminológico usado na tradução da linguagem natural dos documentos, dos indexadores ou dos usuários, numa linguagem de sistema mais restrita.
Outras conceituações também têm sido dadas ao termo tesauro.
Wilks Caracterizam tesauro como a organização de listas de palavras parcialmente sinônimas que explicam ou definem o significado de uma palavra somente por os seus sinônimos, sem a necessidade de explicar o seu significado.
Um exemplo desse entendimento é a utilização dos synsets da Wordnet2 para a descoberta do significado de um termo.
Para Aitchison tesauro é um vocabulário controlado, formalmente organizado de forma que, a priori, os relacionamentos entre conceitos são feitos explicitamente.
Aitchison ainda enfatiza que um tesauro tem duas propostas, sendo a primeira de elas a recuperação de informações, e a segunda, auxiliar o entendimento geral de uma determinada área, fornecendo &quot;mapas semânticos», mostrando os interrelacionamentos entre os conceitos e ajudando a encontrar definições para os termos.
Outras conceituações como a dada por Kilgarriff e Yallop são mais simplistas e caracterizam tesauros apenas como um recurso em o qual as palavras com significados semelhantes são agrupadas.
Observa- se que muitas definições têm sido dadas ao termo tesauro, porém a maioria de elas dá ênfase às relações entre as palavras (seja com similaridade semântica ou sinonímica) e a descoberta do significado de uma palavra através das palavras a ela relacionadas.
Uma explicação para o entendimento de um tesauro, ou como ele poderia ser construído, pode ser visto no trabalho de, que diz:
Everyone likes tezgüino.
Tezgüino makes. A partir de o exemplo apresentado, pode se entender que tezgüino sugere algum tipo de bebida alcoólica feita de milho.
De essa forma, poderíamos associar a esse termo, palavras como cerveja, vinho, cachaça etc., formando dessa maneira o tesauro.
Explicados os conceitos e obtido o entendimento do que é um tesauro, pode- se observar que ele pode ser utilizado em diversas aplicações, tendo sido inicialmente utilizado em sistemas de recuperação de informações.
O trabalho de Jing e Croft faz a criação automática de um tesauro que é utilizado num sistema chamado PhraseFinder.
O tesauro é utilizado para fazer a expansão de consultas, isto é, associar termos relacionados aos termos de uma consulta num sistema de recuperação de documentos.
Um trabalho semelhante, porém em para a língua portuguesa, é apresentado por Pizzato e de Lima, que utiliza um tesauro construído automaticamente para fazer a expansão de consultas na recuperação de documentos.
Além de Ri, os tesauros também têm sido utilizados para outras finalidades.
O trabalho de Heilman e Eskenazi, por exemplo, faz a aplicação de um tesauro gerado automaticamente a partir de um corpus, num sistema de perguntas chamado REAP.
O sistema REAP provê aos estudantes um ambiente de aprendizagem apresentando um conjunto de textos e exercícios que visam o aprimoramento do conhecimento de que o estudante dispõe na língua inglesa.
O objetivo do sistema é permitir aos alunos estudarem as palavras desconhecidas que aparecem num texto, ao invés de apenas listar o seu significado.
Para isso, o sistema faz a geração de perguntas e itens para resposta, conforme apresentado no Fragmento 1, onde os termos em itálico são a resposta correta para a pergunta.
Fragmento 1.
Exemplo de pergunta e resposta do sistema REAP (adaptado de).
Pray, forget, remember Invest, total, owe Accept, oppose, approve Persuade, convince, anger Em esse tipo de sistema o tesauro é utilizado para fazer a obtenção dos termos relacionados, criando a partir de eles os itens de resposta.
A utilização de um tesauro criado automaticamente a partir de um corpus se deu devido a existência de termos raros, que não conseguiam ser cobertos por tesauros gerais como o WordNet.
Outra aplicação dos tesauros gerados automaticamente é a categorização de documentos, como apresentado no trabalho de Wang, que faz a geração de um tesauro baseado na Wikipédia.
Com o tesauro construído, documentos são submetidos ao sistema de classificação de textos.
São procurados os conceitos da Wikipédia dentro de o documento a ser classificado e, para cada um dos conceitos encontrados, são associados sinônimos, hipônimos e termos relacionados encontrados no tesauro, dentro de o documento, enriquecendo assim a representação do documento.
De essa forma, documentos relacionados que originalmente não compartilhavam termos em comum são enriquecidos com os mesmos conceitos e classificados, sendo o resultado dessa nova classificação mais próximo de a correta categorização dos documentos.
Para a língua portuguesa, o trabalho de Moraes e Lima faz a extração de termos a partir de documentos da seção de esportes do jornal Folha de São Paulo.
Para a extração dos termos é utilizada a técnica de Frequência do Termo ­ Frequência Inversa do Documento (do inglês, Term Frequency ­ Inverse Document Frequency ­ TF-IDF) para termos simples, e a técnica de C- Value para documentos compostos.
Após a extração dos termos os autores fazem a clusterização dos mesmos, agrupando termos mais similares.
Por fim, trabalhos como o de Li, que faz a utilização de um tesauro construído automaticamente para a categorização de documentos baseado em redes neurais;
E de Xu e Yu, que faz a criação automática de um tesauro para a filtragem de spams, reforçam a ideia de quão importante é a criação de tesauros.
Existem diferentes formas de construção de tesauros, entre os métodos de apresentados a seguir, alguns utilizam métodos estatísticos, outros conhecimento sintático dos termos, outros ainda utilizam, além de a combinação de ambos, um conhecimento semântico dos termos.
Alguns tesauros podem ser criados de forma manual e outros de forma automática.
Algumas técnicas podem ser genéricas, isto é, sem um domínio específico, e outras orientadas a domínio, utilizando assim um corpus específico para a construção.
A seguir são apresentadas algumas dessas formas de construir tesauros.
Inicialmente os tesauros eram criados de forma manual, porém esse tipo de construção demanda um conhecimento humano sobre o assunto na escolha dos melhores termos para compor cada conceito.
Por exigir uma demanda do ser humano esse tipo de construção necessita muito tempo e esforço.
Esses tipos de tesauros também são de difícil manutenção, pois a língua é dinâmica e está em constantes mudanças, isto é, novas terminologias são adicionadas à língua, palavras do domínio técnico passam a ser de domínio comum, e outras ainda tornam- se obsoletas ou temporariamente impopulares.
Jing coloca que existem dois tipos de tesauros construídos manualmente.
O primeiro de eles é construído para um propósito geral e baseado em termos, como o tesauro de Roget e a Wordnet, e contém termos relacionados como antônimos, sinônimos etc..
O outro tipo é orientado a recuperação de informações como, por exemplo, o Headings).
O último contém relações do tipo &quot;BT( «termos mais genéricos», do inglês Broader Term), NT (&quot;termos mais específicos», do inglês Narrower Term), UF (&quot;termos usados para», do inglês Used For) e RT (&quot;termos relacionados», do inglês Related Te o) e podem ser genéricos ou específicos, dependendo das necessidades de sua construção.
Para a criação manual de tesauros foram propostas padronizações, possibilitando assim a ampliação da utilidade de um tesauro, pois ao invés de estar limitado somente a uma aplicação, ele pode ser utilizado em várias aplicações, inclusive aplicações interligadas.
O trabalho de Aitchison Descreve em detalhes como deve ser feita a construção manual de tesauros, bem como as normas para tal.
Alguns dos tesauros construídos manualmente e mais utilizados atualmente são descritos abaixo:
Tesauro de Roget Apesar de o tesauro de Roget ter sido desenvolvido em 1852 e finalizado 50 anos depois, ele ainda é amplamente utilizado como veremos na subseção 2.1.5 que trata de avaliação de tesauros.
Esse tesauro agrupa os itens lexicais em seis grandes classes:
Abstract relations, space, matter, intelect, volition e affections.
Essas classes são divididas em seções e cada seção é subdividida, resultando num total de 1000 grupos semânticos.
O tesauro de Roget se diferência dos dicionários, pois ele é organizado de acordo com o significado dos termos e não segundo a ordem alfabética.
Esse tesauro foi construído com o objetivo de ajudar o usuário a encontrar palavras que representem uma ideia desejada.
Essas ideias são expressas através de palavras relacionadas, normalmente sinônimos, mas também podem conter antônimos ou termos relacionados.
WordNet Outro tipo de tesauro construído manualmente e muito utilizado na literatura é a WordNet.
A WordNet é uma base de dados lexical para a língua inglesa, desenvolvida sob a direção de George A. Miller na Princeton University.
Em ela substantivos, verbos, adjetivos e advérbios são agrupados num conjunto cognitivo de sinônimos (synsets), onde cada um expressa um conceito distinto.
A WordNet é mais parecida com um tesauro do que com um dicionário devido a a maneira como organiza os synsets.
Os synsets são interconectados através de relações semântico-conceituais e lexicais.
Essas relações variam de acordo com o tipo de palavra como mostrado na Tabela 2.1.
Segundo Miller em, essas relações foram escolhidas para compor a WordNet pois elas são amplamente utilizadas na língua inglesa e com isso são bastante familiares à maioria das pessoas, não sendo necessário um conhecimento avançado em linguística para entender- las.
O verboy é um hiperônimo do verbox se a ação verbox é um tipo de verboy (perceber é um hiperônimo de ouvir);
Tropônimo O verboy é um tropônimo do verbox se a ação verbox é um modo particular de verboy de alguma maneira (sussurrar é um tropônimo de falar);
Implicação O verboy é implicado por o verbox se para fazer o verbox eu devo ter feito primeiro o verboy (roncar é implicado por dormir);
Termos coordenados Aqueles termos que compartilham um mesmo hiperônimo (sussurrar e gritar são termos coordenados, pois têm o mesmo hiperônimo, falar);
Adjetivos e advérbios Antônimo Ex..
Forte é antônimo de fraco;
Sinônimo Ex.. Triste é sinônimo de infeliz.
A Wordnet é amplamente utilizada, não apenas como consulta para a obtenção dos termos relacionados a um determinado termo, mas também como tesauro de referência para avaliação de tesauros, conforme será apresentado na subseção 2.1.5 referente a a avaliação de tesauros.
Em Recuperação de Informação (Ri) os tesauros têm um papel importante e, tratando de um domínio específico, eles auxiliam ainda mais os sistemas de Ri, pois podem fornecer desde um controle sobre o vocabulário na indexação dos termos, até adicionar termos semelhantes que visem melhorar a Ri.
Por este interesse em auxiliar os sistemas como os de Ri, muitas vezes as pessoas se veem confrontadas com a questão de criar e manter automaticamente um tesauro de um domínio específico.
Um tesauro pode ser construído automaticamente sem a necessidade de um corpus (isso ocorre, por exemplo, nos casos em que um tesauro é apenas traduzido), ou através de um corpus.
A construção automática de um tesauro se baseia na identificação, de forma automatizada, dos relacionamentos semânticos entre as palavras, encontrando assim palavras mais similares a uma palavra-chave.
Essa identificação automática pode se dar sem o uso de um corpus (como no caso de tesauros construídos apenas por a tradução de outros tesauros), ou com o uso de corpus.
Quando o processo é de construção automática, Ito Classificam os tesauros em dois tipos:
Tesauros relacionais e tesauros associativos.
A seguir, desenvolvemos esses dois conceitos.
Tesauros relacionais Segundo Ito, são tesauros que definem explicitamente os relacionamentos (como &quot;é-um «e «é-parte-de).
Kaji Generalizam essa classificação, denominando esses tipos de tesauros de taxonômicos.
De essa forma, tesauros relacionais (ou taxonômicos) são aqueles que apresentam uma estrutura taxonômica entre seus termos, podendo ser encontradas nesta estrutura relações como Para a geração automática de tesauros taxonômicos, diversas abordagens vêm sendo adotadas.
Em o trabalho de Hearst é feita a extração de hipônimos de um corpus através da busca por padrões.
Um desses padrões, por exemplo, é encontrar a expressão &quot;such as «entre dois sintagmas nominais, o que pode indicar que o sintagma nominal SN2 é um hipônimo de SN1.
Outros trabalhos que exploram a geração de tesauros taxonômicos são descritos trabalhos fazem a extração de termos e construção de uma taxonomia (com relações &quot;is a», &quot;not is a», por exemplo), baseado na estrutura de artigos da Wikipédia.
Tesauros associativos Segundo Kaji, tesauros associativos utilizam a associação semântica entre termos na sua construção.
Assim, pode- se dizer que o significado de um termo é dado por os outros termos que o modificam.
Esse tipo de tesauro pode ser visto como um grafo, onde os conceitos são representados por os nodos e as relações entre os conceitos são representadas por as arestas.
Em o ano de 1954, Zelig S. Harris publicou em seu artigo &quot;Distributional Structure «a hipótese de que palavras tendem a ter o mesmo significado se compartilham de contextos semelhantes.
Baseados nessa hipótese, diversos trabalhos vêm fazendo a identificação dos termos que compartilham os mesmos contextos, para gerar um tesauro.
Alguns, como o de Kaji, utilizam o valor de Informação Mútua entre os termos para a obtenção do tesauro, enquanto que outros trabalhos como o de Grefenstette passam a utilizar uma métrica de similaridade entre contextos sintáticos, para a identificação dos termos.
Ainda, trabalhos como o de Yang e Powers vão além de o trabalho de Grefenstette e utilizam uma adaptação da técnica de Análise Semântica Latente para obter valores relacionados aos termos antes de aplicar uma métrica de similaridade entre os mesmos.
O trabalho de Kilgarriff e Yallop faz a descrição de um algoritmo simplista para a construção automática de tesauros associativos, que é apresentado no Fragmento Fragmento 2.
Algoritmo para a construção automática de tesauros (adaptado de) De essa forma, se o corpus é composto de n termos, cada termo é representado por um vetor de tamanho n..
A similaridade entre dois vetores pode ser computada através de uma fórmula de similaridade, identificando assim os termos mais similares para cada um dos termos do corpus.
Além desses trabalhos, diversos outros vêm sendo propostos na tentativa de identificação dos melhores relacionamentos entre as palavras[ Cro88, CH90, Gre94, Lin98, KMAY00, Gas01, GL03, NHN07, CC07, AMS08, Bin08, INHN08, KHT08, YP08.
LSP09, XU10].
Porém, mesmo sendo a criação automática de tesauros um assunto antigo, cabe ressaltar que ainda é um desafio encontrar os melhores relacionamentos entre as palavras de forma que o tesauro contenha termos que melhor cubram o escopo dos documentos da coleção.
Rapp coloca que, ao computar a similaridade semântica entre termos, é desejável que seja feita uma avaliação dos resultados obtidos e, assim, diferentes métodos de avaliação de tesauros construídos automaticamente têm surgido.
Segundo Yang e Powers não é uma tarefa trivial fazer uma avaliação de tesauro com a ausência de um benchmark.
Pode ser feita uma avaliação subjetiva, observando a similaridade distribucional e avaliando assim a qualidade dos grupos de termos formados.
Porém uma avaliação assim é muito custosa, pois necessita de experts para a correta medição e se torna inviável para um corpus muito grande.
Outra possibilidade de avaliação de um tesauro é através da comparação dos termos resultantes com outros tesauros ou extratos de tesauros já existentes.
Esses outros tesauros ou fontes lexicais já existentes são um gold standard, ou tesauro de referência.
Grefenstette, por exemplo, usou o tesauro de Roget, o tesauro de Macquarie e o Webster's 7 th Dictionary como estruturas de referência.
Em essa avaliação o autor verificava se dois termos estavam localizados no mesmo tópico nos tesauros de Macquarie e de Roget, ou compartilhando duas ou mais definições no Webster's 7 th Dictionary.
Em esse caso ele era contado como um termo válido, sendo assim um sinônimo ou termo semanticamente relacionado.
Yang e Powers fazem a avaliação de modo semelhante, porém é utilizado como gold standard, além de o tesauro de Roget, a WordNet.
Assim, além de as relações de sinônimos/ antônimos providos por a WordNet, conseguem cobrir termos que não têm um relacionamento definido, mas que estão associados a um determinado tópico do tesauro de Roget.
Outros tesauros utilizados como gold standard são o Moby Thesaurus3, utilizado as a Foreign Language (TOEFL), utilizado nos trabalhos de Rapp.
Uma consideração a ser feita quanto a esse tipo de técnica de avaliação é que, em domínios muito específicos, pode ocorrer inviabilidade de utilizar- la.
Em esta seção apresentaremos uma técnica que visa fazer um agrupamento semântico entre termos que compartilham os mesmos documentos.
Essa técnica é chamada de Análise Semântica Latente pois visa encontrar relações entre termos que não são aparentes quando observados somente do ponto de vista de suas frequências nos documentos.
Essa técnica é apresentada devido a o trabalho de Yang e Powers utilizar uma adaptação da mesma para fazer a construção automática de um tesauro.
A seguir são descritas algumas definições de LSA e uma breve descrição do seu funcionamento.
A Análise Semânica Latente (do inglês, Latent Semantic Analysis ­ LSA) é uma técnica que surgiu motivada por a deficiência do modelo vetorial para lidar com sinônimos.
Sahlgren coloca que num sistema de Ri que utiliza um modelo vetorial dificilmente conseguiremos recuperar documentos com a palavra &quot;ship «se utilizarmos como termo para a pesquisa a palavra &quot;boat».
Por fazer um agrupamento dos termos através das relações semânticas existentes entre os mesmos, a técnica de LSA pode ser utilizada para associar termos semelhantes ao termo que está sendo consultado.
De essa forma ao invés de fazer a recuperação de documentos que contenham apenas o termo &quot;ship», o sistema poderá recuperar documentos que contenham o termo &quot;boat», se o mesmo esteja relacionado semanticamente com o termo &quot;ship».
Inicialmente essa técnica foi denominada de LSI, referindo- se a Indexação Semântica Latente (do inglês, Latent Semantic Indexing) e foi apresentada no trabalho de Dumais, porém os autores passaram a referenciar- la também por LSA.
Manning e Schütze colocam que a LSA é uma técnica que projeta termos e documentos dentro de um espaço com &quot;dimensões de semântica latente», isto é, projeta os termos que coocorrem numa mesma dimensão, e os que não coocorrem com ele, em diferentes dimensões.
Com isso, a LSA é uma técnica que faz uma redução de dimensões, partindo de várias dimensões, que representam termos e documentos, e condensando- as em poucas dimensões &quot;latentes «que colapsam termos e documentos com vetores de contexto similares.
Berry Colocam que o LSA assume que existe uma estrutura latente, ou não aparente, no uso das palavras, e que essa estrutura é parcialmente escondida por a variabilidade da escolha das palavras na construção de um texto.
Segundo Landauer, os passos para a descoberta do significado das palavras são:
Fazer uma representação do corpus numa matriz, onde cada linha representa uma única palavra do corpus e cada coluna representa uma passagem ou contexto em que as palavras ocorrem.
Cada célula contém a frequência de ocorrência da palavra (linha) em determinado contexto (coluna).
Neste passo ainda pode ser adicionado um peso que expressa a importância do termo na passagem, e também a importância que o termo tem no domínio em geral.
Esse peso é calculado baseado em entropias das coocorrências como pode ser visto no trabalho de Dumais.
Após, deve- se aplicar sobre a matriz a técnica de Decomposição em Valores Singulares (do inglês, Singular Value Decomposition -- SVD).
A SVD é um modelo matemático que pode ser visto como uma análise de coocorrência de termos através de um método de redução de dimensões de uma matriz.
Através desse modelo, tenta- se encontrar relação entre palavras que podem não ocorrer numa mesma passagem.
Assim, mesmo se uma palavra palx não aparece num documento com a palavra paly, ela pode ter uma correlação alta com paly, desde que elas compartilhem de contextos com significados similares.
Conforme apresentado por Sahlgren, um argumento para a utilização da SVD é que o espaço resultante não tem apenas as relações encontradas &quot;em a superfície», isto é, aquelas que estão na matriz de termos x documentos, mas também são encontradas relações &quot;latentes», isto é, relações que estão implícitas na matriz.
Isso ocorre pois com a aplicação da técnica de SVD, termos com padrões de coocorrência similares passam a ser agrupados juntos.
Manning e Schutze explicam que para encontrar os contextos similares, parte- se de uma matriz original Atxd com t linhas e d colunas, onde t representa os termos dos documentos e d representa os documentos do corpus.
Com isso, o conteúdo do elemento aij será a frequência do termo i no documento j.
O SVD decompõe a matriz Atxd e a representa através de três matrizes Utxn, nxn e Vdxn, onde n $= min (t, d).
A matriz V é rotacionada sobre sua diagonal principal (Vij $= VTji) obtendo- se VTnxd, com isso obtem- se:
Atxd $= Utxn nxn e VTnxd As matrizes U e VT contêm colunas ortonormais, isto é, os vetores-coluna são ortogonais entre eles.
Assim, se uma matriz C tem colunas ortonormais, então CTC $= I, onde I é uma matriz diagonal com valores singulares iguais a 1 na diagonal principal e valores 0 no resto.
Resumindo, da equação 1, obtém- se:
Matriz original de dimensões m x n que relaciona os termos com os documentos;
Matriz ortogonal de dimensões m x k, onde k é um valor entre m e n;
Matriz com valores singulares de dimensões k x k, onde os valores singulares estão ordenados de forma decrescente, sendo nulos nas últimas linhas da matriz;
VT: Matriz ortogonal de dimensões k x n, onde o T indica que é a matriz V transposta (isto é, as colunas são linhas e as linhas viram colunas).
Um problema ao se trabalhar com matrizes termos x documentos é que 99% das células conteriam valor zero, já que a grande maioria das palavras somente ocorrem num número muito limitado de contextos.
Porém, com a aplicação da SVD a matriz resultante será uma matriz de dimensões reduzidas, se comparada à matriz original.
Essa decomposição pode obter como resultado três tipos de matrizes:
Matriz de comparação termo-termo:
Âk $= U 2 UT Matriz de comparação termo-documento:
Âk $= U VT Matriz de comparação documento-documento:
Âk $= V 2 VT Por fim, uma medida de similaridade é utilizada no espaço dimensional reduzido, completando assim o processo de inferência das palavras ou passagens.
Normalmente neste processo é utilizada a medida da distância entre os dois vetores (utilizando a abordagem do Cosseno).
Este capítulo apresenta trabalhos que estão relacionados à construção automática de tesauros a partir de corpus.
Para facilitar o entendimento das técnicas utilizadas, os trabalhos foram separados em três grupos:
Trabalhos que utilizam técnicas baseadas em janelas, trabalhos que utilizam técnicas baseadas em sintaxe, e por fim, trabalhos que, além de necessitarem da anotação sintática do corpus, ainda procuram por relações semânticas entre os termos para a identificação dos termos relacionados na construção do tesauro.
As técnicas aqui descritas, embora utilizem em sua grande parte apenas métodos estatísticos para fazer a criação de um tesauro, incluem aquelas em que é utilizado conhecimento linguístico básico, onde os termos do corpus podem ser anotados com (POS) tagger.
Porém, não foram incluídos trabalhos onde um conhecimento mais profundo da língua é necessário, exigindo a análise sintática das frases do corpus.
O trabalho de Crouch, seguido por Crouch e Yang, apresenta a criação automática de um tesauro global.
Por tesauro global entende- se um tesauro que é criado uma vez e pode ser usado num ambiente de recuperação de informação para indexar tanto documentos como consultas.
Um tesauro local, por sua vez, é gerado dinamicamente a cada consulta que é realizada no sistema.
Em esse trabalho, a criação automática de um tesauro é realizada baseando- se no discriminatório indica o quanto um termo é representativo para um documento, de acordo com a frequência desse termo no documento e de acordo com a frequência do mesmo na coleção de documentos.
Esses valores discriminatórios podem ser de três tipos, onde n é a quantidade de documentos na coleção:
Indiferentes: No caso de os termos em que a frequência de ocorrência nos documentos é menor do que o n/ 100.
São considerados termos com baixas frequências.
Discriminatórios pobres:
No caso de os termos cuja frequência é maior do que n/ 10.
Esses são considerados termos de alta frequência.
Discriminatórios bons:
Em os casos restantes, ou seja, termos com uma frequência entre n/ 10 e n/ 100.
O tesauro deve ser composto por termos que estão intimamente relacionados na coleção.
Para isso, é utilizado um método de agrupamento (clustering), onde os termos que contêm um valor discriminatório indiferente, isto é, termos com baixas frequências nos documentos, servirão para criar as classes dos agrupamentos.
Os termos restantes dos documentos são agrupados dentro de essas classes.
O problema dessa técnica ocorre quando todos os termos têm frequências baixas, ou seja, pouca informação para ser adquirida e, com isso, os agrupamentos podem ficar pouco significativos.
O trabalho de Church e Hanks utiliza a Informação Mútua, que compara a probabilidade de observar os termos ti e tj juntos (a probabilidade da junção) com a probabilidade de observar os termos ti e tj independentemente.
Sendo P (ti) e P (tj) a probabilidade do termo ti e do termo tj respectivamente, e P (ti, tj) a probabilidade dos termos ti e tj aparecerem juntos, define- se a Informação Mútua IM (ti, tj) entre os termos ti e tj como sendo:
Se existe uma associação entre ti e tj, então a probabilidade P (ti, tj) de aparecerem juntos será muito maior do que a probabilidade de encontrar somente ti ou somente tj e, consequentemente, a informação mútua terá um valor IM (ti, tj)\&gt; 0.
Porém, se não existe uma relação significativa entre ti e tj, então a probabilidade de encontrar ti e tj juntos será praticamente a mesma de encontrar- los sozinhos P (ti, tj) P (ti) P (tj) e a informação mútua entre eles será IM (ti, tj) 0.
Entretanto, se ti e tj raramente aparecem juntos, a probabilidade de ambos será muito menor do que a probabilidade de cada um de eles em separado, forçando assim IM (ti, tj) 0.
Uma explicação mais simplista é dada por Manning, e diz que a Informação Mútua mede o quanto um termo nos fala a respeito de outro.
Essa medida verifica então a probabilidade de um termo andar sempre com outro.
Embora o trabalho de Church e Hanks não vise à criação automática de tesauros, ele serve de suporte para esta tarefa, pois esse trabalho fornece a base estatística de uma interessante variedade de fenômenos linguísticos.
Essa variedade de fenômenos linguísticos permitiria incluir a utilização de termos com &quot;médico «quando uma pessoa é perguntada por um termo semelhante a &quot;enfermeiro».
O trabalho de Kaji Utiliza uma abordagem de associação entre as palavras, também conhecida como associação de primeira ordem.
Essa abordagem propõe que a similaridade semântica possa ser computada por o entendimento lexical entre os vizinhos.
Por exemplo, a similaridade semântica entre as palavras vermelho e azul pode ser definida por o fato de que ambas coocorrem frequentemente com palavras como cor, flor, carro, escuro, claro, e assim por diante.
Assim, para calcular o grau de similaridade entre as palavras que coocorrem, esse trabalho utilizou a medida de Informação Mútua, proposta por Church.
A criação de tesauro proposta por Kaji Consiste na extração de termos, extração de coocorrências dos termos e análise de correlação, como mostrado na Figura 3.1.
A seguir no texto é explicado cada passo para a geração automática de tesauros a partir de corpus, segundo estes autores.
Extração de termos Kaji Colocam que os melhores termos para representar conceitos são substantivos, simples ou compostos, que ocorrem frequentemente no corpus.
Por isso, são extraídos do texto substantivos simples e compostos em que a frequência de ocorrência ultrapassa um determinado limiar pré-estabelecido.
Para a extração também é utilizada uma stoplist.
Essa stoplist é utilizada para fazer uma filtragem no corpus, retirando assim os termos que sabidamente não apresentam interesse nessa relação.
Em a extração de termos compostos também é necessária a utilização de uma stoplist, já que muitos termos compostos extraídos não constituem um bom termo, pois são combinações de palavras sem significado para o texto.
Kaji Utilizaram uma stoplist para o primeiro e uma para o último elemento do termo composto, eliminando assim termos sem significado relevante.
Outro problema encontrado ao se extrair termos compostos é a ambiguidade estrutural dos termos, isto é, termos compostos que podem conter outros termos compostos dentro de eles.
Para isso, Kaji Classificaram os termos compostos em nãomáximos e máximos.
Um termo composto não-máximo é aquele que faz parte de um termo composto maior e um termo composto máximo é aquele que não é parte de um termo composto maior.
Assim, para a correta extração de termos compostos não máximos foi desenvolvido um método estatístico de desambiguação estrutural, descrito a seguir.
Desambiguação estrutural A regra geral do método de desambiguação estrutural é dada como:
Se existe um termo composto CN que inclui dois termos candidatos máximos CN1 e CN2, e esses termos são incompatíveis entre si, então, se um dos dois candidatos é mais frequente, a estrutura de CN incluindo a estrutura desse candidato mais frequente é escolhida.
Assim, podemos citar como exemplo o caso de um termo composto por três elementos W1 W2W3.
Esse termo composto pode ser constituído de duas possíveis estruturas W1 (W2 W3) ou (W1 W2) W3.
Assim é verificado no corpus se o termo composto máximo W2 W3 ocorre mais vezes do que o termo composto W1 W2 e então a estrutura W1 (W2 W3) é preferida.
De o contrário, se o termo composto máximo W1 W2 aparece mais vezes do que o termo W2 W3, então a estrutura W3 é preferida.
Para a contagem de frequências dos termos compostos máximos, Kaji Utilizaram duas abordagens.
São elas:
A estatística global das frequências, isto é, contaram as frequências dos termos compostos do corpus inteiro e essas serviram para desambiguar todos os termos compostos do corpus;
E a estatística local das frequências, isto é, contaram as frequências dos termos compostos em cada documento e assim usaram- nas para desambiguar somente os termos do documento correspondente.
A avaliação desses dois métodos mostrou que o método baseado em estatística local obteve melhores resultados do que o método baseado em estatística global para a desambiguação dos termos compostos.
Extração de coocorrências e análise de correlação Em a extração de coocorrências é coletado qualquer par de termos semanticamente ou contextualmente associados, não importando o tipo de associação.
Em esse trabalho foi utilizada uma técnica de janela para a extração.
A técnica de janela extrai pares de termos que ocorrem juntos dentro de uma janela que vai se movendo através do texto.
Essa janela é composta por um conjunto de sentenças de n palavras, sendo n um número previamente escolhido.
O tamanho da janela pode ser escolhido arbitrariamente e, devido a o custo computacional, os autores escolheram um tamanho de janela entre 20 e 50 palavras.
Esses pares de palavras ainda são filtrados para que não apareçam pares de substantivos compostos que já foram previamente extraídos, pois se eles fossem incluídos na extração de coocorrência, isso causaria redundância.
Em o processo de análise de correlação os autores predeterminaram um número máximo de termos associados a cada termo e um limiar para a Informação Mútua, diminuindo assim a quantidade de termos recuperados.
Os termos que compõem o tesauro são selecionados com base na ordem decrescente de Informação Mútua.
Em e posteriormente em é utilizada a estrutura da Wikipédia para a construção de um tesauro associativo.
Esse tesauro é baseado no montante de informações que podem ser obtidas através da análise da estrutura da mesma, principalmente através dos hyperlinks contidos em cada um dos seus artigos.
Para analisar a relevância dos hyperlinks de cada página e posteriormente encontrar as páginas mais semelhantes, foi desenvolvida uma medida baseada no cálculo de Frequência do Termo ­ Frequência Inversa do Documento (do inglês, Term Frequency ­ Inverse Document Frequency -- TF-IDF), que os autores chamaram de Path Frequency Inversed Backward link Frequency (PF-IBF).
Essa medida foi criada com base na ideia que uma página que compartilha hyperlinks com uma página específica e não compartilha com outras páginas, tem um alto valor de PF-IBF com esta página específica.
O tesauro é criado verificando- se todas as conexões da Wikipédia e calculando para cada uma de elas o valor de PF-IBF.
Com isso, os conceitos que têm maior valor de PF-IBF aparecerão associados no tesauro.
A técnica aqui descrita necessita, além de métodos estatísticos, também de ter o corpus anotado por um analisador sintático, conhecendo assim as categorias gramaticais dos termos e a função dos mesmos na frase.
Assim, podem- se obter relações sintáticas entre termos, como o sujeito, o objeto direto ou o objeto indireto de um verbo, por exemplo.
Grefenstette descreve a criação de um tesauro a partir de textos, porém baseado em sintaxe, isto é, que utiliza os contextos sintáticos para o cálculo da similaridade entre as palavras para a construção do tesauro.
Entende- se por contexto sintático qualquer conjunto de palavras que estabeleçam uma relação sintática com outra palavra no corpus.
Para estabelecer esse contexto podem ser identificadas diversas relações sintáticas entre as palavras, como sujeito, objeto etc..
Esse trabalho foi o primeiro a utilizar informações sintáticas e também foi um dos primeiros a encontrar palavras semanticamente similares (baseadas na sintaxe) através de uma busca automática.
Ele ainda apresenta o sistema SEXTANT (Semantic EXtraction similaridade entre as palavras.
Para a construção do tesauro, Grefenstette faz a extração de determinados contextos sintáticos das palavras e através de eles faz a associação entre as palavras utilizando a medida de similaridade de Jaccard ponderada.
Como resultado, o autor obtém uma lista de palavras semanticamente relacionadas a cada substantivo do corpus.
Em esta técnica são comparados sintagmas nominais, a fim de identificar aqueles que são semanticamente relacionados.
Para a criação do tesauro, Grefenstette realiza os seguintes passos para a obtenção de listas de palavras relacionadas:
Tokenizar o corpus com uma gramática regular.
Os tokens são morfologicamente analisados e um léxico provê as categorias (para então chegar- se ao POS tagging) de cada token;
O texto etiquetado passa por um desambiguador estocástico, deixando cada token com apenas uma etiqueta, isto é, eliminando as ambiguidades.
O texto sem ambiguidades passa por um parser que etiqueta os sintagmas nominais e verbais.
Esses sintagmas é que permitem identificar se um substantivo está ligado a um verbo como sujeito ou como objeto.
São extraídos todos os contextos sintáticos de cada palavra em todas as suas ocorrências no corpus.
São extraídos todos os contextos sintáticos em que os substantivos estão relacionados com adjetivos e sintagmas preposicionais que os modificam.
Se os substantivos estão conectados a um verbo, são extraídos os contextos sintáticos, identificando se fazem papel de sujeito ou objeto.
É utilizada a medida de similaridade para gerar uma lista de palavras semelhantes.
A medida é uma variante da medida de Jaccard (apud), que utiliza pesos associados aos contextos sintáticos.
As duplas de palavras mais similares, isto é, com uma medida de similaridade mais alta, formarão o tesauro daquele conceito.
Assim, a medida de Jaccard ponderada identificará como palavras mais similares aquelas que compartilham um número significativo de contextos semelhantes.
A seguir é explicado o que são os contextos sintáticos e, posteriormente, como é medida a similaridade entre as palavras.
Contextos sintáticos Grefenstette extrai os contextos sintáticos das palavras que aparecem num mesmo sintagma nominal ou entre o núcleo de um sintagma nominal e o núcleo de um sintagma verbal relacionado.
Assim, uma relação sintática é denotada por uma tripa:
Em essa tripla, R é uma relação do tipo:
ADJ: Um adjetivo que modifica um substantivo;
NN: Um substantivo que modifica outro substantivo (especialmente presente na língua inglesa);
Nnprep: Um substantivo que modifica outro substantivo utilizando uma preposição;
SUBJ: Um substantivo que tem o papel de sujeito de um verbo;
DOBJ: Um substantivo que tem o papel de objeto direto de um verbo;
IOBJ: Um substantivo que é objeto indireto de um verbo.
A Tabela 3.1 apresenta alguns exemplos das relações sintáticas extraídas por Grefenstette em seu trabalho.
Assim, para cada palavra no texto são encontradas as relações sintáticas em que ela aparece.
Grefenstette não faz diferenciação entre as relações ADJ, NNPREP e NN, porém, quando um substantivo é objeto direto de um verbo, ele é identificado de forma diferente, não misturado aos outros contextos sintáticos para a mesma palavra.
Assim, no exemplo da Tabela 3.1, os contextos sintáticos da palavra cause seriam:
Medida de similaridade Para fazer a construção do tesauro é necessária uma medida que permita agrupar as palavras.
Grefenstette calcula a similaridade entre duas palavras, palm e paln em função de a quantidade de contextos sintáticos que elas compartilham.
Para o cálculo, Grefenstette leva em conta os pesos globais e pesos locais de cada palavra no contexto sintático.
O peso global pg leva em conta a quantidade de palavras diferentes que estão associadas ao contexto csj no corpus e pode ser computado por a fórmula citada também no trabalho de Gasperin:
Onde f (pali, csj) representa a frequência com que a palavra i ocorre no contexto sintático j, f (csj) representa a frequência desse contexto sintático no corpus, e npals representa o número de palavras diferentes no corpus.
O peso local pl é baseado na frequência do contexto sintático como modificador de uma palavra e pode ser calculado por:
O peso total pt é calculado com a multiplicação dos pesos locais e globais.
Assim, a medida de Jaccard ponderado JP entre duas palavras palm e paln é calculada por:
Min,, max,, Depois de computada a similaridade para todos os contextos do corpus, são geradas listas de palavras mais semelhantes para cada palavra do corpus.
Essas listas de palavras mais semelhantes é que compõem o tesauro.
O artigo descrito em relata a criação de um tesauro baseada na extração de contextos sintáticos para cada termo.
É feita, além de a extração de contextos sintáticos para substantivos (como era feita por Grefenstette), a extração para adjetivos, verbos e advérbios.
Para essa extração, são identificadas triplas no corpus anotado sintaticamente.
Essas triplas são compostas de dois termos e a relação gramatical existente entre eles na frase.
Como exemplo, da frase &quot;I have a brown dog.»
são extraídas as triplas:
Essas triplas são da forma (w, r, w'), onde w e w'são termos e r é a relação existente entre esses termos.
Em o exemplo citado, temos a relação (have, subj, I), sendo o termo &quot;I «o sujeito do verbo &quot;have».
Lin considera não só o sentido direto da relação sintática, mas também o sentido inverso da mesma.
Assim, de uma relação de sujeito entre &quot;I «e &quot;have», são extraídos os contextos (have subj I) e (I subj-of have).
Lin acredita que, quanto maior a quantidade de contextos sintáticos de uma palavra, maior a confiabilidade dos resultados da comparação com as demais palavras.
Para a construção do tesauro, Lin propôs uma medida de similaridade que leva em conta o valor de informação contido numa relação e o valor de informação contido em todas as relações que os termos da primeira compartilham no corpus.
As palavras que tiverem os valores da medida de similaridade mais altos com relação a uma dada palavra formarão a lista de palavras mais similares a tal palavra do corpus.
Gasperin faz a geração automática de um tesauro para a língua portuguesa, criando uma extensão da proposta de Grefenstette.
Em essa proposta, a autora integra as seguintes extensões ao trabalho de Grefenstette:
Leva em conta a bidirecionalidade das relações gramaticais, como foi feito no trabalho de Lin;
Diferência as relações sintáticas extraídas, não diferenciadas no trabalho de Grefenstette, como ADJ e NNPREP;
Adiciona a relação entre substantivos de um mesmo verbo (SOBJ), quando um de eles era sujeito e o outro objeto desse verbo;
Leva em conta a preposição quando a mesma está numa relação entre substantivos.
Por exemplo, numa relação &quot;marca de camisa «ou &quot;marca na camisa», Grefenstette extrai o mesmo contexto sintático para ambas.
Levando em conta a preposição, são extraídos dois contextos sintáticos diferentes.
Para a construção do tesauro, é utilizada a medida de similaridade de Jaccard ponderado como apresentado no trabalho de Grefenstette, obtendo uma lista com os termos mais similares a um determinado termo.
As técnicas descritas a seguir utilizam a Análise Semântica Latente (do inglês, Latent Semantic Analysis -- LSA), ou adaptações da mesma, para descobrir relações &quot;latentes «entre os termos, isto é, relações que não são aparentes se considerarmos apenas a frequência dos termos nos documentos.
O trabalho de Dumais, que foi o primeiro a utilizar a aplicação da LSA, inicialmente chamada LSI.
Em esse trabalho, Dumais Aplicaram a técnica de LSA para a recuperação de documentos médicos num banco de dados composto por 1033 títulos de resumos de documentos médicos.
A recuperação de documentos com a aplicação da LSA foi feita sobre 30 consultas disponíveis no banco de dados.
Com a aplicação da LSA, obtiveram uma precisão de 0.51, enquanto que com recuperação por term matching, isto é, a recuperação buscando a mesma ocorrência do termo na consulta e no documento, foi de 0.45.
Essa melhor precisão na obtenção dos documentos mostrou que a técnica de LSA conseguia encontrar relações entre os termos que eram perdidas por o term matching.
Em 1989 os autores do trabalho registraram a patente &quot;Computer information «referente a o método de recuperação de documentos utilizando a LSA.
A partir de 1993 Dumais começou a participar do Text REtrieval Conference (TREC) apresentando os trabalhos e mostrando a eficiência da técnica de LSA quando aplicada na coleção do TREC.
Em 1997, Landauer e Dumais no trabalho buscaram encontrar associações que acontecem na memória humana, como aquela devida à similaridade entre termos.
Para identificar esse tipo de associação os autores utilizaram os espaços gerados por a Análise Semântica Latente, visando identificar os termos que ocorriam nas mesmas dimensões espaciais.
A técnica de LSA foi utilizada por o fato da mesma associar termos que ocorrem em padrões similares nos documentos, mesmo se eles não coocorrem dentro de um documento.
Como teste, Landauer e Dumais utilizaram o corpus do Test Of English as a Second Language (TOEFL) que contém 80 questões de múltipla escolha, cada uma de elas contendo 4 alternativas de resposta, sendo uma de elas (resposta correta) composta por os sinônimos.
Após fazer a aplicação da LSA no corpus e encontrar as respostas para as respostas do questionário, Landauer e Dumais observaram que fazendo a indução do conhecimento indiretamente utilizando a coocorrência dos termos num corpus com uma grande quantidade de documentos (como o corpus do TOEFL), a técnica de LSA adquire um conhecimento sobre o vocabulário de inglês comparável ao conhecimento obtido por estudantes.
O trabalho de Yang e Powers apresenta uma proposta de criação de tesauros que utiliza, além de informações linguísticas, uma adaptação da técnica de LSA.
Em esse trabalho Yang e Powers colocam que a maioria dos métodos de construção de tesauros simplesmente ignora a saliência das relações gramaticais e efetivamente fundem- nas em apenas um único contexto.
Yang e Powers colocam que os algoritmos para construção de tesauros normalmente calculam a distribuição das palavras num vetor de termos e esse cálculo pode ser sintaticamente condicionado (e.
g através de relações gramaticais), como apresentado no trabalho de Grefenstette ou não condicionado (e.
g através da Embora os métodos que utilizam relações gramaticais consigam ter uma eles também juntam as dependências sintáticas num contexto unificado na construção de um tesauro.
De essa maneira, não conseguem mostrar diferenças latentes nas relações gramaticais para a determinação do significado da palavra num contexto.
Para obter melhores resultados, Yang e Powers propõem primeiramente categorizar os contextos em termos de relações gramaticais, e então utilizar uma adaptação da técnica de LSA para as categorias gramaticais, de forma a obter as relações latentes entre os termos.
Como resultado, é obtida uma matriz de termos relacionados semanticamente.
Essa matriz pode ser interpretada de forma que o produto do cosseno entre as linhas dessa matriz representa a similaridade entre dois termos.
Segundo Yang e Powers, a representação sintática principalmente depende dos seguintes fundamentos:
O significado de um substantivo depende de seus modificadores, como adjetivos, outros substantivos ou núcleos nominais de sintagmas preposicionais, bem como do papel gramatical de um substantivo como sujeito ou objeto de uma frase;
O significado de um verbo depende do seu objeto direto, sujeito ou modificador como, por exemplo, o núcleo nominal num sintagma preposicional.
Com base nesses fundamentos, sabe- se então que as dependências sintáticas podem prover pistas para encontrar o significado de uma palavra dentro de um contexto.
Tendo- se uma tupla r, wj\&gt;, onde wi e wj representam duas palavras e r é a relação de dependência, se wi modifica wj através de r, então todos os wj com um modificador r formarão um contexto para wi, assim como wi formará para wj.
Assim, essas dependências sintáticas (r) podem se classificar em quatro grupos:
RV: Verbos com seus modificadores, como todos os advérbios e os núcleos nominais de sintagmas preposicionais;
AN: Substantivos com seus modificadores, como adjetivos e pré/ pos modificadores;
SV: Sujeitos e seus predicados;
E -- VO:
Predicados e seus objetos.
Para obter essas dependências Yang e Powers utilizaram o parser Link Grammar.
Em o total existem 107 tipos de conexões detectadas por esse parser.
De esses 107 tipos, alguns foram extraídos por Yang e Powers e classificados nos seguintes grupos previamente descritos:
E: Verbos e seus advérbios pré-modificadores EE:
Advérbios e seus advérbios pré-modificadores Verbos seus pós-modificadores, como preposicionais A:
Substantivos e seus adjetivos pré-modificadores AN:
Substantivos e seus substantivos pré-modificadores GN:
Substantivos que estão ligados a nomes próprios advérbios sintagmas M:
Substantivos e seus vários pós-modificadores como sintagmas preposicionais, adjetivos e particípios S:
Sujeito-substantivos/ gerúndios e seus verbos finitos.
Derivados de S, como Ss* g para gerúndios e os seus predicados, Sp para substantivos plurais etc..
Si: Sujeito e seus verbos quando ocorre a inversão do sujeito e do verbo em questões O:
Verbo e seus objetos diretos e indiretos OD:
Verbos e seus complementos de distância OT:
Verbos e seus objetos de tempo P:
Verbo &quot;ser «conectado às palavras que podem ser seus complementos.
Derivados de P, como Pp quando o verbo &quot;ser «está conectado com uma preposição, ou Pa quando o verbo &quot;ser «está conectado com um adjetivo etc..
Após fazer o processamento do corpus, Yang e Powers extraem os relacionamentos para construir quatro matrizes paralelas ou conjuntos de coocorrência, denominados Rx:
RVx, ANx, SVx e Vox em termos de os quatro grupos de dependências sintáticas.
As linhas dessa matriz são denominadas Rvx, Anx, Svx e Vox e as colunas são denominadas rVx, aNx, sVx e vOx respectivamente.
Consideremos SVx uma matriz mxn que representa as dependências de sujeito e como sujeitos.
Em a Tabela 3.2 é mostrado um exemplo de como ficará a matriz SVx, onde as frequências freq_ i_ j representam as frequências de ocorrência do substantivo_ i com o verbo_ j.
Após a obtenção das matrizes de dependência sintática, o próximo passo para a construção do tesauro é realizar a normalização dos termos.
Esse processo é feito substituindo a frequência de cada célula freq (Xi, j) por o valor da sua informação, usando log (freq (Xi, j)+ 1), diminuindo assim o espaço existente entre eventos muito frequentes e eventos raros.
Após, aplica- se uma adaptação da técnica de LSA, para encontrar eventos mais surpreendentes, ao invés de apenas fazer a redução da matriz esparsa obtendo Por fim, Yang e Powers procuram por os termos mais semelhantes contidos na matriz gerada por o processo de LSA.
A similaridade distribucional é utilizada para a comparação dos valores da matriz resultante Â.
Para a obtenção dos termos é normalmente utilizado um método de comparação de vetores.
A medida do Cosseno obtém o ângulo formado por dois vetores e pode ser definida como:
Onde| x| e| y| são a Norma Euclidiana dos vetores x e y respectivamente, isto é, representam o comprimento dos vetores.
Assim, os autores constroem o tesauro utilizando o método adaptado do LSA.
Em este capítulo é descrito o processo de criação de uma ferramenta para a geração automática de um tesauro baseado no método de Kaji, dois tesauros baseados no método desenvolvido por Grefenstette e dois tesauros baseados no método apresentado por Yang e Powers.
O capítulo começa apresentando o corpus utilizado e, a seguir, o modo como foi realizada a criação da ferramenta que implementa os três métodos descritos.
Para a geração dos tesauros associativos foram escolhidas abordagens que utilizam um corpus para a identificação dos termos relacionados.
Para a criação desse corpus, foram coletados documentos do domínio legal e de acesso público.
Esses documentos foram obtidos de sites governamentais que disponibilizam leis, normas ou guidelines do domínio legal.
Todos os documentos foram obtidos com versões em língua inglesa das normas, sendo aproximadamente metade dos documentos obtidos de normas dos Estados Unidos.
Austrália, Nova Zelândia, Unido e Canadá são outros países com grande porcentagem de documentos, restando aproximadamente 20% dos documentos referentes a países que não têm a língua inglesa como idioma oficial.
Embora países como Espanha, Coréia, China e Japão não tenham a língua inglesa como idioma oficial, os documentos recuperados são traduções oficiais das leis desses países.
A partir de essas fontes, foi coletado um total de cem documentos, sendo o maior documento, uma lei americana contendo 72 mil palavras, e o menor documento, uma lei australiana, contendo 128 palavras.
A coleção de documentos é composta por um total de 1.122.836 palavras.
A Tabela 4.1 apresenta algumas estatísticas sobre o corpus utilizado.
Uma dificuldade encontrada ao lidar com textos do domínio legal refere- se à estrutura do texto no documento, composta de itens e subitens, tabelas, parágrafos etc..
Para um melhor aproveitamento por o analisador sintático, os textos que compõem o corpus foram previamente tratados.
Em este tratamento foram retiradas tabelas, referências a figuras, marcações de itens e caracteres especiais como, por exemplo, o símbolo de parágrafo(§).
O Fragmento 3 apresenta um recorte da lei americana &quot;Unfair or deceptive «no formato original e o Fragmento 4 apresenta a mesma lei após o tratamento.
Fragmento 3.
Recorte da lei sem tratamento Unfair Acts or Practices· Assessing whether practice is unfair· An act practice is unfair where it causes or is likely to cause substantial is not outweighed by countervailing benefits to consumers or to competition.
The act or practice must cause or be likely to cause substantial injury to consumers.
Te o be unfair, an act or practice must cause or be likely to cause substantial injury to consumers.
Fragmento 4.
Recorte da lei após o tratamento Unfair Acts or Practices.
Assessing whether practice is unfair.
An act practice is unfair where it causes or is likely to cause substantial injury to countervailing benefits to consumers or to competition.
Public policy be these elements is discussed further below.
The act or practice must cause or be likely to cause substantial injury to consumers.
Te o be unfair, an act or practice must cause or be likely to cause substantial injury to consumers.
Para a criação dos tesauros baseados em sintaxe e dos tesauros baseados em Análise Semântica Latente, os textos do corpus foram analisados por o analisador sintático desenvolvido em Stanford4.
Este analisador sintático utiliza Gramáticas livres de contexto probabilísticas (do Inglês, Probabilistic Context-Free Grammars ­ PCFG) para fornecer uma representação gramatical das relações entre palavras numa sentença.
Este analisador sintático foi escolhido por ter um alto desempenho com textos em língua inglesa, se comparado com outros analisadores para a mesma língua, como os apresentados no trabalho de Mollá e Hutchinson.
Segundo Klein e Manning em, este analisador sintático tem uma taxa de acerto de 86,36%.
Infelizmente até a versão utilizada do analisador sintático, o mesmo não oferecia a opção de lematização dos termos do corpus.
O Fragmento 5 apresenta um trecho do corpus depois de analisado sintaticamente, onde estão em negrito as etiquetas utilizadas para identificar os termos e as relações entre os mesmos, e em itálico as dependências entre os termos.
Inicialmente o analisador sintático cria a estrutura em árvore da sentença, etiquetando, além de a classe gramatical do termo, também as relações sintáticas do termo na frase.
De essa forma obtemos, do exemplo dado no Fragmento 5, o termo &quot;Customer», que está marcado como &quot;NNS».
Este termo é um substantivo, marcado com a etiqueta &quot;NN «e seguido de &quot;S «significando que o mesmo está no plural.
Ainda dessa forma, outras categorias morfossintáticas podem ser observadas como, por exemplo, a etiqueta &quot;JJ «para adjetivos, a etiqueta &quot;VB «para verbos etc..
As etiquetas dos termos seguem o padrão Penn Treebank e podem ser encontradas no Anexo A deste trabalho.
Mais detalhes a A segunda fase da análise de cada frase é composta por a identificação das relações entre os termos na frase.
Em essa fase são marcadas relações entre adjetivos e substantivos, substantivos e outros substantivos, verbos com seu sujeito e objetos direto e indireto etc..
Assim, observando o exemplo dado no Fragmento 5, a relação &quot;nsubj «pode ser entendida como:
O termo &quot;Customers «(que ocupa a primeira posição na frase) é o predicativo do sujeito para o verbo &quot;provide «(que ocupa a terceira posição na frase).
De essa forma, outras relações entre termos podem ser relação entre um adjetivo e um substantivo etc..
A forma como são extraídas as dependências e o significado de cada dependência podem ser encontrados no trabalho Para a extração dos contextos sintáticos no processo de geração automática dos tesauros, foram identificados no texto marcado por o analisador sintático as etiquetas morfossintáticas e as etiquetas das funções sintáticas das palavras.
Estas etiquetas são apresentadas na Tabela 4.2.
Em a Tabela 4.2 a cadeia&quot;[*] &quot;significa «quaisquer caracteres».
Como exemplo, são extraídos, além de termos marcados como &quot;NN «(substantivos no singular), também &quot;NNS «(substantivos no plural), &quot;NNP «(nome próprio no singular) e &quot;NNPS «(nome próprio no plural).
Para relações sintáticas, são extraídos &quot;nsubj «(sujeito nominal), &quot;subj «(sujeito) e &quot;nsubjpass «(sujeito na voz passiva).
Como pode ser observado, o analisador sintático utilizado fornece as etiquetas para os termos e para as relações entre termos, porém não fornece a forma canônica dos termos, isto é, a forma como o termo é, sem flexões de gênero, número ou grau.
Como o analisador sintático não faz esta diferenciação entre os termos, ao fazer a extração dos contextos sintáticos serão tratados como dois termos diferentes os termos que aparecerem nas formas plural e singular, por exemplo.
Em a geração do tesauro esse tipo de diferenciação trouxe resultados positivos e negativos.
Por um lado, foram observados termos tratados diferentemente apenas por a declinação de número, o que poderia ter aumentado a quantidade de relações do termochave com outros termos relacionados, caso houvesse essa normalização.
Por outro lado, foi observado que, na maioria dos casos, quando existia o plural do termo-chave no corpus, ele aparecia como o termo mais similar ao termo-chave.
Essa aparição tende a confirmar a correção do método de geração automática do tesauro, visto que o termochave no plural tende a compartilhar os mesmos contextos sintáticos que o termo-chave no singular.
Em as seções seguintes serão descritas as etapas para a criação do tesauro em cada um dos três métodos descritos anteriormente.
O primeiro é o tesauro gerado por o método de Kaji, o segundo tesauro é gerado por o método de Grefenstette e por fim, o terceiro tesauro é gerado por o método de Yang e Powers.
Para a criação do tesauro baseado no trabalho de Kaji, denominado T1, foram criadas funcionalidades para atender às etapas específicas de:
Tesauro Em esta etapa são extraídos os termos compostos por duas palavras (bigramas) e por três palavras (trigramas).
Esse tipo de extração é feito por uma ferramenta desenvolvida por Banerjee e Pedersen chamada Ngram Statistical Package (NSP) 5.
Detalhes sobre a ferramenta NSP podem ser encontrados no trabalho de Banerjee e Pedersen.
Depois de extraídos todos os bigramas e trigramas foi criada uma funcionalidade para verificar qual estrutura era mais frequente usando a mesma proposta descrita no bigramas e trigramas que são marcados no corpus original como termos que contêm uma palavra apenas (unigrama).
Isso é feito através da união das palavras com o caractere sublinha&quot;».
Por exemplo, o termo &quot;personal information «foi identificado no corpus como sendo um bigrama, logo ele é substituído por o termo &quot;personal_ information «que passa a ser identificado como um unigrama.
O processo de extração de coocorrências utiliza a ferramenta NSP para fazer a identificação de termos que coocorrem dentro de uma janela.
A ferramenta permite ao usuário selecionar o tamanho da janela para a extração dos termos que coocorrem.
A extração das coocorrências foi executada para uma janela contendo 30 termos, pois O resultado da extração de coocorrências é um arquivo texto contendo todas as coocorrências contidas no corpus dentro de uma janela de 30 termos, com a frequência com que aparecem essas coocorrências, seguida da frequência com que o primeiro termo aparece junto a outros termos na primeira posição do bigrama, seguido da frequência com que o segundo termo aparece junto a outros termos na segunda posição do bigrama.
O Fragmento 6 apresenta um trecho da lista de coocorrências extraídas do corpus com suas respectivas frequências.
Fragmento 6.
Exemplos de extração de coocorrências do corpus personal_ data\\&gt; 747 28148 43793 processing\\&gt; personal_ data\\&gt; 716 21573 28196 subsection\\&gt; person\\&gt; 662 45969 60090 processing\\&gt; data\\&gt; 604 21573 43793 Esta etapa utiliza a ferramenta NSP para fazer o cálculo da Informação Mútua (IM) entre os termos que coocorrem no corpus.
Este cálculo é apresentado na subseção 3.1.2.
Como resultado do cálculo, a ferramenta gera uma lista com os termos relacionados, a posição do termo de acordo com o valor de IM entre os demais termos, a frequência de ocorrência do bigrama, a frequência do primeiro termo acompanhado de outros termos, estando na primeira posição do bigrama, e a frequência do segundo termo quando acompanhado de outros termos, estando na segunda posição do bigrama.
O Fragmento 7 apresenta um trecho do resultado da aplicação da IM para o termo &quot;personal_ information», apresentando os termos relacionados com maior valor de IM.
Fragmento 7.
Exemplo de valores de IM para o termo &quot;personal_ information «N-gram Rank Mutual Information personal_ information\\&gt; ibm_ web_ site personal_ information\\&gt; ibm personal_ information\\&gt; personal 58028 Frequency A partir de a lista gerada com o valor da IM de cada par de termos, foi criado um programa para fazer a extração dos termos e o valor da IM para cada termo-chave dado como entrada, gerando o tesauro T1.
Foi gerado um arquivo no formato XML com dez termos relacionados para cada termo-chave de entrada.
O arquivo XML foi criado para fazer a aplicação do tesauro numa ferramenta de recuperação de informações.
Os termos relacionados do tesauro são ordenados no arquivo XML com base na forma decrescente do valor de IM.
O Fragmento 8 apresenta um trecho do arquivo XML gerado para a ferramenta de visualização.
Fragmento 8.
Trecho do arquivo XML para a ferramenta de visualização id $= &quot;9 «term_ id $= &quot;23 «term_ name $= &quot;personal_ information «type $= &quot;concept&quot;\&gt; id $= &quot;1 «display $= &quot;ON&quot;\&gt; id $= &quot;2 «display $= &quot;ON similarity «$= &quot;0.0000021198&quot;\&gt; ibm\/ term\&gt; id $= &quot;3 «display $= &quot;ON&quot;\&gt; id $= &quot;4 «display $= &quot;ON «id $= &quot;5 «display $= &quot;ON&quot;\&gt; id $= &quot;6 «display $= &quot;ON similarity «$= &quot;0.0000015878&quot;\&gt; period\/ term\&gt; id $= &quot;7 «display $= &quot;ON similarity «$= &quot;0.0000014514&quot;\&gt; resell\/ term\&gt; id $= &quot;8 «display $= &quot;ON «id $= &quot;9 «display $= &quot;ON&quot;\&gt; id $= &quot;10 «display $= &quot;ON&quot;\&gt; Assim como no processo de criação do tesauro por o método de Kaji et al.&amp;&amp;&amp;,
a criação dos tesauros por o método de Grefenstette também exigiu o desenvolvimento de programas na linguagem de programação PERL.
Os programas desenvolvidos fazem a extração das relações entre termos no texto, e a geração do arquivo em XML para a visualização dos tesauros.
Foram gerados dois tesauros utilizando o método de Grefenstette, pois um de eles, denominado T2, utiliza um corte nos contextos sintáticos extraídos (o mesmo corte é utilizado para a geração dos tesauros baseados na adaptação da técnica de LSA).
O outro tesauro gerado, denominado T3, não utiliza esse corte de contextos, utilizando, dessa forma, todos os contextos sintáticos extraídos do corpus.
Com os tesauros T2 e T3 gerados, podemos verificar como o corte de contextos pode afetar a criação do tesauro baseado no trabalho de Grefenstette e como este corte pode influenciar os resultados do tesauro gerado utilizando a adaptação da técnica de LSA.
Também podemos fazer uma comparação entre os termos que aparecem no tesauro T3, não aparecem no T2 e que aparecem no tesauro com a adaptação da técnica de LSA, mostrando assim que a adaptação da técnica de LSA pode encontrar termos que antes do corte de contextos estavam semanticamente relacionados.
As etapas para a geração destes tipos de tesauros são apresentadas na Figura 4.2 e explicadas a seguir.
Após o corpus ser analisado sintaticamente, são extraídas as relações identificadas por o analisador sintático.
Para tanto, foi criado um programa que faz a identificação de relações para substantivos e de relações que envolvem verbos.
A diferença entre elas é que as relações para substantivos ocorrem na modificação de um substantivo, seja por outro substantivo, por um adjetivo, ou por outro substantivo através de uma preposição já nas relações que envolvem verbos, o verbo modifica um sintagma nominal e não apenas um substantivo.
Por isso, são extraídos sintagmas nominais em que o núcleo do substantivo é o substantivo identificado na relação sintática por o analisador sintático.
Assim, são extraídos sintagmas nominais onde o núcleo é um substantivo que tem uma relação de sujeito, objeto direto, ou objeto indireto com algum verbo.
Como resultado dessa extração é gerada uma lista contendo todas as relações entre termos identificadas por o analisador sintático e suas respectivas frequências.
O Fragmento 9 apresenta um exemplo da extração dos contextos sintáticos, identificados conforme o trabalho de Grefenstette e explicados na subseção 3.2.1.
Fragmento 9.
Exemplos de contextos sintáticos extraídos do corpus records, electronic\&gt; 23 data, personal\&gt; 1116 information, personal\&gt; 849 data, location\&gt; 32 privacy, health\&gt; 29 european, parliament\&gt; 41 section, paragraph\&gt; 18 recorded, information\&gt; 6 obtained, personal_ information\&gt; 5 rules, health_ information_ privacy\&gt; 21 report, submit\&gt; 20 individual_ information\&gt; 2 Para a geração do tesauro T2 é realizado um corte nos contextos sintáticos.
Este corte é realizado devido a o mesmo também ser utilizado para a geração dos tesauros baseados no trabalho de Yang e Powers.
Em o processo de corte de contextos foram removidos contextos sintáticos que apareciam apenas uma vez no corpus.
De essa forma, por exemplo, caso o contexto sintático &quot;records, electronic\&gt; 1 «existisse, ele seria excluído da lista de contextos por ocorrer apenas uma vez no corpus.
Para o cálculo de similaridade entre os termos é utilizada uma ferramenta desenvolvida por Pablo Gamallo Otero chamada Lingua Toolkit6.
Esta ferramenta integra um analisador sintático e um gerador de tesauros.
Esse gerador de tesauro utiliza um método adaptado de Grefenstette que faz a geração do tesauro baseado em termos compostos por apenas uma palavra.
Como o gerador de tesauro não faz a obtenção dos termos relacionados baseado em sintagmas, o mesmo não foi utilizado nesta dissertação.
Mesmo não utilizando a geração de tesauros proposta por a ferramenta, ela se torna bastante útil ao prover o cálculo de similaridade entre os termos no processo de geração do tesauro.
Assim, parte das funcionalidades da ferramenta é utilizada neste trabalho, realizando o cálculo da similaridade entre os termos-chave e os termos relacionados.
Para o uso das medidas de similaridade da ferramenta Lingua Toolkit, os dados devem ser formatados de modo que a ferramenta processe- os corretamente.
Para isso é necessário criar um arquivo com as relações entre todos os termos-chave e os termos relacionados entre os quais se deseja descobrir o valor de similaridade.
Além deste arquivo, o arquivo contendo os contextos sintáticos com suas respectivas frequências deve ser passado como parâmetro para a ferramenta.
Foram formatados dois arquivos para serem usados como entrada para a ferramenta Lingua Toolkit, um para a geração do tesauro T2 e o outro para a geração do tesauro T3.
Estes arquivos continham os contextos sintáticos e suas respectivas frequências.
A o fim do processo de obtenção da similaridade entre os termos, foram gerados dois arquivos contendo os termos-chave, os termos relacionados e onze valores de similaridade calculados com base em onze medidas de similaridade diferentes.
Um desses arquivos continha os dados para a geração do tesauro T2 e o outro continha os dados para a geração do tesauro T3.
Para a geração de cada um dos tesauros foram extraídos dessas listas os termoschave com seus respectivos termos relacionados e o valor de similaridade de Jaccard.
Os termos foram ordenados decrescentemente por o valor de similaridade.
O Fragmento 10 apresenta um trecho do tesauro T3, contendo o termo-chave &quot;personal_ information», os termos relacionados e os valores de similaridade para cada um dos termos relacionados.
Fragmento 10.
Similaridade gerada para o termo &quot;personal_ information «Termo-chave:
Personal_ information Relacionados:
A geração do tesauro baseado no método de Yang e Powers faz uso de uma adaptação da técnica de Análise Semântica Latente (LSA) para a descoberta de relações não aparentes entre os termos.
Esta técnica utiliza a Decomposição em Valores Singulares (SVD) para realizar os cálculos.
Este método é muito semelhante ao método desenvolvido por Grefenstette, porém ao invés de calcular os valores de similaridade utilizando o valor da frequência dos contextos sintáticos, usa um valor semântico obtido por a SVD.
Foram gerados dois tesauros utilizando este método.
O primeiro de eles, denominado T4, utiliza a métrica de similaridade do Cosseno, conforme descrito no trabalho de Yang e Powers.
O outro tesauro, denominado T5, utiliza a métrica de similaridade de Jaccard, permitindo assim a comparação deste com o tesauro T2, visto que no tesauro T5 somente é adicionada a adaptação da técnica de LSA antes de computar a similaridade entre os termos.
As etapas para a geração dos tesauros são apresentadas na Figura 4.3 e descritas a seguir.
A extração dos contextos sintáticos é realizada praticamente da mesma forma neste trabalho e no trabalho de Grefenstette.
A diferença está na separação entre os contextos extraídos para a geração das matrizes.
Em o trabalho de Yang e Powers, são criadas três matrizes AN, SV e VO, tal como exposto na subseção 3.3.2.1.
A primeira matriz contém as relações entre substantivos e substantivos, adjetivos e substantivos, e substantivos e outros substantivos que são modificados através de uma preposição.
A segunda matriz contém as relações de verbos com substantivos, quando estes últimos atuam como sujeitos do verbo.
A terceira e última matriz contém as relações entre verbos e substantivos, quando estes últimos atuam como objeto (direto ou indireto) dos verbos.
Com os contextos extraídos, foi criada uma matriz AN, na forma An x aN, onde An representa os modificadores dos substantivos e aN representa os substantivos. (
para maiores detalhes ver subseção 3.3.2.1.
Foi criada uma matriz SV na forma Sv x sV, onde Sv representa os sintagmas nominais quando são sujeitos e sV representa os verbos que se relacionam com os sujeitos.
Por fim, foi criada a matriz VO, na forma Vo x vO, onde Vo representa os verbos que modificam os sintagmas nominais quando os mesmos são objetos da frase, e vO representa os sintagmas nominais quando são os objetos desses verbos.
Para uma redução na dimensão das matrizes geradas, foram removidos contextos sintáticos que apareciam apenas uma vez, reduzindo dessa forma o custo computacional para o processamento das matrizes.
A Tabela 4.3 apresenta as dimensões de cada uma das matrizes geradas antes da redução e após a redução dos contextos sintáticos.
Como pode ser observado, houve uma grande redução no tamanho das matrizes SV e VO, indicando que muitos sujeitos apareciam apenas uma vez relacionados a um certo verbo no corpus.
Foi criado um script para a interação das matrizes com o software Octave7.
Octave, também conhecido como Gnu-Octave, é um software livre desenvolvido para a computação matemática.
Maiores informações a respeito de o Octave e suas funções Octave é programa responsável por fazer a Decomposição em Valores Singulares (SVD) das matrizes AN, SV e VO.
Estas matrizes foram decompostas nas matrizes Utxn, nxn e VTnxd, conforme apresentado na subseção 2.2.2.
Após a decomposição das matrizes, foi escolhida uma redução para 250 espaços dimensionais, isto é, foram mantidos os primeiros 250 valores singulares da matriz.
Segundo Yang e Powers os 20 primeiros valores singulares da matriz representam aproximadamente 50% da variação dos valores da matriz e os primeiros 250 valores singulares representam aproximadamente 75% dessa variação.
As matrizes AN, SV e VO são remontadas utilizando o Octave, que realiza a multiplicação das matrizes Utxn, nxn e VTnxd, porém empregando apenas os 250 primeiros valores singulares na matriz.
Como resultado obtêm- se as matrizes AN, SV e VO, porém com os valores semânticos de similaridade entre os termos.
Esses valores variam de acordo com os agrupamentos, tendendo a ficarem valores próximos entre termos similares.
Esta etapa consiste na desconstrução da matriz gerada por o Octave, de forma a recriar os contextos sintáticos, porém com os valores gerados por a decomposição da matriz ao invés de a frequência de ocorrência dos contextos.
Após a reconstrução, o processo segue a etapa 2 do processo de construção de tesauros, conforme descrito no trabalho de Grefenstette, apresentado na subseção 4.3.2 gerando ao final um tesauro com os termos ordenados por similaridade com o termo-chave.
A ferramenta Lingua Toolkit, que aplica a métrica de similaridade nos vetores de termos gerados, apresenta onze opções de medidas de similaridade.
Foram escolhidas duas métricas de similaridade para comparação.
A primeira de elas (Medida do Cosseno) faz a geração do tesauro T4 e foi escolhida por estar descrita no trabalho de Yang e Powers.
A outra medida (Jaccard) faz a geração do tesauro T5 e foi escolhida por ser utilizada no trabalho de Grefenstette.
Os tesauros gerados com os três diferentes processos adotados nessa dissertação sofreram avaliação, com o objetivo de verificar qual das técnicas apresentadas obtém o melhor resultado.
Para a avaliação, cada tesauro foi gerado contendo dez termos-chave e para cada termo-chave foram selecionados os dez termos relacionados mais similares, segundo suas medidas de similaridade.
Por se tratar de um domínio específico, técnicas de avaliação utilizando tesauros construídos manualmente, como a comparação com o tesauro de Roget, o tesauro de Macquarie, o Webster's 7 th Dictionary, ou a WordNet não puderam ser aplicadas.
Optou- se por fazer a avaliação com especialistas do domínio de privacidade de dados.
O perfil de cada um dos avaliadores é apresentado no Apêndice A. O processo de escolha de termos-chave, detalhes do sistema de Recuperação de Informações utilizado e os resultados obtidos são apresentados a seguir.
Os termos-chave para a avaliação dos tesauros foram selecionados de uma ontologia do domínio legal em privacidade de dados, conforme apresentado no trabalho de Vieira, e de um glossário, também do domínio de privacidade de dados, próprio da empresa parceira do projeto.
Reunindo os termos do glossário e os conceitos da ontologia, somávamos um total de 395 termos.
Uma avaliação manual dessa quantidade de termos exigiria muito tempo e tornaria inviável o trabalho devido a o cronograma do mestrado.
Decidiu- se então diminuir a quantidade de termos-chave, bem como limitar a quantidade de termos relacionados para cada termo-chave.
Em conjunto com os avaliadores, decidiu- se por a escolha de 10 termos-chave para a avaliação.
Para a escolha dos termos a serem selecionados, decidiu- se observar a frequência dos mesmos, visto que, quanto maior a quantidade de ocorrências do termo no corpus, mais relações com outros termos ele tem e, mais significativos serão os termos similares.
Em contrapartida, termos mais específicos costumam ter frequência menor.
Optou- se por calcular um limiar que suprisse ambos os casos, não perdendo muitos termos específicos e não deixando uma grande quantidade de termos para serem avaliados.
Decidiu- se utilizar um limiar de 50 ocorrências do termo no corpus, pois foi observado que, com o aumento desse valor de limiar, o número de termos diminuía, porém muitos termos específicos passavam a não aparecer mais na lista.
De essa forma, os termos que tinham uma frequência menor que o limiar não entraram para a lista de termos candidatos a termos-chave.
Este valor de limiar reduziu a lista que continha 395 termos inicialmente, para 99 termos.
A partir de esta lista de 99 termos, optou- se por fazer uma limpeza manual, retirando termos que não eram do domínio específico.
De essa forma, termos como &quot;data», &quot;service», &quot;access», &quot;processing», &quot;system», &quot;action «etc..
Foram removidos.
Com a retirada de sem significado específico para o domínio de privacidade, restou uma lista com 35 termos.
De estes, os avaliadores escolheram 10 termos para servirem de termos-chave para a geração do tesauro.
A lista de termos-chave escolhidos é apresentada na Figura 5.1.
Para cada um dos termos da lista dos 10 termos-chave, foram gerados 50 termos relacionados, referentes aos métodos empregados.
De esses 50 termos, 10 foram obtidos do tesauro construído com método de Kaji, gerando o tesauro denominado T1, 10 foram obtidos do tesauro construído com o método de Grefenstette com o corte de contextos, gerando o tesauro T2, 10 foram obtidos do tesauro construído com o método de Grefenstette sem o corte de contextos, gerando o tesauro T3, 10 foram obtidos do tesauro construído com o método de Yang e Powers e a fórmula de similaridade do Cosseno, gerando o tesauro T4, e 10 foram obtidos do tesauro construído com o método de Yang e Powers e a fórmula de similaridade de Jaccard, gerando o tesauro T5.&amp;&amp;&amp;
Observa- se que foram gerados dois tesauros utilizando o método de Grefenstette, pois o primeiro tesauro gerado (T2, com redução de contextos) serviu de comparação para o método utilizado por Yang e Powers, que utiliza a mesma redução de contextos utilizada para computar a matriz SVD.
De essa forma, procura- se observar o ganho que a adaptação da técnica de LSA teria se comparada com uma técnica sem a aplicação da mesma.
O segundo tesauro gerado por essa técnica (T3, tesauro sem redução de contextos) representa a forma tradicional de geração utilizada por Grefenstette.
Deseja- se, aqui, comparar o desempenho das técnicas em sua forma originalmente proposta por os autores.
Também foram gerados dois tesauros T4 e T5, utilizando o método de Yang e Powers, sendo o primeiro, T4, criado da forma tradicional, utilizando a medida do cosseno para obter termos similares.
O segundo tesauro, T5, foi gerado com base na medida de similaridade de Jaccard, permitindo assim uma comparação com o resultado obtido com a aplicação do método de Grefenstette, que utiliza a mesma medida para computar a similaridade dos termos, e permitindo a avaliação da qualidade dos termos relacionados, indiferentemente da métrica de similaridade, e baseada apenas na aplicação de uma técnica adaptada da LSA.
A o gerar os tesauros, observou- se que existiam alguns termos-chave que continham termos relacionados que ocorriam em mais de um tesauro.
Retornou- se então ao conjunto inicial e removeram- se as duplicatas, utilizando- se apenas uma ocorrência do termo para a avaliação.
De o total de 456 termos gerados para serem remetidos para análise, restaram 387, após a remoção das duplicatas.
A Tabela 5.1 apresenta a frequência dos termos relacionados gerados para cada um dos métodos apresentados.
A princípio, todos os termos deveriam gerar dez termos relacionados para cada termo-chave, porém, como podem ser observados em negrito, os termos &quot;children «e &quot;data_ protection «não geraram a quantidade de termos relacionados pré-estabelecida.
O termo &quot;children «gerou uma quantidade menor de termos do que a préestabelecida, pois as relações contextuais foram reduzidas quando se realizou o corte para a geração do tesauro, restando apenas seis termos relacionados, como pode ser observado em negrito na linha &quot;children», na Tabela 5.1.
Esta baixa quantidade de termos relacionados prejudica a qualidade do tesauro, como veremos na subseção 6.1.
Essa quantidade de termos é corrigida através dos métodos de construção de tesauro T3, T4 ou T5, pois o método que gera o tesauro T3 não realiza o corte dos contextos sintáticos, aumentando assim, o número de relacionamentos entre os termos e obtendo uma melhor qualidade no tesauro.
Os métodos T4 e T5 fazem uso da adaptação da técnica de LSA para a geração dos termos, e com isso, descobrem relações entre os termos que antes não eram aparentes.
Com o uso da adaptação da técnica da LSA a quantidade de relações entre termos aumenta, porém isso não significa que a qualidade do tesauro gerado melhore, isto é, embora a adaptação da técnica de LSA descubra novas relações entre termos, isso não significa que estes novos termos encontrados serão similares, conforme será apresentado na Seção 6.
O termo &quot;data_ protection», nos tesauros que utilizam a abordagem linguística para encontrar os termos compostos, não foi encontrado. Quando
procurado o termo &quot;data_ protection «no corpus observou- se que o mesmo era sempre modificado por outros termos, como por exemplo, &quot;personal data protection «ou &quot;data protection act».
Em a extração, foi priorizadoela sempre extrai o termo composto completo, não havendo a ocorrência de &quot;data_ protection «sem algum modificador no corpus.
Porém, utilizando a abordagem de Kaji, os termos passam por um processo de desambiguação estrutural, conforme explicado na Seção 3.1.3.
Este processo de desambiguação estrutural verificou que o termo &quot;data_ protection «ocorria mais frequentemente que termos como &quot;personal_ data_ protection «ou &quot;data_ protection_ act».
Portanto, ao invés de obtermos um termo composto como &quot;data_ protection_ act», a técnica de desambiguação estrutural obteve o termo &quot;data_ protection».
Para este caso, a desambiguação estrutural obteve mais sucesso que uma abordagem linguística.
Porém, se necessitássemos encontrar termo &quot;personal_ data_ protection «utilizando a abordagem com desambiguação estrutural, não encontraríamos, já que ela transformaria o trigrama citado no bigrama &quot;data_ protection».
Uma regra intuitiva para solucionar este problema é utilizar ambas as técnicas em conjunto.
De essa forma, quando obtemos um termo composto e, dentro deste termo composto, existe outro termo composto mais frequente, assinalamos o relacionamento de ambos com os outros termos relacionados.
Para a avaliação da similaridade entre os termos-chave e seus termos relacionados, foi solicitado aos especialistas de domínio que julgassem a similaridade dos mesmos de acordo com os contextos em que eles ocorriam.
Para isso, o sistema de avaliação foi embutido num sistema de Recuperação de Informações (Ri) desenvolvido no âmbito do projeto com a empresa parceira.
Este sistema inclui o corpus utilizado para fazer a geração dos tesauros, uma ontologia de domínio criada manualmente, contendo um total de 112 conceitos, e um glossário de termos relacionados à área de privacidade, contendo um total de 283 conceitos.
Parte desta ontologia é apresentada no trabalho de Em esse sistema de Ri o usuário pode navegar entre os documentos, ontologia e termos do tesauro, de forma dinâmica.
Com isso, o usuário pode selecionar um termo do tesauro e escolher a opção para localizar o termo selecionado no corpus, na ontologia ou no glossário, caso o termo exista em algum dos mesmos.
A Figura 5.2 apresenta a tela de visualização do tesauro, onde os termos do lado esquerdo são termos- chave e os termos do lado direito são os termos relacionados a cada termo-chave.
Em a mesma figura, pode- se observar o termo-chave selecionado &quot;personal_ information «os termos &quot;sensitive_ information», &quot;patient_ records «etc..
Observando a Figura 5.2 ainda pode- se verificar que o usuário tem as opções de visualizar a região onde o termo &quot;personal_ information «ocorre no corpus e no glossário.
Caso selecionada a opção do corpus, aparecem todas as ocorrências do termo no mesmo, apresentando o nome do documento e a linha em que o termo ocorre, na forma de um concordanceador.
A Figura 5.3 apresenta a interface de visualização das ocorrências do termo quando o mesmo é procurado no corpus.
O mesmo processo de visualização dos termos nos documentos serve para os termos relacionados do tesauro, facilitando assim, ao avaliador, encontrar o contexto em que os termos aparecem, provendo um maior entendimento do termo relacionado.
Em o processo de assinalamento da avaliação, o avaliador deve proceder à seleção do termo-chave e identificação dos termos relacionados gerados como similares, (escolhendo a opção &quot;Similar&quot;), ou não similares (escolhendo a opção &quot;Not similar&quot;) conforme apresentado na Figura 5.4.
Após a identificação dos termos relacionados, o avaliador deve classificar os termos similares, indicando se o mesmo é mais ou menos similar, comparado aos outros termos relacionados.
Para isso, o avaliador utiliza as setas ao lado de o termo relacionado, classificando os termos decrescentemente na ordem de similaridade, de forma que os mais similares fiquem no início da lista.
Caso o usuário não tenha certeza da similaridade de um termo relacionado com o seu termo-chave, pode selecionar a opção &quot;Not sure «entre as opções de similaridade.
Seja quando o avaliador selecionar esta opção, ou quando desejar fornecer alguma explicação a respeito de a classificação de um determinado termo, o mesmo poderá escrever um comentário associado ao termo.
Para isso, basta o usuário selecionar o ícone de &quot;escrever comentário», localizada no canto direito de cada termo relacionado, conforme apresentado na Figura 5.5.
Todos os dados da avaliação, isto é, a marcação de similar, não similar ou &quot;Not sure», a posição do termo comparado com os outros termos relacionados na lista, comentários e o método por o qual o tesauro foi gerado, ficam gravados num arquivo XML.
Este arquivo é carregado toda vez que o usuário acessa o sistema, não sendo necessário o usuário avaliar todo o tesauro numa sessão de utilização do sistema.
Os resultados das avaliações dos especialistas de domínio para cada um dos termos gerados por cada um dos métodos são analisados abaixo.
Os resultados são analisados em termos de as respostas de cada especialista, respostas agrupadas por tesauros e respostas agrupadas por o conjunto de especialistas.
Também são comentadas características referentes ao processo de implementação de cada um dos métodos.
Os resultados aqui analisados são compilados de forma individual, sendo observadas as avaliações de cada tesauro por a visão do especialista.
A primeira análise realizada foi em relação a os termos similares, não similares ou que o avaliador não tem certeza sobre a similaridade, apresentando, além de a quantidade de termos, o percentual que esta quantidade representa no total de termos de cada tesauro.
Após, é apresentada uma análise do sentido semântico dos termos relacionados em relação a o tipo de tesauro que foi construído.
Este tipo de análise permite verificar quais tesauros geram termos que contém um significado mais próximo a o do termochave.
Para isso, utilizou- se a classificação dos termos relacionados, realizada por cada especialista, e desta classificação foram gerados gráficos que apresentam a quantidade de termos relacionados em cada tesauro para cada uma das posições da classificação realizada por o avaliador.
Foram gerados gráficos utilizando as primeiras 25 posições de classificação de cada avaliador, obtendo uma visão ampla do comportamento dos termos para cada tesauro.
A seguir, foram gerados gráficos para as primeiras 10 posições de classificação, observando quais tesauros tinham os termos melhor classificados.
Avaliador 1: O avaliador 1 foi o único a fazer uso da opção &quot;Not sure», indicando, assim, que não poderia avaliar a real similaridade do mesmo.
Isso acontece com termos relacionados em que o significado pode estar associado ao termo-chave dependendo do contexto.
Um exemplo dessa situação ocorre com o termo relacionado &quot;advertisement «(em português, &quot;propaganda&quot;), que foi marcado como &quot;Not sure «para o termo-chave &quot;children «(em português, &quot;crianças&quot;).
Inicialmente, poderíamos inferir que o termo &quot;advertisement «não tem relação com o termo &quot;children», pois para o segundo seria esperado encontrar termos relacionados como &quot;boy «(em português, &quot;menino&quot;), &quot;girl «(em português, &quot;menina&quot;) etc..
Porém como estamos tratando de documentos do domínio legal e entre os documentos temos leis como &quot;Children's online privacy», que trata a respeito de a privacidade para crianças, ou como «Regulation rule pursuant to the telephone crianças, conforme pode ser visto no Fragmento 11.
Fragmento 11.
Lei que trata de propagandas para menores de 12 anos determining whether an advertisement is directed to children under 12: De essa forma a associação entre os termos &quot;advertisement «e &quot;children «não é trivial de ser identificada como similar ou não similar, conforme comentado por o avaliador.
Embora possam existir essas dúvidas, os outros avaliadores preferiram escolher entre &quot;similar «ou &quot;não similar «para termos relacionados, visto que, entre eles, não houve nenhum termo marcado como &quot;Not sure».
O avaliador 1 julgou um total de 387 termos.
De estes, 66 termos o avaliador não soube julgar se eram similares ou não similares ao termo-chave.
Separando as avaliações por tesauro construído, isto é, contando as repetições, obtemos um total de 456 termos avaliados, e destes, 72 termos marcados como &quot;Not sure».
Devido a os outros avaliadores não terem marcado &quot;Not sure «nos tesauros avaliados, serão levados em consideração para a qualidade dos tesauros apenas os termos marcados como similares.
A o final da seção são comentados alguns dados marcados como &quot;Not sure «por o avaliador 1 e as avaliações dadas por os outros avaliadores.
A lista completa de termos julgados por o avaliador pode ser vista no Apêndice B. A Tabela 6.1 apresenta a lista completa de percentuais de termos avaliados por o especialista como &quot;Similar», &quot;Not similar «e &quot;Not sure».
Esta tabela apresenta as avaliações separadas por tesauro, podendo assim mostrar qual tesauro apresentou mais termos similares.
Com isso podemos ver a eficiência de um método para gerar os termos relacionados, e ainda comparar os métodos utilizados.
Uma primeira análise nos permite observar que o tesauro que teve o melhor desempenho, isto é, o tesauro que conteve mais termos relacionados avaliados como &quot;Similar», foi o tesauro T3, com 60% dos termos marcados como similares.
Por outro lado, o tesauro que teve o pior desempenho foi o tesauro T2, apresentando apenas 25,6% de termos marcados como similares.
A diferença entre os tesauros T2 e T3 está apenas no corte nos contextos sintáticos.
Isso mostra que, para o avaliador 1, fez uma grande diferença o corte dos contextos sintáticos.
Embora este corte não fosse necessário para a computabilidade por o método de Grefenstette, mas apenas para a utilização da adaptação da técnica de LSA, é interessante observar que ele provoca a perda de termos que estariam entre termos similares, antes de computar a matriz através do método de Yang e Powers.
Outra análise feita é a da eficiência da adaptação da técnica de LSA, aplicada sobre estes termos, pois a quantidade de termos similares passou de 25,6% (tesauro T2) para 32,2% (tesauros T4 e T5).
Observa- se que a adaptação da técnica de LSA conseguiu descobrir relacionamentos semânticos que embora não existissem mais devido a o corte, ainda existiam na matriz de contextos.
A eficiência da adaptação da técnica de LSA pode ser observada em termos como, por exemplo, &quot;person «encontrado como termo relacionado ao termo-chave &quot;customer «no tesauro T3.
Devido a o corte dos contextos sintáticos, o termo &quot;person «não aparece na lista de termos relacionados do tesauro T2, porém como este termo tinha um significado em outros contextos, a adaptação da técnica de LSA conseguiu encontrar um significado para o mesmo, adicionando este termo ao tesauro T5 como termo relacionado.
Quanto a a métrica de similaridade utilizada (tesauros T4 e T5), para o avaliador 1 não pareceu haver diferença entre a métrica do Cosseno e Jaccard.
Embora não levemos em conta a quantidade de termos marcados como &quot;Not sure», já que estes termos poderiam mascarar alguma diferença na aplicação da métrica.
Para os outros avaliadores fica mais nítida a comparação, visto que não existem termos marcados como &quot;Not sure».
Levando em conta apenas os termos marcados como &quot;Similar», traçou- se um gráfico para verificar a qualidade dos termos gerados em cada tesauro, isto é, de que tesauro é proveniente a maior quantidade de termos marcados como similares.
Este gráfico é apresentado na Figura 6.1, onde no eixo vertical está a quantidade de termos relacionados existentes em cada um dos tesauros.
Em o eixo horizontal está a classificação realizada por o avaliador.
Um detalhe a ser observado é que o gráfico traz uma representação cumulativa, isto é, são somadas as quantidades de termos conforme aumentam as posições.
Assim, para gerar a quantidade de termos similares até a décima posição, o gráfico leva em conta a quantidade de termos similares desde a primeira posição até a décima posição.
A o analisar, por exemplo, a quantidade de termos relacionados gerados por o tesauro T1, levando em conta as cinco primeiras posições classificadas por o avaliador, buscamos o ponto da linha T1, com o número cinco no eixo horizontal.
A partir deste Quantidade de termos relacionados ponto, verifica- se no eixo vertical a quantidade de termos relacionados por o tesauro.
Analisando as curvas traçadas no gráfico da Figura 6.1, observa- se que o tesauro T3 contém a maior quantidade de termos relacionados em todas as posições.
Isso mostra a queda da qualidade dos tesauros que sofreram o corte de contextos.
O segundo tesauro que teve a maior quantidade de termos foi o tesauro T1, que é gerado através de método estatístico, não necessitando de extração de contextos sintáticos.
O tesauro que teve a menor quantidade de termos gerados em todas as posições foi o tesauro T2, mostrando que o corte de contextos e a não adaptação da técnica de LSA recuperam poucos termos similares.
Os tesauros que diferem apenas por a métrica de similaridade (T4 e T5) alcançam um desempenho semelhante para os termos, independente da métrica de similaridade utilizada.
Para melhor analisar os termos nas primeiras posições, o gráfico da Figura 6.2 apresenta as dez primeiras posições de cada um dos tesauros.
Em este gráfico pode ser observado que o tesauro T3 obtém a maior quantidade de termos nas primeiras dez posições.
Assim, observa- se que, dos 54 termos obtidos até a 25ª posição, 44 se encontram entre as dez primeiras posições.
Por outro lado, observamos que o tesauro T1, além de conter uma quantidade menor de termos relacionados como similares, gera termos semanticamente menos similares que o tesauro T3, isto é, tem uma curva de crescimento mais suave que a curva gerada por o tesauro T3.
Assim, observa- se que, dos 44 termos contidos até a 25ª posição, 22 (66% dos termos) estão entre os dez primeiros termos.
Ainda seguindo a classificação realizada por o avaliador 1, podemos concluir que, para um tesauro mais específico, o método de Grefenstette sem a realização do corte de contextos (tesauro T3), poderia ser o mais adequado.
Finalmente, para o avaliador 1, a opção por a métrica de similaridade num tesauro que utiliza uma adaptação da técnica de LSA não parece promover uma grande diferença na quantidade e na qualidade dos termos gerados.
Avaliador 2: O avaliador 2 julgou um total de 387 termos que, quando separados em tesauros, gerou um total de 456 termos avaliados.
O avaliador 2 efetuou seu julgamento utilizando apenas as opções &quot;Similar «e &quot;Not similar», não manifestando, em caso algum, dúvida sobre a similaridade.
Partindo destas avaliações, o tesauro que teve a maior quantidade de termos julgados como similares foi o tesauro gerado com o método de Grefenstette (tesauro T3), com um total de 71,1% dos termos marcados como similares, conforme pode ser observado na Tabela 6.2.
Ainda na Tabela 6.2, pode- se observar que o tesauro que teve a menor quantidade de termos julgados como similares foi o tesauro baseado no trabalho de Yang e Powers utilizando a métrica de similaridade do Cosseno (tesauro T4), com um total de 37,8% dos termos marcados como similares.
Fazendo uma comparação entre os tesauros gerados com e sem a adaptação da técnica de LSA, vemos que o tesauro gerado sem a técnica de LSA (tesauro T2) teve um desempenho melhor ou pelo menos comparável às técnicas que utilizam a LSA, fazendo diferença na aplicação da métrica de similaridade.
Comparando o tesauro T2 com o tesauro em que ocorre a aplicação da LSA antes de gerar os termos relacionados e a utilização da métrica de similaridade do Cosseno, o tesauro T2 mostrou um melhor desempenho, com 47,7% dos termos marcados como similares, contra 37,8% dos termos do tesauro T4.
Porém, quando utilizamos a métrica de similaridade de Jaccard na adaptação da técnica de LSA, observamos que a quantidade de termos similares aumenta de 34 termos (tesauro T4) para 43 termos (tesauro T5), obtendo, dessa forma, um desempenho maior que sem a aplicação da adaptação da técnica de LSA (tesauro T2).
De essa forma, caso fossemos escolher uma métrica de similaridade para a aplicação na geração dos termos semelhantes, segundo a análise dos resultados por o avaliador 2, seria recomendável a utilização da medida de Jaccard ao invés de a aplicação da métrica do Cosseno.
Uma análise mais profunda dos termos reconhecidos como similares pode ser realizada através da observação do gráfico apresentado na Figura 6.3.
Este gráfico apresenta a classificação realizada por o avaliador para as primeiras 25 posições de classificação do avaliador, onde cada curva representa a quantidade de termos Quantidade de termos relacionados relacionados conforme aumenta a posição da classificação.
Como pode ser observado na Figura 6.3, os tesauros T3 e T5 tem a maior quantidade de termos similares nas primeiras posições da classificação.
Porém, conforme as posições da classificação aumentam, o tesauro T5 praticamente se estabiliza e o tesauro T3 passa a ter uma curva suavizada quando comparada com as primeiras posições.
Enquanto isso, o tesauro T1, que não contêm muitos termos nas primeiras posições, cresce a partir de a décima posição.
Podemos observar, também, que o avaliador 2 notou diferença nos resultados da métrica de similaridade utilizada para a geração dos tesauros T4 e T5.
De acordo com a classificação realizada por o avaliador 2, o tesauro que utiliza a métrica de similaridade de Jaccard (tesauro T5) obteve maior quantidade de termos semelhantes nas primeiras 25 posições.
Observando as primeiras dez posições deste gráfico, o que pode ser melhor visto na Figura 6.4, vemos que o tesauro T3, além de conter a maior quantidade de termos marcados como &quot;Similar», também contém os termos mais bem classificados nas primeiras posições.
O comportamento semelhante, entre os tesauros T3 e T5, nas primeiras posições do gráfico, se deve ao fato de ambos compartilharem termos relacionados.
Analisando- se os resultados, observou- se que alguns dos termos que aparecem em ambos os tesauros, foram removidos do tesauro T2 devido a o corte de contextos, mas foram recuperados no tesauro T5 com a adaptação da técnica de LSA e a métrica de similaridade de Jaccard.
Seguindo a classificação realizada por o avaliador 2, podemos concluir que o método de Grefenstette sem o corte de contextos (tesauro T3) obtém um bom desempenho para a geração de tesauros.
Através dessa técnica é possível a geração de uma grande quantidade de termos similares e, ainda, estes termos têm uma forte similaridade semântica com o termo-chave.
Em esta tabela podemos observar que o tesauro que obteve o melhor desempenho foi o tesauro T3, com um total de 70% dos termos assinalados como similares.
Em compensação, o tesauro T2 foi o tesauro que obteve o pior desempenho, tendo apenas 33,7% dos termos marcados como similares.
Comparando com os outros avaliadores, o avaliador 3 tem um perfil de respostas semelhante ao do avaliador 1, apresentando semelhança na avaliação entre os tesauros que têm a maior e menor quantidade de termos semelhantes, bem como a não diferenciação entre métricas de similaridade aplicadas na adaptação da técnica de LSA (tesauros T4 e T5).
Mais uma vez observamos, por as respostas do avaliador 3, que o tesauro gerado por o método de Grefenstette com corte nos contextos sintáticos obteve um baixo desempenho quando comparado com o tesauro gerado por o mesmo método sem o corte nos contextos.
Em a ótica desse avaliador observa- se uma queda na classificação do tesauro T1, relativa à quantidade de termos semelhantes quando comparado com os outros avaliadores.
Para o avaliador 1, por exemplo, o método que gera o tesauro T1 tinha obtido uma grande quantidade de termos semelhantes, sendo o segundo tesauro com maior quantidade dos mesmos.
Para o avaliador 3, o método que gera o tesauro T1 foi o segundo tesauro que gerou a menor quantidade de termos.
Se comparado ao avaliador 2, obtemos uma queda maior ainda na avaliação do tesauro T1, passando de um tesauro com 62 termos similares para um tesauro com 36 termos gerados como similares, enquanto que o tesauro T3 obteve uma queda de 64 termos para 63 termos similares entre os mesmos avaliadores.
Observando a Tabela 6.3 podemos fazer uma comparação do tesauro T2 com o tesauro T5, isto é, diferenciando- se apenas na adaptação da técnica de LSA.
Em esta comparação, o tesauro T5 obteve um desempenho melhor (46,7%), contra os 33,7% do tesauro T2, indicando que a técnica de LSA pode encontrar relações semânticas entre os termos que antes não existiam.
Depois de comparadas as quantidades de termos similares encontrados para cada tesauro, partimos para a análise da classificação dos termos gerados em cada um dos tesauros, verificando se o tesauro, além de gerar uma grande quantidade de termos, também gera termos semanticamente similares.
A Figura 6.5 apresenta um gráfico com a quantidade de termos gerados em cada tesauro, de acordo com as posições que os mesmos ocupam na avaliação.
Para essa análise utilizou- se a classificação realizada por o especialista, que ordenou os termos por ordem decrescente de significado, sendo utilizadas para a criação do gráfico as 25 primeiras posições da classificação realizada por o avaliador 3.
Analisando esse gráfico, observamos que, para o avaliador 3 assim como para os outros avaliadores, o tesauro T3 contém a maior quantidade de termos significativos.
Por outro lado, o tesauro T2, além de conter poucos termos relacionados marcados como similares, também contém termos pouco significativos.
Comparando o tesauro T2 com o tesauro T3, observamos que o corte nos contextos também fez diferença para o avaliador 3, pois acabou retirando termos que eram representativos para o tesauro.
Este corte, embora produza economia no processamento computacional dos termos, diminui quantidade de termos semanticamente similares.
Outra comparação a ser analisada é aquela entre os termos relacionados gerados por o tesauro T4 e por o tesauro T5, que se diferenciam apenas por a métrica de similaridade utilizada.
Como pode ser observado, inicialmente o tesauro T5 tem um desempenho melhor que o T4, obtendo uma maior quantidade de termos relacionados, porém essa diferença desaparece a partir de a 11ª posição.
Embora haja uma diferença na quantidade de termos relacionados, ela não é significativa, principalmente com a melhoria na classificação dada por os avaliadores.
Para observar melhor os termos gerados nas primeiras posições, o gráfico apresentado na Figura 6.6 mostra as primeiras 10 posições da classificação realizada por o avaliador 3.
Em este gráfico podemos observar que, na primeira posição, o tesauro T1 contém mais termos similares do que o tesauro T3, porém na segunda posição ambos os tesauros contêm 8 termos similares e, após esta posição, o tesauro T3 passa a ter uma quantidade maior de termos similares que o tesauro T1.
Podemos observar que, embora para as 25 primeiras posições (Figura 6.5) a métrica de similaridade não tenha apresentado grande diferença, para as 10 primeiras posições da classificação (Figura 6.6) ela apresenta diferença, obtendo a métrica de Jaccard melhores resultados.
Comparações dos resultados entre os três avaliadores Após fazer a análise dos tesauros para cada um dos avaliadores, vamos traçar as principais características observadas em cada uma das avaliações, comparando os resultados obtidos.
A primeira comparação que fazemos é entre os tesauros que obtiveram a maior e a menor quantidade de termos similares.
Analisando as tabelas 6.1, 6.2 e 6.3, observamos que o tesauro que teve mais termos julgados como similares foi o tesauro T3.
Por outro lado, os tesauros que obtiveram a menor quantidade de termos julgados como similares foram os tesauros T2 e T4.
O tesauro T2 teve a menor quantidade de termos julgados como similares por dois dos três avaliadores, mostrando assim que o corte nos contextos teve um grande impacto nos resultados.
O tesauro T4 teve a menor quantidade de termos julgados como similares para um dos avaliadores, mostrando que a métrica de similaridade pode fazer diferença na seleção dos termos para o tesauro.
Isso nos leva à segunda comparação, buscando observar qual métrica de similaridade aplicada na adaptação da técnica de LSA seleciona a maior quantidade de termos similares.
Em as tabelas 6.1, 6.2 e 6.3 pode ser observado que a escolha na métrica de similaridade aplicada na construção do tesauro faz diferença na obtenção de termos similares.
Comparando a técnica que utiliza a métrica do Cosseno (tesauro T4) e a técnica que utiliza a métrica de Jaccard (tesauro T5), vemos que os resultados de dois dos avaliadores indicam que a métrica de Jaccard tem uma eficiência maior que a métrica do Cosseno.
Para um dos avaliadores, a aplicação das métricas não apresentou diferença na quantidade de termos relacionados similares.
Uma última comparação é feita entre os termos gerados através do método de Grefenstette com corte nos contextos (tesauro T2) e o mesmo método porém com a adição da adaptação da técnica de LSA (tesauro T5).
Comparando as tabelas 6.1, 6.2 e 6.3, observamos que, em todos os casos, os resultados com a aplicação da adaptação da técnica de LSA obteve melhores resultados, mostrando que a aplicação da adaptação da técnica de LSA pode realmente descobrir relações semânticas que aparentemente não observamos quando olhamos apenas para as frequências dos termos.
Com isso, acreditase que a aplicação da adaptação da técnica de LSA sobre o método de Grefenstette sem corte de contextos, melhoraria ainda mais os resultados.
6.2 Resultados por tesauro Os resultados apresentados nesta seção são referentes ao tesauro, e não mais à visão do especialista.
Para tal análise, optamos por a divisão em dois grupos:
União das respostas dos avaliadores, isto é, um termo similar é aquele que foi julgado por um especialista como &quot;Similar&quot;;
E interseção, onde um termo é similar caso ele tenha sido avaliado por todos os especialistas como &quot;Similar».
A comparação entre essas abordagens visa destacar os tesauros que geram termos de difícil e de fácil identificação, como similares, por os especialistas.
A seguir são apresentados os resultados de cada uma destas abordagens.
Abordagem da união Esta abordagem procurou unir todos os termos marcados como similares para cada tesauro, verificando qual tesauro contém a maior quantidade de termos similares.
Essa abordagem não consegue identificar o sentido dos termos de cada um dos tesauros (se são termos mais abrangentes ou mais específicos), apenas identificando, de entre todos os termos gerados, quantos são similares.
A ideia desta abordagem é identificar o tesauro que obtém a maior quantidade de termos de uma forma abrangente, pois parte- se do princípio que dois avaliadores discordam da classificação da similaridade de um termo com o termo-chave quando o mesmo é abrangente demais.
De essa forma, termos marcados como &quot;Similar «por apenas um dos avaliadores seriam abrangentes, mas ainda contêm algum relacionamento com o termo-chave.
A Tabela 6.4 apresenta a quantidade de termos similares encontrados para cada tesauro.
Em essa tabela são apresentadas a quantidade de termos marcados como &quot;Similar «por qualquer um dos avaliadores e o total de termos avaliados para cada tesauro.
Podemos observar, nesta tabela, que o tesauro T1 obteve um total de 70% dos termos marcados com &quot;Similar».
Este foi seguido por o tesauro T3, com 64,4% dos termos marcados como similares, indicando que o tesauro T1 tem uma abrangência de termos maior.
Por outro lado, o tesauro T5, apresentou 44,4% dos termos marcados como similares.
Esta abordagem faz a interseção dos resultados indicados por os avaliadores, selecionando apenas os termos relacionados que aparecem marcados como &quot;Similar «em todos os tesauros.
Com isso, esta abordagem tenta identificar o tesauro que contém a maior quantidade de termos significativos para o tesauro, partindo da premissa que, se todos os avaliadores marcaram o termo como &quot;Similar», o termo realmente tem significado para o tesauro.
A Tabela 6.5 apresenta a quantidade de termos obtidos das interseções das respostas dos avaliadores quando os mesmos julgaram um termo como similar ao termochave, para cada tesauro.
Como pode ser observado, o tesauro T3 teve a maior quantidade de termos marcados como similar por os avaliadores, obtendo 51,1% dos termos marcados por os três avaliadores como similares aos termos-chave.
Por outro lado, o tesauro T1 obteve a menor quantidade de termos marcados como similares por todos os especialistas, obtendo um total de 17% dos termos.
Comparando essas duas abordagens, podemos verificar que o tesauro T3 obteve a menor queda na quantidade de termos marcados como similares.
De todos os termos marcados como similares por os avaliadores, apenas 13,3% geraram dúvidas.
Em contrapartida, o tesauro T1 foi o que gerou a maior quantidade de termos em que os avaliadores tiveram dúvidas quanto a a similaridade:
53% dos termos gerados provocaram este tipo de dúvidas.
Aqui podemos verificar, ainda, que a métrica de similaridade também apresentou diferença na quantidade de termos marcados como similares.
O tesauro T5 obteve uma queda menor na quantidade de termos, quando comparado ao tesauro T4.
Essa diferença indica que a utilização da métrica de Jaccard como forma de calcular a similaridade entre os termos, gerou termos que tem uma maior chance de serem marcados por todos os especialistas como similares.
Em esta seção vamos dar atenção especial para alguns casos particulares, pois acreditamos serem casos interessantes para o entendimento dos métodos.
O primeiro caso é o do termo &quot;children», devido a este apresentar uma quantidade menor de termos quando realizado o corte de contextos no método de Grefenstette.
Logo a seguir, é analisado o caso das respostas marcadas como &quot;Not sure», visto que apenas um dos avaliadores usou desta alternativa, tentando descobrir se ocorreriam diferenças na avaliação caso o avaliador tivesse marcado outra alternativa.
Caso &quot;children «A ideia, neste caso, é observar se a não realização de um corte nos contextos sintáticos ou a aplicação da adaptação da técnica de LSA nos termos com a realização do corte melhoram os resultados do tesauro gerado.
Para isto, comparamos a quantidade de termos gerados como similares entre os tesauros.
A Tabela 6.6 apresenta, para o termo-chave &quot;children», a quantidade de termos marcados como &quot;Similar «para termos similares, &quot;Not similar «para termos não similares e &quot;Not sure «para termos que o usuário não soube avaliar.
Analisando a Tabela 6.6, podemos observar que, embora a quantidade de termos tenha aumentado com a adaptação da técnica de LSA (tesauros T4 e T5), a qualidade dos termos não apresentou uma melhora significativa.
Somente o tesauro T4, entre os que utilizam a adaptação da técnica de LSA, apresentou um aumento na quantidade de termos similares, porém apenas por o julgamento do avaliador 3.
Embora tenha aumentado num termo, ele passou a ter outros 3 termos não similares, não valendo a pena a aplicação dessa técnica para o aumento de termos.
Por outro lado, a não realização do corte nos contextos fez aumentar consideravelmente a qualidade dos termos, como pode ser visto no tesauro T3, pois passou de 1 termo similar gerado no tesauro T2 para 5 termos similares no tesauro T3, segundo o avaliador 3, mantendo a mesma quantidade de termos não similares.
Com isso, podemos concluir que, ao invés de utilizar um método usa a adaptação da técnica de LSA para gerar termos relacionados, é melhor aplicar o método de Grefenstette sem a realização do corte de contextos.
Caso &quot;Not sure «A ideia aqui é observar a utilização dos valores de &quot;Not sure «como valores similares ou não similares de acordo com as respostas dos outros especialistas.
De essa forma, caso ambos os outros dois especialistas tenham respondido &quot;Similar «para um termo, ele passa de &quot;Not sure «para &quot;Similar», e caso ambos tenham respondido &quot;Not similar», o termo &quot;Not sure «é confirmado como &quot;Not similar».
Com isso podemos verificar se a mudança, na resposta do avaliador 1, iria acarretar diferenças nos resultados dos tesauros gerados.
A Tabela 6.7 apresenta a quantidade de termos que foram marcados como &quot;Not sure «por o avaliador 1 e foram marcados por os outros avaliadores como &quot;Similar «ou &quot;Not similar».
A tabela ainda apresenta a linha &quot;Discordância», que indica a quantidade de termos que foram marcados por um dos avaliadores como &quot;Similar «e por o outro avaliador como &quot;Not similar», havendo discordância entre os mesmos.
Exemplos de termos marcados como &quot;Not sure «podem ser vistos no Apêndice B. Observando a Tabela 6.7, vemos que a maioria dos termos marcados como &quot;Not sure «por o avaliador 1 foram avaliados diferentemente por os outros avaliadores, havendo discordância entre eles.
Ainda assim, podemos verificar se os termos antes marcados como &quot;Not sure», modificam os resultados da comparação dos tesauros para o avaliador Para isso, remontamos a Tabela 6.1, porém ao invés de colocarmos os valores para &quot;Not sure», adicionamos os valores da Tabela 6.7, modificando o valor de &quot;Not sure «por valor &quot;Desconhecido «quando os outros avaliadores discordavam da resposta.
Os novos valores para os termos marcados como similares e não similares podem ser vistos na Tabela 6.8.
Comparando os valores obtidos na Tabela 6.8, observa- se que pouca coisa mudou com relação a os valores da Tabela 6.1, continuando o tesauro T3 com a maior quantidade de termos selecionados como similares (obtendo um aumento de 3,4%), e o tesauro T2 com a menor quantidade de termos selecionados como similares (obtendo um aumento de 2,3%).
Também podemos observar, comparando as duas tabelas, que houve uma melhora dos resultados obtidos por o tesauro T4 se comparado com o tesauro T5, que só utiliza a métrica de similaridade como diferença.
Em este caso, o tesauro com a métrica de similaridade do Cosseno obteve um melhor desempenho se comparado com a medida de Jaccard.
Em esta seção tecemos alguns comentários com relação a a implementação dos métodos do ponto de vista da utilização das ferramentas, dificuldades encontradas e tempos de processamento.
Ferramentas e implementação O mais simples e o mais fácil de implementar.
Assim podemos definir a implementação do método de Kaji Que utiliza apenas técnicas estatísticas para a construção do tesauro.
Por utilizar apenas técnicas estatísticas, a criação deste tipo de tesauro necessitou apenas da instalação da ferramenta NSP, que computa desde a extração dos termos, até a medida de Informação Mútua.
Para a aplicação desse método foram criadas funcionalidades apenas para o processo de Desambiguação Estrutural, conforme descrito na seção 4.2.1.
O método de Grefenstette, assim como o método de Yang e Powers, utilizam a informação sintática dos termos do corpus.
Para isso é necessário fazer a identificação das classes gramaticais e da estrutura sintática no corpus.
A ferramenta utilizada para este processo foi o analisador sintático desenvolvido por Stanford.
Após a ferramenta fazer a identificação das classes gramaticais e da estrutura sintática dos termos, foi necessário criar uma funcionalidade para a extração das identificações de cada termo.
Para o cálculo da similaridade entre os termos foi utilizada a ferramenta Lingua Toolkit, que permite o cálculo da similaridade com onze métricas diferentes.
Para a utilização dessa ferramenta foram criadas duas funcionalidades, a primeira de elas para fazer a formatação dos dados de entrada da ferramenta e a segunda para a extração dos termos com as respectivas métricas de similaridade.
Por fim, o método de Yang e Powers além de utilizar as ferramentas que o trabalho de Grefenstette utiliza, ainda faz a utilização de uma ferramenta para a Decomposição em Valores Singulares (SVD).
Para a SVD foi utilizada a ferramenta matemática Octave e, com isso, mais duas funcionalidades foram criadas.
A primeira de elas para a criação das matrizes esparsas que serviram de entrada para a ferramenta.
A outra foi criada para extrair os valores gerados por a SVD para cada contexto sintático existente.
Este método também foi o que apresentou maior dificuldade na implementação, pois foi necessária a realização de um corte nos contextos sintáticos para o processamento das matrizes, não sendo possível o processamento sem o corte.
Por fim, vemos que conforme aumentamos a quantidade de informações que desejamos extrair do corpus, mais ferramentas são necessárias e, mais difícil e suscetível ao erro o processo se torna.
Tempos de processamento Para a verificação dos tempos de cada um dos processos, foi utilizado um computador Pentium 4, CPU 3.
20 GHz, contendo 1.49 GB de memória RAM e sistema operacional Linux Ubuntu 9.04.
Em a Tabela 6.9 são apresentados os tempos para a geração dos tesauros em cada um dos processos.
Os tempos de T2 até T5 não levam em conta o tempo de análise sintática do corpus.
Observamos que os tesauros T4 e T5 obtém o mesmo tempo de processamento.
Isto se deve ao fato de diferenciarem- se apenas no fim do processo, ao fazer a extração dos termos relacionados, para a geração do tesauro.
Como os tempos da Tabela 6.9 não incluem os tempos de análise sintática do corpus podemos adicionar o tempo de aproximadamente 29 horas e 30 minutos para o processamento do corpus.
O corpus utilizado está separado em cem documentos, contendo um total de 1.122.836 palavras.
Com isso, o processamento para a geração do tesauro T1 passa a ser o que leva menos tempo para ser gerado.
O tempo da geração do tesauro T1 ainda pode variar de acordo com o tamanho da janela utilizada.
O tempo utilizado apenas para a criação dos termos relacionados, utilizando uma janela de 30 termos, foi de 49 minutos e 6 segundos.
Para a criação de um tesauro que utiliza a anotação sintática do corpus, o tempo é muito maior devido a o tempo de anotação do corpus.
Porém, como a anotação sintática pode ser realizada apenas uma vez para todos os tesauros, vemos que os tesauros gerados por o método de Grefenstette utilizam menos tempo para serem criados.
Levando em consideração o tempo de processamento para a escolha na aplicação de um método de construção automática de tesauro, um cuidado a ser tomado é o processamento do corpus por um analisador sintático, pois observamos que este é o processo que despende maior tempo.
Em a conclusão do presente trabalho, trazemos nossas considerações e percepções acerca de o trabalho apresentado nesta dissertação, e de seus resultados.
Além disso, relacionamos as contribuições científicas deste trabalho e propostas de trabalhos futuros.
Este trabalho estudou processos de construção automática de tesauro, visando à descoberta de características que identifiquem o melhor método de construção para um determinado contexto.
Com isso, um usuário pode definir o método que irá utilizar em seu sistema de acordo com as características desejadas, como ênfase na quantidade de termos gerados, ênfase na similaridade dos termos gerados, tempo de processamento etc..
Foram analisadas detalhadamente as respostas de cada um dos avaliadores identificando os métodos que retornavam a maior e a menor quantidade de termos semelhantes.
Também foram realizadas análises sobre a classificação dos termos realizada por os avaliadores, descobrindo de quais tesauros os termos mais bem classificados eram provenientes, e identificando, dessa forma, características de cada um dos métodos utilizados para a construção dos tesauros.
Após, procedeu- se à análise, não mais por os resultados dos avaliadores individualmente, mas reunindo as respostas dos mesmos.
Para isso, utilizaram- se duas abordagens:
Uma considerando que, caso o termo fosse marcado como similar por algum dos avaliadores, este era considerado similar ao termo-chave;
A outra, considerando que um termo só seria similar ao termo-chave caso ele fosse marcado por todos os avaliadores como similar.
A comparação dessas abordagens mostra que, muitas vezes, um tesauro pode gerar uma grande quantidade de termos similares, porém difíceis de avaliar quanto a sua similaridade com o termo-chave.
Por fim, fez- se a análise de dois casos que se acreditou serem interessantes.
O primeiro de eles foi do termo &quot;children «que, devido a o corte nos contextos, teve a quantidade de termos relacionados diminuída.
Procurou- se verificar a melhor opção entre adicionar a adaptação da técnica de LSA aos termos depois de realizado o corte de contextos, identificando relações semânticas que os termos com o corte não continham, ou utilizar o método de Grefenstette sem a redução de contextos.
Esta última se mostrou com melhores resultados do que a aplicação da adaptação da técnica de LSA.
O segundo caso analisado foi das respostas dadas por o avaliador 1 como &quot;Not sure», utilizando- se do conhecimento dos outros especialistas para aumentar a quantidade de termos similares e não similares nesses casos, observando modificações nos tesauros gerados.
Embora a utilização do conhecimento dos outros especialistas tenha aumentado a quantidade de termos similares para os tesauros, esse aumento não provocou modificação no resultado final, mantendo o tesauro T3 com a maior quantidade de termos gerados como similares.
A avaliação qualitativa realizada por especialistas do domínio de privacidade e utilizada neste trabalho mostrou- se extremamente proveitosa, principalmente por contribuir com a análise de termos que são de difícil identificação como semanticamente similares.
Sabe- se que, em se tratando de semântica, as respostas são muito subjetivas, e essa subjetividade nos permitiu descobrir o sentido dos termos gerados por os métodos estudados.
Os resultados mostraram que a adaptação da técnica de LSA apresenta uma melhora nos resultados, se comparados com os dados originais, quando ambos utilizam um corte nos contextos.
Por outro lado, é melhor utilizar a técnica de Grefenstette sem o corte nos contextos do que utilizar a adaptação da técnica de LSA com um corte nos mesmos.
Ainda, a escolha da métrica de similaridade empregada na adaptação da técnica de LSA se torna importante, mostrando- se a métrica de Jaccard melhor do que a aplicação da métrica do Cosseno no estudo realizado.
Por fim, a análise buscada com este trabalho e as aplicações desenvolvidas foi a de encontrar o melhor método de construção automática de tesauro, avaliada nesse trabalho para o domínio legal.
Para outros domínios, seria interessante realizar novos experimentos, conforme proposto na seção de trabalhos futuros.
Em esta seção, relacionamos algumas das contribuições deste trabalho nos contextos acadêmico e industrial para o conhecimento produzido.
São elas:
Contribuições principais -- Processos de construção automática de tesauros baseados num corpus do domínio em questão;
Sistemas para construção de tesauros baseada em métodos estatísticos, baseada em métodos que utilizam conhecimento sintático, e baseada em métodos com uso da adaptação da técnica de LSA;
Avaliação qualitativa dos resultados obtidos na experimentação do sistema.
Esta avaliação sendo realizada com o apoio de especialistas do domínio de privacidade, permitindo uma visão subjetiva dos termos.
Recursos -- Corpus Privacy, desenvolvido em conjunto com a equipe, no âmbito do projeto APAO, embora não existam quaisquer restrições para a sua utilização em outros projetos e pesquisas;
Corpus Privacy anotado sintaticamente através do parser desenvolvido em Stanford.
Artigo -- &quot;Comparação de técnicas para a construção de tesauros visando o enriquecimento de uma ontologia do domínio legal», aceito no &quot;3º Seminário de Pesquisa em Ontologias no Brasil ­ 3º ONTOBRAS», com resultados preliminares do trabalho até o primeiro semestre de 2010.
Em o decorrer deste trabalho, algumas ideias de trabalhos futuros baseados neste, foram elaboradas.
Algumas destas ideias são detalhadas nesta seção.
São elas:
Geração de tesauro baseada no método de Yang e Powers sem o corte nos contextos A o analisar os resultados obtidos, notou- se que a adaptação da técnica de LSA melhorou os resultados dos tesauros gerados se comparados aos mesmos sem a utilização da técnica.
Porém, devido a limitações de hardware as matrizes antes da execução da LSA tiveram que ser reduzidas, sendo realizado o corte de contextos.
Como apresentado nos resultados, esse corte prejudicou as relações entre os termos.
Com isso, acreditamos que a aplicação da adaptação da técnica de LSA sobre os termos, sem corte, melhoraria os resultados obtidos quando comparado com a técnica de Grefenstette (tesauro T3).
Experimentação dos métodos num domínio diferente Os métodos propostos podem ser aplicados em outros domínios.
A aplicação deste trabalho considerou o domínio de privacidade de dados na indústria de software, o que particulariza a avaliação por especialistas de domínio.
A aplicação em outro domínio permite verificar se as características de cada tesauro gerado permanecem inalteradas.
Realizar a construção de uma taxonomia dos termos relacionados, com relação a o termo-chave Parte- se do princípio que os termos relacionados são gerados por um tesauro associativo, portanto temos termos relacionados associados semanticamente ao termo-chave, porém isso não nos diz muito sobre o termo-chave.
Acredita- se que o refinamento do significado do termo-chave pode ser feito através da criação de uma taxonomia dos termos relacionados, identificando nos mesmos relações melhor definidas como sinonímia, antonímia, meronímia, hiperonímia etc..
Essa taxonomia poderia ser utilizada num sistema de Ri, permitindo ao usuário a escolha de recuperar documentos que além de conter o termo procurado, também documentos que contêm merônimos semanticamente relacionados ao termochave, por exemplo.
Experimentação dos métodos utilizando um corpus em outro idioma A realização de experimentos utilizando um corpus em outro idioma permitiria verificar se o comportamento dos métodos permanece o mesmo quando o idioma é trocado.
Para alguns idiomas adaptações seriam necessárias, como o caso do português em que o contexto sintático de substantivo que modifica substantivo não seria utilizado.
