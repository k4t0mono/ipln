Este trabalho apresenta os resultados obtidos com a pesquisa envolvendo Jogos Educacionais interativos modelados com arquitetura de Sistemas Tutores Inteligentes (STI).
Utilizamos a abordagem de agentes para tratar as funcionalidades associadas aos módulos de uma arquitetura tradicional de STI.
O domínio é modelado com agentes reativos utilizando técnicas de Machine Learning (aprendizagem por reforço).
Os alunos e o tutor são modelados através de agentes cognitivos em arquitetura BDI (belief, desire, intention).
Este conjunto complexo de escolhas interdisciplinares, tanto no nível de projeto de software educacional, como de técnicas de Inteligência Artificial, nos levaram a várias investigações e resultados que trouxeram questionamentos e algumas contribuições para avançar nossa pesquisa na área de ambientes de ensino aprendizagem computadorizada.
Como principal resultado deste trabalho, estendemos a arquitetura proposta por Girrafa e Viccari e introduzimos um novo agente (Mediador) para auxiliar o Tutor a gerenciar o conjunto de informações que recebe do ambiente e dos alunos.
Desta forma, estamos propondo a terceirização de tarefas que são normalmente modeladas no módulo Tutor.
Esta terceirização permite distribuir a complexidade de modelar e supervisionar o conjunto de informações na interação entre os agentes.
A inclusão deste novo agente (mediador) é a nossa proposta para estender a arquitetura de com a finalidade de tratar a enorme quantidade de informações, geradas durante a interação entre os agentes (cognitivos e reativos).
Apresentamos também algumas características sobre agentes de interface, ITS com a abordagem SMA, nossas razões para estender a arquitetura, e o protótipo criado para avaliar nossa proposta.
Palavras-chave: Agentes de Interface, Tis, Agentes Pedagógicos, Jogos Educacionais.
Os STI (Sistemas Tutores Inteligentes) são uma modalidade de software educacional onde se pretende fornecer uma instrução personalizada ao aprendiz (aluno).
Desde o seu surgimento, na década de 70, até os dias de hoje muitas pesquisas vêm sendo conduzidas a fim de se modelar/ implementar ambientes que possam atingir este propósito com o maior grau de qualidade pedagógico e técnica.
Quando se fala em STI imediatamente emerge a questão da complexidade inerente á modelagem e, conseqüentemente implementação destes sistemas.
Recentemente, última década, a tecnologia de agentes foi incorporada ao projeto dos alternativas para se modelar um STI como uma sociedade de agentes.
Este trabalho está inserido no contexto do Grupo de Pesquisa em Informática na Educação (GIE) da FACIN-PUCRS.
Dentro deste grupo existe uma linha de pesquisa trabalhando com a aplicação da tecnologia de agentes na construção de STI.
O trabalho desenvolvido por Giraffa em, explorou o ensino da conscientização ecológica com o auxílio de um &quot;tutor «artificial através de um ambiente que utiliza a metáfora que jogos.
O problema abordado por Giraffa e as soluções apresentadas em seu trabalho trouxeram também novos desafios e novas questões em aberto para serem trabalhadas no grupo.
Uma das questões apontadas por foi abordada por Callegari em.
Em este trabalho, Callegari apresenta uma proposta de ampliação da arquitetura multiagente reativa descrita em, através de uma técnica de aprendizagem por reforço (WLearning).
Esta técnica trouxe resultados que ampliaram a capacidade de exploração do ambiente de jogo, pois os agentes reativos (peixes) aprenderam novos comportamentos.
A possibilidade dos peixes aprenderem novos comportamentos nos levou a questionar como isso impactaria a proposta original de.
Este trabalho de pesquisa propõe a extensão da arquitetura proposta por, para auxiliar a gerência das informações de um STI modelado como um jogo educacional utilizando uma arquitetura multiagente.
Buscamos com estas contribuições solucionar algumas das dificuldades encontradas em modelar este tipo de sistema, assim como ampliar a pesquisa tanto na área de Informática na Educação como a de Inteligência Artificial aplicada à Educação.
Este trabalho se divide em oito capítulos.
Em o capítulo 2 descrevemos a estrutura deste trabalho de pesquisa, nossa principal motivação, o problema em questão, nossa questão de pesquisa e objetivos a serem alcançados.
O capítulo 3 apresenta a pesquisa realizada sobre Agentes de Interface e a modelagem de STI, com a finalidade de obtermos um referencial teórico para o entendimento do problema descrito no capítulo 2, e assim propormos nossa solução.
O capítulo 4 descreve as arquiteturas dos sistemas propostos por e, e as particularidades da solução proposta.
Em o capítulo 5 descrevemos o protótipo que foi desenvolvido com a finalidade de comprovar nossas hipóteses.
Em o capítulo 6 apresentamos nossas conclusões, as limitações encontradas em nossa proposta e sugestões para trabalhos que venham dar continuidade a esta pesquisa.
O capítulo 7 apresenta as referências bibliográficas.
O capítulo 8 contém os anexos.
Motivação Os Sistemas Tutores Inteligentes (STI) originalmente foram idealizados para possibilitar uma instrução/ ensino personalizada a cada aluno (usuário) do sistema.
Entretanto, esta não é uma tarefa trivial, especialmente no que tange a modelagem do aluno e a construção do ambiente.
Muitos problemas ainda estão em aberto para que efetivamente tenhamos STI robustos, confiáveis e que se aproximem da maneira como humanos interagem numa situação de ensino aprendizagem, quer seja ela presencial ou virtual.
As soluções utilizadas nos STI clássicos como o de Konzen e Costa são bastante distantes do que se gostaria de fazer.
As possibilidades que a tecnologia de agentes trouxeram para os pesquisadores de STI permitiram que questões em aberto tais como:
Uso de múltiplas estratégias de ensino, múltiplas representações do conhecimento e modelos mais qualitativos de alunos pudessem ser retomadas.
Além de estas contribuições, novas modalidades para representação e manipulação do domínio surgiram, e com elas novas questões sobre a complexidade do projeto de STI.
Um exemplo é o trabalho desenvolvido por Giraffa, onde foi proposta uma arquitetura que utiliza o paradigma de jogos como forma de modelar o domínio da aplicação.
O trabalho de Giraffa foi utilizado como base para a investigação realizada por Callegari e Oliveira para aplicação de uma técnica de aprendizagem automática no domínio modelado como um Sistema Multiagente (SMA) Reativo.
A aplicação de algoritmos de aprendizagem por reforço aos agentes reativos do MCOE fez com que o grau de complexidade e o volume de informações geradas nas interações entre aluno e tutor aumentassem de forma considerável.
O desafio de pensar numa alternativa de solução para questão do gerenciamento destas informações num contexto mais complexo, foi nossa maior motivação.
Este trabalho apresenta uma alternativa de solução para este problema através da introdução de um agente para auxiliar o tutor nas suas tarefas de gerenciamento das informações do ambiente e atividades dos alunos, tendo por base a proposta de.
A idéia que permeia nosso trabalho é identificar quais as tarefas do tutor que podem ser &quot;terceirizadas «para um &quot;Assistente «(Agente).
O Tutor ficaria, então, com as tarefas de caráter pedagógico, tais como:
Selecionar a estratégia e o conjunto de táticas mais adequadas aos alunos.
Acredita- se que a inclusão desse &quot;Assistente «baixa a complexidade do tratamento do fluxo de informações, reduzindo a sobrecarga de tarefas a serem realizadas por o tutor.
Este &quot;assistente «estaria representado por a figura de um agente de interface (baseado no trabalho de e), que realizaria então um conjunto de tarefas e atividades que auxiliam o aluno e o tutor, tendo este último, como tarefa principal, a gestão da parte pedagógica do atendimento ao aluno.
No entanto, este agente não será, necessariamente, visível para o usuário, mas parte integrante da nova arquitetura proposta neste trabalho, e trabalhando internamente ao sistema.
Dependendo da aplicação pode- se pensar em tornar- lo presente (visível) na interface do sistema.
Problema escolhido para a dissertação O problema escolhido como desencadeador do trabalho de pesquisa baseia- se num dos pontos críticos no projeto de STI:
A complexidade da modelagem e implementação do tutor e o volume de tarefas desempenhadas por ele numa seção de trabalho.
Giraffa em observou que a tarefa de monitorar o ambiente (sistema) e o (s) aluno (s) durante as interações traz não somente uma sobrecarga ao sistema como um todo, mas também compromete sua performance (desempenho), interferindo direto na complexidade da modelagem do Tutor.
No entanto, a monitoração deste conjunto de informações é fundamental para o auxílio personalizado de o (s) aluno (s), sendo necessário buscar alternativas para reduzir esta complexidade.
Isto se agrava quando o domínio do sistema é um jogo, onde a quantidade de informações sobre o ambiente é demasiadamente grande.
Monitorar o aluno, as mudanças do ambiente (jogo) e, em função de isso, adequar o comportamento do tutor (estratégias) não é uma tarefa simples.
A forma como o projetista vai tratar este grande conjunto de informações é uma questão importante e que permanece sem uma resposta única.
Diversas pesquisas desenvolvidas (seção 3.3) exemplificam as alternativas existentes na literatura para tratar este problema.
Outra questão que emerge, com o uso desta abordagem, é a falta de uma definição clara dos papéis dos agentes do sistema, dentro de o processo de monitoração destas informações.
Questão de Pesquisa e hipóteses A questão de pesquisa deste trabalho é:
Que extensões serão necessárias na arquitetura proposta por para auxiliar a diminuir a complexidade de modelagem do tutor e facilitar a distribuição de suas tarefas?
Hipótese 1: Existem tarefas realizadas por o tutor que podem ser terceirizadas;
Hipótese 2: Em ambientes de jogos existem ações diretamente ligadas ao domínio do conteúdo, por parte de o aluno, e outras associadas a circunstâncias do jogo (por exemplo, o resultado da ação do outro colega, comportamento aleatório do jogo, etc).
Hipótese 3: A inclusão de um agente para mediar e organizar o conjunto de informações do ambiente, facilita o trabalho do tutor.
Hipótese 4: Existe a necessidade de se filtrar/ tratar o fluxo de mensagens entre os Sistemas Multiagentes Reativos (SMAR), aluno e tutor, a fim de melhorar a modelagem do sistema e permitir que o agente auxilie o tutor, bem como, os alunos.
Objetivo Estender a arquitetura proposta por para auxiliar a gerência das informações de um STI modelado como um jogo educacional em arquitetura multiagente.
Estudar a implementação dos ambientes MCOE e RL-MCOE no nível de implementação e organização da sociedade de agentes;
Estudar o impacto da aprendizagem por reforço aplicada aos peixes nos demais agentes da sociedade;
Identificar o conjunto de atividades a serem realizadas por o tutor e o agente mediador para monitorar os alunos e o ambiente;
Organizar o conjunto de estratégias e táticas associadas ao comportamento do tutor;
Organizar o conjunto de comportamentos desejáveis que o agente mediador desempenha dentro de o contexto do ambiente;
Identificar o conjunto de mensagens necessárias para garantir a interação entre aluno /mediador/tutor;
Apresentar uma proposta de arquitetura estendida que incorpore os requisitos necessários para solução da questão de pesquisa proposta.
Implementar um protótipo para verificar e validar a extensão proposta na arquitetura original.
A seguir apresentamos o referencial teórico utilizado como base para este trabalho.
Agentes de Interface A utilização de agentes de interface para auxiliar o usuário a manipular as informações contidas nas interfaces dos programas tem se tornado nos últimos anos foco de pesquisa nas áreas de interação homem-máquina, Inteligência Artificial (Ia) e Informática na Educação.
Os softwares, incluindo os softwares educacionais, atualmente são concebidos de forma a ampliar as funções disponíveis para realização de tarefas, e tendem a integrar diversos recursos aumentando, assim, a quantidade de informações que o usuário tem que identificar, associar, escolher e outros.
Este processo acarreta, muitas vezes, um alto &quot;custo cognitivo «para entendimento dos ícones (se for o caso) e funcionalidades da interface.
Segundo Lieberman, a crescente variedade de opções para definição e implementação de interfaces interativas (operações com menus e outras opções adicionadas a cada nova versão) estão ficando difíceis de serem manipuladas e entendidas por os usuários.
Lieberman ressalta que se insistirmos em manter a correspondência num para um entre as ações sobre a interface e suas capacidades, caracterizando uma manipulação direta com a interface, em breve atingiremos um ponto em que nenhuma nova funcionalidade poderá ser adicionada aos nossos sistemas devido a sobrecarga cognitiva que isto acarretará.
Isto é um reflexo da tendência de projetarmos interfaces que disponibilizam todos os recursos que o usuário necessita, na busca de oferecer possibilidades (alternativas) de execução de tarefas de forma completa e diversificada.
Segundo Theo Mandel, num futuro próximo, devido a os avanços das tecnologias de interface, novas funcionalidades poderão ser adicionadas de forma que usuário possa atingir seu objetivos de forma mais abrangente evitando a relação de um­ para- um.
A idéia chave é construir uma interface mais eficaz, que não force o usuário a fazer coisas de uma maneira fixa, permitindo que a informação ou ação do programa apareça numa forma completa.
Mandel sugere que a melhor maneira para fornecer ao usuário uma melhor interface seria projetar um software com as crenças, desejos, necessidades, experiências e expectativas do usuário, usando- as como base para o desenvolvimento do produto.
Certamente esta não é uma tarefa trivial.
Pensar em rastrear os desejos, expectativas, crenças e outros estados mentais para configurar o ambiente (interface) irá requerer um mecanismo de extração automática destes Estados Mentais (Em) a partir de um diálogo com o usuário, que neste momento não dispomos.
Trabalhos utilizando a abordagem mentalística mostram que a pesquisa em Em está avançando mas ainda não produziu resultados que respondam rapidamente as necessidades de configuração necessária para se aplicar no projeto de interfaces de forma efetiva.
Como fazer isto é o grande desafio dos projetistas, especialmente quando consideramos questões envolvendo configuração (automática ou não) e personalização das interfaces.
Lieberman sugere a utilização de agentes de interface para que auxiliem o usuário em suas tarefas, reduzindo a grande carga de informações utilizada por o usuário para realização das mesmas.
Este agente observaria o usuário propondo- lha automação de tarefas.
Por outro lado, esta tarefa demanda uma série de fatores que influenciam a performance do agente como, por exemplo, a quantidade de interações do usuário que o agente necessitaria observar para identificar tarefas automatizáveis, entre outros aspectos de projeto que serão abordados na seção 3.1.2.
Quando se considera a questão de configuração automática da interface através do uso de agentes (que teriam como tarefa capturar preferências do usuário e observar- lo buscando formar um &quot;modelo de usuário&quot;), esta tarefa tem um problema crítico semelhante ao agente assistente, porque demanda uma quantidade grande de interações até que o agente recolha as informações necessárias para fazer o perfil do usuário e, então, organizar a interface forma personalizada.
Para poder configurar automaticamente uma interface baseada nas particularidades do usuário, precisamos traçar seu perfil.
Isto demanda tempo e não se aplica a determinados sistemas que são utilizados de forma eventual por o usuário, como no caso de a maioria dos softwares educacionais.
Quando o professor utiliza um software educacional, este cumpre um papel dentro de o processo de aprendizagem do aluno e não é utilizado de forma tão freqüente, e portanto isso não garante uma coleta suficiente de informações para compor um modelo deste aluno, como seria necessário para a configuração automática.
Observa- se na literatura o grande uso de agentes de interface como executores de tarefas e auxiliares do usuário em suas atividades e.
Em os ambientes voltados ao ensino, o agente de interface, muitas vezes, é confundido como o próprio tutor, no caso de o Sistema Tutor Inteligente (STI) como será discutido adiante (na seção 3.3).
A utilização do termo agente de interface suscita uma variedade de entendimentos deste conceito.
Sua definição, através da tecnologia de agentes, estende- se desde programas que adaptam a interface ou realizam tarefas para o usuário, até módulos de arquiteturas multiagentes que realizam tarefas relacionadas com a interface do sistema.
No entanto, neste trabalho não iremos abordar os agentes que realizam estas tarefas uma vez que desejamos analisar os que automatizam tarefas para o usuário por a proximidade com o nosso trabalho de pesquisa.
Sendo assim, classificamos as diferentes abordagens encontradas na literatura.
Os agentes de interface são citados com as seguintes nomenclaturas:
Agentes de interface e como softbots.
As diferenças e as semelhanças destas duas abordagens podem ser explicadas através das definições dos seguintes autores:·
Lieberman: Um agente de interface é um programa que afeta os objetos de uma interface de manipulação, ou simplesmente, interface, mas sem uma instrução explícita do usuário.
O agente de interface lê as entradas que o usuário fornece através da interface e realiza mudanças nos objetos que o usuário vê na tela.
Estas mudanças podem ser ou não imediatas, ou seja, o agente pode observar várias entradas do usuário, por um longo período, antes de decidir qual decisão tomar ou uma única entrada pode laçar uma série de ações por parte de o agente;·
Etzioni e Weld:
Um agente de interface é descrito como sendo um robô, chamado- o de softbot, e sua tarefa é ser um assistente pessoal que permita realizar uma tarefa estabelecida por o usuário.
Este agente utiliza uma variedade de ferramentas de alto nível como gopher ou netfind do shell UNIX, para obter informações (entrada ou input do robô) e atua, por exemplo, com e-mail ou ftp (saída ou output de um robô).
Desta forma, o softbot pode realizar inferências a respeito de as informações obtidas e então traçar um plano para atingir o objetivo da tarefa a ser realizada.
Além disso, o softbot deve ser capaz de tratar a ambigüidade, omissão e erros nos dados fornecidos por o usuário.·
Lashkari, Metral e Maes:
Postulam que um agente de interface aprende continuamente, &quot;olhando através do ombro do usuário «as suas ações.
Ele monitora o usuário por longos períodos a fim de encontrar padrões de comportamento e, então, oferecer a automação dos mesmos.
Por exemplo, o agente de interface observa (constata) que o usuário costuma armazenar os e-mails enviados por a lista &quot;Algoritmos Genéticos «na pasta &quot;Inteligência Artificial&quot;;
Ele pode então, automatizar esta tarefa na próxima vez que uma mensagem enviada por lista, e tiver este conjunto de palavras, for encontrada.
Ele pode também automatizar a leitura, impressão, resposta e re-envio das mensagens como também determinar prioridades entre elas.
Lieberman compara os agentes de interface com algumas funcionalidades de Sistemas Tutores Inteligentes (STI) e Sistemas de Ajuda Sensíveis ao Contexto (SASC).
Ele descreve que tais sistemas são bons exemplos de agentes de interface onde o usuário pode operar a interface desconsiderando a presença do agente, podendo chamar- lo a qualquer momento para lhe fornecer sugestões ou realizar tarefas sobre os objetos da interface.
Outros agentes de interface podem criticar comportamento do usuário ou aumentar as ações de manipulação direta da interface, com informação extra adquirida e que o usuário julga interessante.
Esta é uma abordagem muito interessante para o trabalho desenvolvido como pesquisa de mestrado, e será detalhada mais adiante.
O softbot de Etzioni pode guardar informações relevantes sobre as tarefas realizadas para serem utilizadas no futuro.
Por exemplo, se o usuário deseja enviar um documento a uma pessoa num determinado grupo, o softbot pode procurar todas as pessoas com o nome fornecido através do comando finger ou então pesquisar em sua base de conhecimento os nomes familiares do local, e que foram adquiridos através de tarefas realizadas anteriormente.
Ele pode, também, realizar inferências a respeito de a informação que se deseja encontrar, dividindo um objetivo em subobjetivos para facilitar e otimizar a quantidade de tarefas que o agente tem para realizar.
Lashkari utiliza o algoritmo de Raciocínio Baseado em Memória para capturar os padrões do usuário.
Quando um usuário toma uma ação, o par situação e situação-ação (situação, situação-ação) é armazenado na memória do agente.
Por exemplo, quando o usuário lê uma mensagem M, o par (M, ação- ler) é memorizado, onde M contém detalhes da mensagem M e informações relevantes.
Quando ocorrem situações, elas são comparadas com as situações armazenadas anteriormente.
Uma vez armazenadas as situações semelhantes na memória, o agente pode calcular uma previsão de uma ação numa nova situação.
Além disso, ele pode calcular, também, o grau de confiança que desta previsão baseado no número de situações semelhantes e a proximidade entre elas.
Lieberman, no artigo Autonomous Interface Agents, descreve os Agentes de Interface Autônomos.
Em este artigo, é apresentado um novo conceito em o qual um agente é considerado um agente de interface e também um agente autônomo quando existe alguma parte da interface que o agente opera de forma autônoma.
O usuário será então capaz de diretamente observar as ações autônomas do agente assim como o agente deve ser capaz de observar as ações tomadas por o usuário na interface, de forma autônoma.
De maneira concreta, o usuário irá ver elementos da interface que parecerão estar se movendo sozinhos em resposta as entradas que o agente demonstra ver por si mesmo antes de ter sido explicitamente instruído.
Os agentes de interface podem ter diferentes disposições no processo de interação do usuário com uma aplicação.
Utilizamos as definições de Wexelblat para definirmos as categorias de Agentes de Interface, pois ele apresenta uma clara e bem elaborada categorização.
Wexelblat parte do princípio que agentes de interface são como um programa ou conjunto de programas com habilidade para compreender uma tarefa delegada por o usuário.
Um agente de interface está, de maneira conceitual, separado do sistema.
Desta forma o agente pode ser disposto das seguintes maneiras:·
O agente intermediador:
O agente serve como intermediário entre o usuário e a aplicação.
Desta forma o usuário interage somente com o agente, que traduz as entradas do usuário para o programa (Figura 3-2).
O agente faz parte da interface, servindo como um auxílio para uma interface mais convencional.
Em seus experimentos, Wexelblat observou que a segunda abordagem pode ter problemas ao tornar o usuário incapaz de ultrapassar o agente e isto pode causar um sentimento de falta de controle por parte de o usuário.
O agente Tatlin Lieberman exemplifica uma proposta de integração de agentes de interface com aplicações convencionais.
Este agente aprende através da observação das ações do usuário com a interface da aplicação e, então, cria uma série de procedimentos que são comuns de forma a automatizar tarefas para o usuário.
Duas etapas ocorrem:
O agente utiliza uma linguagem de scripts para gravar as ações do usuário e controlar a aplicação;
O agente usa um conceito que Lieberman chama de examinability, para aprendizagem através da comparação de sucessivos estados da aplicação.
Linguagens de scripts como por exemplo:
AppleScript, Microsoft Ole, ActiveX, Javascript, etc;
Permitem a comunicação entre aplicações, uma vez que estejam embutidas nas mesmas, e assim viabilizam a sua observação e manipulação de aplicações.
Lieberman chama este tipo de manipulação de Marionette strings.
A Microsoft Corporation criou um software chamado Microsoft Agent (Figura 3-3) que é um conjunto de serviços programáveis para software que permite a utilização de um personagem interativo animado, inserido na interface do Microsoft Windows.
Desta forma os programadores podem desenvolver suas aplicações anexando a elas estes personagens, e assim disponibilizar um assistente interativo que permita guiar, ajudar, entreter o usuário.
O programador pode utilizar os recursos do agente como, por exemplo, sintetização e reconhecimento de voz, gravação de som ou exibir textos em balões, de forma a aumentar a capacidade de interação do usuário com sua aplicação.
Este serviço é instalado no sistema operacional Windows do cliente e pode ser utilizado por programas instalados localmente no computador ou através da visualização de páginas html na Internet que o utilizem.
Wexelblat considera que qualquer programa pode ser considerado mais ou menos como um agente, sob o enfoque de agente de interface, dependendo do grau e o conjunto de propriedades que ele possui.
As propriedades que podem ser associadas são:·
Personalização: A personalização é a habilidade do sistema de conhecer o indivíduo que ele esta observando (em particular os seus objetivos, interesses, hábitos, preferências e assim por diante), alterando seus objetivos e métodos de operação para melhor atingir os desejos específicos do usuário.
O sistema pode ser personalizado para o indivíduo, para uma posição (por exemplo, um sistema que seria utilizado por vários empregados de um setor), para uma empresa onde os seus padrões de procedimentos são seguidos por todos os empregados.·
Autonomia: Autonomia é o grau que um sistema pode atuar sozinho por talvez longos períodos de tempo, sem instruções explícitas do usuário, e a habilidade do sistema em operar enquanto o usuário realiza outras tarefas.
Desta forma realiza tarefas úteis sem esperar por cada evento do usuário.·
Aprendizagem: Esta é propriedade do sistema que permite que ele observe, entenda e adapte- se as mudanças do ambiente.
A terminologia de agente deriva da Ia e encontra suas origens no hardware na noção de sensores.
A maneira com que o agente recolhe dados sobre o ambiente e os atuadores que utiliza são a forma do agente manipular o ambiente.
Em um ambiente de software, sensores e atuadores podem não ter significados físicos, mas a idéia de que um programa pode ter a habilidade de sentir e manipular o ambiente é aplicável e cada vez mais difundida.
Os efeitos de um sistema sobre o seu ambiente pode ser de vários graus, mas o aspecto importante da aprendizagem é o sistema poder sentir e entender as mudanças que ele esta fazendo e reagir de maneira diferenciada baseado no que ele observou.
A aplicação chave desta habilidade esta no sistema detectar e buscar mudanças na propriedade de personalização descrita anteriormente.
Cada uma destas propriedades permite trabalhar numa dimensão em a qual podemos medir os diferentes graus de um sistema.
Estes graus são a autonomia, maior personalização e capacidade de aprendizagem.
Estas considerações permitem dizer que o sistema funciona mais como um &quot;agente».
Não existe um limite para autonomia, personalização e aprendizagem.
Wexelblat definiu cinco aspectos a serem considerados no projeto de Agentes de Interface e que são relacionados às propriedades dos mesmos.
São eles:
Entendimento: Parte da definição da qualidade de um agente é a capacidade de ser compreendido.
O usuário deve ser capaz de entender o que o agente faz.
Geralmente os usuários tomam conhecimento através dos resultados obtidos por as ações do agente, no entanto existem diferentes formas de realizar esta tarefa, como por exemplo:
Confiança Os agentes são úteis a medida que os usuários confiam em eles, delegando- lhes tarefas que se realizem de forma autônoma, sem necessidade de instruções diretas ou repetitivas ou constante supervisão.
Assim, como para nós humanos existem diferentes níveis de confiança, o nível de confiança relacionado ao agente pode ser descrito de acordo com as características da tarefa que o agente irá desempenhar e principalmente com o grau de personificação (personificação será abordada mais adiante) do agente com relação a o usuário.
Ou seja, o usuário costuma ser mais tolerante com relação a tarefas delegadas ao agente que são de certa forma menos importantes para ele.
Por outro lado, quando o agente recebe tarefas de maior importância, como por exemplo, o agendamento de uma reunião, as implicações de um erro costumam a ser menos toleradas, o que diminui o grau de confiança no agente.
Confiança é um estado que cresce gradualmente conforme o agente vai se mostrando mais capaz de desempenhar as tarefas a ele delegadas.
Por exemplo, imagine um agente de interface que filtra informações para o usuário, vasculhando em grupos de newsgroups da Usenet e produza uma lista pessoal de artigos para o usuário ler.
O agente pode observar os hábitos de leitura do usuário e então, inicialmente, oferecer a filtragem dos grupos selecionados que existem em maior número de os quais o usuário lê apenas alguns artigos.
Esta é uma situação em que se procura maximizar a utilidade do agente enquanto minimiza os problemas com artigos que deveriam ser selecionados.
Através da oferta do maior benefício por o menor risco, o agente estimula o crescimento da confiança do usuário.
Um dos problemas de delegar tarefas, seja para um ser humano ou agente de software, é a tendência do usuário a não confiar nos métodos para realização de uma tarefa, de os quais ele desconhece ou não compreende.
Sendo assim, as vezes é mais vantajoso iniciar a execução de tarefas de forma o mais semelhante a do usuário, mesmo que existam métodos mais eficientes.
Uma vez que se obtêm a confiança de que o trabalho pode ser feito, o agente pode então utilizar métodos mais eficientes.
O crescimento da confiança do usuário no agente pode ser medida através do grau que o usuário aceita as sugestões do agente.
Controle Controle tem grande relação com confiança.
A cada momento que o usuário aumenta sua confiança no agente, ele pode dar mais controle sobre ações que o agente pode realizar.
Mas o importante é que o usuário é quem deve delegar este grau de controle e não o contrário.
Deixar isto para o agente caracterizaria o mesmo com o controle da situação.
Controle tem grande influência no projeto de agentes.
Primeiro, um agente deve ser apto a operar com diferentes graus de autonomia.
Se o usuário deseja ter controle de cada operação que o agente pode desenvolver, este se torna menos útil, o que significa que os agentes de interface são de natureza delegativa, ou seja, o usuário entrega ao agente as tarefas que ele pode também realizar.
Segundo, os agentes devem ser capazes de serem instruídos ou receberem tarefas num apropriado nível de detalhe.
O usuário não tem obrigação de informar certos detalhes de como as tarefas devem ser realizadas.
Um exemplo no mundo real é quando pegamos um táxi, onde nos preocupamos com algumas restrições como:
O caminho não deve ser muito longo, não deve custar muito caro e deve ser seguro.
Contudo, não nos preocupamos em dirigir o táxi, uma vez que delegamos esta tarefa ao motorista.
Isto está relacionado fortemente com as propriedades de um agente (autonomia, reatividade, pró-atividade, etc).
Muitos ambientes possuem tarefas complexas onde existem fatores que inevitavelmente são encontrados como, por exemplo, situações em que decisões importantes devem ser tomadas ou quando uma grande quantidade de tarefas deve ser classificada.
Isso exige muitas vezes que o usuário tome o controle para decidir o que o agente deve fazer.
Portanto, o agente realiza suas tarefas até que um destes fatores seja encontrado, e então neste momento o usuário é inserido no &quot;loop».
A interação do usuário neste &quot;Loop «não significa apenas o clique no botão &quot;OK «ou responder sim ou não numa janela dentro de uma seqüência de execução.
O usuário pode não entender onde no processo o agente está inserido, ou como ele chegou até lá, mas ele deve receber informação suficiente para entender o que o agente está perguntando e porquê.
Sendo assim, quando uma situação de decisão não pode ser atendida por o usuário, seja porque ele não está disponível ou porque ele não tem tempo para considerar a decisão, o agente pode suspender a execução até o momento que o usuário puder responder.
A capacidade de poder trocar o controle das ações, usuário e agente de interface, a propriedades como parar (pause) e continuar (resume), colocar o agente em modo de aprendizagem (learing mode) para poder demonstrar um procedimento para o agente, entre outras, são métodos utilizados para dar um maior controle ao usuário sobre as ações do agente de interface.
Distração A maioria dos projetos de interfaces de software são normalmente concentradas em padrões de usabilidade como o formato da tela, cores, fontes e etc., onde o software aguarda por as entradas do usuário.
No entanto, os agentes de interface funcionam com um certo grau de autonomia e isso lhes permite, em alguns casos, tomar a iniciativa de comunicação com o usuário.
Esta iniciativa pode se dar de várias formas como som, imagens ou a combinação de ambas.
Observase que qualquer mudança na interface que não seja esperada por o o usuário é chamada de distração.
Se a atenção do usuário for direcionada para uma tarefa do agente, a iniciativa do agente será vista como uma distração.
A distração é abordada mais como um problema pois ela interrompe o trabalho do usuário, já que o objetivo de um agente de interface é trabalhar para o usuário.
Ela pode também ocorrer sem que o agente esteja visível.
Por exemplo, um agente que consome todos os recursos do sistema conseqüentemente não permite que outros programas funcionem, o que claramente interrompe o trabalho do usuário.
Mas, a distração se observa na interface através da forma com que são realizadas as suas alterações.
Uma interrupção do usuário pode ser feita de diferentes maneiras.
Por exemplo, no Netscape Mail Notification (Figura 3-6).
Este software fica localizado na barra de tarefas1 e verifica o recebimento de novos e-mails sem a necessidade de carregar o Netscape.
Ele informa o usuário sobre a chegada de novos e-mails através uma imagem animada (bandeira) e também emite um som, caso o usuário assim queira.
A forma de interferência utilizada por este software busca reduzir a interrupção das atividades do usuário.
Ela permite que o usuário se mantenha informado sem interromper diretamente o seu trabalho.
A busca do menor nível de interrupção é um dos objetivos desejados num agente de interface.
Lembrando que, o usuário pode ter a opção também de personalizar estes níveis de acordo com as suas necessidades.
Personificação Para se abordar esta questão, se faz necessário distinguir o significado de antropomorfismo e o de personificação.
Antropomorfismo, no âmbito da Informática, significa a utilização de recursos gráficos e/ ou de sons para criar uma presença do tipo humana na interface.
Por exemplo, a geração da imagem Barra de tarefas da família de Sistemas Operacionais Microsoft Windows de uma pessoa, com características humanas, com a finalidade de interagir com o usuário.
A personificação é a tendência de se atribuir características humanas como, emoções e raciocínio, a animais ou objetos, e neste caso ao computador ou software.
Um exemplo é quando falamos &quot;a impressora não gosta de mim «ou &quot;o computador não está a fim de ajudar».
Apesar de muitas vezes estas situações ocorrerem em momentos que o computador não funciona corretamente, frases do tipo &quot;como ele fez isso?»
ocorrem quando o computador realiza tarefas consideradas inteligentes ou de as quais não compreendemos.
Uma vez que se queira tirar vantagem das características sociais dos usuários, a questão que surge é quanto um agente necessita ser personificado.
O ser humano tem uma grande tendência a personificar coisas como objetos e animais, basta saber como e quanto uma agente deverá ser personalizado, e como ele pode ser projetado a fim de estimular, se necessário, esta personificação.
O estímulo pode se dar através de janelas de mensagens como por exemplo, quando uma agente de interface mostra a mensagem «Eu irei filtrar seus quem irá realizar a tarefa, se é o usuário, o computador ou o programa.
É necessário discutir a quantidade ou intensidade deste aspecto, uma vez que o excesso de personificação pode geram muita expectativa ou uma falsa idéia das capacidades do agente.
Segundo, a maioria dos agentes comercializados até 1997 não possuia uma representação visível, de maneira que gerar uma forma personificada para um agente de interface pode trazer vantagens.
A utilização de desenhos, ou imagens que retratem pessoas, e que transmitam emoções, atitudes e intenções, podem ser úteis para que o usuário compreenda as funções do agente ao mesmo tempo em que torna menos hostil a interface.
A fidelidade a forma da figura humana não tão decisiva como fator que aumente a confiança do usuário no agente.
Conclui- se que a representação explícita do agente não é uma necessidade.
Porém, ela permite que o usuário fique mais à vontade durante a sua interação tornando- a mais pessoal e efetiva, maximizando o entendimento e a confiança no agente.
No caso de aplicações educacionais vai depender do objetivo do sistema a sua representação explícita ou não.
Em a nossa proposta deixamos esta questão em aberto para ser decidida por a equipe de projeto do sistema.
O fato identificado foi a necessidade de termos tal agente presente na arquitetura do sistema.
Wexelblat cita que uma das razões para chamarmos nossos sistemas de agentes ao invés de softwares é que devemos lembrar que quando um usuário delega alguma tarefa a outro usuário, ele sabe que as tarefas podem não ser feitas da maneira que ele espera.
Ele também deve ser capaz de acreditar nas capacidades do outro usuário, e confiar que ela pode ser feita.
Ele precisa aceitar compartilhar o seu trabalho, e isso necessita uma certa quantidade de comunicação.
Entre dois usuários isso é &quot;geralmente «simples.
Sendo assim, se faz necessário discutir este novo domínio de problemas, uma vez que os agentes de interface estão surgindo como assistentes para o usuário e com amplas aplicações em projetos de software.
O módulo tutor em STI visto como um agente de interface A idéia de se utilizar o computador como uma &quot;máquina de ensino «buscando automatizar o processo de aprendizagem, motivou os primeiros esforços da década de 60 na utilização de computadores para suporte às atividades docentes.
O paradigma vigente, na época, era eminentemente comportamentalista (Psicologia) e tecnicista (Ciência da Educação).
As tentativas iniciais baseavam- se em apresentar o material instrucional selecionado por o professor ou especialista, de forma estruturada obedecendo a uma seqüência prédeterminada e rígida.
Não havia previsão de escolhas por parte de o aluno.
Os sistemas basicamente ofereciam duas opções para que o aluno escolhesse a solução do problema.
A modelagem considerava, também, textos e exercícios associados, onde os alunos adquiriam conhecimento e habilidades num determinado domínio (conteúdo).
Os softwares reproduziam o sistema expositivo de ensino, que permeava o sistema educacional da época.
Uma porção do conteúdo era apresentada numa ou mais telas (no início interfaces orientadas a caracteres, sem gráficos ou desenhos), e a interação limitavase a apertar a tecla para mudar de tela.
Após a seqüência de telas onde o conteúdo era disponibilizado, era apresentado o bloco de exercícios.
Estes eram de escolha simples ou escolha múltipla.
Esta forma de ensino computadorizado recebeu o nome Computer Assisted Instruction (Cai).
Eles eram impessoais, sob o ponto de vista instrucional, e não objetivavam nenhum tipo de personalização levando em conta o perfil do usuário.
Em a década de 70, Carbonell apresenta uma nova proposta sobre a questão de a «aprendizagem-computadorizada, ou seja, aprendizagem suportada por ambiente (software) educacional.
Ele propôs, com o sistema Scholar, uma nova maneira de conceber estes sistemas levando em consideração a forma como o professor estrutura e desenvolve o conteúdo em sala de aula, ou seja, considerando a dinamicidade que existe na relação aluno-professor.
Ele se baseou no fato de que numa situação de sala de aula o professor observa os alunos e faz uma verificação constante do que está acontecendo durante o andamento das atividades na sala de aula.
E isto deveria ser possível de ser modelado num software educacional.
O professor recebe &quot;feedback «dos alunos tanto verbal, como na forma de atitudes observadoras (movimentos dos olhos, expressão do corpo, etc).
Quando ele aplica um exercício ou teste, é possível medir ou inferir o estado cognitivo corrente do aluno (indicador do seu aproveitamento).
A partir de a avaliação destes dados ele muda seu comportamento (estratégias) e táticas para atuar junto ao aluno.
Esta dinâmica de sala de aula é que se pretende associar ao sistema, i.
É, a idéia de se buscar uma instrução mais personalizada, ou menos impessoal.
Ao contrário de os Cais, estes novos sistemas não realizariam a tarefa de ensinar de uma forma única, mas como uma estrutura orientada à informação, onde o conteúdo que o sistema possui é representado computacionalmente através de diversas formas de representação do conhecimento.
Em o sistema proposto por Carbonel, o conteúdo era representado por redes semânticas.
Desta forma, o sistema mantém um diálogo com o aluno, através do formato textual, utilizando um subconjunto da língua natural em que o sistema foi desenvolvido.
O sistema se baseava nos avanços da área de Inteligência Artificial (Ia), na época (década de 70).
O sistema Scholar e outros trabalhos como o WHY e SOPHIE de Collins e Brown apud, constituem os primeiros Intelligent Cais (ICAI) ou Sistemas Tutores Inteligentes (STI), lembrando que ICAI e STI eram considerados como sinônimos nesta época.
Atualmente isto não é consenso na área de Ia-ED.
Os STI têm como principal objetivo realizar tarefa de aprendizagem de um dado conteúdo (domínio) de forma mais adaptada às necessidades individuais do aluno.
Estes sistemas se baseiam numa arquitetura (representada na Figura 3-7) composta basicamente por:·
Módulo aluno:
Em este módulo estão armazenadas/ modeladas as características individuais do aluno (conhecimento individual sobre o domínio);·
Módulo tutor:
Possui o conhecimento sobre as estratégias e táticas para selecionalas em função de as características do aluno (representadas no módulo aluno);·
Módulo domínio:
Detêm o conhecimento sobre a matéria no formato de regras de produção, estereótipos, etc;·
Interface: Intermedia a interação entre o tutor e o aluno.
Esta arquitetura é denominada de clássica e também conhecida como funcional tripartida (devido a os três módulos envolvidos no ciclo de tutoração) ou tradicional de STI.
Esta proposta trouxe grandes avanços à modelagem de ambientes educacionais, pois separou o domínio da sua forma de manipulação (no sentido de utilização).
Permitindo, assim, que estratégias de ensino fossem associadas em função de as informações oriundas da modelagem do aluno.
Os STI que utilizam esta arquitetura e foram implementados em paradigmas procedurais, apresentaram certas limitações em função de as linguagens utilizadas e do hardware disponível.
A impossibilidade de representar domínios complexos, e falta de uma visão (ou controle) global sobre a aprendizagem do aluno (que permitisse a compreensão das concepções errônea e má interpretações por parte de o aluno), não permitiram a criação de sistemas que atendessem às pretensões iniciais dos STI propostas por Carbonell e seu grupo.
As pesquisas em Inteligência Artificial Distribuída (IAD) no processo de modelagem de sistemas, especialmente os Sistemas Multiagentes (SMA), permitiam que novos níveis de abstração pudessem ser abordados no projeto de STI e resgatadas às questões em aberto pendentes na área.
Modelar STI utilizando uma sociedade de agentes, em substituição aos módulos tradicionais permite, por exemplo, que o módulo tutor não seja composto por uma entidade única, responsável por a tarefa de tutoria, mas composta por vários tutores, como no projeto MATHEMA de.
Em este ambiente cada tutor é um especialista num subconjunto do domínio, permitindo, assim, uma maior especialização do módulo tutor e a adição de novas possibilidades, sob o ponto de vista de uso de múltiplas estratégia de ensino.
A arquitetura clássica, foi ampliada por para se tornar uma arquitetura associada ao modelo de interação que ocorre ao longo de uma sessão de trabalho entre o (s) aluno (s) e o ambiente.
O módulo de domínio não é mais uma forma de tornar as informações interrelacionadas, mas sim um modelo dos aspectos do conhecimento sobre o domínio que o aluno pode acessar durante as interações com o STI (Modelo da situação).
O módulo do estudante não mais relaciona somente as informações sobre a análise das interações do aluno com o domínio, mas busca uma contextualização maior destas interações em função de as ações do aluno, o contexto em que elas ocorrem e a estrutura cognitiva do aluno naquele momento (Modelo de Interação).
O módulo tutor deixou de ser o responsável por a seleção do conteúdo e estratégias para se tornar, de uma forma mais ampla, aquele que conduz o aluno de acordo com objetivos e desafios educacionais que o ambiente proporciona ao aluno (Modelo de permissões).
No entanto, assim como a arquitetura clássica possuía limitações, ainda existem questões que não puderam ser solucionadas como por exemplo:·
o hardware ainda não tem a capacidade de processar satisfatoriamente imagem, voz, cheiro, etc;·
o processamento da linguagem natural ainda é uma questão de pesquisa em aberto;·
a comunicação e o tratamento de informações oriundas da interface são restritos, caracterizando uma interação considerada muito simples.
Todas estas restrições acabam tornando o tutor incapaz de tratar, em sua totalidade, o conjunto de informações que o professor possui em sala de aula.
Contribuições de outras áreas, como a de redes de computadores e sistemas distribuídos, trouxeram novas ferramentas para o ensino, como por exemplo e-mail, fórum, chat, vídeo conferências, informações on-line, e outras(,,, e).
Estas contribuições colocam a relevância de um ensinocomputadorizado, uma vez que estas alternativas vêm ao encontro de as necessidades que os tutores se propõem a resolver:
Ensino personalizado e com a possibilidade de ser realizado em grande escala.
Observa- se, no entanto, que a utilização de um tutor, com uma estratégia menos diretiva, a qual não determina totalmente os caminhos da interação entre o aluno e o conhecimento, permite que o STI atue de forma a complementar o ensino em sala de aula, auxiliando o professor em sua tarefa.
Esta assistência desenvolve um processo contínuo, ao qual Giraffa chama de coreografia, e que pode ser associada ao ciclo de tutoração.
Esta coreografia representa assistência personalizada do tutor, em função de o modelo cognitivo atual do aluno.
Esta assistência tem com finalidade organizar o domínio de acordo com os objetivos educacionais modelados no STI (como por exemplo o paradigma construtivista).
Esta organização do domínio busca alterar o estado cognitivo do aluno (modelo do aluno), finalizando um ciclo na coreografia desenvolvida por o tutor.
Desta forma, o tutor realiza suas funções com a finalidade de assistir o aluno de acordo com suas características individuais, auxiliando- o a organizar o conteúdo apresentado.
Esta assistência segue então os objetivos educacionais desempenhados por o tutor, sendo estes, explicitados através das estratégias e táticas selecionadas.
Desta forma os STI podem desempenhar suas tarefas, auxiliar o aluno e principalmente coletar informações e complementar as tarefas do professor.
Modelagem de tutores em STI Em a literatura encontramos os STI modelados em duas abordagens:
A clássica (funcional, em módulos) e utilizando agentes (os módulos tradicionais são substituídos por uma sociedade de agentes).
Em esta seção analisaremos a modelagem do tutor nestas duas abordagens.
Segundo Wenger, na abordagem clássica o papel do módulo tutor é tomar as decisões pedagógicas em função de as interações com o aluno.
Estas decisões derivam de regras ou estruturas de conhecimento as quais representam o conhecimento do tutor a respeito de o domínio, e estas estão representadas de forma definida no sistema (Módulo Tutor).
O tutor utiliza o modelo do aluno e do modelo de domínio para tomada das decisões didáticas e pedagógicas.
A nível global, estas decisões afetam a seqüência de apresentação do conteúdo, intervenções e questionamentos a serem feitos ao aluno.
Através da forma com que os assuntos estão relacionados, o módulo tutor adapta sua apresentação dos tópicos às necessidades do aluno.
A nível local no sistema (módulo tutor), o tutor decide quando uma intervenção é desejável, se o aluno deve ser interrompido em sua atividade ou não e o que deve ser apresentado em função de as informações avaliadas num dado momento.
A ordem e a maneira com que cada assunto é trabalhado pode produzir diferentes resultados na aprendizagem.
Em os tutores clássicos o controle varia conforme algum critério de otimização, e costuma ser uma decisão de projeto, ou seja, não existe mudança na forma com que é controlada a interação.
Alguns sistemas podem monitorar as atividades dos alunos de perto, adaptando suas ações as respostas dos alunos mas nunca cedendo o controle da interação.
Em diálogos com iniciativas mistas, o controle é compartilhado por o estudante e o sistema, assim como ocorre a troca de perguntas e respostas.
Em este caso, o sistema deve então ser capaz de responder as perguntas do estudante.
Em atividades orientadas ou guideddiscovery learning, o estudante possui o controle total da atividade, e a única maneira do sistema conduzir o aluno é realizando mudanças no ambiente.
Esta forma de controle torna difícil a análise do processo.
Porém a possibilidade do aluno agir de forma independente permite que o sistema não interfira inadequadamente em caso de dúvida.
O tutor analisa as respostas e perguntas do aluno, assim como outras interações (como por exemplo a forma como o aluno desenvolve a solução das tarefas) afins de atualizar o modelo de aluno do sistema.
Esta análise busca adaptar os objetivos do tutor em função de o aluno e do conteúdo que deve ser apresentado.
Em comparação com o professor, os tutores clássicos estão limitados a um único método de ensino e aprendizagem, em função de as limitações na quantidade de regras que podem ser descritas.
A falta de habilidade para ensinar de maneira flexível, adotando diferentes métodos de ensino de maneira apropriada, e permitindo que os estudantes utilizem diferentes estilos aprendizagem restringem as capacidades de um STI clássico.
Wenger considera que no clássico Scholar as estratégias eram primitivas e consistiam principalmente na seleção de tópicos locais.
Estes tópicos locais estavam localizados nos nodos das redes semânticas, que continham uma representação estruturada do conteúdo.
O aluno podia fazer perguntas ao sistema e este deveria identificar as informações relevantes contidas na pergunta de acordo com o domínio.
Isto era feito em função de a distância entre o nodo em que o dado relevante da pergunta está localizado, e o nodo atual (tópico atual).
A cada nodo foram adicionados pesos (na forma de etiquetas numéricas) que permitiam o tutor identificar se o próximo nodo era ou não mais relevante para então gerar perguntas quando a iniciativa era a sua.
No entanto, se estas etiquetas não serviam para a tomada de decisão, eram feitas escolhas aleatórias.
A partir de os resultados obtidos com o Scholar, Collins apud, apresentou o projeto WHY onde seu principal objetivo era fazer um tutor socrático, fruto de sua análise da aplicação do método socrático em tutores e da pesquisa realizada por Carbonell.
Segundo, um tutor socrático ensina através de uma abordagem de exposição indireta, que consiste na oferta, ao aluno, de questões sucessivas que visam formular princípios gerais baseados em casos particulares para que ele possa analisar e avaliar hipóteses, descobrir contradições e finalmente fazer inferências corretas.
Collins gerou aproximadamente sessenta regras que procuravam montar uma estratégia tutorial, que levava em consideração o tipo de aluno que usava o tutor.
Já na metade da década de 80, era crescente o interesse em modelos didático computacionais.
Este assunto permaneceu como uma limitação aos tutores, já que novas estratégias eram abordagens baseadas no conhecimento do tutor humano, cuja habilidade é complexa e, até aquele momento, difícil de ser tratada computacionalmente.
Alguns trabalhos tentaram buscar alternativas na tentativa de tornar um tutor flexível na condução das interações com o aluno, alterando suas estratégias.
O tutor QUADRATIC apud, podia modificar suas próprias estratégias, mas estas modificações eram basicamente ajustes de parâmetros.
Em o Tutor Espertinho de Konzen, o primeiro passo na utilização do sistema é a determinação do perfil do aluno.
Este perfil influenciará na forma de exposição do conteúdo é determinado através de um questionário que determinam o nome, preferência de cores e características de interação (se o aluno possui um perfil visual ou auditivo).
Estas informações restringem a adaptação do tutor na determinação de fatores sobre a interface, e que por sua vez são estáticos, já que não se alteram durante a sessão de trabalho.
Observa- se que os STI clássicos, de uma forma geral, se caracterizam por utilizar uma única estratégia para o ensino do aluno na mesma seção de trabalho.
Mudando apenas quando uma nova sessão inicia.
Ou seja, estes sistemas possuem pouca versatilidade em seu comportamento pedagógico, sem proporcionar uma adaptação dinâmica (no nível de estratégias) as características individuais de aprendizagem de cada aluno.
Em o trabalho de é proposto um modelo de STI para educação de adultos.
Para tal, o modelo abrange alguns princípios pedagógicos das teorias de Knowles, Cross, Bruner e Vygostky apud aplicados para adultos.
Estes princípios foram aplicados a cada um dos módulos da arquitetura clássica de STI.
O modelo foi implementado utilizando mapas conceituais para representar interna e graficamente o conteúdo.
Um editor gráfico permite que tanto o aluno quanto o autor da base de conhecimento (domínio) possam criar mapas conceituais para descrever o conhecimento no sistema.
O módulo tutor tem a tarefa de transformar os relacionamentos expressos no mapa em asserções, para então apresentas- las ao aluno.
Através da análise gráfica do mapa conceitual do aluno, o módulo tutor pode propor ao aluno que novos relacionamentos podem ser incluídos.
Esta análise se da em função de a comparação entre o mapa conceitual do aluno e o do professor.
Em função de o desenvolvimento da Ia distribuída, e da crescente pesquisa em SMA, a tecnologia de agentes passou a ser adotada como uma metodologia alternativa para projetar STI.
Segundo Giraffa, a razão fundamental para modelar STI com uma arquitetura multiagente são suas capacidades de comunicação e interação.
Agentes podem se adaptar e aprender durante uma sessão.
Os agentes desenvolvidos para ambientes de ensino recebem o nome de agentes pedagógicos e seus objetivos podem ser descritos em função de o seu comportamento (estratégia).
Segundo, os comportamentos possíveis para o tutor são:·
Guia: O agente é diretivo em suas intervenções e monitora o aluno todo tempo, conduzindo- o na resolução do problema durante todo processo de interação;·
Assistente: O agente é menos diretivo e monitora o aluno todo o tempo, intervindo baseado em heurísticas sobre a resolução do problema daquele domínio;·
Facilitador: O agente monitora o aluno todo o tempo porém não é diretivo.
Ele apenas oferece dicas sobre a resolução do problema e só intervém quando solicitado.
O tutor pode utilizar um ou vários comportamentos, sendo assim os objetivos podem variar em função de as informações recebidas do usuário (ações do aluno) e da situação que se deseja atingir (plano).
Os agentes pedagógicos2 podem atuar como tutores virtuais, alunos virtuais ou colegas virtuais que auxiliam no processo de aprendizagem.
Estas diferentes formas de atuação podem compor grupos de agentes que distribuem entres si as tarefas.
Estas tarefas podem ser de maior abrangência (modelagem do aluno ou seleção da estratégia e táticas) ou de menor abrangência (cada agente é responsável por uma estratégia).
A distribuição de tarefas permite um melhor desempenho do sistema, subdividindo a complexidade da tutoria em tarefas menores.
A partir de a divisão de tarefas, a tarefa de tutoria passa a ser executada num nível de abstração mais alto.
Desta forma Gouarderes Utilizamos o termo, agente pedagógico, proposto por Vassileva para identificar agentes em ambientes educacionais.
Sugere uma caracterização do processo de aprendizagem desenvolvido em sistemas multiagentes em três níveis de abstração:
Em esta arquitetura o processo de aprendizagem se caracteriza por a capacidade de adaptação dos agentes na condução do aluno;
A partir destes conceitos, passaremos a analisar alguns STI que utilizam agentes em sua arquitetura e como se desenvolve a tarefa de tutoria nestes sistemas.
Estes sistemas foram intencionalmente escolhidos por serem atuais e utilizarem o paradigma construtivista na sua concepção.
Em este paradigma o aluno e o resultado de suas tomadas de decisão são o foco principal do sistema.
Busca- se monitorar o aluno e mapear os erros cometidos e, a partir de eles, fornecer orientação baseada no pensamento reflexivo (análise do erro frente a o contexto).
O sistema LeCS de Rosatelli tem como objetivo dar suporte à aprendizagem colaborativa através da Internet utilizando o método de Estudos de Casos.
Este método tem como objetivo ensinar aos alunos conteúdos baseados em situações complexas e reais.
São apresentadas situações problema onde o aluno deverá buscar uma solução.
A falta de uma estrutura definida no domínio permite que o aluno desenvolva uma flexibilidade cognitiva para que possa lidar com tais situações.
O sistema LeCS é composto por uma sociedade de agentes (arquitetura federativa), que por sua vez é composta por agentes de interface, agente de informação, agente de aconselhamento e um agente facilitador.
O papel do tutor é desempenhado de forma distribuída.
O Agente de Informação lida com o domínio e com o conhecimento pedagógico.
Ele armazena o conteúdo a ser apresentado ao aluno bem como o conhecimento para transmitir- lo.
Este conhecimento está armazenado sob a forma de casos e regras.
O Agente de Aconselhamento dá assistência aos participantes através da monitoração do processo de aprendizagem e realizando intervenções quando necessário.
Estas intervenções dizem respeito ao tempo, à participação, aos erros de compreensão dos alunos que são específicos do estudo de casos e à coordenação no uso das ferramentas da interface.
O Agente de Interface, além de se comunicar com o aluno, realiza a tarefa de modelagem do aluno.
A base de crenças do agente inclui as informações que o agente armazena sobre usuários individuais:
O passo da metodologia em que cada participante está trabalhando, a resposta conjunta do grupo para caso (esta informação é armazenada em apenas um agente de um grupo de alunos).
O agente prepara e ordena as requisições do aluno numa estrutura de dados interna monitorando suas atividades.
A comunicação entre os agentes é intermediada por o agente facilitador.
Com base nas informações (modelo do aluno) armazenadas por o Agente de Interface, este agente e os Agentes de Informação e Aconselhamento desenvolvem o conteúdo e inferem o auxílio necessário para cada aluno.
O conhecimento sobre a estratégia esta distribuída.
O Agente de informação contém o conhecimento sobre a estratégia e a apresentação do conteúdo, já o Agente de Aconselhamento possui o conhecimento específico de como auxiliar o aluno por meio de a estratégia de estudo de casos.
O sistema ITStrategic de Marietto tem como objetivo definir as estratégias instrucionais do STI de forma dinâmica, visando aumentar a adaptabilidade do sistema ao perfil do aluno.
Em este sistema o papel do tutor é desenvolvido de forma distribuída.
O ITStratégic é composto por cinco módulos, de entre estes 4 desempenham a tarefa de tutoria:
O módulo percepção, módulo estudante, o módulo tutoria e o módulo entrega.
Estes módulos são compostos por agentes que desenvolvem subtarefas.
O módulo percepção é formado por receptores (administrador, educador e estudante), que personalizam os diálogos (interface) com os diferentes usuários do sistema (administrador, professor e aluno).
Cada usuário tem uma interação relacionada a suas tarefas para com o sistema (como por exemplo o professor, que tem o papel de atualizar a base de domínio com novos conteúdos).
O módulo estudante é formado por o agente Guia, que é responsável por a ativação ou criação de um modelo de aluno, bem como atualizar e disponibilizar este modelo à sociedade de agentes.
O módulo tutoria é composto por o agente Tutor, que é responsável por a seleção da estratégia de acordo com o modelo cognitivo atual do aluno que serão utilizados para criação de um plano instrucional (chamado plano instrucional linear).
Estas estratégias são descritas por meio de Arquiteturas Instrucionais, que são propostas por Ruth Clark apud Ruth Clark apresenta quatro arquiteturas instrucionais para sistemas de tutoria.
São elas:
Receptiva, diretiva, orientada a descoberta e exploratória.
A partir de estas arquiteturas é proposto o momento instrucional adequado para aplicação de cada uma de elas.
Para isso são definidos os conceitos de desempenho de transferência próxima e distante.
Desempenho de transferência próxima define uma tarefa para o aluno com formato padronizado, com uma estrutura que permite a execução passo a passo, numa seqüência bem definida de procedimentos.
Já o desempenho de transferência distante exige do estudante um certo grau de julgamento e abordagens diferentes para realizar suas tarefas.
As arquiteturas propostas por Clark foram adaptadas para o protótipo ITStrategic, a fim de demonstrar a dinâmica a sua seleção.
É possível fazer uma analogia destas arquiteturas e sua correspondência com os comportamentos do tutor descritos anteriormente por.
Em a Tabela 3-1 estão relacionadas as linhas gerais para seleção de uma arquitetura instrucional no ITStrategic e os comportamentos do tutor.
O plano criado por o módulo de tutoria é então executado por o módulo de entrega que é composto por duas sociedades de agentes:
SAEI (Sociedade dos agentes de eventos instrucionais) e a SDAAI (Sociedade didática dos agentes com arquitetura instrucional).
Os SDAAI fazem a exposição do conteúdo em função de as arquiteturas instrucionais determinadas por o Módulo Tutorial.
Em esta sociedade cada agente é responsável por uma arquitetura, retirando do tutor a tarefa de sequenciamento do conteúdo.
Marietto considera que a utilização de sociedades de agentes permite analisar a tutoria sob aspectos sociais e políticos, dando uma nova abordagem à implementação da instrução por computador.
Aïmuer e Frasson desenvolveram um estudo na utilização de múltiplas estratégias em função de diferentes níveis de conhecimento.
Em este trabalho foram analisadas as aprendizagens um a um, com um colega (companion), através do ensino (by teaching) e aprendizagem por perturbação (disturbing) que foi proposta por Aïmuer e Frasson.
Em a aprendizagem um a um o conteúdo é desenvolvido por o tutor o qual compreende as ações do aluno e provém um ensino adaptado as necessidades individuais do aluno.
Em a aprendizagem com um colega o aluno aprende em companhia de um colega artificial (agente) que interage com o tutor, em conjunto com o aluno.
O aluno artificial também busca respostas as questões propostas por o tutor, como também as discute com o aluno real.
Desta forma procura- se que o aluno acompanhe o raciocínio do colega.
A aprendizagem por ensino coloca o aprendiz humano na posição de professor, tendo então de ensinar o seu companheiro dando exemplos, explicações e soluções para o colega artificial.
Por fim, na aprendizagem por perturbação, participam da interação o tutor, o aluno e o aluno artificial (Troublemaker).
No entanto, diferente da aprendizagem com um colega, o colega do aluno real possui diferentes comportamentos:
Dar respostas para um dado problema com a finalidade de forçar o aluno a reagir e propor a solução correta, ou esperar por a solução do aluno e então dar sugestões, soluções erradas ou um contra-exemplo.
Desta forma o aluno da sua explicação para o aluno artificial sob o controle do tutor.
Se o aluno não é capaz de dar a resposta correta, então o tutor auxilia dando a reposta.
Aïmuer e Frasson realizaram um experimento em, utilizando a linguagem Html onde eram apresentadas questões sobre normas de trânsito para validar o uso de múltiplas estratégias numa forma progressiva.
O experimento trouxe os seguintes resultados:
A aprendizagem por perturbação traz melhores resultados para pessoas com bons conhecimentos sobre o conteúdo, e parece ser menos eficiente para pessoas com pouco conhecimento;
O colega artificial se mostrou eficiente com alunos fracos;
Frasson sugere que o motivo para a estratégia de perturbação não ser eficiente com alunos fracos seja:
O processo de memorização é mais eficaz através dos erros cometidos ao invés de os acertos, especialmente com alunos com bons conhecimentos.
A aprendizagem por perturbação reforça a atenção e aumenta a percepção de pontos importantes, produzindo significados para memorização e argumentação.
Alunos com bom conhecimento são mais motivados por a competição enquanto os com pouco conhecimento preferem ajuda ao invés de novos problemas.
Em conseqüência de os experimentos realizados em, Frasson e seu grupo desenvolveram um protótipo utilizando agentes, onde se observou que a aprendizagem aparece como um processo distribuído entre vários componentes ativos.
Considerando que o conhecimento pedagógico é complexo, muitas vezes impreciso e difícil de avaliar, Frasson utilizou o conceito de Atores para criar um ambiente onde os comportamentos individuais e sociais de diferentes alunos (o real e o artificial) e suas interações com o tutor pudessem ser controlados.
O conceito de atores baseia- se na idéia de agentes inteligentes com capacidades específicas.
Como os outros agentes, atores são entidades autônomas e podem operar sem o controle humano, interagindo com os outros atores através de uma linguagem de comunicação.
Frasson define atores como um agente inteligente que é reativo, orientado, adaptativo e cognitivo.
Desta forma a estratégia de aprendizagem por perturbação é representada da seguinte maneira:
Frasson conclui que a utilização de uma abordagem multiagente permitiu que o sistema abordasse múltiplas estratégias separadamente.
O próximo capítulo apresenta a arquitetura de e o trabalho desenvolvido por Callegari e Oliveira que serviram de base para o desenvolvimento desta dissertação de mestrado.
O problema apresentado na seção 2.2, assim como a questão de pesquisa (seção 2.3) e objetivos (seção 2.4) têm como foco o trabalho desenvolvido por Giraffa e Viccari, cuja proposta era apresentar a modelagem de um STI através do uso da tecnologia de agentes utilizando uma arquitetura de Sistemas Multiagentes (SMA), onde o Kernel Cognitivo do Agente Tutor utiliza uma arquitetura de Estados Mentais.
A arquitetura utilizada para o desenvolvimento do sistema MCOE é composta por um sistema multiagente híbrido que permite a exploração dinâmica e interativa do ambiente.
Ela é composta por agentes reativos, que compõem uma sociedade chamada SMAR (Sistemas Multiagentes Reativos), e agentes cognitivos, ou SMAC (Sistemas Multiagentes Cognitivos).
Os agentes da SMAR desenvolvem um comportamento reativo semelhante ao de um ser do ecossistema do lago.
A cadeia alimentar desenvolve um comportamento autônomo semelhante ao de uma cadeia alimentar real, onde os peixes e demais seres podem se reproduzir, procurar alimento, etc..
Para isso, os agentes seguem uma estrutura semelhante à proposta por (Figura 4-2).
Cada agente é composto por agentes menores que desempenham tarefas bem específicas, como por exemplo:
Mover o agente por o cenário ou fazes- lo absorver um alimento.
Sendo assim, a arquitetura destes agentes foi dividida em dois níveis:
Agentes do tipo base:
É o agente do topo da hierarquia, utilizado para reunir as propriedades e comportamentos básicos de cada agente;
Apenas agrega agentes do tipo componente;
Agentes do tipo componente:
São agentes que definem os comportamentos específicos do agente, como:
Nadar ou reproduzir;
Não agrega agentes de nenhum outro tipo (componente ou base), ou seja, são atômicos.
A interação entre cada agente se da através de eventos e ações.
Os estímulos podem ser externos:
Frio ou toque, ou internos:
Desejo se reproduzir.
As ações desencadeadas dependem do estímulo e do estado atual do ser vivo.
Para o exemplo:
Se um ser vivo vê um alimento (estímulo de visão), mas não está com fome, o alimento não será consumido.
Se o alimento for visto e o ser vivo estiver com fome então o alimento será consumido.
Já os agentes cognitivos SMAC (que representam o comportamento dos alunos e do tutor) são modelados utilizando arquitetura BDI (belief, desire, intention).
Segundo as idéias básicas desta abordagem baseiam- se na descrição do processamento interno de um agente utilizando um conjunto básico de estados mentais (crença, desejo e intenções) e na definição de uma arquitetura de controle através de a qual o agente seleciona racionalmente o curso de suas ações.
Uma crença de um agente corresponde às informações que o agente tem sobre o mundo (ambiente), um desejo de agente (ou objetivo num sistema) intuitivamente corresponde a tarefas estabelecidas por o próprio agente e, intenção é um desejo com o valor agregado do comprometimento em alcançar- lo (e tornar- lo uma crença).
Com abordagem BDI o modelo do aluno foge ao padrão usual de estereótipos, overlay e buggy para um modelo composto por estados mentais, crenças e desejos, que são enviados para um kernel cognitivo (parte deliberativa do agente tutor).
O aluno é considerado/ analisado sempre a partir de o seu conjunto de informações.
Isto é, não há comparação entre a atuação do aluno com algum padrão ou ideal.
A proposta de visa exatamente acompanhar o trabalho do aluno, comparando dados/ informações referentes a construção coletiva de conhecimento, bastando que isto seja expresso no conjunto de estados mentais dos agentes cognitivos.
Esta questão, no entanto, não foi tratada em nenhum trabalho até o momento.
Kernel cognitivo do tutor do MCOE Em o trabalho de, foi desenvolvida a ferramenta X-BDI que permite a implementação do kernel do tutor.
Esta ferramenta faz parte de uma arquitetura distribuída em camadas (Figura 4-3), composta por:
SCIStus Prolog:
Este ambiente disponibiliza ferramentas para construção, depuração e manutenção de programas desenvolvidos com a linguagem Prolog;
X-BDI: Programa em Prolog que implementa a ferramenta X-BDI e é executado por o SICStus Prolog;
BDI. A:
Arquivo que descreve as crenças, desejos e ações iniciais do agente modelado em BDI;
Coreo. A e Rede:
Esta camada expressa o mecanismo de sensoriamento e atuação do kernel cognitivo de um agente.
Esta interação pode ser realizada de duas maneiras.
A primeira é através de um arquivo de coreografia, chamado Coreo.
A, onde são descritas crenças do agente e/ ou de outros agentes presentes no ambiente.
A outra maneira é receber estas crenças de outros programas, por meio de a troca de mensagens numa rede de computadores utilizando Sockets.
Esta capacidade foi herdada do ambiente SICStus Prolog, já que ele disponibiliza este mecanismo de comunicação com o ambiente.
No entanto, a capacidade de interação do X-BDI através da rede permite separar, em termos de implementação, o ambiente de jogo (seus agentes, aluno e sistema) do kernel do agente tutor.
Conseqüentemente, a manutenção e ampliação do ambiente ou do tutor podem ser realizadas de forma independente.
Mas mais do que isto, o tutor tem a possibilidade de interagir com jogos (interfaces de ambientes) em diferentes plataformas ou computadores.
RL-MCOE -- Arquitetura ampliada por Callegari e Oliveira A proposta apresentada por Callegari e Oliveira trouxe novas perspectivas para o MCOE, baseadas no fato de que um ambiente mais dinâmico (que ofereça uma maior variedade de situações para os alunos) possa ser utilizado de forma mais ampla do ponto de vista pedagógico.
Para isto, foram propostas alterações na arquitetura dos agentes do sistema reativo do MCOE para acomodar um método de Aprendizagem por Reforço (AR ou Negotiated W--Learning), que apresentou resultados bastante motivadores.
Esta técnica foi aplicada aos agentes da SMAR, mais especificamente os peixes, que passaram a desenvolver comportamentos mais variados e complexos.
A capacidade de decidir quando caçar uma presa, fugir de um predador ou simplesmente nadar não é mais constituída por regras rígidas, mas por a experiência adquirida ao longo de sua existência.
Em este caso, para que o conhecimento adquirido seja repassado para cada novo elemento, cada espécie de peixe mantém (utiliza e atualiza) de forma coletiva o conhecimento adquirido.
A arquitetura de cada agente é baseada na utilizada por o MCOE, e a dos agentes que utilizam AR são uma derivação desta arquitetura, conforme a Figura 4-4.
Cabe salientar que os demais agentes, como por exemplo água, plantas e microorganismos, não utilizam AR uma vez que não desempenham ações de caça e fuga.
Cada agente possui propriedades em comum, como por exemplo:
Data (ciclo) de nascimento, data de reprodução, data de morte, energia, etc;
Os agentes também possuem comportamentos, como por exemplo:
Receber mensagens do ambiente, selecionar a próxima ação, etc..
Já os subagentes têm a tarefa de observar o estado atual do agente (por exemplo, proximidade de predadores ou presas) e selecionar uma ação para ser decidida por o agente.
Quando o ambiente pede para que cada um dos seus elementos atualize sua posição, cada um dos agentes decide, através do que seus subagentes decidiram, qual a melhor ação a ser tomada e então atualizar sua posição.
A fim de validar seu trabalho, Callegari e Oliveira desenvolveram um protótipo (sem interface gráfica) com a finalidade de demonstrar a aprendizagem entre dois peixes e um ambiente com as dimensões reduzidas (em comparação com as utilizadas no protótipo do MCOE de).
Este protótipo não objetivava representar em sua totalidade a arquitetura desenvolvida por, mas somente a sociedade multiagente AR.
A linguagem de programação utilizada foi C+ por trazer benefícios na etapa de modelagem de agentes com o uso de orientação a objetos.
O agente Mediador Como descrito anteriormente na seção 2.2, a tarefa de monitoração do ambiente num jogo educacional, ações do aluno e adequação do comportamento do tutor a estas mudanças não é uma tarefa trivial.
A importância da arquitetura do sistema no desempenho do mesmo é crucial na obtenção de bons resultados.
Para isso, propomos uma arquitetura estendida (Figura 4-5) com a inclusão de um agente mediador aplicado no protótipo denominado E-MCOE (Extended MCOE).
Para modelar as tarefas realizadas por o Agente Mediador nesta nova arquitetura é proposto um diagrama que descreve o fluxo de informações entre os principais agentes (ou sociedades de agentes) da arquitetura, e a forma com que o novo agente busca informações para auxiliar o tutor.
Este diagrama (Figura 4-6) é composto por os seguintes módulos:
Módulo Interface, Módulo Jogo, Módulo Tutor e Módulo Mediador.
Cada módulo representa um agente (Tutor, Aluno e Mediador) ou uma sociedade (elementos do lago, que representam o ecossistema).
Esta divisão permite identificar as responsabilidades de cada agente e busca clarificar seus papéis/ funções na sociedade (Sistema Tutor).
Auxiliando, também, na coordenação/ análise do fluxo de mensagens entre os agentes.
O diagrama (Figura 4-6) é composto por os seguintes elementos:
Interface Representa um módulo do diagrama e este por sua vez representa um agente ou uma sociedade;
Representa a troca de mensagens entre dois módulos, o sentido, e a forma de recepção de mensagens por o módulo receptor.
Estas podem ser:
Direta: Indireta:
Observação: Em este diagrama temos a inclusão de um novo agente (Mediador).
Para modelar em detalhe as mensagens trocadas entres os módulos apresentamos um protocolo de troca de mensagens para e viabilizar a sua análise.
Cada módulo se comunica com outro através de mensagens.
Estas mensagens obedecem a um padrão determinado que define um protocolo de comunicação simples e funcional.
Desta forma, caso ocorram alterações ou ampliações das funcionalidades de um ou mais módulos estas não terão maior impacto na forma com que são modeladas as demais tarefas.
Cada mensagem é composta por:
Mensagem (remetente, destinatário, cabeçalho, conteúdo) onde:
Este protocolo permite que na modelagem do Agente Mediador possam ser analisadas as mensagens enviadas entre os módulos, e auxiliar o Tutor na tarefa de monitoração do aluno e do jogo (vide 4.3.5).
A Interface do sistema está inserida no Módulo Interface, onde estão concentrados mecanismos de interação com o usuário.
Diferente da abordagem realizada em e em seu protótipo, optamos por separar o Jogo da Interface e assim tratar as questões de monitoração de informações de forma mais detalhada.
O Módulo Interface viabiliza a expressão gráfica dos acontecimentos do jogo e permite a interferência do usuário por meio de objetos que simbolizam as ferramentas (botões, janelas, etc.).
Ele utiliza basicamente mensagens para realizar alterações no seu estado.
Estas mensagens são enviadas por o Módulo Jogo e por o Módulo Tutor.
Por outro lado, quando o usuário interage com algum objeto da interface, este objeto está relacionado com uma mensagem (crença) que então será enviada para o Módulo Jogo e/ ou Tutor.
Por exemplo, quando o aluno seleciona o personagem &quot;Prefeito «e utiliza a ferramenta &quot;Multar «disponível na interface, a seguinte mensagem é enviada ao Módulo Tutor:
Em esta mensagem está descrito qual ferramenta foi utilizada (cabeçalho da mensagem) e a quantidade restante de vezes que o aluno poderá utilizas- la (conteúdo da mensagem).
Também são enviadas mensagens sobre a utilização de pausas e busca de informações, como por exemplo:
A primeira mensagem expressa no cabeçalho que uma pausa foi solicitada e o conteúdo da mensagem informa qual aluno realizou esta solicitação.
Já a segunda mensagem mostra que o aluno solicitou (através do clique sobre o ecômetro) a exibição textual da porcentagem de energia restante no ecossistema (cujo valor é enviado através do conteúdo da mensagem).
Esta informação é utilizada por o Tutor para sua tomada de decisão.
O conjunto de mensagens que podem ser enviadas por o Módulo Interface são as seguintes:
Conforme Callegari, para se avaliar a contribuição das mudanças propostas com o uso da Técnica de Aprendizagem por Reforço sobre agentes reativos, foram realizados experimentos especificamente sobre a classe de agentes reativos do ambiente MCOE.
Por serem elementos reativos e apresentarem mais possibilidades em termos de movimentação, quantidade de estados perceptíveis e ações, os peixes do MCOE foram escolhidos com estudo de caso.
No entanto, Callegari não pretendia apresentar uma nova versão do MCOE que incluísse as novas técnicas, mas apontar diretivas para uma futura atualização do sistema.
Esta atualização está sendo realizada em nosso trabalho, onde foi adicionada a ampliação proposta por Callegari.
As contribuições que o trabalho de Callegari trouxeram são as seguintes:
Não é necessário descrever o comportamento dos peixes frente a as situações em que eles se encontrem, pois este emerge da experiência adquirida;
Estes comportamentos são dinâmicos e podem representar diversas situações (em termos pedagógicos) na simulação de um meio ambiente;
A utilização de Aprendizagem por Reforço pode ser estendida, caso necessário, para outros agentes do Jogo.
Estas contribuições trouxeram uma maior autonomia para o jogo, tornando- o mais dinâmico.
No entanto, a análise do comportamento do sistema (SMAR) não é mais uma tarefa trivial, uma vez que o ambiente não é regido por regras discretas, que geram um leque de comportamentos com proporções definidas.
A cada ciclo do ambiente, os peixes decidem quais ações (caçar, fugir, nadar, procriar, morrer) devem ser tomadas, e estas decisões levam em consideração o estado atual do ambiente.
Isto significa que cada peixe utiliza fatores como:
Sua energia atual, sua posição atual, posição atual dos predadores (dentro de um raio definido), posição atual das presas (dentro de um raio definido), época para reprodução e expectativa de vida, para selecionar as possíveis ações, e, em função de o conhecimento adquirido por decisões anteriores, qual de elas deve ser selecionada.
Um jogo educacional inserido no contexto de um STI tem como principal função colocar o aluno frente a situações onde ele possa interagir e tirar conclusões, obtendo auxílio do tutor em concepções errôneas, e assim aprender o conteúdo de uma forma mais agradável.
No entanto, frente a as contribuições de Callegari, é inviável descrever o comportamento do Tutor em função de todos os estados possíveis do ambiente (posições e quantidades de elementos), e quais as ações que ele deve tomar para cada um destes estados.
Esta situação se compara ao problema do Jogo Wumpus World onde o personagem &quot;Arqueiro «deve encontrar numa caverna a &quot;pepita de ouro», e então sair de lá o mais rápido possível.
A dificuldade encontrada por o personagem (numa forma simplificada) é a escuridão da caverna, ou seja, ele somente sensora o estado da sua posição atual, e através dos sentidos, a presença do monstro &quot;Wumpus «e dos buracos.
Criar um agente &quot;Arqueiro «que desempenhe esta tarefa sem morrer (preferencialmente), pode ser complexa se ele considerar a cada momento todo o conhecimento a respeito de o ambiente, seus elementos, e o próximo estado de cada um de eles.
No caso de o ambiente de jogo do Sistema MCOE, a riqueza de situações que podem ser apresentadas ao aluno permite a ampliação do conhecimento do tutor sobre estas situações e a exploração mais detalhada do conteúdo pedagógico.
Nossa proposta busca disponibilizar um mecanismo (através do Agente Mediador, vide seção 4.3.5) que permita observar de forma mais detalhada e contínua o comportamento do jogo, e assim enviar informações ricas e não volumosas para o tutor.
Em este trabalho, a análise realizada abrange os estados mentais descritos por Giraffa em, o que significa que estamos considerando os fatores analisados por o tutor descritos em.
A possibilidade (proposta) de geração de novas mensagens por os módulos e alteração e ampliação do kernel do tutor estão descritas na seção 6.2.
Sendo assim, o conjunto de mensagens que podem ser enviadas por o Módulo Jogo são as seguintes:
Y representa quantidade de energia atual do elemento.
Z representa um quantidade de unidades de.
Tempo medidas em ciclos de execução do Ambiente do W representa quantidade de elementos desta classe de elemento.
É o responsável por a seleção de estratégias e táticas a serem adotadas para auxiliar o aluno.
A parte deliberativa, denominada de kernel cognitivo, como citado anteriormente, pode tratar as mensagens enviadas do sistema para o kernel cognitivo, assim como receber mensagens do mesmo e retransmitir- las para os módulos correspondentes (Figura 4-7).
O kernel BDI do Agente Tutor é executado num sistema à parte.
Sendo assim, a aplicação com a qual ele se comunica necessita de uma interface que realize a comunicação através do meio, que T representa uma estrutura (vetor) contento a posição atual de todos os elementos desta classe de elemento.
Por exemplo, o Módulo Tutor recebe a seguinte mensagem do Módulo Interface:
Mensagem (Interface, Tutor, ferramenta_ lixeira, 2) Em esta mensagem está descrito que o botão &quot;Colocar Lixeiras «foi pressionado e a quantidade de vezes que o aluno pode utilizas- lo é &quot;2».
Sendo assim, o Módulo Tutor envia a seguinte mensagem para o kernel do Tutor:
Outro exemplo é o recebimento de uma mensagem do Módulo Jogo:
Mensagem Esta mensagem descreve a média de energia dos peixes do tipo &quot;A «e então a seguinte mensagem é enviada:
Já o sistema pode receber mensagem do kernel e distribuir- las nos sistema, como por exemplo:
O Módulo então envia para interface a seguinte mensagem:
Mensagem (Tutor, Interface, aviso, &quot;Verifique a energia de cada elemento do jogo&quot;) Veja que o cabeçalho da mensagem expressa qual a tática (ou conjunto de táticas) deve ser empregada quando esta mensagem for recebida por o Módulo Interface.
Sendo assim, o conjunto de mensagens que podem ser enviadas por o Módulo Tutor é o seguinte:
X representa a mensagem em forma de texto enviada ao destinátario.
Mensagem (Tutor, Interface, alerta, X) Este módulo apresenta o Agente Mediador proposto na arquitetura estendida.
O agente tem como principal tarefa auxiliar o tutor, realizando a leitura, análise e envio de mensagens no sistema.
O Agente Mediador possui as seguintes propriedades:
Autonomia: O agente escolhe uma ação baseado na própria experiência adquirida com a análise das mensagens do sistema;
Habilidade social:
O agente possui um elo de comunicação (troca de mensagens) com o tutor e outros agentes do ambiente (cognitivos);
Reatividade: O agente reage aos estímulos recebidos dos outros agentes (tutor e/ ou aluno) e do ambiente;
Pró-atividade: O agente monitora o ambiente e continuamente passa as informações sobre o estado do ambiente e dos alunos, necessárias para o tutor;
Veracidade: Está comprometido em repassar informações corretas e sempre adequadas ao seu objetivo (auxiliar o tutor a monitorar o ambiente e as ações dos alunos).
Estas informações são definidas por o projetista na fase de especificação do agente.
Por meio de o protocolo de troca mensagens, estabelecido na modelagem do sistema, o agente pode interceptar as mensagens enviadas entre os Módulos e analisar- las.
Utilizamos as considerações de Wexelblat para definir estes comportamentos.
Sendo assim, o agente pode agir de duas formas:
Observação: O agente observa as mensagens que são enviadas de um módulo para o outro sem interferir na comunicação direta entre os mesmos;
Mediação: O agente recebe mensagens de um módulo destinadas a um terceiro e, após a sua análise, envia ou não mensagens para o destinatário;
Esta situação ocorre, por exemplo, quando o jogo envia mensagens para o Agente Tutor.
Mensagens observadas não são analisadas por o seu conteúdo, mas por a sua utilização, de forma que os módulos se comuniquem sem interferência do agente.
Esta monitoração busca identificar se determinadas mensagens estão sendo enviadas entre dois módulos em seu fluxo normal, como por exemplo, quando o Módulo Interface não envia mensagens para o Módulo Tutor por um prolongado período de tempo.
Este então gera mensagens para o Módulo Tutor a fim de informas- lo sobre a falta de interação.
Outras situações podem ser observadas por os seguintes exemplos:
Considere, por exemplo, um tempo limite de 100 ciclos (tempo máximo de partida), e a energia do ecossistema (energia_ ecomentro) variando de 0 a 100 e as mensagens sendo envidas na seqüência de 1 a 6.
O Tutor utiliza a quantidade com que cada ferramenta ainda pode ser utilizada para determinar, quando a energia do ecômetro está abaixo de 70%, se o aluno esta inativo.
Por exemplo, observe que entre a mensagem 3 e 5 nenhuma mensagem sobre a utilização da interface foi enviada (por exemplo, mensagem (Interface, Tutor, ferramenta_ multa, 2).
Sendo assim, o Agente Mediador deve observar este &quot;silêncio «por parte de o aluno e enviar o estado atual das ferramentas para que o Tutor perceba a inatividade do aluno.
O outro comportamento do agente é a mediação da comunicação.
Esta ocorre onde grandes volumes de informações são transmitidos de um Módulo para outro e não são diretamente significativas para o módulo destino.
Esta situação ocorre, por exemplo, entre o jogo e tutor na transmissão da quantidade de energia dos elementos do jogo.
A análise das mensagens se dá através de faixas de valores.
Por exemplo, imagine as seguintes situações (considerando novamente as mensagens apresentadas acima):
Situação 1: A mensagem 1 informa pela primeira vez o tempo de partida.
Este então é assimilado por o Tutor através do reenvio da mensagem.
Isto ocorre também com a mensagem 2 que vem logo a seguir;
Situação 2: Já a mensagem 3 não interessa ao tutor pois ainda não está enquadrada no que Giraffa chamou em de «Tempo de Folga 1.
Como este fator se mantém atualizado dentro de a faixa que interessa ao Tutor, esta mensagem não precisa ser enviada.
O mesmo ocorre com a mensagem 4, mas considerando as faixas ligadas à energia do ecômetro.
Situação 3: Já nas mensagens 5 e 6 é necessário o envio destas mensagens pois são necessárias para tomada de decisão do Tutor (considerando que não foram enviadas outras mensagens entre as mensagens 4 e 5), pois se enquadram em determinadas faixas de valores (0 a 70% de energia, e 80 a 100% do tempo de partida) que interessam ao Tutor.
Observa- se então a necessidade de controlar os intervalos ou faixas e os valores dos parâmetros enviados ao tutor a fim de filtrar mensagens desnecessárias.
Em este trabalho estamos abordando com maior ênfase o comportamento de mediação do Agente.
No entanto, a capacidade de observação poderá ser mais explorada em trabalhos futuros, como por exemplo na observação e criação de novas crenças sobre o uso da interface por o aluno.
Para que o Agente Mediador possa demonstrar este comportamento e executar suas tarefas é necessário definir regras que expressem a sua conduta.
Para isso elaboramos uma linguagem (semelhante ao português estruturado) que permite delinear as ações e a forma com que as mensagens trocadas entre os módulos podem ser analisadas.
Para descrever a linguagem em forma de BNF (Forma de Backus-Naur), com a finalidade de especificar o comportamento do agente.
Cada regra é descrita por a seguinte sintaxe (produções):
O parâmetro (corresponde ao campo da mensagem que se deseja utilizar para análise:
Remetente, destinatário, cabeçalho e conteúdo.
Utilizando esta gramática é descrito o comportamento do agente em função de as mensagens que ele recebe.
Para análise das mensagens existem dois blocos de descrição do comportamento do agente:
Declaração e inicialização das variáveis do agente, e ciclo de análise de mensagens recebidas.
Em a declaração e inicialização as primeiras mensagens enviadas por os módulos permitem inicializar as variáveis do agente.
O ciclo de análise de mensagens recebidas compreende um bloco de regras que são verificadas a cada mensagem recebida por o Módulo Mediador.
Após a descrição das regras do de comportamento do agente, a forma com que elas serão revisadas é realizada da seguinte maneira:
Todas as regras são revisadas a cada mensagem recebida por o agente.
No entanto, dependendo da tecnologia ou ferramenta utilizada para sua implementação, adaptações poderão ser necessárias.
Por exemplo, se utilizarmos a ferramenta X-BDI para implementação do agente, será necessário analisar a forma com que a ferramenta implementa regras e se a forma de revisão da mesmas se adapta a forma de revisão desta proposta.
Com estas informações é apresentado a seguir as soluções encontradas para a análise e o auxílio do Agente Mediador ao Tutor.·
Recepção de mensagens por o Agente Mediador no Código 4-1 descrevemos a recepção de uma mensagem informando a energia dos peixes da espécie &quot;a».
O Agente então armazena esta informação para posterior análise.
Código 4-1: Recepção de mensagens por o Agente Mediador se então· Envio de mensagem para o Agente Tutor O em o (Código 4-2) é exemplificado o envio de mensagens para o tutor baseado na observação do estado atual de um elemento.
Caso a energia do peixe &quot;a «esteja abaixo de o mínimo estabelecido o agente envia uma mensagem que este limite é atingido.
Código 4-2: Envio de mensagem para o Agente Tutor se energia_ peixe_ a_ atual energia_ peixe_ a_ mínima então mensagem (mediador, energia_ peixe_ a_ atual);·
Observação do Agente A observação por parte de o agente se da através da incrementação da variável &quot;tempo_ de_ espera «a cada ciclo do jogo.
Como todas as regras são revisadas a cada nova mensagem, quando o tempo de espera ultrapassa o tempo limite para espera, são enviadas então mensagem para o tutor para que ele possa identificar a falta de interação por parte de o aluno (Código 4-3).
Estas mensagens são o conjunto de informações sobre a interface que o Tutor utiliza para identificar o &quot;silêncio «do aluno.
Código 4-3: Observação do Agente se &quot;tutor «e mensagem.
A cada mensagem recebida, com o cabeçalho &quot;tempo_ de_ partida_ atual «é incrementada a variável &quot;tempo_ de_ espera», que conta o tempo que o aluno não utiliza a interface.
Se alguma mensagem for enviada por a interface para o tutor, esta variável é reinicializada.
Caso o limite de espera seja ultrapassado o agente envia o estado atual das ferramentas para que o tutor possa identificar a falta de interação por parte de o aluno.·
Filtragem de mensagens O agente realiza uma &quot;filtragem «das mensagens enviadas ao Módulo Tutor quando media esta comunicação.
No caso de as mensagens envidas por o Módulo Jogo para o Tutor, o Mediador filtra mensagens a respeito de a energia dos elementos, o tempo de partida e a quantidade de elementos no ambiente.
Abaixo o descreve que se a energia de uma determinada espécie de peixe variar mais que 5%, é enviada então uma mensagem ao tutor com a quantidade de energia atual.
Calcula- se que com esta medida as mensagens sobre energia dos peixes podem ser reduzidas em 80%, retirando assim um volume considerável de informações desnecessárias para o Tutor.
A variação de 5% foi definida a partir de a análise do kernel do Tutor, o qual faz considerações sobre energia em intervalos de 5%.
Código 4-4: Filtragem das mensagens de energia dos peixes então se (var_ energia_ peixe_ A ­ mensagem_ Conteúdo (var_ energia_ peixe_ A ­ mensagem_ Conteúdo 5) ou então mensagem (mediador, mensagem_ Conteúdo);
Com estes mecanismos básicos descrevemos o comportamento do Agente Mediador O conjunto de mensagens que podem ser enviadas por o Módulo Mediador são as seguintes:
X representa quantidade de energia atual do elemento.
X representa quantidade de elementos desta classe de elemento.
X representa quantidade restante para utilização por parte de o aluno.
Cabe salientar que estas mensagens são as mesmas envidas ao tutor por os Módulos Interface e Jogo, mas com uma diferença.
O campo &quot;conteúdo «é variado pois ele é fruto das observações e análises do Agente Mediador.
A medida que novas mensagens sejam incorporadas ao sistema (oriundas de novas funções na interface ou comportamentos no jogo) estas irão gerar novas mensagens.
A elaboração do protótipo foi divida em duas etapas:
A primeira se constituiu no desenvolvimento de um novo protótipo do ambiente MCOE, em escala reduzida, e com recursos gráficos simples, que incluíssem as alterações propostas por Callegari;
A segunda etapa foi a inserção do novo agente na arquitetura do protótipo para avaliação das alterações na modelagem/ manutenção/ execução do sistema.
A fim de permitir a análise e ampliação de nossos resultados, analisamos a utilização de uma linguagem para desenvolvermos o protótipo que permitisse também sua aplicação em diferentes plataformas.
Após o estudo de diferentes linguagens de programação para Web (PERL, ASP, e outras, freqüentes em aplicações para Web), concluímos que a utilização da linguagem Java atendia as necessidades de portabilidade, expansão e documentação que desejávamos.
No entanto foi necessária a conversão do protótipo de C+ para Java.
Outra vantagem obtida por a utilização desta linguagem foi a qualidade gráfica e uma rápida prototipação, uma vez que esta linguagem permite a incorporação de elementos considerados padrão em interfaces de páginas na Web.
Como por exemplo, uso de gifs animadas.
Em o protótipo E-MCOE algumas tarefas que ainda não haviam sido contempladas no protótipo inicial foram implementadas:
Realização da comunicação entre o kernel do tutor e os agentes da interface de jogo:
O protótipo tem a capacidade de receber e enviar mensagens para o kernel do tutor através da rede.
Esta comunicação contém informações sobre as interações do aluno, o comportamento da interface e a identificação do aluno.
Utilização dos agentes propostos por:
O ambiente do protótipo faz uso dos agentes (conjunto de classes) da cadeia alimentar utilizados no trabalho do protótipo RL-MCOE;
A Figura 5-1 apresenta a interface do E-MCOE, onde:
É mais enviada ao tutor;
Lixeiras&quot;; Genérica&quot;;
O E-MCOE é composto por um conjunto de classes e pacotes que resumem o funcionamento básico do sistema.
São elas:
CInterface, CEnvironment, CTutor e CMediador.
A classe CInterface está relacionada com a apresentação e implementação dos mecanismos de interação com o usuário.
A Interface gera a representação gráfica do lago, seus elementos (peixes, plantas, etc) e as ferramentas do usuário (neste caso os botões estão relacionados apenas ao personagem Prefeito).
Também foi inserido um mecanismo para execução das táticas do tutor (basicamente mensagens).
Lembrar que o conteúdo das mensagens vai de acordo com a estratégia adotada.
Se o tutor for mais diretivo será utilizada uma mensagem de conteúdo mais direto.
Esta modelagem utiliza o mesmo conjunto de mensagens utilizadas no MCOE.
Em este protótipo somente disponibilizamos esta opção de tática (mensagens).
Contudo, elas podem ser ampliadas futuramente com a inclusão de outros mecanismos que permitam expressar novas táticas, e assim ampliar a capacidade do tutor de utilizar múltiplas estratégias associadas à múltiplas táticas.
Optamos por criar, neste protótipo uma interface que representa apenas um aluno, pois seriam necessários esforços no controle do diálogo das Interfaces em diferentes computadores e isto não foi previsto no cronograma do PEP.
Além disso, os processos de negociação, de sincronismo e outros, entre as interfaces (CInterface) e seus ambientes (CEnviroment) foram analisados em função de o cronograma.
Um objeto da classe CEnviroment (Ambiente) mantém os mecanismos que dão manutenção para o jogo e seus elementos.
O Ambiente é responsável por o envio de informações sobre o estado atual do ambiente (informações sobre as propriedades dos peixes, plantas, etc) para o tutor.
Objetos desta classe têm inserido em sua implementação os agentes CRLSwitchAgent, referentes ao trabalho de.
Estes agentes foram implementados na forma de um pacote de objetos com a finalidade de tornar- los o mais independentes do sistema.
Como o kernel do Agente Tutor é implementado através da ferramenta X-BDI, a classe CTutor (objeto Tutor) implementa um conjunto de mecanismos para comunicação via sockets com o X-BDI, e um conjunto de rotinas que traduzem as mensagens recebidas e, conseqüentemente, as envia através do sistema para os seus destinatários.
A classe CMediator implementa o Agente Mediador (Mediador).
Para sua implementação (na busca de comprovar inicialmente a independência de tecnologia de sua descrição, vide seção 4) optamos por a ferramenta X-BDI.
E, conseqüentemente para sua modelagem utilizamos o formalismo da ferramenta.
Esta escolha foi realizada em função de a rápida modelagem e do trabalho que vem sendo desenvolvido por o grupo na análise do kernel cognitivo do Tutor e da ferramenta X-BDI.
Sendo assim, o agente utiliza as mesmas idéias descritas anteriormente por a classe CTutor.
Porém, existe uma diferença importante:
Todas as mensagens do sistema, considerando o nível de abstração descrito na seção 4.3 Figura 4-6, são capturadas por o Mediador.
Algumas, como no caso de as mensagens enviadas do Ambiente (Jogo) para o Tutor, são enviadas ou não indiretamente, para o tutor, através do Mediador.
Desta forma analisamos e geramos mensagens conforme a nossa proposta descrita na seção 4.3.
A modelagem e manutenção do agente obteve indiretamente (através da especificação do agente por meio de estados mentais) vantagens, como a facilidade de especificação (alto nível de abstração).
Contudo, à medida que as descrições venham a crescer, visualizar e depurar o modelo tenderá a ser uma tarefa razoavelmente complexa.
Esforços realizados por o nosso grupo de pesquisa, trouxeram alternativas para solução destes problemas.
Em o trabalho de Zamberlam (e) é proposta uma técnica de programação orientada a agentes BDI, associada a um editor.
Este editor, permite ao programador organizar as relações entre os estados mentais do agente por meio de uma notação definida em forma de diagramas, facilitando assim, a sua programação.
Contudo a execução do agente não pode ser avaliada uma vez que o mecanismo de comunicação da ferramenta X-BDI através de sockets está em fase de desenvolvimento.
Desta forma, desenvolvemos um protótipo que possui dupla utilidade, o CX-BDI (Client XBDI) (Figura 5-2).
Através de de ele pudemos descrever as mensagens que podem ser enviadas do kernel do tutor para o sistema, como também as deliberações do Agente Mediador.
Em a Figura 5-2 temos:
Armazenada para envio;
O protótipo poder ser utilizado como um cliente remoto para o X-BDI.
Enviando e recebendo mensagens da ferramenta.
As mensagens enviadas podem gravas e reutilizadas, com a finalidade (no nosso caso) de simular as interações entre os alunos e o tutor.
Desta forma, este protótipo viabilizou a avaliação do fluxo de mensagens, tanto do X-BDI para aplicações clientes (enviando as possíveis respostas da ferramenta) bem como, da própria aplicação cliente para o X-BDI (enviando mensagens).
Conclui- se que a separação de determinadas tarefas do tutor e a delegação das mesmas para um agente especializado contribuiu para modelagem e o entendimento do sistema como um todo.
A manutenção do kernel do Tutor pode agora ser realizada de forma mais independente, sem a preocupação com detalhes sobre o controle do ambiente e da interface.
Futuras manutenções do kernel do Tutor poderão contemplar comportamentos mais complexos e com uma menor dependência das características específicas do sistema.
A o completarmos o trabalho de mestrado pudemos validar a hipótese a cerca de a necessidade e possibilidade de terceirizar atividades originalmente modeladas e implementadas no agente tutor.
Esta é uma importante contribuição que os agentes trouxeram para modelagem de STI como uma sociedade de agentes.
Observamos que a ampliação proposta por Callegari em não trouxe novas informações para simulação e conseqüentemente para o tutor, uma vez que qualquer situação pode ser descrita por meio de regras, como era esperado.
No entanto, a contribuição de Callegari trouxe uma forma mais dinâmica para viabilizar uma simulação mais realista junto ao aluno.
Isto dificulta muito a modelagem do Tutor uma vez que o seu comportamento frente as situações encontradas por os peixes não pode ser descrita de uma forma simplificada, pois a variedade de situações pode ser muito grande para ser tratada por o Tutor.
Sendo assim, este conjunto de comportamentos pode ser analisado e adicionado ao sistema de forma gradual, sendo então, assimilados por o kernel do Tutor e/ ou do Agente Mediador.
Através do protocolo de mensagens é possível expressar na modelagem do fluxo de informações do sistema (do Tutor para interface), quais as táticas que se deseja utilizar junto a interface.
Limitações Frente a nossa proposta de estender uma arquitetura e apresentar uma meio para modelar o fluxo e informações num STI, as seguintes limitações foram identificadas:
Linguagem para especificação do comportamento do agente pode não abranger todos os casos possíveis de interação no sistema.
Em este trabalho utilizamos como base o trabalho desenvolvido por que restringe o domínio, forma de interação e particularidades de um sistema ambientalizado com um jogo ecológico.
A utilização desta forma de descrição do agente pode necessitar adaptações em ambientes que necessitem formas de análise mais elaboradas.
Questões de sincronia e paralelização de processos não foram tratados neste trabalho, visto que a utilização do sistema pode ser realizada por mais de um aluno e, em locais remotos.
Trabalhos futuros Durante o processo de pesquisa, foram identificados diferentes trabalhos que não estão diretamente relacionados com o foco atual de nosso trabalho.
No entanto, relacionamos um conjunto de idéias que podem dar início ou continuação a este trabalho.
Atualização e ampliação das crenças do Tutor considerando que determinadas tarefas de análise podem ser delegadas agora para o Agente Mediador.
Identificamos que algumas tarefas, hoje desempenhadas de forma mais complexa por o Agente Tutor, podem ser modificadas a fim de tornar sua descrição mais simples:
Agente Mediador A criação automática de mensagens ou novas crenças para o tutor.
Expandir a capacidade do Agente Mediador de forma a gerar mensagens para o Tutor com novas crenças, adaptando o Tutor a novas interfaces, mecanismos de interação e ambientes de jogos.
Analisar a sincronia na troca de mensagens entre os módulos, com a finalidade de observar seus efeitos na tomada de decisão do Tutor.
Em este trabalho a pesquisa se focou nos aspectos arquiteturais do sistema, e como as informações podem ser mais bem utilizadas para um melhor acompanhamento pedagógico.
Contudo, aspectos técnicos como desempenho, sincronia, particularidades das tecnologias de redes e programação, e a paralelização de processos robustos no sistema não foram abordados.
A possibilidade de utilizar técnicas de Scripts e Glue code para que novos ambientes de jogos e interfaces possam ser utilizados nesta arquitetura.
Concluímos que a separação da forma de comunicação da maneira com que são realizadas as tarefas no sistema (num nível arquitetural), aumenta o potencial exploratório (no nível pedagógico), uma vez que novas interfaces e jogos que utilizem o mesmo formato de mensagens podem ser incorporados ao sistema utilizando também linguagens de scripts.
Não objetivamos a possibilidade de extensão para outros domínios, mas ampliação gradativa das possibilidades de exploração do domínio e da interface.
Implementação do Agente Mediador utilizando outras técnicas de Ia.
Esta proposta tem por finalidade comparar os resultados que podem ser obtidos com a utilização de diferentes técnicas na implementação do Agente Mediador (Redes neurais, algoritmos genéticos, etc.).
Assim poderemos estabelecer um comparativo entre Técnica/ Domínio/ Interação que mais se adaptam Utilização da tecnologia de Agentes de Interface em STI com outros ambientes (Jogos).
Observa- se atualmente que os Agentes de Interface não estão sendo explorados da forma com que inicialmente foram idealizados.
Limitações que muitas vezes não estão relacionadas com desempenho mas com a necessidade de um volume muito grande de informações levaram a pesquisa nesta área a outros objetivos.
Nosso trabalho apresenta um alternativa para utilização desta pesquisa sob um diferente foco (mas nem tanto distante) que é uso no auxílio de um Tutor virtual.
Nada impede que esta abordagem possa ser utilizada em diferentes trabalhos de pesquisa em STI, pois a necessidade da redução da complexidade em arquitetar para STI é uma necessidade constante.
Personificação do Agente Mediador. A personificação dos Agentes de Interface ainda é uma questão a ser explorada por os pesquisadores da área pois várias questões, como por exemplo entendimento, confiança, controle e distração ainda estão em aberto.
No entanto, a personificação do agente tutor pode trazer benefícios para aprendizagem, mas que não é uma tarefa a ser diretamente tratada por o Agente Tutor.
Sendo esta então tratada por o Agente Mediador.
Utilização de mais agentes na tarefa de auxiliar o tutor em suas tarefas.
Uma característica que se observou na pesquisa sobre modelagem de STI (vide seção 3.3.2) é as tentativas de dividir as tarefas do tutor em tarefas menores.
Talvez estas sejam demonstrações que muitas vezes o Tutor esta sobrecarregado de tarefas, e estas tarefas podem ou não ser de sua alçada.
Em nosso trabalho realizamos a análise das tarefas que não são necessariamente do tutor.
Contudo há a possibilidade de que algumas de elas possam ser categorizadas em entregues a agentes especializados.
Ou seja, colocar mais agentes na sociedade com tarefas mais específicas.
Porém, é uma questão investigativa a ser trabalhada.
