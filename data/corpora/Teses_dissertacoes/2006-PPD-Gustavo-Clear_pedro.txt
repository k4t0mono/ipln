A modelagem analítica pode ser utilizada para prever desempenho, detectar deficiências e avaliar estratégias para melhorar sistemas.
Em o contexto da modelagem computacional, diversos formalismos para a modelagem analítica estão se popularizando devido a o fato de proverem alto-nível de abstração e modularidade.
No entanto, para inferir estimativas de desempenho destes modelos, é necessário resolver um sistema de equações.
Em modelos analíticos estruturados, tais sistemas não se apresentam na forma tradicional, Ax $= b, pois a matriz de coeficientes (A) é trocada por uma expressão algébrica (Q), denominada Descritor Markoviano (ou só descritor).
Logo, a multiplicação convencional, Ax é substituída por a multipicação vetor-descritor (MVD), Qx.
Dois algoritmos foram propostos recentemente para implementar a MVD:
Shuffle e slice.
Ambos apresentam um alto custo computacional, que eleva drasticamente o tempo necessário para resolver modelos complexos.
O objetivo do presente trabalho está relacionado com a utilização de técnicas de alto desempenho para propor versões mais rápidas, tanto para o algoritmo shuffle quanto para o slice.
Os formalismos estruturados constituem num tipo de modelagem analítica.
Esses se caracterizam por apresentarem uma maneira estruturada e modular de projetar sistemas gerando resultados comprovadamente equivalentes a Cadeias de Markov (Cm).
Apesar desses formalismos serem resolvidos da mesma maneira, o mapeamento de modelos analíticos estruturados numa Cm equivalente não é desejado porque exigiria um grande custo de armazenamento.
Por esse motivo, tais formalismos utilizam algoritmos para realizar as operações necessárias na resolução dos modelos.
Atualmente, os dois algoritmos que realizam esta operação, shuffle e slice, apresentam um elevando custo computacional na resolução deste tipo de problema.
Formalismos para modelagem analítica estruturados caracterizam- se por possuírem um Descritor Markoviano (DM ou descritor para abreviar).
Esta estrutura é equivalente a um gerador infinitesimal, uma matriz que armazena as taxas de transição entre os diversos estados de uma Cm.
Da mesma maneira que as CMs, a resolução desses modelos é efetuada resolvendo- se um sistema de equações lineares.
Desta forma, a operação e a multiplicação de um vetor por central na resolução de modelos analíticos estruturados úma matriz.
Os algoritmos shuffle e slice manipulam a estrutura do descritor efetuando esta multiplicação, a chamada Multiplicação Vetor--descritor (MVD).
Utilizar máquinas mais potentes para aumentar o desempenho de aplicações é uma construídos com tecnologias para o consumidor final e conseqüentemente apresentam uma boa relação custo/ benefício.
Essas máquinas estão ganhando popularidade no meio acadêmico onde são utilizadas para pesquisa de ponta nas mais diversas áreas.
Motivação O objetivo de realizar a MVD é efetuar a resolução de um sistema de equações lineares, independente do método de resolução empregado (Método de Newton, Método da Potência, etc).
Atualmente, os métodos numéricos mais utilizados para resolver sistemas lineares são conhecidos como métodos iterativos.
O que caracteriza um método iterativo (para resolução de sistemas de equações lineares) é que, a cada iteração, ele se aproxima da resolução do sistema até que atinja um erro mínimo ou um número máximo de iterações.
Todavia, cada uma dessas iterações efetua a multiplicação de um vetor de resultados aproximado por uma matriz de coeficientes.
Logo, a operação da MVD é executada diversas vezes (tipicamente centenas ou milhares de vezes) até que o problema seja resolvido.
Existem diversas situações em as quais é desejado analisar o desempenho de sistemas computacionais, tais como:
Avaliar o desempenho de um novo processador;
Prever o desempenho de configurações de ambientes e algoritmos;
Avaliar qualidade de serviço de aplicações distribuídas;
Assim por diante.
Existem atualmente três técnicas empregadas para avaliar o desempenho nestas situações:
Bechmarks, modelos de simulação e modelos analíticos.
Benchmarks consistem numa série de aplicações (de custo elevado em termos de processamento) que deverão ser executadas de forma sistemática para qualificar e quantificar o desempenho de dispositivos específicos.
A modelagem por simulação visa a construção de aplicações que simulem o comportamento de um sistema.
Essa técnica pode ser utilizada para avaliar a qualidade de sistemas como redes de computadores, por exemplo.
Em nosso trabalho, focamos nos métodos analíticos.
A modelagem analítica visa a construção de um modelo que represente a realidade sendo estudada.
Mais precisamente, tais modelos caracterizam- se por agregar diversas informações de transição (representando a interação entre entidades do sistema) e a freqüência com as mesmas ocorrem.
Existem diversos formalismos para modelagem analítica, de entre as quais destacam- se:
Redes de Autômatos Estocásticos, Redes Ativas Estocásticas, Redes de Filas de Espera, Redes de Petri Estocásticas (SPN), Algebra de Processos para Avaliação de Desempenho (PEPA) 1.
O escopo deste trabalho é restrito aos métodos de modelagem analítica estruturados.
Estes métodos caracterizam- se por utilizarem álgebra tensorial para representar, através de uma expressão algébrica, um gerador infinitesimal comprovadamente equivalente a Cadeias de Markov.
A vantagem de utilizar modelos analíticos estruturados envés das Cadeias de Markov está na obtenção de um maior poder de abstração.
Para ilustrar, na figura 1, é apresentado um exemplo de Cadeia de Markov que modela dois processos disputando o acesso a um As siglas dos formalismos derivam de suas respectivas siglas internacionais em inglês:
Stochastic Petri Nets (SPN), Performance Evaluation Process Algebra (PEPA) e Stochastic Automata Networks (SAN).
Já utilizando um formalismo de modelagem analítica estruturada, como por exemplo o modelo SAN visto na Figura 2, é possível separar em módulos cada entidade do sistema.
Os algoritmos para os quais apresentamos alternativas de alto desempenho podem ser utilizados para a MVD independente do formalismo utilizado.
Entretanto, cada formalismo possui técnicas específicas para o armazenamento das estruturas algébricas, e conseqüentemente desempenhos diferentes.
Este cenário dificulta a elaboração de uma biblioteca de primitivas para realizar a MVD.
Objetivos O objetivo deste trabalho é empregar técnicas de alto desempenho nos algoritmos shuffle e slice visando acelerar a Multiplicação Vetor--descritor, a operação empregada na resolução de modelos analíticos estruturados.
A plataforma de alto desempenho utilizada para a execução dos testes é um aglomerado de computadores.
Essas plataformas, conhecidas em inglês como clusters, são multicomputadores que compartilham dados utilizando uma rede.
O padrão mais utilizado para a troca de mensagens neste tipo de plataforma é MPI, por tratar- se de um padrão consolidado para a troca de mensagens em multi-computadores, portável, de comprovada eficácia e com ampla documentação disponível.
Organização do Trabalho Em o capítulo 2, o problema da multiplicação vetor-descritor é apresentado seguido de uma explicação dos algoritmos shuffle e slice utilizados para realizar esta operação atualmente.
Em o capítulo 3 são apresentadas as estratégias para realizar a MVD numa plataforma de computação de alto desempenho onde detalhes de escalonamento são fornecidos.
A seguir, no capítulo 4, são mostrados como os testes foram realizados e em seguida os resultados para cada um dos algoritmos.
Finalmente, no capítulo 5 algumas conclusões e perspectivas, para trabalhos futuros, são discutidas.
O apêndice A mostra um exemplo de formalismo para modelagem analítica e como o Descritor Markoviano é gerado.
Em o apêndice B, é apresentada uma descrição gráfica dos modelos utilizados para testar o desempenho das implementações propostas ao longo deste trabalho.
Por fim, no apêndice C, são apresentados os detalhes numéricos dos resultados.
Multiplicação Vetor--descritor Os formalismos analíticos estruturados caracterizam- se por apresentarem uma forma modular de representar sistemas reais.
Esses formalismos são mais atraentes que Cadeias de Markov por permitirem projetar um sistema grande em pequenas partes independentes, especificando as interações entre cada módulo quando necessário.
De essa forma, os formalismos conservam as propriedades das CMs de forma que podem inferir as mesmas estimativas de desempenho de um determinado sistema.
O mapeamento de um modelo analítico estruturado numa Cm é realizado utilizando as operações de álgebra tensorial.
Estas operações combinam os estados independentes de cada um dos módulos do modelo de forma a gerar uma estrutura equivalente ao gerador infinitesimal.
O gerador infinitesimal é uma matriz que contém as taxas de transições entre cada um dos estados num modelo descrito utilizando Cadeias de Markov.
Todavia, como o gerador infinitesimal gerado neste processo é muito esparso, é preferível armazenar as matrizes de forma a minimizar a utilização de memória.
Para tratar este problema, o gerador infinitesimal é então substituído por um Descritor Markoviano (ou somente descritor para abreviar), uma estrutura algébrica que quando resolvida é equivalente ao gerador infinitesimal.
Para resolver modelos descritos utilizando Cm, é necessário resolver um sistema de equações lineares.
A o final deste processo, o vetor solução do sistema conterá informações referentes à permanência em cada estado do modelo.
Em outras palavras, apresentará estimativas de desempenho para o sistema real sendo modelado.
Como os formalismos estruturados apresentam uma equivalência a Cm, o método de resolução é análogo.
No entanto, o gerador infinitesimal não existe nestes últimos, pois é substituído por o descritor.
Em este ponto a operação de multiplicação do vetor solução por a matriz de coeficientes, que é o gerador infinitesimal em Cm, é substituído por a multiplicação do vetor por o Descritor Markoviano.
E portanto esta operação de multiplicação é chamada de multiplicação vetor-descritor.
A resolução de sistemas de equações lineares é realizada geralmente utilizando- se métodos iterativos.
Métodos iterativos caracterizam- se por aproximarem o vetor resultado do sistema a cada iteração.
Em este caso, o número de iterações necessárias para resolver um sistema varia muito, pois é determinado por um erro mínimo do resultado aproximado ou um número máximo de iterações.
A MVD, é portanto, uma operação que é realizada diversas vezes até que o modelo seja resolvido.
O custo computacional desta operação determina o custo total de resolução de um modelo, quantificado em termos de tempo de processamento, por isso existe um grande apelo para que o custo desta operação seja o menor possível.
Uma vez que a Multiplicação Vetor--descritor (MVD) é uma operação algébrica que substitui a multiplicação de um vetor por uma matriz, torna- se necessário compreender as operações algébricas envolvidas nesta expressão.
Em a seção 2.1, os aspectos relevantes da álgebra tensorial são apresentados, bem como algumas propriedade relevantes para a construção dos algoritmos e conseqüentemente importantes para compreender a paralelização destes.
Em seguida, na seção 2.3, os descritores de dois formalismos são apresentados com o intuito de justificar a escolha do formato de entrada escolhido.
Finalmente, na seção 2.4 os dois algoritmos que realizam a MVD, shuffle e slice, são apresentados de forma a ressaltar os aspectos que permitem distribuir o cálculo.
Tensorial Para entender como a Multiplicação Vetor--descritor (MVD) é efetuada, é necessário conhecer as operações algébricas que são utilizadas para mapear um modelo analítico numa cadeia de Markov.
Estas operações são conhecidas como operações de álgebra tensorial clássica ou também por operações de Kronecker.
Apesar de o Descritor Markoviano apenas utilizar o produto tensorial, a soma tensorial é freqüentemente utilizada e, portanto, se torna relevante para compreensão dos algoritmos que realizam a MVD.
As operações de soma e produto tesorial são definidas entre duas matrizes reais.
Como no contexto dos formalismos analíticos estruturados, estas matrizes são sempre quadradas.
Em este trabalho são apresentadas definições e exemplos para casos que contemplam somente matrizes quadradas.
O leitor interessado em encontrar mais informações sobre a álgebra tensorial pode consultar as referências.
Produto Tensorial O produto tensorial é uma operação algébrica definida entre duas matrizes reais.
Dado duas matrizes A e B, onde A é uma matriz n1 1, e B é uma matriz de ordem n2, o produto tensorial entre estas duas matrizes (denotado por A B), gera uma matriz C de ordem n1 × n2, onde cada elemento Ci, j é dado segundo a equação 1.
Em esta equação, x e y são Como foi explicado anteriormente, as matrizes no contexto deste trabalho são sempre quadradas.
De essa forma a ordem de uma matriz representa o número de linhas e colunas.
Números reais positivos.
O operador unário x representa o número inteiro imediatamente inferior a x, e a operação x y calcula o resto da divisão inteira de x dividido por y.
Ci, j $= A/ n2+ 1,/ n2+ 1 n2 n2)+ 1 A idéia do produto tensorial é combinar cada elemento da matriz A com cada elemento da matriz B. Para ilustrar está idéia observe as matrizes abaixo:
A matriz resultante do produto tensorial entre A e B no exemplo acima fica:
Repare que esta operação mapeia em cada elemento da matriz resultante o produto de um elemento de A por um elemento de B. Em outras palavras, o resultado desta operação é uma matriz que contém a combinação de todas as multiplicações possíveis entre elementos das matrizes A e B. Para ilustrar melhor esta idéia, abaixo é apresentado como a multiplicação de cada elemento aij da matriz A multiplica cada elemento bij da matriz B, gerado ao final do produto tensorial.
A11 × a21 Soma Tensorial A soma tensorial é definida com base no produto tensorial.
Esta operação, dentro de o escopo deste trabalho, também recebe como operandos duas matrizes reais quadradas.
Dado duas matrizes A e B, a soma tensorial destas matrizes (denotada por A B), é definida por a equação 2.
Onde, IM denota uma matriz identidade2 da mesma dimensão da matriz M. Note que a soma tensorial gera igualmente uma matriz de ordem n1 × n2.
Para ilustrar o cálculo de uma soma tensorial utilizaremos as mesmas matrizes que utilizamos para exemplificar o produto tensorial:
Para este exemplo, a matriz resultante da soma tensorial entre A e B fica:
A soma tensorial é amplamente utilizada para o mapeamento dos modelos descritos em formalismos analíticos estruturados em cadeias de Markov.
No entanto, é preferível decompor esta operação em produtos tensoriais para homogeneizar o tratamento numérico realizado.
Este aspecto se torna relevante para compreender os algoritmos que realizam a MVD e consequentemente faz- se necessário apresentar como esta decomposição pode ser realizada.
Dada uma série de somas tensoriais com N matrizes, esta propriedade diz que as N Matriz identidade é uma matriz cujo todos os elementos localizados na diagonal principal são iguais a 1 e todos os outros elementos são iguais a zero.
Generalizando o exemplo acima para uma série de somas tensoriais com N matrizes temos:
A idéia de um termo produto tensorial (ou somente termo, para abreviar) é representar diversas operações de produto tensorial consecutivas.
Formalmente, um termo a como na equação 3.
Note composto por o produto tensorial de N matrizes M1 a Mn ficar que esta operação é bastante parecida com um somatório onde ao contrário de somas as operações realizadas são produtos tensoriais.
Um conceito fundamental para a compreensão da MVD é como o Descritor Markoviano é armazenado.
Dependendo do formalismo utilizado para modelagem, a estrutura algébrica do descritor varia.
Para abstrair os detalhes específicos de cada formalismo, adotamos o DM como sendo a soma consecutiva de diversos termos produto-tensorial.
Dada uma série de somas de T termos, onde cada termo é composto por o produto tensorial entre N matrizes, o descritor é apresentado como visto na equação 4.
Em este contexto, é necessário restringir que cada matriz Qi possuirá a mesma ordem, independente do termo k em o qual se encontra.
De essa forma, é possível garantir que cada termo que compõe o descritor resulta numa matriz, se resolvido, de mesma ordem.
Logo, um descritor composto por T termos com N matrizes cada fica como abaixo:
Qi Note que o símbolo Q (k) não denota potenciação e sim funciona como um índice para o somatório (para fazer esta distinção são utilizados os parênteses).
Durante o texto a (k) expressão Q denota o k--ésimo termo do somatório do descritor.
Para representar o descritor inteiramente, o símbolo Q é utilizado sem índices.
Exemplos de Descritores Em esta seção apresentaremos dois exemplos de descritores de dois formalismos analíticos estruturados.
O objetivo aqui é exemplificar como descritores diferentes podem ser manipulado algebricamente gerando uma soma de termos tensoriais como apresentado na equação 4.
Ou, em outras palavras, como os diferentes descritores de cada formalismo podem ser algebricamente manipualdos para a mesma estrutura.
Os dois formalismos abordados nessa seção, Redes de Autômatos Estocásticos (SAN) e Redes de Petri Estocásticas (PEPA), foram escolhidos por a sua popularidade em trabalhos científicos recentes.
Descritor em SAN A idéia de uma Rede de Autômatos Estocásticos é descrever um modelo global de um sistema em diversos módulos (subsistemas) independentes entre si, onde as interações entre esses subsistemas podem ocorrer em alguns casos.
Cada módulo independente é definido como um autômato estocástico.
A modelagem de cada autômato é realizada parametrizando- se estados, transições e eventos.
Uma vez que eventos podem representar sincronismo entre dois ou mais autômatos, os dados sobre um modelo são armazenados em matrizes que definem o comportamento local e matrizes que definem o comportamento sincronizante.
O Descritor Markoviano, em SAN, apresenta- se como visto na equação 5.
Em essa equação, N representa o número de autômatos e E o total de eventos que modelam interações entre os autômatos (eventos sincronizantes).
Como pode ser observado, o descritor de SAN representa uma parte descrita como a soma tensorial entre matrizes.
Como apresentando anteriormente, é possível decompor uma série de somas tensoriais aplicando- se a propriedade da decomposição em fatores normais.
Logo, é possível normalizar o descritor de SAN num descritor que somente possui termos produto-tensorial.
A tabela 1 demonstra como fica o descritor de SAN após a normalização da parte local.
Foge do escopo desse trabalho a apresentação do formalismo SAN em detalhes.
Entretanto, devido a a utilização de estudos de caso utilizando este formalismo, no final do trabalho uma explicação mais aprofundada sobre como os modelos SAN são construídos é fornecida no apêndice A. Descritor em Redes de Petri Estocásticas Redes de Petri Estocásticas (SPN) fornecem uma maneira de modelar sistemas baseados no conceito clássico de Redes de Petri.
De maneira geral, os conceitos existentes em tal formalismo se aproximam dos utilizados em SAN, uma vez que ambos apresentam módulos independentes com pontos de interações específicos.
De maneira análoga a SAN, o descritor utilizando SPN, apresenta- se algebricamente dividido numa parte local e outra destinada a representar as interações entre módulos (parte sincronizante), visto na equação 6.
De a mesma forma que em SAN, as somas tensoriais do descritor para SPN apresentado na equação 6 podem ser substituídas por a soma consecutiva de diversos termos produto-tensorial resultando num descritor como o apresentado na equação 4.
Esses exemplos indicam que, em geral, os formalismos de modelagem analítica estruturados podem beneficiar- se das versões dos algoritmos propostos nesse trabalho.
Algoritmos para a MVD Algebricamente, o problema da Multiplicação Vetor--descritor consiste na multiplicação de um vetor x por um termo algébrico, o descritor, Q. Formalizando essa idéia, temos a equação 7 substituindo a multiplicação original Ax da matriz de coeficientes por o vetor.
Atualmente, existem dois algoritmos que manipulam o DM:
Shuffle e slice.
A geração de uma única matriz, resolvendo a expressão algébrica do DM, não é desejada pois exigiria um grande custo computacional de armazenamento.
Os algoritmos que realizam a MVD tornam- se necessários para manipular esta estrutura de forma a manter o tamanho ocupado por o modelo gerenciável em termos de necessidade de memória.
A seguir serão apresentados os princípios básicos dos dois algoritmos que atualmente realizam a MVD.
Shuffle A demanda por algoritmos que realizassem a MVD de maneira que não fosse necessário resolver o descritor num gerador infinitesimal fez surgir o algoritmo shuffle.
Inicialmente proposto por diversos autores, os principais trabalhos que fazem menção a este algoritmo são e.
De maneira geral, algumas propriedades da álgebra tensorial s~ realização da MVD sem incorrer na geração do gerador infinitesimal.
O shuffle se baseia na decomposição de um termo num produto ordinário de fatores normais, vide equação 8.
Esta propriedade permite que um termo produto-tensorial entre N matrizes seja decomposto na multiplicação de N termos, cada um com N matrizes.
No entanto, após realizada esta decomposição, cada termo apresenta apenas uma matriz com valores originais enquanto todas as outras N -- 1 matrizes são substituídas por uma matriz identidade que conserva a ordem da matriz de mesma posição no termo.
O objetivo de utilizar propriedade é realizar o mapeamento dos elementos de cada matriz no gerador infinitesimal equivalente.
O algoritmo shuffle define os operadores nlef ti e nrighti para mapear os elementos e um operador que das matrizes de um termo no gerador infinitesimal.
O operador nlef ti ório da ordem de dado uma matriz qualquer Qi, de um termo qualquer, realiza o produt´ todas as matrizes que estão à esquerda de Qi.
No caso de a matriz Q1, ou seja, a primeira cão resulta em 1, uma vez que não há matriz de um termo, o operador nlef t1 por defini¸ matrizes à esquerda deste termo.
O operador nrighti se diferência de nlef ti por retornar o produtório da ordem das matrizes que estão à direita de uma matriz Qi.
De forma análoga, este operador é por definição 1 quando a matriz está localizada na extremidade direita de um termo, ou seja, nrightN $= 1, para um termo com N matrizes.
Assim, o algoritmo shuffle se baseia na propriedade da decomposição em fatores normais para reescrever cada termo do descritor como visto na equação 8: NrightN O shuffle implementa a multiplicação de cada termo Q (k) utilizando o resultado da decomposição de um termo em fatores normais ordinários.
Para cada matriz de um termo Qi, o vetor deve ser multiplicado por esta matriz utilizando os resultados de nlef ti e nrighti com o objetivo de mapear a localizaésima matriz deste no cão dos elementos da i-´ gerador infinitesimal.
Por exemplo, a multiplicação do vetor por a última matriz de cada termo ficará como apresentado na figura 3.
Em este caso particular, o operador nrightN´ no resultado do produto tensorial.
Logo, a matriz QN deve ser replicada em nlef tN blocos diagonais no gerador infinitesimal como visto na figura 3.
Entretanto, para as outras matrizes de um termo, esta operação utiliza blocos não contíguos do vetor e, conseqüentemente, exige a alteração de diversos elementos.
O custo computacional em número de multiplicações de ponto flutuante necessárias para a multiplicação do vetor x por um termo qualquer t, é dado por a equação 9.
Onde (t) ni é a ordem da i-ésima matriz do termo t e nzi corresponde ao número de elementos diferentes de zero na i-ésima matriz do termo t..
Ct $= i $= 1 (t) nzi (t) i $= 1 ni Slice O algoritmo slice é relativamente novo e já tem apresentado resultados interessantes na resolução de determinados modelos.
A idéia central neste algoritmo consiste na decomposição dos termos produto-tensorial em pequenas somas algébricas.
Acredita- se que o slice possa aproveitar melhor o poder de processamento de aglomerados de computadores, uma vez que permite a decomposição do problema em menores fatias.
O algoritmo slice é baseado na propriedade da decomposição aditiva.
Esta propriedade demonstra que o produto tensorial consecutivo, entre duas ou mais matrizes, pode ser descrito como a soma da multiplicação de diversas matrizes unitárias.
Esta propriedade é formalizada na equação 10.
O princípio básico do algoritmo slice é aplicar essa propriedade sem considerar a última matriz de cada termo.
As outras matrizes do termo são representadas por diversas matrizes unitárias, cada matriz unitária é chamada de Fator Normal Unitário Aditivo (AUNF ou fator para abreviar), essa sigla deriva da nomenclatura internacional, em inglês, Aditive Unitary Normal Factor.
Para gerar os AUNFs, é efetuado o produto tensorial das N -- 1 matrizes de cada termo produto-tensorial.
Por exemplo, supondo um termo produto-tensorial que envolva três matrizes Q1, Q2 e Q3, a propriedade da decomposição aditiva é efetuada apenas considerando o produto Q1 Q2.
Para exemplificar, supondo que as Q1, Q2 e Q3 sejam:
Utilizando a propriedade da decomposição aditiva todos os elementos das matrizes Q1 e Q2 são multiplicados separadamente para depois serem multiplicados por a matriz Q3, como abaixo:
Este procedimento se diferência do realizado por o shuffle principalmente por este mapear apenas a localização da última matriz de cada termo no DM.
Para realizar este mapeamento, cada AUNF guarda a informação de linha e coluna onde este estaria localizado na matriz resultante do produto tensorial entre as N -- 1 matrizes mais à esquerda de um termo.
Guardando estes índices, a geração de todos os fatores (AUNFs) só precisa ser realizada uma vez.
Esta técnica, portanto permite que os diversos termos tensoriais sejam desmembrados em pequenas multiplicações.
Em máquinas de alto desempenho, como aglomerado de computadores, essa abordagem apresenta- se bastante atraente uma vez que torna possível considerar cada fator como uma tarefa independente.
Este aspecto diferência o slice do shuffle principalmente por a quantidade de dados manipulados na multiplicação de cada fator.
Para ilustrar essa idéia, a figura 4 apresenta um exemplo de multiplicação de um AUNF por a última matriz de um termo.
Em este caso, o número de elementos não nulos na última matriz do termo (nzN), determina a quantidade de multiplicações que serão realizadas.
Em o pior caso, onde a última matriz do termo, QN, não possui zeros, serão necessárias nN × nN multiplicações.
MVD de Alto Desempenho Atualmente, diversas aplicações utilizam computação de alto desempenho.
O mapeamento do DNA humano, a predição de terremotos, a renderização de imagens para auxílio ao diagnóstico de doenças, são alguns exemplos.
Modelos analíticos apresentam- se de grande aplicação prática.
Estes podem ser utilizados, por exemplo, para modelar e apresentar estimativas de desempenho dos mais diversos sistemas computacionais.
Uma aplicação prática possível, por exemplo, é a utilização para analisar sistemas de rede, auxiliando no diagnóstico de problemas como gargalos e roteadores sub-utilizados.
Os formalismos de modelagem analítica, de maneira geral, apresentam restrições na complexidade dos modelos que podem ser resolvidos por dois motivos:
Memória e tempo de resolução.
Tipicamente, a quantidade de memória utilizada por os modelos aumenta à medida que a complexidade destes aumenta.
Atualmente, para mitigar este problema, são utilizados algoritmos que realizam a MVD.
A principal vantagem da utilização destes algoritmos é evitar armazenar o gerador infinitesimal reduzindo drasticamente a demanda de armazenamento.
Em casos não raros, obtém- se uma redução de até 95%.
No entanto, o tempo necessário para a resolução de alguns modelos pode ser um fator limitador.
Em trabalhos recentes, diversas abordagens vêm sendo estudadas, o próprio algoritmo slice neste contexto apresenta avanços significativos.
O presente capítulo mostra como as técnicas de alto desempenho são utilizadas para ida.
As técreduzir o custo de armazenamento e ainda como a MVD pode ser distribu´ nicas aqui empregadas são relacionadas a plataforma de execução pretendida, no caso, um aglomerado de computadores.
Por esta razão a seção 3.1, recapitula as principais características deste tipo de plataforma, assim como as técnicas de programação consagradas em tais ambientes.
Para tornar a leitura mais clara, os algoritmos shuffle e slice, são apresentados respectivamente nas seções 3.3 e 3.4 separadamente.
Para cada versão de alto desempenho de um algoritmo são propostas duas abordagens de distribuição de carga (escalonamento).
Aglomerados de Computadores Um aglomerado de computadores (conhecida por a sigla internacional NOW, Network of Workstations) é uma rede dedicada a unir diversos computadores com o objetivo de cooperarem na resolução de problemas complexos.
A conexão das máquinas é realizada utilizando- se uma infraestrutura de rede e software especial.
O que caracteriza a arquitetura de um aglomerado é cada computador possuir seu espaço de endereçamento exclusivo.
Uma vez que a memória não é compartilhada, cada conjunto de dados relevante para o cálculo deve ser atribuído a uma das partições do espaço total de memória existente.
Desta forma, os dados precisam ser explicitamente particionados.
Ao mesmo tempo que essa característica adiciona complexidade na programação ela encoraja o desenvolvedor a explorar a localidade.
Localidade é a características de aproximar o dado relevante ao processamento de cada tarefa do processador que está executando a tarefa.
Trantando- se portanto de uma característica importante para atingir bons resultados em plataformas de alto desempenho.
Uma vez que permite aos processadores explorarem ao máximo o uso de suas memórias cache.
De as características citadas anteriormente surge um fator que deve ser levado em consideração no desenvolvimento de aplicações em aglomerados:
Sempre que dois processos trocam dados é necessário realizar um processo de sincronização.
O processo de sincronização é realizado utilizando- se primitivas para envio e recebimento de mensagens.
Tais primitivas são a base para o desenvolvimento de aplicações paralelas em aglomerados.
A terminologia troca de mensagens serve para denominar o paradigma utilizado na construção dessas aplicações.
As soluções de alto desempenho apresentadas neste trabalho utilizam uma plataforma do tipo aglomerado de computadores.
O padrão de comunicação adotado é MPI (do inglês, Message Passing Interface) um padrão consolidado para troca de mensagens em aglomerados de computadores.
Em a programação por troca de mensagens são criados diversos processos.
Cada processo sendo designado a um computador.
MPI provê primitivas para cada processo receber um identificador único e conhecer o número total de processos numa dada execução.
Um resumo das primitivas MPI utilizadas nesse trabalho e o seu significado é apresentado a seguir:·
MPI_ Comm_ rank -- retorna o identificador único do processo;·
MPI_ Comm_ size -- retorna o número total de processos executando a aplicação;·
MPI_ Recv -- recebe dados de um determinado processo;·
MPI_ Bcast -- transmite dados para todos os processos do sistema;·
MPI_ Reduce -- recebe dados de todos os processo do sistema aplicando uma operação algébrica;
Os aspectos de programação utilizando MPI se tornam relevantes para a compreensão do presente trabalho.
Importante ressaltar que cada processo conhece o número total de processos (MPI_ Comm_ size) e o seu identificador único numa execução (MPI_ Comm_ rank).
Assim, a comunicação pode ser facilmente implementada sem a configuração de parâmetros de baixo nível dependentes do protocolo de comunicação, tais como porta TCP ou endereço IP das máquinas.
Uma vez que MPI encapsula as primitivas básicas de comunicação, o uso dessa biblioteca permite uma fácil adaptação a diferentes tecnologias de rede.
MVD em Paralelo A idéia da paralelização da Multiplicação Vetor--descritor (MVD) é distribuir algebricamente a multiplicação do vetor dentro de o somatório.
Desta forma, temos por exemplo a possibilidade de executar a multiplicação do vetor por cada um dos termos de forma independente, como pode ser visto na equação 11.
Todavia, a maneira de distribuição da multiplicação depende da propriedade algébrica utilizada por o algoritmo.
Isso diferência as versões paralelas do shuffle e do slice.
Qk k $= 1 i $= 1 Qk x $= k $= 1 i $= 1 A MVD ocorre diversas vezes (tipicamente centenas ou milhares de vezes) para resolver um modelo.
Todavia, a paralelização dos algoritmos shuffle e slice, leva em consideração que a cada passo os processos calculam diversos resultados parciais.
Precisamente, cada processo p calcula um vetor parcial xp.
O algoritmo 1 ilustra como funciona a paralelização de uma iteração onde a MVD é realizada.
Em a notação do algoritmo 1, assim como em outros algoritmos deste trabalho, adota- se a variável procs para determinar o número total de processos existentes no ambiente de execução (equivalente a uma chamada da função MPI_ Comm_ size) e a variável p para determinar cada processo (equivalente a uma chamada da função MPI_ Comm_ rank).
Algoritmo 1 Estratégia de paralelização em alto nível.
Repare que na linha 2 do algoritmo 1, a MVD é realizada por um número indeterminado de iterações.
Todavia, para solucionar modelos com um grau de confiança razoável, o erro aceito é em torno de 10 o que exige um número elevado de iterações.
Alguns métodos iterativos para a solução de sistemas de equaço~ es lineares podem não convergir para um resultado com o erro mínimo estipulado.
Quando isso ocorre, os valores do vetor oscilam sem uma tendência clara a cada passo.
Para evitar que o método execute por um número indeterminado de iterações, na linha 2, existe um número máximo de iterações toleráveis para que o sistema chegue a um resultado.
Caso este número seja atingido, mesmo que a resposta ainda não tenha a precisão desejada, o algoritmo termina.
Em a linha 3 do algoritmo 1, cada processo p multiplica uma parte do descritor por o vetor da iteração atual (xk) gerando parte do vetor da próxima iteração (xk+ 1 p).
A parte do descritor que cada processo multiplica varia dependendo do algoritmo.
Porém, a multiplicação de cada termo de forma independente pode ser realizada diretamente, como visto na equação 11.
Para obter- se o vetor da próxima iteração, é necessário somar todos os vetores parciais.
Assim, nas linhas 4 e 5, cada processo envia o seu vetor parcial para o processo de identificação 0 e este fica encarregado de somar os vetores paraciais (xk+ 1 oxima iteração xk+ 1.
A o final, na linha 6, o processo p ou seja, em broadcast).
A o final deste algoritmo, cada processo possui o vetor da próxima iteração e uma nova etapa de MVD pode iniciar.
O resultado do procedimento da MVD realizada em paralelo é que a cada iteração os processos recebem o vetor da iteração atual xk, cada processo multiplica este por uma parte do descritor gerando um vetor parcial da próxima iteração xk+ 1 p.
O processo de menor identificação acumula os vetores parciais gerando o vetor da próxima k+ 1 iteração (x) e este é transmitido para todos os outros processos.
Este ciclo se repete até que o resultado atinja um erro mínimo ou um número máximo de iterações previamente estipulados.
A figura 5, ilustra como funciona a comunicaça~ o entre os processos em alto nível.
Em este diagrama, a cada iteração k o vetor é transmitido para todos os processos que calculam resultados parciais.
Os resultados parciais são posteriormente somados no processo 0, gerando o vetor da próxima iteração que novamente é enviado a todos processos iniciando um novo ciclo.
Shuffle Paralelo O cálculo específico que será realizado por cada processo é independente da estratégia apresentada no algoritmo 1.
Dependendo do algoritmo utilizado, shuffle ou slice, as possibilidades de distribuir o processamento variam.
De essa maneira, o processamento realizado por cada processo, linha 3, é diferente em cada caso específico.
Apresentaremos a seguir a estratégia de paralelização para o algoritmo shuffle onde são discutidas duas abordagens de escalonamento (distribuição de carga).
Abordagem de Escalonamento Simples Em a primeira abordagem, cada termo constitui uma tarefa independente e o número total de termos é conhecido.
Uma vez que o descritor é a soma de diversos termos, podemos efetuar a multiplicação de cada termo por o vetor de forma independente.
Assim, é possível distribuir o laço que distribuí a multiplicação do vetor por cada termo.
Algoritmo 2 Shuffle utilizando abordagem de escalonamento sem considerar custos.
Em o algoritmo 2, é apresentado como a divisão dos termos que cada processo deverá computar é realizada.
Em esse algoritmo, terms representa o número total de termos do descritor executando num ambiente com procs processos, cada um identificado por a variável p..
Para garantir que não haja cálculo redundante, em outras palavras, que dois ou mais processos não realizarão o mesmo cálculo, cada processador p começa calculando o termo (ou tarefa) de mesmo índice que a identificação do processo, linha 2.
Esse índice recebe, a cada execução do laço o número total de processos (procs) mais ele mesmo t $= t+ procs, linha 8.
Assim, garanti- se que as tarefas designadas a cada processo não coincidam.
Mesmo quando a divisão do número de tarefas por o número de processadores não é exata, esse algoritmo é capaz de distribuir o resto da divisão.
Para exemplificar esta abordagem de escalonamento, apresentamos uma situação de execução hipotética com 16 termos sendo executado por 3 processos, vista na figura 6.
Em a figura cada índice da lista de termos´ designado para um processo, onde o padrão de preenchimento indica o processo para o qual um termo foi designado.
Em esse caso, o primeiro processo receberia os termos de índices 0, 3, 6, 9, 12 e 15.
O segundo processo, de identificador 1, receberia os termos de índice 1, 4, 7, 10 e 13.
O terceiro processo receberia os termos de índices 2, 5, 8, 11 e 14 (prenchidos com).
Garantindo que os processos não realizem cálculo redundante e recebam aproximadamente o mesmo número de tarefas.
Repare que esse algoritmo não impõe restrições ao número de processos que deverão executar uma aplicação.
No entanto, não faz sentido executar a aplicação com um número de processos maior que o número de tarefas (ou termos).
Pois nessa situação, algum processo não realizaria cálculo.
Apesar de essa abordagem apresentar um método direto e eficaz de realizar a distribuição de carga, o fato de não considerar o custo das tarefas pode ocasionar, em determinadas situações onde os termos possuem custos muito discrepante, um resultado pouco eficiente.
Apresentaremos a seguir uma versão de escalonamento para o shuffle que leva em conta o custo computacional das tarefas.
Escalonamento Considerando Custos A segunda abordagem de escalonamento considera os custos computacionais envolvidos no cálculo de cada uma das tarefas.
Uma vez que o número de elementos nulos varia em cada uma das matrizes, a multiplicação de cada termo por o vetor apresenta tipicamente diferentes custos de um termo para outro.
Em esse sentido, foi proposto um algoritmo que tenta equilibrar a carga total de trabalho em cada processo.
A idéia no algoritmo é criar uma lista de tarefas (ou seja, termos) contendo o custo e índice de cada um.
Posteriormente, ordena- se esta lista por custo em ordem decrescente.
Uma vez que a lista está ordenada, se percorre a lista designando uma tarefa sempre ao processo com menor carga.
Algoritmo 3 Shuffle utilizando segunda abordagem de escalonamento, considerando custos.
O algoritmo 3, apresenta essa idéia de escalonamento de forma detalhada.
primeira-mente, o custo computacional do cálculo de cada termo é realizado na linha 4 utilizando- se a equação 9 apresentada no capítulo 2.
A medida que o custo de cada termo é calculado os termos são inseridos numa lista com seus respectivos índices, linha 6.
Após esse procedimento, ordena- se a lista de tarefas por custo em ordem decrescente, colocando a tarefa de maior custo no início da lista1.
As etapas descritas anteriormente, tornam possível A implementaça~ o utiliza o método de ordenaça~ o quicksort que apresenta complexidade O (nlogn).
A o final desse procedimento, as tarefas designadas a cada processo são conhecidas por todos.
Isso implica que todos os processos realizam o algoritmo de distribuição de carga simultaneamente.
Com isso, acrescenta- se uma parcela de pré-processamento realizada antes da MVD.
Entretanto, este processamento não possui um custo significativo pois, na maioria dos casos, o número de termos é tipicamente pequeno.
Slice Paralelo O algoritmo slice utiliza a propriedade da decomposição de um produto tensorial em fatores normais unitários aditivos (ou fatores).
Um fator é basicamente um elemento composto por a multiplicação sucessiva de apenas um elemento não nulo de cada matriz de um termo.
Esta propriedade foi apresentada no capítulo 2, equação 10.
A idéia que deu origem ao algoritmo slice foi a de realizar a geração dos fatores num pré-processamento guardando apenas estes e a última matriz de cada termo.
Para realizar o mapeamento dos elementos da última matriz de um termo no DM, guarda- se o índice desta e associa- se um índice a cada fator (AUNF) juntamente com o resultado das multiplicações sucessivas.
Em outras palavras, cada fator é composto por três informações (E, i, j), onde E é o resultado das multiplicações sucessivas de cada elemento não nulo das N -- 1 primeiras matrizes de um termo;
I, j são respectivamente os índices de linha e coluna deste elemento na matriz gerada resultante do produto tensorial entre as N -- 1 matrizes de um termo.
A geração dos fatores (AUNFs) é realizada numa etapa de pré-processamento uma única vez.
Portanto, essa etapa não representa uma porça~ o significativa do cálculo.
Uma vez gerada a lista de fatores, a mesma é armazenado e utilizada a cada etapa da MVD.
Independente do número total de iterações necessárias para a resolu¸ valores permanecem constantes.
A presente abordagem apresenta um custo de memória diferente do shuffle que armazena apenas as matrizes utilizando compactação HBF2, pois uma vez que a lista de fatores é gerada torna- se necessário armazenar somente essa e a última matriz de cada termo.
HBF é um formato compacto para armazenamento de matrizes, a sigla faz mença~ o as pessoas envolvidas na construça~ o do formato:
Harwell Boeing Form.
Primeira Abordagem de Escalonamento Essa abordagem é bastante semelhante a primeira técnica utilizada para o shuffle.
Apesar de não explorar os aspectos positivos da divisão de tarefas num grão menor proporcionadas por o slice, tal abordagem se torna atraente por permitir que a geração dos AUNFs de cada termo possa ser realizada de forma distribuída.
Como a geração dos fatores é realizada para cada termo e cada termo é uma tarefa independente, não é necessário que todos os processos realizem a etapa de pré-processamento.
Cada processo pode computar apenas a lista de fatores dos termos que irá efetivamente multiplicar a cada iteração.
Desta forma, antes de iniciar o procedimento iterativo que realiza diversas vezes a MVD, pode- se realizar o pré-processamento de forma distribuída.
Devido a considerar cada termo como uma tarefa, essa abordagem assemelhase bastante com a primeira abordagem de escalonamento proposta para o shuffle.
Algoritmo 4 Slice utilizando abordagem simples de escalonamento 2: T $= p 3: Enquanto t terms faça ListaFatoresNormais $= calculaFatoresNormais (t) t $= t+ procs 7: Fim enquanto inimo Ou iteração\&gt; máximo faça 9: Enquanto erro m´ t $= p enquanto t terms faça xk p $= xp+ slice (ListaFatoresNormais, t, x) t $= t+ procs fim enquanto 16: Fim enquanto De forma geral, o algoritmo 4 mostra como a estratégia de paralelização pode incluir o pré-processamento.
As linhas 1 a 7, mostram a geração de uma lista de fatores normais para cada termo t..
Posteriormente, nas linhas 8 a 16, a resolução do sistema é realizada por diversas iterações onde a cada passo o processamento é realizado de forma idêntica ao apresentado na primeira abordagem de escalonamento do shuffle.
A principal vantagem desta abordagem é não existir interdependência entre as tarefas, possibilitando o particionamento do conjunto de dados.
Pois cada termo somente precisa ser armazenado por o processo ao qual foi designado.
Entretanto, esta abordagem não se beneficia da característica do slice de poder quebrar as tarefas em grãos menores.
A próxima abordagem visa justamente implementar um algoritmo de balanceamento de carga com essa característica.
Escalonamento por AUNF O objetivo principal dessa abordagem é considerar cada fator (AUNF) como sendo uma tarefa independente das outras.
A motivação para tal abordagem é a possibilidade de quebrar o problema em unidades de dados com menores custos de processamento.
Em outras palavras, aumenta- se o número de tarefas reduzindo o custo computacional de cada uma.
A idéia central é criar uma lista de fatores que serão multiplicados por cada processo.
Assim, durante a etapa de pré-processamento, é possível atribuir cada fator (tarefa) a um processo, uma vez que o número total de tarefas é conhecido a priori.
Apesar de tornar o grão da aplicação menor, essa abordagem impossibilita a distribuição da etapa de pré-processamento.
Em o algoritmo 5, é mostrado como o pré-processamento é realizado de forma a gerar uma lista de tarefas para cada processo.
Após a execução de tal etapa, ainda no préprocessamento, é efetuado a geração dos fatores.
Em este processo, a última matriz de cada termo é associada a cada tarefa.
Garantindo assim que a multiplicação dos fatores por a última matriz de cada termo possa ser realizada de forma independente do termo ao qual estão associadas. Algoritmo 6 Slice utilizando abordagem que considera cada AUNF como uma tarefa.
Para taref a $= ListaDeT aref as até UltimaT aref a faça k+ 1 k+ 1 xp $= xp+ Slice (x, taref a) 5: Fim para Utilizando essa idéia, o cálculo que cada processo efetua numa iteração fica como no algoritmo 6.
Em esse algoritmo os processos consideram como cada tarefa independente um AUNF o que propicia uma distribuição de carga mais justa.
Dividindo-se os termos em pedaços menores pode-se realizar uma distribuição de carga bastante precisa, em a qual a diferença de processamento de um processo para outro não afeta de maneira significativa o desempenho geral da aplicação.
Resultados Os resultados obtidos por as implementações dos algoritmos propostos no presente trabalho serão apresentados através de gráficos de aceleração (speedup).
Essa métrica visa comparar o tempo de execução da aplicação seqüencial com o obtido após a paralelização.
Formalisando, se uma aplicação seqüencial leva um tempo Tseq para uma determinada entrada de dados, e executando- a em paralelo com p processadores a mesma aplicação leva um tempo Tp, diz- se que o speedup obtido com esta aplicação é dado por a razão entre o tempo seqüencial e o tempo paralelo, como apresentado na equação 12.
Os resultados apresentados foram obtidos utilizando a média de 10 execuções cada uma realizando 100 iterações.
O tempo de uma iteração foi medido utilizando o tempo real da execução com um cronômetro interno à aplicação.
Em este tempo foi incluído o tempo necessário para a transmissão do vetor e dos vetores parciais.
A qualidade dos resultados apresentados foi garantida através da observação do desvio padrão.
Por razões de clareza e espaço os detalhes de cada execução não são apresentados nesta seção mas no apêndice C. Em esse apêndice são apresentados a média, o desvio padrão, o speedup e a eficiência para cada execução realizada.
Cada um dos 104 nós desta plataforma possui dois processadores Itanium-21 de 64 bits operando a 900 Mhz.
Equipados com 3 GB de memória e 72 GB de disco rígido.
Os computadores são interconectados por uma rede de baixa latência Myrinet.
Em o total, o i-cluster2 é composto por 208 processadores, 312 GB de memórias, somando uma capacidade de armazenamento em disco de 7,5 Tb (TeraBytes).
Em relação a o software, cada computador que compõe o icluster-2 utiliza sistema operacional Linux com a distribuição Red Hat (Enterprise Linux AS 3).
A biblioteca utilizada para a programação MPI é lammpi.
Para garantir que outras aplicações não interferissem na execução dos testes, por o uso da rede, o icluster-2 foi utilizado exclusivamente durante os testes.
Desta forma, afirmamos que não havia transmissões de outras aplicações ocorrendo durante cada execução.
Para mitigar o efeito de cache a cada experimento, o ambiente de execução era restaurado.
Isto foi realizado utilizando o comando lamclean que remove arquivos temporários, desalocando recursos e cancelando registros de processos.
A utilização deste comando garante que a cada execução realizada o estado de cada um dos nós é semelhante ao obtido após uma reinicialização dos daemons do MPI.
Casos de Teste Como descrito no capítulo 2, a entrada da aplicação é um descritor markoviano (DM) que consiste na soma consecutiva de uma série de termos produto- tensoriais.
Estes termos são carregados utilizando como entrada um arquivo composto por diversas matrizes.
Supondo um descritor com 2 termos, cada um contendo 3 matrizes como visto na figura 7, o arquivo de entrada seria como visto na figura 8.
Em este formato de entrada, uma linha precedida por&quot;&amp; «indica um comentário.
Foram utilizados quatro casos de teste para verificar o desempenho obtido com as implementações paralelas propostas nesse trabalho.
Dois casos de teste foram estudos de caso reais de modelagem analítica estruturada utilizando o formalismo SAN.
O primeiro Estes processadores possuem cada um uma memórica cache de 3 MB.
Um parâmetro relevante para determinar o aumento de desempenho de uma aplicação paralela é a quantidade de cálculo distribuída.
Esse parâmetro se torna ainda mais relevante em aglomerados de computadores, uma vez que nessas arquiteturas a comunicação representa um fator limitante da aceleração.
A quantidade de cálculo realizada por cada algoritmo varia de forma significativa.
Porém, existe um fator que colabora para o aumento de complexidade simultaneamente em ambos algoritmos.
Se um dado modelo possui o mesmo número de matrizes em cada termo e se a ordem destas matrizes são as a estes modelos mesmas, o fator relevante dentro de o escopo do trabalho que diferenciar´ será o número de elementos não nulos nas matrizes.
Desta forma, defini- se que a esparsidade de um descritor é dada por a média da razão entre o número de elementos não nulos (nzi) e o número total de elementos (ni 2) de cada matriz i.
O resultado desta operação é a porcentagem de elementos não nulos geral do descritor.
A equação 13, mostra como a esparsidade é calculada num descritor composto por T termos, cada um com N matri (k) zes, onde nzi e ni representam respectivamente o número de elementos não nulos e a ordem da i-ésima matriz do k--ésimo termo.
Assim, mais dois testes foram elaborados com base no modelo Misto com o intuito de verificar o comportamento dos algoritmos em situações que envolvessem um grande volume de multiplicações.
Para gerar esses dois modelos, chamados de Denso A e Denso B, foram acrescentados elementos não nulos aleatoriamente nas matrizes do modelo Misto.
A tabela 2 mostra alguns parâmetros relevantes de cada caso de teste.
O primeiro parâmetro é o número de termos de cada descritor.
Esse parâmetro se torna relevante por constituir uma tarefa nos algorimtos shuffle (utilizando ambas abordagens de escalonamento) e slice (primeira abordagem), limitando o número de processadores que podem ser utilizados nesses casos.
Em a segunda coluna, o parâmetro esparsidade mostra a porcentagem média de elementos não nulos das matrizes de cada descritor.
A terceira coluna apresenta o número de fatores (AUNF) relevante por constituir o grão (uma tarefa indivisível) na segunda abordagem de escalonamento do algoritmo slice.
A quarta e a quinta coluna mostram os tempos de execução seqüencial (ou seja, com apenas um processador) necessários para realizar um passo da MVD utilizando os algoritmos shuffle e slice respectivamente.
O tempo de execução do slice neste caso não considera o tempo de pré-processamento.
Em as próximas seções, os resultados obtidos com as abordagens de escalonamento de ambos os algoritmos são apresentados.
Em a seção que aborda os resultados obtidos com o algoritmo slice os tempos de pré-processamento são apresentados.
Por uma questão estrutural a comparação entre os dois algoritmos que realizam a MVD é realizada no capítulo seguinte.
Resultados Shuffle Em a presente seção são mostrados os resultados obtidos com as implementações do shuffle abordadas no capítulo 3.
Os resultados são apresentados de forma a traçar as principais diferenças entre os algoritmos de escalonamento propostos comparando- se o tempo de execução obtido com um determinado número de processadores.
Cada gráfico traça uma relação entre a aceleração obtida (eixo y) e o número de processadores utilizados (eixo x).
O número total de processadores utilizados é limitado por o número de termos nas implementação do shuffle.
A figura 9 apresenta dois gráficos com os resultados para as duas técnicas de escalonamento apresentadas para o shuffle utilizando o caso de teste SC.
A primeira técnica, mostrada na figura 9 (A), mostra valores de aceleração próximos do ideal em alguns pontos.
Esses resultados já apresentam- se satisfatórios se considerado a simplicidade dessa solução.
Por outro lado, observando a curva da técnica que considera custos), conclui- se que essa abordagem, para este caso de teste, não apresenta vantagem.
Outro aspecto que chama atenção é que em determinados pontos ambas as curvas apresentam uma estagnação nos valores de aceleração.
Por exemplo, utilizando 16, 17, 18, 19, 20 e 21 processadores o speedup permanece praticamente constante.
Isso se repete em outros intervalos, como:
13 a 15 e 22 a 31.
Acredita- se que esses pontos de estagnação sejam devido a distribuição de carga.
Essa afirmação pode ser comprovada observando- se que, nos pontos cujo o número de processadores é um múltiplo do número de tarefas (4, 8, 16 e 32), a aceleração está bastante próxima do ideal.
Em a figura 10 observam- se os gráficos que apresentam os resultados para as duas abordagens de escalonamento utilizando o caso de teste Misto.
Semelhantemente aos resultados analisados anteriormente, ambas as técnicas apresentaram acelerações significativas.
Novamente, percebe- se um comportamento bastante parecido.
O que chama atenção nesses dois gráficos é o speedup obtido com 8 processadores com os algoritmos de escalonamento.
Sem considerar custos, figura 10 (A), a aceleração com 8 processadores é maior do que usando 7 processadores com essa mesma versão.
Já considerando custos, figura 10 (B), o resultado com 8 processadores se monstra inferior ao obtido com 9.
Esses aspectos reforçam a impressão de que, na abordagem que considera custos, a relação entre a quantidade de termos não precisa ser um múltiplo do número de processadores.
A figura 11 e a figura 12 apresentam os resultados obtidos respectivamente com os casos de teste Denso A e Denso B utilizando o shuffle.
Observe que para esses dois testes as acelerações são praticamente as mesmas, independente da técnica de escalonamento utilizada.
Isto acontece devido a o fato que todas as tarefas possuem o mesmo custo nesses casos de teste.
A idéia desses dois testes é demonstrar que mesmo com a abordagem que considera custos, o algoritmo shuffle pode apresentar um comportamento pouco escalável quando os termos possuem custos muito semelhantes.
Isso acontece também devido a o tamanho do grão ser sempre limitado por o número total de termos.
A figura 13 apresenta o detalhe da carga atribuída a cada processo para algumas configurações do caso de teste Misto.
A carga é quantificada em número de multiplicações em ponto flutuantes.
Em esta figura, os três gráficos na parte superior apresentam o detalhe do cálculo realizado com 7, 8 e 9 processos respectivamente da esquerda para a direita.
A carga atribuída a cada processo é apresentada em milhares de operações de ponto flutuante (MMP).
Com 7 processos, o desempenho é limitado por um processo que realiza aproximadamente 26 MMPs, já com 8 processos o balanceamento de carga se apresenta de forma mais eficiente uma vez que o processo com mais carga recebe em torno de 15 MMPs.
Porém, ao aumentar o número de processos para 9 a abordagem de escalonamento não evolui.
Como pode ser observado o processo mais carregado computa aproximadamente 15 MMPs também com 9 processadores limitando o aumento de desempenho geral da aplicação.
Logo, pode- se concluir que como o grão de cada tarefa para esses métodos sempre será grande, os resultados obtidos não apresentam uma boa escalabilidade quando o número de tarefas não é divisível por o número de processadores.
O desempenho geral da versão paralela do shuffle foi significativo.
Entretanto, o comportamento da aceleração nos testes não evolui em alguns intervalos.
Isso se deve as características intrínsecas deste algoritmo que não permite dividir um termo em pequenas tarefas.
Um das principais razões que motivaram a paralelização do slice foi a possibilidade de quebrar os termos em mais tarefas.
Resultados Slice Esta seção tem como objetivo apresentar os resultados obtidos com o algoritmo slice utilizando os mesmos casos de teste anteriores.
Como já foi discutido no capítulo 3, o slice de alto desempenho inclui uma etapa de pré-processamento que deve ser realizada uma única vez.
Em esse sentido, a utilização da primeira abordagem de escalonamento, que considera cada termo como uma tarefa independente, foi utilizada por permitir a distribuição desse cálculo.
A tabela 3 mostra os tempos de pré-processamento para quatro casos de teste utilizando a primeira abordagem de escalonamento.
Em essa tabela, são apresentados também o custo computacional para realizar uma iteração da MVD.
Apesar de o custo de uma iteração ser menor que o custo de pré-processamento, o custo de processamento não é impactante no tempo total de execução.
Isso porque são necessárias centenas de iterações para resolver um problema.
O resultado é que o custo de pré-processamento é diluído ao longo de algumas iterações.
Por exemplo, supondo que para o caso de teste SC necessita- se de 200 iterações para o sistema de equações ser resolvido.
Ao todo seriam necessários cerca de 2600 segundos para a resolução do modelo.
Conseqüentemente, nessa situação o tempo de pré-processamento, que para esse teste é aproximadamente 39 segundos, representaria pouco mais de 1% do tempo total de execução.
No entanto, os métodos iterativos de resolução de sistemas de equações lineares não são determinísticos.
Com isso, o número de iteraço~ es necessárias para realizar o pré-processamento pode ser ou não ser significativo dependendo do modelo.
De essa forma, faz- se interessante paralelizar a etapa de pré-processamento para abranger tais situações.
A figura 14 mostra a aceleração obtida na etapa de pré-processamento quando utilizando a abordagem que considera cada termo como uma tarefa.
Essa figura apresenta as acelerações obtidas com os casos de teste SC), Misto (figura 14 (B)), Denso A) e Denso B (figura 14 (D)).
Com o teste SC é possível observar que o desempenho é melhor quando a quantidade de processadores é múltiplo do número de tarefas.
O caso de teste Misto apresenta um comportamento´ importante observar que nos casos de teste onde as tarefas possuem o semelhante.
E mesmo custo, figura 14 C e D, que a aceleração apresenta um comportamento unicamente crescente.
Isso ocorre porque nesses casos a distribuição de carga é uniforme, uma vez que, não existe praticamente diferença nos custos de cada termo.
Apesar de a distribuição do cálculo de pré-processamento ter sido satisfatória em alguns casos, a necessidade de paralelizar esta etapa é menos significativa do que a MVD.
Isso porque o pré-processamento é computado somente uma vez.
Já a MVD é uma operação efetuada diversas vezes até que um modelo seja solucionado.
Em esse ponto, o slice apresenta uma vantagem em sua segunda abordagem de escalonamento por que esta considera cada AUNF como sendo uma tarefa.
Tornando possível quebrar os termos em mais tarefas de custo menor (grão menor).
Em a figura 15 a aceleração obtida com a paralelização da MVD para ambas técnicas de escalonamento é apresentada utilizando o caso de teste SC.
Faz- se importante ressaltar que, para fins comparativos, o cálculo de pré-processamento não foi considerado nos resultados apresentados.
E perceptível, comparando- se os gráficos e (B)), que a técnica de escalonamento considerando cada termo como uma tarefa apresenta maior escalabilidade.
Isso comprova que a utilização de um grão menor é melhor.
Mesmo considerando que a segunda abordagem de escalonamento impede a paralelização da etapa de pré-processamento.
Em a figura 16 são apresentados os resultados para o caso de teste Misto com as duas abordagens de escalonamento.
De forma similar ao comportamento obtido com o caso de teste SC, a utilização da segunda abordagem gera uma curva mais escalável.
Isso confirma a hipótese de que a aplicação é mais adaptável a um grão menor.
Um aspecto que chama atenção nos gráficos da figura 16 é a distância das curvas de speedup da curva ideal.
Em esse teste tal comportamento é justificado porque o tempo de execução é bastante pequeno utilizando a versão seqüencial do algoritmo slice, veja tabela 2.
A conseqüencia disso, é que como o tempo de execução não é muito significativo, o tempo necessário para transmissão dos dados não compensa tanto a utilização da versão paralela.
Em as figura 17 e 18 são apresentados, respectivamente, os resultados para os casos de teste Denso A e Denso B. Com discutido anteriormente, esses dois modelos hipotéticos apresentam situações onde considerar ou não o custo de cada termo não influência no resultado de escalonamento.
Isso ocorre porque o custo computacional de cada tarefa nesses dois casos é o mesmo.
Porém, ao utilizar a segunda abordagem de escalonamento com o slice vislumbra- se uma curva que apresenta um comportamento escalável.
Observando essas duas figura é possível notar que, a medida que o tempo seqüencial do caso de teste é maior, as curvas de aceleração apresentam um comportamento mais próximo de o ideal.
Em geral, os resultados com a segunda abordagem de escalonamento do slice apresentam um comportamento escalável e próximo de o ideal.
Faz- se ressalva aos casos de teste que possuem um custo computacional baixo para a versão seqüencial.
Porém, ainda obtém- se resultados expressivos em tais situações.
Conclusão O presente trabalho apresentou como técnicas de alto desempenho podem ser empregadas para acelerar a Multiplicação Vetor--descritor.
Essa operação é realizada diversas vezes para obter estimativas de desempenho em modelos que utilizam um formalismo analítico estruturado.
Esses modelos são muito utilizados na predição de desempenho de sistemas em geral, pois apresentam uma forma mais eficiente de armazenamento do que Cadeias de Markov.
As soluções propostas nesse trabalho utilizam uma estrutura algébrica comum aos diversos formalismos de modelagem analítica estruturados existentes e portanto podem ser empregadas em diferentes situações.
O foco principal da paralelização foi o processo de uma etapa da MVD, operação que é realizada diversas vezes para inferir estimativas de desempenho de um modelo.
Porém, os detalhes de distribuição de tarefas foram delineados com base nas operações algébricas envolvidas em cada um dos dois algoritmos para realizar tal operação:
Shuffle e slice.
Para cada um dos algoritmos foram apresentadas duas abordagens de escalonamento explorando as características específicas de cada um.
Em todos os testes realizados, obteve- se uma aceleração (speedup) considerável independentemente do algoritmo utilizado e da abordagem de escalonamento.
Em esse mesmo contexto, a utilização de diferentes abordagens de escalonamento tornou possível estudar aspectos relevantes na adaptação de aplicações em ambientes de alto desempenho, mais especificamente, aglomerados de computadores (clusters).
Apesar de uma completa avaliação das diferenças entre o shuffle e o slice fugir do escopo desse trabalho, discutiremos a seguir as principais diferenças entre as versões paralelas desses algoritmos utilizando os casos de teste propostos no capítulo 4.
Comparação entre Shuffle e Slice Para comparar os resultados obtidos com shuffle e slice são mostrados dois gráficos de tempo de execução.
Esses gráficos relacionam o número de processadores utilizados (eixo x) e o tempo de execução obtido (eixo y) para realizar uma iteração da MVD.
No caso de o algoritmo slice os tempos de pré-processamento, apresentados na tabela 3, não são considerados, pois esses são referentes a uma parte do cálculo que é realizada somente uma vez e.
Portanto, ao longo centenas ou milhares de iterações o tempo de pré-processamento não é impactante no tempo total de execução do mesmo.
Os melhores resultados obtidos com shuffle foram utilizando a abordagem de escalonamento que considera o custo das tarefas.
Já com o slice, os melhores resultados apresentados foram utilizando a abordagem de escalonamento que considera cada fator como uma tarefa.
Assim, compara- se os resultados obtidos com cada algoritmo utilizando essas duas abordagens.
Misto. Em a figura 19, os resultados em tempo de execução para os dois algoritmos utilizando o caso de teste SC são apresentados.
Note que a escala utilizada nos gráficos é diferente.
Isso porque o tempo de execução do algoritmo slice é significativamente menor que o do shuffle.
Entretanto, ambos algoritmos apresentam um comportamento bastante escalável.
Denso A. A figura 20 mostra os resultados em tempo de execução com o caso de teste Misto.
Em esse caso, as mesmas afirmações feitas anteriormente se aplicam pois, o comportamento das curvas é bastante semelhante.
Ainda, os tempos de execução obtidos com o slice são bem inferiores aos obtidos utilizando o shuffle e por isso as escalas dos gráficos são diferentes.
Faz- se importante ressaltar que o número de processadores utilizados com o slice, nesse caso de teste, é superior à quantidade de termos.
Como o número de termos é um fator limitante do número de processadores que podem ser utilizados, a escalabilidade do shuffle é sempre limitada por esse fator.
Por outro lado, o slice pode escalar num número bem maior de processadores.
Denso B. Os gráficos da figura 21, que mostram os resultados para o teste Denso A, apresentam as mesmas características já mencionadas.
Entretanto, nos gráficos com o caso de teste Denso B (figura 22), em alguns pontos é possível observar que os resultados obtidos com o shuffle são melhores.
Isso ocorre nas execuções com 4, 8 e 16 processadores.
Não por coincidência, esses são os casos cujo número de processadores é múltiplo da quantidade de termos.
Em princípio, outro fator que contribui para esse comportamento é a semelhança do tempo seqüencial de execução do shuffle e do slice nesse caso de teste.
Trabalhos Futuros Apesar de o slice ter apresentado melhores resultados que o shuffle na maioria dos casos de teste, estudos recentes apontam que a solução ideal para realizar a MVD é uma abordagem híbrida, que misture aspectos de ambos algoritmos.
Em esse sentido, a paralelização deste algoritmo híbrido poderá explorar aspectos das abordagens de escalonamento aqui apresentadas.
O estudo do impacto de paralelização com relação a a quantidade de memória utilizada é também outra possível continuidade ao trabalho aqui apresentado.
Principalmente em modelos que apresentam um elevado número de estados, tornando a memória um fator limitante.
Agrupar AUNFs para otimizar o volume de dados transmitidos a cada iteração é outro possível assunto a ser abordado em futuras investigações.
Entretanto, como o número de fatores tipicamente é bastante elevado, considerar as características de cada fator um- aum pode levar em altos custos.
O estudo de como esse agrupamento pode ser realizado mantendo um compromisso entre tempo de escalonamento e a redução na comunicação torna- se necessário.
Consideraçõres Finais O objetivo desse trabalho foi apresentar como técnicas de alto desempenho podem ser empregadas para acelerar a análise de modelos analíticos estruturados.
Em esse contexto, foi contemplado o uso de MPI, uma ferramenta popular para o desenvolvimento em aglomerados de computadores.
A escolha desse tipo de plataforma, foi motivada principalmente por o baixo custo envolvido em sua construção.
Estabelecendo um compromisso entre custo e benefício que se adapta de maneira a acompanhar a evoluça~ o rápida que ocorre com os micro-processadores.
A principal impressão deixada após a análise dos resultados é que a versão paralela do algoritmo slice apresenta melhores resultados que o shuffle.
No entanto, uma análise´ ltimo aprofundada mostra que isso não é sempre verdade.
Os resultados obtidos com o u caso de teste (Denso B) para o shuffle, por exemplo, em alguns casos superam os resultados do slice.
Também é importante levar em consideração que o slice necessita de uma etapa de pré-processamento.
Logo, uma solução híbrida, que explore características de ambos os algoritmos aparentemente seja mais eficiente.
Em geral, o trabalho realizado até o momento apresentou resultados positivos.
Essa afirmação é atestada por os bons desempenhos obtidos nos testes realizados.
Mesmo quando os tempos seqüenciais dos algoritmos não apresentavam um custo considerável para a realização da MVD estes mostraram- se adaptáveis ao tipo de arquitetura utilizada.
Reforçando as escolhas efetuadas ao longo de o trabalho.
A principal contribuição do presente trabalho é apontar diretivas para o desenvolvimento em aglomerados de computadores.
Mesmo em diferentes formalismos, os algoritmos propostos podem ser utilizados.
Entretanto, o trabalho iniciado aqui não se apresenta completamente esgotado, restando assuntos a serem abordados em trabalhos futuros.
