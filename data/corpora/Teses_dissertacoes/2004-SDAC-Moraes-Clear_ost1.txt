A evolução tecnológica tem permitido aumentar a complexidade dos projetos, e por conseqüência o número de núcleos de propriedade intelectual num mesmo circuito integrado.
Este acréscimo de núcleos conduz à pesquisa de novas estruturas de interconexão intra-chip que devem atender as necessidades de comunicação dos futuros SoCs:
Escalabilidade, reusabilidade e paralelismo.
Uma destas estruturas de interconexão são as redes intra-chip, ou NoCs.
As redes intrachip utilizam conceitos de redes de interconexão de computadores paralelos e redes de computadores.
Para auxiliar no projeto de SoCs a reusabilidade das estruturas de interconexão e dos módulos de hardware é indispensável.
Para aumentar a reusabilidade de projeto, as interfaces externas dos núcleos e as interfaces das estruturas de interconexão devem ser padronizadas.
Em este cenário, o presente trabalho concentra- se no desenvolvimento de redes intra-chip parametrizáveis com interface padrão OCP para síntese em hardware.
A maior contribuição desse trabalho consiste na unificação destas frentes de estudo, NoCs e interfaces padrão, através do desenvolvimento da ferramenta Maia, a qual automatiza a geração de redes intra-chip com interface padrão OCP.
Palavras-chave: Redes intra-chip, interface de rede, protocolo OCP.
O aumento do número de transistores e da freqüência de operação, o curto tempo de projeto e a redução do ciclo de vida dos produtos eletrônicos caracterizam o cenário atual da indústria de semicondutores.
Em 1980, a maioria dos circuitos integrados (CIs) ditos complexos era composta por dezenas de milhares de transistores.
Atualmente, é possível encontrar CIs que contenham dezenas de milhões de transistores.
Contudo, estima- se que até 2012 existam CIs contendo 4 bilhões de transistores, operando a uma freqüência de 10 GHz.
Esse avanço tecnológico permite implementar sistemas computacionais completos num único Ci, SoCs podem ser compostos por processadores, memórias, módulos dedicados em hardware para realização de funções específicas, módulos de software e inclusive tecnologias mais recentes como MEMs (do inglês, Micro-Electro-Mechanical Systems) integrados no mesmo Ci.
A heterogeneidade apresentada por esses sistemas, ou seja, a possibilidade de combinar diferentes tecnologias no mesmo Ci, tem sido aproveitada em diversos setores da indústria.
Tal fato é evidenciado por o sucesso de produtos eletrônicos como telefones celulares, PDAs, aparelhos de jogos eletrônicos, aparelhos de DVDs, máquinas fotográficas digitais (integração de sensores ópticos com lógica digital e analógica), entre outros produtos.
Porém, combinar diferentes tecnologias no mesmo Ci é um processo difícil, que implica o aumento de tempo e custo de projeto de novos produtos.
Por outro lado, existe a necessidade da diminuição no tempo de lançamento do produto no mercado (time- to-- market), o que vêm a contribuir para o domínio de mercado e aumento dos lucros.
Volume de Vendas Ambos os fatores, evolução tecnológica e o curto time- to-- market possuem grande efeito na diminuição do ciclo de vida dos produtos.
Segundo Bergamaschi, a diminuição do ciclo de vida dos produtos pode ser evidenciada por o tempo que um dado produto leva para ter o seu volume de vendas igual a 1 milhão de unidades, como ilustrado na Figura 1.
Um milhão de unidades TV a Cores Celular TV a cabo TV preto e branco Anos após introdução do produto no mercado A Figura acima ilustra a diminuição do ciclo de vida de produtos eletrônicos frente a o volume de vendas após a introdução dos mesmos ao mercado.
A mesma figura mostra que um televisor a cores levou aproximadamente 10 anos para vender 1 milhão de unidades, enquanto, que num ano vendeu- se o mesmo volume de aparelhos de DVD.
Sendo assim, é possível constatar que existe uma grande pressão em relação a a diminuição do tempo de desenvolvimento e de lançamento de um produto ao mercado antes que o mesmo já esteja ultrapassado tecnologicamente.
Dentro deste cenário, as companhias que projetam e vendem SoCs priorizam em seus projetos a utilização de núcleos de propriedade intelectual, ou simplesmente núcleos (do inglês, IP cores), a fim de aumentar a produtividade, minimizando o tempo de desenvolvimento, e conseqüentemente, o time- to-- market de seus produtos.
Apesar de as vantagens inerentes à utilização de núcleos no projeto de SoCs, identificam- se quatro grandes problemas que precisam ser resolvidos para facilitar tal prática.
Esses problemas são:
Integração dos núcleos entre si para compor o SoC;
Escolha das linguagens para descrever os núcleos e o SoC;
Proteção à propriedade intelectual;
Teste dos núcleos e do SoC.
O escopo do presente trabalho de mestrado limita- se ao primeiro desafio, ou seja, a integração de núcleos IPs em SoCs.
O problema de integração de núcleos pode ser abordado a partir de duas questões:
As estruturas de interconexão utilizadas atualmente para integrar núcleos suportarão os requisitos de desempenho e de escalabilidade dos futuros SoCs?
Como integrar núcleos com interfaces externas diferentes à estrutura de interconexão adotada por o SoC alvo?
Duas estruturas de interconexão são usualmente utilizadas para interconectar núcleos num SoC:
Fios ponto-a-ponto dedicados e barramentos, simples ou hierárquicos.
Diversos autores prevêem que as atuais estruturas de interconexão tornarão- se- fatores limitantes para grandes projetos, em função de o aumento da complexidade dos sistemas e do aumento dos requisitos de largura de banda.
Uma possível solução para a integração de núcleos são as redes intra-chip abordagem, um SoC pode ser visto como uma micro-rede de componentes, onde a rede é o meio responsável por a comunicação entre os componentes do sistema, ou seja, os núcleos.
Esta forma de interconexão é discutida no Capítulo 2.
Núcleos são desenvolvidos para um protocolo de comunicação, proprietário ou padrão.
Durante o desenvolvimento de um dado SoC, os núcleos selecionados para compor o mesmo podem ser provenientes de diferentes provedores, os quais podem adotar protocolos distintos daquele associado à estrutura de interconexão que está sendo utilizado no projeto do SoC.
Logo, para inserir tais núcleos no SoC, existe a necessidade de adição de lógica de cola (do inglês, glue logic) que permite a comunicação entre o núcleo e o restante do circuito.
Essa lógica é denominada invólucro (do inglês, wrapper) ou adaptador.
A necessidade de adaptação de núcleos reduz a reusabilidade do mesmo, e aumenta o tempo de projeto do SoC.
A Figura 2, ilustra o problema de interconectar núcleos com interfaces diferentes à estrutura de interconexão de um SoC.
Uma alternativa para evitar a inserção de lógica de cola é padronizar a (s) interface (s) entre o (s) núcleos e a estrutura de interconexão adotada.
Dois padrões de interfaces bastantes difundidos são o VCI da VSIA (Virtual Socket Interface Alliance) e o OCP da Sonics.
Esta abordagem não muda a forma de desenvolver núcleos, pois estes continuam sendo desenvolvidos para um dado protocolo.
O que muda é que esse protocolo é de domínio público, e aceito por a indústria como um padrão, como foi o padrão PCI para os fabricantes de microcomputadores.
Assim, a reusabilidade dos núcleos é maior e o tempo de projeto diminui, pois a integração de núcleos passa a ser um processo simplificado.
O tema de utilização de interfaces padrão é discutido no Capítulo 3 deste trabalho.
O projeto concorrente de hardware e software é uma importante característica dos SoCs.
O procedimento usual para o projeto destes sistemas é utilizar uma dada linguagem para descrever os módulos de hardware e outra linguagem para descrever os procedimentos de software.
Linguagens de descrição de hardware, tais como Verilog e VHDL, têm como características comuns hierarquia (descrição estrutural com utilização de componentes), concorrência entre processos e temporização.
Linguagens para descrição de software, como C ou C+, são baseadas num modelo de execução seqüencial, adaptadas para a execução em processadores de propósito geral.
Estas linguagens para descrição de software geralmente não têm suporte para modelar concorrência e temporização.
Utilizar duas linguagens distintas, com modelos de computação também distintos, para a modelagem do SoC traz as seguintes desvantagens:
A partição do sistema já está definida, não havendo flexibilidade para mover núcleos de hardware para software e vice-versa;
Esta rigidez impede uma exploração do espaço de soluções possíveis para o sistema em desenvolvimento;
A validação do sistema requer técnicas de co-simulação, além de ser efetuada num nível de abstração muito próximo de a implementação final (nível de ciclo), o que pode tornar a validação uma tarefa muito custosa em termos de tempo de CPU.
Em função de estas características é desejável que o projeto de SoC seja feito utilizando uma única linguagem, que dê suporte aos modelos de computação utilizados tanto para modelagem de hardware quanto para modelagem de software.
O uso de uma única linguagem traz como benefícios a possível exploração do espaço de soluções do projeto e um processo de validação simplificado em relação a o processo baseado em co-simulação.
Exemplos de linguagens utilizadas para modelagem concorrente de hardware e software são SystemC, SystemVerilog e SpecC.
Estas linguagens são derivadas de linguagens de descrição de software, acrescentando- se bibliotecas que simulam as características de paralelismo e temporização.
A descrição de sistemas computacionais através destas linguagens permite também aumentar o nível de abstração de projeto.
A elevação dos níveis de abstração de projeto para os chamados níveis sistêmicos permite que detalhes de baixo nível sejam abstraídos, tornando mais fácil descrever a funcionalidade de cada núcleo e suas interconexões.
A dissertação do aluno Edson Ifarraguirre Moreno, desenvolvida em paralelo com este trabalho, tem por foco a modelagem e avaliação de desempenho de redes intra-chip no nível de abstração transacional TLM (do inglês, Transaction Level Modeling), utilizando a linguagem SystemC.
Seu trabalho destaca as vantagens acima citadas, exploração do espaço de soluções e redução do tempo de validação.
Apesar de as vantagens da utilização de SystemC, não há ainda ferramentas para síntese automática do nível TLM para o nível RTL (do inglês, Register Transfer Level), ponto de partida para a síntese de hardware.
Não é objetivo deste trabalho utilizar níveis abstratos de descrição.
Toda a modelagem dos sistemas será feita em VHDL, no nível RTL de abstração.
Como um provedor de núcleos (hardware ou software) pode fornecer a um projetista um dado núcleo, sem entretanto fornecer detalhes que comprometam a sua propriedade intelectual?
Este é um desafio de solução complexa, pois o projetista do núcleo deseja manter a implementação deste fechada, pois isto representa o seu conhecimento -- propriedade intelectual.
O usuário do núcleo deseja informações deste, pois necessita avaliar parâmetros como área, velocidade, potência e testabilidade para decidir se irá comprar ou não o mesmo e utilizar- lo em seu projeto.
A compra de um dado núcleo pode representar investimento na ordem de milhares de dólares.
Diversas técnicas já foram propostas para proteção à propriedade intelectual de núcleos, como utilização de descrições de hardware criptografadas, simulação remota (o usuário do núcleo instancia o núcleo desejado, porém a simulação do mesmo ocorre no servidor do provedor do núcleo) e modelos comportamentais dos núcleos.
A terceira alternativa, modelos comportamentais dos núcleos, mostra- se hoje a mais promissora, em função de o avanço das linguagens sistêmicas, como SystemC.
Caso a descrição SystemC TLM forneça uma estimativa precisa dos parâmetros do núcleo, a integração deste ao sistema é feita neste nível de abstração, permitindo ao projetista definir como será o seu sistema.
Uma vez definido quais núcleos serão utilizados, o projetista adquire a descrição RTL do núcleo TLM utilizado para modelagem do sistema.
Este processo traz os seguintes benefícios:
Efetiva proteção à propriedade intelectual, uma vez que a estimativa dos parâmetros do núcleo é feita para um processo de síntese desconhecido do projetista do SoC;
Redução do tempo de projeto, através do reuso de núcleos.
Em a maioria dos casos, exceto para núcleos descritos na forma de código fonte (soft cores), os usuários de núcleos possuem pouco conhecimento do conteúdo interno dos mesmos, tratando- os como caixa preta.
O usuário tem acesso apenas à fronteira externa dos núcleos instanciados.
Os desenvolvedores dos núcleos definem o método de teste, sem o conhecimento de onde o núcleo será utilizado.
Como resultado, o projetista do núcleo pode ou não fornecer um método de teste com a qualidade adequada.
Se a cobertura é muito fraca, a qualidade do sistema pode ser comprometida.
Por outro lado, se for muito alta, o custo de teste pode aumentar (tempo e requisitos de memória).
Visando simplificar a interface entre os provedores de núcleos, que definem o teste individual dos mesmos, e os projetistas de SoCs, que utilizam os núcleos e devem testar o sistema completo, a proposta de padrão IEEE P1500 define regras para o teste de SoCs.
A proposta de padrão P1500 está focada na padronização da interface entre usuário e provedores de núcleos.
Esta padronização atende:
Uma linguagem padrão capaz de expressar todas as informações relacionadas a teste que devem ser transferidas para o usuário do núcleo;
Uma lógica envoltória de teste padrão configurável, que facilite a integração de núcleos no sistema.
P1500 não cobre:
Método de teste interno dos núcleos;
Integração do teste do sistema;
Otimizações do teste do sistema;
Mecanismos de acesso ao teste;
Fonte e receptor de teste.
Estes pontos não cobertos são responsabilidade dos provedores e do usuário de núcleos, e sua padronização não é viável devido a as diferentes restrições dos núcleos e sistemas.
O tema de pesquisa em teste de SoCs está contemplado na dissertação do aluno Alexandre Amory, trabalho este que esta sendo continuado em seu doutorado.
As estruturas de interconexão atualmente utilizadas podem se tornar o gargalo no projeto dos futuros SoCs, onde dezenas ou centenas de núcleos comporão um determinado sistema computacional.
De essa forma, a pesquisa em redes intra-chip mostra- se relevante tanto para a comunidade acadêmica quanto para a indústria.
A pesquisa e o desenvolvimento de técnicas para a integração de núcleos de forma &quot;plugand-play «(possibilidade de conectar núcleos de hardware distintos e obter funcionamento correto com o restante do sistema sem adição de lógica adicional), tornando a estrutura de interconexão transparente para o projetista, representa a principal motivação para a realização desse trabalho.
O objetivo principal deste trabalho é dominar a tecnologia de interconexão de núcleos através da utilização de redes intra-chip, e a utilização de interfaces padronizadas para a comunicação entre os núcleos.
A contribuição maior do presente trabalho, resultado deste objetivo, é o desenvolvimento de redes-IP1 parametrizáveis com interface padrão OCP para síntese em hardware.
Os objetivos específicos deste trabalho são:
Estender a rede Hermes para as topologias anel, torus e torus dobrado.
Reduzir a utilização de área da rede através da remoção dos buffers2 não utilizados.
Esta otimização é importante, dado que a fila é o componente que mais consome área na chave.
Desenvolver as interfaces de rede OCP (mestre, escravo, mestre-escravo) para a rede Hermes.
Desenvolver uma ferramenta para geração da rede intra-chip Hermes, com interface OCP, em função de os parâmetros do projetista.
Além de a rede-IP, a ferramenta deve gerar os arquivos de configuração utilizados por a ferramenta CoreCreator.
Apresentar pelo menos um estudo de caso de desenvolvimento de SoC com a rede HERMESOCP.
Prototipar o estudo de caso em FPGA.
O termo rede-IP refere- se a uma rede intra-chip como núcleo IP.
Em o contexto deste trabalho, será utilizado o termo fila como sinônimo.
Este trabalho está organizado como segue.
Em o Capítulo 2 são discutidos conceitos de SoCs, com ênfase às estruturas de interconexão.
Em este Capítulo são apresentados conceitos e terminologias de redes intra-chip.
Este Capítulo também inclui uma revisão do estado-da-arte de redes intra-chip.
Finalmente, o Capítulo 7 apresenta as considerações finais sobre este trabalho e direções para trabalhos futuros.
Este Capítulo apresenta os conceitos básicos de SoCs e como os núcleos são interconectados entre si no mesmo.
A forma de interconexão por redes intra-chip é estudada em maior profundidade pois esta atende aos requisitos de desempenho e escalabilidade dos futuros SoCs.
Ainda nesse Capítulo apresenta- se o estado da arte em redes intra-chip e considerações sobre a integração de núcleos a essa estrutura de interconexão.
Como descrito anteriormente, o mercado de semicondutores é caracterizado por produtos eletrônicos cada vez mais complexos, com reduzido tempo de vida.
Com isso, tornou- se comum desenvolver SoCs a partir de núcleos heterogêneos.
A agência de pesquisa In-Stars estima que o mercado mundial de SoCs deve crescer de 20 bilhões no ano de 2000 para 60 bilhões em 2004, ou seja 40% do mercado, representando um crescimento aproximado de 31% ao ano.
A Associação das Indústrias de Semicondutores estima que em 2005 90% da área dos circuitos integrados seja preenchida por núcleos.
Logo, é possível inferir que a produção de SoCs depende da criação e da validação de núcleos que possam ser reutilizados em projetos distintos.
Estima- se que criar um núcleo que possa ser reutilizado por outros projetistas é substancialmente mais difícil (por um fator estimado entre 2 e 5 vezes maior) que desenvolver- lo para um único projeto.
Como ilustrado na Figura 4, um SoC é composto por núcleos não programáveis, processadores e memórias que comunicam- se através de uma estrutura de interconexão e interfaces com o mundo externo.
Núcleo 1 Comunicação entre o núcleo e a estrutura de interconexão Fornecedor B Núcleo n Interface Fornecedor FornecedorA Estrutura de Interconexão Processador Memória SoC A arquitetura acima é composta por núcleos IP.
Estes núcleos podem ser módulos de telecomunicação, processadores DSP (Digital Signal Process), decodificadores de MPEG2 ou MP3, entre outros.
Os núcleos provêm de fornecedores distintos (A, B) e estão integrados a uma estrutura de interconexão que pode ser um barramento ou uma rede intra-chip.
A (s) interface (s) com o mundo externo (I/ O) é (são) utilizada (s) para interconectar periféricos, como:
Porta serial, porta USB ou uma UART (Universal Assynchronous Receiver Transmiter).
Gupta Definem um núcleo como um módulo de hardware pré-projetado e pré-verificado, que pode ser usado na construção de uma aplicação maior ou mais complexa num Ci.
Estes núcleos podem ser classificados em três categorias:
Soft core, firm core e hard core.
Um Soft Core é a descrição de um núcleo numa linguagem de descrição de hardware (e.
g VHDL, Verilog, SystemC).
As principais vantagens apresentadas por um soft core são:
A independência de tecnologia e a flexibilidade.
É possível que o projetista/ usuário modifique o mesmo, visando adequar a funcionalidade deste em prol de o sistema desejado.
Em contrapartida a esta flexibilidade, é responsabilidade do projetista atender às restrições temporais.
Normalmente, os soft cores são acompanhados de scripts de síntese, que guiam o projetista na etapa de concepção.
Um firm core é um netlist que apresenta menos flexibilidade em relação a o soft core e na síntese lógica).
As vantagens em relação a os soft cores são:
Melhor proteção da propriedade intelectual e estimativa de desempenho mais próxima da realidade.
Um hard core é geralmente uma descrição de um layout posicionado e roteado de um ASIC/ FPGA.
Para atingir desempenho, baixo consumo e menor área, estes são otimizados para uma dada tecnologia.
Logo, os hard cores garantem os tempos de propagação do núcleo (timing), além de proverem alta proteção à propriedade intelectual.
Como conseqüência, a flexibilidade é mínima e este é fortemente dependente da tecnologia.
Os núcleos são usualmente interconectados num SoC através de duas estruturas de interconexão:
Fios ponto-a-ponto dedicados e barramentos1, simples ou hierárquicos.
Antes de descrever as estruturas de interconexão citadas acima, torna- se necessário definir alguns conceitos que caracterizam as mesmas.
Paralelismo: Relaciona- se à possibilidade de transferência e/ ou recepção de dados entre dois ou mais pares de núcleos simultaneamente;
Consumo de energia:
Determina a quantidade de energia consumida por um determinado circuito;
Escalabilidade: Refere- se à capacidade de interconectar componentes adicionais à estrutura de interconexão, sem comprometimento significativo no desempenho global do sistema;
Reusabilidade: É a capacidade de utilizar uma dada estrutura de interconexão em projetos distintos.
Essa estrutura deve proporcionar facilidades para que um grande número de núcleos possam trocar informações eficientemente.
Isso, tanto para pares de núcleos como para comunicações concorrentes entre vários pares.
Em a bibliografia é possível encontrar o termo fios globais (do inglês, global wires).
Em a abordagem baseada em fios ponto-a-ponto dedicados (do inglês, dedicated wires), os núcleos são interligados diretamente um ao outro, ou seja, conexão ponto-a-ponto.
O desempenho oferecido por essa estrutura pode ser considerado bom, pois cada comunicação ocorre independentemente das demais.
Este tipo de estrutura de interconexão é eficaz se cada núcleo tem que se comunicar com um número pequeno de núcleos.
Caso pretenda- se interligar um núcleo a vários outros, o número de fios dedicados aumenta proporcionalmente ao número de núcleos, o que pode gerar o congestionamento de fios em volta do mesmo.
Tal característica pode ser considerada uma limitação, à medida que projeta- se SoCs com dezenas a centenas de núcleos.
Outro fator limitante está no fato que o projeto deste tipo de estrutura é específico e, portanto, a reusabilidade é limitada.
A Figura 5 ilustra a abordagem de interconexão descrita acima.
Uma estrutura de interconexão mais reutilizável é a baseada em barramentos compartilhados (do inglês, shared data bus).
Além de a reusabilidade, a baixa área de silício e a baixa latência contribuem para que esta abordagem seja a mais utilizada para interconexão de núcleos nos SoCs atuais.
Um barramento consiste num conjunto de fios que conectam diferentes núcleos do SoC, e sobre o qual dados são transmitidos e recebidos.
Estes núcleos podem ser classificados como mestres e/ ou escravos do barramento.
Um núcleo mestre é uma unidade que controla a transferência num barramento, ou seja, pode solicitar a transmissão ou a recepção dos dados através do barramento.
Por outro lado, um componente escravo é a unidade que apenas responde às solicitações desses mestres.
Como exemplo, pode- se citar um microprocessador, atuando como mestre, e uma memória que efetua o papel de escravo do barramento.
As informações são lidas ou escritas de a/ na memória a partir de os sinais gerados por o microprocessador.
A maioria dos barramentos define um método de arbitragem responsável por o controle de acesso dos núcleos mestres a si.
De entre os vários métodos citam- se o centralizado e o distribuído.
Em o método centralizado, um dispositivo denominado como árbitro ou controlador de barramento é responsável por a atribuição de acesso ao barramento.
Em este caso, existem sinais de requisição e de permissão.
Quando o árbitro percebe uma requisição de direito de acesso, ele gera um sinal de permissão, quando for possível, ao mestre que solicitou o acesso ao barramento.
Em o método de arbitragem descentralizado/ distribuído, não há um árbitro.
Uma das formas utilizadas para descentralizar a arbitragem é de delegar o monitoramento das linhas de requisição aos próprios núcleos do barramento.
De esta maneira, cada núcleo sabe sua prioridade na ordem destas requisições e se podem ou não utilizar o barramento.
A Figura 6, ilustra uma estrutura de interconexão baseada em barramento.
Árbitro Barramento Núcleos A figura acima ilustra uma arquitetura de barramento composta por um único barramento (canal de comunicação) compartilhado entre todos os núcleos sendo estes mestres e/ ou escravos.
Esta arquitetura possui um método de arbitragem centralizado, ou seja, existe um árbitro responsável por o controle de acesso ao barramento.
Apesar de barramentos serem reutilizáveis, pode- se enumerar 3 desvantagens desta forma de interconexão:
Ausência de paralelismo;
Baixa escalabilidade alto consumo de energia.
O paralelismo inexiste em barramentos simples, pois apenas uma transação de comunicação é permitida por vez, dado que todos os núcleos compartilham o mesmo canal de comunicação.
Barramentos hierárquicos podem aumentar o número de transações simultâneas, porém de uma forma limitada (duas a três transações simultâneas).
A escalabilidade é limitada a dezenas de núcleos, segundo.
O consumo de energia é elevado devido a a existência de fios longos.
O acréscimo de núcleos ao barramento aumenta a capacitância total do sistema, o que acaba reduzindo o desempenho elétrico.
Entre as arquiteturas de barramento intra-chip encontradas na literatura, destacam- se:
AMBA da ARM, Avalon da Altera, CoreConnect da IBM.
Geralmente, estas arquiteturas de barramento estão vinculadas à arquitetura de um processador, tal como o AMBA vinculado ao processador ARM, o CoreConnect vinculado ao processador PowerPC e o Avalon vinculado ao processador Nios.
Diversos autores prevêem que as estruturas de interconexão citadas acima tornarão- se- fatores limitantes para grandes projetos, em função de o aumento da complexidade dos sistemas e do aumento dos requisitos de largura de banda.
Uma possível solução para a integração de núcleos são as redes intra-chip.
Como descrito em, as redes intra-chip estão emergindo como uma possível solução para os problemas associados às estruturas de interconexão, devido a algumas características como:
Escalabilidade da largura de banda se comparada à arquiteturas de barramento;
Reusabilidade; Confiabilidade;
Eficiência em termos de consumo de energia.
Redes intra-chip compartilham muitos conceitos com redes de interconexão de computadores paralelos e de redes locais.
Existem duas diferenças básicas entre as abordagens de interconexão citadas acima:
O número de componentes e a distância entre si.
O número de núcleos em SoCs é inferior ao número de componentes em redes locais e a distância entre os núcleos é muito inferior aos componentes de uma rede local.
Estas diferenças conduzem ao desenvolvimento de protocolos particulares às redes intra-chip.
Uma rede pode ser dividida em duas partes:
Os serviços e o sistema de comunicação.
Rijpkema, descrevem alguns serviços que devem ser providos por uma rede intrachip:
Garantir a integridade de dados, ou seja, entregar estes sem serem corrompidos;
Garantir que nenhum dado vai ser perdido por a rede;
Garantir a recepção ordenada dos dados enviados;
Garantia de throughput, referente a a quantidade de dados transferidos por unidade de tempo, garantia de latência, referente a o tempo que uma unidade de dados demora para ser transferida do seu fonte ao seu destino.
Estes serviços pode ser classificados em:
&quot;serviços garantidos «(GT -- guaranteed throughput) ou serviços &quot;melhor-esforço «(Be -- best-effort services).
Serviços GT requerem reserva de recursos para o pior caso, por exemplo garantia de throughput, o que pode vir a ser custoso em termos de recursos de hardware (área).
Os serviços Be não alocam recursos específicos, sendo mais simples de utilizar.
Uma desvantagem das redes Be é a ausência de garantia de limites temporais, como latência e throughput.
Um sistema de comunicação deve proporcionar a transferência de informações de uma origem à um destino.
Como definido por Benini e Guerrier, a comunicação entre os elementos de uma rede intra-chip é baseada na transmissão de mensagem.
Uma mensagem, geralmente, é composta por:
Cabeçalho (header), (ii) carga útil (payload), contendo os dados da mensagem;
Terminador (trailer ou sufixo), incluindo informações utilizadas para a detecção de erros e indicar o término da mensagem.
Geralmente, para transmissão divide- se a mensagem em pacotes.
Um pacote é um bloco de dados que contém detalhes inerentes ao roteamento e ao seqüenciamento dos dados, mantendo uma estrutura semelhante à de uma mensagem.
Um sistema de comunicação deve permitir a troca de mensagens entre todos os núcleos conectados a estrutura da rede.
A estrutura de uma rede intra-chip é basicamente um conjunto de chaves (do inglês, switches) conectadas entre si por canais de comunicação (meio por o qual os dados são enviados).
A forma em a qual as chaves estão conectadas entre si, e os núcleos conectados às chaves, define a topologia da rede.
Uma vez que a chave é o elemento principal da rede intrachip, seu impacto na área final do SoC deve ser minimizado.
Um dos fatores que mais influenciam no consumo de área são as filas para armazenamento temporário de dados.
Logo, ao projetar uma chave deve existir a preocupação em termos de consumo de área e a estratégia de bufferização a ser adotada, já que este fator afeta diretamente no desempenho da rede.
Uma chave pode ser definida como um dispositivo que conecta um número de canais de entrada a um número de canais de saída.
Em outras palavras, uma chave tem a funcionalidade de transferir informações de uma de suas portas de entrada para uma de suas portas de saída.
O intervalo de tempo entre a entrada e a saída de uma informação da chave é denominado de atraso de chaveamento (do inglês, switch-- delay).
Geralmente, a estrutura de uma chave consiste de um módulo de controle de chaveamento, roteamento interno, e buffers de entrada e/ ou de saída.
A estrutura de uma chave genérica é ilustrada na Figura 7.
Buffers de entrada Buffers de saída Controle de chaveamento Uma chave pode possuir buffers para receber dados e buffers para armazenar dados antes de enviar- los para uma porta de saída.
Deve- se notar que é possível projetar chaves que incluam buffers de entrada e/ ou de saída.
Além de os buffers, a chave ilustrada acima é composta por um módulo de controle do chaveamento e uma estrutura de interconexão interna, por exemplo, crossbar.
Topologias de Rede A topologia da rede consiste na organização da mesma sob a forma de um grafo, em o qual as chaves são os vértices deste e os canais de comunicação os arcos.
Em função de as ligações entre as chaves, uma topologia de rede pode ser classificada como estática ou dinâmica.
Se as chaves estão conectadas através de ligações fixas, de forma que entre cada duas chaves exista uma conexão dedicada, a rede de interconexão é dita estática, ou seja, ponto-a-ponto.
Citam- se como exemplos de topologias estáticas:
Estrela, anel, malha, torus bidimensional;
Hipercubo de grau N. Algumas dessas topologias são ilustradas na Figura 8.
Em a interconexão de componentes com redes dinâmicas não existe uma topologia fixa que defina o padrão de interconexão da mesma.
Quando uma conexão entre dois pontos se faz necessária, a rede de interconexão se adapta dinamicamente para permitir a transferência dos dados.
De entre as topologias de redes dinâmicas destacam- se:
Matriz de chaveamento (crossbar), permite a conexão entre dois núcleos quaisquer, desde que estes não se encontrem já ocupados;
Redes multinível, baseiam- se na ligação de pequenas matrizes de chaveamento (normalmente de tamanho 2 x 2) em vários níveis consecutivos e conectadas de forma a reduzir a probabilidade de bloqueios entre níveis.
A Figura 9 ilustra uma matriz de chaveamento 4 x 4.
A matriz de chaveamento é a topologia de menor latência e melhor desempenho, porém apresenta um custo de implementação proporcional ao quadrado do número de núcleos conectados.
Cabe ao projetista analisar qual de entre estas topologias adapta- se melhor a sua aplicação.
Para isso o mesmo deve considerar fatores como:
Relação custo/ desempenho;
Números de núcleos que se pretende interligar à rede;
Grau da chave, ou seja, quantas portas de entrada e saída cada chave possui;
Escalabilidade, confiabilidade, aplicação a que a rede se destina.
Para garantir a transferência de mensagem entre os núcleos, torna- se necessário impedir que situações como deadlock, livelock e starvation venham a ocorrer.
Deadlock é definido como uma dependência cíclica entre as solicitações de acesso a recursos de comunicação e de armazenamento.
Livelock ocorre quando pacotes ficam circulando por a rede sem se aproximar dos seus respectivos destinos.
Starvation ocorre quando um pacote armazenado num buffer solicita um canal de saída, sendo que este permanece bloqueado porque o canal de saída é sempre alocado para outro solicitante de mais alta prioridade.
A escolha da forma em a qual pacotes são transferidos da entrada de uma chave para um de seus canais de saída poderá evitar os fenômenos descritos no parágrafo acima.
Dois métodos de transferência de pacotes são utilizados:
Chaveamento de circuito e o chaveamento de pacotes.
Chaveamento de circuitos (do inglês, circuit switching):
Inicialmente é estabelecido um caminho, denominado de conexão, do núcleo origem (fonte) até o núcleo destino, e logo após são enviados todos os pacotes.
A Figura 10 ilustra esse método.
As figuras acima (a, b) ilustram o modo de transferência de pacotes entre núcleos de uma rede, baseado no método de chaveamento de circuitos.
Em um primeiro momento (figura a), é estabelecido o caminho de comunicação entre a chave fonte (F) e a chave destino (D), ou seja, determinam- se quais chaves receberão e enviarão pacotes até o seu devido destino.
Após o estabelecimento do caminho de comunicação, são enviados os pacotes (figura b).
Chaveamento de pacotes (packet switching):
Este método diferencia- se do chaveamento de circuitos por o fato de que cada pacote informa a cada chave qual a direção que estes irão seguir na rede, ou seja, não existe um caminho pré-definido.
A Figura 11 ilustra esse método.
As figuras acima (a, b, c) ilustram o modo de transferência de pacotes baseado no método de chaveamento de pacotes.
Em este método o estabelecimento do caminho ocorre dinamicamente, ou seja, o pacote pode percorrer caminhos alternativos até chegar ao seu destino.
Em um primeiro momento (a), a chave fonte envia o pacote para seu vizinho, que a partir de as informações sobre a direção que o pacote deve seguir, enviará o mesmo para a próxima chave (b) que fará o mesmo procedimento.
Este procedimento ocorre até que o pacote chegue ao seu destino (c).
O chaveamento de circuitos ao estabelecer um caminho de comunicação para o envio de uma dada mensagem pode subtilizar os canais reservados (período sem envio de pacotes), desperdiçando largura de banda.
Já no chaveamento de pacotes alocam- se apenas os canais necessários para transmissão dos pacotes, permitindo assim que mensagens diferentes compartilhem os demais canais da rede.
Em esta abordagem, o custo para estabelecer o caminho de comunicação não existe, porém adiciona- se um custo de roteamento para cada chave visitada.
A possibilidade de estabelecer caminhos dinamicamente permite que algoritmos de roteamento reajam mais rapidamente ao congestionamento1 e a eventuais falhas na rede, optando por caminhos alternativos.
O emprego do chaveamento de pacotes implica o uso de modos de chaveamento.
Entre os utilizados citam- se store- and-- forward, virtual cut-through e o wormhole, definidos a seguir.
Em o modo store- and-- forward (armazenar e passar) um pacote tem que ser completamente armazenado num buffer antes de ser enviado para a próxima chave.
Este modo gera latência na entrega dos pacotes e pode exigir grande armazenamento nas chaves, as quais devem ser dimensionadas para o tamanho máximo do pacote.
Em o virtual cut-through, uma chave pode enviar um pacote a partir de o momento que a próxima chave garanta poder receber todo o pacote.
Sendo assim, torna- se necessário um buffer para armazenar o pacote completamente, se necessário, como no modo anterior.
A vantagem deste modo em relação a o store- and-- forward está na diminuição da latência de comunicação.
O modo wormhole é uma variação do virtual cut-through com menor utilização de buffers.
Em este modo, os pacotes são quebrados e transmitidos entre as chaves em unidades menores denominadas flits2.
Uma desvantagem associada a este modo é que apenas o flit cabeçalho contém informações sobre o roteamento.
Logo, os demais flits que compõem o pacote devem seguir o mesmo caminho reservado para o cabeçalho.
Se um cabeçalho não puder avançar na Ocorre quando pacotes ficam esperando por a liberação de recursos que estão alocados.
Unidade de controle de fluxo (do inglês, flow control digit ou flow control unit).
Rede em função de a contenção de recursos, todos os flits restantes são bloqueados ao longo de o caminho, até que o caminho seja liberado.
Enquanto os modos de chaveamento definem como um pacote movimenta- se através das chaves, o algoritmo de roteamento define o caminho a ser utilizado por um pacote a partir de o seu envio até o seu destino.
É importante salientar que o algoritmo de roteamento é dependente da topologia adotada.
Dependendo da onde as decisões são tomadas pode- se classificar o roteamento em fonte e distribuído.
Em o roteamento fonte todo o caminho é decidido por a chave origem.
Já no roteamento distribuído a rota do pacote é definida a cada chave visitada.
Com isto, torna- se possível reduzir o tamanho do cabeçalho comparado com o roteamento fonte, que deve conter toda a rota no cabeçalho do pacote.
Em função de o processo de seleção do caminho, o roteamento pode ser classificado como determinístico ou adaptativo.
Em o roteamento determinístico o caminho é único, em função de os endereços das chaves origem e destino.
O roteamento adaptativo prove vários caminhos possíveis da chave fonte para a chave destino.
Em esta abordagem, o caminho de um pacote é estabelecido dependendo das condições da rede, como tráfego e congestionamento de canais.
O roteamento adaptativo pode ser ainda classificado como parcialmente e totalmente adaptativo.
Em o algoritmo parcialmente adaptativo utiliza- se um subconjunto dos caminhos disponíveis entre a origem e o destino, enquanto que no totalmente adaptativo é possível rotear um pacote através de todos os caminhos físicos.
O algoritmo de roteamento também pode ser mínimo ou não-mínimo.
Em o primeiro algoritmo, o pacote deve aproximar- se do destino após cada chave visitada.
Em o algoritmo nãomínimo, um pacote pode ser enviado para um caminho mais longo entre a chave origem e o destino.
Toda rede intra-chip possui um protocolo de comunicação que determina como um núcleo é conectado à rede, assim como, uma informação flui de sua fonte até seu destino.
Assim como as redes de telecomunicação, o protocolo de comunicação em redes intra-chip é organizado em camadas, onde cada uma possui particularidades e funcionalidades de comunicação que apresentam níveis de hierarquia diferentes.
O modelo OSI é uma estrutura hierárquica composta por sete camadas que definem os requisitos para comunicação entre elementos de processamento.
As redes intra-chip, geralmente, implementam um subconjunto das camadas inferiores.
Como descrito em, geralmente as camadas inferiores (física, enlace e rede) dependem da tecnologia de implementação.
Por sua vez, as quatro camadas superiores são dependentes da aplicação.
Estas camadas no contexto de redes intra-chip são descritas a seguir.
Camada Física: Esta camada trata da organização física de interconexão da rede, ou seja, a distribuição dos canais de comunicação entre as chaves e os seus respectivos núcleos.
Esta camada é responsável por os detalhes referentes à transmissão e recepção de pacotes, sem a preocupação de detecção de erros em termos de hardware.
Em este nível são definidos os parâmetros elétricos dos sinais, a direção dos sinais e a largura dos canais.
Camada de Enlace de dados: O principal propósito da camada de enlace é diminuir a falta de confiabilidade na transferência de dados sobre o meio físico.
Esta camada define o protocolo para transmitir dados entre recursos da rede, como por exemplo, o protocolo handshake.
Camada de Rede:
A camada de rede determina a conexão entre um nodo origem e destino (s), estabelecendo o caminho que os pacotes irão utilizar.
Em este nível o projetista deve analisar a sua aplicação a fim de escolher os algoritmos de chaveamento (switching) e roteamento (routing).
Segundo Benini, o roteamento e o chaveamento de redes intra-chip afetam o desempenho e o consumo de energia do sistema.
Camada de Transporte:
A camada de transporte é responsável por o:
Controle de fluxo;
Escolha de o (s) algoritmo (s) de empacotamento e desempacotamento das mensagens e (iii) garantir a recepção ordenada dos pacotes.
Uma diferença existente entre esta camada no contexto de SoCs para redes de comunicação é o tamanho do pacote, que logicamente é inferior.
Camada de Aplicação:
Em o contexto de SoC, as funcionalidades relevantes às três camadas superiores (aplicação, apresentação e sessão) do modelo OSI podem ser combinadas neste nível.
Serviços importantes inerentes a essa camada incluem o gerenciamento e a sincronização de mensagens e conversão de formatos de dados por o receptor.
Apresentadas as definições das camadas, é possível constatar que os serviços de comunicação dos três níveis inferiores do protocolo OSI devem ser implementados em cada chave da rede.
Logo, os serviços correspondentes as camadas superiores são implementadas no próprio núcleo.
Em esta Seção apresenta- se o estado-da-arte em redes intra-chip.
Os resultados dessa revisão são apresentados resumidamente na Tabela 1.
Esta Tabela1 é o resultado de uma análise preliminar de publicações, onde cada linha corresponde a uma proposta de rede intra-chip cujos dados quantitativos ou qualitativos referentes a implementação encontrem- se disponíveis.
Os dados de implementação considerados relevantes estão divididos em três grupos:
Dados da estrutura da chave, apresentados nas quatro primeiras colunas;
Dados de desempenho, nas três colunas seguintes;
Dados de implementação em silício e/ ou prototipação, apresentados na última coluna.
Benini, De Micheli e Ye contribuíram com artigos que apresentam os conceitos nesta área de pesquisa.
Porém, nenhum desses documentos contêm detalhes referentes à implementação de redes intra-chip.
Deve- se ressaltar, que tanto a Tabela como o texto apresentado nessa Seção, refletem o conteúdo da Seção 3 do artigo aceito para publicação no periódico Integration (Elsevier).
Uma escolha comum à maioria das redes intra-chip é o uso do chaveamento de pacotes, não estando esta característica comum exibida na Tabela 1.
Uma exceção é a rede aSoC, onde a definição das rotas das mensagens é fixada no momento da síntese do hardware.
Dois conceitos associados, topologia de rede e estratégia de chaveamento, são os assuntos da primeira coluna da Tabela 1.
A topologia de rede predominante na literatura é a malha.
A razão para esta escolha deriva de três vantagens:
Facilidade de implementação usando tecnologias planares de Ci atuais;
Estratégia de chaveamento simplificada (XY);
rede facilmente escalável.
Outra topologia utilizada é a torus bidirecional, que pode ser utilizada para diminuir o diâmetro da rede.
O torus 2D dobrado é uma opção para redução do aumento do comprimento dos fios quando comparado a torus bidirecional.
Um problema associado às topologias torus e malha é a latência de rede.
Duas redes intra-chip utilizam topologias alternativas para obter redução de latência.
A rede SPIN e a chave proposta por adotam a topologia de árvore gorda, enquanto, a rede Octagon sugere o uso da topologia anel cordal.
Ambas as topologias conduzem a redes de menor diâmetro, com a conseqüente redução de latência.
Observando as estratégias de chaveamento, é possível afirmar que existe uma carência de informações publicadas sobre algoritmos específicos.
Isto indica a necessidade de pesquisas futuras nesta área.
Exemplificando, é sabido que algoritmos de roteamento adaptativos XY são propensos a deadlock, havendo soluções para evitar este fenômeno.
SoCs e redes intra-chip destinadas às tecnologias atuais.
O primeiro grupo inclui as propostas de Dally e Kumar, onde os canais de chaveamento possuem largura de 300 bits sem comprometer significativamente a área no SoC.
Isso pode ser alcançado com o uso de tecnologias de 60 nm para implementar Ci de dimensão 22 mm x 22 mm, com uma rede intra-chip 10 x 10, conectando 100 núcleos com dimensão 2 mm x 2 mm.
Entretanto, isso ainda não é possível nos dias de hoje, ou seja, é uma proposta para futuros SoCs.
O segundo grupo de trabalhos baseai- se em flits cujo tamanho varia entre 8 e 64 bits, uma largura de dado similar às arquiteturas de processadores atuais.
Dois trabalhos apresentam redes intra-chip que foram prototipadas, Marescaux e a rede Hermes.
Ambas as redes utilizam flits de menor tamanho, 16 bits.
O próximo parâmetro na Tabela 1 é a estratégia de bufferização da chave.
A maioria das redes intra-chip adotam filas de entrada.
Filas de entrada implicam numa fila simples por entrada, o que conduz a um menor aumento de área, quando comparado à chaves com filas nas saídas, o que justifica a escolha.
Porém, filas de entrada apresentam o problema de bloqueio head-of-line (caso um flit fique bloqueado, todos os demais flits que entrarem na fila ficarão por conseqüência também bloqueados).
Uma forma de contornar este problema é através da utilização de filas de saída, porém com um custo adicional de bufferização.
Uma solução intermediária é a utilização de canais virtuais de saída associados com canais virtuais multiplexados por tempo, como proposto em.
Outro parâmetro importante é o tamanho da fila, que implica na necessidade de solução em termos de compromisso entre a contenção da rede, latência de entrega dos pacotes e sobrecarga de área da chave.
Filas grandes conduzem a pouca contenção de rede, alta latência de pacote e chaves com bastante área.
Em contrapartida, filas pequenas implicam em situações opostas.
O último parâmetro estrutural consiste na interface chave-núcleo (interface de rede).
Como descrito anteriormente, o uso de interfaces intra-chip padrão é uma tendência na indústria e no meio acadêmico, pois incrementa a reusabilidade dos núcleos.
Uma rede intra-chip com interface de rede proprietária (protocolo próprio), como a proposta em, pode diminuir a reusabilidade da rede devido a a necessidade de se desenvolver invólucros para cada núcleo.
O padrão de interface VCI é utilizado em três redes intra-chip:
Proteo; SPIN e SoCIN.
As redes propostas por Sgroi e Moraes adotam interfaces OCP.
A quinta coluna coleta os resultados referentes à área da chave.
É interessante observar que as duas abordagens direcionadas a ASICs, ambas com flits de 32 bits, possuem área de 0.25 mm2 para tecnologias similares.
Os sistemas prototipados também apresentam resultados similares, em LUTs, de 631 a 890.
Estes dados permitem ao projetista estimar qual o impacto que a rede intra-chip terá na área final e se este custo justifica a sua adoção.
A estimativa do pico de desempenho, apresentado na sexta coluna da Tabela 1, é um parâmetro que precisa de uma análise mais aprofundada para prover uma comparação significativa entre as diferentes redes intra-chip.
De essa forma, esta coluna mostra diferentes unidades para diferentes redes intra-chip.
Esta coluna deve, conseqüentemente, ser considerada como uma ilustração de possíveis valores de desempenho.
A maioria das estimativas são provenientes do produto de três valores:
Número de portas da chave;
Tamanho do flit e freqüência de operação estimada.
Nenhum dado de desempenho significativo foi encontrado nas publicações revisadas.
A margem de variação dos valores deve- se, na maioria das vezes, aos dois últimos valores.
O próximo parâmetro da Tabela 1 diz respeito ao suporte de qualidade de serviço (QoS).
A garantia de QoS mais comum entre as redes intra-chip analisadas é o chaveamento de circuito.
Esta é uma forma de garantir a vazão e QoS para um determinado caminho de comunicação.
Visto que muitas das propostas combinam chaveamento de circuito com técnicas de serviços garantidos, há o conseqüente aumento de área da chave.
Este é o caso das redes intra-chip descritas em e.
Canais virtuais são uma forma de garantir QoS sem comprometer a largura de banda, especialmente quando combinado com técnicas de multiplexação com divisão de tempo (TDM).
Esta ultima técnica, exemplificada em, evita que pacotes fiquem bloqueados por grandes períodos, desde que flits provenientes de diferentes entradas sejam alocados para uma dada fatia de tempo no canal virtual de saída.
Espera- se que SoC atuais e futuros sejam dominados por aplicações do tipo multimídia.
Conseqüentemente, o suporte de QoS é considerado como característica fundamental para redes intra-chip.
Finalmente, observa- se que resultados de implementação de redes intra-chip ainda estão escassos.
Nenhuma da três implementações ASICs encontradas na literatura dão dicas se o projeto resultou num circuito em silício.
Três abordagens são apenas esboços de projeto.
Em contrapartida, duas redes intra-chip relatadas foram prototipadas em FPGAs, e.
Até o presente momento, neste Capítulo, foram apresentados os conceitos fundamentais sobre as estruturas de interconexão de SoCs, enfatizando redes intra-chip.
A Tabela 2 apresenta uma comparação entre as estruturas de interconexão:
Fios ponto-a-ponto dedicados;
Barramento; E redes intra-chip;
Frente a os seguintes critérios:
Tende a utilizar fios mais longos o que aumenta o consumo de energia.
Além disso, existe um aumento de carga capacitiva a cada núcleo acrescentado ao barramento, o que vem a reduzir o desempenho do sistema.
No caso de redes intra-chip não acrescenta- se capacitâncias, pois os núcleos são conectados ponto-a-ponto à porta local da chave.
Menor, se comparado à barramento.
Longos, além de aumento de curtos.
Novos núcleos não Motivo:
Fios mais curtos carga capacitiva a cada núcleo acrescentam capacitâncias, à acrescentado.
Não oferece escalabilidade.
Motivo: Escalável através do Limitada a dezenas de projetado para uma situação acréscimo de mais chaves à núcleos.
Reuso bastante restrito.
Motivo: Projetado para uma situação Totalmente reutilizáveis.
Específica. Um aspecto importante na abordagem de redes intra-chip consiste em como integrar núcleos à rede, garantindo a comunicação entre estes através do meio de comunicação.
A menos que o núcleo atenda ao protocolo de comunicação da rede, torna- se necessário criar um invólucro que permita integrar- lo à mesma.
Um invólucro deve possibilitar a integração física (interface ­ largura de sinais, sinais de entrada e saídasegmentação e remontagem dos pacotes) entre o núcleo e a rede.
Em o contexto de redes intra-chip denomina- se esse invólucro de interface de rede (Ir).
Segundo Kumar, é possível dividir o projeto interno da Ir em duas partes:
A parte específica à rede (independente do núcleo), responsável por a temporização, bufferização e aspectos de sincronização durante a transmissão/ recepção de dados;
Parte específica ao núcleo, Utiliza- se nesse trabalho o termo protocolo de rede como sinônimo para serviços de comunicação.
Praven discute a implementação da interface de rede em dois aspectos:
Como implementar- la, em software ou em hardware;
E onde implementar- la, ou seja, do lado do núcleo ou do lado da chave.
A diferença básica consiste na simplicidade ou na dificuldade de implementar a Ir, e quanto de trabalho se coloca em cada lado.
Além de considerar os aspectos, a divisão de esforços no projeto pode aumentar/ diminuir a reusabilidade da Ir (principalmente do lado da rede) e a proteção da propriedade intelectual de ambos os lados.
Dentro desse contexto, apresentamse duas abordagens:
Deve- se ressaltar que independentemente da abordagem utilizada, a segmentação e a remontagem dos pacotes (criação dos pacotes, definição da estratégia de endereçamento de núcleos, inserção de campos para correção de erro, bufferização dos dados) pode ser realizada tanto no lado da rede como no lado núcleo.
Entretanto, recomenda- se que a maior parte da segmentação e remontagem dos pacotes ocorra no lado núcleo, pois isto corresponde às camadas superiores (transporte e aplicação).
Acredita- se que as IRs da rede intra-chip devam ser idênticas, o que pode favorecer a reusabilidade da mesma, conforme já mencionado ao final da Seção 2.2.2.
A indústria de semicondutores vem concentrando esforços no que diz respeito ao incremento do reuso de núcleos, conforme apresentado na introdução deste trabalho.
A reusabilidade de núcleos ainda está longe do desejado, mas padronizar as interfaces desses núcleos pode conduzir ao aumento de reusabilidade, facilitando a interconexão desses em diferentes SoCs.
Entre as interfaces de comunicação padrão mais difundias na comunidade de semicondutores citase:
VCI (Virtual Component Interface) da VSIA (Virtual Socket Iniciative Alliance) e OCP (Open Core Protocol) da Sonics.
O uso de interfaces padrão permite a migração de uma abordagem bus-centric para uma abordagem core-centric.
Em a abordagem core-centric o projetista concentra- se no projeto do núcleo e não do sistema como um todo.
Bus-Centric core-Centric Núcleo A Núcleo A Protocolo barramento A Protocolo barramento A Protocolo Padrão Protocolo Padrão Adaptação a o protocolo do barramento B Protocolo Padrão Protocolo Padrão Barramento A Barramento B Barramento A barramento A Núcleo A Núcleo A Barramento B As figuras acima ilustram as abordagens bus-centric e core-centric.
Em a abordagem buscentric, um núcleo pode ser conectado diretamente ao barramento alvo, dado a similaridade do protocolo de comunicação A. Porém, para conectar o mesmo núcleo a um barramento B (protocolo diferente do A) torna- se necessário adaptar o núcleo ao protocolo B. Em a abordagem core-centric, o núcleo A, dotado de um protocolo padrão, pode ser conectado ao barramento A e B (caso ambos possuam interfaces padrão similares) sem a necessidade de adaptação de protocolo.
Ou seja, alterações em termos de sinais e métodos de comunicação são desnecessárias.
VCI é um padrão de interface que permite interconectar núcleos a um SoC.
Um núcleo VCI deve ter uma interface compatível com o padrão, caso contrário, o mesmo deve ser envolvido por uma lógica de adaptação de protocolo.
Em este padrão, os núcleos de um sistema são conectados ponto-a-ponto, sendo a comunicação entre interfaces mestre-VCI e escravo-VCI realizada através de transações, que consistem de requisições e possíveis respostas a estas.
Uma transação é composta basicamente por:
Um comando que descreve uma ação que deve ser executada por o lado escravo;
Dado de saída enviado por o lado mestre junto com um comando que necessita de um dado para ser executado (e.
g execução de uma escrita);
dado de resposta -- conseqüência de uma transação executada por o escravo que resulta em dados;
Aceite/ finalização da transação ­ ativando ou negando um ou mais sinais quando uma transação é aceita ou finalizada.
Exemplos de transações são ilustrados na Figura 14.
A figura acima ilustra três tipos de transações: (
a) transação de escrita com aceite de operação; (
b) transação de leitura simples que retorna dados, sem a necessidade de aceite do lado escravo; (
c) multi-cast ­ um mestre inicia transações para múltiplos destinos.
É possível classificar interfaces VCI em três tipos:
Mestre; Escravo;
E mestreescravo.
Uma interface do tipo mestre é aquela que tem a capacidade de começar uma transação através de uma requisição para um determinado escravo.
Já uma interface do tipo escravo deve apenas responder a requisições enviando uma resposta ao núcleo solicitante.
Um núcleo que possua uma interface do tipo mestre-escravo (por exemplo, um co-processador) possui ambas funcionalidades, ou seja, este pode tanto solicitar como atender a uma requisição.
Cada núcleo deve implementar a interface conforme a sua funcionalidade.
Por exemplo, um processador deve implementar uma interface do tipo mestre-VCI, enquanto que uma memória necessita de uma interface do tipo escravo-VCI.
Já um barramento necessita dos três tipos de interfaces, dada a possibilidade de interconexão de núcleos que possuam alguma das três interfaces descritas acima.
Cada interface pode ser baseada numa das três classes de sinais suportadas por o padrão, sendo estas:
VCI básico;
VCI periférico;
VCI avançado.
A documentação do protocolo em questão é exclusiva para membros associados.
Tal fato impossibilitou uma descrição mais detalhada do mesmo.
De a mesma forma que VCI, o padrão de comunicação OCP define uma interface ponto- aponto entre dois núcleos.
Em este contexto, um núcleo deve atuar como mestre e o outro como escravo.
Apenas o mestre (iniciador) pode enviar comandos inicializando as transações.
O escravo por sua vez responde aos comandos informados, tanto recebendo como passando dados ao mestre.
Basicamente, existem dois tipos de comandos:
Escrita e leitura de dados (palavras).
A Figura 15 ilustra dois tipos de transações geradas a partir de os comandos de escrita e leitura.
Extensões para esses comandos são:
No caso de escrita, broadcast, e de leitura, ReadEx.
O comando broadcast diferencia- se do comando de escrita por permitir a transferência de dados de um núcleo mestre-OCP para vários ou todos os núcleos conectados à interface escravo-OCP.
Por exemplo, várias memórias conectadas a um barramento (ou uma chave) com interface escravoOCP.
O segundo comando de extensão ReadEx, leitura exclusiva (do inglês, read exclusive), garante acesso exclusivo a um determinado endereço de memória.
Três comandos foram adicionados na versão 2.0.
São estes:
ReadLinked, WriteNonPost e WriteConditional.
A partir de os comandos descritos acima, torna- se possível transferir palavras entre interfaces OCP.
O número máximo de bits (word size) de uma palavra que pode ser transferida numa operação OCP simples limita- se a:
8, 16, 32, 64 e 128 bits.
Deve- se ressaltar que OCP baseiase no conceito de extensão de zeros (zero-extended), ou seja, utilizam- se zeros para preencher uma palavra com largura menor que as permitidas por o protocolo.
Esta restrição não está presente na versão 2.0 do protocolo.
De essa forma, o usuário poderá configurar a largura da palavra sem um conjunto discreto de valores específicos.
Mestre Comando, endereço Mad Comando aceito ccept ScmdA Sdata Sresp;
Requisição de leitura Requisição aceita Resposta a a requisição;
Escravo Leitura Resposta, dado Escrita Comando, endereço Comando aceito Madd;
As transações de escrita e leitura de palavras podem acontecer separadamente, ou seja, respostas para requisições podem ocorrer em ciclos diferentes.
Além de transações simples (escrita e leitura), OCP possui suporte para transações em modo rajada (do inglês, burst).
O modo rajada caracteriza- se por a transmissão de dados em volume, requerendo acréscimo de sinais na interface OCP.
A utilização desse modo pode ser necessária para núcleos que atuem com alta transferência de dados, como um núcleo DSP.
Além de o modo de transmissão baseado em rajada, OCP suporta requisições e respostas fora de ordem.
Isto é possível a partir de a utilização de identificadores de requisição e respostas, denominados threads.
Em este contexto, quando um núcleo com interface mestre-OCP efetua uma requisição, junto é enviado o identificador da thread (interna a sua interface) correspondente a essa requisição.
De a mesma forma, com toda resposta é provido o identificador referente a mesma.
Logo, o mestre fica sabendo qual requisição foi efetuada com sucesso.
A Figura 16 ilustra um sistema simples contendo um barramento empacotado (com interfaces OCP para o mundo externo) e três núcleos:
Um atuando apenas como mestre, outro apenas como escravo e um terceiro podendo ser tanto mestre como escravo.
Uma interface OCP é composta por um conjunto de sinais que podem ser utilizados para dar suporte às particularidades de um núcleo.
Ou seja, as particularidades inerentes ao núcleo indicam quais sinais devem compor a sua interface e o invólucro OCP em o qual este será inserido.
Todos os sinais OCP são ponto-a-ponto, unidirecionais e são amostrados na borda de subida do relógio.
Estes sinais são classificados em três grupos:
Sinais de fluxo de dados, sinais opcionais de controle, e sinais de teste.
Iniciador do Sistema Iniciador/ alvo do Sistema Alvo do Sistema Núcleo Núcleo Núcleo Mestre Mestre Escravo Escravo Resposta Solicitação Módulo de interface do barramento Escravo Iniciador do barramento Mestre Mestre Escravo Alvo do barramento Iniciador/ alvo do barramento Barramento A figura descreve o modelo de comunicação OCP.
Observar que este é sempre ponto- aponto, ou seja, torna- se necessária a comunicação entre pares mestre-escravo.
Notar também que o módulo OCP escravo interno ao barramento, atua de fato como mestre do barramento.
Sinais de fluxo de dados:
Correspondem a um conjunto de sinais que podem ser utilizados para garantir o fluxo de dados entre dois módulos.
Divide- se este conjunto em:
Sinais básicos e sinais opcionais (simples e complexos).
Os sinais adicionais podem ser utilizados para atender particularidades de um dado módulo, e.
g, permitir transações em modo rajada.
Sinais opcionais de controle:
Relaciona- se esse grupo a transmissão de informações de controle como reset e interrupções.
Sinais de teste:
Referem- se a um grupo de sinais opcionais utilizados para testar um determinado núcleo.
A utilização desses sinais suporta o padrão IEEE 1149.
1. A direção dos sinais descritos acima depende do modo de atuação do núcleo, sendo que este pode atuar como:
Mestre/ escravo e/ ou sistema/ núcleo.
Um núcleo que atua como &quot;sistema «é responsável por gerar sinais de controle.
Por outro lado, um núcleo que atua como &quot;núcleo «não gera esses, utiliza- os.
A Tabela 3 ilustra as seis combinações possíveis.
De entre todos os sinais suportados por o protocolo destaca- se o grupo de sinais básicos.
Justifica- se essa afirmativa porque estes sinais devem compor a interface de qualquer núcleo dotado de interface OCP.
Estes sinais são descritos na Tabela 4.
Em a versão 2.0 deste protocolo, o conjunto de sinais básicos foi reduzido[ OCP03].
Por exemplo, os sinais Mdata e Sdata não precisam compor a interface de um núcleo OCP.
Maiores informações referentes aos sinais OCP podem ser obtidas na especificação do protocolo A utilização do protocolo padrão em questão não garante a comunicação entre todo e qualquer núcleo com interface OCP.
Ou seja, é possível definir várias interfaces OCP todas incompatíveis entre si.
Uma comunicação OCP é garantida à medida que as interfaces dos núcleos são compatíveis.
Sendo assim, as &quot;similaridades «das interfaces devem permitir a conexão e a comunicação entre dois núcleos que adotam OCP.
Em este contexto, duas interfaces são ditas compatíveis se estas atendem à três quesitos:
Compatibilidade de núcleos;
Compatibilidade de protocolo;
Compatibilidade de sinais.
Compatibilidade de núcleos:
Diz respeito ao modo de atuação dos núcleos.
Sendo assim, um núcleo com interface mestre-OCP pode comunicar- se somente com outro que possua uma interface escravo-OCP (ou mestre-escravo).
De a mesma forma, um núcleo que apresenta sinais de sistema em sua interface deve comunicar- se com outro que possua uma interface do tipo núcleo.
Compatibilidade de protocolo:
Refere- se ao suporte de comandos apresentados entre as interfaces.
Por exemplo, se a interface de um núcleo suporta o comando de leitura exclusiva a outra interface também deve suportar este comando.
Compatibilidade de sinais:
Reporta- se à necessidade de equivalência dos sinais utilizados, e da largura destes.
Esta Seção apresenta alguns dos modos de transferência que podem ser implementados com o conjunto de sinais básicos do protocolo em questão.
Objetiva- se com isso, apresentar ao leitor o comportamento do protocolo OCP.
Outros diagramas de transferência podem ser encontrados na especificação OCP.
A Figura 17 ilustra o diagrama de tempo para uma transferência simples de escrita e leitura.
A seqüência para transferência segue os seguintes eventos:
O mestre-OCP inicia a fase de requisição quando ocorre a transição de IDLE para WR no sinal Mcmd.
Em o mesmo instante é apresentado um endereço de memória válido no sinal Maddr, e um dado válido no sinal Mdata.
Estes três sinais devem ser apresentados juntos, conforme a semântica do protocolo.
O escravo-OCP por sua vez, ativa o sinal de ScmdAccept no mesmo ciclo, permitindo a transferência (transação de escrita) sem latência.
Em esse instante, o escravo-OCP captura os valores referentes ao endereço, aos dados e utiliza estes internamente para efetuar a escrita.
Como o ScmdAccept está ativo, isto indica término da fase de requisição.
O mestre-OCP inicia a fase de requisição de leitura (RD2) atribuindo o comando de leitura RD, no sinal MCmd.
Em este momento o mestre apresenta um endereço de memória válido (A2) no sinal Maddr.
O escravo-OCP captura o endereço do sinal Maddr e utiliza este internamente para determinar o dado a ser retornado.
A fase de resposta começa quando o comando SResp passa de NULL para DVA.
Em o mesmo instante o escravo apresenta o dado no sinal SData.
Como o ScmdAccept está ativo, isto indica término da fase de requisição.
A o perceber que o campo SResp indica um dado válido (DVA) o mestre-OCP captura o dado do sinal SData, finalizando a fase de resposta.
A latência gerada por essa fase é igual a 1 ciclo de relógio.
A Figura 18 ilustra um diagrama da requisição de escritas do tipo handshake.
Para cada uma das três requisições de escrita o sinal ScmdAccept é ativo, informando a aceitação da transação.
A seqüência para transferência segue os seguintes eventos:
O mestre-OCP inicia a fase de requisição apresentando o comando de WR1 no sinal MCmd.
Em o mesmo instante é apresentado um endereço válido no sinal Maddr e um dado no sinal MData.
O escravo por sua vez, ativa o sinal de ScmdAccept no mesmo ciclo, gerando assim uma resposta para requisição sem latência (como apresentado anteriormente).
O mestre-OCP inicia, no próximo ciclo de relógio, uma nova fase de requisição.
O escravoOCP, por sua vez, captura o endereço de escrita e o dado.
Em este instante, o ScmdAccept está desativado, o que indica que o escravo-OCP não está pronto para atender a nova requisição de escrita.
O mestre-OCP mantém os valores nos sinais (MCmd, MAddr, MData) até o escravo ativar o sinal ScmdAccept.
Com um ciclo de relógio de latência o escravo ativa o sinal ScmdAccept.
O escravo captura o endereço de escrita e o dado.
Depois de permanecer um ciclo de relógio em IDLE, o mestre começa uma nova fase de requisição de escrita.
O ScmdAccept é ativado com latência de dois ciclos de relógio.
Em este instante, o escravo captura os valores dos sinais MCmd, MAddr, MData.
A Figura 19 ilustra uma requisição de leitura com latência de aceitação e resposta.
A aceitação para requisição de leitura apresenta uma latência igual a 2, que corresponde ao número de ciclos de relógio que o ScmdAccept permaneceu desativado.
Entre a fase e requisição e a fase de resposta apresenta- se uma latência de três ciclos de relógio, referentes ao número de ciclos de relógio do final da fase de requisição (D) para o final da fase de resposta (F).
A seqüência para transferência segue os seguintes eventos:
O mestre-OCP inicia a fase de requisição de leitura apresentando o comando de RD1 no sinal MCmd.
Em o mesmo instante apresenta- se um endereço válido no sinal Maddr.
O escravo por sua vez, não está pronto, sendo assim o ScmdAccept permanece desativado.
O mestre-OCP vê que o ScmdAccept não está ativo, e mantêm todos os valores dos sinais da fase de requisição.
O escravo-OCP ativa o sinal de ScmdAccept.
O mestre-OCP continua mantendo os sinais na fase de requisição.
O campo Sresp continua como NULL.
O escravo-OCP captura o endereço.
Porém, este não está pronto para responder, sendo assim, o sinal SResp continua em NULL.
O escravo-OCP apresenta uma resposta válida, ou seja, o sinal de SResp recebe DVA.
Em o mesmo momento o dado é colocado no SData.
O mestre-OCP recebe a resposta e captura o dado de leitura.
A certificação de um núcleo frente a um padrão de comunicação é de fundamental importância tanto para projetista como para o usuário.
De um lado, o projetista precisa garantir que seu produto (núcleo) atenda às normas do protocolo padrão adotado.
O usuário, por sua vez, quer utilizar o núcleo no seu projeto, sem se preocupar com a validação do mesmo.
Caso contrário, a possível reusabilidade conquistada com a padronização de comunicação é perdida frente a necessidade de verificação do padrão.
A ferramenta CoreCreator permite ao projetista verificar se um núcleo atende à especificação do protocolo OCP.
Deve- se salientar, que a ferramenta CoreCreator suporta apenas núcleos descritos em VHDL e Verilog.
As etapas de certificação de núcleos OCP são descritas abaixo e ilustradas na Figura 20.
Para poder importar um núcleo na ferramenta CoreCreator é necessário descrever a (s) interface (s) mais externa (s) num formato que a mesma possa interpretar.
Dentro desse contexto, o usuário pode proceder de duas formas:
A primeira parte do fluxo de certificação, denominada descrição das interfaces, conforme a Figura 20, corresponde a duas etapas:
Descrição de interfaces não-OCP:
Geração manual do arquivo que reflete a interface não-OCP do núcleo, caso o projetista opte por a opção acima.
Estas interfaces são definidas como bundles (conjunto de sinais).
A Figura 21 ilustra a descrição da interface de um núcleo (RAM) que é descrito na Seção 3.2.5 deste trabalho.
Descrição da interface OCP:
Em esta etapa deve- se criar um arquivo que represente as características da interface OCP do núcleo a ser validado.
Em este exemplo, especifica- se a interface &quot;OCP( «slave_ ocp_ ram&quot;) do tipo escravo (parâmetro interface_ type slave) do invólucro que contém o núcleo (e.
g RAM) e a lógica OCP.
As características OCP são definidas a partir de os parâmetros de configuração dos sinais, conforme ilustrado na Figura 22.
Estas duas descrições serão associadas ao núcleo que iremos validar na ferramenta CoreCretor.
A etapa seguinte, denominada &quot;Conexão dos módulos do sistema «é responsável por conectar:
Estes módulos são divididos em dois grupos:
Qs-Models e QC-Models.
Os módulos servem para modelar um sistema conectado ao núcleo do usuário.
Por sua vez, os módulos são utilizados para modelar núcleos que atuem como mestre (QC- Master) ou escravo (QCSlave).
O comportamento dos módulos Q-Master podem ser definidos a partir de a linguagem STL.
STL é uma linguagem de descrição de tráfego e transações OCP utilizada para exercitar a interface de um núcleo com interface escravo-OCP.
Os módulos Q-Slave podem atuar como memórias ou filas (FIFO) para leitura/ escrita de dados.
É possível definir a latência de reposta para as requisições provindas de um núcleo com interface mestre-OCP.
A Figura 23 ilustra a interface da ferramenta CoreCreator com os módulos acima conectados entre si.
Além desses módulos, a Figura 23 apresenta algumas das fases de certificação.
As principais fases são:
Criação do netlist;
Preparação da simulação;
Simulação; E análise de resultados.
A fase denominada criação do netlist, é responsável por gerar a estrutura de validação do núcleo.
Esta estrutura é um arquivo em formato Verilog correspondente a um netlist que integra todos os componentes do sistema.
Este arquivo Verilog contém todo o projeto e é denominado no contexto da ferramenta CoreCreator de testbench.
Antes de partir para próxima fase, o usuário deve gerar um arquivo top que integre o testbench gerado na etapa anterior com geração de relógio e reset.
Este arquivo deve ser descrito em VHDL (nomeado de stim_ Vhd) ou Verilog (nomeado de stim_ V).
A fase final do fluxo de certificação, apresentada neste documento, é a simulação.
As etapas de empacotamento e síntese não são apresentadas, pois não fazem parte do escopo deste trabalho.
A etapa de simulação compreende três processos:
Objetivando dominar o desenvolvimento de invólucros para núcleos não OCP realizou- se o desenvolvimento de estudos de caso de alguns núcleos, como memórias, contadores, processadores, e chaves de rede intra-chip.
É importante ressaltar que os invólucros OCP desenvolvidos utilizam o conjunto de sinais básicos do protocolo.
Dentro desse contexto, segue a descrição de uma memória com interface do tipo escravo-OCP.
A Figura 24 ilustra uma memória com invólucro OCP.
O invólucro Wrapper_ OCP_ Ram empacota dois módulos:
Memória RAM;
Lógica de interface, denominada Slave_ OCP_ Ram.
A memória atua como escravo do sistema, ou seja, atende requisições de escrita ou de leitura de um núcleo que atue como mestre do sistema.
Os sinais que compõem a interface externa da RAM são:
Address; ­ endereço de memória;
Data ­ dado de escrita/ leitura;
Ce_ n -- quando ativo habilita o acesso à memória;
We_ n ­ quando ativo habilita escrita na memória;
Oe_ n ­ quando ativo habilita a leitura da memória.
O módulo Slave_ OCP_ Ram apresenta em sua interface externa todos os sinais para comunicação com a memória e os sinais utilizados para comunicação com o invólucro OCP (conjunto de sinais básicos mais o sinal Reset_ i).
O comportamento responsável por o controle do protocolo OCP, implementada no módulo Slave_ OCP_ Ram, é descrito na Figura 25.
A máquina de estados, responsável por a interface entre a RAM e protocolo OCP, apresenta os seguintes estados:
Write: Os sinais ce_ n e we_ n são ativados.
Em o mesmo estado, o sinal address recebe Maddr_ i, ou seja, o endereço da memória em o qual o dado deve ser escrito e o data recebe Mdata_ i.
Após o desenvolvimento do invólucro OCP torna- se necessário validar o mesmo.
A estrutura de validação adotada é a mesma ilustrada na Figura 23 (página 35).
A Figura 26 ilustra os resultados da simulação para requisições de escrita e leitura geradas por o módulo Qs-Master para memória com interface OCP.
A seqüência de eventos destacada na Figura 26 é descrita abaixo:
A fase de requisição ocorre com a transição de IDLE para WR no sinal Mcmd_ i $= '1'.
Em o mesmo instante os sinais Maddr_ i e Mdata_ i recebem do módulo mestre (Qs-Master) o endereço de memória e o dado a ser escrito, respectivamente.
Um ciclo de relógio depois da requisição de escrita, o escravo (RAM) ativa os sinais ce_ n e we_ n..
Em este momento, o sinal ScmdAccept_ o é ativado, indicando ao mestre que a escrita do dado (CDEF) no endereço de memória informado no sinal address foi feita.
A latência gerada na fase de escrita é igual a 1 ciclo de relógio.
Após ficar um ciclo de relógio em IDLE o módulo escravo recebe uma requisição de leitura (Mcmd_ i $= '2').
Em o mesmo instante o campo Maddr_ i recebe o endereço que será utilizado para leitura.
Um ciclo de relógio depois da requisição de leitura, os sinais ce_ n e oe_ n são ativados.
Em o mesmo ciclo, ScmdAccept_ o é ativo e o endereço de memória é recebido no sinal address.
Após um ciclo de relógio, é apresentada uma resposta válida no sinal Sresp_ o.
Em o mesmo instante, o dado é colocado no sinal Sdata_ o.
A latência gerada por essa fase é igual a 2 ciclos de relógio.
Slave_ OCP_ RAM e DN os sinais do módulo RAM.
A execução desta simulação, quando lançada por a ferramenta CoreCreator, fornece relatórios referentes a transações e tráfego OCP, e se estes estão conforme o protocolo em questão.
Para determinar se uma interface atende as normas OCP, o ocpcheck verifica uma série critérios para atribuir PASS aos itens ilustrados na Figura 27.
A descrição desses critérios segue:
Address Aligment: Verifica se os endereços estão alinhados corretamente durante as transações.
Complete Transfers:
Os dados que são escritos num conjunto de endereços são comparados com os dados lidos do mesmo conjunto de endereços.
Se estes não forem idênticos, considera- se que este núcleo não atende as normas OCP neste quesito.
Control/ StatusHandshaking:
Verifica- se se os sinais de handshake da interface mudam de acordo as especificações do protocolo.
Group Signal Integrity:
Existem sinais que devem ser ativados no mesmo ciclo de relógio, como, Mcmd e Mdata devem receber valores no mesmo instante.
Protocol: Se todas as fases de uma transação OCP (requisição, resposta e handshaking de dados se configurado) ocorreram de acordo com o que rege o protocolo atribui- se PASS para este item.
Reset: Atribui- se PASS a este item se o sinal reset foi ativado depois de 16 ciclos de relógio e se os dados recebem valores de acordo com o estado desse sinal;
Sinal integrity:
Se nenhum sinal OCP exibe valores como 'X` ou' Z'durante a simulação, considera- se que estes sinais seguem o que rege o protocolo.
O relatório da Figura 28 prove de maneira sucinta as transações ocorridas, assim como os sinais e os valores envolvidos durante as transações.
Por exemplo, no tempo de simulação 5700 ns, ocorre a 28ª transação OCP, correspondendo a uma operação de escrita no endereço 00002 com o valor 89 AB.
Quando ocorrem transações de leitura, o sinal de resposta DVA é recebido.
Após a breve descrição dos protocolos VCI e OCP, torna- se necessário salientar alguns pontos em comum entre eles.
Ambos os protocolos baseiam- se na abordagem de comunicação ponto-a-ponto.
Tanto VCI como OCP possuem capacidades similares que permitem interconectar núcleos num mesmo Ci com menor esforço.
Porém, existem diferenças entre estas abordagens.
O conjunto de sinais de teste que compõe OCP pode ser considerado um diferencial, já que VCI não suporta algo semelhante.
Além de o conjunto de sinais de teste, o OCP possui um ferramental que permite a validação e certificação de núcleos OCP que venham a ser desenvolvidos por o usuário.
Além disso, foi anunciado recentemente que a OCP-IP e a VSIA pretendem unificar o protocolo para interconexão de núcleos.
O conjunto de fatores que levaram à escolha de protocolo OCP pode ser resumido em:
Ser um protocolo padrão aceito por a indústria;
Ter ferramental para certificação de núcleos;
Possível padrão de fato para interconexão de núcleos com a unificação OCP-VSIA;
Uso do protocolo OCP no projeto de pesquisa Brazil-IP 1, projeto este onde a presente dissertação está inserida.
Este Capítulo descreve a rede intra-chip, denominada Hermes, desenvolvida no grupo de atuação de pesquisa do autor dessa dissertação.
A Hermes foi utilizada como base para o desenvolvimento das atividades que compõe essa dissertação.
Após uma descrição sucinta da Hermes apresenta- se a primeira contribuição deste trabalho, Seção 4.2, a qual corresponde ao desenvolvimento de interfaces de rede OCP para a rede intra-chip em questão.
A rede Hermes é uma infra-estrutura para implementação de redes intra-chip.
Diz- se infra-estrutura porque não existe uma única rede intra-chip.
Existe um conjunto de módulos que podem ser utilizados para geração de redes intra-chip.
Exemplos desses módulos são:
Árbitro, filas e portas de entrada/ saída.
A descrição detalhada de cada módulo encontra- se disponível em.
Todos os módulos da Hermes são parametrizáveis, através de uma ferramenta que permite a geração de redes intra-chip em função de as restrições de projeto como:
Largura de palavra;
Profundidade das filas;
Topologia da rede, entre outras.
Em o Capítulo 5, esta ferramenta é apresentada detalhadamente.
Utilizando os módulos citados acima é possível gerar redes intra-chip diretas, com topologias como malha e torus.
Existem protótipos funcionais para a topologia malha implementados no grupo de atuação.
A Hermes implementa os três níveis hierárquicos inferiores do modelo de referência OSI:
Físico; Enlace e rede.
O nível físico da rede Hermes implementa a interface de comunicação entre as chaves.
O nível de enlace adota o protocolo de handshake para o envio e recebimento de dados de forma confiável.
Para compor o nível de rede é adotado o modo de chaveamento de pacotes wormhole.
O pacote na rede Hermes é formado por 1 flit com endereço destino, 1 flit com o tamanho do payload e de 0 a 2 n-1 flits de payload, onde n corresponde ao tamanho do flit.
A rede Hermes utiliza roteamento distribuído, determinístico e com caminho mínimo entre os nodos de origem e destino.
A chave Hermes possui uma lógica de controle de chaveamento centralizada e cinco portas bidirecionais parametrizáveis:
Norte; Sul;
Leste; Oste;
E local.
A estrutura básica de uma chave Hermes é apresentada na Figura 29.
Cada porta (ou canal) é constituído por um conjunto sinais que implementam o protocolo de handshake.
A funcionalidade destes sinais é a seguinte:
Para topologias malha e torus, no máximo cinco portas de acesso são necessárias, sendo uma porta local para conexão ao núcleo e quatro portas para conexão a outras chaves da rede.
No caso de topologias torus todas as chaves possuem 5 portas.
Em a topologia malha, o número de portas depende da posição da chave relativa aos limites da malha.
Em este caso, uma mesma topologia permite a parametrização da chave quanto a o número de portas e filas em função de a posição da chave.
A ferramenta desenvolvida para geração automática da rede realiza esta otimização.
Em a Seção 5.1.3, página 70, apresenta- se um exemplo da redução de área obtida com esta otimização.
Outra particularidade inerente à chave da Hermes foi a de limitar o esquema de armazenamento de flits, empregando apenas filas de entrada (input buffering), descartando as possibilidades de estocagem na saída da chave (filas de saída) e/ ou esquemas mistos de armazenamento.
Isto foi feito porque o armazenamento na entrada da chave é aquele que causa a mínima sobrecarga de área, e este parâmetro, como atestado na bibliografia disponível, determina a área ocupada por a chave.
O tamanho da área de estocagem é também parametrizável.
Resultados de análises iniciais visando determinar o tamanho ótimo dos buffers de entrada na procura do máximo desempenho para a chave Hermes com a mínima área, encontram- se disponíveis em.
Os passos da simulação são descritos a seguir:
A chave recebe um flit da porta local, o sinal rx é ativo e o sinal data_ in recebe o conteúdo do flit.
O flit é armazenado no buffer local e o sinal ack_ rx é ativo indicando que o flit foi recebido (índice 2 na Figura).
A porta local solicita roteamento para ao árbitro (lógica de arbitragem) ativando o sinal h (índice 3 na Figura).
O árbitro pode receber múltiplas solicitações de roteamento (h) simultâneas.
Uma vez determinada a porta de entrada que será atendida, o árbitro solicita à lógica de roteamento conexão a uma dada saída.
Isto é feito ativando- se o sinal req_ rot (índice 4 na Figura).
O sinal header contém o destino, e o sinal incoming a origem do pacote (4, que indica a porta local).
O algoritmo de roteamento é executado, a tabela de roteamento é escrita e o sinal ack_ rot é ativado (índice 5 na Figura), indicando o estabelecimento da conexão, quando possível.
Caso não seja possível rotear a solicitação, o árbitro seleciona a próxima porta com pacotes a transmitir.
A lógica de arbitragem informa o buffer que a conexão foi estabelecida e que o flit pode ser transmitido (índice 6 na Figura).
A chave ativa o sinal tx da porta de saída selecionada e coloca o conteúdo do flit no sinal data_ out da mesma porta (índice 7 na Figura).
Uma vez que o sinal ack_ tx está ativo o flit é removido do buffer e o próximo flit armazenado é enviado.
O segundo flit inicializa o contador, indicando quantos flits devem ser enviados para que a conexão ser finalizada (no presente caso, 7 flits).
A chave, como apresentado na Figura 31, apresenta uma latência de 8 ciclos de relógio para rotear o cabeçalho (primeiro flit), se não houverem colisões ou portas de saídas ocupadas.
Após essa latência, os flits subseqüentes são roteados a cada dois ciclos de relógio, devido a o protocolo handshake.
Considerando que uma chave pode ter até cinco conexões simultâneas, e sendo a freqüência de relógio 25 MHz (estabelecida por propósitos de roteamento), e a largura do flit igual a 8 bits, a chave pode suportar um pico de taxa de transmissão igual a 500 Mbps.
Divide- se o produto por dois, devido a o fato do protocolo handshake necessitar 2 ciclos de relógio para transmitir um flit.
A interface de rede original da Hermes é denominada Send/ Receive.
Esta Ir é um módulo quem contém a lógica de envio e recebimento de pacotes, assim como a montagem, o envio e o recebimento de confirmações.
Esta Ir foi implementada em hardware, do lado do núcleo.
A Figura 32 ilustra este módulo e seus respectivos sinais são detalhados a seguir.
AvSend: Sinaliza que o núcleo tem um pacote a ser enviado através do módulo Send.
O módulo Send/ Receive possui duas máquinas de estados:
Máquina de estados Send;
E máquina de estados Receive.
Esta interface de rede, apesar de funcional, não atende ao requisito de reusabilidade, pois é implementada no lado do núcleo, sendo também proprietária.
Além de isto, o consumo de área é elevado devido a os vetores utilizados para recepção/ envio de dados.
A rede Hermes foi validada com a topologia malha.
A Figura 33 ilustra a transmissão de um pacote da chave 00 para chave 11 numa topologia malha.
Deve- se ressaltar, que apenas os comportamentos de entradas e saídas da chave 10 são ilustrados na simulação.
Os passos da simulação são descritos a seguir:
A chave 00 envia o primeiro flit do pacote (endereço de destino) para o sinal data_ out da porta leste e ativa o sinal tx da mesma porta.
A chave 10 detecta que o sinal rx está ativo na porta oeste e captura o flit do sinal data_ in São necessários 10 ciclos de relógio para rotear esse flit.
Os próximos flits são roteados com dois ciclos de relógio de latência.
A porta de saída sul (índice 3) da chave 10 está livre, free (3)_ $= '1'.
Este sinal passa para '0', indicando ocupação da porta.
A chave 10 coloca o flit no sinal data_ out e ativa o sinal tx da porta sul.
Depois, a chave 11 detecta o sinal rx da porta norte ativo.
O flit é capturado no sinal data_ in e a conexão entre o fonte e o destino é estabelecida.
O segundo flit do pacote contém o número de flits que compõem o payload.
Depois que todos os flits são enviado, a conexão é finalizada e todas a entradas do vetor free de cada chave envolvida na conexão retornam aos seus estados de free.
A latência mínima (ciclos de relógio) para transferir um pacote do fonte ao seu destino é dado por:
Ri+ P × 2 onde n é o número de chaves envolvidas na comunicação (inclusive a fonte e o destino), Ri é o tempo necessário por o algoritmo de roteamento em cada chave visitada, e P é o tamanho do pacote.
Esse número é multiplicado por 2 porque cada flit necessita de 2 ciclos de relógio para ser enviado.
Como descrito anteriormente, uma estrutura de interconexão deve atender ao requisito de reusabilidade de projeto.
Visando aumentar a reusabilidade da Hermes em projetos distintos, padronizou- se as interfaces de rede com o protocolo OCP.
Denomina- se Hermes-OCP a rede intra-chip Hermes com interface OCP.
Objetiva- se com essa proposta simplificar ao máximo as transações (núcleo-chave), tornando a Hermes o mais transparente possível para os núcleos que a empregam como meio de comunicação.
Dependendo do núcleo, a porta local pode possuir uma interface de rede OCP do tipo mestre, escravo ou mestre-escravo.
Núcleos que desejem comunicar- se via a Hermes-OCP devem atender ao protocolo OCP adotado por a rede.
Não basta que os núcleos possuam interfaces OCP compatíveis.
Deve- se definir sobre o protocolo OCP o conjunto de sinais utilizados, e qual o protocolo de comunicação adotado por a rede.
Em outras palavras, o nível físico da Hermes adota OCP, o nível de enlace define um formato de pacote, composto por uma seqüência de transações OCP e o nível de rede é uma comunicação ponto-a-ponto, que pode ser diferente para cada par de núcleos.
Em este contexto foram desenvolvidos para a rede Hermes três tipos de IRs OCP:
Ir mestre (Ir-M);
Ir escravo (Ir-E);
E (iii) Ir mestre-escravo (Ir-ME).
Até o presente momento, as interfaces de rede propostas suportam apenas transações de escrita e leitura.
Núcleos que queiram escrever (enviar pacotes) ou ler dados (receber pacotes) para/ de outros núcleos através da Hermes-OCP devem atender ao protocolo de comunicação da rede, como proposto abaixo:
Que compõe o restante do payload.
Não é possível misturar comandos de escrita e leitura num pacote enviado por a rede o tamanho máximo do payload é de 2 N-1 palavras de N bits, onde N corresponde ao tamanho do flit em bits.
Caso um determinado núcleo necessite um pacote maior que este, é responsabilidade da Ir do mesmo realizar os processos de segmentação e remontagem.
Note- se que isto adiciona uma camada ao protocolo de comunicação da Hermes-OCP, sob responsabilidade do usuário.
Tanto para transações de envio como para de recepção, um conjunto de transações básicas OCP torna- se necessário.
Por exemplo, para o núcleo mestre escrever dados num núcleo escravo, as transações descritas na Tabela 5 devem ser executadas.
Tabela 6 -- Protocolo para transmissão de leituras na rede Hermes.
Sinal MData Destino Tamanho d0 d1 dn-1 Sinal MCmd Para um núcleo escravo responder às solicitações de leitura providas por um núcleo mestre, este deve gerar as transações descritas na Tabela 7.
Cabe ressaltar, que este protocolo de comunicação proposto adota um modelo de comunicação do tipo Norma (Em o Remote Memory Access).
Em este modelo não há um mapa global de endereços, sendo a comunicação realizada por a troca de mensagens entre os núcleos.
Por exemplo, caso um determinado núcleo deseje escrever um conjunto de dados na memória, a mensagem que este enviará para a memória será o endereço da mesma na rede, o endereço inicial de escrita e logo após os dados.
Uma alternativa a este modelo, adotada no projeto Brazil IP, é o modelo Em uma (do inglês, Non-Uniform Memory Access).
Em este modelo há um espaço único de endereçamento, sendo muito similar às estruturas tradicionais de barramento.
Este modelo pode parecer atrativo num primeiro momento, pois simplifica a comunicação, pois basta enviar o endereço de destino e o dado.
Entretanto, este modelo apresenta desvantagens que são descritas abaixo:
Mensagens são tipicamente curtas, compostas normalmente por um endereço e um dado.
Redes intra-chip terão seu desempenho maximizado no momento que se transfere dados em rajada.
As desvantagens citadas acima guiaram a escolha do projeto das IRs OCP e dos sistemas desenvolvidos no contexto dessa dissertação para o modelo Norma.
Objetiva- se na Seção seguinte apresentar o desenvolvimento e a validação das IRs OCP citadas anteriormente.
Essas IRs foram descritas em VHDL, validadas por simulação funcional e prototipadas em FPGA (este processo é discutido no Capítulo 6 deste trabalho).
Foi desenvolvida uma estrutura de validação sobre uma rede Hermes com topologia malha de dimensão 2 x 2, para a certificação, via CoreCreator, da Hermes-OCP.
Conectou- se a três portas locais dessa rede IRs-M e na porta restante uma Ir-E.
Por conseqüente, foram conectados módulos QC-Slave às IRs-M e um módulo QC- Master à Ir-E. A estrutura desenvolvida para validar as IRs OCP da Hermes via CoreCreator é ilustrada Figura 34.
A figura acima ilustra a estrutura de validação utilizada para validar as IRs da HERMESOCP de dimensão 2x2 (representado na figura como W_ noc).
As três IRs-M são representadas por os bundles:
M_ ocp_ 10;
M_ ocp_ 01.
Já a Ir-E é representada por o bundle.
O módulo QC- Master é responsável por gerar os estímulos OCP (pacotes) que devem exercitar as interfaces de rede OCP.
Estes estímulos foram descritos em STL conforme ilustram as Figura 35 e Figura 36.
Além desses módulos compõem a estrutura 4 monitores OCP que devem verificar as transações entre os módulos QC- Master/ Slave e as IRs do lado da rede (W_ noc).
O módulo QC- Master é responsável por o envio de pacotes à rede.
Para isso, foi descrito um arquivo em STL que contém 2 pacotes de 128 bits destinados à mesma chave.
Para que um pacote possa ser transferido por a Hermes-OCP deve- se fragmentar o mesmo em flits.
Um dos pacotes contém flits que devem ser enviados a rede (transações de escrita OCP).
A descrição STL e a fragmentação deste pacote de 128 bits é ilustrada na Figura 35.
O segundo pacote, descrito em STL, utilizado para transmitir leituras por a Hermes-OCP é ilustrado na Figura 36.
As Seções subseqüentes apresentam o projeto das IRs e a validação das mesmas.
Os sinais OCP que compõem a Ir-E são descritos na Tabela 8.
O flit1 recebe o endereço do destino ao qual o pacote deve ser entregue.
Em o segundo flit adiciona- se 1 ao valor que corresponde ao tamanho do pacote, isto porque um comando OCP deve ser inserido para informar a transação a ser efetuada na interface OCP do núcleo destino (leitura ou escrita).
Conseqüentemente, o terceiro flit do pacote recebe um comando OCP.
Finalmente, os flits restantes recebem os dados a serem escritos ou os endereços de dados a serem lidos.
A descrição dos estados que compõem a máquina de recepção núcleo é descrita abaixo:
Em o mesmo estado, o sinal txL é ativo e o sinal data_ outL recebe os endereços fonte e destino.
Quando o sinal ack_ txL é ativo passa- se para o próximo estado.
Mcmd_ i (flit 3).
O contador de flits é incrementado.
Quando o sinal ack_ txL é ativo passase para o próximo estado.
O sinal txL é desativado.
Em o momento que o sinal ack_ txL é ativo passa- se para o próximo estado.
A máquina de recepção chave recebe respostas (por a porta local da chave) às leituras previamente requisitas por o núcleo mestre, montando os pacotes de leitura.
Estes pacotes devem ser enviados a interface de rede mestre-OCP a partir de as transações descritas na Tabela 7.
Observa- se na Figura 39, que no primeiro estado descartam- se os endereços da chave fonte e destino, ou seja, apenas os dados de resposta são enviados ao núcleo com Ir-M. A descrição dos estados que compõem esta máquina é apresentada abaixo:
Em este estado, todos os sinais de saída deste módulo são inicializados em Zero.
A o detectar que o sinal rxL é ativo passa- se para o estado RS1.
OCP. Em o mesmo instante, o sinal Sresp_ o recebe um valor Nulo.
Estabeleceu- se que quando uma resposta à leitura trafega por a rede, o comando OCP associado contém o valor 9 (inválido para OCP).
Desta forma é possível separar o tráfego de requisições de leitura/ escrita do tráfego de respostas à leitura.
Caso o tráfego proveniente da rede contiver o comando 9, a máquina interpreta isto como uma resposta à leitura indo para o estado RS4.
Caso o comando for diferente de 9, isto significa um pacote direcionado a uma porta escravo, a qual não pode por definição receber este tipo de tráfego.
Assim, estes pacotes são descartados, no laço compreendido entre os estados RS5 e RS6.
O comportamento das máquinas descritas acima foram validados por simulação funcional, conforme ilustram a Figura 40.
A Figura 40 apresenta o envio de dois pacotes, um enviado a partir de transações de escrita e o outro com transações leitura (os dois primeiros flits da operação de leitura são transações de escrita, correspondendo ao endereço destino e tamanho do payload).
A descrição dos itens numerados na Figura 40 é apresentada abaixo:
A fase de requisição de escrita inicia quando no sinal Mcmd_ i recebe WR.
Em o mesmo instante, os sinais Madd_ i e Mdata_ i recebem &quot;0 «e o dado a ser escrito respectivamente.
Deve- se salientar que o sinal Madd_ i não esta sendo utilizado porque o endereço de destino é enviado por o sinal Mdata_ i.
Um ciclo de relógio depois da requisição de escrita, o sinal txL é ativo, informando a presença de flits a serem transmitidos.
Em o mesmo ciclo de relógio o sinal ack_ txL é ativo, permitindo colocar o flit no sinal data_ outL.
A chave detecta que o sinal rx da porta local esta ativo.
Em o mesmo instante o sinal data_ in recebe o conteúdo do flit.
Por conseguinte, o flit é armazenado na fila da porta local.
Um ciclo de relógio depois o sinal ScmdAccept_ o recebe o sinal auxScmdAccept, que está ativo, finalizando a fase de escrita.
Cada flit precisa de 4 ciclos de relógio para a execução desse protocolo, sendo 2 ciclos para o protocolo OCP e 2 para o protocolo da rede.
O sinal Mcmd_ i recebe RD (valor 2), iniciando a fase de requisição de leitura.
Em este caso, cada flit corresponde ao endereço de leitura do dado desejado.
Deve- se ressaltar que os dois flits anteriores a fase de requisição de leitura contém, respectivamente, o destino e o número de dados que devem ser retornados ao solicitante das leituras.
Observar que para primeira transação de leitura são necessários 7 ciclos de relógio (necessário para adição do comando OCP no pacote), sendo que para as demais utilizam- se 4 ciclos.
A chave coloca o flit no sinal data_ out e ativa o sinal tx da porta local.
Uma vez que o sinal ack_ tx está ativo o flit é removido do buffer e capturado do sinal data-inL.
O terceiro flit capturado do sinal data_ inL, com valor 0009, corresponde ao comando OCP inválido, descrito anteriormente, que indica uma ou mais respostas do escravo a uma ou mais solicitações do núcleo mestre conectado a chave.
O sinal Sresp_ o informa que existe um dado disponível no sinal Sdata_ o.
A cada resposta valida o sinal MrespAccept_ i é ativo por o núcleo conectado à chave e o dado é capturado por o mesmo.
Ir-E com a chave (porta local) e SPL refere- se aos sinais da porta local da chave.
As interfaces de rede na NoC do tipo mestre permitem a conexão de núcleos com interface de rede do tipo escravo.
Os sinais OCP que compõem uma Ir-M são descritos na Tabela 9.
A lógica responsável por a segmentação e remontagem de pacotes foi dividida em duas máquinas de estado:
Máquina de recepção chave -- recepção e envio dos flits provindos da rede através da geração de transações OCP para a Ir-E do núcleo;
E máquina de recepção núcleo que a partir de as respostas providas do núcleo com Ir-E monta os pacotes para enviar por a rede ao solicitante das mesmas.
A máquina de recepção chave recebe pacotes da rede (porta local da chave) referentes à requisições de leitura ou de escrita de dados a o/ no núcleo com Ir-E. Estes pacotes devem ser enviados a interface de rede escravo-OCP a partir de as transações descritas nas Tabela 5 e Tabela 6.
O comportamento da Ir-M responsável por a recepção e envio dos flits provindos da rede através da geração de transações OCP para a Ir-E do núcleo é ilustrado na Figura 42.
A descrição dos estados que compõem a máquina do módulo Ir-M, Figura 42, segue:
Uma vez que o sinal rxL for ativo (chegou dado da rede na porta local da chave) passa- se para o próximo estado.
Em o presente estado, os sinais source e target recebem os endereços fonte e destino, respectivamente.
Quando o sinal rxL é ativo passa- se para o próximo estado.
O sinal size recebe o flit que contém o tamanho do payload a ser enviado.
Enquanto o sinal rxL estiver desativado, permanece- se neste estado.
Em este estado, captura- se o flit que contém o comando OCP do sinal data_ inL.
Se o comando OCP associado à esse flit contém o valor 9, a máquina interpreta isto como uma resposta à leitura indo para o estado SS5.
Isto significa que este pacote deve ser excluído, pois por definição um núcleo com Ir-E não pode inicializar operações e, por conseqüente, não pode receber este tipo de tráfego.
Sendo assim, estes pacotes são descartados, no laço compreendido entre os estados SS5 e SS6.
Caso o comando for igual a WR/ RD passa- se para o estado SS4.
Em este estado, inicializa- se a fase de requisição a partir de o comando OCP contido no sinal cmdOCP, ou seja, atribuindo- se WR ou RD ao sinal Mcmd_ o.
Em o mesmo instante, o sinal Mdata_ o recebe o primeiro flit a ser transferido e incrementa- se o contador.
Fica- se nesse laço, estados SS3 e SS4, até que todos os flits do payload tenham sido enviados.
O contador de flits é incrementado.
Quando o sinal rxL é ativo passa- se para o estado SS6 (flit descartado, não enviado para o núcleo).
Em o último estado dessa máquina, o contador é incrementado até que o número de flits enviado for igual ao tamanho do payload recebido no estado SS2.
Em a máquina de recepção núcleo observa- se que para cada flit recebido por a Ir-M são necessários dois estados:
Um para capturar e informar que existe um flit a ser transmitido e outro para receber a confirmação que o flit foi transmitido à porta local da chave.
O comportamento da Ir-M OCP responsável por a montagem e envio de pacotes para rede é ilustrado na Figura 43.
Esta máquina corresponde às respostas de pedidos de leitura por algum núcleo mestre conectado à rede.
A descrição dos estados que compõem esta máquina é apresentada abaixo:
A o receber uma resposta válida (DVA) no sinal Sresp_ i e se o sinal busyMaster não estiver ativo passa- se para o estado SS1.
Uma explicação mais detalhada referente a utilidade do sinal busyMaster é apresentada Seção 4.2.4 desse Capítulo.
Em este estado, recebe- se o primeiro flit cujo conteúdo corresponde ao endereço de destino (solicitando dos dados) e o endereço do fonte (origem dos dados).
Este flit é enviado à rede através do sinal data_ outL.
Em o mesmo instante, ativa- se os sinais txL e busyMaster.
Quando o sinal ack_ txL for ativo passa- se para o próximo estado.
Em o presente estado, o sinal txL é desativado.
O sinal txL é ativo e sinal data_ inL recebe o segundo flit que contém o tamanho do payload.
Quando o sinal ack_ trxL for ativo passa- se para o próximo estado.
Em este estado, o sinal txL é desativado.
Em este estado, o sinal txL é ativo e sinal data_ inL recebe um comando interno utilizado para identificar uma resposta de leitura.
O sinal txL é desativado.
Em o último estado da máquina ativa- se o sinal txL.
O sinal data_ outL recebe o conteúdo do próximo flit.
Em o mesmo instante, o contador é incrementado até o envio de todos os flits.
Os comportamentos das máquinas descritas acima foram validados por simulação funcional, conforme ilustra a Figura 44.
SPL refere- se aos sinais da porta local da chave.
A descrição dos itens numerados na Figura 44 é apresentada abaixo:
A chave 11 coloca o flit no sinal data_ out e ativa o sinal tx (porta local).
O primeiro flit corresponde aos endereços da chave fonte e destino, respectivamente.
O módulo Ir-M detecta que o sinal rxL é ativo, informando a presença de flits a serem recebidos.
Em o mesmo ciclo de relógio o sinal ack_ txL é ativo, permitindo capturar o flit no sinal data_ inL e a conexão entre a chave e o módulo Ir-M é estabelecida.
O módulo Ir-M inicia uma transação de escrita OCP, Mcmd_ o $= '1' (observar que os dois primeiros flits foram descartados).
Em o mesmo instante, o sinal Mdata_ o recebe o flit que deve ser enviado.
O módulo QC-Slave aceita a transferência no mesmo clico de relógio, permitindo assim que o módulo Ir-M envie o flit.
Este processo ocorre até o envio de todos os flits.
O módulo Ir-M recebe um segundo pacote cujo terceiro flit indica o tipo de transação a ser efetuada, no caso transação de leitura.
Os demais flits referem- se aos endereços dos dados a serem lidos.
O módulo Ir-M inicia uma transação de leitura OCP (Mcmd_ o $= &quot;2&quot;).
O módulo QCSlave aceita a transferência no mesmo ciclo de relógio (Scmdaccept_ i $= &quot;1&quot;), permitindo assim que o módulo Ir-M envie o flit com o endereço do dado a ser lido.
Após 3 ciclos de relógio o módulo QC-Slave apresenta uma resposta válida no sinal Sresp_ i.
Depois de 6 ciclos de relógio, o módulo Ir-M está pronto para aceitar a resposta, ou seja, capturar o flit do sinal Sdata_ i no sinal data_ outL.
Este processo ocorre até que os dados desejados sejam lidos do módulo QC- Slave e enviadas por a rede até o solicitante dos mesmos.
Em este instante, a chave detecta que o sinal rx da porta local esta ativo.
Em o mesmo instante o sinal data_ in recebe o conteúdo do flit.
Por conseguinte, o flit é armazenado na fila de entrada da porta local até o estabelecimento de conexão com uma das portas de saída.
A Ir-ME é um invólucro que envolve tanto o módulo mestre (Ir-M) como o módulo escravo (Ir-E).
Sendo assim, destacam- se duas situações que devem ser consideradas no desenvolvimento do mesmo:
Disputa entre os módulos por a porta local para envio de pacotes;
E direcionamento dos pacotes provindos da rede:
Para controlar a disputa entre os módulos mestre e escravo à porta local utiliza- se um sinal que deve ser ativo toda a vez que um dos módulos tiver acesso à rede (porta local).
Este sinal é denominado de busyMaster para módulo mestre e de busySlave para o módulo escravo.
Quando um destes módulos quiser enviar dados para a rede deve- se verificar se o sinal de busy do vizinho está ativo.
Se o vizinho estiver com sinal busy em zero, o busy do mesmo deve ser ativado e mantido em nível lógico 1 até o envio de todos os flits.
Para garantir o funcionamento dessa implementação, no módulo escravo este sinal é testado na borda de subida do relógio, enquanto no mestre o teste se dá na borda de decida do relógio.
Para contornar a situação, é enviado no terceiro flit um comando OCP válido indicando que o pacote deve ser entregue ao mestre.
Caso contrário, o terceiro flit recebe um comando OCP inválido, direcionando o mesmo ao escravo.
A recepção deste comando inválido pode ser observado por a interpretação do comando '9', nas Figura 39 (estados RS 3-RS4) e Figura 42 (estados SS3 SS4).
Núcleo Núcleo respR respR Mestre IP Escravo IP Ir-ME núcleo Ir-ME núcleo cmd W/ R Mestre IP payload se cmd! $ »
09 «Mestre busyMaster respR ir-MEchave protocolo OCP busySlave W/ R Escravo IP flits do protocolo OCP Escravo cmd W/ R se cmd $= wr/ rd busySlave Escravo flit 1 flit 2 Mestre flit 3 flits porta local porta local (a) situação 1 ­ requisições de escrita (W)/ leitura (R) do módulo Mestre-IP chegando à porta local da chave no mesmo instante que uma resposta provinda do Escravo-IP.
Já na situação 2, pacotes contendo respostas/ requisições são recebidos por a porta local e divididos em flits.
Os três primeiros flits do pacote são enviados aos módulos Mestre e Escravo da Ir-ME da chave (Figura 45 (b)).
A o receber o terceiro flit cada módulo verifica o comando contido no mesmo, se esse comando for válido os flits restantes são enviados ao seu destino na Ir-ME do núcleo.
Por exemplo, se o comando (cmd) do flit 3 for igual à WR/ RD (como ilustrado na Figura 45 (b)) os demais flits (flits do payload) são enviados ao Escravo IP que está conectado ao Mestre da Ir-ME da chave.
Por sua vez, o módulo Escravo descarta os demais flits.
A Figura 46 apresenta a validação funcional da Ir-ME OCP.
A descrição dos itens numerados na Figura 46 é apresentada abaixo.
O módulo Mestre recebe uma resposta válida no sinal Sresp_ i e o dado de resposta no sinal Sdata_ i.
Em o mesmo ciclo de relógio, o módulo Escravo recebe uma requisição de escrita (Mcmd_ i $= WR) provinda do Mestre IP da Ir-ME do núcleo.
Em esse instante, o módulo Escravo ativa o sinal busySlave informando ao Mestre que a porta local esta sendo utilizada.
Por sua vez, o módulo mestre fica esperando a desativação do sinal busySlave, ou seja, a liberação da porta local.
Tendo acesso à porta local, o Escravo ativa o sinal txL, informando a presença de flits a serem transmitidos.
O primeiro dado é colocado no sinal data_ outL e após um ciclo de relógio, o sinal ack_ txL é ativo, permitindo o envio do mesmo a rede (porta local).
Após enviar todos os flits, o módulo Escravo desativa o sinal busySlave permitindo assim, que Mestre tenha acesso à porta local da chave.
Em o mesmo ciclo de relógio, o sinal txL é ativo.
Após um ciclo de relógio, o primeiro dado é enviado a rede.
Como descrito anteriormente, as IRs OCP desenvolvidas no presente trabalho foram validadas através da ferramenta CoreCreator.
Depois de executar as fases descritas na Seção 3.2.4 (página 33), a ferramenta CoreCreator gera arquivos que representam as transações OCP ocorridas entre duas entidades.
Em o contexto desse trabalho, entre uma chave da rede e um módulo QCMaster/ Slave.
Para facilitar a compreensão do relatório ilustrado na Figura 47 segue o significado de cada sigla utilizada no relatório:
SimTime-tempo de simulação;
Cycle -- tempo de ciclo válido;
CAD (Command Accept Delay) -- número de ciclos de relógios entre a solicitação de uma transação e o aceite dessa por o escravo;
RVD (Response Valid Delay) -- número de ciclos de relógios entre uma solicitação de leitura e apresentação de um dado válido (Resp $= DVA);
RAD (Response Accept Delay) -- número de ciclos de relógios entre uma solicitação de leitura e um dado é aceito (MRespAccept é ativo).
O relatório da Figura 47 prove alguns dos sinais e os valores envolvidos nas transações ocorridas para o envio/ recepção de pacotes do módulo QC- Master para/ de o (o) módulo QC- Slave (conectado a chave 11), conforme simulações ilustradas nas Figura 40 e Figura 41.
SimTime Cycle CAD Cmd Addr Data Resp RVD RAD Em o item A Figura 47 estão representadas as transações de escrita referentes ao envio do primeiro pacote (descrito na Figura 35).
Por exemplo, no tempo de simulação 2750 ns, inicia- se a fase de requisição para uma transação de escrita.
Observar no campo CAD (&quot;2&quot;), que após dois ciclos de relógio o lado escravo OCP (Ir-E da chave) aceita a transação de escrita.
A partir de as informações apresentadas no relatório acima observa- se que para a primeira transação de leitura, desde a solicitação até a recepção de uma resposta válida DVA, foram necessários 6 ciclos OCP, sendo que para as demais transações são necessários apenas 3 ciclos OCP (e.
g transação em destaque, ciclo OCP 75).
Como descrito anteriormente, estes 3 ciclos de relógio são referentes a adição do comando OCP no pacote que deve ser enviado ao seu destino, conforme ilustrado na Figura 40.
O relatório II ilustrado na Figura 48, diferencia- se do relatório anterior pois este é mais detalhado em função de a representação de todos os sinais e valores envolvidos nas transações OCP durante cada ciclo.
O item A representado na Figura 48 contém todas as transações de escritas ocorridas.
Em o relatório anterior (Figura 47), o inicio da primeira transação de escrita ocorre as 2750 ns, já no relatório II esta transação é aparece aos 2950 ns, dois ciclos de relógio referentes a latência de aceite do escravo (sinal ScmdAccept, representado no relatório II por a letra A).
Em o item B, podese observar o inicio das transações de leitura, onde o escravo OCP não aceitou a transação e os valores de resposta são inválidos (Resp $= &quot;NULL&quot;).
Por exemplo, na 75ª transação o módulo QC- Master solicita uma leitura, porém a resposta de aceite (sinal ScmdAccept ativo) ocorre 3 ciclos de relógio depois.
Por fim, o item C apresenta a recepção de valores validos e a finalização das transações de leitura.
Além de os relatórios descritos acima, salienta- se o gerado por o módulo ocpcheck.
Este não é apresentado dado a semelhança ao ilustrado na Figura 27.
A IRs OCP desenvolvidas implementam um mecanismo de controle de fluxo de dados baseado em handshake.
Ou seja, é permitido o envio de flits apenas se o receptor tiver capacidade de absorver- los o que evita a possibilidade de perda de pacotes.
As interfaces de rede descritas nesse Capítulo permitem que várias transações sejam enviadas por um mestre a um ou mais escravo (s) mesmo antes do recebimento do primeiro pacote de resposta.
De essa forma pacotes de resposta podem ser recebidos numa ordem diferente daquela em a qual os pacotes de requisição foram enviados.
Uma forma de contornar essa deficiência é a utilização de filas nas IRs que devem ser utilizadas para garantir a entrega das respostas ao núcleo na mesma ordem das requisições enviadas por o mesmo.
Como trabalho futuro cita- se também a expansão do grupo de sinais das interfaces de rede OCP.
Objetiva- se com isso, suportar a transferência de dados utilizando o modo rajada e threads, conforme especificado em.
A parametrização das chaves e a geração manual da rede a partir de estas é um processo passível de erros, devido a a grande quantidade de fios que ligam as chaves entre si e ao núcleo local, como pode ser observado na Figura 49.
Tipicamente, cada chave tem 30 canais de entrada/ saída.
A automatização deste processo foi uma das motivações para o desenvolvimento da ferramenta Maia, segunda contribuição deste trabalho.
A Maia foi desenvolvida em linguagem JAVA e seu o desenvolvimento inicial (parametrização do código VHDL) ocorreu em cooperação entre o autor desta dissertação e o doutorando José Palma (UFRGS).
Atualmente trabalham na ferramenta o autor desse trabalho, e a bolsista Aline Vieira, que atua no grupo GAPH.
Além de automatizar o processo de interconexão das chaves, a ferramenta permite a escolha do algoritmo de roteamento e a configuração de parâmetros como:
Profundidade das filas;
Largura do flit;
Dimensão da rede.
Pretende-se a partir de a configuração desses parâmetros gerar redes intra-chip que respeitem os requisitos de uma aplicação especifica.
Uma outra funcionalidade da ferramenta é a remoção de filas de entrada de canais não utilizados na chave, o que reduz a área da Hermes.
Além disso, a ferramenta gera tráfego e testbenchs, permitindo com isso validar a rede gerada.
A descrição da parametrização do código da Hermes e as funcionalidades suportadas por a ferramenta são descritas a seguir.
Para gerar uma NoC, a ferramenta Maia utiliza arquivos VHDL que descrevem a rede Hermes.
A partir destes arquivos, a ferramenta gera a estrutura da NoC desejada em função de os parâmetros definidos por o usuário.
Para que os arquivos VHDL da rede Hermes possam ser utilizados por a ferramenta, foram inseridos flags que definem os pontos do código a serem alterados por a mesma.
De entre os arquivos alterados destaca- se o Hermes_ Package_ vhd (biblioteca específica da rede Hermes).
Em esta biblioteca são inseridos os valores configurados por o usuário.
A Figura 50 apresenta um trecho do código VHDL da biblioteca Hermes_ Package.
Largura dos canais de dados Profundidade das filas Tamanho dos ponteiros de controle das filasn_ nodos chaves (nodos) subtype reg4 is std_ logic_ vector;
Tipos e sub-tipos baseados nas subtype reg5 is std_ logic_ vector;
Em este arquivo foram inseridos flags que indicam pontos onde a ferramenta deve inserir os parâmetros escolhidos por o usuário.
O arquivo Hermes_ Package_ vhd é lido por a ferramenta, que faz a substituição dos flags e grava o novo arquivo no diretório de projeto definido por o usuário.
Segue a descrição das flags inseridos no código Hermes_ Package_ vhd:
Seu valor é calculado por a ferramenta de acordo com a profundidade das filas, sendo igual a log2buff_ depht.
Em a Figura 50 também é possível observar a existência de tipos e sub-tipos cujos tamanhos são dependentes das constantes definidas nas flags.
Os demais módulos da rede intra-chip devem ter os seus sinais e portas declaradas com tipos e tamanhos baseados nas constantes geradas na biblioteca Hermes_ Package_ Vhd.
Para parametrização da chave e da fila foram inseridos flags nos arquivos Chave_ vhd (trecho de código ilustrado na Figura 52) e Fila_ vhd (trecho de código ilustrado na Figura 53).
As flags inseridas no arquivo Chave_ vhd são:
Chave, que deve ser substituído por o nome que define o tipo de chave;filas,
onde serão inseridas (mapeadas) as filas utilizadas de acordo com o tipo de chave;
Ezeros, onde são &quot;aterrados «os sinais que deveriam ser conectados às filas removidas.
A Figura 51 mostra os pontos onde ocorre a parametrização nas chaves e nas filas, ou seja, a profundidade (capacidade) das filas e a largura dos canais de dados (que também afeta a largura das filas.
Em o trecho de código mostrado na Figura 52, para a flagzeros, pode- se observar que os sinais que seriam conectados à fila leste, índice '1', são conectados à zero (&quot;aterrados&quot;).
Já no trecho de substituição ao flagfilas, observa- se o mapeamento da fila oeste, índice '0', utilizada por esta chave.
As outras filas utilizadas seriam mapeadas logo a seguir.
A Hermes_ Chave_ vhd serve como base para a geração dos diferentes tipos de chaves.
Os tipos de chaves, bem como a utilização e remoção de filas são discutidas na Seção 5.1.3.
O terceiro arquivo parametrizado foi o Fila_ vhd.
Em este arquivo não foram inseridos flags, porém, alguns trechos precisaram ser modificados.
A Figura 53 apresenta um trecho deste código.
Em este trecho pode- se observar as declarações de sinais e portas com tamanhos baseados nas constantes geradas na biblioteca Hermes_ Package_ vhd, bem como comparações utilizando estas constantes.
Antes das alterações, estes sinais e comparações utilizavam valores numéricos em vez de constantes.
Declaração das portas da entidade Fila Canais de entrada/ saída de dados baseados no tipo regflit, definido por a ferramenta na biblioteca Hermes_ Package type fila_ out is;
Sinais e comparações baseados em signal counter_ flit:
Regflit; A partir de a configuração da Chave, Seção anterior, é possível escolher a topologia mais adequada para a aplicação desejada.
Até o presente momento, a ferramenta Maia permite a geração de quatro topologias:
Malha, torus dobrado, e anel.
As topologias torus utilizam todas as portas de conexão das chaves, o que não acontece nas topologias malha e anel.
A Figura 54 ilustra um exemplo de rede intra-chip organizada sob a topologia malha.
Em esta topologia as filas não utilizadas devem ser removidas da descrição VHDL a fim de reduzir a área da rede intra-chip.
É o caso da chave presente na última coluna da última linha, que possui dois canais sem conexão (sul e oeste).
O tipo de chave é definido por a sua posição na rede.
Por exemplo, a chave mostrada na Figura 54 é classificada como ChaveBR (Bottom Right), ou seja, pertence à última linha e à coluna a direita da rede intra-chip.
Desta forma, são nove os tipos de chaves:
Top Left (Tl), Top Center (Tc), Top Right (TR), Center Left (Cl), Center (CC), Center Right (Cr), Bottom Left (BL), Bottom Center (BC) e Bottom Right (Br).
A remoção de filas não utilizadas veio a colaborar para a redução de área de chaves que não possuem conexões em todas as portas.
A Tabela 10 mostra o consumo de área de uma HERMES 3 x 3, com largura do canal de dados de 8 bits, filas com profundidade de 8 palavras, prototipada na plataforma com o FPGA XC2 V1000.
Foram feitas duas implementações dessa Hermes:
Todas as cinco filas com todas chaves, com um consumo de 57% do dispositivo;
Hermes 3 x 3 gerada por a ferramenta Maia e, portanto, sem as filas da periferia (filas removidas), obtendo- se um consumo de 42% do dispositivo.
Com base nestes dados, fica claro que a redução de área obtida com a remoção das filas sem utilização é importante, dado que a fila é o componente que mais consome área na chave.
A Figura 55 ilustra o arquivo de mais alto nível na hierarquia da rede intra-chip, denominado de NoC_ vhd.
Em este trecho de código pode- se observar os mapeamentos dos diferentes tipos de chaves e as conexões dos sinais, fazendo com que as saídas de uma chave conecte- se às entradas de outra chave adjacente.
Largura do canal de dados, definido na biblioteca HermesPackage signal signal signal signal begin rxN00, rxN01:
Exemplo de cruzamento:
A interface da ferramenta Maia é dividida em quatro blocos básicos:
Área de visualização;
Barra de parametrização da rede;
Menu; E log de processos.
Esta interface é apresentada na Figura 56.
O usuário parametriza a rede a partir de o campos encontrados na barra de parametrização (índice 2 na Figura 56).
A partir desses campos é possível configurar:
a largura do flit;
profundidade das filas de entrada das chaves;
A dimensão da rede;
A topologia.
No caso de a topologia malha o usuário pode escolher o algoritmo de roteamento para sua rede.
Com isso, tornase possível verificar o desempenho do mesmo frente a sua aplicação.
De entre os algoritmos suportados por a ferramenta citam- se:
XY puro;
West--First Minimal;
West--First NonMinimal;
E Negative-First Non-Minimal.
As particularidades inerentes a esses algoritmos de roteamento são descritos em.
A implementação de algoritmos livre de deadlock para as topologias torus e torus dobrado está em andamento.
Até o presente momento a ferramenta Maia apenas permite a geração de redes intra-chip baseadas na estrutura Hermes.
O suporte para geração de redes baseadas na estrutura da rede SoCIN também está em andamento.
Ainda na barra de configuração pode- se selecionar o tipo de testbench a ser gerado.
A ferramenta Maia suporta a geração de dois tipos de testbench:
Descrito em VHDL ou implementado com FLI.
FLI é uma interface de comunicação que permite descrever parte de um sistema em linguagem C e a outra parte em linguagem VHDL.
Em o presente caso, a rede-IP é descrita em VHDL e o testbench em C. O simulador que suporta de forma nativa esta co-simulação ModelSim.
Para facilitar o processo de simulação é gerado um script que pode ser utilizado para compilação e simulação do sistema no simulador ModelSim.
Este script informa ao simulador ModelSim a ordem de compilação dos arquivos e o tempo de simulação do sistema (rede-IP e testbench gerados).
O testbench, nos dois formatos, consiste de leituras e escritas de/ em arquivos, onde cada arquivo de entrada possui os pacotes que um núcleo deve enviar para a rede.
Os arquivos in00.
Txt, arquivo de entrada do núcleo na posição X $= 0 e Y $= 0).
Por sua vez, os arquivos de saída apresentam os pacotes que chegaram a um determinado núcleo ao qual o arquivo está associado.
Estes arquivos recebem o prefixo out mais o endereço da posição do núcleo.
Caso deseje- se utilizar outro simulador, como por exemplo o ActiveVHDL, é responsabilidade do usuário criar e hierarquizar o projeto.
A barra de menu (índice 3 na Figura 56) possui três menus:
File, Flow e Help.
O menu File possui a opção de criar um novo projeto, onde se determina o nome e o diretório de trabalho do mesmo, ou seja onde será gerada a rede-IP e o testbench (se for o caso).
O menu Flow é composto por três itens:
Traffic Generation; Simulation;
E Traffic Analyser.
O módulo Traffic Generation gera três formatos de arquivos de entrada, um para o testbech descrito em VHDL, um segundo para o testbench FLI e um terceiro no formato STL, utilizados na ferramenta CoreCreator.
A partir de a interface desse módulo, conforme ilustrado na Figura 57, é permitido escolher a dimensão da rede (parâmetro herdado da janela principal), a largura do flit (8, 16, 32 e 64 bits, também herdado da janela principal), o número de pacotes a serem enviados por cada núcleo, o número de flits por pacote, o destino dos pacotes e número de vezes que será gerado o tráfego.
O índice 1 da Figura 57 informa a geração de tráfego para 9 núcleos (dimensão 3x3), enquanto que o índice 2 informa a geração de 20 pacotes por núcleo, sendo que cada pacote será composto por 100 flits e o destino destes pacotes serão determinados aleatoriamente.
Por fim, o índice 3 da Figura 57 informa a geração de tráfego apenas para o formato FLI.
O arquivo de tráfego é um conjunto de valores hexadecimais gerados aleatoriamente por a ferramenta.
Estes valores hexadecimais são agrupados em pacotes que seguem o protocolo de comunicação especificado na Seção 4.2.
Após gerar o tráfego é possível testar o sistema através do item do menu Simulation.
A o clicar este item executam- se os scripts do testbench (no caso de a ferramenta Modelsim) e ao final desse processo são gerados os arquivos de saídas.
Devido a a complexidade de visualizar os flits de um pacote da chave origem até o seu destino, optou- se por o desenvolvimento de um módulo que permitisse analisar o tráfego da rede.
Este módulo é denominado de Traffic Analyser.
Além disso, este módulo gera um arquivo, denominado analise.
Txt, que apresenta as seguintes estatísticas:
Número de pacotes recebidos por cada nodo da rede;
Número total de pacotes recebidos;
Tempo mínimo, médio e máximo de transmissão de um pacote;
Desvio padrão do tempo de transmissão de um pacote e tempo total de transmissão de todos os pacotes.
A partir desses resultados é possível comparar diferentes configurações de redes intra-chip para um determinado fluxo de dados, como ilustrado na Figura 59.
A Figura 59 apresenta o exemplo de relatório gerado a partir de a análise de uma rede intra-chip com topologia malha de dimensão 5x5.
Outra funcionalidade apresentada por a ferramenta é a geração dos arquivos necessários para validar uma rede com IRs-OCP.
Os arquivos gerados são:
Descrição da interface OCP;
Arquivo que contém os nomes dos módulos a serem simulados;
E arquivos de tráfego baseados na sintaxe da linguagem STL (já descritos anteriormente).
O último bloco que compõe a interface da ferramenta Maia é o log de processos (índice 4 na Figura 56) que serve para informar o usuário das operações que estão sendo executadas por a ferramenta.
O produto final da ferramenta Maia consiste em redes-IP geradas automaticamente em funções das restrições da aplicação alvo, com interface de rede padronizada (se desejado por o usuário).
Com essa abordagem o usuário deve ser preocupar apenas com as conexões entre os seus núcleos e as portas da rede (como ilustrado na Figura 3, página 6).
Ou seja, todo o funcionamento e a interconexão entre as chaves podem ser assumidos como válidas.
Deve- se ressaltar, que todas as funcionalidades descritas acima, hoje suportadas por a ferramenta, foram primeiramente validadas e depois inseridas na ferramenta em questão.
Até o presente momento, foram prototipadas em FPGA redes-IP geradas por a Maia com largura de canal e flits de 8 e 16 bits.
Em o Capítulo 6, é descrito um estudo de caso que utiliza uma rede-IP gerada por a ferramenta Maia como meio de interconexão dos núcleos.
Este Capítulo descreveu as principais funcionalidades da ferramenta Maia.
Este ferramenta automatizou a geração de redes intra-chip baseadas na infra-estrutura Hermes.
A geração de redes intra-chip através da ferramenta traz os seguintes benefícios:
Redução do tempo de projeto;
Unificação das versões dos códigos dos componentes, simplificando o controle de versões;
Facilidade para geração de diferentes redes intra-chip para a mesma aplicação, permitindo explorar o espaço de soluções para o problema;
Geração automática de tráfego e de testbenchs, produzindo arquivos de teste a rede;
Verificação do tráfego na rede, ou seja, se todos os pacotes enviados são recebidos no seus respectivos destinos;
E geração do template VHDL de nível hierárquico superior, para conexão de núcleos à rede-IP.
Visando validar a interconexão e a comunicação de núcleos com interface padrão OCP via Hermes-OCP foram desenvolvidos dois sistemas como estudos de caso:
Sistema composto por quatro processadores MET21 com Ir-ME e uma rede Hermes-OCP;
E sistema com por duas memórias BlockRAM com Ir-E, um módulo serial com Ir-M, um processador com Ir-ME e uma rede Hermes-OCP.
Este sistema foi denominado de SR8-OCP.
Em este Capítulo, apresenta- se detalhadamente o estudo de caso sistema SR8-OCP.
Justificase essa escolha dado a presença dos três tipos de IRs (mestre, escravo e mestre-escravo).
Objetivase com isso, demonstrar os passos do processo de integração necessários para interconectar núcleos com interface padrão OCP à rede Hermes-OCP.
Cabe ainda salientar, que ambos os estudos e, foram prototipados na plataforma Memec Insight que contém um dispositivo FPGA Virtex-II O primeiro passo para o desenvolvimento do estudo de caso SR8-OCP foi a definição dos parâmetros, da rede Hermes-OCP.
Os parâmetros adotados para gerar essa rede com IRs OCP são:
Largura de flit igual a 16 bits;
Filas com profundidade de 8 posições;
Algoritmo de roteamento XY puro;
Topologia malha de dimensão 2x2;
e duas IRs mestre OCP, uma Ir escravo OCP e uma Ir mestre-escravo OCP.
Definidos os parâmetros da rede, e conseqüentemente, as particularidades inerentes às interfaces OCP (IRs) inicializou- se o desenvolvimento das interfaces de rede OCP de cada um dos núcleos que devem compor o sistema.
De posse da rede Hermes-OCP e dos núcleos com interface OCP o projetista (integrador do sistema) deve garantir o funcionamento do sistema como um todo, após a interconexão de todos os módulos do sistema (núcleos e a rede Hermes-OCP).
Em o presente trabalho, adotaram- se os seguintes passos para interconectar os núcleos à rede intra-chip:
Desenvolvimento de a (s) Ir (s) OCP do lado dos núcleos (ii) validação de a (s) Ir (s) OCP via CoreCreator;
Validação funcional por simulação da integração do núcleo à rede HERMESOCP e prototipação.
A Figura 60 ilustra a estrutura do sistema R 8-OCP.
O MET2 é um processador de testes programável que pode ser utilizado para gerar/ testar valores de testes pseudo-randômicos.
A descrição desse processador ser encontrada em.
Todos os núcleos que compõe a estrutura do estudo de caso em questão foram desenvolvidos no grupo de atuação.
Para cada um dos núcleos foram desenvolvidos invólucros OCP (no contexto dessa dissertação, IRs).
Cabe ainda salientar que esses invólucros foram validados através da utilização da ferramenta CoreCreator.
O núcleo básico de memória disponível no FPGA Virtex II é denominado BlockRAM, composto por 18 kbits.
Cada BlockRAM corresponde à altura de 4 CLBs, estando posicionadas nas laterais esquerda e direita do FPGA.
A Figura 61 ilustra os sinais desse núcleo, que são descritos abaixo, e os sinais da Ir-E OCP (Escravo OCP) desenvolvida.
Esta memória pode receber dados (por a Ir-E OCP) provindo de um núcleo mestre interconectado à Hermes-OCP em quatro formatos diferentes.
Os comandos suportados até o presente momento são:
Read simples;
Write simples;
Write burst modo 1; (
iv) write burst modo 2.
A memória recebe o comando read simples do núcleo que atua como mestre, no seguinte formato:
Mcmd_ i Mdata_ i endereço Onde:
Mcmd_ i informa o comando OCP da mensagem e Mdata_ i informa o endereço da memória a ser lido.
Por sua vez, a memória responde ao núcleo mestre transmitindo dados solicitados no seguinte formato:
Sresp_ o Sdata_ o Onde, Sresp_ o informa que o dado lido por o comando RD está disponível e o sinal Sdata_ o contém o dado lido.
A memória recebe o comando write simples do núcleo que atua como mestre, no seguinte formato:
Onde: Mcmd_ i informa o comando OCP da mensagem.
O sinal Mdata_ i recebe na ordem:
Endereço do núcleo origem da mensagem (fonte);
o comando da mensagem, sendo que o comando write simples é identificado por o valor 1 (um);
o endereço da memória onde o dado será escrito;
E o dado a ser escrito.
A memória recebe o comando write burst modo 1 de um núcleo que atua como mestre, no seguinte formato:
Onde: Mcmd_ i informa o comando OCP da mensagem.
O sinal Mdata_ i recebe na ordem:
Endereço do núcleo origem da mensagem (fonte);
o comando da mensagem, sendo que o comando write burst modo 1 é identificado por o valor 3 (três).
Este comando possibilita que N dados sejam escritos a partir de a informação do número de pares endereço-dado;
O terceiro flit contém o número de dados a serem escritos (nword);
o quarto flit contém o endereço da memória onde será escrito o primeiro dado;
Flit contendo o primeiro dado a ser escrito.
Os próximos pares de flits correspondem a um endereço e o dado a ser escrito.
O comando write burst modo 2 possibilita que N dados sejam escritos a partir de a informação de um endereço inicial, onde N é o número de dados a serem escritos.
A memória recebe o comando write burst modo 2 de um núcleo que atua como mestre, no seguinte formato:
Onde: Mcmd_ i informa o comando OCP da mensagem.
O sinal Mdata_ i recebe na ordem:
Endereço do núcleo origem da mensagem (fonte);
o comando da mensagem, sendo que o comando write burst modo 2 é identificado por o valor 4 (quatro);
o terceiro flit contém o número de dados a serem escritos (nword);
o quarto flit contém o endereço inicial da memória onde serão escritos os dados;
Flit contendo o primeiro dado a ser escrito.
Os próximos flits correspondem a um dado que deve ser escrito.
A Máquina de estados responsável por a implementação dos 4 comandos descritos acima é apresentada no Anexo I, Figura 85.
Os sinais dispostos na parte superior da Figura 67 fazem interface com o computador hospedeiro, que envia e recebe dados bit a bit.
Os sinais dispostos na parte inferior da figura fazem interface com o sistema, que envia e recebe dados byte a byte.
Abaixo segue uma breve explicação sobre cada um dos sinais ilustrados na Figura 67.
A Serial foi envolvida por um invólucro que contém uma interface mestre OCP, conforme ilustrado na Figura 67.
O núcleo Serial_ OCP recebe dados a partir de um programa executando num computador hospedeiro (denominado software serial).
São cinco os formatos permitidos, dependendo do comando recebido.
Estes comandos são:
Read simples;
Write simples;
Write burst modo 1, write burst modo 2;
e reset.
Onde: Comando, sendo read simples identificado por o valor 0 (zero);
endereço de destino da mensagem;
Endereço interno ao núcleo onde será realizada a leitura.
O formato da mensagem transmitida da Serial_ OCP para um núcleo escravo é ilustrada na Figura 69: Mcmd_ o Mdata_ o fonte/ destino tamanho endereço o um núcleo escravo.
Onde: O primeiro flit (fonte/ destino) informa o endereço do núcleo origem (núcleo Serial_ OCP) nos 8 bits mais significativos e o endereço do núcleo destino nos 8 bits menos significativos;
O segundo flit (tamanho) informa o número de flits do payload;
e finalmente o último flit informa o endereço interno ao núcleo onde será realizada a leitura.
Por sua vez, o núcleo Serial_ OCP recebe dados do escravo no seguinte formato:
Onde: Sresp_ i informa que o dado de retorno da leitura está disponível e Sdata_ i contém o dado referente a leitura.
Onde: Data High indica os 8 bits mais significativos do dado lido e data Low informa os 8 bits menos significativos do dado lido.
Onde: Comando, refere- se ao write simples identificado por o valor 1 (um);
o endereço de destino da mensagem;
Endereço interno ao núcleo onde será realizada a escrita;
E o dado a ser escrito.
Onde: O primeiro flit (fonte/ destino) informa o endereço do núcleo origem (núcleo Serial_ OCP) nos 8 bits mais significativos e o endereço do núcleo destino nos 8 bits menos significativos;
O segundo flit (tamanho) informa o número de flits do payload;
o terceiro flit informa o comando da mensagem;
O quarto flit informa o endereço interno ao núcleo onde será realizada a escrita;
O dado a ser escrito.
Onde: Comando write burst modo 1 é identificado por o valor 3 (três);
o segundo flit corresponde ao endereço do núcleo destino da mensagem;
O terceiro flit (nword) informa o número de flits a serem escritos;
O quarto flit informa o endereço interno ao núcleo onde será realizada a escrita;
E o dado a ser escrito.
O núcleo Serial_ OCP transmite o comando write burst modo 1 para o escravo no seguinte formato:
Onde: O primeiro flit (fonte/ destino) informa o endereço do núcleo origem (núcleo Serial_ OCP) nos 8 bits mais significativos e o endereço do núcleo destino nos 8 bits menos significativos;
O segundo flit (tamanho) informa o número de flits do payload;
a terceira transação transmite o endereço interno ao núcleo onde será realizada a leitura;
Nword informa o número de dados a serem escritos;
O endereço 1 corresponde ao endereço interno do núcleo onde será realizada a escrita;
E finalmente o dado a ser escrito.
O núcleo Serial_ OCP recebe o comando write burst modo 2 do software serial no seguinte formato:
Onde: Comando write burst modo 1 é identificado por o valor 4 (quatro);
o segundo flit corresponde ao endereço do núcleo destino da mensagem;
O terceiro flit (nword) informa o número de flits a serem escritos;
O quarto flit informa o endereço interno ao núcleo onde será realizada a escrita;
E o dado a ser escrito.
O núcleo Serial-OCP transmite o comando write burst modo 2 para o escravo no seguinte formato:
Onde: O comando é identificado por o valor 5 (cinco) e o destino informa o endereço do núcleo destino a receber a mensagem.
O núcleo Serial_ OCP transmite o comando reset para o escravo no seguinte formato:
Este comando é enviado por o computador hospedeiro para a inicialização do processador O núcleo R8_ OCP é composto por 4 módulos:
Memória interna (RAM), (ii) processador R8, interface Mestre OCP, e interface Escravo OCP.
O principal módulo desse núcleo é o processador R8 que é uma organização Von Neumann (memória de dados/ instruções unificada), load/ store, com CPI entre 3 e 4, barramento de dados e endereços de 16 bits.
Esta arquitetura é praticamente uma máquina RISC, faltando, contudo, algumas características gerais de máquina RISC, tal como pipeline e módulos de entrada/ saída, como tratamento de interrupções.
O projeto da arquitetura, desenvolvido em VHDL, compreende a descrição de dois blocos principais:
O bloco de controle e o bloco de dados.
O bloco de controle tem por função gerar os comandos para a busca das instruções e envio de comandos ao bloco de dados para que a instrução seja executada.
O bloco de dados contém 16 registradores de uso geral;
Registradores para armazenamento da instrução corrente (Ir), endereço da próxima instrução a executar (PC) e ponteiro de pilha (SP);
Uma ULA (Unidade Lógica e Aritmética) com 13 operações e 4 qualificadores de estado.
A funcionalidade dos sinais do processador R8 é descrita abaixo:
Ck: Sincroniza os sinais internos ao processador.
A interface Mestre OCP é conectada ao processador enquanto a interface Escravo OCP é conectada à RAM interna.
A Figura 80 ilustra os quatro componentes que compõe o invólucro R8_ OCP.
O núcleo R8_ OCP é inicializado a partir de a recepção do comando reset que é recebido através da de o módulo Escravo OCP que ativa o sinal ResetR8.
Além de os 4 módulos que compõe o núcleo R8 OCP destacam- se um módulo constituído de lógica de controle e três multiplexadores:
Mult2; mult3;
mult4; sendo estes representados, respectivamente, por os índices 2, 3 e 4 da Figura 80.
O mult2 é utilizado para verificar se o dado a ser escrito na RAM é o provido por a R8 (dado local) ou o recebido por o módulo Escravo OCP (dado remoto).
O mult3 possui uma funcionalidade semelhante ao mult2, sendo que ao invés de o dado seleciona- se o endereço de escrita ou de leitura.
Por sua vez, o mult4 verifica se os dados de leitura que estão chegando, provêm da memória local (RAM) ou de algum núcleo do tipo escravo conectado a rede (através do módulo Mestre OCP).
O item 5 e 6 da Figura 80, são utilizados para delegar acesso de escrita ou leitura local ou remota através do módulo Escravo OCP (outro núcleo do tipo mestre conectado a rede).
Esta Seção apresenta a validação dos núcleos Serial_ OCP, BlockRAM_ OCP e o R8_ OCP com a Hermes-OCP descrita na Seção anterior.
A primeira etapa do processo de execução corresponde ao envio de um programa de teste do processador R8, através da utilização do programa serial, conforme ilustrado na Figura 81.
O núcleo Serial OCP recebe os dados do programa serial, enviando- os ao núcleo R8 OCP.
Este programa é recebido por o módulo Escravo OCP do núcleo R8 OCP e escrito a partir de o endereço 0x0000 na memória local (RAM) do processador R8.
O programa de teste é ilustrado na Figura 82.
O programa de teste é composto de dois laços.
O primeiro laço é responsável por ler o próprio programa de teste da memória local (RAM), enviando- o para o núcleo BlockRAM_ OCP, via o módulo Mestre OCP (linhas 18 a 24 do código acima).
Após a escrita na memória remota, gera- se um pacote que contém solicitações de leitura para a BlockRAM_ OCP, linhas 30-32.
Após estas linhas, inicia- se o segundo laço, que corresponde à leitura dos valores da BlockRAM_ OCP a partir de o endereço 0x0000 até o 0x0014, gravando- se os mesmos na memória local (RAM) à partir do endereço 0x0050h, linhas 34-40.
O programa grava os dados usando o comando write burst e lê usando o comando read simples.
LDL R1,&amp; FFh LDH R1,&amp; FFh LDL R2,&amp; FEh LDH R2,&amp; FFh LDL R3,&amp; 10h ldl R9,&amp; 21h LDL R5,&amp; 24h LDL R8,&amp; 01h LDL R11,&amp; 50h;
Envia Para A Rede O Comando (Write Burst2) o dado corresponde ao próprio programa para a BLOCKRAM.
A segunda etapa do processo de execução corresponde à inicialização do processador, através do envio do comando de reset para o processador R8, por o núcleo Serial_ OCP.
Após a recepção do comando de reset, o processador executa o programa descrito acima.
A o final da execução, o núcleo Serial_ OCP realiza a leitura da memória local (RAM), a partir de o endereço 50 H, verificando a igualdade entre os valores lidos e os valores originais.
A Figura 83 apresenta o núcleo Serial_ OCP enviando flits para a Hermes-OCP (rede-IP).
Estes flits são direcionados ao núcleo R8_ OCP, a Figura 83 apresenta apenas a recepção e envio dos flits da chave 10.
O núcleo Serial OCP recebe os flits do programa serial.
A existência de dados é indicada por o sinal tx_ av $= &quot;1 «e por os dados no sinal tx_ data.
São necessários 6 ciclos de relógio para recepção de cada dado (flit).
O núcleo Serial OCP inicia as transações de escrita OCP.
Em esse instante, o sinal Mcmd_ o recebe o valor &quot;1 «e o sinal Mdata_ o recebe os flits que devem ser enviados a rede.
Após alguns ciclos de relógio a Ir-E (Escravo OCP) do núcleo R8_ OCP recebe o pacote enviado por a Serial_ OCP.
A Figura 84 ilustra a recepção por parte de o R8_ OCP e a inserção dos dados na memória local (RAM).
O sistema em questão foi prototipado na plataforma de prototipação Memec Insight que contém um dispositivo FPGA Virtex-II 1000 de um milhão de portas lógicas num Ci de 456 pinos.
Além disso, a plataforma oferece também uma memória DDR (Double Data Rate) de 16M x 16 bits, uma PROM XC18 V04 de 4 MBits, duas fontes de relógio (uma de 24 MHz e outra de 100 MHz), uma porta RS-232 serial e conector de 160 pinos para permitir acrescentar módulos especiais.
Junto à plataforma, existe uma interface LVDS (Low-- voltage Differential Signaling) que provê transmissão de dados de 16 bits em alta velocidade.
Para validar este sistema utilizou- se o ChipScope, da Xilinx.
ChipScope permite a visualização dos sinais internos do FPGA selecionados por o usuário em tempo de execução.
A redeIP com topologia malha de dimensão 2X2 (duas BlockRAM com Ir-E OCP) foi sintetizada usando a ferramenta de síntese Leonardo Spectrum.
A Tabela 11 apresenta os dados de área gerados por síntese, mostrando o uso dos recursos do FPGA e para ASIC.
O presente trabalho discutiu o problema de integração de núcleos em dois aspectos:
Estruturas de interconexão e integração de núcleos com interfaces externas padrão.
Com isso foram descritas as estruturas de interconexão utilizadas para interconexão de núcleo em SoCs com ênfase em redes intra-chip.
Além de apresentar os conceitos básicos inerentes a essa abordagem de interconexão, relatou- se o estado da arte de redes intra-chip.
Em o que tange a questão de interfaceamento de núcleos enfatizou- se o estudo do protocolo de comunicação padrão OCP.
A partir de os resultados obtidos acredita- se que o presente trabalho contribui para o avanço em duas áreas de pesquisa de relevância tanto no meio acadêmico como na indústria:
Interfaces padrão de comunicação e redes intra-chip.
De essa forma citam- se as contribuições deste trabalho:
Redução de área da rede através da remoção das filas não utilizadas;
Parametrização da Hermes;
Desenvolvimento das interfaces de rede OCP (mestre, escravo, mestre-escravo) para a rede Hermes;
Unificação das contribuições citadas anteriormente através da ferramenta Maia;
Descrição de um estudo de caso de desenvolvimento de SoC com a rede Hermes-OCP prototipada em FPGA.
Além de as contribuições citadas acima, este trabalho trouxe ao grupo uma experiência no campo de protocolos de comunicação padrão, enfatizando o OCP.
Dentro deste contexto, pode- se citar a certificação de núcleos com interface OCP frente a o fluxo da ferramenta CoreCreator como uma dificuldade encontrada no desenvolvimento do presente trabalho.
A prototipação em FPGA foi outra dificuldade encontrada.
Mesmo havendo uma simulação funcional perfeita, podem ocorrer casos em que o sistema simplesmente não funciona no FPGA.
Situações como não inicialização de máquinas de estado, não inicialização de registradores, atribuições onde não se consideram todos os casos possíveis (ocasionando o warning latch infered), freqüência do relógio da placa superior à freqüência de operação do circuito, por exemplo, são problemas difíceis de detectar e ocasionam atrasos no desenvolvimento do projeto.
A fase de prototipação é imprescindível a qualquer projeto de sistemas computacionais, pois prova que o sistema realmente funciona no hardware e não é apenas um conjunto de formas de onda num simulador.
Como trabalhos futuros citam- se:
Estudar técnicas para suporte a QoS, e garantir entrega ordenada de dados no caso de concorrência;
Ampliar o número de comandos suportados por as IRs OCP;
Inserir na ferramenta Maia a possibilidade de gerar trafego real (e.
g trafego streaming) para aplicações de SoCs, como decodificação de vídeo ou imagem;
Pesquisar e implementar novos algoritmos de roteamento que sejam imunes a deadlock.
