Esta dissertação aborda a utilização de módulos de hardware pré-projetados e pré-verificados, cores, na implementação de sistemas computacionais integrados num único circuito integrado ­ SoC (do inglês, System-on-a-Chip) ­ para dispositivos FPGAs.
O estudo relativo ao estado-da-arte na utilização de cores apresenta:
Características dos cores;
Integração de cores em SoCs;
Problemas relativos ao desenvolvimento e utilização de cores;
Ferramentas para parametrização de cores;
E distribuição de cores através da Internet.
Duas ferramentas desenvolvidas são apresentadas.
A primeira tem como objetivo sistematizar a organização das informações contidas nos projetos, de forma a facilitar sua distribuição através da Internet.
A segunda ferramenta realiza a reconfiguração de hard cores, permitindo que o usuário tenha uma maior flexibilidade para adaptar cores já sintetizados a seus projetos.
A distribuição de cores via Internet e a possibilidade de reconfiguração de dispositivos programáveis requer uma estrutura de comunicação que permita a estes cores trocarem informações.
A maior contribuição deste trabalho é propor uma estrutura de barramento intraFPGA para comunicação entre cores.
Este barramento permite que cores possam ser inseridos, removidos ou substituídos sem afetar o funcionamento do resto do sistema em execução no FPGA.
Desta forma, torna- se realidade o conceito de &quot;hardware virtual», onde reside no dispositivo programável apenas o hardware que está sendo executado, sendo alocado sob a demanda de utilização, da mesma forma que hoje é utilizado o conceito de memória virtual em sistemas operacionais.
Palavras-chave: Cores, distribuição de cores, prototipação, reconfiguração, reuso, FPGAs, SoC.
O avanço tecnológico na construção de sistemas computacionais é tal que permite hoje implementar microprocessadores com 40 milhões de transistores.
O ritmo desses avanços da tecnologia de fabricação tem se mantido exponencial nas últimas décadas, conforme a Lei de Moore.
Esta lei é devida a Gordon E. Moore, que em 1965 observou que a densidade de componentes em circuitos integrados dobrava a intervalos regulares, inferindo que este comportamento perduraria por muito tempo ainda.
O intervalo medido por Moore para que a densidade média dos circuitos integrados dobrasse foi de 18 meses, o que ainda hoje permanece uma taxa estável.
Porém, o mercado atual de semicondutores não é caracterizado apenas por a elevada complexidade dos sistemas, mas também por o curto time- to-- market (tempo até que um novo produto chegue ao mercado), alto desempenho e baixo consumo de potência.
É neste contexto que entram em cena os cores, módulos de hardware complexos précaracterizados, usados no desenvolvimento de sistemas computacionais integrados num único circuito integrado (SoC ­ System-on-a-chip).
Somente através do reuso destes componentes é possível atingir as exigências do mercado atual e reduzir a distância entre a quantidade de recursos disponíveis e a produtividade das equipes de projeto.
Desta forma, o projetista pode concentrar- se no sistema completo sem ter que se preocupar com a funcionalidade interna e externa ou com o desempenho de componentes individuais.
Conforme as estimativas da indústria de semicondutores, o percentual de reuso em CIs será de 90% em 2012.
Porém, a construção de SoCs através do reuso de cores ainda é um processo manual e bastante complicado, devido a a ausência de ferramentas e padrões préestabelecidos por a indústria.
Projetar um core para ser reutilizado não é simplesmente isolar um módulo já pronto.
Construir um core reutilizável leva de 2 a 2,5 vezes o esforço de construção de um projeto normal.
Este esforço, porém, é recompensado quando o core é reutilizado, pois haverá uma redução do time- to-- market, resultante da reutilização do core, e uma redução dos custos de desenvolvimento.
Além disso, para que um core seja reutilizado, ele deve ser codificado de maneira a facilitar o reuso, precisa ser bem documentado, e estar acompanhado de recursos de modelagem abstrata e teste (testbenches), para que o usuário possa validar o sistema que utiliza o core.
O objetivo principal deste trabalho é propor métodos para a distribuição e para a conexão de cores para dispositivos programáveis tipo FPGA.
A idéia é permitir que usuários possam buscar cores na Internet e executar- los no dispositivo FPGA, comunicando- se uns com os outros, e que determinado core possa ser removido, quando seu uso não for mais necessário, para que outro seja inserido em seu lugar.
Para que esta idéia seja posta em prática, é necessário atender alguns requisitos.
O primeiro trata da distribuição de cores através da Internet.
Existe a necessidade da existência de uma ferramenta que auxilie o projetista na organização e distribuição de seus projetos, mas que também proteja seus direitos autorais.
Como segundo requisito, é necessário um ambiente que permita a reconfiguração parcial de FPGAs, para que seja possível a inserção e remoção de hard cores no sistema.
Tal ambiente também deve ser usado para parametrizar os hard cores, de forma a adaptar- los ao projeto do usuário.
O terceiro requisito diz respeito à uma interface de conexão e comunicação entre os cores em execução no FPGA que permita a inserção e remoção de cores sem afetar o funcionamento do resto do sistema.
A Figura 1 ilustra os requisitos da abordagem proposta, os quais devem convergir no objetivo principal do trabalho.
Este volume está organizado da seguinte maneira.
Em o Capítulo 2 é feita uma revisão das características de cores, dos sistemas integrados num único circuito integrado e dos problemas encontrados na utilização de cores.
A o final, o Capítulo mostra ferramentas para parametrização e distribuição de cores.
Em o Capítulo 4 é feito um estudo da arquitetura Virtex e da ferramenta de Floorplanner (editor de planta-baixa), requisitos necessários para que seja possível a reconfiguração de parte do dispositivo de forma a inserir ou retirar cores do sistema.
Em este Capítulo também é apresentado o desenvolvimento de uma ferramenta para reconfiguração de hard cores.
Finalmente, o Capítulo 6 apresenta as conclusões deste trabalho e direções para trabalhos futuros.
Em este Capítulo, na Seção 2.1, é feita uma revisão do estado da arte em cores caracterizando- os (soft, firm e hard).
A Seção 2.2 trata do projeto integrado de cores num único circuito integrado (SoC), e a Seção 2.3 mostra o fluxo de projeto utilizando cores.
Após, na Seção 2.4, são identificados os desafios encontrados quando se implementam cores, tais como a integração dos cores, a escolha das linguagens para descrição de sistemas que serão utilizadas, a proteção da propriedade intelectual do autor e do usuário do core e os testes dos projetos de cores.
Finalmente, na Seção 2.5, são apresentadas algumas ferramentas para personalização de cores e, na Seção 2.6, são analisados alguns web sites de fornecedores de cores através da Internet, para que se possa avaliar a maneira como a distribuição de cores é feita.
Definição de Cores Um core é um módulo de hardware complexo, digital ou analógico, podendo ser descrito em diferentes níveis de abstração.
Estes cores são pré-projetados, pré-verificados (por simulação funcional e back annotation) e prototipados em hardware pelo menos uma vez.
Os cores são usados para construir aplicações maiores e mais complexas num dado circuito integrado.
Como exemplos de cores pode- se citar:
Memórias, processadores e barramento PCI.
Os principais desafios enfrentados por projetistas e usuários de cores são:
Como usar cores projetados por terceiros com o menor esforço possível de projeto;
Como garantir a exatidão funcional do produto final;
Como garantir a testabilidade do sistema desenvolvido.
Dado o fato de que estes módulos &quot;contêm «o conhecimento dos projetistas (que geralmente são proprietários dos cores), freqüentemente estes componentes são submetidos à patentes e direitos de propriedade.
Em outras palavras, um core representa uma propriedade intelectual disponibilizada por o proprietário deste ao usuário do mesmo.
Quanto a a sua disponibilização, pode- se classificar um projeto de core como sendo licenciável ou proprietário.
Um core licenciável é aquele em que o proprietário licência um projeto e um conjunto de ferramentas conferindo a tarefa de projeto do sistema e sua fabricação ao usuário.
Um core proprietário é aquele em que a preocupação principal do proprietário é proteger sua propriedade intelectual, resultando em baixo risco de propriedade intelectual, já que estes disponibilizam apenas a interface externa ao usuário.
Quanto a a forma de disponibilização, os cores podem ser classificados em 3 categorias:
Hard cores:
São otimizados para uma tecnologia específica e não podem ser modificados por o projetista.
Estes cores possuem um layout e planta baixa (floorplanning) prédefinidos.
Possuem como maior vantagem a garantia dos tempos de propagação do circuito (timing).
Sua desvantagem é a de não permitir qualquer tipo de modificação ou personalização.
Firm cores:
Netlist (lista de conexões) gerado para a tecnologia empregada, que muda de fabricante para fabricante.
Este tipo de core pode ser parcialmente parametrizado por o projetista, permitindo que sua arquitetura seja adaptada à necessidade do projeto.
Entretanto, como o netlist é específico para uma dada tecnologia, existe a dificuldade do uso de componentes fornecidos por fabricantes diferentes.
Soft cores:
Descritos em linguagens de descrição de hardware (como VHDL ou Verilog), oferecendo flexibilidade e independência de tecnologia.
O core pode ser modificado e empregado com tecnologias de diferentes fabricantes.
Contudo, os soft cores apresentam como desvantagens:
A não garantia de se atingir os critérios temporais do circuito, uma vez que este ainda não foi sintetizado;
A baixa proteção à propriedade intelectual, uma vez que o core é código aberto.
A Figura 2[ MAD97] ilustra uma arquitetura genérica de um SoC.
Os cores são integrados através de uma rede de interconexão comercial ou adaptada, com um controlador e funções de interface com o meio externo.
Caso os cores sejam obtidos de diferentes fontes a integração dos módulos e o teste do sistema podem ser difíceis, podendo até haver necessidade de que os cores sejam reprojetados, para adequar- los a um protocolo de interface comum.
Em a prática, montar um SoC usando cores é ainda um processo passível de erro que exige trabalho intensivo e consome bastante tempo.
O projeto de criar um SoC usando apenas cores ainda não se tornou realidade por várias razões, entre as quais:
Planejar o sistema é uma tarefa complexa, que requer que os projetistas respondam a questões como qual CPU deve ser usada, que funções devem ser feitas em hardware e/ ou software, etc..
A integração dos cores num SoC é ainda um processo amplamente manual e passível de erro, exigindo que os projetistas entendam bem a funcionalidade, as interfaces e as características elétricas de cores complexos, como microprocessadores, controladores de memória, etc..
Atender a todas as restrições de tempo é muito difícil, devido a a complexidade do sistema.
Em muitos casos, isto requer que os cores sejam adaptados, o que afeta sua reusabilidade.
O projeto físico de sistemas complexos exige ferramentas de CAD de alto desempenho.
Mesmo se a planta-baixa de cada core é pré-definida, colocar- los juntos com roteamento pode causar efeitos indesejados, tais como capacitância de acoplamento que degradam o desempenho.
A verificação do sistema é um dos maiores gargalos do projeto.
Mesmo se os cores são pré-verificados, não significa que todo o sistema funcionará quando eles forem colocados juntos.
Verificação formal, no atual estado da arte, bem como técnicas de simulação de software não têm capacidade ou velocidade para manusear grandes sistemas em tempo hábil.
A ausência de padrões de interface de cores pré-estabelecidos para a indústria e a ausência de ferramentas de síntese de interface eficientes tornam difícil que cores de diferentes fornecedores sejam integrados no mesmo SoC.
A integração hardware-- software é outro grande problema que afeta diretamente o time-- tomarket por que é, geralmente, feita mais tarde no processo de projeto, quando a parte de hardware está estável.
Depois que as principais decisões arquiteturais tenham sido tomadas, a primeira tarefa na construção de um SoC é a integração dos cores num nível mais alto de hierarquia, que pode então ser simulado funcionalmente, sintetizado, ter sua planta-baixa definida e, desde cedo, usado no desenvolvimento do software do sistema.
Esta tarefa de integração requer que o projetista entenda a funcionalidade de centenas de pinos em vários cores e determinar quais de eles devem ser conectados juntos.
Além de o mais, cores são geralmente parametrizados e precisam ser configurados de acordo com o uso no SoC.
O trabalho que vem sendo feito por a VSI Alliance tem como objetivo definir padrões para a integração de cores.
Os atuais sistemas de CAD não são orientados ao uso de cores, pois concentraram- se nas etapas de síntese lógica, síntese física e análise da temporização.
Alguns ambientes de CAD, como Archimate ou Polis modelam os sistemas computacionais em níveis mais abstratos que linguagens de descrição de hardware, porém não são orientados ao uso de cores.
A o nosso conhecimento, não existem ferramentas comerciais de software que possibilitem ao projetista construir um SoC, integrando e configurando cores facilmente.
A complexidade dos SoCs atuais e a falta de ferramentas de alto nível apropriadas fazem do reuso uma técnica de implementação ainda distante da realidade dos projetistas.
Fluxos de Projeto Usando Cores Esta Seção apresenta o fluxo tradicional de projeto de sistemas baseado em firm cores.
O fluxo de projeto consiste de três estágios:
Captura, implementação e verificação.
Este fluxo de projeto é mostrado na Figura 3.
Captura do Projeto Durante a fase de captura, o projeto de aplicação do usuário é desenvolvido utilizando, preferencialmente, linguagens de descrição de hardware.
É também descrito o nível mais alto da hierarquia do projeto, o qual integra o firm core à aplicação do usuário.
O firm core é tratado como uma &quot;caixa preta», não sendo um elemento sintetizável.
Freqüentemente, o projetista do core disponibiliza um modelo funcional que pode ser simulado com a descrição HDL que instancia o core, permitindo assim verificar a funcionalidade do sistema completo (esta etapa é realizada na verificação do projeto).
Implementação do Projeto O segundo estágio é o de implementação.
Durante este estágio, tarefas de tradução e síntese (posicionamento e roteamento) são executadas.
Como os firm cores são dependentes de uma dada tecnologia, eles são fornecidos juntamente com um conjunto de restrições de síntese procurem atender aos requisitos temporais e de área, fixando a posição dos elementos do core e o roteamento dos caminhos críticos.
A integração do core com a aplicação do usuário é feita através de tarefas de tradução, unindo- se netlists oriundos da síntese do projeto do usuário e de o (s) core (s) utilizado (s).
A união de o (s) core (s) com a aplicação do usuário pode fazer com que o sistema como um todo não atenda às restrições de área e atraso.
Algumas técnicas são empregadas para garantir a temporização do circuito:·
Inserir restrições no projeto do usuário.
Similar às restrições fornecidas por o firm core, as restrições aplicadas ao projeto do usuário podem forçar uma determinada localização dos blocos lógicos ou impor limites para o atraso em determinados caminhos.
O método recomendado para inserir restrições é realizar uma síntese preliminar do sistema sem qualquer restrição, utilizando apenas as restrições fornecidas por o core.
A análise estática de temporização indicará a margem de atraso permitida ao projeto do usuário, possibilitando assim inserir- se as restrições necessárias.·
Realizar a planta baixa do sistema (floorplaning), posicionando manualmente blocos críticos próximos uns dos outros, minimizando desta forma atrasos causados por o roteamento.·
Caso as técnicas acima, restrições de temporização e planta baixa não forem efetivas, deve- se modificar a aplicação do usuário.
Um exemplo de modificação comum é a inserção de estágios de pipeline.
Embora isto possa aumentar a latência do projeto, o throughput total aumentará.
O resultado da fase de implementação é um arquivo contendo a descrição física do sistema, ou seja, aplicação do usuário mais o (s) core (s) utilizado (s).
Esta descrição física contém a disposição dos blocos lógicos, o roteamento entre eles e informações de elementos parasitas (capacitâncias de roteamento), necessários à etapa posterior, a verificação do projeto.
Verificação do Projeto O terceiro estágio do fluxo de projeto é a verificação.
Este estágio consiste de duas etapas principais:
Análise de timing e simulação funcional.
A verificação do projeto deve ser feita minuciosamente, e uma pesquisa ampla dos caminhos críticos pode indicar ao projetista onde ele pode aumentar o desempenho.
A etapa de análise de timing realiza a análise estática da temporização, determinando se o projeto atende ou não o desempenho desejado, através da análise dos caminhos críticos do circuito.
Uma forma de guiar as ferramentas utilizadas por sistemas de CAD, como por exemplo o Xilinx Foundation, é inserir restrições de temporização para caminhos críticos, através dos parâmetros TIMESPEC (timing specification).
Estas restrições são utilizadas por a síntese física, gerando- se mensagens de erro caso não seja possível sintetizar o sistema com as restrições impostas.
A simulação funcional verifica a temporização detalhada do sistema, podendo ser funcional ou detalhada.
A simulação funcional é feita durante a etapa de captura do projeto, utilizando atraso zero (ou unitário).
A simulação funcional detalhada utiliza dados provenientes da síntese física, como elementos parasitas de roteamento (back annotation).
Quaisquer conexões adicionais que não foram incluídas nas restrições de temporização também podem ser inspecionadas durante a análise estática, porém podem não atender necessariamente às especificações determinadas por o projetista, uma vez que estas não são &quot;vistas «por a síntese física.
É importante restringir todos os caminhos críticos, a fim de permitir que a ferramenta de posicionamento/ roteamento determine o lugar mais eficiente e mais otimizado para os componentes do projeto.
O modelo tradicional de fluxo de projeto para SoCs, mostrado na Figura 3, é freqüentemente chamado de modelo cascata.
Em este modelo, a transição de fase para fase nunca retorna às atividades da fase anterior.
Assim, o projeto é passado de uma equipe responsável por uma fase, para outra responsável por a fase seguinte, sem que haja muita interação entre elas.
Para grandes projetos esta metodologia simplesmente não funciona.
Grandes projetos têm um conteúdo de software suficiente para que haja a necessidade de se desenvolver o hardware e o software concorrentemente para assegurar a funcionalidade correta do sistema.
Questões físicas devem ser consideradas no início do projeto para assegurar que o desempenho desejado seja também alcançado.
À medida que a complexidade aumenta, o modelo cascata está sendo substituído por um novo modelo, chamado de espiral.
Em o modelo espiral, as equipes de projeto trabalham em múltiplos aspectos do projeto simultaneamente, refinando o projeto a cada etapa.
A Figura 4 mostra o fluxo de projeto em espiral.
Projeto e Verificação do Sistema Especificação física:
Área, potência, projeto da ramificação do clock Especificação de temporização:
Este fluxo é caracterizado por:
Desenvolvimento de hardware e software concorrentemente;
Os projetistas desenvolvem simultaneamente as especificações do sistema, algoritmos para os sub-blocos críticos, verificação em nível de sistema, e as restrições de temporização para a integração final do chip.
Isto significa que todos os aspectos do desenvolvimento de hardware e de software são trabalhados concorrentemente:
Funcionalidade, temporização, projeto físico e verificação.
Desafios Para a Implementação de Cores Apesar de as vantagens inerentes à utilização de cores, identificam- se quatro grandes problemas que devem ser resolvidos para que se possa construir facilmente um SoC, e que serão abordados nas Seções seguintes.
São eles:
Como integrar cores;
Quais linguagens para descrição de sistemas serão utilizadas;
Como proteger a propriedade intelectual do autor e do usuário do core;
Como testar os projetos baseados em cores.
Existem várias entidades trabalhando na padronização de cores, como por exemplo a IEEE e a VSIA.
O grupo IEEE P1500 tem por objetivos:
Desenvolver uma linguagem de descrição de teste de cores, um mecanismo de controle de teste, e um mecanismo de acesso a dados do core.
Estes três objetivos concentram- se na interface de teste entre um core e o restante do sistema ao seu redor.
Não são padronizados os métodos de teste internos ao core e o teste de todo do sistema.
A maioria dos usuários prefere usar as soluções de sua propriedade para estes testes.
A VSIA ­ Virtual Socket Interface Alliance ­ seleciona padrões abertos para a interface entre cores, tornando possível o projeto de SoCs.
Quando um padrão proprietário é necessário, a VSIA tratará com o proprietário deste para disponibilizar seu uso sem pagamento de direitos autorais, como aconteceu por exemplo, com a linguagem Verilog.
A VSIA denomina cores como componentes virtuais.
O objetivo principal da padronização VSIA é permitir que projetistas sejam capazes de conectar cores a sockets (pinos) virtuais em circuitos complexos, como eles conectariam CIs discretos em placas de circuito impresso.
Exemplos de metodologias de interconexão de cores Exemplo 1: Barramentos Padrão Em os estágios iniciais do projeto de um SoC, os cores são projetados com muitas e diferentes interfaces e protocolos de comunicação.
Para contornar o problema de integração entre cores, foram criados padrões para estruturas internas ao circuito integrado.
Atualmente, existem poucas arquiteturas de barramento publicamente disponíveis para guiar os fabricantes, tais como a CoreConnect da IBM, AMBA da ARM e WISHBONE da Silicore.
Estas arquiteturas de barramento são geralmente vinculadas à arquitetura de um processador, tal como o PowerPC ou o ARM.
A Figura 5 ilustra um SOC baseado na arquitetura de barramento CoreConnect.
A arquitetura CoreConnect da IBM fornece três barramentos para interconectar cores e lógica personalizável:
Barramento Local do Processador (Processor Local Bus -- PLB):
Usado para interconectar cores com alto desempenho, grande largura de banda, tais como o PowerPC, controladores DMA e interfaces de memória externa.
Barramento Periférico (On-Chip Peripheral Bus -- OPB):
Usado para interconectar periféricos que trabalham com baixas taxas de dados, tais como portas seriais, portas paralelas, UARTs (Universal Assynchronous Receiver Transmiter), e outros cores com pequena taxa de transferência de E/ S. Barramento de Registradores de Controle de Dispositivos (Device Control Register Bus -- DCR):
Caminho de baixa velocidade, usado para transmitir configuração e informações de estado entre o core processador e outros cores.
Se comparado com a arquitetura SoC genérica mostrada na Figura 2, o PLB seria equivalente ao barramento de interconexão, enquanto que o OPB é responsável por a interface Outra arquitetura que deve ser citada é a WISHBONE.
Esta especificação pode ser utilizada para soft, firm e hard cores, já que firm e hard cores são geralmente concebidos a partir de soft cores.
A especificação não requer o uso de ferramentas de desenvolvimento ou dispositivos-alvo (hardware) específicos.
Os desenvolvedores do WISHBONE foram influenciados por três fatores principais.
Primeiro, havia a necessidade de uma solução boa e confiável para a integração de cores em SoCs.
Segundo, havia a necessidade de uma especificação de interface comum para facilitar as metodologias de projeto estruturadas para grandes equipes de projeto.
Terceiro, eles foram influenciados por as soluções de integração de sistemas tradicionais, fornecidos por barramentos de microcomputador como o PCI, por exemplo.
De fato, a arquitetura do WISHBONE é análoga a um barramento de microcomputador, sendo que:
Oferece uma solução flexível para integração que pode ser facilmente adaptada à uma aplicação específica;
Oferece uma variedade de ciclos de acesso ao barramento e de larguras de caminhos de dados para atender a diferentes sistemas;
E permite que os cores sejam projetados por vários fornecedores.
Os projetistas do WISHBONE criaram uma especificação robusta o suficiente para assegurar a compatibilidade entre IP cores e, ao mesmo tempo, sem restringir a criatividade do projetista e do usuário final.
Em Janeiro de 2001, a organização OpenCores adotou o WISHBONE como um padrão de conectividade entre seus cores.
Ele foi escolhido por ser o único a atender os requisitos adotados por esta instituição.
É um barramento flexível, simples, e o único completamente aberto atualmente, pois sua criadora, a empresa Silicore Corporation, tornou- o aberto ao domínio público.
Ao contrário de arquiteturas como a CoreConnect, o WISHBONE tem uma estrutura simples, composta de um único barramento, como mostra a Figura 6.
Um sistema com muitos componentes pode incluir duas interfaces WISHBONE:
Uma para blocos que exigem alto desempenho e outra para periféricos de baixo desempenho.
Mesmo os cores tendo sido projetados para ter uma interface com um barramento padrão, o projetista deve executar as seguintes tarefas para a criação correta da descrição do Definir os cores necessários para implementar a funcionalidade desejada.
Este processo é uma combinação de identificar cores pré-projetados para serem usados com ou sem modificação e identificar novos cores para serem projetados.
Esta identificação tem favorecido a criação de &quot;portais «de cores, como por exemplo o Design and Reuse Verificar se os cores selecionados são compatíveis com a freqüência de operação, largura de barramento, área requerida, etc..
Entender a funcionalidade de todos os pinos de entrada/ saída em todos os cores e determinar quais devem ser conectados juntos.
Esta tarefa é sensivelmente simplificada por a adoção de um barramento padrão.
Definir as prioridades de acesso ao barramento (política de arbitragem do barramento) e definir prioridades de requisição de interrupção do processador.
Interconectar os pinos de acordo com suas prioridades, deixando espaço para mudanças de última hora (por exemplo, pode- se decidir que pinos de interrupção devem mudar sua prioridade, ou uma nova interrupção ser adicionada).
Definir quais cores podem acessar a memória através de um controlador DMA e executar a tarefa de acordo com a prioridade do dispositivo requerente.
Definir mapas de endereço para todos os cores e passar os valores como parâmetros para cada core, garantindo que não haja conflito de endereços entre cores.
Definir quais são os clocks do sistema e conectar os clocks corretos a cada core, bem como a lógica de controle de clock apropriada.
Definir as entradas e saídas do circuito integrado, incluindo nestes os pinos necessários para a metodologia de teste que será empregada.
Inserir lógica de cola entre cores, caso necessário.
Estas tarefas são feitas manualmente nas metodologias e ferramentas atuais.
Exemplo 2: Projeto com Processador Nios O Nios é um firm core de um processador RISC de propósito geral, configurável (de forma que possa atender às necessidades dos projetos), e que pode ser combinado com a lógica do usuário num dispositivo lógico programável da Altera.
A integração do processador Nios com o hardware de propósito geral no mesmo FPGA resulta num SoC (System-on-a-Chip), como observado na Figura 7.
Algumas características do processador Nios são:
Conjunto de instruções de 16 bits;
Largura de dados com 16 ou 32 bits;
Execução de uma instrução por ciclo de clock;
Suporte para memória on- chip e off-chip;
Desempenho superior à 50 MIPS.
O Nios possui um conjunto de periféricos, tais como UARTs (Universal Asynchronous Receiver/Transmitter), Pios (Parallel Input/ Output), temporizadores e interfaces com memórias SRAM e Flash.
A comunicação com os periféricos é feita através do PBM (Peripheral Bus Module).
O PBM é criado automaticamente por a ferramenta construtora do SoC, de acordo com os periféricos requisitados por o usuário.
O PBM inclui:
Decodificador de endereços, o qual define o endereço de cada periférico e gera os sinais de &quot;chip select&quot;;
Multiplexador de entrada de dados, que fornece um barramento de conexão para transferência de dados entre cada periférico e o processador;
Controle de interrupções, que permite que o usuário determine uma interrupção de hardware para cada periférico;
Gerador de estado de espera, que determina o número de estados de espera necessários a cada periférico;
Adaptador de barramento, módulo opcional que fornece interfaces com periféricos de 8, 16 e 32 bits.
O fluxo de projeto com o processador Nios é mostrado na Figura 8.
Primeiro, o usuário configura o processador de acordo com as necessidades do projeto e seleciona os periféricos a serem utilizados.
Após, de acordo com os periféricos selecionados, é configurado o barramento de comunicação PBM.
Só então o processador Nios é gerado, juntamente com os periféricos.
Em a geração são criados, no lado do hardware, os arquivos HDL, scripts de síntese e testbenches;
Em o lado do software, funções e drivers para os periféricos.
A configuração do processador e dos periféricos é feita conforme mostrado no Exemplo 1 desta mesma Seção, ou seja, seleciona- se as prioridades de interrupção, o mapa de memória, a largura do barramento de dados/ endereço, etc..
A parte hardware é sintetizada com as ferramentas Leonardo e Quartus.
Estas ferramentas têm por função gerar o projeto (hardware) do usuário, conectar o processador Nios e eventualmente conectar cores de terceiros.
O resultado da síntese é um arquivo binário (formato SOF) que é carregado no FPGA.
A ferramenta SignalTap permite capturar sinais diretamente do dispositivo FPGA, atuando como um analisador lógico.
A parte software é feita compilando- se a aplicação do usuário, juntamente com os drivers e bibliotecas do periféricos, através do uso do GCC.
Este fluxo de projeto já permite o desenvolvimento de aplicações completas num único circuito integrado (SoC).
Muitas das tarefas são feitas manualmente, exigindo um alto grau de conhecimento da arquitetura do processador e periféricos por parte de o projetista.
Falta, contudo, um sistema de validação que permita simular conjuntamente o processador, o barramento e lógica do usuário (co-simulação).
Exemplo 3: Firm Core PCI desenvolvido para FPGAs Xilinx Como terceiro exemplo de integração de cores ilustra- se o fluxo de projeto para a utilização de firm cores da Xilinx.
Dada à disponibilidade do firm core PCI, utiliza- se este como exemplo.
A Figura 9 apresenta o fluxo de projeto de hardware e software da aplicação do usuário.
O primeiro passo para implementar um sistema composto por partes hardware e software é a criação da descrição da parte hardware.
Para isso há no sistema de desenvolvimento um projeto padrão, que é utilizado como modelo.
Este projeto padrão contém a interface externa que a parte hardware do sistema deve possuir.
Esta descrição, em linguagem VHDL, não deve ter a síntese física realizada.
A única etapa realizada é a síntese lógica.
O resultado desta síntese é um netlist em formato EDIF, que é posteriormente utilizado, juntamente com o core PCI para a síntese física.
Este fluxo de projeto não dispõe de um modelo funcional do core para simulação, o que dificulta a validação das aplicações desenvolvidas.
Tipicamente, o usuário descreve sua aplicação sem preocupar- se com o core PCI, validando- a por simulação funcional.
Uma vez sua aplicação desenvolvida, é feita a integração aos pinos do core.
Uma vez obtido o netlist EDIF, deve- se copiar este netlist para o local onde se encontra o netlist do core, o esquemático que une os netlists (usuário e core) e o arquivo contendo as restrições de temporização e posicionamento do core no FPGA.
Observa- se que não há um ambiente integrado de desenvolvimento, sendo necessária a execução de diversas etapas manuais.
Também não há a possibilidade de desenvolvimento puramente a partir de VHDL.
Deve- se ter, no nível mais alto de hierarquia, um esquemático.
Uma vez obtido um diretório de projeto contendo os dois netlists e o arquivo com as síntese física.
É importante comentar que o arquivo de restrições contém três partes principais, localização dos pinos de entrada e saída na periferia do FPGA, restrições de temporização e posicionamento dos elementos do core no interior do FPGA.
Este posicionamento é importante para que o circuito alcance o desempenho esperado, que é a freqüência de operação em 33 MHz.
O arquivo resultante da síntese física, bitstream, é utilizado com a parte software da aplicação do usuário.
O uso de sistemas compostos por parte hardware e parte software, com desenvolvimento concorrente (codesign), tem aumentado numa variedade de domínios de projetos, devido a o fato de fornecerem alto desempenho e flexibilidade.
Componentes de hardware fornecem um desempenho maior do que o que pode ser atingido por o software para subsistemas com temporização crítica.
O hardware também fornece interfaces para sensores e atuadores que interagem com o ambiente físico.
Por outro lado, o software permite ao projetista especificar o sistema em altos níveis de abstração num ambiente flexível onde erros, mesmo nos estágios finais do projeto, podem ser rapidamente corrigidos.
O software também contribui para a diminuição do time- to-- market e do custo do sistema.
Linguagens de especificação utilizadas por projetistas de sistemas computacionais podem ser divididas em linguagens de programação de software e linguagens de descrição de hardware.
Linguagens de software como C ou C+ são tradicionalmente baseadas num modelo de execução seqüencial derivado de semânticas de execução de processadores de propósito geral.
Entretanto, linguagens de software geralmente não têm suporte para modelar concorrência e temporização.
Estas deficiências podem ser superadas fornecendo- se ao projetista pacotes de bibliotecas que simulam as características ausentes.
Linguagens de descrição de hardware, tais como Verilog e VHDL são concebidas para especificar hardware, tendo como características comuns hierarquia (descrição estrutural com utilização de componentes), concorrência entre processos (todos os módulos em hardware operam concorrentemente) e temporização.
É desejável para o processo de codesign usar uma única linguagem de especificação para a captura de projeto, pois especificações que usam linguagens diferentes para software e hardware combinam modelos de execução diferentes.
Isto torna estas especificações difíceis de simular e analisar.
Alguns projetistas utilizam uma linguagem de programação, geralmente C+, e estendem esta linguagem com construções para suportar características de hardware.
Esterel. Java O projetista modela o sistema completo num algoritmo ou modelo comportamental.
Uma vez que a especificação está completa, um processo de compilação automático é usado para analisar o especificação, identificando concorrência entre os processos.
O particionamento e os passos de síntese usam a informação de concorrência obtida na etapa de compilação para criar um sistema de hardware-- software otimizado.
Como exemplo de sistemas que utilizam Java para modelar sistemas computacionais, citamos JavaCAD, que é um ambiente distribuído utilizado para simulação remota e proteção de propriedade intelectual.
A linguagem VHDL é utilizada para descrever a parte hardware dos sistemas computacionais, em diversos níveis de abstração:
Algorítmico (ou comportamental), transferência entre registradores, nível lógico com atraso unitário ou nível lógico com atraso detalhado.
A linguagem permite explorar, num nível mais alto de abstração, diferentes alternativas de implementação.
O fato da linguagem VHDL ser um padrão, torna as ferramentas de CAD compatíveis entre si, permitindo também um maior reuso dos soft cores.
A síntese do VHDL para o nível físico é feita automaticamente por ferramentas de CAD, havendo pouca iteração com usuário, tipicamente através da inserção de restrições de área e temporização.
Isto evita a ocorrência de erros no nível físico, diminuindo o time-- tomarket.
SpecC A síntese de SoCs feita diretamente da especificação em nível de sistema é uma abordagem mais flexível, pois o projetista se preocupa com o sistema como um todo, não desenvolvendo separadamente as partes hardware e software.
Entretanto, é necessário o desenvolvimento de uma tecnologia de CAD para fornecer técnicas e ferramentas para a síntese de diferentes componentes (cores).
A linguagem SpecC é uma extensão da linguagem C que inclui suporte para três modelos computacionais:
Processos seqüenciais concorrentes (para software), máquinas de estado finitas com bloco de dados (para hardware), e eventos discretos (para protocolos) A linguagem SpecC foi desenvolvida por diferentes razões:
A fim de especificar um processo de projeto para construir SoCs, é necessária uma linguagem para especificação e modelagem de sistemas nos diferentes estágios do processo de projeto.
Por este motivo, a linguagem SpecC é usada como uma linguagem de especificação de SoCs executável.
Foi desenvolvida como uma SLDL (linguagem de descrição em nível de sistema).
Assim, é possível estudar e experimentar modelos e ferramentas, e desenvolver uma metodologia para SoCs clara, que inclua cores.
Inicialmente, pode servir como uma SLDL padrão, para ser estendida mais tarde, incluindo partes mecânicas, analógicas, ou outras partes do sistema;
Assim, ela pode tornar- se um padrão universal para sistemas.
Esterel A linguagem Esterel é uma linguagem síncrona desenvolvida a partir de 1982 conjuntamente por dois laboratórios franceses INRIA e ENSMP.
A necessidade de atender simultaneamente concorrência e determinismo é a base do modelo de programação síncrono da linguagem Esterel.
Os princípios básicos deste modelo são os seguintes:
Reatividade: O modelo é reativo uma vez que se aplica a sistemas que entram em ação reagindo à presença de estímulos vindos do ambiente em instantes discretos.
Cada reação, portanto, está associada a um instante preciso;
O conjunto destes instantes caracteriza a vida do sistema reativo.
Sincronismo: As reações são instantâneas, sendo que as entradas e saídas se apresentam sincronizadas.
As reações são atômicas, e o modelo síncrono não permite uma nova ativação do sistema enquanto o mesmo estiver reagindo ao estímulo atual.
Portanto, não há concorrência entre as reações, eliminando assim uma fonte de não determinismo que corresponderia ao entrelaçamento (interleaving) de execuções concorrentes.
Difusão Instantânea: A comunicação entre componentes é sempre realizada por um mecanismo de difusão instantânea (broadcasting).
Um sinal emitido é visto no mesmo instante da sua emissão por todos seus receptores.
A difusão é limitada aos instantes de reação:
Um sinal emitido num instante é visto como presente em todos os receptores neste mesmo instante;
Pode haver, entretanto, várias emissões e recepções de sinal em seqüência num mesmo instante.
Determinismo: Contrariamente às abordagens assíncronas, onde a concorrência leva ao não determinismo, o modelo faz conviver concorrência e determinismo.
O modelo síncrono é determinista, o que tem como resultado a simplificação das programações reativas e a capacidade de reproduzir seus comportamentos, simplificando testes e verificações destas.
Em a abordagem síncrona, o tempo é considerado como uma entidade multiforme, sendo visto como um evento externo entre outros, de características diversas do tempo físico;
A noção de tempo físico é na verdade substituída por a noção de ordem e de simultaneidade entre eventos.
Essa visão de tempo multiforme e a não ocorrência de entrelaçamento facilitam em muito o entendimento e a análise dos sistemas de tempo real.
Companhias que desenvolvem cores (também denominados como IP cores, do inglês Intellectual Property), ferramentas para integração de cores e organizações como a VSI Alliance geraram grandes expectativas com relação a o valor e à reusabilidade dos cores.
Apesar de tudo, um obstáculo conhecido para as metodologias baseadas no reuso é a falta de mecanismos para proteger os direitos dos projetistas e proprietários dos cores.
Para que se tenha sucesso, o projeto de um determinado core deve:
Fornecer técnicas para avaliar a correção e a qualidade (área, velocidade, potência, testabilidade) dos sistemas que virão a utilizar o core;
O maior desafio para as ferramentas de projetos baseados no reuso de IPs é a validação do projeto sem comprometer a propriedade intelectual.
Uma técnica utilizada para a proteção de propriedade intelectual é a watermarking.
Ela protege o projetista do core, embutindo uma assinatura digital em componentes IP.
Se a assinatura digital não puder ser removida, em caso de litígio, o fornecedor pode provar que o componente, ilegalmente empregado por o usuário, carrega sua assinatura.
A principal limitação da watermarking é que ela protege o projetista do core só de uma instanciação ilegal de seu componente, mas não esconde sua propriedade intelectual.
Uma watermarking é uma marca que é:
Embutida num objeto (texto, imagem, audio, vídeo) ou parte de propriedade intelectual (hardware, software, algoritmo, organização de dados);
Projetada para identificar o autor, a fonte, as ferramentas e as técnicas utilizadas e/ ou o receptor da propriedade intelectual.
Difícil de detectar e remover.
Uma outra técnica para proteção é baseada em criptografia.
Em este caso o fornecedor libera ao usuário um modelo de simulação preciso, e protege seu core criptografando- o.
Este modelo pode ser instanciado e simulado dentro de o projeto do usuário.
O modelo criptografado é fornecido ao usuário como um objeto pré-compilado para ser conectado ao seu sistema no momento da síntese.
Usar um modelo criptografado e précompilado traz à tona dois problemas:
O modelo criptografado não é portável.
O projetista do core precisa preparar uma versão diferente do modelo criptografado para cada arquitetura alvo.
O usuário do core deve confiar que o modelo criptografado será fiel ao modelo funcional.
Uma terceira técnica para a proteção de IP é empregada no ambiente JavaCAD.
JavaCAD é um ambiente distribuído, baseado numa arquitetura cliente-servidor onde os clientes são os usuários de cores e os servidores são os fornecedores de cores.
O objetivo de JavaCAD é fornecer uma plataforma que suporta o uso de componentes IP distribuídos através da Internet.
Antes de comprar um componente, o usuário do IP quer obter estimativas de custo em termos de área, desempenho e potência da instanciação do componente.
Durante as pesquisas no início do projeto, estimativas aproximadas de custo podem ser suficientes, e podem ser obtidas de um datasheet padrão.
À medida que o projeto for sendo refinado, o usuário do IP pode precisar de informações mais precisas.
Primeiro, ele pode querer um modelo funcional abstrato para testar a funcionalidade do componente dentro de o seu projeto.
Após, ele pode necessitar estimativas de custo precisas que não podem ser obtidas sem o conhecimento (parcial) da implementação e do ambiente do componente.
Em o lado do fornecedor do IP, a questão principal é a proteção da propriedade intelectual:
O fornecedor quer comunicar- se com o usuário com a maior quantidade de informações possível para facilitar a compra, mas ele não quer revelar a sua propriedade intelectual ao usuário do A definição de formatos padrão para descrições de projetos, como o VHDL e o EDIF, foram os primeiros passos importantes para que fosse possível fornecer infra-estrutura às ferramentas para reuso no projeto de hardware.
Com o crescimento da computação por rede, surgiram novos paradigmas para a organização do acesso à informações específicas ao projeto.
A idéia básica é que as informações críticas de projeto, dispersas geograficamente, podem ser automaticamente coletadas e visualizadas através da Web.
Virtualmente, todas as maiores companhias de hardware têm servidores Web que fornecem informações (datasheets, application notes, documentação técnica) aos projetistas.
A Internet pode ser aproveitada não só para compartilhar informações, mas também para executar tarefas críticas de projeto, tais como validação e otimização.
Em esta abordagem, um projetista é um cliente numa arquitetura cliente-servidor, e ele pode solicitar serviços de uma variedade de servidores.
O uso de ferramentas de CAD é um dos tipos de serviços, como também o é a distribuição de propriedade intelectual.
Em o JavaCAD, o usuário do IP cria um projeto instanciando e conectando módulos.
Alguns módulos são disponíveis localmente, outros são remotos.
O JavaCAD tem várias características únicas:
Não especifica quais métodos num módulo remoto devem ser remotos.
Cada fornecedor pode decidir o grau de proteção que ele considera necessário.
Protege também o usuário, pois um módulo não tem visibilidade alguma da estrutura do projeto além de seu limite.
É completamente distribuído.
Fornecedores e usuários podem seguramente comunicar- se por a Internet.
Todas as técnicas de proteção de IP enfocam, principalmente, o projeto de hardware.
Entretanto, a maioria dos sistemas em larga escala contém hardware e software.
A maioria dos componentes IP bem sucedidos no mercado, hoje, são cores que incluem um ou mais processadores.
Enquanto a proteção do core do hardware é ainda uma necessidade fundamental, o software forma freqüentemente a maioria dos IP valiosos para os projetistas de sistemas.
Portanto, é preciso garantir proteção do software desenvolvido por o usuário, ou por o fornecedor.
Workload A Figura 11 mostra um projeto genérico, utilizando um core (em cinza).
A proteção de IP é representada como uma barreira (linha pontilhada) entre o core, que é uma propriedade intelectual do fornecedor, e o resto do sistema, que pertence ao projetista.
Ambos, o fornecedor e o projetista, não podem &quot;enxergar «através da barreira, pois, se pudessem, violariam a propriedade intelectual da outra parte.
Em um ambiente de simulação distribuída, o projetista inicia a sessão de simulação aplicando um conjunto de vetores de teste (workload) nas entradas primárias do projeto.
Caso esteja sendo realizada uma simulação funcional, é muito provável que a instância do core contenha localmente o modelo funcional.
Entretanto, caso o projetista deseje informações mais apuradas, a simulação do core ocorre remotamente, nas máquinas do fornecedor do core.
A premissa básica desta simulação distribuída, ou virtual, é que eventos nas fronteiras não carregam nenhuma propriedade intelectual.
Infelizmente, em geral, essa premissa não é verdadeira no caso de componentes virtuais programáveis.
A Figura 12 ilustra um projeto que contém um core de microprocessador (µP), memória (M) e alguns dispositivos de entrada/ saída (I/ O) conectados por um barramento.
A funcionalidade do projeto é determinada por o algoritmo executado no core.
O workload externo é aplicado através dos dispositivos de entrada/ saída.
Mesmo se for assumido que o workload não é crítico, novas questões surgem com a presença do core do microprocessador:
O algoritmo é uma propriedade intelectual do projetista;
O core do microprocessador é uma propriedade intelectual do fornecedor;
O compilador pertence ao fornecedor e pode conter informações críticas sobre a arquitetura do core microprocessador;
O código executável representa o algoritmo, contendo informações críticas do projetista.
Logo, ocorrem dois problemas:
O compilador precisa do algoritmo do projetista para gerar o código binário, desprotegendo desta forma a propriedade intelectual do projetista do sistema;
A simulação do sistema necessita do código executável que é executado no core do microprocessador, desprotegendo a propriedade intelectual do fornecedor do core.
Para este propósito, foi proposta uma nova abordagem baseada no encapsulamento e criptografia, vista na Figura 13.
O módulo executável, que carrega a propriedade intelectual do fornecedor é representado por o bloco F. Ele pode ser o compilador ou o microprocessador da Figura 12.
Em um ambiente desprotegido, o módulo seria diretamente executado por o projetista para processar os dados de entrada (in) e fornecer os resultados (out).
Em o ambiente proposto, o módulo é fechado numa caixa que fornece proteção de IP, inibindo a execução direta do módulo, enquanto exibe a mesma interface externa e o mesmo comportamento de I/ O. O bloco cinza da Figura 9 é chamado de módulo empacotado (wrapped module).
O projetista instancia e usa módulos empacotados no ambiente do JavaCAD como se eles fossem abertos (desempacotados).
Entretanto, a qualquer momento em que ele tente executar o módulo para processar novos dados de entrada, o invólucro (wrapper) verifica se a execução é ou não autorizada por o fornecedor do core.
O mecanismo de autorização funciona da seguinte forma:
Rodando na máquina do fornecedor.
Como mostrado na Figura 13, o módulo empacotado não tem comunicação direta com o servidor de autorização.
Preferencialmente, um cliente de decriptografia (DecryptC) externo ao invólucro do IP é usado para este propósito.
Existem duas razões para que seja colocado um módulo adicional entre o invólucro do IP e o servidor de autorização.
Primeiro, a ao fornecedor identificar o projetista e, possivelmente, permitir que ele execute o módulo IP.
O módulo IP empacotado é executado na máquina do projetista.
Logo, dados de entrada e de saída (geralmente carregando IP do projetista) não são enviados através da Internet nem desprotegem o fornecedor.
Conforme este protocolo de autorização não impõe penalidades de desempenho significativas.
Em a maioria dos casos, exceto para soft cores, os usuários de cores possuem pouco conhecimento do conteúdo interno dos mesmos, tratando- os como caixa preta.
A estratégia do teste dos cores deve ser definida por os projetistas dos cores.
O usuário tem apenas acesso à fronteira externa dos módulos de hardware instanciados.
De o ponto de vista do projetista do core, o método de teste deve ser definido sem o conhecimento de onde o core virá a ser utilizado.
Como resultado, o projetista pode ou não fornecer um teste com a qualidade adequada.
Se a cobertura é muito fraca, a qualidade do sistema está em risco.
Se é muito alta, o custo de teste pode aumentar (tempo).
Conforme mencionado na Seção 2.4.1, o grupo de trabalho IEEE P1500 trabalha na definição de padrões para a realização do teste de cores embutidos em SoCs.
Técnicas de BIST (built-in-self-test) são utilizadas para o teste de cores.
Uma outra técnica de teste é baseada na serialização dos padrões de testes.
Uma varredura ao redor de o core permite acesso indireto, mas completo, a todas as entradas e saídas do core.
Esta técnica é chamada de mecanismo ring-access.
Ela pode ser interna ou externa ao core e pode ser implementada por o projetista ou por o integrador do core.
A complexidade e os requisitos de hardware desta abordagem são aceitáveis para os atuais circuitos integrados, já que permanece independente das limitações de pinos.
Em adição aos modos de teste normal e internos em cores, um sistema baseado em cores freqüentemente requer vários outros modos de testes.
Um de eles é o teste externo ao core para detectar falhas de interconexão (estática ou dinâmica) entre cores e para testar a lógica definida por o usuário, ao redor de o core.
O maior desafio na concretização de um sistema baseado em core é a integração e coordenação de testes e capacidade de diagnóstico no circuito integrado.
Isto engloba o teste interno de cada core, da lógica definida por o usuário, e suas interconexões.
Para resumir, os testes de projetos baseados em cores enfrentam três problemas principais:
Tornar o teste de core portável;
Fornecer acessibilidade aos nós internos do core;
Compor um teste integrado e seu mecanismo de controle para todo o sistema.
Ferramentas para Personalização de Cores Em esta Seção, serão mostradas algumas ferramentas disponíveis atualmente no mercado e que são utilizadas para parametrizar e distribuir cores.
A ênfase é dada para dispositivos programáveis tipo FPGA, objeto de estudo deste trabalho.
A empresa Xilinx possui diversas ferramentas que permitem projetar sistemas digitais utilizando cores.
De entre estas ferramentas, pode- se citar o Core Generator, que serve para parametrizar cores, sendo utilizado em conjunto com o IP Internet Capture, que fornece um método automatizado para identificar, capturar, e documentar cores.
Outra ferramenta, chamada Chipscope, gera cores que se comunicam com os módulos do sistema, permitindo a análise dos sinais internos.
Xilinx Core Generator System O Xilinx Core Generator System gera cores parametrizados e otimizados para os FPGAs da Xilinx.
O usuário seleciona um core, identifica os parâmetros de entrada e é gerado o core otimizado.
Ele é compatível com descrições VHDL, Verilog e com fluxos de projeto baseados em esquemáticos.
Os cores são entregues com o projeto lógico e com a planta baixa otimizada ou o layout deste.
O fabricante garante que o desempenho é independente do tamanho do dispositivo FPGA e que ele permanece constante à medida em que mais cores são acrescentados.
Para cada core há a geração do seu data sheet e de seu modelo VHDL.
A ferramenta permite que se gere cores simples gratuitamente, como por exemplo, um multiplexador, somadores, subtratores ou memórias.
Para cores mais complexos, como DSPs, processadores e cores para telecomunicações, que precisam ser comprados, a ferramenta disponibiliza links para que o usuário possa entrar em contato com o fornecedor.
Xilinx IP Internet Capture A ferramenta IP Internet Capture opera em conjunto com o sistema Xilinx Core Generator, catalogando cores desenvolvidos.
O IP Internet Capture empacota módulos de projetos criados por projetistas individuais, disponibilizando- os a outros que utilizam o Xilinx Core Generator.
A ferramenta IP Internet Capture não fornece apenas a capacidade de fazer a busca de IPs.
Ela também permite que o projetista inclua modelos de simulação comportamental, testbenches, ou outros arquivos com vetores de simulação.
O IP Internet Capture requer que os projetistas forneçam links para a documentação de seus IPs.
Isto assegura que todo IP catalogado no sistema Xilinx Core Generator forneça um ponto de partida útil para que os projetistas avaliem se o IP está de acordo com as suas necessidades.
Esta documentação é apresentada na forma de arquivos PDF ou páginas Html.
Esta ferramenta fornece aos projetistas um método automatizado para identificar, capturar e documentar um core.
Este core pode estar na forma de código VHDL ou Verilog, ou em forma de uma netlist de função fixa.
O core pode ser compartilhado através da rede do cliente ou num web site.
Uma vez que o novo módulo é capturado e enviado, outros projetistas podem utilizar browsers padrão da Internet para fazer download do IP e instalar- lo em sua cópia do sistema Xilinx Core Generator.
ChipScope O aumento da densidade dos dispositivos FPGAs torna cada vez mais difícil a tarefa de utilizar equipamentos de teste para examinar estes dispositivos em funcionamento.
O ChipScope é uma ferramenta para geração de cores, que permite a análise lógica dos sinais internos de sistemas desenvolvidos para dispositivos Virtex, Virtex-E e Spartan-II.
Os cores disponibilizados por a ferramenta ChipScope comunicam- se com os módulos do sistema em desenvolvimento, permitindo ao projetista visualizar o funcionamento do hardware da mesma forma que faria com um analisador lógico, sem a necessidade da utilização de equipamentos de teste.
As ferramentas disponibilizadas por o ChipScope são:
Core Generator:
Fornece netlists e modelos de instanciação para o core ICON (Integrated Controller) e para o core ILA (Integrated Logic Analyzer);
Core Inserter:
Insere automaticamente os dois tipos de cores no projeto sintetizado do usuário.
Analyzer: Permite configurar e exibir os sinais dos cores ILA.
Os cores ILA permitem que se possa escolher os sinais de sincronismo (trigger) e capturar sinais.
O core ICON comunica- se com os pinos Boundary Scan da placa de prototipação.
A Figura 15 ilustra a estrutura geral de um sistema utilizando os cores inseridos por o ChipScope.
Os cores ILA (para leitura dos sinais internos) e ICON (de controle) podem ser inseridos no projeto do usuário de duas formas:
Gerando os cores com o Core Generator e instanciando- os no código-fonte HDL;
Unindo- se os cores após a síntese lógica dos módulos do sistema em desenvolvimento, usando o Core Inserter.
A Figura 16 ilustra o fluxo de projeto utilizando os cores gerados por as ferramentas do ChipScope.
Altera Megafunction Partners Program (AMPP).
O AMPP é uma aliança entre a Altera e desenvolvedores de propriedade intelectual, fornecendo aos usuários de dispositivos programáveis da Altera um grande conjunto de megafunções.
Para obter- se as megafunções do AMPP, é preciso conectar- se diretamente com os fornecedores.
O web site da Altera fornece uma extensa lista de fornecedores que compõem o AMPP.
MegaCore Functions da Altera.
As funções MegaCore são arquivos descritos em HDL, sendo muitas vezes utilizada a linguagem AHDL, proprietária da Altera.
Estas megafunções são desenvolvidas, pré-testadas, documentadas e licenciadas por a Altera.
Estas funcionalidades são semelhantes aos sistemas Xilinx Core Generator e Xilinx IP Internet Capture.
A Altera também oferece um sistema de test drive para que se possa avaliar uma megafunção antes de comprar- la.
Este sistema permite que o projetista instancie, compile e simule a função para verificar seu tamanho e desempenho, antes de decidir adquirir a licença da mesma.
O fluxo de projeto utilizando o MegaCore é mostrado na Figura 17.
Solicitação de avaliação do OpenCore da Altera Instanciação da função no projeto do usuário Simulação do projeto Escolher outra solução Não A solução funciona para a aplicação do usuário?
Distribuição de cores na Internet Existem na Internet dezenas de web sites de fornecedores de cores abertos ou com propriedade intelectual protegida.
A maioria dos web sites que distribuem cores na Internet são de empresas comerciais, que desenvolvem seus próprios módulos e os vendem através da rede.
Estes módulos são geralmente soft cores sintetizáveis ou hard cores já sintetizados que não se encontram disponíveis para download.
Apenas os documentos contendo as características funcionais dos cores podem ser acessados.
Os cores somente são enviados ao cliente após este entrar em contato com o fornecedor e pagar por eles.
Atualmente, algumas destas empresas estão investindo em sistemas de test drive dos cores, ou seja, o cliente pode simular- los através de simuladores HDL padrão antes de comprálos, conforme mencionado na Seção 2.5.2.
Para isto, o cliente seleciona o core desejado entre os disponíveis na lista do fornecedor.
Logo após ele preenche uma ficha de registro, contendo os dados do cliente.
Geralmente o pedido é atendido em poucas horas, e o cliente recebe um link para FTP via e-mail e pode fazer o download do soft core criptografado, de um modelo de simulação também criptografado, de padrões de teste e de uma documentação abreviada do produto.
Outra categoria de distribuidores de cores encontrada na Internet é a de entidades que promovem a distribuição de módulos com propriedade intelectual livre, também chamados de cores abertos.
Devido a o fato dos cores pagos serem bastante caros, a quantidade dessas entidades vem crescendo cada vez mais.
Estas entidades geralmente disponibilizam soft cores sintetizáveis já simulados, depurados e testados, que podem ser capturados em seus web sites.
Juntamente com os cores, pode- se fazer o download das documentações completas, contendo informações sobre a tecnologia para a qual foi desenvolvido, interface com o mundo externo e informações para teste.
Em alguns desses web sites também pode- se fazer o download de ferramentas para entrada de dados, ferramentas para simulação de código em Verilog ou VHDL, e também ferramentas de síntese tanto para ASICs como para FPGAs.
Os projetistas podem contribuir com estes sites de distribuição de IPs gratuitos, inserindo novos cores às bibliotecas e ajudando na identificação ou resolução de bugs.
Além de web sites onde é possível comprar cores e web sites onde é possível encontrar gratuitamente soft cores, há também uma classe de web sites que servem como &quot;portais «de cores, ou seja, têm como objetivo principal reunir várias outras entidades que disponibilizam cores e ferramentas.
Estes &quot;portais «organizam e classificam estes serviços e facilitam o acesso à essas entidades, direcionando o usuário à seus web sites.
A maior parte dos cores disponíveis, tanto os abertos quanto os com IP protegida, são descritos em linguagem VHDL, enquanto alguns são descritos em Verilog.
Já as aplicações mais encontradas são cores para telecomunicação, processadores, memórias, Des, USB e Ethernet.
A Tabela 2 mostra alguns fornecedores de cores, a linguagem de descrição utilizada, as principais aplicações disponíveis e o endereço de seus respectivos web sites.
O Capítulo anterior tratou dos cores e mostrou as dificuldades em sua utilização.
Este adequadamente, como por exemplo:
Técnicas de codificação de componentes para reuso, documentação e suporte à verificação.
Em a Seção 3.1 são apresentadas algumas práticas de codificação visando facilitar a reutilização de módulos de hardware em novos projetos.
A Seção 3.2 e 3.3 tratam, respectivamente, da documentação e dos testes que devem acompanhar o core.
A o final do Capítulo, na Seção 3.4, apresenta- se a primeira contribuição deste trabalho, um ambiente desenvolvido para a distribuição de cores, independentemente de seu formato, via Internet.
Codificação VHDL para Distribuição de Cores Cada vez mais as equipes de projeto utilizam IP cores para construir SoCs.
Assim, está surgindo um consenso comum entre os projetistas sobre os aspectos-chave de um projeto baseado em reuso, ou seja, um modelo padrão para reuso de projetos.
Em este modelo padrão, a proposta fundamental é que cores bem projetados são a chave para o sucesso do projeto de um SoC.
Não importa o quão bom é o fluxo de integração do SoC, se os blocos que estão sendo utilizados não forem bem projetados o processo de integração será longo e complicado.
Um circuito projetado para ser reutilizado deve ser descrito da maneira mais simples possível e mesmo assim atingir o desempenho desejado.
Quando se projeta pensando em reutilização, algumas recomendações importantes devem ser observadas:
Suporte a tratamento rápido de interrupções (com um banco de registradores dedicado).
Usar construções simples, tipos básicos (para VHDL) e esquemas simples para clock.
Usar estilo de código, nomenclatura, e estruturas consistentes para os processos e máquinas de estados.
Usar um esquema de particionamento regular, com todas as saídas dos módulos registradas e com os módulos aproximadamente do mesmo tamanho.
Fazer o código RTL fácil de entender, usando comentários, nomes significativos, e constantes ou parâmetros, em vez de números.
Tomando estes cuidados, o projetista será capaz de produzir um código que convirja rapidamente ao desempenho desejado, em termos de funcionalidade, temporização, área e potência.
Estruturas simples e regulares são mais fáceis de integrar, verificar e sintetizar do que estruturas complexas.
Para se desenvolver estruturas simples, deve- se utilizar algumas convenções e práticas de codificação.
Isto facilita a identificação e compreensão de sinais e estruturas que compõem a descrição.
A seguir serão descritas algumas das convenções mais importantes, com exemplos de codificação em VHDL.
A) Convenção geral para nomes.
Usar letras minúsculas para os nomes de sinais, nomes de variáveis e nomes de portas (entradas/ saídas do circuito).
Usar letras maiúsculas para nomes de constantes e para tipos definidos por o Usar nomes significativos para sinais, portas, funções e parâmetros.
Não utilizar ra como nome de um barramento de endereço de RAM.
Para este componente, o nome ram_ addr seria mais sugestivo.
Usar o nome clk para sinais de clock.
Se existe mais de um clock no projeto, usar clk como prefixo para todos os clocks, como por exemplo clk_ 1 ou clk_ interface.
Para sinais ativos em '0' (zero), utilizar_ n no final do nome.
Usar o prefixo rst nos nomes de sinais de reset.
Em a descrição de barramentos, usar uma ordem consistente de bits (x DOWNTO y), a fim de estabelecer um padrão entre os projetos.
Por exemplo, bus1:
Quando possível, usar o mesmo nome, ou um similar, para portas e sinais interconectados.
Não utilizar palavras reservadas de outra linguagem (VHDL ou Verilog) para nomes de elementos no código-fonte.
Isto permite uma tradução mais fácil de VHDL para Verilog (ou vice-versa).
B) Nomes de arquiteturas Para as arquiteturas, aconselha- se utilizar nomes sugestivos como: --
ARCHITECTURE rtl_ model Is identificando que se trata do modelo RTL ou -- ARCHITECTURE tb Of my_ test_ bench Is testbench.
C) Cabeçalhos em arquivos-fonte Incluir um cabeçalho no início de cada arquivo-fonte.
O cabeçalho deve incluir:
Aviso de direitos autorais, nome do arquivo, autor, data de criação, versão, Contato, descrição da função do módulo e histórico das modificações, incluindo datas, nome do projetista e descrição das mudanças.
Exemplo de cabeçalho:
Pci_ core.
Vhd Ewerton Capellatti module.
By Version Change Description Original D) Comentários Usar comentários para explicar cada processo, função e declaração de tipos e subtipos.
Usar comentários para explicar portas, sinais e variáveis, bem com grupos de sinais e variáveis.
Os comentários devem ser inseridos na linha ou linhas anteriores às do código ao qual se refere.
Devem ser breves, concisos e explicativos.
Explicações de funções óbvias devem ser evitadas.
Exemplo de bom comentário:
E) Layout Não usar mais de uma expressão (statement) por linha, facilitando a visualização dos mesmos e a inserção de comentários.
Usar no mínimo 3 espaços para cada indentação e no máximo 6.
Indentações estreitas dificultam a identificação de escopos aninhados.
Indentações largas fazem com que o código rapidamente alcance a margem direita.
Exemplo: Evitar o uso de TABs.
Diferenças entre editores podem modificar a posição das tabulações, comprometendo a indentação do código.
O comprimento da linha não deve exceder 72 caracteres.
Linhas com mais de 72 caracteres são difíceis de ler tanto no monitor do PC quanto em impressões.
Se a linha for maior que 72 caracteres, deve- se dividir- la e identar a próxima linha, indicando que se trata da continuação da linha anterior.
Por exemplo: Usar um layout tabular, com uma declaração por linha.
Isto facilita a inserção e remoção de declarações.
Por exemplo: Signal count1 Signal count2 Signal c F) Declarações de portas e mapeamentos Declarar as portas numa ordem lógica e manter essa ordem consistente em todo o projeto.
Declarar as portas, uma por linha, com comentários para cada uma de elas, de preferência na mesma linha.
Declarar primeiro as portas de entrada e depois as de saída.
Declarar as portas na ordem:
Clocks, resets, enables, outros sinais de controle e por último sinais de dados e de endereços.
Sempre usar mapeamento explícito para portas e genéricos, usando associação por nome e não associação posicional.
Deixar uma linha em branco entre mapeamentos de portas de entrada e de saída.
Outra questão importante quando se projeta pensando no reuso de componentes, diz respeito à portabilidade.
Para que se desenvolva um componente portável é preciso que se crie um código independente de tecnologia, compatível com várias ferramentas de simulação e facilmente traduzível de VHDL para Verilog (ou vice-versa).
A) Usar somente tipos do padrão IEEE.
Pode- se criar tipos e subtipos, mas todos devem ser baseados nos tipos do padrão IEEE.
Usar de preferência STD_ LOGIC ao invés de STD_ ULOGIC e STD_ LOGIC_ VECTOR ao invés de STD_ ULOGIC_ VECTOR.
O tipo LOGIC fornece funções de resolução necessárias em barramentos tristate.
O tipo ULOGIC não as fornece.
Além disso, o tipo LOGIC é melhor suportado por as ferramentas de CAD.
Padronizar a utilização de LOGIC ou ULOGIC é ainda mais importante do que a escolha do tipo a ser utilizado.
B) Não usar apenas valores numéricos em declarações de vetores.
Por exemplo, em vez de usar:
Usar uma constante:
Isto facilita a adaptação do circuito a diferentes larguras de barramentos.
C) Usar bibliotecas independentes de tecnologia, como a DesignWare Foundation Library, que contêm arquiteturas otimizadas para componentes aritméticos como somadores, multiplicadores, comparadores e incrementadores/ decrementadores.
D) Não usar expressões GENERATE ou BLOCK, de modo a facilitar a tradução da descrição VHDL para Verilog.
Não existem construções similares em Verilog.
Existem algumas regras de codificação para a questão de síntese.
Pode- se criar um código que atinja melhores tempos de compilação e melhores resultados na síntese, incluindo:
Testabilidade, desempenho, simplificação da análise de temporização estática e comportamente em nivel de portas-lógicas que corresponde ao código RTL original.
A) Inferir Registradores ­ Registradores (flip-flops) são os mecanismos mais utilizados em lógica seqüencial.
Para manter a consistência e assegurar a síntese correta, deve- se utilizar alguns padrões, de forma a inferir registradores independentes de tecnologia.
Usar o sinal de reset do sistema para inicializar sinais sincronizados por registradores.
Exemplo: EXA_ PROC:
Evitar Latches ­ O problema do uso de latches deve- se ao fato da necessidade de criar uma estrutura de armazenamento de uma variável que será utilizada posteriormente, porém sem explicitar qual o sinal de controle para que este armazenamento ocorra.
Logo, a ferramenta infere o sinal de controle, podendo este não ser o desejado por o projetista.
Exemplo de trecho de código VHDL que infere um latch devido a o fato de que a saída' z'não está associada à condição WHEN OTHERS:
EXC_ PROC:
Especificar a Lista Completa de Sensitividade.
Incluir uma lista de sensitividade completa em cada processo.
Se esta lista não for utilizada, o comportamento do projeto antes da síntese pode diferir do comportamento após a síntese.
Alguns compiladores detectam a ausência de sinais na lista, emitindo avisos de erro.
D) Signal vs.
VARIABLE -- Em a simulação VHDL, os sinais recebem valores no próximo ciclo de execução, enquanto que as variáveis têm efeito imediato.
Em a escrita de um código sintetizável, aconselha- se a utilização de sinais ao invés de variáveis, a fim de assegurar que o comportamento da simulação do projeto antes da síntese será equivalente ao da netlist após a síntese.
Se uma estrutura codificada com prioridade não for necessária, recomenda- se o Uma atribuição condicional também pode ser usada para inferir um multiplexador.
Em grandes multiplexadores, na maioria dos simuladores a expressão Case executa mais rápido do que uma atribuição condicional.
Exemplo de atribuição condicional para inferir um multiplexador:
F) Máquinas de Estado Separar a descrição da máquina de estados em dois processos, um para a lógica combinacional e outro para a lógica seqüencial.
Criar um tipo enumerado para o vetor de estados.
Atribuir um estado default para a máquina de estados, de forma a garantir que a máquina partirá do estado ocioso, caso nenhuma condição ocorra para colocar- la num estado específico.
Em VHDL, esta atribuição é feita por a condição WHEN Exemplo:
Documentação do Core Uma das questões mais importantes quando se trata de reuso de cores é ter uma boa documentação.
Esta documentação deve conter todas as informações que o usuário precisa para manusear o core e integrar- lo ao seu sistema.
Primeiramente, deve- se definir um conjunto de documentos com formato uniforme.
Dois tipos diferentes de informação podem ser diferenciados:
Parte funcional, descrevendo funcionalidade, arquitetura e interfaces, e parte relativa à implementação, descrevendo a estrutura de dados, a maneira como o core foi projetado e como ele pode ser verificado e adaptado ao sistema do usuário.
Assim, a documentação pode conter as seguintes informações:
A reutilização de componentes não é somente a transferência do código reutilizável, mas sim a transferência do conhecimento para manusear a funcionalidade de ele.
A qualidade da documentação é o ponto-chave para essa transferência de conhecimento.
Verificação do Core O objetivo da verificação do core é assegurar que o mesmo está correto tanto na funcionalidade quanto na temporização.
O comportamento do core deve estar de acordo com a funcionalidade e temporização descritas na especificação funcional.
A verificação é um dos maiores desafios no desenvolvimento de um projeto, principalmente quando se projeta um core para ser reutilizado.
A verificação deve garantir que o core não apresenta nenhum defeito, pois o mesmo pode ser usado para construir desde um simples video-game até uma aplicação crítica e complexa, como numa missão aeroespacial.
A ausência de defeitos deve ser garantida para todo tipo de configuração do core, com todos os valores possíveis aceitos por seus parâmetros.
Além disso, a equipe de integração deve ser capaz de reutilizar os testbenches no nível do core, pois o core deve ser verificado tanto como um projeto isolado quanto no contexto da aplicação final.
Devido a a complexidade e escopo da verificação funcional, é essencial que um plano global de verificação funcional seja criado e seguido por a equipe de projeto.
Definindo o plano de verificação logo no início do projeto, a equipe pode desenvolver o ambiente de verificação, incluindo testbenches e conjuntos de testes de verificação, também no início do ciclo de projeto.
Ter uma definição clara dos critérios que o core deve obedecer ajuda a concentrar o esforço de verificação e ter uma noção mais exata de quando o core está pronto para ser utilizado.
Os benefícios específicos do desenvolvimento do plano de verificação no início do projeto incluem:
A criação deste plano faz com que os projetistas analisem as tarefas que consomem mais tempo antes de executar- las;
A equipe pode concentrar os esforços nas áreas que a verificação é mais necessária;
O esforço redundante pode ser minimizado;
Os projetistas podem compartilhar sua experiência e conhecimento acumulado com o resto da equipe;
O plano fornece um mecanismo formal para correlacionar as necessidades do projeto à testes específicos, garantindo a integridade da cobertura dos testes;
As informações contidas no plano permitem que uma equipe de suporte à verificação desenvolva o ambiente de verificação em paralelo às tarefas de captura do projeto, executadas por a equipe principal de projetistas.
Isto pode reduzir significantemente o tempo de projeto.
O ambiente de verificação é formado por um conjunto de componentes de testbench, como modelos funcionais de barramentos, monitores de barramento, modelos de memória e a interconexão entre estes componentes e o projeto a ser testado.
O plano de verificação deve ser completamente descrito, ou na especificação funcional do core, ou num documento separado.
Este documento será mudado à medida em que novas questões forem surgindo durante o projeto e que as estratégias forem refinadas.
O plano deve incluir:
Uma descrição da estratégia de teste, tanto no nível de sub-bloco quanto no nível mais elevado (top level);
uma descrição detalhada do ambiente de simulação, incluindo o diagrama de blocos;
A lista dos componentes do testbench, com suas características, e indicando se cada um de eles pode ser comprado de terceiros ou precisam ser desenvolvidos;
A lista de todas as ferramentas de verificação necessárias, incluindo simuladores e ferramentas de criação de testbenches;
Uma lista de testes específicos, com os objetivos e cobertura e com o custo de projeto estimado para cada um;
A análise dos pontos principais da especificação do core, identificando quais testes verificam cada um de eles;
A especificação da funcionalidade que será testada em nível de sub-bloco e da que será testada no nível do core;
A especificação dos critérios que serão utilizados para determinar quando o processo de verificação estará completo.
A verificação de um core consiste de três fases principais:
Verificação de módulos individuais;
Verificação do core e prototipação.
O objetivo da primeira fase é atingir um nível bastante alto de cobertura dos testes no nível de módulos e, depois, concentrar a verificação em nível de core, testando suas interfaces e sua funcionalidade.
Esta abordagem de verificação bottom-up (começando do nível mais baixo até o mais alto) é baseada no princípio de localidade.
É mais fácil detectar e consertar erros em módulos pequenos do que em módulos grandes.
A abordagem tradicionalmente utilizada por projetistas difere da anterior por o fato de não haver um teste exaustivo (ou o mais completo possível) dos módulos.
Em a abordagem tradicional determinados módulos servem de testbench para outros blocos, simplificando a etapa de geração de testbenches.
O problema é que podem haver falhas em determinados módulos, acarretando geração de estímulos com falhas, o que invalida a verificação dos módulos em teste.
Outras vantagens de se utilizar o teste no nível de módulos são:
A observação e o controle de nós internos torna- se mais difícil quanto maior é o circuito.
Atingir uma cobertura completa é mais fácil com blocos menores.
Fazer a depuração no nível do core pode ser muito mais difícil e consome mais tempo do que depurar em nível de módulos.
A abordagem de verificação bottom-up, como um modelo de desenvolvimento em cascata, não é verdadeiramente eficiente.
Em a prática, uma abordagem em espiral envolvendo iterações é a que realmente funciona.
A equipe de projeto faz testes exaustivos no sub-bloco, atinge cerca de cem por cento de cobertura, integra o sub-bloco no core, e então faz a verificação do core.
Inevitavelmente surgem erros, geralmente envolvendo as interfaces e interações entre os módulos.
São então feitas as modificações necessárias nos projetos dos módulos, seguidas de uma nova verificação e integração dos módulos, para que seja feita a verificação do core completo.
O processo composto por várias iterações e refinamentos, até que se atinja o nível desejado de confiabilidade do circuito é chamado de &quot;construção por correção».
Em a realidade, esta abordagem garante uma segurança bastante alta, mas não de cem por cento de correção no funcionamento.
A construção de um protótipo rápido do core é o que permite que a equipe de projeto possa testar o core em aplicações reais, aumentando sua confiabilidade e robustez.
Esta necessidade de um protótipo do core é atendida por o uso do dispositivos programáveis de alta densidade, como os FPGAs.
Em cada fase do projeto, a equipe deve decidir que tipo de testes serão utilizados e quais as ferramentas de verificação que serão necessárias para isso.
Os tipos básicos de testes de verificação incluem:
Teste de adequação ­ Estes testes verificam se o projeto está de acordo com a especificação.
Para um padrão da indústria, como uma interface PCI ou uma interface IEEE 1394, estes testes também verificam a adequação com a especificação publicada.
Em todos os casos, a adequação do projeto com a especificação funcional é verificada da maneira mais completa possível.
Teste de casos extremos ­ Estes testes tentam encontrar situações complexas e casos extremos, em que o projeto provavelmente apresente falhas.
Teste randômico ­ Para muitos projetos, como um processador ou interfaces de barramento complexas, os testes randômicos podem ser úteis como complementos aos testes de adequação e de casos extremos.
Estes são limitados à situação que os projetistas previram.
Testes randômicos podem criar situações que os projetistas não previram e descobrir a maioria dos erros mais difíceis de serem detectados no projeto.
Teste de código real ­ Uma das etapas mais importantes na verificação de um projeto é testálo numa aplicação real, com código real.
Sempre existe a possibilidade de que a equipe de projeto entenda mal uma especificação, e acabe projetando e testando seu código com uma especificação errada.
Teste de regressão ­ A a medida em que os testes são desenvolvidos, eles devem ser adicionados ao conjunto de testes de regressão.
Um dos problemas mais típicos encontrados durante a verificação é que, quando se conserta um erro, outro pode ser descuidadosamente introduzido.
O conjunto de testes de regressão ajuda a verificar que em determinado ponto de referência, a funcionalidade continua sendo mantida à medida em que novas características são adicionadas, e que todos os erros, até aquele ponto, foram corrigidos.
O termo testbench, em VHDL ou Verilog, geralmente se refere ao código utilizado para criar uma seqüência predeterminada de entradas para um circuito e, opcionalmente, observar suas saídas.
É comumente implementado, através das próprias linguagens VHDL ou Verilog, podendo incluir arquivos externos ou rotinas C.
O projeto do testbench difere dependendo da função do core.
Por exemplo, o testbench em nível mais alto para um core de um microprocessador deve, tipicamente, executar programas de teste, enquanto que o testbench de um core de uma interface de barramento deve usar modelos funcionais de barramentos e monitores de barramentos para aplicar estímulos e analisar os resultados.
Existem diferenças significativas entre o projeto do testbench de sub-bloco e o projeto do testbench no nível do core.
Em ambos os casos, o mais importante é garantir que a cobertura de testes é adequada.
A) Testbench de Sub--bloco Devido a o fato de que estes módulos quase nunca possuem interfaces bidirecionais, pode- se desenvolver um único testbench que gere um conjunto de entradas para as portas do sub-bloco e verifique as portas de saída do mesmo.
Em a maioria dos sistemas digitais, estas entradas não são aleatórias, mas sim um conjunto de transações que devem ocorrer numa determinada porta (Figura 23).
Geração de Estímulos Quando se projeta um sub-bloco, pode- se especificar os tipos de transações permitidas em determinada porta do sub-bloco.
Por exemplo, a escrita num registrador consiste numa seqüência específica de dado, endereço e mudança de pinos de controle.
Qualquer outra seqüência de ações é ilegal.
Em o projeto do restante do core, é necessário garantir que nenhum outro sub-bloco que envie sinais para esta porta gere transações ilegais.
Uma vez definido o conjunto de transações legais para as portas de entrada, é necessário gerar seqüências destas transações com valores apropriados para os dados e endereços, para testar o sub-bloco.
Analisa- se a funcionalidade do sub-bloco para determinar seqüências úteis, que servirão para verificar se o comportamento do sub-bloco está de acordo com a especificação, e então são feitos os testes de casos extremos.
Após serem feitos todos os testes, deve- se executar uma ferramenta de cobertura de código, que fornece uma boa indicação da integridade do conjunto de testes.
Verificação de Saídas A geração dos casos de teste é apenas a primeira parte da verificação.
É necessário analisar as reações do projeto para verificar se ele está funcionando corretamente.
Esta análise pode ser feita manualmente, através da monitoração das saídas num visualizador de formas de onda.
Porém, este processo tende a muitos erros, sendo necessário um verificador de saídas automático para o testbench.
Este verificador deve ser exclusivo para o sub-bloco a ser testado, mas existem alguns aspectos comuns à maioria de eles:
É possível verificar que somente transações legais são geradas por as portas de saída do projeto;
É possível verificar que transações específicas são respostas corretas às transações de entrada geradas.
B) Testbench do Core É possível estender os conceitos utilizados em testbenches de módulos para testbenches usados para testar cores.
Estando os módulos integrados dentro de o core, constróise um testbench que, novamente, gera automaticamente as transações para as entradas do core e testa as transações das portas de saída.
Existem algumas razões por as quais deve- se desenvolver um testbench mais poderoso e bem documentado neste nível:
O projeto está mais complexo, exigindo cenários de teste também mais complexos, mais projetistas (talvez toda a equipe que desenvolveu os módulos) estarão trabalhando na verificação do core e o testbench será fornecido ao usuário juntamente com o core, para que ele possa testar o core.
C) Exemplo de Testbench para teste randômico O trecho de código abaixo exemplifica um testbench randômico que obtém uma semente num arquivo e, a partir de ela, gera entradas aleatórias para o circuito a ser testado.
Posteriormente, são calculados os valores esperados para as saídas do circuito, e estes são comparados aos resultados reais obtidos a partir de o circuito.
Code coverage é uma técnica utilizada para exercitar todas as linhas do código e verificar o comportamento de todas as funções ou combinações possíveis destas.
Uma ferramenta de code coverage funciona da seguinte maneira:
Primeiro acrescenta- se checkpoints (pontos de verificação) em locais estratégicos do código-fonte para verificar se uma dada construção foi exercitada.
O código dos testbenches não precisa receber pontos de verificação.
Posteriormente, o core é simulado normalmente, usando todos os testbenches disponíveis.
Os dados de todas as simulações são então coletados e armazenados numa base de dados.
A partir de esta base de dados, são gerados os relatórios que determinam as medidas de cobertura do conjunto de verificação utilizado sobre o projeto.
Os relatórios mais comuns são sobre cobertura de instrução, caminho e expressão.
A cobertura de instrução é também chamada cobertura de bloco, onde um bloco é uma seqüência de instruções que são executadas se uma única condição for verdadeira.
A) Cobertura de instrução.
A cobertura de instrução (ou bloco) avalia quantas do total de linhas do código foram executadas por o conjunto de verificação.
Algumas ferramentas de code coverage fornecem interfaces gráficas, permitindo que o usuário identifique facilmente as instruções que não foram executadas.
A Figura 24 mostra um exemplo de relatório de cobertura de instrução, de forma gráfica, para um pequeno trecho de código.
Este tipo de relatório varia de ferramenta para ferramenta.
O exemplo acima mostra que duas das oito linhas (25% do código) não foram executadas.
Para que se obtenha uma cobertura de 100%, é preciso que se descubra quais condições são necessárias para que o resto do código seja executado e incluir- las no testbench.
Em o caso apresentado, a paridade deve ser definida como ímpar (ODD) ou par (EVEN).
Uma vez determinadas as condições, é preciso, primeiro, entender por que elas nunca aconteceram.
Tratando- se de uma condição que não pode ocorrer nunca, o código em questão está efetivamente &quot;morto&quot;:
Nunca será executado.
Deve, portanto, ser removido.
B) Cobertura de caminho.
A cobertura de caminho avalia todos os caminhos possíveis por os quais podem ser executados uma seqüência de instruções.
O código mostrado na Figura 26 possui quatro TRUE ou False.
Para verificar todos os caminhos possíveis neste trecho de código, é necessário executar- lo sob todas combinações possíveis para as instruções IF_ FALSE-FALSE, False-TRUE, TRUE-FALSE e TRUE-TRUE.
Em o exemplo acima, a cobertura de caminho foi de 75%, pois um dos caminhos não foi exercitado.
Novamente, é necessário determinar as condições para que todos os caminhos sejam executados.
Em este caso, para que este caminho seja executado, a paridade não deve ser definida nem como par, nem como ímpar, e o número de stop bits deve ser dois.
Como no caso anterior, é importante questionar- se sobre a possibilidade da condição não acontecer nunca.
C) Cobertura de expressões.
Em o código da Figura 27, pode- se observar que existem duas condições independentes que podem causar a execução da condição THEN na primeira instrução IF:
A paridade sendo par ou sendo ímpar.
A cobertura de expressão avalia todos os caminhos por os quais uma condição de controle pode ser TRUE.
Como nos casos anteriores, é preciso entender por que um termo de controle de uma expressão não é exercitado.
Em o exemplo anterior, nenhum testbench definiu a paridade como sendo par.
Deve- se, então avaliar se esta condição nunca ocorrerá, e se o termo foi inserido no código equivocadamente.
Ambiente de Distribuição de Cores A padronização da codificação VHDL é necessária para que projetistas possam trabalhar de forma cooperativa.
O mesmo refere- se à documentação e à metodologia de teste empregada.
Quando se desenvolve um core, gera- se uma grande quantidade de informações, incluindo o próprio core, sua documentação e seu testbench.
Visando contribuir com técnicas de distribuição de cores, foi desenvolvido neste trabalho um ambiente de distribuição através da Internet, independente do formato do core.
O objetivo em se criar tal ambiente é o de prover aos projetistas uma forma de distribuir seus projetos e de sistematizar a organização das informações contidas nos projetos.
Para que se manuseie adequadamente os projetos, é necessário ter uma estrutura de dados bem definida.
Isto é ainda mais importante durante o desenvolvimento e a distribuição do core.
A base de dados consiste numa árvore de diretórios, onde ficam localizadas todas as informações dos projetos.
A árvore de diretórios e os arquivos devem ser gerenciados por um sistema de controle de versões.
Isto assegura um processo de desenvolvimento seguro, com consistência de dados.
Para atender ao objetivo de auxiliar na distribuição de cores, desenvolveu- se uma aplicação que cria uma home page de um dado projeto, permitindo:
Organizar os diversos arquivos pertencentes ao projeto;
Controlar as versões desenvolvidas;
Distribuir sua propriedade intelectual;
Proteger a informação através de controle de acesso.
Tal aplicação foi desenvolvida em linguagem Java.
A janela principal da ferramenta é mostrada na Figura 28.
Em ela, o projetista pode entrar com as informações do projeto, tais como nome do projeto, responsável, e-mail para contato, descrição do projeto e pinagem.
A pinagem pode ser definida como de domínio público ou restrita à usuários autorizados.
Em esta mesma janela, encontram- se os botões &quot;Docs», &quot;Fontes», &quot;Testbench», &quot;Arq_ Auxiliares «e &quot;Fer_ Auxiliares «e &quot;Permissões».
Os cinco primeiros botões abrem janelas secundárias, onde é feita a inserção dos arquivos pertencentes ao projeto (documentação, código-fonte, testbenches, arquivos e ferramentas auxiliares).
O objetivo é permitir ao usuário organizar a informação pertencente ao projeto, assim como controlar as diferentes versões desenvolvidas ao longo de o desenvolvimento do core.
Para a entrada de arquivos-fonte e de ferramentas auxiliares é utilizado um controle de versões, pois deve haver a possibilidade de que se tenha várias versões do código-fonte e das ferramentas.
A janela de controle de versões permite que o usuário possa controlar as versões existentes, bem como fornece acesso à janela de controle de arquivos.
Em as janelas de controle de arquivos, além de entrar com os nomes dos arquivos a serem inseridos na base de dados, deve- se fazer uma breve descrição dos mesmos, de maneira a facilitar a consulta.
Também é possível remover arquivos de projetos e abrir arquivos para visualizar seu conteúdo.
A interface também permite definir um arquivo como sendo restrito.
Os arquivos restritos somente podem ser acessados por usuários autorizados.
A autenticação de usuários é feita através do nome do usuário e senha.
O sexto e último botão da janela principal abre a interface do sistema de controle permissões de arquivos.
Em ela podemos visualizar duas listas.
Em a lista da esquerda encontram- se os arquivos de domínio público, enquanto que na lista da direita estão os arquivos restritos.
Em esta tela, além de definir um arquivo como sendo público ou restrito, têm- se acesso a uma outra tela, a de controle de usuários (Figura 32).
Em a esquerda há uma lista com todos os usuários cadastrados, e na direita somente os usuários com acesso aos arquivos restritos.
O funcionamento do controle de acesso será discutido com maiores detalhes posteriormente.
Para cada projeto é criado um diretório raiz com o nome do projeto, no caminho configurado por o usuário.
Dentro deste diretório é armazenada a página Html do projeto, juntamente com os subdiretórios public e restrict que contêm os arquivos de domínio público e de acesso restrito, respectivamente.
&quot;Montador «e &quot;Simulador», e das versões &quot;Multiplexador «e &quot;Tri-State «do projeto Processador_ R6, que possuem arquivos de acesso público.
Se as ferramentas auxiliares ou versões possuírem arquivos com acesso público e também arquivos com acesso restrito, dois subdiretórios com o nome da ferramenta e/ ou versão são criados, um no diretório public e outro no diretório restrict.
O controle de acesso é feito através de dois arquivos:_
Htaccess e_ Htpasswd.
O arquivo_ Htaccess deve ser inserido no diretório que contém os arquivos restritos.
Ele é constituído por um apontador para o arquivo_ Htpasswd e por uma lista contendo os usernames dos usuários autorizados a acessar este diretório, como mostra a Figura 34.
Cada diretório restrito tem seu próprio arquivo.
Htaccess, porém, todos devem apontar para um único arquivo.
Htpasswd, que possui a lista com os usernames de todos os usuários cadastrados e suas respectivas senhas criptografadas.
A Figura 35 exemplifica a estrutura de um arquivo_ Htpasswd.
Em o exemplo acima, o arquivo_ Htaccess aponta para o arquivo_ Htpasswd, que encontra- se no diretório, o nome do projeto é Processador_ R6 e os usuários com acesso ao diretório são:
Moraes, laugusto e alinev.
O arquivo_ Htpasswd é gerado por o programa executável Htpasswd pertencente ao servidor Apache.
Esse programa é utilizado por o sistema quando a senha de um usuário é alterada ou quando um novo usuário é incluído.
Para alterar a senha de um usuário ou incluir um novo usuário a seguinte linha de comando é executada automaticamente por o sistema:
Htpasswd ­b. Htpasswd usuário senha Os arquivos,.
Htaccess e_ Htpassswd, são considerados ocultos por o servidor Web.
Logo, eles não são vistos via FTP ou via Http.
O controle de acesso funciona da seguinte maneira:
Quando o navegador tenta acessar um arquivo, o servidor Apache verifica se existe, no diretório onde tal arquivo se encontra, um arquivo_ Htaccess.
Caso não exista, o acesso é imediato.
Caso exista, significa que aquele diretório é restrito, e então o servidor abre uma janela de autenticação de usuário.
Após o usuário entrar com seu nome, o sistema verifica se o mesmo se encontra na lista de usuários autorizados do arquivo.
Htaccess deste diretório.
Se o nome estiver na lista, o sistema procura por o arquivo.
Htpassswd indicado por o arquivo.
Htaccess e compara a senha digitada com a que consta neste arquivo.
Só então este usuário poderá acessar os dados restritos.
Esta Seção ilustra o resultado da criação da página de um projeto, feita através da ferramenta apresentada na Seção anterior.
Como exemplo, foi utilizada a página do Processador R6, um processador RISC desenvolvido por o GAPH.
A Figura 36 mostra a estrutura da página gerada por a ferramenta.
Em o topo encontra- se o nome do projeto, seguido dos links para as seções &quot;Descrição», &quot;Interface Externa», Download e &quot;Contato», que encontram- se logo abaixo na página.
As seções &quot;Descrição «e &quot;Interface Externa «refletem as entradas feitas na janela principal da ferramenta, mostrada na Figura 28.
A área de &quot;Download «é formada por duas tabelas.
A primeira tabela contém as versões do projeto, descrição de cada versão, arquivos VHDL que compõem cada versão, com suas descrições, indicação de acesso público ou restrito, e links para download dos arquivos.
A segunda tabela (com arquivos complementares), contém a indicação do tipo do arquivo (documentação, testbench, ferramentas e arquivos auxiliares), descrição, indicação de acesso e link para download.
Como já mencionado no início da Seção anterior, esta ferramenta auxilia o projetista de hardware na organização dos dados pertencentes a seus projeto, como por exemplo, arquivos de descrição de hardware, documentação e ferramentas auxiliares.
Além de a organização de dados e controle de versões, a ferramenta também cria uma página Html para cada projeto, permitindo a distribuição de projetos com proteção de propriedade intelectual, caso seja necessário.
A segunda contribuição deste trabalho é a reconfiguração e a distribuição de hard cores na forma de arquivos binários de configuração de dispositivos FPGAs (bitstreams).
A motivação para que se distribua (gratuitamente ou não) hard cores é permitir que outros projetistas possam utilizar módulos de hardware já sintetizados, prontos para serem integrados a novos projetos.
Não só outros projetistas podem ser beneficiados por esta abordagem, mas também usuários comuns, mesmo que estes não tenham conhecimento algum sobre FPGAs ou qualquer outro tipo de hardware programável.
Digamos que um usuário tenha em seu computador uma placa aceleradora com um FPGA, e que num determinado momento ele precise de um hardware para acelerar um processo gráfico ou qualquer outra função crítica em tempo de processamento.
Este usuário poderia conectar- se à Internet, fazer o download do módulo de hardware que ele deseja, e carregar o módulo no FPGA da sua placa, tendo assim o acelerador que necessita.
Entretanto, a distribuição de propriedade intelectual na forma de módulos já sintetizados (hard cores) para FPGAs somente é útil se houver a possibilidade de se &quot;encaixar «novos cores num sistema sendo executado num FPGA sem interromper ou afetar o funcionamento do mesmo.
Para que esta nova abordagem seja factível de ser implementada, é necessário preencher uma série de requisitos:
FPGAs com arquitetura regular e disponibilidade de reconfiguração parcial.
Alguns FPGAs, como por exemplo os da família Virtex, possuem arquitetura interna baseada em colunas, com endereçamento individual.
Este fato permite que o dispositivo possa ter sua configuração modificada dinâmica e parcialmente.
Existência de ferramentas que permitam fixar a forma e a posição relativa dos cores no dispositivo programável.
Exemplo de ferramenta que permite fixar a posição dos circuitos no interior do FPGA é o Floorplanner (Foundation ­ Xilinx).
Existência de ferramentas que permitam a geração de bitstreams parciais.
O conjunto de classes JBits permite teoricamente gerar um arquivo parcial, porém foi verificado por os autores deste trabalho que o bitstream gerado é incorreto.
Desta forma, não há ao conhecimento dos autores, ferramentas para geração e manipulação de arquivos parciais para dispositivos Virtex.
Existência de ferramentas que permitam o download de bitstreams parciais.
Estrutura de conexão entre o core inserido e os demais cores já em operação no FPGA.
Os itens, e carecem hoje de ferramentas.
Não se encontra na literatura referência a ferramentas que manipulam arquivos parciais de configuração.
O presente Capítulo tem por objetivo mostrar o desenvolvimento de uma ferramenta que permite a reconfiguração de parâmetros de um hard core.
Desta forma, o usuário pode buscar no ambiente de distribuição previamente descrito o core já sintetizado, não havendo a necessidade do uso de ferramentas de CAD para síntese, e configurar- lo conforme o seu ambiente de utilização.
A geração do arquivo binário para reconfiguração pode ser total ou parcial, em função de as ferramentas de download disponíveis.
Este Capítulo é organizado da seguinte forma.
A Seção 4.1 revisa a arquitetura dos dispositivos programáveis Virtex que, como comentado anteriormente, é o dispositivo que permite reconfiguração parcial.
A Seção 4.2 apresenta a ferramenta que permite fixar a área de um determinado core dentro de o FPGA.
A Seção 4.3 apresenta o desenvolvimento da ferramenta que permite reconfigurar parâmetros de um hard core, mediante o emprego das classes JBits.
Finalmente, a Seção 4.4 estende o conceito de reconfiguração para reconfiguração parcial.
Revisão da Arquitetura Virtex Existem atualmente no mercado duas famílias de FPGAs que suportam reconfiguração parcial:
A família At40k, desenvolvida por a empresa Atmel, e a família Virtex, desenvolvida por a empresa Xilinx.
O presente trabalho utiliza a família Virtex por esta estar disponível no ambiente de trabalho do autor, ter maior uso no mercado dispor de ferramentas de CAD para o projeto e permitir a implementação de circuitos complexos devido a o elevado número de portas lógicas.
Os FPGAs da família Virtex são compostos por uma matriz de blocos lógicos configuráveis (Configurable Logic Blocks ­ CLBs) cercados por blocos de entrada/ saída (Input/ Output Blocks ­ IOBs).
Em as bordas da direita e esquerda estão localizadas as Block RAMs (BRAMs), como mostra a Figura 37.
As CLBs são módulos básicos que contém elementos para implementar portas lógicas, flip-flops e roteamento personalizáveis.
Os IOBs permitem a comunicação dos sinais internos com dispositivos externos.
As BRAMs permitem o armazenamento de dados com densidade mais alta que CLBs.
Cada BRAM é um bloco configurável de 4096 bits.
Com cada CLB também é possível implementar RAMs de 32-bit síncronas ou assíncronas.
Estas funções lógicas são configuradas através de um bitstream de configuração.
Um bitstream é uma seqüência de bits de configuração, formado por comandos e dados de configuração.
A estrutura do bitstream é mostrada na Figura 38.
O número abaixo de cada campo indica a quantidade de palavras de 32 bits para configurar o dispositivo XCV300.
A quantidade total de palavras é 54.744, sendo o número de bits de configuração 1.751.808.
Cada CLB contém dois slices, como mostra a Figura 39.
Cada slice é formado por duas LUTs (Look-Up--Tables) de quatro entradas, dois flip-flops D e lógica de propagação rápida de &quot;vai-um «aritméticos.
Os elementos básicos dos slices são a LUT F, a LUT G, o flip-flop X e o flip-flop Y. As LUTS podem ser usadas para implementar portas lógicas ou pequenas memórias.
Os flipflops podem ser usados para criar lógica sequencial.
Os slices também possuem multiplexadores internos para controlar a conectividade dos recursos internos (não mostrados na Figura).
Também em cada slice existe a lógica para implementar propagação rápida de &quot;vai-um «em operadores aritméticos.
A Figura 40 ilustra a estrutura interna do dispositivo Virtex.
A maior parte da área é utilizada por recursos de roteamento (linhas horizontais e verticais).
Estes recursos de roteamento são conectados aos blocos lógicos por meio de as switch boxes.
As switch boxes por sua vez estão conectadas aos multiplexadores de entrada e saída, que se ligam às entradas e saídas dos slices.
A razão de se utilizar estes multiplexadores é reduzir o número de conexões entre os slices e as switch box, pois caso não os utilizássemos, seria necessário inserir para cada entrada/ saída um número de chaves proporcional ao número de linhas de roteamento conectadas por a switch box.
Ainda nesta Figura estão ilustrados os dois buffers tri-state da cada CLB.
Cada coluna de CLBs tem dois IOBs acima e dois IOBs abaixo de ela.
Em as bordas direita e esquerda existem três IOBs por linha de CLBs.
A estrutura em colunas da arquitetura de FPGAs Virtex é mostrada na Figura 41.
A unidade mínima de configuração é um frame, o qual corresponde à uma coluna de configuração, direcionada do topo à base do FPGA.
Uma coluna de CLBs contém 48 frames paralelos.
Cada coluna de IOB, uma na esquerda e outra na direita possui 54 frames de dados de configuração.
Cada Block SelectRAM tem 64 frames e os blocos de Interconexão de SelectRAM têm 27 frames.
O bloco central é dedicado à distribuição de clock, contendo 8 frames.
A Figura 41 ilustra a distribuição dos frames sobre os recursos dos circuitos da família Coluna de IOBs da Direita (54 frames) Cn+ 1 Cn -- 1 Bloco SelectRAM (64 frames) IOBs Bloco de Interconexão SelectRAM (27 frames) Cn+ 3 IOBs Coluna de CLBs IOBs IOBs Coluna Central IOBs Coluna de CLBs IOBs Bloco de Interconexão SelectRAM (27 frames) Cn+ 4 Coluna de CLBs Bloco SelectRAM (64 frames) IOBs Cn Coluna de IOBs da Esquerda (54 frames) Cn+ 2 Virtex.
Estes frames podem ser acessados por um endereço principal e um endereço secundário.
O endereço principal é denominado Major Address (MJA), o qual indica o início de um bloco (CLB, IOB, RAM).
O endereço secundário, denominado Minor Address (MNA), indica qual frame dentro deste bloco está sendo acessado.
Os endereços principais alternam entre os lados direito e esquerdo do circuito.
A coluna central não contém CLBs.
Contém configurações para os sinais globais de clock.
Os endereços principais (MJA) das colunas de CLBs do dispositivo XCV50 são mostrados na Figura 42.
A primeira linha da figura mostra os números das colunas de CLBs.
Os frames são lidos e escritos seqüencialmente, em ordem crescente.
Múltiplos frames consecutivos podem ser lidos ou escritos com um único comando de configuração.
Uma coluna inteira de CLBs mais os IOBs, ou uma coluna de blocos de interconexão de SelectRAM podem ser lidos ou escritos através de um único comando.
Ferramenta Xilinx Floorplanner Para que se possa configurar parcialmente um dispositivo FPGA, sem afetar o resto do sistema em funcionamento no mesmo, é preciso que se tenha conhecimento da forma e da área exata ocupada por cada core, permitindo assim que eles sejam &quot;encaixados «sem que haja sobreposição dos mesmos.
Está área é definida no momento da síntese física do core, sendo necessário o uso de uma ferramenta que manipule a lógica contida no dispositivo, delimitando sua disposição no mesmo.
O Floorplanner (gerador de planta-baixa) é uma ferramenta gráfica de localização que permite ao projetista controlar a disposição do seu projeto num dispositivo FPGA usando um paradigma de &quot;arrastar e soltar «usando o mouse.
A ferramenta mostra uma representação hierárquica do projeto na janela Design Hierarchy, usando estruturas e cores para distinguir os diferentes níveis.
A janela Design Nets mostra todas as redes de interconexão pertencentes ao projeto.
A janela Placement mostra a disposição atual da lógica no FPGA, e a janela Floorplan é onde o usuário (projetista) define a nova disposição do projeto no dispositivo.
A Figura 43 mostra as janelas que compõem a interface da ferramenta Floorplanner.
O usuário pode selecionar a parte da lógica que deseja na janela Design Hierarchy e colocar- la onde deseja no FPGA, representado na janela Floorplan.
Floorplanning é uma metodologia opcional utilizada para aumentar o desempenho e a densidade de um projeto que foi posicionado e interconectado automaticamente.
Ela é especificamente direcionada para auxiliar os usuários que necessitam que certos detalhes de seu projeto sejam feitos à mão.
Para isto, o usuário precisa conhecer os detalhes da arquitetura do dispositivo alvo.
Para que se obtenha um floorplanning bem sucedido, é preciso um processo iterativo que pode levar muito tempo até que se possa superar o processo automático da ferramenta de síntese.
O Floorplanner suporta todas as arquiteturas das famílias de FPGAs Spartan/ II, Virtex/ E/ II, e XC4000 da Xilinx.
Para a compreensão dos fluxos de projeto, descritos posteriormente, é necessário apresentar os arquivos que são manipulados por a ferramenta de floorplan.
NCD ­ Arquivo gerado por o MAP (Mapping) ou por o Par (Place and Route).
É usado por o Floorplanner para gerar um projeto físico para o arquivo FNF, na hora de criar um novo floorplan.
NGD ­ Arquivo gerado por o NGDBuild.
É usado por o Floorplanner na hora de criar um novo floorplan, para correlacionar o projeto físico ao projeto lógico, quando gerar o arquivo FNF.
FNF (Floorplanner Netlist File) ­ É a base de dados do Floorplanner.
Em ele são gravadas todas as restrições físicas mostradas na janela de Floorplan.
Se o arquivo FNF é gerado usando um arquivo NCD já posicionado, as informações de posicionamento também são gravadas no arquivo FNF para serem usadas por a janela de posicionamento.
Estas restrições afetam a maneira como a lógica será implementada no dispositivo alvo.
A versão 3.1i do Floorplanner permite que se obtenha um arquivo UCF como uma das entradas para Floorplanning.
FNF (Floorplanner Netlist File) ­ Mencionado anteriormente.
MFP (Mapper Floorplan) ­ É gerado quando o arquivo FNF é salvo.
O arquivo MFP é usado como entrada para o MAP, para transferir as restrições físicas impostas no floorplanning para a ferramenta de implementação automática.
UCF ­ Após criar- se mais restrições graficamente no Floorplanner, é possível que se grave estas restrições no arquivo UCF.
O Floorplanner pode ser utilizado em cinco fluxos de projeto diferentes.
O fluxo mais comumente utilizado é executar um posicionamento e roteamento inicial (ferramentas MAP e Par), e posteriormente utilizar a ferramenta floorplan para refinar a solução obtida.
O usuário define o projeto usando uma ferramenta de captura de esquemático ou HDL.
Após, é executada a síntese lógica e física, gerando- se um arquivo em formato ncd.
Posteriormente, utiliza- se o floorplanner para restringir caminhos críticos ou ajustar o posicionamento automático.
O arquivo resultante do floorplanner, mfp, é utilizado para a geração final do arquivo de configuração.
Este fluxo pode ser visualizado na Figura 44.
O terceiro fluxo de projeto é denominado de &quot;floorplanning iterativo».
É muito semelhante ao primeiro (Place and Route, depois Floorplanning).
A diferença é que o usuário pode utilizar o Floorplanner em várias iterações, fazendo pequenas modificações no posicionamento feito por o Par.
O laço Floorplanner-MAP-PAR é repetido até que se atinja o desempenho esperado (Figura 46).
O quarto fluxo de projeto é denominado de &quot;ampliação de projeto».
É utilizado quando se deseja alterar um projeto previamente implementado num FPGA.
Este projeto pode ter sido implementado com ou sem a utilização do Floorplanner.
O Floorplanner é utilizado para correlacionar a lógica do projeto e para ajustar as informações de restrições de acordo com as novas mudanças.
Finalmente, o quinto fluxo de projeto (Figura 47) permite a criação de restrições a partir de o posicionamento de IOBs.
Pode- se inserir restrições no arquivo UCF através do Floorplanner e implementar o projeto iterativamente, até atingir o posicionamento desejado.
Para isso, é necessário apenas o arquivo NGD gerado previamente.
Em o Floorplanner, o usuário manualmente cria restrições que serão automaticamente escritas no arquivo UCF.
As novas restrições criadas por o Floorplanner têm precedência sobre as já existentes no arquivo UCF.
Posteriormente, o NGDBuild (ferramenta que converte uma descrição obtida da síntese recebendo as restrições inseridas, seguido do MAP e do Par.
Em este Capítulo utilizaremos esta ferramenta para fixar alguns elementos internos (LUT RAM) e pinos de entrada/ saída (IOBs).
Estes elementos também podem ter suas posições fixadas mediante a utilização do arquivo de restrições do usuário.
Em o Capítulo 5 utilizaremos esta ferramenta para definir a forma e a posição dos cores.
Ambiente de Reconfiguração de Hard Cores Como estudo de caso, é apresentado aqui um reconfigurador total de bitstreams, que utiliza JBits.
JBits é constituído por um conjunto de classes Java que fornecem uma API (Application Program Interface) que permite manipular o bitstream da família de FPGAs Virtex.
Com base neste conjunto de classes, desenvolveu- se um ambiente (em forma de Applet) para ser utilizado através da Internet, onde o usuário pode entrar com novos dados e alterar remotamente o conteúdo de um bitstream.
Para isto, é necessário que o dispositivo FPGA, o bitstream, a Applet e a página Html que instancia a Applet estejam localizados numa máquina executando um programa servidor.
Um bitstream (hard core) é tido como uma caixa preta, cujo conteúdo não é visível nem possível de ser alterado.
Porém, com o uso das classes do JBits, surge a possibilidade de reconfiguração de hard cores, mudando este conceito.
Convencionalmente, seria necessário que se alterasse o código-fonte do soft core do circuito.
Logo após, o mesmo precisaria ser novamente sintetizado (lógica e fisicamente).
Logo, percebe- se a vantagem em termos de economia de tempo e de custos que se tem utilizando esta abordagem.
A ferramenta de configuração de bitstreams também permite &quot;esconder «do usuário final a arquitetura do sistema.
O processo de geração de um hard core reutilizável envolve duas etapas:
Geração do hard core e criação da página do reconfigurador.
Em a primeira etapa, o hard core é gerado de forma a receber os parâmetros que caracterizam o funcionamento do circuito através de blocos de RAM internos ao FPGA (por exemplo LUTRAM).
Normalmente, a modificação destes é feita através de uma interface com microprocessador externo ou chaves.
Porém, a abordagem que utiliza blocos de RAM é mais eficiente e mais flexível.
Desta forma, ao gerarmos o hard core, todos os parâmetros deste são lidos de blocos de RAM.
Estes blocos de RAM têm a posição física fixada dentro de o FPGA através de restrições impostas no momento da síntese.
O core sintetizado não tem nenhum parâmetro definido até que seja feita a reconfiguração do bitstream, pois os blocos de RAM foram inicializados em zero.
A segunda etapa do trabalho consiste em gerar a página Html que define a interface do reconfigurador, para que o usuário tenha acesso aos parâmetros que deseja alterar.
Esta interface é criada através de parâmetros inseridos na descrição Html da página.
Os parâmetros são passados para a Applet no momento em que a página é carregada.
Os campos de visualização e inserção de valores são instanciados através desses parâmetros.
Cada campo corresponde à uma LUT (ou parte de ela).
Isto permite que se desenvolvam vários reconfiguradores diferentes apenas alterando tais parâmetros, sem a necessidade de ter que alterar a Applet.
Uma vez gerado o bitstream e a página do reconfigurador, procede- se à alteração do bitstream para configurar- lo conforme a necessidade do usuário.
Após reconfigurar o bitstream, o usuário pode realizar o download do circuito para o dispositivo de prototipação através do mesmo ambiente.
É importante que se perceba o aspecto inovador desta abordagem.
Uma vez gerado o circuito, pode- se modificar- lo sem a necessidade de re-síntese.
Torna- se também extremamente simples modificar o comportamento do circuito, uma vez que toda a manipulação é feita em software.
O software é baseado num modelo cliente-servidor, executando num browser qualquer.
Assim pode- se remotamente reconfigurar o hardware.
Por exemplo, uma dada empresa pode reconfigurar o hardware de todos os seus clientes remotamente, sem necessidade de ir até o cliente, economizando assim custos de manutenção e atualização.
O diagrama da Figura 49 ilustra os passos básicos envolvidos no desenvolvimento de uma aplicação que utiliza o JBits.
Método construtor:
Um objeto JBits deve ser construído antes de qualquer procedimento.
O construtor recebe o tipo de dispositivo a ser utilizado como parâmetro.
A lista de dispositivos pode ser encontrada na classe Devices.
Este método constrói um modelo para o dispositivo selecionado e executa várias inicializações.
O modelo para o construtor é JBits (int deviceType).
Exemplo: Leitura do Bitstream:
Este método recebe um único parâmetro contendo o nome do arquivo do bitstream a ser lido.
Ele carrega um bitstream no objeto JBits construído e mapeia os dados do bitstream para o modelo do dispositivo.
Uma vez que o bitstream tenha sido carregado, os dados de configuração podem ser lidos e escritos.
Exemplo: Alteração dos bits do bitstream:
O método set () escreve os dados de configuração de um dado recurso no elemento configurável.
O recurso é identificado por uma linha e uma coluna de CLBs.
O recurso na CLB selecionada é identificado por uma constante.
Estas constantes são definidas nas classes Java que contém os objetos configuráveis.
Por exemplo, o ajuste da configuração do recurso SLICE0 F1 é feito usando- se a constante S0 F1 na classe S0 F1, ou seja S0 F1.
S0 F1. Um vetor de inteiros fornecendo os bits de configuração é passado para o método set.
Para ajustar a entrada do S0 F1.
S0 F1 para o valor da saída do SLICE1 X, por Exemplo:
Jbits. Set;
Escrita do Bitstream: Similar ao método de leitura do bitstream, o método de escrita recebe método escreve num arquivo o bitstream do objeto JBits contruído.
O modelo para o Exemplo:
Lendo a configuração:
O método get () é usado para ler a configuração de um determinado recurso de um elemento configurável.
O recurso é identificado usando a mesma convenção mencionada no método set ().
A maioria dos dados obtidos através deste método podem ser interpretados e usados por outras partes da aplicação JBits.
O modelo para o método get () é Exemplo:
Acessando as LUTs As LUTs nos CLBs implementam as funções lógicas.
Em o JBits, as LUTs das CLBs da Virtex são definidas na classe LUT.
Esta classe define quatro arrays bidimensionais de inteiros, SLICE0_ F, SLICE0_ G, SLICE1_ F e SLICE1_ G. Em esta Seção é apresentado um exemplo de página Html que gera a interface para o reconfigurador de um determinado bitstream, a partir de as funções de manipulação de bitstreams, encapsuladas na forma de uma Applet.
A Figura 51 mostra o código Html que cria a página do reconfigurador.
Dentro de a tag Applet são definidos:
A quantidade de parâmetros a ser transmitidos, e que correspondem à quantidade de campos de visualização e inserção de valores;
O arquivo binário (bitstream) a ser utilizado (&quot;caminho $= top_ e1_ Bit&quot;);
o endereço IP do servidor;
A porta de comunicação;
E um vetor (&quot;l&quot;) contendo os valores dos parâmetros do circuito a ser configurado (Ex  &quot;n64 (nome do sinal), bin (exibido como binário ou hexadecimal), 31 (linha da CLB), 37 (coluna da CLB), G (LUT F ou G), 0 (slice 0 ou 1), 4 (bit inicial), 0 (bit final)&quot;).
Os bits inicial e final indicam a área dentro de a LUT RAM ocupada por o sinal (ou vetor).
Existem também dois parâmetros opcionais, &quot;negado «e &quot;invertesubstrings».
A Figura 52 mostra a interface do reconfigurador, criada através da página Html.
Em ela, pode- se visualizar:
Os campos contendo os valores armazenados nas LUTRAMs, e que podem ser alterados, o botão &quot;Salvar», para gravar os valores nas LUTRAMs, e o botão &quot;Download», que carrega o arquivo de configuração na placa de prototipação.
A aplicação para reconfiguração total e remota de cores é inserida também no ambiente de distribuição apresentado no Capítulo 3.
É importante ressaltar que um bitstream completo só é utilizável no ambiente (placa) para o qual ele foi sintetizado, devido a as restrições de pinos de entrada e saída.
Para que um hard core seja distribuído e utilizado em diferentes ambientes, é necessária a reconfiguração parcial e a &quot;virtualização «dos pinos de entrada e saída (conexão a um barramento padrão interno e não mais aos pinos de entrada e saída do FPGA).
Esta &quot;virtualização «é equivalente à inserção de um barramento interno, como o WISHBONE, dentro de o FPGA.
Reconfiguração Parcial Encontra-se em fase de desenvolvimento uma ferramenta para geração de bitstreams parciais para FPGAs da família Virtex.
Esta aplicação está escrita em Java, sem a utilização das classes JBits.
Baseada num estudo minucioso da arquitetura interna de FPGAs da família Virtex e de seu arquivo de configuração (bitstream), em, essa ferramenta realiza as mesmas operações do reconfigurador apresentado na Seção anterior, além de gerar um bitstream parcial.
A Figura 53 mostra a interface dessa ferramenta.
Ela possui como entradas um arquivo de configuração completo e um arquivo-texto contendo os parâmetros do protocolo para geração de um bitstream parcial.
Em a janela maior, o usuário visualiza o conteúdo de um arquivo de configuração.
Em as janelas menores (parte inferior direita da Figura) encontram- se as opções para localização de elementos dentro de o bitstream.
É possível realizar a busca por um bit específico informando- se a linha, coluna, Slice e LUT desejados.
O bit correspondente é, então, destacadona janela maior (à esquerda), onde pode ser alterado.
Depois da alteração, no momento de &quot;salvar «o arquivo, o CRC é recalculado e gravado no registrador apropriado.
Caso a opção &quot;Salvar Parcial «seja selecionada, um bitstream parcial é gerado, conforme os parâmetros informados no início do processo.
Devido a o fato da ferramenta de download disponível não permitir o download de arquivos de configuração parciais, o bitstream parcial gerado foi pré-validado através do download no FPGA sem erro de inicialização.
Apesar de o download correto, a ferramenta de download apaga todos dados de configuração do dispositivo após o download do bitstream parcial, impedindo que a reconfiguração parcial seja de fato realizada.
Encontra- se em desenvolvimento uma solução para este problema.
Dispositivos Virtex Como dito anteriormente, é possível alterar parcialmente a funcionalidade do hardware sem interromper o funcionamento do sistema.
Para que este tipo de aplicação seja uma realidade em projetos de hardware é necessário definir uma estratégia de reconfiguração parcial para os dispositivos FPGA.
A idéia é que haja no FPGA uma estrutura análoga a uma interface PCI num PC, onde se conectam dispositivos sem a modificação do sistema.
A estrutura também deve ser responsável por a &quot;virtualização «dos pinos de entrada/ saída.
Esta &quot;virtualização «é necessária para que o core seja portável, pois os pinos de entrada/ saída diferem de um dispositivo para outro.
Esta estrutura está relacionada aos itens e dos requisitos citados no início do Capítulo 4.
Até o presente momento não foi encontrada na literatura referência sobre uma proposta de interface intra-FPGA para que dispositivos reconfiguráveis possam receber cores de forma modular.
Essa modularidade consiste em conectar e remover cores sem que haja necessidade de maiores alterações na lógica pré-existente no FPGA.
Há técnicas semelhantes, voltadas para o projeto de cores em ASICs.
Como exemplo podem ser citados os padrões de barramento Amba, CoreConnect e WISHBONE, já mencionados anteriormente.
A Seção 5.1 apresenta a proposta do barramento de comunicação entre cores, explicando a idéia e a forma de conexão entre os cores.
Em a Seção 5.2 são definidas as estruturas internas do controlador do barramento e dos módulos de envio e recepção de dados.
A Seção 5.3 e 5.4 apresentam, respectivamente, a aplicação utilizada para validar o barramento de comunicação e os resultados da simulação desta aplicação.
A Seção 5.5 apresenta o início da prototipação da interface de comunicação, visando a reconfiguração dinâmica dos cores.
Proposta de Interconexão O ponto de partida para a definição da interface de comunicação foi estabelecer uma porção de hardware fixo (estático) no FPGA, chamado de controlador.
O controlador é responsável por a comunicação com o mundo externo (pinos de entrada/ saída do dispositivo) e por a comunicação com os cores.
Isto significa que os módulos de hardware a serem conectados, os cores, somente comunicarão- se- com o mundo externo através desta interface.
Estamos, desta forma, &quot;virtualizando «os pinos de entrada e saída.
O FPGA deve ser inicialmente carregado apenas com o controlador.
Os cores são carregados em tempo de execução, quando necessários.
Desta forma terá- se- um conceito de hardware semelhante ao conceito de memória virtual, ou seja, em nosso hardware terá- se- apenas os módulos que precisam ser executados naquele momento.
Os demais estão armazenados externamente, para uso posterior.
Em é apresentado um sistema de reconfiguração utilizando como estudo de caso um sistema para processamento de imagens.
Este sistema é reconfigurado quatro vezes para cada conjunto de dados (imagem) a ser processado.
O FPGA inicialmente armazena o sinal de vídeo numa memória, aplicando em seguida duas transformações diferentes sobre as imagens, e finalmente torna- se um modem e transmite o resultado do processamento.
Este exemplo pode ser implementado utilizando a proposta de interface de conexão de cores, sendo cada uma das quatro configurações um core comunicando- se com a interface.
A comunicação entre o controlador e os demais cores é feita através de pinos virtuais.
Estes pinos virtuais são implementados através de buffers tristate, presentes na arquitetura de FPGAs da família Virtex, como mencionado na Seção 4.1.
A idéia inicial era utilizar buffers na fronteira entre o controlador e o core, servindo de conector entre os mesmos.
Estes buffers fariam parte tanto da descrição do controlador quanto da descrição do core.
Haveria, assim, uma sobreposição destes buffers no momento da reconfiguração parcial do FPGA, como motra a Figura 54.
Esta proposta não é factível.
Isto deve- se a fato da CLB compartilhar LUTs, Flip-flops e roteamento.
Logo, uma dada CLB do controlador, que faria a interface com o core, conteria também recursos adicionais de lógica, os quais seriam destruídos no momento da inserção do core.
As ferramentas de síntese não possuem recursos para proibir o uso de roteamento numa área.
Esta abordagem, portanto, não resolveria o problema.
A solução encontrada foi utilizar duas camadas de buffers, uma camada pertencendo ao controlador e outra pertencendo ao core, como mostra a Figura 55.
A conexão dos cores ao controlador é feita por uma linha comum de roteamento.
Definição do Controlador e Interfaces dos Cores A Figura 56 mostra os recursos de roteamento nas saídas dos buffers tristate.
Existem apenas quatro fios paralelos para cada quatro colunas de CLBs (um conjunto de oito buffers).
Estas limitações na arquitetura de roteamento dos buffers tristate impossibilitam o uso de barramentos com grande número de bits.
Experimentos realizados com barramentos de largura de 8 bits não tiveram sucesso na etapa de roteamento.
Decidiu- se, então, utilizar um fio apenas para a transmissão de dados entre os cores.
O controlador da interface deve ser o árbitro deste barramento, gerenciando o aceite ou a rejeição de conexões, bem como o controle de conflitos relativos ao acesso aos pinos de entrada/ saída do FPGA.
Ainda no controlador é definido um core mestre, também estático, que controla a interface com o mundo externo.
O core mestre pode ser modificado, de acordo com a aplicação utilizada.
A Figura 57 ilustra a utilização da interface de comunicação, visando sua validação.
Esta aplicação é composta por 3 módulos:
Controlador, composto por o mestre, árbitro e buffers de comunicação;
Core escravo número 1;
core escravo número 2.
A interface com o mundo externo é feita na parte fixa do FPGA, ou seja, por o controlador.
Esta interface é composta por um barramento de 32 bits (display), e os sinais clock, start, reset.
A comunicação entre o controlador e cada core é feita por 6 sinais:
Data in e data out, responsáveis por o tráfego de dados; (
3-4) request e grant, responsáveis por a solicitação de envio de dados e permissão para enviar- los; (
6-7) clock e reset.
Pinos de E/ S da placa de prototipação clock reset request grant dataIn dataOut Core Escravo2 clock reset grant request dataIn dataOut Core Escravo1 reset clock startM grant dataIn dataOut request Core Mestre Árbitro Display Controlador reset (bi-direcional) Observação:
Por clareza do diagrama não são representados os comandos de abertura dos buffers tri-state.
Excetuando- se o buffer responsável por escrever na linha de dados, sinal dataOut, o qual é controlado por o árbitro, todos os demais estão sempre conduzindo.
A máquina de estados do árbitro é mostrada na Figura 58.
Este tipo de controle permite que haja cores com prioridade mais alta que outros e, ao mesmo tempo, garante que nenhum core com alta prioridade seja atendido mais de uma vez, enquanto um de baixa prioridade fica em estado de espera.
Quando um core deseja enviar dados para outro módulo do sistema, o sinal &quot;req «(request) é enviado por o core, e este fica aguardando o sinal &quot;grant «O árbitro recebe os sinais de request dos cores e atende aos pedidos de acesso ao barramento (um de cada vez) enviando o sinal &quot;grant «para o core que tem permissão de acesso naquele momento.
Após o envio do sinal &quot;grant «a um determinado core, o sinal que habilita o buffer tristate de escrita na linha de dados (&quot;tout&quot;) é ativado (em zero) apenas para aquele core.
Cada transmissão dura 40 ciclos de clock, pois a unidade mínima de transmissão é um pacote de 40 bits.
Após cada transmissão, o árbitro volta a verificar a existência de outro sinal &quot;req «ativo.
A máquina de estados do módulo &quot;Send «fica aguardando a solicitação de envio de dados, no estado &quot;S0».
Quando um dado está disponível para ser enviado ao barramento, o módulo &quot;Send «recebe o sinal &quot;disp «do hw-core.
Isto faz com que este módulo envie um sinal &quot;request «para o árbitro e fique esperando por o sinal &quot;grant».
A o receber o sinal &quot;grant», o módulo recebe o pacote de 40 bits do hw-core, através do sinal &quot;word_ in «(em &quot;S2&quot;).
Em este momento, o sinal &quot;grantC «é enviado ao hw-core para avisar que o dado já está no módulo &quot;Send», e inicia- se a transferência.
Primeiro, é enviado (através do sinal &quot;dataOut&quot;) o &quot;start bit «(bit '0') (ainda em &quot;S2&quot;), seguido da transferência serial do pacote para o barramento de comunicação, durante os 40 ciclos de clock (em &quot;S3&quot;).
O módulo &quot;Receive «monitora constantemente a linha de dados.
O estado normal da linha é em '1' lógico.
Quando recebe um bit '0', o módulo &quot;Receive «percebe que uma transmissão está iniciando, e passa a armazenar os dados da linha, através do sinal dataIn.
Após armazenar os 8 primeiros bits, é feita a verificação do endereço de destino (&quot;S2&quot;).
Se o endereço de destino corresponde ao endereço do core que está recebendo o dado, a recepção dos 32 bits restantes continua (&quot;S3&quot;).
De o contrário, o restante do pacote é ignorado (&quot;S4&quot;).
Mesmo ignorando o pacote, a máquina volta a monitorar a linha somente após os 40 ciclos da transmissão em andamento.
Após receber todo o pacote, o módulo avisa ao hw-core, através do sinal &quot;disp «(&quot;S5&quot;), e disponibiliza este pacote através do sinal &quot;word_ out».
O estado &quot;S6 «é utilizado para que o sinal &quot;disp «fique ativo durante 2 ciclos de clock.
Para ser utilizado junto ao barramento proposto, o core deve ser inserido num invólucro (wrapper), contendo os módulos &quot;Send «e &quot;Receive», além de os buffers de interface, como mostra a Figura 62.
Validação da Proposta de Interface Para que se pudesse por em funcionamento o barramento de interconexão, foi desenvolvida uma aplicação onde podem ser utilizados até três cores (escravos), cada um realizando uma operação aritmética diferente com dois operandos.
O core mestre (integrado ao controlador), além de determinar quando e qual core deve efetuar a operação, também fornece os operandos.
Em esta aplicação foram utilizados três operandos (&quot;A», &quot;B «e &quot;C&quot;) de 32 bits e duas operações (adição e subtração).
Tanto os operandos, quanto a seqüência de instruções são armazenadas em LUTRAMs, dentro de o core mestre.
Cada operando utiliza 2 LUTRAMs, enquanto que a seqüência de instruções utiliza 4 LUTRAMs, podendo armazenar até 8 instruções de 8 bits.
Da mesma maneira que no exemplo da Seção 4.3, estas LUTRAMs foram fixadas em locais pré-determinados, através da ferramenta Floorplanner.
Após, os parâmetros contidos nas LUTRAMs foram inicializados através da ferramenta apresentada também na Seção 4.3.
A o receber o sinal &quot;StartM», proveniente do mundo externo, o core mestre busca as instruções nas LUTRAMs e as carrega ordenadamente num vetor de 64 bits (oito instruções).
Simultaneamente, acontece a busca dos operandos, que são carregados em três registradores de 32 bits.
O core mestre possui ainda um registrador &quot;R «que tem por função armazenar os resultados parciais de cada operação.
Este registrador também pode ser utilizado como um operando, como mostra a Tabela 3.
Por exemplo, se tivermos como instrução a palavra &quot;00010011», é realizada a operação A ­ R. Após a busca de operandos e instruções nas LUTRAMs, o mestre começa as etapas de decodificação e execução de cada instrução.
Para cada instrução, o mestre envia dois pacotes para o mesmo destino, cada um contendo um dos dois operandos.
Primeiramente, é analisada a operação a ser executada.
Isto determina o destino dos dois operandos, ou seja, trata- se do endereço do core que deve efetuar a operação.
Em este momento são definidos os 8 primeiros bits do primeiro pacote (contendo este endereço).
Em esta aplicação, foram utilizados apenas 2 bits para codificar a operação, limitando o número de cores em três (além de a operação &quot;Halt&quot;).
Posteriormente é buscado o primeiro operando, cujo conteúdo é inserido nos 32 bits restantes do pacote e, logo em seguida, é feito o mesmo procedimento com o segundo operando.
O mestre fica, então, em estado de espera, até que o core retorne o resultado.
O core executa a operação para a qual foi projetado e retorna um pacote endereçado ao mestre, contendo o resultado da operação.
O mestre armazena o resultado no registrador &quot;R «e só então busca a próxima instrução.
Os resultados parciais são mostrados no display da placa de prototipação.
Após executar as oito instrução, ou ao encontrar a instrução &quot;Halt», o sistema termina a execução, mostrando o resultado final, e fica esperando novamente por o sinal &quot;StartM».
Resultados da Simulação Antes de ser prototipado em hardware, o sistema foi simulado utilizando o ambiente Active-HDL, da Aldec.
A Figura 64 ilustra um trecho da simulação.
&quot;grant». Em este momento, todos os módulos &quot;Receive «de todos os cores estão recebendo o pacote.
A aplicação apresentada na Seção 5.3 foi prototipada na placa VW300 (Virtual Workbench).
A forma de depuração utilizada na placa de prototipação foi exibir os valores dos operandos e dos resultados num display alfa-numérico.
Em as primeiras tentativas de prototipação, surgiram problemas que impediram o funcionamento correto do barramento.
Um dos problemas aconteceu devido a a falta de inicialização de algumas máquinas de estado.
Uma segunda causa de erro encontrada foi ocasionada por a existência de sinais flutuantes, que afetaram o funcionamento do árbitro.
A causa da existência destes sinais foi o fato de que o grupo de buffers tri-state de conexão entre o controlador e o terceiro core não era utilizado.
A solução foi criar uma lógica extra, apenas para que estes buffers recebessem '0' lógico, evitando assim sinais flutuantes.
Um terceiro fato importante, diz respeito à linha de dados.
Quando nenhuma transmissão está acontecendo, ela deve fica recebendo '1' lógico.
Isto evita que a linha fique em alta impedância, ocasionando novamente sinais flutuantes.
Após a resolução destes problemas, o funcionamento no FPGA foi correto, o que demonstrou que a estrutura de barramento com buffers tri-state pode ser utilizada em dispositivos Virtex.
Reconfiguração dos Cores Utilizando a Interface de Comunicação Uma vez a interface de comunicação validada por simulação e prototipação, procedese à geração dos módulos em separado.
Para o exemplo da Figura 57 são gerados 3 bitstreams:
Um para o controlador e um para cada core escravo.
Para a validação foram criados apenas 2 bitstreams, um para o controlador e outro para um dos cores.
A posição física dos elementos de cada bitstream é definida por a ferramenta de floorplaning (planta-baixa).
Primeiramente, foi gerado um bitstream completo contendo o controlador, com seus buffers tristate de conexão ligados à outra camada de buffers, externa ao controlador, correspondentes aos buffers do core a ser inserido.
Esta outra camada será sobrescrita por a área do segundo bitstream a ser inserida, no momento da reconfiguração parcial.
Os buffers desta camada não podem ficar desconectados, ou seja, não ter nenhuma lógica associada a ele no lado da conexão com o core.
Isto por que a ferramenta de síntese exclui todos os buffers desconectados, pois estes são tidos como desnecessários.
Foi então utilizada uma lógica extra (representada por uma porta lógica and), que serviu para garantir a permanência dos buffers no momento da síntese.
Esta lógica não precisa ser removida, pois é sobrescrita no momento da reconfiguração.
A Figura 65 ilustra o bitstream gerado para o controlador, com a segunda camada de buffers e com a lógica extra.
Como nunca pode ocorrer uma situação em que todos os sinais (&quot;clock», &quot;grant», &quot;dataIn «e &quot;reset&quot;) de entrada recebam '1' lógico simultaneamente, os buffers de saída sempre recebem '0', não interferindo com o funcionamento do árbitro.
Posteriormente, foi gerado o segundo bitstream, contendo um core e as duas camadas de buffers de comunicação, uma interna ao core, e outra correspondendo aos buffers do controlador.
De a mesma forma que para o controlador, os buffers externos ao core também devem ser utilizados, para que não sejam suprimidos no momento da síntese.
Além disso, a ferramenta de síntese não aceita como entrada um projeto que não contenha pinos de saída.
A forma de resolver estes dois problemas foi ligar os buffers externos ao core (correspondentes aos do controlador) a pinos quaisquer de entrada/ saída do FPGA.
Algumas das maiores dificuldade encontradas na etapa de síntese do controlador e do core separadamente, foram:
Fixar os elementos de comunicação ­ buffers tri-state ­ em locais que permitissem a reconfiguração parcial do bitstream sem afetar o resto do sistema, e que os locais fossem os mesmos para o controlador e para o core.
A ferramenta de floorplanning muitas vezes impediu a fixação em determinadas áreas, devido a limitações do dispositivo.
Garantir que o roteamento da lógica do controlador não utilizasse as CLBs a serem ocupadas por o core, e vice-versa.
A ferramenta de floorplanning permite restringir apenas a lógica do sistema, não o roteamento.
Para isto foi preciso adaptar a disposição da lógica, forçando a ferramenta de roteamento a escolher um caminho que não interferisse na área a ser ocupada por o outro core.
Garantir que as linhas de roteamento entre as camadas de buffers fossem exatamente iguais para ambos os bitstreams, pois estes fios serão sobrepostos parcialmente no momento da inserção do core.
Evitar a supressão dos buffers ligados a pinos de saída do FPGA.
Quando encontra um buffer deste tipo, a ferramenta o exclui, e passa a utilizar o buffer do pino de saída.
Para contornar este problema, é necessário restringir os pinos de saída, no momento da síntese lógica, como apenas &quot;output pin», pois o estado default é &quot;tri-state pin».
Evitar que o core utilizasse o clock global do FPGA.
A linha de clock global passa verticalmente por o centro do FPGA, ramificando- se por todas as linhas de CLBs.
Isto faz com que o roteamento do core utilize áreas que serão ocupadas, posteriormente, por outros cores e até mesmo por o controlador.
Para que o clock global não seja utilizado, também é necessário que se faça restrições no momento da síntese lógica do projeto, indicando &quot;use «para o parâmetro clock global.
Estas dificuldades mostram o quão difícil é implementar a reconfiguração de hard cores em FPGAs comerciais e a carência de ferramentas para isto.
É importante mencionar que a maior dificuldade foi garantir o mesmo roteamento entre as camadas de buffers.
Foi necessário manualmente remover o roteamento do core e do controlador, refazer manualmente o roteamento das linhas de conexão entre as camadas de buffers, e depois utilizar o roteamento automático para rotear o restante do circuito para cada um dos dois bitstreams.
A Figura 66 mostra os 6 fios de roteamento entre as camadas de buffers e o limite entre o controlador e do core.
Após diversas iterações manuais obteve- se dois bitstreams com o mesmo roteamento entre as camadas de buffers.
A etapa seguinte é a união destes bitstreams.
Utilizando uma ferramenta desenvolvida localmente ao grupo de pesquisa, estes bitstreams são agrupados num único arquivo de configuração.
Esta ferramenta permite a geração de um bitstream completo, contendo todo o circuito.
Em este caso, a reconfiguração não é parcial, mas sim total, ou seja, um novo arquivo de configuração completo será carregado no FPGA.
A Figura 67 ilustra, na parte superior, os bitstreams gerados separadamente e, na parte inferior o bitstream final, contendo a lógica do core inserida no primeiro bitstream.
A área pontilhada no segundo bitstream indica a área exata a ser inserida no bitstream do controlador.
BITSTREAM n:
Contém:· core escravo.·
buffers tri-state.·
módulos de transmissão e recepção.
Em o presente momento estamos validando (por prototipação) este procedimento, visando provar que é possível a união de diferentes bitstreams num único, mantendo o funcionamento do sistema.
Uma vez o sistema validado por união de bitstreams, e configuração completa do FPGA, procede- se à última etapa do trabalho, ou seja, a geração do arquivo parcial de configuração, contendo o core a ser inserido no bitstream do controlador.
O presente trabalho apresentou:
O estado da arte em cores;
A distribuição de cores através da Internet;
A reconfiguração de hard cores;
E a proposta de um barramento intra-FPGA de comunicação entre cores.
Em o estudo do estado da arte em cores, foram apresentados diversos problemas inerentes à utilização de cores na construção de SoCs, tais como:
A interconexão de cores fornecidos por diferentes fabricantes;
A proteção de propriedade intelectual do projetista do core;
A escolha da linguagem utilizada para desenvolver o core e os testes de cores.
O desenvolvimento da ferramenta para distribuição de cores através da Internet foi motivado por a necessidade de organização de dados de projetos, cujo grau de dificuldade é diretamente proporcional ao tamanho do projeto.
Tal ferramenta auxilia ao projetista na organização de seus projetos, permitindo também a proteção da sua propriedade intelectual.
A ferramenta de reconfiguração de hard cores permite a reconfiguração completa (local ou remota) de bitstreams, sendo utilizada para alterar os parâmetros que definem a funcionalidade do circuito (armazenados em LUTRAMs), através de uma página Html.
Isto reduz bastante o hardware de controle do circuito, diminuindo também o custo.
Esta abordagem também reduz o tempo de projeto, pois o circuito não precisa ser novamente sintetizado.
A reconfiguração remota é factível de ser implementada e tem aplicação industrial, porém, ainda não está sendo explorada amplamente.
A reconfiguração parcial de FPGAs Virtex ainda não é explorada, embora ela seja possível, devido a a inexistência de aplicações comerciais que a utilizem e, principalmente, devido a a ausência de ferramentas de CAD para suporte.
Além de o mais, ela só é realmente útil se conectar cores diretamente num barramento interno ao FPGA.
Tal barramento ainda não existe e seu desenvolvimento é problemático, devido a o número reduzido de recursos internos ao FPGA, tais como buffers tri-state e roteamento entre eles.
Conclui- se desta forma que a reconfiguração parcial em FPGAs comerciais é praticamente inviável, dada a falta de suporte arquitetural e de ferramentas.
Todo o trabalho de geração de cores para reconfiguração teve que ser realizado manualmente para que os cores fossem posicionados e tivessem seu roteamento em locais adequados.
A contribuição científica deste trabalho pode ser resumida em 3 aspectos:
Desenvolvimento de ferramenta para distribuição de cores;
Ferramenta para reconfiguração de hard cores;
Proposta de uma interface de comunicação de cores, já validada funcionalmente, e em fase de prototipação em FPGAs.
Como trabalhos futuros, cita- se:
Concluir a prototipação do barramento, utilizando reconfiguração parcial do dispositivo FPGA;
Sistematizar o processo de interconexão entre cores, através de uma ferramenta de CAD;
Propor um barramento mais genérico, tendo, por exemplo, maior largura de banda, múltiplos árbitros, tolerância a falhas;
Estudar e propor modelos para dispositivos reconfiguráveis mais adequados à utilização de barramentos internos e reconfiguração parcial;
E incluir outros mecanismos de proteção de propriedade intelectual no ambiente de distribuição de cores, como simulação distribuída.
