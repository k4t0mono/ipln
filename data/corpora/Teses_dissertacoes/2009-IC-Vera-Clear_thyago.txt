Este trabalho apresenta e discute os resultados obtidos com a aplicação das técnicas de expansão de consulta denominadas Pseudo Realimentação de Relevantes (PRR) e Realimentação de Relevantes (RR) num Sistema de Recuperação de Informação (SRI) que utiliza o modelo de recuperação de informação denominado TR+.
TR+ é um modelo de recuperação de informação que emprega, além de termos, Relações Lexicais Binárias (RLB) presentes nos textos e nas consultas, para indexar e recuperar documentos textuais em língua portuguesa.
A aplicação das técnicas de expansão de consultas PRR e RR têm como objetivo melhorar os resultados obtidos por o usuário que realiza uma consulta.
As duas técnicas se diferenciam quanto a a participação do usuário:
Enquanto a RR utiliza o julgamento do usuário na definição de quais documentos recuperados por a consulta original fornecerão as informações utilizadas na expansão da consulta, a PRR busca eliminar a participação do usuário durante este processo.
Os resultados obtidos por os experimentos, tanto utilizando PRR quanto RR, não superaram os resultados utilizados como baseline.
A o compararmos entre si os resultados dos experimentos com as técnicas PRR e RR, os experimentos com PRR foram superados por a RR somente numa rodada.
Em o contexto dessa dissertação podemos concluir que a utilização de RLBs ao invés de usar somente termos, é uma opção mais producente.
Palavras-chave: Expansão de Consultas, Sistemas de Recuperação de Informação, Pseudo Realimentação de Relevantes, Realimentação de Relevantes, Relações Lexicais Binárias, Processamento da Língua Natural.
Motivação e contexto do trabalho Para auxiliar os usuários a encontrar, num repositório com um grande volume de documentos em formato digital, os documentos que necessitam, foram desenvolvidos os Sistemas de Recuperação de Informação (SRIs) (Baeza-Yates&amp; Ribeiro-Netto, 1999).
SRIs que trabalham com documentos textuais tem como objetivo principal atender consultas realizadas por usuários através da indexação, classificação e busca de documentos.
Entretanto formular uma consulta correta através de palavras-chave, que possibilite a um SRI retornar ao usuário as informações que ele necessita, pode não ser uma tarefa simples.
Segundo Baeza-Yates e Ribeiro-Netto, a identificação da real necessidade do usuário no momento em que ele busca alguma informação ou documento é um processo muito complexo e pode ser a diferença entre uma recuperação producente e uma recuperação de informações que não atenda as necessidades do usuário.
Apesar de auxiliarem a recuperação de informações, os SRIs dependem da capacidade do usuário de formular eficientemente uma consulta, de maneira que o sistema possa &quot;interpretar «o que o usuário deseja obter como resposta, no momento da recuperação das informações.
Uma alternativa para ajudar ao usuário na formulação da consulta e, por conseqüência, aumentar a eficiência de um SRI, é a utilização de uma técnica denominada Expansão de Consulta (EC).
EC, utilizando novos termos semanticamente relacionados aos já presentes na consulta inicial, é uma técnica tradicional na recuperação de informações.
Estudos realizados por Spink, embora não muito recentes, apontam que 52% das consultas realizadas num sistema de recuperação de informação são refeitas.
Outro estudo, apresentado em abril de 2006 por a iProspect1, empresa pioneira no desenvolvimento de SRIs para marketing, mostra que 82% dos usuários refazem suas consultas acrescentando mais termos, realizando com isso uma expansão da consulta original com novos termos, buscando um meio de encontrar as informações que melhor satisfaçam as suas necessidades.
A utilização de técnicas de expansão de consulta, em conjunto com técnicas de processamento da língua natural (PLN), constitui- se nos dias de hoje uma alternativa viável para se aprimorar o resultado da recuperação, num sistema de recuperação de informação.
A o longo desse trabalho foram estudados os processos e analisados os resultados da aplicação das técnicas de expansão de consulta Pseudo Realimentação de Relevantes (PRR) e Reali1 mentação de Relevantes (RR) num sistema de recuperação de informação que usa o Modelo TR+ para indexar e recuperar documentos textuais em língua portuguesa.
O Modelo TR+ utiliza métodos estatísticos e lingüísticos para indexar e recuperar os documentos, e apresenta características apropriadas para a representação e recuperação textual.
Propõe a utilização de tratamento idêntico para os textos dos documentos e para as consultas antes do processo de recuperação.
O Modelo TR+ indexa e recupera utilizando, tanto sobre a formulação da consulta quanto na indexação dos documentos, descritores de conceitos que incluem termos simples e compostos.
O primeiro passo é o pré-processamento do texto, onde são utilizados métodos de tokenização e etiquetagem morfológica.
Após, são realizadas a nominalização e a captura das relações lexicais binárias (RLBs).
Nominalização, no Modelo TR+, é o processo de transformação de adjetivos, verbos e advérbios em substantivos.
Com a nominalização são definidos os termos simples que constituirão os descritores.
As RLBs constituem os termos compostos e completam a descrição dos conceitos presentes nos documentos.
RLBs (dos tipos classificação, restrição e associação) são relacionamentos entre termos nominalizados, que capturam mecanismos de coesão frásica.
Os descritores (termos e RLBs) têm seus pesos calculados através do conceito de evidência.
Em este cálculo é considerada a freqüência de ocorrência dos termos e, também, o número de relações que há entre eles.
A seguir na Seção 1.2 introduziremos os objetivos do presente trabalho.
Hipótese e objetivos Baeza-Yates e Ribeiro-Netto apresentam várias técnicas de expansão de consulta que buscam a formulação de uma consulta mais eficiente, num sistema de recuperação de informação.
Entretanto, nenhuma dessas técnicas havia sido utilizada em conjunto com o Modelo TR+ num sistema de recuperação de informação.
De este modo, a questão de pesquisa ganha corpo da seguinte forma:
&quot;A aplicação de expansão de consulta num sistema de recuperação de informação que usa o Modelo TR+ pode representar um ganho de precisão ou abrangência na recuperação dos documentos?»
Partindo- se desta questão de pesquisa, tem- se como hipótese que a utilização de técnicas de expansão de consulta em conjunto com o Modelo TR+ pode auxiliar na recuperação de informações, aumentando a precisão das informações recuperadas por o sistema de recuperação de informação.
Esse desempenho pode ser analisado, por exemplo:
Por a comparação da utilização dos termos nominalizados (substantivos concretos e abstratos);
por o número de RLBs utilizadas na expansão da consulta;
Por o número de termos utilizados na expansão da consulta.
O desempenho das técnicas de EC pode ser avaliado por:
Por o cálculo da precisão, abrangência e MAP das informações recuperadas por o sistema.
Em o contexto dessa dissertação, no que tange a avaliação dos experimentos, foram realizadas as análises:
Número de RLBs utilizadas para a EC;
Tipo de RLBs utilizadas para a EC, número de termos utilizados para a EC.
E para a avaliação foram realizados cálculo das métricas:
Precisão, abrangência e MAP.
A dissertação tem como objetivo geral estudar os efeitos resultantes da aplicação de expansão de consulta em conjunto com o Modelo TR+ num sistema de recuperação de informação.
Espera- se que a EC auxilie o usuário, possibilitando que o sistema obtenha maior eficiência no atendimento de suas expectativas.
A técnica empregada vem agregar suas características à estratégia não clássica de representação de documentos e consultas já utilizada por o modelo.
Organização do texto da dissertação O texto da dissertação está organizado em 7 capítulos, seguido de referências e anexos.
Modelos como o Booleano, o Modelo Espaço Vetorial e o Probabilístico são abordados, com suas características.
Nós como importantes para este trabalho.
Em este capítulo descrevemos técnicas com e sem a participação do usuário para a EC.
Em o Capítulo 4 apresentamos as características do Modelo TR+, seu funcionamento e suas peculiaridades.
Em o Capítulo 5 apresentamos alguns trabalhos recentes que utilizam EC em seus estudos e que serviram, de alguma forma, para nortear o trabalho desenvolvido nesta dissertação.
Em o Capítulo 6 apresentamos os experimentos realizados para a validação da proposta da dissertação assim como os resultados obtidos em cada caso.
Em o Capítulo 7 finalizamos a dissertação com as considerações sobre o trabalho desenvolvido, apontando contribuições, limitações e algumas propostas para sua continuidade.
2 Recuperação de Informação Segundo Baeza--Yates e Ribeiro-Netto Recuperação de Informação (Ri) tem o objetivo de representar, armazenar, organizar e acessar alguma informação.
A representação e organização deve possibilitar, ao usuário, acesso rápido e fácil às informações de seu interesse.
Manning Definem o papel de um SRI como sendo de encontrar material (geralmente documentos), de uma natureza não estruturada (geralmente texto), que satisfaça a necessidade de uma informação dentro de grandes coleções (geralmente armazenadas em computadores).
Entretanto a identificação da real necessidade do usuário no momento em que ele busca alguma informação não é uma tarefa trivial.
Para tornar mais fácil ao usuário encontrar informações desejadas em grandes repositórios de informações, foram desenvolvidos os Sistemas de Recuperação de Informação (SRI).
Um SRI, é um sistema de computador capaz de armazenar, recuperar e manter informações.
Com a criação dos SRIs pôde- se então minimizar o esforço do usuário ao procurar a informação desejada.
De entre as informações ou itens recuperados por um SRI, estão os documentos textuais.
SRIs que se preocupam em recuperar documentos textuais têm a finalidade de encontrar documentos que possam conter a resposta para alguma questão que o usuário necessite responder e não encontrar a resposta em si.
Em a Figura 1 apresentamos o processo de recuperação de informação proveniente de Orengo.
Em a Figura 2 apresentada por Chen e Gey, podemos observar os componentes que constituem a arquitetura de um SRI.
A base para qualquer sistema de recuperação de informação são os chamados modelos clássicos de recuperação de informação.
Em a Seção 2.1 serão apresentados os modelos clássicos de SRIs, assim como suas características e seu funcionamento.
As palavras que são utilizadas como termos de índice são principalmente substantivos.
A utilização de substantivos como termos de índice se justifica, por o fato de que substantivos possuem uma semântica fácil de ser identificada.
Adjetivos, advérbios e conectivos são menos úteis como termos de índice porque eles trabalham principalmente como complementos.
Nem todos os termos de um documento podem ser utilizados como um termo de índice, pois não são todos os termos que são capazes de descrever o conteúdo de um documento.
De fato alguns termos são menos expressivos que outros, não contribuindo para a identificação do conteúdo do documento a que ele pertence.
Decidir a importância de um termo para a indexação e sumarização de um documento não é uma tarefa simples.
Apesar de esta dificuldade, as propriedades de um termo de índice podem ser medidas, sendo esta medida útil para avaliar o potencial de cada termo para descrever o conteúdo de um documento.
Podemos exemplificar da seguinte maneira:
Em uma coleção de documentos que possua centenas de milhares de documentos, uma palavra que apareça em todos os documentos é completamente inútil como um termo de índice, pois através deste termo não é possível identificar o documento que o usuário deseja recuperar.
Por outro lado, seguindo o mesmo exemplo quanto a o número de documentos, palavras que estão presentes somente em poucos documentos são úteis como termos de índice, pois restringem e muito o número de documentos que o usuário possa ter interesse de recuperar.
Com isso, podemos identificar quanto a sua relevância através de termos que estejam dentro de um documento.
Baeza-Yates e Ribeiro-Netto definem o grau (peso) que identifica a relevância de um termo quanto a sua capacidade de representar um documento como:
Seja ki um termo de índice, seja dj um documento, e seja wi, j\&gt; $= 0 um peso associado ao par ki, dj.
Entre os modelos de informação existe uma classificação a qual é denominada taxonomia dos SRIs.
Tal taxonomia não será tratada em seu todo, sendo alvo deste estudo os chamados modelos clássicos dos sistemas de informação.
Em a Figura 3, é possível ver a taxomonia dos modelos de recuperação de informação.
Apresentamos uma breve revisão teórica para que possamos ingressar com mais profundidade no estudo dos três modelos clássicos dos SRIs propostos na literatura.
Os modelos clássicos de recuperação de informação que abordaremos nas subseções 2.1.1, 2.1.2 e 2.1.3, são respectivamente:
Modelo Booleano, modelo Vetorial e modelo Probabilístico.
Modelo Booleano O modelo Booleano é reconhecido como um modelo de recuperação de informação simples Partindo da possibilidade de se intuir um conceito num conjunto, o modelo Booleano facilita As consultas no modelo Booleano são especificadas numa expressão Booleana a qual possui uma semântica precisa.
O modelo Booleano recebe grande atenção por parte de desenvolvedores de sistemas comerciais, isso se deve por a sua inerente simplicidade e seu forte formalismo.
Em a Figura 4, podemos ver o modelo Booleano quanto a sua concepção junto a teoria dos conjuntos.
De acordo com Baeza-Yates e Ribeiro-Netto o modelo Booleano possui sua estratégia de recuperação é baseada num critério de decisão binária (o documento recuperado é relevante ou não é relevante à consulta efetuada), sem nenhuma noção de classificação, o qual impede que esse modelo tenha um bom desempenho na recuperação de documentos.
Segundo Baeza-Yates e Ribeiro-Netto, uma vez que uma expressão Booleana possui uma semântica precisa, a tradução das informações necessárias para uma expressão Booleana é um processo nada trivial.
Por isso muitos usuários tem dificuldades em expressar suas necessidades com clareza na hora de realizarem sua consulta no sistema.
Convencionalmente uma consulta q é essencialmente composta por termos de índice e por os três conectivos lógicos:
NOT; And e OR.
Baeza-Yates e Ribeiro-Netto, explicita que o modelo Booleano tenta identificar a não relevância do documento à consulta realizada.
O modelo Booleano não possui uma combinação parcial para uma condição da consulta.
A maior vantagem do modelo Booleano é seu formalismo claro e sua simplicidade.
A principal desvantagem é a necessidade de se ter uma exata combinação entre a consulta e os documentos a serem recuperados, podendo ocorrer portanto, uma recuperação de um número muito pequeno ou um número muito grande de documentos.
Sabe- se que a utilização de pesos não binários nos termos de índices pode acarretar uma substancial melhoria na performance da recuperação de informação.
Modelo Vetorial Segundo Salton, o modelo vetorial utiliza- se de pesos não binários para o processo de recuperação de informação, propondo assim uma estrutura capaz de fazer uma combinação parcial entre a consulta e os documentos.
Isto é realizado por uma atribuição de pesos não binários para os termos de índice de uma consulta e para os termos de índice dos documentos.
Os pesos dos termos são utilizados para que se possa calcular o grau de similaridade entre cada documento armazenado no sistema e a consulta do usuário.
Por classificação, a recuperação de documentos se dá em ordem decrescente ao grau de similaridade.
O principal efeito resultante é uma resposta à consulta através de um conjunto de documentos ordenados, muito mais preciso Ribeiro-Netto, 1999).
Um documento dj e a consulta q de um usuário são representados por vetores t-dimensionais, como podemos ver na Figura 5.
Onde o cosseno do ângulo é o grau de similaridade entre a consulta dj e o documento q..
De acordo com Baeza-Yates e Ribeiro-Netto, a avaliação do grau de similaridade entre o documento dj e a consulta q é proposto por o modelo vetorial, sendo a correlação entre os vetores dj e q..
Esta correlação pode ser quantificada, por o cosseno do ângulo entre estes dois vetores.
Sendo: Onde dj representa o vetor do documento d e q representa uma consulta.
O ranking dos documentos não é influenciado por q, uma vez que o fator é o mesmo para todos os documentos.
O fator dj fornece a normalização do documento no espaço.
Sabe- se que a partir de wi, j\&gt; $= 0 e wi, q\&gt; $= 0, a similaridade sim (q, dj) varia entre 0 e 1.
Assim, o modelo vetorial organiza um ranking de documentos de acordo com o grau de similaridade entre a consulta e o documento, não se preocupando em tentar descobrir se o documento é ou não relevante para a consulta.
Para melhorar a recuperação, pode- se determinar um limiar para o grau de similaridade, para que se recuperem somente os documentos acima de tal limiar, desprezando os documentos que não tenham alcançado o limiar estabelecido.
Entretanto, para que se possa fazer um ranking dos documentos recuperados, deve- se explicitar antes como serão obtidos os pesos dos termos.
Salton e MacGill, demonstram várias maneiras de se calcular o peso de um termo de índice.
Em este trabalho serão tratados apenas princípios básicos que dão suporte às técnicas de clustering.
Tais técnicas são descritas como:
Tendo uma coleção C de objetos e uma pequena descrição de um conjunto A, tem- se como objetivo para um algoritmo de clustering, separar a coleção C em dois conjuntos:
O algoritmo precisa determinar que conjunto é composto por objetos pertencentes ao conjunto A. É necessária uma pequena descrição do conjunto, pois não se possui uma informação completa para decidir precisamente quais os objetos fazem ou não fazem parte do conjunto A;
O algoritmo precisa determinar quais são as características que melhor diferenciam os objetos do conjunto A dos objetos restantes da coleção C. O primeiro conjunto de características é fornecido para a quantificação de um cluster interno.
Um algoritmo eficiente de clustering tenta balancear estes dois efeitos.
A similaridade de um clustering interno, no modelo vetorial é quantificada por a freqüência de um termo ki dentro de um documento dj.
Segundo Salton e MacGill, a freqüência do termo utilizada é chamada de tf (do inglês term frequency) e provê uma medida da capacidade do termo de descrever o conteúdo de um documento (caracterização interna do documento).
Além disso, a dissimilaridade interna do cluster é determinada por a freqüência inversa do documento (idf do inglês inverse document frequency) ki entre os documentos de uma coleção.
Utiliza- se o idf uma vez que termos que aparecem em muitos documentos não são bons para representar um documento de modo que se possa definir se o documento é relevante.
Definição: De acordo com Baeza-Yates e Ribeiro-Netto, seja um número N o número total de documentos no sistema e seja ni o número de documentos em os quais o termo de índice ki esteja presente.
Seja f reqi, j a frequência do termo ki no documento dj (o número de vezes que o termo ki é mencionado no texto no documento dj).
Então, a freqüência normalizada fi, j do termo ki no documento dj pode ser dada por:
Onde o max é calculado sobre todos os termos que são mencionados no texto de um documento dj.
Se o termo ki não aparece no documento dj então fi, j $= 0.
Adicionalmente, idfi, a freqüência inversa do documento por o ki é dada por:
Uma alternativa para se obter um peso com maior precisão para o termo é dada por BaezaYates e Ribeiro-Netto utilizando- se de:
Wi, j $= fi, j × log ni Concluindo, as principais vantagens do modelo vetorial são:
A utilização de peso para os termos melhora o desempenho da recuperação;
A utilização da estratégia de comparação parcial permite a recuperação dos documentos que estão próximos à condição da consulta;
Sua fórmula de ranking utilizando o cosseno classifica os documentos de acordo com o seu grau de similaridade em relação a consulta.
Teoricamente a desvantagem do modelo vetorial é o fato de assumir que os termos de índice são mutuamente independentes.
Entretanto, na prática, considerar- se um termo dependente pode ser uma desvantagem.
Devido a a dependência de muitos termos, sua aplicação indiscriminada para todos os documentos da coleção pode diminuir sua performance.
Modelo Probabilístico O modelo probabilístico de recuperação de informação foi definido por Robertson e Spark Jones.
Mais tarde esse modelo viria a ser conhecido como modelo de recuperação de independência binária.
O modelo probabilístico visa recuperar informação utilizando uma estrutura probabilística.
A recuperação de informação utilizando o modelo probabilístico, tem como idéia principal recuperar o documento relevante de forma exata e nada além disso.
De posse da descrição exata do conjunto de resposta, a recuperação destes documentos torna- se uma tarefa trivial.
Com isso, Baeza-Yates e Ribeiro-Netto definem que a ação de realizar uma consulta, nada mais é do que o ato de especificar as propriedades de um conjunto de respostas ideais.
Infelizmente as propriedades não são conhecidas por nós, sendo conhecido apenas que os termos de índice são utilizados para caracterizar tais propriedades.
O usuário pode ajudar a identificar o conjunto de respostas ideais examinando o resultado da recuperação de documentos e decidindo quais documentos são relevantes e quais não são relevantes.
O sistema então usa essas informações para refinar a descrição do conjunto ideal de respostas.
Por a repetição desse processo espera- se alcançar um conjunto o mais perto possível do conjunto ideal de respostas.
O modelo probabilístico é baseado na seguinte suposição fundamental:
Supõe- se que dada uma consulta q de um usuário e um documento d na coleção, o modelo probabilístico tenta estimar a probabilidade do usuário encontrar o documento d, ou algum outro documento relevante a sua busca.
O modelo probabilístico assume, que a relevância da probabilidade tem relação direta com a representação do documento e com a consulta.
Entretanto o modelo assume que estes documentos são um subconjunto de todos os documentos que o usuário deseja, para um conjunto de respostas que satisfaçam uma consulta q..
Um conjunto ideal de respostas é etiquetado com R e este conjunto deve melhorar a probabilidade de relevância para o usuário.
Documentos do conjunto R são determinados como sendo relevantes de acordo com a consulta.
Documentos que não estão presentes no conjunto R são referidos como não-relevantes à consulta.
Tendo- se uma consulta q, o modelo probabilístico atribui a cada documento d a medida da similaridade com a consulta, a relação P (probabilística) mostra a relevância ou não de d (consulta) para q (documento).
Com isso calculando a probabilidade de d ser relevante para a consulta q..
Examinando- se as probabilidades de relevância utilizando- se um ranking de documentos pode- se minimizar julgamentos errados, (S. E. Robertson &amp; Porter, Definição:
Baeza-Yates e Ribeiro-Netto definem que para o modelo probabilístico, consulta q é um subconjunto dos termos de índice.
Desde que R seja um conjunto de documentos conhecidos (ou supostamente conhecidos) como relevantes, o vetor R seja o complemento de R (i.
e, o conjunto de documentos não relevantes).
seja a probabilidade desse documento dj ser relevante para a consulta q e P (R| dj) seja a probabilidade deste documento dj ser relevante para q..
A similaridade sim (dj, q) entre o documento dj e a consulta q é definida por:
Usando as regras de Bayes temos:
É a probabilidade para a seleção randômica de documentos dj de um conjunto R de documentos relevantes.
P (R), é a probabilidade do documento selecionado randomicamente ser relevante dentro de a coleção.
P (R) é calculado para todos os documentos na coleção.
Baeza-Yates e Ribeiro-Netto descreve:
Assumindo a independência dos termos de índice, temos:
É a probabilidade do termo de índice ki estar presente na seleção randômica dos documentos do conjunto R. P (ki| R) é a probabilidade do termo de índice ki não estar presente na seleção randômica de um conjunto R. As probabilidades associadas ao conjunto R têm significados análogos para a descrição.
Examinando os algoritmos, e tendo P (ki| R)+ P (ki| R) $= 1 e ignorando fatores o quais são constantes para todos documentos no contexto das mesmas consultas, nós podemos finalmente escrever:
Esta é uma expressão importante no modelo probabilístico para se calcular o ranking.
É necessário fazer ou planejar um método para calcular inicialmente as probabilidades P (ki| R) e P (ki| R) uma vez que no início não se conhece o conjunto R. Existem muitas maneiras de se obter o cálculo das probabilidades, esta é apenas uma das maneiras existentes.
A seguir serão discutidas duas maneiras de se calcular as probabilidades.
Em o início do processo (imediatamente depois da especificação da consulta), não há nenhum documento recuperado.
Assim sendo, pode- se assumir duas simplificações que são:
É constante para todos os termos de índice e ki, e assume- se que a distribuição dos termos de índice entre os documentos não relevantes pode ser aproximada por a distribuição dos termos de índice entre todos os documentos da coleção.
As simplificações são:
Onde, como já definido ni é o número de documentos que contêm o termo de índice ki e N é o número total de documentos da coleção.
Dado esta suposição inicial, segundo Baeza-Yates e Ribeiro-Netto nós podemos recuperar documentos que contenham termos da consulta e prove um ranking probabilístico inicial para eles.
Depois disto, este ranking inicial é melhorado como segue.
Seja V um subconjunto de documentos inicialmente recuperados e ordenados por um modelo probabilístico.
Assim um subconjunto ao topo do ranking pode ser definido, por instâncias, constituido de r documentos ordenados onde r é um limiar definido previamente.
Seja Vi um subconjunto de V composto de documentos de V e que contém o termo de índice ki.
Podemos simplificar da seguinte maneira:
V e Vi são usados para identificar o número de elementos neste conjunto.
Para melhorar o ranking probabilístico, (a) é necessário melhorar as suposições utilizando P (ki) e P (Ki| R) para a distribuição dos termos de índice ki entre todos os documentos recuperados, e (b) podemos através de P (ki| R) considerar que todos os documentos não recuperados são documentos não relevantes.
Baeza-Yates e Ribeiro-Netto (1999) assumindo isso, determinam que:
Estes processos podem ser repetidos recursivamente.
Assim, é possível melhorar as suposições para as probabilidades P (ki| R) e P (ki| R) sem assistência humana ao assunto (contrari- ando a idéia inicial).
A última fórmula para P (ki| R) e P (ki| R) onde, frente a valores pequenos de V e Vi são tratados na prática como.
Para burlar este problema Baeza-Yates e Ribeiro-Netto sujerem que um fator de ajuste seja adicionado a freqüência, através:
A utilização da constante 0,5 nem sempre é eficiente.
Uma alternativa para se achar o valor da constate ideal (ou o mais próximo de o ideal), é fracionar ni/ N.
São fatores de ajustamento:
Baeza-Yates e Ribeiro-Netto finalizam o estudo a respeito de o modelo clássico probabilísitico, explicitando as vantagens e desvantagem desse modelo.
A principal vantagem do modelo probabilístico, é que os documentos são ordenados em ordem decrescente em sua probabilidade de ser relevante para com a consulta.
A desvantagem inclui:
A necessidade de uma suposta separação inicial dos documentos em conjuntos de documentos relevantes e não relevantes;
O fato do método não levar em consideração a freqüência em que o os termos de índice ocorrem dentro de os documentos (todos os pesos são binários);
E (iii) a adoção da independência assumida para os termos de índice.
Métricas para avaliação de Sistemas de Recuperação de Informação Em esta seção abordaremos as métricas de avaliação de SRIs mais utilizadas.
Segundo Manning Para se mensurar a efetividade de um sistema de recuperação de informação é necessário uma coleção de testes que contenham três características:
Relevante ou não relevante para cada par consulta-documento.
A proposta padrão para avaliação de SRIs envolve a noção de documentos relevantes e documentos não relevantes.
De acordo com as necessidades dos usuários, um documento numa coleção de teste recebe uma classificação binária onde se diz que o documento é relevante ou não relevante.
A coleção de documentos de teste e a suíte de informações necessárias para o usuário devem possuir um tamanho razoável.
A relevância é estimada para uma informação necessária, não uma consulta.
Podemos exemplificar do seguinte modo:
&quot;A informação de que a união da prática de exercícios físicos e o hábito de uma alimentação saudável são eficazes para uma vida mais longa.»
Esta informação pode ser traduzida para uma consulta assim:
Um documento é relevante se a consulta acima for dirigida à informação necessária, e não porque isto simplesmente contém todas as palavras na consulta.
Esta distinção é muitas vezes confundida na prática, porque as informações necessárias não são claras.
Se um usuário digitar num mecanismo de busca web a palavra Puma, ele pode estar tentando encontrar um exemplar do felino Puma.
Ou estar procurando informações sobre a marca de roupas esportivas com o mesmo nome.
A o se utilizar somente uma palavra à uma consulta, torna- se muito difícil para o sistema saber qual a informação que o usuário realmente necessita.
Entretanto é certo que o usuário sabe qual a informação ele necessita, e ele pode julgar o resultado retornado com base na sua relevância para isso.
Para avaliar o sistema, é necessário uma expressão clara de uma informação que o usuário necessita, o qual pode ser utilizado para o julgamento dos documentos retornados como relevantes e não relevantes.
Para a definição da relevância ou não do documento retornado é utilizado um valor binário, 1 para relevante e 0 para não relevante.
Isto é feito para a simplificação da avaliação da relevância do documento que pode ser ajustado para afinar a performance do sistema.
Segundo Manning É um erro relatar os resultados numa coleção de teste que obteve seus parâmetros afinados para maximizar sua performance numa coleção.
Tal afinamento aumenta a expectativa da performance do sistema, porque os parâmetros serão maximizados para um conjunto de consultas em particular.
Em este caso o procedimento correto é ter um ou mais coleções de teste, e afinar os parâmetros durante o desenvolvimento da coleção de teste.
O responsável por a coleção de teste então executa o sistema com aqueles parâmetros na coleção de teste e relata os resultados para tal coleção como uma estimativa parcial de performance.
Para a avaliação de SRIs além de as métricas apresentadas anteriormente, faz- se necessária a utilização de coleções de textos para testes.
A seguir apresentaremos algumas coleções conhecidas da literatura e que são ou foram utilizadas para a avaliação do desempenho de SRI.
A Coleção Cranfield foi a primeira coleção de teste que permitiu mensurar quantitativamente a eficiência da recuperação de informações.
A coleção Cranfield1 começou ser coletada no início dos anos de 1950, contendo 1.398 resumos de notícias de jornal sobre aerodinâmica, um conjunto de 225 consultas, e um julgamento exaustivo de relevância para todas os pares (consulta-documento).
Text Retrieval Conference (TREC) foi desenvolvido por o Instituto Nacional de Padrões e Tecnologia (NIST) 2 realizou inúmeros testes para avaliação de Ri desde 1992, utilizando muitas trilhas com diferentes coleções de teste.
As coleções de testes renderam durantes esses anos 6 CDs contendo 1,89 milhões de documentos.
Os documentos em sua maioria mas não todos oriundos de artigos de notícias de jornais.
Os documentos estão distribuídos em 450 temas distintos.
Atualmente as TRECs foram descontinuadas, sendo sua posição tomada por o CLEF.
O Forum de avaliação de multilíngües (CLEF) 3, avalia a recuperação de informações em línguas européias em vários idiomas.
Recentemente o NIST tem realizado avaliações utilizando coleções de documentos num tamanho muito maior do que o que era utilizado nas TRECs.
O NIST incluiu em suas avaliações a coleção de páginas web denominada GOV24.
Esta coleção conta com 25 milhões de páginas web.
A coleção GOV2 foi desenvolvida para avaliar SRIs de grandes empresas de busca web.
O projeto NTCIR5 foi desenvolvido com várias coleções de teste de mesmo tamanho para a coleção TREC.
Seu desenvolvimento foi focado em idiomas da Ásia Oriental e tradução de informações recuperadas, onde consultas são realizadas num idioma numa coleção que contenha um ou mais documentos de outros idiomas.
A agência de notícias Reuters6 possui atualmente duas coleções desenvolvidas, Reuters21578 e Reuters-RCV1.
A coleção Reuters-21578 é muito utilizada para à classificação de textos e ela é constituída de 21.578 artigos de notícias.
Reuters-RCV1, consiste de 806.791 documentos.
A Coleção Newsgroups7 é muito utilizada para a classificação de textos.
Esta coleção possui notícias sendo considerado uma categoria).
Após a remoção dos artigos duplicados a coleção conta com 18.941 artigos.
Avaliação de conjuntos de documentos não ordenados As duas medidas mais freqüentes para se mensurar a eficácia de um SRI é o cálculo da precisão e abrangência.
O cálculo dessas métricas é realizado sobre o resultado da consulta realizada.
Precisão (Pr) é a fração dos documentos recuperados que são relevantes, e é expressada por a seguinte fórmula:
Pr $= DocumentosRelevantesRecuperados DocumentosRecuperados Abrangêngia (Ab) é a fração dos documentos relevantes que são recuperados, e é expressada por a seguinte fórmula:
DocumentosRelevantesRecuperados DocumentosRelevantes Precisão e Abrangência pode ser feita examinando a Tabela 1:
Podemos expressar o conteúdo da Tabela 1 utilizando as seguintes fórmulas:
Outra medida muito utilizada é chamada Medida F (do inglês F-measure) (Baeza-Yates&amp; Ribeiro-Netto, 1999), que utiliza o produto entre Precisão e Abrangência, calculando assim a média harmônica entre Precisão e Abrangência.
A Medida F pode ser empregada segundo a seguinte fórmula:
Onde: Onde e assim 2.
A Medida F balanceada utiliza igualmente Precisão e $= 1.
A Medida F balanceada é comumente expressado como Abrangência, utilizando $= 2 F1, que é uma abreviação de F $= 1.
Quando usado $= 1, podemos apresentar a seguinte fórmula:
No entanto, mesmo utilizando um fator de ponderação esta não é a única opção.
Valores de 1 dão ênfase à precisão, enquanto valores de\&gt; 1 da ênfase à abrangência.
Por exemplo, um valor de $= 3 ou $= 5 pode ser utilizado se a abrangência é o que se busca.
Precisão, Abrangência e Medida F são inerentemente medidas entre 0 e 1, entretanto elas também são comumente escritas na forma de porcentagem, numa escala entre 0 e 100.
Avaliação de conjuntos de documentos ordenados Precisão, abrangência e medida-F são medidas baseadas em conjuntos.
Eles são calculados usando um conjunto de documentos não ordenados.
Precisamos estender estas medidas (ou definir novas medidas) se formos avaliar os resultados da recuperação ordenados presentes nos mecanismos de buscas atuais.
Em o contexto de recuperação ordenada, o conjunto apropriado de documentos recuperados é naturalmente dado por os k documentos recuperados ao topo da lista de documentos.
A curva Precisão-Abrangência é estudada da seguinte forma:
Se o esimo documento recuperado é considerado não relevante, então a abrangência é a mesma para k documentos ao topo da lista de documentos recuperados, mas a precisão cai.
Se for relevante, então ambos, precisão e abrangência aumentam, e a curva sobe para a direita.
Para amenizar esta característica da curva, é utilizada a precisão interpolada (do inglês Interpolated Precision) (Manning, 2008).
A precisão interpolada (Pinterp) numa certo nível de abrangência r é definido como a mais alta precisão encontrada por qualquer nível de abrangência r'\&gt; $= r:
Pinterp (r) $= M axr'\&gt; $= r Pinterp (r') Outra medida tradicional, utilizada na avaliação dos SRIs por as TRECs é a Precisão Média, 2008).
Para cada informação necessária, a precisão interpolada é medida em 11 níveis Para cada nível de abrangência, calculamos a média aritmética da precisão interpolada para cada nível de abrangência.
Atualmente outras medidas são mais comuns.
Um exemplo disso é a Precisão Média (do inglês mean average precision (MAP)) (Buckley &amp; Voorhees, 2004).
Entre as medidas de avaliação, MAP mostra- se especialmente boa em discriminação e estabilidade.
Para cada informação buscada, a precisão média é a média do valor da precisão obtido para o conjunto dos k ordenados Rjk o maior resultado dk, então:
Quando um documento relevante não é recuperado, o valor da precisão da equação acima assume o valor 0.
Para uma única informação buscada, a precisão média aproxima- se da área sob a curva interpolada precisão-abrangência para o conjunto de consultas.
Utilizando MAP, os níveis de abrangências não são escolhidos, e não há interpolação.
O valor MAP para a coleção de avaliação é a medida aritmética dos valores da média da precisão para cada informação buscada.
A pontuação calculada para a MAP normalmente varia à cada informação buscada dentro de um mesmo sistema.
Isto significa que um conjunto de necessidades de informação teste deve ser amplo e diversificado o suficiente para ser representativo do sistema de eficácia em diferentes consultas.
As medidas vistas até o momento, excetuando- se a medida MAP, têm seus fatores de precisão calculados para todos os níveis de abrangência.
Entretanto para aplicações como buscas na web esta abordagem não é pertinente para o usuário.
Para esses usuários o que interesse na realidade são quantos bons resultados são disponibilizados para eles na primeira página ou no máximo nas três primeiras páginas.
Isto reduz a mensuração da precisão poucos níveis de resultados recuperados fixados entre 10 e 30 documentos.
Esta medida A vantagem dessa medida é a de não ser necessário saber previamente o tamanho do conjunto do corpus.
A desvantagem dessa medida é que ela é menos estável que as demais medidas, pois, o número total de documentos relevantes para uma consulta influência a precisão para K documentos.
Uma alternativa para o problema encontrado na medida Precisão para K, é a media RPrecisão (do inglês R-Precision).
O conjunto de documentos relevantes pode ser incompleto, tais quando a relevância é formada por a criação do julgamento de relevância para os melhores k resultados de um sistema particular num conjunto de experimentos.
R-Precisão ajusta para o tamanho do conjunto de documentos relevantes.
Se os documentos são relevantes para uma consulta, examinamos os melhores resultados relevantes de um sistema, e descobrir que r são relevantes, então por definição não somente é a precisão (e portanto R-Precisão) r/| REL|, mas a abrangência deste conjunto de resultados é também r/| REL|.
Assim R--Precisão é idêntico a medida Ponto de Equilíbrio (do inglês Break-even Point).
A medida Ponto de Equilíbrio é outra medida utilizada, definida em termos de relacionamentos explorados.
Como a Precisão para K, R-Precisão descreve somente um ponto na curva Precisão-Abrangência, especialmente que tenta resumir a eficácia em toda a curva, uma vez que o usuário deve estar interessado num ponto de equilíbrio e não deve querer saber o melhor ponto da curva (o ponto máximo utilizando a Medida-F) ou a recuperação do nível de interesse de uma aplicação específica (Precisão para K).
Outras duas medidas aplicada rotineiramente quando utilizado aprendizado de máquina para classificação de documentos é o Ganho Cumulativo (do inglês Cumulative Gain) e a medida Ganho Cumulativo Descontado Normalizado (do inglês Normalized Discounted Cumulative Gain (NDCG)).
O NDCG é utilizado para situações onde não se utiliza a noção binária para a relevância de documentos.
Como a Precisão para K, esta medida é avaliada sobre qualquer K ao topo do resultado.
Sendo R (j, d) a pontuação de relevância dado por os avaliadores para o documento d para a consulta j.
Entao: Onde ZK e um fator de normalização calculado.
Este fator tem o intuito de tornar- lo um perfeito ranking de NDCG sendo este 1 para K. Para consultas para cada K'K documentos são recuperados e o último somatório é realizado até K'.
Avaliação de Relevância Para a avaliação correta de um SRI, a informação que se busca encontrar tem que ser relevante para aos documentos existentes na coleção de documentos de teste, e deve ser apropriado para o sistema.
As informações buscadas são melhores designadas por um especialista do domínio.
Utilizando combinações aleatórias de termos de consultas como uma informação a ser recuperada geralmente não é uma boa idéia porque tipicamente estes termos não irão se parecer com a atual distribuição das informações buscadas.
Dadas as informações buscadas, é necessário coletar a avaliação da sua relevância.
Este processo é demorado e dispendioso quando executado por seres humanos.
Para coleções pequenas como a Coleção Cranfield, julgamento exaustivos de cada consulta e cada documento é realizada.
Já para coleções maiores como são as coleções atuais, é usual o julgamento da avaliação da relevância ser realizado somente para um subconjunto dos documentos para cada consulta.
Este método é denominado de Pooling, onde a avaliação da relevância é realizada sobre um subconjunto da coleção que é formada por K documentos retornados melhor ranqueados.
Um humano pode não ser confiável para reportar um julgamento correto de relevância de um documento para uma consulta.
Particularmente e seus julgamentos de relevância são totalmente particulares e variáveis.
Mas isto não é problema para ser resolvido, na analise final, o sucesso de um SRI depende em quão bom esta avaliação satisfaz a necessidade destas particularidades humanas, uma informação buscada por vez.
Todavia, isto é interessante para considerar e medir o quanto há de entendimento entre julgadores e as informações julgadas relevantes.
Em a ciência social, uma medida comum de entendimento entre julgadores é a medida chamada Estatística Kappa (do inglês Kappa Statistic).
Esta medida é designada para o julgamento absoluto e correto um simples acordo medido para avaliar a mudança de entendimento entre os julgamentos. Onde
P (A) é a proporção das vezes julgadas ajustadas, e P (E) é a proporção de vezes que ele espera concordar por mudança.
Em a Tabela 2 podemos observar o entendimento entre os julgamentos 1 e 2: Limites conciliados P (não relevantes) $= (80+ 90)/ (400+ 400) $= 170/800 $= 0,2125 P (relevantes) $= (320+ 310)/ (400+ 400) $= 630/800 $= 0,7878 A probabilidade de dois juízes concordarem por a mudança P (E) 8 $= P (não relevante)+ P (relevante) $= 0,2125+ 0,7878 $= 0,665 Estatística Kappa A avaliação do julgamento de relevância por parte de os julgadores humanos é utilizada em muitas coleções, como por exemplo, as TRECs e na coleções médicas.
Utilizando para isso as regras mostradas na Tabela 2.
Considerações sobre o capítulo Em este capítulo apresentamos uma revisão da literatura sobre Recuperação de Informação.
Abordamos para este trabalho os modelos clássicos para o processo de recuperação de informa8 A estatística limítrofe é calculada somando as linhas ou colunas.
E modelo Probabilístico.
Esta revisão foi muito importante para o melhor entendimento do funcionamento do processo de recuperação de informação e assim poder discernir melhor a respeito de os sistemas de recuperação de informação.
Em este capítulo também abordamos as principais métricas para mensurar o desempenho da recuperação de informação.
Apresentamos também algumas coleções de documentos que são utilizadas com freqüência para a avaliação do processo de Ri.
Em a Subseção 2.2.1 apresentamos as métricas de avaliação para o processo de recuperação de documentos não ordenados.
Em a Seção 2.2.2 apresentamos as métricas utilizadas para a avaliação de conjuntos o resultado do processo de recuperação de documentos ordenados.
Este estudo foi muito importante para o processo de avaliação dos experimentos realizados nesta dissertação.
Com este estudo podemos formular melhor a avaliação dos resultados obtidos além de conhecer outras métricas que são habitualmente utilizadas para avaliação da Ri.
Em o próximo Capítulo (Capítulo 3) apresentaremos uma revisão da literatura sobre Expansão de Consultas e Realimentação de Relevantes (Seção 3.2).
A o abordarmos as técnicas de EC apresentamos duas proposta de análise de documentos, Análise Automática Local e Análise Automática Global, seções 3.1.1 e 3.1.2 respectivamente.
A o apresentarmos a técnica de Realimentação de Relevantes, abordaremos sua aplicação em conjunto com os modelos clássicos de Ri, Modelo Espaço Vetorial, Modelo Booleano (Seção 3.2.2) e Modelo Probabilístico (3.2.3).
Em a Seção 3.2.4 apresentamos o método de Pseudo Realimentação de Relevantes, este método é uma variação da Realimentação de Relevantes e visa automatizar a escolha das informações que serão adicionadas às consultas originais.
Expansão de Consultas Em a expansão de consulta (EC), os usuários contribuem adicionando na consulta inicial palavras ou frases.
Alguns mecanismos de buscas sugerem consultas relacionadas às respostas da consulta original (mecanismos de buscas web), cabendo ao usuário utilizar umas destas sugestões para expandir a consulta original.
A Figura 6 mostra um exemplo de consulta realizada no mecanismo de busca web Yahoo!
1. Em a consulta realizada foi utilizado a palavra &quot;car», e partindo dessa consulta o mecanismo pode sugerir novas palavras para a expansão da consulta.
A questão central nesta forma de expansão de consulta é como gerar alternativas ou consultas expandidas para o usuário.
As formas mais comuns de expansão de consulta são a análise automática global e a análise automática local.
Análise Automática Local Em a estratégia de análise local, os documentos recuperados para uma certa consulta q são examinados no tempo da consulta para determinar os termos que serão utilizados na expansão da consulta.
O processo é similar a pseudo realimentação de relevantes, que apresentaremos na Subseção 3.2.4, ou seja, não utiliza a iteração do usuário para a expansão da consulta.
Croft, 1996).
Uma vantagem da realimentação local é que ela pode ser relativamente eficiente para realizar a expansão baseada nos documentos no topo do ranque dos documentos recuperados por a consulta original.
Isto pode ser levemente mais lento em tempo de execução, entretanto não é necessário a construção de um thesaurus.
A realimentação local requer um busca e acesso da informação no documento extra.
Se a informação do documento é armazenada somente para este propósito, então isto deverá ser contado como um espaço extra em disco para a técnica, entretanto, isto pode ser significativamente menor que uma base de dados de conceitos.
A desvantagem da realimentação local é que ainda não tem muitas alternativas de se trabalhar quando as consultas recuperam poucos documentos relevantes.
Análise do contexto local é uma técnica que combina características tanto da análise global quanto da realimentação local.
A análise do contexto local utiliza grupos de substantivos como conceitos e estes conceitos são selecionados baseados na co-ocorrência com os termos da consulta.
Os conceitos são escolhidos dos documentos melhor ranqueados entre os documentos recuperados por a consulta original (processo similar a realimentação local), mas as melhores passagens são utilizadas ao invés de a totalidade dos documentos.
Conceitos (substantivos) nas n melhores passagens são ranqueados de acordo com a seguinte equação:
Onde:· c é um conceito;·
ftij é o número de ocorrências de ti em pj;·
fcj é o número de ocorrências de c em pj· N é o número de passagens na coleção;·
Ni é o número de passagens contendo ti;·
Nc é o número de passagens contendo c;·
é 0,1 para o valor de &quot;bel «igual a 0.
A fórmula acima é uma variação da medida tf idf.
Em a fórmula, af recompensa os conceitos onde os termos da consulta co-ocorrem freqüentemente, o idfc penaliza conceitos que ocorrem muito na coleção, o idfi enfatiza termos da consulta com baixa freqüência.
A multiplicação da ênfase a co-ocorrência com todos os temos da consulta.
Análise do contexto local possui muitas vantagens, entre eles estão a sua praticidade computacional.
Para cada coleção é necessário somente uma única passagem para coletar a freqüência dos termos e dos substantivos.
A principal desvantagem da análise do contexto local é que este pode requerer um tempo grande para a expansão das consultas.
Análise Automática Global A idéia básica na análise global é que o contexto global de um conceito pode ser utilizado para determinar a similaridade entre conceitos.
Contexto como conceitos podem ser definidos de várias formas.
Em uma definição simplista, todas as palavras são conceitos (excetuando- se as palavras definidas como stopwords) e que o contexto para uma palavra é toda palavra que co-ocorre num documento com tal palavra.
O principal diferencial da análise global, é que ela é usada somente para expansão de consulta, e não substitui a representação original do documento baseada nas palavras.
Crouch e Yang apresentam uma proposta com a utilização de agrupamentos para determinar a análise do contexto para o documento.
Uma das primeiras técnicas que apresentou resultados consistentes e efetivos foi a análise de global aplicada ao sistema INQUERY.
A técnica utilizada no sistema INQUERY, determina que conceito como sendo um grupo de substantivos (um, dois ou três substântivos adjacentes), e o contexto é definido como uma coleção de tamanho determinado (uma janela) em torno de os conceitos (Qiu &amp; Frei, 1993).
Uma janela para ser efetiva possui entre uma e três sentenças.
Um caminho para a visualização da técnica, entretanto de difícil implementação, é o caminho de considerar cada conceito (grupo de substantivo) para ser associado com um pseudo documento.
O conteúdo do pseudo documento, são as palavras que ocorrem em cada janela a tal conceito no corpus.
Por exemplo, o conceito airline pilot pode ter as palavras pay, strike, safety, air, traffic e FAA ocorrendo freqüentemente no pseudo documento correspondente, de acordo com o corpus analisado.
O banco de dados do INQUERY é construído a partir de os pseudo documentos, criando um bando de dados de conceitos.
A principal vantagem da proposta expansão de consulta com análise global, é que ela é relativamente robusta no que tendem o desempenho médio das consultas para este tipo de expansão.
A desvantagem da proposta expansão de consulta com análise global é que a proposta pode ser muito onerosa em se tratando de espaço de disco e tempo computacional para a análise do contexto global e construir uma base de dados pesquisável, e consultas individuais podem ser significativamente degradadas para a expansão.
Realimentação de Relevantes A Realimentação de Relevantes (RR) (Relevance Feedback -- RF) é um processo automático para a modificação da consulta inicial num SRI com base no julgamento da relevância dos documentos recuperados anteriormente.
A idéia por trás da RR é envolver o usuário no processo de Ri para melhorar o resultado final da recuperação.
Em particular os usuários devem julgar a relevância dos documentos recuperados num resultado preliminar.
O processo de RR melhora a formulação da consulta escolhendo termos importantes de documentos considerados relevantes por o usuário recuperados por a consulta original.
Realimentação de Relevantes prevê a participação do usuário para identificar informações importantes à consulta original.
Estas informações podem ser documentos inteiros ou partes dos mesmos.
De o conjunto de documentos inteiros ou partes destes julgados como relevantes por o usuário é feita a extração dos termos ou expressões que incrementarão a consulta original, gerando assim uma nova consulta.
O processo RR é um método interativo que pode ser repetido quantas vezes forem necessários, até o momento em que o usuário estiver satisfeito com o resultado da consulta.
Os procedimentos básicos para RR são:·
O usuário realiza uma consulta;·
O sistema retorna um conjunto de documentos como resultado inicial;·
O usuário marca alguns dos documentos retornados como relevantes ou não relevantes· O sistema calcula a melhor representação da informação pesquisada com base na realimentação do usuário;·
O sistema mostra ao usuário um conjunto revisado do resultado recuperado.
Em a Figura 7, podemos observar o processo de RR para melhorar a consulta original.
As principais vantagens da RR são a sua simplicidade e bons resultados.
Outras vantagens para a utilização do processo de realimentação de relevantes:·
Auxilia os usuários através do processo de reformulação da consulta;·
A operação de busca é realizada numa seqüência de pequenos passos para aproximar o resultado da consulta como o que o usuário necessita;·
Permite um processo controlado das alterações da consulta, visando destacar certos termos, como requer ambientes de busca em particular.
O conceito de realimentação de relevantes foi introduzido em meados da década de 1960.
A RR pode ser aplicada utilizando diversos modelos de Ri.
Em este trabalho abordaremos a utilização de RR nos modelos clássicos de Ri.
Realimentação de Relevantes no Modelo Espaço Vetorial O processo de realimentação de relevantes orginalmente, foi desenvolvido para ser aplicado utilizando vetores de consultas.
Estes vetores são definidos sem a presença de operadores Booleanos.
O processo orginal de RR pode ser apresentado da seguinte forma:
Onde q1 representa o peso do termo 1 na consulta Q0.
O peso dos termos variam entre 0 a valorado com peso igual a 1, está fortemente presente na consulta.
O processo de realimentação de relevantes dará origem a uma nova versão da consulta original, que pode ser apresentada da seguinte forma:
Onde q1 representa o peso referente a o termo 1 modificado.
A adição de novos termos podem ser exercida modificando o peso de 0 para um valor maior que 0.
Este processo de valoração do termos busca aproximar o vetor da consulta de documentos relevantes, ao mesmo tempo em que ele se deva se afastar dos documentos não relevantes para a consulta.
Harman apresentou uma revisão do processo de realimentação de relevantes.
Em esta revisão do processo de RR, é apresentado três métodos para a utilização da realimentação de relevantes inserida no Modelo Espaço Vetorial.
Estes três métodos basicamente unem os vetores dos documentos aos vetores da consulta inicial.
Os três métodos apresentados são:·
Ide Regular n1 n2 Rk -- k $= 1 Sk k $= 1· Ide dec-hi n1 Rk -- S1 k $= 1· Rocchio n1 k $= 1 Rk Sk n1 n2 k $= 1 Onde:·
Rk é o vetor para o documento relevante k;·
Sk é o vetor para o documento não relevante k;·
ni é o número de documentos relevantes;·
n2 é o número de documentos não relevantes;·
e são parâmetros que controlam a contribuição dos documentos relevantes e não relevantes.
Como exposto anteriormente, os três métodos tem como procedimentos básicos a união dos vetores dos documentos e os vetores da consulta original.
Esta união dos vetores realiza uma nova definição dos pesos dos termos da consulta original de forma automática.
Este processo soma o novo peso ao peso da ocorrência atual dos termos da consulta nos documentos relevantes.
Em contrapartida a nova definição dos pesos, subtrai do peso dos termos da consulta original os pesos dos termos da consulta presentes nos documentos não relevantes.
A consulta original tem seus termos expandidos por a adição automática dos termos presentes nos documentos relevantes e não relevantes e que não ainda não estavam presentes na consulta original.
A expansão das consultas é realizada, utilizando somente pesos oriundos de documentos relevantes.
Os termos dos documentos julgados não relevantes participa do processo de expansão modificando os pesos dos novos termos vindos de documentos relevantes.
O método Ide dec-hi utiliza somente documentos julgados não relevantes para a realimentação.
São utilizados os documentos melhor ranqueados, descartando os documentos não relevantes recuperados e apresentados ao usuário.
O método Rocchio, utiliza é baseado na normalização do peso dos documentos, este esquema é utilizado tanto em documentos relevantes como para os documentos não relevantes Salton e Buckley apresentaram uma comparação dos três métodos em experimentos realizados em dois níveis de expansão de consulta em seis corpus diferentes.
O melhor método para todo os seis corpus foi o Ide dec-hi, embora a diferença para os demais métodos seja pequena.
Para o método Rocchio, o melhor resultado foi alcançado utilizando $= 0,25 e $= 0,75, limitando com isso o efeito da realimentação negativa, sendo isto feito de forma automática por o método Ide dec-hi.
Realimentação de Relevantes no Modelo Booleano A o compararmos a utilização do processo de realimentação de relevantes aplicado ao modelo Booleano com os demais modelos clássicos (Espaço Vetorial e Probabilístico), podemos dizer que o primeiro é utilizado em menor escala do que os demais.
Segundo Orengo, isto acontece porque na realimentação de relevantes a escolha dos termos é crucial e no modelo Booleano é necessário a escolha dos operadores para que se possa relacionar os termos.
O modelo Booleano de realimentação utiliza informações relevantes providas por o usuário para calcular o peso para os termos nos documentos recuperados.
Estes pesos são utilizados para ordenadar os termos, buscando a construção de uma nova consulta será constituída de duas partes, uma parte com termos com pesos altos, considerados bons termos e outra parte com termos com pesos baixos, considerados termos ruins.
Tanto os termos considerados bons e ruins, são divididos em dois grupos.
Termos bons são divididos termos do segundo grupo em pares, cada termo é colocado em pares com qualquer outro termo no grupo.
Termos ruins são dividos por a regra, onde os termos do pior grupo são em pares na forma, para todos os pares.
O método de realimentação de relevantes utilizando o modelo Booleano é constituído segundo Salton e MacGill em duas etapas:
Etapa de construção de boas cláusulas e etapa de construção da consulta Booleana modificada, utilizando algumas cláusulas previamente escolhidas.
A utilização da cláusula (que pode ser um termo único ou um conjunto de termos conectados por o operador &quot;e&quot;) depende do seu peso de relevância e da transferência da freqüência esperada.
A medida do peso de relevância é importante para saber se a clausula é útil para recuperar documentos relevantes.
A realimentação da consulta consiste de um conjunto de cláusulas conectadas por o operador lógico ou.
Realimentação de Relevantes no Modelo Probabilístico O modelo probabilístico é baseado na idéia apresentada por Robertson e Spark Jones da distribuição dos termos da consulta em relevantes e não relevantes.
Esta distribuição é realizada, definindo- se os pesos dos termos, da pontuação dos documentos recuperados, e por a soma entre os pesos dos termos presentes nos documentos presentes na consulta.
A definição do peso dos termos é realizada por a seguinte fórmula (Robertson &amp; Spark Jones, wij $= log2 R-r n-r N n-R-r Onde:·
r $= o número de documentos relevantes que possuem o termo i.
Jones apresenta um experimento similar a utilização da fórmula de pesagem de relevantes numa situação operacional de realimentação de relevantes, em a qual o usuário verifica somente alguns documentos relevantes num conjunto inicial de documentos recuperados, e daqueles poucos documentos são somente disponíveis para o esquema de pesagem.
O resultado desta nova pesagem com somente alguns documentos relevantes mostrou melhora significante no seu desempenho em comparação com a performance da definição de novos pesos utilizando somente a medida IDF.
Isto indica que o esquema de nova pesagem probabilística provê um método eficaz para realimentação de relevantes especialmente na nova pesagem dos termos.
A principal vantagem da utilização do modelo probabilístico em conjunto com a realimentação de relevantes, segundo Baeza-Yates e Ribeiro-Netto, é que o processo de realimentação de relevantes é diretamente relacionado para a derivação de novos pesos para os termos da consulta.
Suas desvantagens são:
A definição dos pesos dos termos dos documentos não são realizados na iteração do processo de realimentação;
Pesos calculados em formulações de consultas anteriores são desprezadas;
Não é utilizada em expansão de consulta, somente termos presentes na consulta inicial são pesados novamente.
Para uma recuperação mais eficiente, na abordagem de RR utilizando o modelo Probabilístico, é utilizada a ordenação dos documentos em forma decrescente de acordo com a seguinte fórmula:
P r (x| rel) P r (x| nonrel) Onde:
Pr (x| rel) e Pr (x| nonrel) são a probabilidade da representação de um item relevante ou não no vetor x.
A definição dos termos é realizada independentemente da relevância dos documentos da coleção.
Os pesos dos termos atribuidos aos documentos são definidos utilizando valores binários 0 e 1.
Para o cálculo da similaridade entre a consulta e o documento, podemos utilizar a derivação da equação 3.8, aplicando- à a consulta e cada documento D $ , através de dois parâmetros (pi e ui) que representam a probabilidade que o i-ésimo termo tenha um valor 1 e um documento relevante ou não.
Equação 3.8 derivada é apresentada da seguinte forma:
Onde: Pi $= Pr ui $= Pr O cálculo da similaridade entre a consulta e os documentos, não pode ser utilizada na prática sem o conhecimento prévio para todos os termos do documento dos valores de pi e ui.
Segundo Salton e Buckley alguns métodos foram apresentados para o cálculo dos valores de pi e ui.
Para a pesquisa inicial, quando ainda não se tem conhecimento da relevância das informações dos documentos, assume- se que o valor para pi é constante e geralmente 0,5.
A Tabela 3 apresenta a ocorrência do termo i num subconjunto de documentos relevantes e não relevantes, ui pode ser definido o equivalente ni/ N, a proporção dos documentos na coleção que possui o termo i.
Para a rodada inicial, a expressão 3.9 é então reduzida para sim -- inicial (D, Q) $= dj log i $= 1 N -- ni ni Em o contexto da realimentação das consultas, os valores acumulados e relacionados à relevância dos itens recuperados são utilizados para avaliar a fórmula 3.9.
A avaliação é realizada por a distribuição do termo nos itens relevantes recuperados anteriormente.
Esta distribuição é a mesma para todo o conjunto de itens relevantes, sendo os itens não recuperados rotulados como não relevantes.
Aplicando os fatores presentes na Tabela 3 para aos documentos recuperados da coleção, temos que:
Onde na fórmula 3.13 R representa o número total de itens relevantes recuperados, ri é o número total de itens relevantes recuperados que possuem o termo i, e ni é o número total de itens recuperados que possuem o termo i.
Salton e Buckley, para alguns valores muito pequenos para R e ri A fórmula 3.13, pode causar alguns problemas.
Estes problemas freqüentemente acontecem na prática, por causa de a expressão logarítmica é então reduzida à 0.
Para amenizar este problema, muitas vezes um fator de ajuste é adicionado na definição de pi e ui.
Com isso as fórmulas 3.14 e 3.15 são utilizados em sistemas probabilísticos convencionais para a obtenção dos valores de pi e ui.
Entretanto segundo Salton e Buckley, o fator de ajuste nem sempre é satisfatório, para estes casos, utiliza- se como alternativa o calculo do valor de pi e ui tal que, ni/ N ou (ni ri)/ (N -- R).
Quando documentos não relevantes são recuperados por a consulta inicial, a melhor estimativa para pi, a probabilidade que um termo ocorra num documento relevante é simplesmente a probabilidade de sua ocorrência na coleção completa.
Em este caso, pi $= ni/ N. O fator de ajuste (ni/ N) utilizados nas equações 3.16 e 3.17, substitui o fator 0,5 presentes nas equações 3.14 e 3.15.
Quando os documentos relevantes que não foram recuperados for pequeno, podemos utilizar o fator de ajuste alternativo (ni -- ri)/ (N -- R) (Salton &amp; Buckley, Salton e Buckley, apontam como vantagem do modelo de realimentação probabilística, a utilização do processo de realimentação ser diretamente relacionado à derivação de um peso para termos da consulta.
A o analisarmos a função de similaridade da equação 3.9, podemos observar que o fator de pesagem de log é aumentada para cada termo da consulta i.
Onde é combinado um documento, e o peso do termo ideal sob as condições assumidas de independência do termo e indexação binária do documento (Salton &amp; Buckley, Pseudo Realimentação de Relevantes Pseudo Realimentação de Relevantes (PRR), provem um método para uma análise automática local.
Esta técnica automatiza a parte manual da realimentação de relevantes, de modo que o usuário visa melhorar o desempenho da recuperação diminuindo a interação com o sistema.
O método de pseudo realimentação de relevantes consiste em realizar uma recuperação de informação normal para encontrar um conjunto inicial de documentos relevantes, após a recuperação inicial este método assume que os n documentos recuperados ordenados no topo da lista de documentos recuperados são relevantes.
De posse destes n documentos recuperados preliminarmente, o método realimenta a consulta original com as novas informações.
Manning Apontam que o método de pseudo realimentação de relevantes tende a funcionar melhor do que o método de análise global, apresentado na Subseção na Figura 8, podemos observar o processo de pseudo realimentação de relevantes.
Pseudo realimentação de relevantes é uma variável da realimentação de relevantes que pode lançar mão de todas as técnicas utilizadas na RR.
Considerações sobre o capítulo Em o Capítulo 3 apresentamos uma revisão da literatura sobre as Expansão de Consultas e Realimentação de Relevantes 3.2.
Com este estudo apresentamos as duas técnicas que a literatura aponta para a análise de documentos, sendo:
Análise automática local e análise automática global.
A o estudarmos EC pudemos ter uma visão mais ampla de suas características, benefícios e limitações, o que foi muito importante para o desenvolvimento da dissertação.
Também neste capítulo, apresentamos um estudo sobre Realimentação de Relevantes (Subseção 3.2), onde abordamos a utilização da RR empregando os modelos clássicos de Ri apresentados na Seção 2.1.
Além de abordarmos RR, também apresentamos uma variação de RR denominada Pseudo Realimentação de Relevantes na Subseção 3.2.4.
O estudo tanto sobre RR como PRR foi fundamental para a definição e aplicação destas técnicas no desenvolvimento desta dissertação.
Em o próximo Capítulo (Capítulo 4), apresentaremos o modelo de recuperação de informação utilizado nesta dissertação denominado TR+.
Apresentaremos detalhadamente as características do Modelo TR+ que foram utilizadas por nós neste trabalho.
Em a Seção 4.1 apresentamos o processo de Nominalização dos termos, na Seção 4.2 apresetamos a definição das relações lexicais binárias, na Seção 4.3 apresentamos o Conceito de Evidência, na Seção 4.4 apresentamos a formulação da consulta por o Modelo TR+.
Segundo Gonzalez, podemos definir o Modelo TR+ como um modelo de Ri, pois além de o Modelo TR+ ser capaz de representar textos, também apresenta outras características de um modelo de Ri como:
Indexação, consulta e recuperação de documentos.
Uma outra característica que está presente no Modelo TR+ e que o caracteriza como um modelo de Ri é a definição do espaço dos descritores.
A definição do espaço dos descritores se dá da seguinte forma:
Wt, d e Wr, d são mensurados utilizando a fórmula baseada no conceito de evidência.
Em a Figura 9 proveniente de Gonzalez, podemos observar a fase de indexação de documentos do Modelo TR+.
Em a Figura 10, também proveniente de Gonzalez, é apresentada a etapa de busca dos documentos no Modelo TR+.
Em a Figura 9 são apresentadas as etapas necessárias para serem gerados os espaços dos descritores.
O Modelo TR+ utiliza um tratamento equivalente à construção dos descritores de conceitos (termos simples e compostos) tanto para os documentos como para as consultas realizadas( (i) disjunção lógica entre as RLBs e (ii) conjunção lógica entre os termos e as RLBs) antes do processo de busca e classificação dos documentos.
Os relacionamentos entre os termos nominalizados que possuem a capacidade de capturar mecanismos de coesão frásica são chamados de Relações Lexicais Binárias (RLBs) (Gonzalez, 2005).
TR+, uma forma própria de representação.
Processo de Nominalização Gonzalez cita como definição de nominalização Kehdi, que diz que nominalização é um processo de formação de palavras em o qual um novo substantivo é derivado de uma palavra existente no léxico, principalmente verbos e adjetivos.
Já no Modelo TR+, Gonzalez define nominalização como sendo, a transformação de uma palavra (adjetivo, verbo (incluindo o particípio) ou advérbio), existente no texto, num substantivo semanticamente correspondente, formado através de regras válidas de formação de palavras.
Em o Modelo TR+, substantivos abstratos e concretos são derivados, sendo os substantivos abstratos representando:
Eventos, qualidades, estados, ou outras entidades abstratas capazes de serem derivadas de adjetivos, verbos (incluindo particípio) ou advérbios.
Já substantivos concretos via de regra representam palavras derivadas de verbos ou de adjetivos.
Em a Tabela 4, apresentamos exemplos de nominalização, onde substantivos abstratos e concretos são gerados apartir de verbos (incluindo- se particípios), já adjetivos e advérbios quando passados por o processo de nominalização originam substantivos abstratos.
Utilizando o exemplo apresentado por Gonzalez para exemplificar o processo de nominalização de palavras de as quais não são derivadas de substantivos concretos nem de substantivos abstratos, podemos observar o adjetivo &quot;ovo «(Tabela 4).
Comparando- o com o adjetivo &quot;fluvial», podemos explicar com mais facilidade a não possibilidade do processo de nominalização.
Podemos observar que a equivalência entre &quot;barco fluvial «e &quot;barco de rio «não está presente em &quot;barco oval «e &quot;barco de ovo».
Isto ocorre porque &quot;oval «e &quot;ovo «não são equivalentes, uma vez que &quot;oval «está relacionato ao seu formato (neste contexto, em forma de ovo).
Assim, o adjetivo &quot;oval «é considerado um descritor deste contexto mais adequado para tal do que o substantivo &quot;ovo».
Em o processo de nominalização, no contexto lexical, existem palavras que se mantêm idênticas após o processo.
Em a Tabela 4, podemos observar a palavra &quot;velho», que pode aparecer tanto na forma de adjetivo quanto como substantivo (neste caso, substantivo concreto).
Em o Modelo TR+, os termos adicionados no espaço de descritores, são substantivos originários de um dado texto ou ainda palavras de outras classes, quando não há a possibilidade de se nominalizar- las.
Os substantivos originários de um dado texto são normalizados utilizando o processo de lematização.
São adicionados no espaço de descritores substantivos oriundos da nominalização de adjetivos, advérbios e verbos (incluindo- se particípios).
A concepção dos termos nominalizados desconsidera o tratamento de acentuação ou a forma maiúscula ou minúscula dos termos, sendo esses definidos sem acento e na forma minúscula.
Esses termos denonimados de &quot;termos nominalizados «constituem os argumentos das RLBs.
Apresentaremos em mais detalhes as RLBs na Seção 4.2.
Definições das Relações Lexicais Binárias Relações lexicais binárias (RLBs) são relacionamentos entre termos nominalizados, que capturam mecanismos de coesão frásica.
O processo de identificação dos pesos dos descritores pode utilizar- se das relações lexicais binárias para tal.
Segundo Gonzalez, podemos categorizar as RLBs em três tipos (classificação, restrição e associação) para representar o texto.
Cada tipo de RLB possui um formato próprio, apresentando argumentos específicos que desempenham papéis próprios.
A forma de apresentação de uma RLB é dada da seguinte maneira:
Onde id é um identificador de relação;
T1 e t2 são argumentos (constituidos de termos nominalizados).
Podemos representar os tipos de RLBs e suas características da seguinte maneira:·
Classificação: O identificador da relação é representado por o sinal de igualdade ($ );
T1 representa uma subclasse ou uma instância de t2;
E t2 representa uma classe.
Exemplo: $= (gato, animal) $= (miau, animal)· Restrição:
O identificador da RLB é representado por uma preposição;
T1 representa um elemento modificado;
T2 representa um elemento modificador.
Exemplo: De (equipe, futebol) com (analista, experiencia)· Associação:
O identificador da RLB é representado por um evento;
T1 é um sujeito;
T2 é um objeto (direto ou indireto) ou adjunto.
Exemplo: Superação (trabalhador, dificuldade) moradia.
Em (rainha, londres) Em os exemplos apresentados para as RLBs do tipo associação, podemos observar que seu id, pode se apresentar na forma de preposição, desta forma fica garantido que a relação apareça com dois argumentos.
Segundo Gonzalez, as RLBs dos tipos restrição e associação podem (mas não somente) apresentar em seu id o seguinte formato:
Em o exemplo exposto à RLB do tipo restrição &quot;de (equipe, manutencao)», podemos admitir a utilização para o id do formato evento.
Preposicão teríamos então:
Em o Modelo TR+, o cálculo do peso dos descritores é realizado utilizando- se as RLBs, não havendo distinção quanto a o seu tipo.
Para o Modelo TR+ a identificação do tipo das RLBs é importante para a organização destas em arquivos de índice, visando com isso o aumento do desempenho da pesquisa das RLBs durante o processo de busca na recuperação dos documentos.
Gonzalez define as relações das RLBs como sendo assimétricas, por o fato dos seus argumentos possuírem papéis específicos, constituindo assim uma estrutura de relacionamentos capacitado para a representação dos textos contidos nos documentos (ver exemplo transcrito de Gonzalez no Anexo B).
A classificação das RLBs pode ser realizada tanto por o seu tipo (classificação, restrição e associação) quanto por a sua nominalização (Original ou Derivada).
Podemos exemplificar a classificação das RLBs quanto a sua nominalização da seguinte forma:·
Original: Quando nenhum componente sofreu nominalização Exemplos:·
Derivada: Quando ao menos um compontente sofreu nominalização Exemplos:
João correu -- $= (joão, corredor) O objetivo apontado por Gonzalez na inclusão das RLBs no espaço dos descritores é de aumentar a amplitude da descrição dos textos.
Gonzalez ao descrever as RLBs afirma que estas apresentam relações semânticas equivalentes as apresentadas na estrutura Qualia na teoria do Léxico Gerativo, justificando com assim a utilização das RLBs na recuperação de informação.
A estrutura Qualia, na teoria do Léxico Gerativo, descreve um item lexical' através de quatro papéis:
Formal, constitutivo, agentivo e télico.
Podemos exemplificar tais papéis da seguinte maneira:·
Formal: Diferência' num amplo domínio;
Exemplo: $= (carro, maquina) O carro seria distinguido como uma máquina.·
Constitutivo: Indica o que faz parte de';
Exemplo: Em este exemplo o carro seria fabricado de alumínio.·
Agentivo: Especifica qual a razão de' passar a existir;
Exemplo: Por (composição, autor) Em este exemplo é especificado que a composição é referente a um dado autor.·
Télico: Explica qual a função ou propósito de;
Exemplo: Em este exemplo a função do mecânico seria consertar o vazamento.
Apesar de estas características, Gonzalez afirma que não pretende que as RLBs &quot;interpretem «com distinções, indicações, especificações ou explicações dos tipos apresentados acima.
O objetivo é caracterizar as RLBs como descritores de tais fatos sem a necessidade da utilização de rótulos, excetuando- se a RLB do tipo classificação que utiliza inevitavelmente o rótulo &quot;$ ».
Sem a presença de rótulos pré-estabelecidos, Gonzalez afirma que não tem como pretenção que a preposição &quot;para «indique um propósito, ou ainda que a preposição &quot;por «represente uma ação realizada para o algum agente.
A definição das preposições nas RLBs é dada através da utilização de regras de identificação), e tem como objetivo, descrever algo que o sistema não consegue interpretar, mas entretanto, mesmo que seja representado em ocorrência sintática distintas, deva ser descrito da mesma forma.
Com tudo isso, Gonzalez pretende com a utilização das RLBs, que estas sejam capazes de descrever conceitos independetemente da forma como estes aparecem no texto.
Assim pode- se dizer que as RLBs conceitualizam a &quot;evidência «aplicadas aos descritores.
O conceito de evidência apresentaremos a seguir na Seção 4.3.
Conceito de Evidência Segundo Ferreira e Houaiss, evidência é a condição do que se destaca, é a qualidade do que é evidente e, por sua vez, evidente é aquilo que não oferece ou não dá margem à dúvida.
Em o Modelo TR+ o cálculo dos pesos dos descritores é realizado utilizando o conceito de evidência.
Para o cálculo do peso dos descritores além de a freqüência de ocorrência do descritor no texto, o Modelo TR+ também utiliza a ocorrência das RLBs.
Gonzalez esclarece que o resultado do cálculo do peso de um descritor no Modelo TR+ leva em consideração o processo de nominalização, a capacidade das regras para identificação de RLBs de deduzir estruturas de dependência evidentes e a formulação do cálculo do peso dos descritores.
A representatividade dos descritores é impactada por a nominalização dos mesmos, já que este processo de normalização lexical coloca num único descritor diferentes palavras.
Descritores que passam por o processo de normalização lexical tendem a possuir um peso maior quando comparados com aqueles que não sofreram tal processo, pois os descritores normalizados acumulam a freqüência de ocorrência de outros descritores, uma vez que este representa um conjunto de palavras.
Gonzalez destaca que este processo de normalização pode ser incluído no conceito de transformação de termos &quot;ruins «em termos &quot;bons «apresentado por Salton e MacGill.
A definição da representatividade dos descritores também é impactada por as regras utilizadas para a identificação das RLBs, pois tais regras são capazes de reconhecer somente estruturas de dependência evidentes.
As dependências com preposições a direita após a segunda preposição, são tratadas como sendo &quot;não evidentes».
Gonzalez apresenta o seguinte exemplo:
Analizando estes exemplos, somente a RLB &quot;de (arrombamento, cofre) «seria identificada.
Já as RLBs, &quot;com (arrombamento, explosivo)», &quot;com (cofre, explosivo)», &quot;com (arrombamento, joia) «e &quot;com (cofre, joia) «não são reconhecidas.
Com isso alguns descritores perdem representatividade (RLBs e os termos em elas presentes como argumento) sendo penalizados pois não atende ao conceito de evidência (onde deve haver destaque e não pode haver dúvidas).
Gonzalez destaca que essa abordagem possui duas vantagens, menor esforço computacional (por o não tratamento de ambiguidades), (ii) a utilização do conceito de evidência na influência do cálculo do peso dos descritores faz com que quanto mais evidente mais representativo o descritor será.
Considerando o exemplo apresentado por Gonzalez, (a) &quot;arrombamento do cofre com explosivos», podemos apresentar o cálculo do grau de representatividade através das seguintes descrições:
De os conceitos relacionados a cada um de seus argumentos e a descrição de seus relacionamentos.
Seguindo o mesmos exemplo, &quot;arrombamento do cofre com explosivos», a RLB deve receber 3 unidades de evidência (1 unidade pois há um &quot;arrombamento&quot;;
1 unidade pois há um &quot;cofre&quot;;
E=1  unidade por haver um &quot;arrombamento do cofre&quot;).
Cada ocorrência dos unidade, que é metade do valor atribuído descritores &quot;arrombamento «e &quot;cofre «receberia 1 1 à RLB.
Por ultimo, o descritor &quot;explosivo», por ser o menos evidente, receberá 2 unidade de evidência, diminuida de 1 unidade por a falta de coesão evidente.
O mesmo ocorre &quot;joia «no exemplo (b).
O descritor envolvido recebe uma unidade de evidência a cada nova coesão.
Gonzalez apresenta a seguinte explicação para o cálculo do grau de representatividade dos descritores:
&quot;os termos t1 e t2 e a RLB r, encontrados numa consulta q, têm dupla contribuição no cálculo do valor de relevância de um documento d, caso t1 e t2 estejam relacionados através de r em d..
De o contrário, se t1 e t2 ocorrem em d mas não estão relacionados através de r, a contribuição é simples e, assim, d tende a perder posições na classificação por relevância a q».
Cálculo do peso dos Descritores e do valor de Relevância Para o cálculo do peso dos descritores o Modelo TR+ utiliza a abordagem probabilística, pois tal abordagem mostrou- se mais eficiente para a recuperação de informação, segundo Gonzalez.
Entretanto, Gonzalez deixa claro que o Modelo TR+ pode se utilizar da abordagem vetorial para o cálculo dos pesos dos descritores.
A Equação 4.2, uma adaptação da fórmula OKAPI BM25 apresentada na Equação 4.3 sem o fator IDF (Gonzalez atesta que a utilização do IDF não apresentou melhoria nos resultados dos experimentos), é adotada por o Modelo TR+.
O peso Wi, d do descritor i no documento d é dado por:
Wi, d $= onde:
DLd)+ wi, d K1+ b AV· wi, d é a freqüência do descritor i no documento d;·
Ki, b, DLd e ADVL são os mesmos componentes utilizados na fórmula Okapi BM25.
Wi, d $= wi, d IDFi DLb+ wi, d) k1+ b AV onde:·
Ki e b são parâmetros;·
DLd é o comprimento (a quantidade de palavras) do documento d;·
AVDL é o comprimento médio dos documentos da coleção;·
IDFi $= Log dfi· N é o número de documentos na coleção;·
dfi o número de documentos onde i ocorre.
A evidência wi, d, representada através de wt, d para um termo t num documento d, é calculada da seguinte forma no Modelo TR+:·
ft, d é a freqüência de ocorrência de t em d e· fr, t, d é a quantidade de RLBs onde t é argumento em d, e para uma RLB r, a evidência wi, d num documento d, representada por wr, d é:·
fr, d é a freqüência de ocorrência de r em d e· wt, d é a evidência do argumento d de r em d;
O Anexo B, transcrito de Gonzalez, apresenta alguns exemplos onde é apontado resultados do cálculo baseado em evidência, em comparação à formulação baseada apenas em freqüência de ocorrência.
Os termos e a RLBs são obtidos e têm seus pesos calculados utilizando a mesma abordagem tanto para uma consulta q, quanto para os documentos.
Entretanto, para cada RLB r presente na consulta q, sendo, r $= id, uma RLB ré incluida na consulta Booleana qb, sendo, r '$= id', onde id' é qualquer identificador diferente de id (conforme é exemplificado na Seção 4.4).
O peso Wr, q de r'depende do peso Wr, q de r, sendo penalizado por possuir identificador diferente, mesmo que r e r'possuam os mesmos argumentos.
Wr, q é dado por:
Wr, q Para se obter o valor de relevância VRd, q tanto para um documento d como para uma consulta qé utilizada a seguinte equação:
Wr, q $= (Wi, d, Wi, q) V Rd, q $= onde:·
Wi, d é o peso de termos e/ ou RLBs do documento d e· Wi, q é o peso de termos e/ ou RLBs da consulta q..
Após a definição dos termos e RLBs, assim como seus respectivos pesos, os documentos tem sua classificação dependente do valor da relevância dos mesmos e da formulação da consulta Booleana.
Consulta Booleana A formulação da consulta Booleana qb, no contexto do Modelo TR+, é realizada de acordo com a gramática apresentada a seguir, com formalismo BNF:
Ou operador Booleano de disjunção E operador Booleano de conjunção elemento vazio Em este esquema, a relação entre um descritor X e, possui o mesmo valor de X. A consulta &quot;pintura restaurada», então será formulada no Modelo TR+, da seguinte maneira Ou n2 (p2)) onde:·
r1 $= de (restauracão, pintura),· r2 $= r1 minute $= de (restauracão, pintura),· n1 $ ,· n2 $= pintura,· n1 (p2) $= restauracão,· n2 (p2) $= restaurador,· p1 $= pintura e· p2 $= restaurada.
A notação &quot;$= de «significa qualquer identificador diferente de &quot;de».
Os documentos recuperados são, então, classificados em dois grupos:·
grupo superior, documentos de maior relevância:
Estão presentes neste grupo, documentos que possuem pelo menos uma das RLBs da consulta ou, possuem todos os termos da consulta;·
grupo inferior, documentos de menor relevância:
Estão presentes neste grupo, documentos que possuem pelo menos um dos termos da consulta.
Considerações sobre o capítulo Em o Capítulo 4 apresentamos as características que definem o Modelo TR+ como um modelo de Ri capaz de indexar e recuperar documentos.
Em a Seção 4.1 apresentamos o processo de transformação de uma palavra do texto num substantivo semanticamente correspondente, chama de Nominalização.
Em a Seção 4.2 apresentamos o processo de definição das RLBs, que são os relacionamentos entre os termos nominalizados.
Em a Seção 4.3, apresentamos o conceito de Evidência que é utilizado por o Modelo TR+ para o cálculo do peso dos descritores.
Em a Seção 4.4, apresentamos a formulação da consulta no Modelo TR+.
A consulta foi parte fundamental, uma vez que o modelo é parte central dessa dissertação.
O estudo do Modelo TR+ nos possibilitou colocar em prática os experimentos de aplicação da RR e PRR, uma vez que nos deu embasamento para o entendimento das características do modelo.
Em o próximo capítulo, Capítulo 5, apresentaremos alguns trabalhos selecionados por nós entre os estudados durante o desenvolvimento da dissertação.
Os trabalhos foram escolhidos por colaborarem para a conclusão da dissertação, Em a Seção 5.1 apresentamos a proposta desenvolvida por de avaliação entre os termos da consulta e dos documentos para expansão de consultas.
Em a Seção 5.2, apresentamos o trabalho desenvolvido por Vechtomova e Karamuftuoglu que utilizam a análise lexical para a seleção dos termos que farão parte do processo de EC.
Em a Seção 5.3, apresentamos o trabalho desenvolvido por Chirita e Nejdl, que busca a personalização da EC para a recuperação de documentos Web utilizando informações presentes nos computadores dos usuários.
Em a Seção 5.4, apresentamos o trabalho desenvolvido por Orengo e Huyck, onde através da RR os autores buscam recuperar documentos utilizando informações multilíngües.
Em a Seção 5.5, apresentamos o trabalho desenvolvido por Lee, e que visa a extração de novas amostragens de termos para EC baseados em agrupamentos utilizando PRR.
Em esta seção apresentaremos alguns trabalhos que se utilizam de expansão de consulta e que nortearam o desenvolvimento do trabalho até o presente momento.
Uma Nova Proposta para Avaliação de Expansão de Consulta:
Má Combinação entre termos da consulta e dos documentos Custis e Al-Kofahi não apresentam exatamente um método de EC, mas sim uma proposta para a avaliação da expansão de consultas utilizando a combinação dos termos da consulta efetuada por os usuários e os termos presentes nos documentos numa coleção de um domínio específico.
Os termos utilizados na consulta são retirados dos documentos julgados relevantes um a um, possibilitando com isso determinar a eficiência de diferentes sistemas de recuperação de informação no que diz respeito à perda desses termos.
Para a validação da proposta apresentada por os autores, foram realizados quatro experimentos:
Dois experimentos com a utilização da fórmula OKAPI para o cálculo dos pesos dos termos (com e sem o uso de pseudo realimentação de relevantes para a expansão de consulta);
um experimento fazendo uso do mecanismo de busca proprietário TCS, Thomson Concept Search;
E um experimento utilizando o modelo de linguagem de consulta probabilística (Query Likelihood) (Zhou &amp; Croft, 2005).
O TCS utiliza um corpus externo como fonte de conhecimento tematicamente relacionado à coleção de documentos que será pesquisada.
Para a validação dos experimentos foram utilizadas duas coleções de teste para os quatro sistemas de recuperação de informação já mencionados.
As duas coleções de teste utilizadas são:
O TREC AP89, que é uma coleção de textos da Text Retrieval Conference, e a coleção proprietária de documentos de casos legais chamada FSupp.
Em os experimentos realizados, a estratégia escolhida de remoção dos termos da consulta para toda a coleção de documentos fez uso do Inverse Document Frequence (IDF) (Salton &amp; MacGill, 1983).
Termos com alto valor para o IDF influenciam a classificação dos documentos.
Termos com alto valor para IDF geralmente são termos do domínio específico, que são menos comuns, sendo difícil para uma pessoa não especialista reconhecer- los.
Por esse motivo a remoção desses termos com alto valor para o IDF são removidos em primeiro lugar.
Para comparar a eficiência de cada sistema de recuperação de informação foram utilizadas MAP com precisão para dez documentos, e abrangência para mil documentos.
Os autores concluem que a sua proposta de avaliação de sistemas de recuperação de informação permite medir o grau de melhoria (ou não) da combinação de termos entre a consulta e documentos considerados relevantes.
A avaliação dos sistemas de recuperação de informação é realizada utilizando somente coleções inteiras de documentos evitando, com isso o uso na expansão de consulta de uma combinação de termos que não resulte numa recuperação de documentos eficiente para as necessidades dos usuários.
Outra contribuição importante é que os resultados podem ser avaliados independentemente das métricas escolhida para tal.
Também, os autores mostram que é possível modelar o comportamento de usuários analisando a combinação de termos que estes utilizam na consulta em dois grupos:
Usuários especialistas e usuários iniciantes.
Com o estudo do trabalho realizado por Custis e Al-Kofahi, identificamos a importância e viabilidade de uso da técnica de EC Pseudo Feedback para a aplicação em conjunto com o Modelo TR+ na recuperação de informação.
Unido a isso, outra importante contribuição do trabalho apresentado por Custis e Al-Kofahi foi trazer a oportunidade de um melhor conhecimento de uma situação de uso da fórmula OKAPI.
Expansão de Consulta com termos selecionados usando análise da coesão lexical dos documentos Vechtomova e Karamuftuoglu apresentam uma proposta para expansão de consultas utilizando ligações lexicais coesivas entre os termos da consulta e os termos dos documentos vizinhos aos termos da consulta no documento.
Partes do texto (Snippets) vizinhas ao termo da consulta dentro de o documento são avaliadas para expansão de consultas de forma automática.
Em o trabalho apresentado é explorada a eficácia da utilização de snippets para se expandir consultas de forma interativa com o usuário.
Os autores comparam expansão de consulta utilizando snippets do texto e expansão de consulta com o uso de documentos inteiros.
Também é mencionada no trabalho uma comparação de expansão de consultas utilizando partes do texto selecionado por o usuário versus a expansão de consulta com utilização de documentos inteiros julgados relevantes por o usuário.
A avaliação foi conduzida no TREC 2005 (Text Retrieval Conference), considerando o uso de termos de ligação e termos vizinhos de partes do texto em comparação com termos selecionados de textos inteiros.
A proposta apresentada por os autores foi comparada com a expansão de consulta utilizando a freqüência dos termos no documento como peso, onde todos os termos são extraídos de um texto completo de um documento reconhecidamente relevante, e ordenado.
Os autores apresentaram experimentos com expansão de consultas utilizando pseudo reali-mentação de relevantes para avaliar a proposta de expansão de consulta sem retorno de relevância.
A o término dos estudos concluem que ao apresentarem aos usuários os termos de partes do texto dentro de o contexto como auxílio para a expansão da consulta, os usuários selecionam termos mais eficientes, em contrapartida ao que ocorre quando expõem aos usuários termos fora desse contexto.
Os autores ainda finalizam constatando que existe uma significativa diferença no número de ligações lexicais entre termos de consultas distintas em conjuntos de documentos relevantes quando compardados a um conjunto de documentos não relevantes.
O trabalho apresentado por Vechtomova e Karamuftuoglu foi de grande valor para a formulação de nossa proposta, pois ofereceu uma visão prática da utilização da técnica de EC pseudo realimentação de relevantes, chamada neste trabalho por Vechtomova e Karamuftuoglu de Blind Feedback.
O trabalho também nos apresentou a utilização de snippets dos documentos para a EC, a utilização de snippets associada ao Modelo TR+, é uma alternativa à proposta apresentada nesta dissertação.
Entretanto devido a necessidade de modificações no Modelo TR+, não lançaremos mão de tal abordagem.
O trabalho apresentado por Vechtomova e Karamuftuoglu, fortaleceu a utilização da PRR como uma técnica de EC a ser aplicada junto ao Modelo TR+.
Expansão de Consulta Personalizada para a Web (Chirita &amp; Nejdl, Chirita e Nejdl propõem melhorar o resultado da recuperação produzido por consultas num ambiente Web expandindo- as com termos extraídos de dados obtidos a partir de o computador do usuário, num assim denominado Repositório de Informações Pessoais, dessa forma personalizando o resultado da busca.
Os autores introduziram cinco técnicas para geração de palavras-chave numa consulta, analisando dados do usuário.
Para o ajuste dos termos e análise do nível da co-ocorrência dos componentes, são utilizados thesauri externos.
A expansão da consulta do usuário é feita com novos termos usualmente extraídos de um grande thesaurus, como a WordNet, de onde se extrai os sinônimos dos termos da consulta original.
Ainda, os autores apresentam análises sob quatro cenários diferentes, mostrando que algumas destas propostas aumentam o desempenho especialmente em consultas ambíguas, melhorando a qualidade da classificação da resposta.
Chirita e Nejdl, utilizam expansão de termos baseados na WordNet, entretanto os autores basearam seus estudos na análise do relacionamento entre os dados do repositório pessoal e os termos da consulta original para definir novas palavras que formarão a consulta expandida.
A extração se dá através do cálculo da freqüência do termo nos documentos do repositório pessoal.
A análise local do repositório pessoal está diretamente relacionada com a utilização de Pseudo Realimentação de Relevantes, buscando uma melhora na geração de palavras-chave utilizadas na expansão de consultas que buscam informações na Web.
De um conjunto de documentos classificados como os mais relevantes são extraídos partes do texto que melhor os representam.
Seguindo a etapa de análise, os autores apresentam um estudo sobre a composição lexical para a identificação automática dos conceitos mais importantes na coleção de documentos.
Os autores utilizaram para determinar a composição lexical o processo de análise de substantivos, verificando a combinação dos documentos do repositório pessoal do usuário para todas as composições.
Após a análise local, os autores dirigiram seus estudos para a análise global, para extrair informações inferindo novos termos para a expansão da consulta.
Para a análise global foram estudadas duas técnicas, a primeira baseada na estatística da co-ocorrência de termos e a segunda na expansão baseada em thesaurus.
Somente substantivos são utilizados para esta proposta, os autores justificam essa escolha por a grande capacidade que os substantivos apresentam de conter informações conceituais.
Os termos dos resumos com maior grau de relação para cada termo da consulta são identificados e finalmente a correlação dos termos resultante é calculada para a consulta inteira.
Os autores ainda consideram um passo importante o cálculo do coeficiente de similaridade.
A proposta utiliza a freqüência do documento para um dado termo x, e o número de documentos que contenham tal termo x.
O número de termos utilizados na expansão de consulta é limitado, para melhorar a pontuação alcançada.
Para a validação da proposta foram realizados alguns experimentos.
O primeiro passo dos experimentos foi a instalação do mecanismo de busca proposto nesse trabalho, baseado no Lucene, indexando todos os conteúdos armazenados localmente.
A máquina de um único usuário foi alvo dos experimentos, onde foram realizadas diariamente quatro consultas.
Para cada consulta, foram selecionados os cincos endereços Web melhor classificados gerados para cada versão do algoritmo.
Cada resultado foi &quot;misturado «num conjunto de noventa endereços Web.
Com isso, cada assunto teve que ser acessado entre o conjunto de documentos (325 documentos) para todas as quatro consultas.
Foram realizadas 72 consultas e mais de 6.000 endereços Web foram avaliados durante o experimento.
Para cada endereço Web, o testador teve que entregar uma avaliação com os valores sendo:
0 (não relevante), 1 (relevante) e 2 (altamente relevantes).
Finalmente, a qualidade de cada classificação é estimada usando a versão normalizada do Ganho Cumulativo Descontado (DCG) (Järvelin &amp; Kekäläinen, 2000).
DCG atribui mais peso aos documentos que foram melhores classificados no processo de recuperação.
Analisando os resultados dos quatro cenários, o melhor cenário obteve um aumento de desempenho no que tange a qualidade dos documentos recuperados de 51,21%.
A o término do estudo do trabalho proposto por Chirita e Nejdl, ficou clara a dificuldade de se aplicar a EC utilizando informações contidas na máquina do usuário ao Modelo TR+, uma vez que, para o uso dessa referência seria fundamental dispor de um thesaurus externo como a WordNet.
Com isso a aplicação dessa proposta ao Modelo TR+ foi descartada por o tempo exigido para a construção de um thesaurus à língua portuguesa.
O trabalho proposto por Chirita e Nejdl fortaleceu a nossa decisão de utilizar a técnica de EC pseudo realimentação de relevantes, eliminando a participação do usuário para melhorar a qualidade das informações recuperadas junto ao Modelo TR+.
Realimentação de Relevantes e Recuperação de Informações Multilíngüe Orengo e Huyck apresentam um estudo de realimentação de relevantes num ambiente de recuperação de informação multilíngüe.
Os autores apresentam um experimento em o qual, falantes nativos em português julgam a relevância de documentos escritos em inglês;
Mostram como resultado para seu experimento que a tradução realizada de forma automática apresentou- se tão eficiente quanto a tradução realizada manualmente.
Além disso, o impacto do mau julgamento dos documentos no desempenho da realimentação de relevantes é moderado e varia muito para diferentes tópicos.
Orengo e Huyck utilizaram para este trabalho o sistema CLIR (do inglês Latent Semantic Indexing -- LSI).
Segundo Orengo e Huyck, o principal objetivo da utilização da LSI para a implementação do CLIR, foi de prover o sistema de recursos capazes de compara segmentos de textos escritos numa língua com segmentos de textos escritos em outra língua sem a necessidade da tradução destes textos.
Os autores utilizaram o software para tradução chamado SYSTRAN 3.
0 Professional, para traduzir cerca de 20% dos documentos da coleção.
Orengo e Huyck, escolheram utilizar o SYSTRAN 3.
0 Professional por o fato de ser muito utilizado em trabalhos que se utilizam do sistema CLIR descritos na literatura, e também por o fato do SYSTRAN 3.
0 Professional ser adotado nos experimentos realizados durante o CLEF (Cross- Language Evaluation Forum).
O corpus utilizado no experimento consiste de mais de 113.000 artigos de notícias do Jornal americano Los Angeles Times.
Esta coleção foi utilizada por fazer parte dos experimentos realizados no CLEF.
Utilizaremos a sigla originária do inglês LSI ao nos referirmos sobre indexação semântica latente.
Os experimentos foram realizados a responder duas questões principais:·
Quão bom pesquisadores nativos em português são em reconhecer a relevância de documentos escritos em inglês, comparando documentos traduzidos manualmente com documentos traduzidos automaticamente para o português?·
Qual é o impacto do mau julgamento dos documentos na performance que pode ser alcançado com a RR?
Para responder estas duas questões Orengo e Huyck recrutaram 27 usuários2 com idade média de 29 anos, falantes nativos da língua portuguesa com conhecimento básico ou sem conhecimento da língua inglesa que não conseguiriam expressar as consultas em língua inglesa mas com bom conhecimento de mecanismos de busca.
Os autores extraíram seis tópicos de consulta de um total de cinqüenta consultas do CLEF do ano de 2002, sendo utilizada uma versão em português dos tópicos.
O critério de seleção dos tópicos com base no resultado inicial foi:·
Selecione tópicos com mais de 10 documentos relevantes.
Este critério visa prevenir no quais todos os documentos relevantes são apresentados para o usuário por realimentação.·
Selecione tópicos que tem documentos relevantes entre os 10 primeiros recuperados.
Assim o método RR utiliza somente realimentação positiva, este critério foi utilizado para prevenir a situação em a qual o usuário não julga qualquer documento como sendo relevante.
Dezessete dos cinqüenta tópicos atenderam as condições impostas por os autores.
Os experimentos se deram com apresentação aos pesquisadores dos tópicos de consulta escritos em português e a uma lista de documentos ordenados retornados em resposta a consulta original.
A lista de documentos ordenados foi produzida por a presença de todos os termos do título e descrição utilizando como consulta no sistema CLIR -- LSI.
Os participantes foram convidados a classificar cada documento em relação a o tópico numa das três categorias:
Relevante; Não relevante;
Não sei.
Cada participante leu 6 consultas e 10 documentos para cada consulta, atingindo 60 julgamento de relevância por usuário e 1620 no total.
Os documentos foram apresentados na forma completa e foram expostos numa das seguintes formas:·
o texto original em inglês, retornado do sistema CLIR-LSI,· uma tradução automática produzida utilizando o software SYSTRAN 3.
0 Professional (sistema 2),· uma tradução humana.
Após recolhido o julgamento de todos os 27 pesquisadores, as consultas foram realizadas, submetidas e avaliadas novamente para a precisão e abrangência.
RR foi aplicada substituindo a consulta original por a média vetorial dos documentos selecionados por os usuários como sendo relevantes.
Depois de realizada a avaliação dos resultados, Orengo e Huyck concluíram que:·
44% dos participantes mostraram- se hábeis para avaliar documentos em língua inglesa,· a tradução automática pode realmente ajudar pesquisadores na avaliação da relevância, apesar de produzir documentos deselegantes para a leitura.
Os participantes julgaram com a mesma eficiência documentos traduzidos de forma automática e documentos traduzidos manualmente,· existe uma moderada correlação negativa entre documentos julgados erroneamente e a melhoria que pode prover o método de RR,· o fator que impacta a mudança no desempenho varia muito de um tópico para outro.
Cada tópico responde de forma própria aos julgamentos errados.
Porém, as características de cada tópico que determina o relacionamento entre a mudança no desempenho e erros no julgamento permanecem obscuros,· não foram encontrados relacionamentos entre a mudança no desempenho e a dificuldade dos tópicos ou crença no julgamento ou o conhecimento do assunto,· muitos usuários consideraram o sistema CLIR útil e gostariam que os resultados fossem traduzidos em outras línguas.
Com o estudo do trabalho apresentado por pudemos nos familiarizar com o método de realimentação de relevantes, assim como, com a forma de avaliar a relevância dos documentos recuperados por a consulta original.
Assim sendo, pudemos desenvolver os experimentos com RR em conjunto com o Modelo TR+ para a Ri aplicados nesta dissertação.
Um método de extração de nova amostragem baseado em grupos para Pseudo Realimentação de Relevantes Em este trabalho Lee Apresentam um método para definir novas amostragens baseada em agrupamentos de documentos, para assim selecionar melhores documentos que serão utilizados para a EC utilizando PRR.
A idéia principal desse trabalho é encontrar numa recuperação inicial, um conjunto de documentos &quot;dominantes «que serão utilizados para a EC e com isso enfatizarem o tópico central de uma consulta.
Lee Assumem que documentos dominantes para uma consulta, são aqueles que possuem uma boa representação do tópico de uma consulta, como por exemplo documentos com vizinhos com alta similaridade.
Utilizando a sobreposição de agrupamentos de documentos, um documento dominante aparecerá em muitos agrupamentos com uma alta ordenação.
Assim como um tópico pode ter muitos subtópicos, o conjunto recuperado pode ser dividido em muitos grupos de subtópicos.
Um documento que aparece em todos os subtópicos, provavelmente será subtópico em todos os agrupamentos, assim sendo os autores o chamam de documento dominante.
A partir desses documentos dominantes, são selecionados os termos para a expansão que recuperarão documentos relacionados.
Assim sendo Lee, selecionam novas amostragem de documentos para a realimentação de relevantes utilizando a técnica de clustering k--nearest neighbors (k-NN).
O método de nova amostragem baseado em clustering pega os melhores documentos pseudo relevantes é baseado num modelo de linguagem e no modelo de relevância que mostram ser um caminho útil para se construir um modelo de consulta dos documentos melhores classificados.
O ponto essencial desta proposta é que um documento que aparece em múltiplos clustering melhores classificados contribui mais para termos da consulta do que outros documentos.
Lee Apresentam os passos para o processo de nova amostragem de documentos da seguinte maneira:
Documentos são recuperados por uma dada consulta por o modelo de linguagem probabilística capaz de analisar uma seqüência de palavras gerando partes de um probabilístico de consulta estima modelos de linguagem de documentos utilizando o avaliador máximo probabilístico.
Os documentos podem ser ordenados por a geração probabilística de novas amostragens de consultas dos modelos de linguagem de documentos.
O próximo passo segue com a geração dos clustering utilizando o método k-NN para a recuperação dos N documentos para encontrar entre eles os documentos &quot;dominantes».
Um documento pode pertencer a mais de um clustering.
Em o clustering k-NN, cada documento desempenha um papel central no sentido de formar seu próprio clustering com seus k vizinhos mais próximos por a similaridades entre eles.
Os autores representam um por a pesagem tfidf e normalização cosseno.
A similaridade cosseno é utilizada para calcular similaridades entre os documentos recuperados melhores classificados.
Lee Têm como hipótese em que um documento dominante pode possuir muitos visinhos com similaridade alta, participando de muitos clustering.
Por outro lado documentos pertencentes a um único clustering podem não ter vizinhos com alta similaridade devido a ruídos como polissemias ou termos genéricos.
Clustering de documentos também podem refletir a associação de termos e documentos do cálculo da similaridade.
Em este trabalho, se um documento pertence a muitos clustering e os clustering são altamente relacionados com a consulta, os autores assumem isto como sendo um documento dominante.
Uma nova amostragem baseada em clustering é repetidamente alimentada com documentos dominantes baseados nos clusters de documentos.
Após a formação dos clusters, os autores ordenam os mesmos por o modelo de linguagem baseado em cluster.
Os documentos no topo do ranking dos clusters são utilizados para a realimentação.
Note que os clusters são utilizados somente para a seleção dos documentos.
Finalmente os termos que serão utilizados para a expansão da consulta original são selecionados com base no modelo de relevância para cada documento nos clusters melhor ranqueados.
O modelo de relevância é uma distribuição multinominal em a qual estima a probabilidade do termo w dado uma consulta Q. Para avaliar a proposta realizaram alguns experimentos utilizando cinco corpus do TREC:
ROBUST, AP, WSJ, GOV2 e WT10g.
Sendo os três primeiros, corpus de tamanho pequeno (contendo notícias) e os dois últimos são coleções web consideradas grandes.
Para medir a eficiência da proposta nos experimentos foi utilizado a medida MAP, apresenta na Seção 2.2.
A o final do trabalho podemos observar que a utilização de novas amostragem de documentos baseadas em grupos é uma proposta eficiente quando utilizado em coleções grandes, pois Lee Obtiveram nos resultados dos experimentos em coleções com essas características ganho em todos os experimentos realizados.
Em as coleções GOV2 e o ganho foi de 16,82% e 6,28% respectivamente comparado aos resultados do modelo de linguagem e ao modelo de relevância.
Em a coleção WT10g o ganho foi de 16,63% e 26,38% comparados respectivamente com o modelo de linguagem e o modelo de relevância.
Já os resultados em coleções pequenas não foram tão bons.
Com o estudo do trabalho apresentado por Lee, ficou claro que a utilização de técnicas de agrupamento para a definição dos documentos a serem utilizados na EC junto ao Modelo TR+ é inviável, uma vez que o corpus de documentos utilizado nesta dissertação é de um tamanho pequeno se comparado com corpus utilizados habitualmente em avaliações de Ri, como os presentes por exemplo no CLEF.
Apesar disso a utilização de técnicas de agrupamentos para a expansão de consulta pode ser visto como um futuro teste a ser realizado desde que possamos trabalhar com um corpus de tamanho maior.
Considerações sobre o capítulo Em o Capítulo 5 apresentamos alguns trabalhos estudados durante o desenvolvimento da dissertação.
Os trabalhos apresentados foram selecionados por terem contribuído para a conclusão da dissertação.
Os trabalhos apresentados neste nos possibilitou ter um maior conhecimento da aplicação na prática de EC utilizando RR e PRR.
O estudo do trabalho realizado por Custis e Al-Kofahi, identificamos a importância e viabilidade de uso da técnica de EC Pseudo Realimentação de Relevantes para a aplicação em conjunto com o Modelo TR+ na recuperação de informação.
Unido a isso, outra importante contribuição do trabalho apresentado por Custis e Al-Kofahi foi trazer a oportunidade de um melhor conhecimento de uma situação de uso da fórmula OKAPI.
O trabalho apresentado por Vechtomova e Karamuftuoglu foi de grande valor para a formulação de nossa proposta, pois ofereceu uma visão prática da utilização da técnica de EC pseudo realimentação de relevantes, chamada neste trabalho por Vechtomova e Karamuftuoglu de Blind Feedback.
O trabalho também nos apresentou a utilização de snippets dos documentos para a EC, a utilização de snippets associada ao Modelo TR+, é uma alternativa à proposta apresentada nesta dissertação.
Entretanto devido a necessidade de modificações no Modelo TR+, não lançaremos mão de tal abordagem.
O trabalho apresentado por Vechtomova e Karamuftuoglu, fortaleceu a utilização da PRR como uma técnica de EC a ser aplicada junto ao Modelo TR+.
A o término do estudo do trabalho proposto por Chirita e Nejdl, ficou clara a dificuldade de se aplicar a EC utilizando informações contidas na máquina do usuário ao Modelo TR+, uma vez que, para o uso dessa referência seria fundamental dispor de um thesaurus externo como a WordNet.
Com isso a aplicação dessa proposta ao Modelo TR+ foi descartada por o tempo exigido para a construção de um thesaurus à língua portuguesa.
O trabalho proposto por Chirita e Nejdl fortaleceu a nossa decisão de utilizar a técnica de EC pseudo realimentação de relevantes, eliminando a participação do usuário para melhorar a qualidade das informações recuperadas junto ao Modelo TR+.
Com o estudo do trabalho apresentado por pudemos nos familiarizar com o método de realimentação de relevantes, assim como, com a forma de avaliar a relevância dos documentos recuperados por a consulta original.
Assim sendo, pudemos desenvolver os experimentos com RR em conjunto com o Modelo TR+ à Ri aplicados nesta dissertação.
A o estudarmos o trabalho apresentado por Lee, ficou claro que a utilização de técnicas de agrupamento para a definição dos documentos a serem utilizados na EC junto ao Modelo TR+ é inviável, uma vez que o corpus de documentos utilizado nesta dissertação é de um tamanho pequeno se comparado com corpus utilizados habitualmente em avaliações de Ri, como os presentes por exemplo no CLEF.
Apesar disso a utilização de técnicas de agrupamentos para a expansão de consulta pode ser visto como um futuro teste a ser realizado desde que possamos trabalhar com um corpus de tamanho maior.
Em o capítulo a seguir, Capítulo 6, apresentamos os experimentos realizados para a conclusão do trabalho desenvolvido nesta dissertação.
Em a Seção 6.1 apresentamos os experimentos realizados por Gonzalez, que foram utilizados por nós no contexto da dissertação como baseline.
Em a Seção 6.5 apresentamos 7 experimentos planejados e realizados para avaliar o desempenho da EC com PRR.
Em a Seção 6.7 apresentamos 7 experimentos realizados para avaliar o desempenho da EC com RR.
Em esta seção apresentaremos os experimentos realizados por Gonzalez para o Modelo TR+ utilizados no contexto dessa dissertação como baseline, e também os experimentos planejados para avaliar a aplicação de expansão de consulta utilizando as técnicas Pseudo Realimentação de Relevantes e Realimentação de Relevantes em conjunto ao Modelo Para a realização dos experimentos utilizamos como ponto de partida os resultados obtidos por Gonzalez em seus experimentos, ou seja, utilizamos as consultas realizadas e os documentos recuperados resultantes destas, e a partir destes resultados aplicamos a expansão de consulta.&amp;&amp;&amp;
Para a avaliação dos experimentos foram utilizadas as seguintes métricas apresentadas na Seção avaliação dos experimentos, foram realizados as análises:
O número de RLBs utilizado para a EC;
O tipo de RLBs utilizado para a EC, o número de termos utilizado para a EC.
Experimento com o Modelo TR+ Gonzalez em seu experimento para validação do Modelo TR+ no que diz respeito ao contexto da recuperação de informação, empregou a metodologia utilizada nas TRECs (Text Retrieval Conferences) (Voorhees, 2005).
Foram realizadas 50 consultas referentes a 50 tópicos distintos utilizando o corpus anotado de notícias do Jornal Folha de São Paulo denominado Folha94.
O corpus Folha94 consiste de 4.156 artigos do ano de 1994, cada artigo podendo ser classificado com um ou mais assuntos.
Cada tópico é representado por um título, uma descrição e uma narrativa, os quais indicam as características que identificam um documento como relevante.
O Anexo D, apresenta um exemplo de tópico de consulta utilizado por Gonzalez Após a recuperação dos documentos através de diferentes estratégias de Ri, Gonzalez utilizou o método de pooling, para julgar a relevância dos documentos recuperados.
Em esta etapa, os 100 primeiros documentos recuperados para cada tópico, em cada estratégia de Ri, foram agrupados e ordenados.
De estes documentos agrupados e ordenados, foram descartados os que não representavam informação relevante, conforme a análise da presença dos termos da consulta no título e corpo do texto.
Os documentos restantes foram enviados aos avaliadores num número de até 10 documentos por avaliador.
Finalmente os avaliadores identificaram os documentos relevantes do conjunto de documentos julgados para cada consulta indicada.
A avaliação do Modelo TR+ foi finalizada com o cálculo de métricas consolidadas para se mensurar sistemas de recuperação de informação.
Como métricas foram utilizados o cálculo da precisão e abrangência, além de o cálculo da medida MAP (Mean Average Precision) (Buckley &amp; Voorhees, 2004).
A o analisarmos o experimento realizado por Gonzalez podemos identificar as consultas utilizadas, os termos e as relações lexicais binárias que foram geradas para cada consulta, assim como seus respectivos pesos e os documentos recuperados por elas.
Com as RLBs e termos da consulta apresentadas na Figura 11, podemos recuperar uma lista de documentos ordenados de acordo com sua relevância.
Para cada documento recuperado é definida uma lista de RLBs e termos ordenados.
Assim, para a consulta &quot;abuso sexual», obtemos a lista de documentos parcialmente apresentada na Tabela 5.·
Ordem doc é a ordem de recuperação do documento para uma certa consulta;·
Peso doc é o grau de relevância do documento para uma certa consulta.
Para cada documento é gerada então uma lista de RLBs e termos.
Podemos exemplificar mostrando na Figura 12 parte da lista de RLBs e termos com seus respectivos pesos para o documento identificado como 407 de acordo com a consulta &quot;abuso sexual».
De posse das consultas realizadas por Gonzalez, dos documentos recuperados para cada consulta e das relações lexicais binárias e termos desses documentos, podemos então realizar os experimentos que verificam o desempenho das técnicas de expansão de consulta pseudo realimentação de relevantes e realimentação de relevantes.
Resultados dos experimentos realizados por Gonzalez para validar o Modelo TR+ A Tabela 6 mostra o resultado dos experimentos realizados por Gonzalez para avaliar a performance da recuperado de informações utilizando o Modelo TR+.
Em a Figura 13 é possível visualizar a curva da Precisão x Abrangência.
Podemos observar tanto na Tabela 6 quanto na Figura 13, o desempenho do Modelo TR+ no que tange à recuperação de informação, alcançando para a medida MAP 85, 09%.
O valor atingido por o Modelo TR+ para a medida MAP, pode ser considerado como nosso baseline, e é um resultado bastante expressivo.
Podemos observar que, ao desconsiderarmos a abrangência dos documentos recuperados, a precisão interpolada atingida foi de 97,33%.
Já quando a abrangência dos documentos recuperados é o foco da análise, podemos observar que o Modelo TR+ alcança uma precisão de 48,33%.
Estes resultados demonstram a efiCiência do Modelo TR+ para a recuperação de documentos nos moldes em que foram conduzidos os experimentos.
Todos os experimentos, tanto com PRR como com RR passaram por um processo de normalização dos pesos dos termos e RLBs das consultas expandidas.
O processo de normalização tem o intuito de garantir a uniformidade da faixa de valores dos pesos tanto dos termos como das RLBs utilizados na expansão das consultas.
O processo de normalização é realizado com base nos pesos dos termos e RLBs das consultas originais.
O processo de normalização dos pesos dos termos e das RLBs no contexto desse trabalho, utiliza o maior peso encontrado entre os termos e as RLBs de cada consulta.
Para melhor entendimento, seguindo os exemplos trabalhados até o momento, utilizaremos as RLBs e os pesos apresentados na Figura 11.
Onde o maior peso das RLBs da consulta &quot;abuso sexual «é 3.0 para a RLB do tipo classificação &quot;de (sexualidade, abuso)».
Os termos e RLBs que foram adicionados a esta consulta tiveram seus pesos normalizados para a faixa de valores entre 0 e 3.
Em a Figura 14 apresentamos os pesos das RLBs apresentadas na Figura 11 com seus pesos normalizados.
Julgamento de relevância dos documentos recuperados Após serem realizados os experimentos, o próximo passo a ser cumprido foi a análise dos documentos recuperados com a aplicação da técnica de expansão de consulta e retiradas das RLBs.
Os passos para o julgamento da relevância dos documentos recuperados por os experimentos com EC apresentados nas subseções 6.5 e 6.7, são apresentados na Figura 15, e seguem o roteiro abaixo:·
O primeiro passo tem início após a recuperação dos documentos para a cada consulta.
De posse dos documentos recuperados, é feita a exclusão dos documentos que já tinham sido recuperados e julgados por Gonzalez em seus experimentos.
Esse passo é realizado automaticamente por um programa de computador desenvolvido para tal finalidade;·
O segundo passo após a eliminação dos documentos já julgados por Gonzalez consiste em restringir o total de documentos num número igual a 100 documentos para cada consulta sendo estes os 100 documentos mais relevantes.
Estes 100 documentos passam por um processo de ordenação levando em conta o seu número de identificação;·
O terceiro passo é a eliminação dos documentos que, de entre estes 100 documentos, não contenham informação relevante à consulta;·
Os documentos restantes foram divididos em grupos de até 10 documentos, sendo enviados por email a avaliadores para o julgamento da sua relevância;·
A os avaliadores cabe a tarefa de analisar o conjunto de documentos que lhes foi enviado, marcando os documentos como:
A. Relevante b.
Não Relevante.
Para o avaliador considerar um documento como sendo relevante para uma dada consulta, é necessário que o documento contenha alguma informação digna de ser mencionada num relatório sobre o tópico da consulta.
Excetuando- se a avaliação da relevância dos documentos, que deve ser realizada de forma manual por os avaliadores, os demais passos são realizados utilizando apoio automatizado.
O passo foi planejado para que não se repetisse o trabalho de julgamento realizado por Gonzalez e assim diminuir o tempo de execução dos experimentos.
Os passos e foram planejados para desvincular os documentos de qualquer experimento realizado, aumentando assim a isenção nos resultados.
O passo foi planejado para diminuir o número de documentos a serem julgados, e pode ser assim descrito:
O resultado desses passos foi uma lista de 130 documentos agrupados em 13 conjuntos de 10 documentos cada, independente do tópico da consulta.
Cada conjunto de documentos deve ser enviado para o julgamento de um avaliador (veja exemplo do instrumento de avaliação C).
De posse dessas avaliações, podemos mensurar a qualidade da recuperação realizada por o Modelo TR+ com expansão de consulta.
Etapas da aplicação das técnicas de expansão de consulta PRR e RR em conjunto com o Modelo TR+ Em esta seção apresentaremos passo á passo a aplicação das técnicas de PRR e de RR em conjunto ao Modelo TR+.
As técnicas de expansão de consulta já apresentadas nas seções 3.2 e 3.2.4 foram utilizadas seguindo as consultas realizadas por Gonzalez em seus experimentos junto ao Modelo TR+.
Tendo as consultas realizadas por Gonzalez e conseqüentemente os documentos recuperados para cada consulta podemos assim realizar os experimentos planejados e apresentados nas seções 6.5 e 6.7.
Passos da aplicação da técnica de expansão de consulta PRR em conjunto ao Modelo TR+ Para a utilização da técnica de EC PRR em conjunto ao Modelo TR+ seguimos os seguintes passos:
Passos da aplicação da técnica de expansão de consulta RR em conjunto com o Modelo TR+ Para a utilização da técnica de EC RR em conjunto com o Modelo TR+ seguimos os seguintes passos:
Experimentos com o Modelo TR+ Utilizando Pseudo Realimentação de Relevantes Os experimentos para análise da aplicação da expansão de consulta ao processo descrito assumem que as n RLBs e os m termos dos três documentos recuperados são informações relevantes de acordo com a consulta original.
Com isso podemos expandir a consulta original utilizando um critério pré-definido.
Os experimentos realizados com PRR serão apresentados nas subseções 6.5.1, 6.5.2, 6.5.3, 6.5.4, 6.5.5 e 6.5.6.
Em todos os experimentos foi realizado um processo de normalização dos pesos das RLBs e termos utilizados para expandir a consulta original, apresentado em maiores detalhes na Seção 6.2.
Em a Figura 18 apresentamos o processo de expansão de consulta utilizado para todos os experimentos.
Experimento 1 com PRR Descrição:
Em o primeiro experimento, expandimos as consultas com as três RLBs mais &quot;pesadas «(RLBs com maior evidência nos documentos) provenientes dos três primeiros documentos recuperados, independentemente do tipo dessas, sejam elas Restrições, Associações ou Classificações.
Objetivo: O objetivo desse experimento é analisar se há aumento do desempenho da recuperação dos documentos quando a consulta é expandida utilizando para isso RLBs.
Experimento 2 com PRR Descrição:
Em o segundo experimento, expandimos as consultas utilizando as RLBs quanto a o seu tipo.
Para este experimento utilizamos os três documentos melhor classificados oriundos da consulta original.
A perspectiva desse experimento é identificar se diferentes tipos de RLBs podem obter resultados melhores que outros.
Assim após a consulta original, identificam- se os três documentos mais pesados e as três RLBs de acordo com o seu tipo:
Restrição, Associação ou Classificação.
Novamente a consulta original é realimentada com as RLBs escolhidas.
Este experimento se subdivide em três outros, que diferem como segue:
Objetivo: O objetivo desse experimento é verificar se o tipo de RLB utilizada para a expansão da consulta original possui influência na qualidade da recuperação.
Experimento 3 com PRR Descrição:
O terceiro experimento planejado para avaliar o desempenho do processo de expansão de consulta realimenta a consulta original com os três termos mais &quot;pesados «dos três documentos melhor classificados oriundos da consulta original.
A realimentação da consulta original utilizando os termos mais pesados segue a rotina especificada nos experimentos anteriores, ou seja, após a consulta original são identificados os três documentos mais relevantes e assim os três termos mais pesados desses documentos são utilizados pra realimentar a consulta original.
Objetivo: Com esse experimento temos como objetivo avaliar o desempenho da expansão da consulta utilizando para isso somente termos resultantes da primeira etapa do processo.
Experimento 4 com PRR Descrição:
O Experimento 4 avalia a utilização das cinco RLBs mais &quot;pesadas «provenientes dos três documentos recuperados melhor classificados, oriundos da consulta original.
As RLBs utilizadas neste experimento independen do seu tipo, sejam elas Restrições, Associações ou Classificações.
Objetivo: O objetivo desse experimento é avaliar se o desempenho da recuperação dos documentos é influenciada, quando a consulta é expandida utilizando para isso um número maior de RLBs relevantes à necessidade do usuário.
Experimento 5 com PRR Descrição:
Experimento 5 avalia a utilização dos cinco termos mais &quot;pesados «provenientes dos três documentos recuperados melhor classificados oriundos da consulta original.
Objetivo: O objetivo desse experimento é avaliar se o desempenho da recuperação dos documentos é aumentado, quando a consulta é expandida utilizando para isso um número maior de termos em comparação ao número de termos utilizados no Experimento 3.
Experimento 6 com PRR Descrição:
O Experimento 6 avalia utilização das dez RLBs mais &quot;pesadas «provenientes dos três documentos recuperados melhor classificados oriundos da consulta original.
As RLBs utilizadas neste experimento assim como nos experimentos 1 e 4 independem do seu tipo, sejam elas Restrições, Associações ou Classificações.
Objetivo: Esse experimento tem como objetivo avaliar se existe aumento no desempenho de documentos recuperados quando a consulta é expandida utilizando para isso um número maior de RLBs relevante à necessidade do usuário quando comparado com o número de RLBs utilizadas nos experimentos 6.5.1 e 6.5.4.
Resultados dos Experimentos realizados junto ao Modelo TR+ utilizando Pseudo Realimentação de Relevantes Em esta seção apresentaremos os resultados dos experimentos realizados junto ao Modelo TR+, adicionando RLBs e termos as consultas originais, utilizando para isso a técnica de expansão de consultas Pseudo Realimentação de Relevantes.
Em a Tabela 7 e na Figura 19 expomos os resultados obtidos por os experimentos que adicionaram RLBs as consultas originais em comparação aos resultados do baseline.
Já na Tabela 8 e na Figura 20 apresentamos os resultados da expansão das consultas utilizando termos em comparação aos resultados obtidos por o baseline.
Outra explicação para a media MAP neste experimento ser inferior ao baseline é que ao utilizarmos para a EC RLBs como por exemplo, «prisao.
Por (balconista, abuso)», o SRI recuperará documentos que não são relevantes a consulta original &quot;abuso sexual».
Em este exemplo, muito embora a RLB utilizada possua em seus argumentos o termo &quot;abuso», esta RLB se refere na realidade &quot;a prisão do balconista por algum tipo de abuso».
Reforçando esta conclusão está a análise realizada ao estudarmos as consultas expandidas.
A o término da análise das RLBs utilizadas para a expansão das consultas do Experimento 1 concluímos que:
Foram utilizadas 450 RLBs nas 50 consultas expandidas;
De as 450 RLBs utilizadas somente 94 foram consideradas relevantes ao tópico da consulta;
De as 450 RLBs utilizadas para a expansão das consultas, 356 RLBs foram consideradas irrelevantes para o tópico da consulta.
Estes números apontam a utilização de poucas RLBs relevantes para a expansão das consultas selecionadas para este experimento.
RLBs puderam exercer influência no resultado da recuperação.
Além disso, após a análise das RLBs utilizadas para a expansão das consultas nos experimentos podemos concluir que:
Em o Experimento 2.1 foram utilizadas 450 RLBs, sendo 87 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 363 RLBs não relevantes;
Em o Experimento 2.2 foram utilizadas 450 RLBs para a expansão das consultas, sendo 72 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 378 RLBs não relevantes;
Em o Experimento 2.3 foram utilizadas 450 RLBs para a expansão das consultas, sendo 65 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 385 RLBs não relevantes.
Esta análise aponta a utilização de poucas RLBs relevantes para a expansão das consultas selecionadas para este experimento.
Ri resultou na recuperação de um número maior de documentos irrelevantes para a consulta em comparação aos Experimentos 1 e 2.
Aliado a isso podemos verificar ao analisarmos consulta a consulta os termos utilizados para sua expansão, podemos definir que:
Foram utilizados 450 termos;
De estes somente 78 termos foram considerados relevantes aos tópicos da consulta;
373 termos foram considerados não relevantes.
Essa análise nos leva a crer que aliado ao fato que termos são muito genérico está a utilização para a expansão das consultas de um número muito baixo de termos relevantes, o que leva a um decréscimo considerado para a recuperação de informação.
Resultados do Experimento 4 com PRR Podemos observar na Tabela 7 e na Figura 19 que o aumento do número de RLBs utilizadas para a expansão da consulta não acarreta num desempenho melhor para recuperação de in-formação, sendo seu desempenho de fato prejudicado com este aumento no número de RLBs.
O desempenho na recuperação de informação com 5 RLBs dos três documentos melhor classificados na recuperação realizada por a consulta original atingiu para a medida MAP 65, 26% contra 80,87% para a mesma medida quando utilizado as 3 RLBs dos três documentos melhor classificados por a recuperação da consulta inicial.
A o analisarmos a relevância das RLBs utilizadas para a expansão das consultas podemos constatar que:
Foram utilizadas 750 RLBs no total;
De estas, 125 foram reconhecidas como relevantes;
De o restante das RLBs, ou seja, 625 foram consideradas irrelevantes em comparação aos tópicos das consultas.
A o compararmos o percentual de RLBs relevantes utilizadas para a expansão das consultas deste experimento com o Experimento 1, podemos ver que mesmo com o aumento do número de RLBs o seu percentual foi 4,22% menor.
Isto explicaria o fato de que com o aumento do número de RLBs em relação a o Experimento 1, o seu desempenho foi inferior.
Resultados do Experimento 5 com PRR Os resultados obtidos por este experimento e apresentados na Tabela 8 e na Figura 20, não deixa dúvidas quanto a ineficácia do aumento dos termos de três, no Experimento 3, para cinco termos como proposto nesta rodada de experimentos.
Utilizando cinco termos o experimento obteve uma medida MAP de 11,32% diminuindo ainda mais o desempenho já pouco significativo alcançado no Experimento 3 que, para a mesma medida alcançou 16,93%.
Uma explicação para tal comportamento, apresentado também no Experimento 3, pode ser o fato de que termos são muito genéricos e estão presentes em muitos documentos irrelevantes, e a sua utilização no contexto desse trabalho para Ri resultou na recuperação de um número maior de documentos irrelevantes para a consulta em comparação aos experimentos 1 e 2 respectivamente.
A o analisarmos consulta a consulta os termos utilizados na sua expansão podemos constatar que:
Foram utilizados 705 termos para a expansão das consultas;
De o total 109 termos foram considerados relevantes;
E=641  termos irrelevantes.
Resultados do Experimento 6 com PRR Em a Tabela 7 e na Figura 19 é possível observar que o aumento do número de RLBs não resulta na melhora do desempenho da recuperação de informação quando comparado com os demais experimentos que utilizaram RLBs apresentados nesta seção.
De fato ao se utilizar as 10 RLbs mais pesadas dos três documentos melhor classificados por a recuperação referente a a consulta original, este obteve um valor para a medida MAP de 80,87%, sendo este o valor idêntico ao alcançado por o Experimento 1 onde foram utilizadas as três RLBs para os mesmos três documentos melhor classificados para a consulta original.
Aliado a isso, o fato de que das 1500 RLBs utilizadas, somente 265 foram consideradas relevantes e 1235 não relevantes.
Esta avaliação nos mostra que o percentual de RLBs relevantes utilizadas para a expansão das consultas é muito parecido ao percentual de RLBs utilizadas no Experimento 1, mesmo que num número muito maior.
Assim confirmamos que o aumento do número de RLBs na expansão das consultas não determina um aumento no desempenho da recuperação de informação se estas RLBs não forem num número expressivo de RLBs relevantes para as consultas.
Experimentos realizados junto ao Modelo TR+ utilizando Realimentação de Relevantes Os experimentos utilizando realimentação de relevantes junto ao Modelo TR+, lançou mão da mesma metodologia dos experimentos realizados por Gonzalez e dos experimentos com pseudo realimentação de relevantes (Seção 6.5), difireciando- se apenas quanto a a seleção dos documentos que participaram do processo de EC.
Netes experimentos assumimos que as n RLBs e os m termos dos três primeiros documentos recuperados e julgados como relevantes à consulta original por os usuários são utilizados para a EC.
Com isso podemos expandir a consulta original utilizando um critério pré-definido.
Apresentamos os experimentos realizados nas subseções 6.7.1, 6.7.2, termos utilizados no processo de EC.
O processo de normalização será apresentado em maiores detalhes na Subseção 6.2.
Experimento 1 com RR Descrição:
Em o primeiro experimento, utilizamos para a avaliar o processo de EC as três RLBs mais &quot;pesadas «(RLBs com maior freqüência no documento) provenientes dos três primeiros documentos recuperados e julgados relevantes à consulta original por o usuário, independente do seu tipo, seja ele Restrição, Associação ou Classificação.
Objetivo: O objetivo desse experimento é avaliar se há impacto no desempenho da recuperação dos documentos quando a consulta é expandida utilizando para isso RLBs relevantes à necessidade do usuário.
Experimento 2 com RR Descrição:
O Experimento 2 avalia a aplicação da expansão de consulta utilizando RLBs quanto a o seu tipo.
Para este experimento foram utilizados os três primeiros documentos julgados como relevantes por o usuário à consulta original.
A perspectiva desse experimento é identificar se diferentes tipos de RLBs podem obter resultados melhores que outros.
Assim após a consulta original, identificou- se os três documentos mais pesados extraindo as três RLBs de acordo com o seu tipo:
Restrição, Associação ou Classificação.
Novamente a consulta original é realimentada com as RLBs selecionadas.
Este experimento se subdivide em três outros experimentos que diferem como segue:
Objetivo: O objetivo desse experimento é verificar se o tipo de RLB utilizada para a expansão da consulta original possui influência na recuperação dos documentos.
Experimento 3 com RR Descrição:
O terceiro experimento avalia o desempenho do processo de expansão de consulta utilizando os três termos mais &quot;pesados «dos três primeiros documentos julgados como relevantes à consulta original.
A realimentação da consulta original utilizando os termos mais pesados segue a rotina especificada nos experimentos anteriores, ou seja, após a consulta original são identificados os três documentos mais relevantes e assim os três termos mais pesados desses documentos são utilizados pra realimentar a consulta original.
Objetivo: Com esse experimento temos como objetivo avaliar o desempenho da expansão da consulta utilizando para isso somente termos resultantes da primeira etapa do processo.
Experimento 4 com RR Descrição:
O Experimento 4 avalia a utilização das cinco RLBs mais &quot;pesadas «provenientes dos três primeiros documentos recuperados julgados relevantes à consulta original, inde-pendente do seu tipo, seja ele Restrição, Associação ou Classificação.
Objetivo: O objetivo desse experimento é avaliar se há aumento do desempenho da recuperação dos documentos quando a consulta é expandida utilizando para isso um número maior RLBs relevantes à necessidade do usuário.
Experimento 5 com RR Descrição:
Experimento 5 avalia a utilização dos cinco termos mais &quot;pesados «provenientes dos três primeiros documentos recuperados julgados relevantes à consulta original, independente do seu tipo, seja ele Restrição, Associação ou Classificação.
Objetivo: O objetivo desse experimento é analisar se há aumento no desempenho da recuperação dos documentos, quando a consulta é expandida utilizando para isso um número maior de termos relevantes à necessidade do usuário comparados ao número de termos utilizados no experimento 6.7.3.
Experimento 6 com RR Descrição:
O Experimento 6 avalia a utilização das dez RLBs mais &quot;pesadas «provenientes dos três primeiros documentos recuperados julgados relevantes à consulta original, independente do seu tipo, seja ele Restrição, Associação ou Classificação.
Objetivo: Esse experimento tem como objetivo analisar se existe aumento no desempenho da recuperação quando a consulta é expandida utilizando para isso um número maior de RLBs relevante à necessidade do usuário quando comparado com o número de RLBs utilizadas nos experimentos 6.7.1 e 6.7.4.
Resultados dos Experimentos realizados junto ao Modelo TR+ utilizando Realimentação de Relevantes Em esta seção apresentaremos os resultados dos experimentos realizados junto ao Modelo TR+, adicionando RLBs e termos as consultas originais, utilizando para isso a técnica de expansão de consultas Realimentação de Relevantes.
Em a Tabela 9 e na Figura 21 expomos os resultados obtidos por os experimentos que adicionaram RLBs as consultas originais em comparação aos resultados do baseline.
Já na Tabela 10 e na Figura 22 apresentamos os resultados da expansão das consultas utilizando termos em comparação aos resultados obtidos por o baseline.
Reforçando esta conclusão está a análise realizada ao estudarmos as consultas expandidas.
A o término da análise das RLBs utilizadas para a expansão das consultas do Experimento 1 concluímos que:
Foram utilizadas 450 RLBs nas 50 consultas expandidas;
De as 450 RLBs utilizadas somente 91 foram consideradas relevantes ao tópico da consulta;
De as 450 RLBs utilizadas para a expansão das consultas, 359 RLBs foram consideradas irrelevantes para o tópico da consulta.
Estes números apontam a utilização de poucas RLBs relevantes para a expansão das consultas selecionadas para este experimento.
PRR e RR.
Além disso, após a análise das RLBs utilizadas para a expansão das consultas nos experimentos podemos concluir que:
Em o Experimento 2.1 foram utilizadas 450 RLBs, sendo 89 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 361 RLBs não relevantes;
Em o Experimento 2.2 foram utilizadas 450 RLBs para a expansão das consultas, sendo 69 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 381 RLBs não relevantes;
Em o Experimento 2.3 foram utilizadas 450 RLBs para a expansão das consultas, sendo 60 RLBs consideradas relevantes aos seus respectivos tópicos de consulta e 380 RLBs não relevantes.
Esta análise aponta a utilização de poucas RLBs relevantes para a expansão das consultas selecionadas para este experimento.
Resultados do Experimento 3 com RR Podemos observar nos resultados obtidos no Experimento 3 com RR, que o comportamento desse experimento foi semelhante ao demonstrado por o Experimento 3 com PRR (Seção 6.5.3), e portanto, bastante diferente dos resultados apresentados por Gonzalez.
A utilização dos três termos mais &quot;pesados «dos três documentos mais relevantes à consulta original com RR, resul- tou numa medida MAP com valor de 16,74% contra 16,93% obtidos por o experimento 3 com PRR.
Uma possível explicação para este pequeno decréscimo na medida MAP, se dá por o fato de que em 8 consultas foram adicionados termos de diferentes documentos aos utilizados para o mesmo experimento com PRR.
Tal fato em conjunto com a generalidade de os termos fez que com o resultado do experimento tivesse sido inferior ao executado com PRR.
De fato podemos verificar ao analisarmos consulta a consulta os termos utilizados para sua expansão, podemos definir que:
Foram utilizados 450 termos;
De estes somente 81 termos foram considerados relevantes aos tópicos da consulta;
369 termos foram considerados não relevantes.
Essa análise nos leva a crer que aliado ao fato que termos são muito genéricos está a utilização para a expansão das consultas de um número muito baixo de termos relevantes, o que leva a um decréscimo considerado para a recuperação de informação.
Resultados do Experimento 4 com RR Podemos observar com este experimento, que o aumento do número de RLBs utilizadas para a expansão da consulta não acarreta num desempenho melhor para recuperação dos documentos, ao ser comparado com os resultados obtidos por Gonzalez.
Entretanto, o desempenho na recuperação dos documentos com 5 RLBs dos três documentos melhor classificados na recuperação realizada por a consulta original com RR atingiu para a medida MAP 79, 01% contra 65,26% para a mesma medida, quando utilizado para o mesmo experimento PRR.
A utilização de RR com 5 RLBs teve um ganho de 13,75%, isto nos leva a crer que os novos documentos utilizados no experimento por a RR influenciou positivamente o seu resultado, melhorando seu desempenho na recuperação.
A o analisarmos a relevância das RLBs utilizadas para a expansão das consultas podemos constatar que:
Foram utilizadas 750 RLBs no total;
De estas, 142 foram reconhecidas como relevantes;
De o restante das RLBs, ou seja, 608 foram consideradas irrelevantes em comparação aos tópicos das consultas.
Podemos observar que o aumento no número de RLBs relevantes utilizadas neste experimento em comparação ao número de RLBs utilizadas no Experimento 4 com PRR resultou no aumento da performance no que tange a medida MAP.
Resultados do Experimento 5 com RR Os resultados obtidos por este experimento e apresentados na Tabela 10 e na Figura 22, não deixa dúvidas quanto a ineficácia do aumento dos termos de três, no Experimento 3, para cinco termos como proposto nesta rodada de experimentos.
Utilizando cinco termos o experimento obteve uma medida MAP de 11,01% diminuindo ainda mais o desempenho já pouco significativo alcançado no Experimento 3 que, para a mesma medida alcançou 16,74%.
Uma explicação para tal comportamento, apresentada também no Experimento 3, pode ser o fato de que termos são muito genéricos e estão presentes em muitos documentos irrelevantes, e a sua utilização no contexto desse trabalho para Ri resultou na recuperação de um número maior de documentos irrelevantes para a consulta em comparação aos experimentos 1 e 2 respectivamente.
A o analisarmos consulta a consulta os termos utilizados na sua expansão podemos constatar que:
Foram utilizados 705 termos para a expansão das consultas;
De o total 113 termos foram considerados relevantes;
E=637  termos irrelevantes.
Resultados do Experimento 6 com RR Em a Tabela 9 e na Figura 21 é possível observar que o aumento do número de RLBs não resulta na melhora do desempenho da recuperação de informação quando comparado com os demais experimentos que utilizaram RLBs apresentados nesta seção.
De fato ao se utilizar as 10 RLBs mais pesadas dos três documentos melhor classificados por a recuperação considerados relevantes à consulta original, este obteve um valor para a medida MAP de 80,87%, sendo este o valor idêntico ao alcançado por o Experimento 1, quer seja utilizando PRR e RR, onde foram utilizadas as três RLBs para os mesmos três documentos melhor classificados para a consulta original.
Aliado a isso, o fato de que das 1500 RLBs utilizadas, somente 268 foram consideradas relevantes e 1233 não relevantes.
Esta avaliação nos mostra que o percentual de RLBs relevantes utilizadas para a expansão das consultas é muito parecido ao percentual de RLBs utilizadas no Experimento 1, mesmo que num número muito maior.
Assim confirmamos que o aumento do número de RLBs na expansão das consultas não determina um aumento no desempenho da recuperação de informação se estas RLBs não for num número expressivo de RLBs relevantes para as consultas.
Experimento com a exclusão das RLBs oriundas do Modelo TR+ Descrição:
O quarto experimento avalia o impacto das relações lexicais binárias na recuperação de documentos.
Para tanto esse experimento não adiciona novas RLBs à consulta original, e sim extrai as relações lexicais binárias definidas por o Modelo TR+ para cada consulta.
O experimento tem seu início com a definição das consultas realizadas por Gonzalez, o próximo passo é a exclusão das RLBs oriundas de cada consulta.
Em seguida a consulta é novamente realizada desta vez sem as RLBs.
Este experimento não necessita do processo de normalização (apresentados na Seção 6.2) uma vez que não são acrescidos à consulta original termos e relações lexicais binárias.
Objetivo: Com isso buscamos determinar o quão importantes são as RLBs vindas da con-sulta original para a recuperação dos documentos.
Em a Tabela 11 e na Figura 23, podemos observar o resultado da precisão e da abrangência do experimento realizado para avaliar a imporância das RLBs para a recuperação de informação.
Figura 23 ­ Curva Precisão x Abrangência do experimento com a exclusão das RLBs da consulta original Este experimento mostrou a importância das RLBs para a recuperação de informação, uma vez que ao se retirar as RLBs das consultas se obteve resultado inferior a o que foi atingido nos experimentos realizados por Gonzalez.
De fato ao se avaliar o desempenho do Modelo TR+ em o que tange a recuperação de informação, este obteve para a medida MAP um percentual de 85,09% contra 77,78% quando são retiradas das consultas as RLBs.
Ou seja, a EC não tradicional realizada por o Modelo TR+ ao se utilizar de RLBs para a representação da consulta original, esta constitui- se na expansão de consulta de melhor benefício no contexto desse trabalho.
Considerações sobre o capítulo Em este capítulo apresentamos os experimentos realizados para a avaliação da proposta de EC realizada nesta dissertação.
Apresentamos doze experimentos para as duas técnicas de EC utilizada nesse trabalho, Realimentação de Relevantes e Pseudo Realimentação de Relevantes, também apresentamos um experimento sem a aplicação das técnicas de expansão de consulta PRR e RR e sim a exclusão das RLBs utilizadas por a proposta do Modelo TR+.
Apresentamos ainda para as duas técnicas (RR e PRR) o processo de normalização dos pesos, tanto das RLBs como dos termos envolvidos na EC junto ao Modelo TR+.
Os melhores resultados tanto para os experimentos com PRR quanto com RR foram alcançados, utilizando 3 RLBs e 10 RLBs dos 3 documentos melhor classificados (experimentos com PRRexperimentos com RR).
Entretanto estes experimentos não superaram os resultados obtidos por Gonzalez que foram utilizados por nós como baseline para este trabalho.
Outra constatação sobre os experimentos é que, no contexto dessa dissertação, a utilização de termos tanto para PRR quanto para RR, mostrou- se ineficiente no que tange a Ri.
A o compararmos os experimentos tanto com PRR quanto com RR, podemos constatar que a técnica RR foi superior no que tange a medida MAP em comparação à PRR somente no Experimento 5.
Esta semelhança ocorreu, devido a o fato de que, os documentos utilizados( (i) 3 documentos melhor ranqueados após a recuperação para PRR e 3 documentos melhor classificados por a recuperação e julgados como relevantes por os usuários para RR) tanto para PRR como para RR foram muito semelhantes, ou seja praticamente os mesmos, diferenciandose apenas em 8 consultas.
Com os resultados tão parecidos para os experimentos tanto com PRR como com RR, realizamos o Teste-T (veja Apendice D), para identificar a significância estatística dos resultados dos experimentos.
Com o Teste-T podemos comparar os resultados dos experimentos com EC e o resultado do baseline.
Também utilizamos o Teste-T para compararmos os resultados dos experimentos com EC entre si, quer sejam com PRR e com RR.
Com o resultado do Teste-T podemos tecer algumas conclusões.
Para os experimentos com PRR:
O baseline é superior estatisticamente ao Experimento 1, confirmando os resultados obtidos por a medida MAP para ambos;
Apesar de o baseline ter atingido um valor para a medida MAP superior ao alcançado por o Experimento 2 e suas variantes, o baseline não possui uma superioridade estatística significante em relação a o Experimento 2;
o Teste-T aponta que o baseline é superior ao Experimento 4, o que confirma os valores obtidos por ambos por a medida MAP;
Apesar de o baseline ter alcançado um valor superior para a medida MAP em comparação ao Experimento 6, o Teste-T indica que não há uma superioridade estatística entre os dois experimentos;
A o compararmos os experimentos realizados com PRR que utilizaram RLBs para a EC entre si podemos concluir que, o Experimento 1 é superior estatisticamente aos Experimentos 4 e 6, e o Experimento 4 é superior estatisticamente ao Experimento 6, embora os três possuam o mesmo valor para a medida MAP;
A o utilizarmos o Teste-T para comparar os resultados das variantes do Experimento 2 entre si, podemos concluir que não há diferença estatística significante entre as variações do Experimento 2;
a o compararmos os resultados dos Experimentos 3 e 5 utilizando o Teste-T podemos concluir que não existe diferença significativa entre os dois experimentos.
Para os experimentos com RR:
O baseline é superior estatisticamente ao Experimento 1 confirmando os valores da medida MAP de ambos;
Embora o baseline tenha alcançado um valor para a medida MAP superior às variantes do Experimento 2, ao compararmos estes resultados utilizando o Teste-T, o baseline não possui uma superioridade significativa as variações do Experimento 2;
o Teste-T para os resultados do baseline e do Experimento 4 apontam por a superioridade estatística do baseline, confirmando os valores obtidos por ambos para a media MAP;
Apesar de o baseline ter alcançado para a medida MAP um valor maior que o Experimento 6, ao compararmos estes dois experimentos utilizando o Teste-T, este indica que não há diferença estatística significativa entre eles;
A o compararmos os resultados das variantes do Experimento 2 utilizando o Teste-T podemos concluir que não há diferença estatística entres os três experimentos, como aponta os valores de eles para a medida MAP;
A o compararmos os resultados dos experimentos 1, 4 e 6 entre si (experimentos que utilizam RLBs para a EC) utilizando o Teste-T podemos concluir que, o Experimento 1 é superior ao 4 e 6, o Experimento 4 é superior ao Experimento 6, isto ocorre mesmo que para a medida MAP dos três experimentos tenham obtidos o mesmo valor;
A o compararmos os experimentos 3 e 5 (experimentos que utilizam termos para a EC) utilizando o Teste-T podemos concluir que não há diferença estatística significante entre estes experimentos, ao compararmos entre si.
Em o próximo capítulo (Capítulo 7) apresentamos as conclusões sobre o trabalho desenvolvido nesta dissertação.
Em a Seção 7.2 apresentamos os resultados obtidos, e a públicação resultante do trabalho realizado.
Em a Seção 7.3 expomos as limitações encontradas no decorrer de a dissertação e finalizando na Seção 7.4 apresentamos algumas sujestões para a continuidade do trabalho neste contexto.
Contextualização Sistemas de Recuperação de Informação, que trabalham com documentos textuais, possuem como principal objetivo atender a consultas realizadas por usuários através de indexação, busca e classificação de documentos.
A maior dificuldade enfrentada por o usuário, quanto a a formulação adequada da consulta, é a decisão de quais palavras-chave usar para encontrar os documentos que necessita.
Uma formulação eficiente passa por o conhecimento do usuário sobre o domínio do tema a ser recuperado e sobre o próprio funcionamento do sistema.
Entretanto, formular uma consulta eficiente através de palavras-chave, que possibilitem retornar informações relevantes, pode não ser uma tarefa fácil.
Segundo Baeza-Yates e Ribeiro-Netto, a identificação da real necessidade do usuário é um processo muito complexo e pode ser a diferença entre uma recuperação eficiente e uma recuperação que não atende as suas necessidades.
Uma alternativa é a utilização de Expansão de Consulta, que reformula a consulta original para melhorar seu desempenho.
Para a representação dos conceitos e dos termos presentes nos documentos, diversas alternativas têm sido desenvolvidas e algumas incluem técnicas de Processamento da Língua Natural (PLN).
Em este sentido, Gonzalez apresentou um modelo para recuperação de informação denominado TR+.
O Modelo TR+ alia métodos estatísticos a conhecimento lingüístico para indexar e recuperar textos em língua portuguesa.
Ele utiliza termos e relações lexicais binárias como descritores de conceitos.
Em este contexto, inseriu- se o objetivo desse trabalho, que foi de aplicar as técnicas de EC, Realimentação e Pseudo Realimentação de Relevantes, num sistema que utiliza, para indexar e recuperar documentos textuais, o modelo de recuperação de informação TR+.
Assim esteve inserida no contexto desse trabalho a discussão de experimentos usados para validar da proposta de EC em conjunto com o TR+.
Resultados Obtidos no Capítulo 6 apresentamos os experimentos planejados e aplicados, referentes a cada uma das duas técnicas de EC, Realimentação e Pseudo Realimentação de Relevantes.
Foram executadas ao todo 7 rodadas de experimentos para a posterior discussão de resultados.
Utilizamos, como baseline para os experimentos, os resultados obtidos por Gonzalez.
Analizando os resultados da execução dos experimentos, podemos constatar que nenhum dos resultados obtidos, seja com RR seja com PRR, mensurados por a medida MAP, superaram os valores utilizados como baseline.
Entrentanto, podemos destacar alguns pontos interessantes que resultaram dos experimentos:
RLBs são mais eficientes à EC do que termos no contexto dessa dissertação, tanto nos experimentos com RR como com PRR;
O aumento do número de RLBs utilizadas na EC não aponta uma melhora no desempenho da Ri;
A utilização somente de termos mostrou- se bastante ineficiente no que tange a Ri;now
A o compararmos os resultados dos experimentos tanto com PRR como com RR, podemos observar que os resultados foram bastante semelhantes.
Isto ocorreu devido a a pequena diferença entre os documentos que foram utilizados para a EC em ambas as técnicas (3 documentos melhor colocados por a consulta original e 3 documentos melhor ranqueados julgados relevantes por os usuários).
Somente o Experimento 5 com RR alcançou melhores resultados que o mesmo experimento com PRR.
Isto atesta que a abordagem utilizada nesta dissertação que foi de utilizar RLBs e Termos melhor classificados dos documentos escolhidos para a EC não se mostrou o melhor método no contexto desse trabalho.
O que nos leva crer que a análise prévia a EC das RLBs e dos Termos que serão utilizados seja uma abordagem mais eficiente.
O trabalho desenvolvido nesta dissertação resultou numa publicação no VI Workshop on Information and Human Language Technology, com o seguinte título:·
Recuperação de Informação:
Expansão de Consulta por Pseudo Realimentação de Relevantes no Modelo TR+.
Em este trabalho apresentamos a especificação de experimentos para aplicação da técnica de expansão de consulta com pseudo realimentação de relevantes ao Modelo TR+ em recuperação de informação.
Além de os experimentos realizados com PRR, também apresentamos seus resultados.
O artigo foi apresentado na forma de poster, o que possibilitou além de a divulgação do trabalho, a interação com pesquisadores da área ocasionando a troca de conhecimento e discussões sobre o tema.
O Modelo TR+ foi inicialmente instanciado à língua portuguesa, não tendo ainda sido testado para outras línguas.
Esta característica é um obstáculo a ser ultrapassado, uma vez que as possibilidades de realização de experimentos em outros idiomas estão vinculadas à instanciação do TR+.
Isto acontece pois existem poucos corpora com as características necessárias para utilização por o Modelo TR+.
Este fator limitou a realização de outros experimentos para avaliar a aplicação tanto da técnica Pseudo Realimentação de Relevantes quanto da Realimentação de Relevantes num corpus com um número mais expressivo de documentos que desse condições de tecer uma análise mais consolidada.
Para a continuidade do trabalho apresentado nesta dissertação, faz- se necessária a aplicação dos experimentos num corpus com um volume de documentos significativamente maior que o utilizado em nossos experimentos.
A aplicação num corpus maior nos possibilitaria avaliar de forma significativa a aplicação de EC com RR e PRR em conjunto com o Modelo TR+.
Entretanto, a aplicação da proposta num corpus com maior volume demandaria as seguintes situações:
Disponibilidade desse corpus significativamente maior ao utilizado;
Prototipação de ferramentas mais robustas que dessem suporte ao Modelo TR+ para a automação das etapas de pré-processamento e etiquetagem;
Instanciação do Modelo TR+ para outros idiomas, permitindo a indexação desses documentos e a posterior recuperação.
Também futuramente, o julgamento da relevância das RLBs e Termos que serão utilizados na expansão das consultas é uma abordagem que merece maior atenção para a continuidade do trabalho apresentado nesta dissertação.
