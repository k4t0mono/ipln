Para realizar tarefas complexas em ambientes dinâmicos, agentes racionais devem ter a capacidade de agir direcionados por objetivos e, ao mesmo tempo, devem ser capazes de gerar respostas em tempo real para certas mudanças no ambiente.
Arquiteturas híbridas são criadas como uma combinação das abordagens deliberativa e reativa, de forma a associar as capacidades de deliberação e planejamento com a capacidade de reagir em tempo real a mudanças no ambiente.
Todavia, é normal nas arquiteturas híbridas a implementação destas abordagens em componentes separados, com um alto grau de independência.
Esta independência pode resultar em interferências nocivas de um componente na operação do outro, já que cada um procura atingir seus próprios objetivos da melhor maneira possível, afetando a performance do sistema como um todo.
Em este trabalho, apresentamos uma nova arquitetura híbrida que define um novo modelo para a integração dos componentes deliberativo e reativo.
Não são apresentadas novas formas de implementar o processo deliberativo ou o componente reativo, mas uma nova forma de integrá-em um agente híbrido.
Em esta arquitetura, deliberação e reatividade não são los concorrentes, sendo definidos como partes de um mesmo processo, trabalhando em conjunto para resolver todos os objetivos do agente.
A parte deliberativa gera planos, compostos por ações de alto nível, para realizar os desejos do agente, enquanto a parte reativa é responsável por a execução destas ações, tentando superar dificuldades geradas por mudanças no ambiente.
Desde os estudos de lógica dos antigos filósofos gregos, o ser humano tem buscado mecanismos que permitam a automatização das suas atividades intelectuais.
Atualmente, os computadores superam o cérebro humano no tratamento de grandes volumes de informação ou de informações de grande precisão, ao mesmo tempo em que são incapazes de executar certas atividades corriqueiras para seres humanos.
O que nos dá a capacidade de realizar estas tarefas é a faculdade (um tanto abstrata) chamada inteligência.
Surge assim aquela que é considerada por Marvin Minsky a maior dificuldade já encontrada por o homem1:
A construção de sistemas artificiais dotados de inteligência.
Segundo, a Inteligência Artificial pode ser definida como o campo de estudos da Ciência da Computação que busca a compreensão de entidades inteligentes e a reprodução em sistemas artificiais (de software ou hardware) dos mecanismos responsáveis por o comportamento inteligente.
Outros campos de pesquisa estão envolvidos com o estudo da inteligência:
Psicólogos e filósofos, por exemplo, procuram compreender os mecanismos abstratos do raciocínio humano e propor modelos que expliquem estes mecanismos;
Neurologistas procuram entender e explicar o funcionamento do cérebro humano;
Biólogos e sociólogos tentam compreender o comportamento e a organização social de certos animais e do ser humano, respectivamente.
Os pesquisadores destas áreas buscam na construção de sistemas de inteligência artificial possibilidades de estudos e validação para seus modelos, ao mesmo tempo que fornecem novas informações a respeito de a geração do comportamento inteligente.
Mas a Inteligência Artificial não se restringe a um campo de testes para modelos de inteligência.
Sistemas de Inteligência Artificial podem ser muito úteis na solução computacional de problemas complexos.
Trabalhando em conjunto com seres humanos, ou até substituindo os humanos em algumas atividades, sistemas inteligentes têm apresentado resultados expressivos em certas aplicações práticas.
Mas o que seria uma sistema inteligente?
Como definir se uma entidade é dotada de inteligência artificial?
A resposta para estas perguntas é bastante controversa, e diversas definições são encontradas na literatura.
Classificou as definições de sistemas citado por Hubert Dreyfus em, página 208.
A apresentação da arquitetura será precedida de uma breve descrição das abordagens utilizadas na construção de agentes (deliberativa, reativa e híbrida) e de algumas arquiteturas representativas destas abordagens, no Capítulo 2.
O Capítulo 3 apresenta uma análise das abordagens descritas no Capítulo 2, apresentando considerações a respeito de os pontos positivos e negativos de cada uma, e de características que devem ser adicionadas na arquitetura a ser proposta.
O Capítulo 4 contém a descrição da arquitetura proposta, apresentando a forma como se dá o processamento de informações e a geração de ações do agente.
Além de a descrição dos componentes internos do agente, o capítulo traz ainda alguns comentários sobre as principais características e qualidades da arquitetura, como a forma utilizada para a integração entre deliberação e reatividade.
O Capítulo 5 apresenta um estudo de caso, descrevendo a atuação de um agente implementado com a arquitetura descrita no Capítulo 4 num ambiente baseado no Mundo dos Blocos, mas dotado de um certo grau de reatividade.
Por fim, no Capítulo 6, serão apresentadas algumas conclusões a respeito de a arquitetura proposta e das contribuições desta dissertação.
Em encontramos uma divisão no estudo de agentes racionais em três áreas:
Teorias, linguagens e arquiteturas de agentes.
A primeira concentra- na elaboração de se conceitos e propriedades de agentes e em formalismos que os representem, enquanto a segunda se concentra na busca de linguagens para a programação de agentes que incorporem os princípios das teorias.
As arquiteturas de agentes são a ligação entre as especificações teóricas e a obtenção de resultados práticos, na medida em que buscam a implementação de sistemas segundo tais especificações.
Segundo Pattie Maes1, as arquiteturas são especificações de como podemos construir agentes a partir de módulos e como estes módulos interagem.
O conjunto total de módulos e suas interações devem especificar como, a partir de os dados dos sensores e do estado interno atual do agente, são obtidas ações e o novo estado interno.
Assim, cabe ao construtor da arquitetura definir a forma de dividir o problema e distribuir capacidades aos módulos do agente, além de a melhor forma de construir estes módulos e de como será a sua interação.
A abordagem mais antiga para a construção de agentes, que surgiu com o princípio dos estudos na área, é a chamada abordagem deliberativa.
As arquiteturas deliberativas são baseadas na representação simbólica do mundo e das ações, no raciocínio simbólico e num planejamento de um curso de ações para se chegar ao objetivo.
Em contraposição, a abordagem chamada reativa rompe com a idéia da necessidade de uma representação simbólica do mundo e de raciocínio simbólico.
Em os agentes reativos, as decisões são tomadas em tempo real, normalmente baseadas em pouca informação e regras simples que definem a ação em função de uma situação.
A terceira abordagem busca unir as duas abordagens anteriores, e é conhecida como híbrida.
Em a seqüência deste capítulo, serão apresentadas algumas arquiteturas representativas das três abordagens.
É importante salientar que a classificação das arquiteturas dentro de as abordagens pode ser um tanto controversa.
Em a literatura, podemos encontrar arquiteturas classificadas ora num grupo, ora em outro.
A arquitetura PRS, que veremos mais adiante, é um exemplo, aparecendo algumas vezes como deliberativa (como em), outras como híbrida (como em).
Isto se deve à maior ou menor valorização de algumas Citada em.
Segundo condição de invocação consiste num conjunto de situações (crenças e objetivos) que devem ser satisfeitas para que a AC seja aplicável.
Já o corpo é composto por um grafo, com um nó de inicio e um ou mais nós de fim.
O corpo das ACs pode ser visto como um plano, na medida que se um nó de fim for atingido, o objetivo responsável por ativar o plano foi realizado.
Existem ACs sem corpo, chamadas de primitivas, que tem associadas a si uma ação primitiva que pode ser realizada diretamente por o sistema.
Existem também ACs de metanível, que contêm informações para a manipulação interna dos estados mentais do próprio agente.
Aquelas tarefas selecionadas por o sistema para execução, imediata ou futura, estão contidas na estrutura de intenções.
Normalmente, cada intenção é formada por uma AC em conjunto com outras sub-ACs (ACs normais, mas adotadas para realizar um objetivo parcial da AC principal) necessárias para a execução da primeira, organizadas numa pilha.
As intenções podem estar em três estados:
Ativa, quando estão aptas para execução assim que sua posição na estrutura de intenções permitir;
Suspensa, quando foram selecionadas para a execução, mas nenhuma decisão foi tomada sobre quando deve ser executada, devendo ocorrer uma ativação explícita;
E suspensa condicionalmente, quando aguardam que uma condição, chamada condição de ativação, seja satisfeita.
Existe ainda uma relação de precedência entre as intenções, com o objetivo de evitar conflitos no momento da execução.
Uma intenção de maior precedência deve ser realizada ou retirada da estrutura antes que instruções de menor precedência possam ser executadas.
O Interpretador funciona basicamente da seguinte forma:
Baseado no conteúdo ativo do módulo de objetivos e da Base de Dados num certo momento, ele seleciona um conjunto de ACs aplicáveis, baseado nas condições de invocação.
Esta seleção, baseada na comparação de crenças e objetivos com a condição de invocação, sem nenhuma forma de raciocínio, possibilita grande rapidez no processo.
Mas é possível realizar a escolha levando em conta caminhos alternativos de execução, através da invocação de ACs de metanível.
De o conjunto de ACs selecionados, um ou mais são colocados na estrutura de intenções.
Se o AC foi selecionado em função de um novo objetivo ou de novas crenças do sistema, ele é colocado na estrutura como uma nova intenção, mas se ele foi selecionado devido a um objetivo operacional de uma intenção já em execução, ele é colocado na pilha de Áreas de Conhecimento daquela intenção.
A execução de uma intenção se dá através da realização de ações primitivas, que modificam o mundo externo ou o estado interno do sistema, ou da criação de novos objetivos operacionais.
Novos objetivos e novas crenças a respeito de o mundo resultam em novos ACs selecionados e o ciclo do Interpretador recomeça.
Normalmente, na ausência de novos objetivos ou crenças que ativem novos ACs, o sistema trabalha com as intenções previamente estabelecidas, executando as ações ou expandindo ACs com a chamada de sub-ACs.
Mas novas informações ou objetivos podem levar o sistema a suspender as intenções correntes, e mudar seu foco de ação para novas tarefas.
Várias decisões em PRS são fixas e podem ser implementadas em hardware no Interpretador.
Mas é possível sobrepor estas decisões através de ACs de metanível (por exemplo, ao escolher ACs não apenas por a sua condição de invocação).
A forma de invocar tais ACs de metanível é um tanto complexa, já que as suas condições de invocação normalmente se referem mais ao estado interno do agente do que ao mundo externo.
É importante também que as condições de invocação sejam bastante específicas, para evitar que o Interpretador as invoque freqüentemente ou sem necessidade, resultando em desperdício de tempo tomando decisões desnecessárias.
A execução destes ACs de metanível é normal, podendo ativar outros (sub) ACs de metanível, criando novos objetivos, ou realizando ações.
Segundo plano e as pré-condições para que ele seja adotado para execução:
Um desejo que o plano pode satisfazer, condições de invocação que devem ser satisfeitas e os recursos necessários para a sua execução.
O segundo é uma árvore, onde os nós são ações ou subplanos e os arcos definem a seqüência das ações ou subplanos.
A disposição em árvore permite que os planos já ofereçam opções de ação para diferentes situações que o agente pode encontrar durante a execução.
Como a arquitetura está voltada para a construção de agentes com habilidade social, o agente deve ser capaz de realizar tanto ações quanto comunicações com outros agentes.
Surge, então, a necessidade de dois tipos de plano.
Os scripts são planos para um fim desejado.
Cada nó do plano pode ser um comportamento de execução, um comportamento de cognição (ação interna), outros scripts ou protocolos de cooperação.
Os protocolos de cooperação são o segundo tipo de plano.
Em eles, cada nó é uma chamada a outro protocolo ou a um plano de comunicação primitivo.
Um protocolo composto por apenas um plano de comunicação primitivo é chamado de protocolo primitivo.
O componente CES do módulo Cognição é o responsável por a execução dos scripts, enviando os comportamentos de execução para o módulo executores e os protocolos de cooperação para o CEP.
O CEP lida com os protocolos preparando mensagens para enviar e administrando as recebidas.
O envio e o recebimento são executados por o módulo comunicações.
O CRD é o responsável por o raciocínio sobre o mundo e por a escolha da melhor forma de atingir objetivos ou executar as intenções baseado na situação, decidindo, por exemplo, quais arcos a seguir nos scripts e protocolos de cooperação.
Os processos do CRD envolvem três níveis, que ocorrem seqüencialmente:
Nível estratégico, onde os objetivos são adotados ou os já existentes são revisados em função de uma situação;
Nível tático, onde intenções existentes são revisadas ou novas são formadas a partir de a escolha de planos para realizar os objetivos;
E nível de execução, onde as intenções são escalonadas e preparadas para execução.
O funcionamento do CRD e os seus níveis pode ser visto na Figura 2.4. O Monitor de Eventos (Me) é responsável por endereçar os eventos novos aos outros componentes do CRD.
Cada evento pode ter três origens distintas no agente.
A origem mais evidente é o módulo Sensores, e os eventos consistem em acontecimentos no ambiente que podem ser de interesse do agente.
Outra fonte é o CEP, que recebe as mensagens, filtra as que podem interessar ao CRD e as converte para eventos.
Por último, temos o CES, que capta eventos como sucesso ou falha na execução de um plano, ou a suspensão de um script.
A menos que haja ordem em contrário, o Me direciona os eventos para o Selecionador de Tarefas.
Os desejos do agente são as tarefas que o agente pode executar, e a biblioteca de planos contém todos os planos que o agente conhece para atingir estes desejos e que sejam possíveis de executar através de ações primitivas.
É assumido que, para cada desejo deve haver pelo menos um plano de ações.
O Selecionador de Tarefas (St) observa eventos novos a luz das preferências presentes no módulo Motivações e dos objetivos existentes, decidindo por a adoção ou não de novos objetivos.
Algumas rotinas, como as que controlam conflitos entre objetivos e suas prioridades devem ser criadas por o construtor do agente.
Esta parte do St é chamada parte dependente da aplicação.
Outros procedimentos são gerais, como os responsáveis por tarefas administrativas, filtragem das informações requeridas por a parte dependente da aplicação, atualização na estrutura de objetivos, entre outras.
Estas rotinas formam a parte independente da aplicação.
Segundo A divisão nas partes dependente e independente da aplicação pode ser evitada através da colocação, por o construtor do agente, de todo conhecimento relacionado à adoção ou não de certas tarefas em scripts de metanível.
Assim, a parte dependente da aplicação deixa de existir, cabendo às rotinas da parte independente o controle sobre a adoção de metaobjetivos para solucionar conflitos e prioridades.
O Raciocinador de Meios-Fins (RMF) tem a função de encontrar uma seqüência de ações que leve o agente a atingir cada um dos objetivos da estrutura de objetivos.
Isto é feito através de procedimentos independentes da aplicação, que procuram nos cabeçalhos dos planos da biblioteca quais são compatíveis com as crenças do agente sobre o mundo e adequados para atingir o objetivo.
Existindo mais de um plano possível, um script de metanível deve ser acionado para decidir qual será adotado como uma intenção.
As prioridades na estrutura de intenções seguem a prioridade da estrutura de objetivos.
Em a Base de Dados há uma imagem das intenções e dos objetivos correntes, de forma que o agente tenha crenças sobre seus próprios estados mentais.
O escalonador vê a estrutura de intenções como uma pilha, de onde retira scripts e protocolos.
Os protocolos são enviados para a execução no CEP.
Os scripts são retirados da pilha de intenções, um a um, e colocados, juntamente com os sub-scripts necessários para sua execução, numa estrutura chamada scripts ativos.
Um novo script só poderá ser colocado nesta estrutura quando ela estiver vazia, o que pode decorrer do término ou da suspensão de um script anterior.
A suspensão pode se dar por a falta de recursos para sua execução, por a adoção para execução de um objetivo com maior prioridade ou quando o nó a ser executado é um protocolo de comunicação e a execução só pode continuar com o recebimento de resposta.
Acontecendo algum destes casos, o script suspenso é colocado numa estrutura chamada scripts suspensos, e o Monitor de Eventos passa a esperar por o evento necessário para a reativação.
Uma forma de aumentar a reatividade do sistema é através da implementação de algumas situações que dispensam tratamento no nível estratégico, sendo associadas por o Me ao primeiro script aplicável na formação de uma intenção.
Em este caso, é importante que a intenção tenha a mais alta prioridade, sendo prontamente executada.
Segundo As unidades de comportamento são chamadas de níveis de controle e são dispostas paralelamente, com cada uma de elas estando ligada tanto a sensores como a atuadores.
Esta distribuição paralela evita o gargalo que foi apontado nos módulos de planejamento de outras arquiteturas.
Cada um dos comportamentos implementados individualmente deve realizar alguma tarefa, e o conjunto destes comportamentos dão ao robô o que é chamado de competência.
A implementação dos níveis em peças de hardware independentes possibilitam um ganho de velocidade e a possibilidade de adicionar novas unidades de comportamento, o que deve resultar num aumento da competência global do sistema.
Os níveis são construídos a partir de processadores, referidos por módulos, que enviam mensagens entre si.
Cada processador é uma máquina de estados finitos executando assincronamente, controlando sinais de entrada e enviando sinais para as saídas.
O envio de mensagens acontece através da ligação da saída de cada modulo à entrada de um ou mais resultado não de ações planejadas, mas da interação entre estratégias simples e o ambiente complexo, agindo continuamente em função de circunstâncias imediatas.
A atividade do agente em Pengi se baseia na noção de rotinas, que são modelos de interação entre o agente e o seu ambiente.
As rotinas não estão representadas explicitamente no agente, mas resultam da interação entre as regras que as compõe com a situação do ambiente.
Assim, é o estado do mundo que orienta a seleção de regras que indicam o que fazer, resultando em ações que alteram o mundo.
O agente, ao se engajar na execução de uma rotina, não tem nenhuma noção pré-concebida do resultado de suas ações.
Ele apenas age em resposta a circunstâncias, e novas respostas são aplicadas em caso de mudança nestas circunstâncias.
A atividade do agente é guiada por propriedades relevantes no ambiente, chamadas aspectos indexico funcionais, ou apenas aspectos.
As referências aos componentes do ambiente são sempre feitas levando em conta a sua relação com o agente, e não através da atribuição de uma constante a cada um dos componentes.
Assim, ao invés de termos, por exemplo, um identificador para cada abelha presente no ambiente, temos uma descrição das abelhas relevantes para o agente e de que forma elas são relevantes.
Se houver uma abelha perseguindo o agente em determinado momento, este não se referirá a ela como abelha1 ou outro nome específico, mas por a-abelha- que- está- me- seguindo.
É evidente, também, que esta mesma abelha pode, em outro momento, deixar de perseguir o agente, e outra pode começar a perseguí- passando a segunda a ser referenciada por o identificador a-abelha- lo, que- está- me- seguindo.
A arquitetura é implementada através de dois sistemas, um central e um periférico.
O central é o responsável por a seleção de ações baseado nos aspectos relevantes do meio.
Por não possuir nenhuma representação simbólica e não realizar nenhum processamento simbólico, o sistema central pode ser construído de forma bastante simples, através de um rede combinacional.
As entradas desta rede são enviadas por o sistema de percepção e as saídas vão para o sistema de controle motor.
Assim, quando ocorrem mudanças no meio, a saída do sistema de percepção também mudam, e a mudança é propagada por a rede, resultando em ações diferentes.
Os sistemas de percepção e o sistema de controle motor compõe o sistema periférico.
Guiado por a rede central, o sistema periférico executa processos de percepção chamados rotinas visuais, responsáveis por identificar, marcar e indexar os aspectos do ambiente relevantes aos objetivos do agente.
Duas ações conflitantes podem ter sua adoção possibilitada numa determinada situação.
Algumas vezes, pode haver uma precedência explicita entre as ações para evitar o conflito, mas na maioria dos casos a adoção de uma ação em detrimento de outra depende de outros aspectos da situação.
Por exemplo, se existe uma abelha se deslocando em direção a o pingüim e há um bloco entre eles, duas ações podem ser adotadas:
Fugir ou se dirigir ao bloco e empurrá-de forma a eliminar a abelha.
Em este caso, o que define a ação a ser adotada é um lo, aspecto adicional, a distância até o bloco.
Se a abelha estiver mais próxima do bloco, o melhor é fugir, caso contrário a melhor ação é eliminá-Assim, ações podem se sobrepor, la.
Permitindo ao agente a seleção da melhor entre diferentes opções, mesmo sem haver nenhuma manipulação simbólica.
2.2.3 Rede de Ativação Pattie Maes apresenta, em, uma nova forma de implementar agentes racionais.
A exemplo da Subsumption Architecture, esta abordagem prevê a construção de um agente através de módulos que interagem entre si, cada qual dotado de uma competência específica.
A seleção de qual módulo será ativado e, portanto, de qual ação será executada, é feita através da propagação de energias de ativação e inibição entre os módulos, sem a necessidade de módulos específicos de controle.
Cada um dos módulos é descrito através de uma lista de pré-condições necessárias para a sua ativação, de uma lista de adição, contendo proposições que se tornarão verdadeiras após a ativação do módulo, e uma lista de exclusão, contendo as que se tornarão falsas após a ativação.
O módulo deve conter ainda um parâmetro chamado nível de ativação.
A descrição dos módulos (e, por conseqüência, da ação que cada um executa) em função de pré e pós-condições é inspirada nos operadores dos sistemas de planejamento clássicos.
Um módulo é considerado executável quando todas as suas pré-condições estiverem satisfeitas.
Mas para que a ação real seja executada é necessário que o nível de ativação do agente esteja acima de uma patamar mínimo previamente determinado e seja o maior entre todos os níveis de ativação.
A energia responsável por a ativação dos módulos tem origem nos objetivos globais do agente e no estado corrente do ambiente.
Aqueles módulos que tiverem uma ou mais de suas pré-condições ocorrendo no ambiente são ativadas por o estado, recebendo energia de ativação.
A ativação por os objetivos ocorre por a entrada de energia de ativação nos módulos que realizarem pelo menos um dos objetivos globais do agente, isto é, se pelo menos um dos objetivos fizer parte da lista de adição do módulo.
Por outro lado, os objetivos que foram atingidos e devem ser mantidos assim retiram energia de ativação dos módulos que tem tais objetivos na sua lista de exclusão.
A energia de ativação é conceitual.
Em a verdade, o recebimento de energia de ativação corresponde a um incremento no nível de ativação do módulo, e a retirada de energia corresponde a um decremento.
Os módulos são conectados numa rede através de três tipos de ligação:
Há uma ligação de sucessor do módulo x para o y para cada proposição que esteja na lista de adição de x e na de pré-condições de y;
Há uma ligação de predecessor do módulo x para o y para cada ligação de sucessor de y para x;
E há uma ligação de conflitante do módulo x para o y para cada proposição que esteja na lista de exclusão de y e na de pré-condições de x.
A idéia é que a energia de ativação se propague através destas ligações e se acumule em maior quantidade naquele módulo que é responsável por executar a ação mais indicada para a situação e os objetivos correntes.
Os módulos podem se ativar ou inibir mutuamente, propagando a energia proveniente do ambiente e dos objetivos.
A ativação dos sucessores acontece quando um módulo executável (suas pré-condições são verdadeiras e sua ação será executada quando o nível de ativação atingir um patamar exigido) x incrementa o nível dos seus sucessores y que têm entre suas pré-condições uma proposição que é falsa no ambiente mas que faz parte da liste de adição de x.
Intuitivamente, isto significa que, como o módulo x é executável, a pré-condição do módulo y está prestes a ser satisfeita, e seu nível de ativação deve ser incrementado.
A ativação dos predecessores acontece quando um módulo não executável x incrementa o nível dos seus predecessores y que têm em sua lista de adição uma proposição que é falsa no ambiente e que faz parte das pré-condições de x.
Isto significa que x propaga energia para os módulos capazes de tornarem suas pré-condições verdadeiras.
Por fim, a inibição dos conflitantes ocorre quando um módulo x, executável ou não, decrementa o nível dos seus conflitantes y que têm uma proposição na sua lista de exclusão que é verdadeira no ambiente e que faz parte das pré-condições de x.
Assim, x tenta evitar a ativação dos módulos que podem tornar suas pré-condições falsas no ambiente.
A energia propagada por um módulo, tanto para ativação quanto para inibição, é uma fração da sua própria energia de ativação.
A entrada e o fluxo de energia na rede de módulos são constantes.
Isto significa que o estado do ambiente e os objetivos globais podem variar a qualquer momento sem prejuízo para a atuação do agente.
Caso modificações aconteçam, o nível de ativação dos módulos ativados por o estado do ambiente e/ ou por os objetivos é alterado e a nova situação se propaga por a rede.
Assim, a geração de ações ocorre em ciclos.
O impacto dos objetivos e do estado do ambiente é computado, a propagação é computada e o módulo que for executável e tiver um nível de ativação acima de o limite mínimo e maior que os níveis dos outros módulos é executado.
Em caso de dois módulos com o níveis de ativação iguais e maiores que os dos demais, a escolha é randômica.
Executada a ação, o nível de ativação do módulo que foi ativado passa a ser 0. Alguns parâmetros globais são importantes para o comportamento do agente.
O primeiro é o nível de energia mínimo que um módulo deve atingir para ser ativado.
A cada ciclo em que nenhum módulo é ativado, o nível mínimo é diminuído em 10%, e volta ao valor original após ocorrer uma ativação.
Outros parâmetros são a quantidade de energia injetada na rede por cada proposição que é verdadeira no mundo, a quantidade de energia injetada por um objetivo a ser realizado e a quantidade retirada por um objetivo que deve ser mantido.
A quantidade de energia que deve ser propagada para sucessores, predecessores e conflitantes é calculada em função destes parâmetros.
Aumentando o valor do parâmetro que indica a quantidade de energia injetada por o ambiente, o agente torna- mais reativo.
Por outro lado, se aumentando o valor do parâmetro que indica a quantidade de energia injetada por os objetivos, a atuação do agente se torna mais direcionada a objetivos.
A escolha de valores apropriados para estes parâmetros é muito importante para o comportamento global do agente.
Em é apresentado um modelo matemático que define formalmente os valores de ativação e a quantidade de energia que é propagada por a rede de ativação.
Esta forma de requisitar ativação nos permite implementar níveis que não conhecem as capacidades dos outros, apenas a própria.
Se o nível não for capaz de resolver uma tarefa, ele a repassa ao nível superior.
Se o mais alto nível não conseguir solucionar uma tarefa, significa que o agente como um todo é incapaz de encontrar uma solução, mesmo que conte com a colaboração de outros agentes.
Os níveis superiores enviam sinais aos níveis abaixo informando o insucesso.
O agente então envia uma mensagem recusando a tarefa em caso da requisição ter sido feita por outro agente ou realiza uma rotina de emergência, mesmo que provavelmente sem efeito.
O envio dos planos com cuja execução os níveis se comprometeram para a execução através do NBC (que é o único nível a ter acesso a Interface com o Mundo) ocorre através de um controle top-down, num sentido inverso à requisição de ativação.
Os comprometimentos do NPC enviados ao NPL são planos parciais que descrevem a atuação do agente na solução de um problema num plano conjunto.
Estes planos são escalonados por o NPL juntamente com os gerados no próprio nível, e as intenções são então enviada ao NBC.
Os modelos de comportamento que formam os planos enviados por o nível NPL (e por o NPC através de NPL) são escalonados então juntamente aos gerados no NBC e causam a execução das ações definidas na Interface com o Mundo.
Após lançar uma intenção ao nível imediatamente inferior, o nível passa a esperar a confirmação da execução, de a qual depende a continuidade no tratamento de novas tarefas ou um replanejamento.
2.3.2 TouringMachine A arquitetura TouringMachine foi apresentada por Ferguson em sua tese de doutorado,.
O nome deriva do ambiente de atuação para o qual a arquitetura foi planejada:
O TouringWorld.
Basicamente, este ambiente é composto por objetos fixos, passíveis ou não de colisão, e agentes, que são móveis.
Os agentes são todos do tipo TouringMachine, mas não cooperam entre si.
Seu comportamento se compõe basicamente de deslocamentos dentro deste ambiente, sempre evitando colisões e outros acontecimentos indesejáveis.
No decorrer de esta apresentação, por motivo de clareza, o agente sendo descrito será tratado por &quot;agente», e os demais agentes presentes no ambiente por &quot;entidades».
Embora o ambiente de atuação do agente não seja o mundo real, o TouringWorld também exige do agente uma capacidade reativa, além de uma capacidade de agir racionalmente de forma dirigida a um objetivo e raciocinar em função de (ou sobre as) outras entidades.
A arquitetura TouringMachine, que pode ser vista na Figura 2.8, implementa estas capacidades através de três níveis de controle:
Nível Reativo (nível R), Nível de Planejamento (nível P) e Nível de Modelagem (nível M).
Os níveis operam de forma concorrente, são motivados independentemente e todos geram atividades.
Cada um de eles possui um mecanismo interno próprio e está ligado de forma independente aos subsistemas de Percepção e de Ação, agindo como se fosse o único nível a controlar o agente.
Já se pode perceber duas sensíveis diferenças em relação a a INTERRAP:
Em aquela, ao invés de termos níveis operando de forma concorrente, tínhamos uma distribuição hierárquica das tarefas;
E a estrutura interna era bastante semelhante em todos os níveis.
Ssegundo algumas funcionalidades, mas não deve ser visto como um nível intermediário entre eles.
A Figura 2.9 apresenta um esquema da arquitetura.
Como exemplo das informações que cada um destes componentes manipula, podemos imaginar um robô numa sala:
O componente simbólico atua em função de o modelo simbólico que possui, o componente diagramático atua em função de as imagens que recebe das câmeras de vídeo, e o componente reativo atua em função de os sinais dos sensores.
Não existe qualquer diferença qualitativa entre os três componentes.
A distribuição de atividades entre eles depende do contexto em que o sistema se encontra e do formato da informação, o que pode variar de um momento para outro.
O controle parcial do agente pode variar entre os componentes.
Cada um dos componentes é composto por diversos elementos básicos chamados experts.
Experts são subagentes que executam concorrentemente dentro de a arquitetura (em períodos ou em resposta a estímulos ou ativação direta), cada um responsável por uma atividade cognitiva específica.
Desta forma, temos experts simbólicos, reativos e diagramáticos, distribuídos nos componentes respectivos.
A forma de recebimento, gerenciamento e envio de informações entre os experts é apresentada na Figura 2.10, onde os experts são representados como círculos e as informações são representadas por retângulos.
Os experts formadores do componente simbólico se referem a uma Base de Conhecimento, onde atualizam informações armazenadas, buscam informações para o processamento simbólico e trocam informações entre si.
Os diagramáticos podem se referir a Mundo Real Figura 2.10. Gerenciamento de informações entre os experts, segundo diferentes representações diagramáticas, e cada representação pode ser acessada por mais de um expert.
Já os reativos interagem com o mundo real através de sensores e atuadores, e podem se comunicar diretamente uns com os outros.
É importante salientar que as setas que interconectam os experts reativos entre si e os diagramáticos com as representações são dinâmicas.
A Figura 2.10 apresenta apenas a forma de comunicação interna entre experts de uma mesma classe, mas existe um protocolo para a comunicação entre diferentes classes, chamado EIEP (do inglês Expert Information Exchange Protocol).
Este é um protocolo para a troca de mensagens através de um blackboard.
A troca de mensagens se baseia no conteúdo da mensagem, e não em quem enviou e quem deve receber.
Cada expert seleciona dinamicamente o tipo de informação que deseja receber, e cada mensagem produzida deve informar o seu tipo.
Estes dois princípios permitem a distribuição correta das informações, mesmo sem a indicação do recebedor por quem envia a informação e sem a indicação da origem por quem recebe a informação.
Outra importante característica da arquitetura é o suporte dado à distribuição dos experts numa rede de máquinas.
Isto é feito estendendo o protocolo EIEP para uma rede.
Desta forma, é possível distribuir os diferentes componentes em diferentes máquinas.
Em um sistema composto por diversos robôs, por exemplo, é possível que todos compartilhem o seu conhecimento simbólico, com a implementação do componente num computador central, enquanto os componentes diagramático e reativo são individuais e executam internamente em cada um.
Para facilitar a implementação de agentes utilizando HEIR, existe uma extensão para sistemas operacionais chamada Ethos, que fornece os serviços necessários para a arquitetura, como serviços de ativação e desativação de experts e comunicação, por exemplo.
O conjunto de arquiteturas visto anteriormente é apenas uma pequena porção dentro de o universo de arquiteturas de agentes racionais.
Embora pequeno, o conjunto é representativo de algumas das principais idéias que norteiam esta área de pesquisa e dos seus resultados no que se refere a construção de agentes individualmente, não levando em conta a sua atuação num meio multiagente.
Em a Seção 3.1, as abordagens deliberativa e reativa serão discutidas e comparadas em relação a alguns conceitos importantes que devem caracterizar os agentes, tanto internamente quanto em relação a sua atuação.
Alguns destes conceitos são amplamente apontados como características de agentes, outros foram levantados por na sua defesa da construção de sistemas sem raciocínio simbólico.
Em a Seção 3.2 serão discutidas as formas de integrar deliberação e reatividade utilizadas nas arquiteturas híbridas descritas no capítulo anterior.
Em o início deste trabalho, foi apresentado um conjunto de características que definem um agente.
Brooks, na sua fundamentação da Subsumption Architecture, apresentou mais algumas características de agentes, além de sugerir a correlação entre a complexidade do comportamento do agente e a complexidade do ambiente.
A seguir, será feita uma análise comparativa das abordagens deliberativa e reativa a luz de alguns destes conceitos e características.
3.1.1 Reatividade Com o surgimento da abordagem reativa, que negava a necessidade, para a construção de agentes, de estruturas que são fundamentais nas arquiteturas deliberativas, os conceitos reatividade e deliberação passaram a ser vistos como totalmente distintos e até mesmo como antagônicos.
A reatividade, ou capacidade de reagir a estímulos do meio, seria, por este ponto de vista, uma característica das arquiteturas reativas, dando a elas uma vantagem na atuação em ambientes dinâmicos.
A capacidade de deliberação seria uma característica das arquiteturas deliberativas, dando a elas a vantagem na solução de tarefas que exigem uma coordenação de ações.
Mais tarde, surgiram as arquiteturas híbridas que buscam implementar as características em módulos independentes, de modo que o agente como um todo possa usufruir das vantagens de ambas.
Quando se pensa no conceito de agente reativo como um paradigma para a construção de agentes, o antagonismo entre as abordagens deliberativa e reativa se torna mais evidente:
A abordagem reativa nega a necessidade daquilo que forma a base do funcionamento das arquiteturas deliberativas, ou seja, a representação e manipulação simbólica.
Mas o objetivo desta seção é discutir a reatividade no sentido de geração de respostas a estímulos do meio, ou seja, a reatividade como parte do comportamento do agente.
A geração de respostas aos estímulos do ambiente não exige nenhuma estrutura ou característica que não esteja presente nos agentes deliberativos.
Possuindo os sensores adequados, os agentes deliberativos são capazes de gerar respostas ao que ocorre no mundo em sua volta.
Um certo grau de reatividade está presente em todas as arquiteturas deliberativas descritas anteriormente.
O que dificulta a geração de respostas em tempo real é o processo de deliberação para a escolha da ação, de modo que, num mundo real e de grande dinamicidade, a resposta pode acontecer quando já não é mais necessária.
O tempo de resposta pode ser diminuído com uma representação do conhecimento que permita acesso e geração da resposta a certos estímulos do meio com o mínimo de deliberação.
Além disso, a própria produção de componentes de hardware com processamento cada vez mais veloz tende a aumentar a rapidez da geração de respostas aos estímulos.
Embora exista este grau de reatividade nas arquiteturas deliberativas, é inegável que as arquiteturas reativas apresentam vantagem na rapidez da geração de respostas aos estímulos do meio.
Isto decorre do fato de que os sinais vindos dos sensores geram uma ação imediata nos atuadores, o que significa uma importante vantagem que atuação em ambientes de grande dinamicidade.
Mas é importante que se realce a possibilidade de se ter uma certa reatividade às mudanças do meio, ainda que em grau menor, nas arquiteturas deliberativas.
Em a seqüência deste trabalho, a utilização dos termos &quot;arquitetura reativa «ou &quot;agente reativo «se refere a arquiteturas ou agentes construídos segundo o paradigma que propõe a geração de ações em função de os sinais dos sensores, sem uma representação simbólica do mundo.
Já os termos &quot;reatividade «ou &quot;comportamento reativo «se referem à geração de ações em resposta a estímulos do ambiente, independente da abordagem utilizada na construção do agente.
3.1.2 Comportamento Orientado a Objetivos Em certas ocasiões, a situação do ambiente não permite ao agente realizar seus objetivos diretamente, através de ações isoladas.
Para que o objetivo seja satisfeito, é necessária a realização de uma seqüência de ações que levarão o agente, passo a passo, a realizar sua tarefa.
Mesmo que seja impossível a realização imediata, as ações adotadas devem estar focalizadas em possibilitar a realização futura do objetivo.
Em as arquiteturas reativas Pengi e Subsumption Architecture, as ações são geradas apenas em função de os estímulos recebidos por o agente através dos sensores.
Os objetivos do agente influenciam a sua construção, na medida que definem qual ação é ativada por determinado conjunto de sinais dos sensores.
Mas em tempo de execução, uma ação será executada somente se for ativada por os estímulos do meio, independente da sua importância para o objetivo.
A arquitetura de Rede de Ativação, embora reativa, permite que ações sejam adotadas em função de os objetivos dos agente.
Conforme foi apresentado no capítulo anterior, isto é possível aumentando a quantidade de energia de ativação inserida no sistema por os objetivos e reduzindo a energia inserida por o estado do ambiente.
Mas os encadeamentos de ação são definidos durante a construção do agente, e não existe nenhum compromisso com a realização de uma seqüência, na medida que as ações são executadas em função de uma circunstância momentânea.
Por terem seu comportamento ditado por o estado do ambiente, os agentes reativos não apresentam a capacidade de elaborar previamente uma seqüência de ações que leve ao objetivo.
Em as arquiteturas deliberativas, isto é possível através da construção de planos, que ao serem executados resultam no objetivo.
O conhecimento das condições necessárias para a execução de cada ação que o agente é capaz de realizar, associado ao conhecimento prévio dos resultados da sua execução, permite ao agente construir um encadeamento de tais ações que, partindo do estado atual do mundo, atinja o objetivo.
Por outro lado, variações no ambiente podem provocar problemas para os agentes deliberativos no momento de traduzir o ambiente para uma representação simbólica.
A o se deparar com uma situação inesperada, o agente pode não ser capaz de representar adequadamente a situação, passando a atuar de forma desordenada ou até mesmo interrompendo a atuação.
Os agentes reativos, por não dependerem da representação para a atuação, tendem a manter um funcionamento relativamente estável.
Mesmo que uma drástica alteração no ambiente impossibilite a realização do objetivo, o agente tende a continuar exibindo certos comportamentos básicos, como evitar choques com obstáculos, por exemplo.
3.1.4 Objetivos Múltiplos Em, Brooks diz que seguidamente um agente «terá múltiplos objetivos, alguns conflitantes, que ele tenta obter.
Ele pode estar tentando atingir um certo ponto em frente enquanto evita obstáculos locais».
Embora correta, esta afirmação leva a uma importante reflexão sobre o que são os objetivos de um agente e como as abordagens reativa e deliberativa lidam com a existência de diversos objetivos, possivelmente conflitantes, num agente.
A capacidade de evitar colisões com obstáculos deve ser um dos objetivos de qualquer agente que esteja atuando num ambiente real.
Podemos considerar esta capacidade como inerente ao conceito de agir racionalmente, básico em qualquer agente.
De outro lado estão as tarefas que o agente deve realizar, que estimularam a sua construção.
É preciso que se torne clara a distinção entre os objetivos principais do agente, formados por as tarefas que este deve realizar, e aquelas capacidades que devem ser inerentes ao agente (como evitar obstáculos), que são fundamentais para que os objetivos principais sejam atingidos de forma racional.
A complexidade de certos problemas exige que sua solução seja dividida.
Surgem, assim, objetivos parciais, cuja realização é parte importante para que o objetivo principal seja obtido.
Um exemplo de um objetivo parcial é a obtenção de um mapa de um ambiente, para ser utilizado em futuros deslocamentos do agente.
Por outro lado, a construção de um mapa não tem sentido se não for como objetivo parcial do objetivo principal de se deslocar por o ambiente.
Portanto, existem objetivos que só tem sentido como objetivos parciais.
Assim, consideramos como objetivos do agente apenas aquelas tarefas de alto nível que ele deve realizar durante a sua atuação.
Os objetivos parciais são considerados apenas como passos importantes para a obtenção dos objetivos principais, enquanto os comportamentos básicos inerentes ao comportamento racional são considerados básicos para a realização, de forma satisfatória, das tarefas do agente.
A partir de esta definição, é possível retornar à frase de Brooks citada no início desta seção e afirmar que atingir um determinado ponto e evitar obstáculos não devem ser vistos como objetivos conflitantes:
Atingir o ponto é o objetivo, evitar obstáculos é apenas um comportamento que indica atuação racional e que é necessário para que o objetivo seja realizado.
Assim, os níveis de comportamento (na Subsumption Architecture) e as rotinas (em Pengi) não devem ser vistos individualmente como objetivos, mas como partes importantes para um objetivo principal representado por o conjunto.
Em a Rede de Ativação, a distinção entre objetivos do agente e os objetivos parciais ou inerentes ao comportamento racional é mais evidente.
Os objetivos principais são aqueles que injetam energia nos módulos que são capazes de realizá- los.
Os outros módulos, ativados através da propagação de energia de ativação por a rede ou por a energia injetada por o ambiente realizam os objetivos parciais ou inerentes ao comportamento racional.
Os agentes deliberativos são os mais aptos a lidar com múltiplos objetivos complexos.
A existência de diversos objetivos não acarreta a necessidade de nenhuma transformação estrutural (como a inclusão de novos módulos ou rotinas), apenas a sua inclusão na estrutura que comporta os objetivos do agente.
Para a realização destes objetivos, o agente realizará um planejamento através da adoção de ações e/ ou subplanos para a obtenção dos objetivos parciais e finalmente do objetivo final.
3.1.5 Estar Situado e Ter Corpo A característica de estar situado num ambiente é amplamente aceita como fundamental para que um sistema computacional seja considerado um agente.
O funcionamento do agente é dependente do seu estado interno e do estado do ambiente em que estiver situado.
Em os agentes deliberativos, o estado do ambiente é modelado internamente por o agente e é baseado neste modelo que as ações são tomadas.
Brooks é mais radical no conceito de estar situado, defendendo que o agente não deve modelar o mundo, mas sim agir em função de o próprio ambiente, referindo- constantemente se aos seus sensores e não a um modelo interno.
Esta idéia pode ser resumida na seguinte frase, encontrada em:
&quot;o mundo é seu próprio modelo».
Como vimos anteriormente, a principal vantagem dos agentes reativos em relação a os deliberativos está na atuação em ambientes dinâmicos.
Tais ambientes exigem de agentes deliberativos um constante monitoramento do ambiente e uma constante atualização da representação simbólica, o que pode levar o agente a tomar decisões tarde demais.
Como atuam diretamente em função de as informações dos seus sensores, sem que ocorra nenhum processamento simbólico, os agentes reativos são mais rápidos no tratamento de estímulos do meio e, portanto, mais indicados para lidar com as variações do ambiente.
Por outro lado, a adoção de certos objetivos e a construção de planos para atingí- los dependem de um processo de deliberação.
Assim, torna- evidente a dificuldade inerente aos se agentes reativos no que diz respeito ao tratamento de tarefas que exijam a realização de uma seqüência específica de ações para a sua solução.
Esta dificuldade na realização de tarefas que exijam um comportamento complexo e dirigido ao objetivo é a principal deficiência dos agentes reativos.
As arquiteturas híbridas surgem da combinação das duas abordagens anteriores, como forma de somar as vantagens e superar as deficiências.
É importante unir as duas de forma a dotar o agente tanto das capacidades de deliberação e planejamento como da capacidade de reação instantânea a estímulos do ambiente.
Esta combinação é fundamental em agentes que devem solucionar, em ambientes dinâmicos, tarefas que exigem um comportamento direcionado ao objetivo.
A parte deliberativa é responsável por a construção de planos para solucionar tarefas complexas.
Variações no meio que exijam uma reação rápida são tratadas por a parte reativa.
As formas de realizar a geração de ações através dos processos deliberativo e reativo não representam novidades, na medida em que diversas formas de implementar tais processos podem ser encontrados nas arquiteturas puramente deliberativas e puramente reativas.
O que surge de novo na elaboração de arquiteturas híbridas é a necessidade de um mecanismo de integração entre os processos.
É preciso definir como os processos deliberativo e reativo serão implementados e qual o papel de cada um no funcionamento do agente como um todo.
Em as arquiteturas híbridas apresentadas anteriormente, a integração não representa uma fusão das abordagens deliberativa e reativa.
O que se verifica é uma soma das duas através de módulos com um alto grau de independência, construídos de uma forma puramente deliberativa e puramente reativa, e que realizam suas tarefas de forma independente.
O agente passa a ser comandado por módulos que atuam individualmente na busca por seus próprios objetivos, ao invés de atuarem em conjunto como componentes de um único agente.
Os módulos são construídos para funcionar como se cada um fosse o único a controlar o agente.
Isto significa que um plano construído por o módulo deliberativo não leva em conta o fato de que uma alteração no ambiente possa provocar a ativação do módulo reativo, interrompendo a sua execução, ao mesmo tempo que o módulo reativo, ao tratar da alteração no ambiente, não tem nenhuma noção dos objetivos do módulo deliberativo.
Assim, os problemas novos que surgem na elaboração destas arquiteturas híbridas se relacionam à decisão sobre a quem compete cada tarefa a ser realizada e na decisão sobre quem tem o controle sobre os atuadores em cada momento.
Os módulos não interagem para resolver em conjunto cada tarefa.
Esta divisão em módulos com alto grau de independência pode resultar em interferências de um módulo na atuação do outro, que prejudicam o desempenho global do agente.
Isto porque no momento em que um plano está sendo executado e uma alteração no ambiente ocorre, necessitando ser tratada, o módulo reativo interrompe a execução do plano e assume o controle.
Terminada a atuação do módulo reativo, é possível que o plano que havia sido gerado por o módulo deliberativo não possa continuar sendo executado.
É necessária, no mínimo, uma reavaliação para verificar se o plano continua válido, e, talvez, a realização de um replanejamento.
A necessidade constante de reavaliação e replanejamento faz com que o agente desperdice grande parte do seu processamento.
Sem dúvida, a reação a estímulos do ambiente tende a interferir na realização de planos.
Portanto, é perfeitamente lógico que variações no meio tragam a necessidade de replanejamento.
Mas o alto grau de independência existente entre os processos deliberativo e reativo, que trabalham visando o melhor desempenho individual e não do agente como um todo, tende a aumentar esta necessidade.
Uma das causas de interferências entre os níveis ou componentes de um agente híbrido é a limitação nos recursos, que deve resultar no estabelecimento de uma política que defina prioridades na sua utilização.
Em as arquiteturas apresentadas, o problema é solucionado através da adoção de uma hierarquia de execução (INTERRAP), de regras de controle (TouringMachine) ou através da alternância no controle dos atuadores (HEIR).
Mas em todos os casos, o fato das ações serem geradas em cada nível ou componente sem levar em conta os objetivos dos outros certamente provoca um grau maior de conflitos.
Outro ponto importante que surge com o alto grau de independência entre os níveis ou componentes é a questão da atribuição das tarefas.
Como cada um trabalha de forma independente, é preciso definir a qual de eles cabe a solução de cada tarefa.
Em a TouringMachine, por exemplo, a ativação dos níveis também é feita de forma independente, o que permite que dois níveis diferentes tratem de uma mesma tarefa num determinado momento.
Isto significa que recursos estão sendo consumidos desnecessariamente, já que apenas uma das soluções será posta em prática.
As regras de censura, que filtram as entradas vindas do Subsistema de Percepção para os níveis de controle, visam diminuir esta redundância, mas representam em si um aumento na complexidade do sistema.
A distribuição de tarefas hierárquica implementada por a INTERRAP apresenta uma desvantagem no que se refere a tarefas que devem ser tratadas por níveis mais altos.
Antes da tarefa chegar ao nível capaz de tratá- é possível que os níveis mais baixos tenham feito la, tentativas de encontrar uma solução, diminuindo a agilidade do sistema.
Estas tentativas dos níveis incapazes de resolver a tarefa representam uma desvantagem em relação a ativação direta, que embora mais complexa e passível de redundância, têm o nível capaz de tratar a tarefa ativado independentemente dos outros.
Em a HEIR, as tarefas que cabem a cada um dos componentes estão relacionadas com o tipo de informação que são capazes de tratar.
Em este caso, os objetivos globais do agente são comuns a todos os componentes, mas cada um desempenha tarefas específicas para a obtenção destes objetivos de acordo com as informações disponíveis.
Mas em todas as arquiteturas, o tratamento das tarefas em cada módulo busca o melhor desempenho local, deixando em segundo plano o desempenho global do agente.
Em o capítulo anterior, foi defendida a idéia de que a capacidade de gerar ações em resposta a estímulos do meio não deve ser considerada como uma exclusividade dos agentes construídos seguindo a abordagem reativa.
Mas as respostas às mudanças no meio geradas por agentes puramente deliberativos são mais lentas, pois ao invés de ocorrerem diretamente em resposta aos estímulos dos sensores, ocorrem ao final de um processo de manipulação simbólica.
Por outro lado, a realização de tarefas complexas necessita de um processo de deliberação que faça o agente atuar dirigido principalmente por o objetivo (e não pelo meio), manipulando conhecimento simbólico sobre o problema, sobre o ambiente e sobre o resultado de suas próprias ações.
Assim, a solução para que se obtenha agentes capazes de resolver tarefas complexas em ambientes dinâmicos é a utilização de arquiteturas híbridas, com um processo deliberativo responsável por os objetivos e um módulo reativo responsável por o tratamento de situações que exigem respostas em tempo real.
A avaliação das três arquiteturas híbridas apresentadas no Capítulo 2 nos mostra que a integração entre a parte reativa e a deliberativa é o principal problema desta abordagem.
A arquitetura apresentada a seguir foi desenvolvida buscando uma maior integração entre o processo deliberativo e o módulo reativo, gerando agentes mais homogêneos, de forma a melhorar seu desempenho.
A Figura 4.1 apresenta a organização interna da arquitetura proposta.
Embora a abordagem reativa seja implementada num módulo específico, não é possível identificar uma divisão explícita entre deliberação e reatividade como a que ocorre nas arquiteturas híbridas apresentadas anteriormente.
O Módulo Reativo é apenas o final de um processo que começa de forma deliberativa, sendo o responsável por a realização das ações que compõe os planos do agente.
A integração ocorre através de um módulo chamado Avaliador de Execução.
Em as seções 4.1, 4.2 e 4.3, a arquitetura será apresentada em detalhes através da descrição das formas como foram implementados o processo deliberativo, o Módulo Reativo e o Avaliador de Execução, respectivamente.
Em a Seção 4.4 serão apresentadas algumas considerações a respeito de a arquitetura, tratando principalmente das características da integração entre deliberação e reatividade.
Verificador de Desejos Elegibilidade Biblioteca Crenças de Planos Verificador de Coerência Planejador Intenções Descrição das Ações Avaliador de Execução Sensores Atuadores Módulo Reativo Figura 4.1. A arquitetura proposta A primeira consideração a respeito de a deliberação do agente surge diretamente a partir de a Figura 4.1: Não existe um módulo específico que incorpore a parte deliberativa do agente.
A deliberação é um processo que principia no Verificador de Elegibilidade e termina apenas no Módulo Reativo, responsável por a execução das ações.
O Avaliador de Execução também é parte deste processo, na medida em que é o responsável por controlar a execução.
É impossível, portanto, identificar um módulo deliberativo.
O que existe é um processo deliberativo.
Em esta seção, descreveremos este processo até o momento em que um desejo e o plano adotado para realizá- são armazenados na estrutura de intenções.
A execução do plano lo será descrita juntamente com a descrição do Módulo Reativo e do Avaliador de Execução.
O processo deliberativo segue a abordagem BDI.
Sua distribuição modular das funcionalidades e sua forma de armazenamento das informações são inspiradas na arquitetura IRMA, apresentada por e descrita na Seção 2.1.1. O agente é definido, portanto, através de crenças e desejos.
As crenças são colocadas num repositório de mesmo nome, cujo conteúdo pode ser alterado em função de alterações no meio.
Junto às crenças está a Biblioteca de Planos, que contém planos pré-construídos (completos ou parciais) que podem ser utilizados por o planejador para economizar processamento.
Este repositório também pode ser alterado durante a execução do agente, acrescentando-planos construídos por o se planejador que tenham tido sucesso na obtenção dos seus objetivo.
Os planos pré-construídos podem ser considerados um subconjunto das crenças.
Os desejos são armazenados num repositório de mesmo nome.
Como é possível a existência de desejos incoerentes, representando objetivos impossíveis de ocorrerem simultaneamente, é preciso definir uma forma de, em caso de incoerência, decidir qual será selecionado para uma possível execução.
Isto é feito através da atribuição, por o projetista do sistema, de valores aos desejos, representando sua importância.
O conjunto de desejos é armazenado de forma ordenada, seguindo este parâmetro.
O princípio do processo de geração de ações se dá através do Verificador de Elegibilidade, responsável por avaliar o conjunto de desejos em relação a o conjunto de crenças.
Este passo visa impedir que o agente se comprometa com realizações que sejam desnecessárias ou impossíveis na situação do mundo modelada nas crenças.
Cada desejo é comparado ao conjunto de crenças.
Se houver um crença que indique que o fato representado no desejo já ocorre no mundo, o desejo não deve ser eleito para possível realização por ser desnecessário.
Se houver uma crença que indique a impossibilidade da realização do desejo, também neste caso o desejo não será transmitido adiante no processo por não ser possível de realizar.
Portanto, a função do Verificador de Elegibilidade é selecionar os desejos que forem coerentes com as crenças do agente.
O passo seguinte no processo é a verificação da coerência dos objetivos do agente, e ocorre num módulo chamado Verificador de Coerência.
Para que o agente tenha um comportamento racional, ele não pode se comprometer com a realização de objetivos contraditórios.
Assim, após a análise da coerência do desejo em relação a as crenças, feita por o Verificador de Elegibilidade, deve ser verificada a sua coerência com relação a as intenções já adotadas, com cuja realização o agente está comprometido.
Embora este comprometimento com as intenções seja uma das bases das arquiteturas BDI, é necessário que seja possível reconsiderar ou abandonar intenções com as quais o agente já esteja comprometido.
O comprometimento é importante para evitar que o agente ocupe grande parte do seu processamento reavaliando intenções já estabelecidas.
Por outro lado, as circunstâncias que levaram o agente a se comprometer com um objetivo podem mudar, ou a adoção de uma nova intenção, contraditória, pode ser necessária, fazendo com que a intenção antiga perca o sentido.
Segundo, existe &quot;uma tensão entre a estabilidade que os planos devem exibir para executar seu papel em focalizar o raciocínio prático e a revogabilidade que deve ser inerente em eles, dado que eles são formados baseados em informação incompleta sobre o mundo».
Esta tensão entre estabilidade e flexibilidade exige que o agente possua uma política que convencione sob que circunstâncias as intenções devem ser reexaminadas e, em certos casos, abandonadas.
Esta política também é executada na verificação de coerência.
Como a avaliação dos desejos por o Verificador de Coerência segue a ordem existente dentro de a estrutura de desejos, baseada no parâmetro de importância, se for encontrada alguma incompatibilidade entre alguma intenção (desejo que já tenha sido adotado) e o desejo que está sendo avaliado, é provável que o segundo seja abandonado.
Isto porque o desejo que gerou a intenção foi avaliado anteriormente exatamente por ter uma importância maior.
Mas após a adoção pode ter ocorrido alguma alteração no meio que impossibilite a realização do desejo previamente adotado, provocando a sua substituição por o novo desejo, de parâmetro de importância menor.
Tendo sido adotado um desejo coerente com as crenças e com as intenções, a próxima etapa no processo deliberativo é a construção de planos para que o desejo seja atingido.
Para facilitar e acelerar o planejamento, o planejador pode utilizar os planos armazenados na Biblioteca de Planos.
Assim, é possível que um desejo seja satisfeito, senão por completo, pelo menos em parte, por um plano pré-construído, o que resulta numa economia de tempo e recursos computacionais.
Caso a tarefa não possa ser totalmente tratada por um plano já construído, é executado um processo de planejamento, que construirá planos completos ou completará os planos pré-construídos quando necessário.
A o final do planejamento, a intenção, formada por o desejo e por o plano escolhido ou construído para satisfaze- é colocada numa estrutura de intenções.
Em esta estrutura, os lo, planos são ordenados numa fila, com os mais antigos tendo preferência para a execução.
Como o acesso aos atuadores é restrito ao Módulo Reativo, a execução dos planos é feita por este módulo, com a supervisão do Avaliador de Execução.
A reação em tempo real aos estímulos do ambiente é dada por um módulo chamado Módulo Reativo.
Em a sua definição, buscou- seguir fielmente os princípios da abordagem se reativa, de forma que o módulo não possui nenhum conhecimento sobre seu estado interno em momentos anteriores e nem conhecimento prévio sobre os resultados das suas ações.
A organização interna do módulo é inspirada na Subsumption Architecture, apresentada em e descrita neste trabalho na Seção 2.2.1. O módulo é composto por diversas unidades não seqüenciais, chamadas Níveis de Controle, cada uma responsável por uma ação simples.
De a integração entre estes níveis de controle temos o comportamento de mais alto nível que se deseja do módulo.
Todos os níveis estão conectados diretamente aos sensores e aos atuadores.
Cada nível é ativado por uma certa combinação de sinais dos sensores, resultando na realização da ação para a qual o nível foi concebido.
Não são implementadas as interconexões entre os níveis de controle previstas na Subsumption Architecture.
O que existe entre os níveis é uma hierarquia de execução, que evita conflitos que poderiam surgir quando dois ou mais níveis são ativados ao mesmo tempo.
Assim, a ativação de um nível indica que os níveis que o precedem na hierarquia não puderam ser ativados por aquela combinação de sinais, e que os níveis que o sucedem só poderão ser após a execução da ação gerada por o nível ativado.
O Módulo Reativo interage ainda com o Avaliador de Execução, de quem recebe ações a serem executadas e a quem envia informações contendo os níveis responsáveis por cada ação executada por os atuadores.
Cada ação que deve ser realizada, parte do plano gerado para alcançar um objetivo e repassada por o Avaliador de Execução, é recebida no Módulo Reativo como se fosse a informação de mais um sensor.
Assim, o conteúdo desta informação (que pode ser nulo quando o Avaliador de Execução não envia ação nenhuma) interfere diretamente na seleção de qual nível de controle será ativado.
Não havendo ação nenhuma a ser executada, o módulo atua de forma independente, tendo seus níveis ativados apenas por os sinais dos sensores.
Os níveis ativados neste caso são os responsáveis por manter o agente a salvo de situações no ambiente que possam representar ameaça à sua integridade.
O Módulo Reativo é fixo, isto é, os níveis de controle que o compõe são definidos na construção do agente e não há possibilidade de se incluir ou retirar níveis durante a execução.
Mas o fato de termos a entrada, na forma de sinais de ativação, de ações a serem executadas acaba definindo, indiretamente, subconjuntos de níveis específicos para cada ação.
Isto ocorre porque certos níveis terão entre suas condições de ativação um conjunto de ações (ou apenas uma determinada ação), o que impede sua ativação caso uma ação que não faz parte do conjunto esteja sendo realizada.
Assim, quando o avaliador envia uma ação ao Módulo Reativo, apenas uma parte dos níveis de controle poderá ser ativada.
Graças a esta característica, é possível que um mesmo conjunto de sinais dos sensores seja tratado de maneiras diversas, por níveis diferentes, dependendo da ação que deve ser executada.
Mas é evidente, também, que diversos níveis serão comuns a todas as ações, podendo ser ativados a qualquer momento.
O envio da informação sobre a ativação de um nível, que contém implícita a informação sobre a atividade dos atuadores, é gerada por o próprio nível ativado, como parte da sua funcionalidade.
A informação é gerada e enviada ao Avaliador de Execução juntamente com as instruções motoras enviadas aos atuadores.
A importância deste sinal para o funcionamento do Avaliador de Execução e, portanto, do agente como um todo, será descrita a seguir.
A passagem para o estado 2 se dá quando, durante a execução, um dos níveis indicadores de sucesso é ativado.
Esta mudança de estado faz com que o Me suspenda o envio da ação (limpe o buffer), já que esta foi realizada com sucesso.
Todas as ativações de níveis realizadas entre o envio da ação e a ativação de um nível indicador de sucesso (estado 2) não tem importância para o avaliador.
Portanto, a forma como o nível indicador de sucesso foi atingido (significando que a ação foi realizada) é de responsabilidade apenas do Módulo Reativo, não importando para o avaliador quais níveis foram ativados anteriormente, nem em que ordem isto ocorreu.
Já a passagem para o estado 3 acontece quando o Mm, estando no estado 1 de monitoramento, percebe a ativação de um nível indicador de insucesso ou uma seqüência de ativação dos níveis que indique insucesso.
A exemplo da mudança para o estado 2, também no caso de insucesso o Mm informa ao Me que o envio da ação deve ser suspenso.
O retorno para o estado 1 (tanto do estado 2 quanto do estado 3), para o reinicio do monitoramento, acontece quando é ativado o nível indicador de prontidão, que indica que o Módulo Reativo está pronto para receber outra ação.
Em o momento em que percebe a ativação de um nível de prontidão, o Mm busca na Descrição das Ações as informações necessárias para monitorar a ação que o Me já preparou para o envio e retorna ao estado 1. A nova mudança de estado informa ao Me que já é possível enviar outra ação, reiniciando o ciclo.
Para ilustrar o funcionamento do Avaliador de Execução em relação a os níveis de sucesso, insucesso e prontidão, suponhamos um robô cujo controle foi implementado na arquitetura que está sendo apresentada, atuando num ambiente dinâmico e com a função de deslocar objetos de um local até outro.
Suponhamos, ainda, que o Módulo Reativo só aceita novas tarefas do avaliador se a carga das baterias do robô estiver acima de 50%.
Se a primeira ação do primeiro plano gerado por o processo deliberativo for, por exemplo, mover uma pedra do ponto X para o ponto Y, o primeiro passo do avaliador é verificar, na Descrição das Ações, quais os indicadores de sucesso, de insucesso e de prontidão para esta ação.
O passo seguinte é enviar a ação ao Módulo Reativo e iniciar o monitoramento das ativações.
Se não surgir nenhum problema grave na realização da ação, quando o robô chegar ao ponto Y com a pedra, um certo nível será ativado para que a pedra seja solta no local.
Como este nível conclui a ação, ele certamente é um dos níveis indicadores de sucesso.
A ativação deste nível (Mm entra no estado 2) faz com que seja interrompido o envio da ação, uma vez que esta já foi realizada, e coloca o avaliador na espera da ativação do nível indicador de prontidão, para, então, enviar uma nova ação.
A espera por o nível indicador de prontidão pode parecer, a princípio, desnecessária.
Por que não enviar ao agente uma nova ação assim que a anterior tenha sido concluída?
Em muitos casos é possível que a nova ação não possa ser resolvida de imediato.
No caso de o robô do nosso exemplo, ao final do deslocamento da pedra, as baterias podem estar quase sem carga.
Então, com o avaliador esperando a ativação do nível indicador de prontidão, o Módulo Reativo assumirá o controle do robô, recarregando as baterias.
Em o momento em que o robô estiver com as baterias carregadas, o nível indicador de prontidão é ativado e o monitoramento volta para o estado 1, seguido por o envio de uma nova ação.
Caso o agente esteja em condições de receber outra ação (esteja disponível, com boa carga nas baterias) no momento da ativação do nível indicador de sucesso, o nível indicador de prontidão será ativado de imediato.
Suponhamos, por outro lado, que, após receber a ação, o robô se desloque para o ponto X e, ao chegar lá, não encontre pedra nenhuma (como o ambiente é dinâmico, a pedra pode ter sido movida).
Em este caso, um nível indicador de insucesso será ativado, e o monitoramento passará para o estado 3. Existem também seqüências de ativação indicadoras de insucesso.
Estas seqüências estabelecem ordens de ativação de níveis de comportamento que, se ocorrerem durante a execução de uma ação por o Módulo Reativo, servem de indicativo de que a ação não poderá a b Legenda:
Assim, as seqüências são formadas por níveis que individualmente não indicam insucesso, mas passam a indicar caso executados numa certa ordem.
Voltemos ao exemplo do robô anteriormente citado para vermos um caso de seqüência indicadora de insucesso.
Os níveis responsáveis por o comportamento reativo de desviar um obstáculo (comportamento comum em agentes reativos) não devem ser considerados níveis de insucesso, já que a tarefa deliberativa pode, a principio, ser concluída após o desvio.
Mas se a pedra estiver cercada por obstáculos, o robô exibirá um comportamento como o da Figura 4.4, resultado de sucessivas tentativas de desviar obstáculos.
Em o ponto indicado por a letra b, a ativação do nível responsável por dobrar a esquerda, já ativado quatro vezes anteriormente sem interferir na execução, deve completar uma seqüência de insucesso (já que o robô completou uma volta em torno de o objetivo sem conseguir atingí- lo).
Assim, níveis que normalmente não indicam insucesso, quando executados numa certa seqüência passam a indicar.
Quando o monitoramento atinge o estado 3, o avaliador suspende o envio da ação ao Módulo Reativo, solicita um processo deliberativo de replanejamento da intenção que não pode ser concluída, e o monitoramento passa a aguardar a ativação do nível de prontidão.
Se o processo deliberativo consegue criar um novo plano para o desejo que não pôde ser satisfeito, este plano será executado prioritariamente.
Portanto, ao perceber um indicador de insucesso, o avaliador não busca as razões que impediram a realização da ação.
Estas razões serão levadas em conta apenas no processo deliberativo, no momento do replanejamento.
É importante salientar, ainda, que a percepção da ação (enviada por o avaliador) por o Módulo Reativo juntamente com os sinais dos sensores apresenta vantagens na ativação dos níveis, que pode ser feita de forma mais direcionada ao objetivo.
No caso de o robô descrito acima, por exemplo, enquanto se dirige ao ponto Y podem surgir obstáculos no caminho que provoquem desvios.
Tendo a ação como uma das entradas da mesma forma que os sinais dos sensores, a ativação dos níveis responsáveis por evitar obstáculos pode ser feita de forma menos aleatória, tendo em vista o ponto Y. Além de os comportamentos inerentes ao comportamento racional, como o tratamento das alterações no meio, o Módulo Reativo pode ser capaz de realizar certos objetivos parciais, importantes para os desejos globais do agente.
A implementação dos comportamentos básicos e de tarefas parciais que não necessitam de deliberação no Módulo Reativo possibilita substituir em grande parte o refinamento nos planos que descrevemos anteriormente, reduzindo a complexidade da execução.
Isto decorre do fato de que ações de baixo nível passam a ser realizadas de forma reativa, cabendo ao planejador construir planos compostos por ações de alto nível, equivalentes aos objetivos parciais, que serão enviadas diretamente para execução.
Estas ações de alto nível não precisam ser refinadas no processo deliberativo porque as ações de mais baixo nível que as compõe são implementadas diretamente no Módulo Reativo.
A arquitetura reduz ainda a complexidade no momento da construção dos planos.
A quantidade de alternativas de atuação para atingir o objetivo que devem ser incluídas nos planos é reduzida por a capacidade do Módulo Reativo de se adaptar a certas situações e continuar a realização das ações.
Portanto, o aumento na capacidade e na complexidade do comportamento do Módulo Reativo reduz a complexidade dos planos, tanto na construção, reduzindo a quantidade de caminhos alternativos, como na execução, reduzindo a necessidade de refinamento.
4.4.2 A Forma do Controle Sobre o Módulo Reativo Como foi visto, o Módulo Reativo é construído de forma a poder lidar com uma parte das interferências do meio e continuar com a realização das ações de alto nível dos planos do ponto onde havia parado.
A execução das ações através de um módulo puramente reativo visa exatamente o tratamento de imprevistos durante a execução sem a necessidade de deliberação.
Para que isto seja possível, ele deve ser dotado de um certo grau de autonomia para decidir, em tempo real, qual a melhor forma de realizar a ação.
Isto significa que, durante o monitoramento da realização de uma ação, o avaliador não pode esperar que a ativação dos níveis do Módulo Reativo aconteça numa seqüência pré-estabelecida.
Caso contrário, o agente perderia a sua capacidade reativa e voltaria a ter os mesmos problemas para lidar com ambientes dinâmicos que são verificados nos agentes puramente deliberativos em geral.
Qualquer ativação de nível não prevista na seqüência seria considerada um erro, mesmo que fosse para tratar de uma alteração no ambiente e que o Módulo Reativo tivesse condições de retomar, posteriormente, a seqüência prevista.
A previsão de todas as seqüências de níveis de controle que o agente poderia vir a ativar seria impossível no caso de uma grande dinamicidade no ambiente.
É preciso, portanto, que o avaliador tenha flexibilidade, dando ao Módulo Reativo certa autonomia na realização das ações a ele solicitadas.
É importante salientar que a autonomia do Módulo Reativo se resume a escolha da melhor forma de tratar os estímulos do meio que interferem na realização da ação, já que o seu objetivo é sempre realizar a ação que faz parte de um plano deliberativo.
Mas existem alterações no ambiente que o Módulo Reativo não é capaz de tratar de forma a poder, posteriormente, continuar a realização da ação enviada por o Avaliador de Execução, o que significa uma falha na execução.
O avaliador deve ser capaz de perceber a ocorrência destas falhas e interferir na atuação do Módulo Reativo, suspendendo o envio das ações do plano cuja execução não teve sucesso e reativando o processo deliberativo para a construção de um plano novo, capaz de solucionar a tarefa no ambiente modificado.
O monitoramento através de níveis de sucesso, insucesso e prontidão tem por objetivo dotar a arquitetura deste equilíbrio entre o controle sobre o funcionamento do Módulo Reativo e a autonomia que este deve ter para realizar as ações solicitadas.
Uma vez enviada a ação para execução, o avaliador começa o monitoramento, verificando todas as ativações.
Mas o fato de apenas um pequeno conjunto de níveis de ativação influir no monitoramento permite ao Módulo Reativo escolher em tempo real a melhor forma de realizar a ação.
Todas as ativações de níveis ocorridas entre o envio da ação e a ativação do nível de sucesso, desde que não sejam de níveis ou seqüências de níveis indicadores de insucesso, são irrelevantes para o Avaliador de Execução.
Assim, como a ação foi realizada não é importante.
É importante apenas o fato de que foi realizada, ou no caso de insucesso, que não poderá ser realizada.
Desta forma, é garantida a autonomia ao Módulo Reativo na realização de cada ação.
4.4.3 A Independência do Avaliador Quanto à Forma de Implementação de Deliberação e Reatividade A o contrário de outras arquiteturas, que foram desenvolvidas tendo em vista a atuação num ambiente específico (como TouringMachine) ou a utilização em determinada atividade (como PRS), a arquitetura aqui proposta busca apresentar uma generalidade que lhe permita atuar em atividades ou ambientes diversos.
A proposta da nova arquitetura não teve, em nenhum momento, o objetivo de apresentar novas formas de implementar deliberação ou reatividade.
O objetivo sempre foi a elaboração de uma nova forma de integrar as duas abordagens.
Por isso, é importante salientar que esta forma de integrar deliberação e reatividade, implementada no Avaliador de Execução, pode ser utilizada perfeitamente com processos deliberativos ou módulos reativos implementados de forma diferente da proposta.
Mas para que a utilização da forma de integração seja possível, alguns detalhes importantes devem ser observados.
No que se refere ao Módulo Reativo, é importante que este possa receber a ação a ser executada para que sua atuação seja guiada por ela, e que seja possível monitorar com simplicidade, através de suas ativações internas, esta atuação.
As três arquiteturas reativas apresentadas no Capítulo 2 estão de acordo com esta necessidade.
A Subsumption Architecture é a arquitetura que inspirou a proposta original para a forma de implementar o módulo.
A utilização da arquitetura Pengi seria bastante semelhante, na medida em que a forma de ativação e atuação baseada em rotinas lembra os níveis de controle da Subsumption Architecture.
No caso de a Rede de Ativação, o monitoramento também seria simples, na medida em que as ações são geradas por módulos específicos.
A principal diferença é que no caso de a Rede de Ativação, a ação não chegaria ao módulo como um sinal dos sensores, mas através da energia de ativação dos objetivos.
Quanto a o processo deliberativo, é necessário apenas que o seu resultado seja um conjunto estruturado e ordenado de intenções, compostas por desejo e plano, e que seja possível ao avaliador disparar um processo de replanejamento.
A primeira necessidade é simples, bastando que se elimine de qualquer processo BDI a execução dos planos, interrompendo- após o planejamento.
A possibilidade de que o avaliador dispare o processo o de replanejamento também não deve apresentar dificuldade com qualquer forma que se escolha para implementar o processo deliberativo.
O planejador inicia um processo de planejamento ao receber um desejo que deve ser satisfeito, bastando, portanto, que o avaliador reenvie ao planejador o desejo da intenção que não pode ser realizada com sucesso.
Além disso, é preciso construir a Descrição das Ações.
Como este conjunto de informações é bastante dependente do problema, a definição dos níveis de sucesso, insucesso e prontidão deve ser feita por o implementador do agente.
Em o capítulo seguinte, será descrito um agente implementado utilizando a arquitetura proposta, e a Descrição das Ações deste agente é apresentada em detalhes.
Uma representação do Mundo dos Blocos que define um fato que é o objetivo em si, e um valor, que define a importância daquele desejo.
Existem dois tipos possíveis de desejos:
At, l),\&gt;. As crenças do agente também utilizam os predicados nada_ sobre e sobre.
A única diferença está no fato de que o predicado sobre é seguido de exatamente dois termos, indicando apenas a relação entre dois blocos quando um está colocado diretamente sobre o outro.
A existência de pilhas com mais de dois blocos pode ser deduzida a partir de estas crenças simples.
A atuação do agente começa com a construção de um modelo do mundo, através da transformação dos sinais recebidos dos sensores em representações simbólicas, que serão adicionadas ao conjunto de crenças originais do agente.
No caso de esta implementação, os sensores são simulados, sendo apenas leituras diretas na estrutura de dados que representa o ambiente (um vetor bidimensional).
As crenças não incluirão informações a respeito de a posição absoluta dos blocos (como a sua posição em relação as coordenadas horizontal e vertical), mas trarão informações a respeito de a posição relativa de cada bloco em relação a outros blocos.
Mais precisamente, as crenças trarão informações sobre qual bloco está sobre qual e quais blocos não têm nada sobre si.
Como forma de ilustrar a composição do conjunto de crenças do agente, podemos considerar um agente modelando um estado do mundo idêntico ao apresentado na Figura 5.1. Como a representação do mundo demanda um conjunto relativamente grande de crenças, as apresentadas abaixo são apenas uma pequena parte do conjunto gerado para modelar aquele estado:
Sobre (a, mesa).
Sobre (b, a).
Sobre (d, b).
Sobre (p, d).
Nada_ sobre (p).
Sobre (m, mesa).
Nada_ sobre (m).
Sobre (f, mesa).
Sobre (h, f).
Se o desejo que está em processo de planejamento não puder ser realizado por nenhum dos planos que compõe a biblioteca de planos, um novo plano deve ser construído.
Em a construção deste plano, além de o conjunto ordenado de ações do tipo mover (X, Y), devem ser colocados também o objetivo e as pré e pós-condições, de forma que, se o objetivo for atingido com sucesso, o plano possa ser colocado na biblioteca de planos para uso futuro.
Finalizado o planejamento, temos uma intenção pronta para execução.
O resultado de todo este processo que culminou com a geração de intenções é mostrado na tela da forma apresentada na Figura 5.2. A seguir, o Avaliador de Execução busca a primeira intenção da estrutura de intenções e seleciona a primeira ação de seu plano.
Em este momento, é necessário buscar na Descrição das Ações as informações necessárias para o monitoramento da execução.
Conforme já foi dito, os planos são compostos apenas por ações do tipo mover (X, Y), onde X indica o bloco a ser movido e Y um bloco sobre o qual X deve ser colocado (podendo indicar também a mesa).
Desta forma, a Descrição das Ações será composta apenas por a descrição dos níveis de sucesso, insucesso e final para a ação mover, e o Avaliador só utilizará estas informações para o monitoramento de toda a execução do agente.
O nível de sucesso da ação mover é o nível de comportamento que envia aos atuadores a ordem para largar o bloco X sobre o bloco Y, ativado quando os sensores indicam que a pinça está sobre Y e seu conteúdo é X;
O nível de prontidão é o nível ativado quando a pinça se coloca a uma altura indicada, sem nenhum bloco preso, e sem estar recebendo nenhuma ação para executar;
E os níveis de insucesso são três:
A) o nível ativado quando, havendo uma ação a ser executada, o sinal dos sensores indicando a posição do bloco X não é valido (indicando que o bloco X não está no ambiente);
B) o nível ativado quando, com o bloco X na pinça, o sinal dos sensores indicando a posição do bloco Y não é valido (indicando que o bloco Y não está no ambiente);
C) o nível ativado quando, no momento em que o agente se posiciona para colocar o bloco X sobre o bloco Y, os sinais dos sensores indicam que há outro bloco (um bloco Z qualquer) sobre Y, que faz a pinça subir uma unidade de altura mantendo o bloco X preso.
É importante salientar que o insucesso apontado por o item c) só ocorre no caso de o bloco Z ter sido colocado sobre Y após o planejamento.
Caso contrário, o plano deve trazer uma ação para colocar Z na mesa, desimpedindo Y. Em o momento em que a descrição dos níveis de sucesso, insucesso e prontidão foi lida, o agente envia a ação ao Módulo Reativo.
A partir de então, o Módulo Reativo passa a ativar seus níveis de comportamento de acordo com a ação que está sendo enviada e com os sinais dos sensores, e tais ativações são monitoradas por o avaliador.
Caso o nível de sucesso seja ativado, ou seja, o bloco X é colocado sobre Y, o avaliador interrompe o envio da ação, passando a esperar a ativação do nível de comportamento correspondente ao nível de prontidão para enviar a próxima ação do tipo mover.
Caso não ocorra a ativação do nível de sucesso, e sim de um nível de insucesso, o avaliador retira a intenção que estava sendo resolvida da estrutura de intenções e dispara um processo de replanejamento.
Se um novo plano puder ser construído (isto é, os blocos envolvidos continuam no ambiente), a intenção replanejada é colocada como a primeira a ser realizada na estrutura de intenções, de forma que a próxima ação enviada ao Módulo Reativo seja parte do plano para a sua solução.
Um problema na execução da ação mover (X, Y) primeiro caso não existe a necessidade de nenhuma informação sobre estados anteriores.
Basta que o Módulo Reativo perceba que o conteúdo da pinça é diferente do que deveria e, portanto, deve ser colocado na mesa.
Estando a pinça vazia, reinicia a busca do bloco X. Em o caso de haver algo sobre Y, isto só é percebido quando X já está na pinça.
O agente deveria colocar X sobre a mesa para liberar a pinça e partir para pegar o bloco que estivesse sobre Y. Isto implica em que o agente armazene internamente informações sobre o estado do mundo, o que fere os conceitos que norteiam as arquiteturas puramente reativas.
Isto é ilustrado na Figura 5.4, supondo a ação mover (X, Y).
Em o instante (a), o agente, estando com o bloco X na pinça e tendo se deslocado lateralmente até a posição de Y, começa a descer.
A o atingir Z, no instante (b), o sinal do sensor &quot;tocou «informa que não é possível descer mais, mas como o bloco logo abaixo não é Y, a pinça não é aberta e o agente sobe uma unidade de altura.
Tendo subido uma unidade, a situação do instante (c) é idêntica à do instante (a), e a pinça volta a descer, repetindo o instante (b).
A única forma do Módulo Reativo resolver sozinho este problema seria armazenar, quando de a ativação de nível ocorrida no instante (b), uma informação que lhe permita, no instante (c), perceber que um fato anterior torna este instante diferente do instante (a).
Como esta opção fere a pureza do Módulo Reativo, optou- por considerar o nível se ativado no instante (b) como um nível de insucesso.
Sua ativação provoca a interferência do avaliador, que interrompe o envio da ação e busca a solução do problema através de um replanejamento.
Desta forma, no instante (c) o Módulo Reativo já não tem mais nenhuma ação a executar, o que faz com que a pinça, ao invés de descer novamente e repetir o instante (b), comece a subir com o objetivo de levar X para outro lugar e ficar livre para uma nova ação.
A principal colaboração da arquitetura proposta neste trabalho é a sua forma de integrar deliberação e reatividade.
Ao invés de termos módulos independentes, processando de forma concorrente, cada um as suas próprias tarefas, temos um processo que inicia com a deliberação e culmina com a atuação do Módulo Reativo.
Esta forma de integração, por sua vez, baseia- numa visão diferente do que são os se objetivos do agente.
Arquiteturas híbridas em geral consideram certas alterações no ambiente como tarefas a serem tratadas por o Módulo Reativo, da mesma forma que considera os objetivos do agente como tarefas a serem tratadas por o módulo deliberativo.
Isto leva os módulos a interferirem na atuação um do outro, na medida em que a ativação é independente e cada um procura resolver as suas tarefas da melhor maneira.
Em a arquitetura aqui proposta, todos os componentes do agente estão envolvidos na realização dos objetivos do agente.
O processo deliberativo gera planos, enquanto o Módulo Reativo executa estes planos tratando das interferências do meio.
As alterações do ambiente são consideradas como dificuldades que o Módulo Reativo deve superar na realização da sua função, que é executar os planos deliberativos.
Esta integração foi possibilitada por a inclusão do Avaliador de Execução, um módulo que serve de mediador entre a construção dos planos e a sua execução.
As formas de construir o processo deliberativo e o Módulo Reativo não apresentam novidades, sendo baseadas em arquiteturas bastante conhecidas.
É o funcionamento do avaliador que propicia esta nova forma de integração.
A primeira característica importante é que a interferência entre o processamento deliberativo e o Módulo Reativo diminui, à medida em que ambos não estão atuando de forma concorrente e com objetivos diferentes, mas sim em etapas diferentes para a solução de um mesmo objetivo.
O Módulo Reativo interfere no processo deliberativo apenas quando não for capaz de executar as ações que constituem os planos e que lhe foram enviadas por o avaliador, solicitando um novo planejamento.
O envio da ação a ser executada na forma de mais um sinal de ativação para o Módulo Reativo permite que se implemente este módulo de forma que as alterações no meio sejam tratadas levando em conta a seqüência da ação.
A entrada da ação na forma de mais um sinal dos sensores possibilita que o agente trate um mesmo estado do ambiente de formas diferentes, dependendo da ação.
A ação torna- importante para a definição da ativação dos se níveis, e é a chave para que o Módulo Reativo, mesmo sem nenhum conhecimento específico dos objetivos do agente, atue direcionado a eles.
Além disso, o envio da ação como mais um sinal de sensor permite que o Módulo Reativo seja implementado de forma puramente reativa.
Isto significa que não é necessária qualquer alteração no conceito de a arquitetura reativa utilizada para a sua construção, dotando- a de conhecimento interno sobre o processo delibertaivo, para que o módulo atue em função de os resultados deste processo.
É importante que as ações que compõem os planos e são executadas por o Módulo Reativo sejam de alto nível.
Em primeiro lugar, isto facilita o planejamento.
Quanto mais alto for o nível das ações que o Módulo Reativo é capaz de executar, menor a necessidade de refinamento no planejamento (menor a necessidade da adoção de subplanos para a realização de objetivos parciais simples), e menor o número de possíveis alternativas no andamento da execução do plano que devem ser previstas no momento da sua construção.
Além disso, ações de alto nível reduzem o número de ações por plano, diminuindo a quantidade de envios de ação por parte de o avaliador e, por conseqüência, acelerando a execução dos planos.
Além disso, quanto mais baixo for o seu nível, maior será a quantidade de diferentes ações necessárias para compor os planos.
Um grande número de ações gera um conjunto de descrições de ações muito extenso, o que pode diminuir a eficiência do funcionamento do avaliador no que se refere ao monitoramento.
A execução das ações é monitorada com certa liberdade, uma vez que apenas um pequeno conjunto de ativações dos níveis é relevante para o avaliador.
O Módulo Reativo tem uma certa autonomia para decidir, em função de o estado do ambiente, qual a melhor forma de concluir a ação.
Isto não significa que o módulo tem total liberdade de atuação, uma vez que ele deve atuar para realizar a ação a ele enviada, mas sim que ele tem liberdade quanto a forma como a ação será executada.
Assim, para o Módulo Reativo não é importante a forma como os planos foram gerados, ou quais os objetivos que levaram à sua geração, importando apenas os resultados do processo deliberativo, que são as ações que guiarão sua atuação.
De a mesma forma, os resultados do Módulo Reativo representam para o processamento deliberativo o sucesso das ações planejadas ou, no caso de insucesso, a necessidade de replanejamento.
Não é importante o que ocorre entre o envio da ação e a percepção do sucesso ou do insucesso, ou seja, a forma como o Módulo Reativo atuou.
É importante salientar ainda que a verificação do sucesso ou do insucesso através da ativação dos níveis do Módulo Reativo é mais simples e rápida do que a verificação direta no ambiente ou através da atualização do modelo do mundo, embora possivelmente menos precisa.
A construção de planos de alto nível reduz o gargalo que o planejamento pode representar.
Diz que este gargalo ocorre porque mesmo as ações mais &quot;inconseqüentes «devem ser planejadas.
Em a arquitetura apresentada, as ações que compõe os planos são passos importantes para a realização dos objetivos.
As ações de tratamento do ambiente e algumas ações que atingem objetivos parciais são geradas de forma reativa.
Assim, &quot;ações inconseqüentes «são geradas independentemente de qualquer deliberação, reduzindo o gargalo.
Embora no estudo de caso o processamento interno do agente tenha sido implementado de forma seqüencial, cíclica, a arquitetura prevê a possibilidade de implementação em paralelo dos módulos.
A implementação em paralelo permitiria, por exemplo, que ao perceber a ativação de um nível de insucesso, o avaliador enviasse o desejo que não pode ser realizado para replanejamento imediatamente, ao mesmo tempo em que começaria a enviar para execução e a monitorar a próxima intenção.
A possibilidade de funcionamento em paralelo dos módulos permite que, em trabalhos futuros, o avaliador envie para execução partes de planos que ainda não tiveram seu processo de planejamento concluído.
Em primeiro lugar, isto permite que planos comecem a ser executados mais cedo.
Além disso, esta é uma forma de lidar com a possibilidade de falha na execução dos planos, evitando um excesso de replanejamento.
Isto ocorre porque quando uma ação não é realizada com sucesso, só os passos seguintes já planejados precisam ser abandonados, e não um plano completo, e o resto do plano pode ser construído levando em conta a falha.
Assim, ativado um nível de insucesso, busca- imediatamente novas se alternativas, e é economizado o processamento que teria sido gasto com uma parte de um plano que nunca seria utilizada.
