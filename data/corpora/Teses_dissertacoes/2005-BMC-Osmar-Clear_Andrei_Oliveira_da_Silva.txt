Bioinformática é uma área que necessita gerenciar uma grande quantidade de dados.
Um exemplo é o desenho racional de drogas assistido por computador, onde é necessário organizar inúmeras simulações de atracamento entre proteínas e ligantes.
Projetos relacionados, tais como The United Devices Cancer Research Project, The Smallpox Grid Project e FightAIDS@ home, utilizam grades computacionais para coletar resultados destas simulações distribuídas por vários computadores.
Estes projetos contam com soluções privadas desenvolvidas por empresas comerciais, que implementam a distribuição de tarefas e o tratamento dos resultados.
Devido a a necessidade de tratar inúmeros resultados organizados em formatos específicos, foi desenvolvido um framework dedicado a tratar resultados derivados da biologia molecular, mais especificamente do desenho racional de drogas assistido por computador.
Para validar a implementação, é proposta uma abordagem baseada em aplicações com código aberto, tais como a ferramenta XtremWeb para a distribuição de simulações efetuadas com o software AutoDock 3.0.
A Bioinformática é uma área multidisciplinar que envolve fórmulas e premissas de ciências como Estatística, Física, Química e Ciência da Computação para auxiliar pesquisas no campo da biologia molecular.
Os principais objetivos da Bioinformática são:
Coletar, armazenar e analisar dados derivados do seqüenciamento de genomas numa grande escala.
A quantidade de dados gerados neste campo é bastante significativa e, para a organização e geração de dados de forma rápida, é imprescindível o uso de ferramentas computacionais.
Isto se justifica tanto por o volume de dados gerados e manipulados quanto por a complexidade destes.
Por exemplo, recentemente foi publicado o genoma humano, que contém cerca de 30 mil genes (ou 3 bilhões de bases de DNA).
Se fôssemos imprimir a seqüência deste genoma seriam necessárias cerca de 200 mil páginas.
Luscombe Ressaltam a necessidade da elaboração de ferramentas computacionais que auxiliem na análise e manipulação destes dados.
De entre tais aplicativos pode- se citar programas de simulação de interação entre moléculas (molecular docking) e de dinâmica molecular (molecular dynamics).
Ferramentas de simulação de interação entre moléculas se mostram interessantes, pois são utilizadas no processo de desenvolvimento de medicamentos.
Porém, dois aspectos podem acelerar o processo de pesquisa utilizando simulações:
A distribuição destas por vários computadores e a análise dos resultados.
A montagem de um ambiente para distribuição destas simulações pode ser feita com algumas ferramentas disponíveis, tais como Models@ home, XtremWeb, Condor e Globus.
Por sua vez, a análise de resultados oriundos desta distribuição se preocupa em identificar diferentes formatos de arquivos, extrair informações relevantes e tratar seus conteúdos.
Atualmente, as pesquisas que tratam de analisar dados oriundos da biologia molecular geralmente estão preocupadas com o estudo de genomas, organização bancos de dados de genomas ou com a análise de dados já armazenados.
Existem projetos com foco na distribuição de simulações computacionais para o desenvolvimento de medicamentos.
Porém, as soluções de computação distribuída são implementadas por empresas especializadas e os aspectos envolvidos no tratamento de resultados não são divulgados.
Desta forma, este trabalho apresenta uma solução para tratar dados resultantes de simulações computacionais através de um framework.
Um framework se caracteriza por ser uma arquitetura que pode ser estendida para outras aplicações e interagir com outros programas.
Por exemplo, a partir de um framework pode- se tratar dados de diferentes softwares e estes podem estar interagindo com outras ferramentas.
Em este contexto, o tratamento de dados pode ser visto como uma pré-análise, por exemplo de arquivos resultantes de simulações.
Este tratamento se faz necessário devido a vários fatores, tais como o volume de dados num único arquivo, a complexidade das informações resultantes das simulações e a quantidade de amostras necessárias para um dado processo de pesquisa.
Logo, por a pré-análise destas informações pode- se organizar- las, facilitando o trabalho de especialistas da área.
Baseado no problema apresentado, foi projetada uma solução que visa tratar dados contidos em arquivos de forma genérica, com foco inicial na análise de resultados de simulações.
Foi utilizada, como estudo de caso, uma área da Bioinformática dedicada ao desenvolvimento de medicamentos, chamada desenho racional de drogas assistido por computador.
A base do desenho racional de drogas assistido por computador é a interação entre proteínas-ligantes que, por sua vez, pode ser avaliada por simulações computacionais.
Tais simulações são implementadas por alguns programas disponíveis e podem ter diferentes formatos de saída.
Portanto, um framework deve dar suporte à extensão para o tratamento de resultados de diferentes aplicações.
Além disso, estas simulações podem ser distribuídas para serem executadas em vários computadores com a finalidade de coletar um maior número de resultados num tempo reduzido.
Logo, se faz necessário que o framework seja capaz de interagir com outras aplicações e tratar os formatos utilizados por estas.
Esta dissertação apresenta uma solução para os desafios apresentados utilizando uma abordagem orientada a objetos.
Para tanto, foi necessário estudar a tecnologia de frameworks e formas de tornar uma arquitetura de software reusável através do uso de padrões de projeto.
Para desenvolver este trabalho foram estabelecidas algumas metas que influenciariam no resultado do trabalho.
Primeiramente o framework deve ser capaz de tratar vários tipos de arquivos, tais como resultados de simulações e arquivos compactados.
A solução deve ser capaz de interoperar com outros sistemas e em diferentes situações.
Para testar a interoperabilidade, o framework foi acoplado ao servidor de uma grade computacional, o qual distribui simulações por vários computadores e repassa os resultados destas para serem tratados por o framework desenvolvido.
Como a característica principal de um framework é a sua estensibilidade, foram buscados outros estudos de caso para poder avaliar esta característica na solução apresentada nesta dissertação.
Portanto, foi desenvolvido um exemplo de uso no tratamento de e-mails para impedir a propagação de vírus ou mensagens com consteúdo indevido, além de discutir a aplicabilidade da solução em outros cenários.
A dissertação presente está organizada da seguinte forma:
Biologia molecular;
Conclusão finaliza o trabalho apresentando as vantagens, desvantagens e considerações finais acerca de esta dissertação.
O desenvolvimento de frameworks orientados a objetos é uma questão de grande relevância tanto na indústria como na academia.
Estes sistemas semi-completos visam facilitar o processo de desenvolvimento de software baseados em seu reuso.
Por este motivo, a revisão bibliográfica desta área é de grande importância, a fim de fundamentar e justificar o emprego desta tecnologia no desenvolvimento deste trabalho.
As seguintes sub-seções tratam de:
Definir frameworks, apontar seus benefícios, classificações e seu processo de desenvolvimento.
Segundo Johnson e Foote, um framework é uma aplicação semi-completa e reusável que pode ser especializada para produzir uma aplicação especializada.
Baseados nas premissas básicas de engenharia de software, tais como o reuso, frameworks são criados para serem instanciados em diversas aplicações de forma personalizada.
A primeira referência à criação de frameworks foi realizada por Deutsch onde a principal característica ressaltada é o reuso.
Um framework consiste na modelagem de classes abstratas, ou seja, como uma implementação básica a ser especializada para um uso específico:
Interfaces e classes concretas assim como a colaboração entre estas.
Pree distingue um framework em duas partes:
Frozen spots e hot spots.
Frozen spots definem as funcionalidades básicas, partes imutáveis no framework e que aponta a finalidade deste.
Por sua vez, hot spots são as extensões que caracterizam o reuso da base do framework e personalizam o seu comportamento para uma aplicação específica.
O primeiro framework a ser utilizado foi o Model/ View/ Controller (MVC) que define a funcionalidade de interfaces gráficas para a linguagem Smalltalk-80.
A base deste modelo está em separar o controle da aplicação da interface com o usuário em três partes:·
Model: Define a funcionalidade da aplicação que deve ser independente da interface gráfica;·
View: Gerência a interface gráfica de acordo com o estado da Model;·
Controller: Interage com os outros componentes repassando as ações obtidas da View, tais como eventos de mouse ou teclado, para a Model e vice-versa.
Baseado neste modelo, tem- se a flexibilidade na forma de disponibilização das informações (View).
Por exemplo, uma mesma aplicação pode ter os dados de entrada por linha de comando ou por interfaces gráficas mais complexas.
Isto se deve à extensão de uma classe abstrata que define as funcionalidade básicas da View e como esta interage com a Controller.
Em este caso o frozen spot é a classe Controller, já que esta se mostra mais estática e define o funcionamento básico, e o hot spot é classe abstrata View, a qual pode ser estendida para personalizar a aplicação.
Logo, um framework só passa a ser um (sub) sistema após ter seu (s) hot spot (s) implementados.
Resumidamente, antes da sua extensão um framework não passa de uma definição do funcionamento básico de um (sub) sistema.
Com a crescente popularidade de linguagens orientadas a objetos, frameworks têm adquirido importância devido a a complexidade dos sistemas implementados neste paradigma ter aumentado.
Isto também se deve aos seguintes benefícios obtidos através do uso desta tecnologia:·
Modularidade: As interfaces que descrevem as funções de uma classe permitem que suas implementações herdem esta modularidade.
Esta característica otimiza o projeto e desenvolvimento do software devido a a abstração das funcionalidades de cada componente, o que facilita a sua compreensão e manutenção;·
Reusabilidade: Devido` frozen spots, este pode ser instanciado em diferentes situações com diferentes extensões de suas interfaces.
O reuso destes componentes impacta num aumento substancial na produtividade, qualidade, manutenabilidade, performance e interoperabilidade de um software;·
Extensibilidade: A possibilidade de estender suas interfaces permite ao programador personalizar um framework a uma situação;·
Inversão de controle:
O controle da execução da aplicação se concentra no framework, fazendo com que seja necessário implementar um mínimo de métodos para colocar em prática o produto final.
A base do framework é responsável por receber e redirecionar o tratamento dos eventos.
Por exemplo, para as extensões dos hot spots de forma específica para cada aplicação.
Fayad Enumeram algumas classificações para frameworks:
A o são produtos comerciais, sendo· Frameworks de infra-estrutura:
Geralmente n~ projetados para serem utilizados juntamente a um software.
Esta categoria simplifica o desenvolvimento de aplicações portáveis, tais como interfaces gráficas utilizando o modelo MVC;·
Frameworks de integração:
Geralmente utilizados para integrar aplicações distribuídas com uma interface conhecida.
Estes frameworks aumentam o reuso de uma aplicação sendo utilizado como middleware, assim como frameworks de Object Request Broker· Frameworks de aplicações:
São produtos finais comerciais, complexos e de alto custo tanto de desenvolvimento como compra.
Esta categoria inclui sistemas de grande porte personalizáveis.
Além de esta classificação, frameworks podem ser discernidos por as técnicas utilizadas para estender- los.
Logo, pode- se encontrar whitebox frameworks, blackbox frameworks e graybox frameworks.
Frameworks classificados como whitebox requerem um conhecimento prévio de sua funcionalidade por parte de o programador.
Esta classe de frameworks se baseia na reimplementação de métodos e classes básicas com implementação já disponível, o que os tornam mais complexos.
Blackbox frameworks se baseiam na composição de plug-ins que permitem uma maior facilidade na hora de estender o framework.
Estes frameworks costumam prover uma interface para guiar a implementação destes plug-ins.
Desta forma, blackbox frameworks se apresentam mais fáceis de serem estendidos, porém a implementação de interfaces genéricas que cobrem uma grande parte de casos de uso é uma tarefa complicada.
Uma solução intermediária seria a criação de graybox frameworks, que visam flexibilidade e estensibilidade suficientes, e é capaz de abstrair informações relevantes à implementação de extensões deste.
O processo de desenvolvimento de um framework inicia- se com a análise do domínio do problema e com a análise de soluções existentes, ou seja, o problema é analisado e são estudadas soluções existentes com o intuito de criar uma nova proposta ou adaptar uma já existente.
Após definir onde o framework será aplicado, são executadas as seguintes fases:·
Modelagem e implementação:
Provê as interfaces blackbox e whitebox, ou seja, aquelas que definem as funcionalidades básicas e pontos a serem estendidos, tais como frozen e hot spots.
Esta fase inclui a criação de diagramas UML (Unified Modeling Language) e a utilização de padrões de projeto.
Tendo a base de classes definida, pode- se partir para a implementação em alguma linguagem orientada a objetos.
Como um framework deve ser modelado para ser extensível, há técnicas que facilitam sua modelagem.
Algumas destas técnicas são apresentadas como padrões de projeto, onde são definidas situações e soluções para um projeto orientado a objetos.
Uma arquitetura de software se resume em subsistemas, componentes e a relação entre eles.
Segundo Jacobsen, esta arquitetura se divide em duas partes:
Abstrações arquiteturais e o uso destas.
Frameworks se encontram nas abstrações de uma arquitetura de software.
Logo, seu desenvolvimento pode ser auxiliado por diversos padrões, tais como os padrões de projeto.
Padrões de projeto definem propostas de soluções para o projeto de uma aplicação (Framework) orientada a objetos, sendo que esta pode ser composta de um ou mais padrões de projeto.
Basicamente, estes padrões auxiliam no projeto da arquitetura de uma aplicação possibilitando um maior reuso da mesma.
Gamma Apresentam uma série de mecanismos que ajudam a contornar problemas na fase de projeto e implementação de um framework.
Para os referidos autores, padrões de projeto possuem quatro elementos:·
Nome do padr~· Problema:
Situação onde o padrão se aplica;·
Solução: Descrição dos elementos que solucionarão o problema em questão;·
Conseqüências: Apontam os para os e contras no uso do padrão.
Para melhor catalogar- los, os padrões de projeto foram classificados por em três classes:
Padrões de criação, estruturais e comportamentais.
Padrões de criação definem como projetar objetos de modo que estes sejam instanciados de forma independente.
Estes padrões podem inclusive determinar o comportamento de um objeto.
Por exemplo, uma solução elegante para referenciar um objeto único num programa é utilizando o padrão Singleton.
O funcionamento deste padrão define que a instância de um objeto é retornada por um método estático e esta deve ser única.
Caso não haja uma instância, o objeto é criado internamente à classe.
Este caso pode ser aplicado à instanciação de um framework, onde a sua instância pode ser acessada de qualquer lugar de um programa por intermédio de um único método.
Padrões estruturais definem como criar estruturas mais complexas baseadas na composição de objetos e classes.
Estes padrões podem ser a base do desenvolvimento de frameworks, considerando a natureza da aplicação destes.
Um exemplo de padrão estrutural é o Composite, onde uma hierarquia de classes pode definir que objetos podem chamar outros de mesma natureza, criando um caráter recursivo à hierarquia de classes.
Os padrões comportamentais facilitam a comunicação entre objetos e a composição de eles a fim de prover a funcionalidade que um apenas não teria capacidade.
Um exemplo de padrão comportamental é o Observer, onde é definida a forma de comunicação entre dois objetos interdependentes.
Com isso, cada vez que um objeto sofre alguma alteração este notifica aqueles que dependem de ele, similarmente a uma interrupção.
Logo, padrões de projeto são ferramentas eficazes na construção de frameworks e, por isso, costumam ser relacionados.
O desenvolvimento de um framework necessita que a sua estrutura seja reusável, e a uma das formas de alcançar este objetivo é através do uso de padrões.
Considerando que um framework é destinado a ser estendido a outras aplicações, não basta apenas que este seja projetado e implementado de forma reusável, este deve ser devidamente documentado.
Butler e Dénommée apresentam a documentação necessária a um framework.
Além de desenvolvedores interessados em extender um framework, este pode ser utilizado por aqueles que fazem a manutenção do código e programadores interessados em integrar as funcionalidades com outros frameworks.
Por este motivo uma documentação adequada vem a diminuir a curva de aprendizado referente a o tempo de familiarização com uma nova tecnologia, no caso um framework.
Um framework pode ser documentado das seguintes formas:
Exemplos de uso são práticas comuns, porém podem ser de difícil compreensão para iniciantes.
Este tipo de documentação provê aplicações completas, sendo deficitárias ao que se refere à explicação dos hot spots, ou seja, pontos de um framework a serem estendidos;
Instruções: Uma descrição informal, podendo ser dotada de figuras e exemplos de código, se mostra uma forma de documentação mais completa do que a anterior.
Uma coleção de várias instruções pode ser compilada num volume, chamado Cookbook ou livro de receitas;
Contratos: Um contrato especifica como os elementos do framework se comunicam e suas obrigações.
Este tipo de documentação pode definir instruções num Cookbook demonstrando a arquitetura do framework e suas funcionalidades;
Padrões de projeto:
Padr~ Desta forma pode- se explicar o problema, como este foi resolvido e suas colaborações;
Contextualização: As primeiras instruções num Cookbook podem apresentar o contexto onde o framework se aplica.
Esta documentação possibilita ao usuário, no caso um desenvolvedor, ter uma noção de quais requisitos são compreendidos por o framework.
Logo, baseado neste contexto, tem- se uma noção do que é flexível ou estático na solução proposta;
Manual de referência:
A descrição de cada classe envolvida na arquitetura de um framework auxilia o desenvolvimento e extensão deste.
Assim como a especificação da Application Program Interface (API) da linguagem Java, um manual de referência aponta a função dos métodos e das atributos das classes que compreendem a aplicação;
Anotações sobre o projeto:
Esta documentação inclui um relato detalhado de informações tais como teoria, análise de situações, histórico, componentes e arquitetura;
Outras: A metodologia UML pode auxiliar na documentação de frameworks com diagramas de seqüência, casos de uso e diagramas de classes, por exemplo.
Outros tipos de diagramas podem auxiliar no desenvolvimento de um Cookbook, tais como máquinas de estado e fluxogramas.
Este capítulo apresentou os conceitos envolvidos no desenvolvimento de frameworks.
Primeiramente foi definido o termo, os benefícios destas soluções estensíveis assim como as suas classificações.
Em seguida foram descritos os aspectos envolvidos no desenvolvimento e documentação de frameworks.
Um framework pode ser visto como uma aplicação parcialmente completa que possibilita a extensão e reuso.
Entretanto, não há referência a um número mínimo de classes que o compõe, podendo definir pequenas aplicações, Com menos de dez classes, como um &quot;framelet», como apresentado por Pree e Koskimies.
O próximo capítulo documenta a implementação de um &quot;framelet «desenvolvido para o tratamento de dados envolvidos, a ser aplicado na Bioinformática.
Algumas aplicações costumam lidar com grandes quantidades de arquivos ou eventos.
Simulações computacionais são exemplos de aplicações que geram arquivos de saída em diversos formatos, o que faz necessário automatizar a análise destes resultados.
Por exemplo, algumas áreas da Bioinformática fazem uso de simulações para o desenvolvimento de drogas ou para predizer as estrutura de proteínas.
Os arquivos resultantes destas simulações costumam possuir uma grande quantidade de informações em diversos formatos.
A distribuição de simulações por vários computadores é uma prática adotada por alguns projetos para obter um número maior de resultados num menor tempo.
Um exemplo é o projeto The United Devices Cancer Research Project, que distribui simulações de interação entre proteínas e ligantes com a finalidade de encontrar a cura do câncer.
Em este caso, são recebidos a cada instante centenas de arquivos descrevendo o resultado das simulações e a análise destes é imprescindível para os pesquisadores interessados, no caso especialistas da area farmacêutica.
Este capítulo apresenta o framework desenvolvido para atender à análise de arquivos resultantes de simulações computacionais.
As seções a seguir apontam alguns trabalhos relacionados, a modelagem do framework e possíveis aplicações para a solução proposta.
Assim como os projetos relacionados ao desenvolvimento de drogas, outras aplicações também necessitam de tratamento de dados.
Larson Descrevem a simulação do enovelamento de proteínas de forma distribuída e aponta a necessidade de analisar de centenas a milhares de dados.
Porém, tais projetos não descrevem os métodos utilizados para a análise desta quantidade de informações, o que motiva a criação de um framework que desempenhe esta função.
A tecnologia de frameworks se mostra interessante por causa de seu caráter estensível, possibilitando o uso de uma solução em outras situações e aplicada à análise de outros tipos de arquivos resultante de simulações.
Quanto a o desenvolvimento de frameworks, um trabalho similar ao proposto nesta dissertação é descrito por Al-Shaer com foco no gerenciamento de aplicações distribuídas.
O autor aplica seu framework ao controle de eventos em sistemas distribuídos, o qual foi estendido por Fayad e Hu para ser utilizado como filtro de e-mails.
Comparativamente, o trabalho de Al-Shaer possui um foco bastante diferenciado do que é proposto nesta dissertação.
Porém, ambos frameworks podem ser utilizados em conjunto, por exemplo, no estudo de caso desenvolvido para tratamento de e-mails pode incluir a funcionalidade de filtro de arquivos por intermédio da proposta desta dissertação.
No caso de o filtro de e-mails, o framework obedece ações definidas por alguns parâmetros, por exemplo, pode- se definir endereços a serem ignorados ou palavras-chave.
O trabalho descrito nesta dissertação pode adicionar a funcionalidade de tratar arquivos anexados, como descrito na Seção 3.4.1.
Esta seção detalha o framework desenvolvido utilizando a metodologia UML, apresentadando as classes envolvidas, os pontos a serem estendidos na arquitetura e a modelagem dinâmica, ou seja, os diagramas de seqüência do framework.
Dado o problema de tratamento de simulações, foi criada a noção de tratadores (Handlers).
Um tratador é uma entidade capaz de fazer uma determinada análise e tomar decisões a partir de esta.
A implementação do framework parte da definição dos métodos básicos que um tratador deve ser capaz de desempenhar.
A interface HandlerInterface descreve as funcionalidades de um tratador, cuja implementação básica é provida por a classe abstrata AbstractHandler.
A Figura 3.1 apresenta esta estrutura com os seguintes métodos:
Por sua vez, a classe AbstractHandler implementa estes métodos, com exceção do método handle que deve ser especificado por as subclasses, já com o intuito de definir as funcionalidades básicas de um tratador de arquivos.
Esta classe provê os seguintes atributos:
AbstractHandler são os seguintes:
Arquivo como tratável por o seu nome, através do atributo fmMatcher;
Expressões regulares são notações para especificar e identificar strings.
Ou seja, um conjunto de caracteres define um padrão a ser aceito para uma dada entrada.
Para tornar a identificação dos arquivos mais flexível foi criada a interface FileMatcherInterface, implementada por a classe FilenameMatcher conforme ilustrado na Figura 3.2.
A interface define os métodos a serem implementados por a subclasse utilizando expressões regulares para identificar um nome de arquivo.
Após identificar se o arquivo é tratável por a classe FilenameMatcher, é ativado o tratamento deste de forma a ser determinada em cada subclasse.
Porém, um tratador pode precisar retornar o resultado de sua análise.
Por isso foi desenvolvida a classe HandleResult, descrita na Figura 3.3.
Basicamente, a classe HandleResult possui um conjunto de objetos e propriedades identificados durante o tratamento.
A classe também provê outras informações, tais como um identificador para o resultado, o nome do arquivo e do tratador que efetuou a análise.
O tratamento é subdividido em três tipos de tratadores, dois para guiar a implementação de analisadores de arquivos e um que serve como ponto de entrada do framework.
A Figura 3.4 apresenta estas classes.
O CompositeHandler é o ponto inicial dos tratadores de arquivo.
Ele é responsável por cadastrar os tratadores e redirecionar o tratamento a cada um de eles.
Assim como os outros tratadores, este faz uso do padrão de projeto Composite 2, sendo um tratador composto, ou seja, por definição este pode invocar os tratadores cadastrados em ele, redirecionando o tratamento de um arquivo para outro objeto.
Em esta classe, a função handle testa todos os tratadores cadastrados se estes tratam um dado arquivo.
Caso a resposta seja positiva, o CompositeHandler repassa a responsabilidade de analisar o arquivo a um outro tratador.
Devido a a sua importância, o CompositeHandler também implementa o padrão de projeto Singleton sendo possível acessar- lo por um único método (getInstance) para cadastrar outros tratadores ou iniciar um processo de tratamento.
As classes FileHandler e PkgHandler são responsáveis por definir a implementação de tratadores de arquivos, seguindo a idéia do padrão de projeto Strategy.
Portanto, estas classes abstratas apresentam a implementação básica do método handle e deixam alguns métodos auxiliares para serem implementados por as subclasses.
A classe FileHandler possui uma estrutura bastante simples.
O método handle apenas invoca um outro, chamado analyse, que é responsável por o tratamento e tomada de decisão.
O padrão Composite permite que os objetos sejam tratados como individuais ou composições de objetos, porém se distinção entre eles.
O padrão Singleton garante que a classe possua uma única instância, provendo um ponto de acesso global a esta.
O padrão Strategy permite a especialização de algoritmos em diferentes objetos que possuem a mesma estrutura.
Logo, esta classe pode ser estendida para o tratamento de qualquer tipo de arquivo, cujo conteúdo necessita ser analisado, tais como tratadores de arquivos gerados em simulações computacionais.
Porém, nem todos arquivos podem estar dispostos em formato textual.
Alguns programas costumam compactar os arquivos devido a o tamanho da resposta gerada.
Por exemplo, a ferramenta XtremWeb recebe os resultados de seus clientes num arquivo compactado.
Portanto, foi criada a abstração chamada (PkgHandler) para prover um modelo de tratamento de arquivos compactados.
A classe PkgHandler implementa o tratamento de arquivos compactados que possuam outros documentos que devem ser tratados.
Devido a a grande quantidade de algoritmos e formas de descompactar um arquivo, esta classe implementa o método handle e deixa outros a serem implementados.
A implementação do método handle nesta abstração classifica- a como uma classe composta de outras, ou seja, outros tratadores devem ser previamente cadastrados na mesma.
A o ser invocado, o método handle analisa o conteúdo do arquivo compactado, extrai arquivos que sejam tratáveis e chama os tratadores responsáveis por estes documentos.
No entanto, os métodos responsáveis por a identificação dos nomes de arquivos que se encontram compactados e a extração destes devem ser implementados por as subclasses.
Ou seja, cada extensão desta classe deve implementar uma estratégia ou algoritmo diferente para o tratamento de arquivos compactados.
Dada a modelagem do framework, é necessário apresentar quais partes deste são pontos de extensão e quais componentes são estáticos, ou seja, onde estão os frozen e hot spots da arquitetura proposta.
Devido a os pontos flexíveis da arquitetura estarem localizados tanto no interior dos tratadores como na extensão destes, pode- se considerar que foi desenvolvido um framework do tipo graybox.
Em relação a a estrutura básica do framework, este pode ser estendido por a sua interface de identificação de arquivos.
A classe FileMatcherInterface possibilita a identificação de padrões de nomes de arquivo ou, por exemplo, por padrões dentro destes.
Logo, é possível estender- la para identificar eventos ao invés de padrões de nomes de arquivos.
A Figura 3.5 demonstra como a interface FileMatcherInterface pode ser reutilizada.
A princípio esta abstração é utilizada apenas por a classe AbstractHandler.
Porém, podem ser criadas outras extensões para atender diferentes funções.
Por exemplo, um tratador de arquivos para e-mails (
EmailAttachmentHandler) necessitaria um identificador de arquivos por a sua estrutura (FieleStructureMatcher), uma vez que os nomes podem ser alterados para tentar burlar o sistema.
Seguindo a mesma idéia, um tratador de eventos (EventHandler) pode ter uma classe especializada em identificar- los (EventMatcher) de acordo com parâmetros proprietários da aplicação.
Assim, um identificador de arquivos pode ser especializado para cada extensão da classe AbstractHandler ou da interface HandlerInterface.
Tais classes também caracterizam pontos de extensão do framework, sendo possível mudar apenas a forma de tratamento ou até mesmo a estrutura dos tratadores.
Por exemplo, a estrutura interna de um tratador pode ser alterada, ou seja, tratadores de eventos podem diferir por a extensão da interface HandlerInterface e a redefinição dos métodos desta, assim como demonstrado na Figura 3.5 com a classe EventHandler.
Considerando o framework como blackbox, este pode ser utilizado somente estendendo a classe AbstractHandler e implementando seus métodos ou suas subclasses, como demonstrado na seção anterior com os tratadores FileHandler e PkgHandler.
Desta forma, é necessário implementar poucos métodos para criar novos tratadores de arquivos.
A modelagem dinâmica de uma aplicação visa demonstrar o funcionamento de uma arquitetura.
Logo, nesta seção são apresentados diagramas que permitem compreender o funcionamento do framework desenvolvido.
Primeiramente se faz necessário explicar como se dá a criação de tratadores e como estes são cadastrados.
A Figura 3.6 apresenta a instanciação dos componentes do framework.
O ponto de entrada da arquitetura é a classe CompositeHandler, cuja instância pode ser obtida por intermédio do método getInstance.
Em este método é retornada a instância corrente da classe, caso não haja uma é criado um novo objeto para que outros tratadores sejam cadastrados.
A instanciação dos demais tratadores cria um identificador de arquivos (FilenameMatcher) ativa o modo que imprime mensagens indicando o estado do tratador, como por exemplo, a ação que este está executando.
Alternativamente, podem ser passados outros tipos de objetos que possam auxiliar o tratamento de arquivos, por exemplo, parâmetros para a chamada de comandos do sistema operacional ou objetos de classes que implementem o acesso a bancos de dados.
Em este caso, tais parâmetros devem ser especificados para cada extensão de um tratador.
Porém, a instância da classe FilenameMatcher necessita ser alimentada com padrões, no caso de expressões regulares, para que sejam identificados os arquivos por o método addFile-namePattern.
Por exemplo, se um tratador é responsável por arquivos texto então deve ser adicionada uma expressão regular que permita identificar estes documentos.
Portanto, a chamada addFilenamePattern(&quot;+.
Txt&quot;) possibilita ao tratador aceitar qualquer arquivo com extensão.
Txt. Um passo opcional na preparação é o cadastro de tratadores para que sejam invocados.
No caso de tratadores de arquivos compactados (PkgHandler) é necessário cadastrar tratadores para identificar se existem arquivos a serem analisados dentro de um arquivo compactado.
Logo, várias extensões de tratadores podem ser cadastradas num PkgHandler.
Por fim, os principais tratadores são cadastrados no CompositeHandler, o qual vai redirecionar o tratamento de um arquivo para um dos objetos adicionados.
No caso de uma extensão do framework, devem ser instanciadas e preparadas as subclasses de PkgHandler e FileHandler desenvolvidas para a aplicação em questão.
Após a criação e preparação dos componentes da arquitetura, o framework está apto a tratar arquivos.
Em a Figura 3.7 é demonstrado um diagrama de seqüência do uso do framework.
Em este caso, para simplificar a representação, é apresentado como se apenas um PkgHandler fosse cadastrado no CompositeHandler e apenas um FileHandler tivesse sido adicionado ao PkgHandler.
Quem inicia o processo geralmente é uma aplicação que gera arquivos a serem analisados.
Esta aplicação recupera a instância de CompositeHandler e requisita o tratamento de um arquivo.
A o receber um nome de arquivo por parâmetro, a classe CompositeHandler testa todos os tratadores cadastrados durante sua preparação.
Para testar os tratadores, são invocados os métodos isHandleable de cada classe, os quais fazem uso de seus identificadores de arquivos (FilenameMatcher) para analisar o nome do arquivo de acordo com uma expressão regular dada na preparação do objeto.
No caso de a Figura 3.7, o PkgHandler identifica o arquivo como tratável.
Após esta identificação, os nomes dos arquivos são extraídos por o método getContent e os mesmos são testados por todos os tratadores cadastrados.
Caso um destes tratadores seja responsável por o tratamento de um arquivo, este é extraído por o PkgHandler que invoca o tratador responsável.
O FileHandler analisa o conteúdo do arquivo e armazena informações num HandleResult que é retornado para a aplicação ou a decisão é tomada por o próprio tratador.
Tais ações dependem da finalidade da aplicação.
A principal característica de um framework é seu caráter estensível, ou seja, este deve prover o reuso de sua estrutura para que possa ser utilizado por diferentes aplicações.
Logo, a solução apresentada neste capítulo pode ser reutilizada em outras situações.
A análise de arquivos pode ser interessante em diversas áreas, tais como a Bioinformática, CRM (Costumer Relationship Management) ou aplicações que necessitem gerenciar e-mails.
Em esta seção será apresentado um estudo de caso desenvolvido envolvendo o filtro de e-mails e são discutidas algumas outras alternativas de uso do framework desenvolvido.
Segundo Bhattacharyya, estima- se que e-mails com vírus causem gastos da ordem de 10 a 15 bilhões de dólares por ano no conserto de sistemas computacionais.
Além disso, problemas como a divulgação de conteúdo confidencial de empresas podem acarretar grandes prejuízos.
Um possível cenário para o framework de tratamento de arquivos é o filtro de e-mails indevidos.
Em esta aplicação o framework foi estendido para verificar o conteúdo dessas mensagens para evitar o envio de material confidencial de empresas, tais como códigos fonte de programas.
Com isso, foi desenvolvido um tratador de mensagens com o intuito de identificar palavras dentro de um documento texto, tais como &quot;public class «para programas escritos em Java e um a extensão de arquivos.
Porém, estes documentos podem se encontrar dentro de arquivos compactados, fazendo- se necessária a implementação de arquivos com a extensão zip.
Logo, foram modeladas algumas classes conforme demonstrado na Figura 3.8: ZipPkgHandler:
Estende a classe abstrata PkgHandler implementando o algoritmo de extração de arquivos compactados do tipo ziptarPkgHandler:
Estende a classe abstrata PkgHandler implementando o algoritmo de extração de arquivos compactados do tipo tar.
TxtFileHandler: Estende a classe abstrata FileHandler e identifica certos elementos numa mensagem e efetua uma dada ação, por exemplo, não entregar o e-mail indevido e registrar a ação com os dados do destinatário e fonte do e-mail.
ExeFileHandler: Estende a classe abstrata FileHandler e executa um antivírus para verificar se os arquivos anexados ao e-mail podem ser entregues.
Em o caso destes estarem infectados, pode- se excluir- los e armazenar esta informação num banco de dados, o que viria a indicar se um computador da rede local está com vírus.
A classe CompositeHandler é inicializada com os tratadores e parâmetros, e, quando acionada, procura por a classe que é responsável por a análise de um dado arquivo.
Esta classe é invocada por a classe
EmailScanner, a qual é utilizada antes do envio e recepção de e-mails.
Por exemplo, no caso de envio de um arquivo sourceszip, a classe
EmailScanner solicita o tratamento por a CompositeHandler que, por sua vez, repassa o tratamento para a classe ZipPkgHandler que se encarrega de identificar o conteúdo do arquivo, extraindo os nomes de arquivos identificados por o TxtFileHandler.
Após extraídos, os arquivos são analisados por os seus respectivos tratadores.
Por exemplo, TxtFileHandler para mensagens no formato texto ou ZipPkgHandler novamente no caso de haver outros arquivos compactados dentro de um zip.
No caso de o tratamento do documento ConfidentialCode.
Java é feita a chamada diretamente ao TxtFileHandler.
A inicialização do tratador de arquivos executáveis, ExeFileHandler, pode ser feita por a expressão regular que seleciona anexos com extensão.
Exe ou então todos os tipos de arquivos.
Desta forma este tratador é sempre invocado garantindo que os e-mails serão sempre verificados.
Este exemplo de aplicação do framework é semelhante ao apresentado por Fayad e Hu.
A diferença principal se baseia no foco em tratamento de eventos deste outro.
Porém, pode- se inserir o tratamento de arquivos ao tratamento de evento e vice-versa.
No entanto, a análise de arquivos anexados se mostra mais complicada que o tratamento de eventos.
Um complicador é a identificação de arquivos por sua extensão, onde um usuário pode renomear o arquivo para que este não passe por a análise efetuada por o framework.
Um outro problema relacionado é a manutenção do sistema, ou seja, a cada momento deverá ser desenvolvido um novo tratador para um novo formato de arquivo.
Uma possível extensão para a classe AbstractHandler seria a identificação de mensagens comerciais não solicitadas, ou seja spams.
Assim, pode- se prover um filtro de arquivos e conteúdo de e-mails de forma extensível.
Um outro exemplo de uso para o framework é na implementação de um servidor proxy com cache.
Por definição, um servidor proxy com cache é responsável por armazenar documentos requisitados por clientes numa rede de computadores.
Por exemplo, ao requisitar uma dada página ou arquivo na Internet, pode- se utilizar um servidor proxy para intermediar a comunicação.
Este fará o download de um arquivo e o enviará para quem o requisitou.
Quando um outro usuário acessar o mesmo documento, o servidor proxy enviará o arquivo armazenado em sua cache.
Este procedimento diminui o tráfego da rede e torna o download do arquivo mais rápido.
As extensões do framework descritas na seção anterior podem ser utilizadas para o tratamento de arquivos de um servidor proxy com cache.
Ou seja, antes de armazenar o arquivo e redirecionar- lo ao cliente, o framework irá analisar seu conteúdo para evitar que se propaguem vírus ou que o usuário esteja acessando páginas com conteúdo inadequado.
Portanto, é proporcionado um mecanismo de segurança da rede onde pode- se formar um perfil de uso dos recursos computacionais.
É possível, por exemplo, gerar estatísticas de acesso para cada usuário da rede e, com isso, determinar se este faz uso indevido dos recursos computacionais.
Porém, existem algumas desvantagens neste modelo.
A principal é a perda de performance.
A o analisar arquivos muito grandes, o framework pode gerar um overhead considerável na comunicação e algumas políticas devem ser adotadas, por exemplo, os usuários teriam livre acesso à rede e o tratamento de arquivos pode ser apenas para determinar perfis de uso.
Logo, é gerado um outro problema relacionado à privacidade dos usuários que são monitorados.
Esta tática pode ser utilizada para fins de avaliação da produtividade de funcionários, o que cabe a empresa determinar se é interessante manter esta privacidade ou não.
Este comando identifica a natureza do arquivo por o seu formato interno.
Este capítulo apresentou a modelagem de um framework para tratar arquivos e alguns exemplos de uso da solução proposta.
De entre os trabalhos relacionados descritos nesta seção foi encontrado um framework semelhante que visa controlar eventos em sistemas distribuídos.
Outras pesquisas semelhantes podem ser encontradas em trabalhos relacionados à distribuição de simulações computacionais, porém não é divulgada a solução de tratamento de arquivos.
Após este levantamento de trabalhos relacionados, foi apresentada a documentação do framework com a modelagem estática e dinâmica, assim como seus pontos de extensão.
Baseado na apresentação da estrutura e funcionamento do framework, foram discutidas aplicações que necessitam do tratamento de arquivos.
O próximo capítulo descreve a aplicação do framework desenvolvido para tratar simulações na Bioinformática Estrutural, com um estudo de caso no desenho racional de drogas.
Como mencionado na introdução deste trabalho, a Bioinformática é um campo de pesquisa com grande potencial para servir como estudo de caso para o framework de tratamento de dados.
Esta área demanda grandes quantidades de dados e diversos formatos de saída de simulações computacionais.
Alguns exemplos onde este trabalho pode ser aplicado na Bioinformática são:
Simulações por dinâmica molecular e simulações da interação entre proteínas e ligantes.
Simulações por dinâmica molecular têm por objetivo analisar o comportamento de um sistema molecular, por exemplo para predizer a estrutura de uma proteína.
Tendo por base a estrutura tridimensional de uma molécula, pode- se determinar a função desta.
Este conhecimento é de grande utilidade, pois vem a auxiliar na descoberta de medicamentos pois, com base na função de uma proteína, pode- se encontrar uma pequena molécula que estimule ou iniba esta função.
Esta interação entre proteínas e pequenas moléculas se chama docking molecular.
Portanto, ambas as linhas de pesquisa enumeradas necessitam simulações computacionais, tanto para analisar o comportamento de uma molécula como para avaliar sua interação com outra menor.
As ferramentas computacionais que simulam estes biossistemas costumam gerar diferentes tipos de saídas e, muitas vezes, é necessário analisar algumas informações destes arquivos resultantes.
Em o Desenho Racional de Drogas Assistido por Computador (Computer Assisted Drug Design) é necessário testar várias combinações de interações entre ligantes (pequenas moléculas) e receptores (proteínas alvo) para se obter um medicamento.
Logo, esta situação foi identificada como um bom estudo de caso para o framework desenvolvido, pois há a necessidade de tratar resultados em grande escala que, por sua vez, podem ser resultantes de softwares que utilizam diferentes formatos.
Para realizar este estudo de caso foi utilizado o software AutoDock 3.0, para simular a interação entre proteínas e ligantes, e foi adaptada a plataforma XtremWeb para distribuir as simulações e tratar seus resultados com o framework desenvolvido.
As próximas subseções dissertam sobre a pesquisa envolvida neste estudo de caso.
A pesquisa para o desenvolvimento de novas drogas tem uma história relativamente recente.
Os primeiros trabalhos na área bioquímica datam do final do século XIX, e no início do século XX.
Com o desenvolvimento da química e da biologia, a investigação de novas alternativas para o tratamento de grande parte das doenças passou a estar baseado em fundamentos científicos.
Devido a o avanço da biologia molecular e o advento das técnicas de simulação por computador, o planejamento de medicamentos passou a ser feito de forma mais lógica, o que é chamado de Desenho Racional de Drogas.
O processo do Desenho Racional de Drogas se inicia, geralmente, por o isolamento de um alvo específico, por exemplo uma proteína.
A estrutura da molécula alvo é determinada por cristalografia por difração de raios-X ou ressonância magnética nuclear.
Conhecendo- se a estrutura 3D de uma proteína, uma análise computacional pode apontar prováveis regiões de ligação.
Com isso é possível determinar um conjunto de candidatos (compostos líderes) que possam ligar- se a essa região da proteína alvo (segundo passo da Figura 3).
Após esta triagem os compostos são sintetizados e testados experimentalmente.
Com base nos testes é gerado o medicamento ou é reavaliada a estrutura do receptor e do ligante, reiniciando o ciclo.
O problema com este modelo é que a determinação dos melhores ligantes feita experimentalmente é custosa, pois a busca é aleatória e a produção de compostos necessita um alto investimento.
Outro fator que acentua a inviabilidade do modelo é a possibilidade de repetir o ciclo inúmeras vezes até a obtenção de um produto ideal, o que acarreta em tempo desperdiçado no processo.
Para que o valor de produção do medicamento não seja tão elevado, são utilizadas técnicas de simulação por computador.
Existem softwares que simulam a interação entre proteínas e ligantes, tais como o AutoDock, diminuindo o tempo gasto com a busca de bons ligantes e disponibilizando resultados mais precisos.
Conforme Lengauer e Rarey, o docking molecular constitui a base do desenho racional de drogas assistido por computador.
Isto se deve ao fato de que estas interações entre moléculas são fundamentais para alguns processos biológicos, tais como a transcrição de genes e funções fisiológicas.
O docking molecular pode ser aplicado a macromoléculas, entre proteínas ou proteína´ DNA (Desoxy-Ribo Nucleic Acids ou Acido Desoxiribonucelico em português), ou então a pequenas moléculas (ligantes) e moléculas maiores (receptores).
As interações ligantereceptor são processos de grande importância no desenvolvimento de um fármaco, considerando que várias proteínas regulam funções biológicas por intermédio destas ligações.
Para avaliar o docking entre um ligante e um receptor são utilizadas funções que avaliam a quantidade de energia despendida nesta interação.
Tais funções levam em conta algumas variáveis tais como a polaridade da superfície de cada molécula e as suas formas geométricas.
À direita pode- se observar uma molécula ligante (NADH em verde) se liga a um sítio da molécula receptor (a enzima InhA da Mycobacterium tuberculosis em vermelho).
Portanto, não basta um ligante ter a geometria necessária para se ligar a um local do receptor se as energias não são compatíveis.
Ou seja, deve- se levar em consideração os locais de ligação do receptor (binding sites ou pockets) e as energias destes, conforme ilustrado na Figura 4.2.
Considerando o bloco maior, Receptor, e o bloco menor, Ligante, como moléculas de tamanho diferenciado, pode- se observar que há o processo de translação e rotação para tentar atracar as moléculas.
Porém, estas somente se ligarão em locais onde possam se encaixar devidamente e onde as suas energias de interação sejam compatíveis.
No caso de a reentrância localizada na parte inferior há uma energia propícia, no entanto o Ligante está impedido por um bloqueio físico de interagir com o Receptor naquele local.
Por outro lado, no lado direito o encaixe (geometria) é propício, mas as energias se repelem.
Já no lado esquerdo, as moléculas podem se encaixar e as energias são favoráveis para que a ligação ou atracamento ocorra.
O processo apresentado em três dimensões na Figura 4.2 pode ser simulado por alguns softwares, tais como o AutoDock 3.0, LigandFit e DOCK.
Com base no cenário apresentado envolvendo o Desenho Racional de Drogas Assistido por Computador, foi montado um estudo de caso para o framework de tratamento de dados neste contexto.
A aplicação do framework avalia o conteúdo de arquivos oriundos de simulações de interações entre proteínas e ligantes.
Porém, para acelerar este processo essas simulações são distribuídas para vários computadores.
Portanto, o desenvolvimento deste estudo de caso constitui em três partes:
O desenvolvimento de uma extensão do framework para tratar um ou mais arquivos resultantes de uma simulação, o estudo e integração do framework com uma ferramenta que distribua estas tarefas e o com armazenamento das informações coletadas numa base de dados.
Atualmente existem vários projetos relacionados ao Desenho Racional de Drogas Assistido por Computador.
Os mais populares possuem uma grande quantidade de recursos a seu favor e contam com empresas especializadas dando suporte a suas infra-estruturas de software.
The United Devices Cancer Research Project é uma iniciativa da Universidade de Oxford que procura agentes para o combate ao câncer.
O projeto faz uso de uma grade computacional montada por a empresa United Devices Inc. E o software de simulação LigandFit fornecido por a empresa Accelrys.
De acordo com as estatísticas do projeto, seu banco de dados possui cerca de 3,5 milhões de possibilidades de interação entre proteínas e ligantes, 935 mil computadores caseiros ociosos e 556 mil participantes.
O projeto também é subsidiado por o National Foundation for Cancer Research e a Intel.
Outro projeto de grande relevância com o mesmo escopo é o The Smallpox Grid Project, custeado por a IBM, que visa descobrir ligantes que reajam contra o vírus da varíola.
Este projeto utiliza a mesma infra-estrutura de software do projeto de combate ao câncer (Global Metaprocessor da United Devices e o LigandFit da Accelrys), porém com bancos de dados DB2 e servidores IBM.
The Scripps Research Institute também possui um trabalho relacionado, neste caso com o intuito de encontrar a cura da AIDS.
O FightAIDS@ home utiliza o software AutoDock 3.0 com uma grade computacional montada por a empresa Entropia Inc..
Atualmente o projeto conta com 60 mil computadores a seu favor.
Estes projetos fazem parte de convênios entre várias empresas e possuem um número significativo de colaboradores para desenvolver fármacos para doenças que têm afetado uma grande quantidade de pessoas.
Este fato acentua o sigilo sobre os dados e protocolos utilizados na montagem da grade computacional.
Seguindo na mesma linha de grades computacionais aplicadas ao desenvolvimento de fármacos, porém com maior foco na computação distribuída, o Virtual Laboratory, desenvolvido por Buyya, é uma aplicação onde o cliente requisita a execução de uma tarefa a um servidor que aloca recursos para executar- la.
Em este caso a tarefa é avaliar a interação entre proteínas e ligantes com o software DOCK.
O Virtual Laboratory possui uma infra-estrutura implementada com a plataforma NimrodG e uma busca avançada em bancos de dados, porém não demonstra a solução adotada para analisar os resultados.
A solução apresentada por Buyya Se mostra uma alternativa bastante completa, porém de difícil adoção considerando o grande número de componentes a serem desenvolvidos.
Foster Definem as grades computacionais como recursos coordenados compartilhando e resolvendo problemas em organizações virtuais dinâmicas e multi-institucionais.
A organização virtual (virtual organization ou VO) constitui a base de uma grade computacional, sendo esta um conjunto de participantes compartilhando recursos para cumprir uma tarefa.
Os recursos participantes de uma organização virtual compreendem desde um computador ou software, até instrumentos científicos, tais como telescópios, conectados por redes de grande abrangência.
Estas organizações virtuais podem ter diferentes papéis numa grade computacional:
Podem prover serviços, coletar dados ou publicar resultados, dependendo de sua natureza e da aplicação proposta.
Porém, geralmente costuma- se associar grades computacionais com aplicações Peer-to-Peer (P2P ou Ponto-a-Ponto).
Foster e Iamnitchi apontam semelhanças e diferenças entre as duas definições.
A intersecção das duas tendências está na distribuição da computação e recursos compartilhados.
Por outro lado, as grades possuem aplicações mais complexas e fazem uso de uma variedade maior de recursos, enquanto os sistemas P2P utilizariam aplicações mais simples e um número maior de recursos.
Segundos os autores, de entre alguns exemplos de aplicações P2P estão os compartilhadores de arquivos (Gnutella e Edonkey) e programas de High--Throughput Computing1 (SETI@ home e Folding@ home).
Baker, por sua vez, consideram aplicações similares ao SETI@ home como grades computacionais e as classificam de acordo com os tipos de serviços que elas proporcionam.
Porém, outros termos também são aplicados às grades computacionais.
Foster e Iamnitchi se referem a programas como SETI como Internet Computing e Germain Se denominam a plataforma XtremWeb como Global ou Meta Computing.
Conforme Lodygensky, Global ou Meta Computing podem ser generalizados como grades computacionais, porém esta última categoria é uma subdivisão da primeira, juntamente com P2P.
Segundo o autor, as grades computacionais são um conjunto de organizações virtuais que compartilham recursos de acordo com alguma política, com isso se tem mais controle dos componentes da grade.
Por outro lado, P2P possui recursos mais voláteis e gerenciados de forma descentralizada.
No caso de o projeto Virtual Laboratory é utilizado um modelo de grade computacional sob demanda (On- demand Computing), onde um broker é responsável por alocar e distribuir recursos.
Em este caso é utilizada a ferramenta Nimrod-G, que é uma extensão da plataforma Nimrod desenvolvida para interoperar com outra ferramenta chamada Globus.
Globus é uma das ferramentas mais populares para a criação de grades computacionais, provendo um ambiente seguro para acesso a recursos remotos.
Esta ferramenta possui uma série de componentes que implementam comunicação, segurança e alocação de recursos, além de o suporte a outras linguagens, tais como o MPI (Message Passing Interface) o que permite a utilização em máquinas agregadas (clusters).
Uma outra possibilidade é o uso de outras plataformas, tais como Java Commodity Grid Kit que implementa uma camada que abstrai as chamadas da API do Globus em Java.
Outra ferramenta disponível é o Condor.
Este projeto oferece um sistema de distribuição de tarefas bastante completo que implementa características complexas como ponto de verificação (checkpointing), além de prover a possibilidade de interação com outros sistemas, tais como Globus e XtremWeb.
Models@ home é uma ferramenta baseada num screensaver que possibilita a distribuição de tarefas simples em computadores ociosos.
O código fonte é simples, porém não implementa características importantes como segurança, transmissão de arquivos e acesso a banco de dados.
Outra alternativa na construção de grades computacionais é XtremWeb que possibilita a montagem de uma plataforma genérica para distribuição de tarefas.
O XtremWeb possibilita a execução de qualquer tipo de aplicação e o controle de tarefas por um sistema web.
MyGrid é outra plataforma que provê uma infra-estrutura para criação de uma grade computacional.
Esta ferramenta foi desenvolvida utilizando RMI (Remote Method Invocation) da linguagem Java e alguns scripts 2 para prover acesso aos recursos da grade computacional.
Um projeto relacionado ao MyGrid é OurGrid, o qual implementa a possibilidade de compartilhar recursos de grades computacionais, por exemplo, criadas com MyGrid.
Através do uso destas ferramentas, pode- se acelerar vários processos de pesquisa como, por exemplo, o processo de desenho de medicamentos.
Em este caso é necessário distribuir simulações computacionais, tais como ferramentas de simulação de interação proteína-ligante.
Para avaliar o atracamento entre um receptor e um ligante, e, por conseguinte, estimar aquela configuração que gera o melhor resultado, existem programas que simulam as diferentes possibilidades de ligação.
Estes aplicativos testam o encaixe no sítio de ligação do receptor e avaliam a qualidade do acoplamento (scoring).
De acordo com o scoring, dado na forma de intensidade da energia de interação, é possível determinar se a molécula utilizada é um bom ligante para uma dada proteína.
Atualmente pode- se encontrar uma série de aplicativos disponíveis para este tipo de simulação computacional.
O software adotado para este estudo de caso foi o AutoDock 3.0, o qual é composto de um conjunto de programas:
Ario configurar as torções de um ligante, ou seja, define que AutoTors:
Possibilita ao usu´ partes da molécula podem sofrer rotações.
Por intermédio desta ferramenta é possível aumentar o número de possibilidades de ligações a um sítio, apenas definindo diferentes torções para o ligante;
AutoGrid: Mapeia a estrutura do receptor e suas energias de interação através de grades tridimensionais, onde será testada a interação com o ligante;
AutoDock: Calcula a interação entre o ligante, configurado no programa AutoTors, e o receptor, mapeado por a ferramenta AutoGrid.
Em esta etapa, a busca por regiões de ligação pode ser feita por dois métodos:
Simulated Annealing e Genetic Algorithm.
Logo, para executar uma simulação de docking molecular é necessário inicialmente preparar o arquivo de descrição do ligante com suas conformações (por o software AutoTors).
Os passos seguintes, ou seja a execução dos programas AutoGrid e AutoDock, podem ser executados sem intervenção de um usuário.
Após a sua execução, a ferramenta AutoDock gera um arquivo de extensão.
Dlg, que obedece o padrão «NomeLigante.
NomeReceptor. Dlg», com o resultado da simulação.
Este arquivo possui os seguintes elementos:
Cabeçalho com informações sobre programa e dados referente a a simulação, tais como informações do computador onde foi executada, arquivos de entrada e parâmetros utilizados;
Descrição do ligante, descrevendo os átomos que o compõem e as torções configuradas;
Cálculos executados na simulação, fórmulas e expressões utilizadas;
Parâmetros do método utilizado (Simulated Annealing ou Genetic Algorithm);
Energia e localização de cada átomo envolvido na simulação nos n passos executados;
Também tabelas com os resultados dos passos executados, onde se encontra a menor energia despendida na simulação do atracamanto ligante-receptor.
Portanto, pode- se gerar um conjunto de resultados por a execução de simulações com diversas configurações diferentes de ligantes.
Porém, é de grande valia para especialistas da area de desenho de drogas que estes resultados passassem por uma an´ álise preliminar.
Alguns parâmetros podem chamar a atenção para uma análise mais detalhada de uma simulação e, por a utilização de técnicas computacionais, é possível disponibilizar as informações mais relevantes dos arquivos de saída destas simulações num banco de dados, por exemplo.
Além disso, a distribuição destas tarefas vem a acelerar o processo de descoberta de medicamentos, considerando que existem passos que podem ser executados independentes do usuário.
Por exemplo, o pesquisador prepara o ligante para que a simulação seja agendada e executada numa grade computacional.
A adoção da plataforma XtremWeb se dá por a sua simplicidade e eficiência.
Os principais fatores levados em consideração na utilização desta plataforma para este estudo de caso foi seu código fonte modular, a facilidade de instalação, o armazenamento de estatísticas num banco de dados, transferência de arquivos, a possibilidade de uso na Internet, a implementação de mecanismos de tolerância a falhas e segurança.
Germain Definem a ferramenta XtremWeb como um framework genérico de Global Computing, ou seja, uma plataforma que possibilita compartilhar uso de recursos (ciclos de processador, espaço em disco) para resolver problemas de computação em larga escala.
Segundo os autores, a ferramenta conta com colaboradores que colocam à disposição seus computadores para execução de tarefas determinadas por um servidor, ou seja, são utilizados ciclos de processador de computadores ociosos para processar uma tarefa através da web.
O modelo do XtremWeb possui três componentes básicos, conforme a Figura 4.3: Em chamado de coordenador, este possui a política de Servidor (Dispatcher).
Trabalhador (Worker):
Cliente que executa os trabalhos definidos por o servidor.
Quando o computador estiver ocioso, este componente buscará tarefas a serem executadas e iniciará sua atividade, ao completar o trabalho esta retorna o resultado ao servidor;
Cliente (Client):
Cadastra serviços no servidor para serem executados por o trabalhador, ou seja, é o componente que possibilita ao usuário a submeter um trabalho a ser distribuído.
O protocolo utilizado entre estes componente é feito por chamadas de métodos por RMI, conforme ilustrado na Figura 4.4, que possui as seguintes mensagens:*
HostRegister: A o detectar o computador ocioso o trabalhador se autentica no servidor e recebe a lista de servidores ativos, caso haja apenas um dispatcher este retorna seu próprio endereço;*
WorkRequest: Baseado nas informa¸ trabalhador, o servidor envia tarefa a ser executada ao trabalhador.
Esta é definida com uma lista de parâmetros, o código executável da aplicação e a descrição do trabalho;*
WorkAlive: Durante a execuçonfirmando sua atividade.
Caso esta comunicação não seja feita periodicamente, após um tempo de espera (timeout) o servidor assume que o trabalho foi interrompido e envia a tarefa a um outro trabalhador;
Toda a comunicação entre as partes é feita mediante sockets seguros, ou SSL (Secure Socket Layer).
Primeiramente é feito um teste com a chave pública do coordenador, provida na instalação do software cliente ou trabalhador.
Esta certificação previne ataques de participantes maliciosos, uma vez que é necessária a certificação do coordenador para acessar- lo, além de evitar que seja feita a conexão a um servidor errado.
Este passo é seguido da autenticação por usuário e senha, onde é verificado se o participante está registrado no sistema.
Caso esta etapa seja concluída com sucesso a execução da tarefa é feita.
Germain Descrevem o funcionamento do trabalhador em três processos:*
Controla: Processo criado quando o computador se torna disponível, ou seja, ocioso.
Este componente é responsável por iniciar outros dois processos:
Monitora e Computa;*
Monitora: Processo que gerência a atividade do usuário, caso seja detectado alguma atividade de mouse ou teclado este processo cancela todos os outros processos;
A execução das aplicações utiliza o mecanismo de sand boxing para proteger o trabalhador, restringindo o ambiente de execução no computador do participante, personalizando o consumo de memória e operações envolvendo arquivos de sistema.
Por parte de o servidor é criado um processo para atender cada trabalhador, possuindo mecanismos de tolerância a falhas e balanceamento de carga.
A ferramenta oferece a possibilidade de oferecer vários servidores para atender aos trabalhadores.
Desta forma, ao conectar- se a um servidor, e se este estiver sobrecarregado, outro pode ser utilizado conforme a lista de servidores fornecida no primeiro passo do protocolo de comunicação descrito na Figura 4.4.
Fedak Descrevem a implementação do coordenador em módulos:*
Conjunto de aplicações:
As aplicações são armazenadas com binários pré-compilados (executáveis) para diferentes plataformas, definindo o nome e provendo como estas tratam os parâmetros e que resultados são esperados;*
Conjunto de tarefas:
As tarefas submetidas por os clientes possuem um identificador único e são descritas por os parâmetros de entrada (suportando vários arquivos), e argumentos de entrada;*
Mçomputadores as completaram, quem as submeteu e horário de início e conclusão destas;*
Interface web:
Provê uma interface ao banco de dados para cadastro e consulta de tarefas.
O mecanismo de agendamento de tarefas do servidor se dá por a política de FIFO (First In First Out).
A o receber uma mensagem workRequest, o servidor envia a última tarefa de sua lista ao trabalhador, caso esta tarefa seja interrompida, o que é sinalizado por o envio periódico de um sinal WorkAlive, o trabalho é agendado para outro participante.
As tarefas são executadas em ordem de chegada, ou seja, as primeiras a serem cadastradas são executadas antes.
A escalabilidade é garantida por a possibilidade de se instanciar um conjunto de servidores.
Logo, pedidos negados de conexão por sobrecarga no servidor são feitos a outro servidor, de acordo com a lista obtida no mecanismo de HostRegister.
Isso também possibilita o balanceamento de carga, onde pode- se dedicar alguns servidores apenas para coletar resultados a fim de não sobrecarregar o sistema.
O coordenador utiliza um banco de dados para armazenar contas de usuários e tarefas.
Atualmente a ferramenta conta com banco de dados MySQL acessado por o coordenador via JDBC.
Além disso a ferramenta possui uma série de aplicativos, tais como uma página web para submeter tarefas, consultar resultados e uma aplicação que possibilita a instalação do trabalhador numa rede local.
Para o desenvolvimento deste estudo de caso foi necessário construir uma arquitetura para distribuição e tratamento de simulações de interações proteínas-ligantes.
Logo, o framework desenvolvido teve que ser estendido para suportar os tipos de arquivos resultantes das simulações, e integrado a uma ferramenta de grade computacional.
Portanto, este estudo de caso se divide em duas partes:
A montagem de uma grade computacional, para a execução das simulações, e o tratamento dos resultados.
Devido a o número de requisitos necessários para o desenvolvimento de uma grade computacional, foi adotada uma ferramenta já existente, a qual foi adaptada para que passasse a tratar os resultados de simulações por extensões do framework proposto neste trabalho.
A plataforma XtremWeb, assim como as demais infra-estruturas de grades computacionais, não implementam mecanismos para o tratamento de resultados de simulações.
Logo, a utilização do framework desenvolvido neste caso se mostra interessante por aliar uma nova funcionalidade a estas ferramentas.
Esta integração de aplicativos resulta numa arquitetura que utiliza a plataforma XtremWeb para distribuir simulações computacionais, executadas com AutoDock 3.0, e uma extensão do framework proposto neste trabalho para tratar saídas recebidas por o servidor XtremWeb.
Esta arquitetura, demonstrada na Figura 4.5, implementa a busca de prováveis ligantes para reagir a uma dada proteína de forma similar aos projetos relacionados, porém totalmente baseada em código aberto.
Para distribuir uma simulação de docking molecular são necessários alguns pré-requisitos.
Primeiramente, os arquivos de descrição das moléculas envolvidas (receptor e ligante) são cadastrados como tarefas a serem distribuídas por o servidor XtremWeb, juntamente com um parâmetro indicando o algoritmo a ser usado na simulação (Genetic Algorithm ou Simulated Annealing).
Logo, os trabalhadores XtremWeb devem possuir o software AutoDock 3.0 instalado.
Após a execução da tarefa, o trabalhador envia ao servidor o resultado que é tratado por a extensão do framework desenvolvido.
Devido a a necessidade de executar os aplicativos que compõem o pacote AutoDock 3.0, foi desenvolvido um script que ativa estes programas.
Este script foi cadastrado como uma aplicação no servidor XtremWeb.
Porém, antes da execução de uma simulação é necessário preparar os arquivos das moléculas, onde é necessário conhecimento específico da área de bioquímica.
Além de o estudo sobre a estrutura de moléculas, deve- se analisar os parâmetros dos arquivos gerados por a simulação e os formatos utilizados por a plataforma XtremWeb.
Desta forma é possível determinar que plug-ins devem ser implementados para compor o tratamento de dados.
Conforme apresentado na Figura 4.6, para este estudo de caso foram desenvolvidas duas extensões do framework de tratamento de dados:
ZIPPkgHandler, que estende PkgHandler, e DLGFileHandler, que é uma subclasse de FileHandler.
O desenvolvimento da classe ZIPPkgHandler se justifica por o fato de que durante a simulação por o software AutoDock 3.0 são gerados vários arquivos de saída, que são compactados num arquivo de extensão zip por o trabalhador XtremWeb e enviados ao servidor.
Com o tratamento de dados implementado no servidor, o framework analisa o conteúdo deste arquivo compactado por intermédio da classe ZIPPkgHandler.
XtremWeb, juntamente com as extensões implementadas.
Com isso, foi necessário desenvolver a classe DLGFileHandler para identificar um arquivo com o padrão NomeLigante.
NomeReceptor. Dlg que possui o resultado da simulação por a ferramenta AutoDock 3.0.
Esta classe identifica elementos no arquivo tais como o nome das moléculas envolvidas (receptor e ligante), o método utilizado (Genetic Algorithm ou Simulated Annealing) e o melhor scoring da simulação.
Tendo estes resultados coletados do arquivo, a classe DLGFileHandler armazena as informações da simulação num banco de dados.
Com estas classes implementadas, foi necessário identificar as classes da ferramenta XtremWeb que deveriam ser modificadas para implementar o tratamento de dados.
Logo, foi identificada a classe Dispatcher, que é responsável por inicializar os componentes do servidor XtremWeb, a classe TCPHandlerThread, que trata do armazenamento dos resultados enviados por os trabalhadores.
Portanto, estas classes foram alteradas para inserir chamadas ao framework desenvolvido.
Primeiramente foi adaptada a classe Dispatcher para que esta ative os componentes do framework e suas extensões.
A Figura 4.7 demonstra a inicialização do framework por a ferramenta XtremWeb.
Desta forma, a classe Dispatcher instacia os tratadores ZIPPkgHandler e DLGFileHandler, atribui a eles expressões regulares para identificar arquivos com extensão zip e dlg respectivamente, adiciona DLGFileHandler ao ZIPPkgHandler e este último ao CompositeHandler.
Como o CompositeHandler foi implementado como um Singleton, este pode ser acessado estaticamente de qualquer classe.
Logo, finalizando esta fase de preparação do framework, a classe TCPHandlerThread foi adaptada para chamar o CompositeHandler a cada novo arquivo recebido por o servidor.
A Figura 4.8 apresenta o diagrama de seqüência do tratamento de dados efetuado por o servidor XtremWeb integrado ao framework desenvolvido.
Para simplificar a explicação do fluxo de chamadas neste diagrama de seqüência, não é utilizado o retorno de parâmetros por a classe HandleResult e as ações são tomadas por intermédio do tratador DLGFileHandler.
O processo de tratamento inicia após o recebimento do arquivo por a classe TCPHandlerThread, a qual aponta para a instância do CompositeHandler e requisita o tratamento de um arquivo com extensão zip.
Em esta etapa o ZIPPkgHandler passa a tratar o arquivo, testando cada nome dos arquivos compactados nos tratadores cadastrados em ele.
Considerando a inclusão do DLGFileHandler no ZIPPkgHandler durante a etapa de preparação do framework, ao identificar um arquivo com extensão.
Dlg como tratável por o DLGFileHandler a classe ZIPPkgHandler extrai o arquivo e repassa o tratamento deste para DLGFileHandler.
Desta forma, o conteúdo do arquivo é analisado e as informações mais relevantes deste são extraídas e armazenadas num banco de dados.
Cabe salientar que a plataforma XtremWeb sem o tratamento de dados apenas armazena os resultados num arquivo compactado sem analisar o seu conteúdo.
A integração do framework desenvolvido nesta plataforma automatiza o processo de análise das simulações e facilita a pesquisa de especialistas da Bioinformática.
O resultado deste estudo de caso pode ser observado na Tabela 4.1.
A primeira coluna descreve o nome do arquivo recebido, que possui o nome da aplicação e a identificação da tarefa.
A coluna Scoring possui o resultado da interação entre o ligante e o receptor, ou seja, a quantidade de energia despendida no atracamento das moléculas.
A terceira coluna possui o algoritmo utilizado por o AutoDock para a simulação, seguido das colunas que descrevem o nome do receptor e ligante envolvidos no processo.
Um fator a ser considerado na geração destes resultados é o desempenho da aplicação.
A Figura 4.9 demonstra a quantidade de memória utilizada no tratamento de dados.
Em este gráfico pode ser analisada a performance da classe TCPHandlerThread e o quanto esta ocupa de memória durante a chamada dos tratadores inclusos no framework.
O eixo x aponta para a chamada de cada tratador em função de o tempo e o eixo y denota a quantidade de memória utilizada.
Em este caso, apenas um tratamento ultrapassou 1 Megabyte de memória, onde o ZIPPkgHandler teve que extrair mais de um documento do arquivo compactado.
Porém, ao analisar este gráfico deve- se levar em conta que o framework foi desenvolvido na linguagem de programação Java e, por ser uma linguagem interpretada, esta possui uma memória extra ocupada por a sua Java Virtual Machine (JVM) 4, a qual está inserida nas medidas apresentadas.
Acerca de estas medidas é interessante ressaltar que os arquivos compactados utilizados possuem cerca de 448 Kilobytes cada um.
Conforme o gráfico apresentado na Figura 4.10, ao tratar um arquivo o framework leva em média 8 segundos.
Em esta medição também foi apresentado um pico de 17 segundos decorrente do tratamento de um arquivo com dois resultados de simulações, conforme também demonstrado na Figura 4.9.
Porém este valor também inclui a escrita em arquivo que possibilitou a geração dos gráficos.
O eixo x deste gráfico apresenta as consecutivas chamadas ao framework e o eixo y apresenta o tempo levado para finalizar o tratamento em segundos.
Devido a necessidade de fazer um teste de carga no framework, este foi observado fora de a ferramenta XtremWeb.
Logo, num primeiro instante foi analisada a quantidade memória utilizada por o tratamento dos mesmos arquivos compactados gerados por os trabalhadores XtremWeb, conforme apresentado no gráfico da Figura 4.11.
Em este gráfico são apresentadas no eixo x as chamadas ao framework e no eixo y a quantidade de memória utilizada em Kilobytes.
Portanto, pode- se observar na Figura 4.11 que a utilização de memória por o framework ocupa em média 300 Kilobytes de memória incluindo a JVM para o tratamento de um único arquivo compactado.
No entanto, considerando que um servidor pode vir a receber uma grande quantidade de resultados a cada instante, foi desenvolvido um teste com o intuito de medir o crescimento do consumo de memória com o aumento do número de processos concorrentes requisitando o tratamento de arquivos.
Para desenvolver este teste, foi utilizado um diretório com aproximadamente de 150 arquivos para serem tratados por o framework.
O gráfico apresentado na Figura 4.12 descreve o comportamento do framework ao ser utilizado concorrentemente.
O eixo x do gráfico demonstra o número de processos invocando o tratamento de um arquivo e o eixo y aponta a memória em Kilobytes utilizada durante esta avaliação.
Em este teste pode- se observar que a quantidade de memória utilizada aumenta lentamente em função ao número de processos.
Em o instante em que haviam cerca de 60 processos tratando arquivos a memória consumida é de 400 Kilobytes, e no instante em que cerca de 140 processos acessavam o framework a memória consumida atingiu cerca de 425 Kilobytes.
Ou seja, mesmo com o dobro de processos a quantidade de memória utilizada aumentou apenas 25 Kilobytes.
Este capítulo apresentou um estudo de caso numa das etapas do Desenho Racional de Drogas Assistido por Computador, que é uma das áreas da Bioinformática.
Para desenvolver um fármaco é necessário avaliar a interação (docking) entre macromoléculas (receptores) e moléculas menores (ligantes), o que pode ser feito por softwares de simulação.
Porém, este processo pode ser acelerado ao utilizar grades computacionais para distribuir estas simulações.
Portanto, o framework de tratamento de dados foi utilizado para analisar arquivos resultantes de simulações distribuídas por vários computadores.
A montagem do ambiente de distribuição de tarefas foi feito com a plataforma XtremWeb e o software de simulação de interação receptor-ligante foi o AutoDock 3.0.
O framework foi estendido para tratar arquivos compactados, uma vez que os resultados são recebidos por o servidor XtremWeb desta forma, e arquivos resultantes das simulações.
O servidor XtremWeb foi modificado para implementar o tratamento de resultados por intermédio de chamadas ao framework.
Para avaliar o desempenho do estudo de caso foram efetuados alguns testes no framework, tanto na sua extensão para tratar arquivos resultantes de simulações por o software AutoDock quanto a sua integração com a plataforma XtremWeb.
Os testes asseguraram a viabilidade da solução, considerando o pouco consumo de memória e o tempo de resposta para o tratamento de arquivos.
Uma outra possibilidade de extensão do framework seria por o tratamento de resultados de outras simulações, por exemplo arquivos de saída de um outro software de docking molecular.
Com isso seria possível analisar a interação receptor-ligante por o ponto de vista de métodos computacionais implementados por diferentes ferramentas de simulação.
A principal vantagem deste estudo de caso é o nível de automatização gerado no processo do desenvolvimento de drogas.
A distribuição de simulações aumenta o número de amostras, porém a organização dos resultados coletados facilita a pesquisa dos especialistas da área.
Este trabalho apresentou um framework para o tratamento de dados, tais como resultados de simulações computacionais.
A vantagem da utilização de um framework é que sua modelagem possibilita o reuso para ser especializado para um outro propósito, ou seja, a mesma arquitetura utilizada para um objetivo pode ser aplicada a outro propósito com poucas adesões.
A solução proposta foi utilizada para contribuir com as pesquisas na área da Bioinformática e em seus processos, onde há a necessidade de tratar grandes quantidades de dados.
Estas informações são, geralmente, oriundas de simulações computacionais distribuídas por vários computadores (Grades computacionais).
Com isso, o framework desenvolvido visa dar suporte ao tratamento de dados em diversos formatos, tanto de resultados de simulações como protocolos utilizados por a distribuição destas.
Um exemplo de distribuição de simulações foi implementado utilizando a ferramenta XtremWeb, para distribuir simulações do atracamento receptor-ligante com o software AutoDock 3.0.
A plataforma XtremWeb é responsável por distribuir tarefas em computadores ociosos e receber os resultados destas por um arquivo compactado, que contém os arquivos gerados por a simulação da interação receptor-ligante.
Portanto, pode- se observar pelo menos dois tipos de arquivos a serem tratados:
O arquivo com os resultados das tarefas compactados e os arquivos resultantes das simulações.
Isto cria a necessidade de estender do framework para tratar ambos os casos.
A interação ligante-receptor constitui na base do Desenho Racional de Drogas e a distribuição de simulações se resume numa das etapa no desenvolvimento de um fármaco.
Logo, a arquitetura desenvolvida para distribuição e pré-análise dos resultados coletados vem a acelerar o processo de geração de um medicamento, o que é um dos propósitos da Bioinformática.
Para desenvolver este estudo de caso foi modificado o módulo servidor da plataforma XtremWeb para tratar resultados recebidos, adicionando uma funcionalidade à ferramenta.
Portanto, caso seja desenvolvida uma outra aplicação para ser distribuída por o XtremWeb, basta desenvolver uma nova extensão de tratadores de arquivos para que a ferramenta passe a analisar os resultados, por exemplo, de simulações em Dinâmica Molecular.
Porém, a solução desenvolvida pode ser estendida para outras aplicações fora de a Bioin-formática, como o filtro de arquivos indevidos trocados por e-mail.
Em este caso, extensões do framework desenvolvido podem formar uma aplicação para empresas que necessitem proteger seu ambiente de vírus e conteúdos indesejáveis, tais como spams.
Apesar de o comportamento satisfatório no tratamento de resultados de simulações, o framework possui alguns pontos fracos quando analisado por alguns aspectos.
Um exemplo é a manutenabilidade deste em aplicações que possuem um crescente número de tipos de arquivos a serem tratados.
Apesar de a possibilidade de possuir um tratador padrão para arquivos desconhecidos, o desenvolvimento de um filtro de anexos em e-mails pode ser custoso, considerando que a cada novo formato de arquivo deve- se desenvolver uma nova extensão para o framework.
Desta forma, deveria ser necessário implementar atualizações para o tratamento, o que se mostra trabalhoso uma vez que os tratadores de arquivos possuem um caráter personalizado.
Portanto, o framework não possui potencial para ser utilizado por usuários finais, e sim para ser estendido para aplicações específicas, o que não exclui a possibilidade de desenvolver um filtro de e-mails num servidor especializado.
No entanto, estas aplicações que demandam uma grande quantidade de tratadores de arquivos podem se tornar lentas devido a a busca seqüencial por tratadores de arquivos.
Em este caso, pode- se elaborar políticas de ordenação de tratadores por a sua freqüência de uso.
Por exemplo, os tratadores mais utilizados podem ser testados antes dos demais.
Porém, aplicações com poucos tratadores não precisam se preocupar com esta limitação.
O estudo de caso desenvolvido no Desenho Racional de Drogas possui apenas dois tratadores especializados:
Um para extrair os resultados recebidos da plataforma XtremWeb e outro que analisa arquivos de saída de simulações executadas com AutoDock 3.0.
Em este exemplo o ponto fraco está na análise dos resultados das simulações.
O método aplicado busca por padrões dentro de o arquivo e armazena estas informações num banco de dados, onde não são tratados problemas com arquivos corrompidos e a busca por as informações pode falhar caso um dos elementos do arquivo tenha mudado sua identificação.
Portanto, o uso de processamento de linguagem natural pode ser um método eficiente para identificar os elementos do arquivo resultante da simulação.
Uma possibilidade de trabalho futuro pode ser vista na melhoria da proposta atacando as limitações apresentadas na seção anterior, porém outros aspectos também se mostram interessantes.
Por exemplo, a utilização do framework em outras áreas ou até mesmo em outras aplicações dentro de a Bioinformática podem se caracterizar estudos de caso adicionais.
O uso do filtro de e-mails para aplicações de CRM pode gerar dados para produzir perfis de usuários.
Além disso, simulações de Dinâmica Molecular podem ser tratadas e passar a prover dados para serem utilizados no Desenho Racional de Drogas.
Com isso, pode- se criar uma arquitetura para o desenvolvimento de fármacos construindo um ambiente com os processos de simulação automatizados.
Porém, o framework desenvolvido se mostra apenas o início de um trabalho maior envolvendo mais processos do desenvolvimento de fármacos.
A arquitetura desenvolvida possibilita a extensão deste trabalho para ser utilizado na Internet, de forma similar a projetos como FightAIDS@ home ou The Smallpox Grid Project.
No entanto, para isto seria necessário modificar a forma de contabilização de tarefas por parte de a ferramenta XtremWeb para que esta atue com grupos de usuários.
Desta forma, a elaboração de estatísticas de processamento tornará a aplicação mais atraente para que os usuários aceitem compartilhar seus computadores.
Luscombe Salientam a necessidade de ferramentas computacionais para o auxiliar pesquisas na Biologia Estrutural, e este trabalho explorou esta oportunidade apresentando contribuições na Ciência da Computação.
Desta forma, o estudo de caso apresentado neste trabalho pode servir como o início de uma pesquisa mais abrangente, aproximando a Ciência da Computação à outras áreas.
Desta forma, a motivação da pesquisa é impulsionada por a aplicação direta desta agregando facilidades e funcionalidades para outras áreas, não apenas na Bioinformática mas também em outras investigações.
