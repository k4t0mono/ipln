Os recentes avanços da Computação de Alto Desempenho abrem um largo espectro de possibilidades para as pesquisas na área.
Arquiteturas paralelas e distribuídas modernas apresentam cada vez mais capacidade de processamento em busca de um maior poder computacional.
Ao mesmo tempo, o ganho de desempenho obtido com as plataformas é seguido por um aumento do consumo de energia.
Em este cenário, pesquisas sobre eficiência energética em ambientes de alto desempenho têm surgido como uma forma de encontrar as causas e propor soluções para o consumo excessivo de energia.
Atualmente, uma das mais representativas plataformas de alto desempenho é a grade computacional, que é usada em muitos projetos científicos e acadêmicos em todo mundo.
Em este trabalho, propomos o uso de algoritmos de escalonamento de tarefas energeticamente eficientes para a gestão do consumo de energia em grades computacionais sem causar perdas significativas de desempenho.
A solução é baseada em:
Gestão eficiente de recursos ociosos;
Uso inteligente de recursos ativos;
Desenvolvimento de um mecanismo para estimar com precisão a energia consumida por uma determinada plataforma;
Proposta de novos algoritmos de escalonamento energeticamente eficientes para grades computacionais.
A abordagem criada foi avaliada utilizando o ambiente de simulação SimGrid.
Comparamos nossos algoritmos com cinco algoritmos de escalonamento tradicionais para grades computacionais, que não consideram questões de energia, e um algoritmo recentemente proposto na literatura que lida com questões de consumo de energia.
Os resultados mostram, em alguns cenários, uma redução no consumo de energia de 221,03%, combinada com uma perda de desempenho de 34,60%, com o uso de um dos algoritmos desenvolvidos neste trabalho.
Este exemplo confirma a nossa hipótese de que é possível reduzir significativamente o consumo de energia numa grade computacional sem comprometer de forma proporcional o desempenho.
Palavras-chave: Computação de Alto Desempenho, algoritmos de escalonamento, eficiência energética, simulação.
A evolução rápida de tecnologias computacionais traz uma série de oportunidades e possibilidades de pesquisa em Computação de Alto Desempenho (do inglês, High Performance Computing ­ HPC).
Entretanto, em alguns casos, à medida que os computadores adquirem maior capacidade de processamento eles precisam de mais energia para operar.
Isto preocupa por o impacto negativo que o aumento no consumo de energia tem trazido ao meio ambiente, por o custo financeiro para manter- los em operação e por a necessidade de reduzir o consumo de energia.
O aquecimento global, as alterações climáticas, o esgotamento das reservas de energia e o custo com energia, são algumas das principais preocupações que inquietam os pesquisadores atualmente.
De este modo, empresas de Tecnologia da Informação (Ti) enfrentam o desafio de oferecer maior poder computacional, atendendo às necessidades de expansão das empresas, sem que ocorram perdas significativas com gastos em energia e refrigeração.
As situações citadas conduzem pesquisadores, fabricantes e fornecedores de Ti a investirem em iniciativas de Computação Verde, do inglês, Green Computing, com o intuito de projetar soluções eficientes em termos de eficiência energética e desempenho.
Eficiência energética, em HPC, tornou- se uma questão importante nos últimos anos.
Assim, ambientes HPC tornaram- se um cenário fértil para o desenvolvimento de soluções para o problema da eficiência energética.
Um exemplo de ambiente de alto desempenho amplamente utilizado é o de grade computacional, que permite o compartilhamento de recursos de hardware e de software de forma transparente.
Em função de essa transparência, os usuários não devem estar cientes da escalabilidade, heterogeneidade e localização geográfica dos recursos disponíveis na grade.
Além disso, as grades computacionais possibilitam a alocação de uma enorme quantidade de recursos para a execução de aplicações paralelas a um custo menor do que se fossem utilizados supercomputadores.
Recentemente, alguns trabalhos têm sido desenvolvidos para propor soluções que resolvam o problema da eficiência energética em ambientes HPC (ver Capítulo 3).
A maioria das abordagens propostas para reduzir o consumo de energia, baseia- se em:
Ou desligar recursos ociosos, ou técnicas específicas de escalonamento de tarefas ou ainda alteração da frequência de operação da unidade de processamento.
Este trabalho apresenta uma abordagem para melhorar a eficiência energética em grades computacionais, através do uso de algoritmos de escalonamento energeticamente eficientes com gestão inteligente de recursos ociosos.
Nosso objetivo principal é reduzir o consumo de energia na execução de tarefas, sem reduzir de forma significativa o desempenho da aplicação.
As principais contribuições deste trabalho podem ser resumidas como segue:
Desenvolvimento de um modelo genérico de consumo de energia para grades computacionais;
Desenvolvimento de algoritmos de escalonamento energeticamente eficientes, que sejam capazes de trabalhar com a gestão das máquinas ativas e controle de ociosidade;
Avaliação do comportamento de algoritmos de escalonamento para grades computacionais em relação a o consumo de energia e desempenho.
Para avaliar a abordagem proposta por este trabalho, simulou- se um ambiente de grade usando o framework SimGrid (ver Seção 2.3) em conjunto com a biblioteca LIBTS (Library Tasks Scheduling) (ver Seção 2.4).
Optou- se por simulação, em virtude de a dificuldade de utilizar- se um ambiente real de grade, que possui um custo elevado, configuração complexa e dificuldade de repetição de determinados testes.
Quanto a o tipo de aplicações submetidas à grade, consideramos o tipo mais utilizado em ambientes de grade, as aplicações bag-of-- tasks (aplicações em as quais as tarefas são independentes, sem comunicação entre si).
Essas aplicações são consideradas adequadas, uma vez que em tais ambientes o custo da comunicação é bastante significativo, devido a o fato dos recursos serem interligados por grandes redes de computadores que possuem uma latência de comunicação alta.
Motivação e Objetivos O excesso de consumo de energia é um problema em ambientes de grande porte, como é o caso das grades computacionais.
Assim, focar apenas no desenvolvimento de algoritmos de escalonamento direcionados para melhorias de desempenho, não é mais suficiente.
Por essa razão, propor estratégias de escalonamento de tarefas para reduzir o consumo de energia em grades computacionais motiva este trabalho.
Uma vez que o uso de um bom algoritmo de escalonamento pode evitar, por exemplo:
Que máquinas fiquem ociosas desnecessariamente e/ ou com cargas desbalanceadas e que tarefas sejam enviadas para máquinas inadequadas, diminuindo assim os gastos desnecessários com energia.
O objetivo principal deste trabalho é contribuir para as iniciativas de Green Computing no que diz respeito à redução do consumo de energia na execução de aplicações em ambientes de grade computacional.
Através do desenvolvimento de algoritmos de escalonamento de tarefas energeticamente eficientes que não ocasionem perdas significativas de desempenho.
A presente Dissertação possui ainda os seguintes objetivos estratégicos:
Domínio das técnicas de escalonamento de tarefas para grades computacionais;
Domínio da ferramenta de simulação SimGrid;
Conhecimento das técnicas atualmente utilizadas na redução de consumo de energia em ambientes de HPC;
Conhecimento sobre os cenários de testes necessários para validar algoritmos de escalonamento.
Os objetivos específicos por sua vez, incluem:
Desenvolvimento do módulo de cálculo de consumo de energia na execução de aplicações;
Desenvolvimento de algoritmos de escalonamento energeticamente eficientes estáticos e dinâmicos;
Modificações nos algoritmos específicos para grades:
Workqueue (WQ), Suferrage, XSufferage e Dynamic Fastest Processor to Largest Task First (DFPLTF) para que passem a operar voltados à eficiência energética e não apenas desempenho;
Avaliação do desempenho e da eficiência energética dos algoritmos de escalonamento citados no item anterior, bem como dos desenvolvidos neste trabalho.
Estrutura do Documento A estrutura deste documento está organizada como segue.
Em o Capítulo 2, apresenta- se uma contextualização sobre:
O ambiente de grade computacional, o tema escalonamento de tarefas e os algoritmos mais conhecidos na área, a ferramenta de simulação SimGrid e a biblioteca LIBTS.
Em seguida, o Capítulo 3 apresenta os trabalhos relacionados aos temas economia de energia e escalonamento de tarefas em ambientes HPC.
O Capítulo 4 detalha a implementação do módulo de cálculo de consumo de energia e dos algoritmos de escalonamentos voltados à eficiência energética desenvolvidos neste trabalho.
Em o Capítulo 5, apresentam- se os resultados obtidos e a respectiva discussão dos mesmos.
Por fim, o Capítulo 6 encerra esta Dissertação, com as conclusões e direções para trabalhos futuros.
O objetivo deste capítulo é explicar o ambiente de grade computacional para o qual os algoritmos de escalonamento energeticamente eficientes desenvolvidos por este trabalho são direcionados.
Também são apresentados alguns algoritmos de escalonamento tradicionais e alguns específicos para grades computacionais.
Como é utilizada simulação para construir um ambiente de grade computacional, por a impossibilidade de trabalhar com um ambiente real por ser demorado e custoso, será explicado o funcionamento do robusto ambiente de simulação SimGrid.
Por fim, é apresentada a Library Tasks Scheduling (LIBTS), pois apesar de o SimGrid ter sido criado para trabalhar com algoritmos de escalonamento em aplicações científicas paralelas, ele não possui nenhum algoritmo implementado internamente.
Em este cenário, foi desenvolvida a biblioteca LIBTS que implementa diversos algoritmos de escalonamento para o SimGrid.
Grades Computacionais Grade computacional, de acordo com, é uma infraestrutura composta por hardware e software que permite o compartilhamento de recursos, tais como:
Dados, capacidade de processamento e armazenamento, sendo que esses recursos podem estar espalhados geograficamente.
Além disso, as grades podem ser compostas por uma grande variedade de recursos, como:
Estações de trabalho, supercomputadores, clusters, instrumentos científicos, de entre outros.
Segundo, o objetivo principal das grades é possibilitar a alocação de uma enorme quantidade de recursos para a execução de aplicações paralelas a um custo menor do que se fossem utilizados supercomputadores.
De acordo com, as grades computacionais podem ser classificadas em função de sua funcionalidade em:
Grades de processamento:
São utilizadas para executar aplicações que precisam de uma grande capacidade computacional, voltadas a resolver problemas que não poderiam ser resolvidos por um único recurso;
Grades de dados:
São utilizadas para gerenciar o armazenamento e acesso a grandes quantidades de dados;
Grades de serviços:
Provê uma grande quantidade de serviços, tais como:
Softwares e recursos computacionais.
Como construir uma grade que possua essas três funcionalidades é muito difícil e custoso, na maioria das vezes opta- se por construir uma grade computacional com a funcionalidade mais apropriada para a necessidade apresentada.
A seguir, são introduzidas as características de uma grade computacional segundo Heterogeneidade dos recursos:
Essa característica dificulta o escalonamento de tarefas em grades, pois os recursos podem ter velocidade de processadores diferente, interconexão diferente, velocidade de memória diferente, velocidade e tamanho de disco diferente, de entre outros.
Diferenças que podem fazer com que algumas aplicações não sejam apropriadas para determinados recursos;
Compartilhamento de recursos:
Como numa grade pode ocorrer variações na carga e na disponibilidade das máquinas, pode ocorrer sobrecarga em alguns recursos, prejudicando o desempenho de algumas aplicações;
Movimentação de dados:
Por o fato das aplicações que executam em grades terem uma grande quantidade de dados que precisam ser movidos de um lugar para o outro, é preciso considerar o tempo gasto com a transferência desses dados.
Em função de as características mencionadas anteriormente, escalonamento eficiente de tarefas num ambiente de grade é um problema complexo.
Para obter um bom desempenho na execução das tarefas, o algoritmo utilizado para distribuir- las necessitará escolher os recursos mais apropriados.
Outro fator que deve ser considerado quando se pretende trabalhar com grades computacionais, é o tipo de aplicação mais apropriado para executar nesse ambiente.
Devido a o fato de que normalmente os recursos de uma grade são interligados por grandes redes de computadores, que possuem uma latência de comunicação alta, as aplicações que forem submetidas à grade, normalmente são do tipo Bag-of--Tasks (BoT).
Esse tipo de aplicação possui tarefas independentes, que não necessitam trocar informações entre si, ou seja, não há comunicação ou dependências entre tarefas.
Aplicações BoT incluem buscas maciças (tais como quebra de chave), aplicações de manipulação de imagem e algoritmos de mineração de dados.
Em a próxima seção falaremos a respeito de escalonamento de tarefas e sobre alguns dos principais algoritmos de escalonamento específicos para grades computacionais.
Escalonamento de Tarefas Segundo, o escalonador é responsável por decidir qual job irá executar primeiro, caso hajam vários jobs prontos para executar competindo por o uso da Central Processing Unit (CPU).
Sendo também responsável por:
Decidir qual é o processador mais adequado para executar cada tarefa, decidir qual é o intervalo de tempo que cada tarefa executará em cada processador e alocar os recursos necessários para cada tarefa e disparar a sua execução.
De forma ideal, um escalonador deveria garantir que as tarefas executassem utilizando ao máximo os recursos disponíveis e terminassem no menor tempo possível, sempre respeitando as restrições de tempo ou outras políticas aplicadas às tarefas.
Em a Seção 2.2.1, é apresentada a taxonomia hierárquica para algoritmos de escalonamento proposta por Casavant e Kuhl e na Seção 2.2.2 são abordados alguns dos principais algoritmos de escalonamento conhecidos.
Visando criar uma terminologia comum que facilite o entendimento dos diversos cenários em os quais os algoritmos de escalonamento podem ser aplicados, Casavant e Kuhl criaram uma taxonomia hierárquica para algoritmos de escalonamento em sistemas computacionais distribuídos, ilustrada na Figura 1.
Em uma grade computacional, normalmente o tipo de escalonamento necessário encontra- se no ramo Global.
A seguir é apresentada uma explicação sobre a classificação proposta por Casavant e Kuhl:
Local versus Global:
O escalonamento local determina como os processos residentes num único processador são alocados e executados.
Já o escalonamento global utiliza informações sobre o sistema para alocar processos para múltiplos processadores.
Estático versus Dinâmico:
Em o escalonamento estático, as informações são obtidas antes do início do escalonamento da aplicação, sem possuir informações sobre as mudanças dinâmicas de estado do sistema no decorrer de o processo.
Ou seja, no escalonamento estático a atribuição de tarefas às máquinas é feita antes do início da execução.
Já no escalonamento dinâmico é realizada a alocação de tarefas durante a execução da aplicação.
Ótimo versus Sub-ótimo:
Se toda a informação do estado dos recursos e da aplicação é conhecida, o escalonamento poderá ser ótimo.
Em os casos em que é computacionalmente inviável obter tais informações, o escalonamento alcançado é considerado sub-ótimo.
Aproximação versus Heurística:
O algoritmo de aproximação procura implementar uma solução que seja suficientemente boa em relação a que foi definida como ótima.
Já o algoritmo de heurística, leva em consideração alguns parâmetros que afetam o sistema de uma maneira indireta, como por exemplo, a comunicação entre processos.
Distribuído versus Não distribuído:
Em os escalonadores dinâmicos, as decisões de escalonamento global podem ser de um escalonador centralizado ou pode ser compartilhada por múltiplos escalonadores distribuídos.
Já a estratégia centralizada pode ser mais simples em termos de implementação, se comparada à distribuída.
Entretanto, poderá ser um gargalo em termos de desempenho, pois muitas aplicações podem ser enviadas para serem escalonadas simultaneamente.
Cooperativo versus Não Cooperativo:
Em o modo cooperativo, cada escalonador responsabiliza- se por carregar sua própria porção do escalonamento de tarefas, mas todos os escalonadores trabalham em conjunto para o sistema global.
Esta situação não ocorre no modo não cooperativo, onde os escalonadores individuais agem de forma independente, não se preocupando em melhorar o desempenho do resto do sistema.
Os algoritmos de escalonamento adicionalmente também podem ser classificados em:
Preemptivos e Não Preemptivos:
Escalonadores preemptivos permitem que uma tarefa em execução seja interrompida temporariamente e posteriormente retomada.
Esse fato pode ocorrer se uma tarefa com maior prioridade chegar para ser executada.
Já nos escalonadores não preemptivos, uma vez que uma tarefa for iniciada ela será executada até sua conclusão.
Homogêneos e Heterogêneos:
Escalonadores que operam em sistemas homogêneos são aqueles em os quais as tarefas são distribuídas por as unidades de processamento que possuem a mesma capacidade de processamento, memória e disponibilidade de recursos.
Já os escalonadores que operam em sistemas heterogêneos, são capazes de lidar com sistemas em os quais as unidades têm diferentes capacidades computacionais.
Essa taxonomia além de auxiliar na organização dos algoritmos de escalonamento também facilita o seu desenvolvimento, pois quanto mais informações forem conhecidas sobre o tipo de ambiente e de aplicação com os quais se trabalhará, maior será a eficiência do algoritmo desenvolvido.
Em a literatura, encontram- se diversos algoritmos de escalonamento que se adaptam a diferentes tipos de problemas e sistemas.
De entre eles, há alguns que se destacam por a facilidade de implementação, adaptabilidade e desempenho, tais como:
First In First Out (FIFO):
Algoritmo de escalonamento não preemptivo, em o qual os processos recebem tempo de CPU na mesma ordem em que solicitam.
Como vantagens deste algoritmo, pode- se citar a facilidade de entendimento e implementação, além de sua imparcialidade. Como
desvantagens pode- se mencionar a sensibilidade à ordem de chegada das tarefas e o aumento do tempo médio de espera no caso de processos grandes chegarem primeiro na fila.
Last In First Out (LIFO):
Este algoritmo funciona de maneira simples, a última tarefa a entrar na fila será a primeira a ser executada.
Shortest Job First (SJF):
O SJF também é um algoritmo não preemptivo, que assume que os tempos de execução dos jobs são conhecidos antecipadamente.
Caso haja várias tarefas numa fila de entrada, de igual importância para serem executadas, o escalonador irá selecionar a tarefa mais curta primeiro.
Extraído de.
Se os jobs forem executados como mostra a Figura 2 (a), o tempo de resposta para a tarefa A será de 8 unidades de tempo, da B 12 unidades de tempo, da C 16 unidades de tempo e daD20 unidades de tempo, gerando uma média de 14 unidades de tempo.
Entretanto, se os jobs forem executados como mostra a Figura 2 (b), o tempo de resposta para a tarefa B será de 4 unidades de tempo, da C 8 unidades de tempo, daD12 unidades de tempo e da A 20 unidades de tempo, gerando uma média de 11 unidades de tempo, o que demonstra o ganho de desempenho ao utilizar o algoritmo SJF em relação a o FIFO.
Shortest Remaining Time Next (SRT):
Em o algoritmo SRT o escalonador escolhe o job cujo tempo de execução restante é o mais curto.
Ou seja, ao chegar um novo job o seu tempo será comparado com o tempo que resta do job atual.
Caso o novo job precise de menos tempo para terminar do que o job atual, este será suspenso e o novo job será executado.
Round-Robin (RR):
O algoritmo RR opera em sistemas iterativos, realizando um rodízio entre os processos da seguinte maneira:
Cada job possui um intervalo de tempo (quantum) durante o qual ele pode ser executado.
Caso ele esteja em execução e seu quantum terminar (esse job será colocado no final da fila), será feita a preempção da CPU e esta será alocada para outro job.
Earliest Deadline First (EDF):
Esse algoritmo dá prioridade de execução à tarefa que possui o deadline mais próximo de expirar, ordenando as tarefas com base em seu deadline.
Backfill First Fit (BFF):
O algoritmo BBF funciona de maneira parecida com o FIFO, mas quando não há recursos suficientes para a execução da primeira tarefa da fila, o restante da fila é examinado para encontrar a primeira tarefa que possa ser executada com os recursos e tempo disponíveis.
Backfill Best Fit (BBF):
O algoritmo BBF funciona de maneira parecida com o FIFO e o BFF, mas quando não há recursos suficientes para a execução da primeira tarefa da fila, o restante da fila é examinado para encontrar a tarefa que melhor se encaixa para ser executada com os recursos e tempo disponíveis.
Como citado na seção anterior, o escalonamento em grades computacionais é um processo complexo, em virtude de isso existem alguns algoritmos específicos para esse tipo de ambiente, tais como:
Workqueue (WQ):
Em este algoritmo, a escolha de qual tarefa será submetida para execução é feita de maneira aleatória sempre que um recurso ficar disponível.
O objetivo é que um maior número de tarefas seja atribuído para máquinas mais rápidas, fazendo com que as máquinas mais lentas executem cargas leves.
Uma vantagem deste algoritmo é que ele não precisa de informações a respeito de as tarefas ou dos recursos.
Entretanto, se uma tarefa grande for atribuída a um processador lento próximo de o final da execução da aplicação, a sua conclusão será adiada até que essa tarefa seja finalizada.
Sufferage (Suff):
A lógica deste algoritmo consiste em determinar o quanto cada tarefa pode ser prejudicada se não for escalonada no processador que a execute de forma mais eficiente.
O valor sufferage de cada tarefa é a diferença entre o melhor e o segundo melhor Completion Time (CT), considerando todos os processadores da grade.
A tarefa com o maior valor sufferage terá prioridade de execução.
O valor de CT é dado por a fórmula CT $= Time to Become Available (TBA)+ Task Cost.
Onde, TBA é o tempo para o host tornar- se disponível, Task Cost $= (Task size/ Host speed)/ (1 -- Host load), onde:
Como o valor sufferage de cada tarefa mudará durante a execução da aplicação, cada vez que uma tarefa terminar, as demais, que ainda não começaram a execução, serão desalocadas e o algoritmo calculará os valores sufferage atuais.
Esse processo é repetido até que todas as tarefas sejam completadas.
Uma desvantagem do Sufferage é que ele precisa conhecer informações sobre as tarefas e os recursos e tais informações nem sempre estão disponíveis.
XSufferage (XSuff):
O XSufferage é uma modificação do Sufferage, cuja principal diferença é o método usado para calcular o valor do sufferage.
O XSufferage considera a transferência dos dados de entrada da tarefa durante o cálculo dos tempos de execução.
De essa maneira, ele utiliza as informações relacionadas à CPU e ao tempo estimado de execução da tarefa usado por o Sufferage mais a largura de banda disponível na rede que conecta os recursos.
Para que o recurso mais rápido e com melhor conexão de rede não receba todas as tarefas, o XSufferage considera somente os recursos livres quando vai escalonar uma tarefa.
Dynamic Fastest Processor to Largest Task First (DFPLTF):
É a versão dinâmica do algoritmo estático FPLTF.
O DFPLTF também necessita de três informações para escalonar tarefas:
Task Size, Host Load e Host Speed.
Quando o algoritmo inicia, o TBA de cada host é iniciado com 0 e as tarefas são ordenadas por tamanho em ordem decrescente.
Desta forma, a maior tarefa é a primeira a ser alocada para o host que provê o menor CT.
Assim que uma tarefa é alocada para uma máquina, o valor do TBA relativo a este host é incrementado com Task Cost.
As tarefas são alocadas até que todas as máquinas da grade fiquem em uso.
Depois disso, a execução da aplicação é iniciada.
Em o momento que uma tarefa é completada, todas as demais que não estão executando são escalonadas novamente até que todas as máquinas fiquem em uso.
Tal processo é repetido até que todas as tarefas sejam completadas.
Segundo, o desenvolvimento de algoritmos de escalonamento deve ser focado num conjunto de aplicações específicas, pois se não houver um conhecimento dos detalhes das aplicações a serem escalonadas, o algoritmo pode influenciar negativamente nos resultados.
Como um ambiente de grade computacional possui algumas características especiais, como:
Grande quantidade e heterogeneidade de recursos e desempenho dinâmico, o escalonamento nesse tipo de ambiente torna- se um desafio.
Por isso, como dito anteriormente, conhecer as aplicações com as quais se irá trabalhar, os recursos disponíveis e as características dos mesmos, pode ser um fator crucial para o desenvolvimento de algoritmos de escalonamento que consigam utilizar de maneira eficiente o alto poder computacional das grades.
SimGrid Em o presente trabalho, utiliza- se a ferramenta de simulação de aplicações em ambientes distribuídos heterogêneos, SimGrid, criada em 1999 por Henri Casanova.
A construção da ferramenta deu- se por a necessidade de se utilizar simulação, ao invés de experimentos reais, no estudo de algoritmos de escalonamento para aplicações científicas paralelas.
Como o objetivo inicial do SimGrid era trabalhar com escalonamento de tarefas, existe uma facilidade para estudar estratégias de escalonamento utilizando a ferramenta.
Como motivações para utilizar essa ferramenta, citam- se:
Código opensource, possui uma boa documentação (com descrições sobre os módulos da ferramenta e seu uso) e está disponível para plataforma Linux, Windows e MacOS.
Além disso, diversos trabalhos na área de escalonamento de tarefas, em ambientes distribuídos, utilizam o SimGrid como ferramenta de simulação.
Antes de detalhar a estrutura e o funcionamento do SimGrid é preciso explicar o motivo de utilizar simulação ao invés de um ambiente real.
Em o trabalho de são citados alguns fatores para a utilização de simulação:
A configuração de um ambiente de teste real demanda muito tempo, é custosa e precisa de recursos intensivos;
Um ambiente real não fornece um ambiente repetível e controlável para a experimentação e avaliação de estratégias de escalonamento;
Aplicações reais demoram longos períodos de tempo para executar, dessa forma, não seria viável executar um grande número de experimentos;
A utilização de recursos reais faz com que seja difícil explorar uma grande variedade na configuração de recursos;
A o analisar novos modelos e algoritmos é preciso utilizar um grande número de testes, o que envolve muitos recursos e torna esse processo de alto custo econômico, se for realizado numa plataforma real.
Em decorrência dos fatores mencionados anteriormente, a simulação pode ser usada de maneira eficiente para demonstrar como um sistema real se comporta.
A Figura 3 mostra a arquitetura do SimGrid, que é composta por as seguintes camadas:
Ambientes de programação, núcleo de simulação e base.
Ambientes de Programação:
O SimGrid possui diversos ambientes de programação, cada qual com um objetivo específico.
Estes ambientes serão descritos a seguir:
Meta-SimGrid (MSG):
Deve ser utilizado para modelar problemas teóricos e para comparar diferentes heurísticas;
Simulated MPI (SMPI):
Utilizado para simular o comportamento de aplicações MPI;
Grid Reality and Simulation (GRAS):
Viabiliza a execução de aplicações reais para estudos e testes;
Advanced Metacomputing Overlay Kit (AMOK):
Implementa em alto nível diversos serviços necessários para várias aplicações distribuídas;
SimDag: Usado para a simulação de aplicações paralelas, utilizando um Direct Acyclic Graphs (DAG).
Em esse ambiente é possível especificar relações de dependência entre tarefas de um programa paralelo.
Núcleo de simulação:
Composta por o módulo Surf, que simula uma plataforma virtual.
Como é de muito baixo nível, não se destina a ser usado por os usuários comuns.
O SimGrid é implementado em linguagem C, opensource e funciona em modo texto.
Está disponível para ambientes Linux, Windows e MacOS.
A simulação realizada por o SimGrid é determinística, ou seja, repetindo a mesma simulação os resultados retornados serão sempre os mesmos.
A documentação do SimGrid pode ser consultada no site oficial do projeto, sendo bem estruturada e de fácil compreensão.
Para realizar simulações no SimGrid é preciso modelar três arquivos.
O primeiro contendo a plataforma da grade, o segundo contendo tarefas e o terceiro é um arquivo executável compilado em C usando as Application Programming Interfaces (Apis) do SimGrid.
O arquivo que configura a plataforma da grade (plataform.
Xml) especifica todo o conjunto de recursos da grade, assim como a estrutura de interconexão entre eles.
O mesmo, pode ser modelado no formato eXtensible Markup Language (XML), contendo as seguintes informações:
Especificação dos recursos de computação disponíveis, juntamente com o poder Links que conectam os nós do sistema, juntamente com a largura de banda e suas latências;
Roteamento entre os nós, em o qual são especificados o nó de origem, o nó de destino e os links de conexão que os unem.
O arquivo de modelagem de tarefas que usa o ambiente de programação MSG (ambiente utilizado neste trabalho) especifica os processos que serão executados em cada recurso.
Tal arquivo possui a identificação dos hosts, com os mesmos nomes do arquivo plataform.
Xml e suas funções de master ou slave.
O host que tem a função de master possui as seguintes informações:
Número de tarefas que receberá, tamanho de computação das tarefas, tamanho de comunicação das tarefas e a identificação de quem são os slaves.
O host que possui a função de slave não possui nenhuma informação.
A Figura 4 mostra o arquivo de configuração das tarefas.
Já a Figura 5 apresenta parte do arquivo de configuração da plataforma.
Para que a simulação ocorra, é necessário que algumas funções próprias do SimGrid sejam implementadas, tais como:
Master, slave e escalonamento (algoritmo de escalonamento que atribui às tarefas aos nós).
Essas funções estão implementadas no arquivo mostrado por a Figura 6.
&quot;escalonamento. H&quot;/* LIBTS*/ specific for this msg example&quot;);
Segundo, cada tarefa passa por três fases durante a sua execução:
Inicialização, computação e conclusão.
Em o SimGrid essas três fases podem ser descritas da seguinte forma:
Fase de inicialização:
A tarefa é enviada do mestre para o nó escravo e a tarefa é iniciada.
Essa fase inclui a sobrecarga gerada por o mestre para iniciar uma transferência de dados para um escravo;
Fase de computação:
O escravo processa a tarefa.
Qualquer sobrecarga relacionada com a recepção de arquivos de entrada por um nó escravo também está incluída nesta fase;
Fase de conclusão:
Quando a tarefa estiver concluída, o mestre recebe uma mensagem de que o escravo pode receber outra tarefa.
A fase de inicialização de um escravo pode ocorrer concomitantemente com a fase de conclusão de outro nó escravo.
Library Tasks Scheduling (LIBTS) Segundo, apesar de o SimGrid ser uma ferramenta que auxilia no estudo de algoritmos de escalonamento numa grade computacional, ele não oferece políticas internas de escalonamento de tarefas.
De essa forma, a implementação dos algoritmos de escalonamento deve ser feita por os próprios usuários.
Com o objetivo de criar um ambiente amigável e que facilite o trabalho dos pesquisadores da área de escalonamento de tarefas foi desenvolvida a biblioteca LIBTS.
A LIBTS é desenvolvida em linguagem C e implementa os seguintes algoritmos de escalonamento:
FIFO, LIFO, RR, SJF, WQ, WQR, Sufferage, XSufferage e DFPLTF.
Para interagir com os módulos do SimGrid, a LIBTS foi adicionada ao módulo MSG.
Sua estrutura é composta por o módulo principal chamado escalonamento que possui a chamada para todos os algoritmos de escalonamento citados anteriormente.
Tais algoritmos seguem o padrão citado na Seção 2.2.2 com algumas adaptações para poder utilizar a estrutura de dados do MSG.
A LIBTS funciona com aplicações do tipo master-Slave, sendo que o código masterslave.
C utilizado por a LIBTS foi criado tendo como base o masterslave_ bypass.
C disponibilizado por o SimGrid.
Dentro deste arquivo, são realizadas algumas ações como:
Arquitetura da LIBTS.
Adaptado de.
Caso os usuários queiram desenvolver seu próprio algoritmo de escalonamento para executar na LIBTS, eles podem fazer- lo seguindo os padrões do MSG e em seguida adicionar a chamada da sua função de escalonamento ao código fonte escalonamento.
C, da seguinte forma:
Depois de ter- se apresentado o referencial conceitual em o qual este trabalho fundamenta- se, o próximo capítulo apresenta os trabalhos relacionados à eficiência energética em ambientes de alto desempenho.
Eficiência energética é um tema que vem destacando- se na área computacional, devido a a dificuldade de manter determinadas infraestruturas computacionais em operação, por o alto custo associado a gastos com estruturas de refrigeração, consumo de energia e manutenção.
De acordo com, para garantir a eficiência energética num ambiente de grade computacional é preciso dar atenção aos seguintes fatores:
Ajuste dinâmico da frequência e da voltagem da CPU, do inglês Dynamic Voltage and Frequency Scaling (DVFS);
Desligamento de componentes de hardware de baixa utilização;
Nivelamento de potência;
Gestão térmica.
A técnica de DVFS é usada para controlar a potência da CPU, pois segundo, o consumo de energia do processador é uma parcela significativa da energia total consumida por o sistema.
Os autores também citam que alguns servidores ou seus componentes poderiam ser desligados, ou então, poderiam operar num estado de baixo consumo de energia, sempre atendendo às necessidades das aplicações de entrada.
Mas, devido a o fato desta solução ser dependente da carga de trabalho, o desafio, de acordo com, seria identificar o momento certo de desligar componentes e como fornecer um valor adequado de desaceleração de trabalho.
Técnicas de gestão térmica são utilizadas para gerenciar a elevação das temperaturas, o que pode impactar negativamente na confiabilidade do sistema e pode causar o aumento dos custos com resfriamento.
Em o trabalho desenvolvido por, a carga de trabalho do sistema é ajustada de acordo com um limiar de temperatura prédefinida.
Caso a temperatura de um servidor fique acima de o limite, sua carga de trabalho será reduzida.
Em este capítulo é apresentado o estado-da-arte em técnicas para a redução do consumo de energia em sistemas computacionais como grades e clusters.
A o final deste, é apresentada uma tabela com um comparativo entre os trabalhos apresentados e o trabalho desenvolvido.
O objetivo de apresentar o estado- da arte é mostrar que a maioria dos trabalhos pesquisados a respeito de estratégias de economia de energia em grades computacionais e clusters apresentam soluções que utilizam controle de recursos ociosos e escalonamento de tarefas para obter eficiência energética.
Controle de Recursos Ociosos Essa estratégia consiste em manipular os recursos computacionais disponíveis para que eles não fiquem ociosos consumindo energia de maneira desnecessária.
A seguir, são apresentados alguns trabalhos que utilizam tal estratégia.
O trabalho de apresenta duas estratégias para economizar energia em grades computacionais oportunistas (nesse tipo de sistema se os recursos computacionais não estiverem sendo utilizados por o seu &quot;dono», podem ser usados para executar tarefas de terceiros que tenham sido submetidas à grade), são elas:
Sobreaviso, do inglês standby:
Mantém ativa a memória Random Access Memory (RAM) e reduz a atividade do disco rígido e do processador;
Hibernação, do inglês hibernate:
Salva o estado da memória RAM no disco rígido e reduz o uso de energia da RAM, do disco rígido e do processador.
Segundo os autores, o tempo gasto para colocar e retirar um computador do estado sobreaviso é menor do que do estado hibernação.
Entretanto, o estado de sobreaviso apresenta maior consumo de energia, por o fato da memória RAM permanecer energizada Um fator que deve ser considerado é que o uso das estratégias de sobreaviso e de hibernação, pode reduzir a vida útil dos recursos da grade caso elas ocasionem um aumento excessivo no número de transições entre o estado ativo e os estados citados acima.
Isso ocorre devido a o fato de alguns componentes do computador, como o disco rígido, por exemplo, tolerarem um número máximo de transições durante o seu tempo de vida.
Outro fator importante é determinar após quanto tempo de inatividade do recurso da grade a estratégia deve ser acionada.
Segundo os autores, ao utilizar- se um tempo de inatividade pequeno, o recurso será adormecido logo depois de se tornar ocioso, o que pode aumentar a economia de energia, entretanto, pode aumentar também o tempo de resposta das aplicações que terão que esperar até que o recurso volte à atividade.
Já ao utilizar- se um tempo de inatividade grande, o recurso permanecerá no estado de ociosidade durante mais tempo o que pode reduzir a economia de energia.
Um ponto positivo é que pode reduzir também o tempo de resposta das aplicações, as quais não precisarão esperar até que o recurso torne- se ativo novamente.
Os resultados dos testes mostraram que as estratégias de sobreaviso e de hibernação reduzem o consumo de energia em mais de 80%.
Essa redução no consumo não causa um grande impacto no tempo de resposta das aplicações, aumentando no máximo em 5%, com o uso de hibernação, e em pouco mais de 1%, com o uso de sobreaviso.
Os autores também relatam que quanto maior o valor do tempo de inatividade, menor é a economia de energia,.
Esse fato ocorre devido a o aumento do tempo em que cada máquina permanece no estado ocioso, esperando a chegada de uma nova tarefa.
Quanto a o número de transições entre o estado ativo e os estados de baixo consumo de energia, a estratégia de hibernação utilizando 50 máquinas e tempo de inatividade igual a 0, apresentou o maior número, em média 15 transições por máquina, o que equivale a 8 transições por dia.
Como o número de transições de um disco rígido SATA, por exemplo, pode ser de até 273 por dia, o uso dessa estratégia não reduziria a vida útil desse componente.
Em, é apresentado um escalonador com consciência energética para clusters.
O escalonador proposto implementa três algoritmos de escalonamento, E-FIFO, E-BFF e E-BBF, que são versões com reconhecimento de consumo de energia dos tradicionais algoritmos:
FIFO, BFF e BBF (Seção 2.2.2).
Em esses algoritmos, com adicional de consciência energética, é utilizado o método de desligar nós ociosos caso haja mais de T segundos antes do início da primeira tarefa da fila.
O trabalho também apresenta modelos para calcular diversos componentes de um computador quando ele processador, memória, disco rígido, de entre outros.
Para compõem o cluster são considerados homogêneos.
Para o consumo de energia de está ocioso, tais como:
Baseados nos resultados dos testes, os autores mencionam que o escalonador é capaz de reduzir o consumo de energia entre 6 e 16%, dependendo da carga de trabalho, sem que haja uma perda significativa no tempo de resposta ou aumento do tempo de espera das tarefas.
Sendo que o E-BFF e o E-BBF, foram mais eficientes nos testes realizados do que o E-FIFO, pois diminuem o tempo de espera das tarefas por explorar o preenchimento dos nós ociosos com a execução de tarefas menores o que não ocorre no O trabalho de descreve um escalonador inteligente que visa economizar energia num ambiente de grade.
Os recursos utilizados são provenientes do Grid' 5000.
Os autores utilizaram como pressuposto que apesar de as máquinas serem diferentes, elas possuíam desempenho e consumo idênticos.
Por essa razão, segundo eles, não haveria diferença entre executar um job num conjunto de recursos ou em outro.
A seguir, estão descritos os cinco estados em que os recursos da grade podem estar:
On: Quando o recurso está executando um job.
A energia consumida foi considerada de 108 watts;
Off: Significa que o recurso está desligado e portanto, não está ocupado com jobs.
A energia consumida foi considerada de 5 watts;
Idle: Significa que o recurso está ligado esperando por o recebimento de jobs para executar.
A energia consumida foi considerada de 50 watts;
Booting: Significa que o recurso está passando do estado de Off para On.
A energia consumida foi considerada de 110 watts;
Shutting: Quando um recurso é desligado a partir de On ou Idle.
A energia consumida foi considerada de 110 watts.
A Figura 8 mostra o ciclo de vida dos recursos.
O tempo para a passagem de um estado para o outro é apresentado sobre as setas.
Os tempos Tbooting e Tshutting foram estabelecidos em 100 segundos e 10 segundos respectivamente.
Segundo os autores, a atual política do Grid' 5000 consistia em deixar os recursos ociosos a espera de novos trabalhos para executar, a fim de satisfazer as necessidades dos usuários rapidamente.
Entretanto, essa política chamada de Always On era muito ruim em termos de consumo de energia.
Em virtude de isso, o objetivo dos autores era substituir essa política por novas políticas energéticas, que decidissem entre deixar recursos ligados ou desligar- los assim que eles finalizassem a execução de um job.
Essas novas políticas foram denominadas:
Always On, Always Off, Switch Off Randomly, Load, Switch off Ts, Exponential e Gamma.
Tais políticas foram organizadas em:
Não fazer nada, do inglês, De o Nothing (DN):
Consiste em não alterar o recurso de execução do job e nem deslocar- lo no tempo para aproveitar recursos que já estão ligados, ou seja, eles são executados conforme definido por o escalonador;
O cálculo da energia consumida para executar os jobs dos experimentos foi baseado nas informações de consumo de energia dos estados:
On, Off, Idle, Booting e Shutting.
Analisando os resultados obtidos os autores concluíram que a SA é sempre melhor em termos de economia de energia, chegando a alcançar uma economia de energia, para o site da grade localizado em Bordeaux, de 129,254 kWh.
Escalonamento Voltado para Eficiência Energética Os trabalhos que serão apresentados nessa seção utilizam a estratégia de escalonamento.
Tal estratégia consiste em alocar tarefas a recursos visando reduzir o consumo de energia.
Um estudo sobre escalonamento de tarefas baseado em previsão de temperatura num centro de dados é apresentado em.
Segundo os autores, altas temperaturas dentro de um centro de dados podem aumentar os custos com resfriamento e as taxas de falha de hardware.
Segundo, a computação em alta temperatura é mais propensa a erros, sendo que a taxa de falha de hardware de um dispositivo eletrônico dobra a cada aumento de 10 ºC na temperatura, de acordo com a equação de Arrenhius.
Como a gestão da carga de trabalho pode reduzir as temperaturas dentro de um centro de dados, o trabalho de, baseado em técnicas de previsão de temperatura utilizando Redes Neurais Artificiais (RNA), apresentou um algoritmo de escalonamento de tarefas com reconhecimento térmico, do inglês, Thermal--Aware Scheduling Algorithm (TASA).
Tal algoritmo visa reduzir o consumo de energia e a temperatura num centro de dados, colocando cargas nos nós de computação de forma adequada, reduzindo os picos de temperatura do nó e o tempo de resposta da tarefa.
Para avaliar o desempenho do algoritmo proposto, os autores realizaram um estudo baseado em simulação.
O algoritmo de escalonamento utilizado para comparação com o TASA foi o FIFO.
De acordo com os autores, quando alguns recursos do cluster atingem a temperatura máxima, o TASA atrasa o envio de tarefas, para deixar- los esfriar.
Fato que não ocorre com o FIFO, que por não considerar a temperatura, continua a escalonar tarefas para os recursos.
Os resultados mostraram que o TASA pode economizar até 13,34% de alimentação do sistema de refrigeração do cluster, além de reduzir 2.130 Kg de CO2 por hora, dos cerca de 33.000 kg emitidos a cada hora por o cluster do centro de pesquisa.
Outro benefício é que a temperatura máxima do cluster diminuiu 6,67 °F.
Entretanto, houve um aumento de 15,2% no tempo de resposta das tarefas.
Perda que segundo os autores, seria compensada por os ganhos acima mencionados.
Em sistemas de clusters é de suma importância investir em estratégias de consciência energética, pois o consumo de energia impacta no custo operacional e na confiabilidade desses sistemas.
Com o objetivo de minimizar o consumo de energia e cumprir os prazos especificados por os usuários das aplicações, o trabalho de apresenta algoritmos de escalonamento com consciência energética para aplicações do tipo BoT com restrições de prazo para clusters com Dynamic Voltage Scaling (DVS) habilitado.
DVS é utilizado para reduzir o consumo de energia dinâmica, ajustando a tensão de alimentação de um modo adequado.
O escalonamento proposto funciona da seguinte maneira:
Quando uma tarefa é recebida, o controlador de recursos decide se aceita o trabalho.
O regime de admissão proposto garante que os prazos das tarefas anteriormente aceitas no sistema sejam atendidos.
Caso todas as tarefas possam cumprir seus prazos, os elementos de processamento necessários são alocados para a nova tarefa.
Os autores descrevem os seguintes passos para a admissão de uma nova tarefa e a sua execução no sistema de cluster;
Como uma tarefa consiste em múltiplas tarefas, os passos da são repetidos até que todas as tarefas sejam atribuídas aos elementos de processamento.
Se todas as tarefas cumprirem os prazos, o controlador de recursos aceita a nova tarefa, senão ele a rejeita, porque não pode garantir o prazo da tarefa.
As simulações foram realizadas com dois algoritmos de escalonamento que são variações do EDF, um que usa DVS, o EDF-DVS e outro com participação proporcional, o EDF- PShare.
Para comparar o desempenho, os autores simularam um algoritmo de escalonamento sob tensão mais baixa de alimentação, e o outro sob tensão mais elevada.
Os resultados mostraram que os algoritmos com DVS habilitado possuem uma relação de grande aceitação de tarefas, além de consumirem menos energia em comparação com as versões 1.5 V-estática:
O EDF-1.
5 V sempre executa processadores na velocidade máxima de relógio, por isso possui uma elevada aceitação de tarefas, com o maior consumo de energia, ao ser comparado com o EDF-1.
5 V, PShare-1.
5 V, EDF-DVS, PShare-DVS, EDF0.
9V e PShare-0.
9 V;
O EDF-1.
5 V e o PShare-1.
5 V consomem grande quantidade de energia, porque usam uma tensão de alimentação com 1.5 V;
O EDF-0.
9 V e o PShare-0.
9 V mostraram um menor consumo de energia.
Mas, eles possuem uma aceitação de tarefas inferior a 40%, mesmo sob condições de baixa sobrecarga.
Os autores também realizaram uma comparação de desempenho entre os algoritmos EDF-DVS versus EDF-1.
5 V e PShare-DVS versus PShare-1.
5 V, em termos de índice de aceitação e consumo de energia.
Os resultados mostraram que a melhora na redução de energia sempre é maior do que a degradação da taxa de aceitação.
Quando a carga do sistema torna- se baixa, há uma melhoria na economia de energia e uma perda de aceitação baixa.
Em resumo, os resultados obtidos mostraram que os algoritmos que usam DVS reduzem o consumo de energia com pouca degradação do prazo das tarefas.
O trabalho desenvolvido por trata da exploração da heterogeneidade em grades computacionais para a alocação de recursos com uso eficiente de energia.
Para reduzir o consumo de energia do sistema, os autores utilizaram a técnica de distribuir as aplicações para serem executadas em paralelo numa rede em grade.
Essa distribuição é feita através da utilização de um algoritmo de escalonamento denominado Heterogeneity Aware Meta--scheduling Algorithm (HAMA).
O algoritmo HAMA consegue selecionar de maneira energeticamente eficiente os recursos da grade, selecionando primeiro o recurso mais eficiente em termos de energia de entre os disponíveis na grade (os recursos da grade são classificados em ordem de eficiência de energia).
HAMA ordena as tarefas recebidas com base no algoritmo EDF (Seção 2.2.2).
Em seguida, usa DVS para alterar a velocidade de processamento da CPU com o intuito de alcançar uma maior redução no consumo de energia, sempre buscando respeitar o prazo de conclusão de determinada tarefa.
Os testes foram realizados com base nos seguintes cenários:
Um contendo variações na urgência para a execução dos jobs e o outro com variações na taxa de chegada dos jobs.
Os resultados dos testes mostraram que o HAMA com uso de DVS pode reduzir o consumo de energia do sistema em até 23%, no pior caso, e em até 50% no melhor caso, ao ser comparado com o algoritmo EDF.
Já ao operar sem DVS, o HAMA obteve uma economia de energia de até 21%.
Segundo, uma carga de trabalho normalmente consiste de muitos processos sequenciais independentes, que podem ter sua execução moldada para satisfazer as restrições de energia.
O trabalho fala a respeito de um escalonador que mantém um compromisso entre redução do consumo de energia e pouca perda de desempenho em grades computacionais.
Para isso, é utiliza uma variação do número e da frequência dos processadores disponíveis.
Em o trabalho desenvolvido por, são propostas três estratégias que visam minimizar o consumo de energia e maximizar o desempenho, são elas:
Escala de frequência de CPU:
Técnica para reduzir a velocidade da CPU, a fim de diminuir a energia consumida e o calor que é dissipado.
É empregada para aumentar o rendimento do sistema em vez de ativar nós que serão subutilizados;
Dimensionamento automático de nós:
Mecanismo utilizado para ligar e desligar máquinas, a fim de corresponder a requisitos como tamanho da fila e características das tarefas.
Máquinas só são ativadas quando se considera que o cluster não pode suportar a carga atual e desligadas ao permanecerem inativas por um período de tempo específico;
Atribuição inteligente de jobs:
Camada de otimização implementada nos algoritmos de gerenciamento do cluster, que opera para que não hajam máquinas ligadas sem necessidade.
As simulações foram realizadas num cluster, onde cada nó que o compõe é de uma especificação idêntica, a energia consumida por cada nó sob a mesma carga também é idêntica e todos os trabalhos submetidos ao cluster são estritamente intensivos de CPU.
Com isso, as latências relacionadas ao acesso à memória, disco e rede não são consideradas.
O estudo fundamentou- se na construção de várias políticas de gestão do cluster, baseadas nas estratégias mencionadas anteriormente.
As políticas propostas por os autores são:
Gerenciamento do Cluster:
Essa política é baseada no seguinte esquema de envio de tarefas:
Todas as máquinas estão sempre ligadas;
Uma tarefa é atribuída a um único núcleo num único nó;
Máquinas são arbitrariamente ordenadas de 0 a N-1, onde N é o número total de nós do cluster;
Quando as tarefas são submetidas, elas são enviadas para a fila de tarefas;
Tarefas em espera na fila são submetidas a um núcleo do cluster usando a ordenação FIFO;
As tarefas são submetidas a menor máquina ordenada com um núcleo ocioso;
Todos os núcleos num único nó devem ser escalados para a mesma frequência, seja a frequência mais alta ou a menor frequência suportada, dependendo de qual política de gerenciamento está em uso no cluster.
A política de Gerenciamento do Cluster é dividida de acordo com o nível de frequência utilizado, em:
Hf (High Frequency) -- Em esta política, a frequência das CPUs é sempre definida como a maior frequência suportada.
Em este caso, todas as máquinas permanecem nesse estado durante toda a duração da simulação.
LF (Low Frequency) -- Em esta política, a frequência das CPUs é sempre definida como a menor frequência suportada.
Em este caso, todas as máquinas permanecem nesse estado durante toda a duração da simulação.
Escalonamento no Cluster:
Em esta política as máquinas são ligadas e desligadas com base no número de tarefas atualmente em execução no cluster, bem como nas tarefas que estão esperando na fila.
Inicialmente, todas as máquinas são desligadas.
Caso a máquina não utilize escala de frequência, os nós são ativados conforme a necessidade.
Já se a máquina utiliza escala de frequência, em primeiro lugar a frequência das máquinas ativas é aumentada, a fim de aumentar o rendimento do cluster antes de ligar máquinas adicionais.
Sendo que as máquinas são desligadas depois de permanecer num estado ocioso além de um limite de 300 segundos.
A política de Escalonamento do Cluster é dividida em:
Scaled to the Highest supported Frequency (SHF) -- Todas as CPUs são escalonadas para a frequência mais alta suportada.
Quando os trabalhos são submetidos, eles são atribuídos para os núcleos ociosos do cluster.
Scaled to the Lowest supported Frequency (SLF) -- Todas as CPUs são escalonadas para a menor freqüência suportada.
Quando os trabalhos são submetidos, eles também são atribuídos para os núcleos ociosos do cluster.
Scaled to the lowest Supported freQuency (SSQ) -- Todas as CPUs são inicialmente escalonadas para a menor frequência suportada.
Caso hajam tarefas na fila aguardando para serem executadas, as frequências das máquinas atualmente ligadas são aumentadas.
Se esse aumento da frequência não for suficiente para atender todas as tarefas em espera na fila, máquinas adicionais são ativadas.
Scaled to the loWest supported freQuency (SWQ) -- Todas as CPUs são inicialmente escalonadas para a menor frequência suportada, permanecendo nessa frequência embora existam núcleos ociosos no cluster.
Caso o conjunto de nós ativos esteja na capacidade máxima, as frequências das CPUs são aumentadas, de tal forma que a taxa de transferência do cluster é aumentada por o equivalente a um núcleo adicional (em baixa frequência) para cada tarefa em espera na fila.
Escalonamento com Atribuição Inteligente de Jobs:
Em essa política os autores assumem que a quantidade de tarefas associada a cada posto de trabalho é conhecida no momento da submissão.
De essa maneira, seria possível determinar quais máquinas estão ligadas por mais tempo.
A política de Escalonamento com Atribuição Inteligente de Jobs está dividida em:
SWQI -- A política SWQI aperfeiçoa o mecanismo de atribuição de tarefas SWQ.
Considerando que a quantidade de &quot;trabalho «exigida por uma tarefa é conhecido no momento da sua submissão, pode- se supor a quantidade de &quot;trabalho «que ainda precisa ser preenchida para cada tarefa no cluster.
O que, segundo os autores, permite identificar qual a máquina com um núcleo disponível está escalonada por mais tempo.
A tarefa seguinte na fila é então atribuída a um núcleo nesta máquina.
SWQN -- As tarefas são atribuídas às máquinas que estão executando a tarefa mais recentemente apresentada.
SWQO -- As tarefas são atribuídas às máquinas com a tarefa mais antiga em execução.
Os resultados dos testes realizados por mostraram que:
Hf sempre consome mais energia do que LF, ou seja, um nó é mais eficiente energeticamente quando opera em baixa frequência, mas o tempo de resposta é ruim;
SWQI e SWQO obtiveram a melhor eficiência energética e desempenho global;
SHF e SLF necessitam de um número relativamente grande de transições entre ligado e desligado em comparação com o número de transições exigidas por as políticas que utilizam escala de frequência, como a SWQI e a SWQO.
SWQI e SWQO aumentam as freqüências dos processadores no cluster antes de energizar nós adicionais, ou seja, máquinas adicionais só são ativadas quando todas as máquinas ativas já foram dimensionadas para uma frequência mais elevada;
SHF fornece o melhor tempo de resposta, pois as máquinas sempre executam com a frequência máxima suportada.
Caso as tarefas começem a acumular na fila, máquinas adicionais são imediatamente ligadas, causando um alívio instantâneo para as tarefas em espera na fila;
SLF fornece o pior tempo de resposta de todas as políticas que usam escala de frequência.
Isso ocorre devido a a execução de todos os nós na frequência mínima suportada por a máquina.
Analisando os resultados apresentados, os autores constataram que um nó é energeticamente mais eficiente quando opera em baixa frequência, mas o tempo de resposta é ruim.
Sendo que a quantidade de energia consumida aumenta principalmente de acordo com o número de nós ativos no cluster.
Essa situação pode ser resolvida ao utilizar o dimensionamento automático de nós, que gerência o tempo que as máquinas permanecem executando baseado na carga de trabalho a que o sistema é submetido.
O trabalho de apresenta algumas estratégias de alocação de jobs que podem conduzir a economia de energia ao serem aplicadas num ambiente de grade.
As estratégias propostas por o trabalho visam melhorar a ligação entre os requisitos das aplicações e os recursos da grade, considerando também parâmetros de energia.
Para tal, foi criada a métrica de Energy Congruent Index (ECI) que classifica os recursos com uma combinação entre desempenho e consumo de energia sendo dependente de um mapeamento entre os recursos da grade e um conjunto de benchmarks pré-computados.
O ECI é composto por um vetor de desempenho (Pn) que possui o desempenho de cada um dos nós da grade (valor que é proveniente da execução de benchmarks para diversas aplicações distintas) e por um vetor com os valores de consumo de energia de cada nó em watt (Wn):
Sempre que um novo job chega ao escalonador, o mesmo classifica os recursos disponíveis baseado nos valores de ecih.
De essa forma, o job será executado por o nó livre com o ecih mínimo.
Baseado no ECI, os recursos da grade são classificados em ordem crescente em relação a a métrica MFLOPS/ W. Com relação a o consumo de energia, os autores realizaram a comparação da estratégia Energy--congruent (EC), com a estratégia Less Consuming Resource (LCR) e a Mega Flops per Watt (MFW).
Em a estratégia EC, os jobs são atribuídos às máquinas com base no vetor de ECI dos recursos disponíveis.
Em a LCR, os jobs são atribuídos ao recurso que consome menos energia de entre os disponíveis.
A estratégia MFW, por sua vez, atribui os jobs com base nos valores de MFLOPS/ W dos recursos.
Os testes foram realizados com dois tipos de jobs, um de álgebra linear e o outro de extração de isosuperfície numa grade composta por três máquinas.
Tais máquinas possuíam um desempenho de 1s, 4.9s e 3.4s, e um consumo de energia de 1900 W, 1450W e 2200 W, respectivamente.
Os resultados mostraram que a estratégia LCR é penalizada em desempenho por atribuir os jobs à máquina mais lenta, porém que consome menos energia.
Já a estratégia MFW se comporta como a EC se a máquina que é melhor em termos de MFLOPS/ W (que também é a melhor em termos de desempenho) estiver livre.
Entretanto, se ela não estiver a MFW escolherá a máquina que é melhor em termos de MFLOPS/ W, mas que perde em relação a o desempenho, o que causará um aumento no tempo de resposta.
Quanto a o consumo de energia, todas as estratégias apresentam aproximadamente os mesmos valores.
Segundo os autores, a escolha de uma estratégia dependerá da importância atribuída a ganhar em desempenho ou a economizar significativamente energia.
Conclusão A Tabela 1 apresenta um comparativo entre os trabalhos apresentados anteriormente ressaltando algumas das suas características principais.
Como pode ser observado na Tabela 1, a maioria dos trabalhos voltados para grades computacionais ou clusters (como, e) utiliza como base para o cálculo de consumo valores relativos ao consumo no estado ocioso dos recursos.
Portanto, o cálculo de economia de energia não utiliza os valores relativos a quanto um recurso consome quando está executando tarefas.
Apesar de o trabalho de utilizar o consumo em operação de um recurso, esse valor é fixo (independente do tipo de máquina).
Como as máquinas de uma grade são, na grande maioria das vezes, heterogêneas, é possível considerar que esse valor não representa corretamente a realidade.
O trabalho de por sua vez utiliza apenas controle da temperatura para reduzir o consumo de energia num cluster.
E os trabalhos de e usam DVS para obter uma redução no consumo de energia na execução de tarefas que possuem prioridade na ordem de execução (uso do algoritmo de escalonamento EDF).
Nenhum dos trabalhos anteriormente mencionados pode ser repetido a fim de efetuar uma comparação com o trabalho desenvolvido.
Uma vez que eles ou utilizam técnicas que não podem ser repetidas devido a a falta de um ambiente físico adequado, como as técnicas de DVS e controle de temperatura, ou por utilizarem valores de consumo fixos que não são realísticos para o ambiente de grade que simulamos (e).
Ou ainda, no caso de, por utilizar apenas os valores de consumo no estado ocioso dos recursos para calcular o consumo de energia num ambiente homogêneo de cluster.
O trabalho de associa consumo em watts e desempenho para tomar decisões de escalonamento e compara a sua solução à métrica MFLOPS/ W. Em virtude de isso, o algoritmo de escalonamento utilizado por eles é comparado com os algoritmos desenvolvidos neste trabalho.
Algumas adaptações foram realizadas por não dispormos dos benchmarks utilizados por eles para calcular o desempenho de cada um dos nós da grade que serve como base para o algoritmo de escalonamento tomar decisões.
Calcular o desempenho de cada máquina para cada uma das tarefas que irão executar na grade computacional exige muito trabalho.
Trabalho que aumenta proporcionalmente em relação a a quantidade de máquinas e tarefas, agregando um alto custo computacional e financeiro caso fosse utilizado um ambiente real.
Também se utilizou mais máquinas para os testes, não apenas 3 máquinas como em, a fim de construir um ambiente de grade mais realístico.
A fim de explorar soluções de eficiência energética em grades computacionais através de escalonamento de tarefas, desenvolveu- se um módulo para cálculo de consumo de energia e algoritmos de escalonamento energeticamente eficientes dentro de a arquitetura da LIBTS no SimGrid.
Este capítulo apresenta tais contribuições e traz explicações sobre o seu funcionamento.
Inicialmente, descreve- se a nova estrutura da arquitetura, agora com a possibilidade de calcular o consumo de energia na execução de aplicações.
Em seguida, apresenta- se o módulo responsável por tal cálculo.
Para finalizar, a Seção 4.3 apresenta cada um dos algoritmos de escalonamento desenvolvidos neste trabalho e as alterações realizadas em alguns dos algoritmos mais tradicionais específicos para grades computacionais.
Arquitetura de Escalonamento A estrutura da arquitetura de escalonamento baseia- se na da apresentada na Seção seção) e dos algoritmos de escalonamento energeticamente eficientes implementados neste trabalho.
Os algoritmos são denominados como:
Low Energy Consumption Scheduling Algorithm (LECSA);
Low Energy Consumption Scheduling Algorithm Version 2 (LECSA2);
Low Energy Consumption Scheduling Algorithm Version 3 (LECSA3);
Dynamic Low Energy Consumption Scheduling Algorithm (DLECSA);
Dynamic Low Energy Consumption Scheduling Algorithm Version 2 (DLECSA2);
Dynamic Low Energy Consumption Scheduling Algorithm Version 3 (DLECSA3).
Os algoritmos acima mencionados podem ser classificados segundo a taxonomia hierárquica para algoritmos de escalonamento de Casavant e Kuhl, conforme retratado na Seção 2.2.1.
De acordo com essa taxonomia o LECSA, o LECSA2 e o LECSA3 são classificados como:
Global, estático, sub-ótimo, heurístico, não preemptivo e direcionados para a execução em sistemas heterogêneos.
Já o DLECSA, o DLECSA2 e o DLECSA3 são classificados como:
Global, dinâmico, não-distribuído, não preemptivo que operam em sistemas heterogêneos.
Também foram realizadas alterações nos algoritmos WQ, Sufferage, XSufferage e DFPLTF para que eles tomassem decisões de escalonamento baseados em energia e não somente em desempenho.
Já o algoritmo ECI foi implementado para fins de comparação com algoritmos de escalonamento diretamente voltados à redução de consumo de energia.
A arquitetura pode ser observada na Figura 9.
As partes em destaque representam os algoritmos de escalonamento voltados para eficiência energética e o módulo de cálculo de consumo desenvolvidos neste trabalho.
Como pode ser observado na figura, os algoritmos são divididos em duas classes:
Uma voltada para desempenho, contendo 5 algoritmos, e outra voltada para eficiência energética, contendo 11 algoritmos.
Módulo de Cálculo de Consumo Com o objetivo de estimar o consumo de energia na execução de uma aplicação e, posteriormente, saber quanta energia foi gasta por cada algoritmo de escalonamento, desenvolveu- se o módulo de consumo.
Tal módulo calcula o consumo de energia baseado no consumo do host para executar determinada tarefa, no consumo do host no estado ocioso e no consumo da transferência de uma tarefa.
Ou seja, são consideradas mais informações para o cálculo de consumo de energia do que em alguns dos trabalhos relacionados apresentados no capítulo 3, que só consideram o consumo da máquina no estado ocioso.
Este mecanismo foi implementado dentro de o masterslave.
C da LIBTS, para que fosse possível calcular:
O consumo de energia de cada tarefa, de cada máquina (host) e o consumo total do algoritmo de escalonamento utilizado na execução da aplicação.
O módulo requer cinco informações para funcionar corretamente:
O tamanho da tarefa, o consumo em flops/ watt de um host, o tempo que um host permanece ocioso, o consumo de energia de um host no estado ocioso e o consumo de energia dos links que conectam o host mestre (responsável por enviar a tarefa para o host a qual foi escalonada) ao host escravo.
Este módulo pode ser adaptado para qualquer ambiente de simulação com o mesmo modelo de energia e as medidas de consumo.
A Equação calcula o consumo de energia de cada tarefa.
Onde, taskSize é o tamanho em flops da tarefa e o consumption é a quantidade de flops que o host (em o qual a tarefa foi alocada) consegue executar por watt de energia consumido.
Esta medição é utilizada em diversas pesquisas, incluindo a lista Top500.
O consumo de energia da transferência de uma tarefa do host mestre para o host escravo é dado por a Equação.
Para esse cálculo são usadas as informações do tamanho da tarefa em bits (taskSizeBits), do tempo que essa tarefa levou para ser transferida em segundos (timeTransf) e do consumo do link de conexão (consumptionLink) dado em watts/ bps (quantidade de watts consumidos para transferir um bit por segundo).
A Equação calcula o consumo de energia de cada host.
É utilizada a soma do consumo de cada tarefa que foi executada por ele (ecTaski), somado ao consumo de cada host no estado ocioso e ao consumo da transferência de cada tarefa executada por o host.
O valor do consumo ocioso é calculado multiplicando- se o tempo que o host permanece no estado ocioso (timeIdle) por o consumo ocioso desse host (ecIdle).
Sempre que um host termina de executar uma tarefa começa a contar o seu tempo no estado ocioso, quando ele recebe a próxima tarefa ele sai do estado ocioso para o estado ativo, e assim sucessivamente.
De essa forma, um acumulador calcula o tempo total que cada host permanece no estado ocioso.
Já o consumo total do algoritmo, é a soma do consumo de cada host, dado por a Equação:
Com o uso dessas equações, é possível estimar a quantidade de energia consumida na execução de uma aplicação de acordo com o algoritmo de escalonamento utilizado.
Algoritmos de Escalonamento Energeticamente Eficientes Em esta seção, são apresentados os algoritmos energeticamente eficientes desenvolvidos neste trabalho.
Estes estão divididos em duas classes:
A classe estática e a dinâmica.
A classe estática contém os seguintes algoritmos:
LECSA, LECSA2 (Seção 4.3.2) e LECSA3 (Seção 4.3.3).
A classe dinâmica contém:
DLECSA (Seção 4.3.4), o DLECSA2 (Seção 4.3.5) e o DLECSA3 (Seção 4.3.6).
As próximas seções explicam em detalhes o funcionamento de cada um dos algoritmos, além de mostrar- los através de pseudo-códigos.
O LECSA foi o primeiro algoritmo desenvolvido, toda a sua lógica é direcionada para reduzir o consumo de energia.
A seguir é detalhada a estrutura do LECSA e na Figura 10 apresenta- se o seu pseudo-código.
Inicialmente, as tarefas são ordenadas em ordem decrescente de acordo com o seu taskSize;
Em seguida (linha 4), os hosts são ordenados em ordem decrescente, de acordo com a sua eficiência energética (flops/ watt);
De acordo com a variação no tamanho das tarefas que compõe uma aplicação, é escolhida a quantidade de hosts que será utilizada na execução.
Caso o número de tarefas for maior que a quantidade de hosts, então, a quantidade de máquinas utilizadas é baseada no percentual de variação de heterogeneidade das tarefas por a quantidade de hosts (linha 7).
Por exemplo, com 90 máquinas tendo uma variação de 50% no tamanho das tarefas, serão utilizadas 45 máquinas.
Caso o número de tarefas for menor que a quantidade de hosts, então, a quantidade de máquinas utilizadas é baseada na variação por o número de tarefas.
Por exemplo, com 90 máquinas tendo variação de 50% no tamanho das tarefas e tendo 30 tarefas para escalonar, serão utilizadas 15 máquinas;
As máquinas que não serão utilizadas são desligadas para evitar que fiquem ociosas consumindo energia desnecessariamente;
O próximo passo consiste em dividir o número total de tarefas por o número total de hosts, para que cada host receba a mesma quantidade de tarefas para executar;
Depois disso, é percorrido cada host e enviada uma tarefa por vez até que todas as tarefas tenham sido enviadas.
Para enviar as tarefas existem controles que garantem que as com maior taskSize sejam enviadas para os hosts com melhor eficiência energética.
Em a linha 21, é pré-definida a próxima tarefa da fila a ser enviada.
Em a linha 22, é percorrida a lista de hosts e na sequência (linha 23) envia- se a tarefa.
Em seguida, é verificada qual deve ser a próxima tarefa a ser enviada.
Para isso, é incrementado o índice da tarefa a ser enviada com o valor da quantidade de tarefas por host;
Após o término de todas as tarefas, os hosts que foram utilizados na execução são finalizados.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
De essa forma, garante- se o envio das maiores tarefas para os hosts mais econômicos e tarefas menores para os hosts com menor eficiência energética.
O LECSA2 foi desenvolvido com o objetivo de melhorar o desempenho do LECSA.
Após a realização de alguns testes verificou- se que, em alguns casos testados, a perda de desempenho mostrava- se muito expressiva, apesar de a melhoria na eficiência energética em comparação com os demais algoritmos tradicionais específicos para grades.
Em virtude de isso, foi acrescentada ao código original do LECSA, uma função que ordena os hosts, que serão utilizados no escalonamento das tarefas, por o seu poder computacional.
A Figura 11 apresenta o pseudo-código do LECSA2.
A estrutura do LECSA2 é idêntica a do LECSA nos passos 1-4, mas o passo 5 do LECSA2 consiste na ordenação das máquinas que serão utilizadas no escalonamento por o seu poder computacional, em ordem decrescente.
Os passos 5-6 do LECSA são repetidos no LECSA2, depois da função de ordenação de hosts por o desempenho, descrita anteriormente.
De essa forma, garante- se que as tarefas sejam enviadas para as máquinas com melhor desempenho de entre as com melhor eficiência energética.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
Como a alteração no LECSA2 não atingiu em alguns casos testados o ganho de desempenho esperado, implementou- se o LECSA3 cujas alterações em relação a o LECSA2 podem ser observadas por a Figura 12.
Entretanto, por o fato do LECSA3 ser mais direcionado para obter ganho de desempenho do que o LECSA e o LECSA2, ele apresenta uma redução na eficiência energética, em comparação com os algoritmos citados.
As mudanças estão no momento de ordenação dos hosts em relação a o desempenho e a eficiência energética.
O passo 1 do LECSA2 permanece igual, mas o passo 2 muda.
Em o passo 2, agora os hosts são ordenados em ordem decrescente por o seu poder computacional.
Em seguida, os passos 3 e 4 do LECSA2 são executados.
O passo 5 do LECSA3 também sofre alteração em relação a o do LECSA2.
Esse passo, agora consiste na ordenação das máquinas que serão utilizadas no escalonamento por a sua eficiência energética, em ordem decrescente.
Os passos 5-6 do LECSA são repetidos no LECSA3, depois da função de ordenação de hosts por a eficiência energética descrita anteriormente.
O objetivo das modificações realizadas é garantir que as tarefas sejam enviadas para as máquinas com melhor eficiência energética de entre as com melhor desempenho.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
O objetivo do desenvolvimento do DLECSA é criar uma versão dinâmica do LECSA.
Devido a os outros algoritmos de escalonamento, específicos para grades, testados serem dinâmicos.
Sua dinamicidade é proveniente do fato de um host receber a próxima tarefa da fila assim que finalizar a execução da tarefa atual, o mesmo não ocorre nas versões estáticas do LECSA.
Em as versões estáticas, as tarefas que irão para cada host são prédefinidas antes do início da execução da aplicação.
Sendo que cada host recebe a mesma quantidade de tarefas o que não ocorre nas versões dinâmicas.
A Figura 13 apresenta o pseudo-código do DLECSA.
A seguir descreve- se a estrutura do algoritmo.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
Inicialmente, os hosts são ordenados em ordem decrescente, de acordo com a sua eficiência energética (flops/ watt);
Este passo é idêntico ao passo 3 do algoritmo LECSA, apresentado na Seção 4.3.1;
Este passo é idêntico ao passo 4 do algoritmo LECSA, apresentado na Seção 4.3.1;
A primeira tarefa da fila é escalonada no primeiro host livre encontrado (os hosts estão ordenados por a eficiência energética).
De essa forma, os hosts mais econômicos receberão as tarefas, desde que estejam livres.
Por exemplo, se o primeiro host (mais econômico) estiver ocupado, então, o segundo host (menos econômico) receberá a tarefa (linhas 14-24);
Após o término de todas as tarefas, os hosts que foram utilizados na execução são finalizados.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
O último passo ocorre após o término de todas as tarefas.
Em esse passo, ocorre a finalização das máquinas que foram utilizados na execução.
Como pode ser observado na Figura 14, a lógica do DLECSA2 é similar a do LECSA2, exceto por o fato do primeiro ser dinâmico e o segundo estático, ou seja, a diferença está na forma de realizar o envio das tarefas.
Em o DLECSA3, o primeiro passo consiste na ordenação dos hosts por o poder computacional, em ordem decrescente.
Os próximos passos são idênticos aos passos 2 e 3 do DLECSA.
A etapa seguinte realiza o envio da primeira tarefa da fila ao primeiro host livre encontrado com maior eficiência energética.
A meta é garantir que o host mais eficiente energeticamente de entre os livres, receba a próxima tarefa da fila.
O último passo é idêntico ao passo 5 do DLECSA (Seção 4.3.4) (linhas 26-29).
Em a Figura 15, pode ser observado o pseudo-código do DLECSA3.
Entrada: Tasks:
Lista de tarefas para alocar;
Task_ count:
Quantidade de tarefas;
Slaves: Lista de hosts;
O comportamento do algoritmo EWQ é similar ao do WQ, exceto por o fato do EWQ ser voltado para economia de energia.
De essa forma, inicialmente é realizada a ordenação dos hosts por a sua eficiência energética.
Em seguida, as tarefas são enviadas primeiramente para os hosts mais econômicos.
O objetivo é que um maior número de tarefas seja atribuído para máquinas com menor consumo de energia.
Mas, caso essas máquinas mais eficientes energeticamente, sejam ruins em termos de desempenho, pode ocorrer das tarefas serem enviadas para máquinas com menor eficiência energética.
Isso ocorre, pois a próxima tarefa da fila é enviada para o host que tornar- se disponível primeiro.
A lógica do algoritmo ESuff é similar a da sua versão original.
Entretanto, o objetivo não é melhorar o desempenho com no Sufferage, mas sim melhorar a eficiência energética.
Para tal, ao invés de calcular o quanto cada tarefa poderia ser prejudicada se não for escalonada no processador que a execute de forma mais eficiente em termos de desempenho, é calculado o quanto cada tarefa poderia ser prejudicada se não fosse escalonada na máquina que a execute com maior eficiência energética.
De essa forma, uma tarefa sempre será executada por o host que apresentar o menor consumo de energia de entre todos os hosts da plataforma.
A principal diferença entre o ESuff e o EXSuff é o método usado para calcular o valor sufferage.
O EXSuff considera a transferência dos dados de entrada da tarefa durante o cálculo dos tempos de execução.
Em a Seção 2.2.2, é explicado o cálculo do valor sufferage.
Lembrando que foram feitas alterações nesse cálculo para que ele fosse voltado para eficiência energética, como dito na seção anterior.
Em o algoritmo EDFPLTF, inicialmente as tarefas são ordenadas por tamanho em ordem decrescente da mesma maneira que é feito na sua versão original (Seção 2.2.2).
A diferença do EDFPLTF em relação a o DFPLTF fundamenta- se na meta de que a maior tarefa seja a primeira a ser alocada para o host que possuir o menor consumo de energia (no DFPLTF a maior tarefa é a primeira a ser alocada para o host que provê o menor tempo de execução).
O objetivo deste capítulo é, além de avaliar o mecanismo de cálculo de consumo, analisar também o desempenho e o consumo de energia dos algoritmos desenvolvidos neste trabalho em relação a outros algoritmos de escalonamento para grades computacionais já existentes.
Para tal, utilizaram- se diversas configurações de máquinas visando aproximar- se de casos reais juntamente com distintas configurações de filas de tarefas.
Entre os itens analisados no decorrer deste capítulo, encontram- se:
Avaliação da influência da heterogeneidade das máquinas (diferentes velocidades), da heterogeneidade das tarefas (diferentes tamanhos) e da granularidade das aplicações (variações na relação máquinas por tarefas) no comportamento dos algoritmos desenvolvidos.
Em as seções que seguem, apresenta- se o ambiente de simulação e os cenários de testes utilizados, e por fim a análise dos resultados obtidos.
Ambiente de Simulação Esta seção apresenta o ambiente de simulação utilizado para os testes da abordagem de gerenciamento de eficiência energética em grades computacionais desenvolvida por este trabalho.
O ideal seria realizar os experimentos num ambiente real de grade, pois os resultados seriam mais confiáveis por representarem o comportamento do sistema real.
No entanto, na computação em grade isso é muito raro, pois a construção e manutenção de uma infraestrutura de grade é difícil e financeiramente cara.
Em este cenário, simular o comportamento de ambientes reais de grade torna- se uma alternativa viável, pois não há a necessidade de alocar uma infraestrutura real para realizar experimentos.
Além disso, com o uso de simulação é possível realizar diversos experimentos e combinar diferentes cenários utilizando muito menos tempo.
ESuff, EXSuff, ECI e EDFPLTF foram adicionados ao conjunto de algoritmos de escalonamento implementados na LIBTS.
Cenários de Testes Em esta seção, descreve- se o ambiente utilizado para construir e executar os testes dos algoritmos desenvolvidos.
Bem como, apresentam- se as tarefas utilizadas nos testes realizados, para a avaliação do comportamento, desempenho e consumo de energia dos novos algoritmos de escalonamento em comparação com os já existentes.
Inicialmente, explica- se a granularidade de aplicações utilizadas nos experimentos.
Em seguida, a heterogeneidade das máquinas e das tarefas e, finalmente, a configuração do consumo das máquinas.
Granularidade das Aplicações Definiu-se a granularidade de aplicações, do tipo BoT, com base no trabalho de que estabelece a base para a construção de cenários de teste para experimentos de algoritmos de escalonamento em grade.
Foram construídos três grupos de tarefas compostos por aplicações divididas em diferentes quantidades de tarefas:
29, 144 e 720.
Para cada grupo, há um tamanho médio de tarefa (ver Tabela 2).
O objetivo é configurar diferentes cenários, testando situações em que o número de tarefas é muito menor do que o número de máquinas, e em que o número de tarefas é muito maior do que o número de máquinas.
Em os experimentos as aplicações possuem o mesmo tamanho.
De essa forma, no caso em que o tamanho médio das tarefas é 10 Tflops (grão fino) haverá muito mais tarefas do que quando o tamanho médio das tarefas for de 250 Tflops (grão grosso).
Heterogeneidade das Máquinas Utilizaram-se três plataformas de máquinas, com diferentes níveis de heterogeneidade entre suas máquinas a fim de reproduzir o mais próximo possível a configuração real das grades computacionais.
A velocidade das máquinas é definida de acordo com uma distribuição uniforme, mantendo a média de velocidade de todas as máquinas da grade em aproximadamente 12,36 Gflops.
Os níveis de heterogeneidade das máquinas definidos são (Apêndice A):
Plataforma 1: Baixa heterogeneidade, a velocidade das máquinas varia de acordo com uma distribuição uniforme de 11,23 Gflops até 13,40 Gflops;
Plataforma 2: Média heterogeneidade, a velocidade das máquinas varia de acordo com uma distribuição uniforme de 7,66 Gflops até 14,31 Gflops;
Plataforma 3: Alta heterogeneidade, a velocidade das máquinas varia de acordo com uma distribuição uniforme de 4,71 Gflops até 20,31 Gflops.
Heterogeneidade das Tarefas As tarefas podem ter tamanho médio de 10 Tflops, 50 Tflops e 250 Tflops.
Sendo que, o tamanho das tarefas varia em cada grupo, mas a média de tamanho permanece a mesma do grupo.
A variação no tamanho das tarefas pode levar- las a serem homogêneas a completamente heterogêneas.
Os intervalos utilizados foram de 0%, 25%, 50%, 75% e 100% de variação no tamanho médio das tarefas do grupo.
Por exemplo, para um intervalo de 25% de variação, os tamanhos das tarefas podem apresentar valores de 12.5% abaixo e 12.5% acima de o tamanho médio.
Caso o tamanho médio for de 250 Tflops, o tamanho de cada tarefa variará de 218,75 Tflops a 281,25 Tflops, com o intervalo de 25% de variação.
A aplicação recebe tarefas de acordo com uma distribuição, até que a soma de seus tamanhos alcance o tamanho da aplicação que é de no máximo 7250 Tflops.
Configuração de Consumo das Máquinas Encontrar o poder em flops e consumo em flops/ watt de máquinas &quot;off- the- shelf «não é uma tarefa trivial.
Por essa razão, os valores de consumo de energia em flops/ watt das máquinas utilizadas na simulação, foram definidos conforme a configuração de máquinas reais extraídos dos trabalhos de e.
A Tabela 3 apresenta na primeira coluna a descrição de cada máquina, seguida por os valores do poder computacional, consumo de energia em flops/ watt e em watt, baseados nos trabalhos de e consumo de energia no estado de ociosidade, baseado no.
As máquinas utilizadas como base para a simulação foram escolhidas de acordo com as suas características, tentando manter o ambiente simulado mais realista.
Objetivando construir um ambiente em o qual as máquinas possuem consumos de energia e poder computacional bem variados.
Como pode ser observado na Tabela 3, as máquinas possuem poder computacional variando de 4,7125 Gflops até 20,311 Gflops e consumo de energia variando de 3250000 a 27410000 flops/ watt.
Já os valores relativos ao consumo de energia das máquinas no estado ocioso, foram definidos com base em valores do site Energy Star dependendo do tipo de máquina descrita, variando de 34,57 a 102,1 watts por hora (Apêndice A).
Em o ambiente de simulação construído, as máquinas comunicam- se através de links.
São utilizados 191 links para permitir o envio de tarefas entre a máquina mestre e as escravas.
A fim de simular a distância entre a máquina mestre e uma escrava, a quantidade de links varia.
De essa maneira, para conectar uma determinada máquina escrava ao mestre podem ser utilizados 4 links, enquanto para conectar outra máquina escrava, podem ser utilizados 10 links.
Por essa razão, para que fosse possível calcular o consumo no envio de tarefas entre a máquina mestre e a escrava, foi necessário mapear cada um dos links utilizados por cada canal de comunicação (Apêndice B).
Além disso, também foi preciso, para cada um dos links de comunicação utilizados no ambiente de grade simulado, definir valores de consumo de energia.
Tais valores são baseados em, variando de 2,1 a 13,7 miliwatts/ Mbps (consumo em miliwatts por megabits por segundo transferido) e podem ser observados detalhadamente no Apêndice B. Análise dos Resultados Em esta seção, são apresentados os resultados obtidos nos diferentes cenários de testes descritos anteriormente (Apêndice C).
O objetivo é realizar uma análise a respeito de o comportamento dos algoritmos de escalonamento testados nos quesitos consumo de energia e desempenho.
Plataforma 1 A primeira análise é sobre a plataforma menos heterogênea, a plataforma 1.
Para 29 tarefas, como pode ser observado na Figura 16, as versões estáticas do algoritmo LECSA mostraram- se mais eficientes quanto a o consumo de energia do que os demais algoritmos.
Com 0% de variação no tamanho das tarefas (heterogeneidade das tarefas), o LECSA, se comparado ao segundo menor algoritmo consumidor de energia (DLECSA) tem um ganho de 314,27%.
Quanto a o desempenho, o LECSA tem uma perda de apenas 7,79% em relação a os algoritmos com melhor desempenho, o Suff e o DFPLTF.
Para 25, 50 e 75% de variação, o LECSA, LECSA2 e LECSA3 também são melhores em eficiência energética, sempre apresentando perdas pouco significativas em desempenho.
Entretanto, para 100% de variação, a melhora em relação a o consumo diminui, pois são usadas 29 máquinas, enquanto os demais algoritmos usam uma quantidade menor de máquinas.
Este fator afeta na redução do consumo das versões do LECSA, mas aumenta o seu ganho de desempenho.
Em esse caso, o desempenho do LECSA3 é um dos melhores.
Como podem ser observados, na Figura 17, para 144 tarefas, os ganhos em relação a o consumo de energia são menores que para 29 tarefas.
Para 25% de heterogeneidade das tarefas, a variação com pior perda de desempenho observada, o DLECSA e o DLECSA2 apresentaram uma perda de 76,95% em relação a o melhor algoritmo, o DFPLTF.
Entretanto, para 100% de variação, o LECSA registrou uma perda de desempenho bem menor, de apenas 26,47%, com um ganho de 0,9% em redução de consumo de energia, também em comparação com o DFPLTF.
A Figura 18 por sua vez, ilustra o caso com o maior número de tarefas em o qual a granularidade da aplicação é baixa, ou seja, há muitas tarefas para poucas máquinas.
Tanto as versões estáticas quanto as dinâmicas do LECSA demostraram uma redução no consumo de energia, que foi de no máximo 18,65% para 25% de variação em comparação com o Suff que foi o pior em eficiência energética.
A o analisar a questão desempenho, a pior perda foi demostrada para 25% de variação por os algoritmos DLECSA e DLECSA2.
A perda foi de 78,77%, em comparação com o algoritmo que obteve o melhor desempenho (EWQ).
Já a menor perda de desempenho (19,05%), foi a obtida por o LECSA2 com 100% de variação com uma economia de energia de 0,46% em comparação com o WQ que para este caso foi o melhor em desempenho.
Plataforma 2 Agora analisaremos a plataforma 2, que possui um nível maior de heterogeneidade.
Em virtude de isso, os algoritmos desenvolvidos neste trabalho devem apresentar resultados mais expressivos, no quesito eficiência energética, do que os da plataforma 1.
Inicialmente, para 29 tarefas, as três versões estáticas do LECSA obtiveram valores muito representativos quanto a a eficiência energética sem grandes perdas em relação a o desempenho como apresenta a Figura 19.
Para o caso intermediário, com 50% de heterogeneidade das tarefas, tanto o LECSA quanto o LECSA2, apresentaram uma redução no consumo de energia que atingiu 332,24% em comparação com o pior consumo que foi o obtido por o algoritmo WQR.
Já em relação a o desempenho, para a mesma variação, o LECSA3 foi o melhor, enquanto o LECSA e o LECSA2 apresentaram uma perda de desempenho de apenas 13,61%.
Com 144 tarefas, como se apresenta na Figura 20, a eficiência energética diminui.
Para 100% de variação, é constatada a primeira perda em consumo de energia de todas as versões do LECSA, para alguns dos outros algoritmos testados.
Em comparação com o EDFPLTF, que foi o melhor em relação a o consumo, o LECSA apresentou uma perda de 20,52% em eficiência energética e 74,61% em desempenho.
Entretanto, para 50% de variação o LECSA apresentou um ganho de 11,77% em relação a o consumo de energia, com perda de 57,70% em desempenho, em comparação com o DFPLTF que apresenta o melhor desempenho.
As versões dinâmicas do LECSA também apresentaram uma redução no consumo de energia entre 0 e 75% de heterogeneidade das tarefas.
Para 720 tarefas, como pode ser observado na Figura 21, a perda de eficiência energética permanece para o caso de 100% de heterogeneidade.
Entretanto, para 50% o ganho de eficiência energética do LECSA aumentou, em relação a o caso de 144 tarefas, ficando em 31,28%.
E a perda de desempenho diminuiu, atingindo os 39,29%, em comparação com o Suff que apresenta o melhor desempenho.
Sendo que a perda de desempenho mínima obtida para 720 tarefas foi com 75% de heterogeneidade.
Onde a perda ficou em 9,33%, com ganho de 18,56% em relação a o consumo de energia em comparação com o algoritmo DFPLTF que é o melhor em termos de desempenho para o caso citado.
Plataforma 3 O último caso a ser analisado corresponde ao da plataforma 3, que possui o maior nível de heterogeneidade de máquinas, e portanto, deve apresentar os maiores ganhos de eficiência energética em comparação com os alcançados na plataforma 1 e 2.
Esta grande heterogeneidade de máquinas também faz com que este caso possa ser melhor explorado por os algoritmos desenvolvidos neste trabalho.
Para 29 tarefas, como mostra a Figura 22, há ganho em eficiência energética para todas as variações na heterogeneidade das tarefas.
Por exemplo, com 25% de heterogeneidade o LECSA e o LECSA2 apresentam um ganho de 156,40% em eficiência energética, com apenas 29,51% de perda em desempenho, em comparação com o LECSA3, que é o melhor algoritmo em termos de desempenho.
Já com 100%, em comparação com o DFPLTF, o melhor algoritmo em termos de desempenho, há um ganho de 162,92% em eficiência energética e uma perda de apenas 18,51% em desempenho.
No caso de 144 tarefas, como mostra a Figura 23, para o caso intermediário, com 50% de heterogeneidade, o ganho de eficiência energética do LECSA atinge 76,46%.
Com uma perda de desempenho de 38,93%, em comparação com o algoritmo DFPLTF, que é o melhor em desempenho.
Entretanto, para 100% de variação, o algoritmo ESUFF é o que apresenta o menor consumo de energia, consumindo 92,27% a menos que o DFPLTF (o melhor em desempenho).
Com uma perda de apenas 47,41% em desempenho.
Porém, se o objetivo fosse obter uma perda menor em desempenho e ganhar menos em eficiência energética, o LECSA e o LECSA3 seriam boas alternativas.
Pois, para esse mesmo caso, a perda de desempenho seria de 15,77% e o ganho em consumo de energia de 10,56%.
O último caso a ser analisado é o caso de 720 tarefas, Figura 24.
Para 50% de heterogeneidade, o LECSA apresentou uma redução de 115,63% no consumo de energia, com 47,68% de perda em desempenho em comparação com o WQ que é o melhor em termos de desempenho.
Com essa heterogeneidade, todos os algoritmos desenvolvidos neste trabalho (LECSA, LECSA2, LECSA3, DLECSA, DLECSA2 e DLECSA3) apresentaram uma eficiência energética acima de 45%.
Já para 100% de variação, o melhor em termos de eficiência energética foi o ESUFF com 43,99% de redução de consumo e 48,63% de perda de desempenho em comparação com o EWQ que é o algoritmo que obteve o melhor desempenho.
No entanto, se a intenção for não prejudicar tanto o desempenho, uma opção seria utilizar ou o algoritmo LECSA, ou o algoritmo LECSA3.
Ambos os algoritmos para o mesmo caso apresentado acima possuem um ganho de 29,32% em redução de consumo de energia e perda de apenas 19,81% em desempenho.
Depois de terem sido apresentados os resultados gráfico por gráfico, agora o objetivo é apresentar uma avaliação global dos resultados obtidos para que seja possível analisar qual o comportamento dos algoritmos testados em relação a a granularidade das aplicações, a heterogeneidade das máquinas e heterogeneidade das tarefas.
A seguir, apresentam- se dados extraídos da análise global dos resultados obtidos.
Os dados ilustrados por a Tabela 4 realizam uma comparação do melhor algoritmo em termos de desempenho com o melhor algoritmo em termos de consumo de energia para cada cenário:
O caso que obteve a maior economia de energia foi na plataforma 3 com 29 tarefas e 0% de heterogeneidade de tarefas, com uma perda de 26,56% em desempenho (valores obtidos por o algoritmo LECSA2 em comparação com o melhor algoritmo em termos de desempenho (Suff);
O caso em que houve menor economia de energia foi na plataforma 1 com 29 tarefas e 50% de heterogeneidade de tarefas, com uma perda de 7,08% em desempenho (valores obtidos por o LECSA em comparação com o melhor algoritmo em termos de desempenho, que foi a versão 3 do próprio LECSA);
O caso que atingiu a menor perda de desempenho foi na plataforma 2, com 144 tarefas e 100% de heterogeneidade de tarefas, com redução de 15,55% no consumo de energia (valores obtidos por o algoritmo EDFPLTF em comparação com sua versão original);
O caso em que houve a maior perda de desempenho foi do DLECSA2 na plataforma 3 para 720 tarefas com 0% de heterogeneidade de tarefas, atingindo uma perda de 77,61%, em comparação com o EWQ (o melhor em desempenho).
Porém, o ganho em eficiência energética atingiu 202,25%;
Com 29 tarefas o LECSA2 apresentou para a plataforma 1, 2 e 3, os melhores resultados em termos de maior redução no consumo de energia;
Quanto maior for à heterogeneidade dos hosts, maior é a redução no consumo de energia, entretanto, há maior perda de desempenho;
Quanto maior for à granularidade da aplicação, maior é a economia de energia, entretanto, há uma perda de desempenho, que é no máximo de 34,60%;
Em relação a a heterogeneidade das tarefas, para a plataforma 1 e 3, quanto mais homogêneas forem as tarefas, maior é a redução no consumo de energia.
Quando as tarefas são 100% heterogêneas a redução de consumo de energia fica entre 0,46% e 219,68%;
O algoritmo que obteve o melhor desempenho num número maior de casos, foi o DFPLTF, que aparece em 22 dos 45 casos totais.
O segundo colocado é o EWQ, que aparece em 6 dos 45 casos e em terceiro lugar, aparecem empatados o LECSA3 e o Suff, com 5 ocorrências em 45 casos;
O algoritmo que obteve a melhor eficiência energética num número maior de casos foi o LECSA2, que apareceu em 19 dos 45 casos totais.
O segundo colocado é o LECSA, que aparece em 14 dos 45 casos e em terceiro lugar aparece o ESUFF, com 4 ocorrências em 45 casos.
Quanto a os algoritmos WQ, Suff, XSuff e DFPLTF, que foram modificados para que melhorassem a sua eficiência energética, as versões que globalmente obtiveram as maiores reduções foram:
ESUFF, EWQ e EDFPLTF.
Sendo que, na plataforma 3, as reduções no consumo de energia foram bem mais significativas.
Em a grande maioria dos casos, o consumo de energia foi reduzido por a metade, com ganho também em termos de desempenho.
De modo geral, os algoritmos desenvolvidos neste trabalho, em especial o LECSA, o LECSA2 e o DLECSA, obtiveram ótimos resultados quanto a a eficiência energética, com perdas aceitáveis em desempenho.
Como dito no decorrer deste trabalho, não existe um algoritmo perfeito, que apresente o melhor resultado para qualquer tipo de cenário.
Dependendo das características das máquinas, das tarefas, da rede de comunicação, determinado algoritmo se sobressairá aos demais.
Em virtude de isso, dá- se a importância em se conhecer as características do ambiente de grade ao qual o algoritmo de escalonamento será voltado.
Esta Dissertação teve como objetivos principais:
Desenvolvimento do módulo de cálculo de consumo de energia, apresentado na Seção 4.2;
desenvolvimento de algoritmos de escalonamento energeticamente eficientes, apresentados na Seção 4.3.
Inicialmente, o Capítulo 2 descreve algumas técnicas de escalonamento de tarefas existentes, em seguida apresenta- se o ambiente de simulação utilizado, o SimGrid, juntamente com a arquitetura da LIBTS.
Tal arquitetura foi modificada para que pudessem ser atingidos os objetivos deste trabalho, descritos no Capítulo 4.
Como ponto de partida para os desenvolvimentos descritos nesta Dissertação, realizou- se um estudo referente a as atuais abordagens propostas para melhorar a eficiência energética em ambientes de grade computacional.
Após esse estudo, iniciaramse as modificações na arquitetura original da LIBTS, para adicionar a informação de consumo de energia de cada algoritmo na execução das aplicações.
Sendo esta a primeira contribuição desta Dissertação.
A segunda contribuição deste trabalho deu- se com o desenvolvimento do módulo de cálculo de consumo de energia, que trouxe algumas ideias sobre técnicas de escalonamento de tarefas que poderiam potencialmente reduzir o consumo de energia.
A partir de isso, desenvolveu- se o LECSA, totalmente direcionado para eficiência energética, fato que em alguns casos ocasionava uma perda muito significativa em termos de desempenho.
Por essa razão, na Seção 4.3, foram descritas as outras duas versões do LECSA, todas estáticas.
O desenvolvimento dos três algoritmos de escalonamento estáticos resultou na terceira contribuição deste trabalho.
Como os demais algoritmos, WQ, Suff, XSuff, DFPLTF, ECI, são dinâmicos, a quarta contribuição foi a implementação das versões dinâmicas do LECSA, para fim de comparações de consumo de energia e desempenho, apresentadas na Seção 5.3.
A contribuição mais relevante deste trabalho é a validação do módulo de consumo e dos algoritmos de escalonamento energeticamente eficientes, para uso na ferramenta SimGrid.
O LECSA, o LECSA2 e o DLECSA obtiveram resultados muito significativos em eficiência energética, com perdas aceitáveis em termos de desempenho, principalmente quando o ambiente computacional apresentar alto nível de heterogeneidade entre as máquinas da grade.
Com a análise dos resultados obtidos, pode- se identificar qual algoritmo de escalonamento se torna mais adequado para ganho em eficiência energética ou em desempenho.
Os resultados apresentados nesta Dissertação impulsionaram a proposta de desenvolvimento dos trabalhos futuros.
Uma versão inicial da implementação do módulo de cálculo de consumo e do algoritmo LECSA, rendeu uma aprovação para publicação no ACM-SAC 2013, intitulada:
&quot;Energy Efficiency Management in Computational Grids through Energy--aware «Scheduling».
Trabalhos Futuros Como trabalho futuro propõe- se o desenvolvimento de um escalonador global de aplicações.
Cujo objetivo é que o escalonador seja capaz de decidir qual é a melhor opção de escalonamento em termos ou de redução de consumo de energia ou de desempenho, ou uma boa relação entre consumo e desempenho, conforme a escolha feita por o usuário.
Para que o escalonador seja capaz de tomar decisões de escalonamento ele deverá se basear nas características das tarefas e do ambiente computacional.
Para tal, assim que uma nova aplicação chegar para ser escalonada será necessário verificar a característica da mesma, e em conjunto com as informações das máquinas que compõem a grade, decidir qual é o algoritmo de escalonamento mais adequado para aquele caso.
Este analisador do perfil de aplicações deverá ser baseado em Redes Neurais Artificiais ou Algoritmos Genéticos, pois para decidir qual é o melhor algoritmo de escalonamento para determinada necessidade (desempenho, consumo, ou ambos) deve- se passar por a análise de um histórico de execuções.
O desenvolvimento do escalonador citado acima abrange as seguintes atividades:
Melhoria do módulo de cálculo de consumo de energia;
Implementação de novos algoritmos de escalonamento de tarefas para grades computacionais voltados para desempenho e economia de energia;
Criação de novos cenários de testes;
Realização de novos experimentos para validar os desenvolvimentos realizados.
