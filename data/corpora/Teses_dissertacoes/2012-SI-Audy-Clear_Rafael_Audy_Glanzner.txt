O Desenvolvimento Distribuído de Software (DDS), em nível global, vem sendo utilizado por diversas empresas ao redor de o mundo.
Para auxiliar essas empresas a superar as dificuldades impostas por esse tipo de trabalho, o modelo de capacidade WAVE foi proposto.
No entanto, até a conclusão dessa pesquisa, não era possível utilizar o WAVE efetivamente na indústria, visto que ele não possuía um método de avaliação.
Essa pesquisa propõe um método de avaliação para o WAVE, chamado de 2 DAM-WAVE, possibilitando que as organizações, que desejam implementar as boas práticas do WAVE, descubram em que nível de capacidade se encontram.
Para propor esse método foi realizada uma análise qualitativa de métodos de avaliação existentes, após isto, o resultado foi aplicado numa unidade brasileira de uma organização global e numa unidade indiana de outra organização global, através de dois estudos de caso.
Com o resultado dessa pesquisa um método de avaliação para o WAVE, intitulado 2 DAM-WAVE, e uma ferramenta de apoio para conduzir e facilitar esse processo foram desenvolvidos.
Palavras Chave: Desenvolvimento Distribuído de Software, Modelo de Capacidade, Métodos de Avaliação.
A crescente globalização das últimas décadas tem causado impacto em muitos ramos da indústria e, este fenômeno, não foi diferente no desenvolvimento de software.
A partir de estas transformações, originou- se o Desenvolvimento Distribuído de Software (DDS), que se caracteriza como um projeto de software desenvolvido por equipes dispersas em escala regional, nacional ou global.
Este tipo de abordagem vem atraindo a atenção da academia e das organizações, pois, se utilizado de forma madura, os conceitos do DDS podem auxiliar as empresas na diminuição de custos, no time- to-- market e no aumento de sua presença global, entre outras vantagens.
O interesse, no seu desenvolvimento e uso, torna- se evidente ao se verificar que 300 das 900 empresas-membros da NASSCOM (Associação Nacional das Empresas de Software), localizada na Índia, trabalham com DDS no modelo Offshore Insourcing.
Este modelo caracteriza- se por o desenvolvimento de software distribuído globalmente dentro de uma mesma organização, enquanto que no modelo Offshore Outsourcing, ocorre a terceirização de uma parte do projeto para outra organização presente em outro país.
Apesar de o DDS ser uma área recente, seu amadurecimento perpassa por o entendimento de como as práticas têm evoluído ao longo de o tempo.
Boa parte da literatura existente, que aborda a evolução das práticas em DDS em escala global, concentra- se em seus aspectos estratégicos, tais como, as decisões de se estabelecer centros de DDS e as relações entre cliente e fornecedor.
Percebe- se, também, que a maioria dos estudos tem se concentrado no modelo de offshore outsorcing, e sob a perspectiva das contratantes.
Mas, além de existir um crescimento na estratégia de internal offshoring, as organizações têm enfrentado diversos desafios do ponto de vista técnico.
Alguns estudos destacam a importância de se pensar na evolução do DDS de forma unificada, incluindo aspectos técnicos, não técnicos e organizacionais.
No que diz respeito ao desenvolvimento distribuído de software, na perspectiva do modelo Offshore insourcing, não havia nenhum modelo de capacidade com o objetivo de auxiliar as empresas a melhorar continuamente seus processos organizacionais, tanto os técnicos quanto os não técnicos.
Para preencher esta lacuna, o modelo de capacidade WAVE foi concebido, sugerindo melhorias nas áreas de pessoas, projetos, unidade e portfólio.
Para que uma organização possa atestar a qualidade de seus processos em relação a o modelo de capacidade WAVE, um método de avaliação torna- se necessário.
Métodos de avaliação devem ser capazes de identificar as forças e as fraquezas do processo de software da organização para determinar uma efetiva ação de melhoria.
Existem métodos de avaliação com objetivos, contextos e abordagens diferentes e que variam, principalmente, em sua forma e duração para execução.
Tais diferenças, nos modelos de avaliação, são importantes para atender as organizações e suas diferentes demandas, estejam elas procurando por avaliações iniciais e rápidas ou abrangentes e detalhadas.
Avaliações tendem a demandar bastante tempo e recursos, visto que, normalmente, possuem etapas como:
Entrevistas, análises de artefatos, manipulação de planilhas de resultados, entre outros.
Essa pesquisa propõe um método de avaliação, o 2 DAM-WAVE (Two Dimensional Assessment Method for WAVE), para o modelo WAVE a fim de preencher essa lacuna.
Este método contem duas dimensões, a saber:
A dimensão chamada &quot;miniavaliação», que entrega de forma rápida um indício da capacidade dos processos da organização e a dimensão chamada &quot;mais abrangente», que além de informar o nível de capacidade da organização, também proporciona sugestões de melhorias.
Para diminuir a complexidade da aplicação das avaliações do 2 DAM-WAVE, bem como a sua necessidade de recursos, também foi criada uma ferramenta de apoio.
Justificativa A adoção do DDS por as organizações vem aumentando na última década, no entanto nota- se que os estudos sobre o modelo de negócio Offshore Insourcing foram menos explorados e de forma inconsistente.
A necessidade de uma maior investigação sobre o modelo de negócio de Offshore Insourcing fica ainda mais evidente ao se notar que 36% do mercado brasileiro de serviços offshore foi nesse modelo de negócio.
Para suprir essa lacuna, o modelo de capacidade WAVE foi construído.
No entanto, esse modelo não podia ser aplicado, visto que não havia nenhum método de avaliação para o modelo.
Construir um método de avaliação para o modelo WAVE é importante para o uso efetivo do mesmo por a indústria e, também, por a academia.
Com este método proposto, é possível avaliar o nível de capacidade de empresas, propondo melhorias baseadas nos resultados da avaliação.
Além disso, organizações podem, com posse dos resultados dessas avaliações, traçar planos de melhorias para suas unidades e tomar decisões estratégicas embasadas nas avaliações do WAVE.
A importância de métodos de avaliação para modelos de qualidade é percebida ao se verificar que os dois principais modelos de melhoria internacionais, CMMI e ISO 15504, além de outros, possuem métodos de avaliação.
Exemplos de modelos de qualidade e seus métodos de avaliação são o CMMI e SCAMPI, ISO 15504 e SPICE, MPS.
Br e MA-MPS, entre outros.
Sem esses métodos de avaliação seria impossível identificar em qual nível de maturidade determinada empresa estaria em relação a o CMMI, o MPS-BR, o MMGP ou tantos outros modelos.
Sintetizando, a questão de pesquisa que norteia este estudo é:
Como avaliar uma empresa no modelo de capacidade WAVE?
Objetivos O objetivo geral desta pesquisa é propor um método de avaliação para o modelo de capacidade WAVE, beneficiando organizações que desejam aumentar a sua capacidade em DDS embasando- se nas melhores práticas propostas por o WAVE.
Para atingir o objetivo geral os seguintes objetivos específicos foram identificados:
Aprofundar os estudos da base teórica;
Propor o método um método de avaliação;
Criar uma ferramenta de apoio à aplicação do método de avaliação proposto;
Testar o método de avaliação proposto;
Escrever artigos científicos relacionados à pesquisa.
Estrutura Para alcançar os objetivos propostos, este trabalho possui a seguinte estrutura:
Em o capítulo 2, de embasamento teórico, o conceito de DDS, o modelo de capacidade WAVE e os principais modelos de qualidade e seus métodos de avaliação são explicados.
Além disso, na seção 2.6, também são apresentados os trabalhos relacionados.
Em o capítulo 3 o método de pesquisa é explicado.
Em os capítulos 4 e 5 o método de avaliação 2 DAM-WAVE e a sua ferramenta de apoio são apresentados respectivamente.
Em o capítulo 6 os dois estudos de caso realizados são detalhados junto com seus resultados e uma análise crítica sobre os dados coletados.
Em o capítulo 7 as considerações finais são apresentadas.
Em a seção 2.1, explica- se o que é DDS, suas possíveis configurações, suas vantagens e desvantagens.
Em a seção 2.2, será detalhado o modelo WAVE, explanando porque ele foi proposto, quais são os seus objetivos e estrutura.
Em a seção 2.3 e 2.4 definem- se modelos de capacidade ou maturidade e métodos de avaliação respectivamente.
Em a seção 2.5 os modelos de capacidade e maturidade mais encontrados durante a revisão da literatura são apresentados juntamente com seus métodos de avaliação.
Por fim, na seção 2.6 são descritos os trabalhos relacionados.
Desenvolvimento Distribuído de Software O DDS em escala global, também conhecido como Global Software Development (GSD), define- se como o desenvolvimento de um projeto de software em que a equipe de desenvolvedores não se encontra no mesmo ambiente físico, mas em países diferentes.
A cada ano que passa, percebe- se um aumento na quantidade de organizações aderindo ao desenvolvimento de software global.
Esta tendência fica evidenciada ao analisarmos, segundo dados da Revista Fortune 500, que, no ano de 1990, apenas 23 das maiores empresas americanas tinham uma relação de offshore outsorcing, enquanto que, no ano de 2002, este número passou para 260 empresas.
Existem diversos fatores que podem incentivar as organizações a trabalhar com DDS, principalmente se a distribuição for global.
As principais motivações para se adotar o DDS estão descritas a seguir. --
Demanda e Custos A crescente demanda por grandes sistemas computacionais, que atinjam as necessidades de organizações globalizadas, têm aumentado a busca de profissionais qualificados em projetos de desenvolvimento de software.
Chegou- se a um ponto em que construir projetos co-localizados em países desenvolvidos tornou- se muito caro e a mão de obra qualificada, para tal ação, passou a ser de difícil acesso.
Em esse contexto, o DDS passou a ser uma alternativa para contratações de profissionais aptos e com custo mais acessível. --
Rapidez de resposta ao mercado A distribuição de tarefas em diversas equipes distribuídas globalmente pode, se bem implementada, diminuir o time- to-- market de seus softwares e produtos. --
Mercado e presença global As empresas podem criar unidades em outros países buscando diminuir a distância com o seu mercado consumidor alvo, facilitando, por exemplo, esforços de venda e suporte.
Além disso, essa estratégia pode ser utilizada como marketing, pode atrair incentivos fiscais, entre outras vantagens. --
Rigor e experiência de desenvolvimento A fim de se obter sucesso no ambiente DDS, as empresas devem investir na melhoria de seus processos, buscando diminuir a informalidade de comunicação, pois os membros da equipe não estão co-localizados.
Este problema, uma vez tratado, pode ser visto como uma vantagem para as empresas que desejam melhorar os seus processos. --
Sinergia Cultural Empresas com equipes globalizadas se utilizam de colaboradores com práticas e experiências diferentes e, esta diversidade, propicia que o processo criativo seja mais produtivo e, ainda, ajuda a manter a organização atualizada e receptiva a novas ideias e soluções. --
Escala Trabalhar com DDS facilita na escalabilidade numa empresa.
À medida que a demanda por projetos ou profissionais aumenta, uma empresa pode abrir novas unidades ou ampliar as já existentes.
Existem diversas configurações possíveis dentro de o DDS, sendo que todas apresentam benefícios e desafios diferentes.
Equipes de um determinado projeto distribuído de software podem estar &quot;co-localizadas «ou ter uma distância, que as separa, de dimensão &quot;Nacional», &quot;Continental «ou &quot;Global».
Quando uma empresa inicia um projeto caracterizado por a distância &quot;Continental «ou &quot;Global», ela está trabalhando com Offshore, ou seja, está distribuindo o trabalho para fora de o seu país de origem.
Caso ocorra o contrário, isto é, se o projeto é distribuído dentro de o mesmo país, diz- se que ele é Inshore.
Existe ainda a definição de &quot;Nearshore», criada recentemente, para categorizar projetos distribuídos caracterizados por a distância continental ou entre países que tenham um fuso-horário, cultura ou língua parecidas.
Além de a definição de dispersão entre equipes, existem definições sobre a relação profissional entre estas equipes.
Esta definição depende, basicamente, de qual ou quais empresas os profissionais pertencem.
Os dois conceitos mais utilizados são &quot;Insourcing «e &quot;Outsourcing».
O conceito de &quot;Insourcing «surge quando o projeto é feito dentro de uma única empresa, ou seja, se todas as equipes pertencem a uma mesma empresa.
Por outro lado, o conceito de &quot;Outsourcing «ocorre quando uma empresa terceiriza serviços à outra empresa Considerando a distribuição geográfica e a relação entre empresas, podemos abordar os projetos de DDS dentro de quatro categorias:
&quot;Offshore Insourcing», &quot;Offshore Outsourcing», Inshore Insourcing &quot;e «Inshore Outsourcing», conforme exibido na Figura 1.
É importante destacar que existem outras formas de categorização devido a constante evolução da área.
Embora este tipo de desenvolvimento projete a obtenção de diversos benefícios para as empresas, o DDS também pode acentuar diversas dificuldades encontradas no desenvolvimento de software co-localizado.
Além disso, o DDS ainda impõe novos desafios que podem resultar na falha do projeto se as mesmas não forem mitigadas.
Os principais desafios do DDS podem ser divididos nas seguintes categorias:
&quot;Pessoas», &quot;Processos «apresentados na Tabela 1.
Em DDS, a equipe do projeto está distribuída e, por isto, é preciso atentar a dificuldades como, por exemplo, a percepção das tarefas desenvolvidas e a aquisição de confiança.
Desafios que compreendem a comunicação, coordenação e habilidades interpessoais são agregados na categoria de pessoas. --
Projetos Desafios relativos à engenharia de software, como arquitetura de software, engenharia de requisitos, processos de desenvolvimento, entre outros, tornam- se mais complicados em projetos distribuídos e estão agrupados na categoria de projetos. --
Organização Por último, na categoria de organização, estão aqueles desafios que não estão no escopo do projeto, mas sim da empresa como um todo.
Como exemplo, é possível destacar:
Propriedade intelectual, incentivos fiscais e tributários e seleção e alocação de projetos.
O modelo de capacidade WAVE tem como objetivo auxiliar as unidades das organizações a aumentar a sua capacidade para desenvolver projetos com equipes globalmente distribuídas.
O modelo WAVE foi o primeiro modelo de capacidade criado com foco em empresas que atuam no contexto de offshore insourcing, mas o WAVE também pode ser usado por empresas que trabalhem com offshore outsorcing.
O WAVE é estruturado em &quot;Níveis de Capacidade», &quot;Áreas de Capacidade», &quot;Atributos de Capacidade», Objetivos e &quot;Práticas».
O modelo é dividido em quatro grandes áreas de capacidade:
&quot;Pessoas», &quot;Projetos», &quot;Portfólio «e &quot;Unidade».
Cada uma destas áreas de capacidade agrupam atributos de capacidade de naturezas comuns.
Os atributos de capacidade, por sua vez, são pontos que devem ser monitorados quando se trabalha no contexto de GSD.
Para citar um exemplo, a área de capacidade de &quot;Pessoas «tem uma série de atributos de capacidade relacionados a pessoas como:
&quot;Diferenças Culturais», &quot;Gestão de Conhecimento», Treinamento em Desenvolvimento Distribuído de Software», entre outros.
Cada um destes atributos de capacidade possui um objetivo, que descreve os benefícios que este atributo de capacidade traz para a empresa, caso ele seja bem implementado.
Além disso, atributos de capacidade enumeram uma série de práticas e, à medida que estas práticas vão sendo implementadas, obtém- se uma capacidade maior em lidar com este atributo.
A Tabela 2 mostra a composição do atributo de capacidade &quot;Treinamento em GSD».
Entender as necessidades de treinamento nas diversas unidades, de forma a melhorar a política de treinamento para as equipes e projetos distribuídos.
Nível 2 Prática 2 Existe um programa para treinamentos técnicos e não técnicos nas unidades.
Em o modelo WAVE pode- se definir o nível de capacidade de uma unidade em três escalas:
Por atributos, por área de capacidade ou geral.
Sempre que uma empresa implementa práticas de um atributo, ela aumenta sua capacidade neste atributo.
Dependendo do atributo de capacidade e do nível desejado, mais ou menos práticas devem ser implementadas.
Em o exemplo da Tabela 2 duas práticas são necessárias para atingir o nível dois no atributo de capacidade &quot;Treinamento em DDS «e apenas uma para atingir o nível três.
A o se conquistar, por exemplo, nível dois de capacidade em todos os atributos da área de capacidade de pessoas, obtém- se o nível dois na área de capacidade de pessoas.
De a mesma forma, ao se conquistar o nível dois em todas as áreas de capacidade, a unidade conquista nível dois de capacidade no modelo WAVE.
É importante salientar que uma unidade não pode obter um nível X se ela não tiver implementado todas as práticas do nível imediatamente anterior.
A Figura 2 mostra todos os atributos de capacidade e quais práticas devem ser atingidas para se obter um determinado nível de capacidade do modelo WAVE.
O modelo WAVE tem uma escala de quatro níveis de capacidade:
Ad-hoc (nível um), capacitação (nível dois), preparação (nível três) e integração (nível quatro).
Estes níveis foram baseados no modelo eSCM.
Em o primeiro nível, ad-hoc, encontram- se aquelas unidades que estão num nível inicial no uso de GSD, implementando poucas práticas e normalmente sem nenhum embasamento ou plano de melhoria.
Unidades no segundo nível, em capacitação, são aquelas que já implementaram práticas básicas que facilitam a execução de projetos no contexto de GSD.
As iniciativas de melhoria são normalmente orientadas para projetos inteiros e raramente para toda a unidade.
Estes esforços ainda são feitos sob demanda, dificilmente tendo sido planejados por a organização previamente.
Os atributos de capacidade, mais exigidos neste nível, são os de pessoas, pois é determinante que as equipes envolvidas estejam treinadas para esta troca de paradigma.
Quando uma organização e as unidades adquirem mais experiência em projetos distribuídos globalmente, as iniciativas do nível dois do WAVE são expandidas.
Melhorias antes aplicadas num único projeto demandante, quando chegam ao nível de preparação, passam a ser aplicadas num grupo de projeto, na unidade ou até mesmo em todas as unidades.
Os projetos contam com equipes distribuídas, pouco integradas e normalmente gerenciadas de forma individual.
Por fim, as unidades no nível de capacidade de integração já podem ter projetos com dependências entre mais de uma unidade, em cenários mais complexos e, além disso, padrões para o trabalho no contexto de DDS são criados num nível organizacional.
Modelos de Capacidade ou Maturidade Um modelo de capacidade ou maturidade normalmente tem como objetivo indicar o quão capaz ou madura uma organização é em determinada área ou atividade além de auxiliar a mesma a melhorar seus processos através de uma coleção de melhores práticas.
Existem diversos modelos de capacidade e/ ou maturidade para diversas áreas de estudo e estes não são exclusivos da área de engenharia de software.
CMM, CMMI, ISO 15504 e MPS.
Br são alguns exemplos.
Estes modelos são adotados por muitas organizações, pois se embasam em estudos acadêmicos e nas melhores práticas utilizadas na indústria, transformando- se em excelentes guias para organizações que buscam melhorar os seus processos.
Além disso, organizações com níveis de maturidade e/ ou capacidade considerados altos em modelos prestigiados na indústria, utilizam- se destas conquistas para a promoção e captura de clientes que exijam fornecedores com altos níveis de qualidade.
Existem diferenças relevantes entre modelos de capacidade, maturidade e modelos que agregam as duas configurações.
Os modelos de maturidade são organizados por estágios, sendo que uma empresa evolui de estágio implementando diversas melhorias que em conjunto aumentam a maturidade da mesma.
Os modelos de capacidade são diferentes, pois não há o conceito de estágio, mas sim de continuidade.
Em os modelos de capacidade, uma empresa pode escolher uma ou mais áreas do modelo para se aperfeiçoar.
Desta forma, empresas podem obter nível máximo em algumas áreas e nível mínimo em outras.
Método de Avaliação Modelos de capacidade ou maturidade são mais facilmente aplicados se possuírem pelo menos um método de avaliação.
Um método de avaliação é definido como um conjunto de atividades que devem ser executadas para conduzir adequadamente uma avaliação.
Os métodos de avaliação normalmente levam em consideração os objetivos e restrições da empresa.
Sem estas informações, sua validade é posta à prova, pois não gerará os benefícios esperados por a organização.
As avaliações são aplicadas nas empresas em diferentes contextos e com objetivos distintos.
Avaliações podem ser realizadas com uma equipe interna da empresa com o objetivo de medir a evolução dos seus processos e a real efetividade das melhorias implantadas.
Em outros casos, avaliações são conduzidas com equipes externas, com o objetivo de certificar uma empresa num determinado nível de maturidade ou capacidade.
Avaliações podem ter diversos escopos, configurações e objetivos.
Seja qual for o caso, é importante que a avaliação reflita o estado de uma organização e que as melhorias sugeridas sejam realmente relevantes aos objetivos da organização.
Para isto, é importante que a avaliação seja focada nos processos que devem ser efetivamente melhorados e que, caso a lista de melhorias seja muito grande, as mesmas sejam colocadas em escalas de prioridades.
Existem diversos métodos de avaliação propostos e utilizados em diferentes modelos de maturidade e/ ou capacidade, cada um de eles com características, vantagens e desvantagens distintas.
SCAMPI, MA-MPS, CBA IPI, são alguns exemplos de métodos de avaliação.
Modelos de Maturidade e/ ou Capacidade e seus Métodos de Avaliação Em esta seção serão explorados os principais modelos de maturidade e/ ou capacidade existentes, assim como os seus respectivos métodos de avaliação.
Para isso, foi realizada uma extensa pesquisa de artigos nas bibliotecas IEEE, Elsevier e anais da sociedade brasileira de computação em busca de métodos de avaliação para modelos de referência de qualidade na área de desenvolvimento de software.
Os modelos mais encontrados nos artigos foram o CMM, CMMI e ISO 15504.
Além disso, esses modelos são os principais e mais utilizados modelos de melhoria internacionalmente.
Os modelos MPS.
Br e MMGP foram os mais utilizados de entre os modelos brasileiros.
Modelos como o OPM3, PMMM, KPMMM, P3 M3, CobiT, Six Sigma e Itil também foram estudados, mas eles não apareceram em artigos suficientes para serem considerados relevantes para esse trabalho.
O Capability Maturity Model (CMM) foi criado com o objetivo de auxiliar as organizações a aperfeiçoar a qualidade final de seus produtos.
Seu foco é na melhoria da efetividade, da previsibilidade e do controle dos processos de software de uma organização.
O CMM pode ser dividido em cinco níveis de maturidade:
&quot;Inicial», &quot;Gerenciado», &quot;Definido», &quot;Gerenciado Quantitativamente «e &quot;Otimizado».
Os níveis e as características das empresas em cada um desses estágios estão ilustrados na Figura 3.
O CMM contém, dentro de cada um de seus níveis, sub-níveis, chamados de áreas-chave de processo (KPA).
&quot;Planejamento de Projeto», Medição e Análise &quot;e «Gerência de Configuração «são algumas das KPAs do nível dois de maturidade do CMM.
Cada uma dessas KPAs possui um conjunto de metas que devem ser atingidas para aumentar o nível de maturidade da empresa.
Essas KPAs possuem características comuns, que organizam práticas-chave.
Existem cinco características comuns compartilhadas entre todas as KPAs, que são:
&quot;Compromisso para fazer», &quot;Habilidade para fazer», &quot;Atividades realizadas», &quot;Aferição análise», Inspeção de implementação».
Esse método de avaliação foi desenvolvido por a Software Engineering Institute (Sei) para avaliar uma organização sobre o modelo CMM e foi publicado em 1995.
O método foi desenvolvido para ser totalmente compatível com o CMM Appraisal Framework (CAF).
Estas avaliações mostram os pontos fortes e fracos dos processos avaliados.
Com isso a empresa, a partir de seus objetivos de negócio, pode priorizar as melhorias mais relevantes.
Além disso, a avaliação CMM Based Appraisal ­ Internal Process Improvement (CBAIPI) é robusta o suficiente para avaliar o nível de capacidade e maturidade dos processos em relação a o CMM.
Por ser uma avaliação padrão, os resultados de uma empresa podem ser comparados com a de outra para identificar o nível de maturidade de processos nas diferentes organizações.
Em o CBA-IPI as avaliações são conduzidas por uma equipe treinada no método de avaliação e no modelo CMM.
A equipe de avaliação é composta de profissionais autorizados por o Sei e pelo menos um integrante da empresa avaliada.
As informações utilizadas para a avaliação da empresa são provenientes de análise de documentos, resposta de questionários e entrevistas com uma série de profissionais da empresa.
Este método é composto de três etapas, a de planejamento, a de execução e a de apresentação de resultados.
Em a primeira etapa, são realizadas atividades como definição de objetivos da avaliação, treinamento do CMMI para a equipe de avaliação, explicação dos procedimentos de avaliação, entre outras atividades de planejamento e preparação.
Em a segunda etapa as técnicas de coleta de dados são postas em prática.
Esses dados são organizados e depois consolidados.
Finalmente, na fase 3, os resultados da avaliação são apresentados para a empresa e enviados para a base de dados do Sei.
Ao contrário de o CBA-IPI, o CMM Based Appraisal -- Software Capability Evaluation (CBA-SCE) é uma avaliação voltada para a aquisição de software, ajudando na escolha do fornecedor e possibilitando monitorar os processos de fornecedores já contratados.
Esta avaliação abrange os projetos já finalizados, aqueles que estão em andamento, assim como os que ainda estão em fase de prospecção.
A coleta de dados é realizada através de uma equipe externa à empresa avaliada.
Os dados disponibilizados possibilitam aos interessados na avaliação melhor embasamento para tomada de decisão O ciclo de uma avaliação CBA-SCE, quando utilizado para escolha de fornecedor, pode ser verificado na Figura 5.
A primeira parte consiste em decidir ou não por o uso de uma avaliação CBA-SCE.
Depois deve- se colocar na Request for Proposal (RFP) como as empresas concorrentes terão que disponibilizar as informações para a avaliação SCE.
Ao mesmo tempo, deve- se selecionar e treinar a equipe que conduzirá a avaliação.
Em a segunda parte os avaliadores iniciam o processo de coleta de informações das empresas que foram consideradas competitivas.
A análise destas informações coletadas demonstrará os pontos fracos, fortes e oportunidades de melhoria.
Os resultados serão, então, apresentados à organização que requisitou a avaliação no formato pré-acordado.
Decisão sobre o uso da avaliação SCE.
Recebimento das propostas.
RFP liberada.
Determinar classificação e riscos técnicos Comunicar resultados.
Deve se levar em consideração que nem toda aquisição de software é indicada para aplicar o SCE, deve- se primeiro medir o custo-benefício.
Os fatores mais importantes que devem ser considerados por uma empresa antes de aplicar o SCE são os seguintes:
&quot;criticidade da aquisição», &quot;valor total da aquisição», &quot;controle (gerenciamento)», &quot;precedência do software», &quot;ciclo de vida do projeto», &quot;tempo do projeto «e &quot;tamanho do software».
O CMMI é uma evolução dos modelos CMMs.
A criação dos modelos CMMs ajudaram muito as empresas que os utilizaram ao longo de os anos, percebendo aumento de produtividade, qualidade, precisão dos prazos, entre outras vantagens.
Porém, cada um dos modelos CMM focava numa disciplina diferente e, por conta desta característica, empresas que necessitavam implementar mais de um modelo ao mesmo tempo enfrentavam dificuldades.
Visando acabar com o problema o Sei criou o CMMI, o qual buscava integrar os modelos SW-CMM, SECM e IPD-CMM.
Os mesmos foram escolhidos por a sua aceitação, popularidade e abordagem sobre a melhoria de processos.
O resultado foi um modelo flexível que comporta mais de uma abordagem para melhorias de processos e que suporta empresas novatas e experientes no modelo CMM.
O CMMI é composto de uma coleção de &quot;áreas de processo».
As áreas de processo são um conjunto de práticas relacionadas a uma a uma área que, quando implementadas, satisfazem a um conjunto de metas consideradas importantes para realizar melhorias significativas naquela área.
São 22 no total, &quot;Análise e Resolução de Causas e Gestão de Configuração «são dois exemplos.
Cada uma das áreas de processos é composta de diversos componentes.
Elas iniciam com a descrição de seus objetivos, notas introdutórias para contextualizar os principais conceitos abordados e as áreas de processo relacionadas.
As áreas de processos agregam um conjunto de metas específicas (SG) e genéricas (GG).
As metas específicas descrevem as características que devem estar presentes para que a área de processos seja implementada corretamente.
Por outro lado, as metas genéricas não são exclusivas de uma área de processos, elas são compartilhadas por diversas áreas ao mesmo tempo.
Elas descrevem características para institucionalizar a área de processo em questão, além de tornar seus processos duradouros e efetivos.
O CMMI permite que uma organização evolua de forma contínua ou por estágios.
De a forma contínua, uma organização pode fazer a avaliação somente sobre determinadas áreas de processos e obter maturidades diferentes em cada uma de elas, evoluindo somente as áreas que lhe forem mais relevantes.
Por outro lado, na evolução por estágios, a organização segue um caminho estruturado e sistemático para evolução de processos proposto por o Sei.
Além disso, a abordagem por estágios é muito utilizada para comparação de qualidade de processos entre diferentes organizações.
O Standard CMMI Appraisal Method for Process Improvement (SCAMPI) é uma família de métodos de avaliação para o modelo de referência CMMI e foi desenvolvido por o Sei.
Esses métodos são utilizados para avaliar os pontos fortes e fracos dos processos de uma empresa, revelar riscos e, em alguns casos, determinar a capacidade ou maturidade de uma empresa.
Esses métodos são normalmente utilizados em programas de melhorias de processos ou para avaliar possíveis ou atuais fornecedores.
O SCAMPI possui diferentes métodos de avaliação para cada uma das classes do ARC, modelo de avaliação que define requisitos para avaliação do modelo CMMI, e se chamam &quot;SCAMPI «A», &quot;SCAMPI B «e &quot;SCAMPI C».
O SCAMPI A é o mais rigoroso, pois satisfaz todos os requisitos do modelo ARC classe A. Com uma avaliação nestes moldes, a organização consegue descobrir o seu nível de maturidade ou capacidade.
Estas avaliações são feitas obrigatoriamente por os avaliadores oficiais do Sei e são as que necessitam de mais recursos e tempo para serem completadas. --
SCAMPI B e C As avaliações de classe B são miniavaliações e, normalmente, precedem as avaliações do tipo A, com o objetivo de auxiliar na preparação da organização para a avaliação do tipo A. Além de isto, estas avaliações são utilizadas para identificar oportunidades de melhoria.
Por ultimo, as de classe C, também conhecidas como gap analisys, são utilizadas para identificação de melhorias coerentes aos objetivos da empresa sem despender de muitos recursos.
Ambas as avaliações B e C podem ser realizadas sem avaliadores externos à empresa avaliada, mas não indicam oficialmente o nível de maturidade da empresa avaliada no CMMI.
Os três métodos de avaliação possuem as mesmas fases, o que muda são as atividades presentes em cada uma de elas.
Essa distinção é feita na Tabela 3: Sua elaboração iniciou em 1993 com o projeto intitulado SPICE.
Esse projeto foi desenvolvido por a International Organization for Standardization (Iso) junto com colaboração da comunidade internacional.
A norma Iso/ IEC 15504 tem dois objetivos, a determinação da capacidade de processos de uma organização e a melhoria dos mesmos.
Quando a norma é utilizada para avaliação dos processos, deve- se selecionar um conjunto de processos-chave e, com a avaliação, pode- se indicar os pontos fortes, fracos e riscos inerentes aos processos escolhidos.
Além disso, uma empresa pode avaliar fornecedores em potencial, aplicando a norma Software Process Improvementand Capability Determination (SPICE) para estimar o risco potencial ao se contratar um determinada prestadora de serviços, auxiliando na tomada de decisão A coleção das melhores práticas agregadas na norma são organizadas e classificadas em categorias de processos e níveis de capacidade.
Cada uma das categorias de processo é detalhada em processos mais específicos, ou subcategorias (cliente-fornecedor, engenharia, projeto, suporte e organização).
Cada um dos processos pode ter sua capacidade avaliada, podendo ser classificado como incompleto, executado, gerenciado, estabelecido, previsível ou otimizado.
A norma não apresenta nenhum método de avaliação de forma explícita, mas descreve quais são os requisitos mínimos para uma avaliação.
A Figura 7 mostra os requisitos para a avaliação da norma.
As entradas da avaliação devem conter informações relevantes à empresa que está sendo avaliada como objetivo, processos escolhidos, papéis dos entrevistados, entre outros.
Os resultados da avaliação são indicados como saída, compreendendo identificação de resultados, perfil dos processos e outros entregáveis.
Todo o método de avaliação deve possuir cinco processos principais:
&quot;Planejamento», &quot;Coleta de Dados», &quot;Validação de Dados», &quot;Classificação dos Atributos de Processo e Preparação «e Divulgação dos Resultados.»
Durante o planejamento da avaliação, tarefas como alocação de recursos necessários, descrição das tarefas realizadas, cronograma, entre outras são realizadas.
Em a coleta de dados são coletadas as evidências que servirão como base para o resultado da avaliação.
Depois de coletados os dados, deve- se fazer uma verificação para garantir que os mesmos são consistentes e suficientes para a avaliação de todos os processos escolhidos para avaliação.
Finalmente é definida a capacidade de cada atributo de processo, tomando como base para a decisão as evidências objetivas encontradas.
Este processo deve ser registrado e deve indicar quais evidências implicaram na capacidade do processo.
Por último, o resultado da avaliação deve conter as saídas do processo de avaliação e as mesmas devem ser entregues ao patrocinador da avaliação.
Visando melhorar os processos de desenvolvimento de software de empresas brasileiras, a Associação para Promoção da Excelência do Software Brasileiro (SOFTEX) coordenou o desenvolvimento do modelo MPS.
Br.. O programa MPS.
Br foi inspirado nas seguintes normas internacionais:
Iso/ IEC 12207 e Iso/ IEC 15504 e no modelo CMMI.
O foco do MPS.
Br é a micro, pequena e media empresa.
Uma das vantagens do MPS.
Br é o custo de implantação e certificação muito reduzido em comparação com o CMMI.
O modelo MPS.
Br possui três componentes:
&quot;Modelo de Referência (MRMPS)», &quot;Método de Avaliação (MA-MPS) e «Modelo de Negócio (MN-MPS).
Esses componentes são descritos através de guias, que são:
&quot;Guia Geral», &quot;Guia de Aquisição», &quot;Guia de Avaliação e Guia de Implementação&quot;[ SOF11d, SOF11f, SOF11g, SOF11h, SOF11i, SOF11j, SOF11k, SOF11l, SOF11m, SOF11n].
O Guia Geral contém a descrição geral do modelo de referência MPS.
Br.. O Guia de Aquisição tem o objetivo de apoiar instituições que queiram adquirir produtos de software.
O Guia de Avaliação apresenta os processos e o método de avaliação do modelo MPS.
Br, chamado de MA-MPS.
Por último, os guias de avaliação fornecem orientações para melhorar os níveis de maturidade das empresas através do MR-MPS.
O modelo conta com os seguintes níveis de maturidade:
G (Parcialmente Gerenciado), F (Gerenciado), E (Parcialmente Definido), D (Largamente Definido), C (Definido), B (Gerenciado Quantitativamente) e A (Em Otimização).
Estes sete níveis, se comparados com os cinco níveis do CMMI, facilitam a percepção da evolução da empresa em prazos menores.
Para uma empresa avançar um nível de maturidade, ela vai precisar atender aos propósitos de uma série de processos e, cada um de eles, deverá ter uma capacidade mínima alcançada.
Cada processo possui um propósito que descreve o objetivo geral do mesmo.
Um processo possui também resultados esperados, obtidos depois de sua aplicação.
A capacidade do processo indica o grau de refinamento e institucionalização de um processo.
Um processo torna- se mais capaz ao atender atributos de processos, que são descritos através de resultados esperados.
A definição de capacidade, atributos de processos e resultados esperados é geral para todos os processos.
À medida que a organização avança os níveis do MPS.
Br, mais atributos de processos são exigidos de todos os processos.
O MA-MPS é aderente à norma Iso/ IEC 15504 e possui semelhança com o método SCAMPI.
O objetivo do método é permitir a uma empresa a avaliação dos seus processos de software e atribuição de um nível de maturidade com o resultado.
Além disso, o MA-MPS tem como objetivos ser aplicável a qualquer domínio na indústria de software ser aplicável organizações/ unidades organizacionais de qualquer tamanho.
A avaliação MA-MPS é separada em quatro subprocessos:
&quot;Contratar «Avaliação», &quot;Preparar a realização da avaliação», Realizar a avaliação final &quot;e «Documentar os resultados da avaliação».
Cada um desses subprocessos contém uma série de atividades, descritas na Tabela 4.
Durante a execução desses processos são obtidos dados e informações que caracterizam os processos de software da empresa avaliada.
É verificado quanto dos resultados esperados e propósitos dos processos são verificados e atingidos respectivamente.
E com base nesses dados é atribuído um nível de maturidade à organização/ unidade organizacional avaliada.
O MMGP é um modelo de maturidade para gerenciamento de projetos.
O modelo foi publicado em 2002 e tinha como objetivo ajudar a equipe de gerenciamento de projetos do Instituto de Desenvolvimento Geral (INDG) a avaliar estágio de maturidade de determinados departamentos das organizações para as quais prestava consultoria.
Ele já foi aplicado em dezenas de departamentos de organizações brasileiras.
O modelo Prado-MMGP possui cinco níveis de maturidade:
&quot;Inicial», &quot;Conhecido», &quot;Padronizado», &quot;Gerenciado», &quot;Otimizado».
Para que um departamento aumente sua maturidade, ele deve implementar melhores práticas em seis dimensões a saber:
&quot;Conhecimentos de gerenciamento», &quot;Uso prático de metodologias», &quot;Informatização, «Relacionamentos humanos», &quot;Estrutura organizacional», Alinhamento com os negócios da organização».
Cada dimensão exige mais práticas à medida que os níveis de maturidade são aumentados.
A descrição do que se espera em cada dimensão dependendo do nível de maturidade no Prado-MMGP é descrito na Tabela 5.
A avaliação no MMGP é realizada através de um questionário respondido por o departamento que deseja ser avaliado.
O questionário é composto por quarenta perguntas, sendo 10 para cada nível, abrangendo todas as dimensões relevantes em cada um de eles.
Este questionário está disponível na Web.
O site que hospeda o questionário possibilita que, ao final da avaliação, a empresa possa comparar- se com outras da mesma categoria.
As perguntas têm sempre cinco respostas, cada opção tem uma quantidade de pontos associada que variam entre 0 e 10.
Depois que o questionário é concluído, soma- se os pontos de todas as respostas.
Por fim, se utiliza a fórmula &quot;Avaliação Final å/ 100 «para se descobrir o nível da empresa ou departamento.
Em a Tabela 6 tem- se o exemplo de uma empresa que está entre o nível 1 e 2.
Diferente dos outros modelos, no MMGP uma empresa pode estar no nível 3 sem estar 100% em conformidade com o nível o 2.
A tese de doutorado em que o modelo de capacidade WAVE foi proposto é o principal trabalho relacionado dessa pesquisa, visto que o método de avaliação que é proposto nesse trabalho estende o modelo WAVE.
Essa pesquisa utiliza como base a estrutura de níveis e áreas do modelo WAVE para propor o método de avaliação.
O modelo de capacidade WAVE está descrito na seção 2.2.
Durante a revisão teórica foi encontrada uma pesquisa que também se propõe a avaliar processos de empresas com foco em ambientes DDS.
Em este trabalho, os pesquisadores verificaram que o modelo CMM e a norma ISO 9001 não endereçavam problemas inerentes ao DDS.
Baseando- se no conceito de Key Process Areas (KPYs) do CMM e da ISO 9001 os pesquisadores propuseram 24 novas KPIs para endereçar os desafios de DDS.
Cada uma dessas KPYs tinham 3 níveis de maturidade, para verificar a sua relevância, foram submetidas a um grupo de 34 avaliadores com experiência comprovada em DDS e em diferentes áreas de atuação.
Depois de validado o modelo de referência, foi criado um método de avaliação.
Esse método era composto por um questionário que continha uma série de perguntas para cada KPY.
Esses questionários foram aplicados em seis equipes da SAP, a fim de verificar o nível de maturidade em DDS de cada uma destas.
Os resultados obtidos em cada uma das equipes foram bem diferentes, duas estavam no nível 3, duas no nível 2 e duas no nível 1.
Para verificar a assertividade do método de avaliação foram verificadas algumas métricas dos projetos avaliados, como produtividade e qualidade.
Esse cruzamento indicou que as equipes com melhores métricas tinham maior nível de maturidade no modelo de maturidade proposto, indicando que ele estava correto.
Esse trabalho teve como principal contribuição a proposição de framework de evolução de maturidade, com indícios que atestam a sua qualidade.
No entanto, o tipo de método de avaliação proposto, contendo somente questionários como fonte de dados, não prove sugestões de melhorias e nem leva em consideração os objetivos da empresa avaliada.
Além disso, não possui uma ferramenta de apoio para avaliações.
O trabalho descrito em apresenta uma proposta de medição de riscos quantitativamente qualitativamente em ambientes distribuídos, estendendo o modelo proposto em.
Esse trabalho não é diretamente relacionado, pois é específico para a parte de riscos e baseia- se somente em análise de dados coletadas através de medições.
Isso se distancia muito de métodos de avaliação como o SCAMPI, SPICE ou MA-MPS, que se baseiam principalmente em entrevistas, questionários e análise de documentos como fonte de dados e que são a base para esta pesquisa.
Diversos outros trabalhos sobre métodos de avaliação foram lidos, não totalmente relacionados uma vez que não trabalhavam dentro de o contexto de DDS.
Enquanto que a finalidade da pesquisa é achar a solução para um problema, é o método científico que estrutura os passos para que a solução do problema seja encontrada.
Esses passos têm como objetivo aumentar a confiabilidade na validade dos resultados encontrados.
O método de pesquisa pode ser dividido em duas grandes fases, a elaboração da teoria e a verificação da mesma.
Em a fase de elaboração da teoria, durante a proposta do método de avaliação ao modelo WAVE, utilizou- se um estudo empírico qualitativo.
Isto se faz necessário, pois o estudo é aplicado e com intervenção humana.
A utilização de estudos empíricos diminui as chances de encontrar, nos resultados, grandes discrepâncias entre a teoria e a prática, questão fundamental para esta pesquisa.
A abordagem qualitativa foi necessária, visto que não existem dados suficientes que pudessem ser usados para propor, através de análises estatísticas, um método de avaliação para o WAVE.
Em esta abordagem é possível levar em consideração diversos componentes, como a experiência adquirida no estudo de métodos de avaliação existentes, DDS e do próprio WAVE.
A conclusão desses estudos que possibilitaram a proposta do método de avaliação do WAVE.
Dois estudos de caso, com interferência direta do pesquisador, foram utilizados como método de pesquisa para avaliar o método de avaliação proposto.
Considera- se que o método em questão é o mais indicado, pois o 2 DAM-WAVE nunca havia sido testado, justificando a necessidade de validar seus procedimentos e eventos num ambiente real.
A coleta de dados ocorreu na forma de entrevistas, questionários e coleta de artefatos, condições ideias para a aplicação de um estudo de caso.
Sabe- se que os resultados dos estudos de caso não podem ser generalizados devido a a baixa representatividade da amostra, mas este não é o objetivo da pesquisa.
A generalização, de fato, ocorrerá à medida que o 2 DAM-WAVE for aplicado em diversas organizações através da análise de melhorias e sugestões, da mesma forma que os outros métodos de avaliação estudados evoluem.
Ambas as dimensões do 2 DAM-WAVE foram aplicadas durante os dois estudos de caso.
As duas unidades de análise foram, respectivamente, uma unidade brasileira que trabalha com DDS e com a configuração de Offshore Insourcing e uma unidade indiana de outra organização que trabalha com Offshore Outsourcing.
As etapas que foram necessárias para se propor e testar o 2 DAM-WAVE estão descritas abaixo e ilustradas na Figura 8. --
Estudo da Base Teórica Esta etapa contemplou, principalmente, &quot;DDS», &quot;WAVE «e &quot;Métodos de Avaliação», e foi muito importante para a proposta do método de avaliação do 2 DAM-WAVE.
Este estudo foi descrito no capítulo 2.
Em esta etapa, também se realizou um estudo exploratório, elencando as principais características dos métodos de avaliação existentes.
Estas características foram analisadas sob a ótica do WAVE e do DDS, elencando as vantagens, desvantagens e dificuldades de usar- las para compor o método de avaliação do WAVE (Ap L). --
Método de Avaliação Preliminar e Ferramenta de Apoio Em esta etapa foi proposto o método de avaliação preliminar do modelo WAVE, o 2 DAM-WAVE.
Além disso, foi criada uma ferramenta de apoio com o intuito de automatizar e facilitar o processo de avaliação do 2 DAM-WAVE.
A proposta do 2 DAM-WAVE está descrita no capítulo 4 e a ferramenta de apoio no capítulo 5. --
Estudos de Caso Etapa onde foi realizada a pesquisa confirmatória através de dois estudos de caso, implementando os seguintes passos:
&quot;Identificação de Pontos Críticos», &quot;Delimitação do Estudo», &quot;Estabelecer Objetivos», &quot;Fazer o Desenho da Pesquisa», &quot;Coletar Dados», &quot;Organizar Informações», Relatar Resultados».
Os pontos críticos foram identificados através de um cuidadoso estudo do processo proposto e através de uma análise de riscos.
O estudo foi delimitado junto com os patrocinadores da pesquisa na unidade de análise e, também, foram expostos os objetivos do estudo de caso.
O desenho da pesquisa e o plano de coleta de dados foram feitos por o pesquisador, levando em consideração o método de avaliação proposto.
Todas as coletas de dados foram conduzidas por o pesquisador ou por a ferramenta de apoio.
Depois de coletados todos os dados, as informações foram organizadas e compartilhadas com cada uma das unidades de análise, além de servirem de insumo para alterações no método de avaliação e para sugestões de melhoria em futuros trabalhos.
A descrição do estudo de caso está no capítulo 6. --
Método de Avaliação Proposto Em esta etapa foram realizadas melhorias no método de avaliação preliminar, proposto antes da condução dos estudos de caso.
Essas melhorias foram identificadas durante os dois estudos de caso, através de análises de feedback dos envolvidos e da experiência adquirida por o pesquisador e estão descritas na seção 6.5.
O método de avaliação 2 DAM-WAVE tem duas dimensões, uma miniavaliação e outra mais abrangente, detalhadas nas seções 4.1 e 4.2 respectivamente.
Essa proposta é relevante devido a a impossibilidade de reunir as melhores práticas identificadas (Ap L) nos métodos de avaliação estudados em apenas um método de avaliação para o WAVE com apenas uma dimensão.
A ideia de ter mais de uma dimensão dentro de um método de avaliação para estes diferentes cenários, já é utilizada, em parte, por outros modelos de maturidade ou capacidade.
O modelo de maturidade do CMMI tem o seu método de avaliação SCAMPI definido em três níveis:
A, B e C. Em este modelo, o nível A realiza uma avaliação que consome muitos recursos e entrega resultados profundos e abrangentes.
Já o SCAMPI C faz uma rápida análise inicial dos processos e artefatos da unidade avaliada.
Modelos como o MPS.
Br não definem mais de um tipo de avaliação, mas existem iniciativas na indústria e academia que buscam criar avaliações iniciais, com menor complexidade e necessidade de investimentos.
A dimensão mais abrangente traz como referências o SCAMPI A, SPICE e MA-MPS enquanto que a miniavaliação utiliza o SCAMPI C e o método de avaliação do MMGP como norteadores.
O objetivo da dimensão mais abrangente é avaliar cuidadosamente os processos e artefatos da organização.
Utiliza- se, como fonte de dados, as entrevistas com diversos funcionários e as análises de documentação da unidade, chegando a conclusões não triviais e identificando pontos fortes, fracos e melhorias a serem priorizadas.
Uma avaliação como esta demanda muito em relação a tempo e recursos, por isso outra dimensão deve ser criada.
A miniavaliação deve ser menos demandante de recursos e tempo e não tem como objetivo avaliar a organização com profundidade, mas sim fazer um estudo inicial do estado de seus processos.
Esta dimensão não deve exigir especialistas no modelo WAVE, e é realizada, na sua totalidade, através de uma ferramenta de apoio, prospectando evidências através de questionários Web, como o modelo Prado.
Os resultados de ambas as dimensões do 2 DAM-WAVE devem ser armazenadas num repositório histórico para benchmarking.
Os resultados das capacidades das unidades avaliadas, junto com as informações da unidade, possibilitarão verificar, por exemplo, a evolução das capacidades das unidades brasileiras em DDS ao longo de os anos.
Além disso, será possível ao avaliador verificar como outras unidades resolveram problemas típicos do DDS em outras avaliações, podendo utilizar essas informações para propor as melhorias em outra avaliação.
Com uma estrutura Web montada, pode- se disponibilizar às unidades avaliadas uma forma de se compararem com outras empresas do mercado.
Além disso, esse banco histórico pode proporcionar à comunidade acadêmica uma oportunidade de analisar a evolução do mercado nessa área.
Essa prática já é parcialmente utilizada no MMGP.
Para que isso seja possível, deve- se garantir às empresas que os dados serão confidenciais, ou seja, não será possível recuperar dados de uma unidade específica.
Dimensão da Miniavaliação A miniavaliação do WAVE tem como objetivo realizar uma avaliação inicial e rápida sobre a capacidade de uma unidade de uma organização em DDS, e possibilitar que a mesma se compare com outras unidades já avaliadas.
O processo da miniavaliação é ilustrado na Figura 9.
Esta miniavaliação é inteiramente online, e realizada por uma ferramenta de apoio, desenvolvida durante essa pesquisa e detalhada no Capítulo 5.
Possui, como principal característica, não necessitar da intervenção de nenhum especialista em DDS ou WAVE para calcular os resultados.
A parte da ferramenta de apoio que dá suporte para a miniavaliação foi baseada principalmente na MPCM, sistema de avaliação do Prado MMGP.
Optou- se por realizar a miniavaliação por questionários, visto que este método possibilita a captação de dados altamente estruturados e que podem ser tratados sem a intervenção humana.
Além disso, é facilmente disponibilizado para as unidades e não exige destas nenhum tipo de conhecimento prévio no modelo de capacidade O processo da dimensão da miniavaliação do WAVE é dividido em três fases principais:
&quot;Planejar e Preparar a Avaliação», &quot;Condução da Avaliação», Relato dos Resultados».
Estas são apresentadas nas seções, 5.1.1, 5.1.2 e 5.1.3, respectivamente.
A Figura 10 apresenta as atividades da fase de &quot;Planejar e Preparar a Avaliação».
As atividades de &quot;Cadastro da Empresa e Cadastro de Participantes «são descritas abaixo.
Para se submeter à miniavaliação, a unidade precisa se cadastrar na ferramenta de apoio Web e responder a uma série de perguntas sobre o seu perfil, tais como número de funcionários e experiência em DDS.
Se a unidade já possuir um perfil e, portanto, já tiver realizado a avaliação do WAVE numa das dimensões disponíveis, poderá refazer a avaliação, quantas vezes julgar necessário.
Tal ação possibilita que uma unidade, sem muito esforço, perceba a evolução de seus processos ao longo de o tempo.
Esta prática é normalmente utilizada em programas de melhorias de processos.
Depois de logada, a unidade deve selecionar seis usuários para participar da miniavaliação através da resposta aos questionários.
Sabe- se que avaliações que se utilizam somente de questionários para a coleta de dados, são altamente dependentes da opinião de quem responde os mesmos, por isso a avaliação utilizou dois grupos de profissionais, três com responsabilidades técnicas e três com responsabilidades gerenciais.
Desta forma, através de uma heurística, busca- se diminuir o impacto de opiniões extremas dentro de os grupos e verificar se as percepções sobre as capacidades da unidade são uniformes em ambos os grupos.
É importante salientar que os usuários escolhidos para responder aos questionários devem ter, no contexto da unidade avaliada, experiência em DDS e, além disso, é obrigatório que os escolhidos trabalhem em projetos relevantes da mesma.
Em o contexto desta avaliação, um projeto relevante é distribuído e é representativo para a unidade em termos financeiros, de utilização de processos e tamanho de equipe.
Por fim, nota- se que, se comparada com a dimensão mais abrangente, esta fase de miniavaliação é reduzida, visto que não existe a necessidade de planejamento da avaliação ou de treinamento de uma equipe de avaliação, pois todo o trabalho de análise de dados é realizado automaticamente através da ferramenta de apoio.
A Tabela 7 mapeia, para cada atividade da fase de &quot;Planejar e Preparar a Avaliação», quais são os Use Cases (&quot;UCs&quot;) da ferramenta de apoio que são utilizados.
A Figura 11 mostra as atividades da fase de &quot;Condução da Avaliação».
As atividades de &quot;Coleta de Evidências», &quot;Aplicação de Heurística», &quot;Documentação de Evidências e Geração de Resultados da Aplicação «são descritas abaixo.
Tabela 8 -- Exemplo de mapeamento entre pergunta da miniavaliação x atributo do WAVE Atributo do WAVE $= Diferenças Culturais Sobre os desafios gerados por as diferenças culturais, existentes entre os membros de uma organização fisicamente distribuída.
Alternativa Prática do WAVE Alternativa 1.
Não implementa práticas do As pessoas desconhecem a existência de diferenças WAVE.
Alternativa 2.
Não implementa práticas do Algumas pessoas sabem que existem diferenças WAVE.
Implementa Cult1.
Alternativa 3.
&quot;Os colaboradores entendem Algumas pessoas aprendem sozinhas ou com colegas que há diferenças culturais e sobre as diferenças culturais existentes entre os compartilham informalmente membros da organização fisicamente distribuída e dicas de como lidar com elas.»
tentam lidar com elas da melhor maneira possível.
Implementa Cult2.
Alternativa 4.
A unidade preparou um treinamento, que é aplicado unidades são treinados na os times que têm interação com outras unidades, como lidar com diferenças sobre como lidar com as diferenças culturais.
Implementa Cult3.
Alternativa 5.
&quot;Iniciativas globais para lidar A organização possui iniciativas globais para melhor com as diferenças culturais são lidar com as suas diferenças culturais.
Estas iniciativas desenvolvidas.»
são implementadas em todas as suas unidades.
Todas as perguntas foram submetidas à validação de dois especialistas em DDS, sendo um de eles o autor do modelo WAVE.
Estes especialistas receberam um documento explicando o que deveria ser feito (Ap B) e uma planilha para facilitar a análise das perguntas (Ap C).
Algumas perguntas são suprimidas do questionário dos respondentes pertencentes ao grupo técnico, visto que algumas práticas do modelo WAVE não são percebidas por esse grupo.
Atributos da área de capacidade de &quot;Portfólio «são exemplos dessa exceção, como «Alocação de projetos (Alpr).
Os respondentes não têm limite pré-estabelecido de tempo para responder às questões da avaliação na ferramenta de apoio.
Depois de todos os respondentes terminarem de preencher os questionários, a ferramenta de apoio calcula, através de uma heurística, se os dados são válidos ou se existe alguma discrepância relevante entre os resultados.
A heurística verifica se mais de 66% das respostas de cada pergunta são iguais, se não forem os dados são considerados inconclusivos.
Se as respostas de por os menos uma pergunta forem consideradas inconclusivas por a heurística, os respondentes deverão chegar a um consenso, respondendo mais uma vez a um questionário na ferramenta de apoio que contem somente as perguntas com resposta inconclusiva.
Depois de aprovados por a heurística, os dados coletados na avaliação são gravados no banco de dados da avaliação.
Logo após, tem início a atividade de &quot;Geração de Resultados da Avaliação».
Em este ponto da atividade, já se possui todos os dados necessários à geração dos resultados, entregues por a miniavaliação através da ferramenta de apoio.
Por ser uma avaliação simples e sem intervenção de um time de avaliação com especialistas no modelo WAVE ou em DDS, o resultado da miniavaliação não fornece propostas de melhorias.
Além disso, assim como o SCAMPI C, seus resultados não são considerados suficientemente assertivos, mas seu resultado pode ser considerado como uma indicação da suposta capacidade da empresa em DDS.
Por outro lado, consegue- se identificar os pontos fortes e fracos da unidade avaliada, mostrando o seu suposto nível de capacidade em DDS e a aderência aos níveis de capacidade não implementados.
Outra característica é a de possibilitar a comparação da unidade avaliada com outras unidades já avaliadas por a avaliação do WAVE, em qualquer uma das duas dimensões.
A Tabela 9 mapeia, para cada atividade da fase de &quot;Condução da Avaliação», quais são os Use Cases (&quot;UCs&quot;) da ferramenta de apoio que são utilizados.
A Figura 12 mostra as atividades da fase de &quot;Relato de Resultados».
As atividades de &quot;Arquivamento das Informações da Avaliação», Entregar Benchmarking &quot;e «Entrega de Resultados da Avaliação «são descritas abaixo.
Durante a atividade de &quot;Arquivamento das informações da avaliação «os dados avaliados são inseridos, por a ferramenta de apoio, numa base que concentra os dados de todas as miniavaliações e das avaliações mais abrangentes já realizadas.
A partir de esta base de dados históricos, a unidade poderá se comparar com outras unidades, através de uma série de relatórios que ficam disponibilizados por a ferramenta de apoio.
Será possível, por exemplo, verificar a evolução das capacidades de unidades em DDS, por região, descobrir qual a porcentagem de unidades em determinado nível, etc..
Estes dados também ficarão disponíveis para a comunidade científica.
Esses relatórios foram deixados para a fase dois da ferramenta, mesmo assim a estrutura de dados já está pronta para consumo.
Em a última atividade da miniavaliação, a unidade pode acessar os resultados gerados na ferramenta de apoio e, os mesmos, podem ser acessados a qualquer momento mediante o acesso à ferramenta.
Além disso, a ferramenta de apoio possibilitará, na segunda versão, a visualização de benchmarkings realizados por a equipe do WAVE, com a possibilidade de acesso aos dados históricos de outras avaliações para que a unidade possa se comparar com outras unidades de outras organizações.
Os resultados da miniavaliação são:
&quot;Suposto Nível de Capacidade por «Área de Capacidade», &quot;Suposto Nível de Capacidade do WAVE», &quot;Aderência por Nível de Capacidade e Aderência por Áreas de Capacidade».
Os dois primeiros tipos de resultado foram inspirados no SCAMPI C, enquanto que os dois últimos se embasaram no MMGP.
O resultado &quot;Suposto Nível de Capacidade por Área de Capacidade «é calculado para todo o nível de capacidade em todas as áreas de capacidade do modelo WAVE.
Considera- se implementado um nível se:
Se uma área Y falhar em atingir o nível X do WAVE, sabe- se que nenhum dos níveis acima de X podem ser considerados como atingidos, segundo o modelo de capacidade do WAVE.
O resultado &quot;Suposto Nível de Capacidade do WAVE «segue a mesma lógica do cálculo anterior, mas é geral para o modelo todo.
Seu cálculo é gerado para todos os níveis de capacidade do modelo WAVE.
Considera- se implementado um nível se:
É importante ressaltar que uma unidade não é considerada de nível X, se pelo menos uma prática de algum nível inferior a X não tiver sido implementada.
O resultado &quot;Aderência por Nível de Capacidade «é um entregável que auxilia a unidade a verificar o quão perto ela está de atingir um nível de capacidade X, numa das áreas de capacidade.
Este cálculo também é executado para todo o nível, em todas as áreas de capacidade, e sua aderência é calculada por:
É importante ressaltar que o fato de uma empresa possuir 100% de aderência num nível X de capacidade não indica que é este o seu nível de capacidade.
Isso fica mais claro, tomando como exemplo uma unidade que tenha:
Esta dimensão de avaliação se baseou, principalmente, no método de avaliação do Modelo Prado MMGP e no SCAMPI C.
A Tabela 10 mapeia, para cada atividade da fase de &quot;Planejar e Preparar a Avaliação», quais são os Use Cases (&quot;UCs&quot;) utilizados da ferramenta de apoio.
A dimensão mais abrangente do WAVE busca realizar uma avaliação detalhada sobre a capacidade de uma unidade em DDS, utilizando o modelo WAVE como referência.
Diferente da miniavaliação, essa dimensão realiza uma análise profunda dos processos e atividades da unidade e utiliza um time de avaliação especializado em DDS, no modelo de capacidade WAVE e em seu método de avaliação.
Este cuidado possibilita a proposta de melhorias ordenadas por relevância e com planos de ação para a sua implementação.
O processo da avaliação mais abrangente é ilustrado na Figura 14.
As fases desta dimensão mais abrangente são iguais às da miniavaliação, porém suas atividades mudam significativamente.
Estas atividades baseiam- se, principalmente, nas atividades do SCAMPI A e MA-MPS.
Cada atividade possui uma descrição, assim como também ocorre na miniavaliação, e uma tabela, que auxilia o time de avaliação a conduzir a avaliação.
Um exemplo de uso dessa tabela é ilustrado na Tabela 11 que indica quais os critérios de entrada e saída, os responsáveis, os participantes e quais artefatos são utilizados na atividade.
Indica quais são os papéis que participam da atividade de alguma forma.
Indica quais são os artefatos do 2 DAM-WAVE utilizados durante o andamento da atividade.
Durante a primeira fase da avaliação mais abrangente, chamada de &quot;Planejar e Preparar a Avaliação», a unidade que será avaliada cadastra- se na mesma ferramenta de apoio da miniavaliação, inserindo, também, informações sobre o seu perfil.
A unidade deve reunir um time de avaliação, que será composto por um membro da unidade a ser avaliada e por um profissional indicado por o grupo MuNDDoS, que atuará como líder da avaliação.
Em esta fase, também, são escolhidos os projetos que serão utilizados para a avaliação e se discute como será a coleta de evidências, adquiridas na avaliação mais abrangente, através de entrevistas e análises de documentos.
Por fim, esta fase entrega um plano de avaliação que descreve:
Objetivos, marcos, entregáveis, entre outras informações (Ap D).
Após o planejamento, inicia- se a fase de &quot;Condução da Avaliação», que é a fase mais extensa e, talvez, a mais importante.
Em ela, o avaliador interno e o líder da avaliação coletam e analisam documentos e ferramentas que geram evidências de implementação de práticas do WAVE por a unidade.
Além disso, o avaliador líder conduz as entrevistas planejadas com o objetivo de buscar afirmações que comprovem ou não a implementação de práticas do WAVE.
Estas informações são constantemente consolidadas em planilhas que são utilizadas para verificar a necessidade de outros dados ou para identificar contradições entre os dados armazenados (ApS I e J).
Depois de coletados todos os dados necessários, iniciam- se os cálculos dos resultados da avaliação, sendo primeiro por projeto analisado e, após, em nível de unidade.
Baseando- se nas evidências e afirmações coletadas na unidade e em seus objetivos, as melhorias são sugeridas e priorizadas por o time de avaliação e é criada uma listagem dos pontos fortes e fracos da unidade (Ap K).
Em a última fase da avaliação, a de &quot;Relato de Resultados», os artefatos utilizados na ferramenta de apoio são arquivados na ferramenta de apoio.
Outra ação, que ocorre nesta fase, é a inclusão dos resultados da avaliação no benchmarking do WAVE, a ser utilizado por unidades que queiram se comparar com outras e para a percepção de tendências na área de DDS.
Por último, são apresentados todos os resultados encontrados na avaliação para todos os stakeholders da avaliação na unidade.
As três fases, &quot;Planejar e Preparar a Avaliação», &quot;Condução da Avaliação e Relato dos Resultados «são apresentadas nas seções, 5.2.1, 5.2.2 e 5.2.3 respectivamente.
A fase de planejamento e preparação deve ser cuidadosamente realizada para garantir uma avaliação sem problemas críticos.
A Figura 15 ilustra as atividades desta fase.
As atividades de &quot;Analisar Requisitos», &quot;Seleção e Preparação da Equipe», Desenvolvimento do Plano de Avaliação «são explicadas a seguir. --
Analisar Requisitos Em a atividade &quot;Analisar Requisitos», a unidade acessa a ferramenta de apoio da avaliação 2 DAM-WAVE, hospedada na Web, e cadastra o seu perfil, caso ainda não possua um.
Depois, solicita o início de uma avaliação mais abrangente e, para isso, a ferramenta de apoio sugere uma lista de avaliadores indicados por o grupo MuNDDoS.
A unidade interessada deve, então, entrar em contato com um desses avaliadores para atuar como líder da avaliação da dimensão mais abrangente.
O líder da avaliação tem a responsabilidade de conduzir a avaliação mais abrangente, pois possui conhecimento e experiência no modelo de capacidade WAVE e no método de avaliação 2 DAM-WAVE.
Em esta atividade também ocorre a definição do membro da unidade que realizará o papel de patrocinador da avaliação.
Depois de acordados estes papéis, o patrocinador apresenta ao líder da avaliação, a sua unidade, seu negócio e os objetivos com a avaliação.
A Tabela 12 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Analisar Requisitos».
Usuário da unidade cadastrado na ferramenta de apoio do 2 DAM-WAVE como &quot;Patrocinador».
Plano de Avaliação «foi iniciado (Ap D);
Perfil da unidade cadastrada na ferramenta de apoio;
Critério de Definido o líder da avaliação e o patrocinador;
Saída Líder da avaliação contextualizado sobre os objetivos e situação da unidade sendo avaliada.
Responsáveis Patrocinador.
Líder da avaliação; Participantes Patrocinador.
Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs: --
UC1 -- Registro;
Artefatos -- UC2 -- Editar unidade;
Utilizados -- UC4 -- Iniciar avaliação mais abrangente; --
UC22-Realizar download de artefatos.
&quot;Plano de Avaliação «iniciado (Ap D).
Critério de Entrada -- Seleção e Preparação da Equipe Durante a atividade de &quot;Seleção e Preparação da Equipe», é escolhido o avaliador interno à unidade do time de avaliação.
É obrigatória a utilização de um avaliador interno, este deve ter experiência em DDS, conhecer os processos da unidade e já ter participado de projetos relevantes da unidade que será avaliada.
Este tipo de avaliador agrega qualidade à avaliação, provendo rápido acesso a documentos e pessoas da unidade, além de compartilhar o conhecimento sobre a unidade que está sendo avaliada.
O líder da avaliação cadastrará este avaliador na ferramenta de apoio.
A ferramenta enviará um e-mail, informando ao avaliador interno sobre suas novas responsabilidades e indicando um material de leitura obrigatória que resume DDS, o modelo de capacidade WAVE e seu método de avaliação.
Por fim, é realizada uma reunião de kick-off com o time de avaliação e o patrocinador.
Em esta reunião, o líder da avaliação deve se certificar de que os avaliadores internos entenderam os conceitos apresentados no material indicado realizando um pequeno treinamento sobre DDS, WAVE e o 2 DAM-WAVE (Ap E).
A Tabela 13 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Seleção e Preparação da Equipe». --
UC20 -- Contextualizar membro do time interno de avaliação;
Utilizados -- UC24 -- Realizar download de treinamentos.
&quot;Plano de Avaliação «preenchido (Ap D). --
Desenvolvimento do Plano da Avaliação Em a última atividade desta fase, &quot;Desenvolvimento do Plano de Avaliação», ocorre a identificação de quais projetos da unidade serão utilizados para a avaliação.
Obriga- se a utilização de dois projetos, um terminado recentemente e outro em fase final de desenvolvimento.
Desta forma, garante- se que pelo menos um dos projetos já passou por todas as fases do desenvolvimento e o outro ainda está com o time montado, facilitando o acesso aos profissionais e aos documentos do projeto Os projetos escolhidos devem ser representativos da unidade e relevantes para a avaliação, portanto é imperativo que os mesmos sejam distribuídos e que tenham interação com outras unidades, além de serem representativos da unidade em relação a faturamento, tamanho médio da equipe e utilização de processos.&amp;&amp;&amp;
O escopo desta dimensão abrange todo o modelo WAVE, visto que sua complexidade não é tão grande como em outros modelos de qualidade, como por exemplo, os modelos CMMI ou MPS.
Br, que justificam avaliações de escopo reduzido.
Depois de decididos os projetos que serão avaliados, o &quot;Plano de Avaliação «deverá ser concluído (Ap D).
Este documento, que contém os planos para a coleta de evidências e afirmações, o cronograma da avaliação, seus entregáveis, entre outros, é escrito por o avaliador líder com o auxílio do avaliador interno.
O planejamento da avaliação é muito importante para evitar problemas críticos no decorrer de a avaliação.
Depois de preenchido, o documento deve ser revisado por o patrocinador da avaliação e assinado.
É importante tomar cuidado durante o planejamento das coletas de dados para se marcar quatro sessões de entrevistas, cada uma de elas com dois profissionais.
Duas dessas sessões devem ser com grupos de profissionais técnicos e as outras duas com grupos de profissionais gerenciais.
É importante ter representatividade de ambos os projetos avaliados em todas as seções de entrevistas, para facilitar a identificação de diferenças de capacidades entre os projetos.
Além disso, é muito importante que uma das sessões de entrevistas do grupo gerencial conte com a participação de um profissional que gerencie um portfólio de projetos.
Esse tipo de profissional é necessário para responder com detalhes perguntas relacionadas a área de portfólio do WAVE.
Por último, é importante agendar a coleta de evidências entre a segunda e a terceira sessão de entrevistas, dessa forma o avaliador pode aprender sobre a organização nas primeiras duas sessões, verificar o que foi aprendido com a análise de artefatos e, por fim, utilizar as últimas entrevistas para esclarecer dúvidas.
Em esta atividade também é criada a &quot;Tabela de Riscos da Avaliação «(Ap F), que será monitorada por o time de avaliação e que servirá de base para identificar possíveis problemas durante a avaliação da unidade.
A Tabela 14 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Desenvolvimento do Plano de Avaliação».
Critério de &quot;Plano da Avaliação «finalizado e aprovado (Ap D);
Saída &quot;Tabela de Riscos da Avaliação «iniciada (Ap F).
Responsáveis Líder da avaliação.
Líder da avaliação; Participantes Avaliador interno;
Patrocinador. Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs:
Artefatos -- UC22 -- Realizar download de artefatos.
Utilizados &quot;Plano de Avaliação «concluído e aprovado( «Ap D);
Lista de Riscos da Avaliação «preenchido (Ap F).
A fase de &quot;Condução da Avaliação «é onde todas as coletas de evidências e afirmações são realizadas, os cálculos sobre a capacidade da unidade é feito e, também, onde as melhorias, pontos fortes e fracos são identificados.
As atividades de &quot;Preparar Participantes», &quot;Coleta de Evidências e Afirmações», &quot;Documentação de Evidências e Afirmações», &quot;Verificação de Evidências e Afirmações», Validar as Primeiras Descobertas &quot;e «Geração de Resultados de Avaliação «são detalhadas abaixo e ilustradas na Figura 16. --
Preparar Participantes A atividade de &quot;Preparar Participantes «é utilizada para informar os profissionais que irão participar da avaliação, contextualizando- os sobre a mesma.
Estas pessoas são, na sua maioria, aquelas que foram selecionadas na fase anterior para serem entrevistadas.
Esta atividade pode ser concluída informando para a ferramenta de apoio do 2 DAM-WAVE os e-mails dos profissionais envolvidos.
A ferramenta, então, envia um e-mail, apresentando a avaliação e seus objetivos.
A Tabela 15 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Preparar Participantes».
Plano da Avaliação «que contém a lista dos profissionais que serão entrevistados.
Funcionários que serão entrevistados contextualizados sobre a avaliação da unidade e seus objetivos.
Líder da avaliação; Funcionários que irão participar das entrevistas.
Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs: --
UC21 -- Contextualizar participantes das entrevistas. --
Coleta de Evidências e Afirmações Durante a &quot;Coleta de Evidências e Afirmações», o avaliador líder conduz as entrevistas planejadas no &quot;Plano de Avaliação «utilizando a &quot;Agenda Base de Entrevistas «como auxílio (Ap G).
Este artefato estrutura parcialmente as entrevistas através de uma pauta, auxiliando o avaliador a abordar todas as práticas do WAVE.
Estas entrevistas são realizadas ou com grupos de profissionais técnicos ou com grupos de profissionais gerenciais.
Para as entrevistas não consumirem muito tempo dos profissionais e não se tornarem improdutivas, não devem passar de uma hora de duração.
Para otimizar o tempo disponível, as entrevistas devem ser gravadas, liberando o avaliador de anotar as respostas.
Importante frisar que o conteúdo das entrevistas não é igual para o grupo de profissionais técnicos e gerenciais, por o mesmo motivo que a miniavaliação tem questionários diferentes para esses dois grupos.
Em o final, os resultados das entrevistas podem gerar, para cada prática do WAVE, afirmações positivas, pontos fracos relevantes e sugestões de melhorias.
Entre a segunda e a terceira seção de entrevistas, o avaliador líder e o avaliador interno, prospectam evidências da implementação de práticas de atributos do WAVE na unidade avaliada.
Esta busca é guiada por a &quot;Lista de Evidências Esperadas «(Ap H), que lista quais artefatos e ferramentas são normalmente esperados para considerar uma prática implementada.
Esta fonte de dados gera, para cada prática do WAVE, evidências de implementação, pontos fracos e pontos fracos relevantes.
Pontos fracos, relevantes ou não, poderão ser utilizadas durante a geração de propostas de melhorias.
A Tabela 16 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Coleta de Evidências e Afirmações».
Em a atividade de &quot;Documentação de Evidências e Afirmações «ambas as fontes de dados, entrevistas e análise de evidências, devem ser consolidadas na &quot;Planilha de Evidências e Afirmações do Projeto «(Ap I).
As entrevistas gravadas e os documentos analisados devem ser compilados em afirmações ou evidências positivas, negativas e em possíveis melhorias.
Existem sempre duas planilhas de evidências e afirmações neste momento da avaliação, sendo uma para cada projeto avaliado, definidos durante o planejamento da avaliação.
A Tabela 17 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Documentação de Evidências e Afirmações».
Evidências e afirmações consolidadas para cada um dos dois projetos nos artefatos de &quot;Planilha de Evidências e Afirmações do Projeto «(Ap I).
Líder da avaliação; Avaliador interno.
Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs: --
UC22-Realizar download de artefatos.
&quot;Lista de Evidências Esperadas «consultada( «Ap H);
Entrevistas Gravadas «consultadas;
&quot;Planilha de Evidências e Afirmações do Projeto «preenchida (Ap -- Verificação de Evidências e Afirmações É na atividade de &quot;Verificação de Evidências e Afirmações «que o avaliador líder verifica se os resultados das entrevistas e da análise de evidências indicam o mesmo resultado.
Além disso, o avaliador líder identifica se evidências ou afirmações de determinada prática foram esquecidas ou são insuficientes para alguns dos projetos avaliados.
Depois, o resultado da análise é compartilhado com o avaliador interno e se discute a necessidade de um complemento na coleta de evidências ou afirmações já realizada.
Se esta nova coleta for considerada necessária, o &quot;Plano da Avaliação «(Ap D) e a &quot;Planilha de Riscos «(Ap F) devem ser alterados e o processo de avaliação volta para a atividade de &quot;Coleta de Evidências e Afirmações».
A Tabela 18 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Verificação de Evidências e Afirmações».
Decisão tomada sobre a necessidade ou não de mais informações para a apuração dos resultados da avaliação;
Opcional ­ &quot;Atualização do Plano de Avaliação «para a nova rodada de busca de evidências e afirmações.
Líder da avaliação; Avaliador interno.
&quot;Planilha de Evidências e Afirmações do Projeto «consultada (&quot;Ap Opcional -- Plano de Avaliação «alterado (Ap D);
Opcional -- &quot;Lista de Riscos da Avaliação «alterado (Ap F). --
Validar as Primeiras Descobertas Em a atividade de &quot;Validar as Primeiras Descobertas», tem início a verificação de implementação das práticas do WAVE para cada um dos projetos avaliados.
Para ser considerada implementada, uma prática do WAVE necessita de uma afirmação positiva e, quando indicado por a &quot;Lista de Evidências Esperadas «(Ap H), uma evidência válida deve ser encontrada.
Além disso, as práticas consideradas implementadas não podem ter nenhum ponto fraco relevante.
As evidências não são obrigatórias para todas as práticas, pois muitas destas só podem ser comprovadas através da afirmação de um profissional.
A prática CULT1 do WAVE é um exemplo de isso:
&quot;Os colaboradores entendem que há diferenças culturais e compartilham informalmente dicas de como lidar com elas.».
O critério de avaliação é ilustrado na Tabela 19.
Implementado», indicam que a prática foi considerada como implementada.
O grau de &quot;Parcialmente Implementado «indica uma prática não aceita, mas que seria aceita caso não possuísse problemas relevantes.
Por fim, práticas de grau &quot;Não Implementado», como o nome sugere, não são consideradas implementadas e não se tem registro de esforços da unidade para a implementação da mesma.
Depois de descoberta a capacidade dos projetos da unidade, verifica- se o nível da unidade como um todo.
Para isso, o avaliador líder deve consolidar as duas planilhas de avaliação na &quot;Planilha de Avaliação da Unidade «(Ap J).
Esta planilha consolidada verifica, para toda a prática, o projeto que obteve o menor nível de capacidade e este é considerado como o nível de capacidade da prática para toda a unidade.
Os pontos em que os projetos avaliados obtiveram diferentes níveis de capacidade são utilizados, por o avaliador líder, para propor melhorias para a unidade.
Depois de ter os dados consolidados lançados na planilha da unidade, a mesma calcula a capacidade da unidade como um todo.
A Tabela 20 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Validar as Primeiras Descobertas».
Planilha de Evidências e Afirmações do Projeto «(Ap I) e &quot;Planilha de Avaliação da Unidade «(Ap J) preenchidas com as evidências e afirmações obtidas na avaliação;
Descoberta dos níveis de cada atributo do WAVE para cada projeto avaliado e para a unidade em geral.
Líder da avaliação; Avaliador interno.
Líder da avaliação; Avaliador interno.
Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs: --
UC22-Realizar download de artefatos.
&quot;Planilha de Evidências e Afirmações do Projeto «concluída( «Ap I);
Planilha de Avaliação da Unidade «concluída (Ap J). --
Geração de Resultados da Avaliação Por último, o time de avaliação se utiliza dos dados obtidos durante a avaliação para montar o &quot;Documento de Resultados da Avaliação «(Ap K).
Este possui os resultados de capacidade dos projetos da unidade e da unidade como um todo.
Além disso, possui uma lista de pontos fortes e fracos da unidade e uma lista de sugestões de melhorias priorizadas de acordo com os objetivos da unidade.
Para auxiliar na prospecção de melhorias para a unidade, o time de avaliação deve verificar os seguintes dados coletados ao longo de a avaliação:
WAVE, auxilia neste processo.
A Tabela 21 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Geração de Resultados da Avaliação».
Em a última fase, chamada &quot;Relato de Resultados», os resultados da avaliação são apresentados para a unidade e enviados para a base de dados do MuNDDoS.
A Figura 17 mostra as atividades da última fase da avaliação mais abrangente.
As atividades &quot;Arquivamento das Informações da Avaliação», Entregar Benchmarking &quot;e «Entrega de Resultados da Avaliação «são detalhadas abaixo. --
Arquivamento das Informações de Avaliação Em a atividade &quot;Arquivamento das Informações da Avaliação», os resultados obtidos na fase anterior e todos os artefatos relevantes são incluídos na base de dados de avaliações históricas do WAVE.
Os artefatos considerados relevantes são:
As planilhas de evidências e afirmações da unidade, o documento de resultados da avaliação, a tabela de riscos e o plano da avaliação.
O avaliador líder realiza o upload destes documentos na ferramenta de apoio para que a unidade avaliada possa consultar futuramente estas informações.
A Tabela 22 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Arquivamento das Informações de Avaliação».
Em a atividade de &quot;Entregar Benchmarking», o avaliador líder preenche na ferramenta de apoio quais foram os níveis encontrados para cada atributo do WAVE.
Estes dados são incluídos num banco de dados histórico, que é utilizado para gerar o benchmarking da avaliação 2 DAM-WAVE.
A Tabela 23 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Entregar Benchmarking».
Níveis de capacidade da unidade em cada atributo do WAVE registrados na ferramenta de apoio.
Líder da avaliação. Ferramenta de apoio do 2 DAM-WAVE utilizada através dos UCs: --
UC23 -- Cadastrar resultados da avaliação. --
Entrega de Resultados de Avaliação Em a última atividade, &quot;Entrega de Resultados da Avaliação», o líder da avaliação apresenta, a todos os stakeholders, os resultados obtidos.
Por fim, o time de avaliação utiliza a ferramenta de apoio para cadastrar lições aprendidas e melhorias para o método de avaliação 2 DAM-WAVE.
Estas melhorias e lições aprendidas serão utilizadas por o MuNDDoS para evoluir o processo da ferramenta de apoio.
A Tabela 24 ilustra os critérios de entrada e saída, os responsáveis, participantes e os artefatos utilizados na atividade de &quot;Entrega de Resultados de Avaliação».
Nem todos os UCs identificados para a ferramenta de apoio foram implementados na primeira versão do software, somente aqueles necessários para a avaliação foram priorizados.
Os UCs marcados em amarelo nos diagramas das seções 6.1, 6.2 e 6.4 foram incluídos como sugestões para as próximas versões do software de apoio.
Os UCs da ferramenta de apoio foram divididos em quatro domínios para facilitar o entendimento:
&quot;Inicio de Avaliações», &quot;Miniavaliação», &quot;Avaliação mais Abrangente «e &quot;Resultado de Avaliações».
Esses domínios são descritos nas seções 6.1, 6.2, 6.3 e 6.4 respectivamente.
Os atores que interagem com a ferramenta de apoio e a descrição de seus papéis são consolidados na Tabela 25.
Funcionários da unidade que irão responder aos questionários da dimensão de miniavaliação do 2 DAM-WAVE.
Criados automaticamente por o UC 3.
Funcionário aprovado por o MuNDDoS para conduzir avaliações da dimensão abrangente do 2 DAM-WAVE.
Usuários da ferramenta de apoio antes da autenticação.
Domínio de &quot;Início de Avaliações «Essa seção apresenta requisitos funcionais do domínio de &quot;Início de Avaliações «da ferramenta de apoio, especificados como casos de uso.
Esse domínio inclui todos os UCs relevantes para se cadastrar na ferramenta, iniciar avaliações e manutenção de unidades e organizações.
A Figura 18 ilustra os UCs da dimensão de &quot;Início de Avaliações «no formato de diagrama de casos de uso da UML.
O UC &quot;Registro «possibilita que um usuário, que acesse a ferramenta na internet, se registre.
O UC &quot;Editar unidade «possibilita ao patrocinador inserir ou editar as informações da sua unidade, conforme ilustrado na Figura 19.
Ele é sempre chamado através dos UCs que iniciam a avaliação abrangente e a miniavaliação.
O UC &quot;Iniciar miniavaliação «possibilita ao patrocinador iniciar a dimensão de miniavaliação do 2 DAM-WAVE.
A dimensão de miniavaliação é toda gerenciada por a ferramenta de apoio e não necessita de interferência de um especialista no modelo de capacidade WAVE.
Este UC chama o UC 2 para atualizar as informações da unidade e depois abre uma tela que possibilita cadastrar os respondentes da miniavaliação, conforme ilustrado na Figura 20.
Depois de cadastrados, o UC envia um e-mail para os respondentes, avisando- os de suas responsabilidades.
O UC3 é detalhado no apêndice M. O UC &quot;Iniciar avaliação mais abrangente «lista os contatos dos Líderes de Avaliação do 2 DAM-WAVE.
É nesta tela que o patrocinador vai verificar qual o líder de avaliação que está mais perto de a sua unidade e pegar o contato do mesmo, conforme ilustrado na Figura 21.
Este UC não registra nada na ferramenta de apoio, pois a avaliação mais abrangente só é registrada na ferramenta no final do processo de avaliação, através do UC 23.
O UC4 é detalhado no apêndice M. O UC &quot;Vincular unidade à organização «possibilita ao patrocinador vincular a sua unidade a uma organização já existente ou a uma nova.
O vínculo de unidades à uma organização é importante para que os patrocinadores das diversas unidades de uma mesma organização possam enxergar os resultados das outras unidades.
Isso possibilita, por exemplo, a comparação entre as unidades de uma mesma organização através do UC 34.
O UC5 é detalhado no apêndice M. O UC &quot;Confirmar vínculo da unidade à organização «permite a um patrocinador aprovar ou não a requisição de vínculo de uma determinada unidade à sua.
Uma vez aprovada a requisição, ambos os patrocinadores poderão ver relatórios de qualquer unidade abaixo de esta organização.
O UC6 é detalhado no apêndice M. Domínio de &quot;Miniavaliação «Essa seção apresenta requisitos funcionais do domínio de &quot;Miniavaliação «da ferramenta de apoio, especificados como casos de uso.
Esse domínio inclui todos os UCs relevantes para se responder a miniavaliação, verificar quem são os funcionários que ainda não responderam e um UC para cadastro de melhorias para o WAVE e 2 DAM-WAVE.
A Figura 22 ilustra os UCs da dimensão de &quot;Miniavaliação «no formato de diagrama de casos de uso da UML.
O UC &quot;Responder avaliação «possibilita ao respondente preencher o questionário da miniavaliação (Ap A).
Este questionário é impresso na tela de acordo com o tipo do respondente logado, técnico ou gerencial, conforme a Figura 23.
Uma miniavaliação só é considerada finalizada depois que todos os 6 respondentes entrarem num consenso sobre todas as perguntas.
Por isso, deve haver uma validação quando o último respondente preencher o questionário.
Esta validação de consenso itera entre as perguntas e respostas de todos os respondentes e marca como inconclusiva uma pergunta quando 66% de suas respostas não forem iguais.
Quando uma ou mais perguntas forem inconclusivas, uma nova requisição de resposta de questionário é mandada para todos os respondentes.
O e-mail enviado irá explicitar as perguntas inconclusivas e o contato de todos os respondentes da miniavaliação, conforme a Figura 24.
Espera- se que os respondentes entrem em consenso informalmente e respondam novamente os questionários que, dessa vez, irá mostra somente as perguntas marcadas como inconclusivas.
O UC &quot;Cadastrar sugestões e lições aprendidas», possibilita a diversos atores do sistema a cadastrar sugestões para melhorar o método de avaliação 2 DAM-WAVE, o modelo WAVE ou a própria ferramenta.
O UC11 é detalhado no apêndice M. O UC &quot;Verificar status dos respondentes «possibilita ao patrocinador verificar qual o status da miniavaliação.
Este UC é importante para que o patrocinador possa investigar se algum funcionário está trancando a avaliação.
O UC12 é detalhado no apêndice M. Domínio de &quot;Avaliação Mais Abrangente «Esta seção apresenta requisitos funcionais do domínio de &quot;Avaliação Mais Abrangente «da ferramenta de apoio, especificados como casos de uso.
Esse domínio inclui todos os UCs relevantes para se conduzir uma avaliação mais abrangente.
A Figura 25 ilustra os UCs da dimensão de &quot;Avaliação Mais Abrangente «no formato de diagrama de casos de uso da UML.
O UC &quot;Contextualizar membros do time interno de avaliação «auxilia o líder da avaliação a contextualizar os funcionários escolhidos para compor o time interno da avaliação.
Este UC envia um e-mail para os funcionários escolhidos, contextualizando- os sobre a avaliação e indicando material sobre o WAVE, 2 DAM-WAVE e DDS.
O UC20 é detalhado no apêndice M. O UC &quot;Contextualizar participantes das entrevistas «auxilia o líder da avaliação a contextualizar os funcionários escolhidos para participar das entrevistas, conforme ilustrado na Figura 26.
Este UC envia um e-mail para estes funcionários, contextualizando- os sobre a avaliação e indicando material sobre o WAVE, 2 DAM-WAVE e DDS.
O UC21 é detalhado no apêndice M. O UC &quot;Realizar download de artefatos «permite ao líder da avaliação realizar o download das últimas versões de todos os artefatos necessários para a condução da avaliação de dimensão mais abrangente do 2 DAM-WAVE, conforme ilustrado na Figura 27.
O UC22 é detalhado no apêndice M. O UC &quot;Cadastrar resultados da avaliação «permite ao líder de avaliação cadastrar os resultados de uma avaliação mais abrangente realizada, conforme ilustrado na Figura 28.
Em este UC, o líder da avaliação irá selecionar a unidade que ele avaliou, vai fazer o upload dos artefatos relevantes da avaliação e informar o nível de cada atributo do WAVE encontrado para a unidade em questão.
Depois de cadastrados estes dados, o patrocinador poderá verificar estas informações por o UC 31 em qualquer momento.
O UC23 é detalhado no apêndice M. O UC &quot;Realizar download de treinamentos «permite a qualquer usuário realizar o download de um material que introduz o WAVE, 2 DAM-WAVE e DDS.
Além de os treinamentos, a tela deste UC apresenta informações sobre os pesquisadores envolvidos com o WAVE e o 2 DAM-WAVE.
O UC24 é detalhado no apêndice M. Domínio de &quot;Resultado de Avaliações «Esta seção apresenta requisitos funcionais do domínio de &quot;Resultado de Avaliações «da ferramenta de apoio, especificados como casos de uso.
Esse domínio inclui todos os UCs relevantes para a listagem, verificação e comparação de resultados.
Além disso, nesse domínio estão os UCs que possibilitam a consulta e comparação com o benchmarking de DDS que será disponibilizado no futuro.
A Figura 29 ilustra os UCs da dimensão de &quot;Resultado de Avaliações «no formato de diagrama de casos de uso da UML.
O UC &quot;Consultar resultado da avaliação «permite ao patrocinador consultar o resultado de qualquer dimensão de avaliação do 2 DAM-WAVE que já tenha sido completada.
Em todas as avaliações, o nível de capacidade geral da unidade no WAVE é exibido junto com os gráficos de aderência geral da unidade ao WAVE e à aderência da unidade nas áreas de pessoas, projetos, portfólio e unidade do WAVE, conforme ilustrado na Figura 30.
Além disso, o resultado de uma avaliação de dimensão mais abrangente expõe os artefatos relevantes para download, conforme ilustrado na Figura 31.
O UC30 é detalhado no apêndice M. O UC &quot;Listar avaliações «permite ao patrocinador verificar todas as avaliações iniciadas para a sua organização, conforme ilustrado na Figura 32.
Este UC é o ponto de entrada para os UCs 12, 30, 33 e 34.
O UC31 é detalhado no apêndice M. O UC &quot;Consultar benchmarking «permite a qualquer usuário verificar o benchmarking gerado por a equipe MuNDDoS com os dados coletados no 2 DAMWAVE.
Este UC disponibiliza links para fazer download dos benchmarkings gerados.
O UC32 é detalhado no apêndice M. O UC &quot;Consultar benchmarking «permite ao patrocinador comparar um resultado de avaliação da sua unidade com a média das unidades avaliadas até o momento.
O patrocinador deve ter a possibilidade de fazer um filtro sobre as avaliações que serão utilizadas para fazer a média de comparação, podendo, por exemplo, comparar- se somente com avaliações realizadas em unidades brasileiras.
O layout da tela de comparação deve mostrar duas avaliações lado a lado, como se tivessem duas telas do UC 30 em paralelo.
Em a parte da esquerda deve aparecer o resultado da avaliação da unidade selecionada por o patrocinador e, na direita, a média de resultados das avaliações filtradas.
O UC33 é detalhado no apêndice M. O UC &quot;Comparar resultados das avaliações «permite ao patrocinador comparar dois resultados de avaliações conduzidas na sua organização.
A ferramenta deve mostras as duas avaliações selecionadas lado a lado, como se houvesse duas telas do UC 30 em paralelo.
O UC34 é detalhado no apêndice M. Com o objetivo de testar o método de avaliação proposto, aplicaram- se dois estudos de caso em duas grandes organizações, e, nos dois casos, ambas as dimensões de avaliação do 2 DAM-WAVE foram aplicadas.
As organizações foram escolhidas por serem pioneiras no DDS, ambas com mais de duas décadas de experiência na área e por terem um bom relacionamento com o grupo de pesquisa MuNDDoS.
Em estas organizações, foram escolhidas unidades com mais de uma década de experiência em DDS e que desenvolvessem projetos distribuídos com outras unidades da organização.
Outra característica, das duas organizações escolhidas, é a preocupação e busca constante de melhoria em seus processos, através de publicação de artigos e fomento à pesquisa.
Este entendimento foi importante para que os avaliadores obtivessem, das organizações e profissionais envolvidos, todo o respaldo necessário para a condução das avaliações.
Durante o processo de escolha das organizações, procurou- se identificar uma que trabalhasse com offshore insourcing e outra com offshore outsorcing.
A aplicação do estudo de caso, na primeira organização, buscava testar o método de avaliação do WAVE no ambiente em que o modelo havia sido originalmente proposto.
Já na segunda organização trabalhada, além de testar o método de avaliação, buscava- se testar a hipótese, levantada na concepção do WAVE, de que o modelo também poderia ser aplicado em organizações que praticavam o offshore outsorcing.
Frisa- se que a segunda avaliação procurou avaliar a relação entre as unidades da organização e não entre a unidade avaliada e seu cliente final.
Ambos os estudos de caso, coletaram feedbacks acerca de a validade das sugestões fornecidas, com o intuito de verificar se a avaliação proposta sugeriu sugestões relevantes para a unidade avaliada.
As duas dimensões foram avaliadas nos dois estudos de caso aplicados, devido a a intenção de averiguar se a dimensão da miniavaliação indicaria uma capacidade semelhante à da avaliação mais abrangente.
Além disso, ambas as dimensões avaliaram os mesmos projetos e consultaram as mesmas pessoas.
Os objetivos, de ambos os estudos de caso, são sumarizados na seção faz- se a descrição das etapas e atividades necessárias para a realização dos estudos de caso.
Em a seção 6.4 são apresentados os resultados dos dois estudos em questão e, por último, na seção 6.5, é realizada uma avaliação crítica do 2 DAM-WAVE com base nos estudos de caso citados.
Objetivo Testar a aplicabilidade das duas dimensões do 2 DAM-WAVE, verificando se ambas as dimensões do 2 DAM-WAVE indicam um resultado similar, e, também, se a avaliação entrega resultados relevantes em organizações que trabalham com offshore insourcing ou offshore outsorcing.
Unidade do Estudo O nome das organizações das unidades avaliadas nesta pesquisa serão referenciados como unidade &quot;A «e unidade &quot;B «durante esta dissertação.
A unidade &quot;A «possui mais de 700 funcionários, enquanto que a organização possui em torno de 70 mil funcionários.
O lucro da organização gira em aproximadamente 3 bilhões de dólares.
Em relação a a experiência em DDS, a unidade avaliada acumula mais de 10 anos de experiência, desenvolvendo projetos junto a diversos centros de desenvolvimento ao redor de o globo.
A unidade avaliada encontra- se instalada no parque tecnológico da PUCRS.
Para a avaliação da unidade &quot;A», foram escolhidos dois projetos representativos para a unidade em relação a faturamento, tamanho médio da equipe e utilização de processos.
Estes projetos tinham interação constante com mais duas unidades da organização.
A unidade &quot;B «possui mais de 25 mil funcionários, enquanto que a organização possui em torno de 150 mil funcionários.
O lucro da organização gira em aproximadamente 1,5 bilhões de dólares.
Em relação a a experiência em DDS, a unidade avaliada acumula mais de 20 anos de experiência, desenvolvendo projetos junto a diversos centros de desenvolvimento para clientes ao redor de o globo.
A unidade avaliada encontra- se instalada em Bangalore na Índia e, importante frisar, que a mesma trabalha na configuração de Offshore Outsourcing.
Para a avaliação da unidade &quot;B «também foram escolhidos dois projetos representativos para a unidade em relação a faturamento, tamanho médio da equipe e utilização de processos, mas, no entanto, alguns cuidados foram tomados, devido a o fato da organização trabalhar com outsorcing.
Foram escolhidos dois projetos que apresentassem distribuição global com outras unidades da própria organização e não só distribuição entre o cliente e a unidade.
Desta forma, a avaliação do WAVE buscou verificar as interações entre as unidades da mesma organização, com o intuito de identificar sua capacidade em Etapas O estudo de caso foi executado em três etapas:
&quot;Planejamento e «Aprovação», Aplicação do 2DMA-WAVE &quot;e «Análise dos Dados».
Em a primeira etapa, &quot;Planejamento e Aprovação», foram estabelecidos os contatos com a unidade &quot;A «e a unidade &quot;B».
Em as primeiras reuniões o 2 DAMWAVE e o WAVE foram apresentados, detalhando os benefícios e a quantidade de recursos necessários para a aplicação de ambas as dimensões desta avaliação.
Além disso, foram evidenciados os resultados esperados da pesquisa e, também, assinados os termos de confidencialidade.
A ferramenta de apoio, desenvolvida nesta pesquisa, auxilia na contextualização das organizações em relação a o WAVE, 2 DAM-WAVE e as necessidades e benefícios desta avaliação.
Porém, como o primeiro contato das organizações ocorreu através dos pesquisadores da PUCRS, e não por o uso da ferramenta de apoio, houve a necessidade de contextualização verbal.
Tabela 26 ­ Etapa &quot;Planejamento e Aprovação do Estudo de Caso «na unidade &quot;A «Etapa de Planejamento e Aprovação do Estudo de Caso na Unidade &quot;A «Atividade Contato com a unidade A para aplicar o 2 DAMWAVE Identificação dos recursos e profissionais necessários Disponibilização dos recursos e profissionais para a avaliação Participantes Pesquisador da PUCRS X Pesquisador da PUCRS Y Pesquisador da PUCRS Z Patrocinador da Avaliação da Unidade Pesquisador da PUCRS X Patrocinador da Avaliação da Unidade Gerente de Projetos da Unidade Gerente de Unidade da Unidade Duração Início 15/11/2011 Final 02/12/2011 1 hora de reunião Início 02/11/2011 Final 12/12/2011 O principal desafio, enfrentado nesta etapa e em ambas as organizações, foi a argumentação sobre os benefícios da avaliação e da necessidade de liberação de recursos para atender às demandas de ambas as dimensões da avaliação.&amp;&amp;&amp;
Por isso, algumas atividades da avaliação não alcançaram o nível de profundidade inicialmente desejado.
Durante a atividade &quot;Desenvolvimento do Plano de Avaliação», por exemplo, o artefato &quot;Plano da Avaliação «(Ap D) não foi totalmente preenchido.
Importante frisar que se tomou cuidado para que nenhuma restrição, que realmente afetasse o bom andamento da avaliação, fosse admitida.
Etapa de Planejamento e Aprovação do Estudo de Caso na Unidade &quot;B «Atividade Participantes Contato com a unidade B para aplicar o 2 DAMWAVE Identificação dos recursos e profissionais necessários Disponibilização dos recursos e profissionais para a avaliação Pesquisador da PUCRS X Pesquisador da PUCRS Y Patrocinador da Avaliação da Unidade Início 15/01/2012 Final 30/01/2012 Pesquisador da PUCRS X Patrocinador da Avaliação da Unidade 30 minutos de reunião Patrocinador da Avaliação da Unidade Duração Início 23/02/2012 Final 28/02/2012 Em a etapa de condução da avaliação, chamada &quot;Aplicação do 2DMAWAVE», foram executadas todas as atividades previstas no 2 DAM-WAVE, tanto para a dimensão de miniavaliação, quanto para a dimensão mais abrangente.&amp;&amp;&amp;
Os envolvidos e a duração de cada atividade necessária, para completar esta etapa, foram sumarizados na Tabela 28 para a unidade &quot;A «e na Tabela 29 para a unidade &quot;B».
Em a unidade &quot;A», a atividade de planejamento da avaliação foi finalizada junto com a última coleta de dados.
Embora a maioria dos dados do artefato &quot;Plano de Avaliação «(Ap D) já estivessem preenchidos, o planejamento das coletas de dados ficou em aberto durante toda a condução da avaliação.
Isto ocorreu devido a a dificuldade de alocação dos funcionários dos projetos avaliados, mas, mesmo assim, não houve prejuízos para a avaliação, visto que o avaliador estava perto de a unidade avaliada e com tempo disponível para eventuais compromissos.
A condução da miniavaliação demandou mais de uma semana para ser finalizada, visto que um dos respondentes demorou em responder o questionário.
Houve somente uma rodada de respostas aos formulários Web, pois, na primeira rodada todos os 23 atributos do WAVE obtiveram consenso.
Os dados coletados na avaliação mais abrangente foram suficientes para a conclusão da avaliação, no entanto algumas dificuldades, aqui relatadas, foram encontradas.
Em uma das seções de entrevistas, foram alocados três funcionários de perfil técnico ao mesmo tempo e, essa configuração, dificultou a conclusão da entrevista num tempo menor que 1 hora, fazendo com que os funcionários cansassem e participassem menos na parte final.
Além disso, devido a restrições de horário, o avaliador interno só esteve disponível durante uma hora para a análise de artefatos e isto, embora tenha sido suficiente, não foi o ideal.
Durante a análise de dados, a maioria das sugestões encontradas surgiu a partir de as próprias sugestões dos avaliados.
Devido a a alta capacidade da unidade em DDS e à pequena discrepância de capacidade entre os projetos, poucas sugestões foram identificadas através da comparação entre projetos e por a análise de práticas não implementadas.
Sugestões do avaliador também foram incluídas no grupo de melhorias propostas, mas não em grande quantidade, visto que a unidade &quot;A «foi a primeira a ser avaliada com o 2 DAM-WAVE por este avaliador.
Em a unidade &quot;B», em relação a o término do &quot;Plano de Avaliação «(Ap D), ocorreu um problema parecido com o que se percebeu na unidade &quot;A», porém, neste estudo de caso, ele foi terminado antes da conclusão da coleta de dados da avaliação mais abrangente.
Tal problema ocorreu, também, devido a a dificuldade de alocação dos funcionários dos projetos avaliados.
A condução da miniavaliação foi realizada uma semana após a condução da avaliação mais abrangente.
Como a miniavaliação não necessita de especialistas em WAVE ou em 2 DAM-WAVE para acontecer, optou- se por dedicar todo o tempo do avaliador líder hospedado, na unidade &quot;B», para conduzir a avaliação mais abrangente.
A miniavaliação, na unidade &quot;B», assim como na unidade &quot;A», também precisou de duas rodadas de respostas, visto que, na primeira rodada, constatou- se que 5, dos 23 atributos, não obtiveram consenso.
Em ambos os estudos de caso, a ferramenta de apoio facilitou a discussão entre os entrevistados para que pudessem chegar a um consenso e responder novamente os questionários Web.
Em a avaliação mais abrangente, todas as entrevistas ocorreram dentro de o prazo de uma hora, estabelecido por o processo, e os dados coletados foram suficientes para a conclusão da avaliação.
Assim como no primeiro estudo de caso, devido a restrições de horário, o avaliador interno só esteve disponível durante meia hora para a análise de artefatos.
Embora tenha sido tempo suficiente, não foi o ideal, pois se obteria melhor proveito se os artefatos fossem analisados com mais detalhes, possibilitando, assim, uma proposta de sugestões acerca de a qualidade dos artefatos e não só sobre sua existência ou não.
Durante a análise de dados, a maioria das sugestões encontradas surgiu a partir de as discrepâncias de capacidade entre os projetos e da experiência do avaliador.
Outro fato percebido foi que, em ambos os projetos avaliados, em alguns casos, identificaram- se processos e ferramentas diferentes e, na maioria das vezes, devido a a imposições de clientes, questão comum em ambientes de outsorcing.
Além disso, o avaliador pôde utilizar a experiência adquirida no estudo de caso anterior para propor melhorias para a organização.
A unidade &quot;B «identificou a maioria das melhorias propostas como relevantes e, algumas de elas já estavam inclusive sendo endereçadas por o departamento de pesquisa da unidade.
Além disso, a unidade demonstrou grande interesse em continuar utilizando, internamente, o WAVE e o 2 DAM-WAVE para melhorar os seus processos.
Finalmente, na etapa &quot;Análise dos Dados», houve o tratamento e a organização de todas as sugestões de melhorias e feedbacks coletados.
Estas sugestões de melhorias foram estimuladas durante toda a avaliação, mas, principalmente, nos momentos de coleta de dados e nas reuniões.
As melhorias e a percepção do pesquisador embasam o exposto na seção 6.5 de &quot;Análise Crítica».
Os envolvidos e a duração de cada atividade necessária para completar esta etapa, foram sumarizados na Tabela 30.
Os resultados obtidos na avaliação de ambas as dimensões da unidade &quot;A «estão sumarizadas na Tabela 31, enquanto que os resultados de ambas as dimensões da unidade &quot;B «estão sumarizadas na Tabela 33.
Os resultados demonstram que a unidade &quot;A «tem uma grande capacidade para a realização de desenvolvimento distribuído de software.
A alta capacidade na área de capacidade de &quot;Projetos «denota que, esta unidade, tem processos e ferramentas que endereçam todos os aspectos relacionados à engenharia de software que são referenciados no WAVE.
As questões que mais se destacaram nesta área de capacidade, na unidade &quot;A», foram os atributos de &quot;Gerência de Riscos», &quot;Gerência de Configuração e Ferramentas de Colaboração».
Estes 3 atributos, não só implementaram todas as práticas do WAVE, como também não registraram nenhum defeito não relevante ou sugestão de melhoria.
No entanto, foram sugeridas questões relevantes para a melhoria de outros atributos, como:
&quot;Aumento na oferta de salas de videoconferência», &quot;Compra de webcams para os desktops a fim de possibilitar comunicação com rico contexto», &quot;Utilizar uma ferramenta para realizar o tracking de requisitos», entre outras.
Em a área de &quot;Portfólio», a unidade &quot;A «obteve máxima capacidade, indicação de que possui capacidade de gerir múltiplos projetos com colaboração de outras unidades, sendo totalmente aderente ao modelo WAVE.
Isto significa, por exemplo, que o seu processo de alocação de projetos é formal e uniforme em toda a organização.
Além disso, este processo envolve diferentes tipos de profissionais e unidades, tendo a participação de profissionais da área técnica para a estimativas, de profissionais da área gerencial para auxiliar na criação do cronograma e de profissionais da área de negócio, para verificar a relevância do projeto para a organização.
Nenhuma sugestão de melhoria foi encontrada para esta área de capacidade.
Em relação a a área de &quot;Unidade», a unidade &quot;A «também foi muito bem, uma vez que suas políticas e padrões, tanto em nível de unidade quanto em nível organizacional, são comunicadas a todos os funcionários através de treinamentos e e-mails.
Além disso, possui diversas formas que possibilitam sugerir e aprimorar os processos da unidade e da organização, através de portais, blogs, grupos de melhorias, entre outros.
O único ponto fraco, encontrado nesta área, é a constatação de que nem todos os funcionários sabem de todas as formas oferecidas para contribuir com a evolução dos processos da unidade.
Para ajudar a sanar este problema, foi aconselhada a construção de um portal que congregasse todos os mecanismos disponíveis.
Por último, mesmo tendo obtido um grande nível de capacidade, a área de &quot;Pessoas «foi a que teve a maior quantidade de sugestões de melhorias propostas.
Embora a unidade &quot;A «possua algumas melhorias para auxiliar na aquisição de confiança, as mesmas não foram padronizadas e espalhadas na unidade ou organização.
Existe muito espaço para melhorias neste atributo, como por exemplo, estabelecer avaliações de feedback entre as unidades com o objetivo de avaliar o trabalho desenvolvido ou aumentar o número de viagens, no início de projetos críticos, para possibilitar que os times se conheçam.
Além disso, foram sugeridas melhorias para aprimorar a percepção dos membros do time sobre os processos de outras unidades e, também, sobre a disponibilidade de pessoas distribuídas em outras unidades.
Em o total, dezenove melhorias foram sugeridas, separadas de acordo com a Tabela 32.
Os resultados da unidade &quot;B», apresentados na Tabela 33, mostram que, embora a unidade tenha obtido um alto nível de capacidade em DDS, ainda possui muito espaço para melhorias.
O principal motivo para que a unidade não tenha implementado mais práticas do nível 4 de capacidade do WAVE, deve- se ao fato de que, em alguns projetos, há a adoção de ferramentas, práticas e processos do cliente destes projetos e, esta prática, dificulta a padronização de certas iniciativas na organização.
A unidade demonstrou ter diversas iniciativas para lidar com as dificuldades relacionadas à área de capacidade de &quot;Pessoas».
Existe a disponibilidade de uma ampla gama de oportunidades de treinamento e capacitação em questões técnicas e não técnicas, tanto em níveis organizacionais quanto em nível de unidade.
Além disso, existem processos definidos para a maioria dos tipos de projetos e uma constante preocupação em diminuir o impacto das diferenças culturais, bem como em aumentar a aquisição de confiança entre os membros do time.
No entanto, alguns pontos de melhoria se fazem necessários em relação a o atributo de capacidade de &quot;Percepção (awareness) sobre as atividades», visto que se identificou a inexistência de uma ferramenta padrão que auxilie nesse sentido.
Em o atributo de &quot;Gestão de conhecimento», verificou- se que diferentes projetos utilizam diferentes ferramentas, como Wikis ou Portais, provocando, na organização, dificuldades de acesso ao conhecimento de uma forma padronizada.
Por último, no atributo de &quot;Aprendizado», percebeu- se a necessidade de um portal que ofereça, num só espaço, todas as oportunidades de aprimoramento para os profissionais da organização, pois, durante as entrevistas, notou- se que a maioria dos profissionais não sabia de todas as oportunidades disponíveis neste sentido.
Em a área de &quot;Projetos», a unidade &quot;B «também se preocupa com grande parte dos desafios do DDS, através de processos e ferramentas, no entanto, alguns atributos do WAVE podem ser amplamente melhorados, como os atributos &quot;Gerência de Riscos», &quot;Ferramentas de Colaboração e Engenharia de Requisitos».
Notou- se que a gerência de riscos é controlada em todos os projetos e existe um processo para escalar riscos mais eminentes, porém esta lista de riscos não fica disponível para todas as pessoas do projeto.
Não existe, também, uma ferramenta de colaboração padronizada na unidade, que auxilie na divulgação de riscos para todos os níveis, na verificação de status de atividades e na disponibilidade da equipe, entre outros.
Por fim, assim como observado na unidade &quot;A», a unidade &quot;B «também sofre com a falta de uma ferramenta que gerencie o ciclo de vida dos requisitos de um projeto.
Em a área de &quot;Portfólio», a unidade &quot;B «obteve, também, máxima capacidade, que indica que a organização tem um processo definido e padronizado para alocação de projetos, que a unidade executa todos os tipos de projetos e que existe um PMO em nível de unidade e organização.
Para esta área de capacidade não houve nenhuma sugestão de melhoria.
Por fim, na área de &quot;Unidade», a unidade &quot;B «implementou corretamente o atributo &quot;Políticas e padrões», mas não implementou diversas práticas do atributo &quot;Iniciativas de melhoria de processo de software».
Em relação a o atributo &quot;Políticas e padrões», assim como na unidade &quot;A», as políticas e padrões são corretamente comunicadas a todos os funcionários através de treinamentos, atendimento por telefone, via portal, entre outras formas.
Quanto a o atributo &quot;Iniciativas de melhoria de processo de software», percebeu- se que a maioria dos entrevistados não soube explicar quais eram os canais de sugestão de melhorias.
Sabendo que estes canais existem, pois foram identificados durante a análise de artefatos, sugeriu- se que estes deveriam ser mais bem divulgados, incentivando o uso por parte de os colaboradores, além de serem agregados e oferecidos na forma de um portal de melhorias.
Em o total, vinte e duas melhorias foram sugeridas, distribuídas de acordo com a Tabela 34.
A aplicação do 2 DAM-WAVE, em ambiente real, atingiu seu objetivo, uma vez que a capacidade da unidade avaliada foi percebida com a assertividade esperada em ambas as dimensões, de acordo com a percepção do gerente da unidade e do pesquisador.
A troca de experiências e a coleta de dados obtiveram um feedback positivo de todos os envolvidos na avaliação.
Estes dados, coletados através da prática de se conduzir dois estudos de caso, foram confrontados com o modelo preliminar do 2 DAM-WAVE, proposto através de uma análise qualitativa dos estudos realizados na base teórica.
Essa análise identificou cinco lições aprendidas e estão descritas a seguir: --
Lição aprendida 1 ­ Aumentar as sessões de entrevistas e limitar a quantidade de pessoas Ao longo de a condução dos dois estudos de caso, percebeu- se que as entrevistas que continham mais de 2 pessoas tendiam a passar do tempo préestabelecido de 1 hora de duração, acarretando na perda do foco dos entrevistados e no aumento da velocidade das entrevistas, prejudicando uma análise apurada de determinados atributos do WAVE.
Optou- se, então, por limitar o número de entrevistados para 2 a cada sessão e, desta forma, a conclusão das entrevistas ficou facilitada, todavia sem a perda da oportunidade de promoção da discussão através de diferentes pontos de vista.
Além de o exposto, notou- se a necessidade de aumentar para 4 o número de sessões de entrevistas, sendo que duas técnicas e duas gerenciais e, também, de formas intercaladas.
Este formato possibilita, então, aprender sobre a unidade nas primeiras duas sessões de entrevistas técnicas e não técnicas, cruzar as descobertas com a análise de artefatos e, por fim, utilizar as últimas duas sessões de entrevistas para diminuir dúvidas e confirmar afirmações e discrepâncias já identificadas.
As alterações no 2 DAM-WAVE, decorrentes desta lição aprendida, estão descritas na Tabela 35. --
Lição aprendida 2 ­ Realizar análise de artefatos com o avaliador líder e entre as sessões de entrevistas Em a primeira versão do processo de avaliação, a análise de artefatos era feita em paralelo com as entrevistas e sem ordem definida.
Em um dos estudos de caso, notou- se que realizar a análise de artefatos antes das entrevistas não era o ideal, pois ainda não se tinha conhecimento das ferramentas, atividades e processos que existiam na unidade.
Em o outro estudo de caso, a análise de artefatos foi realizada ao final da avaliação e, esta prática, também, não se configurou como ideal, pois, através da análise dos artefatos, perceberam- se inconsistências que seriam melhores tratadas se abordadas nas entrevistas.
Por conta das duas situações constatadas, mudou- se o processo para que a análise de artefatos fosse realizada entre as 4 sessões de entrevistas.
As alterações no 2 DAM-WAVE, decorrentes desta lição aprendida, estão descritas na Tabela 36. --
Lição aprendida 3 ­ Entrevistar um gerente de portfólio ou equivalente A partir de os estudos de caso, notou- se que somente as entrevistas com profissionais que desempenhavam o papel de gerente de portfólio ou equivalente, conseguiam responder determinadas perguntas do WAVE com detalhes.
Estes profissionais, que geralmente são responsáveis por a gerência de múltiplos projetos, conseguem responder com mais propriedade sobre como é o processo de alocação de projetos e a estrutura de PMOs na organização, entre outros atributos.
Sendo assim, efetuaram- se mudanças no processo para que pelo menos um profissional, com estas responsabilidades, participe da avaliação.
As alterações no 2 DAM-WAVE, decorrentes desta lição aprendida, estão descritas na Tabela 37. --
Lição aprendida 4 ­ Tamanho da equipe de avaliação Em ambos os estudos de caso, notou- se que não eram necessários dois funcionários da unidade avaliada para participarem como membros do time interno de avaliação.
Essa quantidade havia sido originalmente proposta porque se esperava que os avaliadores internos à unidade avaliada seriam responsáveis por a análise de artefatos sem o envolvimento do avaliador líder.
Esse tipo de situação ocorre em outros métodos de avaliação consolidados, como por exemplo, no SCAMPI A.
No entanto, o treinamento dado no início das avaliações do 2 DAM-WAVE não é suficiente para que os avaliadores internos consigam realizar essa atividade sozinhos.
Além disso, seria um desperdício não utilizar o conhecimento adquirido nas entrevistas do avaliador líder durante a análise de artefatos.
Por conta disso, a demanda do papel de avaliador interno à organização diminuiu no 2 DAM-WAVE, justificando o envolvimento de somente um funcionário. --
Lição aprendida 5 ­ Rever aplicabilidade de atributos do WAVE A partir de os dois estudos de caso, percebeu- se que alguns atributos do modelo WAVE deveriam ser verificados, atualizados e, inclusive, alguns excluídos.
Um exemplo ocorre ao analisarmos os atributos &quot;Aprendizado «e &quot;Treinamento «que, por tratarem de questões similares, poderiam ser agregados, trazendo, assim, mais consistência ao modelo.
O atributo &quot;Distância percebida entre as unidades distribuídas «não pôde ser avaliado, pois, na verdade, representa uma composição de diversos outros atributos como &quot;Diferenças culturais «e &quot;Aquisição de confiança «e, sendo assim, sugere- se que o mesmo seja retirado do modelo.
O atributo &quot;Infraestrutura «é muito genérico, pois da forma como está escrito, pode ser facilmente considerado implementado ou não implementado, dependendo exclusivamente da interpretação do avaliador.
Os atributos &quot;Tipos de projeto e «&quot;Ciclo de vida de desenvolvimento de software «devem ser revisitados, pois, durante a avaliação dos especialistas às perguntas da miniavaliação, identificou- se incoerências no caminho de evolução destes atributos.
Por fim, sugere- se a atualização do atributo &quot;Escritório de gerência de projetos», visto que o termo PMO não é mais utilizado em ambas as unidades avaliadas.
A o final dessa pesquisa, organizações que buscam aumentar a sua capacidade em DDS podem utilizar o WAVE como modelo de referência em seus programas de melhorias de processos.
Para avaliar a evolução dos processos, essas empresas podem utilizar o 2 DAM-WAVE em ciclos sucessivos de melhoria.
Portanto, esta pesquisa atingiu seu objetivo geral, que era de propor um método de avaliação para o modelo de capacidade WAVE, que auxiliasse as organizações a avaliar a sua capacidade no modelo de referência WAVE.
A proposta do método de avaliação 2 DAM-WAVE está descrita no capítulo 4 e é a principal contribuição dessa pesquisa.
O objetivo específico de &quot;Aprofundar os estudos da base teórica», foi atingido ao se estudar sobre DDS, WAVE, modelos de referência e métodos de avaliação.
Esse estudo está descrito no capítulo 2 e embasou o 2 DAM-WAVE (Two--dimensional Assessmente Method ­ WAVE), que é método de avaliação proposto, descrito no capítulo 4 e que atinge o objetivo específico de &quot;Propor o método um método de avaliação».
Este método de avaliação possui duas dimensões, uma para miniavaliações e outra mais abrangente.
As duas dimensões propostas auxiliam a aplicação do WAVE em organizações em diferentes estágios e necessidades de melhoria.
O método proposto é acompanhado por uma ferramenta de apoio para facilitar o processo de avaliação, atingindo o objetivo específico &quot;Criar uma ferramenta de apoio à aplicação do método de avaliação proposto», descrito no capítulo 5.
Essa ferramenta suporta todas as atividades de ambas as dimensões do 2 DAM-WAVE sendo considerada outra grande contribuição da pesquisa.
Tanto o método de avaliação como a sua ferramenta de apoio foram aplicados na indústria, através de dois estudos de caso, abrangendo as duas dimensões do 2 DAM-WAVE, auxiliando ambas as unidades avaliadas a perceberem seus pontos fracos, fortes e oportunidades de melhoria de forma priorizada.
Além disso, essas aplicações auxiliaram a encontrar pontos de melhorias no WAVE e no 2 DAM-WAVE.
Estas experiências atingiram o objetivo específico &quot;Testar o método de avaliação proposto «e foram descritas no capítulo Por último, três artigos sobre essa pesquisa foram redigidos, até a data da entrega dessa dissertação.
Dois de eles foram aprovados e outro está à espera de aprovação.
Essa produção científica atinge o último objetivo específico de &quot;Escrever artigos científicos relacionados à pesquisa».
Contribuições Esta pesquisa traz contribuições tanto para a academia quanto para a indústria.
Além disso, o conhecimento adquirido, durante o desenvolvimento da dissertação, contribuiu para o meu crescimento profissional e pessoal, descritos a seguir.
Essa pesquisa agregou valor à área de DDS ao se propor um método de avaliação para o modelo de capacidade WAVE, visto que somente um método de avaliação, focado para empresas que trabalham com configuração offshore, foi encontrado durante a revisão bibliográfica.
O=2  DAM-WAVE também complementa o modelo de capacidade WAVE, habilitando- o a ser aplicado na indústria ou academia.
Além disso, a ferramenta de apoio proposta auxilia em todas as atividades do 2 DAM-WAVE, além de possibilitar que pesquisadores possam verificar a evolução da capacidade do DDS ao longo de o tempo, melhorando a percepção da academia sobre o que está ocorrendo na indústria.
A indústria também será beneficiada por esta pesquisa, pois, com o 2 DAMWAVE, empresas poderão ser avaliadas, obtendo sugestões de melhorias e indicação de capacidade de processos.
Além disso, o método de avaliação mantém um repositório de boas práticas para que empresas possam verificar como outras empresas melhoram seus processos em ambientes DDS.
A indústria também é beneficiada por a ferramenta de apoio desenvolvida nessa pesquisa, uma vez que a mesma possibilita miniavaliações sem nenhum custo para a unidade interessada e contato facilitado com especialistas em DDS.
Além disso, organizações podem, com o 2 DAM-WAVE, verificar se todas as suas unidades possuem uma capacidade comum em DDS e identificar gargalos e oportunidades de melhorias em suas unidades.
Finalmente, este estudo aprofundou meus conhecimentos em DDS, modelos de capacidade e métodos de avaliação, tornando- me um profissional apto a contribuir para a academia e para a indústria como especialista nestes conceitos.
Além disso, a condução desta pesquisa me auxiliou no processo de amadurecimento como pessoa, melhorando a minha capacidade de realização e meu método de trabalho.
Limitações Por conta do método de pesquisa escolhido, estudo de caso, essa pesquisa apresenta limitações inerentes aos estudos qualitativos.
A principal limitação está relacionada a generalização de resultados, uma vez que somente dois estudos de caso foram aplicados.
Por essa questão, não se pode afirmar que o 2 DAM-WAVE não precise de ajustes para ser aplicado em outras organizações que trabalham com DDS.
Além disso, a ferramenta de apoio não foi amplamente testada, sendo utilizada somente nos dois estudos de caso.
Isso quer dizer que podem existir defeitos na mesma e esses podem aparecer a medida que novas organizações busquem o 2 DAM-WAVE para realizar avaliações de capacidade.
Outra limitação da ferramenta é que somente as partes necessárias para o segundo estudo de caso foram traduzidas para a língua Inglesa.
Também não foi implementado um mecanismo de troca de língua, o que quer dizer que hoje, a ferramenta tem que ser republicada no servidor Web para trocar a língua.
Finalmente, conforme verificado durante a aplicação dos estudos de caso, o modelo de capacidade WAVE deve ser revisitado, a fim de melhorar os seus atributos.
Alguns atributos do WAVE se tornam redundantes ao avaliar questões parecidas, outros não são necessários e alguns poucos devem ser atualizados, esse detalhamento foi feito na seção 6.5.
Essas melhorias auxiliariam as avaliações o 2 DAM-WAVE a gerar sugestões de melhorias mais relevantes para a unidade avaliada.
Isso se tornou uma limitação do trabalho, visto que esta pesquisa não tinha, no seu escopo, a melhoria do modelo de capacidade WAVE.
Trabalhos Futuros Percebe-se uma oportunidade para aplicar o WAVE e o 2 DAM-WAVE em mais organizações.
Essas avaliações auxiliariam no amadurecimento do WAVE e do 2 DAM-WAVE através da experiência adquirida e coleta de feedbacks.
Esse trabalho atenuaria a principal limitação dessa pesquisa e da de o WAVE, que foi a capacidade de generalização.
Além disso, sugere- se a revisão do WAVE, levando em consideração as lições aprendidas dessa pesquisa e descritas na seção 6.5.
Esse trabalho é importante para aumentar a assertividade do 2 DAM-WAVE sobre o nível de capacidade das unidades avaliadas.
Além disso, essa iniciativa seria importante para facilitar as avaliações tirando ambiguidades existentes hoje no modelo Por último, melhorar a ferramenta de apoio do 2 DAM-WAVE, aplicando testes mais rigorosos, melhorando seu conteúdo textual, traduzindo todo o seu conteúdo para inglês, e também, implementando o UCs sugeridos no capítulo 5.
A ampliação dos testes da ferramenta de apoio diminuiria o risco de ocorrerem dificuldades no seu uso fora de o ambiente controlado dos estudos de caso.
A ampliação e qualificação do conteúdo textual, junto com a tradução para o inglês facilitaria o uso da ferramenta, do WAVE e do 2 DAM-WAVE por a comunidade científica e profissional.
Por último, a implementação dos UCs sugeridos proporcionariam funcionalidades que se tornariam muito interessantes para a indústria e para a academia, destacando- se os UCs que envolvem a disponibilização do benchmarking de DDS.
Estas funcionalidades aumentariam o valor agregado das avaliações do 2 DAM-WAVE, gerando mais incentivo para a condução de novas avaliações em outras organizações.
