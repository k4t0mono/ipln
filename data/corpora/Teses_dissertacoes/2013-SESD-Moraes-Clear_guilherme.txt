A capacidade de integração em sistemas embarcados acompanha a tendência da Lei de Moore, a qual prevê que a cada dezoito meses o número de transistores em circuitos integrados dobra, enquanto seu custo permanece constante.
Outra observação importante em sistemas embarcados é que aplicações com mais de um processador estão cada vez mais presentes no mercado.
Estes dispositivos com diversos elementos de processamento são denominados MPSoCs (do inglês, Multiprocessor Sytem-on-Chip).
Os MPSoCs permitem o desenvolvimento de sistemas complexos, com alto desempenho.
Para que um MPSoC atenda às restrições das aplicações em ele executadas, técnicas de gerência e adaptabilidade de recursos devem ser pesquisadas e desenvolvidas.
O presente trabalho apresenta o desenvolvimento e avaliação de técnicas de controle adaptativo para atendimentos a requisitos de aplicações executando em MPSoCs.
Para efetuar o controle do MPSoC utiliza- se o mecanismo de monitoramento das aplicações.
A técnica de monitoramento analisa os requisitos das aplicações, em tempo de execução, verificando possíveis violações nestes requisitos, como vazão e latência.
O monitoramento é o gatilho para a execução das técnicas adaptativas desenvolvidas no escopo deste trabalho:
Alteração dinâmica na prioridade de escalonamento de tarefas e migração de tarefas.
Para avaliar as técnicas propostas, foi utilizado a plataforma HeMPS com gerência de recursos centralizada e distribuída.
Os resultados mostram que, independente da gerência de recursos que se utiliza, centralizada ou distribuída, as técnicas de adaptabilidade proveem redução de latência e jitter, sem comprometimento do tempo total de execução das aplicações.
Com a execução das técnicas de adaptabilidade, o tempo total de execução da aplicação principal não é penalizado, nos casos de teste, melhorando- se em até 7%.
Palavras-Chave: MPSoC, NoC, gerenciamento de aplicações, controle adaptativo, técnicas de adaptabilidade, monitoramento de tarefas, migração de tarefas, escalonamento.
Gordon Moore, em 1965, constatou que a cada 18 meses o número de transistores em circuitos integrados dobra, enquanto seu custo permanece constante.
Tortato e Hexsel comentam que a capacidade de sistemas embarcados vem acompanhando a tendência da Lei de Moore e que as aplicações com mais de um processador estão cada vez mais presentes no mercado.
Como consequência do aumento do número de transistores, tornou- se possível desenvolver sistemas completos elementos de processamento (PEs ­ Processing Elements).
Segundo, sistemas embarcados estão cada vez mais presentes em produtos de bens de consumo como televisores, micro-ondas, telefones celulares e tablets, e a principal característica nestes produtos é executar funcionalidades específicas.
Um MPSoC pode ser projetado para uma determinada aplicação ou conjunto de aplicações, ou ser de propósito genérico, tal qual os FPGAs (Field-Programmable Gate Array) são hoje para o projeto de circuitos digitais.
Em o primeiro caso, as decisões arquiteturais são realizadas em tempo de projeto, podendo- se otimizar elementos como a NoC ou a hierarquia de memória para os requisitos das aplicações alvo.
Em o segundo caso, MPSoCs de propósito genérico, estes devem ser capazes de executar diferentes aplicações e classes de aplicações.
Para que isto seja possível, os MPSoCs devem prover técnicas de adaptabilidade para prover qualidade de serviço.
Exemplos de MPSoCs de propósito genérico incluem os dispositivos TILERA e INTEL.
O foco da presente Dissertação é no projeto de MPSoCs de propósito genérico e no desenvolvimento de técnicas de adaptabilidade para garantir o atendimento às restrições das aplicações.
As técnicas de adaptabilidade incluem, por exemplo:
Migração de tarefas para balanceamento de carga, mantendo as tarefas comunicantes da mesma aplicação sendo executas próximas uma das outras;
Monitoramento de tarefas, para verificar o atendimento às restrições das aplicações, como vazão e latência;
Controle distribuído, para efetuar gerenciamento de recursos;
DVFS, alteração dinâmica de voltagem e frequência;
Chaveamento por circuito, reserva totalmente o canal físico entre o par comunicante (processadores que executam tarefas comunicantes), possibilitando máxima vazão;
Alterações na prioridade de comunicação.
Para prover adaptabilidade em tempo de execução, Fattah Comentam que muitos trabalhos propõem estruturas de monitoramento que observam o estado dos sistemas em tempo de execução em termos de:
Transações, temperatura, sobrecarga na rede, falhas, defeitos, etc..
Para que um sistema possa efetuar o monitoramento das aplicações, é necessário coletar as características das aplicações através de profiling (perfil).
Baseado nos dados desta coleta na etapa de monitoramento, o processador monitor é capaz de efetuar tomadas de decisão, tais como:
Alteração da prioridade de comunicação, migração de tarefas, escalonamento, DVFS (Dynamic Voltage and Frequency Scaling), e aumento da fatia de tempo alocada em cada processador para a execução das tarefas.
A adaptabilidade num MPSoC pode ser vista como um sistema de controle em malha fechada.
A Figura 1 ilustra os três passos do processo:
Monitoramento, diagnóstico e ação.
O monitoramento é efetuado em nível de tarefa num dado elemento de processamento (PE).
Os dados monitorados são enviados para um dado PE do sistema, o qual é responsável por a decisão de qual ação deve ser tomada em caso de não atendimento a determinados requisitos de aplicação.
A ação de diagnóstico pode ser centralizada ou distribuída.
Finalmente temos a tomada de ação, que envolve alguma das técnicas mencionadas anteriormente.
O processo é cíclico, executado de forma contínua ao longo de a execução das aplicações.
Avaliação dos dados monitorados e escolha da ação a tomar 3 -- Ação:
Escalabilidade é outro ponto importante que se deve levar em consideração no projeto de MPSoCs.
MPSoCs podem executar diversas aplicações em paralelo com carga de trabalho dinâmica (inserção de novas aplicações no MPSOC em tempo de execução).
Em o nível arquitetural a utilização de redes intra-chip (NoCs) tem se mostrado uma alternativa promissora em MPSoCs, dado que estas permitem múltiplas comunicações simultâneas.
Em o nível de gerência de recursos, o gerenciamento distribuído do MPSoC em regiões virtuais, denominadas clusters, é também apontada na literatura como uma técnica para prover escalabilidade em sistemas com elevado número de elementos de processamento.
Objetivos A presente Dissertação possui os seguintes objetivos estratégicos:
Domínio da tecnologia de projeto de MPSoCs que utilizam NoCs como meio de comunicação;
Domínio de técnicas adaptativas para garantir o atendimento às restrições das aplicações;
Domínio de técnicas de monitoramento de tarefas;
Domínio de técnicas de gerenciamento de recursos em MPSoCs.
Os objetivos específicos da presente Dissertação incluem:
Desenvolver uma técnica de migração de tarefas em MPSoCs;
Desenvolver escalonamento baseado em prioridades para tarefas executando em MPSoCs;
Desenvolver monitoramento para controle de deadlines de tarefas;
Utilizar a migração de tarefas para a desfragmentação do sistema, técnica esta denominada de reclustering.
Contribuições da Dissertação A presente Dissertação tem por contribuição o desenvolvimento de duas técnicas de adaptabilidade no projeto de MPSoCs:
Alteração dinâmica na prioridade de escalonamento de tarefas e migração de tarefas.
Ambas as técnicas são controladas por monitores de desempenho.
A migração de tarefas é empregada em dois cenários:
Estrutura do Documento A estrutura do documento está organizada como segue.
Em o segundo Capítulo apresenta- se uma visão do estado da arte nos temas em os quais a presente Dissertação contribui:
Monitoramento de tarefas, escalonamento, controle distribuído e migração de tarefas em MPSoC.
O Capítulo 3 apresenta de forma sucinta a arquitetura de referência adotada ­ MPSoC HeMPS.
O Capítulo 4 detalha a técnica de monitoramento implementada.
Os Capítulos 5 e 6 apresentam as técnicas de escalonamento por prioridade e a migração de tarefas, respectivamente.
O Capítulo 7 apresenta os resultados obtidos e a respectiva discussão dos mesmos.
O Capítulo 8 encerra esta Dissertação, com as conclusões e direções para trabalhos futuros.
Em este Capítulo apresenta- se o estado da arte nos temas relacionados ao presente trabalho.
Analisaremos as pesquisas realizadas para o monitoramento de tarefas, escalonamentos eficientes em MPSoC, controle distribuído e migração de tarefas.
A estrutura do Capítulo está dividida conforme os assuntos relacionados ao trabalho.
Em a primeira Seção apresenta- se o estado da arte para o monitoramento de tarefas.
Em a segunda Seção tem- se as pesquisas relacionadas a escalonamentos em MPSoC.
Em a terceira Seção apresenta- se o estado da arte para controle distribuído.
Em a quarta Seção apresentam- se os trabalhos relacionados à migração de tarefas.
Por fim, a última Seção deste Capítulo, tem- se as considerações finais e uma tabela comparativa entre os trabalhos analisados.
Monitoramento de Tarefas Em esta seção apresentam- se pesquisas referentes ao monitoramento de tarefas em MPSoCs.
O objetivo de uma técnica de monitoramento de tarefas é para efetuar o controle das aplicações.
Definem que a adaptabilidade dos MPSoCs necessitam desse tipo de mecanismos.
Stan Apresentam um método para controle de deadlines melhorando a qualidade de serviço em aplicações multimídia.
O método consiste na detecção de violações de tempo num MPSoC.
Os PEs do MPSoC contém uma estrutura de monitoramento que verifica a infraestrutura de comunicação.
Todos os dados transferidos são armazenados e seus tempos são comparados a um comportamento de referência esperado.
A estrutura de monitoramento é implementada num dispositivo que é mapeado no espaço de endereçamento do processador, como podemos ver na Figura 2.
A estrutura de monitoramento implementa um mecanismo watchdog que conta a quantidade de eventos que são executados antes do tempo limite, ou entre dois limites de tempo ou depois de um tempo limite.
Os limites de intervalo de tempos utilizados para verificar um determinado evento são armazenados em parâmetros programáveis, que são configurados nas aplicações;
Esses valores são computados em tempo de projeto.
O tempo limite pode ser alterado por as variações de frequências (causadas por a variação de temperatura no ambiente operacional) ou por algumas falhas de hardware.
Em esta pesquisa, os autores não apresentam os resultados obtidos, apenas explicam o funcionamento de seu mecanismo de monitoramento de tarefas em MPSoC.
Ciordas Apresentam diversas alternativas para monitoramento de NoCs e avaliam qual é o impacto dessas técnicas no projeto de NoCs.
Essas alternativas variam do uso de interconexões físicas, separadas para dados de aplicações e dados de monitoramento.
Para cada alternativa os autores avaliaram o custo da área das interconexões, o impacto de modificações no fluxo do projeto e a reusabilidade dos recursos de debug para tráfego de dados das aplicações.
O monitoramento da NoC é explorado em três alternativas:
Interconexões físicas separadas;
Interconexões físicas comuns com recursos físicos separados;
Interconexões físicas comuns com recursos físicos compartilhados.
Para a avaliação das alternativas de monitoramento, os autores apresentam duas características:
Probes, componentes de hardware que monitoram o tráfego dos dados na rede;
Serviço de monitoramento de acesso (MSA ­ Monitoring Service Access Point), efetua a reconfiguração em tempo de execução baseado nos dados enviados por os probes.
NoC Virtual para monitoramento é criada.
As alternativas apresentadas na Figura 3 (b) e na Figura 3 (c) requerem um maior número de recursos de hardware e de conexões que a alternativa apresentada na Figura 3 (d), porém separam os dados de monitoramento dos dados das aplicações.
A escolha do projetista deve ser baseada no compromisso entre custo de área e desempenho do monitoramento.
Matos Apresentam um mecanismo para controle de redimensionamento dinâmico de buffer para cada canal de entrada do roteador, que é feito através de um monitoramento de tráfego na rede, em tempo de execução.
Além disso, a configuração dinâmica da profundidade do buffer é feita sem qualquer pausa ou interrupção do sistema.
O bloco de controle de profundidade do buffer foi implementado para cada canal de entrada do roteador, sendo a arquitetura com o bloco de controle apresentada na Figura armazenar os flits.
A FIFO é controlada por o bloco Input Channel Controller que realiza o controle de fluxo, e o roteamento dos flits do canal de entrada.
O Buffer Depth Controller é o bloco com o controle proposto por o trabalho.
O bloco de controle de profundidade do buffer é composto por quatro outros blocos:
Monitor, observa o tráfego de dados no canal;
Integrador, calcula a nova profundidade do buffer de acordo com o tráfego de dados monitorado e a aplicação;
Alocação de slots de buffer, implementa um protocolo para distribuir os slots do buffer para cada canal de acordo com a profundidade calculada por o integrador;
Decisão de redimensionamento, verifica quando cada canal irá permitir a troca da profundidade do buffer.
Esse bloco de controle de profundidade do buffer é apresentado na Figura 5.
Com a arquitetura proposta, os autores conseguiram diminuir a latência em 80% e dobrar a vazão, com a alteração dinâmica da profundidade do buffer.
Escalonamento Em esta seção apresentam- se pesquisas referentes a algoritmos de escalonamento de tarefas em MPSoCs.
Coskun Apresentam um algoritmo de escalonamento de tarefas com o objetivo de atingir uma distribuição térmica uniforme em MPSoCs.
Os autores projetaram e avaliaram políticas de escalonamento no nível de sistema operacional.
Também, apresentam duas técnicas que podem ser aplicadas para o controle da temperatura em MPSoCs.
A primeira técnica é a migração dinâmica de threads.
É um método de gerenciamento térmico em MPSoC que migra threads de um processador quente para um processador frio.
Em a implementação dessa técnica a limiar de temperatura para efetuar a migração foi configurada para 85° C, que é considerada uma temperatura crítica em muitos sistemas.
A segunda técnica é a de gerenciamento térmico para dimensionamento dinâmico de voltagem e frequência quando atingida a temperatura limiar.
Essa técnica diminui a temperatura do processador reduzindo o consumo de energia.
Todas as aplicações são executadas com frequência máxima, a menos que a temperatura crítica seja atingida.
Se um processador atinge esta temperatura, o nível de voltagem do processador é reduzido para diminuir a frequência até que a aplicação atual termine.
Além de essas duas técnicas, os autores apresentam duas políticas de escalonamento usando como função custo a temperatura.
O primeiro algoritmo envia tarefas para processadores mais frios.
O segundo algoritmo efetua o envio de tarefas analisando o histórico de temperaturas do processador e pode ser implementada em sistemas reais.
Essa pesquisa demonstrou que técnicas que fazem uso de medições de temperatura para atingir um valor térmico ideal e para otimizar a temperatura não afetam o desempenho do sistema.
Os autores avaliaram o desempenho do sistema utilizando as técnicas apresentadas, demonstrando que o desempenho do sistema não foi comprometido com o uso dessas técnicas.
Tafesse Apresentam dois algoritmos de escalonamento, um para MPSoCs baseados em barramento e outro para MPSoCs baseados em NoC:
Algoritmo de escalonamento objetivando maximizar o desempenho (para MPSoCs baseados em barramento); (
ii) algoritmo de escalonamento baseado no volume de tráfego (para MPSoCs baseados em NoC).
O primeiro algoritmo apresentado é o escalonador para barramentos.
Esse algoritmo utiliza um índice de desempenho, que quantifica o desempenho do sistema considerando o valor médio do tempo de execução por tarefa, utilização do processador, vazão, uso do buffer, e a energia, determinando o custo da tarefa por processador.
O escalonador irá decidir por escalonar a tarefa no processador que tiver a melhor função custo de desempenho.
O segundo algoritmo apresentado por os autores é o escalonamento que utiliza o volume de tráfego como função custo.
A principal contribuição dessa técnica é que o mapeamento da aplicação e o processo de escalonamento são controlados juntos.
Esse algoritmo calcula a latência da comunicação para escalonar e mapear as tarefas.
Os resultados obtidos na avaliação dos dois algoritmos de escalonamento mostraram que projetar técnicas de escalonamento, buscando resolver problemas como otimização de temperatura, balanceamento de cargas e gerenciamento térmico, resulta em melhores desempenhos para o sistema do que utilizando algoritmos de escalonamento clássicos.
Zhaoguo Apresentam um algoritmo de escalonamento para diminuir a temperatura e economizar energia em MPSoCs.
O algoritmo atribui alta prioridade para os processadores com baixa temperatura.
O sistema opera em dois modos:
Modo ativo e modo ocioso.
Durante o modo ativo as tarefas podem ser escalonadas e executadas.
Durante o modo ocioso as tarefas são preemptadas e o sistema passa a economizar energia.
Inicialmente, os processadores operam em modo ocioso.
Então, a decisão do escalonamento é baseada na temperatura de todos os processadores do MPSoC, e é escolhido o processador com menor temperatura.
Para apresentar os benefícios do algoritmo proposto, os autores efetuaram uma comparação da eficiência do controle de temperatura da técnica proposta com a técnica de alteração dinâmica de voltagem (DVS).
Com isso, concluem que o algoritmo proposto atinge o valor de temperatura ideal (34° C) em todos processadores do MPSoC, mantendo- os frios.
Já o DVS, que diminui a voltagem e a frequência do chip, irá perder energia durante o longo período de execução, o que faz a temperatura subir rapidamente.
O trabalho apresentado por os autores mostra a importância de efetuar um controle da temperatura do chip considerando as perdas de energia.
Com a proposta, os autores conseguiram efetuar uma economia de 70% de energia no sistema.
Controle Distribuído Em esta Seção apresentam- se pesquisas referentes ao gerenciamento distribuído de tarefas em MPSoCs.
Essas técnicas têm por objetivo efetuar o monitoramento de tarefas de forma distribuída, como apresentado em.
Segundo, o gerenciamento distribuído pode garantir ganhos de desempenho, tolerância a falhas e escalabilidade.
E outros comentam que o gerenciamento distribuído é mais escalável e eficiente.
Fattah Apresentam uma pesquisa de monitoramento de sistemas adaptativos, para facilitar o gerenciamento do MPSoC em diferentes aspectos, tais como:
como se pode ver na Figura 6, em destaque, o roteador e seus componentes locais compõem um célula.
De acordo com a demanda do sistema, uma célula pode conter diferentes capacidades de monitoramento, tais como:
Sensores de temperatura, monitores de consumo de energia e detectores de falhas.
Cada célula tem seu próprio gerenciador, que em função de os seus mecanismos de monitoramento, relata as condições da célula para um gerenciador de alto nível (não detalhado no artigo), recebendo comandos do mesmo.
Um conjunto de células forma um grupo (cluster) e são gerenciadas por um gerenciador do grupo (nível intermediário de gerenciamento).
Diferentes políticas de agrupamento podem ser aplicadas:
Uma aplicação pode conter múltiplos grupos, onde cada um executa um conjunto de tarefas ou cada grupo pode executar tarefas de várias aplicações.
Assim, este trabalho propõe um gerenciamento hierárquico de três níveis, conforme apresentado na Figura 7: Em o nível de célula (local); (
ii) no nível de grupo (intermediário);
Alto nível (global).
O gerenciador de alto nível é responsável por o controle global e por a coordenação dos gerenciadores de grupo.
O gerenciador no nível de célula é executado no sistema operacional e é carregado na criação de uma nova tarefa, quando invocada.
Os autores comentam que o gerenciamento hierárquico pode ser visto como uma solução de` dividir e conquistar' para futuros sistemas multicores.
Shabbir Apresentam um comparativo entre duas versões de gerenciamento de recursos distribuídos:
Credit Based e Rate Based.
Os gerenciadores foram desenvolvidos para controlar um grande número de processadores executando aplicações concorrentes.
A primeira versão do gerenciador de recursos proposto por os autores é o Credit Based, que permite o uso de aplicações que tenham restrições rígidas de desempenhos;
A arquitetura modelada para a proposta consiste em processadores conectados numa NoC e os gerentes de recursos consistem num controlador de admissão.
Os controladores de admissão são responsáveis por a avaliação de restrições de tempo de novas aplicações utilizando os recursos disponíveis.
Caso os recursos disponíveis do MPSoC não atendam os requisitos da nova aplicação, então, o controlador de admissão rejeita o pedido e a aplicação pode solicitar serviços com um menor nível de qualidade.
Em a Figura 8 os autores apresentam diagramas de gerenciamento de recursos centralizados e sua proposta de gerenciamento distribuído.
O modelo de gerenciamento centralizado monitora a vazão de cada aplicação e compara com sua vazão desejada.
O gerente centralizado (RM) tem que monitorar e controlar todas as aplicações e seus desempenhos, ocasionando problemas de escalabilidade devido a o tempo de monitoramento.
Para resolver esse problema, os autores apresentam duas versões de gerenciamento distribuído.
O gerenciamento distribuído procura minimizar o envolvimento do gerenciador central no processo e investe mais inteligência no processador local.
Em as duas versões de gerenciamento de recursos distribuído há um controlador de admissão central conectados aos núcleos de processamento numa NoC.
O controlador de admissão central é uma interface que calcula os créditos, sendo estes créditos distribuídos entre os processadores do sistema.
Os árbitros dos processadores locais aplicam os créditos para que as restrições de vazão das aplicações sejam satisfeitas.
Em o gerenciador de recursos por Credit Based o controlador de admissões envia os créditos dos processadores conforme o mapeamento das tarefas nos processadores.
Para fazer cumprir esses créditos, cada processador tem um kernel que armazena esses créditos num contador.
Depois que os créditos acabam os contadores são recarregados com seus valores recebidos por o controlador central e o processo continua.
Em o gerenciador de recursos por Rate Based cada processador tem seu arbitro local.
O controlador de admissão do rate based calcula os créditos da mesma forma que o credit based.
O controlador de admissão envia os créditos para cada arbitro local de cada processador.
Os árbitros locais recebem os créditos e executam as tarefas de modo que se existir recursos disponíveis no sistema a tarefa é executada numa taxa maior do que a desejada, terminando mais rapidamente.
Os experimentos mostram que gerenciadores de recursos distribuídos são mais escaláveis, são mais eficientes com aplicações dinâmicas e requerem menos armazenamento.
O gerenciamento Credit Based é mais eficaz para fazer cumprir as restrições de vazão, já o Rate Based é mais eficaz para aplicações que podem fazer uso de todos os recursos disponíveis do sistema.
Kobbe Apresentam um esquema de gerenciamento de recursos distribuído em MPSoC, chamado DistRM.
Essa proposta foi projetada para ser um sistema sem qualquer sincronização global ou comunicação global.
Para alcançar escalabilidade, os autores desenvolveram os princípios de sistemas multi-agentes para efetuar o gerenciamento de recursos.
Cada aplicação do sistema tem um agente dedicado para gerenciar os recursos.
A computação necessária de cada agente é desempenhada nos mesmos PEs das aplicações, mas a computação de todo o gerenciamento global de recursos é distribuída em todos os PEs do MPSoC.
Cada agente visa aumentar a aceleração de suas aplicações procurando por outros PEs no sistema que possam ser usados.
Portanto, ele usa a capacidade de aplicações maleáveis (o número de PEs atribuídos a um agente pode ser alterado durante a sua execução) para poder adaptar PEs adicionais.
Quando existir mais de uma aplicação executando no sistema, os PEs disponíveis devem ser compartilhados de entre as diferentes aplicações.
Os recursos não são mais gerenciados numa região central, mas em muitas regiões espalhadas em todo o chip.
Adicionalmente, as comunicações necessárias para gerenciar os recursos ocorrem principalmente em áreas locais.
Essas áreas são distribuídas no chip ao invés de estarem concentradas num único ponto.
Todas essas vantagens ajudam a criar um sistema multi-agentes escalável e menos intrusivo para aplicações executando no sistema.
Comparando com o gerenciamento centralizado, a solução proposta por os autores apresenta um maior número de mensagens trafegando por a NoC, mas os autores avaliam que essas mensagens são pacotes pequenos e na maioria das vezes requer poucos hops na NoC e são distribuídos em todo o MPSoC.
Migração de Tarefas Em esta Seção apresentam- se pesquisas referentes à migração de tarefas em MPSoCs.
Essa técnica surgiu com foco em desempenho e tolerância a falhas em sistemas distribuídos.
Barcelos comenta que a área de sistemas embarcados está próxima a de sistemas distribuídos.
Segundo, especificamente em MPSoCs, diversas condições podem requerer migração de tarefas:
Acquaviva Propõem uma nova técnica para reduzir a temperatura de um MPSoC, baseada em migração de tarefas entre processadores.
O algoritmo proposto explora as informações de temperatura em tempo de execução para balancear a temperatura do MPSoC.
MPSoCs são caracterizados por possuírem uma grande área de silício, e experimentos demonstram uma distribuição desigual de densidade de calor.
A técnica proposta é chamada MiGra e é composta por três algoritmos.
O primeiro algoritmo é denominado Total Swap.
Esse algoritmo consiste na seleção de um conjunto de processadores entre o processador fonte (onde está a tarefa a ser migrada) e processadores candidatos a receber a tarefa.
O algoritmo utiliza três condições para realizar a migração:
Este algoritmo assume que todas as tarefas presentes no processador fonte são migradas.
Devido a este fato, foi desenvolvido um novo algoritmo que desempenha uma busca de tarefas mais eficiente para migrar entre dois processadores, buscando diminuir o número de migrações e a quantidade de dados trafegando na NoC.
O segundo algoritmo do MiGra, denominado Full Search, não está sujeito às limitações da pesquisa exaustiva do Total Swap, pois permite que seja migrada apenas uma tarefa de cada vez.
O problema é o número de comparações necessárias para calcular o custo da migração de todos os possíveis conjuntos de tarefas a migrar de um processador fonte para todos os possíveis conjuntos de tarefas para um processador destino.
Buscando evitar este problema, da necessidade de um grande número de comparações, foi desenvolvido o algoritmo Bounded Search que diminui as limitações do Full Search e mantém o custo computacional do Total Swap.
Assim, o algoritmo foi modificado considerando que o efeito da migração da tarefa no balanceamento da temperatura diminui junto com a carga.
Isto leva para o fato de que se pode limitar o número de tarefas para serem migradas, considerando apenas as tarefas com maior carga.
Esses três algoritmos exploram a uniformização de temperatura de um MPSoC em tempo de execução para determinar o conjunto de tarefas que será migrado de um processador com temperatura elevada para um processador com baixa temperatura.
Porém, o problema deste trabalho é que os autores comentam os algoritmos utilizados, mas não detalham a forma de como a migração é efetuada.
Apenas são explicados os motivos para fazer a migração, faltando informar como a mesma é realizada.
Pittau Apresentam uma camada middleware que implementa a migração de tarefas num MPSoC.
Os autores comentam que o mapeamento dinâmico de tarefas baseado em migração tem sido muito explorado para melhorar o desempenho e diminuir o consumo de energia em MPSoCs.
Para aplicações multimídia, migração de tarefas deve ser cuidadosamente avaliada para que não ocorram perdas de deadline.
Foi caracterizado o desempenho de uma dada aplicação multimídia e o seu gasto de energia.
Os experimentos mostram que a migração em nível de middleware ou sistema operacional é possível e pode levar a melhorias na economia de energia.
Os autores propõem dois tipos de mecanismos para migração de tarefas, os quais diferem na forma de gerenciar a memória.
A primeira versão é a Task Recreation.
Este mecanismo destrói o processo no processador fonte e recria no processador destino.
Esta versão é baseada na execução de chamadas de sistema que cuidam da alocação de espaço de memória necessário para as tarefas.
A outra estratégia para migração é a Task Replication, onde existe uma réplica de cada tarefa em cada sistema operacional local.
Somente um processador por vez pode executar uma réplica da tarefa.
Enquanto a tarefa é executada num processador, a réplica de ela está numa fila de tarefas em outro processador.
Em esta pesquisa os autores consideram cada tarefa um processo com seu espaço de endereçamento privado.
Assim facilita- se o mapeamento de aplicações numa plataforma com memória distribuída.
O framework suporta migração de tarefas de modo que a política de gerenciamento de tarefas possa cuidar do mapeamento em tempo de execução, melhorando o desempenho, gerenciamento térmico e segurança.
Layouni Avaliam a técnica de migração de tarefas de software por replicação, em MPSoC.
A migração de tarefas de software é realizada em tempo de execução e gerenciada por o sistema operacional.
A necessidade de migração pode ser para fins de:
Balanceamento de cargas, tolerância a falhas, economia de energia e gerenciamento térmico do chip.
Os autores comentam que a migração de tarefas envolve a habilidade de interromper a execução de uma tarefa num processador e dar sequência à mesma em outro.
Os autores adotam uma estratégia de replicação de tarefas, tanto para MPSoCs heterogêneos e homogêneos, juntamente com o uso de notificação de checkpoints (pontos de migração da tarefa).
O usuário é responsável por configurar esses checkpoints no código da aplicação, o desempenho da aplicação depende desses checkpoints.
Isso é feito via sistema operacional e é facilmente extensível, segundo os autores.
A estratégia de migração consiste em replicação dos códigos das tarefas em cada processador onde a migração será habilitada.
Em a Figura 9 os autores apresentam a funcionalidade da migração de tarefas, com a tarefa migrada e a réplica da mesma.
A CPU_ 1 e a CPU_ 2 contém as réplicas das tarefas, contendo dois possíveis estados:
A migração da tarefa só poderá ser executada quando a tarefa encontrar seu checkpoint.
Quando se decide efetuar a migração de tarefas, primeiramente se salva o contexto desta tarefa numa memória compartilhada.
Após, a tarefa &quot;migrada «é retirada do sistema ou suspensa.
A réplica pode ser reiniciada ou criada em outro processador, o contexto salvo na memória compartilhada é restaurado.
Por fim a tarefa pode ser Os autores definem que o processo de migração de tarefas envolve a habilidade de parar uma tarefa num processador e dar continuidade a ela em outro processador, melhorando o desempenho do sistema.
O objetivo da pesquisa de Ozturk É apresentar um método de migração.
O algoritmo decide se será migrado o código ou os dados, buscando satisfazer os requisitos de comunicação.
A escolha entre as duas opções de migração é realizada em tempo de execução baseado em estatísticas coletadas na etapa de profiling.
A migração é dividida em três etapas, como é apresentada na Figura 10: Profiling:
Etapa para fazer o experimento de cada aplicação, sendo calculado o custo da energia de comunicação na rede e, também, calculado o custo da transferência dos dados das tarefas;
Anotação de código:
Etapa para especificar a migração de código ou de dados.
Para a decisão da migração de código ou dados os autores calculam o custo da energia de comunicação entre as tarefas da aplicação.
Essas duas primeiras etapas são desempenhadas em tempo de compilação.
A terceira etapa é a execução do algoritmo de migração do código ou dos dados.
Em este trabalho os autores focam apenas na descrição dos cálculos da decisão de migrar o código ou os dados das tarefas, não descrevendo como realmente é efetuada a migração.
Outro importante detalhe não descrito por os autores é apresentar de que forma segue a execução da aplicação e a comunicação entre as tarefas, levando em conta a migração de apenas o código ou os dados.
Os autores descrevem que em suas experiências, com várias aplicações em MPSoCs, a migração de tarefas pode melhorar o desempenho e o poder computacional destes.
Considerações Finais A Tabela 1 apresenta um comparativo entre os trabalhos analisados neste Capítulo.
Como podemos notar, foram analisados trabalhos com objetivos diferentes, mostrando que as pesquisas estão cada vez mais dedicadas para MPSoCs adaptativos.
Visando a adaptabilidade dos MPSoCs, as pesquisas analisadas no estado da arte apresentam técnicas de monitoramento de tarefas, escalonamento, controle distribuído e migração de tarefas para gerenciar a uniformização de temperatura, minimização de energia, balanceamento de carga, melhorias no desempenho, etc..
As pesquisas analisadas no estado da arte de monitoramento de tarefas apresentam diferentes objetivos de monitoramento.
Em temos a proposta de um método para controle de deadlines capaz de melhorar a qualidade de serviços para aplicações multimídia.
Em os autores apresentam alternativas de monitoramento utilizando interconexões físicas separadas para dados de aplicações e dados de monitoramento, avaliando o impacto dessas técnicas nos projetos de NoCs.
Em é proposto um mecanismo baseado em monitoramento de tarefas para efetuar um controle de redimensionamento dinâmico de buffer, em tempo de execução.
Em o estado da arte de escalonamento de tarefas, foram apresentadas pesquisas que apresentam objetivos de gerenciamento térmico e economia de energia.
Mostram que as pesquisas para escalonamento em MPSoCs focam na minimização da energia consumida.
As pesquisas referentes a controles distribuídos de MPSoCs tem por objetivo tornar os sistemas escaláveis, capazes de ter vários monitores gerenciando os recursos do sistema.
Em temos uma proposta de controle distribuído capaz de efetuar o monitoramento do sistema em três níveis:
Local, cluster e global.
Em os autores apresentam duas técnicas para efetuar melhorias no desempenho do sistema, com aplicações controladas por um gerente de recursos.
Em os autores apresentam uma proposta de controle distribuído, em MPSoC, baseado num algoritmo multi-agente, que gerência os recursos do sistema.
Para a migração de tarefas, temos no estado da arte como principal objetivo o balanceamento de carga.
Em alguns casos, o ponto de migração é predefinido na codificação da tarefa.
Apenas efetua a migração de tarefas conforme real necessidade, considerando o processador com alta temperatura ou até mesmo com alta frequência, sem a necessidade de forçar a migração (com pontos de migração configurados por o usuário em tempo de projeto), como feito em e.
Em esta questão, mostra- se que nenhuma das pesquisas analisadas apresenta um controle distribuído para o gerenciamento de tarefas a ponto de controlar a necessidade de efetuar a migração de uma determinada tarefa baseado em dados coletados por um monitoramento do sistema.
Outro ponto importante a se destacar, é que na pesquisa realizada por Ozturk É utilizado um processo dividido por etapas (profiling, configuração e execução), assim como o presente trabalho.
A originalidade da pesquisa desenvolvida na presente Dissertação é a integração e avaliação de diversas técnicas, as quais são avaliadas individualmente na literatura.
As técnicas que serão detalhadas posteriormente envolvem o controle distribuído de recursos do MPSoC, monitoramento de vazão e latência, e as técnicas de escalonamento e migração de tarefas para prover adaptabilidade às aplicações.
Em este Capítulo é apresentado o MPSoC homogêneo HeMPS (Hermes Multiprocessor System), utilizado como plataforma de referência para integração das técnicas de adaptabilidade deste trabalho.
Essa plataforma é utilizada em duas versões:
Arquitetura com controle de recursos centralizado, contendo um processador responsável por a gerência de todo o sistema, apresentada na Seção 3.1;
arquitetura com controle de recursos distribuído, contendo um MPSoC dividido em regiões, cada qual com um processador responsável por a gerência da região, apresentada na Seção 3.2.
O MPSoC HeMPS assume que todas as aplicações são modeladas através de um grafo de tarefas, onde os vértices representam tarefas e as arestas representam a comunicações entre as tarefas da aplicação.
As tarefas sem dependências de recepção de dados são denominadas iniciais.
Em o momento de inicialização de uma dada aplicação, a heurística de mapeamento carrega no MPSoC somente as tarefas iniciais.
As demais tarefas são inseridas dinamicamente no sistema em função de as requisições de comunicação e dos recursos disponíveis.
A Figura 11 mostra um exemplo de uma aplicação modelada de acordo com esta abordagem.
Arquitetura com Controle Centralizado de Recursos A arquitetura HeMPS é um MPSoC homogêneo que emprega elementos de processamentos, denominados Plasma-IP, interconectados por a NoC Hermes que é utilizada como infraestrutura de comunicação.
Também, tem- se uma memória externa, denominada repositório de tarefas, aa qual contém o código-objeto de todas as tarefas que executarão no sistema.
Em a Figura 12 é ilustrada uma instância do MPSoC HeMPS configurado como uma NoC de dimensão 2x3 interconectando os Plasmas-IP.
Os elementos de processamento do MPSoC HeMPS são divididos em:
Mestre, Plasma-IP MP, o qual gerência os recursos do sistema;
Escravos, Plasma-IP SL, efetuam a execução das tarefas.
Cada Plasma-IP é composto por:
Interface de rede (Ni, do inglês, Network Interface):
É a interface de ligação entre o elemento de processamento e a NoC.
Sendo o módulo responsável por o envio e recebimento de pacotes na rede.
Processador Plasma:
Processador RISC de 32 bits com organização de memória Von Neumann.
Oferece suporte a linguagem de programação C com tratamento de interrupções.
Memória privada:
Onde está armazenado o microkernel (sistema operacional simples) que executa em cada processador Plasma.
Em o Plasma-IP SL a memória é dividida em páginas com tamanho fixo para alocação das tarefas (cada tarefa utiliza uma página da memória).
Módulo de acesso direto à memória (DMA, do inglês, Direct Memory Access):
Módulo que auxilia o Plasma no envio e recebimento de mensagens com a Ni.
Assim, o DMA permite que o Plasma continue sua execução de tarefas sem a necessidade de controlar diretamente a troca de mensagens com a rede.
A principal função deste módulo é transferir o código-objeto das tarefas (que chegam por a Ni) para a memória do Plasma.
A gerência de recursos do sistema é centralizada devido a o fato de conter apenas um processador mestre para gerenciar todo o sistema.
O processador mestre é responsável por gerenciar os recursos do sistema, sendo o único processador que tem acesso ao repositório de tarefas.
Em o momento em que a HeMPS inicia sua execução, o processador mestre aloca as tarefas iniciais nos processadores escravos.
Durante a execução, cada processador escravo pode solicitar ao mestre a alocação dinâmica de tarefas do repositório.
Além disso, recursos podem ficar disponíveis quando determinada tarefa terminar a sua execução.
Cada processador escravo executa um microkernel, que suporta execução multitarefa e comunicação entre tarefas.
O protocolo adotado para a comunicação entre tarefas é o read request.
Segundo Carara, este protocolo garante o controle de fluxo fim-a-fim e o ordenamento de armazenada no pipe local (área de memória do sistema operacional), e a computação continua, caracterizando uma escrita não-bloqueante.
A o executar a primitiva origem, e havendo dados no pipe, estes são enviados através da NoC.
A leitura é desta forma bloqueante.
Este protocolo tem a vantagem de reduzir o tráfego na rede, pois uma mensagem só é injetada na rede se a mesma tiver sido solicitada.
Arquitetura com Controle Distribuído de Recursos De a mesma forma que a arquitetura com gerência de recursos centralizada, a arquitetura distribuída da HeMPS emprega processadores Plasma-IP interconectados por a NoC Hermes.
Em a Figura 13 é ilustrada uma instância do MPSoC HeMPS distribuído configurado como uma NoC de dimensão 6x6 divido em 4 clusters 3x3.
Em a arquitetura centralizada temos um processador mestre que gerência todo o sistema.
A característica da arquitetura distribuída é aumentar a quantidade de mestres dividindo a gerência por regiões.
Com isso, um processador não fica responsável por gerenciar todo o sistema, mas sim a sua região (que é formada por n processadores, formando um cluster).
Assim, a arquitetura distribuída contém três níveis de processamento:
Mestre global;
Mestres locais;
Processadores escravos.
O SP (processador escravo) é responsável por a execução das tarefas.
Todos os SPs executam um sistema operacional simples que permite comunicação entre PEs e execução multitarefa, com suporte a função de monitoramento de tarefas.
O LMP (processador mestre local) é responsável por a gerência do cluster, executando funções de adaptabilidade, mapeamento de tarefas e efetua a comunicação com os outros LMPs e o GMP.
O LMP é responsável por a gerência das aplicações.
Em alguns casos, o cluster não tem espaço para mapear todas as tarefas de uma aplicação, então, o LMP pode mapear tarefas fora de seu cluster.
O GMP (processador mestre global) efetua ações de gerência global, como acesso ao repositório de tarefas, seleção de cluster que irá receber determinada aplicação, envio de tarefas aos clusters, além de o controle do próprio cluster.
A vantagem da gerência distribuída sobre a centralizada reside no fato que as tarefas que requerem mais computação, como mapeamento e migração de tarefas, são delegadas a vários PEs (LMPs).
Também, o monitoramento é efetuado em nível de cluster, diminuindo o tráfego na rede.
Este Capítulo apresenta a primeira contribuição da Dissertação:
A implementação do mecanismo de monitoramento de tarefas.
O monitoramento de tarefas foi projetado buscando minimizar problemas que afetam diretamente o desempenho das aplicações sendo executadas em MPSoCs, tais como:
Perda de deadlines das aplicações;
Vazão ou latência não respeitadas;
Tarefas sendo executadas distantes de suas comunicantes, aumentando o consumo de energia na NoC.
A solução para esses problemas é essencial para que um MPSoC tenha características de um sistema adaptativo, provendo ganhos de desempenho e economia de energia.
O mecanismo de monitoramento é a primeira técnica do processo de adaptabilidade.
Este é um processo cíclico, executando de forma contínua ao longo de a execução das aplicações no sistema.
A adaptabilidade faz uso das três técnicas descritas nesta Dissertação.
A Figura 14 ilustra as três etapas do processo.
A primeira etapa é efetuar a gerência de determinada aplicação, coletando dados relativos aos parâmetros de desempenho monitorados (como deadlines, vazão, latência).
Após efetuar o monitoramento, temos a técnica de gerência (como apresentada no Capítulo 3, podendo ser centralizada ou distribuída), que é responsável por a tomada de decisões, baseado nos dados coletados por o monitor.
Com isso, a última etapa do processo de adaptabilidade é a execução de uma das técnicas adaptativas, que podem ser:
Alteração das características de escalonamento, detalhada no Capítulo 5;
efetuar a migração de determinada tarefa da aplicação monitorada, detalhada no Capítulo 6.
A técnica de monitoramento foi desenvolvida para as plataformas com gerência de recursos centralizada e distribuída, sendo o mesmo protocolo para ambas as plataformas.
Em a Seção 4.1, apresenta- se a estrutura do monitoramento de tarefas, descrevendo a configuração necessária para sua execução.
Em a Seção 4.2, apresenta- se o protocolo de monitoramento, descrevendo o funcionamento desta técnica e de que forma pode afetar o desempenho das aplicações do sistema.
Estrutura do Monitoramento de Tarefas O monitoramento é configurado baseado nos dados coletados na etapa de profiling (avaliação das características da aplicação).
Em a etapa de profiling deve- se verificar qual o deadline1 aceitável da aplicação.
Para isso, a aplicação a ser monitorada é executada sozinha no MPSoC e é analisada a latência média de comunicação entre as tarefas.
Com base nessas latências, é definido o deadline aceitável da aplicação.
Para configurar o deadline de uma aplicação, foi adicionada uma nova função na foi criada uma chamada de sistema, denominada SETDEADLINE, que atribui o valor de deadline no campo deadline da TCB2 da tarefa.
O campo deadline foi adicionado na TCB, pois originalmente este não existia.
Durante a análise de dados na etapa de profiling, também, deve- se informar a quantidade aceitável de perdas de deadlines da aplicação.
Para armazenar essa quantidade adicionou- se na TCB o campo max_ miss, que representa quantas violações a aplicação pode sofrer antes do PE monitor solicitar ao PE mestre a alteração nas características do escalonador de tarefas (descritas no entre duas tarefas excede o valor configurado no campo deadline, na etapa de profiling.
Também, adicionou- se na TCB o campo max_ miss_ migra que representa o valor aceitável de perdas de deadline antes de solicitar de migração.
Logo, na etapa de profiling devem ser configurados três parâmetros:
Deadline, max_ miss, e max_ miss_ migra.
Em o Figura 15, ilustra- se o processo para configuração do monitoramento da aplicação.
Inicialmente tem- se determinada aplicação descrita por algumas tarefas.
Cada tarefa, TaskC.
C por exemplo, faz uso da API de comunicação, implementada no os valores de configuração da tarefa.
Esta função realiza uma chamada de sistema implementada no microkernel do processador escravo (kernel_ slave.
Em esta chamada de sistema, atribui- se os valores parametrizáveis, na função, aos respectivos campos da TCB, que estão declarados no kernel_ slave.
H. O PE que estiver executando a tarefa com configuração de deadline é o responsável por o monitoramento da aplicação.
Com o deadline configurado, o monitor inicia sua execução analisando a latência de comunicação da tarefa.
Quando a quantidade de perdas de deadlines atingir o valor configurado nma_ miss, este PE solicita a alteração das características de escalonamento ao PE mestre, e quando a quantidade de perdas de Em esta Seção apresenta- se o protocolo de monitoramento de tarefas.
Define- se como &quot;PE monitor «um PE que está monitorando uma ou mais tarefas em ele executando.
O PE monitor verifica violações de deadline e a necessidade de aplicar alguma técnica de adaptabilidade, repassando a informação ao PE mestre, responsável por a gerência de recursos.
Como apresentado na Seção 3.1, a arquitetura com gerência centralizada de recursos contém apenas um processador mestre.
Em este caso, a tomada de decisões será totalmente gerenciada por tal processador.
Já na arquitetura com gerência distribuída de recursos, Seção 3.2, existe um processador mestre por região.
Assim, o PE mestre responsável por a tomada de decisões será o mestre responsável por a aplicação monitorada.
Em a Figura 16 apresenta- se um cenário de monitoramento num MPSoC com gerência centralizada de recursos.
O cenário contêm uma aplicação formada por seis tarefas (A-F), executando no MPSoC, juntamente com uma aplicação que gera tráfego de dados que compete por recursos na rede (aplicação denominada distrubing).
A aplicação disturbing gera atrasos na comunicação, podendo gerar a ocorrência de perdas de deadlines na aplicação principal.
A tarefa F é a tarefa monitorada, pois é a tarefa que gera os dados da aplicação (última tarefa do grafo).
O processador que está executando essa tarefa é o processador responsável por o monitoramento da aplicação.
A Figura 16 (a), apresenta o mapeamento inicial das tarefas, com o monitoramento analisando o cumprimento dos deadlines da tarefa F. na Figura 16 (b), o PE monitor verifica que a quantidade de violações de deadlines atingiu a quantidade configurada no campo max_ miss da TCB da tarefa F. Com isso, o PE monitor envia um pacote ao PE mestre solicitando que sejam alteradas as características de escalonamento de todas as tarefas da aplicação.
Essas características serão detalhadas na Seção 5.3.
Em a Figura 16 (c), o PE mestre recebe a solicitação do PE monitor, para executar a técnica de adaptabilidade.
Após isso, o PE mestre envia pacotes para todos os processadores, que executam as tarefas da aplicação monitorada, solicitando aumento da prioridade e time-slice das mesmas.
A o receber o pacote de solicitação, do PE mestre, os PEs escravos alteram as características do escalonamento das tarefas da aplicação monitorada.
Em a Figura 17 apresenta- se um cenário de monitoramento num MPSoC com gerência distribuída de recursos.
De a mesma forma que o cenário apresentado na Figura 16, este cenário contêm uma aplicação formada por seis tarefas (A-F), executando no MPSoC, juntamente com uma aplicação disturbing para gerar atrasos na comunicação, podendo gerar a ocorrência de perdas de deadlines na aplicação principal.
O protocolo de monitoramento numa arquitetura com gerência distribuída de recursos é semelhante ao protocolo com gerência centralizada de recursos.
A principal diferença está no processador que gerência as ações de adaptabilidade.
Em a gerência centralizada o processador mestre é o PE responsável por as ações, já na gerência distribuída, o PE responsável por a execução das ações de adaptabilidade são os processadores locais de cada cluster.
Quando um PE monitor identificar a necessidade de executar alguma técnica de adaptabilidade, este PE deve enviar um pacote ao PE mestre local, responsável por a gerência de recursos do cluster, informando tal necessidade.
Assim como no cenário apresentado na Figura 16, a tarefa F é a tarefa configurada para conter o controle de perdas de deadline, e o processador que está executando essa tarefa é o processador responsável por o monitoramento da aplicação.
A Figura 1 Figura 17 (a), apresenta o mapeamento inicial das tarefas, com o monitoramento analisando o deadline da tarefa F. na Figura 17 Figura 16 (b), o PE monitor verifica que a quantidade de violações de deadlines atingiu a quantidade configurada no campo max_ miss da TCB da tarefa monitorada.
Com isso, o PE monitor envia um pacote ao PE mestre local, solicitando que sejam alteradas as características de escalonamento de todas as tarefas da aplicação.
Em a Figura 17 Figura 16 (c), o PE mestre local recebe a solicitação do PE monitor, para executar a técnica de adaptabilidade.
Após isso, o PE mestre local envia pacotes para todos os processadores, que executam as tarefas da aplicação monitorada, solicitando aumento da prioridade e time-slice das mesmas.
A o receber o pacote de solicitação, do PE mestre local, os PEs escravos alteram as características do escalonamento das tarefas.
Em a sequência, o monitoramento volta a sua execução normal, na Figura 17 (d), verificando a existência de novas violações de deadline.
Em a Figura 17 (e) o PE monitor identifica que novas violações de deadline aconteceram, atingindo o valor configurado no campo max_ miss_ migra da TCB da tarefa F. Com isso, o PE monitor envia um pacote ao PE mestre local informando tais violações e solicitando a migração de alguma tarefa da aplicação monitorada.
A o receber o pacote, o PE mestre local verifica se existem tarefas sendo executadas fora de o seu cluster (essa verificação é detalhada na Seção 6.3).
Em este caso, o PE mestre local verifica que a tarefa C deve ser migrada.
Sabendo qual tarefa migrar, o PE mestre local calcula uma nova posição para a tarefa (esse cálculo é, também, detalhado na Seção 6.3) e envia um pacote de migração ao processador que está executando a tarefa C. na Figura 17 (f) o PE escravo recebe o pacote de migração e migra a tarefa C para sua nova posição, mais próxima de suas comunicantes.
Com isso, o sistema é desfragmentado, melhorando- se o desempenho da aplicação, e reduz- se a energia consumida na NoC.
Em este Capítulo apresentam- se três algoritmos de escalonamento.
O primeiro é o Round-Robin, descrito na Seção 5.1.
O segundo algoritmo apresentado é o Round-Robin com adição de prioridades de tarefas, detalhado na Seção 5.2.
Ambos os algoritmos serviram como base para o desenvolvimento do algoritmo de escalonamento preemptivo baseado em prioridades com uso de time-slice, apresentado na Seção 5.3.
Este é o algoritmo de escalonamento utilizado no MPSoC HeMPS para avaliação das técnicas de adaptabilidade da presente Dissertação.
Ele foi desenvolvido por e adaptado para o presente trabalho, nas plataformas centralizada e distribuída.
Algoritmo de Escalonamento Round--Robin apresenta- se o algoritmo de escalonamento Round-Robin.
Este escalonamento garante que todas as tarefas do processador sejam executadas com o mesmo período de tempo e uma por vez.
As tarefas são escalonadas numa lista circular percorrida regularmente.
Em, os autores apresentam o algoritmo Round-Robin.
Esse algoritmo garante que cada tarefa é alocada no processador por um determinado intervalo de tempo fixo, denominado time-slice.
Para cada ciclo de relógio, um contador de time-slice é incrementado.
Quando uma tarefa completa seu time-slice, o seu contador é zerado e a próxima tarefa da fila é escalonada, passando a ser executada com o mesmo período de tempo.
Em a Figura 18, apresenta- se uma fila circular com três tarefas a serem executadas no processador.
Inicialmente, é alocada a primeira tarefa da fila, Task1.
Como podemos ver na figura, o tempo de execução é de 200 ms..
Quando seu time-slice acabar, a tarefa é preemptada para que a Task2 seja escalonada.
O ciclo é contínuo, alocando uma tarefa por vez e com o mesmo período de tempo.
Quando uma tarefa é finalizada, antes de seu time-slice encerrar (como podemos ver no caso de a Task2), a próxima tarefa da fila é alocada.
Segundo, o escalonamento por Round-Robin não satisfaz os requisitos de sistemas tempo real, pois esses sistemas contém tarefas que executam com diferentes requisitos de desempenho.
Algoritmo de Escalonamento Round--Robin com Prioridade de Tarefas Em esta Seção apresenta- se um complemento ao algoritmo de escalonamento RoundRobin, apresentado na Seção anterior.
Em, os autores apresentam o algoritmo Round-Robin baseado em prioridade.
De modo geral, os kernels suportam até 256 níveis de prioridades, onde o valor 0 representa maior prioridade e o valor 255 representa menor prioridade.
Com este algoritmo, a alocação das tarefas é feita de forma circular e cada tarefa tem sua prioridade.
Sendo que algumas tarefas podem ter prioridade maior do que as outras.
As tarefas com maiores prioridades executam primeiro.
Se uma tarefa com maior prioridade do que a tarefa atual em execução estiver pronta para executar, o microkernel salva o contexto da tarefa atual, em sua TCB, e passa a executar a tarefa com a prioridade maior.
A Figura 19 apresenta uma fila circular de tarefas para escalonar.
A Task1 é inicialmente escalonada.
Quando um evento externo, como dados para uma tarefa de maior prioridade, como a Task2, é recebido por o processador, a Task1 é preemptada para que a tarefa com maior importância seja executada.
Em seguida o mesmo ocorre com a Task2, que é preemptada por a Task3 que contém maior prioridade.
A Task3 ficará em execução até ser finalizada, ou entrar em estado de espera ou até que entre, na fila de tarefas, uma tarefa com maior prioridade.
De a mesma forma que o algoritmo Round-Robin, apresentado na Seção anterior, comentam que o algoritmo ilustrado na Figura 19 não atende os requisitos de sistemas em tempo real.
Como alternativa, na próxima Seção apresenta- se um algoritmo baseado no Round-Robin com prioridade fazendo uso do time-slice dinâmico e não fixo, descrito em.
Algoritmo de Escalonamento Preemptivo Baseado em Prioridade/ Time-Slice Em esta Seção apresenta- se o algoritmo de escalonamento adaptado para o presente trabalho.
Este algoritmo tem por base o escalonamento Round-Robin com prioridade de tarefas, apresentado na Seção 5.2.
De a mesma forma que o Round-Robin, esse escalonador contem uma fila circular de tarefas.
Porém, o diferencial deste algoritmo é o uso de duas características fundamentais para a escolha de qual tarefa escalonar:
Prioridade, responsável por definir qual tarefa deve ser escalonada antes;
Time-slice, neste algoritmo o tempo não é fixo, podendo ser alterado no decorrer de a execução do sistema.
Em a Figura 20, apresenta- se um cenário com três tarefas para serem escalonadas.
Inicialmente a Task1 é escalonada com time-slice de 100ms e com a mesma prioridade das demais tarefas, Task2 e Task3.
Assim como o algoritmo apresentado na Seção 5.2, este algoritmo escalona as tarefas numa fila circular regular, executando a Task2 e na sequência a Task3, com o mesmo período de tempo.
Quando Task1 retorna sua execução, a Task3 tem sua prioridade e seu time-slice alterados em tempo de execução.
De essa forma, a Task1 tem seu contador de tempo salvo e é preemptada, para que a Task3 seja escalonada e executada com seu novo período de tempo.
Após a execução da Task3, o contador de tempo da Task1 é restaurado e ela retorna sua execução a partir de o ponto em que foi preemptada.
Como descrito no Capítulo 4, o monitoramento de tarefas, para controle de violações de deadlines, afeta diretamente a decisão do algoritmo de escalonamento.
Como o monitoramento envia pacotes ao PE mestre solicitando a execução de técnicas de adaptabilidade, o PE mestre efetua alterações nas prioridades e time-slice de todas as tarefas da aplicação em monitoramento.
De essa forma, quando uma aplicação começar a violar o deadline, então, as tarefas passarão a ter maiores prioridades e maior tempo de execução em seus processadores.
As prioridades das tarefas são aumentadas do nível baixo para o alto, já o time-slice é aumenta em 60%.
Inicialmente as tarefas são escalonadas com 10 kciclos de relógio.
A o efetuar a troca das características o time-slice passa para 16 kciclos de relógio.
O presente Capítulo apresenta a técnica de migração de tarefas desenvolvida no escopo da presente Dissertação.
Esta técnica tem por objetivos realizar o balanceamento de carga no MPSoC e desfragmentar o sistema.
Para isso, as tarefas comunicantes devem ser executas próximas uma das outras.
Com essa técnica podemos reduzir a energia consumida na comunicação e otimizar o desempenho das aplicações do sistema.
Em a Seção 6.1 apresenta- se o protocolo de migração de tarefas, descrevendo como o código objeto, dados e contexto da tarefa são enviados para um novo processador.
Em a Seção 6.2 apresenta- se a heurística de migração de tarefas numa arquitetura com gerência centralizada de recursos.
A heurística de migração de tarefas num MPSoC com gerência distribuída de recursos apresenta- se na Seção 6.3.
Em a Seção 6.4 descrevese a forma que o monitoramento de tarefas age diretamente no momento que a migração deve ser efetuada.
O protocolo e a heurística de migração, aqui detalhados, foram publicados em Protocolo de Migração de Tarefas Em esta Seção apresenta- se o protocolo de migração de tarefas, definindo a forma como o código objeto, dados e contexto são enviados para outro processador.
Este protocolo é utilizado, da mesma maneira, na arquitetura com gerência de recursos centralizada e na distribuída.
A técnica de migração de tarefas foi desenvolvida utilizando o MPSoC HeMPS como plataforma de referência, contendo as seguintes características:
Em a Figura 21, apresenta- se o protocolo de migração de tarefas num diagrama de sequência.
A seguir, serão descritos os passos presentes na figura.
PE mestre executa a heurística para saber qual tarefa deve ser migrada e computa qual será a nova posição dessa tarefa.
Note que a tarefa que será migrada continua sua execução, em paralelo.
A heurística de decisão será apresentada nas Seções 6.2 e 6.3.
PE alvo um pacote com todo o conteúdo da página (com código e dados) da tarefa e sua TCB.
A tarefa migrada é escalonada em sua nova posição, uma vez que o código objeto, os dados e a TCB foram completamente recebidos.
O desempenho do protocolo de migração de tarefas é a função treq e tP, tempo para solicitar a migração e computar a nova posição da tarefa;
E tM, tempo para transmitir a tarefa e escalonas- la num novo PE.
Durante treq e tP a tarefa a ser migrada continua sua execução.
Durante tmig a tarefa é preemptada e só retorna sua execução na nova posição Esse protocolo foi desenvolvido em conjunto com outro membro do grupo de pesquisa do Autor, Guilherme Castilhos, na plataforma HeMPS com gerência de recursos centralizada e distribuído.
Heurística de Migração de Tarefas com Gerência Centralizada de Recursos Esta Seção apresentada a heurística de migração de tarefas numa arquitetura com gerência centralizada de recursos.
Esta heurística define qual tarefa, da aplicação monitorada, deve ser migrada e para qual processador ela deve ser alocada.
Como dito no início deste Capítulo, a heurística de migração de tarefas é realizada de forma diferente entre a gerência centralizada e a distribuída.
Em relação a o protocolo apresentado na Figura 21, a heurística de migração de tarefas corresponde à segunda etapa do protocolo de migração de tarefas.
O processo de migração de tarefas foi desenvolvido visando reduzir o tráfego de dados na rede.
Para reduzir o congestionamento na rede, precisamos manter as tarefas sendo executadas em processadores vizinhos, visando reduzir a carga de comunicação na NoC.
A Figura 22 apresenta o pseudocódigo da heurística de migração de tarefas.
Este processo está dividido nas seguintes etapas:
Deadlines, solicitando o serviço de migração de tarefas ao PE mestre.
Baseado na etapa de profiling, o PE mestre verifica qual tarefa (tM) da aplicação deve ser migrada.
A tarefa tM continua a ser normalmente escalonada, passando para o estado migrating apenas quando vier a confirmação do mestre com o endereço do PE destino.
Onde: Esbit:
Consumo de energia de cada roteador (esse valor é igual para todos os roteadores);
Nhops: Distância entre os roteadores comunicantes.
Heurística de Migração de Tarefas com Gerência Distribuída de Recursos Esta Seção apresenta a heurística de migração de tarefas numa arquitetura com gerência distribuída de recursos.
A diferença desta heurística para a heurística apresentada na Seção 6.2, está na forma como o processador decide quem deve ser migrado e para onde migrar.
A Figura 23 apresenta o pseudocódigo da heurística de migração de tarefas desenvolvido.
Este processo está dividido nas seguintes etapas:
PEs distantes 1 hop de n0.
Caso| N|\&gt; 1, P conterá os processadores contidos no quadrado envolvente que contém todos os processadores de N. Para esta heurística, só serão adicionados ao conjunto P aqueles processadores que pertencerem ao cluster da aplicação monitorada.
Interação do Monitoramento com Migração de Tarefas Como apresentado no Capítulo 4, o monitoramento de tarefas é o mecanismo responsável por a solicitação da alteração de prioridades e time-slice das tarefas de uma determinada aplicação, afetando diretamente o escalonamento (Capítulo 5).
Em alguns casos, apenas efetuar a troca das características de escalonamento é suficiente para não haver mais violações de deadlines por a aplicação.
Porém, em outros casos efetuar essa troca não basta e a aplicação continua violando deadlines.
Em esses casos o monitoramento de tarefas deve solicitar a execução da técnica de migração de tarefas.
Em a Figura 24, apresenta- se a interação do monitoramento com a migração de tarefas.
Para ilustrar a migração de tarefas foi utilizada arquitetura distribuída de recursos.
A etapa 1 da Figura ilustra a configuração inicial da aplicação.
O LMP0 é responsável por gerenciar a aplicação principal.
Há quatro tarefas mapeadas no cluster da aplicação (A, B, C, F) e duas tarefas mapeadas em clusters vizinhos (D, E).
Em a etapa 2 o PE monitor verifica perdas de deadlines e solicita a alteração das características de escalonamento.
A etapa 3 apresenta- se os pacotes de solicitação para aumento das prioridades da aplicação principal.
Até este ponto, tem- se a execução do protocolo da técnica de adaptabilidade responsável por as trocas das características das tarefas, apresentadas no capítulo 5, afetando diretamente o escalonamento.
Despois que o mestre envia um pacote solicitando para que todas as tarefas da aplicação sejam alteradas, o PE monitor continua efetuando o monitorando da aplicação, para verificar se as violações de deadlines continuam ocorrendo, etapa 4.
Em a Etapa 5, o PE monitor verifica as mensagens de comunicação das tarefas.
Em a Etapa 6, o PE monitor identifica que a quantidade de perdas de deadline configurada no max_ miss_ migra, da TCB da tarefa F, atingiu as violações analisadas.
Com isso, solicita ao PE mestre local a execução da técnica de adaptabilidade.
Como explicado anteriormente, o PE mestre local define que todas as tarefas fora de o cluster de sua aplicação devem ser migradas, nesse caso as tarefas D e E. Sabendo quais tarefas migrar (tm) o PE mestre local, na Etapa 7, define qual será a nova posição de tm e envia uma solicitação de migração para os PEs escravos que estão executando as tarefa D e E. na Etapa 5 ocorre a migração das tarefas e logo em seguida, na Etapa 6, as tarefas migradas são escalonadas em suas novas posições.
Assim como descrito na Seção 4.2, com a execução das técnicas de adaptabilidade, o sistema é desfragmentado e não há mais perturbações entre as tarefas comunicantes, melhorando- se o desempenho da aplicação, e reduz- se a energia consumida na NoC.
Este Capítulo apresenta os resultados da implementação da arquitetura HeMPS com técnicas de adaptabilidade apresentadas nos Capítulos 4, 5 e 6.
São analisados dois cenários de execução:
O primeiro onde se apresenta uma execução com gerência centralizada de recursos, e outro com a execução num MPSoC com gerência distribuída de recursos.
Para efetuar a avaliação do trabalho realizado no decorrer de o curso de Mestrado, obteve- se resultados experimentais a partir de uma NoC 6x6 instanciada no MPSoC HeMPS, apresentado no Capítulo 3.
Em a Seção 7.1, apresenta- se os resultados obtidos a partir de um MPSoC com gerência centralizada de recursos.
Em a Seção 7.2, apresente- se as avaliações aplicadas a um MPSoC com gerência distribuída de recursos.
A seguir apresentam- se algumas características relevantes para a avaliação das técnicas de adaptabilidade:
Kciclos de relógio, conforme decisão do monitoramento de tarefas.
Monitoramento para mais ou para menos.
Quando a perda de deadline atingir esse valor a prioridade e o time-slice das tarefas da aplicação serão alterados.
Avaliação de um MPSoC com Gerência Centralizada de Recursos Em esta Seção apresentam- se os primeiros resultados obtidos do presente trabalho.
É avaliado o comportamento de um sistema com gerência centralizada de recursos, fazendo uso das técnicas de adaptabilidade.
Em a Seção 7.1.1 tem- se a descrição do cenário de teste.
Em a Seção 7.1.2 apresenta- se os resultados obtidos deste cenário descrito.
Em esta Seção apresenta- se o cenário experimental configurado para a obtenção dos dados apresentados na Seção 7.1.2.
Em a Figura 25 apresenta- se o cenário utilizado para a obtenção dos dados desta Seção.
A Etapa 1 ilustra o mapeamento inicial das tarefas.
A aplicação monitorada está em destaque, composta por 6 tarefas (A, B, C, D, E, F).
A tarefa F contém a configuração necessária para que o processador, que a está executando, faça o monitoramento de sua aplicação.
Em um cenário dinâmico, onde aplicações são inseridas/ removidas em tempo de execução, o MPSoC pode estar com muitos de seus recursos em uso.
Em um dado momento, novas aplicações podem ser carregadas no MPSoC, com comunicações competindo com a comunicação de aplicação principal.
Desta forma, o desempenho da aplicação principal é penalizado e o microkernel do PE responsável por o monitoramento solicita ao PE mestre (M) o aumento da prioridade e do time-slice das tarefas da aplicação monitorada, Etapa 2.
A o receber a solicitação, na Etapa 3, o PE mestre envia pacotes de solicitação de alteração das características do escalonamento aos PEs escravos, que executam as tarefas da aplicação monitorada.
A Etapa 4 ilustra o PE monitor continuando seu monitoramento, agora com as alterações no escalonamento.
Nota- se, na Etapa 5, que as alterações de escalonamento não foram suficientes para melhorar o desempenho da aplicação.
Assim, o PE monitor envia um pacote ao PE mestre solicitando migração de alguma tarefa da aplicação.
Baseado nos dados coletados na etapa de profiling, o PE mestre decide qual tarefa deve ser migrada, neste caso, tarefa C. Sabendo qual tarefa deve migrar, o PE mestre escolhe uma nova posição e, ainda na Etapa 5, envia um pacote solicitando a migração desta tarefa.
Em a Etapa 6 a tarefa é migrada para a posição mais próxima entre suas tarefas comunicantes, restaurando o desempenho da aplicação e economizando energia na comunicação.
Em esta Seção apresenta- se a avaliação da aplicação experimental descrita na Seção anterior, apresentando e analisando gráficos dos tempos de iteração da aplicação principal para o cenário de teste.
Estes resultados foram publicados em.
O desempenho do protocolo de monitoramento com a execução das técnicas de adaptabilidade foi avaliado de acordo com os quatro cenários descritos a seguir, baseado no mapeamento das tarefas apresentados na Figura 25: Tarefa C (a tarefa que deve ser migrada) da aplicação principal executando, respectivamente, nos cenários` 1',` 2',` 3',` 4'.
As tarefas iniciais da aplicação(` A'e` B') são as primeiras a serem mapeadas, produzindo dados para as tarefas que ainda não estão mapeadas.
Quando as tarefas consumidoras são mapeadas, elas podem consumir mais depressa, o que explica as pequenas variações de tempo no início do processo.
A Figura 26 ilustra que, após o mapeamento das tarefas consumidoras, o tempo das iterações passa a ser praticamente constante, oscilando entre 3800 e 4500 ciclos de relógio.
Este é considerado o cenário de referência para os demais dados desta Seção.
A Figura 27 (cenário` 2') mostra que o tempo das iterações, mesmo depois de mapeadas as tarefas consumidoras, continua com alta variação.
Esta variação ocorre por causa de as aplicações de perturbação mapeadas no sistema.
Essas aplicações atrasam a comunicação da aplicação inicial, o que explica tal variação, com altos picos.
O tempo se torna constante após a iteração 80, pois as tarefas de perturbação são finalizadas, como em destaque na figura.
A oscilação de tempo, após o término das tarefas de perturbação, fica alta por o fato de que as tarefas de perturbação se comunicam com o PE mestre para finalizar a tarefa.
A Figura 28 (cenário` 3') apresenta- se o tempo de iteração com o monitoramento analisando os dados da tarefa F. Podemos notar poucas variações de tempo, pois após algumas perdas de deadline (max_ miss) o PE escravo, responsável por o monitoramento da aplicação, solicita ao PE mestre a troca da prioridade e o aumento do time-slice de todas as tarefas da aplicação principal.
De essa forma notamos que em alguns períodos o tempo fica praticamente constante em 5000 ciclos de relógio, como podemos ver entre as linhas tracejadas.
Em a Figura 29 (cenário` 4') tem- se a execução da técnica de migração de tarefas.
Em esse caso, a tarefa F (tarefa que está sendo monitorada) continua com perdas de deadline, mesmo após as alterações no escalonamento na iteração 20.
Podemos notar que na iteração 40 a tarefa C é migrada, havendo uma elevação no pico de tempo.
Esse pico ocorre devido a o tempo de execução do protocolo de migração.
Após a migração, notamos que o tempo das iterações passa a ser praticamente constante, oscilando entre 3500 e 4100 ciclos de relógio.
De essa forma, este cenário demonstra que a migração da tarefa C atingiu o objetivo desejado, melhorando o desempenho do sistema, em comparação com a Figura 26, cenário com a aplicação sozinha no sistema.
E comparado ao cenário com aplicações de perturbação, Figura 27, o ganho é maior, passando a latência de, aproximadamente, 5000 ciclos de relógio para 3500 ciclos de relógio.
Como pode- se verificar nos resultados apresentados, as técnicas de adaptabilidade atingiram seus objetivos em diminuir as violações de deadline da aplicação monitorada.
Em a Tabela 2, podemos analisar que com a execução dessas técnicas o desempenho do sistema não foi penalizado, baseando- se no tempo total de execução do cenário com tarefas para perturbação.
Com a execução das técnicas de adaptabilidade, o tempo total de execução da aplicação principal não é afetado, nesse caso, melhorando- se em até 7,5%.
Isso demonstra que as técnicas de adaptabilidade proveem redução de latência e jitter, sem afetar o tempo de execução total do sistema.
Avaliação de um MPSoC com Gerência Distribuída de Recursos Após apresentar os resultados obtidos com a utilização de um MPSoC com gerência centralizada de recursos, nesta Seção, apresentam- se os resultados obtidos com o uso de um MPSoC com gerência distribuída de recursos.
É avaliado o comportamento do sistema, fazendo uso das técnicas de adaptabilidade.
Em a Seção 7.2.1 tem- se a descrição do cenário de teste.
Em a Seção 7.2.2 apresenta- se os resultados obtidos através deste cenário descrito.
Em esta Seção apresenta- se o cenário experimental configurado para a obtenção dos dados apresentados na Seção 7.2.1.
Em a Figura 30 apresenta- se o cenário utilizado para a obtenção dos dados analisados na próxima Seção.
De a mesma forma que na Figura 25, a aplicação monitorada está em destaque, composta por 6 tarefas (A, B, C, D, E, F).
A tarefa F contém a configuração necessária para que o processador, que está executando ela, faça o monitoramento de sua aplicação.
O mapeamento, no MPSoC com gerência distribuída, é dinâmico e tenta mapear as tarefas próximas umas das outras.
Por isso, para este cenário, usam- se diversas aplicações para perturbação, fazendo com que a aplicação principal (que é a última a ser mapeada) fique com algumas tarefas fora de o cluster de sua aplicação, deixando o sistema fragmentado devido a o fato de não conter espaços para todas as tarefas no mesmo cluster.
As Etapas de 1 a 4, deste cenário, são as mesmas apresentadas na Seção 7.1.1.
A diferença entre o cenário distribuído para o centralizado é no protocolo de migração.
Em a gerência centralizada deve- se migrar uma tarefa da aplicação.
Em a gerência distribuída devem- se migrar todas as tarefas que estiverem fora de o cluster de seu mestre, se possível.
Desta forma, na Etapa 5 o PE mestre envia uma solicitação de migração para as tarefas C e E que executam fora de o cluster.
Em a Etapa 6 nota- se a desfragmentação do sistema, fazendo com que a aplicação principal seja executada com suas tarefas próximas umas das outras.
Assim, é possível economizar energia na comunicação e aumentar o desempenho do sistema.
Em esta Seção apresenta- se a avaliação da aplicação experimental descrita na Seção anterior, apresentando e analisando gráficos dos tempos de iteração da aplicação principal para o cenário de teste.
O desempenho do protocolo de monitoramento com a execução das técnicas de adaptabilidade, num sistema com controle de recursos distribuído, foi avaliado de acordo com os três cenários descritos a seguir, baseado no mapeamento das tarefas apresentados na Figura 30: A Figura 31 mostra que o tempo das iterações, mesmo depois de mapeadas as tarefas consumidoras, continua com alta variação.
Esta variação ocorre por causa de as aplicações de perturbação mapeadas no sistema.
Após o mapeamento das tarefas consumidoras, o tempo das iterações passa a ser praticamente constante, atingindo 10 kciclos de relógio por iteração.
Este é considerado o cenário de referência para os próximos cenários analisados.
Em a Figura 33 (cenário` 3') temos a execução da técnica de migração de tarefas.
Em esse caso, a tarefa F (tarefa que está sendo monitorada) continua com perdas de deadline após alterações no escalonador.
Podemos notar que, aproximadamente, na iteração 80 as tarefas C e E são migradas, havendo um alto pico de tempo.
Esse pico ocorre devido a o tempo de execução do protocolo de migração descrito no Capítulo 6.
Após as migrações, notamos que o tempo das iterações passa a ser constante em 8,5 kciclos de relógio, abaixo de o tempo apresentado no cenário de referência que se mostra entre 9,3 e 10 kciclos de relógio.
Desta forma, a tarefa parou de perder deadline, que inicialmente estava configurado em 9 kciclos de relógio.
Assim como nos cenários de gerência centralizada de recursos, apresentados na Seção 7.1, as técnicas de adaptabilidade atingiram seus objetivos, também na gerência distribuída de recursos, reduzindo a quantidade de violações de deadline da aplicação monitorada.
Em a Tabela 3, analisa- se o tempo total de execução, em ciclos de relógio, da aplicação principal.
Com a execução das técnicas de adaptabilidade, o tempo total de execução da aplicação principal não é penalizado, nesse caso, melhorando- se em até 3%.
A diferença de tempo entre o cenário de referência e o cenário com alterações nas características de escalonamento é o tempo gasto por o protocolo adaptativo, que solicita as alterações de prioridade e time-slice das tarefas da aplicação monitorada.
De a mesma forma que na gerência centralizada, demonstra- se que as técnicas de adaptabilidade proveem redução de latência e jitter, sem afetar o tempo de execução total do sistema.
Esta Dissertação teve como principal objetivo apresentar técnicas de controle adaptativo para atendimento a requisitos de aplicações em MPSoCs.
Descreveu- se uma técnica de análise de dados em tempo de execução, que é o monitoramento de tarefas, apresentado no Capítulo 4.
Também, foram apresentadas duas técnicas para prover a adaptabilidade:
Alteração das características do escalonamento das tarefas, apresentado no Capítulo 5;
migração de tarefas, aproximando tarefas comunicantes e desfragmentando o sistema, apresentado no Capítulo 6.
Como ponto de partida desta Dissertação, temos a plataforma HeMPS centralizada e distribuída, como descrito no Capítulo 3.
Esta plataforma foi modificada a fim de serem adicionadas técnicas de adaptabilidade para MPSoCs.
Essas técnicas foram estudadas e analisadas dentro de um contexto de estado-da-arte, apresentado no Capítulo 2.
De entre as modificações efetuadas na plataforma, destacam- se o desenvolvimento do monitoramento de tarefas, heurística de migração de tarefas e adaptação do algoritmo de escalonamento preemptivo baseado em prioridades.
A implementação das técnicas de adaptabilidade envolveu modificações de software (porte do kernel).
A primeira contribuição deste trabalho foi discutida durante o Capítulo 4, onde apresenta- se a forma de como uma aplicação deve ser monitorada para aplicar técnicas a fim de evitar violações de deadline.
A segunda contribuição deste trabalho foi detalhada no Capítulo 5, demonstrando a operação do escalonador adaptado neste trabalho, apresentando sua sequência de criação divida em três etapas:
Algoritmo base (Round-Robin); (
ii) aprimoramento do algoritmo base, adicionando prioridade às tarefas;
Algoritmo final, com alteração da prioridade e time-slice em tempo de execução.
A terceira contribuição deste trabalho foi descrita no Capítulo 6, onde apresentou- se a técnica de migração de tarefas, protocolo e heurística, possibilitando a desfragmentação do sistema, economia de energia e melhoras no desempenho das aplicações.
Com isso, os resultados analisados mostram que, independente da gerência de recursos que se utiliza, centralizada ou distribuída, as técnicas de adaptabilidade proveem redução de latência e jitter, sem comprometimento do tempo total de execução das aplicações.
A contribuição mais relevante deste trabalho é que as técnicas de adaptabilidades adicionadas na plataforma MPSoC, centralizada e distribuída, estão validadas e operacionais.
Ou seja, as duas arquiteturas da plataforma executam um microkernel com suporte a controle adaptativo do sistema.
Publicações Relacionadas ao Tema da Dissertação As contribuições apresentadas neste trabalho foram publicadas na forma de dois artigos em Conferências:
Como trabalhos futuros enumeram- se as seguintes atividades:
Adicionar as técnicas de adaptabilidade, apresentadas neste trabalho, a uma plataforma com suporte à tolerância a falhas.
Incluir outras técnicas de adaptabilidade:
Prioridade de comunicação, DVFS, comutação por circuito (circuit-- switching).
Generalizar os monitores para avaliarem outros requisitos de aplicação, como tempo de execução ou vazão.
Avaliar e implementar a utilização de uma rede dedicada para o fluxo de dados do gerenciamento.
