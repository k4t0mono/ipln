Define- se correferência como a relação entre diversos componentes linguísticos com uma mesma entidade de mundo.
A resolução automática de correferência textual está inserida num contexto muito importante na área de Processamento da Linguagem Natural, pois vários sistemas necessitam dessa tarefa.
O nível de processamento linguístico depende do conhecimento de mundo, e isso ainda é um desafio para a área.
Esse desafio estimulou e tornou- se o objeto de estudo desta dissertação.
Em esse sentido, analisamos o papel das categorias de entidades nomeadas e, através de aprendizado de máquina, verificamos as condições de resolução em diferentes categorias.
Os resultados dos experimentos demonstraram que o conhecimento de mundo, representado nas categorias de entidades nomeadas, auxilia nessa tarefa, pois o percentual de retorno do sistema com base nas categorias teve uma melhora de 17% em comparação com a versão sem as categorias.
Palavras-Chave: Resolução de Correferência, Processamento da Linguagem Natural, Entidades Nomeadas, Aprendizado de Máquina.
A área de Processamento da Linguagem Natural (PLN) está se destacando nos últimos anos devido a a necessidade de otimizar a grande quantidade de informação disponível na internet.
Com isso, várias aplicações estão ganhando destaque, como a sumarização automática e a extração de informação.
Uma tarefa envolvida nessas aplicações é a resolução de correferência.
Esta tarefa diz respeito ao processo de identificar automaticamente e corretamente as expressões correferentes, que são expressões que se referem a uma mesma entidade de mundo.
Por necessitar do conhecimento de mundo, essa tarefa ainda apresenta grandes desafios para a área.
Em se tratando da língua portuguesa, a disponibilidade de recursos é ainda muito reduzida.
Em trabalhos que abordam a língua inglesa, nota- se o uso de um conjunto de categorias de entidades, em especial, nas avaliações conjuntas da área.
Uma definição para conjunto de categorias é que especificam grupos que apresentam as mesmas características.
Acredita- se que para o português também se conseguirá melhores resultados para a resolução de correferência daqueles existentes hoje se for considerada a observação de tipos de categorias.
Uma avaliação conjunta é o ACE, a qual define que suas tarefas abranjam expressões linguísticas formadas por nomes próprios, bem como sua retomada por nomes comuns ou grupos nominais (por exemplo, &quot;o candidato democrata&quot;), além de expressões temporais (horas e datas) e expressões numéricas (percentuais e monetárias).
Em o ACE essas expressões são denominadas &quot;Named Entities».
Esta avaliação trata de textos da língua inglesa.
Já a avaliação conjunta para o português, o HAREM, foca em expressões linguísticas referenciadas num texto apenas por um nome próprio (como nomes de Pessoas, Organizações, Lugares), e também expressões temporais e numéricas.
Em o HAREM essas expressões são denominadas &quot;Entidades Mencionadas».
Em este trabalho, será adotada a proposta do ACE, que inclui na análise os substantivos comuns e sintagmas nominais relacionados aos nomes próprios identificados e, por isso, se fará uso da nomenclatura Entidades Nomeadas -- ENs (Named Entities).
No que se refere às definições das categorias de ENs, este trabalho seguirá as definições propostas por a avaliação HAREM.
Com base nesse cenário, parte- se da hipótese que o uso de categorias específicas de entidades nomeadas tem um impacto positivo na tarefa de resolução de correferência, já que cada categoria apresenta características distintas e bem definidas.
Como a categorização delimita o domínio, torna- se mais viável o uso de informação semântica como instrumento de apoio no processo de resolução de correferência.
A informação semântica é dada no presente trabalho através da análise automática feita por o analisador sintático Palavras.
O objetivo deste trabalho é propor e avaliar métodos para a resolução de correferência para a língua portuguesa, com foco nas categorias de ENs e utilizando informações semânticas fornecidas por o analisador sintático Palavras relativas às categorias de ENs.
No que se refere aos objetivos específicos, pode- se listar:
Levantamento das features propostas por outros trabalhos, tanto para a língua inglesa como para a portuguesa;
Seleção de um conjunto de features de acordo com o estudo realizado;
Modelagem e desenvolvimento de um protótipo;
Realização de experimentos;
Comparação da resolução considerando o conjunto completo de expressões com o conjunto limitado por categorias;
Avaliação dos resultados.
Este trabalho considera como hipótese que o uso de categorias de ENs pode auxiliar na tarefa de resolução de correferência, uma vez que categorias de ENs são representadas por um conjunto mais coeso de tipos semânticos.
A presente dissertação está estruturada da seguinte forma:
O capítulo 2 apresenta a fundamentação teórica do trabalho, como os conceitos de correferência e a descrição das conferências ACE e HAREM.
Já o capítulo 3 traz a descrição dos trabalhos relacionados, realizando um levantamento das features apresentadas em cada um de eles.
O capítulo 4 lista os recursos utilizados para a realização dos experimentos.
O capítulo 5 apresenta as características técnicas do protótipo desenvolvido, enquanto que o capítulo 6 descreve os experimentos realizados, como também uma avaliação dos seus resultados.
O capítulo 7 traz as considerações finais, com as contribuições, limitações e trabalhos futuros.
Este capítulo irá abordar os conceitos base para a elaboração desta dissertação, que são a resolução de correferência e as categorias de ENs, de acordo com duas avaliações conjuntas:
O ACE e o HAREM.
Resolução de correferência é uma tarefa importante em diversas aplicações de PLN, pois de ela depende uma compreensão adequada dos textos.
O principal desafio da tarefa está na identificação automática e correta de expressões correferentes, que são as expressões que se referem a uma mesma entidade.
A discussão sobre a biotecnologia nacional está enviesada, pois está sendo entendida como sinônimo de transgenia.
A opinião é do agrônomo Miguel Guerra, da UFSC (Universidade Federal de Santa Catarina).
Em o fragmento de texto da Figura 1, retirado do texto Ciencia_ 2000.6389.
Txt do corpus Summ-it (descrito no Capítulo 4), as expressões Guerra e o agrônomo fazem referência à entidade Miguel Guerra, já mencionada anteriormente no texto.
Para não repetir a mesma expressão, faz- se uso de outra diferente, mas que retoma a mesma entidade mencionada previamente.
Este é um método muito utilizado no processo de escrita, para não deixar o texto repetitivo e cansativo.
A dificuldade dessa tarefa pode ser explicada por a dependência da compreensão do contexto, que está relacionada a questões linguísticas e habilidades cognitivas humanas complexas, de difícil reprodução por sistemas computacionais.
Por exemplo, como inferir computacionalmente que a palavra agrônomo, que está sendo citada dois parágrafos abaixo de a expressão o agrônomo Miguel Guerra está se referindo a esta entidade e não a uma outra?
O conjunto dessas expressões referenciais relativas a uma mesma entidade de mundo denomina- se cadeia de correferência.
Este conjunto é responsável por a construção coesa de um texto e por isso sua importância, já que a coesão é responsável por a compreensão textual.
Para uma melhor compreensão de correferência, é preciso definir anáfora, já que seus conceitos estão relacionados.
Anáfora se define como toda a retomada de uma ideia já introduzida por uma entidade mencionada anteriormente.
Pode- se dizer que quando uma entidade é citada pela primeira vez num texto, se faz o processo de evocação da entidade.
A expressão que faz a retomada da entidade é dita anafórica, e a expressão a quem ela se refere é chamada de antecedente.
A relação entre essas expressões denomina- se relação de correferência.
Em o fragmento do exemplo anteriormente citado, Miguel Guerra é o antecedente e Guerra é a anáfora.
Assim, expressões correferentes fazem referência à mesma entidade, enquanto expressões anafóricas podem retomar uma referência ou ativar um novo referente.
A anáfora pressupõe um par ordenado (antecedente, anáfora) e a correferência remete à ideia de conjunto.
A Figura 2 (retirada de) ilustra um exemplo de anáfora sem a relação de correferência.
O Eurocenter oferece cursos de Japonês na bela cidade de Kanazawa.
Os cursos têm quatro semanas de duração.
As aulas do nível avançado incluem refeições típicas e passeios a pontos turísticos.
De acordo com o exemplo, a expressão anafórica Os cursos retoma uma expressão já citada no discurso, cursos de Japonês (antecedente), sendo que essas duas expressões fazem menção à mesma entidade, são expressões correferenciais e anafóricas.
Já a expressão As aulas do nível avançado não é correferente a nenhum termo, mas apresenta significado na expressão cursos de Japonês, sendo uma expressão anafórica, mas não correferente.
Geralmente, para o desenvolvimento do processo de resolução, é preciso realizar, além de a análise sintática das frases, também a análise semântica e de contexto, o que envolve conhecimento de mundo.
Uma combinação dessas informações se faz necessária para realizar a identificação das expressões correferentes.
Porém, capturar um modelo do contexto é ainda um grande desafio para a área.
Já a identificação de tipos semânticos é uma tarefa bem desenvolvida que pode ser adotada como parte da resolução de correferência.
A seção a seguir irá apresentar a descrição mais detalhada das categorias de ENs de acordo com duas avaliações conjuntas na área.
Em esta seção são apresentadas categorias de ENs, tal como abordadas nas avaliações conjuntas ACE e HAREM.
Avaliações conjuntas são eventos com o intuito de incentivar e avaliar os sistemas desenvolvidos para resolver uma ou mais tarefas específicas, de acordo com os objetivos da avaliação.
Para este trabalho foram estudadas duas avaliações, o ACE e o HAREM, com o foco em tarefas relacionadas ao tema desta dissertação.
O ACE é uma avaliação conjunta internacional com o intuito de abordar a compreensão da linguagem humana por meio de a tecnologia, provendo o reconhecimento da linguagem textual.
Uma das tarefas definidas por essa avaliação diz respeito à identificação e relacionamento de entidades nomeadas de acordo com categorias pré-estabelecidas.
Entidades não pertencentes às categorias pré-definidas não devem ser consideradas.
A tarefa de reconhecimento dos relacionamentos entre as entidades corresponde à resolução de correferência.
No que se refere à forma de tratamento dada ao problema por os sistemas, não há restrições em usar e buscar conhecimento extratextual, isto é, pode- se utilizar de dados externos aos textos como meio de apoio para o reconhecimento, como realizar consultas à internet e bases de dados, como a WordNet1.
O ACE trata também dos sintagmas nominais, além de os nomes próprios, na tarefa de relacionamento entre as entidades.
O sintagma consiste num conjunto de elementos que constituem uma unidade significativa dentro de a oração, mantendo relações de dependência e ordem.
Sua organização é referente a um elemento central, denominado de núcleo.
De acordo com a classificação do núcleo é determinado o nome para o sintagma, por exemplo, no sintagma verbal, o verbo é o seu núcleo;
Já no sintagma adjetival, o núcleo é um adjetivo.
O sintagma nominal (Sn) pode ter como núcleo um nome ou um pronome substantivo A estrutura básica de uma sentença é formada por um sintagma nominal e um sintagma verbal.
Além desses elementos, uma oração pode ter outros sintagmas complementares, como, por exemplo, o sintagma preposicional e o sintagma adjetival.
O sintagma preposicional é constituído de uma preposição seguido de um Sn.
Um sintagma preposicional ocorre dentro de um Sn, sintagma verbal ou sintagma adjetival.
Retomando o exemplo da página 17, pode- se definir a seguinte estrutura sintática para a frase:
A opinião é do agrônomo Miguel Guerra, da UFSC.
Por meio de esta ilustração, é possível identificar a composição de um Sn (no exemplo marcado por a etiqueta &quot;g&quot;).
Essa estrutura foi criada através da ferramenta de geração de estrutura sintática desenvolvida por Bick, que se encontra disponível para a língua portuguesa na Web2.
Esta dissertação tratará os sintagmas nominais para a tarefa de resolução de correferência.
No que se refere às categorias de ENs, o ACE as define da seguinte forma (os exemplos são retirados do corpus Summ-it, descrito no Capítulo 4):
FAC (instalação), que contempla aeroportos e outras construções GPE (entidade geopolítica) abrange continentes, países ou estados a..
Exemplo: &quot;O Brasil&quot;;
LOC (localização), que se refere a endereços, fronteiras e regiões gerais européia&quot;;
ORG (organização), diz respeito a empresas, órgãos governamentais, de entre outros que orienta o governo francês sobre aspectos éticos da biotecnologia&quot;;
Per (pessoa), que se refere tanto a grupos como a indivíduos Observando a descrição de cada categoria, percebe- se que uma categoria possui um conjunto de características, as quais expressam uma delimitação das possibilidades de identificação para uma EN.
Esse conjunto pode permitir a definição de um conhecimento de mundo em relação a a tarefa de correferência, já que uma categoria representa um grupo de definições específicas.
Para realizar a marcação de correferência, a avaliação definiu que cada entidade é identificada por uma etiqueta.
Após, outra etiqueta irá identificar se é um referente (REF) ou um atributo de referência (ATR).
ATR é toda a entidade que faz ligação com o referente e, por isso, o mesmo deverá acompanhar a etiqueta do referente, gerando, assim, o elo de correferência.
O subtipo também é indicado, por exemplo, individual (ind), grupo (group).
A Tabela 1 mostra um exemplo dessa marcação.
O HAREM é uma avaliação conjunta que tem o objetivo de avaliar sistemas reconhecedores de entidades nomeadas ou entidades mencionadas (EMs), de acordo com a sua terminologia própria.
EMs são definidas como nomes próprios considerando- se o contexto em o qual o nome está inserido.
O HAREM, em sua segunda edição, propôs uma nova trilha na avaliação referente a o reconhecimento de relações entre EMs, a ReRelEM (Reconhecimento de Relações entre Entidades Mencionadas), uma tarefa próxima à resolução de correferência que, no entanto, não considera os sintagmas nominais com o núcleo substantivo comum.
A seguir, serão descritas as categorias definidas no HAREM (os exemplos são retirados do corpus Summ-it, descrito no Capítulo 4):
Pessoa: Refere- se a uma pessoa ou grupo de pessoas Organização:
Refere- se a entidades que apresentam características definidas por uma estrutura organizacional Acontecimento:
Abrange eventos que descrevam um conjunto de atividades ou ações Lugar:
Entidades que referenciam um local específico Abstração:
Entidades que exprimam idéias a..
Sem exemplos no corpus.
Obra: Entidades que foram construídas por o homem e que tenham um nome próprio Valor:
Refere- se a entidades absolutas ou relativas.
Itens numéricos utilizados para marcar ordem no texto não devem ser considerados a..
Sem exemplos no corpus.
Coisa: Refere- se a objetos (com ou sem forma determinada), ou a um conjunto de objetos Tempo:
Entidades que se referem explicitamente à data ou hora.
Nomes de meses com a primeira letra em maiúscula são considerados membros dessa categoria.
Não devem ser considerados valores que identifiquem idade a..
Sem exemplos no corpus.
Outro: Entidades que não atenderam a nenhuma das categorias acima listadas A tarefa de classificação do HAREM se diferência do ACE por identificar todos os nomes próprios do texto (classificando- os como Outro, se não for de nenhuma das categorias definidas anteriormente).
Outra diferença é que o HAREM trata apenas nomes próprios, enquanto o ACE considera todas as referências ocorridas no texto em relação a uma categoria, e irá relacionar a expressão &quot;o pesquisador «com um nome próprio previamente introduzido no texto, &quot;José Steiner», por exemplo.
Para a marcação de correferência, o HAREM determina que cada entidade receba um número como identificação (Id).
Quando ocorre a relação de correferência, esse Id deverá ser informado na marcação corel, sendo esta a responsável em criar as relações entre as entidades.
Caso ocorra que a referência seja entre mais de uma entidade, devese colocar o Id de todas as entidades, separado por espaço, conforme exemplo da Figura 4 (as marcações e delimitam a EN).
Em 9 de Setembro de 1895, foi organizado em Id $= &quot;15&quot;\&gt; New York o Id $= &quot;16 «COREL $= &quot;15 «TIPOREL $= &quot;ocorre_ em&quot;\&gt; Congresso Americano de Bowling TIPOREL $= &quot;ident ocorre_ em&quot;\&gt; ABC\/ EM\&gt; -- Id $= &quot;18 «COREL $= &quot;16 15 «TIPOREL $= &quot;ident ocorre_ em&quot;\&gt; American Bowling Congress sediado em Id $= &quot;19 «COREL $= &quot;15 16 17 18 «TIPOREL $= &quot;incluido sede_ de&quot;\&gt; Milwaukee com o objectivo de aplicar medidas correctivas contra os excessos de jogatina e aperfeiçoar ainda mais as regras.
Para realizar a marcação de correferência, também será necessário realizar a identificação do tipo de relação entre as entidades correlacionadas.
A avaliação definiu as seguintes identificações e como devem ser aplicadas:
Identidade ­ todas as relações, exigindo igualdade de categoria, tipo e subtipo.
Inclusão ­ todas as relações, exceto valor, exigindo igualdade de categoria.
Ocorre_ em ­ relação entre acontecimento e local, e relação entre organização e local.
Outra ­ várias relações que não se encaixam nas definições anteriores.
Um exemplo é dado por as relações familiares entre entidades do tipo Pessoa.
A relação de identidade ocorre entre entidades mencionadas da mesma categoria.
A relação de inclusão é estabelecida quando uma entidade faz parte de outra entidade.
A relação ocorre_ em infere relação de localização, por isso, deve ser interpretada como localizada_ em quando estiver tratando a relação entre categorias do tipo Organização e Local.
Abaixo, a descrição de como a marcação deverá ocorrer para identificar as relações entre entidades.
Identidade (sem TIPOREL ou TIPOREL $= &quot;ident&quot;) inclusão (TIPOREL $= &quot;inclui «ou TIPOREL $= &quot;incluido&quot;) ocorre_ em (TIPOREL $= &quot;ocorre_ em «ou TIPOREL $= &quot;sede_ de&quot;) Os exemplos da Figura 4 mostram o modelo de retorno dos sistemas, fazendo uso da marcação de relação e de correferência.
É importante considerar essas definições, pois os sistemas são avaliados com base nessas informações e formato.
A partir de a compreensão do que é correferência, percebe- se o quanto é importante sua resolução para diversos sistemas computacionais, como a sumarização automática, já que sua resolução está diretamente relacionada com a clareza e a coerência textual.
Observando, também, as definições das características para determinar uma categoria, pode- se inferir que elas podem ser utilizadas como forma de conhecimento de mundo.
Em este trabalho, conhecimento de mundo é o contexto do assunto em que a EN está inserida.
Assim, cada categoria é vista a partir de suas peculiaridades semânticas, o que poderá possibilitar melhores resultados na tarefa de resolução de correferência.
Como essas avaliações conjuntas atuam focando o uso das categorias de ENs, torna- se interessante desenvolver sistemas que atendam aos objetivos dessas avaliações e, com isso, tentar atingir melhores resultados em relação a a língua portuguesa.
Este capítulo irá descrever um conjunto de trabalhos relacionados compreendendo um estudo das features para a resolução de correferência.
Um conjunto de features que seja significativo para a tarefa de resolução, com base nos resultados dos trabalhos estudados, é identificado.
O trabalho de Soon Trata da tarefa de resolução de correferência abordando os vários tipos de sintagmas nominais.
Cabe destacar que esse trabalho trata da tarefa em textos de qualquer domínio em língua inglesa.
Essa foi a primeira proposta que uniu os conceitos de aprendizado de máquina e processamento de corpus.
Essa abordagem necessita de um corpus anotado com informações das cadeias de correferência dos sintagmas nominais.
Essas informações são usadas no processo de aprendizado para a tarefa de resolução de correferência, definida por o MUC-63 e MUC-7.
Uma diferença da proposta dos autores está em identificar todas as entidades e não apenas as que são estabelecidas por o MUC-6 e O processo de resolução ocorre através do aprendizado com base em features para classificar um par de termos como anafórico ou não.
Os autores usaram 12 features, que são:
Alias -- um termo é sigla do outro;
I_ Pronoun -- se o antecedente é pronome;
J_ Pronoun -- se a anáfora é pronome;
Def_ NP -- se a anáfora começa por o artigo the;
Dem_ NP -- se a anáfora começa por this, that, these ou those;
Str_ Match -- ambos os termos possuem a mesma grafia;
Number -- ambos os termos são numerais;
Conferência substituída por o ACE.
Gender -- ambos os termos possuem o mesmo gênero;
Proper_ Name -- se os termos são nomes próprios;
Appositive -- se a anáfora é aposto do antecedente;
Dist -- número de frases que separam os termos;
SemClass -- se os termos possuem a mesma categoria semântica.
Essa informação é extraída da WordNet.
Para quase todas as features são considerados os valores &quot;verdadeiro «ou &quot;falso», sendo que a feature 12 apresenta, além desses valores, o valor &quot;desconhecido», caso não identifique uma categoria semântica de entre as definidas.
Outra feature que traz um valor diferente é a 11, sendo atribuído um valor numérico, já que se trata da distância entre a anáfora e o antecedente.
Um dos experimentos realizados foi de verificar a cobertura, precisão e medida-F de cada feature separadamente.
Como resultado, os autores constataram que apenas as features &quot;STR «Match», &quot;Alias «e &quot;Appositive «tiveram um valor de retorno diferente de zero.
De acordo com os autores, esse resultado demonstra que as features são importantes para a tarefa, pois isoladamente apresentam retorno na classificação dos pares.
Por esse ser o primeiro trabalho com features, ele é comumente considerado o baseline na área de PLN para a resolução de correferência.
Outro trabalho que descreve uma solução para a resolução de correferência em língua inglesa baseada em aprendizado de máquina é o de Strube e Ponzetto.
Essa proposta baseia- se em Soon, contudo, faz o uso mais elaborado de bases de conhecimento externas, sendo estas a Wikipédia4 e a WordNet.
A utilização de bases de conhecimento na resolução de correferência permite a busca de informação semântica, a qual auxilia no processo de desambiguação de entidades nomeadas.
Por exemplo, um texto apresenta a entidade Bento Gonçalves.
Como identificar se a entidade está se referindo à cidade Bento Gonçalves do Rio Grande do Sul, à Avenida de Porto Alegre ou ao personagem que fez parte da Revolução Farroupilha?
Poderia- se- resolver a questão com a ajuda da identificação de palavras próximas à entidade em conjunto com consultas a bases de conhecimento.
Para essa tarefa, são extraídos pares de termos (representados por ERi e ERj), os quais passarão por um processo de análise para determinar se são relacionados ou não.
Esse processo de análise contempla as seguintes features, além de as 12 features apresentadas em Soon:
I_ Semrole -- o papel semântico (informação fornecida por o parser Assert) do antecedente (ERi);
J_ Semrole -- o papel semântico (informação fornecida por o parser Assert) da anáfora (ERj);
WN_ Similarity_ Best -- a maior pontuação de similaridade entre todos os synsets dos pares (baseada na taxonomia da WordNet ­ tamanho do caminho percorrido na taxonomia);
WN_ Similarity_ Avg -- a média da pontuação de similaridade;
I/ J_ Gloss_ Contains -- atribui- se o valor indefinido se não há páginas da Wikipédia intituladas com ERi/ j, verdadeiro se ERi estiver presente no título e ERj no primeiro parágrafo do texto (e vice-versa), caso contrário, falso;
I/ J_ Related_ Contains -- atribui- se o valor indefinido se não há páginas da Wikipédia intituladas com ERi/ j, verdadeiro se ERi estiver presente no título e ERj presente em pelo menos um hyperlink (e vice-versa), senão, falso;
I/ J_ Categories_ Contains -- atribui- se o valor indefinido se não há páginas da Wikipédia intituladas com ERi/ j, verdadeiro se ERi estiver presente no título e ERj na lista de categorias da página de ERj (e vice-versa), senão, falso;
Gloss_ Overlap -- a média (medida de similaridade) entre o primeiro parágrafo do texto da página de ERi/ j, calculada por a equação:
&quot;tanh «representa a função tangente hiperbólica, utilizada para minimizar os outliers (valores discrepantes).
Wiki_ Relatedness_ Best -- a pontuação mais alta do relacionamento de CERi e CERj (onde C é o conjunto de categorias extraídas a partir de as páginas de ERi/ j).
Essa pontuação é calculada a partir de o caminho percorrido no gráfico de categorias da Wikipédia;
Wiki_ Relatedness_ Avg -- a média dessa pontuação.
As features 3 e 4 são referentes à WordNet, enquanto que as features 5, 6, 7, 8, 9 e 10 à Wikipédia.
Para determinar a página da Wikipédia que será usada para a definição das features, o autor fez uso de um algoritmo que recupera páginas da Wikipédia e as desambigua semanticamente.
Para isso, é realizada uma consulta através dos termos, retornando todos os redirecionamentos (por exemplo, a palavra carro redireciona para automóvel).
Através do mesmo algoritmo, resolve- se a ambiguidade das páginas, retornando a página que representará cada termo.
Com o objetivo de comparar as features do trabalho de Soon E as que se referem ao uso de base de conhecimento, os autores realizaram um experimento processando o corpus disponibilizado por o ACE do ano de 2003 utilizando apenas as features de Soon E, depois, com o conjunto todo de features, isto é, incluindo as features relacionadas com a Wikipédia e a WordNet.
Os resultados obtidos demonstraram que o uso de base de conhecimento (informação semântica) proporciona melhores resultados à tarefa de resolução de correferência.
Os valores são detalhados na Tabela 2.
Em Souza[ SOU08], o sistema ACROPOS é apresentado com objetivo de automatizar a resolução de correferência para a língua portuguesa.
O sistema seleciona as cadeias de correferência de um texto através do aprendizado dos pares de expressões anafóricas.
Esse é o único trabalho que trata da resolução de sintagmas nominais para a língua portuguesa.
Há outros trabalhos que tratam apenas da resolução de pronomes, tais como, e.
Esse sistema não observa as diferentes categorias referenciais, observadas no reconhecimento de entidades nomeadas.
Os pares de sintagmas são gerados de acordo com a metodologia apresentada em, a qual faz a associação entre os sintagmas da cadeia da seguinte forma:
SN1 SN2, SN2-SN3, SN3-SN4 para os pares positivos.
Isto é, o primeiro sintagma da cadeia forma par com o segundo, o segundo com o terceiro e assim sucessivamente.
E para os pares negativos, o segundo sintagma da cadeia (SN2) faz par com todos os sintagmas existentes entre ele e o primeiro sintagma.
Também de acordo com a proposta de Soon, o autor fez uso de features, sendo que algumas foram adaptadas para atender às características do corpus disponível.
Abaixo estão listadas as features definidas para a tarefa:
Cores--Match -- comparação dos núcleos do par de sintagmas;
Distance -- distância em número de frases entre os dois sintagmas;
Antecedent-is-pronoun -- verificação se o antecedente é pronome;
Anaphora-is-pronoun -- se a anáfora for um pronome receberá o valor verdadeiro;
Both-proper-names -- se os sintagmas são nomes próprios;
Gender-agreement -- concordância de gênero;
Number-agreement -- concordância de número;
Both-subject -- se os sintagmas são sujeitos;
Semantic-agreement -- concordância semântica (se possuem etiquetas semânticas idênticas);
Same-semantic- -- mesmo grupo semântico (caso possuam etiquetas semânticas que pertençam ao mesmo grupo).
Em a feature 10, o autor selecionou as etiquetas de mesmo grupo de acordo com a definição de, criador do analisador sintático, o qual será detalhado no Capítulo 4.
A partir desse retorno, nota- se que as features &quot;cores-match», &quot;same-semanticgroup», &quot;both-subject», &quot;gender-agreement «e &quot;distance «foram as que apresentaram maior relevância, já que o algoritmo de aprendizado as utilizou para gerar a árvore de decisão.
Ng e Cardie propuseram um conjunto de 37 features, classificadas de acordo com 4 grupos:
Lexical, gramatical, semântico e posicional.
Por exemplo, a feature &quot;strings iguais «é classificada como lexical, enquanto a feature &quot;aposto «como gramatical.
Essas novas features estão listadas no Anexo A (serão listadas apenas as que diferem do baseline).
De acordo com os resultados, as features que apresentaram maior importância para identificar se um par é anafórico ou não foram as features &quot;alias «e a &quot;mesmo núcleo».
Essas mesmas features também foram destacadas no trabalho de Soon Outro trabalho de Ng apresenta uma lista menor de features do que aquela proposta por o autor anteriormente, trazendo uma classificação também diferente.
Em este trabalho a classificação está dividida da seguinte forma:
Features que descrevem o candidato a antecedente, features que descrevem o pronome e features que descrevem o relacionamento entre eles.
Por intermédio desse conjunto de features, o autor quer realizar a tarefa apenas para a resolução de pronomes.
Em outra proposta que se refere à resolução de correferência, Ng faz uso de sete tipos de features para determinar a classe semântica.
Para realizar a identificação da classe semântica, busca a informação na WordNet, relacionando os nomes das classes definidas por o ACE com as existentes na WordNet.
Para a extração de informação gramatical fez utilização do parser Minipar.
As features são as seguintes:
Word -- para cada palavra de um Sn é criado a feature Word, menos para as stopwords;
Subj_ verb -- se um determinado Sn está envolvido com a relação de verbo subordinado, é criada então a feature;
Verb_ obj -- se um Sn possui a relação de objeto com um verbo;
EN -- faz uso do BBN's IdentiFinder (sistema que determina o tipo de um EN de acordo com as regras do MUC) para o reconhecimento de EN.
Associar o tipo de EN segue as regras do ACE;
Wn_ Class -- para cada keyword (listadas na Tabela 3) da feature Word é determinado se um núcleo de um Sn é hipônimo da feature Word na WordNet.
Induced_ class -- Com o uso do IdentiFinder, coloca- se como rótulo o tipo de EN em cada EN e com o Minipar (que é o analisador sintático) extrai- se as informações de aposto.
O autor faz o cálculo da probabilidade de substantivos comuns que co-ocorrerem com cada tipo de EN baseado no aposto, e se essa probabilidade for maior que 0,7, então, atribui- se a essa feature o valor do tipo de EN.
Neighbor -- com base na pesquisa na área de semântica lexical, que diz que há uma similaridade na distribuição dos SNs, criou- se essa feature, que para cada Sn são escolhidos dez SNs vizinhos e similares semanticamente.
Essa similaridade semântica é provida de um tesauro desenvolvido por Lin's A Tabela 3 apresenta a relação entre as categorias do ACE com as keywords da WordNet.
Essas keywords foram escolhidas através dos experimentos realizados por o autor na base de treino levando em consideração a WordNet e as classes semânticas do ACE.
O trabalho de Ng é a primeira proposta a considerar categorias de ENs de acordo com os conceitos estabelecidos por uma avaliação conjunta.
Em outro trabalho, o autor desenvolveu uma medida para determinar se um termo é anafórico, ou seja, ajudar a definir se um par é anafórico ou não.
O autor fez uso das 37 features do seu trabalho para o processo de classificação do par.
O método de geração dos pares segue a proposta de Soon, tanto para os positivos quanto para os negativos.
A proposta é gerar pares de exemplos certos e errados e, depois do processo de aprendizado, classificar se um par é correferente ou não.
Em esse trabalho, o autor utilizou- se do corpus do ACE como base de dados.
Para método de comparação, o autor fez uso de dois trabalhos seus anteriores, como também de outros autores que atuaram na mesma área com relação a sua proposta de uso da medida de probabilidade da anáfora.
De acordo com o autor, a medida-F de seu sistema proposto foi maior do que todos os outros sistemas utilizados para comparação.
Nota- se que os trabalhos para o inglês são mais elaborados em comparação aos trabalhos que tratam do português.
Um dos motivos é o fato de atualmente existir mais recursos disponíveis para o inglês do que para o português.
Um exemplo disso seria a WordNet.
Os resultados dos experimentos de Strube e Ponzetto mostram que o percentual de acerto usando as features para a WordNet é superior em relação a o experimento sem as mesmas.
Em relação a a evolução das features percebe- se que as primeiras focavam- se no processamento morfológico.
À medida que a informação semântica através do acesso a bases de conhecimento passou a ser utilizada, novas features foram criadas com o uso desse conhecimento.
Considerando os resultados alcançados nos trabalhos, é possível constatar que aqueles que englobaram as features propostas com o uso de base de conhecimento conseguiram obter resultados melhores.
No que diz respeito à informação semântica, é preciso analisar quais features são possíveis de implementar de acordo com os recursos disponíveis para a língua portuguesa, pois, por exemplo, não há uma base de informação como a WordNet que esteja bem definida para o português.
Um recurso semântico prático que poderia ser utilizado são as informações semânticas fornecidas por a análise do analisador sintático Palavras, descrito em detalhes no Capítulo 4.
Com base nos estudos anteriores e nas possibilidades práticas de implementação, identificou- se as seguintes features a serem implementadas, detalhadas no Capítulo 5: Este capítulo irá apresentar os recursos que foram escolhidos para a realização deste trabalho.
A escolha ocorreu considerando a disponibilidade dos mesmos para a língua portuguesa.
O analisador sintático Palavras possui o objetivo de processar textos da língua portuguesa, realizando as análises morfossintáticas e semânticas.
Foi desenvolvido por Bick, como tese de seu doutorado.
Sua saída é um único arquivo com todas as informações do processamento.
Essa ferramenta participou da avaliação conjunta HAREM, obtendo índices bons em sua avaliação.
Para a tarefa de identificação, o analisador alcançou os melhores resultados entre os participantes, enquanto para a tarefa de marcação semântica, conseguiu os melhores resultados em 2 dos 4 cenários (cenários podem ser descritos como conjuntos de parâmetros pré-definidos para realização dos testes) disponibilizados por a avaliação (63% para os dois cenários).
Para ambas as tarefas foram considerados os resultados da medida-F.
Uma das etapas do analisador é a identificação das ENs e sua classificação de acordo com premissas definidas por o autor.
Para isso, ocorre a associação de cada entidade identificada com etiquetas semânticas.
Será apresentado a seguir como o autor realizou a marcação semântica no que diz respeito à desambiguação, já que essa informação é relevante para a tarefa de resolução de correferência.
O autor definiu uma lista com várias etiquetas para realizar as marcações, tanto para informações morfossintáticas como semânticas.
A lista com o conjunto completo de etiquetas utilizadas é encontrada em.
Em o total 157 etiquetas semânticas foram definidas, classificadas de acordo com um conjunto de características definidas por o autor.
A seguir, na Tabela 4, um exemplo de conjunto de etiquetas semânticas e as características atribuídas para a representação de seres humanos.
O analisador realiza o processo de desambiguação criando uma árvore de derivação.
Cada final de caminho da árvore equivale a uma classe, sendo denominada por o autor como protótipo.
Em o exemplo da Tabela 4, o protótipo definido é o de humanos.
Um protótipo é um conjunto de etiquetas semânticas que determinam uma classe.
Por exemplo, para definir se uma classe pertence ao protótipo animal precisa apresentar as seguintes características:
É concreto, animado, não-humano e se move.
Por intermédio dos protótipos, o autor determina a possível classe de uma palavra.
Mesmo não fazendo uso de bases de conhecimento, como dicionários, o autor conseguiu estabelecer um conjunto de características de forma a criar, indiretamente, o conhecimento de mundo, auxiliando- o no processo de desambiguação.
Depois de determinado o protótipo, é necessário realizar a desambiguação entre as possíveis etiquetas do conjunto.
Para isso, o autor faz uso de uma gramática de restrições criada por ele, de forma a atender as peculiaridades da língua portuguesa.
Para realizar essa tarefa de desambiguação, faz- se necessário verificar o retorno da análise da palavra vizinha.
Por exemplo, o verbo correr com a característica de movimento necessita de um complemento que também apresente a mesma característica, ou seja, de movimento Tendo em vista que a ferramenta participou do HAREM, o autor estabeleceu uma associação entre algumas das etiquetas retornadas por o analisador com as categorias definidas por a avaliação conjunta.
Nota- se que para realizar a associação, um conjunto de características, que expressa uma relação entre as marcações, é considerado.
Esse processo de associação ocorre para todas as categorias estabelecidas na avaliação conjunta.
Assim, pode- se inferir que as categorias de ENs representam um conhecimento de mundo.
O Summ-it é um corpus de textos em língua portuguesa com anotações linguísticas.
Esse recurso é muito importante para essa área de estudos, por proporcionar uma base de conhecimento rica em informações linguísticas relacionadas ao discurso.
O corpus é composto por cinquenta textos jornalísticos do caderno de Ciências da Folha de São Paulo retirados do corpus PLN-BR5.
Os textos foram anotados com informação sintática, de correferência e de estrutura retórica.
O Summ-it também conta com sumários construídos de forma manual e automática.
O analisador sintático utilizado para processar o corpus foi o Palavras.
Com o intuito de melhorar a visualização das informações extraídas do analisador, o arquivo gerado foi dividido em três outros arquivos.
Um arquivo com as informações dos tokens, composto por o token e seu respectivo Id;
Outro com as informações dos sintagmas, isto é, qual o Id do token inicial e final do sintagma e outro com as informações sintáticassemânticas associadas ao Id do token.
Os arquivos estão em formato XML.
A escolha por a extensão XML deu- se devido a este ser um formato padrão.
A nomenclatura adotada para identificar os arquivos foi:
Título_ de o_ textotipo_ arquivo.
Xml, aonde tipo_ arquivo é definido da seguinte forma:
Tokens para tokens, phrases para estruturas sintagmáticas e pos para sintático-semântico.
Sendo assim, para cada texto são encontrados três arquivos oriundos do analisador e mais um arquivo, o de markables, com as informações dos sintagmas nominais do texto.
O arquivo de markables foi criado manualmente, anotado através da ferramenta MMAX.
De os 5047 markables (sintagmas nominais anotados), a maior parte corresponde a sintagmas nominais com nome núcleo.
Já os pronomes representam apenas Projeto destinado ao desenvolvimento de recursos e ferramentas para a recuperação de Cabe destacar que a anotação do corpus não levou em consideração a identificação das categorias de ENs.
Como os sistemas de resolução de correferência são avaliados nos contextos de conferências, como ACE e HAREM, observa- se a importância de uma análise de corpus em relação a essas categorias.
Além disso, as categorias podem servir como uma estrutura inicial para definição de características semânticas que podem auxiliar o processo de resolução automática de correferência.
Com base no retorno do analisador Palavras e da relação das etiquetas semânticas do mesmo com as categorias da avaliação conjunta, realizou- se uma análise das cadeias do corpus, em que se constatou que do total das 589 cadeias, há 84 cadeias da categoria Pessoa, por exemplo.
O Apêndice A apresenta a quantidade de cadeias por texto do corpus.
Em a Tabela 6 pode- se verificar o total de cadeias por categoria do corpus.
É compreensível que a categoria Outro apresente um valor maior que das demais categorias, pois o corpus é composto por o caderno de ciências, abordando assuntos relacionados a animais.
Acrescenta- se, também, que o conjunto de etiquetas que Bick associou para cada categoria do HAREM é menor que o total retornado no processamento do analisador.
Por isso, foi atribuído para a categoria Outro um grupo muito heterogêneo de etiquetas semânticas.
Abaixo (Figura 6 e 7) são apresentados exemplos de cadeias do corpus Summ-it..
Uma pele biônica pele\&gt; an a pele-robô futura pele-robô\&gt; ac anbo a tecnologia\&gt; domain Legenda:
Mattson e colegas\&gt; Hfam a equipe\&gt; HH os cientistas\&gt; Hprof Legenda:
Através desses exemplos é possível constatar que a marcação semântica da categoria Pessoa apresenta uma semelhança (começam por a letra H), o que automaticamente possibilita sua comparação.
Já a categoria Outro não apresenta essa semelhança, o que a torna mais complexa de se resolver de forma automática.
Cabe salientar, também, que as categorias apresentam um conjunto de características mais definido em relação a a categoria Outro.
China\&gt; civ Legenda:
Já a Figura 9 apresenta um exemplo em o qual a entidade a China teve sua marcação semântica atribuída à categoria Organização (org) e, depois, para a anáfora com mesmo núcleo, foi atribuída uma etiqueta de outra categoria (categoria Local -- civ).
Uma possível explicação pode estar relacionada à vacuidade semântica para a entidade China.
O Weka6 é uma coleção de algoritmos de aprendizado de máquina para tarefas de mineração de dados.
Possui recursos de pré-processamento, classificação, agrupamento, visualização, entre outros.
Sua implementação é em linguagem Java, que tem como principal característica ser portável.
Por isso, o Weka pode ser executado nas mais variadas plataformas, aproveitando os benefícios de uma linguagem orientada a objetos como modularidade, polimorfismo, encapsulamento, reutilização de código, de entre outros.
Além disso, é um software de domínio público.
O método de aprendizado de máquina consiste em aprender através de exemplos, de os quais características diferenciam exemplos de determinadas classes.
Para isso, como dados de entrada, é necessário fornecer características que representam os exemplos.
Essas características são conhecidas na área como features.
O Weka possui um formato próprio de arquivo, o ARFF.
Antes de aplicar os dados a qualquer algoritmo do pacote Weka, estes devem ser convertidos para o formato, que é composto por basicamente duas partes.
A primeira contém uma lista de todos os atributos, onde se deve definir o tipo do atributo ou os valores que ele pode representar, vírgulas.
A segunda parte consiste das instâncias, ou seja, os registros a serem minerados com o valor dos atributos para cada instância, separados por vírgula.
A ausência de um item num registro deve ser atribuída por o símbolo&quot;?».
São vários os métodos implementados no Weka.
Para este trabalho, será utilizado o algoritmo J48, o qual retorna uma árvore de decisão com as features relevantes que foram identificadas por meio de a análise dos exemplos.
A árvore de decisão é muito utilizada para a inferência indutiva.
É um método de aproximação de função de valor distinto, sendo suas funções de aprendizado representadas por uma árvore, a árvore de decisão.
A construção da árvore é top-down, ou seja, do nodo raiz para os ramos.
Primeiro, verifica- se qual de entre os atributos será o nodo raiz.
A escolha é de acordo com o valor de entropia.
Entropia é a medida da impureza da coleção dos exemplos de treino.
Através dessa medida é possível medir a eficácia dos atributos na classificação da base de treino.
Assim, quanto menor a entropia mais significativo é o atributo, então, mais ao topo da árvore ele será colocado.
Os outros nodos da árvore também são escolhidos de acordo com seu valor de entropia, sendo primeiro montado o ramo da árvore do lado esquerdo e depois do lado direito.
Esses valores são calculados de acordo com os testes dos atributos na base de treino.
Os atributos mais utilizados nos testes são escolhidos para compor a árvore.
Pode ocorrer que alguns atributos fiquem de fora de a árvore por o fato de não apresentarem uma significância nos testes, isto é, não foram utilizados de forma a ajudar na resolução do problema.
Já o método escolhido para avaliar a árvore de decisão foi a validação cruzada.
Essa abordagem faz uso de pedaços do pacote de treino para treinar e de um outro para testar (conhecidos como k--folds).
Por exemplo, se a validação cruzada for configurada para dez, significa que as instâncias de treino serão quebradas em dez partes, agrupando- se em pacotes.
Em um pacote de dez instâncias, nove são usadas para treino e uma para teste, dentro de o processo de treino.
De o total de pacotes obtidos por a divisão, 1 é selecionado para teste e o restante para treino.
Por exemplo, num arquivo de 1000 instâncias, têm- se 100 pacotes com dez instâncias cada, sendo que 99 pacotes serão utilizados para treino e 1 pacote para teste.
Essas informações de testes são usadas para medir o erro da validação.
Os recursos utilizados neste trabalho foram escolhidos de acordo com sua disponibilidade para o português.
Por isso, apesar de compreender que o corpus é de tamanho pequeno, é o que há de disponível com as informações necessárias, principalmente a marcação manual das cadeias de correferência para a composição das características dos exemplos e, também, para permitir a avaliação posterior do sistema.
O uso de aprendizado de máquina foi escolhido por ser o que é utilizado em outros trabalhos da área, como Soon, Strube e Ponzetto e Ng e Cardie Cabe destacar que este trabalho não fez nenhum tipo de correção da marcação do analisador.
Essa postura foi adotada pois a intenção é trabalhar com os dados extraídos de forma automática através dos recursos que se possui para a tarefa.
Assim como a classificação, a identificação das entidades nomeadas realizada por o analisador também não é corrigida ou revisada, manual ou automaticamente.
Para realizar a tarefa de resolução de correferência, um protótipo foi desenvolvido em duas versões.
Uma, que será o baseline do trabalho, e outra, que fará uso das categorias de ENs.
Para a segunda versão será dado o nome de Recorcaten, que significa &quot;REsolução de CORrefência por CATegorias de ENs».
A primeira etapa do trabalho foi levantar os requisitos do protótipo e modelar- lo de forma a possibilitar sua reutilização.
A entrada do protótipo é o corpus Summ-it processado por o analisador Palavras.
Após sua execução, é gerado o arquivo ARFF, que será a entrada para o Weka, finalizando o ciclo de execuções.
A seguir serão descritas as características específicas tanto do baseline como do Recorcaten.
A primeira fase de implementação tem a função de gerar os pares de sintagmas sem considerar as categorias de ENs.
A linguagem escolhida para a implementação foi a Java, já que é a linguagem utilizada por o grupo de pesquisa para o desenvolvimento de outras aplicações, bem como por ser uma linguagem disponível para uso e desenvolvimento de forma gratuita.
O protótipo foi modelado de modo a possibilitar a reutilização de parte de suas funções, por isso, decidiu- se segmentar- lo num conjunto de classes.
Assim, foi criada uma classe para a leitura dos arquivos do corpus, empregando a API JDOM7 para a leitura da extensão XML, uma para a geração dos pares, uma classe específica para cada feature, e outra para gerar o arquivo TXT.
Foi utilizada a API Weka8 para gerar o arquivo ARFF.
Essa divisão possibilita a inclusão de uma nova feature ou uma exclusão a qualquer momento, já que o processo de invocação das classes ocorre no programa principal.
Como apresentado no Capítulo 4, o corpus é composto por um conjunto de arquivos.
O processamento do sistema necessita buscar dados em todos os arquivos, pois cada um possui uma informação específica necessária para obter as informações comparativas das features.
A seguir será detalhada a função de cada arquivo do corpus para o sistema.
O arquivo de markables é composto por informações de todos os sintagmas nominais do texto.
Uma informação importante é o conjunto de sintagmas que fazem parte das cadeias de correferência, pois o processamento do sistema é dependente de ela.
O elemento member do arquivo diz a qual cadeia o sintagma pertence.
Com essa informação é possível determinar os sintagmas que farão parte dos pares positivos e negativos posteriormente, pois se agrupam os sintagmas que pertencem ao mesmo valor de member.
Esse é o primeiro arquivo processado por o sistema.
A Figura 12 mostra um exemplo do arquivo markables.
Esta está inserida juntamente com o pacote de instalação do Weka.
A geração dos pares dará- se- da seguinte forma:
Os pares positivos serão gerados a partir de os sintagmas pertencentes à mesma cadeia, tendo como base a proposta de Strube e Ponzetto, o qual coloca que todos os elementos de uma cadeia farão par com todos.
A cadeia formada por SN1, SN2, SN3 e SN4, por exemplo, formará os seguintes pares positivos:
SN1-SN2, SN1-SN3, SN1-SN4, SN2-SN3, SN2-SN4, SN3-SN4 (cada Sn representa um sintagma da cadeia).
Em o exemplo da Figura 13, o sintagma ele e seus colegas fará par com Mattson e colegas, a equipe e os cientistas.
Decidiu- se utilizar a proposta de Strube e Ponzetto nos pares positivos, pois esta proporciona um conjunto maior de exemplos positivos se comparada com a de Soon, a qual é implementada no trabalho de Souza.
Já os pares negativos serão agrupados de acordo com a proposta de Soon, onde o segundo membro faz par com os sintagmas existentes entre ele e o primeiro membro da cadeia, sendo representado por SN1 e SN2, respectivamente.
Por exemplo, cada sintagma entre SN1 e SN2 é representado por uma letra do alfabeto (a, b, pode ser observado na Figura 14, que ilustra um recorte do conjunto de sintagmas entre os dois elementos da cadeia.
Assim, o sintagma Mattson e colegas formará par negativo com Mattson, a morte e os doentes.
O segundo arquivo a ser processado é o arquivo de phrases, composto por as informações dos tokens que compõem as estruturas sintagmáticas e o seu núcleo.
Em esse arquivo há uma marcação ­ markable_ ref ­ que associa a estrutura ao sintagma dos markables.
Essa marcação foi realizada apenas para os sintagmas pertencentes às cadeias de correferência.
Assim, os demais sintagmas não foram associados.
Através dessa marcação consegue- se obter o núcleo do sintagma.
É através do núcleo que as comparações dos pares serão realizadas.
Cabe destacar que essa marcação será utilizada para a geração dos pares positivos.
Para os pares negativos será utilizada a informação da marcação from, obtida no arquivo de markables, como forma de obter a informação do núcleo.
A escolha dessa associação se fez necessária pois nem todos os sintagmas pertencentes aos pares negativos possuem a marcação markable_ ref..
Optou- se em utilizar apenas a informação do from, pois nem sempre os valores do from- to do arquivo de markables correspondem aos do arquivo de phrases.
Isso ocorre porque o arquivo de markables foi marcado manualmente enquanto a marcação do phrases foi feita automaticamente e sem revisão.
O número de pares negativos acaba sendo maior que o de pares positivos.
Como forma de equalizar os exemplos, os pares positivos serão repetidos até alcançarem o valor aproximado do total de exemplos negativos.
Esse procedimento é necessário para não ocasionar um aprendizado tendencioso por o algoritmo de aprendizado na classificação das features para a criação da árvore de decisão, já que o algoritmo gera a árvore de acordo com a significância de cada feature.
As informações sintáticas e semânticas são encontradas no arquivo de pos.
Ou seja, nesse arquivo busca- se as informações referentes ao gênero, número e marcação semântica retornadas por o analisador sintático.
De acordo com a Figura 16, o valor de gênero é obtido na etiqueta gender, o de número na etiqueta number e a informação semântica nas etiquetas semantic ou complement.
Por intermédio da marcação tokenref é que será identificado o núcleo do sintagma, obtido no arquivo de phrases anteriormente explicado.
A seguir são listadas as features que foram implementadas no baseline:
MNucleo_ Semantico -- se os núcleos do par são da mesma marcação semântica;
MGenero -- se os núcleos do par apresentam o mesmo gênero (masculino/ feminino);
MNumero ­ se os núcleos do par apresentam o mesmo número (singular/ plural);
MNucleo -- se os núcleos são idênticos;
MConj_ Semantico -- se os núcleos do par pertencem ao mesmo conjunto de marcação semântica.
Os valores atribuídos a todas as features foram definidos em true quando verdadeiro e false quando falso.
As features &quot;MNucleo», &quot;MGenero «e &quot;MNumero «são classificadas em nível gramatical e apresentam um papel importante na tarefa, pois estão diretamente associadas com a relação da anáfora com o antecedente.
Já as features &quot;MNucleo_ Semantico «e &quot;MConj_ Semantico «introduzem o conhecimento semântico na tarefa de resolução de correferência.
Para finalizar, o arquivo de tokens é utilizado para comparação do núcleo do sintagma, localizado através da marcação Id, a qual possui armazenado o valor de token, que é a informação associada nos outros arquivos.
O sistema realiza a leitura dos arquivos do corpus acima listados.
Primeiramente, faz- se a classificação dos pares positivos e negativos, armazenando como referência a identificação do markable e do valor da marcação do from.
Em sequência, faz- se a busca no arquivo de phrases para descobrir o núcleo do sintagma.
Com essa informação, busca- se o valor do token no arquivo de tokens e no arquivo de phrases os valores de gênero, número e etiqueta semântica.
Após, é realizado o processo de teste das features, armazenando o markable de referência e o valor de retorno das features.
Com as informações armazenadas, é gerado um arquivo no formato TXT para ser a base de entrada para a classe que gera o arquivo ARFF, sendo este o arquivo de entrada do Weka, como já mencionado no Capítulo 4.
A Figura 18 ilustra um exemplo do arquivo TXT criado para os pares positivos.
É indispensável definir corretamente as informações das colunas, pois a API para gerar o arquivo ARFF irá realizar a conversão do arquivo de acordo com as informações repassadas, sendo definidas por a identificação das colunas.
A Figura 19 apresenta uma visão detalhada do processo do protótipo, ilustrando o que foi descrito neste capítulo.
Essa versão do protótipo considera as categorias de ENs na escolha das cadeias.
Assim, os pares gerados, tanto positivos quanto negativos, serão apenas daquelas cadeias pré-definidas através da seleção das categorias.
Para realizar a seleção das cadeias de acordo com as categorias, fez- se necessário alterar a classe que gera os pares para que considerasse a informação das categorias.
Primeiro, identifica- se qual é a categoria da cadeia.
Caso a mesma pertença à categoria definida (o Capítulo 6 irá apresentar detalhadamente as definições das categorias para o conjunto de experimentos), os pares de sintagmas da cadeia serão agrupados.
O método utilizado para agrupar os pares é o mesmo do baseline, ou seja, os pares positivos serão gerados entre todos os membros de uma cadeia, enquanto que para os pares negativos o segundo sintagma da cadeia formará par com todos os sintagmas existentes entre ele e o primeiro sintagma da cadeia.
O arquivo TXT de saída do sistema continua no mesmo formato do baseline, com as mesmas features já citadas.
Este arquivo será a entrada para a Java API Weka criar o arquivo ARFF.
Apesar de demorada, a tarefa de levantamento de requisitos e modelagem do protótipo foi fundamental para que possibilitasse grande parte de reutilização das classes entre a primeira versão e a segunda.
A diferença entre o baseline e o Recorcaten refere- se ao processo de escolha das cadeias que serão utilizadas para gerar os pares, tanto os positivos como negativos.
Essa modificação é responsável por a inclusão do conhecimento de mundo na tarefa de resolução de correferência.
Assim, o baseline compreende todas as cadeias disponíveis no corpus, enquanto que o Recorcaten faz uso apenas das cadeias associadas às categorias específicas.
Para escolha do conjunto de features considerou- se o retorno do algoritmo J48 do trabalho de Souza e as colocações dos trabalhos de Soon, Strube e Ponzetto e Ng e Cardie.
Optou- se por um conjunto pequeno de features, mas que todas fossem importantes de forma a constarem na árvore de decisão, pois o intuito é realizar experimentos com determinadas categorias considerando sempre o mesmo conjunto de features.
A descrição desses experimentos será apresentada no capítulo a seguir.
Para realizar a avaliação dos resultados serão utilizadas as medidas de cobertura, precisão e medida-F. A medida-F é a média entre a cobertura e a precisão.
A escolha dessas medidas foi por serem as medidas utilizadas nos trabalhos da área.
A partir de o conjunto de 50 textos do corpus, foi utilizado um subconjunto composto por 31 textos dos 50, para a geração do arquivo de treino e o restante dos textos, 19, criou- se outro subconjunto para a geração do arquivo de teste.
Essas definições de conjuntos serão utilizadas tanto para o baseline como para o Recorcaten.
O primeiro experimento foi gerar, tanto o arquivo de treino como o de teste, a partir de o baseline.
O arquivo de treino foi composto por 6849 exemplos positivos (pares de sintagmas correferentespares de sintagmas não correferentes).
Esse treino serviu para induzir a árvore de decisão, a qual será utilizada para os testes futuros.
Percebe- se por a árvore gerada na Figura 20 que todas as features escolhidas foram utilizadas por o algoritmo de aprendizado de máquina, sendo que a feature &quot;MNucleo «é a raiz da árvore, o que significa ser a feature mais significativa, ou seja, a mais importante no processo de definir se um par é correferente ou não.
O arquivo de teste do baseline foi composto por um total de 1311 pares positivos e 1358 pares negativos, sendo que do total foram selecionados 540 corretos na classificação dos pares positivos e 771 dos pares negativos.
Esse arquivo foi processado com base na árvore de decisão ilustrada na Figura 20.
Seu retorno de acerto total foi de 53%.
A Tabela 7 mostra as informações dos percentuais das medidas de cobertura, precisão e medida-F, obtidos na classificação dos pares positivos e negativos.
O segundo experimento foi gerar um arquivo de teste com base na segunda versão do sistema, a Recorcaten.
Esta versão faz um filtro por categoria na geração dos pares, a qual foi aplicada ao subconjunto de teste.
A categoria escolhida nesse experimento foi a categoria Pessoa.
O arquivo teve um total de 196 pares positivos e 201 pares negativos.
O percentual de retorno foi de 69%.
Retomando, a base de treino é a mesma utilizada para o baseline, isto é, fez- se uso da árvore de decisão definida por o arquivo de treino do baseline.
A Tabela 8 apresenta os resultados.
Os próximos experimentos foram realizar os testes com as categorias Acontecimento, Local e Organização separadamente.
A escolha por essas categorias deu- se em consideração a quantidade de cadeias do corpus.
O Apêndice A lista a quantidade de cadeias por texto do corpus.
O critério de seleção das categorias foi considerar a quantidade total de cadeias por categoria do corpus.
Aquelas que apresentaram um valor maior que 20 cadeias foram selecionadas (não considerando a categoria Outro).
Notou- se que a categoria Local atingiu um percentual de 98% na classificação em geral, sendo que classificou todos os pares positivos corretamente.
Já as categorias Acontecimento e Organização alcançaram um percentual de 44%, não conseguindo classificar nenhum par correferente corretamente.
Comparando apenas o percentual da medida-F deste resultado com o obtido com o arquivo de teste do baseline, percebe- se que ocorreu um aumento de acerto.
A o analisar mais detalhadamente o retorno do Weka, percebe- se que a classificação correta dos pares correferentes foi maior na versão do sistema Recorcaten do que do baseline.
O sistema Recorcaten acertou 119 do total, ou seja, o percentual de 65%, enquanto que o baseline classificou 540, isto é, 46%.
A partir desse resultado, infere- se que o uso das categorias ajudou na tarefa, já que contribuiu para aumentar o percentual de classificação correta dos pares correferentes.
Não obstante, também contribuiu para melhorar o acerto dos pares não correferentes, que passou de 48% no baseline para 71% no Recorcaten.
A o observar as Tabelas, nota- se que tanto a medida de cobertura quanto a de precisão aumentaram, o que significa que ocorreu um aumento tanto na cobertura do corpus como na precisão de sua classificação e não apenas o aumento de uma única medida.
A Figura 23 mostra a saída de retorno do teste do baseline completa do Weka.
Essa figura apresenta a árvore de decisão, a matriz de confusão e todas as informações que a ferramenta retorna para o processo realizado de classificação.
Já a Figura 24 apresenta os resultados obtidos com a categoria Pessoa.
Ambas as Figuras encontramse no final deste capítulo.
As Figuras 25, 26 e 27 (apresentadas no final deste capítulo) mostram o resultado completo do retorno do Weka para as categorias Acontecimento, Local e Organização, respectivamente.
O fato de não haver ocorrido a classificação correta de nenhum par correferente está relacionado com a marcação do conjunto de etiquetas semânticas da cadeia.
Isto é, uma cadeia não apresenta o mesmo conjunto de etiquetas de uma categoria específica.
A o analisar a árvore, percebe- se que a etiqueta semântica é determinante para definir se um par é correferente ou não.
Observe o exemplo de uma cadeia na Figura 21.
A marcação para a cadeia da Figura 21 é da categoria Acontecimento, contudo, o outro sintagma possui marcação semântica de outra categoria (ac).
O par gerado nessa cadeia é correferente, no entanto, ao usar a árvore de decisão para classificálo, o mesmo seria considerado não correferente (não pertence ao mesmo conjunto semântico da categoria Acontecimento, o que induz a classificação de não correferente na árvore).
Em outro experimento, agrupou- se todas as categorias selecionadas para o trabalho (Pessoa, Acontecimento, Local e Organização) para gerar um único arquivo de teste.
Os resultados desse experimento foram de acerto na classificação correta dos pares de 70,25%, sendo que 64% foi para os pares correferentes.
A Tabela 12 mostra os resultados das medidas de cobertura, precisão e medida-F desse experimento.
Observando o percentual de retorno dos testes de todas as categorias com a categoria Pessoa, a diferença é pequena.
Nota- se que os pares positivos não obtiveram um ganho significativo de acerto, contudo, os pares negativos tiveram um percentual de 4% de aumento, o que acabou elevando a medida-F final do processo de classificação.
A o realizar uma revisão manual do retorno do protótipo de ambas as versões foi possível constatar alguns problemas, principalmente no que se refere ao processo de geração dos pares.
Um de eles é a constatação de que alguns sintagmas do corpus não possuem a marcação do núcleo e, por consequência, acaba- se descartando a geração de um par, assim como de uma cadeia, principalmente na versão Recorcaten, já que a seleção da cadeia ocorre através da categoria da mesma.
Esse problema ocasionou um impacto na quantidade dos pares considerando as categorias, tendo em vista que a quantidade de cadeias por categoria não possui um valor elevado, o que acabou gerando um conjunto pequeno de exemplos tanto para os pares positivos como para os negativos.
Como já mencionado anteriormente, a questão de uma cadeia possuir marcações de etiquetas de categorias diferentes proporcionou alterações no processo de classificação dos pares positivos.
Uma das alterações constatadas foi ao analisar a árvore de decisão, já que uma de suas ramificações, a feature &quot;MNucleo_ Semantico», se estiver com o valor true, irá informar que o par não é correferente.
De acordo com os resultados, observa- se que o uso de categorias proporcionou uma melhora no percentual de acerto ao definir se um par é anafórico ou não.
Com isso, pode- se inferir que o uso de conhecimento semântico na tarefa de resolução de correferência é relevante para o processo de resolução, retornando um maior número de acerto na classificação correta dos pares.
Através dos experimentos também foi possível constatar a importância do conhecimento de mundo para a tarefa.
Como visto, algumas categorias (Acontecimento e Organização) não apresentaram um retorno satisfatório na classificação dos pares correferentes porque o processo de desambiguação não foi realizado da forma correta.
Algumas marcações de etiquetas dessas categorias foram utilizadas para identificar outras categorias, como a de Pessoa.
A Figura 22 ilustra essa colocação.
Mesmo apresentando sintagmas com núcleos iguais (Nasa), o analisador sintático informou etiquetas semânticas de categorias diferentes (neste caso, da categoria Organização (org) e Pessoa (hum), respectivamente).
Nasa\&gt; org a agência espacial Americana agência\&gt; HH a Nasa Nasa\&gt; org a Nasa Nasa\&gt; hum a Nasa Nasa\&gt; org Legenda:
Assim, ressalta- se a necessidade de bases de conhecimento mais estruturadas e com sinônimos, como a WordNet, para complementar e apoiar a tarefa de resolução de correferência.
Apesar de ser uma tarefa importante para a área de PLN, ainda há muitas pesquisas a serem realizadas para a resolução de correferência, em especial, tratando da língua portuguesa.
Trabalhos recentes têm empregado cada vez mais recursos semânticos para alimentar os sistemas de resolução de correferência.
Porém, enquanto hoje estão disponíveis para a língua inglesa recursos que ajudam na tarefa, como a WordNet, a mesma disponibilidade não existe para o português.
Um recurso alternativo para inclusão de informação semântica para o português é através do uso do analisador Palavras e sua anotação semântica.
Em esta dissertação exploramos a anotação semântica e as categorias semânticas como uma informação adicional ao processo de resolução de correferência.
Como método de avaliação, optamos realizar experimentos com diferentes categorias semânticas.
Os resultados obtidos mostraram que o uso das categorias proporciona uma melhora no processo de classificação dos pares de expressões anafóricas.
Isso demonstra a importância do conhecimento de mundo para realizar a tarefa de resolução de correferência com resultados mais robustos.
A partir de a análise dos resultados, infere- se que o comportamento do analisador Palavras na etiquetação das categorias Pessoa e Local foi mais estável, atribuindo etiquetas semânticas mais coesas nessas categorias.
Já para as categorias Acontecimento e Organização, o mesmo não ocorreu.
Além de o conjunto de etiquetas ser mais diferenciado, o erro do analisador na classificação também ocorre e tem influência nos resultados.
Um exemplo disso é a atribuição da etiqueta &quot;hum «(Pessoa) para Nasa (Figura 22), que na verdade é uma Organização.
Verificando o contexto que a expressão se encontrava no texto, constatou- se que realmente a marcação da etiqueta &quot;hum «foi equivocada.
Como uma revisão na marcação semântica do corpus não foi realizada não há como mensurar o percentual total de marcações incorretas.
Contudo, num levantamento parcial, esses erros não são predominantes.
Pode- se considerar como contribuições deste trabalho:
Estudo da evolução das features referente a a tarefa de resolução de correferência;
Desenvolvimento de um protótipo para experimentação de resolução de correferência;
Realização de experimentos considerando a proposta deste trabalho (o uso das categorias);
Análise e discussão dos resultados;
Produção de um artigo no CelSul (Círculo de Estudos Linguísticos do Sul) intitulado &quot;A dificuldade da tarefa de resolução de correferência».
Um dos pontos limitadores encontrado é o tamanho do corpus utilizado nos experimentos deste trabalho.
A limitação de recursos para a língua portuguesa dificulta o avanço das pesquisas na área.
Outra consideração é a não revisão da anotação do analisador sintático Palavras no corpus escolhido.
Uma revisão com o levantamento do que há de marcação incorreta auxiliaria na análise dos resultados obtidos, principalmente em relação a o uso das categorias.
Com isso, uma avaliação mais precisa do sistema seria possível.
Após a realização deste trabalho identificou- se a possibilidade dos seguintes trabalhos futuros:
Realizar o processo de identificação das ENs através de palavras vizinhas e/ ou verbos, não se limitando ao analisador Palavras;
Acrescentar ao processo de resolução o uso de outros recursos, tais como dicionários e Wikipédia, por exemplo;
Inclusão de novas features a partir de a inserção dos novos recursos;
Adaptação do protótipo para realizar a tarefa para a língua inglesa.
