Este trabalho apresenta um estudo sobre as tarefas de interação contidas em sistemas de visualização de imagens médicas.
Baseado nesse estudo, o desenvolvimento de um dispositivo de interação para ambientes imersivos de visualização de imagens médicas é proposto.
Esse dispositivo agrega as vantagens do mapeamento direto das ações do usuário para interação num ambiente virtual com um método para entrada de valores numéricos através de um sensor multitouch.
Como resultado foi constatado que, apesar de os usuários gastarem mais tempo com as tarefas de entrada de valores no ambiente virtual, o dispositivo apresentou uma precisão similar à obtida num ambiente desktop.
A reconstrução tridimensional de modelos a partir de imagens obtidas através de exames radiológicos, como por exemplo, tomografia computadorizada ou ressonância magnética, vem cada vez sendo utilizada com mais freqüência por médicos como auxílio na detecção de patologias nos pacientes.
O recurso de reconstrução tridimensional dos órgãos do corpo humano, a partir de estas imagens, está presente em grande parte das ferramentas de visualização de dados médicos para ambientes desktop.
Esses ambientes também oferecem outros recursos para avaliação das imagens, tais como plano de corte, alteração de parâmetros da imagem, medições, etc..
O uso de Realidade Virtual (RV) para interação neste tipo de ambiente pode trazer alguns benefícios, como por exemplo, tornar mais intuitiva a manipulação do volume de dados tridimensional.
Apesar de já existirem alguns estudos sobre a implementação das tarefas suportadas por os ambientes de visualização de imagens médicas, tais como, maneiras de se controlar um plano de corte, métodos para se realizar medidas nos volumes, métodos de segmentação interativa, etc., essa utilização ainda é pouco explorada.
Uma das razões disto é o fato de que a utilização de interfaces puramente imersivas acarreta complicações para operações simples como, por exemplo, a entrada de dados textuais ou numéricos e a escolha de opções em menus.
Em estes casos a utilização de dispositivos convencionais, como mouse e teclado, para a entrada dos dados acarretaria perda da sensação de imersão por parte de o usuário.
Em este sentido, este trabalho desenvolveu um dispositivo de interação que tem o objetivo de permitir a manipulação de dados médicos em ambientes imersivos.
Foram abordadas tarefas interativas de perfil essencialmente tridimensional, como a manipulação do volume e do plano de corte, bem como tarefas de entrada de dados numéricos ou textuais com precisão.
A idéia central é possibilitar que o usuário, de posse do dispositivo desenvolvido, possa realizar as duas classes de tarefas de forma simples e sem a quebra da sensação de imersão no ambiente tridimensional, mesmo quando se estiver fazendo uma tarefa essencialmente bidimensional.
Para atingir este objetivo, foi desenvolvida uma ferramenta que unificou o controle das funcionalidades tridimensionais com as bidimensionais.
As tarefas tridimensionais, como a manipulação do volume, são executadas de maneira simples, uma vez que o dispositivo possui um rastreador de posição para este tipo de controle.
Para prover o suporte necessário para entrada de dados foi utilizada uma superfície sensível ao toque.
O capítulo seguinte apresenta um estudo sobre as principais tarefas interativas encontradas nos sistemas de visualização de dados médicos.
Os sistemas que desempenham as tarefas comuns à ambientes de visualização de imagens médicas fazendo uso de realidade virtual são apresentados no capítulo 3.
O capítulo 4 apresenta um levantamento das principais ferramentas de visualização de dados médicos existentes, seguido de um estudo comparativo sobre as funcionalidades destes ambientes.
Em o capítulo 5 é apresentado o desenvolvimento do dispositivo e no capítulo 6 uma avaliação do mesmo.
O texto finaliza com um capítulo de conclusões e possibilidade de trabalhos futuros.
Ambientes de visualização de imagens médicas tem como objetivo auxiliar médicos na tomada de decisões.
Para fornecer este suporte, estas ferramentas precisam desempenhar diferentes tarefas que permitam uma exploração mais clara dos dados.
Estas tarefas variam entre realizar modificações nas imagens, e aplicar imagem.
Em este capítulo é apresentada uma pequena introdução sobre imagens médicas e também são apresentadas algumas das tarefas utilizadas por ambientes de visualização.
Em este trabalho são abordadas as imagens médicas que representam um conjunto de fatias do corpo, isso porque esse tipo de imagem permite que seja feita uma reconstrução tridimensional.
Essas imagens podem ser obtidas através de exames como, por exemplo, tomografia computadorizada (CT) ou ressonância magnética (MRI).
Os pixels, onde pixel é a menor parcela da imagem, dessas imagens variam numa escala de tons de cinza.
Em imagens DICOM, que é o formato de armazenamento padrão de equipamentos de aquisição de imagens médicas, os tons de cinza da imagem são representados em 12 bits, permitindo uma maior precisão para identificar a variação de tonalidades entres as diferentes estruturas do corpo.
A partir de essas imagens é possível reconstruir graficamente um modelo volumétrico do corpo humano.
Esse modelo volumétrico nada mais é do que uma série de imagens 2D empilhadas que passam a idéia de um volume.
A Figura 1 ilustra esse conceito de empilhar imagens para criação de um modelo volumétrico.
A partir desse modelo podem ser realizadas operações sobre os voxels, análogo a pixel só que em relação a volumes, de maneira que se possa visualizar os órgãos reconstruídos com mais clareza.
Imagens Médica Em imagens médicas as partes que compõe um órgão possuem tons de cinza semelhante.
Assim, para se visualizar uma determinada região ou órgão do corpo humano, é necessário que se realizem alguns ajustes nos parâmetros de exibição da imagem.
Esses ajustes permitem que os órgãos de interesse sejam visualizados com mais clareza.
De entre os parâmetros utilizados para a geração dessas imagens destacam- se o janelamento, a opacidade e a cor.
O centro e a largura da janela da imagem são parâmetros de importância para dar maior destaque a determinadas regiões do corpo humano.
A alteração desses parâmetros implica na alteração de um &quot;mapeamento «que é feito entre os tons de cinza existentes nas imagens DICOM e os tons de cinza que são apresentados para o usuário.
Em as imagens DICOM os tons de cinza são representados em 12 bits, e como em monitores convencionais (CRT, LCD, etc.) os tons de cinza são representados em 8 bits, existe a necessidade de se realizar esse mapeamento.
O mapeamento realizado nada mais é do que a escolha de uma parcela dos tons de cinza da imagem original que será exibida com os 8 bits de tons de cinza representáveis.
A Figura 2 demonstra como a alteração dos parâmetros de janelamento influência na exibição da imagem.
Em a parte superior da figura estão as imagens resultantes da alteração dos parâmetros.
Os gráficos na parte inferior da imagem mostram a escala de tons de cinza que são representáveis por a aplicação (eixo y) e a intensidade dos tons de cinza dos pixels da imagem original (eixo x).
A imagem deste exemplo tem a intensidade de seus pixels variando de 0 a 170.
Em a imagem central a janela foi definida com o centro em 85 e largura em 171, assim toda a escala de tons de cinza será utilizada para representar todas as intensidades dos pixels da imagem original.
Em a imagem à esquerda, a largura da janela foi reduzida.
Com isso é possível aumentar o nível de detalhes da imagem uma vez que a escala de tons de cinza suportados por a aplicação tem de representar um número menor de tons de cinza pertencentes à imagem original.
Já a imagem à direita teve o valor do centro alterado para 40 e a largura mantida em 171, com isto uma parte da escala de tons de cinza não está sendo utilizada para representar os tons de cinza da imagem original, mais precisamente a parcela correspondente às cores mais escuras, gerando, assim, uma imagem mais clara.
Os valores centro e largura da imagem também são conhecidos como, respectivamente, brilho e contraste.
A opacidade é controlada através de funções de transferência que são aplicadas às imagens numa etapa de pré-processamento.
Estas funções agem sobre a imagem como filtros com o objetivo de definir regiões transparentes, semitransparentes ou totalmente opacas.
A opacidade de cada voxel é definida por uma função que, dado o nível de cinza do voxel, calcula um valor de opacidade que pode variar de zero (totalmente transparente) a um (totalmente opaco).
As cores são atribuídas à imagem também por meio de funções de transferência.
Algumas funções utilizadas para determinar opacidade também podem ser utilizadas para determinar as cores, de maneira que cada valor de tom de cinza é mapeado para um valor RGB.
Em aplicações desktop as alterações das funções de transferência podem ser controladas através de interfaces WIMP (Window Icon Menu Pointer), em as quais o usuário pode especificar valores de cor e opacidade para cada intervalo de tons de cinza.
Kniss apresenta uma forma diferente de se alterar as funções de transferência, tanto para opacidade, quanto para cores.
A partir de um gráfico composto por os tons de cinza (eixo x) e por o modulo do gradiente (eixo y) de cada voxels do volume, o usuário pode definir dinamicamente quais cores representam quais intensidades (Figura 3).
O gradiente é um vetor cuja direção indica os locais em os quais os níveis de cinza sofrem maior variação.
O módulo desse vetor varia conforme a diferença entre os tons de cinza.
Fonte: O resultado desse gráfico são nuvens de pontos, onde cada um desses pontos representa um voxel.
Com isso é possível obter resultados como, por exemplo, determinar que os voxels que correspondem a osso encontram- se no canto inferior direito do gráfico.
Isso porque ossos possuem uma tonalidade mais clara (valores mais altos de tom de cinza) e não variam muito entre si (valores baixos do modulo do gradiente).
Um exemplo dessa interface pode ser observado na Figura 4, onde, dado o gráfico das intensidades dos voxels, cada um dos triângulos são elementos criados por o usuário para indicar qual cor será utilizada para os voxels contidos no triângulo.
Como as estruturas contidas no volume de dados representam objetos tridimensionais (órgãos do corpo humano), um ponto fundamental no processo de interação com estes dados, é dar ao usuário a possibilidade para se visualizar- los de diversos ângulos.
Para isso é necessário que o usuário possua uma forma de manipular o modelo.
Como esta é uma tarefa que o usuário executa com freqüência é necessário que ela seja de fácil utilização e não consuma muito tempo interação do usuário.
Fonte: Para as aplicações desktop uma das formas de manipular do modelo é através de uma Arcball mapeada sobre o modelo.
A Arcball é uma técnica para controlar a rotação de objetos tridimensionais através do mouse.
A idéia é que existe uma esfera invisível envolvendo o modelo e quando o usuário movimenta o mouse sobre essa esfera ela gira, girando o modelo contido em ela.
O software VolVis, por exemplo, utiliza esta técnica para manipulação do volume de dados.
Outra ferramenta de interação existente em ambientes de visualização que trabalham com modelos volumétricos é o chamado plano de corte.
O Plano de Corte permite investigar estruturas internas do volume que está sendo visualizado.
Basicamente, o usuário controla um plano que pode ser movido por dentro de o volume e que permite visualizar o corte gerado por a intersecção deste plano com o volume.
Em a Figura 5 pode ser observado um plano de corte aplicado a uma região do cérebro.
Em este caso, um dos lados do volume cortado por o plano fica ocluso, permitindo, assim, a visualização do interior do cérebro.
A interação com esse plano pode ser realizada de diferentes formas em ambientes desktop.
Rosset, por exemplo, propõe o uso de um dispositivo utilizado para edição de vídeos, chamado Jog-Wheel (Figura 6), para realizar a interação com esse plano de corte.
Com o Jog-Wheel o usuário seleciona qual dos eixos deseja movimentar o plano através dos botões.
A partir de isso, o usuário pode girar o plano sobre o eixo selecionado através da roda.
Existem casos onde é necessário que o usuário selecione determinadas regiões num modelo volumétrico através de segmentação de regiões de interesse, as chamadas Roi.
Existem diferentes métodos de segmentação, que variam da segmentação totalmente manual, em a qual o usuário tem de especificar manualmente toda a região que tem interesse em separar das demais, até a segmentação totalmente automática, em a qual o usuário deve apenas indicar que parte do corpo deseja selecionar e a aplicação determina a região.
A Figura 7 exemplifica um dos resultados que pode ser obtido através do uso de segmentação nos modelos.
Em esse caso, a partir de uma série de imagens da cabeça foi possível separar o osso dos demais tecidos, permitindo, assim, a geração de um modelo apenas com o crânio.
Porém, mesmo os métodos totalmente automáticos de segmentação podem não apresentar resultados precisos e, por isso, o usuário pode precisar refinar o resultado apresentado por a aplicação.
Toennies apresenta uma técnica semiautomática para segmentação de modelos volumétricos através de interfaces bidimensionais.
Para o funcionamento dessa técnica o usuário deve especificar parâmetros para identificar o que ele deseja segmentar, como, por exemplo, o tom de cinza da região, e em seguida indicar com o mouse um ponto na sua tela.
Esse ponto definido por o usuário é a origem de um raio ortogonal ao espaço de coordenadas da tela do usuário.
Os voxels por o qual o raio passar, que possuam as características especificadas por o usuário, serão utilizados como voxels iniciais para a segmentação da Roi.
A partir de cada um dos voxels iniciais verifica- se se seus vizinhos também possuem as características especificadas por o usuário, se possuírem esses voxels farão parte da Roi.
A o final do processo todos voxels que foram encontrados que atenderem às condições especificadas por o usuário são exibidos para que o usuário avalie se a segmentação foi correta.
Para realizar um melhor planejamento de uma cirurgia, pode ser necessário ter acesso não apenas a informações visuais.
Pode ser importante obter medições do modelo, pois no momento da realização de um procedimento cirúrgico, o médico pode ter uma idéia mais clara de como executar o procedimento causando o menor dano possível aos tecidos, evitando, por exemplo, o corte de regiões saudáveis do paciente.
Existem diferentes medidas que podem ser obtidas a partir de um modelo, de entre elas se destacam distância, área, volume e ângulo.
Preim mostra a implementação de algumas técnicas para realizar medições de distância, ângulo e volume num ambiente desktop.
Para isso ele utiliza diferentes widgets 3 D, como pode ser visto na Figura 8a onde é apresentado o widget de volume, na Figura 8b o widget de distancia e na Figura 8c o widget de angulo.
Esses widgets devem possuir cores distintas do resto da cena para facilitar sua visualização.
Todas as medições realizadas por o usuário no sistema podem ser salvas, e junto com a medida também é salva a orientação em que o usuário estava visualizando o modelo.
As medidas podem ser realizadas tanto numa visão tridimensional do modelo, quanto numa visualização bidimensional.
Fonte: Imagens Médicas Em este capítulo serão apresentados trabalhos que tem como foco a visualização de imagens médicas em Ambientes Virtuais (AVs) imersivos.
Em estes ambientes imersivos deve ser dada uma atenção especial quanto a o modo que as tarefas são realizadas, isso porque em AVs a interação com a aplicação é feita por meio de dispositivos não convencionais, ou seja, podem ser utilizados equipamentos como HMDs, luvas e rastreadores de posição.
Como a maioria dos usuários está acostumada somente com métodos tradicionais de interação (por meio de teclado e mouse) é necessária uma avaliação cuidadosa do processo de interação com dispositivos de RV.
A utilização de dispositivos de RV pode trazer benefícios para a interação, como, por exemplo, a facilitação da manipulação de um objeto tridimensional através da utilização de um rastreador de posição.
Isso porque os movimentos que o usuário realiza no mundo real são diretamente mapeados para o mundo virtual, fazendo com que o usuário tenha a impressão de estar manipulando um objeto real.
Por outro lado, a interação com menus ou troca de parâmetros do sistema podem ser mais fáceis de realizar em ambiente desktop através de mouse e teclado.
Em as próximas seções são apresentadas algumas técnicas de RV utilizadas para executar as mesmas tarefas interativas descritas no capítulo 2, porém em AVs imersivos.
A entrada de parâmetros numéricos em sistemas de visualização de imagens médicas, como por exemplo, janelamento da imagem, valores das funções de transferência, entre outros, pode ser complicada de se apresentar em ambientes imersivos, uma vez que não se utiliza teclado.
A maior parte das aplicações em AV estudadas optou por o uso de menus bidimensionais adaptados para AVs para realizar o controle desses parâmetros.
Estes menus também são utilizados para outras tarefas, como, por exemplo, abertura de um conjunto de imagens ou mesmo salvamento de alterações realizadas nos modelos.
Esses menus bidimensionais adaptados são versões dos clássicos menus encontrados em aplicações desktop.
A interação com estes menus é feita através de um apontador controlado por o usuário.
Esses menus podem estar dispostos de diferentes formas para o usuário, tal como numa região fixa de seu campo de visão ou preso a uma prancheta que o usuário possa segurar.
A utilização de menus bidimensionais adaptados para AVs trás para o usuário o benefício de ser um meio de interação com o qual ele está acostumado a lidar normalmente.
Porém, mesmo apresentando- o todas as funcionalidades necessárias para interação, a utilização de menus bidimensionais adaptados pode causar efeitos indesejáveis como a oclusão de elementos importantes da visualização, como pode ser visto na Figura 9, onde o menu acaba ocupando quase todo o campo de visão do usuário.
Fonte: Para solucionar o problema de oclusão podem- se utilizar diferentes métodos para controlar os parâmetros da imagem.
Por exemplo, pode- se utilizar um menu com um tamanho reduzido para que atrapalhe o menos possível o campo de visão do usuário.
Outra solução é a apresentada por Wössner, onde além de utilizar uma interface adaptada, é utilizado um conjunto de gestos para controlar atributos da imagem, como por exemplo, o giro do pulso para controlar a quantidade de brilho do conjunto de dados.
Para realizar a movimentação do modelo em ambientes imersivos pode- se usar algum tipo de rastreamento de posição.
De entre os trabalhos avaliados foram encontradas duas formas de se realizar a movimentação do modelo, uma utilizando um único rastreador para interação com toda a aplicação, e outra utilizando dois rastreadores, um dedicado à movimentação do modelo e outro para as demais tarefas de interação.
Em as aplicações que utilizam apenas um rastreador para controlar toda a interação é necessário que se realize uma operação intermediária para permitir a movimentação do modelo, por exemplo, alterar do modo de manipulação da interface para o modo de manipulação do modelo.
Outra opção é deixar que a mão não-dominante controle a movimentação do modelo, diminuindo, assim, o tempo gasto com troca de operação e deixando a mão dominante disponível para realizar operações que exigem mais precisão.
Outra maneira de se manipular o volume é através de interfaces tangíveis.
Qi usa um cubo que o usuário deve manipular.
Este cubo é rastreado e todos seus movimentos e rotações são diretamente mapeados para o modelo.
Com isso o usuário tem um controle mais preciso de quais movimentos são necessários para colocar o modelo na uma posição desejada.
Um exemplo do usuário interagindo desta maneira pode ser visto na Figura 10.
Quanto a a exploração do interior de modelos volumétricos uma das soluções existentes é a apresentada por Wössner.
Chamado de probe, esse método consiste num cubo de visualização, o qual é controlado por o usuário através de um dispositivo de rastreamento, que pode ser movimentado por dentro de o modelo permitindo uma visualização de estruturas internas.
Utilizando a técnica, apenas a região interna que está envolta por o cubo de visualização é exibida para o usuário, deixando assim o resto do modelo oculto, como pode ser observado na Figura 11.
Ainda em termos de visualização de partes internas do modelo existe a possibilidade da utilização do plano de corte.
Em AVs o controle deste plano pode ser feito através de um rastreador preso à mão do usuário ou a um objeto que está sendo manipulado por este usuário.
Como o rastreador é capaz de capturar as informações de translação e rotação o usuário tem total controle sobre os movimentos realizados por o plano.
Fonte: Existem ainda outras formas de se controlar esse plano de corte.
Qi, por exemplo, apresenta duas abordagens que utilizam objetos reais como uma caneta e um quadro, que são rastreados.
Segundo Qi a idéia de se utilizar a caneta para interação baseia- se no fato de que a maioria dos usuários já está acostumado a utilizar uma caneta como dispositivo de interação e também que, em trabalhos futuros, esta mesma caneta poderia ser utilizada para facilitar a criação de uma interface híbrida com elementos em 2D e em 3D.
Apenas cinco graus de liberdade são capturados por esta caneta, isso porque o rastreamento óptico empregado não consegue capturar a rotação ao redor de a caneta, e o plano de corte se localiza na ponta da caneta sendo perpendicular a orientação da mesma.
A terceira e última forma apresentada por Qi é a utilização de um quadro que tem seus movimentos rastreados com seis graus de liberdade.
Segundo Qi, a utilização de um quadro para controlar o plano de corte facilita a interação para o usuário, uma vez que esse quadro se assemelha mais com o plano de corte que está sendo controlado.
A inspeção do modelo nada mais é do que uma tarefa de visualização dos utilizando- o como um rastreador de posição ou interagindo diretamente através da interface disponível no tablet pc.
A tarefa de marcação dos erros cometidos por o método de segmentação automático também pode ser desempenhada em ambas as interfaces e serve para determinar quais regiões necessitam de ajustes para segmentação.
Para marcar uma região, o usuário deve pintar a superfície do modelo, tanto através da interface 3 D, como da 2D.
Se o usuário considerar que uma região está segmentada de maneira correta deve pintar- la com a cor verde.
Se julgar que uma região não está corretamente segmentada, mas necessita apenas de pequenos ajustes, ela é pintada com a cor amarela e, finalmente, se a segmentação de uma região está bastante diferente do esperado, então a região é pintada com a cor vermelha.
Fonte: O processo de correção dos erros também pode ser executado tanto via interface 2D como 3D.
O usuário deforma a região segmentada apenas tocando a segmentado.
Para realizar esse deslocamento o usuário conta com opções como deslocar a superfície através de uma esfera, de um plano ou deslocar os pontos da superfície.
Quando está utilizando a esfera para correção dos erros, o usuário pode determinar o seu raio para obter maior precisão na correção, pois ela é utilizada para melhor segmentar regiões curvas do modelo, como pode ser visto na Figura 14.
A utilização do plano tem como objetivo planificar regiões do modelo segmentado e, finalmente, o deslocamento dos pontos é recomendado para os lugares onde se deseja obter uma maior precisão do que está sendo segmentado, uma vez que se deve selecionar cada ponto e moves- los para a posição desejada.
Para a realização de medidas em AVs, Reitinger apresenta um estudo de métodos para medição num fígado.
O autor afirma ter escolhido este órgão em específico pois é o que apresenta mais irregularidades entre pacientes diferentes, e por isso é fundamental obterem- se medidas para um entendimento mais claro de como proceder durante um procedimento cirúrgico.
Reitinger propõe três medidas a serem realizadas em sua aplicação:
Distância, volume e ângulo.
Fonte: Para medição da distância são propostos três métodos:
Distância ponto- aponto, uma medição semi-automática e uma medição com o auxílio de uma régua.
Para a distância ponto-a-ponto o usuário, que utiliza um rastreador de posição em forma de caneta, indica diretamente o ponto inicial e o final onde será realizada a medição.
Em o método semi-automático, o usuário precisa apenas indicar a face inicial e final, e o sistema encarrega- se de achar a menor distância entre essas faces para realizar o cálculo.
Para realizar medição com uma régua, é disponibilizada ao usuário uma régua real que ele deve levar até o objeto que deseja realizar a medida, como visto na Figura 15 a, e o sistema encarrega- se de calcular a distância.
Para o cálculo de volume são dadas duas opções ao usuário.
Em a primeira, cálculo direto do volume, o usuário deve apenas especificar uma parte segmentada do modelo através do rastreador, que o sistema exibirá o volume desta área.
A outra forma é através de um copo de medidas real, com o qual o usuário especifica uma região segmentada a ser medida e a leva até esse copo, assim, é exibido o volume do objeto.
Por fim, para realizar a medição de ângulos o usuário deve especificar com a caneta rastreada um ponto inicial de onde dois vetores sairão, e, em seguida, dois outros pontos que correspondem a ponta dos vetores.
A partir desses dois vetores a aplicação calcula o ângulo.
Fonte: Como visto no capítulo 2 a análise das imagens médicas é feita através da inspeção de um conjunto de imagens 2D ou de um modelo 3D reconstruído a partir de essas imagens.
De posse dessas informações o médico é capaz de diagnosticar uma doença ou realizar o planejamento de um procedimento cirúrgico.
O capítulo 3 por sua vez apresentou exemplos de como AVs podem desempenhar as tarefas de interação e visualização de modelos reconstruídos.
A utilização de AVs para sistemas de diagnóstico por imagens pode trazer benefícios tanto para a visualização quanto para a interação com o modelo reconstruído.
O usuário estando imerso num AV tem mais facilidade em determinar as relações de tamanhos dos órgãos contidos no volume, uma vez que, diferente da análise baseada apenas em imagens bidimensionais, ele pode se movimentar livremente em volta do modelo para observar- lo de diferentes ângulos.
Este recurso também possibilita retirar informações quanto a forma dos órgãos contidos no volume que esta sendo analisado.
Com esses recursos o usuário tem mais condições de realizar uma melhor avaliação sem que haja necessidade da realização de um procedimento cirúrgico invasivo no paciente.
A utilização de um HMD num AV traz vantagens quanto a a visualização das informações que estão sendo exibidas.
Através de um HMD que rastreie a posição e orientação da cabeça do usuário é possível dar ao usuário um controle direto sobre o que será visualizado, além de tornar o controle dessa visualização mais intuitivo, uma vez que a mudança de um ponto de vista é feita com os movimentos da própria cabeça.
Em os AVs com o suporte ao rastreamento de posição, o usuário tem a possibilidade de realizar uma interação intuitiva.
A partir de um rastreador de posição preso à mão do usuário, basta que ele realize um movimento ou rotação que estes serão mapeados diretamente para o AV, permitindo a interação natural com o volume de dados, como se o usuário estivesse interagindo com um objeto real.
Assim como a utilização de AVs pode trazer benefícios para uma aplicação também existem características destes ambientes que podem trazer problemas à interação do usuário.
Como o ambiente utiliza dispositivos não convencionais, como por exemplo, rastreador de posição, HMD, etc., o usuário pode se sentir algum tipo de desconforto com a utilização do equipamento.
O uso de dispositivos deste tipo também traz a necessidade de que o usuário trabalhe com técnicas especificas para os equipamentos utilizados, técnicas com as quais pode não estar familiarizado, dificultando assim seu desempenho na interação com o ambiente.
O uso de AVs também pode apresentar dificuldades para a representação de alguns recursos que são de uso comum em ambientes desktop.
A exibição e seleção de menus do sistema, por exemplo, torna- se mais complicada uma vez que em ambientes desktop se utilizam apenas duas dimensões para representar os menus, já em AVs existe a adição da terceira dimensão.
Esta dimensão a mais traz uma maior complexidade para seleção de uma opção, por exemplo, o usuário controla o mouse para selecionar a posição X e Y de uma opção, porém num AV ele também deve se preocupar com a profundidade de onde essa opção se encontra num menu no espaço (posição Z).
Outro problema da utilização de menus em AVs é que a exibição de um menu, por ser uma estrutura bidimensional, pode comprometer a noção de profundidade do AV, retirando assim uma das vantagens da utilização de um AV.
Por exemplo, se for exibido um menu 2D que venha a ocupar todo o campo de visão do usuário, como já mencionado na seção 3.1.
Outro problema comum em AVs é o processo de entrada de valores alfanuméricos, isso porque o usuário não possui um dispositivo convencional para entrada dos dados, como um teclado para realizar interação.
Os equipamentos utilizados em AVs como rastreadores, HMDs, etc., possuem um custo mais elevado que os dispositivos convencionais, como mouse e teclado, por este motivo a construção de um AV que utilize esse tipo de dispositivo é menos comum do que os ambientes tridimensionais não imersivos.
Além de isto, dependendo do tipo de dispositivos que se está utilizando existe a complexidade envolvida na montagem da configuração, o que afeta a mobilidade do sistema, uma vez que a todo momento que se desejar deslocar o sistema para algum outro lugar será necessário desmontar- lo e remontar- lo no novo lugar, e com a montagem não sendo trivial é necessário tempo e alguém capacitado para a tarefa.
Como uma possível solução para os problemas apontados na seção anterior, poderia ser adotada a estratégia de utilizarem- se dispositivos convencionais como mouse e teclado.
Entretanto, uma vez que o usuário esteja utilizando um HMD este fica impossibilitado de enxergar a localização destes dispositivos.
No caso de um teclado, por exemplo, para tornar seu uso possível seria necessário não só rastrear sua posição e orientação, mas também rastrear os movimentos de todos os dedos das mãos do usuário e exibir- los no HMD, pois nem todos os usuários são capazes de digitar sem olhar para o teclado.
O mouse também apresenta deficiências em seu uso em AVs, a primeira de elas é a necessidade de uma superfície plana para que ele possa ser apoiado.
Outro problema é a limitação de dois graus de liberdade para a interação.
Mesmo existindo maneiras de se contornar essa deficiência, como por exemplo, a utilização combinada de botões ou de teclas, este dispositivo ainda se mostra inferior para interação em AVs se comparado a dispositivos criados especialmente para esta finalidade.
Para um dispositivo ser eficiente num AV ele deve possuir algumas características que tornam sua utilização simples.
O primeiro objetivo do dispositivo tem que ser não só permitir a execução de uma tarefa, mas sim, facilitar a interação do usuário na execução da mesma.
Em aplicações de visualização, o dispositivo deve ser minimalista em termos de o espaço ocupado no campo de visão do usuário, a fim de não desviar a atenção do objetivo principal da aplicação, que é visualizar o modelo ou imagem.
Como o usuário pode passar longos períodos de tempo operando o sistema é necessário que o dispositivo não cause desconforto enquanto está sendo utilizado.
Se o dispositivo for desconfortável, por mais que ele possa a ser eficiente, o desconforto pode comprometer o desempenho.
Por exemplo, se o dispositivo for pesado o usuário terá dificuldade de utilizar- lo por longos períodos de tempo.
As informações contidas ou apresentadas no dispositivo devem ser claras e de fácil entendimento.
A intenção do dispositivo é facilitar a interação do usuário e a adição de uma série de comandos poderosos, porém complexos de se utilizar pode distrair o usuário, fazendo com que ele tenha que se concentrar mais para compreender o funcionamento do dispositivo do que para visualizar os dados de fato.
Como o objetivo deste trabalho é desenvolver uma ferramenta que auxilie a interação com ambientes de visualização de imagens médicas em AV imersivos, foram estudadas quatro ferramentas que desempenham as tarefas básicas de rendering e entrada de valores.
Para a seleção das ferramentas foram definidos os seguintes critérios:
Possibilidade de visualização da reconstrução 3D das imagens, capacidade de alterar os parâmetros do janelamento, e a possibilidade de se alterar as funções de transferência de cor e opacidade.
As ferramentas selecionadas para se realizar o estudo foram:
AMIDE, VolPack, DeskVox e VolSuite.
AMIDE (Amide's a Medical Imaging Data Examiner) é uma ferramenta de código aberto desenvolvida em C/ C+, que possui as operações básicas de uma aplicação de visualização de imagens médicas.
Além de a reconstrução do volume, possui recursos como o janelamento, ajuste das funções de transferência de cor e opacidade.
Uma característica interessante desta ferramenta é a existência de um conjunto de configurações pré-definidas para o janelamento de regiões específicas do corpo humano.
Por exemplo, existe uma configuração que possui os parâmetros de janelamento que favorecem a visualização do fígado, isso para que o usuário não gaste tempo procurando quais os melhores valores para visualização do órgão.
A aplicação oferece também a possibilidade de definição de ROIs a partir de formas geométricas pré-definidas, incluindo caixa, esfera e cilindro.
Para definir uma Roi o usuário deve especificar, através de entrada de texto ou comando de interface, o centro e as dimensões da forma geométrica escolhida.
A partir de a definição de ROIs a aplicação possibilita que o usuário realize medições quanto a a intensidade dos tons de cinza contidos na Roi.
A aplicação também possui recursos para reconstrução tridimensional a partir de as imagens.
A qualidade do modelo gerado pode ser observada na Figura 16.
A interação com esse modelo é feita através de uma Arcball ou de controles disponíveis na interface.
Fonte: O desempenho do processo de rendering do volume é baixo, não possibilitando a movimentação do volume em tempo-real.
Em a visualização tridimensional também não está disponível a opção de controlar planos de corte para a exploração de estruturas internas do modelo.
Isto se deve ao fato de que esta aplicação tenha grande parte de seus recursos voltados a visualização das imagens em 2D.
Esta é uma biblioteca de código aberto, desenvolvida por Philippe Lacroute do laboratório de computação gráfica da universidade de Stanford, na linguagem de programação C/ C+.
O objetivo dessa biblioteca é o rendering rápido de modelos volumétricos de alta qualidade.
A biblioteca suporta a utilização de funções de transferência de cor e opacidade desenvolvidas por o usuário.
Porém não possui funções próprias para o tratamento das imagens, também não possui o tratamento para o janelamento das imagens.
O rendering do volume apresenta boa qualidade visual, como pode ser observado na Figura 17, e é gerado de forma rápida, permitindo a interação em tempo-real.
A biblioteca também possui recursos que aumentam a qualidade do modelo como ajustes na iluminação do volume e a geração de sombras.
A biblioteca não possui a implementação de planos de corte para o modelo gerado, deixando esta funcionalidade a cargo de a implementação do usuário.
Fonte: DeskVox (Desktop Volume Explorer) é uma aplicação desenvolvida em conjunto por a Brown University e por a universidade de Stuttgart.
A aplicação é de código aberto e foi desenvolvida em C/ C+.
Essa aplicação possui os recursos básicos para o ajuste de funções de transferência, de opacidade e cor, porém não possui meios de se alterar o janelamento das imagens.
O rendering do volume é feito em tempo-real e sua qualidade pode ser observada na Figura 18.
Esta aplicação permite que o usuário controle um plano de corte para a visualização das estruturas internas do modelo.
O controle desse plano de corte é feito através da interface por meio de sliders que controlam a translação do plano de corte ao longo de cada eixo cartesiano.
A aplicação também permite a criação de uma Roi, que consiste numa caixa cujo centro e as dimensões são definidos por o usuário.
VolSuite é uma aplicação de código aberto desenvolvida em C/ C+, e que tem como objetivo ser o mais portável e extensível possível.
Isto facilita tanto sua utilização quanto a modificação dos módulos já existentes na aplicação por outros desenvolvedores.
Esta aplicação disponibiliza meios de alterar o janelamento das imagens, e também de alterar as funções de transferência de cor e opacidade.
Os valores podem ser alterados através de comandos de interfaces ou entrada direta dos valores por comandos textuais.
Fonte: O rendering do volume é feito em tempo-real e a qualidade da imagem gerada por a aplicação pode ser observada na Figura 19.
A aplicação possui ainda a opção de se definir uma Roi que funciona de maneira similar à apresentada na aplicação DeskVox.
Fonte: Existe também a possibilidade de se definirem múltiplos planos de corte.
Esses planos de corte podem ser ativados juntos ou em separado, dando ao usuário maior liberdade de interação.
A partir de o estudo realizado com as ferramentas foi possível determinar qual de elas satisfaz melhor as características necessárias.
A Tabela 1 apresenta um resumo dos recursos que cada uma das ferramentas possui.
A aplicação AMIDE possui funcionalidades interessantes para o tratamento das imagens médicas.
Porém optou- se por não utilizar- la por o fato de ela não possuir recursos básicos como o plano de corte no modelo tridimensional e também por a velocidade de rendering do modelo.
A biblioteca VolPack possui qualidade nos modelos gerados e é rápida em sua execução, mas não possui muitos recursos para o tratamento da imagem e também não possui implementação de planos de corte Por estes motivos não foi escolhida para utilização neste trabalho.
A aplicação DeskVox possui funções de transferência, boa velocidade de rendering do volume e planos de corte já implementados.
Porém não possui meio de se alterar o janelamento das imagens e por isso acaba não tendo todos os requerimentos necessários.
VolSuite foi aplicação escolhida para servir de base para desenvolvimento do trabalho.
Além de possuir todos os recursos necessários (janelamento, funções de transferência de cor e opacidade, planos de corte e boa velocidade de rendering), ela possui a vantagem de ser facilmente extensível.
Com base nos resultados da avaliação de ambientes de visualização de imagens médicas apresentada no capítulo 4, das características desejáveis de um AV voltado à visualização de dados médicos, apresentadas no capítulo Erro!
Fonte de referência não encontrada.,
a seguir é apresentado o projeto e o desenvolvimento de um dispositivo para interação com dados médicos (volumétricos) num ambiente virtual imersivo.
O foco do projeto foi desenvolver novas técnicas de interação para a realização das principais tarefas inerentes aos ambientes de visualização de dados médicos, descritas na seção 2.2.
Permitindo que sejam realizadas tarefas 3D ou 2 D, mantendo a interação uniforme e sem perda da sensação de imersão.
Utilizando- se os algoritmos de visualização da ferramenta VolSuite, cuja escolha foi justificada na seção 4.5, foi desenvolvido um dispositivo de interação.
Esse dispositivo é capaz de servir tanto às interações tridimensionais da aplicação, tais como a movimentação do plano de corte ou do volume de dados, quanto a a entrada de parâmetros numéricos, como por exemplo, alteração dos valores do janelamento ou o controle da opacidade dos voxels do volume de dados.
O objetivo foi executar toda a aplicação num ambiente imersivo com o usuário fazendo uso de um capacete de VR (HMD) e controlar a interação somente com técnicas que utilizassem este dispositivo, que está nas mãos do usuário.
A idéia é aliar as facilidades de manipulação 3D trazidas por um dispositivo do tipo rastreador de posição, às potencialidades de um dispositivo sensível ao toque para a entrada de dados.
Detalhes deste dispositivo são apresentados a seguir.
O dispositivo criado consiste de uma caixa de acrílico opaco com alças laterais conforme a Figura 20.
Em a parte superior da caixa existe uma superfície sensível ao toque simultâneo de múltiplos dedos, chamada a partir de aqui de sensor multi-touch.
Como prolongamento desta superfície existe a área utilizada para um menu de opções.
As alças laterais foram adicionadas para que o usuário tivesse maior facilidade para manipular o dispositivo, isso porque ele tem a opção de realizar diferentes operações com o mesmo, e algumas de elas poderiam tornar- se difíceis se estas alças não existissem.
Para a manipulação do dispositivo no AV foi preso um rastreador de posição na lateral direita da caixa.
Este rastreador permite que um modelo virtual da caixa seja exibido ao usuário dentro de o AV.
O formato de uma caixa foi adotado em função de o modo como é feito o rastreamento dos dedos na superfície multi-touch.
Para realizar esse rastreamento é utilizada uma câmera que se encontra dentro de a caixa na parte inferior e, dado o ângulo de visão da câmera, para que esta &quot;enxergue «toda a superfície que captura os movimentos dedos é necessário que haja uma distância mínima entre a câmera e esta superfície.
Em o caso, a câmera utilizada no dispositivo é uma QuickCam Para o para Notebooks da empresa Logitech1.
Para uma superfície com dimensões de 13 cm por 8 cm foi determinado empiricamente que a distância mínima deveria ser de 18 cm.
Em a Figura 21 pode- se observar um desenho esquemático do posicionamento da câmera dentro de a caixa.
A forma de construção desta superfície multi-touch teve como base o projeto MiniMT desenvolvido por o Natural User Interface group, em o qual o objetivo é a construção de um sensor multi-touch eficiente e de baixo custo.
Foi adotada a solução de utilizar o projeto MiniMT para construção do sensor multi-touch devido a a indisponibilidade de uma superfície multi-touch profissional Logitech.
Com\&gt; semelhante à de um iPhone2, Surface3 oupause PC 9004, que caso existisse, seria possível reduzir o tamanho do dispositivo.
Implantado em cada uma das alças laterais da caixa existe um botão, conforme a Figura 22.
Esses botões permitem que o usuário acesse os modos de interação do ambiente virtual, quais sejam:·
Seleção das opções do menu;·
Manipulação do modelo;·
Manipulação do plano de corte.
A fim de permitir que o usuário selecione quais parâmetros estará alterando através do sensor multi-touch foi disponibilizado um menu para seleção das opções.
Esse menu é exibido à direita da superfície multi-touch, conforme mostra a Figura (center/ width) e de controle das funções de transferência (alpha /red/green/blue).
Para realizar o apontamento de uma funcionalidade do menu, o usuário deve apenas apontar com o dedo indicador da mão direita, em o qual é instalado um rastreador de posição, a opção que deseja selecionar (Figura 24).
A fim de facilitar o apontamento de uma opção de um menu no AV, são providos ao usuário alguns tipos de feedback.
Durante o apontamento, uma pequena esfera é exibida na posição relativa ao dedo do usuário que está com o rastreador, e a opção que está prestes a ser selecionada é destacada através de uma cor, como forma de prover um feedback visual ao usuário.
Além de isto, um feedback tátil é dado por a utilização de uma superfície plana rígida (de acrílico) que se estende à direita área da superfície multi-touch e que serve como apoio físico para o dedo durante o movimento de apontamento.
A escolha efetiva da opção é feita por o pressionamento do botão que se localiza na alça esquerda da caixa.
Após a seleção, a opção correspondente será exibida sobre o sensor multi-touch para que o usuário realize a modificação desejada.
A decisão de não se colocar o menu sobre o sensor multi-touch foi tomada para que o usuário tivesse disponível, de forma simultânea no dispositivo, a opção atual (janelamento ou função de transferência) e o menu de seleção.
Isto visa também diminuir o esforço cognitivo do usuário, evitando a adição de mais um modo ao dispositivo, como um modo de seleção de opções e um modo de alteração de parâmetros.
Quando uma das opções para alteração dos parâmetros do janelamento (Center/ Width) é selecionada, é exibido um ThumbWheel (botão circular giratório) na superfície multi-touch, conforme a Figura 25.
O usuário poderá então selecionar o valor desejado para o parâmetro movendo o ThumbWheel para direita, para aumentar o valor, ou para esquerda, para diminuir o valor.
O valor atual deste parâmetro é sempre exibido sobre a superfície multi-touch.
Caso o usuário deseje alterar o nível de precisão da entrada dos valores, ou seja, o quanto o valor se altera à medida que o ThumbWheel é movido, o usuário deve realizar um movimento de zoom-in para aumentar o valor do passo com que o ThumbWheel se move.
Este movimento consiste em tocar simultaneamente dois dedos juntos no sensor multi-touch e separar- los (Figura 26 A).
Em oposição a este movimento existe o de zoom-out para diminuir o valor do passo.
Para executar- lo o usuário toca simultaneamente dois dedos separados no sensor multi-touch e os aproxima (Figura 26 B).
Quando o usuário selecionar a opção para alterar a função de transferência de cor ou de opacidade, o gráfico correspondente à função escolhida será exibido sobre o sensor multi-touch.
Em o exemplo da Figura 27 observa- se o gráfico da função para alteração do alpha.
Para alterar os valores das funções de transferência o usuário deve apenas tocar com o dedo sobre os pontos de controle e mover- los por o gráfico.
A manipulação do plano de corte é ativada quando o usuário pressiona e segura o botão que se encontra na alça direita do dispositivo.
Enquanto o usuário mantiver o botão pressionado o modo de manipulação do plano de corte estará ativo e será exibido, logo acima de a superfície multi-touch, um quadrado semitransparente, conforme a imagem Figura 28A.
Como este quadrado segue todos os movimentos do dispositivo, para posicionar o plano o usuário deve apenas levar esse quadrado semitransparente para posição desejada em relação a o volume e liberar o botão direito.
Com isso, no lugar do plano semitransparente, é exibida a imagem correspondente ao plano selecionado.
A manipulação do volume de dados é feita de maneira similar à manipulação do plano de corte.
Para ativar- lo usuário deve pressionar e manter pressionados ambos os botões do dispositivo.
Enquanto o usuário estiver no modo de manipulação do volume todos os movimentos (translações e rotações) realizados com o dispositivo serão diretamente mapeados para o volume.
Em o momento em que o usuário deixar o modo de manipulação, soltando os botões, o volume manterá sua a última posição.
O primeiro passo para o desenvolvimento da aplicação foi a adaptação da ferramenta escolhida, no caso o VolSuite.
A partir de esta ferramenta foi extraída a biblioteca que controla apenas a parte de carga de arquivos e rendering de volume que é a OSCVR (Ohio Supercomputer Center Volume Rendering library).
Porém como algumas das funcionalidades dessa biblioteca estão focadas para o desenvolvimento de aplicações desktop algumas modificações tiveram de ser feitas para que essas funcionalidades pudessem ser utilizadas no AV implementado.
As alterações realizadas foram no controle das funções de transferência, isso porque as classes da biblioteca, que controlavam as funções de transferência, estavam orientadas para utilização em conjunto com eventos gerados por um mouse, logo foi necessária a alteração de alguns trechos de código para que a biblioteca tivesse suporte também à ambientes com qualquer tipo de dispositivo.
Para o desenvolvimento do sensor multi-touch inicialmente foi pensado em se adquirir um produto comercial para utilizar junto ao dispositivo, pois isso poderia poupar tempo de implementação e adaptação, uma vez que já poderiam existir drivers prontos para o sensor.
Porém, por questões como custo e dificuldade para se adquirir um produto optou- se por outra solução.
A solução escolhida foi a de utilizar uma câmera para rastrear a posição dos dedos através da biblioteca TouchLib.
Esta é uma biblioteca que utiliza um método chamado Iluminação Difusa.
No caso de o dispositivo criado, existe a câmera dentro de a caixa que filma uma região transparente coberta por um papel, esse papel atua como difusor da luz externa, gerando assim imagens como na Figura 29A para ser realizado o processamento para detecção dos dedos, após o tratamento é gerando uma imagem resultante como na Figura 29B.
Para o funcionamento correto deste sensor é necessário que exista uma fonte de iluminação constante sobre a superfície coberta por o papel.
Após a captura da imagem a biblioteca aplica alguns filtros sobre ela, até que a imagem resultante seja apenas a marca de onde os dedos do usuário encostam sobre a superfície.
A partir de esta imagem resultante as marcas dos dedos capturados são rastreadas, permitindo assim rastrear diferentes dedos e suas respectivas posições.
Essa biblioteca possui a vantagem de que todo esse processamento é realizado numa thread separada, permitindo que a aplicação não fique limitada à velocidade da taxa de captura da câmera utilizada, em geral trinta quadros por segundo.
Uma vez que as bibliotecas de rendering de volume e do sensor multi-touch estavam funcionais o passo seguinte foi a integração dessas duas bibliotecas.
O sensor multi-touch ficou responsável por todo o controle da alteração dos parâmetros do janelamento e das funções de transferência.
Para a seleção das funcionalidades do dispositivo existem dois botões, localizados um em cada uma das alças da caixa.
O controle desses botões é feito através de uma placa paralela.
Essa placa tem a capacidade de controlar o estado de até cinco botões.
Para leitura do estado dos botões uma thread distinta a aplicação fica continuamente verificando o estados dos botões e repassando esta informação para a aplicação.
Para realizar uma avaliação sobre a efetividade do dispositivo criado foi realizada uma avaliação empírica com uma amostra de 12 usuários.
Os testes foram realizados em dois ambientes:
O AV deste trabalho que faz uso do dispositivo criado e o ambiente VolSuite, descrito na seção 4.4.
Isto foi feito com o intuito de avaliar a efetividade do dispositivo criado em relação a as técnicas interativas já tradicionalmente utilizadas para ambientes de visualização de imagens médicas Para a avaliação foram definidas as seguintes hipóteses:
O sensor multi-touch é capaz de permitir a entrada de valores numéricos em AVs de visualização de imagens médicas de forma tão precisa quanto as técnicas usadas em ambientes desktop;
Os usuários irão preferir manipular o volume e o plano de corte através do dispositivo;
Os usuários irão preferir realizar a alteração dos parâmetros de janelamento e das funções de transferência no ambiente desktop;
Os usuários levarão menos tempo, no AV, para realizar as tarefas de posicionamento (do volume e do plano de corte);
Os usuários levarão mais tempo, no AV, para realizar as tarefas de alteração dos parâmetros de janelamento e das funções de transferência.
Para que o dispositivo, o ambiente desenvolvido e o roteiro dos testes apresentassem a menor quantidade de erros, alguns testes preliminares foram realizados.
De um primeiro estudo informal de usabilidade participaram dois usuários especialistas com conhecimento em AVs e técnicas de interação.
O objetivo desse estudo foi apontar quais melhorias podiam ser feitas para que o sistema se tornasse mais amigável ao usuário.
A partir desse estudo algumas características do dispositivo e do ambiente puderam ser alteradas para que o usuário tivesse uma maior facilidade ao interagir com o AV.
Quanto a o ambiente virtual foi decido colocar o usuário dentro de uma sala virtual, de maneira que ele tivesse uma melhor percepção do posicionamento espacial dos objetos a sua volta.
Também foi decidido colocar um painel na parede à esquerda do usuário com as informações correspondentes ao teste que ele estivesse realizando, como por exemplo, na Figura 30 onde é exibida a imagem de referência do posicionamento do volume.
Inicialmente, a área reservada para a exibição da imagem obtida com o plano de corte era exibida com uma dimensão grande em relação a o tamanho do objeto virtual que representava o dispositivo com o objetivo de permitir que o usuário observasse com detalhe a referida imagem.
Isto, entretanto, causava desconforto aos usuários, pois a imagem obstruía uma grande parte o campo de visão do usuário.
Em face de isto, decidiu- se reduzir o tamanho desta área, uma vez que se o usuário desejasse visualizar a imagem com mais detalhes bastaria aproximar o dispositivo dos seus olhos.
Ainda com relação a o plano de corte, foi decidido que o volume só sofreria o corte enquanto o usuário estivesse no modo de manipulação do plano, fora desse modo o volume sempre seria exibido inteiro.
Essa decisão foi tomada por o fato de que dependendo do corte que o usuário realizasse no volume, ficaria difícil identificar qual parte do volume estava sendo cortada, como por exemplo na Figura 32A onde é complicado identificar qual corte está sendo realizado.
Em a Figura 32B por outro lado, fica bastante claro qual parcela do volume está sendo cortada.
Quanto a o dispositivo real foram detectados problemas quanto a a qualidade do sensor multi-touch utilizado.
Como já explicado na seção 5.6, para o funcionamento correto do sensor é necessário um ambiente com uma iluminação uniforme.
Porém o projeto MiniMT tem como premissa que o sensor fique estático e não em constante movimento, como no caso de o dispositivo criado para este trabalho.
Com isso toda vez que o usuário movimentava o dispositivo, o sensor multi-touch acabava perdendo a calibração inicial referente a a iluminação, e apresentava problemas na captura da posição dos dedos, chegando ao ponto do dispositivo parar de funcionar se as mudanças de iluminação fossem muito significativas, como por exemplo, quando o corpo do usuário gerava sombras sobre o dispositivo.
A solução para este problema foi solicitar que usuários durante a execução dos testes que utilizassem o sensor multi-touch, apoiassem o dispositivo sobre uma superfície pré-definida de maneira que este recebesse uma iluminação ideal para seu funcionamento.
Apesar de limitar os movimentos do usuário com o dispositivo no momento da interação com o sensor multi-touch apenas 16% usuários expressaram que sentiram algum desconforto ao utilizar o dispositivo nesta posição.
A partir de os resultados obtidos através do questionário pré-teste foi possível definir um perfil dos usuários que participaram do experimento.
Todos os usuários possuíam escolaridade de nível superior, e grande parte de eles possuía conhecimentos sólidos sobre computadores e utilizava computador com bastante freqüência.
De entre os usuários testados, apenas 33% possuíam um conhecimento profundo sobre RV e suas aplicações, embora 16% tenham afirmado que apesar de não possuir tal conhecimento, já haviam participado de outros experimentos envolvendo RV.
Quanto a o conhecimento sobre visualização de imagens médicas apenas três usuários afirmaram possuir algum tipo de experiência com este tipo de aplicação.
Foram criadas quatro tarefas:
Duas para avaliar a efetividade do sensor multi-touch e duas para avaliar a efetividade da movimentação do plano de corte e do volume.
Como a idéia destas tarefas era avaliar as hipóteses definidas no início deste capítulo, comparando a execução das tarefas com mouse e teclado no ambiente desktop em relação a a execução das mesmas com o dispositivo no AV, todas as tarefas foram criadas para serem executadas em ambos ambientes.
Para medir a precisão na entrada de números foram utilizados os atributos de janelamento.
Foi pedido que o usuário estabelecesse a uma janela com centro em 150 e largura da janela em 40.
O usuário deveria executar esta tarefa da maneira como foi descrita na seção 5.3.
A execução desta tarefa no ambiente desktop apresentava apenas uma diferença:
Ao invés de o usuário informar para a aplicação o valor de centro e largura da janela era necessário informar os limites da janela.
Para a janela de centro 150 e largura 40 o usuário deveria informar como limite inferior 130 e limite superior 170.
O usuário dispunha de dois métodos para realizar esta tarefa:
Alterar os valores através de um slider ou;
Entrar os valores diretamente por o teclado.
Em a Figura 33 é possível visualizar a interface para esta tarefa.
Para a alteração destes valores no ambiente desktop o usuário deveria alterar a posição dos pontos de controle arrastando- os com o mouse.
Em a Figura 35 é possível visualizar a interface correspondente a esta tarefa no ambiente desktop.
As tarefas relativas ao posicionamento do plano de corte e do volume visavam obter informações subjetivas quanto a a preferência do usuário em relação a o método de manipulação.
Para tanto o usuário era solicitado a reproduzir o posicionado do volume e do plano de corte, com base em imagens que lhe eram apresentadas.
Em a Figura 36A observa- se a imagem que definine a posição e a orientação do volume e na Figura 36 B, a imagem da posição desejada para o plano de corte.
A execução desta tarefa no AV está descrita na seção 5.5.
Para o posicionamento do volume no ambiente desktop o usuário podia controlar as rotações do volume pressionando o botão esquerdo do mouse sobre a tela onde era exibido o volume e alterar sua rotação através de um Arcball.
A movimentação do volume era feita com botão direito do mouse pressionado, bastando que o usuário arrastasse o mouse para alterar a posição do volume.
A interface correspondente à movimentação do volume pode ser observada na Figura 37A.
Para formalizar o processo de testes com o usuário e com isto dar condições iguais a todos os participantes, foi determinado um protocolo para a execução dos mesmos.
Em a execução de todos os testes havia sempre um avaliador presente guiando o usuário.
O primeiro passo era entregar ao usuário um Termo de Consentimento Informado que dava informações de quais dados estavam sendo coletados e qual a finalidade do teste.
Após concordar com os termos estabelecidos o usuário assinava o documento e então era entregue a ele o questionário pré-teste.
Este questionário buscava extrair informações quanto a o nível de conhecimento do usuário sobre computadores, RV e imagens médicas.
A o término do preenchimento do questionário era lido um texto ao usuário com uma explicação sobre o projeto e sobre as tarefas que este deveria realizar.
Depois de feita a introdução aos testes, o avaliador lia para o usuário a explicação correspondente àquele ambiente que iria ser testado primeiro.
Metade dos usuários testou primeiro o AV, e a outra metade iniciou por o ambiente desktop.
A o fim da explicação o usuário passava por um período de aprendizado sobre as tarefas que iria desempenhar no ambiente.
Com o fim do período de ambientação o usuário realizava as tarefas descritas na seção 6.3.
Após acabar a execução de todas as tarefas era dado início ao mesmo processo de introdução ao ambiente, treinamento e execução dos testes, porém para o ambiente que não havia sido testado.
Após a execução das tarefas em ambos ambientes era entregue ao usuário o questionário pós-teste.
Esse questionário visava avaliar a opinião subjetiva do usuário quanto a a interação em cada uma das tarefas dos dois ambientes testados.
As questões pediam que o usuário classificasse a dificuldade da execução das tarefas numa escala de um a cinco, onde um representava muito difícil e cinco representava muito fácil.
Existia ainda um espaço para que o usuário realizasse críticas ou sugestões sobre cada uma das tarefas.
Com o término do preenchimento do questionário pós-teste o avaliador agradecia a presença do usuário e encerrava os testes.
Uma vez que as tarefas e o protocolo de testes estavam bem definidos foi possível realizar um teste piloto.
O objetivo deste teste foi realizar uma análise sobre o método utilizado para realizar os demais testes e também foi importante para se estabelecer uma estimativa de tempo que um usuário levaria realizando todo o procedimento de teste.
O teste piloto foi realizado com um usuário que possuía experiência tanto em interação com dispositivos e técnicas de RV quanto em imagens médicas.
A partir desse teste foi possível identificar algumas questões sobre a execução dos testes, que são relatadas a seguir.
Devido a o longo período que o usuário estaria utilizando o AV foi determinado que o usuário realizasse a interação com o dispositivo da mesma forma que no ambiente virtual, ou seja, sentado.
Foram levantadas também questões sobre o modo como que as informações eram apresentadas.
Inicialmente no AV as imagens de referência correspondentes às tarefas eram exibidas à esquerda do usuário no ambiente, e para o ambiente desktop o usuário possuía as imagens em suas mãos.
A fim de manter um nível de dificuldade similar para os dois ambientes as imagens de referência no ambiente desktop foram afixadas na parede a esquerda do usuário, dando assim condições similares às apresentadas no AV.
Os testes foram realizados com 12 (doze) usuários e, de acordo com os questionários pré-teste, o perfil ficou definido como usuários com bastante experiência em utilização de computadores, conhecimento razoável sobre RV e pouco conhecimento sobre imagens médicas.
Para as tarefas de janelamento e de função de transferência foi medido o tempo gasto e a precisão dos valores informados por o usuário.
Foram realizadas duas classes de avaliação.
Uma objetiva, baseada em parâmetros como tempo gasto e precisão na execução das tarefas, e outra subjetiva que buscou avaliar o nível de satisfação dos usuários com os dispositivos utilizados.
Para as tarefas de posicionamento do plano de corte e do volume, apenas o tempo de execução foi controlado.
A precisão do posicionamento era controlada por o avaliador, que avaliava se o usuário conseguia ou não realizar a tarefa com sucesso.
Quanto a o tempo gasto em cada uma das tarefas o gráfico da Figura 38 apresenta a média e os valores de mínimo e máximo para cada uma das tarefas em cada um dos ambientes.
Para cada tarefa foi realizado um teste ANOVA tendo como variável entre usuários, o ambiente testado e como variável entre grupos, o tempo gasto para conclusão das tarefas.
Para a movimentação do volume com o alpha-level utilizado não foi encontrado efeito positivo no desempenho do dispositivo.
Já para a movimentação do plano de corte foi encontrado um efeito positivo em favor de o uso do dispositivo $= 11,830, p 0,002).
Isso indica um melhor desempenho quanto ao tempo, para os usuários que utilizaram o dispositivo, o que é atribuído à forma como a interface desktop controla o plano de corte.
Cerca de 60% dos usuários afirmaram, inclusive, que a forma de movimentação, disponível na interface desktop, era confusa.
Para a tarefa de janelamento foi encontrado um efeito significativo em favor de o ambiente desktop $= 25,995, p 0,000).
Em este caso o tempo gasto na tarefa mostrou- se inferior no ambiente desktop devido a a possibilidade do usuário dar entrada nos valores diretamente através do teclado.
Para todas as funções de transferência foram encontrados resultados significativos para o ambiente desktop $= 5,044, p 0,035, vermelho:
F $= 7,852, p 0,01, verde:
F $= 13,950, p 0,001 e azul:
F $= 4,750, 0,040).
Alguns usuários afirmaram que gastaram mais tempo nesta tarefa no AV por possuírem uma maior experiência com interação com mouse, o que acabou facilitando a interação no ambiente desktop.
Os resultados obtidos através da avaliação do tempo gasto por o usuário sustentam parte da hipótese H4.
Ficou demonstrado que os usuários levam menos tempo para realizar a tarefa de posicionamento do plano de corte no AV.
Porém, segundo a ANOVA, não foi possível obter resultados com uma diferença significativa entre os tempos de manipulação do volume entre os dois tipos de ambientes.
Uma possibilidade para a não obtenção de uma diferença significativa entre os tempos para a manipulação do volume pode ser devido a o fato de que esta tarefa era a primeira tarefa de manipulação.
Sendo assim o usuário poderia ainda estar se acostumando com o equipamento no momento da movimentação do volume, comprometendo assim o seu desempenho.
A hipótese H5 foi comprovada através da avaliação pois os usuários levaram mais tempo para concluir as tarefas de precisão (janelamento e funções de transferência) no AV, tendo uma diferença estatisticamente significativa em favor de o ambiente desktop.
Quanto a a precisão das entradas dos valores, na tarefa de janelamento, foi analisado o valor informado por o usuário para o centro e a janela em comparação aos valores que eram solicitados.
Para o janelamento não houve a necessidade de se realizar nenhum teste estatístico, uma vez que todos os usuários foram capazes de informar ao sistema os valores corretos.
Ainda relativo à precisão para as funções de transferência, foi observado o erro em cada ponto, onde o erro é a distância de cada um dos cinco pontos do gráfico para a posição que eles estavam no gráfico modelo.
Em este caso foi realizado um teste ANOVA tendo como variável entre usuários o ambiente testado e variável entre grupos a soma dos erros que cada usuário cometeu numa função de transferência.
O gráfico da Figura 39 apresenta a média da soma dos erros que cada usuário cometeu em cada uma das funções, no AV e no desktop.
Para o alpha-level utilizado não foi possível determinar um efeito significativo em nenhuma das quatro funções de transferência.
Com isso é possível afirmar, em termos de precisão, que o AV mostrou- se tão eficiente quanto o ambiente desktop.
Através destes resultados é possível sustentar a hipótese H1.
No que diz respeito a precisão de valores numéricos, testada através da função de janelamento, o dispositivo mostrou- se capaz de permitir que os usuários informassem valores exatos, atingindo assim os resultados esperados.
Para a precisão de posição, testada através do posicionamento dos pontos de controle das funções de transferência, o dispositivo também apresentou resultados satisfatórios.
A análise estatística, porém, mostrou que não foi encontrada uma diferença significativa entre os erros cometidos com o dispositivo e os erros cometidos no ambiente desktop, tornando assim o dispositivo equivalente ao ambiente desktop neste quesito.
Com relação a a opinião subjetiva dos usuários obtida através dos questionários pós-teste também foi realizado uma ANOVA tendo como variável entre usuários o ambiente testado e como variável entre grupos a nota dada por o usuário.
O gráfico da Figura 40 mostra a média das notas dadas por os usuários a cada uma das tarefas.
Com o alpha-level utilizado não foi possível determinar um efeito positivo em relação a a nota dada para a movimentação do volume.
Apesar de alguns usuários afirmarem que o uso do dispositivo se mostrava mais intuitivo para a movimentação do volume, outros apresentaram alguma dificuldade até entenderem por completo o funcionamento do dispositivo.
Para a movimentação do plano de corte foram encontrados resultados positivos em favor de o AV $= 33,800, p 0,000).
Diversos usuários apresentaram dificuldades ao utilizar a ferramenta do ambiente desktop, sendo que dois usuários não conseguiram posicionar o plano de maneira correta.
Tanto para o janelamento quanto para a função de transferência foram encontrados resultados positivos em favor de o ambiente desktop (janelamento:
F $= 14,191, p 0,001 e funções de transferência:
F $= 6,044, p 0,022).
Isso devido a diversos usuários afirmarem terem mais experiência com interação com mouse e teclado, também devido a algumas limitações do tipo de sensor multitouch utilizado.
Como este depende de uma fonte de luz estável para o funcionamento correto, em alguns momentos da interação ocorria uma perda na calibração, causando dificuldades a interação do usuário.
De acordo com as notas atribuídas à cada uma das tarefas é possível realizar a avaliação correspondente a hipótese H3.
A preferência dos usuários por realizar as tarefas de janelamento e funções de transferência no ambiente desktop ficou clara através na análise realizada, suportando a hipótese.
A hipótese H2 não pode ser totalmente comprovada.
A preferência dos usuários por o AV na manipulação do plano de corte foi possível ser comprovada.
Porém não foi possível obter uma diferença significativa quanto a a preferência do usuário na manipulação do volume.
Com isso não foi possível confirmar a hipótese de forma completa.
De forma geral, apesar de os usuários gastarem um tempo maior na interação com o dispositivo, para a entrada de valores, o mesmo mostrou- se capaz de fornecer um método de entrada de valores com precisão.
O uso de AVs naturalmente já traz benefícios para a manipulação de modelos tridimensionais, uma vez que através de dispositivos como rastreadores de posição a interação pode se tornar mais intuitiva.
Porém uma das barreiras que impede a popularização do uso de sistemas de RV é a dificuldade para a entrada de dados numéricos.
Este trabalho propôs- se a desenvolver um dispositivo que une as vantagens de uma interação com um rastreador de posição, com um método de entrada de valores numéricos num AV, se obriga o usuário do AV a utilizar um dispositivo como um teclado ou um mouse, que, se utilizados reduziriam a imersão do usuário AV.
Para a movimentação do volume e do plano de corte usou- se uma caixa com alças o que permitiu a movimentação de forma simples e precisa.
A seleção de opções de menus também se mostrou eficiente e foi referida como extremamente simples por os usuários.
Como forma de aprimoramento do processo de apontamento das opções no menu, pode- se ainda criar ranhuras sobre a superfície de acrílico de maneira que estas marquem os limites físicos de cada opção.
Com isto se consegue prover mais uma informação tátil para a seleção das opções, permitindo inclusive uma interação Eyes-Off, em que o usuário não precisaria olhar para suas mãos ou para o dispositivo ao realizar a seleção de uma opção.
O método proposto para entrada de valores utilizou um sensor multi-touch preso ao dispositivo.
Apesar de apresentar algumas dificuldades, principalmente do ponto de vista tecnológico (luminosidade do ambiente), o processo de interação foi considerado simples por os usuários e permitiu a manutenção da sensação de imersão no ambiente virtual.
Além de a entrada de valores numéricos o sensor multi-touch também poderia ser utilizado para se realizar a entrada textos, servindo como uma forma de anotação no AV.
Esta tarefa poderia ser executa tanto permitindo que o usuário escrevesse com o dedo sobre a superfície multi-touch, quanto utilizando o Thumwheel de maneira similar à executada com valores numéricos.
Em face de a extrema facilidade relatada por os usuários com relação a o acesso de opções do menu uma alternativa para a entrada de dados seria utilizar um painel numérico no formato de uma calculadora sobre a mesma superfície dos menus.
Em visualização de imagens médicas o recurso utilizado para aumentar ou diminuir a precisão dos valores do janelamento poderia ser utilizado com outras finalidades.
Uma de elas seria para alterar a escala de qualquer objeto tridimensional na cena apenas aproximando ou afastando os dedos, também numa interação EyesOff.
Poderia- se ainda empregar o recurso utilizado para aumentar ou diminuir a precisão dos valores do janelamento (zoom-in e zoom-out, apresentados na seção posição, o sensor multi-touch serviria para controlar o tamanho desta probe.
