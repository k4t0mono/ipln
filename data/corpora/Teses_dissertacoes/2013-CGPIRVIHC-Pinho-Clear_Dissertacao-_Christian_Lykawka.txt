Este trabalho tem como objetivo estudar o processo de conversão da informação de profundidade de uma cena capturada de um ambiente real, numa representação tátil através de geradores de tato (haptic display).
Como resultado do estudo, foi desenvolvida uma interface que poderá auxiliar deficientes visuais a se deslocarem em ambientes contendo obstáculos.
Primeiramente são apresentadas técnicas de captura e obtenção de profundidade de cena, exemplos de dispositivos hápticos e tecnologias já existentes de apoio a deficientes visuais.
Por fim, as etapas de construção e testes da interface desenvolvida são detalhadas.
O estudo resultou num protótipo funcional que mapeou a profundidade de cena diretamente ao display háptico da forma mais imediata possível, em termos de conversão de dados, promovendo o processo de substituição sensorial de visão para tato.
Palavras Chave: Profundidade de Cena, Kinect, Dispositivo Háptico, Display Háptico, Substituição Sensorial, Deficiência Visual.
A tarefa de se deslocar num ambiente contendo obstáculos utiliza primariamente o sentido da visão, tornando- se mais difícil para aqueles indivíduos que possuem deficiência visual.
As tecnologias hoje existentes podem auxiliar estas pessoas na sua locomoção, fazendo, por exemplo, a transformação da informação visual em sensação tátil.
Esta conversão de um sentido humano para outro, utilizando- se de dispositivos especiais, é chamada de substituição sensorial.
De entre as tecnologias mais adequadas para promover a substituição sensorial, destacam- se aquelas especializadas na captura e processamento de imagens e que permitem codificar uma representação digital do ambiente real.
A evolução nesta área de estudo faz com que os seus resultados apareçam de forma cada vez mais precisa, mesmo quando são utilizadas tecnologias consideradas de baixo custo e acessíveis para a população em geral, como micro câmeras digitais computadores portáteis.
Algumas destas representações digitais do ambiente são tridimensionais (3 D) embora sejam geradas a partir de imagens (2 D), como por exemplo, através do processamento da informação estereoscópica proveniente de múltiplas câmeras que filmam o ambiente simultaneamente.
Estas técnicas muito se assemelham aos processos da visão humana e da percepção de formas geométricas, volumes e distâncias entre o sujeito e objetos do mundo real e destes entre si.
A partir de a disponibilidade de uma informação 3D do ambiente, adquirida por visão computacional, é possível transformar- la e exibir- la através dos dispositivos chamados displays hápticos1 que provocam sensação de tato em seu usuário.
Com este tipo de dispositivo, o usuário pode, após um período de treinamento, sentir através do tato as informações de geometria captadas do ambiente e apresentadas no display, em tempo real, experimentando um processo de substituição sensorial potencialmente interessante para aqueles usuários portadores de deficiência visual.
O adjetivo háptico significa &quot;relativo ao tato», um &quot;sinônimo de tátil».
Com um sistema deste tipo acoplado ao corpo, um deficiente visual poderia, por exemplo, receber dados que o auxiliariam na tarefa de desviar de obstáculos a sua frente.
Para adaptar o display háptico ao corpo do usuário podem ser usados cintos, coletes, capacetes, luvas, meias, ou outros artefatos que podem ser vestidos por este usuário.
Em este contexto, o presente trabalho apresenta inicialmente um estudo abrangendo três áreas distintas:
Algoritmos de Visão Computacional com o objetivo específico de extrair informação 3D do ambiente;
Percepção tátil humana e o uso de displays hápticos em aplicações de auxílio à navegação;
E trabalhos relacionados à substituição sensorial em usuários deficientes visuais.
Por fim, são detalhados os processos de construção e testes de um protótipo que reúne características das três áreas de conhecimento abordadas.
Em esta parte final do estudo também estão descritos os procedimentos de prototipação, as tecnologias escolhidas, as especificações de sistema e a aplicação de testes com usuários.
Como resultados, o protótipo funcional pôde mapear a profundidade de cena para o display háptico.
Isto permitiu, por exemplo, que participantes dos testes executassem tarefas de navegar num percurso predefinido somente utilizando as informações geradas neste equipamento para se guiar.
De entre os participantes dos testes havia videntes e cegos, portanto também foi possível comparar os resultados destes dois grupos entre si.
A captura e obtenção da profundidade da cena é objeto de estudo fortemente vinculado à Visão Computacional.
Este processo possui aplicações para orientar máquinas dentro de o campo da robótica, para segmentar imagens digitais, para auxiliar usuários a navegarem em ambientes reais ou virtuais e, mais recentemente, aplicações voltadas ao entretenimento.
Para este estudo, são abordados trabalhos correlacionados a métodos e dispositivos capazes de extrair tal informação do ambiente real.
O objetivo é entender os conceitos envolvidos e as possibilidades na obtenção deste tipo de dado que alimentaria um sistema que promova a substituição sensorial, baseado em profundidade de cena.
Para entender este processo, é importante entender como é feita a representação da profundidade da cena.
Ela é normalmente descrita por uma imagem em a qual cada pixel registra, através da intensidade de sua cor, a distância de um ponto do mundo real registrado neste pixel, até a posição a partir de a qual foi capturada a imagem (posição da câmera).
A este tipo de imagem dá- se o nome de Mapa de Profundidade.
Em cenas geradas sinteticamente através de Computação Gráfica é possível extrair um mapa de profundidade preciso do ambiente virtual.
Isto porque estes mapas já fazem parte do processo computacional que sintetiza estas cenas, através das técnicas conhecidas como z-buffer ou depth-- buffer Em o exemplo da Figura 1, pode- se observar uma imagem sintética à esquerda e seu respectivo mapa de profundidade à direita (depth-- buffer).
Em a convenção utilizada no mapa percebe- se que os pixels de maior intensidade estão representando as áreas mais próximas do observador.
Já as partes mais distantes da cena aparecem em preto, pois a calibração do software que a gerou indicou uma distância máxima a ser computada.
Autor Em ambientes reais, entretanto, a geração de um mapa de profundidade depende de métodos específicos para extrair esta informação a partir de outros meios.
Três das principais tecnologias de aquisição da profundidade de uma cena real são os mapas de disparidade, calculados a partir de um par de &quot;tempo de voo «que um feixe Laser leva para atingir um ponto específico e os sistemas baseados em luz estruturada, que projetam um padrão de luz na cena para utilizar como referência durante uma posterior captura.
A seguir serão abordadas tais estratégias para a obtenção da profundidade de uma cena real.
A partir deste princípio, existem técnicas que processam as imagens obtidas de pontos de vista diferentes, buscando identificar um mesmo ponto nas duas imagens.
Quando este ponto comum é encontrado nas imagens, o afastamento entre eles, chamado de disparidade, pode ser calculado.
Esta disparidade fornece também a informação de profundidade, pois quanto mais distante o objeto estiver das câmeras, maior será a diferença (disparidade) detectada, comparando- se as múltiplas imagens, na região em que este objeto aparece.
Portanto, a entrada destes métodos que medem a distância de objetos por disparidade são as múltiplas imagens em 2D capturadas da mesma cena, e que serão processadas para gerar um mapa de disparidade.
Como saída, o mapa gerado correlaciona a disparidade encontrada entre os pixels, com a profundidade de cena.
Em a Figura 3, as duas imagens superiores são da mesma cena, mas feitas a partir de duas câmeras ligeiramente afastadas.
Em a imagem inferior à esquerda, aparece o mapa de disparidade gerado por o o algoritmo R-SMW e, à direita, o mapa de profundidade da cena de referência.
A diferença na precisão obtida como resultado final, quando comparado à imagem de referência, deve- se a calibração das câmeras, configuração das diferentes etapas do processamento das imagens, dos algoritmos, e da quantidade de detalhes presentes na cena.
Em este caso calibração refere- se ao conhecimento dos parâmetros óticos das câmeras, como ângulo de visão, nível de distorção radial, e à determinação da posição de uma em relação a a outra.
Com relação a a busca da correlação entre as múltiplas imagens adquiridas de uma cena, isto pode ser feito a partir de diferentes estratégias.
É possível dividir tais técnicas entre aquelas baseadas em características aparentes nas imagens, que buscam por pontos de referência e formas detectáveis, ou em algoritmos baseados em informação de área, que consideram grupos de pixels vizinhos para criar uma assinatura e utilizar- la em processos de varredura.
Tais processos são considerados como uns dos mais amplamente pesquisados na área de visão computacional, com resultados qualitativos e computacionais diversos, conforme ilustrado na Figura 4.
Disparidade Fonte: De entre os desafios na tentativa de se correlacionar múltiplas imagens reais extraídas da mesma cena estão as variações fotométricas2 e as regiões com poucos detalhes, como ilustrado na Figura 5.
Estes problemas dificultam a busca por a correlação entre os pixels das duas imagens, resultando num mapa de disparidade não condizente com a profundidade de cena real.
Imagens Reais Fonte: Autor Outra característica dos mapas de disparidade é que seus algoritmos podem requerer um tempo de processamento alto, que dependendo da capacidade do hardware disponível, pode inviabilizar sua geração em tempo real.
Existem tecnologias que extraem mapas de profundidade da cena real estimando o tempo que uma luz emitida a partir de um ponto conhecido leva para atingir os objetos do ambiente e retornar a uma câmera, igualmente posicionada em local conhecido.
O princípio básico de funcionamento é semelhante ao de um radar, com um emissor de sinal e um receptor, que neste caso, são uma fonte de luz e uma câmera (Figura 6).
Em os pontos mais distantes da câmera, o tempo entre a emissão e recepção da luz é maior, ao contrário de os pontos mais próximos.
A fim de Por estarem em pontos diferentes no espaço, as câmeras estarão expostas a intensidades diversas de luminosidade e isto potencialmente resultará em imagens que dificultam a busca da correlação.
Por exemplo, uma das câmeras pode receber luz solar direta enquanto a outra estar à sombra, mesmo que supostamente muito próximas entre si.
Este processamento deve operar na ordem de pico-segundos para obter precisão próxima a um milímetro de distância.
Outra técnica que permite a obtenção da profundidade de uma cena real é a utilização de luz estruturada (structured light).
O processo consiste na projeção de padrões conhecidos na cena (que introduz informação extra no ambiente) para então capturar- los com uma câmera.
As variações encontradas entre o padrão capturado por a câmera e uma imagem de gabarito são medidas, permitindo assim obter uma estimativa da distância entre os objetos e a câmera em si.
Estes padrões normalmente são projetados através de Laser no ambiente como uma nuvem de pontos, linhas paralelas ou uma grade (Figura 7).
Alguns desses sistemas também utilizam de variações de intensidade de luz ou codificação de cores ao longo de o padrão projetado para facilitar a posterior análise dos dados obtidos (Gattass &amp; Costa).
Esta técnica calcula a distância entre a câmera e os objetos da cena por triangulação de pontos.
De entre as informações previamente conhecidas para o cálculo, está o gabarito -- que pode ser adquirido por a captura de uma imagem com o padrão de luz sobre uma superfície plana, posicionada a uma distância e ângulo conhecidos em relação a a câmera.
A partir de a informação 2D do gabarito capturado, é possível estabelecer com antecipação a disposição dos seus pontos no espaço, durante este processo de calibração do sistema.
Após a calibração, quando se captura a imagem de uma cena com o Laser projetado sobre um objeto, o algoritmo segmenta a linha do Laser, e relaciona os pontos desta linha com os pontos da imagem do gabarito, sobrepondo as duas imagens.
Um dispositivo baseado nesta tecnologia é o Microsoft Kinect que possui um emissor de luz capaz de projetar um padrão pré-definido de pontos no ambiente utilizando Laser infravermelho e uma câmera sensível a este espectro de luz para capturar a informação em tempo real.
A obtenção da profundidade da cena é obtida através do modelo matemático descrito por Khoshelham.
3 Displays Hápticos Desde os trabalhos de Ernst Heinrich Weber originalmente publicados no século 19), a percepção tátil humana vem sendo estudada e mapeada a partir de a metodologia científica.
Utilizando um compasso de metal, Weber mapeou a capacidade humana de distinguir a localização e a distância entre dois pontos de contato na pele e, a partir de isto, constatou que existe uma variação na precisão dos resultados obtidos de acordo com a região do corpo em questão.
A fim de aprofundar estes resultados e também responder questões ainda em aberto, tais como a diferenciação entre grupos de homens e mulheres e quanto a a lateralidade do corpo, Weinstein obteve dados como os ilustrados na Figura 12, que apresenta o limiar da capacidade de uma pessoa do sexo masculino em distinguir dois pontos de toque simultâneos na pele, em diferentes regiões do corpo.
Observou- se que neste teste específico, além de os dados aparecem praticamente inalterados entre o grupo masculino e feminino, ambos os lados direito e esquerdo do corpo também apresentam limiares aproximados.
Este mapeamento identificou que regiões como mãos, pés e o rosto possuem, em média, limiares menores que um décimo daqueles amostrados nas regiões das pernas, braços e nas costas.
Também na década de 60, as pesquisas de Ronald T. Verrilo estabeleceram parâmetros a respeito de a sensibilidade da pele referentes a estímulos em função de a frequência vibratória, formato e área da superfície de contato.
Estes estudos para aferir limiares a partir de estímulos gerados por equipamentos eletrônicos por pressão e por vibração na superfície da pele apresentaram resultados que serviriam como base para o aperfeiçoamento dos dispositivos hápticos.
Décadas mais tarde, estudos apontam que os limites da resolução tátil humana estão presentes na área dos dedos, lábios e na superfície da língua.
A seguir serão abordadas pesquisas em tecnologias aplicadas a geração de tato com embasamento na fisiologia humana e em testes aplicados a grupos de usuários utilizando sistemas desta natureza.
Os dispositivos hápticos são equipamentos que têm como objetivo transmitir ao usuário sensações táteis em interações humano-computador que vão desde a simulação de forças contrárias ao movimento do operador (force feedback) até a simulação de textura em superfícies através de estímulos elétricos, por calor ou vibrotáteis (touch feedback).
Em a ampla maioria das aplicações que se utilizam desta modalidade sensorial (tato), ela acontece em conjunto à estimulação dos outros sentidos do usuário (principalmente visão e audição), nos sistemas ditos multimodais (Myles &amp; Binseel, 2007).
Em estas redundantes e/ ou complementares às modalidades sensoriais visual e auditiva.
A partir de as correlações encontradas nos diferentes tipos de fibras mecanorreceptoras identificadas no corpo humano, foi possível classificar como as estruturas fisiológicas relacionadas ao tato reagem a estímulos específicos, trazendo dados ainda mais direcionados ao desenvolvimento de interfaces hápticas.
A Tabela 1 resume algumas das características relevantes de entre as estruturas fisiológicas responsáveis por o tato humano, subdividindo- as em colunas de acordo com a velocidade em que se adaptam ao estímulo e em linhas que classificam sua profundidade em que são encontradas na pele.
A adaptação ao estímulo é uma das limitações existentes no sistema tátil, pois após a exposição prolongada aos estímulos a ele aplicados, o limiar de percepção é aumentado.
A fim de reduzir este efeito, estudos sugerem minimizar o tempo contínuo de geração desses estímulos.
Outro fenômeno observado na pele é chamado mascaramento, que pode ser espacial, temporal ou ambos.
Em esses casos, o estímulo gerado é sobreposto por o efeito de outro estímulo apresentado, causando dificuldade aos indivíduos em distinguir- los separadamente.
As soluções apontadas nas pesquisas baseiam- se na calibração das frequências e distâncias utilizadas na geração dos estímulos.
Existem diferentes alternativas em termos de tecnologia para o desenvolvimento de dispositivos hápticos.
A maioria de elas é baseada em células geradoras de tato, conhecidas como &quot;atuadores «ou também como tactors.
Para geração de estímulos vibratórios, os tactors classificados como Linear Resonant Actuators (LRA), utilizam um sistema capaz de oscilar um pistão linearmente no interior de uma bobina eletromagnética, constituindo- se, basicamente, em versões miniaturizadas de solenoides.
Um exemplo comercial destes tactors pode ser visto na Figura 13.
Estas células têm apenas três centímetros de diâmetro e geram estímulos na frequência de 250 Hz (à esquerdaà direita). (
Engineering Acoustics, Inc) Outra tecnologia para geração de tato através da vibração é chamada de Eccentric Rotating Mass (ERM), e explora a oscilação causada por a rotação de uma massa assimétrica em torno de o eixo de um motor.
Estes tactors são amplamente utilizados em aparelhos celulares, pagers e controles de videogames para transmitir sinais de alerta via feedback tátil para o usuário, e por este motivo, possuem muitas alternativas disponíveis no mercado.
A Figura 14 ilustra duas variações de forma, com um tactor ERM cilíndrico (à esquerda) e um tactor ERM &quot;panqueca «(à direita). (
Precision Microdrives Limited) Existem ainda outras tecnologias para a fabricação de células geradoras de tato por vibração, mas que ainda não estão amplamente difundidas no mercado.
Uma de elas utiliza o efeito piezelétrico, que é um fenômeno físico presente em alguns materiais tais como cristais de quartzo e cerâmicas especiais.
Estes materiais geram um campo elétrico enquanto estiverem sob a ação de um esforço mecânico.
Porém, o mais interessante a respeito destes materiais é que o processo também é válido quando invertido.
Com a aplicação de um campo elétrico sobre eles, é possível deformar o material fisicamente.
Isto permite gerar vibração se este processo de aplicação de energia eletromagnética for controlado.
A Figura 15 ilustra algumas das variedades já comercialmente disponíveis de tactors piezelétricos.
Outro exemplo são tactors que utilizam ar-comprimido para causar estímulos táteis.
Estes ainda apresentam um tempo de resposta lento e, portanto, limitantes para os tipos de sinais possíveis de serem apresentados aos usuários.
Existem soluções pneumáticas em fase de protótipos que exigem, por exemplo, um cilindro de CO2 para gerar a pressão necessária para movimentar os tactors.
Outra forma de geração de estímulos táteis, e que não envolve vibração, acontece através da aplicação de corrente elétrica diretamente na pele.
Os fatores de estudo neste caso são em relação a o tipo de eletrodo, distribuição da corrente elétrica e impedância no contato com a pele humana. (
Piezo Systems, Inc.) Os displays hápticos (haptic displays) são dispositivos responsáveis por transmitir informações para o usuário através de um ou mais tactors, dispostos em contato com o corpo.
A maioria das aplicações com dispositivos hápticos utiliza este feedback sensorial para complementar principalmente a modalidade da visão.
Em um trabalho de Van Erp foram desenvolvidos testes em ambientes de Realidade Virtual (RV) para avaliar a utilização de um display háptico na região do torso.
Este dispositivo foi projetado para apoiar os usuários a completarem tarefas num ambiente com informação visual reduzida, como por exemplo, sob a presença de névoa.
As tarefas foram propostas a um grupo de pilotos estudantes da Royal Dutch Airlines Flight Academy (KLS) e aconteceram dentro de um simulador de voo de helicóptero (RV).
Foi comprovado que, a partir de a utilização do dispositivo tátil transmissor de informações complementares a respeito de o ambiente, houve melhorias significativas no desempenho dos pilotos no simulador.
Foram aferidas colisões contra obstáculos do cenário durante as tarefas, utilizando grupos de testes com e sem a utilização do display háptico.
O dispositivo tátil transmitiu qual a proximidade dos obstáculos próximos, na forma de vibrações mais ou menos intensas.
Em as manobras horizontais do helicóptero, foram reduzidos em 27% o número de colisões no grupo de testes exposto ao feedback tátil, e reduções em 56% para colisões durante movimentos verticais do helicóptero.
O trabalho apresentado por Barros relata experimentos para medir o desempenho de diferentes grupos ao navegarem um robô em ambiente simulado (RV), com a tarefa de encontrar e coletar determinados objetos.
O intuito do trabalho foi entender a influência da informação tátil transmitida, de forma complementar, a usuários que estivessem tele-operando um robô, considerando que a informação primária disponível era visual.
A interface chamada de Collision--Proximity Feedback (CPF) foi responsável por transmitir ao operador qual era a distância dos obstáculos próximos ao robô.
Foram testadas duas implementações desta interface:
Uma totalmente visual;
E outra utilizando o dispositivo TactaBelt composto por oito tactors posicionados ao redor de a cintura.
Os grupos estudados foram subdivididos de entre as combinações possíveis, com e sem ambas as interfaces CPF, de acordo com a Tabela 2.
O desempenho dos usuários foi medido por o do número de colisões por minuto do robô com os obstáculos do ambiente, por os objetivos encontrados por minuto, por o total de objetivos encontrados ao final da tarefa, e por a qualidade dos esboços do ambiente desenhado após os testes.
Como resultados aferidos, a melhor compreensão a respeito de o ambiente (melhores esboços desenhados) e o menor número de colisões por minuto aconteceram nos grupos em que ambas as interfaces CPF (tátil e visual) foram empregadas.
O uso de displays hápticos também foi considerado eficiente para auxiliar pessoas durante o cumprimento de tarefas de navegação com pontos de referência (em Inglês, waypoints) ao longo de um percurso.
Em os experimentos de van Erp, foram feitos experimentos em situações operacionais, ou seja, sem a utilização de simuladores, com o objetivo de guiar o grupo de testes por uma trilha pré-determinada.
Os meios de locomoção utilizados foram caminhada a pé, voo por helicóptero e pilotando um barco.
O posicionamento dos tactors foi feito na região do torso, ao redor de a cintura, com uma resolução capaz de descrever trezentos e sessenta graus a partir de oito pontos dispostos equidistantes entre si.
Os resultados da utilização do display tátil nas tarefas descritas foram diretamente comparáveis à navegação por mapa e bússola ou por dispositivo eletrônico com GPS, mesmo em situações que apresentem sobrecarga de informação visual, stress ou baixa visibilidade.
A Figura 18 representa as diferenças de rota que o piloto de um helicóptero obteve ao passar por quatro pontos determinados no plano de voo.
Em o topo, a figura ilustra, na parte superior, a rota traçada a partir de instruções verbais vindas de um navegador (copiloto).
Em a parte inferior, a figura mostra os resultados da mesma rota, porém com a utilização do display háptico que indicou constantemente a direção dos pontos de referência ao longo de o trajeto.
Em um estudo anterior, o mesmo autor havia demonstrado que a região do torso possui três vantagens importantes na escolha do posicionamento do display háptico no corpo para tarefas de navegação:
Por ser ampla, não necessita da minimização do tamanho dos tactors nem os limita a ser um grupo reduzido;
A informação apresentada através do torso não inviabiliza ações feitas por o usuário através das mãos;
O torso por ser um volume, a priori é uma região interessante para representações de informações 2D e 3 D, sendo estas geográficas ou navegacionais.
Este estudo traz também um caso prático de desenvolvimento de um display háptico capaz de transmitir informação direcional ao usuário por o intermédio do tato.
Em ele, é especialmente interessante a descrição de um método que permite a correta calibração do equipamento.
A Figura 19 ilustra o experimento de calibração em que, para cada tactor ativado, os usuários tiveram que indicar qual a direção correspondente pode ser percebia, dentro de um raio de 270 graus.
Este trabalho também destaca que, na busca por precisão ideal durante a apresentação de estímulos vibrotáteis na região do abdômen, foi observado que ambos os lados do cérebro são privilegiados simultaneamente, pois esta área passa por a sobreposição de dermátomos3 no plano sagital (que divide o corpo em duas partes iguais).
Além disso, o abdômen é destacado como centro sinestésico da &quot;ego localização «por ser um ponto de referência para os membros e a cabeça -- que rotacionam em relação a o torso (Cholewiak, Brill,&amp; Schwab, 2004).
Assim, a linha média do tronco passa a dividir o espaço perceptível sem ser influenciada por as variações presentes nos movimentos dos olhos e da cabeça.
Em estudos com células hápticas modulares posicionadas ao redor de a cabeça, Cassinelli demonstra que é possível promover a resposta motora para desviar de objetos não visíveis e em rota de aproximação.
Os testes foram feitos com pessoas não treinadas e vendadas utilizando o display háptico em questão.
Quando um objeto era projetado em direção a a cabeça do usuário, mesmo vindo de trás, a reação de esquiva foi manifestada através de estímulos exclusivamente gerados por o dispositivo.
4 Tecnologias de Apoio a Deficientes Visuais A substituição sensorial pode ser estimulada entre sistemas sensoriais diferentes, como no exemplo do braile, em o qual o toque substitui a leitura feita normalmente por a visão.
A própria escrita pode ser considerada uma das primeiras substituições sensoriais criadas por o homem, pois mapeia através da leitura visual as informações tipicamente auditivas das palavras faladas.
Desde a década de 60 são realizados estudos a respeito de a substituição sensorial a partir de o tato, em sua maioria voltada para o auxílio aos deficientes visuais.
Inicialmente inspirados na capacidade destes indivíduos em ler com os dedos através do método braile, trabalhos foram dedicados ao desenvolvimento de dispositivos que convertem informações textuais em estímulos táteis.
A Figura 21 ilustra trabalhos pioneiros, à esquerda, utilizando um display háptico formado por uma matriz de 24x6 células táteis para leitura de texto convertido diretamente de impressos e, à direita, o mesmo sistema adaptado para converter imagens do ambiente por uma câmera.
Fontes: E Um dos parâmetros de avaliação na conversão de texto impresso para tato é a quantidade de palavras por minuto (ppm) que o usuário é capaz de ler corretamente.
Em o sistema de Bliss e Linvill, por exemplo, usuários treinados durante sete meses puderam ler em velocidades de até 50 ppm enquanto usuários altamente treinados em braile são capazes de ler 180 ppm.
Já no estudo para capturar imagens do ambiente via câmera e representar- la na forma de tato, a matriz tátil utilizada por Bliss foi de 12x12 células e o método de avaliação foi baseado na tentativa de identificação de geometrias básicas (triângulos, diamantes, cruzes, círculos, quadrados retângulos) desenhadas num quadro-negro, aproximadamente 2,5m de distância dos usuários.
Destaca- se que neste caso foram transmitidas informações que vão além de caracteres e textos como objetos de estudo na promoção da substituição sensorial visão-tátil (em Inglês, Tactile-visual Sensory Substitution -- TVSS) (Bach-y-Rita, Collins, Saunders,&amp; White, 1969).
Ainda na década de 60, estudos com métodos invasivos testaram estímulos elétricos diretos no córtex visual para posteriormente produzir um equipamento capaz de capturar imagens em vídeo e transmitir- las aos pacientes cegos.
A Figura 22 ilustra como uma imagem capturada por uma câmera (A) é filtrada para conter apenas as bordas detectáveis (B) (Dobelle, 2000).
Em este experimento o objetivo era descobrir qual a melhor forma de transmitir a imagem digital para o córtex e este tipo de imagem apresentou melhores resultados.
Em a Figura 23 estão ilustrados os eletrodos posicionados no paciente por procedimento cirúrgico (imagem em raios-X à esquerda), uma micro câmera afixada aos óculos (à direita) e computador portátil para processamento das imagens (ao centro).
Estas partes compõe o sistema completo de visão artificial contendo descrito por Dobelle.
Este trabalho, embora utilize uma técnica invasiva, é considerado estado da arte em termos de resultados obtidos, pois permitiu que um usuário cego, após anos de treinamento, pudesse transitar em Nova Iorque e em outras cidades utilizando transporte público.
Um ponto fraco do sistema, relatado por os usuários foi a dificuldade em distinguirem distâncias entre os objetos presentes no ambiente, fato que levou os pesquisadores a iniciarem testes com medições de distâncias com aparelhos ultrassônicos que poderiam modular a intensidade das regiões da imagem considerando a proximidade dos objetos em si.
O motivo é que a representação através dos contornos das imagens não contém informações relativas à profundidade da cena.
Mais recentemente, a tecnologia chamada BrainPort da empresa Wicab está próxima a se tornar produto comercial.
Ela é capaz de projetar imagens em tempo real na língua do usuário, por estímulos eletro-táteis.
O dispositivo é composto por uma matriz de 400 tactors que exibe na superfície da língua, imagens captadas por a câmera montada nos óculos do usuário (Figura 24).
Ele converte imagens 2D para uma matriz de tactors que é colocada em contato com a língua do usuário -- uma das partes mais sensível ao tato no corpo humano.
Assim como o trabalho descrito por Dobelle, o BrainPort utiliza a exibição dos contornos dos objetos da cena a serem transmitidos ao display háptico.
Os resultados apresentados por o BrainPort são, de certa forma, similares aqueles descritos por Dobelle a respeito de a transmissão direta de imagens ao córtex visual, pois usuários treinados também puderam identificar formas geométricas, manipular objetos e até utilizar o sistema como auxiliar para a sua mobilidade.
A informação gerada a partir de a utilização de filtros de imagens que destacam contornos e bordas de imagens capturadas por câmeras digitais, existente no trabalho de descrito por Dobelle e no BrainPort, também pode ser exibida num display háptico posicionado no tórax do usuário, como ilustra a Figura 25.
A imagem inicialmente captada por a câmera (a) é então filtrada por algoritmos de detecção de bordas (b).
O resultado final é mapeado para uma matriz de tactors (c) que exibirá ao usuário a informação no display háptico formado por a matriz de 8x6 tactors.
Com relação a a conversão da profundidade de cena para dispositivos hápticos, existe um trabalho experimental para a criação um equipamento que auxilie a navegação a partir de a construção de rotas em ambientes com obstáculos utilizando um par de câmeras estéreo.
Em ele, é possível alternar entre um modo que guia o usuário ao longo de a rota e outro que é ativado quando este estiver em situação de uma colisão eminente com algum obstáculo.
A conversão à modalidade tátil neste caso é feita por um colete que contém quatro tactors distribuídos nos ombros e nas laterais dos quadris, que informa quando o usuário deve girar o corpo durante o percurso.
Em outro estudo, que também se utiliza da informação de profundidade da cena, esta é convertida para um cinturão de tactors que são ativados de acordo com a proximidade dos obstáculos próximos ao usuário.
Os casos abordados demonstram aplicações que visam ao auxílio de deficientes visuais, seja através de estímulos táteis ou aqueles diretamente enviados ao córtex cerebral, e que transformam informações originalmente visuais (através de câmeras digitais) por o processo de substituição sensorial.
É importante se observar que o treinamento para qualquer tipo de substituição sensorial requer adaptações que contam com a plasticidade do cérebro humano.
Isto requer dedicação considerável por parte de os indivíduos participantes em sessões de treinamento e adaptação, ou seja, um novo aprendizado.
Os sentidos naturais humanos são desenvolvidos durante anos ao longo de uma vida, portanto é esperado que a substituição de eles também exija treinamento adequado (Kaczmarek, Webster, Bach-y-Rita,&amp; Tompkins, 5 Análise dos Trabalhos Abordados A partir de a análise dos trabalhos apresentados nos capítulos 3 e 4 que abordam a utilização de displays hápticos, foi possível classificar- los a respeito de o posicionamento dos tactors no corpo, da respectiva resolução tátil, se a aplicação era multimodal (dependente de outros sentidos além de o tato) e de seus resultados obtidos.&amp;&amp;&amp;
A Tabela 3 contém a listagem dos trabalhos abordados para a análise ser apresentada a seguir.
Com relação a a disposição física no corpo dos usuários e tipo de estímulo tátil utilizado, a Tabela 4 traz a resolução horizontal e vertical dos tactors e suas frequências de vibração.
Observa- se que a forma mais comum de geração de estímulos táteis ocorreu através de células que produzem vibração, com a maioria das aplicações apresentando dados dispostos no plano horizontal com relação a o usuário.
Apesar de que três dos trabalhos citados possuem resolução vertical maior que um, apenas dois de eles buscaram transmitir a informação vertical a respeito de o ambiente (altura dos objetos).
Os demais casos (inclusive T6) transmitiram informações em torno de o eixo longitudinal do corpo humano, exclusivamente.
As frequências de vibração mais comuns de entre aquelas informadas permaneceram na faixa de 142 Hz e 300 Hz, o que indica a intenção dos pesquisadores em estimular a camada de pele mais profunda, a partir de os valores mencionados na Tabela 1.
Já o posicionamento dos tactors no corpo concentra- se na cintura e tórax, provavelmente porque a maior parte dos trabalhos citados exige que os usuários utilizem os membros para operar ou para deslocarem- se no ambiente.
Em a Tabela 5, estão listadas a caracterização dos de sistemas multimodais, quais os tipos de informação transmitidas por meio de o tato e quais técnicas de obtenção da informação original (fonte) foram catalogadas.
Sistemas multimodais foram utilizados quando o tato transmitiu informações além de a visão e audição a fim de melhorar o desempenho dos usuários em tarefas de navegação.
Com exceção do T8, os demais trabalhos focaram na codificação de distâncias e direções de objetos ou alvos em relação a o usuário.
Como fonte de dados a ser convertida para o tato (exibida no display háptico) houve uma variação interessante que incluiu o uso de simuladores e dados criados por o computador a partir de ambientes virtuais e o uso de hardware específico como GPS, ultrassom e câmeras digitais.
Dois dos trabalhos citados (T5 e T6) basearam- se na fonte de informação a respeito de a profundidade de cena com mapas de profundidade.
O presente trabalho desenvolveu um protótipo capaz de adquirir a profundidade de cena (por Visão Computacional) e exibir- la através de um dispositivo tátil em tempo real, utilizando componentes atualmente disponíveis no mercado.
Este protótipo permitiu serem transmitidas informações do ambiente ao usuário, por substituição sensorial (visão convertida para tato).
Este tópico aborda o processo do desenvolvimento, iniciando- se por a análise dos trabalhos abordados para então detalhar o equipamento construído e os procedimentos de testes efetuados.
Os trabalhos listados na Tabela 3 foram utilizados como fonte de referência durante o desenvolvimento da arquitetura do protótipo e escolha dos componentes.
Os trabalhos T5 e T6, por trabalharem com a navegação em ambientes utilizando o mesmo tipo de substituição sensorial, e por explorarem a profundidade de cena, inspiraram a configuração ilustrada na Figura 26.
Em ela são descritos os componentes de um protótipo ideal, composto de um óculos, chapéu ou boné com um par de micro-câmeras acoplada a ser utilizado por o usuário, responsável por a captura da profundidade de cena.
Estas informações então são enviadas ao display háptico, que é vestido por o usuário.
Este possui a forma de uma cinta a ser posicionada na região do abdômen.
A conversão dos dados obtidos por as câmeras e o controle dos tactors do display ocorre na unidade de processamento que idealmente deve ser um dispositivo portátil, como, por exemplo, um smartphone.
Opcionalmente, um controle remoto permite habilitar e desabilitar o display háptico, a qualquer momento (caso contrário, isto poderia ser feito diretamente na unidade de processamento).
Autor A escolha por a região do torso foi fundamentada principalmente nos trabalhos T1, T2 e T3 (de van Erp) que demonstraram ser possível a codificação de distância e direção, tendo como alvo esta região do corpo.
Isto também permite a liberação de braços e pernas para ações de locomoção e de manipulação de objetos.
Para este trabalho, houve a necessidade em se desenvolver um display háptico específico, já que não foram encontradas alternativas prontas no mercado com as características aqui descritas.
O display háptico desenvolvido é formado por uma matriz de 7x5 tactors que cobre a área do abdômen com uma densidade de tactors similar aquela encontrada nos trabalhos anteriores listados na Tabela 4.
O espaçamento entre tactors utilizado na composição da matriz foi de cinco centímetros na direção horizontal e quatro centímetros na direção vertical.
Autor A Figura 28 é uma foto do display háptico desenvolvido com (A) microcontrolador e (B) cinta com tactors.
Autor A cinta é feita do material chamado Neoprene e recebeu uma camada de Velcro costurada para permitir o posicionamento dos tactors com maior liberdade durante a construção e utilização do protótipo.
Autor Em o display háptico desenvolvido, cada célula tátil (tactor) é um motor de corrente contínua (DC) que produz vibração por Rotação de Massa Excêntrica (Eccentric Rotating Mass, ERM), similar ao motor à esquerda na Figura 14.
Os motores utilizados neste trabalho foram retirados de aparelhos celulares descartados (sucata), já que nestes equipamentos existe um motor deste tipo que é responsável por o efeito de vibração do telefone.
Cada motor recebeu um encapsulamento usinado em Poliacetal (Tecaform) para isolar seu eixo e massa excêntrica do contato com o corpo (em detalhe na Figura 30).
Esta etapa se deu necessária devido a o fato de que estes motores foram extraídos de telefones celulares e, portanto, não possuem nenhum tipo de blindagem original.
Autor A matriz de motores do display háptico é controlada por um microcontrolador Arduino.
Este hardware foi programado para responder a um protocolo de controle especificamente desenvolvido durante este trabalho, descrito na seção 6.4.
Um circuito eletrônico auxiliar também foi desenvolvido para suprir a alimentação necessária aos motores da matriz.
Para controlar a intensidade de cada tactor individualmente, o software de controle teve que variar a potência dos motores.
Em um circuito eletrônico com portas de saída analógicas, é possível controlar a intensidade de um motor DC a partir de a tensão exata a ser transmitida, já que estas portas permitem determinar arbitrariamente qual a voltagem deve alimentar cada tactor.
Assim, quanto menor a tensão, mais baixa a velocidade de rotação do motor e consequentemente, menor será a vibração.
Já quando a tensão máxima é utilizada, estes motores passam a girar em frequência máxima e transmitem assim a sua vibração mais intensa.
Em o caso deste trabalho, o microcontrolador Arduino utilizado não possuía portas analógicas suficientes para controlar os 35 motores desta forma.
Como alternativa, foi programada a técnica de modulação por largura de pulso (Pulse Width Modulation, PWM) utilizando apenas as portas digitais deste microcontrolador.
Em esta técnica, o sinal digital passa a controlar a frequência em que a alimentação do motor esta está ligada ou não, ao longo de o tempo, e em alta velocidade.
Com relação a a captura da profundidade da cena foi observado que, das três técnicas abordadas no Capítulo 2, cada qual possui características próprias em termos de custos computacionais, componentes eletrônicos especializados e limitações técnicas.
Os mapas de disparidade podem ser obtidos a partir de a combinação de câmeras digitais comuns e um processador de uso geral.
Este processador deve fazer operações de varredura das imagens ao ponto de correlacionar- las através de processos computacionais, em tempo real.
Estes processos, entretanto, são de alto custo computacional e também apresentam limitações relacionadas a diferenças fotométricas e de falta de detalhe em regiões específicas das imagens capturadas.
As câmeras do tipo time-of-flight (ToF) são desenvolvidas com hardware específico, capaz de processar sinais refletidos por o ambiente (processo descrito na seção 2.2).
O emprego desta tecnologia é atualmente limitado por o alto custo dos seus processadores especializados.
No caso de os sistemas baseados em luz estruturada, estes utilizam uma técnica similar aos mapas de disparidade, porém com a projeção de padrões previamente conhecidos no ambiente real (conforme abordado na seção 2.3).
Um dos desafios desta técnica é fazer com que a projeção de padrões utilize um espectro de luz com o mínimo de interferência dos fatores externos ao sistema.
Por exemplo, a utilização da luz infravermelha na projeção de padrões previamente conhecidos no ambiente não interfere na visão humana, porém apresenta limitações em ambientes externos devido a o fato da luz solar também estar neste espectro de luz.
Este tipo de &quot;ruído «pode inviabilizar a utilização de um equipamento baseado nesta tecnologia na tentativa de obtenção da profundidade de cena durante uma caminhada à luz de o dia.
Portanto, considerando as três técnicas estudadas, numa situação ideal os sistemas híbridos seriam os mais aptos a combinar pontos fortes de cada um dos três métodos descritos.
Assim, seria possível capturar um mapa de profundidade de cena com maior fidelidade e em ambientes mais adversos.
Um exemplo deste tipo de abordagem acontece a partir de a utilização de uma câmera do tipo ToF, combinada com diversas câmeras convencionais para geração de mapas de disparidade.
Para fazer a captura da profundidade de cena no protótipo desenvolvido, o dispositivo Kinect foi escolhido como uma alternativa de baixo custo e amplamente acessível em termos de hardware e de bibliotecas de software.
Sua tecnologia baseada em luz estruturada pode operar em ambientes internos e oferece facilidades interessantes para, pelo menos, a criação de protótipos e estudos preliminares.
O processo de conversão dos dados adquiridos por o Kinect em informações táteis exibidas no display háptico foi feito por um computador portátil, baseado no sistema operacional Microsoft Windows.
O protótipo desenvolvido utilizou componentes conforme ilustra a Figura 31.
A utilização de partes facilmente encontradas no mercado proporcionou a integração rápida dos componentes descritos na seção 6.1, para fins de prototipação.
Autor Em os estágios iniciais do desenvolvimento do protótipo, uma matriz de 7x5 Leds foi utilizada ao invés de os tactors, com o objetivo de facilitar a programação do Arduino (Figura 32).
Assim foi possível identificar visualmente o mapeamento das portas do microcontrolador e implantar o protocolo de comunicação que permitiu a utilização da técnica de PWM para controlar a intensidade de cada saída digital.
Autor O protocolo de comunicação entre o computador e o microcontrolador Arduino é unidirecional, pois o display háptico apenas recebe comandos de entrada.
Esta comunicação ocorre na faixa de frequência entre 25 Hz e 30 Hz, utilizando um protocolo composto por pacotes de dados enviados que possuem um caractere que indica o seu início e uma sequência de 35 valores (caracteres) que informam a intensidade de cada célula da matriz, iniciando- se do topo à esquerda e descendo, linha a linha, conforme ilustrado na Figura 33.
Autor O protocolo desenvolvido suporta seis níveis de intensidade para cada célula, codificados por os caracteres ASCII de &quot;A «até &quot;F», sendo que o caractere &quot;A «representa a maior intensidade e o caractere &quot;E «representa a intensidade mínima e &quot;F «representa a célula desligada.
Já o caractere &quot;Z», demarca o início do pacote.
Exemplificando, um quadro composto por a sequência de caracteres &quot;ZAFFFFFAFFFFFFFFFFAFFFFFFFFFFAFFFFFA «coloca as células dos quatro cantos da matriz e a célula central em potência máxima, enquanto as demais permanecem desligadas.
A Figura 34 ilustra como esta sequência de caracteres fica disposta na matriz do display.
Autor Os quadros contendo a profundidade da cena são capturados na resolução de 320x240 pixels por o Kinect e a conversão redimensiona- os para 7x5 pixels.
Além de a conversão entre as resoluções de entrada e de saída, o software desenvolvido mapeia as distâncias dos objetos para a intensidade de cada tactor.
Cada pixel adquirido por o Kinect representa a distância entre o objeto e o plano da câmera, na faixa entre 100 cm e 300 cm.
Distâncias fora de esta faixa são informadas como &quot;indeterminadas «por o dispositivo e, infelizmente, não são diferenciadas quando estas ocorrem por exceder o limite inferior ou superior.
A conversão entre distâncias obtidas por o Kinect para a intensidade dos tactors pode ser calibrada neste protótipo e é objeto de análise na seção 8.1 deste documento.
A Figura 35 contém dois exemplos que ilustram o quanto este processo de conversão resulta numa matriz consideravelmente abstrata, quando comparada à imagem originalmente adquirida.
Isto acontece devido a grande perda de informação proveniente da redução de resolução entre a imagem obtida do Kinect e a saída para o display háptico.
Autor 7 Teste-Piloto Durante o desenvolvimento do protótipo, foi executado um teste-piloto para auxiliar no processo de calibração do equipamento.
Três aspectos específicos foram abordados e serão explicados a seguir, sendo estes a percepção da intensidade dos tactors, a discriminação de pontos da matriz e a percepção de padrões de movimento.
Cada um destes aspectos foi testado separadamente, pois estão relacionados a características distintas no processo de substituição sensorial em questão.
Com o objetivo de concentrar os testes no display háptico, sem a interferência do equipamento de captura da profundidade da cena, o display foi controlado diretamente por comandos gerados por o computador, em tempo real.
Desta forma, os processos de obtenção e de conversão da profundidade de cena foram excluídos do conjunto de variáveis avaliadas nesta etapa.
Este teste foi aplicado para um conjunto total de 21 participantes, de entre os eles dois deficientes visuais.
O tempo de cada sessão de testes desta etapa foi determinado para que não ultrapassasse 15 minutos.
As próximas seções deste capítulo descrevem o estudo piloto, apresentando a metodologia dos testes.
Inicialmente é descrita a preparação do usuário, seguida da metodologia de avaliação de cada um dos aspectos (seções 7.2, 7.3 e 7.4).
A o final, é apresentada uma avaliação dos resultados (seção 7.5).
