As redes móveis ad hoc são caracterizadas por a alta mobilidade, baixa largura de banda devido a as limitações do meio de transmissão wireless e por a escassez de energia dos nodos, razões por as quais a topologia dessas redes sofrem alterações imprevisíveis reduzindo diretamente a taxa de entrega de pacotes na rede.
Em este trabalho é destacada a atividade de roteamento em cenários de mobilidade, pois construir protocolos de roteamento que garantam boa taxa de entrega de pacotes em tal ambiente é um dos principais desafios em redes ad hoc, visto que uma rota eleita como a melhor num dado momento não existirá em outro.
Em este sentido propõe- se um novo critério de seleção de rotas para o protocolo de roteamento OLSR (Optimized Link State Routing) a fim de garantir melhores taxas de entrega de pacotes mesmo em ambientes de alta mobilidade.
Em esse critério, uma rota para um destino é selecionada se ela é a menor rota de maior grau de conectividade, o que difere do OLSR original que usa apenas o tamanho da rota como critério.
O grau de conectividade de uma rota é dado por a soma do grau de cada nodo desse caminho, ou seja, é dado por a soma da quantidade de vizinhos (enlaces) de cada nodo da rota.
Esse critério se beneficia do fato do OLSR fazer roteamento dinâmico salto- a- salto, o que permite que cada nodo intermediário, com base nas informações mais atuais de sua tabela de rotas, interfira na rota a ser utilizada no roteamento de pacotes, logo se cada nodo intermediário possuir um maior grau de conectividade, em caso de falhas de enlaces por causa de a mobilidade, aumenta- se a possibilidade de que mais rapidamente seja utilizado um caminho alternativo até o destino.
A versão do OLSR executando o critério proposto, chamamos de OLSR_ PD (OLSR based), ou seja, é a versão do OLSR que faz roteamento baseado no grau de conectividade do caminho.
Para avaliar o desempenho do OLSR_ PD foram realizadas simulações em que parâmetros como mobilidade e número de nodos variaram a fim de validar o funcionamento desse protocolo sob as mais variadas situações de mobilidade, tráfego e escalabilidade.
Os resultados experimentais das simulações mostraram que o OLSR_ PD alcança substancial aumento na taxa de entrega e de repasse de pacotes em relação a o OLSR original, com insignificante aumento no número de pacotes de controle na rede.
Palavras chaves:
Redes móveis ad hoc, grau de conectividade, redes wireless, OLSR.
As redes wireless são redes em que a transmissão de dados é feita por meio de ondas eletromagnéticas que se propagam por a atmosfera ou por o espaço, sendo uma alternativa às redes cabeadas por serem de fácil instalação nos mais variados ambientes.
O avanço das pesquisas nas áreas de telecomunicações e segurança de redes sem fio, somados à redução do tamanho e dos custos de dispositivos e equipamentos para redes wireless, têm provocado um rápido aumento do uso das redes wireless em todos os seguimentos da sociedade.
Segundo Kurose e Ross as redes sem fio podem ser classificadas em redes infra-estruturadas ou sem infra-estrutura.
Em as redes infra-estruturadas, os nodos são associados a uma ou mais estação base (ponto de acesso), que prestam serviços como, atribuição de endereço e roteamento.
Em este tipo de rede toda comunicação entre nodos é intermediada por a estação base, não havendo comunicação direta entre os nodos.
Redes wireless sem infra-estrutura, também conhecidas como redes móveis ad hoc ou ainda como MANET (Mobile Ad-hoc Network), são redes em que os nodos são móveis e capazes de se comunicar diretamente entre si, formando dinâmica e rapidamente uma rede sem fio temporária, sem a presença de estações base centralizadora.
Em MANETs cada nodo funciona como roteador e como estação, pois são capazes de descobrir e manter rotas para outros nodos da rede e ainda executar aplicações dos usuários.
Redes móveis ad hoc possuem algumas limitações em relação a as redes fixas, tais como:
Toda comunicação é feita por um meio não confiável e com altas taxas de erros;
Em redes MANETs a comunicação entre nodos pode ser feita de maneira direta ou por múltiplos saltos.
Em o primeiro tipo, cada nodo comunica- se apenas com nodos vizinhos que estiverem dentro de o alcance de sua transmissão de rádio.
Já no segundo, se dois nodos estão fora de o alcance do rádio um do outro e precisam se comunicar, todas as mensagens enviadas entre eles devem passar por um ou mais nodos intermediários que atuarão como roteadores.
Por causa de o limitado alcance do sinal de rádio dos nodos móveis, quase sempre a comunicação entre nodos é feita por &quot;múltiplos saltos».
Em redes MANETs onde a comunicação é feita por múltiplos saltos;
Os nodos podem se mover a velocidades constantes ou aleatórias;
É baixa a largura de banda disponível;
E onde há escassez de energia é constante mudanças na topologia da rede e consequentemente a quebra de enlaces (links) de comunicação.
Segundo Xue e Nahrstedt, desenvolver protocolos de roteamento para tal ambiente, que garanta altas taxas de entrega de pacotes com baixo consumo de recursos da rede, mesmo na presença de nodos ou links falhos, é um problema dos mais desafiadores em redes ad hoc.
Protocolos de roteamento são softwares que operam na camada de rede dos nodos roteadores de uma rede (dispositivos móveis em MANETs), os quais são responsáveis por escolher quais rotas serão utilizadas na comunicação entre dois nodos, com base nas informações das tabelas de roteamento de cada nodo.
À medida que ocorrem mudanças na topologia e links de comunicação se tornam falhos, as tabelas de roteamento dos nodos ficam desatualizadas por um período de tempo.
Pacotes em trânsito nesse período poderão ser descartados, visto que links foram quebrados e as tabelas de rotas dos nodos intermediários ainda não foram atualizadas.
O intervalo de tempo entre a ocorrência de alterações na rede até o reconhecimento das mudanças e a atualização das tabelas de rotas é chamado de &quot;latência de convergência».
Os protocolos de roteamento, quanto a a construção das tabelas de roteamento, podem ser classificados em três categorias:
Pró-ativos, reativos e híbridos.
Os pró-ativos mantêm em todos os nodos da rede uma tabela de rotas para todos os destinos conhecidos da rede e a cada mudança na topologia ou de tempos em tempos todas as tabelas de rotas em todos os nodos são atualizadas, começando por os nodos mais próximos às alterações (falhas), os quais informarão aos demais sobre as mudanças.
Protocolos pró-ativos têm como vantagem, o fato de que sempre que uma rota for requisitada estará disponível, todavia ao custo de consumir grande largura de banda com mensagens de controle para atualização de tabelas, o que tende a se agravar com o aumento da mobilidade dos nodos.
Os reativos constroem rotas apenas sob demanda, ou seja, apenas quando são requisitadas, porém, dependendo do tamanho da rede, a procura por rotas sob demanda pode acarretar demoras imprevisíveis.
Todavia consome menos recursos da rede com a troca periódica de mensagens de controle.
Já os protocolos híbridos são construídos contendo características dos pró-ativos e dos reativos.
Essas classes de protocolos serão melhor discutidas nas seções do Tanto os protocolos reativos quanto os pró-ativos sofrem degradação na largura de banda e apresentam altas taxas de perdas de pacotes em situações de alta mobilidade dos nodos, todavia, segundo Abolhasan E Royer e Toh, os próativos têm desempenho inferior aos reativos em cenários de alta mobilidade e alta densidade de nodos.
Várias técnicas e estudos têm sido apresentados a fim de melhorar o desempenho dos protocolos pró-ativos.
Uma técnica apresentada no OLSR (Optimized Link State Routing) introduz uma nova estratégia de propagação de reduzir ao máximo o número de nodos responsáveis por retransmitir as mensagens de controle na rede.
Em Abolhasan, foram analisados vários protocolos próativos e o OLSR é o que mostrou melhor escalabilidade e controle de overhead em cenários de mobilidade.
Segundo Jacquet, o OLSR é um protocolo de roteamento robusto, visto que se recupera rapidamente de falhas provocadas por causa de a mobilidade dos nodos e reage bem à latência de convergência provocada por as mudanças na topologia, pois o roteamento de pacotes é feito de maneira dinâmica salto- a- salto, o que permite que em caso de falhas em rotas, nodos imediatamente anteriores à falha possam interferir na rota de pacotes já em trânsito com base nas informações mais atuais de sua tabela de rotas.
Em este sentido, a priorização de rotas de maior grau de conectividade, como proposto neste trabalho, deve aumentar a probabilidade de trânsito em caso de mudança topológica.
Há na literatura várias propostas, como encontradas em Badis, Couto E Cordeiro, as quais visam melhorar o desempenho seleção dos conjuntos MPR ou na seleção de rotas.
Porém, para o critério de seleção de rotas, não foi encontrada proposta tal como sugerida neste trabalho.
O objetivo deste trabalho é apresentar e avaliar uma extensão ao protocolo de roteamento OLSR, propondo um novo critério para seleção de rotas a esse protocolo.
Em esse critério, em cada entrada na tabela de roteamento, o próximo nodo (próximo salto) em direção a um destino é selecionado se ele faz parte da menor rota de maior grau de conectividade, ou seja, primeiro é verificado se a rota encontrada é o menor caminho até o destino.
Depois, se existir mais de um caminho de mesmo comprimento é escolhido aquele que possui maior grau de conectividade, o que difere do OLSR original que usa apenas o menor caminho como critério.
A a versão do OLSR executando esse critério conectividade do caminho.
Esse critério se beneficia do fato do OLSR fazer roteamento salto- a- salto, visto que os nodos intermediários podem interferir na rota com base em informações mais atuais de suas tabelas de rotas.
A ideia básica é que, caso ocorram falhas na rota em uso e links dessa rota se tornem indisponíveis, o nodo imediatamente anterior a falha, sendo um nodo da rota de maior grau, deve ter maior probabilidade, se comparado a nodos de outras rotas, de calcular uma rota alternativa para o destino.
Paralelamente a isso, tendo detectado a falha, o nodo deve enviar uma mensagem Tc (Topology Control) a outros nodos, alterando a topologia da rede.
Nodos anteriores a este, na rota de dados, receberão a mensagem Tc e, por fazerem parte da rota de maior grau, tem maior chance de calcular uma rota alternativa para o destino, se comparados a nodos de outras rotas.
Assim, utilizando este critério, espera- se que os nodos da rota escolhida tenham maior probabilidade de encontrar rotas alternativas para um dado destinatário de dados, de tal forma que, o descarte de pacotes, devido a a mudança topológica durante o tráfego de dados, seja minimizado.
Como resultado da adoção desse critério esperamos que em cenários de mobilidade e constantes mudanças de topologia, seja reduzida a taxa de pacotes descartados, bem como o atraso fim-a-fim e consequentemente aumentando a taxa de entrega de pacotes com pouco ou nenhum aumento no overhead na rede, quando comparado à versão original do OLSR.
Para avaliar o desempenho do OLSR_ PD, este protocolo fora implementado no Ns-2 (Network Simulator), e foram realizadas simulações, em que parâmetros como mobilidade e número de nodos variavam a fim de validar o funcionamento desse protocolo sob as mais variadas situações de mobilidade, tráfego e escalabilidade.
Os resultados experimentais das simulações também são apresentados.
Este trabalho é dividido em seis capítulos, estando organizado da seguinte forma:
Em o Capítulo 1 é feita a introdução, onde são apresentados os objetivos e a motivação para a implementação do protocolo proposto.
Em o Capítulo 2 são apresentados os conceitos fundamentais para o trabalho, como classificações dos protocolos de roteamentos e trabalhos relacionados.
Em o Capítulo 3 é descrito o funcionamento do protocolo de roteamento OLSR e suas principais partes.
Em o Capítulo 4 é descrito a proposta e o processo de implementação do OLSR_ PD.
Em o Capítulo 5 são apresentadas as métricas utilizadas para avaliação do desempenho dos protocolos OLSR e OLSR_ PD, bem como os resultados obtidos.
Por fim no Capítulo 6 são apresentadas as conclusões e propostas para trabalhos futuros.
Em este capítulo são introduzidos alguns dos principais conceitos e trabalhos relacionados sobre roteamento em redes de computadores e principalmente conceitos utilizados no roteamento em redes MANETs.
Este capítulo está organizado da seguinte forma:
Em a Seção 2.1 são apresentados os principais algoritmos de roteamento utilizados em redes de computadores;
Em a Seção 2.2 são apresentados os principais conceitos relacionados às MANETs e os principais protocolos de roteamento utilizados nessas redes;
Em a Seção 2.3 são abordados conceitos sobre roteamento tolerante a falhas em redes ad hoc;
E na última seção, 2.4, são apresentados conceitos e os principais protocolos de roteamento que implementam mecanismos de qualidade de serviço QoS;
A principal finalidade das redes de computadores é possibilitar a comunicação entre computadores e o compartilhamento de recursos.
O melhor exemplo de redes é a própria Internet, a qual pode ser definida como um conjunto de redes de diferentes formatos, tamanhos, topologias e arquiteturas.
Cada rede na Internet é formada por um ou mais roteadores, os quais interligam essas redes graças à criação de protocolos comuns, como o IP (Internet Protocol), que permite que computadores de diferentes redes possam ser localizados, estabelecendo conexões e transmissões de dados entre si.
A comunicação entre computadores na Internet, geralmente é feita em múltiplos saltos, visto que, para que pacotes de dados de uma aplicação rodando num computador origem alcance um destino, esses são repassados várias vezes por os grandes roteadores da Internet até que um desses roteadores conheça o endereço da rede do computador destino.
A escolha do caminho por o qual os pacotes serão encaminhados e a definição das estruturas de dados utilizadas no roteamento são realizadas por os chamados Algoritmos de Roteamento, os quais constituem um dos principais elementos do projeto da camada de redes.
Em uma definição dada por Tanembaun, algoritmos de roteamento &quot;é a parte do software da camada de rede responsável por a decisão sobre a linha de saída a ser usada na transmissão do pacote de entrada», ou seja, são algoritmos, partes de protocolos de roteamento, cuja principal finalidade é calcular e manter atualizadas nos roteadores, as melhores rotas para encaminhar pacotes em direção a os demais destinos.
Segundo Tanembaun certas propriedades são desejáveis num algoritmo de roteamento de entre as quais destaca- se:
Correção, simplicidade, robustez, estabilidade, equidade e otimização.
A correção e simplicidade são auto-explicáveis;
Já robustez referese à capacidade do algoritmo de roteamento, mesmo em ambientes onde hosts (computadores), roteadores e links se tornem falhos repentinamente e que as topologias mudem muitas vezes, este deve aceitar as alterações na topologia e no tráfego sem exigir que as tarefas dos demais computadores sejam interrompidas e que a rede seja reinicializada sempre que um roteador falhar.
A estabilidade trata da capacidade do algoritmo alcançar o equilíbrio e permanecer nesse estado.
A equidade refere- se ao tratamento igualitário a todos os pares origem-destino que desejam comunicar- se na rede, e a otimização refere- se à utilização da banda de tal forma que a eficiência global seja máxima sem, no entanto, comprometer a equidade.
De todas as propriedades citadas, neste trabalho será dado destaque à robustez, visto que essa é uma das características do protocolo de roteamento OLSR que, por ser pró-ativo e fazer roteamento dinâmico, atualiza sua tabela de rotas à medida que falhas e alterações da topologia acontecem.
Também a proposta do novo critério de seleção de rotas ao OLSR visa garantir maior robustez, visto que, rotas cujos nodos possuam o maior grau de conectividade entre seus pares, aumenta a possibilidade de que em caso de falha na rota principal, a partir de aquele ponto, mais rapidamente uma rota alternativa seja encontrada.
Em Tanembaun é destacada duas categorias principais de algoritmos de roteamento:
Algoritmos não adaptativos e adaptativos.
Os não adaptativos desconsideram medidas ou estimativas do tráfego e da topologia atual para construir sua tabela de roteamento, visto que, rotas para todos os destinos conhecidos já são calculadas off-line e transferidas para os roteadores quando a rede é inicializada, por isso esse procedimento é também conhecido como roteamento estático.
Já os adaptativos constroem e mudam suas decisões de roteamento, com base nas informações de topologia atual, e eventualmente em informações sobre o tráfego e distância das rotas, por isso esse procedimento também é conhecido como roteamento dinâmico.
A seguir destacamos alguns dos principais algoritmos de roteamento conhecidos.
O algoritmo do caminho mais curto, em suas várias formas, é um dos mais utilizados em protocolos de roteamento.
Segundo Tanembaun dado um grafo de uma sub-rede, com cada nodo do grafo representando um roteador e cada arco indicando uma linha de comunicação (link), para escolher um caminho entre um par de roteadores, o algoritmo simplesmente encontra o caminho mais curto entre eles no grafo.
O caminho mais curto geralmente é o caminho com menor número de saltos (hops), ou seja, o número de arestas entre um nodo origem e um destino.
Logo segundo esse critério, os caminhos A-C-D e A-B-D da Figura 2 são iguais em distância.
Outra métrica utilizada é a distância geográfica, ou seja, cada arco é avaliado em termos de metros.
Se, por acaso, a Figura 2 possuísse uma escala, o caminho entre A-C-D seria visivelmente mais longo.
Outros algoritmos rotulam os arcos atribuindo a estes valores, que segundo Tanembaun &quot;podem ser calculados como uma função da distância, da largura de banda, do tráfego médio, do custo da comunicação, do comprimento médio da fila, do retardo médio entre outros».
Existem vários algoritmos utilizados para calcular o caminho mais curto entre dois nodos de um grafo, de entre eles destacam- se o algoritmo de Dijkstra e o de busca em largura.
Em este trabalho é considerado como caminho mais curto aquele que possuir o menor número de saltos e para implementar o algoritmo do caminho mais curto é utilizado o algoritmo de busca em largura.
O algoritmo do vetor de distância, mais comumente chamado de Algoritmo de Bellman-Ford ou Distributed Bellman-Ford (DBF) e algoritmo de Ford--Fulkerson foi o algoritmo utilizado na precursora da Internet, a ARPANET (Advanced Research Projects Agency Network), e ainda hoje é utilizado no protocolo RIP (Routing Information Protocol).
Em esse algoritmo, cada roteador cria e mantém uma tabela contendo a melhor distância conhecida até cada destino da rede e determina qual aresta (próximo roteador) que deverá ser utilizado para alcançar- los.
Periodicamente cada nodo envia toda sua tabela de rotas, apenas para seus vizinhos a 1 salto.
A o receber as tabelas de um vizinho, cada nodo atualiza sua tabela de rotas comparando as informações dessa mensagem com as informações de sua própria tabela, se encontrar rotas menores ou novos roteadores de destino, atualiza sua tabela e armazena de onde veio a informação Esse algoritmo apresenta como vantagem sua simplicidade e eficiência computacional, devido a sua característica distribuída.
Todavia apresenta uma baixa convergência na presença de muitas mudanças de topologia, e tende a criar loops, principalmente em condições não estáveis, como constantes alterações na topologia da rede, como ocorre na MANETs.
Em a tabela de roteamento construída em cada roteador, cada entrada de rota é indexada por o endereço dos outros roteadores da sub-rede.
Além de a coluna indexadora, esse vetor é composto por o campo que guarda a aresta de saída a ser utilizada para alcançar o destino, e um campo que guarda o custo para alcançar o destino, que pode registrar a estimativa do tempo ou a distância até esse destino.
Em a Tabela 1 é apresentada a tabela de rotas criada por o roteador A do conjunto de redes, representados na Figura 3.
A coluna &quot;destino «registra o endereço de cada destino conhecido do roteador A;
A coluna &quot;enlace «define qual a aresta de saída para se alcançar o destino;
E por fim o campo &quot;custo «recebe o custo para alcançar cada destino em número de saltos.
2.1.3. Roteamento com o algoritmo do estado do enlace (Link State) Devido a algumas limitações do algoritmo do Vetor de distância, tais como:
Não levar em consideração largura de banda para calcular o custo de seleção de rotas;
E por consumir muito tempo para convergir, ou seja, calcular todas suas rotas, criando loops que ficou conhecido como &quot;problema da contagem até o infinito», então em 1979 o DBF deixou de ser utilizado na ARPANET, quando foi substituído por o algoritmo de roteamento baseado no estado do enlace Ls (Link State).
Cada roteador, executando esse algoritmo, ao detectar uma alteração no estado do seus enlaces com algum roteador vizinho, então é criado um pacote que levará a informação, apenas de o (s) link (s) que sofreram alterações, para todos os outros roteadores da rede, diferente do DBF que envia toda a tabela de rota apenas para seus vizinhos.
A o receber esses pacotes, cada roteador atualiza suas informações sobre a topologia dessa rede.
Segundo Tanembaun, o algoritmo do estado do enlace apresenta convergência mais rápida que o DBF, evita loops e ainda suporta mais de uma rota e métrica de seleção de rotas.
O funcionamento básico desse algoritmo pode ser resumido em cinco passos:
Descobrimento dos vizinhos e aprendizagem de seus endereços de rede;
Medição do atraso ou custo de comunicação para cada um de seus vizinhos;
Confecção de um pacote contendo tudo o que já aprendeu;
Envio deste pacote para todos os outros roteadores da rede;
Cálculo do menor caminho para todos os outros roteadores da rede.
O principal protocolo de roteamento representante do algoritmo do estado do enlace é o OSPF (Open Shortest Path First) e foi o protocolo criado para substituir o RIP na ARPANET.
Diferentemente do RIP, cada roteador OSPF guarda em sua tabela de roteamento, informações sobre todos os links da rede e seu estado atual de forma que possua uma exata representação de toda topologia da rede e dessa forma é possível que cada roteador escolha a melhor (menor) rota para alcançar cada destino da rede.
As informações disponíveis nessa tabela são:
O endereço identificador da interface de rede do nodo, o número do enlace e a distância ou custo para alcançar o destino.
Segundo Tanembaun, atualmente o OSPF é um dos protocolos de roteamento mais empregados na Internet, pois é suportado na maioria dos roteadores e servidores da internet, funcionando bem em redes de pequeno e grande porte.
O OSPF é um protocolo de roteamento projetado para fazer distinção entre hosts e roteadores na Internet, o que permite que sejam armazenadas entradas de rotas apenas para os roteadores, reduzindo a quantidade de entradas de rotas, de forma que, se for preciso alcançar algum host, basta localizar o roteador (Gateway) daquela sub-rede e este saberá localizar o host.
Já o RIP, fora projetado como um protocolo de roteamento interno (IGP ­ Internal Gateway Protocol), de forma que, esse protocolo só faz roteamento entre hosts de uma mesma sub-rede.
De os protocolos apresentados nessa seção, tanto os algoritmos &quot;vetor de distância «como o &quot;estado do enlace «em suas versões originais não são adequados para implementar roteamento em redes MANETs, devido a a mobilidade e limitações de recursos dessas redes.
Existem vários algoritmos de roteamento para redes ad hoc que exploram características desses dois algoritmos de roteamento, às vezes combinando- os a fim de adequar- los às peculiaridades dessas redes.
Em a próxima seção são discutidas as principais características e os principais protocolos de roteamento usados em MANETs.
Devido a a limitação do alcance do sinal de rádio a comunicação em redes ad hoc geralmente é feita em links de múltiplos saltos, onde nodos intermediários são utilizados como roteadores na comunicação.
Para que esses nodos atuem como roteadores, estes devem possuir algum protocolo de roteamento que funcione de forma eficiente nesse ambiente.
Um protocolo de roteamento é um software que é executado no roteador, o qual se baseia em algum algoritmo ou mecanismo de roteamento.
A atividade de roteamento envolve a determinação de rotas e o repasse de pacotes de dados.
Essa função é executada na camada de redes do modelo TCP/ IP.
Em este trabalho a expressão &quot;pacotes de dados «será usada referindo- se a pacotes enviados por a aplicação, em contraste a &quot;pacotes de controle ou pacotes de roteamento», que são pacotes gerados para criar e manter a atividade de roteamento.
Segundo Cordeiro, para se construir protocolos de roteamento para MANETs os seguintes requisitos são desejáveis:
Prover mecanismos de escolha do melhor caminho para envio e recebimento de pacotes;
Efetuar roteamento com a menor sobrecarga de rede possível;
Ser independente da tecnologia da rede;
Ser capaz de lidar de maneira tolerante a falhas e consistente com as mudanças de topologia, falhas de equipamento e diferentes cargas de tráfego.
Algoritmos tradicionais de roteamento para redes fixas ou mesmo para Internet, como o vetor de distância DV (Distance Vector) e do estado do enlace (Link state) não são adequados para o ambiente de uma MANET.
Para superar este problema, vários protocolos de roteamento têm sido propostos para MANETs.
Segundo Abolhasan E Royer e Toh, esses protocolos podem ser classificados em três grupos diferentes:
Table-driven ou pró-ativos;
On- demand ou reativos;
E os híbridos, os quais agregam características tanto dos protocolos pró-ativos como dos reativos.
Os protocolos de roteamento também podem ser classificados quanto a a técnica de roteamento e podem ser divididos em duas categorias:
Os que fazem roteamento na origem (source routing) e roteamento salto- a- salto (hop-by-hop).
O roteamento baseado na origem, é uma técnica em que o nodo origem determina toda a rota por onde os pacotes deverão passar até encontrar o destino, ou seja, o pacote enviado carrega o endereço completo do nodo origem até o nodo destino, restando para os nodos intermediários apenas analisar no cabeçalho o endereço do próximo salto em direção a o destino e repassar o pacote.
Essa técnica tem como vantagem o fato dos nodos intermediários não precisar armazenar rotas para todos os destinos.
Como desvantagens:
Não são adequados para grandes redes, onde o número de nodos intermediários é grande e onde ocorrem frequentes falhas de rota;
E quanto maior a rede, maior será o tamanho do cabeçalho dos pacotes, visto que terá de carregar os endereços de todos os nodos intermediários na rota.
Em o roteamento salto- a- salto, cada pacote carrega apenas o endereço do destino e o endereço do próximo nodo em direção a o destino.
Logo cada nodo intermediário deverá usar sua tabela de roteamento para repassar cada pacote em direção a o destino.
As vantagens dessa estratégia é que as rotas são sempre atualizadas à medida que ocorrem mudanças na topologia da rede, logo os nodos intermediários repassam os pacotes com base em informações mais recentes e por melhores rotas.
Como desvantagem, cada nodo deve manter uma tabela com rotas para todos os destinos conhecidos da rede, o que gera constante tráfego na rede, visto que para manter atualizadas as tabelas de rotas para cada destino é constante o envio de mensagens de controle enviadas por cada nodo para seus vizinhos.
Em uma rede executando um protocolo de roteamento pró-ativo, cada nodo mantém uma ou mais tabelas de rotas para todos os nodos da rede, independentemente do uso ou necessidade dessas rotas.
Para manter suas tabelas de rotas atualizadas, de tempos em tempos ou quando ocorrem mudanças na vizinhança, cada nodo propaga para todos os seus vizinhos, informações de sua tabela de rotas.
A o receber essas mensagens os outros nodos atualizam suas tabelas de rotas, e mais adiante propagam essas alterações para os seus vizinhos, até que todos os nodos da rede tenham suas tabelas atualizadas.
De essa forma, quando uma das rotas for requisitada ela pode ser usada imediatamente.
Vários protocolos pró-ativos têm sido propostos para redes ad hoc.
Em Abolhasan E Royer e Toh, são analisados vários desses protocolos, de os quais os dois mais difundidos e estudados são:
O DSDV (DestinationSequenced Distance-Vect Routing Algorithm) e o OLSR (Optimized Link State Routing).
Segundo Abolhasan, os protocolos roteamento pró-ativos não são indicados para redes grandes, onde o número de nodos é variável ou ainda quando esses são muito móveis, visto consumirem uma quantia significativa de largura de banda da rede com mensagens de atualização de topologia da rede.
De esses protocolos o que se mostrou melhor escalável é OLSR, o qual diminui o tráfego na rede, reduzindo o número de nodos que reenviam mensagens de atualização, pois cada nodo utiliza- se da técnica repassar suas mensagens de controle.
Por ter apresentado o melhor desempenho e escalabilidade entre os pró-ativos, e a fim de melhorar o desempenho desse protocolo em ambientes de alta mobilidade e falhas dos nodos é que escolhemos esse protocolo para que fosse feita a adaptação do novo critério de seleção de rotas proposto neste trabalho.
O OLSR será descrito em detalhes no Capítulo 3.
Protocolos reativos têm suas atividades de roteamento iniciadas por o nodo de origem, ou seja, rotas são criadas apenas quando um nodo de origem deseja enviar dados para um destino qualquer.
Por essas características esses protocolos também são classificados como on- demand, cujas principais atividades consistem no processo de descobrir rotas e manter rotas.
A descoberta da rota se inicia quando um nodo origem precisa de uma rota para um destino, então ele inunda a rede com mensagens de requisição de rotas (rout_ request).
Cada nodo intermediário ao receber a mensagem, se ele não for o nodo destino apenas atualiza seus dados com base nas informações do pacote de requisição de rotas, coloca sua identificação no pacote e repassa as mensagens.
A o encontrar o destino este retorna uma mensagem com a rota descoberta (route_ reply) através dos nodos intermediários até chegar ao nodo de origem.
Quando a rota origem-destino é encontrada o nodo de origem passa a utilizar- la até que esta se torne indisponível ou por um período de tempo também conhecido como tempo de vida TTL (Time-to-Live).
Segundo Royer e Toh, protocolos de roteamento reativos sob demanda não gastam recursos da rede com rotas desnecessárias, porém o processo de descoberta da rota é mais demorado e até imprevisível.
Em protocolos reativos o processo de manutenção de rota consiste em apagar rotas falhas, ou reiniciar o processo de descoberta de rota em caso de mudança de topologia.
A manutenção de rotas depende muito do modelo de detecção de falha disponível nas camadas inferiores.
Vários são os protocolos reativos propostos na literatura, sendo os mais difundidos, segundo Abolhasan E Royer e Toh, o AODV (Ad Hoc On--Demand Distance Vector Routing) e o DSR (Dynamic Source Routing).
Em experimentos realizados em Perkins E Villela e Duarte, esses dois protocolos se destacam de entre os protocolos reativos por apresentarem desempenho consideravelmente maior sob diversos aspectos, tais como:
Segundo Chakeres e Perkins, o IETF MANET Work Group a partir de experiências adquiridas e com base nas melhores práticas em protocolos de roteamento para redes ad hoc tem proposto um protocolo reativo chamado DYMO (Dynamic MANET On-Demand Routing Protocol).
DYMO é resultado da combinação das melhores características de dois protocolos anteriores a ele o DSR e AODV.
Nenhum desses protocolos serão detalhados nesse trabalho, visto não contribuírem para os objetivos do mesmo.
Segundo Abolhasan, protocolos de roteamento híbridos possuem tanto as características dos protocolos pró-ativos como dos reativos.
Estes protocolos foram projetados para permitir maior escalabilidade da rede.
Para tanto, nodos que estão no alcance uns dos outros são vistos como um grupo.
O processo de manutenção de rotas dentro de um grupo é feito por algoritmos de roteamento pró-ativos evitando sobrecarregar toda rede com mensagens de descobertas de rotas.
Quando um destino está em outros grupos então é utilizado um processo reativo para descobrimento de rotas.
Muitos dos protocolos híbridos propostos são baseados em zonas ou áreas, ou seja, cada grupo de nodos que estão ao alcance do outro a apenas 1 salto são considerados uma zona e os outros grupos como árvores ou grupos de nodos.
Vários protocolos híbridos têm sido propostos na literatura, sendo um dos principais e mais difundido o ZRP (Zone Routing Protocol).
Em Abolhasan, vários protocolos híbridos são analisados, e segundo esse autor os protocolos de roteamento híbridos têm o potencial de prover maior escalabilidade que protocolos puramente pró-ativos ou reativos.
Isto porque eles tendem reduzir o número de nodos que reencaminham requisições de rotas.
A grande maioria dos algoritmos de roteamento, propostos para MANETs, são projetados para trabalhar em ambientes de comportamento ideal onde nodos e links não falham.
Segundo Xue e Nahrstedt, tais protocolos não são indicados para redes onde é alto o índice de falhas, pois apresentam altas taxas de perdas de pacotes.
Em simulações feitas por Xue e Nahrstedt o DSR, um dos protocolos mais difundido em MANETs, quando submetido a testes em ambientes com 20% de falhas de rotas, apresentou perda de 30% dos pacotes enviados, índice intolerável por algumas aplicações.
A principal problemática quando se propõe construir um protocolo de roteamento tolerante a falhas é garantir alta taxa de entrega de pacotes, mesmo na presença de falhas na rede sem, no entanto consumir grandes quantidades de largura de banda e recursos da rede.
Visando atender a tais objetivos, várias propostas de protocolos de roteamento tolerante a falhas têm se utilizado da redundância de pacotes, os quais são enviados por múltiplos caminhos simultaneamente entre os pares, origem e destino, ou ainda o uso de rotas alternativas que são guardadas para o caso de ocorrer falhas na rota principal.
Tais protocolos têm alcançado altas taxas de entrega de pacotes, todavia muitos destes apresentam um grande consumo de recursos da rede por causa de a duplicação de pacotes enviados por múltiplos caminhos entre a origem e o destino.
Conforme Xue e Nahrstedt, a redundância é um dos principais recursos utilizados para tornar um sistema tolerante a falhas.
Redes móveis ad hoc são altamente redundantes, pois entre um nodo origem e destino pode existir vários caminhos diferentes.
Tal redundância em redes ad hoc facilita a implementação de protocolos de roteamento tolerante a falhas.
Existem basicamente dois tipos de protocolos de roteamento tolerante a falhas que fazem roteamento por múltiplos caminhos.
O primeiro se utiliza tanto da redundância de pacotes como de rotas, pois para cada pacote gerado é enviado uma cópia por todos os caminhos redundantes entre origem e destino acarretando em alto consumo da largura de banda disponível.
O segundo apenas cria e guarda as rotas redundantes na tabela de roteamento, utilizando apenas uma por vez, caso a primeira venha a falhar, outras rotas já estarão disponíveis.
Geralmente esses protocolos fazem roteamento na origem (source routing), visto que o nodo origem é quem tem de calcular e guardar rotas redundantes para um dado destino.
Segundo Oomm e Misra, vários protocolos baseados no roteamento por múltiplos caminhos tem sido criados.
Esses protocolos são fortes em tolerância à falhas, todavia, a maioria desses algoritmos introduzem uma quantia desnecessária de overhead na rede.
Segundo Kim, os principais algoritmos de roteamento baseados em múltiplos caminhos para redes ad hoc são:
O End-to-End Fault Tolerant Routing (E2FT) o qual segundo Oomm e Misra, é capaz de significativa redução no overhead com envio de múltiplos pacotes, enquanto garante uma satisfatória taxa de entrega de pacotes;
O Ad hoc On- demand Multipath Distance Vector Routing (AOMDV) é um dos mais notáveis protocolos de roteamento por múltiplos caminhos em pesquisas em redes ad hoc, o qual se baseia nos conceitos do AODV.
Para alcançar múltiplas rotas ele aceita múltiplos requisições de rotas e mantém uma tabela de mecanismos de descoberta de caminhos disjuntos para prover rotas livres de falhas.
Em Shoroeder e Junior, é proposto um algoritmo de roteamento dinâmico, tolerante a falhas para funcionar na Internet.
Em essa proposta o principal critério de roteamento é a seleção de rotas robustas.
Rotas robustas no sentido de rotas em que os nodos intermediários possuam um alto grau de conectividade, pois em caso da ocorrência de falhas em parte do caminho (nodos ou links), é possível encontrar um caminho alternativo que parte do ponto em que a falha foi conhecida em direção a o nodo destino, o que faz esse algoritmo tolerante a falhas.
Segundo Shoroeder e Junior, esse algoritmo é dinâmico, no sentido que, cada nodo ao receber uma mensagem a ser roteada escolhe apenas a próxima aresta da rota, permitindo que nodos intermediários da rota possam escolher um caminho melhor que os conhecidos por o roteador de origem da mensagem.
Esse roteamento explora o fato de que nodos mais próximos a um evento de alteração de estado de nodo ou link, recebam a informação do evento antes dos demais nodos da rede.
Esse conceito pode ser estendido também às informações de congestionamento, caso em que uma aresta pode ser considerada temporariamente falha.
Para que esse algoritmo funcione é necessário que cada nodo possua uma representação local da topologia da rede, mesmo que algumas entradas sejam desatualizadas esse algoritmo funcionará por ser tolerante a falhas.
Essa representação é feita através de uma estrutura de grafos simétricos, com um conjunto de vértices (nodos) e de arestas (links).
Essa estrutura é atualizada periodicamente através de troca de mensagens.
Como exemplo da representação da rede em cada nodo, suponhamos a rede ilustrada na Figura 4.
Em cada nodo haverá uma representação da topologia com os Para calcular rotas em que os nodos intermediários possuam maior redundância de links em direção a o destino, é utilizado o algoritmo do fluxo máximo proposto por Ford Fulkerson.
Segundo Shoroeder e Junior, esse algoritmo &quot;é utilizado para avaliar a redundância de caminhos, visto que, quanto maior o fluxo máximo, maior a quantidade de caminhos disjuntos até o destino e, por consequência maior é o número de atalhos que podem ser utilizados em caso de falha».
Por exemplo, na rede representada na Figura 4, se o caminho escolhido por o nodo origem s, para chegar ao destino t, se iniciasse a partir de a aresta (s, a), em caso de falha da aresta (a, e), o nodo a possui rotas alternativas, como a aresta (a, c), o qual ainda possui um caminho até o destino.
Esse algoritmo recebe como entrada um par de nodos da rede, correspondentes a origem e ao destino de uma mensagem a ser enviada.
O algoritmo então é executado em cada nodo da rede, iniciando por o nodo de origem, escolhendo o próximo nodo da rota de entre os seus nodos vizinhos.
Quando a mensagem chega a um nodo escolhido, esse executa o mesmo algoritmo para escolher o nodo seguinte, e assim, até que o destino seja alcançado.
Conforme Shoroeder e Junior, na escolha de um caminho também é utilizado um critério secundário, o caminho de menor comprimento.
Logo para avaliação de uma aresta, é utilizada aquela, cujo caminho seja o menor caminho de maior redundância até o destino que passa por aquela aresta.
Por exemplo, na rede representada por a Figura 4, caso s precise enviar uma mensagem para t, a aresta (s, a) será avaliada.
Observa- se que, por essa aresta possuir duas rotas que leva ao destino t, cada uma com comprimentos diferentes.
Em este caso, para a avaliação da aresta (s, a) será utilizado o menor caminho que passa por essa aresta que é o caminho (s, a, e, t).
Para manter atualizas as tabelas de topologia em cada nodo periodicamente são enviadas mensagens de atualização, na presença ou não de alterações de topologia da rede.
Cada mensagem contém um conjunto de triplas:
Uma aresta;
A situação ou estado da aresta (funcional ou falho);
E um contador para ordenação dos eventos (time stamp).
Um nodo ao receber uma mensagem de atualização inclui ou substitui informações de roteamento em tabela de rotas.
Se um nodo observa que durante um intervalo de tempo ele não recebe nenhuma mensagem por uma aresta, então aquela aresta é considerada como falha, e essa informação é enviada para os outros nodos.
Caso um nodo receba uma informação de uma aresta antes inexistente, este insere essa informação na sua tabela de topologia e a aresta passa a ser considerada funcional.
Provas do funcionamento desse algoritmo são apresentadas em Shoroeder e Junior.
Em redes de computadores um dos principais critérios para seleção de rotas utilizados por protocolos de roteamento é o número de saltos.
Ocorre que para algumas aplicações do usuário apenas esse critério pode não garantir o funcionamento satisfatório de aplicações multimídias e de tempo real, visto que esses serviços necessitam de garantia de que alguns parâmetros como largura de banda, atraso e perdas de pacotes estejam dentro de limites bem definidos.
Segundo Leguay, para tais requisitos dá- se o nome de Qualidade de Serviço (QoS), que pode ser definida como a capacidade da rede prover serviço de encaminhamento de dados de forma consistente e previsível.
Em redes de computadores, QoS pode ser entendida como a capacidade da rede, através dos mecanismos de reserva de largura de banda e priorização de tráfego, fornecer garantias de que determinados fluxos de tráfego irão ter tratamento diferenciado.
É importante destacar que a implementação de protocolos de roteamento que atendam requisitos de QoS tendem a consumir mais largura de banda da rede e recursos de processamento dos roteadores.
Para que informações sobre a qualidade dos links precisam ser trocadas entre os nodos, consumindo assim largura de banda adicional.
Para descobrir a rota que possui a melhor QoS, se faz necessário analisar todas as rotas possíveis entre os nodos origem e destino, o que gera processamento extra nos roteadores.
A complexidade de fazer roteamento baseado em QoS em MANETs é exatamente não consumir recursos, como largura de banda e tempo de processamento, visto largura de banda e fonte de alimentação (energia elétrica) são as principais limitações dessas redes.
Adicional a essas limitações, em redes ad hoc os nodos são móveis, fazendo com que a QoS de rotas mudem em tempos imprevisíveis.
Em a Seção 3.5 são apresentadas algumas características de alguns protocolos de roteamento para MANETs que implementam QoS.
Em esta seção são apresentadas as principais definições utilizadas para descrever o critério proposto neste trabalho.
Grafo: É possível definir grafo como um par G $= (V, E), onde V é um conjunto não vazio e finito de vértices, e um conjunto E de arestas (arcos), que pode ser vazio, é uma relação entre dois vértices pertencentes a V. Dado v1, v2 pertencentes a V, e uma aresta ou ainda apenas dígrafo, se cada aresta é denotada por de forma que, essa diferença é representada por a seta numa ou ambas as extremidades do arco das arestas (Figura 6).
Para representar arestas entre v1, v2 essa distinção será desprezada e uma aresta entre dois vértices, será referenciada apenas como.
Em este trabalho grafos serão utilizados para representar as topologias das redes, onde os vértices representam os nodos (roteadores) e as arestas os links ou enlaces de comunicação entre um par de nodos.
Adjacência: Um vértice v1 é adjacente ao vértice v2, ambos pertencentes a V, se existe uma aresta entre eles, ou seja, se a ponta inicial do arco está em v1 é a ponta final em v2.
Em uma relação de adjacência pode acontecer de v1 ser adjacente a v2, sem que v2 seja adjacente a v1.
Tomando como exemplo a Figura 5 o vértice C possui 3 vizinhos adjacentes:
Os vértices A, D e E. Grau de um vértice:
Em teoria dos grafos o grau de um vértice v, d, equivale ao número de arestas (links) incidentes ao vértice v..
Os loops são contados duas vezes, por exemplo, o vértice D do grafo da Figura 5 possui grau igual a d (D) $= 3.
Em dígrafos existem os conceitos de grau de entrada, que representa o número de arestas que chegam a um vértice v, e o grau de saída, que é dado por o número de arestas que partem de um vértice v..
Logo num dígrafo, o grau de um vértice é dado por a soma dos graus de entrada e saída, como se observa no vértice C do grafo da Figura 6, cuja aresta de entrada é (A, C) e as arestas de saída são (C, E) e (C, D), logo d (C) $= 3.
Caminho num grafo:
Um caminho c de v1 a vn é uma sequência de arestas caminho é dado por o número de arestas que o caminho usa.
Em esse trabalho o comprimento de um caminho, ora será referenciado como a distância ou como número de saltos para se alcançar um destino.
Já o termo rota será utilizado como sinônimo para caminho, pois é o mais comumente utilizado no contexto de redes de computadores para designar o caminho por o qual um dado nodo origem envia uma mensagem a um destino.
Grau de um caminho:
O grau do caminho c é denotado por a soma do grau de do caminho «é dado por a soma do grau de todos os nodos intermediários aos nodos nodo origem não foi considerado nos cálculos, por não influenciar nos resultados e para não adicionar mais atividade de processamento no protocolo.
Com base na Figura 5, o grau do caminho entre a origem A e o destino E seguindo por o caminho c $= (A, C) (C, E) é igual a d (A+ C+ E) $= d (C)+ d (E), como d (C) $= 3 e d (E) $= 2, então d (A+ C+ E) $= 5.
O OLSR (Optimized Link State Routing) é um protocolo que executa o roteamento salto- a- salto, pró-ativo, orientado a tabelas de roteamento, o qual é uma versão otimizada do protocolo puramente baseado no estado do enlace (Link State).
Como em todos os algoritmos baseados no estado do enlace, cada nodo mantém atualizadas as informações sobre a topologia da rede através da troca periódica de mensagens de controle.
Segundo Abolhasan, esse protocolo tem se destacado entre os pró-ativos, porque reduz significativamente o número de retransmissões de mensagens de controle na rede.
Para isso utiliza- se de duas técnicas:
Primeiro apenas um grupo de nodos é selecionado para propagar mensagens de controle na rede, técnica Cada nodo possui o seu grupo de nodos MPR para difundir suas mensagens de controle;
Segundo Jacquet, por essas características, este protocolo é adequado para operar em grandes e densas redes ad hoc suportando centenas de nodos.
Por causa de a natureza proativa do OLSR, enquanto um nodo permanecer ativo, deve manter rotas para todos os destinos conhecidos da rede.
A rota ótima, segundo o critério de seleção de rotas do OLSR, é aquela de menor comprimento em termo de número de saltos.
Em o OLSR cada pacote de controle enviado possui um número de sequência, o qual é incrementado a cada pacote enviado, tornando possível a distinção entre informações mais velhas das recentes.
Logo não importa a ordem de chegada dos pacotes, o OLSR usará sempre as informações mais recentes.
Segundo Jacquet Mensagens de controle são trocadas entre nodos através de comunicação não segura usando o protocolo da camada de transporte UDP (User Datagram Protocol) e a porta 698 a qual tem sido designada por a Iana (Internet Assigned Names Authority) exclusivamente para ser usada por o OLSR.
Pequenas perdas de mensagens de controle, devido a não garantia de entrega de pacotes do UDP, são perfeitamente suportadas por o OLSR, visto que as informações dos pacotes perdidos são logo compensadas por novas mensagens enviadas periodicamente.
O OLSR utiliza dois tipos básicos de mensagens de controle:
Mensagem HELLO e mensagem de controle de topologia (Tc ­ Topology Control).
Uma mensagem HELLO é enviada por cada nodo apenas para os seus vizinhos a 1 salto, a qual é utilizada para fornecer informações sobre o estado dos links desse nodo com seus vizinhos.
As informações das mensagens HELLO são utilizadas para que cada nodo construa seu conjunto MPR e a lista de nodos que o tem selecionado como MPR (MPR selector).
Já as mensagens Tc são enviadas por um nodo para todos os outros nodos da rede contendo informações da lista de MPR selector daquele nodo.
As mensagens Tc só podem ser retransmitidas (repassadas) por os nodos MPRs.
Esses conceitos serão discutidos em mais detalhes nas próximas seções.
O OLSR adota um formato unificado de pacote para transmitir qualquer mensagem de controle ou de dado relacionado ao protocolo (Figura 7).
A finalidade de usar um formato único é facilitar possíveis extensões do protocolo sem perder compatibilidade com as definições básicas do protocolo.
Em um único pacote básico do OLSR é possível transportar vários tipos de mensagens até que o tamanho do pacote alcance o máximo permitido por a rede.
Como se observa na parte superior da Figura 7 existe uma sequência de números em que cada dígito correspondente a 1 bit os quais têm por finalidade indicar o tamanho de cada campo.
Este pacote é dividido em duas partes, conforme segue- se:
Cabeçalho do pacote que é composto dos campos:
Packet Length -- é o comprimento do pacote que é dado em bytes;
Packet sequence number -- é número de sequência do pacote que é o identificador único do pacote, o qual é incrementado em 1 a cada novo pacote gerado.
Cabeçalho da mensagem que é composto dos campos:
Message type -- tipo da mensagem que identifica que tipo de mensagem é encontrada no campo MESSAGE;
Vtime -- campo que registra o tempo de validade da mensagem;
Message size -- contém o tamanho da mensagem em bytes;
Originator address -- carrega o endereço da principal interface de rede do nodo que originou a mensagem;
Time to Live ­ o campo tempo de vida da mensagem recebe um número inteiro que representa a quantidade máxima de vezes que o pacote pode ser repassado, esse valor é decrementado em 1 a cada salto até chegar a 0 (zero) quando a mensagem deve ser descartada;
Hop count -- contador de salto registra por quantos nodos essa mensagem já passou.
A cada salto, esse número é incrementado em 1;
Message sequence number -- é número de sequência da mensagem que é incrementado a cada nova mensagem partindo daquele nodo.
Um mesmo pacote pode carregar vários tipos de mensagens, como HELLO e Tc.
Maiores detalhes sobre cada campo do pacote básico pode ser obtido em Jacquet A técnica utilizada por o OLSR para reduzir o número de pacotes de controle selecionar, de entre seus vizinhos a 1 salto, o menor número de nodos que irão repassar suas mensagens de controle.
O principal critério para que um nodo selecione seu conjunto MPR é que esse grupo de nodos alcance todos os nodos a 2 saltos de distância do nodo origem.
Para escolher o conjunto de nodos MPRs, são utilizadas as informações dos nodos vizinhos alcançáveis a 1 salto contidas nas mensagens do HELLO.
Segundo Jacquet E Qayyum, o conjunto MPR do nodo S, é chamado MPR (S).
Um nodo só é escolhido como MPR (S) se ele possuir um link bidirecional para S e alcançar o maior número de nodos vizinhos a 2 saltos do nodo S. É importante destacar que quanto menor o número de nodos no conjunto MPR (S) mais eficientemente esse protocolo funcionará, pois apenas os nodos MPR (S) podem reencaminhar mensagens de controle geradas em S. Quanto aos demais nodos vizinhos a 1 salto de S, mas que não fazem parte do conjunto MPR (S), apenas leem e processam as informações que estão nos pacotes, todavia não podem repassar- las, como se observa na Figura 9.
Em o OLSR apenas os nodos selecionados como MPR são utilizados como nodos intermediários/ roteadores para a formação das rotas.
Para implementar este esquema, com base em informações do tipo de link da mensagem HELLO, cada nodo mantém uma lista dos vizinhos a 1 salto que o tem selecionado ele como MPR (MPR Selector) e periodicamente espalha essa lista por toda a rede.
A o receber essas informações, cada nodo calcula e atualiza suas rotas para cada destino conhecido na rede.
Logo, numa rede de nodos OLSR, rotas sempre serão uma sequência de saltos através de MPRs até um determinado destino.
Em a Figura 8 é apresentado o processo de envio de mensagens de controle por difusão de pacotes sem MPR.
Em esse exemplo para alcançar nodos a 3 saltos do nodo S foram necessárias 24 nodos retransmissores.
Já na Figura 9 é apresentado o processo de envio por difusão usando MPR, observa- se significativa redução do número de retransmissões de 24 para apenas 11 e alcançando todos os nodos a 3 saltos.
Em ambas as ilustrações a mensagem de controle a ser difundida parte do nodo S no centro.
A o receber novas mensagens HELLO, o conjunto MPR de um nodo é recalculado sempre que:
Um dos principais critérios para seleção do conjunto de nodos MPR é a alcançabilidade, ou seja, a capacidade de alcançar o maior número de nodos a 2 saltos do nodo S. A o escolher tais nodos busca- se diminuir o conjunto MPR ao mínimo de nodos suficientes para alcançar os benefícios do MPR.
Pode ocorrer, no entanto, do conjunto MPR (S) coincidir com o conjunto de todos os vizinhos a 1 salto.
Situação que ocorre toda vez que a rede é inicializada.
Mais detalhes sobre o cálculo do MPR de um nodo, e provas do funcionamento desse algoritmo são encontrados em.
O OLSR utiliza dois tipos básicos de mensagens de controle para criar e manter as informações de rotas da rede sempre atualizadas.
A mensagem mais básica do OLSR é a mensagem HELLO que cada nodo envia apenas para seus vizinhos a 1 salto, a qual é utilizada para detecção do estado dos links com vizinhos a 1 salto.
Para construção e divulgação de informações da tabela de rotas de cada nodo, são enviadas periodicamente mensagens de controle de topologia (Tc) as quais são propagadas para todos os nodos da rede por os nodos MPRs.
Para que um nodo possa escolher seu conjunto MPR, primeiro ele precisa detectar seus vizinhos a 1 salto.
Em o OLSR, cada nodo detecta seus vizinhos enviando periodicamente mensagens de HELLO para todos os nodos ao alcance de sua transmissão de rádio.
Esses vizinhos por sua vez processam as mensagens, mas não as repassam, pois o valor do campo &quot;Time te o Live «do cabeçalho da mensagem HELLO é igual a 1 e com apenas um salto o tempo de vida da mensagem expira não podendo mais ser repassada adiante (Figura 7).
Em a implementação do OLSR utilizada nesse trabalho o intervalo de tempo padrão para envio de mensagens de HELLO é de dois segundos;
Segundo Jacquet, para que nodos de links unidirecionais não sejam escolhidos como MPR, todos os links devem ser checados em ambas as direções.
Por exemplo, se o nodo A recebe uma mensagem HELLO de B, então o nodo A marca em sua tabela de rotas o link para o nodo B como sendo assíncrono (unidirecional).
A o criar uma mensagem HELLO, o nodo A informa em ela que possui um link assíncrono para o nodo B. O nodo B ao receber a mensagem, verifica que A pode escutar- lo, logo marca em sua tabela que possui um link síncrono (bidirecional) com o nodo A. Em a próxima mensagem de HELLO enviada por B é incluído na mensagem a informação de que B possui um link bidirecional com A. A o receber essa mensagem o nodo A reconhece que pode ser ouvido por o nodo B, como também pode ouvir- lo, logo marca o link com B como sendo síncrono.
Em a Figura 10 é apresentado o formato básico de uma mensagem HELLO.
Em o cabeçalho da mensagem são encontrados os seguintes campos:
Reserved que recebe por padrão uma sequência de zeros Htime -- especifica o intervalo de tempo em que cada mensagem de HELLO é enviada;
Willingness -- registra o grau de disposição de cada nodo para repassar pacotes em nome de outros nodos.
Esse campo recebe valores entre 0 e 7 significando respectivamente &quot;nunca disponível «e &quot;sempre disponível».
Em a implementação do OLSR utilizada neste trabalho, em todos os nodos esse campo recebe o valor padrão &quot;3», significando &quot;disposição normal «em repassar pacotes.
Em o cabeçalho das informações sobre cada vizinho a 1 salto, existem os seguintes campos:
Link Code -- que é subdividido em dois outros campos, recebendo duas informações básicas:
O campo tipo do nodo vizinho (neighbor type) que pode receber os valores &quot;síncrono», &quot;MPR», ou &quot;não é mais vizinho «e tipo de link (Link type), que pode receber os valores:
&quot;assíncrono», &quot;síncrono «ou &quot;desconhecido&quot;;
Neighbor interface address -- Campos que armazenam o endereço da interface de rede do nodo vizinho, se o nodo vizinho tiver mais que uma interface de rede os endereços são inseridos nesse campo.
Com base nas informações das mensagens de HELLO várias bases de informações são criadas, como:
Tabela de múltiplas interfaces, tabelas de links bidirecionais, tabelas de vizinhos a 1 e 2 saltos;
Conjunto de MPR e conjunto de MPR Selectors.
Todas esses repositórios de informações serão detalhados na Seção 3.3.
Para que cada nodo construa uma tabela com informações da topologia da rede, todo nodo que foi selecionado como MPR e apenas os nodos MPRs, devem enviar (por broadcast), periodicamente mensagens de controle de topologia (Tc) para todos os nodos da rede, contendo informações dos links para todos os nodos de seu conjunto MPR Selector.
Em a Figura 12 é apresentado o formato básico de uma mensagem Tc a qual é divida nos seguintes campos:
ANSN (Advertised Neighbor Sequence Number) ­ esse campo recebe um número de sequência relacionado ao conjunto de MPR Selector anunciado.
Toda vez que ocorrer uma alteração no conjunto MPR Selector do nodo que gerou a mensagem Tc esse campo é incrementado em 1.
Esse número de sequência é utilizado para evitar loops infinitos de repasse de uma mensagem Tc, e para indicar se a mensagem é a mais nova, se não for a mais nova ou já tiver sido processada a mensagem é descartada sem processamento algum;
Reserved que recebe por padrão uma sequência de zeros Advertised Neighbor Main Address ­ esse campo recebe o endereço da interface de rede principal dos vizinhos anunciados, os quais fazem parte do conjunto MPR Selector daquele nodo.
As mensagens Tc são enviadas em intervalos fixos, todavia se ocorrer alguma alteração no conjunto MPR Selector do nodo emissor da mensagem Tc, a próxima mensagem é enviada antes do tempo programado.
Todas as próximas mensagens Tc serão enviadas no tempo padrão para envio de mensagem Tc, até ocorrer outra mudança no conjunto MPR Selector.
Em a implementação do OLSR, o intervalo de tempo padrão para envio de mensagens Tc é de cinco segundos.
Toda vez que uma mensagem Tc é recebida, cada nodo da rede cria ou atualiza uma tabela de topologia (Subseção 3.3.7), onde são registradas as informações sobre a topologia da rede, as quais serão utilizadas para o cálculo da tabela de roteamento.
A o receber uma mensagem Tc, cada nodo verifica se já existe alguma entrada com as mesmas informações em sua tabela de topologia, caso exista a mensagem é descartada e não é repassada adiante;
Se não existir ou se o número de sequência da mensagem Tc for mais recente, então as informações mais recentes são inseridas na tabela e a entrada antiga é removida.
Após a mensagem é repassada adiante, se o nodo for MPR do remetente da mensagem Tc.
Em redes MANETs pode ocorrer que alguns nodos OLSR disponham de mais de uma interface de rede.
Em esses casos os nodos que possuem múltiplas interfaces devem gerar periodicamente mensagens MID (Multiple Interface Declaration) que serão enviadas por broadcast para todos os nodos da rede utilizando o mecanismo do MPR.
Em a Figura 13 é apresentado o formato de uma mensagem MID.
Em o OLSR cada nodo é identificado por o endereço de rede principal.
Em nodos com apenas uma interface de rede, o endereço principal é o endereço da única interface de rede.
Já em redes com múltiplas interfaces é eleita uma interface como sendo a principal e as demais são relacionadas a essa interface.
O campo OLSR Interface Address da Figura 13 recebe todos os múltiplos endereços do nodo que criou a mensagem MID, excluindo o endereço da interface principal que já vem indicado no campo Originator Address do pacote básico do OLSR (Figura 7).
As informações contidas nessa mensagem são guardadas numa base de informações e utilizadas no cálculo da tabela de roteamento.
Em este trabalho mensagens MID não serão geradas, visto que os nodos não foram configurados para operar com múltiplas interfaces de redes, por não contribuir para os objetivos propostos nesse trabalho, todavia em trabalhos futuros pode- se avaliar o desempenho do OLSR_ PD quando trabalhando com nodos de múltiplas interfaces.
Para que nodos OLSR construam e mantenham as tabelas de roteamento para todos os nodos da rede, as informações obtidas através da troca de mensagens HELLO e Tc são armazenadas e organizadas em várias bases de informações, as quais serão descritas nas próximas subseções.
Cada nodo OLSR guarda uma tabela onde são registradas as múltiplas interfaces de redes para cada destino da rede.
Cada registro nessa tabela é chamado de &quot;tupla de associação de interface «e é composto por os seguintes campos:
I_ iface_ addr I_ main_ addr I_ time O campo I_ iface_ addr é um dos múltiplos endereços de interface de rede de um nodo;
O I_ main_ addr é o endereço da principal interface de rede do nodo;
E o I_ time especifica a hora que esta tupla expira e deve ser removida.
Em nodos com mais de uma interface de rede, a interface principal aparece em várias tuplas referenciando as placas adicionais.
Em cada nodo OLSR deve ser mantida uma base de informações dos links de comunicação entre esse nodo e todos os seus vizinhos a 1 salto.
O mecanismo utilizado para detectar os links entre nodos são as mensagens de HELLO.
A cada recebimento de uma mensagem HELLO um nodo cria ou atualiza sua tabela de links contendo tuplas (registros) com os seguintes campos:
L_ local_ iface_ addr -- L_ neighbor_ iface_ addr -- L_ SYM_ time -- L_ ASYM_ time -- L_ time O campo L_ local_ iface_ addr é o endereço da interface de rede local, ou seja, do próprio nodo que calcula o conjunto de links;
O campo L_ neighbor_ iface_ addr é o endereço da interface de rede do nodo vizinho;
O campo L_ SYM_ time registra até quando (em redes reais, o tempo no formato hh:
Mm: Ss) o link pode ser considerado simétrico;
O campo L_ ASYM_ time registra até quando o link pode ser considerado assimétrico;
Por último, o campo L_ time é o tempo de vida do registro na base de informações, que ao expirar indica que o registro deve ser removido.
Após receber uma mensagem HELLO cada nodo deve processar- la e construir ou atualizar uma base de informações de seus vizinhos a 1 salto.
Essas informações são armazenadas em tuplas contendo os seguintes campos:
N_ neighbor_ main_ addr N_ status N_ willingness O campo N_ neighbor_ main_ addr é o endereço da principal interface de rede do vizinho;
N_ status guarda o estado do link com o vizinho, se &quot;simétrico», &quot;assimétrico «ou &quot;perdido&quot;;
O campo N_ willingness recebe valores inteiros entre 0 e 7, e representa o grau de disposição do nodo vizinho em repassar mensagens em nome de outros nodos, significando respectivamente &quot;nunca disponível para retransmitir «e &quot;sempre disponível para retransmitir «em nome de outros nodos.
O campo N_ status tem seu estado alterado com base nas informações dos campos L_ SYM_ time e L_ ASYM_ time da base de informações de links (Subseção 3.3.2).
Se o tempo especificado em L_ SYM_ time ainda não expirou, N_ status é declarado &quot;simétrico».
Se o tempo especificado em L_ SYM_ time expirou, então o estado de N_ status é declarado &quot;assimétrico».
Se ambos L_ SYM_ time e L_ ASYM_ time são expirados, o N_ status é declarado &quot;perdido», indicando que o link com o vizinho não existe mais A o receber mensagens HELLO, cada nodo deve processar- la e construir ou atualizar sua tabela de vizinhos a 2 saltos.
Essa tabela de vizinhos a 2 saltos é formada por o conjunto de nodos que possuem link simétrico com um vizinho simétrico a 1 salto.
Essas informações são guardadas em tuplas contendo os seguintes campos:
N_ neighbor_ main_ addr -- N_ 2h op_ addr N_ time O campo N_ neighbor_ main_ addr é o endereço da principal interface de rede do vizinho a 1 salto que enviou a mensagem HELLO;
O campo N_ 2h op_ addr é o endereço da interface de rede principal de um vizinho a 2 saltos de distância, que possui um link simétrico com o N_ neighbor_ main_ addr;
E o campo N_ time registra a hora em que essa tupla expira e deve ser removida.
Para construir a tabela de vizinhos a 2 saltos, após receber uma mensagem HELLO as seguintes restrições são observadas:
L_ neighbor_ iface_ addr da base de informações do conjunto de links (Subseção 3.3.2) cujo tempo de validade do campo L_ SYM_ time não tenha expirado, ou seja, que exista ainda um link simétrico entre os dois nodos;
Como apresentado na Seção 3.1, o conjunto MPR de um nodo S é denotado por MPR (S) e equivale ao menor número possível de nodos, capazes de alcançar todos os nodos a 2 saltos do nodo S. Após executar o algoritmo que calcula o MPR, cada nodo constrói uma tabela contendo o seu conjunto de nodos MPR, ou seja, são escolhidos quais nodos que poderão repassar suas mensagens Tc, os quais, consequentemente, pertencem ao grupo dos nodos que podem ser escolhidos como próximo salto na construção da tabela de roteamento desse nodo.
Após um nodo qualquer S calcular o seu conjunto de nodos MPR, inicialmente nenhum dos vizinhos de S possui a informação se pertence ao conjunto MPR (S).
Para que os vizinhos de S adquiram essa informação, ao criar uma mensagem HELLO o nodo S insere no campo neighbor type qual o tipo de link para um determinado vizinho X, que pode assumir três possíveis valores &quot;síncrono», &quot;MPR «ou &quot;não mais vizinho».
Cada nodo vizinho X, ao receber essa mensagem HELLO do nodo S, verifica qual o tipo de link informado no campo neighbor type, se este for &quot;MPR «significa que o nodo S tem selecionado X como seu MPR, logo o nodo X insere o endereço do nodo S no conjunto de nodos que o selecionaram como MPR (Subseção 3.3.6), conjunto este posteriormente enviado por X nas suas mensagens Tc.
Como cada nodo S precisa escolher o seu conjunto MPR (S), também todo nodo S precisa guardar informações de quais nodos selecionaram S como seu MPR.
Essas informações são guardadas em tabelas chamadas de conjunto de selecionadores de MPR (MPR Selector), cujas tuplas contêm os seguintes campos:
MS_ main_ addr MS_ time Em a tabela construída em S o campo MS_ main_ addr guarda o endereço da principal interface de rede do vizinho que selecionou S como seu MPR;
Já o campo MS_ time equivale ao tempo de validade do link para o nodo que escolheu S como MPR.
Esse campo recebe o tempo contido no campo Vtime do cabeçalho da mensagem HELLO (Figura 7).
É importante destacar que cada nodo envia periodicamente suas tabelas MPR Selector para todos os nodos da rede através de suas mensagens de Tc, de forma que cada nodo possa ter informações suficientes para construir sua tabela de topologia.
Para possibilitar a construção ou atualização de uma base com informações da topologia da rede, cada nodo MPR envia mensagens Tc (Subseção 3.2.2) contendo informações do conjunto de nodos que o selecionaram como seu MPR (Subseção 3.3.6).
A o receber e processar uma mensagem Tc cada nodo forma sua tabela de topologia com a seguinte estrutura:
T_ dest_ addr ­ T_ last_ addr T_ time T_ seq O campo T_ dest_ addr recebe o endereço de um destino que é um nodo que selecionou o originador da mensagem Tc como MPR;
T_ last_ addr é o endereço do nodo MPR que originou a mensagem Tc ou ainda um nodo capaz de alcançar o destino;
O T_ seq é o número de sequência (campo ANSN) da mensagem Tc originada de um dado nodo MPR;
E o campo T_ time registra o tempo de validade da tupla na tabela de topologia Em a tabela de topologia construída em cada nodo OLSR, não são registrados todos os links que compõem a rede, mas apenas aqueles que passam por nodos MPRs (Seção retransmissões de mensagens de controle na rede.
Segundo Jacquet, esse não é um problema para o OLSR, mas uma de suas vantagens, pois consegue reduzir o overhead, o tempo de processamento de mensagens de controle de topologia e ainda assim permite que todos os nodos da rede sejam alcançados toda vez que uma rota for requisitada.
Provas do funcionamento do MPR são encontradas em.
Em redes executando o OLSR, cada nodo constrói e mantem uma tabela de roteamento que o permite enviar ou reencaminhar pacotes para todos os destinos conhecidos na rede.
Para construir ou atualizar a tabela de roteamento, um nodo OLSR utiliza informações dos seguintes repositórios:
Conjunto de links, conjunto de vizinhos a 1 salto, conjunto de vizinhos a 2 saltos, tabela de topologia, e base de informações de múltiplas interfaces de rede (Seção 3.3).
Caso ocorra alterações, como inserção ou exclusão de tuplas em qualquer desses repositórios, toda tabela de roteamento é recalculada a fim de manter atualizadas rotas para todos os destinos da rede.
O ato de recalcular a tabela de roteamento não cria ou dispara quaisquer mensagem adicional a ser transmitida por a rede ou na vizinhança, visto que são utilizadas apenas informações de tabelas locais.
Cada entrada de rota é registrada na tabela de roteamento no seguinte formato:
R_ dest_ addr -- R_ next_ addr R_ dist R_ iface_ addr R_ iface_ addr Por fazer roteamento salto- a- salto, para cada destino da rede, o OLSR registra na tabela de rotas apenas o próximo salto na rota em direção a o destino.
Em uma entrada de rota na tabela de roteamento o campo R_ dest_ addr equivale a um dos destinos da rede, o qual está a uma distância igual a R_ dist (em número de salto) do nodo local;
Para cada destino R_ dest_ addr é guardada apenas uma entrada na tabela de roteamento, logo o número de entradas na tabela de roteamento será igual ao número total de nodos da rede menos um (o nodo local que executa o cálculo).
O R_ next_ addr é o endereço da principal da interface de rede de um vizinho simétrico, que obrigatoriamente é um nodo MPR do nodo local, sendo portanto, o nodo escolhido como próximo salto na rota em direção a o destino R_ dest_ addr.
Já R_ iface_ addr é o endereço da interface de rede do nodo local, por a qual é possível alcançar o nodo vizinho simétrico R_ next_ addr.
O campo R_ iface_ addr é utilizado, porque um mesmo nodo pode possuir várias interfaces de rede, e é necessário saber por quais de elas é possível alcançar o R_ next_ addr.
Como neste trabalho todos os nodos foram configurados com apenas uma interface de rede, R_ iface_ addr sempre recebe o endereço da principal interface do nodo local.
Segundo Jacquet, para construir e manter uma tabela de roteamento num nodo X, um algoritmo que encontra o &quot;menor caminho «entre dois nodos é executado sobre um grafo direcionado contendo o arco X-\&gt; Y, onde Y é qualquer vizinho simétrico de X;
O arco Y-&gt; Z, onde Y é um nodo vizinho a 1 salto (Subseção 3.3.3), cujo campo &quot;willingness «seja diferente de &quot;nunca disponível», e desde que, exista uma entrada na tabela de vizinhos a 2 saltos com Y como N_ neighbor_ main_ addr e Z como N_ 2h op_ addr (Subseção 3.3.4);
E o arco U-\&gt; V, onde existe uma entrada na base de informações sobre a topologia da rede (Subseção 3.3.7) com V como T_ dest_ addr e U como T_ last_ addr.
Tanto o algoritmo proposto em Jacquet Como o implementado na versão do OLSR para o Ns-2 utilizam o algoritmo de &quot;busca em largura «sobre um grafo, pois esse algoritmo descobre todos os vértices à distância h a partir de X, antes de descobrir quaisquer vértices à distância h+ 1.
Em Jacquet, são encontrados os procedimentos para calcular ou recalcular as tabelas de roteamento em cada nodo executando o OLSR, os quais transcrevemos a seguir: (tradução nossa) 1 Todas as entradas da tabela de rotas são removidas. --
Para cada registro na tabela de vizinhos a 1 salto, cujo link seja simétrico (N_ status $= SYM), e cujo tempo de validade do link seja maior que a hora atual (L_ time\&gt; $= hora atual) uma nova entrada de rota é registrada na tabela de roteamento, onde destino (R_ dest_ addr) e o endereço do próximo salto (Rnext_ addr) são ambos iniciados com o endereço do vizinho analisado e a distância (R_ dist) é iniciada com 1 salto:
R_ dest_ addr $= L_ neighbor_ iface_ addr, da tupla do link analisado;
R_ next_ addr $= L_ neighbor_ iface_ addr, da tupla do link analisado;
R_ dist R_ iface_ addr $= L_ local_ iface_ addr da tupla do link analisado;
N_ neighbor_ main_ addr corresponde a pelo menos um nodo vizinho a 1 salto cujo campo willingness seja diferente de &quot;nunca disponível «então a tupla recebe:
R_ dest_ addr $= O endereço principal do vizinho a 2 saltos (N_ 2h op_ addr);
R_ next_ addr $= O R_ next_ addr da entrada na tabela de roteamento em que:
R_ dest_ addr N_ neighbor_ main_ addr da tupla de vizinho a 2 salto em análise;
R_ dist R_ iface_ addr $= O R_ iface_ addr da entrada na tabela de roteamento em que:
R_ dest_ addr N_ neighbor_ main_ addr da tupla de vizinho a 2 saltos; --
Para cada entrada na Tabela De Topologia, se o seus T_ DEST_ ADDR não corresponde a R_ DEST_ ADDR de qualquer entrada de rotas na tabela de roteamento, E seu T_ LAST_ ADDR corresponde a R_ DEST_ ADDR de uma entrada de rota, cujo R_ DIST seja igual a h (saltos), então uma nova entrada de rota deve ser registrada na tabela de roteamento (se já não existe) onde:
R_ dest_ addr $= T_ dest_ addr da tupla da tabela de topologia em análise;
R_ next_ addr $= R_ next_ addr da entrada de rota registrada R_ dist R_ iface_ addr $= R_ iface_ addr da entrada de rota registrada 5 Em caso de haver múltiplas interfaces de rede, para cada entrada na base de múltiplas interfaces de rede, onde base de múltiplas interfaces de rede) &quot;e «não existir entrada de criada na tabela de roteamento com:
R_ dest_ addr I_ iface_ addr da entrada da base de múltiplas interfaces de rede;
R_ next_ addr R_ next_ addr e então os destinos a h+ 1 saltos, até que seja construída rota para o último destino mais distante da rede.
Conforme análise feita em Abolhasan, o OLSR tem se destacado de entre vários protocolos de roteamento pró-ativos propostos, por manter o tempo todo uma rota para cada destino conhecido na rede e ainda reduzir significativamente o número de mensagens de controle na rede por utilizar apenas nodos selecionados como MPR para repassar mensagens de controle.
Mesmo apresentando tais vantagens, pesquisas têm constatado que o critério de seleção de rotas do OLSR, com base apenas no número de saltos pode não proporcionar as melhores rotas.
Segundo Aslam Tais rotas podem não dar suporte a qualidade de serviço (QoS) para satisfazer os requisitos de aplicações como transmissão de voz e vídeo, visto que nem sempre o menor caminho atende a restrições quanto a taxa de perdas de pacotes, atrasos, jitter (variação do atraso) e banda mínima por se apresentarem instáveis.
Em Leguay Foram analisadas várias extensões do protocolo OLSR que visam prover qualidade de serviço às rotas selecionadas.
De entre as propostas analisadas, está a apresentada em Lamont, que propõe que o conjunto MPR de um nodo seja formado por os nodos que possuam links de maior largura de banda, isto porque no critério padrão do OLSR nodos de links de baixa largura de banda ou que apresente alto congestionamento podem ser selecionados.
Segundo Leguay QoS e realmente garante rotas com maior comprimento de banda e menor atraso fim-afim.
Todavia aumenta o tamanho do cabeçalho das mensagens Tc e é incompatível com a versão padrão do OLSR.
Em Couto É apresentada uma nova métrica para seleção de rotas o ETX (Expected Transmission Count), a qual busca rotas de maior largura de banda por encontrar rotas com o menor número esperado de transmissões requeridas para que um pacote possa ser entregue e seu recebimento possa ser confirmado por o destino final, mesmo que essa rota apresente um número maior de saltos.
Caso haja mais de uma rota com o mesmo ETX, então é escolhida aquela que possuir menor número de saltos.
Esta abordagem leva em consideração o fato de que em MANETs várias rotas podem ter a mesma quantidade de saltos, entretanto com diferentes qualidades dos links, podendo ocorrer que rotas com maior número de saltos apresentem maior qualidade.
Uma extensão do OLSR tem sido proposta por o projeto OLSR.
ORG utilizando essa métrica.
Segundo Cordeiro, de acordo com estudo comparativo feitos por Passos O protocolo OLSR com a extensão ETX em redes móveis ad hoc sem fio tende a causar instabilidade de rotas e altas taxas de perda de pacotes.
Isso ocorre porque em algumas situações a métrica ETX pode dar uma falsa visão a respeito de o estado da rede.
Em Cordeiro, é proposto OLSR-LD (OLSR Link Delay), o qual apresenta uma extensão para a escolha de rotas no protocolo OLSR baseado na métrica de retardo de transmissão entre dois nodos, em adição às métricas de menor perda e número mínimo de saltos.
Esse protocolo, segundo o autor, une características do OLSR a uma técnica de medição de capacidade de enlace chamada adHoc Probe, a qual foi enlace apenas num sentido, para tanto, pares de pacotes de tamanho fixo devem ser enviados em direção única, com o tempo de envio registrado em cada pacote transmitido.
A o receber esse pacote de controle, o destino pode então calcular o atraso de via única OWD (One Way Delay) e a capacidade do enlace num sentido.
Segundo Cordeiro, ao se calcular o OWD mínimo é possível determinar, também, o retardo da transmissão.
Como o AdHoc Probe fornece informações do atraso apenas num sentido, a mensagem HELLO foi alterada para que informações do retardo possam ser obtidas em ambos os sentidos do enlace, para tanto, duas mensagens de controle HELLO são enviadas ao mesmo tempo, com o mesmo tamanho e em tempos regulares.
Caso o tamanho fixo da mensagem não seja alcançado, esse pacote é preenchido com bits extras para que todos as mensagens HELLO do OLSR-LD tenham o mesmo tamanho.
A mensagem Tc também foi alterada, a fim de carregar informações do retardo de transmissão entre o nodo emissor e todos os seus MPR Selectors.
A ideia é que rotas com menor retardo na transmissão possam ser escolhidas reduzindo o atraso e a perda de pacotes.
Como se observa, porém, esse protocolo introduz uma grande carga de roteamento na rede, pois duplica o número de mensagens HELLO, além de inserir bits adicionais para que o tamanho fixo possa ser alcançado.
Em este capítulo é descrito o novo critério de seleção de rotas para o OLSR.
Em este critério, em cada entrada na tabela de roteamento, o próximo nodo (próximo salto) em direção a um destino é selecionado se ele faz parte da menor rota de maior grau de conectividade, o que difere do OLSR original que usa apenas o tamanho do caminho (caminho mais curto em saltos) como critério.
A a versão do OLSR executando esse critério conectividade do caminho.
Os criadores do OLSR na RFC 3626 (Request for Comments) afirmam que, em situações onde exista vários caminhos diferentes, de mesmo comprimento, até um dado destino, vários nodos vizinhos a 1 salto podem ser selecionados como próximo salto.
Esses autores sugerem que, nessas situações, seja possível selecionar como próximo salto aqueles nodos MPR que possuírem maior grau de disposição em repassar (willingness) pacotes em nome de outros nodos.
Considerando a situação acima, não propomos como critério de desempate a avaliação do grau de disposição em cooperar dos nodos MPR, mas avaliamos se o nodo MPR, vizinho a 1 salto, faz parte do menor caminho de maior grau de conectividade.
O restante deste capítulo está organizado da seguinte forma:
Em a Seção 4.1 a proposta de implementação do protocolo é descrita;
Em a Seção 4.2 são apresentadas as mudanças efetuadas no OLSR original para viabilização do novo critério de seleção de rotas;
Em a Seção 4.3 é apresentado o algoritmo de seleção de rotas do protocolo proposto;
O OLSR_ PD não é um novo protocolo de roteamento, mas uma extensão do OLSR que segue os princípios básicos de funcionamento desse protocolo (Capítulo 3), utilizando as mesmas mensagens, estruturas de dados, e comportamentos em ele implementados.
Por herdar tais características do OLSR, o OLSR_ PD é, também, um protocolo de roteamento dinâmico, por fazer roteamento salto- a- salto, e robusto, pois se adapta bem às falhas se recuperando de elas sem que seja necessário reinicializar todo serviço e que todos os pacotes tenham de ser reenviados toda vez que ocorrerem falhas.
Tanto no OLSR como no OLSR_ PD são mantidas entradas na tabela de roteamento para cada destino da rede.
Por fazerem roteamento salto- a- salto, uma entrada na tabela de roteamento não registra toda rota até ao destino, mas apenas o endereço do próximo salto para alcançar- lo.
Em redes MANETs, em situações de alta densidade de nodos na rede, ocorre de vários nodos poderem ser utilizados como próximo salto na rota, pois fazem parte de rotas que possuem o mesmo número de saltos e levam aos mesmos destinos.
Para esta situação, propomos, neste trabalho, um novo critério de seleção de rotas ao OLSR, o qual visa tomar como próximo salto na rota, aquele nodo que fizer parte da &quot;menor rota de maior grau de conectividade».
O principal propósito em adotar esse critério é que, caso ocorram falhas na rota em uso e links dessa rota se tornem indisponíveis, o nodo imediatamente anterior a falha, sendo um nodo da rota de maior grau, deve ter maior probabilidade, se comparado a nodos de outras rotas, de calcular, mais rapidamente, uma rota alternativa para o destino.
Paralelamente a isso, tendo detectado a falha, o nodo deve enviar uma mensagem Tc aos outros nodos, com informações das alterações na topologia da rede.
Nodos anteriores a este, na mesma rota de dados, receberão a mensagem Tc e, por fazerem parte da rota de maior grau, têm maior chance de calcular uma rota alternativa para o destino, se comparados a nodos de outras rotas.
Assim, utilizando este critério, espera- se que os nodos da rota escolhida tenham maior probabilidade de encontrar rotas alternativas para alcançar um dado destinatário de dados, de tal forma que o descarte de pacotes, devido a a mudança topológica durante o tráfego de dados, seja minimizado.
Além de a redução no descarte de pacotes, espera- se reduzir ainda o atraso fim-a-fim e a variação do atraso (jitter), com pouco ou insignificante aumente do overhead na rede, quando comparado à versão original do OLSR.
São encontrados na literatura alguns algoritmos roteamento que usam critérios semelhantes ao proposto nesse trabalho.
Em Shoroeder é proposto um protocolo de roteamento reativo, dinâmico e tolerante a falhas (Subseção 2.3.2), em que cada nodo, sempre que precisa enviar ou encaminhar algum pacote de dados, executa o algoritmo do fluxo máximo para avaliar qual de seus vizinhos a 1 salto possui maior número de caminhos redundantes em direção a o destino.
Aquele que possuir o maior fluxo máximo, também é o nodo que possui maior quantidade de caminhos disjuntos até o destino e, por consequência maior é o número de atalhos que podem ser utilizados em caso de falha.
Segundo Shoroeder, uma característica interessante desse protocolo é que, nem sempre o caminho mais robusto, ou de maior grau de redundância, será o menor caminho, podendo ocorrer de destinos que estão a dois ou três saltos de distância precisarem do dobro ou mais saltos para que sejam alcançados.
É importante destacar as diferenças básicas entre o algoritmo proposto neste trabalho e o de Shoroeder.
Primeiro que o protocolo apresentado aqui é pró-ativo e o outro reativo;
Segundo que, em Shoroeder dado um par de vértices (origem, destino), para cada nodo vizinho do nodo origem é avaliada todas as arestas a fim de identificar quantas de elas levam ao destino, obtendo- se assim, a aresta que a partir de ela, possui o maior número de caminhos de links disjuntos até o destino, mesmo que esse caminho possua o dobro ou mais saltos que o menor caminho para esse destino.
Em o OLSR_ PD é verificado, para cada destino, qual o menor caminho que apresenta maior grau de conectividade, o qual é dado por a soma do grau de conectividade de todos os nodos de uma rota.
Para implementar esse critério no OLSR_ PD, é preciso que cada nodo conheça o grau de conectividade de todos os nodos MPR da rede, pois somente nodos MPR podem ser utilizados na formação de rotas em redes com nodos OLSR.
Para calcular o seu grau de conectividade, cada nodo MPR S, antes de enviar uma mensagem Tc, conta o número de vizinhos contidos na tabela de vizinhos a 1 salto, com os quais possua um link de comunicação simétrico.
Então, cada nodo S insere a informação do seu grau de conectividade em todas as suas mensagens Tc, que são periodicamente enviadas para todos os nodos da rede.
A o receber uma mensagem Tc cada nodo cria ou atualiza uma tabela de topologia, armazenando informações dos links entre o nodo remetente S e seus MPR Selectors e também o grau do nodo S, informações essas, essenciais para o cálculo do grau de conectividade das possíveis rotas para cada destino da rede.
Esses conceitos serão melhores detalhados nas próximas seções.
Como visto na Seção 3.2, cada nodo ao receber as mensagens de HELLO toma conhecimento de todos os links de comunicação de ele com todos os seus vizinhos a até 2 saltos de distância, dando origem a três bases de informações:
Base de informações do conjunto de links (Subseção 3.3.2);
Base de informações sobre vizinhos a 1 salto (Subseção 3.3.3);
E base de informações sobre vizinhos a 2 saltos (Subseção 3.3.4).
A o receber mensagens Tc, enviadas por todos os nodos MPR da rede, cada nodo recebe informações dos links dos nodos MPRs com seus MPR Selectors (nodos que selecionaram o nodo que enviou a mensagem Tc como seu MPR) (Seção 3.1), dando origem a uma tabela chamada &quot;base de informações da topologia da rede «ou &quot;tabela de topologia».
Essa tabela de topologia foi extraída do arquivo de registro da simulação (traces) com 10 nodos executando o OLSR, no tempo de 20 segundos de simulação.
Ela é composta por 4 colunas (veja Subseção 3.3.7), sendo que a coluna T_ dest_ addr recebe o endereço da interface de um nodo MPR Selector;
A coluna T_ last_ addr recebe o principal endereço do nodo MPR selecionado;
A coluna T_ seq recebe o número de sequência contido na mensagem Tc;
E o T_ time registra o tempo de validade da tupla na tabela de topologia.
Conforme se observa na Tabela 3 a partir de a primeira linha, primeira coluna, os nodos 5, 7, 9, 3 e 4 fazem parte do conjunto de MPR Selectors do nodo 6, e que os nodos 8, 6, 3 fazem parte do conjunto de MPR Selectors do nodo 5 e assim sucessivamente.
Com base nessas duas colunas podemos obter, parcialmente, o número de arestas incidentes sobre um vértice.
Parcialmente porque, nem todos os vizinhos de um nodo o selecionam como seu MPR.
Para o nodo 6 identificamos na tabela de topologia o conjunto conectividade desse nodo d $= 5, conforme se observa na Figura 15.
Já para o nodo 5 é encontrado apenas 3 arestas, a saber representa o grau desse nodo, pois d $= 4.
Como se observa, apenas com base nas informações da tabela de topologia não é possível obter o grau dos nodos, a fim de calcular rotas com base no grau de conectividade dos nodos do caminho.
Visto que, o OLSR não possui todas as informações necessárias para o cálculo do grau de conectividade dos nodos da rede, algumas alterações nas estruturas da mensagem Tc e das tabelas de topologia e de roteamento se fizeram necessárias, como descrito na próximas subseções.
Para que cada nodo tome conhecimento do grau de conectividade todos os nodos MPR da rede, visto que apenas as informações das estruturas de dados disponíveis no OLSR não são suficientes, foi acrescentado ao cabeçalho da mensagem Tc um novo campo o qual chamamos de &quot;Grau_ nodo_ que_ envia_ TC», aumentando o cabeçalho dessa mensagem em dois 2 bytes que é suficiente para representar números entre 0 e 65535.
O grau de um nodo é calculado toda vez que um nodo MPR gerar uma mensagem Tc contendo a sua tabela de MPR Selectors (3.2.2). Como
visto na seção 2.5 o grau de um nodo (vértice) é dado por o total de arestas (links) incidentes nesse nodo.
Em o OLSR, essa informação pode ser obtida contando- se a quantidade de vizinhos simétricos que um dado nodo possui, com base em sua &quot;tabela de vizinhos a 1 salto».
Após contar o número de vizinhos, esse total é acrescentado ao campo &quot;Grau_ nodo_ que_ envia_ TC «e então a mensagem é enviada para todos os nodos da rede, sendo repassados apenas por os nodos MPR do nodo que cria ou que repassa essa mensagem.
Para armazenar o grau de conectividade do nodo que envia a mensagem Tc, foi acrescentado à tabela de topologia um campo chamado T_ grau.
A seguir é apresentado a estrutura da nova tabela de topologia:
T_ dest_ addr ­ T_ last_ addr T_ seq T_ grau T_ time Em a Tabela 4 é apresentada a tabela de topologia para o nodo 9 da rede da Figura 15 agora calculada por o OLSR_ PD.
Em a quarta coluna, &quot;T_ grau», é encontrado o grau de todos os nodos MPR listados na segunda coluna dessa tabela (T_ last_ addr).
Em essa rede apenas os nodos 7 e 8 não constam como MPR de nenhum nodo, por isso não têm os seus endereços listados na coluna 2 sendo, portanto, lhes atribuído grau de conectividade igual a 0, isso porque não são MPR.
Isso não é um problema para a formação de rotas no OLSR_ PD, visto que, no OLSR nodos não MPR nunca são utilizados como nodos intermediários ou como próximo salto na tabela de roteamento, mas apenas como nodo destino.
A situação dos nodos 7 e 8 muda, se e somente se, ocorrer mudanças na topologia da rede e algum nodo eleger- los como seu MPR.
Tanto no OLSR quanto no OLSR_ PD a tabela de roteamento é calculada toda vez que a rede é inicializada ou recalculada toda vez que ocorrem alterações na topologia da rede.
A diferença básica é que, para suportar o cálculo do &quot;grau do caminho «proposto neste trabalho, a tabela de roteamento do OLSR_ PD recebe um campo chamado &quot;R_ soma_ grau «responsável por guardar o grau de conectividade do caminho a ser percorrido a partir de o próximo salto na rota &quot;R_ last_ addr».
A estrutura dessa tabela de roteamento é apresentada a seguir:
R_ dest_ addr -- R_ next_ addr -- R_ dist -- R_ iface_ addr -- R_ soma_ grau Cada entrada na tabela de roteamento de nodos OLSR_ PD pode ser interpretada da seguinte forma:
O grau do caminho &quot;R_ soma_ grau «da menor rota de maior grau até o destino &quot;R_ dest_ addr «está a uma distância &quot;R_ dist «do nodo local, cujo próximo salto é &quot;R_ next_ addr», nodo este, que faz parte do menor caminho de maior grau de conectividade e pode ser alcançado a partir de a interface de rede &quot;R_ iface_ addr «do nodo local.
Conforme proposto na RFC 3626 e implementado por Ros, o cálculo da tabela de roteamento em nodos OLSR é feito executando- se um algoritmo do &quot;caminho mais curto».
Após encontrar o primeiro &quot;caminho mais curto «o vizinho simétrico do nodo local, participante dessa rota, é eleito como o &quot;próximo salto «(R_ next_ addr) em direção a o destino.
Em o OLSR_ PD, também é utilizado o algoritmo do &quot;caminho mais curto», todavia, são avaliados todos os caminhos disponíveis de mesmo comprimento que levam ao destino, porém escolhido apenas aquele que possuir o &quot;maior grau de conectividade».
Após a escolha da rota, o vizinho simétrico do nodo local, participante dessa rota, é então selecionado como &quot;próximo salto «para alcançar aquele destino.
O procedimento utilizado por o OLSR para encontrar o &quot;caminho mais curto «numa rede, baseia- se em executar o algoritmo de &quot;busca em largura «sobre o grafo da rede.
Em Cormen Encontramos a seguinte definição para o algoritmo de &quot;busca em largura&quot;:
Dado um grafo G $= (V, E) e um vértice de origem distinta s, a busca em largura explora sistematicamente as arestas de G até &quot;descobrir «cada vértice acessível a partir de s.
O algoritmo calcula a distância (menor número de arestas) desde s até todos os vértices acessíveis desse tipo.
Ele também produz uma &quot;árvore primeiro na extensão «com raiz s que contém todos os vértices acessíveis.
Para qualquer vértice v acessível a partir de s, o caminho na árvore primeiro na extensão de s até v corresponde a um &quot;caminho mais curto «de s até v em G, ou seja, um caminho que contém o número mínimo de arestas.
O algoritmo funciona sobre grafos orientados e também não orientados.
A busca em largura recebe esse nome porque expande a fronteira entre vértices descobertos e não descobertos uniformemente ao longo.
Isto é, o algoritmo descobre todos os vértices à distância k a partir de s, antes de descobrir quaisquer vértices à distância k+ 1. (
pg 422) Para calcular a tabela de roteamento do OLSR_ PD, o algoritmo de busca em largura é executado em cada nodo da rede, criando entradas de rotas para todos os destinos que estão a uma distância h do nodo X, ou seja, primeiro avalia- se todos os arcos X-\&gt; Y, onde Y é qualquer vizinho simétrico de X. O grau do caminho para cada destinho Y é igual ao total de vizinhos de Y informado nas mensagens de HELLO e disponível na tabela de vizinhos a 2 saltos.
Para cada destino a 2 saltos (h $= 2), representados por o arco Y-&gt; Z, onde Y é um nodo vizinho a 1 salto, cujo campo &quot;willingness «seja diferente de &quot;nunca disponível «e desde que exista uma entrada na tabela de vizinhos a 2 saltos com Y como N_ neighbor_ main_ addr e Z como N_ 2h op_ addr, o grau do caminho até Z é dado por a soma do &quot;R_ soma_ grau «do nodo Y mais o grau do nodo destino Z contido na em o campo &quot;T_ grau «da tabela de topologia.
Em caso de haver mais de um caminho para o destino Z, sempre o que possuir o maior grau de conectividade será o escolhido.
Para destinos a mais de 2 saltos, representados por o arco U-\&gt; V, onde existe uma entrada na tabela de topologia da rede (Subseção 4.2.2) com V como T_ dest_ addr e U como T_ last_ addr, já o grau do caminho até V é dado por a soma do grau de V, encontrado no campo &quot;T_ grau «da tabela de topologia, mais o &quot;R_ soma_ grau «do nodo &quot;R_ dest_ addr «da tabela de roteamento que seja igual ao nodo U. Havendo mais de um caminho com a mesma distância até U, aquele que possuir maior grau de conectividade é o escolhido.
Todo o procedimento para calcular ou recalcular as tabelas de roteamento em nodos executando o OLSR_ PD, com exceção do cálculo do grau de conectividade do caminho, segue basicamente os mesmos princípios de execução do OLSR.
A seguir, é apresentado o procedimento utilizado para o cálculo da tabela de roteamento do OLSR_ PD, em o qual é dado destaque, em &quot;negrito», para o cálculo do grau de conectividade da rotas da rede.
R_ dest_ addr $= L_ neighbor_ iface_ addr, da tupla do link analisado;
R_ next_ addr $= L_ neighbor_ iface_ addr, da tupla do link analisado;
R_ dist R_ iface_ addr $= L_ local_ iface_ addr da tupla do link analisado;
R_ soma_ grau $= Total de vizinhos do nodo L_ neighbor_ iface_ addr tal que:
N_ neighbor_ main_ addr corresponda a pelo menos um nodo vizinho a 1 salto cujo campo willingness seja diferente de &quot;nunca disponível», então a tupla da tabela de roteamento recebe:
R_ dest_ addr $= O endereço principal do vizinho a 2 saltos (N_ 2h op_ addr);
R_ next_ addr $= O R_ next_ addr da entrada na tabela de roteamento em que:
R_ dest_ addr N_ neighbor_ main_ addr da tupla de vizinho a 2 salto em análise;
R_ dist R_ iface_ addr $= O R_ iface_ addr da entrada na tabela de roteamento em que:
R_ dest_ addr N_ neighbor_ main_ addr da tupla de vizinho a 2 saltos;
R_ soma_ grau $= O grau do nodo N_ 2h op_ addr contido no campo &quot;T_ grau «da tabela de topologia, tal do caminho do nodo R_ next_ addr da entrada na tabela de roteamento em que:
R_ dest_ addr N_ neighbor_ main_ addr da tupla de vizinho a 2 salto em análise;
T_ dest_ addr não corresponder a algum destino R_ dest_ addr da tabela de roteamento &quot;e «o T_ last_ addr da tupla em análise, corresponder a R_ dest_ addr de alguma entrada de rota, cujo R_ dist seja igual a &quot;h», então uma nova entrada de rota deve ser criada, onde:
R_ dest_ addr $= T_ dest_ addr da tupla da tabela de topologia em análise;
R_ next_ addr $= R_ next_ addr da entrada de rota registrada R_ dist R_ iface_ addr $= R_ iface_ addr da entrada de rota registrada R_ soma_ grau $= O grau de T_ dest_ addr contido no campo &quot;T_ grau «da tabela de topologia mais o grau do caminho para o nodo R_ dest_ addr da entrada na tabela de roteamento em que:
Caso o T_ dest_ addr corresponda a R_ dest_ addr de alguma entrada da tabela de roteamento (caso já exista rota para o destino) e a distância R_ dist do nodo R_ dest_ addr seja diferente de h+ 1, então descarta- se essa nova entrada e passa- se a análise da próxima tupla da tabela de topologia.
R_ dest_ addr I_ iface_ addr da entrada da base de múltiplas interfaces de rede;
R_ next_ addr R_ next_ addr (da entrada de rota onde R_ dist $= R_ dist (da entrada de rota onde R_ iface_ addr $= R_ iface_ addr (da entrada de rota onde R_ soma_ grau $= O grau de I_ iface_ addr contido no campo &quot;T_ grau «da tabela de topologia, tal que caminho do nodo R_ dest_ addr da entrada na tabela de roteamento em que:
Em o Apêndice B é apresentado o algoritmo (pseudocódigo) e as estruturas de dados básicas utilizadas no cálculo da tabela de roteamento no OLSR_ PD.
Para demonstrar o funcionamento do algoritmo que implementa o critério de seleção de rotas proposto neste trabalho, foram executadas simulações no Ns-2 (Network Simulator) com o OLSR e com o OLSR_ PD.
O cenário da rede ad hoc na simulação utilizada como exemplo possui 10 nodos, sem mobilidade e cuja topologia é representada na Figura 17.
A finalidade dessa simulação é obter as bases de informações criadas em cada protocolo para ajudar na compreensão do critério proposto neste trabalho.
Os resultados foram extraídos do arquivo de registro de simulação e da base de informações do conjunto de links (Tabela 6) do nodo que executa o cálculo, nesse caso o nodo 9.
Essas duas tabelas são idênticas em ambos os protocolos, portanto são representadas juntas.
Para construir sua tabela de rotas para vizinhos a 1 salto, o nodo 9 executa o algoritmo de roteamento sobre sua tabela de vizinhos a 1 salto (Tabela 5).
O primeiro vizinho a ser avaliado, nesse exemplo é o nodo 5.
Então é verificado se o status do link nodo 5 é vizinho simétrico do nodo 9, então é avaliado na tabela de links (Tabela 6) se o tempo de vida do link é expirado.
Como o valor, em segundos, do campo nova entrada de rota é inserida na tabela de roteamento do nodo 9, onde:
O campo destino dessa tupla (R_ dest_ addr) recebe o endereço do nodo 5 em análise, o campo de próximo salto em direção a o destino (R_ next_ addr) recebe o endereço do próprio nodo 5, visto que, o destino está a apenas 1 salto de distância (R_ dist), portanto não necessitando de nodos intermediários, sendo o próprio destino o próximo salto na rota.
Já o campo R_ iface_ addr recebe o endereço da interface de rede do nodo local que liga este nodo ao nodo próximo salto em direção a o destino (R_ next_ addr) que nesse caso é também o endereço identificador do próprio nodo local 9.
O campo grau do caminho (R_ soma_ grau) para do nodo destino 5 é obtido analisando- se quantas vezes o nodo 5 aparece no campo &quot;N_ neighbor_ main_ addr «da tabela de vizinhos a 2 saltos mais 1.
Observe que na Tabela 8 constam os links partindo do nodo 5: (5,6), (5,8), (5,3), ou seja, apenas 3 links.
Por não constar nessa tabela o link entre os nodos 5 com o nodo 9, que executa o cálculo, é sempre somado mais 1 ao total de links identificados, de forma que o grau do caminho do nodo 9 até o nodo 5 é igual a &quot;4».
Tabela 6 -- Base de informações do conjunto de links do nodo 9 OLSR e OLSR_ PD L_ local_ iface_ addr L_ neighbor_ iface_ addr L_ SYM_ time L_ ASYM_ time L_ time Calculada entradas de rota para o nodo destino 5, então são avaliados todos os outros nodos vizinhos a 1 salto seguindo os mesmos critérios apresentados acima.
Após encerrado o cálculo de rotas para os vizinhos a 1 salto a tabela de roteamento do nodo 9 estará como apresentado na Tabela 7.
Para calcular as entradas de rotas para vizinhos a 2 saltos, o nodo 9 executa o algoritmo de roteamento sobre sua tabela de vizinhos a 2 saltos.
Em a Figura 17, os nodos a 2 saltos do nodo 9, são representados por os vértices pintados de vermelho.
Analisando a Tabela 8, o primeiro vizinho a 2 saltos avaliado como destino, é o nodo 5.
O primeiro passo é verificar se o nodo 5, informado nessa tabela como um vizinho a 2 saltos não é também um vizinho a 1 salto.
Verifica- se que o nodo 5 é na verdade um vizinho a 1 salto, visto que, o nodo 5 aparece como vizinho a 2 saltos (N_ 2h op_ addr) e também aparece como um vizinho simétrico a 1 salto (N_ neighbor_ main_ addr), logo o cálculo de uma entrada de rota para o nodo 5 é cancelada e passa- se então para análise do próximo registro.
É importante observar que na mesma situação do nodo 5 estão os nodos 6 e 8, pois são informados como vizinhos a 2 saltos, mas também são vizinhos a 1 salto, logo os mesmos procedimentos são executados para esses nodos.
Em a Figura 17, os vertices que representam os nodos 5, 6 e 8 são pintados de azul, por serem vizinhos a 1 salto, porém as bordas desses vértices são pintadas de vermelho, representando que esses nodos também são informados como sendo vizinhos a 2 saltos.
Após avaliado o nodo 5, na próxima iteração é analisado o nodo 3 como um destino a 2 saltos.
A leitura dessa tupla, da Tabela 8, pode ser assim compreendida:
Que o vizinho simétrico 6 informa que possui um link simétrico com o nodo 3, e que o tempo de vida dessa tupla expira no tempo de 24.493948 da simulação.
Como exposto no parágrafo anterior, primeiro é verificado se o nodo 3 não é também um vizinho a 1 salto.
Verifica- se que esse nodo não é vizinho a 1 salto, pois não existe entrada na tabela de vizinhos a 1 salto, cujo vizinho simétrico seja o nodo 3.
Verificando ainda a entrada para o destino 3, é analisado se o nodo 6 (N_ neighbor_ main_ addr) da tabela de vizinhos a 2 saltos (Tabela 8) é também um vizinho simétrico, N_ neighbor_ main_ addr, contido na Tabela 5 e se este possui o grau de disposição em repassar mensagens em nome de outros &quot;willingness «diferente de &quot;nunca disponível», o que é positivo, visto que, o nodo 6 consta como um o nodo 3, está &quot;disponível «para repassar as mensagens deste nodo.
Encerrados os procedimentos de cálculo de rota para o destino 3, uma nova entrada de rota é inserida na tabela de roteamento do nodo 9, onde:
O campo destino dessa tupla &quot;R_ dest_ addr «recebe o endereço do nodo 3;
o campo de próximo salto em direção a o destino &quot;R_ next_ addr «recebe o endereço do nodo 6, pois é o nodo imediatamente anterior ao nodo 3 e por estar a 1 salto do nodo origem;
O campo &quot;R_ dist «que recebe o número de saltos para alcançar o nodo 3 que é igual a &quot;2&quot;;
O campo R_ iface_ addr recebe o endereço da interface de rede &quot;9 «que também é o identificador do nodo que executa o cálculo;
E por último o valor do campo &quot;R_ soma_ grau», que registra o grau do caminho até o destino 3, que é igual a &quot;9».
Esse valor é obtido analisando se existe alguma entrada na tabela de topologia do nodo 9, cujo o campo T_ last_ addr seja igual ao nodo destino 3 em análise.
Em a 9º tupla da Tabela 10 é encontrado o nodo 3 no campo T_ last_ addr, então é tomado o valor de &quot;T_ grau «dessa tupla, que é igual a &quot;4», mais o grau do caminho do nodo destino &quot;R_ dest_ addr «da tabela de roteamento (Tabela 7) que seja igual ao nodo N_ neighbor_ main_ addr da tupla de vizinho a 2 saltos em análise, nesse caso do nodo 6.
O grau do caminho para o destino 6 na tabela de roteamento é igual a &quot;5», logo o grau do caminho até o nodo destino em análise &quot;3 «é igual a &quot;4+ 5 $= 9».
Em as próximas iterações na tabela de vizinhos a 2 saltos, são analisados e igualmente calculadas rotas para os destinos 7, 6, 8 e 3.
A o encontrar novamente o nodo 3, subentende- se que a partir de o nodo 9 existe mais de uma rota para alcançar o nodo 3, sendo o primeiro caminho e o segundo recém encontrado,.
Após calculada o grau do caminho da nova rota até o destino 3, que é igual a &quot;8 «é verificado se este é maior que o grau do caminho da entrada anteriormente registrada para o nodo 3, que é igual a &quot;9».
Como o grau do caminho da nova entrada é menor que a anteriormente armazenada, essa nova entrada é descartada e a antiga é mantida na tabela de roteamento.
Os procedimentos para calcular rotas para vizinhos a 2 saltos são executados até que todas as tuplas da tabela de vizinhos a 2 saltos sejam analisadas.
Encerrada essa segunda fase da construção da tabela de roteamento, essa conterá entradas de rota para vizinhos a 1 e 2 saltos, como representada na Tabela 9.
Para exemplificar a execução da quarta etapa do algoritmo descrito na Seção 4.3, passamos então a analisar a tabela de topologia do nodo 9.
Em a outros campos.
A o ser executado para essa tupla, primeiro é verificado na tabela de roteamento, a que fora construída até este momento, se já existe rota para o nodo 5, bem como também existe entrada de rota correspondente ao nodo 6, que é o nodo imediatamente anterior a 5 capaz de alcançar- lo, todavia, verifica- se que o nodo 5 não está a h+ 1 saltos do nodo 9 (3 saltos nessa iteração), e que a distância do nodo 6 não é igual a h saltos, logo ignora- se essa entrada da tabela de topologia e passase para as próximas iterações.&amp;&amp;&amp;
Em as 9 primeiras tuplas da Tabela 10 (coluna OLSR_ PD) todos os nodos T_ dest_ addr correspondem a algum R_ dest_ addr da tabela de topologia, todavia esses destinos são não reprovados, igual porque h+ 1 ou porque R_ dist do destino nodo nodos para os quais ainda não foram construídas entradas de rotas, são os nodos 0, 1 e 2, cujas distâncias, em relação a o nodo 9, são respectivamente 4, 3, 3 saltos.
R_ dest_ addr $= T_ last_ addr, ou seja, que já existe entrada de rota para o nodo 3 e que saltos do nodo origem.
Então é criada uma nova entrada na tabela de roteamento onde:
O destino R_ dest_ addr recebe 2;
o próximo salto R_ next_ addr recebe 6 que é também o próximo salto para que o nodo 9 alcance o nodo 3;
o endereço da interface de rede do nodo 9, capaz de alcançar o destino 3, R_ iface_ addr recebe 9, que é o próprio endereço identificador do nodo 9;
o campo que registra a distância do destino 3 em relação a o nodo 9, R_ dist recebe h+ 1, ou seja, 3;
e por último o campo que registra o grau do caminho &quot;R_ soma_ grau «que é obtido somando- se o grau do nodo destino 2, d $= 3, mais o grau logo o grau do caminho até o destino 2 passando por T_ last_ addr é igual a d $= 12.&amp;&amp;&amp; Após inserir a entrada de rota para o destino 2, nas próximas iterações sobre a tabela de topologia, serão avaliados vários T_ dest_ addr, todavia, apenas entradas para 0 e 1 serão criadas, executando- se os mesmos procedimentos descritos até aqui.
Para exemplificar casos em que existem mais que uma rota para alcançar um mesmo destino a mais de 2 saltos do nodo origem, tomemos como exemplo a entrada para o nodo 2.
Continuando as iterações sobre a tabela de topologia, ao alcançar a 17ª seleção de rotas para vizinhos a h+ 1 saltos do nodo origem, como descrito anteriormento, rotas para o nodo 0, então essa tupla é reprovada e não mais analisada.
Em a 19ª tupla, verifica- se que existem entradas de rotas tanto para os nodos 2 quanto para o nodo 4.
A seguir é analisado então se o nodo 2 está a h+ 1 saltos do nodo 9 e se o nodo 4 está a h saltos, o que é positivo, indicando a existência de uma nova rota em direção a o destino 2, logo deve- se criar uma entrada de rota temporária para o destino 2, onde:
R_ dest_ addr $= 2;
R_ last_ addr $= 6;
R_ iface_ addr $= 9;
R_ dist $= 3;
e R_ soma_ grau $= 11.
Logo após, é comparado o grau do caminho da nova entrada, que é igual 8, com o grau do caminho da antiga entrada de rota, que é igual 12.
Como o grau do caminho da nova entrada é menor, está é descartada e antiga mantida.
Em essa quarta etapa de execução desse algoritmo serão avaliados todos os destinos que estão a mais de 2 saltos do nodo origem, até que não seja mais encontrado nenhum destino a ser avaliado.
Como neste trabalho os nodos são configurados para trabalhar apenas com uma interface de rede, quando for executada a 5ª parte do algoritmo descrito na Seção 4.3, então a base de informações de múltiplas interfaces de redes (Subseção 3.3.2) será encontrada vazia, não sendo, portanto, executada nenhuma ação nessa etapa de execução do algoritmo.
Após executados os procedimentos descritos nesse capítulo, a tabela de roteamento do nodo 9 estará completa, como demonstrada na Tabela 11.
Em essa tabela estão disponíveis entradas de rotas para todos os nodos da rede, com exceção do 9 que a calculou, as quais permitem que o nodo 9 envie ou repasse mensagens para quaisquer nodos da rede, escolhendo apenas o próximo salto em direção a o destino.
Cada nodo ao receber uma mensagem a ser repassada, por possuir também uma tabela de rotas como a apresentada nesta seção, reencaminha os pacotes de dados que, de salto em salto, percorrendo sempre o caminho de maior grau de conectividade, alcança ao destino.
Em este trabalho a avaliação do desempenho do OLSR_ PD em relação a o OLSR é feita com base no método de simulação, que é um dos principais métodos para avaliar o desempenho de protocolos de roteamento.
Segundo Law e Kelton, a utilização de simulação para avaliar desempenho de sistemas traz vantagens significativas para o pesquisador, tais como:
Possibilidade de criação e controle dos cenários experimentais, de maneira que não seria possível no sistema real;
A possibilidade de simular longos períodos de execução de um sistema real em tempo reduzido;
E em geral, é mais econômico que testar o sistema real, pois evita gastos com aquisição e manutenção de equipamentos.
Em este capítulo são apresentados os resultados da avaliação de desempenho dos protocolos OLSR e OLSR_ PD, os quais são avaliados sob vários critérios.
O restante desse capítulo está organizado como se segue:
Em a Seção 5.1 são apresentadas as ferramentas utilizadas para simulação e extração dos resultados;
Em a Seção 5.2 são apresentadas as métricas utilizadas para avaliar o desempenho desses protocolos;
Em a Seção 5.3 são apresentadas as configurações utilizadas nas simulações executadas neste trabalho;
E, por fim, na Seção 5.4, os resultados das simulações são apresentados e analisados sob diversas métricas e critérios.
Para implementar a proposta de alteração no OLSR, fora utilizado o simulador de redes Ns-2 (Network Simulator) versão 2.31 que é um simulador de redes por eventos discretos direcionado para pesquisas em redes de computadores, criado basicamente utilizando duas linguagens de programação:
O C+, que é uma linguagem compilada, com o qual é implementado o núcleo do Ns-2;
e o OTCL (Object Tool Command Language), que é uma linguagem interpretada, a qual é usado para escrever os scripts da simulação em si, ou seja, para construir a topologia das redes, os cenários de mobilidade, as configurações dos nodos e os protocolos de comunicação e de roteamento a serem utilizados.
O Ns-2 dá suporte a simulações em redes cabeadas e wireless (tanto local como via satélite) e implementa agentes que representam os nodos de uma rede, sendo cada agente composto por camadas, individualmente configuráveis, que simulam nodos de redes.
A distribuição padrão do Ns-2 traz implementado os principais protocolos de roteamento em MANETs, como o DSDV, DSR, AODV e o Tora.
Como se observa a versão padrão desse simulador não traz uma implementação do OLSR, por isso foi instalado uma versão do OLSR implementada para o Ns-2 por Ros chamada 3626.
A partir de a versão original do OLSR foram feitas alterações na mensagem de controle de topologia Tc, na tabela de topologia e alterações no critério de seleção de rotas desse protocolo, dando origem assim à versão nomeada de OLSR_ PD.
Em a versão original do Ns-2 encontramos algumas ferramentas para geração de modelos de mobilidade e padrões de tráfego para as simulações:
O Setdest é o gerador de cenário e movimentação dos nodos com base no modelo de mobilidade Random Waypoint;
E o cbrgen.
Tcl que é um script feito em TCL para geração de padrões de tráfego.
Ambos os programas foram adotados nos experimentos com esses protocolos, pois geram arquivos de cenário de movimentação e de tráfego de dados na rede reconhecidos por o Ns-2 e por serem bastantes utilizados por a comunidade científica.
Para extrair os resultados apresentados neste trabalho, foi criado um pequeno script feito usando Shell Script1 e a linguagem AWK para geração de relatórios com informações como taxa de entrega, pacotes repassados com sucesso e o número de descartes e seus motivos (Apêndice C).
Para extração do atraso médio fim-a-fim e da variação do atraso (Jitter) foi utilizado o software TraceGraph que é uma ferramenta gráfica criada para auxiliar na análise dos resultados das simulações feitas no Ns-2, gerando relatório e mais de 200 gráficos.
As métricas de avaliação de desempenho citadas anteriormente, são descritas na próxima seção.
Para medir o desempenho do OLSR_ PD em relação a o OLSR, parâmetros como mobilidade e quantidade de nodos sofreram variações a fim de testar o desempenho do 1 Arquivo de texto que contem uma lista de comandos interpretados por um Shell, criado com a finalidade de automatizar tarefas repetitivas como criação de relatório e análise destes.
As métricas de avaliação de desempenho utilizadas neste trabalho são as seguintes:
Entregues ao destino e o número de pacotes gerados por a aplicação na fonte;
VoIP não é tolerante a perda de pacotes:
Perdas mínimas de 1%, por exemplo, podem degradar uma chamada, provocando erros audíveis.
HELLO e Tc, as quais possuem tamanhos diferentes, neste trabalho essa métrica será dada em &quot;total de bytes «de controle gerados na rede por simulação.
A fim de avaliar o desempenho do novo critério de seleção de rotas proposto neste trabalho, em relação a o OLSR, foram construídos cenários que permitam avaliar a taxa de entrega e repasse de pacotes com a variação da mobilidade e quantidade de nodos na rede, bem como os efeitos desse critério para outras métricas.
Em a Tabela 12 são apresentados os principais parâmetros utilizados para configurar as simulações.
10, 15 e 25 Número de conexões para cada quantidade de nodos.
0-1,5, e 020m/s Velocidades que podem variar entre o mínimo e o máximo numa simulação.
Para cada quantidade de nodos/ velocidade, foram execuções por simulação realizadas 10 execuções.
Foram combinados 2 padrões de movimentação com cinco padrões de tráfego diferentes.
Protocolos de Roteamento OLSR e Protocolo de tráfego de dados Tráfego CBR Área da simulação Áreas dadas em metros quadrados definidas 1000 x 1000, respectivamente para as quantidades de nodos 25, 1500 x 1500 e 50, 100 e 200 nodos.
Tempo de simulação 100 segundos Tempo em segundos de simulação padrão para todos os cenários/ mobilidade.
Modelo de Mobilidade Antena Randon Waypoint Protocolos de roteamento para redes wireless, próativos, que fazem roteamento salto a salto e se baseiam no estado do enlace, para reconstruir suas tabelas de roteamento.
Constant Bit Rate ou taxa constante de bits Padrão de movimentação gerado por o Setdest, um aplicativo que acompanha o Ns-2 para geração de cenários e padrões de movimentação de pontos aleatórios.
Um dos padrões de mobilidade mais utilizado em simulações com redes ad hoc.
OmniAntenna Antena Omni direcional que permite uma cobertura de Modelo de Propagação Shadowing Sombreamento ­ modelo de propagação que segundo o manual do Network Simulator é o mais indicado para ambientes outdoor.
Meio físico WirelessPhy Meio físico de transmissão sem fio.
Taxa de Geração de Pacotes 4 pacotes/ s Como o trafego é CBR, são enviados a cada segundo 4 pacotes.
Protocolo de transporte (User Datagram Protocol) Protocolo de transporte não orientado a conexão.
Tamanho dos Pacotes 1000 bytes Tamanho dos pacotes definidos na configuração do padrão de tráfego.
Tempo de Pausa dos nodos 2 segundos Tempo máximo de pausa de um nodo antes que ele inicie um nova movimentação como proposto por o padrão de movimentação Randon Waypoint.
Capacidade da fila (Buffer) 50 pacotes Buffer onde pacotes gerados aguardam por o acesso ao meio para que possam ser enviados.
Caso essa fila esteja cheia, pacotes mais antigos são descartados.
Segundo todos os pacotes, de dados e de roteamento, passam por esse buffer (fila) a qual implementa regras de prioridade para o envio dos pacotes.
Pacotes de controle tem prioridade sobre os pacotes de dados.
Para geração dos cenários de movimentação, foi utilizado o software Setdest, que cria cenários baseado no modelo de mobilidade Random Waypoint, modelo proposto e utilizado pela primeira vez por Johnson e Maltz.
Em este modelo cada nodo se move em direções aleatórias dentro de a área de simulação.
A adoção do Random a mobilidade dos nodos provoque rompimento de enlaces e consequentemente a reconfiguração da tabela de roteamento de cada nodo da rede.
Isso possibilita avaliar a taxa de entrega de pacotes de cada protocolo em cenários de mobilidade imprevisível e falhas de rota.
Para geração do tráfego de dados nas simulações, foi utilizado o gerador cbrgen.
Tcl, o qual cria aleatoriamente conexões TCP (Transport Control Protocol) ou UDP (User Datagram Protocol) entre dois nodos.
Em as simulações realizadas neste trabalho optou- se por utilizar o padrão de tráfego CBR (Constant Bit Rate) para operar em conjunto ao protocolo de transporte UDP, visto que o TCP emprega mecanismos de controle de congestionamento, o que não funciona com o serviço de tráfego CBR, pois este continua enviando pacotes sempre a uma mesma taxa, independente se há ou não congestionamento na rede.
O motivo da utilização do tráfego CBR é que, dado dois protocolos de roteamento, ambos executando o mesmo cenário de movimentação e tráfego CBR, a quantidade de pacotes de dados gerados por a aplicação é igual nos dois protocolos, o que permite avaliar- los em condições de igualdade, pois ambos são executados sob uma mesma carga de trabalho.
Em as simulações aqui apresentadas os pacotes de dados tiveram seu tamanho fixado em 1000 bytes, e foram gerados a uma taxa constante de 4 pacotes por segundos.
A transmissão de dados de cada conexão é iniciada em tempos aleatórios dentro de o intervalo de 0 a 30 segundos da simulação.
Como observado na Tabela 12, os principais parâmetros que sofreram variações nas simulações foram, quantidades de nodos, a mobilidade dos nodos e o número de conexões por simulação.
Foram criados cenários com 25, 50, 100 e 200 nodos, sendo o número de fontes de tráfego 10, 15 e 25 e o tempo de simulação igual a 100 segundos para todos os cenários.
Quanto a a variação da mobilidade dos nodos, para cada quantidade de nodos, foram criados dois cenários de baixa mobilidade, onde a velocidade dos nodos variam entre 0 a 1,5 m/ s, e dois cenários de alta mobilidade, em que a velocidade dos nodos variam entre 0 a 20 m/ s.
Para criar 10 diferentes cenários em cada simulação, considerando a relação quantidade de nodos/ mobilidade, foram criados cinco padrões de tráfegos com origens e destinos diferentes, os quais combinados com os dois cenários de mobilidade por simulação, originam os dez diferentes cenários.
A o variar a quantidade nodos nos ambientes de simulação, torna- se possível avaliar qual o nível de degradação no desempenho do OLSR e do OLSR_ PD diante de o aumento de nodos na rede.
A variação no número de nodos neste trabalho não tem a finalidade de aumentar a densidade da rede, visto que à medida que o número de nodos cresce, cresce também a área em a qual estão dispostos.
A densidade da rede, neste trabalho, é definida como o número médio de vizinhos a 1 salto por nodo (e).
Em Haerri a densidade de uma rede, que pode ser formalizada como:
Como se observa, a densidade média dos nodos das redes com 25 e 100 nodos é de 8,72, já as redes com 50 e 200 nodos possuem densidade igual a 9,81.
Verifica- se que há uma diferença de 1,09 na densidade entre essas redes.
Essa variação não interfere nas análises propostas neste trabalho, haja vista que, a intenção é avaliar o OLSR e OLSR_ PD quanto a a variação da mobilidade e quantidade de nodos na rede e possibilitar mais atividade de roteamento, para os cenários simulados.
Quanto a variação do parâmetro mobilidade, a intenção é avaliar a taxa de entrega de pacotes do OLSR_ PD em relação a o OLSR em situações de baixa e alta mobilidade.
Isto porque, como ambos os protocolos são pró-ativos, em situações de mobilidade basta uma mudança na vizinhança de um nodo, que será ativada a atualização das tabelas de rotas de todos os nodos da rede, provocando queda no desempenho desses protocolos.
Para compensar essas variações e dar maior credibilidade aos resultados, para cada quantidade de nodos foram realizadas 20 rodadas de execuções para cada quantidade de nodos, sendo 10 para os cenários de baixa mobilidade e 10 para os cenários de alta mobilidade.
Também para todas as métricas avaliadas são calculados o intervalo de confiança (IC2) de 95% relativos à média das amostras em cada simulação, que é um índice bastante utilizado para análise de resultados de simulações, os quais estão representados nos gráficos como uma barra de erros.
Conforme se observa na tabela Tabela 12 a área das simulações também variaram:
Para 25 nodos a área é de 750x750 metros;
Para 50 nodos 1000x1000;
para 100 nodos 1500x1500;
e para 2000 nodos 2000x2000.
Essa variação visa criar uma distância suficiente para que haja vários nodos intermediários nas conexões e, consequentemente, aumento de atividades de roteamento durante as simulações, o que não aconteceria se a área tivesse tamanho fixo, visto que o alcance do sinal de rádio de nodos 802.11b operando a uma frequência de 2,4 GHz pode chegar a 250 metros.
Em esta seção são apresentados os resultados das simulações realizadas neste trabalho.
Essas simulações foram conduzidas com a finalidade de avaliar o comportamento e a efiCiência do OLSR e do OLSR_ PD sob um variado conjunto de situações.
De uma forma geral, os parâmetros que variaram nos vários modelos de simulações são:·
alfa -- é o coeficiente de confiança que é uma probabilidade variando entre 0 ­ 1;·
DesvPad -- é o desvio padrão do intervalo das amostras;·
tamanho -- equivale ao número de amostras analisadas roteamento;
As métricas que serão observadas nos resultados das simulações são:
A taxa de entrega de pacotes, a taxa e quantidade de pacotes reencaminhados com sucesso, o atraso fim-a-fim, a variação do atraso (jitter), carga de roteamento normalizada da quantidade de bytes e de pacotes de controle utilizadas na criação e manutenção das tabelas de roteamento.
Também são identificadas as principais causas que levam às perdas de pacotes Em a Tabela 13 e Figura 18, são apresentadas as taxas de entrega de pacotes para os cenários de baixa mobilidade e alta mobilidade.
Observa- se, por esses dados que, para ambos os cenários de mobilidade e quantidade de nodos, o OLSR_ PD apresenta ganho na taxa de entrega de pacotes, em relação a o OLSR original.
Figura 18 -- Taxa de entrega de pacotes vs número de nodos -- Mobilidade entre 0-1,50 e 0-20 m/ s Analisando os dados contidos na Tabela 13 e no gráfico da Figura 18, verifica- se que, à medida que cresce o número de nodos, a taxa de entrega de pacotes diminui rapidamente.
Para ambientes de baixa mobilidade, nas redes com 25 nodos, a taxa de entrega de pacotes do OLSR e OLSR_ PD atinge, respectivamente, 47,28% e 50,37% já para redes com 200 nodos, essa taxa fica em 5,57% para o OLSR e 6,20% para o OLSR_ PD.
Para ambiente de alta mobilidade, em redes com 25 nodos, o OLSR e OLSR_ PD apresenta, respectivamente, a taxa de entrega de 69,87% e 74,70%, já para redes com 200 nodos, essa taxa fica em 5,40% para o OLSR e 5,62% para o OLSR_ PD.
Segundo Abolhasan, não ser bons em escalabilidade, é uma característica de protocolos pró-ativos, e mesmo o OLSR que, segundo esse mesmo autor, apresenta a melhor escalabilidade de entre os protocolos pró-ativos avaliados em seu trabalho, sofre tal degradação, visto que, cada nodo precisa manter, em todo tempo, rotas para todos os outros nodos da rede.
CBR, não implementam controles de congestionamento, de forma que, mesmo que as filas nos roteadores estejam cheias, os nodos origens de tráfego continuam enviando pacotes de maneira constante.
Segundo Tanembaun, quando pacotes chegam a um roteador e a memória deste está cheia, esses pacotes podem ser descartados.
Outro aspecto a se analisar nesses resultados é que, manter a densidade da rede igual ou próxima, para os protocolos em estudo, não garante a mesma e nem compatíveis taxas de entrega, pois nesse caso, a taxa entrega é diretamente influenciada por o aumento no número de nodos na rede.
Esse é o caso por exemplo dos cenários com 25 e 100 nodos e 50 e 200 nodos que possuem densidade iguais, mas que por causa de o aumento na quantidade de nodos na rede é registrado um significativo aumento na quantidade de pacotes de controle na rede, o que influência, diretamente, para a queda na taxa de entrega de pacotes.
Outra situação que se observa no gráfico da Figura 18, é que as taxas de entrega foram bastante baixas, mesmo para a quantidade mínima de nodos, 25 nesse caso, a taxa de entrega, para ambos os protocolos, ficou entre 47% a 74% e para a quantidade máxima de nodos, 200 nodos, a taxa registrada ficou em pouco mais de 5%.
De entre os principais fatores que determinaram o baixo desempenho, destacamos o tamanho das áreas determinadas para cada simulação, que combinado à mobilidade, faz com que os nodos se dispersem, ou mesmo se isolem, em determinados momentos, provocando perdas de pacotes.
As áreas para cenários com 25, 50, 100 e 200 nodos, propostos neste trabalho, possuem respectivamente as seguintes medidas:
750x750, 1000x1000, 1500x1500 e 2000x2000 metros.
Essas áreas permitem manter a semelhança na densidade das redes simuladas, e foram assim criadas com o propósito de aumentar o comprimento das rotas, em número de saltos, à medida que se aumenta o número de nodos, a fim de possibilitar cenários com maior atividade de roteamento de pacotes.
Todavia isso pode influenciar no desempenho do OLSR, pois segundo Jacquet E Huhtonen esse protocolo, por suas características, apresenta melhor desempenho em redes densas, ou seja, redes onde os nodos estejam mais próximos uns dos outros.
Quanto a variação da mobilidade, se observa que a taxa de entrega, nos cenários de mobilidade entre 0 e 20 m/ s, em ambos os protocolos, se mostrou superior às taxas alcançadas nos cenários de baixa mobilidade, para as simulações com 25, 50 e 100 nodos.
A maior diferença é encontrada nas simulações com 25 nodos, pois enquanto no cenário de baixa mobilidade o OLSR apresenta taxa de 47,28% e o OLSR_ PD 50,37%, no cenário de alta mobilidade o OLSR registra a taxa de 69,87% e o OLSR_ PD 74,70%.
Resultados obtidos em Gowrishankar E Choi e Ko mostram que a tendência dos protocolos de roteamento é que, ao se aumentar a mobilidade dos nodos da rede, diminua a taxa de entrega, visto que mais pacotes de controle são gerados, aumentando a disputa por os recursos da rede.
Todavia, não foi o que ocorreu nas simulações para os cenários com 25, 50 e 100 nodos.
Essa diferença na taxa de entrega, descrita acima, pode ser compreendida analisando- se os dados da taxa de repasse de pacotes com sucesso e comparando- os com as taxas de entrega, de forma que se torna possível inferir que, nas simulações de cenários de alta mobilidade, é maior o número de pares origem-destino alcançáveis com apenas 1 salto, ou seja, onde ocorrem comunicação direta.
Considerando que tanto a taxa de entrega, quanto a taxa de repasses com sucesso são dadas por a relação entre taxa de entrega/ taxa de repasse por o número de pacotes enviados e, considerando ainda, que pacotes repassados com sucesso são eventos praticados apenas por nodos intermediários em rotas com múltiplos saltos, para estes resultados em específico, ao extrairmos a diferença da Taxa de Entrega de Pacotes (TEP) por a Taxa de Repasse com Sucesso (TRS), obtemos, no mínimo, a taxa de entrega de pacotes que foram feitas por rotas com apenas 1 salto.&amp;&amp;&amp;
Em o mínimo porque um pacote pode ser repassado várias vezes numa rota, o que, todavia, não será considerado nessa análise.
A situação anterior pode ser ilustrada tomando- se os resultados obtidos, para as redes com 25 nodos em cenários de alta mobilidade.
Primeiro subtrai a TEP por a TRS, que neste caso, para o OLSR TEP $= 69,87% e TRS $= 29,73%, logo a diferença entre TEP-TRS $= 40,14% e para o OLSR_ PD a TEP $= 74,70% e a TRS $= 38,62%, logo TEP-TRS $= 36,08%.
Considerando que, para os cenários analisados, a mobilidade e a disposição topológica de cada nodo são as mesmas, mudando- se apenas o protocolo de roteamento, pode- se concluir que, no mínimo, 40,14% da TEP alcançada por esses protocolos foram registradas entre vizinhos a 1 salto.
Para reforçar essa hipótese, vale destacar que a TRS alcançada nas redes com 25, 50, e 100, em cenários de baixa mobilidade, foram maiores que as alcançadas nos cenários de alta mobilidade e que, mesmo assim, a taxa de entrega registrada foi menor nas três redes.
Analisando, ainda, os resultados do atraso médio fim-a-fim verifica- se, para as redes com 25, 50 e 100 nodos, que o atraso médio registrado nos cenários de alta mobilidade é bem inferior ao registrado em cenários de baixa mobilidade.
Segundo Tanembaun, de entre os fatores que influenciam o atraso médio na entrega de pacotes estão o comprimento do caminho e o nível de congestionamento.
Visto que, nas redes de alta mobilidade, é registrada uma significativa redução no atraso, em ambos os protocolos, infere- se que a distância média, em número de saltos, entre os pares origemdestino são menores que a distância em cenários de alta mobilidade.
Em a Tabela 14 e Figura 19, são apresentados os valores do número médio de nodos intermediário percorridos por os pacotes de dados em cada simulação.
Esses valores são obtidos por a razão entre o total de pacotes recebidos por a soma do número de nodos intermediários por onde esses pacotes passaram.
Como se observa, nos cenários de alta mobilidade, tanto o OLSR quanto o OLSR_ PD, apresentam redução no número médio de nodos intermediários na rota dos pacotes de dados, pois enquanto que no cenário de baixa mobilidade o OLSR e OLSR_ PD apresentam, respectivamente, o número médio de nodos intermediários de 0,88380119 e 0,93204027 nodos, no cenário de alta mobilidade esses valores reduzem para, respectivamente, 0,56391286 e 0,65006015 nodos.
Esses valores comprovam o que se infere nos parágrafos anteriores, pois mostram que o aumento na taxa de entrega de pacotes, em ambos os protocolos, em cenários de alta mobilidade, deve- se ao fato de que a maioria das trocas de pacotes foram feitas através de comunicação direta com os vizinhos a 1 salto.
A troca de pacotes por comunicação direta com os vizinhos a 1 salto evita descartes de pacotes por evitar congestionamentos em roteadores intermediários, além de proporcionar significativa redução na média do atraso fim-a-fim, como se observa na Tabela 17 e Figura 21.
Em a Tabela 15e Figura 20 são apresentadas as taxas médias de pacotes repassados com sucesso, ou seja, a quantidade de vezes que a camada de redes repassou pacotes de dados e estes chegaram ao próximo nodo da rota, conforme determinado por o nodo que repassou os pacotes.
O número de repasses de pacotes com sucesso está diretamente relacionado à taxa de entrega de pacotes, visto que, demonstra a capacidade do protocolo de roteamento de, em ambientes de múltiplos saltos, encontrar as melhores rotas de forma que mais pacotes alcancem seu destino.
Os resultados apresentados na Tabela 15 e Figura 20 mostram que o OLSR_ PD, quanto a a taxa de repasse de pacotes, apresenta um desempenho superior à versão original do OLSR em todos os cenários de mobilidade e para todas as quantidades de nodos.
Como se observa, por esses dados, ambos os protocolos apresentam suas melhores taxas de repasse no cenário de baixa mobilidade e com o menor número de nodos na rede (25 nodos).
Em esse cenário, o OLSR alcançou a taxa de 50,57%, enquanto o OLSR_ PD alcançou 56,77%, ou seja, esse último apresenta um ganho médio de 6,2% no número de repasses com sucesso.
Já a menor taxa média de repasse foi registrada no cenário de alta mobilidade com 200 nodos na rede, onde a menor taxa do OLSR foi de 5,85% e a do OLSR_ PD foi de 6,27%, ou seja, o OLSR_ PD apresentou um ganho médio de 0,42% em repasses com sucesso.
Como se observa, aumentando- se o número de nodos na rede e a mobilidade dos nodos, a taxa média de repasse diminui.
E isso porque, com o aumento do número de nodos na rede, haverá mais nodos enviando pacotes de controle HELLO e Tc na rede, além de que, cada pacote tem o seu tamanho aumentado, pois deve carregar informações de mais nodos.
Já com o aumento da mobilidade ocorrem mais quebras de links, o que pode motivar perdas de pacotes já em trânsito e disparar a emissão de novos pacotes de controle, que devem ser enviados antes do tempo padrão.
Com mais pacotes de roteamento na rede, recursos como largura de banda e espaços nas filas de saída da camada MAC, ficam saturados com pacotes de controle, visto que estes têm prioridade sobre os pacotes de dados, provocando mais descartes de pacotes.
Outro fator que pode ter determinado essa significativa redução na da taxa de repasse, nos cenários de alta mobilidade, é a presença de mais pares fontes-destinos de tráfegos alcançáveis com apenas um salto entre si, de forma que não se faz necessário o repasse dos pacotes, ou seja, apresentam comunicação direta.
Isso é facilmente verificável, se considerarmos que tanto a taxa de entrega quanto a taxa de repasse com sucesso são obtidas por a divisão do total de pacotes entregues ou repassados por o total de pacotes enviados, e que pacotes repassados com sucesso são eventos registrados apenas em nodos intermediários de rotas com múltiplos saltos.
Logo ao extrair a diferença entre a taxa de recebidos e taxa de repassados com sucesso, é possível inferir que a diferença representa, no mínimo, a taxa de pacotes entregues por canais de comunicação direta, conforme apresentado na Subseção 5.4.1.
Em a Tabela 14 e Figura 19 são apresentados os números médios de nodos intermediários percorridas por os pacotes de dados recebidos.
O que se observa, nesses resultados, é que nos cenários de alta mobilidade a média de nodos intermediários fica bem abaixo que a média em cenários de baixa mobilidade, o que prova que grande parte dos pacotes de dados trocadas em ambientes de alta mobilidade foram realizadas entre vizinhos diretos, sem a necessidade de nodos roteadores intermediários.
Figura 20 -- Taxa de pacotes repassados com sucesso vs número de nodos ­ Mobilidade entre 0-1,5 e 0-20 m/ s Como se observa no gráfico da Figura 20, o OLSR_ PD apresenta seus melhores resultados, em relação a o OLSR, nos cenários de alta mobilidade, principalmente com 25, 50 e 100 nodos.
A o extrair o percentual da diferença3 entre o OLSR_ PD e o OLSR essa diferença fica mais evidente, conforme Tabela 16.
Por esses resultados, é possível verificar que nessas três redes, no cenário de alta mobilidade, o desempenho do OLSR_ PD praticamente dobra, em relação a o desempenho em redes de baixa mobilidade.
Apenas para rede com 200 nodos é que o desempenho do OLSR_ PD cai, em relação a o cenário de baixa mobilidade.
Por apresentar suas melhores taxas de repasse nos cenários de maior mobilidade, é possível afirmar que, como proposto, as rotas escolhidas por o OLSR_ PD, aumenta a probabilidade de que em caso de falhas em links, o que é comum em ambientes de alta mobilidade, o nodo imediatamente anterior à falha, por fazer parte da rota de maior grau de conectividade, encontre mais rapidamente uma rota alternativa para o destino dos pacotes.
OLSR_ PD e o OLSR dada por a razão entre a diferença entre o OLSR_ PD e o OLSR por o total do OLSR Mobilidade entre 0-1,5 m/ s Nodos Mobilidade entre 0-20 m/ s Percentual da diferença Nodos Percentual da diferença Em a Tabela 17 e na Figura 21 são apresentados os resultados do desempenho dos protocolos OLSR e OLSR_ PD em relação a a média do atraso fim-a-fim.
Como se observa nos resultados da Tabela 17 o OLSR_ PD apresenta um aumento no atraso médio fim-afim em relação a o OLSR, em três dos quatro cenários com 25 e 50 nodos.
Já para cenários com 100 e 200 nodos, o OLSR_ PD apresenta redução no atraso em três dos quatro cenários simulados.
De uma maneira geral, como era de se esperar, à medida que se aumenta o número de nodos, aumenta- se também o atraso médio e isso porque se aumenta o número de pacotes de controle na rede e a disputa por os canais de comunicação e, neste trabalho em específico, aumenta- se também o tamanho da área em a qual os nodos estão dispostos, o que faz aumentar o número de nodos intermediários nas rotas, por aumentar a distância entre os nodos mais extremos.
Como exemplo, para cenários com 25 nodos o atraso médio fica na casa dos 4 e 7 centésimos de segundos, enquanto que para cenários com 200 nodos esse atraso médio aumenta, ficando entre 3,2 a 4,6 segundos.
Conforme resultados da Tabela 17, o OLSR_ PD registra maiores atrasos, com relação a o OLSR, nos cenários de baixa mobilidade e em redes com 25 e 50 nodos.
O aumento nesses dois casos é de aproximadamente 0,01 segundos.
Já para no cenário de alta mobilidade, na rede com 25 nodos o OLSR_ PD mostra uma redução no atraso médio, de aproximadamente 0,02 segundos.
Para redes com 50 nodos e alta mobilidade, o OLSR_ PD apresenta maior atraso médio que o OLSR, com 0,007 segundos de diferença.
Para redes com 100 e 200 nodos, em cenário de alta mobilidade o OLSR_ PD registra redução no atraso médio de, respectivamente, 0,017 segundos e de 0,08 segundos.
Já para cenários de baixa mobilidade e rede com 100 nodos é registrado um aumento no atraso de 0,03 segundos e uma redução no atraso de 0,055 segundos para redes com 200 nodos.
De esses resultados, infere- se que o OLSR_ PD registra os menores atrasos nos cenários de alta mobilidade e para redes com maiores números de nodos, e isso por conta do novo critério de seleção de rotas, que aumenta a probabilidade de que nodos participantes da rota de maior grau de conectividade, consigam encontrar mais rapidamente caminhos alternativos em direção a um destino, em caso de falhas nos links da rota principal.
A o se analisar os resultados da Tabela 17, especificamente para cenários com baixa mobilidade, verifica- se que o OLSR_ PD apresenta um aumento na média do atraso fim-a-fim em relação a o OLSR.
Alguns fatores, como o processamento adicional para se calcular o grau de conectividade, podem ter influenciado o aumento do atraso apresentado por o OLSR_ PD, todavia, é importante destacar que o atraso fim-a-fim é extraído da média do atraso de todos os pacotes recebidos nos respectivos destinos.
Visto que, o OLSR_ PD apresentou maior taxa de entrega de pacotes, e que o OLSR_ PD entregou mais pacotes por rotas, cuja média de nodos intermediários eram maiores que o OLSR, infere- se que o tempo para envio dos pacotes por essas rotas influenciou para o aumento na média do atraso apresentada por o É importante destacar, que ambos os protocolos alcançam melhor desempenho, em relação a a média do atraso, em todos os cenários de alta mobilidade.
Essa não é a tendência, pois Choi e Ko afirmam que o aumento na velocidade do nodos induz a frequentes mudanças de topologia e aumenta a probabilidade de que links se quebrem, consumindo, então, tempo adicional com processo de descoberta de novas rotas, o que consequentemente aumenta o atraso na entrega de pacotes.
A explicação para esse fato, também, deve- se à presença de mais pares fontes-destinos de tráfegos alcançáveis com apenas 1 salto nessas redes, de forma que, pacotes trocados por esses pares, não sofrem com o processamento adicional registrado em rotas de múltiplos saltos, reduzindo, assim, a média do atraso fim-a-fim.
Reflexos do tráfego entre vizinhos a 1 saltos é registrado na Figura 18, onde as taxas de entregas, para cenários de alta mobilidade, para redes com 25, 50 e 100 nodos, apresentam ganhos superiores às taxas apresentadas em cenários de baixa mobilidade.
Em a Subseção 5.4.1, os efeitos dessa disposição topológica são discutidos com mais detalhes.
Em a Figura 22 e na Tabela 18 são apresentados os resultados da variação do atraso de ambos os protocolos analisados neste trabalho.
É importante destacar que a avaliação da variação do atraso e do atraso médio fornecem informações fundamentais para validação da funcionalidade do OLSR_ PD, pois se os pacotes de dados são entregues com menos atraso, ou que a variação desse atraso é menor que o apresentado por o OLSR original, significa que o critério de seleção de rotas proposto para o OLSR_ PD consegue, em caso de falhas nas rotas previamente escolhidas, realmente reduzir o tempo para que rotas alternativas sejam escolhidas.
Em os resultados apresentados na Tabela 18 e na Figura 22, se observa que o OLSR_ PD tem um melhor desempenho que o OLSR original em seis das oito redes simuladas.
Semelhante aos resultados apresentados na análise do atraso médio fim-afim, também a variação do atraso aumenta à medida que o número de nodos aumentam.
As causas para esse aumento são as mesmas apresentadas na Subseção 5.4.3: Aumento no tamanho da área de simulação;
E aumento no número de nodos intermediários nas comunicações.
O ganho no desempenho, apresentado por o OLSR_ PD, quanto a a variação média do atraso, se mostrou bastante satisfatório, em relação a o OLSR original.
A redução média da variação do atraso do OLSR_ PD, chega à casa dos décimos de segundos, enquanto que, a redução no atraso médio fim-a-fim fica na casa dos centésimos de segundo.
Para os cenários de baixa mobilidade, enquanto que no OLSR o menor e o maior Jitter médio foram, respectivamente, de 0,086559202 segundos e de 3,357559377 segundos, no OLSR_ PD esses valores foram de 0,102236287 segundos e de 3,068307629 segundos.
De maneira análoga, para cenários de alta mobilidade, enquanto que no OLSR o menor e o maior Jitter médio foram, respectivamente, de 0,104512899 segundos e de 2,830582691 segundos, e no OLSR_ PD esses valores foram de 0,062613169 segundos e de 2,544217361 segundos.
Com base nesses resultados verifica- se que o OLSR_ PD se mostra mais adequado para operar em ambientes com maior mobilidade e número de nodos na rede.
Em esta seção são apresentados os resultados da carga de roteamento normalizada que é dada por a quantidade pacotes de roteamento enviados por pacotes de dados entregues.
Essa métrica visa identificar em cada protocolo quantos pacotes de roteamento são necessários para que um pacote de dados seja entregue.
A carga de roteamento normalizada também será apresentada em termos de quantos bytes de roteamento são necessários para que um byte de dados seja entregue.
Segundo Choi e Ko, o OLSR por ser um protocolo de roteamento próativo, orientado a tabelas, apresenta alta carga de roteamento por necessitar manter, em todo tempo, rotas para todos os nodos da rede.
As mensagens de controle geradas por o OLSR e OLSR_ PD, consideradas para esse cálculo, são as mensagens de HELLO e as mensagens Tc.
Como descrito na Seção 4.2, para implementar o critério de seleção de rotas no OLSR_ PD, não foi necessário criar ou disparar nenhuma mensagem de controle adicional na rede, mas foi acrescentado ao cabeçalho da mensagem Tc, um campo de dois bytes, para carregar as informações sobre o grau de conectividade dos nodos emissores das mensagens Tc.
Devido a esse fato é de se esperar um pequeno aumento no número de bytes de controle na rede, visto que para cada mensagem Tc enviada na rede, mais dois bytes de controle trafegam por a rede.
O total médio de bytes gerados em cada simulação são apresentados na Tabela 19.
Como observado na Tabela 19 o OLSR_ PD, como previsto, acrescenta alguns bytes de controle na rede, todavia, como apresentado na Tabela 20 e Figura 23, em termos de quantidade de pacotes de roteamento necessários para que um pacote de dados seja entregue, o OLSR_ PD apresenta um ganho em relação a o OLSR original.
Esse ganho se mostra constante em todos os cenários de mobilidade e para todas as quantidades de nodos.
Esse ganho deve- se primeiramente ao ganho nas taxas de entregas de pacotes apresentadas por o OLSR_ PD.
Figura 23 -- Carga de roteamento normalizada em número de pacotes vs o número de nodos ­ mobilidade entre 0-1,5 m/ s Outro detalhe registrado nos gráficos, apresentados nesta seção, é que a carga de roteamento na rede aumenta à medida que aumenta o número nodos.
Isso porque quando se aumenta o número de nodos, aumenta- se o número de nodos transmitindo ou repassando mensagens Tc por toda a rede, bem como o número de nodos enviando mensagens de HELLO.
Quanto a a mobilidade dos nodos, observando- se a carga de roteamento normalizada nos 2 gráficos apresentados, verifica- se que esta reduz em situações de alta mobilidade, para as redes com 25 e 50 nodos.
Isso pode ser explicado por o fato de que, a taxa de entrega de pacotes em cenários de alta mobilidade, foi maior do que a apresentada em cenários de baixa mobilidade, e como a carga de roteamento normalizada é dada por a razão entre pacotes de roteamento gerados por pacotes de dados entregues, o que faz com que a carga de roteamento normalizada seja menor nos cenários de alta mobilidade, o que significa que foram necessários menos pacotes de controle para que um pacote de dados fosse entregue.
Observando, porém, o total de bytes registrados em cada uma das simulações com baixa e alta mobilidade, apresentado na Tabela 19, verifica- se que, em ambos os protocolos, a medida que aumenta a velocidade cresce também o número de bytes de roteamento na rede, e isso porque a mobilidade faz romper links de comunicação, fazendo com que cada nodo reconstrua todas as suas tabelas novamente, gerando mais mensagens HELLO e Tc na rede.
Como apresentado nesta subseção, o OLSR_ PD adiciona bytes de roteamento extras na rede, a fim de que o critério de seleção de rotas aqui proposto possa ser implementado, todavia a análise da carga de roteamento normalizada mostra que o custo para enviar um pacote de dados no OLSR_ PD é inferior, em todos os cenários, que o custo apresentado por o OLSR original.
Figura 24 -- Carga de roteamento normalizada em bytes vs o número de nodos ­ mobilidade entre 0-1,5 e 0-20 m/ s Em esta seção são apresentados os números médio de pacotes descartados em todas as simulações e o motivo do descarte.
Pacotes de dados são descartados por vários motivos, como congestionamento nas filas dos roteadores, colisões de pacotes e quebra de links.
Todavia segundo Tanembaun, em redes sem fio a maioria das perdas de pacotes deve- se às interferências (ruídos) no enlace aéreo.
Em a Tabela 22 é apresentado um resumo da média de pacotes descartados em todos as simulações realizadas neste trabalho.
De uma maneira geral, observa- se que o OLSR_ PD apresenta um menor descarte de pacotes em ambos os cenários de mobilidade e para todas as quantidades de nodos.
Os dados dessa tabela revelam que a principal causa de descarte de pacotes, nessas simulações é o excesso de retransmissões sem resposta feitas por a camada MAC evento CBK (Callback).
Quando a camada de redes recebe um pacote de dados e insere em seu cabeçalho a rota (ou o próximo salto) para chegar ao destino, então este é repassado para a camada MAC a fim de que esta obtenha acesso ao meio e transmita o pacote.
Esse pacote aguarda na fila (buffer de saída) da camada MAC até que o acesso ao meio tenha sido alcançado ou que este pacote seja descartado.
Segundo Tanembaun[ TAN03], existem duas técnicas para que a camada MAC acesse ao meio em redes sem fio ad hoc.
O primeiro consiste basicamente no nodo roteador escutar o meio para certificar- se de nenhum outro nodo esteja transmitindo naquele momento.
Caso o meio esteja livre o pacote de dados é enviado e o nodo remetente fica aguardando uma mensagem ACK (Acknowledgment) acusando o recebimento do pacote, se passado um período de tempo e essa mensagem de ACK não chegar, então esse pacote é reenviado um determinado número de vezes, até que o remetente receba uma confirmação.
Caso esta confirmação não chegue, após n tentativas de envio, o pacote é devolvido à camada de redes e, neste trabalho em específico, esse pacote é descartado recebendo o flag CBK.
Em a segunda técnica, antes que os pacotes de dados sejam enviados, as camadas MAC, do remetente e do destinatário, trocam pequenos quadros chamados RTS (Request to Send) e CTS (Clear to Send).
Um quadro RTS solicita a liberação para transmitir dados, e então a camada MAC do origem fica aguardando que o destinatário retorne um pacote CTS, que garante livre acesso ao meio até o fim da transmissão.
Se o nodo origem envia um quadro RTS mas não recebe um CTS, após um número determinado de tentativas o pacote de dados é devolvido à camada de redes porque a camada MAC não conseguiu transmitir o pacote.
Este é descartado, sendo registrado no arquivo de trace com o flag CBK.
As principais causas para que pacotes sejam descartados por CBK por a camada MAC são, principalmente, a quebra de links por causa de a mobilidade, os ruídos e colisões de pacotes com os de outros transmissores.
Em a Figura 25, é apresentado a média normalizada de pacotes descartados por falta de rotas, a qual é dada por a razão entre média de pacotes descartados por falta de rotas (NRTE geral) por o total de pacotes repassados com sucesso.
Por esse gráfico é possível identificar qual a média de pacotes descartados por falta de rotas, para cada pacote de dados repassados com sucesso.
É importante destacar que apenas pacotes descartados nos nodos intermediários entram nesse cálculo, pois a atividade de repasse nunca é realizada no nodo que originou o pacote, mas apenas nos nodos intermediários de uma rota.
Quanto a média normalizada, apresentada na Tabela 23 e Figura 25, o OLSR_ PD apresenta um melhor desempenho em praticamente todas os tamanhos de rede e cenários de mobilidade, com exceção do cenário de baixa mobilidade com 100 nodos.
É importante observar que no cenário de baixa mobilidade com 100 nodos o OLSR repassou 1.548,65 pacotes com sucesso, enquanto que o OLSR_ PD repassou 1.787,10, o que significa que o OLSR_ PD conseguiu repassar, a mais que o OLSR, a quantia de 238,45 pacotes de dados.
Ocorre, todavia, que o OLSR_ PD descartou uma média de 76,1 pacotes por falta de rotas nos nodos intermediários, enquanto que o OLSR descartou a média de 58,3 pacotes, diferença esta, que fez o desempenho do OLSR_ PD cair para este cenário, o que, todavia, não interferiu para que o OLSR_ PD apresentasse maior taxa de entrega de pacotes do OLSR_ PD, haja vista, no computo geral de descartes, o OLSR apresentou maior descarte de pacotes que o OLSR_ PD.
Figura 25 -- Média normalizada de descarte por falta de rotas em nodos intermediários, dada por a razão entre pacotes &quot;descartados por NRTE geral «por pacotes repassados com sucesso Analisando, ainda, a média normalizada de descartes, foi registrada na rede com 25 nodos, no cenário de alta mobilidade, a maior diferença entre os protocolos, pois no OLSR_ PD para cada pacote repassado com sucesso, uma média de 0,004481 pacotes são descartados por falta de rotas, enquanto que no OLSR, essa relação sobe para 0,040176 pacotes descartados.&amp;&amp;&amp;
A terceira maior causa de descarte de pacotes é o descarte por falta de espaço interface da fila da camada MAC que pode estar cheia, e quando os pacotes de dados chegam esses são rejeitados sendo descartados.
Em este trabalho a fila da camada MAC foi configurada para no máximo 50 pacotes.
Observando a Tabela 24, verifica- se que à medida que aumenta o número de nodos na rede, o descarte por falta de espaço na fila (IFQ) tem o maior aumento, em ambos os protocolos, pois enquanto nos cenários com 25 nodos, para cenário com baixa e alta mobilidade, a média de descarte por IFQ corresponde por 4,12% a 6,49% dos pacotes descartados na rede.
Já para a rede com 200 nodos, para cenários de baixa e alta mobilidade, a média de descarte por IFQ representa em torno de 25% a 29% dos motivos de descarte em ambos os protocolos.
As outras causas de descarte de pacotes, separadamente, possuem valores pouco expressivos, todavia, neste trabalho, também, foram identificadas mais quatro causas de descarte de pacotes, sendo seus flags &quot;END «que indica pacotes que foram descartados porque a simulação chegou ao fim, e eles ainda estavam na fila da camada MAC de algum nodo.
Outra causa é quando um pacote tem seu tempo de vida TTL (Time to Live) expirado e tem de ser descartado para não ficar percorrendo a rede indefinidamente.
Um pacote também pode ser descartado se ele for recebido mais que uma vez por um receptor, pois fica caracterizado que esse pacote pode estar em loop infinito, logo é descartado e no arquivo trace recebe o flag &quot;LOOP».
Por último, destacamos o descarte por ARP (Adress Resolution Protocol).
Esse tipo de descarte ocorre quando um pacote de dados sai da camada de rede.
Primeiro ele passa por a camada de link de dados LL (Link Layer) que converte o endereço de IP em endereços de MAC, ou seja, em endereço físico do destinatário.
Se o ARP possui o endereço físico do destino, ele o coloca no cabeçalho do pacote, senão o pacote é armazenado temporariamente no buffer ARP, que envia uma mensagem, por broadcast, a fim de identificar o endereço MAC do nodo portador do endereço de IP fornecido no pacote de dados.
Esse buffer possui espaço para apenas um pacote, para cada destino desconhecido.
Se no intervalo em que está sendo feita a consulta chegar um novo pacote, cujo endereço de IP seja o mesmo de um pacote já armazenado no buffer ARP, o pacote mais antigo é descartado e o novo é alocado em seu lugar.
Pacotes descartados por esse motivo recebem o flag ARP.
Em esta subseção se verificou que em ambos os protocolos o descarte de pacotes é alto, reduzindo significativamente a taxa de entrega de pacotes, todavia se observa que o OLSR_ PD consegue apresentar uma redução no número de descartes, de uma maneira geral, e um ganho na média normalizada de pacotes/ bytes descartados.
Em este trabalho é apresentada a proposta de um novo critério de seleção de rotas para o OLSR, que além de o critério do comprimento da rota, considera ainda, se esta possui o maior grau de conectividade, de entre as rotas disponíveis.
A essa versão do OSLR chamamos de OLSR_ PD ou OLSR baseado no grau de conectividade do caminho.
Para implementar o OLSR_ PD foram mantidas as principais características do OLSR, e alterado apenas o critério de seleção de rotas.
Para avaliar o desempenho desses dois protocolos foram executadas várias baterias de simulações, utilizando o simulador de redes Ns-2, cujos resultados foram analisados e apresentados neste trabalho.
De uma maneira geral, observou- se que o OLSR_ PD apresenta um ganho de desempenho nos quesitos taxa de entrega de pacotes e taxa de repasse de pacotes com sucesso, e isso foi registrado em todos os cenários de mobilidade e quantidades de nodos, comprovando assim que o critério de seleção de rotas proposto aumenta a probabilidade de entrega de pacotes, visto que reduz o número de pacotes descartados em todos os cenários simulados.
Em a avaliação da métrica atraso médio fim-a-fim o OLSR_ PD apresenta melhor desempenho médio em quatro das oito simulações executadas, obtendo melhor desempenho em cenários de maior mobilidade e maior quantidade de nodos.
Quanto a a variação desse atraso (Jitter) o OLSR_ PD também apresenta um ganho de desempenho, em relação a o OLSR original, pois reduz a média da variação do atraso em seisdas oito simulações apresentadas, também apresentando melhor desempenho no ambiente de maior mobilidade.
Esses resultados reforçam a tese de que a seleção de rotas que possuem o maior grau de conectividade, pode aumentar a probabilidade, de que, em casos de falhas nessas rotas os nodos imediatamente anteriores às falhas, por pertencer à rota de maior grau, têm maior probabilidade, se comparado a nodos de outras rotas, de calcular, mais rapidamente, uma rota alternativa para o destino.
Os resultados experimentais apontam, como já era previsto, que o OLSR_ PD acrescenta alguns bytes de controle na rede, se comparado ao OLSR.
Todavia quando é feita a análise da carga de roteamento normalizada entre esses protocolos, verifica- se que o custo para transmitir 1 byte no OLSR_ PD é menor que no OLSR, o que torna insignificante o número de bytes de controle a mais na rede, se comparado aos benefícios do aumento da taxa de entrega de pacotes.
De uma maneira geral, o OLSR_ PD apresentou um desempenho superior ao OLSR original.
Consegue apresentar maiores taxas de entrega em cenários de baixa mobilidade e mantém esse desempenho em cenários de alta mobilidade.
Considerando o número de nodos na rede, ambos os protocolos apresentam perda de desempenho, mas mesmo nesses cenários o OLSR_ PD mantem um ganho em relação a o OLSR.
Como proposta para trabalhos futuros, fica a ideia de acrescentar ao critério de seleção de rotas do OLSR_ PD uma nova característica, que considere, também, a média de conectividade dos nodos desse caminho, de forma que seja escolhida sempre a menor rota cujos nodos do caminho possuam o maior grau médio de conectividade.
Também deixamos a proposta de implementar critérios de QoS no OLSR_ PD para seleção dos nodos MPR de forma que a menor rota de maior grau de conectividade também seja uma rota que atenda à requisitos de QoS.
Sugerimos ainda a avaliação do OLSR e do OLSR_ PD utilizando- se outras métricas de avaliação de desempenho, como variação na densidade da rede.
Por fim sugerimos que a avaliação do desempenho do OLSR_ PD em relação a as outras extensões do OLSR como o QOLSR, OLSR-ML e o OLSR-LD e com outros protocolos pró-ativos e reativos utilizados em MANETs.
