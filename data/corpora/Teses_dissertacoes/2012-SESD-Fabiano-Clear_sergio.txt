Sistemas MPSoC modernos fazem uso de recursos que eram disponibilizados apenas em computadores de propósito geral provendo mais funcionalidades para as aplicações.
A evolução arquitetural possibilita que mais recursos sejam implementados nestes sistemas embarcados e determina um aumento na complexidade dos novos projetos de hardware e software.
Além de o aumento da complexidade de projeto em sistemas MPSoC atuais, torna- se evidente a dificuldade na utilização eficiente dos recursos computacionais encontrados em tais plataformas.
Assim como o determinismo e o tempo de resposta priorizado em muitos sistemas embarcados, a programabilidade de MPSoCs é muito relevante.
De essa forma, interfaces bem definidas de software ajudam o desenvolvedor a criar aplicações que utilizam de maneira otimizada os recursos computacionais encontrados nestes sistemas.
A maior parte das aplicações embarcadas são divididas em tarefas e estaticamente mapeadas a elementos de processamento em tempo de projeto, de forma a otimizar um conjunto de métricas pré-estabelecidas.
No entanto, a natureza dinâmica de novas aplicações estabelece que estratégias eficientes de mapeamento dinâmico e migração de tarefas sejam implementadas.
Em este contexto, esta tese apresenta um modelo para aplicações dinâmicas e gerenciamento distribuído destas em sistemas MPSoC homogêneos.
O gerenciamento do sistema faz uso dos conceitos de migração de tarefas e restrições temporais, onde parâmetros de caracterização das tarefas são utilizados nas tomadas de decisão de escalonamento e otimização em tempo de execução.
Em este trabalho é utilizada uma arquitetura MPSoC homogênea, composta por elementos de processamento com memórias locais interconectados por uma NoC.
Este ambiente permite a execução de aplicações gerenciadas por um sistema operacional distribuído que implementa o modelo proposto e oferece diversos serviços para o desenvolvimento e otimização de aplicações embarcadas.
Muitos trabalhos na área fazem uso de um gerente centralizado para realizar a otimização do sistema em tempo de execução, no entanto tais soluções tendem a ser pouco escaláveis.
Os resultados obtidos mostram que o uso de gerentes distribuídos apresentam maior eficiência para sistemas com um grande número de elementos de processamento e tarefas, com redução nos tempos de estabilização do sistema e redução nas perdas de deadline para aplicações com restrições de tempo real.
Palavras Chave: Sistemas embarcados, Sistemas Operacionais, MPSoC, RTOS, Modelagem de aplicações, Mapeamento dinâmico, Migração de tarefas.
Sistemas embarcados tradicionalmente fazem uso de um único elemento de processamento em conjunto com módulos de entrada e saída e memória integrados num único chip, sendo esta organização arquitetural conhecida como sistema num chip ou SoC.
A complexidade, aliada aos requisitos de desempenho em aplicações embarcadas, no entanto, têm crescido substancialmente.
O emprego de multiprocessamento num mesmo chip provê o poder computacional necessário para a execução de aplicações que demandam cada vez mais desempenho.
De essa forma, sistemas multiprocessados num chip ou MPSoCs, são utilizados com o intuito de oferecer o poder de processamento necessário para a execução de aplicações reais complexas aliado às necessidades da aplicação.
Os problemas enfrentados para a obtenção de aumento do paralelismo em nível de instrução (ILP) não são recentes, e muitas vezes como alternativa são utilizadas soluções que implementam o paralelismo em nível de thread (TLP).
Integrando- se múltiplos elementos de processamento num mesmo chip, torna- se possível a exploração de TLP, contornando- se dessa forma o gargalo no desempenho.
A o ser utilizado um grande número de elementos de processamento integrados, trabalhando em frequências reduzidas, é possível a obtenção de um alto desempenho do sistema e ao mesmo tempo uma redução significativa no consumo de energia, algo essencial para dispositivos que operam com baterias e que ainda assim precisam ter seu tempo de operação prolongado e peso reduzido.
A integração de diversos elementos de processamento num único chip com o objetivo de executar aplicações paralelas demanda a utilização de infraestruturas de comunicação eficientes.
Estas estruturas podem ser baseadas em barramentos, conexões ponto-a-ponto ou redes intra-chip.
Redes intra-chip (NoCs) são compostas por um conjunto de roteadores interconectados por canais de comunicação, e oferecem uma série de vantagens sobre as outras estruturas de interconexão tais como redução no consumo de energia e escalabilidade, o que torna o seu uso ideal para sistemas com grande número de elementos de processamento.
NoCs fazem uso de conceitos como topologias, algoritmos de roteamento e técnicas de bufferização, sendo estes advindos de redes de computadores de propósito geral.
De essa forma, muitas das técnicas originadas em sistemas distribuídos podem ser diretamente aplicadas neste tipo de organização.
Um dos grandes problemas decorrentes do uso de sistemas multiprocessados está no aproveitamento efetivo de recursos.
Para que os recursos sejam utilizados eficientemente, a aplicação precisa ser descrita como um conjunto de tarefas comunicantes distribuídas entre elementos de processamento e trabalhando em paralelo.
O grande problema está no fato de boa parte das aplicações seguir um fluxo de execução serial e principalmente no fato de não existir suporte para a implementação de aplicações distribuídas de maneira a facilitar a programação em ambientes multiprocessados.
Ainda quando existente o suporte para a programação em ambientes MPSoC, muitas vezes é necessário que seja feita a atribuição de tarefas à elementos de processamento em tempo de projeto sem a possiblidade de modificação, o que pode não ser eficiente no caso de aplicações que são carregadas dinamicamente ou possuem algum tipo de interação com o usuário que consequentemente modifica o perfil de execução.
A aplicação composta por um conjunto de tarefas pode ser mapeada de maneira automatizada com o uso de métodos estáticos ou dinâmicos.
Os métodos estáticos são utilizados em situações onde o conjunto de tarefas que compõem a aplicação é fixo.
Métodos dinâmicos são adequados a aplicações com um conjunto variável de tarefas ou tarefas com características variáveis.
O objetivo de métodos estáticos e dinâmicos é encontrar o melhor posicionamento das tarefas na arquitetura de acordo com alguma métrica, como por exemplo redução do consumo de energia, redução no tráfego na rede e balanceamento de carga dos elementos de processamento.
Em tempo de execução, além de o mapeamento dinâmico de tarefas métodos que utilizam o conceito de migração de tarefas podem ser aplicados com o intuito de melhorar o desempenho de determinada aplicação já previamente mapeada.
A migração de tarefas trasfere estas de um elemento de processamento a outro, podendo ser gerenciada por o desenvolvedor da aplicação ou de maneira automática.
Motivação Sistemas embarcados multiprocessados estão presentes na maioria das aplicações que foram tradicionalmente gerenciadas por sistemas monoprocessados.
A utilização de múltiplos elementos de processamento num único chip introduz novos desafios devido a o aumento da complexidade arquitetural.
Entre os principais desafios podem ser salientados a programabilidade, otimização e reuso de tais sistemas para aplicações com características dinâmicas.
Uma forma de lidar com tais fatores está em reduzir o esforço necessário para construir aplicações para MPSoCs.
Sistemas operacionais de tempo real oferecem interfaces padronizadas e dessa forma os desenvolvedores podem utilizar ou pelo menos ter facilitado o acesso ao poder computacional disponível no hardware.
Conforme o poder computacional oferecido por novos MPSoCs aumenta, aplicações e funcionalidades podem ser incluídas em tempo de execução, algo pouco comum em sistemas embarcados multiprocessados do passado.
Tipicamente, MPSoCs eram formados por poucos elementos de processamento de poder computacional mediano, onde a aplicação era completamente definida e tinha suas tarefas atribuídas a processadores em tempo de projeto.
Algumas aplicações atuais, no entanto, possuem uma complexidade aumentada e apresentam uma carga variável aos elementos de processamento assim como um perfil variável de tráfego na rede de interconexão, o que torna praticamente impossível definir em tempo de projeto a melhor forma de alocar tarefas a recursos.
Outras aplicações, além de apresentarem características dinâmicas, possuem a necessidade de cumprir com restrições de tempo real especificadas em tempo de projeto.
De essa forma, mecanismos eficientes que permitam adaptar recursos de hardware às necessidades da aplicação precisam ser implementados.
Arquiteturas MPSoC podem ser classificadas como heterogêneas e homogêneas.
Soluções heterogêneas oferecem uma série de vantagens como redução no consumo de energia aliado a um bom compromisso de área em silício.
Entretanto, quando comparadas à soluções homogêneas, seu projeto e manutenção podem ser considerados complexos do ponto de vista de implementação.
De essa forma, soluções homogêneas permitem um projeto mais rápido e o reuso da mesma arquitetura para diferentes produtos.
Além disso, estas soluções permitem uma exploração do espaço de projeto de maneira simplificada, através do uso de ferramentas em alto nível, interfaces padronizadas e o uso de algoritmos mais simples para a realização da atividade de mapeamento de tarefas, algo desejável devido a o considerável aumento no número de elementos de processamento em MPSoCs nos últimos anos.
Objetivos e Originalidade Objetiva-se com o desenvolvimento deste trabalho apresentar um modelo de tarefas e arquitetura multiprocessada que descreva aplicações dinâmicas de tempo real, e que suporte a otimização da aplicação com o uso de técnicas de migração de tarefas e mapeamento dinâmico.
Os objetivos específicos deste trabalho incluem:·
Definição de um modelo de tarefas de tempo real e aspectos arquiteturais, o qual suporta aplicações com características dinâmicas;·
Implementação do modelo de tarefas proposto num sistema operacional de tempo real;·
Definição de uma API para o sistema operacional com o intuito de facilitar o desenvolvimento de aplicações embarcadas em ambientes multiprocessados;·
Implementação de um mecanismo para a otimização do sistema em tempo de execução de maneira automática e distribuída, utilizando serviços de avaliação de estado, trocas de mensagem e migração de tarefas;·
Validação do modelo de tarefas proposto numa ferramenta de simulação baseada num protótipo em hardware o qual implementa o modelo arquitetural especificado;·
Descrição de aplicações de acordo com a API implementada e utilização destas aplicações para avaliação de resultados;
A originalidade deste trabalho consiste na proposta de um novo modelo de tarefas que incorpora parâmetros de tempo real na descrição de aplicações multiprocessadas dinâmicas em ambientes intra-chip.
Diversos trabalhos que empregam o conceito de mapeamento dinâmico de tarefas não abordam questões como o contexto de execução de aplicações, sendo voltados basicamente a aplicações de streaming.
Ainda, não são levadas em consideração as restrições de tempo real, e devido a maneira demasiadamente simplificada em a qual tarefas executam de acordo com os modelos encontrados na maioria dos trabalhos investigados, uma modificação no mapeamento ou inclusão de novas tarefas em tempo de execução pode desestabilizar a execução da aplicação.
Outros trabalhos os quais empregam o conceito de migração de tarefas utilizam pontos de migração, o que torna a migração de tarefas não transparente ao desenvolvedor.
Outro ponto é que a maioria dos trabalhos que utilizam algum mecanismo para a gerência automática de migração o fazem de maneira centralizada, tornando- se pouco escaláveis para arquiteturas MPSoC com um grande número de elementos de processamento.
Organização do Trabalho O presente trabalho apresenta- se organizado em sete capítulos.
Em o primeiro foi apresentada uma breve introdução sobre o tema a ser abordado.
Além disso a motivação e os objetivos foram enumerados.
O Capítulo 2 apresenta uma série de conceitos gerais sobre sistemas embarcados, complementado a introdução.
Em o Capítulo 3 são apresentados diversos trabalhos relacionados sobre mapeamento e migração de tarefas e comparados ao modelo proposto.
A o final do Capítulo, um quadro comparativo de todos os trabalhos avaliados é apresentado, classificando os mesmos de acordo com critérios estabelecidos.
O Capítulo 4 apresenta o modelo proposto para a descrição de aplicações dinâmicas de tempo real e a arquitetura proposta para a execução destas, abordando os parâmetros necessários para representar tarefas e como são escalonadas.
Além disso são apresentados os protocolos de comunicação entre tarefas, migração de tarefas e gerência de migração.
Em o Capítulo 5 é apresentada a implementação do modelo proposto na forma de um sistema operacional, focando principalmente no modelo de tarefas.
Os parâmetros caracterizados utilizados como base de tempo de escalonamento são apresentados, assim como o escalonamento e comunicação entre tarefas.
Em este Capítulo são abordados alguns detalhes de como é realizado o mapeamento, migração e gerência de tarefas, além de a API do sistema operacional.
A o final do Capítulo, a implementação do modelo de arquitetura proposto é apresentada.
O Capítulo 6 dedica- se aos experimentos realizados.
Inicialmente, são abordados testes de desempenho e overhead do sistema operacional.
A seguir, alguns testes do mecanismo de gerência de migração são realizados sobre aplicações sintéticas, comparando um modelo de migração centralizado ao modelo de migração distribuído proposto.
A o final do Capítulo, aplicações reais são modeladas de acordo com a proposta e posteriormente avaliadas.
O Capítulo 7 relaciona algumas conclusões obtidas e aponta sugestões para trabalhos futuros relacionados ao tema proposto.
Este Capítulo apresenta conceitos gerais sobre sistemas embarcados, sendo estes essenciais para a compreensão do restante do texto.
Serão abordados tópicos como sistemas de tempo real, sistemas multiprocessados, modelagem e mapeamento de tarefas que compõem uma aplicação.
Sistemas de Tempo Real Em muitos sistemas embarcados estão presentes restrições temporais, aliadas as já presentes restrições que caracterizam este tipo de sistema como a vida útil de baterias, tamanho, imunidade a choques e desgastes entre outros.
Algumas aplicações exigem tempo de resposta determinado, e a validade do resultado do processamento depende deste fator.
Sistemas desta natureza são conhecidos como sistemas de tempo real ou RTSs.
Segundo Farines, os sistemas de tempo real podem ser divididos em duas categorias distintas:·
Hard Real-Time -- Possuem restrições estritas quanto a o tempo de resposta e variação deste.
Sistemas hard devem sempre prover resultados no tempo determinado, ou a validade do próprio sistema torna- se nula.
Outros sistemas ou vidas podem depender destes;·
Soft Real-Time -- Possuem restrições quanto a o tempo de resposta, no entanto o sistema não é invalidado no caso de atrasos, apenas tem seu desempenho degradado.
Os sistemas operacionais de tempo real ou RTOSs são aqueles que controlam aplicações com algum tipo de restrição de tempo real.
Desta forma, muitos RTSs são gerenciados por sistemas operacionais deste tipo.
Esta classe de sistema operacional provê funcionalidades semelhantes a sistemas de propósito geral, como atendimento a interrupções, abstração de processos ou tarefas, comunicação entre processos ou tarefas e gerenciamento de memória.
De acordo com Farines, o principal objetivo de um RTOS é garantir a execução de uma tarefa dentro de o seu tempo determinado.
O fator chave neste conceito é o jitter do sistema, que é a variação da periodicidade frente o real período de uma tarefa.
Normalmente, um sistema operacional hard real-time possui menor e mais previsível jitter que um sistema operacional soft real-time.
Desta forma, o objetivo no projeto de um sistema deste tipo não é desempenho em termos de throughput, e sim previsibilidade.
Sistemas operacionais que geralmente conseguem atender requisições temporais são ditos soft real-time Os, e aqueles que atendem suas requisições sempre e de maneira determinística são ditos hard real-time Os.
Muitos são os sistemas operacionais pertencentes à categoria real-time, entre os quais destacam- se MicroC/ OS-II, AMX, CMX, Integrity e MQX.
Sistemas Embarcados Multiprocessados Por questões de custo, tempo de projeto, desempenho e confiabilidade, é desejável que sistemas embarcados sejam implementados na forma de um único chip, dando origem aos chamados SoC.
Comumente, SoCs são construídos como um agrupamento de componentes heterogêneos, como elementos de processamento, memórias, aceleradores (co-processadores) e meio de interconexão entre os componentes.
Uma especialização deste tipo de sistema embarcado deu origem aos sistemas que empregam mais de um elemento de processamento, os chamados MPSoC.
Segundo Jerraya, sistemas MPSoC podem ser, de maneira equivocada, comparados a arquiteturas CMP.
Ainda, CMPs são construídos com a integração de múltiplos elementos de processamento (normalmente do mesmo tipo) num único chip, aproveitando a alta densidade de transistores oferecida por tecnologias de implementação de hardware atuais e não importando o consumo de energia (voltado a desempenho).
MPSoCs, por outro lado, possuem arquiteturas customizadas e têm como objetivo utilizar a alta densidade de transistores aliada às necessidades de uma determinada aplicação.
Estas necessidades podem ser determinadas por o tempo de resposta, consumo de energia, tamanho, entre outros.
Algumas das razões para o emprego de MPSoCs em projetos atuais está ligado a fatores como redução no tempo de projeto, simplificação do processo de verificação em sistemas complexos e extensão da programabilidade de plataformas.
MPSoCs são classificados como homogêneos ou heterogêneos.
Sistemas que possuem mais de um tipo de elemento de processamento são heterogêneos e os com um único tipo são classificados como homogêneos.
A heterogeneidade tem como objetivo fornecer componentes específicos a uma determinada aplicação, e esta deve ser aplicada conforme a necessidade.
Muitas vezes, devido a o grande número de componentes presentes num mesmo MPSoC opta- se por um menor nível de heterogeneidade, simplificando dessa forma o projeto de hardware e software.
Elementos de processamento Elementos de processamento são unidades de execução implementadas em hardware, onde aplicações são executadas.
Estas unidades de execução podem ser elementos de propósito geral, como processadores de conjuntos de instruções (ISPs), elementos de processamento especializados (DSPs), estruturas implementadas em FPGA, núcleos de propriedade intelectual (IPs) dedicados e memórias especializadas.
Meios de interconexão Para que as unidades de execução presentes num chip possam trocar informações são necessárias estruturas de interconexão que realizam a comunicação entre estas.
Estas estruturas podem ser barramentos multiponto, barramentos hierárquicos, conexões ponto a ponto e redes intra-chip.
Estes meios de interconexão diferenciam- se por sua organização física, desempenho, escalabilidade, consumo de energia, custo de implementação entre outros fatores.
Barramentos multiponto são estruturas comumente utilizadas para conectar elementos de processamento num mesmo chip.
São relativamente escaláveis, permitindo a conexão de dezenas de nodos, o que torna a implementação de hardware de interconexão relativamente simples e organizada.
Em o entando, o meio é compartilhado entre os processadores e problemas como colisões de mensagens, aumento no consumo de energia e carga capacitiva tornam- se inevitáveis com o aumento do número de nodos.
Uma forma encontrada para amenizar estes problemas é a implementação de barramentos de forma hierárquica.
Essa solução, no entanto, apenas ameniza os problemas anteriormente citados.
Conexões ponto a ponto possuem um desempenho ótimo, uma vez que são linhas dedicadas entre elementos de processamento.
De o ponto de vista de projeto são pouco escaláveis e custosas em termos de área em silício, o que limita o seu uso a poucos elementos de processamento.
Redes intra-chip são propostas como a solução para os problemas citados, e seu uso é crescente no projeto de MPSoCs com dezenas e mesmo centenas de elementos de processamento.
NoCs são implementadas por roteadores e canais de comunicação entre estes, na forma de conexões ponto a ponto, e são altamente escaláveis além de prover um maior paralelismo comparado a barramentos.
Os roteadores podem ser dispostos em diferentes topologias, e a estes são conectados elementos de processamento.
Abstração de Sistemas com Modelos em Alto Nivel O aumento da complexidade e os desafios encontrados quando de a especificação até a construção e manutenção de sistemas MPSoC tornam evidente a crescente utilização de descrições em alto nível de abstração.
Segundo Ost, a modelagem consiste em produzir uma descrição do sistema, ou parte deste, utilizando algum tipo de formalismo.
Estas descrições são baseadas numa especificação e podem estar na forma de representações gráficas ou linguagens.
Ainda, de acordo com Lehoczky, um modelo deve conter as mesmas propriedades da entidade modelada que são relevantes a uma determinada aplicação.
Em este contexto, um modelo é uma simplificação de uma entidade, construído com o intuito de acelerar determinado processo, e sua utilidade depende da relevância da representação adotada para a resolução de um problema específico.
Exploração do Espaço de Projeto Usualmente, o co-design inicia em nível de sistema, onde a divisão final do sistema hardware e software ainda não foi completada.
Após os passos iniciais, um modelo de verificação funcional pode ser feito através de mecanismos de co-simulação, os quais ajudam na validação e refinamento do sistema.
Restrições comuns de sistemas embarcados, como time- to-- market exíguo e a alta complexidade de projetos atuais, implicam na utilização de simuladores em diferentes níveis de abstração por parte de os projetistas, desde simuladores de conjunto de instruções até descrições em nível de sistema, usualmente implementadas em ADL.
Em estes simuladores, tanto modelos de hardware quanto de software são executados com o intuito de se realizar uma análise do comportamento do sistema num estágio inicial de desenvolvimento.
Em este contexto, diversos trabalhos apresentam esforços no que diz respeito a modelagem de RTOS e aplicações num alto nível de abstração.
O maior problema nesta abordagem é que quando o projeto é refinado, apesar de o modelo do RTOS poder ser traduzido automaticamente em software, normalmente um RTOS amplamente adotado é preferido, o que previne que resultados obtidos durante a modelagem sejam suficientemente precisos quando a implementação do hardware real estiver concluída.
Yoo apresenta o problema de equivalência de código, o qual é definido como, se o código executado por o sistema modelado for diferente do executado por a arquitetura alvo, então o comportamento do sistema pode ser diferente do que foi simulado.
Assim, decisões erradas de projeto podem ser tomadas.
Além disso, ao utilizar- se abordagens de simulação em alto nível de abstração, usualmente o comportamento de tempo do sistema não é levado em consideração ou o mesmo não é completamente preciso.
Simuladores onde o quesito de timing da arquitetura alvo não for replicado podem modelar o sistema embarcado paralelo imprecisamente.
Tarefas Em o contexto deste trabalho, tarefas são unidades sequenciais e básicas de execução.
Tarefas podem coexistir num mesmo sistema, onde compartilham tempo de processamento se estiverem num mesmo elemento de processamento ou executam paralelamente se estiverem distribuídas.
Uma aplicação embarcada multiprocessada é composta por um conjunto de tarefas, que executam num conjunto de elementos de processamento e implementam uma determinada funcionalidade.
Essencialmente, no contexto deste trabalho tarefas são uma funcionalidade implementada em software.
Outros trabalhos utilizam o conceito de tarefas em hardware, no entando este conceito não se aplica ao modelo aqui proposto.
Particionamento e Mapeamento de Tarefas O particionamento das tarefas da aplicação compreende no agrupamento de tarefas.
A atividade de mapeamento tem como objetivo realizar o posicionamento dos grupos de tarefas na arquitetura, utilizando para esse fim uma função de mapeamento.
Sabe- se que o problema de mapeamento é Np-completo e algoritmos como Simulated Annealing, Tabu Search, Cutting Tree, métodos gulosos entre outros podem ser utilizados como alternativa ao método exaustivo para a obtenção de resultados aceitáveis quanto a qualidade do mapeamento, além de a vantagem de possuírem um tempo de computação reduzido.
As métricas mais comuns para a realização do mapeamento são consumo de energia, latência, ocupação dos canais de comunicação, carga dos elementos de processamento e tempo de resposta da aplicação.
Uma proposta de classificação para o mapeamento de tarefas é apresentada por Mandelli.
Esta proposta classifica o mapeamento de acordo com quatro critérios, sendo estes o momento em que é executado;
O número de tarefas por elemento de processamento;
A entidade de controle do mapeamento;
E a arquitetura alvo.
Assim, esta classificação pode ser detalhada como:·
Momento em que é executado Estático:
Realizado em tempo de projeto.
As heurísticas utilizadas para a realização do mapeamento podem levar em consideração todos os aspectos do sistema, uma vez que o conjunto de tarefas já é definido.
Entretanto, as heurísticas de mapeamento em tempo de projeto são computacionalmente complexas para lidarem com sistemas dinâmicos.
Dinâmico: Realizado em tempo de execução.
Heurísticas podem utilizar informações definidas em tempo de projeto, além de algoritmos simples e rápidos para a realização do mapeamento de tarefas dinamicamente.
Com reservas de recursos:
Heurísticas realizam a verificação de recursos antes de realizar o mapeamento.
Sem reservas de recursos:
Heurísticas realizam o mapeamento de acordo com a necessidade.
O sistema pode não ter recursos suficientes para mapear uma tarefa, sendo necessário esperar a liberação de recursos.·
Número de tarefas Monotarefa:
Uma única tarefa pode ser mapeada por elemento de processamento.
Multitarefa: Diversas tarefas podem ser mapeadas num mesmo elemento de processamento.·
Entidade de controle Centralizado:
Um elemento de processamento é responsável por a gerência do mapeamento.
Distribuído: Diversos elementos de processamento são responsáveis por a gerência.
Pode ser dividido em regiões, onde um elemento é responsável por o controle do mapeamento de outros na mesma região.·
Arquitetura alvo Homogênea:
Todos os elementos de processamento são idênticos.
Heterogênea: Diferentes tipos de elemento de processamento ou aceleradores são utilizados.
Anteriormente ao mapeamento deve ser realizado o binding que consiste em definir quais tarefas podem ser executadas por elementos específicos.
Migração de Tarefas A migração de tarefas consiste na relocação de tarefas de um elemento de processamento para outro em tempo de execução.
Assim, o conceito de migração pode ser diferenciado do mapeamento, uma vez que numa migração uma tarefa necessariamente precisa existir (estar mapeada).
Para que este processo ocorra, torna- se necessário parar a execução da tarefa a ser migrada, salvar o contexto do elemento de processamento1, realizar a cópia dos segmentos de código, dados e o contexto para o elemento de processamento destino, criar uma tarefa nova no destino, restaurar na tarefa criada o contexto copiado, reiniciar a tarefa e destruir a tarefa migrada no elemento de processamento de origem.
Existem essencialmente duas formas de serem implementados mecanismos de migração de tarefas de acordo com Nollet.
O primeiro, consiste na utilização de pontos de migração a serem definidos no código das tarefas.
Este tipo de migração possui algumas vantagens, como simplicidade na implementação do mecanismo e determinismo.
Assim, a invocação do processo de migração apenas irá ocorrer em momentos oportunos pois o mesmo é definido por o desenvolvedor.
Além disso, existe uma menor chance de ocorrerem perdas de deadline em sistemas de tempo real, uma vez que pontos críticos na execução podem ser tratados ou avaliados em tempo de projeto.
A principal desvantagem dessa forma é a necessidade do programador estar envolvido na otimização, decidindo exatamente os pontos ideais de migração.
No caso de aplicações realmente dinâmicas, a decisão sobre onde adicionar pontos de migração no código pode ser inviável, e é possível que a aplicação venha a piorar seu desempenho.
O segundo mecanismo consiste na implementação da migração de tarefas de maneira transparente.
Em esta forma, o processo de migração é controlado por um sistema operacional, que deve decidir, com base em algum critério, relocar tarefas de um elemento de processamento a outro.
As vantagens dessa forma de migração são a transparência do processo de migração em relação a aplicação (o programador não precisa definir pontos de migração) e adaptabilidade da O salvamento do contexto de um processador consiste em armazenar o conteúdo de registradores (que mantém o estado atual do processador) numa estrutura de dados específica, com o intuito de restaurar o estado de execução num momento oportuno.
O presente Capítulo apresenta alguns dos trabalhos relacionados encontrados na literatura.
Tais trabalhos são classificados de acordo com o seu tipo de mapeamento, sendo este estático ou dinâmico.
O conceito de migração de tarefas diverge em alguns pontos do conceito de mapeamento dinâmico e alguns trabalhos, incluindo este, foram classificados numa categoria a parte.
Mapeamento Estático Os trabalhos apresentados nesta Seção referem- se ao mapeamento estático realizado em sistemas MPSoC.
Alguns trabalhos não detalham formalmente o modelo utilizado para a realização do mapeamento de tarefas, mas preocupam- se com a descrição da técnica utilizada para a realização dessa atividade.
Naturalmente, a maioria dos trabalhos pode utilizar um modelo correspondente a algum dos apresentados anteriormente.
O trabalho apresentado por Mihal utiliza o conceito de modelos de computação para descrever os requisitos da aplicação com relação a comunicação e princípios arquiteturais sobre NoCs, com o intuito de modelar aplicações paralelas em ambientes heterogêneos.
Em a abordagem utilizada, a aplicação é descrita em alto nível e particionada manualmente.
O particionamento atribui as partes que compõem uma aplicação a elementos de processamento, e os mesmos são posteriormente mapeados na arquitetura.
Em este trabalho não é apresentada nenhuma técnica automática para realização do mapeamento, o qual é feito manualmente.
Em os trabalhos apresentados por Lei é proposta uma solução para o problema de mapeamento, a qual faz a utilização de algoritmos genéticos.
A aplicação é modelada através de dois diferentes grafos, chamados STG e MTG.
Esses grafos são gerados automaticamente por a ferramenta TGFF.
Em o trabalho, os autores descrevem a arquitetura como uma NoC malha, e propõem um algoritmo que tem como objetivo a redução no tempo de execução da aplicação.
A proposta do trabalho de Rhee consiste em lidar com o problema de mapeamento de elementos de processamento numa NoC, com o objetivo de reduzir o consumo de energia e o congestionamento do meio de interconexão.
Os autores propõem uma técnica que permite o mapeamento de múltiplos elementos de processamento a cada roteador da rede, reduzindo assim o número de saltos médio.
As aplicações são modeladas como grafos que representam o volume de dados transmitidos entre elementos de processamento.
Segundo os autores, reduções de até 81% no consumo de energia e 2.5% na largura de banda necessária são observadas, comparando essa técnica com outras que utilizam apenas o mapeamento de um elemento de processamento por roteador da rede.
Os trabalhos de Hu utilizam um grafo denominado CTG para descrever uma aplicação.
Esta descrição baseia- se na caracterização da comunicação através de pesos atribuídos a canais de comunicação, representados por a quantidade de dados transmitidos.
Este modelo, além de o volume e largura de banda necessária para a comunicação, incorpora informações referentes a computação, especificada detalhadamente através de seu tempo de execução, consumo de energia e tempo limite para execução.
O objetivo dos autores é propor uma técnica com o intuito de reduzir o consumo de energia de uma determinada aplicação, e o algoritmo utilizado por os autores para melhorar o tempo de mapeamento é divisão e conquista.
Murali utiliza uma representação em forma de grafo de elementos de processamento para descrever a arquitetura.
O objetivo dos autores é realizar o mapeamento de acordo com a largura de banda necessária a aplicação.
Em seu trabalho, apresenta uma ferramenta que permite selecionar a topologia de NoC empregada.
Além de isto, realiza um estudo de duas alternativas para a estratégia de roteamento que pode ser um caminho único mínimo ou múltiplos caminhos, permitindo a divisão de tráfego na rede.
O trabalho é estendido em, incorporando outras métricas ao modelo como latência e consumo de energia da aplicação.
Em são realizados estudos sobre um conjunto de aplicações, e diversas soluções de mapeamento são investigadas utilizando o método Tabu Search.
Manolache apresenta uma proposta para a solução do problema de falhas temporárias em canais de comunicação utilizando para isso redundância de mensagens.
Em o trabalho são apresentados modelos para a aplicação e seu mapeamento, para o hardware e para a comunicação.
O modelo da aplicação é representado por um conjunto de grafos direcionados acíclicos.
Cada tarefa é modelada num grafo e possui parâmetros como período, tempo de execução e deadline.
O mapeamento das tarefas é feito em tempo de projeto utilizando- se o algoritmo Tabu Search, e o caminho dos pacotes é definido em nível de aplicação.
O objetivo do trabalho é garantir tolerância a falhas e reduzir a latência média para a entrega de mensagens na rede.
O trabalho apresentado por Srinivasan aprofunda- se numa técnica de minimização do consumo de energia no mapeamento de elementos de processamento, e utiliza critérios adicionais como largura de banda e latência.
Os autores modelam o problema de mapeamento definindo elementos de processamento como vértices de um grafo direcionado, e arestas como a largura de banda e latência necessárias a aplicação em questão.
Para solucionar o problema do mapeamento, definem uma função que permite atribuir elementos de processamento a tiles na rede.
A rede possui topologia malha, e parâmetros como largura de banda e consumo de energia são definidos para cada roteador.
Diversos algoritmos que implementam funções multimídia como MP3 e H. 263 são utilizados para realização dos experimentos, e o método de mapeamento utilizado por os autores é o algoritmo Cutting Tree.
O problema do mapemento de tarefas numa NoC com topologia malha é apresentado por Marcon em.
Em o trabalho, o grafo CWG é utilizado para representar o volume de dados de comunicações entre elementos de processamento e o CDG para representar a ordenação de mensagens.
Os autores utilizam a técnica Simulated Annealing e também um método exaustivo para encontrar o melhor mapeamento.
Comparado ao trabalho apresentado por Hu, foram obtidas melhorias significativas na qualidade do mapeamento, sendo o consumo de energia e tempo de execução as métricas utilizadas.
Em é utilizado um novo grafo, chamado CDCG, o qual detalha o instante de envio de cada pacote de dados na rede, e o trabalho apresenta novamente resultados significativos comparado a trabalhos anteriores.
Um trabalho mais recente apresenta outras técnicas para a realização do mapeamento, entre elas pode- se enumerar Greedy Incremental, Largest Communication First e o método Tabu Search.
Orsila modela aplicações com o uso de grafos direcionados, que incorporam informações sobre a dependência entre tarefas, o volume de dados transferido e o tempo de computação.
Em este trabalho é apresentado um método para otimizar os parâmetros do algoritmo Simulated Annealing, com o intuito de diminuir o tempo necessário para encontrar soluções adequadas ao problema de mapeamento.
Como resultado, observou- se que diferentes métodos devem ser utilizados para realização das otimizações, divididas como locais e globais.
Uma extensão do trabalho é realizada em, apresentando resultados comparativos com relação a o uso de memória para a execução dos algoritmos utilizados.
Em o trabalho apresentado por Mehran, os autores modelam aplicações através de grafos de elementos de processamento, que detalham suas dependências e necessidades com relação a banda de comunicação.
Um algoritmo de mapeamento chamado Spiral é proposto.
Esse algoritmo procura mapear elementos de processamento de maneira espiral numa NoC.
Em os estudos realizados, foram experimentados mapeamentos com dimensões da rede entre 3x3 e 6x6 tiles, e os resultados apresentaram ganhos significativos na qualidade do mapeamento ao comparar seu método a algoritmos genéticos.
Mapeamento Dinâmico Os trabalhos apresentados nessa Seção referem- se ao mapeamento dinâmico realizado em diversos ambientes MPSoC.
Novamente, alguns trabalhos não detalham formalmente o modelo utilizado para a descrição das tarefas a serem particionadas ou mapeadas, mas preocupam- se com a descrição da técnica utilizada para a realização dessa atividade.
Ngouganga apresenta uma solução para o mapeamento numa arquitetura MPSoC homogênea, utilizando elementos de processamento que executam um microkernel e encontram- se conectados numa NoC.
Em o trabalho desenvolvido, define- se um elemento de processamento mestre e múltiplos escravos, sendo o mestre responsável por o mapeamento dinâmico das tarefas no sistema.
Inicialmente, não existe um mapeamento estabelecido, dessa forma o sistema dinamicamente atribui tarefas a processadores.
Dois algoritmos são utilizados no trabalho, sendo eles Simulated Annealing e força direcionada.
O tempo para realização do mapeamento é ignorado neste trabalho.
Segundo os autores, o algoritmo de força direcionada apresentou um tempo de execução menor que o Simulated Annealing, e resultados comparados a soluções que utilizam mapeamento aleatório apresentaram boa escalabilidade.
O trabalho desenvolvido por Wronski utiliza os algoritmos BF e WF para a realização de mapeamento dinâmico numa arquitetura MPSoC.
Um modelo implementado em alto nível é utilizado para simular os elementos de processamento, e o meio de interconexão utilizado é uma NoC descrita em nível RTL.
Através da co-simulação os autores conseguem estimar o consumo de energia da aplicação para diferentes tipos de mapeamento.
Cada tarefa do sistema é representada por um valor de tempo de execução, e um número de chaveamentos (atribuído aleatoriamente).
Em todos os experimentos foram utilizadas aplicações sintéticas geradas a partir de o gerador TGFF.
Os resultados apontam grandes mudanças no consumo de energia da aplicação, dependendo do mapeamento empregado.
Brião estende este trabalho e utiliza outros algoritmos, como a combinação da técnica de clusterização linear com os algoritmos BF e WF.
Hölsenspies apresenta um trabalho voltado a estimativas na qualidade de mapeamentos de aplicações com requisitos de tempo real em arquiteturas MPSoC heterogêneas.
As aplicações são modeladas como grafos direcionados, constituídos por tarefas e caminhos de comunicação representados por filas.
Em este trabalho, um dos elementos de processamento é utilizado como gerente, e executa um sistema operacional dedicado.
A gerência baseia- se em informações obtidas em tempo de projeto (número de processadores, estimativas em geral, etc.) e em tempo de execução toma decisões quanto a o mapeamento com o objetivo de reduzir o consumo de energia e garantir qualidade de serviço.
Em são incorporados mais detalhes ao modelo e apresentados mecanismos de mapeamento para áreas reconfiguráveis da arquitetura.
Chou utiliza um método que realiza o mapeamento de elementos de processamento em MPSoCs homogêneos.
Uma NoC com topologia malha é utilizada como meio de interconexão e são utilizados dois caminhos separados para controle e dados de uma determinada aplicação.
Em o trabalho, as aplicações são modeladas a partir de grafos que representam o volume de dados e largura de banda exigidos por a aplicação.
Um elemento de processamento gerente é utilizado como controlador do mapeamento, e o mesmo deve em tempo de execução alocar elementos de processamento disponíveis no MPSoC e dinamicamente realocar elementos de processamento com o intuito de diminuir a fragmentação da aplicação1.
Segundo os autores, seu método apresenta melhorias significativas com relação a mapeamento aleatório em consumo de energia (45%) e pouca penalidade na qualidade comparado a um mapeamento exaustivo que teria um tempo de execução infinitamente maior para o tamanho do MPSoC empregado (dimensão 7x7).
Este trabalho é complementado em, onde os autores utilizam o conceito de perfis baseados no comportamento do usuário para realizar o mapeamento dinamicamente, avaliando a periodicidade e volume de dados das tarefas.
Diferentes técnicas de mapeamento são avaliadas, sendo uma proposta em que utiliza áreas contíguas para mapear tarefas de uma aplicação, e a outra utiliza regiões em formato geométrico.
São utilizadas aplicações reais para a realização dos experimentos.
Mehran realiza um estudo sobre a qualidade do mapeamento dinâmico num sistema MPSoC formado por uma rede de dimensão 4x4.
Segundo os autores, o comportamento de uma determinada aplicação varia dinamicamente durante seu tempo de vida, o que motiva a utilização de diferentes mapeamentos durante sua execução.
O algoritmo Spiral é utilizado novamente neste Conforme uma aplicação é dita fragmentada ou não contígua quando tarefas altamente comunicantes encontram- se distantes (com relação a o número de saltos na rede), o que acarreta numa execução não otimizada da aplicação.
Al Faruque realiza a descrição de aplicações utilizando grafos de dependência entre tarefas e largura de banda necessária.
O mapeamento das tarefas é realizado de maneira distribuída, utilizando gerentes locais para diferentes elementos de processamento dentro de um mesmo cluster virtual e gerentes globais para selecionar determinado cluster dinamicamente.
Assim, um mecanismo é implementado para sincronizar gerentes locais e globais e realizar as tomadas de decisão de maneira distribuída utilizando técnicas de seleção de cluster, migração e re-clusterização.
São apresentadas comparações com outros trabalhos que utilizam heurísticas de mapeamento semelhante porém empregando o modelo centralizado, e resultados positivos na abordagem distribuída são encontrados em MPSoCs de grandes dimensões, com tamanhos a partir de 12x12 até 64x64 nodos.
Wildermann propõe uma técnica para a realizar o mapeamento dinâmico de tarefas num ambiente MPSoC homogêneo, onde o objetivo é reduzir o consumo de energia de uma determinada aplicação e garantir o cumprimento de requisitos de execução.
Aplicações são descritas por grafos, e o conceito de tarefas mestre/ escravo é utilizado para reproduzir o comportamento de aplicações do tipo streaming.
A heurística proposta procura reduzir sobrecargas de comunicação geradas por tarefas dinamicamente mapeadas e utiliza o conceito de autômatos celulares, onde células modificam sua ocupação de acordo com o estado dos vizinhos.
Uma avaliação da heurística é apresentada, e métricas como tempo médio de processamento de uma aplicação, deadlines e sobrecarga de comunicação são utilizadas.
Para comparações, é utilizada a heurística NN, e apesar de esta possuir um baixo overhead, a heurística proposta mostra- se mais eficiente pois apresenta o melhor compromisso levando em consideração as métricas utilizadas.
Zipf apresenta uma heurística para a realização do mapeamento dinâmico de tarefas em ambientes MPSoC homogêneos.
A proposta consiste em organizar o algoritmo de gerência de mapeamento de maneira distribuída, de forma que as dimensões do sistema sejam escaláveis.
Em o trabalho, tarefas podem ser mapeadas em tempo de execução de acordo com informações de outros nodos sobre a carga de processamento, tamanho das tarefas, requisitos de comunicação e contenções na rede.
Para a obtenção de resultados os autores utilizam um protótipo numa malha de dimensões 3x3.
Segundo os autores, a solução proposta possui uma penalidade de 25% perante um algoritmo exato.
Ainda, a qualidade do mapeamento em malhas de maiores dimensões, onde o algoritmo Simulated Annealing é utilizado como referência é reduzida em 30%.
De acordo com a proposta, estas penalidades são razoáveis, uma vez que existe um baixo custo computacional e de comunicação e dessa forma a solução descentralizada torna- se viável para sistemas dinâmicos com grande número de processadores.
As heurísticas NN e BN propostas por Carvalho são complementadas por Singh para incluir o suporte multitarefa ao mapeamento de aplicações dinâmicas.
As aplicações são des-critas em grafos em forma de árvore, onde uma tarefa inicial é utilizada para mapear outras.
Estas tarefas iniciais (uma para cada aplicação) são dispostas em regiões centrais de grupos virtuais de elementos de processamento (clusters), e processadores são alocados de acordo com a necessidade da aplicação dentro destes grupos.
Além disso, é apresentado no conceito de agrupamento de tarefas com o objetivo de alocar tarefas comunicantes num mesmo elemento de processamento.
Em é utilizada uma variação para a alocação de tarefas num mesmo elemento de processamento (agrupamento), levando- se em consideração o histórico de tarefas mapeadas num dado elemento de processamento para tomar- se a decisão de mapeamento local (tarefa comunica- se com alguma previamente mapeada localmente) ou em outro nodo.
Carvalho propõe diversas heurísticas dinâmicas para o mapeamento de tarefas em MPSoCs heterogêneos com o objetivo de reduzir congestionamentos na rede.
Para isso, pares de tarefas comunicantes são aproximadas, diminuindo o número de saltos entre estas e consequentemente os caminhos congestionados.
Aplicações são modeladas por grafos que retratam tarefas e comunicações entre estas.
Novas tarefas são mapeadas dinamicamente a partir de tarefas iniciais neste modelo.
De acordo com o trabalho, o custo médio das soluções propostas comparadas ao método estático de referência é em torno de 16% com relação a o consumo de energia e volume de dados.
Diversas aplicações reais são modeladas para a obtenção de resultados, e algoritmos como MPEG4, MWD, RBERG e VOPD são avaliados com as heurísticas propostas.
Em o trabalho de Schranzhofer informações sobre o mapeamento da aplicação são definidas em tempo de projeto e incluídas em templates que são armazenados em tabelas.
Em tempo de execução o sistema é avaliado por um mecanismo de gerência, e dinamicamente o mapeamento mais adequado é selecionado.
De acordo com os resultados, o custo da solução proposta é bastante baixo e a redução do consumo de energia comparado a um trabalho publicado por o mesmo autor anteriormente é em torno de 45%.
O modelo de aplicação utilizado é formado por tarefas que possuem determinado uso de processador e consumo de energia e entre estas tarefas são definidas transações.
Braak propõe a gerência de recursos em tempo de execução com o objetivo de prover um certo nível de flexibilidade e tolerância a falhas em sistemas MPSoC heterogêneos devido a imperfeições na fabricação de circuitos integrados e falhas decorrentes de desgastes.
Inicialmente, é realizado um particionamento da aplicação em tarefas.
Após, em tempo de execução a alocação de recursos é realizada em quatro fases:
Binding, mapping, routing e validation.
Tarefas são descritas por grafos e possuem requisitos de tempo de processamento e comunicação.
Os experimentos realizados demonstram que a solução é viável, e que o tempo de alocação por recurso é medido em dezenas de milissegundos.
A ferramenta TGFF é utilizada para gerar diferentes cenários de aplicações sintéticas, sendo tais cenários variações entre conjuntos de tarefas altamente comunicantes e com alta utilização de tempo de processador.
Mandelli apresenta novas heurísticas para a realização do mapeamento dinâmico de tarefas em MPSoCs homogêneos com o objetivo de reduzir o consumo de energia e explorar a dependência entre tarefas em tais ambientes.
O trabalho de Carvalho é utilizado como referência para o modelo de aplicação empregado, que consiste em tarefas iniciais e tarefas mapeadas dinamicamente a partir de estas.
O mesmo trabalho é utilizado nos resultados obtidos, onde as heurísticas NN, BN, PL e BN são comparadas a outras propostas, como LEC-DN (mapeamento), Premap (clusterização) e Premap-DN (combinação entre métodos).
Uma contribuição significativa é a extensão do modelo de tarefas e das heurísticas para incluir o suporte multi-tarefa, algo pouco explorado por trabalhos na área.
Migração de Tarefas Nollet apresenta um estudo que utiliza um gerenciamento centralizado de recursos em tempo de execução através do uso de uma heurística para migração de tarefas num ambiente heterogêneo.
O trabalho baseia- se numa plataforma que conta com um processador ARM conectado a elementos de processamento escravos, interconectados por uma NoC malha 3x3.
Em o trabalho, um sistema operacional centralizado realiza o gerenciamento e alocação dos recursos computacionais, e na aplicação são definidos pontos de migração que podem ser utilizados por o sistema operacional.
Os nodos escravos são implementados numa FPGA e são reconfiguráveis em tempo de execução, o que permite a execução de tarefas tanto em hardware quanto em software.
A arquitetura utilizada é apresentada por Mignolet.
O objetivo de utilizar migrações de tarefa no contexto do trabalho ocorre em virtude de modificações nas características da aplicação ou falhas durante o mapeamento de recursos.
Em o trabalho é complementado com o intuito de diminuir o tempo de reação encontrado nos mecanismos de migração previamente propostos.
Os autores propõem uma técnica de reutilização de registradores de depuração encontrados no processador utilizado com o intuito de diminuir o overhead inicial de migrações de tarefas.
O trabalho de Bertozzi aborda migrações de tarefas em MPSoCs e propõe um mecanismo onde um sistema operacional (uCLinux modificado) centralizado realiza a gerência.
Em a aplicação, implementada seguindo um modelo mestre escravo, o usuário é responsável por definir pontos de migração.
Tarefas mestre são responsáveis por realizar a admissão e alocação de recursos, objetivando o balanceamento de carga no sistema.
Como resultados, os autores realizam uma série de comparações e concluem que o overhead gerado por o mecanismo implementado é baixo se comparado a soluções distribuídas, que podem inviabilizar a utilização de migração de tarefas.
Ozturk apresenta uma nova abordagem para o processo de migração, denominada de migração seletiva.
Essa abordagem é descrita por três componentes principais:
Personalização, anotação de código e migração seletiva.
As primeiras duas etapas são realizadas em tempo de projeto.
Assim, a etapa de personalização realiza a coleta do custo energético da migração de fragmentos específicos tanto de código quanto de dados através da rede de comunicação.
Os custos são anotados no código e utilizados durante a migração seletiva que acontece em tempo de execução.
A arquitetura utilizada no trabalho é composta por oito elementos de processamento 32 kB de memória local, interligados por um barramento.
Um conjunto de benchmarks criado por os autores é utilizado para a obtenção de resultados, sendo o consumo de energia e tempo de execução das aplicações as métricas utilizadas para a avaliação.
Carta apresenta o algoritmo MiGra que tem como objetivo reduzir gradientes de temperatura em MPSoCs, utilizando migrações de tarefas.
O mecanismo apresentado baseia- se em valores de temperatura do chip que são medidos em tempo de execução para tentar balancear sua temperatura sem contudo aumentar o consumo de energia.
O algoritmo MiGra, diferentemente de outras técnicas que reagem quando são observadas altas temperaturas, tenta fazer com que as temperaturas dos elementos de processamento fiquem numa média do sistema como um todo.
De essa forma, tarefas podem ser migradas mesmo de nodos considerados mais frios, ao contrário de outras técnicas que migram tarefas somente de nodos mais quentes.
A o término de uma migração, é observado o consumo total de energia do chip.
Como resultado, são apresentadas comparações entre abordagens que realizam balanceamento de carga simples e balanceamento de carga que leva em consideração o consumo de energia.
Em Götz é apresentado um fluxo para a realização da realocação dinâmica de tarefas híbridas, as quais podem executar tanto em hardware quanto em software.
Em o modelo proposto, tarefas são representadas por um grafo de transição de estados e cada estado é denominado bloco de computação, que representa uma determinada operação de uma tarefa.
Em a descrição do grafo são verificados pontos de encontro entre as versões software e hardware da tarefa.
Ainda na descrição são representados pontos de troca, onde pode ser realizada a realocação de tarefas.
Em estes pontos existe somente um contexto que precisa ser salvo.
O modelo é implementado numa ferramenta que é capaz de gerar as versões de hardware e software da tarefa juntamente com um componente de gerenciamento da migração, relacionado com um sistema operacional.
Pittau apresenta um estudo sobre uso da migração de tarefas e seu impacto em aplicações multimídia em MPSoCs.
Em o trabalho são empregados elementos de processamento que possuem a funcionalidade que permite variar a frequência de operação, sendo estes interconectados por um barramento.
Cada elemento de processamento possui uma memória local, onde são armazenados os dados das tarefas.
O mecanismo de migração realiza a transferência destes dados para um módulo de memória compartilhado entre os elementos de processamento no evento de uma migração, com o intuito de reduzir o overhead quando comparado a uma solução que utiliza puramente trocas de mensagens.
A proposta de Brião leva em consideração o overhead da migração de tarefas num ambiente dinâmico e apresenta seu impacto em termos de consumo de energia, desempenho e restrições de tempo real no contexto de MPSoCs baseados em NoC.
Em o trabalho, foi desenvolvida uma ferramenta capaz de simular o comportamento de sistemas baseados em NoC que executam tarefas geradas por a ferramenta TGFF, as quais são dinamicamente carregadas.
A migração de tarefas é executada baseada num modelo de cópia da tarefa, que consiste em migrar todo o contexto e código.
Segundo os autores, a migração de tarefas pode ser utilizada em sistemas embarcados visto que apresenta ganhos em termos de desempenho e redução no consumo de energia envolvidos no sistema e ainda garantir o cumprimento de deadlines em sistemas soft real-time.
Em o trabalho de Mulas que consiste num complemento dos trabalhos de Carta e Pittau, o processo de migração de tarefas é realizado por um middleware (MPOS) e o principal objetivo é obter uma política de balanceamento térmico e energético para aplicações de streaming em ambientes MPSoC levando em consideração o desvio padrão da temperatura dos elementos de processamento mais quentes e mais frios.
Assim como no trabalho anterior, migrações são feitas através de um mecanismo denominado por os autores por replicação de tarefas, que consiste em se manter uma cópia de cada tarefa em todos os processadores.
Segundo os autores, manter uma cópia reduz o overhead natural de uma migração embora implique em maior área necessária em memória.
Marchesan apresenta um mecanismo para a realização de migrações de tarefa num MPSoC baseado em NoC.
Em o trabalho, tarefas são especificadas com requisitos de computação e filas de comunicação e são gerenciadas por um sistema operacional que executa em cada nodo da arquitetura, fornecendo serviços de comunicação e migração de tarefas.
Em o mecanismo implementado, são definidos pontos de migração nas chamadas às primitivas de comunicação, dessa forma migrações de tarefa apenas ocorrem quando tarefas comunicam- se.
O objetivo do trabalho é apresentar a viabilidade da implementação de mecanismos de migração em plataformas altamente distribuídas e escaláveis, onde cada nodo da arquitetura é caracterizado por possuir uma memória local e filas de comunicação em hardware.
Para a obtenção de resultados são utilizadas aplicações reais (Des e MJPEG), onde comparações entre decisões de migração baseadas em utilização de processador e localidade das tarefas são realizadas.
Shen propõe a utilização de uma arquitetura MPSoC heterogênea configurável baseada em elementos de processamento que possuem o mesmo conjunto de instruções básico.
A idéia é utilizar estes elementos de processamento em diferentes versões e realizar migrações de tarefas, sendo o conjunto de instruções extendido para a execução de tarefas específicas com o intuito de melhorar a execução destas e reduzir o consumo de energia do sistema.
Os autores argumentam que um grande percentual da execução de aplicações utiliza apenas o conjunto de instruções básico, e que a heterogeneidade e homogeneidade da plataforma deve ser balanceada para que sejam obtidas melhorias com extensões dos elementos de processamento.
Assim, tarefas podem ser migradas entre elementos de processamento apenas se o elemento destino possuir todas as instruções necessárias para a execução destas.
O trabalho se concentra na infra-estrutura necessária para suportar o escalonamento de tarefas e migração entre elementos de processamento, e a aplicação utilizada no estudo de caso apresentado é o MJPEG.
Cuesta explora os benefícios de técnicas de migração thermal-- aware em sistemas MPSoC.
Os autores propõem políticas para a redução da temperatura média do chip e gradientes de temperatura com pouco impacto no desempenho.
Em o trabalho são propostas três políticas de migração baseadas em funções adaptáveis para três fatores distintos:
Média do desvio padrão de temperatura entre processadores, temperatura máxima do chip e gradiente termal entre os núcleos.
Os experimentos realizados foram desenvolvidos numa plataforma de emulação MPSoC (composta por um processador PowerPC mestre e outros oito RISC escravos interconectados por barramentos) e os mecanismos propostos integrados num sistema operacional que realiza a migração de tarefas e medições de temperatura.
Segundo os autores, a redução na temperatura comparada a outros trabalhos relacionados é em torno de 30%.
Cannella propõe a descrição de aplicações utilizando PPNs num ambiente MPSoC homogêneo.
Cada nodo possui uma memória local, e é interconectado a outros por uma NoC e filas de comunicação.
Em o trabalho, um sistema operacional fornece serviços de comunicação e migração de tarefas.
Migrações de tarefas são utilizadas para garantir determinado aspecto (modelado na aplicação) como qualidade de serviço, disponibilidade de recursos ou consumo de energia.
Duas aplicações reais são avaliadas nos resultados (Sobel e MJPEG), e a plataforma como um todo é a amplamente discutida apresentando resultados de overhead para os protocolos de comunicação e migração de tarefas.
Ainda, a aplicação MJPEG é explorada no intuito de variar as métricas de desempenho em tempo de execução, utilizando para isso a modelagem proposta e o mecanismo de migração.
Análise Comparativa e Questões em Aberto As Tabelas 3.1 e 3.2 apresentam um resumo das principais características dos trabalhos relacionados ao mapeamento e migração de tarefas em sistemas embarcados dos últimos anos.
Como pode ser observado, há uma grande quantidade de trabalhos abordando tanto o mapeamento estático quanto o mapeamento dinâmico e migração de tarefas, com um crescente interesse com relação a sistemas dinâmicos em trabalhos recentes.
Apesar de as diversas vantagens na utilização de arquiteturas heterogêneas, a maioria dos trabalhos utiliza um modelo homogêneo.
Grande parte dos autores argumenta que o espaço de projeto é mais facilmente explorável neste tipo de arquitetura, e que os modelos podem ser simplificados significativamente.
Ainda, existe uma forte tendência a se transferir parte da complexidade na implementação de sistemas MPSoC para o software, uma vez que é possível desenvolver chips com centenas de núcleos com tecnologias de fabricação atuais.
Assim, a replicação de núcleos com as mesmas características facilita o processo de desenvolvimento do software e do hardware e permite uma maior flexibilidade da arquitetura para diferentes aplicações.
Em o presente trabalho será adotada uma arquitetura MPSoC homogênea com memórias distribuídas, uma vez que de acordo com trabalhos recentes esta é a abordagem mais adequada para um grande número de elementos de processamento.
Boa parte dos trabalhos utiliza reserva de recursos, que consiste em alocar espaço para todas as tarefas da aplicação mesmo que existam tarefas que não estejam executando no momento.
A reserva de recursos pode ser utilizada para garantir QoS, entretanto as restrições impostas por este tipo de mecanismo são grandes:
Subutilização dos recursos computacionais e;
Dimensionamento pessimista da arquitetura, pois podem ser necessários mais núcleos devido a reserva.
Segundo Mandelli a reserva de recursos pode aumentar o tempo de execução da aplicação pois é necessário que haja espaço para todas as tarefas de uma dada aplicação, e esta deixa de executar até que isto aconteça.
Em um sistema sem reservas, tarefas podem executar a medida em que for necessário se houver um recurso disponível, não sendo necessário o mapeamento completo da aplicação.
De essa forma, no presente trabalho será utilizada a abordagem sem reserva de recursos.
O emprego de mecanismos de mapeamento e migração que fornecem suporte multi-tarefa é crescente em trabalhos recentes.
A abordagem multi-tarefa possui uma série de vantagens, tais como redução do tráfego na rede de interconexão (tarefas podem ser mapeadas para um mesmo elemento de processamento), redução do tamanho da arquitetura MPSoC, uma vez que um mesmo nodo pode ser compartilhado por diversas tarefas e maior flexibilidade em aplicações dinâmicas.
Muitas vezes, tarefas não possuem grande complexidade computacional e alocar- las num nodo que não possui recursos multi-tarefa inevitavelmente subutiliza a arquitetura.
Seguindo a idéia proposta em trabalhos recentes, será adotado neste trabalho a abordagem multitarefa.
Este modelo vem ao encontro de o modelo multi-programado que predomina em sistemas operacionais de propósito geral.
São três os modelos de gerenciamento para a realização do mapeamento dinâmico e migração de tarefas encontrados na literatura:
Controlado por o usuário;
Centralizado e;
Distribuído. A maioria dos trabalhos, com exceção de Al Faruque, Zipf, Marchesan e Cannella utilizam o conceito de gerenciamento centralizado.
Em o modelo centralizado, um elemento de processamento mestre controla todos os outros presentes no sistema e possui uma visão global das características da aplicação.
O modelo centralizado permite a implementação de mecanismos eficientes do ponto de vista da qualidade do mapeamento dinâmico, ao custo da sua escalabilidade.
Novos sistemas que possuem um grande número de processadores e tarefas tornarão o trabalho do mestre cada vez maior, sobrecarregando- o.
Em o modelo distribuído, a responsabilidade por o mapeamento dinâmico é compartilhada entre todos os elementos de processamento.
Trocas de mensagem são necessárias para que sejam conhecidas características da aplicação e estado dos outros nodos, uma vez que não existe visão global do sistema.
De essa forma, as decisões relacionadas ao mapeamento dinâmico são realizadas por a interação entre nodos.
Apesar de a gerência distribuída do mapeamento dinâmico em MPSoCs ser pouco explorada até o presente momento, esta será a abordagem adotada pois acredita- se que no futuro o modelo centralizado será um gargalo.
O modelo de gerência distribuído proposto é uma contribuição deste trabalho.
De maneira geral, tarefas de aplicações embarcadas podem ser facilmente representadas por grafos, sendo esta a representação utilizada por a maioria dos trabalhos revisados.
Alguns trabalhos não possuem uma representação em alto nível, e descrevem seu modelo como sendo parte da própria implementação.
As principais características representadas nos modelos estudados referem- se ao volume de dados e largura de banda, uma vez que estes são de grande interesse em ambientes que empregam NoCs como meio de interconexão.
O processamento das tarefas nos nodos é muitas vezes representado simplesmente por ciclos de relógio ou utilização do processador e não é frequentemente explorado nos modelos.
Alguns trabalhos ignoram o conceito de contexto de tarefa, o que simplifica o modelo de mapeamento dinâmico e migração, mas restringe muito a aplicabilidade destes modelos em aplicações reais.
Outro conceito pouco utilizado é a implementação de algoritmos de escalonamento de tempo real em sistemas MPSoC e representação dos parâmetros das tarefas num modelo em alto nível.
A criação de uma representação em alto nível que incorpora parâmetros de tempo real é uma contribuição original deste trabalho, uma vez que nos trabalhos encontrados na literatura este conceito é pouco explorado.
Com relação a a programabilidade, muitas vezes a aplicação é modelada simplesmente como transferências de fluxos de dados, e as funcionalidades disponibilizadas restringem- se a primitivas de comunicação.
O presente trabalho propõe um modelo de programação mais completo do ponto de vista da aplicação, onde um sistema operacional fornece suporte semelhante a sistemas de propósito geral e facilita o desenvolvimento de aplicações embarcadas.
A maior parte dos trabalhos revisados utilizam como função de custo o consumo de energia.
Outros trabalhos consideram o tempo de execução da aplicação, utilização dos canais da rede e temperatura do chip, e indiretamente redução no consumo de energia de maneira proporcional.
A redução no consumo de energia é de extrema relavância em ambientes MPSoC, no entanto outros problemas precisam ser atacados devido a flexibilidade de sistemas dinâmicos, que permitem a inclusão de novas funcionalidades em tempo de execução e possuem um perfil variável de execução.
Assim, este trabalho utiliza como função de custo a utilização de processador e garantias de tempo real da aplicação, sendo esta uma abordagem pouco explorada nos trabalhos da área.
Segundo Zipf a migração de tarefas diferencia- se do mapeamento dinâmico uma vez que no segundo novas tarefas podem ser mapeadas em tempo de execução.
O autor deste trabalho discorda, pois o fato de existir um mecanismo que permita a migração de tarefas de um nodo a outro não invalida a possibilidade de existir outro mecanismo que permita a realização do mapeamento dinamicamente.
Apesar de o presente trabalho estar inserido na classificação migração de tarefas, foram modelados e descritos mecanismos para a realização do mapeamento dinâmico.
O mecanismo de migração é uma contribuição significativa deste trabalho, sendo este o principal motivo da classificação utilizada.
Considerações Finais Este Capítulo apresentou os principais trabalhos encontrados na literatura relacionados ao tema proposto.
De essa forma, o presente trabalho tem como intuito complementar o estado da arte, apresentando um modelo para a realização do mapeamento dinâmico e migração de tarefas em sistemas MPSoC homogêneos com grande número de nodos.
Foram identificadas algumas limitações com relação a os modelos de tarefa, programabilidade e gerência destas em ambientes dinâmicos, e dessa forma espera- se contribuir para o avanço desta área de pesquisa.
Tabela 3.2 ­ Resumo comparativo entre os trabalhos sobre migração Autor Nollet Bertozzi Ozturk Carta Götz Arquitetura Reserva de Recursos Multitarefa Gerenciamento Modelo de Aplicação Heterogênea Não Sim Controlado por o usuário Homogênea Não Sim Centralizado Homogênea Não Centralizado Tarefas com QoS e volume de dados (grafos) Tarefas mestre/ escravas Tarefas de hardware e software Tarefas com utilização de processador Blocos de computação e pontos de encontro (grafos) Tarefas e filas de comunicação Tempo de execução e número de chaveamentos (grafos) Tarefas com utilização de processador Tarefas com tempo de execução e filas de comunicação (grafos) Tarefas com tempo de processador e comunicação (grafos) Homogênea Não Sim Centralizado Heterogênea Não Sim Controlado por o usuário Homogênea Não Sim Homogênea Sim Sim Controlado por o usuário Centralizado Mulas Marchesan Homogênea Não Sim Centralizado Homogênea Sim Sim Distribuído Shen Heterogênea Não Sim Centralizado Cuesta Cannella Proposta Heterogênea Não Sim Centralizado Homogênea Não Sim Distribuído Pittau Brião Tarefas e filas de comunicação (PPNs) Tarefas de tempo real e melhor esforço caracterizadas, volume de dados (grafos) Infraestrutura de Comunicação NoC malha Algoritmo Função Custo Pontos de migração (gerenciado por o SO) Modificação do perfil e falhas NoC malha Pontos de migração Barramento Migração seletiva NoC malha MiGra Barramento Pontos de migração Balanceamento de carga Consumo de energia e tempo de execução Temperatura, consumo de energia Barramento Pontos de migração Consumo de energia NoC malha Best Fit, Worst Fit e outros Consumo de energia e tempo de execução NoC malha MiGra/ DVFS (gerenciado por o SO) Serviço de melhoria, pontos de migração (gerenciado por o SO) First Match First Served Temperatura, consumo de energia Utilização de processador, distância entre tarefas Tempo de execução NoC malha Barramento e NoC Barramento NoC malha NoC malha Pontos de migração (gerenciado por o SO) Serviços do SO Busca por espalhamento em situação de sobrecarga (gerenciado por o Temperatura QoS, consumo de energia Tempo real da aplicação (deadlines), utilização de processador, tempo de migração Em este Capítulo é apresentado o modelo utilizado para representar características da aplicação e arquitetura MPSoC no contexto deste trabalho.&amp;&amp;&amp;
Inicialmente a organização da arquitetura adotada é discutida, a definição do problema é apresentada e definições gerais são utilizadas como introdução ao modelo formal aqui descrito.
Organização da Arquitetura O emprego de um mesmo tipo de elemento de processamento para a construção da arquitetura MPSoC caracteriza uma implementação homogênea e de diferentes tipos caracteriza uma implementação heterogênea.
A utilização de elementos de processamento diferentes entre si, e específicos a determinadas tarefas garantem uma melhor utilização da área em silício e redução no consumo de energia, devido a especialização destes elementos para determinada aplicação.
No entanto, a complexidade da organização do ponto de vista de projeto é aumentada em arquiteturas com dezenas ou mesmo centenas de processadores, em virtude de a perda de regularidade.
Além disso, o espaço de soluções para o mapeamento de tarefas é comprometido, uma vez que nem todos os elementos de processamento podem executar as mesmas operações.
Outro ponto seria a redução da modularidade (o que aumenta o tempo de projeto) e o aumento da complexidade na programação do software que executa em tais arquiteturas.
A programabilidade de tais plataformas é um fator importante a ser avalidado, sendo este um dos maiores desafios enfrentados em arquiteturas com grande número de processadores.
Em relação a o meio de interconexão, diversos trabalhos citam NoCs como o principal meio de comunicação utilizado em arquiteturas MPSoC devido a sua escalabilidade e modularidade comparado a barramentos multiponto e conexões ponto a ponto.
Os problemas enfrentados em arquiteturas baseadas em barramento tornam- se mais evidentes com o aumento do número de processadores, sendo estes o aumento de colisões de mensagens (o meio é compartilhado), limitações físicas como o aumento da carga capacitiva e redução na frequência de operação.
O emprego de NoCs contorna esses problemas pois o número de processadores é escalável do ponto de vista físico (são utilizados fios curtos e não compartilhados) e comunicações entre diferentes elementos de processamento podem ocorrer de forma paralela.
Um grande número de trabalhos utiliza arquiteturas MPSoC homogêneas por motivos práticos.
Entre as vantagens estão a diminuição do tempo de projeto, melhor modularização, maior facilidade de exploração do espaço de projeto utilizando ferramentas de alto nível, possibilidade do emprego de algoritmos mais simples para a realização do mapeamento de tarefas e reutilização da mesma arquitetura para diferentes produtos.
A organização homogênea empregada neste trabalho é caracterizada por um conjunto de elementos de processamento idênticos conectados por uma NoC com topologia malha de duas dimensões.
Definições Gerais Em este trabalho, são definidas descrições em alto nível que modelam características da arquitetura e da aplicação.
O objetivo destas descrições é simplificar a definição dos processos de mapeamento e reconfiguração de aplicações multiprocessadas no contexto do ambiente MPSoC apresentado.
É possível representar separadamente a aplicação e a estrutura aonde a mesma irá executar.
Assim, diferentes partes da plataforma podem ser enumeradas como pertencentes a duas principais categorias, sendo estas arquitetura e aplicação.
A categoria arquitetura é constituída por:·
Hardware Elementos de processamento Meio de interconexão· Software Sistema operacional A categoria aplicação é constituída por um conjunto de tarefas, onde cada uma possui as propriedades a seguir.
Basicamente, uma tarefa possui um tempo de computação e um tempo de comunicação.
Tarefas periódicas têm definido seus parâmetros de intervalo entre execuções (ou invocações), o tempo que executam entre estes intervalos e o limite de tempo para o término de execução.
Tarefas aperiódicas não possuem definição de intervalo de tempo entre suas execuções.
Em o contexto deste trabalho, tarefas periódicas possuem parâmetros de tempo real (período, tempo de execução e deadline) e as aperiódicas são tarefas de melhor esforço ou eventos externos, como interrupções por exemplo.
Não são definidas tarefas periódicas de melhor esforço no presente modelo, entretanto podem receber tal classificação tarefas que estejam perdendo deadlines.
A comunicação entre tarefas é feita por trocas de mensagem ou memória compartilhada, e que no segundo caso pode ser encapsulada por o sistema operacional (mantendo o modelo de trocas de mensagem) ou realizada diretamente por uma região de memória compartilhada e protegida por exclusão mútua.
As propriedades de uma tarefa são resumidas em:·
Computação Periódicas Tarefas de tempo real -- RT Melhor esforço -- NRT Aperiódicas Eventos -- RT Melhor esforço -- NRT· Comunicação Trocas de mensagem Memória compartilhada Diretamente por exclusão mútua Encapsulada por o sistema operacional A arquitetura de hardware é formada por uma série de nodos compostos por um elemento de processamento com uma interface de rede e um roteador da NoC.
Em cada processador, uma instância de sistema operacional é executada (arquitetura de software), e cada sistema operacional gerência uma ou mais tarefas da aplicação.
As tarefas fazem uso de serviços fornecidos por o sistema operacional.
Os nodos conectados em rede, formando uma malha de duas dimensões compõem a arquitetura.
A Figura 4.1 apresenta um exemplo de tal arquitetura, separando os elementos de hardware e software.
A aplicação é constituída por um conjunto de tarefas distribuídas entre nodos da rede.
Estas tarefas podem realizar determinado processamento e comunicar entre si localmente ou remotamente de maneira transparente.
Outras tarefas podem entrar, serem replicadas ou saírem do sistema durante o tempo de execução.
Tarefas possuem parâmetros que serão detalhados adiante, e podem executar num mesmo elemento de processamento, compartilhando recursos como tempo de processador e acesso ao meio de interconexão.
O modelo proposto faz a utilização de grafos para representar características tanto da arquitetura quanto da aplicação mapeada na mesma.
Este modelo será apresentado na Seção 4.5.
Apenas as tarefas necessárias para a inicialização da aplicação precisam estar mapeadas antes da execução do sistema, uma vez que mecanismos de mapeamento dinâmico e migração de tarefas fornecidos por o sistema operacional podem ser utilizados para reconfigurar a aplicação em tempo de execução.
Definição do Problema Diversos trabalhos apresentam soluções para o mapemento de aplicações de maneira estática.
Embora sejam estas soluções ideais para aplicações que possuam um comportamento conhecido em tempo de projeto, o mesmo não é verdadeiro para aplicações que variam suas características durante o tempo de execução.
Outro caso seria o de sistemas que permitem a inclusão dinâmica de aplicações.
Para estes, soluções que possibilitam a realização do mapeamento dinamicamente apresentam melhores resultados.
A variação do perfil da aplicação durante sua execução pode acarretar em problemas como perdas dos deadlines, saturação dos canais na rede e até problemas térmicos.
De essa forma, mecanismos de reconfiguração dinâmica podem reduzir estes problemas e garantir, ou pelo menos melhorar, o tempo de resposta em sistemas desta natureza.
Em o contexto desse trabalho, é realizado um mapeamento de tarefas iniciais de maneira estática (em tempo de projeto).
O sistema operacional que executa nos elementos de processamento provê serviços para mapear dinamicamente tarefas no sistema, através de primitivas para a criação e replicação de tarefas.
Além disso, este monitora periodicamente as características das tarefas que estão em execução.
Caso ocorram variações sensíveis em suas características, diferentes ações podem ser tomadas.
Um mecanismo de gerência presente em cada elemento de processamento observa o perfil de execução local e em caso de necessidade procura migrar tarefas de acordo com os recursos disponíveis em nodos vizinhos.
Antes de maiores detalhes, no entanto, serão apresentados os modelos propostos.
Modelo Proposto Aplicação O modelo de aplicação proposto é composto por um conjunto de tarefas que executam em elementos de processamento da arquitetura.
Cada tarefa possui parâmetros individuais apresentados a seguir, além de seu código e dados que implementam sua funcionalidade.
Uma tarefa é definida por uma n-upla i $= idi, uidi, pi, ei, di, lci, pwri, cdi, dti, ctxi\&gt; sendo idi sua identificação local, uidi sua identificação única, pi seu período;
Ei o tempo de execução ou capacidade no período; Di seu deadline;
Lci o volume de dados gerado por o envio de mensagens; Pwri o consumo de energia médio;
Cdi o tamanho do segmento de código, dti o tamanho do segmento de dados e ctxi o seu contexto.
Os parâmetros pi, ei e di são regidos por uma política de escalonamento de tempo real e descritos numa unidade de tempo abstrata, denominada tick 1.
Algumas dessas políticas estão descritas em.
Os parâmetros pwri, cdi e dti são dependentes de tecnologia, compilador utilizado e algoritmo, e precisam ser posteriormente caracterizados.
Cada tarefa i é preemptiva e gera jobs a cada pi ticks, sendo que estes jobs possuem um tempo de execução ei que precisa ser completado antes do próximo período para que não ocorram perdas de deadline.
O overhead em virtude de trocas de contexto e algoritmo de escalonamento são incluídos no tempo de execução da tarefa, afetando seu progresso de execução de maneira proporcional.
Cada tarefa, a qual executa de acordo com o modelo de tarefas, é atribuída a um único nodo, e cada nodo pode executar uma ou mais tarefas que compartilham tempo de processador de acordo com os parâmetros citados anteriormente.
O conjunto de tarefas a ser executado nos nodos que compõem a arquitetura implementam a aplicação multiprocessada.
Diversas aplicações podem executar numa mesma arquitetura, compartilhando recursos.
Como cada nodo possui um escalonador de tarefas local, são utilizadas duas identificações para uma mesma tarefa sendo idi sua identificação local, que indica um índice numa lista de tarefas e apenas é relevante no contexto do nodo em que determinada tarefa executa e uidi sua identificação única ou global.
Tarefas podem não ter especificados seus parâmetros pi, ei e di, e neste caso são definidas como tarefas de melhor esforço.
Este tipo de tarefa executa aperiodicamente, e somente quando houver tempo de processamento livre, ou seja, o tempo de processamento é inicialmente reservado às tarefas de tempo real.
Tarefas de melhor esforço compartilham o tempo livre entre si, e são escalonadas com um algoritmo rotativo, onde cada uma executa por um tick.
Em virtude de a reserva para as tarefas de tempo real, tarefas de melhor esforço podem ter postergada sua execução indefinidamente.
O acesso a recursos compartilhados (regiões críticas) são mutualmente exclusivos por natureza.
De essa forma, o acesso precisa ser serializado.
Primitivas de sincronização como semáforos e mutexes. Apesar de as tarefas serem preemptivas no presente modelo, em virtude de o compartilhamento de recursos tarefas podem ser bloqueadas por outras de menor prioridade (problema da inversão de prioridade).
Este é um problema que deve ser resolvido em nível de aplicação ou com a utilização de mecanismos que fogem ao escopo do presente trabalho.
Definição. O modelo de tarefas proposto assume que:
As tarefas podem ser periódicas (tarefas de tempo real) ou de melhor esforço;
o deadline relativo de uma tarefa de tempo real é igual ao seu período;
As tarefas que compõem diferentes aplicações são independentes, ou seja, não possuem precedência;
Tarefas podem ser inicialmente mapeadas num determinado elemento de processamento e posteriormente realocadas; Tarefas podem entrar e sair do sistema a qualquer momento.
Tick é considerada a unidade mínima de escalonamento. Todos os parâmetros de tempo real são representados com ticks, e o próprio tick possui um valor de tempo determinado.
A comunicação entre tarefas é representada por a tupla cij $= j, ij\&gt;, onde j é a tarefa alvo e ij o volume de dados gerado especificamente para a tarefa alvo.
Como a soma dos dados transmitidos por uma tarefa é composto por uma ou múltiplas comunicações (sendo esta uma lista de comunicações), o total de dados enviado por a tarefa geradora do tráfego é representado por lci, assumindo n como sendo o número de comunicações:
O processo de realocação de tarefas a diferentes nodos em tempo de execução é referenciado como migração no contexto deste trabalho.
Tarefas podem ser migradas de um nodo. Este tipo de informação é armazenada no contexto da tarefa.
Arquitetura A arquitetura proposta é composta por elementos de processamento conectados através de filas a uma rede-intra-chip (NoC) com estrutura regular numa malha de duas dimensões, roteamento determinístico XY e chaveamento de pacotes utilizando o método wormhole.
Com o intuito de facilitar a validação e prototipação, além de os motivos anteriormente citados, será utilizada uma arquitetura homogênea composta por processadores simples2.
O modelo, no entanto, é genérico o suficiente para incorporar parâmetros necessários para a representação de plataformas MPSoC heterogêneas.
A modelagem de ambientes MPSoC heterogêneos, no entanto, foge ao escopo do presente trabalho.
As características de um nodo da arquitetura são representadas por a n-upla µm $= ctm, fm, lm, ntm, spm, om, msm, iqm, oqm, vm\&gt; sendo ctm o tipo de processador;
Fm a frequência; Lm a carga de processador resultante dos parâmetros das tarefas que executam no mesmo;
Ntm o número de tarefas presentes; Spm a política de escalonamento utilizada por o sistema operacional;
Om o overhead do sistema operacional; Msm o tamanho da memória de programa e dados (em bytes);
Iqm o tamanho da fila de entrada da interface de rede, oqm o tamanho da fila de saída da interface de rede (ambas as filas tem seu tamanho especificado nodos m e n originados em m..
Para cada canal de comunicação3 originado no nodo, seus parâmetros são representados por a tripla vmn $= µn, dvmn, hmn\&gt;, sendo µn o processador alvo, dvmn volume de dados transmitido e hmn o número de saltos entre os nodos utilizando o roteamento XY.
O volume de dados transmitido por o nodo num determinado canal de comunicação é constituido por a soma de lci de todas as tarefas de m que transmitem dados para um mesmo nodo n destino:
Processadores que implementam um conjunto de instruções regular, não possuem cache nem mecanismos de gerência de memória em hardware como uma unidade MMU.
Entende- se por canal de comunicação um caminho virtual estabelecido entre dois nodos, de forma que entre eles esteja ocorrendo troca de mensagens.
O mapeamento dos elementos de processamento a tiles 4 é feito de maneira estática no contexto deste trabalho, uma vez que os elementos de processamento são idênticos e o efeito do mapeamento e agrupamento de tarefas é realizado em nível de aplicação.
Representações em Alto Nível Grande parte dos trabalhos na área utilizam grafos para descrever diferentes aspectos da aplicação e da arquitetura.
Esta representação mostra- se dessa forma natural, e será utilizada para descrever o modelo proposto.
As representações em alto nível apresentadas a seguir são descritas por grafos direcionados.
Aplicação -- O Modelo ATM Em o modelo de tarefas da aplicação, ou ATM uma aplicação é representada por um grafo ATG $= G (T, C) composto por um conjunto de tarefas.
As tarefas são representadas por vértices 1 a n e a comunicação entre as mesmas por arestas cij.
Cada elemento de processamento pode executar múltiplas tarefas, o que permite que as mesmas se comuniquem tanto localmente como remotamente (realizando acesso ao meio de interconexão).
Essas tarefas possuem parâmetros individuais, sendo esses identificação local e global, período, capacidade, deadline, lista de comunicações, consumo de energia e tamanho dos segmentos de código e dados e seu estado, descritos na Figura 4.2.
Os parâmetros mandatórios descritos nos vértices são a identificação local e global, o período a capacidade e deadline.
Cada tarefa é representada por um vértice e uma identificação da legenda é utilizada para descrever detalhadamenete seus parâmetros, incluindo a caracterização se necessário.
Entre tarefas comunicantes existem arestas, onde é representada a direção da comunicação, bem como o volume de dados enviado por a tarefa de origem.
O mapeamento inicial é apresentado por o isolamento de tarefas em grupos, não sendo sua representação obrigatória.
Esta representação também é utilizada para descrever o funcionamento dos protocolos de comunicação, mapeamento e migração propostos, omitindo- se detalhes como parâmetros das tarefas e volume de dados.
Em este trabalho, tile é uma posição arbitrária na rede de interconexão onde é posicionado fisicamente um elemento de processamento.
O grafo de tarefas da aplicação, ou ATG é utilizado para representar o modelo, descrevendo tanto a aplicação como a comunicação existente entre tarefas, e parâmetros individuais de execução e caracterização de cada tarefa.
Formalmente, o ATG é definido como:
Definição. Um grafo de tarefas da aplicação é um grafo dirigido representado por o par da aplicação e o conjunto de arestas representa as comunicações entre tarefas.
Define- se idi a identificação local, uidi a identificação única, pi o período da tarefa, ei a capacidade da tarefa, onde ei pi, di o deadline, onde ei di, pwri o consumo de energia, dti o tamanho do segmento de dados, cdi o tamanho do segmento de código e ctxi seu contexto.
Sendo ijq a quantidade de dados da mensagem de índice q (mq) que são enviados da tarefa i para a tarefa j, e sendo kij o total de kij mensagens enviadas de i para j, então ij $= q $= 1 ijq é o volume de dados enviado de i para j.
O volume de dados originado da tarefa i é lci $= i $= 1 ij, onde n é o número de comunicações da tarefa.
Cada vértice i T é uma tupla i $= idi, uidi, pi, ei, di, lci, pwri, cdi, dti, ctxi.
Cada aresta cij C é uma tripla cij $= i, j, ij, tal que i $= j e ij\&gt; 0.
Arquitetura -- O Modelo ACCM O modelo de comunicação e computação da arquitetura, ou ACCM é apresentado a seguir.
Em este modelo, o grafo ACCG $= G (N, L) é utilizado para representar características da arquitetura de hardware e software e a topologia da rede de comunicação.
O modelo apresenta as configurações dos nodos e sua posição, além de o volume de dados que trafega entre os enlaces da rede.
Os nodos são representados no grafo ACCG por vértices µ1 a µc e a comunicação por tvkl formado por a soma do volume de dados vm de todos os nodos que possuem seu tráfego direcionado por o mesmo caminho.
Em os vértices são representadas informações como carga, número de tarefas, política de escalonamento, tipo de processador empregado, frequência de operação, tamanho da memória e tamanho das filas entre elementos de processamento e roteadores e volume de dados total originado por o nodo.
Em a Figura 4.4 são apresentados os parâmetros que caracterizam a configuração de nodos e a informação sobre o volume de dados.
O grafo de comunicação e computação da arquitetura, ou ACCG é utilizado para descrever o modelo, representando uma arquitetura como a comunicação existente entre nodos e parâmetros individuais de cada nodo.
Formalmente, o ACCG é definido como:
Cada aresta tvkl L é composta por a soma dos volumes de dados vmn vm que atravessam o enlace representado por a aresta.
A Figura 4.5 apresenta uma arquitetura exemplo composta por seis nodos dispostos numa topologia malha 3x2.
Em o exemplo, os volumes de dados que transitam nos enlaces são tv12 $= 200, tv21 $= 50 e tv25 $= 300.
A configuração dos nodos é µ1 $= MIPS, 25, 0.5, 4, RM, 0.005, 32768, 64, 200, µ2 $= MIPS, 25, 0.6, 3, RM, 0.005, 32768, 64, 200 e µ5 $= MIPS, 25, 0.2, 4, RM, enlace tv25 é 300 e como v2 $= 200, supõem- se que 150 bytes do volume de dados enviado por µ2 são direcionados ao nodo µ5, e os outros 50 são enviados a µ1.
µ1, por sua vez, envia 150 bytes a µ5 e 50 bytes a µ2.
Uma representação semelhante é apresentada por Murali.
Em o presente trabalho, no entanto, outros aspectos da arquitetura são mostrados no grafo ao invés de a largura de banda disponível entre os enlaces.
De essa forma, a semelhança entre as representações restringe- se ao formato da topologia.
Comunicação Entre Tarefas O modelo proposto assume que o conjunto de tarefas que compõem a aplicação, assim como suas características, podem ser modificadas durante sua execução.
De essa forma, não é possível realizar a comunicação direta entre tarefas não fixas sem o conhecimento de sua localização.
O processo de criação ou mapeamento de tarefas é gerenciado por o sistema operacional, e novas tarefas podem entrar e deixar o sistema em tempo de execução, modificando o mapeamento inicial.
Para contornar este problema, assume- se uma tarefa de controle de comunicação em cada nodo, a qual possui uma identificação conhecida.
Esta tarefa não pode ser removida nem migrada para outro nodo, pois é essencial para que o sistema de comunicação entre tarefas que migram entre nodos funcione adequadamente.
Inicialmente, uma tarefa que deseja se comunicar com outra utiliza a informação sobre a posição da tarefa destino baseando- se na informação conhecida sobre o mapeamento inicial, obtido em tempo de projeto.
Esta informação é armazenada numa referência local.
Supõe- se que pelo menos uma das tarefas comunicantes seja não fixa neste caso.
Antes de comunicar diretamente com a tarefa destino, no entanto, a tarefa de origem verifica se a tarefa destino encontra- se no mesmo processador.
Em este caso, a comunicação é feita diretamente.
Se o destino não for local, a tarefa envia uma solicitação à tarefa de controle do nodo remoto.
Caso a tarefa destino esteja neste nodo, a tarefa de controle de comunicação responde com esta informação.
Caso contrário, a tarefa controle responde informando para onde a outra foi migrada.
Todas as tarefas que deixam um nodo são adicionadas a uma lista deste nodo, pesquisada a cada solicitação.
Caso uma tarefa migrada anteriormente retorne ao nodo, esta é removida da lista.
Com a informação sobre a nova posição da tarefa destino, a tarefa origem tenta se comunicar novamente, realizando uma pergunta à tarefa de controle do novo nodo.
O processo se repete até que a tarefa de origem encontre a tarefa destino, e possa se comunicar diretamente com a mesma.
A comunicação entre tarefas é gerenciada por o sistema operacional.
Tarefas comunicantes apenas realizam chamadas a primitivas sobre as primitivas de comunicação serão apresentados no Capítulo 5.
Request, t4 ack n2 t3 t2, n3 t2 t3, n1 t3 t2, n1 t2 t1, n1 t1 nack, t4 request, t3 Task:
A Figura 4.6 apresenta o protocolo de comunicação.
Em o exemplo, a tarefa n1 t3 deseja comunicar com n2 t3.
Para isso, envia um request µ2, t3 ao nodo µ2.
A tarefa de controle em µ2 verifica a lista de tarefas migradas, e responde nack, µ3, t4 a n1 t3.
A seguir, n1 t3 solicita a comunicação com n2 t3 à tarefa de controle de µ3 realizando um request µ3, t4.
O controle verifica a lista de tarefas migradas, e como não encontra a tarefa solicitada responde a n1 t3 com ack, n2 t3.
A o receber a informação, n1 t3 atualiza sua informação local sobre a tarefa remota e comunica- se diretamente com n2 t3.
Caso venha a se comunicar com n2 t3 novamente, a tarefa n1 t3 realiza um request µ3, t4 diretamente a µ3.
A identificação local da tarefa é utilizada para que tarefas que executam num mesmo nodo possam se comunicar diretamente, já a identificação global possibilita uma identificação única de qualquer tarefa do sistema, além de diferenciar tarefas migradas de outros nodos de tarefas originalmente mapeadas localmente.
De a mesma forma que tarefas migratórias são mantidas numa lista, tarefas excluídas também são mantidas nesta, juntamente com a informação de exclusão.
Caso ocorra uma solicitação à uma terefa excluída naquele nodo, a tarefa de controle informa a origem.
Tarefas que iniciam a comunicação também podem ser migradas para outros nodos.
Em este caso, o processo de comunicação acontece da mesma forma.
Juntamente com a mensagem, é sempre enviada a informação sobre a origem da mesma, identificando a tarefa de origem no destino.
Caso a tarefa que iniciou o processo de comunicação seja migrada, a tarefa destino automaticamente recebe esta informação na próxima comunicação.
Durante a execução do protocolo, ou seja, do início (solicitação da tarefa) até o envio propriamente dito, a tarefa de origem não pode ser migrada, permanecendo fixa no mesmo processador.
De a mesma forma, ao receber uma requisição à uma tarefa local, a tarefa de controle não permite que a mesma seja migrada até que a comunicação tenha sido concluída.
Detalhes sobre o protocolo de migração serão apresentados na Seção 4.9.
Caso as tarefas comunicantes sejam fixas, ou seja, foram configuradas para que não sejam migradas, a comunicação entre as mesmas é estabelecida diretamente, pois sua localização é conhecida já em tempo de projeto.
Este mecanismo de comunicação direta é essencial para a implementação do protocolo de comunicação descrito nesta Seção.
A comunicação entre tarefas ocorre dentro de o tempo de execução de cada tarefa, ou seja, assume- se que a comunicação possui tempo de processamento e faz parte da tarefa.
Assim, uma tarefa pode ser preemptada a qualquer momento por o sistema operacional durante sua comunicação e continuar o processo no seu próximo período.
Tarefas de melhor esforço, as quais não possuem parâmetros de tempo real, executam sempre que houver tempo de processamento livre, e compartilham este tempo entre si.
Escalonamento de Tarefas Em a literatura são encontradas diversas propostas para a realização do escalonamento de tarefas em sistemas de tempo real.
Entre os algoritmos mais utilizados estão o First Come First Served (FCFS), Round Robin (RR), Rate Monotonic (RM), Deadline Monotonic (DM), Least Laxity First (LLF) e Earliest Deadline First (EDF).
A política empregada no modelo proposto é o algoritmo Rate Monotonic, onde tarefas com períodos menores possuem prioridade sobre outras tarefas.
Esta política, no entanto, não garante que todas as tarefas serão executadas obedecendo restrições temporais caso o conjunto não seja escalonável.
Detalhes sobre o teste de escalonabilidade empregado são descritos na Seção 4.10.
Em a Figura 4.7 é apresentado o escalonamento de três tarefas com os parâmetros pi, ei e di sendo respectivamente 1 $= 14, 4, 14, 2 $= 16, 4, 16 e 3 $= 40, 7, 40.
As tarefas de maior prioridade, no caso com menor período, sempre preemptam as de menor prioridade.
A ocupação do processador para o exemplo apresentado é de 71% e de acordo com a política RM, este conjunto de três tarefas é escalonável.
Mapeamento Dinâmico O mapeamento é uma função que define a posição das tarefas nos recursos da arquitetura.
A qualidade do mapeamento influência diretamente no desempenho da aplicação, pois congestionamentos e sobrecargas advindos de um mapeamento ruim comprometem a execução de suas tarefas, subutilizando recursos.
Mapeamento Estático Inicial O mapeamento inicial das tarefas da aplicação é definido em tempo de projeto.
Este mapeamento pode ser feito manualmente, ou automatizado com o intuito de maximizar a função de custo do mapeamento, onde o custo é definido como consumo de energia, tempo de processamento, ocupação dos canais na rede de comunicação, número de saltos entre nodos, entre outros.
Em este trabalho, as tarefas iniciais são atribuídas a nodos manualmente, sendo necessário o conhecimento prévio do grafo que descreve a aplicação em seu estado inicial.
Segundo, o tempo de mapeamento estático não é crítico quando comparado ao tempo de mapemento realizado em tempo de execução.
Assim, o tempo de mapeamento em sistemas dinâmicos deve ser considerado, uma vez que impacta diretamente no desempenho da aplicação.
O problema do mapeamento é Np-completo e mesmo em tempo de projeto pode ser proibitivo, o que motiva utilização de heurísticas com o intuito de reduzir este tempo.
Em os sistemas que possuem um conjunto fixo de tarefas, técnicas de mapeamento estático são utilizadas com o intuito de otimizar o custo do mapeamento.
Este mapeamento inicial é realizado sobre todas as tarefas do sistema, ou seja, as tarefas e os seus parâmetros são definidos em tempo de projeto.
Em o modelo proposto, novas tarefas podem ser adicionadas, destruídas, replicadas ou terem seus parâmetros modificados em tempo de execução.
Assim, técnicas de mapeamento estático tendem a ser pouco eficientes do ponto de vista de custo do mapeamento para aplicações dinâmicas, uma vez que este custo varia de acordo com o perfil da aplicação.
Outro aspecto é o tempo de execução de heurísticas comumente utilizadas para a realização do mapeamento estático, que em cenários dinâmicos tornam- se impraticáveis.
O emprego de heurísticas estáticas para o mapeamento inicial não é invalidada por o comportamento dinâmico da aplicação, pois no modelo proposto parte das tarefas podem ser confinadas a posições fixas.
Além disso, não existe um conhecimento prévio sobre o perfil de execução da aplicação, e a melhor escolha é sem dúvidas tomar a melhor decisão possível sobre o mapeamento já em tempo de projeto, e otimizar a aplicação dinamicamente de acordo com as variações no perfil da aplicação.
Vale ressaltar que além de tarefas configuradas como fixas, as tarefas iniciais da aplicação necessariamente precisam ser mapeadas estaticamente.
Repositório Local de Tarefas O trabalho aqui apresentado propõe além de instâncias distribuídas de um sistema operacional em cada nodo, a utilização de repositórios locais de tarefas.
A idéia é, em tempo de projeto definir grupos de tarefas (particionamento) e associar- los a repositórios.
Cada instância do sistema operacional é responsável por a gerência de seu próprio repositório, descentralizando o controle e permitindo dessa forma uma gerência de maneira distribuída.
O modelo proposto difere de trabalhos como, os quais utilizam um único repositório numa memória centralizada e um mecanismo de paginação que faz a utilização de código não relocável.
O modelo proposto neste trabalho, no entanto, não possui a limitação imposta por o tamanho de páginas ou código, o que permite uma melhor utilização da memória uma vez que esta é alocada em segmentos e dinamicamente.
Uma única região de memória dividida em segmentos existe em cada nodo, e dessa forma a fragmentação interna é minimizada.
Mapeamento de Tarefas e Variação de Carga Em este trabalho, o mapeamento dinâmico das tarefas é feito por a criação ou replicação de tarefas num nodo da arquitetura.
A o ser mapeada (o que pode ser feito a partir de uma tarefa já mepada) uma tarefa é configurada com os parâmetros descritos na Seção 4.4 e mapeada localmente.
Diferentemente de outros trabalhos propostos na literatura, os quais utilizam diversas heurísticas para mapear tarefas dinamicamente, o presente trabalho aproxima o modelo de tarefas e seu mapeamento a conceitos de sistemas operacionais clássicos.
O mecanismo de migração é utilizado para modificar esse mapeamento de tarefas em tempo de execução, obtendo uma funcionalidade semelhante ao mapeamento dinâmico empregado em trabalhos relacionados.
Outros trabalhos como utilizam o conceito de migração de tarefas como proposto neste trabalho.
O evento de criação, replicação ou modificação de tarefas altera o cenário inicial sobre a utilização do sistema, usado como referência para a realização do mapeamento inicial.
Algumas vezes, um nodo em questão não possui recursos disponíveis para mapear e executar uma tarefa e é criada uma situação de sobrecarga.
O efeito da sobrecarga, considerando o modelo proposto, torna o conjunto de tarefas não escalonável e faz com que a aplicação perca seu critério de tempo real.
Outra situação é a saturação e contenção dos canais de comunicação da rede originado de fluxos de dados de novas tarefas.
Ainda, uma nova tarefa comunicante pode ser mapeada a uma grande distância em saltos na rede, o que faz com que seu fluxo de dados percorra muitos enlaces e ocupe recursos de maneira não otimizada.
Em o exemplo apresentado na Figura 4.8, dois nodos µ1 e µ2 possuem três tarefas em seu mapeamento inicial.
Os parâmetros especificados das tarefas são idi, uidi, pi, ei e di.
O e 78% respectivamente nesta configuração Figura 76 $= 100 e gera outro volume 67 $= 300 de n2 t3.
A carga do nodo µ2 sobe para 98% após o mapeamento da tarefa, deixando- o numa situação de sobrecarga.
O último passo) consiste em migrar a tarefa n2 t4 para o nodo µ1, distribuindo o processamento.
A carga dos nodos nesta configuração é de 78%.
São três as possíveis situações que incidem numa situação de sobrecarga:
Uma tarefa de tempo real já mapeada tem seus parâmetros alterados, aumentando sua prioridade e consequentemente seu uso de processador ou seu uso da rede;
Uma nova tarefa é mapeada, aumentando a carga de processamento ou uso da rede além de o limite imposto e;
Uma tarefa já mapeada é replicada e é ultrapassado o limite de utilização da rede ou processamento.
Migração de Tarefas O processo de migração de tarefas ocorre em diversas etapas, e pode ser realizado por um gerente de migração ou por uma tarefa qualquer local, desde que não seja ela mesma (uma tarefa O cálculo da carga (ou fator de utilização) é apresentado da Seção 4.10.
O controle de recursos de cada nodo é mantido por gerentes de migração distribuídos e é detalhado na Seção 4.10.
De essa forma, o processo de migração por si só não realiza nenhum tipo de controle de recursos como utilização de processador e ocupação dos canais, e apenas falha caso o nodo destino não consiga mapear a tarefa migrada por não possuir memória livre ou a tarefa possuir comunicações pendentes não resolvidas dentro de um tempo pré-determinado.
O protocolo de troca de mensagens automaticamente resolve as dependências entre tarefas comunicantes após migrações, pois garante que exista uma referência local atualizada sobre determinada tarefa antes que uma mensagem propriamente dita seja enviada.
Tarefas comunicantes podem possuir um atraso no processo de migração até que comunicações pendentes sejam resolvidas.
Em este caso, o mecanismo de migração libera a tarefa a ser migrada para que esta conclua comunicações pendentes e não permite que novas comunicações sejam realizadas, postergando respostas a solicitações para trocas de mensagem para esta tarefa.
A migração de tarefas consiste nos seguintes passos, apresentados na Figura 4.9, onde os passos 1 a 4 são descritos em 4.9 (a), os passos 5 a 9 em 4.9 (b) e o passo 10 em 4.9 (c):
o código da tarefa é enviado ao nodo destino;
A tarefa que está sendo migrada é bloqueada;
Os dados da pilha são enviados;
O contexto da tarefa é enviado;
O código é relocado no nodo destino;
É realizado o mapeamento no nodo destino;
A tarefa tem seu contexto restaurado;
O nodo destino responde sobre o estado da migração, juntamente com a identificação local da nova tarefa;
A tarefa é excluída no nodo origem;
A identificação da tarefa no nodo destino é adicionada a uma lista de tarefas migradas local.
Block task, n1 t1 send.
Code n1 t3, n2 t1 send.
Data. Context n1 t3, n2 t1 n1 t3, n2 t1 t3, n1 t3 t1, n2 t1 t2, n2 t2 (a) t1, n2 t1 t1, n1 t1 ack n1 t3, t3 t2, n1 t2 t2, n2 t2 Task:
A tarefa de controle de comunicações é responsável por receber, mapear e restaurar o contexto da tarefa migrada, além de notificar a origem sobre o estado da operação.
Esta tarefa também é responsável por manter atualizada a lista de tarefas migradas, atender a solicitações de mensagem e resolver conflitos no caso de comunicações pendentes.
Como citado anteriormente, esta tarefa possui uma posição fixa, e não pode ser migrada.
São realizadas quatro trocas de mensagem entre nodos para a execução do protocolo, e outras mensagens internas a cada nodo são feitas por memória compartilhada e encapsuladas por o sistema operacional.
As trocas de mensagem compreendem o envio do código, dados e contexto, e recebimento do estado da migração (sucesso ou falha) envidado por o destino.
O tempo para a realização do processo não é desprezível, uma vez que a tarefa a ser migrada fica bloqueada durante a execução do protocolo.
Este tempo de migração varia de acordo com a tarefa, a quantidade de dados armazenado na pilha da mesma e seu número de comunicações.
Em o nodo destino o processo de migração ocorre de acordo com os parâmetros da tarefa de controle de comunicações, executando no seu tempo e não interferindo no atual conjunto de tarefas que executa no nodo.
Em o nodo origem, o protocolo executa dentro de o tempo da tarefa que invoca a migração, e caso esta tarefa seja o gerente, o restante das tarefas continua executando normalmente.
Gerência de Migração A gerência de migração é utilizada para controlar a forma como o sistema deve proceder com relação a modificações em seu perfil de execução.
O mecanismo de gerência é responsável por avaliar o estado do sistema e realizar decisões de migração.
Algumas das funções de custo utilizadas em trabalhos da literatura são:
Utilização dos elementos de processamento;
Ocupação dos canais da rede;
Número de saltos;
Consumo de energia;
Entre outros.
Em este trabalho propõe- se a utilização de uma abordagem distribuída, isto é, cada nodo possui um gerente de migração local.
Este gerente local possui os mesmos atribuitos de uma tarefa de tempo real e comunica- se com outros gerentes diretamente.
A Figura 4.10 apresenta um exemplo que emprega gerentes distribuídos.
Em o exemplo, uma malha 3x2 é utilizada, onde a tarefa de controle de comunicação, a gerência de migração local (T2) e as tarefas de usuário executam no mesmo ambiente.
Ainda, ambas compartilham os serviços fornecidos por a camada inferior, composta por o sistema operacional, elementos de processamento e rede de interconexão.
Definição. Um determinado nodo é considerado sobrecarregado quando ui\&gt; uli ou tvi\&gt; fbwi.
Em o modelo de tarefas proposto, é assumido que os parâmetros pi e di da política de escalonamento são iguais e dessa forma ui $= li.
O fator de utilização, no entanto, pode ser avaliado independentemente da política de escalonamento como indicador do estado (normal ou sobrecarregado) do nodo.
Cada política de escalonamento possui um limite de utilização específico, e esse limite pode variar ainda de acordo com o número de tarefas presentes no sistema.
Para o algoritmo RM, o qual possui prioridade fixa, esse limite é definido por:
O processo de gerência e migração possui um custo que está relacionado às decisões de migração (algoritmo de gerência), transferência do código, parada da tarefa a ser migrada, transferência de seus dados, reinicio da tarefa no nodo destino e resposta ao nodo origem.
O custo da gerência de migração é representado por:
Onde representa o tempo para a execução do algoritmo de gerência no nodo origem e trocas de mensagem com nodos vizinhos (candidatos), o tempo para a transferência dos segmentos de dados, código e contexto da tarefa e o tempo para o reinício da tarefa e resposta à origem.
O custo do processo deve ser avaliado como sendo parte do tempo de execução da tarefa a ser migrada de forma que ei+ i pi para que os deadlines da tarefa sejam respeitados.
Além disso, torna- se necessária a avaliação da taxa de utilização no nodo destino tal que uk ulk para que todos os deadlines sejam respeitados, onde:
Além de os parâmetros citados, deve ser observada a quantidade de memória disponível no nodo destino para que este possa receber a tarefa a ser migrada e que a largura de banda disponível comporte a tarefa tal que vi fbwk.
A quantidade de memória disponível é especificada por fmk, e é definida por:
Ou seja, a memória disponível fmk é obtida a partir de a subtração entre o valor do tamanho de memória total e a soma de todos os segmentos de dados e código de todas as tarefas presentes no elemento de processamento em conjunto com o tamanho dos segmentos do sistema operacional.
Caso a tarefa possua uma quantidade de dados e código maior que a memória disponível no elemento de processamento destino, a migração não poderá ocorrer.
Sendo i a tarefa a ser migrada e k o processador destino, o teste resume- se a:
A largura de banda disponível no roteador destino pode ser apenas aproximada, uma vez que é difícil realizar o cálculo de todos os fluxos de dados que trafegam por o roteador em questão.
Para avaliar esta condição, faz- se necessário calcular a largura de banda disponível no nodo destino:
Fbwk $= bwk -- tvk A largura de banda disponível deve ser tal que fbwk vi, para que a tarefa possa migrar para o nodo destino sem prejudicar a comunicação das tarefas remotas do nodo e de outros que possuam comunicações que utilizam enlaces vizinhos e fazem parte do caminho de comunicação de vi a partir de o nodo destino.
Gerentes Distribuídos Conforme citado anteriormente, cada nodo possui um gerente de migração local no modelo proposto.
A solução proposta tem como objetivo melhorar o estado global do sistema de maneira progressiva, sem ter no entanto um custo elevado do ponto de vista computacional (solução greedy incremental).
Algumas das decisões realizadas por o gerente, como a escolha da tarefa a ser migrada e o nodo alvo da migração podem ser realizadas de acordo com diversas heurísticas.
A escolha da tarefa a migrar pode levar em consideração parâmetros como utilização do processador por a tarefa, número de comunicações, volume de dados, número de saltos ou simplesmente uma escolha randômica.
Outras decisões são a busca por candidatos de migração e a escolha do nodo alvo.
Entre as heurísticas utilizadas para realizar a seleção estão os algoritmos Nearest Neighbor (NN), First Free (FF) e heurísticas que avaliam o volume de dados e contenções na rede como o Minimum Maximum Channel Load (MMCL), Minimum Average Channel Load (MACL), Path Load (PL) e Best Neighbor (BN).
As funções de custo podem levar em consideração diferentes fatores como a carga de processamento livre, memória disponível, proximidade em saltos na rede, ocupação dos canais e alcançabilidade.
A Figura 4.11 apresenta um exemplo, onde um nodo sobrecarregado utiliza um método semelhante as heurísticas NN e BN para realizar a busca por candidatos.
O método proposto utiliza a busca por vizinhos por espalhamento.
Em este método, são enviadas mensagens para todos os vizinhos a um mesmo número de saltos de uma só vez, ao contrário de outras heurísticas propostas.
O número de vizinhos cresce a medida que o número de saltos aumenta, desde que os limites da rede não tenham sido atingidos, quando mais uma vez o seu número diminui progressivamente.
Em o exemplo apresentado, que consiste de uma malha com dimensões 6x6, um elemento de processamento encontra- se em sobrecarga.
O primeiro passo do algoritmo consiste em realizar a busca por recursos nos 4 vizinhos que encontram- se a um salto de distância.
Não havendo recurso disponível, é realizada uma busca em 8 vizinhos que estão a dois saltos sendo este o segundo passo.
Em o terceiro passo, é realizada uma busca em 10 vizinhos, e os limites da rede começam a ser atingidos a partir deste ponto.
A diferença desta estratégia comparada as estratégias NN e BN é que todos os vizinhos que estiverem a uma mesma distância em saltos são consultados de uma única vez e com suas respostas, o gerente local decide qual o melhor candidato levando em consideração não apenas a ocupação dos canais (por o número de saltos), mas também a carga de processamento e a memória disponível.
Outro ponto é que a heurística é executada em qualquer elemento de processamento sobrecarregado, e não a partir de um mestre.
Além disso, o algoritmo é executado para que posteriormente seja realizada uma migração de tarefa para outro nodo, ao invés de mapear uma nova tarefa por medida de necessidade de executar tal tarefa, como é o caso de outros trabalhos os quais utilizam a heurística para a realização do mapeamento dinâmico de tarefas.
As solicitações realizadas aos nodos candidatos são feitas diretamente a seus gerentes locais.
Estes respondem com informações como carga do nodo, número de tarefas, política de escalonamento, tráfego gerado e memória livre.
Com base nas informações de todos os candidados desta distância (um salto, por exemplo), o gerente de migração decide por a melhor opção entre todos os recursos disponíveis no passo corrente do algoritmo.
Caso não exista recurso disponível, novas solicitações são realizadas aos próximos candidados, até os limites da rede.
Caso não seja encontrado recurso disponível, o nodo permanece em sobrecarga e não apto a realizar nova busca por um tempo não determinado neste momento.
Todas as funções que realizam escolhas levam em consideração os limites impostos por as definições anteriormente apresentadas.
A única excessão refere- se ao custo da migração.
O custo de migração define o tempo em o qual a tarefa a ser migrada não irá executar.
Este custo pode ser amortizado a longo prazo após a migração para tarefas que estão perdendo deadlines, uma vez que manter estas tarefas executando em nodos sobrecarregados faz com que estas deixem de executar de acordo com seus parâmetros de tempo real.
Considerações Finais Este Capítulo apresentou os modelos de aplicação, arquitetura e protocolos para comunicação, mapeamento e migração de tarefas no ambiente em questão.
Estes modelos e protocolos foram utilizados como base para a implementação do sistema operacional Hellfire Os, apresentado no Capítulo 5.
A seguir serão apresentadas as implementações dos modelos de tarefa, gerenciamento de aplicação e arquitetura propostos no Capítulo 4.
Estas implementações foram utilizadas para validar o modelo proposto com a obtenção de resultados.
Características Gerais Em este trabalho foi desenvolvido um sistema operacional de tempo real (HellFire Os) portável e totalmente preemptivo, baseado numa arquitetura kernel monolítico, porém modular.
Este sistema operacional implementa o modelo de tarefas descrito no Capítulo 4, e atualmente possui algumas ferramentas para o desenvolvimento e simulação de aplicações embarcadas de tempo real.
O sistema operacional pode ser configurado de acordo com a aplicação a ser executada, e parâmetros como o número máximo de tarefas no sistema, tamanho de pilha das tarefas, tamanho da memória heap (pode ser alocada dinamicamente), política de escalonamento, opções para debug, logging e migração de tarefas podem ser customizados.
Essa customização permite que o tamanho da imagem binária final1 do sistema operacional seja otimizada, tornando possível a execução do sistema em arquiteturas com tamanho de memória reduzido.
Algumas das funcionalidades disponibilizadas ao desenvolvedor incluem:·
Sistema operacional preemptivo (tarefas podem opcionalmente cooperar);·
Gerenciamento dinâmico de tarefas (adicionar, remover, bloquear, resumir, alterar parâmetros,· Chamadas de sistema (informações sobre deadlines, uso de processador, memória, energia, parâmetros de tarefas, tempos de trocas de contexto);·
Diferentes políticas de escalonamento para tarefas com prioridade fixa e dinâmica;·
Exclusão mútua e semáforos;·
Mailboxes;· Alocação, liberação e gerência dinâmica de memória;·
Verificações de integridade do sistema de forma automática;·
LibC customizada;
A imagem binária final do sistema é composta por o sistema operacional e repositório local de tarefas que executam no mesmo.
Esta imagem é carregada na memória de um nodo, permitindo que após a inicialização o sistema operacional execute as tarefas.·
Biblioteca para emulação de ponto flutuante com precisão simples (com funcionalidades adicionais como conversões, cálculos de raiz quadrada e funções trigonométricas);·
Comunicação entre tarefas por trocas de mensagem ou memória compartilhada (primitivas bloqueantes e não bloqueantes);·
Migração de tarefas;·
Gerência de migração;
Periféricos são acessados através de entrada e saída mapeada em memória ou por portas de entrada e saída.
O mapa de periféricos pode ser configurado na camada de abstração de hardware (HAL) para uma solução específica de hardware, o que facilita a portabilidade do sistema operacional para outras arquiteturas.
Atualmente, existem portes para as arquiteturas MIPS (multiprocessador), x86 e ARM (monoprocessador).
A Figura 5.1 apresenta a estrutura do sistema operacional.
Todas as funções dependentes de arquitetura são implementadas na HAL.
O kernel do sistema é implementado sobre esta camada (camada 2).
Alguns device drivers de baixo nível são implementados nesta camada, onde possuem acesso privilegiado a estruturas internas do sistema e ao hardware.
Uma biblioteca reduzida de funções padrão da linguagem C (LibC), assim como a API do sistema operacional são implementadas sobre o kernel (camada 3).
Tanto as tarefas quanto o sistema operacional compartilham a biblioteca padrão, o que permite redução na utilização de memória.
As tarefas de usuário são implementadas na camada 4, e utilizam da API disponibilizada.
Em esta camada também são implementados os device drivers que executam em nível de usuário (como o controle de comunicação e gerência de migração), que possuem os mesmos parâmetros de tarefas de usuário, ou seja, são regidos por a mesma política de escalonamento.
Rotinas de tratamento de interrupção, salvamento e recuperação de contexto são dependentes de arquitetura e dessa forma foram escritas em linguagem de máquina.
Essas rotinas fazem parte da camada de abstração de hardware.
Apenas uma parte desta camada é descrita em linguagem de máquina, sendo o restante de todo o software descrito em linguagem C. É importante salientar que esta camada pode ser facilmente portada para outras arquiteturas, devido a modularidade do sistema operacional.
Os endereços dos periféricos acessíveis por software são ilustrados da Figura 5.2.
A definição destes endereços faz parte da HAL específica para a implementação dos nodos utilizados na arquitetura, que consistem em processadores Plasma modificados.
Detalhes sobre a organização interna dos nodos serão apresentados na Seção 5.8.
Um fluxo de execução básico do sistema é apresentado na Figura 5.3.
Este fluxo não apresenta estados onde tarefas são mapeadas e excluídas durante a execução entre outros detalhes, por questões de simplicidade.
O fluxo de execução é descrito a seguir.
Estruturas de dados do sistema operacional (e hardware específico) são inicializadas.
Após esta inicialização, os tratadores de interrupção são registrados e habilitados.
Em este momento, tarefas iniciais são adicionadas ao sistema e a execução é iniciada.
O sistema fica em espera até o acontecimento de um evento de interrupção.
Em este momento a rotina de serviço de interrupções é chamada, o contexto básico do processador é salvo e um tratador para a interrupção é invocado de acordo com a origem da interrupção.
Em um evento de timer, o tratador de interrupções para escalonamento é chamado, o contexto da tarefa é salvo e o escalonador é invocado.
Após o escalonamento, o contexto da tarefa escolhida é restaurado, e sua execução é continuada.
Se durante a execução de uma tarefa, a mesma abrir mão de sua fatia de tempo de processador (modo cooperativo), o tratador de interrupções para escalonamento é chamado diretamente.
Outras interrupções são tratadas da mesma maneira que interrupções de timer, entretanto não ocorre reescalonamento de tarefas.
Após a execução do kernel driver, a rotina de serviço de interrupções restaura o contexto da tarefa interrompida e sua execução é continuada.
Medidas de Escalonamento De acordo com, um sistema operacional de tempo real não é apenas definido por seu comportamento, ou seja sua política de escalonamento, mas também por suas propriedades temporais, as quais impactam na evolução da execução de um conjunto de tarefas.
Em este trabalho, a implementação do modelo de tarefas replica estas propriedades, e origina o valor do parâmetro chamado overhead do sistema operacional.
Base de Tempo Em o presente trabalho, a base de tempo é provida por um contador em hardware 2 de 32 bits, que opera na mesma frequência do elemento de processamento.
Esta base de tempo é referenciada como tick, e corresponde às unidades das medidas utilizadas nas definições dos parâmetros de tarefa descritos na Seção 4.4.
Pode- se selecionar um sinal apropriado deste contador em hardware, e a partir deste sinal obter a geração de interrupções de timer, as quais ocorrem numa inversão lógica do sinal selecionado.
De acordo com o sinal e frequência de operação, podem ser obtidos diferentes períodos de tick.
O período de tick é calculado de acordo com a fórmula, onde a é o sinal desejado do contador e freq é a frequência de operação do elemento de processamento, em hertz:
Diferentes frequências de operação e seleção de sinais do contador definem um grande conjunto de valores para o tempo do tick, permitindo ao desenvolvedor a escolha da granularidade de escalonamento adequada a uma determinada aplicação.
A Tabela 5.1 apresenta valores para tempos de tick, variando- se o sinal selecionado do contador (bit) e a frequência de operação.
Por exemplo, ao selecionar o décimo quinto bit menos significativo do contador, temos os tempos apresentados na segunda coluna da tabela, para cada frequência.
Pode ser observado que a seleção de sinais com bits de maior significância torna maior o tempo de tick, uma vez que estes são invertidos no contador em hardware com menor frequência.
A Tabela 5.2 enumera a quantidade de interrupções de timer por segundo, de acordo com a frequência de operação e sinal selecionado do contador.
Observa- se que a 100 MHz e com o sinal 15 selecionado, são geradas 3125 interrupções por segundo, o que equivale, num algoritmo de escalonamento que não reescalona a tarefa recém preemptada ao mesmo número de trocas de contexto.
Os valores de 25 MHz para a frequência de operação e sinal 18 do contador foram utilizados como padrão, o que corresponde ao período de 10.48ms entre interrupções.
Assim, são realizadas Detalhes sobre a arquitetura empregada estão descritos na Seção 5.8.
O sistema operacional Hellfire Os provê a chamada de sistema3 Os_ LastContextSwitchTime() que retorna o tempo gasto em trocas de contexto em ciclos.
Esta chamada utiliza o contador em hardware para efetuar a medição, sendo portanto independente das ferramentas de software.
Tendose o tempo gasto em trocas de contexto (dependente da política de escalonamento, implementação e compilador utilizado), o número de interrupções de timer por segundo (ticks) e a frequência de operação, o overhead pode ser calculado por:
Onde overhead é expresso por um número entre 0 e 1, tps é o número de ticks por segundo, csl é a latência (ou tempo) das trocas de contexto e freq é a frequência de operação, em hertz.
O tempo de uma troca de contexto é despendido sempre que ocorrer uma interrupção de timer.
Assim, esse custo incide sempre sobre o progresso das tarefas, uma vez que as fatias de tempo de processador são distribuídas de acordo com a política de escalonamento empregada, e o overhead é absorvido a cada tick.
A API do sistema operacional Hellfire Os é apresentada na Seção 5.6.
Como exemplo, a uma frequência de operação de 25 MHz e um período entre interrupções de 10.48ms, uma tarefa escalonada executa por aproximadamente 262000 ciclos (supondo que no período em questão a tarefa não realiza chamada por reescalonemento e a mesma seja preemptada após o término do tick).
Se for considerada uma latência de 1500 ciclos do sistema operacional4, é observado um overhead de aproximadamente 0.57%.
Interrupções do timer são utilizadas para a geração de ticks do sistema.
O seu período deve ser bem balanceado, de forma que uma fatia de tempo muito longa pode tornar o sistema pouco responsivo (e pode não honrar as restrições de tempo real) e uma fatia de tempo muito curta pode aumentar o overhead do sistema operacional.
Implementação do Modelo de Tarefas Uma tarefa é definida por os parâmetros descritos na Seção 4.4.
Essencialmente, o sistema de uma tarefa é definido como um bloco de código em linguagem C, implementado por uma função pode ser entendida como uma função que itera infinitamente, mas pode ser interrompida a qualquer momento por o sistema operacional (a tarefa é preemptada) e ter sua execução continuada posteriormente.
O escalonamento de tarefas pode utilizar diversas políticas, conforme descrito na Seção que o sistema operacional escolha outra tarefa para execução.
A Figura 5.4 apresenta um exemplo de implementação, mostrando de maneira geral como uma tarefa é organizada.
Variáveis locais são declaradas no corpo da tarefa, e armazenadas em sua pilha.
O código de inicialização é um segmento de código que executa apenas uma vez, não sendo seu uso mandatório (pode ser utilizado, no entanto, para inicializar estruturas de dados da tarefa).
O verdadeiro código da tarefa executa num laço infinito.
Cada tarefa do sistema encontra- se num dos seguintes estados:
Pronta, executando, bloqueada, esperando e não executou ainda.
A tarefa é considerada pronta quando a mesma foi preemptada por o sistema operacional ou realizou pedido de reescalonamento voluntariamente.
Em este estado, a tarefa encontra- se na fila de escalonamento.
Em o estado executando a tarefa encontra- se em execução, e esta acabou de ser escalonada.
A tarefa encontra- se no estado bloqueada quando está pronta para executar, no entanto foi removida da fila de escalonamento (voluntariamente ou não).
Valor estimado, obtido por testes realizados no sistema operacional Hellfire Os compilado com GCC 4.
6.0 e executando a política Rate Monotonic com 10 tarefas.
A latência depende de fatores como compilador, arquitetura, política de escalonamento e sua implementação e número de tarefas.
Em o estado esperando a tarefa está em espera num semáforo, e não pode progredir sua execução até que outra tarefa incremente o mesmo até o ponto em que ela seja liberada.
Inicialmente, todas as tarefas encontram- se no estado não executou ainda.
Após a primeira execução, se não ficar presa num semáforo ou bloqueada uma determinada tarefa é mantida no estado pronta até que seja escalonada novamente.
Caso não exista tarefa a ser escalonada, uma tarefa especial adicionada na inicialização do sistema chamada idle task é escalonada, não podendo esta ser bloqueada ou excluída.
Apenas são executadas tarefas que estiverem na fila de escalonamento.
Os possíveis estados de uma tarefa são apresentados na Figura 5.5.
Para garantir a execução de tempo real do sistema, tarefas não podem desabilitar interrupções.
Mascarar uma interrupção do timer, mesmo que por um curto espaço de tempo, pode fazer com que o kernel perca a interrupção e o escalonamento perca sua validade de tempo real.
Todas as informações que dizem respeito a tarefas são armazenadas numa estrutura especial denominada TCB ou bloco de controle de tarefa.
Em esta estrutura, o sistema operacional mantém todas as propriedades das tarefas:
Sua identificação, descrição, estado de escalonamento, informações de progresso, período, tempo de execução, deadline, utilização do processador e memória, contexto da tarefa, ponteiros de uso geral (região de memória da pilha, por exemplo) e informações sobre transmissão de dados.
Escalonamento de Tarefas O mecanismo de escalonamento foi implementado em dois níveis.
A cada tick, o escalonador de tarefas periódicas (primeiro nível) é executado, e tarefas de tempo real são tratadas de acordo com a política RM representada no Algoritmo 5.6.
Caso não existam tarefas de tempo real a serem escalonadas, o escalonador de tarefas de melhor esforço (segundo nível) é executado.
Este escalonador, apresentado no Algoritmo 5.7, escolhe entre as tarefas de melhor esforço de acordo com um algoritmo circular.
Assim, as tarefas periódicas possuem precedência sobre as aperiódicas de melhor esforço.
Apenas as tarefas de tempo real são consideradas no momento em que é avaliada a carga do processador, uma vez que estas obrigatoriamente devem executar.
Tarefas de melhor esforço são executadas apenas se houver tempo de processador livre, e desta forma não incidem em carga extra.
Entre as tarefas de melhor esforço encontra- se uma tarefa de sistema, denominada idle task.
Esta tarefa possui a identificação de número zero, e tem um papel fundamental para o funcionamento do sistema operacional.
A idle task não pode ser excluída, bloqueada ou migrada.
Em a Figura 5.8 é apresentado um exemplo do funcionamento do escalonamento em dois níveis.
As melhor esforço.
Em este exemplo a carga do elemento de processamento é 70%.
Se for levado em consideração um tempo de tick de 10.48ms e uma frequência de 25 MHz, o tempo de execução das tarefas 1, 2 e 3 seria aproximadamente 262000, 524000 e 262000 ciclos respectivamente.
Ainda, a tarefa 1 executa a cada 42ms (4 ticks), 2 a cada 63ms (6 ticks) e 3 a cada 84ms (8 ticks).
Logicamente, uma tarefa pode abrir mão de sua fatia de processador a qualquer momento, e não executar até completar seu tick.
Esse tipo de situação ocorre quando uma tarefa deve ser executada num período determinado e completa seu trabalho rapidamente.
O restante do tempo de tick pode ser utilizado por outras tarefas, e dessa forma a tarefa voluntariamente pede por reescalonamento.
Em a atual implementação, no momento em que uma tarefa abre mão de tempo de processador, o escalonador de melhor esforço é executado.
Comunicação Entre Tarefas A comunicação entre tarefas é realizada por dois modelos diferentes no sistema Hellfire Os.
O primeiro é o modelo de comunicação por memória compartilhada, adequado para tarefas que executam no mesmo nodo.
O outro modelo é comunicação por trocas de mensagens, adequado para tarefas que executam em nodos diferentes.
Estes dois modelos diferem em sua perspectiva de programação.
Comunicação por memória compartilhada pode ser implementada por a proteção de uma estrutura de dados global compartilhada.
Esta estrutura pode ser de qualquer tipo, como por exemplo uma struct em linguagem de programação C. A proteção é feita com o uso de primitivas para exclusão mútua ou semáforos e abstraem sua implementação como trocas de mensagem.
Apenas tarefas fixas e num mesmo nodo podem utilizar tais primitivas, uma vez que a memória local é utilizada para realizar a comunicação.
Em estas primitivas, não são utilizados os drivers de comunicação da NoC.
Diz- se que tarefas acessam dados concomitantemente quando determinada tarefa modifica uma estrutura de dados (mas não completa a modificação) e ocorre uma troca de contexto, sendo que a tarefa escalonada também acessa a estrutura, corrompendo dados (numa escrita) ou lendo dados corrompidos.
As primitivas de comunicação por trocas de mansagem seguem o modelo produtor/ consumidor.
Cada tarefa possui uma fila circular local de recepção com tamanho configurável, contendo pacotes que podem ser retirados em ordem por a primitiva adequada.
Se a fila estiver vazia, a tarefa fica bloqueada na primitiva de recebimento (no caso de uma primitiva bloqueante) ou é mantida na primitiva até que ocorra um timeout, especificado na aplicação.
De a mesma forma, uma tarefa que envia dados a outra pode ficar bloqueada na primitiva de envio no caso de contenções na rede.
Caso a tarefa receptora não possua mais espaço na fila de recepção, pacotes subsequentes são descartados.
O descarte de pacotes foi utilizado pois existe uma única fila em hardware por nodo, e normalmente existem diversas tarefas em cada nodo.
Se uma tarefa não está tratando os pacotes recebidos, apenas os seus são descartados, não comprometendo a recepção de mensagens de outras tarefas.
A inserção de pacotes na fila de recepção, assim como bloqueio e liberação de tarefas é gerenciado por drivers do sistema operacional.
Um controle de fluxo pode ser implementado A Figura 5.9 apresenta o caminho efetuado por os dados durante uma troca de mensagem entre duas tarefas de nodos distintos.
Inicialmente, a primitiva de envio da origem encapsula a mensagem contida num espaço de memória em nível de aplicação em pacotes, preenchendo a fila de saída da tarefa.
De esta fila é retirado um pacote, o qual é copiado para a fila de saída em hardware.
A interface de rede é sinalizada, e o pacote é enviado por a rede.
A o chegar ao nodo destino preenchendo a fila de entrada, é gerada uma interrupção e o sistema operacional retira o pacote desta fila e o decodifica, encaminhando este para a fila da tarefa destino.
Posteriormente a mensagem é desencapsulada e copiada para um espaço de memória em nível de aplicação.
A implementação das primitivas de comunicação por trocas de mensagem foi realizada em dois níveis.
As primitivas de comunicação de alto nível, expostas na API do sistema, são responsáveis por encapsular e desencapsular mensagens em pacotes de dados, tomando conta de detalhes como padding e sequenciamento.
Internamente, drivers do sistema são responsáveis por realizar a transferência de pacotes entre nodos origem e destino.
Estes drivers trabalham com pacotes de tamanho fixo, e sinalizam a interface de comunicação da rede durante o envio de dados para filas em hardware, e recebem um sinal da interface durante o recebimento de dados, quando retiram dados da fila de recebimento em hardware e copiam estes dados para filas circulares de pacotes de cada tarefa.
O formato dos pacotes de dados é apresentado na Figura 5.10.
Os pacotes possuem um cabeçalho, contendo o endereço do roteador destino e o tamanho do payload 6.
Após o cabeçalho são apresentados os dados a serem transferidos.
Estes dados são compostos por uma identificação do nodo origem, uma identificação da tarefa origem e tarefa destino, o tamanho da mensagem (pode ser maior que o tamanho do pacote) um número de sequência e por fim os dados que serão colocados na fila de software da tarefa.
Desta forma, os dados contidos após o payload serão gerenciados por o driver de comunicação do sistema operacional, e seu conteúdo não é relevante para o meio de interconexão.
Este formato de pacote acarreta num overhead de comunicação em torno de 9.37% devido a os cabeçalhos.
O tamanho de pacote pode ser modificado, e para isso tanto o tamanho das filas em hardware quanto a configuração do sistema operacional precisam ser as mesmas.
Este tamanho foi definido como padrão após uma série de testes, e escolhido devido a o seu compromisso entre tamanho das filas, tempo de processamento de pacotes e overhead devido a o padding.
A Figura 5.11 apresenta o desempenho de pico na transferência de dados em nível de aplicação para diferentes tamanhos de fila em hardware empregados.
Em os testes foi assumida uma situação ideal com o envio de uma única mensagem de cada tamanho, onde tarefas de tempo real de envio e recebimento ocupam toda a capacidade de processamento em dois nodos vizinhos para realizar a comunicação.
As primitivas básicas para o envio e recebimento de mensagens assumem uma identificação fixa das tarefas envolvidas na comunicação.
Conforme o modelo apresentado anteriormente na Seção entre este tipo de tarefa foi apresentado na mesma Seção.
Para tarefas não fixas é utilizada uma controle organiza a comunicação.
O controle de comunicação sincroniza o recebimento e atualiza sejam atendidas e tarefas que invocam tal primitiva tenham atualizada a informação de comunicação localmente.
As primitivas de comunicação são apresentadas na Seção 5.6.
Alocação Dinâmica de Memória Um mecanismo de alocação dinâmica de memória foi implementado para ser utilizado tanto por o sistema operacional (alocação dos espaços de pilha das tarefas, filas de comunicação, estruturas de controle) quanto por as tarefas da aplicação.
Este mecanismo é implementado por as primitivas em diferentes arquiteturas.
Tarefas que alocam memória dinamicamente devem ser configuradas como fixas, sendo esta uma limitação da atual implementação e discutida nos Trabalhos Futuros.
O alocador baseia- se numa única região estática de memória em cada nodo, tendo seu tamanho definido em tempo de projeto.
Para alocar um segmento de memória, o alocador percorre uma lista encadeada de ponteiros, onde são definidos o início e fim de cada segmento.
A lista é percorrida em ordem, e caso exista espaço contíguo entre segmentos já alocados para armazenar o espaço requerido (método First Fit), é feito o ajuste de ponteiros e retornada a posição inicial da região alocada.
Durante a alocação também é feita a compactação do heap.
A compactação consiste em unir segmentos contíguos anteriormente alocados e já liberados de memória num único segmento contíguo memória livre, diminuindo- se a fragmentação.
Mapeamento de Tarefas no Sistema Hellfire Os Esta Seção apresenta como é realizada a atividade de mapeamento no sistema operacional Hellfire Os.
São abordados o mapeamento das tarefas iniciais e o suporte do sistema operacional para a realização de mapeamento dinâmico e migrações de tarefa.
Os gerentes de migração são discutidos no final da Seção.
Mapeamento Inicial Em este momento, o mapeamento das tarefas iniciais é realizado manualmente, isto é, o desenvolvedor é responsável por descrever a aplicação e definir os grupos de tarefa (particionamento), e a posição dos grupos nos respectivos nodos.
Estas definições são feitas no código fonte da aplicação, como apresentado na Figura 5.12.
Em o exemplo, seis tarefas iniciais são mapeadas em dois elementos de processamento.
Não foi especificada a quantidade de nodos que compõem a arquitetura, sendo este um parâmetro de configuração do sistema operacional e da arquitetura em tempo de projeto.
Apenas uma parte da descrição da aplicação onde é realizado o mapeamento está sendo apresentada, sendo a implementação das tarefas não relevante no exemplo.
A identificação da tarefa no contexto de execução (por exemplo t3) é gerenciada por o sistema operacional, assim como sua identificação global.
De essa forma, os parâmetros passados às primitivas de mapeamento de tarefas consistem num ponteiro para a função que implementa sua funcionalidade7, parâmetros de execução (período, capacidade e deadline), um texto de identificação, tamanho da pilha, valor de consumo energético arbitrário e definição sobre a possibilidade de migração ou não da tarefa (fixa ou não fixa).
A Figura 5.13 descreve este mapeamento de uma maneira simplificada, representando a posição das tarefas nos nodos da arquitetura numa malha 2x2.
Não estão representadas no exemplo as tarefas do sistema operacional, sendo estas a tarefa 0 (idle), tarefa 1 (controle de comunicações) e tarefa 2 (gerente de migração).
Repositório Local de Tarefas Em conjunto com o mapeamento das tarefas iniciais, são definidos os conteúdos dos repositórios locais de cada nodo.
Estes repositórios possuem a implementação das tarefas, e são organizados de maneira distribuída.
Assim como o mapeamento das tarefas iniciais, o conteúdo dos repositórios é especificado manualmente, e pode ser realizado com o uso de diretivas de préprocessador ou arquivos de código fonte separados.
Em a Figura 5.14 é apresentada a organização do repositório local de tarefas.
Cada instância de sistema operacional possui seu próprio repositório, que pode ser modificado dinamicamente.
Durante inicialização do sistema, o repositório local é formado por tarefas iniciais e tarefas locais dinâmicas, ou seja, que não foram mapeadas.
Qualquer tarefa presente no repositório local pode ser mapeada por outra tarefa ou durante a inicialização por o sistema operacional.
Caso venha a ser excluída, uma tarefa local permanece no repositório.
A modificação dinâmica dos repositórios locais compreende na relocação de tarefas e faz parte do mecanismo de migração, apresentado na Seção Cada nodo possui uma única memória local e o código do sistema operacional, assim como o repositório de tarefas local, é mantido nesta memória.
Tarefas armazenadas no repositório local Implementação do código da tarefa.
Esta função pode realizar chamadas a outras funções recursivamente.
Mapeamento Dinâmico O mapeamento dinâmico de tarefas é realizado por a adição de novas tarefas (primitivas é realizado por outras tarefas, e pode alterar as características de carga do sistema.
Logicamente, a migração de tarefas ou a exclusão destas possui o efeito inverso, liberando recursos localmente.
Em a Figura 5.16 é apresentado um exemplo onde é realizado o mapeamento dinâmico com Esta tarefa realiza a própria replicação após certo ponto em sua execução, e uma outra tarefa com as mesmas características é mapeada dinamicamente variando a carga do sistema.
A implementação do exemplo é apresentada na primeira parte da Figura, onde é ilustrado o uso da API do sistema operacional.
Tarefa Escalonada aplicação consiste de um conjunto inicial de cinco tarefas, sendo a tarefa 1 a única de tempo real e excluída.
Após sua exclusão a utilização do elemento de processamento é reduzida, e as tarefas de melhor esforço passam a executar com maior frequência.
A tarefa 5 possui uma utilização de processamento de 50%, e em virtude de isso as tarefas de melhor esforço perdem prioridade, como pode ser observado por o seu perfil de execução na Figura de execução modificado durante toda a execução da aplicação.
As tarefas 5 e 6 possuem um jitter variável, entretanto após o término da tarefa 5, a tarefa 6 passa a executar sem variações.
Esse jitter é aceitável, uma vez que as tarefas cumprem com seus deadlines dentro de o período estabelecido.
A carga máxima de processamento é de 87% e nenhum deadline é perdido durante a execução.
Migração de Tarefas O sistema operacional atualmente possui uma primitiva que permite a migração explícita parâmetros a identificação de uma tarefa local e o nodo destino da tarefa.
Todas as tarefas que forem mapeadas no sistema podem ser migradas, desde que tenham sido previamente configuradas como não fixas com a opção TASK_ CAN_ MIGRATE.
Tarefas de sistema, tarefas fixas, assim como a tarefa idle task e drivers são configurados com a opção TASK_ CANNOT_ MIGRATE, e a primitiva de migração é impedida de migrar tais tarefas.
Em a Figura 5.19 é apresentado um exemplo de uso da primitiva de migração.
Em o exemplo, existem duas tarefas da aplicação atribuídas ao nodo 0.
Após executarem por um tempo determinado por o algoritmo, a tarefa migration executa a primitiva de migração, transferindo a tarefa i am alive para o nodo 1.
A primitiva de migração além de realizar a transferência de uma tarefa para outro nodo insere numa lista a identificação global da tarefa migrada.
Caso seja enviada uma mensagem para a tarefa migrada, a tarefa de controle de comunicação responde para onde a tarefa foi migrada, de forma que a tarefa do nodo origem possa descobrir o novo destino.
O protocolo é descrito anteriormente na Seção 4.6.
Caso a tarefa seja transferida para um nodo onde já esteve, sua entrada na lista de migração é removida.
Mecanismos para realizar a migração de tarefas em ambientes que possuem uma unidade de gerência de memória (MMU) são mais simples de serem implementados, uma vez que não é necessário nenhum cuidado adicional ao ser transferido o código de um nodo para outro.
Uma unidade MMU é utilizada para realizar a tradução de endereços lógicos para físicos, permitindo a carga de código de tarefas em posições arbitrárias da memória.
Por questões de simplicidade do hardware, optou- se por não utilizar uma unidade de gerência de memória neste trabalho e sim um mecanismo parcialmente suportado por o compilador.
Este mecanismo, consiste na emissão de código relocável (PIC) em conjunto com uma tabela específica, que deve ser gerenciada por o sistema operacional.
A tabela gerada por o compilador, e mantida por o sistema operacional é chamada GOT, e em ela são armazenados endereços físicos para saltos e acessos à memória.
O compilador, dessa forma, realiza a geração de código com endereços relativos à tabela GOT.
Por exemplo, uma tarefa compilada para o endereço de memória 0x00000000 é relocada para o endereço 0x00000 A00 após o processo de migração.
Para que o código possa executar adequadamente, é necessário apenas realizar a modificação nas entradas da tabela GOT, acresentando 0xA00 aos valores antigos.
O trabalho de Marchesan utiliza um sistema semelhante de relocação, no entanto este não possui qualquer relação com o trabalho aqui apresentado.
Para que este mecanismo funcione, o sistema operacional e as tarefas da aplicação precisam ser compilados com flags específicas e após a geração do código binário, este precisa ser processado e os valores iniciais das tabelas GOT de cada tarefa definidos.
O processo de migração de tarefas transfere para um nodo destino, além de o contexto e dados da pilha da tarefa, o seu código e sua GOT que faz parte do contexto da tarefa.
A o receber uma tarefa, o mecanismo de migração no destino atualiza as entradas na GOT da tarefa para os endereços físicos da memória.
Gerentes Distribuídos para Migração de Tarefas A implementação dos gerentes de migração é apresentada a seguir.
Cada gerente é uma tarefa de tempo real, e possui uma identificação local fixa.
Os parâmetros desta tarefa podem ser modificados em tempo de projeto com o intuito de melhorar o tempo de estabilização do sistema em caso de sobrecargas.
Sendo esta uma tarefa de tempo real, um percentual de carga de processamento é reservado para a gerência.
Cada nodo possui um gerente local, e em conjunto trabalham para reduzir perdas de deadline em situações de sobrecarga.
Os gerentes de migração podem ser adicionados opcionalmente ao sistema, sendo este um parâmetro de configuração do sistema operacional.
O algoritmo de gerência possui o seguinte funcionamento, e é apresentado no Algoritmo parte de gerentes de outros nodos.
Caso existam solicitações, responder a estas com informações locais e remover estes nodos da pesquisa por candidatos num primeiro momento (nesta iteração do algoritmo).
Juntamente com as solicitações, podem existir respostas atrasadas de outros nodos, em decorrência a perguntas feitas por o gerente local anteriormente.
Ignora- se estas respostas.
A seguir, são verificadas as perdas de deadline do conjunto de tarefas e a carga do sistema, e caso a situação seja considerada normal (não houve um aumento nas perdas de deadline e a carga do sistema esteja abaixo de o limite) o algoritmo é terminado nesta iteração.
Caso contrário, o nodo é considerado sobrecarregado e é feita uma lista de tarefas que podem ser migradas.
De esta lista, são removidas tarefas fixas e tarefas bloqueadas e a melhor tarefa é escolhida para ser migrada.
Se não houver tarefa alguma para ser migrada, esta iteração do algoritmo é terminada, e o gerente deve esperar por algum tempo antes de executar novamente.
Se houver pelo menos uma tarefa apta a ser migrada, é realizada uma pesquisa por o melhor nodo candidato a receber a tarefa utilizando o algoritmo de espalhamento proposto.
Para isto é composta uma lista com os candidatos, a qual é formada por respostas de recursos disponíveis em cada candidato.
O melhor candidato é escolhido e é realizada a migração.
Caso ocorra alguma falha, o próximo candidato é escolhido, e é realizada uma nova tentativa.
Se não houver candidato após a falha, o gerente deve esperar por algum tempo antes de executar novamente.
Se a migração for completada com sucesso, o gerente deve esperar por um tempo pequeno antes de iniciar uma nova iteração.
Este tempo é calculado com base na identificação do nodo, e difere para cada um com o objetivo de evitar ao máximo situações de deadlock.
API do Sistema Hellfire Os Em esta Seção é apresentada a API do sistema operacional Hellfire Os.
A interface do sistema é relativamente simples e em conjunto com as bibliotecas implementadas fornece os serviços necessários para o desenvolvimento de aplicações embarcadas de tempo real.
A API consiste em 6 classes de chamadas de sistema:
Gerenciamento de tarefas, informações do sistema, exclusão mútua, gerenciamento de memória, primitivas de comunicação e migração de tarefas.
Esta API é apresentada na Tabela 5.3.
Toolchain Para o desenvolvimento de aplicações e do sistema operacional foi construído um conjunto de ferramentas para o ambiente Linux, baseado na coleção de compiladores GCC versão 4.6.0.
Os fontes do compilador foram modificados com o intuito de evitar a geração de instruções com acesso desalinhado à memória.
As ferramentas tem como arquitetura alvo o conjunto de instruções MIPS I, e incluem:·
compilador cruzado (mips-elf-gcc);·
montador de linguagem de máquina (mips-elf- as);·
ferramentas para manipulação de binários (mips-elf- objdump, mips-elf- readelf, mips- elf-- objcopy).
Em conjunto com as ferramentas Gnu são utilizados scripts com o intuito de automatizar diversos processos, como compilação, ligação, manipulação de binários, geração hexdumps e configuração do sistema operacional.
Para a construção de uma imagem binária a ser carregada em cada elemento de processamento, são realizados alguns passos:
Montagem, compilação e customização do sistema operacional;
Compilação da aplicação;
Criação de uma imagem ELF contendo a aplicação e sistema operacional;
Criação de uma imagem binária final, utilizando ferramentas para a manipulação.
A criação da imagem final é necessária para que a mesma possa ser diretamente carregada na memória de determinado nodo.
Arquitetura MPSoC A arquitetura é composta por um conjunto homogêneo de elementos de processamento, que se comunicam por meio de uma rede utilizando chaveamento por pacotes.
O conjunto composto por um elemento de processamento, filas, um roteador e lógica de controle para a interface de rede implementa uma unidade de processamento, ou nodo.
O elemento de processamento contido em cada nodo possui uma memória local, e executa uma instância do sistema operacional Hellfire Os.
Cada instância do sistema operacional, com o suporte adicional do hardware, possui os recursos para a execução de aplicações multiprocessadas distribuídas e de tempo real.
Os elementos de processamento implementam o conjunto de instruções MIPS I e possuem um pipeline de dois estágios.
Entre os recursos disponíveis em cada elemento estão uma memória local, um contador (timer), uma controladora de interrupções e uma interface de comunicação serial.
Nenhum recurso avançado como gerenciamento de memória (MMU) ou cache foram implementados.
O processador Plasma foi modificado para incluir acesso e controle às filas dispostas entre ele e o roteador da rede e utilizado como elemento de processamento.
O roteador contido em cada nodo implementa o repasse de pacotes por a rede.
Este roteador possui cinco portas de rede (quatro portas conectadas a outros roteadores e uma porta local), por onde o repasse de pacotes acontece segundo o algoritmo XY determinístico.
Em o momento em que os pacotes chegam ao destino, estes são direcionados para a porta local, onde estão dispostas filas.
A Figura 5.21 detalha os componentes que compõem um nodo.
As filas são acessadas por o elemento de processamento através de registradores mapeados em memória.
Para ler os dados da fila de entrada, por exemplo, o driver de comunicação do sistema operacional realiza uma série de leituras sequenciais num endereço específico.
O wrapper implementado entre o elemento de processamento e as filas encarrega- se de efetuar a sinalização, e desta forma um flit pode ser copiado da fila em hardware para a memória local em dois ciclos 8.
Em o momento em que a fila de entrada de dados (sentido rede para o elemento de processamento) estiver cheia, uma interrupção é gerada por o wrapper.
O sistema operacional trata a interrupção e executa o driver de comunicação, que direciona o pacote para a fila em software da tarefa destino.
Em o momento em que a fila de saída de dados (sentido elemento de processamento para a rede) estiver cheia, é gerado um sinal no wrapper e o pacote é encaminhado por a rede até que chegue à fila da interface de rede do nodo destino.
A arquitetura proposta foi implementada em três diferentes protótipos e uma ferramenta de simulação, a qual foi utilizada para a avaliação de resultados uma vez que não foi possível neste momento a construção de um protótipo com um grande número de nodos.
Em o primeiro protótipo foi implementado um único nodo, com o intuito de validar o funcionamento básico da interface de rede.
Em o segundo, quatro nodos numa malha 2x2 foram utilizados para testes iniciais da interface de rede e drivers do sistema operacional.
O último protótipo construído possui seis nodos numa malha com topologia 3x2.
Os protótipos foram utilizados para calibrar a ferramenta de simulação, previamente caracterizada.
Em os nodos foram configurados roteadores Hermes com filas internas de 16 flits e filas da interface de rede com 64 flits e cada elemento de processamento possui 32 kB de memória local.
Ferramenta de Simulação N-MIPS é uma ferramenta de simulação que oferece um ambiente MPSoC com um conjunto de até centenas de nodos interconectados numa rede com topologia malha.
Os elementos de processamento são implementados como simuladores do conjunto de instruções (ou ISSs) da arquitetura MIPS e a rede intra-chip como uma malha 2D organizada como um modelo de rede composto por roteadores Hermes.
O tamanho da memória local dos elementos de processamento assim como o número de elementos e as dimensões da malha são configuráveis.
Em a atual implementação foi configurada uma memória de 1 MB por nodo e dessa forma um grande número de tarefas pode executar em cada elemento de processamento, o que permite a verificação de cenários complexos de aplicação.
Esta ferramenta implementa um sistema MPSoC completo em linguagem C, e simula a execução de software utilizando precisão em nível de ciclo.
A o utilizar informações anotadas de hardware com relação a a latências e potência, simulações rápidas de sistemas MPSoC complexos podem ser realizadas, mantendo no entanto informações detalhadas sobre desempenho, comportamento e Em a arquitetura do elemento de processamento em questão, um acesso à memória é realizado por instruções load/ store, e sua latência é de dois ciclos devido a o acesso à memória, que é compartilhada entre dados e instruções.
Para que a ferramenta representasse as reais características da arquitetura MPSoC proposta, a interface de rede e o roteador Hermes foram modelados e incluídos na ferramenta em e.
Este roteador possui características como arbitragem rotativa, chaveamento por pacotes wormhole, armazenamento na entrada, controle de fluxo handshake e algoritmo de roteamento XY determinístico na implementação utilizada.
Após a arbitragem, a qual possui um atraso em torno de sete ciclos por roteador conforme observado em simulações HDL e também caracterizado por Ost, a cada dois ciclos é repassado um flit de 16 bits por salto na rede com o controle de fluxo handshake.
Após formado um caminho entre roteadores origem e destino, a comunicação ocorre na forma de pipeline.
De essa forma, é interessante que seja transferida uma quantidade significativa de dados a cada envio de pacote, de forma que as perdas geradas por o tempo de arbitragem sejam amortizadas.
A latência em ciclos para cada pacote é descrita como:
Lpacket $ + (2 × Nflits) Congestionamentos acontecem quando uma determinada porta nos roteadores intermediários está no mesmo caminho de mais de uma transferência simultânea.
Em este caso, a primeira transferência precisa terminar para que a porta fique livre para outra transferência.
Este comportamento está implementado no simulador, assim uma boa aproximação da real latência do hardware em situações de congestionamento é representada.
O sistema operacional utiliza endereçamento sequencial entre os elementos de processamento.
De essa forma, torna- se necessário converter um número de elemento de processamento para o endereço do nodo na rede.
Em nível de aplicação, é utilizada a definição Core que realiza esta conversão, levando em consideração as dimensões da rede.
A implementação da definição é apresentada na Figura 5.22.
O mesmo sistema de endereçamento é utilizado tanto na ferramenta de simulação quanto no protótipo, e segue o modelo de endereçamento de uma rede Hermes.
O número máximo teórico de elementos de processamento suportados por o simulador é de 256, e as dimensões limite para a malha de interconexão são de 16x16 nodos.
A posição e endereçamento de cada nodo numa malha 4x4 é ilustrado na Figura 5.23.
Em este sistema adotado, cada elemento de processamento possui uma posição fixa na rede de interconexão.
Como os elementos de processamento são todos idênticos, o mapeamento das tarefas é suficiente para explorar o espaço de projeto das aplicações.
Em ambientes heterogêneos outras alternativas tornam- se possíveis, como o mapeamento dos elementos de processamento a posições arbitrárias da rede.
Este tipo de mapeamento permite a otimização da aplicação em outro nível, no entanto este foge ao escopo do presente trabalho.
Além de os periféricos implementados no protótipo real, a ferramenta inclui um sistema de log de informações para cada elemento de processamento.
O sistema de log é acessado por o sistema operacional por endereços mapeados em memória.
Assim, esta funcionalidade permite que o sistema operacional exporte informações de execução das aplicações em tempo real.
A cada tick, informações detalhadas sobre cada tarefa são armazenadas num arquivo, que pode ser posteriormente utilizado para realizar a extração de perfis de execução, geração de estatísticas de simulação e gráficos com o escalonamento das tarefas, volume de comunicação entre outros.
Outras saídas geradas por o simulador incluem os dispositivos de entrada e saída padrão como UARTs, terminais de alta velocidade e informações sobre as instruções executadas em cada ISS.
Considerações Finais O modelo de aplicações proposto neste trabalho foi implementado num RTOS e o modelo de arquitetura foi prototipado e adaptado a um simulador implementado anteriormente.
Estas implementações têm como objetivo representar e validar os modelos propostos, uma vez que estes por serem originais não puderam ser retratados em sistemas já existentes.
O sistema operacional é totalmente preemptivo, altamente configurável, possui bibliotecas padrão customizadas, temporizadores, semáforos, alocação dinâmica de memória, funcionalidades de depuração, suporte a diversas políticas de escalonamento, drivers de comunicação, mapeamento dinâmico de tarefas, migração de tarefas e serviços de gerência de migração distribuídos.
A arquitetura foi inicialmente modelada em RTL e então caracterizada e implementada num simulador compatível com o conjunto de instruções MIPS I em nível de ciclo.
Elementos de processamento, filas de comunicação em hardware e roteadores da rede de comunicação são todos emulados no simulador, e o número de processadores, tamanho das filas, assim como as dimensões da malha e tamanho das filas internas aos roteadores da rede são configuráveis.
A primeira parte deste Capítulo apresenta a avaliação de diversos componentes do sistema operacional, com o intuito de validar a implementação frente o modelo proposto.
Em a segunda parte são avaliadas aplicações sintéticas e reais, explorando as vantagens da abordagem de gerência de migração distribuída para conjuntos de tarefas que executam conforme o modelo.
As métricas utilizadas referem- se ao overhead do sistema operacional, utilização dos elementos de processamento, número de migrações realizadas, tempo de estabilização do sistema e perdas de deadline da aplicação.
Em todos os testes realizados, foi considerada uma frequência de relógio de 25 MHz (a não ser quando especificada outra frequência) e um tempo de tick de 10.48ms. A configuração das filas de entrada dos roteadores é de largura de 16 bits por flit com um tamanho de 16 flits, filas de entrada e saída da interface de rede entre os elementos de processamento e os roteadores com 64 flits cada e filas de software com capacidade para 32 pacotes para cada tarefa.
Como definido anteriormente, o tamanho dos pacotes é mesmo das filas da interface de rede, sendo a configuração das filas de hardware a mesma para o sistema operacional e para a arquitetura.
As dimensões das malhas utilizadas nos testes são 3x2, 4x4 e 6x5 nodos.
As tarefas de controle de comunicação são e invocação destes a cada 104ms.
O limite de utilização dos nodos foi definido de acordo com o valor conservador de 69% de utilização (segundo a política RM) e é apenas maior para casos onde uma única tarefa da aplicação é mantida em determinado nodo.
Para a realização de medidas relacionadas a contagem de ciclos de relógio, foi utilizado um contador em hardware (emulado no simulador) acessível ao sistema operacional por um registrador mapeado em memória.
Tanto as aplicações sintéticas quanto as aplicações reais foram implementadas em linguagem C e descritas a partir de representações que utilizam o grafo ATG proposto.
As aplicações iniciais utilizadas para extrair informações sobre o desempenho do sistema operacional com relação a o escalonamento de tarefas, primitivas de uso geral e trocas de mansagem não foram detalhadas por serem triviais. Como
plataforma de simulação foi utilizada a ferramenta N-MIPS descrita brevemente na Seção 5.8.
Esta ferramenta possui recursos para a extração de informações de execução de aplicações e trabalha em conjunto com o sistema operacional para este fim.
Os resultados gerados neste Capítulo foram extraídos diretamente desta ferramenta.
Desempenho do Sistema Operacional Trocas de Contexto O primeiro teste realizado refere- se ao desempenho do sistema operacional com relação a as trocas de contexto.
Para a geração dos diferentes cenários, foram utilizadas três frequências de operação distintas:
25 MHz (protótipo e ferramenta de simulação), 100 MHz (frequência de operação típica para sistemas com um grande número de elementos de processamento implementados em ASIC, por exemplosistemas embarcados modernos e de alto desempenho).
Em a Tabela 6.1 é apresentado o desempenho do sistema operacional com relação a as trocas de contexto em diferentes situações.
Foram criados cenários onde são executadas de 5 a 70 tarefas num mesmo elemento de processamento.
Em os testes realizados observou- se que os parâmetros das tarefas, assim como a variação do conjunto de tarefas entre periódicas e aperiódicas (tempo real, melhor esforço ou híbrido) não influência no tempo de execução do escalonador do sistema operacional.
Este comportamento deve- se ao fato do escalonamento ser realizado em dois níveis, ou seja, o algoritmo RM é executado e caso não existam tarefas de tempo real a serem executadas, o escalonador de melhor esforço é executado.
Tarefas de qualquer tipo podem ser mapeadas ou excluídas a qualquer instante, e por isso os dois níveis de escalonamento são realizados.
Independente das características do conjunto de tarefas, o tempo das trocas de contexto aumenta linearmente de acordo com o número de tarefas como pode ser observado nos resultados.
A frequência de operação dos elementos de processamento influência diretamente no overhead, uma vez que o tempo de tick é mantido constante.
Considerando o pior caso de de-sempenho, com uma frequência de operação de 25 MHz e 70 tarefas num nodo, o tempo de trocas de contexto é relativamente baixo e representa em torno de 3% do tempo total de execução.
A=100  MHz, um conjunto formado por 50 tarefas pode ser escalonado em torno de 60 us, o que permite que o sistema operacional seja utilizado em aplicações de tempo real com um grande número de tarefas.
Devido a o baixo overhead, para um número reduzido de tarefas é possível desconsiderar a influência do sistema operacional na execução das mesmas independente da frequência de operação utilizada.
Em a implementação, o tempo de escalonamento avança sobre o tempo de execução da tarefa rescém escalonada, fazendo com que esta tenha a execução do próximo job reduzida em exatamente o número de ciclos utilizado por o sistema operacional para salvar os registradores na pilha da tarefa preemptada, executar o escalonador de tarefas e restaurar o contexto da tarefa corrente.
Idealmente, no momento da ocorrência de uma interrupção de timer a próxima tarefa deveria começar a executar.
Sabe- se que é impossível não existir um custo para o salvamento de contexto, escalonamento e restauração (numa implementação puramente software), mas é possível reduzir ao máximo o tempo de execução do sistema operacional criando- se um escalonamento de tarefas próximo de o ideal, que é o caso da atual implementação.
Primitivas de Uso Geral Algumas primitivas e eventos do sistema operacional foram medidos com relação a sua latência.
Assim como o tempo das trocas de contexto, o tempo de execução destas primitivas é considerado como parte do tempo de execução das tarefas que as invocam.
A execução da rotina de interrupção da interface de rede ocorre no tempo de execução da tarefa corrente no elemento de processamento que recebe um pacote, sendo a melhoria do seu desempenho ou alternativas a este comportamento um trabalho futuro.
Alternativas incluem postergação da interrupção até o término do job corrente, replicação de filas em hardware e outros mecanismos auxiliares como módulos Em a Tabela 6.2 são apresentados os valores medidos.
O tamanho de pilha utilizado nas tarefas é de 2 kB, sendo que este tamanho influência no tempo de replicação das tarefas (é necessário realizar a cópia do contexto de estas).
São consideradas 10 tarefas nas medições, e este número influência no tempo de trocas de contexto como observado anteriormente.
A latência das primitivas influenciada por a quantidade de memória requerida, uma vez que apenas ponteiros são manipulados nas estruturas de dados no alocador de memória implementado.
Internamente, esta primitiva executa uma chamada à Os_ AddTask() ou Os_ AddPeriodicTask() (dependendo do tipo de tarefa replicada).
O maior custo ocorre no momento em que o contexto e a pilha da tarefa são copiados, sendo este o motivo de um maior tempo de execução da primitiva a tarefa pai não pode ser bloqueada até o término da tarefa filha, nem ter seus dados modificados.
Para o contexto de aplicação do sistema operacional proposto (aplicações embarcadas de tempo real) este modelo de cópia é válido, uma vez que o tamanho das tarefas é bastante reduzido, o que Primitivas de Comunicação O desempenho das primitivas de comunicação medido refere- se a uma taxa de transferência constante obtida em nível de aplicação.
Foi utilizado um controle de fluxo para evitar a saturação das filas em software, além de reduzir ao máximo a influência da execução da rotina de tratamento de interrupção da rede em tarefas não envolvidas com a comunicação.
Desta forma, interrupções sucessivas em virtude de um grande número de mensagens ou mensagens formadas por uma grande quantidade de pacotes ocorrem dentro de o tempo de execução da tarefa destino.
Para a realização dos testes, foram utilizados dois nodos vizinhos numa malha 3x2 enviando- se 500 mensagens para a obtenção de cada ponto na Figura 6.1.
O tamanho das mensagens é de 50 a 1000 bytes com intervalos de 50 bytes entre cada teste.
O número de pacotes gerado na rede foi de 500 a 4500 por teste, com um volume de dados entre 25000 e 500000 bytes.
Em virtude de o desempenho da rede de interconexão ser muito maior que as taxas alcançadas em nível de aplicação, a distância entre nodos não influenciou nos testes.
Em redes com um grande número de nodos alguns dos enlaces são compartilhados em transferências entre múltiplos elementos de processamento, e as contenções geradas podem influenciar no desempenho de comunicação de acordo com a distância entre os nodos com relação a a taxa de transferência e latência.
A taxa de transferência obtida com o uso das primitivas de comunicação em nível de aplicação foi medida variando- se os parâmetros da tarefa de origem das mensagens.
Foram criados cenários com utilização de processamento de 20%, 40%, 60% e 80%.
Em todos os casos, a tarefa receptora da comunicação possui uma utilização de 80%.
Em os testes realizados, é evidente Outro detalhe observado é a variação de desempenho em virtude de o tamanho das mensagens para cada um dos cenários.
Esta variação ocorre principalmente em virtude de o padding realizado por a média obtida foi de 543 Kbps para 20% de utilização, 1120 Kbps para 40%, 1827 Kbps para 60% e 2212 Kbps para 80% de utilização.
Sem controle de fluxo, as taxas de transferência dobram (não é necessária uma confirmação para cada mensagem) e a transferência de mensagens maiores que 1000 bytes também aumenta substancialmente o desempenho.
Não foram utilizadas mensagens maiores devido a o tempo despendido para realizar a simulação em virtude de o volume de dados e mensagens transferidas.
O desempenho de pico obtido (transferência de uma única mensagem de um nodo a outro, com ocupação total de processamento, sem controle de fluxo) é maior que os números apresentados, pois não é necessário que ocorra sincronização entre os drivers de envio e recebimento dos nodos envolvidos na transferência.
O desempenho de pico das primitivas de comunicação foi utilizado para projetar o tamanho das filas de hardware e software, sendo este apresentado na Seção 5.3.
Utilizações entre 20% e 80% foram escolhidas em virtude de a taxa mínima de transferência esperada e tempo de processamento livre para outras tarefas do sistema executarem normalmente.
Migração de Tarefas O último aspecto analisado nesta Seção refere- se ao desempenho obtido por a primitiva Os_ Task O tempo de migração inclui a cópia do contexto da tarefa a ser migrada, cópia dos segmentos de código e dados, tempo de restauração do contexto da tarefa no destino e resposta da operação, contendo a identificação da tarefa no nodo remoto ou uma falha.
Em os testes realizados, o tamanho total das tarefas migradas foi variado entre 1 kB e 4 kB e a influência da carga do nodo destino no tempo de migração foi avaliado para situações com 20% (carga baixa), 50% (carga média) e 80% (carga alta).
Em todas as situações, os nodos destino possuem três tarefas de sistema em execução além de outras cinco de uma aplicação qualquer.
Os parâmetros destas tarefas foram modificados para gerar as três situações de carga avaliadas.
A invocação direta da primitiva de migração por a aplicação permite que uma tarefa de melhor esforço ou tempo real seja migrada para um nodo altamente carregado (acima de o limite de utilização da política RM).
No entanto, migrações realizadas por os gerentes de migração evitam tais situações realizando a avaliação de carga antes de efeturem migrações.
O caso de alta carga foi avaliado para demonstrar uma situação que excede os limites de carga de acordo com o modelo proposto.
Em a Tabela 6.3 são apresentados os cenários de teste.
Como pode ser observado, o tempo de migração aumenta linearmente de acordo com o tamanho das tarefas.
Em situações onde nodos destino estão pouco carregados, a migração de uma tarefa de 1 kB é realizada em torno de 3ms. Uma tarefa de 4 kB é migrada na mesma situação de carga em 9.5ms, ou seja, num tempo inferior a um tick do sistema.
Em este caso é possível realizar a migração de tarefas sem chance de haver perdas de deadline, pois o processo ocorre atomicamente dentro de o tick da tarefa que invocou a migração ou do gerente de migração.
A taxa de transferência de dados ao nodo destino no último caso apresentado ocorre a 3367 Kbps (média em virtude de o protocolo de migração), uma vez que o destino possui memória em filas com o tamanho suficiente para receber toda a tarefa, evitando um controle de fluxo e transferindo uma quantidade de informação significativa num curto espaço de tempo.
Nodos destino altamente carregados fazem com que o processo de migração se torne mais lento que em outras situações, com tempos variando entre 28ms e 29.66ms. Este atraso deve- se principalmente a redução de prioridade da tarefa de controle de comunicação.
Com 80% de carga, além de a carga da tarefa que está sendo migrada, existe uma menor probabilidade da tarefa de controle de comunicação ser executada, e dessa forma o processo é postergado e a tarefa a ser migrada é mantida bloqueada, o que pode fazer com que esta perca deadlines.
O processo de migração ocorre dentro de o tempo de execução da tarefa que invoca a primitiva.
No entanto, o processo pode exceder o tempo de execução desta tarefa, sendo continuado apenas no próximo período.
Uma tarefa pode realizar uma migração que leve mais de um tick sem que ocorram perdas de deadline em virtude de a migração se esta possuir parâmetros de execução suficientes (período e capacidade) e a tarefa que está sendo migrada não possuir uma prioridade maior que esta, de acordo com a política RM.
Perdas de deadline em tarefas que estão sendo migradas não podem ser facilmente calculadas com antecedência, pois são dependentes dos parâmetros do conjunto de tarefas em execução.
Gerentes de Migração em Aplicações Sintéticas Em esta Seção serão apresentados quatro cenários que demonstram o comportamento do mecanismo de gerência de migração de tarefas distribuído frente um gerente centralizado.
Em todos os casos foi mantida uma carga inicial idêntica em ambas abordagens para a obtenção dos resultados.
Com a abordagem distribuída, cada nodo possui um gerente de migração independente que mantém apenas a informação de carga local, e com a abordagem centralizada um dos nodos possui um gerente de migração centralizado e os outros possuem uma tarefa escrava que atende às solicitações de migração deste gerente.
O gerente de migração é posicionado num nodo próximo a o centro da malha em todos os casos, e corresponde aos nodos 1 (malha 3x2), 5 (malha 4x4) e 14 (malha 6x5).
De essa forma, os gerentes locais comunicam- se com o centralizado informando a carga inicial do nodo (para que o gerente mantenha esta informação localmente) no início da execução e enviam mensagens a este a cada mudança de estado de carga (aumento ou diminuição da ocupação, número de tarefas e memória disponível).
O gerente centralizado envia mensagens de migração após a tomada de decisão às tarefas escravas, que realizam a migração da tarefa escolhida por o gerente para um nodo destino também escolhido por o gerente.
A implementação do gerente centralizado leva em consideração o mesmo critério de seleção do alvo de migração dos gerentes distribuídos, ou seja, o algoritmo de busca por espalhamento a partir de o ponto de sobrecarga.
A diferença é que nem o gerente nem nodos afetados por uma sobrecarga enviam mensagens de solicitação aos nodos vizinhos (como é o caso no uso de gerentes distribuídos), pois a informação é mantida no gerente sempre atualizada.
Devido a diferenças no perfil de execução das tarefas em nodos afetados, a ordem das migrações pode divergir entre as duas abordagens, assim como as tarefas escolhidas, os destinos e número de migrações.
Por possuir uma visão global do sistema, o gerente centralizado possui a possibilidade de realizar migrações utilizando diferentes critérios, como selecionar regiões menos populadas da malha ou outros.
Este tipo de critério não foi utilizado, pois a idéia do algoritmo de espalhamento é justamente manter próximas as tarefas originalmente mapeadas num mesmo nodo, evitando a fragmentação da aplicação e consequentemente reduzindo a ocupação de enlaces no caminho de comunicação.
Em os testes realizados, foram criadas situações onde múltiplos nodos encontram- se sobrecarregados com o objetivo de estressar a eficiência das duas abordagens.
Além disso, os algoritmos de gerência de migração apenas são ativados a partir de o tick 100, para que todas as tarefas das aplicações exemplo executem pelo menos uma vez e dessa forma os gerentes tenham a opção de escolher qualquer uma do particionamento como candidata a migração1.
Em estes cenários, existem diversos elementos de processamento em sobrecarga e que possuem tarefas que estão perdendo deadlines.
Em todos os testes realizados, as aplicações foram simuladas por 5000ms (5 segundos).
Todas as tarefas foram configuradas com um tamanho de pilha de 4 kB, e devido a a simplicidade de implementação de estas (modelos de tarefa), o tamanho do código é bastante reduzido, variando entre 50 e 300 bytes.
A medida de tempo utilizada nos exemplos é ticks, uma vez que os algoritmos de gerência executam e sincronizam com base em parâmetros de tempo real que utilizam esta unidade.
De essa forma, ao reduzir- se o tempo de tick, reduz- se o tempo de execução dos algoritmos.
Vale ressaltar que as trocas de mensagens entre gerentes de migração e suas decisões ocorrem dentro de o tempo de execução destes, e desta forma a execução das tarefas que compõem a aplicação não é afetada.
As tarefas candidatas a migração devem ser configuradas na aplicação como não fixas.
Além disso, para que possam ser migradas seu contexto precisa ser inicializado, o que acontece após a execução do primeiro job (a tarefa encontra- se no estado pronto).
Aplicação 1, MPSoC 3x2 A primeira aplicação sintética é apresentada na Figura 6.2, a qual possui suas tarefas iniciais mapeadas num MPSoC com dimensões 3x2, juntamente com tarefas de controle de comunicação e gerentes de migração.
O número inicial de tarefas da aplicação é 18 e os nodos 2 e 3 encontram- se uma carga de 89% e 94% respectivamente2.
Em tempo de execução é mapeada mais uma tarefa no nodo 0, aumentando sua carga para 76%.
Esta aplicação possui um alto grau de comunicação e as tarefas mapeadas em cada nodo possuem parâmetros pouco semelhantes.
Em o exemplo, é ilustrada a situação de sobrecarga numa malha de pequenas dimensões onde uma aplicação complexa está executando e inicialmente dois elementos de processamento encontram- se em sobrecarga.
Após o mapeamento de mais uma tarefa no nodo 0, são três os elementos de processamento em sobrecarga.
O cálculo de carga é apresentado na Seção 4.10.
As tarefas possuem uma utilização definida por a divisão de seus parâmetros de ocupação ei por seus períodos pi, e a carga do nodo é definida por a soma das utilizações de todas as tarefas da aplicação e do sistema operacional.
Para o nodo 2 a utilização é definida como u2 $= 10 Em a Figura 6.3 é apresentado o perfil de carga da aplicação em duas situações distintas, onde um gerente de migração centralizado é responsável por estabilizar a carga (Figura 6.3 (a)) e outra onde gerentes distribuídos são utilizados (Figura 6.3 (b)).
Como pode ser observado, os gerentes distribuídos conseguem estabilizar a carga dos nodos em menor tempo.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre o tick 100 e 275.
O algoritmo de gerência troca mensagens, toma decisões e realiza 5 migrações em 175 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre o tick 100 e 190, onde 5 migrações são realizadas em 90 ticks.
Após as migrações as cargas dos nodos afetados 2, 3 e 0 são de 58%, 62% e 60% respectivamente no primeiro caso (gerente centralizado) e 61%, 62% e 60% no segundo caso.
Os nodos 4 e 5 recebem as tarefas dos nodos afetados, sendo sua carga final 62% e 52% no primeiro caso e 57% e 38% no segundo.
A Figura 6.4 apresenta o mapeamento inicial (Figura 6.4 (a)) e após (Figura 6.4 (b)) a estabilização do sistema com gerentes distribuídos.
Tarefas de diferentes nodos são identificadas por cores.
Como pode ser observado, o nodo 2 (roxo) tem suas tarefas t6 e t4 migradas para o nodo 5, que encontra- se a um salto de distância na rede.
O nodo 3 (amarelo) tem suas tarefas t7 e t4 migradas para o nodo 4 que também está posicionado a um salto de distância.
Nenhum vizinho a um salto de distância apto a receber tarefas é encontrado por o gerente de migração do nodo 0 (verde), o que faz com que a busca por espalhamento continue.
A dois saltos, o nodo 4 possui tempo de processamento livre para receber e executar a tarefa t3.
As transferências que geram os maiores picos representam as migrações de tarefa.
Comparandose a Figura 6.5 (a) e a Figura 6.5 (b) é possível observar que as transferências relacionadas a migrações acontecem aproximadamente entre os ticks 160 e 260 no primeiro caso e num espaço de tempo menor, aproximadamente entre os ticks 130 e 165 (estão mais próximas umas das outras) no segundo caso com gerentes distribuídos.
Além disso, no segundo caso é observada a ocorrência de duas migrações em paralelo, representada por a sobreposição de tranferências na representação utilizada Nem todas as migrações são concretizadas em todos os casos, pois a modificação do perfil de carga do nodo destino, assim como trocas de mensagem entre o gerente centralizado e tarefas escravas durante uma migração pode fazer com que esta não seja possível em determinado instante (Figura 6.5 (a), vê- se 6 transferências grandes, e apenas 5 migrações efetivadas).&amp;&amp;&amp;
Este tipo de situação pode ocorrer quando existe um número significativo de nodos (para as dimensões do MPSoC) em sobrecarga exatamente no mesmo instante de tempo.
Para evitar situações de sobrecarga adicionais, o processo de migração é cancelado e realizado posteriormente.
O tráfego gerado por as tarefas que compõem a aplicação neste exemplo varia entre 100 Kbps e 700 Kbps aproximadamente e atinge mais de 2000 Kbps em alguns momentos durante migrações.
Um resumo dos experimentos relacionados à primeira aplicação é apresentado na Tabela ao término do tempo de execução seriam perdidos 16 deadlines.
Com o mecanismo de gerência centralizado, as perdas de deadline são reduzidas para 8, e são realizadas 5 migrações.
Com gerentes distribuídos, as perdas de deadline são reduzidas para 5, uma melhoria de 37.50% em comparação ao mecanismo centralizado e são realizadas 5 migrações.
O tempo de estabilização do sistema com gerentes distribuídos apresenta uma melhoria de 48.57% para esta aplicação.
A segunda aplicação sintética é apresentada na Figura 6.6.
Esta aplicação possui suas tarefas iniciais mapeadas num MPSoC com dimensões 4x4, juntamente com tarefas de controle de comunicação e gerentes de migração.
O número de tarefas inicial da aplicação é 36 e os nodos 2, 3, 10 e 11 encontram- se em sobrecarga, com 89%, 94%, 89% e 95% de carga respectivamente.
Em tempo de execução são mapeadas mais duas tarefas, sendo uma no nodo 0 e outra no nodo 8, aumentando carga destes para 76%.
Esta aplicação, assim como a anterior, possui um alto grau de comunicação e como característica as tarefas mapeadas em cada nodo possuem parâmetros pouco semelhantes.
Em o exemplo é ilustrada a situação de sobrecarga numa malha de dimensões médias onde uma aplicação complexa está executando e quatro elementos de processamento encontram- se em situação de sobrecarga inicialmente.
Após o mapeamento dinâmico de tarefas nos nodos 0 e 8, são seis os elementos de processamento em sobrecarga.
As cargas dos nodos afetados 2, 3, 10, 11, 0 e 8 são de 62%, 63%, 58%, 45%, 60% e 66% após as migrações realizadas por o gerente centralizado (Figura 6.7 (a)).
Os nodos 4, 6, 7, 12, 14 e 15 recebem tarefas dos nodos afetados, tendo a carga final de 28%, 55%, 50%, 20%, 23% e 43% respectivamente.
Gerentes distribuídos (Figura 6.7 (b)) realizam a estabilização da carga dos nodos afetados deixando- os com 58%, 62%, 64%, 60% e 66% de utilização respectivamente.
Os nodos 4, 6, 7, 14 e 15 recebem as tarefas migradas neste caso, ficando com 37%, 64%, 60%, 25% e 40% de carga respectivamente.
O perfil de tráfego gerado na rede de interconexão é apresentado na Figura 6.9.
Novamente, as transferências que geram os maiores picos representam as migrações de tarefa.
Comparandose as Figuras 6.9 (a) e 6.9 (b) é possível observar que as transferências relacionadas a migrações acontecem num espaço de tempo menor com gerentes distribuídos.
Estas transferências acontecem entre os ticks 115 e 365 com o mecanismo de gerência centralizado e entre os ticks 105 e 255 com o mecanismo de gerência distribuído.
O tráfego gerado por as tarefas que compõem a aplicação varia entre 100 Kbps e 600 Kbps aproximadamente e atinge mais de 2000 Kbps durante migrações de tarefas.
A Tabela 6.5 apresenta um resumo dos experimentos relacionados à segunda aplicação.
Sem gerência de migração, ao término do tempo de execução seriam perdidos 68 deadlines no total.
Com o mecanismo de gerência centralizado, as perdas de deadline são reduzidas para 14, e 11 migrações são realizadas.
Com gerentes distribuídos, as perdas de deadline são reduzidas para 6, o que representa uma melhoria de 57.14% em comparação ao mecanismo centralizado sendo realizadas 10 migrações.
Em esta aplicação, a estabilização do sistema ocorre com uma redução significativa de tempo ao serem utilizados gerentes distribuídos, com uma melhoria de 41.81%.
A terceira aplicação sintética é apresentada na Figura 6.10.
Para este experimento uma abordagem diferente foi utilizada, e consiste em replicar instâncias da mesma aplicação em MPSoCs com dimensões 3x2, 4x4 e 6x5.
Para estes MPSoCs são alocadas 3, 4 e 7 instâncias desta mesma aplicação respectivamente, ou seja 12, 16 e 28 tarefas.
Este experimento ilustra situações onde diversas aplicações independentes executam num mesmo ambiente.
Em o exemplo, cada instância da aplicação é mapeada num único elemento de processamento sendo sua carga total 100%, composta por a aplicação e o gerente de migração (gerente distribuído, gerente centralizado ou tarefa de migração).
O exemplo aqui ilustrado apresenta uma situação prática de aplicação do modelo proposto, onde apenas é definido um elemento de processamento onde é realizado o mapeamento de todas as tarefas iniciais de uma aplicação.
Por exemplo, um usuário inicia um vídeo numa plataforma multiprocessada hipotética e o decodificador (representado por a aplicação) possui tarefas que são alocadas a um único elemento de processamento inicialmente.
Devido a as necessidades de processamento da aplicação, algumas destas tarefas devem ser realocadas a outros elementos de processamento para que a qualidade de execução esperada seja alcançada (são eliminadas as perdas de deadline, e por consequência, eliminam- se as perdas de frame).
As instâncias de cada aplicação não possuem dependências entre si, e dessa forma o mecanismo de gerência pode explorar o conceito de localidade, que se adapta naturalmente ao modelo de gerentes distribuídos.
Para cada instância, são definidas 4 tarefas, onde as tarefas t4 e t5 recebem dados e dessa forma dependem da tarefa t3 e a tarefa t6 recebe dados de t4 e t5.
Para esta aplicação, são definidas 4 comunicações, com volumes de dados que variam entre 64 e 128 bytes.
Aplicação 3, MPSoC 3x2 A primeira versão da terceira aplicação utiliza uma malha com dimensões 3x2, onde os nodos 0, 3 e 5 possuem uma instância da aplicação cada e encontram- se em sobrecarga.
Em a Figura aplicações anteriores, é evidente uma redução nos tempos de estabilização da carga nas duas abordagens de gerência.
Esta redução deve- se ao fato de uma menor complexidade da aplicação utilizada e menor dependência de comunicação entre tarefas, o que simplifica as decisões dos gerentes.
Observa- se que os gerentes distribuídos conseguem estabilizar a carga dos nodos em menor tempo.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 200, ou seja em 100 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 175, ou seja em 75 ticks.
Em o primeiro caso, são realizadas 5 migrações e no segundo 6 migrações.
O perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência é apresentado na Figura 6.12 para o caso centralizado característica da aplicação) e durante migrações atinge a taxa de 4000 Kbps.
Após as migrações de tarefa, pode- se observar uma mudança no perfil de tráfego com relação a a origem das mensagens.
Inicialmente, os únicos nodos que originam tráfego (interno) são os nodos 0, 3 e 5, que possuem as aplicações e encontram- se em sobrecarga.
Após a migração de tarefas, os nodos 1, 2 e 4 também passam a originar tráfego, fato este que pode ser observado a partir de as primeiras migrações na Figura 6.12 (b) após o tick 100.
Parte do tráfego originalmente direcionado internamente aos nodos passa a ser direcionado para a rede de interconexão, e tarefas migradas que possuem comunicações com tarefas dos nodos origem também passam a transmitir seu tráfego por a rede.
Aplicação 3, MPSoC 4x4 Em a segunda versão da terceira aplicação é utilizada uma malha com dimensões 4x4, estando quatro elementos de processamento em situação de sobrecarga.
Em a Figura) e gerentes distribuídos (Figura 6.13 (b)).
Observa- se que os gerentes distribuídos conseguem estabilizar a carga dos nodos em menor tempo.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 310, ou seja em 210 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 165, ou seja em 65 ticks.
Em os dois casos são realizadas 8 migrações.
Observa- se que os gerentes distribuídos conseguem estabilizar a carga dos nodos em menor tempo.
Com malhas desta dimensão, mesmo aplicações simples como a ilustrada neste exemplo são beneficiadas com o uso de gerentes distribuídos devido a a sua escalabilidade.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 390, ou seja em 290 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 165, ou seja em 65 ticks, praticamente o mesmo tempo dos experimentos anteriores com esta aplicação, independente do tamanho da malha.
Em os dois casos são realizadas 14 migrações.
A Figura 6.16 apresenta o mapeamento inicial verdeazul marinhoroxoamarelovermelhorosaazul claro) são migradas para o nodo 22.
Inicialmente 23 nodos encontram- se desocupados, e após as migrações apenas 13 nodos não executam nenhuma tarefa da aplicação.
A Figura 6.17 apresenta o perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência para o caso centralizado) e distribuído).
O volume de dados gerado por a aplicação mantêm- se entre 100 Kbps e 200 Kbps inicialmente e durante migrações atinge a taxa de 4000 Kbps.
Algumas tarefas perdem deadlines, e após a estabilização o volume de dados da aplicação mantêm- se entre 100 Kbps e 300 Kbps.
Pode- se observar uma mudança no perfil de tráfego com relação a a origem das mensagens e volume de dados após as migrações de tarefas.
Inicialmente, os únicos nodos que originam tráfego (interno) são os nodos 0, 5, 9, 13, 15, 25 e 28 sendo estes os que possuem as aplicações e encontram- se em sobrecarga.
Após a migração de tarefas, todos os nodos que recebem tarefas também passam a originar tráfego, fato este que pode ser observado a partir de as primeiras migrações na Figura 6.17 (b) após o tick para a rede de interconexão.
Em a Tabela 6.6 é apresentado um resumo dos experimentos relacionados à terceira aplicação.
Sem gerência de migração, ao término do tempo de execução seriam perdidos 36 deadlines no primeiro experimento (malha 3x2), 48 no segundo (malha 4x4) e 84 no terceiro (malha 6x5).
Com o mecanismo de gerência centralizado, as perdas de deadline são reduzidas para 10, 20 e 33 nos respectivos experimentos.
Utilizando- se o mecanismo de gerência distribuído, as perdas de deadline são reduzidas para 9 no primeiro experimento, 12 no segundo e 24 (melhoria de 27.27%) no terceiro caso.
O tempo de estabilização é menor com a abordagem distribuída, e os ganhos em comparação a abordagem centralizada são de 25% (malha 3x2), 69.04% (malha 4x4) e 56,66% (malha 6x5).
A quarta aplicação sintética é apresentada na Figura 6.18.
Uma abordagem semelhante à aplicação anterior foi utilizada, e consiste em replicar instâncias da mesma aplicação em MPSoCs com dimensões 3x2, 4x4 e 6x5.
Para estes MPSoCs são novamente alocadas 3, 4 e 7 instâncias desta aplicação, ou seja 27, 36 e 63 tarefas.
Em o exemplo, cada instância da aplicação é mapeada num único elemento de processamento sendo sua carga total 110%, composta por a aplicação e o gerente de migração (gerente distribuído, gerente centralizado ou tarefa de migração).
O exemplo aqui ilustrado apresenta uma situação onde uma aplicação relativamente complexa é mapeada num único elemento de processamento, e diversas migrações devem ser realizadas para que esta possa executar de acordo com seus parâmetros de tempo real.
As instâncias de cada aplicação não possuem dependências entre si.
Tarefas da mesma aplicação, no entanto, possuem maior dependência que na aplicação anterior.
Para cada instância, são definidas 9 tarefas, onde as tarefas t4, t5, t6, t7 recebem dados da tarefa t3, t8 recebe dados de t4, t9 recebe dados das tarefas t3, t4 e t5, t10 recebe dados de t4, t5, t6 e t7 e t11 recebe dados de t8, t9 e t10.
Para esta aplicação, são definidas 15 comunicações, com volumes de dados que variam entre 64 e 1280 bytes.
Aplicação 4, MPSoC 3x2 A primeira versão da quarta aplicação utiliza uma malha com dimensões 3x2, onde os nodos 0, 3 e 5 possuem uma instância da aplicação cada e encontram- se em sobrecarga, assim como na aplicação anterior.
Em a Figura 6.19 são apresentados os perfis de carga ao longo de o tempo onde num caso é utilizado um gerente centralizado) e em outro gerentes distribuídos).
Comparado à aplicação anterior, esta apresenta um aumento nos tempos de estabilização da carga nas duas abordagens de gerência.
O aumento deve- se ao fato de uma maior complexidade da aplicação em virtude de o número de tarefas e dependências de comunicação, uma vez que migrações não podem ser realizadas no instante em que tarefas envolvidas no processo estiverem realizando trocas de mensagem.
Para este exemplo, gerentes distribuídos conseguem estabilizar a carga dos nodos em menor tempo apesar de terem o desempenho bastante comprometido.
O número de dependências em cada aplicação, em conjunto com um número significativo de elementos de processamento sobrecarregados ao mesmo tempo restringe o paralelismo do algoritmo de gerência distribuído, e ele passa a ter um desempenho próximo a o do gerente centralizado.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 340, ou seja em 240 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 305, ou seja em 205 ticks.
Em ambos os casos são realizadas 9 migrações.
Em a Figura Figura 6.20 é apresentado o perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência para o caso centralizado b) após o tick 100.
Parte do tráfego originalmente direcionado internamente aos nodos passa a ser direcionado para a rede de interconexão, e dessa forma tarefas migradas as quais possuem comunicações com tarefas dos nodos origem passam a transmitir seu tráfego por a rede.
Aplicação 4, MPSoC 4x4 Em a segunda versão da quarta aplicação é utilizada uma malha com dimensões 4x4, estando quatro elementos de processamento em situação de sobrecarga.
Em a Figura) e gerentes distribuídos (Figura 6.21 (b)).
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 410, ou seja em 310 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 195, ou seja em 95 ticks e mais uma vez é observada uma redução no tempo de estabilização.
Em os dois casos são realizadas 12 migrações.
Existem diversos elementos de processamento com carga baixa, e desta forma o algoritmo de gerência distribuído consegue establizar o sistema em tempo reduzido.
O perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência é apresentado na Figura 6.22 para o caso centralizado (Figura 6.22 (a)) e distribuído (Figura 6.22 (b)).
O tráfego gerado na rede por as tarefas que compõem a aplicação mantêm- se entre 100 Kbps e 600 Kbps e durante migrações atinge a taxa de 4000 Kbps.
Após as migrações, o tráfego gerado na rede passa a variar entre 100 Kbps e 1200 Kbps.
A partir de o tick 100 observa- se uma mudança no perfil de tráfego da aplicação em virtude de as migrações.
Em o início da execução, apenas os nodos 0, 5, 9 e 15 realizam a geração de tráfego, pois é nestes que estão alocadas as aplicações.
Em virtude de as migrações de tarefa, outros nodos passam a transmitir dados, e o tráfego antes direcionado apenas internamente aos nodos passa por a rede de interconexão devido a as comunicações entre tarefas migradas e tarefas residentes nos nodos de origem.
Aplicação 4, MPSoC 6x5 A terceira versão da quarta aplicação faz uso de uma malha com dimensões 6x5, onde os nodos 0, 5, 9, 13, 15, 25 e 28 encontram- se em sobrecarga.
Em a Figura 6.23 são apresentados os perfis de carga ao longo de o tempo com um único gerente centralizado (Figura 6.23 (a)) e com gerentes distribuídos (Figura 6.23 (b)).
Com malhas desta dimensão, aplicações relativamente complexas como a ilustrada neste exemplo são beneficiadas com o uso de gerentes distribuídos mesmo com muitas dependências entre tarefas.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 375, ou seja em 275 ticks.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 190, ou seja em 90 ticks, o mesmo tempo do experimento anterior com esta mesma aplicação.
Em os dois casos são realizadas 20 migrações.
O mapeamento inicial da aplicação é apresentado na Figura 6.24 (a), e o mapeamento final obtido por os gerentes distribuídos na Figura 6.24 (b).
Em este cenário, as tarefas t5 e t9 do nodo 0 (verde) são migradas para o nodo 1 e t4 para o nodo 6.
As tarefas t8 e t6 do nodo 5 (azul marinho) são migradas para o nodo 4 e t4 para o nodo 11.
O nodo 9 (roxo) tem suas tarefas t10, t5 e t8 migradas para os nodos 3, 8 e 10 respectivamente enquanto o nodo 13 (amarelo) tem suas tarefas t6, t10 e t7 migradas para os nodos 7, 12 e 14.
As tarefas t9, t10 e t4 do nodo 15 (vermelho) são migradas para 14, 16 e 21 enquanto t4, t7 e t6 do nodo 25 (rosa) são migradas para os nodos 19, 24 e 26 respectivamente.
O nodo 28 (azul claro) tem as tarefas t5, t9 e t8 migradas para os nodos 22, 27 e 29.
Anterior às migrações, 23 nodos estão desocupados (sem tarefas da aplicação) e após as migrações, apenas 5 nodos encontram- se nesta situação.
Após a estabilização o volume de dados da aplicação mantêm- se entre 100 Kbps e 1500 Kbps, com o maior número de transferências em torno de 600 kbps.
Pode- se observar uma mudança no perfil de tráfego com relação a a origem das mensagens e volume de dados após as migrações de tarefas.
Inicialmente, os únicos nodos que originam tráfego (interno) são os nodos 0, 5, 9, 13, 15, 25 e 28 sendo estes os que possuem as aplicações e encontram- se em sobrecarga.
Após a migração de tarefas, todos os nodos que recebem tarefas também passam a originar tráfego, fato este que pode ser observado a partir de as primeiras migrações na Figura 6.25 (b) após o tick para a rede de interconexão.
Em a Tabela 6.7 é apresentado um resumo dos experimentos relacionados à quarta aplicação.
Sem gerência de migração, ao término do tempo de execução seriam perdidos 24 deadlines no primeiro experimento (malha 3x2), 32 no segundo (malha 4x4) e 56 no terceiro (malha 6x5).
Com o mecanismo de gerência centralizado, as perdas de deadline são reduzidas para 8, 13 e 18 nos respectivos experimentos.
Utilizando- se o mecanismo de gerência distribuído, as perdas de deadline são reduzidas para 8 no primeiro experimento (sem melhoria), 13 (melhoria de 38.46%) no segundo e 12 (melhoria de 33.33%) no terceiro experimento.
O tempo de estabilização é menor com a abordagem distribuída, e os ganhos em comparação a abordagem centralizada são de 14.58% (malha 3x2malha 4x4) e 67.27% (malha 6x5).
Esta Seção apresenta aplicações reais descritas de acordo com o modelo proposto.
Para estas aplicações, são ilustradas situações onde o desempenho da mesma pode ser beneficiado com o uso de gerentes de migração distribuídos.
Aplicações que possuem requisitos de execução de suas tarefas definidos em tempo de projeto devem ser otimizadas dinamicamente caso não estejam cumprindo com estes requisitos.
Este tipo de situação ocorre caso as necessidades de processamento da aplicação com relação a o tempo de resposta e capacidade não sejam possíveis para todas as tarefas da aplicação com o mapeamento inicial, que pode ser não otimizado.
Em os testes realizados, a aplicação é mapeada inicialmente num único nodo e passa a executar de acordo com seus parâmetros de tempo real a medida que tarefas são migradas para outros nodos com recursos disponíveis.
Em a aplicação MJPEG um pipeline para a de compressão de vídeo é ilustrado, e o grafo que descreve o fluxo de compressão de 16 blocos de 8x8 pixels (32x32 pixels de um frame de vídeo) desta aplicação é apresentado na Figura 6.26.
A tarefa t3 implementa a funcionalidade do bloco RGB2YUV, que tem como finalidade trasformar as três componentes que formam um pixel do espaço de cor RGB para o espaço de cor YUV (luminância e duas crominâncias).
O bloco DCT é implementado na tarefa t4, e realiza a transformada do cossendo sobre os pixels do bloco, obtendo- se coeficientes que podem ser posteriormente comprimidos.
A quantização destes coeficientes é realizada na tarefa t5 a qual representa o bloco QUANT.
Este bloco tem como objetivo diminuir a precisão dos coeficientes, tornando- os altamente redundantes, o que facilita o processo de compressão.
A compressão do conjunto de pixels é realizada por a tarefa t6 que implementa a funcionalidade do bloco VLC do codificador.
Cada bloco possui requisitos como quantidade de dados transmitidos e tempo de processamento, previamente caracterizados.
O bloco RGB2YUV (tarefa t3) possui um tempo de processamento de 88000 ciclos transmite 3072 bytes ao próximo estágio.
O bloco DCT (tarefa t4) utiliza 86352 ciclos, transmitindo 6144 bytes ao próximo bloco.
O próximo estágio, representado por o bloco QUANT (tarefa t5) possui um tempo de processamento de 104144 ciclos e transmite 6144 bytes ao estágio VLC, que comprime o fluxo de dados em 260496 ciclos.
Para a caracterização, os tempos de processamento de cada bloco foram obtidos no trabalho de Ngouanga e foi utilizado um tick de tempo de execução para transmitir cada mensagem entre blocos devido a a sincronização necessária para a identificação global das tarefas, além de um tick adicional de processamento para todas as tarefas, uma vez que nenhuma possui tempo de processamento maior que este valor.
Em o exemplo aqui apresentado, cada tarefa da aplicação foi configurada para executar a cada 10 ticks, e as tarefas dependem do resultado das anteriores.
Em a implementação atual, a primeira tarefa apenas é liberada ao término da última em execuções sucessivas, tornando serial a execução de cada pipeline por fins de simplicidade e para evitar a saturação das filas em software, que possuem um tamanho limitado.
Como cada tarefa da aplicação executa a cada 104ms espera- se que todas completem seu trabalho em aproximadamente 416ms para a obtenção de uma taxa de 2.4 frames por segundo, com 80% de utilização de tempo de segundo, uma vez que o processamento de 16 blocos de 8x8 pixels é totalmente independente nesta implementação.
O sistema encontra- se completamente estabilizado após as migrações a partir de o tick 400 e executa em torno de 26 iterações em 5.5 segundos, alcançando o desempenho de aproximado de 10483633 ciclos por iteração do pipeline ou uma taxa de 4.77 frames por segundo, sendo este o valor esperado em virtude de os parâmetros de configuração e caracterização em tempo de projeto.
Um outro cenário de teste foi criado, onde além de a aplicação MJPEG existem outras tarefas nos nodos previamente disponíveis.
Estas tarefas compõem uma aplicação hipotética, que é apresentada na Figura 6.29.
Esta aplicação também possui um intenso fluxo de comunicação entre suas tarefas além de uma utilização significativa de processamento.
O objetivo deste cenário é demonstrar a possibilidade de migrar tarefas durante a execução de uma aplicação para otimizar o perfil de execução desta definido em tempo de projeto, mesmo num ambiente onde os recursos são compartilhados com outras tarefas.
Em a Figura 6.30 é apresentado o mapeamento da aplicação hipotética e da aplicação MJPEG que é o mesmo do caso anterior onde apenas esta aplicação era alocada.
As tarefas da aplicação hipotética possuem seus próprios parâmetros de tempo real e seu volume de dados, além de compartilhar os canais de comunicação com a aplicação MJPEG.
O mapeamento inicial é ilustrado na Figura 6.30 (a) e o mapeamento final após as migrações na Figura 6.30 (b).
A configuração do sistema e o desempenho da aplicação MJPEG mantida até o tick 300) é a mesma para este caso e o anterior, uma vez que as comunicações entre as tarefas da aplicação ocorrem no mesmo nodo, e não existem outras tarefas executando nestes.
Após as migrações, que ocorrem em aproximadamente 95 ticks inicialmente alocado no nodo 0 inicialmente alocado no nodo 5) passa a ter variável seu desempenho entre 7862252 ciclos e 13105096 ciclos.
Esta variação, no entanto, não influência no desempenho final da aplicação MJPEG, que mantém uma taxa de 4.77 frames por segundo mesmo com outra aplicação executando em paralelo no sistema.
Os módulos da aplicação correspondem às seguintes tarefas:
Demux (t3), variable length decoder (t4), run length decoder (t5), inverse scan (t6), AC/ DC prediction (t7), inverse quantizer, inverse cossine transform, up sample, VOP reconstruction, padding, VOP memory, up sample 2, reference memory, downsample and context calculation, arithmetic decoder, memory e stripe memory.
As tarefas t4 (variable length decoder arithmetic decoder) definem o início de caminhos independentes dentro de o pipeline.
Novamente, por questões de simplicidade e com o intuito de evitar a saturação das filas em software devido a seu tamanho limitado, cada iteração sucessiva de execução do pipeline ocorre após o término da anterior.
Todas as tarefas da aplicação executam a cada 104ms, e num pior caso onde cada tarefa dependesse do resultado da tarefa anterior o término de uma iteração deveria ocorrer em até 1781ms.
Obviamente este não é o caso da aplicação, tendo em vista os dois caminhos paralelos do pipeline.
O tempo de uma iteração não pode ser reduzido por a metade, no entanto, devido a alguns ciclos existentes no fluxo de execução da aplicação.
Todas as tarefas da aplicação alocadas a um único nodo correspondem a 340% de utilização com os parâmetros configurados.
Cada tarefa da aplicação utiliza 20% de tempo de processador, e dessa forma não é possível alocar mais do que duas tarefas por nodo, sem exceder os limites de utilização.
Os mapeamentos inicial e final da aplicação VOPD caracterizada com os parâmetros descritos num MPSoC 4x4 são apresentados na Figura 6.33.
Em este cenário, todas as tarefas da aplicação são mapeadas no nodo 5 (Figura 6.33 (a)).
Este encontra- se em sobrecarga, e o gerente de migração realiza 15 migrações para nodos vizinhos utilizando o algoritmo de espalhamento.
Como previsto, são alocadas no máximo duas tarefas por nodo devido a os limites de utilização (Figura O posicionamento das tarefas nos nodos é dependente dos parâmetros de caracterização.
Se o limite de utilização fosse maior que 69%, mais tarefas poderiam ser alocadas num mesmo nodo respeitando as restrições de tempo real com os parâmetros utilizados.
Mais tarefas poderiam ser alocadas também no caso de a utilização de cada tarefa ser menor.
Se as tarefas fossem configuradas com parâmetros de tempo real mais estritos (por exemplo, com período de 52ms e capacidade de 2 ticks), apenas uma tarefa da aplicação poderia ser alocada por nodo.
Uma situação interessante ocorre na execução da aplicação com o mapeamento inicial.
A carga do nodo 5 é tão alta que apenas algumas tarefas executam inicialmente, e o pipeline de decodificação VOP é mantido bloqueado.
O restante das tarefas, devido a as perdas de deadline não chegam a executar nenhuma vez, e dessa forma o sistema operacional sequer conta sua ocupação.
À medida que tarefas são migradas, momentaneamente a carga do nodo 5 cai e rapidamente sobe pois tarefas com a execução anteriormente bloqueadas passam a executar, apesar de as perdas de deadline.
Esta situação pode ser observada na Figura 6.34 (a) do tick 100 (início do algoritmo de gerência) até o ponto em que todas as tarefas são migradas, o que ocorre no tick 450.
A partir de o tick 450 a aplicação tem todas as suas tarefas mapeadas definitivamente, e uma iteração do pipeline é executada em aproximadamente 36697866 ciclos, ou 1468ms, um valor muito próximo a o esperado como pior caso.
As transferências de dados entre as tarefas são ilustradas na Figura 6.34 (b).
O segundo cenário criado para a aplicação VOPD faz uso de um MPSoC 6x5, onde quatro instâncias do pipeline de decodificação VOP são alocados.
Todas as tarefas de um mesmo pipeline são inicialmente alocadas num único nodo.
Em este cenário, a configuração de todas as tarefas da e como a utilização destas é um pouco menor, até três tarefas desta aplicação podem ser alocadas a cada elemento de processamento em conjunto com as tarefas do sistema operacional, totalizando uma carga de 65%.
Todas as tarefas da aplicação executam a cada 115ms, e num pior caso onde cada tarefa dependesse do resultado da tarefa anterior o término de uma iteração de cada instância do pipeline deveria ocorrer em até 1960ms.
As 17 tarefas de cada instância correspondem a 309% de utilização em cada um dos nodos.
Os mapeamentos inicial e final da aplicação VOPD caracterizada com os parâmetros descritos num MPSoC 6x5 são apresentados na Figura 6.35.
Em este cenário, são mapeados pipelines independentes nos nodos 7, 10, 24 e 29 (Figura 6.35 (a)).
Estes encontram- se em sobrecarga, e os gerentes de migração realizam 56 migrações para nodos vizinhos utilizando o algoritmo de espalhamento.
Como previsto, são alocadas no máximo três tarefas por nodo devido a os limites de utilização e configuração das tarefas (Figura 6.35 (b)).
A Figura 6.36 apresenta a carga do MPSoC ao longo de o tempo para dois casos distintos, onde no primeiro um gerente de migração centralizado é utilizado (Figura 6.36 (a)) e no segundo gerentes distribuídos.
Esta aplicação, que consiste num grande número de tarefas e um MPSoC de grandes dimensões deixa clara uma maior eficiência de gerentes distribuídos.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 1300 ou seja em 1200 ticks, aproximadamente 12.576 s.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 500 ou seja em 400 ticks, aproximadamente 4.192 s.
Em os dois casos são realizadas 56 migrações.
A partir de o tick 500 (Figura 6.36 (b)) a aplicação tem todas as suas tarefas mapeadas definitivamente, e uma iteração de cada um dos pipelines é executada em aproximadamente 40367871 ciclos, ou 1614ms, um valor muito próximo a o esperado como pior caso (1960ms, não considerando o paralelismo de execução do fluxo nem os ciclos no grafo).
Em a Figura 6.37 é apresentado o perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência para o mecanismo centralizado (Figura 6.37 (a)) e distribuído (Figura 6.37 (b)).
Inicialmente, em virtude de as perdas de deadline, a aplicação basicamente não realiza a transferência de dados.
Após a estabilização, o volume de dados da aplicação mantêm- se entre 100 kbps e 700 kbps (gerente centralizado) e entre 100 Kbps e 900 Kbps (gerentes distribuídos).
A diferença deve- se ao posicionamento das tarefas no MPSoC, que não é o mesmo para os dois casos.
Observa- se que a aplicação apenas começa a executar após as migrações de tarefa, que ocorrem em menor tempo no caso de os gerentes distribuídos.
O comportamento de módulos de hardware e software de um codificador MPEG4 descrito por Milojevic é simulado nesta aplicação.
Novamente, apenas as taxas de transferência de dados são especificados para cada módulo, e dessa forma modelou- se o processamento de maneira semelhante às aplicações anteriores.
Em esta aplicação, cada tarefa representa um módulo, e todas as tarefas foram configuradas para executarem a cada 115ms.
São utilizados 2 ticks de tempo de execução por tarefa, onde um é reservado para a transferência de dados e outro para o processamento.
Para esta aplicação são utilizadas quatro instâncias do pipeline de codificação MPEG4 num MPSoC 6x5.
Todas as tarefas de um mesmo pipeline são inicialmente alocadas num único nodo.
Cada tarefa da aplicação possui uma utilização de 18.18%, e desta forma até três tarefas podem ser alocadas a cada elemento de processamento em conjunto com as tarefas do sistema operacional, totalizando uma carga de 65%.
As tarefas da aplicação executam a cada 115ms, e num pior caso onde cada tarefa dependesse do resultado da tarefa anterior o término de uma iteração de cada instância do pipeline deveria ocorrer em até 2075ms (não considerando os ciclos nem o paralelismo no pipeline72 tarefas da aplicação no total) correspondem a 327% de utilização em cada um dos nodos ocupados.
Os mapeamentos inicial e final da aplicação MPEG4 caracterizada com os parâmetros descritos num MPSoC 6x5 são apresentados na Figura 6.39.
Em este cenário, são mapeados pipelines independentes nos nodos 7, 10, 24 e 29).
Estes encontram- se em sobrecarga, e os gerentes de migração realizam 60 migrações para nodos vizinhos utilizando o algoritmo de espalhamento.
São alocadas no máximo três tarefas por nodo devido a os limites de utilização e configuração das tarefas).
A Figura 6.40 apresenta a carga do MPSoC ao longo de o tempo para os casos onde um gerente de migração centralizado é utilizado) e outro onde são utilizados gerentes distribuídos.
Esta aplicação, que consiste num grande número de tarefas e um MPSoC de grandes dimensões apresenta novamente uma maior eficiência dos gerentes distribuídos.
O tempo de estabilização no primeiro cenário (gerente centralizado) acontece entre os ticks 100 e 1380 ou seja em 1280 ticks, aproximadamente 13.414 s.
Em o segundo cenário (gerentes distribuídos) a estabilização ocorre entre os ticks 100 e 700 ou seja em 600 ticks, aproximadamente 6.288 s.
Em os dois casos são realizadas 60 migrações.
A partir de o tick 700) a aplicação tem todas as suas tarefas mapeadas definitivamente, e uma iteração de cada um dos pipelines é executada em aproximadamente 57669496 ciclos, ou 2306ms.
Em a Figura 6.41 é apresentado o perfil de tráfego gerado por a aplicação e em decorrência das migrações e trocas de mensagem de gerência para o mecanismo centralizado) e distribuído).
Inicialmente, em virtude de as perdas de deadline, a aplicação basicamente não realiza a transferência de dados.
Após a estabilização, o volume de dados da aplicação mantêm- se entre 100 kbps e 1500 kbps.
Um resumo de experimentos realizados com a aplicação MPEG4 num MPSoC 6x5 é apresentado na Tabela 6.9.
Sem gerência de migração, ao término do tempo de execução seriam perdidos 9292 deadlines.
Com o mecanismo de gerência centralizado, as perdas de deadline são reduzidas para 2383 e utilizando- se o mecanismo de gerência distribuído, as perdas mantêm- se em 1288, o que representa uma melhoria de 45.95%.
O tempo de estabilização é menor com a abordagem distribuída, e o ganho em comparação a abordagem centralizada para esta aplicação é de 53.12%.
Em a Tabela 6.10 é apresentado um resumo dos experimentos realizados com relação a gerência de migração.
Em os casos apresentados, foram ilustradas situações onde múltiplos nodos encontram- se em sobrecarga em diferentes malhas e em diferentes cenários.
Buscou- se nestes experimentos destacar as vantagens da utilização de gerentes distribuídos neste tipo de aplicação.
Experimentos onde apenas um nodo encontra- se em sobrecarga são apresentados na Tabela a aplicação MJPEG o nodo 0 e as aplicações VOPD e MPEG4 o nodo 5.
Observa- se que neste tipo de situação, a abordagem distribuída não apresenta uma melhoria significativa sobre a abordagem centralizada para aplicações com um pequeno número de tarefas.
As aplicações VOPD e MPEG4, por terem um número significativo de tarefas e diversas dependências entre estas, possuem um melhor desempenho com a abordagem distribuída.
Em estes casos, o número de mensagens necessário para sincronizar o gerente centralizado com as tarefas escravas aumenta o tempo de estabilização, e consequentemente influência nas perdas de deadline.
Métodos gulosos podem ser eficientemente utilizados para a resolução de alocação de recursos em ambientes MPSoC com um grande número de elementos de processamento ou tarefas.
O modelo proposto faz uso do conceito multitarefa, e dessa forma o problema de migração e mapeamento de tarefas torna- se ainda mais complexo quando comparado a modelos monotarefa.
Algoritmos comumente utilizados para a resolução do problema de mapeamento de tarefas de forma estática, tais como o Simulated Annealing, tendem a ter altos tempos de computação e mesmo com otimizações tornam- se proibitivos para uso em aplicações dinâmicas.
As desvantagens de métodos gulosos estão relacionadas principalmente ao fato da não existência de uma solução ótima de mapeamento, pois busca- se otimizar a solução progressivamente e não de maneira global.
Além disso é impossível prever a alocação de recursos de aplicações dinâmicas em tempo de projeto.
Este tipo de solução, no entanto, possui uma complexidade computacional reduzida e pode ser aplicada em sistemas com um grande número de tarefas sem ocasionar em longos tempos de execução nas tomadas de decisão.
Com relação a os experimentos realizados, foram apresentadas duas soluções para o gerenciamento de migrações sendo uma de elas voltada ao modelo de gerência centralizado, e outra ao modelo de gerência distribuído.
O modelo centralizado ilustrado nos resultados é apenas uma das formas de se implementar tal solução.
A implementação adotada para o mecanismo centralizado faz uso de um gerente mestre e tarefas escravas em outros nodos da arquitetura, e foi feita desta forma pois adapta- se aos modelos de tarefa e arquitetura propostos.
A principal desvantagem encontrada no uso de um gerente centralizado está relacionada às trocas de mensagem necessárias para manter atualizada a informação de todos os nodos.
O desempenho desta solução é agravado com o aumento do número de nodos e em virtude de a modificação do perfil de execução das tarefas, devido a a modificação dos seus parâmetros ou a entrada e saída de tarefas no sistema.
De essa forma, a solução de gerência de migração centralizada tende a ser pouco escalável neste tipo de sistema.
Gerentes distribuídos mostram- se mais eficientes para um grande número de tarefas e elementos de processamento, uma vez que trocas de mensagem entre gerentes tornam- se necessárias apenas em situações de sobrecarga, ou seja, em momentos onde há a necessidade de serem realizadas migrações de tarefa.
Além disso, por serem independentes, diversas migrações podem ocorrer em paralelo em áreas distindas do sistema MPSoC sem serem afetadas por o número de elementos de processamento ou tarefas.
O mecanismo de gerência distribuído perde eficiência no momento em que são necessárias muitas iterações do algoritmo devido a a não disponibilidade de recursos em nodos próximos.
Este tipo de situação é mais clara em MPSoCs altamente sobrecarregados, como é o caso das aplicações sintéticas 3 e 4 com malhas de dimensões 3x2, onde 50% dos elementos de processamento encontram- se sobrecarregados exatamente ao mesmo tempo.
Foi observado que com apenas um único nodo em sobrecarga, ambas abordagens possuem um desempenho semelhante tanto em tempo de estabilização quanto em perdas de deadline para aplicações com um número reduzido de tarefas.
A medida que o número de nodos em sobrecarga aumenta, e a medida em que existam nodos com carga livre na vizinhança dos pontos de sobrecarga, a abordagem distribuída mostra- se mais eficiente.
Em virtude de as observações realizadas, para a abordagem distribuída não importa o número de nodos num MPSoC, mas sim o quão próximo recursos de processamento livre podem ser encontrados.
A o estarem próximos (distância em saltos) os elementos de processamento com carga livre suficiente para receberem tarefas de um nodo sobrecarregado, menos mensagens de gerência são necessárias e dessa forma o algoritmo termina em tempo reduzido.
Acredita- se que o número de elementos de processamento em sistemas MPSoC tende a crescer, e dessa forma será mais comum que ocorram situações onde mais de um nodo encontra- se em sobrecarga em sistemas dinâmicos.
Apesar disso, devido a o grande número de elementos de processamento é provável que existam recursos disponíveis neste mesmo MPSoC para executar a aplicação, bastando para isso modificar o seu mapeamento.
O modelo proposto assume a execução de tarefas utilizando o conceito de tempo real, e dessa forma supõe- se que devam ser mantidos os critérios de ordem de execução, melhoria na execução da aplicação em casos de sobrecarga e redução nas perdas de deadline e por isso o modelo de gerentes distribuído mostra- se mais adequado que o modelo centralizado, pois nos casos avaliados a estabilização do sistema ocorre em menor tempo.
Em este Capítulo são apresentadas inicialmente as contribuições do presente trabalho e publicações relacionadas a este.
Após, as conclusões são expostas e pontos relacionados a trabalhos futuros são enumerados.
Contribuições As contribuições relacionadas ao presente trabalho podem ser descritas como:·
Revisão do estado da arte -- A primeira contribuição do presente trabalho refere- se à investigação de trabalhos relacionados com o tema proposto e classificação destes.
São investigados trabalhos sobre o mapeamento de tarefas (estático e dinâmico) e migração de tarefas, e a partir de sua classificação foi possível observar as lacunas existentes no estado da arte.·
Definição de um modelo de tarefas e arquitetura -- A segunda contribuição diz respeito à definição de um modelo de tarefas com parâmetros de tempo real e organização MPSoC para a execução de aplicações multitarefa.
O modelo de tarefas apresentado ataca pontos pouco explorados por outros trabalhos, como tempo real e caracterização das tarefas que compõem a aplicação.
Com relação a o modelo de arquitetura, foi proposta uma solução homogênea.·
Gerentes distribuídos -- A terceira contribuição refere- se à definição de mecanismos para a implementação de gerentes distribuídos.
A gerência de migração não restringe- se apenas às tomadas de decisão sobre o destino das tarefas a serem migradas, mas também aos protocolos de controle de comunicação e processo de migração de maneira coordenada.
Foi apresentado o protocolo para controle de comunicação para tarefas com identificação global, o protocolo utilizado por a primitiva de migração para a realização do processo e o algoritmo de espalhamento para a seleção de alvos de migração utilizado por os gerentes.
Uma característica única relacionada ao modelo de tarefas e gerentes de migração é a migração de tarefas sem a necessidade de definição de pontos de migração.·
Implementação de um sistema operacional preemptivo de tempo real e gerentes de migração distribuídos -- A quarta contribuição deste trabalho diz respeito à implementação dos modelos propostos num sistema operacional (Hellfire Os).
Um conjunto extenso de algoritmos foi implementado em módulos, e a união destes módulos permitiu a construção de um kernel com suporte a uma grande quantidade de serviços para aplicações de tempo real.
Os principais módulos podem ser enumerados como:
Camada de abstração de hardware;
Kernel; Escalonador de tarefas multinível;
Alocador de memória;
Biblioteca padrão ANSI C e biblioteca de ponto flutuante;
Mecanismos de exclusão mútua;
Subsistema de trocas de mensagem e drivers para NoC;
Gerentes de migração.·
Extensão de uma ferramenta de simulação -- A quinta contribuição refere- se à extensão da ferramenta de simulação N-MIPS para adaptar- se ao modelo de arquitetura proposto.
Esta ferramenta utiliza anotações do hardware para emular o comportamento de um ambiente MPSoC completo baseado em NoC além de estimar o tempo de execução de aplicações multiprocessadas.
Publicações· Magalhães, Felipe;
LONGHI, Oliver;
JOHANN, Sergio F.;
Aguiar, Alexandra;
Hessel, (ISQED), 2012.
V. 1.
P. 1-7.·
ANTUNES, Eduardo B.;
Soares, Matheus;
JOHANN, Sergio F.;
Aguiar, Alexandra;·
ANTUNES, Eduardo B.;
Aguiar, Alexandra;
JOHANN, Sergio F.;
Sartori, Marcos;·
Aguiar, Alexandra.;
JOHANN, Sergio F.;
MAGALHAES, Felipe.;
CASAGRANDE, Thiago.
Design. Los Alamitos:
IEEE, 2010.
V. 1.
P. 730-737.
Prototyping (RSP).
Los Alamnitos: IEEE Computer Society, 2008.
V. 1.
P. 27-33.
Conclusões Sistemas que fazem uso de arquiteturas heterogêneas apresentam uma série de vantagens, como especialização dos elementos de processamento para determinado domínio e redução no consumo de energia.
Apesar de estas vantagens, foi identificado que a maioria dos trabalhos encontrados na literatura utilizam o modelo homogêneo.
As principais justificativas para a contínua utilização deste modelo são:
Transferência da complexidade para o software;
Facilidade no reuso de componentes de hardware e redução no tempo de projeto;
Flexibilidade da arquitetura para diferentes aplicações.
Com relação a o tipo de mapeamento empregado, existe uma grande quantidade de trabalhos na literatura que abordam tanto o mapeamento estático quando o mapeamento dinâmico e migração de tarefas.
Sistemas dinâmicos, no entanto, têm recebido atenção especial nos últimos anos, algo que pode ser observado em virtude de o crescente número de trabalhos relacionados a esta abordagem.
Muitos dos trabalhos encontrados na literatura, utilizam o conceito de gerente centralizado para realizar migrações ou o mapeamento de tarefas.
Entre as vantagens desta abordagem estão a facilidade de manter o estado global do sistema, menor complexidade de implementação e possibilidade de avaliar o estado de todo o sistema.
As desvantagens são a concentração de todo o fluxo de mensagens de gerência para uma única região da rede, ponto único de falha e impossiblidade de realizar diversas migrações ou mapeamentos de maneira paralela.
Ainda, com o aumento do número de processadores em arquiteturas MPSoC atuais, a utilização de um único gerente tende a ser pouco escalável.
A principal proposta do presente trabalho é contribuir para a área de mapeamento dinâmico distribuído e migração de tarefas em sistemas MPSoC homogêneos.
Em este trabalho, um modelo de tarefas e gerentes distribuídos foi proposto.
Tal modelo emprega conceitos de tempo real que mostrase relevante para um conjunto grande de aplicações embarcadas.
Além disso, o gerenciamento distribuído também proposto objetiva a redução no tempo de migrações em sistemas com um grande número de elementos de processamento e tarefas, sendo crescente o emprego este tipo de sistema em aplicações atuais.
Trabalhos Futuros Em esta Seção são enumeradas algumas sugestões para trabalhos futuros.·
Integração do framework CAFES ao framework de desenvolvimento de software do Hellfire Os.
Parâmetros de caracterização das tarefas podem ser convertidos para ocupação de processamento (já existente no CAFES) de maneira relativamente fácil utilizando políticas de escalonamento estáticas.
De essa forma, o particionamento e mapeamento inicial podem ser realizados de maneira automatizada.·
Implementação de heurísticas para a redução do número de migrações de tarefas.
Podem ser levadas em consideração características dos nodos vizinhos e escolhas relacionadas à seleção das tarefas a serem migradas.·
Implementação de heurísticas que levem em consideração as dependências entre tarefas com o objetivo de aproximar tarefas comunicantes, reduzindo o uso dos canais de comunicação, saturação dos canais e consumo de energia.
Estas heurísticas poderiam melhorar a abordagem do algoritmo de espalhamento que realiza estas otimizações porém de maneira ingênua.·
Migração de tarefas que alocam memória dinamicamente em nível de aplicação.
Poderia- se manter uma lista de alocações, ou ponteiros para regiões de memória alocadas por determinada tarefa.
Com base nesta lista, alocar no nodo destino da migração as regiões de memória com os mesmos tamanhos, e durante a migração copiar cada uma destas para o nodo destino, da mesma forma como é atualmente feito com a pilha das tarefas.·
Redefinição dos modelos de energia atualmente implementados no simulador N-MIPS e integração destes modelos no sistema operacional.
Será necessário caracterizar a arquitetura para diferentes tecnologias.·
Inclusão de módulos DMA entre os elementos de processamento e interface de rede, com o intuito de reduzir o overhead do sistema operacional em trocas de mensagem.·
Extensão da ferramenta de simulação para incluir o conceito de GALS, além de outros tipos de elemento de processamento.·
Investigação de mecanismos de migração de tarefas e mapeamento dinâmico em sistemas heterogêneos ou heterogêneos com um ISA que pode ser extendido.
Elementos de processamento com um conjunto reduzido de registradores também é uma possibilidade.
Atualmente, já é possível realizar a compilação da aplicação e do sistema operacional para um conjunto reduzido de registradores, e esta aplicação e sistema operacional executam normalmente numa versão completa do elemento de processamento, ou numa versão com a metade do número de registradores (com uma perda de desempenho relativamente baixa).
