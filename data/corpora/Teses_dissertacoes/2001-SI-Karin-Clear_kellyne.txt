Data Warehouses (DWs) lidam com uma grande quantidade de dados e, devido a este alto volume de dados que é manipulado e agregado nas consultas, costumam- se enfrentar problemas com o tempo de resposta.
Uma técnica comum encontrada para otimização dessas consultas é o uso de agregados pré-computados, porém, a utilização desses agregados deve ser transparente para os usuários do DW.
Para que isso seja possível, é necessária a criação de um mecanismo de redirecionamento de consultas consciente dos agregados.
A presente dissertação de mestrado apresenta um mecanismo de redirecionamento de consultas a dados agregados em ambientes de DW.
Este mecanismo compreende um algoritmo de redirecionamento o qual reformula as consultas submetidas de forma transparente ao usuário do DW, bem como os metadados necessários à reformulação.
A principal contribuição deste mecanismo, em relação a outros existentes, é a sua habilidade para tratar esquemas multidimensionais do tipo estrela com múltiplas tabelas de fatos.
Palavras-Chave: Data warehouse, Agregados, Mecanismo de redirecionamento de consultas, Metadados.
Um data warehouse (DW) é um típico sistema de apoio à decisão (SAD), que surgiu para lidar com o grande volume de dados existentes atualmente nas organizações.
Como Kimball et al Definem, um DW é uma fonte de dados consultável do empreendimento.
O processamento analítico online ou OLAP (on-line analytical processing) constitui- se do tipo de processamento e das ferramentas voltadas para análise típica de DW.
As OLAP, os quais possuem capacidades analíticas e envolvem consultas interativas aos dados.
Para facilitar análises complexas e a visualização de seus resultados, os dados num DW são, tipicamente, modelados multidimensionalmente.
A modelagem dimensional (Md) busca apresentar os dados de uma organização num ambiente padrão que seja intuitivo e permita um acesso de alto desempenho.
A idéia fundamental da Md, é que todos os tipos de dados de um negócio podem ser representados como um tipo de cubo, cujas células contêm valores mensuráveis e os limites do cubo definem as dimensões dos dados.
O esquema estrela é o mais utilizado na modelagem dimensional, sendo o mesmo composto de uma tabela de fatos circundada por várias tabelas dimensionais (dimensões).
A exploração dos dados em DWs é feita por os usuários através de operações (e.
g drills), ferramentas e aplicações projetadas para esse fim, e que tipicamente exploram a estrutura multidimensional dos dados.
As principais operações de navegação num sistema OLAP são:·
Slice- dice ­ consiste em mudar a ordem das dimensões;·
Drill-down ­ é a forma de pedir mais detalhes;·
Drill-up ­ operação contrária ao drill-down;·
Alguns outros tipos de &quot;drill».
Embora uma das grandes diferenças entre os sistemas transacionais tradicionais (OLTP -- online transaction processing) e os sistemas OLAP seja o tamanho de suas bases de dados, 2 Introdução esta não é a única característica que distingue esses tipos de sistema.
Também existem diferenças na forma com que as atualizações e consultas são realizadas e a quantidade de dados envolvidos nas consultas.
Consultas em SADs podem ser divididas em duas classes· Consultas intensivas em dados (data-intensive) -- que acessam um número grande de registros, não importando se eles são recuperados através de índices ou buscas por toda a tabela.·
Consultas seletivas sobre dados (data-selective) ­ tipicamente envolvem menos registros, mas contêm critérios de seleção complexos e diversos.
Os usuários típicos do negócio tendem a utilizar esses tipos de consultas da seguinte forma:
O uso de índices ajuda as consultas data-selective, mas a melhora de desempenho em consultas data-intensive requer métodos para acessar uma grande quantidade de dados de forma rápida e consistente.
Duas estratégias podem ser utilizadas para reduzir o tempo de acesso a um grande número de registros:·
Particionamento, que é a técnica que divide a base de dados em base menores.
Por exemplo, cada base pode representar um certo período de tempo, ou a base pode ser dividida de acordo com as necessidades de certos usuários ­ similar à idéia de data mart.
O particionamento permite a redução do número de registros que o sistema precisa processar;·
Agregação, que pré-calcula os fatos necessários para que o sistema acesse menos registros.
Enquanto que em bases de dados para sistemas OLTP evita- se o uso e manutenção de tabelas derivadas ­ compostas de dados que podem ser encontrados em outras tabelas, esta abordagem é bastante interessante em sistemas OLAP, pois a mesma provê respostas mais rápidas tanto para consultas data-selective como data-intensive.
Enquanto as consultas dataselective podem achar os registros que necessitam nas tabelas originais, de menor granularidade, as consultas data-intensive podem buscar seus resultados em tabelas agregadas (i.
e pré-calculadas a partir de as originais), desta forma ganhando tempo no processamento da consulta.
Como DW tratam com um grande volume de dados, se as consultas mais interessantes a dados contendo agregação puderem ser armazenadas no warehouse, consultas subseqüentes poderão ser calculadas mais rapidamente, porque elas não precisarão acessar sempre os dados originais para poder responder as consultas.
Assim, o uso de tabelas agregadas vem ao encontro de o problema de desempenho enfrentado nos sistemas OLAP existentes.
Contudo, o uso de agregados pré-computados exige para sua implantação uma estratégia adequada aos usuários deste DW.
Um exemplo sobre a utilização de agregados é ilustrado em, onde um DW foi projetado para apoiar vários escritórios de uma empresa distribuídos por o país:
&quot;Depois de desenvolvido o DW, a equipe do projeto resolveu pré-computar valores sumarizados para suas seleções mais comuns no intuito de aumentar o desempenho.
Eles decidiram construir alguns agregados e armazenar- los em tabelas separadas, e os usuários foram ensinados a utilizar essas tabelas para cada tipo de consulta.
A o apresentar este exemplo, Inmon et al Tentam convencer que a utilização de tabelas agregadas não pode ser considerada uma boa idéia.
Porém, o problema enfrentado nesse estudo de caso foi a estratégia adotada para uso desses agregados:
Os usuários tiveram que ser treinados para que pudessem se beneficiar da utilização dos agregados, já que a responsabilidade de chamar o agregado específico na consulta SQL ficava a cargo de o usuário do sistema.
Um redirecionador de consultas é um serviço que interpreta uma consulta recebida, verifica os metadados para identificar onde as tabelas necessárias estão localizadas e, então redireciona a consulta a seus componentes adequadamente.
Um redirecionador de consultas com consciência de agregados, também chamando de navegador de agregados em, é um caso especial de redirecionamento de consultas que reconhece quando uma consulta pode ser satisfeita por uma tabela agregada, ao invés de realizar todos os cálculos em cima de as tabelas originais.
Em este caso, há a escolha automática dos agregados mais adequados e reformulação da consulta em termos destes, de forma transparente ao usuário.
A existência de um mecanismo de redirecionamento de consultas com consciência de agregados provê transparência na escolha e processamento da tabela agregada mais adequada para responder a consulta submetida, facilitando a navegação dos usuários através dos dados do DW, já que os mesmos não precisam tomar conhecimento dos agregados existentes para tirar proveito dos seus benefícios.
De entre os trabalhos estudados sobre redirecionamento de consultas a dados agregados não apresentaram soluções que abordassem o uso de múltiplas tabelas de fatos num DW, abordagem bastante comum em organizações que implantam DW a partir de a idéia de vários data marts distribuídos.
Além disso, esses trabalhos não costumam apresentar uma solução completa para um mecanismo de redirecionamento de consultas consciente de agregados que demonstre quais os metadados necessários para o funcionamento do redirecionador e os algoritmos utilizados no redirecionamento em si.
Desta forma, o presente trabalho propõe a modelagem e construção de um redirecionador de consultas a data warehouses que permita aos usuários-finais desse ambiente, obter melhoras no desempenho das suas consultas.
Esse mecanismo de redirecionamento é responsável por a escolha e processamento do agregado mais adequado para responder a consulta submetida por o usuário sem que o mesmo conheça esses agregados ­ critério transparência.
Ele compreende um algoritmo de redirecionamento o qual reformula as consultas submetidas de forma transparente ao usuário do DW, bem como os metadados necessários à reformulação.
A principal contribuição deste mecanismo, em relação a outros existentes, é a sua habilidade para tratar esquemas multidimensionais do tipo estrela com múltiplas tabelas de fatos.
Assim, espera- se que com a construção deste mecanismo de redirecionamento, as consultas a sistemas OLAP tenham uma melhora de desempenho, dentro de o critério transparência, satisfazendo de uma forma mais efetiva os usuários do DW.
Também, esperase que esses usuários utilizem mais o DW já que as suas consultas poderão ser respondidas num menor tempo hábil, sem qualquer preocupação com a escolha do agregado.
Para que seja possível o uso de agregados por um mecanismo de redirecionamento, é necessária a existência de uma estratégia de criação desses agregados de modo que haja um balanceamento entre os gastos em armazenamento e o tempo tomado nas atualizações com o ganho de desempenho.
Outro aspecto que deve ser considerado é a forma com que as consultas com funções de agregação serão redirecionadas e, para isso, é preciso existir uma maneira de representar as tabelas agregadas e como elas se relacionam com os dados base do DW.
Em este intuito, foram realizados estudos na área de criação, representação e redirecionamento de consultas a tabelas agregadas.
O restante desta dissertação está estruturada da seguinte forma:
Em o capítulo a seguir, serão apresentados os conceitos básicos sobre a tecnologia de DW, com foco centrado em agregados, tendo uma preocupação em mostrar o porquê da sua utilização, que critérios podem ser utilizados para sua criação, os trabalhos relacionados às estratégias de redirecionamento de consultas e as formas de representação dos agregados.
Algumas ferramentas OLAP que provêem o uso de agregados também são analisadas.
Em o capítulo 3 é mostrada a proposta do mecanismo de redirecionamento de consultas, contando com a descrição do algoritmo de redirecionamento, a forma com que os agregados serão representados e aspectos relacionados ao protótipo do redirecionador.
O estudo de caso utilizado para a validação do mecanismo de redirecionamento é apresentado no capítulo 4.
As considerações finais e trabalhos futuros aparecem descritos no capítulo 5.
Este capítulo provê uma visão geral sobre a tecnologia de DW e agregados (no escopo dessa tecnologia).
São descritos os termos básicos relacionados à DW, como:
Modelagem dimensional, sistemas OLAP e exploração dos dados;
E relacionados a agregados, levando em consideração a sua utilização em ambientes de DW.
Para isto, serão descritos alguns trabalhos relacionados à criação de agregados e redirecionamento de consultas em ambientes de DW que contêm tabelas agregadas.
Relacionado a este último assunto, foram estudados trabalhos focados nas estratégias de redirecionamento de consultas e como os agregados podem ser representados.
A o final do capítulo, são examinadas algumas ferramentas que provêem algum mecanismo para gerência de agregados, bem como as conclusões sobre os estudos efetuados.
Um data warehouse, na visão de, é um banco de dados analítico usado como fundamento para os SADs.
Ele é desenvolvido para grandes volumes de dados de somente leitura, provendo acesso intuitivo para informações que devem ser usadas para tomada de decisões.
DW também pode ser definido como uma coleção de tecnologias de apoio à decisão, com o propósito de possibilitar aos que trabalham com conhecimento (executivos, gerentes, analistas) ter decisões melhores e mais rápidas.
Segundo, um data warehouse é uma coleção de dados que tem por objetivo dar apoio aos processos de tomada de decisão e tem as seguintes características:
Não-volátil: Os dados são apenas para consulta.
7 Data Warehouse e Agregados Resumidamente, um DW é uma fonte de dados consultável do empreendimento.
Segundo, os requisitos para um data warehouse são:
O DW deve prover acesso aos dados corporativos ou organizacionais;
Os dados num DW devem ser consistentes;
Os dados num DW podem ser separados e combinados por todas as possíveis medidas do negócio (requisito para o slice and dice);
Um DW não é constituído apenas de dados, mas também de um conjunto de ferramentas para consulta, análise e visualização de informações;
Um DW é um lugar onde são publicados dados que já foram usados.
Os dados de um DW são divididos, de acordo com a sua utilização, em:·
Dados do negócio;·
Metadados. Dados do negócio são os dados necessários para gerenciar a organização ou negócio.
Eles representam as atividades empreendedoras do negócio e os objetos do mundo real que ele negocia, e são utilizados em sistemas fontes e SADs.
Metadados poderiam ser simplesmente considerados &quot;dados sobre dados», mas esses dados devem ser gerenciados por algum tipo de programa.
Desta forma, os dados que descrevem o significado e a estrutura dos dados do negócio, assim como de que forma eles são criados, acessados e usados são chamados de metadados.
Autores da área costumam classificar os metadados segundo diferentes critérios.
Para existem três tipos de metadados:
Metadados de definição (built-time) ­ utilizados no desenvolvimento da aplicação;
Metadados de controle ­ utilizados por o DW para controlar e gerenciar a sua infraestrutura;
Metadados de uso ­ são estruturados para uso dos usuários-finais.
Kimball et al Vêem dois tipos de metadados:
Um DW orientado a assunto, que representa um subconjunto de um DW que inclui dados relevantes de uma função particular do negócio, é chamado de data mart (DM).
De uma forma simplificada, podemos considerar um DM como um subconjunto lógico de um data warehouse.
O termo data mart é utilizado para descrever a maneira como cada departamento individualmente implementa seu próprio sistema de gerência de informações, e ele é usualmente organizado em torno de um único processo do negócio, representando um projeto que pode ser completado e executado mais rapidamente.
Uma abordagem para construção de DMs é o uso de uma DW Bus Architecture que consiste na construção de um DW onde os DMs são organizados em volta das dimensões conformadas.
As dimensões conformadas consistem nas dimensões que significam a mesma coisa para todas as tabelas de fatos a que a mesma se une -- maiores detalhes em.
O planejamento do DW pode ser feito através de fases numa arquitetura global ­ o DW Bus Architecture.
A idéia básica é que cada DM seja implementado separadamente, mas que a cada nova implementação de um DM o mesmo adere a essa arquitetura, se encaixando como peças de um quebra-cabeça.
A escolha dessa abordagem é feita uma vez que a construção de DW numa organização através de um DW central ou separado por áreas não se mostram muito boas.
Em o primeiro caso, são necessários mais tempo e recursos para construção e implantação do DW para toda a organização.
Além de o tempo e custo, outra conseqüência é a demora para disponibilizar dados aos usuários do DW, sendo que algumas áreas da organização têm uma maior necessidade e prioridade para utilização desses dados para apoio às suas decisões.
Se então partíssemos para uma abordagem de construção de DWs separados ­ construídos à medida que eles fossem necessários, não seria possível a integração dos mesmos mais tarde quando essa fosse necessária.
Os passos que podem ser seguidos por a equipe que implementa a construção de um DW são:
Criar uma arquitetura que circunde e defina o escopo e implementação de um DW completo.
Este trabalha adota a definição de um DW como um BD consultável (não-volátil) já que o enfoque maior é dado à submissão de consultas aos seus dados e, de entre os tipos de metadados citados, aqueles que serão utilizados e definidos serão os metadados de controle.
Também se deve notar que o uso de vários processos (representados por várias tabelas de fatos) apoiados num conjunto de dimensões conformadas se apresenta como uma abordagem interessante para implantação de um DW numa organização.
Modelagem dimensional é a técnica de projeto que busca apresentar os dados de uma organização num ambiente padrão que seja intuitivo para o processamento analítico e que permita um acesso de alto desempenho.
Todo modelo dimensional é composto por dois tipos de tabela:
Geralmente, as dimensões contêm hierarquias entre os atributos, que representam a granularidade dos itens de dados, sendo que numa mesma dimensão podem existir várias hierarquias de relacionamentos entre os seus atributos.
Exemplos de hierarquias comuns entre atributos são mostrados na Figura 3.
Uma base de dados baseada no modelo dimensional pode ser vista como um cubo ndimensional, ou simplesmente cubo;
Em o qual cada dimensão é um critério de agregação, e cada célula do cubo contém medidas numéricas ou fatos associados a um valor de cada dimensão do cubo.
A Figura 4 mostra a representação do esquema da Figura 2 em formato de cubo.
Algumas implementações mais sofisticadas de BD requerem o uso de esquemas com múltiplas tabelas de fatos.
Em alguns casos, as múltiplas tabelas de fatos existem porque elas contêm fatos não-relacionados ou por causa de as diferenças na periodicidade dos tempos de carga.
Em outros casos, múltiplas tabelas de fatos existem porque elas podem melhorar o desempenho.
Como exemplo podemos citar o uso das tabelas agregadas.
Um exemplo de um esquema com múltiplas tabelas de fatos pode ser visto na Figura 5.
Cada tabela de fatos representa as unidades de medida de cada área de negócio (e.
g Revenue para Vendas, Shipment para Marketing), sendo que as mesmas são construídas de acordo com as dimensões conformadas.
Item de Linha Id_ IL Com um modelo dimensional criado ­ contendo ou não hierarquias entre seus atributos, os usuários poderão se utilizar de diversos tipos de exploração sobre os dados armazenados no DW.
O processamento OLAP refere- se ao tipo de processamento e às ferramentas voltadas para análise típica de SADs.
As consultas aos dados nesses sistemas são feitas de forma interativa e os dados são apresentados numa visão multidimensional;
Por isso mesmo, suas bases de dados são conhecidas como MDDBs database (multidimensional bases de dados multidimensional).
Considerando as aplicações de uma organização, podemos dividir- las em:
Aplicações que apóiam os processos primários da companhia ou OLTP;
ROLAP (OLAP relacional) é um conjunto de interfaces para o usuário e aplicações que dão aos bancos de dados relacionais uma aparência de dimensional.
Suas ferramentas fazem uso extensivo de metadados.
Ele é um tipo de aplicação de três camadas (three tier), já que existe um servidor de aplicações entre MOLAP (OLAP multidimensional) é um conjunto de interfaces, aplicações e tecnologias de bancos de dados proprietários que tem uma aparência dimensional.
MOLAP contém três camadas ou mais (three+ thier) de aplicação;
Como no ROLAP, ele contém um servidor (OLAP), mais o cubo OLAP, entre as para o apoio à decisão, elas costumam ter funções analíticas mais poderosas;
HOLAP (OLAP híbrido) combina as características dos sistemas ROLAP e O problema geral dos sistemas OLAP é caracterizado de um lado por uma base de dados grande armazenada num DW e, consultas condensando informações detalhadas do outro lado.
Uma das principais demandas desses sistemas, então, é o desempenho, i.
e a avaliação eficiente de consultas analíticas complexas e o tempo de resposta adequado para consultas interativas.
Algumas formas de melhorar o desempenho das consultas a sistemas OLAP são apontadas em, entre as quais agregados, que são o objeto deste trabalho.
A exploração dos dados por os usuários-finais de um DW, pode se feita através de operações, ferramentas e aplicações projetadas especialmente para esse propósito.
Em processamento analítico, basicamente o usuário busca visualizar as variáveis da tabela de fatos sob uma ou mais dimensões de análise, isto é, atributos das dimensões.
Tipicamente, em consultas SQL isto resulta na aplicação de funções de agregação (e.
g SUM, COUNT, AVG, Min, MAX) sobre os atributos da tabela de fatos, usando os atributos das dimensões como colunas de agrupamento, através da cláusula group by.
Qualquer um dos atributos das tabelas utilizadas pode ser usado para especificar restrições na consulta (uso da cláusula where).
Por exemplo, se utilizássemos o esquema representado na Figura 2 e um usuário do sistema necessitasse de informações sobre as vendas dos produtos disponíveis nas lojas na cidade de Aracaju durante o ultimo mês, teríamos a consulta mostrada na Figura 6, onde:
Data Warehouse e Agregados na cláusula Where é feita a junção entre as tabelas de fatos e dimensões e as eventuais restrições sobre os atributos dimensionais%;
As principais operações de navegação num sistema OLAP são:
Slice and dice ­ consiste em mudar a ordem das dimensões, mudando desta forma a orientação segundo a qual os dados são visualizados;
Drill-down ­ é a forma de pedir mais detalhes.
Todos os atributos das tabelas dimensionais podem se tornar colunas de agrupamento, e esse processo de adicionar grupos a partir de colunas pode ser composto de várias tabelas dimensionais;
Drill-up (rollup) ­ operação contrária ao drill-down, mas que não precisa necessariamente ser feita na mesma ordem em que as colunas de agrupamento foram adicionadas;
Além de a realização destas operações sobre os dados, os mesmos podem ser explorados por os usuários através de:
Relatórios padrões ­ relatórios pré-prontos de formato fixo, que exigem uma interação mínima dos usuários, possuem uma grande audiência e execuções regulares;
Mineração de dados ­ aplicação de algoritmos para extrair padrões sobre dados, sem a necessidade de aplicar as outras etapas do processo de KDD;
Consultas pré-prontas ­ que normalmente são entregues ao usuário como parte do O nível máximo de detalhe contido nas tabelas de um DW é conhecido como granularidade.
Quanto maior o detalhamento, menor a granularidade;
Quanto menor o detalhamento, maior a granularidade.
Por exemplo, se considerarmos uma base de dados de uma determinada empresa e representarmos todos os registros de compras de um cliente durante um mês, estaremos representando os dados desse cliente numa baixa granularidade (Figura 7);
Mas se representarmos o sumário dos gastos feitos por o mesmo cliente num dado mês, estaremos usando um baixo nível de detalhe e uma alta granularidade (Figura 7).
Em a fase de projeto do DW é tomada a decisão do nível de granularidade em a qual serão compostas as tabelas base do DW.
Dependendo da decisão do projetista, a tabela de fatos pode conter a sua granularidade diferente das dimensões do esquema e o nível de detalhe pode ser atômico ou não.
Mês Mar Jun Set Nov Dez Valor Data Warehouse e Agregados Em esta dissertação, o termo granularidade será utilizado para referenciar um determinado nível de detalhamento de um esquema e não apenas para referir- se ao nível em que se encontram armazenados os dados de uma tabela original do DW.
As consultas submetidas a um DW dificilmente são feitas diretamente sobre os dados que estão armazenados num nível de granularidade atômico, mas sim sobre algum tipo de sumário elaborado a partir de a agregação destes dados.
A aplicação de funções de agregação em cima de um grande número de registros acaba levando a um alto tempo de computação da consulta.
De entre as estratégias encontradas para resolução deste problema temos a utilização da agregação dos dados, porém essa utilização pode ser:
Ad-hoc -- as consultas são computadas em tempo de execução;
Cubo -- todos os agregados são materializados;
O cálculo em tempo de execução das consultas possui problemas óbvios de desempenho, considerando o alto volume de dados.
Já com o cubo, para todas as combinações possíveis de dimensões/ valores de dimensões, a agregação ­ tipicamente restrita à soma de valores ­ seria calculada e materializada.
O uso do cubo apresenta uma série de problemas, entre eles:
Alto consumo de espaço de armazenamento;
Nem todas as combinações possíveis são observadas na prática, resultando em espaço e tempo de computação desnecessários;
Limitação na resposta a alguns tipos de consultas.
Tipicamente o problema se apresenta quando é desejado algum tipo de agregação diferente de soma (e.
g MAX, Min, COUNT, AVG), ou quando se deseja estabelecer condições de restrição (e.
g cidade $= &quot;Aracaju&quot;).
Com a pré-computação parcial, são pré-computadas as agregações para aquelas combinações de dimensões/ atributos dimensionais consideradas benéficas (e.
g consultas freqüentes, consultas muito onerosas, etc.), as quais passam a coexistir com os dados originais.
Tipicamente é usada a função de soma, mas qualquer uma das funções de agregação conhecidas pode ser aplicada sobre os dados numéricos.
Deve- se ressaltar que durante o texto, os termos:
Tabelas agregadas, agregados, visão materializada, pré-computação parcial, dados pré-computados, visão agregada, tabela sumário, cubóide, objeto multidimensional serão considerados equivalentes.
O motivo da utilização de todos estes termos deve- se à não uniformidade encontrada na literatura para referenciar os mesmos.
Agregados são construídos primariamente para aumentar o desempenho das consultas.
Estima- se, em alguns casos, que os ganhos cheguem a um fator de 100 ou 1000 vezes, mas Kimball et al Alerta que o potencial de utilização de agregados deve ser bem explorado antes de tentar se investir em mais recursos computacionais (hardware).
Os agregados em geral são armazenados em tabelas separadas e cada tabela de fatos agregada deve estar associada a uma ou mais dimensões encolhidas.
As dimensões encolhidas são tabelas dimensionais que contêm apenas os atributos que fazem sentido no nível de granularidade em que a tabela de fatos a ela associada estiver.
Em a Figura 8 temos um exemplo de um esquema de uma tabela agregada, derivada do esquema contido na Figura 2.
Em ele, observamos que duas dimensões foram encolhidas:
A dimensão Tempo (não contendo mais o atributo Dia) e a dimensão Produto, agora chamada de Categoria, de a qual os atributos Nome_ produto e Tipo desapareceram.
A dimensão Loja foi eliminada.
Além de o aumento de desempenho, agregados também podem ser construídos para armazenar fatos que não podem ser representados numa granularidade menor.
Por exemplo, na Figura 8, se for interessante armazenar as previsões de venda mensais de uma determinada loja, pode ser criado um novo atributo na tabela de fatos agregada contendo o valor previsto (campo Prev_ Vendas), o qual não pode ser representado em níveis inferiores, por que a granularidade escolhida foi vendas diárias.
Contudo, isso implica uma perda de transparência dos agregados.
A criação de agregados introduz uma família de tabelas de fatos que usualmente derivam de uma tabela de fatos com baixa granularidade ­ a tabela base.
Cada membro da família representa um grau de sumarização particular entre uma ou mais dimensões.
Os serviços de gerenciamento de consultas são um conjunto de capacidades que gerenciam a troca entre a formulação da consulta, a sua execução no BD e o retorno do conjunto de resultados para o usuário.
Eles têm um impacto significativo na interação do usuário com o BD.
De entre esses sistemas temos:·
Simplificação de contexto ­ protege o usuário das complexidades dos dados e da linguagem de consulta antes que qualquer consulta específica seja formulada, se utilizando de metadados de apoio criados para auxiliar essa tarefa;·
Reformulação de consultas ­ é um serviço que interpreta um consulta recebida e infere de que forma ela será melhor resolvida.
A forma mais simples de reformulação é o redirecionamento, descrito a seguir;·
Redirecionamento da consulta e multipass SQL ­ é o serviço que interpreta uma consulta recebida, verifica os metadados para identificar onde as tabelas necessárias estão localizadas e, então redireciona a consulta ou seus componentes adequadamente.
Esse é o serviço que torna possível o gerenciamento de tabelas de fatos separadas em diferentes plataformas;·
Consciência (awareness) dos agregados ­ é um caso especial de redirecionamento de consultas, em o qual o serviço reconhece que a consulta pode ser satisfeita por uma tabela agregada, ao invés de realizar todos os cálculos em cima de a tabela base.
Em este caso, há a escolha automática dos agregados mais adequados e reformulação da consulta em termos destes, de forma transparente ao usuário;·
Consciência dos dados ­ é um serviço que permite aos usuários perguntar por itens tais como qual o ano corrente ou o ano anterior de vendas sem ter que saber os períodos específicos das datas;·
Governing das consultas ­ é um serviço que tenta impedir que consultas malformuladas (e.
g consultas com loops aninhados, incorretas, etc) acabem degradando o desempenho do DW.
A Figura 9 mostra a arquitetura funcional de um mecanismo de reformulação de consulta consciente dos agregados proposta em, chamado navegador de agregados.
Kimball et al Indicam que os redirecionadores de consulta consciente de agregados ideais devam estar entre o SGBD e a ferramenta front-end.
Assim, todos os clientes que submetam consultas SQL ao DW podem se beneficiar do seu uso, pois as consultas submetidas são interceptadas por o mecanismo e redirecionadas adequadamente.
Como já destacado, o foco do presente trabalho encontra- se no serviço de redirecionamento consciente dos agregados, denominado neste trabalho simplesmente como redirecionador de consultas ou mecanismo de redirecionamento.
Utilização de Agregados em ambientes de DW Entre os trabalhos estudados que tratam de consultas submetidas ao DW a dados resultando em agregação, são encontradas as seguintes abordagens:
Otimização da forma como a consulta é respondida por o SGBD (e.
g). Utilização de estimativas para formação de agregados;
Criação de visões agregadas.
Em as duas primeiras abordagens, são necessárias mudanças significativas no SGBD.
Em, propõe- se um esquema de agregação online, que muda a interface para o processamento de agregados, a qual permite que os usuários observem o progresso das suas consultas assim como controlem a execução das mesmas em tempo real.
Contudo, a mudança não ocorre apenas no nível de interface, pois ela também corresponde a mudanças no processamento das consultas, otimização, e produção e uso de estatísticas.
Além disso, o problema de desempenho persiste, já que as consultas deverão ser realizadas sobre um grande volume de dados.
Em os trabalhos que abordam a otimização do plano das consultas, o foco é sobre a seleção de um bom plano de consulta ou seqüência de pedidos para o sistema de armazenamento que vai responder a consulta, já que consultas complexas permitenos o uso de operações de reordem.
Em o trabalho de é mostrado um conjunto de formas alternativas de execução que podem aumentar a qualidade dos planos de consultas produzidos, baseado em transformações que permitam a otimização de consultas contendo agrupamento e junção, bem como em algoritmos de otimização que possam incorporar essas transformações sem aumentar o espaço de consulta dramaticamente.
Em, é proposto um novo operador, denominado projeção generalizada, em o qual as consultas são reescritas através da movimentação dos operadores de agregação na árvore de consulta, no sentido de colocar as agregações acima ou abaixo de a árvore de consulta, e unir vários operadores de agregação num só ou separar um operador em vários outros.
Contudo, para que essas políticas sejam aplicáveis seria indispensável que o SGBD mudasse a forma como processa as consultas SQL, o que não se caracteriza como uma finalidade deste trabalho, uma vez que se deseja aproveitar todos avanços já incorporados em produtos com suporte e processamento OLAP.
A abordagem das visões agregadas consiste em materializar, isto é, processar e possivelmente armazenar, visões contendo a resposta de consultas a dados com funções de agregação.
Dentro de esta abordagem, existem duas propostas:
Materialização dinâmica e estática.
A materialização dinâmica deixa a cargo de o SGBD e/ ou ferramenta OLAP a decisão de quais agregados devem ser mantidos por o SGBD, baseado na monitoração das consultas submetidas ao SGBD.
Em a materialização estática, a decisão de quais agregados manter é tomada por um usuário, neste caso, o DBA.
As duas abordagens de materialização de visões são complementares.
A materialização estática reflete os requisitos expressos da organização e a materialização dinâmica reflete os requisitos dos usuários do sistema naquele momento.
Organizacionalmente, a materialização estática é fundamental já que os agregados são criados a partir de os requisitos decisionais da organização, levando em conta os tipos de análise e/ ou de usuários, prioritários.
Ela assim possibilita a criação de agregados que serão bastante utilizados e que respondam a consultas que exijam um alto tempo de computação, os quais são armazenados na base.
A materialização dinâmica acaba refletindo um momento dentro de a organização e pedidos de usuários específicos (e.
g uma seqüência de drills relacionados).
Contudo, neste caso, certos agregados, em particular os que são importantes para a organização, podem acabar sendo excluídos e novos agregados podem acabar sendo criados e armazenados, os quais eventualmente não seriam consultados novamente.
A monitoração e sugestão dos agregados que devem ser criados e excluídos é bastante importante, mas não podemos permitir que as tabelas agregadas fundamentais à organização sejam criadas/ excluídas sem que haja ao menos a interação de um usuário ­ especialista no domínio ou DBA, pois o mesmo poderá verificar se a operação de inclusão/ exclusão das tabelas agregadas reflete o perfil da organização como um todo ou apenas um conjunto de pedidos específicos dos usuários num dado momento.
Segundo Karlapalem, o problema de seleção dessas visões (materializar dinamicamente) deve considerar:·
Os benefícios no custo de processamento das consultas no futuro;·
O custo de manutenção das visões agregadas materializadas;·
O custo de reorganização.
Trabalhos recentes como tratam do assunto das visões dinâmicas.
O propósito do Dynamat é ser um sistema de gerenciamento de visões que coexiste e coopera com arquiteturas do lado do cliente.
Ele facilita o trabalho do administrador porque monitora e calibra o sistema constantemente.
Fragmentos candidatos são buscados para responder a uma consulta utilizando o índice de diretórios.
Este índice é responsável por achar os candidatos entre os resultados materializados e é construído para que não seja necessário testar todos os fragmentos.
A escolha do fragmento que responderá à consulta depende do conteúdo do repositório de visões, responsável por armazenar os dados materializados.
Para seleção de qual fragmento deve ser escolhido, utiliza- se uma medida de goodness.
De entre aquelas que obtêm melhores resultados tem- se:
Tempo em que o fragmento foi acessado por o sistema (último acesso), freqüência de acesso do fragmento, o tamanho do resultado e a taxa para recomputar o fragmento.
O algoritmo Quasi-Optimal proposto por otimiza o custo global de computar um cube-by apud.
Um cube-by é um operador associado com um conjunto de n dimensões que computa 2n group-bys para cada uma das combinações das 1 a 1, 2 a 2, de cubóide.
A computação pode ser total (todos os cubóides) ou parcial (alguns de eles).
O algoritmo considera dois custos:
O custo da derivação direta e derivação indireta de um cubóide a partir de outro cubóide, levando em consideração o uso dos cubóides por os usuários e, acha a solução mais próxima o possível para o melhor custo global para criação de visões.
A utilização dos cubóides é feita através de uma seqüência de interações ­ consultas sobre os dados, e depois sobre os cubóides derivados através de uma série de drills.
Neto et al Propõem a realização de análises periódicas para a seleção dos agregados, sendo possível descartar aqueles cuja utilização não seja mais necessária.
São propostos dois modelos, um para ser utilizado quando de a criação do DW e, outro quando os agregados já foram criados e estão sendo monitorados.
O modelo de custos para escolha dos primeiros agregados a serem materializados leva em consideração o fator de expansão do DW e o número de I/ O's que serão economizados.
O modelo de custos estendido leva em consideração a freqüência com que os agregados são utilizados.
São selecionados os agregados mais utilizados, i.
e, os que apresentam o fator de freqüência de utilização máximo.
A estratégia do servidor OLAP CubeStar é armazenar consultas précalculadas para reutilização numa cache de agregados, porém, as tabelas agregadas são criadas apenas quando necessárias.
Uma partição de um possível cubo de dados multidimensional agregado é descrito como um objeto multidimensional (Me o).
Ele utiliza um algoritmo para combinar os Me os nessa cache, cuja meta é compor aqueles fragmentos de objetos multidimensionais na cache que permitem a computação da consulta com menor custo.
Assim, vários Me os ou fragmentos de Me os são selecionados de forma a responder a consulta.
As condições para determinar se um Me o é um candidato para responder a consulta são:
A granularidade do Me o deve ser menor ou igual à granularidade da consulta;
A consulta e o Me o candidato podem se sobrepor.
A solução aproximada dada por o algoritmo é escolher sucessivamente para cada parte da consulta o que ainda não foi coberto por um objeto multidimensional com o menor tempo de acesso estimado por célula de dados resultante.
Porém, quando a cache se encontra cheia e novos agregados precisam ser adicionados, é necessária a remoção de alguns desses objetos.
Para isso, existe a estratégia de substituição, que seleciona os Me os que devem ser removidos da cache e quais novos agregados devem ser adicionados e, mantém um conhecimento sobre o esquema e propriedades do modelo de dados para que possa haver uma estimativa mais apurada dos benefícios desses objetos em cache.
A abordagem de apesar de se mostrar uma boa alternativa para uso de agregados pré-calculados não pode ser aplicável porque a sobreposição de uma consulta por um Me o candidato é um problema Np-completo.
Sabe- se que nenhum algoritmo em tempo polinomial foi descoberto para os problemas NPcompletos e, por isso, considera- se que qualquer problema nessa classe é considerado intratável.
O presente trabalho trata apenas de visões agregadas estáticas porque, para o uso de visões dinâmicas seria necessária a construção de uma arquitetura para gerenciamento das visões (como no caso de o Dynamat e CubeStar), o que fugiria ao escopo deste trabalho.
Considerando o uso de visões estáticas ou tabelas agregadas, os ganhos advindos para o negócio com a utilização de um conjunto de tabelas agregadas têm dois componentes principais:
As tabelas agregadas devem satisfazer os requisitos de tempo de resposta;
Deve- se usar as tabelas agregadas para reduzir o custo total de um conjunto de requisitos operacionais (e.
g redução na atividade do disco), o que pode gerar, através dessa economia acumulada, uma redução nos requisitos de hardware para um dado conjunto de consultas.
Devemos lembrar que no contexto organizacional os agregados estáticos se mostram importantes já que eles refletem os requisitos da organização como um todo:
As análises mais freqüentes ou prioritárias, os usuários a serem priorizados, etc..
Percebe- se que a construção de agregados é uma das formas mais efetivas que um DBA tem para lidar com o desempenho das consultas em sistemas OLAP, porém dois problemas devem ser contornados:
A ferramenta do usuário-final não deve endereçar especificamente o agregado a ser usado na consulta SQL, ou ele não será usado.
Se isso acontecer, acaba não existindo uma flexibilidade para criação e exclusão de agregados, bem como resistência ao seu uso, como discutido no exemplo de.
Uma forma de contornar este problema é utilizar um serviço de redirecionamento da consulta;
A coexistência das tabelas base e dos agregados pré-computados ocupa muito espaço, já que sua construção pode multiplicar geometricamente a carga do BD.
Critérios para definição de agregados serão discutidos na seção 2.5.
Para que os agregados sejam bem utilizados, deve existir uma boa estratégia de agregação.
Kimball et al, definem que uma boa estratégia deve:
Prover grandes ganhos de desempenho para o maior número de categorias de usuários possível;
Aumentar de forma razoável o espaço de armazenamento no DW ­ um fator em torno de dois;
Ser completamente transparente para o usuário e para os desenvolvedores de aplicações ­ nenhum de eles deve referenciar diretamente os agregados;
Beneficiar todos os usuários do DW, independentemente da ferramenta de consulta utilizada;
Causar o mínimo de impacto possível às ferramentas de extração, sendo que a criação dos agregados deve ser feita da forma mais automatizada possível;
Causar o mínimo de impacto possível às responsabilidades administrativas do DBA.
Como já foi destacado, o uso de agregados depende de quais funcionalidades a ferramenta utilizada provê.
Se a mesma contém um mecanismo para redirecionamento de consultas, os usuários poderão navegar por as tabelas agregadas de forma transparente;
Senão os usuários devem ser treinados para que possam se beneficiar da sua utilização, com as possíveis conseqüências apontadas em.
De entre as metas básicas que devem ser observadas no momento de projetar e desenvolver um mecanismo de redirecionamento ou, no momento da escolha de uma ferramenta, temos:
Agregados devem ser armazenados em suas próprias tabelas de fatos;
Dimensões unidas a uma tabela de fatos agregada devem ser encolhidas;
As tabelas de fatos agregadas devem estar associadas a uma &quot;família de esquemas&quot;;
As consultas devem referenciar exclusivamente a tabela de fatos base.
Existe uma falta de consenso quando se discute quais critérios devem ser levados em consideração quando são criadas tabelas agregadas em ambientes de DW.
Geralmente os autores comentam em seus trabalhos sobre um ou outro critério, não existindo muitos indicativos sobre quais de eles deveriam ser priorizados.
Em a literatura são encontrados trabalhos que trazem algumas estratégias para determinação do custo de criação de agregados, tais como.
Esta função é particularmente importante no contexto de materialização dinâmica de visões, discutida na seção 2.4.1.
Este trabalho não tratará da criação de uma função de custos para criação de agregados (está concentrado apenas no redirecionamento) já que, como comenta, no contexto de materialização de estática de visões, a preocupação sobre o que agregar não deve ser extremada, pois à medida que o sistema é utilizado, os agregados mudam ­ novos agregados são criados e outros são excluídos;
E provavelmente os agregados que são escolhidos de início não serão aqueles que serão mais utilizados por os usuários.
Através do levantamento de vários trabalhos na literatura, foi possível fazer uma compilação das recomendações dadas por vários autores.
Por motivos de clareza, elas foram classificadas em:
Critérios Técnicos Critérios Não-Técnicos Vale destacar, contudo, que a proposição de novos critérios de agregação, ou de sua priorização, não são objetos deste trabalho.
Esta compilação foi feita no sentido de estabelecer um referencial onde é possível assumir que a qualidade dos agregados não interfira significativamente no resultado das consultas, pois assume- se que os agregados foram construídos da forma mais adequada possível.
Conhecendo melhor o domínio da aplicação é possível detectar que tipos de consultas são mais constantemente realizadas no DW, para que as mesmas sejam criadas.
Isso pode ser feito através:
Depois da criação das primeiras tabelas agregadas, alguns testes de desempenho devem ser realizados e, esses agregados são revisados para serem utilizados por os usuários.
De aí, eles são monitorados sobre certo período de tempo e os ajustes são feitos sobre os mesmos.
Kimball et al Sugerem que as características apresentadas abaixo devem ser monitoradas num ambiente de DW, de forma que a criação dos agregados seja facilitada.
Características que devem ser monitoradas online:' (
utilização dos agregados e tabela base -- para verificar a freqüência com que os agregados são utilizados;
Características que podem ser monitoradas offline:' (
informações estatísticas -- cálculos realizados sobre os metadados mantidos por o DW que deverão conter todas as informações que são monitoradas online;
Sapia sugere a modelagem do comportamento das consultas do usuário através de perfis, já que o perfil do usuário pode ser utilizado para prover aos sistemas OLAP desempenho em tempo de execução, através da próxima consulta a ser realizada por o usuário.
Ele considera a correlação entre consultas sucessivas através da natureza navegacional de aplicações OLAP (drills) dando um nível de abstração mais alto para as consultas.
A abordagem leva em consideração a última consulta realizada por o usuário e toda a história das sessões do usuário combinada com o conhecimento do domínio que é capturado por os perfis do usuário.
Duas sessões têm padrões comuns se elas contém consultas similares.
Duas consultas são similares, se elas são próximas (em distância).
A distância entre duas consultas q1 e q2 equivale ao número de operações (drills, etc.) necessárias para transformar a consulta q1 na consulta q2.
Se padrões de interação típicos dos usuários são conhecidos, esta informação pode ser utilizada para construir perfis de consultas para usuários ou grupos de usuários.
Esta informação pode ser utilizada para otimizar o desempenho de um sistema OLAP já que a idéia é utilizar os perfis juntos com o prefixo conhecido da sessão para prever quais consultas o usuário deverá perguntar durante o resto da sessão.
Desta forma, os agregados que não estão sendo utilizados podem ser excluídos, e com o uso das estatísticas, novos agregados podem ser criados.
O trabalho do DBA é estimar o quão grande os agregados serão, quanto tempo levará para a sua construção e qual a estimativa de ganho em tempo de consulta.
Wedekind et al Em consideram que não só aspectos técnicos devem ser considerados para decidir que combinações de group-by são válidas para serem materializadas, pois existem características semânticas que podem ajudar na escolha.
A sua proposta para a agregação de dados estatísticos foi a separação de uma parte que contenha uma hierarquia entre seus atributos de outra que não contenha.
As pré-agregações são feitas para a combinação que contém hierarquia enquanto as consultas group-by que não contém hierarquia entre seus atributos são computadas em tempo de execução.
Assim, agregados devem ser criados apenas para dimensões que contêm alguma hierarquia entre seus atributos.
Tempo de resposta da consulta -- Um dos maiores motivos para utilização de agregados é a diminuição global do tempo de resposta das consultas dos usuários do DW, já que a noção de on-line (OLAP) enfatiza a necessidade de um tempo de resposta pequeno para uma alta interatividade de exploração dos dados.
Leitura dos registros (I/ O -- entrada/ saída) -- Dependente do gerenciador do banco de dados (SGBD) e sistema operacional, os quais definem qual a forma como os dados são armazenados e recuperados Tempo para computar a tabela agregada -- Em este caso, quais os cálculos, I/ O, entre outros realizados para consultar a tabela base e para a manutenção do agregado no banco de dados.
Número de Tabelas de Fatos -- Levando em conta quais consultas podem ser satisfeitas por agregados num nível básico, deve haver uma avaliação de que tabelas de agregados trazem um melhor desempenho para o sistema e balancear isto com a quantidade de espaço utilizado e o tempo tomado nas atualizações.
Uma política de manutenção de um número de tabelas de fatos que não seja muito grande (o suficiente para melhorar as consultas, mas que não necessite aumentar muito o espaço em disco) pode ser aplicada, pois a criação de muitas tabelas acaba dificultando a manutenção do DW.
Quantidade de Registros Sumarizados -- a quantidade de registros fatos da tabela original que um registro da tabela de fatos agregada está sumarizando, deve ser levada em consideração, pois não é interessante manter tabelas agregadas onde a maioria dos seus registros sumarizam apenas um fato da tabela base.
Uma das formas mais efetivas de controlar a explosão de agregados, mas ainda assim se beneficiando de seu valor, é ter certeza que cada agregado sumariza pelo menos 10, de preferência 20 ou mais itens de um nível inferior.
Além de haver uma verificação sobre quais são os conjuntos de atributos que aparecem mais freqüentemente nas consultas, deve- se considerar o número de valores por atributo que são candidatos à agregação, pois se a diferença de registros entre dois níveis de agregação for pequena, não vale a pena criar uma nova tabela agregada.
Uma forma de escolher quais agregados devem ser armazenados é o cálculo do Fator de Compressão (FC).
O FC é calculado por o número de registros produzidos por uma agregação dividido por o número de registros recuperados.
Assim, se sumarizarmos a venda de produtos por categoria, originalmente correspondente a 1000 registros e forem apresentados como resultado 100 registros, o FC seria 0,1.
Se o fator de compressão for próximo de 1, o agregado não deve ser armazenado, pois o seu tamanho é muito próximo de a tabela de fatos base Tamanho da base de dados ­ Freqüentemente, na criação das primeiras tabelas agregadas pode acontecer que o conjunto de agregados supere o espaço de armazenamento utilizado por os dados base.
Assim, o tempo e os recursos requeridos para manter uma grande quantidade de agregados num DW podem se tornar um problema.
Para Kimball et al, é razoável planejar o overhead de armazenamento em 100% para agregados, isto é, a soma de todas as tabelas agregadas (tabelas de fatos derivadas mais dimensões encolhidas) deve ser aproximadamente igual em armazenamento à soma das tabelas de nível mais baixo.
O tamanho da base de dados pode se referir ao espaço físico em disco máximo ocupado por o BD ou ao número máximo de células na base de dados.
Dispersão de Dados -- Com a adição de novas dimensões e até mesmo de dados a uma base de dados de um DW, o número de células cresce rapidamente.
Em situações onde menos de 10% das células têm dados, a base é considerada esparsa.
Outro tipo de dado esparso é criado quando muitas células contêm o mesmo valor.
Tipicamente isto acontece em registros representando uma série de tempo, em que um fato não se altera ao longo de o tempo.
Por exemplo, em registros representando vendas diárias através das variáveis preço, unidades vendidas, valor vendido etc., a variável preço pode permanecer inalterada ao longo de os meses e, portanto, ser repetida em todos os registros.
A falha de dispersão (sparcity failure) corresponde ao espaço alocado para as células num BD que acaba não sendo ocupado, já que existe uma grande diferença entre o número de células no BD e o número de células que realmente contêm dados.
Quanto menor a porcentagem dessas células que contém dados, maior a falha.
A falha de dispersão é um fenômeno que acontece freqüentemente em DWs, mas de difícil previsão, pois nem sempre o tamanho planejado das tabelas agregadas é alcançado (ele é sempre superado).
Muitas vezes a falha de dispersão começa já na tabela base e, acaba se propagando ao longo de as agregações para as tabelas agregadas.
Armazenamento dos Dados -- As formas de armazenamento dos agregados num DW são:
Junto com tabelas de fatos e dimensões originais;
Em tabelas de fatos e dimensões separadas;
A segunda técnica é mais recomendada, porque o uso de registros agregados junto com os registros de granularidade mais baixa provoca problemas, principalmente no momento de distinguir quais são os registros de base e quais são os registros agregados.
A técnica mais apropriada para construção de agregados, então, pega cada novo agregado e cria uma tabela de fatos separada para ele.
Esta nova tabela derivada é unida a um conjunto de dimensões encolhidas.
Em a maioria dos sistemas OLAP conhecidos, as tabelas agregadas são selecionadas e pré-computadas, acompanhada da seleção dos índices apropriados sobre elas.
Algumas das formas de indexação em sistemas OLAP são encontradas em.
A criação e uso de agregados deve ser paralela à criação e uso de índices, pois tanto os índices quanto as tabelas agregadas consomem um recurso único, a saber, espaço.
Conseqüentemente, essa seleção deve ser feita em conjunto, para o uso mais eficiente do espaço.
Em o trabalho proposto por Gupta et al É apresentado um algoritmo &quot;guloso «(greedy) para seleção das tabelas agregadas e dos índices e, é mostrado que um algoritmo de complexidade moderada pode ser executado de forma bastante eficiente.
Porém, é bom lembrar que a criação de tabelas agregadas diminui a necessidade de criação de índices na tabela de fatos, já que muitas das consultas serão redirecionadas para algum agregado e espera- se com isso que a tabela base seja utilizada somente quando não houver outra alternativa.
Custo de manutenção dos agregados;
Necessidade de união de tabelas (union);
Hardware/ Software (Plataforma/ Sistema Operacional/SGBD/ ferramenta front-end);
Tipos de funções de agregação e cálculos utilizados.
De entre os critérios estudados, aqueles que acabaram sendo considerados como mais interessantes e acabaram sendo adotados neste trabalho foram:
Tempo de resposta ­ para atender as consultas dos usuários de uma forma mais eficaz;
Requisitos expressos por os usuários ­ que demonstra aquilo que o usuário espera do sistema;
Tamanho ­ manutenção de um número não muito grande de tabelas (para facilitar o gerenciamento das mesmas) e agregados não muito próximos das respectivas tabelas originadoras (cálculo do FC) e, crescimento controlado da base de dados;
Armazenar os agregados em tabelas separadas da tabela original;
Índices; Monitorar as consultas ­ apesar desse critério interessar mais a materialização de dados dinâmicos, um monitor pode ser utilizado para prover estatísticas de utilização dos agregados.
Um critério importante não considerado foi a dispersão dos dados, pois, neste caso, existe uma dificuldade de prever quando problemas relativos a ele poderão acontecer.
Redirecionamento de Consultas Agregadas Para que uma consulta submetida a um DW, que contenha funções de agregação, seja redirecionada a uma tabela agregada apropriada, são necessárias:
As próximas subseções mostrarão alguns trabalhos que tratam desses dois problemas.
Alguns dos trabalhos encontrados na literatura que tratam do redirecionamento de consultas em DW são descritos no restante desta seção.
O navegador de agregados (NA) é um sistema de redirecionamento de consultas que se utiliza da menor tabela de fatos existente, de entre os esquemas disponíveis.
Ele é um componente funcional que permite a otimização do desempenho de classes de consultas no DW através do armazenamento e gestão de valores agregados na base de dados, sem que o usuário necessite conhecer esses agregados.
O NA consiste de uma camada sobre o SGBD que intercepta as consultas SQL enviadas por o cliente.
Muitos destes navegadores mantêm estatísticas de todas as consultas SQL recebidas, geram relatórios dos níveis de uso dos agregados e podem sugerir que novos agregados devam ser adicionados por o DBA.
A criação de agregados num DW introduz uma família de tabelas de fatos que são usualmente derivadas de uma tabela de fatos com uma granularidade maior.
A tabela de fatos base, e todas as tabelas de fatos agregadas relacionadas a ela, devem ser associadas juntas a uma &quot;família de esquemas «para que haja uma forma de identificar quais tabelas se relacionam.
O conceito de família de esquemas é discutido com mais detalhes na Seção Segundo, o algoritmo para escolha do melhor esquema agregado que responda uma consulta é:
Ordenar todas as tabelas de fatos agregadas, através da família de esquemas, da menor (i.
e com o menor número de registros) para a maior;
Para cada sentença SQL apresentada ao SGBD:
Procurar a menor tabela de fatos que ainda não foi examinada na família de esquemas referenciados por a consulta;
Se os atributos forem encontrados, é necessário substituir o nome da tabela de fatos e dimensões do nível base por os nomes das tabelas de fatos e dimensões agregadas na consulta realizada.
Se o passo 2 falhar, tentar o mesmo passo novamente, até chegar ao esquema base.
Se não for encontrada nenhuma tabela de fatos agregada que satisfaça os critérios estabelecidos, as tabelas bases deverão ser utilizadas;
Senão, executar o SQL alterado.
De entre as limitações encontradas no algoritmo acima, tem- se:·
O algoritmo só admite esquemas com apenas uma tabela de fatos, o que não é interessante quando a organização decide construir data marts separados e decide realizar consultas contendo informações que estão distribuídas em vários data marts.·
Os agregados não podem ser subconjuntos de uma tabela de fatos, i.
E., não é possível criar uma tabela de fatos apenas com os Produtos de certas Categorias.
A restrição feita sobre um subconjunto de valores de atributos (ou fatos) é imprescindível para aplicações distribuídas ou data marts;·
Uso de índices ­ como entre vários outros autores afirmam a utilização de índices aumenta o desempenho das consultas;
Então, pode ser mais vantajoso utilizar uma tabela um pouco maior (mas indexada) do que uma tabela menor (não indexada) para responder uma consulta, quando as mesmas tiverem um número de registros muito próximo;·
O critério tamanho considera apenas se uma tabela de fatos é maior ou menor que a outra, porém, se a consulta precisar fazer a busca por algum atributo dimensional e a tabela de dimensão de um agregado for bem maior que a do outro e os dois tiverem uma tabela de fatos com o número de registros muito próximos, pode ser interessante utilizar o agregado que tiver versões encolhidas das dimensões.
Data Warehouse e Agregados· A verificação se as informações contidas no agregado podem realmente responder a consulta não é suficiente (Passo 2.2).
Algumas vezes, não é possível recuperar a resposta da consulta mesmo se os atributos são encontrados porque algumas funções de agregação sobre os atributos não podem ser recuperadas no nível de granularidade igual ao da consulta (se essas funções não tiverem sido calculadas e armazenadas junto à tabela agregada);·
Não considera, também, a utilização de fatos calculados e externos.
O armazenamento de atributos calculados, e.
g SUM/ SUM, que normalmente são pedidos por os usuários do DW corresponde a uma economia em tempo de execução, pois os cálculos serão realizados apenas no momento de criação do agregado.
Deve- se ressaltar que os usuários não tomarão conhecimento que esses valores foram pré-calculados e armazenados.
Apesar de a inserção de atributos externos implicar numa perda de transparência, eles também correspondem a informações requeridas por os usuários e poderiam ser armazenados junto aos dados contidos no DW;·
Não existe nenhum indicativo de formas de monitoramento das consultas realizadas para que seja feita a análise dessas informações no momento de criar novos agregados.
Tampouco dos dados monitorados.
A abordagem de Srivasta et al Detecta quando a informação existente na visão materializada é suficiente para responder uma consulta.
Em o trabalho, define- se que uma consulta Q'é uma reescrita da consulta Q que usa a visão V se:
Q e Q'computam o mesmo multiconjunto de respostas para qualquer base de dados dada, e Q'contém uma ou mais ocorrências de V na sua cláusula from de um dos seus blocos, onde um bloco corresponde a cada subconsulta da consulta submetida (caso a consulta contenha union).
Assim, uma visão V é utilizável para executar a consulta Q, se existe uma consulta Q'tal que Q'é uma reescrita de Q que usa V;
Desta forma, V deve substituir algumas das consultas e condições de Q. E ela será utilizável para responder uma consulta Q, se V não descartar nenhuma coluna que Q necessite.
Para utilizar visões que envolvem agregações, deve- se verificar:
A) se as informações das visões (agregadas) são suficientes para computar os agregados necessários na consulta;
B) se as corretas multiplicidades existem e podem ser computadas.
Os algoritmos propostos por se utilizam de várias condições de usabilidade para determinar se as consultas podem ser reescritas, porém a maioria dessas condições se mostraram com certa complexidade (quando não eram ininteligíveis).
Além disso, o trabalho se encontra apenas num nível teórico não havendo indicadores de como ele poderia ser aplicado num ambiente operacional.
O trabalho de propõe uma arquitetura para acesso distribuído a DW via Web onde os dados são armazenados segundo o esquema estrela, contendo dados num nível inferior (base) além de um conjunto de hierarquias de agregação (que em já passa a ser considerado o uso de um grafo de derivação).
Sua proposta considera a existência de um DW global que contém todos os dados, e diferentes sites onde são encontrados fragmentos das tabelas de fatos tanto no nível do esquema base quanto dos esquemas agregados.
Os fragmentos contêm tabelas onde o escopo dos dados é restringido a alguns valores.
Por exemplo, no site de uma filial X de uma empresa, o fragmento poderia conter os dados referentes apenas da filial X, e se houvesse a necessidade de consultar dados de outras filiais, recorreria- se ao DW global.
Foi construída uma interface para Web ­ o login-site, que possibilita a consulta aos dados através de consultas pré-prontas.
Assim, o login-site redireciona essas consultas para os sites que sejam mais adequados para responder a consulta solicitada.
O trabalho apresentado por trata mais os aspectos de distribuição dos dados de um DW na Web, dando pouco enfoque ao redirecionamento em si.
Em a realidade, o redirecionamento apresentado é feito para decidir para qual login-site a consulta deve ser enviada.
Contudo, se num mesmo login-site existem vários agregados passíveis de utilização na resposta à consulta, este trabalho não aborda como é feita a escolha do agregado específico.
Além disso, considera- se que a base para as consultas é constituída por apenas um esquema estrela, porém, já que o trabalho apresentado trata de dados distribuídos de uma organização, é bastante provável que exista mais de uma tabela de fatos para representar os dados a serem analisados por os decisores da organização.
Para que seja viável o redirecionamento de uma consulta ao agregado apropriado, deverá existir, além de uma estratégia/ algoritmo de redirecionamento de consultas, uma forma de representar a existência e relacionamento destes agregados através de metadados.
Algumas de elas são apresentadas a seguir.
A família consiste de um esquema base contendo uma única tabela de fatos com dados não-agregados com as suas dimensões associadas, mais um conjunto de esquemas agregados, que contém as tabelas de fatos e dimensões.
Cada membro da família representa um grau de sumarização particular entre uma ou mais dimensões.
O registro desta família de tabelas de fatos, junto com as tabelas dimensionais encolhidas associadas a ela, é um dos poucos metadados necessários para o projeto de um navegador de agregados proposto por.
De entre esses metadados que são necessário para a construção de agregados tem- se:
Contudo, a definição dos metadados que devem ser utilizados por o mecanismo não está detalhada e não existe um esquema que represente os relacionamentos entre os agregados.
Conflitos de origem também não são tratados.
Além disso, a família de esquemas só consegue representar um esquema como sendo base para os agregados criados.
O grafo de derivação proposto por Souza para representar os agregados, serve como base a um algoritmo que otimiza o custo de computar um cube-by.
O grafo de derivação (G,) é composto de:
Vértices -- onde cada vértice pertencente ao grafo G é um cubóide do operador cube-by;
Arestas dirigidas de derivação (vi, vj) em, i j, de vi para vj, se vj tiver todas as dimensões de vi, menos uma.
Cada aresta é rotulada com os dois custos de derivação:
Direto e Indireto.
O custo direto D (vi, vj) significa que vj é um prefixo de vi, conseqüentemente vj pode ser calculado diretamente de vi.
Se vj não é prefixo de vi, o custo da computação de vj a partir de vi é indireto, I (vi, vj), o que significa que vi pode ser reorganizado para gerar vj diretamente a partir de ele.
É obvio que o custo direto D de um cubóide é sempre menor que o custo indireto I. Considerando o grafo da Figura 10, LT é o cubóide derivador de L e T, i.
e L e T têm todas as dimensões de LT, menos uma.
As arestas são rotuladas com os custos (D, I).
Semelhante ao trabalho de, temos trabalhos como.
Em, os agregados são representados segundo a arquitetura de treliças (reticulado) proposta por e apud, onde os agregados são representados por cada nó n representa um agregado, e uma aresta a, entre dois nós n e m, direcionada de n para m, representa um relacionamento entre os agregados n e m, que indica que m pode ser obtido através de n.
Os reticulados são utilizados para o cálculo das funções de custos propostas.
Em, o grafo de derivação (DG) consiste num grafo orientado em o qual V (DG) representando os vértices do grafo, representa um conjunto de agregações (medidas numéricas agregadas).
Já as arestas E (DG) representam um conjunto de relações de dependência.
Uma relação de dependência é denotada por.
Uma agregação v DG é dependente de outra agregação u DG (v u) se e somente se v pode ser determinada usando apenas o resultado de u.
Esta estrutura de grafo é utilizada para fragmentação dos dados no De entre os trabalhos apresentados, todos eles consideram apenas um vértice como sendo o originador do resto do grafo, i.
e só é possível existir um esquema base para criação e relacionamento entre os agregados.
Um DWCDM (DW Conceptual Data Model) tem como objetivo prover formas de representação de uma visão conceitual multidimensional dos dados e descrever tanto o domínio abstrato do negócio (Enterprise Model) quanto as possíveis visões de informação da empresa que um cliente particular pode querer analisar (Client Model) ­ as visões agregadas.
De forma a ter uma conceitualização adequada da informação multidimensional, um DWCDM deve prover a possibilidade de modelar explicitamente as agregações e dimensões relevantes.
O DWCDM proposto por é baseado no modelo Er, onde uma dimensão/ atributo dimensional (neste caso, Dia) é modelado através dos seus valores atômicos e pode se relacionar com outras dimensões para representar as agregações.
A extensão ao Er é feita para representar a estrutura de agregações, mas não deve conter funções de agregação e nem o modo como esses valores serão computados.
Um esquema conceitual pode incluir entidades agregadas adicionais que denotam agregações entre dimensões e podem conter atributos (e.
g, função_ de_ agregação (atributo_ dimensional).
Para isso, é necessário adicionar novas entidades agregadas e as definições dos novos níveis, introduzidos nas dimensões.
Um modelo de dados conceitual pode conter agregações multidimensionais e várias dimensões (organizadas hierarquicamente) que podem ser abstraídas e descritas para serem utilizadas numa linguagem de consultas e/ ou para otimização semântica de um BD multidimensional.
Assim, um DWCDM pode servir como um metamodelo de referência para derivar as inter-relações entre níveis e dimensões.
A solução apresentada em para o problema de representação de agregados se encontra apenas num nível conceitual não podendo ser considerada como uma solução &quot;implementável».
Como um dos objetivos deste trabalho é a construção de um protótipo do mecanismo de redirecionamento de agregados, a utilização da representação apresentada no trabalho de foi desconsiderada.
Normalmente, utiliza- se o esquema estrela para mapear as estruturas dimensionais no modelo relacional.
Mas o uso de uma única tabela dimensional para cada dimensão acaba sendo problemático se existem atributos de classe que são específicos.
Por exemplo, numa dimensão de Produtos, poderíamos ter atributos específicos para um grupo de Produtos (e.
g videocassete, lava-roupa, etc.) e manter- los em tabelas separadas.
Para lidar com esse problema, a tabela dimensional (tradicional do esquema estrela) é substituída (particionada) por tabelas dimensionais específicas de classe, cada uma podendo ter um esquema diferente.
Os fundamentos da hierarquia são classes básicas e todas as classes num nível mais alto são recursivamente definidas como visões das classes` menores' (num nível abaixo de a hierarquia).
O nome das classes-filho assim como todos os atributos em comum são propagados para seus pais (cria- se uma visão com union all de todos os filhos).
Informações de cada nó da classe de uma dimensão são armazenada numa relação ou visão, contendo todos os elementos dimensionais abaixo de o nó e informações sobre os seus pais na hierarquia de classificação e o subconjunto de propriedades (atributos) visíveis a todos os outros nós.
Como o escopo do Me o é definido por um nó de classificação, as consultas SQL não precisam de nenhuma restrição além de as condições de junção das classes.
O trabalho de está mais centrado na representação das dimensões e não no relacionamento entre as tabelas do agregado entre si.
Além disso, um detalhe bastante importante e que acabou não sendo considerado no trabalho de é a sobrecarga (overload) do SGBD para unir as classes-filho toda vez que uma consulta submetida contiver uma dessas classes-pai.
Ferramentas De entre as ferramentas que fornecem algum tipo de mecanismo para gerência de agregados, tem- se:
Aperio Aggregate Navigator; Red Brick VistaTM da Informix;
Teleran iSum; Aggregate Navigator da Business Objects;
Datadriller da Openair Software; MS SQL/ Server OLAP Sevices;
Oracle. Um estudo sobre as principais características de cada uma das ferramentas acima descritas (excluindo o Oracle) foi realizado em.
A análise das funcionalidades das mesmas acabou sendo dificultada devido a a falta de documentação adequada e dificuldades relacionadas ao teste dos produtos.
De entre os aspectos que foram observados para avaliar as ferramentas, temos:
Transparência na reescrita das consultas;
Informações relativas aos metadados utilizados por o mecanismo provido por a ferramenta ­ quais os metadados e como eles são gerenciados;
Criação/ manutenção das tabelas:
Se é dinâmica, estática ou não informada;
Monitoração das consultas realizadas ­ se existe um monitor para indicar quais agregados poderiam ser criados/ excluídos ou se cabe ao usuário decidir os candidatos a agregação;
Como citado em[ KIM96b], a forma mais interessante de se manter um mecanismo de gerência de agregados é ter- lo como uma camada sobre o SGBD;
Porém, grande parte das ferramentas avaliadas foram construídas tendo esse mecanismo como parte integrante do SGBD.
Além disso, não havia documentação nessas ferramentas que indicasse como os agregados eram construídos, para que depois fossem utilizados por os usuários.
Os fabricantes apenas consideravam que havia a necessidade de criação de tabelas agregadas/ sumário, não se atendo a detalhes de como elas seriam criadas no DW e, se a criação das mesmas era realmente realizada automaticamente por as ferramentas.
E nenhuma de elas demonstrava a possibilidade de criar um agregado que pudesse derivar de mais de uma tabela de fatos e nem especificava quais metadados eram necessários para o gerenciamento dos agregados.
Como menciona, vendedores de ferramentas para DW tentam conquistar uma posição de frente no mercado, mas com a rapidez que os projetos acontecem, normalmente eles acabam trazendo propostas incompletas.
Assim, apenas num estágio adiante é que acontecem os esforços para padronização, criação de uma terminologia uniforme e até mesmo a fundamentação teórica.
Considerações sobre os trabalhos relacionados Percebe- se que o uso de agregados em ambientes de DW constitui- se num diferencial importante para a satisfação dos usuários-finais, já que suas consultas tendem a ser respondidas num menor tempo.
Como visto, a utilização de um mecanismo de gerência de agregados é bastante recomendada.
Contudo, os usuários não devem estar cientes da existência dos mesmos ­ transparência no uso dos agregados.
Este trabalho foca o uso de agregados estáticos, porque eles privilegiam os requisitos decisionais de uma organização.
Ainda, permite utilizar tecnologias já existentes incorporadas solucionar o problema de uso e escolha de tabelas agregadas para responder consultas submetidas por os usuários do DW, de forma transparente.
O estudo de trabalhos na área de utilização de agregados serviram como um ponto de partida para o presente trabalho.
Foram detectados os problemas/ limitações nas propostas existentes para redirecionamento de consultas a dados agregados, em particular a proposta do navegador de agregados de Kimball et al, adequada ao contexto dos agregados estáticos.
De entre as limitações já citadas, o presente trabalho considera duas com particular atenção:
O seu funcionamento em esquemas estrela de múltiplas tabelas de fatos, abordagem comum em organizações que constróem o DW a partir de vários DMs, e a especificação dos metadados necessários ao funcionamento de um redirecionador.
Com relação a este último aspecto, propostas de utilização de uma estrutura de grafo para representar relacionamento entre agregados, tais como, foram estudadas e adaptadas.
O presente trabalho foi desenvolvido no intuito de criar um mecanismo de redirecionamento de consultas, que considerou os principais conceitos vistos até o presente momento para escolher e processar o agregado mais apropriado para responder uma consulta submetida a um DW.
Seu objetivo principal é o de definir um mecanismo para seleção de agregados candidatos para responder uma consulta a um DW que possibilite a escolha do agregado mais adequado.
Para isso, foram estudadas formas de redirecionamento de consulta e, representação dos agregados (e metadados necessários) para que o algoritmo proposto pudesse funcionar adequadamente.
Trabalhos anteriores sobre mecanismos de redirecionamento de consultas a dados agregados num DW não se utilizavam de um esquema com múltiplas tabelas de fatos e não definiam uma estratégia clara sobre como os dados seriam redirecionados à tabela agregada apropriada.
Kimball et al Apresenta uma solução de redirecionador de consultas consciente dos agregados.
Todavia, o trabalho se mostrou restritivo com relação a abordagem empregada pois o mesmo não considera:
Como visto anteriormente, considera- se que os dados já foram carregados no DW e que os agregados já foram construídos e materializados (seguindo alguns dos critérios apresentados ou por critérios não discutidos aqui);
Todavia, problemas relacionados à criação e manutenção destes agregados encontram- se fora de o escopo deste trabalho.
Os agregados deverão ser representados de forma que seja possível recuperar as informações necessárias para que o algoritmo de redirecionamento funcione adequadamente.
Os metadados necessários podem ser subdivididos em quatro classes:
Metadados referentes aos atributos;
Metadados referentes às tabelas;
Metadados referentes aos esquemas (tabela de fatos+ dimensões);
Metadados referentes ao relacionamento entre os agregados.
Os metadados mantidos para cada atributo são:
As possíveis restrições feitas sobre eles ­ para posterior verificação se as restrições realizadas sobre os atributos invalidam o uso do agregado para responder a consulta (caso a consulta necessite de dados não constantes no agregado devido a a restrição).
Sendo que as restrições se limitam à utilização do operador lógico &quot;e&quot;;
Quais atributos estão indexados.
Adicionalmente, para cada atributo fato são armazenados:
As informações sobre as tabelas do esquema constituem- se em:
Tamanho da tabela (tanto fatos como dimensões) ­ para possibilitar as comparações realizadas no momento de escolha do candidato mais adequado a responder a consulta, através do critério menor esquema;
Se a mesma é indexada (e por quais atributos) ­ também para possibilitar comparações durante a escolha do candidato.
Porém o uso do critério tabela indexada para escolha do agregado só deve ser observado se a (s) tabela (s) contendo o (s) atributo (s) indexado (s) estiver (em) contida (s) na consulta;
Quais os atributos pertencentes à tabela.
Com relação a o esquema, devemos verificar a sua disponibilidade (se no momento ele pode ser consultado ou não;
Caso ele esteja fora de o ar, em manutenção, contém dados desatualizados etc.) e quais tabelas fazem parte do dado esquema.
Note- se que, à exceção de a composição das tabelas por atributos, e a existência de índices, todas as demais informações não existem tradicionalmente no dicionário de dados de um SGBD.
Sendo que elas devem ser informadas por um usuário ­ DBA.
O relacionamento entre os agregados é feito através de uma grafo dirigido.
Em o grafo de agregados, inspirado em trabalhos como, são representadas as possíveis derivações e o relacionamento acontece não apenas entre os agregados e a base, mas também entre agregados.
Teremos, então, um grafo dirigido G (V, E) em o qual V representa os agregados e E a distância entre os agregados.
Em outras palavras, nos vértices do grafo são representados os esquemas, composto das tabelas dimensionais e de fatos, e nas arestas a relação de derivação rotulada com a taxa de compressão entre as tabelas de fatos.
A representação do grafo em considera que um vértice deriva de outro se estes estão ligados por uma aresta, sendo que o vértice destino (vértice derivado) contém todas as dimensões do vértice origem (derivador), menos um.
Em o contexto deste trabalho, admite- se que a diferença entre dois agregados relacionados seja apenas o grau de encolhimento das dimensões.
Assim, no grafo aqui proposto, um esquema agregado derivado (também chamado vértice derivado ou vértice filho) deve conter ao menos uma dimensão encolhida em relação a o seu esquema agregado derivador (também chamado vértice derivador ou vértice pai).
A nova tabela de fatos, então, terá seus atributos numéricos agregados (por qualquer uma função de agregação SQL conhecida) com relação a os atributos das tabelas dimensionais que deixaram de existir na hierarquia da dimensão por conta da dimensão ter sido encolhida.
Ainda existem dois tipos de arestas:
Derivação direta e indireta.
Quando a aresta é de derivação direta, o esquema agregado derivado foi obtido através da agregação do esquema agregado derivador.
Quando a derivação é indireta, embora fosse possível, o agregado derivado não foi criado a partir de o derivador, porque o custo de criação foi estimado por o DBA como maior, em comparação com o agregado derivador direto.
O custo de criação consiste no tempo despendido para o cálculo e construção do agregado.
Para demonstrar como o grafo representa a relação entre os agregados, consideraremos o esquema da Figura 2 com as dimensões tempo, produto e loja e considerando que existe uma hierarquia entre os atributos das dimensões.
Suponha que se deseja criar os seguintes agregados:
A1 ­ Total das vendas mensais de todos os produtos para todas as lojas.
A2 ­ Total das vendas estaduais e mensais de todos os produtos.
A3 ­ Total das vendas estaduais diárias para todos os produtos.
A4 ­ Total das vendas anuais por loja.
O grafo de derivação resultante é apresentado na Figura 12.
O agregado A1 apresenta todas as dimensões do esquema base, sendo que a dimensão Tempo foi encolhida.
O agregado A2 também apresenta as mesmas dimensões do esquema base, sendo que duas foram encolhidas (Tempo e Loja).
Percebe- se no entanto que, por A2 conter somente dimensões que constem em A1, em grau de encolhimento maior, a relação de derivação estabelecida entre A2 e A1 tem menor custo de criação, do que entre A2 e o esquema base.
Assim, A1 é derivado direto de Venda e A2 é derivado direto de A1.
O mesmo raciocínio é aplicado para a derivação de A3 a partir de Venda.
Já no caso de A4, existem dois agregados pré-existentes (A2 e A3) que poderiam ser usados para computar- lo.
Em este caso, é escolhido aquele que tem custo de criação menor (A2), mas indica- se o outro possível derivador (A3) através de uma aresta de derivação indireta.
Todas as arestas são rotuladas com a taxa de compressão entre as tabelas.
Considerando que o mecanismo de redirecionamento proposto trabalha com esquemas com múltiplas tabelas de fatos, o grafo proposto pode conter mais de uma fonte, ou seja, um vértice que não é destino de nenhuma aresta.
Também um vértice pode ser destino de mais de uma aresta de derivação direta, representando um agregado derivado de múltiplas tabelas de fatos e que corresponde à junção entre estas tabelas.
Assim, poderíamos ter um grafo como mostrado na Figura 13, onde o Agr6 deriva de dois agregados diferentes.
Provavelmente Agr2 e Base2 são esquemas que contêm algumas dimensões em comum e Agr6 contém um subconjunto destas dimensões, então atributos fatos das diferentes dimensões foram unidos numa nova tabela de fatos.
Desta forma, um mesmo agregado pode responder um número maior de consultas.
A escolha de uma estrutura de grafo para representar o relacionamento entre agregados deve- se à possibilidade de se, ao se caminhar por o grafo a partir de a base, poder desconsiderar vários candidatos ao mesmo tempo.
Com efeito, se for verificado que um agregado (vértice) não pode responder uma consulta, podemos desconsiderar como potenciais candidatos todos os vértices entre os quais há um caminho de derivação a partir de aquele agregado sem ter que verificar- los.
Por exemplo, se considerássemos o grafo da Figura 13 e fosse verificado que uma consulta recebida por o DW não pudesse ser respondida por o agregado Agr2, não seria necessário verificar se Agr5, Agr6, Agr7 e Agr8 responderiam a consulta, porque os mesmos seriam desconsiderados recursivamente.
Com a utilização de uma estrutura de grafo para representar as tabelas agregadas, foi necessária a busca de um algoritmo de caminhamento;
Aquele que se mostrou mais apropriado para caminhar no grafo foi a busca em largura.
Como já mencionado, quando detectado que um agregado não pode responder uma consulta, nenhum dos seus descendentes derivados estará tampouco apto.
Assim para descartar mais rapidamente um agregado e todos os agregados de ele derivados usa- se um algoritmo de busca em profundidade, pois ele explora completamente uma aresta e todos os vértices alcançados por ele.
Consideraremos que o grafo de agregados é um dígrafo -- grafo direcionado onde cada aresta possui apenas uma direção, já que caminharemos sempre da base (raiz do dígrafo) até os agregados que não contêm mais filhos para serem explorados (sumidouros).
A solução apresentada para este problema considera além de o esquema estrela simples, o uso de uma arquitetura com várias tabelas de fatos unidas através de dimensões conformadas.
Deve- se observar que os agregados devem ser distintos entre si e que os metadados descritos na Seção 3.1 foram definidos.
O algoritmo que está sendo proposto considera somente consultas monobloco (select from where group by) onde a cláusula select pode conter funções de agregação do SQL.
Assim, dada um consulta SQL e existindo grafos de derivação com a relação entre as tabelas armazenadas no DW, a escolha do agregado que responderá a consulta é feita da seguinte forma:
Para selecionar o candidato mais adequado para responder a consulta, utilizaremos o algoritmo busca em largura.
Para consultas a apenas um esquema, ele começa considerando a base como o vértice fonte e caminha por o grafo verificando se o dado vértice (agregado) tem possibilidade de responder a consulta.
Em consultas a mais de um esquema ao mesmo tempo, primeiramente a consulta é subdividida e as novas consultas geradas são verificadas a partir de o vértice que contém a tabela de fatos correspondente.
Caso seja verificado que o vértice escolhido não consegue obter a resposta da consulta, ele e todos os seus filhos são desconsiderados através do algoritmo de busca em profundidade, onde todos os vértices são marcados como &quot;desconsiderado».
Quando é verificado que um vértice pode responder uma consulta e que o mesmo não contém restrições, o (s) seu (s) pai (s) mais imediato (s) nãoindexado (s) pode (m) ser eliminado (s) da lista de candidatos.
Lembrando que em cada aresta há um valor associado à distância entre os dois agregados.
O fator de parada é o fim da exploração do grafo.
Em um segundo momento, se restar mais de um candidato, é feita a escolha do agregado mais adequado a partir de os critérios de desempate:
Tamanho do esquema, uso de índices ou não e ocorrência de tabelas encolhidas.
Tendo um candidato escolhido, a consulta é reescrita para que ele seja utilizado sendo que as tabelas que pertencem ao esquema base são substituídas por as respectivas tabelas do esquema agregado escolhido, levando em consideração a correspondência de uma tabela com a sua versão encolhida.
Como entrada para o algoritmo, teremos consultas escritas em SQL onde os atributos dimensionais se encontram organizados no início da cláusula select seguidos por as funções de agregação aplicadas aos fatos.
A cláusula group by conterá os mesmos atributos dimensionais que aparecem na cláusula select.
Também, deve- se observar que as consultas realizadas por os usuários do mecanismo não devem conter redundâncias de tabelas ou atributos, i.
e tabelas e atributos que não interfiram no resultado da consulta não devem ser referenciadas na mesma.
O algoritmo proposto para o redirecionador de consultas, segue o modelo de algoritmo da proposta do Kimball mas considerando alguns aspectos não abordados no seu algoritmo, como citado na Seção 2.6.1.1.
O algoritmo pode ser subdividido em três partes:
Quebra das consultas, para consultas que referenciam múltiplas tabelas de fatos.
Em este caso, a consulta será dividida em consultas a cada um dos componentes, e mais tarde, todos os agregados resultantes serão juntados;
Escolha dos candidatos que podem responder a consulta.
A lista de candidatos inclui todos os esquemas que tem a possibilidade de responder a consulta;
E, por fim, a priorização na escolha do candidato mais adequado.
A divisão da consulta nos seus diversos componentes pode ser feita como descrito a seguir:
Identificar as n tabelas de fatos distintas que aparecem na consulta;
Criar n componentes (consultas) distintos, onde cada um de eles deve conter todas as tabelas de dimensão da consulta original e todos os atributos dimensionais contidos no select/ group-by, incluindo as possíveis restrições aos atributos realizados na cláusula where;
O Mecanismo de Redirecionamento Caso os atributos fatos contenham restrições, as mesmas serão incorporadas ao componente correspondente à sua tabela de fatos;
Se a consulta da Figura 14 fosse realizada sobre o esquema da Figura 5, ela seria subdividida nas consultas mostradas na Figura 15.
A escolha dos candidatos é feita para cada consulta individual ou um dos seus componentes, caso ela seja uma consulta que referencie múltiplos fatos.
Desta forma, para cada consulta, verificar a partir de a base correspondente a tabela de fatos referenciada:
Caso o esquema não seja a base, verificar se todos os atributos da consulta pertencem ao esquema:
Verificar além de os atributos no select, também os atributos que estão no where, no group by e, se tanto nas dimensões quanto nos fatos existem os atributos requeridos na consulta;
Verificar se a função de agregação pode ser respondida com o agregado (principalmente os cálculos que exijam funções diferentes de SUM, pois muitos dos agregados são criados aplicando apenas sumarizações em cima de a tabela de fatos que está num nível acima de ele e a consulta pode exigir o uso de outras funções de agregação).
Verificar se existem restrições (de valores) nos atributos dos esquemas e se a consulta pode ser respondida de qualquer forma (mesmo com a restrição).
Se um esquema for desconsiderado, nem é preciso verificar os seus filhos (eles também serão desconsiderados por` herança', através do uso de uma representação para o relacionamento entre os mesmos).
Verificar se o agregado está disponível*.
Se ele estiver disponível e puder responder a consulta então:
Colocar- lo na lista de candidatos que podem responder a consulta, marcando- o como visitado.
Se o esquema agregado pai (já incluído na lista) não contiver tabelas indexadas por atributos que pertençam à consulta submetida, retirar- lo da lista de candidatos.
Caminhar em direção a os agregados filhos (no nível seguinte), até que não existam mais filhos, sempre escolhendo a aresta que ainda não foi explorada e realizar os passos 1 e 2 para cada um dos filhos que ainda não foram &quot;desconsiderados».
Senão, desconsiderar o agregado e todos os seus descendentes, marcando os como &quot;desconsiderados».
Considera- se que um agregado esteja disponível quando ele pode ser consultado por o usuário.
A não-disponibilidade de um agregado pode ocorrer quando ele estiver em manutenção, fora de o ar ou em qualquer outra situação em que o DBA ache necessário não deixar- lo disponível para consulta.
Ainda considerando o esquema da Figura 5, as consultas das Figura 14 e Figura 15, e se tivéssemos os agregados da Figura 16, a escolha dos candidatos seria feita da seguinte forma:
Para a consulta 1 verificamos qual agregado pode responder- la.
Primeiramente vemos que o Agregado 1 consegue, vamos para um nível abaixo e verificamos que o Agregado 3 também pode responder- la e ficamos com o Agregado 3.
Fazemos o mesmo procedimento para a consulta 2 e verificamos que o Agregado 3 pode responder- la.
Para a escolha do candidato apropriado que responderá a consulta, quando a consulta é subdividida em vários componentes, consideraremos dois casos:
Se existem elementos em comum de entre as listas, aplicar os critérios de priorização para estes elementos;
Caso contrário, a priorização é feita para cada agregado e depois é feita uma junção dos mesmos.
A priorização do esquema mais adequado a responder a consulta é feita da seguinte forma:
Verificar de entre os esquemas candidatos qual é o menor e, manter os menores e aqueles que estão indexados.
O critério menor refere- se às tabelas (tanto fatos como dimensões) que contenham o menor no de registros, onde este tamanho está relacionado às tabelas que pertencem à consulta e, o no de registros contidos na tabela de fatos é mais relevante que os atributos das dimensões.
Preferir os esquemas com a menor granularidade que possam responder a consulta e verificar se o uso de dimensão encolhida reduz realmente o número de registros.
Ver o ganho com índices, caso o tamanho do indexado não for muito maior que o não-indexado, balancear o custo da utilização.
Inicialmente, o uso de índices e o ganho obtido com a utilização dos mesmos deverá ser feito através de parâmetros informados ao redirecionador por o DBA.
Reescrever a consulta, se possível, de forma que a tabela de fatos agregada apropriada seja utilizada -- garantindo que existe uma equivalência entre a consulta original e a consulta reescrita.
Devemos lembrar que cada nova operação aplicada ao esquema base corresponde a uma nova consulta ao esquema e, desta forma, uma nova verificação realizada por o algoritmo para ver se as tabelas agregadas disponíveis podem responder a consulta.
O módulo de monitoração apresenta funcionalidades limitadas.
Ele se restringe à capacidade de monitorar as consultas submetidas, não contendo capacidades relativas à análise dos dados armazenados em log para sugestão de quais agregados poderiam ser criados/ excluídos e que valores poderiam ser calculados e armazenados juntamente aos outros atributos do esquema.
As consultas submetidas por os usuários são monitoradas e depois que a consulta é reescrita, a mesma é armazenada juntamente com a indicação de qual agregado foi utilizado para responder- la, para futura verificação de quais agregados estão sendo mais ou menos utilizados por os usuários e quais as consultas mais típicas dos usuários, i.
e para cada consulta são armazenados a indicação dos agregados utilizados para responder- la, as tabelas contidas na consulta e seus atributos com as devidas restrições.&amp;&amp;&amp;
Como descrito na Seção 3.1, será necessária a utilização de alguns algoritmos de caminhamento em grafos, descritos em e.
Para isso, foram adaptados os algoritmos busca em largura e busca em profundidade para que fosse possível navegar entre os agregados armazenados na base de dados.
Antes de apresentar o algoritmo refinado, é necessário conhecer o conceito de lista de adjacência.
A representação de um grafo pode ser feita computacionalmente por listas ou matrizes de adjacência, porém as matrizes costumam ser bastante esparsas.
A representação da lista de adjacência de G $= (V, E) é um array Adj de listas de| V|, um para cada vértice V. Para cada u V, a lista de adjacência Adj contém (aponta para) todos os vértices v para o qual existe uma aresta (u, v) E, i.
e Adj consiste em todos os vértices adjacentes a u em G. Se G é um dígrafo, a soma do tamanho de todas as listas de adjacência é igual a| E|.
Para o grafo da Figura 13, teríamos a lista de adjacência mostrada na Figura 17.
O Mecanismo de Redirecionamento Uma lista de adjacência pode ser adaptada para representar grafos com pesos, i.
e A seguir serão descritos, com mais detalhes, os algoritmos utilizados.
Considerando: G (V, E) um grafo dirigido conexo Q uma consulta submetida ao redirecionador R a reescrita da consulta Q Adj a lista de adjacências de v F uma fila P uma pilha C um conjunto contendo os candidatos a responder a consulta O algoritmo principal é mostrado na Figura 18.
A verificação se a consulta submetida Q pode ser respondida é feita através do procedimento indicado na Figura 19, em que é retornada a consulta reescrita.
O procedimento indicado por é mostrado na Figura 21, que tem como retorno a indicação se a consulta pode ou não ser respondida por o vértice indicado.
O restante dos procedimentos funciona da seguinte forma:
Visitar (v, w) ­ corresponde ir do vértice v para o vértice w;
Com_ Restrição ­ verificar se o esquema contém alguma restrição;
E_ Indexado ­ verifica se o vértice v contém índice em alguma das tabelas participantes;
Retira_ Candidato_ Lista ­ Retira vértice v do conjunto C (candidatos a responder a consulta);
Pai ­ Escolhido (C) todos os atributos contidos na consulta Q;
Reescrever (Q, v) ­ reescreve a consulta Q para usar o agregado correspondente ao vértice v, trocando as tabelas da consulta original por suas versões encolhidas correspondentes.
Não esquecendo de verificar se existe &quot;not null «caso o agregado tenha sido gerado por mais de uma tabela de fatos.
Em este momento também são armazenados a consulta realizada e o agregado escolhido para responder- la num arquivo de log.
Os cálculos que envolvem mais de um atributo devem ser considerados como várias funções independentes aplicadas ao diferentes atributos, e.
g se tivéssemos SUM (X+ Y) consideraríamos as somas em separado SUM+ SUM (Y), pois desta forma poderiam ser verificadas as correspondências entre as funções.
A equivalência entre as funções de agregação do agregado e da consulta submetida são encontradas na Tabela 4.
Derivação. As classes restantes contêm os metadados de controle para que seja possível fazer a verificação dos objetos contidos no esquema ­ que servirão como` resposta' às perguntas que serão feitas por os procedimentos do redirecionador.
Características do modelo:
A associação Versao_ Encolhida foi criada para facilitar a substituição da tabela base por uma tabela num nível de granularidade diferente na reescrita da consulta;
As operações Elimina e Desmarcar da classe Esquema são operações de classe e não apenas de instância.
As operações Eh_ Indexada e Com_ Restricão foram criados na classe Tabela para facilitar no momento de seleção e desempate entre os candidatos;
A operação Responde (C) de Esquema verifica se o esquema atual consegue responder a consulta C. Esta operação troca mensagens com as operações Eh_ Indexada, Com_ Restrição e Atributos_ Contidos da classe Tabela e através da operação Atributos_ Contidos verifica na classe Atributo as funções aplicadas aos atributos para verificar a equivalência dos mesmos e se algum atributo calculado contido na consulta pode ser respondido por um atributo calculado préarmazenado.
A criação de uma classe Função teve como objetivo verificar a equivalência entre O intuito da criação de um protótipo do redirecionador de consultas é de implementar o algoritmo para` validar' as estratégias de agregação.
Ele foi desenvolvido apenas para reescrever consultas, tendo como parâmetro de entrada uma consulta em SQL e como retorno uma consulta SQL reescrita ou o informe de que a mesma não pode ser reescrita (pois só poderá ser respondida por a tabela base).
O escopo da solução foi reduzido para que a implementação pudesse ser realizada no tempo disponibilizado para a mesma.
Isso não invalida a contribuição do trabalho já que a maioria das consultas submetidas podem ser apropriadamente respondidas por o agregado mais adequado.
Assim, foram considerados agregados onde apenas uma função de agregação era aplicada aos atributos numéricos (não impedindo que o mesmo atributo fosse agregado por várias funções distintas).
Como ambiente de programação foi utilizado o Borland Delphi e as tabelas contendo os metadados do sistema foram armazenadas num BD nativo da Borland.
O protótipo pode ser subdividido em dois módulos principais:
O módulo para manutenção dos metadados referentes à representação dos agregados;
Os metadados mantidos correspondem aos atributos das classes contidas no diagrama da Figura 23, além de as informações armazenadas através da monitoração das consultas submetidas.
Exemplos de interfaces para manutenção dos metadados são vistas na Figura 24.
Apesar de o intuito deste protótipo não ser o de se constituir numa ferramenta front-end para o usuário (já que o mecanismo de redirecionamento deve ser independente de SGBD e front-end), foi construída uma interface gráfica (Figura 25 a Figura 27) para geração de consulta para:·'
garantir' que a consulta não conteria atributos e tabelas redundantes;
Evitar que fosse construído um parser para reconhecer corretamente os tokens da consulta.
Os passos para a construção da consulta podem ser vistos na Figura 25, que acabarão gerando a consulta descrita na Figura 26.
Somente no final do processo teremos a consulta reescrita e a atualização dos dados de monitoração.
Em a Figura 27 temos a consulta construída na Figura 26 reescrita -- as tabelas que foram modificadas por o algoritmo estão destacadas por uma elipse e os atributos, com um traço.
Este estudo de caso foi realizado no PPGCC/ FACIN/ PUCRS em ambiente Windows/ NT utilizando- se de uma estação de trabalho Pentium III 800 com HD de 43 Gb e 500 Mb de RAM, sendo que os dados foram armazenados no SGBD SQL/ Server 7.0.
Os dados deste estudo de caso foram provenientes do APB-1 OLAP Benchmark.
Uma visão geral do benchmark será dada a seguir e informações complementares poderão ser encontradas no Anexo B. O APB-1 (analytical processing benchmark) é um avaliador que simula uma situação de negócio OLAP de forma realista.
A sua meta é medir o desempenho global do servidor OLAP e para isso, algumas operações comuns (carga, atualização, cálculos, desempenho é o AQM (analytical queries per minute) que considera todas as operações citadas.
De entre as peculiaridades encontradas no APB-1 Benchmark podemos citar que todos os atributos nas dimensões pertencem a uma dada hierarquia, existe mais de uma tabela de fatos e alguns dos valores requisitados nas consultas são derivados (calculados) a partir de alguns atributos do esquema.
Ele é constituído de quatro tabelas de fatos (SALES ­ principal, INVENTORY, PRODCOS, CUSTSHIP).
A tabela principal é construída a partir de tabelas distintas que são carregadas em duas das fases do benchmark (carga e atualização dos dados), bem como de cálculos realizados em cima desses dados (no caso, para saber a previsão de vendas).
A tabela Inventory é representada na Figura 29 e a representação das demais tabelas de fatos pode ser encontrada no Anexo A. As dimensões conformadas são comuns a quase todas as tabelas de fatos desse estudo de caso e estão disponíveis para carga de duas formas:
Hierarquia e árvore.
São elas:
PRODUCT, CUSTOMER, CHANNEL, Time e Scenario (atual, orçamento e previsão ­ que é calculada através dos outros cenários).
Como já citado, todas as dimensões do APB-1 contêm uma hierarquia entre seus atributos.
Devemos lembrar que a dimensão tempo é de suma importância porque além de os dados num DW serem históricos, muitas das consultas com agregação realizadas num DW são realizadas sobre a dimensão tempo ou ela está envolvida de alguma forma, e.
g restrições sobre intervalos de tempo, etc..
De entre os atributos fatos, tem- se aqueles que são de entrada (units_ sales, dollar_ sales, inventory, product_ cost e shipping_ cost) e as medidas calculadas (average_ price, cost, margin_ percent e smoothed_ sales).
Alguns de eles só são válidos na sua tabela de fatos correspondente (e.
g, o atributo product_ cost só aparece na tabela de fatos PRODCOS).
O processo de Staging compreende as atividades de extração, limpeza, transformação, carga e indexação e serve para preparar os dados provindos dos sistemas OLTP para uso no DW.
Ele chega a custar em torno de 70% do esforço de construção do DW.
As etapas realizadas são discutidas abaixo.
Inicialmente foram gerados os dados que seriam utilizados no estudo de caso, através do programa disponibilizado em*.
Antes de carregar os dados para o SGBD alvo, algumas modificações foram realizadas nos arquivos originais para facilitar a carga dos mesmos no SGBD.
Em particular, destaca- se a mudança na representação do inventário (INVENTORY) via programa, para que seja possível se utilizar da dimensão tempo (Time) -- Figura 30 (a).
Além disso, as tabelas dimensionais foram carregadas para o Microsoft Access a partir de os arquivos que continham uma representação hierárquica para que fosse possível a geração de chaves mais apropriadas para estas tabelas.
A criação das chaves foi feita utilizando um recurso provido por o MS Access (AutoNumeração) sobre um atributo do tipo inteiro, o qual, para cada nova linha na tabela, associa ao campo chave o próximo valor de identificador, que é igual ao último valor do identificador mais um.
Também via programa foram gerados os arquivos das tabelas de fatos já com as chaves das tabelas relacionadas ­ um exemplo pode ser visto na Figura 30 (b).
Essas modificações não acarretarão a invalidade do uso do Benchmark porque esses dados serão utilizados apenas para validação do modelo proposto e não para uma avaliação comparativa com outras ferramentas OLAP.
As consultas realizadas para geração destes arquivos intermediários se encontram no Anexo A. Também foi criada a dimensão Scenario, apesar de a mesma conter apenas 3 registros, porque era preferível manter uma dimensão com poucos atributos a usar atributos textuais na tabela de fatos.
Por fim, os dados já transformados foram carregados para o banco de dados escolhido ­ o MS SQL/ Server 7.0, onde a população das tabelas foi feita através do DTS Package, recurso oferecido por o SQL/ Server para carga e transformação dos dados.
Como as dimensões já haviam sido previamente vinculadas no Access para uso por o programa utilizado no processo de Staging não foi necessária fazer nenhuma nova modificação entre elas.
O processo de Staging no todo demorou em torno de duas semanas.
Alguns agregados foram modelados sobre o esquema base, bem como sobre os agregados assim criados e consultas foram realizadas a nível conceitual, para que pudesse ser construída e testada a validade do algoritmo de redirecionamento proposto.
Para a modelagem dos agregados foram considerados como base principal os esquemas representados na Figura 28 e na Figura 29, a partir de eles, foram criadas tabelas agregadas.
Os critérios adotados para criação das tabelas agregadas foram:
Benchmark; Estudo de Caso desempenho;
De entre as tabelas agregadas criadas, uma variedade de cenários foi considerada:
Dimensões foram encolhidas (e.
g num dos agregados, a dimensão PRODUCT continha apenas os atributos line e division);
Em o momento de criar agregados a partir de múltiplas tabelas de fatos, os critérios que mais interessam são os critérios não-técnicos, principalmente o levantamento dos requisitos dos usuários.
Contudo, deve- se observar que problemas relativos à dispersão dos dados aparecem neste momento, pois raramente as dimensões conformadas envolvidas são utilizadas no seu todo por as diferentes tabelas de fatos a elas unidas.
Para gerenciar esse tipo de tabela agregada, deve- se verificar nas consultas que a utilizarão se os fatos que eventualmente contenham valores nulos são tratados (uso do not null na cláusula where).
Porém, apesar destes problemas, os ganho obtidos na criação de tabelas agregadas a partir de múltiplas tabelas de fatos acabam compensando devido:
Os agregados definidos para este estudo de caso formam o grafo de derivação mostrado na Figura 31, que foi construído para que fosse possível cobrir os pontos principais do algoritmo proposto.
Eles são mostrados nas Figura 32 a Figura 37, e descritos com mais detalhes abaixo.
É importante destacar que para a criação dos agregados, foi necessária a geração além de as tabelas de fatos correspondentes aos agregados, a versão encolhida de algumas dimensões (e.
g Product, Customer e Time).
Um resumo das características destes agregados pode ser encontrado nas Tabelas 5 e 6.
O primeiro agregado criado neste estudo de caso encontra- se na Figura 32.
O mesmo foi derivado do esquema Sales em que as dimensões Channel e Scenario foram desconsideradas, resultando na agregação dos fatos para todos os atributos dessas dimensões.
A função de agregação utilizada foi sumarização dos atributos numéricos (fatos) e o fator de compressão ficou em torno de 76,61%, ficando relativamente próximo de a base.
O fator de compressão considerado é calculado por uma regra de três entre o tamanho do derivador e o tamanho do derivado.
As tabelas Customer e Product se encontram indexadas, a primeira por o atributo Store e a segunda por os atributos Code e Group.
Os metadados para este agregado são:
O esquema se encontra disponível e é composto por as dimensões Product, Time e Customer e por a tabela de fatos Agregado_ 1;
As tabelas Product e Customer são indexadas por os atributos Code e Group e, Store, respectivamente;
Nenhum dos atributos contém restrição de valores;
A função de agregação aplicada sobre os fatos foi SUM;
Os atributos contidos nas tabelas e o tamanho de cada uma de elas são mostrados no Anexo A, sendo que todos os atributos são provindos do esquema derivador.
O segundo agregado criado, representado na Figura 33, para este estudo de caso derivou do esquema original representado na Figura 28.
Em ele, as dimensões Product e Channel foram desconsideradas, a dimensão Customer foi encolhida e os fatos foram sumarizados e contados.
O fator de compressão foi de 0,00207%.
Para o Agregado_ 4, temos os seguintes metadados:
O esquema se encontra disponível e é composto por as dimensões Scenario, Time e CustRetailer e por a tabela de fatos Agregado_ 4;
Nenhuma tabela se encontra indexada e nenhum dos atributos contém restrição ou é calculado;
Foram aplicadas as funções SUM e COUNT nos atributos fatos.
Em este caso, também, todos os atributos são provindos do esquema derivador.
Um agregado derivado de um outro agregado é visto na Figura 34.
O Agregado_ 5 foi derivado do Agregado_ 4, em o qual a dimensão Scenario foi desconsiderada, a dimensão Time foi encolhida e um novo fato aparece, Average_ Price, que corresponde ao cálculo:
O fator de compressão entre Agregado_ 5 e Agregado_ 4 é de 35,29%.
Considerando que o Agregado_ 5 poderia ser construído originalmente a partir de o Agregado_ 1, teríamos o fator de compressão próximo a 0,00095%.
Os metadados para este agregado são:
O esquema se encontra disponível e é composto por as dimensões TimeQtr e CustRetailer e por a tabela de fatos Agregado_ 5;
As tabelas não se encontram indexadas e os atributos não contém restrição de valores;
Foi aplicada a função de agregação SUM sobre os fatos numéricos;
Um atributo calculado foi inserido:
Average_ price.
Um agregado criado a partir de uma das tabelas de fatos secundárias ­ Inventário, é visto na Figura 35, em a qual a dimensão Customer se encontra indexada e as dimensões Product e Time foram encolhidas:
Product contém agora apenas os atributos Line e Division e, a dimensão tempo (Time) não considera mais o atributo mês (Month).
A função de agregação utilizada foi a sumarização e o fator de compressão é de 0,38%.
Temos os seguintes metadados:
O esquema se encontra disponível e é composto por as dimensões ProdLine, TimeQtr e CustRetailer e por a tabela de fatos Agregado_ 2;
A tabela Customer se encontra indexada e os atributos provêm da sua tabela derivadora, não contendo restrição de valores;
Outro agregado criado a partir de a tabela Inventário é visto na Figura 36, onde a dimensão Time foi restrita aos atributos onde Year $= 1996 e as dimensões Customer e Product foram encolhidas:
A primeira considera apenas o atributo Retailer e a segunda é igual a dimensão associada ao Agregado_ 2.
O fator de compressão ficou aproximadamente em 0,042%.
Para o Agregado_ 3, temos os seguintes metadados:
O esquema se encontra disponível e é composto por as dimensões ProdLine, Time e CustRetailer e por a tabela de fatos Agregado_ 3;
Nenhuma tabela se encontra indexada e nenhum dos atributos é calculado, sendo que todos eles provêem do esquema derivador;
A dimensão Time é restrita por o atributo Year;
Foi aplicada a função SUM no atributo fato.
Um exemplo de um agregado que se encontra num quarto nível de agregação é encontrado na Figura 37.
Ele deriva do Agregado 5 (Figura 34) e do Agregado 2 (Figura 35).
As dimensões em comum entre os dois agregados são Customer e Time;
Para a criação deste agregado, a dimensão Customer (e sua versão encolhida) foi excluída e a dimensão Time foi mantida.
O fator de compressão deste agregado com o Agregado_ 2 é de 0,002251% e com o Agregado_ 5 é de 1,3889%.
Os metadados para este agregado são:
O esquema se encontra disponível e é composto por a dimensão TimeQtr e por a tabela de fatos Agregado_ 6;
As tabelas não se encontram indexadas, os atributos não contém restrição de valores e nenhum de eles é calculado;
As Tabela 5 e Tabela 6 sumarizam as operações realizadas sobre as tabelas de fatos e dimensões para criação dos agregados utilizados neste estudo de caso.
As consultas SQL para criação dos agregados a partir de os seus esquemas derivadores e dimensões encolhidas são encontradas no Anexo A. As tabelas encolhidas foram criadas a partir de as dimensões carregadas no SGBD e as chaves das mesmas foram criadas através de recursos oferecidos por o SGBD.
Como a carga só foi realizada para os dados da primeira fase do APB-1 Benchmark e os agregados criados consideraram apenas as duas tabelas de fatos principais, de entre as consultas sugeridas por a documentação da serem submetidas ao DW, duas de elas poderão ser respondidas por os dados contidos no SGBD retidos para este estudo de caso.
Essas consultas consistem em análises de algumas medidas do negócio e elas contêm um modelo (template) que permite a realização de drills nas dimensões contidas no seu modelo:
Consulta 1: Análise das vendas Consulta 3: Análise do inventário dos produtos A descrição do modelo das consultas pode ser visto no Anexo B. Um exemplo de uma consulta submetida ao mecanismo de redirecionamento e que foi reescrita é apresentada na Figura 38.
Ela é uma das formas de exploração possibilitadas por a Consulta 1.
Sendo que P_ Cust e P_ Time são parâmetros de entrada.
Seguindo os passos do algoritmo, teríamos:
Em o passo 1 não é necessário dividir a consulta pois a mesma referência apenas uma tabela de fatos;
Em o passo 2 temos como candidatos os Agregados 1 e 5.
O Agregado 6 foi desconsiderado porque não contém todos os atributos necessários para responder a consulta, o Agregado 4 é desconsiderado uma vez que o Agregado 5 deriva de ele e o Agregado 4 não está indexado e Sales por existirem outros candidatos que possam responder à consulta;
Em o passo 3, os Agregados 1 é eliminado da lista de candidatos pois o ganho obtido por o índice não é maior que o ganho em tamanho, já que o fator de compressão do Agregado 1 com relação a o Agregado 5 é 0,0009547% maior.
Como o parâmetro informado por o administrador para ser utilizado no desempate entre agregados, quando existe uma diferença entre uma agregado` menor' e outro indexado, é de um fator de compressão de até 80%+, escolheríamos o Agregado 5.
Assim, teremos a consulta reescrita vista na Figura 39, onde são encontrados em negrito os atributos e tabelas que foram substituídos, sendo que o atributo Average_ Price substitui o cálculo contido na consulta pois os mesmos são correspondentes.
Comparando os tempo dos agregados em relação a a base (Sales), teríamos as seguintes diferenças percentuais em tempo de resposta:
Sendo que para este exemplo, apesar de a diferença percentual entre os Agregados 4 e 5 ter sido grande, o tempo de resposta dos mesmos para a dada consulta foi muito próximo (quase instantâneo).
Uma das formas de exploração possibilitadas por a Consulta 3 é apresentada na Figura 40, onde P_ Prod, P_ Cust são parâmetros de entrada.
Novamente seguindo os procedimentos do algoritmo, teríamos:
Como a consulta referência apenas uma tabela de fatos, no passo 1 é indicado que iríamos explorar o subgrafo que contém a tabela Inventory como base.
Em o passo 2 verificamos que os agregados 2 e 3 conseguem responder a consulta, pois os dois contêm todos os atributos da consulta e apesar de a restrição contida no Agregado 3, a mesma não interfere na resposta da consulta.
A escolha ficou com o Agregado 3 pois o mesmo contém um fator de compressão maior com relação a a base do que o Agregado 2 e as dimensões associadas a ele contêm menos registros para serem` varridos' por o SGBD.
A consulta da Figura 40 foi reescrita e submetida aos agregados contidos na lista de candidatos.
Temos as seguintes diferenças em tempo de resposta:
O exemplo de uma consulta que envolve mais de uma tabela de fatos é vista na Figura 42, sendo que P_ Ano é um parâmetro de entrada.
Mais uma vez acompanhando os passos do algoritmo, teríamos:
Como a consulta referência mais de uma tabela de fatos, no passo 1 a mesma seria subdividida em dois componentes, e cada um exploraria o subgrafo que contém a tabela de fatos correspondente como raiz da árvore geradora.
Consideraremos que a consulta 1 refere- se a tabela Sales e a consulta 2 à tabela Inventory.
Para a consulta 1, temos que todos agregados do subgrafo conseguem responder a consulta.
O mesmo procedimento é realizado para a consulta 2 e temos que o Agregado 3 não pode responder a consulta devido a a restrição de valores, sendo que mantemos como candidatos os agregados 2 e 6.
Como há uma interseção entre o conjunto de candidatos dos componentes que pertencem à consulta submetida ­ o Agregado 6, a consulta é reescrita para utilizar- lo, ficando como mostrada na Figura 43.
Em este trabalho foi realizado um estudo sobre algumas abordagens relacionadas ao uso de agregados em ambientes de DW.
Foram exploradas num primeiro momento as vantagens que o uso de agregados traria a um DW implantado numa organização, mostrando que a utilização de uma estratégia adequada é de grande valia e pode trazer ganhos através da redução do tempo de resposta das consultas dos usuários.
O estudo de formas de criação de agregados trouxe critérios que se mostraram interessantes de serem seguidos nesta fase de construção.
Verificou- se que em nível organizacional, a utilização de agregados estáticos é bastante importante.
Todavia, para que o uso desses agregados traga reais benefícios à organização, eles devem ser utilizados de forma transparente por o usuário porque se os mesmos tiverem que ser treinados para isso, os agregados acabarão tendo pouca valia (como discutido em).
A construção de um mecanismo de redirecionamento de consultas consciente dos agregados vem ao encontro deste problema.
Foram realizados estudos que abordavam formas de redirecionamento de consultas e representação dos agregados, através de os quais foi possível verificar que haviam poucos trabalhos que abordavam a tarefa do redirecionamento em si.
A análise destes trabalhos mostrou que:
De este modo, este trabalho apresentou um mecanismo de redirecionamento de consultas consciente dos agregados que permite a monitoração e reescrita das consultas submetidas ao DW direcionando- as ao agregado mais adequado, levando em consideração os aspectos não abordados por os trabalhos estudados.
A construção do mecanismo de redirecionamento possibilitou a definição dos metadados necessários para sua utilização e a criação de um algoritmo para a escolha dos candidatos a responder uma consulta.
Algumas dificuldades foram encontradas no decorrer de o trabalho, principalmente no que tange a implementação do estudo de caso.
Em um primeiro momento, um dos grandes problemas encontrados para a criação e manipulação dos dados para o estudo de caso foram os recursos da máquina disponível para esse processo, pois o espaço em disco disponível foi quase que totalmente ocupado apenas com a carga dos dados base.
A seguir, foi adquirida uma máquina com recursos suficientes para que o estudo de caso fosse realizado sem prejuízos.
Contudo devido a os problemas operacionais enfrentados com esta máquina (e.
g Alguns aspectos deste trabalho ainda precisam ser melhor investigados.
Primeiramente poderia ser dada atenção à validação do trabalho, pois devido as dificuldades enfrentadas para realizar- la, os resultados não foram muito satisfatórios, faltando mostrar que critérios foram utilizados para avaliação.
As consultas não muito comuns em ambientes de DW também poderiam passar a ser tratadas por o mecanismo proposto (e.
g consultas contendo union, minus, e operadores como having e distinct).
Em um outro momento, pode ser possível aprofundar mais os estudos em direção a a formalização dos algoritmos apresentados.
Um aspecto que pode ser abordado, é o uso do mecanismo de redirecionamento em múltiplas plataformas e SGBDs para que a parametrização dos critérios mais relevantes na escolha do agregado mais adequado seja feita da melhor forma possível.
Uma outra possibilidade seria a criação de heurísticas para o balanceamento de custos de escolha entre candidatos, i.
e o mecanismo deve ser capaz de verificar sozinho quando índices e tabelas dimensionais encolhidas são mais vantajosos que uma tabela de fatos contendo um número menor de registros, não sendo necessária a utilização de parâmetros externos informados.
Considerando os aspectos de implementação, temos três possibilidades de trabalho:
Tornar a implementação abrangente a toda solução apresentada por o algoritmo proposto;
Encaixar o protótipo do mecanismo entre o SGBD e as várias ferramenta de exploração dos dados ­ front-end;
Criar um módulo com as estatísticas de utilização dos dados do DW através das informações mantidas no log do sistema.
