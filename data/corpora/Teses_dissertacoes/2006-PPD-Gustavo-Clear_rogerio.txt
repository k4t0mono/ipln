Grandes volumes de trabalho para impressão são cada vez mais comuns devido a o aumento da demanda por documentos personalizados.
Em este contexto, Impressão de Dados Variáveis (Variable Data Printing -- VDP) tornou- se uma ferramenta muito útil para profissionais de marketing que necessitam personalizar mensagens para cada cliente em materiais promocionais e campanhas de publicidade.
VDP permite a criação de documentos baseados num modelo (template) contendo partes estáticas e variáveis.
A ferramenta de renderização deve ser capaz de transformar a parte variável num formato composto, ou PDL (Page Description Language) tais como PDF (Portable Document Format), PS (PostScript) ou SVG (Scalable Vector Graphics).
A quantidade de conteúdo variável num documento é totalmente dependente do modelo (layout) da publicação definido por um profissional da área.
Além disso, o conteúdo variável a ser renderizado pode variar de acordo com os dados lidos do banco de dados.
Desta forma, este processo é chamado repetidamente e pode tornar- se facilmente um gargalo, especialmente num ambiente de produção comprometendo inteiramente a geração de um documento.
Em este cenário, técnicas de alto desempenho aparecem como uma interessante alternativa para aumentar o rendimento da fase de renderização.
Este trabalho introduz uma solução paralela portável e escalável para a ferramenta de renderização chamada FOP (Formatting Objects Processor), a qual é usada para renderizar o conteúdo variável expresso em linguagem XSL-FO (eXtensible Stylesheet Language--Formatting Obects).
Criação de documentos personalizados é uma prática cada vez mais comum com a evolução do mundo digital.
A montagem e transformação automática de documentos tornou- se um processo necessário para atender a demanda.
Tipicamente, documentos personalizados contêm áreas que são comuns num conjunto de documentos, e portanto conteúdo estático, assim como áreas personalizadas e variáveis.
Em o método tradicional de informação variável, ferramentas de documentação permitem que os designers definam um modelo que servirá de base para um conjunto de documentos.
Além disso, o designer também define áreas vazias (tamanho fixo), em as quais o conteúdo variável será colocado.
Assim, o layout comum é o mesmo para todos os documentos e embora possa conter dados variáveis, não pode responder a propriedades dinâmicas como redimensionamento do tamanho dos dados variáveis.
Estas limitações têm disparado esforços em pesquisas para automatizar o processo de criação de documentos personalizados.
Documentos podem ser escritos como modelos e a produção pode ser automatizada mantendo um alto nível de qualidade de criação.
Este é o foco desse trabalho, explorar como a geração de tais documentos é alcançada num ambiente de produção.
Casas para imprimir e finalizar documentos.
Tem sido provado que o uso de XSL-FO em partes não definidas do documento torna possível a integração dos dados variáveis tardiamente no processo, até mesmo durante a própria impressão.
Esta forma é claramente mais vantajosa visto que não requer disponibilidade dos dados variáveis durante a fase de projeto (design) do documento.
Também permite a transmissão dos documentos e dados ainda como modelos, ao invés de um documento completamente expandido.
Motivação O objetivo dessa pesquisa é explorar e indicar uma solução escalável e modular para executar a composição de dados variáveis usando ferramentas paralelas de renderização.
A maioria dos ambientes de produção de publicações digitais usam impressoras digitais em paralelo para maximizar o equilíbrio entre os processos, assim como toda a produção de documentos (jobs).
Em tal ambiente, todas as atividades relacionadas à preparação do documento precisam ser executadas num determinado espaço de tempo, já que as tarefas jobs são completados numa ordem seqüencial em múltiplas impressoras.
No caso de impressão de dados variáveis, acima de os passos existentes de preparação para impressão, existe a necessidade de integrar os dados variáveis no modelo e renderizar as partes não definidas ou estáticas do documento.
O processo de renderização é usualmente muito extenso e no caso de milhares de documentos pode tornar- se um gargalo.
Impressoras digitais modernas também são capazes de imprimir na mesma velocidade de um renderizador.
Esta taxa é o mínimo requerido para manter a impressora digital trabalhando em velocidade máxima.
Quando as impressoras digitais são usadas em paralelo, a velocidade do renderizador é multiplicada por o número de impressoras, assim, torna- se muito difícil de alimentar a todas as impressoras na velocidade necessária.
Quando o processo de renderização é centralizado num único processador, uma quebra provavelmente irá acontecer, uma vez que a velocidade das impressoras em paralelo excede a velocidade do processo de renderização criando um gargalo.
Similarmente ao conceito de usar impressoras em paralelo a fim de alcançar um melhor desempenho e mais rapidamente consumir os jobs, nosso objetivo é desenvolver uma proposta para paralelizar a ferramenta de renderização de documentos XSL-FO.
Os resultados mostram que o sistema desenvolvido pode combinar com a velocidade de impressoras rodando em paralelo.
Também temos que considerar que é necessário prover um número adequado de processadores para atingir a velocidade ideal.
Os resultados deste trabalho mostram uma solução modular e escalável para impressão de dados variáveis com renderização em tempo de impressão.
Estrutura do Volume Este trabalho foi dividido em 6 capítulos incluindo introdução e conclusão.
Os quatro primeiros descrevem as bases teóricas a esta dissertação.
Em o Capítulo 2, é feita uma conceituação de engenharia de documentos apresentando alguns padrões, linguagens e ferramentas utilizados na area de publica¸ ções digitais.
Em o Capítulo 3, conceitos de processamento de alto desempenho são brevemente citados também como embasamento para a dissertação.
Uma análise do problema em sua versão seqüencial é descrito no Capítulo 4 assim como um posicionamento em relação a as bases teóricas listadas.
Além disso, neste Capítulo o ambiente utilizado para desenvolvimento da solução paralela e uma descrição dos documentos utilizados para a realização dos testes são abordados.
Nos demais capítulos estão as principais contribuições obtidas ao longo de esta dissertação.
Em o Capítulo 5, apresenta- se as estratégias de paralelização da ferramenta FOP utilizadas até atingir- se o modelo atual.
Finalmente, na conclusão são tecidas as considerações finais a respeito de o modelo proposto bem como os trabalhos futuros relacionados.
Engenharia de Documentos Engenharia de Documentos está desenvolvendo- se como uma nova disciplina para especificar, esboçar, e implementar documentos eletr^ onicos que fornecem interfaces para processos de negócios via serviços baseados em Web.
Em o mundo dos negócios, documentos sempre tiveram um papel fundamental como meio de` medida que as empresas crescentemente interação entre o negócio e as pessoas envolvidas.
A movem suas atividades para a Internet e experimentam novas maneiras de como fazer negócios, podemos começar a tratar documentos como interfaces.
Muitos tipos de documentos são essenciais para os negócios.
Alguns como catálogos, brochuras e folhetos ajudam os compradores a localizar e selecionar produtos e serviços.
Outros como guias de usuários e manuais, são feitos para proverem um uso mais efetivo dos produtos e serviços após a compra.
Primeiramente, documentos na Web eram usados somente para documentos não-transacionais.
Mais tarde, com o avanço das tecnologias documentos como pedidos, faturas, passaram a ter grande importância como tipos de documentos eletr^ onicos.
Definições Documentos narrativos são tradicionalmente chamados de publicações e a técnica de análise e modelagem empregada é denominada análise de documentos.
Como contraste, documentos transacionais são otimizados para uso em negócios e diferem substancialmente das publicações orientadas a usuários.
O método utilizado neste caso é nomeado modelagem de dados.
A Engenharia de Documentos surge então como uma mescla desses métodos sendo efetivo tanto para documentos narrativos como para transacionais.
Documentos modelos podem ser criados e reutilizados para diferentes tipos de negócios, encorajando os criadores a balanceálos para negócios internos e a necessidade de serem entendidos em outras áreas.
Análise de Documentos Análise de documentos é conduzida com o objetivo de abstrair um modelo lógico de uma instância existente de um tipo de documento único codificando o modelo num esquema XML (EXtensible Markup Language).
O método de análise de documentos permite aos usuários executarem tarefas específicas com novas instâncias criadas a partir de o documento.
Por exemplo, quando o tipo de documento é uma publicação, o novo esquema separa descrição da estrutura do documento e o conteúdo da estrutura de apresentação do mesmo.
Isto inclui fontes, tamanhos e atributos de formatação que são usados para representar ou ressaltar vários conteúdos.
Assim que essa separação acontece, um ou mais estilos podem ser utilizados para formatar de maneira consistente qualquer instância válida do documento.
Modelagem de Dados A Modelagem de dados é dedicado a entender e descrever uma estrutura lógica de objetos de dados que têm várias propriedades e associações umas com as outras.
O objetivo típico da modelagem de dados é definir uma ou mais categorias ou esquemas para organizar essas propriedades e associações eficientemente para criar, revisar, apagar objetos de dados ou para encontrar aqueles com características específicas.
Análise de documentos e modelagem de dados compartilha o objetivo de criar uma descrição formal de uma classe de instâncias, porém o método é melhor aplicado quando não há um número ilimitado de instâncias idênticas.
Unificando Análise de Documentos e Modelagem de Dados Análise de documentos e modelagem de dados são provenientes de diferentes disciplinas e utilizam diferentes ferramentas, terminologias e técnicas.
Especialistas de cada área não sabiam como conversar e também não reconheciam uma parte comum em ambos objetivos.
Ambos oferecem valiosas contribuições para criação de documentos porém têm tido pouca interação.
A Engenharia de Documentos unifica estas duas perspectivas identificando e enfatizando o que têm em comum ao invés de ressaltar suas diferenças.
Antes da análise de como a Engenharia de Documentos utiliza os conceitos de análise de documentos e modelagem de dados, é importante que sejam apresentados os três tipos de informações encontradas em documentos:·
Conteúdo -- informação que diz &quot;o que isso significa».·
Estrutura -- &quot;onde é isso «ou &quot;como isso é organizado ou montado».
Agrega conteúdo e informação em mais de um componente reusável.·
Apresentação -- &quot;como isso é mostrado».
Embora o item apresentação seja o menos importante, é essencial analisar- lo com cuidado, primeiramente devido a a sua correlação com a estrutura e o conteúdo.
Correlações estas que seguem padrões para diferentes tipos de documentos.
Os pontos cruciais da análise e modelagem de dados harmonizados na Engenharia de Documentos são:·
Identificar a apresentação, conteúdo, e componentes estruturais definindo os relacionamentos entre si.·
Identificar componentes de &quot;bom «conteúdo.·
Esboçar, descrever, e organizar padrões para facilitar o reuso.·
Montar modelos de documentos hierárquicos para organizar os componentes de acordo com os requerimentos de um contexto específico.
Em este contexto, XML é uma tecnologia quem tem se destacado bastante no contexto da Engenharia de Documentos.
De entre suas principais vantagens, podem ser citados:·
Permite que novos vocabulários sejam criados para tipos particulares de documentos.´
uma linguagem hierárquica (o que facilita a organização dos componentes).·
Facilita a integração de uma variedade de paradigmas tais como banco de dados, orientação a objetos, e estrutura de documentos.
Com o crescimento da Engenharia de Documentos e a facilidade de mesclar layout e conteúdos provenientes de banco de dados, várias empresas começaram a desenvolver padrões baseados em XML para controlar o processo de impressão.
Documentos personalizados para diferentes campanhas de marketing aumentaram essa necessidade assim como a capacidade das impressoras digitais cada vez mais poderosas.
Para impedir a crescente criação de modelos de composição de documentos por parte de empresas que lidam diretamente com impressão digital, foi criado um consórcio de empresas que trabalhariam unidas na definição de uma linguagem única de impressão.
Os membros dessa iniciativa desenvolveram uma linguagem não-proprietária denominada PPML PPML é uma linguagem padrão utilizada para impressão digital construída a partir de XML desenvolvida por o PODi.
PPML tem sido designado para melhorar o processo de rasterização para o conteúdo de documentos que usam linguagens tradicionais de impressão.
PPML na verdade introduz o método de conteúdo reusável através de o qual conteúdos usados em muitas páginas podem ser enviados para a impressora uma única vez e acessados quantas vezes for necessário.
Isto permite que conteúdos de alta qualidade gráfica sejam rasterizados também uma única vez e acessados através de instruções modelo ao invés de reenviar- se todo o gráfico toda vez que o mesmo deva ser impresso.
Cada objeto reusável em PPML é chamado recurso.
A fim de garantir que todos os recursos estejam disponíveis e a impressora digital possa acessar- los, PPML permite referências externas URL (Universal Resource Identifier).
Usualmente, a impressora digital pode acessar os recursos requeridos diretamente de uma unidade disco local ou através de uma LAN (Local Area Network).
O conteúdo variável é integrado dentro de o objeto PPML e é formatado através do uso de XSL-FO.
O objeto que contém o XSL-FO é denominado &quot;copy-hole», que é uma área definida no PPML a qual pode conter um conteúdo variável expresso na própria linguagem XSL-FO ou conteúdo não variável como imagens TIFF (Tagged Image File Format), BMP (Bit-Mapped Graphic), etc..
XSL-FO (também abreviado como FO -- Formatting Objects) é um padrão definido por o consórcio W3C (World Wide Web Consortium), o qual conta com empresas envolvidas com Internet e Web, introduzido para formatar conteúdo XML em mídias paginadas.
De modo ideal, funciona em conjunto com XSL-T (eXtensible Stylesheet Language -- Transformations) para mapear conteúdo XML num modelo de página.
Quando o XSL-FO é completado com ambos:
Modelo de paginação e conteúdo formatado, o renderizador XSL-FO executa o passo de composição do conteúdo dentro de as páginas obtendo assim o documento final conforme ilustrado na Figura 2.1.
A composição é um passo complexo e requer ordem de impressão assim como conhecimento do modelo.
A ferramenta de renderização XSL-FO usada em nossa solução é o FOP (Formatting Object Processor).
Podemos dizer que PPML é utilizado para definição do layout da página e XSL-FO contém a parte renderizável por a ferramenta FOP dentro de a página.
PPML é hierárquico.
Como podemos ver em 2.2, o elemento raiz pode conter elementos Tarefas (Job), que podem conter Documentos (DOCUMENTS), que contêm Páginas (PAGE), as quais contêm marcas (MARKS) os quais são denominados copy-- holes.
Em um documento PPML podemos encontrar copy-- holes cujo conteúdo pode ser uma imagem, espaço em branco, ou um conteúdo de texto.
Em este trabalho, estamos particularmente interessados em conteúdos de textos representados em XSL Formatting Objects, ou simplesmente XSL-FO, visto que é a linguagem de entrada para a ferramenta de renderização FOP.
XSL-FO é um vocabulário que descreve como as páginas irão aparecer para o leitor.
Existem 56 elementos XSL-FO todos listados em sendo 99% de eles inicializados por o prefixo fo.
Os objetos de formatação (FOs) diferem basicamente naquilo que cada um de eles representa.
Por exemplo, o objeto fo:
List-item- label é um marcador localizado na frente de uma lista.
Pode ser um número, uma bolinha ou um caracter qualquer.
Um fo:
List-item-body contem o texto de um item na lista.
Um FO quando processado, pode ser quebrado em mais de uma página e para facilitar a impressão, foi dividido em quatro áreas principais também hierárquicas como PPML:·
Regiões: Nível mais alto da hierarquia.
Pode- se imaginar como uma região de uma página contendo cabeçalho, texto e rodapé.
FOs que produzem regiões são do tipo fo:
Region-body, fo:
Region- after.·
Blocos: Representam um bloco de texto como um parágrafo.
Fo: Block e fo: List--
block são exemplos.·
Linhas: Esta área representa uma linha de texto dentro de um parágrafo.·
Entre linhas:
São partes de uma linha como um simples caracter, uma referência de rodapé, ou uma equação matemática.
Fo: external-graphic, fo:
Inline, etc..
Em um documento PPML, um copy-hole contendo XSL-FO é facilmente identificado por o delimitador Root\&gt; Root\&gt;, como mostrado em 2.3.
A combinação de PPML e XSL-FO tem sido escolhida para representar modelos de documentos com alto grau de flexibilidade, reusabilidade e otimização de impressão.
A sinergia alcançada por essa combinação garante que a parte não variável do modelo seja expressa como reusáveis, e a parte variável como fragmentos XSL-FO.
Após a inserção dos dados variáveis no documento, várias instâncias de documentos são formadas.
O passo final é compor ou renderizar as partes em XSL-FO numa linguagem de descrição de página (PDL -- Page Description Language) que nada mais é do que dispor os comandos de uma página impressa para comandos que a impressora possa executar- los.
PCL (Printer Control Language) da Hp e Postscript da Adobe são dois dos PDLs mais utilizado atualmente.
O processo de renderização é processado por a ferramenta FOP.
FOP é um dos mais comuns processadores no mercado não somente porque é uma aplicação de código aberto, mas também porque provê uma grande variedade de formatos de saída além´ uma aplica¸ de flexibilidade.
E cão Java que lê objetos de formatação (FO) renderizando para diferentes formatos de saída tais como PDF, PostScript, SVG, que é o foco dos resultados de renderizações realizadas nesse trabalho, entre outros.
A Figura 2.4 mostra como o processo de renderização é feito com o uso da ferramenta FOP partindo- se de um documento PPML contendo copy-- holes em XSL-FO.
A o ser localizado no documento uma marca que indica um copy-hole, Position $ ' X1, Y1 minute\&gt;, a área delimitada por as entradas fo:
Root é enviada para a ferramenta FOP que devolverá o mesmo conteúdo renderizado em SVG.
O texto renderizado é realocado na mesma posição onde encontrava- se o XSL-FO no documento PPML.
O processo de renderização é tipicamente composto por três diferentes passos como ilustrado por a Figura 2.5.
Geração de uma árvore de objetos de formatação e resolução de propriedades;
Geração de uma árvore de trabalho (area tree) representando o documento modelado composto por uma hierarquia retangular tendo as folhas como elementos de texto ou imagens;
Conversão ou mapeamento da árvore de trabalho (area tree) para o formato de saída.
As vantagens deste método estão na completa independência entre a representação do documento XSL-FO e a construção interna da árvore de trabalho.
De este modo, é possível mapear a area tree para diferentes conjuntos de PDLs.
Processamento de Alto Desempenho Aárea de processamento de alto desempenho vem se tornando ao longo de os anos cada vez mais necessária para que se possa obter, de forma efetiva, a solução de grandes problemas científicos.
Em tais problemas, muitas vezes, os computadores tradicionais não conseguem produzir um resultado necessário dentro de limites de tempo razoáveis, comprometendo assim a viabilidade das soluções para estes problemas.
Por outro lado, sistemas computacionais de alto desempenho, principalmente aqueles com arquitetura paralela, oferecem um maior potencial para a abordagem.
Tais sistemas devem ser utilizados de forma que se possa efetivamente aproveitar a maior capacidade computacional disponível.
Este Capítulo, apresenta de forma resumida alguns dos principais conceitos abordados na area de processamento de alto desempenho tais como, modelos de arquiteturas, programa¸ ção e algoritmos, assim como alguns fatores de desempenho utilizados para medir o ganho em relação a versão seqüencial.
Modelos de Arquiteturas de Processamento Paralelo Muito já foi desenvolvido em termos de hardware paralelo, e várias classificações foram propostas.
A mais conhecida por a comunidade computacional é a classificação de Flynn, que apesar de antiga é bastante respeitada.
Já a classificação de Duncan, mais recente, representa o esforço de acomodar novas arquiteturas que surgiram após a taxonomia de Flynn.
Classificação de Flynn Segundo Flynn, o processo computacional deve ser visto como uma relação entre fluxos de instruções e fluxos de dados.
Um fluxo de instruções equivale a uma seqüência de instruções executadas (num processador) sobre um fluxo de dados aos quais estas instruções estão relacionadas.
As arquiteturas de computadores são divididas em 4 classes cada uma apresentando um esquema genérico de acordo com o fluxo de dados e instruções.
Single Instruction Stream/ Single Data Stream (fluxo único de Instruções/ fluxo único de dados) corresponde ao tradicional modelo Von Neumann.
Um processador executa seqüencialmente um conjunto de instruções sobre um conjunto de dados (Figura 3.2).
Single Instruction Stream/ Multiple Data Stream (fluxo único de instruções/ fluxo múltiplo de dados).
Envolve múltiplos processadores controlados por uma única unidade mestre executando simultaneamente a mesma instrução em diversos conjuntos de dados (Figura 3.3).
Arquiteturas SIMD são utilizadas para manipulação de matrizes e processamento de imagens.
Multiple Instruction Stream/ Single Data Stream (Fluxo múltiplo de instruções/ Fluxo único de dados).
Envolve múltiplos processadores executando diferentes instruções num único conjunto de dados.
Diferentes instruções operam a mesma posição de memória ao mesmo tempo, executando instruções diferentes.
Esta classe é considerada vazia, por ser tecnicamente impraticável. (
Figura 3.4).
Multiple Instruction Stream/ Multiple Data Stream (fluxo múltiplo de instruções/ fluxo múltiplo de dados).
Envolve múltiplos processadores executando diferentes instruções em diferentes conjuntos de dados, de maneira independente (Figura 3.5).
Esta classe engloba a maioria dos computadores paralelos.
Dentro de a classificação MIMD enquadram- se os seguintes modelos de arquiteturas:
Máquinas Vetoriais (PVP -- Parallel Vector Processor) -- máquinas que possuem processadores compostos de vários pipelines vetoriais com alto poder de processamento.
Cray e NEC são exemplos de máquinas vetoriais.
Multiprocessadores Simétricos (SMP -- Symmetric Multiprocessing) -- são sistemas constituídos de vários processadores comerciais, conectados a uma memória compartilhada, na maioria dos casos através de um barramento de alta velocidade.
Máquinas Massivamente Paralelas (MPP -- Massively Parallel Processing) -- diversos microprocessadores interligados através de uma rede de interconexão normalmente proprietária.
Cada nó de processamento da malha de interconexão pode possuir mais de um processador e podem existir máquinas com milhares destes nós.
A diferença em relação a os dois últimos modelos de máquinas é que estas não possuem uma memória compartilhada.
Memória Compartilhada Distribuída (DSM -- Distributed Shared Memory) -- sistemas em que, apesar de a memória encontrar- se fisicamente distribuída através dos nós, todos os processadores podem endereçar todas as memórias.
Isso se deve à implementação de um único espaço de endereçamento.
Ethernet e ATM (Asynchronous Transfer Mode).
Em a prática, uma rede local de estações que já existe é utilizada para execução de aplicações paralelas.
Grades computacionais -- são ambientes para computação distribuída de alto desempenho que permitem o compartilhamento de recursos heterogêneos.
Uma grade é uma coleção de recursos computacionais distribuídos sobre uma rede, que estão disponíveis a um usuário ou a uma aplicação.
Grade computacional é uma infra-estrutura de software e hardware que provê serviços seguros, consistentes, de acesso penetrante a um custo relativamente acessível.
Classificação de Duncan A classificação de Duncan surgiu da necessidade de acomodar arquiteturas mais recentes.
Duncan exclui arquiteturas que apresentem apenas mecanismos de paralelismo de baixo nível (pipeline, múltiplas unidades funcionais e processadores dedicados para entrada e saída), que já se tornaram lugar comum nos computadores modernos, e mantém os elementos da classificação de Flynn, no que diz respeito ao fluxo de dados e instruções.
A classificação de Duncan apresentada na Figura 3.6, divide as arquiteturas em dois grupos principais:
Arquiteturas síncronas e assíncronas.
Arquiteturas Síncronas Arquiteturas paralelas síncronas coordenam suas operações concorrentes sincronamente em todos os processadores, através de relógios globais, unidades de controle únicas ou controladores de unidades vetoriais.
Tais arquiteturas apresentam pouca flexibilidade para a expressão de algoritmos paralelos.·
Processadores Vetoriais: São caracterizados por possuírem um hardware específico (múltiplas unidades funcionais organizadas utilizando pipeline) para a otimização de operações efetuadas sobre vetores.·
Arquiteturas SIMD:
Arquiteturas SIMD apresentam múltiplos processadores, sob a supervisão de uma unidade central de controle, que executam a mesma instrução sincronamente em conjuntos de dados distintos.·
Arquiteturas Sistólicas: Têm como principal objetivo fornecer uma estrutura eficiente para a solução de problemas que necessitem de computação intensiva junto a grande quantidade de operações de E/ S. Essas arquiteturas se caracterizam por a presença de vários processadores, organizados de maneira pipeline, que formam uma cadeia em a qual apenas os processadores localizados nos limites desta estrutura possuem comunicação com a memória.
Arquiteturas Assíncronas Estas arquiteturas caracterizam- se por o controle descentralizado de hardware, de maneira que os processadores são independentes entre si.
Essa categoria é formada por as máquinas MIMD, sejam elas convencionais ou não.·
Arquiteturas MIMD:
Relacionam arquiteturas compostas por vários processadores independentes, onde se executam diferentes fluxos de instruções em dados locais a esses processadores.·
Paradigma MIMD:
Essa classe engloba as arquiteturas assíncronas que, apesar de apresentarem a característica de multiplicidade de fluxo de dados e instruções das arquiteturas MIMD, são organizadas segundo conceitos tão fundamentais a seu projeto quanto suas características MIMD.
Estas características próprias de cada arquitetura, dificultam a sua classificação como puramente MIMD.
Por isso, tais arquiteturas se denominam paradigmas arquiteturais MIMD.
Compartilhamento de Memória Um outro critério para a classificação de máquinas paralelas é o compartilhamento da memória.
Memória compartilhada é assim denominada quando dois ou mais processos compartilham uma mesma região de memória.
É a maneira mais rápida dos processadores efetuarem uma troca de dados, porém um lugar da memória não pode ser modificado por uma tarefa enquanto outra estiver acessando.
A Figura 3.7 mostra como o acesso à memória por os processadores é feito.
Máquinas SMP utilizam este modelo.
Em arquiteturas de memória distribuída, cada processador possui sua própria memória local, sendo então fracamente acoplados.
Em virtude de não haver compartilhamento de memória, os processos comunicam- se via troca de mensagens, que se trata da transferência explicita de dados entre os processadores.
Dependendo de uma máquina paralela utilizar- se ou não de uma memória compartilhada por todos os processadores, pode- se diferenciar:
Multiprocessadores ou Multicomputadores.
Multiprocessadores Esse tipo de máquina possui apenas um espaço de endereçamento, de forma que todos os processadores P são capazes de endereçar todas as memórias M. Essas características resultam do fato desse tipo de máquina paralela ser construída a partir de a replicação apenas do componente processador de uma arquitetura convencional conforme mostra a Figura 3.9.
De aí o nome múltiplos processadores.
Em relação a o tipo de acesso às memórias do sistema, multiprocessadores podem ser classificados como:
Uma (Uniform Memory Access), Em uma (Non-Uniform Memory Access) e Coma (Cache-Only Memory Architecture).
A memória usada nessas máquinas é centralizada e encontra- se à mesma distância de todos os processadores, fazendo com que a latência de acesso à memória seja igual para todos os processadores do sistema (uniforme) (Figura 3.10).
Como o barramento é a rede de interconexão mais usada nessas máquinas e suporta apenas uma transação por vez, a memória principal é normalmente implementada com um único bloco.
A memória usada nessas máquinas é distribuída, implementada com múltiplos módulos que são associados um a cada processador.
O espaço de endereçamento éúnico, e cada processador pode endereçar toda a memória do sistema.
Se o endereço gerado por o processador encontrar- se no módulo de memória diretamente ligado a ele (local) o tempo de acesso a ele será menor que o tempo de acesso a um módulo que está diretamente ligado a outro processador (remoto) que só pode ser acessado através da rede de interconexão.
Por esse motivo, essas máquinas possuem um acesso não uniforme à memória.
Em uma máquina Coma, todas as memórias locais estão estruturadas como memórias cache e são chamadas de Coma caches.
Essas caches têm muito mais capacidade que uma cache tradicional.
Arquiteturas Coma têm suporte de hardware para a replicação efetiva do mesmo bloco de cache em múltiplos nós fazendo com que essas arquiteturas sejam mais caras de implementar que as máquinas Em uma.
Multicomputadores Cada processador P possui uma memória local M, a qual só ele tem acesso.
As memórias dos outros processadores são consideradas memórias remotas e possuem espaços de endereçamento distintos.
Como não é possível o uso de variáveis compartilhadas nesse ambiente, a troca de informações com outros processos é feita por envio de mensagens por a rede de interconexão.
Por essa razão, essas máquinas também são chamadas de sistemas de troca de mensagens.
Em relação a o tipo de acesso às memórias do sistema, multicomputadores podem ser classi- ficados como:
Norma (Non-Remote Memory Access).
Como uma arquitetura tradicional inteira foi replicada na construção dessas máquinas, os registradores de endereçamento de cada nó só conseguem endereçar a sua memória local.
Modelos de Programação Paralela Os modelos de programação paralela existem como uma camada de abstração sobre a arquitetura do hardware e da memória do computador.
No entanto, esses modelos não são específicos de uma determinada arquitetura nem de um tipo de memória.
Geralmente, a escolha do modelo a ser utilizado depende do programador, do tipo de hardware disponível e das características da aplicação.
Paralelismo Implícito e Explícito Em o paralelismo explícito, a linguagem de programação contém mecanismos para paralelização do programa.
Desta forma, o programador pode utilizar seu conhecimento empírico para explorar ao máximo o potencial de paralelização de suas aplicações.
No entanto, de acordo com paralelização de programas é muito difícil para ser realizado por pessoas.
Por exemplo, somente compiladores são confiáveis para realização da análise de dependências em sistemas paralelos com memória compartilhada.
Por outro lado, deve- se ressaltar que o paralelismo explícito diminui a complexidade dos compiladores paralelizadores, pois elimina a necessidade da detecção automática do paralelismo em tempo de compilação.
Em o paralelismo implícito, a linguagem de programação não contém mecanismos para paralelização dos programas.
A principal vantagem deste método consiste na liberação do programador do envolvimento com a paralelização de suas aplicações.
Além disso, o paralelismo implícito aumenta a portabilidade de programas entre sistemas paralelos, eliminando a necessidade da alteração do código fonte em função de a arquitetura paralela a ser utilizada.
Outra característica interessante da exploração automática consiste no aproveitamento tanto dos programas seqüenciais já existentes quanto dos ambientes de desenvolvimento (depuração) direcionados para o paradigma seqüencial.
Paralelismo de Dados O paralelismo de dados representa o uso de múltiplas unidades para se aplicar a mesma operação simultaneamente num dado conjunto de elementos.
Segundo, K unidades de processamento adicionais geram um aumento de vazão de K vezes no sistema.
Por vazão, entende- se o número de resultados obtidos por ciclo de tempo.
A execução deste tipo de algoritmo pode ser verificada, por exemplo, em algoritmos paralelos de multiplicação de matrizes.
Troca de Mensagens O desenvolvimento de programas paralelos e distribuídos encontra na programação baseada em troca de mensagens, uma abordagem eficaz para explorar as características das máquinas de memória distribuída.
Com o uso de clusters e de bibliotecas de suporte às trocas de mensagens, como o padrão MPI (Message Passing Interface), aplicações eficientes e economicamente viáveis podem ser construídas.
MPI é uma biblioteca que contém funções para implementar programas que executam trocas de mensagens numa ambiente distribuído.
Estes programas rodam num cluster e o ambiente MPI se encarrega da distribuição destes processos.
Existem implementações de MPI para diversas plataformas de hardware e software.
Isto quer dizer que é possível montar um cluster com nós de diferentes arquiteturas e usar MPI para resolver um problema de maneira distribuída.
Uma utilidade imediata disto seria utilizar arquiteturas especializadas num tipo de processamento para resolver partes do problema que devem assim ser abordados.
No entanto isto imediatamente nos leva a nos perguntarmos como podemos trocar mensagens entre máquinas de arquiteturas diferentes, que possuem tipos internos de dados diferentes.
Para resolver este problema, MPI define seus próprios tipos básicos, que são independentes da arquitetura real da máquina.
MPI se encarrega de converter esses tipos de dados para os tipos de dados internos.
Modelos de Algoritmos Paralelos Existem vários modelos de programação paralela que podem ser escolhidos por o programador para estruturar ou organizar o desenvolvimento de programas.
A escolha de um ou de outro depende das características da aplicação, dos recursos computacionais disponíveis para quem vai desenvolver o programa e do tipo de paralelismo encontrado no problema.
Em as próximas seções, é explicado, resumidamente, alguns dos paradigmas mais comumente utilizados na implementação de programas paralelos.
Divisão e Conquista Um algoritmo de divisão e conquista primeiramente divide o problema original em diversos subproblemas, que são mais fáceis de se resolver do que o original, e então resolve os subproblemas, geralmente recursivamente.
Finalmente o algoritmo mescla as soluções dos subproblemas para construir uma solução de um problema original.
Pipeline Em o paradigma pipeline um número de processos forma um pipeline virtual.
Os processos podem formar esses pipelines de uma maneira linear, multidimensional, cíclica ou acíclica.
Um fluxo contínuo de dados entra no primeiro estágio do pipeline e os processos são executados nos demais estágios complementares, de forma simultânea.
Cada processo no pipeline pode ser visto como um consumidor de uma seqüência de dados precedendo- o no pipeline e como produtor de dados sucedendo- o no pipeline.
Mestre/ Escravo Em este paradigma, um ou mais processos mestre executam as tarefas essenciais do programa paralelo e dividem o resto das tarefas para os processos escravos.
Quando um processo escravo termina sua tarefa, ele informa o mestre que atribui uma nova tarefa para o escravo.
Este paradigma é bastante simples, visto que o controle está centralizado num processo mestre.
Sua desvantagem é que o mestre pode se tornar o gargalo na comunicação.
Isso acontece quando as tarefas são muito pequenas (ou escravos são relativamente rápidos).
Pool de Trabalho Em este modelo, um pool (conjunto) de tarefas é disponibilizado por uma estrutura de dados global e um determinado número de processos é criado para executar esse conjunto de tarefas.
Em o início só existe um único pedaço de tarefa;
Gradativamente os processos buscam pedaços da tarefa e imediatamente passam a executar- los, espalhando o processamento.
O programa paralelo termina quando o pool de trabalho fica vazio.
Fases Paralelas Em este modelo, a aplicação consiste num número de etapas, onde cada etapa é dividida em duas fases:
Uma fase de computação, quando os múltiplos processos executam processamentos independentes;
Seguida de uma fase de interação, quando os processos executam uma ou mais operações de interação síncrona, tais como barreiras ou comunicações bloqueantes.
Critérios de Avaliação Uma característica fundamental da computação paralela trata- se do aumento de velocidade de processamento através da utilização do paralelismo.
Em este contexto, duas medidas muito importantes, de entre várias outras, para a verificação da qualidade de algoritmos paralelos são aceleração (speedup) e eficiência.
Aceleração é o aumento de velocidade observado quando se executa um determinado processo em p processadores em relação a a execução deste processo num único processador.
Speedup $= Onde, Tp T1 $= tempo de execução em 1 processador (serial) Tp $= tempo de execução em p processadores (paralela) O ganho de speedup deveria tender a p, que seria o seu valor ideal 1.
Outra medida importante é a eficiência, que trata da relação entre o speedup e o número de processadores.
Tal medida é obtida através da seguinte fórmula:
Eficiência $= speedup Np Np é o número de processadores utilizados para executar o programa paralelo.
Dada as fórmulas acima, nota- se que o speedup ideal deve ser igual a quantidade de processadores utilizados no programa paralelo.
A eficiência deve estar entre zero e um, pois indica um valor relativo.
Se for alcançado um speedup ideal também é alcançada a eficiência ideal que é igual a 1.
Fatores de Desempenho Granularidade A granularidade de um sistema paralelo corresponde ao tamanho das unidades de trabalho submetidas aos processadores.
Isto acaba influenciando na determinação do porte e da quantidade de processadores, uma vez que existe uma relação entre esses dois fatores.
Em uma linguagem seqüencial, a unidade de paralelismo é todo o programa.
Em uma linguagem paralela, entretanto, a unidade de paralelismo pode ser definida, em ordem decrescente de granularidade, como um processo, um objeto, um comando, uma expressão ou uma cláusula O nível de granularidade varia de fina (muito pouco processamento por comunicação de byte) a grossa.
Quanto mais fina a granularidade, menor a aceleração devido a a quantidade de sincronização exigida.
Portabilidade Portabilidade é a capacidade que um software tem de ser compilado ou executado em diferentes arquiteturas de sistemas computacionais (diferentes arquiteturas de hardware ou de sistema operacional).
Escalabilidade Escalabilidade é a capacidade de evoluir um software ou fazer com que o mesmo obtenha recursos adicionais sem perda de desempenho em sua funcionalidade.
Definições Gerais Em este Capítulo é apresentado uma análise do problema enfrentado atualmente com a versão seqüencial da ferramenta FOP.
Além disso, um posicionamento em relação a o embasamento descrito nos Capítulos anteriores assim como uma descrição do ambiente de testes e hardware utilizados na obtenção dos resultados.
Análise do Problema Impressoras digitais atualmente encontradas no mercado têm velocidade de rasterização que chegam a cerca de 60 páginas por minuto, que significa cerca de uma página por segundo.
Isto é possível se a página já esteja representada num formato que a impressora possa consumir, ou seja, já tenha passado por o processo de renderização e também rasterização.
O conteúdo variável de uma página representado em XSL-FO varia de acordo com a publicação desenhada por o designer.
Isto significa que uma página pode conter somente um único´ importante que o processo XSL-FO a ser renderizado num documento PPML ou vários.
E de renderização sustente este tipo de desempenho médio para que a impressora consiga atingir seu potencial máximo de impressão.
Em a Figura 4.1, podemos notar que após o processo de renderização há ainda outro processo denominado rasterização que irá justamente converter o documento PPML na linguagem da impressora.
Entretanto, este processo é bem mais rápido do que a fase de renderização não ameaçando o desempenho da impressão.
De modo contrário, dependendo da quantidade de copy-- holes contendo dados variáveis em XSL-FO, a fase de renderização pode tornar- se um gargalo.
Em a versão seqüencial da ferramenta FOP, somente um XSL-FO pode ser enviado por vez ficando o processo de renderização parado até que o XSL-FO enviado seja completamente renderizado e realocado em sua posição de origem no documento PPML (Figura 4.2).
Em casas de impressão de grande porte, o número de copy-- holes com conteúdo variável pode facilmente chegar a milhões.
Por esse motivo, é comum disparar a renderização horas antes do processo de impressão para que não se perca tempo.
Muitas vezes esse processo é executado durante a noite para que a impressão ocorra sem problemas durante o dia.
Devido a a grande quantidade de dados a serem impressos, uma impressão de uma campanha de publicidade para um grande cliente pode durar muitas horas.
Em este cenário, qualquer ganho de desempenho significa muito tempo do total de horas utilizado.
Isso é fundamental para que um cliente decida por uma casa de impressão e não outra na hora de solicitar o serviço.
Em busca desse ganho de desempenho, a proposta de paralelização da fase de renderização através do uso da ferramenta FOP torna- se uma solução de grande significado, pois aumentaria em muito a velocidade com que os documentos são renderizados dando a possibilidade de um aproveitamento maior da real capacidade de impressão das atuais impressoras digitais disponíveis no mercado.
A arquitetura mostra que o arquivo PPML é lido e salvo num dispositivo de disco ou qualquer outra mídia de entrada/ saída.
Isto será melhor apresentado no Capítulo 5, porém é importante destacarmos este fator que é de fundamental relevância para ambos os modelos:
Posicionamento O primeiro problema que um programador de aplicações de alto desempenho tem que lidar é com a escolha entre arquiteturas multiprocessadas ou multicomputadores.
Máquinas multiprocessadas, como apresentado na Seção 3.1 do Capítulo 3, utilizam um esquema global de acesso à memória, e geralmente precisam de um bom barramento para interconexão entre processadores e memória.
Hoje em dia, tais máquinas estão perdendo espaço para plataformas de multicomputadores como clusters ou grades computacionais.
Estas máquinas apresentam um esquema de memória distribuída, e no caso de clusters, são conectados por uma rede rápida dedicada.
O desenvolvimento de aplicações para esses tipos de máquinas é bem diferente.
O primeiro modelo é baseado no paradigma de memória compartilhada e o segundo é tipicamente baseado no paradigma de troca de mensagens.
Programar para plataformas com memória distribuída é mais complexo porque cada processador da arquitetura tem uma memória local e não pode acessar diretamente a memória de outros processadores.
Em este cenário, a aplicação deve ser dividida em módulos, também chamados de processos, que não compartilham o mesmo espaço de endereçamento entre eles.
Assim, os processos não podem trocar informações através de variáveis compartilhadas.
A alternativa é prover uma série de comunicações primitivas as quais baseiam- se em duas funcionalidades principais:
Considerando que portabilidade e escalabilidade são funcionalidades desejáveis em implementações de alto desempenho, decidimos adotar a linguagem de programação Java em nossa implementação.
Java não é freqüentemente utilizada para esse tipo de aplicações por duas razões:
É uma linguagem interpretada e é baseada num ambiente virtual (JVM Java Virtual Machine), que garante a portabilidade.
Estes dois fatores são responsáveis por um custo computacional que na maioria das vezes é considerado muito significativo por os desenvolvedores de aplicações de alto desempenho.
Entretanto, nesta implementação, portabilidade e compatibilidade com diferentes sistemas operacionais são cruciais.
Para o desenvolvimento deste trabalho foi utilizado o Java Standard Development Kit e o modelo de programação paralela por passagem de mensagens com utilização da biblioteca MPI para realizar a comunicação entre os processos.
Mais especificamente, foi escolhida a implementação mpich juntamente com mpi.
Java que é uma implementação Java orientada a objetos para o padrão MPI.
O modelo de algoritmo paralelo escolhido foi o mestre/ escravo, visto que em todas as arquiteturas desenvolvidas há sempre um módulo mestre e escravos, no caso as ferramentas FOP rodando em paralelo.
Os experimentos foram realizados em processadores rodando Linux, visto que era a configuração de hardware disponível para testes.
Entretanto, é importante mencionar que mpi.
Java também é compatível com o sistema operacional Windows, assegurando a portabilidade.
Plataformas de Hardware Os resultados apresentados neste trabalho foram obtidos em dois diferentes agregados:
Amaz^ onia e Ombrófila.
Ambos instalados no CPAD (Centro de Pesquisa de Alto Desempenho) sob coordenação do professor César De Rose, que disponibiliza a infra-estrutura para realização de pesquisas em projetos cadastrados na área de Alto Desempenho.
Amaz^ onia Amaz^ onia (Figura 4.4) é um agregado heterogêneo com 31 nós com as seguintes configurações:·
8 Hp Compaq dc5000 MT com processadores Pentium IV de 2.8 GHz com 1 GB de memória· 8 Hp NetServers E800 cada um com 2 processadores Intel Pentium III 1GHz e 256 MB de memória RAM· 8 Hp NetServers E60 cada um com 2 processadores Intel Pentium III 550MHz e 256 MB de memória RAM· 2 Hp workstation zx2000 cada um com 1 processador Intel Itanium2 900 MHz e 1 GB de memória RAM· 5 Hp Integrity rx2600 cada um com 2 processadores Intel Itanium2 1.5 GHz com 2 GB de memória RAM Utiliza uma rede de alto desempenho Myrinet para comunicação das aplicações e uma rede Fast-Ethernet.&amp;&amp;&amp;
Para os testes realizados neste agregado, foram utilizadas 8 máquinas com duplo processador Pentium IV 1Ghz com 1 GB de memória RAM conectadas por uma rede FastEthernet de 100 MB.
Ombrófila O agregado Ombrófila (Figura 4.5) é composto de 16 máquinas Hp e-pc com processador Pentium III de 1 GHz, 256 MB de memória e 20 GB de disco.
Utiliza uma rede Fast-Ethernet para comunicação das aplicações.
Para os testes realizados neste agregado, foram utilizadas 8 máquinas conectadas por uma rede 100 MB FastEthernet.
Casos de Estudo Arquivos PPML podem conter ou referenciar uma grande quantidade de diferentes objetos que vão de vários tipos de imagens a documentos PDF e PostScript, e linguagens baseadas em XML como SVG e XSL-FO.
Contudo, neste trabalho o foco principal não é destacar o potencial da linguagem PPML, mas sim a capacidade da ferramenta FOP em sua versão paralela de renderizar uma grande quantidade de XSL-FOs.
Logo, para a realização dos testes os mesmos documentos foram replicados n vezes num único job num arquivo PPML, ou seja, os mesmos XSL-FOs com o mesmo conteúdo são enviados para o FOP.
O primeiro arquivo PPML de entrada, chamando Mini, contem um job com mil documentos a serem renderizados.
Cada documento é composto por duas páginas como mostra a Figura 4.6 distribuídas da seguinte forma:·
Página 1: 1 copy-hole com XSL-FO composto por 4 blocos de texto e aproximadamente 107 palavras.·
Página 2: 3 copy-- holes com XSL-FO, respectivamente composto por 6 blocos de texto e aproximadamente 130 palavras, 2 blocos de texto e aproximadamente 43 palavras e 1 bloco de texto com 36 palavras.
O segundo teste (CAP) tem dois mil documentos.
O documento tem duas páginas, cada uma com as seguintes características:·
Página 1: 3 copy-- holes com XSL-FO, todos com 1 bloco de texto, respectivamente com 4 palavras, 6 palavras e 7 palavras.·
Página 2: 3 copy-- holes com XSL-FO, respectivamente com 4 blocos de texto e 56 palavras, 1 bloco de texto e 6 palavras e 1 bloco de texto com 2 palavras.
O terceiro teste é denominado Appl.
Tem um job com mil documentos.
Cada documento contem três páginas como segue:·
Página 1: 2 copy-- holes com XSL-FO, ambos compostos somente por 1 bloco de texto cada, respectivamente com 11 palavras e com 13 palavras.
Assim, o número de fragmentos XSL-FO a serem renderizados chega a 3000.
Tal entrada foi gerada usando o modelo mostrado na Figura 4.8.
O último teste é idêntico ao terceiro mas com um job de dois mil documentos, o que resultará em 6000 XSL-FOs a serem renderizados.
Este último teste também foi gerado por o modelo mostrado na Figura 4.8.
Em este Capítulo são apresentadas as estratégias de paralelização adotadas para a renderização de documentos XSL-FO através do uso da ferramenta FOP.
Para cada estratégia é descrito, resumidamente, como a implementação se desenvolveu seguido dos resultados obtidos em cada arquitetura apresentada.
Estratégia Inicial Tanto na versão seqüencial do FOP como na solução de alto desempenho, o documento de saída gerado após a renderização, é composto por a mesma estrutura do PPML de entrada, porém com os FOs substituídos por sua correspondente versão renderizada, conforme descrito no Capítulo 4, Seção 4.1.
Em a versão seqüencial, a parte do documento PPML que não é renderizável (parte estática) é automaticamente copiada para o PPML de saída até o momento em que um copy-hole com conteúdo XSL-FO é encontrado.
Este é enviado para o FOP que retorna SVG salvo no PPML de saída.
Entretanto, na versão de alto desempenho este processo de envio e espera por a renderização não é possível, já que o extrator de FOs não pára a busca por XSL-FOs assim que o primeiro é encontrado.
Pelo contrário, ao encontrar- lo já o envia para o FOP e segue a busca no documento por mais copy-- holes contendo XSL-FOs.
Para lidar com o recebimento de vários FOs enviados por o extrator, que na arquitetura mostrada na Figura 5.1 aparece como consumidor PPML, foram adicionados ao esquema FOPs rodando em paralelo.
Com vários FOs sendo enviados para o FOP e SVGs retornando para serem realocados no PPML (para que o consumidor PPML soubesse onde realocar- los) fez- se necessário a criação de um identificador único para conteúdo enviado para renderização.
Assim, o arquivo PPML de saída é gerado da seguinte forma:
O consumidor PPML varre o documento em busca de copy-- holes com conteúdo renderizável.
Aquilo que não é renderizável já vai sendo gravado no documento de saída em memória.
Quando um XSL-FO é encontrado, um identificador é gerado e o XSL-FO enviado para o FOP, e no documento de saída abre- se uma lacuna esperando que o SVG com o identificador correspondente retorne para que seja realocado em sua posição.
Como a busca por XSL-FOs` medida que os FOs renderizados v~ prossegue, o arquivo segue sendo gerado.
A ao retornando, entram numa fila para que o consumidor verifique qual o identificador correspondente à primeira lacuna no documento.
Caso seja encontrado, o SVG é imediatamente re-inserido fechando aquela lacuna.
Caso não seja encontrado, a fila de FOs renderizados cresce até que o esperado seja enviado por um dos FOPs.
Quando não há mais FOs na fila, o documento é transposto da memória para a unidade de disco.
PPML de origem removendo os FOs e enviar- los para o broker.
A thread de recebimento salva o conteúdo estático (parte não renderizada) do PPML em memória, e recebe os FOs renderizados enviados por os módulos FOP realocando- os em sua posição de origem.
O broker é responsável componente FOP que requisitou trabalho.
De forma a obter um melhor desempenho, este componente foi dividido em duas threads:
O módulo FOP é o responsável por renderizar- los, e quando este processo é finalizado, o resultado é enviado de volta para a thread de recebimento do consumidor PPML, que também notifica os módulos FOP de que está pronta para receber outro FO.
Um comentário final sobre a implementação do processo de renderização XSL-FO está relacionado ao uso das threads.
Sistemas de programação concorrente usando threads introduzem problemas relacionados ao acesso simultâneo de recursos compartilhados.
Um sistema é denominado thread- safe se este está salvo para chamar múltiplas threads mesmo que em paralelo.
O contrário pode causar comportamentos imprevisíveis e gerar resultados inesperados, corromper estruturas de dados internas, etc..
Em Java, uma implementação chamada thread- safe é alcançada com:
Resultados Alguns experimentos foram executados a fim de que as vantagens e desvantagens da abordagem descrita na Seção anterior fossem apontadas.
Esta Seção apresenta os resultados destes experimentos que utilizaram o documento XSL-FO Mini apresentados na Seção 4.4 como entrada.
Buscando um parâmetro de comparação, a versão seqüencial da ferramenta de renderização foi executada utilizando um processador do agregado Amaz^ onia descrito no Capítulo 4 Seção 4.3, resultando num tempo de execução de 350,05 segundos.
Cada tempo de execução apresentado nesta Seção foi obtido após 5 execuções descartando o maior e o menor valor encontrado.
O primeiro conjunto de experimentos foi executado com a seguinte configuração dos módulos:
Um consumidor PPML, um broker, e de um a quatro módulos FOP.
Em cada configuração, cada módulo foi exclusivamente designado para um processador do agregado.
Os resultados deste experimento são mostrados na Figura 5.2.
Como pode ser observado, o tempo de execução cai de 350,05 segundos para menos de 100 segundos com quatro módulos FOP executando em paralelo em diferentes processadores.
A análise dos resultados revelam as diferenças entre a versão seqüencial e a versão de alto desempenho usando somente três processadores.
Embora o segundo não apresente módulos FOP rodando em paralelo, um melhor tempo de execução é alcançado apesar de o custo de comunicação introduzido por o agregado.
Isto pode ser explicado por a modificação adicionada no procedimento de leitura e escrita dos arquivos de entrada e saída descritos na Seção 5.1.1.
Os benefícios reais da versão de alto desempenho começam a aparecer no experimento com quatro processadores.
Em este caso, existem dois módulos FOP executando em paralelo e o tempo de execução cai quase à metade da configuração anterior.
Uma pequena diferença entre o tempo de execução com três ou quatro módulos FOP é outra informação interessante que podemos extrair do gráfico.
Isso é um forte indício de que o módulo broker começa a ter problemas para escalar quando tem que lidar com mais de três módulos FOP rodando em paralelo.
De modo a validar esta hipótese, mais experimentos foram executados com configurações de 5 à 14 módulos FOP.
A fim de confirmar tal suposição, medimos o tempo que os módulos FOP ficam aguardando por a comunicação.
A Figura 5.4 apresenta os resultados comparando o tempo total de execução para cada configuração com o tempo gasto com a comunicação dos módulos FOP.
Com uma configuração de 6 a 14 módulos FOP, o tempo gasto com comunicação por um módulo FOP representa cerca de 70% do tempo de execução.
Podemos colher outra análise importante do gráfico apresentado na Figura 5.5, o qual mostra a diferença entre o tempo de execução do módulo FOP mais rápido e do mais lento para´ possçada configuração executada.
E ivel notar que à medida que o número de módulos FOP aumenta, a diferença entre o mais rápido e o mais lento cresce até que atinja uma diferença de aproximadamente 15 segundos.
Em esta situação, o módulo broker pode não responder ao grupo de módulos FOP igualmente e por esta razão, alguns módulos FOP gastam mais tempo esperando por comunicação com o broker do que os demais.
Levando- se em consideração as análises feitas até agora, a configuração ideal de módulos FOP por broker para um conjunto de dados de entrada de mesma característica é de 1 broker e 3 módulos FOP.
Tais descobertas estão alinhadas com o objetivo de identificar um conceito de unidade composto por um broker e um certo número de renderizadores.
Esta unidade será para melhorar o desempenho desta abordagem, a melhor solução seria ter uma configuração com múltiplos brokers, em a qual o módulo consumidor PPML coordena um conjunto de módulos broker cada um lidando com seu próprio grupo de módulos FOP.
A Figura 5.6 representa este novo esquema descrito na Seção 5.2 a seguir.
Múltiplos Brokers Com base nos resultados apresentados anteriormente na Seção 5.1.2 e em cima de a análise de que quanto maior o número de módulos FOP o módulo broker pode não responder igualmente devido a o tempo gasto com a comunicação, a estratégia de utilização de múltiplos brokers foi implementada.
Implementação Basicamente, esta estratégia conforme mostrado na Figura 5.6 replica o número de brokers fazendo com que o consumidor PPML tenha mais opções livres ao enviar os FOs.
Portanto, a funcionalidade das threads anteriormente explicada na Seção 5.1.1 é mantida adicionando- se somente a possibilidade do consumidor PPML enviar FOs para diferentes módulos brokers.
O objetivo desta estratégia era provar que mesmo com o aumento do tempo gasto com a comunicação devido a o incremento do número de brokers comunicando- se com módulos FOP e conseqüentemente do número de FOs transitando, o módulo broker, identificado como um possível gargalo, pudesse ser aliviado e como conseqüência melhores resultados alcançados.
Resultados Os resultados apresentados na Tabela 5.2, porém não confirmaram as expectativas.
Como pode- se notar, com diferentes combinações de Brokers (B) e módulos FOP (F), o tempo de execução em segundos foi pior em todos os casos.
Indo mais a fundo na detecção da causa dessa queda no desempenho, mediu- se o tempo que o módulo FOP gastava recebendo e enviando os FOs, e foi possível identificar que o tempo de recebimento caiu, porém o tempo de envio aumentou sensivelmente.
Isto demonstra que com a adição dos múltiplos brokers o gargalo transferiu- se para a fase posterior, que no caso é consumidor PPML o qual recebe os vários FOs renderizados e monta o arquivo PPML de saída.
Como o recebimento dos FOs renderizados é feito através de uma única thread implementada no consumidor PPML, há uma concorrência com o processo de busca e envio de FOs que é gerenciado também por o mesmo módulo.
Logo, com o aumento na velocidade de renderização dos FOs tanto a montagem do arquivo final quanto a busca por novos FOs a serem renderizados que são tarefas que exigem muito do processo acabam concorrendo e conseqüentemente a thread de recebimento nem sempre está pronta para receber os FOs dos módulos FOP.
Portanto, uma possível solução para este problema seria implementar o recebimento dos FOs separadamente em outro processo de modo que não haja concorrência.
A estratégia apresentada a seguir na Seção 5.3 mostra como isto seria arquitetado.
Divisão do Consumidor PPML Diferentemente das soluções anteriores em que o módulo responsável por varrer o documento PPML a procura de FOs era o mesmo responsável por a tarefa de recebimento dos FOs renderizados enviados por os módulos FOP, nesta arquitetura o objetivo foi justamente separar este processo de recebimento colocando- o num processo separado a fim de evitar sobrecarga do módulo consumidor.
Além disso, um buffer de FOs foi adicionado ao módulo broker o qual processamento.
Com essa nova funcionalidade, primeiro o buffer é preenchido com vários FOs variando a quantidade de acordo com o tamanho do buffer e também do FO, e somente após estar cheio é enviado para um módulo FOP que irá processar- los.
Implementação A Figura 5.7 mostra a adição de um novo processo na arquitetura denominado recebedor PPML (receiver), o qual anteriormente fazia parte do módulo consumidor PPML.
O processo de renderização se dá então da seguinte maneira:
O consumidor PPML continua responsável por varrer o arquivo PPML de origem retirando os FOs a serem enviados para os brokers.
Estes são enviados para um buffer de FOs no módulo broker que ao atingir o tamanho especificado os distribui entre os módulos FOP para renderização.
Durante o processo de varredura no PPML, a parte não-renderizável do documento vai sendo armazenada num vetor, e assim que um copy-hole contendo FOs é localizado é enviado para a fila.
Seguindo o processo normalmente, o broker envia os FOs para os módulos FOP que os renderizam, e estes após a renderização os enviam para o receiver.
Em este momento, para que o arquivo de saída seja montado substituindo os FOs por SVGs, o receiver acessa o vetor preenchido por o consumidor PPML a fim de que a parte não renderizada seja copiada para o arquivo de saída e, de acordo com o identificador do FO, este seja corretamente substituído por o código SVG.
Este processo se repete até que não hajam mais FOs a serem renderizados.
Resultados Esta Seção apresenta os resultados destes experimentos que utilizaram os documentos XSLFO apresentados na Seção 4.4 como entrada.
Maiores detalhes sobre estes resultados podem ser encontrados em.
Buscando um parâmetro de comparação, a versão seqüencial da ferramenta de renderização foi executada utilizando um processador do agregado Ombrófila descrito na Seção 4.3, resultando nos tempos apresentados nas figuras 5.8, 5.9 e 5.10.
Cada tempo de execução apresentado nesta Seção foi obtido após 5 execuções descartando o maior e o menor valor encontrado.
Para entender melhor os gráficos e tabelas apresentados, conforme descrito na implementação esta solução apresenta em sua arquitetura a divisão do consumidor PPML o que significa a adição de um novo processo.
Assim, onde aparecem 4 processadores em paralelo temos a seguinte configuração:·
1 consumidor PPML· 1 recebedor PPML· 1 Broker De esta forma, para termos pelo menos 2 módulos FOP trabalhando realmente em paralelo é necessário no mínimo 5 processadores.
O primeiro experimento foi executado utilizando o arquivo de entrada Mini, o qual contém 1000 documentos.
Este é o menor job utilizado nos testes, porém representa uma alta densidade em termos de números de palavras por bloco de texto.
Em este caso, o melhor tempo de execução foi de 79,07 segundos, mas esta configuração apresenta eficiência baixa.
Em a verdade, de 7 à 12 processadores o ganho em termos de tempo de execução não é muito significativo, indicando que o sistema pode não ter vantagens quando há mais de 4 módulos FOP rodando em paralelo.
A Figura 5.8 mostra os resultados para este caso de teste.
Em o segundo experimento, foi utilizado o arquivo de entrada CAP.
Este é mais denso em termos de elementos a serem renderizados.
O tempo seqüencial neste caso foi de 491,51 segundos para renderizar 2000 documentos.
O melhor tempo de execução foi alcançado com 8 processadores, porém novamente o ganho de 7 à 12 processadores não é significativo em termos de tempo de execução.
Os resultados deste experimento são mostrados na Figura 5.9.
Para o último experimento, foi utilizado o mesmo modelo somente trocando o número de documentos contidos no job de entrada Appl com 1000 e 2000 documentos.
Tal procedimento permitiu uma análise de escalabilidade da solução em paralelo quando a quantidade de trabalho é aumentada.
O experimento com 1000 documentos apresentou a melhor execução com 11 processadores.
Por outro lado, para renderizar 2000 documentos, a execução mais rápida foi obtida com 10 processadores.
Os resultados mostram que a solução paralela escalonou bem quando a quantidade de documentos a serem renderizados dobrou.
Os resultados são mostrados na Figura 5.10.
FOP tornando- se um gargalo.
Análise Complementar Em os testes apresentados neste Capítulo, não levam em consideração dois fatores de grande importância nos resultados:
O tempo de entrada e saída e a variação do tamanho do buffer.
Esta Seção mostra uma análise complementar considerando estes dois fatores.
Entrada/ Saída Um fator relevante nos resultados mostrados é o dispositivo de entrada e saída (I/ O -- Input/ Output).
Em todos os testes realizados, o tempo gasto com I/ O está presente nos resultados.
Entretanto, como o dispositivo de I/ O é o mesmo para ambos os casos, seqüencial e paralelo, para que se tenha uma idéia do ganho real obtido na paralelização da ferramenta FOP, é essencial que o tempo de I/ O seja analisado.
Para isso, mais alguns testes foram executados para que fossem coletados os tempos de I/ O em ambas as versões.
Como era esperado, o tempo de I/ O foi muito parecido como mostrado na Tabela 5.3.
Portanto, se removermos o tempo gasto com I/ O nos casos de testes realizados, verificamos que o ganho real com o paralelismo é muito grande conforme mostrado nas a tabelas 5.4, 5.5, e 5.6.
Em todos os casos a eficiência foi maior do que 75% chegando até a atingir 89,45% para renderizar o PPML Appl de 1000 documentos com 7 processadores.
Em a Figura 5.7, que descreve a arquitetura da solução de divisão do consumidor PPML, nota- se que entre o consumidor PPML e o Broker há um buffer de FOs.
Tendo em vista que um único FO é um dado muito pequeno, o buffer foi criado para acumular um número significativo de FOs a serem enviados para os módulos FOP de modo que justificasse o tempo de comunicação gasto neste processo.
Desta forma, o consumidor PPML varre o arquivo PPML retirando os FOs e enviando- os para o buffer até que este atinja um tamanho especificado, sendo então enviado para a renderização.
Em os testes realizados neste trabalho, o tamanho do buffer foi fixado em 64 Kbytes.
Este mesmo tamanho é assumido para o buffer de saída do broker para o recebedor PPML que realoca os SVGs nas posições corretas no PPML.
Portanto, a variação deste buffer pode interferir diretamente nos tempos encontrados tanto para mais quanto para menos.
Um mínimo de testes utilizando- se outros tamanhos de buffer foram realizados.
Contudo, estes testes serviram somente para identificar qual tamanho base em Kbytes seria utilizado em todos os testes.
Como resultado, o tamanho de 64 KB mostrou um desempenho superior, mas nada pode- se afirmar visto que foi um teste isolado, sem variação do tamanho dos documentos de entrada, entre outras possíveis variáveis.
Considerações Finais Com o ganho de aproximadamente 30% após a execução da primeira estratégia que foi implementada simplesmente para validar uma idéia sem nenhuma preocupação com otimização de código e demais técnicas computacionais, já foi possível concluir que o ganho de termos uma versão paralela de renderização de documentos XSL-FO seria válido.
Considerando- se que um cliente de grande porte imprime milhões de documentos para distribuir aos seus clientes e este processo leva por volta de 24 horas, um ganho de 50% na eficiência já reduziria em 12 horas o tempo total de renderização.
Isto é um ganho muito grande tratando- se de mercado.
Alguns resultados ainda estão por ser obtidos.
Novas alternativas ainda estão por serem exploradas como apresentado na Seção 6.1.
Espera- se um ganho ainda maior ao executarmos a solução numa máquina SMP.
Todavia, acreditamos que a solução já esteja validada e os resultados futuros são ainda mais promissores.
Este trabalho rendeu uma publicação numa conferência internacional (SAC -- Symposium on Applied Computing), além de a colaboração e reconhecimento do laboratório da Hp em Bristol que vem demonstrando cada vez mais interesse na utilização dos modelos apresentados neste trabalho num de seus produtos.
Trabalhos Futuros Os resultados apresentados neste trabalho indicam que ainda é possível se alcançar resultados melhores na renderização de documentos XSL-FO usando técnicas computacionais de alto desempenho.
Em a primeira implementação foi usado threads e o paradigma de programação por troca de mensagens para diminuir o tempo de execução de 350,05 para 93,30 segundos para uma tarefa contendo mil documentos.
Embora o ganho de desempenho possa ser considerado satisfatório, a principal contribuição deste trabalho foi indicar a melhor configuração entre as estudadas.
A primeira estratégia apresentada com um único broker traz à tona o problema de saturação do módulo broker, que lida com o recebimento de FOs renderizados ao mesmo tempo que verifica módulos FOP ociosos os quais requisitam novos FOs a serem processados.
Baseado em tal fato, uma segunda estratégia foi implementada contendo múltiplos módulos brokers que não apresentou, num primeiro momento, os resultados esperados.
Porém, com a adição de um buffer no broker permitindo o envio não somente de um único FO para ser renderizado, mas vários ao mesmo tempo, foi obtido mais um ganho de desempenho conforme apresentado nos resultados no Capítulo 5, Seção 5.2.2.
Entretanto, sabe- se que em ambas alternativas o arquivo PPML de saída é gerado em memória até que seja inteiramente finalizado quando é descarregado para o ambiente físico.
Além de a limitação de tamanho que pode ser encontrada em testes futuros, já que, por exemplo, um PPML com dois mil documentos pode em casos somente com FOs simples gerar um arquivo de saída em torno de 23 MB, existe o problema da ordenação dos FOs que deve ser mantida conforme no PPML original.
Considerando todos os casos nesta linha potencial de pesquisa, como trabalhos futuros temos alguns pontos interessantes que podemos destacar.
Para solucionar o problema mencionado acima de a geração do arquivo de saída, o uso de Dom (Document Object Model) pode ser melhor investigado a fim de que o documento seja montado dinamicamente à medida em que os FOs renderizados são enviados dos módulos FOP para o consumidor PPML.
Fora isso, nessa primeira versão implementada tanto os brokers quanto os módulos FOP foram implementados utilizando- se de primitivas MPI síncronas.
Com isso, o recebedor PPML caso não esteja pronto para receber um FO renderizado faz com que o módulo FOP fique trancado no envio até que o mesmo esteja pronto para o recebimento.
Em este caso, primitivas assíncronas podem utilizadas de mode que os módulos FOP não fiquem trancados caso tal situação ocorra.
Balanceamento de carga é uma outra possibilidade a ser pesquisada.
Em os exemplos de arquivos PPML utilizados neste trabalho optou- se por utilizar FOs de mesmo tamanho, já que o objetivo era obter um volume significativo de documentos e não complexidade.
Entretanto, é bastante comum termos diferentes tipos de FOs com diferentes complexidades em documentos PPML os quais conseqüentemente exigem um tempo maior ou menor de renderização.
Tal fato possibilita que em implementações futuras seja possível dimensionar o tamanho de um FO através de seu tipo de modo que seja possível enviar os maiores FOs para os processadores de maior capacidade balanceando, assim, o processamento.
Somando- se ainda a essas alternativas, o dimensionamento correto do buffer surge como mais uma estratégia a ser explorada.
A solução com múltiplos brokers apresentada na Seção 5.2 considera um buffer cujo tamanho foi fixado em 64 KB.
Contudo, este valor não foi definido de forma estatística, pois no momento o que se buscava era a validade da solução e se haveria ganho de desempenho em relação a as demais estratégias.
Logo, testes com buffers de maior tamanho devem ser executados para que se possa ter uma relação entre ganho de desempenho e tamanho do buffer e, por conseguinte, eleger a melhor opção baseada em resultados.
Experimentos em plataformas multi-processadas (SMP) para as quais a implementação teria que sofrer algumas adaptações, porém a estratégia é idêntica.
O módulo FOP tratado não como uma caixa-preta é uma idéia a longo prazo, porém não descartada.
Após todos os experimentos realizados nos trabalhos aqui mencionados, dependendo da resposta obtida num ambiente real de impressão talvez não seja necessário tal modificação.
Entretanto, uma versão preparada para uso de threads (thread safe) do FOP já está pronta para ser utilizada.
FOP em sua versão liberada atualmente usa variáveis estáticas para configuração de dados e leitura de imagens.
Entretanto, uma versão não disponibilizada já contorna esses problemas e será a base para o desenvolvimento de uma versão paralela futuramente.
