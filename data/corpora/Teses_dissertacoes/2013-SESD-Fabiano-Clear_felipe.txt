Sistemas intrachip multiprocessados (MPSoCs) podem ser encontrados em praticamente todos os ramos do mercado e o projeto desses sistemas normalmente apresenta diversas restrições, como por exemplo área do chip utilizada, o que o dificulta.
MPSoCs do estado da arte utilizam redes intrachip como meio de comunicação principal, e a tendência é que sistemas baseados em redes intrachip continuem a ser utilizados por um longo tempo, graças a uma maior flexibilidade em seu projeto e também uma alta capacidade de comunicação.
Porém, tais sistemas ainda apresentam certas restrições em seu uso, como por exemplo a localização das tarefas que o compõem.
Técnicas de mapeamento e particionamento de tarefas de uma aplicação buscam solucionar tais problemas, ou ao menos diminuir- los a um ponto não crítico, mas nem sempre são bem sucedidos.
Em este contexto, arquiteturas do tipo cluster surgem como uma alternativa viável para MPSoCs, normalmente apresentando uma arquitetura híbrida em sua constituição, utilizando mais de um meio de comunicação, podendo assim agrupar elementos por questões de &quot;afinidade «e ainda assim utilizando meios de comunicação com grande paralelismo, como redes intrachip.
De esta maneira, este trabalho introduz o HC-MPSoC, uma arquitetura clusterizada para sistemas intrachip, que utiliza redes intrachip e barramentos de uma maneira conjunta, formando grupos de elementos distribuídos de forma independente por todo sistema.
É apresentando ainda, o HellfireOS, sistema operacional de tempo real adaptado para executar sobre a arquitetura, com drivers disponibilizados para uso.
Todos os módulos do HC-MPSoC, assim como do HellfireOS, e os resultados obtidos utilizando a arquitetura, são apresentados no decorrer de o texto.
Palavras Chave: Sistemas embarcados, Barramento, NoC, Cluster, RTOS, Comunicação Embarcada.
Atualmente, é possível encontrar Sistemas Embarcados (SE) em diversos produtos disponíveis no mercado, como por exemplo, em eletrônicos, na indústria robótica e aviônica e em equipamentos médicos.
Uma das principais características destes sistemas é o fato de que, normalmente, são projetados para uma aplicação específica, além de apresentarem alguns requisitos de projeto, como memórias de dados e código pequenas e consumo de energia limitado.
Muitos desses sistemas apresentam, além de as restrições citadas anteriormente, restrições temporais, onde uma única requisição não atendida no tempo devido coloca em risco o funcionamento do sistema como um todo.
Tais sistemas são conhecidos como Sistemas de Tempo Real (RTS) e, a fim de garantir seus funcionamentos, é muito comum a utilização de um Sistema Operacional (Os) que possa atender os requisitos de tempo real, sendo este conhecido como Sistema Operacional de Tempo Real (RTOS).
Para tornar este gerenciamento de tempo real possível, um RTOS utiliza uma unidade de escalonamento de tempo real que, além de gerenciar a ordem de execução das tarefas presentes, escalona estas de forma a tentar cumprir todas restrições temporais.
A fim de otimizar, de entre outras coisas, seu custo e desempenho computacional e energético, é desejável que SEs possam ser implementados numa única pastilha de silício (chip), sendo este sistema conhecido como System-on-Chip (SoC).
Um SoC normalmente é composto de diversos componentes, como:
CPUs, memórias, barramentos e DSPs no mesmo chip.
A evolução tecnológica permitiu, ao longo de os anos, que mais de uma unidade de processamento fosse utilizada num mesmo chip e o SoC resultante passou a ser denominado Multiprocessor System-on-Chip (MPSoC).
Uma das grandes vantagens de se utilizar MPSoCs é a possibilidade da divisão da carga de processamento entre os processadores, o que pode acarretar num ganho de desempenho energético e também computacional.
A Figura 1.1 mostra um MPSoC formado por quatro unidades de processamento, interligadas por um meio de comunicação qualquer, uma memória compartilhada por todas unidades e acessada via o meio de comunicação e, ainda, um meio de comunicação com o mundo externo (Input/ Output -- I/ O).
A comunicação entre os componentes internos de um SoC ou de um MPSoC é dada via um meio de comunicação, de entre os quais podem- se destacar:
Barramento, unidade básica de comunicação em que os pacotes trocados entre os componentes ocupam o meio de comunicação de forma exclusiva, e;
Redes intra-chip (NoC) em que os conceitos de redes de computadores, com roteadores que orientam o tráfego de informação, são aplicados dentro de um chip.
Mais detalhes a respeito de o funcionamento desses meios de comunicação serão apresentados na Seção 1.1.
Dentro de o contexto apresentado, dois pontos importantes podem ser ressaltados, assim como um questionamento a respeito de o futuro de sistemas embarcados:
A crescente relevância de SEs e sua utilização cada vez maior nos sistemas eletrônicos presentes no cotidiano das pessoas, onde tarefas, que antes eram exclusivas a sistemas de propósito geral, como, por exemplo, processamento de imagens, passaram a ser executadas dentro de um chip;
O aumento da complexidade das aplicações cresceu conjuntamente com a evolução de tecnologias, porém, ferramentas de suporte ao desenvolvimento de tais aplicações não cresceram no mesmo ritmo, e;
Qual será o próximo passo da evolução dos Sistemas Embarcados?
Quanto a este questionamento pode- se dizer que, naturalmente a tendência é incorporar novas funcionalidades ao sistema, tanto em nível de hardware quanto em nível de software.
Por exemplo, se pode imaginar que num futuro breve dispositivos embarcados sejam capazes de produzir imagens holográficas em tempo real.
Refletindo sobre esta possibilidade, a viabilização deste tipo de aplicação passa por a proposição de novas arquiteturas de hardware e software.
Em o hardware é necessário que a arquitetura permita o aumento de desempenho de execução da aplicação.
Isto não somente por o aumento do número de processadores ou por a utilização de um processador com poder de processamento maior, mas por estruturas que permitam e dêem suporte a isto.
Também, os meios de comunicação devem ser repensados e re-projetados para atender a crescente demanda de desempenho das aplicações.
De o ponto de vista do software novas propostas, como a virtualização, devem ser estudadas, assim como novas políticas de escalonamento de tarefas e técnicas de mapeamento e particionamento das mesmas.
Ainda, se deve considerar a crescente demanda do consumo de energia destes sistemas, fato que nunca pode ser ignorado em sistemas embarcados.
Logo, existem diferentes fronteiras a serem transpostas para a evolução dos sistemas embarcados, isto é, para se chegar a nova geração de sistemas embarcados.
Em este sentido, este trabalho busca transpor a fronteira da arquitetura de hardware, propondo uma nova arquitetura para sistemas embarcados que permita aumentar o desempenho de execução de aplicações complexas, ao mesmo tempo em que seja simples de programar- la.
Meios de Comunicação Em sistemas embarcados multiprocessados, duas ou mais CPUs com um consumo de energia reduzido são utilizadas, diminuindo assim suas frequências de operação e, consequentemente sua capacidade computacional.
Porém, graças a o uso de paralelismo, esses sistemas ainda são capazes de realizar tarefas complexas, pois a carga de processamento total pode ser dividida entre todas as unidades do sistema e executar em paralelo, compensando a menor capacidade de cada Um cuidado que deve ser tomado ao se utilizar MPSoCs está no fato de que, não apenas as capacidades computacional e de armazenamento do sistema influem no seu desempenho, mas também a capacidade de comunicação.
Por exemplo, num sistema altamente comunicante, se o meio de comunicação escolhido não suportar diversas trocas de mensagens num tempo aceitável, o desempenho será prejudicado.
Uma tendência de uso, até poucos anos atrás, o uso de um ou mais barramentos como meio de comunicação principal, está mudando, pois NoCs já fazem parte de muitos sistemas e seu uso só tende a aumentar com o passar do tempo.
Barramento Em sistemas que utilizem barramentos, N nodos1 são interligados por uma ou mais vias que efetuam as trocas de mensagens de maneira individual, ou seja, quando um nodo está utilizando a via, todos os outros devem aguardar por o término deste uso.
O principal motivo do barramento ser largamente usado ainda hoje está na sua simplicidade e eficiência.
Uma grande limitação dos barramentos está em sua escalabilidade, ou seja, seu uso em sistemas com muitos nodos.
Para situações em que um barramento simples (exemplificado na Figura podem ser usadas, como por exemplo o barramento hierárquico.
A Figura 1.3 apresenta um sistema interligado por barramentos hierárquicos.
É possível observar diferentes níveis de barramentos.
Esta técnica aumenta a escalabilidade de sistemas baseados em barramentos, porém aumenta também a complexidade de implementação do sistema.
Network-on-Chip Conforme descrito anteriormente, barramentos possuem limitações de escalabilidade, o que pode afetar o desempenho do sistema como um todo.
A fim de solucionar este problema, algumas soluções foram pesquisadas, como por exemplo, as Redes Intra-chip.
Em esse modelo, a abordagem para comunicação muda em relação a aquela adotada por os barramentos.
Diferentemente dos barramentos, em que normalmente todos os elementos são interligados por um meio simples e direto de comunicação, em NoCs roteadores gerenciam todo tráfego e direcionam os pacotes da maneira mais adequada, realizando a troca de informação de maneira paralela e independente.
De entre as topologias de NoC existentes, é possível ressaltar três:
Malha, torus e octagonal, descritas a seguir.
O modelo mais usado é o de rede tipo malha 2D regular (do inglês, mesh) onde todas as conexões possuem o mesmo comprimento, o que facilita seu projeto.
Em esse modelo todos roteadores, excluindo os nodos externos que possuem apenas duas ou três conexões, estão interligados a quatro roteadores vizinhos, agilizando a troca de pacotes.
De entre diferentes modelos encontrados para uso, o modelo de NoC escolhido foi a NoC Hermes--Handshake, sendo que esta usa uma topologia do tipo malha e é constituída por os seguintes módulos:
Roteadores; Buffers, e;
Controladores do fluxo de informações dos roteadores (switchcontrol).
A Figura 1.5 apresenta a organização interna de um roteador da NoC Hermes.
Em a figura é possível observar a presença de 5 portas, sendo 4 de envio e recebimento de pacotes por a rede e uma local.
Em cada uma das portas existe um buffer de tamanho n parametrizável, responsável por armazenar temporariamente as informações que chegam e saem do roteador.
Os pacotes trocados por a rede são denominados flits, podendo variar seu tamanho de acordo com as necessidades da aplicação.
O tamanho usado por a distribuição utilizada neste trabalho é de 16 bits.
O controle do tráfego interno de informações do roteador é feito por um componente do roteador chamado switchcontrol, sendo esse composto por duas unidades:
Controle, encarregado de realizar o chaveamento para troca de informações entre as portas, e;
Árbitro, módulo gerenciador de pacotes.
Cada uma das filas ao receberem um novo pacote, requisitam chaveamento ao árbitro.
O árbitro seleciona a de maior prioridade e solicita chaveamento à lógica de chaveamento (controle).
Sendo possível, a conexão é estabelecida e o árbitro é informado.
Por sua vez, o árbitro informa a fila que começa a enviar os pacotes armazenados.
O escalonamento interno entre as filas é realizado utilizando- se o algoritmo Priority Round Robin, onde o escalonador funciona de maneira circular, porém utilizando diferentes prioridades.
Já o algoritmo de roteamento de pacotes da NoC, que determina o trajeto que os pacotes irão fazer para ir do ponto A para o ponto B, é o XY.
Cluster Um cluster pode ser definido como um sistema onde dois ou mais sistemas independentes trabalham de maneira cooperativa, a fim de atingir um objetivo comum.
Em outras palavras, cada um dos sistemas independentes recebe uma parcela do trabalho, dividindo assim a carga total do sistema em parcelas menores.
Clusters são usados na indústria há muitos anos, com o intuito de processar grandes quantidades de informação num menor espaço de tempo, sendo que um dos primeiros modelos surgiu na década de 60.
Inicialmente eram projetados para operar sobre mainframes 2, sendo necessário o uso de um software que fizesse a divisão das tarefas entre os diferentes pontos.
Por volta de a década de 80 com o aumento da tecnologia no desenvolvimento de processadores, assim como a evolução das redes de computadores, novos modelos de clusters começaram a surgir.
Máquinas de uso geral puderam, então, ser usadas numa rede para dividir a carga de processamento.
De entre os diversos modelos de clusters disponíveis, é possível destacar três:
Computador dedicado ao processamento de um volume grande de informações equilibrada.
Para isso, requer um monitoramento constante na sua comunicação e em seus mecanismos de redundância, pois se ocorrer alguma falha, haverá uma interrupção no seu funcionamento;
Uma forte tendência nos últimos anos é a utilização de modelos de clusters em sistemas embarcados, ampliando assim suas capacidades de comunicação e processamento.
Sendo assim, este trabalho descreve a implementação de uma arquitetura para sistemas embarcados, utilizando os conceitos apresentados de barramentos, NoCs e clusters.
Motivação A partir de o surgimento de sistemas embarcados multiprocessados tarefas que exigiam um grande poder computacional puderam ser executadas a partir de um pequeno chip.
Essa capacidade proporcionou o surgimento de novas tecnologias que agrupam numa única plataforma diversas funções.
Ao mesmo tempo, muitas tarefas realizadas por SE são críticas, como por exemplo o controle do sistema de pouso de um avião, ou até mesmo os controles de segurança de uma usina nuclear.
De este modo, é de grande importância que os SEs apresentem não apenas grande poder computacional e de comunicação, mas também apresentem estabilidade e segurança na sua execução.
Arquiteturas do tipo cluster apresentam características que contemplam todos os pontos citados.
Por exemplo, num sistema crítico em que a integralidade das informações é crucial, utilizando- se uma arquitetura cluster é possível replicar essas informações em diferentes pontos, garantindo assim sua segurança.
Um outro possível cenário de uso de clusters é a divisão das aplicações conforme suas características, isolando as tarefas que compõem o sistema entre diferentes domínios.
Por exemplo, num sistema multimídia uma possível divisão poderia ser feita conforme a Figura 1.6, aonde é possível observar quatro domínios, cada qual com uma especialização:
Vídeo, áudio, entrada/ saída e memória.
Sendo assim, este trabalho apresenta uma arquitetura utilizando clusters para sistemas embarcados, introduzindo os conceitos de sua implementação e, também, do suporte de alto nível, via sistema operacional, utilizando o HellfireOS, arquitetura esta denominada HC-MPSoC (Hellfire Cluster--based MPSoC).
Objetivos O objetivo principal deste trabalho é propor uma nova arquitetura para Sistemas Embarcados, explorando as características de barramentos e NoCs.
Esta arquitetura será composta por ambos meios de comunicação e por unidades de processamento distribuídas no sistema.
A plataforma proposta foi descrita em linguagem de descrição de hardware (VHDL), executando em cada instância de um processador, uma imagem3 do sistema operacional HellfireOS.
A validação dos resultados foi obtida através de simulações em nível RTL, assim como em processos de síntese para tecnologias FPGA e de 65 nm da St.
Organização do Texto Este trabalho está organizado da seguinte maneira:
O próximo capítulo aborda uma revisão do estado da arte de sistemas embarcados utilizando clusters, seguido por o Capítulo 3, onde o Sistema Hellfire é apresentado.
Já no Capítulo 4 o trabalho desenvolvido é apresentado, com o detalhamento de todos os módulos que compõem o HC-MPSoC, sendo que os resultados obtidos são apresentados no Capítulo 5.
Por último, o Capítulo 6 contém uma breve conclusão deste trabalho, assim como uma discussão sobre trabalhos futuros a serem desenvolvidos sobre a plataforma.
Em este capítulo serão apresentados alguns trabalhos relacionados a arquiteturas de clusters embarcados.
Será feita uma análise de cada trabalho individualmente e, então uma comparação das metodologias adotadas.
Apesar de muitos trabalhos, de outras áreas de pesquisa inclusive, apresentarem algumas características que poderiam entrar nesta comparação, apenas os casos de sistemas intrachip foram levados em consideração.
Performance Evaluation Of Cluster--Based Homogeneous Multiprocessor Systemon-Chip Using FPGA Device O trabalho apresenta um MPSoC formado por 17 processadores NiosII agrupados em quatro grupos de quatro processadores cada, e mais um processador central que controla todo o sistema, dividindo as tarefas entre os grupos de processadores.
Cada grupo esta interligado via uma memória compartilhada e cada processador possui uma memória local para execução de suas tarefas.
Para realizar a comunicação entre os grupos de processadores e o processador central uma NoC irregular foi utilizada.
O acesso a periféricos, assim como a entrada e saída de dados é todo realizado no processador mestre, centralizando o controle de operações do MPSoC num único ponto.
A Figura 2.1 apresenta o modelo de cluster utilizado no trabalho referenciado.
Algumas considerações podem ser feitas a respeito de o modelo adotado por os autores, como por exemplo a possibilidade de diferentes configurações da arquitetura do modelo.
Por o fato de uma NoC irregular ter sido usada, com roteadores específicos, cada mudança desejada no layout da arquitetura implica diretamente em mudanças nos roteadores, que devem ser adaptados à nova configuração.
Um outro ponto relevante é o fato de que uma unidade central foi utilizada, controlando o funcionamento de todo o sistema, assim como a entrada e saída de dados.
Essa prática pode limitar a capacidade do sistema, funcionando como um gargalo, pois o desempenho da unidade central pode não ser satisfatório, se comparado com o os escravos.
Para verificação do sistema, os autores apresentam dois casos de teste, Multiplicação de Matrizes e Transformada Rápida de Fourier, porém não se tem maiores detalhes de sua implementação, passando a idéia de que nenhum suporte de alto nível foi utilizado.
As principais diferenças entre o trabalho apresentado em e o trabalho aqui proposto está no fato de que este trabalho apresenta uma arquitetura mais facilmente configurável, pois utiliza uma NoC parametrizável.
Outro ponto importante é o controle centralizado apresentado por, diferente do completo paralelismo empregado por o trabalho proposto.
Uma última consideração reside no fato de que nenhum tipo de suporte de alto-nível foi apresentado por, ao contrário de o que este trabalho propõem.
Em, os autores introduzem um modelo de cluster para sistemas embarcados, formado por processadores ARM agrupados em clusters de tamanho variável, que se comunicam por um barramento do tipo AMBA-AHB.
A comunicação entre clusters é realizada por uma NoC que possui um cluster em cada nodo.
A Figura 2.2 apresenta um modelo do MPSoC utilizado numa prototipação, com meios de comunicação, processadores e IPs.
É possível notar a presença de quatro módulos diferentes:
Ethernet In/Out responsável por a entrada e saída de dados do MPSoC, PCC responsável por a comunicação entre clusters, cluster formado por três processadores e DDR II Interface que realiza a interface para uma memória global do sistema.
A parte interna do cluster é composta por três processadores, uma unidade de controle de memória (DMA) e uma unidade de comunicação com a NoC.
Para validar o sistema, um algoritmo de tempo real de processamento de vídeo foi implementado e prototipado em FPGA com o propósito de provar que o sistema garante desempenho de processamento de tempo real.
O sistema introduzido em apresenta uma estrutura muito promissora para uso de clusters embarcados, porém, ao contrário de o trabalho aqui sugerido, nenhum tipo de suporte altonível é apresentado, o que aumenta a complexidade de seu projeto.
Um modelo de cluster utilizando uma NoC como meio de comunicação entre nodos, e barramentos simples como meio de comunicação interna para cada nodo foi apresentada em, nomeado P2012.
Em este modelo, os nodos são compostos por módulos IP, podendo estes serem módulos de hardware ou software, além de dois módulos para comunicação do nodo com o roteador da NoC.
Além de a arquitetura de clusters introduzida, um algoritmo de decisão entre hardware e software foi apresentado, para otimização do sistema.
A Figura 2.3 apresenta o modelo de cluster introduzido em, ilustrando a divisão interna entre módulos de software e hardware.
O trabalho apresenta um modelo facilmente configurável, escalável para grandes quantidades de núcleos IP, apresentando suporte para decisão da divisão das aplicações entre módulos hardware e software, porém, ao contrário de o trabalho sugerido aqui, a plataforma P2012 utiliza núcleos IP proprietários, o que pode dificultar o seu uso e integração com projetos que não utilizem tais IPs.
A Clustered NoC-Group Communication Em um sistema de clusters utilizando apenas uma NoC com seus roteadores alterados é apresentado.
Ao contrário de os trabalhos anteriores citados, o trabalho apresentado em não utiliza barramentos para comunicar os núcleos internos de seus clusters, que ficam interligados diretamente no roteador da NoC.
O roteador da NoC utilizada foi alterado, sendo adicionadas mais três portas locais.
A Figura 2.4 apresenta a visão do novo roteador utilizado, onde é possível verificar a presença de quatro portas locais, além de as portas norte, sul, leste e oeste.
Esta solução foi adotada visando diminuir a complexidade do desenvolvimento do MPSoC, pois além de a estrutura da NoC utilizada, nenhum outro meio de comunicação precisa ser usado.
Todavia, para permitir o uso de quatro processadores num mesmo roteador, a estrutura do mesmo teve de ser alterada, assim como seu algoritmo de escalonamento interno, o que implica num maior overhead de controle, podendo resultar num menor desempenho.
Uma importante limitação da arquitetura apresentada em está na escalabilidade do modelo.
O número de IPs em cada cluster está limitado a quatro unidades, sempre, o que diminui o espaço explorável de projeto.
Outra questão é o fato de que nenhum suporte de alto-nível foi previsto por o modelo, o que aumenta a complexidade do projeto.
Embedded Virtualization O trabalho apresentado em introduz um outro tipo de modelo para utilização de clusters embarcados.
Enquanto todas as outras soluções ilustradas utilizam implementações físicas dos meios de comunicação e computação, o trabalho apresentado por utiliza técnicas de virtualização para ampliar a capacidade de configuração do MPSoC.
Esta solução utiliza processadores MIPS e como meio de comunicação central uma NoC.
A Figura 2.5 ilustra um MPSoC formado por quatro processadores (na imagem, cada processador é representado como PE) e uma NoC tipo malha central.
Em cada nodo, n domínios podem ser instanciados, sendo que cada domínio corresponde a um processador virtual.
Uma importante limitação desta arquitetura reside no fato de que o overhead para o uso de processadores virtuais pode ser muito custoso, assim como a escolha do processador utilizado, pois esta escolha esta limitada aos processadores disponibilizados para uso.
Dynamic SMP Clusters Em é apresentado um modelo de clusters dinâmicos, em que a troca de mensagens internas é realizada por memórias locais.
Os módulos internos de cada cluster são interligados utilizando- se barramentos e a comunicação externa utiliza conexões ponto-a-ponto.
A Figura 2.6 apresenta a visão geral da arquitetura, onde é possível observar a presença de um módulo externo de comunicação, representando as conexões ponto-a-ponto, e três tipos de módulos internos em cada cluster:
Local Network, representando o barramento interno, e os módulos 'P` e'M', equivalentes aos processadores e memórias, respectivamente.
A grande limitação desta arquitetura está no fato da utilização de uma conexão pontoa-ponto.
Ao mesmo tempo em que este tipo de arquitetura provê uma grande capacidade de comunicação, o seu uso está limitado a poucos nodos, graças a uma grande complexidade de implementação.
Um outro ponto que difere o trabalho em do trabalho aqui proposto é o fato que nenhum tipo de suporte de alto nível ao seu uso foi fornecido.
Uma importante diferença da arquitetura apresentada em e do trabalho aqui proposto esta no fato de que o número de processadores internos em cada nodo é fixado em três, além de o fato de nenhum tipo de suporte de alto-nível ter sido apresentado.
CN* correspondem aos nodos contendo os módulos IP.
Pode- se ainda visualizar- se três roteadores centrais, nominados CR1, CR2 e CR3, responsáveis por interligar os roteadores que contém nodos.
Nenhuma colocação foi feita a respeito de quais núcleos IP foram utilizados na arquitetura, ao contrário de o trabalho aqui apresentando, que utiliza núcleos do tipo Plasma.
Uma outra importante consideração está no fato da utilização de uma arquitetura irregular, o que pode acarretar num maior esforço de fabricação.
Comparação de Trabalhos A Tabela 2.1 apresenta uma comparação dos trabalhos apresentados e do trabalho proposto, sendo que seis pontos foram usados como fatores de comparação, conforme segue:
A -- Meio de comunicação interno do cluster:
Corresponde ao meio de comunicação utilizado por os nodos internos em cada cluster;
B -- Meio de Comunicação Central entre clusters:
Meio de comunicação utilizado para realizar a comunicação entre diferentes clusters;
C -- Suporte de Alto--nível:
Compara os trabalhos, indicando a presença de suporte de desenvolvimento por algum sistema operacional, via API;
D -- Controle do Sistema:
Indica se existe um nodo no sistema que realize a divisão de tarefas, assim como a entrada e saída de dados;
E -- Complexidade de Configuração da Arquitetura:
Compara a complexidade para configurar arquiteturas de diferentes tamanhos e parâmetros e, o quão fácil é feita esta configuração, e;
F -- Núcleo de Processamento Utilizado:
Indica o tipo de núcleo IP utilizado.
IP define um núcleo genérico, quando nenhum foi explicitamente definido.
A partir de a tabela, é possível observar uma grande tendência no uso de barramentos em cada cluster, sendo este o meio de comunicação adotado por seis dos oito trabalhos relatados.
Um outro ponto em comum na maioria dos casos, com apenas uma exceção, é a adoção de uma NoC como meio de comunicação central, interligando os clusters do sistema.
A partir de isso conclui- se que o trabalho aqui apresentado segue a tendência atual para o uso de clusters em sistemas intrachip.
Um ponto importante e de grande relevância é o fato de que em apenas um dos casos citados existe algum tipo de suporte ao desenvolvimento de aplicações nas plataformas discutidas, fato este que o trabalho aqui apresentado suprime, pois disponibiliza uma API (Application programming interface) para uso em conjunto com a plataforma.
Apesar de o tempo para o projeto de sistemas embarcados ser cada vez menor, visando não perder o time- to-- market, as restrições que o envolvem estão cada mais significativas.
Visando auxiliar seu desenvolvimento e, também, diminuir o tempo de projeto, diversas plataformas como, por exemplo, e, disponibilizam recursos como ferramentas de simulação e depuração, que agilizam este processo.
Um outro exemplo de ferramenta de auxílio ao desenvolvimento de sistemas embarcados é o Hellfire Framework, que será usado como base para o desenvolvimento deste trabalho.
Atualmente, o Sistema Hellfire é constituído por cinco módulos:
HellfireOS: Sistema operacional embarcado de tempo real, contendo primitivas para gerenciamento do sistema, de comunicação e migração de tarefas, de entre outras, acessadas via uma· Plataforma de Hardware:
Composta por N processadores MIPS-Plasma, interligados por um meio de comunicação, podendo este ser um barramento ou uma NoC;
Ambiente de Simulação:
Descrito em linguagem 'C', composto por um Instruction Set Simulator (ISS) de um processador MIPS-Plasma e de um modelo em alto nível do meio de comunicação, possuindo precisão de ciclo;
Construtor de Arquitetura: Utilizado para especificar a arquitetura destino, assim como configurar todos os parâmetros do HellfireOS, e;
Web--Framework: Integra numa única interface web os módulos HellfireOS, N-MIPS e Construtor de Arquitetura, apresentando um fluxo de projeto introduzido em.
Os módulos do HellfireOS, do ambiente de simulação, do construtor da arquitetura e do WebFramework serão apresentado com mais detalhes nas próximas seções.
HellfireOS O HellfireOS (HFOS) é um RTOS desenvolvido no Grupo de Sistemas Embarcados (GSE) que, além de controlar todos os recursos de hardware disponíveis, provê mecanismos para tratar restrições temporais.
O HFOS foi projetado para permitir a configuração de certos parâmetros do Os, possibilitando assim a customização da plataforma alvo.
Para permitir tal customização, o HFOS foi projetado de maneira modular e independente, aonde cada módulo corresponde a uma funcionalidade específica.
A Figura 3.1 apresenta a organização em camadas do HFOS, onde todas funções dependentes de hardware estão definidas na primeira camada, denominada Hardware Abstraction Layer (HAL).
O uKernel localiza- se acima de essa camada, assim como os drivers de comunicação, migração, gerência de memória, ponto flutuante, exclusão mútua e a biblioteca de funções padrão de o'C'.
O HellfireOS permite a configuração de diversos parâmetros com propósito de diminuir o tamanho da imagem final, possibilitando assim, seu uso em plataformas com limitações de memória.
Em tempo de projeto podem ser definidos o número máximo de tarefas de usuário, o tamanho da pilha de tarefas e do heap, a política de escalonamento que será usada e se certos drivers serão ou não habilitados, como por exemplo, o driver de migração e o de ponto flutuante.
Além disso, é possível ainda definir o tamanho do tick, que corresponde a unidade temporal mínima do kernel.
De uma maneira prática cada tick corresponde a um período de execução do sistema, podendo variar de 0,32 ms até 83.88 ms..
É importante notar que quanto maior o valor do tick, maior será o tempo de execução de cada período e consequentemente menor será a responsividade do Os.
De a mesma maneira, ticks muito pequenos reservam pouco tempo para execução dos aplicativos, passando boa parte do tempo apenas trocando o contexto das tarefas a cada novo período.
Por esses motivos o valor padrão adotado para uso no HellfireOS é o de 10,48 ms..
Para facilitar seu uso, o HFOS disponibiliza uma API, sendo a mesma dividida em cinco categorias:
Após compilar os fontes do kernel e da aplicação, uma única imagem é gerada.
Esta imagem pode ser simulada num ISS ou prototipada em hardware.
Em sistemas multiprocessados cada processador recebe uma imagem do Os, podendo ser, ou não, a mesma imagem, para todos processadores, de acordo com a configuração realizada por o projetista.
MIPS é uma ferramenta de simulação desenvolvida para facilitar o teste e depuração de sistemas embarcados, fornecendo diversos relatórios do funcionamento do sistema.
O N-MIPS é um Instrunction Set Simulator (ISS), que executa códigos objeto nativos, de acordo com a implementação de um processador Plasma.
Além disso, o mesmo código usado para simulação pode ser usado no hardware real.
Em conjunto com o simulador de instruções existe uma ferramenta que efetua a análise do consumo de energia do sistema, assim como a contagem de ciclos.
Uma emulação temporal e funcional da UART foi implementada de modo a fornecer a simulação da saída de dados dos processadores.
Posteriormente, um modelo de barramento compartilhado foi incorporado, seguido por um modelo em alto-nível de uma NoC, permitindo a simulação de sistemas multiprocessados.
Adicionalmente, diversos relatórios de desempenho do sistema são gerados, aumentado a gama de informações fornecidas ao desenvolvedor.
Os seguintes relatórios são gerados automaticamente:
De posse destas informações o projetista pode avaliar as características do sistema implementado e decidir por validar o modelo atual, ou então voltar à etapa de projeto e refinar o mesmo.
Construtor de Arquitetura O terceiro módulo, chamado de Construtor de Arquitetura, é utilizado para especificar a arquitetura destino, assim como configurar todos os parâmetros do HellfireOS.
Toda configuração do sistema pode ser feita via uma intuitiva interface web, projetada para facilitar o desenvolvimento do projeto.
O desenvolvedor pode criar e testar um MPSoC completo apenas utilizando esta ferramenta.
A o acessar a interface web do HFFW, o desenvolvedor deve criar um projeto e, então fazer a inclusão da aplicação que executará no sistema.
Isto pode ser feito de três maneiras:
Fazendo upload de um arquivo já contendo a descrição da aplicação;
Ii) criando um arquivo novo na interface web e descrevendo a aplicação, ou;
Iii) carregando alguns dos exemplos disponibilizados.
O próximo passo do fluxo é a configuração da plataforma a ser usada.
Para realizar esta etapa o desenvolvedor utilizará o Construtor de Arquitetura.
Em a Figura 3.2, é possível notar que o projetista pode escolher entre cinco tipo de processadores MIPS (identificados por uma letra A) e dois tipos de meio de comunicação, barramento ou NoC (identificados por uma letra B).
Para configurar todo sistema, o projetista deve apenas arrastar e soltar os módulos desejados para a área de trabalho (identificada, na imagem, por uma letra C).
Esta figura ilustra, ainda, um MPSoC formado por nove processadores interconectados por uma NoC 3x3.
O projetista pode então configurar cada processador individualmente, ou então, todos de uma só vez.
Todos parâmetros podem ser definidos apenas selecionando botões na interface gráfica, e todo sistema é montado automaticamente em background.
É possível configurar os seguintes parâmetros do HellfireOS, conforme apresentado na Figura 3.3: User Max Tasks (A):
Define o número máximo de tarefas que o desenvolvedor pode adicionar ao sistema;
System Heap Size (B):
Tamanho da memória dinâmica que será disponibilizado para uso;
Tick Size (C):
Define o tamanho do tick do sistema, em ms;
NoC Buffer Size (D):
Define o tamanho dos buffers dos roteadores da NoC que serão utilizados por o simulador;
Ni Buffer Size (E):
Determina o tamanho dos buffers intermediários, localizados entre o processador e o meio de comunicação, e;
Após a configuração do sistema, o sistema é compilado e, não havendo nenhum erro de compilação pode- se passar para o próximo passo do projeto.
Por último, o sistema é simulado.
A Figura 3.4 apresenta o resultado da simulação de um sistema no Hellfire Framework, onde pode- se notar a presença de diversas abas.
Cada uma dessas abas corresponde a um relatório específico, gerado por a ferramenta N-MIPS, conforme segue:
Application Outputs: Apresenta a saída padrão dos processadores individualmente;
Reports: Ilustra as instruções assembly utilizadas por a aplicação, assim como a porcentagem de uso das mesmas e também o consumo de energia do processador;
Log: Apresenta um log, ciclo a ciclo, do funcionamento do HFOS;
Graphics: Disponibiliza, graficamente, alguns relatórios do sistema como, por exemplo, consumo de energia e perda de deadlines;
Briefing: Resumo geral do funcionamento do sistema, agregando num único relatório algumas informações importantes, como quantidade e momento das comunicações e quais tarefas estão perdendo deadlines e quando, por exemplo, e;
Caso todos os resultados sejam satisfatórios o projetista tem a opção de fazer o download das imagens geradas para cada processador, assim como os relatórios das aplicações simuladas.
Se o resultado não for o esperado é possível voltar a algum ponto específico do fluxo, refinar- lo e, então, realizar a simulação novamente.
Em este capítulo são apresentados os detalhes do trabalho desenvolvido visando atingir os objetivos mencionados na Seção 1.4, que teve como base motivadora a necessidade por uma plataforma de alto desempenho e suporte de alto-nível para sistemas embarcados, conforme discutido ao longo de o texto.
Trabalho realizado em duas etapas, conforme ordem apresentada:
Assim como unidades de processamento;
Cada uma destas etapas será detalhada a seguir.
Arquitetura de Hardware A divisão de tarefas entre diferentes processadores para aumento de desempenho do sistema já é uma pratica comum em sistemas embarcados, porém o meio de comunicação pode ser um gargalo do sistema, por não ter uma grande escalabilidade, limitando o número de processadores que podem ser utilizados (barramento), ou por apresentar situações onde o mapeamento de tarefas no MPSoC pode resultar num tempo de troca de mensagens proibitivo (NoC), graças a uma má localização das mesmas no sistema.&amp;&amp;&amp;
A plataforma desenvolvida busca propor uma solução que minimiza ambas limitações utilizando um sistema híbrido, composto por uma NoC e por diversos barramentos.
A Figura 4.1 apresenta uma visão geral da plataforma desenvolvida.
É possível notar a presença de uma NoC centralizada, responsável por a troca de mensagens entre nodos e, em cada nodo, um sub-sistema composto por um barramento simples e N unidades internas conectadas a este barramento.
É importante ressaltar que cada um dos nodos da NoC pode ser composto por um cluster, ou então por módulos IP quaisquer, de acordo com as necessidades do desenvolvedor.
A implementação dos módulos de hardware foi realizada em duas etapas:
Implementação do barramento e de seus módulos, e;
Ii) implementação dos módulos de comunicação entre o barramento e a NoC.
Barramento Um modelo de barramento foi implementado para servir como meio de comunicação entre os elementos que compõem um cluster.
Este barramento é composto por um meio de comunicação compartilhado, controlado por um árbitro que decide qual porta terá acesso ao meio e utiliza um algoritmo rotativo.
A Figura 4.2 apresenta a estrutura básica do barramento utilizado.
Este exemplo é composto por quatro unidades IP conectadas ao barramento via wrappers, identificadas na figura como W. Estes wrappers são responsáveis por a conversão dos protocolos de comunicação entre o módulo IP e o barramento, e também responsáveis por solicitar o acesso ao meio de comunicação ao árbitro.
Assim, o árbitro pode gerenciar os acessos ao barramento, e as unidades de entrada e saída, identificadas na figura por I/ O. Cada um dos módulos apresentados serão discutidos no decorrer de o texto.
A validação do barramento foi realizada através simulações, utilizando a ferramenta ModelSim e em prototipações em FPGA.
Os três sinais de entrada do árbitro são:
Bus_ req, data_ ack e data_ h, destacados e descritos a seguir.
Bus_ req:
Composto por y sinais, sendo y igual ao numero de núcleos conectados ao barramento, ou seja, ao número de portas de entrada e saída interligadas ao barramento.
Por meio deste sinal o árbitro recebe a solicitação de cada porta para acesso ao barramento;
Data_ h:
Composto por w vetores de dados de tamanho k, sendo w igual ao numero de núcleos conectados ao barramento e k o tamanho do flit 3 utilizado.
Este vetor de entrada é interligado diretamente à saída de todos os nodos conectados ao barramento, e é utilizado por o árbitro, após uma requisição ter sido recebida, para avaliar se o destinatário da mensagem está disponível, e;
Data_ ack:
Composto por n sinais, sendo n igual ao número de núcleos conectados ao barramento.
Este sinal é recebido por o árbitro tendo como origem o destinatário, e é utilizado para notificar o árbitro de que a mensagem foi recebida em seu destino.
Como saída o árbitro possuí quatro sinais:
Bus_ ack, bus_ ind, bus_ wr e data_ a..
Cada um de eles terá seus detalhes comentados a seguir.
Bus_ ack:
Vetor de y sinais, sendo y o número de nodos que compõem o barramento.
Utilizado para notificar o solicitante de que o dado foi recebido por o destinatário;
Bus_ ind:
Um valor integral que contém o índice do solicitante escolhido por o árbitro para ter acesso ao barramento;
Bus_ wr:
Este sinal binário é utilizado para notificar o módulo de controle de escrita do barramento de que o dado em sua porta de entrada, com índice armazenado em bus_ ind deve ser escrito no barramento, e;
Data_ a:
Composto por n sinais, sendo n igual ao numero de núcleos conectados ao barramento.
Sinal usado por o árbitro para notificar o destinatário de que uma mensagem endereçada a ele está disponível.
O árbitro é composto por duas máquinas de controle.
A primeira é utilizada para o controle da porta que irá ter sua solicitação atendida, e utiliza um algoritmo rotativo, de maneira a tentar evitar starvation4, garantindo justiça entre todas as requisições.
Quando uma requisição é recebida e o árbitro decidir por atendes- la, o solicitante terá acesso ao barramento até enviar todo seu pacote.
A segunda máquina de controle é utilizada para garantir a sincronia dos dados entre o solicitante e o destinatário.
Para realizar isto o árbitro utiliza um protocolo de comunicação baseado no protocolo credit-based, aonde, após receber uma sinalização de envio liberado, ou então um &quot;crédito «para envio, o solicitante pode transmitir toda sua mensagem.
A Figura 4.4 apresenta um exemplo de uma porta solicitando acesso ao barramento para o árbitro, o envio de seu dado, o recebimento no destinatário e a sinalização ao solicitante de dado recebido.
É importante ressaltar que neste exemplo o módulo wrapper foi omitido para simplificar o entendimento.
Em este exemplo, supõe- se que o nodo 0000 deseja enviar um flit para o nodo 1111.
Os passos para o envio são descritor a seguir:
Wrapper O segundo módulo desenvolvido foi o wrapper, sendo este composto por um bloco responsável por interligar o módulo IP à via de comunicação e por uma unidade de entrada e saída, para controlar o acesso aos dados do barramento.
Cinco sinais de entrada e cinco sinais de saída compõem a interface externa deste módulo e cada um destes sinais será comentado no decorrer de o texto.
Os sinais de entrada do wrapper são:
Bus_ data_ in, data_ req, bus_ ack, data_ in, ack_ tx e rx.
Detalhes do uso de cada sinal estão descritos a seguir.
Bus_ data_ in:
Vetor de tamanho Y, sendo Y o tamanho do flit utilizado.
Recebe o valor de saída do barramento e o escreve na porta de entrada do IP;
Data_ req:
Sinal de um bit utilizado para sinalizar a presença de um dado no barramento com destino ao nodo deste wrapper;
Bus_ ack:
Sinal de um bit que serve como resposta positiva a uma solicitação feita ao árbitro para envio no barramento;
Data_ in:
Vetor de N bits, sendo N o tamanho do flit utilizado.
Porta de entrada de dados vindo do IP com destino ao barramento, e;
Rx: Sinal de um bit usado para sinalização de novo dado vindo do módulo IP com destino ao barramento.
Como saída, o wrapper possui os sinais:
Tx, ack_ rx, data_ out, data_ ack, bus_ req e bus_ data_ out..
A seguir um maior detalhamento a respeito de cada sinal.
Tx: Sinal de um bit usado para sinalizar o IP da disponibilidade de um novo dado no barramento;
Data_ out:
Vetor de X bits, sendo X o tamanho do flit, recebe o valor de saída do barramento e o copia para entrada do IP;
Data_ ack:
Sinal de um bit que contém uma resposta positiva de um dado escrito no barramento;
Bus_ req:
Bit utilizado para solicitar acesso do barramento ao árbitro, e;
Bus_ data_ out:
Vetor de K bits, sendo K o tamanho do flit, que armazena o pacote vindo do IP e o escreve na entrada do barramento.
Importante ressaltar que este módulo funciona apenas como um conversor de protocolos, realizando uma ponte de troca de dados entre um IP e o barramento, servindo como interface de acesso ao árbitro.
Módulo de Comunicação Barramento-NoC O último módulo de hardware desenvolvido, foi o wrapper responsável por interligar um cluster, via a data port do barramento, à uma porta da NoC.
O módulo criado foi nomeado Cluster Interface (Ci), sendo composto por duas filas para armazenamento temporário dos dados que trafegam entre um roteador da NoC e o barramento interno do cluster.
Este módulo executa em paralelo com as unidades IP que estão operando no sistema, ou seja, ele funciona como um IP qualquer conectado ao barramento interno do cluster.
Sendo assim, para enviar uma mensagem para outro cluster, a mensagem deve sair de seu IP, passando por o Ci, que está interconectado à NoC via porta local do roteador, que a envia para o cluster destino.
Em o destino da mensagem, o roteador recebe a mensagem na porta local, que repassa para o Ci do cluster.
Por fim, o módulo encaminha a mensagem para a unidade IP destino.
Em a versão implementada neste trabalho, o protocolo de comunicação adotado entre os nodos da NoC é o handshake e, para uso de outro protocolo, o módulo Ci deve ser adaptado.
A Figura 4.6 apresenta uma visão do módulo Ci, onde pode- se observar os sinais utilizados para troca de dados com um roteador da NoC com o barramento.
É importante ressaltar que no modelo adotado, o módulo de comunicação barramento-NoC concorre com os IPs internos do cluster por o barramento, podendo contribuir para um aumento no tráfego de informações.
O fluxo de troca de informações entre o cluster e um roteador é realizado em dois momentos distintos:
O envio de uma mensagem de dados completa (de tamanho definido em tempo de projeto) da via de comunicação origem para o Ci e, somente após o recebimento de toda mensagem, o repasse desta mensagem para a via de comunicação destino.
A Figura 4.7 apresenta um exemplo de envio de um mensagem de um nodo num cluster para um nodo em outro cluster.
Em a figura é possível observar a presença de uma NoC externa, contendo em cada porta local de seus roteadores um cluster formado por dois núcleos IP, um barramento e o módulo Ci.
Em um primeiro momento (bloco A da figura) o nodo origem envia sua mensagem para o módulo Ci via barramento.
Após toda mensagem ser armazenada no buffer intermediário do Ci, uma solicitação de envio é realizada para a porta local da NoC.
Assim que recebe uma liberação da NoC, o módulo Ci envia a mensagem para o cluster destino, via NoC (bloco B da figura).
Por último (bloco C da figura), esta mensagem é recebida por o módulo Ci do cluster destino via porta local.
Assim que recebe toda, o módulo encaminha esta mensagem, via barramento interno para o nodo destino.
Atualização do Driver do HellfireOS Finalizada a etapa de desenvolvimento e validação de todos módulos de hardware, o suporte de alto-nível via sistema operacional HellfireOS foi implementado.
Um driver para comunicação já existia em versões prévias do HFOS, porém apenas com suporte à comunicação direta entre dois nodos.
Este driver serviu como base para o desenvolvimento da versão destinada à comunicação entre clusters.
Um detalhe importante é que a comunicação entre componentes presentes num mesmo cluster usará a nova versão do driver desenvolvido, ficando o driver antigo destinado somente a MPSoCs simples5.
Source_ id, unsigned char buf, unsigned short* size) utilizada para recebimento de mensagens, que funcionam da seguinte maneira:
MPSoCs simples se refere aos MPSoCs formados por um único meio de comunicação, com apenas um nível de profundidade, ou seja, sem diferentes níveis de comunicação, como em barramentos hierárquicos, por exemplo.
Driver de envio de mensagens:
Armazena num buffer intermediário em software, na seguinte ordem:
Endereço do roteador destino;
Ii) o tamanho do pacote, para controle do roteador;
Iii) o id da CPU que está enviando a mensagem;
Iv) id da tarefa destino e também da tarefa origem concatenados;
Vi) o tamanho total da mensagem enviada;
Vii) quantidade de pacotes que compõem a mensagem, e;
Viii) o conteúdo da mensagem;
Driver de recebimento de mensagens:
Tratada por o driver de recepção de mensagens;
A nova versão do driver de comunicação ampliará as informações contidas no corpo das mensagens, apenas adicionando mais dois campos, correspondentes aos endereços de roteador destino, para trânsito entre clusters, e IP destino, para encaminhamento interno no cluster destino.
A estrutura do novo pacote pode ser observada na Figura 4.8 e seus dados serão comentados a seguir.
Módulo_ OUT_ ID:
Contém o endereço do módulo Ci no barramento interno do cluster, sendo este endereço fixo independentemente do número de IPs;
Payload: Tamanho total da mensagem enviada, considerando o cabeçalho;
Cluster_ Destino_ ID:
Endereço do nodo de destino na NoC e utiliza os endereços da NoC empregada, no caso deste trabalho, a NoC Hermes;
Nodo_ Destino_ ID:
Armazena o endereço do nodo destino internamente ao cluster que recebeu a mensagem;
CPU_ Origem_ ID:
Contém o endereço do nodo que originou a mensagem;
Task_ Origem_ ID e Task_ Destino_ ID:
Armazena dois dados concatenados, cada um de oito bits, a identificação da tarefa originária da mensagem e a identificação da tarefa destino da mensagem;
Tamanho da Mensagem:
Contém o tamanho total da mensagem, utilizado por o driver de recebimento para casos em que a mensagem seja segmentada;
Sequênciamento de Pacote:
Campo também utilizado em situações em que a mensagem é segmentada para poder reestruturas- la, e;
Para comunicação entre clusters as funções de comunicação do HFOS serão utilizadas, porém com o acréscimo de um parâmetro cada, sendo o protótipo das funções apresentado a seguir:
Para enviar mensagem entre os clusters o projetista deve ter conhecimento do mapeamento das tarefas realizado, sabendo, deste modo, o cluster, o nodo e a tarefa de destino da mensagem.
Em casos de comunicação interna num cluster o projetista deve apenas passar 1 como nodo destino e o mecânismo de controle interno do driver realiza a conversão do endereço de envio correto.
Ambas funções possuem duas versões, uma bloqueante e outra não bloqueante.
A versão não bloqueante destas funções recebe um parâmetro extra, um valor de timeout, que é utilizado como tempo limite para realizar a operação desejada.
Em estes casos um contador interno é utilizado no driver, servindo como controle de tempo máximo de espera.
Assim que o contador atinge o valor de timeout, o driver retorna uma mensagem informando falha na operação.
Em os modelos bloqueantes o timeout é considerado zero, ou seja, o driver aguarda até finalizar a operação.
Cluster Após implementação e validação de todos os módulos de hardware que compõem o MPSoC proposto neste trabalho, assim como a atualização e disponibilização de um driver para o HellfireOS, uma versão final da arquitetura foi gerada, para fins de simulação, prototipação e debug.
Esta arquitetura básica inicial serviu como template para geração de casos de teste de validação da arquitetura física, assim como validação do driver descrito e é composta dos seguintes módulos:
IBI); Wrappers para interligar a NoC aos clusters, e;
Vi) imagens do HellfireOS que executam sobre os IPs.
As Bis utilizadas neste trabalho possuem buffers de armazenamento temporários, assim como no Ci.
Isto se deve ao fato de que, dessa maneira, o tempo gasto entre a interação IPbarramento pode ser reduzido, permitindo um melhor desempenho no processo de saída de dados do IP.
Um cenário em que é possível verificar a melhor eficiência deste modelo é o seguinte:
Considerando um processo p comunicante qualquer, toda vez que p precisar trocar mensagens com outro IP, a mensagem será armazenada temporariamente no buffer intermediário, sendo enviada quando o barramento estiver livre, liberando a tarefa para seguir sua execução.
Não havendo este buffer, a tarefa ficaria presa até conseguir enviar a mensagem, o que poderia atrasar sua execução e, por consequência, comprometer o funcionamento do sistema.
A Figura 4.9 apresenta a arquitetura final usada para validação dos módulos.
É possível notar que em cada cluster existe um número diferente de IPs, e que os módulos Ci e Bi foram ocultados.
Ambos, driver e arquitetura, foram validados em simulações utilizando Modelsim e por prototipação, utilizando uma FPGA Virtex II Pró, e os resultados serão apresentados na Seção Após implementação e validação de todos os componentes introduzidos neste trabalho:
Para obtenção de resultados, MPSoCs de tamanho variado, possuindo de quatro pontos1 até 81 pontos que utilizam tamanhos de cluster interno variados, porém com número de pontos internos ao cluster nunca maior do que oito, foram gerados.
Para fins de comparação, MPSoCs utilizando apenas uma NoC como meio de comunicação também foram gerados, contendo o mesmo número de pontos dos casos de teste para clusters.
Os detalhes dos resultados obtidos e a comparação dos resultados para uma solução utilizando um MPSoC que empregue clusters e sua versão que utiliza apenas um NoC são apresentados a seguir.
A Figura 5.1 apresenta um exemplo de como foi feita a divisão de nodos de um MPSoC formado unicamente por uma NoC para um MPSoC clusterizado.
Em este exemplo, um MPSoC contendo 16 pontos de comunicação é apresentado numa configuração utilizando somente uma NoC e, então este mesmo MPSoC é ilustrado utilizando clusters.
NoC central interligando todos os nodos.
A lista a seguir apresenta, para cada caso a configuração do número de pontos por cluster, assim como o tamanho de NoC central utilizada:
9 pontos:
NoC central de tamanho 2x2, três nodos contendo dois pontos e um nodo contendo três pontos;
12 pontos NoC central de tamanho 2x2, quatro nodos de três pontos cada;
16 pontos NoC central de tamanho 2x2, quatro nodos com quatro pontos cada;
25 pontos NoC central de tamanho 2x2, três nodos com seis pontos e um nodo com sete pontos;
36 pontos NoC central de tamanho 3x2, seis nodos contendo seis pontos cada;
42 pontos NoC central de tamanho 3x2, seis nodos com sete pontos cada;
49 pontos NoC central de tamanho 3x3, cinco nodos contendo cinco pontos cada e quatro nodos com seis pontos cada;
64 pontos NoC central de tamanho 3x3, oito nodos com sete pontos cada e um nodo com oito pontos;
72 pontos NoC central de tamanho 3x3, nove nodos com oito pontos cada, e;
81 pontos NoC central de tamanho 4x3, dez nodos com sete pontos cada, um nodo com seis pontos e um nodo com cinco pontos.
Além de todos estes MPSoCs gerados, outros dez MPSoCs foram criados, utilizando apenas um NoC central, para fins de comparação.
As seguintes dimensões de NoC foram utilizadas:
3x3, 4x3, 4x4, 5x5, 6x6, 7x6, 7x7, 8x8, 9x8 e 9x9.
A Tabela 5.1 apresenta uma comparação dos resultados obtidos para as duas soluções, ilustrando o ganho de área ao se utilizar um MPSoC formado por clusters.
É possível notar que em todos os casos, houve uma diminuição significativa no uso de área do dispositivo.
A Figura 5.2 apresenta um gráfico apontando o crescimento de área de ambas soluções, cluster e MPSoC simples, onde é possível observar o comportamento de crescimento da solução utilizando apenas um NoC como meio de comunicação.
Utilizando- se clusters, o aumento de área não ocorre nessa mesma taxa de crescimento, com um aumento menos significativo, quando comparado à solução anterior.
A Tabela 5.2 apresenta os dados referentes às velocidades de execução obtidas a partir de a síntese para o dispositivo.
Em a tabela pode- se observar as frequências de operação para ambas soluções, MPSoC simples e cluster, assim como o percentual de perda de velocidade da solução utilizando clusters.
Esta perda já era esperada, e ocorre devido a um aumento na complexidade do hardware projetado.
A Figura 5.3 apresenta um gráfico das frequências obtidas.
É possível observar certa linearidade em tais frequências em ambos os casos, com uma frequência levemente inferior para solução do tipo cluster, o que, conforme comentado anteriormente, era esperado.
Resultados para Virtex II Assim como utilizado na obtenção de resultados para a Virtex V, a obtenção de resultados para Virtex II contou com diferentes cenários distintos, porém com um menor número de casos de teste, se comparado aos casos usados na Seção 5.1.1.
Isso se deve ao fato de que a Virtex II é um dispositivo com menores recursos, limitando seu uso.
De esta maneira, apenas quatro MPSoCs foram configurados, conforme a lista a seguir apresenta:
9 pontos:
NoC central de tamanho 2x2, três nodos contendo dois pontos e um nodo contendo três pontos;
12 pontos NoC central de tamanho 2x2, quatro nodos de três pontos cada;
16 pontos NoC central de tamanho 2x2, quatro nodos com quatro pontos cada;
25 pontos NoC central de tamanho 2x2, três nodos com seis pontos e um nodo com sete pontos;
Para fins de comparação, outros quatro MPSoCs foram criados, utilizando apenas um NoC central.
As seguintes dimensões de NoC foram utilizadas:
3x3, 4x3, 4x4 e 5x5.
A Tabela 5.3 apresenta uma comparação dos resultados obtidos para as duas soluções, ilustrando a diferença de ocupação entre cada uma.
Um detalhe importante a se ressaltar neste caso é o fato de que a FPGA utilizada contém recursos muito mais limitados em relação a a Virtex V. Graças a isso o crescimento apresentado por ambas soluções é muito mais rápido, porém com o mesmo comportamento anterior.
V. Isto ocorre pois, conforme citado anteriormente, esta FPGA contém menos recursos disponíveis, forçando a implementação de certos módulos do hardware de maneira menos otimizada, mascarando possíveis melhorias passiveis de ocorrer na síntese.
Finalmente, a Figura 5.5 apresenta o gráfico das velocidades obtidas, onde é possível observar uma queda nas velocidades, de maneira geral quando comparada à Virtex V, graças às limitações da placa já comentadas no texto.
Com posse desses dados foi possível concluir que, utilizando- se a solução de clusters para sistemas intrachip multiprocessados, obtém- se uma diminuição na área ocupada do dispositivo em todos casos, porém diminuindo sua frequência de operação também.
Para a Virtex V obteve- se um ganho médio relacionado a área de 69.84%, com uma queda média na frequência de 6.79%.
No caso de a Virtex II o ganho médio em área foi de 55.28% com um ganho médio na frequência de Resultados de síntese para tecnologia 65 nm Para geração de resultados de síntese para tecnologia 65 nm, os mesmos dez MPSoCs configurados para síntese em FPGA, na sessão 5.1, foram utilizados.
Dois tipos de resultados foram obtidos nesta classe, a de área física ocupada e a potência para ambas soluções.
MPSoCs de nove pontos a 81, utilizando soluções do tipo cluster e puramente utilizando NoCs.
É possível observar um redução significativa na área ocupada por MPSoCs do tipo cluster, chegando a ocupar uma área até 80% menor.
A Figura 5.6 apresenta o gráfico do crescimento das áreas de ambas soluções.
É possível observar um crescimento linear no uso de área quando utiliza- se puramente NoCs, ao contrário de o crescimento de uso de área das soluções do tipo cluster, e que o crescimento é muito menor.
Após obtenção das áreas utilizadas para ambas configurações de MPSoC, cluster e NoC, os resultados para suas potências foram gerados.
Esses resultados são estimativas geradas por a ferramenta RC, da Cadence.
A Tabela 5.6 apresenta a comparação dos resultados.
Assim como nos resultados de área, os resultados de potência apresentam um menor uso na solução do tipo cluster, quando compara à solução puramente com NoC.
Em este caso, a potência chega a ser 227% menor no MPSoC clusterizado.
Um gráfico representando a taxa de crescimento da potência para ambas as soluções pode ser observado na Figura 5.7, aonde, novamente a solução do tipo NoC apresenta um crescimento linear, ao contrário de o tipo cluster, em que o crescimento se dá numa taxa muito menor.
A partir de os dados coletados, pode- se observar que, assim como nos resultados obtidos na síntese para tecnologias FPGA obtém- se uma diminuição na área ocupada por a solução do tipo cluster, assim como uma menor potência.
Obteve- se um ganho médio relacionado a área de 66.88%, com uma potência em média 149.32% menor.
Resultados de desempenho de comunicação Para realizar a extração de resultados de desempenho de comunicação, cinco cenários foram gerados para cada tipo de MPSoC, conforme segue:
9 pontos:
NoC central de tamanho 2x2, três nodos contendo dois pontos e um nodo contendo três pontos;
16 pontos NoC central de tamanho 2x2, quatro nodos com quatro pontos cada;
25 pontos NoC central de tamanho 2x2, três nodos com seis pontos e um nodo com sete pontos;
36 pontos NoC central de tamanho 3x2, seis nodos contendo seis pontos cada;
49 pontos NoC central de tamanho 3x3, cinco nodos contendo cinco pontos cada e quatro nodos com seis pontos cada, e;
81 pontos NoC central de tamanho 4x3, dez nodos com sete pontos cada, um nodo com seis pontos e um nodo com cinco pontos.
Para comparação, cinco MPSoCs formados somente por NoC foram utilizados, contendo os mesmo números de pontos de comunicação citados anteriormente, possuindo as seguintes dimensões:
9 pontos:
NoC 3x3;
ii) 16 pontos:
NoC 4x4;
iii) 25 pontos:
NoC 5x5;
iv) 49 pontos:
NoC 7x7, e;
81 pontos:
NoC 9x9.
Para avaliar a capacidade comunicativa do MPSoC clusterizado foi buscado o cenário que mais utilizasse o meio de comunicação, sendo o cenário escolhido um em que todos os pontos se comunicassem com todos, utilizando o meio em sua totalidade.
Em cada um dos testes realizados o tamanho das mensagens trocadas variou de 64 bytes até 512 bytes, sendo os resultados apresentados em número de ciclos de relógio.
A Tabela 5.7 apresenta os valores obtidos em simulações para nove pontos de conexão.
Quatro tamanhos de mensagens foram utilizados, 64 bytes, 128 bytes, 256 bytes e 512 bytes.
É possível observar ainda, dois campos para cada tamanho de mensagem, Total e Interno.
O campo Total, como o nome sugere, refere- se ao tempo total que um ponto leva para enviar mensagens para todos os outros pontos.
Já o campo Interno refere- se ao tempo que um ponto leva para enviar mensagens para todos os pontos que fazem parte de seu cluster.
A Figura 5.8 apresenta um gráfico do tempos médios, em ciclos, dos envios em MPSoCs com nove pontos, neste caso observou- se um aumento de 64.98% em média no tempo Total de troca de mensagens do MPSoC clusterizado com uma redução média de 30.79% no tempo de envio Interno.
A Tabela 5.8 apresenta a comparação dos resultados obtidos para 16 pontos de comunicação, demonstrando mais uma vez uma menor eficiência para o envio Total de mensagens do MPSoC clusterizado, porém com um menor tempo para troca de mensagens na parte interna do cluster, por os mesmos motivos já comentados anteriormente.
O gráfico dos tempos médios de envio para MPSoCs com 16 pontos de comunicação é apresentado na Figura 5.9 aonde é possível observar uma queda média de 23.29% no tempo de troca de mensagens internas no cluster e um aumento de 123.64% em média para o envio Total.
Em a Tabela 5.9 os resultados apresentados diferem dos demais obtidos.
Enquanto o tempo Total manteve o mesmo comportamento dos demais casos, com o MPSoC clusterizado levando mais tempo para enviar suas mensagens, neste caso o tempo Interno também foi maior no MPSoC clusterizado.
Acredita- se que este fato ocorreu graças a uma relação entre o número de pontos internos em cada cluster, frente a o tamanho total do MPSoC, fato este porém que deverá ser abordado num trabalho futuro.
A Figura 5.11 apresenta um gráfico comparando os tempos de envio de ambas arquiteturas.
O MPSoC formado por cluster obteve uma média 88.10% maior para envios totais, porém, como nos casos de nove e 16 pontos, observou- se uma redução no tempo de envio para os pontos internos do cluster, numa taxa média de 50.10%.
O ultimo cenário utilizado foi formado por 81 pontos de comunicação, e os resultados podem ser visualizados na Tabela 5.11, onde é possível notar- se o mesmo comportamento dos casos de nove, 16 e 49 pontos, com um tempo Total maior para arquitetura do tipo cluster e um tempo menor para envios internos.
Após verificação de todos os cenários, pode- se chegar a conclusão de que o tempo médio para envio de mensagens Total utilizando- se MPSoCs clusterizados é 117.77% maior, porém com uma redução no tempo médio de comunicação interna do cluster de 20.26%.
O trabalho proposto apresentou um modelo de arquitetura clusterizada para MPSoCs, denominada HC-MPSoC, utilizando barramentos e NoCs.
Esse modelo apresenta uma organização híbrida, constituída por nodos formados por núcleos IP interligados por um barramento, e uma rede intrachip central interligando todos estes nodos.
Foram apresentados todos os detalhes de sua implementação, explicando o funcionamento de cada módulo que faz parte do sistema, sendo estes os módulos desenvolvidos:
Barramento, wrappers que interligam o barramento ao roteador da NoC, wrappers para interligar o processador utilizado ao barramento e a descrição de um driver para uso do HellfireOS nesta arquitetura.
Esta arquitetura foi projetada de modo a permitir o agrupamento de módulos IP com maior afinidade em grupos, denominados clusters.
De essa maneira buscouse permitir ao desenvolvedor projetar seu sistema de forma direcionada à aplicação, utilizando os recursos da maneira mais otimizada possível.
Em o sentido de validação da arquitetura, três cenários de estudo de caso foram propostos.
Em todos os cenários foi feita uma comparação com MPSoCs formados unicamente por uma NoC central, ou seja, com apenas um IP em cada roteador.
Isso foi feito para ter- se um ponto de referência nos dados obtidos nos resultados para o HC-MPSoC.
O primeiro cenário foi a geração de resultados para sínteses em dispositivos FPGA, onde dois dispositivos, Virtex V e Virtex IIP, foram utilizados.
Em este primeiro cenário foram comparadas as áreas de ocupação nos dispositivos e as frequências de operação obtidas.
Observou- se que a arquitetura clusterizada ocupou, em média, uma área 69.84% menor para o dispositivo Virtex V e 55.28% para Virtex II.
Os resultados de frequência apontam uma queda média de 6.79% nos resultados obtidos para Virtex V e um ganho de 7.05% para Virtex IIP.
Em o segundo cenário, resultados da síntese física para tecnologia de 65 nm da STMicro foram obtidos.
Em este caso a frequência alvo foi setada para 500 MHz e a área física do chip e a potência estimada foram avaliadas.
Os resultados apontam para um uso médio de área 66.88% menor utilizando- se um MPSoC clusterizado, com uma redução média na potência estimada de O ultimo cenário utilizado para comparação foi o desempenho de comunicação da arquitetura desenvolvida.
Em este caso, tráfego era injetado na arquitetura e os tempos, em ciclos de relógio, anotados.
Os resultados apontaram um tempo maior para troca de mensagens utilizando- se uma arquitetura do tipo cluster de, em média, 117.77%.
Porém, quando comparados os tempos de comunicação somente dos pontos internos ao cluster, o HC-MPSoC obteve um tempo de comunicação A arquitetura proposta se mostrou válida e foi verificada por simulações e prototipações em FPGA.
As alterações realizadas no HellfireOS foram validadas nestes cenários citados anteriormente e mostraram- se funcionais.
Além disso, uma revisão bibliográfica foi realizada com o intuito de explorar alguns dos principais trabalhos relacionados existentes.
Uma breve análise crítica de cada um desses trabalhos com relação a o modelo proposto pôde ser apreciada ao longo de sua descrição.
Também realizou- se uma pesquisa no sentido de oferecer ao leitor um embasamento teórico mais aprofundado sobre as questões de infraestruturas de comunicação em sistemas embarcados multiprocessados.
Trabalhos Futuros É importante destacar que a pesquisa realizada, não obstante, deixa margem para que diversos trabalhos futuros possam ser realizados.
Inicialmente, a verificação mais precisa com relação a o impacto da divisão de unidades de processamento em clusters, assim como a maneira mais eficiente de fazer- lo.
Ainda no sentido da divisão do sistema, deve- se buscar métodos de mapeamento e particionamento de tarefas que levem em consideração este tipo de arquitetura.
A implementação de modelos em alto nível da arquitetura, como simuladores, para uma mais rápida verificação de aplicações executando sobre ela é uma tarefa muito importante a ser realizada, agilizando assim o processo de desenvolvimento.
Finalmente, é interessante a avaliação da arquitetura proposta frente outras plataformas.
Deve- se verificar quais componentes arquiteturais beneficiam ou prejudicam o desempenho do sistema como um todo, bem como atualizar e evoluir a arquitetura atual.
Publicações Durante o período do mestrado, período este de dois anos, alguns trabalhos científicos foram submetidos para conferencias nacionais e internacionais.
Além disso um mini-curso a respeito de sistemas embarcados foi elaborado e publicado numa revista nacional por dois anos seguidos, além de ter sido ministrado por o autor nos eventos de lançamento de tais revistas.
A lista a seguir apresenta os documentos submetidos e aceitos para publicação durante o período do mestrado do autor:
Introdução ao desenvolvimento de software embarcado -- Curso publicado em revista do CBSEC e ministrado por o autor nos eventos de lançamento;
Adapting Embedded Systems'Framework to Provide Virtualization:
The Hellfire Case Study Artigo CBSEC 2011;
MPSoCs -- Artigo ICC D2012;
2011, e;
