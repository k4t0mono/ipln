Em a área de Mineração de Dados, experimentos vem sendo realizados utilizando Conjuntos de Classificadores.
Estes experimentos são baseados em comparações empíricas que sofrem com a falta de cuidados no que diz respeito à questões de aleatoriedade destes métodos.
Experimentamos o Random Forests para avaliar a eficiência do algoritmo quando submetido a estas questões.
Estudos sobre os resultados mostram que a sensibilidade do Random Forests é significativamente maior quando comparado com a de outros métodos encontrados na literatura, como Bagging e Boosting.
O proposito desta dissertação é diminuir a sensibilidade do Random Forests quando submetido a aleatoriedade.
Para alcançar este objetivo, implementamos uma extensão do método, que chamamos de Random Forests Estocástico.
Logo especificamos como podem ser alcançadas melhorias no problema encontrado no algoritmo combinando seus resultados.
Por último, um estudo é apresentado mostrando as melhorias atingidas no problema de sensibilidade.
Palavras-chave: Mineração de Dados, Conjuntos de Classificadores, Random Forests, Bagging, Boosting.
Análise comparativa:
O grande volume de dados gerados por os sistemas de computação aumentam consideravelmente dia a dia.
Os sistemas que produzem esta quantidade de dados são executados em diferentes contextos, como corporações, empresas de diferentes portes, instituições governamentais e todo tipo de entidade que possa ter um processo ou atividade informatizada.
Há pouco tempo atrás, o volume de dados era calculado em gigabyte (GB).
Com o rápido crescimento do volume de dados gerados por os sistemas, este passou a ser calculado em terabyte (Tb) e petabyte (PB).
Estes dados são de grande valor, e podem auxiliar empresas no planejamento e na tomada de decisões.
Importantes informações estão escondidas, e não podem ser descobertas de maneira rápida e fácil por os sistemas convencionais.
Para atender esta necessidade, surgiu a Mineração de Dados.
Esta técnica tem como objetivo descobrir informações não triviais dentro desse conjunto de dados.
A Mineração de Dados utiliza métodos de outras áreas, como por exemplo, Estatística Clássica e Inteligência Artificial, para extrair conhecimento sobre um conjunto de dados, segundo Freitas.
Com o desenvolvimento da área, foram implementadas diferentes tarefas de Mineração de Dados, como:
Análise de Regras de Classificação, Análise de Padrões de Sequência, Análise Clusters, Análise de Outliers e Classificação e Predição.
Especificamente dentro de a tarefa de Classificação e Predição existe a Combinação de Classificadores, que basicamente combina o resultado de um grupo de classificadores com o objetivo de aumentar a precisão da classificação.
Incluídos no conjunto dos algoritmos que implementam esta técnica estão Bagging, Boosting e Random Forests.
Estudos apresentados por Fernandes et al.
Identificaram que conjuntos de classificadores como Bagging e Boosting, quando submetidos à aleatoriedade, classificam dados de forma instável.
O efeito causado por a aleatoriedade produz uma importante variação no resultado da classificação, fazendo com que em algumas situações estes fiquem distantes do desvio padrão.
Para estudar o comportamento do Random Forests quando submetido à aleatoriedade, experimentamos este utilizando como exemplo o experimento do estudo citado anteriormente.
A seguir apresentaremos a motivação para a realização do presente trabalho e qual o caminho a ser seguido para atingir o objetivo do mesmo.
Objetivos do trabalho Motivados por a hipótese de saber se é possível adaptar o método Random Forests para que este seja menos vulnerável à aleatoriedade, os seguintes objetivos específicos foram traçados buscando responder esta questão:·
Implementar uma extensão do método de mineração de dados Random Forests, o qual chamaremos de Random Forests Estocástico, e especificar como podem ser atingidas melhorias de precisão e estabilidade com a combinação de seus resultados;·
Experimentar o Random Forests Estocástico e analisar seus resultados, comparando estes com os resultados do Random Forests.
Buscamos assim identificar se melhorias na precisão e diminuição da variabilidade dos resultados podem ser alcançadas.
Estrutura do Trabalho Este documento esta organizado da seguinte forma:
O Capítulo 1 apresenta a introdução, hipótese de pesquisa, objetivos do trabalho e sua estrutura.
O Capítulo 2 apresenta a revisão da literatura, bem como conceitos fundamentais para o entendimento do presente trabalho, como Mineração de Dados, Classificadores e Combinação de Classificadores.
Para um melhor entendimento dos algoritmos estudados, detalhamos o funcionamento de Bagging, Boosting e Random Forests.
Trabalhos relacionados a esta dissertação são apresentados no final do capítulo.
Em o Capítulo 3, o experimento que demostra a sensibilidade do Random Forests quando submetido à aleatoriedade é definido e um estudo sobre seus resultados é apresentado.
O Capítulo 4 descreve a implementação do Random Forests Estocástico e apresenta, como podem ser obtidos ganhos de precisão e como a variabilidade dos resultados de classificação pode se diminuída através da combinação de resultados.
Descreve também o experimento ao qual o Random Forests Estocástico foi submetido.
Em o final do capítulo, os resultados experimentais são analisados e comparados com os resultados obtidos no experimento com Random Forests.
Por último, no Capítulo 5, a conclusão do trabalho e a contribuição do mesmo são apresentadas.
Em o presente capítulo serão apresentados conceitos importantes para o entendimento do contexto desta dissertação.
Uma noção geral sobre Mineração de Dados, Classificadores e Combinação de Classificadores será transmitida.
Em um segundo momento, uma abordagem mais técnica é dirigida dentro de a área de Combinação de Classificadores, apresentando um conjunto de três algoritmos:
Bagging, Boosting e Random Forests.
Os resultados da pesquisa sobre o assunto citado acima são de fundamental importância para o desenvolvimento do trabalho.
Mineração de Dados A Mineração de Dados faz parte do processo conhecido como KDD (Knowledge Discovery in Databases), que pode ser observado na Figura 2.1.
Este processo consiste num série de etapas de transformação, pre-processamento dos dados até o pós-processamento dos resultados da mineração de dados.
Segundo Tan et al.
A Mineração de Dados permite a extração não trivial de conhecimento previamente desconhecido e potencialmente útil em bases de dados.
É possível descobrir informações úteis como padrões ou anomalias que por outros meios poderiam ser ignorados.
Para atingir tal objetivo esta utiliza técnicas de varias outras áreas (Estatística Clássica, Inteligência Artificial e Aprendizado de Maquina), segundo Freitas.
Observamos que tarefas como a busca de informações utilizando sistemas gerenciadores de banco de dados ou a busca de páginas da internet através da utilização de um mecanismos de busca não são consideradas tarefas de mineração de dados e sim de recuperação de dados.
As técnicas tradicionais de análise de dados encontravam dificuldades para poder superar os desafios que as bases de dados proporcionavam.
Dados complexos e com alta dimensionalidade, distribuição de dados e análises não tradicionais motivaram o surgimento desta área.
As tarefas de mineração de dados estão divididas em dois grupos:
1) tarefas que tentam prever o valor de um atributo baseado em n atributos 2) tarefas descritivas que tentam derivar padrões que resumam o relacionamento subjacente dos dados.
Integrando os grupos citados acima, encontramos tarefas como a Análise de Regras de Classificação, Análise de Padrões de Sequência, Análise de Cluster, Análise de Outlier e a Classificação e Predição.
Especificamente dentro de a tarefa de Classificação e Predição existem os Classificadores e a Combinação de Classificadores, que são parte do nosso estudo e serão apresentados nas próximas seções.
Classificadores A tarefa dos Classificadores é tentar prever a classe de um objeto representado por uma instância, baseado no valor dos seus atributos.
Para executar a tarefa de previsão, o classificador utiliza um conjunto de atributos, denominados previsores, e um atributo, denominado classe.
Os atributos previsores são utilizados para definir uma classificação efetiva dos registros pertencentes ao conjunto de dados em estudo.
O atributo classe, por sua vez, é utilizado com uma hipótese de classificação que será válida ou não por a análise resultante da classificação por meio de os atributos previsores, conforme descrito por Carvalho.
Para construção e teste do modelo, o algorimo utiliza dois subconjuntos de dados extraídos da base de dados original.
O primeiro conhecido como conjunto de treinamento que é utilizado para construir o classificador.
O segundo conhecido como conjunto de testes é utilizado para testar a precisão do modelo.
O conjunto de treinamento é percorrido analisando as relações existentes entre os atributos previsores e o atributo classe.
Estas relações são então usadas para prever as classes das instâncias presentes no conjunto de teste, segundo Mitchell.
Para testar a precisão do modelo o algoritmo analisa o conjunto de testes e o atributo classe não é considerado.
Após prever as classes das instâncias do conjunto de teste, estas são comparadas com as classes de hipótese definidas por o classificador.
O resultado gerado a partir de o conjunto de teste é utilizado para obter a taxa de acerto, que é calculada comparando a quantidade de previsões corretas sobre a quantidade de instâncias do conjunto de teste.
Como resultado, temos a taxa de classificação do algoritmo.
Buscando melhorar esta taxa, surgiu a Combinação de Classificadores, que será apresentada na seção seguinte.
Combinação de Classificadores A previsão por múltiplos classificadores é conhecida como técnica de Combinação de Classificadores.
Um método de conjunto constrói um conjunto de classificadores básicos a partir de um conjunto de dados de treinamento.
Para prever a possível classe de uma determinada instância, todos os classificadores votam por uma classe e a mais votada é selecionada.
Para entender como esta técnica de combinação de classificadores pode melhorar o desempenho, analisaremos o seguinte caso:
Sobre um conjunto de vinte e cinco classificadores binários, onde cada um possui uma taxa de erro de $= 0.35, o rótulo da classe de uma instância de testes D1 é selecionado escolhendo a classe mais votada sobre as previsões feitas por os classificadores básicos.
Se os classificadores forem idênticos, então o grupo classificará erroneamente, permanecendo a taxa de erro de 0.35.
Se os classificadores forem independentes e seus erros não estiverem correlacionados, então o grupo fará uma previsão incorreta se mais da metade dos classificadores estiverem incorretos, como pode ser observado no cálculo da Equação 2.1.
Cálculo da taxa de erro:
A taxa é consideravelmente menor que a taxa dos classificadores básicos.
Para um melhor entendimento a Tabela 2.1 resume o exemplo apresentado anteriormente.
A Figura 2.2 mostra uma visão logica do método de aprendizagem de grupo.
Para uma melhor compreensão do funcionamento dos classificadores de conjuntos, apresentaremos Bagging, Boosting e Random Forests métodos largamente utilizados por a comunidade científica.
Figura 2.2: Uma visão logica do método de aprendizagem de grupo.
Também conhecido como agregação de Bootstrap, foi proposto por Breiman, a idéia básica do algoritmo é criar classificadores a partir de uma base de dados de treinamento utilizando distri-buição uniforme de probabilidades.
Cada amostra de Bootstrap possui o mesmo tamanho dos dados originais, já que a amostragem é feita com substituição.
Algumas instâncias podem aparecer repetidamente no mesmo conjunto de treinamento, enquanto que outras podem ser omitidas, segundo Quinlan.
Os classificadores são gerados independentemente, e a classificação é definida por o voto majoritário sobre todos os classificadores.
Bagging consiste em combinar T classificadores de N amostras geradas a partir de o conjunto de treinamento M com R instâncias.
Cada classificador contem m instâncias do conjunto de treinamento original M. A o invés de utilizar todas as instâncias do conjunto original de treinamento, o método de amostragem escolhe instâncias uniformemente com repetição.
O método de amostragem gerará K exemplos, que representam aspectos originais da base de dados.
Para cada exemplo o classificador é gerado independentemente.
A classificação de uma nova instância será executada sobre cada um desses T classificadores.
Para cada tentativa t $= Ci será gerado e ao final um classificador C* será formado através da geração de T classificadores obtidos em cada tentativa.
Para classificar uma amostra desconhecida, cada classificador Ci retorna o seu voto.
A o final, o classificador C* retorna a classe com maior número de votos.
Perturbações no conjunto de treinamento podem causar mudanças significativas no classificador construído.
Com isto, Bagging pode melhorar a sua precisão, segundo Breiman.
O pseudocódigo de Bagging é exibido na Figura 2.3.
Boosting é um método de combinação de classificadores desenvolvido para oferecer uma classificação com maior eficiência.
Este é um procedimento iterativo usado para alterar adaptativamente a distribuição de exemplos de treinamento, de modo que os classificadores de base foquem em exemplos que sejam difíceis de classificar.
A partir deste método foram criados vários algoritmos, como por exemplo, AdaBoost (Adaptative Boosting), proposto por Freund e Schapire.
Diferentemente de Bagging, Boosting atribui um peso para cada conjunto de treinamento, que pode ser utilizado para desenhar um conjunto de amostras de Bootstrap a partir de os dados originais.
Podem também ser usados por o classificador de base para descobrir um modelo que tenha tendência na A distribuição de amostragem do conjunto de treinamento funciona da seguinte forma:
Inicialmente os exemplos recebem peso 1/ N, assim todos possuem a mesma probabilidade de serem escolhidos para treinamento.
Uma amostra é desenhada de acordo com a distribuição de amostras dos exemplos de treinamento, para obter um novo conjunto de treinamento.
Logo após, um classificador é induzido a partir de o conjunto de treinamento que é utilizado para classificar todas as instâncias do conjunto de dados original.
Os pesos dos exemplos de treinamento são atualizados ao final de cada rodada de Boosting.
Para forçar que o classificador foque nos exemplos que são de difícil classificação, os exemplos que são classificados incorretamente terão o seu peso aumentado, os que forem classificados corretamente terão seu peso diminuído.
À medida que as rodadas de Boosting avançam, os exemplos mais difíceis de ser classificados se tornam ainda mais predominantes.
O conjunto final é obtido agregando- se os classificadores de base resultantes de cada rodada de Boosting.
A seguir uma explicação técnica do funcionamento de AdaBoost será apresentada para um melhor entendimento:
Inicialmente, AdaBoost inicializa os pesos de todos os N exemplos com o valor 1/ n..
A primeira geração feita escolherá instâncias de uma maneira uniforme.
Logo depois de criado o conjunto de treinamento Di a partir de D, um classificador Ci é treinado sobre Di.
O conjunto de treinamento D é classificado por o classificador Ci.
A taxa de erro do classificador Ci (linha sete do Algoritmo de Boosting observado na Figura 2.4), é calculada levando em conta o número de instâncias da amostra.
O peso de cada uma das instâncias é a efetividade do classificador Ci.
Caso a taxa de erro seja superior ao palpite aleatório, descarta- se a amostra e outra amostra é gerada com os pesos em N reinicializados.
Caso a taxa de erro i seja satisfatória, a atualização dos pesos é feita de acordo com a importância do classificador, utilizando para tanto a Equação 2.2.
Random Forests foi proposto formalmente por Breiman.
Este é um algoritmo de Combinação de Classificadores projetado especialmente para árvores de decisão.
Consiste numa coleção de aleatórios são gerados a partir de uma distribuição de probabilidade fixa sobre o vetor de entrada inicial.
A precisão do Random Forests é medida probabilisticamente em termos de margem do treinamento aleatório a partir de o vetor Y, X. A margem do classificador é medida antravés da Equação 2.3: A classe hk é prevista de X de acordo com um classificador construído utilizando o vetor randômico K. A precisão do classificador para prever um determinado exemplo de X aumenta de acordo com o aumento da margem.
A medida que a correlação das árvores aumenta, ou a força do conjunto diminui, o limite de erro de generalização tende a aumentar.
O limite de erro de generalização converge para a expressão que pode ser observada na Fórmula 2.4 quando o número de árvores for suficientemente grande.
P E $= Px, y (mg (X, Y) 0) árvore que denota na equação a seguir:
Px, y (P (h (X,) $= Y) -- maxj $= y P (h (X,) $= j) 0 Random Forests não faz overfit cada vez que mais árvores são adicionadas, mas sim produz um valor limite de erro de generalização.
O limite superior de erro de generalização pode ser derivado da integração de dois parâmetros:
Um é da medida individual da precisão de cada classificador, calculada por a equação da margem do classificador apresentada acima, e da dependência entre eles.
Para aumentar à aleatoriedade, Bagging pode ser utilizado em conjunto com a seleção aleatória de características.
Cada novo conjunto de treinamento é criado por substituição a partir de o novo vetor de entrada inicial.
Uma nova árvore é induzida a partir de um novo conjunto de treinamento usando seleção aleatória de características.
As árvores atingem o seu tamanho máximo e não é executada a poda sobre as mesmas.
Podem ser enumeradas duas razões para a utilização de Bagging:
A primeira é que a sua utilização melhora a precisão quando as características aleatórias são utilizadas;
Estas estimativas são feitas utilizando a técnica Out-of-Bag, que funciona da seguinte forma.
Suponha um método para construção de um classificador a partir de um conjunto de treinamento qualquer, e um determinado conjunto de treinamento T. A partir destes, são formados os conjuntos de treinamento de Bootstrap Tk.
Em seguida são construídos os classificadores h (x, Tx).
Este voto é dado para formar o Bagged Predictor.
Para cada y, x no conjunto de treinamento são agregados votos somente para aqueles classificadores os quais Tk não contem y, x.
Este classificador é conhecido como Out-of-Bag.
Em cada conjunto de treinamento de Bootstrap um terço das instâncias é deixado de fora.
Portanto as estimativas de Out-of-Bag são baseadas em combinar somente um terço dos classificadores.
A medida que a taxa de erro diminui e o número de combinações aumenta, as estimativas de Out-of-Bag tendem a superestimar a taxa de erro corrente.
A força e correlação entre as árvores também pode ser estimada utilizando o método de Out-of-Bag.
Estas estimativas internas ajudam a conhecer a precisão de cada classificador e como este pode ser melhorado, segundo Breiman.
Cada árvore de decisão usa um vetor aleatório, que é gerado a partir de distribuição de probabilidade fixa.
Um vetor aleatório pode ser incorporado ao processo de desenvolvimento da árvore de diversas maneiras.
Uma técnica conhecida e a Floresta-RI, onde Ri refere- se à seleção aleatória de entrada, consiste em selecionar aleatoriamente F características de entrada para dividir em cada nodo da árvore de decisão.
Ao invés de examinar todas as características disponíveis, o nodo é dividido a partir de estas F características selecionadas.
A árvore é desenvolvida utilizando a técnica de CART que denota no crescimento integral das árvores sem poda.
Logo depois da construção das árvores, as previsões são combinadas usando um esquema de votação por maioria.
A força e a correlação do Random Forests podem depender do tamanho de F. Se F for suficientemente pequeno, as árvores tendem a se tornar menos correlacionadas.
A força do classificador tende a melhorar com um número maior de características F. Para balancear o número de características, é comumente escolhido como F $= log2 d+ 1, onde d é o número de características de entrada.
Se o número de d características originais for muito pequeno, é difícil escolher um conjunto independente de características aleatórias para construir uma árvore de decisão.
Para aumentar o espaço das características, são criadas combinações lineares das características de entrada.
Esta abordagem é conhecida como Floresta-RC, conforme apresentado por Breiman.
Em cada nodo uma nova característica é gerada selecionando aleatoriamente L características de entrada.
Estas são combinadas linearmente, usando coeficientes gerados a partir de uma distribuição uniforme na faixa de.
Em cada nodo são geradas F novas características combinadas aleatoriamente, e a melhor é selecionada para dividir o nodo.
Suponha que existam M variáveis de entrada.
Logo depois que cada árvore é construída, o valor da variável mth no exemplo de Out-of-Bag é randomicamente permutado, e o conjunto de dados classificado por a árvore correspondente.
A clas-sificação dada por cada Xn que está fora de o Out-of-Bag é salva.
Este procedimento é repetido por é comparada com o rótulo da classe verdadeira de Xn para calcular a taxa de erro de classificação.
A saída é o aumento percentual da taxa de classificação incorreta em relação a a taxa de Out-of-Bag.
Para um melhor entendimento do Random Forests, a Figura 2.5 mostra o processo de construção do modelo, enquanto que a Figura 2.6 mostra o processo de classificação das instâncias.
A Figura com o Random Forests, além de as características e variações do mesmo.
Trabalhos Relacionados Esta seção apresenta trabalhos relacionados com o aqui proposto.
Estes objetivam melhorar a performance do Random Forests em algum aspecto, da mesma forma que o presente trabalho.
O estudo realizado por Tsymbal et al.
Demostrou que a precisão do Random Forests pode ser melhorada substituindo a função de combinação do resultado dos classificadores por a integração dinâmica, que é baseada no desempenho local das estimativas de performance dos preditores básicos.
O experimento conduzido no trabalho demostrou que a integração dinâmica aumentou a precisão em algumas bases de dados.
Conforme Robnik--Sikonja, individualmente, cada um dos classificadores base não são preditores efetivos ou seja, a seleção randômica dos atributos faz com que, individualmente, cada um dos classificadores seja mais fraco.
O primeiro objetivo do trabalho foi fortalecer individualmente cada um dos classificadores, sem sacrificar a variedade entre eles.
O segundo objetivo tratou de aumentar a variância sem sacrificar a força de cada um.
Foram alcançadas melhorias no primeiro objetivo usando o algoritmo ReliefF para a estimativa de atributos e no segundo objetivo usando diferentes medidas de avaliação de atributos para seleção de divisão.
Os classificadores, em certas situações, não obtiveram o mesmo sucesso ao classificar instâncias, tendo sido utilizadas estimativas internas para identificar instâncias mais similares ao do rotulo desejado.
Em seguida, os votos das árvores foram ponderados com a força que eles demostraram para aquela instância.
Com isso, foram alcançadas melhorias em várias bases de dados.
Boinee et al.
Notaram que algoritmos de aprendizado como AdaBoost e Bagging melhoraram o resultado da classificação.
Em o trabalho, o autor experimentou utilizar estas técnicas de metaaprendizado combinando com o Random Forests.
Um experimento foi conduzido e observou- se em média vantagem em favor de o que ele chamou de Bagged Random Forests, em relação a o Random Forests.
Thongkam et al.
Propuseram uma combinação de AdaBoost e Random Forests para construir um modelo de predição para o câncer de mama.
O Random Forests foi usado como um weak learner de AdaBoost para selecionar as instâncias com um peso maior durante o processo de Boosting, procurando melhorar a precisão, estabilidade e problemas de overfiting.
A capacidade do método foi avaliada medindo a taxa de acerto, sensibilidade e especificidade.
O resultado do experimento determinou que o método proposto superou C4.
5, AdaBoost e o próprio Random Forests.
Os trabalhos investigados aqui tem em comum a preocupação em melhorar a precisão do Random Forests.
Notamos apenas na preocupação em observar o comportamento da sensibilidade.
Percebemos também que, em nenhum dos trabalhos, questões relacionadas à aleatoriedade foram levadas em conta, diferentemente do trabalho apresentado aqui, cujo objetivo é melhorar a precisão e a variabilidade dos resultados do Random Forests quando submetido à aleatoriedade.
O presente capítulo apresenta um estudo sobre o comportamento do Random Forests quando submetido à aleatoriedade.
A Seção 3.1 descreve o experimento executado, os artefatos utilizados, configurações aplicadas e técnicas empregadas durante o experimento.
A Seção 3.2 desenvolve um estudo comparativo utilizando como base os resultados experimentais.
Em um primeiro momento, os resultados do Random Forests são analisados, mostrando as tendências encontradas.
Em o final, uma segunda análise, comparando os resultados do Random Forests com relação a resultados de outros algoritmos encontrados na literatura, é apresentada.
Definição do experimento utilizando aleatoriedade Uma série de estudos foram realizados anteriormente comparando Bagging e Boosting, o que nos auxilia na construção do experimento.
Para executar o experimento, foi utilizada a ferramenta WEKA (Waikato Enviroment for Knowledge Analysis 3.4.6), e o resultado foi armazenado numa base de dados.
A classificação foi executada utilizando a técnica de ten-folds stratified cross-validation, que utiliza 90% do conjunto de dados para treinamento e 10% para testes.
Mais detalhes sobre esta técnica podem se encontrados em.
Para execução dos testes foram utilizadas trinta bases de dados com diferentes características exibidas na Tabela 3.1, esta foi retirada de, maiores informações podem ser consultadas na fonte.
As bases de dados pertencem à Universidade da California Irvine e da Universidade de West Virginia.
Os resultados comparados de Bagging e Boosting foram extraídos foram configurados na ferramenta Weka com a opção Q, que utiliza bootstrap para construir os classificadores.
Random Forests constrói os classificadores utilizando esta técnica, conforme encontrado em.
Para configurar a semente a ser utilizada, o parametro foi configurado de forma aleatória conforme apresentaremos na especificação da configuração.
Procurando alcançar uma maior precisão no resultado do experimento ao igual que em, foram removidos os 5 maiores e os 5 menores resultados de cada base de dados considerando o número de classificadores utilizados.
Este procedimento evita que algum resultado com um desvio considerável exerça um peso grande no cálculo do percentual de média de acerto.
O experimento foi executado em duas rodadas, em as quais foram aplicadas as seguintes configurações para cada base de dados:·
Configuração 1;
­ Sementes:
1 até 100 (Os resultados de todas as execuções foram agrupados num único resultado).·
Configuração 2;
­ Sementes:
Default $= 1.
Os dados resultantes do presente experimento estão disponíveis em formato digital na biblioteca da Pontifícia Universidade Católica do Rio Grande do Sul.
O resultado do experimento é apresentado na Tabela 3.2.
Esta lista o resultado experimental para cada uma das configurações descritas anteriormente.
Estes resultados servirão como fonte para nossas observações e estudos.
73.5294% para a semente Default e 67.8431% para 100 sementes e 10 classificadores, 64.7059% para a semente Default e 66.0784% para 100 sementes e 30 classificadores e 64.7059% para a semente Default e 65.719% para 100 sementes e 50 classificadores.
Os resultados apresentados na Tabela 3.2 mostram a variabilidade causada por a aleatoriedade no Random Forests.
Isto é constatando comparando a distância entre os resultados encontrados nas duas configurações do experimento.
A continuação observaremos os resultados do Random Forests em comparação com Bagging e Boosting.
Observaremos se a tendência da instabilidade pode ser identificada nas próximas comparações.
Para alguns pesquisadores, como Quinlan um método pode ser considerado mais preciso do que o outro se a diferença na média de acerto for igual ou superior a 2%.
Utilizaremos este percentual como base para comparar os algoritmos e ressaltar caso algum resultado encontrado alcance este valor.
Para observar o efeito da utilização de 100 sementes randômicas, utilizaremos os valores da coluna de média de acerto que se encontram na Tabela 3.2.
A seguir, compararemos Random Forests, Bagging e Boosting com base nos valores da coluna citada anteriormente.
Considerando a margem de 2% ou mais de diferença, observamos a seguir em quantas situações o Random Forests foi mais preciso que Bagging e Boosting.
Os resultados para Bagging e Boosting foram retirados de.
Para fins de comparação, levaremos em conta a quantidade de classificadores utilizados e a utilização da semente Default ou a seleção aleatória das sementes.
Observando os resultados da média de acerto, identifi-camos que Random Forests foi melhor em 20/90, Bagging em 14/90 e Boosting em 10/90 dos casos.
O resultado foi formado por a soma dos resultados da classificação com 10, 30 e 50 classificadores utilizando a semente Default.
Este resultado mostra uma ampla vantagem para o Random Forests quando utilizado com a semente Default.
Apesar de o resultado indicar vantagem para o Random Forests, os resultados de média de acerto variam quando aplicada a seleção randômica da semente.
Utilizando a mesma quantidade de classificadores da observação anterior, e 100 sementes randômicas, o resultado encontrado foi o seguinte:
Boosting foi melhor em 12/90, Bagging em 10/90 e Random Forests 16/90 dos casos.
Mesmo permanecendo dentro de a margem de 2% em 52/90 dos casos, este resultado mostra uma queda na vantagem do Random Forests quando utilizadas as 100 sementes randômicas, quando comparado ao uso da semente Default.
Buscando confirmar a tendência da instabilidade ao utilizar a seleção randômica da semente, observaremos o comportamento do Random Forests com relação as bases de dados B05, B31, B13 e B17.
Consideraremos as características das bases de dados com o número de instâncias e desbalanceamento.
A base de dados B05 possui 286 instâncias, e o resultado da média de acerto de classificação para a semente Default foi de 54.0229%, enquanto que para 100 sementes randômicas foi 49.1315%, o que totaliza uma diferença de 4.8914%.
A base de dados B31 possui 1484 instâncias e a média resultante foi de 34.4519% para a semente Default e 49.3463% para a seleção randômica da semente, o que proporciona uma diferença de 14.8944%.
Esta observação mostra que independente da quantidade de instâncias, ao utilizar 100 sementes randômicas, Random Forests apresenta variabilidade nos seus resultados.
A observação sobre as bases de dados B13 e B17 verifica o comportamento do Random Forests quando a base de dados possui um bom balanceamento em relação a a seleção de 100 sementes randômicas.
A base de dados B13 possui duas classes, 303 instâncias e um ótimo balanceamento de 0.0080.
O resultado para esta base de dados foi de 88.1720% utilizando a semente Default e de 88.3393% para a utilização de 100 sementes.
A base de dados B17 possui duas classes, 3196 instâncias e um balanceamento de 0.0020.
O resultado para esta base de dados foi de 99.1667% para a semente Default e de 99.2430% utilizando 100 sementes randômicas.
Esta última observação mostra que para estes dois casos, o balanceamento da base de dados e a utilização de 100 sementes randômicas não causou instabilidade no algoritmo.
O desvio padrão encontrado em foi de 0.5% para Bagging e 0.75% para Boosting.
A comparação destes resultados mostra uma vantagem para Bagging de 0.25%.
Calculamos o desvio padrão para Random Forests utilizando o resultado do nosso experimento e o valor encontrado foi de 2.1833%.
Comparamos o resultado do Random Forests com relação a os de Bagging e Boosting, e os resultados encontrados mostram uma vantagem de 1.6833% para Bagging e 1.4333% para Boosting.
Outro ponto observado foi a média da distância, que representa a distância entre o maior e o menor valor de classificação para uma mesma base de dados.
O valor encontrado para Random Forests foi de 7.9978%, o que mostra que dependendo da semente, são gerados valores muito distantes do desvio padrão.
Para Bagging, encontramos 1.9259%, e 2.9167% para Boosting.
Estes resultados proporcionam uma ampla vantagem de 6.0719% em favor de Bagging e de 5.0808% em favor de Boosting.
A Tabela 3.3 exibe 9 casos em os quais a distância entre o valor mínimo e o valor máximo é maior a 10.00%.
Estes exemplos nos mostram que o efeito da aleatoriedade causa variabilidade nos resultados do Random Forests.
A outra comparação realizada refere- se aos valores de distância citados anteriormente.
Foram analisados valores encontrados de entre todas as bases de dados, não necessariamente os mais altos.
A primeira observação realizada sore o Random Forests foi uma comparação entre o comportamento do algoritmo utilizando a semente Default e a seleção randômica da semente.
Encontramos uma diferença que chegou a ultrapassar os 10% utilizando as duas configurações possíveis do experimento.
Observamos que ao aumentar o número de classificadores, a diferença diminuiu.
Considerando a margem 2% citada anetriormente, encontramos um comportamento instável do Random Forests em comparação a Bagging e Boosting, conforme descrevemos anteriormente.
Utilizando a semente Default, observamos que Random Forests foi superior em 20/90 dos casos, Bagging 14/90 e Boosting 10/90, o que nos indica uma superioridade do Random Forests quando utilizada apenas uma semente.
Quando observado o comportamento do Random Forests utilizando a seleção randô-mica da semente, encontramos o seguinte resultado:
Boosting foi melhor em 12/90 casos, Bagging em 10/90 e Random Forests em 16/90.
O resultado da observação anterior nos mostra que a seleção randômica da semente causa instabilidade no algoritmo.
Este resultado pode ser confirmado quando comparamos o desvio padrão do resultado da classificação e a distância em comparação com os dos demais algoritmos.
Os resultados das observações apresentadas acima nos mostram que o Random Forests possui um bom rendimento utilizando a semente Default.
Quando analisamos o algoritmo com relação a seleção randômica da semente, notamos instabilidade no seu comportamento.
Esta instabilidade causou uma grande variação nos percentuais de média de acerto, refletindo por consequência no valor de desvio padrão e na distância.
Visando explorar a sensibilidade detectada no Random Forests, este trabalho propõe a implementação e análise do método Random Forests Estocástico, a fim de tentar superar o problema da aleatoriedade.
O presente capítulo apresenta o desenvolvimento e experimentação do Random Forests Estocástico.
Em a Seção 4.1, o seu funcionamento é descrito, assim como a estratégia para superar o problema causado por a aleatoriedade.
A seção 4.2 descreve o experimento realizado para analisar a precisão do Random Forests Estocástico.
A Seção 4.3 apresenta um estudo sobre os resultados experimentais.
Procurando alcançar um espectro maior na análise dos resultados, estes são observados por aspectos diferentes.
Para tanto, serão comparados os resultados do Random Forests Estocástico, do Random Forests, de Bagging e de Boosting.
Por fim, comparações quantitativas serão feitas considerando características das bases de dados.
Método Random Forests Estocástico Apoiados por a literatura investigada na Seção 2.4, e por os resultados encontrados nos experimentos da Seção 3.2, apresentaremos a nossa proposta.
Esta tem como objetivo melhorar a precisão e diminuir a variabilidade dos resultados do método Random Forests quando este é submetido à aleatoriedade.
Desenvolvimento do método Propomos implementar uma extensão do Random Forests, o qual chamamos de Random Forests Estocástico.
Destacamos que a nossa implementação não realizou nenhuma alteração no funcionamento básico do Random Forests.
Não foi feita nenhuma alteração no processo de construção do modelo, o qual será igual ao apresentado na Figura 2.5.
Funcionalidades como seleção de características, geração aleatória dos vetores, cálculo do valor limite do erro de generalização, não execução de poda não foram modificadas.
O Random Forests Estocástico adiciona um novo método o qual implementa a classificação estocástica, servindo esta como resultado da classificação.
A Figura estocástica, ao invés de retornar um único voto, como o fazem os conjuntos de classificadores, retorna uma matriz de probabilidades.
As informações providas como resultado da classificação são a classe votada, percentual de votos e a quantidade de votos.
As informações citadas anteriormente são retornadas para cada elemento do conjunto de resultados.
O percentual de votos é calculado utilizando a quantidade de votos que esta classe obteve sobre o total de classificadores da floresta.
A Fórmula 4.1 é utilizada para calcular o percentual de votos e conta com os seguintes elementos:
P é o percentual resultante de uma classe x, e é calculado multiplicando- se v que é a quantidade de votos da classe, por cem.
O resultado desta operação é dividido por T, que é o numero de árvores da floresta.
O pseudocódigo do método, é apresentado no Algoritmo 4.1.
Para um melhor entendimento do funcionamento do Random Forests Estocástico descreveremos o mesmo a seguir.
Em a linha 2 é classificada a instância I, armazenando o resultado em D. O código executado desde a linha 4 até a linha 11 verifica se a classe votada encontra- se dentro de a matriz de resultados, e computa mais um voto caso verdadeiro.
O percentual de votos da classe em questão é atualizado.
Em a linha 12 verifica- se se a classe votada foi localizada na matriz de resultados.
Caso não tenha sido encontrada, será adicionada uma nova posição na matriz de resultados.
Um voto será computado e o percentual de votos é atualizado para a classe em questão.
Como podemos observar nas linhas 8 e 16, a Fórmula 4.1 é utilizada para calcular o percentual de votos para a classe em questão.
Finalmente, na linha 19, o resultado de classificação estocástica é retornado.
O código fonte do Random Forests Estocástico está disponível em formato digital na biblioteca da Pontifícia Universidade Católica do Rio Grande do Sul.
Algoritmo 4.1: Algoritmo do método de classificação do Random Forests Estocástico.
1: For all (i M C) do for all (j M R) do F $= true M R (j).
V otes+ M R (j).
P ercent $= (M R (j).
V otes 100)/ M C. Lenght) M R. Insert M R. Class $= D M R. V otes $= 1 M R. P ercent $ .
V otes 100)/ M C. Lenght) Diminuindo a variabilidade dos resultados A chave para diminuir a variabilidade dos resultados causada por a aleatoriedade consistem em combinar diferentes resultados de classificação do Random Forests Estocástico.
Estas séries de classificações devem ser executadas utilizando diferentes configurações de sementes, em todos os casos.
Estes resultados são combinados, e a classe mais votada de entre todos os resultados é selecionada como resultado da classificação.
Combinar os resultados é agrupar o resultado de cada classificação estocástica num único resultado.
O campo agrupador é o Class e o campo Percent é utilizado para compor a soma.
A seguir apresentaremos um exemplo de como o problema de sensibilidade é solucionado.
Suponha uma instância I de um determinado conjunto de teste T, onde o rótulo da classe esperado para esta instância seja A. Suponha um determinado conjunto de treinamento R e suponha também que um grupo de quatro conjuntos de classificadores em os quais a semente foi configurada com os valores 5, 10, 15 e 20 respectivamente em cada um, tenham sido construídos utilizando o conjunto de treinamento citado anteriormente.
Em seguida a instância I é classificada sobre cada um dos modelos criados.
Por causa de a variação da semente a precisão foi afetada e a classe A foi selecionada apenas quando a semente foi configurada com o valor 15, o que representa 25% de acerto para este pacote de sementes.
Observamos que no conjunto de 5, 10 e 20 sementes, a classe A recebeu no mínimo 10% e no máximo 30% dos votos.
Quando observado o resultado para a semente com o valor 15, em a qual a classificação foi efetiva, a classe A recebeu 100% dos votos como esperado.
Combinando os resultados do pacote de 5, 10, 15 e 20 sementes computamos o seguinte resultado que pode ser observado na coluna total:
160/400% dos votos para a classe A, 90/400% para a classe B e 150/400% para a classe C. Como a classe A foi a mais votada sobre todos os resultados está será selecionada como resultado da votação deste pacote de sementes.
Este exemplo nos mostra como o problema da sensibilidade pode ser solucionado combinando uma série de resultados.
Em a próxima seção executaremos um experimento utilizando o Random Forests Estocástico.
O experimento será executado nos moldes do experimento realizado com o Random Forests apresentado anteriormente, na seção 3.1.
Estudaremos o comportamento do Random Forests Estocástico quando submetido à aleatoriedade e compararemos estes resultados com os do Random Forests.
Definição do experimento utilizando aleatoriedade Para estudar o comportamento do Random Forests Estocástico, planejamos e executamos um novo experimento, que será apresentado a seguir.
Especificamos o experimento atual com base no experimento da Seção 3.1.
Para adaptar o experimento ao nosso método algumas características do experimento foram alteradas.
Para a construção dos modelos e execução dos testes, utilizamos as mesmas bases de dados utilizadas no experimento da Seção 3.1.
A classificação foi executada utilizando a técnica de tenfolds stratified cross-validation.
Utilizando uma quantidade de classificadores C e um número de sementes S, que varia dependendo do pacote de sementes.
Cada base de dados foi classificada utilizando 10, 30 e 50 classificadores.
Em o experimento com Random Forests foram utilizadas 100 configurações de sementes, variando de 1 até 100.
Em o presente experimento utilizaremos 100 pacotes compostos de 10 sementes cada.
Os resultados da classificação das 10 sementes de cada pacote serão combinados formando um único resultado.
Os pacotes de sementes serão compostos por Por uma questão estatística foram removidos os 5 maiores e os 5 menores resultados de cada base de dados.
Com isso tratamos de evitar que resultados distantes causem uma variação muito grande na hora de calcular a média de acerto.
Os resultados do experimento podem ser observados na tabela 4.3.
Estes servirão como base para análise e posterior comparação com os resultados obtidos no experimento do Random Forests.
O código fonte e os dados resultantes do experimento aqui apresentado estão disponíveis em formato digital na biblioteca da Pontifícia Universidade Católica do Rio Grande do Sul.
Em a próxima seção apresentaremos os resultados do experimento aqui descrito.
Em a presente seção analisaremos o comportamento do Random Forests Estocástico utilizando como base o resultado do experimento da Seção 4.2, que pode ser observado na Tabela 4.3.
O estudo analisa os resultados por diferentes aspectos, comprando os resultados do Random Forests Estocástico com os obtidos no experimento utilizando Random Forests.
Em a sequência, compararemos estes resultados com os de Bagging e Boosting.
Analisaremos os resultados subdividindo as bases de dados, utilizando como critério a quantidade de instâncias.
Outro critério de subdivisão para análise será o desbalanceamento das bases de dados.
Por último, estudaremos casos onde comportamentos excepcionais foram identificados.
Observando os resultados da Tabela 4.4, a qual consolida o resultado do experimento para 10, 30 e 50 classificadores, identificamos que o resultado da distância foi diminuído consideravelmente em favor de o Random Forests Estocástico com relação a o Random Forests.
A distância para o Random Forests foi de 7.9978% e o do Random Forests Estocástico de 3.8363%, o que representa uma diferença de 4.1613%.
Para o desvio padrão também encontramos uma diferença significativa:
1.4072% em favor de o Random Forests.
A diferença encontrada é inferior a 2%, margem que utilizamos para considerar que um algoritmo é melhor do que o outro.
Como podemos observar na Tabela 4.5, em nenhum dos três casos, a diferença na média de acerto superou os 2%.
Utilizando 10 classificadores, a média de acerto para o Random Forests foi de 77.1359% e de 76.045% para o Random Forests Estocástico, o que resulta numa diferença de 1.0945%.
Utilizando 30 classificadores, o resultado foi de 77.7869% para o Random Forests e 76.3734% para o Random Forests Estocástico o que resulta numa diferença de Observamos que apesar de a queda no percentual de média de acerto do Randon Forests Estocástico esta não é suficiente para considerar este menos preciso que o Random Forests, se considerada a margem de 2%.
Anteriormente mostramos que a diferença média entre a distância foi de 4.1613% a menos em favor de o Random Forests Estocástico com relação a o Random Forests.
Esta diferença nos permite afirmar que o Random Forests Estocástico para as bases de dados utilizadas nos experimento gerou valores mais próximos, mostrando que é menos sensível ao efeito causado por a seleção randômica da semente, problema encontrado no Random Forests.
Analisando os resultados individualmente por a quantidade de classificadores utilizados (podem ser observados na Tabela 4.5), notamos que com 10 classificadores a distância foi de 5.8210% para o Random Forests Estocástico e de 10.0457% para o Random Forests, o que resulta numa diferença de 4.2247% a menos em favor de o Random Forests Estocástico.
Quando utilizados 30 classificadores, o valor foi de 3.7857% para o Random Forests Estocástico e de 7.4487% para o Random Forests, resultando numa diferença de 3.6630% a menos em favor de o Random Forests Estocástico.
Finalmente, para 50 classificadores, o valor do Random Forests Estocástico foi de em favor de o Random Forests Estocástico.
A análise acima nos mostrou melhoria na estabilidade do Random Forests Estocástico, obtendo resultados mais próximos da média de acerto.
Os valores de desvio padrão para 10 classificadores foram de 1.5978% para o Random Forests Estocástico e de 2.6949% para o Random Forests, o que resultou numa diferença de 1.0971% em favor de o Random Forests Estocástico.
Utilizando 30 classificadores, o desvio padrão foi de numa vantagem de 1.1498% em favor de o Random Forests Estocástico.
Finalmente, utilizando 50 classificadores, o desvio padrão para o Random Forests Estocástico foi de 0.6553% e para o Random Forests foi de 1.8015%, resultando numa diferença de 1.1462% em favor de o Random Forests Estocástico.
Observamos que quando o número de classificadores aumentou de 10 para 30, a diferença entre o desvio padrão do Random Forests Estocástico e do Random Forests aumenta mais do que quando incrementado o número de classificadores de 30 para 50, onde este valor se manteve um pouco mais próximo.
Esta observação nos mostra que em todas as diferentes configurações de classificadores, o Random Forests Estocástico obteve resultados significativos no desvio padrão se comparado com o Random Forests.
4.3.2 Análise comparativa:
Random Forests Estocastico versus Random Forests com relação a Bagging e Boosting A próxima avaliação analisa o comportamento do Random Forests Estocástico e do Random Forests em relação a Bagging e Boosting.
Para tanto, observaremos as Tabelas 4.4, que possui os resultados consolidados para 10, 30 e 50 classificadores, e 4.5, que apresenta os resultados separados por o número de classificadores.
Identificamos anteriormente que quando observada a média de acerto, o Random Forests Estocástico obteve resultados menos performáticos que o Random Forests.
Se comparado com Boosting, que obteve uma média de acerto de 79.3448%, o Random Forests obteve 77.6436%, o que resultou numa diferença de 1.6985%.
Quando comparamos Boosting com o Random Forests Estocástico, o último obteve uma média de acerto de 76.2364%, resultando numa diferença de 3.1084%.
Quando comparado com Bagging, que obteve um percentual de acerto médio de 80.1165%, observamos que a diferença de média de acerto em comparação ao Random Forests foi de 2.4729%, e a diferença com relação a o Random Forests Estocástico foi de 3.8801%.
Notamos que os resultados observados do Random Forests Estocástico são menos eficientes quando comparados com os resultados de Bagging e Boosting, enquanto que se comparados os resultados de Random Forests com os de Bagging e Boosting, obteve- se resultados mais próximos.
Identificamos anteriormente uma diferença considerável no valor da distância em favor de o Random Forests Estocástico em comparação com o Random Forests.
Em comparação aos de Bagging e Boosting, a distância para o Random Forests Estocástico foi de 3.8363%, o que resultou numa diferença de 1.91045% em comparação ao Bagging, que obteve uma distância de 1.9259%.
Diferença esta menor que a diferença de 6.0719%, encontrada com relação a Random Forests, que obteve uma distância de 7.9978%.
Comparando estes resultados com Boosting, que obteve uma distância de 2.9170%, encontramos uma pequena diferença de 0.9193% a menos em favor deste com relação a o Random Forests Estocástico.
Esta mesma comparação feita para o Random Forests resultou numa vantagem de 5.8008% em favor de Boosting.
Observando a Tabela 4.4, identificamos que o desvio padrão para Bagging foi de 0.5000% e de observamos o resultado do Random Forests Estocástico, encontramos 1.0532% de desvio padrão, o que resulta numa diferença menor com relação a a Bagging e Boosting quando comparado com Random Forests.
Esta análise considerou três variáveis (média de acerto, distância e desvio padrão) para comparar os resultados do Random Forests Estocástico e Random Forests.
Inicialmente, comparamos os dois algoritmos, e num segundo momento comparamos os resultados destes com os resultados de Bagging e Boosting.
Identificamos uma pequena desvantagem do Random Forests Estocástico na média de acerto com relação a o Random Forests, e uma significativa vantagem com relação a a distância e ao desvio padrão.
A seguir, analisamos os resultados contabilizando os casos em os quais um algoritmo foi mais performático que o outro.
Observando o resultado do experimento por outra perspectiva, analisaremos o número de vezes que o Random Forests Estocástico foi superior ao Random Forests, e vice-versa.
Comparando os resultado de todas as bases de dados e considerando a margem de 2% utilizada anteriormente em outras observações, identificamos que na média de acerto o Random Forests foi superior em 12/90 casos, enquanto que o Random Forests Estocástico foi em 8/90.
Observando o desvio padrão, o Random Forests Estocástico foi melhor em 16/90 casos e o Random Forests em 0/90.
Por último, para a distância, contabilizamos que o Random Forests Estocástico foi melhor em 44/90 casos e o Random Forests em 0/90.
Em relação a o número de classificadores, utilizando 10 classificadores, encontramos que na média de acerto o Random Forests foi melhor em 4/30 casos, e o Random Forests Estocástico em 2/30.
O resultado do desvio padrão indicou que o Random Forests Estocástico foi melhor em 5/30 casos e o Random Forests em 0/30.
Em a distância, o Random Forests Estocástico foi melhor em 16/30 casos contra 0/30 do oponente.
Classificando com 30 classificadores, o Random Forests foi melhor em 4/30, e o Random Forests Estocástico em 3/30 dos casos para a média de acerto.
Em o desvio padrão, o Random Forests Estocástico foi melhor em 6/30 casos e o Random Forests 0/30.
Em a distância, o Random Forests Estocástico foi melhor em 14/30 casos e o Random Forests em 0/30.
Finalmente, utilizando 50 classificadores, notamos que a média de acerto do Random Forests foi melhor em 4/30 casos e o Random Forests Estocástico em 3/30.
O resultado para o desvio padrão mostra que o Random Forests Estocástico foi melhor em 5/30, e o Random Forests em 0/30.
O resultado da distância para 50 classificadores mostra que o Random Forests Estocástico foi melhor em 14/30 resultados e o Random Forests em 0/30.
Quando analisado o resultado da distância e do desvio padrão para estas bases de dados, concluimos que o Random Forests Estocástico é consideravelmente menos sensível que o Random Forests.
Apesar de o Random Forests Estocástico estar dentro de a margem de 2% em 70/90 casos na média de acerto, para esta medida o Random Forests obteve vantagem.
Analisando separadamente por o número de classificadores, notamos um comportamento parecido para as três configurações, sendo que o Random Forests foi levemente mais preciso na média de acerto.
Analisando o desvio padrão e a distância, notamos uma ampla vantagem em favor de o Random Forests Estocástico, comprovando que este é mais estável que o Random Forests.
A próxima comparação de resultado será nos moldes da apresentada aqui, porém não levaremos em conta a margem de 2%.
Diferentemente da desvantagem encontrada no percentual de média de acerto do Random Forests Estocástico, apresentada na análise da Subseção 4.3.3, nos resultados que apresentaremos a seguir encontraremos vantagens a favor.
Observando a média de acerto, contabilizamos que o Random Forests Estocástico foi melhor em 48/90 casos, enquanto que e o Random Forests foi melhor em 32/90.
Contrário ao resultado apresentado aqui, a Tabela 4.4 mostra desvantagem na média do Random Forests Estocástico, fato causado por o baixo desempenho em algumas bases de dados.
Para uma melhor visualização e entendimento do resultado apresentado nesta subseção, os gráficos exibidos nas Figuras 4.2, 4.3 e 4.4 servem como auxílio.
Continuando com o nosso estudo, encontramos que a diferença do desvio padrão aumentou, sendo o Random Forests Estocástico melhor em 80/90 casos e o Random Forests em 0/90.
Em a contabilização da distância, notamos que o Random Forests Estocástico foi superior em 69/90 casos e o Random Forests em 2/90.
Identificamos, para este caso, que à medida que o número de classificadores aumentou, a diferença na contabilização dos resultados do percentual de acerto diminuiu.
Por exemplo, comparando o percentual de media de acerto para 10 classificadores o Random Forests Estocástico foi melhor em 22/30 casos e o Random Forests em 7/30.
Utilizando 30 classificadores, o Random Forests Estocástico foi melhor em 14/30 casos e o Random Forests em 12/30, e finalmente, para 50 classificadores, o Random Forests foi melhor em 13/90 casos e o Random Forests Estocástico em 12/30.
Analisando o desvio padrão e distância, considerando o número de classificadores, encontramos uma ampla vantagem em favor de o Random Forests Estocástico.
Observando o desvio padrão e utilizando 10 classificadores o Random Forests Estocástico foi melhor em 20/30 casos e o Random Forests em 0/30.
Utilizando 30 classificadores, o primeiro foi melhor em 26/30 casos e o segundo em 0/30.
Finalmente para 50 classificadores, o Random Forests Estocástico foi melhor em 25/30 casos e o Random Forests em 0/30 casos.
Comparando a distância, o Random Forests Estocástico foi melhor em todos os casos.
Utilizando 10 classificadores, o Random Forests Estocástico foi melhor em 26/30 casos contra 0/30 do oponente.
Utilizando 30 classificadores, o Random Forests Estocástico foi melhor em 20/30, casos contra 1/30 do Random Forests.
Utilizando 50 classificadores, o primeiro foi melhor em 23/30 casos e o segundo se manteve com 1/30 dos casos.
Estocástico versus Random Forests utilizando 10 classificadores.
Esta análise mostra que apesar de a desvantagem do Random Forests Estocástico na média de acerto e quando considerado o percentual de 2%, no geral, este obteve um melhor rendimento.
Estocástico versus Random Forests utilizando 50 classificadores.
Comparações, assim como os resultados de desvio padrão e distância.
Em a próxima seção observaremos os resultados experimentais que contemplam desde aspectos como desbalanceamento e quantidade de instâncias por base de dados.
Buscamos com isto identificar se alguma destas características exerce alguma influência sobre os resultados.
O objetivo da análise seguinte é comparar o comportamento dos algoritmos considerando a quantidade de instâncias e o desbalanceamento.
Esta comparação será elaborada separadamente.
Para comparar os resultados por a quantidade de instâncias e por o desbalanceamento, separamos as bases de dados em três grupos para cada observação:·
Grupos de bases de dados para comparar por o desbalanceamento:
­ Grupo A:
Desbalanceamento de 0.0001 até 0.0999.·
Grupos de bases de dados para comparação por o número de instâncias:
­ Grupo D:
De 1 até 300 instâncias.
Desbalanceamento A análise foi elaborada sobre o resultado geral e sobre o resultado individual, considerando o número de classificadores.
Analisando o resultado geral das bases de dados do Grupo A, encontramos que tanto para o percentual de acerto, como para desvio padrão e distância, o Random Forests Estocástico foi melhor em todos os casos.
Comparando a média de acerto do Random Forests Estocástico, esta foi de 79.6299%, e para o Random Forests de 78.5149%.
A distância encontrada foi de 4.0602% para o primeiro e 7.4724% para o segundo.
Apesar de a diferença de 3.4122% encontrada na distância, a diferença do desvio padrão não foi tão alta.
O desvio padrão do Random Forests Estocástico foi de 1.1523%, enquanto que o do e do Random Forests foi de 1.9100%.
Observando individualmente por o número de classificadores, encontramos o seguinte resultado.
Utilizando 10 classificadores, o Random Forests Estocástico foi melhor que o Random Forests na média de acerto, com 79.3400% contra 77.7173%, na distância foi de 5.5443% contra 8.7999%, e no desvio padrão foi de 1.5651% contra 2.2363%.
Quando utilizados 30 classificadores, o Random Forests Estocástico manteve a vantagem em todos os resultados, com 79.7271% contra 78.7594% de percentual de acerto, o resultado da distância foi de 4.2070% contra 7.1739%, e o desvio padrão de 1.0395% contra 1.8290%.
Utilizando 50 classificadores para este conjunto de bases de dados, o resultado encontrado manteve- se parecido com os encontrados aqui anteriormente.
A média de acerto para o Random Forests Estocástico foi de 79.8224% contra 79.0680%, a distância foi de primeiro contra 1.6646% do segundo.
Para este conjunto de bases de dados, encontramos uma diferença não muito significativa em favor de o Random Forests Estocástico no percentual de média de acerto e no desvio padrão.
Observando a distância encontramos uma diferença um pouco maior de 3.4121%.
O resultado encontrado no Grupo A não se confirma no Grupo B, como mostraremos a seguir.
Encontramos uma queda considerável na média de acerto e na distância entre elas.
O Random Forests Estocástico obteve uma média de acerto de 57.3096%, e o Random Forests de 62.9061%.
Observando individualmente o resultados das bases de dados do Grupo B, encontramos duas diferenças consideráveis que causaram esta vantagem em favor de o Random Forests.
Para a base de dados B32, a média de acerto do Random Forests foi de 85.8249% e para o Random Forests Estocástico de 77.7442%.
Já para a base de dados B31 a média de acerto para o primeiro foi de 49.3463%, e para o segundo 32.3117%.
Verificando as características das bases de dados B31 e B32 notamos que a diferença entre o desbalanceamento de ambas não é grande, já que o da primeira é de 0.1370 e o da segunda 0.1140.
Para os demais resultados deste grupo encontramos um comportamento similar ao do Grupo A. O Random Forests Estocástico obteve uma média de 6.4252% de distância, e o Random Forests de 12.5900%.
O primeiro obteve um desvio padrão de 1.6448%, e o segundo de 3.5610%.
Este último resultado mostra que o comportamento sobre estes resultados se manteve tanto para o Grupo A como para o Grupo B. Os resultados encontrados individualmente para os distintos conjuntos de classificadores mostram um resultado igual ao resultado geral, em o qual o Random Forests obteve vantagem no percentual de média de acerto e o Random Forests Estocástico obteve vantagem na distância e desvio padrão.
Quando 10 classificadores foram utilizados, o Random Forests obteve Estocástico obteve vantagem na distância, com 9.8867% contra 16.2474%, e no desvio padrão com O mesmo comportamento encontramos para 30 classificadores.
O Random Forests obteve uma média de acerto de 63.0544% contra 57.6224% do Random Forests Estocástico.
A distância do Random Forests Estocástico foi de 6.9296% contra 11.7424%, e o desvio padrão foi de 1.4978% contra 3.3552% do Random Forests.
Finalmente, utilizando 50 classificadores encontramos uma vantagem em favor de o Random Forests no percentual de média de acerto, de 63.1945% contra com 2.4295% contra 9.7893%, e no desvio padrão, com 0.8788% contra 2.8523%.
Os resultados observados no Grupo B nos mostram que a vantagem em favor de o Random Forests Estocástico se manteve na distância e no desvio padrão, porém encontramos uma vantagem considerável em favor de o Random Forests no percentual de média de acerto.
Analisando detalhadamente o resultado de cada base de dados, percebemos que ao classificar as bases B31 e B32 o Random Forests Estocástico foi notoriamente menos preciso que o Random Forests.
Este resultado exerceu um peso grande no resultado final do grupo na média de acerto.
Os resultados encontrados para o Grupo C mostram um comportamento similar ao do Grupo A. A única diferença, neste caso, é uma leve vantagem em favor de o Random Forests no percentual de média de acerto.
A média de acerto, considerando as três configurações do Random Forests Estocástico, foi de 86.6082%, e para o Random Forests, de 87.4903%.
A distância para o primeiro foi de Forests Estocástico, e de 1.4548% para o Random Forests.
Observando individualmente por o número de classificadores utilizados, encontramos, como em casos anteriores, o mesmo comportamento, em o qual o Random Forests foi melhor no percentual de média de acerto, e o Random Forests Estocástico no desvio padrão e na distância.
Classificando com um conjunto de 10 classificadores, o Random Forests obteve uma média de acerto de 87.2237% contra 86.5067% do Random Forests Estocástico.
A distância foi favorável ao Random Forests Estocástico, com 3.1410% contra 6.7810%, assim como o desvio padrão, com 0.9323% contra 1.8585% do Random Forests.
O mesmo observamos para 30 classificadores.
Random Forests obteve uma média de acerto de 87.5290% contra 86.6569%.
Em a distância, o Random Forests Estocástico obteve um melhor resultado, com 1.0781% contra utilizando 50 classificadores, na média de acerto o Random Forests foi melhor com 87.7183% contra contra 1.7428%.
Em o Grupo C notamos um comportamento parecido com o do Grupo A porém com uma notória queda no desvio padrão e na distância, além de perceber um aumento no percentual de média de acerto.
Analisando o resultado desta observação e considerando o desbalanceamento das bases de dados, percebemos um comportamento padrão:
À medida que aumentamos o número de classificadores durante o experimento, o percentual de desvio padrão e da distância diminuíram.
Em alguns casos, como o do Grupo C, a distância do desvio padrão entre o Random Forests Estocástico e o Random Forests também aumentou à medida que os classificadores aumentaram.
Excepcionalmente no Grupo A, identificamos que o Random Forests Estocástico foi levemente superior que o Random Forests na média de acerto, o que não ocorre nos demais grupos.
Em a distância e no desvio padrão, o Random Forests Estocástico foi melhor em todos os casos.
Especificamente no Grupo B, encontramos uma queda significativa no percentual de média de acerto.
Investigamos a possível causa e identificamos que para as bases de dados B31 e B32, o resultado do Random Forests Estocástico é consideravelmente inferior ao do Random Forests.
Este resultado não nos permite deduzir que o desbalanceamento tem influência no resultado por dois motivos.
O primeiro é que para as demais bases de dados do grupo as médias de acerto são similares com as demais médias de acerto do experimento, estando estas próximas.
O segundo é que no resultado do Grupo C, em o qual o desbalanceamento é maior, encontramos um comportamento similar ao do Grupo A, o que mostra que esta característica não tem influência direta sobre os resultados.
Identificamos, no caso de o Grupo B, que a média de acerto foi inferior à 22.3203% com relação a o Grupo A, e 29.2986% com relação a o Grupo C. Finalmente, notamos uma diferença importante entre o Grupo A e o Grupo C:
Estes grupos não foram afetados por nenhum comportamento excepcional, e identificamos que em todos os casos para 10, 30 e 50 classificadores no Grupo C, em o qual o desbalanceamento foi mais alto, obteve- se uma melhor média de acerto, e distância e desvio padrão menores.
Este resultado mostra que o desbalanceamento para estes casos não é uma característica que pode afetar o resultado da classificação.
Destacamos que a afirmação anterior é válida para as bases de dados apresentadas na Tabela 3.1.
Número de instâncias Esta nova análise observa os resultados dividindo as bases de dados por o número de instâncias.
Uma nova observação será realizada sobre o resultado de cada grupo.
O resultado médio do conjunto de bases de dados Grupo D nos mostra um resultado que se confirma na maioria das observações.
O Random Forest é melhor no percentual de média de acerto com 77.7561% contra 76.5373% do Random Forests Estocástico.
O desvio padrão do Random Forests Estocástico foi de 1.9436% e do Random Forests de 3.5970%.
Já a distância do primeiro foi de 7.0477% e do segundo 12.6529%.
Os resultados individuais para cada conjunto de classificadores mostram o mesmo comportamento que o resultado geral.
Utilizando 10 classificadores o Random Forests obteve uma média de acerto de 77.2668% contra 76.1487% do Random Forests Estocástico.
O desvio padrão do Random Forests Estocástico foi de 2.8339% contra 4.2924%.
Já a distância do primeiro foi de 10.5087% contra 15.5160% do segundo.
Para 30 classificadores a vantagem em favor de o Random Forests no percentual de acerto foi mantida, com 77.8879% contra 77.8802%.
Este número de classificadores nos mostra uma vantagem no desvio padrão em favor de o Random Forests Estocástico, de 1.6604% contra 3.4238%, mantendo a distância com 6.9767% contra 11.8323%.
Finalmente, utilizando 50 classificadores, notamos uma distância levemente superior em favor de o Random Forests no percentual de média de acerto, com 78.1136% contra 76.5832% do Random Forests Estocástico.
O desvio padrão do Random Forests Estocástico foi melhor com 1.3367% contra 3.0759% do Random Forests, e a distância no caso foi de 3.6578% para o primeiro e de 10.6105% para o segundo.
Para o Grupo E encontramos um comportamento similar ao encontrado no Grupo D:
O Random Forests Estocástico foi melhor na distância e desvio padrão e o Random Forests na média de acerto.
A média de acerto do Random Forests foi de 75.0430% contra 73.7717% do Random Forests Estocástico.
O desvio padrão do Random Forests Estocástico foi de 0.7386% contra 1.6702% do Random Forests, e a distância do primeiro foi de 2.6127% contra 6.6451% do segundo.
Individualmente para cada conjunto de classificadores o comportamento foi igual ao resultado geral, não ocorrendo nenhuma exceção neste caso.
Com 10 classificadores, o Random Forests obteve vantagem na média de acerto, com 74.5327% contra 73.6539% do Random Forests Estocástico.
O desvio padrão do Random Forests Estocástico foi melhor, com 1.3083% contra 2.2188% do Random Forests, a distância do primeiro foi melhor, com 4.2968% contra 8.6660%.
Observando o resultado para 30 classificadores a vantagem na média de acerto em favor de o Random Forests foi de 75.1668% contra último, utilizando 50 classificadores, o Random Forests obteve uma média de acerto de 75.4295% contra 73.8765%.
O desvio padrão do Random Forests Estocástico foi de 0.3028% contra 1.2717% do Random Forests e a distância do primeiro foi de 0.9705% e do segundo 4.9674%.
Em o Grupo F, agrupando os resultados de todos os conjuntos de classificadores, o Random Forests obteve uma média de acerto de 80.3955% contra 78.6076% do Random Forests.
Observando o desvio padrão encontramos que o Random Forests Estocástico foi melhor, com 0.3116% contra cada grupo de classificadores, notamos o mesmo resultado, em o qual o Random Forests foi melhor na média de acerto e o Random Forests Estocástico na distância e desvio padrão.
Utilizando 10 classificadores, o Random Forests obteve uma média de acerto de 79.8681% contra 78.5753% do Random Forests Estocástico.
Em o desvio padrão, o Random Forests Estocástico obteve 0.4090% contra 1.2727% do Random Forests.
A distância do Random Forests Estocástico foi de 1.7855% contra 4.8927% do Random Forests.
Com 30 classificadores, o Random Forests obteve uma média de acerto de 80.5749% contra 78.6308% do Random Forests Estocástico.
Para o desvio padrão, o Random Forests Estocástico manteve a vantagem, com 0.3113% contra 0.9715% do Random Forests.
O primeiro também manteve a vantagem na distância, com 1.2354% contra 3.3652% do segundo.
Finalmente, utilizando 50 classificadores, a média de acerto do Random Forests foi melhor, com 80.7436% contra 78.6168% do Random Forests Estocástico.
Por último, o desvio padrão do Random Forests Estocástico foi de 0.2143% contra 0.8328%, e a distância do primeiro foi de 0.7922% contra 3.1762% do segundo.
Notamos que o número de instâncias não é uma característica que afeta o desempenho e a estabilidade do Random Forests Estocástico.
Esta afirmação se apoia na seguinte observação:
O Grupo F é o que possui as bases de dados com o maior número de instâncias, e obteve a melhor média de acerto, distância e desvio padrão quando comparando com o resultado dos demais grupos de bases de dados.
Notamos também que o número de instâncias não tem efeito sobre a relação de média de acerto, distância e desvio padrão, já que no Grupo D a média de acerto foi maior que a do Grupo E o que não acontece com a distância e desvio padrão, que são menores no Grupo E. Quando comparamos o resultado do Random Forests Estocástico com o do Random Forests, notamos no resultado geral o mesmo comportamento em todos os grupos e casos.
O Random Forests é melhor no percentual de média de acerto, e o Random Forests Estocástico na distância e desvio padrão.
Analisando os resultados mais especificamente, não identificamos nenhum comportamento excepcional, o que mostra que o número de instâncias não influência na estabilidade do algoritmo.
Identificamos, nas análises anteriores uma mesma tendência em favor de o Random Forests Estocástico nos resultados da distância e desvio padrão, e uma pequena vantagem em favor de o Random Forests no percentual de média de acerto.
Aqui a nossa análise é focada sobre resultados individuais de cada base de dados, em os quais um resultado excepcional seja identificado.
Separamos vinte e três resultados identificados sobre os resultados do experimento:
Oito referentes à percentual de média de acerto, quatro sobre desvio padrão e onze referentes à distância.
Para selecionar os resultados utilizamos o seguinte critério:·
Percentual de média de acerto:
Diferença maior ou igual a 9% entre os classificadores.·
Desvio padrão: Diferença maior ou igual a 5%.·
Distância: Diferença maior ou igual a 9%.
Observando o percentual de média de acerto, identificamos comportamentos excepcionais para as bases de dados B10, B20 e B31.
Todos os resultados identificados aqui para o percentual de média de acerto são em favor de o Random Forests.
Para a base de dados B10, encontramos dois resultados significativos:
Utilizando 30 classificadores, a média de acerto do Random Forests foi de 66.0784% contra 44.6405% do Random Forests Estocástico, resultando numa diferença de 21.4379%:
Utilizando 50 classificadores, o primeiro obteve uma média de acerto de 65.7190% contra 44.1176% do segundo, resultando numa diferença de 21.6014%.
Para a base de dados B20 encontramos significativa diferença nas três configurações.
Utilizando 10 classificadores o percentual de acerto do Random Forests foi de 55.4321% contra 45.9259%, resultando numa diferença de 11.3581%;
Por último, utilizando 50 classificadores, o Random Forests obteve de média de acerto de 57.0371% contra 44.4444% do Random Forests Estocástico, resultando numa diferença de 12.5927%.
Notamos que para o caso da base de dados B20, à medida que o número de classificadores foi aumentando, a diferença entre os resultados também aumentou.
Para a base de dados B31, encontramos, como na base B20, diferença nos três conjuntos de classificadores.
Utilizando 10 classificadores, o percentual de acerto do Random Forests foi de média de acerto do primeiro foi de 50.1541% contra 32.3117%, resultando numa diferença de acerto para o Random Forests foi de 51.1186% contra 32.2148%, resultando numa diferença de 18.9083%.
Para a base de dados B31, assim como para a base de dados B20, notamos que à medida que o número de classificadores aumenta, a diferença entre os resultados também aumenta.
Os casos específicos de diferença considerável na média de acerto destacados aqui mostram uma ampla vantagem em favor de o Random Forest.
Notamos também que nos casos em que uma diferença grande foi encontrada nos três conjuntos de classificadores, à medida que o número de classificadores aumenta, a diferença entre os resultados também aumenta.
Sobre todos os resultados de desvio padrão destacamos quatro casos de notória diferença.
Para a base de dados B09 utilizando 50 classificadores encontramos um desvio padrão de 0% para o Random Forests Estocástico, e de 5.3326% para o Random Forests.
A base de dados B20 obteve os seguintes resultados:
Com 30 classificadores o desvio padrão do Random Forests Estocástico obteve 0% de desvio padrão e o Random Forests 7.0623%, e utilizando 50 classificadores o primeiro também obteve 0% de desvio padrão contra 6.9078%.
Por último, para a base de dados B31, o resultado do desvio padrão para o Random Forests Estocástico foi de 0.7185% contra 6.6485% do Random Forests resultando numa diferença de 5.9300%.
Notamos que para estes casos ocorreu um ganho significativo em favor de o Random Forests Estocástico, mostrando que este consegue alcançar uma ótima estabilidade.
Analisando os resultados do experimento e o comportamento do Random Forests Estocástico com relação a a distância, encontramos valores que mostram uma grande queda nos resultados gerados por o Random Forests Estocástico.
De entre todos estes resultados destacamos onze que superaram os 9% de diferença.
Observando o resultado da base de dados B08, encontramos que para 10 classificadores a distância do Random Forests Estocástico foi de 0%, contra 15.3846% do Random Forests.
A o classificar a base de dados B09 utilizando 50 classificadores, o Random Forests Estocástico obteve 0% de distância contra 22.2222% do Random Forests.
A performance anterior manteve- se para a base de dados B10:
Utilizando 50 classificadores, o Random Forests Estocástico obteve 0% de distância, e o Random Forests 11.7647%.
Para a base de dados B13 utilizando 30 classificadores, o Random Forests Estocástico obteve 0% de distância contra 9.6774%.
O resultado do base de dados B11 utilizando 50 classificadores é um pouco distante dos anteriores, em o qual o Random Forests Estocástico obteve 7.1429% contra 21.4286% do Random Forests resultando numa diferença de 14.2857%.
Detectamos, na observação, resultados significativos para os três conjuntos de classificadores para a bases de dados B20 e B31.
Para a base de dados B20 encontramos os seguintes resultados:
Com 10 classificadores o Random Forests Estocástico obteve 11.1111% de distância e o Random Forests 22.2223%, resultando numa diferença de 11.1112%.
Utilizando 30 classificadores, o Random Forests Estocástico obteve 0% de distância contra 22.2223% do Random Forests.
Finalmente, utilizando 50 classificadores, o primeiro manteve 0% de distância contra Os resultados da base de dados B31 mostram que com 10 classificadores, o Random Forests Estocástico obteve uma média de 3.3557% contra 24.8322% do Random Forests, resultando numa diferença de 21.4765%.
Utilizando 30 classificadores, o Random Forests Estocástico obteve uma média de 2.0134% contra 16.1074%, resultando numa diferença de 14.0940%.
Classificando com 50 classificadores, o primeiro obteve uma distância de 0% contra 15.4363% do segundo.
Os resultados apresentados aqui mostram uma grande diferença entre os resultados de distância gerados por o Random Forests Estocástico e por o Random Forests.
Os casos analisados mostram que o Random Forests Estocástico alcançou baixos percentuais de distância sendo estes valores consideravelmente menores que os valores de distância gerados por o Random Forests.
Este trabalho apresentou um método de mineração de dados que objetiva diminuir a variabilidade encontrada nos resultados do método Random Forests quando submetido à aleatoriedade.
Para alcançar o objetivo principal deste trabalho, foi desenvolvido um método chamado Random Forests Estocástico na Seção 4.1, e sua performance experimentada e avaliada nas Seções 4.2 e 4.3.
Como parte do desenvolvimento do trabalho, foi implementado o algoritmo junto com a especificação e exemplificação de como é possível obter ganhos de precisão e estabilidade.
Esta produção cumpre com o primeiro objetivo específico desta dissertação.
O segundo objetivo específico foi alcançado nas seções em as quais o Random Forests Estocástico foi experimentado, e sua precisão e estabilidade foram avaliadas.
Para avaliar o comportamento do Random Forests Estocástico com relação a o do Random Forests, foram realizadas uma série de comparações sobre os resultados do experimento.
Comparamos os resultados considerando e não considerando o número de classificadores.
Comparamos ambos resultados com relação a a Bagging e Boosting.
Buscando uma nova perspectiva de análise, realizamos uma comparação quantitativa dos resultados levando e não levando em conta a margem de 2%.
Outro ponto importante da análise foi a divisão das bases de dados por características.
Separamos as bases de dados por seu desbalanceamento, e por o número de instâncias, e observamos se estas características influenciaram na performance e estabilidade do algoritmo.
Por último, um estudo de exceções foi feito, em o qual destacamos casos em os quais uma diferença considerável no resultado foi encontrado.
Com relação a os resultados encontrados, o Random Forests Estocástico obteve vantagem em algumas comparações.
As observações sobre os estudos citados anteriormente mostram que o Random Forests Estocástico obteve notória vantagem em relação a o Random Forests quando analisados os valores de desvio padrão e distância.
Comparando os resultados de percentual de acerto, encontramos vantagem em favor de o Random Forests.
Em a comparação quantitativa, o Random Forests foi melhor quando considerada a margem de 2% ao comparar os resultados, enquanto que o Random Forests Estocástico foi superior quando não utilizada esta margem.
Todos os resultados apresentados até aqui nos permitem concluir que dentro de as bases de dados experimentadas no presente trabalho, o Random Forests Estocástico conseguiu uma menor variabilidade nos resultados quando comparado ao Random Forests.
Realizando algumas adaptações como por exemplo, a possibilidade de processar este de forma distribuída, permitirão que este possa ser utilizado em sistemas de recomendação.
Lições aprendidas Este trabalho nos deixou os seguintes aprendizados:·
Um bom entendimento sobre Mineração de Dados, Combinção de Classificadores, Bagging e Boosting.·
Uma compreensão mais profunda sobre o Random Forests e o entendimento de que, além de melhorar a estabilidade, como alcançado no presente trabalho, outras melhorias em performance e estabilidade podem ser alcançadas.
Estas possíveis melhorias abrem caminho para trabalhos futuros.
Contribuição trabalho A contribuição principal do trabalho foi mostrar através da implementação e experimentação do método Random Forests Estocástico que é possível adaptar o método Random Forests para que este seja menos vulnerável à aleatoriedade.
Os objetivos específicos, que serviram para responder a pergunta da hipótese do presente trabalho, somados ao estudo inicial sobre o Random Forests, produziram três outras menores contribuições que claramente podem ser apontadas:·
Um estudo através de experimentos que mostra a variabilidade dos resultados do Random Forests quando submetido à aleatoriedade;·
A proposta e implementação do novo método Random Forests Estocástico;·
Um exprimento que serviu para medir a precisão e a variabilidade dos resultados do Random Forests Estocástico.
A primeira das contribuições menores citada acima serviu como apoio e justificativa para o desenvolvimento desta dissertação.
Experimentamos e estudamos os resultados por diferentes aspectos.
Inicialmente comparamos os resultados experimentais do Random Forests, considerando o número de sementes utilizadas.
Comparando os resultados utilizando a semente Default, notamos que o Random Forests obteve melhor desempenho se comparado com o alcançado com a seleção aleatória da semente.
Buscando identificar a origem da instabilidade encontrada, comparamos os resultados com os de Bagging e Boosting.
Esta comparação nos mostrou que observando o percentual de media de acerto do Random Forests, encontramos resultados levemente inferiores aos resultados destes algoritmos.
Em a sequência, aplicamos uma comparação quantitativa.
Contabilizamos o número de vezes que um algoritmo foi melhor que os demais.
O resultado desta comparação mostrou um melhor desempenho em favor de o Random Forests.
Apesar de o melhor desempenho, notamos uma queda de performance quando aplicada a seleção aleatória da semente.
Decidimos observar então o resultado do experimento por outro aspecto, e o fizemos analisando a distância e o desvio padrão.
A o comparar os resultados de desvio padrão e distância, encontramos uma notória diferença à favor de Bagging e Boosting em relação a a Random Forests.
Notamos que este gerou resultados de classificação muito distantes de distância e um desvio padrão muito alto quando comparado com os demais algoritmos.
Este estudo nos mostrou através dos seus resultados que o Random Forests é sensível à seleção aleatória da semente, servindo este como base para a realização deste trabalho.
A implementação do Random Forests Estocástico foi a segunda menor contribuição.
O desenvolvimento do método não implicou em alterar nenhuma funcionalidade interna do Random Forests, e sim utilizar as funcionalidades já existentes para o seu desenvolvimento.
Apresentamos a fórmula para calcular os percentuais de voto e descrevemos seus componentes.
O funcionamento do algoritmo foi comentado passo a passo, para um melhor entendimento.
Em o fim, a estratégia para diminuir a sensibilidade causada por a aleatoriedade combinando diferentes resultados de classificação foi explicada e exemplificada.
A última contribuição deste trabalho é um estudo comparativo entre os resultados obtidos no experimento do Random Forests com os do Random Forests Estocástico.
Inicialmente um experimento foi planejado e executado utilizando como base o primeiro cenário apresentado no presente trabalho.
Coletadas as informações deste experimento, iniciamos as distintas análises.
Comparamos os resultados por perspectivas diferentes.
Analisamos as médias e comparamos estas de forma consolidada, de acordo com o número de classificadores.
Comparamos os resultados de ambos métodos relacionando seus resultados com os de Bagging e Boosting.
Uma comparação quantitativa foi realizada para conhecer o número de casos em que um algoritmo foi melhor que o outro.
Os resultados foram analisados levando em conta diferentes características das bases de dados.
Por ultimo, as exceções foram destacadas.
O resultado de todas estas diferentes análises nos mostraram no geral um melhor despenho do Random Forests Estocástico no que diz respeito à distância e desvio padrão e vantagem no percentual de acerto em favor de o Random Forests.
A última afirmação só não foi verdadeira na comparação apresentada na Subseção 4.3.4, em a qual a vantagem em favor de o Random Forests Estocástico foi encontrada na comparação da média de acerto.
Isto mostra que mesmo não conseguindo uma vantagem expressiva, capaz de superar os 2%, este foi mais preciso que o Random Forests na maioria dos casos.
Trabalhos Futuros Dentro de o contexto deste trabalho, do desenvolvimento do Random Forests Estocástico e do experimento que mostra os ganhos obtidos, foi possível identificar o seguinte trabalho futuro:·
Desenvolver melhorias no Random Forests Estocástico;
O desenvolvimento do item citado acima adicionaria novos mecanismos ao funcionamento atual do Random Forests Estocástico.
Uma melhoria significativa seria possibilitar a configuração de um pacote de sementes N, sendo N\&gt; $= 1, possibilitando assim a paralelização da construção dos modelos.
Outra funcionalidade a ser adicionada seria a paralelização da classificação de uma instância sobre as N florestas construídas.
As melhorias citadas anteriormente dizem respeito a questões de performance de execução das tarefas.
