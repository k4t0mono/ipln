A cada dia a evolução de máquinas e técnicas computacionais tem exigido uma melhor análise e acompanhamento de seus sistemas.
Em esta área se insere o estudo de avaliação de sistemas.
De entre as técnicas utilizadas para avaliar sistemas, modelos markovianos tem sido muito utilizados e trazem uma série de vantagens.
Orém, o grande inconveniente no uso de cadeias de Markov é que a matriz de transição (gerador infinitesimal) pode ser tão grande que não é possível armazenas- la e nem mesmo resolves- la.
Redes de autômatos estocásticos &quot;SAN «surgiu como um formalismo que, apesar de se basear em cadeias de Markov, tem como grande vantagem a redução da carga de memória, pois trabalha com pequenas matrizes que ficam armazenadas em formato tensorial.
SAN consiste de um número de autômatos estocásticos individuais que operam com relativa dependência uns dos outros.
As únicas formas de independência são eventos sincronizantes e taxas funcionais.
Quando não existe no modelo a ocorrência de transições funcionais, utiliza- se para a solução a álgebra tensorial clássica.
ATG, com seus dois operadores, produto tensorial e soma tensorial.
Em o trabalho são apresentadas as propriedades da álgebra tensorial clássica, bem como suas provas algébricas.
Quando um modelo possui elementos funcionais, a resolução utiliza a álgebra tensorial generalizada.
ATG, com dois operadores, quais sejam:
Produto tensorial generalizado e soma tensorial generalizada.
O custo de resolução de uma rede de autômatos estocásticos é, via de regra, bastante baixo, exceto quando a existência de transições funcionais cria um ciclo de dependência entre os diversos autômatos do modelo.
Para que seja resolvida uma rede de autômatos estocásticos onde isso ocorre, é necessário quebrar este ciclo de dependência através de algum tipo de compatibilidade entre o produto tensorial generalizado e a multiplicação de matrizes.
Conseguimos, neste trabalho, provar que esta compatibilidade não se verifica da mesma forma que na álgebra tensorial clássica.
Adicionalmente, simples permutações não resolvem o problema.
De entre as diversas opções de permutações testadas, grande parte gera erros quanto a avaliação da matriz, o que, por si só, impossibilita a compatibilidade.
Dois dos experimentos foram destacados, de entre os poucos em que a avaliação está correta, porém, a ordem dos elementos da matriz está invertida.
Concluímos que o fato de conseguirmos inverter os elementos da matriz para a ordem correta, tornaria possível alguma forma de compatibilidade, a partir de esta compatibilidade, o próximo fasso seria o desenvolvimento de um algoritmo para comparar o custo computacional dessa inversão em relação a outras soluções de SAN.
A cada dia pode- se observar a evolução crescente e a complexidade de sistemas, o que tem exigido o desenvolvimento de ferramentas que permitam a modelagem e a análise do desempenho e confiabilidade dos mesmos.
Outro destaque que tem merecido a atenção da área de computação científica, tem sido o tamanho dos sistemas, o que tem gerado problemas de grandes proporções, difíceis de serem armazenados e também de serem resolvidos.
Em função de isso, nos últimos anos a modelagem e análise de sistemas tem recebido cada vez mais a atenção por parte de pesquisadores e cientistas que se dispunham, antes de ser implementado ou construído fisicamente, a prever o comportamento destes sistemas.
A evolução destes estudos tem sido feita desde IVWH, onde iniciaram- se trabalhos com cadeias de Markov.
O primeiro formalismo estudado foi as redes de filas de espera,.
A partir de IWTU, foi possível a generalização das redes de filas de espera,.
Já na década de UH, estudos mais detalhados provém uma nova solução através do algoritmo conhecido como &quot;algoritmo de convolução»,, através do cálculo da constante de normalização para compensar a escolha de valores numéricos para as taxas de visita de cada estação.
A partir destes estudos surgiram ferramentas baseadas em grafos, como as álgebras, que trabalham com uma nova forma que modela o funcionamento (de onde se extrai índices de desempenho) com ferramentas fáceis de definir e analizar.
Grande parte destes formalismos baseia- se em cadeias de Markov para a busca da solução e avaliação destes sistemas, porém, como será visto no decorrer deste trabalho, este tipo de solução apresenta como grande inconveniente a complexidade dos mesmos, tanto a nível de solução quanto de armazenamento Com a evolução dos sistemas distribuídos, tornaram- se freqüentes problemas práticos de paralelismo e sincronismo.
Entre as décadas de 80 e 90, surgiu um novo formalismo, definido como rede de autômatos estocásticos,,.
Este formalismo baseia- se também em cadeias de Markov, porém, com maior facilidade de manipulação e armazenamento, pois divide o sistema em pequenos subsistemas que interagem entre si,.
Diversos autores tem escrito sobre redes de autômatos estocásticos,,, como um formalismo que consegue representar um sistema de forma mais compacta que o tradicional (formatos esparsos), bem como, um formalismo que evita o grande problema de armazenamento e tem um tempo de solução do problema menor.
Este trabalho estuda a base matemática, de um ponto de vista numérico, que fundamenta redes de autômatos estocásticos com o objetivo principal de otimizar a sua solução.
Redes de autômatos estocásticos utilizam- se da álgebra tensorial para a solução de sistemas, tendo sido concentrados estudos principalmente em suas propriedades.
A multiplicação ordinária de matrizes.
O objetivo do presente trabalho então é estudar, analisar e demonstrar as propriedades da álgebra tensorial clássica e generalizada e com base nestas, verificar possibilidades de aplicar a propriedade anteriormente citada, já estudada e provada para a álgebra tensorial clássica e ainda não estudada para a álgebra tensorial generalizada.
Em estudo prévio desenvolvido por a autora do trabalho, foi descoberta a incompatibilidade da aplicação direta desta propriedade, conforme pode ser observado no capítulo T. Em função de isto, nesta obra serão buscadas alternativas matemáticas para solucionar esta incompatibilidade A álgebra tensorial divide- se basicamente em álgebra tensorial clássica e álgebra tensorial generalizada, neste segundo caso, trabalhando- se quando o sistema possui elementos funcionais, ou seja, elementos não constantes, que variam de acordo com o estado de cada autômato da rede de autômatos estocásticos.
Muitas das propriedades da álgebra tensorial clássica já foram provadas e estão bem definidas, e no caso de a álgebra tensorial generalizada o mesmo não ocorre.
O fato de não serem conhecidas algumas propriedades da álgebra tensorial generalizada, gera a necessidade de transformar os elementos funcionais de uma rede de autômatos estocásticos em constantes, através da propriedade da decomposição em produto tensorial clássico, que pode ser vista no capítulo S. Em este caso, o sistema passa a trabalhar sem funções, pois transforma- se cada função, fazendo com que a matriz seja decomposta em tantos produtos tensoriais quanto o número de linhas da matriz onde será aplicada a função.
Como pode ser visto, isso acarreta em grande prejuízo em termos de processamento.
Por isso, torna- se quase imprescindível a descoberta de novas propriedades para que se possa trabalhar diretamente com as funções, ou seja, com cálculos aplicados de álgebra tensorial generalizada.
Em resumo, todo o problema resolvido por a álgebra tensorial generalizada também pode ser resolvido por a álgebra tensorial clássica, sem prejuízo do resultado final, porém com o agravante de aumentar os custos de processamento.
Estudos recentes tem mostrado e provado várias propriedades para a álgebra tensorial generalizada, que tem melhorado em muito o tempo de processamento para a resolução de problemas.
A partir de estas provas, alguns problemas podem ser resolvidos sem decompor as funções em novos produtos tensoriais, porém para que se possa resolver de fato todos os problemas diretamente com as funções, torna- se necessário a prova da propriedade da compatibilidade do produto tensorial generalizado sobre.
Divisão do trabalho. Para chegar ao estudo das propriedades da álgebra tensorial, é importante fazer um estudo prévio da evolução da avaliação de desempenho dos sistemas, de toda a teoria que cerca o assunto.
Em o capítulo P, será abordado o tema avaliação de desempenho, a modelagem dos sistemas e técnicas utilizadas para medir e avaliar os sistemas.
Será abordado de forma mais criteriosa, a modelagem, e basicamente citada a monitoração (técnica esta, não focalizada por o trabalho).
Entre as formas de modelar sistemas, ênfase será dada a modelos analíticos, pois em eles serão aplicados nossos estudos.
Conhecer o passado significa &quot;carregar a bagagem «da experiência de anos de pesquisa.
O estudo de novas técnicas é gerado a partir de experiências passadas.
Formalismos de modelagem são estudados a décadas, servindo de embasamento para pesquisas e criação do formalismo de redes de autômatos estocásticos.
Em o capítulo P apresenta- se um breve histórico do estudo destes formalismos.
Redes de autômatos estocásticos baseiam- se em cadeias de Markov.
Em o capítulo Q, pode ser encontrado o estudo de redes de autômatos estocásticos, definições básicas e a forma de modelar sistemas a partir de estas.
Serão apresentados exemplos de autômatos com eventos locais, eventos sincronizantes, transições funcionais, bem como uma explicação sobre cada um dos temas abordados.
Em seguida é apresentada uma coletânea de informações referentes a cadeias de Markov e o descritor markoviano.
Gomo, a partir de a análise de um sistema gerar o descritor markoviano, utilizado para P o cálculo de redes de autômatos estocáticos.
A partir de o sistema modelado através de cadeias de Markov, o sistema pode ser resolvido através de equações de sistemas lineares.
Estes sistemas são dividos basicamente entre diretos e indiretos.
Em o capítulo R, inicia- se a definição de álgebra tensorial clássica e álgebra tensorial generalizada.
Apresenta- se os operadores matriciais utilizados, produto tensorial e soma tensorial, bem como sua operacionalização e exemplos do uso.
Também apresenta- se a definição de fator normal, definição esta de grande importância no uso da soma tensorial, tanto clássica quanto generalizada.
Estudar os operadores matriciais nos possibilita contato direto com as propriedades aplicadas tanto na álgebra tensorial clássica, quanto na álgebra tensorial generalizada.
Em o capítulo S, faz- se a demonstração algébrica das propriedades do produto tensorial e da soma tensorial clássica, bem como a demonstração algébrica das propriedades do produto tensorial generalizado e da soma tensorial generaliza.
Cada propriedade será estudada e analisada, com o intuito de fundamentar, apresentar a prova de cada uma e abrir perspectivas para o surgimento de novas propriedades, que em muito poderão auxiliar na simplificação da resolução de redes de autômatos estocásticos.
Em o capítulo T, com base nas provas apresentadas no capítulo S, pode ser iniciado o estudo da busca para a compatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes, sabendo- se que esta não se apresenta da mesma forma que na álgebra tensorial clássica.
Primeiro apresenta- se as matrizes bases do estudo (e f), em seguida, apresenta- se as variações sobre as mesmas, bem como variação sobre a identidade, ou seja, sua transposta.
A partir de estas variações, serão apresentados estudos realizados sobre cada variação, acompanhada de explicação e justificativa de cada variação estudada.
A partir de os estudos realizados sobre as matrizes resultantes das multiplicações, no capítulo U, conclusão, serão tecidas considerações, destacando os resultados mais próximos, ou seja, onde não se verifica a ocorrência de avaliações erradas sobre as matrizes, para a partir de estas solucionar o problema da incompatibilidade que está sendo estudada.
Por final, apresenta- se idéias para a continuidade futura deste trabalho.
Avaliação de desempenho O revolucionário processo de evolução tecnológica tanto a nível de hardware quanto de software tem exigido constantes estudos e merecido a atenção de diversas áreas.
De entre estas áreas, destaca- se a avaliação de desempenho, que tem como motivação medir e avaliar um sistema pronto ou a ser projetado.
Existem, basicamente, duas fases utilizadas na técnica de avaliação de desempenho:
Modelagem e monitoração.
Modelagem. Modelo, segundo uma análise literal da falavra, é a representação simplificada de alguma coisa.
Segundo, um modelo é uma réplica ou uma abstração da característica essencial de um processo.
Um modelo, tratando- se de avaliação de desempenho, é uma visão simplificada de um sistema, onde procura- se buscar ao máximo a realidade do sistema, de maneira a fornecer, dentro de uma tolerância aceitável, diagnósticos precisos do mesmo.
Quando um sistema não existe ainda, normalmente um modelo é a melhor alternativa.
Exemplos de modelos podem ser observados em.
Um modelo é freqüentemente a única alternativa prática se o sistema ainda não existe ou se é necessário analisar o sistema submetido a uma carga ainda inexistente.
Em o desenvolvimento de um modelo, torna- se necessário:·
escolha do nível de abstração que será utilizado para descrever o sistema a ser modelado;·
escolha das características do sistema que devem ser incluídas no modelo;·
escolha dos índices de desempenho apropriados;·
escolha dos valores numéricos como parâmetros do sistema Utiliza- se um modelo basicamente de duas maneiras, para simulação ou para resolução analítica.
Modelos de simulação.
A simulação pode ser considerada como a reprodução funcional de uma realidade através de um modelo a ser analisado e avaliado.
Ela deve descrever as características funcionais do modelo e conter todos os detalhes relevantes.
Simulação é a forma mais popular de avaliar sistemas reais, existe grande facilidade para ser empregada, pois são programas de computador em que as operações e carga são descritas através de algoritmos apropriados.
São implementados em linguagens próprias S para as construções destes modelos e os índices de performance são obtidos através da monitoração do programa em execução.
A abordagem de simulação proporciona a solução de problemas matemáticos não probabilísticos por reprodução de um processo estocástico que tem momentos ou distribuições de probabilidade satisfazendo as relações matemáticas do problema não probabilístico.
Roblemas que desobedecem a soluções diretas por causa de o tamanho, complexidade ou estrutura, são frequentemente avaliados através de modelos de simulação.
A principal desvantagem da simulação é o custo, por o fato de serem dispendiosos e caros em termos de execução em máquinas.
Além de isto, devido a as muitas possibilidades de um sistema real, pode ser difícil uma descrição exata.
Os modelos analíticos descrevem o sistema e sua carga em termos abstratos, onde as medidas de desempenho são obtidas através da solução numérica de um modelo resultante.
Os modelos analíticos podem ser determinísticos I ou estocásticos P.
Em os modelos estocásticos existe uma análise probabilística do comportamento do sistema, onde os parâmetros do sistema são descritos por variáveis aleatórias, com distribuições de probabilidades convenientes, pois se todos os detalhes forem incluídos, a complexidade pode tornar o modelo intratável.
De a mesma forma, em alguns casos, esses detalhes podem ser desconhecidos no momento da modelagem.
A principal desvantagem dos modelos estocásticos é o fato do modelo analítico se tornar muito caro em termos de complexidade computacional e de necessidade de armazenamento MyhivyS hi SswUveÇÃy hifícil de mostrar que estão corretos Relações de causa-efeito estabelecidas num programa Caros em termos de ciclos de execução de gPU.
Formalismo de modelagem é a linguagem alfanumérica ou gráfica para especificar os modelos[ QW].
As primeiras pesquisas sobre modelagem que se tem conhecimento são sobre análise direta de processos estocásticos através de cadeias de Markov.
Estes tiveram suas raízes com a criação dos modelos de Markov, por o matemático russo Markov e posteriormente, por o matemático dinamarquês Erlang em redes de telefones.
Observações importantes, inicialmente de tackson, originaram um novo formalismo, as redes de fila de espera.
Newell demonstraram a existência de um produto para a solução de redes fechadas.
Palacios generalizaram a família de redes, estudando uma solução para este produto,.
Segundo eles, a rede de fila de espera aberta, com capacidade ilimitada, com diversas classes distintas de clientes e forma de atendimento sem prioridade, pode ter seus índices de desempenho obtidos por um conjunto de fórmulas desenvolvido com base no teorema de chegada e na lei de vittle.
A partir de IWUQ, com os estudos de Reizer e Uobayashi surgiram os algoritmos chamados &quot;algoritmos de convolução», ou seja, uma recursividade inteligente com constantes Em o modelo determinístico os valores são previamente determinados.
Em o modelo estocástico os parâmetros são descritos por variáveis aleatórioas com distribuições de probabilidade conveniente.
De normalizações de incremento da população de clientes.
O cálculo dos índices de desempenho obtidos por o algoritmo de convolução proposto por fuzen tem por objetivo determinar uma constante de normalização para compensar a escolha de valores numéricos para as taxas de visita de cada estação.
Outros estudos, como os de Reiser e Vavenberg geraram algoritmos que calculam o equilíbrio das probabilidades dos estados.
A análise feita por estes estudiosos evitou o cálculo de normalizações constantes, o que se tornou um conceito fundamental na teoria das filas.
Uma implementação deste algoritmo pode ser encontrada na ferramenta de software gQx.
Systems) Uma diferente aproximação estudada foi a criação do software PexAgie, de Mcuenna, Mitra e tu.
Romakrishnan para a solução de modelos markovianos de redes de filas de espera significativamente grandes para serem resolvidos com técnicas computacionais simples.
Este software se propôs a resolver multiclasses, redes de filas abertas, redes de filas fechadas e mistas.
Outras abordagens sobre as redes de filas de espera foram buscadas, principalmente devido a necessidade de resolução de problemas mais complexos, porém essas culminaram em simples extensões do formalismo de redes de filas de espera.
A partir de estas extensões, iniciaram- se novos estudos, em especial mecanismos de sincronismo e paralelismo.
Os sistemas baseados nestes mecanismos são, geralmente, difíceis de serem estudados e construídos, em função de a explosão do número de estados do modelo.
Por volta de IWTH, foram introduzidas por Carl edam Petri, as redes de Petri, como uma extensão de autômatos seqüenciais, caracterizando sistemas por meio de transações locais entre os estados, com isso permitindo vencer as limitações dos métodos formais Q definidos por sistemas seqüenciais com respeito a os exibidos para os sistemas distribuídos.
Rede de Petri é uma ferramenta gráfica e algébrica que apresenta um bom nível de abstração em comparação com outros modelos gráficos.
É um modelo do tipo estado-evento, onde cada evento possui pré-condições que vão pemitir sua ocorrência e pós-condições decorrentes desta, as quais são, por sua vez, pré-condições de outros eventos posteriores.
Uma rede de Petri é vista como um tipo particular de grafo orientado, que permite modelar as propriedades estáticas de um sistema a eventos discretos, constituído de dois tipos de nós:
As transições fique correspondem aos eventos que caracterizam as mudanças de estado do sistemaA, e os lugares fique correspondem as condições que devem ser certificadas para os eventos aconteceremA, interligados por arcos direcionados ponderados.
Rede de Petri é, portanto, um formalismo que permite a modelagem de sistemas dinâmicos discretos com grande poder de expressividade, permitindo representar com facilidade todas as relações de causalidade entre os processos em situação de:
Seqüencialidade, con) ito, concorrência e sincronização.
As redes de Petri podem variar de simples temporizações constantes até mecanismos mais sofisticados, conforme segue:·
redes de Petri estocásticas.
Um estudo aprofundado e exemplos de redes de Petri estocásticas pode ser encontrado em;·
redes de Petri estocásticas generalizadas,;·
redes de Petri de alto nível (redes coloridas),;·
redes de Petri estocásticas generalizadas superpostas.
Métodos formais e processos algébricos caracterizam sistemas distribuídos de dois níveis:
Como meio de entendimento e, mais recentemente, como uma ferramenta para especificação de sistemas distribuídos com projetos bem definidos em seus paradigmas e métodos.
Novas técnicas de modelagem surgiram, através do cálculo de sistemas comunicantes (Calculus Comunicating Systems).
De entre estas técnicas podem ser destacadas:·
álgebras de processos estocásticos;·
redes de autômatos estocásticos D Existem também as ferramentas desenvolvidas em cima de grafos para descrever o comportamento temporal de eventos, que não se baseiam em cadeias de Markov, como:
Monitoração. Esta técnica, também conhecida como experimentação direta, consiste na observação direta do funcionamento de sistemas reais,.
A monitoração sugere grande fidelidade em relação a as medidas obtidas, pois neste caso, não existe nenhuma abstração quanto a o funcionamento do sistema.
Ossui basicamente duas desvantagens a saber:
V Sensibilidade da técnica de monitoração em relação a quantidade e representatividade das amostras de funcionamento a serem consideradas.
E, principalmente a necessidade da existência física e real do sistema que será avaliado.
Traz como conseqüências:·
custo e tempo:
A implementação de um sistema não estável pode conduzir a grandes alterações ou até mesmo a sua perda total.
O custo e tempo para a implementação de um sistema, que pode necessitar novos testes, podem atrasar em muito a implantação do sistema definitivo.·
dificuldade de reprodução:
Algumas vezes, torna- se necessário repetir um experimento com pequenas variações em alguns parâmetros e podem existir estímulos externos que fujam ao controle da experiência, invalidando qualquer comparação com os resultados anteriores Redes de autômatos estocásticos De entre as técnicas descritas anteriormente, os formalismos mais usados baseiam- se em cadeias de Markov, pois normalmente são menos suscetíveis a erros, demandam menos tempo e possuem uma limitada complexidade matemática.
Todavia, o espaço de estados gerados pode ser tão grande que além de o modelo não ser tratável, a matriz de transição I é tão grande que não pode ser armazenada.
O formalismo de redes de autômatos estocásticos (SAN) descreve um sistema completo como uma coleção de subsistemas que interagem uns com os outros.
Cada um destes subsistemas é descrito como um autômato estocástico, ou seja, um autômato onde as transições são modeladas por processos estocásticos de tempo contínuo ou discreto,.
A técnica de redes de autômatos estocásticos proporciona uma metodologia conveniente que combina diferentes técnicas de modelagem, de uma forma muito particular para modelagem de processos paralelos, com processos comunicantes e processos concorrentes.
Segundo, o formalismo de redes de autômatos estocásticos é uma técnica atrativa de modelar sistemas complexos com iteração entre os componentes.
Os componentes do sistema são modelados por simples autômatos e iterações entre estes componentes.
Uma rede de autômatos estocásticos consiste de um número de autômatos estocásticos individuais que operam com uma relativa independência uns dos outros.
Um autômato é representado por um número de estados e as regras que governam a movimentação destes estados.
Diz- se, nas definições, autômatos estocásticos, porque em eles o tempo é tratado como uma variável aleatória, com o comportamento descrito por um processo estocástico com distribuição exponencialP.
Uma variável aleatória é uma regra que atribui um valor numérico para cada possível resultado de um experimento.
Denominado um conjunto de n resultados S, pode ser definida formalmente uma variável aleatória X como uma função de S nos números reais, ou seja:
Logo, X (s) define um número real para o resultado s pertencente a S. A grande vantagem do uso de SAN é a redução de carga de memória para o armazenamento da matriz de transição da cadeia de Markov, que fica armazenada em formato tensorial.
Uma definição formal de redes de autômatos estocásticos, bem como a solução de um modelo através de SAN, podem ser encontrados em e.
Para o bom entendimento do formalismo SAN, é necessário conhecer alguns conceitos importantes, como autômatos, transições locais, transições sincronizadas e transições funcionais, bem como a geração e utilização do descritor markoviano.
Watriz de transição é o gerador infinitesimal da cadeia de Markov associada a um modelo original.
Mais informações podem ser vistas no capítulo Q, subtítulo QFP.
Distribuição exponencial é a distribuição de probabilidade que melhor descreve um processo desconhecido.
Esta parte do princípio que cada fenômeno é independente, logo a entropia é a maior possível.
Autômatos. Um autômato é composto por um conjunto de estados e um conjunto de transições entre estes estados.
Essas transições podem representar eventos locais, ou seja, um evento local associado a uma única transição local Agou eventos sincronizados, onde exista um evento sincronizante associado a um conjunto de transições locais que devem ser sincronizadas.
Snformalmente, pode- se dizer que o estado de uma rede de autômatos estocásticos é definido como a combinação de todos os estados internos de um autômato.
Assim, numa rede constituída de três autômatos, cada um com quatro estados locais, existe uma rede de autômatos estocásticos com um total de 43 $= 64 estados globais diferentes em que, para que se altere o estado global de toda a rede de autômatos estocásticos, basta apenas um único autômato alterar o seu estado local.
A mudança no estado global de uma rede de autômatos estocásticos pode ser conseqüência de um evento local ou de um evento sincronizante.
Um evento local corresponde a mudança de estado de um único autômato, enquanto na ocorrência de um evento sincronizante, ocorre a mudança do estado interno de um ou mais autômatos.
Um evento local ocorre quando o funcionamento de cada autômato é independente de outro autômato, ou seja, em qualquer tempo e independente de outras transições.
Em este tipo de transição, a alteração do estado de um autômato não provoca alterações em outros autômatos da rede de autômatos estocásticos.
Em a figura QFI, pode ser visto um exemplo de transição local, em seguida a explicação do mesmo.
O autômato B possui dois estados internos, denominados b0 e b1.
Em função de o modelo possuir somente eventos locais, todas as setas tem a taxa de disparo correspondente à transição, aqui representadas por ti, onde i varia de 1 a 5.
A título de ilustração e melhor entendimento, na figura QFP será apresentada a cadeia de Markov correspondente ao modelo de rede de autômatos estocásticos com eventos locais, representada na figura QFI.
É importante notar que na SAN apresentada na figura QFI, não existe interação entre os dois autômatos Diferente dos eventos locais, os eventos sincronizados são mais complexos, onde o funcionamento de um autômato depende de evento (s) de outro autômato.
Um evento sincronizante é associado a um conjunto de transições sincronizadas, onde a taxa de disparoQ deve ser associada a cada transição sincronizada e a ocorrência de um evento sincronizado se dá simultaneamente em todos os autômatos envolvidos.
Em o processo de sincronização pode ser vista uma relação do tipo mestre-escravo, onde um autômato é escolhido aleatoriamente como mestre e os demais como escravos.
Em este processo, apenas a taxa de transição não é suficiente, pois necessita- se do que se chama de tripla de sincronização, onde existe um identificador do evento sincronizante R, a taxa de disparo e uma probabilidade de ocorrência S.
A melhor maneira de entender a tripla de sincronização é através da relação mestre-escravo.
Supondo que para cada evento sincronizante, um autômato é escolhido como mestre, tem- se a seguinte estrutura:·
o identificador do evento sincronizante aparece nas setas de ligação dos autômatos;·
as etiquetas das setas de ligação representam as transições sincronizadas do autômato mestre que apresentam a taxa de disparo correspondente a ocorrência do evento sincronizante foco;·
as etiquetas das setas de ligação representam as transições sincronizadas dos autômatos escravos que apresentam taxa igual a um;·
as transições associadas a um mesmo evento sincronizante, que tem como origem um mesmo estado local, devem apresentar uma probabilidade de escolha entre si, a soma dessas probabilidades é obrigatoriamente igual a um;·
em os autômatos mestre e escravo, caso haja uma única transição associada ao evento sincronizante, a probabilidade p vale um;
Taxa de disparo:
Descreve a taxa em que o evento ocorre.
Evento sincronizante:
Nome necessário para identificar as transições que podem ser disparadas simultaneamente.
S Probabilidade de ocorrência:
Estabelece a relação entre todas as transições correspondentes a um mesmo evento que pode ser disparado· para o autômato mestre, a tripla é escrita sob a forma (s, T, p), onde s é o identificador do evento sincronizante, T é a taxa de disparo e p é a probabilidade de ocorrência;
Em a figura QFQ, as transições dos estados a0 para a1, a1 para a2, a2 para a0 e b0 para b1 são transições locais.
As transições dos estados a2 para a0 e a2 para a1 no primeiro autômato e de b1 para b0 no segundo autômato, são transições sincronizadas que correspondem ao mesmo evento sincronizante s.
De o estado a2 para a0 é possível observar duas transições, uma local de taxa t3 e outra através do evento sincronizante s.
A título de ilustração e melhor entendimento, na figura QFR será apresentada a cadeia de Markov correspondente ao modelo de rede de autômatos estocásticos (SAN) representada na figura QFQ.
A ocorrência do evento sincronizado s causa uma das duas situações:
O autômato A passa do estado a2 para o estado a1 e ao mesmo tempo o autômato B passa do estado b1 para o estado b0 com a probabilidade p2 Y ou P. A uma transição, seja ela local ou sincronizada, cujo valor não é constante, mas sim uma função do estado interno de outros autômatos da rede de autômatos estocásticos, denomina- se transição funcional.
Uma transição pode acontecer de acordo com eventos sincronizados Agou eventos locais.
No caso de eventos locais, a taxa é funcional, e em caso de eventos sincronizantes, pode a taxa Agou a probabilidade serem funcionais.
A figura QFS apresenta uma rede de autômatos estocásticos cujo autômato e possui uma transição funcional, ou seja, depende do estado interno do autômato B.
Em este exemplo, a transição do estado b0 para o estado b1 é dependente do autômato A, agora chamada de f e definida como:
Em o exemplo, o disparo da transição do estado b0 para b1 irá ocorrer com uma taxa delta1 se o autômato A estiver no estado a0.
De acordo com o formalismo SAN, a expressão matemática para a função pode ser escrita como:
Como citado anteriormente, o uso de transições funcionais não se restringe apenas a eventos locais.
De fato, num evento sincronizado não só a taxa, mas também a probabilidade de ocorrência de um evento pode ser expressa por uma função.
O uso de transições funcionais é um poderoso recurso do formalismo SAN, pois permite escrever uma estrutura extremamente complexa com um formato bastante compacto e simples.
O custo computacional para trabalhar com taxas funcionais tem diminuído enormemente com o desenvolvimento de soluções numéricas para modelos de redes de autômatos estocásticos.
Descritor markoviano Um autômato é um modelo matemático de um sistema com entradas e saídas discretas.
O sistema pode estar em qualquer uma de um número finito de configurações internas ou estados.
Um estado de um sistema sumariza a informação referente a entradas passadas que é necessária para determinar o comportamento do sistema para entradas subseqüentes.
Se for possível representar o comportamento físico de um sistema, descrevendo os diferentes estados que o mesmo pode ocupar, indicando como ele se move de um estado para o outro e se o tempo dispendido em cada estado possui uma distribuição exponencial, pode dizer- se que este é um processo de Markov.
Associado a todo o processo de Markov existe um grupo de estados.
A evolução deste sistema entre os estados é representado por transições que ocorrem instantaneamente, em outras falavras, a movimentação de um estado para outro não consome tempo algum.
Uma propriedade fundamental de um sistema de Markov é que a evolução futura do sistema depende somente do estado atual e não do passado.
Se os espaços de um processo de Markov forem discretos, o processo é chamado de cadeia de Markov.
Cadeias de Markov são, na realidade, um formalismo de modelagem de sistemas que descreve um sistema com um processo estocástico, onde o sistema modelado é caracterizado por os seus estados e a forma por a qual eles se alteram.
As cadeias de Markov podem ser compreendidas como uma máquina de estados, que caracteriza o funcionamento do sistema por os estados possíveis que ele pode assumir (nodos) e das transições que pode assumir (arcos).
Segundo a escala de tempo, uma cadeia de Markov pode ser de dois tipos:·
Cadeias de Markov a escala de tempo contínuo:
Em este tipo de modelo as variáveis de estado mudam continuamente no tempo.·
Cadeias de Markov a escala de tempo discreto:
Em este tipo de modelo as variáveis de estado mudam só num conjunto discreto de pontos no tempo (DTMC) gadeias de Markov são um formalismo para modelar sistemas supondo que:·
os estados do sistema são discretos;·
a escala de tempo que rege a transição entre estados do sistema pode se dar de forma contínua (CTMC) ou discreta (DTMC);·
a transição entre estados do sistema só depende do seu estado atual, não importando por quais estados o sistema já fassou ou irá passar;·
a freqüência (CTMC) ou a probabilidade (DTMC) de transição de estados do sistema se dá segundo uma lei exponencial Nosso maior interesse neste trabalho é em escala de tempo contínuo, portanto nos deteremos em apresentar o vetor solução das equações para CTMC e a montagem do gerador infinitesimal.
A representação gráfica de uma cadeia de Markov é feita por autômatos onde associa- se a cada lugar um estado do sistema e a cada arco uma taxa (CTMC) ou probabilidade (DTMC).
Matematicamente, uma cadeia de Markov é representada por uma matriz de transição de estados, onde:
IT· para CTMC esta matriz de transição é chamada de gerador infinitesimal (Q) e cada elemento numa linha i e numa coluna j representa a taxa de transição do sistema do estado i para o estado j, os elementos diagonais de Q representam o ajuste necessário para que a soma dos elementos de cada linha seja igual a zero;·
para hTwg esta matriz de transição é chamada de matriz estocástica (P) e a diferença básica é que cada elemento representa a probabilidade de transição entre estados, os elementos diagonais de P representam o ajuste necessário para que a soma dos elementos de cada linha seja igual a um O resultado da análise estacionária de uma cadeia de Markov é expresso por o vetor de probabilidade marginal dos estados do sistema.
Este vetor define qual a probabilidade (estacionária) de cada um dos estados do sistema,.
Descritor markoviano é, portanto, uma descrição compacta da matriz de transição (gerador infinitesimal) da cadeia de Markov associada a um modelo original.
Os resultados estacionários do modelo são obtidos através de um vetor de probabilidade pi que associa uma probabilidade pii a cada um dos n estados da cadeia de Markov.
A partir de o vetor pi, obtem- se informações sobre o sistema modelado, como o número de tarefas executadas, tempos médios, etc..
Onde Q é o gerador infinitesimal da cadeia de Markov.
O gerador infinitesimal (Q) é uma matriz quadrada de ordem nQ igual ao número de estados do autômato.
O autômato A possui três estados, ou seja, nQ $= 3.
Cada linha e cada coluna de Q é associada a um estado de A, segundo a ordem lexicográfica dos estados.
A primeira linha e a primeira coluna de Q correspondem ao estado a0, a segunda linha e coluna correspondem ao estado a1 e a terceira, ao estado a2.
Roporção de tempo em que a cadeia de Markov permanece em cada um de seus estados sob um tempo finito.
Assim, com excessão da diagonal principal, obtem- se todos os elementos de Q. Para a diagonal principal, coloca- se os valores de tal forma que a soma dos elementos de cada uma das linhas da matriz seja nula.
A matriz de transição (Q) do autômato equivalente a rede de autômatos estocásticos é dada por a soma tensorial U das matrizes de transições locais.
No caso de eventos sincronizantes, utiliza- se além de a matriz de transições locais, as matrizes representando cada evento sincronizante, representadas por um far de matrizes para cada autômato.
A primeira matriz do far (chamada de matriz positiva) representa a ocorrência de um evento sincronizante.
O ajuste diagonal correspondente as taxas expressas na primeira matriz será feito por a segunda matriz (chamada matriz negativa).
Em a matriz negativa, todos os elementos fora de a diagonal principal são nulos.
Em uma rede de autômatos estocásticos podem haver três tipos de autômatos:·
Um autômato mestre que contém a taxa de disparo do evento sincronizante.
A existência de probabilidade associada a uma transição tem por efeito da taxa correspondente por a probabilidade.
A matriz negativa (ajuste) contém a taxa negativa.·
Um ou mais autômatos escravos.
As matrizes positivas, neste caso, contém uma taxa de disparo igual a um.
A matriz negativa contém uma taxa de disparo igual a um.·
eutômatos que não são influenciados por o evento sincronizante.
As matrizes positivas e negativas são matrizes identidade, pois a ocorrência do evento sincronizante não altera o estado destes autômatos O descritor, neste caso, é montado em duas partes, uma correspondendo aos eventos sincronizantes e outra aos eventos locais.
A parte local é definida por uma soma tensorial das matrizes locais de cada evento (conforme visto anteriormente).
A parte sincronizante (cada um) corresponde a soma dos produtos tensoriais V de cada evento sincronizante.
Dependendo da escolha do autômato mestre do evento sincronizante, o autômato apresentado na figura QFQ pode ter duas representações diferentes, no entanto, o resultado final para a matriz de transição não se altera.
A parte local da rede de autômatos estocásticos da figura QFQ é representada por:
A definição de soma tensorial, bem como sua solução, pode ser vista no capítulo R. A definição de produto tensorial, bem como sua solução pode ser vista no capítulo R. Se escolhido o autômato e como mestre do evento sincronizante s, tem- se:
Parte positiva:
Arte negativa:
Se escolhido o autômato f como mestre do evento sincronizante s, tem- se:
Parte positiva:
De onde chega- se ao gerador infinitesimal do autômato global, dado por:
Um exemplo de modelagem usando o descritor markoviano e sua resolução pode ser encontrada em.
Em a realidade, as transições funcionais não alteram o descritor, mas exigem o uso da soma e do produto tensorial generalizado, que serão discutidos no próximo capítulo.
Soluções numéricas para cadeias de Markov.
De entre os diferentes métodos de resolução do sistema formado por as equações QFQ e QFR, existem os métodos analíticos e os métodos numéricos,.
Métodos analíticos de resolução de sistemas de equações lineares são os que fornecem uma solução para o sistema de equações lineares sem que seja necessário sua resolução numérica.
A aplicabilidade destes métodos é reduzida, pois se aplicam somente em alguns tipos de modelos.
De entre os exemplos de aplicabilidade destes métodos, podem ser citados:·
processos de nascimento e morte;·
soluções a forma produto para redes de fila de espera Conforme, processo de nascimento e morte com número de estados infinito possui uma solução a forma produto se todas as transições forem descritas por distribuições exponenciais, se a taxa de entrada for inferior a capacidade de atendimento e se as taxas de chegada e atendimento forem independentes da carga.
Nosso interesse se concentra em métodos numéricos para a resolução de sistemas de equações lineares, portanto, ênfase será dada aos mesmos.
Métodos numéricos Os métodos numéricos de solução de sistemas lineares são classificados em dois grupos, a saber:·
métodos numéricos diretosY e· métodos numéricos iterativos Mesmo adotando um critério (rapidez, economia de tempo, segurança na obtenção do resultado) não se pode Carantir, a priori, qual método é o mais eficiente.
Em geral, métodos diretos são apropriados quando o número de estados do sistema modelado não é muito grande fina ordem de até um ou poucos milhares de estados) e quando a matriz de transição de estados do sistema não é esparsa.
Entretanto, podem ser convenientes se a matriz possuir estruturas especiais como, por exemplo, matrizes de banda.
Em este método os zeros da matriz original são preservados e as iterações são conduzidas com a matriz original, tornando os cálculos autocorrigíveis, o que tende a minimizar os erros de arredondamento.
Alguns exemplos de métodos diretos são:
Eliminação de gauss, e fatorização vU.
Será apresentado a seguir um exemplo do uso do método de fatorização vU:
Seja o sistema linear xM $= b.
O processo de fatoração para solução deste sistema consiste em decompor a matriz A num produto de dois ou mais fatores e, em seguida, resolver uma seqüência de sistemas lineares que conduzirá à solução do sistema linear original.
Uma matriz não singular A é o resultado do produto de duas matrizes.
Onde L é uma matriz triangular inferior, ou seja, tem somente elementos abaixo de a diagonal principal e U é uma matriz triangular superior, ou seja, tem somente elementos da diagonal para cima.
Por exemplo, uma matriz A de R x R elementos, poderia ser vista da seguinte forma:
Observação: A diagonal principal da matriz L foi carregada com 1 por opção, pois poderia ter sido a diagonal da matriz U.
Então, o sistema linear, através da decomposição, pode ser resolvido como:
Primeiro sendo resolvido para o vetor O como LY $= b e resolvendo UX $= O.
A equação LY $= b pode ser resolvida por substituição direta, como segue:
Enquanto a equação UX $= O pode ser resolvida por substituição inversa, conforme segue:
Onde algoritmos para calcular equações através deste método podem ser encontrados em, Os métodos iterativos são, normalmente, os mais utilizados para a resolução de cadeias de Markov, pois os métodos diretos não são adequados para modelos de sistemas com elevado número de estados, onde a matriz de transição é de ordem muito alta.
Em os métodos iterativos é gerada uma seqüência de valores aproximados pi (k) do vetor de probabilidades estacionárias que devem convergir para a solução pi.
Cada iteração dos métodos tem um custo aproximadamente igual ao da multiplicação de um vetor por uma matriz (esparsa).
Como exemplos de métodos iterativos podem ser citados o método de tacobi, gauss-Seidel, ernoldi, qwRiS, Sobre-relaxação sucessiva (SyR) e o método da Potência,.
Foi escolhido, como exemplo de método iterativo, o método da potência para demonstrar o cálculo do vetor de probabilidades estacionárias pi.
Em este método, a solução é piP (K) e o esquema iterativo é pi (k+ 1) $= pi (k) P.
Este é um método conhecido das cadeias de Markov onde o elemento j de pi (k) é igual a probabilidade do processo estar no estado j no k--ésimo fasso.
É um método iterativo onde para sabermos o valor de pi n+ 1 precisamos saber o valor de pi n e assim sucessivamente, conforme segue:
Como todo método iterativo, sua solução é dada através de aproximações constantes.
Quando de a análise do sistema, de acordo com os dados, o próprio usuário informa a diferença tolerável.
Diz- se que um sistema converge se este segue em direção a solução e que o sistema estagna, quando em repetidas iterações os valores são os mesmos.
Algoritmos para calcular equações através deste método podem ser encontrados em,.
Em a tentativa de acelerar o processo para Carantir a solução, Canhando velocidade de processamento, podemos potencializar a matriz, onde:
Pp.. Cabe salientar que em matrizes esparsas a aplicação deste artifício tende a aumentar o número de elementos não nulos, acarretando em problemas de ocupação de espaço em memória.
Em estes casos, só resta a alternativa de fazer multiplicações sucessivas em P, para que a matriz possa ser armazenada, mesmo que com isso gere muitas multiplicações até a convergência, acarretando em mais processamento.
Então, para o método da potência só precisamos, na realidade, de multiplicações de um vetor por uma matriz pifiP) $= pi 1, e como em muitas vezes não necessitamos armazenar os valores intermediários, armazenamos somente um ou poucos vetores, diminuindo em muito a carga de memória.
Álgebra Tensorial. O estudo deste capítulo divide- se basicamente em álgebra tensorial clássica e álgebra tensorial generalizada, aqui representadas por ATC e ATG respectivamente, fundamentais para o entendimento de SAN.
Em a primeira parte é demonstrada a álgebra tensorial clássica (ATC), sua resolução e principais propriedades.
Em a segunda parte é demonstrada a álgebra tensorial generalizada, sua solução e principais propriedades.
Álgebra tensorial clássica (ATC).
A álgebra tensorial clássica não é algo novo, em IWUV, havio já escreveu uma publicação sobre a mesma, no entanto com o nome de uronecker.
A ATC é utilizada quando as transições são constantes.
Ela é definida por dois operadores matriciais:
I.· N representando o conjunto dos números naturais.·
R representando o conjunto dos números reais.·
representando o subconjunto de N que contém todos os valores da até b, inclusive estes.·
representando o subconjunto de R que contém as posições da matriz do elemento a e do elemento b, inclusive estes.
Representando a multiplicação entre os elementos Será abordado primeiro o produto tensorial clássico, definido o fator normal e, em seguida a soma tensorial clássica RFIFI Produto tensorial O produto tensorial de duas matrizes A e B de dimensões e respectivamente, é uma matriz de dimensões.
Essa matriz pode ser vista como uma matriz constiuída de a1 x a2 blocos, cada um de dimensão b1 x b2.
A definição de cada um dos elementos da matriz resultante é feita levando- se em conta a qual bloco o referido elemento pertence e a sua posição interna dentro desse bloco,.
Formalmente, o produto tensorial da matriz A de tamanho nA x nA e da matriz B de tamanho nB x nB, denotada A x B é uma matriz C de tamanho nA nB x nA nB, onde C pode ser decomposta em n2 blocos de tamanho nB x nB,.
Sejam duas matrizes:
Onde:· ai, j ebi, j são os elementos das matrizes A e B;·
A x B é o produto tensorial das matrizes A e B;·
A. B é o produto convencional das matrizes A e B.·
c é o elemento da i-ésima linha do k--ésimo bloco horizontal e da l-ésima coluna do j-ésimo bloco vertical da matriz g..
C $= A x B e calculado como:
A especificação de um elemento em particular é suficiente para especificar a ocorrência de um elemento no bloco.
A especificação de um elemento na matriz pode ser escrita assim:
C53 $= a2, 1 b2, 3 está posicionado no bloco e a posição interna é 2, 3 do bloco.
O produto tensorial C $= A x B é definido algebricamente por a designação do valor ai, j.
Bk, l ao elemento de posição (k, l) do bloco (i, j).
Quando calculado o produto tensorial de uma matriz quadrada qualquer por uma matriz identidade, a esse cálculo dá- se o nome de fator normal.
Para esse cálculo existe a possibilidade de dois fatores normais, quais sejam:
Número de linhas e colunas da matriz.
Seja uma matriz.
Quando aplicado o produto tensorial de uma matriz identidade por outra matriz identidade, o resultado é uma matriz identidade de dimensão igual ao produto das dimensões das duas matrizes:
Para aplicar a soma tensorial a duas matrizes é necessário conhecer o conceito de matriz identidade.
Toda e qualquer matriz é identidade quando mi, j $= 1 se i $= j e mi, j $= 0 se i $= j e a matriz é quadrada.
A soma tensorial de duas matrizes A e B é definida como a soma convencional dos fatores normais das duas matrizes, conforme segue, A+ B $= (A x IB)+ (Ia x B) Onde:·
A e B são as matrizes quadradas A e B;·
A x B é o produto tensorial das matrizes A e B;·
A+ B é a soma tensorial das matrizes A e B;·
A+ B é a soma convencional das matrizes A e B;·
Ia e IB são as matrizes identidade da mesma ordem que as matrizes A e B respectivamente Observações:·
e soma tensorial de duas matrizes só pode ser feita em matrizes quadradas.·
O operador x (produto tensorial) tem prioridade sobre o operador+ (soma tensorial) e os dois operadores tem prioridade sobre os operadores tradicionais. (
multiplicação) e+ (adição) matrizes.
Formalmente, a soma tensorial da matriz A, de tamanho nA x nA e a matriz B de tamanho nB x nB, denotada A+ B é a matriz C, de tamanho nA nB x nA nB, definida por A x InB+ InA x B, onde InA e InB são matrizes identidades de tamanho nA e nB respectivamente,.
Sejam duas matrizes:
A soma tensorial de A e B é dada por C $= A+ B e é igual a (A x I3)+ (I2 x B) O operador Gi, j também é conhecido como operador delta de uronecker RFIFQ Propriedades da soma e do produto tensorial clássico As propriedades da álgebra tensorial clássica (ATC) para redes de autômatos estocásticos (SAN) podem ser vistas em, e são as seguintes:
Associatividade. Distributividade sobre adição clássica.
Compatibilidade com a multiplicação clássica.
Compatibilidade com a transposição de matrizes.
Compatibilidade com a inversão de matrizes.
Decomposição em fatores normais.
Distributividade com relação a a multiplicação por a matriz identidade.
Comutatividade dos fatores normais.
Em o capítulo S, podem ser acompanhadas as provas algébricas das propriedades citadas anteriormente Álgebra tensorial generalizada (ATG) O conceito de ATG é ainda novo, foi introduzida por Plateau e tem sido alvo de muitos estudos em função de a possibilidade de ser usada para modelar sistemas complexos como os de paralelismo e sincronismo.
O objetivo dessa álgebra é trabalhar com objetos que são funções discretas sobre linhas de uma matriz, ora constantes, ora funções discretas sobre os números reais.
Ermite trabalhar com um ou mais elementos que podem ter avaliações diferentes, conseqüentemente, trabalha- se com uma matriz que pode ter instâncias distintas.
A ATG é considerada uma extensão da ATC e a diferença principal entre as duas é que na ATG é introduzido o conceito de elementos funcionais.
Um elemento funcional é uma função real dos índices de linha de uma ou mais matrizes.
Um elemento funcional b é dito dependente da matriz A se algum índice de linha da matriz A pertencer a um conjunto de parâmetros desse elemento funcional.
Uma matriz que contém pelo menos um elemento funcional dependente da matriz A é dita dependente de).
Os parâmetros de uma matriz são a união dos parâmetros de todos os elementos funcionais.
A ATG é também definida por dois operadores matriciais:
I.· A (B) representando a matriz funcional A que tem como parâmetro a matriz B;·
ak representando o índice da linha k da matriz A;·
ai, j (B) representando o elemento funcional (i, j) da matriz A (B);·
ai, j (bk) representando o elemento funcional (i, j) avaliado por a linha bk;·
A (B) &quot;x «B (A) representando o produto tensorial generalizado entre as matrizes A (B) e B (A);·
A (B)&quot;+ «B (A) representando a soma tensorial generalizada entre as matrizes A (B) e B (A).
Produto tensorial generalizado Sejam duas matrizes:
Os elementos da matriz A variam em função de os elementos da matriz B e por isso denota- se A (B) e o mesmo ocorre para a matriz B, que denota- se por B (A).
O produto tensorial generalizado é definido por C $= A (B) &quot;x «B (A) e calculado como:
O produto tensorial generalizado C $= A (B) &quot;x «B (A) é definido algebricamente por a atribuição do valor ai, j (bk).
Bk, l (ai) ao elemento c, iFeF:
Exemplo prático C $= A (B) &quot;x «B (A):
Sejam duas matrizes:
Onde i, j pertence e k, l pertence O exemplo a seguir mostra o uso do produto tensorial generalizado aplicado a duas matrizes com elementos funcionais, onde, de acordo com a linha da matriz, se tem uma avaliação distinta para os elementos funcionais Em a matriz A, o valor de f varia de acordo com a posição da matriz B, conforme segue:
O mesmo é verdade para as funções da matriz B, que variam de acordo com a posição da matriz A, conforme segue:
O produto tensorial generalizado de C $= A (B) &quot;x «B (A) será:
Soma tensorial generalizada.
Para aplicar a soma tensorial generalizada a duas matrizes, assim como a soma tensorial clássica, utiliza- se o conceito de matriz identidade.
A soma tensorial generalizada de duas matrizes quadradas A e B é definida como a soma convencional dos fatores normais das duas matrizes, conforme segue:
Onde, aproveitam- se as convenções feitas até aqui· e soma tensorial generalizada de duas matrizes só pode ser feita em matrizes quadradas.·
O operador &quot;x «(produto tensorial generalizado) tem prioridade sobre o operador&quot;+ «(soma tensorial generalizada) e os dois operadores tem prioridade sobre os operadores tradicionais. (
multiplicação) e+ (adição) de duas matrizes Sejam duas matrizes:
A soma tensorial generalizada A (B)&quot;+ «B (A) é definida algebricamente por a atribuição do valor ai, j (bk).
Sejam duas matrizes:
Onde i, j pertence, k, l pertence e Gi, j $= 1 se i $= j e 0 se i $= j Exemplo prático:
Sejam duas matrizes com elementos funcionais, onde, de acordo com a linha da matriz, se tem uma avaliação distinta para os elementos funcionais.
Em a matriz A, o valor de f varia de acordo com a posição da matriz B, conforme segue:
O mesmo é verdade para as funções da matriz B, que variam de acordo com a posição da matriz A, conforme segue:
Propriedades da soma e do produto tensorial generalizados.
As propriedades da álgebra tensorial generalizada (ATG) para redes de autômatos estocásticos (SAN) podem ser vistas em e são as seguintes:
Distributividade do produto tensorial generalizado com relação a a soma convencional de matrizes.
Associatividade do produto tensorial generalizado e da soma tensorial generalizada.
Distributividade com relação a a multiplicação por a matriz identidade.
Decomposição em fatores normais.
Decomposição em produto tensorial clássico. Onde
lk (A) é a decomposição em linhas da matriz A, ou seja Demonstração algébrica das propriedades.
As provas apresentadas neste capítulo já existiam, apesar de serem encontradas em apenas uma obra.
Orém esta foi utilizada somente como base, pois para que fosse possível analisar uma nova propriedade, era necessário conhecer em detalhes as existentes.
As provas realizadas neste trabalho, foram aqui resolvidas fasso a fasso, até mesmo para buscar uma maior familiariedade com as mesmas.
Cada propriedade aqui demonstrada foi primeiro testada algébricamente.
Produto tensorial clássico x e soma tensorial clássica+ Associatividade.
Compatibilidade do &quot;x «com a multiplicação ordinária de matrizes Como pode ser observado no estudo dos formalismos, desde a criação de cadeias de Markov por o matemático Markov, muito tem- se estudado e pesquisas realizadas na obtenção de soluções para a análise de problemas de avaliação de desempenho.
De entre as técnicas pesquisadas, grande destaque tem sido dado a redes de autômatos estocásticos, pois através desta, pode- se reduzir significativamente a carga de memória para o armazenamento da matriz de transição da cadeia de Markov, que (ca armazenada em formato tensorial, logo dividida em pequenas matrizes.
O uso da álgebra tensorial permite que sejam efetuados cálculos entre as matrizes, como o produto tensorial clássico e a soma tensorial clássica, que já possuem muitas de suas propriedades básicas bem definidas e conhecidas.
A equação A (B) &quot;x «B (A) $= A (B) &quot;x «IB.
Ia &quot;x «B (A) tem sua incompatibilidade facilmente provada através da demonstração que segue.
Como pode ser observado, os blocos não diagonais da matriz D, ou seja os elementos do bloco IDH, bem como os elementos do bloco HDI, tem sua avaliação em função de elementos errados da matriz e.
Desta forma, não existe compatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes.
A partir de esta constatação, serão buscadas alternativas para tornar esta propriedade válida Estudo de alternativas A partir de a incompatibilidade, busca- se uma alternativa para a compatibilidade da multiplicação, tendo por base, permutações genéricas.
De entre as permutações serão utilizadas transposição e a simples inversão de linhas e colunas, como pode ser visto a seguir.
Por simplicidade, nas demonstrações seria adotado e (f) como e f (e) como f, pois todas as matrizes serão sempre funcionais variações da matriz e.
Para fins de testes, pegou- se a matriz A e aplicou- se a ela permutações, apresentou- se sua transposta e aplicou- se permutação também a esta transposta Para fins de testes, usaremos a diagonal invertida da matriz identidade de A e de B, simbolizadas neste trabalho por Ia e IB respectivamente.
Como tanto a matriz A quanto a matriz B possuem dois elementos, a transposta da identidade 0 1 das mesmas será:
1 0. Com base nas variações da matriz A, apresentadas no item, apresenta- se as variações possíveis da mesma aplicando- se o produto tensorial generalizado a IB Com base nas variações da matriz B, apresentadas no item, apresenta- se as variações possíveis da mesma aplicando- se o cálculo da Ia sobre as variações de B.
Com base nas variações da matriz A, apresentadas no item, apresenta- se as variações possíveis da mesma aplicando- se o cálculo da matriz A sobre as variações de IB variações da matriz.
A &quot;x «B Com base nas variações da matriz Ia apresenta- se as variações possíveis da mesma aplicando- se o cálculo da matriz Ia sobre as variações da matriz B.
As variações analisadas A partir de as variações aplicadas nas matrizes A, B e I e também nas variações aplicadas ao produto tensorial generalizado de A &quot;x «IB e Ia &quot;x «B, buscam- se alternativas para a compatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes.
A cada teste demonstrado será apresentada uma explicação que justifica a incompatibilidade do mesmo.
Para melhor entendimento destas explicações, é importante fazer algumas definições:
Quando houver referência a elementos não diagonais nos blocos, a referência será feita aos elementos representados por b e quando houver referência aos elementos diagonais nos blocos, a referência será feita aos elementos representados por y.
Onde o conjunto dos elementos b e y representam os blocos diagonais e a parte em branco representa o que será chamado de blocos não diagonais.
Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de A &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado às variações propostas para a matriz B No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «B T, pode ser observado que além de a avaliação da matriz A errada nos blocos não diagonais, também houve uma inversão dos resultados não diagonais de todos os blocos.
No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «P (B), pode ser observado que além de a avaliação da matriz A errada nos blocos não diagonais, também houve uma inversão na horizontal dos resultados de todos os elementos dos blocos.
No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «P (B T), pode ser observado que além de a avaliação da matriz A errada nos blocos não diagonais, também houve uma inversão na vertical dos resultados de todos os elementos dos blocos.
Como pode ser observado, o fato de aplicarmos permutações à matriz f não resolve o problema da incompatibilidade do produto tensorial com a multiplicação ordinária de matrizes.
No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «B os blocos não diagonais estão com sua avaliação errada, porém aplicando as diversas permutações a matriz f, além de os blocos permanecerem com suas avaliações erradas, ainda existiu uma inversão dos valores da matriz resultante, o que impossibilita a prova de compatibilidade.
Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de At &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado às variações propostas para a matriz B. O fato de aplicar a transposta da matriz e fez com que os blocos não diagonais da matriz resultante ficassem invertidos.
Oderia então ser afirmado que a inversão destes blocos seria a solução para a prova da incompatibilidade.
No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «B T, pode ser observado que além de a inversão dos blocos não diagonais, também houve uma inversão dos resultados das diagonais dos elementos de todos os blocos.
No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «P (B), pode ser observado que houve uma inversão vertical dos elementos nos blocos diagonais.
Os blocos não diagonais estão invertidos, além de haver a inversão vertical dos elementos nos blocos não diagonais.
No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «P (B T), pode ser observado que houve uma inversão horizontal dos elementos nos blocos diagonais, bem como erro de avaliação dos mesmos.
Os blocos não diagonais estão invertidos, houve a inversão horizontal dos elementos nos blocos não diagonais, bem como erro de avaliação dos elementos dos mesmos sobre as variações de Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (A) &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B, pode ser observado que houve uma inversão na horizontal dos blocos.
Além disso, a avaliação dos blocos não diagonais está errada.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B T, pode ser observado que houve uma inversão na horizontal dos blocos.
Além disso, a avaliação dos blocos não diagonais está errada.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B), pode ser observado que houve uma inversão na horizontal dos blocos.
Além disso, a avaliação dos blocos está errada tanto para a matriz e quanto para a f..
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B T), pode ser observado que houve uma inversão na horizontal dos blocos, a avaliação dos blocos está errada tanto para a matriz e quanto para a f..
O fato de aplicarmos a permutação em e, gerou erros bem mais sérios às matrizes resultantes, tornando completamente inviável a prova da propriedade da compatibilidade Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (A) T &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B, pode ser observado que houve uma inversão na horizontal dos blocos, a avaliação de todos os elementos dos blocos está errada para a matriz e.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B, pode ser observado que houve uma rotação no sentido horário nos blocos.
A avaliação de todos os elementos não diagonais dos blocos está errada para a matriz e f, bem como para os elementos da diagonal dos blocos, a avaliação da matriz e está errada.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «P (B), pode ser observado que houve uma rotação no sentido horário nos blocos.
A avaliação de todos os elementos de todos os blocos está errada para a matriz e, bem como, existe uma inversão interna na horizontal de todos os blocos.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «P (B T), pode ser observado que houve uma rotação no sentido horário nos blocos.
A avaliação de todos os elementos de todos os blocos está errada para a matriz e, bem como, existe uma inversão interna na horizontal de todos os blocos.
Também em alguns elementos, houve uma avaliação errada para a matriz f..
No caso de a multiplicação (P (AT) &quot;x «IB.
Ia &quot;x «P (B T)), houve uma inversão nos elementos não diagonais de todos os blocos.
Em este caso, houve também uma avaliação errada da matriz f somente no primeiro bloco, com os elementos não diagonais.
De todos os testes deste item, o último foi o que mais se aproximou do resultado esperado.
Em esta matriz resultante, foram então aplicadas algumas permutações, que não demonstraremos aqui, pois o resultado não chegou ao esperado Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de A &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B No caso de a multiplicação A &quot;x «I B.
Ia &quot;x «B, houve uma inversão vertical em todos os elementos dos blocos.
No caso de a multiplicação A &quot;x «I B.
Ia &quot;x «B T, houve uma rotação no sentido horário de todos os elementos dos blocos.
Em os blocos diagonais, os elementos internos não diagonais tem sua avaliação errada em relação a matriz f..
Em os blocos não diagonais, os elementos não diagonais tiveram sua avaliação errada em relação a as matrizes e f, e os elementos da diagonal tiveram sua avaliação errada em relação a matriz e.
No caso de a multiplicação A &quot;x «I B.
Ia &quot;x «P (B), houve uma inversão de todos os elementos nos blocos.
Em os blocos diagonais, os elementos internos não diagonais tem sua avaliação errada em relação a as matrizes e f..
Em os blocos diagonais, houve uma avaliação errada em relação a matriz f No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «P (B T), houve uma inversão dos elementos da diagonal dos blocos diagonais, bem como avaliação da matriz f errada.
Em os blocos não diagonais houve a mesma inversão, porém nos elementos não diagonais, a avaliação ocorreu de forma errada na matriz e, e nos elementos internos diagonais a avaliação errada em relação a as matrizes e f Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (A) &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B, houve uma inversão horizontal dos blocos.
Internamente, nos blocos, houve uma inversão na vertical dos elementos.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B T, houve uma inversão horizontal dos blocos.
Internamente, nos blocos, houve uma rotação anti-horária.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B), houve uma inversão horizontal dos blocos.
Internamente, nos blocos, houve uma inversão em diagonal dos elementos.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B T), houve uma inversão horizontal dos blocos.
Internamente, nos blocos, houve uma inversão em diagonal dos elementos.
Em todos os experimentos onde foi utilizado P (A) &quot;x «IB pode- se observar a avaliação errada de praticamente todos os elementos da matriz resultante, além de o mesmo gerar inversões imprevisíveis TFQFU Produto de At &quot;x «IB sobre as variações de Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de At &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B. No caso de a multiplicação At &quot;x «I B.
Ia &quot;x «B, houve uma inversão dos blocos não diagonais.
Internamente, nos blocos, houve uma avaliação errada da matriz f em todos os elementos da matriz resultante, além de uma inversão na vertical em todos os blocos No caso de a multiplicação At &quot;x «I B.
Ia &quot;x «B T, houve uma inversão dos blocos não diagonais.
Internamente, nos blocos, houve uma avaliação errada da matriz f em todos os elementos não diagonais da matriz resultante, além de uma rotação interna no sentido anti-horário em todos os elementos No caso de a multiplicação At &quot;x «I B.
Ia &quot;x «P (B), houve uma inversão dos blocos não diagonais.
Internamente, nos blocos, houve uma avaliação errada da matriz f em todos os elementos da matriz resultante No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «P (B T), houve uma inversão dos blocos não diagonais.
Internamente, nos blocos, houve uma inversão nos elementos não diagonais de todos os blocos da matriz.
Em os elementos não diagonais de todos os blocos houve uma avaliação errada da matriz f..
Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (AT) &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos, houve uma inversão na vertical dos elementos de todos os blocos.
Rouve erro na avaliação em relação a matriz e da matriz f em todos os elementos da matriz resultante.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B T, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos, houve uma inversão no sentido anti-horário dos elementos de todos os blocos.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «P (B), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos, houve uma inversão dos elementos diagonais de todos os blocos.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «P (B T), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos, houve uma inversão dos elementos diagonais de todos os blocos.
Em todos os experimentos com o resultado de P (AT) &quot;x «IB há uma rotação no sentido horário em todos os blocos.
Smportante observar que, neste caso, todos os experimentos geraram erro de avaliação da matriz e muitos de eles das matrizes e f Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de A &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da inversão da matriz identidade de A aplicado as variações propostas para a matriz B No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «B, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos diagonais, houve uma avaliação errada em relação a matriz e No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «B T, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, nos blocos diagonais, houve uma avaliação errada em relação a matriz e nos elementos diagonais e em relação as matrizes e f nos elementos não diagonais.
Em os blocos não diagonais, houve erro na avaliação dos elementos não diagonais em relação a matriz f No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «P (B), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, em todos os blocos houve uma rotação dos elementos no sentido horário.
Em os blocos diagonais, houve erro na avaliação de todos os elementos em relação a matriz e No caso de a multiplicação A &quot;x «IB.
Ia &quot;x «P (B T), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, em todos os blocos houve uma rotação dos elementos no sentido horário.
Em os blocos diagonais, houve erro na avaliação de todos os elementos, na diagonal em relação as matrizes e f, e nos elementos não diagonais em relação a matriz e.
Em os blocos não diagonais, houve erro de avaliação nos elementos diagonais em relação a matriz f..
Em a análise deste item, pode ser observado que quando trabalhado com a inversa da matriz f, ocorrem problemas de avaliação somente em relação a matriz e, e para ser mais exato, somente nos blocos da diagonal TFQFIH Produto de At &quot;x «IB sobre as variações de.
A &quot;x «B Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de At &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da inversa da matriz identidade de A aplicado as variações propostas para a matriz B No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «B, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, todas as avaliações dos elementos estão corretas.
Isso significa que, se conseguirmos rotacionar a matriz uma vez no sentido anti-horário, teremos a solução para a compatibilidade procurada No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «B T, houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, houve uma avaliação errada em relação a matriz f em todos os blocos nos elementos não diagonais No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «P (B), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, houve uma inversão na vertical em todos os blocos, de todos os elementos, porém a avaliação dos mesmos está correta No caso de a multiplicação At &quot;x «IB.
Ia &quot;x «P (B T), houve uma rotação no sentido horário nos blocos da matriz resultante.
Internamente, houve também uma rotação no sentido horário de todos os elementos.
Ocorreu também uma avaliação errada em relação a matriz f, em todos os blocos, nos elementos diagonais.
Deve- se prestar atenção a primeira e terceira multiplicação analisada.
Em esta, todos os elementos tem sua avaliação correta.
Em o primeiro caso, existe a necessidade de uma rotação anti-horário na matriz resultante para que houvesse algum tipo de compatibilidade.
Em o terceiro caso, além de esta rotação, também seria necessário uma inversão de colunas Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (A) &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da inversa da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B, houve uma avaliação errada em relação a matriz e em todos os elementos nos blocos diagonais.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «B T, houve uma inversão nos elementos não diagonais em todos os blocos.
Em os blocos diagonais, houve uma avaliação errada dos elementos em diagonal em relação a matriz e nos elementos não diagonais, avaliação errada em relação as matrizes e f..
Em os blocos não diagonais, houve uma avaliação errada nos elementos não diagonais em relação a matriz f..
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B), houve uma avaliação errada em relação a matriz e em todos os elementos nos blocos não diagonais.
No caso de a multiplicação P (A) &quot;x «IB.
Ia &quot;x «P (B T), houve uma rotação no sentido horário em todos os elementos da matriz.
Em os blocos diagonais, houve uma avaliação errada dos elementos não diagonais em relação a matriz e nos elementos diagonais, avaliação errada em relação as matrizes e f..
Em os blocos não diagonais, houve uma avaliação errada nos elementos diagonais em relação a matriz f TFQFIP Produto de.
A &quot;x «B Em este item serão apresentadas as multiplicações ordinárias da matriz resultante de P (AT) &quot;x «IB por os resultados obtidos através do produto tensorial generalizado da inversa da matriz identidade de A aplicado as variações propostas para a matriz B.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B, houve uma avaliação errada em relação a matriz e em todos os elementos da matriz resultante.
Em os blocos não diagonais, houve uma inversão dos elementos não diagonais.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «B T, houve uma inversão dos elementos não diagonais em todos os blocos da matriz resultante, bem como, houve uma avaliação errada em relação a matriz e em todos os elementos diagonais e em relação as matrizes e f em todos os elementos não diagonais.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «P (B), houve uma avaliação errada em relação a matriz e em todos os elementos da matriz resultante.
No caso de a multiplicação P (AT) &quot;x «IB.
Ia &quot;x «(B T), houve uma inversão dos elementos no sentido vertical em todos os elementos da matriz resultante.
Rouve também uma avaliação errada em relação a matriz e em todos os elementos não diagonais e em relação as matrizes e f, em todos os elementos diagonais Conclusão Redes de autômatos estocásticos tem sido amplamente estudadas como uma forma de modelar sistemas, uma maneira eficiente de representar sistemas com componentes interagindo entre si, como no caso de sistemas paralelos e sistemas distribuídos.
Sistemas modelados através de redes de autômatos estocásticos podem trabalhar com transições funcionais.
Em uma rede de autômatos estocásticos com transições funcionais onde não há ciclo de dependência, o sistema pode ser resolvido através da reorganização de elementos através da propriedade da compatibilidade sobre a multiplicação, conforme segue:
Quando a matriz B possui elementos funcionais dependentes da matriz A, o sistema pode ser resolvido através da decomposição:
Quando a matriz A possui elementos funcionais dependentes da matriz B, pode ser resolvido através da decomposição:
No entanto, quando há um ciclo de dependência entre as matrizes, ainda não existe outra solução senão fatiar os elementos dependentes em diversas matrizes e utilizar a álgebra tensorial clássica para resolver- las através da propriedade da decomposição em produto tensorial clássico, ou seja:
Em este caso, o produto tensorial generalizado poderá ser escrito como uma soma ordinária de produtos tensoriais.
Por exemplo, a matriz:
Em este caso, o custo computacional aumenta significativamente pois o número de matrizes a serem resolvidas é igual ao número de linhas das matrizes.
A descoberta de uma forma de compatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes elimina a necessidade, nos casos onde há ciclo de dependência, da decomposição, ou seja de tornar- la clássica, diminuindo o tempo e custo para a resolução de modelos baseados em SAN rova da incompatibilidade Com base nos conhecimentos adquiridos, fassou- se, no capítulo U, a estudar uma alternativa à distributividade do produto clássico de matrizes sobre o produto tensorial generalizado.&amp;&amp;&amp;
Até então, não havia sido encontrada nenhuma prova de compatibilidade ou incompatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes.
Especulações surgiram na área científica de que essa propriedade poderia ser provada.
O primeiro fasso, como não poderia deixar de ser neste caso, foi provar algebricamente a incomfatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes para o caso da existência de um ciclo de dependência.
Como pode ser observado no item TFI, a avaliação dos elementos da diagonal principal da matriz resultante estão corretos, porém ocorre uma avaliação errada dos elementos nos blocos não diagonais da matriz resultante.
De posse da prova de incompatibilidade, o próximo fasso foi a busca de alternativas Resultados obtidos A as matrizes A e B foram aplicadas permutações (e A, bem como, utilizou- se a transposta da matriz identidade do tamanho de A e B (TFPFQ).
Sobre essas permutações aplicou- se o produto tensorial generalizado por as respectivas identidades (TFPFR, TFPFS, TFPFT, TFPFUA, variações da matriz A &quot;x «IB multiplicadas por as variações da matriz Ia &quot;x «B.
Em a maioria dos resultados obtidos, a avaliação dos elementos da matriz A aparece errada em relação a matriz B, o mesmo podendo ser dito dos elementos da matriz B em relação a matriz).
De os resultados obtidos, dois chamam a atenção para possíveis soluções, quais sejam:
UFPFI Produto tensorial generalizado da transposta de produto tensorial generalizado de A por IB multiplicado por o.
O fato de ser usada a transposta da matriz A fez com que os blocos não diagonais da matriz resultante ficassem invertidos, porém as avaliações tanto da matriz A quanto da matriz B estão UH corretas.
Isso significa dizer que se encontrada uma solução matemática ou uma solução algorítmica para a inversão dos blocos, estaria aqui a solução para o problema da incompatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes UFPFP Produto tensorial generalizado da transposta de produto tensorial generalizado da inversa de A por IB Ia por B multiplicado por o.
O fato de ser usado a transposta da matriz A e a transposta da matriz Ia fez com que houvesse uma rotação no sentido horário nos blocos da matriz resultante, porém as avaliações tanto da matriz A quanto da matriz B estão corretas.
Isso significa dizer que se encontrada uma solução matemática ou uma solução algorítmica para uma rotação no sentido anti-horário ou três rotações no sentido horário com os blocos da matriz resultante, estaria aqui a solução para o problema da incompatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes.
É importante salientar que essa matriz resultante será resolvida como um sistema de equações lineares, ou seja, não é possível simplesmente inverter blocos fiUFPA ou rotacionar- la fiUFQA, pois isso alteraria o resultado final Trabalhos futuros Todo o trabalho, seja ele de qualquer espécie, deve ter um início, meio e fim.
O fim de um trabalho pode e deve ser o início de outro, o que constitui a perpetuação de um estudo e evolução constante.
Esse trabalho não termina aqui, pois muito mais do que demonstrar a incompatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes, constrói uma base de informações indicando que no caso de a álgebra tensorial generalizada, o fato de serem aplicadas somente permutações não resolve o problema de avaliações erradas sobre matrizes como vinha sendo cogitado até então.
Dando continuidade ao estudo da álgebra tensorial generalizada, pernandes, Plateau e Stewart, em IWWV, provaram que utilizando- se de fatores normais e reorganizando os elementos da matriz consegue- se resolver redes de autômatos estocásticos com elementos funcionais quando não houver ciclo de dependência entre as duas matrizes.
Para isso utiliza- se a propriedade da compatibilidade da multiplicação, conforme demonstram as fórmulas UFI e UFP.
Em este mesmo estudo, esta propriedade foi generalizada, para que pudesse ser aplicada em qualquer SAN que não tivesse ciclo de dependência.
O próximo fasso para a continuidade deste trabalho, acreditamos ser a procura de soluções matemáticas e algorítmicas para a inversão e rotação de blocos destas matrizes resultantes para então sim, afirmar e provar a compatibilidade desejada.
A tendência é, a partir de a prova desejada, poder generalizar também essa solução, seguindo a linha de pesquisa utilizada por pernandes, Plateau e Stewart.
Essa pesquisa é bem mais ampla e complexa, pois busca a otimização da solução para redes de autômatos estocásticos com elementos funcionais quando houver ciclo de dependência entre as duas matrizes, com a utilização de métodos iterativos, contribuindo para a evolução e otimização da ferramenta PEPS (Performance evaluation of parallel Systems) sgualmente, é uma seqüência natural buscar soluções para que possam ser aplicados métodos diretos de resolução de sistemas lineares sobre estas matrizes em formato tensorial, por exemplo a decomposição vFU, agilizando e solucionando qualquer tipo de SAN por um outro conjunto de métodos além de os métodos iterativos já conhecidos.
