A resolução de Sistemas de Equações Lineares é um problema de grande importância em Ciência da Computação.
Entretanto, os métodos tradicionais não oferecem garantia de soluções corretas e nem mesmo da existência de uma solução.
Por isso, cada vez mais tem- se aplicado a Computação Verificada em tais algoritmos.
Por outro lado, a Computação Verificada aumenta o custo computacional e, em alguns casos, impossibilita a resolução dos sistemas num tempo aceitável.
Uma alternativa encontrada para minimizar o custo é a utilização de Computação Paralela.
Diversos trabalhos têm focado em otimizar a Computação Verificada para execução em agregados de computadores.
Entretanto, dado o grande avanço dos processadores com múltiplos núcleos de processamento (cores), é uma necessidade premente que sejam também propostas soluções baseadas em modelos de paralelismo para memória compartilhada buscando, assim, explorar eficientemente as novas arquiteturas.
Em esse contexto, o presente trabalho apresenta uma ferramenta para resolução verificada de Sistemas Lineares Densos Intervalares de Grande Porte.
Além de prover verificação automática dos resultados, a ferramenta é otimizada para execução em arquiteturas multicore.
As estratégias adotadas permitiram desenvolver uma solução escalável que, ao resolver Sistemas Intervalares de ordem 15.000x15.
000 num computador com 8 cores, obteve redução de 85% no tempo de execução e speedup de 6,70 em comparação com a solução inicial.
Palavras-chave: Computação Verificada;
Sistemas Lineares Intervalares;
Multicore. Diversos problemas podem ser modelados através de Equações Diferenciais (EDs) e Sistemas de Equações Lineares Algébricas (Selas).
Uma ED é definida num conjunto infinito de pontos, ou seja, num espaço contínuo.
Porém, para que possa ser resolvida computacionalmente, faz- se necessário discretizar- la (criar um espaço discreto e finito), processo esse que implica na resolução de Selas.
De essa forma, a resolução de Selas assume papel de extrema importância para as mais variadas áreas do conhecimento.
Um Sistema Linear é tipicamente expresso na forma Ax $= b, em a qual A é uma matriz formada por os coeficientes, x é o vetor das incógnitas do sistema e b é o vetor dos termos independentes.
O sistema é composto por n equações com n incógnitas e, quando empregado na modelagem de problemas ou discretização de EDs, o valor de n costuma ser na ordem dos milhares.
Selas podem ser densos ou esparsos.
Um Sistema Esparso é aquele em que 80% ou mais dos coeficientes das incógnitas nas equações são nulos, enquanto os densos possuem coeficientes não nulos para mais de 20% das variáveis.
Por fim, sistemas cujo valor de n é elevado são ditos de grande porte.
Dada sua complexidade, a resolução de Selas de grande porte requer, na prática, a utilização de ferramentas computacionais e, com frequência, de Computação Paralela de Alto Desempenho.
No entanto, em Ciência da Computação a garantia de que um algoritmo foi testado e está correto não implica, necessariamente, que o resultado computado por ele será correto.
Frequentemente, um computador digital produz resultados incorretos para problemas numéricos, não devido a erros de programação ou ao uso de hardware não confiável, mas, simplesmente, por serem máquinas discretas e finitas que não conseguem tratar alguns dos aspectos contínuos e infinitos da pode causar grandes problemas, pois o Matemática.
Até mesmo um número simples como 10 computador não é capaz de executar cálculos exatos com o mesmo.
Isso ocorre porque a fração não possui representação finita exata na notação binária.
Em tais situações, decimal 10 os computadores aproximam, através de frações finitas, os números reais originalmente expressos por frações decimais infinitas.
Essa diferença entre o valor exato e o aproximado é dita erro de arredondamento,.
Assim, os métodos numéricos que utilizam Aritmética de Ponto Flutuante tradicional oferecem apenas uma aproximação do resultado e, uma vez que o resultado exato é desconhecido, não é possível saber quão boa é essa aproximação.
Já a Computação Verificada permite ao computador determinar se o resultado encontrado é correto e/ ou útil.
De posse dessa informação, é possível optar por um algoritmo alternativo, repetir a computação utilizando maior exatidão ou informar ao usuário quando o resultado não é válido.
Logo, uma execução de um algoritmo auto-validado fornece resultados com uma garantia que não pode ser oferecida mesmo por milhões de execuções com ponto flutuante tradicional.
Adicionalmente, muitas vezes tais técnicas permitem ao computador estabelecer a existência e unicidade da solução.
Portanto, a verificação automática dos resultados é de suma importância na redução do impacto dos erros de aritmética na Computação Numérica.
A Computação Verificada emprega a Aritmética Intervalar que, por sua vez, define as operações aritméticas básicas através de números intervalares (intervalos numéricos).
Além de viabilizar a aplicação prática da Computação Verificada, outro grande benefício da Aritmética Intervalar é permitir trabalhar- se com os Sistemas Lineares Intervalares, ou seja, sistemas em que os valores contidos em A e b são intervalos ao invés de números pontuais.
Tais sistemas têm adquirido cada vez mais importância científica por permitirem a representação de dados incertos, ou seja, aqueles em que os instrumentos empregados para sua obtenção apresentam variações e imperfeições ou em que a modelagem não é exata, de entre outros.
Em princípio, a resolução verificada desses Selas implicaria na necessidade de resolver um número infinito de matrizes contidas num intervalo.
Entretanto, por ser esse um problema Np-Completo, o que acontece na prática é a computação de um intervalo estreito o qual contém tais matrizes.
Uma estratégia, para tal, é obter soluções aproximadas de Sistemas Lineares Pontuais, ou seja, aqueles cujas equações são formadas por números pontuais, com o auxílio de bibliotecas matemáticas otimizadas, tais como o LINPACK, LAPACK (Linear Algebra PACKage), ou ScaLAPACK (SCAlable Linear Algebra PACKage), e, a partir de a solução aproximada, calcular os limites que constituem o intervalo em o qual a solução reside.
Bibliotecas como LAPACK e ScaLAPACK fazem uso de Computação Paralela visando otimizar a resolução dos mais variados problemas de Álgebra Linear.
Entretanto, mesmo com a utilização dessas bibliotecas de software otimizadas, a resolução de Selas continua apresentando grande custo computacional quando se tratando de Sistemas de Grande Porte.
O custo torna- se ainda maior ao considerar Sistemas Lineares Intervalares.
Além disso, as bibliotecas otimizadas disponíveis atualmente para Álgebra Linear não oferecem suporte à resolução de Sistemas Intervalares, bem como não suportam resolução verificada mesmo de Sistemas Pontuais.
As bibliotecas puramente de Computação Verificada, por outro lado, embora permitam a resolução verificada e, em alguns casos, deem suporte aos Sistemas Intervalares, acabam transformando- se num gargalo na aplicação por requererem uma grande quantidade de operações adicionais.
A ferramenta de Computação Verificada mais popular no mundo hoje é o C-XSC (C for eXtended Scientific Computing).
Visando equilibrar esse cenário, diversos trabalhos têm sido desenvolvidos combinando algoritmos de Computação Verificada com técnicas da Computação Paralela.
Em geral, tais trabalhos são voltados aos agregados de computadores (clusters) e empregam, por exemplo, a biblioteca MPI (Message Passing Interface) em conjunto com o ScaLAPACK.
Basicamente, utilizam- se as bibliotecas otimizadas para acelerar alguns trechos específicos dos algoritmos de Computação Verificada.
Entretanto, nos últimos anos muitas modificações vêm ocorrendo na Computação de Alto Desempenho.
Os processadores atingiram frequências de clock bastante próximas do limite suportado por as atuais tecnologias, o que tem dificultado crescimento maior de sua velocidade, pois o aumento da frequência dos clocks tornou- se um esforço com custos muito elevados e ganhos, proporcionalmente, muito baixos.
Diante de isso, a solução encontrada por as fabricantes tem sido empacotar diversos processadores num único, criando os chamados processadores multicore.
Esse processo deu início à popularização das arquiteturas paralelas entre os usuários domésticos e pequenos laboratórios.
Em complemento, sabe- se que os fenômenos naturais são inerentemente paralelos, logo, é natural expressar as computações relativas aos mesmos de forma paralela, pois, em algumas situações, a ordem de execução é importante para o melhor entendimento do problema real, mesmo que em outras ela seja irrelevante.
Assim, a adaptação das soluções da Computação Verificada para esse novo nicho de arquiteturas é de grande interesse.
Em esse contexto, o presente trabalho foi concebido visando desenvolver um solver (ferramenta computacional para resolução) de Selas Intervalares Densos de Grande Porte que execute a verificação automática dos resultados e seja otimizado para execução escalável em arquiteturas com processadores multicore.
Trabalhos Relacionados Existem diversos trabalhos que combinam a Computação Verificada e a Computação Paralela na resolução de Selas para, respectivamente, gerar resultados validados e obter um tempo de execução não impeditivo.
Alguns desses, como e, operam Sistemas Lineares do tipo pontual enquanto outros, como, resolvem Sistemas Lineares Intervalares.
Duas ferramentas estado da arte para Sistemas Intervalares Densos de Grande Porte são apresentadas em e em.
Em ambos os casos os autores obtiveram resultados satisfatórios, tanto em relação a a qualidade das soluções computadas quanto a o tempo de execução das ferramentas em agregados de computadores.
O trabalho desenvolvido em apresenta uma nova abordagem para o cálculo do produto escalar ótimo, algoritmo em o qual se baseia o C-XSC.
Os autores apresentam também uma versão da solução paralelizada para agregados de computadores.
Seu resultado final é um solver voltado a Sistemas Lineares Intervalares Densos de Grande Porte.
Já o trabalho desenvolvido em emprega a Aritmética Intervalar do tipo Ponto-Médio e Raio e um algoritmo baseado no Método de Newton, o qual será visto no Capítulo 3, para a resolução de Sistemas Intervalares Densos.
Assim como em, os autores utilizaram a PBLAS e ScaLAPACK para implementação de uma versão paralela da ferramenta voltada a ambientes heterogêneos com troca de mensagens.
Motivação A necessidade original de alto desempenho em Computação Numérica veio de uma série de contextos envolvendo equações diferenciais parciais, como dinâmica de fluidos, previsão do tempo, processamento de imagens entre outros.
Porém, em decorrência dos grandes avanços da computação nos últimos anos, mesmo para problemas menores os usuários têm se tornado mais exigentes desejando simular modelos maiores, mais precisos e multidimensionais, além de integrar problemas que antes eram simulados separadamente.
As EDs e os Selas estão entre as ferramentas matemáticas mais utilizadas nesses casos e sua resolução em tempo adequado somente é viável com ferramentas da Computação Paralela.
Sabe- se hoje que muitas das estratégias criadas para otimização dos algoritmos da Álgebra Linear Densa, como no LAPACK, por exemplo, levaram a ideias e mecanismos que influenciaram positivamente outras categorias de algoritmos paralelos.
Portanto, o desenvolvimento de projetos combinando problemas da Álgebra Linear (como a resolução de Selas) com Computação Paralela é um trabalho com motivações em ambas as disciplinas.
Por um lado, a Computação Paralela contribui com as mais variadas áreas do conhecimento, pois permite executar simulações em tempo viável e, por outro, essas áreas apresentam situações que levam a algoritmos genéricos o bastante a ponto de influenciar positivamente diversas outras aplicações da Computação Paralela.
A aplicação da Computação Verificada em tais algoritmos tem duas motivações principais.
A primeira é controlar os erros de arredondamento, de modo a oferecer resultados corretos e confiáveis.
A segunda é permitir a resolução de Sistemas Lineares Intervalares visando dar suporte a problemas que operam com dados incertos e/ ou imprecisos.
Por fim, a proposta de uma solução que explore o paralelismo em processadores multicore justifica- se não apenas por o contexto mercadológico atual, mas também por suas tendências futuras.
A grande popularização das arquiteturas multicore torna a ferramenta acessível para uma infinidade de públicos, diferentemente daquelas desenvolvidas para aglomerados de computadores.
Ademais, mesmo os aglomerados atuais vêm sendo construídos utilizando processadores multicore em seus nós.
Em esse contexto, a exploração do paralelismo no nível atual não é suficiente para tirar proveito de todas as características das novas máquinas, demonstrando a necessidade de aplicar técnicas específicas de programação e, ao mesmo tempo, mesclar- las com as estruturas de softwares já existentes.
Objetivos O objetivo central do presente trabalho é desenvolver uma ferramenta computacional para resolução de Selas Intervalares Densos de Grande Porte com verificação automática dos resultados otimizada para execução em arquiteturas multicore.
Essa ferramenta deverá ser capaz de prover resultados verificados para Sistemas Lineares em que os dados contidos nas matrizes e vetores são intervalos ao invés de números pontuais.
Tal implementação deverá tirar proveito das características presentes nas arquiteturas dotadas de processadores multicore visando ganhos de desempenho de modo que seu tempo de execução seja satisfatório para o usuário.
Objetivos secundários aparecem como consequência da metodologia adotada, tais como:
Investigar a resolução de Selas Densos de Grande Porte;
Realizar estudos comparativos da Aritmética Intervalar;
Estudar as arquiteturas de memória compartilhada;
Explorar a programação multithread;
Organização do Trabalho Esta Dissertação está dividida em seis capítulos, sendo o primeiro de eles a presente introdução.
O restante está organizado da seguinte forma:
Algoritmos para Álgebra Linear de Alto Desempenho.
Por fim, algumas das bibliotecas mais utilizadas para essa finalidade são apresentadas;
A compreensão do inter-relacionamento entre as características de um algoritmo paralelo e aquelas da arquitetura sobre a qual ele irá executar é fundamental para a obtenção de alto desempenho.
Em as três últimas décadas, diversos algoritmos e softwares para resolução de problemas da Álgebra Linear têm sido desenvolvidos visando alto desempenho e portabilidade.
O resultado mais importante neste contexto foi o desenvolvimento da biblioteca BLAS (Basic Linear Algebra Subprograms), que é utilizada como núcleo para desenvolvimento dos mais populares pacotes de software para Álgebra Linear.
Em este capítulo, serão inicialmente abordados aspectos gerais das arquiteturas dotadas de processadores multicore.
Em a sequência, discute- se a Álgebra Linear de Alto Desempenho focando sua programação em arquiteturas multicore.
Por fim, a biblioteca BLAS e os pacotes mais populares para Álgebra Linear de Alto Desempenho são apresentados.
Arquiteturas Multicore O paralelismo, atualmente, está presente em todos os níveis da Computação indo desde o paralelismo de instruções num pipeline, passando por os processadores multicore, colocados como solução para o problema de limitação no crescimento do clock, até sistemas distribuídos de larga escala como as grades computacionais.
Em os últimos 20 anos, os fabricantes de microprocessadores exploraram altos graus de Instruction Level Parallelism (ILP).
Baseando- se nisso, muitas gerações de processadores foram construídas aumentando- se cada vez mais a frequência do clock e com pipelines cada vez mais profundos.
As aplicações beneficiavam- se naturalmente dessas inovações e, como consequência, para atingir maior desempenho bastava simplesmente delegar aos compiladores a exploração eficiente do ILP.
Porém, devido a vários fatores, em especial às limitações físicas, tornou- se necessário alterar o foco do paralelismo do ILP para o TLP (Thread Level Parallelism).
Em esse, o ganho de desempenho é alcançado através da replicação das unidades de execução (cores) ao passo que se mantêm os clocks numa faixa em a qual o consumo de energia e dissipação de calor são menores e, portanto, menos problemáticos.
Ao longo de os anos, diversas foram as tentativas de desenvolver compiladores paralelizantes.
Entretanto, esses se demonstraram úteis apenas em algumas classes restritas de problemas.
Assim, no contexto dos computadores multicore, não é possível fundamentar- se apenas nos compiladores para obter ganhos de desempenho.
Faz- se necessário reescrever as aplicações de modo a tirar proveito do paralelismo de granularidade fina.
Embora a obsolescência dos paradigmas tradicionais esteja ocorrendo de maneira bastante rápida, não há, ainda, uma alternativa bem compreendida a qual possa ser utilizada como base única para os desenvolvedores.
Diferentemente das premissas adotadas em modelos anteriores, os núcleos de um processador multicore não podem ser considerados independentemente, ou seja, arquiteturas multicore não devem ser vistas como novas SMP (Symmetric Multiprocessor).
Isso porque, tais núcleos compartilham recursos intra-chip (inclusive múltiplos caches e TLB (Translation Lookahead Buffer), o que não ocorria com os múltiplos processadores independentes,.
Essa situação tende a ser agravada considerando que se espera, futuramente, ter uma variedade de combinações de componentes, como a mistura de diferentes núcleos, aceleradores de hardware e sistemas de memória diversificados.
Os autores de,, apontam alguns fatores como causas desse aumento:·
&quot;Mais transistores e clocks mais lentos&quot;: Tal abordagem tende a elevar o número de cores nos processadores e, por consequência, a quantidade de paralelismo requerido.
Modelos baseados em pipelines profundos e estreitos tendem a perder espaço para os designs baseados em pipelines rasos e amplos.
Com isso, para extrair desempenho dos multicores, os programadores terão de explorar um nível maior de paralelismo, ou seja, explorar- lo em nível de múltiplos threads (thread-level parallelism (TLP)).
Serão necessários, para tal, mecanismos mais eficientes de comunicação entre os processadores e de sincronização para melhorar o gerenciamento dos recursos.
De essa forma, a abordagem adotada por os designs superescalares, em a qual a complexidade do paralelismo era mascarada em hardware por uma combinação de paralelismo crescente em nível de instrução (ILP) e pipelines profundos e estreitos, deixa de ser satisfatória.
Necessita- se, portanto, que o paralelismo seja explorado em software.·
&quot;Muro de memória mais espesso&quot;: A eficiência na comunicação tende a se tornar cada vez mais essencial.
Os pinos que conectam processador e memória principal transformaram- se num gargalo devido a o crescimento do número de pinos e à queda da largura de banda por pino.
Assim, estima- se que a lacuna de desempenho existente entre processador e memória, a qual já é de aproximadamente mil ciclos, cresça em torno de 50% por ano.
Adicionalmente, estima- se que o número de cores num único chip duplicará a cada 18 meses.
Uma vez que as limitações de espaço físico inibirão o crescimento dos recursos de cache na mesma proporção, a quantidade de cache por core tende a diminuir cada vez mais.
Com isso, pode- se esperar aumento significativo em problemas como largura de banda da memória, latência de memória e fragmentação de cache.·»
Limitações dos processadores commodity devem aumentar a heterogeneidade e complexidade dos sistemas&quot;:
Sabe- se que, por motivos econômicos, os sistemas petascale serão construídos com processadores commodity of- the- shelf (de prateleira).
Infelizmente, as arquiteturas de propósito geral não são capazes de atingir as características requeridas por as aplicações de pesquisa de ponta.
Consequentemente, em adição aos diferentes níveis de multithreading que os sistemas multicore deverão explorar (nível de core, de socket, de placa e nível de memória distribuída), os mesmos deverão, também, incorporar uma diversidade de elementos de processamento para uso específico, tais como GPUs (Graphics Processing Unit), FPGAs (Field Programmable Gate Array), de entre outros.
Tal heterogeneidade incrementará ainda mais complexidade de controle e programação.
Uma vez que os designs oferecidos hoje por os fabricantes já divergem entre si e que configurações de hardware heterogêneas já podem ser facilmente encontradas, não se pode esperar obter uma categoria de arquitetura comum para a qual desenvolver os modelos de programação futuros.
Embora ainda não se tenha claro quais as estratégias futuras que os fabricantes utilizarão para manter o crescimento do número de núcleos, é possível identificar algumas propriedades que os algoritmos deverão apresentar para alcançar níveis mais altos de TLP:·
Granularidade fina:
Os cores são e, provavelmente, continuarão sendo associados com memórias locais relativamente pequenas.
Assim, deve- se reorganizar as operações em tarefas que operem sob pequenas porções de dados para reduzir o tráfego no barramento e aumentar a localidade de dados.·
Não sincronismo:
Uma vez que o grau de TLP cresce e a granularidade diminui, a presença de pontos de sincronização numa execução paralela afeta seriamente a eficiência de um algoritmo.
Deve- se, portanto, evitar- los.
Álgebra Linear de Alto Desempenho Embora a descontinuidade introduzida por as novas arquiteturas vá ser ubíqua, diversos autores como argumentam que há razões para focar- se os esforços em problemas da Álgebra Linear em geral e da Álgebra Linear Densa dada sua importância em diversas aplicações da Ciência da Computação.
Além disso, argumentam que, como tais problemas já são bastante conhecidos e estudados, tem- se um embasamento que cria vantagem estratégica para os esforços de pesquisa, uma vez que já se sabe exatamente como seus algoritmos funcionam e onde podem ser alterados.
Outro ponto exposto por tais autores é que as técnicas de Álgebra Linear são genéricas o suficiente para que os ganhos obtidos com seus estudos possam ser, posteriormente, aplicados a outras áreas, como ocorreu no desenvolvimento do LAPACK.
De acordo com a exploração eficiente do paralelismo nas operações da Álgebra Linear em arquiteturas multicore apresenta dois requisitos básicos:
Granularidade fina e operações assíncronas.
De fato, as técnicas que vêm apresentando melhores resultados em tais arquiteturas são a exploração do paralelismo em nível de tarefas, redução dos TLB (translation lookahead buffer) misses e escalonamento dinâmico de operações com execução fora de ordem, ou seja, de maneira semelhante a um pipeline superescalar,.
Adicionalmente, é um fato bem estabelecido que a técnica de execução com adiantamento/ antecipação de operações (look ahead), possível devido a a execução fora de ordem, pode ser utilizada para aumentar significativamente o desempenho na fatoração de matrizes.
Sabe- se, também, que outro fator de grande importância na Computação Paralela é o particionamento dos dados.
Determinar o esquema mais adequado para divisão dos dados num algoritmo influência diretamente o desempenho do programa paralelo.
Em os cálculos com matrizes os dois métodos mais utilizados são o particionamento por faixas (striped partitioning) e o particionamento por submatrizes (checkerboard partitioning).
Tais métodos subdividem- se ainda de duas maneiras:
Distribuição por blocos e distribuição cíclica.
As figuras 2.1, 2.2, 2.3 e 2.4 ilustram essas o funcionamento dessas distribuições.
Em o desenvolvimento do LINPACK não houve preocupação com a movimentação dos dados por a memória.
Já no LAPACK e ScaLAPACK organizou- se os algoritmos visando que os mesmos se beneficiassem da hierarquia de memória ao diminuir o máximo o movimento dos dados por ela.
Utilizou- se, para tal, o particionamento por submatrizes com distribuição cíclica.
A Figura 2.5 ilustra uma divisão típica da hierarquia de memória nos computadores modernos.
Em os autores afirmam que um nível intermediário, o espaço de endereçamento acessível ao TLB, deve ser considerado entre os caches L1 e L2.
Em arquiteturas multicore, no entanto, a literatura vem apontando que o particionamento por submatrizes com distribuição cíclica não é o método mais eficiente.
A maior limitação para execução das computações de granularidade fina é que a BLAS geralmente tem desempenho bastante ruim para blocos pequenos de dados.
Essa situação pode ser melhorada armazenando- se as matrizes em pequenos blocos ao invés de utilizar o column major format, formato padrão de armazenamento do FORTRAN, e, então, cada bloco contiguamente no formato column major.
Como resultado tem- se um padrão mais regular de acesso à memória e o desempenho da BLAS é consideravelmente melhorado.
SuperMatrix, bem como alguns exemplos de sua aplicação com resultados bastante satisfatórios, são apresentados em e.
Uma opção para facilitar a manipulação das matrizes constituídas por blocos de submatrizes é a Flash API.
Os autores da Plasma, descrita no próximo capítulo, vêm seguindo as mesmas estratégias anteriormente citadas bem como a abordagem do SuperMatrix.
Em os autores apoiam a ideia de que a quebra das operações em pequenas tarefas reduz o tráfego no barramento e tira melhor proveito da localidade de dados.
Em relação a o escalonamento fora de ordem e o não sincronismo, os autores observam que isso permite amenizar o problema da latência no acesso à memória.
Adicionalmente, é apresentada a necessidade de reformular os algoritmos utilizados por o LAPACK e ScaLAPACK e coloca- se como alternativa a utilização de DAGs (Direct Acyclic Graph) onde os nodos representam tarefas e as arestas as dependências entre elas.
Um grafo acíclico dirigido é um grafo dirigido sem ciclos, isto é, para qualquer vértice v, não há nenhum caminho dirigido começando e acabando em v..
Seja G $= (N, A) um DAG, onde N $= a ser feita por o algoritmo e os arcos representam as dependências de dados.
Em particular, um arco (i, j) A indica que a operação correspondente ao nó j usa o resultado da operação correspondente ao nó i.
As operações podem tanto ser elementares, como a adição de dois escalares, quanto operações de alto nível, como a execução de uma subrotina.
Os algoritmos propostos em recebem o nome de tiled algorithms.
A divisão dos dados em pequenos blocos quadrados de colunas contíguas é defendida, ou seja, uma divisão por subma-trizes em blocos.
Por fim, os autores atentam para o balanceamento de carga e de tarefas os quais devem ser cuidadosamente implementados de modo que a escalabilidade não seja comprometida.
O trabalho apresentado em aplica a Computação Paralela reorganizando o código e dados de forma a tirar proveito das novas arquiteturas paralelas como Em uma (Non-Uniform Memory Access) dotadas de processadores multicore.
Em esse caso o autor desenvolveu um sistema que paraleliza operações sob matrizes para arquiteturas multicore considerando- as como blocos hierárquicos que servem como unidades de dados sob as quais as operações, vistas como unidades de requisitadas e verifica internamente as dependências para, então, executar- las na melhor ordem possível.
Tal ideia assemelha- se aos pipelines de micro arquiteturas superescalares.
Esse trabalho e, principalmente, o desenvolvimento da biblioteca Plasma confirmam a tendência mundial de desenvolvimento de softwares para Álgebra Linear de Alto Desempenho voltados aos novos nichos de arquiteturas.
Bibliotecas e Pacotes de Software Esta seção apresenta, inicialmente, a biblioteca BLAS.
Após, alguns dos pacotes de software para Álgebra Linear construídos com base nessa são abordados.
A BLAS (Basic Linear Algebra Subprograms) surgiu como resultado de um acordo para especificar um conjunto de operações básicas de Álgebra Linear que foi implementado originalmente em FORTRAN 66 e, após, FORTRAN 77.
Com o passar dos anos, implementações de referência para FORTRAN 95 e C foram publicadas.
A BLAS se tornou a biblioteca de Álgebra Linear mais utilizada mundialmente, pois, além de seu bom desempenho, o fato de desenvolver softwares em torno de um núcleo comum é visto como uma boa prática de Engenharia de Software.
A BLAS original executa operações entre escalares e vetores.
Sua descrição completa está disponível em e complementada por.
Com o surgimento das máquinas vetoriais, das máquinas com hierarquia de memória e das arquiteturas de memória compartilhada, surgiu a necessidade de softwares para exploração adequada de tais arquiteturas.
Assim, uma extensão da BLAS original (hoje conhecida como Level 2 BLAS) foi proposta em para execução de operações entre vetores e matrizes.
Em os autores apresentam um implementação modelo da Level 2 BLAS em FORTRAN 77 e também um conjunto de programas para teste.
Entretanto, frequentemente a Level 2 BLAS não se adaptava bem aos computadores com hierarquia de memória cujo processamento era de fato paralelo.
Em esse contexto, foi proposta na Level 3 BLAS para execução de operações de matrizes com matrizes.
Tais operações são executadas em blocos permitindo, assim, reuso dos dados enquanto um bloco encontra- se na cache ou na memória local, o que evita movimentação excessiva dos dados por a hierarquia de memória,. Como
exemplo das operações executadas por a Level 1 BLAS tem- se o cálculo do produto interno de um vetor.
Tais operações envolvem complexidade de dados da ordem O (n) e custo computacional também da ordem de O (n).
Em a Level 2 BLAS, as operações envolvem custo computacional de O n2 com complexidade de dados também de O n2.
Um exemplo de operação realizada neste nível é o produto entre um vetor e uma matriz.
Por fim, na Level 3 BLAS, a complexidade de dados é de O n2 e o custo computacional da ordem de O n3.
Como exemplo, pode- se citar a multiplicação de duas matrizes.
As ordens de complexidade das operações são o fator responsável por a adoção dos nomes Level 1, 2 e 3.
Em o contexto do presente trabalho, a Level 3 BLAS é a de maior interesse.
Esse nível possui 81 diferentes combinações as quais se tratam tanto de rotinas em alto nível da Álgebra Linear quanto de operações elementares para construção dessas rotinas.
Os algoritmos da Level 3 BLAS foram originalmente implementados para auxiliar o desenvolvimento de procedimentos em termos de operações em submatrizes ou blocos.
Diversos trabalhos comprovaram a efetividade dos algoritmos em blocos da Level 3 BLAS para uma variedade de arquiteturas, em as quais o desempenho decai fortemente com o excesso de movimentação dos dados na hierarquia de memória.
As Level 2 e Level 3 BLAS armazenam as matrizes na memória na forma de vetores bi-dimensionais,.
A implementação de referência da BLAS está disponível livremente na Internet.
Entretanto, a maioria dos fabricantes de computadores oferece versões proprietárias dessas rotinas otimizadas para suas arquiteturas.
Essas, em alguns casos, encontram- se disponíveis gratuitamente enquanto em outros é necessário adquirir licenças para utilização.
De entre as mais populares pode- se citar:
AMD Core Math Library -- ACML -- implementação multithread da AMD disponibilizada gratuitamente e otimizada para execução em processadores Opteron;
Apple Velocity Engine -- versão da Apple embarcada nos processadores G4 e G5 que expande a arquitetura PowerPC através da adição de uma unidade de execução vetorial de 128 bits que opera paralelamente dados inteiros e de ponto flutuante.
Em o momento em que os computadores Apple passaram a ser construídos com processadores Intel, tal tecnologia foi incorporada por o recurso Intel's Streaming SIMD Extensions (SSE);
Hp's Mathematical Software Library -- MLIB -- implementação da Hp disponível para os sistemas Hp-UX, desde servidores com um único processador até os mais robustos com múltiplos processadores como Superdome, otimizada para os processadores Hp PA-RISC 2.0 e Intel Itanium 2;
Intel Math Kernel Library -- MKL -- implementação da Intel otimizada para arquiteturas dotadas de processadores Xeon, Core i7, Itanium, Pentium e família Core em geral.
Possui implementações sequenciais das rotinas, altamente otimizadas apenas em nível de instruções, e versões multithread.
Além disso, existem ainda disponíveis gratuitamente na Internet diversas implementações alternativas da BLAS construídas sob diferentes abordagens tais como a Atlas (Automatically Tuned Linear Algebra Software), e a Goto BLAS.
Tanto a Goto BLAS quanto a Atlas e a grande maioria das implementações proprietárias da BLAS emprega recursos de multithread.
Cabe, ainda, observar a existência de uma versão paralela da BLAS para agregados de computadores, a PBLAS (Parallel Basic Linear Algebra Subprograms).
Surgida inicialmente como PB-BLAS (Parallel Block Basic Linear Algebra Subprograms), a PBLAS está disponível para qualquer sistema com suporte a MPI (Message Passing Interface) ou PVM (Parallel Virtual Machine).
A PBLAS foi construída utilizando como base a versão sequencial da BLAS e a biblioteca BLACS (Basic Linear Algebra Communication Subprograms), uma biblioteca desenvolvida para facilitar o desenvolvimento de programas de Álgebra Linear em ambientes com troca de mensagens.
Os trabalhos relacionados apresentados no início desta Dissertação foram implementados com a PBLAS.
Entretanto, como o presente trabalho é focado em processadores multicore, somente versões sequenciais e multithread da BLAS tradicional foram empregadas.
A seguir, são apresentados os pacotes de software mais populares para Álgebra Linear de Alto Desempenho.
Tais pacotes são implementados com emprego da BLAS e foram desenvolvidos ao longo de as últimas décadas de modo a acompanhar as constantes evoluções das novas arquiteturas de hardware.
O LINPACK é um pacote criado para os supercomputadores utilizados nos anos 70 e começo dos anos 80.
Consiste numa coleção de programas para resolução de Selas.
Suas rotinas são escritas em FORTRAN e resolvem os sistemas através da abordagem decomposicional da Álgebra Linear, ou seja, dada uma matriz A, decompõe- se a mesma num produto de outras matrizes mais simples e bem estruturadas, as quais podem ser facilmente manipuladas para resolver o problema original.
Foi desenvolvido de modo a executar as operações de ponto flutuante através de chamadas as rotinas da Level 1 BLAS.
Os algoritmos são orientados a colunas, ou seja, as matrizes são sempre referenciadas por colunas e não por linhas, objetivando aumentar a eficiência ao preservar a localidade de dados.
Isso ocorre porque o FORTRAN armazena as matrizes por colunas.
Assim, ao acessar uma coluna de uma matriz, as referências à memória serão sequenciais.
Atualmente, o LINPACK é mais conhecido enquanto benchmark do que biblioteca.
O Benchmark LINPACK foi originalmente concebido para fornecer aos usuários da biblioteca LINPACK informações sobre os tempos de execução necessários para resolução dos Selas.
A primeira aparição do LINPACK como benchmark foi em 1979.
Com o passar dos anos foi recebendo incrementos e, nos dias de hoje, é composto por três benchmarks.
O mais importante desses é o Highly Parallel Computing Benchmark (HPL), pois serve como medida para elaboração da lista dos 500 computadores mais rápidos do mundo.
O método usado no benchmark é decomposição Lu com pivotamento parcial, a matriz é do tipo densa, composta por elementos inteiros distribuídos aleatoriamente entre 1 e 1.
A resolução do Sistema de Equações requer O (n3) operações de ponto flutuante, mais especificamente 2/3n3+ 2n2+ O (n) adições e multiplicações de ponto flutuante.
De entre as técnicas para melhora do desempenho na resolução dos Selas, duas se destacam no LINPACK:
Desenrolamento dos laços e reuso dos dados.
Observa- se que, frequentemente, o maior volume de computação de um programa está localizado em menos de 3% do código fonte.
Essa porcentagem do código, também chamada de código crítico, consiste, em geral, num ou alguns poucos laços de repetição imersos, ou seja, num nível maior de aninhamento.
O desenrolamento do laço consiste em replicar seu conteúdo, fazendo os devidos ajustes, o que aumenta o desempenho porque causa uma diminuição direta dos overheads inerentes ao loop.
Em as máquinas com instruções vetoriais, no entanto, essa técnica tem o efeito oposto.
Em relação a o reuso de dados, sabe- se que a cada passo do processo de fatoração do LINPACK são feitas operações vetoriais para modificar uma submatriz inteira dos dados.
Essa atualização faz com que um bloco de dados seja lido, atualizado e escrito novamente na memória central.
O número de operações de ponto flutuante é 2/3n3 e o número de referências a dados é, em ambos os casos (leitura e escrita), de 2/3n3.
Assim, para cada par adição/ multiplicação é feita a leitura e escrita dos elementos, levando a um baixo reuso dos dados.
Mesmo quando as operações são vetoriais, existe um gargalo significante na movimentação dos dados, o que resulta em desempenho ruim nas máquinas modernas.
Em máquinas vetoriais, isso se traduz em duas operações de vetor e três referências vetoriais á memória.
Em os computadores superescalares isso resulta numa grande movimentação e atualização dos dados.
Esse contexto faz com que o LINPACK tenha desempenho reduzido em computadores de alto desempenho em os quais o custo do movimento dos dados é semelhante ao das operações de ponto flutuante.
Uma possível solução é reestruturar os algoritmos de modo que explorem a hierarquia de memória das arquiteturas, o que pode ser feito, por exemplo, armazenando os dados o maior tempo possível nas memórias de nível mais próximo de o processador, ou seja, aumentando o reuso dos dados.
Tais otimizações, presentes nos níveis 2 e 3 da BLAS, foram posteriormente adotados por outros pacotes como o LAPACK.
LAPACK ­ Linear Algebra PACKage O LAPACK foi desenvolvido no final dos anos 80 visando permitir as já amplamente utilizadas bibliotecas EISPACK (Eigensystem Package) e LINPACK rodarem eficientemente em computadores paralelos de memória compartilhada e vetoriais.
Em tais máquinas, esses pacotes são ineficientes porque seus padrões de acesso à memória negligenciam a hierarquia de memória, o que torna o custo do acesso aos dados seja bastante alto.
De modo a contornar esse problema, os algoritmos no LAPACK foram reorganizados para utilizar as operações de matrizes em bloco, tais como multiplicação de matrizes, nos laços mais internos.
Essas operações em bloco podem ser otimizadas para cada arquitetura de modo a tirar proveito da hierarquia de memória e prover uma forma de se atingir alta eficiência nas diversas máquinas modernas,,.
Escrito em FORTRAN 77, o LAPACK provê subrotinas para resolução de Sistemas de Equações Lineares, problemas de Auto-Valores, de entre outros.
As fatorações de matrizes disponíveis são Lu, Cholesky, QR, SVD, Schur e Schur Generalizada.
São suportadas matrizes densas e do tipo banda com elementos reais ou complexos, porém, matrizes esparsas não são.
Em relação a o EISPACK e LINPACK obteve- se melhorias em quatro aspectos principais:
Velocidade, exatidão, robustez e funcionalidades.
Considerando- se seu nicho de arquiteturas, o LAPACK é, ainda hoje, o programa estado da arte para resolução de problemas de equações densas e do tipo banda, além de outros tipos de operações da Álgebra Linear.
Enquanto o LINPACK e EISPACK são baseados nas operações vetoriais da BLAS, o LAPACK explora o nível 3, tendo, inclusive, influenciado posteriormente o desenvolvimento desse nível.
Tal influência deve- se ao fato de que algumas operações da BLAS somente passaram a ser utilizadas com maior frequência e foram, portanto, implementadas como rotinas separadas após a implementação do LAPACK.
Exemplos dessas são copiar uma matriz (Ge_ COPY) e calcular a norma de uma matriz (Ge_ NORM), de entre outras.
Devido a a granularidade grossa do nível 3 das operações da BLAS, seu uso provê alta eficiência em muitos computadores de alto desempenho, principalmente naqueles em que implementações otimizadas são oferecidas por o fabricante da máquina.
Alguns anos mais tarde, com o advento dos agregados de computadores, surgiu o ScaLAPACK, uma versão paralela do LAPACK para máquinas de memória distribuída.
ScaLAPACK ­ Scalable Linear Algebra PACKage O desenvolvimento do ScaLAPACK foi iniciado em 1991 e sua primeira publicação ocorreu no final de 1994.
Surgiu com objetivo de estender o LAPACK para execução escalável nas arquiteturas paralelas de memória distribuída, uma vez que nessas a hierarquia de memória inclui, além de a hierarquia de registradores, cache e memória local de cada processador, a memória externa dos outros processadores.
O ScaLAPACK suporta matrizes densas e do tipo banda.
Sua implementação baseia- se no paradigma de programação SPMD Single-Program-Multiple-Data empregando, para tal, troca explícita de mensagens em redes com suporte a PVM e/ ou MPI.
São utilizados os níveis 1, 2 e 3 da versão paralela da BLAS, PBLAS, e a BLACS, anteriormente apresentadas.
Assim como no LAPACK, as rotinas do ScaLAPACK empregam algoritmos que operam em blocos.
Tais algoritmos assumem que as matrizes são formadas por decomposição cíclica em blocos bi-dimensionais.
Suas rotinas foram mantidas, sempre que possível, compatíveis com suas equivalentes no LAPACK.
De essa forma, em códigos alto nível as chamadas LAPACK e ScaLAPACK são bastante semelhantes, facilitando os esforços de implementação por parte de os usuários.
Para atingir escalabilidade, além de o particionamento em blocos de tamanhos ajustáveis dos algoritmos, o ScaLAPACK possui diversos algoritmos equivalentes para um mesmo cálculo.
Com isso, escolhe- se em tempo de execução o melhor algoritmo para uma dada entrada ou arquitetura.
Por fim, sabe- se que o modo como os dados são distribuídos por os processos tem grande impacto no balanceamento de carga e nos custos da comunicação.
A distribuição cíclica em blocos provê um mecanismo simples para distribuição de dados com algoritmos particionados em blocos em arquiteturas de memória distribuída sendo, por isso, utilizada por o ScaLAPACK,.
Plasma ­ Parallel Linear Algebra for Scalable MultiCore Architectures A abordagem clássica da Álgebra Linear de Alto Desempenho adotada por os pacotes anteriores consiste em explorar o paralelismo oferecido por as versões otimizadas da BLAS e PBLAS.
No entanto, tem- se observado que limitar o uso da memória compartilhada ao paralelismo fork-join, como ocorre com OpenMP, ou à utilização de versões multithread da BLAS não é suficiente para tratar todas as questões de desempenho em computadores multicore.
Diversos são os relatos na literatura, como por exemplo, de que, mesmo vinculando- se o LAPACK a versões multithread altamente otimizadas da BLAS, suas rotinas não exploram de maneira adequada os processadores multicore.
Isso ocorre porque os diversos núcleos dos processadores multicore não podem ser considerados como processadores independentes, dado que compartilham barramento e também recursos dentro de o mesmo chip.
Diante de isso e do contexto apresentado no início deste capítulo, surgiu o projeto Plasma (Parallel Linear Algebra for Scalable MultiCore Architectures) o qual é apresentado em.
A Plasma consiste numa nova biblioteca em desenvolvimento por os mesmos idealizadores do LINPACK, LAPACK e ScaLAPACK, e deverá ser a próxima geração dos pacotes de software para Álgebra Linear de Alto Desempenho.
O desenvolvimento da Plasma tem se dado de acordo com os princípios apontados na Seção 2.2.
Para tal, a BLAS é utilizada apenas na implementação otimizada das operações com fluxo único de execução, também conhecidas como núcleos (kernels).
Com isso, as otimizações em nível de instrução, ou seja, aquelas dependentes de máquina, são exploradas por a BLAS ao passo que o paralelismo é explorado num nível algorítmico acima de o nível da BLAS.
Por essa razão, a Plasma deve ser vinculada a versões sequenciais da BLAS ao invés de versões multithread como ocorria com seus antecessores.
A Figura 2.6 ilustra as diferenças no nível de paralelismo.
Entretanto, não há, ainda, disponível uma versão completa final da Plasma a qual possa substituir por completo o LAPACK e/ ou ScaLAPACK.
Em janeiro de 2009 os códigos-fonte de uma versão inicial com algumas rotinas da Plasma foram disponibilizados.
Em 04 de julho de 2009 uma segunda versão, mais completa e com mais rotinas, foi publicada contendo além de os códigos-fonte um instalador e documentações da biblioteca.
Em o momento da conclusão do presente trabalho, a versão mais atual disponível é 2.1.0 de 15 de novembro de 2009.
Entretanto, embora a Plasma tenha sido proposta para ser sucessora do LAPACK e ScaLAPACK, a migração desses para a Plasma não será de maneira transparente para o usuário, como ocorreu na migração do LAPACK para ScaLAPACK, em que ambos apresentavam as mesmas rotinas e essas eram chamadas de maneira similar.
Considerações Finais Este capítulo apresentou uma contextualização geral do tipo de arquitetura e das ferramentas de software para exploração do paralelismo empregadas neste trabalho.
Cabe observar que o paralelismo tem conquistado espaço na Ciência da Computação como solução para os mais diversos problemas.
Porém, as arquiteturas para tal estão em constante evolução e, portanto, nenhuma dessas pode ter a expectativa de se manter como solução ideal por muito tempo.
De essa forma, a escolha da arquitetura a ser utilizada no desenvolvimento de uma solução computacional deve priorizar atender os requisitos particulares da aplicação em questão.
Em o presente trabalho optou- se por trabalhar com computadores multicore por os motivos já expostos, em especial a facilidade de acesso às mesmas.
As ferramentas abordadas neste capítulo são aquelas que, ao longo de o projeto, foram identificadas como mais adequadas para a aplicação em questão.
A Computação Verificada garante o rigor matemático das operações fornecendo como resposta um intervalo o qual contém, com certeza, o resultado exato.
Os métodos que realizam a verificação automática dos resultados são chamados métodos auto-validados (self validated) e apresentam, basicamente, três objetivos:
Produzir resultados rigorosos;
Resolver o problema sem que o custo computacional seja demasiadamente maior do que o dos métodos puramente numéricos;
Aritmética Intervalar Aritmética Intervalar é uma aritmética definida para intervalos, ao invés de números reais.
Não se trata de uma ideia nova, sua primeira aparição foi registrada em 1924 e foi reinventada diversas vezes desde então, nunca foi o foco principal da Computação Numérica, mas, também, nunca foi totalmente abandonada,.
A Aritmética Intervalar permite ao computador trabalhar com o contínuo e uma de suas principais funções é controlar o erro.
Embora não elimine os efeitos dos erros de arredondamento, limita- os quando utilizada em conjunto com arredondamentos direcionados.
Em uma computação típica, ou seja, não intervalar, o resultado é um número que representa um ponto no eixo dos números reais e está a alguma distância desconhecida da resposta exata.
Em a Computação Intervalar, por outro lado, o resultado é um par de números que formam um intervalo que contém o resultado exato.
Tal intervalo recebe o nome de enclosure, ou, inclusão,.
De essa forma, mesmo que a resposta exata continue desconhecida, ao menos é possível estimar o quão desconhecida ela é,.
A avaliação intervalar de uma expressão aritmética costuma apresentar o dobro do custo computacional que a avaliação da mesma expressão com Aritmética de Ponto Flutuante convencional.
Entretanto, uma única avaliação intervalar produz uma garantia do resultado que não é produzida mesmo com milhões de avaliações convencionais.
Isso porque, é impossível avaliar todos os pontos no eixo dos números reais, dado que entre dois números reais existem, sempre, infinitos outros números e, além disso, muitos pontos não são finitamente representáveis,.
Um intervalo real é um subconjunto fechado, limitado e não vazio dos números reais, representado conforme a Equação 3.1, em a qual x e x denotam, respectivamente, o limite inferior e superior do intervalo.
Tais limites são também chamados de Ínfimo e Supremo, respectivamente.
Por essa razão, essa forma de representar intervalos é denominada Representação Ínfimo-Supremo ou Infimum-Supremum.
Um intervalo real cobre toda a faixa de valores reais entre suas extremidades e, nos casos em que x $= x, o intervalo é chamado intervalo pontual podendo ser escrito apenas como x ao invés de.
De maneira análoga, números exatos podem também ser representados como intervalos pontuais.
Por exemplo, o número 2 pode ser escrito na forma,.
A Equação 3.2 apresenta outra representação possível para intervalos, chamada de Representação por Ponto-Médio e Raio, ou, Midpoint-Radius.
As representações em e (3.2) são equivalentes para operações teóricas em, em as quais não há necessidade de arredondamento dos resultados.
Entretanto, a situação muda ao considerar cálculos executados num computador digital, pois, nesse caso, os números reais precisam ser aproximados por números de ponto flutuante do Sistema de Ponto Flutuante.
Essa aproximação é feita por um mapeamento especial chamado arredondamento (rounding) definido por:
F. Uma operação em ponto flutuante é dita de máxima exatidão quando seu resultado arredondado difere do resultado exato em, no máximo, uma unidade na última casa decimal.
A máxima exatidão é um comportamento padrão nos computadores quando considerando operações de ponto flutuante individuais.
Porém, após uma série de operações consecutivas, o resultado pode ser completamente errado.
Uma vez que os computadores executam milhões de operações em ponto flutuante por segundo, atenção especial deve ser dada à confiabilidade dos resultados,.
Além de os arredondamentos executados em cada operação de ponto flutuante, arredondamentos adicionais são necessários nos dados de entrada e nas constantes.
Isso porque, as pessoas costumam pensar e trabalhar com notação decimal, logo, os programas utilizam essa mesma notação em suas interfaces criando a necessidade de mapear os dados decimais fornecidos por o usuário para o Sistema de Ponto Flutuante Binário do computador.
Tais arredondamentos costumam ocorrer em tempo de execução e, como em geral os números decimais não possuem representação binária exata, um pequeno erro, chamado erro de conversão, é gerado a cada mapeamento.
A operação de arredondamento deve satisfazer duas condições:
X $= x para todo xy x y para todo x, y A primeira condição garante que os números não são alterados por um arredondamento.
Já a segunda significa que o arredondamento é monotônico, ou seja, a ordem dos elementos é mantida ao arredondar- los.
Existem três tipos de arredondamentos:
Para preservar a garantia de que o valor correto sempre se encontra no intervalo, seus pontos extremos devem ser arredondados &quot;para fora», ou seja, em x aplica- se arredondamento direcionado para baixo e em x arredondamento direcionado para cima.
Diz- se que um arredondamento é anti-simétrico quando possui a seguinte propriedade:
Portanto, o arredondamento para o elemento mais próximo é anti-simétrico, porém, os arredondamentos direcionados e não o são.
Ao invés de isso, (x) $ &quot;¤ x e (x) $= x.
Os arredondamentos direcionados satisfazem as demais condições x, e x para todo x.
Dadas as propriedades dos arredondamentos, é importante considerar como as operações básicas No caso de a representação ínfimo-Supremo deve- se ter cuidado em alguns casos, especialmente nas multiplicações, pois, dependendo do sinal dos operandos, diferentes definições da operação são utilizados.
Já no caso de a aritmética representada por Ponto-Médio e Raio isso não ocorre, todas as operações são definidas diretamente sem necessidade de distinção.
Por outro lado, a definição padrão da Aritmética de Ponto--Médio e Raio pode resultar em intervalos mais amplos do que o desejado nas multiplicações e divisões, efeito esse que recebe o nome de overestimation.
Considerando esse contexto, cada representação da Aritmética Intervalar possui algumas vantagens e desvantagens.
As próximas seções descrevem brevemente as definições das operações básicas para ambas as representações.
Em a representação Ínfimo-Supremo, a execução de operações aritméticas básicas com intervalos é bastante próxima das operações com números pontuais tradicionais.
De fato, uma única fórmula estende a definição das quatro operações básicas da Aritmética Real para suas versões intervalares.
Ou seja, calcula- se as quatro possíveis combinações para os limites superior e inferior e, na sequência, escolhe- se o menor resultado como limite inferior e o maior resultado como limite superior.
De essa forma, todas as combinações possíveis para xy estarão contidas no intervalo.
Porém, embora essa fórmula seja uma definição conveniente para operações intervalares, em geral não é a melhor opção, pois requer sempre a computação das quatro combinações de extremos sendo que em diversas situações é possível executar operações menos custosas.
Por exemplo, a multiplicação de dois intervalos e nos casos em que simultaneamente 0/ e y/ pode ser reduzida para a multiplicação de dois números reais.
Aplicando as propriedades da monotonicidade às operações reais elementares, define- se as seguintes fórmulas mais convenientes,:
Cabe observar que a premissa de que as operações intervalares podem ser executadas com base apenas nos pontos finais do intervalo é válida somente para funções monotônicas, ou seja, aquelas que não alteram sua direção ao longo de o domínio.
Em outras funções, como por exemplo sinh, deve- se avaliar internamente os intervalos para obtenção dos mínimos e máximos.
Diversos axiomas matemáticos falham quando considerados num Sistema de Ponto Flutuante, mesmo em operações tradicionais.
Por exemplo, a identidade x $= x2 não é uma operação de resultado confiável.
Entretanto, é possível construir sob o Sistema de Ponto Flutuante Padrão IEEE uma Aritmética Intervalar que jamais resulte em estado de erro, embora possa, em alguns casos, retornar valores tais como, os quais não possuem utilidade prática.
A seguir são apresentadas as operações intervalares na representação de Ponto-Médio e Raio conforme definidas em.
De modo a facilitar a visualização, as operações em ponto Y $= y, I, as operações aritméticas básicas são definidas por:
As operações intervalares sempre satisfazem a propriedade fundamental da isotonicidade, ou seja, se X está contido em outro intervalo X e Y contido em Y, então a combinação de X e Y está contida no intervalo computado por a combinação dos intervalos maiores X e Y.
Qualquer representação ou implementação de uma Aritmética Intervalar deve, portanto, obedecer a isotonici-dade.
Conforme visto anteriormente, a representação por Ponto-Médio e Raio pode, em algumas situações, causar efeitos de overestimation.
Tal efeito numa operação intervalar é dado por:
Onde consiste na medida de overestimation.
Entretanto, Rump provou que o efeito de overestimation nas operações aritméticas básicas utilizando Aritmética de Ponto--Médio e Raio, bem como em operações sob vetores e matrizes, é limitado ao fator de 1, 5.
Para intervalos de raio pequeno esse fator se reduz a 1.
Por fim, Rump observa que, além de a implementação das operações da Aritmética de Ponto--Médio e Raio ser bastante simples nos computadores atuais, essa permite construir rotinas muito mais rápidas do que a abordagem tradicional de ínfimo-Supremo, principalmente nos computadores paralelos.
Computação Verificada e Resolução de Selas A Computação Verificada garante o rigor matemático das operações.
Sua implementação requer, além de o emprego de algoritmos corretos, que as operações sejam executadas com máxima exatidão e construídas utilizando Aritmética Intervalar, a qual, por sua vez, deve ser computacionalmente implementada com o emprego de arredondamentos direcionados.
Cabe observar, porém, que a Computação Verificada não elimina a necessidade de verificação dos algoritmos, compiladores, sistemas operacionais, de entre outros, uma vez que o passo de verificação pode resultar em falsos positivos devido a erros de programação ou ambiente de execução não confiável.
O passo inicial para realizar Computação Verificada é substituir as operações em por suas equivalentes intervalares e, então, executar- las utilizando Aritmética Intervalar.
De essa forma, produzse resultados intervalares.
Porém, em geral, o diâmetro dos intervalos, ou seja, a distância entre x e x, é tão grande que o resultado torna- se inútil.
Logo, métodos mais sofisticados fazem- se necessários.
Tais métodos consistem numa combinação dos benefícios da Aritmética Intervalar com um mecanismo de refinamento dos intervalos encontrados, de forma que seu diâmetro seja o menor possível contendo o resultado exato.
O refinamento iterativo é um processo que, a partir de uma solução inicial, repete o cálculo visando diminuir o erro da mesma até que o tamanho do intervalo seja menor do que a exatidão desejada.
Assim, a inclusão verificada é dada por o intervalo somado ao erro.
Tais métodos, em geral, obtêm êxito em encontrar uma inclusão suficientemente útil da solução e, caso contrário, notificam o usuário de que a computação falhou.
Em a Aritmética de Ponto Flutuante convencional, por outro lado, a computação pode falhar sem que qualquer sinal seja dado ao usuário ou, ainda, pode ser dado um resultado incorreto.
Muitos dos algoritmos para verificação numérica são baseados na aplicação dos teoremas de ponto fixo clássicos da Matemática.
Por exemplo, a convergência é garantida por o Teorema de Ponto Fixo de Brouwer.
Seja X $= In um vetor intervalar em ponto flutuante que satisfaz as condições do Teorema de Ponto Fixo de Brouwer.
Supondo que é possível encontrar fixo x de f.
A afirmação permanece válida substituindo- se f por sua avaliação intervalar na a Computação Numérica provar a existência e unicidade das soluções para Sistemas Lineares e Não-Lineares,.
Versões intervalares de diversos métodos clássicos para resolução de Selas estão disponíveis, porém, elas costumam diferir bastante de suas versões tradicionais.
Por exemplo, em geral o sistema Ax $= b precisa ser pré-condicionado com uma matriz pontual para que os algoritmos sejam eficientes.
Uma possibilidade é calcular a solução aproximada para um sistema pontual utilizando- se bibliotecas de software otimizadas e, então, empregar essa solução na obtenção dos limites para formar um intervalo em o qual se sabe que a solução exata está contida.
Outra grande diferença é a habilidade da Computação Verificada de encontrar soluções mesmo para problemas bastante mal condicionados.
O condicionamento de uma matriz regular quadrada A é definido por a Equação 3.10.
Tal número aponta o quanto modificações na entrada dos dados influenciam na qualidade do resultado final da computação e permite determinar o quão confiável é a solução do Sela.
É um número de o qual interessa a ordem de grandeza e, além disso, está relacionado com a exatidão de máquina usada.
Se cond (A) $= 105 mas a exatidão decimal da máquina for de 17 casas, então não há problema em se perder os últimos cinco dígitos.
Porém, se a exatidão decimal for de apenas 6 casas decimais, então o resultado será confiável apenas até a primeira casa decimal.
Tipicamente, algoritmos de ponto flutuante convencionais podem encontrar uma solução para problemas com condicionamento em torno de 108.
Por outro lado, um algoritmo em Computação Verificada terá, em geral, sucesso em encontrar uma solução mesmo para problemas com condicionamento em torno de 2.5.1015,.
Em a próxima subseção é apresentado o Método Verificado Baseado no Método de Newton, o qual foi escolhido para desenvolvimento do presente trabalho.
Sua descrição completa, bem como uma implementação sequencial do mesmo utilizando C-XSC, pode ser encontrada em.
Seja Ax $= b um Sistema de Equações, encontrar a solução do mesmo é equivalente a encontrar a raiz de uma função f $= Ax -- b.
Assim, o Método de Newton gera a seguinte iteração de ponto fixo, onde x é algum valor inicial arbitrário qualquer:
Em geral, a inversa exata de A não é conhecida.
Assim, ao invés de, a chamada Newtonlike Iteration1 é utilizada, onde R A-1 é uma inversa aproximada de A:
Substituindo a iteração real x (k) por vetores intervalares (k) In, se existe um índice k com (k), então, por o Teorema de Ponto Fixo de Brouwer, a Equação 3.12 tem pelo menos um ponto fixo x (k).
Supondo que R é regular, então esse ponto fixo é também uma solução para Ax $= b.
Cabe observar que a relação de inclusão para vetores e matrizes intervalares é de subconjunto é dada por(^ $ ).
Entretanto, considerando o diâmetro de, obtém- se:
D $= d (k)+ d R A (k+ 1) -- b d (k) Assim, em geral, a relação de subconjunto não é satisfeita.
Por essa razão, o lado direito de é modificado para a equação a seguir, onde I denota a matriz identidade nxn:
Sabe- se que se existe um índice k com (k), então as matrizes R e A são regulares e existe uma solução única x do sistema Ax $= b com x.
Esse resultado permanece válido para qualquer matriz R. Entretanto, é um fato empírico que quanto mais R se aproxima da inversa de A, mais rapidamente o método converge.
Adicionalmente, é um princípio numérico bem estabelecido que uma solução aproximada x~ de Ax $= b pode ser melhorada resolvendo- se o sistema Ay $= d, onde d $= b -- A~ x é o resíduo de A~ x.
Uma vez que y $= A-1 (b -- A~ x) $= x -- x~, a solução exata de Ax $= b é dada por x $= x~+ y.
Aplicando a Equação 3.14 ao sistema residual, obtém- se o Esquema de Iteração Residual:
X)+ (I -- Ra~ $ :
Z A equação residual Ay $= d tem uma solução única y (k) para a iteração intervalar correspondente.
Além disso, uma vez que y $= x -- x~, uma solução verificada da solução única de Ax $= b é dada por x~+.
Esses resultados permanecem válidos ao substituir as expressões exatas z e C em por extensões intervalares.
Entretanto, para diminuir os efeitos de overestimation, recomenda- se fortemente avaliar b -- A~ x e I -- Ra sem arredondamentos intermediários.
Baseada no Método de Newton Considerações Finais Em este capítulo foram apresentadas as bases necessárias para a construção de um solver com verificação automática dos resultados.
Constatou- se que, para a resolução de Selas de acordo com a proposta deste trabalho, o Método Verificado Baseado no Método de Newton é o mais adequado por ser capaz de resolver Sistemas Densos permitindo o emprego da Aritmética Intervalar de PontoMédio e Raio.
Tal aritmética é de grande importância nesse contexto por possibilitar a utilização das bibliotecas de software otimizadas para Álgebra Linear vistas no capítulo anterior.
A implementação empregando essas bibliotecas traz grandes benefícios não apenas em termos de desempenho mas também facilita o desenvolvimento.
Observou- se também que atenção especial deve ser dada às direções dos arredondamentos quando trabalhando com Computação Verificada.
O presente trabalho foi desenvolvido com o objetivo de construir uma ferramenta computacional para resolução de Selas Intervalares Densos de Grande Porte com verificação automática dos resultados otimizada para execução em arquiteturas multicore.
A obtenção de tal resultado envolve a aplicação dos conceitos, ferramentas e estratégias discutidos nos capítulos anteriores.
Em este capítulo, é descrito o processo executado para implementação do solver proposto.
Primeiramente, é apresentada uma solução inicial a qual foi desenvolvida visando validar a abordagem proposta e, consequentemente, obter um software capaz de executar nos computadores foco do trabalho, embora sem ganhos de desempenho.
Após, são descritas as avaliações realizadas em tal versão de modo a validar seus resultados numéricos e obter os custos computacionais dos passos de execução.
Por fim, o desenvolvimento da versão otimizada é apresentado.
Solução Proposta O solver proposto no presente trabalho foi construído com base no Método de Newton descrito no Capítulo 3.
A implementação de tal método utilizando a Aritmética Intervalar de Ponto--Médio e Raio é dada por o Algoritmo 4.1, o qual é apresentado em e trata- se de uma adaptação do algoritmo originalmente proposto por.
Como resultado, o algoritmo gera um vetor em que cada elemento é um intervalo o qual contém o resultado correto.
Tais intervalos são de máxima exatidão.
Algoritmo 4.1: Resolução Auto-- Validada de um Sistema Linear Intervalar Quadrado.
R (-- x(,) x Verificação falhou Empregou- se, para a implementação inicial do Algoritmo 4.1, a linguagem C+ e a biblioteca Intel MKL 10.
2.1.017 como versão otimizada das bibliotecas BLAS e LAPACK.
É importante observar que, devido a as operações da Aritmética Intervalar, o algoritmo tem um consumo de memória bastante elevado.
Somando- se a entrada com os vetores e matrizes auxiliares necessários, tem- se a utilização de um total de 8 matrizes nxn e 20 vetores de ordem n..
Visando obter maior desempenho, a inversa aproximada R e a solução aproximada x são calculadas utilizando- se apenas a matriz de ponto-médio e operações de ponto flutuante tradicionais.
Posteriormente, na computação do resíduo, utiliza- se a Aritmética Intervalar em conjunto com a matriz intervalar original e o vetor intervalar para garantir a exatidão do resultado.
Em o Passo 1 do algoritmo, ou seja, no cálculo de R, as seguintes rotinas do LAPACK foram empregadas:·
dgetrf: Computa, em dupla exatidão (double), uma fatoração Lu da matriz utilizando pivotamento parcial com troca de linhas.
A fatoração tem o formato A $= P. L. U, onde P é a matriz de permutação, L uma matriz triangular inferior com elementos diagonais unitários e U triangular superior;·
dlange: Calcula a norma da matriz A a partir de a fatoração Lu resultante de dgetrf;·
dgecon: Computa, a partir de a saída de dlange e da A original, o número de condicionamento do sistema;·
dgetri: Calcula, com dupla exatidão, uma matriz inversa aproximada de A. O cálculo é feito a partir de o resultado da fatoração Lu dado por dgetrf e composto por os seguintes passos:
Inversão triangular de U por forward substitution (substituição para frente);
Resolução do sistema triangular X:
XL $= U 1 (backward substituion);
Permutação reversa de colunas, O cálculo do condicionamento do sistema foi inserido como rotina intermediária no Passo 1 por depender da saída da fatoração Lu, a qual, por sua vez, é sobrescrita no cálculo da inversa aproximada.
Em o Passo 2 do algoritmo, ou seja, no cálculo da solução x aproximada, utilizou- se a seguinte rotina da BLAS:·
dgemv: Calcula, em dupla exatidão, a multiplicação entre a matriz R e o vetor b.
Os passos 3 e 4 computam, respectivamente, a inclusão do resíduo e a inclusão da matriz de iteração, ou seja, as inclusões necessárias para iniciar a iteração de verificação.
Dado que e, assim como e, são intervalares, é necessário a utilização dos algoritmos da Aritmética de Ponto--Médio e Raio apresentados em.
Seja I+ F o conjunto dos números intervalares no Sistema de Ponto Flutuante, sejam os intervalos de Ponto-Médio e Raio A $= a~, I+ F e B $ ~, são definidas para o padrão IEEE 754 por o Algoritmo 4.2.
De maneira análoga, a multiplicação é definida por o Algoritmo 4.3.
Os símbolos, e indicam, respectivamente, os modos de arredondamento para o elemento mais próximo, direcionado para baixo e direcionado para cima.
Algoritmo 4.2: Adição e subtração de Ponto-Médio e Raio no padrão IEEE 754.
C|+ Algoritmo 4.3: Multiplicação de Ponto--Médio e Raio no padrão IEEE 754.
Conforme visto anteriormente, as grandes vantagens da Aritmética de Ponto--Médio e Raio são permitir cálculos com operações de ponto flutuante puras e não necessitar de alterações intermediárias no modo de arredondamento, diferentemente da abordagem Ínfimo-Supremo.
Portanto, embora e sejam intervalares, o cálculo dos mesmos foi implementado empregando- se, respectivamente, as rotinas dgemv e dgemm da BLAS com arredondamentos direcionados.
A rotina dgemv implementa, em exatidão dupla, a multiplicação de matriz por vetor, enquanto dgemm implementa, também em dupla exatidão, a multiplicação de matriz por matriz.
De modo a formar os limites superior e inferior de, dgemm é executada duas vezes, uma com arredondamentos direcionados para cima e outra com arredondamentos direcionados para baixo.
Esse controle é feito no C+ através das funções disponibilizadas por a biblioteca fenv.
H. Em o presente trabalho empregou- se a rotina fesetround, a qual recebe como parâmetro a direção desejada do arredondamento e altera o mesmo no processador em o qual o processo está executando.
Os macros que representam os tipos de arredondamento possíveis para essa função são:
FE_ DOWNWARD, FE_ TONEAREST, FE_ TOWARDZERO, FE_ UPWARD os quais correspondem a, respectivamente, arredondamento direcionado para baixo, para o elemento mais próximo, direcionado a zero e direcionado para cima.
Um erro de arredondamento é gerado na avaliação do ponto-médio.
Esse erro pode ser compensado com a utilização de uma unidade de erro relativa.
Em o autor representa a unidade de erro relativa como, define $= 1 2, e define o menor número representável de ponto flutuante positivo não normalizado por.
Em o padrão de exatidão dupla IEEE 754, epsilon $= 2-52 e $= 2-1074.
Assim, a avaliação do ponto-médio(~ c) e do raio(~) de C é implementada através do Algoritmo 4.4.
Por fim, os passos de 5 a 15 implementam o Iteração Baseada no Método de Newton para encontrar a inclusão da solução.
Em estes passos a Aritmética de Ponto--Médio e Raio é aplicada em conjunto com os arredondamentos direcionados.
Em a multiplicação.
Utilizou- se no interior do resultado prévio.
Cabe lembrar que, conforme visto na Seção 3.2.1, a relação de Algoritmo 4.4: Multiplicação de Matrizes em Ponto-Médio e Raio no padrão IEEE 754.
Avaliação de Exatidão e Levantamento da Complexidade de Tempo Dois diferentes tipos de testes foram executados para avaliar a implementação inicial:
De de-sempenho (tempo de execução) e de exatidão.
Os testes de desempenho tiveram dois objetivos.
O primeiro de eles é verificar a viabilidade da solução proposta, ou seja, se as estratégias empregadas são capazes de produzir uma ferramenta que resolva Sistemas Intervalares de Grande Porte em tempo satisfatório nas arquiteturas multicore.
O segundo objetivo é verificar quais os trechos do algoritmo que possuem maior custo computacional.
Embora nos autores apontem os trechos do algoritmo com maior complexidade, a implementação deste projeto difere daquela em relação a as ferramentas de software, paradigma de programação e arquitetura utilizadas, logo, faz- se necessário reavaliar os custos.
Já os testes de exatidão fazem- se necessários para garantir que os algoritmos e ferramentas utilizadas obtêm, de fato, resultados válidos e úteis.
Em um primeiro momento, o ambiente para execução dos testes foi um computador portátil equipado com processador Intel Core 2 Duo T6400@ 2.00 GHz com 2 MB de cache, 3 GB de memória RAM DDR2 operando em Dual Channel a 667 MHz.
O computador executava o sistema operacional Ubuntu Linux 9.04, versão 32 bits, kernel 2.6.28-13-generic.
Empregou- se a biblioteca Intel MKL 10.
2.1.017 para chamadas às versões otimizadas das bibliotecas LAPACK e BLAS e o compilador utilizado foi o GCC.
Posteriormente, avaliou- se novamente a implementação inicial na arquitetura paralela de maior porte utilizada durante os testes da solução final, conforme será visto no próximo capítulo.
Visando verificar a exatidão dos resultados, gerou- se um sistema baseado na fórmula de Boothroyd/ Dekker de ordem 10 para o qual a solução exata é conhecida.
Tal matriz é um exemplo de matriz mal condicionada sendo que, para n $= 10, apresenta condicionamento de 1, 09.10+ 15.
De modo a tornar os dados de entrada intervalares, preencheu- se a matriz relativa ao raio de A e o vetor correspondente ao raio de b com o valor 0, 1.10-10.
O sistema foi resolvido com a implementação inicial do presente trabalho e, na sequência, comparou- se os resultados com a solução exata e com os resultados apresentados por.
Tais valores são descritos na Tabela embora o algoritmo utilize a Aritmética de Ponto--Médio e Raio.
Percebe- se que os resultados das duas versões apresentam pequenas diferenças nos diâmetros dos intervalos, embora ambas contenham o resultado exato.
Acredita- se que tais variações nos diâmetros se devam às diferentes estruturas de desenvolvimento e teste utilizadas.
Em especial, a implementação de utilizou como entrada dados pontuais, foi compilada com Intel icc 10.0 e executada em sistema operacional e processadores de 64 bits, enquanto o presente trabalho foi avaliado com entradas intervalares, em 32 bits e compilador GCC.
Além disso, diferentes paradigmas de programação, distribuições do sistema operacional Linux e versões da biblioteca MKL foram empregados.
Ainda no contexto de avaliação de exatidão dos resultados, resolveu- se um sistema de ordem valor 0, 1.10-10 e o número de condicionamento do sistema é igual a 6, 12.101.
Em esse caso, verificouse o comportamento do solver proposto ao resolver problemas bem condicionados.
A Tabela 4.2 apresenta os dez primeiros valores resultantes dessa avaliação.
Gerou- se diversos outros sistemas de maneira análoga e os testes levaram, em todos os casos, a resultados de comportamento semelhantes ao descrito a seguir.
Em relação a os testes de desempenho, o procedimento executado foi gerar matrizes A e vetores b de tamanhos variados e preencher- los com números aleatórios entre 0 e 1.
Contabilizou- se os tempos de execução para cada um dos passos do Algoritmo 4.1 sendo que a contabilização do Passo 1 foi subdividida em 4 submedições, o Passo 3 em duas e os passos de 6 a 15 unidos numa única medida.
Executou- se o algoritmo 10 vezes, removeu- se os tempos extremos inferior e superior de cada passo e obteve- se os valores finais através da média dos restantes.
Utilizou- se, para tal, as funções de tempo próprias do sistema operacional Linux, as quais estão definidas no arquivo de cabeçalho time.
H. A Tabela 4.3 apresenta os tempos médios, em segundos, contabilizados para resolução de um sistema de ordem 5.000 formado por valores gerados aleatoriamente.
Os tempos descritos fazem referência às seguintes operações:
Fatoração Lu da matriz A;
Cálculo da norma de A;
Cálculo do número de condicionamento;
Computação de R, matriz inversa aproximada de A;
Cálculo da solução aproximada de x (Passo 2);
Cálculo do resíduo de x;
Cálculo da inclusão do resíduo de x, ou seja, cálculo do z (Passo 3.2);
Computação da inclusão da matriz de iteração (pré-condicionamento), ou seja, cálculo de (Passo 4);
Inicialização do vetor intervalar de máquina (Passo 5);
Refinamento e teste de inclusão, passo final da verificação;
Observando- se a Tabela 4.3 é possível perceber claramente que os passos 1 e 4 apresentam a maior complexidade de tempo do algoritmo.
O Passo 1 consumiu um total de 144,65s e o Passo 4 109,45s correspondendo, respectivamente, a 55% e 42% do tempo total de execução.
Em o Passo 1 aproximadamente 9% do custo corresponde a fatoração Lu da matriz e o restante à rotina de inversão da matriz propriamente dita.
Contabilizou- se, também, o tempo médio gasto por a instrução que altera o tipo de arredondamento do processador.
Tal operação consome em média 0, 0000025 segundos.
Considerando o algoritmo otimizado para multiplicação de matrizes com Aritmética Ínfimo-Supremo proposto por, o qual requer n2 alterações no modo de arredondamento, teria- se- um custo adicional de 62, 5 segundos (aproximadamente 24%) relativo às alterações no arredondamento ao resolver- se um sistema com n $= 5000.
Logo, comprova- se que, de fato, a utilização da Aritmética Intervalar de Ponto--Médio e Raio traz grandes ganhos não apenas por permitir a utilização de bibliotecas otimizadas, mas, também, por a economia gerada ao eliminar as constantes alterações no modo de arredondamento.
Otimização da Solução Proposta Conforme constatado nas avaliações apresentadas na Seção 4.2.2, os passos 1 (inversão da matriz e 4 do algoritmo (cálculo da inclusão) consomem, juntos, 97% do tempo total de execução da ferramenta.
De essa forma, optou- se por focar a otimização do solver nesses dois pontos.
Observase novamente que, devido a as operações da Aritmética Intervalar, o algoritmo tem um consumo de memória bastante elevado dada a quantidade de vetores e matrizes auxiliares necessários.
De essa forma, na solução otimizada todos os vetores e matrizes são dinamicamente criados e liberados.
As próximas seções descrevem a paralelização do solver desenvolvido.
Inicialmente, efetuou- se uma busca na literatura por algoritmos que permitissem uma paralelização eficiente do cálculo da matriz inversa.
Entretanto, não foram encontradas muitas referências de métodos paralelos destinados à inversão de matrizes genéricas.
Os trabalhos disponíveis relatam, basicamente, algoritmos para inversão em paralelo das chamadas Matrizes Simétricas PositivoDefinidas (Symmetric Positive--Definite Matrices).
Tais técnicas fazem uso das estruturas especiais dessas aplicando, por exemplo, a fatoração de Cholesky.
Dado que o presente projeto é destinado a Selas Densos, necessita- se trabalhar com matrizes quadradas genéricas não sendo, portanto, possível basear- se em tais técnicas.
De fato, há consenso na literatura de que a inversão de matrizes é um procedimento altamente custoso computacionalmente.
Em muitas situações os problemas são remodelados para evitar a necessidade de calcular matrizes inversas, porém, nem sempre isso é possível.
Há relatos na literatura de um algoritmo capaz de inverter uma matriz quadrada em O log 2 n operações.
Entretanto, tal algoritmo é apenas de interesse teórico, uma vez que o mesmo necessita de um número excessivo de processadores:
N4. Desconhece- se há algum algoritmo capaz de produzir uma inversa com complexidade menor do que O log 2n, mesmo no caso de matrizes triangulares.
A biblioteca C-XSC utiliza o método da Eliminação de Gauss--Jordan (EGJ) para o cálculo da inversa.
Porém, seu tempo para execução verificada é bastante elevado.
Por outro lado, embora a resolução verificada de Selas com o Método Verificado Baseado no Método de Newton seja uma das situações em que é necessário o cálculo da matriz inversa, o mesmo requer apenas uma inversa aproximada, ou seja, não há problema em perder- se parte da exatidão.
Cabe lembrar, entretanto, que quanto mais R se aproxima da inversa de A, mais rapidamente o método converge.
Em os autores obtiveram ótimos resultados ao otimizar o solver apresentado em.
Para tal, reduziram o tempo gasto por o C-XSC na inversão de matrizes simplesmente eliminando os trechos de código da biblioteca responsáveis por a alta exatidão.
Partindo desse resultado, trabalhos seguintes, como, obtiveram ganhos adicionais eliminando por completo C-XSC e delegando a responsabilidade de calcular a inversa para bibliotecas numéricas otimizadas, como à rotina pdgetri do ScaLAPACK.
Contudo, existem obstáculos à ideia de adotar- se a mesma estratégia de em processadores multicore.
Delegar a inversão da matriz A à rotina dgetri do LAPACK, por exemplo, não traz ganhos satisfatórios, conforme será visto no Capítulo 5.
Em esse contexto, optou- se por empregar a biblioteca Plasma para essa finalidade.
Com isso, é possível se beneficiar das diversas otimizações, apresentadas no Capítulo 2, que a biblioteca disponibiliza para processadores multicore.
Entretanto, a biblioteca Plasma se encontra em desenvolvimento e a implementação disponível até o momento da conclusão do projeto aqui descrito não oferece rotinas para o cálculo da matriz inversa.
Por outro lado, tem- se já disponíveis as rotinas para fatoração Lu, QR e Cholesky de matrizes.
Adicionalmente, a rotina Plasma_ dgesv permite calcular a solução de um Sela no formato ou seja, número de colunas da matriz B).
A decomposição Lu com pivotamento parcial e trocas de linhas é executada como passo intermediário na fatoração de A. Em a sequência, a forma fatorada de A é utilizada para resolver o Sela.
De acordo com as propriedades Álgebra Linear, tem- se que a multiplicação de uma matriz A por sua inversa R resulta na matriz identidade I. Acrescentando-se a isso o fato de que a rotina Plasma_ dgesv permite a B, ao lado direito da equação, assumir a estrutura de uma matriz, empregou- se tal rotina como solução neste projeto.
Para tal, a rotina é parametrizada atribuindo- se à matriz A os elementos da matriz a qual se deseja inverter e para B a identidade I de A. De essa forma, a resolução X do sistema dada por Plasma_ dgesv coincide com a inversa aproximada R de A. Conforme visto no Capítulo 2, para que a Plasma obtenha bom desempenho é necessário vincular- la a implementações otimizadas, porém sequenciais, da BLAS.
Entretanto, neste trabalho utilizou- se a MKL multithread devido a as paralelizações que essa oferece para os demais passos do algoritmo em os quais a Plasma não é utilizada.
Para solucionar tal conflito, introduziu- se no algoritmo chamadas à função mkl_ set_ em um_ threads.
A mkl_ set_ em um_ threads recebe como parâmetro um inteiro que representa o número máximo de threads que podem ser disparadas por o ambiente multithreading OpenMP da MKL.
Assim, faz- se uma chamada mkl_ set_ em um_ threads como passo anterior à execução da Plasma_ dgesv.
Terminada a rotina da Plasma, executa- se novamente mkl_ set_ em um_ threads passando como parâmetro o número de cores disponíveis.
Com essa abordagem, obtém- se os benefícios da biblioteca Plasma no escopo da Álgebra Linear e as otimizações, em nível de instrução, da MKL nos trechos mais internos das operações.
A otimização do Passo 4, ou seja, do cálculo da matriz de inclusão, deu- se através da paralelização do cálculo dos limites inferior e superior de, além de o emprego da função dgemm da MKL para implementação da multiplicação de matrizes.
Para tal, aplicou- se programação multithread, com threads POSIX (Portable Operating System Interface), baseada no conceito de afinidade de processador (thread affinity).
Afinidade de processador é uma ferramenta que permite definir o (s) processador (es) em que um thread ou processo deve ser executado.
Embora não seja possível impedir as interrupções causadas por o escalonador do sistema operacional na execução dos threads, ao utilizar thread affinity é possível garantir que um thread não será atribuído a um processador diferente daquele desejado após uma interrupção.
Tal controle é de fundamental importância para certificar- se de que um thread não será executado num processador configurado com modo de arredondamento diferente do esperado.
De essa forma, garante- se que as propriedades das operações da Aritmética Intervalar serão respeitadas e, portanto, os resultados confiáveis.
Além disso, a afinidade de processador permite obter ganhos de desempenho, pois viabiliza, por exemplo, definir que threads que colaboram entre si numa determinada operação sejam escalonados de forma mais eficiente.
Em esse contexto, a estratégia adotada é criar threads POSIX dividindo igualmente de entre o número de cores disponíveis o cálculo dos limites superior e inferior de.
Para isso, os threads são definidos com afinidade de processador e, então, atribuídos estaticamente aos cores configurados com um mesmo modo de arredondamento.
Criou- se um algoritmo para tal divisão, o qual é descrito por o Algoritmo 4.5.
Algoritmo 4.5: Função para distribuição balanceada, de entre os threads, dos cores disponíveis.
ProcsDispo $= i CPU_ SET (i,&amp; procGERAL_ SET) procsDownW_ VT $= i CPU_ SET (i,&amp; procDownWa_ SET) procsUpWar_ VT $= i CPU_ SET (i,&amp; procUpWard_ SET) O Algoritmo 4.5 tem como objetivo efetuar o balanceamento dos recursos, assim, tem- se n/ 2 threads calculando cada limite, todos escalonados em paralelo.
Utiliza- se, para tal, três variáveis do tipo &quot;cpu_ set_ t», disponíveis no cabeçalho sched.
H, e três vetores de inteiros sendo, em ambos os casos, uma variável para definição dos processadores relativos ao cálculo do limite superior, outra para o cálculo do limite inferior e uma terceira que define o conjunto completo de processadores disponíveis.
A definição do conjunto completo visa facilitar as alterações nos arredondamentos dos processadores e o escalonamento daquelas operações em que se tem todos os cores cooperando e utilizando um mesmo modo de arredondamento, como, por exemplo, na inversão da matriz A. As variáveis do tipo &quot;cpu_ set_ t «definem os conjuntos de máscaras de processadores.
Esses são passados como parâmetros para a função sched_ setaffinity que, por sua vez, é responsável por a configuração da afinidade de processador.
Já os vetores de inteiros recebem os identificadores dos processadores e são utilizados por a função que modifica o arredondamento de vários processadores simultaneamente, a qual será descrita na sequência.
Verificou- se, através de análise dos arquivos de configuração do Linux, que a identificação dos cores na arquitetura utilizada segue o seguinte padrão:
Os cores do primeiro processador físico recebem números pares sequenciais iniciando em 0, enquanto os cores do segundo processador recebem números ímpares iniciando por 1.
Portanto, para a divisão dos recursos, o Algoritmo 4.5 verifica, inicialmente, o número de processadores a ser utilizado.
Caso houver apenas um core disponível, então os três vetores e conjuntos de máscaras recebem apenas o identificador 0.
Havendo mais de um núcleo disponível e, sendo a quantidade par, os vetores procsUpWar_ VT e procsDownW_ VT, assim como os conjuntos &quot;cpu_ set_ t», recebem n/ 2 posições.
Os núcleos com identificadores ímpares são atribuídos para o cálculo do limite inferior, enquanto os pares destinam- se ao limite superior.
De essa forma, todos os threads que calculam um limite são escalonados nos cores de um mesmo processador físico.
Com isso, além de aumentar a localidade de dados na memória cache, facilita- se a comunicação e sincronização.
Em caso de número ímpar de cores disponíveis, o limite superior é calculado com n/ 2+ 1 núcleos.
Iniciado o Passo 4 do algoritmo, a primeira etapa é configurar os modos de arredondamento dos processadores para execução dos cálculos da matriz de inclusão.
Visando facilitar esse processo nas execuções com múltiplos cores, criou- se uma função que recebe três parâmetros:
A direção para a qual o arredondamento deve ser configurado, um vetor de inteiros, preenchido por o Algoritmo 4.5, que contém os identificadores de todos os processadores cujos modos de arredondamento devem ser alterados para aquela direção e o número de processadores que compõem o vetor.
De posse dessas informações, a função executa um laço for modificando, para cada processador indicado no vetor, o modo de arredondamento.
Utiliza- se, para isso, um conjunto cpu_ set_ t temporário o qual, a cada iteração do laço, é reiniciado e recebe exclusivamente o processador indicado por a posição atual do vetor.
Em a sequência, a afinidade de processador da função é alterada por uma chamada à sched_ setaffinity de modo que essa execute somente no processador indicado por o cpu_ set_ t..
Uma vez atribuída ao processador i, a função invoca a rotina fesetround para efetuar o chaveamento do modo de arredondamento.
O Algoritmo 4.6 descreve a rotina desenvolvida.
Alterados os arredondamentos, cria- se os threads para execução dos cálculos.
Cada thread tem Algoritmo 4.6: Rotina para alteração do modo arredondamento de um conjunto de processadores.
CPU_ ZERO(&amp; processadorAtual) CPU_ SET (arrayProcs,&amp; processadorAtual) perror (&quot;Erro ao setar arredondamento do processador&quot;) exit fesetround (direcao) como instrução inicial a definição de sua afinidade de processador.
Assim, uma vez iniciados, os threads alteram sua afinidade e permanecem bloqueados até que sua execução seja liberada por o fluxo principal do programa.
Utilizou- se, para a sincronização, três semáforos:
Um para controle do fluxo de cálculo do limite superior, outro do limite inferior e o terceiro para sincronização com o fluxo principal.
De essa forma, após liberar a execução dos threads que calculam os limites, o programa principal permanece bloqueado por um semáforo aguardando o término dos mesmos.
Uma vez formados os limites, os threads enviam sinal ao semáforo para desbloqueio do fluxo principal.
Desenvolveu- se também uma estratégia alternativa para esse passo do solver a qual consiste em utilizar os n processadores para a formação de cada limite.
Em esse caso, primeiro seta- se o arredondamento de todos os n processadores para DOWNWARD e calcula- se o limite inferior utilizando os n processadores.
Em a sequência, seta- se o arredondamento dos n processadores para UPWARD e calcula- se o limite superior utilizando, novamente, os n processadores.
Assim como na abordagem até então discutida, essa emprega a rotina dgemm da MKL para a multiplicação de R e A, ou seja, ambas se beneficiam das otimizações relativas à arquitetura do processador.
Avaliou- se, ainda, a estratégia de dividir manualmente as matrizes R e A num número elevado de pequenas submatrizes, conforme ocorre nos tiled algorithms, e computar- las em diversos threads em paralelos utilizando a função dgemm sequencial da BLAS.
Porém, não se obteve ganhos nesse aspecto, pois o overhead introduzido por a quebra, sincronização e reconstrução das matrizes eliminou os ganhos oriundos da operação com blocos de menor magnitude levando a tempos de execução iguais ou superiores aos obtidos com a dgemm multithreaded.
Adicionalmente, a complexidade de programação introduzida é bastante elevada.
Cabe observar, porém, que esse é um resultado esperado, dado que a MKL é altamente otimizada para o processador utilizado.
Considerações Finais Este capítulo apresentou o desenvolvimento da solução proposta por o presente trabalho.
Primeiramente, foi descrita uma versão inicial, a qual teve três importantes contribuições:
Comprovou a viabilidade técnica em executar a proposta do trabalho empregando as ferramentas e hardware disponíveis;
Possibilitou o levantamento do custo computacional do algoritmo de modo que um plano de otimização pudesse ser adequadamente traçado;
Permitiu a validação dos resultados numéricos.
Em a sequência, abordou- se a paralelização da solução proposta explicitando o emprego dos conceitos discutidos até então.
Constatou- se que, de entre os dois trechos do algoritmo com maior potencial para otimização de desempenho, um de eles pode ser tratado sem grande complexidade aplicando- se uma identidade matemática à função Plasma_ dgesv.
Com isso, simula- se um procedimento de inversão de matriz, dado que não há tal rotina disponível na versão atual da biblioteca Plasma.
Já no segundo trecho, duas estratégias com pequenas diferenças foram adotadas.
O próximo capítulo descreve em detalhes os testes executados no solver resultante desse processo de otimização.
A avaliação dos resultados deste projeto deu- se de duas formas:
Através da análise de desempenho da ferramenta, executando- a em diferentes números de processadores, e de testes de exatidão com os resultados calculados.
Uma vez que o objetivo principal do trabalho é reduzir o tempo de computação, os testes de desempenho visaram medir os valores de speedup obtidos por a solução otimizada.
Em relação a os testes de exatidão, embora já realizados anteriormente com a versão inicial do solver, fez- se necessário repetir- los para garantir que a exatidão dos resultados numéricos não tenha sido comprometida por as otimizações matemáticas e modificações na implementação do algoritmo.
Este capítulo apresenta, inicialmente, o ambiente em o qual os testes foram executados.
Em a sequência, descreve- se a avaliação de exatidão e compara- se a mesma com a versão original do solver.
Por fim, os testes de desempenho são apresentados e discutidos.
Ambiente de Execução dos Testes As avaliações da solução final deste projeto, descritas nas próximas seções, foram realizadas num computador Dell PowerEdge R610 disponibilizado por o LAD (Laboratório de Alto Desempenho) da PUC-RS.
As configurações de software e versões das bibliotecas utilizadas são as seguintes:·
Sistema Operacional Linux, kernel versão 2.6.28-11-s erver, distribuição Ubuntu 9.04;·
Compilador gcc versão 4.3.3;·
Intel MKL 10.
2.2.025 como implementação otimizada da BLAS e LAPACK;·
Biblioteca PLASMA 2. 1.0;
Em relação a o hardware, a configuração disponível é a seguinte:·
2 processadores Quad- core Intel (R) Xeon (R) CPU E5520@ 2.27 GHz;·
Memórias cache L1 de 128 KB, L2 de 1 MB e L3 de 8 MB compartilhada.
Todos os níveis possuem ECC (Error Correction Code) e são associativos, sendo os níveis L1 e L2 associativos por grupos de 8 vias e o L3 associativo por grupo de 16 vias;·
16 GB de memória RAM DDR3@ 1066 MHz.
Cabe observar que, durante a execução dos testes, a tecnologia de Hyperthreading dos processadores encontrava- se habilitada podendo, portanto, gerar interferência nos resultados de desempenho.
Entretanto, uma vez que o solver desenvolvido emprega afinidade de processador, elimina- se a possibilidade de escalonamento dos threads nos processadores virtuais.
De modo a minimizar tal influência, incluiu- se também na versão inicial da ferramenta chamadas à rotina para controle de afinidade de processador.
A Figura 5.1 ilustra o diagrama de blocos para um sistema com 2 processadores Quad- core Intel (R) Xeon (R) CPU E5520.
Avaliações de Exatidão Visando verificar a exatidão dos resultados e certificar- se do não comprometimento da mesma devido a as modificações introduzidas durante a paralelização do algoritmo, executou- se um processo análogo àquele realizado para avaliar a solução inicial.
Gerou- se sistemas baseados num formato clássico de matriz e também constituídos por números aleatórios entre 0 e 1.
Em a sequência, resolveu- se tais sistemas com as versões original e otimizada da ferramenta para, então, comparar os resultados dessas.
Em a avaliação da solução paralela, variou- se o número de cores em que a mesma executa.
Com isso, é possível certificar- se de que, no ambiente paralelo, as operações de sincronização entre os threads bem como as trocas de contexto dos processadores não afetam a exatidão, ou seja, o algoritmo não está sujeito a condições de corrida.
Todos os testes foram repetidos 10 vezes para cada situação e obtiveram, em todos os casos, resultados numéricos idênticos.
O sistema clássico utilizado é formado por a matriz de ordem 10 dada por a fórmula de Boothroyd/ Dekker, conforme definido no Capítulo 4.
Cabe lembrar que tal matriz é um exemplo de matriz mal condicionada, seu condicionamento para n $= 10 é de 1, 09.10+ 15.
De modo a tornar os dados de entrada intervalares, preencheu- se a matriz relativa ao raio de A e o vetor correspondente ao raio de b com o valor 0, 1.10-10.
A Tabela 5.1 apresenta a solução exata do sistema e os resultados numéricos obtidos por o solver utilizando: (
a) Implementação inicial; (
b) Implementação otimizada executando em 1 núcleo; (
C) Implementação otimizada executando em 8 núcleos.
Executou- se tal avaliação variando o número de cores entre 1 e 8.
Porém, uma vez que os resultados obtidos com quantidades intermediárias de cores foram exatamente iguais aos obtidos por a execução com 8 núcleos, omitiu- se os mesmos na Tabela 5.1.
Com objetivo de facilitar a visualização, os resultados são apresentados na notação Ínfimo-Supremo e os valores arredondados para 5 casas decimais, pois o solver efetua todos os cálculos com variáveis de exatidão dupla (tipo double do C+).
Verifica- se, através dos resultados da Tabela 5.1, que o requisito de exatidão da ferramenta é atendido em todas as avaliações realizadas.
No caso de a solução paralela executando em 1 núcleo, o menor diâmetro é de 0, 00054 para uma exatidão de 5 casas decimais e o maior de 0, 85209.
A maior amplitude ocorre na posição 9 de x, as demais apresentam diâmetros bastante menores e, em todos os casos, contêm a solução exata.
Comparando- se a execução do algoritmo paralelo em 8 cores com a execução em 1 core percebe- se uma sensível diferença nos resultados.
Os valores obtidos foram semelhantes para as posições 0, 1, 2, 3 e 6.
Entretanto, para as posições 4, 5, 7, 8 e 9 houve uma pequena melhora na execução com 8 cores, a qual apresentou diâmetro mais amplo no valor de 0, 85144.
Já em relação a o solver inicial, houve um leve aumento dos diâmetros em geral.
Apesar disso, todos os intervalos contêm a solução exata.
Adicionalmente, cabe observar que mesmo um diâmetro mais amplo é considerado uma solução verificada, especialmente se tratando de sistemas mal condicionados como é o caso do gerado por a Equação de Boothroyd/Dekker.
O próximo teste de exatidão se deu através da resolução de um sistema de ordem 10 com valores para A e b gerados aleatoriamente entre 0 e 1.
O número de condicionamento do sistema é igual a 1.56.102.
De essa forma, tem- se a avaliação do solver considerando um sistema bem condicionado.
Gerou- se diversos outros sistemas de maneira análoga e os testes levaram a resultados de comportamento semelhantes.
A Tabela 5.2 apresenta os resultados numéricos obtidos para tal sistema.
Novamente, executou- se a implementação otimizada do solver variando o número de núcleos entre 1 e 8.
Entretanto, nesse caso obteve- se resultados exatamente iguais para todas as situações, o que é esperado por o fato do sistema ser bem condicionado.
Assim, a Tabela 5.2 condensa o resultado das execuções do algoritmo paralelo, sem distinção do número de cores, e os valores são apresentados com exatidão de 10 casas decimais.
Conforme esperado, obteve- se resultados bastante satisfatórios para o sistema bem condicionado.
Em o exemplo da Tabela 5.2, exceto por as posições 0 e 2, os valores apresentaram diâmetro 0 até a sétima casa decimal.
Já nas posições 0 e 2, o diâmetro corresponde a 1.10-7, ou seja, variação de apenas uma unidade na última casa decimal.
Somente após a oitava casa decimal os diâmetros apresentaram crescimento.
Tal situação confirma que, de fato, para problemas bem condicionados o solver encontra enclosures iguais ou muito próximas da solução exata.
Observa- se, também, que em tal situação os valores calculados por a implementação otimizada são exatamente iguais aos obtidos por a solução inicial.
Diante de tais resultados, é possível afirmar que as estratégias de otimização adotadas no desenvolvimento do solver paralelo não comprometeram a confiabilidade dos resultados.
Cabe ainda observar que, para problemas bem condicionados, além de a maior exatidão a ferramenta apresenta também melhor desempenho.
Isso porque, para o sistema mal condicionado, o passo de verificação do solver obteve êxito em encontrar a enclosure após três iterações, enquanto ao resolver sistemas bem condicionados as enclosures foram obtidas na segunda iteração.
Avaliações de Desempenho Executou-se testes de desempenho com objetivo de avaliar o sucesso das estratégias adotadas na otimização da ferramenta.
Para esses, gerou- se matrizes A e vetores b de ordens variadas formados por valores aleatórios entre 0 e 1.
De essa forma, avalia- se também a escalabilidade da solução desenvolvida e tamanhos de problema para os quais a mesma pode não ser adequada.
De a mesma forma que no Capítulo 4, as contabilizações de tempo se deram com o emprego de funções das bibliotecas do Linux.
O número de amostras utilizado nos testes foi 10.
Assim, para cada tamanho de problema e variação no número de threads e/ ou algoritmo, executou- se 10 vezes a contabilização do tempo consumido por cada passo.
Em a sequência, eliminou- se os dois valores extremos, ou seja, os tempos maior e menor de execução.
Obteve- se o resultado final através da média aritmética das amostras restantes.
Em a eliminação dos extremos foram considerados os tempos para cada passo em particular e não para as execuções como todo.
Pretende-se, com isso, amenizar vieses relacionados às atividades do sistema operacional.
Adicionalmente, cabe observar que o computador utilizado encontra- se num cluster o qual é acessado remotamente e, portanto, o ambiente de teste não é totalmente controlado.
Todas as medições de tempo foram realizadas através de novas execuções do programa.
O custo das operações de leitura dos arquivos contendo a matriz A e o vetor b foram, também, contabilizados em todas as situações, porém, não constituem os totais descritos nas tabelas.
Tais tempos serão apresentados juntamente com o número de condicionamento dos sistemas.
Todas as demais operações de entrada e saída são consideradas, ou seja, seus tempos encontram- se inclusos nas medições.
Isso porque, a operação de leitura dos arquivos é um passo anterior à execução do solver propriamente dito, enquanto as demais, como, por exemplo, alocação de memória, são operações componentes dos passos de resolução do sistema.
De modo a facilitar a visualização dos tempos, adotou- se para todas as tabelas a seguinte convenção:
Em a coluna &quot;Algoritmo», o símbolo &quot;S. Al.»
representa o Algoritmo Inicial Alterado enquanto o símbolo &quot;Para.»
refere- se à Implementação Paralela do Solver.
A coluna &quot;Cores «apresenta o número de núcleos do processador empregados na respectiva execução.
A coluna &quot;Total «apresenta o tempo total consumido para execução completa do solver, desconsiderando a leitura dos arquivos.
Por fim, as colunas de rótulo iniciado por &quot;Passo «referem- se aos passos de execução da ferramenta.
Em estes casos, condensou- se os tempos consumidos por os passos de 6 a 15 num único tempo.
Portanto, os tempos consumidos por os passos do Algoritmo 4.1 são transpostos nas tabelas a seguir da seguinte forma:
Cálculo da solução aproximada de x (Passo 2);
Cálculo da inclusão do resíduo de x, ou seja, cálculo do z (Passo 3);
Computação da inclusão da matriz de iteração (pré-condicionamento), ou seja, cálculo de (Passo 4);
Inicialização do vetor intervalar de máquina (Passo 5);
Refinamento e teste de inclusão, passo final da verificação;
Execução completa (incluindo operações de entrada e saída, exceto leitura dos arquivos).
O Algoritmo Inicial Alterado referido nas tabelas corresponde a uma paralelização parcial do solver inicial.
Trata- se de uma modificação do algoritmo original em que se manteve inalterada a maior parte dos passos, incluindo as chamadas às rotinas MKL.
A alteração, neste caso, refere- se à inclusão no algoritmo de chamadas às rotinas da MKL que manipulam o número de threads para que as operações da biblioteca passem a executar no modo multithread.
Compilou- se essa versão do solver vinculada à implementação multithread da MKL.
Com isso, obtém- se dois tipos de avaliação:
Tal estratégia corresponde a formar os limites de sequencialmente, porém utilizando- se os n cores disponíveis para calcular cada um dos limites.
Basicamente, mantém- se a computação dos limites superior e inferior da matriz em momentos separados, ou seja, calcula- se o limite inferior e, na sequência, o superior.
Porém, dado que o trecho de maior custo computacional no cálculo dos limites corresponde à operação de multiplicação de matrizes e que, além disso, tal operação é executada por uma chamada à rotina dgemm da BLAS, o fato de utilizar a MKL multithread permite, por si só, obter ganhos de desempenho para este passo.
Assim, tem- se uma abordagem alternativa, em que cada limite é calculado em n núcleos, à paralelização original, em a qual cada limite é formado em n/ 2 cores.
A Tabela 5.3 apresenta os resultados obtidos para a resolução de um sistema de ordem 1.000.
O tempo médio consumido para a leitura dos arquivos nesta situação é de 0, 089153 segundos.
Observa- se que, para os resultados da Tabela 5.3, as variações de tempo foram desprezíveis.
Esse comportamento é esperado devido a o tamanho do problema, pois, embora um sistema de ordem 1.000 seja considerado de grande porte, trata- se de um problema pequeno para o contexto das tecnologias aplicadas.
Com isso, de modo geral os ganhos oriundos da paralelização costumam não compensar o overhead introduzido por os mecanismos de controle e sincronização.
De fato, percebe- se que, em alguns casos, a execução com número maior de threads obteve desempenho inferior às execuções com quantidades menores.
Ademais, em intervalos de tempo tão pequenos (todos menores do que um segundo), a imprecisão de medição e/ ou cálculo das médias pode ser suficiente para gerar tais diferenças.
Assim, para os próximos testes aumentou- se o valor de n dos sistema para quantidades com as quais se espera obter resultados mais adequados.
A próxima avaliação deu- se, portanto, com um sistema de ordem 6.000.
O número de condicionamento do mesmo é igual a 2, 61.106 e o tempo médio consumido por a leitura dos arquivos com matrizes e vetores foi de 3, 51 segundos.
Os tempos são apresentados na Tabela 5.4.
Em a avaliação do sistema de ordem 6.000 já é possível perceber os benefícios advindos das otimizações.
A Tabela 5.5 apresenta os speedups relativos à Tabela 5.4, onde a coluna &quot;Cores «representa o número de núcleos em o qual o solver paralelo foi executado.
A coluna &quot;Sp T. T. Par.»
apresenta os speedups considerando os tempos totais de execução do algoritmo paralelo executando em &quot;cores&quot;_ P ara. (
n) núcleos em relação a o algoritmo paralelo executando em 1 núcleo, ou seja, Sp $= T Em a coluna &quot;Sp T. T. Seq.»
são descritos os speedups obtidos por a execução paralela em &quot;cores&quot;_ P ara. (
n) núcleos em comparação ao algoritmo original, ou seja, Sp $= T relação à versão inicial desenvolvida com o LAPACK.
A o calcular- se o speedup apenas com base na versão paralela executando em 1 núcleo, negligencia- se as otimizações introduzidas por o emprego da biblioteca Plasma.
Isso porque, conforme visto anteriormente, as otimizações da Plasma não se resumem apenas ao paralelismo das tarefas mas, também, a novas abordagens no gerenciamento dos dados e no escalonamento das operações de maneira mais adequada aos computadores multicore.
Cabe, ainda, avaliar em separado os speedups obtidos apenas nos passos que foram otimizados para execução em paralelo, uma vez que, ao comparar- se somente os tempos totais de execução, tem- se sobre os speedups, a influência dos diversos trechos não paralelizados.
A coluna «Sp P1.
Par. &quot;descreve os speedups do Passo 1 do algoritmo (cálculo da matriz inversa) relacionando o solver paralelo em execução com 1 e com «cores «núcleos.
Já na coluna «Sp P1.
Seq. &quot;são apresentados os speedups relativos ao algoritmo paralelo executando em «cores «núcleos em comparação à implementação desenvolvida com o LAPACK.
De maneira análoga, as colunas «Sp P4.
Par. &quot;e «Sp P4.
Seq. &quot;descrevem os speedups do Passo 4 (pré-condicionamento do sistema) comparando- se, respectivamente, a execução do solver paralelo em «cores «núcleos com sua execução em 1 núcleo e com a solução inicial.
A Figura 5.2 ilustra os dados da Tabela 5.5.
Observa- se que a coluna &quot;Sp T. T. Par.»
iniciou com speedup próximo a o linear e, gradualmente, afastou- se do mesmo.
Já sua equivalente em relação a o solver inicial, ou seja, a linha &quot;Sp T. T. Seq.»,
apresentou, primeiramente, speedup superlinear, porém, decresceu gradualmente ficando abaixo de a reta linear a partir de 5 cores.
Esse resultado pode ser explicado por a influência dos trechos sequenciais, uma vez que o cálculo de tal reta considera o tempo total de execução.
A análise do mesmo em conjunto com as colunas seguintes reforça tal conclusão.
A reta «Sp P1.
Par. «apresentou speedup bastante próximo a o linear nos primeiros pontos.
Após, iniciou- se um distanciamento pequeno e gradual.
Acredita- se que tal situação seja resultado da granularidade do sistema.
Já a coluna «Sp P1.
Seq.», conforme esperado, manteve speedup superlinear para todos os valores.
A avaliação dessas duas retas evidência os fortes ganhos de desempenho advindos do emprego da biblioteca Plasma, principalmente ao comparar- se com os resultados apresentados por o LAPACK.
Por fim, as retas «Sp P4.
Par. &quot;e «Sp P4.
Seq. «apresentaram, conforme esperado, comportamentos bastante similares ao longo de todo o gráfico.
Ambas iniciaram próximas ao speedup linear e se distanciaram do mesmo com o aumento do número de cores.
Acredita- se que, assim como na inversão da matriz, tal comportamento deva- se à granularidade do sistema.
Portanto, espera- se que aumentando a ordem do mesmo os speedups se mantenham mais próximos à reta linear.
A próxima avaliação de desempenho foi realizada considerando um sistema de ordem 10.000.
O número de condicionamento do mesmo é igual a 1, 52.107 e o tempo médio consumido por a leitura dos arquivos com matrizes e vetores foi de 15, 38 segundos.
Os tempos contabilizados são apresentados na Tabela 5.6.
Os speedups obtidos para tal sistema são apresentados na Tabela 5.7 e ilustrados na Figura 5.3.
Linear Sp T. T. Par. Sp T. T. Seq.
Sp P1.
Par. Sp P1.
Seq. Sp P4.
Par. A análise dos dados para o sistema de ordem 10.000 confirma a hipótese de que um sistema de maior porte do que aquele de ordem 6.000 poderia alcançar resultados ainda melhores.
De fato, em todos os cálculos obteve- se valores de speedup maiores para n $= 10.000.
Acredita- se que esse fato seja devido a o tamanho dos blocos de dados carregados na memória cache serem mais adequados para exploração da localidade de dados e do paralelismo, em especial no nível 3 da BLAS, o qual se sabe tem desempenho diretamente dependente do tamanho dos blocos de dados.
Figura 5.3: Speedups obtidos por o solver otimizado na resolução de um sistema gerado aleatoriamente de ordem 10.000.
Speedup superlinear em todas as execuções.
Tabela 5.9: Tempos médios, em segundos, consumidos por o solver otimizado para resolução de um sistema aleatório de ordem 18.000.
Algoritmo S. Al. S. Al.
Para. Para.
Para. Para.
Figura 5.4: Speedups obtidos por o solver otimizado na resolução de um sistema gerado aleatoriamente de ordem 15.000.
Concorrência dos threads por o cache, causando ociosidade nos threads.
Observa- se, também, que nos sistemas de maior ordem a abordagem alternativa de paralelização do Passo 4, ou seja, a coluna «Sp P4.
Seq. &quot;obteve resultados ligeiramente melhores do que a abordagem principal( «Sp P4.
Par.&quot;). É importante observar que os ganhos de desempenho da paralelização indicada por «Sp P4.
Par. «se devem principalmente ao reuso dos dados em cache, ou seja, no momento em que um thread carrega uma posição ou bloco da memória para o cálculo do limite superior (ou inferior), por ser o cache compartilhado, o mesmo pode ser também acessado por o (s) thread (s) do limite inferior (ou superior) sem que haja necessidade de buscar novamente os dados na memória.
Acredita- se, nesse caso, que o não sincronismo dos threads que operam sobre os mesmos dados, compartilhando cache, seja responsável por a diferença.
Enquanto na abordagem Linear Sp T. T. Par.
Sp T. T. Seq.
Sp P1.
Par. Sp P1.
Seq. Sp P4.
Par. Cabe ainda observar que, embora o passo de verificação não tenha sido explicitamente paralelizado no desenvolvimento do solver otimizado, o fato de empregar as rotinas multithread da MKL fez com que o mesmo obtivesse ganhos de desempenho ao aumentar o número de cores mantendo, assim, constante a proporcionalidade do tempo consumido por tal passo.
A o resolver, com 1 thread, o sistema de ordem 6.000, o passo de verificação representava 2% do tempo total de execução do solver paralelo e 10% quando executando com 8 threads.
Em o sistema de ordem 10.000, sua participação nas mesmas situações corresponde a, respectivamente, 1,75% e 9,5% do custo total.
Já para o sistema com n $= 15.000, tal passo responde por, aproximadamente, 2% em 1 núcleo e 4% em 8 núcleos.
Por fim, no sistema de ordem 18.000, tais custos correspondem, respectivamente, a 1% e 8%.
Executou- se ainda o solver para sistemas de ordem 20.000.
Entretanto, embora a resolução de Selas dessa ordem seja suportada por a ferramenta no ambiente de testes disponível, não foi possível concluir tais avaliações.
Isso porque, após 2 horas, em média, de execução do solver, o processo recebe sinal de kill do escalonador do sistema operacional.
A Figura 5.6 ilustra o crescimento do tempo de execução do solver em relação a o crescimento da ordem do Sela resolvido.
Por fim, a comparação entre os tempos consumidos por as rotinas do LAPACK em ambiente com processadores multicore confirma, em todas as situações, que de fato o pacote não oferece ganhos de desempenho em arquiteturas do tipo multicore.
O passo de inversão da matriz, por exemplo, apresentou, para os sistemas de ordem 15.000 e 18.000, respectivamente, speedups de apenas 1, 02 e 1, 04 ao executar em 8 cores.
Considerações Finais Em este capítulo, diversas avaliações do solver otimizado foram apresentadas.
Em relação a a exatidão dos resultados numéricos, avaliou- se tanto sistemas bem condicionados quanto mal condicionados, obteve- se resultados satisfatórios em ambas as situações.
Tais resultados foram comparados à versão original da ferramenta e, dessa forma, comprovou- se que não houve perda de qualidade com a otimização da solução proposta.
Em relação a os testes de desempenho, sistemas de diferentes ordens de grandeza foram resolvidos.
De modo geral, obteve- se como resultado o comportamento esperado, apenas para o sistema de ordem 18.000 os tempos de execução se apresentaram imprevisíveis.
Em encontram- se matrizes correspondentes a problemas reais das mais diversas áreas.
Cabe observar, de modo a contextualizar o porte dos sistemas resolvidos neste trabalho, a variedade das ordens das matrizes disponíveis.
Em a disciplina de Engenharia Química, por exemplo, diversas matrizes apresentam n menor do que 1.000.
Já em problemas relacionados a energia elétrica, matrizes com ordem de ordem 5.000, 12.000, de entre outras.
O sistema de maior porte encontrado pertence à disciplina de Mecânica Estrutural, a ordem do mesmo é de 90.449.
Assim, pode- se considerar os resultados bastante satisfatórios, uma vez que foi possível resolver, com ganhos de desempenho, sistemas de ordens variadas que abrangem uma diversidade de problemas reais.
Adicionalmente, os speedups apresentados são bastante significativos para a classe de arquitetura em questão.
Confirmou- se, ainda, através das avaliações deste capítulo, que, de fato, o LAPACK não apresenta ganhos de desempenho significativos em arquiteturas multicore.
Este trabalho apresentou uma aplicação da Computação Verificada em conjunto com a Computação Paralela para resolução de Sistemas de Equações Lineares Intervalares.
Dentro desse contexto, a principal contribuição do mesmo é a disponibilização de uma ferramenta para resolução de Sistemas Intervalares Densos de Grande Porte com verificação automática dos resultados otimizada para execução em arquiteturas dotadas de processadores multicore.
Tal ferramenta é capaz de prover resultados auto-validados para Sistemas Lineares cujos dados de entrada podem ser tanto intervalos quanto números pontuais, permitindo, dessa forma, ao usuário resolver problemas utilizando dados incertos.
A exploração do paralelismo inerente ao algoritmo permite ao solver se beneficiar das características presentes nas arquiteturas paralelas obtendo, assim, ganhos de desempenho.
Em este projeto, explorou- se os processadores multicore de modo a tornar o tempo de execução da solução desenvolvida mais satisfatório para o usuário.
Adicionalmente, bibliotecas de software para Álgebra Linear, altamente otimizadas para as arquiteturas em questão, foram empregadas para otimizar a execução do solver desenvolvido.
Para viabilizar essa estratégia, identificou- se como o algoritmo mais adequado da Computação Verificada para resolução de Selas o Método Verificado Baseado no Método de Newton.
Além de ser um algoritmo da Computação Verificada, o principal diferencial desse método é o fato de permitir sua implementação empregando a Aritmética de Ponto--Médio e Raio, o que possibilita o desenvolvimento baseado nas bibliotecas MKL e Plasma.
De fato, as avaliações de desempenho demonstraram êxito no atendimento daquele que pode ser resumido como objetivo principal deste trabalho:
Otimização do solver para execução com ganhos de desempenho em arquiteturas multicore.
Com efeito, observou- se, devido a a utilização das rotinas da biblioteca Plasma, que não apenas o paralelismo em nível de threads foi responsável por o ganhos.
A estratégia de execução do software de modo análogo a um pipeline superescalar, através de práticas como escalonamento e execução fora de ordem, antecipação de operações, não sincronismo e divisão das matrizes em submatrizes, trouxe também forte contribuição para o desempenho do solver.
Comparando- se, o passo de inversão da matriz A executado por chamadas às rotinas da Plasma com o mesmo passo executado por o LAPACK, ambos utilizando somente 1 núcleo, tem- se uma diferença em torno de aproximadamente 1, 65 vezes.
Além disso, ao aumentar- se o número de núcleos, enquanto a solução que utiliza a Plasma apresentou speedup crescente e bastante satisfatório, seu equivalente utilizando LAPACK apresentou variação mínima no tempo de execução e speedup médio abaixo de 1, 05 para 8 cores.
Comparando- se as execuções multithread empregando a Plasma com aquela utilizando LAPACK, obteve- se speedups bastante superiores em todas as situações.
As demais constatações acerca de o desempenho apresentaram- se também satisfatórias.
Em geral, obteve- se speedups de valor considerável tanto em relação a os passos paralelizados quanto a os tempos totais de execução, especialmente considerando a classe de arquitetura empregada.
Realizou- se, ainda, avaliações utilizando números de threads superiores ao número de processadores disponíveis.
Tais testes apresentaram, em todos os casos, perda de desempenho.
Cabe observar que, apesar de o computador utilizado durante as avaliações possuir o recurso de Hyperthreading habilitado, essa situação é esperada devido a o fato do algoritmo estar paralelizado e do Hyperthreading ser uma técnica que, em geral, traz ganhos para os trechos de softwares não paralelos.
A escalabilidade é, também, uma característica presente no solver desenvolvido.
As avaliações do Capítulo 5 mostraram que, exceto para o sistema de ordem 18.000, ao comparar- se a resolução de dois sistemas num mesmo número de cores, em todos os casos o speedup é maior para o sistema de maior ordem.
Adicionalmente, considerando- se a resolução de um mesmo sistema e a variação apenas do número de cores, o crescimento do speedup, embora não-linear, é mantido em todas as situações.
Em relação a exatidão, obteve- se resultados bastante satisfatórios.
Mesmo para o sistema fortemente mal condicionado (matriz de Boothroyd/ Dekker), a ferramenta encontrou soluções verificadas.
Já considerando os sistemas gerados aleatoriamente que, por sua vez, apresentam bom condicionamento, os resultados são ainda mais precisos.
Em diversos casos o intervalo apresentou diâmetro igual a 0 para uma exatidão de sete casas decimais, em outros houve variação de apenas uma unidade na última casa decimal.
Portanto, de modo geral os resultados obtidos podem ser considerados bastante satisfatórios, uma vez que todos os objetivos da Computação Verificada foram atingidos e que as estratégias de desenvolvimento adotadas permitiram ao solver atender o requisito de desempenho definido.
Além disso, conforme observado no Capítulo 5, a ordem dos sistemas resolvidos é suficiente para abranger uma série de problemas científicos reais.
Cabe ainda observar que, embora o solver utilize um algoritmo destinado a resolução de Sistemas Densos, o mesmo é, também, capaz de resolver Sistemas Esparsos.
Entretanto, por não ser otimizado para esse tipo de problema, tais sistemas são tratados por o solver de maneira análoga aos Selas Densos e, por isso, os potenciais benefícios de desempenho e armazenamento inerentes às estruturas esparsas são desprezados.
A habilidade de resolver Sistemas Intervalares Densos de Grande Porte com verificação automática dos resultados é de notória importância para diversas áreas do conhecimento, principalmente ao trabalhar com dados incertos.
Em esse contexto, a possibilidade de executar tais computações com tempo reduzido em arquiteturas multicore, as quais possuem baixo custo e se tornam cada vez mais populares, oferece grandes facilidades a diversos pesquisadores para o correto entendimento dos problemas por eles modelados.
Trabalhos Futuros Os resultados deste projeto encontram- se parcialmente publicados em.
Durante a rea-lização do mesmo, identificou- se alguns pontos de interesse para a continuação e aperfeiçoamento da pesquisa desenvolvida.
Tratam- se de aspectos para melhoria da solução aqui apresentada tanto considerando o contexto desenvolvido quanto as possibilidades para ampliação do escopo.
São eles:·
Otimização dos passos do Algoritmo 4.1 não paralelizados no presente trabalho;·
Aperfeiçoamento da paralelização de modo a aumentar a escalabilidade do solver;·
Desenvolvimento de uma estratégia que permita detectar, em tempo de execução, a abordagem de paralelização mais adequada em relação a o Passo 4 do Algoritmo 4.1 para resolução de um dado sistema;·
Implementação de algoritmos alternativos para verificação dos resultados, os quais devem permitir obter benefícios das matrizes com estruturas especiais como, por exemplo, Sistemas Esparsos;·
Integração da solução desenvolvida com soluções para ambientes paralelos baseados em troca de mensagem visando exploração do solver em agregados de computadores cujos nós são constituídos por computadores dotados de processadores multicore;·
Desenvolvimento de estratégias que permitam obter ganhos de desempenho em computadores heterogêneos/ híbridos, ou seja, naqueles em que é possível explorar o paralelismo não apenas em CPUs com múltiplos cores mas também em GPUs.
Uma possibilidade nesse sentido Architectures) bem como uma possível integração quando houverem bibliotecas disponibilizadas por o mesmo.
