Este trabalho relata um método para extração de sintagmas nominais (SNs) de sentenças escritas em português.
Os SNs extraídos servirão como base na formação dos índices de documentos e na formação dos termos de consulta do usuário, aplicados a sistemas de recuperação de informações (SRI).
Esta dissertação apresenta um estudo detalhado da estrutura do sintagma nominal, fixando- se na abordagem de Mário A_ Perini para identificar regras que venham a compor uma gramática do Sn.
Esta gramática é incorporada ao método ED-CER, cujo protótipo é composto por dois módulos:
Seletor e Analisador.
Esses módulos são descritos neste trabalho, tendo sido também prototipados.
O módulo Seletor extrai da sentença um candidato a Sn e o envia ao módulo Analisador.
Em o módulo Analisador utilizamos um analisador sintático do tipo LR para a extração do Sn:
Os candidatos a Sn, que estão de acordo com a gramática são extraídos.
Finalmente, o trabalho é comparado com outros trabalhos correlatos.
Palavras-chave: Processamento de linguagem natural (PLN), extração de sintagma nominal, recuperação de informações (Ri).
O objetivo geral deste trabalho é propor um método para a extração automática do Sintagma nominal (Sn) de sentenças em português, aplicando recursos de Processamento de Linguagem Natural (PLN) em Sistemas de Recuperação de Informações (SRI).
Foi assim proposta a metodologia ED-CER, que possui dois módulos:
Seletor e Analisador.
Nosso desafio está em encontrar palavras-chave ou expressões-chave para representar o conteúdo de resumos (indexação), podendo entre estas encontrar as palavras-chave extraídas da consulta do usuário, na procura posterior por esses documentos (consultas).
Essas tarefas de indexação e consulta são aplicadas a SRI.
O processo de seleção e busca da informação num banco de dados de SRI pode ser visto sob dois pontos de vista diferentes.
Um de eles é o do usuário da informação.
Vamos considerar como usuário uma pessoa que precisa de uma informação e usa um SRI para tentar satisfazer a essa necessidade.
Outro ponto de vista é decidir como colecionar informação, organizar- la e armazenar- la para mais tarde procurar- la e recuperála.
Meadow e seus co-autores abordam especificamente o tratamento da informação em Recuperação de Informações (Ri).
Para esses autores a informação tem certas características básicas:
É representada por um conjunto de &quot;símbolos «organizados numa &quot;estrutura».
Um conjunto de símbolos forma um conjunto maior, um texto, que possui informações.
Essas informações podem estar contidas em documentos como jornais, livros, artigos etc, e apresentadas para entendimento humano.
Ri envolve, então, três conceitos:
Como representar a informação, como interpretar a estrutura de seus símbolos e como identificar um conjunto de símbolos.
De essa idéia básica proveniente de ficaremos com o que aqueles autores citam como sendo a característica básica da informação:
Conjunto de &quot;símbolos «organizados numa &quot;estrutura».
Acreditamos que o Sn que nos propomos a identificar e extrair, nas sentenças, é também uma informação.
Uma informação que é composta de um conjunto de símbolos e possui uma estrutura (a ser abordada no capítulo 3), que acreditamos ser significativa para a identificação do tema ou assunto principal de um documento.
Em todo o nosso trabalho e para todo o processo funcional trabalhado, trataremos a informação somente como textos escritos em língua natural.
O corpus (conjunto de textos usados no trabalho) que utilizamos provem dos resumos de dissertações do Programa de Pós-graduação em Ciência da Computação, em formato digital, dos alunos da Pontifícia Universidade Católica do Rio Grande do Sul (PUCRS).
Em geral os documentos possuem uma enorme variedade de frases ou idéias que podem servir de índice.
Um item do índice pode ser qualquer palavra de um documento, sendo de vital importância que esta palavra represente, de uma forma geral, o significado do conteúdo do documento.
Meadow e seus co-autores confirmam essa idéia:
&quot;os termos que representam o assunto do texto podem ser usados como índice do texto».
Pode- se, então, colocar a seguinte questão:
Quais as palavras ideais para indexar o texto?
Poderíamos indexar todas as palavras do texto, mas teríamos problemas referentes à performance e poderíamos estar indexando palavras diferentes com mesmo significado, com isso criando índices duplicados.
Têm surgido novas tecnologias de processamento, análise e interpretação do conteúdo de um texto, em particular o conteúdo da linguagem natural, para auxiliar no problema de indexação em recuperação de informações.
Em esta fase as áreas de Ri e PLN convergem na busca por palavras ou conjuntos de palavras que possuem uma representação temática maior, servindo ao processo de indexação e consulta.
Segundo Coulon e Kayser as palavras de um texto podem- se dividir em duas categorias:
As que possuem significado e as demais.
Entre as palavras que possuem significado estão palavras (ou conjuntos de palavras) normalmente com sentido substantivo que, segundo Thrane, podem realizar certas funções gramaticais (como sujeito e objeto), certas funções semânticas (como agente e instrumento) ou certas funções retóricas (como tópico ou tema).
A estas palavras, ou conjuntos de palavras, denomina- se Sn, e as mesmas constituem o conjunto de palavras que utilizaremos para servir como índice de documentos em Ri.
Buscamos na lingüística embasamento sobre a estrutura do Sn.
Tivemos basicamente como autores, na lingüística, Mario A_ Perini e Yara G_ Liberato.
Desenvolvemos então um método denominado ED-CER, de extração do Sn, constituído de dois módulos.
Através de um módulo denominado Seletor, eliminamos palavras que com certeza não fazem parte de um Sn (como verbos, locuções e pontuação) decompondo assim a sentença em partes menores, de onde são extraídos &quot;candidatos «a Sn.
Esses candidatos são enviados a um módulo denominado Analisador, que utiliza uma gramática do Sn e um processo de parsing semelhante ao empregado nos analisadores sintáticos LR.
Em o módulo Analisador é feita a análise sintática do candidato a Sn verificando a sua conformidade, ou não, com a gramática.
Se o candidato a Sn está de acordo com as regras da gramática, é reconhecido como Sn.
Para demonstrar nosso método de extração de Sn (ED-CER) e também analisar os resultados, desenvolvemos um protótipo, construído em linguagem de programação Para validação dos resultados utilizando o método ED-CER utilizamos a conferência manual, o trabalho de Bick e alguns exemplos utilizados no trabalho correlato de Vieira.
A dissertação está estruturada em capítulos, precedidos desta introdução e seguidos de uma conclusão.
Em o capítulo 2 descrevemos os desafios da Ri em atender às necessidades de consulta do usuário, a formação e tipos de índices necessários à Ri, também utilizando técnicas de PLN, bem como a questão da relevância ou não dos documentos recuperados numa consulta.
Em o capítulo 3 procuramos refletir a caminhada realizada para encontrar conceitos, definições e a estruturação dos sintagmas nominais (SNs) (em termos de o conjunto de palavras que os compõem) em sentenças da língua portuguesa.
Tivemos como autores, para estudos bibliográficos, Mário A_ Perini e Yara G_ Liberato, ambos pesquisadores da Universidade Federal de Minas Gerais (UFMG) na área de estudos lingüísticos.
Diante de as pesquisas desses dois autores é que conseguimos definir uma estrutura para o Sn.
O resultado desta estrutura foi transferido para a gramática que usamos na elaboração de nosso modelo de extração do Sn, abordado no capítulo 5.
Os maiores avanços no uso do PLN, na Ri, estão em trabalhos feitos para a língua inglesa.
Procuramos, no capítulo 4, descrever os trabalhos correlatos que nos serviram de base.
Destacamos um trabalho para a língua portuguesa, desenvolvido por Vieira e seus co-autores, de onde retiramos exemplos que são validados por nosso método ED-CER.
Em o capítulo 5 descrevemos nossos ensaios até desenvolvermos um método para a extração do Sn.
A o método resultante damos o nome ED-CER.
O protótipo do EDCER possui dois módulos descritos em detalhe e com exemplos neste capítulo, e também funcionou como elemento de validação de nossa proposta.
Considerações finais e trabalhos futuros são colocados no capítulo 6, da conclusão.
Grande parte das informações armazenadas por o homem se encontra, atualmente, em formato digital.
Uma das preocupações dos pesquisadores da área de Ri está em como organizar e representar as inserções de novos documentos neste acervo, bem como facilitar a busca aos documentos, numa posterior recuperação.
Os documentos ficam armazenados num banco de dados textuais em língua natural e, através de uma interface, também em língua natural, os usuários buscam por documentos específicos.
O PLN, segundo Evans e Zhai, pode ser aplicado a um sistema de Ri em dois momentos:
1) na construção das representações lógicas dos documentos, ou seja, na indexação;
2) na construção da representação da necessidade de informação do usuário, ou seja, na formulação da consulta.
Em este capítulo abordamos aspectos de Ri, no que diz respeito a formação de índices e tipos de consultas de usuários a um SRI.
Também discutimos sobre a colaboração das técnicas de PLN aplicadas a Ri.
Para Baeza-Yates e Ribeiro-Neto, o cenário inicial que introduz o processo de Ri é composto, de um lado, por a necessidade de informação dos usuários e, de outro lado, por uma coleção de documentos digitais entre os quais, possivelmente, existem alguns documentos contendo informações relevantes aos usuários.
Alguns fatores dificultam uma solução para o problema de Ri:
Nem sempre o usuário consegue expressar o que quer de forma adequada, em virtude de a construção da consulta ou da interpretação por o sistema e, a quantidade de documentos não relevantes pode ser, e geralmente é, muito grande.
Acrescentamos a estas dificuldades citadas por Baeza-Yates e Ribeiro-Neto, também, a questão da indexação, onde a seleção dos termos de índice dos documentos é crítica na determinação do nível de precisão (precision) e resposta (recall) a uma tarefa de Ri.
Um sistema de Ri pode ser avaliado, no resultado de uma pesquisa, por o ranking de documentos relevantes ou não que traz como retorno.
Existem duas propriedades que são medidas para avaliar esse ranking:
Precisão, que é o percentual de documentos relevantes retornados, em relação a todo o conjunto de documentos, e resposta, que é o percentual de todos os documentos relevantes, no conjunto de documentos retornados.
Se toda a coleção é recuperada, então a resposta é 100%, mas a precisão é baixa.
Se poucos documentos são retornados, a precisão é alta, mas a resposta é baixa.
Usando um exemplo de requisição de informação &quot;I «(de uma coleção de referência de teste) e seu conjunto &quot;R «de documentos relevantes, seja R o número de documentos neste conjunto.
Assume- se que uma dada estratégia de recuperação processe a requisição de informação &quot;I «e gere um conjunto-resposta de documentos &quot;A».
Seja A o número de documentos neste conjunto.
Ainda, seja Ra o número de documentos da interseção dos conjuntos &quot;R «e &quot;A».
Temos, então, que:
Resposta é a fração do conjunto dos documentos relevantes (o conjunto &quot;R&quot;) que é recuperado:
Resposta $= Ra/ R. Precisão é a fração do conjunto dos documentos recuperados (o conjunto &quot;A&quot;) que é relevante:
Precisão $= Ra/ A. Precisão e resposta são, então, duas propriedades que devem ser observadas no resultado da recuperação.
A precisão inicia em 100% e resposta inicia em 0%.
Também podemos dizer que as informações em formato texto não são projetadas para serem usadas numa recuperação de documentos por o computador.
A forma desestruturada que um texto pode apresentar pode ser outra dificuldade, quando se deseja procurar alguma informação específica no conjunto de palavras do texto.
Nosso desafio, neste trabalho, é localizar, no conjunto de palavras que formam uma sentença, o Sn para uso por a Ri na formação de índices e de termos de consultas dos usuários.
Os SRIs podem ser classificados quanto a o modo operacional ou quanto a a forma de trabalho do usuário.
Para o modo operacional, segundo Baeza-Yates e Ribeiro-Neto, existem duas classificações:
Sistemas de recuperação convencionais (ou ad-hoc) e (2) filtragem.
Para a forma de trabalho do usuário temos também duas classificações:
Sistemas de recuperação propriamente ditos e browsing (tarefa semelhante à de folhear páginas de um livro em busca de informação, sem ter, como objetivo, uma consulta específica mas, somente, referência a um determinado assunto).
Em o modo operacional, nos sistemas de recuperação convencionais, os documentos permanecem estáticos enquanto as consultas ad-hoc são submetidas ao sistema.
Como exemplo, podemos citar o acesso a uma enciclopédia eletrônica.
A o processo onde os documentos são inseridos dinamicamente na base de informações, denominamos filtragem.
Um exemplo de filtragem pode ser um acesso a um banco de dados com informações referentes a quantidades em estoque de produtos de uma determinada empresa, onde documentos de compra e venda de produtos ficam atualizando as informações de produtos, dinamicamente.
Para nosso propósito, podemos considerar que iremos atuar no modo operacional, e realizar recuperação convencional.
Como forma de trabalho do usuário, no sistema de recuperação propriamente dito, o usuário executa uma consulta com informações específicas;
Por exemplo, o usuário faz uma pesquisa procurando informações sobre &quot;consumo de café».
É este o tipo de consulta que pretendemos, especificamente, beneficiar com nosso trabalho.
De esta informação pretendida por o usuário, podemos selecionar o Sn como tema ou assunto necessários ao usuário.
A outra forma de trabalho, denominada browsing, diz respeito a informações não definidas por os usuários, isto é, o caso em que o usuário não está disposto a especificar uma consulta, querendo explorar um determinado conjunto de documentos procurando referências a assuntos que lhe possam interessar.
Um exemplo disso pode ser o acesso que o usuário faz a um jornal qualquer na Internet, &quot;folheando «os documentos à procura de informações e links interessantes para aquele momento.
Analisaremos, a seguir, com maiores detalhes, a questão das formas de consulta e tipos de usuários que podem acessar um SRI, e também a questão da indexação automática de documentos.
Coulon e Kayser afirmam que podemos resumir um texto em palavras-chave e, através de uma expressão, identificar se um texto responde positiva ou negativamente a uma consulta.
Uma consulta em SRI expressa a necessidade do usuário por informação.
Consulta é o nome dado a um comando que pode ser expresso em linguagem natural com a finalidade de especificar que informação deve ser recuperada.
O resultado da pesquisa do usuário constitui um conjunto de documentos, relevantes ou não.
O termo &quot;relevante «é usado aqui para representar que um item contém as informações buscadas.
Em uma pesquisa, a informação para o SRI pode ser relevante enquanto que, para o usuário, não.
O usuário já pode ter conhecimento desta informação (o que a torna irrelevante para ele) enquanto que, para o SRI, pode ser uma informação relevante e necessária para acesso a outras informações relacionadas com a necessidade do usuário.
Segundo Kowalski, quando o usuário decide pesquisar um assunto, o banco de dados é logicamente dividido em: --
itens relevantes -- são os itens que ajudam na pesquisa em resposta à questão formulada por o usuário. --
itens não relevantes -- são os itens que não provêm nenhuma informação diretamente útil.
Para recuperar o documento de maior valor ou relevância, muitos sistemas de Ri usam um modelo que produz uma classificação de documentos, em ordem decrescente de probabilidade de relevância.
A classificação é feita analisando consecutivamente a relevância do documento em relação a os documentos que não foram ainda recuperados, até chegar a uma lista de documentos que estão classificados em ordem decrescente de probabilidade de relevância.
Podemos, por exemplo, usar a palavra mais freqüente no documento como descrição do conteúdo do documento, mas não podemos dizer que um documento que possui três ocorrências dessa palavra é três vezes mais importante do que um documento que possui somente uma ocorrência dessa palavra.
Cowie e Lehnert afirmam que um texto longo pode conter informações relevantes em poucos parágrafos.
Muitos modelos experimentaram abordagens probabilísticas, usando freqüência de palavras, para computar a probabilidade de um texto ser relevante.
Para detectar parágrafos relevantes, é calculado o número de vezes em que as palavras-chaves aparecem no parágrafo, em relação a todo o texto.
Esta comparação permite calcular a probabilidade de um documento ser relevante, baseado na freqüência da ocorrência de uma palavra no documento.
Baeza-Yates e Ribeiro-Neto classificam as consultas em: --
Consulta por palavra-chave.
É a consulta por uma palavra única, onde o sistema busca esta mesma palavra num determinado contexto ou busca palavras semelhantes a ela.
Também existem as consultas por frases, que nada mais são do que uma seqüência de consultas, para cada uma das palavras da frase. --
Consulta por padrões de comparação.
É um padrão um conjunto de características sintáticas que devem acontecer numa parte do texto.
Os principais tipos de padrões etc..
Então, se uma parte do texto coincide com um dos tipos de padrão, ela é evidenciada. --
Consulta estruturada.
É a consulta com estruturas fixas.
Sabe- se que o conjunto de documentos possui em comum, por exemplo, uma especificação de endereço residencial.
Então, faz- se a busca por o conteúdo desta estrutura.
A consulta estruturada pode ocorrer com hipertexto, onde a consulta é do tipo browsing (isto é, sem uma especificação do conteúdo procurado e somente uma referência), ou com estrutura hierárquica, que é um modelo natural para alguns tipos de textos como, por exemplo, os livros. --
Consulta em linguagem natural.
Envolve etapas de análise léxica, eliminação de stopwords1 e stemming2.
Soma- se, à complexidade da busca, o fato seguinte:
Um usuário não especialista na área, que não tem domínio do assunto, pode não usar o vocabulário da área para fazer sua pesquisa.
O usuário inicia sua pesquisa com um conceito geral da informação que procura, ele não tem uma idéia específica do que precisa.
Até mesmo quando um usuário especialista no assunto faz a sua pesquisa ele tem restrições, pois cada autor pode ter um vocabulário específico.
Assim, um SRI deve prover ferramentas para ajudar o usuário nas suas especificações de busca.
Em particular, as ferramentas de busca devem ser automáticas e, através de um sistema interativo, auxiliar no desenvolvimento da especificação da pesquisa.
Além de as facilidades que o usuário deve ter na formulação da consulta num SRI, devemos ter uma preocupação com a forma com que os documentos são indexados.
Veremos a seguir conceitos sobre indexação automática de documentos.
Um índice é um conceito ou uma coleção de palavras associadas a ponteiros para recuperação rápida de informação.
Um dos problemas da Ri consiste, principalmente, na construção de índices eficientes, processando consultas de usuários com alta performance e obtendo a maior qualidade possível no conjunto de respostas.
Um índice pode ser qualquer palavra de um documento, sendo de vital importância que esta palavra represente, de uma forma geral, o significado do conteúdo do documento.
Para indexar um livro, um artigo de jornal, um relatório técnico, são registrados valores de vários atributos que possam depois ser usados como base na pesquisa.
Entre estes, os mais comuns são as palavras-chave do texto.
Para facilitar a recuperação, podemos criar atributos que, nesta coleção, facilitem a identificação do significado e posterior recuperação.
Podemos relacionar ou agrupar registros que compartilham valores de atributos com o mesmo significado.
Por exemplo, &quot;areia do deserto «pode ser a cor de um automóvel e pode ser a própria areia do deserto.
Existem alguns assuntos específicos que podem possuir uma estrutura e classificação pré-definida em sua apresentação (por exemplo:
Assuntos que envolvem a área de botânica da biologia, ou então a classificação dos livros em assunto, autor, nacionalidade etc).
As palavras também podem ser truncadas e armazenadas, para conseguir, assim, maior aproximação com uma mesma raiz.
Para encontrar palavras similares, podemos usar dicionários ou thesauri que contenham o relacionamento de uma palavra com outras.
Usaremos a definição de thesaurus de Baeza-Yates e Ribeiro-Neto:
&quot;uma estrutura de dados composta de uma lista pré-compilada de palavras importantes num dado domínio do conhecimento, sendo que cada uma destas palavras está associada a uma lista de outras palavras relacionadas».
Por exemplo, a palavra &quot;hostilidades», mencionada num documento, pode ser interessante quando a consulta é feita usando as palavras &quot;conflito armado», pois ambas as expressões possuem semelhança no significado, e o dicionário ou thesaurus pode declarar que o termo para representar as duas palavras acima é &quot;guerra».
Pode- se fazer uso, também, da associação de palavras num dado contexto.
Segundo Evans e Zhai, um item lexical é uma unidade, uma parte da sentença coerente semanticamente, composta normalmente por a união de duas, três ou mais palavras de uma frase ou sentença, como é o caso de nomes próprios e termos técnicos.
Alguns exemplos de itens lexicais podem ser:
&quot;cachorro quente», &quot;gás lacrimogêneo», &quot;classes gramaticais», &quot;Fernando Henrique Cardoso «e &quot;papel de parede».
Para permitir a recuperação das informações, os sistemas de Ri podem ter, por exemplo, em sua estrutura, a lista de todos os documentos que possuem uma determinada palavra (posting) e a freqüência com que ela ocorre em cada documento.
Esta estrutura é denominada de índice invertido (inverted index), e permite que, através da palavra selecionada na pesquisa, sejam recuperados todos os documentos associados.
Uma versão mais sofisticada do índice invertido possui, também, informações sobre quais as posições do texto em que a palavra ocorre (position information).
Nossa sugestão é extrair os SNs das sentenças, e usar- los como índices.
Veremos, no capítulo 3, maiores detalhes do que os SNs representam numa sentença.
Por enquanto, podemos exemplificar nossa sugestão de índices utilizando o Sn.
Considerando a sentença:
&quot;O turista americano viajou de ônibus», os assuntos ou temas principais tratados nesta sentença são:
&quot;O turista americano «e &quot;ônibus».
Estes dois conjuntos de palavras são os SNs.
A indexação automática pode ser feita utilizando palavras ou conjuntos de palavras (frases) de um documento.
Existem duas formas básicas de procura por uma expressão sintática para criar um índice:
Por palavra ou por frase.
A frase é a menor unidade de comunicação lingüística e apresenta um significado completo.
Segundo Cegalla &quot;a frase pode revestir as mais variadas formas, desde a simples palavra até o período mais complexo elaborado segundo os padrões sintáticos do idioma».
Já para Beardon e seus co-autores, na computação, frase é um componente menor de uma simples sentença.
Por exemplo, podemos dizer que a sentença:
&quot;Nossa tia saiu para as compras «possui duas frases ou sintagmas:
&quot;Nossa tia «e &quot;saiu para as compras».
O processo de percorrer todo o texto explorando a estrutura da sentença, uma vez que se conhece a gramática da linguagem, denomina- se parsing.
Parser é um programa que, fornecido um léxico (lista de palavras e suas categorias sintáticas), uma gramática (conjunto de regras que mostra o relacionamento entre as palavras) e um texto, é capaz de determinar se uma sentença é gramaticalmente correta ou não.
Um atributo como &quot;autor», por exemplo, é gramaticalmente reconhecido como uma frase que consiste do último nome, uma vírgula, um espaço em branco, primeiro nome, uma vírgula, um espaço em branco e o nome do meio.
Se um documento é identificado por os assuntos &quot;História Européia «e &quot;Revolução Francesa», cada uma dessas frases pode ser um índice para facilitar a consulta a um assunto específico que indica.
Se formos usar a palavra &quot;História «ou &quot;Revolução», somente, não teremos uma especialização do assunto.
Em outra situação, se quisermos pesquisar informações sobre a &quot;Companhia Zaffari de Alimentos ou Zaffari Supermercados», podemos indexar somente a palavra &quot;Zaffari «e encontramos os dois documentos.
Porém, como temos diversos tipos de usuários, entre eles os principiantes que, talvez, procurariam sobre &quot;História Européia «procurando pela palavra &quot;Européia», temos também os usuários mais experientes que seriam mais precisos e procurariam por &quot;História Européia».
Então, dependendo do uso do SRI, as duas opções devem servir de formação de índices, a palavra e a frase.
Porém para uma melhor representação do significado do texto, é importante que esta palavra ou conjunto de palavras seja suficiente para a identificação do tema ou assunto principal do documento.
Para Grefenstette as possibilidades de diferentes sentidos, quando os termos são múltiplos, são menores do que o sentido de uma única palavra.
Acreditamos que existam palavras mais ou menos carregadas de significado na sentença.
Baseados na pesquisa realizada podemos afirmar que o Sn é um forte candidato a conter palavras com significado.
Um SRI pode executar tarefas de PLN, como parsing de texto, para encontrar termos e usar estes termos para expressar significado, capturar o conteúdo de um documento na recuperação etc..
O SRI mais tradicional simplesmente extrai cadeias de caracteres para usar como índice.
É nesta fase que as áreas de Ri e PLN convergem.
Podem ser extraídos termos de uma consulta em linguagem natural que são confrontados com termos que servem de índices de documentos, para determinar a relevância de cada documento na consulta.
Em geral, os documentos possuem uma enorme variedade de frases que podem servir de índice, porém é necessário selecionar um conjunto de elas.
Quais as palavras ideais para indexar o texto e como organizar- las?
Poderíamos indexar todas as palavras do texto, mas teríamos problema com performance e poderíamos estar indexando palavras diferentes com mesmo significado e, com isso, criando índices duplicados.
É sobre essa questão que centramos nosso trabalho.
Em a busca por palavras ou conjuntos de palavras que possuem uma representação temática maior, encontramos o Autores como Perini definem Sn como uma classe gramatical com comportamento sintático de sujeito, de objeto direto e, se precedido de preposição, de adjunto adnominal ou de objeto indireto.
Segundo Liberato, o Sn é a parte do enunciado que representa um conceito ou referente.
Para Liberato, os referentes podem ser entidades abstratas ou concretas;
Podem ser identificados por nomes próprios ou através de um Sn descritivo;
E podem ter uso referencial, representando uma entidade, ou uso atributivo, representando um papel.
Em o capítulo que segue, abordamos em detalhe a estrutura do Sn, sob o ponto de vista da lingüística, trazendo a esta dissertação as contribuições de Perini[ Perini1986, 1994, 1995, 1996Liberato1997].
Tivemos basicamente como referências, nesta etapa de estudos, Mário A. Perini e Yara G. Liberato.
O objetivo das pesquisas desses dois autores foi procurar definir uma estrutura para o Sn.
Esta estrutura foi transferida para a gramática que usamos na implementação de nosso trabalho abordada no capítulo 5.
Veremos que o Sn pode ser tratado de forma sintática ou semântica.
Optamos, ao definir um método de extração do Sn, por o tratamento sintático, por a facilidade de se tratar computacionalmente a forma, ao invés de o significado.
Conhecendo as estruturas frasais da língua portuguesa, podemos entender e analisar seus elementos com base na relação entre eles.
As seqüências gramaticais da nossa língua são denominadas sentenças.
Por exemplo, seja a sentença:
A moça assustou o rapaz.
Esta sentença se divide em duas partes principais:
&quot;a moça «e &quot;assustou o rapaz».
Intuitivamente os falantes/ ouvintes continuarão a subdividir ainda a sentença, em outras partes constituintes:
Inicialmente farão uma divisão entre &quot;assustar «e &quot;o rapaz «e, em seguida, entre &quot;a «e &quot;moça», e entre &quot;o «e &quot;rapaz».
A cada uma dessas partes em que se divide a sentença, dá- se o nome de &quot;constituinte», sendo que a própria sentença também é um constituinte.
Em as estruturas frasais observa- se uma hierarquia, isto é, a sentença possui constituintes e estes contêm outros constituintes.
Cada constituinte possui uma estrutura própria e pode ter comportamento sintático diferente Perini entende por constituintes certos grupos de unidades que fazem parte de seqüências maiores, mas que mostram certo grau de coesão entre si.
Por exemplo, seja a sentença:
A casa de Lulu é azul e branca.
Os falantes &quot;sentem «que a &quot;a casa de Lulu «forma uma unidade, o que não se verifica com &quot;Lulu é azul».
Dizemos então que &quot;a casa de Lulu «é um constituinte e que &quot;Lulu é azul «não é um constituinte.
A idéia de que as frases são formadas de constituintes, um ou mais e muitas vezes uns dentro de os outros, concorda com o que diz Liberato em:
&quot;um sintagma, pode possuir mais de um constituinte ou pode ser formado por um único constituinte, ou constituinte simples».
Assim, a sentença poderia ser analisada como contendo, entre outros, os constituintes seguintes:
&quot;a casa de Lulu é azul e branca», &quot;a casa de Lulu», &quot;casa de Lulu», &quot;azul e branca», &quot;é azul e branca «etc..
É importante, segundo Perini, ter uma boa noção da estruturação das sentenças em constituintes, porque toda a análise se baseia em ela.
Por exemplo, os constituintes costumam receber uma &quot;função «na análise tradicional:
&quot;a casa de Lulu «é sujeito, e &quot;azul e branca «é predicativo do sujeito.
Já a seqüência &quot;Lulu é azul «não recebe função alguma, pois não é um constituinte.
Existem várias formas de representar a hierarquização dos constituintes, conforme mostrado nas figuras 3.1 e 3.2.
Tendo como base a sentença, falantes e ouvintes também sabem que &quot;moça «e &quot;rapaz «são do mesmo tipo e que &quot;assustar «não é.
Estas são as classes que ouvinte/ falante intuitivamente conhecem, independente de saberem que são substantivos, adjetivos, verbo etc..
Para nossa representação poderíamos usar letras e números para identificar- los, mas a gramática tradicional da língua portuguesa já os rotulou, e faremos uso desta rotulação.
Com base nisso podemos classificar as palavras que compõem a sentença em:
Art Art moça assustou rapaz.
Art $= artigo N $= nome ou substantivo V $= verbo No caso de o agrupamento formado por o artigo e por o nome, tem- se um Sn.
Também se representa a intuição dos falantes/ ouvintes sobre as relações hierárquicas e as classes de palavras existentes na seqüência &quot;assustou o rapaz».
Essa seqüência forma um constituinte que se denomina sintagma verbal (SV), por ser o verbo o seu núcleo (figura 3.4).
Basta existir o verbo para que haja um SV, por exemplo:
A estrutura sintática indica a forma como as palavras são relacionadas umas com as outras na sentença.
Esta estrutura indica como as palavras são agrupadas numa frase, qual palavra modifica o que em outras palavras, e quais palavras são o centro na sentença.
A forma mais comum de representar a gramática de uma sentença é quebrando- a em suas subpartes principais.
E suas subpartes são quebradas em forma de árvore.
A sentença completa fica conforme o desenho mostrado na figura 3.5, sob a forma de uma árvore rotulada.
Em a representação em árvore (figura 3.5) as palavras são símbolos terminais.
E outros símbolos como S (sentença), Sn ou SV conforme figura 3.5, são denominados símbolos não terminais.
Os símbolos gramaticais como N e V, conforme figura 3.5, descrevem a categoria da palavra.
Para construir a estrutura em árvore de uma sentença, devemos conhecer quais as estruturas legais da língua.
Um conjunto de regras de reescrita descreve quais as estruturas permitidas.
Essas regras dizem que um certo símbolo pode ser expandido em árvore, por a seqüência de outros símbolos.
Cada símbolo é um constituinte da sentença que pode ser composto de uma ou mais palavras.
Para autores como Lobato os sintagmas são formados por constituintes, que nada mais são do que uma palavra ou conjunto de palavras de uma sentença, dividindo- a, normalmente, em duas subpartes básicas:
Sn e SV.
Os sintagmas desempenham uma função na sentença e se combinam em conjuntos em torno de um núcleo.
Dependendo do núcleo, podemos falar em Sn ou SV.
Quando o núcleo for um nome falamos em Sn e quando o núcleo for um verbo, SV.
Ainda podemos ter o sintagma preposicionado (SP), quando este tem função modificadora sobre um ou outro sintagma, combinando preposições e substantivos.
Em a língua inglesa, Allen, por exemplo, afirma que podemos separar as palavras em duas classes:
Classe aberta e classe fechada.
A classe aberta compreende as palavras do tipo:
Nomes, adjetivos, verbos e advérbios.
A classe fechada compreende as palavras do tipo:
Artigos, pronomes, preposições e conjunções.
Allen afirma que as palavras que pertencem à classe aberta formam a base da sentença, elas indicam o tipo de coisa, atividade ou qualidade que a frase descreve.
O Sn, segundo este autor, é constituído de palavras de ambas as classes, cuja base é um nome.
Outra colocação de Allen é que o Sn consiste de nomes comuns e nomes próprios que podem ter uma ou mais palavras.
Por exemplo: New York Times.
O Sn apresenta um núcleo, que pode ser um nome próprio ou comum;
Pode ser ainda um pronome substantivo, pronome pessoal, pronome demonstrativo, pronome indefinido, pronome interrogativo, pronome possessivo, pronome relativo etc..
Além de o núcleo, o Sn pode apresentar determinante (s) e/ ou modificador (es), sendo os determinantes os que antecedem o núcleo e os modificadores os antepostos ou pospostos.
Os artigos, numerais e pronomes adjetivos podem funcionar como determinantes do núcleo;
Alguns podem estar juntos, outros não.
Os exemplos apresentados nesta seção são extraídos do Projeto Rede Escola da Universidade Federal do Rio de Janeiro, e que referência os estudos de Perini sobre Sn.
Por exemplo, analisemos a sentença.
Dia abençoado, esta terça-feira, véspera de Santo Antônio.
Em a sentença o pronome demonstrativo &quot;esta «é o determinante.
Em o Sn os adjetivos, locuções adjetivas, advérbios e locuções adverbiais podem ser denominados modificadores.
Conforme o exemplo, a palavra &quot;abençoado «tem esta função, onde o núcleo &quot;dia «está sendo modificado pela palavra &quot;abençoado».
Em nosso dia a dia, fazemos uso de nomes para funções como:
Identificar seres e objetos (substantivos) e caracterizar, especificar ou especializar seres e objetos (adjetivos).
O substantivo é, por natureza, o núcleo do Sn e o adjetivo, do ponto de vista funcional, tem a posição de modificador do núcleo do Sn.
Podemos dizer, então, que o Sn possui mais do que uma possibilidade de estruturação.
Ele pode ser formado ora por determinante (DET)+ núcleo (N)+ modificador (MOD);
Ora por N+ MOD;
Ora por DET+ MOD+ N+ MOD;
Ora por DET+ N. Por exemplo, analisemos o conteúdo da tabela 3.1: Os pronomes pessoais ou pronomes demonstrativos são, por si só, em alguns casos, Sn.
Por exemplo, analisemos e.
Ele chegou atrasado.
Isto é meu.
Em a sentença o pronome pessoal &quot;ele «é o Sn e na sentença o pronome demonstrativo &quot;isto «é o Sn.
A gramática tradicional classifica o SP ligado a nome como um adjunto adnominal nos casos em que expressa idéia de posse, pertença, autoria, especificação, origem, semelhança, fim, matéria, qualidade e restrição.
Por exemplo, analisemos as sentenças a:
A casa está pronta. (
posse) Os parafusos estão frouxos. (
pertença) O conto agradou. (
autoria) Enriqueceu sua coleção. (
especificação) A água era fresca e cristalina. (
origem) O sambista tinha aspecto. (
semelhança) Fecharam a secular casa. (
fim) Serviu champanha em taças. (
matéria) Raul Pompéia era homem. (
qualidade) Acácio tinha fama. (
restrição) Considerando o Sn como uma classe de formas, podemos reconhecer- lo analisando e verificando a sua estrutura interna.
Para Perini as unidades lingüísticas apresentam dois aspectos fundamentais:
A forma (o significante) e o significado.
Por exemplo, seja a palavra &quot;reloginho».
De o ponto de vista formal pode- se levar em conta sua pronúncia, sua composição morfológica, onde o radical seria &quot;relog «e o sufixo &quot;inho», seu comportamento sintático etc..
De o ponto de vista do significado, podemos considerar que é um objeto usado para indicar horas, indica um objeto relativamente pequeno etc..
Então, seguindo as considerações deste mesmo autor, a descrição de uma língua é composta de 3 (três) entidades: --
uma descrição formal (fonologia, morfologia e sintaxe); --
uma descrição semântica; --
um sistema que relaciona o plano semântico com o plano formal.
Observamos nas sentenças a exemplos de frases com igual sintaxe e diferente semântica.
Esta é a mulher mais bonita de Belo Horizonte.
Esta é a poesia mais bonita de Mário Quintana.
Esta é a gravata mais bonita de Mário Quintana.
Conforme Perini o Sn tem uma estrutura bastante complexa, incluindo vários termos de comportamento sintático diverso;
Ou seja, é possível distinguir, dentro de o Sn, diversas funções sintáticas.
Perini acredita que os constituintes, para compor um Sn, possuam posições rígidas.
Ele estabelece o conceito de &quot;SN máximo», formado por a seqüência mais longa possível de termos, tais que todos tenham comportamento sintático claramente diferente.
Este autor divide o Sn máximo em duas estruturas:
Uma estrutura que está à esquerda e outra à direita, incluindo o núcleo do sintagma nominal (NSN).
Em a figura 3.6 apresentamos a estrutura do Sn máximo de Perini e, na tabela 3.3-1, a descrição detalhada dos itens que podem aparecer nesta estrutura.
Cada função sintática possui um conjunto de classes gramaticais pertencentes a ela.
Classes gramaticais são os grupos de palavras do mesmo tipo.
Os tipos de palavras podem ser:
Verbo, pronome, substantivo, adjetivo etc..
Conforme descrito na tabela 3.3-1, nota- se que a função &quot;Pdet «não aparece na estrutura interna do Sn descrito por Perini.
Segundo o autor, esta função sempre estará antecedendo ou sucedendo um Sn, mas não é parte de ele.
Perini afirma que, nas estruturas frasais da língua portuguesa, as ocorrências do Sn máximo, com todos os seus termos, são muito raras.
Ele define Sn não máximo como todas as ocorrências de Sn que não possuam a representação de obrigatoriamente todas as funções, mas existe a obrigatoriedade de seguir- se esta seqüência.
Ainda podemos citar algumas regras que definem obrigatoriedades de ocorrência de termos (constituintes) em relação uns aos outros.
Como nosso objetivo é extrair o Sn, essas regras de obrigatoriedade das seqüências dos termos podem vir a colaborar na definição de uma gramática específica para o Sn.
Alguns exemplos dessas regras são mostrados na tabela 3.3.
ModI, ModE e PNE, PNI só podem ocorrer na presença de um núcleo.
A única função que pode ocorrer mais de uma vez na sentença é PV e em posições variáveis.
O elemento parentético (entre vírgulas) somente pode estar entre NSN e os Mod, nunca entre PN e NSN.
Uma mesa, por assim dizer, velha.
Antes do Sintagma Preposicionado (que é um Mod) só pode ocorrer um NSN.
Instituto do coração As palavras &quot;dois «e &quot;poucos «nunca aparecem num mesmo sintagma A coordenação de dois PNs é marcada por conjunção &quot;e «e não se confunde com a repetição da função.
Entre o ModI e o ModE pode existir um sinal de pontuação(,).
Um ataque cardíaco, fulminante O NSN é o único destes termos que pode constituir um Sn sozinho.
O que usaremos dos estudos do Perini, neste trabalho, é a parte que diz respeito à descrição formal, principalmente a representação sintática dos constituintes das frases.
Para Liberato os SNs possuem uma função referencial, isto é, se referem a um objeto do mundo exterior como, por exemplo, uma entidade, identificada através de uma palavra ou expressão.
Liberato afirma que o Sn fornece pistas para que o ouvinte identifique o seu referente.
As pistas estão nas palavras e na posição que elas ocupam no Sn, e também em elementos de fora de o Sn.
Por exemplo, sempre que se encontrar um determinante, começa um Sn.
Liberato também concorda que o sintagma nominal possui uma organização em que os constituintes desempenham diferentes funções dependendo de sua posição e da relação que estabelecem entre si.
É baseada nisso que representa a estrutura interna do Sn, definida em termos de as funções que os elementos exercem no processo de identificação do referente.
O significado e os mecanismos utilizados na sua construção servem apenas de base para o estabelecimento dessas funções.
Enquanto Perini preocupa- se mais com a estrutura sintática dos constituintes do Sn, Liberato preocupase mais com as funções semânticas.
Diferente de Perini, Liberato se preocupa em definir cada uma das funções.
As funções semânticas dos componentes de um Sn definidas por Liberato são:
Classificador (CLA), subclassificador (SUB), qualificador (Qual), recortador (REC) e quantificador (QUAN).
Essas funções determinam como os objetos são classificados no mundo (tipos de características de acordo com a classe gramatical).
Em a tabela 3.4 apresentamos as principais categorias gramaticais que representam cada uma dessas funções.
O elemento &quot;classificador «(CLA) delimita a classe mais ampla, em que o referente é enquadrado numa determinada descrição.
Por exemplo: Um exercício (CLA) vai resolver o seu problema.
&quot;um exercício», na sentença, refere- se a uma entidade ou papel e pode ser enquadrado numa classe de entidades denominadas &quot;exercício».
Já, se dissermos:
Um exercício aeróbico (SUB) vai resolver o seu problema.
Estamos delimitando uma subclasse &quot;exercício aeróbico», na sentença, dentro de uma classe mais ampla que é &quot;exercício», então este elemento é denominado &quot;subclassificador «(SUB).
O elemento &quot;qualificador «(Qual) fornece características do referente que, no entanto, não são utilizadas como delimitação de subclasse de uma classe mais ampla em que o referente é enquadrado na descrição (tem função explicativa).
Por exemplo: A agenda lotada (Qual) de hoje.
O elemento &quot;recortador «indica se o referente é constituído da totalidade ou de parte dos elementos da menor classe delimitada qualitativamente.
Os recortadores podem ser divididos em duas categorias, segundo o tipo de recorte que indicam:
Parcial (RECPAR) ou universal (RECUNI).
Por exemplo: Os (RECUNI) telhados da capela.
Um (RECPAR) telhado da capela.
O elemento &quot;quantificador «(QUAN) indica a quantidade de elementos que constituem o referente.
Por exemplo: As poucas (QUAN) horas que me restam.
O elemento &quot;partitivo «(PART) faz um recorte parcial sobre uma classe de entidades representadas por um Sn.
Por exemplo: A menor parte (PART) das revistas compradas.
De o trabalho de Liberato também foi possível extrair algumas regras de ocorrência das funções que podem nos ajudar na formulação da gramática do Sn.
Vejamos, na tabela 3.5, alguns exemplos dessas regras.
Ex: As idéias mais loucas.
As mais loucas idéias.
Com o objetivo de completar a análise da estrutura do Sn para definição da nossa gramática, comparamos as idéias de Perini e Liberato.
A análise semântica proposta no trabalho de Liberato, em oposição ao trabalho sintático de Perini, discute em profundidade aspectos isolados da composição do Sn sem uma preocupação com a sua estrutura geral.
Enquanto Perini se preocupa com as palavras e a seqüência de elas para obter a forma do Sn, Liberato se preocupa somente com os enunciados das sentenças, e com a relação entre os enunciados e seu significado comunicativo.
Podemos distinguir os trabalhos de Perini e Liberato como sendo, respectivamente, um trabalho de avaliação sintática e um trabalho de avaliação semântico-pragmática.
Fizemos uma comparação das funções definidas por Perini e por Liberato a qual é mostrada na tabela 3.6.
Podemos extrair algumas conclusões dessa comparação:
As funções definidas por Liberato como SUB e Qual, podem acontecer antes ou depois do núcleo do Sn.
Em os exemplos 2, 3 e 4, conforme tabela 3.6, os núcleos do Sn respectivamente são:
&quot;agenda», &quot;telhados», &quot;dias».
Em os exemplos 7, 8 e 9 são respectivamente núcleos do Sn:
&quot;velho», &quot;assunto «e &quot;Vozes dÁfrica».
Existem, porém, as funções CLA e NSN que são idênticas, em ambas as abordagens, quanto a sua ocorrência e função dentro de o Sn.
Optamos por utilizar as funções e posições do Sn definidas por Perini.
Nos pareceu mais fácil tratar o comportamento formal dos constituintes no Sn e a relação entre eles, do que tratar a função semântica de cada um em relação a o núcleo do Sn.
Para Liberato, interpretar um Sn é, por exemplo, ao se falar de cabeça, saber que ela pertence a um corpo, que tem outros esquemas do tipo olhos, boca, nariz etc..
Esse conjunto de esquemas é tratado através de scripts, frames ou planos (plans).
Alguns autores dizem que esta rede não tem limite, outros afirmam que o processo deve parar em algum lugar.
Outros, ainda, acreditam que ela seja como uma bola de futebol, dá voltas e volta a pontos por onde já passou.
Por exemplo, quando pedimos &quot;a conta «num restaurante o garçom conhece todo o processo necessário para atender o pedido.
Outro exemplo interessante com sentido pragmático é:
&quot;o filho do Guto «e &quot;meu sobrinho «têm significado gramatical diferente, mas podem- se referir a um mesmo referente, portanto a análise leva em conta traços não só do significado gramatical das expressões mas também o seu contexto situacional e dos locutores.
Esta é uma das principais dificuldades de se tratar computacionalmente o significado das palavras e de elas nas sentenças.
Outra constatação interessante é que a estrutura da sentença não reflete o significado.
Por exemplo, a sentença &quot;a captura», pode ter significado diferente, quando se fala de basebol ou de perseguição policial, porém a estrutura sintática é a mesma, os significados diferentes surgem da inserção da palavra em cada contexto.
Entender o significado de uma sentença depende da situação em a qual a sentença é produzida.
Baseados nos estudos lingüísticos de Perini[ Perini1995, Perini1996] e Liberato observamos que o Sn possui forma sintática, tratada por Perini e semântica, tratada por Liberato.
Optamos por utilizar os conceitos, regras e forma estudados por Perini, por a facilidade de se tratar computacionalmente a forma mais do que o significado.
O que conseguimos a partir desses estudos foi definir uma estrutura, com suas respectivas funções e classes gramaticais, e um conjunto de regras para o Sn.
Tudo isso se transformou na gramática que definimos em nossa proposta descrita no capítulo 5.
Para o processo de extração, precisaremos definir um algoritmo para percorrer os termos da sentença extraindo o conjunto de palavras que formam o Sn, com base na gramática definida.
Em este capítulo são descritos alguns trabalhos encontrados na literatura, que tratam do assunto &quot;extração do Sn «e que servem como ponto de partida para o estudo e desenvolvimento realizados.
A maioria dos trabalhos de extração de Sn é desenvolvida tendo a língua inglesa como base.
Existe atualmente uma pesquisa na Universidade do Vale do Rio dos Sinos ­ RS sobre extração do Sn, para a língua portuguesa.
Descreveremos este trabalho, e outros dois trabalhos desenvolvidos para a língua inglesa.
Os trabalhos escolhidos para uma descrição e voltados à língua inglesa são os desenvolvidos por Voutilainen e Cardie e Pierce e possuem como base os seguintes trabalhos:
Bourigault -- &quot;Surface grammatical», publicado em 1988.
O trabalho de Cardie também cita, na bibliografia, o trabalho de Voutilainen.
A o final deste capítulo tecemos algumas considerações sobre cada um dos trabalhos descritos.
Nptool é um sistema construído por Voutilainen para extrair SNs de textos escritos na língua inglesa.
O principal objetivo de seu trabalho foi auxiliar a tarefa de reconhecer palavras representativas de um texto, para a função de índice.
A principal característica desse sistema é a atenção especial dada à descrição léxica e morfológica.
A análise morfológica é baseada numa descrição detalhada das categorias derivacionais e inflexionais das palavras.
O sistema utiliza um léxico com mais de 56.000 radicais de palavras.
A arquitetura do Nptool é composta dos módulos apresentados na figura 4.1 e que serão descritos na seqüência.
Em a etapa de pré-processamento o processador recebe o texto em ASCII (American Standard Code for Information Interchange), preferivelmente anotado em SGML, reconhece os limites das sentenças, normaliza convenções tipográficas e verticaliza o texto.
Em a análise morfológica, o analisador morfológico reconhece todas as inflexões e formas derivadas de cada palavra buscada no léxico.
Um exemplo do resultado da análise morfológica é apresentado na figura 4.2.
O parsing da gramática de restrições, neste processo, consiste de duas fases:
Desambiguação morfológica e restrição sintática.
A desambiguação morfológica possui a tarefa de descartar as leituras morfológicas onde o léxico apresentou mais de uma possibilidade para a palavra.
Por exemplo, tendo o resultado, conforme figura 4.3, do analisador morfológico para a sentença &quot;a single», o léxico retorna três leituras morfológicas possíveis para a palavra &quot;single».
Duas das análises referem- se a verbo e a outra se refere a um adjetivo (A).
O desambiguador possui um conjunto de regras, extraído da gramática inglesa, onde 99,7% de todas as ambigüidades são resolvidas.
A ambigüidade da palavra &quot;single «é resolvida com a seguinte regra:
&quot;Um determinante nunca está seguido de um verbo».
Assim, a palavra &quot;a «está marcada como sendo determinante (DET).
Então somente a palavra &quot;single», marcada como adjetivo (A), é que pode ficar;
As demais, marcadas como verbo (V), são eliminadas.
Depois da desambiguação morfológica as palavras são analisadas sintaticamente.
Note- se que a ambigüidade sintática foi introduzida diretamente no léxico.
Vejamos o exemplo, conforme figura 4.4, onde a palavra &quot;inlet «é ambígua devido a uma leitura de pré-modificador(@\&gt; N) e uma leitura de nome principal(@ NH).
Todas as etiquetas que descrevem funções sintáticas são precedidas do símbolo@, conforme tabela 4.1.
O sistema possui aproximadamente 120 regras sintáticas.
Essas regras definem a gramática e especificam, por exemplo, a ordem dos determinantes e modificadores, ou que um verbo auxiliar é seguido por um verbo principal etc..
Porém essas regras não são suficientes para resolver as ambigüidades nas funções sintáticas das palavras.
Em este momento o sistema passa, então, para a fase de parsing (Sn-hostil ou Sn-amigável).
Para o tratamento de ambigüidades sintáticas o sistema Nptool usa um parser que produz todas as possibilidades de sentenças que concordam com a gramática.
Usaremos a sentença com duas opções geradas por o parser, conforme figura 4.5, para exemplificar o tratamento das ambigüidades sintáticas.
Opção 1: A ambigüidade léxica ou léxico-morfológica está descrita no léxico conforme a figura 4.6.
Para poupar espaço e facilitar a descrição do exemplo, omitimos os códigos morfológicos nesta figura.
Em a fase de extração do Sn, a diferença entre as duas opções, para a sentença da figura 4.5, está na avaliação de &quot;cylinder head&quot;:
Em a opção 1 o sistema reportaria &quot;cylinder «como um Sn, enquanto na opção 2 o sistema reportaria &quot;cylinder head «como um Sn.
Podem existir mais do que duas possibilidades de derivação para candidatos ao Sn, porém o parser seleciona somente duas:
A sentença que possui o menor número de palavras como parte de um Sn, denominado Sn-hostil (Np-hostile), como é o caso da opção 1 na figura 4.5, onde o@ NH faz parte de um Sn porém@ V não;
E a sentença que possui o maior número de palavras como parte de um Sn, caso da opção 2 na figura 4.5, onde@\&gt; N e@ NH, ambos, fazem parte do Sn, por isso denominado Sn-amigável (NPfriendly).
Os SNs propostos são dados nas linhas indentadas, conforme figura 4.7, marcados com o símbolo np:».
Estes são os SNs que possuem ocorrências no parsing Sn-hostil e também no parsing Sn-amigável.
O objetivo ao selecionar os SNs, a partir de essas análises contraditórias é que um candidato a Sn produzido nos dois sistemas de parsing (Sn-hostil e Sn-amigável) é provavelmente um Sn identificado como não ambíguo na fase de intersecção seguinte.
Para poder determinar a forma do Sn o sistema Nptool usa um programa denominado &quot;gawk «que permite definir uma expressão regular para a forma do Sn.
Um exemplo da expressão regular definida no sistema é apresentado na figura 4.8.
A comparação da saída dos dois parsing (Sn-hostil e Sn-amigável) é feita na fase de intersecção dos resultados.
Os SNs propostos por os parsing Sn-hostil e Sn-amigável são sujeitos a uma rotina onde todos os candidatos a Sn com uma ocorrência idêntica na saída, Sn-hostil e Sn-amigável, são identificados com o símbolo ok, e os candidatos que permanecem com saídas distintas são denominados &quot;incertos «e são marcados com o símbolo&quot;?».
Os SNs extraídos, como resultado final do Nptool, para o exemplo da figura 4.7, são mostrados na figura 4.9.
O trabalho de Cardie e Pierce se resume a usar um corpus com os SNs já marcados (do Penn Treebank Wall Street Journal) e usar um etiquetador para marcar as classes gramaticais das palavras deste corpus.
A partir de isso o autor extrai regras que são compostas das combinações das classes gramaticais das palavras presentes nos SNs marcados.
Para extrair o Sn de um novo documento, o autor usa o mesmo etiquetador (para marcar as classes gramaticais) e aplica as regras produzidas no processo anterior.
Cardie e Pierce acreditam que a precisão de identificação do Sn é um componente crítico de qualquer parser;
Por outro lado, acredita que, para os SRI, o Sn é o principal recurso para a indexação de termos multi-palavras.
Podemos visualizar o projeto de Cardie e Pierce em três fases, conforme a figura o corpus com os SNs marcados e etapa de processamento sobre um novo corpus), fase de aperfeiçoamento da gramática para o Sn e fase de avaliação.
A fase de definição de regras tem como objetivo criar uma base de regras (gramática) a partir de o corpus com os SNs já marcados.
Um exemplo do corpus marcado é apresentado na figura 4.11, onde os SNs estão marcados com».
When is for,' s typically jet and.
A primeira tarefa da etapa sobre o corpus com SNs marcados é etiquetar as palavras com suas respectivas classes gramaticais.
Para cada palavra (wi) é associada uma etiqueta (ti).
Podemos observar a marcação das palavras com suas respectivas classes gramaticais na figura 4.12.
Em a próxima etapa é feita uma pesquisa no texto, palavra por palavra, da esquerda para a direita, e são extraídas as seqüências de classes gramaticais de cada um dos SNs marcados (regras do Sn), como mostra a figura 4.13.
A última tarefa desta etapa é a remoção de regras do Sn que aparecem repetidas.
Em a etapa seguinte, sobre um novo corpus, a primeira tarefa é utilizar o mesmo etiquetador utilizado na etapa anterior, para etiquetar as palavras do texto.
Dado então um novo texto, conforme figura 4.14, o resultado (texto etiquetado) pode ser observado na figura 4.15.
Em a próxima etapa as palavras do texto marcado são lidas, da esquerda para a direita.
De forma cumulativa as palavras são lidas e confrontadas com as regras de Sn (da etapa anterior).
O conjunto de palavras ou palavra que estiver de acordo com alguma das regras do Sn é, então, marcado como um Sn.
Se, para o conjunto de palavras lidas, existirem múltiplas regras, é escolhida a regra que possua o maior número de palavras.
Um esquema das duas etapas do trabalho de Cardie e Pierce pode ser visto na figura 4.16.
Em o processo de geração de regras são criadas muitas regras &quot;ruins «ou inúteis.
Essas regras &quot;ruins «surgem devido a quatro fatores:
Erros nos SNs marcado no corpus;
Em este exemplo da figura 4.17, o etiquetador marcou &quot;manufacturing «como sendo um verbo, o que iria gerar uma regra de Sn:
VBG NNS. Essa regra identificaria erroneamente um Sn numa sentença do tipo:
Onde &quot;boarding «não deveria ser marcado como verbo, mas o foi, devido a uma regra errada.
Para dispor de um mecanismo viável para identificar SNs, a gramática deve ser melhorada removendo regras problemáticas.
Em este momento inicia a próxima fase:
Em esta fase, primeiramente, é validado o conjunto de regras do Sn produzindo um ranking das regras em termos de utilidade das mesmas, na identificação do Sn, num novo texto.
A performance do conjunto de regras é medida em termos de precisão, utilizando a fórmula conforme apresentada na figura 4.18.
O benefício de cada uma das regras usadas durante o parsing é dado por:
&quot;Br $= Cr «-- Er «onde r é a regra, Cr é o número de SNs corretamente identificados por a regra e Er é o número de erros de precisão por os quais cada regra é responsável.
O sistema, então, que estão entre vírgulas, por exemplo:
&quot;O futebol brasileiro, que é conhecido por todo o mundo, representa a nossa força no esporte».
Existe ainda uma revisão humana durante a qual algumas regras podem ser removidas.
A meta da revisão humana é descartar regras que introduzem ambigüidades ou correspondem a SNs complexos, isto é, que são problemáticas.
São considerados SNs complexos os SNs que:
Contêm preposição, ponto ou dois pontos, regras que começam e/ ou acabam com um verbo ou advérbio, regras que contém vírgulas ou aspas, regras que terminam com adjetivos.
A terceira e última etapa é uma etapa de avaliação, onde dois outros corpora com SNs extraídos de dois outros trabalhos de autores distintos foram comparados ao trabalho de Cardie e Pierce.
As fórmulas apresentadas na figura 4.2.11 são utilizadas para calcular a precisão e a resposta por aqueles autores.
O trabalho de Cardie e Pierce não atinge 100% da extração dos SNs devido a erros originários de quatro causas principais: --
erros na marcação dos SNs do &quot;Penn Treebank&quot;; --
erros no etiquetador de classes gramaticais, que não marca corretamente as palavras; --
processo de eliminação manual de regras duplas ou ambíguas, onde podem ser eliminadas regras de eventual importância; --
problemas de marcação de expressões idiomáticas e especializadas, tais como horas, datas, valores monetários e frases numéricas.
O trabalho de Vieira e seus co-autores é um trabalho de extração semi-automática de Sn para resolver co-referência, utilizando as árvores sintáticas geradas por o software interativo do projeto Visual Interactive Syntax Learning (VISL), da Universidade de Aarhus na Dinamarca.
O corpus usado neste trabalho é constituído por um conjunto de 15 textos do Jornal Correio do Povo, no tema &quot;economia».
Em é apresentado um estudo detalhado sobre as descrições definidas (SNs iniciados por artigo definido) na língua inglesa.
Esse trabalho tem sido base para estudos sobre a resolução de descrições definidas da língua portuguesa.
Seu objetivo é, primeiramente, quantificar o uso de descrições definidas no corpus.
Como resultado o trabalho obtem, dos SNs extraídos, aproximadamente 50% de eles como descrições definidas, o que os autores afirmam ser suficiente para justificar seu propósito.
Os textos são submetidos ao software VISL, que gera a árvore sintática das sentenças.
Podemos ver um exemplo dessa geração, na figura 4.21.
As árvores sintáticas, geradas por o software VISL para cada um dos textos, contêm SNs.
Um programa em linguagem &quot;C «gera, a partir de a árvore sintática, listas dos SNs em PROLOG.
A árvore gerada por o VISL é quebrada em sub-árvores.
O programa em &quot;C «faz, então, a varredura na árvore à procura de um símbolo np.
Quando o encontra, armazena todas as palavras extraídas até o final da sub-árvore.
Em este processamento pode- se também observar que o aparecimento de um &quot;nome «(ver exemplo da figura 4.22), como a palavra &quot;aposentadorias», durante a varredura na árvore, também é destacado (símbolo N) dentro de o Sn.
A presença de um símbolo &quot;pp «indica uma preposição e registra a presença de um SP, que também é destacado (ver figura 4.22 com a expressão &quot;de as aposentadorias&quot;).
Extraímos, para exemplo, parte das listas PROLOG, constituídas conforme figura O algoritmo usado por Vieira e seus co-autores é apresentado na figura 4.23.
Para cada nodo da árvore faça Se o nodo possuir a marca&quot;:
Np». De as listas, conforme figura 4.22, são extraídos os SNs internos.
Um programa em linguagem de programação PROLOG faz essa extração.
Um exemplo, conforme figura observar que foi extraído o Sn &quot;o novo cálculo das aposentadorias».
A lista dos SNs teve que passar por uma revisão manual, onde os erros encontrados foram corrigidos manualmente.
A o final, esta lista de SNs serve como entrada ao sistema para anotação automática de co-referência.
As dificuldades encontradas no trabalho, conforme, foram (ver tabela 4.2) relacionadas às seguintes situações:
Em o capítulo 5, faremos uso de exemplos deste trabalho para comparação com os resultados do nosso trabalho.
Depois de ter estudado a estrutura do Sn, conforme apresentado no capítulo 3, e com base nos trabalhos correlatos descritos neste capítulo, iniciamos nossas tentativas em direção a um método de extração do Sn de sentenças em língua portuguesa.
Fizemos uma análise dos trabalhos de Cardie Voutilainen e Vieira e seus co-autores e, baseados no conhecimento lingüístico que adquirimos, nos permitimos alguns ensaios ou simples questionamentos antes de nossa decisão por um método.
O método que usamos para a extração do Sn está descrito no capítulo 5.
O trabalho de Cardie e Pierce, num primeiro momento, nos pareceu ser adaptável também para a língua portuguesa.
O processo de extração é muito simples e, como o de Voutilainen, faz análise de texto em nível de palavra, o que também propomos.
Os principais erros na extração são devidos a problemas na marcação dos SNs no corpus, erro no etiquetador que, por não possuir regras para tratar a ambigüidade, pode etiquetar erroneamente.
Mas o principal fator de erro são as regras geradas automaticamente.
Depois de geradas elas são conferidas e alteradas manualmente, o que pode, por exemplo, eliminar regras de eventual importância.
Acreditamos que as regras de formação do Sn são de vital importância para a extração do Sn.
Enquanto Cardie e Pierce tentam criar regras, a partir de o corpora etiquetados, nós acreditamos que conseguiríamos definir uma gramática, a partir de as definições dos lingüistas sobre o Sn.
O trabalho de Cardie e Pierce também extrai regras baseadas num corpus de domínio específico.
Se as regras geradas a partir deste corpus forem aplicadas a corpora de domínios diferentes, os resultados possivelmente não atingirão um nível de satisfação equivalente.
O trabalho de Voutilainen nos parece possuir uma metodologia de extração do Sn moldada sobre tarefas pertencentes a um sistema clássico de PLN, isto é, possui um léxico, um processamento morfológico e um processo de parsing.
Ele é um sistema bastante completo e complexo.
O processamento morfológico e sintático é feito sobre todas as palavras do texto.
O léxico possui as etiquetas morfológicas e sintáticas das palavras (e também etiquetas diferentes para as ambigüidades).
Este sistema possui regras sintáticas para toda a gramática da língua inglesa.
Nós não teríamos condições de desenvolver um projeto completo, para a língua portuguesa, nos moldes do Nptool, num trabalho de mestrado.
Como nosso objetivo é extrair somente o Sn, partimos dos textos já etiquetados e com etiquetas não ambíguas, não necessitando de um léxico.
Isto é, o processo de análise morfológica usado por Voutilainen, nós o faremos manualmente.
Com isso, as ambigüidades serão tratadas na etiquetagem manual que iremos fazer.
A grande vantagem do trabalho de Voutilainen é que ele pode ser usado para extrair outras estruturas das sentenças, uma vez que possui regras para toda a gramática da língua inglesa.
O processamento da ferramenta Nptool é feito palavra por palavra, opção que também adotaremos em nosso trabalho.
O trabalho de Vieira e seus co-autores não se utiliza de uma gramática para extração do Sn.
É inicialmente utilizado, para gerar a árvore sintática, o software interativo VISL.
Não discute o formalismo utilizado para gerar esta árvore.
Em a árvore sintática gerada por o VISL, os SNs já estão evidenciados, tornando a tarefa de extrair- los uma tarefa simples e que não envolve técnicas de PLN.
Em a segunda etapa, denominada &quot;extração dos SNs internos», os SNs são simplesmente desmembrados das listas PROLOG e extraídos.
Vieira e seus co-autores necessitam extrair os SNs para resolver problemas de coreferência.
Em nosso trabalho, temos como aplicação a extração do Sn para o auxílio na criação de índices para a Ri.
Podemos observar, com isso, que a extração do Sn também é utilizada para resolver outros problemas, e não só o problema de indexação nos SRI.
O que utilizaremos do trabalho de Vieira são os exemplos citados como dificuldades da extração.
Utilizamos esses mesmos exemplos para mostrarmos, no capítulo 5, o tratamento por nosso método.
Veremos, no próximo capítulo, nossa proposta para extração do Sn, com o protótipo que criamos para validar- la.
Baseados no levantamento bibliográfico na área de PLN, e em relatos lingüísticos sobre o Sn, iniciamos alguns ensaios em direção a o desenvolvimento de uma proposta de extração do Sn.
Em um primeiro momento pensamos em separar as sentenças em seus dois constituintes básicos, que são os Sn e SV.
Procuraríamos na sentença, primeiramente, por um verbo.
O que estivesse a sua esquerda poderia conter um Sn e o que estivesse à direita seria um constituinte do SV.
Porém constatamos que, entre os constituintes do SV, à direita, também poderia existir um Sn.
Isso pode ser observado no capítulo 3, figuras 3.3 e 3.4, onde &quot;o rapaz «é um Sn constituinte de um SV.
Concluímos, então, que pode existir um Sn antes e depois de um verbo e que o verbo nunca é parte de um Resolvemos então realizar o processamento da sentença recortando- a em partes menores, onde o corte aconteceria cada vez que um verbo fosse encontrado.
Entretanto, como será descrito na seção 5.2.3, além de os verbos, outras classes gramaticais também são responsáveis por o corte da sentença em partes menores.
Essas palavras são denominadas &quot;palavras de corte».
Todos os exemplos citados neste capítulo são extraídos de um único corpus, descrito na seção 5.2.1, e que constitui nosso material para testes.
Partiremos do pressuposto que as palavras do texto já estão etiquetadas, com etiquetas que designam suas classes gramaticais.
A marcação que usamos nos exemplos foi feita manualmente.
Alguns detalhes das etiquetas são apresentados na seção 5.2.2.
Em a seção 5.3.1.1 apresentamos o software que desenvolvemos para validar as ocorrências do Sn máximo de Perini.
Descrevemos, também, na seção Fizemos primeiramente a avaliação manual dos SNs extraídos através de nosso método.
Depois usamos, assim como observado em, um software interativo que gera a árvore sintática, onde podemos identificar os SNs.
Também usamos, para a avaliação do nosso método, os textos utilizados no trabalho de Vieira e seus co-autores.
Descrevemos, então, neste capítulo, nosso método para a extração de SNs de sentenças escritas em português, denominado ED-CER.
Este método possui dois módulos de processamento:
Módulo Seletor e módulo Analisador.
O nome ED-CER é derivado da sua própria forma de processamento, onde as palavras dos textos são lidas da esquerda (E) para a direita (D), existe um &quot;corte «(C), uma &quot;exclusão «de palavras (E) e &quot;reconhecimento «do Sn (R).
Veremos os detalhes de cada um dos módulos na seqüência.
Em a seção 5.4-1 detalhamos o protótipo que desenvolvemos para aplicação do método ED-CER.
A figura 5.1 resume o método ED-CER incluindo os seus dois módulos.
O objetivo deste módulo é encontrar candidatos a Sn que serão enviados ao módulo Analisador, responsável por o reconhecimento dos SNs.
O módulo Seletor encontra candidatos eliminando palavras com etiquetas gramaticais que sabemos não fazerem parte de um Sn.
As classes de palavras que definimos como classes que não pertencem a um Sn (denominadas etiquetas de corte) são:
Verbos, sinais de pontuação e locuções.
Abordamos na seção 5.2.3 a definição das etiquetas de corte e exclusão e a situação em que elas acontecem.
Em a seção 5.2.4 descrevemos um exemplo do funcionamento do módulo Seletor e o algoritmo proposto.
Começaremos descrevendo algumas considerações sobre o corpus que utilizamos neste trabalho.
Um SRI, normalmente, possui um conjunto de documentos, armazenados e tratados por assunto.
A a união de documentos que tratam de um mesmo tema ou assunto, denominamos de &quot;domínio semântico «dos documentos.
Se fossemos tratar o Sn em sua forma semântica (tratando ambigüidades) e não sintática como propomos, conseguiríamos maior precisão nos resultados se o conjunto de textos tivesse um domínio semântico bem específico.
Para o nosso propósito, o corpus não precisa ter um domínio semântico.
Porém, o que encontramos com muita freqüência no corpus são siglas utilizadas na área de ciência da computação como, por exemplo:
SGBD (Sistema Gerenciador de Banco de Dados), Www (world wide web) etc..
Veremos maiores detalhes, na seção 5.2.2, sobre como tratamos essas siglas no corpus e quais as etiquetas usadas para estes tipos de palavras.
O corpus de entrada do protótipo, que usamos desde o início deste trabalho, é constituído dos resumos de dissertações do curso de Mestrado em Ciência da Computação, em formato digital, dos alunos da PUCRS.
A etiquetagem das palavras nos textos (resumos de dissertações) foi feita manualmente.
Utilizamos, como base para definição das etiquetas, as categorias gramaticais definidas nas funções do Sn máximo de Perini.
Definimos, como etiquetas necessárias para a marcação do corpus, as etiquetas apresentadas na tabela 5.1.
Em a etiquetagem manual as ambigüidades são resolvidas por o agente humano.
Ele necessariamente deve ter conhecimento da língua portuguesa, para diferenciar, num texto, palavras ambíguas.
Existem palavras que podem, segundo a gramática, pertencer a mais de o que uma classe gramatical.
Vejamos um exemplo, dadas as sentenças e A a nossa direita o mato está coberto de neve.
Eu mato quem roubou o meu carro.
Se formos avaliar o que diz o dicionário em relação a a palavra &quot;mato», encontraremos duas possíveis referências.
Uma, definida como verbo, referente a o verbo &quot;matar», na sentença, no tempo presente e na primeira pessoa do singular.
Outra, referente a um substantivo masculino, na sentença que, segundo o dicionário, significa:
&quot;terreno inculto em que crescem plantas agrestes».
O etiquetador (usuário do protótipo) deverá, então, marcar na sentença (30) a palavra &quot;mato «como sendo um substantivo (mato_ SU) e na sentença (31) marcar a palavra &quot;mato «como sendo um verbo (mato_ VB).
Enumeramos alguns detalhes que devem ser observados na marcação do corpus, para termos um bom resultado neste método de extração do Sn.
Esses detalhes foram obtidos durante os testes de validação do protótipo:
1) Os itens lexicais devem estar em letras minúsculas, seguidos de um sinal « «e da etiqueta em letras maiúsculas.
Os itens do texto, com suas respectivas etiquetas, devem estar verticalizados.
Um exemplo do formato do texto de entrada é apresentado na tabela 5.2.
2) As locuções (prepositivas, adverbiais, conjuntivas) constituídas de mais de uma palavra deverão ser reconhecidas como um único item lexical.
Assim, teremos, por exemplo:
A marcação &quot;a-partir- de_ LG «como válida para a locução prepositiva:
&quot;a partir de&quot;; &quot;visto-que_ LG «como válida para a locução conjuntiva:
&quot;visto que «etc. 3) As contrações devem ter suas palavras separadas.
Por exemplo, a palavra &quot;em a deve ser etiquetada como «em_ PR a_ AR&quot;;
A palavra &quot;de a, como «de_ PR a_ AR&quot;;
A palavra &quot;em este, como «em_ PR este_ PD «etc. 4) As siglas, anotações bibliográficas, nomes de software, links etc podem ser tratados como substantivos, adjetivos ou nomes próprios, dependendo da sua representatividade no texto.
Por exemplo, &quot;ieee-1209_ NP», &quot;pucrs_ NP», &quot;imagus_ SU», &quot;sadg_ SU».
Texto original A automatização da tradução tem sido um desafio constante para lingüistas e cientistas da computação nas últimas décadas.
Visando obter, como candidato a Sn, um conjunto de palavras obedecendo à formação do Sn máximo de Perini, o módulo Seletor realiza, para cada candidato a Sn, duas etapas:
A etapa de corte e a etapa de exclusão de palavras.
O processamento inicia lendo a palavra mais à esquerda, e segue lendo palavra por palavra.
Em o final desta seção apresentamos o algoritmo que definimos para este módulo.
As etiquetas de corte e de exclusão foram definidas durante os testes de validação do protótipo.
Verificamos que, além de quebrar a sentença em partes menores, usando verbos, ligações e pontuação, outras palavras poderiam ser também eliminadas junto com o corte ou, então, poderiam ser eliminadas quando fossem a primeira palavra a ser lida.
Podemos resumir as etapas de corte e exclusão da seguinte forma:
A etapa de corte é feita em dois momentos: --
a o ser encontrada uma etiqueta do tipo_ VB,_ LG,_ PN, ou -- quando a etiqueta da primeira palavra lida for do tipo:_
PR ou_ Com o.
A etapa de exclusão é feita nos seguintes momentos: --
quando se eliminam a palavra de corte(_ VB,_ LG ou_ PN) ou -- quando se elimina palavras anteriores ao corte que possuam as etiquetas:_
PR,_ AV,_ Com o,_ AR,_ Nu ou -- quando se elimina a primeira palavra lida, se ela possuir a etiqueta do tipo:_
PR ou_ Com o.
Para facilitar o entendimento da ocorrência das situações de corte e exclusão, iremos numerar- las e descrever- las com alguns exemplos.
Dada a sentença:
Um estudo, a partir de um corpus da área econômica, é apresentado visando à definição de um conjunto de divergências estruturais.
A palavra de corte na sentença primeiramente seria &quot;a partir de», que é uma locução e viria marcada com a etiqueta&quot;_ LG».
O processamento quebraria a sentença na palavra &quot;a partir de», eliminando- a.
O candidato a Sn que sobraria seria &quot;um estudo,», como podemos observar na figura 5.2.
Como podemos observar na figura 5.2, a vírgula», «poderia ser eliminada do candidato a Sn.
Isso pouparia regras desnecessárias para tratar a vírgula na gramática que definimos no módulo seguinte (módulo Analisador).
Então optamos por excluir a etiqueta anterior à palavra de corte, quando esta for uma vírgula marcada com a etiqueta_ Com o.
Assim teríamos, então, como resultado final da sentença, o candidato &quot;um estudo», sem a vírgula, como podemos verificar na figura 5.3.
O mesmo corte com eliminação da vírgula pode ser observado no tratamento da sentença, com a segunda palavra de corte que aparece na sentença, que é o verbo &quot;é».
O candidato a Sn, neste caso, seria o mostrado na figura 5.4: Existem outros tipos de palavras, além de a vírgula(_ Com o), que podem ser eliminadas com as palavras de corte.
Esses tipos de palavras são as preposições(_ PR), os advérbios(_ AV), os artigos(_ AR) e os numerais(_ Nu).
Vejamos exemplos de cada um de eles na figura 5.5.
Preposições(_ PR) resultado:
Lê $= a existência de predisposição para reutilizar Corta $= reutilizar Exclui $= para reutilizar Candidato a Sn:
A existência de predisposição Advérbios(_ AV) resultado:
Lê $= um plano de reuniões e posteriormente controlar Corta $= controlar Exclui $= e posteriormente controlar Candidato a Sn:
Um plano de reuniões Artigos(_ AR) resultado:
Lê $= um ambiente não completamente acabado, que Corta $= que Exclui $ , que Candidato a Sn:
Um ambiente não completamente acabado Lê $= o motive Corta $= motive Exclui $= o motive texto etiquetado:
Lê $= de componentes de software e (Corta $= (Exclui $= e (Candidato a Sn:
De componentes de software Corta $ ) Exclui $= 3) ocorrência Pode também existir mais de uma ocorrência dessas etiquetas(_ Com o,_ PR,_ AV,_ AR,_ Nu), antes da palavra de corte.
Definimos que todas as ocorrências para estas palavras (anteriores à palavra de corte) devem ser eliminadas.
Um exemplo pode ser observado na figura 5.6, onde são eliminadas, junto com o verbo, as palavras &quot;para «e &quot;melhor «que possuem etiquetas&quot;_ PR &quot;e&quot;_ AV», respectivamente.
Concluímos que existem palavras que podem ser eliminadas quando se constituirem na primeira palavra lida.
A primeira palavra lida pode ser a primeira palavra do texto (conforme exemplo na figura 5.7), ou a primeira palavra lida após um processo de corte e exclusão.
São as palavras que possuem etiquetas do tipo_ PR ou_ Com o.
Lê $= em Exclui $= em Candidato a Sn:
Lê $= muitos avanços foram alcançados Corta $= alcançados Exclui $= alcançados Candidato a Sn:
Muitos avanços Exclui $ , Exclui $= porém Candidato a Sn:
Descrevemos agora o funcionamento completo do Seletor usando como exemplo uma sentença enviada ao módulo Seletor:
Gramáticas_ SU Síncronas_ AJ Árvores_ SU como_ PR formalismo_ SU para_ PR projeto_ SU de_ PR um_ AR módulo_ SU de_ PR transferência_ SU estrutural_ AJ,_ Com o que_ LG o_ AR componente_ SU principal_ AJ de_ PR sistemas_ SU de_ PR tradução_ SU automática_ AJ baseados_ VB em_ PR o_ AR método_ SU transfer_ AJ O processo de corte e exclusão se inicia lendo a primeira palavra mais à esquerda:
&quot;O_ AR».
Esta etiqueta não é de corte e nem é uma das excluídas quando lida por primeiro, então a palavra seguinte é lida, &quot;trabalho_ SU», que também possui etiqueta que não é de corte.
A próxima palavra, &quot;descreve_ VB», possui etiqueta de corte, então o módulo Seletor elimina a palavra &quot;descreve «verificando se a palavra anterior possui etiquetas do tipo:_
PR,_ AV,_ Com o,_ AR,_ Nu.
Em este caso não possui.
Então, seleciona &quot;o trabalho «como candidato a Sn e inicia uma nova leitura de palavras.
O segundo corte é feito no pronome relativo que_ LG», que será eliminado juntamente com a vírgula que possui a etiqueta do tipo&quot;_ Com o.
O terceiro corte é feito no verbo &quot;é_ VB», que é simplesmente eliminado, não gerando nenhum candidato.
O quarto corte é feito no verbo &quot;baseados_ VB «que será simplemente eliminado, pois anterior a ele existe uma palavra com etiqueta do tipo&quot;_ Su «que não faz parte da lista de etiquetas eliminadas junto com o corte.
O quinto corte é feito na preposição &quot;em_ PR», derivada da contração de &quot;em+ o «(em_ PR o_ AR), que faz parte da lista das palavras eliminadas quando for a primeira a ser lida.
Este corte também não gera candidatos a Sn.
E o sexto corte é finalmente feito em o»._
PN», onde somente esta marca é eliminada, por não possuir anteriormente uma etiqueta que possa ser eliminada junto com este corte.
A visualização do processo de corte e exclusão, para esta sentença, ficaria conforme a figura 5.9.
As palavras denominadas &quot;Candidato a SN «são enviadas ao módulo Analisador.
Propomos assim o algoritmo apresentado na figura 5.10, para o módulo Seletor, que inclui as etapas de corte e exclusão.
Lê $= o trabalho descreve_ VB Corta $= descreve Exclui $= descreve Candidato a Sn:
O trabalho Lê $= as Gramáticas Síncronas de Adjunção de Árvores como formalismo para projeto de um módulo de transferência estrutural,_ CO que_ LG Corta $= que Exclui $ , que Candidato a Sn:
As Gramáticas Síncronas de Adjunção de Árvores como formalismo para projeto de um módulo de transferência estrutural Corta $= é Exclui $= é baseados_ VB Corta $= baseados Exclui $= baseados Candidato a Sn:
O componente principal de sistemas de tradução automática Lê $= em_ PR Corta $= em Exclui $= em Corta $ .
Este módulo é o responsável por o reconhecimento ou não do candidato a Sn como um Sn.
Para tanto, utiliza a gramática definida na seção 5.3.1.
O programa inicia a leitura das palavras que constituem o candidato a Sn verificando sua conformidade com a gramática.
Utilizamos um analisador sintático do tipo LR para fazer esta análise sintática e reconhecer os SNs de acordo com a gramática.
Veremos, na seção acordo com a gramática (que não são reconhecidos por ela) não são extraídos como Sn por o módulo Analisador.
Em o protótipo que desenvolvemos, os SNs reconhecidos são gravados num arquivo de saída.
O conhecimento da estrutura sintática do Sn é codificado na gramática.
Uma gramática é pensada, aqui, como um conjunto de regras que mostram o relacionamento entre as palavras.
Para o nosso objetivo, a gramática irá tratar do relacionamento entre as palavras que compõem o Sn.
A gramática que usaremos para definir o Sn é uma gramática do tipo livre de contexto.
Uma gramática livre de contexto pode aplicar regras recursivas onde o mesmo símbolo aparece à direita e à esquerda das regras.
A seguir, na seção da gramática para o ED-CER, para nos auxiliar na verificação do Sn máximo de Perini conferindo, assim, as seqüências gramaticais que ocorrem na formação de um Sn.
Para concluirmos a etapa de definição da estrutura do Sn, em busca de uma definição para a gramática, sentimos a necessidade de visualizar a seqüência de palavras, definidas por Perini, como formadoras do Sn máximo.
Hagège afirma que &quot;qualquer trabalho lingüístico, seja ele de lingüística teórica ou de lingüística computacional, deve ser baseado na observação dos fenômenos da língua».
Aplicando à lingüística uma metodologia científica tradicional, um trabalho que tenha como objetivo o processamento automático de uma língua deve ter em conta os seguintes fundamentos: --
a observação dos dados; --
a formulação de hipóteses sobre o modo como os dados são organizados; --
a verificação dessas hipóteses.
Seguindo esta idéia desenvolvemos, então, um protótipo, que nos auxiliou na validação das seqüências, e na definição da estrutura de formação do Sn.
O protótipo foi escrito na linguagem Visual Basic 6.
O da Microsoft.
Os textos usados para avaliação são os resumos de dissertações que constituem nosso corpus, descrito na seção 5.2.1.
O protótipo que desenvolvemos exige que o texto seja digitado.
Em seguida o usuário deve clicar no botão &quot;classifica».
Em este momento o texto é classificado com suas respectivas funções.
Para a tarefa de classificação, o programa usa um conjunto de vetores que possuem as palavras possíveis para cada uma das funções sintáticas, definidas por Perini.
Por exemplo, para a função PDET o vetor teria as palavras &quot;todos», &quot;ambos», &quot;todas», &quot;ambas&quot;;
Para a função DET:
&quot;a», &quot;as», &quot;o», &quot;os», &quot;um», &quot;uma», &quot;uns», &quot;umas «etc;
Para a função POSS:
&quot;meu», &quot;minha», &quot;meus», &quot;minhas», &quot;seus», &quot;suas», &quot;teus», &quot;tuas», &quot;vosso», &quot;vossa «etc;
Para a função REF:
&quot;mesmo», &quot;próprio», &quot;própria», &quot;certo «etc;
Para a função QF:
&quot;poucos», &quot;vários», &quot;único «etc;
Para a função PNE:
&quot;meio», &quot;pretenso», &quot;mero&quot;;
Para a função PNI:
&quot;mau», &quot;claro», &quot;grande «etc;
Para a função PV:
&quot;dois», &quot;três», &quot;quatro», &quot;cinco «etc e;
Para marcar os SP:
&quot;de», &quot;de a, «das, &quot;de o, «dos.
Em a segunda janela é apresentado novamente o texto marcado, com as funções entre colchetes e, na terceira janela, somente aparece a seqüência de funções, sem o texto.
Palavras que ficam marcadas com o símbolo « «são palavras que não pertencem a uma das funções apresentadas por Perini ou são os verbos.
Executam- se aqui os substantivos que pertencem à classificação de Perini, mas possível representar através de um vetor todos os substantivos existentes na língua portuguesa.
Este programa simplesmente nos auxiliou na visualização das ocorrências das funções definidas por Perini para as palavras que compõem o Sn.
Iniciamos nosso trabalho definindo na gramática as regras que Perini definiu para o Sn máximo.
Devido a a rara ocorrência de um Sn máximo em nosso corpus e também em nossa língua portuguesa em geral, optamos por definir uma gramática mais resumida.
Agrupamos duas ou mais funções, o que é também visto como possível por Perini e que não deixa de seguir a estrutura básica que o Sn máximo possui.
A estrutura básica do Sn ficou, então, definida conforme figura 5.12: Em o apresentado na figura 5.12, DET é o determinante, PN é o pré-núcleo, NSN é o núcleo do Sn e MOD é o modificador.
As categorias sintáticas definidas para cada uma das funções definidas em são apresentadas na tabela 5.3.
Utilizando regras de combinação e ocorrências das funções definidas por Perini e as etiquetas que definimos para as categorias gramaticais das palavras, definimos então, como símbolos terminais (tokens) e símbolos não terminais as etiquetas conforme apresentadas na tabela 5.4 e tabela 5.5 respectivamente.
Tabela 5.5 -- Símbolos não terminais para a gramática ED-CER Utilizamos a notação BNF (Forma de Backus e Naur) utilizada por Aho e seus coautores, para representação da gramática do Sn.
Concluímos, então, tendo como a gramática utilizada no método ED-CER, a apresentada na figura 5.13.
Para o processo de extração do Sn, além de a gramática, utilizamos um processo de parsing que se utiliza da técnica de análise sintática LR, descrito a seguir.
Dada uma gramática, é possível escrever um programa que verifique se o texto dado está de acordo com as regras da gramática.
Um programa que realiza tal função é denominado parser.
O parser percorre todo o texto explorando todas as possibilidades possíveis de aplicações de regras.
Para o nosso trabalho, esse parsing irá analisar as categorias gramaticais das palavras, uma a uma.
A técnica de parsing que utilizamos em nosso trabalho é baseada num analisador sintático LR.
A análise sintática LR é uma análise do tipo bottom-up, também conhecida como análise de &quot;empilhar e reduzir».
Construímos um programa em linguagem &quot;C «que utiliza esta técnica para a extração do Sn.
O programa pode ser observado no anexo 1.
A técnica LR é utilizada para decompor uma ampla classe de gramáticas livres do contexto.
É denominada LR (k);
O &quot;L «significa varredura da entrada da esquerda para a direita (left- to right), o &quot;R «provém do fato de contruir uma derivação mais à direita ao contrário (rightmost derivations) e o &quot;k», o número de símbolos de entrada de lookahead, que são usados ao se tomar decisões na análise sintática.
Quando (k) for omitido, &quot;k «é assumido como 1.
Um exemplo da estrutura do analisador LR é apresentado na figura 5.14.
Resumidamente, em nosso modelo ED-CER, o analisador começa lendo a palavra mais à esquerda, verifica, através da etiqueta da palavra, a qual token a etiqueta pertence, e empilha o token.
Os elementos da pilha são confrontados com a gramática (de cima para baixo da pilha) em busca de uma regra que reduza os elementos da pilha a um símbolo não terminal.
Se existir esta regra os elementos da pilha que concordam com a regra são reduzidos ao símbolo não terminal e continuam na pilha.
Este processo é executado até que todas as palavras do candidato a Sn sejam lidas.
Se o candidato a Sn for reconhecido o que restará na pilha é um único elemento não terminal, cujo símbolo é &quot;Sn».
As duas últimas regras da gramática somente são validadas quando todas as palavras do candidato a Sn forem lidas.
Um exemplo do funcionamento do analisador LR, que implementamos no protótipo, pode ser observado no anexo 2.
É neste processo de parsing que os candidatos a Sn serão reconhecidos ou não.
Para serem reconhecidos eles devem estar em conformidade com a gramática.
Desenvolvemos um protótipo que integra os dois módulos propostos para a extração do Sn.
Este protótipo foi desenvolvido na linguagem &quot;C».
Durante o processamento o texto passará por os módulos do sistema, os quais analisam palavra a palavra, extraindo os candidatos a Sn, reconhecendo- os como SNs ou não.
A entrada para o protótipo do método ED-CER é um texto que pode ser visto no anexo 3 (resumo de uma dissertação), cujo nome (pode ser qualquer nome) deve ser colocado na interface de entrada do protótipo.
Para nosso exemplo usamos texto1_ Txt.
O texto original pode ser observado na figura 5.15.
A interface pode ser vista na figura 5.17.
Em este trabalho, abordamos o processo da autoria de hipertextos de apoio ao ensino-aprendizagem, e apresentamos a proposta de um ambiente de hipertexto que privilegia a construção do conhecimento por o leitor aprendiz.
O aprendiz deve desempenhar, de acordo com as bases construtivistas, o papel de criador de significado, e para tanto necessita de um ambiente não completamente acabado, que o motive participar e o integre no processo de elaboração de um produto.
Tomamos como base, para a contagem de SNs extraídos, aproximadamente 10 textos do nosso corpus.
Verificamos que, dos 10 textos submetidos ao protótipo ED-CER, foram extraídos 95,6%.
Podemos observar no gráfico da figura 5.18 o comportamento de extração, para cada um dos 10 textos do corpus.
Para a verificação e avaliação dos resultados, podemos proceder de três maneiras: (
I) Conferência manual, já que os SNs podem ser observados sentença a sentença.
Utilizamos o processo de validação manual ao longo de todo o desenvolvimento do trabalho.
Bick não possui em seu léxico todo o vocabulário utilizado em nosso corpus.
Portanto, sentenças que possuam palavras ou itens lexicais do tipo:
&quot;case», &quot;interlíngua», &quot;método transfer», &quot;assíncronas «etc não são reconhecidas.
Podemos observar um exemplo da extração de Sn utilizando o trabalho de Bick na figura 5.19, em formato de árvore.
Em o anexo 4 apresentamos o resultado, conforme Bick, utilizando o mesmo texto mostrado no anexo 3, utilizado no protótipo ED-CER.
Nota- se que ainda poderemos aprimorar a gramática, incluindo ou excluindo regras.
A cada inclusão, alteração ou eliminação de uma das regras, todas as sentenças anteriormente validadas devem passar por uma nova validação.
Apresentamos aqui dois textos com SNs que não foram extraídos, que aparecem no texto em formato sublinhado, os quais podem ser observados nas figuras 5.20 e 5.21.
Texto: É apresentado, neste trabalho, um estudo sobre a área de tradução automática, focalizando inicialmente os principais métodos utilizados na construção de sistemas automatizados de tradução:
Métodos diretos, métodos baseados nos conceitos de interlíngua e transfer.
SNs extraídos:
Este trabalho, um estudo sobre a área de tradução automática:
A construção de sistemas automatizados de tradução:
Métodos diretos, métodos baseados nos conceitos de interlíngua e transfer Sn não extraído:
Texto: O trabalho descreve as Gramáticas Síncronas de Adjunção de Árvores como formalismo para projeto de um módulo de transferência estrutural, que é o componente principal de sistemas de tradução automática baseados no método transfer.
O módulo de transferência realiza o mapeamento das discrepâncias existentes entre a representação estrutural do texto na língua-fonte e a representação correspondente na língua-alvo.
Um estudo, a partir de um corpus da área econômica, é apresentado visando a definição de um conjunto de divergências estruturais existentes na tradução entre as línguas portuguesa e inglesa.
Para validação do modelo proposto, é apresentado o protótipo de uma ferramenta que realiza as transformações estruturais observadas no corpus empregado, utilizando os conceitos de Gramáticas Síncronas de Adjunção de Árvores.
SNs extraídos:
O trabalho:
As como formalismo para projeto de um módulo de transferência estrutural:
O componente principal de sistemas de tradução automática:
O método transfer:
O módulo de transferência:
O mapeamento das discrepâncias existentes entre a representação estrutural do texto na língua-fonte e a representação correspondente na língua-alvo:
Um estudo:
Um corpus da área econômica:
A definição de um conjunto de divergências estruturais:
Validação do modelo proposto:
O protótipo de uma ferramenta:
As transformações estruturais:
O corpus empregado:
Os conceitos de gramáticas síncronas de adjunção de árvores SNs não extraído:
Podemos considerar que os exemplos apontados na figura 5.20 e 5.21 podem ser facilmente resolvidos com a inclusão de novas regras na gramática.
O aumento no volume de documentos em formato digital desafia os pesquisadores a criar novos processos, mais automatizados possíveis, para guardar de forma organizada este acervo, bem como facilitar sua posterior recuperação.
Entre outras tarefas de Ri, centramos nossa idéia em extrair o Sn a partir de bases de textos em português, com o objetivo de auxiliar na criação de índices automáticos de documentos.
Acreditamos que a questão da indexação é crítica para a determinação do nível de precisão e resposta de um processo de Ri.
Para auxiliar a tarefa de indexação, sugerimos a criação de índices a partir de o Sn das sentenças.
Concluímos que o Sn é um conjunto de palavras que representa o significado da sentença, mas não é somente utilizando- o como índice, que estaremos resolvendo todo o problema de indexação.
Também existem fatores específicos da língua natural que podem dificultar o processo.
Podemos citar aqui além de a ausência de estrutura do texto, dificultando o tratamento computacional, o fenômeno da ambigüidade.
Conhecendo as estruturas frasais da língua portuguesa, pudemos entender e analisar os elementos que compõem o Sn.
Pesquisar sua estrutura foi importante para conseguirmos combinar as classes gramaticais das palavras que constituem o Sn, concluindo com a gramática definida para o método ED-CER.
Pudemos também observar os pontos de vista dos autores em relação a os aspectos semântico e sintático que o Sn pode apresentar, o que nos auxiliou na decisão por o tratamento da forma sintática do Sn.
De entre os trabalhos correlatos estudados, podemos afirmar que são grandes os avanços na indexação, utilizando PLN na língua inglesa.
Também constatamos que, dos três trabalhos avaliados, todos conseguem obter sucesso na extração utilizando técnicas distintas uma das outras para o processo de extração.
Acreditamos que outras idéias ainda devam surgir, que possam ser aproveitadas na continuidade deste trabalho.
Tratamos de extrair o mais longo Sn possível das sentenças.
Porém, se for interessante para o processo de Ri reduzir o Sn, poderemos utilizar o mesmo método, remodelando as regras da gramática para reconhecer SNs menores.
A fase de definição do método ED-CER foi a principal e a mais empolgante de todo este trabalho.
Podemos dizer que a prototipação foi muito importante para auxiliar na fase de validação, até chegarmos a uma gramática e a um processo de parsing satisfatórios, mas que ainda podem ser melhorados.
O que podemos concluir, especificamente em relação a este trabalho, é que é possível obter sucesso na extração automática do Sn quando conseguimos identificar regras que se combinam para uma descrição formal (sintática) da estrutura que queremos identificar.
Deve- se mencionar que evitamos a etapa de tratamento semântico das palavras, onde encontraríamos ambigüidades, que foram tratadas manualmente no momento da etiquetagem manual do texto.
Devemos considerar que nosso trabalho de extração do Sn não é totalmente automático, devido a a etapa de etiquetagem manual.
Por outro lado, devemos observar que a etiquetagem, a qual realizamos manualmente, é tema de outros trabalhos já bem consolidados como por exemplo podemos citar o trabalho de Marques, o que nos permite considerar- la um problema já de adiantada solução, do ponto de vista algorítmico, cujo foco não se constitui no foco específico de nosso trabalho.
Como trabalho futuro, podemos sugerir a utilização de um etiquetador que gere as etiquetas definidas para este trabalho, respeitadas as regras que para elas determinamos.
Usamos o mesmo corpus desde o início deste trabalho.
Como próxima etapa seria interessante testar o protótipo com outros corpora continuando a testar e validar os SNs extraídos de novos textos, e assim podendo testar novamente as regras da gramática.
Podemos sugerir que sejam tratadas, primeiramente, as dificuldades levantadas na seção 5.6.
Essas dificuldades são provenientes da falta de regras específicas na gramática, que podem ser deduzidas a partir de o teste de empilhar e reduzir do analisador sintático LR e inseridas como novas regras da gramática.
Em o atual estágio em que o trabalho se encontra já podemos passar a integrar os resultados obtidos com o projeto do doutorando Gonzalez, que tem como objetivo geral, à aplicação de PLN à Ri, onde procura destacar a utilização de Sn em estrutura hierárquica temática, como parte do projeto SEMA.
