Encontrar petróleo é uma tarefa difícil que requer grandes quantidades de informações e recursos.
Ao longo de décadas de pesquisa, os geólogos da Petrobras acumularam grandes quantidades de dados.
Além disso, na geologia do petróleo outras fontes de dados são importantes, fontes estas, que em geral estão dispersas e possuem várias formas de represenção.
Esta dissertação relata a criação de um banco de dados que agrega diversos dados de origem paleoclimática e paleogeográfica provenientes do Atlântico Sul.
Grande parte destes dados foram extraídos de cartas estratigráficas, convertidos e armazenados em forma de um modelo numérico.
Modelo este, que é resultado de agregações de dados provenientes das bacias sedimentares brasileiras e da criação de uma solução algorítmica capaz de mapear os dados coletados ao longo de a área designada.
Estes dados são relativos a um período de tempo entre a idade geológica atual até 140 milhões de anos atrás.
Os 140 milhões de anos correspondem ao período de deslocamento do continente Sul-Americano desde a costa da África até a posição atual.
Durante esse deslocamento houveram diversas mudanças naturais nas bacias sedimentares oceânicas até chegarem ao estado atual.
O grupamento destes dados potencializa a descoberta de conhecimento relativo aos fatores necessários para a deposição de matéria orgânica e geração de petróleo no fundo do mar, assim, estes novos fatores podem vir a melhorar as probabilidades de descoberta de petróleo.
Palavras-chave: Geoinformatica;
Algoritmos; Banco de Dados;
Bacias Sedimentares; Descoberta de Conhecimento.
Quando se fala em exploração de petróleo há uma grande quantidade de dados paleoclimáticos e paleogeográficos a serem explorados e analisados.
A estratigrafia e sísmica geram grandes volumes de dados.
Esses dados usualmente são gerados e acumulados de maneiras distintas, tanto na representação como na forma e local de armazenamento.
O trabalho relatado nesta dissertação, mostra a criação de um modelo numérico que simula a evolução de dados naturais, bem como um banco de dados que suporta esse modelo.
O modelo é gerado através da coleta de diversos dados paleogeográficos e paleoclimáticos.
Esses dados correspondem a margem continental brasileira e são relativos à área em que hoje se localiza a parte sul do Oceano Atlântico.
Eles são correspondentes a escalas de tempo geológico de modo que é possível perceber a sucessão de sedimentos num determinado local.
Em Ciência da Computação trabalhamos com tecnologias muito recentes.
De fato, a diferença temporal entre as tecnologias atuais e as tecnologias ultrapassadas, em geral, é de apenas alguns anos.
Em outras ciências, como a Geologia, dados antigos representam um conhecimento que é importante não apenas para compreendermos fatos passados, mas também (e principalmente) para ajudar a compreender melhor os dados geológicos atuais.
Quando se trata de dados da natureza, a quantidade e a diversidade dos dados tende a ser enorme.
O grande volume de dados tende a dificultar analises e extrações de conhecimento.
Dois dos motivos por os quais grandes volumes de dados se tornam complexos, para análise e extração de conhecimento, é a falta de unificação de padrões e as várias formas e locais de armazenamentos.
O trabalho relatado nesta dissertação trata da unificação de locais e padrões de grandes volumes de dados geofísicos.
Este volumes são expressivos não somente por abranger uma grande área física, mas também por compor dados de outras idades geológicas.
Para entendermos melhor o presente é preciso estudar o passado, deste modo foram analisados e agrupados dados relativos a um período de 140 milhões de anos atrás.
Este período é relativo à separação dos continentes da América do Sul e da África.
Em esse intervalo de tempo foram formadas as Bacias Sedimentares Marginais brasileiras como conhecemos hoje.
Um conjunto de dados numéricos mostrando a evolução de elementos geofísicos, bem como a trajetória da deriva do continente Sul-Americano, abre novas oportunidades de pesquisas.
Como consequência de análises nos dados paleoclimáticos e paleogeográficos é possível obter indicadores de probabilidade de estabelecimento de condições favoráveis para a deposição e preservação de sedimentos ricos em matéria orgânica no espaço e no tempo e consequentemente na predição de ocorrência de potenciais rochas geradoras de petróleo.
Motivação mais de 50 anos de pesquisas e explorações realizadas por a Petrobras nas bacias sedimentares da costa brasileira propiciaram o acúmulo de grandes quantidades de informações.
Muitos são os meios utilizados para armazenamento destas informações.
Os gráficos originados de sísmicas e cartas estratigráficas (ver Capítulo 2) são meios altamente utilizados e que armazenam grandes quantidades de informações.
Contudo, sabe- se que grandes volumes de dados acumulados durante anos tendem a possuir informações ocultas e potencialmente úteis (ver seção 2.4).
Especialmente quando se trata de dados geológicos, o potencial para descobertas é muito grande, pois as formações geológicas dos tempos atuais são resultados de longos processos, entre outros, de transformação das próprias matérias da natureza ao decorrer no tempo.
As cartas estratigráficas agregam grandes quantidades de dados de forma gráfica.
Isto, a priori, facilita nosso entendimento e ajuda- nos a termos uma visão geral dos dados, porém nos traz uma série de limitações.
Estas limitações dizem respeito a certas técnicas estatísticas e computacionais para a descoberta de informações e padrões entre os dados.
Para utilização destas técnicas é necessário primeiramente adaptar os dados geofísicos em modelos numéricos.
Além de os dados provenientes das cartas estratigráficas, temos inúmeros dados geofísicos e climáticos que possuem relação indireta com a formação do petróleo (o capítulo 2 exemplifica).
Unir estes dados torna mais fácil a visualização das informações e a descoberta de conhecimento.
A organização de modelos numéricos de dados geofísicos também tem como benefício organizar dados atualmente caóticos.
A literatura possui vários trabalhos que se destinam a organizar estes dados.
Podemos citar Cheng-fang, que criou modelos de qualidade para garantir medidas como normalização dos dados, integridade, precisão e segurança dos dados de sísmica.
Estes são especificamente alguns dos problemas que os Sistemas Gerenciadores de Banco de Dados (SGBD) foram criados para resolver.
Sendo assim, podemos além de gerar conhecimento, organizar grandes quantidades de informações geofísicas.
Segundo Ketzer, &quot;Poder prever locais com maior probabilidade de sucesso pode ser muito vantajoso para a estatal brasileira em termos financeiros e de tempo».
De fato, grandes empresas petrolíferas investem em pesquisa afim de melhorar o acerto quanto a os locais a serem perfurados.
Para melhorar a predição dos locais e por consequência, minimizar custos, é necessário um banco de dados sólido que contenha grandes volumes de dados relevantes e dispostos num modelo numérico para que as técnicas de KDD e GKD possam ser aplicadas.
Para criar o modelo numérico são necessárias soluções que atendam as questões de pesquisa.
Questões que começam a partir de a transformação dos dados geofísicos (imagens, Cartas Estratigráficas etc).
em dados que sejam suportados por os algoritmos de mineração de dados.
Fundamentação Teórica Este capítulo se propõe a introduzir conceitos relativos a duas áreas do conhecimento.
A Seção principais fatores, tanto em sua composição como em sua representação (Seção 2.2).
Em a segunda área do conhecimento, computação, serão mostrados conceitos básicos sobre banco de dados (Seção 2.3) e descoberta de conhecimento em banco de dados (KDD) (Seção 2.4), seguido de alguns conceitos básicos sobre algoritmos e ETL.
Primeiramente serão apresentados os conceitos geológicos relativos à formação das placas tectônicas, os quais são a base para a formação e evolução das bacias.
Em seguida, serão apresentados os conceitos relativos às coordenadas geográficas, dados paleogeográficos, paleoclimáticos e paleoceanográficos, bem como a função de alguns destes dados na geologia do petróleo.
Após, é realizada uma síntese sobre Banco de Dados e Sistemas Gerenciadores de Banco de Dados, juntamente com alguns conceitos de KDD, GKD, ETL e algoritmos.
Dados Geológicos Esta seção trata de diversos paleodados e dados geológicos.
Estas expressões (paleodados, dados geológicos) são muito utilizadas nesta dissertação, de modo que é importante esclarecer algumas formalidades quanto as mesmas.
O termo &quot;paleo «vem do grego &quot;palaiós «que significa antigo.
Em palavras como:
Paleodados ou paleoclimáticos, o termo &quot;paleo «age como prefixo, indicando referência a algo do passado.
Sendo assim, &quot;paleodados «refere- se a dados do passado.
Em esta dissertação, &quot;paleodados «refere- se a dados numa janela de tempo compreendida entre a idade geológica atual até 140 milhões de anos atrás.
Dados geológicos são todos aqueles referentes à geologia.
Logo, a grande maioria dos dados geológicos (especialmente aqui utilizados) são paleodados, mas nem todo paleodado é um dado geológico.
Em uma visão geral, esta seção é dividida em subseções que apresentam conceitos importantes sobre os paleodados utilizados.
Começando por a sub-seção &quot;Evolução Tectônica e Deriva Continental», os conceitos são apresentados numa visão &quot;Top-Down».
Assim, os conceitos da evolução tectônica servem como uma visão geral para uma melhor compreensão das outras seções, que apresentam outros conceitos geológicos que neste trabalho se relacionam com a deriva continental.
Em um período anterior há aproximadamente 200 milhões de anos existia um único continente denominado Pangéia (do Grego, &quot;todas as terras&quot;).
Ao longo de o tempo, esse supercontinente começou a se fragmentar.
Formou Laurásia e Gondwana, que se fragmentaram de modo a formar os continentes como conhecemos hoje.
A África e a América do sul são resultados da fragmentação do Gondwana.
Essa separação teve início há aproximadamente 150 milhões de anos atrás.
A figura 2.1 exemplifica.
A Teoria da Deriva Continental é a teoria que trata da separação dos continentes.
Tida como teoria fundamental da geologia e da geomorfologia, ela foi publicada em 1915 por Alfred Wegener e sofreu várias atualizações até a data atual.
Inicialmente refutada por físicos, a teoria de Wegener ficou anos sob debate da comunidade científica.
O principal problema eram as hipóteses de Wegener quanto a as forças que moviam os continentes, e a velocidade com que eles se moviam.
Alguns anos mais tarde, geólogos vieram a provar o encaixe dos continentes devido a similaridades de alguns locais.
Rochas similares com a mesma idade foram encontradas na costa leste da América do Sul e na costa oeste da África.
Fósseis de alguns dinossauros da mesma espécie também foram encontrados em ambos continentes.
O fato de alguns fósseis de répteis, como o Mesosaurus, existirem somente na África (costa oeste) e na América do Sul (costa leste) sugere que os continentes estavam conectados.
Em 1960, o geólogo Harry Hess expôs a renovação constante dos assoalhos oceânicos.
A ideia principal partira da existência de poucas rochas com mais de 100 milhões de anos, o que sugere que as rochas mais novas se sobrepõem às mais antigas no assoalho oceânico.
Em 1965, J_ Tuzo Wilson propôs que a ilha do Havaí e outras ilhas vulcânicas teriam se formado por a movimentação das placas sobre pontos quentes do manto da terra.
Essa teoria ajudou a identificar o &quot;Círculo de Fogo do Pacífico «juntamente com parte da placa do Pacífico, reforçando a teoria da tectônica das placas.
A figura 2.2 mostra as grandes placas que compõem a superfície do planeta.
Note os pontos onde há vulcanismo (em vermelho) e o limite noroeste da placa do pacífico.
Existem modelos de como ocorreu a deriva continental.
Esses modelos respondem a questões como:
Qual foi a trajetória do continente desde a fragmentação de Pangéia, quanto tempo levou para se deslocar uma distância x num ponto y e uma idade z, etc..
Este trabalho visa dar suporte a uma reprodução numérica para o modelo de Moulin, uma opção ao modelo de Müller, que segundo o consultor do projeto, Dr_ Daniel Aslanian, é um modelo que apresenta menos concordância com as condições de contorno definidas por os dados de anomalias magnéticas.
As bacias sedimentares brasileiras foram originadas de eventos tectono-estratigráficos, que segundo o modelo de Moulin, modificaram a Placa da América do Sul de modo a deslocar- la até a posição atual.
Enquanto os continentes se separavam, levavam junto com si as bacias sedimentares, que não apenas se deslocavam, mas também sofriam transformações em sua superfície sedimentar.
Em esse processo, a superfície sedimentar do assoalho oceânico relativo às Bacias Sedimentares brasileiras recebeu uma contínua deposição de novos estratos.
Isto significa que novos sedimentos se sobrepõem aos mais antigos.
Esses sedimentos estão diretamente ligados com a formação do petróleo, pois alguns de eles formam (ou auxiliam a formar) os hidrocarbonetos, elementos químicos que compõem o petróleo.
Esses hidrocarbonetos são gerados a grandes profundidades e trazidos à superfície através desses eventos geológicos.
Os hidrocarbonetos são compostos químicos constituídos apenas de carbono (C) e hidrogênio (H).
Essa configuração química permite com que os hidrocarbonetos agreguem átomos de oxigênio (O), nitrogênio (N) e enxofre (S), assim eles são capazes de formar diferentes compostos como o gás natural e o petróleo.
Segundo Popp as bacias sedimentares são divididas em 8 tipos distintos.
Em o Brasil há apenas 5 tipos de elas:
Interior (tipo I), Intra continental (tipo II), Rift--Valley (tipo III), Costeira estável (tipo V) e Delta Terciário (tipo VIII).
Em este trabalho utilizamos apenas os tipos III, V e VIII, pois as bacias marginais brasileiras se enquadram apenas nestes tipos.
Estas bacias se estendem ao longo de a costa brasileira e parte da costa Uruguaia.
Começando ao sul por a bacia de Pelotas, que tem início no Uruguai e se estende por todo o Rio Grande do Sul, até a bacia do Foz do Amazonas que vai até a cidade do Oiapoque.
Estas bacias possuem diferentes tamanhos.
Sua distância em relação a a costa varia muito de bacia para bacia.
Grande parte das bacias está dentro de o território brasileiro.
Este território compreende um espaço de 200 milhas náuticas de distância da costa em direção a o Atlântico.
A figura 2.3 mostra as bacias e a linha que marca o limite do território marítimo brasileiro.
É sabido que a terra possui um campo gravitacional, e que a gravidade gera a aceleração gravitacional que é a taxa de aumento de velocidade na queda de um corpo.
Se a terra possuísse a forma de uma esfera perfeita esta aceleração seria igual em qualquer parte do globo.
Porém nosso planeta é um geóide com distribuição distinta de massa.
A diferente distribuição de massa, juntamente com a forma da terra (geóide ou esfera imperfeita) gera um campo gravitacional variável.
Essa variação pode ser utilizada para encontrar domos de sal, determinar limites de quebra de plataforma e avaliar dados de uma bacia inexplorada.
A figura 2.4), mostra o campo gravitacional no globo, onde o vermelho representa uma gravidade maior.
De a mesma forma que a terra possui uma gravidade, também possui um campo magnético.
Embora até hoje a origem do campo magnético da terra seja desconhecida, sabe- se que a capacidade magnética de algumas rochas é maior do que outras.
Esse conjunto de informações pode ser utilizado para determinar a conformação de uma bacia e detectar corpos metálicos no fundo do mar.
Coordenadas geográficas compreendem um sistema de localização global, onde uma latitude é uma distância angular em relação a a linha do equador e longitude é uma distância angular em relação a o Meridiano Inicial (Greenwich).
Valores de Longitudes possuem duas formas de representação.
A primeira são valores positivos para pontos a leste de Greenwich que se estendem até 180o e valores negativos para pontos a oeste, que se estendem até 180o.
A segunda é uma angulação inteira que aumenta na direção leste, até completar a volta no globo e chegar a Greenwich com 360o.
Em este trabalho utilizamos as coordenadas geográficas para marcação dos locais.
Cada ponto é uma referência ao estado atual da Terra, logo, se uma coordenada X indica a costa brasileira, a mesma coordenada' X'há 15 milhões de anos atrás, deve indicar algum ponto dentro de o continente Sul Americano.
Em termos de longitude utilizamos a notação que vai de 0 a 360o devido a a praticidade, pois a grande maioria dos dados coletados utilizam esta notação.
As cartas estratigráficas são ferramentas muito utilizadas no estudo das bacias sedimentares.
Esquematicamente ficam evidenciados muitos atributos da área estudada.
São eles:
A sucessão de estratos e sua representatividade na área estudada e no tempo geológico;
A natureza litológica das camadas e as variações laterais de fácies sedimentares;
As lacunas na história geológica daquela bacia e muitos outros.
Com as cartas estratigráficas é possível saber, de forma visual, a sucessão dos depósitos de sedimentos nas bacias.
O processo de criação de uma carta estratigráfica reflete os conceitos dos autores.
Ali estão presentes tanto dados reais, como possíveis dados.
De este modo uma carta estratigráfica possui um processo contínuo de evolução, onde uma área que hoje possui x dados atribuídos, amanhã poderá ter x+ 1 dados.
A figura 2.5 mostra a carta estratigráfica referente a a Bacia de Santos.
O trabalho aqui descrito, devido meramente ao desconhecimento, iniciou com a versão de 2003 das cartas.
Assim que descobrimos as versões mais recentes o trabalho foi reiniciado.
Contudo, a pesquisa e a experiência ganha com as cartas antigas serviram de pilares para o trabalho final.
A figura 2.6 realiza uma comparação entre as cartas de 2003 e 2007, referentes à bacia de Pelotas, para as idades geológicas mais recentes que a idade Santoniana.
Como podemos ver na figura 2.6 a diferença entre as cartasé significativa.
Além de a riqueza de detalhes, as novas cartas possuem algumas divergências com as cartas mais antigas.
Assim é de fundamental importância que o repositório das informações seja flexível para a atualização dos dados.
Geologia do Petróleo A geração e acúmulo de hidrocarbonetos requer uma série de elementos e processos essenciais.
Sabemos que é necessária a existência de um depósito sedimentar rico em matéria orgânica como fonte dos hidrocarbonetos (rocha geradora), uma rocha porosa capaz de armazenar os hidrocarbonetos (rocha reservatório), uma rocha que impeça a fuga do fluido (rocha selo) e uma trapa (ou armadilha) que permita o acúmulo.
Em condições favoráveis, o hidrocarboneto da rocha geradora é submetido a elevada pressão e temperatura e o fluido migra até a rocha reservatório onde é finalmente trapeado.
Porém, a simples presença destes elementos (os diferentes tipos de rocha necessários) não garante a existência de reservas de hidrocarbonetos, uma vez que é fundamental que a origem e desenvolvimento de cada um dos elementos e os processos sigam uma ordem temporal favorável.
Grande parte das informações são representadas nas cartas estratigráficas, porém, a ordem temporal utilizada por os elementos leva em consideração outros processos para a formação dos hidrocarbonetos.
Pressão e temperatura são dois fatores importantes que também devem ser considerados.
Como vimos na seção acima (2.2), as rochas são essenciais para a formação do Petróleo.
De entre os 3 tipos de rochas, as essenciais são as sedimentares, pois fazem parte do processo, porém as ígneas e metamórficas podem eventualmente ser importantes como reservatórios para o óleo.
Esta seção inicia com um breve resumo sobre a formação das rochas.
A seguir, as subseções mostram algumas particularidades dos três tipos de rocha.
Os três tipos de rochas possuem subclassificações que são características possivelmente úteis na aplicação das técnicas de mineração de dados.
Há milhões de anos atrás quando a Terra era poeira cósmica, em torno de os 3.000o C, algumas substâncias começaram a liquefazer- se.
O ferro liquefeito começou a formar o núcleo, o silício e os óxidos metálicos começaram a formar o manto.
Quando esta temperatura começou a baixar, a crosta começou a se solidificar.
A solidificação da crosta gerou as primeiras rochas.
Estas rochas são classificadas como rochas ígneas ou magmáticas por originarem- se do magma, que consiste nestas mesmas rochas fundidas a temperaturas entre 800 a 1.500o C.
Quando a crosta da Terra esfriou a uma temperatura de 374o C, o vapor da atmosfera começou a se condensar em chuva, o que posteriormente formou os primeiros mares.
As rochas sedimentares se originaram por consequência da ação das águas que reduziam as rochas ígneas à fragmentos e faziam com que esses fragmentos se consolidassem, criando as primeiras rochas sedimentares.
As rochas que ficavam presas em altas temperaturas na superfície da Terra (grandes profundidades, mas ainda no manto) e sofriam efeitos de forte pressão acabavam sofrendo metamorfismo ao passar dos anos.
Estas são classificadas como rochas metamórficas.
Rochas Sedimentares Camadas de partículas que encontramos com abundância na superfície terrestre, como a areia e conchas de organismos são alguns precursores de rochas sedimentares.
Essas partículas formam- se na superfície de restos de rochas que vão sendo alteradas e erodidas por meio de intemperismos Intemperismos são fenômenos físicos e químicos que levam à degradação de uma rocha.
Juntamente com a erosão, o intemperismo produz dois tipos de sedimentos, os clásticos e os químicos e biológicos.
Basicamente, a diferença entre sedimentos clásticos e químicos/ biológicos é como eles são gerados.
Os clásticos são gerados através da fragmentação e retrabalhamento de fragmentos de rocha.
Os químicos e biológicos são produzidos por meio de intemperismos e reações biológicas locais Como exemplo de rocha sedimentar clástica, pode- se citar o Folhelho.
Ele possui uma grande importância econômica já que é um potencial gerador de hidrocarbonetos.
Banco de Dados Um banco de dados constitui um conjunto de registros dispostos numa estrutura que possibilita a reorganização dos mesmos.
Atualmente quando falamos em banco de dados, falamos em SGBD.
Além de o banco de dados em si, os SGBDs provem a interface necessária para realizar as mais diversas operações possíveis num banco de dados.
Um SGBD é constituído por um conjunto de dados associados a um conjunto de programas para acesso a esses dados.
Segundo Silberschatz o principal objetivo de um SGBD é ser tanto conveniente, como eficiente para recuperação e armazenamento dos dados.
Os SGBDs apresentam grandes vantagens em relação a outras formas de armazenamento como planilhas e arquivos de texto.
Com SGBDs é mais fácil de evitar alguns problemas que ocorrem quando se trabalha com grandes volumes de dados.
São eles:
Inconsistência dos dados;
Redundância dos dados;
Dificuldade de acesso aos dados;
Problemas de integridade;
Problemas de atomicidade;
Um banco de dados pode ter outra classificação de acordo com suas características.
O trabalho relatado nesta dissertação constitui um banco de dados temporal.
Estes se diferenciam dos bancos convencionais por a presença de dados do passado e/ ou futuro.
Os bancos de dados convencionais são projetados para capturar os dados mais recentes.
Eles possuem uma estrutura relacional formada por tuplas e atributos que podem ser visualizados em duas dimensões.
Essa relação também é conhecida como snapshot relation, pois captura uma imagem da realidade.
Em os bancos de dados temporais a estrutura é formada por 3 dimensões.
As duas dimensões do modelo relacional mais a dimensão tempo.
Essa estrutura também é chamada de time cube.
Em esse trabalho possuímos muitos dados temporais representados.
Resumidamente, mapeamentos de litologias numa latitude e uma longitude, ao decorrer de uma idade geológica, ligados a valores de batimetria e anomalias gravimétricas.
Descoberta de Conhecimento em Banco de Dados (KDD) Análises com base em informações diversas é uma prática comum.
Com o avanço da tecnologia, houve um grande avanço na coleta e armazenamento de dados.
Como consequência, os bancos de dados tornam- se cada vez maiores.
Assim, da mesma forma que os dados são acumulados, informações ficam ocultas em meio aos grandes volumes de dados.
Analisar os dados e informações tem se tornado uma tarefa mais complexa e demorada.
Devido a estes motivos, técnicas computacionais e algoritmos para análise de dados foram criados.
O KDD é um processo que compreende várias etapas de análise de dados, visando descobrir informações previamente desconhecidas.
Segundo Fayyad et al.
A Descoberta de Conhecimento em Banco de Dados (KDD) é um processo não trivial de identificar padrões interessantes de dados.
Han e Kamber definem padrões interessantes como aqueles que são facilmente entendidos por humanos, são válidos com um certo grau de certeza, são potencialmente úteis e previamente desconhecidos.
Devido a o grande crescimento no volume de dados das bases atuais, técnicas de KDD tornam- se cada vez mais necessárias para se obter conhecimento em meio a informações dispersas.
As aplicações do KDD se espalham por diversas áreas do conhecimento.
Astronomia, negócios de marketing, detecção de fraudes, investimentos e telecomunicações são alguns exemplos de áreas em as quais o KDD é utilizado.
Processos de KDD não estão presentes no banco de dados final (aqui descrito), porém um dos principais objetivos deste banco de dados é tornar os dados paleogeográficos mais compatíveis com os processos de KDD, e por consequência, permitir novas descobertas a partir de os dados envolvidos.
De este modo serão apresentados os conceitos e técnicas relacionados ao KDD.
Em uma visão geral Fayyad define KDD nas seguintes partes como mostra a figura 2.7.
A Mineração de Dados (Data Mining) é comumente é confundida com KDD, porém mineração de dados é uma parte de todo processo de KDD.
Segundo Hand et al.
Data Mining é uma nova disciplina concebida da intersecção de várias disciplinas como a estatística, banco de dados, reconhecimento de padrões e inteligência artificial.
Fayyad et al.
Define Data Mining como &quot;aplicação de algoritmos específicos para extração dos padrões de dados».
Tan et al.
Define Data Mining como uma parte integral do KDD, onde o processo como um todo visa descobrir informação útil em dados brutos.
Em meio a execução de um processo de mineração de dados, são utilizados algoritmos que trabalham os dados de acordo com as suas configurações previamente estabelecidas e o propósito do processo de KDD a ser realizado.
Matheus et al.,
em 1993 tentou classificar os algoritmos de mineração em quatro classes:·
Identificação de classes:
Com base em similaridade entre os registros, o algoritmo os agrupa em diferentes classes.·
Classificação: Encontra regras que identificam características de uma determinada classe.·
Análise de dependência:
Encontra regras que predizem o valor de um atributo com base no valor de outro atributo.·
Algoritmos de classificação:
Prevêem variáveis discretas, com base em outros atributos do conjunto de dados.·
Algoritmos de regressão:
Prevêem variáveis contínuas, como lucro ou perda, baseando- se nos outros atributos do dataset· Algoritmos de segmentação (clustering):
Dividem dados em grupos de itens que têm propriedades semelhantes.·
Algoritmos de associação:
Encontram correlações, que podem gerar regras de associação, entre atributos diferentes num conjunto de dados.
Em a sessão 4.3.5 é apresentado um plano de mineração para os dados obtidos.
Este plano baseia- se em duas técnicas de mineração de dados, são elas:
Classificação e Associação.
Para que o plano possa ser entendido é necessário compreender alguns conceitos sobre estas técnicas.
Modelos de classificação por sua vez possuem duas classificações que são definidas quanto a o seu objetivo.
Estes modelos podem ser descritivos ou preditivos.
Modelos descritivos servem para explicar quais características de um registro o incluem numa determinada classe.
Um exemplo clássico é um conjunto de dados que possua maus pagadores e bons pagadores.
Então, a partir deste dataset, podemos definir quais são as características que distinguem maus pagadores dos bons pagadores com um determinado grau de precisão.
Assim, com o resultado de uma classificação por modelos descritivos podemos gerar árvores de decisão que nos ajudem a escolher indivíduos, como por exemplo, os bons pagadores.
Modelos preditivos ajudam a classificar indivíduos numa determinada classe.
Imagine que surja uma nova espécie de animal.
A partir de uma árvore de decisão, concebida com um modelo descritivo de classificação, podemos inferir a classe do animal (mamífero, réptil, etc).
Regressão -- Segundo Tan et al.,
regressão é uma técnica de modelagem preditiva, onde a variável a ser estimada é contínua.
Formalmente, regressão é a tarefa de aprendizagem de uma função f que mapeia cada conjunto de atributos x numa saída contínua y.
Assim, a meta da regressão é encontrar uma função que suporte os dados de entrada com um erro mínimo.
Segmentação -- Segmentação (clustering) é uma técnica para separar os dados em grupos distintos de acordo com suas características.
Algoritmos de segmentação são extremamente úteis em diversas áreas, seja para separar dados de modo a facilitar sua manipulação ou para unir- los por utilidade prática Em a Biologia, por exemplo, a segmentação é utilizada em grandes bancos de dados de DNA para encontrar similaridades em grupos de genes, e separar- los de acordo com suas similaridades.
Em a medicina, a segmentação pode ajudar a detectar padrões entre doenças, isolando seus fatores e características.
Além de as áreas científicas, a segmentação também pode ser utilizada em empresas para classificar clientes em grupos distintos e assim oferecer produtos mais propícios ao perfil do cliente.
Associação -- Uma regra de associação é uma expressão implícita na forma X-\&gt; Y, onde a força da regra é determinada por as variáveis:
Suporte e confiança.
O suporte determina a quantidade de ocorrências que contém os itens X e Y, ou seja, representa a relevância da regra.
Já a confiança determina a frequência de Y em relação a X.
Formalmente suporte e confiança são determinados por:
Conf ianca, c (X-\&gt; Y) $= Suporte, s (X-\&gt; Y) $= Descoberta de Conhecimento Geográfico (GKD) Geographic Knowledge Discovery é um tipo especial de KDD.
Segundo Miller, uma das diferenças entre o GKD e o KDD está na relação entre os dados que estão presentes nas dimensões.
Em o processo de KDD suas várias dimensões são relativamente independentes, enquanto que no GKD as várias dimensões de dados geradas são inter-relacionadas e possuem medidas padrões entre as dimensões.
Outra particularidade está na existência da etapa de mineração de dados no KDD, enquanto que, no processo de GKD a etapa similar é a mineração de dados espaciais.
Spatial Data Mining (SDM) se difere do Data mining convencional por trabalhar com dados espaciais.
Segundo Shekhar extrair padrões interessantes e úteis de Bases de Dados Espaciais é mais difícil do que a mineração em dados convencionais devido a complexidade do relacionamento dos dados espaciais.
Miller e Han, classificam as regras de mineração de dados espaciais em cinco categorias, são elas:·
Associações espaço-temporais· Generalizações espaço-temporais· Segmentação de dados espaço-temporais· Regras de evolução· Meta regras Associações espaço-temporais são similares a regras de associação utilizadas na mineração de dados convencionais, onde a ocorrência de x é seguida por a ocorrência de y em z% das vezes.
A diferença na associação espaço temporal é que o foco é alterado dos dados em si, para a alteração dos dados no espaço-tempo.
Generalizações espaço-temporais é a agregação de dados segundo padrões em sua hierarquia.
Por exemplo, um processo de generalização baseado em dados paleoclimáticos de Porto Alegre poderia gerar a seguinte regra:
&quot;Verões em Porto Alegre são quentes e secos».
Segmentação de dados espaço-temporais é muito similar a segmentação de dados convencional.
Ambas compartilham a mesma ideia de dividir indivíduos de acordo com sua característica, porém devido as dimensões extras, a dificuldade, bem como a possibilidade de se obter informações é muito maior.
Regras de evolução são regras que se aplicam especialmente no domínio espaço-temporal.
Elas descrevem a maneira como entidades se comportam ao longo de o tempo.
Essas regras tendem a gerar um volume muito grande de dados, por este motivo é indicado o uso de dados e variáveis de controle antes do experimento.
Podemos supor a seguinte situação no contexto da evolução litológica do Atlântico Sul, a seguinte regra de evolução gerada para uma rocha x, potencial geradora de petróleo no local (bacia) y.
Dados: Y:
Bacia ou parte de uma bacia sedimentar costeira;
X: Uma área com rocha potencialmente geradora de petróleo no local y;
A seguinte regra de evolução poderia ser gerada:
&quot;um segmento x apresenta uma rota espaçotemporal similar de entre espaços de tempo t;
Após t\&gt; m, x se estende em direção a os pontos p1, p2, p3, p4, p5.
Meta regras são regras que geram resultados com base na análise das regras principais.
Em outras palavras, elas servem para descrever dados sobre as outras regras aplicadas e seus resultados.
Um dos objetivos da base de dados descrita nessa dissertação é simplificar o processo de descoberta de conhecimento.
Uma vez que a estrutura do banco permite que dados presentes no espaço geográfico sejam mapeados como dados comuns, o Spatial Data Mining se torna mais simples.
Abraham e Roddick, já previam que bancos temporais poderiam ser abstraídos e utilizados como bancos convencionais, porém, é indicado a utilização de um processo de GKD para se obter melhores resultados.
Algoritmos e ETL Em a seção 2.3 foram apresentados, de forma condensada, conceitos sobre banco de dados e SGBDs.
Em as seções 2.4 e 2.5 foram abordados conceitos necessários para o entendimento de KDD e GKD.
Esta Seção apresenta conceitos básicos sobre processos de Extração, transformação e carga (ETL) de dados, juntamente com conceitos de algoritmos, que neste trabalho foram criados para o mapeamento e carga dos dados.
Quando possuímos um grande volume de dados a serem gerados, e neste caso, mapeados automaticamente;
Bons algoritmos se tornam cruciais.
Sedgewick define algoritmos como métodos solucionadores de problemas e adequados para implementação num programa de computador.
Quanto maior a quantidade de dados e maior o número de loops, os programas tendem a possuírem um custo computacional maior.
Assim, para transformar e carregar grandes quantidades de dados o desempenho torna- se fundamental.
Se por um lado uma boa estrutura, com bons algoritmos se traduz em ganhos de performance, e por consequência, economia de tempo.
Por outro lado uma estrutura e algoritmos ruins, podem inviabilizar processos.
Para tratamento dos dados desde a coleta até a carga no banco da dados é comum a criação de ferramentas que automatizam processos.
O processo de extração, transformação e carga de dados, geralmente é utilizado para montar um Data Warehouse ou um Data Mart.
O processo de ETL é dividido em 3 partes.
A primeira parte consiste em extrair dados de fontes externas que podem estar em diversos meios e formatos.
Geralmente estes dados provem de estruturas relacionais de um banco de dados, porém também é comum estarem em forma de texto puro, provenientes de relatórios, vindos de web sites, etc..
Estes formatos também podem vir de estruturas não relacionais de banco de dados, como Sistemas de Gestão da Informação (IMS), Métodos de acesso de armazenamento virtual (VSAM) ou Métodos de acesso sequencial indexado (ISAM).
A parte de transformação é altamente dependente da parte de extração, sendo que, quanto mais dados e mais diversificadas as fontes, maior tende a ser o processo de transformação dos dados.
A transformação também é muito dependente do que se precisa no banco de dados, alguns exigem formatos mais específicos, o que demanda mais conhecimento das necessidades técnicas e de negócio Por fim, a parte de carga dos dados compreende o processo de carregar os dados extraídos e transformados para o banco de dados.
Essa fase demanda iteração direta, na maioria dos casos, com o DW.
Isto significa que as estruturas de banco de dados e DW tem de estar bem formadas para receber os dados, bem como as ferramentas de ETL tem de estar de acordo com as necessidades do projeto.
Um DW é um conjunto de dados orientada a assunto, não volátil, integrado e variante no tempo que provem suporte para tomada de decisão.
Em outras palavras, um DW é um conjunto de dados selecionados de um banco de dados, organizados de forma orientada ao assunto de maneira a facilitar consultas e possibilitar a visualização de informações de forma rápida.
De certo modo, o processo de ETL para criação de um data warehouse tem o mesmo perfil do processo de ETL para a criação do banco de dados descrito nesta dissertação.
Em ambos os processos, os dados são coletados objetivando organizar- los.
Porém, neste trabalho, o processo de ETL visa extrair informações de diversas fontes de dados (diferente do DW, onde geralmente os dados são coletados de uma ou mais base de dados) para organizas- los num banco de dados.
De o mesmo modo que processos de KDD passaram a utilizar algoritmos e softwares que automatizam parte do processo, os processos de ETL também evoluíram.
Ferramentas para ETL são necessárias devido a o grande volume de dados.
Quando os dados são de diversos tipos e formatos, a ETL torna- se ainda mais importante.
Questões de Pesquisa O mapeamento de dados num plano espacial altamente sinuoso, como é a margem continental brasileira, se mostra um grande desafio computacional.
Vários fatores estão envolvidos, pois o mapeamento envolve diversos dados que devem ser interligados, e fatores que devem possuir concordância entre si (ver capítulo:
Fundamentação Teórica 2).
Assim, a coleta, a padronização e a normalização dos dados, são algumas das tarefas precedentes e necessárias para a criação de um bom modelo.
O modelo, que por sua vez é necessário e indispensável para o mapeamento adequado dos dados.
Como questões de pesquisa, em geral, podemos resumir a algumas perguntas.
Como representar dados paleogeográficos e paleoclimáticos extraídos de diversas fontes, de maneira com que todos estejam interligados entre si a ponto de representar a evolução tectônica continental num período de 140 milhões de anos?
Como manter representados de maneira fiel aos dados originais, e por consequência a realidade geológica, os dados transformados e interligados?
Como tornar o resultado final, um banco de dados que seja prático para aplicar técnicas de KDD?
A quantidade de informações visuais, remete- nos à seguinte questão de pesquisa:
&quot;Como organizar tantas informações paleogeográficas a fim de tornar viável a utilização de técnicas de descoberta de conhecimento em banco de dados?».
Cenário de Pesquisa As questões de pesquisa descritas no inicio do capítulo, foram planejadas e trabalhadas ao longo de o desenvolvimento do trabalho.
Poucas referências foram encontradas e com subáreas ligeiramente parecidas, alguns trabalhos serviram como fundamentação teórica.
Porém, possivelmente devido a a natureza deste trabalho, não foram encontrados trabalhos relacionados com grande relevância a ponto de ajudar na metodologia, na criação do modelo do banco de dados ou no mapeamento dos dados.
Inicialmente, um processo de transcrição dos dados foi realizado com as cartas estratigráficas das quatro bacias sedimentares mais ao sul da costa brasileira.
Essas cartas foram trabalhadas para expandir seus dados por toda a região sul da costa de forma a completar os dados faltantes.
Foi realizado ainda um processo de KDD nos dados obtidos e desse processo foram gerados alguns resultados, como por exemplo, coordenadas geográficas com possíveis reservas de petróleo.
Este primeiro projeto serviu de startup (e para testes).
De entre os problemas de pesquisa encontrados, os problemas com a atualidade dos dados litoestratigráficos e como eles devem ser representados, se destacaram de entre os demais.
As incertezas quanto a as informações geofísicas que foram obtidas se mostraram agravantes.
A o longo que as primeiras questões de pesquisa eram respondidas, novas questões eram geradas.
Qual é a precisão dos dados originais?
Quais os limites de precisão do mapeamento para que os mesmos sejam considerados realísticos?
Existem meios presentes na literatura para mapear dados desta natureza?
Qual seria uma boa maneira de mapear milhões de dados de maneira fiel e automática?
O capítulo 4, constitui- se no relato do desenvolvimento que produziu os resultados deste trabalho, da pesquisa e de todo processo realizado com os resultados da mesma.
Em ele será possível compreender como o banco de dados foi populado, quais as metodologias utilizadas e qual o resultado final.
Desenvolvimento Este capítulo se propõe a introduzir as etapas de desenvolvimento deste trabalho desde a criação do primeiro modelo do banco de dados até o banco de dados final, bem como sua integração com o modelo estrela (formato para DW e aplicação de processos de KDD).
O banco de dados aqui descrito é uma evolução de outros modelos primitivos que sofreram uma série de alterações e foram divididos, basicamente, em três grandes etapas.
As duas primeiras etapas são relatadas com o intuito de mostrar a evolução do trabalho e facilitar a compreensão do motivo de algumas escolhas relativas ao modelo final, que está na terceira etapa.
Este capítulo também aborda a solução desenvolvida para mapeamento dos dados estratigráficos, bem como a ferramenta criada para realizar o mapeamento desses dados em áreas sinuosas como a costa brasileira.
Introdução ao problema Como descrito na seção 2.1.5, as cartas estratigráficas são de fundamental importância para entender a formação dos hidrocarbonetos, e por consequência as atividades petrolíferas.
Assim, as cartas estratigráficas foram o ponto de partida deste trabalho.
Segundo Wang as atuais bases de dados geográficas são modeladas sem levar em consideração possíveis processos de KDD.
Isso gera problemas quando a base de dados começa a ter um grande volume, pois torna- se difícil encontrar conhecimento em meio a dados dispersos.
Assim, para chegar num modelo robusto e passível de processos de KDD seguimos as etapas de Contudo o modelo se mostrou incompleto para o preenchimento das informações.
Então, mais uma etapa foi criada, a etapa de estimativa de dados, que ficou entre as etapas de transformação e mineração.
A figura 4.1 ilustra as etapas do processo e a seguir são descritas as atividades e questões de pesquisa de cada etapa.
Com o foco especificamente nas cartas estratigráficas, num procedimento inicial e incerto, devido a os nossos conhecimentos em geociências o trabalho foi limitado a quatro bacias.
Foram coletados dados de quatro das bacias sedimentares mais ao sul da costa brasileira.
Estes dados foram coletados das cartas estratigráficas de 2003, devido a o nosso desconhecimento das cartas mais recentes.
Essa seleção de dados serviu para iniciar um trabalho prévio para o banco de dados litoestratigráfico (descrito na seção 4.2).
A vantagem de um trabalho prévio é que ele gera experiências, assim, hipóteses e procedimentos podem ser validados.
Toda a experiência ganha, serve como base para planejar o próximo modelo.
Um modelo mais robusto e construído em menos tempo devido a redução na taxa de retrabalho.
Como forma de mapeamento para os dados selecionados foram utilizadas coordenadas geográficas (Lat-Lon).
Os dados de batimetria da respectiva área também foram coletados.
Esses dados foram obtidos do site TOPEX, o qual informa coordenadas com precisão de um minuto.
Levando em consideração o limite territorial brasileiro, que é de 200 milhas náuticas, optamos por dividir o eixo x da carta em quadrantes de 10,01 Km..
Assim obtivemos 37 quadrantes entre a costa e o limite territorial brasileiro.
Como nosso foco é a criação de um banco de dados para utilização de técnicas de GKD e KDD, surgiu a primeira necessidade.
Como representar as litologias de forma numérica?
A primeira solução, a representação por potência de dois, se mostrou prática, pois com ela várias litologias podem ser representadas com um valor.
Isto também é prático para decompor os valores e por consequência obter as litologias que compõem o território.
A figura 4.2 mostra um exemplo.
A transformação dos dados se mostrou uma etapa relativamente curta.
Basicamente os dados foram selecionados para criar um arquivo.
Arff, formato utilizado por o WEKA.
Como atributo classe, foi criado um atributo formado por outros dois atributos.
O primeiro atributo se refere as áreas licenciadas por a Agência Nacional de Petróleo (ANP), isto significa, 1 para áreas licenciadas e 0 para áreas não licenciadas, o outro atributo é relativo as atividades de extração de petróleo no local, 1 se o ponto referido possui atividade de extração, 0 caso não possua.
Assim definimos o atributo classe como um ou lógico entre os outros dois atributos.
Com os dados reais representados numericamente, é necessário encontrar uma maneira de mapear estes dados de forma a representar uma grande área.
Como as unidades numéricas representantes dos dados reais são apenas algumas centenas, achamos que a maneira mais realista seria centralizar os dados fontes na área de sua respectiva bacia.
Com os dados fontes centralizados em cada bacia, processos de interpolação foram realizados com o intuito de estimar novos dados para cobrir a área restante de cada bacia, levando em consideração que a área das bacias é uniforme e portanto, deveria ter mesmo comportamento sedimentar.
Com isso, para cada duas bacias vizinhas, os dados da bacia mais ao sul eram interpolados com a bacia mais ao norte.
Este processo gerou os dados faltantes para o preenchimento das bacias.
Assim, esses dados completam a área norte da bacia ao sul, e o sul da bacia ao norte.
Após definido o atributo classe partiu- se para as atividades de mineração.
O algoritmo de Classificação J48 foi utilizado para criar um mapa de probabilidade dos possíveis locais com ocorrência de petróleo. Como
critérios de classificação foram utilizadas as similaridades litográficas decorrentes das idades geológicas e da profundidade do terreno.
Foi realizado um breve processo de mineração com o algoritmo APRIORI.
Consideramos apenas operação foram obtidas algumas informações sobre as áreas em questão.
Essas informações foram valiosas a ponto de validação do modelo.
A seção a seguir descreve os resultados como um todo.
De entre as quatro bacias estudadas nesta primeira etapa, as áreas em que o atributo classe foi 'verdadeiro' apresentaram Folhelho, que é uma rocha geradora e selo (liga rochas, impedindo que vase o óleo, ver seção 2.2), ou na idade Campaniana ou na Coniaciana, que datam de períodos de 70,6 a 83,5 e 85,8 a 88,6 milhões de anos atrás (respectivamente).
Encontrar essa associação foi importante, pois essas idades geológicas estão num período de tempo que é justamente o período necessário para maturação dos hidrocarbonetos.
Esta maturação significa uma potencial transformação dos hidrocarbonetos em petróleo ou gás.
Parte do resultado deste etapa de mineração se encontra no apêndice O tempo de maturação dos hidrocarbonetos possui uma variação maior que a mostrada acima, pois depende de vários fatores como pressão, temperatura, etc..
Porém a maioria data desse período de tempo.
Podemos associar a descoberta como uma validação do trabalho, embora haja alguns problemas quanto a a metodologia, a descoberta mostra que o mapeamento se mostrou relativamente confiável.
O fato de termos realizado o trabalho com cartas antigas nos limita em precisão e acurácia dos dados.
A forma de obter dados por interpolação matemática teve a consequência de perdermos a ligação com os dados originais.
Estes fatores levaram à criação de uma nova base de dados.
Assim, de entre a atualização das fontes (dados geofísicos), foram aproveitadas as técnicas e metodologias bem sucedidas, ao mesmo tempo em que aquelas que apresentaram problemas ou se mostraram insatisfatórias foram remodeladas ou substituídas.
A estrutura do banco de dados foi continuada e expandida, de modo que o banco de dados litoestratigráfico pode ser considerado uma nova versão destes dados produzidos e descritos nesta seção.
Banco de dados Litoestratigráficos Tendo em vista as oportunidades de melhoria do trabalho anterior, foi iniciado o processo de criação de um novo banco de dados.
A metodologia beneficiou- se da experiência adquirida nos testes descritos acima.
As metodologias do processo que se mostraram eficazes, como descrito no final da seção anterior, continuaram a ser utilizadas.
Bem como, aquelas que apresentaram problemas foram alteradas e/ ou substituídas.
Em a etapa de seleção, seção 4.1.1, foram realizadas as extrações dos dados mais recentes e atualizada a forma de organizar as litologias de modo a facilitar o processo de mineração.
Também foi introduzido o valor '1' para marcar um quadrante como parcialmente sem depósitos, ou seja, numa área de, por exemplo, 10 km pode haver informação somente para parte do terreno.
A etapa de pré-processamento sofreu uma significativa mudança.
Para esta etapa foi desenvolvida, em Delphi, uma ferramenta para Extração Transformação e Carga (ETL) dos dados coletados.
A ferramenta realiza alterações de formatos, importa planilhas Excel, realiza cálculos, aplica os algoritmos criados para estimativas e carrega os dados para o banco de dados.
A figura 4.3 mostra a interface da ferramenta, juntamente com um breve resumo de suas funções.
A principal função da ferramenta se encontra na parte de carga dos dados, pois a mesma comporta os algoritmos criados para mapear os dados nas coordenadas estimadas.
A função de mapeamento é basicamente dividida em três partes:
O upload da planilha pré formatada, o preenchimento dos dados na costa e a gravação dos dados estimados no banco de dados.
O mapeamento dos dados seguiu a mesma metodologia da base anterior.
Contudo, a técnica de estimativa e mapeamento dos dados foi refeita.
Após os dados originais serem mapeados nas bissetrizes, foi utilizada a fórmula de Haversine para calcular a distância entre pontos.
Assim, como parâmetros para o ponto médio foram usadas a distância entre o ponto em questão e os pontos mais próximos em ambas as bissetrizes.
A formula de Haversine foi escolhida para se obter uma distância mais precisa, já que trabalhamos num plano esférico.
Essa fórmula leva em consideração a curvatura de uma esfera (nesse caso a Terra) e calcula a distância entre dois pontos.
R $= earth sradius lat $= lat2 -- lat1 long $= long2 -- long1 a $= sin2 (lat/ 2)+ cos (lat1).
Cos (lat2).
Sin2 (long/ 2) c $= 2.
Atan2) d $= R. C Para estimar o valor de um ponto x no espaço foi criado um algoritmo que se baseia na distância entre o ponto em questão e os pontos mais próximos de cada bissetriz.
Assim, o algoritmo cria uma matriz de valores que são mapeados em pontos no espaço.
Então, para cada idade geológica, faz- se os seguintes passos:
Para cada índice correspondente, dentro de uma idade geológica, segue- se os seguintes passos:
Não continua- se com os próximos passos;
Após todos os valores litoestratigráficos serem obtidos e devidamente mapeados, foram realizados alguns testes com o auxílio de dados pré-conhecidos e ferramentas de modelagem espacial.
A o final do processo, dados foram extraídos diretamente da base para verificar o modelo de batimetria.
A figura 4.4, criada via SURFER, mostra um modelo 3D criado com os dados (correspondentes a idade geológica mais atual) extraídos diretamente do banco de dados.
PaleoGeoDB Paleo Geographic Database é o banco de dados criado para comportar o modelo numérico final.
Este modelo numérico, constitui todos os dados coletados, transformados e integrados.
Após a conclusão da Base de dados litoestratigráfica, foi expandido o modelo do banco de dados de modo a comportar outros dados geofísicos.
O banco de dados batizado como PaleoGeoDB, possui uma estrutura aprimorada em relação a o banco de dados anterior.
A estrutura do mapeamento das cartas foi alterada para haver mais coesão com a realidade.
Em o banco de dados litoestratigrafico (etapa 2, ver Seção 4.2) os dados eram mapeados nas bissetrizes e os demais dados eram estimados através de algoritmos.
Porém, foi constatado que mapear os dados de uma carta para uma bacia, sem realizar estimativas de dados, torna o mapeamento mais real.
As estimativas dos dados não são propícias, devido a o fato de que os dados presentes nas cartas estratigráficas já possuem uma relação de ordem e distância.
Outra técnica descartada foi a interpolação de valores entre as bacias, pois geologicamente, não faz sentido interpolar valores entre bacias, uma vez que estas possuem divisões naturais em que os sedimentos foram depositados durante as eras.
Estas divisões existem justamente por haver características distintas entre as bacias.
Outra mudança, em relação a o banco de dados da etapa 2, foi a relação dos dados com a área relativa aos mesmos.
Esta mudança foi adotada devido a o fato de que as cartas correspondem as formações geológicas das bacias, e não as 200 milhas náuticas como fora feito no trabalho prévio.
Devido a estes fatores, alteramos a nossa abordagem em relação a o mapeamento das litologias.
Em esta nova abordagem cada carta corresponde a uma única bacia, assim como a distância entre os pontos se tornou variável devido a o tamanho das bacias em relação a a costa.
De entre as questões que cercam a criação de um modelo, talvez as mais evidentes sejam:
&quot;Quais dados possivelmente estarão presentes?
&quot;e «Como garantir que eles possam ser adicionados de forma harmoniosa com os demais dados?».
Devido a estas questões foram levantados os dados que possivelmente seriam assimilados no banco de dados.
Com base no modelo anteriormente criado, foram realizadas as melhorias e atualizações para criar o modelo atual.
Primeiramente foram selecionados os dados relevantes para o banco de dados.
Além de os dados já utilizados no banco anterior, foram adicionados a arquitetura do banco suporte a dados como:
Como mostrado na figura 4.5 o modelo permite armazenar dados paleogeográficos e paleoclimáticos.
A seguir, são descritas, detalhadamente, as tabelas e os campos do banco de dados.
Em o banco de dados temos cinco tabelas estáticas que descrevem o tempo geológico.
São elas:
Idades, Epocas, Periodos, Eras, Eons.
Basicamente estas tabelas guardam os nomes dos tempos geológicos, juntamente com uma campo para observação.
No caso de a tabela Idades, que é a divisão mínima do tempo geológico aqui utilizado, são utilizados dois campos para marcar em quantos milhões de anos atrás a idade teve início e fim (MA_ ini, MA_ fim).
A tabela FatoresClimaticos armazena dados climáticos em geral.
Esses dados geralmente são obtidos em janelas de tempo menores que as das idades geológicas.
Inicialmente, foram criadas tabelas para dados de Gás Carbônico (CO2) e Isótopos de Oxigênio.
Ambos possuem um registro para cada milhão de ano.
A tabela Pontos é a principal tabela no banco de dados, pois esta representa as informações da bacia no espaço e tempo.
O campo RPB (Referente a Parte de Bacia) serve para armazenar a sub parte da bacia que o ponto pertence e pode ser completado com as seguintes opções:
Linha de Costa, Plataforma, Talude e Sopé.
O campo PRD serve para armazenar a Porcentagem Relativa de Depósitos numa área.
Essa tabela utiliza coordenadas geográficas para marcar um local.
A o final duas 'malhas' são mostradas.
Uma com informações de batimetria e gravimetria, dispostas em linhas e colunas com precisão de 1 minuto de grau.
Outra com dados dos sedimentos, disposta sinuosamente no globo e com distância irregular entre os pontos.
A malha com os dados atuais de gravimetria e batimetria é disposta apenas para o tempo presente, já que esses dados não existem para outras idades geológicas.
Porém, a malha com os dados dos sedimentos é expandida para as idades geológicas anteriores.
As coordenadas atuais (Campos:
Lat_ at, lon_ at) são mantidas fins de referência, contudo, cada ponto em distintas idades geológicas possuem distintas coordenadas.
As coordenadas em idades geológicas passadas são flags que marcam onde cada ponto esteve no passado.
Assim estas coordenadas constituem a reconstituição da deriva continental.
Esta reconstituição é estimada de maneira abstrata e deve sofrer ajustes para se adaptar por o modelo de deriva Como um ponto representa uma determinada área na bacia, tem- se mais de uma litologia para o mesmo ponto.
Porém também há partes da área que não possuem depósitos.
A porcentagem da área que não possui depósitos deve ser subtraída, assim deve ser armazenada a porcentagem da área total que sofreu depósitos, para isso temos o campo PRD.
Para controle de validade e qualidade dos dados temos a tabela proveniencias.
Esta tabela serve para armazenar a data de criação dos dados, a data das fontes provenientes das cartas estratigráficas, a descrição de outras fontes, o método utilizado e o endereço da página utilizada como fonte (Campo:
Como uma bacia é constituída de várias formações, foi adicionada a tabela Formacao.
Esta tabela armazena, além de o nome da formação, o ambiente de sedimentação e o Potencial Papel no Sistema Petrolífero.
A tabela camadas serve para armazenar camadas provenientes de perfis de sísmica marítima.
Em ela é possível atribuir dados mais precisos que servem para validação e aprimoramento dos dados no banco de dados.
Para cada camada é possível definir dados como:
Litologia que constitui a camada, idade e espessura da camada.
A figura 4.6 mostra um perfil de Sísmica Marítima (interpretado) e suas camadas para a bacia de Santos.
A tabela rochas armazena basicamente dados das litologias, tipo da litologia e outras divisões.
Estas divisões além de armazenar a informação tem como objetivo auxiliar no processo de KDD, pois isso torna possível executar algoritmos baseando- se em grupos de litologias.
Por fim, a tabela rocha_ pontos serve para armazenar valores correspondentes a uma única litologia, já que a tabela pontos armazena os valores somados.
Em resumo, o modelo do banco permite armazenar:·
Informações sobre as litologias presentes nas bacias sedimentares;·
As litologias locais, variantes conforme o tempo geológico;·
O tempo geológico, separado em Idades, Épocas, Períodos, Eras e Eons;·
Informações explicitas sobre qual parte da bacia um ponto de dados (os dados são mapeados em pontos no mapa) pertence;·
Estimativas referente a a quantidade de depósitos litológicos presentes no local e no tempo geológico;·
Dados de batimetria e gravimetria para cada ponto no tempo e espaço;·
Dados de formação de uma bacia;·
Dados de sísmica marítima, separados por camadas;·
Metadados para a proveniência dos dados.
Além de o modelo completo do banco, existe um modelo estrela (Pronto para DW), com o objetivo de facilitar a obtenção de informação em tempo real.
Foram criados scripts de inserção de dados, para realizar a carga neste modelo, de modo que os dados presentes no PaleoGeoDB estejam presentes no modelo estrela do banco.
A figura 4.7 ilustra o formato do modelo estrela.
Quanto a o limite territorial, a grande questão é:
&quot;Como manter os dados dentro de os limites sinuosos das bacias, de maneira a representar os dados reais de forma fiel?».
A estratégia adotada foi primeiro obter as linhas que limitam o território.
Assim, basicamente temos que obter as coordenadas que marcam a linha da costa e a linha do final da bacia.
Para obter as coordenadas foram utilizadas 2 fontes.
De o National Oceanic and Atmospheric Administration (NOAA) foi obtida a linha da costa.
O NOAA foi escolhido por três razões;
Para obter as demais coordenadas, foi utilizado o TOPEX, que gera coordenadas com precisão de quatro casas decimais, juntamente com a altitude/ profundidade do local.
A terceira razão por a qual o NOAA foi utilizado é devido a o fato de que o TOPEX não gera linhas de contorno continental, assim para gerarmos uma linha de costa (LC) seria necessário verificações de coordenadas com outras fontes.
Foi obtido um total de 4.142.875 pares de coordenadas, considerando as coordenadas relativas à terrenos acima de o nível do mar.
Para validar as linhas foram utilizadas duas ferramentas.
Primeiramente foi montado um Mapa 3D com o auxílio do software Surfer.
Depois criado um arquivo.
KML para o Google Earth.
Em o Google Earth os dados de costa se mostraram deslocados algumas dezenas de metros em direção Oeste.
Porém todos uniformes, ou seja, mostravam o contorno idêntico ao do Google Earth, apenas com uma certa diferença em relação a a longitude.
Para resolver o problema os dados foram mesclados com os do TOPEX.
Foram filtrados, de entre aqueles dados que possuem 0 (zero) no valor de profundidade, os que mais se aproximam da linha da costa.
Assim foram obtidos os dados do TOPEX com base nos dados do NOAA.
Diretamente do NOAA foi obtida a linha da costa.
Para obter a linha limite, foram utilizados os dados do TOPEX que já estavam no banco de dados.
Para isso foi usado um filtro simples via SQL.
Aquelas regiões que estão próximas a 3.000 metros formam a linha (L3K).
Este filtro foi aplicado até obter uma boa relação entre precisão e quantidade de dados que formam a linha.
Em o final o filtro ficou com uma variação em torno de 15 metros.
Para aproveitar melhor as informações presentes nas cartas estratigráficas uma terceira linha foi estabelecida.
Como as cartas tem um indicador de quebra de plataforma (QP), faz sentido que os dados sejam distribuídos de acordo com o local.
O exemplo a seguir ajuda- nos a visualizar melhor a situação.
Digamos que a bacia x numa latitude y possua 300 metros de distância da costa.
Imagine que a quebra de plataforma inicie a 50 metros da costa.
Com apenas duas linhas teríamos um dado de litologia a cada 8,1 km, isto daria apenas 6 dados antes da quebra de plataforma independente de quantos dados houvessem na carta.
Se naturalmente houvessem 9 dados na carta antes dos 50m, então teríamos 3 dados fora de o local.
Ou seja, 3 dados estariam no Talude ao invés de estarem na Plataforma continental.
Não foram encontradas fontes que possuíssem coordenadas ou mesmo informações que indicassem pontos de quebra de plataforma.
Assim, os pontos foram estabelecidos e exportados via Surfer com base no modelo 3D criado com os dados do banco.
Após a criação da linha de QP, obtivemos três linhas no banco de dados, LC, QP e L3K.
Para a execução do algoritmo de preenchimento (Seção 4.3.4) pequenos espaços foram preservados de entre as bacias, visando prevenir a sobreposição de dados.
Além disso, do ponto de vista geológico, é melhor que haja pequenos espaços em branco (o que representa a divisão das bacias) do que presença de dados de outra bacia.
O software desenvolvido exporta as coordenadas geradas.
Assim, com as mesmas foi criado um arquivo.
Kml que é utilizado por o Google Earth para visualizar pontos, linhas e outras referências.
A figura 4.8 mostra a pré-visualização das linhas.
Devido a a enorme quantidade de dados, e a enorme área para atribuir esses dados, a necessidade de um bom sistema para automatização do processo é fundamental.
Possivelmente devido a o fato da originalidade e especificidade do trabalho aqui descrito, não foram encontradas técnicas na literatura ou trabalhos correlatos que fossem úteis para a distribuição e mapeamento automático dos dados.
Em uma visão alto nível, foram elaboradas 3 soluções.
Uma utilizando distorção de imagens, outra utilizando ângulos em relação a a costa, e outra com base em fórmulas e distribuição dos dados.
Solução A:
Distorção de imagens.
A técnica de fusão de imagens consiste, numa interpolação de pixels entre duas figuras de modo a criar uma única figura preservando suas principais características.
Em outras palavras, esta técnica visa fundir duas ou mais imagens para sintetizar a informação significante de cada imagem numa única imagem.
Esta técnica é amplamente utilizada para sensoriamento remoto, geração de imagens médicas e aplicações militares.
Como não faz sentido (do ponto de vista geológico) unir dados de duas bacias, a técnica seria adaptada para uma distorção da imagem, e aplicada em subdivisões dos gráficos das cartas estratigráficas.
Cada carta deveria ser fatiada em 34 partes, que correspondem às 34 idades geológicas pertinentes a este trabalho, deste modo cada fatia corresponderia a uma bacia numa idade geológica.
Estas fatias seriam distorcidas, através de algoritmos presentes na literatura, de modo a completar a área de uma bacia.
Com uma imagem cobrindo uma bacia, a atividade a seguir seria transcrever as legendas presentes nas cartas para os respectivos valores.
A vantagem desta técnica é que o mapeamento dentro de os limites teria uma excelente precisão, já que a imagem da carta (fonte original) seria ajustada de modo gráfico nos limites da bacia.
Porém essa técnica possui alguns inconvenientes.
Como definir a distância entre um dado e outro de forma a não perder informações é uma das questões, já que a transcrição gráfica automatizada não é flexível como a análise humana quanto a as litologias dos fontes.
Outro grande problema é a transcrição para os valores em si, já que as litologias presentes nas cartas são compostas de cores e traços.
A figura 4.9 representa o recorte da bacia de Jequitinhonha relativo à idade Ypresiana.
Verticalmente esta imagem seria deformada de um limite a outro da bacia e horizontalmente da costa até a profundidade de 3.000 metros no Atlântico.
Solução B: Linhas de distribuição com base em ângulos de 90o partindo da costa.
Partindo da ideia de que os dados devem ficar perpendiculares à linha de costa relativa à bacia, observou- se que a criação de um limite angular centrado nos 90o poderia ser uma boa opção.
Assim, para cada linha de dados a ser mapeada um cálculo deve ser realizado para determinar a direção da linha.
O algoritmo consiste em formar uma matriz de pontos onde:
O valor na Matriz são pontos para determinar a angulação.
I é um ponto na linha da costa e j o registro limite previamente escolhido indo em direção a o Oceano.
O valor de j é uma coordenada utilizada para calcular a melhor variação do ângulo de modo a ajustar as linhas e impedir espaços em branco ou sobreposições.
A figura 4.10 mostra linhas em forma de 'T', onde a linha que segue em direção a o Oceano é a linha de preenchimento dos dados.
A linha verde mostra um caso de sucesso, ao contrário de as linhas vermelha e preta, onde a linha vermelha cruza com a preta havendo sobreposição de dados.
Como a quantidade de dados é imensa e a costa brasileira é muito sinuosa, controlar a angulação das linhas de preenchimento automaticamente de forma a evitar espaços em branco e colisões se mostra uma tarefa complexa.
Por esse motivo esta técnica foi descartada.
Solução C: Fórmulas para distribuição de dados.
A ideia desta solução é que, a partir de cada ponto o próximo ponto seja localizado via um conjunto de fórmulas.
Para construção deste algoritmo duas fórmulas são essenciais:
Haversine para encontrar a distância entre dois pontos e uma fórmula para se obter a curvatura entre dois pontos.
Para se obter a curvatura, simbolizada por (Teta), entre duas coordenadas geográficas utiliza- se a seguinte fórmula:
Estas fórmulas são utilizadas em meio ao algoritmo, de modo que para cada ponto são chamadas funções que utilizam ambas as fórmulas.
A seguir o algoritmo é descrito, em duas etapas e em alto nível.
Para cada carta primeiramente divide- se a mesma na quebra de talude, então para cada uma das partes:
A ordem de etapas descritas acima faz parte de um laço lógico que se repete n vezes para o preenchimento de uma bacia, mais 34 vezes para preencher- la nas idades geológicas.
O resultado dos passos lógicos, descritos acima, é o preenchimento completo de uma bacia.
É importante lembrar que os dados de idades mais antigas não são atribuídos diretamente as coordenadas, estes apenas são dispostos na extensão da bacia para posteriormente serem mapeados com flags de posição e deslocamento.
O resultado dos passos lógicos, descritos acima, é o preenchimento completo de uma bacia.
Porém algumas variáveis de entrada são necessárias para iniciar o algoritmo.
Essas variáveis são os pontos iniciais (pontos na LC) e finais (pontos da QP) que determinam a distância total (passo 1).
Duas questões são importantes para a definição dessas variáveis:
&quot;Quais os pontos iniciais e finais a serem utilizados?
E como obter- los?».
Para um correto mapeamento as linhas ao serem preenchidas devem ficar com um ângulo inicial de 90 graus em relação a bacia.
Os itens listados a seguir mostram os passos lógicos criados para definir os pontos a serem usados nas retas perpendiculares a costa.
Após obter a quantidade de pontos, com a mesma distância de seguimento, traça- se as linhas de LC, QP, e L3K.
Cada uma dessas linhas é armazenada num vetor, então, entre dois vetores traça- se as retas como descrito no primeiro algoritmo.
Como dados de entrada para o algoritmo, são necessárias as coordenadas limites de cada bacia.
Porém, devido a a sinuosidade da costa, e a extensão do terreno das bacias, são necessárias coordenadas extras para ajustar a curvatura e a direção das linhas.
Para isso foram criadas linhas, de modo visual, no Google Earth;
Suas coordenadas foram capturadas e exportadas.
Essas coordenadas utilizadas podem ser conferidas no apêndice A. Esta solução se mostrou eficaz, tanto em termos de precisão como em performance.
A figura conferido no apêndice F. Este algoritmo pode ser utilizado para preenchimento de quaisquer dados numéricos ao longo de qualquer região numa superfície esférica.
Para isso, devem apenas ser estabelecidos as coordenadas de limite e controle (coordenadas internas a uma determinada área que ajudam na precisão das linhas).
Para implementar os algoritmos e carregar os dados no banco a ferramenta de ETL, descrita na seção 4.2, foi atualizada.
A ferramenta mais do que realizar a ETL e executar os algoritmos, demonstra bom funcionamento dos algoritmos criados, validando a teoria desenvolvida.
Seu desempenho provase satisfatório ao realizar milhões de cálculos na inserção dos registros (mais detalhes da ferramenta, podem ser conferidas no apêndice E).
Problemas encontrados.
Foram encontrados alguns problemas com a solução.
Estes problemas referem- se a precisão no mapeamento dos dados e em geral não chegam a ser significantes já que as áreas trabalhadas são bem extensas e a falha na precisão das fórmulas é pequena.
O primeiro fator que leva à imperfeição da solução se deve ao fato do algoritmo estar construído com base em duas fórmulas que não são 100% precisas.
A figura 4.11 é uma amostra da primeira geração de dados produzidos.
Podemos notar que ela possui alguns defeitos de sobreposição dos dados.
A sobreposição, ocorre por três fatores.
O primeiro refere- se à precisão da formula de Haversine.
Isso implica que quanto maior a precisão dos dados, maior é o grau de falha da fórmula.
Este fato foi constatado com análise entre as bacias que possuíam muitos dados para áreas muito pequenas (e consequentemente exigiam mais precisão).
Estas tiveram uma sobreposição mais acentuada dos que as demais bacias.
O segundo fator é a fórmula de curvatura que pode vir a tomar uma direção oposta a esperada, e assim fazer com que dados sejam mapeados muito próximos à outros (em termos de visualização, sobrepostos).
Caso sobrem dados ao final de um segmento, a curvatura tende a fazer com que o próximo dado após o final do segmento (primeiro que sobrou), entre as retas que cortam as bacias perpendicularmente, seja mapeado antes do último dado.
A figura 4.12 exemplifica.
Como os dados são mapeados em linhas ao longo de a costa, onde cada linha representa o mesmo grupo de litologias, este fator não chega a ser um problema.
Em outras palavras, os dados sobrepostos provenientes de uma mesma linha paralela à costa são os mesmos.
O terceiro fator é o ajuste da quantidade de dados e seus segmentos.
Este fator pode ser corrigido alterando alguns valores em variáveis dentro de o algoritmo.
Eliminando este fator de erro, diminui- se os problemas com o segundo fator, pois quando o segmento dos dados é muito grande, sobram dados no final.
Assim, o cálculo da distância, junto a curvatura, ajuda a criar anomalias no mapeamento.
Mais que um plano de mineração, esta seção se dispõe a criar um plano de KDD e GKD, onde a mineração de dados deve ser executada de diversas maneiras e com diversas configurações para os algoritmos.
Este plano se propõe não apenas para descoberta de conhecimento, mas também para validar e melhorar a precisão no mapeamento dos dados.
Para executar este plano é importante seguir sua ordem, pois em alguns casos um processo depende dos resultados de outros.
A generalização espaço-temporal por exemplo, define uma regra geral baseada numa hierarquia dos dados e um conjunto de padrões.
Para isso é necessário que regras de Associação e Associação espaço-temporal sejam previamente conhecidas.
O plano aqui descrito, trata sobre técnicas de mineração, citando itens como objetivos dentro de um tópico.
Algumas técnicas em GKD são possivelmente mais difíceis de se executar que outras.
Primeiramente por a própria natureza do GKD e a mineração espacial.
Segundo, porque as possibilidades de descoberta em meio aos dados espaço-temporais são tantas, que possivelmente sejam necessários novos algoritmos para se obter toda informação previamente desconhecida.
Associação Visa encontrar similaridades entre as rochas e fatores climáticos.
De entre algumas possíveis similaridades podemos citar:·
Similaridade entre as rochas encontradas nos locais onde há extração atualmente (para validação da base).·
Similaridades entre rochas geradoras presentes numa formação e rochas de outras formações com potencial previamente desconhecido.·
Correlações entre gravimetria e demais dados geológicos.
Classificação O plano de mineração para Classificação, Visa criar modelos de indução com base nos geodados, possivelmente um mapa de ajuda a tomada de decisão para perfuração de poços (locais com petróleo).
Para isso devem ser usados modelos de classificação preditiva onde os atributos sugeridos são:
Lat, Lon, Batimetria, Gravimetria, Isótopos de Oxigênio, e CO2.
Para atributo classe sugere- se, com base em a (s) rocha (s) geradora (s) da bacia:
Marcar '1' caso haja presença de rocha com potencial para ser geradora (ver seção 2.2) e 0 caso não haja a rocha na coordenada.
Regras de evolução Com base em mineração espacial é possível determinar padrões de evolução dos geodados.
De entre outros possíveis resultados, provenientes de um processo de GKD, pode- se citar:·
Criação de um gráfico que mostre o caminho percorrido por os sedimentos.
Isso pode ser importante para detectar domos de sal, que naturalmente tendem a se achatar horizontalmente, alterando a área ocupada por os sedimentos.·
Possível criação de uma malha que ligue valores de sedimentos de modo a detectar anomalias e, por consequência, detectar falhas ou domos de sal.
A figura 4.13 mostra uma possível malha entre os sedimentos representados por 'x` e'Losangos'.
A o criar uma evolução desta malha as anomalias ficarão visíveis, o que facilitaria o processo para descoberta de domos de sal que podem esconder grandes reservas de óleo no pré-sal.
Associação espaço temporal Similar a associação convencional, porém com o foco em encontrar similaridades entre as alterações dos dados no espaço-tempo.
De entre algumas possíveis similaridades podemos citar:·
Similaridade entre a evolução das rochas geradoras de hidrocarbonetos.·
Padrões temporais entre CO2, Isotopo de Oxigênio, gravimetria e as rochas com papel importante nos locais produtores de petróleo.
Generalização espaço-temporal Com esta etapa da descoberta de conhecimento, podemos agregar algumas informações previamente conhecidas a fim de induzir regras gerais em torno de algo.
Possivelmente um conjunto de fatores que levem a uma indicação do tipo:
Uma bacia que possuiu sedimentos x numa idade y possui reservas numa área ocupada por o sedimento x.
Esta etapa é importante para difundir o conhecimento gerado, porém demanda conhecimentos com alto grau de confiança como entrada.
Segmentação de dados espaço-temporais Podemos segmentar os dados com base em seu comportamento espaço-temporal.
Essa etapa requer como entrada dados de associação, regras de evolução e associação espaço-temporal.
A ideia é separar os dados geológicos em grupos.
De modo geral, de entre estas separações, pode- se prever:·
Áreas com um determinado percentual de chance de haver petróleo, sal etc.· Áreas com características paleogeográficas ou paleoclimáticas em comum.
Conclusões Em este Capítulo são relatados os resultados obtidos, e após, são feitas as considerações sobre as contribuições científicas.
De modo simples os resultados da pesquisa e do desenvolvimento do trabalho serão ligados com as possibilidades de benefícios tanto para a academia quanto para a indústria petrolífera.
Finalmente serão apresentados alguns dos possíveis trabalhos futuros.
Resultados Obtidos Um banco de dados paleogeográficos e paleoclimaticos foi desenvolvido.
Seus dados foram coletados de diversas fontes e grande parte de eles foram adaptados para serem representados de forma numérica.
Esta forma numérica constitui- se num modelo representativo para os dados e paleodados das bacias sedimentares brasileiras.
Milhões de dados compõem a estrutura proposta;
Em sua maioria dados estratigráficos que representam camadas de depósitos sedimentares referentes tanto ao período atual, como à períodos passados desde a separação dos continentes da África e da América do Sul.
Acompanhando os dados estratigráficos, estão diversos metadados que ajudam no entendimento da composição sedimentar do terreno.
Além de outros dados que são importantes indicadores climáticos, como os níveis de Gás Carbônico.
Como relatado no capítulo 4, o trabalho evoluiu de um sistema simples e pouco coerente com os aspectos geológicos, a um sistema realístico que representa os dados naturais e abre margem para representar- los de forma evolutiva ao longo de os 140 milhões de anos.
Foram obtidas, e mapeadas ao longo de a costa brasileira, duas malhas de dados.
A primeira possui coordenadas, batimetria e dados gravimétricos.
A segunda representa os dados, e metadados, litoestratigráficos, que foram mapeados automaticamente conforme descrito na seção 4.3, mais especificamente com a solução criada e descrita na seção 4.3.4.
A primeira malha pode ser visualizada na figura 4.4.
Esta malha foi obtida com auxílio da ferramenta de ETL criada (descrita na seção 4.2).
Esta ferramenta sofreu alterações de modo a comportar os algoritmos desenvolvidos para a geração da segunda malha de dados.
A versão final da ferramenta pode ser visualizada no apêndice E, juntamente com comentários descrevendo suas funções.
Os resultados referentes à segunda malha de dados podem ser conferidos no apêndice F. Os gráficos mostrados neste apêndice representam pontos em determinadas coordenadas, onde cada ponto possui um conjunto de informações que por sua vez estão armazenadas na tabela pontos do banco de dados.
O banco de dados final, somente para a idade geológica atual, armazena 83.273 pontos de dados ao longo de as bacias.
Conforme descrito na seção 4.3.2, foram obtidas 4.142.875 coordenadas para a primeira malha, contendo a gravimetria e a batimetria do terreno.
Contribuição Científica É sabido que a extração de óleo é uma atividade em constante evolução e com descobertas recentes.
Uma das contribuições científicas deste trabalho é ajudar na construção de conhecimento relativo aos elementos necessários para a formação do óleo.
É importante salientar que o banco de dados como um todo é resultado de pesquisas aplicadas de forma a agrupar dados e representar a evolução das bacias sedimentares brasileiras.
Assim, a contribuição não se baseia num simples modelo de banco de dados.
Em uma visão geral, o banco de dados é resultado de todo processo de pesquisa e desenvolvimento descrito nesta dissertação.
O modelo criado é uma alternativa ao modelo estrela, que apesar de ser prático para a criação de um DW, demanda um grande espaço para ser armazenado, pois a tabela central sofre grande aumento de dados a cada nova paleo_ propriedade adicionada (ver figura 4.7).
O modelo estrela possui diversas vantagens em relação a o modelo criado;
Este é mais claro, eficaz para criação de DW e possivelmente mais prático para KDD.
De fato, o modelo criado não se propõe a ser o melhor modelo, este se propõe a ser uma alternativa que sacrifica flexibilidade, entre outros aspectos, para obter ganhos em relação a o armazenamento, uma vez que diversos tipos de dados distintos (paleo_ propriedade) tendem a ser armazenados.
O modelo criado possui uma forma específica para comportar os dados requeridos por o cenário da pesquisa, este foi testado com diversas cargas de dados com auxílio da ferramenta de ETL criada.
Além disso, o formato do modelo, com uma tabela central baseadas em coordenadas, permite facilmente a adição de novos dados paleoclimáticos.
Caso os novos dados tenham ligações com uma região, basta ligar- los a tabela principal (pontos), caso sejam dados referentes a toda Terra (ou toda a área em questão), estes podem ser ligados a tabela Idades (como exemplo:
Fatores Climáticos).
O problema mais comum de se trabalhar com dados geográficos é o fato de que o valor de distância referente a longitude é alterada conforme a distância da linha do equador.
Porém o algoritmo desenvolvido utiliza a fórmula de Haversine para mapear estes dados, assim a distância é calculada considerando a variação da longitude.
De este modo, o algoritmo detém uma, relativa, boa precisão em relação a distância dos pontos.
O algoritmo de mapeamento de dados mostra- se uma importante contribuição, uma vez que pode ser utilizado para propagar quaisquer dados, com representatividade numérica, ao longo de uma superfície na Terra.
Os dados presentes no banco são úteis para futuras pesquisas em geoinformática.
Estes servem como pilar para a construção de conhecimento que poderá ser aplicado diretamente nas geociências e por consequência na indústria petrolífera.
Por fim, este trabalho gera potencial para significativas descobertas científicas, principalmente em questão dos trabalhos futuros, possíveis com base no que foi obtido.
A seção abaixo descreve algumas possibilidades em relação a o que pode ser feito para extensão do trabalho descrito nesta dissertação.
Trabalhos Futuros O trabalho relatado nesta dissertação abre caminho para muitos trabalhos futuros.
Por se tratar de um trabalho multidisciplinar, que envolve diretamente duas ciências (computação e geologia), diversos ramos são possíveis para continuação da pesquisa.
Novos trabalhos em ambas as ciências agregarão valor ao que foi criado.
Novos conhecimentos podem ser obtidos, novas soluções poderão ser criadas para melhorar as mais distintas tarefas, principalmente aquelas ligadas à extração de óleo.
A quantidade de dados possíveis de serem agregados é praticamente infinita, além disso, a proveniência dos dados, a quantidade de um determinado elemento num local e a atualidade dos dados;
Não apenas influenciam na precisão das informações extraídas mas também ajudam a extrair novos conhecimentos por meio de técnicas de KDD.
A absoluta maioria dos dados foram mapeados por a solução algorítmica criada para determinar sua localização.
Devido a este fator, apesar de os testes e verificações visuais, é possível que muitos dados estejam com um mapeamento incoerente com a realidade.
Desta forma, um trabalho futuro proposto é um sistema de verificação dos dados, que atualize coordenadas de pontos de acordo com dados empíricos.
Cada bacia possui várias sequências que são pacotes de rochas sedimentares relativos a um grupo no tempo geológico.
Embora hajam subsequências, em geral, as duas grandes sequências presentes são a sequência Rift e a sequência Drift.
Os dados presentes nestas divisões possuem diferentes fontes.
Assim, um possível trabalho futuro, seria a classificação dos dados (presentes no banco) quanto as subsequências.
A ANP disponibiliza anualmente informações sobre os locais com extração ativa de petróleo.
Estes dados podem ser úteis para processos de KDD, de modo a descobrir padrões entre eles e determinar chances de haver petróleo em outras bacias baseando- se nos dados extraídos destas áreas.
A figura 5.1 é um mapa com as áreas de extração.
As áreas em amarelo ao longo de a costa são as áreas das bacias sedimentares oceânicas (áreas de interesse).
Dados de Sísmica Marítima apresentam as camadas de litologias no tempo presente com uma maior precisão que os provenientes das cartas, pois estes são coletados diretamente do referido local, logo, estes dados são fundamentais para manter o banco de dados atualizado.
Além disso, os dados provenientes da Sísmica, podem ser coletados e usados para agregar precisão, verificar e estabelecer uma ordem nos dados do banco.
A ampliação do modelo do banco de dados também constitui um importante trabalho futuro.
A medida que novos tipos de dados forem sendo obtidos, o modelo deve ser expandido.
Para isso a ferramenta de ETL criada deve ser melhorada e atualizada para servir ao novo cenário de dados e banco de dados.
A medida que muitos dados são produzidos são necessários procedimentos para assegurar a sua qualidades.
Propõe- se a criação de um modelo de verificação para os dados, juntamente com um sistema especialista que valide os dados presentes no banco de dados.
Este sistema deve ser flexível para aceitar não somente a entrada de dados reais, mas também a entrada de conhecimento geológico.
Esse conhecimento deve ser interpretado por o software e transformado em regras, que por sua vez, devem ser analisadas para localizar possíveis dados discrepantes, errôneos ou mapeados em local errado.
Todo o resultado da pesquisa, descrito aqui, pode ser replicado para a costa Africana.
A única diferença seria, basicamente, a obtenção dos dados fontes (cartas estratigráficas, coordenadas etc).
O desenvolvimento deste trabalho ajudaria a criar um modelo de evolução mais realístico e completo, já que as bacias da costa Brasileira e Africana um dia foram uma só.
Por fim, como dito no plano de mineração 4.3.5, novos algoritmos de mineração, especializados em dados paleogeográficos e paleoclimáticos, podem ser decisivos para a descoberta de conhecimento neste banco, pois as possibilidades de descoberta em meio aos dados paleogeográficos são tantas que possivelmente sejam necessários novos algoritmos para se obter toda informação previamente desconhecida.
