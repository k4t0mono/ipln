Sistemas multiprocessados em chip (MPSoCs -- Multiprocessor Systems-on-Chip) estão sendo considerados como provável padrão para implementar os sistemas embarcados futuros.
O poder computacional destas plataformas possibilita a execução simultânea de diversas aplicações com diferentes requisitos.
O emprego de redes intrachip (NoCs ­ Networks-on-Chip) como infraestrutura de comunicação em tais plataformas é uma realidade em pesquisas acadêmicas e projetos industriais.
NoCs são comumente vistas como alternativa aos tradicionais barramentos, oferecendo como principais vantagens escalabilidade e suporte a diversas comunicações em paralelo.
Contudo, a motivação para o seu emprego em SoCs (Systems-on-Chip) vai além de essas vantagens óbvias, visto que NoCs podem suportar diversos serviços de comunicação com diferentes níveis de qualidade.
Visto que comumente as aplicações que executam em MPSoCs são compostas por diferentes tarefas comunicantes, o eficiente suporte à comunicação tem um papel fundamental no desempenho destas e é uma área estratégica no desenvolvimento de plataformas multiprocessadas.
Muitos trabalhos têm sido conduzidos na última década nas áreas de NoCs e MPSoCs, entretanto poucos tratam a lacuna existente entre os níveis de rede (serviços de comunicação) e de aplicação em MPSoCs baseados em NoC.
Este trabalho tem por objetivo a implementação de diferentes serviços de comunicação no nível de rede e a disponibilização destes no nível de aplicação, preenchendo assim a lacuna existente entre tais níveis através de uma melhor integração hardware/ software.
A metodologia de projeto seguida neste trabalho parte da implementação de mecanismos específicos no nível da rede, os quais dão suporte a serviços de comunicação diferenciados.
Tais serviços são expostos no nível de aplicação através de primitivas que compõem a API (Application Programming Interface) de comunicação.
O propósito desta abordagem é oferecer ao desenvolvedor de aplicações meios, em software, para satisfazer os requisitos de comunicação das aplicações, especialmente daquelas com restrições temporais.
As avaliações realizadas mostram o funcionamento e os benefícios obtidos através da utilização dos serviços implementados, além de apontar alguns cenários onde estes não se adequam tão bem.
Palavras chave:
MPSoC, NoC, QoS, API e serviços de comunicação.
Para a próxima década, a lei de Moore prevê a integração de vários bilhões de transistores num único chip.
Entretanto, tornou- se claro que em termos de processamento a exploração do paralelismo no nível de instrução, com pipelines profundos e agressivas técnicas superescalares, juntamente com o uso da abundância de transistores para implementar caches chegou ao seu limite.
O aumento do desempenho a partir de altas frequências está cada vez mais difícil devido a os problemas de dissipação de calor e ao elevado consumo de energia.
A solução está em arquiteturas multiprocessadas, as quais apresentam uma melhor relação desempenho/ consumo que arquiteturas monoprocessadas com desempenho semelhante, além de possibilitarem a exploração do paralelismo em níveis mais altos de abstração.
Para amortizar os custos de fabricação e os longos ciclos de desenvolvimento de projetos ASIC, os pesquisadores buscam soluções para satisfazer a crescente necessidade de programabilidade pós-fabricação, a qual é oferecida por os processadores.
O uso de vários processadores no projeto de sistemas embarcados e a sua integração num único chip (SoC -- System-on-Chip) deram origem a uma nova classe de sistemas chamada de MPSoC (Multiprocessor System-on-Chip).
MPSoCs emergiram na última década como uma importante e auspiciosa classe de sistemas VLSI (Very Large Scale Integration).
Essa classe é considerada a mais promissora na continuidade da exploração do alto nível de integração proporcionado por a tecnologia de semicondutores, satisfazendo restrições de desempenho e consumo de energia.
Um MPSoC é um sistema integrado num único chip que agrega múltiplos processadores como componentes principais.
Em um nível mais alto de abstração, MPSoCs podem ser vistos como plataformas reconfiguráveis através da programação (software) dos seus processadores.
O crescente interesse nessa nova classe de sistemas reside na sua capacidade de combinar alto desempenho e flexibilidade.
Graças à sua programabilidade, um mesmo MPSoC pode ser empregado em diferentes produtos, reduzindo o time-- tomarket destes e estendendo a vida útil da plataforma (time-in-- market).
Essa reusabilidade aumenta o volume de produção dos chips e reduz o custo destes para o consumidor.
O projeto de MPSoCs é uma atividade multidisciplinar que envolve infraestruturas de comunicação intra-chip, arquitetura de microprocessadores e memórias, modelos de programação, fluxos de co-simulação e metodologias para modelagem e exploração do espaço de projeto.
Quanto a o multiprocessamento, MPSoCs podem ser classificados em duas categorias.
Heterogêneos: Sistemas compostos por diferentes tipos de processadores (GPPs, DSPs, ASIPs, etc), aceleradores e periféricos.
Homogêneos: Sistemas compostos por uma unidade básica chamada de elemento de processamento (PE ­ Processing Element), a qual é instanciada múltiplas vezes.
Comumente, os componentes básicos de um PE incluem um processador de propósito geral e uma memória local.
Arquiteturas heterogêneas são mais voltadas a aplicações com rígidas restrições de potência, consumo de energia e desempenho, sendo mais difíceis de serem programadas e menos flexíveis que arquiteturas homogêneas.
A homogeneidade oriunda da replicação dos PEs tem como principais benefícios escalabilidade e tolerância a falhas, além de favorecer o layout do circuito e técnicas como mapeamento e migração de tarefas.
A disponibilidade de diversos recursos de processamento presente nos MPSoCs possibilita a exploração do paralelismo no nível de tarefas.
Para tal fim, as aplicações desenvolvidas são compostas por diversas tarefas que podem ser executadas em paralelo, sendo estas mapeadas nos processadores da plataforma alvo.
Além disso, várias aplicações podem executar simultaneamente, caracterizando o paralelismo no nível de aplicação.
Em geral, aplicações são independentes e não exigem comunicação entre si.
Entretanto, tarefas de uma mesma aplicação comunicam- se entre si para troca de dados e sincronização.
Com o aumento do número de aplicações/ tarefas executando simultaneamente, o volume de dados movimentados na plataforma intensifica- se a ponto de poder comprometer o desempenho geral do sistema.
Em virtude de a relação direta entre comunicação entre tarefas e desempenho da aplicação, é imprescindível que a infraestrutura de comunicação empregada suporte elevadas taxas de comunicação e alto grau de paralelismo.
A solução natural para tal problema está nas redes de interconexão intra-chip (NoCs ­ Networks-on-Chip), as quais além de suprirem as necessidades relativas a largura de banda e paralelismo, proporcionam a escalabilidade necessária para o crescimento dos sistemas.
Em é apresentada uma avaliação analítica e experimental onde os autores comparam várias infraestruturas de comunicação intra-chip (barramentos, NoCs e conexões ponto-a-ponto) e verificam que NoCs apresentam as menores diferenças entre atrasos estimados e atrasos reais obtidos após a extração do layout.
NoCs são basicamente compostas por roteadores e canais de comunicação ponto-a-ponto que interconectam núcleos de propriedade intelectual (IP -- Intellectual Property) de um sistema integrado.
O roteador é o elemento principal, sendo responsável por a definição de rotas (roteamento), controle de fluxo, qualidade de serviço e garantia de entrega dos pacotes.
Escalabilidade está inerentemente presente no conceito de NoCs, visto que a largura de banda agregada cresce junto com suas dimensões (e.
g adição de roteadores e enlaces).
O modelo de comunicação utilizado é troca de mensagens transmitidas na forma de pacotes.
Recentemente, diversas pesquisas têm sido conduzidas na área de NoCs a fim de propor diferentes serviços de comunicação que estendem o serviço básico de troca de mensagens, tais como controle de prioridades no envio, estabelecimento de conexões (temporárias ou permanentes) e suporte à comunicação coletiva (multicast/ broadcast).
O principal objetivo desses serviços é proporcionar um tratamento diferenciado aos fluxos de comunicação com restrições temporais (e.
g latência e vazão), oferecendo diferentes níveis de qualidade (QoS ­ Quality-of--Service), a fim de prover meios para o atendimento de deadlines.
MPSoCs baseados em NoC são uma nova tendência em sistemas embarcados.
A união dessas duas áreas segue o exemplo de sucesso dos clusters da área de processamento paralelo, onde processadores são interconectados por redes de alto desempenho.
A partir de essa união, torna- se possível a criação de plataformas intra-chip escaláveis e programáveis com alto poder computacional, capazes de executar simultaneamente diversas aplicações.
Todavia, a integração de várias aplicações sobre a mesma plataforma deve ser conduzida com cautela, uma vez que cada aplicação tem seus próprios requisitos e padrões de comunicação entre tarefas, os quais exigem da rede diferentes serviços de comunicação.
Portanto, fica evidente a necessidade de ampliar a programabilidade dos MPSoCs baseados em NoC a fim de disponibilizar os serviços de comunicação da rede no nível de software.
Essa abordagem visa estender a união arquitetural (MPSoCs e NoCs) até o nível de software, oferecendo um controle mais amplo sobre a plataforma.
Isso favorece a exploração do espaço de projeto e facilita a otimização incremental das aplicações a partir de ciclos programação e avaliação.
O desenvolvimento de aplicações paralelas para plataformas multiprocessadas deve seguir um modelo de programação que determina como as tarefas se comunicam e se sincronizam.
Tipicamente um modelo de programação consiste em primitivas incorporadas a uma linguagem de programação.
A funcionalidade de tais primitivas pode ser implementada diretamente por a infraestrutura de comunicação ou a partir de serviços básicos oferecidos por esta (e.
g multicast a partir de vários unicasts).
Os principais modelos de programação paralela são:
Troca de mensagens:
Em este modelo, comunicação e sincronização são expressas explicitamente no código fonte das aplicações utilizando primitivas que implementam a maior controle sobre a execução paralela, permitindo a eficiente exploração dos serviços de comunicação oferecidos por a plataforma, a fim de satisfazer os requisitos das aplicações.
A eficiência da solução depende do programador.
Plataformas com arquitetura de memória Norma (Em o Remote Memory Access) empregam esse modelo de programação, cuja implementação mais conhecida é o MPI.
Memória compartilhada:
Em este modelo, a comunicação entre tarefas é expressa implicitamente no código fonte a partir de o acesso a variáveis compartilhadas em memória.
A sincronização entre elas depende da implementação de mecanismos de exclusão mútua (e.
g semáforos).
Em esse modelo o paralelismo é explorado principalmente por o compilador (e.
g diretivas de compilação), facilitando a programação das aplicações.
A eficiência da solução depende do compilador.
Plataformas com arquitetura de memória Uma (Uniform Memory Access) e Em uma (Non Uniform Memory Access), tipicamente empregam esse modelo de programação, cuja implementação mais conhecida é o OpenMP.
A melhor maneira de programar MPSoCs em relação a produtividade e qualidades dos resultados é atualmente um tópico de intensa discussão.
O desenvolvimento de aplicações altamente otimizadas exige um grande esforço, necessitando de ajustes cuidadosos em termos de algoritmo, particionamento e mapeamento na plataforma alvo.
Originalidade e objetivos da Tese A originalidade do trabalho está na exposição dos serviços de comunicação da NoC no nível de software através de uma API (Application Programming Interface), preenchendo assim a lacuna existente entre os níveis de rede e de aplicação em MPSoCs baseados em NoC.
A partir de primitivas de comunicação em software, o programador deve ser capaz de programar aplicações de maneira que elas atinjam seus requisitos.
Essa abordagem visa dar autonomia às aplicações, permitindo que elas tenham controle sobre os recursos da rede de maneira distribuída e em tempo de execução.
O presente trabalho foi desenvolvido dentro de o escopo de MPSoCs homogêneos com arquitetura de memória Norma (troca de mensagens) e NoCs com topologia malha bidimensional e roteamento distribuído, tendo como base o MPSoC acadêmico HeMPS Os serviços oferecidos por um determinado módulo (hardware/ software) são as funcionalidades que este implementa.
O termo serviço diferenciado refere- se a uma extensão das funcionalidades básicas, visando oferecer um controle mais amplo sobre o módulo tornando- o mais flexível e personalizável.
Os seguintes serviços de comunicação diferenciados foram adicionados à API do MPSoC HeMPS:
Baseado em prioridades:
A prioridade de uma mensagem está relacionada à alocação de recursos da rede para a sua transmissão.
Uma mensagem com alta prioridade tem mais recursos disponíveis que uma mensagem com baixa prioridade;
Baseado em conexão:
Antes da transmissão de um fluxo de mensagens, uma conexão é estabelecida entre um par origem/ destino e os recursos da rede permanecem alocados durante toda a comunicação;
Roteamento diferenciado:
Uma mensagem pode ser transmitida por a rede por um caminho determinístico ou adaptativo;
Comunicação coletiva (Multicast):
Uma mesma mensagem é transmitida para vários destinos de maneira escalável.
Os objetivos estratégicos da presente Tese incluem:
Analisar o ganho de desempenho proporcionado por os serviços implementados em relação a o serviço básico de comunicação;
Explorar qualidade dos serviços de comunicação (QoS) a partir de o nível de software, de maneira a satisfazer os requisitos de desempenho das aplicações;
Minimizar a interferência entre aplicações que executam simultaneamente, a fim de tornar o desempenho destas independente da presença/ ausência umas das outras;
Dominar o projeto de MPSoCs baseados em NoC desde o nível de rede até o nível de aplicação.
Tais objetivos estratégicos dependem dos seguintes objetivos específicos:
Nível de rede o Implementação de um mecanismo de alocação de recursos baseado em prioridades fixas;
Nível de sistema operacional o Definição de primitivas de comunicação e parâmetros;
Contribuição Este trabalho deixa como contribuição para a comunidade de pesquisa em MPSoCs um framework open source (Apêndice B ­ HeMPS Generator) que possibilita a geração automatizada de MPSoCs baseados em NoC com suporte a diversos serviços de comunicação acessíveis via software, a fim de permitir ao projetista controlar o compartilhamento da arquitetura de interconexão em alto nível e atingir os requisitos das aplicações.
Tal framework permite ainda a seleção de diversos parâmetros de hardware/ software, mapeamento de tarefas e depuração no nível de aplicação.
A plataforma gerada é completamente descrita em VHDL RTL sintetizável.
Para fins de simulação, o framework disponibiliza também, modelos SystemC com precisão de ciclo para processadores (ISS) e memórias.
Organização do texto O restante do texto está organizado em mais seis capítulos:
QoS e composability) a sistemas que executam aplicações de tempo real;
Combina as vantagens de algoritmos de roteamento determinístico e adaptativo a fim de assegurar a disponibilidade de um número maior de recursos de comunicação a tráfegos prioritários;
Os Apêndices A e B apresentam, respectivamente, a lista das publicações realizadas durante o período do doutorado e o framework HeMPS Generator.
Diferentes arquiteturas de MPSoCs têm sido propostas recentemente, tanto no âmbito acadêmico como industrial, focando vários domínios de aplicação.
No entanto, proporcionar meios a fim de que as aplicações tenham seus requisitos de desempenho satisfeitos ainda continua sendo um desafio.
Este Capítulo é dividido em duas seções.
Em a Seção 2.1 são revisados MPSoCs baseados em NoCs, discutindo algumas de suas características como arquitetura e serviços/ API de comunicação.
Tais MPSoCs reúnem características que definem a tendência das futuras plataformas multiprocessadas.
A Seção 2.2 apresenta várias propostas que têm por finalidade oferecer garantias de desempenho às aplicações a partir de mecanismos específicos agregados ao sistema.
Cada uma das seções inclui em seu final considerações sobre os trabalhos revisados.
MPSoCs baseados em NoCs O dispositivo Tile64 foi desenvolvido por a Tilera e pode ser visto como uma evolução do processador RAW.
Trata- se de uma matriz homogênea bidimensional de 64 PEs interconectados por a NoC iMesh.
Além de os PEs, a NoC conecta também controladores de memória e de entrada/ saída.
Cada PE contém um processador VLIW, caches L1 e L2, um DMA e um roteador.
Um PE pode executar de maneira independente um sistema operacional completo ou vários PEs podem ser agrupados a fim suportar um sistema operacional multiprocessado como o SMP Linux.
A família de dispositivos Tile-Gx é a mais recente e suporta até 100 PEs, no entanto segue a mesma arquitetura básica do Tile64 ilustrada na Figura 1.
A NoC iMesh é composta por 5 redes malha bidimensionais:
UDN (User Dynamic Network), IDN (I/ O Dynamic Network), STN (Static Network), MDN (Memory Dynamic Network) e TDN (Tile Dynamic Network).
As redes dinâmicas (UDN, IDN, MDM e TDN) implementam chaveamento por pacotes (wormhole) e a rede estática (STN) implementa chaveamento por circuito.
As redes UDN, IDN e STN estão integradas no pipeline do processador, permitindo rápido acesso via registradores.
Assim, qualquer instrução do processador pode ter como origem e/ ou destino uma dessas redes.
Essa abordagem não dissocia comunicação e computação dentro de o PE, pois o processador é responsável por a injeção e retirada de pacotes nas redes, estando desta maneira sujeito à bloqueios devido a a ausência de dados durante uma leitura ou ausência de espaço durante uma escrita.
A Tilera fornece ao programador a biblioteca iLib, a qual possui uma série de primitivas de comunicação implementadas sobre a rede UDN.
Essa biblioteca é independente de sistema operacional e dá acesso direto à rede, devendo ser ligada a cada uma das aplicações durante o processo de compilação.
A iLib implementa comunicação baseada em sockets e troca de mensagens.
Através de sockets é possível criar conexões lógicas a partir de a alocação de buffers (FIFO) no PE destino.
Dois tipos de conexão lógica são suportadas;
Raw channels e buffered channels.
Utilizando raw channels, conexões lógicas são criadas alocando buffers de acesso rápido no nível da rede (integrados no pipeline), enquanto buffered channels aloca buffers na memória local.
Raw channels oferece comunicação com baixa latência, entretanto o controle de fluxo fima-fim deve ser implementado por o programador.
Buffered channels implementa o protocolo de comunicação rendezvous, onde a origem da comunicação solicita permissão de envio e aguarda uma resposta do destino, antes de enviar dados (protocolo síncrono).
A comunicação baseada em troca de mensagens é semelhante ao padrão MPI, suportando o envio de mensagens a qualquer momento para qualquer destino sem a necessidade de uma conexão.
Resultados comparativos entre os tipos de comunicação suportados reportam uma vazão (bytes/ ciclo) de 3,93 para raw channels, 1,95 para buffered channels e 1 para troca de mensagens, considerando enlaces de 4 bytes.
O projeto Terascale da Intel apresenta um array de processamento composto por 80 tiles operando a uma frequência de 4 GHz (Figura 2).
Um tile consiste num PE conectado a um roteador.
Cada PE possui duas unidades independentes de ponto flutuante de precisão simples (FPMAC), memória de instruções (IMEM) e memória de dados (DMEM).
A NoC empregada apresenta topologia malha, chaveamento por pacotes (wormhole) e interfaces assíncronas.
Toda comunicação entre pico de desempenho atingido é 1.0 Tflops à 1V e 1.28 Tflops à 1.2 V. A potência dissipada é estimada em 98W à 1V e 181W à 1.2 V. O projeto possui em torno de 100 milhões de transistores.
Em o nível de arquitetura, observa- se uma estrutura típica de MPSoC baseado em NoC.
Entretanto o fato dos PEs serem baseados em unidades de ponto flutuante e o baixo suporte a software o deixa a margem da tendência em sistemas embarcados.
SIMPLE (Simple Multiprocessor Platform Environment) é uma plataforma virtual baseada em SystemC, usada para o desenvolvimento e validação de MPSoCs homogêneos com suporte a aplicações de tempo real.
O sistema é baseado em PEs interconectados por a NoC SoCIN.
Cada PE contém um processador Java, memória local, interface de rede, portas de entrada/ saída e um relógio de tempo real.
Os processadores implementam RTSJ (Real-Time Specification for Java), dessa maneira suportando multithread e aplicações de tempo real.
A troca de mensagens entre threads é suportada por a Com-API, a qual permite o estabelecimento de canais de comunicação e a atribuição de diferentes prioridades às mensagens.
Entretanto a NoC não dá suporte a serviços de comunicação com QoS, baseados em conexões ou prioridades.
Como estudo de caso foi implementado um controlador de guindaste (crane) particionado em três threads.
Cada uma é executada por um dos três processadores que compõem a instância da plataforma.
Alguns tempos obtidos em relação a o processamento do envio e da recepção de dados variam, respectivamente, de 4800 e 3700 ciclos de clock para mensagens de 1 byte a 312100 e 388700 ciclos de clock para mensagens de 490 bytes.
Estes valores não consideram a latência da NoC, apenas o tempo de processamento das primitivas de comunicação.
A Hs-Scale é um MPSoC que visa a auto-adaptabilidade do sistema em tempo de execução a partir de a técnica de migração de tarefas.
A migração de uma tarefa é disparada a partir de o monitoramento da carga do processador ou da ocupação das filas de mensagens recebidas.
Não há uma preocupação em relação a heurística utilizada para selecionar o processador destino da tarefa a ser migrada.
Requisições de migração são enviadas aos processadores mais próximos e a tarefa é migrada para o primeiro que aceitar a requisição.
Apenas o código da tarefa é migrado, restringindo a abordagem à migração apenas de tarefas modeladas como laços contendo a sequência recepção, processamento e envio de dados.
A arquitetura do sistema é formada por uma matriz bidimensional homogênea de NPUs (Network Processing Units) que se comunicam através da NoC Hermes.
Cada NPU inclui um processador Plasma, memória local, interface de rede (Ni -- Network Interface), roteador (implícito no Network Layer), temporizador (Timer) e UART.
A Figura 3 ilustra uma instância 4x4 da Hs-Scale juntamente da estrutura da NPU.
Cada NPU executa um µkernel (microkernel) preemptivo com capacidade de executar várias tarefas simultaneamente.
O µkernel implementa também alguns mecanismos típicos de sistemas operacionais como alocação dinâmica de memória, semáforos e mutex, além de uma API básica de comunicação entre tarefas.
Essa API é baseada no padrão MPI de troca de mensagens e possui apenas duas primitivas;
Envio e recepção de mensagens.
O protocolo de comunicação empregado é eager, onde a origem da comunicação envia dados independente do estado do destino (protocolo assíncrono).
Não há um acordo entre origem e destino antes do início da transmissão.
Visto que a API é implementada no µkernel, as primitivas são invocadas a partir de chamadas de sistema.
Essa abordagem evita que as tarefas tenham acesso direto ao hardware.
Resultados obtidos a partir de uma instância 4x4 multi-FPGA (Figura 4) da plataforma mostram a elevação da vazão de um decodificador MJPEG quando as tarefas, inicialmente mapeadas na mesma NPU, são migradas uma a uma para as NPUs vizinhas.
Resultados semelhantes são observados em a partir de a simulação de uma instância 2x2 da plataforma executando a mesma aplicação.
NePA (Networked Processor Array) é uma matriz bidimensional homogênea de PEs baseados no processador OpenRISC (Figura 5).
A plataforma inclui também um simulador escrito em SystemC e modelos RTL sintetizáveis (Verilog) dos componentes que compõem a arquitetura.
Além de canais virtuais, a NoC replica os canais físicos no eixo Y (norte e sul) criando dois caminhos verticais disjuntos, visando a prevenção de deadlock em algoritmos de roteamento adaptativos.
O sistema conta com NIs bem definidas que abstraem a complexidade da NoC e dissociam computação e comunicação graças a módulos DMA responsáveis por o envio e recepção de pacotes.
Essa plataforma não oferece uma API de comunicação de alto nível, sendo a troca de mensagens implementada através da leitura/ escrita em registradores da Ni mapeados em memória.
Para demonstrar a utilidade do simulador, o benchmark SPLASH-2 foi executado sobre uma instância 7x7 do NePA, avaliando a potência média dissipada para diferentes mapeamentos.
MPSoCs baseados em NoC.
Ele é baseado na ferramenta NoCWizard, a qual permite a geração de NoCs (Verilog RTL) a partir de a especificação de diversos parâmetros como topologia, controle de fluxo, modo de chaveamento e algoritmo de roteamento.
O ambiente possui uma biblioteca de IPs contendo diferentes processadores e aceleradores, o que possibilita a geração de MPSoCs heterogêneos.
O sistema é todo descrito num arquivo XML (características da NoC, IPs e mapeamento) que é utilizado como entrada para as ferramentas de geração automatizada.
Além de a infraestrutura de hardware, xENoC inclui também uma biblioteca para troca de mensagens e sincronização entre tarefas chamada ocMPI (on- chip MPI).
Essa biblioteca é uma versão embarcada do padrão MPI e é independente de sistema operacional.
As primitivas MPI suportadas são listadas na Figura 6.
Dependendo dos requisitos da aplicação, apenas um subconjunto das primitivas precisa ser incluído.
A quantidade de memória necessária para armazenar a biblioteca pode variar de 4942 bytes (primitivas básicas) à 13258 bytes (conjunto completo).
Visto que a NoC gerada suporta apenas transmissões unicast, serviços de comunicação coletiva como broadcast 2x2 da plataforma reportam speed-ups próximos do número de processadores, para aplicações com alto grau de independência de dados.
Em é apresentado um fluxo integrado automatizado para a geração de MPSoCs voltados para FPGAs.
A arquitetura é baseada em processadores Silicon Hive e na NoC Aethereal.
O MPSoC é descrito num arquivo de especificação do sistema, o qual serve como entrada para o fluxo.
A o final, é gerada uma descrição VHDL RTL do sistema e modelos de simulação para cada um dos seus componentes.
A Figura 7 mostra um trecho do arquivo de especificação juntamente com a arquitetura correspondente.
O host (Figura 7) atua como mestre do sistema, podendo ser um computador ou um processador embarcado.
Além de depuração do sistema, ele tem como principais funções carregar os códigos objetos das tarefas nas memórias locais dos processadores e configurar a NoC através do estabelecimento das conexões entre IPs comunicantes.
O serviço de comunicação baseado em conexões implementado por a Aethereal permite a especificação dos parâmetros da conexão (e.
g largura de banda e latência máxima) em tempo de projeto.
Visto que o host é responsável por o estabelecimento das conexões, estas são transparentes aos IPs.
A comunicação é realizada através de interfaces de entrada/ saída mapeadas em memória.
Para a validação do fluxo, dois sistemas foram gerados.
O primeiro consistindo de três processadores (sendo um o host) conectados a um único roteador executando uma aplicação produtor/ consumidor.
O segundo tem como host um computador e a arquitetura é semelhante a da Figura 7, utilizando alguns recursos da placa de prototipação como memória e dispositivos de áudio/ vídeo.
Para o segundo sistema, várias topologias de rede foram utilizadas, desde um único roteador até uma malha 2x2.
Também apresenta um fluxo de projeto de MPSoCs baseados em NoCs voltado para FPGAs.
Inicialmente é gerada a NoC utilizando a ferramenta NoC Generator.
Essa ferramenta permite a geração de NoCs vazão garantida através da multiplexação espacial dos enlaces (SDM ­ Spatial Division Multiplexing).
Uma vez gerada a NoC, PEs baseados no processador microblaze são conectados às interfaces de rede através de portas FSL (Fast Simplex Link), concluindo assim a geração da infraestrutura de hardware do MPSoC.
A comunicação entre PEs é baseada em conexões, as quais são estabelecidas por um PE que controla a comunicação do MPSoC.
As configurações das conexões são geradas em tempo de projeto por a ferramenta NoC Generator e dependem dos requisitos de comunicação das aplicações a serem executadas.
O PE de controle armazena estas configurações e estabelece as conexões antes das aplicações iniciarem a execução.
Experimentos realizados sobre uma instância 3x3 da plataforma avaliam apenas os tempos para o estabelecimento de conexões, os quais os autores afirmam ser muito baixos.
Entretanto, o tempo para o estabelecimento de uma conexão entre dois PEs se mostra alto quando comparado à plataforma HeMPS leva em torno de 500 ciclos de clock.
Em é apresentada uma metodologia que auxilia o projetista na construção de MPSoCs baseados em NoCs, desenvolvimento de aplicações e análise de desempenho.
Os PEs são criados utilizando a ferramenta SOPC builder da Altera, a qual permite a seleção de diversos periféricos em torno de o processador NIOS II.
A NoC utilizada com infraestrutura de comunicação entre os PEs é criada a partir de a ferramenta NoCMaker, a qual oferece ainda um ambiente de simulação onde é possível avaliar desempenho, consumo de energia e área.
Como estudo de caso foi criado um MPSoC composto por quinze PEs escravos e um mestre interconectados por uma malha bidimensional.
O PE mestre tem acesso exclusivo a 16 MB de memória SDRAM fora de chip e é responsável por orquestrar o trabalho dos PEs escravos.
A NoC utilizada implementa chaveamento por pacotes (wormhole) e controle de fluxo handshake, e oferece apenas o serviço básico de troca de mensagens.
Para troca de mensagens entre tarefas é utilizada a biblioteca ocMPI.
A escalabilidade da plataforma foi avaliada utilizando duas aplicações;
Multiplicação de matrizes e detector de círculos.
O detector de círculos apresentou um ganho de desempenho linear juntamente com aumento o número de processadores, enquanto a multiplicação de matrizes apresentou ganhos até 7 processadores.
Em a Tese de Murilo a NoC xpipes foi modificada a fim de oferecer serviços de comunicação baseados em prioridades e conexão.
Um mecanismo de prioridades foi implementado no árbitro do roteador (centralizado) e tem como objetivo definir a ordem em a qual são servidas as requisições vindas das portas de entrada.
Quando duas ou mais portas de entrada requisitam uma mesma porta de saída, o árbitro serve primeiro aquela que contém o pacote com maior prioridade.
A prioridade de um pacote pode variar de 0 à 7 (mais alta) e é inserida no seu cabeçalho.
Essa abordagem oferece baixas garantias visto que as prioridades são verificadas apenas quando há requisições simultâneas para uma mesma porta de saída.
O atendimento do árbitro está mais diretamente relacionado com a ordem das requisições, sendo as prioridades na realidade um mecanismo de desempate.
O suporte à conexões físicas é baseado num mecanismo de chaveamento por circuito implementado sobre chaveamento por pacotes.
O estabelecimento de uma conexão é feito a partir de um pacote de abertura de conexão que é enviado da origem ao destino.
O pacote de abertura de conexão reserva toda a largura de banda do caminho percorrido por toda duração da comunicação.
Conexões podem ser unidirecionais ou bidirecionais.
A conexão é desfeita por um pacote de fechamento de conexão enviado por a origem, o qual desaloca os recursos da rede à medida que vai sendo transmitido por a conexão.
Uma API foi desenvolvida para integrar os dois novos serviços de comunicação da rede no nível de software e permitir às aplicações explorarem QoS.
Ela interage diretamente com a interface de rede, a qual é responsável por definir a prioridade no cabeçalho dos pacotes e gerenciar abertura/ fechamento de conexões.
A Figura 8 lista as serviços de comunicação baseado em prioridades ou conexão.
Sobre tais primitivas foi adicionada uma implementação da API OpenMP especialmente voltada para MPSoCs.
Em essa abordagem o programador não acessa diretamente as primitivas de QoS, as quais são chamadas por a implementação do OpenMP.
A eficiente exploração de QoS depende das ferramentas de suporte que geram código a partir de a descrição das aplicações utilizando o OpenMP.
A Figura 9 ilustra o modelo da plataforma virtual com arquitetura de memória compartilhada criada utilizando o ambiente de simulação MPARM.
O MPARM possibilita a simulação de sistemas descritos em SystemC (com precisão de ciclo), os quais são criados a partir de uma livre combinação de PEs, memórias e infraestruturas de comunicação.
O PE é composto por um ISS (Instruction Set Simulator) ARM, cache L1 e alguns periféricos como controlador de interrupções e UART.
Em termos de infraestrutura de comunicação, o ambiente oferece barramentos, crossbars e NoCs.
Como sistema operacional, são suportados o RTEMS e uma versão reduzida do µClinux.
Uma instância 3x8 da plataforma contendo 8 PEs e dois bancos de memória compartilhada foi avaliada utilizando variações do Repository).
A partir de diversos experimentos observou- se uma redução de até 66% no tempo de execução em relação a a implementação tradicional do OpenMP, graças a o suporte a prioridades.
Este trabalho propõe uma interface para troca de mensagens em MPSoCs baseados em NoCs chamada de MMPI (Multiprocessor Message Passing Interface).
Tal interface é compatível com o padrão MPI no nível de código fonte e seu objetivo é melhorar a eficiência da exploração do espaço de projeto em termos de mapeamento de aplicações.
Um arquivo de mapeamento armazena a localização das tarefas no sistema e código fonte das aplicações em relação a o mapeamento de suas tarefas.
Diferentes alternativas de mapeamento podem ser avaliadas alterando- se apenas o arquivo de mapeamento, entretanto somente mapeamento estático é suportado.
A Figura 10 mostra a plataforma em a qual a interface foi implementada e a arquitetura do PE.
A implementação de tal plataforma é baseada no ambiente de simulação M5, o qual oferece modelos de hardware para criação e simulação de sistemas.
Como no caso de a biblioteca ocMPI oferecida por o ambiente xENoC, padrões e comunicação mais complexos são memória necessária para suportar a implementação mínima da MMPI é 11 KB, podendo variar de acordo com número de funções requisitadas.
A Tabela 1 apresenta um quadro comparativo listando algumas características de cada um dos trabalhos revisados.
A última linha da Tabela apresenta características do trabalho aqui proposto.
Uma característica comum em sistemas baseados em NoC é a utilização da topologia malha, cuja principal característica está relacionada à capacidade de adequarse a aplicações que podem ser particionadas em várias tarefas (e.
g operações com matrizes e processamento de imagens).
Além de ser quase um consenso, a regularidade apresentada por esta topologia é bastante adequada para a construção de arquiteturas homogêneas, enquanto topologias irregulares (personalizadas) são tipicamente empregadas em arquiteturas heterogêneas projetadas para aplicações específicas.
A natureza inerentemente distribuída das NoCs favorece também o modelo de programação baseado em troca de mensagens, uma vez que qualquer comunicação entre IPs é realizada através de pacotes transmitidos de um ponto a outro da rede.
Em a realidade qualquer infraestrutura de comunicação realiza troca de mensagens entre os IPs conectados a ela.
Mesmo em arquiteturas de memória compartilhada distribuída (Em uma) que implementem um modelo de programação baseado em memória compartilhada, a comunicação implícita é convertida em mensagens trocadas entre IPs e módulos de memória distribuídos.
O custo dessa conversão é o preço pago por a expressão implícita do paralelismo na implementação das aplicações e por a abstração da memória distribuída, ambas as facilidades oferecidas por o modelo de programação de memória compartilhada.
Além de o mais, aplicações paralelas são tipicamente modeladas a partir de grafos que explicitam a comunicação (e.
g CTG-Communication Task Graph e SDF--Synchronous Data Flow), onde os vértices representam tarefas e as arestas representam troca de mensagens.
Observa- se que a maioria dos trabalhos revisados está num estágio inicial na integração entre MPSoCs e NoCs, como poder evidenciado principalmente no projeto Terascale, NePA, e, os quais não oferecem nem mesmo uma API de comunicação básica implementada em alto nível.
No geral as Apis comumente implementam apenas o serviço básico de comunicação composto por envio e recepção de mensagens (troca de mensagens), oferecendo pouco ou nenhum controle sobre os recursos da rede.
Padrões de comunicação mais complexos são ordinariamente implementados em software a partir de o serviço básico como em xENoC, e.
De a mesma maneira, poucas das NoCs empregadas implementam serviços de comunicação com capacidade de oferecer algum tipo de garantia às aplicações além de a entrega das mensagens.
O desenvolvimento conjunto entre os serviços de comunicação das NoCs e o suporte em software a estes é uma área estratégica fundamental para a evolução dos MPSoCs e foco dessa Tese.
A seguir são listados os serviços de comunicação abordados nesse trabalho relacionando- os com o estado da arte.
Prioridades o:
Implementado no roteador como um mecanismo de desempate entre requisições simultâneas para uma mesma porta de saída;
Conexão o Tile64:
Implementa conexão lógica a partir de a alocação de buffers no PE destino;
Roteamento diferenciado o Até o presente momento, nenhum trabalho revisado implementa tal serviço, sendo este, no conhecimento do autor, proposto pela primeira vez em e tratado nesta Tese.
O MPSoC GENESYS[ OBE10] permite a criação de plataformas para diversos domínios de aplicação (e.
g aviação e automotivo) a partir de uma infraestrutura que oferece um conjunto de serviços básicos.
Esses serviços são de 4 tipos:
Sincronização; Comunicação;
Configuração e controle de execução.
Sobre estes, serviços de mais alto nível são implementados por os IPs que compõem o sistema e personalizam a plataforma para um determinado domínio de aplicação.
A definição dos serviços básicos originou- se a partir de discussões com indústrias de diferentes domínios de aplicação.
O conjunto de serviços básicos é mantido mínimo, incluindo apenas aqueles considerados fundamentais para suportar domínios específicos de aplicações.
A Figura 11 ilustra a estrutura dos serviços.
Em o centro da figura estão os serviços básicos (core services), para os quais existem diferentes opções de implementação.
Por exemplo, os serviços de comunicação podem ser implementado por uma NoC ou um barramento.
Acima de os serviços básicos pode- se observar um refinamento destes a fim de tornar- los cada vez mais específicos, dependendo da aplicação alvo.
Um protótipo do GENESYS foi implementado utilizando um FPGA Stratix III para executar o simulador automotivo TORCS.
Os resultados mostram a adequação do MPSoC para a implementação de sistemas com rígidas restrições de latência e largura de banda.
Este trabalho apresenta uma abordagem para acessar os serviços da Spidergon STNoC a partir de o nível de software.
A abordagem é baseada numa camada de drivers sobre o hardware e uma biblioteca de funções (libstnoc) que implementa a API.
A Spidergon STNoC oferece serviços relativos a gerenciamento de energia, roteamento, segurança e QoS.
Tais serviços são acessíveis em tempo de execução e expostos ao nível de software através de registradores mapeados em memória.
A Figura 12 ilustra a organização das camadas de software que compõem a abordagem.
Através da ferramenta gráfica iNoC é possível gerar diferentes instâncias da Spidergon STNoC (descrição RTL) juntamente dos drivers (Linux), os quais podem ser inseridos no kernel ou compilados separadamente como módulos.
Como estudo de caso foi utilizada a plataforma heterogênea Morpheus executando uma aplicação de detecção de movimentos em vídeo vigilância.
A Figura 13 ilustra a arquitetura da plataforma.
O processador ARM é o supervisor do sistema e configura comunicação entre os demais recursos computacionais através da libstnoc.
Fig. 2: The components of our software solution.
QoS services.
Te o aid the system designer in easy employment of Spidergon STNoC based systems a GUI tool is available.
Routers and network interfaces are represented as icons and the links between them can be edited graphically 6:!
Te o develop s which are an extension of node is connected to the node NoC and Ni services can!
Be set.
Memory&amp; 8473!
Addresses ht, and across links, Spidergon of the programmable registers inside each network interface er aylink $= leading to hierarchical can also be set.
Morpheus Fig.. Morpheus communication ion generate scripts, verification environments, and docue is used to encode four states:
In this work we leverage this plug-in support, to extend Id field any Spidergon STNoC system;
This allows to blend Este trabalho apresenta uma interface de rede que oferece serviços garantidos e Be através de conexões.
A Ni oferece os serviços no nível de transporte do modelo de referência Iso-OSI devido a este ser o primeiro nível onde os serviços oferecidos são independentes da implementação da rede.
Toda a complexidade da gerência dos serviços está implementada na Ni, simplificando a NoC.
Em tempo de projeto alguns parâmetros podem ser configurados como número de portas, tipo das portas (mestre ou escravo), número de conexões por portas e nível de serviço das portas.
As conexões são unidirecionais com as garantias configuráveis, podendo ser unicast ou multicast.
Elas são baseadas em TDM (Time Division Multiplexing), permitindo o compartilhamento de um mesmo enlace por diferentes conexões.
Um IP central chamado de módulo de configuração é responsável por configurar todas as conexões de uma determinada aplicação antes desta iniciar sua execução.
As interfaces de rede origem e destino de uma conexão são configuradas remotamente por o módulo de configuração.
Ele oferece um controle global sobre o estado das conexões e a disponibilidade de enlaces no sistema.
No entanto, tal abordagem eleva o tempo para o estabelecimento de uma conexão, além de poder comprometer a escalabilidade do sistema.
Este trabalho apresenta uma interface de rede que suporta um serviço de comunicação baseado em prioridades.
O objetivo é oferecer diferentes níveis de QoS a fim de atingir os requisitos de aplicações de tempo real.
A Figura 14 ilustra a arquitetura da interface de rede.
Os dados gerados por o IP são injetados numa das três portas bidirecionais.
Cada porta corresponde a um nível de prioridade e tem uma fila associada (queue) que armazena os dados oriundos do IP.
Baseado nas prioridades das portas, o módulo scheduler seleciona uma das filas para injetar os pacotes na rede.
As prioridades e a política de escalonamento podem ser definidas por o usuário.
Os módulos flit/ packet builder e flit/ packet stripper são responsáveis, respectivamente, por o empacotamento e desempacotamento dos dados.
O módulo credit controller é responsável por o controle de fluxo fim-a-fim.
Essa interface de rede implementa na realidade um controle de acesso ao meio físico, visto que o serviço de prioridades oferecido se mostra independente da implementação arquitetura de interconexão.
O MPSoCs SpiNNaker implementa um controle de admissão adaptativo com o propósito de proporcionar um serviço de comunicação com garantias sobre uma infraestrutura de comunicação assíncrona chamada CHAIN (Chip Area INterconnect).
Tal controle de admissão garante limites de latência no acesso a uma memória SDRAM externa e é implementado localmente em cada um dos IPs do sistema, regulando dinamicamente a taxa de injeção.
A ideia é manter a CHAIN operando abaixo de o ponto de saturação, pois assim a largura de banda agregada tende a ser igualmente compartilhada por os IPs.
O controle de admissão é baseado num convencional laço de realimentação fechado.
A referência do laço indica a latência máxima para obter- se uma resposta da SDRAM e a saída é a taxa de injeção.
Resultados obtidos num cenário com 5 IPs acessando uma SDRAM mostram uma redução da latência média e máxima de 28% e 47,5%, respectivamente, utilizando o controle de admissão proposto.
Este trabalho descreve uma NoC dinamicamente reconfigurável proposta para MPSoCs adaptativos.
A particularidade dessa NoC é a capacidade alterar dinamicamente algumas de suas características juntamente com a mudança nos requisitos de comunicação das aplicações.
Sua inteligência está implementada na pilha de protocolos chamada de Smart Network Stack (SNS), a qual toma decisões sobre roteamento, modo de chaveamento e tamanho de pacote, dependendo dos dados a serem enviados.
As novas características da NoC são incluídas no cabeçalho dos pacotes e processados por os roteadores.
Alguns experimentos foram conduzidos sobre uma topologia torus 4x4 utilizando o simulador de redes Ns-2.
Entretanto, por a falta de resultados comparativos com uma versão da NoC que não implementa a SNS, os resultados obtidos não deixam claro os ganhos da NoC proposta.
O CoMPSoC explora o serviço de comunicação baseado em conexões da NoC Aethereal com o intuito de evitar a interferência entre os fluxos das aplicações que executam simultaneamente sobre a plataforma.
O grau de independência do desempenho de uma aplicação, independente da presença ou ausência de outras aplicações na plataforma é chamado de composability.
Essa propriedade visa garantir que os requisitos das aplicações são atingidos em diferentes cenários.
Diferente de arquiteturas Be, o fluxo de projeto do CoMPSoC tem um papel relevante no que diz respeito a composability, movendo a complexidade da alocação de recursos em tempo de execução para os tempos de projeto e compilação.
Isto impõem restrições que não permitem ao CoMPSoC carregar aplicações dinamicamente, limitando- o a criação de sistemas estaticamente alocados.
Como estudo de caso, um decodificador JPEG e um processador de áudio são executados sobre uma instância da plataforma em FPGA composta por três processadores, um codificador de áudio e um controlador de vídeo interconectados por a NoC Aethereal.
Os resultados mostram que ambas as aplicações atingem seus requisitos quando executam simultaneamente.
Entretanto, não há nenhuma comparação entre o desempenho das aplicações executando sozinhas na plataforma e juntas.
Tal comparação poderia evidenciar a efetividade do isolamento entre as aplicações.
Este trabalho apresenta uma abordagem dinâmica para garantir composability.
O trabalho propõe um gerenciador de recursos central que é responsável por controlar a interferência entre as aplicações, de maneira que elas consigam manter seus requisitos de desempenho.
O gerenciador de recursos monitora o desempenho das aplicações através de mensagens de controle oriundas destas.
Quando o gerenciador de recursos detecta que uma aplicação X está operando abaixo de o requisito devido a a interferência de uma aplicação Y, ele suspende a execução da aplicação Y até que a aplicação X recupere seu desempenho.
O tempo de reação do sistema depende da frequência das mensagens de controle enviadas por as aplicações.
Um balanço deve ser feito entre o tempo de reação e a carga do sistema, visto que uma alta frequência de mensagens resulta numa reação mais rápida ao custo da elevação do tráfego.
Um estudo de caso envolvendo um decodificador JPEG e um decodificador H263 foi desenvolvido sobre um modelo POOSL (Parallel Object-Oriented Specification Language) da plataforma.
Os resultados mostram que sem o gerenciador de recursos, o decodificador JPEG atinge uma vazão além de a mínima e o decodificador H263 fica com a vazão abaixo de a desejada.
Quando o gerenciador de recursos é empregado, ambas as aplicações atingem os requisitos mínimos de vazão, ainda que abaixo de a vazão atingida quando estas executam sozinhas na plataforma.
É importante ressaltar que os resultados obtidos a partir de o modelo POOSL não consideram a contenção na infraestrutura de comunicação, a qual pode ser considerada a principal fonte de interferências entre aplicações.
Os autores argumentam que a concorrência por os recursos computacionais já é suficiente para demonstrar a complexidade do problema.
A Tabela 2 apresenta um resumo das soluções investigadas para garantir os requisitos de desempenho das aplicações.
A última linha da Tabela resume a ideia do trabalho aqui proposto.
Em geral, observa- se soluções para oferecer garantias implementadas apenas no nível de hardware, sem o correspondente suporte no nível de software.
As soluções propostas são invisíveis do ponto de vista da aplicação e não dão ao projetista a possibilidade gerenciar os fluxos.
Alguns trabalhos nem mesmo suportam serviços de comunicação diferenciados no nível de interconexão e contornam esta deficiência através de abordagens como controle de admissão.
Outra abordagem observada e que vai na contramão do paradigma de sistemas multiprocessados é o gerenciamento centralizado da infraestrutura de comunicação, também observada em algumas propostas de MPSoCs baseados em NoCs.
Oferece uma infraestrutura de serviços básicos de 4 tipos (sincronização, comunicação, configuração e controle de execução), a partir de os quais serviços de mais alto nível são implementados a fim de personalizar a plataforma para um determinado domínio de aplicação.
Abordagem para expor os serviços da Spidergon STNoC (gerenciamento de energia, roteamento, segurança e QoS) no nível de software a partir de registradores mapeados em memória acessíveis através da biblioteca libstnoc.
Apresenta uma interface de rede que oferece serviços garantidos e Be através de conexões (TDM), as quais são estabelecidas por um IP central.
Apresenta uma interface de rede que oferece um serviço de comunicação baseado em prioridades a partir de diferentes portas.
Cada porta corresponde a uma prioridade e tem uma fila associada.
Propõe um controle de admissão de tráfego adaptativo, a fim de manter a SpiNNaker infraestrutura de comunicação operando abaixo de o ponto de saturação.
O controle é distribuído e baseado num laço de realimentação fechado que regula a taxa de injeção dos IPs.
Descreve uma NoC que altera dinamicamente algumas de suas características (roteamento, modo de chaveamento e tamanho de pacote) a fim de adaptar- se a mudanças nos requisitos de comunicação das aplicações.
Explora o serviço de comunicação baseado em conexões da NoC Aethereal CoMPSoC com o intuito de garantir a independência do desempenho de aplicações que executam simultaneamente sobre a plataforma (Composability).
Propõe um gerenciador central de recursos que controla a interferência entre aplicações que executam simultaneamente sobre a plataforma.
Oferece uma API de alto nível para controlar dinamicamente o compartilhamento do barramento entre IPs.
Desenvolvimento Esta Tese de serviços de comunicação partir da implementação de mecanismos específicos no nível da NoC e o suporte a estes em software através de uma API de comunicação de alto nível.
Este Capítulo descreve o MPSoC acadêmico HeMPS, o qual serve de base para a realização do presente trabalho e diversos outros dentro de o grupo de pesquisa GAPH.
Todos os serviços de comunicação diferenciados propostos foram implementados e avaliados sobre essa plataforma.
Ela pode ser dividia em três partes principais;
Infraestrutura de hardware (arquitetura), (ii) microkernel (middleware) e (iii) aplicações (software).
Cada uma dessas partes será descrita em três seções distintas.
A seção 3.4 encerra o capítulo apresentando as camadas que compõem o sistema.
Infraestrutura de hardware HeMPS (Hermes Multiprocessor System) é um MPSoC homogêneo baseado no processador Plasma e na NoC Hermes.
Instâncias deste MPSoC são criadas a partir de a interconexão de Plasma-IPs (PEs) através da NoC Hermes (infraestrutura de comunicação).
Além de os componentes de computação e comunicação, há também uma memória externa chamada repositório de tarefas (Task Repository), a qual armazena as tarefas das aplicações a serem executadas.
A Figura 17 ilustra uma instância 2x3 do MPSoC mostrando seus principais componentes de hardware.
A seguir estes são descritos nas subseções seguintes.
Os Plasma-IPs são os PEs do sistema e podem ser de dois tipos;
Mestre (Plasma-IP MP), responsável por o gerenciamento dos recursos de computação e (ii) escravo (Plasma-IP SL), realiza a computação das aplicações.
A gerência dos recursos de computação (Plasma-IP SL) é centralizada, realizada por um único Plasma-IP MP, o qual não computa aplicações.
O Plasma-IP é constituído por os seguintes componentes:
Processador Plasma:
Processador RISC de 32 bits que implementa um subconjunto de instruções da arquitetura MIPS.
Diferentemente do MIPS original, o Plasma apresenta uma organização de memória Von Neumann.
O processador oferece ainda suporte à linguagem C através do compilador gcc;
Memória privada (RAM):
Armazena o microkernel executado por o processador Plasma.
No caso de o Plasma-IP SL, além de o microkernel, a memória armazena também tarefas das aplicações;
Interface de rede (Network Interface):
Realiza a interface entre o Plasma e a NoC Hermes.
É responsável por o envio e recebimento de pacotes na rede;
DMA (Direct Memory Access):
Desenvolvido para auxiliar o Plasma na troca de mensagens, possibilitando ao processador continuar a computação enquanto o DMA recebe/ transmite pacotes;
Para atingir alto desempenho nos PEs, a arquitetura do Plasma-IP visa a separação entre computação e comunicação.
A interface de rede e o DMA são responsáveis por enviar e receber pacotes (comunicação) enquanto o processador Plasma executa as tarefas (computação).
A memória local (scratch pad) é uma RAM dupla porta que permite acesso simultâneo por o processador e por o DMA.
A NoC Hermes emprega uma topologia malha 2 D, chaveamento por pacotes (wormhole) e controle de fluxo baseado em crédito.
Os roteadores têm buffers de entrada, uma lógica de controle (Switch Control ­ arbitragem e roteamento) compartilhada por todas as portas, um crossbar interno e até cinco portas bidirecionais (norte, sul, leste, oeste e local).
A Figura 18 ilustra uma instância 3x3 da NoC Hermes juntamente da arquitetura interna do roteador.
A porta local estabelece a comunicação entre o roteador e seu IP, sendo as demais portas utilizadas para conectar o roteador aos roteadores vizinhos.
A arbitragem das requisições oriundas das portas de entrada é realizada utilizando escalonamento round-robin e os pacotes são roteados utilizando o algoritmo de roteamento XY.
As aplicações que executam sobre a plataforma são particionadas em diversas tarefas que se comunicam através de troca de mensagens.
O repositório de tarefas é uma memória externa ao MPSoC, de grande capacidade em relação a as memórias privadas, a qual armazena o código-objeto das tarefas que executarão no sistema.
O Plasma-IP MP é o único a ter acesso ao repositório de tarefas (conexão direta) e é responsável por mapear e alocar as tarefas em Os SL.
Um conjunto inicial de aplicações é armazenado no repositório em tempo de projeto, no momento da geração da plataforma.
Durante a execução do sistema essa memória opera como uma memória ROM, sob o ponto de vista do MPSoC (Plasma-IP MP), podendo entretanto receber novas aplicações dinamicamente, em tempo de execução, através de um host externo.
Microkernel Cada processador escravo executa um microkernel que suporta a execução de múltiplas tarefas e a comunicação entre estas.
A memória local do Plasma-IP SL é dividida em páginas (tamanho fixo e iguais), de as quais as primeiras são alocadas por o microkernel e as demais por as tarefas (uma por página).
O escalonamento de tarefas implementado é o round-robin sem prioridades.
O microkernel possui uma tabela de tarefas com a localização de todas as tarefas alocadas no sistema (locais e remotas).
As páginas são protegidas por o microkernel e toda comunicação entre tarefas é realizada através de troca de mensagens.
A comunicação é suportada através de um pipe comunicação da plataforma HeMPS.
Tal pipe é implementado como um vetor na área de memória do microkernel, o qual armazena mensagens enviadas por as tarefas locais.
As primitivas de comunicação são implementadas por o microkernel e invocadas por as tarefas através de chamadas de sistemas.
Essa abordagem mantém o sistema estruturado em camadas (Seção 3.4), impossibilitando às aplicações o acesso direto à infraestrutura de comunicação.
O modelo de computação que garante a sincronização entre tarefas é baseado em redes de processos de Kahn (KPN -- Kahn Process Networks).
KPN é um modelo de computação distribuído onde canais de comunicação baseados em FIFOs infinitas (pipes) conectam os processos uns aos outros, formando uma rede.
Esse modelo se baseia no princípio fundamental de que a leitura do canal de comunicação deve ser bloqueante e a escrita deve ser não-bloqueante.
O protocolo de comunicação adotado é o read request, o qual garante o controle de fluxo fim-a-fim e o ordenamento de mensagens.
Quando uma tarefa qualquer a mensagem pode ser lida do pipe local (comunicação local) ou de um pipe remoto (comunicação remota).
Se as tarefas comunicantes estão alocadas no mesmo PE, a mensagem é lida do pipe local.
Caso contrário, o microkernel envia uma requisição de mensagem para o PE onde a mensagem está armazenada, a tarefa entra em estado de espera (wait) e uma nova tarefa é escalonada.
Quando a mensagem requisitada é recebida, o microkernel a armazena na página da tarefa destino e muda seu estado para pronta (ready).
A Figura 19 ilustra a comunicação remota entre tarefas.
Em a Figura 19 (a) é assumido que a tarefa t2 armazenou uma mensagem no pipe (global_ pipe) endereçada à tarefa t5 (Send(&amp; msg, t5), a qual requisita uma mensagem à tarefa t2 (Receive(&amp; msg, t2).
Em a Figura 19 (b) a mensagem requisitada (msg) é transmitida e armazenada na página da tarefa t5.
O microkernel garante o ordenamento das mensagens numerando- as à medida localização da tarefa destino/ origem da mensagem.
É tarefa do microkernel obter a localização das tarefa (tabela de tarefas) durante o processamento das primitivas de comunicação.
Essa abordagem permite que o código das aplicações seja independente do mapeamento.
Processor 1 Send(&amp; msg, t5);
Processor 1 Processor 2 t3 t6 t2 t5 Receive(&amp; msg, t2);
Send(&amp; msg, t5);
T4 global_ pipe microkernel microkernel request_ msg (a) Processor 2 t3 t6 t2 t5 Receive(&amp; msg, t2);
Esse microkernel foi desenvolvido especialmente para a plataforma HeMPS a partir de o sistema operacional disponível na distribuição do processador Plasma.
Ele é praticamente todo escrito na linguagem C, tendo apenas o chaveamento de contexto e a inicialização do segmento de dados globais e estáticos(.
Bss) escritos em assembly.
Suas principais funcionalidades são o suporte a multitarefa, a API de comunicação e o tratamento de interrupções (hardware/ software), o que resulta um tamanho reduzido de aproximadamente 15 KB, típico de sistemas embarcados.
Aplicações As aplicações paralelas desenvolvidas para a plataforma HeMPS são particionadas em tarefas descritas em linguagem C. Cada tarefa tem sua própria função representadas a partir de grafos dirigidos onde os vértices representam as tarefas e as arestas representam o fluxo de dados.
A Figura 20 ilustra duas aplicações de processamento de vídeo representadas a partir de grafos.
Em este exemplo, os vértices dos grafos estão assinalados com a quantidades de dados transferidos entre tarefas em MB/ s.
Decoder; (b) Multi--Window Displayer.
Várias aplicações reais têm sido desenvolvidas para a plataforma HeMPS como decodificadores JPEG, MJPEG e ADPCM, multiplicador de matrizes e resolvedor de equações.
Além disso, uma abordagem comum é a modelagem de aplicações a partir de traces de execução e grafos como os da Figura 20.
Em essa abordagem cada tarefa é tipicamente descrita como um laço contendo a sequência recepção, tempo de processamento e envio de dados.
Aplicações que executam em MPSoCs possuem muitas vezes uma carga dinâmica, onde as tarefas que as compõem são alocadas sob demanda.
Isso implica um número variável de tarefas executando simultaneamente, o qual pode exceder a capacidade dos recursos de processamento disponíveis.
Para lidar com esta questão, a plataforma HeMPS suporta carga de trabalho dinâmica, onde somente um subconjunto de tarefas é inicialmente alocado no sistema (mapeamento estático).
As demais tarefas são armazenadas no repositório e alocadas sob demanda (mapeamento dinâmico).
A carga de trabalho dinâmica ocorre através da alocação de tarefas sob demanda durante a execução das aplicações.
O desenvolvedor de uma aplicação define o subconjunto de tarefas necessário para o início da execução.
Tipicamente aquelas que iniciam o fluxo e dados).
O evento que dispara a alocação mensagem está alocada no sistema.
Se a tarefa está alocada, a mensagem é armazenada no pipe.
Caso contrário, o microkernel primeiro envia ao processador mestre uma requisição de tarefa e em seguida armazena a mensagem no pipe.
Esse processo é transparente ao nível de tarefa e é ilustrado na Figura 21.
Task layer Microkernel layer Yes Is ti allocated?
A o receber uma mensagem de requisição de tarefa, o processador mestre procura a tarefa no repositório e a transmite a um processador escravo que tenha uma página disponível.
Concluída a transmissão, o processador mestre notifica todos os escravos sobre a localização da nova tarefa alocada.
A plataforma HeMPS suporta dois tipos de mapeamento;
Estático e dinâmico.
O mapeamento estático é realizado em tempo de projeto, onde é definido em qual PE uma determinada tarefa deve ser executada.
Todas as tarefas de uma aplicação podem ser mapeadas estaticamente ou apenas um subconjunto destas, sendo as demais mapeadas dinamicamente por o processador mestre.
O mapeamento dinâmico é caracterizado por a carga de trabalho dinâmica.
O algoritmo utilizado para selecionar o PE onde uma nova tarefa deve ser alocada é baseado na heurística LEC-DN (Low Energy Consumption ­ Dependences Neighborhood).
Essa heurística tem como principal objetivo a redução na energia de comunicação.
O PE selecionado por o algoritmo é o mais próximo (em número de hops) dos PEs onde já estão alocadas tarefas com as quais a nova tarefa deve se comunicar.
Para resolver esse problema, uma das possibilidades é a utilização da técnica de migração de tarefas (fora de o escopo da presente Tese).
Essa técnica se faria útil para aproximar tarefas comunicantes, migrando uma tarefa que se comunica com outra de um PE distante para um mais próximo.
Entretanto, sua eficiência depende de PEs disponíveis que habilitem uma redistribuição de tarefas.
Caso o sistema esteja fragmentado e com praticamente todos os PEs alocados, essa técnica não induz a melhora de desempenho desejada.
Por outro lado, as colisões entre fluxos de diferentes aplicações, devido a a fragmentação do sistema, podem ser minimizadas a partir de serviços de comunicação que ofereçam algum tipo de garantia.
Tais serviços possibilitam a reserva de recursos de comunicação à aplicações com requisitos de desempenho, deixando os demais recursos livres para serem compartilhados entre as outras aplicações.
De essa maneira, mesmo que as tarefas comunicantes estejam dispersas na plataforma, o fluxo de dados se mantém contínuo, evitando o aumento da latência devido a a bloqueios oriundos de regiões congestionadas.
Camadas do sistema Tipicamente sistemas computacionais são divididos em camadas com diferentes níveis de abstração a fim de gerenciar sua complexidade.
Cada camada tem uma funcionalidade específica e se comunica com as camadas adjacentes.
De essa maneira, cada camada se serve dos serviços oferecidos por as camadas inferiores e fornece serviços às camadas superiores.
A Figura 23 ilustra as diferentes camadas que compõem a plataforma HeMPS e as entidades correspondentes.
Notar que as camadas Task, Os e Transport são replicadas nas várias instâncias do Plasma-IP.
A seguir são descritas cada uma das camadas.
Camada de aplicação (Applications):
Contém as aplicações a serem mapeadas no sistema.
Cada aplicação é representa por um grafo dirigido podendo ter suas tarefas distribuídas em vários PEs;
Camada de tarefa (Task):
Contém a descrição das aplicações a partir de tarefas que se comunicam usando as primitivas implementadas por a API;
Camada de sistema (Os):
É composta por um conjunto de drivers responsáveis por o carregamento de tarefas, gerenciamento da memória local e empacotamento/ desempacotamento de mensagens.
Além disso, escalonamento de tarefas (round-robin) e implementa a API;
Camada de transporte (Transport):
Executa a injeção/ recepção de pacotes e controle de fluxo;
Camada de rede (Network):
Responsável por a transmissão de pacotes sem perda de dados.
O MPSoC HeMPS segue claramente a tendência dos futuros sistemas embarcados multiprocessados, apresentando uma arquitetura estruturada e suporte básico em software para o desenvolvimento de aplicações paralelas.
Esse sistema será utilizado como base para a implementação dos serviços de comunicação diferenciados propostos nessa Tese.
A implementação de tais serviços segue uma abordagem bottom-up, partindo- se da implementação de mecanismos específicos no nível de rede e criando suporte a estes até o nível de software.
Uma vez revisada uma série de trabalhos relacionados, posicionando a presente Tese em relação a o estado da arte (Capítulo 2), e apresentada a arquitetura do MPSoC de referência (Capítulo 3), este Capítulo apresenta a primeira contribuição desta Tese, a qual compreende os serviços de comunicação baseados em prioridades e conexões.
Tais serviços foram implementados e avaliados sobre as plataformas HeMPS e Hs-Scale.
A plataforma HeMPS é a plataforma alvo deste trabalho, no entanto, a utilização da plataforma Hs-Scale neste Capítulo deve- se ao período de doutorado sanduíche realizado no laboratório LIRMM (Montpellier/ França), durante o qual esses serviços vinham sendo desenvolvidos.
Os serviços de comunicação implementados por as NoCs podem ser de dois tipos:
Melhor esforço (Be ­ Best-Effort) ou serviço garantido (Gs ­ Guaranteed Service).
Serviços de comunicação do tipo Be garantem a entrega de todos os pacotes entre um par origem/ destino, contudo não proporcionam nenhum tipo de garantia em relação a métricas de desempenho como vazão ou latência.
Esse tipo de serviço atribui a mesma prioridade a todos os pacotes, impossibilitando um tratamento diferenciado para fluxos de aplicações com algum tipo de restrição temporal.
O termo QoS refere- se à capacidade de uma rede de distinguir fluxos e tratar- los de maneira diferenciada, proporcionando diferentes níveis de qualidade.
Portanto, serviços de comunicação do tipo Be são inadequados para satisfazer requisitos de QoS de aplicações com rígidas restrições temporais.
Para atender a requisitos de desempenho, a rede comumente implementa mecanismos específicos em sua arquitetura.
Este Capítulo apresenta dois mecanismos que fornecem, respectivamente, suporte aos serviços de comunicação baseado em prioridades e conexões:
Alocação de recursos baseado em prioridades fixas e chaveamento por circuito.
O serviço de comunicação baseado em prioridades proporciona garantias flexíveis aos fluxos de aplicações onde certas variações no desempenho da comunicação não são relevantes.
Já o serviço de comunicação baseado em conexões proporciona garantias rígidas a partir de a reserva exclusiva de recursos da rede por todo o tempo da comunicação.
Conexões garantem uma comunicação fim-a-fim livre de qualquer tipo de interferência por parte de outras comunicações que ocorrem em paralelo na rede.
Tais serviços de comunicação proporcionam ao projetista acesso aos mecanismos que controlam a alocação de recursos da NoC.
A partir de serviços de comunicação que oferecem algum tipo de garantia pode- se explorar QoS a fim de evitar a interferência entre os fluxos de aplicações que executam simultaneamente sobre uma mesma plataforma, caracterizando composability no nível da rede.
Composability é uma propriedade que visa garantir a satisfação dos requisitos das aplicações independente das demais aplicações executando simultaneamente no sistema.
Visto que aplicações com diferentes requisitos de desempenho podem executar simultaneamente, composability deve ser garantida àquelas com restrições temporais (e.
g aplicações de tempo real).
Composability é frequentemente atingida em tempo de projeto ou através de políticas de escalonamento específicas em sistemas operacionais de tempo real.
Em a indústria automotiva e aeroespacial, por exemplo, composability é frequentemente atingida não compartilhando recursos (computação/ comunicação) entre as aplicações.
Em o presente trabalho, composability é atingida no nível da rede a partir de a exploração da QoS por meio de os serviços de comunicação propostos.
Entretanto, no nível de processamento, o compartilhamento dos PEs por diferentes tarefas pode acarretar interferência entre aplicações.
Para minimizar essa interferência e atingir composability também no nível de processamento, no final deste Capítulo é apresentado um escalonamento preemptivo com prioridades, o qual permite que tarefas pertencentes a aplicações com restrições temporais tenham acesso privilegiado ao processador.
Mecanismos de prioridades e chaveamento por circuito na NoC Hermes Originalmente a NoC Hermes emprega uma topologia malha bidimensional construída a partir de roteadores com até cinco portas bidirecionais.
Os roteadores localizados nas bordas da malha têm menos portas que aqueles localizados entre as bordas.
De as cinco possíveis portas, quatro (norte, sul, leste e oeste) são utilizadas para a conexão com roteadores vizinhos e uma (local) conecta o roteador ao IP.
Os roteadores possuem buffers de entrada para o armazenamento temporário de flits, um crossbar que conecta as portas de entrada às portas de saída e um módulo chamado de Switch Control, responsável por a arbitragem das portas de entrada, roteamento e controle do crossbar.
A principal modificação feita na arquitetura do roteador para suportar um serviço de comunicação baseado em prioridades foi a duplicação dos canais físicos (portas bidirecionais).
O roteador resultante suporta até dez portas bidirecionais.
A partir de essa nova arquitetura um mecanismo de prioridades pode ser usado na alocação dos canais físicos.
A Figura 24 ilustra a arquitetura do novo roteador.
Os dois canais físicos numa mesma direção são numerados de 0 a 1.
O mesmo vale para porta local.
A replicação dos canais físicos é uma abordagem que vem se popularizando recentemente.
Tal abordagem é empregada principalmente como uma alternativa a canais virtuais.
A implementação de ambas abordagens implica custos de área relacionados aos buffers de entrada e ao crossbar.
No entanto, a abordagem de canais virtuais necessita ainda um custo extra relativo à multiplexação dos canais físicos (TDM), o que torna seu custo total em área superior à replicação dos canais físicos, considerando o número de canais virtuais e físicos iguais.
Além disso, a largura de banda agregada do roteador é diretamente proporcional ao fator de replicação dos canais físicos, ao passo que o aumento do número de canais virtuais não altera a largura de banda.
A potência dissipada por ambas as abordagens é similar Canais virtuais foram introduzidos por Dally e Seitz, visando resolver o problema de deadlock em redes que implementam wormhole e não visando desempenho, apesar de contribuírem para uma melhor utilização dos canais físicos.
Essa abordagem é uma herança das redes de computadores, onde há uma limitação significativa no número de conexões que conectam dois elementos comunicantes.
Em esse caso a multiplexação do meio físico torna- se a alternativa mais adequada.
Por outro lado, dentro de um chip, a abundância de espaço disponível para conexões favorece a replicação dos canais físicos.
O mecanismo de prioridades implementado nesse roteador é baseado em prioridades fixas.
Duas classes de tráfego são distinguidas por a NoC:
Pacotes com prioridade alta e pacotes com prioridade baixa.
Um canal físico é reservado para transmitir exclusivamente pacotes com prioridade alta, ao passo que o outro canal pode transmitir pacotes com prioridade alta ou baixa.
O compartilhamento de um dos canais físicos entre as duas classes de tráfego aumenta o suporte da rede a pacotes com prioridade alta, pois possibilita a transmissão de dois fluxos de alta prioridade simultaneamente na mesma direção.
O mecanismo de prioridades oferece um serviço de comunicação diferenciado a tráfegos de alta prioridade através da reserva virtual de recursos (recursos em cinza escuro na Figura 24).
Todavia, quando mais de dois fluxos de alta prioridade competem por um mesmo caminho, a interferência entre eles nessa implementação é inevitável.
De fato, NoCs que empregam algum tipo de mecanismo de prioridades tendem a atuar como NoCs Be à medida que o tráfego de alta prioridade se intensifica.
Esse mecanismo explora a tolerância de algumas aplicações à variações modestas no desempenho da rede, onde a perda de alguns deadlines não é um problema (e.
g soft real time).
O serviço de comunicação baseado em conexões é suportado a partir de o modo de chaveamento por circuito.
Esse chaveamento coexiste juntamente com o chaveamento por pacotes, de maneira que a NoC Hermes suporta simultaneamente ambos os chaveamentos.
Uma conexão física é estabelecida entre um único par origem/ destino e os recursos da rede permanecem alocados durante todo o tempo da comunicação.
As conexões são unidirecionais e estabelecidas/ encerradas por a origem da comunicação através de pacotes de controle (dois flits).
Essa abordagem de chaveamento por circuito é a mais simples que pode ser implementada, considerando a arquitetura da NoC Hermes.
Ela exige alterações mínimas na arquitetura do roteador e apresenta um baixo custo em área.
Tal simplicidade deve- se ao fato de que o chaveamento por circuito foi implementado sobre o chaveamento por pacotes.
Em o chaveamento por pacotes, os flits de payload de um pacote comum seguem o caminho alocado por o flit de cabeçalho.
Esse caminho permanece alocado até o último flit de payload ser transmitido.
Em a abordagem de chaveamento por circuito implementada, o pacote de controle que estabelece uma conexão é o flit de cabeçalho de um pacote comum e as mensagens transmitidas por a conexão representam o payload desse pacote.
O pacote de controle que desaloca a conexão representa o último flit de payload de um pacote comum.
Toda a largura de banda do caminho entre origem e destino é alocada por a conexão, permitindo às aplicações atingir a máxima vazão possível sem qualquer tipo de interferência proveniente de outras comunicações.
Visto que a alocação total da largura de banda pode subutilizar os recursos quando a vazão das aplicações é baixa, conexões são restritas somente ao canal 0.
Assim o canal 1 está sempre disponível para transmitir pacotes usando chaveamento por pacotes.
As portas locais do roteador são utilizadas por o PE dependendo do serviço de comunicação.
A porta local 0 é utilizada por o serviço baseado em conexões enquanto a porta local 1 serve o serviço baseado em prioridades.
Pacotes injetados na NoC por a porta local 0 são transmitidos a partir de o modo de chaveamento por circuito, enquanto os pacotes injetados na porta local 1 são transmitidos utilizando chaveamento por pacotes.
Um PE pode manter uma conexão através da porta local 0, enquanto envia pacotes por a porta local 1 utilizando chaveamento por pacotes.
Visto que a porta local 0 permite a conexão entre apenas dois PEs, o objetivo dessa abordagem é possibilitar aos PEs conectados comunicarem- se com outros PEs utilizando chaveamento por pacotes através da porta local 1, mantendo a conexão estabelecida.
A NoC diferência os pacotes injetados a partir de campos específicos no cabeçalho.
Quando um pacote chega a um roteador, o módulo Switch Control (Figura 24) extrai informações do cabeçalho para executar o algoritmo de roteamento e a alocação/ desalocação dos canais físicos.
A Figura 25 ilustra a estrutura do pacote.
O primeiro flit é o cabeçalho do pacote e os demais que o seguem compõem o payload.
O último flit do pacote é sinalizado por um sinal chamado eop (end-of-- packet).
O flit de cabeçalho contém os seguintes campos:
Service (4 bits):
Tipo do pacote (e.
g estabelecimento/ encerramento de conexão e modo de chaveamento);
Unused (3 bits):
Bits não utilizados atualmente;
P: Prioridade do pacote;
Integração dos mecanismos no nível de software Ambos os mecanismos (alocação de recursos baseada em prioridades e chaveamento por circuito) foram integrados nas Apis de comunicação das plataformas HeMPS e Hs-Scale, dando origem aos serviços de comunicação baseados em prioridades e conexões.
Esses serviços de alto nível permitem o gerenciamento de recursos da NoC Hermes em software.
Em ambas as plataformas, o sistema operacional (microkernel) é responsável por a ligação entre a API (nível de tarefas) e os mecanismos da NoC (nível de rede).
Esta abordagem possibilita ao programador explorar QoS em alto nível a partir de o código fonte das tarefas que compõem as aplicações.
Ambas as plataformas dão suporte à programação em alto nível através da linguagem C. As Apis de comunicação das plataformas HeMPS e Hs-Scale implementam duas básico de troca de mensagens do tipo Be.
Para suportar os novos mecanismos suporte ao serviço de comunicação baseado em conexões.
Os protótipos das primitivas aparecem na Listagem 1.
O parâmetro target, presente nas primitivas, refere- se à tarefa destino.
A localização das tarefas (mapeamento) é transparente ao programador e é responsabilidade do sistema operacional localizar as tarefas baseado em tabelas de mapeamento.
Essa abordagem oferece um nível mais alto de abstração ao programador durante o desenvolvimento das aplicações.
Listagem 1 ­ Primitivas para suporte aos serviços de comunicação baseados em prioridades e conexão.
O parâmetro priority pode assumir três valores definidos como constantes:
HIGH; LOW e GT.
Os dois primeiros valores referem- se à prioridade da mensagem a ser enviada e dão suporte ao serviço de comunicação baseado em prioridades.
A prioridade da mensagem é especificada no nível de tarefa, desce toda a pilha de protocolo até o nível de rede e seta o bit de prioridade (P -- Figura 25) no cabeçalho de o (s) pacote (s) que compõem a mensagem.
Esse processo efetivamente faz a ligação entre os níveis de tarefa e de rede.
O valor GT (Guaranteed Throughput) indica que a mensagem deve ser enviada por a conexão previamente estabelecida.
Em este caso, o valor GT não seta o bit de prioridade no cabeçalho, mas o campo de serviço (Service -- Figura 25).
Uma conexão entre um par origem/ destino é estabelecida por o PE origem da comunicação o envia ao PE destino.
Esse pacote vai alocando recursos da rede por os quais é transmitido a fim de criar a conexão.
Uma vez estabelecida a conexão, as mensagens são parâmetro priority com o valor GT.
A o fim da comunicação, a conexão é encerrada por o conexão e o envia ao PE destino.
Esse pacote é transmitido por a conexão e vai desalocando os recursos da rede conforme avança em direção a o PE destino.
Visto que uma conexão aloca toda a largura de banda do caminho entre origem e destino, cada roteador suporta apenas uma conexão com a porta local 0.
Portanto, apenas uma tarefa por PE pode estabelecer uma conexão.
Esta conexão permanece conexão não esteja escalonada.
O roteador não é capaz de preemptar a conexão quando a tarefa origem da comunicação perde o processador.
Se outra tarefa no mesmo PE tentar estabelecer uma conexão, ela ficará bloqueada até que a conexão seja encerrada.
O mesmo vale para uma tarefa que já tem uma conexão estabelecida, ao tentar estabelecer uma segunda conexão.
Essa limitação habilita somente uma tarefa por PE comunicar- se utilizando o serviço de conexões, enquanto as demais devem utilizar o serviço de prioridades.
Portanto, deve- se evitar alocar no mesmo PE tarefas que se servem do serviço de comunicação baseado em conexões.
Isso deve ser incluído como uma restrição na heurística de mapeamento.
Avaliação Esta Seção apresenta os resultados obtidos a partir de simulações das plataformas HeMPS e Hs-Scale.
Ambas as plataformas estão totalmente descritas em VHDL RTL sintetizável e possuem modelos SystemC com precisão de ciclo do processador Plasma e sua memória privada para fins de aceleração da simulação.
Os fluxos de perturbação utilizados nos experimentos podem ser caracterizados como diversos tráfegos comuns em MPSoCs como atualização de blocos de cache, debug, carga e migração de tarefas.
Esta Seção avalia o serviço de comunicação baseado em prioridades sobre a plataforma HeMPS.
O objetivo é verificar o impacto que o controle priorizado sobre os recursos da rede tem na vazão dos fluxos.
Dois cenários foram avaliados numa instância 4x4 da plataforma.
O primeiro cenário simula um MPSoC homogêneo, onde todos os fluxos são gerados por Plasma-IPs.
O segundo cenário simula um MPSoC heterogêneo com geradores de tráfego perturbando os fluxos gerados por os Plasma-IPs.
O objetivo deste primeiro experimento é mostrar o comportamento da NoC conforme o número de fluxos com alta prioridade vai aumentando.
A Figura 26 ilustra a distribuição espacial dos fluxos utilizados no experimento, segundo o algoritmo de roteamento Hamiltoniano.
Esse algoritmo é detalhado no Capítulo 5.
F1 e F2 são fluxos que exigem QoS, enquanto os demais (F3, F4, F5 e F6) são fluxos de perturbação.
Um fluxo é composto por rajadas de pacotes (524 flits/ pacote) intercaladas por tempos ociosos.
A taxa de injeção dos fluxos F1 e F2 é 30% da largura de banda do enlace e os fluxos de perturbação têm uma taxa de injeção média igual a 18,5%.
Essas taxas de injeção garantem a saturação de regiões onde há competição de recursos, como entre os roteadores 5 e 6, visando uma clara demonstração do funcionamento do serviço de comunicação baseado em prioridades.
Todos os fluxos são gerados por aplicações sintéticas executando sobre os processadores Plasma.
A Figura 27 apresenta as vazões dos fluxos observadas nos destinos 2, 3, 4 e 5 flows).
Visto que cada um dos pares de fluxos F 3-F4 e F 5-F6 tem o mesmo destino, a vazão de cada par foi calculada como a vazão total no destino dividida por dois, pois os fluxos têm a mesma taxa de injeção.
Inicialmente, somente os fluxos que exigem QoS enviam pacotes com alta prioridade e a vazão de ambos é próxima da taxa de injeção.
O serviço de comunicação baseado em prioridades proporciona um isolamento parcial entre fluxos de alta e baixa prioridade.
Pode- se observar que os fluxos de perturbação quase não interferem na vazão dos fluxos que exigem QoS, apesar de a grande concorrência por os canais físicos entre os roteadores 5 e 6 (Figura 26 ­ cinco fluxos concorrem por os dois canais físicos).
A partir de essa situação, conforme aumenta o número de fluxos de perturbação que passa a enviar pacotes de alta prioridade, a vazão dos fluxos F1 e F2 decai.
Quando todos os seis fluxos passam a enviar pacotes de alta prioridade, a NoC começa a operar como uma NoC Be.
Isso ocorre porque todos os fluxos são tratados igualmente visto que possuem à mesma prioridade.
Em essa condição, as vazões dos fluxos F1 e F2 reduziram de 29,91% e 28,83% para 21,95% e 20.91%, respectivamente.
Esse experimento mostra que:
NoCs que oferecem apenas serviços de comunicação do tipo Be subutilizam os recursos da rede por falta de controle sobre estes;
Quando o número de fluxos de alta prioridade não excede o suporte à QoS projetada, o serviço de comunicação baseado em prioridades é capaz de oferecer garantias flexíveis aos fluxos que exigem QoS.
Em esse experimento, a NoC dá garantias a até dois fluxos concorrendo por caminhos em comuns;
Abundância de recursos e alta largura de banda não são suficientes para oferecer garantias aos fluxos.
Garantias dependem do controle sobre os recursos da NoC a partir de mecanismos especiais adicionados à sua arquitetura;
Mesmo não excedendo a largura de banda total da NoC, os fluxos podem causar interferências entre si.
O segundo experimento tem por objetivo mostrar que o serviço de comunicação baseado em prioridades pode eficientemente proporcionar garantias de vazão mesmo em situações onde os tráfegos de perturbação têm altas taxas de injeção.
A Figura 28 ilustra a distribuição espacial dos fluxos.
F1 é um fluxo que exige QoS e é gerado por uma processador Plasma, enquanto os fluxos de perturbação F2 e F3 são gerados por geradores de tráfego.
A taxa de injeção do fluxo F1 é 30% da largura de banda do enlace e os fluxos F2 e F3 tem uma taxa de injeção igual a 100%.
Os geradores dos tráfego emulam IPs especializados com altas taxas de injeção.
Ainda que uma taxa de 100% possa parecer irreal, ela pode ser facilmente obtida se os IPs operam em frequências superiores à NoC.
Em este cenário, considerando uma NoC Be com canais físicos duplicados, a vazão do fluxo F1 observada no destino 3 é igual a 10,5%, aproximadamente 1/3 da taxa de injeção.
Esse baixo desempenho deve- se a dois motivos:
A taxa de injeção dos fluxos F2 e F3 é muito alta, o que dificulta o acesso do fluxo F1 aos recursos compartilhados;
Todos fluxos são tratados igualmente por a NoC, independente dos seus requisitos.
Considerando uma NoC com suporte a mecanismo de prioridades e definindo a prioridade do fluxo F1 como alta (via API), enquanto a prioridades dos fluxos F2 e F3 é definida como baixa, F1 atinge uma vazão igual a 29,8% da largura de banda do enlace.
O mecanismo de prioridades cria uma reserva virtual, onde certos recursos estão disponíveis exclusivamente para fluxos de alta prioridade.
Esta Seção utiliza os serviços de comunicação baseados em prioridades e conexões a fim de atingir composability sobre a plataforma Hs-Scale.
O objetivo é garantir os requisitos de desempenho da aplicação alvo quando esta é mapeada na plataforma juntamente com outras aplicações que concorrem por recursos de comunicação em comum.
Os experimentos foram realizados numa instância 4x4 da plataforma Hs-Scale misturando aplicações reais e sintéticas.
A aplicação real (alvo) é um decodificador áudio/ vídeo com restrições temporais composto por sete tarefas.
A Figura 29 ilustra o grafo de tarefas do decodificador.
O pipeline de vídeo é executado por um decodificador MJPEG particionado em três tarefas e o pipeline de áudio é composto por um decodificador ADPCM (Ad) e um filtro do tipo FIR.
Uma tarefa inicial chamada SPLIT demultiplexa os streams compactados (áudio/ vídeo) e os envia aos respectivos pipelines, enquanto a tarefa JOIN sincroniza os streams descompactados.
A vazão mínima requerida por a aplicação é 30 frames/ s (vídeo) e 32000 amostras/ s (áudio estéreo) sincronizados.
As aplicações sintéticas não têm restrições temporais e apenas emulam acesso a dispositivos de saída e memórias, os quais são emulados por tarefas em software.
Inicialmente, o decodificador é mapeado sozinho na plataforma e as tarefas se comunicam utilizando o serviço de comunicação baseado em prioridades.
A vazão obtida é igual a 31,13 frames/ s e é usada como referência.
Visto que neste experimento o pipeline de vídeo produz um volume de dados significativamente maior que o pipeline de áudio, no decorrer de o texto a vazão da aplicação é expressa apenas em frames/ s, no entanto ela inclui também as amostras de áudio, pois a vazão é mensurada na tarefa JOIN.
O mapeamento ótimo mostrado na Figura 30 é comumente obtido durante a inicialização do sistema, quando todos os recursos estão disponíveis.
Em sistemas onde pode haver carga dinâmica de aplicações, como smart phones e tablets, elas são frequentemente alocadas e removidas da plataforma, resultando na dispersão (fragmentação) dos recursos disponíveis (Seção 3.3.2 -- Figura 22).
Consequentemente, um mapeamento ótimo é cada vez mais difícil de ser atingido em tempo de execução, a menos que o sistema suporte algum tipo de remapeamento dinâmico (e.
gmigração de tarefas).
As novas aplicações alocadas tendem a compartilhar os recursos do sistema com as aplicações já alocadas.
A Figura 31 ilustra uma situação onde não foi possível atingir um mapeamento ótimo do decodificador devido a a dispersão dos recursos.
Quatro novas aplicações foram adicionadas ao sistema, cada uma com duas tarefas:
T1àMEM, T2àMEM, T3àOUT e T 4 àOUT.
O mapeamento resultante é suscetível à interferência entre as aplicações devido a a concorrências por os recursos da rede.
A Tabela 3 apresenta a vazão do decodificador variando o número de aplicações com fluxos de alta prioridade no mapeamento apresentado na Figura 31 para seis diferentes cenários.
Quando somente os fluxos do decodificador têm alta prioridade, a vazão obtida é apenas 1,6% menor que a de referência, mantendo- se acima de os 30 frames/ s requeridos por a aplicação.
O serviço de comunicação baseado em prioridades efetivamente garante aos fluxos da aplicação alvo acesso privilegiado aos recursos da rede, evitando interferências por parte de os demais fluxos.
No entanto, as limitações desse tipo serviço tornam- se evidentes na proporção em que o número de fluxos de alta prioridade concorrendo por recursos de comunicação em comum aumenta.
Isso pode ser observado na degradação da vazão nos cenários S2 a S5, quando as tarefas T4, T3, T1 e T2 passam uma a uma a enviar pacotes com alta prioridade.
A vazão é reduzida em 52% quando os fluxos de todas aplicação tem alta prioridade (cenário S5).
Em essa situação, a NoC passa a operar em modo Be e sua alta largura de banda não é suficiente para garantir os requisitos da aplicação alvo.
A partir desse cenário, onde o serviço de prioridades já não oferece mais garantias para atingir o requisito mínimo de 30 frames/ s, o serviço de conexões é empregado.
Visto que o fluxo de dados do pipeline de vídeo tem uma taxa mais elevada que o de áudio, ele foi escolhido para usar o serviço de conexões.
Este último cenário (S6) é mostrado na última linha da Tabela 3, onde somente as tarefas do decodificador de vídeo comunicam- se através de conexões, enquanto as demais se mantém enviando pacotes de alta prioridade.
O serviço de comunicação baseado em conexões estendeu as garantias oferecidas por o sistema e ainda elevou a vazão da aplicação alvo em 3,5% em relação a a vazão de referência.
Os resultados obtidos nos cenários S1 e S6 mostram a eficiência dos serviços de comunicação propostos no gerenciamento dos fluxos a partir de o nível de software.
A transmissão de um determinado fluxo através da NoC pode modificar a sua taxa de injeção, introduzindo valores variáveis de latência e resultando na perda de certos deadlines no IP destino.
Essa variação instantânea da latência é chamada de jitter e deve ser minimizada em aplicações com restrições temporais.
Em uma transmissão sem jitter, os pacotes de um determinado fluxo são transmitidos dentro de intervalos de tempo constantes, como mostra a Figura 32 (a).
Uma discrepância na latência dos pacotes altera o intervalo de tempo em o qual estes são transmitidos, caracterizando o jitter (Figura 32 (b)).
A Figura 33 e a Figura 34 mostram o jitter do pipeline de vídeo correspondente aos cenários de referência e S1 a S6 (Tabela 3).
O eixo X representa o intervalo de tempo entre os blocos decodificados (i na Figura 32) que chegam à tarefa JOIN e o eixo Y representa a quantidade de blocos decodificados que chegam em cada intervalo de tempo.
A Figura 33 mostra o jitter para os cenários;
Referência; Alta prioridade para os fluxos das tarefas do decodificador áudio/ vídeo;
E conexões para os fluxos das tarefas do pipeline de vídeo (cenário S6).
Em esses três cenários, a maior parte dos blocos decodificados chega à tarefa JOIN dentro de os intervalos (média e desvio padrão):
191± 55, 192± 59, 189± 57 kilo ciclos de clock para os cenários de referência, S1 e S6 respectivamente.
Além de vazões semelhantes, a similaridade entre as três curvas mostra que os serviços propostos garantem jitter equivalente mesmo na presença de fluxos de perturbação.
A Figura 35 mostra a área, medida em LUTs e FFs, para os principais componentes da NPU:
PE, contendo o processador Plasma, interface de rede e memória local;
Roteador da NoC.
A área de uma NPU mapeada no dispositivo Virtex5 LX330 sem suporte aos serviços de comunicação propostos é igual a 4016/1997 LUTs/ FFs.
A versão da NPU suportando tais serviços tem uma área igual a 5652/2384 LUTs/ FFs, tendo um acréscimo de LUTs e FFs de 40,74%/ 19,38%, respectivamente.
Esse acréscimo de área é proveniente do aumento na área do roteador, devido a a duplicação dos canais físicos, que por sua vez dobra sua largura de banda.
O impacto da área do roteador na área da NPU pode ser reduzido se um processador mais complexo que Plasma for utilizado.
O CoMPSoC, por exemplo, reporta uma área de 57882 LUTs para um MPSoC com 3 processadores, SRAM e dispositivos de entrada/ saída para áudio/ vídeo.
Dispositivo: Virtex5 LX330.
Escalonamento preemptivo com prioridades A partir de os serviços de comunicação baseados em prioridades e conexões podese evitar a interferência entre os fluxos das aplicações graças a o controle sobre os recursos da NoC que estes proporcionam.
Assim é possível atingir composability no nível da rede.
Entretanto, quando diferentes tarefas compartilham o mesmo processador, o tempo de processamento é dividido entre elas e isso pode reduzir o desempenho das aplicações levando- as à perda de deadlines.
Para controlar a interferência entre tarefas alocadas no mesmo PE, pode- se empregar um mecanismo de prioridades no algoritmo de escalonamento.
A ideia é aumentar a prioridade das tarefas pertencentes a aplicações com restrições temporais.
Obviamente, quando tarefas de aplicações com restrições temporais compartilham o mesmo PE, tal solução pode ser ineficiente, devendo- se evitar essa situação durante o mapeamento.
Como dito anteriormente, o microkernel da plataforma HeMPS (Seção 3.2) escalona as tarefas utilizando round-robin.
Em esse escalonamento o processador é compartilhado igualmente por as tarefas.
Elas são colocadas numa lista circular que é percorrida regularmente, alocando o processador para cada uma por um intervalo de tempo fixo chamado time slice.
A o final do time slice, a tarefa em execução é preemptada e uma nova tarefa é escalonada.
O mecanismo de prioridades, aqui incluído no round-robin, permite ao desenvolvedor indicar, em tempo de projeto, a prioridade e o time slice de cada tarefa.
Em essa abordagem, uma tarefa com prioridade mais alta que a tarefa em execução pode preemptar- la.
A tarefa preemptada tem o restante do seu time slice armazenado, o qual é restaurado quando ela for escalonada novamente.
A Figura 36 ilustra um exemplo do funcionamento do algoritmo round-robin incrementado com prioridades e time slice definidos por tarefa.
Em o exemplo da Figura 36 o processador é compartilhado por quatro tarefas, três com prioridade e time slice iguais, e uma com prioridade mais alta e time slice maior (Task4).
Note que a tarefa Task1 é escalonada novamente após a tarefa Task3 devido a o fato de que a tarefa Task4 estava em estado de espera (wait) no que tarefa Task4 está pronta para executar (ready) ela preempta a tarefa em execução, a qual volta a executar o restante do seu time slice após a tarefa Task4 terminar o seu ou entrar em estado de espera novamente.
Para avaliar o mecanismo de prioridades implementado sobre o escalonamento round-robin, utilizou- se novamente como aplicação alvo o decodificador áudio/ vídeo.
Como perturbação, utilizou- se um multiplicador de matrizes que implementa o algoritmo de Fox.
Tal multiplicador é composto por dez tarefas.
Mais detalhes sobre essa aplicação serão apresentados no Capítulo 6.
A Figura 37 ilustra o mapeamento das duas aplicações sobre uma instância 3x4 da plataforma HeMPS.
Note que todas as tarefas do decodificador compartilham os PEs com tarefas do multiplicador de matrizes.
Os fluxos das duas aplicações (omitidos da figura) são isolados no nível da rede através do serviço de comunicação baseado em prioridades.
S5 da Tabela 3, onde a NoC opera em modo Be, tratando igualmente todos os fluxos.
A fim de reduzir tal interferência, a prioridade das tarefas da aplicação alvo foram aumentadas em relação a as tarefas do multiplicador de matrizes (cenário S3).
Assim, as tarefas da aplicação alvo podem preemptar as tarefas do multiplicador de matrizes sempre que estiverem prontas para executar.
Em relação a o cenário S1, no cenário S3 o tempo de execução da aplicação alvo aumentou 2,6% e a vazão reduziu 4,6%.
Para minimizar a interferência entre as aplicações, no cenário S4 o time slice das tarefas da aplicação alvo é o dobro do time slice das tarefas do multiplicador de matrizes.
Como resultado, o isolamento entre as aplicações é quase total e o desempenho da aplicação alvo é muito semelhante ao obtido quando esta executa sozinha sobre a plataforma.
A Figura 38 mostra o intervalo de tempo entre frames decodificados por a aplicação alvo em cada um dos 4 cenários da Tabela 4.
Em os cenários onde a aplicação alvo executa sozinha sobre a plataforma e onde ela está isolada (S3 e S4), observase que um frame é decodificado a cada± 2300000 ciclos de clock.
Em o cenário S2, onde a aplicação alvo sofre uma interferência do multiplicador de matrizes, inicialmente observase que um frame é decodificado a cada± 3700000 ciclos de clock.
Após um certo tempo tem- se um frame é decodificado a cada± 2300000 ciclos de clock.
Essa variação evidência o momento em que multiplicador terminou de multiplicar as 180 matrizes e foi desalocado, deixando a aplicação alvo executar sozinha sobre a plataforma.
Considerações A grande disponibilidade de recursos (e.
g buffers, canais físicos, largura de banda) na implementação de NoCs deve ser gerenciada de maneira inteligente a partir de mecanismos específicos que ofereçam controle sobre a alocação destes.
Esses mecanismos dão suporte à criação de serviços de comunicação diferenciados que devem ser utilizados com a finalidade de combinar, da melhor maneira possível, a alocação de recursos de rede com os requisitos de comunicação das aplicações.
Em MPSoCs baseados em NoCs, o acesso a tais serviços através da API de comunicação aumenta a programabilidade do sistema oferecendo um controle mais amplo sobre a plataforma.
O controle sobre os recursos da NoC oferecido por os serviços de comunicação baseados em prioridades e conexões possibilita a minimização da interferência de fluxos Be sobre os fluxos de aplicações com restrições temporais.
Entretanto em ambientes multitarefa, tal interferência deve ser considerada também no nível de processamento.
Portanto, o tempo de processamento dos PE deve também ser gerenciado através do escalonamento de tarefas, a fim de possibilitar a combinação entre a alocação de recursos de comunicação e processamento.
Este Capítulo apresenta a segunda contribuição desta Tese, o serviço de comunicação com roteamento diferenciado.
O termo diferenciado refere- se à possibilidade que o serviço oferece de aplicar um algoritmo de roteamento adaptativo ou determinístico a uma determinada mensagem.
Após uma revisão sobre o estado da arte, acredita- se que esse serviço é uma contribuição original tanto na área de NoCs quanto de MPSoCs.
Os algoritmos de roteamento podem ser classificados, segundo a definição de o (s) caminho (s) entre um par origem/ destino, como determinísticos ou adaptativos.
Um algoritmo determinístico fornece sempre o mesmo caminho entre um determinado par origem/ destino, pois tal caminho é definido unicamente por as posições relativas do par.
Por outro lado, dependendo do grau adaptividade, um algoritmo adaptativo pode fornecer mais de um caminho entre um par origem/ destino.
Tipicamente o caminho é definido em função de o estado instantâneo da rede (roteamento distribuído), incluindo pontos de congestionamento e falhas nos enlaces e/ ou roteadores.
Entretanto, ele pode ser também definido por a origem (roteamento na origem) a partir de um conjunto de caminhos prédefinido.
A principal vantagem de um algoritmo determinístico é a sua simplicidade, além de prover baixa latência quando a rede não está congestionada.
Em contrapartida, um algoritmo adaptativo está apto a evitar canais congestionados usando caminhos alternativos, adequando- se melhor a redes com tráfego intenso.
A capacidade de adaptação de um algoritmo de roteamento aumenta a chance dos pacotes trafegarem em locais distantes de pontos quentes da rede (hot-spots).
Quanto a adaptatividade, o algoritmo pode ser completamente adaptativo ou parcialmente adaptativo.
A diferença entre eles é que este último impõe restrições de roteamento que limitam sua busca por caminhos alternativos.
De acordo com a minimalidade, um algoritmo de roteamento adaptativo pode ser classificado como mínimo ou não-mínimo.
Um algoritmo mínimo considera somente os menores caminhos entre um determinado par origem/ destino.
Esta obrigatoriedade não ocorre num algoritmo nãomínimo, que pode adotar caminhos de qualquer comprimento.
Essa característica habilita uma busca por caminhos alternativos mais ampla que um algoritmo mínimo.
Este Capítulo propõe um esquema de roteamento orientado a fluxo que permite rotear fluxos de pacotes de diferentes classes através de diferentes versões do algoritmo de roteamento.
Esse esquema visa unir as vantagens dos algoritmos de roteamento determinístico e adaptativo com o propósito de criar um serviço de comunicação com roteamento diferenciado.
Visto que um algoritmo adaptativo pode fornecer vários caminhos entre um par origem/ destino, ele oferece um serviço de comunicação com uma qualidade superior a um algoritmo determinístico, pois além de estar apto a evitar bloqueios, ele reduz a contenção, ainda que possa acarretar aumento da latência devido a o uso de um caminho mais longo, no caso de algoritmos não-mínimos.
A partir de o esquema proposto, a NoC passa a suportar simultaneamente os dois tipos de algoritmos.
A ideia é utilizar o algoritmo adaptativo no roteamento de mensagens com restrições temporais flexíveis, enquanto as demais são roteadas deterministicamente.
Roteamento orientado a fluxo O roteamento orientado a fluxo é um esquema que pode ser implementado tendo como base qualquer algoritmo de roteamento adaptativo.
A condição básica é que exista uma versão determinística do algoritmo adaptativo selecionado.
Pode ser provado que esta versão sempre existe fixando um único caminho para cada par origem/ destino a partir de o conjunto de caminhos fornecidos por o algoritmo adaptativo.
Visto que um algoritmo adaptativo oferece caminhos alternativos, ele pode ser aplicado a fluxos de alta prioridade, enquanto fluxos de baixa prioridade são roteados usando a versão determinística do mesmo algoritmo.
Os roteadores são responsáveis por selecionar a versão do algoritmo a ser aplicada para cada pacote durante a transmissão.
Durante a execução do roteamento por o roteador, uma questão importante em algoritmos adaptativos é a política de seleção da porta de saída de entre as retornadas por o algoritmo.
Uma política comum é basear a decisão no nível de congestionamento dos roteadores vizinhos.
No entanto, tal abordagem não garante um caminho livre de congestionamento, nem mesmo o caminho menos congestionado, pois se trata de uma informação local e instantânea, a qual pode orientar o roteamento para áreas congestionadas que não são localmente visíveis.
Para reduzir o custo de área e manter a implementação o mais simples possível, o esquema proposto não adota detecção de congestionamento para selecionar a porta de saída.
Quando o algoritmo retorna mais de uma porta de saída disponível, a porta selecionada é aquela que leva a um dos caminhos mais curtos.
O custo de área do esquema proposto é muito baixo, menos de 1% da área do roteador.
O roteamento orientado a fluxo pode ser implementado tendo como base algoritmos adaptativos conhecidos como odd-even ou aqueles baseados no modelo turn model (e.
g west first e north last).
Este trabalho implementa o roteamento orientado a fluxo sobre a NoC Hermes tendo como base o algoritmo de roteamento Hamiltoniano, o qual substitui o algoritmo XY.
O algoritmo Hamiltoniano foi escolhido devido a a simplicidade em obter- se uma versão determinística a partir de a versão adaptativa, além de servir de base para a implementação de algoritmos multicast (e.
g dual-path e multipath).
Em, uma versão mínima adaptativa desse algoritmo chamada HAMUM (Hamiltonian Adaptive Multicast Unicast Method) foi comparada com os algoritmos XY, odd-even e o esquema DyAD.
O HAMUM apresentou um desempenho superior em termos de latência média sobre malhas de dimensões 8x8 e 14x14, considerando uma distribuição de tráfego com um hot-spot.
Um caminho Hamiltoniano é um caminho acíclico em o qual é possível atingir todos os nodos de um grafo passando apenas uma vez em cada nodo.
Sobre uma malha bidimensional podem ser definidos vários caminhos Hamiltonianos.
A Figura 39 ilustra dois caminhos Hamiltonianos definidos sobre uma rede malha 5x5 com apenas um canal físico (bidirecional) entre roteadores vizinhos.
Os enlaces sólidos identificam um caminho Hamiltoniano que parte do roteador 0 e vai até o roteador 24, ao passo que os enlaces tracejados identificam um caminho Hamiltoniano reverso.
Os roteadores foram identificados utilizando rótulos que variam de 0 a N-1, sendo N o número de roteadores.
Os rótulos crescem da esquerda para a direita em linhas pares e da direita para a esquerda em linhas ímpares.
A partir de os caminhos Hamiltonianos definidos, a rede pode ser dividida em duas sub-redes disjuntas e acíclicas.
Uma sub-rede contém os enlaces que vão de um rótulo menor para um maior e a outra contém os enlaces que vão de um rótulo maior para um menor.
Os caminhos seguem a ordem crescente ou decrescente dos rótulos.
Os enlaces pontilhados, os quais não fazem parte dos caminhos Hamiltonianos, podem ser usados para reduzir o comprimento das rotas.
A versão não-mínima parcialmente adaptativa do algoritmo de roteamento Hamiltoniano funciona como segue.
Um pacote num roteador com rótulo menor que o destino (origem destino) é encaminhado para qualquer roteador vizinho cujo rótulo seja maior que o roteador local e menor/ igual ao destino (local vizinho destino).
Considere, por exemplo, o roteador 12 como origem e o roteador 22 como destino.
Alguns dos roteador com rótulo maior que o destino (origem\&gt; destino), ele é encaminhado para qualquer roteador vizinho cujo rótulo seja menor que o roteador local e maior/ igual ao destino (local\&gt; vizinho destino).
Considere, por exemplo, o roteador 13 como origem e Para criar uma versão mínima determinística do algoritmo a partir de a versão nãomínima parcialmente adaptativa, a condição de encaminhamento pode ser restringida para &quot;encaminhar o pacote para o maior/ menor vizinho, cujo rótulo seja menor/ maior que o destino «(dependendo dos rótulos origem e destino).
em os exemplos 1222 e 137, os Ambas as versões do algoritmo de roteamento Hamiltoniano são livres de deadlock uma vez que os pacotes são roteados sobre subredes disjuntas e acíclicas.
De maneira semelhante ao algoritmo de roteamento odd-even, o qual proíbe algumas mudanças de direção em colunas ímpares e pares da malha, o algoritmo Hamiltoniano proíbe algumas mudanças de direção em linhas ímpares e pares, a fim de evitar ciclos que podem acarretar deadlock.
Considerando os caminhos Hamiltonianos definidos na Figura 39, as mudanças de direção norte/ oeste e sul/ leste são proibidas em linhas pares da malha, e as mudanças de direção norte/ leste e sul/ oeste são proibidas em linhas impares.
Em este trabalho, o algoritmo de roteamento Hamiltoniano é utilizado simultaneamente nas duas versões apresentadas não-mínima parcialmente adaptativa e mínima determinística, referidas no restante do texto apenas como adaptativa e determinística, respectivamente.
Para permitir aos roteadores decidirem a versão do algoritmo a ser aplicada, um bit disponível no cabeçalho do pacote (campo unused Figura 25) é definido como bit de roteamento.
Durante a transmissão de um pacote, o bit de roteamento é verificado por os roteadores e então a versão correspondente do algoritmo de roteamento é executada.
Esse processo se repete em cada roteador percorrido por o pacote (roteamento distribuído).
Integração do roteamento orientado a fluxo no nível de software O controle sobre qual versão do algoritmo de roteamento deve ser utilizada foi integrada à API de comunicação da plataforma HeMPS através do parâmetro priority, cuja versão do algoritmo a ser utilizada depende apenas do valor do parâmetro priority.
Durante o processamento da primitiva cabeçalho do pacote que carrega a mensagem.
Definindo o parâmetro priority, indica que a versão adaptativa do algoritmo de roteamento deve ser aplicada.
A o utilizar o valor LOW, os pacotes são definidos para serem roteados deterministicamente.
Uma questão a ser tratada ao utilizar um algoritmo de roteamento adaptativo é o ordenamento das mensagens, pois estas podem tomar caminhos diferentes e chegarem ao destino numa ordem diferente de a qual foram enviadas.
A premissa para a ocorrência de um desordenamento é a transmissão simultânea de duas ou mais mensagens de uma origem para um mesmo destino.
A NoC Hermes não implementa nenhum tipo mecanismo que garanta o ordenamento das mensagens.
Entretanto, na plataforma HeMPS, esse ordenamento é assegurado em software por o protocolo de comunicação read request implementado por o microkernel (Seção 3.2).
Esse protocolo garante que um PE origem somente envia uma mensagem n depois que o PE destino recebeu a mensagem n-1.
Avaliação Esta Seção apresenta dois experimentos utilizados para avaliar o serviço de comunicação com roteamento diferenciado.
O primeiro experimento foi realizado utilizando tráfego sintético gerado por geradores de tráfego conectados à NoC Hermes.
Em este caso o ordenamento dos pacotes não é tratado.
O objetivo é avaliar o serviço de comunicação sob diferentes intensidades de tráfego.
O segundo experimento foi realizado utilizando tráfego gerado por um decodificador MJPEG executando sobre a plataforma HeMPS (ordenamento dos pacotes assegurado).
As métricas de desempenho utilizadas são latência, vazão e jitter.
A topologia utilizada é malha 5x5 com canais físicos simples e chaveamento por pacotes.
Duas distribuições espaciais de tráfego foram avaliadas:
Hot-spot e complemento.
A Figura 40 apresenta a distribuição de tráfego hot-spot utilizada.
Dois hotspots ocorrem nos roteadores 12 e 17.
A linha tracejada corresponde ao fluxo avaliado e as linhas sólidas correspondem aos fluxos de perturbação.
Os caminhos tomados por os fluxos na Figura 40 consideram a versão determinística do algoritmo Hamiltoniano.
O fluxo avaliado tem uma taxa de injeção fixa de 30% da largura de banda do enlace e os fluxos de perturbação têm sua taxa de injeção variando de 5% a 50%.
O fluxo 222 é avaliado em três cenários de roteamento:
Determinístico: Todos os fluxos são roteados utilizando a versão determinística do algoritmo de roteamento Hamiltoniano.
Adaptativo: Todos os fluxos são roteados utilizando a versão adaptativa do algoritmo de roteamento Hamiltoniano.
Orientado a fluxo:
Somente o fluxo 222 é roteado usando a versão adaptativa do algoritmo de roteamento Hamiltoniano, enquanto os demais são roteados deterministicamente.
Os gráficos a seguir mostram os resultados de latência, vazão e jitter obtidos para o fluxo 222.
As curvas Flow correspondem aos resultados obtidos roteando adaptativamente somente o fluxo 222.
Os resultados de jitter foram obtidos considerando a taxa de injeção dos fluxos de perturbação igual a 20% da largura de banda do enlace.
Para outras taxas de injeção moderadas (abaixo de o ponto de saturação da rede) o comportamento é similar.
Deter. Adapt.
Thoughput(%) Deter.
Adapt. Observar a latência e a vazão do fluxo 222 nos cenários onde todos fluxos são roteados utilizando a mesma versão do algoritmo de roteamento (adaptativa ou determinística).
A adaptatividade melhora o desempenho do roteamento Hamiltoniano, apresentando um bom desempenho quando a taxa de injeção dos fluxos de perturbação é baixa.
Entretanto, sob tráfegos mais intensos, o desempenho da versão adaptativa decai como a determinística.
Note que a partir de certas taxas de injeção dos fluxos de perturbação, os valores médios de latência e vazão do fluxo 222 começam, respectivamente, a diminuir e aumentar.
Isso ocorre porque quanto maior a taxa de injeção dos fluxos de perturbação, mais cedo os geradores de tráfego terminam de enviar todos os pacotes desses fluxos.
Logo, em taxas de injeção mais altas, eles não perturbam o fluxo 222 durante toda a transmissão dos seus pacotes.
Quando o esquema de roteamento orientado a fluxo é empregado, a latência e a vazão do fluxo 222 não são significativamente afetadas por os fluxos de perturbação.
Graças à combinação proporcionada por esse esquema, o algoritmo determinístico limita os caminhos disponíveis para os fluxos de perturbação, deixando mais caminhos livres para serem explorados por o algoritmo adaptativo empregado por o fluxo 222.
Por exemplo, quando a porta norte do roteador 7 não está disponível, o fluxo intensidade.
Quando todos os fluxos são roteados deterministicamente, o fluxo 222 não está apto a evitar a área de hot-spot e seu desempenho é severamente afetado.
Uma queda de desempenho semelhante pode ser observada quando todos os fluxos são roteados adaptativamente.
Em este caso, quando a porta norte do roteador 7 não está disponível, os fluxos de perturbação estão habilitados a explorar caminhos alternativos usando a porta oeste do roteador 7, que por sua vez podem perturbar o fluxo 222, visto que agora este último tem de compartilhar os recursos da NoC com os demais fluxos.
O mesmo comportamento é observado quando o jitter é avaliado, como mostra a Figura 43.
O roteamento adaptativo atenua o jitter, comparado com o roteamento determinístico, mas não o elimina.
O roteamento orientado a fluxo praticamente remove todo o jitter do fluxo 222, com quase todos pacotes tendo a mesma latência.
Note que nesse cenário uma versão mínima adaptativa do algoritmo de roteamento Hamiltoniano não ofereceria caminhos alternativos ao fluxo 222, visto que a menor distância entre dois pontos é uma linha reta.
Os bons resultados obtidos com o cenário hot-spot devem- se ao fato de que Deter.
Adapt. Flow Disturbing injection rate(%) Fluxo 618 Average packet (clock cycles) existem áreas livres de congestionamento na rede e o algoritmo adaptativo consegue encontrar caminhos alternativos nestas áreas.
Uma situação bem diferente surge num cenário com distribuição de tráfego complemento, onde a carga está igualmente distribuída na rede.
Os gráficos da Figura 44 mostram a latência média dos fluxos 618 e 123 obtidos com um taxa de injeção de 20% da largura de banda do enlace, enquanto a taxa de injeção dos fluxos de perturbação variam de 5% a 50%.
Mesmo limitando a disponibilidade de caminhos para os demais fluxos através da versão determinística do algoritmo, o roteamento orientado a fluxo apresentou pouco ganho em relação a todos os fluxos sendo roteados igualmente.
Este experimento destaca a limitação dos algoritmos adaptativos na busca de caminhos alternativos em situações onde o tráfego está bem distribuído na rede, como no caso de uma distribuição de tráfego complemento.
Deter. Adapt.
A aplicação alvo neste experimento é um decodificador MJPEG particionado em nove tarefas, as quais comunicam- se como um pipeline.
A tarefa Start envia continuamente blocos compactados para a tarefa IVLC1, a qual efetivamente inicia a decodificação.
O mapeamento e os fluxos da aplicação sobre a plataforma HeMPS são ilustrados na Figura 45.
Os PlasmaIPs SL conectados aos roteadores 3, 4, 5, 6 e 7 executam somente tarefas de debug do sistema, gerando mensagens para o Plasma-IP MP (Master) que correspondem a fluxos de perturbação.
Esse cenário caracteriza o Plasma-IP MP como um hot-spot, o qual perturba a comunicação entre as tarefas IVLC2 e IVLC3.
Devido a o alto tempo de computação das tarefas em software (computação intensiva), a taxa de injeção gerada por elas é inferior a 3% da largura de banda dos enlaces da NoC.
Os mesmos três cenários de roteamento da Seção 5.3.1 são repetidos:
Todos os fluxos roteados deterministicamente;
Todos fluxos roteados adaptativamente;
E somente os fluxos do decodificador MJPEG roteados adaptativamente.
A versão do algoritmo de roteamento a ser empregada sobre os fluxos de mensagens é definida no A Tabela 5 apresenta os resultados médios de latência e vazão para todos os fluxos gerados por as tarefas do decodificador MJPEG considerando os três cenários de roteamento.
Os resultados de latência estão em ciclos de clock e a vazão corresponde a uma percentagem da largura de banda total do enlace.
O tempo total (penúltima linha da tabela) corresponde ao tempo gasto para terminar a execução da aplicação em ciclos de clock.
A última linha da tabela mostra o aumento no tempo total de execução em relação a a aplicação executando sozinha na plataforma (sem perturbações).
Comparando o roteamento determinístico e adaptativo, observa- se que a latência média dos pacotes do fluxo IVLC2 IVLC3 é próxima, enquanto o tempo total de execução é significativamente diferente.
Em o cenário determinístico, devido a a alta concorrência por a porta norte do roteador 7, a tarefa IVLC2 é contida e seus pacotes só começam a ser entregues à tarefa IVLC3 depois que algumas tarefas de debug terminam e o tráfefo intenso no hot-spot diminui.
Devido a tal contenção, o tempo total de execução aumenta, entretanto, a latência média dos pacotes permanece baixa porque a maioria destes só começa a ser injetada na rede após a redução do hot-spot.
O roteamento orientado a fluxo consegue desviar do hot-spot, mantendo a latência e a vazão do fluxo IVLC2 IVLC3 semelhantes aos demais e com um aumento no tempo total de execução de apenas 1,3%.
Esses resultados mostram que o roteamento orientado a fluxo favorece composability, visto que o desempenho obtido é próximo a o da aplicação executando sozinha sobre a plataforma.
A Figura 46 apresenta os resultados de jitter da aplicação.
Como observado anteriormente, num cenário de hot-spot o roteamento orientado a fluxo praticamente elimina o jitter.
Uma análise superficial poderia assumir que devido a as baixas taxas de injeção de tarefas executando em software, a interferência entre seus fluxos seria mínima.
Entretanto, este experimento demonstra que num MPSoC real a interferência entre os fluxos das aplicações pode afetar significativamente métricas de desempenho importantes em aplicações com restrições de QoS.
Deter. Adapt.
Este Capítulo apresenta a terceira contribuição desta Tese, a comunicação coletiva baseada em multicast.
Esse tipo de comunicação é o resultado da demanda de operações que envolvem dados compartilhados entre tarefas e que precisam ser transmitidos e recebidos através de um modelo de troca de mensagem.
Dependendo da aplicação, a programação paralela pode fazer uso de diversos padrões de comunicação coletiva como gather, reduce e scatter.
Entretanto, o padrão mais utilizado e que recebe maior atenção da comunidade de pesquisa é o multicast.
O broadcast também é muito utilizado e pode ser tratado como um caso especial do multicast.
Visto que a infraestrutura de comunicação dos MPSoCs vem rapidamente mudando de barramentos para NoCs, alguns serviços oferecidos por os barramentos também devem estar disponíveis em NoCs, em especial o serviço de comunicação coletiva.
Esse serviço é responsável por a execução eficiente de diversas aplicações paralelas como algoritmos de pesquisa, busca em grafos e operações com matrizes (inversão e multiplicação por exemplo).
Ele também é empregado na implementação de diferentes protocolos como controle e configuração de rede, sincronização e coerência de cache.
Apesar de arquiteturas de interconexão baseadas em barramentos não serem escaláveis e proporcionarem baixo suporte a comunicações paralelas, elas nativamente suportam comunicação coletiva.
Em NoCs com topologia malha, a implementação eficiente desse tipo de comunicação depende de algoritmos especiais de multicast.
Comumente, o suporte a mensagens multicast é implementado de maneira não-escalável, enviando separadamente uma cópia da mensagem para cada destino.
Tal solução aumenta o volume do tráfego na rede e consequentemente o consumo de energia à medida que aumenta o número de destinos das mensagens multicast.
Algoritmos multicast para redes com topologia malha têm sido estudados e propostos amplamente para arquiteturas paralelas.
Este Capítulo apresenta a implementação do algoritmo multicast dual-path na NoC Hermes com a finalidade de dar suporte em hardware ao serviço de comunicação coletiva na plataforma HeMPS.
Tal algoritmo permite a transmissão de mensagens multicast de maneira escalável, pois o número de cópias enviadas é limitado por o número máximo de conjuntos em os quais os destinos são agrupados.
Algoritmo multicast dual-path na NoC Hermes O algoritmo dual-path foi originalmente proposto por Lin et al.
Em para multicomputadores e tem como base o algoritmo de roteamento Hamiltoniano (Seção possuir uma descrição clara e concisa que facilita sua implementação em NoCs com topologia malha.
A origem da mensagem multicast deve dividir o conjunto de destinos em dois subconjuntos, um contendo os destinos com rótulos maiores que a origem e outro contendo os menores.
Em seguida, uma cópia da mensagem é enviada separadamente para cada subconjunto.
Caso todos os rótulos do conjunto de destinos sejam maiores ou menores que a origem, apenas uma cópia de mensagem é enviada.
A escalabilidade da transmissão da mensagem multicast é garantida por o número máximo de cópias enviadas.
O algoritmo dual-path garante que são enviadas no máximo duas cópias da mensagem, independente do número de destinos.
Para suportar a transmissão multicast, o cabeçalho dos pacotes da NoC Hermes foi estendido de maneira a incluir vários destinos, como ilustra a Figura 47.
Cada flit de destino no cabeçalho tem o campo service (Figura 25) indicando que se trata de um destino do pacote.
O fim do cabeçalho é indicado por o campo service do último flit de destino.
O cabeçalho de pacotes multicast tem tamanho variado, dependendo do número de destinos.
O caminho tomado por os pacotes multicast é definido por o algoritmo de roteamento Hamiltoniano, o qual define também o caminho tomado por os pacotes unicast.
Durante o roteamento dos pacotes multicast, o algoritmo Hamiltoniano é executado baseado no primeiro destino contido no cabeçalho, de maneira análoga a pacotes unicast.
Quando o pacote chega ao primeiro destino contido no cabeçalho, a porta local do roteador é alocada.
Em seguida, o roteador remove esse destino do cabeçalho e o roteamento é executado novamente baseado no próximo destino.
Em essa segunda execução do roteamento, uma porta em direção a o próximo destino é alocada.
Esse processo se repete nos demais roteadores do caminho até o último destino contido no cabeçalho.
Em cada roteador destino, exceto o último, o pacote é encaminhado simultaneamente para as duas portas alocadas.
O avanço do pacote nesses roteadores depende da disponibilidade simultânea do IP (porta local) e do roteador vizinho (porta norte, sul, leste ou oesteab) ilustram o processo de roteamento considerando os pacotes multicast apresentados na Figura 48 e o roteador 6 como origem.
As figuras ilustram apenas os cabeçalhos, entretanto o payload está anexado a estes.
Visto que a transmissão de pacotes multicast demanda a alocação de muitos recursos, a versão não-mínima parcialmente adaptativa do algoritmo de roteamento Hamiltoniano é empregada.
A ideia é oferecer o máximo de recursos disponíveis a estes pacotes para que eles sejam transmitidos o mais rápido possível, com o intuito de evitar a sobrecarga intensificação do tráfego na rede.
Integração do multicast dual-path no nível de software Em o desenvolvimento de aplicações paralelas, a comunicação coletiva simplifica a programação, facilita a implementação de esquemas eficientes de comunicação e reflete o agrupamento conceitual de tarefas.
O interesse no uso de comunicação coletiva não é novidade e a sua importância pode ser evidenciada por a sua inclusão em bibliotecas como CCL, no padrão MPI e no suporte a linguagens paralelas.
O serviço de comunicação coletiva foi adicionado à API da plataforma HeMPS através da primitiva NoC Hermes.
Essa primitiva possibilita uma comunicação envolvendo uma tarefa origem e várias tarefas destinos através de uma única chamada de sistema.
As tarefas destino parâmetros são:
Message* msg:
Mensagem a ser enviada;
Toda a preparação das cópias da mensagem como localização dos PEs onde as tarefas destino estão alocadas, divisão e ordenamento dos PEs destinos é realizada por o destino não esteja alocada no sistema durante o processamento da primitiva, o microkernel solicita a alocação ao processador mestre.
A comunicação multicast também segue o protocolo de comunicação read request (Seção 3.2).
Portanto, o PE origem do multicast só inicia a transmissão após receber a requisição da mensagem de todas as tarefas destino.
A integração do multicast dual-path na plataforma HeMPS apresenta uma limitação em relação a o número de tarefas destinatárias de uma mensagem multicast.
Esta limitação deve- se ao fato de que o microkernel utiliza uma mesma estrutura de dado (struct da linguagem C) para descrever mensagens unicast e multicast.
Antes da integração, esse descritor de mensagem já era utilizado em diversas funções do microkernel no tratamento de mensagens unicast.
Em o descritor há um campo de 32 bits utilizado para indicar a (s) tarefa (s) destino da mensagem.
No caso de mensagens unicast esse campo interpretado como um valor inteiro que indica a tarefa destino.
No caso de mensagens multicast esse mesmo campo indica as tarefas destino a partir de uma codificação, onde cada bit corresponde ao identificador de uma tarefa do sistema.
A limitação oriunda do compartilhamento do descritor de mensagens é que uma mensagem multicast pode ter no máximo 32 tarefas destino, sendo que o identificador destas deve estar dentro de o intervalo 0 a 31.
Tal abordagem foi escolhida com o intuito de minimizar as mudanças na estrutura do microkernel e maximizar a reutilização de código (e.
g Avaliação A comunicação coletiva foi avaliada sobre diferentes instâncias da plataforma HeMPS.
Os experimentos realizados visam comparar o algoritmo multicast dual-path com a trivial implementação de multicast baseada no envio de múltiplas mensagens unicast.
As avaliações foram feitas utilizando um protocolo de coerência de cache e duas diferentes aplicações.
A primeira avaliação foi feita a partir de o protocolo de coerência de cache MSI.
A segunda avaliação foi feita utilizando uma aplicação produtor/ consumidores e a última foi realizada utilizando um multiplicador de matrizes distribuído que implementa o algoritmo de Fox.
Esta seção avalia os ganhos obtidos a partir de a utilização de mensagens multicast no protocolo de coerência de cache MSI (Modified Shared Invalid).
Para a realização desta avaliação, uma cache de dados L1 foi adicionada ao Plasma-IP SL, e um IP de memória cache de dados L2 foi adicionado ao MPSoC, como mostra a Figura 51.
A cache L1 é privada ao passo que a cache L2 armazena os blocos de memória compartilhados por os PEs.
O MSI é um protocolo de coerência de cache baseado em diretório.
Segundo esse protocolo um bloco compartilhado pode estar num dos três possíveis estados;
Modified, uma cópia do bloco foi modificada em alguma cache L1, portanto, a cache L2 não contém uma entrada válida desse bloco, Shared, zero ou mais caches L1 podem conter uma cópia idêntica de um bloco que está armazenado na cache L2 e Invalid, o bloco não é válido.
Esse protocolo foi implementado parte em hardware (cache controller ­ Plasma-IP SL) e parte em software (microkernel).
As principais funções do módulo cache controller são detectar miss/ hit e tratar operações de leitura/ escrita.
O microkernel realiza a substituição de blocos e operações de write-back.
A seguir são avaliados os ganhos obtidos a partir de a utilização de mensagens multicast na implementação das operações de invalidação de bloco e write-back, sobre uma instância 5x5 da plataforma HeMPS.
A versão do MSI que implementa essas operações utilizando mensagens multicast é chamada de OPT (optimized), ao passo que a versão suportando apenas mensagens unicast é chamada de No-OPT (no optimized).
Ambas as versões foram comparadas em termos de tempo e consumo de energia gastos nas comunicações entre PEs e cache L2 durante a execução das operações.
Para a avaliação de consumo de energia é adotado o modelo baseado em volume de energia no envio de um bit, numa transmissão fim-a-fim, entre dois pontos da NoC.
Ebit $= nhops* ESbit+* ELbit Onde:
ESbit, ELbit e nhops representam, respectivamente, o consumo de energia num roteador, nos fios de interconexão e o número de roteadores por onde o bit passou.
O modelo de energia foi calibrado usando a tecnologia St/ IBM CMOS 65 nm a 1 V, adotando clock-- gating, 100 MHz de frequência e taxa de injeção de 10% da largura de banda dos enlaces.
A ferramenta PrimePower gera os valores de potência e energia usados na equação 1.
Após um acesso de leitura à cache L1 resultar num miss, o PE tem de enviar à cache L2 uma requisição de leitura a um bloco modificado.
A o receber essa requisição, a cache L2 envia uma requisição de write-back ao PE que mantém o acesso exclusivo ao bloco requisitado.
Esse PE então executa o write-back enviando uma cópia do bloco à cache L2 e outra cópia ao PE que requisitou a leitura.
Esta seção avalia os ganhos obtidos na requisição de leitura a partir de a utilização de mensagens multicast na operação de write-back.
Os experimentos realizados variam a distância em hops entre o PE que requisita a leitura de um bloco e a cache L2.
Figura 52 apresenta os resultados de consumo de energia.
A utilização de mensagens multicast (OPT) reduziu em média 12% o consumo de energia.
Entretanto, a utilização de múltiplas mensagens unicast (No-OPT) apresentou um desempenho pouco superior em termos de tempo (em média 30 ciclos de clock mais rápida).
Isso pode ocorrer quando o custo de preparação da mensagem multicast não é compensado devido a o baixo número de destinos, dois nesse caso (L2 e PE que mantém o bloco).
Além disso, o caminho tomado por a mensagem multicast pode ser muito longo em relação a as unicasts, visto que ela utiliza um único caminho para atingir todos destinos.
Essa aplicação experimental consiste num produtor que envia uma mensagem multicast e em seguida espera uma resposta (acknowledge) de cada consumidor.
Os consumidores (destinos) recebem a mensagem e em seguida enviam a resposta ao produtor.
A Listagem 2 mostra o núcleo do código do produtor.
Dois tempos são capturados:
T_ Send, corresponde ao tempo necessário para o produtor processar o envio da mensagem e t_ Ack, corresponde ao tempo necessário para todos consumidores receberem a mensagem e confirmarem a recepção.
Os experimentos foram realizados sobre uma instância 5x5 da plataforma HeMPS, fixando o produtor no centro da malha e variando o número de consumidores ao seu redor, implicando sempre o envio de duas cópias da mensagem.
Listagem 2 ­ Código do produtor.
/* Gets the initial time*/&amp; ifdef Dual_ PATH/* Sends the message using the dual-path algorithm*/ Multicast(&amp; msg, target_ list, TARGETS);
Send(&amp; msg, target_ list, HIGH);&amp;
endif for/* Receives the acknowledgements*/ Receive(&amp; msg, target_ list);
O multiplicador de matrizes distribuído é uma implementação do algoritmo de Fox.
Esse algoritmo foi desenvolvido para realizar a multiplicação de matrizes de maneira distribuída em multicomputadores.
O algoritmo assume matrizes de ordem n e um número de tarefas t onde a raiz quadrada de t divide n.
As matrizes a serem multiplicadas são particionadas em submatrizes de ordem n/ t e atribuídas às tarefas.
O particionamento segue um padrão de tabuleiro de damas.
A Figura 57 ilustra duas matrizes (A e B) de ordem 12 (n) a serem multiplicadas, particionadas entre 9 tarefas (t).
T21 e T22as tarefas na borda norte enviam para as tarefas na borda sul na mesma coluna).
As tarefas origem do broadcast em cada linha variam a cada iteração.
Inicialmente o broadcast é feito por as tarefas na diagonal principal e a cada iteração a diagonal é deslocada (com rotação) para a direita, indicando as novas tarefas origem.
O algoritmo de Fox foi implementado sobre a plataforma HeMPS em duas versões.
Uma utiliza o multicast dual-path para fazer o broadcast da submatriz de A enquanto a outra o faz a partir de múltiplas mensagens unicast.
Foram realizadas multiplicações de matrizes de ordem 33, 44 e 55, utilizando grids de tarefas de ordem 3, 4 e 5, respectivamente.
Os grids de tarefas foram mapeados sobre instâncias da plataforma HeMPS de mesma ordem.
Em todos experimentos cada tarefa é responsável por a multiplicação de submatrizes de ordem 11.
A Tabela 7 apresenta os tempos em ciclos de clock para a conclusão das multiplicações e os ganhos obtidos a partir de o emprego do multicast dual-path.
No caso de o grid 3x3, a versão com múltiplos unicasts tem um desempenho superior, pois o número de destinos do broadcast é pequeno (dois destinos por linha).
A medida que o grid aumenta, e consequentemente o número de destinos do broadcast, o multicast dual-path vai apresentando ganhos crescentes.
Devido a a limitação discutida na seção 6.2, não foi possível realizar experimentos com grids de tarefas maiores.
Entretanto, visto que a submatriz difundida em broadcast pode ser considerada uma mensagem grande, os ganhos proporcionados por o multicast dual-path em grids maiores devem seguir os resultados da Figura 56.
Este trabalho originou- se a partir de a união natural de dois tópicos de pesquisa estratégicos que direcionam a evolução dos sistemas embarcados;
Redes e sistemas multiprocessados intra-chip (NoCs e MPSoCs).
Visto que essas duas áreas evoluíram separadamente por anos, a integração deve considerar o melhor dos dois mundos;
Tese a partir de os serviços de comunicação diferenciados.
A implementação de mecanismos específicos no nível da rede e o suporte a estes no nível de software a partir de uma API de comunicação consolidaram a integração entre NoCs e MPSoCs.
Os mecanismos implementados na NoC que dão suporte aos serviços de comunicação diferenciados são controlados por o cabeçalho dos pacotes.
Campos específicos no cabeçalho de um pacote expõem tais mecanismos a níveis superiores (IP).
Diferente de diversos trabalhos relacionados, essa abordagem permite o acesso aos mecanismo sem a necessidade de interfaces de rede específicas, as quais os expõem através de registradores mapeados em memória.
As interfaces de rede a serem utilizadas com esta NoC podem simplesmente fazer o papel de uma camada de adaptação entre as interfaces de comunicação ou entre as frequências de operação da rede e do IP no caso de MPSoCs GALS.
A NoC em si pode ser vista como um IP de comunicação stand alone pronto para ser empregado em qualquer projeto, dando ao projetista a liberdade de criar suas próprias interfaces de rede, uma vez que diferentes IPs possuem diferentes interfaces.
A metodologia de integração proposta nesta Tese foi implementada em software no microkernel (HeMPS e Hs-Scale).
A ideia é capturar o serviço de comunicação a ser utilizado por a aplicação a partir de as primitivas da API, e durante o processamento destas, o microkernel configura o cabeçalho do pacote de acordo com o serviço.
Tal metodologia é simples e de baixo custo em termos de memória, uma vez que é implementada em software.
A mesma metodologia pode ser implementada numa biblioteca de funções específica, caso não haja um sistema operacional ou este não possua código aberto.
Além disso, essa metodologia pode ser implementada por qualquer processador utilizando uma linguagem de programação de alto nível (e.
g C ou C+).
O microkernel tomado como ponto de partida para a realização deste trabalho tinha um tamanho de 15 KB.
Após a inclusão do suporte aos serviços de comunicação diferenciados e o escalonamento de tarefas baseado em prioridades o tamanho atual é 22 KB.
Em termos percentuais, pode- se dizer que o aumento de 46,6% (7 KB) é considerável, entretanto o microkernel como um todo continua com um tamanho reduzido e adequado a sistemas embarcados.
Em termos de hardware, o maior impacto foi relativo à duplicação dos canais físicos para suportar o serviço de comunicação baseado em prioridades.
Os demais serviços de comunicação implementados não exigem a adição/ replicação de módulos hardware específicos à arquitetura do roteador.
Os mecanismos que dão suporte a eles são implementados a partir de pequenas alterações nos módulos já existentes na arquitetura do roteador, acarretando baixo custo de área.
Caso o roteador alvo já tenha os canais físicos replicados, a implementação de um mecanismo de alocação baseado em prioridades também tem baixo custo.
Além de aumentar a largura de banda agregada do roteador, múltiplos canais físicos podem ser explorados também para tolerância a falhas.
As avaliações realizadas mostraram a eficiência dos serviços de comunicação implementados e os benefícios obtidos controlando- os em software a partir de a API.
Tal controle oferece ao programador meios para explorar o espaço de projeto em busca dos melhores resultados, a fim de satisfazer os requisitos das aplicações.
Tipicamente, os serviços de comunicação implementados proporcionam ganhos em situações de tráfego mais elevado onde há concorrência por recursos da NoC.
Isso mostra que em situações onde a carga da rede é baixa, esta pode operar numa frequência inferior à dos IPs, com o propósito de elevar o tráfego do ponto de vista da rede.
Assim ela passa a consumir menos energia e os serviços de comunicação podem ser utilizados eficientemente.
Os serviços de comunicação foram avaliados separadamente, entretanto, todos estão disponíveis na API de comunicação da plataforma HeMPS, podendo ser utilizados concomitantemente por o programador das aplicações.
Os resultados obtidos a partir de simulações RTL agregam valor a estes, uma vez que o comportamento simulado é muito próximo de o apresentado por uma implementação física.
Apesar de as simulações terem considerado instâncias pequenas de MPSoC (e.
g Um significativo passo foi dado em relação a a versão da plataforma HeMPS utilizada como ponto de partida para a realização deste trabalho.
Além de as implementações acrescentadas ao longo de a Tese, muitos bugs foram resolvidos, chegando- se a um nível mínimo de estabilidade do sistema que habilita a sua distribuição, de maneira que outros grupos de pesquisa além de o GAPH possam ajudar a enriquecer- la e tornar- la ainda mais estável, desenvolvendo novas aplicações e relatando eventuais bugs.
A implementação de aplicações a partir de algoritmos paralelos (troca de mensagens) ou grafos de tarefas utilizando a API não apresenta grandes dificuldades.
A plataforma HeMPS é uma fonte de conhecimento que envolve conceitos de diversas áreas da engenharia e da computação.
Durante o período do doutorado foi possível exercitar a abrangência multidisciplinar envolvida no projeto de MPSoCs em vários níveis de abstração como:
Programação VHDL e redes de computadores, durante o desenvolvimento de novos serviços comunicação na NoC Hermes;
Sistemas operacionais, durante a implementação de novas primitivas de comunicação e escalonamento baseado em prioridades no microkernel da plataforma HeMPS;
Interface hardware/ software, durante o desenvolvimento de novos drivers;
Programação SystemC e arquitetura de computadores, durante o desenvolvimento de modelos abstratos de processadores e memórias, a fim de acelerar a simulação da plataforma HeMPS;
Programação paralela e arquiteturas paralelas durante o desenvolvimento de aplicações;
Programação orientada a objetos, durante o desenvolvimento do framework de geração e depuração da plataforma HeMPS (Apêndice B ­ HeMPS Generator).
Trabalhos futuros As garantias flexíveis oferecidas por serviços de comunicação como o baseado em prioridades (Capítulo 4) ou com roteamento diferenciado (Capítulo 5) podem ser severamente afetadas quando muitas aplicações compartilham os mesmos serviços simultaneamente.
Tal situação foi evidenciada no experimento com o decodificador áudio/ vídeo apresentado na Seção 4.3.2 (Tabela 3).
Em um cenário onde todas as aplicações transmitiam fluxos de alta prioridade, foi necessário mudar o serviço de comunicação do pipeline de vídeo para um baseado em conexão, a fim de que o decodificador atingisse novamente a vazão mínima exigida.
Tal mudança foi simples, entretanto, realizada manualmente a partir de uma alteração mínima no código fonte da aplicação.
Em sistemas dinâmicos onde todo momento aplicações são alocadas/ desalocadas, certos serviços de comunicação diferenciados são necessários apenas quando há concorrência por os recursos da infra-estrutura de comunicação.
Em este caso seria desejável o próprio sistema realizar a monitoração do desempenho das aplicações e dinamicamente adaptar o serviço de comunicação de maneira autônoma, baseado apenas nas restrições especificadas por o programador em tempo de projeto.
Tais restrições podem ser obtidas através de um traçado de perfil (profiling) da aplicação onde são estabelecidos limites de desempenho, como vazão, latência e jitter.
Dependendo do mapeamento de uma aplicação na plataforma, o seu desempenho geral pode ser afetado em decorrência da deterioração da comunicação de apenas algumas tarefas, devido a as dependências entre estas.
Portando, uma possível abordagem é realizar uma monitoração entre pares de tarefas comunicantes e ajustar o serviço de comunicação localmente, ao invés de interferir globalmente em toda a aplicação.
Tal monitoração e ajuste do serviço de comunicação podem ser implementados no microkernel como trabalhos futuros.
