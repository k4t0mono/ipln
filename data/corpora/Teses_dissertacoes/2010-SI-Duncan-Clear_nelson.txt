A indústria de software investe montantes de dinheiro em busca da melhoria de seus produtos e serviços.
Atualmente, os clientes estão cada vez mais exigentes e procuram fábricas que possuam um rigoroso controle de qualidade.
A qualidade é medida por meio de os modelos de qualidades adotados, como CMMI, Iso, IEC, de entre outros.
A exigência dos clientes faz as organizações selarem contratos que medem o nível da qualidade de seus serviços.
Esses contratos prevêem como sanções pesadas multas.
O cumprimento de prazos e custos é uma das exigências previstas nesse tipo de contrato.
A base para que se cumpram prazos e custos é a estimativa de esforço de desenvolvimento e, após a entrega do produto, o esforço para a manutenção do software.
O desafio dos pesquisadores está em apoiar a indústria de software com trabalhos na área de estimativas que possam tornar as mesmas mais precisas.
Além disso, as estimativas não devem onerar as equipes de software para não agregar mais custos aos projetos.
Esta tese é fruto de uma pesquisa realizada ao longo de quatro anos, dois de os quais atuando num projeto de manutenção de software pertencente a um grande banco governamental brasileiro.
O projeto era mantido por uma fábrica de software parceira do Programa de Pós-graduação em Ciência da Computação da Faculdade de Informática da PUCRS.
A pesquisa inspirou esta tese de doutorado que apresenta, como uma opção para a área de estimativas, um modelo de esforço em manutenção de software.
O modelo aqui apresentado apoia tanto a indústria de software como as pesquisas na área de estimativas.
Palavras-chave: Estimativas de Esforço;
Manutenção de Software;
Modelos Preditivos; Técnicas de Estimativas;
Modelo­E10. Esforço é provavelmente a mais popular métrica de software.
Ele é definido como a relação entre pessoa/ hora, dia, semana, mês ou ano.
Contudo, estimar o esforço é um dos principais desafios na área de estimativas de software.
Para se estimar o esforço é necessário conhecer outras medidas do software, como por exemplo o tamanho do projeto.
Em o mundo tangível, o tamanho é a medida que representa o volume ou a massa.
Em o mundo intangível, neste caso software, o tamanho é representado por linhas de código ou funcionalidades.
As medidas mais comuns para determinarem o tamanho de um software são Linhas de Código (LOC), Pontos por Função (FP) ou Pontos por Caso de Uso (UCP).
Essas medidas servem de base para a utilização de técnicas para as estimativas de esforço.
Estimar o esforço é uma atividade importante no desenvolvimento de software, pois ela é utilizada na composição de informações como custos e prazos, as quais são essenciais para o projeto.
Infelizmente, as técnicas de estimativas de esforço não produzem resultados satisfatórios, os erros nas estimativas parecem ser regra e não exceção.
Em boa parte dos projetos de software, as estimativas de esforço são baseadas em experiências passadas, onde dados de projetos anteriores e similares são analisados para se estimar o esforço de um novo projeto.
Todavia, estimativas utilizando esse tipo de técnica não se aplicam quando o novo projeto apresentar características diferentes dos anteriores.
Outrossim, as organizações que não coletam e armazenam adequadamente os dados de seus projetos anteriores têm dificuldades em estimar o esforço de novos projetos.
É por isso que, as organizações que utilizam modelos de qualidade, como o CMMI, SPICE e Iso, têm menos dificuldade para fazer- lo Com o crescente uso de computadores e software emergiu a necessidade de manutenção de software nas organizações.
A manutenção é um processo de modificação operacional no software, podendo ser:
Correção de erros, migração para uma nova tecnologia e plataforma, ou ainda, uma adaptação para que sejam levados em consideração novos requisitos.
A fase de manutenção de software é a mais trabalhosa e custosa, especialmente no caso de grandes sistemas de software, que têm um ciclo de vida mais longo.
Assim, para garantir o controle do processo de manutenção é igualmente necessário um planejamento que envolva as estimativas de tamanho, esforço e custos.
Existem várias técnicas para estimar o esforço no desenvolvimento de software.
Em geral, para se estimar o esforço de manutenção de software, a indústria aplica as mesmas técnicas de estimativas de esforço utilizadas para seu desenvolvimento.
Todavia, quando essas técnicas são utilizadas no contexto de manutenção, a precisão das estimativas tende a ficar comprometida.
Isso porque, o valor das métricas na fase de desenvolvimento de software não são os mesmos da fase de manutenção.
Por exemplo, o tamanho;
Uma das medidas base para as estimativas, pode ser distorcido por a reutilização de componentes, o que diminui o tamanho da manutenção à ser realizada.
As seções seguintes apresentam a caracterização do problema na área de estimativas de esforço, bem como a questão de pesquisa, seguida dos objetivos e da organização do trabalho.
Caracterização do Problema Em o estado da arte das estimativas de esforço em projetos de software, além de as poucas técnicas voltadas à manutenção de software, nota- se a utilização de técnicas de estimativas de esforço, específicas para o desenvolvimento de software, sendo igualmente utilizadas para estimar seu esforço de manutenção, como relata a Seção 2.7 do Capítulo 2.
De essa forma, podem aparecer distorções nos valores estimados, pois a manutenção de software possui algumas particularidades como:
Custo da alteração, tipo de manutenção, reutilização de código, de entre outros, que as técnicas de estimativas voltadas ao desenvolvimento não levam em consideração.
A revisão sistemática, apresentada no Capítulo 3, mostra o desafio de pesquisadores na busca de soluções para estimar o esforço de desenvolvimento de software com maior precisão.
Também percebe- se em ela a pequena quantidade de propostas específicas para manutenção de software, talvez por não ser dada a devida importância às características que a diferem do desenvolvimento de software.
Outrossim, nota- se que, a maior parte dos trabalhos na área negligenciam a utilização conjunta de mais de uma técnica para estimar de esforço, como sugerido por Tipicamente, as técnicas disponíveis para estimativas de esforço se baseiam em experiências de projetos anteriores, por meio de a coleta, armazenamento e análise de seus dados.
Muitas vezes, essas técnicas são calibradas com as atualizações dos dados de projetos mais recentes.
A calibragem é importante por tentar impedir a defasagem da técnica em relação a a realidade dos projetos em termos de avanços tecnológicos, de entre os quais se destacam:
Linguagem de programação, bancos de dados e processos de desenvolvimento de software.
A calibragem das técnicas de estimativas não é uma tarefa trivial que possa ser realizada sem demandar um esforço significativo.
Talvez, por esse motivo, as técnicas baseadas na expertise, como o Planning Poker e o Delphi, vêm se destacando nas estimativas de esforço na manutenção de software.
Se por um lado as técnicas baseadas na expertise são boas por a simplicidade e praticidade, por outro, elas possuem três fatores que prontamente as deixam em posição de desvantagem.
O primeiro de eles é a imprecisão das estimativas, já que tais técnicas são muito dependentes da experiência das pessoas.
O segundo fator é a dependência de conhecimento humano, já que os indivíduos mais experientes tornam- se essenciais para que se alcance boas estimativas e isso pode acarretar mais custo para o projeto com relação a contratar ou manter pessoas com o nível de experiência necessário.
E por fim, a oneração dos indivíduos, já que as tais técnicas requerem reuniões periódicas quando são realizadas e debatidas as estimativas.
As desvantagens relacionadas à prática de técnicas baseadas na expertise foram constatadas no dia a dia de um projeto de manutenção de software.
O projeto pertencia a um grande banco estatal brasileiro e envolvia um orçamento bastante representativo na empresa parceira, como relata e seu controle era bem rigoroso porque previa multas pesadas caso orçamentos e prazos não fossem devidamente cumpridos.
Por fim, a Seção 1.2 apresenta a questão de pesquisa na tentativa de suprir os problemas da área de estimativas aqui apresentados.
Questão de Pesquisa Em meio às necessidades conhecidas da área de estimativas de esforço em manutenção de software, remete- se a seguinte questão de pesquisa:
&quot;Como estimar esforço de trabalho em manutenção de software, doravante denominado ETMS, de forma a alcançar boas aproximações em relação a o esforço real, sem depender de uma única técnica de estimativas e da expertise e, ainda, possibilitar a calibragem com dados de estimativas anteriores para que não ocorram defasagens dos modelos preditivos utilizados?»,
onde entende- se que boas aproximações é um valor percentual mínimo de erro nas estimativas, quando comparado com o esforço real, aceitável por a organização.&amp;&amp;&amp;
Objetivos As sessões abaixo apresentam os objetivos traçados para composição desta tese.
Esta tese propõe um modelo para a melhoria das estimativas de esforço de trabalho num projeto de manutenção de uma fábrica de software, por meio de a revisão da literatura, da revisão sistemática e de um estudo de caso exploratório.
Para atingir o objetivo geral e, ainda, responder a questão de pesquisa, os seguintes objetivos específicos foram elaborados:·
Explorar os trabalhos fundamentais da área de estimativas de esforço em projetos de software;·
Realizar uma revisão sistemática para avaliar trabalhos correlatos, a fim de situar a pesquisa em relação a o estado da arte na área;·
Realizar um Estudo de Caso Exploratório num projeto de uma fábrica de software a fim de levantar as necessidades da prática das estimativas de esforço em manutenção de software;·
Propor um modelo para estimativas de esforço em manutenção de software que responda a questão de pesquisa apresentada na seção 1.2, atenda as necessidades da organização, identificadas no Estudo de Caso do Capítulo 4 e, ainda, esteja alinhado com a literatura seminal, Capítulo 2 e com as recentes pesquisas na área, Capítulo 3;·
Realizar experimentos aplicando o modelo proposto sobre os dados reais de um projeto a fim de rejeitar a hipótese nula e comprovar a hipótese alternativa formuladas para tal;&amp;&amp;&amp;·
Analisar o desempenho dos resultados obtidos com os experimentos, e tirar as devidas conclusões sobre o modelo proposto.
Metodologia Para o desenvolvimento desta tese foram realizados:
Um estudo de caso exploratório, com o intuito de identificar as dificuldades da área de estimativas num projeto de software de uma organização;
Uma revisão da literatura para identificar aspectos vistos como importantes nos trabalhos seminais da área de estimativas, onde tais aspectos serviram de base para o alinhamento do estudo de caso com a literatura;
Uma revisão sistemática para identificar o estado da arte das estimativas de manutenção de software segundo os aspectos identificados nos trabalhos seminais;
Uma proposta de modelo de estimativas alinhado com a literatura seminal, com o estado da arte e com um ambiente real de estimativas em manutenção de software (estudo de caso exploratório);
Por fim, um experimento com dados reais de um projeto para a verificação e análise do modelo proposto.
Organização do Trabalho Este trabalho está organizado da seguinte forma:
O Capítulo 1 faz uma breve introdução sobre as estimativas de esforço em desenvolvimento e na manutenção de software apresentando a caracterização do problema, a questão de pesquisa, os objetivos a serem alcançados para a conclusão da pesquisa e a organização do trabalho;
O Capítulo 2 faz uma revisão da literatura básica na área de estimativas de esforço para projetos de software apresentando seus principais trabalhos;
O Capítulo 3 faz uma revisão sistemática para avaliar trabalhos correlatos;
O Capítulo 4 faz um relato dos trabalhos realizados na fábrica de software da empresa parceira do grupo de pesquisa do autor;
O experimento e os resultados obtidos in-vitro com os dados reais de um projeto da empresa parceira para validar o Modelo­E10;
o Capítulo 7 apresenta as considerações finais da pesquisa seguida da contribuição científica, da contribuição para o mercado, da sugestão de trabalhos futuros e das considerações finais;
Por fim, são apresentadas as referências bibliográficas utilizadas e os seguintes apêndices:
Apêndice A ­ Protocolo do Estudo de Caso Exploratório.
Apêndice B ­ Proposta de Classificação de Documento para o COCOMO 2.
0. Apêndice C ­ Complexidade de Documentos.
Este capítulo apresenta os conceitos básicos e os trabalhos seminais da área de estimativas de esforço em projetos de software.
Algumas técnicas são amplamente utilizadas no mercado, e outros ainda estão apenas no meio científico.
Classificação das Técnicas de Estimativas Esta pesquisa adota a taxonomia sugerida por entender que esta, além de ser a primeira proposta de taxonomia na área, é a mais adequada ao estado da arte das estimativas classificando, se não todas, boa parte das técnicas existentes na literatura.
Assim, as técnicas de estimativas são classificadas como se segue:·
Empíricas e Compostas:
Classe que engloba principalmente as técnicas tradicionais, como COCOMO 81 e o COCOMO 2, que vêm do acrônimo de Constructive Cost Model.
São técnicas calibradas com dados de projetos de software anteriores e que, com a aplicação de diferentes equações, indicam valores estimados para esforço, prazo e custo;·
Dinâmicas: Classe de técnicas que consideram as mudanças nas estimativas de esforço e custo com o passar do tempo da realização do projeto.
Essas técnicas são geralmente representados por equações diferenciais de primeira ordem, como a Equação do Software proposta por Akiyama em;·
Baseadas em expertise:
Classe de técnicas que foca na análise de especialistas, ou ainda, adota estratégias de dedução sobre uma base de dados históricos, onde regras de inferência ajudam na escolha dos melhores valores de estimativas;·
Orientadas a Aprendizado de Máquina (OAM):
Classe que se utiliza de técnicas das redes neurais, raciocínio baseado em casos, lógica fuzzy e árvores de decisão e regressão como estratégia para realização das estimativas;·
Baseadas em Regressão:
Classe das técnicas comumente utilizados, sendo muitas vezes incluídos dentro de técnicas maiores que utilizam a regressão como mais um fator para o cálculo das estimativas.
Geralmente, técnicas pertencentes a esta classe se dividem em regressão simples e regressão robusta.
É importante salientar que alguns autores utilizam o termo &quot;modelo de estimativas», outros utilizam o termo &quot;técnicas de estimativas&quot;;
Já outros utilizam &quot;abordagens de estimativas».
Sobretudo, esta pesquisa adota o termo &quot;técnica de estimativas «por entender que o termo &quot;modelos de estimativas «é a abstração da aplicação das diferentes técnicas de estimativas, conforme, descartando assim o termo &quot;abordagem».
Empíricas e Compostas A primeira versão do COCOMO, o COCOMO 81, foi proposta por o Dr. Barry Boehm e derivado da coleta de dados de 161 projetos de software, posteriormente calibrados por meio de um modelo estatístico bayesiano.
O COCOMO 81 foi considerado a técnica de estimativas de custo mais bem sucedido da década de 80.
Porém, com o advento das linguagens orientadas a objetos e o desenvolvimento de novos processos de desenvolvimento de software, iniciaram- se esforços para a criação de uma técnica capaz de suprimir as dificuldades desta com relação a esses novos desafios.
O COCOMO é baseado numa série de direcionadores de custos que auxiliam na precisão das estimativas.
Em sua primeira versão é levado em consideração apenas o desenvolvimento de software.
Em o COCOMO 2, versão mais evoluída da técnica, foi introduzido o suporte a componentes reusáveis, além de o reconhecimento de diferentes abordagens de desenvolvimento de software como:
O COCOMO 2, basicamente, é subdividido de acordo com a fase em que se situa o processo de desenvolvimento de software:
O funcionamento básico do COCOMO 2, independentemente da sua subdivisão e se dá por meio de a utilização de medidas de tamanho como FP ou LOC.
A utilização do COCOMO 2 está sujeita às seguintes limitações:·
os direcionadores de custo são baseados em tecnologias envolvidas nos projetos de software e a datação da sua última calibragem é do ano 2000.
Novas tecnologias surgiram de lá para cá, o que sugere que a calibragem de seus direcionadores esteja desatualizada;
E· a alta complexidade envolvida em sua utilização devido a o grande número de variáveis externas e direcionadores de custo para o cálculo das estimativas, tornando- o pouco amigável.
Embora à primeira vista o COCOMO 2 não pareça ser muito amigável, existem diversas vantagens que devem ser consideradas quando de a escolha de uma técnica de estimativas· é bem documentado;·
é disponibilizado livremente, podendo ser incorporado em diferentes softwares para realização de estimativas;·
endereça questões como reutilização de código e é relativamente flexível para diferentes projetos existentes;·
independente do processo de desenvolvimento de software, embora baseado no processo espiral.
Em contraponto com o exposto acima, existem duas desvantagens críticas do COCOMO 2· pode ocorrer imprecisão nas estimativas caso os projetos a serem estimados não possuam características similares aos projetos utilizados na sua calibragem;·
alta complexidade devido a a agregação de um número enorme de variáveis no cálculo das equações, tornando proibitiva sua adoção em projetos de pequeno porte;·
é dependente de calibragem, processo não menos complexo e que tem influência direta no resultado das estimativas.
Dinâmicas A equação do software, proposta por Akiyama em, é uma técnica dinâmico, derivado da curva de Putnam­Norden­Rayleigh, que assume uma distribuição específica de esforço sobre o projeto de desenvolvimento de software.
A equação deriva de dados de produtividade de mais de quatro mil projetos de software atuais, e o valor estimado é dado por a Equação 2.1, onde:
E é o esforço pessoa/ mês ou pessoa/ ano;
T é a duração do projeto em meses ou ano;
B é um fator de características especiais, apresentado na Tabela 2.1;
e P é uma constante que representa a produtividade.
A constante P, da Equação 2.1, é o parâmetro de produtividade que indica:·
o processo de maturidade e gerenciamento de práticas;·
a utilização das boas práticas da engenharia de software;·
o nível de utilização das linguagens de programação;·
o estado do ambiente de software;·
a habilidades de experiência do time;
E· a complexidade da aplicação.
Os valores típicos podem ser P $= 2000 para desenvolvimento de aplicações de tempo real;
P $= 10000 para sistemas de software em telecomunicações;
P $= 28000 para sistemas de software em negócios.
O parâmetro de produtividade pode ser derivado de dados históricos locais de esforço de projetos anteriores.
É importante observar que a equação tem dois parâmetros independentes;
Embora pareça simples, a utilização da equação apresenta algumas limitações, sendo elas:
I) dificuldade das estimativas de tamanho;
E ii) a aparente ausência de um método de calibragem de suas constantes, o que faz com que não sejam utilizados os dados atualizados de um projeto.
Baseadas em Expertise A técnica de expertise do Delphi foi desenvolvido por a Rand Corporation, no final da década de 40, como forma de realizar predições de eventos futuros.
Mais recentemente, tal abordagem vem sendo utilizada como forma de guiar um grupo determinado de indivíduos a um consenso sobre determinado assunto.
O funcionamento do Delphi se dá através dos seguintes passos:·
o coordenador apresenta aos indivíduos especialistas informações relevantes sobre o projeto, bem como uma especificação inicial do mesmo;·
o coordenador promove uma reunião do grupo de indivíduos especialistas, quando são discutidas as estimativas;·
os especialistas preenchem formulários indicando suas estimativas individuais para o esforço total do projeto e do esforço total do desenvolvimento.
Os valores indicados por os especialistas estão contidos num intervalo:
Valor limite inferior, valor provável e valor limite superior;·
o coordenador organiza um relatório contendo as estimativas do grupo e as estimativas individuais, tornando público este relatório;·
o coordenador convoca uma reunião durante a qual os especialistas discutem as estimativas atuais.
Esse processo é iterativo até que haja consenso entre os especialistas.
As estimativas do grupo são calculadas como média ponderada das estimativas individuais, como mostra a Equação 2.2:
A variância das estimativas individuais é definida como apresenta a Equação 2.3:
Estimativas $= limitesuperior+ limiteinf erior O Delphi mostra- se útil quando há necessidade de estimar valores sem o apoio de grandes volumes de dados empíricos.
Embora limitado, a técnica pode servir de apoio a outras técnicas, como foi o caso de sua utilização na calibragem Bayesiana dos dados do COCOMO 2 e na especificação de informações prioritárias e necessárias à calibragem.
Informações adicionais da calibragem Bayesiana do COCOMO 2 podem ser encontradas em.
Outra técnica baseada em expertise é o Planning Poker, largamente utilizado e divulgado por a metodologia ágil Scrum.
O termo Planning Poker foi criado por James Grenning e popularizado por Mike Cohn.
O Scrum prega que a atividade de estimar deve ser realizada por todos os membros envolvidos no processo, durante uma reunião de planejamento, que define um conjunto de tarefas prioritárias a serem realizadas num período de duas a quatro semanas após a reunião;
A granularidade utilizada na realização das estimativas para cada tarefa no Planning Poker, ao contrário de o Delphi, baseia- se numa série numérica que visa limitar o número de escolhas possíveis dos participantes buscando agilidade e diminuição no tempo gasto durante as estimativas.
As estimativas se baseiam numa série de Fibonacci, como apresenta a Equação 2.4.
F (n) $= F+ F (n -- 2) se outros casos.
Cada número desta série numérica é escrito em cartas montando- se um baralho, utilizado durante a reunião de planejamento.
Este baralho também possui duas cartas coringa, sendo uma composta por um ponto de interrogação, que quando utilizada especifica que o membro não consegue estimar a tarefa por motivo a ser explicado na reunião, e uma com a figura de uma xícara de café, que demonstra a necessidade de um descanso para a continuação da reunião.
Assim como no Delphi, o Planning Poker onera as equipes de desenvolvimento, pois estas necessitam deslocar seus membros para reuniões onde são estimados os valores empíricos das demandas.
Realizar as estimativas de forma empírica pode trazer, de entre outros, dois visíveis problemas:
I) falta de precisão nas estimativas de prazos, onde estes quando mal mensurados podem causar aumento da pressão na equipe e, consequentemente, desgaste de seus membros por trabalhar em demasia para cumprir- lo;
E ii) dependência do conhecimento humano, o que se torna prejudicial para as estimativas de esforço, se a rotatividade de pessoal for alta.
Orientadas a Aprendizado de Máquina As técnicas para as estimativas de software baseadas em Aprendizado de Máquina (ML­Machine Learning), representam boas alternativas às técnicas tradicionais, as quais são baseadas em regressão, técnicas estatísticas, ou ainda, na expertise humana.
O método para a criação de modelos de ML é a exploração dos dados históricos do domínio, feita por algoritmos específicos na tentativa de formular ou inferir um conjunto de regras que permitam a dedução de valores futuros.
Algumas diferentes abordagens de ML para o desenvolvimento de modelos preditivos de software são detalhadas nas seções:
2.5.1 Redes Neurais;
2.5.2 Sistemas Fuzzy;
2.5.3 Raciocínio Baseado em Casos;
E 2.1 Árvores de Classificação e Regressão.
As redes Backpropagation Trained Feed­Forward ou, simplesmente, redes backpropagation, são comumente utilizadas quando o assunto é técnica de estimativas de métricas de software.
Essas redes são implementadas através da seleção de uma arquitetura apropriada de neurônios, que inclui, de entre outras coisas, a definição de quantas camadas de neurônios são utilizadas, o número de neurônios em cada camada e como estes se conectam uns com os outros.
É necessário, também, definir uma função de transferência, que mapeia a entrada recebida por o neurônio e propaga a saída correspondente.
Assim como toda técnica de ML, a rede deve utilizar dados históricos para seu aprendizado.
Através de um conjunto de treinamento, a rede aprende por meio de o ajuste de seus pesos, de forma a minimizar a distância entre a saída estimada e a saída real.
Esse processo ocorre iterativamente até que o poder de generalização da rede seja considerado ótimo.
Embora seja considerada uma técnica robusta para construção de modelos preditivos, reforça o fato de que as redes neurais não estão imunes aos problemas que decaem sobre as técnicas estatísticas, como a existência de outliers, instâncias vistas como excepcionais à amostra, colinearidade entre as variáveis, valores incompletos ou perdidos.
Outro problema identificado é o funcionamento dito caixa preta das redes, pois as mesmas não detalham informações de como chegaram ao resultado final.
Esse comportamento é tido como crítico para situações em que se deseja fazer uma análise causal, entendendo e conhecendo as particularidades que levaram determinada métrica a atingir certo valor.
Basicamente, um sistema fuzzy é um mapeamento de valores em termos linguísticos, por exemplo, &quot;muito baixo», &quot;baixo», &quot;alto «e &quot;muito alto «para um conjunto de valores de variáveis correspondentes.
A entrada do sistema fuzzy pode ser tanto numérica como linguística, assim como o mesmo pode ser dito para a saída.
Em o contexto de métricas de software, um sistema fuzzy pode ser entendido como o todo de três componentes básicos:·
Funções de mapeamento de domínio:
Funções que definem os intervalos de valores que farão parte de determinada categoria;·
Base de regras:
Conjunto de regras que podem ser obtidas através dos dados históricos do projeto ou da visão do especialista sobre o domínio, que realizará a conexão entre as funções de mapeamento de domínio de entrada para as funções de mapeamento de domínio de saída;·
Processo de defuzzyficação:
Como várias funções de mapeamento de domínio de saída são possíveis, deve haver um componente do sistema responsável por a definição de uma única categoria ou valor numérico de saída do sistema.
Este componente é chamado de processo de defuzzyficação.
A vantagem da utilização de sistemas fuzzy para estimativas de software é sua fácil compreensão, devido a o uso de termos linguísticos, fazendo com que o mesmo possa ser analisado e criticado por pessoas sem conhecimento ou treinamento prévio.
Como desvantagem, a dificuldade de especificação de um sistema que permita uma alta precisão de resultados mantendo uma interface interpretável, onde geralmente, sistemas mais complexos precisam de mais regras, levando a um aumento de complexidade e decréscimo de poder de interpretação.
O raciocínio baseado em casos é um método de armazenar observações (dados históricos do projeto, no contexto de estimativas), e utilizar- las quando de a identificação de uma nova observação, através da recuperação das observações que mais se aproximam da mesma, de forma a permitir uma resolução satisfatória do novo problema.
Um sistema de raciocínio baseado em casos deve possuir os seguintes componentes:·
Pré-processador: Responsável por a preparação dos dados de entrada do sistema;·
Função de similaridade:
Responsável por a identificação de casos similares;·
Módulo de predição:
Responsável por o fornecimento do valor de saída estimado;
E· Atualizador de memória:
Responsável por a agregação do novo caso à base de casos, caso seja necessário.
A premissa básica deste método, no contexto de estimativas de software, é a simulação de como um especialista utiliza seu conhecimento de projetos anteriores para indicar os valores estimados de determinada métrica.
O problema dessa técnica é que os projetos têm que ter a mesma característica para que as estimativas tenham uma boa proximidade do real.
Há bons resultados dessa técnica nas estimativas de custos em projetos de desenvolvimento de software com característica web hypermedia Árvores de decisão e de regressão são conceitos similares, mas diferem na representação do atributo que se deseja prever.
Ambas se utilizam de um conjunto de dados previamente conhecidos, induzindo as regras necessárias para classificarem esses dados.
Existem vários métodos para a construção dessas árvores.
Porém, estes são, em sua grande maioria, uma variação de uma mesma estratégia top-down.
Essa estratégia consiste da análise de qual atributo dos registros de dados melhor divide o conjunto de dados em subpopulações disjuntas.
De entre as abordagens utilizadas para a realização dessa divisão estão:
O cálculo do erro médio quadrado, o cálculo de entropia, de entre outros.
Uma árvore de decisão contém nos seus nodos folha, o valor do atributo que se pretende prever classificado como uma categoria (rótulo), enquanto uma árvore de regressão vai utilizar funções lineares em cada nodo folha para geração de um valor contínuo, dentro de um intervalo de valores possíveis.
Para que essas árvores sejam capazes de gerar um modelos preditivos satisfatórios e generalizáveis, é necessário um conjunto de dados para treinamento, que inclui o valor do atributo alvo, e um conjunto diferente para testes, onde o atributo alvo é omitido.
A Figura 2.1 mostra uma árvore de regressão utilizada para estimativas de tempo médio de desenvolvimento num projeto de software.
As árvores de regressão são mais utilizadas em métricas de software do que as de decisão.
Isso é dado por a própria necessidade que o domínio impõe de obtenção de resultados numéricos.
Além de serem utilizadas para estimar esforço, as árvores de regressão também são utilizadas para estimarem defeitos.
A vantagem em se utilizar as árvores de regressão é que elas são simples de serem aplicadas sobre um conjunto de dados, já que existem várias ferramentas que as implementam, como o WEKA por exemplo.
Existem duas desvantagens em se utilizar essas árvores, a primeira de elas está relacionada à facilidade de compreensão, onde há uma dependência do número de níveis e nodos da árvore e quanto mais níveis e nodos a árvore tiver, menos compreensível ela se torna.
Outra desvantagem é que, por depender de dados do projeto, a árvore é sensível à outliers, isso quer dizer que a qualidade dos dados é importante para que se obtenha bons resultados com essa técnica.
Regressão Estatística Uma reta de regressão resume a relação entre duas variáveis, onde uma de elas ajuda a explicar ou predizer a outra.
Como se tratam de duas variáveis, seu grau de correlação deve ser calculado e, quanto maior esse grau, maior é a influência da variável explicativa na variável resposta.
Sendo assim, uma reta de regressão é uma linha, traçada sobre um gráfico de dispersão, que descreve uma variável de resposta y de acordo com o comportamento de uma variável explicativa x.
Para padronizar a forma de visualização da regressão, usa- se uma reta de regressão de mínimosquadrados, onde esta é uma reta que torna menor possível a soma dos quadrados das distâncias verticais dos pontos observados à reta.
Para se achar uma reta de mínimos-quadrados faz- se necessário encontrar as médias e desvios padrões das duas variáveis, bem como sua correlação.
Os indivíduos têm dados de uma variável explicativa x e uma variável de resposta y.
A partir de os dados deve- se calcular as médias x e y e, ainda, os desvios padrões sx e sy das duas variáveis e, também, a correlação r.
A reta de regressão de mínimos-quadrados é dada por a Equação 2.5, onde y^ (lê- se &quot;y «chapéu) e fornece uma resposta preditiva.
A Figura 2.2 apresenta um exemplo do gráfico resultante da aplicação da regressão de mínimos-quadrados num determinado conjunto de dados.
Com declividade dada por a Equação 2.6, b $= r sy sx Com intercepto dado por a Equação 2.7.
Após traçar a reta de regressão pode haver a necessidade de melhorar a correlação r entre as variáveis.
Isso é feito a partir de o ajuste dessa reta, também chamado de limpeza dos dados.
Uma técnica de limpeza é a retirada dos valores que se encontram distantes da linha de tendência traçada sobre o eixo x de um gráfico de resíduos, onde o gráfico de resíduo é um gráfico de dispersão dos resíduos de regressão versus a variável explicativa.
Sua função é ajudar no ajuste de uma reta de regressão, e o resíduo é dado por a Equação 2.8.
A regressão é amplamente aplicada em vários domínios de conhecimento.
Existem diversos trabalhos envolvendo a regressão linear para estimativas em software.
Contudo, deve- se ter alguns cuidados para a utilização da regressão nas estimativas de desenvolvimento de software (PDS), isso porque, talvez não esteja explícita uma correlação linear entre os dados, mas sim, uma correlação exponencial.
Assim, as variáveis do modelo devem ser cuidadosamente selecionadas e, além disso, utilizar a regressão faz com que o modelo preditivo tenha uma forte dependência da qualidade dos dados e seja sensível a outliers.
As seguintes situações que, quando simultâneas, tornam fortemente recomendável o uso da regressão:·
quando o projeto dispõe de muitos dados, aumentando o grau de liberdade disponível e permitindo a identificação de padrões nos dados;·
quando os dados são bem comportados, no sentido estatístico da palavra, entende- se que não existe um número significativo de outliers;·
quando um número reduzido de variáveis independentes é suficiente para estimar linearmente a variável dependente, de forma a se ter um resultado interpretável;·
quando não existem valores faltantes das variáveis independentes;·
quando as variáveis independentes são todas contínuas ou todas discretas, pois não existem técnicas estatísticas que permitam a manipulação dos dois tipos de variáveis simultaneamente;·
quando as variáveis independentes não são correlacionadas entre si, pois variáveis que possuem alto grau de correlação prejudicam a técnica de regressão de mínimos-quadrados.
A principal desvantagem da regressão linear simples ou múltipla é que quando aplicada sobre dados de software ela pode apresentar os seguintes problemas:
I) dificuldade na escolha das métricas a serem utilizadas;
Ii) coexistência de vários processos de desenvolvimento de software;
E iii) disponibilidade de dados quantitativos versus qualitativos.
Segundo, existem outros problemas relacionados à utilização da regressão, sendo eles:·
Multicolinearidade: É o número de variáveis preditivas altamente correlacionadas positivamente ou negativamente, o que pode distorcer o resultado da predição;·
Ajuste no modelo de dados:
Por causa de a falta de dados, alguns pesquisadores ajustam os dados em seus modelos preditivos e não testam o modelo resultante numa nova série de dados;·
Remoção de dados dos modelos:
Podem existir erros de registro por a transcrição de dados.
Assim, é necessária uma análise mais detalhada antes que se faça a remoção dos dados;
E· Média dos dados:
Utilizando médias reduz- se a quantidade de informação disponível para testes, perdendo- se os detalhes, isso pode tornar as conclusões fracamente argumentadas.
Análise das Propostas da Literatura Os aspectos relacionados abaixo foram identificados como importantes para a área de estimativas.
Tais aspectos foram definidos com base nas deficiências das técnicas de estimativas aqui apresentadas em serem utilizadas para a manutenção de software e, ainda, observadas no Estudo de Caso Exploratório, apresentado no Capítulo 4.·
Proposta: Apresenta o nome da proposta apresentada na revisão da literatura;·
Domínio: Informa se a proposta se insere no contexto de desenvolvimento ou manutenção de software.
Seus possíveis valores são: (Desenv.
/ Manut.);·
Representação: Informa o domínio do valor de ETMS estimado.
Seus possíveis valores são: (Numérica/ Categórica), onde numérica é um valor que representa o esforço de trabalho em horas para uma pessoa e categórico é um valor textual que representa um intervalo de valores;·
Base Histórica: Informa se a proposta utiliza base de dados histórica de projetos anteriores.
Seus possíveis valores são: (Sim/ Não);·
Combinação: Informa se a proposta combina diferentes técnicas de estimativas para aumentar a precisão ou se as mesmas são utilizadas isoladamente.
Seus possíveis valores são: (Sim/ Não);·
A o Menos 3: Informa se na proposta da literatura são utilizadas ao menos três técnicas combinadas para compor o valor do esforço estimado de ETMS visando melhorar a precisão, conforme sugere.
Os possíveis valores são: (Sim/ Não);·
Calibragem: Informa se a proposta apresentada é passível de calibragem.
Seus possíveis valores são (Sim/ Não);·
AvaliaçãoMP: Informa se a proposta possui algum componente para que sejam avaliadas as estimativas e estas se ajustem com o passar do tempo para melhorar sua precisão.
Seus possíveis valores são: (Sim/ Não);
E· Classificação:
Refere- se à classificação da proposta segundo a sugestão de.
Os possíveis valores são: (Empíricos e Compostos/ Dinâmicos/ Expertise/ OAM/ Regressão).
Apoiado nos aspectos supracitados, a Tabela 2.2 apresenta um resumo analítico dessas propostas destacando, por sombreamento, os aspectos considerados importantes para compor uma técnica de estimativas que atenda a área de manutenção de software.
Considerações Finais do Capítulo Para a melhoria da precisão do valor de esforço estimado, a literatura sugere que se utilize pelo menos três técnicas de estimativas.
Todavia, essa deficiência não foi observada em nenhuma das técnicas de estimativas, não havendo, consequentemente, uma discussão de como agregar ou retirar tais técnicas e de como selecionar os valores de esforço estimados por as mesmas.
Essa deficiência também foi constatada por meio de o Estudo de Caso Exploratório num projeto real de uma fábrica de software, apresentado no Capítulo 4, onde surgiu a proposta do Modelo­E10, apresentado no Capítulo 5.
Este capítulo apresenta o protocolo da revisão sistemática realizada na área de estimativas de esforço de forma a referenciar trabalhos de pesquisadores que buscam responder a questão de pesquisa apresentada na seção 1.2 do Capítulo 1.
Protocolo da Revisão Questão Foco: Identificar iniciativas com relação a as estimativas de esforço em projetos de manutenção de software, com o intuito de estabelecer quais técnicas de estimativas estão sendo amplamente utilizadas no contexto de pesquisa na área de estimativas de software.
Qualidade e Amplitude da Questão:·
Problema: A literatura apresenta uma gama de propostas de técnicas para estimativas de esforço.
O desafio dos pesquisadores é aperfeiçoar tais técnicas para que tenham resultados cada vez mais precisos.
Assim, torna- se necessário verificar o estado da arte nessa área de pesquisa, explicitando as boas práticas já definidas e as lacunas ainda existentes.·
Questão: Quais são os tipos de técnicas de estimativas de esforço utilizadas no contexto de manutenção de software que contribuam para pesquisas futuras?·
Palavras-chave e sinônimos:
Estimation: Software Effort Estimation, Estimating Software Effort, Software Effort Prediction, Predicting Software Effort.·
Intervenção: Identificação e avaliação das soluções expostas nas pesquisas.·
Controle: Inexistente.·
Efeito: Consolidação do conhecimento e identificação do estado da arte das estimativas de· Medição de resultados:
Número de trabalhos identificados.·
População: Artigos publicados em periódicos e anais de conferências relacionados ao tema de pesquisa, com data de publicação posterior a 2007, já que foi utilizada a revisão sistemática de para a verificação de trabalhos anteriores a 2007 e não foi encontrado nenhum relevante à área em questão.·
Aplicação: Pesquisadores da área.·
Projeto experimental:
Não se aplica.
Definição dos critérios de seleção das fontes:
Disponibilidade de consulta a artigos completos (full papers) através da Web por o convênio PUCRS­CAPES;
Existência de mecanismos de busca com publicações referentes aos últimos 3 anos.
Idioma dos estudos:
Inglês. Identificação das fontes:
Strings de busca· (&quot;Software Effort «OR (Maintenance And (Estimation OR Prediction)) OR( (Estimating OR Predicting) And &quot;Software Effort&quot;) OR Maintenance);
Lista de fontes:
IEEEXplore, ACM Digital Library, Citeseer library, CiteseerX library, SpringerLink, ScienceDirect e DBLP.
Seleção das fontes após avaliação:
Foram selecionadas as fontes IEEEXplore, ACM Digital Library, SpringerLink e ScienceDirect.
Verificação de referências:
Todas as fontes selecionadas são confiáveis e amplamente utilizadas por pesquisadores do mundo inteiro.
Definição dos estudos:·
Critérios de exclusão dos estudos:·
Definição do tipo do estudo:
Não são considerados trabalhos que indicam os desafios e as direções a serem tomadas na área de pesquisa em questão (roadmaps), mas são considerados aqueles que apresentam propostas para a área de estimativas de esforço tanto em desenvolvimento como em manutenção de software;
E de busca oferecidos em cada uma das fontes selecionadas;
Leitura dos meta-dados de cada artigo;
Leitura de título e o resumo (abstract) de cada artigo aprovado na primeira triagem;
Execução da Seleção:·
Seleção inicial dos estudos:
A busca em todos os mecanismos resultou em 81 artigos;·
Avaliação da qualidade dos estudos:
14 estudos foram selecionados para a extração de informações;
E· Revisão da seleção:
A seleção dos estudos foi aprovada por os professores orientadores do trabalho.
Critérios de inclusão e exclusão de informações:
As informações extraídas dos estudos devem conter todos os aspectos envolvidos para estimar o esforço em manutenção de software, desde a coleta de métricas do projeto, passando por a escolha da técnica e aplicação do modelo preditivo.
As soluções propostas nos artigos podem incluir técnicas, métodos, modelos, estratégias ou qualquer outra iniciativa relacionada à estimativas de esforço.
Formulários para extração dos dados:
Abaixo são apresentados os aspectos considerados relevantes neste trabalho para responder a questão de pesquisa apresentada na seção 1.2 do Capítulo Caso Exploratório realizado na empresa parceira, apresentado no Capítulo 4.·
Proposta: Apresenta o sobrenome do primeiro autor e a referência bibliográfica da proposta;·
Método de Pesquisa: Apresenta como a pesquisa foi conduzida.
Os possíveis valores de coluna (Comparativo/ Estudo de Caso/Protótipo), conotam respectivamente:
A comparação de diferentes propostas, a realização de um estudo de caso num ambiente real e a proposta de um protótipo;·
Foco de Contribuição: Informa o contexto da contribuição (Científica/ Mercado);·
Classificação: Classifica a proposta conforme sugere (Empíricos e Compostos/ Dinâmicos/ Expertise/ OAM/ Regressão);·
Descrição: Faz uma breve descrição da proposta;·
Domínio: Informa se a proposta de estimativas de esforço se insere no contexto de desenvolvimento ou manutenção de software (Desenv.
/ Manut.);·
Representação: Informa o domínio do valor de ETMS estimado por a proposta, onde numérica é um valor que representa o esforço de trabalho em horas para uma pessoa, e categórico é um valor textual que representa um intervalo de valores (Numérica/ Categórica);·
Base Histórica: Informa se o trabalho se baseia em dados anteriores de projetos (Sim/ Não);·
Combinação: Informa se a proposta combina diferentes técnicas de estimativas com intuito de melhorar a precisão (Sim/ Não);·
A o Menos 3: Informa se a proposta utiliza pelo menos três técnicas de estimativas visando melhorar a precisão, conforme sugerem (Sim/ Não);·
Calibragem: Informa se a proposta permite a calibragem da técnica (Sim/ Não);
E· Possui AvaliaçãoMP:
Informa se a proposta apresentada consegue avaliar o desempenho dos modelos preditivos das técnicas de estimativas que melhor obtiveram resultados nas estimativas anteriores (Sim/ Não).
Execução da extração:
Vide tabelas 3.1 e 3.6.
Resolução de divergências entre os pesquisadores:
Não se aplica.
Apresentação dos resultados em tabelas:
Vide tabelas 3.2 a 3.4.
Comentários finais:·
Número de estudos:
Foram retornados 81 artigos de os quais 14 foram selecionados e outros 67 artigos foram descartados;·
Possíveis fontes de distorções identificadas:
O número de fontes de busca utilizadas dos estudos relevantes em diferentes áreas de pesquisa;
A qualidade dos motores de busca das fontes selecionadas;
E a influência do autor na seleção dos artigos e na extração das informações;·
Variação entre revisores:
Não se aplica;
E· Aplicação dos resultados:
Os resultados obtidos são aplicados para identificar contribuições;·
Recomendações: Nenhuma.
A Tabela 3.1 mostra as informações gerais dos trabalhos relacionados com intuito de classificar- los conforme os aspectos relevantes à área de estimativas de software.
Sugere que as estimativas de esforço sejam realizadas com base nos dados históricos de projetos Baskeles estimados com o COCOMO.
Utiliza algoritmos de redes neurais:
Back Propagation Multilayer Comparativo Científico Perceptrons, Radial Basis Function (RBF) e Support Vector Regression (SVR), todos para gerarem uma árvore de regressão de esforço estimado.
Braga Sugere que para as estimativas de esforço sejam utilizadas técnicas com base em Algoritmos Comparativo Científico Genéticos proposto com SVR, RBF e Regressão Linear.
Deng Sugere que para as estimativas de esforço, a utilização de algoritmos de ML como:
Multi--layer Comparativo Científico Perceptrons, K­Nearest, Neighbour (k­NN) e RBF.
Sugere que para as estimativas de esforço deve- se avaliar a confiabilidade da expertise, indicando Gary Comparativo Científico Expertise as melhores variáveis a serem utilizadas nas estimativas por meio de a mineração de dados.
Jingzhou Protótipo Científico Sugere que para as estimativas sejam utilizadas analogias de métricas de projetos anteriores.
Mercado Sugere que para as estimativas de esforço sejam utilizadas Redes Neurais Compostas.
Kultur Estudo de Caso Sugere para as estimativas o esforço os projetos sejam particionados em ordem cronológica, Lokan Comparativo Mercado ao invés utilizar a comparação entre projetos, como feito tradicionalmente.
E realiza uma Regressão Linear sobre os dados.
Mendes Sugere que as estimativas de esforço, para projetos futuros, sejam realizadas com base em Comparativo Científico Regressão projetos anteriores similares.
E utiliza a regressão linear para tal tarefa.
Mohammad Sugere que as estimativas de esforço sejam realizadas por analogia, fazendo uma subseleção Comparativo Científico dos resultados por meio de a Lógica Fuzzy.
Sugere que as estimativas de esforço sejam realizadas com base em analogia de projetos ante-Mohammad Comparativo Científico Dinâmicos riores.
E utiliza a Lógica Fuzzy e o Modelo Grey, para tal, quando este último gera a equação preditiva de esforço.
Estudo de Patil Sugere que as estimativas de esforço sejam realizadas por meio de medidas no código de Mercado Empírico Caso linguagens de quarta geração.
Sugere que as estimativas de esforço sejam realizadas por meio de K­means e Redes Neurais, Seo Comparativo Científico para eliminar outliers.
Depois, realiza as estimativas utilizando Redes Neurais e Regressão com Mínimos Quadrados.
Sugere que para realizar as estimativas de esforço em manutenção de software, corretiva e pre-Shukla Estudo de Caso Mercado ventiva, sejam utilizadas Redes Neurais para indicar os direcionadores de custos mais promissores.
YongWang Sugere que as estimativas de esforço sejam realizadas durante todo o processo de software Comparativo Científico Dinâmicos utilizando uma equação preditiva gerada por o Modelo Grey.
A Tabela 3.2 mostra a frequência da classificação dos trabalhos relacionados conforme a sugestão de.
A frequência absoluta é dada por a contagem dos trabalhos conforme se enquadram na classificação sugerida por a autora.
A frequência relativa é dada por o percentual em relação a a quantidade total de trabalhos encontrados.
A Tabela 3.3 mostra a frequência do Método de Pesquisa utilizado por os autores.
Essa classificação foi utilizada para identificar se os estudos eram comparações entre técnicas de estimativas, aplicação de estudo de caso e protótipo.
Essa classificação ajuda a localizar se os trabalhos encontrados possuem foco científico ou de mercado.
A Tabela 3.4 apresenta a frequência do foco dos trabalhos identificados.
Um trabalho com cunho científico é importante para que as técnicas de estimativas apresentadas possam ser analisadas e aprimoradas.
Inversamente, o foco no mercado é importante para identificar as vantagens e desvantagens de adoção das mesmas, além de a avaliação dos resultados num ambiente real.
A Tabela 3.6 mostra como as propostas atuais estão em relação a as deficiências da área de estimativas, discutidas nas seções 1.1 e 1.2 do Capítulo 1.
Uma proposta que enriqueça essa área é aquela que preencha os aspectos aqui apontados.
Tabela 3.6: Extração das informações relativas ao contexto das estimativas de ETMS.
Proposta Domínio Representação Base Histórica Combinação A o menos 3 AvaliaçãoMP Calibragem Baskeles Desenv.
Numérica Sim Não Sim Não Sim Jingzhou Desenv.
Numérica Sim Não Sim Sim Kultur Desenv.
Numérica Sim Não Sim Não Sim Mohammad Desenv.
Numérica Sim Sim Não Não Sim Manut.
Numérica Sim Não Não Sim Shukla Os problemas identificados com as estimativas de esforço, apresentados na seção 1.1, são inerentes à manutenção de software.
Por isso é interessante saber a frequência de trabalhos que tentam estimar o esforço de manutenção em software.
Portanto, o Domínio foi classificado como:
Esforço de Desenvolvimento e Esforço de Manutenção. Assim, a Tabela 3.7 a frequência dos trabalhos encontrados em seus respectivos domínios.
A Tabela 3.8 mostra a frequência de como os trabalhos fazem a representação dos valores das estimativas.
Isso é importante para identificar se existe uma outra forma de representação de esforço, que não seja numérica, para ser utilizada por as técnicas de estimativas.
A Tabela 3.9 apresenta a frequência com que os trabalhos identificados utilizam dados históricos de projetos como base para estimativas futuras.
Isso é importante para definir a estratégia de utilização desses dados.
A Tabela 3.10 apresenta a frequência com que os trabalhos relacionados combinam as diferentes técnicas de estimativas utilizadas.
A combinação de técnicas é importante para realizar sua autoavaliação.
A Tabela 3.11 apresenta a frequência com que os trabalhos identificados utilizam pelo menos três técnicas de estimativas, estando alinhados com as sugestão de.
Isso é importante porque, segundo os autores, quanto mais técnicas se utilizar, maior a possibilidade de convergência entre o esforço estimado e o esforço real, consequentemente, a precisão das estimativas é aumentada.
Em este contexto, entende- se por AvaliaçãoMP uma forma de manter as técnicas que obtiverem melhor desempenho nas estimativas e de descartar as que não obtiverem resultados satisfatórios.
Essa funcionalidade é importante por fazer um ajuste fino nos valores de esforço estimados por as técnicas utilizadas.
Assim, a Tabela 3.12 apresenta a frequência com que os trabalhos relacionados utilizam a AvaliaçãoMP.
A Tabela 3.13 apresenta a frequência com que os trabalhos identificados utilizam a calibragem das técnicas de estimativas.
A calibragem é importante porque ela mantém os dados, utilizados por as técnicas, atualizados, e como consequência, pode aumentar a precisão das estimativas.
Como mostrado na Tabela 3.6, nenhuma das propostas atuais conseguem atender todos os aspectos observados para responder a questão de pesquisa apresentada na seção 1.2 do Capítulo 1.
Assim, faz- se necessário encontrar uma proposta que atenda tais aspectos.
Isso porque estes são essenciais na prática das estimativas, como observado no estudo de caso exploratório apresentado no Capítulo 4.
Vale ressaltar, também observando a Tabela 3.6, que poucos são os trabalhos voltados especificamente às estimativas de ETMS.
Em a realidade, as organizações adaptam técnicas de estimativas para desenvolvimento de software para estimar o esforço de manutenção, como discutido na seção 1.1 do Capítulo 1.
Outrossim, a maioria das pesquisas, bem como o mercado, não combinam diferentes técnicas de estimativas de esforço e todos esses fatores comprometem a precisão das estimativas contrariando a sugestão de autores da área:
Para responder a questão de pesquisa apresentada na Seção 1.2 do Capítulo 1, e, ainda, atender os aspectos relevantes da área de estimativas de esforço em manutenção de software, uma proposta deve:·
Se basear em dados históricos do projeto:
Como apresentado na Tabela 3.9, a maior parte das propostas atuais se baseiam em dados históricos de projetos e, além disso, na classificação da solução apresentada na Tabela 3.2, 7 das 14 propostas são baseadas em OAM que, por sua vez, também utiliza dados históricos.
A tendência em se usar bases de dados históricas se deve principalmente à coleta e ao armazenamento de dados de projetos como uma prática regular nas fábricas de software.
Isso tudo é suficiente para justificar a utilização de dados históricos de projetos nas estimativas;·
Ter o domínio na manutenção de software:
Como apresentado na Tabela 3.7, das propostas atuais apenas uma é voltada para a manutenção de software, o que deixa evidente a deficiência de trabalhos para projetos com tal característica.
Por isso, as organizações utilizam técnicas de estimativas de desenvolvimento de software improvisando- as para a manutenção do mesmo.
Assim, é importante preencher essa deficiência e ter uma proposta de estimativas específica para manutenção de software;·
Ter uma representação numérica:
Todas as propostas atuais estimam o valor de esforço de trabalho com uma representação numérica, como apresenta a Tabela 3.8.
Essa deficiência também foi observada numa fábrica de software objeto do Estudo de Caso Exploratório apresentado no Capítulo 4.
Assim, seguindo essas tendências e deficiências, uma proposta para estimar o esforço de manutenção em software deve ter como resultado um valor de esforço representado por um valor numérico;·
Fazer uso de pelo menos três técnicas de estimativas:
A literatura básica na área de estimativas como:,
relatam a importância de se utilizar mais de uma técnica para estimar o esforço em projetos de software, contudo, 10 das 14 propostas atuais, negligenciam essa afirmação e utilizam apenas uma técnica para estimar esforço, como apresenta a Tabela 3.11.
O ideal é uma proposta que faça o uso de pelo menos três técnicas de estimativas e que, ainda, apresente critérios de adoção e de retirada dessas técnicas;·
Avaliação do desempenho das estimativas realizadas combinando as diferentes técnicas de estimativas utilizadas:
A Tabela 3.10 mostra que apenas 2 das 14 propostas utilizam e combinam mais de uma técnica de estimativas.
A combinação de técnicas é importante porque aumenta a chance de se encontrar um ou mais valores de esforço estimados mais próximos do valor de esforço real.
A Tabela 3.12 mostra que também somente 2 das 14 propostas de técnicas de estimativas são passíveis de AvaliaçãoMP.
A AvaliaçãoMP é importante porque permite que sejam apenas selecionadas as técnicas com bom desempenho para estimar o esforço de trabalho.
De essa forma, uma proposta de estimativas em manutenção de software deve combinar e avaliar as técnicas utilizada;
E· Permitir a calibragem constante do modelo:
De as propostas atuais, 10 de 14 permitem que os modelos preditivos das técnicas de estimativas utilizadas sejam calibrados, como apresenta a Tabela 3.13.
Esse aspecto é importante para manter o modelo preditivo de estimativas atualizado conforme a realidade do projeto, o que torna esse aspecto essencial para uma proposta de estimativas em manutenção de software.
Finalmente, os aspectos supracitados foram ratificados por meio de a Revisão da Literatura, Capítulo 2, do Estudo de Caso Exploratório, Capítulo 4, bem como, incorporados ao Modelo­E10 para atender a área de estimativas de ETMS, Capítulo 5.
Este capítulo apresenta um estudo de caso exploratório realizado numa fábrica de software.
O estudo em questão tem enfoque em melhorar a precisão das estimativas de ETMS, bem como, desonerar os membros da equipe de projeto que, na época deste estudo, era responsável por estimar o ETMS num dos projetos da organização.
Este estudo foi patrocinado por os gestores de um dos projetos da fábrica de software.
Cenário A Hewlett­Packard Company (Hp) possui no TECNOPUC­Parque Tecnológico da Pontifícia Universidade Católica, em Porto Alegre, RS, uma fábrica de software que atende clientes, desde a esfera governamental até a iniciativa privada.
Esses vários projetos, em diferentes áreas de conhecimento, exigem que a organização tenha seu quadro funcional composto por diferentes experiências que, quando em convívio, tornam seu ambiente rico e heterogêneo para o desenvolvimento também de pesquisas.
Visando atrair mais clientes e adquirir maior credibilidade no segmento de desenvolvimento de software, em 2002, a organização iniciou a busca por o CMM nível 3.
Em novembro de 2005, após um grande esforço por parte de a organização e de seus colaboradores, foram alcançados os requisitos para elevar- la ao nível 3 do CMM, sendo parte deste esforço em parceria com a PUCRS.
O projeto escolhido por os gestores da organização para aplicar o estudo de caso em questão é um projeto de manutenção de software de um grande banco estatal, que envolvia um alto orçamento e, ainda, era regido por um contrato de SLA.
Por isso, o projeto tinha grande interesse em melhorar as suas estimativas de ETMS.
Por questões de confidencialidade, daqui por diante, este projeto é referenciado por projeto P1.
O projeto P1 contava com 63 colaboradores divididos em quatro equipes:
Projeto, com 20 membros;
Cliente com 12 membros;
Servidor com 12 membros;
E Testes, com 17 membros.
Cada equipe possuía um líder técnico e, além destes, um profissional de Software Quality Assurance (SQA) e um subgerente, responsável por organizar e acompanhar o cronograma das demandas.
A equipe de Projeto é responsável por estimar os prazos e realizar criação ou alteração nos documentos de projeto do software;
A equipe de Cliente é responsável por o desenvolvimento ou manutenção do código de telas e regras de negócio na parte cliente da aplicação, com base nos documentos de projeto do software;
A equipe de Servidor é responsável por o desenvolvimento ou manutenção do código da parte de banco de dados da aplicação, com base nos documentos de projeto do software;
Por fim, a equipe de Testes é responsável por os testes de integração do software com base nos seus requisitos e documentação de projeto.
O projeto P1 possui um PDS em cascata orientado a entregáveis, onde cada equipe representa uma fase desse PDS.
Os projetos têm livre arbítrio para a escolha das ferramentas para auxiliarem na gestão do PDS sendo que o projeto P1 utiliza o MS­EPM (Enterprise Project Management), para o controle de prazos das atividades;
O MS­Excel para as estimativas do ETMS e onde são armazenadas as sugestões de estimativas de um membro da equipe de projeto (expertise);
O IBM Rational Clear Quest para o armazenamento de informações referentes a defeitos, tamanhos e esforço;
RequisitePro para a gerência dos requisitos;
E, por fim, um software próprio para apontamento das horas trabalhadas dos membros das equipes (esforço real).
Tipicamente, o software é dividido em versões, sendo que o projeto deve entregar uma quantidade de FP/ mês para o cliente.
O FP é distribuído dentro de uma ou mais versões do produto.
Para cada versão do produto é determinado um conjunto de requisitos, que são atribuídos a uma demanda chamada de Ordem de Serviço (Os), as quais contêm as alterações a serem realizadas no software.
Requisitos do Projeto Os requisitos para a busca de técnicas de estimativas foram definidos por meio de reuniões formais com os gestores de projetos, com base na experiência nos projetos da organização.
Sendo assim, os requisitos foram:·
Entrada e saída numérica:
As técnicas utilizadas devem ter como entrada valores numéricos como FPs, KLOC, de entre outros, os quais se encontram devidamente armazenados na base de dados do projeto.
Além disso, os valores de entradas também devem ter algum tipo de relação com o valor do Esforço Real de trabalho na tentativa de se encontrar um padrão dos dados coletados.
Já a saída produzida, deve ser um valor numérico dado em horas de trabalho representando o esforço de uma pessoa/ hora;·
Justificativa de resultado desnecessária:
Para o projeto o que importa é o valor do esforço de trabalho em horas, assim, não é necessário inferir como as estimativas são realizada e muito menos a justificativa de seus resultados;·
Fácil utilização:
A técnica adotada tem que ser de fácil utilização para onerar o mínimo possível os responsáveis por as estimativas;·
Basear- se nos dados históricos do projeto:
A sugestão dos gestores foi explorar a base histórica de um dos projetos da organização, alimentada desde 2004.
Essa base histórica está em conformidade com as exigências do modelo de qualidade CMM nível 3;·
Atualização constante da técnica (calibragem):
Com a atualização constante da técnica, uma demanda estimada, depois de finalizada, passa a ser considerada para as próximas estimativas.
A calibragem é importante porque com o passar do tempo aumenta as chances de estimativas mais precisas;·
Eliminar a expertise:
Atualmente a organização utiliza uma técnica baseada em expertise, a qual leva em consideração as sugestões de estimativas dos membros da equipe com base em sua experiência.
É ideal que as técnicas estudadas não sejam baseadas na expertise, por dois motivos:
I) desonerar as equipes;
E ii) não depender de conhecimento humano para as estimativas.
A realização deste estudo de caso obedeceu o esquema apresentado na Figura 4.2, como sugere.
Em ela são mostradas as etapas utilizadas para a realização do estudo de caso no projeto P1.
O ponto de partida do estudo de caso foi o levantamento e o estudo das métricas existentes no projeto, realizada na etapa:
&quot;Métricas do Projeto».
Todas as métricas coletadas estavam devidamente documentadas, o que facilitou o levantamento e entendimento das mesmas.
Em a etapa &quot;Métodos de Análise «foram estudadas e definidas as técnicas de estimativas sugeridas por a literatura, e utilizadas neste estudo de caso.
As técnicas estatísticas e de mineração foram as mais apropriadas para as estimativas de ETMS, pois as mesmas são ideais para se trabalhar sobre os dados históricos.
A etapa das &quot;Hipóteses «é o passo onde foram definidas as hipóteses alternativas do estudo de caso.
A hipótese nula foi formulada após as reuniões com gestores e líderes do projeto P1, onde foi relatado o problema de estimativas do projeto.
Já as hipóteses alternativas surgiram por meio de os &quot;Ensaios Empíricos».
Estas últimas guiaram a validação dos experimentos realizados no estudo de caso.
Os experimentos foram devidamente planejados com base nas hipóteses formuladas.
A princípio a intenção era de validar as hipóteses em outros projetos, contudo, isso não foi possível, por falta de um projeto que tivesse uma base de dados como a do projeto P1.
Os resultados obtidos foram avaliados por a proximidade do valor de ETMS estimado com o valor real de esforço de demandas atuais.
A expectativa nessa etapa, era que as técnicas de estimativas utilizadas nos &quot;Ensaios Empíricos «e definidas no &quot;Método de Análise», refutassem a hipótese H0 e ratificassem uma ou mais hipóteses alternativas, apresentadas e discutidas na Tabela 4.1.
O resultado do estudo de caso foi, por inferência, um modelo para estimativas de ETMS.
Este modelo é apresentado e discutido em detalhes do Capítulo 5.
O protocolo deste estudo de caso exploratório se encontra no Apêndice A. Definição das Hipóteses e Técnicas Por meio de os &quot;Ensaios Empíricos «com os dados do projeto P1 emergiram as hipóteses apresentadas na Tabela 4.1.
Tais hipóteses foram baseadas nas variáveis existentes na base do projeto P1:
Function Points (FP) e Quantidade de Documentos (QtdeDoc).
A FP era conhecida por determinar o tamanho da demanda a ser implementada;
Já a quantidade de documentos teve que ser extraída por meio de consultas SQL.
A quantidade de documentos foi escolhida porque o projeto P1 possui uma boa documentação do projeto.
Além disso, sugere que sejam utilizados os documentos do projeto para a realização das estimativas em ETMS, o que ajudou na escolha dessa variável.
Para a obtenção deste último foi realizado um grande esforço de preparação de dados.
A hipótese H6 só foi utilizada para a fase 3 do estudo de caso, seção 4.7, deste capítulo.
E a hipótese nula não foi alterada.
H0: Nenhuma técnica de estimativas é mais precisa que a técnica atual, baseada em expertise.
H1: Conhecida a quantidade de documentos (artefatos de software) impactados por uma demanda é possível determinar seu esforço total de trabalho com mais precisão que a técnica atual.
H2: Conhecida a quantidade de documentos por equipe impactados por uma demanda é possível determinar o esforço de trabalho de cada equipe com mais precisão que a técnica atual.
H3: Conhecido o tamanho da demanda, em pontos de função, é possível determinar o esforço total de trabalho desta com mais precisão que a técnica atual.
H4: Conhecidos o tamanho da demanda, em pontos de função, e a quantidade de documentos relacionados à mesma, é possível determinar o esforço total de trabalho da demanda com mais precisão que a técnica atual.
H5: Utilizada mais de uma técnica de estimativas de esforço de trabalho em manutenção de software é possível determinar o esforço de trabalho de cada equipe com mais precisão que a técnica atual.
H6: Com base na complexidade dos documentos utilizados em cada fase do projeto é possível determinar o esforço de trabalho de cada equipe com mais precisão que a técnica atual.
Havia também uma hipótese para estimar o esforço de trabalho em manutenção de software utilizando FP por fase, contudo, essa hipótese não evoluiu, porque não foi possível determinar os FP de cada fase.
Diante de as hipóteses formuladas, foram escolhidas algumas técnicas para as estimativas de ETMS com base nos requisitos definidos por os gestores do projeto P1.
As técnicas de estimativas adotadas para este estudo de caso são sugeridas na literatura por autores da área de Engenharia de Software como:
A principal vantagem de se utilizar as técnicas sugeridas é a maturidade das mesmas na resolução de problemas em diferentes áreas de conhecimento.
As técnicas escolhidas foram:·
Regressão Linear Simples e Múltipla: A regressão Simples e Múltipla são técnicas estatísticas que se baseiam nos dados do projeto.
Uma das principais características destas técnicas é a facilidade de aplicação após a preparação dos dados;·
Algoritmo M5P:
O M5P é uma técnica que se baseia em árvore de regressão.
Ela analisa os dados históricos do projeto e gera um ou mais modelos preditivos representados por equações lineares para estimar o atributo classe, neste caso, o ETMS.
Esta técnica é encontrada na ferramenta WEKA, o qual é um software de descoberta de conhecimento em base de dados que contém vários algoritmos de mineração;·
Árvore REPTree:
O REPTree é uma técnica de estimativas que gera uma árvore de decisão baseada na redução de ganho/ variância dos dados.
A profundidade da árvore é dada por o cálculo de um valor de redução de erro.
A o final se tem uma árvore de decisão onde os nós folhas são os valores das estimativas com base nas variáveis de entradas definidas;·
Percentual de Esforço por Equipe:
O percentual de esforço por equipe é o percentual médio de esforço desprendido de cada equipe no desempenho de suas atividades em determinada Os.
Esse valor é calculado em duas etapas, a primeira de elas é calcular a proporção de esforço de cada equipe com base nos dados históricos do esforço real do projeto P1.
A segunda etapa é estimar o esforço total da Os, por meio de a regressão linear, e calcular o ETMS com base na proporção por equipe;·
Quartil 1 (25%):
O primeiro quartil é uma técnica estatística que identifica o valor a partir de o qual se encontram os 25% dos valores mais baixos, computados do 1o ao 25o termo de uma amostra ordenada.
A aplicação dessa técnica permite obter um valor que represente o valor mais baixo de esforço real para que este seja utilizado para calcular o ETMS com base na proporção de esforço real por equipe;·
Mediana: A mediana, ou segundo quartil (Q2), é o valor do termo do meio de uma amostra de valores ordenados.
Essa técnica permite obter o valor mediano de ETMS, mais precisamente o valor do meio de uma amostra ordenada.
Com isso, pretende-se obter valores intermediários de esforço para que sejam balanceadas as estimativas;·
Quartil 3 (75%):
O terceiro quartil (Q3) é uma técnica estatística que identifica o valor a partir de o qual se encontram os 25% dos valores mais elevados, a partir de o 75o termo até o último de uma amostra ordenada.
A aplicação dessa técnica permite obter um valor que represente o valor mais alto de esforço real para que este seja utilizado para calcular o ETMS com base na proporção de esforço real por equipe;
A Tabela 4.2 apresenta as expectativas na aplicação das técnicas definidas para responder as hipóteses formuladas.
A avaliação das técnicas de estimativas para ETMS aplicadas nas fases 1, 2 e 3, foi realizada por o cálculo do módulo da diferença entre o valor de esforço estimado de ETMS, utilizando a técnica definida na respectiva fase com o valor do esforço real.
Esses valores foram comparados com a diferença, também em módulo, do esforço real com a expertise dos membros da equipe.
O escore foi composto por a quantidade de valores estimados das OSs que se aproximaram do esforço real.
Fase 1 ­ Regressão Linear Simples e Múltipla Essa primeira fase visou encontrar uma forma de melhorar a precisão das estimativas de ETMS por meio de a regressão linear nos dados históricos do projeto P1.
A riqueza de dados do projeto foi o fator determinante para a aplicação da técnica regressão linear.
Os atributos disponíveis na base do projeto para realizar a regressão linear eram FP e Quantidade de Documentos (QtdeDoc).
Uma equação que expresse um padrão e forneça um valor de esforço de trabalho total estimado para toda a demanda.
Uma equação que expresse um padrão e forneça um valor de esforço Regressão Múltipla de trabalho para cada fase da demanda.
A soma de seus valores individuais representa o valor total de esforço de trabalho da demanda.
Equações que expressam padrões conforme o comportamento dos dados, não necessariamente único.
Estas, quando aplicadas sobre as variáveis definidas na hipótese, podem fornecer um valor de esforço de trabalho para cada fase e total da demanda, dependendo de uma ou mais características da demanda.
Uma árvore de regressão que expresse um padrão e forneça valores REPTree de esforço de trabalho da demanda, tanto total como por equipe.
A proximidade do percentual médio de esforço por equipe do esforço% Esforço por Equipe real de trabalho da demanda.
Este valor é calculado sobre o total de esforço de trabalho estimado para uma demanda.
A proximidade do valor do percentual médio de esforço por equipe do esforço real, representando os menores valores de esforço.
Este valor Quartil 1 (25%) pode ser utilizado para calcular os valores de esforço da demanda para determinada equipe.
A proximidade do valor central do percentual médio por equipe do esforço real da demanda, podendo este ser utilizado para estimar o Mediana esforço de trabalho por equipe, bem como o esforço de trabalho total da demanda.
A proximidade do valor do percentual médio de esforço por equipe do esforço real, representando os maiores valores de esforço.
Este valor Quartil 3 (75%) pode ser utilizado para calcular os valores de esforço da demanda para determinada equipe.
Essas OSs, doravante chamadas de conjunto de treino, foram utilizadas para encontrar a equação de regressão linear, que representa o modelo preditivo da técnica.
Aplicando a equação encontrada num conjunto de vinte OSs, doravante denominado de conjunto de testes, obteveram- se os resultados apresentados na Tabela 4.3.
Em a Tabela 4.3 observa- se que a expertise teve um escore maior do que a técnica de regressão linear baseada em FP.
De essa forma, não se obteve sucesso para refutar a hipótese H0, chegando à conclusão de que, para este caso em particular, as estimativas com regressão linear baseada no tamanho da demanda não produz bons resultados, rejeitando- se a hipótese H3.
Em busca de melhores resultados foi usada a variável explicativa QtdeDoc ao invés de FP.
Para gerar o modelo preditivo utilizando a regressão linear, agora com base em QtdeDoc, foi montada uma consulta SQL na base de dados do projeto e o resultado foi um total de 544.
Realizando a limpeza nos dados, o número de demandas caiu para 523 e a correlação da variável QtdeDoc com a variável de esforço real foi de 0, 86.
Aplicando as equações encontradas no conjunto de treino, obteve- se o resultado apresentado na Tabela 4.4.
Esses resultados foram mais promissores que aqueles apresentados na Tabela 4.3.
De essa forma, a precisão da técnica baseada na quantidade de documentos foi significativamente melhor que a precisão da técnica baseada em FP.
Com isso foi possível refutar a hipótese H0 e ratificar a hipótese alternativa H1.
Em o último experimento realizado utilizou- se regressão linear múltipla.
Esta técnica levou em consideração mais de um atributo para gerar o modelo preditivo.
Para este caso foram considerados os atributos FP e QtdeDoc juntos.
Para gerar o modelo preditivo utilizando a regressão múltipla foi realizada uma consulta SQL na base de dados do projeto, e o resultado foi um total de 296 OSs retornadas.
Após a limpeza dos dados, permaneceram 286.
Os resultados obtidos foram menos promissores que àqueles com a regressão linear baseada em QtdeDoc, como pode ser observado na Tabela 4.5.
Assim, para este caso, a hipótese H0 foi ratificada e a hipótese H4 foi rejeitada.
Os resultados até aqui obtidos foram apresentados numa reunião com os gestores e os líderes técnicos do projeto P1 em 18/08/2007.
Quando estimado por total de esforço de trabalho da demanda, os valores encontrados tiveram uma precisão maior do que a expertise dos membros da equipe.
Apesar de os resultados alcançados serem promissores, os gestores e os líderes técnicos do projeto manifestaram a necessidade em se estimar o ETMS das OSs por equipe.
Em esse sentido, foi sugerida a aplicação da regressão linear para estimar ETMS para cada fase do projeto, e não mais para o total de OSs.
Tendo em vista a necessidade em se estimar o ETMS por fase, aplicou- se então uma regressão linear simples em cada fase do projeto P1, quando considerada apenas a QtdeDoc, visto que não havia como identificar o FP de cada fase.
A Tabela 4.6 apresenta os resultados obtidos, assim, nas estimativas da equipe de projeto a hipótese H2 foi validada e a hipótese H0 foi rejeitada.
Em as demais estimativas a hipótese alternativa H2 foi rejeitada.
O resultado desse experimento foi apresentado aos líderes e gestores do projeto P1 na reunião do dia 27/08/2007.
Apesar de resultados promissores com a utilização da regressão linear simples com base em na QtdeDoc, como mostrado na Tabela 4.6, os líderes e os gestores do projeto P1 não ficaram convencidos de que o resultado obtido era confiável, por isso, sugeriram investigar outras técnicas de estimativas.
Em essa primeira fase, os ganhos com as estimativas de ETMS foram significativos no tocante a as estimativas do esforço total, porém não tão significantes quando o esforço passou a ser estimado por fase.
A Tabela 4.7 apresenta as hipóteses validadas, onde a coluna &quot;Esforço «mostra o tipo de esforço estimado, podendo ser total ou por fase;
A coluna &quot;Técnica «mostra quais técnicas foram utilizadas para se estimar o ETMS;
A coluna &quot;Atributos «mostra quais atributos foram utilizados por as respectivas técnicas;
E, por fim, a coluna &quot;Hipóteses Válidas «mostra quais hipóteses formuladas foram ratificadas com a aplicação das respectivas técnicas de estimativas de ETMS.
Fase 2 ­ Combinação de Técnicas de Estimativas As estimativas por regressão simples e múltipla, quando aplicadas por fase, não produziram resultados satisfatórios.
Em meio a isso, a alternativa foi combinar diferentes técnicas de estimativas com intuito de aumentar o escore em relação a a expertise, que neste contexto são àquelas estimativas mais próximas do esforço real, pois segundo, utilizar mais de uma técnica pode fazer com que os valores de esforço estimado convirjam para os valores de esforços reais.
Assim, como a expertise é empírica e não combina diferentes técnicas e, ainda, o uso da regressão linear não produziu resultado satisfatório, há certa evidência de que a precisão das estimativas atuais pode melhorar com a combinação de diferentes técnicas.
Um problema enfrentado na combinação de diferentes técnicas de estimativas está em determinar quais valores estimados são mantidos ou descartados.
Em são apresentadas técnicas de agrupamento para encontrar similaridade entre objetos.
Transpondo essa ideia para as estimativas de ETMS, é possível agrupar os valores de esforço estimado de diferentes técnicas e, a partir de isso, escolher os valores mais promissores para serem utilizados na composição do valor de esforço estimado.
Para considerar os indivíduos pertencentes a um mesmo agrupamento, determina- se o grau de similaridade entre os mesmos.
Por exemplo, pode- se sugerir um intervalo de 1 a 9 para determinar um grau de similaridade representado por a distância desses indivíduos.
De essa forma, valores de esforço entre 1 e 9 pertencem ao mesmo agrupamento, acima de essa distância os valores de esforço pertencem a outro agrupamento.
O cálculo do grau de similaridade é realizado por meio de a distância Euclidiana, como sugere.
Logo, a regra geral para se manter os valores de esforço é:
&quot;Quanto maior o número de indivíduos num agrupamento, maior a chance de utilização dos valores de esforço deste agrupamento para compor o estimado de ETMS».
A composição do valor final do ETMS com base na combinação de técnicas de estimativas devem obedecer as seguintes regras:
Selecionando assim, o grupo mais denso (indivíduos mais próximos);
As menores distâncias de cada agrupamento, até que seja possível identificar um valor de desempate entre as distâncias somadas;
As regras devem ser aplicadas na sequência sugerida.
O resultado da aplicação das regras é um valor único de esforço estimado para cada fase do projeto P1.
A Tabela 4.8 apresenta um exemplo fictício para ilustrar o funcionamento das estimativas de ETMS utilizando a combinação de diferentes técnicas de estimativas.
Supondo que os dados são de uma Os numa determinada fase do projeto, na coluna &quot;Técnicas «da respectiva tabela, encontrase o nome da técnica utilizada;
Já na coluna &quot;Esforço «é apresentado o valor de esforço estimado por a técnica aplicada.
Com isso, descobre- se que o agrupamento 2 é mais denso que o agrupamento 1.
Portanto, as da média dos valores de esforço estimado das técnicas pertencentes ao agrupamento 2, que para este exemplo foi de 36, 33 horas.
A quarta regra é aplicada quando ocorre um empate entre o valor da soma das distâncias de diferentes agrupamentos mas de mesmo número de indivíduos.
Quando isso ocorre, retira- se os indivíduos com as maiores distâncias de cada agrupamento, verificando se há ou não empate na soma das distâncias restantes.
Caso ainda persista o empate, retira- se então, a segunda maior distância.
Essa iteração se segue até que não haja mais empate nas distâncias, ou até que os indivíduos dos agrupamentos sejam únicos.
A Tabela 4.11 apresenta um exemplo dos valores de esforço para a aplicação da quarta regra.
Em a Figura 4.4, pode- se observar dois agrupamentos de indivíduos com os valores estimados de ETMS, encontrados por a combinação de diferentes técnicas de estimativas.
Aplicando a primeira, segunda e terceira regras, encontra- se um empate entre a soma dos valores das distâncias de cada agrupamento, como mostra a Tabela 4.12.
Com a aplicação da quarta regra, desconsideram- se os maiores valores de distância.
Em este das distâncias.
Ainda não se sabe qual o agrupamento mais denso, pois a soma das distâncias continua tendo o O agrupamento 2 é considerado o mais denso, pois existe uma menor distância entre seus indivíduos.
O valor estimado de esforço de trabalho total é calculado por a média dos valores encontrados por cada técnica de estimativas dada por o agrupamento escolhido, agrupamento 2, dado por A quinta regra garante que, caso haja empate em todas as distâncias, valores médios dos agrupamentos podem sugerir um bom valor de esforço por meio de a média aritmética das medianas dos agrupamentos selecionados.
Para exemplificar esse cenário são considerados os seguintes valores estimados de ETMS apresentados na Tabela 4.14.
A Tabela 4.15 mostra um exemplo de empate que pode existir entre as distâncias dos dois agrupamentos identificados por o primeiro critério.
De essa forma, o valor da mediana dos valores de esforço estimado de cada agrupamento são, respectivamente, 7 horas do agrupamento 1 e 33 horas do agrupamento 2.
O valor do esforço estimado é calculado por a média entre 7 e 33, e seu valor final é de 20 horas.
A sexta regra é utilizada quando todos os agrupamentos são compostos por valores únicos.
Isso indica que a distância entre esses valores é maior do que o intervalo de 1 a 9 definido.
Esse exemplo é mostrado na Tabela 4.16.
Em este caso, é calculada a média aritmética de todos os valores e sugerida como valor estimado de ETMS da demanda.
O valor calculado nesse exemplo foi de 55, 2 horas.
Para aplicar a combinação de várias técnicas foram seguidos os seguintes passos:
Desde sua implantação até o ano de 2007.
A Tabela 4.17 apresenta um resumo com as técnicas de estimativas aplicadas, as hipóteses a serem ratificadas, as suas fases e a quantidade de demanda utilizada para compor o conjunto de treino;
A Tabela 4.18 apresenta os escores obtidos com a utilização da combinação de várias técnicas de estimativas.
Nota- se que, para todas as fases do projeto P1, os resultados por meio de a combinação de várias técnicas de estimativas foi significativamente superior aos das estimativas realizadas por meio de a expertise.
Isso significa que a hipótese H5 foi validada e a hipótese nula H0 rejeitada.
A partir de os resultados alcançados os gestores e líderes técnicos do projeto pediram que fosse implementada uma planilha utilizando a combinação de técnicas de estimativas, pois estas tiveram resultados muito mais promissores ao trabalho realizado na Fase 1, apresentada na seção 4.5.
Sendo assim, as planilhas foram implementadas e utilizadas para realizarem estimativas de ETMS para o projeto P1.
Apesar disso, os gerentes do projeto pediram um estudo de técnicas de estimativas que não se baseasse somente nos dados históricos.
O principal argumento dos gestores do projeto foi o de validar se realmente não havia nenhuma outra técnica que pudesse produzir resultados melhores que a combinação das técnicas de estimativas.
Fase 3 ­ Verificação da Complexidade em Documentos de Projeto O projeto P1 possui uma série de documentos estruturados com seções bem definidas, contendo todas as regras de negócio e todos os pseudocódigos da aplicação.
O time de projeto é o responsável por fazer a criação e a manutenção desses documentos.
Em 14/10/2007 foi dado início aos trabalhos de estimativas com base na complexidade da alteração de cada documento de projeto associado a uma demanda.
Os tipos de documentos existentes no projeto P1 são:
Documento de Projeto (DD), Documento de Interface com o Usuário (DEIG) e Documento de Módulos.
Em esta fase é utilizada a hipótese H6, apresentada na seção 4.4 deste capítulo.
Uma classificação de complexidade baseada nos direcionadores de custos do COCOMO 2.
0, apresentada no Apêndice B, é proposta por.
Essa classificação se mostrou apropriada para ser utilizada nos documentos do projeto P1 porque sua proposta se parece com a forma como os membros da equipe realizavam suas estimativas.
Cada uma das classificações foi mapeada para dentro de os documentos de projeto.
Esse mapeamento foi realizado com a ajuda do líder técnico e membros da equipe de projeto, e os líderes técnicos das equipes de Cliente, Servidor e Testes, além de o SQA do projeto.
Para a realização dessa fase ocorreram 15 encontros semanais quando foram desenvolvidas as seguintes atividades:·
Mapeamento da classificação proposta por para cada tipo de funcionalidade em cada tipo de documento do projeto P1;·
Classificação da complexidade das alterações em cada tipo de documento do projeto;·
Escrita de um manual explicativo para classificar e contar a complexidade das alterações dos documentos;·
Criação de uma interface para o cálculo das estimativas baseada na complexidade das alterações nos documentos de projeto;·
Apresentação da interface para os líderes de equipe e coleta das sugestões de melhorias;
E· Implantação do projeto piloto para coletar dados e avaliar as estimativas por a complexidade da alteração no documento.
O Apêndice C apresenta um exemplo do guia de classificação da complexidade dos documentos, composto por:·
nome do documento no cabeçalho;·
função, onde sua complexidade foi determinada por meio de reuniões com membros da equipe;·
classificação da complexidade de alteração dada por cada equipe para a função;·
granularidade definida para a complexidade da alteração;
E· alteração impactada na funcionalidade denominada de OBMaker, responsável por a geração de código e que tem uma contagem própria que deve ser considerada para documentos de projeto (Apêndice C. 4 ­ Regra de contagem para OBMaker).
Os fatores de ponderação foram considerados como frações de horas e mapeados para tal, como apresenta a Tabela 4.20.
Além disso, nas reuniões os líderes de equipe afirmaram que o tempo mínimo de uma demanda era de 30 minutos, portanto, foi criado o fator de ponderação &quot;Extra Baixo «com um valor de 0, 5 horas para representar demandas pequenas.
Para utilizar a técnica com base em complexidade de documentos, os seguintes passos foram seguidos:
A o final, o valor de ETMS de uma Os é dado por a soma dos fatores de ponderação para cada tipo de alteração do documento.
Devido a o grande esforço necessário para a realização da classificação de alterações por documento em todas as fases do projeto P1, o escopo do experimento foi reduzido a 19 demandas e somente à fase de projeto.
Os resultados estão na Tabela 4.21.
Os resultados foram apresentados em 22/01/2008 e muito bem recebidos por a equipe do projeto, pois o esforço estimado de trabalho chegou muito próximo de o esforço real, quando comparado às técnicas aplicadas anteriormente.
Contudo, esta técnica pode não ter bons resultados em outras fases, já que nas fases anteriores as melhores estimativas alcançadas eram na fase de Projeto.
Essa técnica chegou a ser implantada como um piloto no projeto P1 mas por onerar muito os membros da equipe, os gerentes do projeto decidiram por abandonar- la e ficaram com a combinação de várias técnicas.
Esta técnica de classificação das alterações nos documentos revelou que, muitas vezes, o projetista &quot;gasta «exatamente o valor estimado do ETMS para realizar as alterações numa demanda.
Essa informação foi confirmada por os líderes de equipe do projeto em reuniões formais.
Este fato é explicado por, como &quot;Síndrome de Estudante», quando a pessoa se comporta como um estudante, deixando sempre para executar suas tarefas na última hora e utilizando todo o tempo estimado para realizar- la.
Os ganhos com as estimativas de ETMS nessa terceira fase, como na segunda fase, foram significativos.
A Tabela 4.22, apresenta as hipóteses validadas utilizando a complexidade de documentos para estimar o valor de ETMS.
Em o momento da realização do estudo de caso, a sugestão das estimativas de ETMS é baseada na análise dos artefatos de software, quando o projetista avalia empiricamente o esforço necessário para realizar as alterações numa demanda.
Em a tentativa de melhorar a precisão das estimativas e acabar com o empirismo no projeto P1, foram sugeridas técnicas de estimativas apresentadas neste capítulo e alinhadas com os requisitos definidos por os seus gestores.
Uma síntese dos trabalhos realizados é apresentada na Tabela 4.23.
Vantagens: Simplicidade de utilização, fácil calibragem, fácil entendimento, desonera membros da equipe de projeto.
Desvantagens: Sensível à outliers, dificuldade em identificar os atributos, necessidade de muitos dados.
Calcular o valor de esforço estimado por equipe com base nos FP e Quantidade de Documentos.
Não, pois monta a árvore de decisão montada pode ser muito Vantagens:
Simplicidade de utilização, fácil calibragem, desonera membros da equipe de projeto.
Desvantagens: Dificuldade em iden-tação e implementação, depen- tificar os atributos, necessidade de dendo da quantidade de dados.
Montar uma árvore de decisão com os daREPTree dos de o esforço por equipe.
Calcular o esforço médio gasto por equipe Equipe para implantar uma demanda.
Vantagens: Simplicidade de utilização, fácil calibragem, desonera membros da equipe de projeto.
Calcular o percentual de esforço com base Desvantagens:
Estimar o esforço de uma deQuartil 1 grande esforço na manda por fase.
Calcular o percentual de esforço, com base Sim, aplicada em conjunto com Mediana na mediana dos esforços de demandas fioutras técnicas.
Calcular o percentual de esforço, com base Quartil 3 nos maiores valores de esforço gasto por equipe para finalizar uma demanda.
Vantagens: Não é sensível a outliers, não necessita de dados de projetos.
Calcular o esforço com base na complexi-Complexidade de Dodumentos Desvantagens:
Dificuldade na utilizadade das alterações em documentos estrução, difícil calibragem, dependência de intrusão humana, não desonera membros da equipe de projeto.
Considerações Finais do Estudo de Caso As técnicas de estimativas exploradas para este estudo de caso contribuem para um projeto de software à medida em que se consegue boas aproximações do esforço de trabalho real e, ainda, desonera equipes, diminuindo a relocação de recursos para realizar estimativas.
As lições aprendidas com a aplicação deste estudo de caso foram:
Horas ou em dias, e não categórico, como:
Alto, médio e baixo, por exemplo.
Isso porque um valor de hora deve ser assumido para ser colocado num cronograma de acompanhamento de demandas.
Sendo assim, algumas técnicas de mineração de dados, como a classificação, não podem ser utilizadas para se estimar ETMS neste cenário;
Sendo assim, ficou claro que quanto mais as estimativas forem independentes de fatores humanos, menos esse problema aparecerá;
Base nos dados de projetos pode- se calibrar o modelo preditivo constantemente, de forma iterativa, assim, o modelo preditivo sempre se mostrará atualizado, havendo uma grande possibilidade de convergência com o esforço real;
E diferentes técnicas de estimativas, bem como agrupar os valores considerando sua similaridade por a distância euclidiana, é uma forma de descobrir um conjunto de valores para serem utilizados nas estimativas de ETMS.
Assim, acredita- se que, quanto mais técnicas e mais valores próximos agrupados, maior a possibilidade de convergência para o esforço real de trabalho.
Por fim, o resultado deste estudo de caso exploratório foram duas publicações no SEW' 08 (Software Engineering Workshop).
Os artigos publicados foram:
A Quasi­Experiment for Effort and Defect Estimation using Least Square Linear Regression and Function Points e Issues on As atuais técnicas de estimativas, apresentadas por a literatura, são utilizadas por a indústria de software de forma isolada, o que pode comprometer a precisão das estimativas.
Quando se utiliza mais de um modelo de estimativas a probabilidade de melhorar a precisão das mesmas aumenta significativamente.
Portanto, para responder a questão de pesquisa apresentada no Capítulo 1 seção 1.2, o presente capítulo apresenta o Modelo­E10, um modelo de estimativas capaz de alcançar boas aproximações do esforço de trabalho estimado sem depender da expertise de pessoas e, ainda, flexível a ponto de combinar diferentes técnicas de estimativas e de se autoajustar para melhorar estimativas futuras.
Requisitos para Utilização do Modelo­E10 Para a utilização do Modelo­E10, os seguintes requisitos devem ser satisfeitos:·
Definição do Nível de Exigência: O &quot;Nível de Exigência «é um percentual parametrizável que indica a tolerância de erro do valor do esforço estimado em relação a o valor de esforço real das demandas.
Os gerentes de projeto devem definir qual é o &quot;Nível de Exigência «das estimativas do Modelo­E10.
Esse parâmetro permite definir se um valor estimado para uma demanda é considerado bom ou ruim.
O Modelo­E10 considera boas estimativas se o esforço estimado para uma demanda, em relação a o esforço real da mesma, estiver dentro de o Nível de Exigência.
Inversamente, o modelo considera estimativas ruins, aquelas onde o esforço estimado da demanda, também em relação a o seu esforço real, estiver fora de o Nível de Exigência.
Por exemplo, se o Nível de Exigência é de 20%, um bom valor estimado é qualquer valor de esforço que esteja dentro de os 20% em relação a o esforço real da demanda.
Os valores que estiverem fora desses 20%, tanto para cima quanto para baixo, são considerados valores estimados ruins;·
Coleta de Dados do Projeto: A coleta regular dos dados do projeto que se deseja estimar é essencial para o bom funcionamento do Modelo­E10, pois ela mantém os dados do projeto sempre atualizados e o Modelo­E10 depende destes para realizar suas estimativas;·
Métricas de Projeto Coletadas: Para iniciar a utilização do modelo deve- se coletar no mínimo o Tamanho e o Esforço Real das demandas.
Quanto mais métricas forem coletadas melhor é para explicar a relação entre as métricas e o esforço a estimar.
Quanto mais forte a relação entre as métricas e o esforço, melhor a possibilidade de precisão do modelo.
Caso existam muitas métricas, o cálculo da correlação estatística entre cada métrica e o esforço real da demanda pode auxiliar na escolha das métricas para compor o modelo;·
Ter Volume de Dados Estatisticamente Significativo:
Para a utilização do Modelo­E10 são necessários dados de pelo menos 30 demandas finalizadas.
Esses dados são utilizados por as técnicas de estimativas incorporadas ao modelo.
Esse valor de 30 demandas torna os dados do modelo estatisticamente relevante;·
Escolha das Técnicas de Estimativas: O Modelo­E10 é uma proposta flexível projetada para agregar diferentes técnicas de estimativas ou retirar àquelas que não estejam tendo um bom desempenho.
Em a seção 5.3 é realizada uma discussão de como agregar ou retirar técnicas de estimativas para serem utilizadas por o Modelo­E10, bem como uma sugestão de quais técnicas podem ser adotadas inicialmente no modelo;·
Adotar no mínimo três técnicas:
Para o bom funcionamento do Modelo­E10, são necessárias no mínimo três técnicas de estimativas.
Essa quantidade de técnica é sugerida por.
Três técnicas geram no mínimo três modelos preditivos, o que aumenta a quantidade de valores de ETMS do modelo, e possibilita boas aproximações do esforço real da demanda;·
Definição de uma Ferramenta para aplicar as Técnicas de Estimativas:
O Modelo­ E10 utiliza técnicas de estimativas oferecidas por ferramentas de terceiros.
Como o modelo se baseia em dados de projetos, as técnicas de estimativas mais utilizadas são àquelas baseadas em estatística e mineração de dados.
Porém, não há nenhuma restrição para utilização de outras técnicas de estimativas, como o COCOMO por exemplo.
A ferramenta sugerida para a aplicação de técnicas de estimativas baseadas em mineração de dados e estatística é a ferramenta WEKA, a qual é gratuita e possui uma gama de algoritmos de mineração que podem ser amplamente utilizados para estimar o ETMS.
Caso essas ferramentas não ofereçam alguma das técnicas de estimativas que se deseje utilizar, a sugestão é que se implemente tal técnica por a parte interessada em utilizar- la.
Apresentação O Modelo­E10 é um modelo com o propósito de estimar o ETMS.
O modelo pode trabalhar com dois tipos de fontes de dados:
&quot;Dados de Projetos e Dados de Outras Técnicas». Os &quot;Dados de Projetos «são aqueles coletados por um projeto de uma organização e armazenados num ou mais repositórios de dados.
Geralmente um banco de dados ou ferramentas diversas para acompanhamento do projeto.
É sobre os &quot;Dados de Projetos «que atuam as técnicas de estimativas para tentar encontrar um valor do ETMS próximo a o esforço real.
Por sua vez, os &quot;Dados de Outras Técnicas «são gerados por técnicas externas às utilizadas por o Modelo­E10, como por exemplo:
O COCOMO 2.
0 ou o Planning Poker do SCRUM.
Há apenas duas exigências para a utilização dos valores estimados advindos de técnicas externas:
I) que os valores gerados por essas técnicas sejam numéricos;
Ii) que o valor do esforço de diferentes técnicas de estimativas esteja expresso numa única unidade de tempo, podendo ser em meses, dias, horas ou minutos.
A Figura 5.1 apresenta o Modelo­E10, onde o mesmo é constituído de oito fases, sendo elas:
E disponibilizados para o Modelo­E10;
agregados aos dados das estimativas dos períodos anteriores;
Os dados utilizados para estimar o ETMS podem estar devidamente armazenados numa base de dados centralizada, como nas organizações avaliadas no nível 2 do CMMI;
Ou não, como é o caso de organizações que gerenciam projetos de software utilizando ferramentas para controle de cronograma ou planilhas para acompanhamento de atividades, prazos e custos.
Assim, os dados devem ser coletados de forma a possibilitarem fácil acesso e não necessariamente precisam estar num banco de dados organizacional ou de projeto.
Contudo, quando estes dados estão disponibilizados num repositório central a extração destes é facilitada.
A saída desta fase é um conjunto de Dados de Projetos, que pode ser:
Identificador da demanda, esforço real, FP e QtdeDoc, por exemplo e, em se tratando de valores advindos de Estimativas de Outras Técnicas, pode se ter, além de os supracitados, o esforço estimado por a técnica externa ao Modelo­E10.
Esses valores de esforço são endereçados à fase de Retroalimentação do Modelo­E10.
A Retroalimentação é a união dos dados de todas as demandas anteriormente estimadas, com os dados das demandas que obtiveram melhores estimativas do período imediatamente anterior ao que se está estimando.
Em este contexto, um período é uma fatia de tempo definida por a organização.
Esses dados, quando unidos, são utilizados por as técnicas de estimativas para gerar os modelos preditivos a serem utilizados nas estimativas do período corrente.
Portanto, a Retroalimentação é uma forma de garantir que as técnicas de estimativas aplicadas gerem os modelos preditivos para o Modelo­E10 com base no esforço real atualizado das demandas, que são àqueles definidos na Seção A Figura 5.2 ilustra a Retroalimentação.
A calibragem inicial, representada na Figura 5.2 (a), contém os dados das demandas anteriores que estejam dentro de o Nível de Exigência do projeto.
A Figura 5.2 (b) representa as estimativas de esforço do período corrente baseadas na calibragem inicial.
Após a entrega das demandas, seleciona- se as estimativas que estiverem dentro de o Nível de Exigência do projeto sendo estas agregadas aos dados das demandas anteriores, e formando um novo conjunto de dados para serem utilizados nas estimativas do próximo período, como apresenta a Figura 5.2 (c).
A Retroalimentação é uma das principais vantagens do modelo porque com as estimativas atualizadas cresce a possibilidade do modelo estimar o ETMS convergindo para o valor do esforço real das demandas.
Além disso, as técnicas de estimativas atualmente difundidas no mercado, como o Planning Poker, não oferecem a funcionalidade de Retroalimentação, e outros processos devem ser realizados em paralelo, como por exemplo, armazenar os valores estimados e aplicar técnicas de estimativas sobre esses dados.
Já o COCOMO, também difundido no mercado, pode ser retroalimentado e calibrado com dados atualizados do projeto, porém, esse processo não é trivial de ser realizado.
A saída desta fase é um conjunto de dados, mostrado na Figura 5.2 (c), para ser armazenado no repositório da fase Calibragem, denominado Dados Calibrados.
Em a fase de Calibragem duas ações são realizadas.
A primeira de elas é o armazenamento dos dados advindos da fase Retroalimentação.
A segunda é a avaliação dos modelos preditivos, gerados por a aplicação das técnicas de estimativas apresentada na seção 5.2.4, e que estimaram dentro de o Nível de Exigência do projeto.
Ambas as informações são armazenadas no repositório Dados Calibrados e são utilizadas para realizar as estimativas de demandas do próximo período.
A avaliação dos modelos preditivos é realizada em duas etapas:
Em a primeira é calculado, para cada demanda estimada, o percentual do valor de esforço estimado em relação a o esforço real, como mostra a Equação 5.1.
A segunda etapa é a contagem da quantidade das demandas, cujo valor do percentual de esforço estimado está dentro de o Nível de Exigência do projeto.
Essa contagem é chamada de fator de ponderação e, quanto maior esse fator, maior será o peso do modelo preditivo no próximo período de estimativas.
Supondo que um conjunto de seis demandas tenham tido as aproximações do esforço real apresentadas na Tabela 5.1, e o Nível de Exigência seja de 20%, os modelos preditivos &quot;M5PTamanho «e &quot;M 5 P-QtdeDoc «terão peso 4, e o modelo preditivo &quot;RL­QtdeDoc «terá peso 1 para o próximo período de estimativas.
Só é possível avaliar os modelos preditivos de demandas que já foram entregues.
Também é importante salientar que na primeira execução do Modelo­E10, o peso de todos os modelos preditivos tem o valor de 1.
Não há atualmente nenhuma técnica de estimativas difundida no mercado que realize a avaliação constante dos modelos preditivos por ela gerados, fazendo desta, uma contribuição importante do Modelo­E10 para a área de estimativas.
O resultado desta fase é o armazenamento dos dados das estimativas, bem como o valor do peso de cada modelo preditivo, onde este último é passado à fase de Agrupamentos.
A escolha das técnicas é um dos requisitos para a adoção do modelo, como apresentado na seção projeto, armazenados no repositório Dados Calibrados.
O valor das métricas do projeto são os dados de entrada das técnicas.
Logo, para a utilização das técnicas torna- se necessário informar o valor das métricas coletadas (variáveis independentes), para que as mesmas gerem o modelo preditivo.
Em o exemplo da Figura 5.3, é mostrada uma técnica onde se informa a variável independente FP e a dependente Esforço Real.
Quando aplica- se a técnica sobre os dados de projeto é produzido um modelo preditivo que, neste caso, é uma equação linear.
O Modelo­E10 possibilita a utilização de diferentes técnicas de estimativas, inclusive àquelas utilizadas por o mercado.
Essa é das vantagens em relação a as observadas na literatura e no mercado.
A saída produzida por esta fase é um ou mais modelos preditivos para estimar o ETMS para tantas quantas forem as técnicas utilizadas sobre os dados do projeto.
Este resultado é transmitido à fase Modelos Preditivos.
Em esta fase são aplicados os modelos preditivos da fase anterior sobre os dados de entrada do projeto.
Os dados de entrada dos modelos preditivos são os dados atuais das demandas, previamente conhecidos, informados por o usuário.
Por exemplo, para se estimar o ETMS de uma demanda devese informar ao modelo preditivo o valor da métrica tamanho da demanda, em FP.
Com esse dado informado, o modelo preditivo sugere um valor de ETMS.
Geralmente os dados de entrada são calculados por outras técnicas.
O tamanho em FP, por exemplo, é calculado como sugerido por a técnica de Function Points regida por o IFPUG.
Supondo que o modelo preditivo gerado conforme ilustra a Figura 5.3, seja este dado por a Equação Esf orcoEstimado $= 4F P+ 8, 5 Supondo também que o tamanho da demanda em FP seja igual a 18, logo, a aplicação do modelo preditivo é informar o FP para a Equação 5.2.
O Esforço Estimado por esse modelo preditivo para a demanda de tamanho 18 é de 80, 5 horas de trabalho para uma pessoa.
Os modelos preditivos têm a vantagem de estarem sempre atualizados por o Modelo­E10 por meio de a Retroalimentação.
Assim, cada modelo preditivo vai gerar um valor estimado de ETMS e haverão tantos valores de ETMS quantos forem os modelos aplicados.
A saída desta fase é um conjunto de valores de estimativas de ETMS endereçados à fase Agrupamentos.
Um agrupamento é dado por um conjunto de indivíduos com certo grau de similaridade.
Os agrupamentos do Modelo­E10 são construídos utilizando três elementos:
I) o Nível de Exigência do Modelo­E10;
ii) o valor estimado por cada modelo preditivo;
E iii) média ponderada dos valores do modelo preditivo realizado na fase de Calibragem das técnicas utilizadas.
A construção dos agrupamentos foi uma evolução do Estudo de Caso apresentado no Capítulo 4, seção 4.6, onde os mesmos eram encontrados com base na distância de Euclidiana, como relatado naquele capítulo.
Assim, a Equação 5.3 apresenta o cálculo da proximidade para determinar se um indivíduo pertence ou não a um agrupamento, onde ET M S é o Esforço Estimado de Manutenção em Software, N E é o Nível de Exigência parametrizado no Modelo­E10, M P é a média ponderada do ETMS conforme o fator de ponderação dos modelos preditivos utilizados e i representa a técnica que gerou o modelo preditivo.
O agrupamento é uma das principais contribuições do Modelo­E10 diferenciando- o das demais propostas existentes na literatura e utilizadas no mercado.
Isso porque os valores agrupados refletem as &quot;opiniões «dos modelos preditivos para estimar o ETMS. Quanto mais
opiniões de diferentes modelos preditivos convergirem, maior é a probabilidade dos mesmos estimarem próximo a o esforço real da demanda.
Não há um limite para a quantidade de agrupamentos, como também pode ocorrer de não ser encontrado nenhum agrupamento.
Caso este último ocorra, cada valor é considerado um agrupamento.
A saída desta fase são os agrupamentos encontrados, endereçados à fase Seleção.
A fase de Seleção é responsável por eleger os agrupamentos que contém os valores para compor o ETMS.
É nessa fase que os agrupamentos com melhor chance de realizar boas estimativas são selecionados.
A chance é determinada por a proximidade dos valores, sendo assim, quanto mais valores próximos um do outro um agrupamento tiver, maior a chance em realizar estimativas próximas do esforço real.
As regras para a seleção dos agrupamentos foram geradas por meio de o estudo de caso apresentado no Capítulo 4 e apresentadas na seção 4.6.
Contudo, elas foram aperfeiçoadas para o Modelo­E10.
A regra 2 do estudo de caso, por exemplo, deixou de existir porque já estava implícita nos agrupamentos, com isso, das seis regras originalmente propostas, restaram apenas cinco, apresentadas abaixo, e devendo ser executadas na ordem disposta:
Assim, a média é aplicada para suavizar os valores estimados centralizando- os num valor único estimado.
Para o Modelo­E10 isso é importante porque em caso de valores muito divergentes a média suaviza a distância entre os mesmos, o que aumentam as chances do valor estimado de ETMS ficar mais próximo de o esforço real.
A saída desta fase são os valores do ETMS, onde estes são endereçados à fase de Estimativas.
Em esta fase os valores do ETMS encontrados em cada agrupamento são &quot;fundidos «por meio de o cálculo da média aritmética entre os mesmos.
A vantagem em se utilizar a média aritmética é que esta permite centralizar valores de esforço estimado que por ventura estejam muito distante um do outro.
De essa forma, mesmo o modelo não estimando bem, a média tenta reduzir o erro, pois o valor estimado é um valor intermediário entre o menor e o maior valor sugerido por os agrupamentos.
Finalmente, a saída desta fase é um valor estimado de ETMS informado ao usuário e armazenado na base de dados do projeto.
Como o Modelo­E10 é iterativo, para as próximas estimativas todas suas fases são executadas novamente.
Critérios de Elegibilidade das Técnicas de Estimativas Em esta seção são discutidos alguns critérios denominados de Critérios de Elegibilidade.
Estabelecer estes critérios é importante para que se tenha uma forma sistemática de se inserir ou retirar as técnicas de estimativas do Modelo­E10, evitando assim, o empirismo no momento de se definir tais técnicas.
Os Critérios de Elegibilidade servem para responder duas questões que emergiram por meio de o Estudo de Caso Exploratório do Capítulo 4.
A primeira de elas é:
Em meio a uma grande quantidade de técnicas de estimativas, quais de elas adotar para o Modelo­E10?
Respondendo essa primeira questão, os seguintes pontos devem ser considerados:·
Utilizar os dados do projeto:
As técnicas devem se basear nos dados de projeto porque esses dados, quando devidamente coletados e analisados, podem revelar padrões de comportamento.
Os padrões podem ser descobertos por meio de a mineração de dados, a qual utiliza técnicas estatísticas e de inteligência artificial.
Existem diversas técnicas de mineração de dados que podem ser utilizadas para as estimativas.
Geralmente as organizações que utilizam um modelo de qualidade como o CMMI, possuem coleta e armazenamento dos dados, assim, não há dificuldade em extrair os dados para as técnicas de estimativas serem aplicadas sobre os mesmos.·
Não ser sensível a volume de dados estatisticamente insignificante:
A técnica pode trabalhar com um volume de dados pequeno desde que seja estatisticamente significativo.
Inicialmente a sugestão é que se tenha dados de pelo menos 30 demandas para iniciar o Modelo­E10.·
Trabalhar com valores numéricos:
Os dados de projeto são suas métricas, estas possuem valores numéricos que expressam uma medida de grandeza dentro de o projeto.
Para se estimar o esforço faz- se necessário informar os dados de entrada para uma demanda.
Conhecidos os dados de entrada é calculada a saída, neste caso, o esforço estimado, que em grande parte das técnicas sugeridas por a literatura produzem uma saída numérica, que pode estar representado em dias, em meses, em horas ou até mesmo em minutos trabalhados.
A segunda questão é:
Quando e como adotar e retirar técnicas do Modelo­E10?
Para se adotar uma técnica basta que esta atenda os Critérios de Elegibilidade descritos na primeira questão.
Para a retirada de técnicas é necessário avaliar os modelos preditivos gerados por as mesmas no fim de cada rodada de estimativas.
O Modelo­E10 disponibiliza uma avaliação dos modelos preditivos gerados onde é possível saber o desempenho de cada modelo preditivo da rodada anterior.
Esse desempenho só pode ser analisado depois que as demandas estiverem sido finalizadas, e seus esforços reais devidamente alimentados na base dados de projeto.
O desempenho dos modelos preditivos é medido por o seu fator de ponderação, que indica quais estão com baixo desempenho.
Um modelo preditivo deve ser retirado do Modelo­E10 quando:
Em seis rodadas consecutivas de estimativas (rodadas essas suficientes para se ter um volume de dados retroalimentados considerável), o seu fator de ponderação tiver o valor igual a um.
A Tabela 5.2 apresenta uma sugestão de um conjunto de técnicas de estimativas que podem ser adotadas por o Modelo­E10.
A tabela está organizada com a coluna &quot;Técnica», que sugere três técnicas baseadas em estatística e mineração de dados;
Seguida da coluna &quot;Justificativa», que justifica a escolha da técnica sugerida;
Em a sequência, a coluna &quot;Requisito», que apresenta os requisitos básicos para que a técnica seja utilizada;
E, por fim, a coluna &quot;Para o Modelo­E10», que apresenta a vantagem e desvantagem de utilizar tais técnicas sugeridas para o Modelo­E10.
Gera uma equação para preditiva representar o comportamento dos dados em função de o Gera um modelo preditivo para cada variável independente;
MS­Excel ou o SPSS.
Expressam diferentes opiniões uma ou mais variáveis explicatinas estimativas de vas;
Extrair dados do projeto;
Quanto maior a diversidade de Utilizar uma ferramenta como o valores estimados maior é a possibilidade de convergência do valor estimado de ETMS para o esforço real;
Desvantagem: Os modelos gerados por as técnicas são sensíveis à Gera uma árvore de regressão com uma ou mais equações lineares para representar o ETMS;
Gera um modelo preditivo para uma variável independente ou um conjunto de elas;
Fácil aplicação.
Definir a variável preditiva e as variáveis explicativas;
Gerar um arquivo».
Csv «com os dados do projeto;
Ferramenta para aplicação do algoritmo.
Busca o comportamento dos dados expresso numa árvore de decisão binária para conjuntos de dados do projeto;
Decision Stump -- Por ser uma técnica de ML expressa uma representação diferente das anteriores para o comportamento dos dados;
Fácil aplicação.
As técnicas sugeridas na Tabela 5.2 atendem os Critérios de Elegibilidade e tiveram um bom desempenho tanto no estudo de caso apresentado no Capítulo 4, como no experimento realizado no 6.
Porém, as técnicas Percentual de Esforço por Equipe, Quartil 1 (25%), Mediana e Quartil 3 (75%), utilizadas no Capítulo 4, não foram sugeridas aqui, porque as mesmas não obtiveram desempenho satisfatório para estimar o valor de ETMS.
O REPTree foi substituído por o Decision Stump, porque a complexidade de implementação do primeiro é alta quando se utiliza um conjunto de variáveis independentes.
Já o último gera, uma árvore binária mais simples de entender e implementar.
Considerações Finais do Modelo­E10 O Modelo­E10 é sistemático para estimativas de ETMS evitando que as estimativas sejam realizadas de forma empírica.
Outrossim, por se basear em dados históricos de projetos, o modelo pode fazer uso de várias técnicas de estimativas baseadas em mineração de dados.
Essa é uma das vantagens do Modelo­E10, pois permite que seja gerado pelo menos um modelo preditivo para cada técnica utilizada.
Essa vantagem alinha o Modelo­E10 com a literatura, onde os autores sugerem que a utilização de mais de uma técnica de estimativas tornam os valores estimados mais convergentes com o esforço real.
Outra vantagem do Modelo­E10 é ter seus modelos preditivos sempre atualizados, já que para as estimativas futuras é realizada a Retroalimentação, onde as melhores estimativas do período anterior compõem o conjunto de dados utilizados no próximo período de estimativas.
Outrossim, os modelos preditivos são avaliados quanto a o seu desempenho;
Com isso é feita a ponderação dos modelos preditivos que obtiveram boas aproximações do esforço real.
Os resultados dos modelos preditivos são agrupados conforme seu grau de similaridade, dado por a multiplicação do nível de exigência do Modelo­E10 com sua média ponderada.
Essa característica do modelo é fundamental para estimar o valor do ETMS, pois quanto mais indivíduos estiverem nos agrupamentos, maior a chance dos diferentes modelos preditivos conseguirem boas aproximações do esforço real.
A seleção escolhe os agrupamentos com o maior número de indivíduos e calcula a média aritmética entre os mesmos para informar ao usuário o valor estimado de ETMS.
O Modelo­E10 não exclui a utilização de outras técnicas de estimativas como o COCOMO 2.
0 ou o Planning Poker, pois estas podem ser agregadas ao modelo desde que atendam os Critérios de Elegibilidade aqui apresentados.
As desvantagens do Modelo­E10 são, principalmente, em relação a os requisitos necessários para sua utilização.
A primeira de elas diz respeito à preparação dos dados de demandas para a primeira iteração do modelo.
Este trabalho é manual e laborioso, pois necessita de conhecimento na base do projeto e de construção de rotinas SQL para a extração dos dados.
Outra desvantagem diz respeito à definição das variáveis independentes, utilizadas por as técnicas de estimativas, uma tarefa criteriosa e igualmente laboriosa, a qual deve ser realizada por meio de o cálculo da correlação entre as mesmas e o esforço real.
A Tabela 5.3 apresenta como o modelo Modelo­E10 contribui para a área de estimativas segundo os aspectos apresentados nos Capítulos 2 e 3 e, ainda, observados no Estudo de Caso Exploratório do 4.
Por isso, o Modelo­E10 consegue responder a questão de pesquisa apresentada na Seção 1.2 do Capítulo 1.
Os experimentos foram realizados seguindo o processo de experimentação sugerido por[ HOR+ 00] e apresentado na Figura 6.1.
As seções subsequentes apresentam o protocolo de experimento utilizado neste trabalho.
Definição A motivação do experimento é avaliar o resultado das estimativas de esforço realizadas por o Modelo­E10 sobre os dados reais de uma fábrica de software.
Objeto de Estudo.
O objeto de estudo é o valor estimado de esforço de trabalho em projetos de manutenção de software.
O esforço é provavelmente a mais popular métrica que se tem em software.
É a partir de o esforço que são definidos prazos e custos.
Propósito. O propósito do experimento é avaliar se o Modelo­E10 pode ser amplamente utilizado nos projetos de uma fábrica de software, tendo o potencial de ao menos substituir a expertise de membros da equipe em o que tange estimar o ETMS.
Perspectivas. De o ponto de vista de pesquisa, a perspectiva é apresentar o Modelo­E10 como uma alternativa viável para se estimar o ETMS de um projeto com boas aproximações do esforço real.
De o ponto de vista de mercado é oferecer um modelo, que possa ser amplamente aplicado numa organização com boas aproximações do esforço real e sem onerar suas equipes.
Foco. O principal efeito estudado no experimento é o desempenho do Modelo­E10 sobre os dados reais de projeto.
Aqui, três aspectos são enfatizados:
I) a aproximação do esforço estimado com o esforço real utilizando diferentes técnicas de estimativas e, ainda, autoajustando o modelo para que seus modelos preditivos evoluam;
Ii) a possibilidade de substituir a expertise de um projeto para não haver mais dependência do conhecimento humano;
E iii) a desoneração das equipes responsáveis por as estimativas.
Contexto. O experimento é executado no contexto de estimativas de esforço de trabalho em manutenção de software.
Além disso, o experimento é conduzido com dados de um projeto da HP­ Consulting­Porto Alegre, o qual mantinha à época, um software de operação bancária pertencente a um grande banco estatal brasileiro.
O projeto possuía um grande orçamento e uma equipe com mais de 60 pessoas envolvidas diretamente no projeto.
Os dados do projeto eram devidamente coletados e armazenados em repositórios do próprio projeto, e foram coletados no período janeiro de 2006 ao primeiro trimestre de 2008.
O sumário da definição é:
Analisar os resultados do Modelo­E10 para o propósito de avaliação à respeito das estimativas de esforço, que é a métrica sendo avaliada, e seu desvio em relação a o esforço real do ponto de vista dos profissionais responsáveis por as estimativas no contexto de Estimativas de Esforço em Manutenção de Software.
Planejamento O experimento é focado em estimar o ETMS e é executado em laboratório, por isso é classificado utiliza dados reais de um dos projetos da HP­Consulting­Porto Alegre.
Usar dados de projeto de software, no contexto experimental, permite que outros pesquisadores tenham uma oportunidade de reproduzirem o experimento em questão para que, no futuro, possam avaliar e sugerir melhorias no Modelo­E10.
Um aspecto importante do experimento é saber como e o quê se quer formalmente avaliar no Modelo­E10.
Isso é realizado por meio de a formulação das hipóteses baseadas no seguinte pressuposto:
&quot;Uma fábrica de software utiliza a expertise de seus membros de equipe para estimar o esforço de manutenção de software por fase, como apresentado no Capítulo 4.
É sabido que existem três problemas ao se utilizar a expertise para estimar o ETMS.
O primeiro de eles é relativo à precisão das estimativas, que se mostram um tanto distorcidas, dando a falsa impressão que a precisão do membro da equipe é muito maior do que qualquer modelo que se possa adotar.
Este primeiro problema é conhecido como &quot;Síndrome de Estudante».
O segundo problema é a oneração dos membros das equipes, pois os mesmos têm que vasculhar documentos de sistema além de se reunirem para estimar tempo necessário para realizar uma demanda, isso aumenta o custo do projeto, visto que os membros de equipe poderiam estar trabalhando na implementação das demandas.
O terceiro e último problema é a dependência de conhecimento humano, que pode aumentar o custo do projeto por tornar seus membros essenciais e insubstituíveis.
Baseado no pressuposto, é formulada a hipótese com a definição das medidas necessárias para sua avaliação.
Hipótese Nula H0:
As estimativas de esforço de manutenção das demandas são mais próximas do esforço real (µEsf orcoReal) quando baseadas na expertise (µEEE) do que quando baseadas no modelo proposto.
Portanto, na visão organizacional, não há melhoria na precisão das estimativas de ETMS quando se utiliza o Modelo­E10 ao invés de a expertise do projeto P1.
Hipótese alternativa H1:,
onde Expertise Expertise Expertise M odelo-E10 M odelo-E10 $ | µEsf orcoReal -- µEEE| e M odelo-E10 $ | µEsf orcoReal -- µM odelo-E10|.
Medidas necessárias:
Pontos de Função (FP) e Quantidade de Documentos impactados por uma demanda (QtdeDoc).·
FP: Representa o tamanho da demanda a ser implementada em pontos de função;·
QtdeDoc: Representa a quantidade de documentos de sistema impactados por uma demanda.
A variável dependente é o esforço de trabalho estimado para cada fase de manutenção de uma demanda.
O esforço é computado em horas trabalhadas por uma pessoa.
As variáveis independentes são FP e QtdeDoc, devidamente coletadas por o projeto P1.
A amostra escolhida para o experimento foram as demandas do ano de 2005 a 2008, pois os dados anteriores à 2005, apesar de existirem, foram migrados de bases de dados antigas do projeto para uma nova base.
Analisando as informações das demandas anteriores à 2005 foram encontrados dados faltantes como:
Tamanho, data da demanda, identificador da demanda, de entre outros.
Provavelmente esses dados faltantes foram decorrência de incompatibilidades da migração, e, por isso, as demandas anteriores à 2005 foram descartadas do experimento.
As demandas foram divididas em conjunto de treino e teste.
Para o conjunto de treino do modelo foram separadas as demandas pertencentes ao ano de 2005, pois o volume de dados é considerável para aplicar as técnicas de estimativas do Modelo­E10.
Assim, o conjunto de treino teve 37 demandas selecionadas, e as mesmas serviram para a calibragem inicial do Modelo­E10.
Para o conjunto de testes foram escolhidas as demandas do período de 2006 a 2008, totalizando 118 demandas;
Estas foram separadas em seus respectivos meses obedecendo a sua ordem cronológica de entrada.
Esse procedimento simulou a realidade do projeto P1 e a quantidade de demandas que por mês era bem variada.
As variáveis dependentes e independentes foram escolhidas para o experimento em questão.
Ainda, foram definidas as escalas de mensuração para as variáveis.
Os princípios gerais do experimento são:
Randomização. Os sujeitos (demandas) não são selecionados aleatoriamente.
Foi obedecida uma ordem cronológica na seleção.
Essa ordem é importante, porque simula o ambiente real do projeto P1 na fábrica de software, o que torna a validação do Modelo­E10 a mais realista possível.
Agrupamentos. Há um agrupamento sistemático que deve ser realizado para melhorar a visualização dos resultados.
Isso foi identificado num estudo de caso realizado anteriormente na fábrica de software.
Como existem 24 meses a serem analisados, uma análise realizada mês a mês torna difícil a interpretação dos resultados.
Para tanto, as demandas foram agrupadas por ano e trimestre para a execução do experimento.
Balanceamento. A princípio não há como saber se a quantidade de demanda existente em cada mês influência no resultado final das estimativas de esforço.
Portanto, nenhum balanceamento dos dados foi realizado.
Sendo assim, em diferentes meses há diferentes quantidades de demandas.
Tipos de padrão do esboço.
Abaixo são apresentados os padrões de esboço do experimento para refutar ou ratificar as hipóteses nula e alternativa deste experimento.
São realizados uma série de testes estatísticos para verificar se a expertise tem melhor aproximação do esforço real do que o Modelo­E10.
Os objetos são os dados das demandas devidamente armazenados no repositório do projeto P1.
O repositório é composto por tabelas que ficam armazenadas numa base de dados MS­SQL Server 2000 e acessada por as ferramentas MS­Project Manager e IBM­RequisitePro.
Os dados foram extraídos por meio de consultas SQL executadas no banco MS­SQL Server (FP e QtdeDoc).
Também foi encontrado o esforço estimado por a expertise;
Dado esse, essencial para medir o desempenho do Modelo­E10.
Operacionalização A população do experimento é composta apenas por os dados da equipe de Projeto, pois os líderes de equipe relataram a existência de distorções nas estimativas realizadas nas fases de Cliente, Servidor e Testes.
Assim, esses dados são devidamente extraídos das bases do projeto P1, por meio de consultas SQL, e exportados para planilhas do MS­Excel.
Com os dados devidamente armazenados na planilha, é utilizada a ferramenta WEKA para calibrar o modelo, gerando assim as equações para realizar as estimativas.
Tais equações são chamadas de modelos preditivos.
Os modelos preditivos são aplicados sobre os dados das demandas que se pretende estimar, e que estão no MS­Excel.
Para tanto é necessário informar ao modelo preditivo as variáveis independentes que, neste caso, são:
FP e QtdeDoc.
Em o MS­Excel foi montado um conjunto de planilhas de dados mensais das demandas.
Cada planilha mensal contém uma macro para realizar as estimativas.
Cada planilha mensal está associada a uma planilha de avaliação dos melhores modelos preditivos do mês atual.
Essa implementação está em conformidade com o Modelo­E10 apresentado no Capítulo 5.
O Modelo­E10 necessita de uma calibragem inicial com os dados das demandas do projeto.
A calibragem do Modelo­E10 deve ser realizada com os dados das demandas do ano de 2005 totalizando 37 demandas.
A Figura 6.2 apresenta um diagrama de atividades do processo de execução do experimento.
Após a avaliação das técnicas utilizadas, o passo seguinte é alterar esse arquivo».
Csv «adicionando as melhores estimativas do período atual.
Este, então, passa a conter os dados das demandas da calibragem inicial e os dados do esforço real dessas últimas demandas estimadas.
Assim, os novos modelos preditivos são gerados por as técnicas de estimativas utilizadas na ferramenta WEKA e o ciclo recomeça.
A execução desse processo de experimentação é iterativa até que não haja mais demandas para se estimar.
A ordem das estimativas é cronológica e mensal, simulando a realidade do projeto P1.
Os dados das demandas ficavam devidamente armazenados nas bases do projeto P1 e foram extraídos por meio de consultas SQL a essas bases.
Houve a ajuda do SQA do projeto, um especialista que conhecia bem os dados do projeto P1.
Além de o SQA, havia uma boa documentação sobre os dados armazenados, que foi amplamente explorada para se extrair as informações referentes aos dados do projeto P1.
Por último, os líderes de equipe contribuíram para validar se os dados foram extraídos corretamente da base do projeto.
Para tanto, foram realizadas algumas reuniões formais em as quais essa extração foi validada.
Análise e Interpretação O esforço de trabalho real das 118 demandas utilizadas no experimento gera o histograma apresentado na Figura 6.3, com média de aproximadamente 56, 5 horas;
Desvio padrão de aproximadamente 52, 29 horas;
Mediana de aproximadamente 37, 7 horas;
Curtose de aproximadamente 3 indicando que a distribuição é leptocúrtica e possui um desvio padrão menor em relação a a uma distribuição mesocúrtica ou platicúrtica;
E coeficiente de assimetria de aproximadamente 1, 75, indicando que a distribuição é assimétrica positiva.
Por a característica do histograma apresentado na Figura 6.3 suspeita- se que o teste realizado para a validação da hipótese seja não-paramétrico, ou seja, a amostra não possui distribuição normal.
Originalmente a quantidade de demandas para o experimento era de 172, porém, após o Estudo de Caso, apresentado no Capítulo 4, foram identificados três fatos, abaixo relacionados, que poderiam distorcer os resultados do experimento.
Esses fatos contribuíram para a retirada de 17 demandas, de as quais poderiam distorcer os resultados.
A o final, restaram 155 demandas, com 37 de elas do ano de 2005 e compondo o conjunto de treino.·
Síndrome de Estudante: São identificados como &quot;Síndrome de Estudante «as demandas que tiveram o esforço real com proximidade de até 4 horas das horas estimadas por o expertise.
Além disso, são considerados outliers as estimativas que acertaram o esforço real de trabalho, pois não é possível identificar se o acerto realmente existiu ou se interferiu nos valores estimados.·
Mudança do responsável por o SQA do projeto:
Em o início de 2007 houve a troca da pessoa responsável por a qualidade do projeto.
Esta também era responsável por manter os dados do projeto.
Talvez por a inexperiência do novo membro, alguns dados do baseline original, que contém as estimativas originais das demandas do projeto, foram sobrepostos por os dados do baseline revisado, que contém informações sobre o replanejamento do esforço das demandas.
Assim, o baseline original do primeiro trimestre de 2007 foi praticamente todo sobreposto por o baseline revisado, e o esforço estimado, quando não acertou, se aproximou muito do esforço real.
Esse comportamento pode dar a impressão de que as estimativas realizadas com a expertise da equipe são muito melhores que qualquer técnica que possa ser adotada e, por isso, os dados referentes ao primeiro trimestre de 2007 foram descartados do experimento.·
Contas de chegada: Segundo informações em reuniões formais com os líderes de equipe, demandas consideradas pequenas, de até 8 horas, em sua maior parte, não eram estimadas.
Assim, o valor real de trabalho era lançado como estimado.
Outrossim, a única equipe que aparentemente seguia o processo de estimativas das demandas corretamente, era a equipe de projeto.
Em grande parte das demandas, as equipes de Cliente, Servidor e Testes, lançavam o esforço real como o estimado por a expertise.
Esse problema foi corrigido por o novo responsável de SQA do projeto, mas a maioria dos dados pertencentes às estimativas dessas equipes ficou comprometida.
Com 118 demandas restantes, fez- se uma análise para descobrir se haviam mais outliers, obtendose o gráfico
Box plot apresentado na Figura 6.4.
A partir desse gráfico foi possível identificar outros outliers, contudo, esses foram mantidos para não afetar o volume de dados do experimento.
Existem duas formas para se avaliar a aderência da amostra à normalidade:
O Teste de Kolmogorov­ Smirnov e o Teste de Shapiro­Wilk.
O primeiro é utilizado para identificar a normalidade em pequenas amostras;
Já o segundo em amostras acima de 50 indivíduos.
Como a amostra tem 118 indivíduos, o teste realizado é o de Shapiro­Wilk.
A Tabela 6.2 apresenta o resultado do Teste de Shapiro­Wilk de aderência à normalidade.
Para testar a hipótese nula é realizado o teste de Wilcoxon.
O critério para rejeição de H0 em favor de H1 é:
H1: Expertise\&gt; M odelo-E10 rejeita- se H0 se p -- valor 0, 05.
Se esse fato for comprovado, vai indicar que, em média, o Modelo-E10 estima mais próximo de o esforço real do que a expertise dos membros do projeto P1.
A Tabela 6.3 apresenta o resultado do teste de Wilcoxon.
O p -- valor apresentado na Tabela 6.3 é um valor bi-caudal ou bilateral.
A hipótese H1 trata de um teste unilateral, portanto o p -- valor deve ser dividido por dois.
Logo, p -- valor $= 0,05 2, ou seja, p -- valor $= 0, 025.
Com base nesse valor consegue- se rejeitar a hipótese nula num nível de significância de 2% em favor de H1.
Pressupõe- se então, que o Modelo­E10 estima em média mais próximo de o esforço real do que a expertise dos membros do projeto P1.
Além de o teste estatístico foi realizada uma série de análises complementares com intuito de verificar o desempenho do Modelo­E10 em relação a a expertise.
Para o projeto P1 superestimar as estimativas de ETMS é melhor que subestimar, visto que, o projeto é regido por um contrato de SLA, e está sujeito à pesadas multas quando ocorre atraso nas entregas de suas demandas.
Inicialmente é realizada a avaliação do Modelo­E10 e da expertise por meio de o Mean Magnitude Relative Error (M M Re) e do Percentage Relative Error Deviation (P RED).
O M M Re apresenta a média do erro relativo e o P RED o percentual de instâncias que estão dentro de a margem de erro aceitável, onde x é a margem de erro a ser considerada aceitável.
Uma margem de erro aceitável é um valor entre 25% e 40%.
Em seguida é avaliado o desempenho do Modelo­E10 e da expertise por meio de a média das estimativas, sumarizadas por trimestre.
A Tabela 6.4 apresenta o resultado do M M Re e o P RED após a execução do experimento.
Como o projeto P1 permite uma tolerância de 20% na margem de erro das estimativas, os valores de x foram P RED, P RED e P RED, respectivamente, alinham o experimento com as sugestões da literatura.
Como mostra a Tabela 6.4, o Modelo­E10 obteve um desempenho tão bom quanto a expertise.
Isso pode ser observado por meio de o P RED, que indica o percentual de acerto das instâncias estimadas.
Contudo, o M M Re do Modelo­E10 foi mais alto que o da expertise.
Isso indica que o Modelo­E10 é menos preciso que a expertise.
Este fato não invalida o resultado obtido, pois realizou experimentos com o M M Re e relata que quando este é utilizado para avaliar modelos, tende a identificar os modelos que subestimam como superior ao modelo verdadeiro, e modelos que superestimam como inferior ao verdadeiro.
Assim, quando analisadas as demandas estimadas, descobriu- se que o modelo superestima o esforço das demandas em 70% dos casos.
Isso explica o desempenho do pior do M M Re do Modelo­E10 em comparação com a expertise, e comprova o relato de.
A Figura 6.5 apresenta um resumo analítico trimestral do desempenho do Modelo­E10 e da expertise, ambos em relação a o esforço real de trabalho.
Como pode- se, perceber o Modelo­E10 é melhor que a expertise em 5 trimestres, enquanto que a expertise supera o Modelo­E10 em 3 trimestres.
Como relatado na 6.4.2, havia problemas de distorções no Trimestre 01/2007, por isso, o mesmo foi retirado da análise.
A Tabela 6.5 apresenta uma análise dos resultados absolutos obtidos.
Foram analisadas apenas as demandas onde o Modelo­E10 e a expertise não estimaram dentro de o Nível de Exigência do projeto P1, ou seja, errar em 20% para cima ou para baixo do esforço real.
Também foi calculado o erro quadrático médio de ambos Root Mean Squared Error para se saber qual modelo teve menos erros nas estimativas, que tiveram resultados aquém de o Nível de Exigência do projeto P1.
Com esses resultados pode- se inferir que para o projeto P1, o Modelo­E10 é mais adequado, por superestimar mais e, em média, errar menos.
Isso não ocorre com a expertise, pois ela subestima mais e tem um erro quadrático maior quando comparado ao Modelo­E10.
Sumário e Conclusões Em o experimento foi investigada a seguinte hipótese:
1. O Modelo­E10 estima o esforço de trabalho em manutenção de software mais próximo de o esforço real do que a expertise de membros da equipe.
Inicialmente foi realizado o teste de Shapiro­Wilk para verificar o comportamento dos dados das demandas selecionadas para o experimento, quando descobriu- se que o esforço real das demandas não aderiam a uma distribuição normal.
Portanto, o teste de hipótese caracterizou- se por ser nãoparamétrico.
As amostras são classificadas como relacionadas, pois todas tinham seus valores de esforço real, bem como seus valores de esforço estimado por a expertise.
Com essas características dos dados, o teste de Wilcoxon é o mais recomendado para testar a hipótese em favor de H1.
Aplicando o teste, este mostrou- se em favor de a hipótese H1 com um nível de significância de 2%.
Com a hipótese H0 negada, outras análises foram realizadas para medir o desempenho do Modelo­E10 versus a expertise.
Para tanto foram calculadas as medidas de precisão P RED e M M Re sugeridas por.
O desempenho do Modelo­E10, foi tão bom quanto o da expertise, e o percentual de instâncias que estavam dentro de os níveis de exigência do projeto P1 foi 4% maior em favor de o Modelo­E10, como apresentado na Tabela 6.4.
Também foram comparadas as diferenças absolutas do esforço real com o Modelo­E10 versus o esforço real com a expertise das demandas.
E ainda, foi realizado um teste de RM SE para as demandas que estimaram fora de o Nível de Exigência do projeto P1, quando constatou- se que o desempenho do Modelo­E10 obteve um erro quadrático médio menor que o da expertise, indicando ser mais preciso de entre as demandas que estavam fora de o Nível de Exigência do projeto.
Finalmente, pode- se inferir que o Modelo­E10 não só pode ser utilizado por o projeto P1 para as estimativas de esforço de trabalho em manutenção de software, como também, por qualquer projeto que utilize os atributos FP e QtdeDoc.
Dentro de os trabalhos apresentados por a literatura percebe- se o empenho de pesquisadores na tentativa de encontrar e aplicar técnicas de estimativas de esforço em projetos de software.
O Modelo­E10 foi concebido por meio de um estudo empírico dado por a observação dos problemas referentes às estimativas de esforço num grande projeto de software da HP­Consulting, conforme relatado por os seus gerentes e mostrado no Estudo de Caso do Capítulo 4.
Os problemas enfrentados por o projeto como:
Obter boas aproximações, desonerar membros das equipes e necessidade de autoajuste para não desatualizar seus modelos preditivos, sem desconsiderar as pesquisas na área, foram as premissas básicas para construir a questão de pesquisa apresentada na seção 1.2 do Capítulo 1.
Este capítulo apresenta as conclusões do trabalho realizado, bem como a Contribuição Científica, a Contribuição para o Mercado, a sugestão de Trabalhos Futuros e as Considerações Finais da tese.
Contribuição Científica Uma das deficiências observadas na área das estimativas é que, em geral, os trabalhos estão mais concentrados nas estimativas de esforço em desenvolvimento e não em manutenção de software.
Empregar as técnicas de estimativas de esforço em desenvolvimento na manutenção de software não é uma boa prática, pois estas podem distorcer o valor do esforço estimado.
Isso porque as estimativas de esforço para projetos de desenvolvimento se baseiam em dados de projetos anteriores e similares, enquanto que para a manutenção são baseados em dados histórico do projeto em questão.
Outra deficiência da área é que a maioria dos trabalhos utilizam as técnicas para estimar o esforço de forma isolada, quando a literatura sugere que se utilize diferentes técnicas de estimativas em conjunto.
Além disso, as propostas encontradas na literatura deixam lacunas a serem preenchidas como:
Quais dados devem ser devidamente coletados para a aplicação das mesmas?
Que tipo de técnicas de estimativas podem ser adotadas por um projeto?
Quais os requisitos de um projeto para que as técnicas sejam aplicáveis em seu contexto?
Como adotar ou descartar uma técnica de estimativas para um projeto?
Qual a quantidade mínima de dados que um projeto deve ter para aplicar as técnicas de estimativas adotadas?
Este trabalho contribui cientificamente porque propõe um modelo para estimativas de ETMS alinhado com as sugestões da literatura na área, possibilitando a utilização de mais de uma técnica e discutindo as características para a adoção e descarte das mesmas.
Outrossim, o modelo possui uma proposta de retroalimentação que busca impedir a desatualização de seus modelos preditivos, e igualmente possibilita a agregação das boas práticas das técnicas de estimativas propostas na literatura, desde que cumpram os critérios de elegibilidade estabelecidos.
Por fim, o Modelo­E10 foi concebido por um método científico, com uma avaliação criteriosa e sistemática do modelo por meio de experimentação, apresentada no Capítulo 6, onde o resultado obtido com o modelo foi satisfatório.
Contribuição para o Mercado Os experimentos preliminares realizados com os dados reais do projeto P1, apresentados nos resultados obtidos nos experimentos do Estudo de Caso mostraram que a utilização dos dados de um projeto poderia proporcionar aproximações do esforço real de trabalho consideravelmente boas.
Além disso, ao se basear nos dados do projeto, as estimativas ganham agilidade em seu cálculo, já que podem ser aplicadas técnicas estatísticas e de mineração utilizando ferramentas de terceiros.
Isso faz com que o esforço de membros de equipe seja substancialmente reduzido com a utilização do modelo.
O Modelo­E10 foi concebido de forma a permitir que técnicas de estimativas disseminadas no mercado como o COCOMO e o Planning Poker, também possam ser utilizadas em conjunto com outras técnicas.
Isso permite que um projeto não necessite abandonar sua atual técnica de estimativas, agregando a mesma no Modelo­E10, desde que esta satisfaça os critérios de elegibilidade, apresentados na seção 5.3 do Capítulo 5.
Um projeto de software, que possui uma coleta de dados regular e mantém o histórico desses dados devidamente atualizado, é um potencial candidato para adotar o Modelo­E10.
Trabalhos Futuros Uma das sugestões de trabalhos futuros é realizar a mineração de dados para avaliar os modelos preditivos, das técnicas de estimativas utilizadas, com melhor desempenho.
Isso porque o modelo implementado só avalia os modelos preditivos com base na medição de seu desempenho no período imediatamente anterior a o que se está estimando.
Acredita- se que a avaliação desses modelos preditivos seria mais precisa se, para cada modelo, fosse utilizada uma ou mais técnicas de mineração de dados sobre os dados históricos de desempenho, composto por todos os períodos anteriores.
Há indícios de que o Modelo­E10 possa ser utilizado em diferentes cenários de projetos em manutenção de software, isso porque, o modelo tem como base os dados históricos de projetos, o que o torna dependente da qualidade e do tipo dos dados coletados, e não da característica do projeto em si.
De essa forma, uma segunda sugestão é realizar experimentos com o Modelo­E10 aplicando- o em projetos de manutenção com outros cenários.
Isso garantiria sua generalização, caso os resultados alcançados fossem satisfatórios como os alcançados com o P1.
Uma terceira sugestão de trabalho futuro é a modelagem de um repositório para estimativas de software e a implementação de uma ferramenta que possa realizar as estimativas.
Não há na literatura, uma sugestão de um repositório para armazenamento de estimativas, tampouco o de uma ferramenta para realizar estimativas.
Um repositório é providencial porque possibilita a extração de conhecimento sobre as estimativas realizadas, o que pode ajudar a encontrar causas raiz para más estimativas, por exemplo, onde técnicas de mineração de dados ou de aprendizado de máquina poderia ser utilizada para este fim.
No que diz respeito à ferramenta, esta seria essencial para desonerar ainda mais os membros de equipe e facilitar a extração, transformação e carga (processo de ETL) dos dados de projetos que por ventura estivessem em diferentes repositórios.
Outrossim, a ferramenta poderia auxiliar na análise causal em problemas ocorridos nas estimativas por meio de relatórios diversos.
Considerações Finais O Modelo­E10 se diferência dos demais trabalhos existentes na literatura por permitir a utilização de diferentes técnicas de estimativas de esforço combinando- as, de modo a ajustar os valores estimados, levando em consideração as boas práticas de cada técnica.
Apesar de afirmar a falta de evidências para substituir a expertise por outras técnicas de estimativas, a literatura afirma que a expertise é suscetível a &quot;Síndrome de Estudante».
Isso foi constatado no Estudo de Caso realizado numa fábrica de software, apresentado no Capítulo 4.
Outrossim, o experimento com o Modelo­E10 alcançou resultados promissores para inferir que este modelo pode pelo menos substituir a expertise.
Isso reduz o impacto da &quot;Síndrome de Estudante», possibilitando um maior comprometimento no cumprimento de prazos e custos por parte de os projetos.
Finalmente, o Modelo­E10 não foi proposto com o propósito de ser uma solução para os problemas existentes na área de estimativas de ETMS, mesmo porque afirma que as estimativas em projetos de software estão longe de serem uma ciência exata.
Entretanto, o Modelo­E10 é sólido o bastante para ser utilizado por o mercado e por pesquisadores, quando ambos poderão explorar- lo o suficiente e proporem melhorias e adaptações para sua utilização neste amplo cenário das estimativas de esforço em manutenção de software.
