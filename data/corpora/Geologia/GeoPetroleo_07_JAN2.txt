O principal objetivo deste trabalho de pesquisa é avaliar a utilização de algumas metodologias de Mineração dos Dados (Data-Mining), que permitam identificar commaior clareza os limites de um reservatório de gás natural, ou seja, para a Delimitação de Fronteiras de um Reservatório de gás natural.

Estas metodologias, foram desenvolvidas sobre dados coletados por amostras de geoquímica de superfície, cujos levantamentos foram realizados em tempos diferentes e ocorridos para obter dados durante as estações de inverno (novembro) e de verão (julho) do reservatório de Sabinsvalle na Pensylvânia.

Dentre estas metodologias foram utilizadas técnicas de classificação supervisionada tais como redes neurais artificiais, árvores de decisão e aprendizado bayesiano.

Estas técnicas foram aplicadas às variáveis oriundas de amostras de hidrocarbonetos leves (gases) adsorvidos pelo solo, com uma série de descrições do solo e alguns fatores ambientais, considerados importantes nas análises.

A eficiência de cada método aplicado foi avaliada e observado o desempenho dos classificadores, usados como ferramentas preditivas na definição dos limites do reservatório em questão.

A aplicação destes métodos de classificação supervisionada, também tem como objetivo, a confirmação dos resultados obtidos das prospecções geoquímicas, contribuindo para clarificar as informações e tornar o conhecimento adquirido mais consistente e preciso.

Para atender aos objetivos citados acima, e obter uma melhor correlação possível entre os dados coletados e a posição dos hidrocarbonetos no reservatório, foram realizados em uma etapa anterior à aplicação das técnicas de mineração dos dados, estudos estatísticos convencionais dos dois bancos de dados, correspondentes aos levantamentos de novembro e julho.

Esta etapa consistiu no estudo dos dados e no seu comportamento interpretados por cálculos de médias, desvio padrão, valores mínimos e máximos, erro padrão, para as variáveis dependentes e frequências analisadas apenas para as variáveis categóricas.

Finalmente, foram realizadas análises de histogramas, box-plot e identificação de outliers, considerados muito importante na análise.

A busca por estes valores outliers, está na preocupação de alcançar o melhor resultado possível na futura modelagem, como também o tratamento destes visa minimizar os erros e melhorar o desempenho dos classificadores.

A integração, a incerteza presente nos dados e o gerenciamento do risco são questões chaves na geociências, na geoquímica de superfície e nas aplicações da indústria de óleo e gás.

Durante anos, muitos esforços tem surgido com o objetivo de encontrar novos métodos para solucionar estas questões.

A proximidade do próximo milênio e como grande parte dos problemas tem se transformado em questões muito complexas, torna-se difícil solucionar estes problemas através de apenas uma disciplina.

Os crescentes custos associados na maioria das vezes à pobres predições, levaram a uma necessidade cada vez maior da integração de diferentes disciplinas, da fusão dos dados, da redução do risco, do gerenciamento das incertezas e de aproximações multidisciplinares realizadas na indústria de óleo e gás.

Esta integração de disciplinas tem se tornado cada vez mais importante, quando comparada a apenas uma de curiosidade profissional que possa existir por parte dos cientistas.

Como resultado, hoje, é a integração dos resultados que deverá se transformar em uma nova forma de integração de disciplinas.

Em função disto, novas técnicas computacionais inteligentes tornaram-se cada vez mais necessárias, contribuindo para a integração e aplicação destas diferentes disciplinas tais como a Geologia, a Geoquímica de Superfície, a Geoestatística, a Geociências, a Engenharia de reservatórios, a Prospecção, dentre outras.

O desenvolvimento destas novas ferramentas que visam a redução de riscos exploratórios tem se tornado uma meta almejada por Instituições e empresas que buscam a descoberta de novos campos de petróleo e gás natural.

Em particular, a geoquímica de superfície juntamente com a sísmica, a análise estrutural e as imagens de satélite, costumam ser integradas numa etapa preliminar que antecede as atividades de prospecção mais onerosas, como a sísmica 3D.

Historicamente, tem-se comprovado que a integração de ferramentas de diferentes disciplinas, tem contribuído significativamente para reduzir os riscos e os custos operacionais nas etapas seguintes de avaliação do campo de petróleo e gás natural.

Com este propósito, diversas técnicas computacionais baseadas em paradigmas da inteligência artificial, tem sido empregadas com sucesso na indústria de petróleo e gás.

Dentre estas técnicas estão as redes neurais artificiais, as árvores de decisão, os sistemas baseados em regras, os algorítmos genéticos, a lógica fuzzy e outras aproximações computacionais, que oferecem uma excelente oportunidade e um grande desafio para a resolução de problemas práticos e mais complexos.

Outro aspecto importante destas técnicas computacionais, é o conceito da incorporação da informação heurística na forma de conhecimento inteligente, aplicadas nos processos de resolver problemas.

Esta capacidade é certo que tem se transformado mais crescente na indústria de óleo e gás.

A construção de modelos determinísticos e de interpretação tem sido crescentemente substituídos por estes métodos computacionais.

A diversidade destas aplicações de mineração de dados usadas nos problemas de campos de óleo e gás e a aceitação destas metodologias, tem se manifestado em grande interesse principalmente por parte de engenheiros e cientistas em todo mundo.

Nesta dissertação, apenas as técnicas computacionais de redes neurais, árvores de decisão e aprendizado bayesiano foram empregadas, juntamente com técnicas estatísticas convencionais e análises geológicas detalhadas, para identificar com maior certeza os limites do reservatório de gás natural.

A utilização destas metodologias que auxiliam a interpretação das informações contidas nas variáveis colhidas durante os levantamentos geoquímicos de superfície, encontra motivação fundamentada não somente na precisão dos resultados obtidos, mas também, na integração e aquisição de informações e conhecimentos relevantes relativos ao problema da determinação dos limites do reservatório de gás natural.

Esta dissertação está inicialmente constituída de quatro capítulos teóricos, um capítulo de resultados e um último capítulo com a conclusão do trabalho de pesquisa.

A organização deste trabalho de pesquisa com a descrição do conteúdo de cada capítulo está descrita resumidamente abaixo.

O Capítulo 1 descreve uma Introdução da tese.

A ênfase está na descrição dos objetivos e na motivação encontrada para a escolha do trabalho de tese.

E por último, de que forma está constituída a dissertação, que corresponde a esta seção.

O Capítulo 2 descreve a Mineração de Dados (Data-Mining), mostrando inicialmente um histórico com a evolução natural do processo de MD, suas principais definições, etapas, tarefas e aplicações.

A ênfase das tarefas está na tarefa de classificação que corresponde a parte mais importante do trabalho de pesquisa.

E por último uma citação da aplicação da classificação à Delimitação das Fronteiras de Reservatório de Gás Natural, como uma principal aplicação, por se tratar do tema desta tese de mestrado.

O Capítulo 3 descreve as acumulações de petróleo, o que são estas acumulações e como estas são formadas.

São apresentadas algumas noções da geologia do petróleo como origem, migração e aprisionamento do petróleo.

O que é necessário para que ocorra este aprisionamento, formação das armadilhas ou trapas e seus principais tipos encontrados na literatura.

São descritas com detalhes, a preservação, a integridade do trapa, a remigração do óleo até a superfície e a posterior formação de microseeps.

O Capítulo 4 corresponde ao capítulo em que são apresentados resumidamente formas de se realizar o reconhecimento de um objetivo da geoquímica de superfície, onde deve ser aplicada e quais as etapas de prospecção das bacias terrestres.

São discutidos também os métodos diretos e indiretos mais usados na análise geoquímica e suas principais características.

E finalmente, alguns benefícios que esta pode trazer para a Indústria de Petróleo & Gás.

O Capítulo 5 corresponde ao Estudo dos Casos e Resultados.

No Estudo do Casos, são descritas as principais características do reservatório, os procedimentos usados para a coleta dos dados e os materiais usados nos levantamentos geoquímicos.

No Estudo dos Resultados, faz-se uma descrição dos banco de dados, avalia-se os resultados das aplicações das metodologias, utilizando-se gráficos e tabelas, no final, discute-se os resultados.

O Capítulo 6 corresponde as conclusões do trabalho, incluindo as principais dificuldades encontradas para a realização do presente trabalho e algumas direções futuras a serem tomadas.

Uma das maiores razões porque a mineração de dados tem atraído uma grande atenção na indústria da informação nos últimos anos, é a ampla disponibilidade de enormes quantidades de dados e a iminente necessidade de se transformar estes dados em informação e conhecimento útil.

Esta informação e conhecimento, podem ser usados em aplicações de gerenciamento de negócios, controle de produção e análises de mercado, na engenharia e exploração da ciência.

A mineração de dados pode ser vista como um resultado da evolução natural da tecnologia de informação.

Um caminho evolucionário desta tecnologia de informação, tem sido amplamente adotado na indústria e apresenta como principais funcionalidades.

Coleção de dados e criação de banco de dados, sistemas de gerenciamento de banco de dados (incluindo o armazenamento dos dados e processamento da transação de banco de dados), análise de dados e entendimento ( incluindo o data warehouse e a mineração de dados).

O desenvolvimento de mecanismos de coleção de dados e criação de banco de dados, serviram como um pré-requisito para o desenvolvimento de mecanismos efetivos para armazenar e restabelecer dados, processar transações de banco de dados, além de utilizar Comandos de Acesso a um Banco de Dados1, e processamento da transação.

Na década de sessenta, houve uma transformação sistemática da tecnologia de informação e banco de dados, onde os sistemas de processamento de banco de dados primitivos foram substituídos por sistemas de banco de dados poderosos e sofisticados.

Estes numerosos sistemas de banco de dados criados, oferecem modernos mecanismos de processamento de transação e linguagens de acesso como uma prática comum.

Com isto, a análise de dados e o entendimento foram se transformando naturalmente em um alvo importante para os Sistemas de Gerenciamento de Banco de Dados(SGBDs).

Durante a década de setenta, a pesquisa e o desenvolvimento progrediram grandemente, passando de sistemas de gerenciamento de banco de dados de redes hierárquicos a Sistemas de Banco de Dados Relacionais,, ferramentas de modelagem de dados e técnicas de organização de dados.

Como resultado, os usuários passam a ter acesso à dados flexíveis e convenientes, através das linguagens de comando de acesso e da otimização do processamento desta linguagem, das interfaces dos usuários e gerenciamento da transação.

Muitos métodos eficientes para Processamento de transação on-line2, onde uma linguagem de comando de acesso é visto como uma transação somente para leitura, tem contribuído substancialmente para a evolução e para a ampla aceitação da tecnologia relacional.

Estes métodos de processamento tem sido de grande importancia e tornaram-se uma excelente ferramenta para armazenar e gerenciar grandes quantidades de dados.

Da década de oitenta ao presente momento, a tecnologia de informação tem sido caracterizada pela adoção popular da tecnologia relacional e surgimento das atividades de pesquisa e desenvolvimento de novos e poderosos Sistemas de Gerenciamento de Banco de Dados (SGBDs).

Estes sistemas de banco de dados relacionais, aplicados a sistemas orientados, incluindo banco de dados espaciais, temporais, multimídia e científicos tem crescido grandemente, assim como, sistemas de banco de dados heterogêneos e de informação global baseados na Internet, como a World Wide Web (WWW).

A intensificação de atividades relacionadas a distribuição e divisão dos dados, também tem crescido assustadoramente e se colocado como uma questão vital na indústria da informação.

Nas últimas três décadas, a tecnologia hardware do computador teve um incrível e constante progresso, além de liderar um extenso fornecimento de poderosos computadores.

Esta tecnologia providencia um grande estímulo para a indústria da informação e de banco de dados, como também, da transformação de inúmeros sistemas de informação repositórios disponíveis para o gerenciamento da transação, informação recuperada e análise de dados.

Estes dados agora podem ser armazenados em muitos diferentes tipos de banco de dados.

Como resultado, um componente da mineração de dados que tem surgido recentemente são os armazéns de dados (DataWarehousing), que se refere ao processo de coleta e pré-processamento dos dados armazenados em um ou mais banco de dados operacionais, com o objetivo de servir de fonte para sistemas de suporte de decisão.

O resultado deste processo é a criação de um depósito de dados (DD), uma coleção de dados integrados e possivelmente estruturados no tempo ( dados históricos).

Esta tecnologia de armazenamento dos dados inclui a limpeza e integração dos dados, Sistema de Armazenamento Multidimensional de Dados, em formato de cubo, que permite o rápido agregamento dos dados e detalhamento das análises, bem como, a habilidade para distinguir as informações sob diferentes pontos de vista.

Embora este armazenamento multidimensional dos dados oferecçam suporte aos processos de tomada de decisão, são necessárias outras ferramentas de análise de dados adicionais mais profundas como associação, classificação, agrupamento e caracterização dos dados.

A abundância destes dados associada a necessidade de poderosas ferramentas de análise de dados, tem sido descrita como uma situação de dados ricos, mas informação pobre (data rich but poor information).

O rápido crescimento de enormes quantidades de dados coletados e armazenados em grandes banco de dados tem superado a habilidade humana na compreensão e análise destes dados, sem que existam poderosas ferramentas para esta análise.

Como resultado, dados coletados em extensos banco de dados, transformaram-se em arquivos de dados que raramente são visitados (data tombs).

Consequentemente, decisões importantes são tomadas não somente baseadas em informações ricas de dados armazenados em banco de dados, mas também sobre a intuição humana, considerada ainda de extrema importância no processo de tomada de decisão.

Estes analistas responsáveis pelo processo de análise das informações retiradas de banco de dados, não apresentam as ferramentas necessárias para extrair o conhecimento valioso inserido em grandes quantidades de dados.

Assim, toda esta análise e interpretação que antes era realizada manualmente e que consumia muito tempo e alto custo, com o passar dos anos, transformou-se em impraticável em muitos domínios de aplicação conforme o volume e dimensionalidade dos dados foi crescendo.

Consequentemente, houve um surgimento de um grande buraco (gap) entre a geração e o entendimento dos dados, motivando o desenvolvimento sistemático de ferramentas de mineração de dados, onde estes dados possam ser inteligentemente apresentados e analisados.

Este capítulo faz uma revisão da importância e motivação da mineração de dados, e seus principais conceitos.

A mineração de dados como um processo ou fase da extração de conhecimento.

Apresenta as definições do processo de MD e descreve os seus passos.

São discutidos os seus principais objetivos e na seção 2,5 são descritos os principais métodos da mineração de dados existentes.

São descritas as mais novas e importantes aplicações da mineração de dados.

O termo Mineração de Dados refere-se simplesmente ao estado de extrair ou " minerar " conhecimento a partir de grandes quantidades de dados.


Caracteriza um processo que busca encontrar pepitas em uma grande quantidade de matéria-prima(ouro).

Existem muitos outros termos que apresentam significado similar ou parecido para a mineração de dados, como Descoberta de Conhecimento em Banco de Dados, Extração de Conhecimento em Banco de Dados, Análise Dados ou Padrões e Arquevologia de Dados.

Muitas pessoas referem-se à Mineração de Dados como um sinônimo para outro termo muito utilizado popularmente.

Extração de Conhecimento em Banco de Dados.

Outras referem-se à mineração de dados simplesmente como um passo essencial no processo de Extração de Conhecimento em Banco de Dados, em que o passo da MD deve interagir com o usuário ou com um conhecimento base.

Com isto, os padrões interessantes são apresentados ao usuário e devem ser armazenados como um conhecimento novo extraído a partir de um conhecimento base.

De acordo com esta visão, a Mineração de Dados é somente um passo no processo de extração de conhecimento.

Entretanto, o termo Mineração de Dados se transformou em uma escolha popular.

No ambiente comercial, este termo é mais utilizado para denotar o processo como um todo.

Processo este que envolve a aplicação de algorítmos para a extração de padrões dos dados e engloba desde a definição e identificação até a resolução de um problema de mineração.

Este processo este é constituído de várias fases ou passos.

Dentre os passos que constituem o processo de Mineração de Dados estão.

Entendimento e identificação do objetivo, criação de um banco de dados alvo, pré-processamento dos dados (incluindo limpeza e transformação), extração de padrões, interpretação e avaliação dos resultados e descoberta do conhecimento.

Nesta dissertação, o termo da Mineração de Dados é utilizado para representar todo o Processo de Extração de Conhecimento interessante a partir de grandes quantidades de dados armazenados em banco de dados, armazéns de dados ou outras fontes de armazenamento de informação repositória.

O passo deste processo em que são aplicados os algorítmos sobre os dados é denominado passo da extração de padrões.

O processo de mineração de Dados envolve uma integração de técnicas multidisciplinares como Estatística, Aprendizado da Máquina, Tecnologia de Banco de Dados, Reconhecimento de Padrões, Redes Neurais, dentre outras.

Em vista disso, este processo é considerado uma das mais importantes frentes dos sistemas de banco de dados e uma das maiores promessas interdisciplinares desenvolvidas na indústria da informação.

Tradução para o termo Knowledge Discovery in DataBases (KDD).

Esta seção subdivide-se em duas partes.

São apresentadas duas definições básicas do processo de MD e descritos alguns termos comumente utilizadas nesta área.

São apresentados os passos que constituem o processo de mineração de dados.

Existem na literatura muitas definições para o termo mineração de dados.

O processo de Mineração de Dados pode ser definido como um processo não trivial de identificação de padrões válidos, novos, potencialmente úteis e inteligíveis em um conjunto de dados.

Processo. O processo de mineração de dados é constituído da vários passos que envolvem a preparação dos dados, a procura por padrões, a interpretação e avaliação dos resultados, dentre outros.

O processo é dito ser não trivial porque apresenta algum grau de autonomia (semi-automático) no processamento e na avaliação dos resultados.

Neste processo semiautomático o sistema deve ser capaz de decidir que cálculos deve realizar e que resultados devem ser interessantes no contexto da extração do conhecimento.

Corresponde a um conjunto de fatos (por exemplo,casos em um banco de dados) utilizados.

Este conjunto de dados pode ser natural ou sintético.

Um conjunto de dados natural é encontrado em banco de dados, e é resultante, por exemplo, de operações transacionais de uma determinada empresa ou de fenômenos naturais.

Um conjunto de dados sintético é gerado artificialmente e os valores de atributos são normalmente gerados aleatoriamente, somente seguindo uma distribuição estatística.

É uma expressão em uma determinada linguagem que descreve um subconjunto de dados ou modelos associados a este subconjunto de dados.

A extração de um padrão também é designada como um ajuste ou construção de um modelo aos dados, encontrando estruturas nos dados ou em geral realizando qualquer descrição de alto nível a partir de um conjunto de dados.

Dado um conjunto de fatos (dados) F, uma linguagem L, e uma medida de certeza C, um padrão pode ser definido como uma declaração S em L que descreve relacionamentos entre um subconjunto Fs de F com um grau de certeza C.

Um padrão deve ser mais simples que um dados propriamente dito, implicando na necessidade de uma linguagem para se representar os padrões.

Um exemplo de linguagem ou formalismo utilizado para a representação de padrões é uma linguagem de equações.

Quanto aos tipos de padrões extraídos no processo de mineração de dados, podem-se encontrar na literatura duas classificações básicas para estes padrões.

Preditivos e descritivos (ou informativos).

Os padrões preditivos são construídos com o intuito de se resolver um problema específico de predição de valores de um ou mais atributos, em função dos valores de outros atributos.

Enquanto os padrões descritivos, o ponto central está em se apresentar informações interessantes que um analista de dados possa ainda não conhecer.

Na terminologia utilizada na comunidade de aprendizado de máquina, a distinção é feita através da separação dos algorítmos em dois tipos.

Os de aprendizado supervisionado e os de aprendizado não-supervisionado, correspondendo aos algorítmos que geram padrões preditivos e descritivos, respectivamente.

Em muitos casos os usuários não tem idéia que tipos de padrões extraídos dos dados devem ser interessantes e procuram em paralelo, por outros tipos de padrões.

O importante, é ter um sistema de mineração de dados em que possa ser possível extrair múltiplos tipos de padrões que acomodem diferentes expectativas ao usuário.

Além disso, estes sistemas de MD devem estar disponíveis para descobrir padrões com muitos níveis de abstração.

Como consequência da Definição citada anteriormente, surge uma medida importante chamada de Interessabilidade5.

Nesta medida, numerosos padrões podem ser extraídos de banco de dados somente se forem interessantes.

Um padrão interessante (de acordo com alguma medida de interesse) e certeza (de acordo com o critério do usuário) representa conhecimento.

Usualmente esta noção de Interessabilidade corresponde a uma medida global do valor de um padrão, em que todos os padrões devem ser válidos, novos, potencialmente úteis e inteligíveis.

Padrões Válidos. Os padrões descobertos devem ser válidos sobre os dados novos com algum grau de certeza.

A representação do grau de certeza é essencial para se determinar o quanto um sistema ou usuário pode confiar nos padrões e tomar decisões a partir deles.

Um grau de certeza envolve vários fatores, incluindo a integridade dos dados, o tamanho da amostra utilizada no processo de descoberta, e, possivelmente, o grau de existência do conhecimento de domínio disponível.

Sem um grau de certeza suficiente os padrões descobertos não podem ser considerados como conhecimento.

Padrões Novos.

A questão de um padrão descoberto ser novo depende do ponto de vista do qual se está analisando, que pode ser o escopo do sistema ou do usuário.

Para um sistema, um determinado padrão descoberto pode ser novo, mas para o usuário este padrão pode ser uma Tautologia e não representar um conhecimento.

Os padrões descobertos devem ser novos, pelo menos para o sistema e preferencialmente para o usuário.

Padrões Potencialmente Úteis.

Os padrões descobertos são úteis se eles podem ajudar a alcançar o objetivo do sistema ou do usuário.

A decisão se os padrões extraídos são úteis é feita no passo de interpretação e avaliação (seção 2,3,2) do processo de MD, atividade na qual o julgamento humano é usualmente requisitado.

Padrões Inteligíveis. Um dos objetivos do processo de mineração de dados é produzir conhecimento que possa ser compreendido facilmente, de forma a tornar mais fácil o entendimento dos dados que originaram este conhecimento.

Isto implica em que a linguagem para representação dos padrões possam ser transformados de forma a se tornarem inteligíveis.

Uma técnica bastante utilizada para alcançar este objetivo é apresentar os padrões de forma gráfica que facilite seu entendimento.

O processo de mineração de dados pode ser definido como a análise e exploração de grandes quantidades de dados, para descobrir o completo significado dos padrões e regras, por meio automático ou semi-automático.

Esta definição apresentada por Berry e Linoff, enfatiza que grandes quantidades de dados continuam a serem geradas hoje, muito mais por meio de técnicas automáticas do que pela análise e exploração do completo significado dos padrões e regras extraídos.

Como resultado, esta definição tem levado muitas pessoas a acreditar que o processo de MD é um produto que pode ser comprado e não uma área a ser dominada.

Em um processo de mineração de dados, muitas são as atividades com o qual o analista de dados está envolvido.

No nível mais alto, o analista de dados, em resposta a um objetivo definido (seção 2,4), consulta o banco de dados para extrair informações relevantes a realização deste objetivo6.

É feita, então, a análise dos dados utilizando-se de ferramentas de análise e/ou visualização.

Estas ferramentas de análise e visualização constituem os componentes do sistema de MD utilizado.

Conforme o analista de dados vai interagindo com os dados através do sistema de mineração de dados, ele vai ganhando algum nível de entendimento (insight) acerca destes dados.

Este entendimento permite que ele realize a construção de um modelo a partir dos dados.

O analista então apresenta os resultados retirados deste modelo.

Esta atividade do analista de dados, auxiliada por um sistema de mineração de dados, está relacionada a vários passos do processo de MD.

O processo de MD é iterativo, começando com o entendimento e identificação do problema e terminando com a descoberta do conhecimento útil.

Os passos do processo de mineração de dados se complementam, ou seja, o processo envolve significantes iterações, podendo conter ciclos entre qualquer um dos passos e o analista de dados pode ir e vir entre estes passos repetidamente.

Este ciclo, é portanto tanto iterativo quanto interativo.

Esta seção detalha cada um destes passos que constituem o processo de mineração de dados.

Contudo, esta visão é apenas conceitual e na prática, alguns dos passos podem ser realizados simultaneamente.

O processo de mineração de dados inicia quando o analista de dados busca o entendimento claro do domínio do problema, e o conhecimento relevante necessário a identificação deste problema.

A investigação acerca do conteúdo do conjunto de dados com nomes de campos, tipos, etc, deve ser identificados e englobados em dicionários de dados pelos analistas de dados.

É usualmente recomendada se despender uma quantidade significante de tempo juntamente com a organização interessada, para entender a forma, conteúdo e fontes de dados.

Somente então, o problema real pode ser encontrado.

Informações complementares acerca da estrutura do conjunto de dados e de relacionamentos entre seus objetos, como também informações que ajudem ao analista de dados sobre a qualidade destes dados ser ou não satisfatória a análise do problema.

Estas informações adicionais podem servir de ajuda no passo da extração de padrões.

Este passo do processo de MD, é importante porque sem um claro entendimento do problema real a ser identificado, os resultados obtidos podem não ser satisfatórios.

Este passo inclui a criação de um conjunto de dados que deverá ser escolhido como alvo, através da seleção deste conjunto de dados sobre o qual a extração de padrões deverá ser realizada.

Este conjunto de dados é normalmente chamado de "mine relation".

Ao mesmo tempo em que a seleção do conjunto de dados alvo é realizada, o foco está em definir, um subconjunto de atributos relevantes ou uma amostra de dados necessária ao problema da mineração de dados a ser resolvido.

Com isto, este passo torna-se bastante importante, na medida em que o conjunto de dados a ser escolhido como alvo, vai refletir diretamente na qualidade dos padrões extraídos a partir de uma coleção de dados.

Este terceiro passo do processo de mineração de dados é composto da limpeza de dados (Data cleaning) e transformação dos dados.

O passo inclui operações básicas para a remoção de ruídos ou valores aberrantes (outliers) quando necessário, retirada de eventuais inconsistências nos dados, coleção de informação necessária a construção do modelo, tratamento de campos não disponíveis, bem como, decidir questões sobre banco de dados, como tipos de dados, esquemas de dados e mapeamento de valores desconhecidos e perdidos em alguns atributos.

Corresponde ainda, a redução e projeção dos dados em que visa encontrar aspectos úteis para representar estes dados.

Dependendo do objetivo da atividade de MD, pode-se utilizar a redução de dimensionalidade através da aplicação de métodos de transformação dos dados, para reduzir o número efetivo dos atributos analisados ou para encontrar representações invariantes para os padrões extraídos.

O passo da extração de padrões corresponde a procura por padrões interessantes em um conjunto de dados, através da seleção de métodos a serem aplicados.

A medida que estes dados vão interagindo com a experiência do analista de dados na seleção de uma hipótese, este analista deve então decidir qual o tipo de modelo e parâmetros que devem ser apropriados ao desenvolvimento deste modelo.

Após isto, o algorítmo de mineração de dados deve ser escolhido e posteriormente executado e os padrões devem ser representados em uma forma particular.

Neste passo do processo de MD, a extração de padrões é feita através da aplicação de algorítmos específicos que utilizam técnicas computacionais multidiciplinares provenientes de áreas de pesquisa como Estatística e Aprendizado da máquina.

A maior parte destes algorítmos podem ser vistos como composições de técnicas e princípios básicos para implementar métodos gerais.

Estes algorítmos utilizados no processo de MD podem englobar três principais componentes, representação do Modelo, critério de avaliação do modelo e procura do algorítmo.

Após os padrões serem extraídos estes devem ser interpretados, possivelmente retornando a qualquer um dos passos anteriores do processo de MD.

Seguido da interpretação deve vir a tarefa de visualização destes padrões extraídos, dos modelos e dados utilizados para a remoção de padrões irrelevantes e redundantes, assim como, da representação deste padrões em informação útil e inteligível ao usuário.

Esta informação pode ser de várias formas.

Simplesmente através da realização de um relatório notificando resultados das análises.

Ou através de formas mais complicadas, como gráficos e em alguns casos, é desejável que haja descrições de ações a serem tomadas diretamente como saída.

Esta saída deve determinar que tarefas designam aplicações do processo de MD.

Este último passo do processo de mineração de dados inclui a incorporação do conhecimento descoberto em um sistema de desempenho, realizando ações baseadas no conhecimento ou simplesmente documentando este conhecimento por meio da realização de relatórios que deverão ser notificados as partes interessadas, bem como, checando e resolvendo conflitos potenciais que possam vir a existir durante a interpretação do conhecimento útil extraído.

O processo de mineração de dados envolve repetidas aplicações iterativas associadas a tarefas particulares para extração de padrões dos dados.

Estas tarefas que serão discutidas na seção 2,5 podem apresentar objetivos que devem ser aplicados sucessivamente para encontrar um resultado desejado.

Os objetivos dependem da análise e entendimento do processo de extração de conhecimento como um todo, pelo analista de dados.

Embora os limites entre a predição e descrição não sejam visíveis (alguns dos modelos preditivos podem ser descritivos ou vice-versa), a distinção entre eles é importante para entender qual o objetivo de extração dos padrões deve ser aplicado como um todo e de que forma a atividade de mineração de dados é exercida.

Esta seção apresenta uma breve revisão dos dois principais objetivos da mineração de dados.

Em ambos os objetivos, o processo de descoberta do conhecimento procura encontrar automaticamente novos padrões.

No objetivo preditivo o esforço da mineração de dados está em descrever a automatização do processo de tomada de decisão.

Este processo visa encontrar padrões preditivos através da criação de um modelo, capaz de predizer valores futuros ou desconhecidos de um ou mais atributos, em função dos valores de outros atributos.

Na predição a atividade principal está em encontrar atributos de interesse a partir de um conjunto de atributos relevantes (por meio de análises estatísticas) e predizer a distribuição do valor de certos atributos, baseados em uma coleção de dados similares aos objetos selecionados.

Por outro lado, um modelo preditivo pode ser interpretado como sendo uma reflexão da realidade, em que normalmente, os resultados desta predição são descritos diretamente.

Se for oferecido a uma pessoa um crédito, ou um seguro ou uma oportunidade para esta ganhar uma viagem para Orlando, os resultados dependem do modelo utilizado para esta proposta.

Neste cenário, a medida mais importante de um modelo será a sua exatidão.

Ou seja, o quanto mais exato será o modelo utilizado.

Usualmente, análises de regressão, modelo linear generalizado, análises de correlação e árvores de decisão são ferramentas muito utilizadas para alcançar um objetivo de predição com qualidade.

Algorítmos genéticos e modelos de redes neurais, também são usadas popularmente para a realização deste objetivo.

No objetivo descritivo o esforço da mineração dos dados está em aumentar o entendimento do que está inserido nos dados.

Este objetivo tem como principal meta, encontrar padrões descritivos (seção 2,3,1), que forneçam ao analista de dados o entendimento e as informações interessantes que descrevam os dados.

A descrição providência uma concisa sumarização de uma coleção dos dados e as distingue uma das outras.

Esta sumarização é chamada de caracterização e a comparação entre duas ou mais coleções de dados é chamada de discriminação.

Esta não deve cobrir somente estas propriedades de forma resumida, como soma, média, mas também, propriedades de dispersão sobre os dados, como variância, quartiles, etc.

Pode ser usado, por exemplo, para comparar vendas de uma empresa Européia e Asiática, identificando importantes fatores no qual discriminam as duas classes e apresentam uma revisão sumarizada.

A descrição resulta em ações que não podem ser automatizadas diretamente de resultados de um modelo.

Assim o melhor modelo pode muitas vezes gerar ou não predições muito exatas.

O termo modelo também é utilizado na literatura para fazer referência a um padrão ou conjunto de padrões.

Diz-se que se está aprendendo, construindo ou induzindo um modelo a partir de um conjunto de dados quando para denotar o processo de procura por um conjunto de padrões ou modelo subjacente a esta coleção.

Quando se faz uma estimativa dos valores para os atributos de itens da coleção cujos valores não são conhecidos, diz-se que o modelo está sendo aplicado a esta coleção.

A mineração de dados envolve a construção destes modelos para a determinação de padrões extraídos a partir de dados observados.

Esta construção dos modelos ora reflete conhecimento útil ora interessante, como parte de todo o processo de mineração de dados, onde o julgamento subjetivo do homem é tipicamente necessário.

Surgem a partir daí, dois principais formalismos matemáticos muito usados para a construção e o ajuste de um modelo.

No modelo estatístico os efeitos são puramente não-determinísticos, enquanto que no modelo lógico os efeitos seguem aproximações determinísticas.

A mineração de dados os modelos estatísticos são mais amplamente utilizados como base para as suas aplicações, visto que os dados usados em um processo de MD apresentam um típico grau de incerteza no mundo real.

As tarefas da mineração de dados podem apresentar diferentes objetivos dependendo de como todo o processo de descoberta de conhecimento deve ser entendido e de como o problema deve ser resolvido.

Para cada tarefa apresentada existem diferentes métodos que devem ser aplicados para alcançar um objetivo definido.

Na sua maior parte, são baseados no treinamento e teste de técnicas de Aprendizados da Máquina, Reconhecimento de Padrões e Estatística.

Estas tarefas apresentam-se definidas no primeiro passo da identificação do problema de MD (Seção 2).

Existem na literatura inúmeras possíveis tarefas da mineração de dados, algumas mais comumente encontradas.

Regressão, Classificação, Agrupamento (Clustering), Modelagem das Dependências, Análise das Ligações (Associations), Visualização do Modelo, Análise de Dados Exploratórios (ADE) e Análise de Desvios.

Entretanto, nesta seção é discutido suscintamente a Tarefa de classificação por ser de grande importância e escopo desta dissertação.

Os parágrafos à seguir fazem uma revisão dos principais conceitos desta tarefa de Classificação.

Finalmente, na seção 2,5,3, está definido o conceito de métodos da tarefa de Classificação e os principais métodos que são abordados nesta dissertação.

Árvores de Decisão, Aprendizado Bayesiano e Redes Neurais.

No capítulo anterior foi mencionado que existem algumas tarefas que fazem parte do processo de mineração de dados, dentre elas, está uma de grande importância nesta dissertação, a tarefa de Classificação.

Esta tarefa procede o passo de pré-processamento dos dados no processo de MD e corresponde ao passo de extração de padrões.

Esta tarefa de Classificação gera padrões de predição semelhantes à tarefa de regressão, sendo que a primeira prediz o valor de um atributo nominal ou categórico ao invés de um atributo de valor real.

O atributo alvo da predição é chamado classe.

Possíveis aplicações desta área podem ser a predição do comportamento dos clientes de um banco, a sinalização de transações fraudulentas, predição de ações de valores, entre outras.

Nesta tarefa, os atributos da relação mina são particionados em dois grupos.

Um dos grupos contém somente um atributo, que corresponde ao atributo alvo, ou seja, o atributo do qual se deve fazer a predição da classe.

O outro grupo contém os atributos a serem utilizados na predição da classe, denominados atributos previsores ou atributos de predição.

O atributo Buys_Computer é o atributo alvo e os atributos Age, Income, Student e Credt_Rating são os atributos previsores.

O objetivo da tarefa de Classificação é através da utilização de algum método, gerar um modelo de classificação a partir da relação mina (conjunto de treinamento), de tal forma que este modelo permita a classificação de novas tuplas, ou seja, de tuplas que não foram utilizadas para a geração do modelo.

Por este motivo é que o conjunto de treinamento utilizado deve representar a real distribuição de valores dos atributos.

O processo de Classificação dos Dados corresponde a uma primeira etapa de Aprendizado dos Dados, onde os dados de Treinamento são analisados por um algorítmo de classificação.

E em uma segunda etapa à Classificação, em que os dados de Teste são usados para estimar a exatidão da classificação.

Na Seção seguinte serão descritos os dois passos deste processo de classificação dos dados.

O primeiro passo, corresponde à Construção do modelo.

Enquanto que o segundo passo da Classificação corresponde ao Uso do Modelo.

Cada um destes passos será descrito nos parágrafos à seguir.

Neste primeiro passo, um modelo é construído para descrever um conjunto pré-determinado de classes de dados ou conceitos.

O modelo é construído pela análise de tuplas10 contidas em banco de dados e que são descritas pelos atributos.

Cada tupla é então assumida pertencer a uma classe pré-definida, como determinado por um dos atributos, chamado atributo classe.

Estas tuplas dos dados uma vez analisada para construir o modelo forma coletivamente o conjunto de treinamento dos dados.

As tuplas individuais que fazem parte do conjunto de treinamento são referidas como amostras de treinamento e são relacionadas ao acaso da população da amostra.

Desde que a classe de cada amostra treinada é conhecida, este passo é também conhecido como Aprendizado Supervisionado.

Neste aprendizado o treinamento dos dados realizado a partir de um conjunto de observações, medidas, etc, deve ser acompanhado por categorias indicando a classe destas observações em que novos dados são classificados baseados sobre o conjunto de treinamento.

Enquanto que no Aprendizado Não-Supervisionado (Clustering) a classe de cada amostra treinada é desconhecida e dado um conjunto de observações, medidas, etc, o objetivo será o de aprender o número de classes ou clusters nos dados.

Tipicamente o modelo de aprendizado é representado na forma de regras de classificação, árvores de decisão e formulações matemáticas.

Por exemplo, dado um banco de dados com informação de créditos de consumidores, as regras de classificação podem ser aprendidas para identificar os consumidores que tem créditos satisfatórios.

Assim, as regras podem ser usadas, para classificar futuras amostras de dados, bem como, providenciar um melhor entendimento do conteúdo dos bancos de dados.

Onde as regras aprendidas a partir da análise dos dados e da existência de clientes pode ser usada para predizer a taxa de crédito dos novos ou futuros clientes.

Uma vez construído o modelo, este é usado para classificar objetos futuros e desconhecidos.

Deve-se em seguida estimar a exatidão ou precisão do mesmo, ou seja, o quão efetivo este é na predição da classe de novas tuplas.

Duas importantes técnicas são bastante utilizadas para estimar a exatidão de um modelo (classificador).

Na primeira técnica, está o método holdout,que refere-se a uma técnica simples que usa um conjunto de teste de amostras de classes.

Estas amostras são selecionadas ao acaso e são independentes das amostras de treinamento.

Outra técnica bastante utilizada para estimar a exatidão é a validação Cruzada (cross-validation).

Nesta técnica as tuplas são aleatoriamente divididas em k partições de tamanho aproximadamente iguais.

As tuplas não presentes em uma dada partição são utilizadas para a geração do modelo de classificação.

Este modelo é testado, utilizando-se a partição correspondente.

Assim, são gerados k modelos, cada um com sua própria taxa de erro de teste, taxa esta calculada sobre o conjunto de teste.

A exatidão de um modelo sobre um dado conjunto de teste é a percentagem das amostras deste conjunto de teste que estão corretamente classificadas pelo modelo.

Para cada amostra teste, a classe conhecida é comparada com o aprendizado do modelo na predição da classe para aquela amostra.

Assim, se a exatidão de um modelo foi estimada baseado sobre o conjunto de treinamento dos dados, esta estimativa pode ter sido otimista, normalmente pelo fato de ter havido uma superespecialização (overfitting) sobre os dados na fase de adequação do modelo.

Se a exatidão de um modelo é considerada aceitável, o modelo pode ser usado para classificar futuras tuplas dos dados ou objetos pelo qual a classe não é conhecida.

Assim, cada dado também é conhecido na literatura do Aprendizado da Máquina como dados desconhecidos ou não vistos.

No passo de Extração de Padrões do processo de mineração de dados, pode-se utilizar diversos métodos (ou paradigmas) de aprendizado indutivo.

Esta Seção descreve as diferenças entre este tipo de aprendizado e o aprendizado dedutivo para dar uma definição do que seja um método de MD na tarefa de classificação.

Primeiramente, deve-se fazer uma análise das duas principais técnicas utilizadas para se fazer inferência (ou aprendizado) de informações a partir de uma coleção de dados.

Dedução e indução.

Dedução é uma técnica utilizada para inferir informações que são uma consequência lógica da informação armazenada na coleção de dados.

Esta técnica é encontrada em SGBDs dedutivos, onde são armazenados fatos (ou relações) e regras, com as quais pode-se derivar informações a partir dos fatos.

Note que este tipo de inferência gera informações que são uma consequência lógica dos dados utilizados, ou seja, não há informações ou padrões novos.

Por este motivo, a técnica de dedução não é muito utlizada em mineração de dados, onde, os padrões interessantes devem ser novos.

No entanto, a integração de técnicas dedutivas e indutivas parece ser um bom caminho para aumentar a qualidade dos padrões extraídos em sistemas de MD.

Em, por exemplo, é discutido como banco de dados dedutivos, visualização de regras e indução de regras podem ser utilizados cooperativamente para se fazer MD.

Na indução, há inferência de informação que constitui uma generalização dos dados utilizados.

Por exemplo, considere as relações Empregados, Gerentes e Departamentos em um banco de dados relacional.

Utilizando-se este paradigma, pode-se induzir que cada empregado tem um gerente, o que é uma generalização a partir dos dados existentes naquelas relações.

Pode ser que haja pelo menos um empregado que não tenha gerente.

Porém, na indução, este fato não é importante, contanto que a generalização produzida se mostre válida na maioria dos casos.

Ao se utilizar o paradigma de indução, diz-se estar realizando um aprendizado indutivo.

A diferença mais importante entre dedução e indução é que a primeira resulta em declarações verdadeiras (absolutas) sobre a coleção de dados utilizada na inferência, enquanto que a Segunda resulta em declarações provavelmente corretas sobre esta coleção.

A partir dos conceitos acima definidos, pode-se dizer, que os métodos de mineração de dados envolvem a utilização de alguma técnica de aprendizado indutivo, objetivando a adequação (inferência) de um modelo ou a determinação de similaridades a partir de um conjunto de dados.

Alguns dos métodos da Classificação tem sido propostos por pesquisadores do Aprendizado da Máquina, Sistemas Inteligentes, Estatísticos e Neurobiologistas.

Dentre os métodos de Classificação podemos citar.

Indução de Árvores de Decisão.

Este processo é análogo ao que acontece com seres humanos e outras criaturas inteligentes (denominadas sistemas cognitivos).

Estes tentam entender o ambiente a sua volta através do uso de uma generalização desse ambiente, ou seja, de um modelo.

Durante a fase de aprendizado, o sistema cognitivo observa o ambiente e reconhece similaridades entre objetos e eventos, similaridades estas que servem para a generalização do modelo.

Neurais, Classificação Bayesiana, Associações, Algorítmos Genéticos, Logica Fuzzy e Análise de Agrupamento (Clustering).

Entretanto, nesta dissertação apenas os métodos de Indução de Árvores de Decisão, Aprendizado Bayesiano e Redes Neurais serão discutidos com mais detalhes.

Amplamente utilizada em algorítmos de classificação, as árvores de decisão são representações simples do conhecimento e um meio eficiente de construir classificadores que predizem classes baseadas nos valores de atributos de um conjunto de dados.

Normalmente, os algorítmos que se encaixam neste método produzem inicialmente uma estrutura de representação de conhecimento denominada árvore de decisão, que posteriormente é transformada no conjunto de regras de produção.

Por este motivo, estas árvores de decisão são também chamadas de algorítmos de indução de regras.

Estes algorítmos de regras são bastante utilizados para classificação pelo fato de produzir padrões inteligíveis.

Os padrões gerados neste método são regras de produção.

Uma regra de produção é uma declaração da forma C1.

C2, onde C1 e C2 são o antecedente e o consequente da regra, respectivamente.

Estes, por sua vez, geralmente são compostos de uma conjunção de predicados e de um predicado, respectivamente.

Predicados são relações sobre objetos e/ou valores de um banco de dados da forma ai v onde ai faz referência ao i-ésimo atributo da tupla t, v é um valor qualquer pertencente a Dom(ai), e é um operador relacional ( >, < <,> ou =).

Esta regra denota que sempre que os atributos previsores Student e Credit_Rating assumem os valores >40 e Excellent, respectivamente, é previsto o valor no para a classe do atributo alvo Buys_Computer.

Na verdade árvores de decisão e regras de produção são padrões equivalentes, no sentido de que pode-se converter uma representação na outra.

Uma árvore de decisão é constituída de uma série de nós internos, onde cada um deste nós está associado a um atributo previsor.

Partindo de um determinado nó interno, tem-se k arestas (ramos), onde k é o número de possíveis valores do atributo previsor.

Cada uma destas arestas termina em outro nó da árvore, que pode ser outro nó interno ou uma folha.

As folhas (nós externos) da árvore de decisão correspondem a valores do atributo alvo, ou seja, a uma predição da classe deste atributo.

Nesta árvore, há três nós internos, correspondentes aos atributos previsores Age, Student e Credit_Rating.

De cada um deste nós, partem arestas que terminam em outros nós ou folhas.

Considere, por exemplo, o atributo Age, correspondente à raíz da árvore.

Deste atributo, partem três arestas, sendo que o correspondente ao valor overcast termina em uma folha que prediz o valor yes para o atributo alvo Buys_Computer.

As outras duas arestas saindo deste nó terminam nos internos correspondentes aos atributos Student e Credit_Rating.

Note que estes dois nós internos podem ser considerados como raízes de suas respectivas sub-árvores.

Árvores de decisão, na sua forma normal, são univariáveis, significando que cada vértice corresponde a um único atributo previsor.

Árvores univariantes são o tipo mais estudado na literatura.

No entanto, pode-se encontrar trabalhos sobre árvores de decisão multivariáveis ou oblíquas, nas quais o teste feito em um dos nós da árvore é constituído de uma combinação linear dos atributos previsores.

De forma genérica, pode-se dizer que um algorítmo de indução de árvores de decisão ou de indução de regras possui os seguintes parâmetros de entrada.

Uma relação R correspondente ao conjunto de treinamento, onde, em cada uma de suas tuplas, um dos atributos é o atributo alvo e os demais são os atributos previsores, ou atributos candidatos.

Uma função de avaliação que determina a qualidade de um determinado atributo com relação ao quão bem este atributo, por si só, classifica o conjunto de treinamento.

Um critério de parada que determina quando a expansão da árvore deve terminar.

O algorítmo de indução de árvores de decisão segue iterativamente, a cada passo gerando uma sub-árvore da árvore de decisão inicial.

A árvore inicial é constituída de um único nó, a raiz, ao qual estão associadas todas as tuplas de relação R.

Um dos atributos do conjunto de atributos previsores é escolhido para formar a raíz da árvore, de acordo com a função de avaliação sendo utilizada.

Uma vez escolhido este atributo, o conjunto de dados é particionado, segundo os valores deste atributo.

Cada uma destas partições é associada a uma das arestas que saem do nó correspondente ao atributo selecionado.

Os demais nós da árvore são produzidos aplicando-se recursivamente o algorítmo a cada uma das partições.

A cada iteração, se o critério de parada não é satisfeito, a árvore é novamente expandida.

Em relação à função de avaliação, esta varia de um algorítmo de indução de árvores de decisão ou IR para o outro.

A seguir são examinados três tipos de funções de avaliação utilizadas nestes algorítmos presentes na literatura.

Ganho de Informação (Information Gain).

Esta medida, utilizada nos algorítmos ID3 E C4,5, se baseia no conceito de entropia, comumente utilizada na área de Teoria da Informação.

Sejam C uma coleção de tuplas e c a cardinalidade de Dom(ac).

A entropia de C com relação aos c valores de ac é dada por onde pi é a fração da coleção C cujo atributo alvo é da classe i.

O ganho de informação, G(C,ai), de um determinado atributo candidato ai, com relação a uma coleção C, onde ci é o número de elementos de Dom (ai), e Cv é a subcoleção de C na qual o atributo candidato ai tem valor v.

Taxa de Ganho de Informação (Information Gain Ratio).

Redução do Índice Gini (Reduction of the Gini Index).

Esta medida, primeiramente proposta em, é utilizada nos algorítmos SPRINT e CART.

Esta medida se baseia na redução do Índice Gini, que é definido pela Para um conjunto de dados contendo tuplas de v classes diferentes, a medida de Redução do Índice Gini, GR, é definida pela seguinte expressão.

Para exemplificar como uma função de avaliação é utilizada para seleção de um atributo a partir de um conjunto de atributos candidatos, considere a medida G (C,ai), o ganho de informação.

Examinando-se os valores acima, pode-se concluir que o atributo Age é o selecionado para o nó raiz.

As tuplas de C são, então, particionadas pelos ramos partindo da raiz, correspondentes aos valores de Age encontrados em C.

Esta mesma função de avaliação é aplicada recursivamente aos nós nos quais estes ramos chegam, à exceção do nó terminal (folha) onde o ramo para para o valor overcast termina.

Em virtude de uma árvore de decisão ser expandida gradualmente, surge a questão de quando é o melhor momento no qual esta expansão deve ser interrompida.

Para resolver este problema, normalmente é utilizada a técnica de poda da árvore.

A poda de um nó da árvore de decisão consiste da remoção da sub-árvore com raiz neste nó, tornando-o um nó folha, e da atribuição do valor de classificação mais comum dentre as tuplas associadas àquele nó.

Esta técnica tem os objetivos de remover as ramificações da árvore associadas a dados espúrios, através da seleção da sub-árvore com a mínima taxa de erro estimada, e melhorar a compreensão das regras geradas a partir da árvore de decisão.

Há duas abordagens principais para se fazer a poda de árvore de decisão.

Nesta o particionamento da árvore de decisão pode chegar ao fim durante a fase de expansão.

Usualmente, o critério de parada é calculado para dar uma estimativa do ganho esperado em expansões adicionais da árvore e a expansão é terminada quando um limite mínimo de ganho não é esperado.

Esta abordagem é a mais utilizada.

Uma variante desta abordagem é utilizada pelo algorítmo C4,5.

Esta variante tem os seguintes passos principais.

Indução da árvore de decisão, conforme descrito anteriormente.

Conversão da árvore de decisão em um conjunto de regras de produção equivalente, através da criação de uma regra para cada caminho da árvore da raiz até um nó terminal (folha).

Poda (generalização) de cada regra através da remoção de predicados que resultem em um melhoramento da precisão estimada.

Ordenação das regras resultantes da generalização, levando-se em consideração sua precisão estimada.

Nesta abordagem, nós internos são removidos somente se a precisão de classificação das regras após a remoção não é pior quando comparada à precisão da árvore original, considerando-se o conjunto de validação separado do conjunto de treinamento.

Aprendizado Bayesiano Em um processo de aprendizado uma das maneiras de se representar uma hipótese é através de um classificador de Bayes.

Estes classificadores Bayesianos são estatísticos e sua principal função é utilizar uma série de curvas de distribuição de probabilidades para predizer as probabilidades de uma classe membro, bem como, a probabilidade em que uma dada amostra deve pertencer a uma classe particular.

A abordagem utilizada no Aprendizado Bayesiano Simples (ABS) para classificar uma nova tupla é associar a seu atributo alvo o valor mais provável.

Neste método, é feita uma análise dos relacionamentos existentes entre cada um dos atributos previsores e o atributo alvo, para gerar uma porbabilidade condicional para cada um desses relacionamentos.

Quando uma nova tupla deve ser classificada, a predição é feita através da combinação dos efeitos de cada atributo previsor sobre o atributo alvo.

O Aprendizado Bayesiano Simples é somente aplicável na teoria, se os atributos previsores são estatisticamente independentes.

Por exemplo, dados acerca de um cliente contêm atributos (tais como peso, escolaridade, salário, etc) que estão relacionados a sua idade.

Neste caso, a utilização do ABS superestimaria o feito do atributo idade.

Não obstante esta limitação, na prática é mostrado que o ABS é bastante utilizado em virtude de sua simplicidade e rapidez na investigação de padrões simples.

Durante a fase de construção do modelo, a probabilidade de cada valor v(ac) do atributo alvo é calculada através da contagem de quantas vezes este ocorre no conjunto de treinamento.

Esta probalidade é denominada probabilidade anterior (prior probability).

Deve-se calcular em adição às probabilidades anteriores, o quanto frequentemente cada valor de cada atributo previsor ocorre em combinação com cada um dos valores do atributo alvo.

Estas frequências são, então, utilizadas para o cálculo de probalidades condicionais que juntamente com as probabilidades anteriores, são utilizadas para se fazer a predição do valor da classe da nova tupla.

Nesta Equação, argmax é um operador que retorna o valor do atributo alvo associado ao valor máximo dentre todos os valores de P(vj|t) calculados para cada valor vj no domínio do atributo alvo ac O Teorema de Bayes pode ser utilizado para escrever a Equação de outra forma.

Os valores P(t|vj) e P(vj) correpondem, respectivamente à probabilidade da tupla t dados vj e à probabilidade anterior do valor vj, que podem ser estimadas a partir do conjunto de treinamento.

Para descrever estas estimativas, seja nt o número de tuplas na relação R que satisfazem à condição C, onde C corresponde a uma conjunção de predicados.

Com base na definição de nt, pode-se estimar o valor da probabilidade anterior nas quais o atributo P (vj) através da Equação.

Onde, nt (ac = vj) corresponde ao número de tuplas em R nas quais o atributo alvo ac tem o valor vj, e nt(true) corresponde ao número de tuplas em R.

Para a estimativa do valor P(t|vj), deve-se considerar cada atributo ai da tupla t e o tipo deste atributo, se numérico ou simbólico.

O valor P(t|vj) é calculado pelo produtório dos valores P(ai = v(ai)| ac = vj), onde cada um destes fatores é dado pela Equação.

Nesta equação, µvj e s 2vj são a média e a variância de v(ai) para o valor vj do atributo alvo ac, e g é a função densidade gaussiana com média µvj e variância s 2vj.

Considere, ainda, que a nova tupla a ser classificada é (<=30, medium, yes, fair,?).

O objetivo é predizer o valor do atributo alvo Buys_Computer para esta nova tupla.

Instanciando a Equação, o valor v* é definido a seguir.

Note que, na expressão final, os valores v(ai) são instanciados utilizando-se os valores dos atributos previsores da nova tupla.

Para calcular v*, calculam-se todos os fatores da expressão acima.

Para as probabilidades anteriores, tem-se que P(yes) = 14 e P(no) = 14.

De forma similar, calculam-se as probabilidades condicionais.

Por exemplo, para Credit_Rating = fair, P(fair| yes)= e P(fair no)=.

Calculando-se as demais probabilidades condicionais, obtêm-se os seguintes valores.

Através da aplicação do operador argmax aos dois valores acima, pode-se deduzir que o valor de v* para este exemplo e igual a no, visto que o valor máximo de P(t|vj)P(vj) na equação 2,8 ocorre quando o atributo alvo Buys_Computer assume este valor.

As redes neurais são capazes de resolver problemas não lineares pelo aprendizado das relações entre uma série de parâmetros de entrada e de saída.

O procedimento de treinamento está em ajustar as funções pesos internas para cada dado conhecido e reproduzido.

O treinamento da rede, deve então estar disponível a predizer as variáveis de saída para os dados que esta não tenham sido previamente vistos.

As redes neurais são usadas muito frequentemente na engenharia elétrica, reconhecimento de padrões e muitas outras aplicações.

A aplicação na indústria de óleo e gás é relativamente recente.

Uma das redes mais comumente usadas é a rede back propagation.

Esta consite de pelo menos três camadas.

Uma camada de entrada, uma camada de saída e uma ou mais camadas intermediárias.

Cada camada é composta de neurônios, no qual correspondem a junções de entradas recebidas a partir de neurônios de outras camadas.

A entrada para um neurônio individual consiste de sinais recebidos a partir de outros neurônios, usando uma função de transferência algébrica combinada fatores e fatores peso associados a cada conecção.

Existem muitas formas para conectar uma rede.

O número de camadas intermediárias, o número de neurônios em cada camada intermediária, o número de conecções entre as camadas e a função de transferência específica usada que podem variar.

Apresenta uma camada de entrada com três neurônios, uma única camada intermediária, contendo três neurônios e uma camada de saída com um único neurônio.

Neste caso, a rede é feed forward, onde cada camada recebe a entrada somente a partir da camada precedente e totalmente conectada, em cada neurônio recebe as entradas a partir de todos os neurônios da camada precedente.

Uma ilustração mais detalhada de como esta rede funciona é mostrada.

Quando um valor de entrada é apresentado a cada neurônio da camada de entrada, a rede multiplica cada entrada por peso correspondente a um neurônio na camada intermediária.

A função de transferência é aplicada para gerar os neurônios da camada intermediária.

Nesta dissertação a função de transferência utilizada na camada intermediária foi a função de transferência sigmóide, onde a entrada para um dado neurônio da camada intermediária é fornecido pela equação abaixo, onde, Ij é a entrada do j-ésimo neurônio da camada intermediária, xi é o valor do iésimo neurônio precedente ou da camada de entrada e wij é o peso associado com a conecção entre o i-ésimo neurônio de entrada e o j-ésimo neurônio intermediário.

Outras funções de transferência como, a função linear, log-sigmóide também podem ser usadas.

Um procedimento similar é então usado para mapear a camada intermediária dentro de uma camada de saída, neste caso consistindo de somente um neurônio.

O processo de determinação da magnitude dos pesos que resulta em uma saída precisa é chamada de treinamento.

Vários métodos encontrados na literatura podem fazer isto, entretanto o método da rede back propagation é o mais comumente usado.

O método é baseado na determinação do erro entre a predição das variáveis de saída e os valores conhecidos do conjunto de treinamento dos dados.

O parâmetro erro é comumente definido como root mean square dos erros para todos os pontos usados no treinamento.

Os fatores peso são ajustados pela determinação do efeito de mudança de cada peso sobre o erro na variável de saída prevista.

Este processo leva a determinação da derivada parcial do erro com respeito a cada um dos pesos.

Os pesos são ajustados na proporção em que a derivada parcial associada é calculada na direção da redução deste erro.

O algorítmo usado para propagar a correção do erro para dentro da rede é geralmente da forma, onde, E é o parãmetro erro e é o fator de proporcionalidade chamado de taxa de aprendizado.

O processo de ajuste dos pesos continua até o erro se tornar menor que algum limite desejado, após o qual a rede é considerada treinada.

Uma vez que a rede foi treinada, esta pode receber novos dados de entrada que não foram usados para o treinamento e aplicar os fatores pesos obtidos durante o treinamento.

O processo de construir uma rede, treinar esta e otimizar sua performance é realizado considerávelmente através de tentativas e erros.

Existem métodos para selecionar o número de camadas intermediárias e de neurônios.

A melhor função de transferência e o número de conecções são também formas de escolha para analisar a taxa de aprendizado da rede.

Entretanto, nesta dissertação foi usado uma rede muito simples, com uma função de transferência mais comum e uma única camada intermediária para facilitar o estudo.

Até a década passada existiam somente poucos exemplos de aplicações do processo de extração de conhecimento em banco de dados.

Com o decorrer dos anos, houve um esforço por parte dos pesquisadores da área de mineração de dados, em desenvolver novos sistemas de sucesso baseadas em novas competências e associados a novas aplicações.

Hoje, estes sistemas foram desenvolvidos em uso operacional e em diferentes domínios de interesse, com o objetivo de solucionar problemas mundiais reais em grande escala.

Aplicações de técnicas computacionais usadas com o objetivo de implementar as metodologias usadas na exloração de petróleo em geral, tem sido indicado como ferramentas tecnológicas importantes na indústria de petróleo e gás.

O levantamento geoquímico de superfície envolve amostras coletadas no solo e análises destas para indicadores de óleo e/ou gás em subsuperfície.

Na teoria, estas análises podem ser usadas para melhorar a eficiência exploratória de pobres prospectos, antes da inspeção sísmica e/ou poços terem sido perfurados.

Estas análises de geoquímica de superfície apesar de não serem completamente aceitas devido a grande dificuldade na análise dos dados, tem se transformado em uma importante ferramenta para definir as fronteiras de um reservatório de petróleo.

Análises estatísticas convencionais tem mostrado que existe de fato uma correlação entre dados de geoquímica de superfície e a locação de um lugar amostrado com respeito às fronteiras de um reservatório de petróleo.

Contudo, métodos de análise não podem ser usados diretamente como ferramentas preditivas.

O sucesso na aplicação da Mineração de Dados na forma apresentada nesta dissertação com àrvores de decisão, redes neurais e aprendizado bayesiano para determinar o lugar de uma amostra específica, dados as concentrações de hidrocarbonetos no solo e sob certas condições ambientais, devem apresentar-se dentro das linhas traçadas referentes às fronteiras do reservatório de petróleo.

Mostra a aplicação da mineração de dados utilizada nesta dissertação, através da geoquímica de superfície.

As setas em cinza, indicam o escape dos hidrocarbonetos pela acumulação ou trap até a superfície.

As linhas verdes são as fronteiras sul e norte do reservatório e as linhas pontilhadas vermelha e azul, correspondem aos levantamentos geoquímicos de superfície.

No estado líquido o petróleo é uma substância oleosa inflamável, menos densa que a água, com cheiro característico e cor variando entre o negro e o castanho-claro.

Este é constituído basicamente, por uma mistura de compostos químicos orgânicos (hidrocarbonetos).

Quando a mistura contém uma maior porcentagem de moléculas pequenas seu estado físico é gasoso e quando a mistura contém moléculas maiores seu estado físico é líquido, nas condições normais de temperatura e pressão.

O petróleo contém centenas de compostos químicos e separá-los em componentes puros ou misturas de composição conhecida é praticamente impossível.

Assim, este é normalmente separado em frações de acordo com a faixa de ebulição dos compostos.

Dentre estas frações típicas do petróleo podemos citar o gás residual, gás liquefeito do petróleo (GLP), gasolina, querosene, gasóleo leve e pesado, lubrificantes e resíduo.

Os óleos obtidos de diferentes reservatórios de petróleo possuem características diferentes.

Alguns são pretos, densos, viscosos, liberando pouco ou nenhum gás, enquanto que outros são castanhos ou bastante claros, com baixa viscosidade e densidade, liberando quantidade apreciável de gás.

Outros reservatórios podem ainda, produzir somente gás.

A alta porcentagem de carbono e hidrogênio existente no petróleo mostra que os seus principais constituintes são os hidrocarbonetos.

Os outros constituintes aparecem sob a forma de compostos orgânicos que contêm outros elementos, sendo os mais comuns o nitrogênio, o enxofre e o oxigênio.

Metais também podem ocorrer como sais de ácidos orgânicos.

Este capítulo faz uma abordagem resumida do termo petróleo, discute seus principais constituintes, composição, bem como, as principais características para a formação de acumulações em reservatórios de petróleo.

A seção 3,2 oferece uma breve noção da geologia do petróleo, abordando sua origem, migração e tipos de rochas existentes nos reservatórios.

A seção 3,3 discute os mecanismos de formação das trapas e seus principais tipos.

Finalmente, na seção 3,4 é abordada a questão da preservação do petróleo e a formação de exsudações na superfície.

Os principais grupos de componentes dos óleos são os hidrocarbonetos saturados, os hidrocarbonetos aromáticos, as resinas e os asfaltenos.

Os hidrocarbonetos saturados constituem o maior grupo, formado por alcanos normais (n-parafinas), isoalcanos (isoparafinas) e cicloalcanos (naftenos).

No petróleo são encontradas parafinas normais e ramificadas que vão do metano até 45 átomos de carbono.

As parafinas normais usualmente representam cerca de 15 a 20% do petróleo, mas podendo variar entre limites mais amplos de 3 a 35%.

Os hidrocarbonetos aromáticos compreendem, os naftenoaromáticos e os benzotiofenos e seus derivados (que contêm heterociclos com enxofre).

O gás natural é uma mistura de hidrocarbonetos cuja composição abrange desde o metano até o hexano.

Encontra-se na forma livre ou associado ao óleo em reservatórios naturais contendo pequenas quantidades de diluentes e contaminantes.

Hidrocarbonetos são compostos orgânicos formados por carbono e hidrogênio.

De acordo com sua estrutura, são classificados em saturados, insaturados e aromáticos.

Os hidrocarbonetos saturados também denominados de alcanos ou parafinas2, são aqueles cujos átomos de carbono são unidos somente por ligações simples e ao maior número possível de átomos de hidrogênio, constituindo cadeias lineares, ramificadas ou cíclicas, interligadas ou não.

Os hidrocarbonetos insaturados, também denominados de olefinas apresentam pelo menos uma dupla ou tripla ligação carbono-carbono, enquanto que os hidrocarbonetos aromáticos, também chamados de arenos apresentam pelo menos um anel de benzeno na sua estrutura.

Nesta seção, discutimos estes diferentes tipos de hidrocarbonetos e suas principais características.

Hidrocarbonetos parafínicos normais.

Estes hidrocarbonetos também chamados na literatura de alcanos, possuem fórmula geral C2nH2n+2.

Os nomes dos alcanos são formados por um prefixo (que especifica o número de carbonos) e do sufixo ano.

O mais simples deles é o metano, constituído por um átomo de carbono ligado a quatro átomos de hidrogênio.

Hidrocarbonetos parafínicos ramificados.

Os hidrocarbonetos parafínicos podem apresentar ramificações em um ou mais átomos de carbono e são também denominados de isoparafinas ou isoalcanos.

Possuem a mesma fórmula geral dos alcanos normais.

Hidrocarbonetos parafínicos cíclicos.

Em muitos hidrocarbonetos os átomos de carbono são dispostos na forma de anéis.

Podem apresentar radicais parafínicos normais ou ramificados ligados ao anel ou outro hidrocarboneto cíclico.

Na indústria do petróleo são conhecidos como naftênicos.

A nomenclatura utilizada é a mesma dos parafínicos, agora com o prefixo ciclo.

Hidrocarbonetos insaturados.

Os hidrocarbonetos insaturados dos quais os mais comuns são os alcenos, apresentam fórmula geral CnH2n.

Assim como para os alcanos, o prefixo especifica o número de carbonos e o sufixo é eno.

Dependendo do número de duplas ligações são conhecidos como diolefinas, triolefinas, etc.

Quando ocorre uma tripla ligação carbono-carbono, os hidrocarbonetos insaturados são denominados de alcinos e o sufixo é ino.

Estes hidrocarbonetos insaturados constituem um grupo extremamente reativo e embora sejam biologicamente metabolizados em grande quantidade, dificilmente são preservados na natureza.

Hidrocarbonetos aromáticos.

São constituídos por ligações duplas e simples que alternam em anéis com seis átomos de carbono.

O composto mais simples é o benzeno.

Ao contrário dos compostos insaturados, o benzeno tem considerável estabilidade e devido ao seu pronunciado odor, todos os compostos que contêm o anel benzeno são conhecidos como hidrocarbonetos aromáticos.

Tal como nos naftênicos, pode ocorrer a preesença de aromáticos formados por mais de um anel benzênico, que podem estar isolados, conjugados ou condensados.

Podem ocorrer ainda compostos mistos, isto é, que apresentam núcleo aromático e radical naftênico ou núcleo naftênico e radical aromático.

Com o objetivo de se conhecer melhor a constituição do petróleo, a American Petroleum Institute (API) realizou análises em vários petróleos de diferentes origens, chegando às seguintes conclusões.

Todos os petróleos contêm substancialmente os mesmos hidrocarbonetos em diferentes quantidades.

A quantidade relativa de cada grupo de hidrocarbonetos presente varia muito de petróleo para petróleo.

Como consequência, segundo estas quantidades, diferentes serão as características dos tipos de petróleo.

A quantidade relativa dos compostos individuais dentro de cada grupo de hidrocarbonetos, é aproximadamente da mesma ordem de grandeza para diferentes petróleos.

Como mencionado na Seção 3,1, o petróleo contém apreciável quantidade de constituintes que possuem elementos como enxofre, nitrogênio, oxigênio e metais.

Estes constituintes chamados na literatura de Não-Hidrocarbonetos são considerados como impurezas e podem aparecer em toda a faixa de ebulição do petróleo, mas tendem a se concentrar nas frações mais pesadas.

Nos próximos tópicos são apresentadas algumas das principais características destes não-hidrocarbonetos.

Compostos sulfurados.

O enxofre é o terceiro elemento mais abundante encontrado no petróleo e sua concentração média é de 0,65% em peso, com uma faixa apresentando valores entre 0,02 e 4,00%.

O enxofre ocorre no petróleo sob a forma de sulfetos, polissulfetos, benzotiofenos e derivados, moléculas policíclicas com nitrogênio e oxigênio, gás sulfídrico, dissulfeto de carbono, sulfeto de carbonila e enxofre elementar (muito raro).

Tais compostos estão presentes em todos os tipos de petróleo, e em geral quanto maior a densidade do petróleo, maior será seu teor de enxofre.

Os compostos sulfurados, além de indesejáveis, pois concorrem para aumentar a polaridade dos óleos, são os responsáveis pela corrosividade dos produtos de petróleo, contaminam os catalisadores uitlizados nos processos de transformação e determinam a cor e o cheiro dos produtos finais.

São tóxicos e produzem SO2 e SO3 por combustão, gases altamente poluentes da atmosfera, os quais formam H2SO3 e H2SO4 (ácido sulfúrico) em meio aquoso.

Os petróleos contêm em média 0,17% em peso de nitrogênio com maior concentração nas frações pesadas.

Os compostos nitrogenados apresentam-se quase que em sua totalidade na forma orgânica e são termicamente estáveis.

Aparecem nas formas de priridinas, quinolinas, pirróis, indóis, porfirinas, e compostos policíclicos com enxofre, oxigênio e metais.

Estes compostos nitrogenados aumentam a capacidade do óleo de reter a água em emulsão.

Durante o refino tornam instáveis os produtos finais, propiciando a formação de gomas e alterando a coloração, além de serem também responsáveis pela contaminação dos catalisadores.

Aparecem no petróleo de uma forma mais ou menos complexa, tais como ácidos carboxílicos, fenóis, cresóis, ésteres, amidas, cetonas e benzofuranos.

De um modo geral, eles tendem a se concentrar nas frações mais pesadas e são responsáveis pela acidez e coloração (ácidos naftênicos), odor (fenóis), formação de gomas e corrosividade das frações do petróleo.

Apresentam-se como sais orgânicos dissolvidos na água emulsionada ao petróleo, facilmente removidos através do processo de dessalgação e na forma de compostos organometálicos complexos, que tendem a se concentrar nas frações mais pesadas.

Os metais que podem ocorrer no petróleo são ferro, cobre, zinco, chumbo, molibdênio, cobalto, arsênico, mangânes, cromo, sódio, níquel e vanádio, sendo os dois últimos de maior incidência.

Estes compostos metálicos são também responsáveis pela contaminação dos catalisadores.

A presença de sódio em combustíveis para fornos reduz o ponto de fusão dos tijolos refratários.

E o vanádio nos gases de combustão pode atacar os tubos de exaustão.

Resinas e Asfaltenos.

São moléculas grandes com alta relação carbono/hidrogênio e presença de enxofre, oxigênio e nitrogênio (de 6,9 a 7,3%).

A estrutura básica é constituída de 3 a 10 ou mais anéis geralmente aromáticos em cada molécula.

As estruturas básicas das resinas e asfaltenos são semelhantes, mas existem diferenças importantes.

Asfaltenos não estão dissolvidos no petróleo e sim dispersos na forma coloidal.

As resinas ao contrário, são facilmente solúveis.

Asfaltenos puros são sólidos escuros e não-voláteis e as resinas puras, além de serem líquidos pesados ou sólidos pastosos, são tão voláteis como um hidrocarboneto do mesmo tamanho.

As resinas de alto peso molecular são avermelhadas, enquanto que as mais leves são menos coloridas.

Nesta Seção são abordados algumas noções mais importantes da geologia do petróleo.

Esta dividi-se em três subseções.

Na seção 3,2,1 é discutido a origem e geração do petróleo.

Na seção 3,2,2 é apresentado o prcesso de migração do petróleo.

Finalmente, na seção 3,2,3, são mostradas as principais características das rochas reservatórios e selantes.

São discutidos ainda, as principais características e os dois mais importantes tipos de reservatórios encontrados na literatura.

A origem do petróleo está relacionada à matéria orgânica acumulada e preservada nas bacias sedimentares brasileiras sob condições adequadas.

Esta matéria orgânica marinha é basicamente originada de microorganismos e algas que formam o fitoplâncton e não pode sofrer processos de oxidação.

A necessidade de condições nãooxidantes pressupõe um ambiente de deposição composto de sedimentos de baixa permeabilidade, inibidor da ação da água circulante em seu interior.

A interação dos fatores como, matéria orgânica, sedimento e condições termoquímicas apropriadas, é fundamental para o início da cadeia de processos que leva à formação do petróleo.

A matéria orgânica proveniente de vegetais superiores também pode dar origem ao petróleo, todavia sua preservação torna-se mais difícil em função do meio oxidante onde vivem.

O tipo de hidrocarboneto gerado, óleo ou gás, é determinado fundamentalmente pela constituição da matéria orgânica original e pela intensidade do processo térmico atuante sobre ela após sua deposição.

A matéria orgânica proveniente do fitoplâncton quando submetida a condições térmicas adequadas, tende a gerar hidrocarbonetos predominantemente líquidos.

O processo atuante sobre a matéria orgânica vegetal lenhosa poderá ter como consequência a geração de hidrocarbonetos gasosos.

Admitindo um ambiente apropriado após a incorporação da matéria orgânica ao sedimento, dá-se aumento de carga sedimentar e de temperatura começando então, a se delinear o processo que passa pelos seguintes estágios evolutivos.

Na faixa de temperaturas mais baixas, até 65oC, predomina a atividade bacteriana que provoca a reorganização celular e transforma a matéria orgânica em querogênio.

O produto gerado é o metano bioquímico ou biogênico.

Este processo é denominado de Diagênese.

O incremento da temperatura até 165oC é determinante da quebra das moléculas de querogênio e resulta na geração de hidrocarbonetos líquidos e gasosos, processo este denominado de Catagênese.

A continuação do processo avançando até 210oC, propicia a quebra das moléculas de hidrocarbonetos líquidos e sua transformação em gás leve, processo denominado de Metagênese.

Ultrapassando esta fase e continuando com o incremento de temperatura, leva à degradação do hidrocarboneto gerado deixando como remanescente grafite, gás carbônico e algum resíduo de gás metano, chamado de Metamorfismo.

Assim, o processo de geração de petróleo como um todo é resultado da captação da energia solar através da fotossíntese e transformação da matéria orgânica com a contribuição do fluxo de calor oriundo do interior da terra.

Para se ter uma acumulação de petróleo é necessário que após o processo de geração, ocorra a migração e que esta tenha seu caminho interrompido pela existência de alguma armadilha ou trapa (trap) geológico.

A migração tem sido um dos mais questionados fatores controladores da ocorrência do petróleo, além do menos conclusivo e o que mais suscita polêmica entre os geólogos do petróleo.

O fato é que o petróleo é gerado em uma rocha fonte denominada de rocha geradora e que se desloca para outra, onde se acumula denominada de rocha reservatório.

As formas de migração tem tido várias explicações e muitos modelos bem fundamentados tem sido propostos para explicar as acumulações existentes no país.

Uma explicação clássica para o processo atribui papel relevante à fase de expulsão da água das rochas geradoras que levaria consigo o petróleo durante os processos de compactação.

Outra explicação estaria no microfaturamento das rochas geradoras.

Assim, isto facilitaria o entendimento do fluxo através de um meio da baixíssima permeabilidade como as rochas argilosas ou folhelhos.

A expulsão do petróleo da rocha geradora, de onde foi gerado, dá-se o nome de migração primária.

E ao seu percurso ao longo de uma rocha porosa e permeável até ser interceptado e posteriormente ser contido por uma armadilha geológica dá-se o nome de migração secundária.

Esquematiza estes caminhos de migração do óleo, mostrando quando ocorre os dois tipos de migração.

A não contenção do petróleo em sua migração permitiria seu percurso continuado em busca de zonas de menor pressão até se perder através de exsudações, oxidação e degradação bacteriana na superfície que será discutido com mais detalhes na seção 3,4.

Folhelhos são definidos como uma rocha geradora porosa, impermeável composta de uma mistura de lama e matéria orgânica.

Após ter sido gerado e migrado, o petróleo é eventualmente acumulado em um espaço que permite o armazenamento dos hidrocarbonetos na rocha, esta denominada de rocha reservatório.

Esta rocha pode apresentar qualquer origem ou natureza, entretanto para se constituir em um reservatório deve apresentar espaços vazios no seu interior, denominado de porosidade.

Estes vazios devem estar interconectados para conferir a esta rocha reservatório uma capacidade de transmitir e trocar fluidos ao longo do reservatório e também pelo conduto de migração, que conecta este reservatório com um pod da rocha reservatório, característica esta chamada de permeabilidade.

De uma maneira geral, uma rocha reservatório é constituída de grãos minerais com poros existentes entre estes grãos, onde é encontrado o petróleo.

Estes grãos que estão conectados uns aos outros por um material recebe o nome de cimento, enquanto que o material muito fino existente entre os grãos é chamado de matriz.

Assim, uma rocha reservatório deve ser porosa e permeável, apresentado poros, que devem ser preenchidos por gás, óleo e água, similarmente ao que ocorre na natureza.

Desse modo, podem se constituir rochas reservatório os arenitos e calcarenitos e todas as rochas sedimentares essencialmente dotadas de porosidade intergranular que sejam permeáveis.

Algumas rochas como folhelhos e alguns carbonatos, normalmente porosos porém impermeáveis, podem vir a se constituir reservatórios quando se apresentam naturalmente fraturados.

Uma vez atendidas as condições de geração, migração e reservatório e para que se dê a acumulação do petróleo, existe a necessidade de que alguma barreira se interponha no seu caminho de migração até a superfície.

Esta barreira é produzida pela rocha selante, cuja característica principal é a sua baixa permeabilidade.

Além da permeabilidade, a rocha selante deve ser dotada de plasticidade, característica que a capacita a manter sua condição selante mesmo após submetida a esforços determinantes de deformações.

Duas classes de rochas são selantes por excelência.

Os folhelhos e os evaporitos (sal).

Outros tipos de rochas também podem funcionar como tal.

A eficiência selante de uma rocha não depende só de sua espessura, mas também de sua extensão.

Exemplifica a disposição espacial entre as rochas reservatório e as rochas selantes que propicia a acumulação do petróleo.

Na análise de um reservatório de petróleo é fundamental o conhecimento de propriedades básicas da rocha e dos fluidos nela contidos.

Estas propriedades determinam a medida do espaço entre os grãos, as quantidades destes fluidos existentes no meio poroso, sua distribuição, capacidade de se moverem e a mais importante de todas, a quantidade de fluidos que pode ser extraída.

Como citado anteriormente na Seção 3, uma rocha reservatório é composta de grãos, matriz e cimento.

A medida do espaço existente entre estes grãos pode ser definida como porosidade.

Assim, podemos dizer que o volume total ocupado por uma rocha reservatório é a soma do volume dos materiais sólidos (grãos, matriz e cimento) e do volume poroso.

Em última análise, a porosidade depende da forma da arrumação e da variação de tamanho dos grãos, além do grau de cimentação da rocha.

Normalmente existe comunicação entre os poros de uma rocha.

Porém, devido a cimentação, alguns poros podem ficar totalmente isolados.

Chama-se porosidade absoluta a razão entre o volume de todos os poros, interconectados ou não, e o volume total da rocha.

A razão entre o volume dos poros interconectados e o volume total da rocha é denominado de porosidade efetiva.

Como os poros isolados não estão acessíveis para a produção de fluidos, o parâmetro realmente importante para a engenharia de reservatórios é a porosidade efetiva, pois representa o volume máximo de fluidos que pode ser extraído da rocha.

A porosidade primária ocorre quando da conversão do material sedimentar em rocha.

Entretanto, após a sua formação a rocha é submetida a esforços mecânicos, podendo resultar daí o aparecimento de fraturas, ou seja, o aparecimento de mais espaços vazios.

Esta nova porosidade é chamada de porosidade secundária.

Em rochas calcárias é frequente a ocorrência de dissolução de parte dos sólidos devido ao ataque da água de formação, resultando também em porosidade secundária.

A porosidade é medida a partir de perfis elétricos executados nos poços ou de ensaios de laboratório em amostras da rocha.

Nas bacias sedimentares brasileiras produtoras de petróleo, os reservatórios são dominantemente convencionais, arenitos e calcarenitos.

Porém, existem exemplos de acumulações de hidrocarbonetos em rochas, tanto sedimentares quanto ígneas e metamórficas não convencionais, como os folhelhos fraturados na Bacia do Recôncavo, BA, os basaltos da Bacia de Campos, RJ, e as rochas metamórficas fraturadas da Bacia Sergipe-Alagoas.

Um corpo que inicialmente tem um volume V ao ser submetido a uma compressão P, sofrerá uma redução de volume.

O quociente entre a redução de volume.

Dividindo-se a variação fracional pelo.

Assim, a compressibilidade é definida pelo quociente entre a variação fracional de volume e a variação de pressão.

Os poros de uma rocha reservatório apresentam-se cheios de fluidos que exercem pressão sobre as paredes dos mesmos, da mesma forma que o ar exerce uma pressão de dentro para fora em um balão de soprar.

Assim, como o tamanho do balão depende da pressão interna, isto é, da quantidade de ar contida no seu interior, o volume dos poros é uma função da sua pressão interna.

Ao ser retirada uma certa quantidade de fluido do inetrior da rocha, a pressão cai e os poros tem seus volumes reduzidos.

A relação entre esta variação fracional dos volumes dos poros e a variação de pressão, dá-se o nome de compressibilidade efetiva da formação, muito aplicada pelos engenheiros de reservatório.

A compressibilidade efetiva da formação pode desempenhar um papel muito importante durante certa etapa da vida produtiva de um reservatório de petróleo.

Os poros de uma rocha reservatório, além de hidrocarbonetos, contêm água.

Assim sendo, o conhecimento do volume poroso não é suficiente para se estabelecer as quantidades de óleo e/ou gás contidas nas formações.

Para que estas quantidades sejam estimadas, é necessário se estabelecer que percentual do volume poroso é ocupado por cada fluido.

Esses percentuais recebem o nome de saturação.

A saturação de óleo, água e gás corresponde ao percentual do volume poroso Vp ocupado por cada uma destas fases, ou seja.

Saturação do Óleo.

Saturação de Gás.

Saturação de Água.

Mesmo que uma rocha contenha uma quantidade apreciável de poros e dentro desses poros existam hidrocarbonetos em uma quantidade razoável, não há a garantia de que eles possam ser extraídos.

Para que isso ocorra, é necessário que a rocha permita o fluxo de fluidos através dela.

Assim, a permeabilidade pode ser definida como a capacidade de uma rocha permitir o fluxo de fluidos.

Estes fluidos percorrem o que se pode chamar de canais porosos, ou gargantas4.

Quanto mais cheios de estrangulamento, mais estreitos e mais tortuosos forem essas gargantas, maior será o grau de dificuldade para os fluidos se moverem no seu interior, o que corresponde a uma permeabilidade baixa.

Por outro lado, poros maiores e mais conectados oferecem menor resistência ao fluxo de fluidos e a uma maior permeabilidade.

A permeabilidade tem por símbolo a letra K e sua unidade de medida mais utilizada é o darcy, em homenagem ao engenheiro francês Henry D'Arcy, que formulou a equação de deslocamento de fluidos em meios porosos.

Do mesmo modo, a permeabilidade pode ser definida.

Quando existe apenas um fluido saturando a rocha, esta propriedade recebe o nome de permeabilidade absoluta.

Quando uma rocha reservatório contêm sempre dois ou mais fluidos, de modo que a permeabilidade absoluta não é suficiente para se medir a facilidade com que determinado fluido se move no meio poroso, a facilidade com que cada um se move é chamada de permeabilidade efetiva.

E finalmente, quando os valores de permeabilidade são submetidos a um processo de normalização, ou seja, estes valores de permeabilidade forem divididos por um mesmo valor de permeabilidade escolhido como base, tem o que chamamos de permeabilidade relativa.

A mobilidade pode ser definida como sendo a relação entre a sua permeabilidade efetiva e a sua viscosidade.

Por exemplo, a mobilidade do óleo (fluido deslocado) é dada por o = ko /µo e da água (fluido injetado) por w = kw /µw.

Assim, como as permeabilidades efetivas, as mobilidades também dependem das saturações.

Quanto maior for a razão de mobilidades menor será a eficiência de deslocamento de óleo, uma vez que devido à sua maior mobilidade o fluido injetado tenderá a furar o banco de óleo criando caminhos preferenciais entre os poços injetores e os produtores.

Quando uma gota de petróleo se move através dos poros de uma rocha, um trabalho será realizado pela gota para distorcer e forçar a passagem desta gota através das gargantas existentes entre os poros.

A força requerida para que isto ocorra é chamada de pressão capilar ou pressão de injeção.

Esta pressão capilar é função do tamanho (raio) da garganta do poro, da tensão interfacial entre a água e o petróleo e da molhabilidade do sistema petróleo-água-rocha.

É a tensão interfacial entre o petróleo e a água (dyne cm-1).

T é a molhabilidade (graus), expressa como o ângulo de contato da interface petróleo-água contra a superfície da rocha e R o raio do poro (cm).

A tensão interfacial depende das propriedades do petróleo e da água e é independente das características da rocha.

Esta é uma função primariamente da composição do petróleo e da temperatura, geralmente diminui com o aumento da temperatura.

Para uma dada composição do petróleo a tensão interfacial deve ser considerada efetivamente constante em grandes partes do caminho de migração, a menos que ocorra considerável migração vertical.

As tensões interfaciais entre o gás-água são geralmente mais altas que para o óleo-água.

Isto significa que para uma mesma rocha, pressões capilares são mais altas para gás que para óleo.

As pressões flutuantes (buoyance) contudo, são normalmente mais altas para gás.

Os tamanhos dos poros são de maior importância para o controle do trapeamento e da migração secundária.

A pressão capilar pode ser medida diretamente em laboratório através de técnicas de injeção para ambas rochas reservatório e selantes.

O princípio desta técnica baseia-se na injeção em um plug do fluido de mercúrio (não molhado), onde a saturação deste mercúrio como porcentagem do volume do poro (volume cumulativo de mercúrio injetado) é medido como uma função do aumento da pressão capilar do plug.

A pressão no qual o primeiro mercúrio inicia a saturação dos poros da rocha é a pressão capilar.

É ilustrado as condições requeridas para o transporte de uma gota de óleo através das gargantas de um poro da rocha.

Nesta subseção são discutidos alguns dos principais tipos de reservatórios encontrados na literatura.

Na subseção 3,1, é apresentado as características mais importantes dos reservatórios carbonáticos com seus principais eventos diagenéticos.

E na subseção 3,2 são mostrados os principais fatores que controlam a permeabilidade e a porosidade de um reservatório arenítico.

Nos reservatórios carbonáticos, a geração e deposição da maior parte dos carbonatos é controlada pela atividade biológica.

Cerca de 90% dos carbonatos são de origem biológica.

Dentre os pré-requisitos mais importantes para a formação destes carbonatos podemos citar, a temperatura, a luz, a salinidade e a disponibilidade de nutrientes.

Estes nutrientes vão controlar a locação geográfica e o ambiente deposicional deles e como resultado estarão limitados mais à superfícies rasas.

Os sedimentos carbonáticos são compostos de pequenas variedades de minerais altamente susceptíveis a alterações químicas, mais que por retrabalhamento físico dos sedimentos.

Processos de recristalização e dissolução podem contribuir para uma profunda modificação na qualidade do reservatório.

Contudo, a combinação dos efeitos diagenéticos e da atividade biológica dos carbonatos terão grande atuação sobre a heterogeneidade da porosidade e da permeabilidade, gerando incerteza na predição da qualidade do reservatório.

Dentre os eventos da diagênese5 mais importantes que atuam para alterar a porosidade e a permeabilidade.

Cimentação.

Corresponde a um processo químico diagenético que consiste na precipitação de um cimento no espaço poroso e geralmente é usado a catodoluminescência para identificar e correlacionar o cimento.

Atua reduzindo a porosidade e a permeabilidade.

A diagênese caracteriza todos os processos que ocorrem após a deposição dos sedimentos e transforma os sedimentos em rocha.

Podendo ocorrer por processos químicos, físicos ou mecânicos.

Dissolução.

Processo químico em que a água pode apresentar composições variadas e vir carregada de ácidos.

Atua dissolvendo os constituintes da rocha, gerando um constituinte poroso.

Fraturamento.

Ocorre por falhamento, atuando grandemente sobre a permeabilidade.

Recristalização.

Processo que ocorre por metamorfismo da micrita dentro de extensos cristais com aumento da porosidade.

Dolomitização.

Processo diagenético que ocorre por substituição ou cimentação do carbonato pelo magnésio criando extensos poros.

A dolomita sofre recristalização associado ao aumento no tamanho do cristal e formação de mosaicos, como também, o rearranjo do espaço poroso está associado ao aumento da permeabilidade.

Os tipos de poros também apresentam grande importância quando combinados com o controle diagenético e deposicional para predizer a qualidade do reservatório.

Assim podemos descrever os principais tipos de poros.

Apresentam poros maiores que os grãos Intergranulares.

Entre grãos Intragranulares ou celular.

Apresentam-se no interior dos grãos Chalky.

Reservatórios Areníticos Diferentemente dos reservatórios carbonáticos citados anteriormente, como susceptíveis à alterações qúimicas, a mineralogia das areias consiste de grãos que são quimicamente estáveis no ambiente deposicional próximo á superfície.

Assim, a areia é derivada principalmente da erosão de uma área fonte, sendo transportada para o lugar de deposição por processos físicos.

Nestes reservatórios areníticos, os parâmetros físicos mais importantes são o tamanho de grão, seleção (sorting), arredondamento e devem ser usados para entender e predizer os processos e ambientes deposicionais no qual as areias estão depositadas.

Estes parâmetros apresentam grande influência sobre a permeabilidade e a porosidade, conforme detalhados a seguir.

Corresponde a uma medida do grão de areia segundo seu eixo maior.

Um menor tamanho no grão aumenta a porosidade e diminui a permeabilidade.

Este fator de textura mede o grau de homogeneidade em tamanho de grão.

Mede o quanto a superfície é mais homogênea.

Podem ser chamados de arredondados quando se aproximam da forma de círculo.

Ou angulosos, quando apresentam forma mais irregular, com arestas ou cristas.

Definidos como ocorrências que determinam a arquitetura básica e geometria de um reservatório siliclástico.

No cenário marinho são depositados em sistemas fluviais, eólicos e lacustres.

No cenário não marinho estes reservatórios são deltáicos, marinhos rasos e marinho fundo.

Podem ser ovalados, quando apresentam forma de um ovo ou esféricos, quando os grãos apresentam forma de esfera.

É exemplificado nestes dois últimos fatores de textura, o arredondamento e a esfericidade de forma que o resultado da granulometria pode atuar na porosidade e permeabilidade, oferecendo uma maior confiabilidade no peneiramento.

Um dos requisitos para a formação de uma jazida de petróleo é a existência de armadilhas ou trapas (traps), que podem ter diferentes origens, características e dimensões.

Na literatura surgem muitas definições para o termo trapa.

Um trapa e definido como um arranjo geométrico das rochas reservatório e selante que permite significantes acumulações de óleo e/ou gás em subsuperfície.

Já um trapa representa uma locação de um obstáculo em subsuperfície para a migração de petróleo através da superfície da terra, no qual gera uma concentração local de hidrocarbonetos.

As armadilhas ou trapas são constituídas em sua totalidade por dois elementos básicos descritos anteriormente na seção 3, as rochas reservatório e as rochas selantes.

Admitindo-se diferentes bacias sedimentares de dimensões equivalentes, contendo rochas geradoras com potenciais de geração de hidrocarbonetos também equivalentes, teores de matéria orgânica e condições termoquímicas, os volumes de petróleo a serem encontrados poderão ser os mais distintos.

Desde volumes gigantescos em umas até significantes em outras, dependendo de seu grau de estruturação, da existência e inter-relação das armadilhas e dos contatos que estas armadilhas propiciem entre rochas reservatórios e geradoras.

Em última instância, de nada vale uma bacia sedimentar dotada de rochas potencialmente geradoras e reservatórios se não estiverem presentes as armadilhas contentoras da migração.

A identificação de um trapa é o primeiro passo na avaliação de um prospecto e uma importante etapa em qualquer programa de exploração.

Desta forma, o sucesso futuro na exploração de óleo e gás, irá depender crescentemente de uma melhoria no entendimento de como os trapas são formados, de seus tempos de formação e das diversas variedades de tipos de trapas.

As trapas são classificadas como estruturais, estratigráficos, hidrodinãmicos e combinados.

Esta seção está dividida em outras duas subseções.

Na seção 3,3,1, desatem-se aos mecanismos de trapeamento dos hidrocarbonetos.

Na seção 3,3 apresentou-se as mais importantes classificações das trapas e suas principais características.

Um trapa existe sob condições de subsuperfície que geram a concentração e acumulação de petróleo.

Depois do petróleo ser gerado e expelido pelas rochas geradoras, este irá mover-se de lugares de alto potencial de energia para lugares de baixo potencial de energia.

Este processo lidera uma perda de petróleo na subsuperfície da terra.

As trapas em subsuperfície devem apresentar mínima energia potencial local.

Nestes lugares, a rota de migração do petróleo será obstruída.

Os mesmos princípios físicos básicos aplicados a migração secundária e selos são usados para o trapeamento.

Assim, um trapa é formado onde a pressão capilar alcançada de um selo excede a pressão flutuante (buoyance) dirigida para cima do petróleo nas rochas porosas e permeáveis.

Ambos o óleo e o gás devem ocorrer em um trapa, onde o gás repousa acima do óleo devido a ser menos denso que o óleo.

Se um trapa é preenchido primeiro com óleo e então com o gás (por exemplo como um resultado do aumento da maturidade da rocha geradora), a expansão da capa do gás deve substituir o óleo passado o spill-point (estrutura em que já foi completamente preenchida com óleo) da trapa.

O óleo pode então migrar mergulho acima para o próximo trapa disponível.

Note que, a trapa ilustrada não está completamente transbordado de óleo.

Uma capa de gás está acima do perna de óleo (oil-leg), mas a estrutura do ponto de derramamento está a alguma distância abaixo do contato óleo-água.

As trapas são geralmente classificados como trapas estruturais, estratigráficos, hidrodinâmicos ou combinados.

As trapas estruturais são criadas por deformações estruturais.

As trapas estruturais são definidas por serem criados pela deformação pós-deposicional das camadas geológicas, de forma a gerar uma geometria (estrutura) que permite a acumulação de hidrocarbonetos em subsuperfície.

Um trapa estratigráfico é principalmente causado por variações laterais de faceis sedimentares.

Estas variações devem ser essencialmente herdadas a partir de características deposicionais originais da bacia ou pode resultar de mudanças subsequentes diagenéticas.

A detecção destes tipos de trapas é dependente do bom entendimento da evolução da bacia e de sua estratigrafia.

Estes trapas são causados pelo fluxo de água através de um reservatório/carrier bed ou formados pelo movimento intersticial dos fluidos através da bacia.

Existem relativamente poucas bacias no mundo onde as trapas hidrodinâmicos são conhecidos e tenham um significante impacto sobre o entrapeamento causado pelo petróleo.

Uma vez conhecido as condições necessárias para estabelecer a escala de uma bacia, os prospectos individuais podem ser avaliados com uma visão de efeitos hidrodinâmicos.

Sob condições de forte fluxo hidrodinâmico os contatos petróleo-água devem ser mais inclinados que horizontais.

Claramente, um entendimento da evolução estrutural e estratigráfica da bacia é requerida para uma avaliação do impacto.

Estes trapas exibem tanto elementos estruturais quanto estratigráficos.

O uso do termo trapa combinado, está restrito aos aspectos no qual nem os elementos estruturais nem os estratigráficos podem sozinhos formar uma trapa, mas estes só podem ser formados essencialmente pelos dois.

O petróleo é um fluido frágil, uma mistura de óleo e gás que é difícil de se preservar.

Ele é facilmente degradável por destruição ou perda para a atmosfera de quantidades desconhecidas.

A partir do momento em que o óleo se separa do betume 7 na rocha geradora, este sofre mudanças composicionais que continuam através da migração e acumulação.

Exceto por mudanças na mistura de óleo e gás que ocorrem em resposta à variações na pressão e temperatura durante a migração do petróleo, a maior parte da degradação e dos processos destrutivos ocorrem dentro de um trapa.

Uma composição química original do petróleo em uma acumulação pode ser alterada ou degradada por processos químicos ou biológicos existentes na natureza.

Estes processos incluem aumento ou diminuição da temperatura, que ocorre por mudanças de profundidade, por fluxo da água meteórica e atividade bacteriológica.

A destruição completa de uma acumulação é usualmente causada pela erosão.

O petróleo é uma mistura complexa de fluidos líquidos e gasosos, cujas proporções devem depender de condições de pressão, volume e temperatura na trapa.

Estes fluidos são usualmente descritos por algumas propriedades, tais como gravidade API, porcentagem de enxofre, GOR (razão gás-óleo) e viscosidade.

Embora estas propriedades estejam limitadas a valores representativos em reservatórios mais rasos, estes providenciam uma forma de orientação para os reservatórios mais profundos.

O grau API de uma série de óleos, tende a aumentar com a profundidade.

Contudo, a composição do petróleo depende do fenômeno complexo que estes parâmetros (físicos ou químicos) geralmente são incapazes de descrever, quando este passa por vários estágios de degradação.

Geralmente, o óleo e o betume presentes na rocha reservatório apresentam muitas similaridades em sua composição.

Ambos, são compostos por hidrocarbonetos e compostos polares, divididos entre asfaltenos e resinas.

A principal diferença entre o óleo acumulado e o betume são criadas durante a migração primária (expulsão) e a migração secundária.

Os compostos polares são depletados no óleo acumulado tendo em vista que estes componentes são facilmente sorvidos dentro de uma matriz da rocha geradora e do querogênio.

A composição molecular do óleo é muito menos afetada durante a migração do que os parâmetros físicos e químicos.

Estudos prévios, mostram que diferentes moléculas podem exibir diferenças nos tempos de retenção, durante a migração no sistema petrolífero.

Definido como a fração da matéria orgânica contida nas rochas sedimentares que é solúvel em solventes orgânicos.

Dependendo das aproximações analíticas, a preservação ou degradação do petróleo pode ser demonstrada usando diferentes parâmetros, ora físicos, químicos ou moleculares.

Alguns destes parâmetros são modificados durante a degradação do petróleo.

Os principais fatores que influenciam a composição do óleo antes, durante e depois do trapeamento na rocha reservatório são mostrados a seguir.

Representação esquemática dos principais fatores e processos que influenciam a composição do óleo.

As setas inclinadas para cima indicam um aumento, enquanto as setas inclinadas para baixo, indicam uma diminuição.

Os fatores primários que influenciam a composição do óleo antes do trapeamento ou seja, antes do óleo entrar no trapa, são as características da rocha geradora e as condições de migração primária e secundária.

A composição do óleo é influenciada em algumas extensões pela natureza do material da fonte (orgânica) e por condições paleoambientais no qual este foi depositado.

Ambos os fatores, geram diferentes tipos de querogênio que se comportam diferentemente durante a catagênese.

Vários outros agentes geológicos, físicos ou químicos, atuam para afetar significantemente a composição do óleo durante a migração primária e secundária.

Os principais fatores que influenciam a composição do óleo na rocha reservatório são a pressão e a temperatura.

Estes fatores aumentam ou diminuem com o aumento ou diminuição da profundidade e afetam o GOR na hora da acumulação.

Por outro lado, as condições de pressão, volume e temperatura no reservatório estabelecem as condições no qual dão lugar a processos de alteração secundária.

As alterações secundárias influenciam a composição do óleo após este ser acumulado no trapa e estão relacionados a cinco diferentes processos.

Estes processos são a maturação termal, a degradação física e biológica, a segregação gravitacional, a remigração e a remoção de asfaltos.

Esta seção se subdivide em duas outras.

Na seção 3,4,1, é discutido o fenômeno de remigração como importante processo que influencia a composição do óleo.

E na seção 3,4,2, é discutida a formação de exsudações com suas carcaterísticas mais importantes para a análise da prospecção.

Algumas mudanças composicionais dentro de uma acumulação de óleo podem estar relacionadas com a eficiência da rocha selante.

Esta rocha selante acima de uma acumulação que providencia um selo perfeito, vai prevenir uma mudança composicional durante o vazamento do óleo trapeado.

Contudo, a maior parte dos hidrocarbonetos na trapa pode estar sujeito a algum tipo de vazamento.

Este vazamento está associado as condições geológicas em que as trapas são formadas.

Algumas vezes, estas condições estão relacionadas a eventos tectônicos que causam movimentos ao longo de uma falha nas trapas.

Neste caso, o fenômeno de remigração deve ocorrer, sendo caracterizado por significantes perdas de hidrocarbonetos mais leves.

Este fenômeno ocorre por dois processos.

A separação ea migração.

Na separação, a pressão de alívio adequada ao falhamento converte a única fase do sistema fluido a um sistema de duas fases, onde uma capa de gás se forma acima do óleo.

Na migração, este gás é perdido através do vazamento com o óleo leve e migra para as trapas mais rasas, onde sob temperatura e pressão adequadas, podem induzir uma condensação.

Com isto, uma nova acumulação contendo um fluido com alto grau API pode ser formada.

Este fato está em contraste com o óleo de baixo grau API que deixou a acumulação original.

E, baseado na composição molecular, este óleo terá um nível de maturidade térmica que será similar ao óleo de alto grau API.

Podemos dizer que estas migrações para cima de fluidos acumulados em trapas mais rasas podem resultar em acumulações de um óleo de alta qualidade.

Os hidrocarbonetos que são gerados ou trapeados a uma profundidade e vazam, são geralmente detectáveis próximo a superfície ou na superfície, por técnicas de exploração de geoquímica de superfície.

Este fato apresenta uma associação das anomalias de geoquímica de superfície com as falhas, que podem estar relacionadas a uma acumulação de petróleo.

A presença destas anomalias em superfície, ocorre grandemente em áreas que apresentam uma geologia simples e representam o final do caminho de uma migração do óleo que pode percorrer a uma pequena distância de migração vertical ou a uma longa distância de migração lateral.

Diferentes tipos de exsudações ocorrem em bacias que geram hidrocarbonetos ativamente e/ou contém excelentes caminhos de migração.

Exsudações ativas são facilmente detectáveis pela maioria dos métodos de amostragem geoquímica.

As áreas onde os hidrocarbonetos em subsuperfície não formam exsudações ativas são caracterizadas por exsudações passivas.

Estas ocorrem em bacias onde a geração de hidrocarbonetos é restrita ou a migração é esporádica ou inibida por uma barreira de migração.

Assim, as macroexsudações referem-se ao óleo visível e as emanações de gás.

Enquanto, as microexsudações são definidas como concentrações relativamente elevadas de hidrocarbonetos voláteis ou semi-voláteis detectáveis por análises geoquímicas ou efeitos induzidos em solos e sedimentos.

As taxas de microexsudações e as concentrações de hidrocarbonetos em superfície podem variar significativamente com o tempo.

Estas exsudações de hidrocarbonetos em superfície e as anomalias de geoquímica no solo, aparecem e desaparecem em curtos espaços de tempo, em semanas, meses e anos.

Observações empíricas e simulações computacionais sugerem que o mecanismo de microexudações é flutuante e o fluxo de gás de fase contínua passa através dos poros da água molhada e das fraturas.

Os métodos de exploração de superfície assumem que os hidrocarbonetos migram em uma direção preferencialmente vertical a partir das rochas geradoras e reservatórios até a superfície.

A evidência de um vazamento vertical de hidrocarbonetos pode ser vista em sísmica convencional e seções de alta resolução.

O uso da geoquímica de superfície na exploração de petróleo tem sido amplamente baseado na detecção direta de hidrocarbonetos leves correspondente à observações visíveis de exsudações de óleo e gás, denominadas de macroexsudações (macroseepage) ou por medidas da reação de produtos de hidrocarbonetos próximos a superfície resultando em microexsudações (microseepage).

Assim, as pequenas quantidades detectadas por análises diretas de hidrocarbonetos leves, ocorrem nos espaços do poro no solo e são adsorvidas nas porções dos finos grãos do solo ou são incorporadas na semente deste.

As medidas de reação dos produtos próximos à superfície usa métodos indiretos é baseada em expressões de moderada a longas faixas de microexsudações.

Estes métodos indiretos ocorrem por mudanças induzidas das microexsudações para solo, sedimento e vegetação.

Os métodos de geoquímica de superfície tem sido usado desde 1930, mas nas últimas décadas tem existido um interesse renovado na geoqúimica de exploração.

Esta renovação aliada ao desenvolvimento de métodos analíticos e de interpretação, tem produzido um novo corpo de dados e insight sobre a geoquímica de exploração.

Levantamentos geoquímicos e estudos de pesquisa documentam que microexsudações de hidrocarbonetos originados a partir de acumulações de óleo e gás, seguem alguns princípios básicos, como são comuns e muito espalhados,movem-se verticalmente e as acumulações são dinâmicas e os selos imperfeitos.

Indicações em superfície de exsudações de óleo e gás tem sido observadas por milhares de anos e tem liderado a descoberta de importantes áreas que produzem petróleo.

Embora a descoberta de uma anomalia de geoquímica de superfície não garanta a descoberta comercialmente significante de petróleo, esta anomalia estabelece a presença de hidrocarbonetos na área de interesse.

As exsudações de hidrocarbonetos em superfície representam o final do caminho de migração.

Estas anomalias podem representar concentrações de hidrocarbonetos presentes nos sedimentos e águas.

Anomalias microbiológicas e botânicas.

Mudanças mineralógicas e alterações elétricas, magnéticas e propriedades sísmicas próxima a superfície, bem como, sedimentos deposicionais.

Este capítulo aborda as principais questões da Geoquímica de Superfície.

Na seção 4,2 são discutidos os objetivos mais importantes em um levantamento geoquímico de superfície.

Na seção 4,3 são mostradas as etapas da prospecção em bacias onshore, os principais métodos de amostragem e análise geoquímica identificados na literatura, bem como, métodos usados nesta dissertação para interpretação dos dados geoquímicos de superfície.

Finalmente, na seção 4,4, são discutidos alguns benefícios gerados para a indústria de petróleo & gás.

Os principais objetivos de um levantamento de geoquímica de superfície encontrados para a exploração de óleo e gás.

Estabelecer a presença e distribuição de hidrocarbonetos na área de interesse de desenvolvimento e de exploração.

Determinar a provável carga de hidrocarboneto para especificar a exploração e a avaliação dos prospectos na atividade de exploração.

O objetivo de um reconhecimento de um levantamento geoquímico de superfície está em encontrar exsudações e microexsudações que providenciem a direta evidência de que hidrocarbonetos termogênicos tenham sido gerados, estes documentam a presença de um sistema petrolífero funcionando e identificam as porções da bacia que são mais prospectivas.

Se o objetivo é avaliar questões da exploração e avaliação dos prospectos, os resultados dos levantamentos geoquímicos podem identificar aqueles associados com fortes anomalias de hidrocarbonetos, e além disso, disponibilizar grandes malhas de prospectos sobre a base da associação deles com indicadores de hidrocarbonetos.

A prospecção na geoquímica de superfície de uma determinada área a ser identificada, pode ocorrer em bacias terrestres (bacias onshore) ou em bacias marítimas(bacias offshore).

Na primeira, as amostras de gases leves são comumente detectadas em headspace de solos em áreas ambientais.

E na segunda, as amostras são coletadas por meio de piston core no assoalho marinho.

A amostragem inclue headspace, probe, blender e hidrocarbonetos adsorvidos.

Algumas questões importantes na seleção de uma área prospectável devem ser consideradas como, se existe uma área fonte rica em matéria orgânica ou se a rocha fonte teria atingido uma temperatura suficiente para gerar grandes volumes de hidrocarbonetos.

E por último, conhecer os caminhos de migração dos hidrocarbonetos que levem a um trapa.

Estes caminhos de migração que podem ser por migração primária e secundário ou migração terciária, devem ser observados através da distribuição regional dos seeps em relação as estruturas.

Abaixo, estão básicas de um levantamento geoquímico.

Seleção da área a ser estudada Esta etapa corresponde a uma avaliação regional inicial, que compreende estudos geológicos, geofísicos e sensoriamento remoto.

Nesta etapa são realizados avaliações de tendências e prospectos regionais.

Seleção do melhor programa geoquímico Nesta etapa devem ser aplicadas técnicas de amostragem de campo, programas laboratoriais.

Programação de amostragem Corresponde a avaliação do programa de amostragem onshore e/ou offshore.

Ocorre quando existe vazamento a partir de um trapa e a pressão flutuante (buoyant) é maior que a capilar, assim a gota de óleo pode mover-se através da porosidade rochosa.

A amostragem geoquímica compreende a algumas fases que são consideradas importantes para a realização de boas inspeções, tais como o planejamento, a logística e as ferramentas de coleta.

A seguir serão descritos com detalhes estas fases.

A fase de planejamento inclui a discussão da área a ser analisada, a malha de amostragem e escolha de pontos e os tipos de levantamentos.

A discussão da área, corresponde em levantar dados, discutir com o cliente sobre a geologia, a geofísica, as estruturas em subsuperfície, a quantidade de amostras, a logística (custos) e definir parâmetros cartográficos da área a ser levantada.

Datum, projeção e mc(meridiano central).

A determinação da malha de amostragem e a escolha dos pontos, é geralmente recomendada para estudos exploratórios, malhas de 500m e a distribuição de pontos deve ser de forma mais regular possível, sendo que estes pontos devem ser direcionados em cima de falhamentos e estruturas mapeadas.

Os tipos de levantamentos devem ser em carta topográfica ou sísmica.

Nesta fase de logística são realizados os levantamentos das necessidades, como materiais de escritório, de campo e os equipamentos de segurança.

Deve ser escolhido uma cidade para servir como área base do levantamento.

O controle de custos, também é importante por levantar e controlar as despesas, tais como mão-de-obra, hospedagem, aluguel de carro, combustíveis, alimentação e outros.

E por último, a formação de uma equipe de campo (geólogo, técnico ou operador) e a localização dos pontos do levantamento, são também consideradas necessárias para a realização de um bom levantamento geoquímico.

As ferramentas de coleta compreendem tipos de amostragens que podem ser por gases livres(headspace e probe), hidrocarbonetos oclusos (blender) e/ou hidrocarbonetos adsorvidos (adsorvidos).

Os gases livres são altamente móveis e encontrados em espaços intersticiaisou poros.

Enquanto, que os gases sorvidos ( adsorvidos ou absorvidos) apresentam mobilidade restrita.

Alguns tipos de ocorrências e maneiras de amostragem de gás no solo e exsudações na água podem ser descritos a seguir.

Comumente empregado para análises de amostras que são repassadas para recipientes em latas.

As amostras são oriundas de perfurações e/ou sedimentos rasos.

Nesta técnica um volume controlado de sedimento é inserido na lata com um volume de salmoura.

A lata é então selada e um volume de salmoura medido é substituído pelo nitrogênio para criar um volume de headspace conhecido.

Após o equilíbrio ser atingido a concentração de gases livres pode então ser medida com injeção de uma seringa de uma amostra headspace dentro de um cromatógrafo de gás equipado com um detector de ionização de chama.

Corresponde a uma leitura direta de gases livres e comumente empregada em análises que devem ser conduzidas sobre fluidos de perfuração ou amostras de rocha recuperada a partir de uma escavação ou furo no solo.

Estas escavações profundas quase sempre se encontram com água, no qual podem influenciar a coleção de gases livres, forçando a analisar o conteúdo de algum tipo de gás na água reciclada ou no sistema lama no qual é usado para perfurar o buraco.

Assim, um pequeno tubo concêntrico selado é assentado no solo a algumas profundidades.

Com um auxílio de uma seringa usada para evacuar os gases residuais a partir do probe antes da amostra de gás no solo ser coletada.

A amostra de gás no solo é coletada em vidros de 125ml e evacuada.

Blender (intersticiais).

Empregada em análises onde se utiliza um agregador de partículas.

Os hidrocarbonetos são moídos e desagregados em um liquidificador, em seguida, realiza-se por meio de uma seringa, a amostragem que corresponde a injeção dos hidrocarbonetos no cromatógrafo e em seguida no interior do blender.

Gases Adsorvidos.

A análise deste gás ou extração ácida captura gases adsorvidos em sedimentos finos, seja em inclusões no interior de carbonatos autigênicos ou por águas estruturadas.

De acordo com, o gás permanece protegido no interior da estrutura da água e por isso.

Não realiza trocas com gases livres nos espaços intersticiais.

É protegido de ataques microbianos e migra verticalmente segundo handshake migration.

A adsorção aumenta quando o grânulo adsorvente diminui ( aumento da área superficial).

E pode ser física ou química.

Física ou de Wan der Waal.

Ocorre por energia de adsorção baixa e ligação frouxa da substância adsorvida ao adsorvente.

Ocorre por energia de adsorção elevada e ligação firme da substância adsorvida.

Pode envolver um cátion ou ânion estranho.

A análise geoquímica pode ser dividida em duas fases importantes.

A Quantificação dos hidrocarbonetos presentes (Screening Analysis), que pode ser realizada em todas as amostras através da análise de Cromatografia gasosa, Fluorescência Quantitativa e Cromatograma a Gás (Whole Extract-GC).

A caracterização dos hidrocarbonetos encontrados (Detailed Analysis) que é realizada através das análises de Biomarcadores (GM-MS), Diamandóides e Isótopos de Carbono.

Esta última será realizada em amostras com alta concentração de gases (acima de 500ppm), através da espectrometria de massa com a finalidade de determinar a origem dos hidrocarbonetos.

Entretanto, nesta dissertação será descrito apenas o método de quantificação de cromatografia a gás por ter sido este o único método de análise geoquímica utilizado.

Corresponde a análise geoquímica para quantificação dos hidrocarbonetos leves (C1 a C5), em que a mistura gasosa deverá ser retirada dos recipientes oriundos do campo e injetados em cromatógrafos de alta resolução capazes de determinar e quantificar as concentrações em ppm de metano, etano, propano, propeno, i-butano, 1-buteno e npentano.

O cromatógrafo deve ser equipado por uma coluna capilar e um detector de ionização de chama2 (FID ou DIC).

O princípio básico do cromatógrafo ocorre por separação das misturas e por interação diferencial dos seus componentes entre uma fase estacionária FE(líquido ou sólido) e uma fase móvel-FM ( líquido ou gás).

Para que ocorra a separação destes constituintes das misturas, estes devem ser voláteis ou evaporáveis, termicamente estáveis e com ponto de ebulição até 300oC.

Assim, as amostras coletadas devem ser injetadas em um vaporizador em uma coluna cromatográfica gerando um sinal quando da passagem de substâncias que não o gás de arraste.

Definido como um tipo de detector onde os íons são gerados durante a queima dos eluentes em uma chama de H2 + ar.

A calibração do cromatógrafo deve ser diária, utilizando-se uma mistura gasosa contendo concentrações conhecidas e o cálculo destas concentrações e a transferência dos valores para o formato digital deverá ser automatizado evitando assim erros de transcrição.

Os erros analíticos devem ser inferiores a 15%.

Os dados de geoquímica de superfície muitas vezes podem apresentar ruídos (noisy).

Isto tem sido de grande problema para o uso das técnicas de geoquímica de superfície.

Como também, tem gerado uma grande responsabilidade para os analistas no que se refere a interpretação dos resultados de muitas inspeções geoquímicas.

A característica da vida de uma população natural determinada em um solo ou sedimento, irá incluir todos os possíveis membros de uma área de interesse.

A população amostrada ou amostra estatística, engloba amostras individuais ou medidas realizadas no campo.

A população amostrada será então muito menor que a população total, requerendo que esta população amostrada deva ser representativa da população total.

Esta representatividade pode ser obtida por uma faixa amostrada, mas o grid (malha) amostrado é aproximadamente mais comumente usado em avaliações de lugares específicos que devem enfatizar uma área de interesse.

O número de amostras ou medidas requeridas é também dependente dos objetivos de um levantamento de geoquímica de superfície.

Sendo estes importantes durante um processo de planejamento.

Durante o reconhecimento de um objetivo de uma avaliação da geoquímica de superfície, em que se deseja determinar se uma bacia é prospectiva ou não, poucas amostras são requeridas na identificação dos prospectos.

A separação de amostras com anomalias de amostras background 3 é uma das mais críticas partes dos levantamentos de geoquímica de superfície.

Não existe uma proporção de amostras com anomalias a ser distinguidas a partir de amostras background.

A prática comum de considerar amostras maiores que uma média ou dois desvios padrões como anomalias existenciais que não tem base científica.

Este limiar ou fronteira entre anomalias e background, deve ser determinado objetivamente usando os dados disponíveis.

E um reconhecimento de um levantamento ou determinação da prospectividade de uma fronteira de uma bacia, muitas poucas amostras ou medidas devem ser anomalias.

A amostra background não é um único valor.

Isto é uma faixa de valores, particularmente para cobrir uma ampla área de inspeções ou ter contraste no solo, condições geológicas e ambientais.

Indicações em superfície de exsudações de óleo e gás tem sido causadas a milhares de anos, como exsudações que tem liderado a descoberta de muitas importantes áreas produtoras de petróleo.

Embora a descoberta de uma superfície com anomalias geoquímicas não garanta a descoberta significante de petróleo, isto estabelece a presença de hidrocarbonetos na área de interesse.

As exsudações de hidrocarbonetos em superfície representam o caminho final da migração.

Trapas e estruturas ao longo deste caminho devem ser considerados significantemente mais prospectivos que aqueles associados as anomalias.

Assim, benefícios potenciais podem ser apontados como importantes para o completo sucesso na busca desta detecção de hidrocarbonetos em superfície e se obter o sucesso na exploração geoquímica.

Dentre estes principais benefícios podem ser citados.

Detectar hidrocarbonetos diretamente ou de forma induzida por mudanças no solo, sedimentos próximos à superfície e/ou no fundo do mar.

Documentar a presença de um Sistema Petrolífero funcionando na área de interesse.

Permitir um high-grading das bacias, plays e/ou prospectos4 para adquirir arrendamentos ou realizar a condução de inspeções sísmicas detalhadas em uma etapa anterior à prospecção.

O termo play corresponde a uma série de trapas, enquanto que prospecto é definido como uma feição geológica mapeada resultante de estudos geológicos e geofísicos que justifiquem a exploração de petróleo e gás natural.

Avaliar áreas em que inspeções sísmicas são impraticáveis e não efetivas por fatores ambientais e geológicos.

Providenciar métodos aplicáveis para trapas estruturais e estratigráficos com a abilidade para localizar trapas invisíveis e pobremente imageados com dados sísmicos.

Ter pouco ou nenhum impacto ambiental (maior parte inclui métodos de geoquímica de superfície).

Nesta seção um prévio estudo dos casos é apresentado.

Na seção 5 serão discutidos algumas das principais características do reservatório de Sabinsville que será utilizado nesta dissertação.

Este reservatório foi primeiramente analisado, seus dados e amostragens foram usados nesta dissertação na análise dos resultados.

Na seção 5 são descritos os equipamentos utilizados para a amostragem e finalmente na seção 5,1 é apresentada a metodologia para a coleta dos dados.

O reservatório de Sabinsville, localizado no Norte central da Pensylvânia nos Estados Unidos Da América, foi escolhido como lugar de estudo, porque está isolado de outras fontes de gás natural ou óleos, como também porque não existe nenhuma camada de carvão(coal beds) pelo qual o gás natural possa ser adsorvido acima ou adjacente ao reservatório.

O reservatório de Sabinsville é um campo de gás natural depletado do Devoniano do Arenito Oriskany, situado a uma profundidade de aproximadamente 1219m.

A produção deste campo teve início em 1935 e posteriormente foi transformado em reservatório de armazenamento de gás natural 1951.

À esquerda um mapa da Pensylvânia, com a localização do reservatório de Sabinsvalle (acima).

Abaixo e à direita, o Arenito Oriskany.

O gás natural oriundo do sudoeste dos Estados Unidos da América, é armazenado no reservatório para uso durante as estações de calor no nordeste desta região.

A pressão do reservatório varia anualmente e a pressão máxima não pode exceder a pressão de formação original de quando o reservatório foi descoberto.

Pode ser visto uma estrutura do mapa de contorno mostrando a forma e a extensão do reservatório.

Esta indica que o trapa é uma estrutura anticlinal de direção nordeste-sudoeste e que apresenta uma falha sobre o limite sul.

Estrutura de contorno do topo do Arenito Oriskany, mostrando a forma e a extensão do reservatório de Sabinsville.

A técnica do Headspace foi escolhida para realizar os levantamentos e aplicada por apresentar fácil uso na coleção das amostras, além de ser de baixo custo.

Esta técnica também é menos susceptível a mudanças na pressão barômétrica, removendo deste modo, qualquer fonte adicional de variabilidade.

Na técnica do headspace as concentrações dos hidrocarbonetos das amostras do solo foram determinadas usando um cromatógrafo a gás, com um detector de ionização de chama.

As amostras foram armazenadas em um refrigerador até posterior análise.

Estas amostras foram então seladas em um tubo de vidro e foram aquecidas até 80oC por uma hora com o objetivo de liberar o gas livre parcialmente retido entre os sedimentos.

Após o aquecimento, 500 µl de volume dos gás headspace foi extraído e imediatamente injetado com uma micro seringa dentro de um cromatógrafo de gás calibrado.

O cromatógrafo foi calibrado com padrões de gás de C1 A C5 e diluídos em ar.

Os dados de calibração foram ajustados por uma curva de regressão não linear, como descrito.

O conteúdo da mistura do solo no tempo da coleção da amostra, foi determinado por medida da perda de peso após o aquecimento da amostra aberta a 80 oC durante 48 horas.

Este procedimento foi realizado para retirar a água entre os poros e para não ocorrer desidratação dos minerais presentes.

O fator mistura não foi categorizado, mas entrou nas análises estatísticas como uma porcentagem peso.

Foram conduzidos dois levantamentos geoquímicos no reservatório de Sabinsville, em novembro de 1994 e em julho de 1995.

Estes diferentes tempos dos levantamentos foram escolhidos, para se obter dados durante as estações de inverno e de verão, apesar destes serem correspondentes exatamente as pressões máximas e mínimas do reservatório.

A primeira devería ocorrer tipicamente em setembro e a última em março ou abril.

A estação de verão, correspondente ao mês de julho refere-se ao período de recarga e novembro marca o início da produção anual.

Cada levantamento consistiu de uma única linha de perfil de aproximadamente 80 posições em intervalos de aproximadamente 76m (250ft) atravessando o reservatório.

As amostras foram coletadas, a uma profundidade entre 15 e 30cm (6 e 12 polegadas, respectivamente).

Amostras múltiplas (10 a 20) foram coletadas nas 3 locações ao longo da linha do perfil.

Para cada posição foram coletados também dados ambientais.

Dentre estes parâmetros ambientais estão incluídos, a inclinação da superfície, o aspecto, o tipo de solo, o uso do terreno e o conteúdo da mistura no solo.

Foram definidas três ou mais categorias para cada fator ambiental e os valores numéricos foram atribuídos para cada categoria.

Finalmente, a categoria estatística final usada nas análises foi a relação das fronteiras do reservatório para cada posição da amostra no reservatório.

Isto foi definido por através da projeção das fronteiras para a superfície e então determinado onde as amostras se posicionavam em relação à estes limites do reservatório.

As posições das amostras que se encontravam acima do reservatório foram designadas como categoria 2 e as posições fora do reservatório foram atribuídas a categoria 1.

Nesta Seção, serão discutidos alguns dos primeiros resultados geo-estatísticos obtidos das inspeções geoquímicas, em uma etapa anterior à aplicação das técnicas de mineração de dados, denominada nesta dissertação de Análise Exploratória dos dados.

Esta etapa, torna-se importante por extrair informações úteis para cada inspeção, que visem um melhor conhecimento dos dados.

Em uma etapa posterior são aplicados as técnicas de Mineração de dados, em que modelos de classificação supervisionada, de redes neurais artificiais, árvores de decisão e aprendizado bayesiano foram construídos e analisados.

Estas técnicas de modelagem quando integradas as análises geo-estatísticas convencionais proporcionam uma melhor exatidão dos resultados geoquímicos obtidos.

Esta seção subdivide-se na seção 5, que corresponde a etapa de Análise Exploratória dos dados e na seção 5,2, que corresponde a Aplicação das técnicas de Mineração de Dados.

Foram utilizados dois bancos de dados referentes aos dois levantamentos geoquímicos correspondentes aos meses de novembro e de julho, como citado na seção 5.

Estes banco de dados estão constituídos de 16 variáveis, sendo que 10 correspondem as variáveis dependentes, dentre elas, amostras coletadas de hidrocarbonetos leves (gases) de C1 a C5 e amostras de gases adsorvidos no solo.

Dentre as variáveis coletadas, foram incluídas 6 variáveis categóricas, descritas como fatores ambientais de solo.

Entretanto, estes parâmetros ambientais foram usados somente para uma análise das médias e frequências, por apresentarem sua importância relacionada ao números de ocorrências destes nas concentrações dos hidrocarbonetos referentes aos levantamentos geoquímicos.

Cada banco de dados apresenta cada um, um total de 83 registros, sendo que o banco de dados referente ao levantamento de julho totalizou apenas 82 registros nas variáveis dependentes.

Isto deve-se ao fato de que no banco de dados a amostra 397 apresentou apenas dados faltantes.

Linha de perfil mostrando as fronteiras norte e sul.

A linha pontilhada em azul corresponde ao levantamento de novembro e a vermelha ao levantamento de julho.

Em uma prévia análise dos bancos de dados, foi observado que as concentrações de metano apresentam-se relativamente muito baixas para os gases adsorvidos.

Este fato é surpreendente, quando comparamos a uma composição de um gás natural típico.

O propano e o butano apresentam concentrações baixas, como era esperado pelas concentrações do gás natural típico.

Finalmente, o pentano está presente em altas quantidades, o que não era esperado.

Isto pode ser atribuído ao fato de que nos Estados Unidos da América, os gases mais leves são geralmente retirados e reinjetados primeiro, ficando os gases mais pesados como sendo utilizados como um pulmão.

Desta forma, a composição deste gás final, nunca será a mesma que a composição do gás original.

Nesta pesquisa, era de extrema importância identificar na linha de perfil, em que foram coletados as amostras geoquímicas, as fronteiras do reservatório de gás natural.

Entretanto, esta linha não pode ser mostrada em um plano, pois não foram coletadas juntamente com as amostras as coordenadas x e y.

A linha foi traçada no espaço contendo todos os pontos amostrados referentes aos dois levantamentos geoquímicos.

Observou-se que no levantamento de novembro a fronteira sul está presente entre o intervalo de 1577-1692m e a fronteira norte no intervalo de 4084-4161m.

Enquanto que no levantamento de julho, a fronteira sul encontra-se entre o intervalos de 1547-1623m e a fronteira norte no intervalo de 4107-4183m.

Com o objetivo de conhecer melhor os dados e seu comportamento, referente aos dois levantamentos geoquímicos, foram aplicadas análises estatísticas convencionais.

Com este intuito foram construídos inicialmente tabelas descritivas, onde foram calculadas as médias, as amplitudes, os valores máximos e mínimos, os desvios padrões e erros padrões.

Em seguida foram determinadas as médias e as frequências para os fatores ambientais.

Finalmente, foram construídos gráficos de histogramas, box-plots, linhas de perfis, dendograma e as coordenadas estrela, para uma discussão mais detalhada dos outliers.

Esta é uma etapa importante no estudo, porque oferece um sólido conhecimento dos dados para posterior aplicação das metodologias de classificação supervisionada.

Construção das Tabelas Descritivas para os levantamentos geoquímicos.

Primeiramente, montou-se tabelas descritivas referentes aos levantamentos geoquímicos de novembro e julho, respectivamente, com os primeiros resultados geo-estatísticos obtidos.

As médias apresentaram-se baixas e os desvios padrão (DP) com valores um pouco mais elevados.

Os valores mínimos permaneceram constantes e nulos.

Verifica-se também, que os maiores valores obtidos para todos os cálculos foram observados nas amostras de etano, butano e pentano, enquanto que os menores valores foram observados para o metano e propano.

Isto deve-se ao fato de que dentre as 5 espécies de hidrocarbonetos presentes nos levantamentos geoquímicos, o etano, o butano e o pentano apresentam-se com concentrações mais elevadas quando comparadas a um gás natural típico, como explicado na seção 5,2.

Observa-se que os valores dos gases adsorvidos no solo apresentam-se aparentemente mais elevados, pois estão em ppb (partes /bilhão), enquanto que os gases livres estão em ppm (partes /milhão) e não podem ser comparados.

Neste levantamento, verifica-se a permanência dos maiores valores também para as amostras de etano, butano e pentano, enquanto que os menores valores foram encontrados para o metano e o propano.

Entretanto, os valores mínimos não apresentaram-se constantes, mas se situaram em torno do valor nulo.

As médias apresentaram valores baixos, mas um pouco mais alto que o desvio padrão.

Na análise dos dois levantamentos geoquímicos, notamos algumas diferenças contrastantes.

Estas diferenças estão associadas as diferenças nas temperaturas, ou melhor, condições atmosféricas e composição do solo diferentes, já que foram levantamentos realizados em estações climáticas diferentes, no inverno (novembro) e no verão (julho).

Análise das Médias e Frequências dos Parâmetros Ambientais.

Para uma melhor análise de todas as variáveis, foram plotados os gráficos referentes às médias das 6 variáveis categóricas e construído tabelas destas médias.

Dentre os fatores ambientais estão.

A mistura no solo, o aspecto, o uso do terreno, a posição no reservatório, a inclinação e o tipo de solo das variáveis etano escolhidas.

Na discussão dos resultados obtidos foi escolhido a variável etano (gás e no solo) como o melhor candidato por apresentar as melhores correlações.

Gráficos referentes das médias dos fatores ambientais da variável etano (C2) gás para os levantamentos de novembro e julho.

Do mesmo modo que na análise das variáveis dependentes, foram encontrados, valores mais elevados para as médias referente ao levantamento de novembro.

Os gráficos que obtiveram as maiores médias foram os fatores da mistura, uso da terra, tipo de solo e inclinação para as duas variáveis etano.

O fator posição foi desconsiderado nas análises.

Gráficos referentes das médias dos fatores ambientais da variável etano (C2) solo para os levantamentos de novembro e julho.

É mostrado as médias dos fatores ambientais e em seguida o gráfico destas médias, para a variável etano solo.

Observa-se que as variáveis mistura, uso do terreno, tipo de solo e inclinação apresentaram as maiores ocorrências, estando estes mais frequentes nas concentrações da variável etano.

A variável mistura não foi categorizada.

Entretanto, os valores encontrados para a frequência correspondeu na variável uso do terreno a categoria wood lot (categoria 4) que foi a de maior corrência.

Verifica-se que o fator uso do terreno, reflete a quantidade de distúrbio no solo.

Já a categoria solo do tipo Volúsia /Chippewa atribuída ao outro fator encontrado como de maior ocorrência, o tipo de solo, foi definida por apresentar textura do solo fina, alto teor de matéria orgânica e sem hardpan (camada do subsolo mais dura ou silte).

Prosseguindo nas análises foram construídos gráficos de Histogramas e BoxPlot ´s para todos os alcanos.

Nas análises dos gráficos a seguir, é mostrado os histogramas referentes as variáveis escolhidas para os levantamentos de novembro e de julho, respectivamente.

Primeiramente, são comparados os resultados obtidos para a variável etano gás.

O gráfico não apresenta uma boa simetria, evidenciando 3 diferentes populações.

A população maior é mostrada com um círculo, com baixo número de observações e aparece como a mais importante, porque corresponde a uma possível pesença de outliers.

Para a mesma variável etano gás, entretanto para o levantamento realizado em julho, verifica-se a possivel região de outliers, com uma população um pouco menor, quando comparada ao levantamento de novembro.

Em continuidade a análise geo-estatística da variável etano (C2) gás e considerando os dois levantamentos geoquímicos juntamente, foram constatados a presença de outliers nos dados, já identificados nos histogramas, através da construção de gráficos box-plots.

Os casos destacam-se pelo afastamento da dispersão esperado para o conjunto de dados de novembro.

Enquanto, outros destacam-se como valores afastados da distribuição amostral observada para o levantamento geoquímico de julho.

Observa-se que no primeiro levantamento geoquímico existe uma maior população de outliers e extremos, quando comparamos com o segundo levantamento, que apresentou uma população com um número menor de outliers.

Gráfico box-plot da variável etano (C2) gás referente aos levantamentos geoquímicos de novembro e julho.

Esta análise é considerada bastante importante, porque a presença ou a ausência destes outliers pode afetar bastante a modelagem que será realizada futuramente, principalmente no caso da construção da rede neural.

Para uma melhor identificação dos casos descritos anteriormente na linha de perfil, percorrida durante a coleta dos dados, foram plotados gráficos mostrando um perfil das variáveis em função da distância percorrida.

A seguir é mostrado um gráfico do perfil da variável etano gás referente ao levantamento geoquímico de novembro.

Foi traçado também as fronteiras do reservatório determinadas como descrito anteriormente na seção Observa-se que foram encontrados outliers e extremos em maior quantidade fora das fronteiras do reservatório e na linha de perfil observa-se também alguns sinais mais elevados que aparecem no interior e na parte externa dos limites norte e sul do reservatório.

Linha de perfil da variável etano (C2) gás para o levantamento de novembro.

As linhas verdes significam as fronteiras.

Com o objetivo de identificar todos os valores outliers e extremos, foram plotados box-plots para todas as variáveis correspondentes aos dois levantamentos geoquímicos.

Entretanto, apenas os gráficos para a variável etano foram discutidos nesta dissertação e os outros gráficos referentes às outras variáveis, tanto box-plots quanto as linhas de perfis encontram-se no anexo 3.

Em seguida foi mostrado uma linha de perfil para a variável etano gás referente ao levantamento de julho.

Observamos no gráfico apresentado que não houve presença de extremos, foram encontrados apenas outliers nos dados.

Estes estiveram presentes tanto no interior das fronteiras, quanto no exterior dos limites do reservatório.

Como mostrado na análise anterior da mesma variável, mas do levantamento de novembro, foram observados mais sinais fora do reservatório, principalmente na fronteira sul e apenas um sinal mais elevado no interior das fronteiras do reservatório.

Linha de perfil da variável etano (C2) gás para o levantamento de julho.

As linhas verdes significam as fronteiras.

Na análise desta tabela observa-se um total de 28 outliers e 29 extremos para o levantamento geoquímico referente ao mês de novembro.

Enquanto, que apenas 14 outliers e 3 extremos referentes ao levantamento realizado em julho.

Tabela com a quantidade de outliers e extremos presentes nos dois levantamentos geoquímicos (novembro e julho).

O estudo dos outliers é uma importante etapa na análise dos dados, pois em um conjunto de dados podemos encontrar determinadas observações que fogem ao comportamento geral da base de dados como um todo.

Estes outliers podem ser considerados ruídos ou exceções, valores espúrios ou somente valores indesejáveis na massa de dados.

Assim, sugere-se que se faça um tratamento destes outliers com a eliminação dos registros espúrios, através da aplicação de métodos estatísticos.

Entretanto, em algumas aplicações o outlier é justamente o que se busca no estudo, uma exceção ou registros importantes na massa de dados.

Neste caso, deve-se avaliar a conveniência da permanência destes no conjunto de dados.

Na análise do reservatório utilizado nesta dissertação, vimos que existe a presença de uma falha no limite da fronteira sul.

Contudo, em reservatórios de armazenamento de gás os hidrocarbonetos migram em uma direção preferencialmente vertical a partir das rochas geradoras e reservatórios até a superfície das estruturas trapeadas.

Entretanto, se algum vazamento ocorrer a partir deste trapa ou uma migração ocorrer pela estrutura de da falha ao sul, pode-se ter gerado a migração do escape de gás pela lateral.

Neste caso, a migração pode ter ocorrido tanto lateralmente quanto verticalmente.

Estes fato pode explicar a presença destes outliers na fronteira ao sul do reservatório.

Vamos prosseguir a nossa análise das outras variáveis, para em seguida realizarmos a melhor avaliação para a presença desta população mais dispersa presente nos dados.

Prosseguindo na análise destes outliers, é discutido aqui os gráficos de histogramas, box-plots e linhas de perfis para a outra variável escolhida, o etano no solo.

É mostrado um histograma para esta variável e verifica-se que o gráfico não mostra boa simetria, caracterizando-se pela novembro.

Presença de três populações, sendo que existe uma maior população, com aproximadamente 2,5 observações e importante para a análise.

Esta população é observada nos valores assinalados em círculo do gráfico.

Existe uma semelhança para os gráficos mostrados da variável etano no solo para a outra variável etano gás referente ao levantamento de novembro.

As duas variáveis apresentaram uma população maior e mais afastada da população amostral.

Entretanto, as médias apresentaram-se mais altas para a variável etano no solo que para o etano gás.

Em continuidade a análise estatística para a mesma variável etano no solo, foi plotado um histograma desta variável referente ao levantamento de julho.

Na análise, observa-se da mesma forma que para o levantamento de novembro, uma população que foge ao comportamento geral do banco de dados como um todo.

Histograma referente a variável etano (C2) no solo do levantamento de julho.

Foi plotado um gráfico box-plot para a variável etano no solo dos levantamentos de novembro e julho.

Foram encontrados para esta variável outliers e extremos.

Os casos identificados no banco de dados como 171, 179, 181, 195, 196, 239, 240 e 243 referente ao levantamento geoquímico de julho, destacam-se como valores demasiadamente afastados da distribuição amostral, por estarem mais dispersos do conjunto de dados.

Enquanto que os casos 329, 333, 356 e 376 destacam-se como casos dispersos referente ao levantamento de julho.

Linha de perfil da variável etano (C2) no solo para o levantamento de julho.

As linhas verdes significam as fronteiras.

Exatamente como descrito anteriormente na análise da variável etano gás, o primeiro levantamento geoquímico apresentou uma maior quantidade de outliers que no levantamento de julho.

Podemos observar que há uma grande repetição nos resultados das variáveis entre os levantamentos realizados de uma mesma área.

A evidência desta repetibilidade nas análises do perfil, por exemplo, pode estar associada aos fatores ambientais da superfície como composição e condições de solo, que podem alterar as concentrações dos hidrocarbonetos, quando combinados a grande dispersão nos dados.

Com o objetivo de finalmente concluírmos nossa interpretação a respeito dos outliers e extremos encontrados nos dados, prosseguimos nossa análise do levantamento de novembro.

Este foi o que apresentou uma quantidade significante de oultiers e extremos.

Foi então construído primeiramente um dendrograma.

Observa-se que foram separados os 2 grupos referentes às posições acima do reservatório (categoria 2) e fora do reservatório( categoria 1).

Dendrograma referente as amostras do levantamento de novembro.

Desta forma, vemos claramente que não existem nos dados pontos que possam ser considerados como valores espúrios ou pontos indesejáveis na massa de dados.

Tal fato é comprovado usualmente pelo gráfico.

Gráfico das coordenadas estrela das variáveis presentes no levantamento de novembro.

Anterior, em que o espaço multidimensional é representado em coordenadas estrela.

Na seção anterior foi realizado uma análise dos dados para que fosse possível o melhor conhecimento dos dados.

Nesta seção serão aplicadas as técnicas de mineração de dados e construídos os modelos das redes neurais artificiais, árvores de decisão e aprendizado bayesiano, sobre os bancos de dados referentes aos levantamentos geoquímicos de novembro e julho.

Os dados foram pré-processados e a normalização realizada.

Os outliers e extremos encontrados na etapa anterior foram mantidos, pois sua permanência era de extrema importância na pequena massa de dados, e estes não foram considerados como valores espúrios, fato este já explicado na etapa anterior da seção 5.

Esta seção subdivide-se em outras três.

Na seção 5,2,2,1, foram construídos os modelos da rede neural artificial e discutidos sua principais características.

Na seção 5,2,2,2, foram aplicadas as técnicas da árvore de decisão para os dois levantamentos.

Finalmente, na seção 5,2,2,3 foram construídos os modelos do aprendizado bayesiano.

Aplicação das Redes Neurais Artificiais Nesta pesquisa foi utilizado a rede neural do tipo MLP (Multilayer Perceptron) da classe de redes multilayer feedforward.

Esta escolha foi devido ao fato de que esta rede é mais utilizada em problemas envolvendo previsão e análises temporais.

Estas redes são chamadas desta forma porque o processamento da informação dá-se no sentido progressivo, através das interconexões entre os neurônios das camadas adjacentes.

Cada unidade de uma camada é conectada para a frente a cada unidade da camada seguinte.

As ativações fluem da camada de entrada para a camada oculta e daí para a camada de saída.

Como sempre, o conhecimento da rede é codificado nos pesos sobre as conexões entre as unidades.

O algorítmo utilizado foi o Backpropagation (Retropropagação), comumente usado para este tipo de rede neural.

Foram realizadas várias tentativas a fim de se conseguir o melhor resultado possível nos dois levantamentos geoquímicos.

Inicialmente foi construída uma rede com 16 neurônios na camada de entrada e pela utilização da fórmula encontrada na literatura 2(n + 1), usando n=16 tentou-se descobrir quantos neurônios poderíam ser utilizados na camada intermediária.

A primeira tentativa ocorreu com 34 neurônios na camada intermediária, 16 neurônios na camada de entrada e 1 neurônio na camada de saída.

Entretanto, não houve sucesso na RNA encontrada.

Novas tentativas foram realizadas, retirando os neurônios da camada intermediária e avaliando o desempenho da rede.

Foi observado que para uma camada intermediária contendo 10 neurônios o treinamento foi eficiente.

Assim, a melhor rede devería ser executada, com uma camada de entrada com 16 neurônios, uma camada intermediária contendo 10 neurônios e 1 camada de saída com 1 neurônio apenas.

Os 16 neurônios correspondem as variáveis de entrada, que foram todas usadas inclusive os parâmetros ambientais descritos no anexo 1.

O único neurônio da camada de saída consistiu da variável posição no reservatório, sendo atribuído a categoria 2 para os hidrocarbonetos localizados acima do reservatório e a categoria 1, para os hidrocarbonetos situados fora das fronteiras do reservatório de gás natural.

Inicialmente, foi realizado o treinamento, a verificação e o teste da rede usando um total de 83 registros.

Observou-se que sem alterarmos o conjunto de dados, esta apresentou um desempenho bastante baixo, com 76 % dos dados classificados corretamente para o levantamento de novembro e 73 % dos dados classificados corretamente para o levantamento de julho.

Os modelos foram cosntruídos utilizando diferentes classificadores, entretanto não houve sucesso na construção destes modelos.

Efetuou-se então a análise dos bancos de dados.

Observou-se que haviam mais amostras contendo a categoria 1 do que a categoria 2.

A solução encontrada então, foi equilibrar a massa de dados, tentando treinar a rede com dados que tivessem uma quantidade parecida de 1 e 2.

Assim, aumentou-se os bancos de dados, trabalhando com um total de 102 registros.

Isto porque, se o treinamento estivesse equilibrado o desempenho dos classificadores devería automaticamente tornar-se melhor.

A construção da rede foi conduzida com os parâmetros já selecionados.

Construção da RNA para o levantamento de novembro Prosseguiu-se com esta rede e primeiramente com o levantamento geoquímico conduzido em novembro, dividindo-se os dados e separando-os 70% para treinamento, 15% para verificação e 15% para teste.

Os dados de treinamento e citados anteriormente foram equilibrados pelas posições 1 e 2 do reservatório.

Após o ajuste dos dados, foi obtido na construção do modelo 68 pontos para treinamento, 15 para verificação e 19 para teste.

Desta forma, tentou-se selecionar uma melhor e mais simples função de transferência que devería ser aplicada às três camadas.

A melhor função de ativação a ser usada na camada de entrada foi a linear, para a camada intermediária a sigmóide ou hiperbólica e na camada de saída a logística.

Tentou-se também não oferecer à rede nenhuma função de ativação afim de se buscar uma boa previsão, entretanto não houve sucesso.

Cabe ressaltar que o treinamento foi interrompido em função desta ter alcançado o número máximo de épocas.

Principais parâmetros adotados na construção da RNA para o levantamento de novembro.

Uma arquitetura do melhor modelo da rede neural obtida, é mostrada a seguir.

Observa-se que esta apresenta os valores de entrada, referentes as 16 variáveis conectadas a cada neurônio na camada de entrada.

Uma camada intermediária com seus pesos calculados e uma camada de saída referente a posição dos hidrocarbonetos no reservatório, ou seja, o melhor modelo da rede encontrado apresenta-se da forma 16x10x1.

Neste trabalho de pesquisa a saída pode ser 1 ou 2, sendo que o valor atual 2 corresponde aos pontos situados acima do reservatório, correspondentes as anomalias procuradas no presente trabalho de pesquisa.

Arquitetura da RNA.

Com o modelo da RNA obtido e a rede construída utilizando-se todos os parâmetros citados anteriormente, verificou-se na regressão se existiam boas correlações nos dados para se avaliar se podería seguir adiante.

Observou-se uma correlação de 97% para o treinamento, 97 % para a verificação e 96 % para o teste.

Entretanto, após sucessivas tentativas de treinamento o erro convergiu, e somente a 1300 épocas a rede "aprendeu".

Importante ressaltar que o número de épocas refere-se ao número de vezes que a rede após ter sido treinada, aprende.

Portanto a RNA referente ao banco de dados de novembro levou algum tempo para aprender.

Gráfico do erro de treinamento em função do número de épocas do levantamento de novembro.

Com o bom resultado obtido na regressão podemos dar continuidade ao trabalho e verificar a curva do erro do treinamento.

Verifica-se uma boa convergência do erro à 1300 épocas.

Verifica-se uma curva exponencial, decrescente e próximas tanto no treinamento quanto na verificação.

Além disso, após 1200 épocas a curva tende a convergir a um erro mínimo e passa a ser retilínea.

O resultado dos erros obtidos para o treinamento, verificação e teste foram 0,0431, 0,0436 e 0,0416, respectivamente.

Em seguida verificou-se os resultados obtidos para o conjunto de dados da previsão, para compararmos os valores previstos pela rede com os valores atuais (reais).

Com esse objetivo, foi traçado um gráfico da posição no reservatório em função da distância percorrida durante o levantamento geoquímico de novembro.

Gráfico dos valores atuais (linha contínua) e valores previstos (pontos) para o levantamento de novembro.

Podemos observar que a previsão foi realizada para todos os registros com bons índices de acerto, superiores a 95 % e a rede teve boa performance com os valores previstos por esta próximos aos valores reais.

Construção da RNA para o levantamento de julho Todo o procedimento anterior foi realizado novamente usando o banco de dados referente ao levantamento de julho.

Os parâmetros citados anteriormente foram repetidos, para que pudessemos realizar uma comparação dos dois levantamentos geoquímicos e avaliarmos o resultado da previsão da rede, identificando o desempenho dos classificadores.

Contudo, houve uma diferença relacionada ao aprendizado da rede no levantamento de julho.

Esta diferença refere-se ao número de vezes ou épocas que a rede aprendeu.

Principais parâmetros adotados na construção da RNA para o levantamento de julho.

Prosseguiu-se com a previsão e verificou-se estatisticamente se a regressão obteve bons resultados e boas correlações.

O índice de acerto da previsão apresentou-se muito bom, como podemos observar na curva a seguir.

O gráfico mostra uma boa convergência do erro tanto para treinamento quanto para a verificação e uma curva decrescente e exponencial a 700 épocas, bastante próximas uma da da outra.

Gráfico do erro de treinamento em função do número de épocas do levantamento de julho.

Observa-se também que a 500 épocas a curva começa a assumir uma forma retilínea, com era esperado.

Os resultados do erro obtidos para o treinamento e verificação foram de 0,01766, 0,03918 e 0,04711, respectivamente.

A previsão da rede foi finalizada, com bons índices de acerto e foi traçado um gráfico a seguir, da posição no reservatório em função da distância percorrida para este levantamento.

Gráfico dos valores atuais (linha contínua) e valores previstos (pontos).

Como podemos observar no gráfico quase todos os valores previstos pela rede estão situados em cima ou muito próximos aos valores reais.

Isto pode ter sido comprovado pelo índice de acerto de 99 % obtido.

Para a análise da árvore de decisão outro programa mais simples foi utilizado, denominado de WEKA 3,1.

Foram usadas como entradas as 16 variáveis, sendo 10 variáveis dependentes e 6 variáveis categóricas.

E as classes corresponderam as posições dos hidrocarbonetos no reservatório, já citadas anteriormente.

A classe 1 corresponde a posição dos hidrocarbonetos que estão situados fora do reservatório e a classe 2 corresponde a posição dos hidrocarbonetos situados acima do reservatório de gás natural.

Inicialmente foi construída os modelos das árvores para os dois levantamentos geoquímicos sem alterar nos dados.

O resultados obtidos não foram os melhores, do mesmo modo que na RNA.

O índice de acerto obtido foi de 70 % para o levantamento de novembro e 75 % para o levantamento de julho.

Outra tentativa foi então realizada.

A solução encontrada foi utilizar o mesmo procedimento realizado anteriormente para a rede neural.

Assim, equilibrou-se os dados referentes as posições do reservatório 1 e 2, para termos a metade dos dados de treinamento com posição 1 e a outra metade treinada com posição 2.

O restante foi utilizado no conjunto de teste.

O total final de registros ficou em 102 registros.

Prosseguiu-se então para a construção das árvores de decisão dos dois levantamentos.

Construção da Árvore de Decisão para o levantamento de Novembro.

Observa-se que árvore mais simples foi com o classificador J48.

A árvore de tamanho 5 e com apenas 3 folhas.

Foram separados um conjunto de treinamento e de teste de 70 % e 30 % respectivamente, como na rede neural.

E observados todos os resultados para os 4 tipos de classificadores mostrados.

O treinamento e o teste foi realizado usando os diferentes classificadores, para que fosse possível avaliarmos o desempenho dos mesmos.

Vemos que o índice de acerto para o classificador J48 ficou em 100 % e um erro de 0%, significando que este classificador teve um ótimo desempenho.

O ADTree também obteve um índice de acerto de 100%, mas um erro um pouco maior de 5,33 %.

É mostrado uma avaliação do split realizado, com os principais resultados dos erros comparando os 4 melhores classificadores.

Principais resultados do teste com diferentes classificadores para o levantamento de novembro.

Observa-se também que a matriz de confusão para o classificador J48 e o ADTree mostraram-se iguais.

Foram classificados 19 instâncias como reservatório 1 e apenas 12 como reservatório 2.

Pelo fato do classificador J48 ter apresentado a melhor árvore, de tamanho 5 e número de folhas 3, este foi escolhido para ser discutido.

Principais parâmetros do modelo da árvore para o levantamento de novembro.

Um algorítmo exemplificando do modelo da árvore construído foi montado logo a seguir.

Vemos que para valores da distância <= 4084 as posições assumidas no reservatório podem ser 1 ou 2.

Apenas 21 destas instâncias foram classificadas como posições situadas fora do reservatório, ou seja, posição 1, quando as distâncias foram <= 1577.

Enquanto, 51 das instâncias foram classificadas como posições situadas acima do reservatório, ou seja, 2, quando a distância foi >1577.

Estas instâncias classificadas como categoria 2 correspondem exatamente às anomalias procuradas e as distâncias 4084 e 1577, aos valores identificados como fronteira norte e fronteira sul do reservatório, quando foi desenhado a linha de perfil na seção 5,2.

Para valores > 4084 observamos que 30 instâncias foram classificadas como reservatório 1.

Arquitetura da árvore de decisão para o levantamento de novembro.

É mostrado uma arquitetura da árvore construída resultado do algorítmo implementado anteriormente.

Foram escolhidas as variáveis etano gás e etano no solo respectivamente, para ser apresentado um conjunto de treinamento referente ao levantamento de novembro.

É mostrado estes conjuntos de treinamento para estas variáveis.

Conjunto de treinamento da variável etano (C2) gás referente ao levantamento de novembro.

Conjunto de treinamento da variável etano (C2) no solo referente ao levantamento de novembro.

Construção da Árvore de Decisão para o levantamento de julho.

Todo procedimento foi repetido para o levantamento de julho.

Da mesma forma que no levantamento de novembro, foram separados um conjunto de treinamento e de teste de 70 % e 30 % respectivamente.

E observados todos os resultados para os 4 tipos de classificadores mostrados.

O treinamento e o teste foi realizado usando os diferentes classificadores.

Vemos que o índice de acerto para o classificador J48 ficou em 100 % e um erro de 0%, significando que este classificador teve um ótimo desempenho.

É mostrado uma avaliação do split realizado, com os principais resultados dos erros.

Principais resultados do treinamento com diferentes classificadores para o levantamento de julho.

Um algorítmo exemplificando a árvore construída foi montado logo a seguir.

Vemos que para valores da distância <= 4107 as posições assumidas no reservatório podem ser 1 ou 2.

Apenas 21 destas instâncias foram classificadas como posições situadas fora do reservatório, ou seja, posição 1, quando as distâncias foram <= 1547.

Enquanto que 51 das instâncias foram classificadas como posições situadas acima do reservatório, ou seja, 2, quando a distância percorrida foi >1547.

Estas instâncias classificadas como categoria 2 correspondem exatamente às anomalias procuradas e as distâncias 4107 e 1547, aos valores identificados como a fronteira norte e a fronteira sul do reservatório.

Para valores > 4107 observamos que 30 instâncias foram classificadas como reservatório 1.

É mostrado uma arquitetura da árvore de decisão para o levantamento de julho.

Podemos observar que a árvore de decisão mostra explicitamente as fronteiras do reservatório.

Arquitetura da árvore de decisão para o levantamento de julho.

Foram escolhidas as variáveis etano gás e etano no solo para ser apresentado um conjunto de treinamento o levantamento de julho.

É mostrado estes conjuntos de treinamento para estas variáveis.

Conjunto de treinamento da variável etano (C2) gás referente ao levantamento de julho.

Conjunto de treinamento da variável etano (C2) no solo referente ao levantamento de julho.

O procedimento aplicado inicialmente para equilibrar os dados foi repetido para a aplicação desta metodologia.

Foram separados diferentemente dos métodos anteriores 80% dos dados para treinamento e 20% dos dados para teste, pois o modelo não se mostrou muito eficiente quando o split foi realizado com 70%.

Foram comparados os classificadores para os levantamentos de novembro e de julho.

Inicialmente prosseguiu-se o treinamento e o teste para novembro.

Método do Aprendizado Bayesiano para o levantamento de novembro.

Foram testados vários classificadores, entretanto apenas dois deste mostraram-se com melhor desempenho.

O naive bayes simple e naive bayes.

Foi observado que o classificador naive bayes apresentou o melhor desempenho, ficando em 90,5% e um erro menor que 0,17%.

Na matriz de confusão observa-se que 12 instâncias foram classificadas como reservatório 1 e das 9, 2 instâncias foram classificadas como reservatório 1 e 7 como reservatório 2.

Resultados do teste com diferentes classificadores para o levantamento de novembro.

Método do Aprendizado Bayesiano para o levantamento de julho.

Foram testados os mesmos classificadores usados para o levantamento de novembro.

O naive bayes simple e naive bayes.

Resultados do teste com diferentes classificadores para o levantamento de julho.

Observa-se que os modelos construídos para o aprendizado bayesiano, no levantamento de julho, o classificadore que apresentou-se mais eficiente e com melhor desempenho foi o naive bayes simple, obtendo um índice de acerto de 95% e apenas 1 instância não classificada corretamente.

Em uma primeira etapa foi realizada uma análise geoestatística tomando como base as diferenças temporais dos levantamentos geoquímicos, realizados em diferentes estações do ano.

Foi observado significativas diferenças entre os levantamentos geoquímicos, que foram atribuídas basicamente as condições atmosféricas, principalmente de temperatura, e as condições de solo.

Sugere-se, que estas diferenças nos resultados possam ser amenizadas, quando as amostras coletadas em diferentes posições dos levantamentos geoquímicos forem menos espassadas que os levantamentos geoquímicos convencionais, de forma a obter melhores correlações estatísticas.

Os fatores ambientais de mistura no solo, tipo de solo e uso do terreno, apresentaram um maior número de ocorrências nas concentrações dos gases.

A importância desta avaliação, sugere que procedimentos específicos devam ser usados para discutir os efeitos individuais da cada fator sobre as medidas.

Com isto, estudos adicionais são necessários para identificar estes efeitos.

Os levantamentos geoquímicos e estudos de pesquisa documentam que o caminho de migração dos hidrocarbonetos é predominantemente vertical.

Contudo, a presença da falha que se forma no limite desta com a fronteira ao sul do reservatório de gás, sugere a causa de uma migração do gás, que pode ter escapado lateralmente por estes limites.

Isto implica que as dispersões presentes nos dados possam estar associadas tanto a uma migração vertical, quanto a uma migração lateral de escape do gás.

Procurou-se avaliar nas análises algum comportamento das amostras de gases comparativamente entre as duas inspeções, com o objetivo de identificar a existência de algum padrão ou classes de padrões associados aos dados.

A seguir, construiu-se modelos de previsões utilizando métodos de inteligência computacional, tais como as redes neurais artificiais, as árvores de decisão e o aprendizado bayesiano.

Os modelos construídos mostraram resultados bastante satisfatórios, com índices de acertos e performance elevados.

Estes modelos de previsões foram construídos com o objetivo de identificar as anomalias presentes no reservatório e para posterior confirmação das análises geoestatísticas e geoquímicas previamente realizadas.

Observou-se com isto, que o modelo da rede neural e da árvore de decisão apresentaram-se como ferramentas de exploração necessárias para o mapeamento das fronteiras do reservatório.

Enquanto que, o modelo construído para o aprendizado se mostrou menos eficiente.

Este determinou apenas a probabilidade de ocorrência das amostras de gases estarem mais nas posições acima ou fora do reservatório.

A construção do modelo neural foi a que consumiu a maior parte do tempo da pesquisa em função de ser considerado um modelo com base em tentativas e convergência do erro.

Assim, várias redes foram construídas durante a fase de pesquisa, bem como, foram ajustados parâmetros como, taxas de treinamento, funções de ativação, até conseguir os resultados satisfatórios.

Mostrou-se um método eficiente, mas implícito para a determinação das anomalias.

A construção deste modelo foi bastante simples e rápida.

Nos resultados obtidos na construção deste modelo, observou-se que, no que se refere a determinação das fronteiras do reservatório, os resultados foram excelentes, visivelmente mostrados e confirmados com a geoquímica de superfície.

A árvore de decisão é considerado o método de classificação mais explícito e de fácil construção.

No modelo do aprendizado utilizou-se todos os 102 registros.

Entretanto, deste total foram separados 90 registros para treinamento, equivalente a 80% dos dados e 12 registros para teste, correspondente a 20% dos dados.

Pode-se observar, que diferentemente dos outros modelos construídos, foram separados porcentagens diferentes dos dados de treinamento e teste.

Isto porque este método, mostrou-se o menos eficiente a 70% dos dados de treinamento.

O trabalho de pesquisa realizado engloba características importantes de reservatórios de petróleo para as instituições petrolíferas.

Por este motivo, houve uma grande dificuldade na busca de informações e de dados que fossem utilizados no presente trabalho.

Acredita-se que em razão do segmento a que se destina o petróleo, a confidencialidade dos dados seja um dos requisitos mais importantes para estas empresas, uma vez que tais trabalhos devam ser de acesso restrito.

Com isto, encontrar dados disponíveis e que fossem utilizados nesta dissertação foi um grande problema, o que dificultou bastante as avaliações e principalmente a criatividade no desenvolvimento das análises e da modelagem.

A base de dados disponível também se mostrou pequena para a realização da pesquisa.

Em vista da proposta da dissertação, que era de aplicar as metodologias de mineração de dados para a determinação das fronteiras do reservatório, era necessário um banco de dados maior, para que fosse possível a utilização das outras metodologias de MD.

A análise dos outliers também não apresentou resultados satisfatórios.

Esta etapa tomou grande parte do tempo no presente trabalho.

E apesar dos registros parecerem ser valores espúrios em função da aparente divergência com os demais, estes foram conferidos e checados por métodos específicos e verificados que correspondiam efetivamente a massa de dados.

Há portanto, a necessidade de se aprofundar nas causas que levaram a se ter dados com estas características.

Em termos de trabalhos futuros, existem muitos estudos ainda que poderíam ser realizados, pois o problema mostrou-se muito mais complexo do que podería parecer.

Abaixo é mostrado algumas sugestões para uma continuidade da pesquisa desenvolvida.

Análise multivariável, realizar estudos da variabilidade das amostras de gases através das comparações das médias das variâncias no espaço temporal, em que poderíam ser identificados os efeitos dos fatores ambientais que podem alterar significativamente as medidas.

Implementação do programa,implementar um programa em qualquer linguagem que podería oferecer uma maior flexibilidade em modificar o algorítmo para uma melhor aplicação à casos específicos dos métodos utilizados.

Estudos adicionais, que confirmem a migração de escape dos hidrocarbonetos lateralmente pelos limites da falha presente no reservatório com a fronteira ao sul.

