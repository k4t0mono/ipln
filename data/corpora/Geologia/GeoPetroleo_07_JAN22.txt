A geometria fractal vem sendo utilizada cada vez com maior freqüência para caracterizar e descrever os fenômenos geológicos.

A sua aplicação se estende desde o ponto de vista microscópico, como análise de lâminas delgadas de rochas, estudos de percolação de fluidos e estudos de características de sedimentação, até o entendimento de processos macroscópicos, como distribuição de padrões de fraturamento para análises tectônicas ou então geração de distribuições de propriedades petrofísicas para estudos de fluxo de fluidos em meios porosos.

Este último tópico é o tema principal desta tese.

Estudamos as principais propriedades de famílias de funções conhecidas por movimento Browniano fractal (mBf) e ruido Gaussiano fractal (rGf), com vistas à sua utilização para o modelamento de perfis elétricos, acústicos e radioativos de poços, determinando as características destas distribuições a partir da técnica estatística da análise R/S, que fornece o parâmetro H, expoente de Hurst, que caracteriza a intermitência destes processos.

Com o valor de H realizamos interpolações estocásticas de propriedades de rochas, estimando valores em pontos não amostrados, que respeitam as características estruturais expressas nos perfis dos pontos amostrados pelos poços.

A malha pode ser refinada para atender às necessidades da simulação de fluxo.

O algoritmo utilizado para este fim é uma modificação do processo de adições sucessivas aleatórias, com a particularidade de condicionar a simulação estocástica aos dados disponíveis.

Em seu estágio atual, o algoritmo realiza uma simulação 2-D.

Concluímos que as distribuições fractais têm aplicabilidade nos estudos de reservatórios de petróleo e que as técnicas da análise R/S e da simulação estocástica via adições sucessivas aleatórias modificado, em combinação com técnicas geoestatísticas como a variografia e a krigagem, são ferramentas de grande utilidade para a caracterização de propriedades geológicas na escala de simulação de fluxo.

A tese está organizada como segue.

O primeiro capítulo aborda os principais conceitos de fractais, os métodos de medida da dimensão fractal e algumas aplicações mais recentes na área das geociências.

O segundo capítulo trata das propriedades das famílias de funções mBf e rGf.

O terceiro capítulo estuda os processos dinâmicos e, em particular, a equação logística, para a calibração da análise R/S, cujas características constituem o tema central do capítulo quarto, que também mostra sua aplicação aos perfis elétricos de poços.

No capítulo cinco são apresentados os conceitos de interpolação por krigagem e por simulação estocástica, com sua aplicação para gerar parâmetros petrofísicos em pontos não amostrados dos reservatórios.

O termo fractal foi introduzido por Mandelbrot em 1975, para designar uma nova geometria de formas fracionárias, comumente encontradas na natureza, cuja descrição pela geometria euclidiana tradicional não mostrava resultados satisfatórios.

As aplicações práticas nas áreas das geociências são freqüentes, como por exemplo, a medida do litoral de países ou continentes, a extensão de rios e redes de drenagem, a caracterização de superfícies topográficas, a representação de cadeias de montanhas, para citar aspectos macroscópicos, ou então, a caracterização de meios porosos, percolação de fluidos e outras aplicações no âmbito microscópico.

Para estudos geológicos de reservatórios de petróleo, um dos problemas de mais difícil solução é a transferência de informações entre as diversas escalas de trabalho.

A teoria dos fractais pode vir a contribuir para a descrição e o entendimento destes fenômenos, uma vez que dispõe de ferramentas para estudar as relações geométricas em diferentes escalas de observação.

Através delas pode-se entender melhor como o comportamento de um processo na escala microscópica pode influenciar no comportamento macroscópico.

O entendimento humano a respeito dos fenômenos naturais é feito a partir de modelos teóricos, que devem levar em consideração a geometria de partículas que variam de tamanho desde a escala subatômica até a escala do universo.

Em cada campo da ciência houve a tendência a desenvolver conceitos adaptados e utilizados de forma intuitiva e corriqueira por seus pesquisadores.

Os conceitos da geometria euclidiana como linhas, círculos, esferas e tetraedros, constituíram uma primeira aproximação para o problema.

A definição de fractal é muito controversa.

Apresenta a seguinte definição.

Fractal é um conjunto para o qual a dimensão de Hausdorff-Besícovitch é maior que a dimensão topológica.

Como esta conceituação envolve a definição prévia de conjunto e das dimensões topológica e de Hausdorf-Besicovitch, que por sua vez encerram certo formalismo matemático, foi proposta uma definição mais simples e de mais fácil comprovação experimental.

Um fractal é uma forma constituída por partes similares ao todo de alguma maneira.

Um fractal conserva atributos morfológicos em qualquer escala de observação, ou seja, o fractal deve apresentar invariância por escala, o que constitui uma propriedade de grande utilidade, em particular em estudos de processos naturais e fenômenos geológicos.

Para considerar uma distribuição de freqüência de tamanhos como fractal, requer-se que o número de objetos maiores que um determinado tamanho característico (escala) tenha uma dependência segundo uma lei de potência com o tamanho (escala).

Vários modelos de distribuições estatísticas são utilizados para descrever os fenômenos geológicos, entre os quais o normal e o lognormal, amparado por teorema de limite central, para o caso de eventos estatisticamente independentes.

As distribuições de lei de potência, entretanto, são as únicas que não possuem um tamanho característico, o que permite sua utilização em fenômenos invariantes por escala.

Esta invariância prove a base racional para a sua aplicabilidade.

Todas as formas conhecidas da natureza apresentam um tamanho característico, como por exemplo, uma esfera é caracterizada pelo seu raio e uma pessoa pela sua altura.

As formas artificiais também podem ser aproximadas normalmente por tamanhos característicos como, por exemplo, o pneu de um automóvel representado pela medida de seu aro.

Os objetos que apresentam tamanho característico via de regra têm contornos suaves, o que permite sua representação por meio de figuras geométricas simples.

Quando a rugosidade da forma geométrica aumenta progressivamente, é cada vez mais difícil representá-la por meio de uma ou poucas figuras geométricas simples combinadas.

Há a necessidade de se introduzirem novos conceitos de tamanho característico para poder representar estas formas.

Como exemplo, temos as nuvens que, por sua complexidade, dificilmente serão bem representadas por figuras geométricas simples.

Uma conseqüência importante do fato de as formas com tamanho característico serem suaves é que elas não perdem as propriedades para suavizações em escalas menores que este tamanho.

Com isto, pode-se aplicar o cálculo diferencia! nestas formas.

Já no caso de fractais não se pode traçar uma tangente à sua curva, porque a rugosidade está presente até em escalas infinitesimais.

Por isto, nenhuma forma fractal pode ser diferenciável, uma vez que a invariância por escala assegura que as irregularidades em escala macroscópica são reproduzidas em qualquer escala menor.

Podemos incorrer em erros grosseiros ao provocar a suavização em uma determinada escala, negligenciando as escalas menores e aplicando o cálculo diferencial.

A invariância por escala é caracterizada por novas medidas denominadas dimensões fractais.

Dentre elas, a mais freqüentemente usada é a dimensão de Hausdorff.

O nosso conceito intuitivo de dimensão é o de que ela toma valores numéricos inteiros, que coincidem com os graus de liberdade, definidos pelo número de variáveis independentes do sistema.

O espaço euclidiano especifica-se por esse tipo de dimensão.

Assim, uma linha é um espaço unidimensional, onde um ponto é representado por um único valor real.

Um plano é um espaço bidimensional, onde um ponto é representado por dois valores reais.

A dimensão definida de acordo com os graus de liberdade pode, no entanto, conduzir a erros.

Um exemplo é a estranha curva, conhecida como de Peano, desenhada sem levantar a ponta do lápis e que preenche totalmente um plano.

Um ponto nesta curva, como em qualquer curva, pode ser caracterizado por um valor real.

Portanto, como a curva de Peano preenche o plano, um ponto no plano também pode ser representado por um valor real, fato que contradiz a definição empírica, dada por dois valores reais.

O conceito de dimensão deve ser revisto, recebendo uma nova definição, para englobar o conceito de similaridade.

Se tomarmos uma forma geométrica e a dividirmos em aD pedaços similares de tamanho 1/a, podemos dizer que o expoente D corresponde à dimensão, que recebe o nome de dimensão de similaridade.

Sua feição mais interessante é a de que não necessariamente ela é um número inteiro.

Neste caso D passa a ser uma dimensão fractal.

Se tivermos b formas similares de tamanho 1/a, então a dimensão de similaridade (Ds).

A dimensão de similaridade pode ser interpretada como um índice de complexidade da forma geométrica, no sentido de que as dimensões maiores descrevem formas mais complexas que as dimensões menores.

Um inconveniente da dimensão Ds é que ela só é definida para objetos que possuam similaridade em senso estrito, o que nem sempre se verifica para as formas encontradas na natureza.

Este contratempo pode ser superado com a definição de uma generalização da dimensão acima, conhecida por dimensão de Hausdorff, em homenagem a este estudioso, do início do século.

A dimensão de Hausderf DH é obtida quando a medida dada é zero.

Pode-se provar que ela é única e definida para qualquer tipo de fractal.

O cálculo rigoroso desta dimensão é geralmente muito difícil.

Outra dimensão baseada no mesmo princípio da anterior, porém com aplicabilidade prática maior, é a dimensão de capacidade (Dc).

Em casos práticos da física, entretanto, as duas dimensões acima estão definidas para r-0, o que implica em comprimento igual a zero, que não representa um conceito físico segundo o princípio da incerteza.

Isto provoca um limite inferior no conceito de dimensão.

Por outro lado, para cada problema físico há um limite superior acima do qual a invariância por escala não se mantém, tendo-se que adaptar o conceito de dimensão para este fato.

Estes limites inferior e superior são importantes porque servem como restritores e podem impedir que as grandezas físicas medidas neste intervalo sejam divergentes.

As dimensões obtidas por diferentes métodos de medida podem não ser exatamente iguais.

Para manter o rigor, devemos distinguir cada dimensão com seu nome.

Na maioria dos problemas envolvendo objetos naturais, sabe-se que as diferenças entre as medidas são pequenas quando comparadas ao erro de observação.

Devido a isto,podemos designar a dimensão fractal genericamente, sem distinção do método de medição, entendendo-se por dimensão fractal toda dimensão que pode tomar valores fracionários.

Vários métodos práticos para estimar a dimensão fractal foram desenvolvidos, podendo ser agrupados em pelo menos cinco categorias distintas.

Contagem de caixas.

Utilização das relações de medida fractal.

Utilização da função de correlação.

Utilização da função distribuição de probabilidade.

Utilização do espectro de freqüência.

Este método consiste em aproximar uma forma fractal a partir de formas geométricas com medida característica bem definida, como por exemplo, círculos, quadrados ou células.

Para cada tipo de problema a técnica de medição é diferente.

Assim, para formas do tipo linha de costa, definimos um tamanho de raio r e,a partir de uma extremidade, recobrimo-la com círculos de raio r.

Cada interseção do círculo com a linha será o novo ponto de centro contando-se o número total de segmentos necessários para o recobrimento.

Aproximação da medida de para o segmento de reta seguinte.

Fazem-se unha por segmentos que correspondem ao raio dos círculos,várias medições, mudando-se o comprimento.

Para situações onde o número de segmentos obedece è relação.

Definimos D como sendo a dimensão fractal da linha.

Esta técnica é usualmente empregada para medir linhas de costa ou gráficos de trajetórias aleatórias.

Uma variante deste método, com maior aplicabilidade e facilidade computacional, consiste em dividir um certo espaço em quadrados ou cubos de lado r e então contar o número de quadrados ou cubos que contém pelo menos um ponto do objeto a ser medido.

Novamente são efetuadas várias medições variando-se o tamanho de r, de forma que a relação deva ser satisfeita para que D represente uma dimensão fractal.

Esta técnica pode ser utilizada em medidas de figuras complicadas como rios com muitos canais distributários ou imagens microscópicas.

Outra extensão da técnica é a medição da dimensão de informação, especialmente destinada a distribuições estocásticas de pontos.

Como acima, o espaço é dividido em formas geométricas de tamanho característico r, medindo-se a probabilidade P,(r) de um ponto escolhido ao acaso estar contido na célula i.

Nos objetos geométricos não fractais observa-se uma relação entre o comprimento do lado (L), área superficial (A) e volume (V), de modo que, caso multipliquemos o comprimento por um fator k, a Ain e o V1'3 também se multiplicam pelo mesmo fator.

Para o caso de termos uma quantidade U que incrementa em 2D vezes quando multiplicamos o seu comprimento por 2, podemos dizer que ela é D-dimensional.

A principal dificuldade para este método é a escolha do centro da esfera.

Uma vez que o cálculo de valores médios a partir de mudanças na posição do centro, bem como, a própria escolha do tipo de média podem conduzir a resultados diferentes, recomenda-se posicionar o centro da esfera no centro de massa da distribuição.

Para distribuições com caráter fractal a função de autocorrelação segue uma lei de potência, sem ter medida característica, com a correlação diminuindo com o aumento da distância r segundo uma taxa constante.

Nos casos onde se observa a proporcionalidade podemos dizer que a autocorrelação diminui de um fator 2 quando a distância aumenta 2 vezes.

Admitimos que P[X > rj] seja a probabilidade de um objeto ter tamanho maior que um valor r.

Esta probabilidade está associada com a função densidade de probabilidade.

Quando provocamos uma mudança de escala, transformamos r para b.

O caráter fractal da distribuição estabelece a invariância por escala para qualquer valor positivo b.

O expoente D pode ser considerado como sendo a dimensão fractal nos casos em que r representa uma medida unidimensional (comprimento).

Em outras situações, D é apenas um parâmetro que caracteriza a distribuição.

Podemos obter um espectro de freqüência ao estudar as feições estatísticas de processos aleatórios espaciais ou temporais.

Caso o caráter apresentado seja fractal, podemos determinar a sua dimensão.

Em analogia com o método, quando mudamos o limite superior de freqüência de observação, o qual indica as freqüências desprezadas acima de uma freqüência critica (fc), o espectro do sinal fractal deve permanecer invariante.

Além das dimensões fractais citadas anteriormente (similaridade, Hausdorff, capacidade e informação), podem ser definidas outras dimensões fractais, algumas com aplicabilidade restrita.

Para definir lq supomos um conjunto de pontos distribuídos aleatoriamente em um espaço d-dimensional, dividindo-se este espaço em cubos de aresta r.

Definindo Pé como sendo a probabilidade de um ponto pertencer ao cubo i e assumindo arbitrariamente um número positivo q.

Para o caso particular de q = 1, a expressão reproduz a entropia clássica de Shanon.

Esta generalização da dimensão de informação vem sendo muito estudada em distribuições do tipo multifractal.

Várias equações diferenciais de primeira ordem não-lineares apresentam soluções que não convergem para um ponto fixo no limite.

A solução pode se manter em uma região de tamanho finito, cuja órbita é chamada de atratos.

Quando possuem aspectos de auto-similaridade, estes atratores são fractais.

Podemos calcular a dimensão fractal através dos métodos expostos, como por exemplo o de contagem de caixas, porém não se encontrou ainda uma fórmula para calcular diretamente a dimensão fractal de um sistema dinâmico.

Uma fórmula indireta para a determinação da dimensão é por meio dos expoentes de Lyapunov(se tivermos dois pontos alinhados segundo uma direção a separados pela distância no tempo t no tempo t+r, então podemos definir o expoente de Lyapunov).

Valores positivos úeA indicam que os pontos estão se separando exponenciaímente e valores negativos indicam aproximação exponencial.

O subscrito a representa a direção e precisamos de um valor de a para cada grau de liberdade.

Para um espaço d-dimensional, precisamos de j expoentes de Lyapunov de modo que a dimensão fractal seja onde o subscrito j é o menor número inteiro que torna A negativo.

Esta dimensão fractal é conhecida como dimensão de Lyapunov ou Kaplan-Yorke e, de modo geral, coincide com a dimensão de informação.

O movimento aleatório de partículas em estruturas fractais apresenta várias propriedades que ainda não haviam sido encontradas no espaço euclidiano.

Estas novas propriedades são caracterizadas também por uma nova quantidade denominada dimensão fractal espectral.

Podemos definir esta dimensão a partir da relação do valor esperado da distância média quadrática (R) a partir da origem após um número N de passos.

Para o espaço euclidiano, a relação se reduz ao caso particular do movimento browniano.

Para estruturas fractais, os valores de D são fracionários e diferentes de D, resultando no comportamento anômalo do movimento aleatório em fractais.

Esta dimensão espectral controla o número total de pontos distintos visitados durante o movimento, bem como a probabilidade de voltar à origem após percorrer N passos.

Situações mais complexas podem acontecer quando a relação é divergente, porém estão fora do escopo desta tese.

Outra definição mais apropriada para utilização computacional é a que calcula o passo de tempo T(x) no qual uma partícula, partindo da origem, atinge a distância x pela primeira vez.

O nome espectral é proveniente de uma propriedade de materiais elásticos com estrutura fractal.

Para pequenas oscilações em torno da posição de equilíbrio destes materiais, a densidade espectral p(w) da oscilação é uma função da freqüência w segundo a lei de potência.

Uma vez que D controla o espectro de oscilações da estrutura fractal, recebe o nome de dimensão fractal espectral.

Esta dimensão, também denominada por dimensão de conectividade, caracteriza o número de ligações conectadas entre dois pontos distintos, tendo grande aplicação em fenômenos elétricos.

Neste tipo de problemas, fisicamente é mais interessante medir a distância entre dois pontos pelo número de ligações que um elétron deve percorrer para sair de um ponto a outro, do que simplesmente medir a distância pela raiz quadrada da soma dos quadrados das coordenadas cartesianas.

A dimensão de espalhamento (D) não é limitada pelo espaço euclidiano em que a estrutura está contida, podendo ser maior que 2 para um plano, e aumentar indefinidamente para um grande número de ligações em d.

Muito embora a dimensão fractal seja a medida básica para a representação de formas auto-similares e fenômenos naturais, nem sempre é possível descrever as formas mais complicadas através de um único número.

Faz-se necessário ampliar o conceito de dimensão fractal, podendo-se abordar o problema de duas formas distintas.

Generalização da dimensão fractal para torná-la dependente da escala de observação.

Introdução de novas medidas que descrevam as flutuações espaciais da dimensão fractal.

No primeiro caso é possível definir uma dimensão fractal a partir de um comprimento, impondo limites superior e inferior na escala de observação.

Para o segundo, estaremos trabalhando com objetos cuja dimensão fractal varia em cada parte do mesmo, passando-se intuitivamente para o conceito de multifractal.

A teoria dos multifractais foi desenvolvida para analisar formas com mais de um tamanho característico.

A sua grande generalidade, semelhante à da termodinâmica, é a principal vantagem na sua aplicação para descrever os fenômenos naturais.

Em termos simples, a generalização de dimensão fractal para medida multifractal envolve a passagem de um número finito para um número infinito de dimensões, que podem inclusive ser negativas.

Muitos multifractais podem ser construídos a partir da repetição iterativa de dois ou mais geradores, resultando em um fractal não-uniforme , cuja dimensão é representada pela função f(a) ou pela dimensão de informação de ordem q (Dq).

As duas grandezas estão relacionadas por uma transformada de Legendre.

Desta maneira, garante-se que existe uma função o(q) definida para cada valor de q, que permite substituir a equação por um único fractal geométrico auto-simiiar de dimensão onde as dimensões generalizadas são dadas.

A forma fractal não-uniforme pode ser aproximada por um fractal uniforme diferente, de acordo com cada valor diferente de q.

Este valor de q representa a inclinação (derivada) da curva f(a) em um gráfico f(a) vs a.

A interpretação geométrica de Dq também pode ser visualizada na figura.

Neste item serão apresentados três exemplos clássicos de formas geométricas fractais, que por sua simplicidade na geração e na medida da dimensão, fornecem uma boa base para o entendimento destes conceitos.

Consideremos um segmento de reta de comprimento unitário [0,1] o qual será dividido em três partes iguais, retirando-se em seguida o terço central.

Em sucessivas iterações, continua-se o processo de dividir os segmentos restantes em três partes e retirar o terço central.

Após um numero infinito de iterações teremos produzido a poeira de Cantor.

Em termos matemáticos, a poeira representa um conjunto completo, porém, sem densidade.

Em outras palavras, cada ponto limite deste conjunto pertence ao conjunto e, em qualquer subconjunto de [0,1] sempre haverá pelo menos um subintervalo que não contém nenhuma parte do conjunto.

A filosofia de geração deste fractal é semelhante à do caso anterior, podendo ser considerado uma extensão da poeira de Cantor para duas ou mais dimensões.

Para o caso I bidimensional, tomamos uma figura geométrica qualquer como gerador, neste exemplo,um triângulo totalmente preenchido.

Divide-se internamente este triângulo sierpinski em 4 menores de igual tamanho, retirando-se o triângulo central.

O processo é repetido recursivamente em infinitas iterações sobre os triângulos preenchidos restantes.

Em cada aplicação, um triângulo preenchido é substituído por 3 novos, com uma mudança de escala com fator igual a 1/2.

Desta forma, pela equação temos a dimensão fractal.

É interessante notar que a área visível deste fractal tende a zero ao passo que o perímetro dos buracos tende a infinito.

Esta constitui um dos exemplos mais ilustrativos de que uma curva pode ter dimensão fracionária.

O ponto de partida é um segmento de reta de comprimento unitário, que também, pode ser substituído por um polígono qualquer com aresta unitária.

O processo iterativo se faz pela substituição de cada segmento do passo anterior por quatro novos de comprimento igual a 1/3 do comprimento anterior.

Os fractais têm sido utilizados para descrever vários fenômenos geológicos, que incluem desde aspectos macroscópicos como estudos sismológicos, tectônicos e geomorfológicos, como também aspectos meso-e microscópicos, como correlação entre rochas, sedimentologia e análise de meios porosos.

A seguir serão descritas algumas aplicações encontradas na literatura.

O comprimento de um litoral é calculado multiplicando-se uma medida unitária r peto número de segmentos N(r) necessários para fazer o recobrimento da costa.

Tomam-se vários valores diferentes de r, obtendo-se distintos N(r).

Estes ciados são plotados em um gráfico log-log de r vs N(r), resultando em um alinhamento cujo gradiente 6 esta relacionado com a dimensão fractal por 0=1-D.

Os valores da dimensão fractal reportados por vários autores situam-se entre 1 < D < 1,4 com média de 1,2.

Constatou-se que quanto maior o número D, mais acidentado é o litoral.

Aplicando-se o procedimento descrito a um círculo, observa-se que o gráfico log-log de r vs N(r) não é linear, provando que formas com comprimento característico nunca produzem retas em gráficos.

Se considerarmos a linha do litoral como sendo um corte praticado na superfície da Terra, ou seja, um corte efetuado em seu relevo, constituído por montanhas e vales, podemos estimar a dimensão fractal deste relevo a partir da dimensão da costa, adicionando-se 1 ao valor de D.

Portanto, a dimensão fractal média do relevo terrestre situa-se em 2,2, valor consistente com medidas realizadas diretamente.

Reconhece várias propriedades fractais em sistemas de drenagem.

Uma relação bem conhecida entre o comprimento do canal principal (L) e a área de drenagem (A) da bacia hidrográfica é dada pela lei de Hack.

Visão esquematica de uma bacia hidrográfica, mostrando o canal principal de comprimento L e a area de drenagem A.

O expoente ir foi relacionado com a dimens o fractal, obtendo-se D = 2.

Os resultados estudando rios da Virgínia e Maryland apontam para valores de a = 0,6, fornecendo D = 1,2.

De modo geral, a dimensão fractal para o canal principal situa-se entre 1,1 ^ D ^ 1,3.

Entretanto, mantém restrições quanto ao aspecto de similaridade entre as diversas bacias hidrográficas pois, de acordo com observações, estas bacias mudam de forma no sentido de jusante, tornando-se mais longas e estreitas.

Por outro lado, as bacias maiores são mais alongadas, ao passo que as menores são mais ovaladas.

Estas características podem suprimir o caráter fractal dos rios.

A forma do sistema fluvial também pode ser interpretada como fractal.

Um exemplo clássico é a do rio Amazonas , cuja dimensão fractal obtida pelo método de contagem de caixas é de 1,85.

Para o rio Nilo, reporta-se na literatura o valor 1,4.

Estes números demonstram haver uma relação entre a dimensão fractal e o regime pluviométrico, tendo-se maiores valores para regimes de chuvas mais contínuos, nos quais, para manter o equilíbrio do sistema, a drenagem deve ser quase imediata, o que implica em maior cobertura do rio e seus afluentes, aumentando o valor da dimensão.

Os terremotos constituem outra área com aplicações para a geometria fractal.

A distribuição espacial dos terremotos é localizada em alguns agrupamentos na crosta terrestre.

Embora o erro cometido na determinação da dimensão fractal destes agrupamentos possa ser grande, reportam-se valores na faixa de 1,2 a 1,6.

A distribuição de freqüência do número de terremotos secundários (N(t)) associados com o de maior intensidade segue uma lei de potência conhecida como fórmula de Omori.

Uma grande quantidade de processos geológicos estão relacionados com o fenômeno de fragmentação.

Citam-se os processos tectônicos, envolvendo falhamentos e fraturamentos, os mecanismos de intemperismo das rochas e os processos explosivos, como vulcanismo e ação do homem.

Admite-se que a distribuição dos falhamentos na crosta terrestre é fractal e cada sistema de falhas apresenta características próprias com relação aos abalos sísmicos.

Embora as distribuições de freqüência e tamanho das falhas seja fractal, não podemos concluir que a dimensão fractal das falhas seja igual à dos terremotos.

Esta hipótese implica que o intervalo de tempo entre abalos consecutivos seja independente da escala, o que não é observado na prática.

De modo geral, o intervalo de tempo entre dois terremotos é maior para os falhamentos menores.

Um modelo teórico simples para fragmentação, baseado no mesmo princípio do conjunto de Cantor.

A cada iteração do processo, dois blocos diagonalmente opostos são fraturados e os outros são mantidos intactos, gerando um fractal de dimensão D=2,60.

Fizeram um levantamento estatístico da distribuição de juntas e fraturas em rochas do embasamento de Yucca Mountain, Nevada.

Calculando a dimensão fractal, obtiveram D = 1,7 em duas dimensões.

A estimativa de reservas de bens minerais é feita com base em estudos estatísticos, com o objetivo de determinar a quantidade de minério explotável acima de um determinado teor crítico, específico para cada tipo de minério.

Estas estimativas são realizadas tanto em caráter regional como local.

Vários autores sugerem haver uma relação linear entre o logaritmo da tonelagem de minério acima do teor crítico e o logaritmo do teor, sendo esta relação fractal.

Para garantir o caráter fractal desta relação, é necessário que o mecanismo de concentração do minério seja invariante por escala.

Embora alguns destes mecanismos já estejam exaustivamente estudados, a complexidade dos fenômenos não está ainda totalmente compreendida, não permitindo a formulação de modelos quantitativos adequados.

Em vários exemplos com minérios , observam-se valores de dimensão fractal que vão de 2,01 para depósitos de mercúrio a 1,16 para minério de cobre nos Estados Unidos, o que demonstra existirem diferentes processos invariantes por escala responsáveis pela concentração dos diversos minerais.

Acredita-se também que a distribuição dos campos de petróleo obedeça à geometria fractal.

Estudos realizados no Golfo do México, reportam valores de dimensão fractal para distribuições de volumes de óleo da ordem de 2,22.

Há grande diferença em medidas que podem ser atribuídas às características geológicas regionais diferentes ou à controvérsia na delimitação dos campos e de suas reservas petrolíferas.

As análises petrofísicas fornecem parâmetros importantes para o estudo de reservatórios de petróleo.

O caráter fractal das rochas porosas faz com que o estudo da dimensão contribua para a determinação dos parâmetros.

Um dos trabalhos pioneiros foi realizado e estudaram superfícies fraturadas em arenitos, usando imagens de microscopia eletrônica.

As fotos são convertidas em imagens bimodais onde as cores claras representam o espaço poroso e as escuras os grãos.

Cada contraste claro/escuro constitui uma feição e calcuia-se a dimensão fractal a partir de um plot log-log do número de feições vs deslocamento unitário.

A dimensão fractal obtida pelos autores acima varia entre 2,57 e 2,87.

Estudaram a topografia de afloramentos de rochas cristalinas e sedimentares em escalas variando de 10 a 1m.

Estes autores utilizam funções aleatórias do tipo movimento browniano fractal ou funções de Weierstrass-Mandelbrot para o modelamento das superfícies.

Fazem contagem do número de moléculas adsorvidas para cobrir uma superfície porosa, utilizando vários tamanhos de molécula para introduzir o fator de escala.

Usam a técnica de espalhamento de pequeno ângulo (small-angle scattering,SAS) de neutrons termais em amostras de arenitos, folhelhos e carbonates, observando características fractais nos dois primeiros, que chegam a dimensões de 2,96.

Já para os carbonatos, o ajuste no plot bilogaritmo não foi bom, o que levou os autores a considerar estas rochas como rugosas, porém não como fractais.

Uma aplicação mais prática da dimensão fractal foi dada, relacionando a porosidade das rochas com a dimensão fractal.

A avaliação quantitativa da saturação de fluidos no espaço poroso das rochas foi estabelecida com sua lei,onde Sw é a saturação de água, a constante =1 na proposta original, Rw resistividade da água que impregna a rocha, # porosidade, m o expoente de cimentação e Rj a resistivídade da rocha.

Os parâmetros a e m são determinados a partir de ensaios de laboratório, onde se mede a resistivídade RQ de amostras de rocha impregnadas de água com as características da água de formação e o parâmetro n em testes de impregnação progressiva com petróleo da amostra saturada por água, medindo-se sua resistivídade.

Tomam-se valores para satisfazer ao ajuste gráfico de linhas retas, embora estes valores violem a definição das grandezas.

Propuseram uma generalização da lei de Archie, interpretando os dados acima como "crossover" entre distintos regimes fractais, entre sistemas de porosidade efetiva e sistemas com microporosidade, que afetam as medidas de resistivídade tanto em ensaios de laboratório como os próprios perfis elétricos nas medições de poços.

Com a adoção de valores adequados do expoente de cimentação para cada regime e do expoente de saturação nos correspondentes intervalos de porosidade, esta generalização da lei de Archie fornece valores mais confiáveis de saturação de fluidos, sem precisar impor artifícios matemáticos para o valor de a.

Estudos recentes de digitação viscosa ("viscous fingering") utilizando modelos de geometria fractal de percolação de fluidos estão ganhando importância cada vez maior em reservatórios de hidrocarbonetos, uma vez que os métodos de recuperação secundária de petróleo através de injeção de água estão sendo continuamente mais utilizados para melhorar o índice de recuperação de óleo das jazidas.

Os ensaios de laboratório, usando duas placas de vidro , uma lisa e outra rugosa, mostram caráter fractal no deslocamento de glicerina por óleo, que pode ser reproduzido por simulação em computador.

O padrão de deslocamento mostra uma dimensão fractal da ordem de D = 1,72.

O sistema água/óleo produz padrões similares aos do teste.

Os perfis elétricos são uma das principais ferramentas de trabalho em estudos de reservatórios de hidrocarbonetos.

Por serem corridos praticamente em todos os poços e por apresentarem vários princípios físicos, geram a medição de diferentes propriedades como, por exemplo, a porosidade, o conteúdo de argila, a saturação de água, entre outras.

O caráter fractal destes registros tem chamado a atenção de pesquisadores.

Hewett foi um precursor ao adaptar o formalismo, interpretando as curvas de perfis como funções de ruído Gaussiano fractal e movimento Browniano fractal.

A aplicabilidade da dimensão fractal, obtida a partir do expoente de Hurst H=2-D, vai até a interpolação de propriedades entre poços, através de técnicas geoestatístícas.

A abordagem heurística é seguida nesta tese, onde estudamos os procedimentos na intenção de entender e melhorar o processo.

O conceito de multifractal é também abordado para quantificação e modelamento de heterogeneidades de rochas reservatório, utilizando perfis de dipmeter.

As pesquisas ainda estão em andamento, mas os autores acreditam ser possível identificar diferentes tipos litológicos com a análise multifractal das curvas de microrresistividade.

Nos fenômenos naturais, o acaso tem grande importância para a caracterização dos processos, o que implica em uma necessidade prática em relacionar aleatoriedade com fractais.

De um modo geral, o poder do acaso é subestimado na caracterização dos processos naturais.

Em uma conceituação física ingênua, os efeitos da aleatoriedade são mais manifestos no plano microscópico, podendo ser insignificantes no macroscópico.

No caso de fractais aleatórios, o acaso mantém sua importância de forma constante em todas as escalas de observação.

Por fractal aleatório entende-se todo o fractal gerado por regras não-determinísticas.

Como exemplo, podemos gerar um fractal determinístico ao eliminar a quarta parte superior de um quadrado, iterando o processo sucessivas vezes.

Se repetirmos o processo, só que escolhendo ao acaso a quarta parte a ser eliminada, o fractal gerado será estocástico, podendo a figura ser uma imagem possível.

É fácil verificar que os aspectos geométricos diferentes, porém a dimensão fractal deles é a mesma, por construção.

Existem, também descritas, funções fractais aleatórias.

Uma destas, estudada m extensivamente, é o processo de difusão conhecido por movimento browniano ou aleatório, com sua generalização para movimento browniano fractal.

O movimento browniano foi observado, e constatou experimentalmente o fato de o movimento aleatório apresentado por partículas microscópicas de pólen ter origem em causas puramente físicas e não biológicas como era acreditado até então.

As partículas subatômicas, átomos, moléculas e demais componentes da natureza encontram-se em constante movimentação devido a flutuações térmicas (energia térmica), apresentando colisões aleatórias de seus componentes.

Em uma resolução microscópica, podemos entender o movimento browniano como sendo constituído por deslocamento de uma partícula através de passos segundo uma direção aleatória, com comprimento característico.

É importante observar que, em um movimento browniano, a posição de uma partícula não é independente de sua posição no instante anterior, mas sim, o deslocamento da partícula em um dado instante de tempo é independente do deslocamento da mesma partícula em outro intervalo de tempo.

O movimento browniano é auto-similar, no sentido de que o caminho aleatório em uma escala de observação é semelhante ao apresentado em outra escala maior ou menor.

Já para o caso de admitirmos o tempo como uma dimensão adicional, no caso a posição da partícula em função do tempo, também chamada por registro do movimento, o fractal passa a ser auto-afim, uma vez que os fatores de multiplicação da escala de tempo diferem dos fatores da escala de observação.

Para melhor entendimento dos fundamentos matemáticos envolvidos, vamos adotar a argumentação, baseada em conceitos termodinâmicos.

Para o caso unidimensional de movimento ao longo de um eixo, consideramos uma partícula realizando deslocamentos de tamanho microscópico positivos ou negativos, a cada tempo t.

Podemos também impor a condição de que os deslocamentos não se realizem em espaçamentos de tamanho constante, mas sim com o comprimento dado por uma distribuição gaussiana de probabilidade.

Desta forma, a intervalos de tempo t escolhemos aleatoriamente um deslocamento de comprimento sendo p(t)d a probabilidade de encontrarmos f no intervalo que vai de g a f + df A seqüência de passos constitui um conjunto de variáveis aleatórias gaussianas independentes.

Os deslocamentos efetuados pelas partículas em movimento browniano só podem ser observados a partir de uma resolução finita.

Em inúmeros processos físicos, não nos interessa o valor do deslocamento a cada instante t, mas precisamos da informação a cada b t, onde b é um número qualquer.

O deslocamento final passa a ser então uma combinação linear de vários incrementos independentes.

Ao mudarmos a resolução de um movimento browniano, observamos que o seu registro parece não mudar.

Esta propriedade é conhecida como invariância por escala ou simetria de um registro.

A equação constitui a prova de que o movimento browniano é um processo invariante em distribuição e auto-afim, pois ao mudar a escala de tempo por um fator b e a escala de medida variou por um fator b0,5.

A posição da partícula no movimento browniano, dada por X(t) é , portanto, uma função aleatória, que foi definida como sendo.

XW-XftKlf-tjw onde fé um número aleatório de uma distribuição gaussiana.

A generalização do movimento browniano foi proposta para designar uma família de funções aleatórias gaussianas, controladas por um parâmetro H restrito ao intervalo 0 < H < 1.

O processo de movimento browniano fractal (mBf) apresenta média de incrementos.

A feição básica do movimento browniano fractal é que a interdependência entre seus incrementos é infinita , ou seja, o mBf apresenta alcance da autocorrelação infinito.

Com isto, os incrementos passados tem correlação com os incrementos futuros.

Analisando a fórmula verificamos que a correlação tende a zero para H ~ 1/2 e, neste caso, não temos mais correlação entre os eventos passado e futuro.

Estamos então no caso particular do movimento browniano.

Para valores de H 3 1/2 teremos C(t) 5 0 independente do valor de t.

Ocorre persistência para H > 1/2, onde teremos a maior probabilidade de continuar uma tendência de alta (ou baixa) do passado para o futuro.

Já para valores de H < 1/2 ocorre a anti-persistência, ou seja, uma tendência de valores altos no passado mais provavelmente será seguida por uma tendência de baixos valores no futuro e vice-versa.

Estes resultados da equação estão em desacordo com o que normalmente é esperado para sistemas físicos e registros estocásticos.

A premissa mais utilizada por estatísticos é a de que a correlação entre dois eventos decresce à medida que aumenta a distância entre eles, sendo nula a partir de um certo limite.

Para esta família de funções (mBf) a exceção constitui a regra, uma vez que o comportamento de lei de potência para a função de correlação se mantém por várias escalas.

Segundo a equação, um incremento gaussiano independente dX(t') de tamanho unitário no instante t' contribui para a posição da partícula browniana XH(t) em um instante posterior t, segundo a função linear K(t-t').

Da mesma forma que o movimento browniano, o processo X^t não é diferenciável por apresentar auto-similaridade.

A falta de derivada é um inconveniente, especialmente para funções utilizadas como modelo para interpolação e extrapolação de propriedades.

Para o movimento browniano foram estabelecidos vários métodos, muitos deles desprovidos de rigor matemático, na tentativa de encontrar "uma função derivada para o mB", e as funções assim obtidas foram classificadas como "ruído gaussiano branco".

Para o mBf sugerem aproximações análogas, às quais eles denominaram "ruído Gaussiano fractal" (rGf).

Para valores muito pequenos de Õ, os processos XH(t) e XH não podem ser distinguidos em termos práticos, com exceção dos efeitos de altas freqüências que geram a não-diferenciabilidade de XH.

A correlação entre dois incrementos de XH(t) é outra propriedade interessante para a utilização do mBf como modelo físico.

Supondo os pontos conhecidos nos instantes fixos e não negativos T, e T2, podemos estabelecer a correlação entre os incrementos de XH(t) sobre os intervalos de tempo.

Para quaisquer valores de e S2 temos que a correlação é positiva (persistente) para 1/2 < H 1, negativa (antipersistente) para 0 < H < 1/2 e nula para H = 0 e 1/2.

Conhecendo-se dois valores de XH, como por exemplo, XH(0) = 0 por conveniência e XH(T) com T > 0, podemos extrapolar e interpolar valores no intervalo -oo < t < oo, a partir da fórmula de interpolação/extrapolação, em função da variável reduzida s = t/T.

Para H = 1/2 a interpolação se faz por meio de linhas retas e a extrapolação considera que a melhor estimativa do próximo ponto é o ponto anterior, portanto, XH(t) = XH(T) para t > T ou Xh(í) = XH(0) para t < 0.

Quando 1/2 < H < 1, QH(s) apresenta uma derivada contínua que satisfaz as relações.

Q'(0)<0 , Qh'(1)<1 e QH(1'2)>1 resultando em interpoiações segundo curvas suaves.

Para extrapolação, temos que QH(s) Hjs|2H"1 para grandes valores de s, o que determina uma tendência não-linear divergente para t - ±00.

No caso de 0 < H < 1/2, QH(s) é diferenciável com exceção dos pontos s = 0 e s = 1, onde apresenta cúspides.

Para grandes valores de s, QH(s) ~ 1/2, o que determina a extrapolação segundo uma tendência que converge para o valor médio de XH(0) e XH(T).

Mostra a evolução da interpolação/extrapolação para os casos de 0 < H < 1/2 e 1/2 < H < 1.

Estes resultados podem ser generalizados para mais de dois pontos conhecidos, obtendo-se expressões um pouco mais complicadas, porém ainda como funções de variáveis reduzidas convenientemente escolhidas.

A função rGf também constitui um modelo estocástico com propriedades interessantes.

Sendo um processo estacionário, a covariância entre incrementos separados por um intervalo de tempo.

Estas funções foram estudadas, para vários valores de H e de outro parâmetro denominado M = "memória do processo".

Esta "memória" se refere ao fato de não se contar com séries temporais de tamanho infinito nos processos práticos, havendo necessidade de se estudar o efeito do volume de dados nas estatísticas.

Em especial, observaram que testes estatísticos demonstram que as séries geradas com valores de H < 0,5 são ricas em termos de altas freqüências, fazendo com que grandes valores positivos apresentem a tendência a ser seguidos por grandes valores negativos, promovendo um tipo de "compensação".

Já para H > 0,5 o rGf é preferencialmente dominado por termos de baixa freqüência, levando à característica de os grandes valores positivos ou negativos tenderem a persistir.

Os autores acima recomendam que as séries artificialmente produzidas em ensaios de computador sejam comparadas com os registros naturais, para verificar visualmente a adequação do uso do rGf como modelo.

Caso a aparência das curvas seja muito diferente, podemos descartar o uso destas funções.

Já se houverem semelhanças, porém, ainda que com pequenas distorções, deve-se tentar um valor diferente de H.

Quando o grau de ajuste visual parecer adequado, deve-se então partir para testes estatísticos que quantifiquem o bom ajuste.

Ainda no mesmo trabalho, destacam a característica visual de rGf s sintéticos com 0,5 < H < 1 apresentarem, desafortunadamente, aspectos de ciclicidade, embora no seu mecanismo gerador não esteja embutida nenhuma estrutura periódica, levando os autores a concluir que os ciclos devem ser considerados efeitos espúrios.

A amplitude aparente destes ciclos é da ordem de 1/3 do tamanho total da amostra, variando proporcionalmente com o mesmo (efeito "memória").

Os testes estatísticos de análise espectral ou de Fouríer realizados pelos autores não confirmam esta aparente periodicidade do ruído Gaussiano fractal.

Outro resultado interessante apontado pelos autores acima refere-se à correlação entre médias amostrais de eventos passados (P) e futuros (F).

Neste caso, verificaram que, mesmo tomando médias de intervalos longos e sucessivos, elas poderiam ter valores muito diferentes, sendo também diferentes da média amostrai tomando os dois intervalos em conjunto.

Foram plotadas médias calculadas a partir de séries geradas com valores distintos de H e tamanho fixo de "memória" M = 10000.

O número de amostras futuras foi mantido em F = 50 e o de P variou.

Para um mesmo valor de P a média de A^g aumenta rapidamente com o aumento de H.

Para um mesmo valor de H, a média diminui à medida que P aumenta.

Foram tomadas as mesmas curvas para H = 0,7 e H = 0,5 da figura anterior, acrescidas da curva para H = 0,7 e M = 20.

Pode ser visualizado o efeito do tamanho da memória, observando-se que a curva para M = 20 apresenta comportamento de pequena escala próximo ao de H = 0,7 e M = 10000 mas, para grande escala, tende ao comportamento de H = 0,5.

Portanto, para o modelamento de fenômenos naturais a partir de séries de rGf sintéticas, não importa somente conhecer o valor adequado de H mas também, para melhor ajuste, deve-se gerar séries com tamanho de memória grande, mais precisos para o processo de interpolação e extrapolação das propriedades.

Para um grande número de sistemas físicos, ao provocarmos pequenas modificações nas condições iniciais, pouco iremos alterar o resultado final.

Como exemplo, uma torneira pouco aberta deixa fluir a água em fluxo laminar e, para pequenas modificações na abertura da mesma, não iremos alterar as condições de fluxo da água, permitindo que uma pessoa lave as mãos sem se molhar.

Há outros sistemas que tem como propriedade típica uma dependência muito acentuada para condições iniciais, observando-se efeitos contrários ao salientado acima.

No mesmo exemplo, a partir de um ponto crítico de abertura, o fluxo de água passa a ser turbulento.

Nesta região, um pequeno deslocamento na abertura da torneira muda o regime de fluxo, fazendo com que, em termos práticos, a pessoa em volta se molhe.

Este comportamento completamente imprevisível passou a ser conhecido como comportamento caótico (vácuo, desordem, confusão), podendo se desenvolver em sistemas dinâmicos não-lineares com mais de dois graus de liberdade para equações diferenciais, ou mais de um grau de liberdade para diferenças finitas.

Nos últimos anos desenvolveram-se muitos métodos para a classificação dos diferentes tipos de caos, descobrindo-se que vários sistemas diferentes apresentam transições semelhantes da ordem para o caos, podendo esta rota ser controlada por meio de parâmetros externos.

Até o final do século passado, acreditava-se que os sistemas determinísticos, governados por equações diferenciais para calcular o comportamento futuro do processo a partir de condições iniciais, eram completamente regulares e longe de serem caóticos, pois os estados sucessivos evoluíam continuamente dos estados anteriores.

Poincaré foi o pioneiro em demonstrar que alguns sistemas mecânicos, cuja evolução temporal é dada por equações de Hamilton, poderiam apresentar comportamento caótico.

Somente após o trabalho, a descoberta de Poincaré deixou de ser uma mera curiosidade científica.

Neste trabalho, Lorenz analisou um conjunto de três equações diferenciais não-lineares de primeira ordem, chegando à conclusão que elas poderiam levar a trajetórias caóticas.

O termo caos determinístico é utilizado para designar o movimento irregular ou caótico, gerado por sistemas não-lineares cujas leis dinâmicas determinam, de forma única, a evolução temporal de um estado do sistema, a partir do conhecimento de um histórico do mesmo.

A predição do comportamento futuro destes sistemas para tempos muito longos é impossível de forma prática, uma vez que as condições iniciais e os cálculos podem ser estabelecidos somente com uma precisão finita, mas os erros crescem de forma exponencial, conduzindo rapidamente ao caos.

Os sistemas não-lineares podem ser divididos em sistemas dissipativos e sistemas conservativos.

Nos dissipativos só ocorre a transição para o caos nos casos em que o sistema sofre influência externa, ou seja, se ele for aberto.

Até o presente, admite-se que existam pelo menos quatro rotas distintas que conduzem ao caos em sistemas dissipativos.

Uma proposta foi efetuada seguindo idéias pré-lançadas.

Este último considerava a turbulência no tempo como o limite de uma seqüência infinita de instabilidades, cada uma delas criando uma nova freqüência básica quasi-periódica.

Os primeiros autores provaram que, já após a terceira iteração, a trajetória passa a ficar confinada a uma região limitada do espaço de fases, nas quais as trajetórias, inicialmente pouco separadas, se afastam exponencialmente, de modo que o movimento passa a ser caótico.

A região do espaço de fase recebe o nome de bacia atratora.

Uma segunda proposição, é conhecida como rota de intermitência.

Por intermitência entendem-se os movimentos irregulares estatisticamente distribuídos, que passam a afetar um sinal de comportamento regular no tempo.

O número destas interferências aumenta de acordo com a variação de um parâmetro de controle externo, até atingir estágios completamente caóticos.

Outra rota bastante conhecida é a rota de bifurcações.

Analisando uma equação diferencial simples para descrever a taxa de variação de populações ao longo do tempo, observaram que o tamanho da população oscila entre valores fixos, cujo número dobra para certos valores particulares de um parâmetro externo de controle.

A partir daí as variações passam a ser irregulares.

Esta equação também possui grande aplicabilidade para outros sistemas físicos.

Uma quarta rota foi proposta quando discutiram a assimetria introduzida nas equações estudadas por Feigenbaum, mostrando uma descontinuidade na origem, que se reflete em "cascatas" que levam ao caos de forma diferente que o cenário exposto em Feigenbaum.

A caracterização das trajetórias que levam ao caos pode ser feita de forma qualitativa, analisando-se os gráficos dos mapas resultantes das equações diferenciais.

Um exemplo destes mapas é o que representa um corte de uma superfície no espaço de fase de muitas dimensões, conhecida por superfície ou seção de Poincaré, onde se estuda a figura formada pelos pontos em que a superfície é perfurada pelas trajetórias.

Nesta figura, a seção de Poincaré representa um corte no modelo de Hénon-Heiles, que descreve o movimento de uma estrela dentro de uma galáxia com simetria axial.

Para baixas energias, o comportamento é regular, formando curvas fechadas.

Em energias intermediárias, ocorrem regiões regulares e caóticas.

Para altas energias, os pontos se distribuem de maneira complicada, não formando curvas fechadas, caracterizando o comportamento predominantemente caótico.

As medidas quantitativas para caracterizar o movimento caótico.

Expoente de Lyapunov.

Descreve o afastamento de dois pontos originalmente próximos pela ação de uma função de iteração f.

Medida invariante.

Mostra a distribuição dos valores iterados no intervalo unitário.

Função de correlação.

Mede a correlação entre iterações distantes de m passos.

A partir do mapeamento de uma equação simples.

Observamos que pontos inicialmente muito próximos podem sofrer uma separação exponencial, levando ao caos.

O termo mede o fator médio peío qual a distância entre dois pontos próximos aumenta após uma iteração.

O expoente de Lyapunov também mede, em média, a perda de informação após cada iteração em torno da posição de um ponto no intervalo [0,1].

Isto pode ser interpretado matematicamente aplicando a regra da cadeia.

Apenas como exemplo, podemos calcular a perda de informação após uma iteração com um mapa linear.

Dividimos um intervalo [0,1] em n partes iguais, nas quais um ponto pode ocorrer com igual probabilidade 1/n.

Para mapeamentos com dimensões maiores, em primeiro lugar os pontos fixos e a sua estabilidade.

Nos casos em que uma seqüência de iterações não apresenta pontos fixos estáveis, a separação entre dois pontos inicia exponencialmente e o expoente de Lyapunov torna-se independente próximos cresce após n iterações.

Tomando-se por base um mapa como o fornecido um intervalo [0,1] podemos definir a medida invariantep(í) como sendo a densidade de estados do resultado das iterações.

A fórmula acima permite calcular médias temporais sobre uma função g(f) como se fossem médias sobre a medida invariante.

Observamos então que, para uma dimensão, restabelecemos a fórmula clássica da média em mecânica estatística e, para sistemas ergódicos, podemos trocar a média temporal por uma média de "ensemble" sobre uma distribuição estacionaria.

Uma das equações não-lineares mais simples é a chamada equação logística ou mapa logístico.

Tomando-se inicialmente um valor "0 que entra na equação como , calcula-se o valor de f, como M.

Em seguida, pega-se o valor de e obtém-se o valor de f2.

O processo segue recursivamente gerando o mapa f0.

As iterações foram estudadas , que observou pela primeira vez o notável comportamento desta equação, dependendo do valor escolhido para a constante b.

Uma particularidade é a de que os valores de f devem estar restritos ao intervalo (0,1).

Para valores maiores que 1, as iterações divergem rapidamente para -a>.

A função apresenta um valor máximo em f = 1/2 correspondente a b/4.

Para um comportamento dinâmico não-trivial, requer-se que b < 4.

Já para b < 1, todas as trajetórias são atraídas para f = 0.

Portanto, o domínio aceitável para soluções não-trivias restringe o parâmetro b para 1 < b < 4.

Para fora destes limites o processo se extingue.

Para um melhor entendimento da mecânica do processo, estudam-se os pontos fixos desta equação.

Resolvendo-se para ft obtém-se dois pontos fixos.

A equação logística também pode ser escrita na forma generalizada.

Quando z = 2, esta forma é equivalente à expressão.

Estudaram o comportamento no contexto de grupos de renormalização.

Observaram que esta equação possui duas raízes.

A primeira é igual a 1 para a = O e decresce à medida que a aumenta, convergindo para um ponto fixo para valores pequenos de a (= 3/4 pi z=2).

A partir deste ponto, o comportamento passa a ser instável, convergindo para ciclos de 2k pontos, com k = 1,2,3, até entrar em regime caótico, quando a convergência passa para infinitos pontos.

O valor de a crítico (a) para a entrada em caos depende do valor de z.

Sabe-se que para a = 2 o sistema é caótico independente do valor de z.

Para a > 2 a função rapidamente diverge para qualquer valor de z.

Observando mais atentamente, nota-se que, mesmo para valores de a > a", existem ainda janelas de atratores finitos misturados com as regiões caóticas.

A rota para o caos com as características não é exclusiva da equação, podendo também ser constatada em várias outras, que compartilham entre si algumas poucas propriedades matemáticas como, por exemplo, o fato de terem um único máximo.

A equação logística com z = 2 tem várias propriedades como a seqüência de bifurcação, janelas de atratores finitos, constantes universais, entre outras, que têm sido medidas em vários experimentos de sistemas físicos tais como os hidrodinâmicos, ópticos, acústicos, eletrônicos, biológicos e químicos.

Em muitos sistemas físicos, normalmente são observados fenômenos de assimetria, ou seja, comportamentos diferenciados para f-0t e f-0.

Introduziram um termo de assimetria na equação, obtendo.

Que constitui uma generalização.

Estes autores verificaram que o mapa fornece um tipo de diagrama de fase no espaço definido por (ev e2< av a2), onde conjuntos complexos de hipersuperfícies de p-furcações ocorrem nos pontos críticos como a entrada em caos, que corresponde a uma generalização de a(z).

E outra que corresponde a uma generalização do ponto onde desaparecem os atratores finitos.

A evolução dos atratores nesta equação é uma função de (ev ez, av a2), da mesma forma como o expoente de Lyapunov.

A quantificação do movimento caótico para a equação logística pode ser feita por meio de expoentes de Lyapunov.

Para expoentes negativos, as soluções adjacentes convergem e são, portanto, previsíveis.

Para expoentes positivos as soluções adjacentes divergem e obtém-se o caos.

Nos pontos onde o expoente se iguala a zero, ocorrem as bifurcações da rota para o caos.

Para os trabalhos desta tese, calculamos séries temporais com base na equação para vários valores de a e z, aplicando posteriormente a técnica de análise RIS para obter os valores do expoente de Hurst H(z,a) e da amplitude A(z,a).

Mostra a evolução de H vs a e a evolução de A vs a para valores fixos de z = 2, que refletem em essência a própria evolução dos atratores, em particular para z > 1, ao longo das sucessivas bifurcações que conduzem ao regime caótico.

Como conclusão, observamos que o gráfico H vs a pode se constituir em uma caracterização da rota para o caos diferente das quatro citadas anteriormente.

A equação logística é um bom protótipo para efetuar testes em metodologias do tipo análise R/S.

Os processos que dependem de seleções aleatórias nas ciências naturais, supostamente deveriam obedecer a duas proposições bem conhecidos .

Os sistemas naturais têm tempo de memória curto a nível microscópico, o que eqüivale a dizer que os efeitos de perturbações aleatórias atuando no sistema são sentidos durante um intervalo de tempo limitado, com a correlação dos eventos caindo exponencialmente.

Perturbações de pequena intensidade conduzem a alterações pequenas ou previsíveis no comportamento futuro do sistema.

Em muitos exemplos, entretanto, estes dois dogmas não são verdadeiros, como é o caso dos sistemas dinâmicos apresentados no Capítulo III, cuja evolução pode levar a rotas completamente caóticas, desobedecendo, ou então, as funções mBf e rGf do Capítulo II, que podem apresentar correlações em várias escalas, não verificando a proposição.

As técnicas estatísticas comuns não são eficazes para o tratamento de sistemas com larga amplitude de correlações.

Estes autores apontam uma técnica estabelecida, a qual denominaram análise R/S, para determinar parâmetros que caracterizam estas distribuições.

O problema estudado em profundidade estava ligado à construção de barragens.

Durante muito tempo este cientista estudou o comportamento do rio Nilo, envolvido na construção da barragem de Assuã.

Do ponto de vista operacional, pretendia determinar o volume ideal de armazenamento de água em um reservatório, baseado nos dados de vazão de água requerida ao longo do tempo.

Um reservatório ideal deveria ter as seguintes propriedades.

O volume de água fornecido para a usina (vazão de saída) deve ser constante.

O nível de água após um determinado período deve permanecer constante.

O lago não deve encher demais para não extravasar e.

A capacidade de armazenamento deve ser a menor possível, de modo a compatibilizar As condições i e ii determinam que o volume de água liberado por ano seja igual ao volume médio de água que entra no reservatório durante um período de t anos.

A condição iv implica em que o reservatório ideal também fique quase seco em algum período, para evitar ser superdimensionado.

Estudou também vários outros registros geofísicos como nível de água em lagos, vazões de rios, regimes de chuvas entre outros, chegando à conclusão que, para poder comparar fenômenos com origem e características diferentes, era necessário dividir R(t,r) pelo desvio padrão S(t,7).

Esquema de um reservatório de água mostrando o significado das variáveis para a análise R/S.

Estudaram os fundamentos da análise R/S e sua real utilidade para a descrição de séries temporais com correlação em várias escalas, como é o caso das funções mBf e rGf.

Perceberam que, apesar de a formulação inicial proposta apresentar falhas, a idéia geral da lei era válida.

Reconhece a validade da lei de Hurst para fenômenos naturais, onde se esperava um crescimento de R(t,r) segundo i6, porém a partir dos casos bem documentados, os cientistas se vêm forçados a concluir que há correlação em grande escala, proporcional a j, onde h gira em torno de 0,7.

Apresentou a primeira aplicação prática da análise R/S em estudos de reservatórios de petróleo, utilizando esta estatística para determinar o valor de H em registros de perfis elétricos de poços e aplicar este parâmetro na simulação estocástica de propriedades de rochas.

Ainda nesta área de petróleo, a análise RIS também foi aplicada.

Apresenta os conceitos da lei em forma didática, conferindo os testes de validade efetuados com moedas e cartas de baralho, por meio de simulações por computador, gerando uma quantidade bem maior de dados, o que lhe permite concluir que o valor de H tende assintoticamente para 0,5 nas situações em que Hurst obtinha Hs0,7.

Para a classe dos processos estacionários, somente aqueles em que a auto-correlação decresce lentamente, como uma potência do intervalo de tempo considerado, são capazes de preservar as propriedades da lei de Hurst quando r-.

O parâmetro H pode ser determinado a partir de gráficos em papel bilogaritmo para as situações em que há uma dependência de lei de potência entre re R(t,r)/S(t,7).

Apontam particularidades que devem ser levadas em consideração para a construção e interpretação de tais diagramas.

Os gráficos analisados pelos autores acima consistiram em amostras de rGf com 10000 valores, semelhantes aos discutidos.

Por definição, para r=1a análise fica indeterminada pois R(t,1) = 0 e S(t,1) = 0.

Para t-2, obtivemos R(t,2)/S(t,2) = 1 ou flutuações em torno deste número.

Utilizando uma definição um pouco diferente,obtiveram R(t,2)/S(t,2) = 2.

Os casos práticos devem ser analisados a partir de r-3, até o número máximo de dados N.

O primeiro passo consiste em definir uma seqüência de intervalos r, ou seja, fixar os diversos tamanhos de amostras a serem analisados.

Uma vez fixados os valores de N e r, escolhemos os pontos de partida t, que podem variar de 1 a N-j+1.

Para poucos pontos (caso extremo 1 ponto com t = 1), a interpretação gráfica pode ser prejudicada pelas flutuações amostrais, inviabilizando obter-se uma conclusão rigorosa.

Por outro lado, um número excessivo de pontos, por exemplo, uma análise a cada ponto t faz com que o gráfico tenha um aspecto triangular, com N-2 pontos em r -3 e 1 ponto em r = N, o que representa redundância de informação, pois os valores de R/S de amostras sobrepostas não são independentes.

A análise também passa a ser dependente de N, tornando difícil a comparação de gráficos de séries com tamanhos diferentes.

A filosofia da análise R/S é explorar a distribuição da variável aleatória R(t,r)/S(t,7), plotando-se valores independentes desta variável.

Para simulações teóricas sempre podemos construir várias séries independentes, porém os registros e amostragens em fenômenos naturais normalmente só podem ser realizados uma única vez.

Um procedimento alternativo consiste em quebrar a série em subséries, evitando sobreposição de amostras, o que gera valores de R(t,r)/S(t,r) independentes.

Os autores acima utilizam pontos de partida em t = 1, 100, 1400 para valores de r< 500 e t = 1000, 2000, 8000 ou até N -r t 1, a depender do menor valor entre estes dois, para r> 500.

Em nossos trabalhos adotamos a mesma série de pontos de partida, acrescentando os pontos 10000, 15000, 20000, 30000 e 40000 para séries maiores que 10000 amostras.

Cada valor de R(t,r)/S(tJr) calculado é representado por um sinal +.

Calcula-se o valor da média aritmética para todos os valores obtidos em um mesmo r.

Traça-se uma regressão linear pelos pontos do valor médio, obtendo-se o valor de H a partir da inclinação desta reta e, o valor de A pela interseção com o eixo das abscissas.

Para o caso de "crossover", são efetuadas tantas regressões quantas mudanças de H forem detectadas.

Nossos resultados são obtidos a partir da reta de melhor ajuste do programa gráfico GRAPHER.

Realizou vários testes com moedas para criar uma seqüência aleatória de caras e coroas com igual probabilidade de ocorrência.

Por serem eventos independentes, o resultado esperado para H é 0,5, como de fato foi comprovado pelo pesquisador.

Para simular valores de H superiores a 0,5 encontrados nos registros físicos, este autor utilizou um baralho onde as cartas eram numeradas segundo a freqüência de uma população normal, em ±1, ±3, ±5 e ±7.

Desta forma, nas 52 cartas haviam 26 números 1,16 números 3, 8 números 5 e 2 números 7.

Após misturar bem, o baralho era "cortado" ao acaso e o número do corte era anotado, gerando uma seqüência aleatória com H = 0,5.

Retirando algumas cartas após o terceiro corte, segundo regras pré-estabelecidas, e introduzindo um coringa no jogo,conseguiu introduzir um viés na distribuição anteriormente obtida.

Quando a carta do corte era o coringa, todas as cartas voltavam ao baralho e iniciava-se uma nova seqüência.

O processo acima gera séries intervalos r da ordem do número de cartas na mão.

Em média, observou que coringa aparecia no 27° corte.

Portanto, se o viés for positivo, a tendência será crescente e, se for negativo,decescente.

Utilizou um gerador de números aleatórios para construir uma seqüência de valores +1 e -1 com igual relacionando o número +1 com cara e -1 com coroa.

A variável f(t) considerada para análise R/S é formada pela soma de 10 números, repetindo-se o processo até um numero toral n(50000) de amostras.

O valor de H obtido é de 0,503 ± 0,008 e o de A = 1,3 ± 0,1.

Introduzindo um viés no processamento acima, foi possível para o autor simular também o jogo de cartas, obtendo uma amostra de 100000 valores.

O ajuste de H proposto é 0,65 ± 0,2, observando-se que para tempos muito grandes, t > 50000, há uma tendência da inclinação passar para 0,5 assintoticamente.

A interpretação gráfica nesta parte é dificultada, pois são necessárias determinações em várias décadas para se obter um bom ajuste, o que levaria a simulações com um número muito grande de pontos.

Este processo de calibração foi parcialmente repetido em nosso trabalho.

Geramos uma variável aleatória ^t com igual probabilidade de valer +1 e -1, a partir de uma distribuição uniforme de números aleatórios.

As análises R/S apresentam valores de H-0,507 ± 0,007 e A = 1,134 ± 0,067, a depender da semente utilizada.

Aumentando a probabilidade de $t valer +1, passando sucessivamente para 60%, 70%, 80%, 90% e 99,75%, os valores de H obtidos da análise R/S permaneceram da ordem de 0,502 ± 0,02 e A = 1,166 ± 0,106.

Este constitui um exemplo de que, apesar de a distribuição binomial ficar cada vez mais assimétrica, o valor de H continua sendo igual a 0,5 em média.

A equação logística foi utilizada para a calibração, especialmente para os casos de anti-persistência e movimento aleatório.

Diversos valores de z e a foram testados observando-se comportamento semelhante em todos os casos.

Para valores de a que levam a um atrator que é um ponto fixo, temos H=1, que significa comportamento totalmente persistente.

Para a=2 temos movimento aleatório em qualquer valor de z, gerando valores de H = 0,5.

Após abordar a metodologia e a calibração da interpretação gráfica, restam alguns efeitos que devem ser levados em conta para a correta definição de H.

Os valores muito pequenos de r sofrem grandes influências de fatores quase sempre irrelevantes para a análise R/S, mas que provocam grande dispersão nos valores de R(t,r)/S(t,r) nesta região do gráfico.

Desta forma, os pontos iniciais devem ser descartados para a análise.

São unânimes em considerar um limite inferior da ordem de rmin = 20.

Em nossos experimentos este limite aparenta ser menor, da ordem de rmin = 7.

O efeito transiente observado nos ensaios é maior para H < 0,6, com tendência a um crescimento rápido à medida que H - 0, estando acima de r = 1000 para H = 0,1.

As análises R/S efetuadas nas simulações com rGf com tamanho de memória (M) diferentes demonstram que os valores de R(t,r)/S(t,r) diminuem consideravelmente na região de grandes valores de r quando M passa a ser menor que 3000.

A região do transiente, entretanto, permanece inalterada.

O gráfico finai pode conter três regiões distintas , iniciando com um transiente, passando para H 0,5.

Este comportamento pressupõe que a variável aleatória R(t,r)/S(t,i) se comporta assintoticamente como p5, em função do tamanho M, que controla o intervalo onde vale a relação com i^.

Designando o ponto de transição por M\ os autores observaram, que para H da ordem de 0,7, M = 3M, o que requereria mais de 30000 amostras para um comportamento de H = 0,5.

Estes dados também são coerentes com os obtidos nas simulações do jogo de baralho onde H > 0,5.

Nas análises R/S dos registros de perfis de poços, não observamos este comportamento assintótico para t1,5.

Desta forma, podemos considerar os valores de H obtidos como confiáveis.

O conceito de correlação em grande escala, visto sob a ótica acima, pode ser melhor compreendido pois, por dependência estatística infinita dos registros geofísicos, entende-se que as correlações existentes atingem uma amplitude maior do que o maior tamanho de registro disponível para análise.

Aumentando progressivamente o valor de a, observa-se a evolução para seu atrator, que ocorre em tempos pequenos (t < 100) para a <s 0,60.

Vemos um alinhamento para H = 1 correspondente aos pontos calculados para t ^ 100 e outro para t = 1 com H = 0,5, mostrando um "crossover" para H = 1 no primeiro gráfico.

Quando o atrator de $t passa a ser atingido após t = 100, observa-se que os pontos R/S analisados em t = 100 passam a ter o mesmo comportamento que os de t = 1 acima.

Para valores da ordem de a = 0,75 já não é mais visível o alinhamento H = 1.

O "crossover" H = 0 para H = 0,5 já esta bem demarcado, atingindo a totalidade dos pontos de partida.

Para a > 0,80 temos H -0 que se mantém até o ponto de entrada em caos.

A partir da entrada em caos, aumentando progressivamente a verifica-se um crescimento de H em direção a H = 0,5, atingido em a = 2, o que confirma a natureza aleatória dos dados neste ponto.

O crescimento de H também é através de "crossover" , começando com um transiente de H = 0, passando para H > 0.

À medida que a aumenta o ponto de "crossover" diminui rapidamente, ao passo que H = 0,5 só é atingido assintoticamente em a = 2.

A presença de elementos periódicos pode complicar o aspecto gráfico, porém não necessariamente invalidar o fenômeno Hurst.

Em outros casos, onde ocorrem ciclos de duração menor, o efeito cíclico aliado ao efeito provocado por subharmônicas do ciclo principal pode mascarar a interdependência de grande escala expressa pela lei de Hurst.

Neste caso, o valor de H não pode ser determinado graficamente com diagramas construídos a partir dos dados brutos.

De um modo geral, os ciclos e subharmônicas provocam quebras no alinhamento do diagrama log-log de R/S vs r.

Estas quebras podem transformar-se em pequenos patamares com H 0.

Quando a ciclicidade é muito acentuada, as quebras tendem a se juntar, baixando o valor de H, que pode chegar até H = 0 (tendência completamente horizontal).

Sugere que se proceda a uma normalização dos dados, para se tirar o efeito de ciclicidade, de modo que a seqüência apresente média igual a 0 e variância 1.

Em seu exemplo de medidas de altura de ondas do mar ao longo do tempo aponta uma quebra associada a um período de 1 ano.

A análise R/S dos dados brutos indica H = 0,87.

Este "crossover" reflete a passagem de um regime persistente para um regime aleatório.

O exemplo acima também comprova a robustez da análise estatística R/S, uma vez que a distribuição das medidas de ondas é fortemente assimétrica.

Conforme discutido, mesmo distribuições de incrementos lognormais, hiperbólicas ou gama, também podem gerar valores de H = 0,5.

Para A -0 temos um sistema persistente com H = 1.

À medida que A aumenta, o comprimento de onda diminui, provocando o surgimento de eventos cíclicos em (t).

Estes ciclos se refletem na análise R/S como "crossover" entre dois regimes, um com H = 1 e outro com H -0.

Observa-se a evolução do ponto de "crossover" diminuindo o valor de rcom o aumento de A.

O falso valor de H, calculado sem levar o "crossover" em consideração.

Os perfis elétricos, acústicos e radioativos de poços são interpretados como rGf.

Nestas séries temporais, a profundidade faz o papel do tempo.

Em poços de petróleo, via de regra, são registradas medidas de resistivídade através de corrente elétrica induzida (ILD), de radioatividade natural de raios gama (GR), de tempo de trânsito de onda sonora (DT), de radioatividade através do bombardeio da rocha com raios gama (RHOB) e de radioatividade por bombardeio de nêutrons com registro do índice de hidrogênio (NPHl).

As três últimas medidas refletem a propriedade da porosidade das rochas.

Os raios gama podem ser associados com os diferentes tipos de litologia atravessados pelo poço.

A resistivídade possui uma relação com o conteúdo de fluido existente no espaço poroso.

Com estes registros é possível caracterizar as seqüências de rochas, a sua porosidade e o conteúdo de fluido presente nos poros.

Com o auxílio da análise R/S determina-se o valor do expoente H, que está relacionado com a dimensão fractal.

Mostra os registros dos perfis corridos em um poço da plataforma continental brasileira.

A seção sedimentar corresponde às formações Macaé, Campos e Emborê.

Da base para o topo, a seqüência inicia com depósitos marinhos em ambiente de mar semirrestrito, com o desenvolvimento de uma rampa carbonática predominantemente de água rasa, caracterizada por calcarenitos oolíticos e oncolíticos da Formação Macaé Inferior.

O bascuiamento da bacia sedimentar para leste provocou o afogamento desta rampa e a sedimentação passou a ser caracteristicamente de água profunda, representada por margas e calcílutitos da Formação Macaé Superior.

Durante esta fase, houve intensa movimentação tectônica devido ao bascuiamento da bacia, que ocasionou também a movimentação de camadas salíferas depositadas na fase rift anterior à deposição da rampa carbonática.

Houve a formação de calhas estruturais que serviram como zonas de captação de areias turbidíticas (Arenito Namorado).

Com o contínuo bascuiamento da Bacia, instalou-se um oceano aberto, onde a sedimentação passou a ter um caráter transgressivo com elásticos grosseiros na porção marginal (Formação Emborê) e folhelhos marinhos na porção distai (Membro Ubatuba, Formação Campos).

Nestes folhelhos distais, ainda por ação da tectônica salífera associada com variações do nível do mar, ocorreu uma segunda fase de deposição turbidítica cretácica, constituída pelos arenitos do Membro Carapebus da Formação Campos.

Os reservatórios de hidrocarbonetos são formados por duas espessas seções de arenitos do Membro Carapebus.

A seqüência superior é constituída por pacotes de arenitos de idade eocênica média, com ocorrência restrita de óleo, tendo pequena expressão econômica.

Os reservatórios principais são formados por espessos pacotes de arenitos, de idade Coniaciano e Maastrichtiano.

Com o auxílio de dados petrográficos, petrofísicos e de perfis, individualizou doís tipos litológicos principais.

O primeiro, litofácies A, é constituído por arenitos muito grosseiros, com grânulos dispersos e microconglomerados.

O segundo, litofácies B, é formado por arenitos médios a grosseiros.

Pelo processo de cálculo de R(t,r)/S(t,r) podemos concluir que esta razão não é sensível às mudanças litológicas desta seção sedimentar, não apresentando "crossover" em função das diferentes unidades litológicas maiores (formações).

A ausência de mudança de direção e, portanto, dimensão fractal provavelmente se deve ao fato de as seqüências sedimentares serem constituídas por arenitos e folhelhos, com exceção da base, onde ocorrem os carbonatos com pouca espessura.

Resultado diverso foi encontrado nas rochas do Terciário da China.

Estes autores observaram um aumento brusco no valor do expoente H das rochas do Mioceno para o Pleistoceno, talvez associado a feições estruturais resultantes de colisão de placas.

Também apontam a existência de quebras na tendência dos valores médios de R/S, que podem estar relacionadas às periodicidades "escondidas" dos estratos sedimentares.

Para estudar a distribuição em área e o comportamento espacial do valor de H e A, tomamos 52 poços de um campo de petróleo para análise.

A seção sedimentar corresponde à mesma descrita acima.

O mapa mostra a distribuição geográfica dos poços.

Mostra os valores médios de H e A por poço e a média dos três perfis que refletem a porosidade (DT, RHOB, NPHl).

Como observação, destaca-se que os valores de H e A foram calculados sobre os dados brutos, sem efetuar correções para os efeitos de ambiente de perfilagem ou verticalização dos poços direcionais.

A efetivação destas correções não altera o resultado final pois elas essencialmente não mudam a forma final da curva.

H e A apresentam uma variabilidade concordante com a estrutura geológica local, mostrada pelo mapa do topo do marco cinza vulcânica.

A análise desses mapas pode auxiliar na determinação do valor de H na direção horizontal.

O parâmetro H constitui-se em um dado de entrada de capital importância para estudos geoestatfsticos, com grande utilidade para os procedimentos de interpolação por krigagem ou para simulação estocástica de propriedades.

Como conclusão, podemos afirmar que os perfis de poços possuem correlação estatística de grande escala, cuja intensidade é dada pelo parâmetro H.

Embora nos exemplos analisados não haja uma relação direta que permita diagnosticar unidades geológicas diferentes, esta possibilidade deve ser investigada em seqüências que apresentem maior variabilidade litológica.

Outra frente aberta à pesquisa é o estudo das características da análise R/S e seus resultados utilizando perfis de maior resolução vertical como, por exemplo, as ferramentas radioativas de maior resolução (RHOB e NPHl) e/ou os perfis de mergulho (dipmeter).

O estudo de variáveis aleatórias regionalizadas é caracterizado pelo fato de não dispormos de dados amostrais em todos os pontos do domínio, Para o caso da indústria do petróleo, a amostragem é feita, via de regra, através de poços, perfurados em áreas mais favoráveis à prospecção, previamente determinadas por estudos geofísicos e geológicos.

O alto custo de cada poço, que implica a otimização dos locais perfurados no terreno, é um dos principais fatores na definição do número de poços a perfurar em uma determinada área.

Vários fatores, como as características permo-porosas das rochas, o tamamho da acumulação de petróleo, o número de reservatórios na seção sedimentar, entre outros, também são de grande importância para a tomada de decisão quanto ao número de poços.

Pelos motivos acima, depreende-se que a amostragem nas áreas petrolíferas é dispersa, com o espaçamento dos poços variando desde algumas centenas de metros até poucos quilômetros entre eles.

Por outro lado, a densidade de amostragem é anisotrópica, sendo muito mais abundante na direção vertical, ao longo do poço, do que na direção horizontal.

Os estudos geológicos e de engenharia de produção dos reservatórios de hidrocarbonetos são efetuados com base em modelos.

Especialmente no segundo caso, realizam-se simulações do comportamento do reservatório frente a processos de recuperação secundária e terciária.

Estes estudos necessitam de informações em uma malha mais refinada do que aquela obtida só pela posição dos poços.

Cabe aos geólogos e engenheiros encarregados de estudar e gerenciar a explotação dos campos de hidrocarbonetos a tarefa de prover as informações necessárias ao modelamento matemático.

A interpolação estocástica é uma ferramenta adequada para este fim, uma vez que permite caracterizar as propriedades desejadas e, a partir da análise espacial dos dados, realizar inferências destas mesmas propriedades sobre pontos não amostrados.

Obtém-se então uma imagem do reservatório.

Duas técnicas de interpolação estocástica são bastante difundidas na indústria do petróleo.

A primeira, denominada krigagem, fornece uma imagem otimizada pela minimização da função variância associada aos dados.

A segunda, em contrapartida, preserva a variabilidade da distribuição, produzindo imagens de grande utilidade para o estudo do impacto desta variabilidade sobre o processo em apreço.

Nesta seção, vamos apresentar as noções básicas de estatística necessárias ao bom entendimento dos problemas de interpolação espacial.

Uma variável aleatória (VA) pode ser definida como uma variável que pode assumir uma série de valores, denominados realizações, que apresentam uma probabilidade de ocorrência.

Quando o número de valores possíveis é finito temos uma variável aleatória discreta.

Quando este número é infinito e os valores possíveis pertencem a um conjunto denso, a VA é contínua e sua distribuição de probabilidade é dada por uma função acumulada.

Esta função de distribuição acumulada caracteriza plenamente a VA.

Denominamos de esperança matemática à soma ponderada pela probabilidade de todas as possíveis ocorrências da VA.

Onde f(í) = F'(í) é a função densidade de probabilidade, definida como sendo a derivada da função distribuição de probabilidade, onde ela existir.

A variância da VA é definida como sendo a esperança do desvio quadrático de E em torno de seu valor médio.

O operador variância é linear, no sentido de que a esperança de uma combinação linear de VA independentes é a combinação linear das esperanças das VA.

Na maioria dos problemas geológicos, normalmente é mais importante conhecer a relação de dependência entre duas variáveis aleatórias, ou seja, a relação entre uma realização da variável =, e outra ~2.

Este padrão de dependência torna-se um elemento crítico de grande importância em processos de inferência estatística como, por exemplo, quando queremos estimar valores de porosidade em uma malha tridimensional a partir dos dados de perfis de poços perfurados.

A distribuição das realizações do par de VA =1 e =2 é caracterizada pela função distribuição de probabilidade conjunta que, na prática, é estimada pela proporção de pares de valores abaixo dos respectivos limites.

Graficamente, o grau de independência pode ser analisado pela dispersão dos dados, plotados em um gráfico cartesiano de =1 e =2, em torno da linha de 45°.

O momento de inércia deste diagrama é conhecido por semi-variograma, dado pela expressão, que nada mais é do que a diferença média quadrática entre os dois componentes de cada distribuição.

Quanto maior o valor do semi-variograma, maior é a dispersão em torno da linha de 45° e menor a relação entre as duas variáveis.

O semi-variograma representa uma medida da variabilidade, ao passo que a covariância e o coeficiente de correlação são medidas de similaridade.

O caso mais freqüente dos problemas geológicos de interpolação é o de se ter a medida de um mesmo atributo em duas posições diferentes separadas por um vetor t.

Neste caso, a variável aleatória, deve ser inferida, para fins de mapeamento, a partir de um número finito de pontos amostrais.

Analisando os n pares de pontos amostrais do domínio A, podemos estimar as características da função semi-variograma pelo semi-variograma experimental.

Variando o vetor r, obtemos uma função vetorial que caracteriza a incerteza espacial da VA =(t) no domínio A.

Para a construção de um modelo matemático adotamos médias sobre a distribuição espacial de =(t) e =(t+r), baseadas em critérios geológicos que, via de regra, não podem ser provados ou refutados por testes estatísticos.

Os processos de ínferência estatística envolvem modelamento sobre várias realizações do par de VA =(t) e =(t+T).

Nos processos geológicos, entretanto, não é possível obter mais de uma realização destas VA.

Este problema é superado admitindo-se que o par de VA acima apresenta a mesma lei de distribuição para qualquer translação do vetor r, ou seja, a lei espacial é invariante por translação ou estacionaria.

Muitos fenômenos físicos apresentam uma capacidade infinita de dispersão, onde não se pode definir a variância a priori (C(0)) nem a covariância, mas pode-se definir o semi-variograma.

Nestes casos, pode-se relaxar as condições de estacionariedade, mantendo-se a condição i e admitindo-se a existência e estacionariedade somente do semi-variograma, ou seja, os incrementos possuem variância finita independente de t.

As duas principais características de um semi-variograma são comportamento na origem, que pode ser parabólico, linear ou pepítico, existência ou não de um patamar de estabilização do valor de y(r) à medida que r aumenta(amplitude ou "range" de correlação).

Para o tratamento matemático, são empregados os seguintes modelos teóricos para o modelamento dos semi-variogramas experimentais.

Todo o semi-variograma deve começar pela origem dos eixos.

Na prática, entretanto, normalmente se observa uma descontinuidade na origem, na maioria das vezes ocasionada por um patamar com valor em uma distância menor do que o menor espaçamento entre duas observações disponíveis.

Este efeito é conhecido como efeito pepita e caracteriza a ausência de correlação à escala de amostragem do estudo.

Para distribuições de variáveis aleatórias com características de mBf, estabelecem que as características estruturais dadas pelo semi-variograma obedecem a uma lei de potência.

Uma desvantagem do semi-variograma, como ferramenta estatística para estudar o comportamento e a correlação espacial de uma variável aleatória, é o seu limitado raio de ação, tendo significado até distâncias máximas aproximadamente iguais à metade do domínio.

As distribuições fractais, por outro lado, possuem correlações em todas as escalas, com longo alcance.

A determinação do parâmetro H por meio de semi-variogramas sofre, portanto, esta influência, sendo válida somente para pequenos espaçamentos t.

Para correlações de longo alcance, a análise R/S constitui-se em uma ferramenta mais apropriada.

Mostra o semi-variograma de um poço na mesma área estudada pela análise R/S do capítulo IV.

Mostra os resultados da análise R/S.

Observa-se claramente que o semi-variograma experimental não se ajusta mais ao modelo teórico a partir de r 100, ou seja, para espessuras maiores do que 20-25m.

A partir destas espessuras, o semi-variograma já começa a sofrer influências de uma deriva, muito provavelmente associada às espessuras de camadas litológicas atravessadas.

A análise R/S não é sensível a estas variações litológicas, que provavelmente se representariam como "crossover", uma vez que a quantidade de pontos não é suficiente para o seu registro, determinando, portanto, um valor de H com maior precisão para correlações de longo alcance.

O valor de H para a direção vertical é determinado de forma precisa por meio da análise R/S dos registros de poços.

Para os problemas de interpolação necessitamos caracterizar o valor de H na direção horizontal.

Propôs utilizar o mesmo valor da vertical, apoiado no fato de os processos geológicos atuantes na formação de rochas sedimentares afetarem grandes áreas, sujeitas às mesmas variações de clima e tempo.

Somente com a disponibilidade de mapas de contorno de propriedades que não estejam muito suavizados, deve-se preterir a hipótese acima e determinar H diretamente dos mapas, através de técnicas de estimativa da dimensão fractal como expostas no Capítulo I.

Utilizaram dados de poços horizontais e verticais para examinar a variabilidade de parâmetros de reservatórios, concluindo que os perfis destes poços podem ser caracterizados como rGf com dimensão fractal semelhante.

Também utilizaram dados de poços horizontais, observando que havia mudanças do valor de H da vertical para a horizontal, o que inviabilizaria assumir a hipótese acima.

No conjunto de dados disponíveis para esta tese não temos poços horizontais para confrontar estas duas hipóteses de trabalho.

Uma vez que os mapas geológicos normalmente são suavizados, não apresentando resolução para a variabilidade em pequena escala, não nos parece aconselhável obter o valor de H através deles.

Enquanto não dispusermos de elementos mais significativos, adotaremos a mesma hipótese para a determinação de H na direção horizontal, calculando um valor médio para os poços de uma área.

A idéia básica em um processo de interpolação espacial linear por técnicas de regressão é estimar o valor desconhecido de uma variável a partir de uma combinação linear de alguns valores conhecidos em pontos próximos ao ponto a determinar.

As informações requeridas para este procedimento são os valores conhecidos para a propriedade a estimar e uma informação estrutural, como por exemplo, um semi-variograma.

O processo de krigagem é uma técnica de interpolação que fornece o melhor estimador linear não tendencioso de uma variável, a partir de um conjunto de amostras, requerendo o conhecimento prévio dos momentos de segunda ordem, covariância e semi-variograma, os quais normalmente podem ser inferidos.

A característica principal da krigagem é minimizar o erro cometido ao se estimar o valor de uma variável (t), representando uma propriedade a ser mapeada, num ponto arbitrário t do domínio.

A estimativa é feita a partir de uma combinação linear dos dados amostrais, de tal forma que o valor estimado f(t) seja dado por.

Onde a simboliza o ponto amostrai.

Uma vez que admitimos a nossa variável aleatória como apresentando uma certa continuidade, aceitando a condição de estacionariedade do fenômeno, temos que a esperança matemática dos dados estimados deve ser igual à esperança dos dados reais.

Efetuando as operações algébricas convenientes, como bem demonstrado nos livros que tratam de krigagem , o problema passa a ser o de determinar os pesos Aa que minimizem a variância o2k, sujeitos à condição.

Para minimizar uma função de A devemos fazer com que as derivadas parciais em relação aos AJs sejam iguais a zero.

Como temos uma relação condicionante, podemos aplicar o método dos multiplicadores de Lagrange (/#), definindo uma nova função.

O sistema de krigagem resulta diretamente ao se fazerem as derivadas parciais de 0 em relação às incógnitas A e /# iguais a zero.

Reescrevendo as equações, já em termos de semi-variograma.

O semi-variograma, portanto, é ferramenta estatística de fundamental importância para a solução dos problemas de krigagem.

Para familiarização com sistemas de krigagem e verificação das propriedades estudamos dois problemas simples de interpolação e extrapolação entre três e quatro pontos conhecidos, para um segmento de tamanho unitário T, com os mesmos extremos do caso anterior para quatro pontos.

A estrutura de mBf é dada pelo semi-variograma de lei de potência utilizado, estudando-se a sensibilidade do método para valores diferentes de H.

Para valores de H < 0,5 evidencia-se um caráter antipersistente na interpolação.

Para H = 0,5 a interpolação é linear e para H > 0,5 observa-se persistência, mantendo-se a continuidade da tendência da interpolação.

O mesmo se verifica para extrapolação à direita e à esquerda dos dados.

Estas observações são semelhantes àquelas efetuadas, em um contexto diferente ao da krigagem.

Para interpolações e extrapolações de dados petroffsicos de perfis, o expoente H é da ordem de 0,8 a 0,9 , o que mostra a importância de se familiarizar com o comportamento persistente do processo.

Em muitos estudos de reservatórios não estamos interessados somente no melhor estimador de uma variável em um determinado ponto, mas sim, no impacto da variabilidade da distribuição de uma propriedade no processo.

Este objetivo é alcançado com o auxílio da simulação estocástica, onde a principal meta é reproduzir a estrutura da função de autocovariãncia da distribuição original.

Para os trabalhos desta tese adotamos um método simples e direto desenvolvido no âmbito da computação gráfica, descrito de forma bastante didática e com algoritmos.

Este método já foi aplicado na área petrolífera, sendo conhecido por adições sucessivas aleatórias.

Com ele se produzem múltiplas distribuições equiprováveis de uma propriedade, com uma estrutura de correlação de um mBf com intermitência medida pelo parâmetro H, definido previamente.

O primeiro passo consiste em determinar um valor interpolado para o ponto médio entre dois pontos amostrais.

Esta interpolação pode ser efetuada por um método "spline", ou então, como é o nosso caso, por um processo linear de krigagem.

O segundo passo é adicionar um componente aleatório ao valor, que preserve as suas características espaciais.

O processo passa a ser recursivo, incorporando-se os valores assim determinados ao banco de dados, interpolando-se novamente para o ponto médio da nova escala e adicionando-se outro componente aleatório.

A premissa básica da qual partiu é supor que os incrementos sucessivos de uma variável f(t) sejam estacionários, obedecendo â lei de potência.

A interpolação para o ponto médio é feita por krigagem, com a posterior adição de um componente aleatório D,, representado por um deslocamento aleatório gaussiano de média 0 e variância A,2.

Como observado, este método não preserva a estacionariedade do sistema.

Entretanto, é um método muito utilizado para produzir simulações de paisagens e cadeias de montanhas em computação gráfica, embora gere certos alinhamentos indesejáveis nas figuras, que correspondem justamente às primeiras interpolações.

A variante proposta consiste em acrescentar um deslocamento aleatório Dn a todos os pontos do estágio n, e não somente aos pontos ínterpolados.

O autor acima acredita que esta técnica permite contornar o problema da perda de estacionariedade.

Outra vantagem deste segundo método é o fato de permitir a interpolação para pontos com um fator de escala r qualquer, não necessariamente igual a 0,5 como no caso anterior.

Para atender às exigências do semi-variograma, é necessário adicionar um componente aleatório Dn a todos os pontos do estágio n, que tenha por variância.

Este parâmetro adicional r pode mudar a aparência do fractal.

A feição do fractal controlada pelo parâmetro r é denominada de lacunaridade.

Podemos novamente desenvolver o mesmo raciocínio matemático para a interpolação entre dois pontos,amostrados de uma populção gaussiana (0,0), com escala T.

Após resolver o problema algébrico, chegamos ao valor da variância da perturbação aleatória no passo n.

Mostra uma aplicação deste método para o problema dos três pontos estudado na krigagem.

Em todas as simulações realizadas observamos que há a preservação da variância total da distribuição, porém o semi-variograma teórico não é preservado.

Os semi-variogramas das simulações coincidem com o da interpolação.

Por outro lado, este método não preserva os valores originais, uma vez que as adições aleatórias são efetuadas sobre todos os pontos do domínio, inclusive os amostrais.

Desta forma, a simulação estocástica por adições sucessivas aleatórias não é condicional no sentido estrito.

Estamos propondo nesta tese um método para condicionar este procedimento de simulação.

Partimos da premissa que, no ponto amostrai, temos uma realização da variável aleatória representativa da propriedade em estudo.

Devido às características de unicidade da amostragem em fenômenos geológicos, conforme discutido no início deste capítulo, aceitamos esta realização da VA como correspondente ao evento certo, ou seja, a sua probabilidade de ocorrência é igual a 1.

Desta forma, a variabilidade aleatória neste ponto é nula, o que eqüivale a dizer que Aff2 = 0.

À medida que nos afastamos do ponto amostrai, a incerteza na determinação do ponto interpolado aumenta, supondo-se que a maior variabilidade deva ocorrer a distâncias acima do alcance ou área de influência da informação.

Assim, A2 cresce à medida que nos afastamos dos pontos amostrais até um limite superior, em nosso caso tomado igual à variância de "ensemble" dos dados.

Uma primeira solução para este problema foi obtida considerando-se a variância o2 de onde.

M = posição à esquerda do ponto a interpolar, j = posição à direita do ponto a interpolar e d = distância do ponto à esquerda ao ponto a interpolar.

Para a interpolação inicial ao ponto médio, portanto, fazemos = (ensemble).

O valor de dos novos pontos ínterpolados no estágio n > 1 é obtido pela fórmula acima, ao passo que nos pontos interpolados deste mesmo estágio usa-se a mesma fórmula de recorrência.

Mostra um exemplo de interpolação por este processo, para H = 0,5 e H = 0,8, com várias sementes de números aleatórios, aplicado ao mesmo problema dos três pontos acima citado.

Observa-se que as simulações passaram a ser condicionadas aos pontos de observação, mas surgiram feições do tipo "bico" no ponto médio entre as amostras, devido principalmente às próprias características do processo de interpolação por krigagem e, secundariamente, ao processo da interpolação da variância, pelo qual os pontos serão perturbados a cada iteração.

Para valores de H > 0,5 este efeito é um pouco mais suave, porém ainda está presente.

Estas feições não são desejáveis em qualquer processo de inferência estatística, podendo ser comparáveis aos alinhamentos observados em suas figuras de paisagens.

Conforme dissemos acima, a informação do ponto amostrai tem um alcance de influência.

Baseado neste fato, estudamos então um método híbrido entre a simulação não condicional de Voss e a nossa proposta acima.

Este alcance da informação deve ser obtido de fontes externas ao processo de interpolação, quer por conhecimento prévio da geologia, quer por estudos de variografia ou outra ferramenta que possa indicar as características estruturais da propriedade a ser interpolada.

A filosofia desta nova proposta consiste, portanto, em se utilizar o processo de interpolação de Voss nos pontos situados fora do alcance da informação, mesclando-se com a nossa proposta inicial para pontos a distâncias menores que este alcance.

Para controlar o cálculo correto da variância a ser aplicada em cada ponto para cada estágio de interpolação utilizamos uma função tangente hiperbólica.

Este valor de a2 passa então pelo processo de recorrência para as interpolações sucessivas.

O parâmetro 0 controla efetivamente a influência do alcance da informação.

Em nossos exemplos a distância total entre dois pontos amostrais foi de T = 50, obtendo-se um valor de k = 80000.

Se multiplicarmos o valor de T por um fator b qualquer, o valor de k deve ser multiplicado por um fator b2, podendo-se então calcular o valor correspondente de fi.

Analisando a fórmula temos que, para valores altos do argumento da tangente hiperbólica, seu valor se aproxima de 1, o que faz com que a variância calculada se aproxime da mesma calculada pelo método de Voss.

Este fato ocorre para informação com pequenas distâncias de influência e/ou para interpolações em pontos localizados a grandes distâncias da informação.

Quando o argumento da função for pequeno, o valor da tangente hiperbólica tende a zero, o que faz com que a variância calculada se aproxime da proposta desta tese.

Este resultado é provocado por interpolações em pontos próximos à informação e/ou para grande alcance da influência da informação.

O conhecimento das correlações espaciais da propriedade a ser interpelada permite o correto dimensionamento do parâmetro 0, permitindo o modelamento de situações que vão desde o efeito pepita, ou seja, correlação inferior á distância mínima de amostragem e interpolação, até correlação de longo alcance.

Mostram o resultado deste método aplicado ao problema dos três pontos mencionado anteriormente, para diversos valores de H, 0 e sementes de números aleatórios.

Este procedimento foi aplicado em interpolação estocástica de perfis de poços.

Mostra um exemplo para três perfis teóricos, um em cada extremidade e um no meio do intervalo, simbolizando uma camada de reservatório envolvida por duas camadas de rochas não-reservatório.

O valor de 0 arbitrado foi de 800.

Apresenta-se um caso real de três perfis de GR.

A resolução da interpolação horizontal pode ser adequada à malha geoestatística, ou outra mais conveniente, para evitar problemas de mudança de escala.

O valor de H utilizado foi de 0,887, obtido das análises R/S dos três poços.

A variografia destes dados indica uma distância de correlação da ordem de 12,5, obtendo-se um valor de fi igual a 512.

Como conclusão, podemos dizer que a variografia e a análise R/S constituem técnicas complementares para o conhecimento da distribuição espacial de VA.

O método de simulação estocástica de adições sucessivas aleatórias foi condicionado às informações disponíveis com sucesso, tornando-se uma ferramenta auxiliar útil ao estudo da variabilidade e sua influência em estudos de reservatórios de hidrocarbonetos.

Recomendamos prosseguir os estudos para desenvolver novas técnicas de interpolação não-lineares, a partir dos mesmos fundamentos da krigagem, com vistas ao aproveitamento do parâmetro A da análise R/S, informação esta que não é utilizada.

Para a simulação estocástica, estão em aberto ainda a inclusão de outras técnicas mais sofisticadas do que a de adições aleatórias para a geração de distribuições fractais, que constituiriam uma seqüência natural desta tese.

A geometria fractal é uma ferramenta útil para caracterizar os fenômenos geológicos e mostrou-se adequada para atender às necessidades da caracterização de reservatórios de hidrocarbonetos.

As famílias de funções mBf e rGf são importantes para o modelamento de perfis elétricos de poços, bem como de propriedades petrofísicas deles derivadas, como a porosidade e a permeabilidade.

A equação logística prove um valioso banco de dados para a calibração do algoritmo para efetuar a análise R/S e o entendimento de sua robustez estatística para a identificação de mudanças no regime fractal ("crossovers").

A análise R/S é uma ferramenta estatística com potencial para caracterizar o grau de intermitência de uma curva de perfil, através do parâmetro H, não se observando fenômenos de "crossover" nas escalas estudadas.

Os valores de H > 1/2 mostram que estes registros apresentam correlação em grande escala na direção vertical.

A ausência de "crossovers" pode ser explicada pelo fato de a seção sedimentar estudada ser constituída praticamente só por intercalações de folhelhos e arenitos, com exceção da porção basal, onde ocorrem pequenas espessuras de carbonatos, não havendo amostragem suficiente para gerar um possível "crossover".

Outras ferramentas geoestatísticas, como o variograma e o coeficiente de correlação, estão sujeitas ao efeito de deriva provocado pelas diferentes camadas geológicas, o que limita a sua utilização para caracterizar somente a pequena escala na direção vertical.

Para os dados de perfis disponíveis nesta tese, os valores de H variaram.

Os valores dos parâmetros entre as diversas curvas em um mesmo poço mostram-se próximos, indicando a utilidade da análise R/S para identificar HeA usando diversas propriedades físico-químicas.

O método de adições sucessivas aleatórias foi generalizado para permitir o condicionamento aos dados originais em uma simulação estocástica, gerando distribuições de propriedades de rocha que podem ser utilizadas em estudos de reservatórios de hidrocarbonetos.

A incorporação do parâmetro fi para monitorar o alcance da influência de um ponto amostral constitui uma feição interessante para o método de adições sucessivas aleatórias.

Estudar a aplicação da análise R/S em perfis de mergulho (dipmeter), que, por terem maior resolução de amostragem que os outros perfis, podem ser de grande utilidade para a caracterização correta do expoente H e, portanto, da dimensão fractal.

Estudar o desenvolvimento de técnicas geoestatísticas não-lineares nos mesmos moldes da krigagem, que propiciem o aproveitamento do parâmetro A além de H, gerados pela análise R/S.

Nos procedimentos de krigagem simples e ordinária, por serem lineares, este parâmetro é eliminado por simplificação de variáveis, não sendo utilizado.

Desenvolver o algoritmo para possibilitar a realização de simulação estocástica pelo método generalizado de adições sucessivas aleatórias com maior número de poços, não alinhados (simulação a 3-D).

Estudar a implementação de outras técnicas mais sofisticadas do que a adição sucessiva aleatória para gerar distribuições de caráter fractal, que constitui uma extensão natural desta tese.