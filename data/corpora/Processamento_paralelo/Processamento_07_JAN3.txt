O processo de Computação de Alto Desempenho (SCAD) são importantes ferramentas para a física teórica e experimental onde aplicações típicas necessitam de grande poder de processamento, redes de alta velocidade e armazenamento de grandes massas de dados.

Neste trabalho apresentamos o SCAD do Centro Brasileiro de Pesquisas Físicas CBPF/MCT abordando as duas principais linhas de ação.

A primeira está voltada para o ambiente de Cluster de microcomputadores, sua operacionalização e funcionalidade, relatando suas características de hardware e software, seus sub-sistemas de gerenciamento e monitoração e também alguns projetos/aplicações que já o utilizam de maneira independente.

Na segunda apresentamos o Projeto Grid local dando uma atenção introdutória ao sistema Globus e suas aplicações.

A demanda por computação de alta performance é uma característica de instituições de pesquisa em física.

Diversos grupos de pesquisa empregam métodos computacionais intensos e complexos tanto para simulações numéricas quanto para o processamento de dados experimentais.

A capacidade de processamento dessas instituições vem crescendo significativamente, ao longo dos anos à medida que processadores e estações de trabalho cada vez mais poderosas vão surgindo no mercado.

Com o desenvolvimento das tecnologias de comunicação em redes as instituições vêm disponibilizando parte de seus recursos computacionais a fim de alcançar um maior potencial através de técnicas de processamento distribuído.

Este é o cenário de materialização do projeto Grid onde diversos centros e grupos de pesquisas estão interessados em implantar uma malha computacional geograficamente distribuída alcançando assim uma alta capacidade de processamento.

As áreas de aplicações para esta malha são por exemplo processamento de grande volume de dados para a física de altas energias, a biologia (processamento de imagens médicas e a identificação e mapeamento dos genes no DNA) e áreas dedicadas a análise quantitativas oriundas de observações da terra.

No caso do CBPF são desenvolvidas as seguintes atividades computacionais, simulações numéricas (cálculos de estruturas moleculares, métodos de Monte-Carlo, modelagem ambiental), ajustes matemáticos de dados experimentais, cálculo algébrico, processamento de sinais e imagens e redes neurais.

Para atender essas necessidades computacionais o CBPF criou o Projeto SSOLAR atuando em duas áreas, a construção de um ambiente em cluster de computadores e a participação no projeto Grid.

A fim de atender a demanda de computação científica o CBPF adquiriu um Cluster de computadores do tipo Beowulf.

Dessa forma, o CBPF conta atualmente com uma infra-estrutura central de processamento baseado no Cluster da empresa Microway, com 39 processadores AMD Athlon XP 1800+, 50 GBytes de memória RAM e 868 GBytes de disco rígido, interligados por uma rede em tecnologia Gigabit Ethernet.

O sistema operacional utilizado é o Linux RedHat com compiladores C/C++, FORTRAN77 e FORTRAN90, biblioteca MPI, sistema de gerência de fila OpenPBS (Portable Batch System)  e de monitoramento Ganglia.

Cluster Beowulf é o nome dado à arquitetura de multicomputadores utilizados para computação paralela ou distribuída, que oferece baixo custo e alta capacidade de processamento.

É normalmente composto por um conjunto de microcomputadores comuns formado por um nó mestre e nós escravos conectados via rede, rodando um sistema operacional paralelo.

Nesse modelo, o nó mestre tem a função de controlar o cluster, distribuir os arquivos e as tarefas para os nós escravos, além de servir de gateway para conexão externa.

Até o momento identificamos duas formas de utilização desse ambiente no CBPF.

A primeira está baseada na submissão de programas desenvolvidos em linguagem C ou FORTRAN, por grupos de pesquisa do próprio instituto ou por meio de suas colaborações.

A segunda está caracterizada pela utilização de softwares comerciais como Mathematica, Matlab e Maple.

A utilização do segundo caso, vem sendo solicitada pela grande maioria dos usuários devido principalmente a maior interatividade e versatilidade desse tipo de ferramenta no auxílio a problemas de física.

Cluster de microcomputadores para cálculo científico do CBPF.

Todos os nós têm dois processadores sendo seis deles com um espaço de endereçamento de 4 GB e os outros treze com 2 GB.

A troca de informação e a conexão à rede local é feita por uma rede de alta velocidade de 1 Gbps.

O ambiente em cluster forma uma grade (grid) de computadores que pode ser interligada em ambiente semelhantes em outras instituições em outros países.

O projeto Grid liderado pelo CERN (Laboratório Europeu de Pesquisas em Física Nuclear) tem um caráter multidisciplinar e está centrado em áreas com uso intensivo de computação e de comunicação em redes.

A infra-estrutura prevista para o desenvolvimento do Grid no CBPF consiste na ampliação do cluster e na interligação com o Grid computacional nacional.

O projeto Grid do CBPF está seguindo o cronograma do CERN estando organizado em duas fases principais.

Na primeira fase, que vai do ano de 2002 a 2004 pretende-se montar o protótipo do Grid, tendo como principais objetivos.
Preparar o ambiente computacional desenvolvendo uma infra-estrutura e ferramentas comuns de softwares para as aplicações de física.

Estabelecer as tecnologias necessárias, a estrutura de redes e a administração do Grid.

Nesta etapa está prevista também a validação das tecnologias e a construção de ambientes cada vez mais complexos.

Na segunda fase, entre os anos de 2005 a 2007 pretende-se participar da operação do Grid mundial na área da física.

O CBPF tem hoje três grupos de pesquisa envolvidos nos experimentos do CERN.

O principal interesse do CBPF é a utilização do Grid para a solução de problemas da física por meio de uma infra-estrutura computacional maior do que a existente localmente, integrada e compartilhada com grupos colaboradores.

A estrutura elaborada para o funcionamento do Grid será formada por uma série de camadas hierárquicas denominadas "Tiers", com um núcleo central no CERN ("Tier 0") ligados a centros regionais em diversos países.

A integração dos recursos computacionais de cada um dos "Tiers" será feita por meio de um software de gerenciamento de recursos computacionais e de conexões de redes em alta velocidade.

Dessa forma, é desejável implementar no CBPF uma unidade do tipo "Tier 2" a fim de satisfazer as necessidades computacionais dos grupos participantes nos experimentos do CERN.

Deve ser levado em conta que o Grid não é só uma infra-estrutura para os experimentos no CERN, podendo o CBPF dar uma contribuição a outras áreas da física como por exemplo Física Estatística, Magnetismo, Nanotecnologia, Cosmologia que necessitam também de poder computacional.

A proposta do Grid no CBPF está na integração de ambientes heterogêneos de computação incentivando a utilização de softwares livres e o desenvolvimento dos softwares locais dos grupos de pesquisas.

Na fase atual do projeto dedicamos três computadores, a fim de testar e validar as tecnologias envolvidas em um grid experimental local.

O ponto importante na organização de um ambiente grid são os serviços de redes especializados que são compartilhados entre aplicações e usuários, implementados em uma camada intermediária localizada entre a rede e a aplicação.

Atualmente identifica-se duas versões mais difundidas para a camada intermediária e serviços de grid, são elas, Globus e Grid-Engine.

O CBPF adotou o Globus para o gerenciamento dos recursos computacionais.

O projeto Globus é liderado pela Divisão de Ciências da Computação e Matemática do Laboratório Nacional de Argonne, do Instituto de Ciências da Informação da Universidade do Sul da Califórnia, e o Laboratório de Sistemas Distribuídos da Universidade de Chicago sendo um pacote de software de código aberto e estando a disposição aos usuários para sua utilização.

Estamos utilizando o Globus Toolkit 22, Grid Packaging Technology, Grid APIs, Essential Grid Tools e Essential Grid Services.

Os principais serviços do sistema Globus são o gerenciamento de recursos, comunicação, serviço de informação e serviço de segurança.

Para utilização do Globus é necessário a obtenção de certificados para cada computador pertencente ao grid local ("host certificates").

Além disso é necessário um certificado para cada usuário ("user certificates") autorizando a utilizar o ambiente completo.

Todos os certificados são autenticados pela organização Globus (globus org).

Este ambiente completo de certificados, computadores em rede e usuários definem um ambiente em grade computacional.

O ambiente completo de certificados, computadores (recursos) em rede e usuários definem uma grade computacional.

A partir dessa estrutura é possível executar comandos de envios de jobs" no grid.

O "globus-job-run" é o comando mais simples para o envio de "jobs" no grid.

A sintaxe define o computador e o programa a ser executado.

Os comandos para submeter "jobs" no Globus (globus-job-run, globus-job-submit e mpirun) são "scripts shell" que utilizam o comando básico "globusrun".

O "globusrun" pode também ser utilizado para envio de "jobs" especificados por meio da linguagem RSL (Resource Specification Language).

A RSL é uma linguagem que descreve os recursos disponíveis em cada computador pertencente ao grid e a forma de execução dos "jobs".

Entre as principais vantagens do Globus podemos destacar a facilidade para a autenticação dos usuários em múltiplos computadores, autenticação única para todos os recursos, a presença de uma infra-estrutura de segurança permitindo autenticação e comunicação segura em uma rede aberta, no caso do CBPF, a utilização pela comunidade de física.

O Grid permite também o uso de técnicas de programação em paralelo (passagem de mensagens).

O ambiente MPI ("Message Passing Interface") está disponível no Grid através da versão MPICH-G2 (versão portátil do MPI para o Globus).

O padrão MPI define uma biblioteca de rotinas que implementam uma comunicação ponto a ponto onde a operação "send" é usada para iniciar uma transferência de dados entre dois programas concorrentes e a operação "receive" é usada para obter dados do sistema no espaço de memória da aplicação.

Existem ainda operações coletivas ("collective") envolvendo múltiplos processos.

Recentemente o Globus foi instalado no Cluster do CBPF adicionando a este a característica de um ambiente Grid.

Está em estudo a integração da versão PBSPro ao Globus permitindo o Cluster atuar como Grid.

A interface PBS-Globus permite ao usuário enviar "jobs" de forma simplificada ao Globus.

O processo é tratado diretamente pela fila do PBS, sendo possível o monitoramento com comandos PBS normais.

Uma importante vantagem é que "jobs" PBS podem ser executados em qualquer lugar do Grid.

Neste trabalho apresentamos o projeto SSOLAR estabelecendo um ambiente computacional de alto desempenho, em Cluster e Grid, para a simulação e análise de dados experimentais intensos no CBPF.

O ambiente em cluster está hoje em fase inicial de utilização pelos grupos de pesquisa do CBPF.

O ambiente em Grid conta com uma infraestrutura mínima para capacitação e formação de recursos humanos na área de engenharia e física que permitirá a montagem e a operação do sistema.

Este ambiente está funcionando atualmente com o sistema Globus como camada intermediária para habilitação de serviços de Grid.

Ambos os projetos deverão ser integrados em um único ambiente de alto desempenho no futuro.

Existem ainda dificuldades para que se utilize todo o potencial de programação em paralelo.

Será necessário para isso que o desenvolvimento dos softwares locais dos grupos de pesquisa integrem ou utilizem as bibliotecas MPI.

Da mesma forma, está sendo exigido por usuários do sistema a disponibilização de softwares comerciais que apresentem maior versatilidade e interface gráfica.

