Diversas políticas de escalonamento para aplicações paralelas voltadas a ambientes computacionais distribuídos têm sido propostas.

Embora tais políticas apresentem bons resultados, elas são, geralmente, avaliadas em cenários específicos.

Quando o cenário muda, com diferentes ambientes distribuídos e condições de carga, essas políticas podem ter seu desempenho deteriorado.

Nesse contexto, este trabalho apresenta um estudo comparativo envolvendo dez políticas de escalonamento avaliadas em diferentes cenários.

Cada uma das políticas foi submetida a uma combinação de quatro cargas de trabalho de ocupação da UCP e três variações da taxa de comunicação média entre os processos, utilizando a rede.

Foram considerados ainda três sistemas distribuídos distintos, dois clusters, com diferentes quantidades de nós, e um grid computacional.

Foi utilizada a simulação com ambientes próximos ao real e cargas de trabalho obtidas de modelos realísticos.

Os resultados demonstraram que, embora as políticas sejam voltadas a ambientes computacionais paralelos e distribuídos, quando o cenário muda, o desempenho cai e a ordem de classificação entre as políticas se altera.

Os resultados permitiram ainda demonstrar a necessidade de se considerar a comunicação entre os processos durante o escalonamento em grids computacionais.

Os avanços tecnológicos obtidos nas últimas décadas, principalmente no que se refere ao desenvolvimento dos microprocessadores e das redes de comunicação, possibilitaram rápidas e profundas mudanças.

A computação, que era baseada unicamente no uso de computadores seqüenciais e centralizados, é caracterizada, atualmente, pela grande conectividade dos recursos, tornando cada vez mais comum o uso de Sistemas Distribuídos.

Sistemas Distribuídos são compostos por computadores autônomos, que interligados por uma rede de comunicação e utilizando software apropriado, coordenam suas tarefas.

Eles surgiram da necessidade de compartilhar recursos de modo eficiente, mas seu uso tem se estendido a diversos domínios.

Uma das áreas que se beneficiou dos Sistemas Distribuídos é a Computação Paralela.

A Computação Paralela explora a existência de tarefas concorrentes, que podem ser executadas em paralelo, a fim de obter um tempo de resposta menor.

Para dar suporte à Computação Paralela, utiliza-se um computador com múltiplos elementos de processamento (EPs), capazes de comunicar e cooperar para resolver grandes problemas mais rapidamente.

Uma forma de obter uma arquitetura com múltiplos EPs é utilizar um sistema distribuído.

Os avanços em capacidade de processamento, em tecnologias de rede e em ferramentas de software tornaram os Sistemas Distribuídos uma infra-estrutura conveniente para o processamento paralelo.

Essa convergência, entre Computação Paralela e Sistemas Distribuídos, é denominada Computação Paralela e Distribuída  e vêm se tornando bastante atrativa, especialmente por prover uma boa relação custo/benefício.

É preciso ressaltar, no entanto, que existem problemas com essa abordagem.

Nos Sistemas Distribuídos os elementos de processamento são, potencialmente, heterogêneos e são interligados por uma rede de comunicação compartilhada e de baixa velocidade.

Além disso, é preciso considerar que existem cargas de trabalho externas às aplicações paralelas.

Esses fatores tornam o software paralelo e distribuído ainda mais complexo e se refletem diretamente no desempenho do sistema, no que se refere à adequada utilização dos recursos disponíveis.

O escalonamento das tarefas para os recursos disponíveis nesses ambientes se torna uma tarefa de extrema importância.

O escalonamento refere-se à atividade de alocar os recursos disponíveis entre as tarefas que compõem cada aplicação.

Em qualquer sistema, um bom escalonamento, baseado nos objetivos propostos, é determinante para obter um bom desempenho.

O escalonamento em Sistemas Distribuídos tem sido largamente estudado.

Há uma intensa atividade de pesquisa, buscando formas eficientes de alocar aplicações paralelas nos principais sistemas distribuídos utilizados para processamento paralelo, Network of Workstations (NOW), clusters e grids computacionais.

Muitos conceitos e técnicas utilizados para o escalonamento de aplicações em computadores paralelos não são adequados quando se trata de um sistema distribuído, havendo a necessidade de adaptar essas técnicas ou criar novas técnicas que garantam um bom desempenho.

As decisões comuns, que devem ser tomadas pelo software que realiza o escalonamento, são determinadas por políticas de escalonamento.

As políticas de escalonamento determinam, por exemplo, quais aplicações obterão acesso aos recursos disponíveis, a quantidade de recursos que serão destinados para as aplicações e a localização desses recursos.

Para obter um bom desempenho é necessário empregar boas políticas de escalonamento, adequadas ao ambiente computacional alvo e a carga de trabalho esperada.

Clusters e grids são uma alternativa interessante e viável para a execução de aplicações paralelas e têm sido largamente empregados.

Enquanto máquinas verdadeiramente paralelas possuem um alto custo de aquisição e manutenção, além de grande dependência de um fabricante, os sistemas paralelos distribuídos apresentam uma excelente relação custo/benefício e uma grande flexibilidade.

Além disso, a disponibilidade de diversas ferramentas de software facilitam o desenvolvimento de uma aplicação paralela.

Essas ferramentas são particularmente interessantes porque permitem que aplicações paralelas possam ser portáveis entre diferentes sistemas computacionais paralelos.

Exemplos dessas ferramentas são Parallel Virtual Machine  e o projeto Globus  para grids computacionais.

Devido à grande evolução dos sistemas paralelos e distribuídos, diversas políticas de escalonamento para aplicações paralelas têm sido propostas para esses ambientes.

Essas políticas têm atraído a atenção de pesquisadores, uma vez que os resultados obtidos têm indicado bons desempenhos.

Entretanto, tais políticas são avaliadas com o objetivo apenas de demonstrar sua validade e/ou superioridade sob um determinado aspecto.

Sob diferentes condições de carga, a política pode ter seu desempenho deteriorado, o que, na maioria das vezes, não é verificado.

Analisar o comportamento de uma política de escalonamento sob diferentes cenários é uma importante tarefa para se compreender como a mesma se comportaria em um ambiente real e, assim, garantir um bom desempenho.

Diversos trabalhos comparam diferentes estratégias para o escalonamento em clusters, NOWs  e em grids.

Entretanto, nesses trabalhos não há a preocupação em verificar o comportamento da política de escalonamento sob diferentes condições de carga que podem ocorrer e nem sua aplicabilidade a outros ambientes distribuídos.

Uma política de escalonamento que apresenta um bom desempenho sob determinada carga de trabalho e ambiente distribuído pode ter seu desempenho reduzido quando o cenário muda.

O contrário também pode ocorrer.

Uma política que obtém mau desempenho sob determinada carga pode se comportar bem sob outra.

Este trabalho é motivado pela necessidade de verificar o comportamento de políticas de escalonamento para aplicações paralelas sob diferentes cenários.

Complementar o trabalho do grupo de pesquisa em que este trabalho se insere é também uma importante motivação para a definição e execução deste trabalho.

O grupo de pesquisa do Laboratório de Sistemas Distribuídos e Programação Concorrente (LaSDPC) Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (ICMC-USP) tem direcionado esforços nas linhas de pesquisa em que este trabalho se insere.

O grupo vêm acumulando conhecimento nas áreas de avaliação de desempenho de sistemas computacionais e no escalonamento de aplicações paralelas em Sistemas Distribuídos.

Seguindo a linha desse trabalho diversos trabalhos relacionados ao escalonamento foram desenvolvidos, dentre os quais pode-se destacar.
Especificação e implementação do AMIGO. Implementação de uma interface gráfica para o ambiente AMIGO.
Integração AMIGO-PVM e implementação da política Dynamic Policy Without Preemption. Integração AMIGO-MPI. Integração AMIGO-CORBA. Monitoração aplicada ao escalonamento em sistemas distribuídos e Análise de métricas de desempenho.
Definição de índices de carga para definir o grau de heterogeneidade de um sistema distribuído.
Definição de uma política de escalonamento para aplicações com alta comunicação na rede, Network Bound Scheduling Policy.
Aquisição do conhecimento de aplicações paralelas aplicado ao escalonamento de processos e definição da política GAS.
Estudo de caso para o escalonamento em grids computacionais. Definição de índices de carga para políticas de escalonamento memory-bound, VOORS. Um simulador para o escalonamento em ambientes paralelos e distribuídos heterogêneos.
Nesse contexto, o problema central estudado neste trabalho é a avaliação de desempenho de políticas de escalonamento para aplicações paralelas sob diferentes cenários.

O objetivo principal deste trabalho é analisar o comportamento de políticas de escalonamento voltadas a ambientes paralelos e distribuídos quando submetidas a diferentes condições de carga e quando aplicadas a diferentes ambientes computacionais distribuídos.

Dentre as contribuições esperadas com a execução deste trabalho, pode-se destacar as seguintes, Complementar trabalhos que propõem e avaliam políticas de escalonamento, apontando restrições e características inerentes às políticas que não foram identificadas nos trabalhos originais.

Como discutido, grande parte da avaliação de desempenho conduzida nos trabalhos que propõem novas políticas tem o objetivo apenas de validar a proposta.

Geralmente, as restrições e a aplicabilidade da política a diferentes cenários não é identificada.

Verificar a aplicabilidade de políticas de escalonamento voltadas a clusters em grids computacionais.

O escalonamento em grids é uma intensa atividade de pesquisa, motivada pelas restrições que esse ambiente impõe ao escalonador.

Políticas de escalonamento utilizadas em clusters podem ter sua aplicabilidade reduzida em grids, devido a tais restrições.

Verificar que política melhor se aplica a determinado cenário.

Um estudo, realizado aplicando uma avaliação de desempenho adequada, deve permitir analisar, comparativamente, diversas políticas e apontar aquela que obteve o melhor desempenho sob um determinado cenário estudado.

Um aspecto importante desse estudo é que o mesmo se aproxime ao máximo de um ambiente real.

Definição de uma sistemática para avaliar, comparativamente, políticas de escalonamento.

Poucos trabalhos tratam da metodologia de avaliação de desempenho de políticas e discutem técnicas para comparar políticas.

Pretende-se com este trabalho, revisar e apresentar técnicas aplicáveis para comparar políticas de escalonamento.

Analisar o impacto da comunicação entre os processos das aplicações em grids computacionais.

Grids são compostos por computadores pertencentes a diferentes organizações.

Entre essas organizações existe uma rede com alto atraso e baixa largura de banda (geralmente, a Internet).

Aplicações que se comunicam pela rede podem ter seu desempenho reduzido devido aos atrasos gerados pela rede de comunicação.

Esta dissertação está organizada em oito capítulos e dois apêndices, sendo o primeiro capítulo esta Introdução.

Os três capítulos seguintes destinam-se à revisão bibliográfica das áreas em que este trabalho se insere.

É tratada a Computação Paralela e Distribuída, destacando-se as arquiteturas utilizadas para a execução de aplicações paralelas.

Ferramentas disponíveis para a programação paralela em ambientes distribuídos também são discutidas.

O escalonamento em clusters, NOW e grids é tratado.

Detalhes inerentes a estes ambientes que interferem no escalonamento e, conseqüentemente, no desempenho, são tratados ao longo do capítulo.

Destina-se a revisar as técnicas empregadas na avaliação de desempenho.

A revisão apresentada nestes três capítulos visa fornecer ao leitor o embasamento necessário à compreensão deste trabalho.

É tratada a avaliação de desempenho no contexto específico do escalonamento, buscando enfatizar as escolhas realizadas neste trabalho com relação às cargas de trabalho, à métrica de desempenho e à utilização de simulação, como técnica de avaliação de desempenho.

As políticas de escalonamento estudadas são detalhadas, apontando seu funcionamento.

Além disso, as cargas de trabalho são analisadas, provendo detalhes das distribuições de grau de paralelismo, tempo de execução e utilização da rede.

O modelo de simulação empregado neste trabalho, assim como o simulador que o implementa são descritos com detalhes.

As extensões aplicadas ao simulador durante esse trabalho também são detalhadas.

A parametrização do modelo de simulação é discutida e, em seguida, os resultados são analisados.

Apresenta detalhes dos logs disponíveis no repositório Parallel Workload Archive, visando complementar a discussão apresentada a respeito dos modelos de carga de trabalho.

Tais modelos foram gerados a partir de logs, muito dos quais estão disponíveis nesse repositório.

São apresentados os intervalos de confiança para os experimentos conduzidos neste trabalho e é apresentado o modo como o cálculo foi efetuado.

A Computação Paralela e Distribuída é a convergência de duas áreas surgidas com motivações e características distintas, a Computação Paralela e os Sistemas Distribuídos, trazendo benefícios para ambas.

Essa convergência surgiu dos avanços tecnológicos que tornaram os Sistemas Distribuídos uma infra-estrutura de suporte à Computação Paralela.

Para dar suporte à Computação Paralela diversas arquiteturas podem ser empregadas.

Arquiteturas MIMD com memória distribuída têm sido usadas para aplicações que demandam grande potência computacional.

Exemplo são as arquiteturas de processamento maciçamente paralelo. Massively Parallel Processing (MPP), constituídas por um grande número de elementos de processamento (EPs) fortemente acoplados por uma rede de interconexão proprietária de alta velocidade.

Outra forma de obter uma arquitetura paralela com memória distribuída é utilizando um Sistema Distribuído (SD).

Um SD é logicamente similar a um MPP, custando uma fração do preço e apresentando-se bastante flexível (devido à independência de fabricante).

Os Sistemas Distribuídos têm evoluído bastante e possuem várias características desejáveis na computação paralela, transparência de acesso aos recursos, confiabilidade, tolerância à falhas.

A Computação Paralela sobre Sistemas Distribuídos, ou Computação Paralela Distribuída, surgiu como alternativa ao uso de supercomputadores paralelos caros, especializados e proprietários.

Os avanços obtidos em capacidade de processamento, tecnologia de rede e em ferramentas de software tornaram os Sistemas Distribuídos uma infra-estrutura conveniente para o processamento paralelo.

A Computação Paralela Distribuída, é, portanto, bastante atrativa.

A idéia básica é utilizar os computadores que compõem um sistema distribuído como elementos de processamento de uma máquina paralela virtual (ou ambiente paralelo virtual).

Entretanto é preciso ressaltar que existem desvantagens e problemas.

Técnicas e mecanismos antes utilizados na Computação Paralela nem sempre são convenientes na Computação Paralela e Distribuída.

Fatores característicos dos Sistemas Distribuídos, tais como heterogeneidade, atraso na rede e carga de trabalho externa às aplicações paralelas, tornam a utilização e o gerenciamento desses sistemas tarefas complexas.

Neste capítulo são abordados conceitos inerentes à Computação Paralela Distribuída.

Para facilitar o estudo, Computação Paralela e Sistemas Distribuídos são tratados separadamente.

Em seguida, a convergência das duas áreas é apresentada em termos dos sistemas computacionais distribuídos empregados para executar aplicações paralelas e as ferramentas de software empregadas para esse fim.

O objetivo desse capítulo é identificar características do hardware e do software básico que influenciam no desempenho.

Embora os computadores uniprocessados tradicionais tornem-se mais rápidos, existem aplicações que não podem ser executadas com eficiência em arquiteturas seqüenciais.

Algumas aplicações, em virtude do uso de algoritmos complexos e/ou conjuntos de dados extensos, demandam grande potência computacional, outras são naturalmente paralelas.

Com o objetivo principal de prover melhores desempenho e adequação para essas aplicações, surgiu a Computação Paralela.

A Computação Paralela explora a existência de tarefas concorrentes, que podem ser executadas em paralelo a fim de obter um tempo de resposta menor.

Para dar suporte à Computação Paralela utiliza-se um computador com múltiplos EPs, capazes de comunicar e cooperar para resolver grandes problemas mais rapidamente.

Paralelismo não é um conceito novo em computação.

Por exemplo, no nível de instruções são comuns organizações pipeline, possibilitando o processamento paralelo de instruções e, conseqüentemente, um desempenho maior, se comparado ao processamento puramente seqüencial.

Embora o paralelismo de baixo nível apresente melhorias, só é possível obter grande aumento de desempenho, a um fator teoricamente ilimitado, através da replicação de toda a UCP.

Um único processador possui limitações físicas.

A velocidade do circuito não pode ultrapassar a velocidade da luz e o desenvolvimento de processadores já esbarra em problemas de refrigeração e nos efeitos da mecânica quântica.

Esses fatores, aliados às inovações tecnológicas (como a VLSI) e o conseqüente barateamento dos componentes de hardware, têm tornado a construção de computadores paralelos bastante atrativa.

Existem também motivações relacionadas ao software.

A tolerância a falhas, obtida através da replicação de EPs, é uma característica altamente desejada para aplicações que necessitam de confiabilidade.

Entretanto, é importante ressaltar que o software é o grande desafio dessa área.

Um computador paralelo tem pouca ou nenhuma utilidade sem um bom programa paralelo.

Embora várias técnicas de programação paralela tenham sido desenvolvidas, a construção de aplicações paralelas é ainda uma onerosa ta-refa para o programador.

A divisão de uma aplicação em processos, que possam ser atribuídos aos EPs de forma eficiente, e a sincronização são tarefas extremamente complexas.

Quando dois ou mais processos inicializaram e não terminaram sua execução diz-se que existe concorrência.

Geralmente, existe disputa entre esses processos pelo uso de um processador.

Para que haja paralelismo é preciso que dois ou mais processos estejam em execução.

Assim, processos paralelos são também concorrentes, mas o contrário nem sempre é verdade.

O Paralelismo implica no uso de um sistema paralelo, composto por múltiplos elementos de processamento.

Já a concorrência pode ocorrer tanto em sistemas paralelos quando em sistemas com um único processador.

Em sistemas uniprocessados tem-se um pseudoparalelismo, a execução de cada processo em pequenos intervalos de tempo dá a impressão de que os processos executam simultaneamente.

Granulosidade ou nível de paralelismo refere-se ao tamanho da unidade de trabalho executada pelos processadores, sendo classificada em fina, média e grossa.

A granulosidade fina indica um paralelismo a nível de operações ou de instruções, sendo, geralmente, implementada em hardware.

Na granulosidade média, as unidades de trabalho são constituídas de blocos de instruções, geralmente, esse nível de paralelismo exige suporte de linguagens de programação paralela.

No último nível da classificação, a granulosidade grossa, o paralelismo é dado a nível dos processos ou tarefas, executando simultaneamente.

Os processos e/ou threads que compõem uma aplicação paralela podem ser estruturados sob duas abordagens principais, o paralelismo de dados e o paralelismo funcional.

No paralelismo de dados, também denominado Single Program Multiple Data (SPMD), os dados a serem processados são divididos em porções, geralmente do mesmo tamanho.

Cada processador executa o mesmo código, operando sobre uma porção diferente dos dados.

Daí a denominação paralelismo de dados, o paralelismo obtido se deve à decomposição dos dados entre diversos EPs.

No paralelismo funcional ou Multiple Program Multiple Data (MPMD), cada tarefa possui um conjunto de instruções distinto que podem ou não operar sobre o mesmo conjunto de dados.

O nome de deve ao fato de que cada tarefa possui uma função diferente.

Speedup e Eficiência são importantes métricas para medir a qualidade de um programa paralelo.

O Speedup permite verificar o ganho de desempenho obtido com o uso de um programa paralelo em relação ao programa seqüencial mais rápido que executa a mesma tarefa.

A Eficiência determina a taxa de utilização dos processadores.

Em sistemas homogêneos (com processadores de mesma potência computacional e mesma quantidade de memória), o Speedup é dado pela equação.

O Speedup obtido com p processadores, S(p), consiste na razão entre o tempo T gasto para executar o programa seqüencial (em um processador) e o tempo T gasto para executar o programa paralelo em p processadores.

O número total de EPs, T o tempo para executar o algoritmo seqüencial em um elemento de processamento do tipo i, T o tempo para executar o algoritmo paralelo no conjunto de EPs e T (EP) o tempo médio ponderado para executar o algoritmo em um EP, o Speedup é dado pela equação.

A Eficiência E(p) é dada pela equação, que é a razão entre o speedup S(p) e o número de processadores p utilizado.

Pelas equações observa-se que o caso ideal seria S(p) = p e E(p) = 1, um ganho igual ao número de processadores utilizado e uma utilização de 100% dos processadores.

Entretanto, o caso ideal é dificilmente alcançado, devido a diversos fatores, atraso na comunicação, balanceamento de carga inadequado, partes seqüenciais do programa paralelo, etc.

Para dar suporte à Computação Paralela diferentes arquiteturas podem ser usadas, existindo, assim, uma grande diversidade de arquiteturas paralelas.

Elas variam no que se refere aos componentes utilizados, ao modo de interligá-los e até mesmo ao modelo de programação.

Os elementos de processamento podem variar desde simples ULAs até UCPs e computadores completos.

A quantidade de EPs varia, dependendo do propósito da arquitetura paralela e da interconexão utilizada (quanto menor a latência e maior a largura de banda maior o número de EPs).

Com relação aos elementos de memória existe também uma grande variedade de características.

Geralmente, a memória é utilizada em módulos de forma a permitir acessos paralelos por diferentes EPs.

A capacidade total e de cada módulo de memória também varia.

Apesar da diversidade de características apresentada pelos elementos de processamento e de memória, a maior divergência das arquiteturas de computadores paralelos é a forma de interligar esses elementos.

Esse é o fator que apresenta grande influência nas características e no desempenho de um computador paralelo e que dá origem a diversas classificações de computadores paralelos.

Taxonomias de computadores paralelos Diante da diversidade de computadores paralelos, faz-se necessária a introdução de uma classificação.

Diversos esquemas foram propostos para classificar arquiteturas de computadores paralelos, mas nenhum teve ampla aceitação.

A Taxonomia de Flynn  é baseada em dois conceitos, fluxos de instruções e fluxos de dados.

Um fluxo de instruções é uma seqüência de instruções executadas, cada fluxo corresponde a um contador de programa.

Um fluxo de dados consiste em um conjunto de operandos manipulado por um fluxo de instruções.

Considerando-se a unicidade ou multiplicidade dos fluxos, obtém-se as quatro categorias que compõem a classificação de Flynn.
Taxonomia de Flynn para computadores paralelos  Single Instruction, Single Data (SISD) possui um único fluxo de instrução.

O contador de programa é o registrador da UCP que armazena a próxima instrução a ser executada único fluxo de dados.

Computadores seriais, baseados no modelo de von Neumann, compõem essa categoria.

Ainda que exista paralelismo de baixo nível (pipeline de instruções), apenas uma instrução é decodificada por vez e, mesmo utilizando múltiplas unidades funcionais, ainda existe apenas uma unidade de controle.

Single Instruction, Multiple Data (SIMD) um único fluxo de instrução é executado por múltiplos elementos de processamento sobre conjuntos de dados distintos.

Há apenas uma unidade de controle que busca a próxima instrução a ser executada paralelamente pelas várias unidades aritméticas sobre seus próprios dados.

Processadores vetoriais e matriciais são exemplos de arquiteturas SIMD.

Multiple Instruction, Single Data (MISD) múltiplos fluxos de instruções operam sobre um mesmo fluxo de dados.

Esta categoria é um tanto confusa, existindo uma divergência entre os autores sobre a existência de arquiteturas que possam ser classificadas como MISD.

Stallings  afirma que essa estrutura nunca foi implementada.

Flynn e Rudd  e Zomaya  classificam arrays sistólicos como representantes dessa categoria.

Multiple Instruction, Multiple Data (MIMD) um conjunto de processadores executam simultaneamente diferentes seqüências de instruções sobre diferentes conjuntos de dados.

Essa categoria engloba a maior parte dos computadores paralelos.

Embora útil e bastante difundida, a taxonomia de Flynn se limita às quatro categorias citadas, que não são suficientes para acomodar de forma adequada vários computadores modernos.

Assim, os elementos dessa classificação foram mantidos em taxonomias mais abrangentes.

Em 1990, Duncan apresentou uma taxonomia, tendo como um dos objetivos incluir processadores vetoriais com pipeline e outras arquiteturas que são difíceis de acomodar na Taxonomia de Flynn.

Excluir arquiteturas que empregam apenas paralelismo de baixo nível e manter elementos da Taxonomia de Flynn também foram objetivos da Taxonomia de Duncan.

Essa classificação é dividida em arquiteturas síncronas e assíncronas.

As arquiteturas Síncronas coordenam operações concorrentes utilizando-se de relógio global, unidade de controle central ou controladoras de unidade vetorial.

Esse grupo é composto pelas arquiteturas SIMD da taxonomia de Flynn, pelas arquiteturas vetoriais e sistólicas.

Nas arquiteturas Assíncronas não há controle centralizado mantido por hardware, os processadores podem operar de maneira autônoma.

Esse grupo é composto, basicamente, pelas arquiteturas MIMD da taxonomia de Flynn, sejam elas convencionais (MIMD com memória distribuída ou compartilhada) ou não-convencionais (MIMD/SIMD, Fluxo de Dados, Redução ou Dirigidas a demanda e Frente de Onda).

Apesar da taxonomia de Duncan ser bastante abrangente, grande parte dos autores preferem utilizar uma taxonomia mais simples que engloba as arquiteturas de computadores paralelos mais utilizadas atualmente.

Este esquema se caracteriza por manter as quatro categorias da Taxonomia de Flynn e pela sub-divisão das categorias SIMD e MIMD.

A categoria SIMD foi dividida em dois grupos, Processadores Vetoriais e Matriciais.

O primeiro é composto por supercomputadores numéricos e máquinas que operam sobre vetores, realizando a mesma operação em cada elemento do vetor.

O segundo grupo é composto por máquinas com uma unidade de controle principal que repassa a próxima instrução a ULAs independentes.

A categoria MIMD é dividida, de acordo com o modelo de comunicação, em multiprocessadores e multicomputadores.

Essas arquiteturas são discutidas na seção seguinte.

Em qualquer computador paralelo, tarefas paralelas de um mesmo job precisam trocar informações.

Há duas formas dessa interação ocorrer, acessando um espaço de memória compartilhado ou trocando mensagens.

Esses dois modos de interação são suportados, respectivamente, por dois modelos, Multiprocessadores e Multicomputadores.

A diferença básica está no modo que a memória é acessível aos EPs.

Nos Multiprocessadores os EPs compartilham uma mesma memória física, e por isso são também denominados Sistemas de Memória Compartilhada.

Embora os módulos de Os conceitos de job e tarefa são discutidos no próximo capítulo memória possam estar fisicamente separados, existe um único espaço de endereçamento virtual para todos os EPs.

No segundo modelo de comunicação, Multicomputadores, a memória encontra-se física e logicamente distribuída, sendo por isso conhecido também como Sistemas de Memória Distribuída.

Cada EP tem sua própria memória e seu próprio espaço de endereçamento, inacessível a outros EPs por meio de instruções LOAD e STORE.

Em sistemas com memória distribuída, a interação entre os EPs ocorre por meio de passagem de mensagens, utilizando a redes de interconexão.

Isso tem grandes implicações sobre o software, tornando-o mais complexo.

Nos sistemas de memória compartilhada, processos em diferentes EPs podem se comunicar apenas lendo e escrevendo na memória.

Isso facilita a sincronização, que pode ser feita utilizando-se semáforos e monitores, mecanismos já utilizados em computadores seriais.

Apesar do desenvolvimento de aplicações ser mais trabalhoso, os multicomputadores ainda são mais fáceis de construir e são escaláveis.

Para solucionar a dificuldade no desenvolvimento de aplicações, o que se tem feito é construir sistemas híbridos, em que uma das abordagens utilizadas é conhecida como Distributed Shared Memory.

Nessa abordagem o sistema operacional simula um sistema de memória compartilhada que permite à aplicação acessar a memória de todo o computador paralelo como um único espaço de endereçamento.

Existem três tipos de multiprocessadores, Uniform Memory Access (UMA), None são bastante utilizados atualmente.

Em arquiteturas UMA qualquer porção de memória têm o mesmo tempo de acesso para qualquer EP, enquanto em arquiteturas NUMA os tempos de acesso a cada região de memória difere de EP para EP.

Em NUMA cada EP possui uma memória local e o espaço de endereçamento compartilhado é formado pela combinação destas.

As arquiteturas NUMA podem possuir coerência de cache em hardware Cache Coherent NUMA (CC-NUMA) ou não possuir coerência de cache Non-Coherent NUMA.

Em arquiteturas COMA, a memória fisicamente remota é acessível apenas através de cache.

Multicomputadores podem ser divididos em duas categorias.

A primeira é representada pelos MPPs (Massively Parallel Processing), consistindo de sistemas com acoplamento forte, formados por um grande número de (UCPs) interconectadas por uma rede proprietária de alta velocidade.

A segunda categoria inclui NOW (Network of Workstations) e COW (Cluster 5 Redes de interconexão conectam UCPs e módulos de memória a outras UCPs e a outros módulos de memória, permitindo a troca de dados.

Um sistema computacional (hardware + software) é escalável se ele pode ser aumentado para acomodar a demanda por funcionalidade e desempenho e/ou diminuído para reduzir custos.

O desenvolvimento de microprocessadores mais potentes, menores e mais baratos, assim como o aumento da confiabilidade e da velocidade das redes de comunicação de dados mudaram o panorama da computação na década de 80.

As organizações possuíam, geralmente, um único mainframe, ao qual vários usuários eram conectados por meio de terminais.

Esse modelo foi substituído pelo uso de pequenos computadores interconectados por uma rede de comunicação de dados.

Desse novo modelo surgiram os chamados Sistemas Distribuídos.

Surgidos da neces-sidade de compartilhar recursos de modo eficiente, os Sistemas Distribuídos tornaram-se uma alternativa, eficiente e de baixo custo, aos sistemas centralizados.

Os Sistemas Distribuídos apresentam algumas vantagens sobre os sistemas centralizados, melhor relação custo/desempenho, possibilidade de obter capacidade de processamento superior ao de um mainframe, confiabilidade (o sistema continua a funcionar quando um computador falha) e crescimento escalar (mais computadores podem ser adicionados ao sistema, conforme a necessidade).

No entanto, vale ressaltar que, apesar dessas vantagens, a construção de um SD não é uma tarefa trivial.

O software é bastante complexo e o projetista deve estar atento a este aspecto.

Segundo Coulouris, um SD é aquele no qual os componentes de hardware ou software localizados em computadores interligados em rede se comunicam e coordenam suas ações utilizando somente passagem de mensagens.

Dessa definição destaca-se alguns aspectos importantes de um SD, pode estar separado por qualquer distância, por exemplo, uma mesma sala ou continentes, os eventos ocorrem concorrentemente, não há relógio global.

A Internet e as Intranets são exemplos de Sistemas Distribuídos.

Entretanto, há uma grande dificuldade em classificar um sistema computacional como distribuído ou não.

Tanenbaum  comenta uma dessas dificuldades, "existe na literatura uma terrível confusão entre redes de computadores e sistemas distribuídos".

Segundo Tanenbaum, a principal diferença entre as redes e os sistemas distribuídos é a transparência.

Ao contrário do que ocorre em uma rede de computadores, em que o usuário explicitamente invoca uma tarefa, num sistema distribuído os detalhes de um comando são responsabilidade do sistema, dando ao usuário a sensação de um sistema unificado.

A transparência e a autonomia dos computadores são as características chave da definição de Tanenbaum e Steen.

Para Mullender  um SD é composto por vários computadores realizando tarefas em conjunto, destacando duas características básicas, interconexão entre os computadores e a existência de cooperação e coordenação para manter o estado do sistema.

Neste trabalho, a seguinte definição de sistema distribuído será considerada, Um sistema distribuído é uma coleção de computadores autônomos interligados por uma rede de comunicação e que utilizam passagem de mensagens para cooperar e coordenar suas ações.

Embora não exista na literatura especializada uma definição única e abrangente para Sistemas Distribuídos, a maioria dos autores concordam que para ser considerado um sistema distribuído um sistema computacional deve apresentar algumas características.

Duas dentre elas são consenso na maioria dos trabalhos, a transparência e o compartilhamento de recursos.

Essas e outras características são apresentadas a seguir.

A seguir são descritas as principais características dos Sistemas Distribuídos.

Embora não seja uma regra, Sistemas Distribuídos são, em geral, compostos por elementos heterogêneos (rede, hardware, sistema operacional, linguagens de programação).

Elementos distintos não devem impossibilitar a comunicação ou gerar inconsistências.

Na alocação de tarefas a heterogeneidade deve ser considerada, uma vez que existem nós com diferentes potências computacionais, é preciso escolher o que melhor se aplica às restrições de determinada tarefa.

Compartilhamento de recursos Recurso é todo elemento que pode ser compartilhado através de uma rede, englobando desde componentes de hardware, como processadores e impressoras, até entidades de software, como arquivos e bases de dados.

O compartilhamento de recursos merece atenção especial em sistemas distribuídos, visto que os recursos estão separados fisicamente.

O propósito do compartilhamento pode ser reduzir custos, melhorar o desempenho, permitir trabalho cooperativo.

Há recursos escassos que devem ser gerenciados pelo sistema de modo a garantir a melhor utilização, além de existirem recursos cujo acesso deve ser controlado.

Coulouris  Relaciona-se ao modo como o usuário e o programador de aplicações vêem o sistema.

Se um sistema distribuído é visto como um sistema único, ocultando a existência de componentes independentes e separados fisicamente, então ele é transparente.

Em ANSA  e ISO, oito formas de transparência são identificadas, acesso, localização, concorrência, replicação, falhas, mobilidade (ou migração), desempenho, propriedade escalar (scaling).

Embora as oito formas de transparência sejam apenas diretrizes para a construção de sistemas distribuídos, duas delas são muito importantes, transparência de acesso e de localização.

Juntas recebem um nome especial, transparência de rede.

Tratamento de falhas Falhas podem ocorrer em qualquer sistema.

O tratamento de falhas em sistemas distribuídos é particularmente complexo, pois, quando um componente do sistema falha, os demais continuam ativos, podendo gerar inconsistências.

Quando um componente do sistema falha, somente o trabalho que estava usando este componente deve ser afetado, devendo ainda ser possível completar o trabalho em outro componente.

Para lidar com as falhas algumas técnicas são empregadas, detecção de falhas, mascaramento de falhas (minimizar os efeitos de uma falha), recuperação de falhas (retornar o sistema para um estado correto antes da falha ocorrer) e redundância (replicar componentes, garantindo que, se um componente do sistema falhar, haverá outro, devidamente atualizado, para cumprir sua função).

Capacidade escalar (Scalability) É a propriedade de manter-se estável quando a quantidade de recursos e de usuários aumenta significativamente.

Um exemplo é a Internet.

Teoricamente, não há limite para o número de computadores e de usuários (e nem mesmo para a distância) de um sistema distribuído.

Na prática, a obtenção da propriedade escalar é limitada por fatores como a rede.

Várias técnicas têm sido empregadas com o objetivo de possibilitar maior expansão do sistema, utilização de algoritmos descentralizados, evitando gargalos, replicação e estruturação hierárquica de servidores e dados, utilização de caches.

Concorrência Concorrência é uma característica natural dos Sistemas Distribuídos, que decorre da existência de múltiplos usuários e do compartilhamento de recursos.

Em um mesmo instante, pode haver mais de um usuário tentando acessar o mesmo recurso.

O processo (ou objeto) que representa um recurso compartilhado deve assegurar que o mesmo opere corretamente e mantenha seu estado consistente.

Isto é obtido com o uso de operações sincronizadas.

Abertura Um sistema aberto é aquele que pode se comunicar com outro sistema aberto usando regras padronizadas quanto a formato, conteúdo e significado das mensagens enviadas e recebidas.

Em um sistema aberto novos componentes de hardware e software podem ser adicionados, independentemente de fabricantes individuais.

O aumento da velocidade e da confiabilidade das Redes de Computadores tornaram-nas o meio de comunicação mais utilizado para interligar os componentes de um sistema distribuído.

Em termos práticos, um SD é construído adicionando-se um conjunto de softwares a uma rede de computadores.

O desempenho de um algoritmo distribuído depende em grande parte da largura de banda e da latência da comunicação entre os nós.

Nos últimos anos a busca por alta largura de banda e baixa latência têm sido intensificada com avanços não somente em hardware, mas também com protocolos altamente eficientes que minimizam o overhead.

Redes de alta velocidade, alcançando taxas de 100 Mbps e 1 Gbps e com uma boa relação custo/desempenho, já são comuns.

Entretanto, quando se fala em Sistemas Distribuídos, velocidade não é suficiente sem confiabilidade.

O software das Redes de Computadores é organizado como uma pilha de protocolos, o que ajuda a lidar com a complexidade da rede e com aspectos importantes, como a detecção de falhas e a garantia de entrega de um pacote.

Sistemas distribuídos podem ser construídos com uma grande variedade de Redes de Computadores, tanto em escala (redes locais LANs, redes geograficamente distribuídas WANs, inter-redes) quanto em tecnologia de transmissão (Ethernet, Token Ring, ATM).

As tecnologias de interligação em redes são particularmente interessantes, pois possibilitam redes heterogêneas serem integradas.

A tecnologia de interligação em redes TCP/IP é utilizada na Internet  e é empregada na grande maioria dos sis-temas distribuídos, operando de maneira uniforme, tanto em redes locais quanto em redes que atravessam países.

As Redes de Computadores são amplamente discutidas em Tanenbaum, Comer  e Kurose e Ross.

Os processos em um sistema distribuído, assim como nos sistemas centralizados, precisam se comunicar e sincronizar suas ações.

Devido à ausência de memória compartilhada, mecanismos como semáforos e monitores não podem ser usados.

Nos Sistemas Distribuídos a comunicação entre processos InterProcess Communication (IPC) é realizada através de passagem de mensagens, utilizando o suporte provido pela rede.

Nas redes TCP/IP, dois protocolos da camada de transporte provêem tipos diferentes de serviço para passagem de mensagens.

O Transmission Control Protocol (TCP), baseado num stream de bytes e orientado à conexão, garante a entrega da mensagem, mas gera maior overhead que o User Datagram Protocol (UDP), que se baseia em pacotes e não possui conexão.

O UDP apresenta maior desempenho porém não há garantia de entrega.

A arquitetura TCP/IP provê uma API que permite programar facilmente utilizando os protocolos TCP e UDP.

Ela A Largura de Banda é uma métrica de desempenho de uma rede e se refere à quantidade de dados que pode ser enviada por unidade de tempo.

Outra métrica importante é a Latência, definida como o tempo total necessário para transferir uma mensagem da origem até o destino.

Diversos atrasos podem ocorrer na transmissão de uma mensagem, sobrecarga (overhead), propagação, roteamento e contenção (tráfego na rede).

Fornece um conjunto de operações que possibilitam a comunicação e abstrações úteis como o Socket, uma referência a uma porta usada por um processo em um host, que pode ser usado para entregar uma mensagem a um processo.

A passagem de mensagens é a forma mais simples de IPC.

A passagem de mensagens é suportada pelas operações send e receive, que envolvem um par de processos.

Um processo envia uma mensagem para outro processo através da rede e o processo destinatário recebe a mensagem.

O mecanismo de comunicação pode ser síncrono ou assíncrono.

No mecanismo síncrono, os processos emissor e receptor sincronizam em cada mensagem e, neste caso, send e receive são bloqueantes.

Assim, toda vez que um processo emissor envia uma mensagem, ele fica parado até que a mensagem seja recebida pelo processo receptor e toda vez que um processo receptor chama receive, ele bloqueia à espera da chegada da mensagem.

Quando o mecanismo é assíncrono o processo emissor faz uma chamada send e continua sua execução normal, ou seja, ele não bloqueia à espera do envio da mensagem.

O processo receptor no mecanismo assíncrono continua sua execução normal e quando a mensagem chega, ele pode sofrer uma interrupção ou pode, a qualquer instante de sua execução, verificar num buffer se a mensagem chegou.

O mecanismo síncrono é mais simples no que se refere à programação, mas provoca perda de desempenho, pois impede que outras operações ocorram paralelamente ao envio e ao recebimento de uma mensagem.

Nos Sistemas Distribuídos, os processos se comunicam utilizando, basicamente, dois modelos, Comunicação cliente-servidor, baseia-se num protocolo Requisição-Resposta.

Um processo cliente envia uma mensagem para um processo servidor solicitando um serviço.

O processo servidor executa o serviço e envia uma mensagem, contendo o resultado, para o processo cliente.

A resposta é a confirmação do recebimento e, possivelmente, da execução da solicitação.

O protocolo pode ser ainda mais confiável com a utilização de uma confirmação de recebimento da resposta, enviada do cliente para o servidor.

Comunicação de grupo, é utilizada quando há necessidade de um processo comunicar-se com mais de um processo, em que o modelo cliente-servidor é inadequado.

Nesse caso, uma operação multicast é mais adequada.

Em operações multicast, uma mesma mensagem pode ser enviada para cada processo membro de um grupo.

A comunicação em grupo pode possuir vários objetivos, entre eles, tolerância a falhas, melhoria de desempenho por meio de serviços replicados, atualização múltipla.

A Remote Procedure Call (RPC) introduz uma camada de abstração que permite realizar uma chamada remota do mesmo modo que é feita uma chamada a um procedimento local, facilitando o trabalho de programação.

Ele baseia-se no modelo cliente-servidor e utiliza passagem de mensagens para implementar a comunicação de fato.

O uso de uma interface de serviço, contendo os métodos que podem ser chamados remotamente, é a chave do funcionamento da RPC.

A partir dessa interface é possível gerar código stub (que encapsula as chamadas do cliente) e código skeleton (que encapsula a comunicação do servidor).

Remote Method Invocation, uma tecnologia da plataforma Java, e Common Object Request Broker Architecture  são similares ao RPC, porém destinam-se ao uso com o paradigma de programação orientado a objetos.

Elas realizam invocações a métodos em objetos contidos no espaço de endereçamento de um processo remoto.

É possível encontrar na literatura da área diferentes denominações para os sistemas distribuídos utilizados para a execução de aplicações paralelas, de acordo com características particulares, Network of Workstations (NOW), Cluster of Workstations (COW), Network of Computers (NoC), Network of Machines (NOM), Cluster of SMPs (CLUMP).

Entretanto, a grande maioria dos trabalhos utiliza apenas os termos NOW  e COW.

Os termos NOWs e COWs são usados para designar uma rede convencional de computadores independentes.

Esses computadores possuem seu próprio sistema operacional e podem variar desde estações de trabalho ou PCs até SMPs ou MPPs.

O termo COW (ou, simplesmente, Cluster) sugere o uso de uma rede de alta velocidade e computadores homogêneos, formando uma arquitetura projetada especialmente para processamento paralelo.

NOWs são usadas para designar um conjunto de computadores, geralmente heterogêneos, interligados por uma rede de propósito geral.

Os computadores de uma NOW são usados tanto por aplicações paralelas quanto por usuários interativos.

A Computação Paralela e Distribuída explora a possibilidade de utilizar os computadores de NOWs e COWs como elementos de processamento de uma máquina paralela virtual.

NOWs e clusters são as arquiteturas paralelas mais comuns em pequenas e também em grandes organizações.

Seu uso é motivado por sua semelhança com os MPPs, incluindo o uso de passagem de mensagens como modelo de programação básico, para o qual existem ferramentas maduras e consolidadas.

Além disso, NOWs e clusters apresentam vantagens sobre os computadores paralelos especializados, tais como, maior accessibilidade no que se refere ao custo e à alta disponibilidade, aumento da capacidade de processamento dos computadores pessoais, aumento da largura de banda e diminuição da latência das redes, sendo comum taxas de transferências na ordem de gigabits/segundo, facilidade de integrar novos computadores e de aumentar a capacidade de processamento do sistema.

Apesar das vantagens das NOWs e dos clusters sobre os computadores paralelos especializados, existem fatores que trazem novos problemas para o software paralelo.

Um desses fatores é a interatividade dos usuários.

É preciso lidar com cargas de trabalho externas às aplicações paralelas.

Os usuários das estações de trabalho não podem ter suas atividades deterioradas em função da carga de trabalho paralela.

Ainda não está claro como o escalonador deve lidar nesse caso.

O escalonamento em NOWs será discutido no próximo capítulo.

A heterogeneidade, que por um lado pode ser vista como uma vantagem, por outro é o maior problema para as aplicações paralelas.

É possível tirar proveito da heterogeneidade alocando o conjunto de computadores mais adequado às necessidades computacionais de uma aplicação paralela.

Além disso, os processos possuem demandas computacionais diferentes, sendo interessante alocar os melhores computadores para os processos que demandam maior potência computacional.

Entretanto, é preciso lidar com as diversas heterogeneidades possíveis.

Essa heterogeneidade surge em níveis configuracionais e arquiteturais.

Uma NOW pode ser construída apenas com estações de trabalho ou pode conter, também, outras arquiteturas, como SMPs e MPPs.

Ainda que seja construída com uma única arquitetura os nós podem ter potência computacional diferente e/ou diferentes quantidades de memória.

Além disso, os nós podem estar rodando sistemas operacionais distintos (Unix, Windows), possuir processadores com diferentes arquiteturas (RISC, CISC) e, conseqüentemente, diferentes formatos de dados.

A rede também pode ser heterogênea, contendo diversas tecnologias de transmissão com diferentes largura de banda e latência.

Alguns nós podem ser interligados, por exemplo, à taxa de transferência de 1 Gbps e outros por taxas de apenas 100 ou 10 Mbps.

A heterogeneidade torna o desenvolvimento de software paralelo ainda mais complexo.

Existem ferramentas que agregam em suas funcionalidades o tratamento da heterogeneidade.

Elas permitem a distribuição dos processos e o gerenciamento de recursos de modo transparente, liberando o programador dos detalhes da comunicação.

Algumas dessas ferramentas são discutidas na seção seguinte.

A programação paralela em sistemas paralelos e distribuídos exige que toda a cooperação entre os computadores ocorra por meio de troca de mensagens.

Isso pode ser feito manualmente, utilizando sockets ou através de ambientes de passagem de mensagens.

Os ambientes de passagem de mensagens implementam diretamente o modelo de programação paralela por troca de mensagens, permitindo aos programadores implementar programas paralelos sem se preocupar diretamente com a comunicação entre os processos.

Os ambientes de passagem de mensagens são extensões de linguagens seqüenciais, implementadas através de bibliotecas de passagem de mensagens.

Esses ambientes provêem os recursos necessários à programação paralela, como criação, comunicação, sincronização de processos.

Existem diversos ambientes de passagens de mensagens, que diferem em detalhes de implementação do mesmo paradigma de passagem de mensagens.

Os ambientes de passagem de mensagens mais populares são MPI e PVM.

A absoluta maioria dos programas que utilizam passagem de mensagens é escrita utilizando um desses ambientes.

Parallel Virtual Machine (PVM) faz com que, na visão do usuário e do programador, um conjunto de computadores heterogêneos sejam uma única máquina paralela virtual.

O PVM é composto por um conjunto de bibliotecas e ferramentas que permitem o desenvolvimento eficiente de programas paralelos e a manipulação transparente de mensagens, conversão de dados e escalonamento de tarefas através de uma rede de computadores com arquiteturas imcompatíveis.

O PVM foi desenvolvido inicialmente para estações de trabalho Unix, mas atualmente existem implementações para uma variedade de plataformas.

As principais características do PVM são, coleção de máquinas (host pool) configurada pelo usuário, transparência de acesso ao hardware, computação baseada em processos, paradigma de passagem de mensagens explícito, utilização de ambientes heterogêneos, suporte a multiprocessadores.

O modelo de computação do PVM é baseado na existência de várias tarefas em uma mesma aplicação.

O PVM suporta tanto o paralelismo de dados quanto o paralelismo funcional.

Para que o programador possa introduzir paralelismo no código, possibilitando a cooperação entre as tarefas da aplicação, o PVM provê uma biblioteca de rotinas.

Essa biblioteca provê primitivas que o programador pode usar para passar mensagens, criar processos, coordenar tarefas e modificar a máquina virtual.

O PVM possui também um processo daemon que executa em cada computador que compõe a máquina virtual, denominado pvmd3 ou pvmd.

Os daemons utilizam algoritmos distribuídos para inicializar e coordenar a operação da máquina virtual, incluindo o roteamento de mensagens.

Message Passing Interface (MPI) é um padrão "de facto" para a implementação de ambientes de passagem de mensagem.

Uma variedade de bibliotecas de passagem de mensagens foram desenvolvidas desde a década de 80.

Elas diferiam umas das outras, tornando difícil construir programas paralelos portáveis.

Em 1992, foi formado o MPI Forum com o objetivo de estabelecer uma interface padrão para a implementação de ambientes de passagem de mensagens.

Devido ao limite de tempo imposto à formulação do padrão 10 do MPI, em 1994 definiu-se um conjunto básico de rotinas relacionadas à comunicação ponto-a-ponto e em grupo.

O MPI 10  define um conjunto de rotinas, que ofe-recem os seguintes serviços, comunicação ponto-a-ponto, comunicação em grupo, suporte a grupos de processos, suporte a contextos de comunicação, suporte a topologia de processos.

O grande número de implementações MPI demonstraram uma significativa aceitação do padrão MPI 11  O MPI-2 foi concluído em 1997.

Ele apresenta diversas correções e esclarecimentos à versão 11, além de definir novos conjuntos de rotinas, dentre os quais incluem-se, gerenciamento de processos, entrada e saída paralelas.

Várias implementações do MPI, tanto comerciais como de domínio público, estão disponíveis.

As funções básicas da biblioteca de troca de mensagens têm diversas variações dentre as diferentes implementações existentes.

As implementações de domínio público mais comuns são LAM/MPI  e MPICH.

Grids Computacionais, ou simplesmente grids, são a mais nova e promissora infraestrutura para a Computação Paralela Distribuída.

O termo "grid" surgiu da analogia com a rede elétrica, os consumidores simplesmente usam a energia sem conhecimento de como e onde ela é gerada.

Grids serão capazes de prover um serviço semelhante, o usuário conecta-se ao grid e se torna capaz de resolver seus problemas sem qualquer conhecimento dos recursos envolvidos.

Não há uma definição precisa de grids, globalmente aceita e que não se sobreponha com tecnologias relacionadas.

Segundo Foster  três pontos definem um grid, 1 Coordena recursos que não estão sujeitos a controle centralizado 2 Usa interfaces e protocolos de propósito geral, abertos e padronizados Muitos pesquisadores veêm Grids Computacionais como uma evolução de tecnologias familiares como computação distribuída, web, Peer-to-Peer, Application Service Provider (ASP).

Os grids consistem no compartilhamento de recursos computacionais (dados, capacidade de processamento, armazenamento), pertencentes a diferentes organizações e geograficamente separados.

O compartilhamento se dá através de redes de interconexão e de softwares de monitoramento e controle de informações.

Os recursos podem ser bastante heterogêneos e por estarem geograficamente distribuídos, geralmente, a Internet é usada.

A maior dificuldade no uso de grids surge pelo fato dos recursos pertencerem a diferentes organizações.

Assim, é preciso haver políticas bem definidas para se administrar o uso desses recursos.

Os grids devem ser seguros, consistentes, pervasivos e possuir um baixo custo de acesso.

A construção de grids possui diversas motivações.

Uma delas é a confiabilidade, obtida devido à existência de múltiplos recursos.

Assim, se um componente falha outro pode substituí-lo sem maiores prejuízos para a aplicação.

Também relacionada à existência de múltiplos recursos, outra motivação (talvez a principal) é a busca por maior potência computacional.

Utilizando grids é possível compartilhar um imenso número de computadores para a execução de aplicações paralelas, tirando proveito da existência de muitos recursos computacionais sub-utilizados em diferentes organizações.

Esses recursos, quando integrados, oferecem alta capacidade de processamento.

Outros atrativos são, o compartilhamento de caros supercomputadores, como MPPs, entre diversas instituições, o acesso transparente a recursos remotos, como bases de dados e softwares, a computação em tempo real e sob-demanda.

Apesar dos grandes benefícios que um grid traz, é preciso estar atento às suas limitações.

Apresenta as principais características dos sistemas utilizados para a execução de aplicações paralelas.

Os grids possuem características fortemente distintas dos demais sistemas paralelos.

Assim, um algoritmo proposto para outras arquiteturas tem sua eficiência reduzida em grids.

Nem toda aplicação pode ser paralelizada para execução em grids.

Algumas aplicações requerem o desenvolvimento de novos algoritmos, o que, geralmente, representa uma tarefa onerosa a fim de obter um tempo de resposta satisfatório.

Quando se trata de grids, alguns princípios básicos devem ser observados, Grids envolvem recursos heterogêneos, abrangendo um grande número de tecnologias.

Os recursos estão geograficamente distribuídos entre múltiplos domínios administrativos e são propriedade de organizações distintas, que têm autonomia sobre tais recursos.

World Wide Web um sistema de informação global baseado em hipertexto que usa a Internet como mecanismo de transporte para intercambiar informação textual, imagens, vídeo, áudio.

Grids devem ser escaláveis.

Um grid pode crescer e potenciais problemas de desempenho podem surgir.

Aplicações devem ser descentralizadas e projetadas para alta latência e baixa largura de banda.

Grids devem ser dinâmicos e adaptáveis.

Esses sistemas são bastante suscetíveis a falhas e devem ter meios de se recuperar delas.

Para prover as funcionalidades de um grid e lidar com as características citadas, os grids necessitam de alguns serviços básicos, como gerenciamento de recursos, autenticação, comunicação e transferência de dados eficiente e confiável, monitoração do estado dos recursos do grid, escalonamento.

Assim, os componentes de um grid devem ser bem estruturados.

Quatro componentes são necessários para formar um grid, Elementos físicos recursos globalmente acessíveis através da Internet.

Exemplos são computadores (PCs, MPPs, SMPs), redes, sistemas operacionais de cada computador (Unix, Linux, Windows), incluindo suas bibliotecas e protocolos de rede, dispositivos de armazenamento, bases de dados, instrumentos científicos, como telescópio, sensores.

Middleware núcleo oferece os principais serviços do grid, gerenciamento de processos remotos, co-alocação de recursos, acesso aos dispositivos de armazenamento, descoberta e registro de informações, segurança, qualidade de serviço, como reserva de recursos.

Middleware de nível de usuário, inclui ambientes de desenvolvimento, ferramentas de programação, brokers para a gerência dos recursos, escalonamento.

Aplicações e portais. Aplicações de grid são desenvolvidas usando, tipicamente, os recursos providos pelo ambiente (linguagens e utilitários, como MPI, potência computacional, instrumentos científicos.

Os portais oferecem serviços através de uma interface Web, em que os usuários podem submeter e coletar resultados das suas aplicações em recursos remotos.

A infra-estrutura de um grid é uma combinação de capacidades e recursos identificados para um problema e ambiente específicos.

Essa infra-estrutura pode mudar conforme as funcionalidades que se deseja prover num grid.

Entretanto, essas diferenças não devem ser sinônimo de imcompatibilidades.

Devido à expectativa gerada em torno dos grids, muitos dos chamados Sistemas para Computação em Grid, pacotes de software que implementam os serviços necessários ao funcionamento de um grid têm sido propostos.

Entretanto, eles têm sido criados sem padronização, retardando o crescimento e a consolidação dos grids.

Para estabelecer padrões foi criado o Global Grid Forum (GGF).

O GGF especificou a OGSI (Open Grid Services Infrastructure) e a OGSA (Open Grid Service Architecture), que estabelecem a natureza dos serviços que respondem às mensagens dos protocolos presentes em um grid.

O projeto Globus, é, provavelmente, o Sistema de Computação em Grid mais conhecido e com maior aceitação por parte dos administradores.

Ele provê um conjunto de softwares que possibilita às aplicações manipular recursos computacionais heterogêneos distribuídos como uma única máquina virtual.

Ele provê os serviços básicos e as capacidades requeridas para construir um Grid Computacional, segurança, localização e gerenciamento de recursos e comunicação.

O Globus permite a adoção de diferentes escalonadores, possuindo interfaces com o Condor, LoadLeveler, PBS.

Apesar do constante aumento de desempenho dos computadores seqüenciais baseados no modelo de von Neuman, a Computação Paralela já é uma necessidade real nos mais variados setores da sociedade.

No entanto, os altos custos dificultam a aquisição e a utilização de computadores paralelos.

Essa situação tem levado à busca de modos alternativos para prover alto desempenho a um custo menor.

Os Sistemas Distribuídos surgem então como uma alternativa viável, de baixo custo e alta flexibilidade.

A arquitetura sobre a qual um sistema distribuído é construído se assemelha em muitos aspectos a alguns dos computadores paralelos mais utilizados atualmente, os MPPs.

É possível visualizar um Sistema Distribuído, representado pelas NOWs e COWs, como uma máquina paralela virtual.

A utilização de ambientes de passagem de mensagens e o aumento da confiabilidade e da eficiência dos Sistemas Distribuídos têm tornado a Computação Paralela e Distribuída bastante comum.

Entretanto, a Computação Paralela Distribuída traz novas complexidades, sendo ainda alvo de intensa pesquisa.

Muitos aspectos antes utilizados em Computação Paralela se mostram inadequados para um ambiente com as características dos Sistemas Distribuídos.

Um ponto crítico é o escalonamento.

O desempenho de uma aplicação paralela depende de um bom escalonamento, o que não é fácil de se obter quando é preciso lidar com a heterogeneidade das NOWs e COWs, com cargas de trabalho externas às aplicações paralelas e com uma rede de comunicação relativamente lenta.

O escalonamento refere-se à atividade de alocar os recursos disponíveis, tal como elementos de processamento, disco e rede, entre as aplicações e entre as tarefas que compõem cada aplicação.

Em qualquer sistema, um bom escalonamento, baseado nos objetivos propostos, é determinante para obter um bom desempenho.

O escalonamento de aplicações paralelas (parallel job scheduling) tem sido amplamente estudado na literatura de Computação Paralela e Distribuída.

Enquanto em computadores verdadeiramente paralelos as pesquisas relacionadas ao escalonamento já estão consideravelmente consolidadas, em sistemas computacionais distribuídos há uma intensa atividade de pesquisa, buscando formas eficientes de alocar aplicações paralelas em NOWs e COWs.

Muitos conceitos e técnicas utilizados para o escalonamento de aplicações em computadores paralelos não são adequados quando se trata de um sistema distribuído, havendo a necessidade de adaptar essas técnicas ou criar novas técnicas que garantam um bom desempenho.

Em Computação Paralela Distribuída, o escalonamento é um fator crítico para alcançar eficiência.

Sistemas distribuídos oferecem considerável potência computacional.

Entretanto, fatores como a característica de arquitetura de propósito geral das NOWs, a heterogeneidade e os atrasos na rede de comunicação dificultam as decisões do escalonamento e interferem no desempenho.

Além disso, o escalonador, software responsável pelo escalonamento, deve lidar com objetivos conflitantes propostos para o escalonamento.

Este capítulo destina-se à abordagem dos principais conceitos e características relacionados ao escalonamento de aplicações paralelas em sistemas distribuídos, como NOWs e COWs.

Embora o enfoque seja dado à Computação Paralela Distribuída, o assunto aqui tratado se aplica também às arquiteturas verdadeiramente paralelas.

A terminologia da área de escalonamento é bastante inconsistente.

Existe na literatura um desacordo em relação aos termos usados e, conseqüentemente, uma grande dificuldade em relacionar os vários trabalhos desenvolvidos.

O trabalho de Souza  trata em detalhes os vários problemas existentes com a terminologia da área.

A fim de esclarecer os principais termos utilizados no escalonamento e ao longo deste trabalho, esta seção é destinada à terminologia da área.

Processos, programas, tarefas, threads, aplicações e jobs Um processo é um programa em execução, contendo, além de um conjunto de instruções, uma entrada, uma saída e um estado (pilha, contador de programa e demais informações necessárias à execução do programa).

O termo tarefa é empregado como sinônimo de processo.

Threads ou lightweight processes são, segundo Tanenbaum, linhas de execução (concorrentes) que podem existir em um mesmo processo.

Cada thread executa de forma seqüencial, similarmente a um processo, mas compartilha com outras threads o mesmo espaço de endereçamento de memória do processo a que pertence.

Isso facilita as trocas de contexto.

Os termos aplicação e job designam o mesmo elemento, a maior "entidade" de execução.

Uma aplicação pode conter apenas um processo (quando é uma aplicação seqüencial) ou vários processos que cooperam para a resolução de um problema (no caso de uma aplicação concorrente).

Política de escalonamento e estratégia de escalonamento tem o mesmo sentido.

Ambos os termos são usados para designar as decisões que devem ser tomadas em um escalonamento.

Um exemplo de política ou estratégia de escalonamento é a decisão de quando e como serão coletadas informações a respeito da carga do sistema.

Os mecanismos de escalonamento são os comandos e/ou instruções que, atuando como "ferramentas", desempenham as atividades básicas para a realização do escalonamento.

As instruções que coletam informações sobre a carga de um sistema são exemplos de mecanismos de escalonamento.

O termo algoritmo de escalonamento será utilizado neste trabalho num sentido mais amplo.

O algoritmo de escalonamento inclui políticas e mecanismos de escalonamento.

Escalonamento de processos, escalonamento de aplicações paralelas, balanceamento de carga, alocação de recursos O maior problema de se falar sobre escalonamento é que este termo tem diferentes significados para diferentes pessoas.

Um erro bastante comum é o uso do termo balanceamento de cargas como sinônimo de escalonamento realizado em tempo de execução da aplicação.

Balanceamento de cargas é um dos possíveis objetivos do escalonamento.

Um termo comumente empregado como sinônimo de escalonamento é alocação de recursos.

Segundo Casavant e Kuhl  os termos escalonamento e alocação de recursos designam a mesma atividade sob pontos de vista diferentes.

Enquanto o termo escalonamento aborda a questão em termos de processos ou aplicações (os consumidores dos recursos) a alocação de recursos leva em consideração os elementos de processamento (os recursos).

Os termos escalonamento de processos e escalonamento de aplicações paralelas são sinônimos da mesma atividade, dando ênfase ao que está sendo escalonado.

O escalonamento é definido por Casavant e Kuhl  como um "recurso para o gerenciamento de recursos", dividido em três componentes básicos, Consumidores (aplicações e processos, que compõem cada aplicação)  Recursos (elementos de processamento, memória, rede de comunicação, etc)  Políticas de escalonamento O escalonador é responsável pelo gerenciamento dos recursos.

Os consumidores obtêm acesso aos recursos através do escalonador, que, utilizando as regras de uma política de escalonamento, atribui os recursos disponíveis entre os consumidores.

Essas regras são definidas com base nos objetivos propostos para o escalonamento.

Assim, as decisões do escalonador são afetadas pelos objetivos propostos.

Possíveis objetivos são, diminuir o tempo médio de resposta, diminuir atrasos na comunicação, maximizar a utilização dos recursos disponíveis, balancear a carga entre os EPs.

O escalonador pode ser implementado na própria aplicação, no nível do sistema operacional ou em um aplicativo desenvolvido para este fim.

Em Sistemas Distribuídos o escalonamento pode ser realizado em duas etapas.

Na primeira etapa, o escalonador decide, entre as aplicações submetidas ao sistema, qual o conjunto de aplicações terá acesso aos recursos computacionais, qual a localização desses recursos e a quantidade destes que será disponibilizada para cada aplicação.

Na segunda etapa, as tarefas que compõem a aplicação são mapeadas localmente nos EPs.

Diferentes técnicas e metodologias foram desenvolvidas para o escalonamento.

Com o objetivo de organizar o conhecimento adquirido na área de escalonamento e facilitar a comparação entre os trabalhos desenvolvidos, várias classificações foram propostas.

Propuseram uma taxonomia para o escalonamento em sistemas distribuídos de propósito geral, cujo foco é o escalonamento realizado com vários processadores, denominado escalonamento global.

Essa taxonomia merece destaque por ser uma das mais completas, além der ser bastante utilizada e referenciada.

Em virtude dessas características e por ser bastante apropriada, essa taxonomia será empregada para classificar as estratégias de escalonamento discutidas neste trabalho.

A taxonomia de Casavant e Kuhl  divide-se em classificação hierárquica e classificação plana, na qual os termos relacionam-se de modo independente.

A primeira divisão da classificação hierárquica é o escalonamento local ou global.

No escalonamento local os processos são atribuídos, segundo uma política de compartilhamento de tempo, a um único processador.

O escalonamento global refere-se à atividade de decidir onde os processos que compõem um job serão alocados em um sistema com vários elementos de processamento.

Essa taxonomia divide o escalonamento global em estático e dinâmico, de acordo com o momento em que as decisões do escalonador são tomadas.

No escalonamento estático, as decisões são tomadas no momento da compilação da aplicação, sendo necessário que as informações sobre o sistema estejam disponíveis.

É comum a modelagem da aplicação através de grafos, onde os processos são representados por nós e as dependências (relacionadas à comunicação) entre os processos são representados pelos arestas.

É comum também utilizar Programação Matemática e Teoria das Filas para modelar as aplicações.

Para resolver um modelo são empregados algoritmos que buscam uma solução ótima (o que é um problema NP-completo) ou, quando algumas informações não estão disponíveis, sub-ótima.

As soluções sub-ótimas empregam o uso de Heurísticas ou resultados aproximados na busca de uma solução aceitável para o problema.

No escalonamento dinâmico, assume-se que muito pouca informação a respeito dos recursos necessários às aplicações é conhecida a priori.

Assume-se também que o ambiente em que a aplicação será executada é desconhecido ou as características do ambiente podem mudar dinamicamente.

As informações sobre o estado do sistema são coletadas, em tempo de execução, para auxiliar nas decisões do escalonamento, dando maior flexibilidade e aumentando o desempenho global.

As decisões do escalonamento dinâmico podem ser fisicamente distribuídas entre diversos EPs ou fisicamente não distribuídas (quando as decisões são realizadas em um único EPs).

Quando as decisões são fisicamente distribuídas, o escalonamento pode ser cooperativo ou não cooperativo.

No escalonamento cooperativo os escalonadores trabalham cooperativamente, interagindo durante a alocação de recursos, na busca da melhor alocação dos recursos do sistema.

No escalonamento não cooperativo os escalonadores trabalham isoladamente, tendo autonomia para decidir como alocar seus próprios recursos.

No caso do escalonamento cooperativo, soluções ótimas e sub-ótimas podem ser ser empregadas.

Como no escalonamento estático, as soluções sub-ótimas podem ser obtidas através de resultados aproximados ou utilizando heurísticas.

A classificação plana da taxonomia de Casavant e Kuhl  engloba características do escalonamento que não têm relação de hierarquia e são, portanto, independentes, como balanceamento de carga, atribuição inicial, reatribuição dinâmica e escalonamento adaptativo.

O balanceamento de carga (load balancing) e o compartilhamento de carga (load sharing) são mecanismos utilizados para a distribuição de carga.

O compartilhamento de carga busca evitar que EPs fiquem sobrecarregados enquanto outros EPs possam estar disponíveis.

O balanceamento de carga estende o mecanismo de compartilhamento de carga, buscando manter a mesma carga em cada elemento de processamento.

O escalonamento com reatribuição dinâmica  é comumente utilizado para se obter balanceamento de cargas.

Na reatribuição dinâmica, um processo, que já foi atribuído a um EP e, possivelmente, já iniciou sua execução, pode ser migrado para outro EP.

O caso contrário à reatribuição dinâmica é denominado atribuição inicial, em que um processo inicia e termina sua execução no mesmo EP para o qual foi atribuído (mesmo sob altas variações de carga).

A migração de processos na reatribuição dinâmica é uma atividade que gera muita sobrecarga, principalmente em sistemas distribuídos, pois, além de ser necessário salvar todo o contexto do processo, é necessário transferir o processo pela rede de comunicação.

Os mecanismos citados buscam aumentar o desempenho, assim como no escalonamento adaptativo, em que o comportamento das políticas de escalonamento são alteradas em função do estado atual do sistema.

No escalonamento local os processos são atribuídos a um único elemento de processamento.

O escalonamento local é comum em computadores pessoais com sistemas operacionais multitarefa.

Em geral, esse tipo de escalonamento é realizado pelo sistema operacional e baseia-se no compartilhamento do elemento de processamento por meio de técnicas de compartilhamento de tempo (time-sharing).

Nas técnicas de time-sharing o tempo de uso de um EP é dividido em pequenas fatias de tempo (time-slices).

Cada processo, em uma fila de processos aguardando pela utilização do EP, utiliza o EP durante um time-slice, liberando-o, em seguida, para uso por outro processo na fila.

Caso o processo não tenha terminado sua execução neste time-slice, ele volta à fila (geralmente, ao final) para utilizar mais um time-slice e assim sucessivamente.

O sistema operacional é responsável pela suspensão e ativação dos processos por meio de técnicas de preempção.

Através dessas técnicas, conhecidas também como multiprogramação, é possível otimizar o uso do processador, que não fica parado enquanto um processo está bloqueado.

Além  disso, a utilização de time-slices pequenos favorece processos interativos, dando ao usuário a impressão de que vários processos rodam em paralelo, quando na verdade, devido à existência de apenas um processador, existe um pseudoparalelismo entre processos concorrentes.

Detalhes sobre o escalonamento local podem ser encontrados em.

No escalonamento global, caracterizado pela existência de mais do que um elemento de processamento, os processos de cada aplicação são distribuídos entre os EPs disponíveis.

Várias características relacionadas ao escalonamento global foram discutidas.

Os elementos de processamento de um sistema paralelo precisam ser compartilhados.

Utilizando técnicas de compartilhamento de tempo, um processo pode, de uma maneira geral, assumir três estados, pronto, bloqueado, executando.

Um processo é dito executando quando está alocando o processador.

Um processo executando pode ir para o estado estado pronto (seu time-slice, também denominado quantum, expirou e ainda não acabou sua execução) ou bloqueado.

Um processo é bloqueado quando faz um pedido ao sistema operacional, E/S, por exemplo, e permanece nesse estado até que o pedido seja atendido.

Quando o pedido é atendido o processo vai para o estado pronto.

Um processo no estado pronto é aquele capaz de continuar sua execução, mas não pode alocar o processador porque outro processo está executando, entre as aplicações que são submetidas ao sistema.

Nesse sentido, as políticas de escalonamento podem ser organizadas através de duas dimensões, compartilhamento de tempo (time sharing) e compartilhamento de espaço (space sharing).

As políticas de compartilhamento de espaço dividem os EPs disponíveis em conjuntos disjuntos, denominados partições.

Cada partição é atribuída a uma aplicação paralela, que, geralmente, ocupa a partição até que termine sua execução.

Com relação à maneira como as partições são criadas e mantidas as políticas de compartilhamento de espaço são classificadas em fixas (são pré-estabelecidas durante a configuração do sistema e não são alteradas), adaptativas (o estado do sistema é considerado a fim de realizar o particionamento) e dinâmicas (considerando o estado do sistema, definem, sob demanda, o tamanho da partição, que pode ser alterado em tempo de execução).

A utilização de políticas de compartilhamento de espaço reduz o custo com troca de contextos, mas seu uso isolado não é adequado.

Como o particionamento é realizado considerando o número de elementos de processamento e não a potência computacional de cada EP, as políticas de compartilhamento de espaço são pouco eficazes em sistemas heterogêneos.

Além disso, é muito difícil para uma única aplicação utilizar eficientemente todos os EPs.

A multiprogramação é necessária para melhorar os tempos de resposta do conjunto de aplicações submetidas ao sistema e melhorar a utilização dos recursos.

A multiprogramação, no entanto, é um problema complexo para o escalonamento em sistemas distribuídos.

A existência de múltiplas aplicações, com diferentes requisitos computacionais, exige o uso de boas técnicas de compartilhamento de tempo.

O compartilhamento de tempo em sistemas paralelos e distribuídos é uma extensão do compartilhamento de tempo usado no escalonamento local.

O tempo de processamento dos diversos EPs pode ser compartilhado sob duas abordagens.

Na primeira, cada processo em uma fila global obtêm acesso a um dos EPs por um intervalo de tempo.

Quando esse tempo expira, o processo volta a fila para que seja escalonado novamente, possivelmente para outro EP.

Essa abordagem apresenta dois problemas, o acesso a fila global pode causar disputa, tornando-se um gargalo e não é possível tirar proveito da utilização da memória principal e da cache de um EP.

Além disso, a utilização dessa abordagem requer modificações no sistema operacional.

A segunda abordagem tem sido utilizada nos sistemas distribuídos de propósito geral.

Em NOWs e COWs o escalonamento de uma aplicação paralela é dividido em um etapa global e local.

Na etapa global, em um dado momento, o escalonador decide, dentre as aplicações submetidas ao sistema, qual aplicação terá acesso aos elementos de processamento.

As tarefas que compõem a aplicação são, então, mapeadas para os EPs disponíveis, através de processos e threads.

Os processos (da mesma aplicação ou de aplicações diferentes) escalonados para um mesmo EP competem pela utilização do recurso.

O sistema operacional local é responsável pelo compartilhamento do tempo de processamento entre esses processos, tomando decisões isoladamente dos demais EPs.

Um problema dessa segunda abordagem, distribuída, é a diferença de carga de trabalho entre os EPs.

É possível atribuir muita carga a determinados EPs e subutilizar outros.

A diferença de carga surge também pela existência de usuários que geram cargas de trabalho externas às aplicações paralelas.

Dessa forma, torna-se necessário utilizar políticas de escalonamento que tenham por objetivo o compartilhamento ou o balanceamento de carga.

Uma forma de obter balanceamento de cargas é utilizar a migração de processos Uma característica de suma importância em uma NOW é a interação entre as cargas de trabalho seqüencial e paralela.

Em uma NOW, o que se tem buscado é não degradar o desempenho das aplicações seqüenciais e/ou interativas dos usuários, utilizando apenas EPs ociosos para executar aplicações paralelas.

Quando o proprietário de uma estação de trabalho volta a utilizá-la duas estratégias podem ser empregadas.

Uma mais agressiva, migra os processos das aplicações paralelas para outros EPs.

A outra, mais conservadora, atribui aos processos paralelos uma prioridade menor do que os processos seqüenciais.

Outro problema da segunda abordagem, as políticas de compartilhamento de tempo distribuídas, é a falta de sincronização entre os EPs, gerando um atraso considerável na execução das aplicações.

O atraso ocorre porque um processo rodando em um EP pode querer se comunicar com um processo em outro EP que não está rodando.

Assim, é preciso esperar até que o processo ocupe o processador.

Estratégias de escalonamento cooperativo (coscheduling) tem sido estudadas para permitir que as tarefas de uma mesma aplicação sejam escalonadas em seus respectivos EPs ao mesmo tempo.

Entretanto, essas estratégias requerem alguma forma de sincronização entre os escalonadores locais.

Devido às características dos sistemas distribuídos, a sincronização explícita é pouco atrativa, levando à busca de estratégias que utilizem a sincronização implícita.

Um exemplo de política de escalonamento cooperativo é o gang scheduling.

Para que o escalonamento cumpra seus objetivos, apresentando um desempenho adequado, é necessário, além do conhecimento a respeito dos recursos computacionais do sistema, conhecimento a respeito da carga de trabalho e das aplicações paralelas.

Em vários trabalhos o conhecimento sobre as aplicações paralelas tem sido utilizado para obter melhor desempenho.

O trabalho de Senger, desenvolvido no Laboratório de Sistemas Distribuídos e Programação Concorrente (LaSDPC), investiga a obtenção e utilização do conhecimento sobre as aplicações paralelas no escalonamento em sistemas computacionais distribuídos, através da definição de mecanismos eficientes para prover esse conhecimento ao escalonador.

Atualmente, grande parte das políticas de escalonamento têm levado em consideração as características da aplicação que está sendo executada, procurando tratar adequadamente aplicações com diferentes requisitos.

Três classes principais de aplicações têm sido consideradas no escalonamento de aplicações paralelas, CPU-Bound aplicações dessa classe possuem alta demanda por processamento e baixa comunicação entre os processos.

Memory-Bound escalonar adequadamente aplicações dessa classe é importante uma vez que falhas de páginas podem deteriorar consideravelmente o desempenho.

Em geral, o que se busca ao escalonar aplicações memory-bound é evitar falhas de páginas, o que pode ser alcançado escalonando os processos para os EPs com maiores quantidades de memória.

I/O-Bound Essa classe engloba aplicações que realizam muita operação em dispositivos de entrada/saída.

Aplicações I/O-Bound são também classificadas como Disk-Bound (quando fazem muito acesso a disco) e Network-Bound (quando efetuam muita comunicação, gerando alto tráfego na rede).

As políticas de escalonamento determinam quais, quando e como os mecanismos de escalonamento serão empregados para que o escalonamento seja efetuado.

Em geral, são as políticas que determinam o desempenho do escalonamento.

Um algoritmo de escalonamento pode ser organizado como um conjunto de políticas de escalonamento, permitindo uma visão modular das diferentes atividades desempenhadas por ele.

A quantidade e a função dessas políticas variam de acordo com a visão e o enfoque que se dá à área de escalonamento de processos.

Um enfoque bastante interessante é apresentado por  e é aplicado a algoritmos de escalonamento dinâmico, que são baseados na distribuição da carga entre os diversos elementos de processamento utilizado migração de processos.

Um algoritmo de escalonamento é composto por quatro políticas, Política de Informação é responsável por definir em que momento informações sobre o estado do sistema são necessárias, de que elementos de processamento essas informações devem ser coletadas, e que tipo de informação deve ser utilizada Política de Seleção relaciona-se à decisão de qual processo será transferido após a definição de qual elemento de processamento será um transmissor.

Política de Localização responsável por definir um elemento de processamento parceiro para participar da transferência.

Quando a memória principal é insuficiente, uma área do disco (memória secundária) é destinada a armazenar temporariamente dados de um programa que não estão sendo utilizados no momento.

Quando o programa precisa desses dados ocorre uma falha de página.

Então, o sistema operacional busca os dados no disco e coloca na memória principal.

Política de Transferência determina a disponibilidade de um elemento de processamento para participar de uma transferência de processos, seja como transmissor ou como receptor.

A carga de um elemento de processamento é uma informação de grande importância, pois permite avaliar o quanto um EP está carregado.

Essa informação permite dizer se o EP está apto a receber mais tarefas para executar ou se está sobrecarregado (podendo, até mesmo, ser necessário transferir tarefas para outro EP).

De modo geral, a carga é medida por meio de índices de carga, que são valores inteiros não-negativos.

O valor zero de um índice de carga indica que não há carga e, à medida que a carga aumenta, o valor de um índice de carga também aumenta.

Índices baseados nas filas de acesso a algum recurso, como EP e memória, índices baseados na taxa de utilização de um recurso e índices baseados no tempo de resposta são alguns exemplos de índices de carga.

A obtenção e a utilização de índices de carga são tarefas complexas.

A medição de um índice gera sobrecarga sobre o sistema, sendo necessário garantir que a medição interfira o mínimo possível no comportamento do sistema.

A escolha de índices de carga ruins pode fornecer resultados imprecisos para aplicações que possuam requisitos bem definidos em termos de recursos (por exemplo, o mais importante para uma aplicação CPU-Bound é saber o quanto a CPU está ocupada).

É possível combinar índices para obter uma informação mais precisa do estado do sistema, chegando a conclusões mais próximas da realidade.

Devido à heterogeneidade dos sistemas distribuídos, índices de carga absolutos podem levar a erros na utilização dos índices.

Por exemplo um processador mais rápido que esteja mais carregado que outro mais lento pode ser uma melhor opção para receber uma nova tarefa.

Assim, os índices de carga precisam ser normalizados de forma que a potência computacional dos elementos de processamento seja considerada.

Índices de carga são discutidos com maiores detalhes em Santana e Zaluska, Branco, Voorsluys.

Algumas políticas de escalonamento serão discutidas ao longo deste trabalho.

Duas políticas utilizadas neste trabalho foram desenvolvidas no Laboratório de Sistemas Distribuídos e Programação Concorrente (LaSDPC).

A DPWP (Dynamical Policy Without Preemption) é uma política voltada a aplicações CPU-Bound, enquanto a NBSP (Network-Bound Scheduling Policy), como o próprio nome diz, é voltada para aplicações Network-Bound.

Ambas têm como objetivo melhorar o tempo de resposta das aplicações.

Os objetivos propostos para um escalonamento são os principais elementos que devem ser traduzidos para uma política de escalonamento.

Como é a política que toma as decisões do escalonamento de uma aplicação paralela, cabe a esta cumprir os objetivos propostos.

O objetivo primário do escalonamento de aplicações paralelas é garantir que as aplicações possam ser executadas e consigam terminar sua execução.

Apesar desse objetivo ser bastante óbvio, ele deve ser sempre considerado, pois nenhum outro objetivo deve interferir na execução de uma aplicação (ou de seus processos).

Os objetivos propostos para o escalonamento podem ser bastante variados.

Os mais comumente empregados são objetivos ligados à utilização dos recursos e à satisfação do usuário, como, Minimizar o tempo de resposta o tempo de resposta é o tempo gasto desde a chegada de uma aplicação no sistema até o término de sua execução.

Menor tempo de resposta significa que a aplicação foi escalonada e/ou foi executada mais rapidamente.

Maximizar o throughput o throughput é o número de tarefas processadas por unidade de tempo.

Esse objetivo está relacionado à exploração da capacidade do sistema.

Quando o throughput é igual ao número de tarefas que chegam significa que o sistema não está saturado.

Maximizar a utilização dos recursos esse objetivo representa a porcentagem da capacidade de um recurso, como um EP, que está sendo utilizada.

O cumprimento desse objetivo caracteriza-se, principalmente, pelo esforço em não permitir que os recursos fiquem ociosos.

Isso pode ser obtido com multiprogramação.

É importante notar que algumas vezes os objetivos podem ser contrastantes.

Por exemplo, quando se procura maximizar a utilização do processador, o que geralmente se faz é escalonar processos grandes primeiro.

Isso acaba por aumentar o tempo de resposta.

Portanto, maximizar a utilização dos recursos e minimizar o tempo de resposta pode não ser possível.

Uma medida de desempenho útil para verificar a qualidade do escalonamento é verificar se uma política de desempenho cumpre os objetivos para a qual foi proposta.

Os objetivos de uma política de escalonamento podem ser formalizadas através de métricas de desempenho, permitindo avaliar quantitativamente se os objetivos estão sendo atingidos (KRALLMANN et al Medidas de desempenho são discutidas.

O escalonamento em NOWs e COWs é, geralmente, realizado por um software que roda sobre o sistema operacional, como um middleware para as aplicações paralelas.

É comum encontrar na literatura o termo Job Management System  como sinônimo desses ambientes de escalonamento.

Existem vários ambientes de escalonamento disponíveis.

Grande parte desses ambientes são (ou possuem) versões de domínio público.

Eles são otimizados com base no sistema computacional para o qual foram construídos, podendo, inclusive, ser parte integrante do sistema operacional.

Os ambientes de escalonamento, implementados externamente ao sistema operacional, apresentam vantagens, como, controle e planejamento da utilização dos recursos por parte do administrador, adaptabilidade e portabilidade a sistemas heterogêneos.

Alguns dos ambientes de escalonamento mais conhecidos são discutidos a seguir.

No final desta seção é apresentado um quadro comparativo entre os ambientes discutidos.

Condor Condor  é um sistema de escalonamento batch para LANs.

Os jobs executam em segundo plano, utilizando estações de trabalho ociosas.

Quando o proprietário de uma estação de trabalho retorna, os processos paralelos são suspensos.

Provido com suporte à migração e à checkpoint, os processos paralelos são migrados para outro EP se o usuário continuar a utilizar a estação de trabalho.

O Condor possui uma interface de gerenciamento denominada CARMI (Condor Application Resource Management Interface).

Através dessa interface o usuário pode especificar a arquitetura do EP, a quantidade de memória, a quantidade de swap e o sistema operacional.

No Condor um gerente centralizado é responsável pelo escalonamento e atribuição de tarefas aos EPs.

Prioridades são implementadas através de um algoritmo up-down, que incrementa a prioridade de aplicações que estão a mais tempo na fila e reduz a prioridade de aplicações que utilizaram vários recursos em instantes de tempos passados.

O LoadLeveler  é um produto usado em estação de trabalho IBM baseado no Condor.

No Load Leveler as políticas de escalonamento podem ser alteradas através de uma coleção de utilitários e através de uma interface gráfica.

O LSF  é baseado no compartilhamento de carga entre os EPs.

Permite a execução remota de forma transparente e o escalonamento de aplicações paralelas em clusters heterogêneos de larga escala.

O usuário pode especificar características que são usadas pelo software escalonador durante a distribuição de tarefas.

Alguns exemplos são, quantidade de memória principal, quantidade de espaço em disco, arquitetura dos EPs.

O administrador do sistema pode inserir medidas de desempenho adicionais, a fim de tornar as decisões do escalonador mais flexíveis.

O Sun Grid Engine visa a utilização ótima dos recursos computacionais em ambientes distribuídos.

Ele suporta várias plataformas, principalmente, sistemas UNIX.

Esse ambiente possui um conjunto de filas e um escalonador mestre, que recebe as aplicações dos usuários.

Os processos daemons, que executam em cada EP, buscam os EPs apropriados para as aplicações.

Se os recursos que satisfaçam os requisitos da aplicação não estiverem disponíveis, o sistema aguarda a liberação desses recursos.

O Sun Grid Engine implementa migração de processos e checkpointing, o que possibilita a recuperação do trabalho em caso de falhas.

Outro mecanismo de tolerância a falhas é a replicação do escalonador mestre.

O ambiente possui suporte à customização, permitindo ao usuário submeter aplicações e selecionar arquitetura específica, quantidade de memória, sistema operacional.

Além disso, prioridades podem ser solicitadas e o administrador pode configurar restrições de acesso aos usuários do ambiente.

As políticas, assim como as filas e os períodos de verificação de carga dos EPs, podem ser configurados em tempo de execução, sem necessidade de interrupção na execução do ambiente.

O ambiente DQS possui várias filas, nas quais os usuários submetem suas aplicações.

Esse ambiente possui implementação para diversos sistemas operacionais.

O DQS implementa tolerância a falhas, com a existência de um escalonador auxiliar, que assume as atividades do escalonador mestre em caso de falhas.

A fim de realizar o escalonamento e a atribuição de tarefas o DQS se baseia na carga média do sistema, alocando aplicações e tarefas para os EPs ociosos.

O usuário pode especificar os requisitos computacionais de sua aplicação, como quantidade de memória, arquitetura dos EPs e podem também especificar características da aplicação.

O DQS pode ser configurado para aplicar restrições aos usuários.

É formado por um processo mestre, que é responsável pelo escalonamento das aplicações, e de processos daemon, que coletam informações sobre a carga nos EPs para serem submetidas ao processo mestre.

O usuário fornece as características das aplicações, que são inseridas em filas específicas de acordo com essas características.

Recursos importantes para o escalonador podem ser configurados pelo administrador, assim como as políticas de escalonamento e o número de filas do ambiente podem ser alterados em tempo de execução.

PBS (Portable Batch System), O PBS visa fornecer controle sobre a execução e o escalonamento de aplicações, tanto em uma rede de estações de trabalho, quanto em máquinas com processamento maciçamente paralelo (MPPs).

Ele segue o modelo de filas múltiplas.

O PBS utiliza políticas configuradas pelo usuário, que podem conter prioridades e informações sobre a aplicação para realizar o escalonamento.

AMIGO (dynAMical flexIble schedulinG envirOnmet), O AMIGO (dynAMical flexIble schedulinG envirOnment) foi desenvolvido no Laboratório de Sistemas Distribuídos e Programação Concorrente (LaSDPC).

Ele foi especificado e implementado através do trabalho de doutorado de Souza  e dos trabalhos de mestrado de Araújo, Figueiredo, Campos  e Santos.

Esse software foi desenvolvido com a finalidade de gerenciar o escalonamento de aplicações em sistemas computacionais heterogêneos e distribuídos, executando sistemas UNIX, de maneira flexível e dinâmica.

O AMIGO é flexível porque possui a possibi lidade de se alterar configurações (por exemplo, inserir ou remover políticas de escalonamento) de acordo com as necessidades do usuário.

A parte dinâmica refere-se à adequação do ambiente em relação a novas situações/configurações em tempo de execução.

O AMIGO foi projetado com uma estrutura modular de duas camadas, independentes em tempo de execução.

A camada superior é composta por uma interface gráfica, na qual o usuário tem acesso a detalhes do ambiente, como, seleção de políticas de escalonamento, inserção de informações sobre o hardware, definição de métricas para monitoramento da política de escalonamento.

Todas essas configurações são armazenadas em arquivos, que são utilizados pela camada inferior.

Os arquivos de configuração são o único elo de ligação entre as camadas.

A camada inferior é composta por três módulos, o ambiente de passagem de mensagens, o AMIGO Daemom (AMIGOD) e as políticas de escalonamento.

O ambiente de passagem de mensagens atua requisitando elementos de processamento, nos quais as aplicações paralelas devem ser executadas.

O AMIGO pode ser acoplado a qualquer ambiente, desde que uma interface de comunicação tenha sido previamente construída.

Atualmente, existem interfaces para PVM, MPI e CORBA.

O AMIGOD é um processo servidor distribuído, que executa em cada EP.

Funciona como um elo entre a política e o ambiente de passagem de mensagens.

Sua responsabilidade se resume a rotear e gerenciar as mensagens trocadas entre os módulos da camada inferior, iniciar e terminar a execução de políticas de escalonamento e manter informações sobre execução de outros AMIGODs.

Não há uma hierarquia.

Mesmo com a possibilidade maior complexidade e sobrecarga de comunicação, os AMIGODs são completamente distribuídos, possibilitando melhor tolerância a falhas e propriedade escalar.

As políticas de escalonamento são responsáveis por verificar e repassar ao AMIGOD, quais são os elementos de processamento adequados para a execução das aplicações.

Utilizando o AMIGO, as aplicações paralelas não precisam ser modificadas ou adaptadas e o escalonamento é transparente, ocultando detalhes de implementação e das políticas usadas.

O AMIGO não possui mecanismos de checkpointing e migração de processos.

São relacionadas algumas características consideradas importantes para os ambien tes de escalonamento para NOWs e COWs.

As características são classificadas em suportadas totalmente, parcialmente suportadas e não suportadas pelo ambiente de escalonamento.

As características citadas são, heterogeneidade, passag mensagens (se o ambiente suporta ambientes de passagem de mensagens como PVM e MPI), políticas dinâmicas (possibilidade de reconfiguração em tempo de execução), sem recompilação (escalona sem a necessidade de recompilação do código da aplicação), checkpointing, migração, balanceamento de carga, gratuito (se é ou possui uma versão de domínio público).

Quadro comparativo dos ambientes de escalonamento.

Em grids computacionais o escalonamento é, particularmente, desafiador.

Embora as políticas de escalonamento propostas para uso em Clusters e NOWs possam ser usadas, elas tem sua aplicabilidade reduzida em grids, oferecendo desempenhos ruins nesses sistemas.

Resume as características típicas dos principais sistemas utilizados para computação paralela de alto desempenho.

Até mesmo entre grids e NOWs as diferenças são consideráveis.

Dessa forma, o que se tem buscado é o desenvolvimento de políticas de escalonamento dedicadas a esses sistemas.

Políticas que contemplam o tratamento das características inerentes aos grids obtêm ganhos de desempenho significativos quando comparadas às políticas de escalonamento que não comtemplam.

Algumas características dos grids dificultam as decisões do escalonador.

Nos grids, os recursos de hardware e software são bastante heterogêneos, apresentando grandes diferenças de desempenho, múltiplas arquiteturas e múltiplas imagens de sistema operacional.

A grande quantidade de recursos é outro dificultador para a atividade de escalonamento.

O gerenciamento de recursos envolve descobrir, monitorar e alocar recursos.

Assim, a existência de muitos recursos pode tornar o escalonador um gargalo e dificultar manter consistente as informações de estado dos recursos disponíveis.

Os recursos são compartilhados por vários usuários, redes e computadores pertencem a diferentes domínios administrativos, cada qual com sua própria política de utilização.

Tudo isso, pode levar a uma grande variação de carga e a uma grande variação nos recursos disponíveis para as aplicações paralelas.

Os usuários de um determinado domínio administrativo têm prioridade sobre seus recursos, o escalonador deve priorizar as aplicações locais, só escalonando aplicações paralelas em momentos de baixa utilização.

A comunicação e a consistência das informações necessárias ao escalonamento é um dos mais graves problemas.

A transferência de informações em grids deve ser limitada para que não haja degradação no desempenho causada pela contenção na rede.

Deve-se evitar muita comunicação e réplicas, que devem ser atualizadas com freqüência.

O tipo de aplicação dos grids também está relacionado à comunicação.

Geralmente, a intensidade de comunicação entre as tarefas de uma aplicação determina à que tipo de plataforma ela se aplica.

Em plataformas com fraco acoplamento as tarefas que compõem uma aplicação devem trocar pouca ou nenhuma informação.

Aplicações desse tipo, em que suas tarefas são independentes, recebem o nome de Bag-of-Tasks e são comuns em grids.

Vale ressaltar que é possível submeter aplicações paralelas com comunicação intensiva ao escalonador de um grid, mas cabe ao escalonador procurar, dentre os recursos do grid, aquele que provenha um bom desempenho (um MPP, por exemplo).

As características acima citadas influenciam em outro aspecto do escalonador, sua organização.

Tipicamente, um escalonador centralizado não é aplicável a grids computacionais, pois, num grid, nenhum sistema pode controlar todos os recursos.

Devido à grande escala, ampla distribuição e existência de múltiplos domínios administrativos (em que os administradores de cada site não desejam dispor do controle sobre seus recursos), é pouco viável utilizar uma abordagem centralizada.

Os Grids Computacionais utilizam escalonadores capazes de dividir a carga de trabalho entre si, cooperativamente.

Existem, basicamente, três tipos de escalonadores, centralizado, descentralizado e hierárquico.

Esse tipo de escalonador, empregado, tradicionalmente, em clusters e NOWs, controla todos os recursos do sistema, podendo se tornar um gargalo.

Ele toma todas as decisões de quando, como e onde cada aplicação e tarefa deve executar.

Além disso, ele é responsável por receber as requisições de todos os usuários e arbitrar, entre estes, qual terá acesso aos recursos compartilhados.

Uma alternativa aos escalonadores centralizados é o escalonador dito, descentralizado.

Nesse modelo a carga de trabalho é dividida entre escalonadores do mesmo nível.

Cada escalonar pode decidir em que recurso do sistema determinada tarefa será escalonada.

Uma característica importante desse modelo é que cada escalonador tem Modelos de escalonadores.

Conhecimento do estado dos demais, sendo capaz de promover um balanceamento da carga.

Quando uma requisição chega a um escalonador sobrecarregado, ele verifica qual dos seus vizinhos possui menor sobrecarga e envia a solicitação para ele.

Um problema desse modelo é a sobrecarga gerada pela comunicação para manter o estado dos escalonadores vizinhos atualizado.

O terceiro tipo de escalonador é o hierárquico.

Nesse modelo existem dois ou mais níveis de escalonadores.

Cada escalonador do nível mais baixo é responsável por um conjunto de recursos computacionais.

Nos níveis superiores os escalonadores, conhecidos como meta-escalonadores, não são mais responsáveis por recursos e sim por um grupo de escalonadores de nível inferior.

A decisão de escalonamento ocorre no escalonador de mais alto nível.

Para tanto, os demais escalonadores (de nível inferior) devem enviar, periodicamente, seus estados ao meta-escalonador.

O escalonamento é uma atividade natural na computação que decorre da existência de vários usuários requisitando o uso de um ou mais recursos.

O escalonamento é uma atividade de extrema importância.

Apenas com a adequada utilização dos recursos, provendo às aplicações os requisitos computacionais necessários, é possível obter um bom desempenho.

Em clusters, NOWs e, principalmente, em grids o escalonamento ainda é alvo de intensa pesquisa.

A heterogeneidade, a variação de carga, a interatividade do usuário, o fraco acoplamento entre os EPs são características desses sistemas que devem ser consideradas nas políticas de escalonamento.

Além disso, diferentes objetivos são propostos para a atividade de escalonamento e aplicações com diferentes requisitos são submetidas ao sistema.

Tudo isso torna extremamente complexo o desenvolvimento de uma única política de escalonamento que trate adequadamente todos os sistemas e todas as aplicações.

Existe uma forte tendência em desenvolver políticas que tratem situações e problemas específicos.

Essa tendência é evidenciada no LSF e no AMIGO, que suportam a troca dinâmica das políticas de escalonamento baseado no estado do sistema e no tipo de aplicação a ser escalonada.

Dessa forma, muitas abordagens têm sido propostas para o escalonamento em NOWs, tornando difícil comparar diferentes alternativas.

Nesse contexto, a avaliação de desempenho tem um importante papel.

Somente com critérios bem definidos, utilizando técnicas de avaliação de desempenho que permitam classificar e comparar as políticas de escalonamento disponíveis, é possível escolher a melhor abordagem.

A avaliação de desempenho está se tornando uma atividade cada vez mais importante em todo o processo computacional.

Isto se deve ao fato de que uma boa avaliação pode garantir maior desempenho a um custo menor.

Além disso, a crescente complexidade dos sistemas computacionais (hardware + software) exige o uso de técnicas elaboradas para verificar o desempenho.

Antes de qualquer coisa, é preciso definir o que é desempenho.

Uma figura de desempenho para um sistema computacional corresponde ao resultado de uma análise da quantidade de serviços prestados em relação ao tempo total decorrido desde o início desses serviços.

A satisfação do usuário em relação à qualidade de um serviço é tam-bém um parâmetro relacionado ao desempenho, embora não seja um parâmetro confiável.

O desempenho só pode ser definido com maior clareza ao se conhecer os objetivos do serviço que será avaliado.

As métricas de desempenho permitem formalizar e quantificar os objetivos de um serviço a fim de obter resultados confiáveis da avaliação de desempenho.

A importância da avaliação de desempenho é refletida pela existência de uma grande quantidade de pesquisas na área e de um grande número de conferências e jornais especializados.

Além disso, grande parte dos eventos possuem seções voltadas especialmente para a avaliação de desempenho em domínios específicos, como o escalonamento de aplicações paralelas.

No entanto, na maioria das vezes, a avaliação de desempenho é simplesmente ignorada e freqüentemente usada de forma incorreta.

Em geral, o desuso e a incorreta aplicação da avaliação de desempenho se deve ao fato de que essa é uma tarefa difícil, cujas técnicas nem sempre são dominadas.

A experiência do analista de desempenho é um fator primordial.

A avaliação de desempenho é empregada em muitas situações diferentes e com vários propósitos.

Em sistemas computacionais distribuídos a avaliação de desempenho pode ser aplicada na análise de sistemas existentes, análise de sistemas em desenvolvimento ou seleção de um determinado sistema.

Em sistemas existentes a avaliação de desempenho é empregada com o objetivo de maximizar a eficiência e a utilização de um dado recurso ou processamento, minimizando os custos e o tempo de resposta, entre outros objetivos.

Os sistemas em desenvolvimento são avaliados para predizer seu comportamento, sendo que a avaliação estende-se desde a concepção do sistema até sua instalação.

Quando se trata de selecionar um sistema, uma comparação do desempenho é realizada segundo algum parâmetro.

No restante deste capítulo são abordadas as métricas e técnicas utilizadas para verificar a qualidade de um serviço, seja com o objetivo de seleção ou de melhoria.

A próxima seção destina-se a conceituar métricas de desempenho e a apresentar algumas métricas largamente utilizadas.

Em seguida, as técnicas são abordadas, procurando enfatizar as características e os domínios em que cada técnica é recomendada.

Benchmarking, uma das técnicas de avaliação de desempenho, é abordada.

Uma avaliação de desempenho baseia-se na análise de métricas de desempenho.

As métricas de desempenho permitem formalizar os objetivos de um serviço e quantificar os resultados de uma avaliação de desempenho.

Para afirmar se o desempenho está bom ou ruim ou o quanto o desempenho é bom ou ruim, é preciso verificar o valor de uma métrica de desempenho adequada para avaliar o objetivo considerado.

Para avaliar o desempenho, de forma objetiva, uma métrica deve ser definida.

As métricas tradicionalmente empregadas para avaliar o desempenho são, Tempo de resposta médio é a média do tempo total que os jobs esperam no sistema, desde a chegada até a partida.

O tempo de resposta é considerado ser uma métrica orientada ao usuário.

Minimizando essa métrica os resultados são retornados mais rapidamente.

Throughput é o número de tarefas que o sistema processa por unidade de tempo.

Em sistemas não saturados, o throughput é igual à taxa de chegada, assim, tipicamente o que é considerado é a taxa máxima de chegada que o sistema pode sustentar (throughput sustentável).

O throughput sustentável é considerado ser uma métrica orientada ao sistema.

Maximizar essa métrica significa que mais trabalho é completado por unidade de tempo.

A avaliação de desempenho consiste em coletar informações associadas aos parâmetros significativos para a análise.

As técnicas para a avaliação de desempenho são os métodos utilizados para a obtenção dessas informações.

Selecionar uma técnica é um passo importante da avaliação de desempenho.

Muitas considerações estão envolvidas nesta escolha, por exemplo, o estágio de desenvolvimento do sistema que se quer avaliar, o tempo disponível para avaliação, a disponibilidade de ferramentas e o nível de precisão desejado.

Em geral, apenas uma técnica é utilizada na avaliação, no entanto, nada impede que mais de uma técnica seja usada seqüencialmente, de forma complementar.

As técnicas para avaliação de desempenho podem ser divididas em dois grandes grupos, técnicas de modelagem e técnicas de aferição.

Em alguns casos, existe a necessidade de avaliar o desempenho sem utilizar o sistema computacional em si.

Pode ser que não se deseje interferir no comportamento do sistema ou este ainda não foi desenvolvido.

Uma boa alternativa é a utilização de técnicas de modelagem.

As técnicas de modelagem baseiam-se na representação de um determinado sistema computacional na forma de modelos.

Um modelo é uma abstração de um sistema computacional que preserva as características mais relevantes desse sistema.

O modelo de um sistema deve ser o mais simples possível, contendo somente características essenciais.

A inclusão de muitos detalhes em um modelo pode torná-lo complexo sem necessidade  e, conseqüentemente, dificultar a avaliação.

Diversas técnicas de modelagem podem ser utilizadas para desenvolver modelos.

A literatura apresenta várias delas, porém, as mais utilizadas são Redes de Filas, Redes de Petri, Statecharts e Cadeias de Markov.

Existem diversas situações nos sistemas computacionais em que há concorrência por algum recurso compartilhado, como UCP ou disco rígido.

Como, geralmente, a quantidade se serviços é maior do que o número de recursos disponíveis, formam-se filas de serviços a serem atendidos.

Para permitir modelar esse tipo de sistema existe uma técnica denominada Redes de Filas.

Essa técnica é baseada na Teoria das Filas (um ramo das probabilidades).

As Redes de Filas possuem uma sólida base matemática, mas sua representação gráfica é limitada a apenas duas entidades, centro de serviços e usuários, em que o primeiro é um provedor de serviços que são usufruídos pelo segundo.

Um centro de serviço pode possuir mais de um servidor de acordo com o sistema sendo modelado.

Existe também uma fila de espera para os usuários que requisitaram um serviço mas ainda não obtiveram acesso.

A técnica de Redes de Filas é bastante limitada para modelar sistemas, pois não permite que se modele várias características que podem ser desejáveis conter em um modelo, como a situação dos serviços em estados pronto, bloqueado e processando.

Informalmente, Redes de Petri, podem ser definidas como uma técnica que permite a especificação de sistemas utilizando representação matemática.

Essa técnica possui mecanismos poderosos de análise, sendo bastante adequada aos sistemas computacionais da atualidade, visto que permite modelar sistemas paralelos, concorrentes, assíncronos e não-determinísticos.

A representação gráfica de uma rede de petri é bastante poderosa.

Redes de Petri permitem modelar, facilmente, várias características de um sistema que não são possíveis representar em Redes de Filas.

Uma desvantagem de Redes de Petri é a grande complexidade do modelo quando sistemas maiores são considerados.

Statecharts  são uma extensão das máquinas de estado finito, possibilitando representar hierarquia, concorrência e comunicação entre os diversos estados de um determinado sistema.

São usados principalmente para sistemas que reagem a estímulos externos e internos, normalmente sob condições críticas em relação ao tempo.

Statecharts são usados para modelar sistemas complexos, nos quais os diagramas de estado não são eficientes.

As cadeias de Markov  modelam sistemas de acordo com suas probabilidades de transações.

Uma cadeia de Markov é um processo estocástico que tem uma propriedade especial denominada Memoryless.

Essa propriedade se refere ao fato de que uma transição para um determinado estado depende somente do estado atual.

As maiores vantagens da utilização de técnicas de modelagem são a flexibilidade dessas técnicas (podem ser aplicadas tanto em sistemas existentes quanto em sistemas ainda não desenvolvidos) e a relação custo-benefício (o custo é baixo para o grau de precisão obtido).

No entanto, vale ressaltar que as abstrações dos modelos implicam em simplificações que diminuem a precisão dessas técnicas.

As técnicas de modelagem tem uma precisão menor que as técnicas de aferição.

Uma grande desvantagem das técnicas de modelagem é a dificuldade em validar o modelo.

Uma vez definido um modelo de um sistema computacional, é preciso resolvê-lo para se obter os resultados que demonstram o desempenho do sistema modelado.

Um modelo pode ser resolvido utilizando solução analítica ou solução por simulação.

A solução analítica exige domínio matemático, mas é mais rápida e barata, enquanto a simulação apresenta resultados com melhor qualidade, permitindo especificar mais detalhes no modelo.

Porém, a simulação envolve a construção de um programa computacional que represente o modelo, sendo mais demorada e mais cara.

A escolha de uma das abordagens depende de fatores diretamente ligados ao sistema e à avaliação.

Apresenta algumas diretrizes que auxiliam na escolha de uma ou outra abordagem.

Utilizando a técnica de solução analítica é possível escrever uma relação funcional entre os parâmetros do sistema e os critérios de desempenho escolhidos, em termos de equações.

Essas equações podem ser resolvidas por meio de análise matemática.

Em geral, solução analítica é mais rápida e, por isso, é o método preferido para resolver modelos.

Essa técnica também fornece resultados mais precisos.

No entanto, a solução analítica nem sempre é aplicável, pois, à medida que a complexidade do sistema modelado aumenta, também aumenta a dificuldade da utilização desta técnica.

Para que o modelo seja resolvido, algumas simplificações podem ser necessárias.

Essas simplificações representam restrições, que, em geral, não correspondem ao que é verificado nos sistemas reais.

Embora seja um método que fornece resultados expressivamente exatos, as restrições podem levar a um modelo que não representa adequadamente o sistema real, tornando sem sentido a utilização desse modelo.

Geralmente, os modelos são representados utilizando-se redes de filas.

A solução analítica possui um custo relativamente baixo e o tempo para a solução desejada depende da complexidade do problema.

Simulação  é uma das abordagens mais comuns para a avaliação de desempenho de sistemas computacionais.

Simular o comportamento de um objeto (ou um sistema de objetos) é uma necessidade em várias áreas do conhecimento.

Em computação, simulação refere-se ao emprego de um programa de computador (um simulador) para a implementação do modelo de algum fenômeno ou sistema dinâmico (sistemas cujos estados se alteram com o tempo).

Quando o modelo envolve um grande número de informações e não é possível fazer as simplificações necessárias para a utilização de solução analítica, pode-se optar por simulação, para resolver um modelo.

Fatores, como flexibilidade, facilidade na utilização e custos relativamente baixos têm motivado o emprego da simulação.

Os maiores problemas na utilização de simulação são a dificuldade de verificar se o simulador está correto e a grande quantidade de computação necessária para obter medidas válidas do ponto de vista estatístico (MAJUM-A simulação distribuída busca solucionar esse problema inserindo paralelismo em uma simulação executada em uma arquitetura distribuída.

Souza  utiliza simulação para avaliar políticas de escalonamento.

No trabalho de Ishii  e de Senger, a simulação foi utilizada para demonstrar as melhorias obtidas de suas propostas para o escalonamento de aplicações paralelas em Computação Paralela e Distribuída.

As técnicas de aferição são aplicadas a sistemas computacionais já implementados ou em fase final de seu desenvolvimento, podendo também ser aplicadas a protótipos.

Assim, a partir da experimentação sobre o próprio sistema (ou um protótipo) é possível verificar o desempenho.

As técnicas de aferição são as técnicas que apresentam os resultados mais próximos da realidade.

Elas proporcionam maior precisão em relação às técnicas de modelagem, mas, requerem que o sistema computacional (ou ao menos um protótipo) esteja disponível.

O maior problema no uso de técnicas de aferição é que estas atuam diretamente sobre o sistema, podendo influenciar no comportamento do mesmo, as técnicas de aferição disputam por recursos com o sistema sendo avaliado.

Algumas das principais técnicas de aferição são construção de protótipos, coleta de dados e benchmarking.

As duas primeiras técnicas são discutidas a seguir e benchmarking é vista.

Assim como nas técnicas de modelagem, a escolha entre uma das técnicas de aferição depende de alguns fatores.

Apresenta um esquema que ajuda a direcionar essa decisão.

Quando se deseja avaliar um sistema computacional que ainda não foi desenvolvido (ou que esteja em desenvolvimento) e a precisão é um fator importante, uma alternativa é a construção de um protótipo.

Um protótipo é uma simplificação do sistema computacional que se deseja avaliar, mantendo-se as funcionalidades e as características essenciais de tal sistema.

Os protótipos possuem menor custo e maior facilidade de alteração em relação à construção e alteração do sistema real.

Entretanto, no que se refere às outras técnicas de aferição, a construção de protótipos têm maior custo.

Para se construir um protótipo é preciso, primeiramente, verificar a adequabilidade de um sistema à construção de protótipos.

Em seguida, delimitando e conhecendo os domínios funcionais e comportamentais do sistema real é possível desenvolver o protótipo.

A construção de um protótipo é constituída de diversas fases de desenvolvimento, teste e melhorias e verificação, até que se tenha um protótipo que reproduza as características fundamentais e as funcionalidades do sistema real.

Coleta de Dados Quando, numa avaliação de desempenho, os dados podem ser obtidos diretamente do sistema computacional e a precisão é importante, a coleta de dados é uma técnica adequada.

Dentre as técnicas de aferição, coleta de dados é a mais precisa.

No entanto, a coleta de dados deve ser realizada de forma criteriosa.

A coleta de dados e o sistema sendo avaliado concorrem pela utilização de recursos, como o processador, o que pode interferir no comportamento do sistema real.

Sem tratamento adequado o tempo gasto na coleta são acrescentados aos cálculos das métricas de desempenho, gerando dados incorretos.

Uma aplicação útil da coleta de dados é a validação de modelos.

A coleta de dados pode ser aplicada a um sistema existente e os dados colhidos podem ser comparados aos dados fornecidos por um modelo desse sistema.

O modelo validado pode ser usado para verificar alternativas.

A coleta de dados é realizada com a utilização de monitores que podem ser de dois tipos, Monitores de hardware, são equipamentos de hardware específicos utilizados para coletar dados relacionados ao objeto em estudo e analisá-los.

Os monitores de hardware devem se limitar à coleta dos dados, mantendo os dados inalterados e fiéis aos dados originais.

Monitores de software, são usados em casos nos quais se deseja observar características específicas do software.

Essas características são bastante peculiares ao software e não podem ser detectadas por monitores de hardware.

Exemplos de uso são a verificação da existência ou não de uma fila de espera associada a algum recurso.

O trabalho de doutorado de Souza  aplica monitoração ao escalonamento de processos em sistemas distribuídos.

Ele objetiva prover uma arquitetura de monitoração que permita avaliar e obter métricas de desempenho representativas de maneira eficiente e com baixa sobrecarga.

Essa arquitetura pode ser usada por qualquer escalonador.

Benchmarking é uma técnica de aferição bastante empregada na avaliação de desempenho, principalmente, quando se deseja comparar alternativas.

Segundo Jain, benchmarking é o processo de comparação de desempenho entre dois ou mais sistemas por meio de medições e, para se efetuar tais medições, são utilizadas cargas de trabalho (workloads)  1 denominadas benchmarks.

Essa denominação deve-se ao fato de que o termo benchmark tem sido comumente empregado na literatura como sinônimo de carga de trabalho em geral.

Embora alguns autores restrinjam o termo benchmark a cargas de trabalho reais, nesse trabalho benchmarks serão usados como cargas de trabalho em geral.

Os benchmarks são programas utilizados para avaliar hardware, software ou sistemas computacionais completos.

Esses programas definem cargas de trabalho que representam as características essenciais de um domínio de aplicação.

Segundo Weicker, o que torna um programa um benchmark é o fato de que esse programa é padronizado (contendo especificações detalhadas), tendo sido projetado ou selecionado para executar em diferentes sistemas computacionais com o objetivo de realizar comparações justas do desempenho desses sistemas.

Assim, algumas características são importantes para um benchmark.
Portável um benchmark deve ter a possibilidade de executar em diferentes sistemas computacionais, não devendo haver qualquer dependência de hardware e software.

Um  benchmark deve poder ser executado tanto em um mainframe quanto em computadores portáteis.

Conjunto de todas as requisições de serviço (processamento) submetidas a um sistema durante um período de tempo.

Por exemplo um benchmark para avaliar computadores paralelos deve rodar em qualquer computador paralelo que se deseje comparar o desempenho.

Justo não deve haver qualquer influência em um benchmark que privilegie determinado tipo de hardware ou software.

Embora até mesmo programas portáveis possuam certas estruturas que privilegiam o sistema para o qual foram originalmente escritos, os benchmarks devem diminuir esse problema e devem ser o mais justo possível.

Relevante um benchmark deve representar adequadamente a área de aplicação para a qual se destina.

Ele deve emular (comportar-se como outro aceitando as mesmas entradas e produzindo as mesmas saídas) apenas certos domínios de aplicações específicos (que tem características de comportamento comum para os fatores sendo medidos).

Um benchmark, que se destina a representar diversos domínios de aplicações, torna-se complexo demais ou seu resultado perde a importância.

Simples Em suma, um benchmark deve ser fácil de medir e de explicar.

A especificação de um benchmark deve ser simples de entender e implementar.

Uma especificação simples ajuda a minimizar influências de implementação de uma plataforma para outra.

Um benchmark que não é simples dificilmente será adotado pelos desenvolvedores de um produto e pelos usuários.

Ao executar os benchmarks sobre diversos sistemas é possível obter as métricas de desempenho e assim realizar uma análise comparativa, garantindo qual possui melhor desempenho para um dado domínio de aplicação.

Freqüentemente, benchmarks utilizam, para medir o desempenho de sistemas computacionais, tanto tarefas mais gerais, como realização de E/S, quanto tarefas específicas, como Crivo de Eratóstenes, operações sobre matrizes, etc.

Qualquer aspecto do desempenho, que seja interessante avaliar, pode ser medido através de benchmarks.

A utilização de benchmarks também exige alguns cuidados para se efetuar a avaliação de desempenho.

Sendo Benchmarking uma técnica de aferição, é necessário verificar se a utilização dos benchmarks não influenciará o comportamento do próprio sistema.

Outro aspecto que merece atenção é a escolha das métricas de desempenho.

As métricas não podem ser genéricas, visto que, benchmarks são usados para avaliar características particulares, e devem ser adequadas para caracterizar os aspectos de desempenho sendo avaliados.

É importante considerar também as influências de outros componentes do sistema sobre os componentes sendo avaliados.

Por exemplo, as unidades MIPS (Milhões de Instruções Por Segundo) e FLOPS (Floating Point Operations Per Second) são controvérsias, pois fornecem valores perigosamente absolutos, mesmo diante de fatores distintos (como arquiteturas Reduced Instruction Set Computers (RISC) e Complex Instruction Set Computers (CISC)), que podem influenciar os resultados. 

É baseado em um algoritmo utilizado para encontrar todos os números primos abaixo de um dado número n e é utilizado para comparar microprocessadores.

A utilização de benchmarks para avaliar o desempenho de políticas de escalonamento de processos para aplicações paralelas é possível.

Como dito anteriormente, benchmarks, definem cargas de trabalho.

Assim, os benchmarks impõem uma carga de trabalho a uma política de escalonamento de processos, que deve portanto gerenciar essa carga de trabalho e responder adequadamente a ela.

Assim, um escalonador é apenas um gerenciador de carga de trabalho que deve garantir o desempenho do sistema submetido à avaliação.

Através das medições é possível dizer qual política se comportou melhor sobre determinada carga de trabalho, e que, conseqüentemente, é melhor para determinada aplicação.

A avaliação de desempenho, no atual estágio de desenvolvimento das técnicas de produção de software, é essencial para se obter um bom sistema.

Segundo Jain, a avaliação de desempenho é uma arte, que não pode ser realizada mecanicamente.

Portanto, cabe ao analista de desempenho conhecer e fazer as escolhas certas para obter sucesso em uma avaliação de desempenho.

Existem diversas técnicas de avaliação de desempenho que podem ser utilizadas para avaliar sistemas e políticas de escalonamento de processos.

A escolha da técnica a ser utilizada está diretamente relacionada ao estágio de desenvolvimento do sistema (ou política de escalonamento de processos) a ser avaliado e aos propósitos da avaliação.

As técnicas de modelagem são muito úteis quando o sistema ainda não foi desenvolvido.

Atualmente, é uma necessidade verificar o comportamento de um sistema antes mesmo de iniciar seu desenvolvimento.

Embora as técnicas de modelagem não possuam a mesma precisão das técnicas de aferição, elas são boas alternativas porque fornecem bons resultados a um custo razoável.

Quando o sistema a ser avaliado já está implementado, as técnicas de aferição são bastante adequadas, principalmente pela precisão que fornecem.

Cada vez mais as técnicas de aferição são melhoradas no sentido de fornecer resultados mais precisos e influenciar menos na execução do sistema sendo avaliado.

A técnica mais adequada quando se deseja fazer uma escolha entre dois ou mais sistemas, com base numa comparação de desempenho, é benchmarking.

Os benchmarks fornecem meios adequados para comparar diversas alternativas e garantir qual é melhor para determinado domínio de aplicação.

O escalonamento pode afetar profundamente a eficiência de um computador paralelo.

Aumentar a eficiência de uma máquina Cray T3 E, contendo 644 processadores de 80% para 90% (taxa de utilização) significa uma economia de 2 milhões de dólares, que seriam gastos na compra de 81 novos processadores para suportar a mesma quantidade de jobs.

Um bom escalonador reduz a perda de recursos, melhora a utilização do sistema e aumenta o throughput.

O escalonador é também capaz de prover melhorias do ponto de vista do usuário, diminuindo o tempo de resposta das aplicações.

Apesar disso, muitos administradores de ambientes de produção simplesmente escolhem uma política da literatura e a adaptam ao seu ambiente.

Embora se obtenha um escalonamento válido, o desempenho pode não ser adequado.

Obter desempenho no escalonamento é uma tarefa complexa, especialmente em Computação Paralela Distribuída.

Foram discutidos diversos fatores que influenciam nas decisões do escalonador e, conseqüentemente, na qualidade do serviço provido.

A obtenção de um bom escalonamento depende de uma série de características do sistema computacional utilizado e da carga de trabalho imposta ao escalonador.

Dessa forma, torna-se difícil encontrar um único algoritmo que seja eficiente para todos os sistemas, levando ao desenvolvimento de diversas propostas para cenários específicos.

Selecionar uma boa política de escalonamento depende de uma série de restrições.

Nesse contexto, a avaliação de desempenho tem um importante papel, pois permite verificar a validade de uma proposta, a qualidade do escalonamento gerado e possíveis problemas de desempenho.

A avaliação de desempenho permite também comparar e selecionar políticas de escalonamento.

Entretanto, é preciso estar atento ao fato de que diferenças de desempenho podem ser causadas também pela metodologia de avaliação.

Neste capítulo, é tratada a avaliação de desempenho no contexto específico do escalonamento de aplicações paralelas, relacionando os principais trabalhos da área.

O foco do assunto aqui tratado são as cargas de trabalho e as métricas de desempenho que têm sido utilizadas.

A seção seguinte dá uma visão geral da metodologia empregada para avaliar o escalonamento, ficando os detalhes inerentes à seleção da carga e das métricas.

A avaliação de desempenho do escalonamento requer o uso de uma metodologia adequada.

Existem diversos detalhes e opções que devem ser observados a fim de obter uma avaliação confiável, cujos resultados possam ser reproduzidos e facilmente explicados.

Não existe na literatura muitos trabalhos que tratam das metodologias empregadas na avaliação de políticas de escalonamento para aplicações paralelas.

Grande parte do conhecimento resulta de trabalhos que apresentam novas propostas para o escalonamento e utilizam a avaliação de desempenho para demonstrar a validade e/ou a superioridade da sua proposta.

Como visto no capítulo anterior, diversas técnicas se aplicam à avaliação de políticas de escalonamento.

Quando uma política está implementada num sistema real ou num protótipo, as técnicas de aferição apresentam resultados mais precisos.

A solução analítica tem sua aplicabilidade reduzida devido à complexidade.

A simulação pode apresentar resultados bastante satisfatórios.

Os modelos empregados nos simuladores representam com um alto grau de fidelidade as características de um sistema real.

No entanto, o que, geralmente, se deseja numa avaliação de desempenho é comparar alternativas e selecionar aquela que obteve o melhor desempenho.

Nesse caso, uma técnica bastante adequada é Benchmarking.

Em um dos mais importantes trabalhos voltados à avaliação de desempenho do escalonamento, Feitelson e Rudolph  discutem métricas de desempenho e propõem o uso de benchmarks para avaliar o escalonamento de aplicações paralelas.

Segundo os autores, ao contrário de benchmarks padrão, que consistem de um conjunto de jobs representativos, executados isoladamente, um benchmark para avaliar o escalonamento especifica o momento da submissão ao sistema e a estrutura interna de cada job (consumo de UCP e de memória, paralelismo, acesso a dispositivos de I/O).

Um aspecto importante dessa carga de trabalho, usada como benchmark, é que ela seja padronizada, pois, assim, é possível realizar comparações justas e confiáveis entre diferentes escalonadores.

Além disso, é possível comparar diferentes propostas independentemente se a carga de trabalho é aplicada a um sistema real, em simulação ou em solução analítica.

Parte da análise de desempenho é verificar sob que condições de carga uma política de escalonamento não é mais capaz de processar jobs.

Isso é particularmente útil para o planejamento de capacidade de um sistema.

Além disso, as diferenças de desempenho aparecem quando os sistemas sob estudo são submetidos a uma carga que estresse sua capacidade.

Tal análise só é possível em sistemas abertos on-line.

Escalonadores são sistemas de filas, os jobs chegam, podem aguardar um tempo na fila, recebem o serviço requerido e, finalmente, deixam o sistema.

Os sistemas de filas podem ser on-line ou off-line.

No caso de sistemas on-line um sistema pode ainda ser aberto ou fechado.

Os três tipos genéricos de sistemas de fila.

Em um sistema off-line todos os jobs e os recursos requeridos por esses jobs são conhecidos no início.

Nenhum job chega depois que o sistema está em execução.

Assim, um escalonamento ótimo pode ser empregado.

Sistemas off-line são frequentemente usados para escalonadores em lotes (batch) ou que utilizam compartilhamento de espaço.

Nesse caso, a avaliação utilizando técnicas analíticas fornece uma boa predição do desempenho.

Em um sistema on-line os jobs podem chegar a qualquer instante.

O escalonador deve processar novos jobs no momento em que eles chegam, sem qualquer conhecimento de chegadas futuras.

Assim, planejamento é possível somente no estado atual.

Possivelmente, o próximo job que chega requer um novo planejamento, tornando necessário alterar o escalonamento atual.

Assim, computar uma nova solução deve ser rápido e, freqüentemente, essa decisão é crítica, pois o estado do sistema pode ser profundamente afetado no futuro.

Em sistemas fechados online assume-se um conjunto fixo de jobs, havendo um limite máximo de jobs no sistema.

Novas chegadas só ocorrerão quando jobs deixam o sistema.

Nesse caso, o sistema nunca excede sua capacidade.

Um modelo mais realístico e representativo dos escalonadores atuais é o sistema aberto on-line.

Os jobs chegam num fluxo infinito, independentemente de outros jobs terminarem e das condições de carga do sistema.

Esse modelo é mais complexo, necessitando que o processo de chegada também seja modelado.

O escalonador em um sistema aberto on-line deve ser capaz de lidar com situações extremas, com intervalos de alta carga.

Assim, é interessante avaliar quando o escalonador não é mais capaz de manipular a carga que chega.

O sistema fica saturado, uma vez que um aumento na carga de trabalho não resulta em um alta utilização, mas a qualidade do serviço provido (tempo de resposta médio, por exemplo) cai significativamente.

Krallmann apresentam recomendações para a seleção e avaliação de sistemas de escalonamento de jobs em sistemas paralelos.

Segundo os autores, é possível comparar diferentes escalonadores se a mesma "função objetivo" e a mesma carga de trabalho forem usadas.

O termo "função objetivo" equivale ao termo métrica de desempenho, enfatizando que a métrica deve ser escolhida de acordo com o objetivo a que determinada política de escalonamento se propõe.

A função objetiva atribui um valor escalar, denominado custo de escalonamento, a cada escalonamento realizado.

Assim, é possível verificar se o escalonamento cumpre seu objetivo, distinguindo bons e maus escalonamentos e classificando escalonadores.

Tipicamente, o que se faz para comparar políticas de escalonamento é aplicar a mesma carga de trabalho às diferentes alternativas e verificar (por meio das métricas coletadas) como elas se comportam.

Espera-se que as diferenças nos resultados obtidos durante a avaliação reflitam as diferenças dos sistemas em estudo.

Entretanto, os resultados dependem não somente do sistema, mas também da métrica usada e da carga de trabalho imposta a ele.

Existem várias interações entre sistema, métrica e carga de trabalho que podem levar a resultados incoerentes.

A seleção de cargas de trabalho e das métricas de desempenho são discutidas nas seções seguintes.

O desempenho de um sistema computacional depende da carga de trabalho que lhe é imposta.

Assim, bons modelos de carga são necessários para avaliar o escalonamento.

Existem diversos trabalhos que discutem sobre a aplicação, caracterização e uso de cargas de trabalho na avaliação de políticas de escalonamento para aplicações paralelas.

As cargas de trabalho utilizadas para avaliar sistemas abertos on-line são compostas por duas componentes principais, um intervalo de chegada de jobs e uma descrição da estrutura interna de cada job.

A primeira componente especifica em que momento, de um dado período de tempo, um job será submetido ao escalonador.

Essa componente está relacionada às características do usuário (humano), podendo haver ciclos diários, devido aos padrões de trabalho.

Além disso, usuários tipicamente reagem ao desempenho do escalonador.

Se o tempo de resposta é pequeno, mais jobs são submetidos.

Em um certo nível de carga (muito alta) o escalonador não é mais capaz de prover um bom serviço e o tempo de resposta aumenta.

Nesse ponto, o usuário pára de submeter novos jobs e, possivelmente, o ciclo se repete.

A segunda componente especifica os requerimentos de recurso de cada job.

Consumo de UCP e elementos da estrutura interna de um job podem ser modelados, tal como paralelismo, barreira, comunicação, acesso a dispositivos de I/O.

Existe uma grande discussão a respeito de que elementos devem ser modelados, tanto no processo de chegada, quanto na descrição da estrutura de um job.

Segundo Feitelson e Rudolph  quanto mais características forem modeladas na carga de trabalho, mais características do escalonador serão exercitadas.

Isso seria útil, por exemplo, para avaliar o impacto de determinada característica provida por um escalonador sobre outro que não provê a mesma característica.

Entretanto, quanto mais detalhes uma carga de trabalho provê mais complexa ela se torna e mais difícil é compreender a interação entre seus componentes e os possíveis resultados sobre a avaliação de desempenho.

A escolha da carga de trabalho está diretamente relacionada às características do sistema em estudo e ao objetivo da avaliação.

As informações da estrutura interna dos jobs podem variar de carga para carga.

Por exemplo, se o objetivo é avaliar o desempenho de uma política de escalonamento voltada a aplicações CPU-Bound não faz sentido manter informações de acesso à rede.

Entretanto, se o objetivo é verificar a melhoria de desempenho provida por uma política que trata a comunicação entre os processos sob outra que não trata, então a informação de acesso à rede é essencial.

Existem, basicamente, duas opções para se obter uma carga de trabalho para avaliar o escalonamento.

Uma é utilizar diretamente logs coletados da execução de aplicações paralelas, a outra é utilizar modelos de cargas de trabalho.

Existe uma grande discussão a respeito das vantagens e desvantagens do uso de cada abordagem.

Os modelos, também denominados modelos de cargas de trabalho sintéticas, usam distribuições de probabilidade para gerar os dados da carga de trabalho.

Essas distribuições podem ser definidas com base em pouco ou nenhum conhecimento (modelos puros ou "naive") ou através da análise de logs de cargas de trabalhos reais (modelos realísticos).

O processo de gerar um modelo de carga de trabalho a partir de logs coletados em ambientes reais é denominado caracterização de carga.

Basicamente, o que se faz é analisar características importantes do log, definindo distribuições de probabilidades (juntamente com seus parâmetros) que reflitam um comportamento similar no modelo.

Um exemplo é o intervalo entre chegadas que pode ser modelado por meio de uma Poisson com média 1500, como utilizado em.

A caracterização de carga é uma importante área de pesquisa que têm sido intensificada nos últimos anos.

Segundo Lo, a escolha, simplesmente, entre logs e modelos de carga de trabalhos realísticos não afeta o desempenho relativo das políticas de escalonamento avaliadas, ou seja, se uma política A obtêm o melhor desempenho para um log ela também será a melhor para a carga de trabalho sintética.

Isso reforça a idéia de que para se comparar políticas o importante é que a mesma carga de trabalho seja utilizada.

Algumas observações, no entanto, podem nortear o uso de modelos de carga de trabalho realísticos, Os logs podem conter anomalias que tornam a carga não representativa.

Por exemplo, é possível encontrar submissões repetidas de um mesmo job por um mesmo usuário.

Esse comportamento pode dominar a carga de trabalho por um período relativamente pequeno e afetar o resultado do desempenho.

As modelagem de carga de trabalho é realizada basicamente com base em cargas de trabalhos reais, obtidas dos logs.

Assim, o comportamento do modelo e do log são similares.

Os modelos permitem alterar alguns parâmetros para ajustar a carga de trabalho à avaliação.

Por exemplo, pode não fazer sentido utilizar a carga de trabalho coletada em um sistema de 400 nós em outro sistema contendo apenas 64 nós.

Utilizando um modelo é possível ajustar a carga a esse parâmetro, mantendo as mesmas características da carga de trabalho real.

Diante do exposto, neste trabalho optou-se pelo uso de modelos realísticos de carga de trabalho.

A fim de obter tais modelos foram pesquisados dois repositórios de cargas de trabalho, HPC Workload/Resource Trace Respository  e o Parallel Workload Archive.

O primeiro contém apenas logs e, além disso, dados sobre o sistema paralelo e as configurações do escalonador não estão disponíveis.

O Parallel Workload Archive fornece logs e modelos realísticos.

Esses modelos são discutidos na seção seguinte.

A maior parte dos modelos disponíveis no Parallel Workload Archive foram criados com base na análise estatística de logs coletados em diferentes sistemas paralelos de larga escala.

Grande parte desses logs também estão disponíveis no repositório (vide Apêndice A).

No Parallel Workload Archive é fornecida uma descrição detalhada de cada modelo e referências, tanto do autor do modelo quanto de trabalhos que utilizam-no.

Está também disponível código para gerar cargas de trabalho utilizando o modelo e há um grande esforço em utilizar um formato padrão para definir a carga.

Esse padrão é discutido na seção seguinte.

Os modelos disponíveis se dividem em duas categorias, modelos de jobs rígidos e modelos de jobs flexíveis Chapin  Essa classificação se deve aos tipos de jobs existentes.

A flexibilidade dos jobs é classificada em rígida, moldável, evolving e maleável.

Quando o escalonador deve fornecer ao job exatamente a quantidade de recursos requerida e esta não se altera durante a execução, o job é rígido.

Só assim um job rígido é capaz de executar.

Os jobs moldáveis, ao contrário, são capazes de executar com uma quantidade mínima de recursos, melhorando seu desempenho até que uma quantidade máxima de recursos lhe seja atribuída.

O escalonador decide, dentro do intervalo, quantos recursos atribuir.

Nos jobs evolving a quantidade de recursos requerida varia durante a execução.

O job passa por diferentes fases de paralelismo, decicindo se mais ou menos recursos são necessários.

Cabe ao escalonador apenas prover a quantidade requisitada.

Nos jobs maleáveis a quantidade de recursos atribuída aos jobs pode ser alterada pelo sistema.

O escalonador decide se o job deve liberar recursos ou se recursos adicionais lhe serão atribuídos.

Os modelos para jobs rígidos fornecem o tempo de submissão, número de recursos requeridos e tempo de execução de cada job.

Ao contrário, um modelo de jobs flexíveis descreve como a aplicação executa em diferentes níveis de paralelismo.

Isso pode ser expresso, por exemplo pelo total de computação e uma função de speedup.

Os modelos Feitelson96, Jann97 e Lublin99 foram utilizados neste trabalho e serão analisados no capítulo seguinte.

Entretanto, para fundamentar a escolha adotada neste trabalho, todos os modelos são detalhados a seguir.

A escolha realizada neste trabalho baseia-se no fato de que modelos de jobs moldáveis não se aplicam às políticas de escalonamento avaliadas neste trabalho.

Isso será discutido em detalhes no próximo capítulo.

Embora não seja um modelo para aplicações paralelas, este é um modelo bastante útil.

Ele especifica o processo de chegada para jobs interativos em um ambiente multiusuário.

O modelo fornece a taxa de chegada como uma função da hora do dia, incluindo padrões de chegada cíclicos.

A função para dias normais fornece a taxa de chegada com base no tempo t, relativo à hora do dia num intervalo de 8 h30 min e 18 h.

Para ser usada em simulação baseada em eventos, onde é necessário o intervalo entre chegadas, a função deve ser derivada.

Este modelo também não é voltado a aplicações paralelas.

Ele fornece o tempo de execução de processos em um ambiente interativo.

A distribuição proposta é válida para processos maiores que três segundos.

Devido a essa restrição a probabilidade de que um processo executará mais do que t segundos.

Num estudo posterior, Harchol-Balter e Downey  reafirmaram o modelo e forneceram outros valores para k, além de outras fórmulas para obter o tempo de execução.

Este modelo é útil para jobs flexíveis.

Ele fornece características de speedup de aplicações paralelas, desbalanceamento, trabalho serial e overhead paralelo.

Ele apresenta uma função que quantificando o desbalanceamento, a quantidade de trabalho serial e por processador e os atrasos de comunicação e congestionamento fornece o tempo de execução de um job com n processadores alocados.

Nesse trabalho, são fornecidos dois conjuntos de valores.

O primeiro obtém um baixo speedup para jobs pequenos e o segundo conjunto de valores obtém um speedup razoável para jobs grandes.

Este é, provavelmente, o primeiro modelo detalhado para aplicações paralelas.

O modelo foi criado com o objetivo de refletir cargas de trabalho reais.

Da observação dos logs foram constatadas algumas características, A predominância de jobs pequenos e com tamanho igual a potência de dois, mesmo sem razões arquiteturais.

Todos os logs possuem um número significativo de jobs seqüenciais e de jobs que usam menos de dez processadores.

Há pequenos jobs que rodam por um longo tempo e grandes jobs que rodam por um curto tempo, mas a tendência é grandes jobs rodarem por um longo período.

O grau de paralelismo (ou tamanho do job) é dado por uma distribuição Harmônica de ordem 1 5  Essa distribuição foi ajustada para enfatizar jobs de tamanhos pequenos e potência de dois.

Para gerar o tempo de execução de um job é usada uma distribuição Hiper-Exponencial, tal que o coeficiente de variação seja maior que um.

Existe uma relação linear entre o tamanho do job e a probabilidade de usar a exponencial com média maior.

Assim, há uma distribuição diferente para cada tamanho de job, com tempo de execução médio maior para jobs maiores.

Uma distribuição Zipf é usada para definir o número de execuções repetidas de um job.

A probabilidade de um job ser executado n vezes é proporcional.

O processo de chegada usado no modelo segue uma distribuição Poisson, ajustada para a repetição de jobs, uma vez que um job repetido só chega ao sistema depois que o anterior termina.

Observando o código fornecido em PWA  a distribuição de intervalo entre chegadas é dada por uma Exponencial de média 1500 segundos.

Este é um modelo para jobs moldáveis e maleáveis, que inclui, portanto, uma função de speedup.

A dominância de jobs com tamanho potência de dois é ignorada nesse modelo.

Segundo o autor, isso é resultado do particionamento do sistema.

O grau de paralelismo é dado por uma distribuição Log-Uniforme.

O modelo utiliza um tempo de execução cumulativo, que equivale à soma do tempo de execução em todos os processadores.

O tempo de execução médio é obtido por meio da função de speedup, fornecendo como parâmetro o número de processadores alocados pelo escalonador.

Uma distribuição Log-Uniforme é usada.

A função de speedup é modelada usando três parâmetros, o grau de paralelismo, a variância no paralelismo e o número de processadores.

O processo de chegada segue uma distribuição Poisson.

Entretanto, as chegadas só acontecem durante a primeira parte (correspondente ao dia num ambiente real).

Na segunda parte (noite) não há chegadas, o sistema apenas executa os jobs colocados na fila.

Ele foi construído para jobs rígidos.

O modelo usa a distribuição Hiper-Erlang de Ordem Comum tanto para o tempo de execução quanto para o intervalo entre chegadas.

Os parâmetros usados baseiam em combinar os três primeiros momentos do log.

A distribuição Hiper-ErLang é um generalização das distribuições Exponencial, Hiperexponencial e Erlang.

Como as características dos jobs com diferentes tamanhos diferem, existem diferentes parâmetros de acordo com o grau de paralelismo.

Foram definidos intervalos com base em potência de dois ou múltiplos de cinco.

Cada intervalo possui seus próprios parâmetros e, além disso, existem parâmetros diferentes para intervalo entre chegadas e tempo de execução.

Esse modelo é reutilizado para modelar a carga de trabalho do LLNL ASCI Blue-Pacific.

Esse modelo difere do CTC SP2 apenas no que se refere aos valores dos parâmetros empregados.


Este não é propriamente um modelo com distribuições de probabilidade.

Trata-se de um framework para criar modelos da estrutura interna de aplicações paralelas com o objetivo de investigar as conexões entre o comportamento da aplicação e o escalonamento.

Esse framework deve ser completado com valores de parâmetros específicos para criar um modelo.

Entretanto, nenhum conjunto de parâmetros foi ainda sugerido devido à falta de logs de dados reais a respeito da estrutura interna das aplicações.

Trata-se de um modelo detalhado para jobs rígidos.

Inclui padrão de chegada baseado em um ciclo diário com intervalos de pico e correlação entre tempo de execução e o número de nós requisitados.

Segundo o autor, jobs com tamanho potência de dois devem ser enfatizados, assim como jobs seqüenciais, conforme encontrado nos logs.

Dessa forma, os jobs são divididos em três classes, seqüenciais, potência de dois e o restante.

A probabilidade de que um job seja seqüencial é 024.

Se ele for paralelo, a probabilidade de que seja potência de dois é 075.

O tempo de execução é modelado com base na correlação entre tamanho do job e tempo de execução.

É usada uma distribuição Hiper-Gamma composta de duas Gammas e um parâmetro p.

Esse parâmetro é linearmente dependente do tamanho do job.

Ao contrário da grande maioria dos modelos, o processo de chegada é detalhado.

As chegadas são baseadas em duas distribuições Gamma, uma para modelar picos no intervalo entre chegadas e outra para modelar o ciclo diário.

O modelo faz ainda distinção entre jobs batch e interativos, existindo parâmetros distintos para cada um deles.

Esse é um modelo para gerar jobs moldáveis.

Ele é composto por um modelo para gerar jobs rígidos e um modelo para converter jobs rígidos em moldáveis.

Para isso ele gera um conjunto de alternativas contendo tamanho de partição e tempo de execução.

Baseia-se no modelo de speedup de Downey, propondo novos parâmetros para as distribuições.

Trata-se de um modelo detalhado para gerar tempo de execução estimado pelo usuário de forma bastante realística.

O modelo captura o comportamento do usuário.

Pelas observações quando um usuário submete uma aplicação paralela ele fornece valores muito pequenos e, freqüentemente, fornece o maior valor permitido para a estimativa do tempo de execução.

O modelo é composto por duas partes, 1) um gerador realístico de distribuições de estimativa de tempo de execução do usuário 2) um aplicativo que adiciona a estimativa a logs e modelos existentes (utilizando formato padrão de cargas de trabalho).

Apresenta um resumo das características dos modelos disponíveis no Parallel Workload Archive.

Cada modelo recebe um nome composto pelo seu principal autor e o ano de sua criação.

Alguns modelos são para jobs paralelos (rígidos ou flexíveis), outros para jobs seqüencias em ambiente Unix.

As informações providas por cada modelo variam.

Algumas características são parcialmente informadas.

Comparação dos modelos de carga de trabalho disponíveis no Parallel Workload Archive.

Para facilitar a utilização desses modelos e dos logs das cargas de trabalho disponíveis no Parallel Workload Archive foi criado um formato padrão.

Ele é discutido na seção seguinte.

O Formato Padrão para Cargas de Trabalho, Standard Workload Format (SWF), visa facilitar o uso de logs e modelos em programas e simuladores.

Com o SWF é possível utilizar diferentes cargas de trabalho (seja um log ou um modelo) sem necessidade de alterar o código que interpreta os arquivos da carga.

O SWF foi especificado para ser portável e fácil de interpretar.

Cada carga de trabalho é armazenada em um arquivo ASCII, em que cada linha armazena os dados de um job.

As linhas contém uma quantidade pré-definida de campos, quando um campo não se aplica ao tipo de carga seu valor é "-1".

Geralmente, o arquivo começa com comentários sobre o modelo ou sobre o ambiente em que os logs foram coletados.

Os campos que compõem cada linha no arquivo que especifica uma carga de trabalho são descritos.

Uma descrição detalhada sobre o SWF pode ser obtida em Chapin A avaliação de desempenho não depende apenas do sistema em estudo e da carga de trabalho que lhe é imposta, mas também da métrica de desempenho.

Assim, para obter resultados conclusivos de uma avaliação de políticas de escalonamento para aplicações paralelas, a escolha de uma métrica adequada tem grande relevância.

Diversos trabalhos discutem o uso de métricas nesse contexto.

A métrica de desempenho deve ser escolhida com base em diversos aspectos, objetivo da avaliação, características do sistema em estudo e características da carga de trabalho.

Geralmente, para um dado problema existem diversas métricas que se aplicam.

É importante que a métrica de desempenho reflita com fidelidade o comportamento do sistema sob a carga de trabalho imposta.

Feitelson e Rudolph  apresentam uma discussão da escolha da métrica com relação ao tipo de sistema de fila.

Segundo os autores, existe uma métrica de desempenho apropriada e comumente usada para cada um dos três sistemas de fila.

Para sistemas off-line a métrica escolhida é Makespan, enquanto que para sistemas fechados on-line e abertos online as métricas mais apropriadas são, respectivamente, Throughput e Tempo de resposta.

Makespan é dado pelo tempo total gasto para executar toda a carga de trabalho.

Como em sistemas off-line todos os jobs são conhecidos no início cabe ao escalonador otimizar a alocação de recursos fornecendo o melhor tempo de resposta para cada um dos jobs e, conseqüentemente, o melhor tempo de resposta total.

Em um sistema fechado on-line o processo de chegada depende do desempenho do sistema.

Cada vez que um job termina ele é imediatamente re-submetido.

Nesse caso, a análise é verificar o Throughput, o número de jobs executados por unidade de tempo.

Tempo de Resposta é o tempo decorrido desde a submissão até o término de um job.

Esta é a principal métrica para sistemas abertos on-line Descrição dos campos do Standard Workload Format  porque Utilização e Throughput são determinados pela taxa de chegada e pelos requisitos do job, não pelo escalonador.

Feitelson e Rudolph  afirmam que a métrica Tempo de Resposta Médio enfatiza jobs longos ao invés de jobs pequenos, que são mais comuns nas cargas de trabalho.

Por exemplo, o tempo de resposta médio de 100 jobs de 1 hora e um job de 3 semanas é 6 horas.

Nesse trabalho e em outro trabalho posterior, Feitelson, os autores afirmam que isso é um problema e apresentam a métrica Slowdown como uma possível solução.

A métrica Slowdown apresenta um problema, jobs muito pequenos com atrasos razoáveis podem levar a valores de Slowdown excessivamente altos.

Por exemplo, um job que executa por apenas um segundo, mas aguarda 20 minutos na fila para ser escalonado terá um Slowdown igual a 1200.

A solução para tal problema é uma outra métrica que impõe um limite ao Slowdown, denominado Slowdown Limitado (Bounded Slowdown).

O Slowdown limitado é dado pela razão entre o maior(tempo de resposta, limite) e o maior(tempo de execução real, limite).

Assim, o mesmo job do exemplo anterior teria, utilizando um limite de 10 segundos, um Slowdown Limitado igual a 120.

Outra abordagem para a escolha da métrica de desempenho é apresentada.

Segundo os autores, a métrica de desempenho deve ser escolhida com base no objetivo do escalonamento.

Relacionar a métrica ao objetivo torna mais fácil a escolha da métrica, pois diminui-se o número possível de métricas que podem ser utilizadas.

Um exemplo são políticas de escalonamento que tem como objetivo otimizar o acesso à memória.

Com base nesse objetivo métricas relacionadas ao uso da memória serão escolhidas, como, percentual de utilização da memória, quantidade de paginação, percentual de utilização de swap.

Entretanto, ainda existem muitas métricas que se aplicam a esse objetivo.

Souza  analisa diversas métricas de desempenho quanto à sua adequação aos objetivos do escalonamento.

O autor também analisa diversas métricas quanto à sua relação com os tipos de sistemas de filas e quanto à sua aplicação em sistemas distribuídos heterogêneos.

Segundo Krallmann, cada escalonador tem seu próprio objetivo e, assim, não seria possível comparar dois escalonadores.

Por outro lado a comparação de diferentes políticas de escalonamento faz sentido se a mesma métrica de desempenho for utilizada.

Quando duas políticas de escalonamento são submetidas à mesma carga de trabalho e analisadas sob a mesma métrica de desempenho é possível concluir qual obteve melhor desempenho sob um determinado aspecto, mesmo que elas possuam objetivos distintos.

Quando se deseja, por exemplo, avaliar políticas com o objetivo de verificar qual otimiza o uso da rede, pode-se utilizar a taxa de utilização da rede para avaliar uma política que otimize o acesso à memória.

Provavelmente, a política se comportará mal, mas o fato é que a política está sendo analisada sob o aspecto da rede.

Nesse sentido, a comparação é plausível.

Quando se compara duas ou mais políticas de escalonamento espera-se que a métrica de desempenho seja capaz de fornecer resultados conclusivos à respeito da qualidade de um escalonamento.

Espera-se que a métrica ofereça uma comparação justa entre diferentes políticas, permitindo que se estabeleça uma relação do tipo escalonador > escalonador.

É preciso estar atento ao fato de que a métrica reduz o escalonamento de milhares de jobs em um único número, de forma que escalonadores sejam facilmente comparáveis.

Assim, explicar os efeitos capturados pela métrica de desempenho e responder à grande questão de qual escalonador é Esse valor foi obtido usando a primeira definição de Slowdown, tempo de resposta de um job normalizado pelo tempo em que o job está verdadeiramente executando.

O melhor depende, também, da carga de trabalho.

Diante de todo o exposto, a métrica Tempo de Resposta Médio é bastante atrativa.

Alguns pontos adicionais descrevem a escolha dessa métrica para a avaliação de desempenho conduzida neste trabalho, Tempo de resposta é uma das métricas mais conhecidas e utilizadas, sendo mais fácil para um pesquisador comparar seu trabalho com os demais utilizando uma métrica bastante conhecida.

Grande parte dos objetivos de um escalonador tem relação com diminuir o tempo de resposta.

Por exemplo, reduzir o percentual de swap é uma forma de otimizar o uso da memória que resulta em um melhor tempo de resposta.

O problema apresentado por Feitelson e Rudolph  e discutido acima não é visto neste trabalho como um problema.

Isso é apenas um reflexo do uso de uma média aritmética.

Além disso, não é incorreto o fato de jobs longos terem grande influência na métrica, uma vez que jobs grandes consomem recursos por um longo período e provocam atrasos nos demais jobs.

Neste capítulo foram apresentados alguns aspectos relacionados à avaliação de desempenho no contexto do escalonamento de aplicações paralelas.

A obtenção de resultados conclusivos em uma avaliação de desempenho requer o uso de uma metodologia adequada, principalmente quando o objetivo é comparar alternativas.

A escolha da carga de trabalho e da métrica de desempenho têm grande influência na avaliação.

Quando se deseja comparar diferentes alternativas a mesma carga de trabalho e a mesma métrica de desempenho devem ser usadas.

Entretanto, alguns aspectos relacionados à escolha de cargas de trabalho e métricas devem ser observados.

Assim, diretrizes para a escolha da carga de trabalho foram apresentadas, apontando vantagens de modelos sobre logs.

A escolha pela métrica Tempo de Resposta Médio para a avaliação conduzida neste trabalho foi justificada, uma vez que acredita-se que a utilização dessa métrica oferece resultados conclusivos.

Diversos trabalhos que comparam políticas de escalonamento de aplicações paralelas, referentes aos sistemas computacionais distribuídos, fazem uso da métrica Tempo de Resposta.

Diversas políticas de escalonamento para aplicações paralelas em ambientes computacionais distribuídos têm atraído a atenção de pesquisadores, uma vez que os resultados obtidos com tais políticas têm indicado bons desempenhos.

Entretanto, tais políticas são avaliadas com o objetivo apenas de demonstrar sua superioridade sob um determinado aspecto.

Sob diferentes condições de carga, a política pode ter seu desempenho deteriorado, o que, na maioria das vezes, não é verificado.

Analisar o comportamento de uma política de escalonamento sob diferentes cenários é uma importante tarefa para se compreender como a mesma se comportaria em um ambiente real.

Além disso, o conhecimento de como a política se comporta sobre diferentes condições de carga pode garantir que se obtenha bons desempenhos.

Vários trabalhos comparam diferentes estratégias para o escalonamento em clusters e NOW  e até mesmo em grids.

Entretanto, nesses trabalhos não há a preocupação em verificar o comportamento da política de escalonamento sob diferentes condições de carga que podem ocorrer.

Nesse contexto, o presente trabalho, estuda o comportamento de diferentes políticas de escalonamento, verificando sua aplicabilidade a clusters e grids computacionais e a diferentes situações de carga.

Foram selecionadas 10 políticas voltadas ao escalonamento em ambientes paralelos e distribuídos.

Utilizando simulação, cada uma das políticas foi submetida a uma combinação de 4 cargas de UCP e 3 cargas de rede, num total de 12 cargas de trabalho distintas.

Cada uma das cargas de trabalho foi aplicada à política de escalonamento quando em execução em 3 diferentes sistemas computacionais distribuídos.

Os sistemas computacionais considerados neste estudo foram, um cluster de 32 nós interligados por uma rede Gigabit Ethernet, um cluster de 128 nós interligados por uma rede Gigabit Ethernet e um grid de 512 nós, composto por sites que têm em média 8 computadores.

Cada um dos sites do grid se comunica com os demais por meio da Internet.

A obtenção dos dados dos sistemas utilizados na parametrização do simulador é discutido no capítulo seguinte.

Este capítulo destina-se a descrever as políticas avaliadas neste trabalho, as cargas de trabalho utilizadas e o simulador.

Quanto às políticas de escalonamento, suas principais características são discutidas, focando nos aspectos que influenciam seu comportamento e, conseqüentemente, no desempenho obtido.

As cargas de trabalho selecionadas são analisadas, sob diversos aspectos, com o objetivo de compreender os resultados obtidos nas simulações.

No que se refere ao simulador, o modelo UniMPP, utilizado para predizer o tempo de resposta, os detalhes da implementação do simulador, assim como as extensões aplicadas ao mesmo durante este trabalho, são discutidas.

Nesta seção, são apresentadas as políticas de escalonamento estudadas neste trabalho.

A política de escalonamento Round Robin é talvez a mais simples e mais conhecida das políticas de escalonamento.

Utilizando essa política os processos são atribuídos aos elementos de processamento de maneira cíclica, até que não haja mais nenhum processo a ser escalonado.

Esta política é interessante e bastante utilizada devido à coleta de informações do sistema, como tamanho das tarefas e taxa de utilização da UCP, não ser necessária.

Entretanto, em Sistemas Distribuídos, a utilização da política de escalonamento Round Robin não é adequada.

Nesses sistemas, ela pode gerar um grande desbalanceamento de carga entre os processadores, uma vez que máquinas com baixa potência computacional recebem a mesma quantidade de carga de máquinas com grande potência computacional.

Assim, devido à heterogeneidade configuracional dos Sistemas Distribuídos, essa política apresenta, freqüentemente, tempos de resposta muito mais altos do que políticas que consideram a heterogeneidade.

Analisam algoritmos de balanceamento de carga, estudando seus efeitos no desempenho de sistemas distribuídos fracamente acoplados.

Todos os algoritmos são compostos, basicamente, por dois elementos, Load Information Manager (LIM), responsável pelas políticas de informação e de localização.

A coleta e gerenciamento da informação de carga e a tomada de decisão da localização de um job são realizados pelos LIMs que executam em cada host que compõe o sistema.

Os LIMs monitoram a carga constantemente e cooperam entre eles do modo definido pelo algoritmo de balanceamento de carga.

Load Balance Manager (LBM), responsável pelo mecanismo de balanceamento de carga.

Existe um LBM em cada host.

O LBM estabelece uma conexão entre o host destino e o host remoto e, interagindo com os componentes do sistema, permite que o processo execute no host remoto.

A separação entre política e mecanismo de escalonamento torna possível a experimentação de diferentes algoritmos alterando apenas o LIM.

Assim, cinco algoritmos foram estudados, Random, Disted, Lowest, Central e Global.

O índice de carga utilizado é o mesmo para todos os algoritmos.

O índice de carga do ambiente é calculado com base no comprimento da fila de processos em espera pela UCP.

Assim, computadores com muitos processos na fila estariam, segundo este índice de carga, mais carregados.

O funcionamento de cada um dos 5 algoritmos é descrito a seguir.

Disted Neste algoritmo, a política de informação é inteiramente distribuída.

Periodicamente, os LIMs de cada host coletam a informação de carga do sistema local e calculam o índice de carga.

Caso o novo índice seja significativamente diferente do último índice calculado, o índice atual é enviado para todos os demais LIMs em cada host do sistema.

A política de localização baseia suas decisões nos índices de carga armazenados localmente.

Quando um processo é iniciado, o LIM verifica os índices de todos os hosts para decidir qual receberá o novo processo.

Na versão do algoritmo descrita em Zhou e Ferrari, o processo será executado no host com menor carga somente se a carga local estiver acima de um dado limiar.

No trabalho de Mello, o processo sempre será executado no host com a menor carga.

Esta é também a versão utilizada neste trabalho.

Se todos os hosts estiverem carregados, ou seja, o índice de carga estiver acima de um dado limite, o processo é executado no host que o iniciou.

Global Tendo em vista que o algoritmo Disted gera muitas mensagens para a troca dos índices de carga, o algoritmo Global propõe uma abordagem que visa reduzir o número de mensagens trocadas entre os hosts.

Neste algoritmo existe um LIM mestre que recebe todos os índices de carga do sistema, enquanto existe um LIM escravo em cada um dos demais hosts.

Os LIMs escravos calculam o índice de carga local e enviam para o LIM mestre quando há mudanças significativas.

Em intervalos de tempo, o LIM mestre envia para cada um dos escravos um vetor contendo os índices de carga de todos os hosts.

A política de localização deste algoritmo é igual ao do algoritmo Disted.

A decisão de alocação dos processos continua sendo distribuída.

Quando um processo é iniciado, o LIM verifica os índices de carga locais para decidir em qual host o processo será executado.

Central Neste algoritmo, existe um LIM mestre que centraliza todas as decisões.

Tanto a informação de carga coletada, quanto as requisições de execução de processos são direcionadas para o LIM mestre.

Os LIMs escravos periodicamente coletam e calculam o índice de carga e enviam para o LIM mestre, que armazena as informações de carga de todo o sistema.

Quando um processo chega num host que executa um LIM escravo, a requisição de execução do processo é repassada ao LIM mestre.

Exceto pelo fato de que a decisão de que em que host um processo será executado é tomada apenas pelo LIM mestre, a política de localização deste algoritmo é igual à política de localização do algoritmo Disted.

É preciso atentar para o fato de que neste algoritmo o LIM mestre pode se tornar um gargalo e de que tal algoritmo tem sua aplicabilidade reduzida em sistemas escaláveis de larga escala.

Lowest Este algoritmo troca informações de carga sob demanda.

Quando um novo processo chega ao sistema, o LIM do host que iniciou o processo define um conjunto de hosts, cujo limite é definido pela política de informação.

O LIM local solicita, então, para cada LIM desse conjunto de hosts, a informação de carga.

De posse desses dados, a política de localização define qual o host com a menor carga e seleciona este host para executar o novo processo.

Este algoritmo difere dos anteriores, pois o número de mensagens trocadas no sistema independe do número de computadores.

Random Diferentemente dos algoritmos Disted, Global, Central e Lowest, o algoritmo Random não utiliza qualquer informação a respeito da carga dos computadores que compõem o sistema.

Quando uma requisição para execução de um processo chega ao sistema, o computador que irá receber o processo é escolhido de forma aleatória.

Os cinco algoritmos foram avaliados e comparados em termos de seu tempo de resposta médio.

Com exceção do algoritmo Random, os demais algoritmos têm desempenho muito próximo.

As políticas de informação dos algoritmos Disted, Global e Central oferecem uma melhor alocação dos processos, mas consomem muitos recursos do sistema, sobrecarregando o meio de comunicação.

A partir de todas as análises efetuadas, foi possível concluir também que algoritmos centralizados, tais como o Global, respondem melhor para ambientes onde a carga é constantemente alterada, enquanto algoritmos distribuídos, tais como o Lowest, impõem menor sobrecarga no sistema e atingem maior escala.

Finalmente, conclui-se que o algoritmo Lowest é o mais indicado para ambientes distribuídos.

A Dynamic Policy Without Preemption (DPWP) é apresentada no trabalho de mestrado de Araújo.

Trata-se de uma política voltada a aplicações CPU-Bound que busca balancear a carga entre os elementos de processamento em ambientes distribuídos heterogêneos.

As principais características da DPWP são, Dinâmica.

Essa política tem a capacidade de se adequar às mudanças do ambiente computacional, durante a execução das aplicações paralelas.

Na DPWP não está incluído nenhum mecanismo de checkpoint e migração.

Tratamento da heterogeneidade no que tange às diferenças de potência computacional dos EPs do sistema.

No trabalho de Araújo, a DPWP utiliza como índice de carga o tamanho da fila de processos normalizado pela capacidade de processamento da UCP.

A versão utilizada neste trabalho é apresentada em Senger.

O índice de carga utilizado é a ocupação dos processos normalizado pela capacidade de processamento do EP.

A ocupação é dada pela soma dos tempos de execução dos processos na fila do EP.

Isto se deve ao fato de que o tamanho da fila de processos não é um bom parâmetro para o índice de carga.

Um EP pode conter 1 processo de 100 segundos enquanto outro tem 10 processos de 1 segundo.

No segundo caso, o tamanho da fila é maior, entretanto, o primeiro EP estará mais carregado.

A DPWP mantém um vetor que armazena o índice de carga de cada EP do sistema.

Esse vetor é mantido em ordem ascendente.

Quando um job chega ao sistema os índices de carga são recalculados e o vetor é reordenado.

Em seguida, a DPWP distribui cada um dos processos desse job seqüencialmente sobre os EPs, na ordem definida no vetor.

Se o número de processos é maior que a quantidade de EPs, a DPWP reinicia a distribuição dos processos a partir do EP na primeira posição do vetor.

Assim, privilegia-se a alocação de processos, primeiramente, nos EPs com menor carga.

A Network Bound Scheduling Policy (NBSP) foi proposta no trabalho de mestrado de Ishii.

Trata-se de uma extensão da política de escalonamento DPWP para contemplar o tratamento de aplicações Network-Bound.

O escalonamento realizado pela NBSP baseia-se em quantificar o impacto no processamento causado pela comunicação.

A NBSP incorpora duas modificações à DPWP, a adoção de equações que quantificam o impacto da comunicação e a distribuição dos processos com base em uma constante k, que define a utilização máxima da rede de comunicação.

São empregadas duas técnicas de atribuição dos processos aos EPs do sistema.

A primeira escalona da mesma forma empregada na DPWP e a segunda realiza uma alocação denominada escalonamento em grupo, na qual todos os processos de um mesmo job são alocados em um único EP.

A adoção de uma das técnicas depende da constante k.

Enquanto a largura de banda utilizada por um EP é menor do que a constante k, o escalonamento realizado pela NBSP é idêntico ao escalonamento realizado pela DPWP.

Para cada processo alocado em um determinado EP, a largura de banda utilizada por esse elemento de processamento é calculada.

Se esta largura de banda exceder o valor da constante k é aplicado o escalonamento em grupo.

Todos os processos de um job que ainda não foram escalonados são alocados no EP que ocupa a primeira posição do vetor (segundo a DPWP).

A taxa de utilização de 25% como valor da constante k mostrou-se adequada, segundo os experimentos conduzidos em Ishii  Genetic Algorithm Scheduling (GAS) é um algoritmo de escalonamento definido no trabalho de doutorado de Senger.

Ele emprega o conhecimento obtido pelas aplicações paralelas na utilização de recursos, com o objetivo de melhorar o escalonamento em ambientes distribuídos heterogêneos.

O algoritmo utiliza como entradas a aplicação paralela (número de EPs requisitados), o padrão de comportamento na utilização de recursos da aplicação, empregando o modelo de aquisição de conhecimento descrito em Senger  e a predição de sua ocupação, em milhões de instruções, obtida através do algoritmo Instance-Based Learning (IBL), descrito no mesmo trabalho.

O algoritmo também usa informações do ambiente distribuído, como capacidade e carga dos EPs, custo de comunicação.

O GAS utiliza Algoritmos Genéticos (AG) para obter uma solução aceitável de quais os EPs mais adequados para atender aos requisitos das aplicações paralelas.

AGs são baseados em técnicas de busca probabilísticas usadas para a exploração de grandes espaços de busca.

Para tanto, utiliza-se uma função de fitness para calcular a aptidão de cada indivíduo de uma população.

A função de fitness utilizada no GAS é composta por 2 termos.

O primeiro denota a estimativa do custo computacional de atribuir um processo a um determinado EP.

O segundo termo considera o custo que será adicionado ao realizar a comunicação entre os processos.

Os custos são ponderados utilizando 2 variáveis que quantificam a porcentagem de processamento e a porcentagem de comunicação entre os processos de um job.

O custo computacional do algoritmo GAS é proporcional à quantidade de EPs solicitados pela aplicação.

O algoritmo Tree Load Balancing Algorithm (TLBA) visa o balanceamento de cargas em sistemas distribuídos heterogêneos e com possibilidade de crescimento em escala.

Ele é o resultado do trabalho de doutorado de Mello.

Esse algoritmo cria uma topologia de interconexão lógica entre os EPs em formato de árvore e realiza migração de processos para melhorar o balanceamento de cargas no sistema.

Assim, o algoritmo gera um baixo número de mensagens durante as operações de balanceamento de carga, oferece estabilidade em situações de carga pesada e obtém valores baixos para tempos de resposta médio das aplicações paralelas.

O TLBA utiliza uma nova técnica para calcular o índice de carga, que se baseia na ocupação de UCP e de memória.

No TLBA, os índices de carga são calculados periodicamente.

Quando o valor do índice de carga de um EP varia acima ou abaixo de um dado limiar (threshold), o índice é propagado para demais EPs na árvore, no sentido da raiz.

Quando é preciso localizar o melhor EP para receber um processo, a TLBA busca, a partir do nó raiz da árvore (mantida em memória principal), o EP com menor carga.

Quando um EP encontra-se sobrecarregado, ele solicita ao EP raiz a média de ociosidade dos EPs do sistema.

Em seguida, a viabilidade de transferir processos de um EP carregado para outro ocioso é analisada.

Se for viável, o receptor é localizado e o processo migrado, desde que este ainda não tenha sido migrado k vezes no ambiente.

O valor k impede que um processo seja migrado indefinidamente em determinadas situações, como no caso em que todos os EPs estão 100% ocupados.

A TLBA também tem mecanismos para tratamento de falhas  Para avaliar as políticas de escalonamento estudadas nesta dissertação, foram definidas algumas cargas de trabalho.

Embora seja interessante avaliar um grid computacional com cargas caracterizadas especialmente para esse ambiente, após uma vasta pesquisa, não foram encontradas tais cargas.

Existe um esforço com o objetivo de prover modelos de cargas de trabalho para grids.

Em um dos mais significativos trabalhos, Li discutem as características da execução de aplicações paralelas em um grid formado por clusters em cinco universidades.

Entretanto, os logs coletados não têm informação de co-alocação e o sistema tem uma baixa utilização, que varia de 7,3% a 22%.

As cargas de trabalho utilizadas foram obtidas a partir de 3 modelos disponíveis no Parallel Workload Archive.

Entretanto, os modelos para jobs moldáveis não são aplicáveis às políticas de escalonamento avaliadas neste trabalho, uma vez que elas não utilizam a informação de speedup fornecida pelo modelo.

Para gerar as cargas, utilizou-se o código disponível no Parallel Workload Archive, ajustando-se seus parâmetros.

Os parâmetros de todos os modelos foram alterados para gerar jobs com um grau de paralelismo máximo de 64 nós e mínimo de 1 nó.

Para o modelo de, foram utilizados os parâmetros para jobs interativos.

De todos os códigos, as informações extraídas foram o tempo de submissão, o grau de paralelismo e o tempo de execução de cada job.

O código do modelo  forneceu valores negativos para o tempo de submissão.

Assim, tal informação foi descartada e o tempo de submissão foi obtido por meio do próprio simulador (descrito abaixo), utilizando uma função de distribuição de probabilidades Exponencial com média 1500 segundos.

A informação de que é essa a distribuição para o tempo de chegada no modelo Feitelson96, foi obtida a partir do código.

As cargas de trabalho utilizadas neste trabalho são analisadas a seguir.

Foi utilizada uma amostragem de 1000 jobs.

É apresentada a freqüência de jobs com cada grau de paralelismo.

Os códigos são bem documentados e sua compreensão é complementada pelo artigo que propõe o modelo.

O código disponível data de 1997, ano em que o modelo foi estendido.

Originalmente, o modelo não tinha distribuição para intervalo de chegada e alguns trabalhos assumiram o uso da Poisson.

Apresenta uma grande quantidade de jobs seqüenciais e de jobs com um grau de paralelismo baixo.

Nota-se que mais de 18% dos jobs são seqüenciais e quase 90% dos jobs têm, no máximo, 16 processos.

Outra característica observada é que aproximadamente 55% dos jobs paralelos têm tamanho potência de dois.

A carga  tem uma quantidade significativa de jobs com grau de paralelismo 64, que se aproxima de 8%, enquanto nas demais cargas tal valor não ultrapassa 2%.

Observa-se que a quantidade de jobs com um mesmo grau de paralelismo é melhor distribuída.

Os graus de paralelismo que têm maior freqüência variam de 1 a 8 e todos estão próximos de 6%.

Além disso, a distribuição cumulativa de tamanho de jobs chega a 90% apenas quando o grau de paralelismo é igual a 46, enquanto que nas cargas  90% corresponde, respectivamente, aos graus de paralelismo 32, 21 e 22.


Aproximadamente 40% dos jobs são seqüenciais e existem muitos jobs pequenos, quase 70% dos jobs têm no máximo 8 processos.

Um aspecto interessante que pode ser claramente observado é que a freqüência diminui à medida que o grau de paralelismo aumenta.

A freqüência de jobs com tamanho potência de dois é bem pequena, sendo insignificante a preferência por tais jobs.

Pode-se observar que, ao contrário, a maioria dos jobs tem tamanho potência de dois, cerca de 65%.

Essa carga tem apenas 12% de jobs seqüenciais, valor pequeno em relação às demais cargas.

Novamente a quantidade de jobs pequenos é alta, com aproximadamente 88% dos jobs com grau de paralelismo 16.

Outro aspecto importante a se observar nas cargas de trabalho é o tempo de execução dos jobs.

Para tanto, foram gerados os histogramas a seguir.

Com uma amostragem de 1000 jobs, é apresentada a freqüência de jobs em cada intervalo.

A respeito da carga, observa-se  que o maior job da amostra tem entre 1050 e 1060 minutos de tempo de execução.

Para a carga, esse valor é menor, com o maior job variando entre 300 e 310 minutos, enquanto  o tempo de execução do maior job se aproxima dos 1800 minutos.

Apresenta um valor moderado, sendo que o maior job tem um tempo de execução de aproximadamente 750 minutos.

Em todas as cargas, exceto, observa-se que há uma quantidade significativa de jobs grandes, sendo que estes estão mais distribuídos entre os intervalos.

No primeiro nota-se alguns intervalos em que a quantidade de jobs se aproxima de 2%, como é o caso do último intervalo.

Embora existam jobs grandes, nota-se que jobs com um tempo de execução pequeno são bem mais freqüentes.

Nas cargas a quantidade de jobs com até 10 minutos de tempo de execução se aproxima, respectivamente, de 70%, 84%, 48% e 88%.

Para se ter uma visão melhor dessa tendência, a freqüência dos jobs com até 20 minutos é apresentada, em intervalos de 10 segundos.

Em todos os casos a tendência se confirma, havendo uma quantidade maior de jobs com tempo de execução pequeno.

Nota-se que os jobs são melhores distribuídos com relação ao tempo de execução para a carga.

Observando-se os histogramas de tamanho de job e tempo de execução, nota-se que a freqüência de jobs pequenos e com baixo tempo de execução é bem maior.

A combinação de um grau de paralelismo baixo com um tempo de execução também baixo nos jobs pode levar a uma baixa utilização do sistema.

Eles correlacionam grau de paralelismo (eixo das abscissas) e tempo de execução dos jobs (eixo das ordenadas).

Nos gráficos da esquerda foram representados todos os jobs de uma amostragem de 1000 jobs.

Utilizando a mesma amostragem, nos gráficos da direita são representados apenas os jobs com até 1000 segundos de tempo de execução.

Os gráficos da direita permitem visualizar melhor uma tendência percebida nas cargas de trabalho, uma freqüência alta de jobs com baixo grau de paralelismo e baixo tempo de execução.

Na carga  grande parte dos jobs possuem baixo grau de paralelismo e baixo tempo de execução.

Entretanto, nota-se que existem jobs que impõem uma alta carga, havendo jobs que combinam alto grau de paralelismo ou alto tempo de execução.

Existe ainda jobs com grau de paralelismo e tempo de execução altos.

Por exemplo, existe um job com grau de paralelismo 64 que possui um tempo de execução de cerca de 42000 segundos.

Assim, apesar da existência de um grande número de jobs que impõem uma baixa carga, existem jobs com elevados tempo de execução e/ou grau de paralelismo.

A tendência apresentada pela curva é que quanto maior o grau de paralelismo, menor o tempo de execução do job.

Enquanto existe job seqüencial com tempo de execução de aproximadamente 18000 segundos, para o grau de paralelismo 64 um job possui um tempo de execução de aproximadamente 100 segundos.

Isso pode levar a uma baixa utilização do sistema.


A correlação entre grau de paralelismo e tempo de execução na carga  se assemelha ao comportamento da carga.

Mas existem algumas diferenças.

Nota-se uma freqüência pequena de jobs com um alto tempo de execução para os jobs com grau de paralelismo maior que 32.

Nota-se ainda um grande número de jobs seqüenciais com elevado tempo de execução.

Apesar de existir um agrupamento de jobs pequenos e com baixo tempo de execução, os jobs estão bastante dispersos em toda a área esquerda do gráfico, com uma quantidade significativa de jobs com tempo de execução alto.

Na carga  a grande maioria dos jobs com elevado tempo de execução são os jobs com grau de paralelismo potência de dois.

Essa carga, assim como na carga, apresenta um número significativo de jobs que impõem alta carga ao sistema.

Essa característica só não é percebida na carga.

Complementando o estudo das cargas de trabalho utilizadas, a submissão de jobs ao sistema é analisada nos gráficos a seguir.

A submissão de jobs ao sistema, modelada por meio do intervalo entre chegadas, é um importante parâmetro para especificar uma carga de trabalho para sistemas abertos on-line (para informações sobre sistemas abertos on-line e sobre o intervalo de chegada como um dos componentes de cargas de trabalho para avaliar tais sistemas).

Para a carga, 80% dos jobs tem um intervalo entre chegadas próximo ou inferior a 2500 segundos.

Para a carga, representada no gráfico, este índice é alcançado próximo dos 700 segundos.

Para as cargas  e  80% dos jobs tem um intervalo entre chegadas inferior a, respectivamente, 500 segundos e 300 segundos.

Os gráficos representam 144 horas de execução de um sistema paralelo.

O tempo é dividido em intervalos de 1 hora e é dada a quantidade de jobs submetidos em cada um desse intervalos.

Correlação entre intervalo de chegada e quantidade de jobs submetidos.

Os gráficos acima ressaltam o comportamento do usuário que submete os jobs.

Notase nos gráficos que após intervalos com alta submissão existe intervalos em que a quantidade de jobs submetidos ao sistema cai bastante, havendo intervalos sem submissão.

O usuário reage ao tempo de resposta obtido no sistema, ou seja, se o tempo de resposta é pequeno os usuários submetem mais jobs.

Quando esse tempo de resposta aumenta, devido à existência de muitos jobs no sistema, o usuário para de submeter jobs.

Uma informação essencial para esse trabalho e que não é fornecida nas cargas de trabalho descritas acima é a comunicação entre os processos utilizando a rede.

Assim, para avaliar o impacto da comunicação sobre o tempo de resposta obtido com o uso das políticas de escalonamento, cada umas das 4 cargas de trabalho descritas acima foram combinadas com 3 variações do uso da rede de comunicação, gerando um total de 12 cargas de trabalho.

A primeira variação é sem uso da rede, ou seja, os processos não se comunicam por meio da rede, sendo, nesse caso, aplicações "bag-of-tasks".

Na segunda variação é utilizada uma distribuição de probabilidades para o envio e o recebimento de mensagens utilizando a rede de comunicação que segue uma Poisson com média 100 Kbps.

Na terceira variação também é utilizada uma distribuição de probabilidades para modelar o uso da rede de comunicação e, nesse caso, utiliza-se uma Poisson com média 1000 Kbps.

Essa função de distribuição de probabilidades foi adotada com base nos experimentos conduzidos em Ishii, que demonstraram que a Poisson segue o mesmo comportamento da função Hiper-Exponencial, definida no trabalho de Chodnekar  A avaliação de desempenho conduzida neste trabalho utiliza simulação.

Para realizar tal simulação, foi adotado o modelo Unified Modeling for Predicting Performance (UniMPP), definido por Mello e Senger.

Por meio desse modelo, é possível predizer o tempo de resposta de aplicações paralelas em ambientes distribuídos heterogêneos, como clusters e grids computacionais.

O UniMPP unifica os modelos, para consumo de UCP, para tempo gasto na transmissão de mensagens e os modelos para volume de mensagens e distribuições de probabilidades de geração de mensagens.

O UniMPP agrega ainda características de atrasos voluntários das aplicações e acesso a disco.

Mello e Senger  conduziram experimentos a fim de validar o modelo e demonstraram que o o mesmo é capaz de predizer, com precisão, o comportamento da execução de aplicações paralelas em ambientes distribuídos heterogêneos.

O tempo de resposta gerado por meio do modelo foi similar ao observado em execuções reais, apresentando erros com valores próximos a 0.

Nesse modelo, um processo p chega ao sistema no instante a, seguindo uma função de distribuição de probabilidades e é iniciado no computador c, que mantém uma fila q de seus processos no instante t.

Cada computador c é composto pela sêxtupla, onde, pc é a potência computacional total do computador i, medida em instruções por unidade de tempo (MIPS, por exemplo), mm é o total de memória principal, vm é o total da memória virtual, dr é o throughput de leitura do disco rígido, dw é o throughput de escrita no disco rígido e lo é o tempo consumido no envio e recebimento de mensagens.

Os processos das aplicações paralelas são representadas pela sêxtupla {mp, sm, pdfdm, pdfdr, pdfdw, pdfnet }.
Onde, mp representa o consumo de processamento, sm é a quantidade de memória estática alocada pelo processo, pdfdm é a função de distribuição de probabilidades para a ocupação dinâmica de memória, pdfdr é a função de distribuição de probabilidades para leitura no disco rígido, pdfdw é a distribuição de probabilidades para escrita no disco rígido, pdfnet é a distribuição de probabilidades para envio e recebimento de mensagens utilizando a rede de comunicação.

O UniMPP fornece as equações para quantificar os atrasos impostos a um processo e para obter o tempo de resposta do mesmo.

Quando um processo p é executado em um computador c, seu tempo de execução TE  é dado pela equação 6 1  Essa equação se aplica a condições ideais, ou seja, não há nenhum atraso causado por competição, por acesso à memória ou a dispositivos de I/O.

Assim, TE  é dado pela razão entre mp e pc, que devem ser expressos na mesma métrica, como MIPS ou MFLOPS.

A equação fornece o tempo de execução de um processo considerando o atraso gerado pelo uso das memórias principal e virtual.

TE é dado pela equação e  representa uma porcentagem obtida por meio de uma função de atraso.

A função de atraso é gerada por uma ferramenta de benchmark (explicada a seguir) em que no eixo x é dada a ocupação da memória até que toda a memória virtual seja usada e no eixo y é dado o valor de  (o atraso imposto à execução do processo devido à ocupação da memória).

Por meio de experimentos, Mello e Senger  observaram que a função de atraso por ocupação da memória tem um comportamento linear durante o uso da memória principal e exponencial a partir do momento em que a memória virtual começa a ser usada.

Considerar o atraso na execução de um processo causado pelo uso da memória não é suficiente para predizer com precisão seu tempo de resposta.

Assim, o modelo UniMPP foi complementado com equações para quantificar atrasos gerados pelo acesso ao disco, tanto leitura quanto escrita e atrasos gerados pelo envio e recebimento de mensagens na rede de comunicação (equação 65).

A equação modela o atraso imposto à execução de um processo gerado por leitura ao disco rígido, em que nr é o número de acesso de leitura, bsize representa o tamanho do buffer de dados, dr representa o throughput para leitura no disco e wtdr representa o tempo de espera para usar o recurso.

Para operações de escrita no disco rígido é fornecida a equação 64, em que nw é o número de acessos de escrita, bsize representa o tamanho do buffer de dados para escrita, dw representa o throughput para escrita no disco rígido e wtdw representa o tempo de espera para usar o recurso.

Os atrasos causados pelo uso da rede de comunicação variam de acordo com diversos fatores, largura de banda, latência, overhead do protocolo de comunicação, tamanho da mensagem.

O atraso causado pelo envio e recebimento de mensagens é definido na equação, na qual nm é o número de mensagens recebidas e enviadas, é o tempo gasto para enviar e receber mensagens na rede de comunicação, sem considerar a espera pelo uso do recurso e wtn representa o tempo de fila para enviar ou receber uma mensagem quando o recurso está ocupado.

Representa o overhead da mensagem que é multiplicada por 2 para quantificar o empacotamento no emissor e o desempacotamento no receptor e l  representa a latência para transmitir uma mensagem.

No modelo UniMPP, é proposta a equação que unifica os modelos de atrasos definidos nas equações acima.

Por meio dessa equação, é possível predizer o tempo de resposta de um processo p em um computador c, em que lz é o atraso voluntário do processo, gerado por chamadas de sistema sleep.

Quando há migração do processo, os parâmetros (capacidade da rede, memória, disco) do computador em que o processo está executando podem alterar os atrasos impostos ao processo, assim o tempo de resposta de um processo p que migra entre n computadores é obtido pela equação 68 O modelo UniMPP foi implementado em um simulador, denominado SchedSim.

Ele foi implementado em Java  e utiliza conceitos de orientação a objetos, que facilitam sua extensão e adição de funcionalidades.

O simulador é parametrizado com a configuração de um ambiente computacional (capacidade de UCP, memória principal e virtual, throughput de disco, capacidade da rede de comunicação) e recebe processos para execução, cujos dados podem ser obtidos de funções de distribuição de probabilidade ou de arquivos de dados.

Utilizando esse simulador, é possível avaliar diferentes estratégias de escalonamento.

A fim de obter uma parametrização mais próxima de um ambiente de execução real, é definido, juntamente com o simulador, um conjunto de benchmarks que permitem extrair informação de um sistema real.

Esses benchmarks foram utilizados para parametrizar as simulações conduzidas neste trabalho.

As ferramentas de benchmark são, mips mede a capacidade do processador em Milhões de Instruções Por Segundo (MIPS).

Memo, mede os atrasos causados pela troca de contexto entre processos, durante a ocupação de toda a memória principal e virtual.

Discio, mede o throughput médio de escrita (com e sem buffer) e o throughput médio de leitura em discos rígidos e em dispositivos de armazenamento remotos (via NFS).

Net, permite avaliar o tempo gasto no envio e recebimento de mensagens sobre a rede de comunicação, por meio de duas aplicações, uma cliente e outra servidora.

Visando realizar a avaliação de desempenho aqui conduzida, o simulador SchedSim foi utilizado e estendido para se adequar às necessidades deste trabalho.

A primeira extensão foi a implementação de outras duas políticas.

O simulador permite a implementação de diferentes algoritmos de escalonamento, empregando o conceito de Abstração.

Dentre as dez políticas utilizadas, duas foram implementadas neste trabalho, a política Round Robin e a política NBSP.

As políticas Random, Disted, Global, Central, Lowest e TLBA foram implementadas no SchedSim durante o trabalho de Mello e Senger.

As políticas DPWP e GAS foram implementadas por Senger.

A política DPWP utilizada neste trabalho é uma versão estendida.

Na versão original, a DPWP utiliza como índice de carga o tamanho da fila de processos normalizado pela capacidade do processador.

Neste trabalho, ao invés do tamanho da fila é utilizada a ocupação dos processos.

Originalmente, o simulador obtém o intervalo entre chegadas utilizando uma função de distribuição de probabilidades.

Para permitir também a obtenção do intervalo entre chegadas a partir de um arquivo, o simulador foi modificado.

Essa modificação permite que o intervalo de chegadas seja obtido a partir do campo Tempo de submissão do formato padrão para cargas de trabalho (SWF).

O intervalo entre chegadas de um job e um job é obtido pela diferença entre Tempo de submissao e Tempo de submissao.

Outra extensão aplicada ao simulador se refere à geração de mensagens na rede de comunicação.

Ela foi necessária para permitir a geração de uma carga de rede pesada e para obter mais controle sobre o número de mensagens geradas.

A cada quantum do processador fornecido para a execução de um processo, este gera um dado número de mensagens.

Com a extensão no simulador, o número de mensagens geradas é dado pela taxa de comunicação nesse intervalo dividida por 32 bytes, o tamanho (fixo) de cada mensagem.

A taxa de comunicação de um processo é dada por uma função de distribuição de probabilidades.

Neste trabalho, quando há uso da rede, a taxa de comunicação segue uma Poisson com média de 100 Kbps ou 1000 Kbps.

Para tornar o simulador mais flexível, foram implementados dois geradores de configurações de clusters e NOW's.

O primeiro utiliza dados de computadores parametrizados por meio dos benchmarks fornecidos com o simulador e permite a replicação de tais dados.

O inconveniente de tal opção é que quando se deseja um sistema de larga escala com base em poucos computadores parametrizados, obtém-se um sistema com pouca heterogeneidade.

O segundo gerador resolve esse problema.

Ele utiliza funções de distribuição de probabilidades para obter cada um dos parâmetros que compõem um computador segundo o modelo UniMPP.

A segunda opção foi utilizada neste trabalho e será detalhada.

Os dados gerados a respeito do sistema é armazenado em formato XML, podendo ser interpretado, posteriormente, pelo simulador.

Este capítulo destinou-se a apresentar o estudo conduzido neste trabalho.

Foram discutidas as políticas de escalonamento avaliadas e as cargas de trabalho a que tais políticas foram submetidas.

Todas as políticas são voltadas a ambientes computacionais distribuídos e buscam minimizar a comunicação para realizar o escalonamento.

Exceto a política NBSP e GAS, todas as políticas são voltadas a aplicações CPU-Bound e não tratam da comunicação entre os processos que compõem uma aplicação.

A NBSP é voltada a aplicações Network-Bound e a política GAS contempla o tratamento da comunicação entre os processos que compões um job.

A análise das cargas demonstrou características distintas em cada uma.

A carga se distingue bastante das demais, apresentando uma baixa requisição de serviço.

A quantidade de serviço requerida por cada carga de trabalho também difere.

As cargas  apresentam uma grande freqüência de jobs com tamanho potência de 2, enquanto isso não ocorre nas demais ( e ).

Em todas as cargas, a freqüência de jobs com um baixo grau de paralelismo (menor que 16) e um baixo tempo de execução (menos de 1 hora) ultrapassa 50%.

A combinação dessas cargas com as cargas de rede garante que as principais características das políticas e dos sistemas computacionais serão consideradas.

A avaliação de desempenho foi conduzida com a utilização de simulação.

Assim, o simulador utilizado, assim como o modelo que ele implementa foram discutidos.

O modelo UniMPP mostra-se bastante adequado à avaliação realizada neste trabalho, fornecendo resultados precisos.

A flexibilidade do simulador desenvolvido em Java e orientado a objetos garantiu que as extensões necessárias a este trabalho pudessem ser implementadas.

As extensões foram a implementação de novas políticas, o modo de leitura do intervalo de chegada, a geração de mensagens para a rede de comunicação e os geradores de sistemas computacionais para parametrizar o simulador.

Desse modo, foi possível conduzir o estudo proposto neste trabalho, obtendo bons resultados da comparação das diferentes políticas sob as diferentes cargas de trabalho em clusters e grids.

No capítulo seguinte são apresentados a parametrização do simulador e os resultados obtidos na avaliação de desempenho.

Neste capítulo, é discutida a parametrização do modelo de simulação utilizado neste trabalho, assim como os resultados obtidos.

Conforme discutido anteriormente, a simulação foi utilizada para obter o resultado da execução das políticas de escalonamento.

O resultado de cada execução é expresso em Tempo de Resposta Médio.

Simulação oferece bons resultados quando se utiliza um modelo adequado.

O modelo UniMPP, utilizado neste trabalho, oferece resultados bastante precisos, permitindo cumprir um dos objetivos propostos para o estudo conduzido nesta dissertação, obter resultado o mais próximo possível de um ambiente real.

Para tanto, o modelo precisa ser parametrizado com dados da configuração de clusters e grids, assim como os encontrados em ambientes de produção e acadêmico.

Tais sistemas são, geralmente, compostos por um elevado número de computadores interligados por uma rede de alta velocidade.

Entretanto, tais clusters e grids não estão disponíveis para efetuar a parametrização.

A solução encontrada foi gerar tais sistemas de forma estatística, utilizando funções de distribuição de probabilidades para obter cada um dos parâmetros necessários à avaliação de desempenho.

As distribuições usadas para cada um dos parâmetros que compõem a sêxtupla que modela um computador c no modelo UniMPP foram, Para aproximar os sistemas gerados de sistemas reais, foram utilizados alguns limiares, obtidos de um sistema real parametrizado por meio dos benchmarks providos com o simulador.

Essa parametrização foi realizada nos laboratórios de computação do LaSDPC e da Universidade Estadual de Ponta Grossa, Paraná neste trabalho e no trabalho de Senger.

Os computadores denominados antrax, pegasus e andromeda formam um cluster interligado por uma rede Gigabit Ethernet.

Os computadores são interligados aos demais através da Internet, assim como em grids computacionais.

Diagrama do sistema utilizado na parametrização.

Tempo gasto para enviar e receber mensagens na rede de comunicação, para cada par de computadores do sistema parametrizado (em segundos) Observando os valores do sistema parametrizado, verifica-se que existem limites entre as capacidades de cada elemento de um computador.

Por exemplo, dificilmente um computador com 1200 MIPS terá apenas 16 MB de memória principal e 1024 MB de memória virtual.

A fim de gerar dados de computadores, mantendo os limites entre as capacidades de componentes próximos aos limites em um computador real, foram definidos alguns limiares.

Para gerar a capacidade de processamento do computador i, pc, utiliza-se apenas a distribuição Normal com média 1500.

A fim de gerar a quantidade de memória principal, mm, limiares são considerados da seguinte maneira, se 068  c  41, então mm é considerado, senão um novo valor de mm é gerado, utilizando a distribuição, até que a relação seja verdadeira.

Os valores dos limiares, 068 e 41, foram obtidos do menor e do maior valor da relação  MIPS observada nos computadores parametrizados com benchmarks, conforme memoria principal.

Para obter os valores da memória virtual, mv, do throughput de escrita, dw, e do throughput de leitura, dr, do disco rígido, uma idéia semelhante foi aplicada.

Se 05 10, então o valor de mv é considerado, senão mv é gerado novamente utilizando a distribuição.

Para o disco, se a relação for satisfeita, então dr e dw são considerados, senão dw é gerado novamente, até que a relação seja verdadeira.

Os limiares para a memória virtual e o disco foram obtidos da mesma maneira.

Os valores 05 e 10 são, memoria principal respectivamente, o menor e o maior valor da relação observada na  memoria virtual throughput leitura em disco.

Para gerar a matriz de tempo gasto para enviar e receber mensagens na rede de comunicação, entre cada par de computadores, é considerado, primeiramente, o número de redes, nn.

Utilizando uma função de distribuição de probabilidade Normal com média nn, cada computador é colocado em uma das nn redes.

Considerando-se um tempo nulo para a comunicação entre processos no mesmo computador, os demais casos são dados pelo seguinte, se os dois computadores fazem parte da mesma rede(esse é o valor de para 2 computadores em uma rede Gigabit Ethernet), senão  segue uma distribuição Exponencial com média 1 segundo.

Os valores obtidos são observados na comunicação entre 2 computadores que utilizam a Internet.

Dessa forma, foram gerados os 3 sistemas computacionais distintos para parametrizar o simulador.

Nesses dois clusters, foi considerado uma única rede e, assim, todos os pares de computadores têm igual a 000004.

O terceiro sistema gerado é um grid com 512 nós.

Cada site foi gerado com uma média de 8 computadores, ou seja, nn = 64.

No grid, computadores no mesmo site têm igual a 000004, enquanto computadores em sites distintos possuem valores de elevados para representar o uso da Internet.

Utilizando o sistema parametrizado, foram obtidas as equações que fornecem o valor de na equação 62 e que permitem quantificar os atrasos impostos pelo uso da memória principal e virtual.

Essas equações foram obtidas por meio da execução do benchmark memo.

A parametrização dos processos que chegam ao sistema é obtida das cargas de trabalho.

Das cargas são extraídas as distribuições de probabilidade para intervalo entre chegadas, consumo de UCP por processo e grau de paralelismo.

A distribuição de probabilidades para o envio e o recebimento de mensagens utilizando a rede de comunicação segue uma Poisson com média 0 Kbps, 100 Kbps ou 1000 Kbps.

Utilizando a parametrização apresentada na seção anterior, diversas simulações foram conduzidas.

Como discutido, simulação oferece bons resultados, próximos de uma execução real.

Além disso, uma das grandes vantagens do uso de simulação é o controle sobre os parâmetros de entrada.

Assim, a fim de verificar a influência das cargas de trabalho e dos diferentes ambientes computacionais sobre as políticas de escalonamento, foram conduzidos diversos experimentos, em um total de 3240 simulações.

As 10 políticas de escalonamento discutidas(Random, Lowest, Disted, Global, Central, TLBA, GAS, Round Robin, DPWPExt, NBSP) foram submetidas às cargas quando em execução em um cluster de 32 nós, em um cluster de 128 nós e em um grid de 512 nós.

Para cada um desses cenários, foram ainda aplicadas 3 cargas de rede distintas.

Cada experimento foi executado 10 vezes a fim de obter a média aritmética.

Para aferir a significância estatística de tais experimentos, optou-se por utilizar intervalos de confiança.

As médias obtidas de cada experimento e o intervalo de confiança de 95% são apresentados no Apêndice B.

Neste apêndice é também discutido o cálculo do intervalo de confiança para amostras pequenas.

Cada gráfico sumariza os resultados obtidos da execução das 10 políticas estudadas neste trabalho quando submetidas à execução em um determinado ambiente computacional, impondo-lhes uma carga de UCP e uma carga de rede.

O eixo x representa a quantidade de jobs executados e o eixo y representa o tempo de resposta médio.

Para facilitar a visualização dos resultados obtidos com as cargas de rede, os gráficos foram agrupados, pelo ambiente computacional e pela carga de UCP, variando-se apenas a informação da rede.

Os três gráficos, na página seguinte, sumarizam os resultados da execução da carga de UCP  em um cluster de 32 nós interligados por uma rede Gigabit Ethernet.

Foram representadas as curvas resultantes da execução das 10 políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Nota-se dois conjuntos de políticas com tempos de resposta médios bastante próximos.

As políticas Lowest, Disted, Global, Central e TLBA formam o primeiro conjunto, com os menores tempos de resposta médios.

O segundo conjunto é formado pelas políticas Round Robin, NBSP e DPWP.

A política Random obteve um tempo de resposta médio maior que esses dois conjuntos, apresentando melhor desempenho apenas do que a política GAS.

A GAS obteve o pior desempenho e distanciou-se significativamente das demais políticas de escalonamento, que obtiveram o comportamento esperado.

Os resultados obtidos pela política GAS devem se a função de fitness utilizada, que, provavelmente, apresenta melhores resultados em sistemas com alta carga.

Cluster 32 nós com a carga, sem rede Cluster 32 nós com a carga, 100 Kbps Cluster 32 nós com a carga, 1000 Kbps Um aspecto a se observar é o fato da política Round Robin possuir resultados muito próximos às políticas NBSP e DPWP, o que não deveria ocorrer.

Considerando-se que o sistema utilizado é bastante heterogêneo, esse aspecto pode ser explicado por uma baixa carga imposta ao sistema.

Verificando-se as características da carga  nota-se que isso pode ocorrer.

Essa carga possui intervalos entre chegadas altos e uma alta freqüência de jobs com baixo tempo de execução e baixo grau de paralelismo.

Entretanto, nota-se uma menor variação dos tempos de resposta médios da política GAS em relação às demais políticas.

Isso evidencia o fato da função de fitness se comportar melhor em condições de carga mais elevadas.

Quanto maior a carga de rede, melhor o comportamento da política GAS.

Os três gráficos a seguir, sumarizam os resultados da execução da carga de UCP  em um cluster de 32 nós interligados por uma rede Gigabit Ethernet.

Representam os resultados da execução das políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Em todos os gráficos nota-se um tempo de resposta muito baixo, o que se deve à baixa utilização que carga  impõe ao sistema.

Neste sistema, com uma rede Gigabit Ethernet, a introdução de carga de rede não altera o cenário.

Observa-se que a política GAS obtém os piores resultados, seguida pela Random.

As demais políticas de escalonamento, apresentam um comportamento similar.

Esse comportamento se repete quando a carga de rede aumenta.

Na próxima página são apresentados os resultados da execução da carga de UCP  para um cluster de 32 nós interligados por uma rede Gigabit Ethernet.

Os gráficos representam os resultado da execução das políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Nota-se novamente que o aumento da taxa de comunicação entre os processos não aumenta, significativamente, o tempo de resposta dos processos.

A taxa de comunicação não impõe uma alta ocupação à rede.

Entretanto, o aumento da taxa de comunicação evidencia, mais uma vez, que a função de fitness da política GAS se comporta melhor em condições de maior carga de rede.

A política GAS se aproxima das demais políticas, chegando a obter melhores desempenhos que a política Random, à medida que a carga de rede aumenta.

Independentemente do aumento da carga de rede, as políticas TLBA, Lowest, Disted, Central, Global, NBSP, DPWPExt e Round Robin apresentam a mesma ordem de classificação.

A política TLBA obtém o menor tempo de resposta médio, seguida pela Lowest, Central, Disted, Global.

Isso é um aspecto esperado em todos os cenários, uma vez que o escalonamento produzido por essas políticas é muito próximo.

Com exceção da política Lowest, os índices de carga dessas políticas são coletados e utilizados nas decisões do escalonamento de forma bastante semelhante.

A política Random apresenta tempos de resposta médios bastante próximos para as três cargas de rede, conforme observado nos gráficos.

Já a política GAS, quando a rede não é utilizada, apresenta o pior tempo de resposta dentre as 10 políticas.

Na presença de comunicação por intermédio da rede a política GAS se aproxima das demais, obtendo melhor desempenho que a Random.

Isso novamente evidencia que a função de fitness se comporta melhor em cenários com uso da rede.

Em todos os gráficos anteriores as políticas NBSP e DPWPExt apresentam um comportamento bastante similar entre elas.

Isso acontece quando não há sobrecarga na rede.

Em casos em que há sobrecarga na rede a DPWPExt tende a obter desempenhos piores.

Dessa forma, pode se concluir que o aumento da taxa de comunicação não provoca sobrecarga na comunicação entre os processos utilizando a rede e, consequentemente não causa impacto sobre o tempo de resposta obtido na execução das políticas.

Outro aspecto a se observar é o comportamento da política Round Robin, que possui tempos de resposta médios muito próximos aos das demais políticas.

Tal aspecto pode ocorrer em sistemas homogêneos ou quando a carga imposta ao sistema não é significativa.

Uma vez que o cluster utilizado nesses cenários é heterogêneo, e provável que esse aspecto esteja relacionado à carga imposta ao sistema.

Para finalizar a análise dos cenários que utilizam o cluster de 32 nós, com rede Gigabit Ethernet, são apresentados os resultados da execução da carga de UCP.

Novamente, esses gráficos representam os resultado da execução das políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Grande parte das características apresentadas pelas políticas de escalonamento para as cargas de trabalho, e  se repetem para a carga.

A ordem de classificação entre as políticas é também o mesmo, com a TLBA apresentando os melhores tempos de resposta médios e a formação de dois conjuntos de políticas, com tempos de resposta médios bem próximos, TLBA, Lowest, Central, Disted e Global num conjunto e NBSP, DPWPExt e Round Robin noutro conjunto.

Outro aspecto que se repete é o pior tempo de resposta da política GAS, com um elevado tempo de resposta (em comparação com as demais políticas) na ausência de carga de rede.

O comportamento das políticas para a carga  se assemelha ao comportamento das políticas para a carga.

Nota-se um elevado pico no tempo de resposta médio para 60 jobs submetidos ao sistema.

Este aspecto é notório para a carga  que possui intervalos com um elevado número de jobs submetidos ao sistema seguidos por uma elevada queda desse número.

Esse aspecto, assim como na carga  representa a interação dos usuários com o sistema, modelando a reação do mesmo ao tempo de resposta.

Quando o tempo de resposta é baixo, mais jobs são submetidos ao sistema e quando o tempo de resposta aumenta o número de jobs submetidos tende a diminuir.

Os cenários apresentados a seguir envolvem o uso de um cluster de 128 nós interligados por uma rede Gigabit Ethernet.

Novamente os cenários são variados, executando as 10 políticas sem carga de rede, com uma carga de 100 Kbps em média por processo e com uma carga de 1000 Kbps em média por processo.

Os tempos de resposta médios e o comportamento das políticas NBSP, DPWPExt, TLBA, GAS, Central, Global e Disted quando executadas no cluster de 128 nós são bastante similares aos resultados obtidos nos cenários utilizando um cluster de 32 nós.

Já as políticas Random, Round Robin, Lowest quando executadas no cluster de 128 nós obtiveram desempenhos piores aos observados no cluster de 32 nós, além de uma maior variação na curva dos tempos de resposta médios.

Esses resultados podem ser explicados por dois motivos principais, O sistema não foi bem exercitado, ou seja, a carga de trabalho não foi suficiente para causar impacto sobre o tempo de resposta médio.

O cluster de 128 nós é bem mais heterogêneo e provê maior custo para o algoritmo de escalonamento.

As políticas Round Robin e Random não coletam/utilizam qualquer índice de carga, podendo realizar escalonamentos em computadores sobrecarregados.

Embora a política Lowest utilize índices de carga, apenas uma pequena fração da quantidade de computadores total é considerada no momento de um escalonamento.

Assim, computadores com maior potência computacional livre podem ser desconsiderados para receber processos, utilizando tal política.

Nas simulações realizadas em ambos os clusters a política Lowest coleta e utiliza índice de carga de 8 computadores, selecionados aleatoriamente.

A seguir são apresentados os resultados da execução da carga de UCP  no cluster de 128 nós interligados por uma rede Gigabit Ethernet.

Representam os resultado da execução das 10 políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Analisando os gráficos para a carga de trabalho  em um cluster de 128 nós para a mesma carga em um cluster de 32 nós, observa-se que, exceto pelas políticas Random, Round Robin e Lowest, as políticas se comportam de forma semelhante nesses dois sistemas.

No cluster de 128 nós, as políticas Random, Round Robin e Lowest apresentam tempo de resposta médio superiores ao observados no cluster de 32 nós.

Conforme discutido, isso se deve à maior heterogeneidade deste cluster e das políticas utilizarem pouca ou nenhuma informação de carga.

Assim como nos gráficos anteriores a política GAS obtém melhores resultados para cargas de rede mais altas.

No intervalo entre 10 e 20 jobs a GAS obtém o melhor tempo de resposta dentre todas as políticas, mas perde desempenho quando o número de jobs aumenta.

A política TLBA obtém os melhores resultados para quase todos os pontos da curva nos três gráficos.

As políticas NBSP, DPWPExt, Disted, Global e Central apresentam resultados muito próximos à TLBA.

Há uma grande variação na curva apresentada pela política Random.

Essa política realiza o escalonamento selecionando aleatoriamente os computadores que receberão os processos de um job.

Devido à heterogeneidade essa política pode obter desempenhos muito ruins.

Os resultados da execução da carga de UCP  em um cluster de 128 nós interligados por uma rede Gigabit Ethernet são apresentados nos gráficos a seguir.

Contêm os resultados da execução das políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Como nos resultados do cluster de 32 nós o tempo de resposta obtido pelas políticas é bem pequeno, evidenciando a baixa utilização do sistema, inclusive da rede de comunicação.

Independentemente da taxa de comunicação, os tempos de resposta médios das mesmas políticas são muito próximos.

É interessante notar que, para a carga Jann-ASCI, as políticas NBSP e DPWPExt apresentam os melhores tempos de resposta, ao contrário do que acontece para as demais cargas, em que a política TLBA apresenta os melhores resultados.

A carga de rede é nula para o primeiro gráfico, de 100 kbps em média por processo no segundo e de 1000 kbps em média por processo no terceiro gráfico.

O comportamento das políticas de escalonamento para essa carga no cluster de 128 nós é similar ao comportamento das políticas para a carga  nesse mesmo ambiente computacional.

A mesma ordem de classificação das políticas pode ser observada.

Pode se notar, entretanto, que a política GAS obtém tempos de resposta com menor variação para as diferentes quantidades de jobs.

Apresentam os resultados obtidos da execução da carga  no cluster de 128 nós com rede Gigabit Ethernet.

As mesmas cargas de rede dos casos anteriores foram avaliadas, carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Os resultados obtidos para essa carga é semelhante aos resultados obtidos para as cargas  e, incluindo a ordem de classificação das políticas.

A única exceção é a política GAS que obtém o pior tempo de resposta entre todas as políticas e o pior resultado, obtendo desempenho superior apenas a política Random.

Em todos os cenários que utilizaram clusters verificou-se que nem mesmo a inserção de carga de rede de 1000 kbps em média por processo provocou impacto nos tempos de resposta obtidos com a utilização das políticas de escalonamento.

Essa taxa de comunicação não foi suficiente para provocar sobrecarga de comunicação numa rede com a largura de banda de uma rede Gigabit Ethernet.

De modo contrário, nos cenários que utilizam grids computacionais o aumento da carga de rede causou grande impacto nos tempos de resposta médios obtidos com a utilização das políticas.

A inserção de carga de rede mais pesada alterou, inclusive a ordem de classificação das políticas estudadas.

Os próximos três gráficos sumarizam os resultados da execução da carga de UCP  em um grid de 512 nós.

Os nós em um mesmo site são interligados por uma rede Gigabit Ethernet e cada site é interligado aos demais utilizando a Internet.

São representadas as curvas resultantes da execução das 10 políticas, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

Nota-se que na ausência de rede, a execução em um grid possui comportamento e tempos de resposta médios próximos ao cluster.

A diferença principal está nos resultados obtidos pelas políticas Random, Round Robin e Lowest no grid, que obtêm tempos de resposta menores que no cluster.

Isto se deve, possivelmente, à existência de um número maior de recursos, ampliando as chances de tais políticas escalonarem para nós com baixa utilização.

No grid, à medida que a taxa de comunicação na rede aumenta o comportamento das políticas se altera significativamente e os tempos de resposta médios aumentam em comparação aos clusters.

No o maior tempo de resposta médio é da política GAS, que atinge valores próximos a 140 segundos, enquanto no o maior tempo de resposta pertence à política Random com valor próximo a 3600 segundos.

Já no a política Round Robin atinge o valor de 32000 segundos.

Na presença de carga de rede  as políticas Random, Round Robin e Lowest apresentam os piores resultados.

Isso é esperado já que tais políticas utilizam pouca ou nenhuma informação da carga do sistema.

As políticas TLBA, Disted, Central, Global, DPW-PExt formam um grupo de políticas com tempos de respostas médio muito próximos.

O tempo de resposta dessas políticas aumenta à medida que a carga na rede aumenta, demonstrando que a comunicação causa grande impacto na execução da carga de trabalho.

Os melhores tempos de resposta médios, com a utilização da rede, pertencem às políticas GAS e NBSP.

A NBSP apresenta o melhor resultado também na ausência de carga na rede.

Neste gráfico a NBSP possui um comportamento muito próximo das políticas DPWPExt e Central.

O comportamento similar da NBSP e da DPWPExt para cargas de trabalho CPU-Bound é esperado, sendo que a NBSP apresenta vantagens quando a ocupação da rede de comunicação aumenta.

Os resultados obtidos com as políticas GAS e NBSP demonstram a necessidade de se considerar a rede no escalonamento em grids computacionais.

Essas duas políticas utilizam informação da carga de comunicação na rede.

A política GAS apresenta o pior tempos de resposta médio dentre as 10 políticas, enquanto  ela apresenta o segundos melhor tempo de resposta, atrás apenas da política NBSP.

A NBSP apresenta um tempo de resposta muito menor que as demais políticas, inclusive do que a GAS, demonstrando claramente a necessidade de considerar o a comunicação no escalonamento em grids computacionais.

A política NBSP escalona com base no impacto que a comunicação provoca na execução de uma carga de trabalho.

Os resultados apresentados nos gráficos a seguir também demonstram tal necessidade.

As taxas de comunicação da rede em cada gráfico são, respectivamente, nula, 100 kbps em média por processo e 1000 kbps em média por processo.

Enquanto a carga  impõe uma baixa carga para clusters, em grids o tempo de resposta médio é elevado, alcançando 3000 segundos.

Novamente as políticas que obtém os melhores resultados, distanciando-se significativamente das demais, são NBSP e GAS.

Essas políticas consideram a rede de comunicação no momento do escalonamento.

A NBSP obtém os melhores resultados porque considera o impacto da utilização da rede sobre os processos.

As taxas de comunicação da rede em cada gráfico são, respectivamente, nula, 100 kbps em média por processo e 1000 kbps em média por processo.

O comportamento das políticas avaliadas sob a carga  no grid apresenta um comportamento semelhante à carga  para o mesmo ambiente computacional.

Nota-se que a inserção de uma carga de rede mais pesada deteriora sobremaneira o desempenho das políticas de escalonamento.

A política GAS, no entanto, apresenta tempos de resposta médios melhores para uma carga de rede maior.

Embora o comportamento das políticas para essa carga se assemelhe ao comportamento para a carga  os tempos de resposta médios obtidos para esta carga é um tanto maior do que para a carga.

Finalizando os resultados das simulações conduzidas neste trabalho são apresentados a seguir os resultados para a carga de UCP  no grid.

Sumarizam os resultados, respectivamente, para uma carga de rede nula, de 100 kbps em média por processo e de 1000 kbps em média por processo.

O comportamento das políticas para essa carga é também semelhante ao comportamento para a carga.

A política NBSP obtém novamente o melhor desempenho na presença de carga de rede, seguida pela política GAS.

Um aspecto que pode ser notado aqui, assim como nos demais resultados para o grid computacional é que quanto maior a taxa de comunicação maior o desempenho da política NBSP em relação as demais políticas estudadas neste trabalho.

Neste capítulo, foi apresentada a parametrização utilizada no simulador.

Os ambientes computacionais estudados neste trabalho foram obtidos por meio de funções de distribuição de probabilidades.

Alguns limiares obtidos de um sistema parametrizado foram usados a fim de obter ambientes próximos do real.

Os experimentos conduzidos neste trabalho e os resultados obtidos por meio das simulações permitiram cumprir os objetivos propostos para este trabalho.

Isso será melhor discutido no próximo capítulo, juntamente com as contribuições deste trabalho.

Os resultados permitiram verificar que diferentes cargas de trabalho podem levar a diferentes comportamentos para uma mesma política de escalonamento.

Dentre as políticas avaliadas não são adequadas a todos os cenários.

Observou-se que a TLBA apresenta bons resultados nos clusters avaliados, enquanto a GAS apresenta escalonamentos ruins nesses sistemas.

Por outro lado a GAS apresenta bons escalonamentos em grids computacionais e para ambientes cuja carga de comunicação entre os processos é alta.

A NBSP apresentou os melhores resultados em grids, embora não tenha apresentado os melhores resultados para uma carga CPU-Bound e para clusters.

Os resultados obtidos com grids demonstram que tais sistemas são pouco adequados à execução de aplicações paralelas nas quais há muita comunicação entre seus processos, oferecendo bom desempenho para aplicações bag-of-tasks.

Os resultados obtidos com a GAS e com a NBSP, principalmente, evidenciam a necessidade de que as políticas de escalonamento voltadas a grids computacionais contemplem o tratamento da comunicação entre os processos.

O capítulo a seguir apresenta as conclusões finais e as principais contribuições obtidas com o desenvolvimento deste trabalho de mestrado.

Além disso, são apontados caminhos para trabalhos futuros.

O escalonamento pode afetar profundamente a eficiência de um sistema.

Um bom escalonamento, considerando as características do sistema e da carga de trabalho, pode garantir uma melhor utilização dos recursos computacionais e, em conseqüência, um melhor tempo de resposta para as aplicações paralelas.

Entretanto, o escalonamento em sistemas computacionais paralelos e distribuídos é uma atividade complexa, pois uma série de fatores influenciam as decisões do escalonador.

Fatores como a heterogeneidade, o baixo desempenho da rede e aplicações com diferentes características exigem o uso de políticas de escalonamento que contemplem o tratamento dessas características nas suas decisões.

Os resultados dos experimentos conduzidos neste trabalho demonstraram a necessidade de considerar características do sistema e da carga de trabalho nas decisões do escalonador.

Os resultados demonstraram que políticas que coletam índices de carga e tratam a heterogeneidade como a TLBA, DPWP e NBSP obtêm melhores resultados em sistemas heterogêneos como clusters e grids computacionais do que políticas que não consideram, como Round Robin e Random.

Políticas como a GAS, que consideram características da carga de trabalho, obtêm melhores resultados.

Além disso, a NBSP, que considera a utilização da rede nas decisões do escalonamento obteve melhores resultados do que as demais políticas estudadas neste trabalho, sob elevadas condições de carga.

O problema central estudado neste trabalho é a avaliação de desempenho de políticas de escalonamento para aplicações paralelas considerando-se diferentes cenários.

A evolução dos sistemas distribuídos têm tornado tais sistemas uma alternativa viável para a execução de aplicações paralelas.

Diversas políticas de escalonamento, geralmente especializadas, têm sido propostas com vistas e melhorar o desempenho nesses sistemas.

O problema é que essas políticas são, na grande maioria dos trabalhos que as propõe, avaliadas apenas com o objetivo de demonstrar sua superioridade sob um determinado aspecto.

O desempenho dessas políticas sobe diferentes condições de carga e ambientes computacionais não é verificado.

Nesse contexto, uma das principais preocupações deste trabalho foi demonstrar a necessidade de se analisar o comportamento de uma política de escalonamento para aplicações paralelas sob diferentes condições de carga e em diferentes ambientes computacionais distribuídos.

Dessa forma, é possível compreender como a mesma se comportaria em um ambiente real.

Tal compreensão pode garantir que se obtenha bons desempenhos e que se tome decisões adequadas quando o cenário muda.

Souza  propõe a troca da política de escalonamento, de modo on-line, quando as condições de carga se alteram em um sistema.

Entretanto, é preciso primeiramente conhecer o comportamento das políticas em cada cenário.

Daí a relevância deste trabalho.

A avaliação de desempenho das dez políticas de escalonamento descritas neste trabalho nos três ambientes computacionais e sob diferentes cargas de trabalho permitiram alcançar os objetivos propostos.

As conclusões deste trabalho são descritas na próxima seção em função das contribuições esperadas.

Também são detalhadas algumas contribuições adicionais deste trabalho e trabalhos que ainda podem ser conduzidos com base nesta dissertação.

Os resultados obtidos da avaliação de desempenho conduzida neste trabalho demonstram, principalmente, a necessidade de se verificar o comportamento de uma política de escalonamento sob diferentes condições de carga.

As políticas de escalonamento obtiveram desempenho ruim quando os cenários mudaram.

Um aspecto de grande importância que este trabalho permitiu verificar foi que grids são pouco adequados à execução de aplicações paralelas com uma alta carga de comunicação entre seus processos sem que haja uma boa política de escalonamento.

Políticas voltadas a grids computacionais devem contemplar o tratamento da comunicação entre os processos para que sejam obtidos bons escalonamentos.

O foco deste trabalho é a avaliação de desempenho, mas para se conduzir uma boa avaliação é necessário conhecer os fatores que interferem no desempenho.

Dessa forma, a Computação Paralela Distribuída e o Escalonamento foram tratados nesta dissertação.

No que se refere à avaliação de desempenho de políticas de escalonamento e a aplicação de técnicas para comparar políticas a revisão bibliográfica contribuiu significativamente para uma área carente de bons trabalhos.

Nos capítulos  desta dissertação analisados os principais trabalhos que tratam da avaliação de desempenho no escalonamento.

Esta dissertação fornece material de referência para trabalhos que envolvam escalonamento de aplicações paralelas, clusters, grids computacionais e, especialmente, técnicas aplicáveis à avaliação de desempenho do escalonamento.

Definição de uma sistemática para avaliar, comparativamente, políticas de escalonamento A discussão apresentada a respeito de cargas de trabalho e métricas de desempenho fornecem uma base adequada para a condução de diversas outras comparações entre diferentes políticas de escalonamento.

Diversas modelos de carga de trabalho foram apresentados e quatro desses foram analisados sob diferentes aspectos que devem ser considerados na avaliação do escalonamento.

As discussões a respeito da métrica "tempo de resposta médio" apontaram-na como uma métrica adequada à comparação de políticas.

A avaliação de desempenho conduzida neste trabalho e os critérios utilizados para sua condução podem ser utilizados como uma sistemática para avaliar, comparativamente, políticas de escalonamento.

O simulador, a parametrização dos clusters e grids computacionais e a análise das cargas de trabalho servem como base para futuras comparações entre políticas de escalonamento para aplicações paralelas.

Complemento de trabalhos que propõem e avaliam políticas de escalonamento Uma das contribuições deste trabalho refere-se ao relacionamento deste com os demais trabalhos desenvolvidos no grupo de pesquisa Laboratório de Sistemas Distribuídos e Proramação Concorrente (LaSDPC).

O trabalho apresentado nesta dissertação complementa alguns desses trabalhos.

Dentre as políticas avaliadas três foram definidas no LaSDPC, DPWP, NBSP e GAS.

Neste trabalho, essas políticas foram avaliadas sob aspectos distintos dos providos no trabalho original que propõe a política.

Algumas das contribuições que se pode destacar em relação a esses trabalhos são, g Comprovou-se que a NBSP se aplica a grids computacionais e obtém bons resultados, especialmente, sob alta taxa de comunicação na rede.

Com relação à política GAS pôde se verificar que tal política oferece melhores desempenhos para aplicações Network-Bound.

A DPWP é uma política com desempenho moderado, oferecendo resultados satisfatórios para aplicações CPU-Bound tanto em clusters quanto em grids computacionais Além dos trabalhos citados e dos trabalhos que propõem as políticas estudadas neste trabalho outros trabalhos foram complementados com o desenvolvimento desta dissertação.

Exemplos são os trabalhos que discutem cargas de trabalho e métricas de desempenho e também trabalhos que comparam políticas de escalonamento.

Verificação da aplicabilidade de políticas de escalonamento voltadas a clusters, em grids computacionais Todas as políticas estudadas neste trabalho foram desenvolvidas originalmente para clusters.

Embora tais políticas possam ser utilizadas em grids não se podia garantir sua aplicabilidade a grids computacionais.

Este trabalho, demonstrou através de experimentos que essas políticas, com exceção das políticas NBSP e GAS, tem sua aplicabilidade reduzida em grids computacionais.

As políticas Round Robin e Random que nem sequer são adequadas a cluster heterogêneos obtiveram tempos de resposta médios muito elevados em grids computacionais, especialmente em aplicações que utilizam a rede.

Essas políticas não utilizam qualquer informação de carga e não tratam a heterogeneidade.

A política Lowest também apresentou resultados piores nos grids.

O fato dessa política coletar informação de apenas um subconjunto de computadores sistema reduz a troca de informações de carga mas leva a escalonamentos piores do que no caso de coletar informação de todo o sistema, como na política Disted.

As políticas Disted, Central, Global, TLBA e DPWPExt também tiveram sua aplicabilidade reduzida nos grids.

Enquanto a política NBSP obteve valores inferiores a 2500 segundos de tempo de resposta médio para a execução de 300 jobs da carga  as políticas citadas obtiveram tempos de resposta entre 25000 e 35000 segundos.

Para o mesmo cenário de carga de trabalho em um cluster de 128 nós, essas políticas, inclusive a NBSP, obtiveram tempos de resposta médios entre 50 e 110 segundos.

Verificação das políticas que melhor se aplicam a determinado cenário Por meio deste trabalho foi possível identificar algumas políticas que melhor ou pior se aplicam a determinados cenários.

Os resultados demonstraram que não há uma política que obtenha bons resultados em todos os cenários.

Assim, alguns cenários são identificados a seguir juntamente com a(s) política(s) que melhor ou pior se aplica(m).

A política NBSP foi superior em todos os cenários em que a carga de comunicação na rede causou atrasos na execução dos processos.

A política GAS foi a que obteve o pior comportamento para aplicações bag-of-tasks.

A política TLBA apresentou o comportamento mais estável dentre as 10 políticas para os cenários que utilizam clusters.

Os tempos de resposta médios dessa política está entre os 5 melhores para todos os cenários que envolvem clusters.

Demonstração do impacto da comunicação entre os processos em grids computacionais Os resultados obtidos demonstraram que a comunicação entre processos pode gerar grandes atrasos na execução dos processos em um grid computacional.

Para uma carga de rede nula, o tempo de resposta máximo é de 130 segundos,o tempo de resposta sobe para um máximo de 3500 segundos para uma carga de 100 kbps em média por processo e para 30000 segundos.

Este gráfico sumariza os resultados para uma carga de rede de 1000 kbps em média por processo.

O impacto causado pela comunicação fica ainda mais evidente ao observar a carga  num cluster e num grids.

Diversos outros trabalhos podem ser conduzidos com vistas a melhorar e complementar este trabalho.

Além disso, os resultados obtidos nesta dissertação motivam a definição de alguns trabalhos futuros.

A seguir estão algumas diretrizes de trabalhos que podem ser conduzidos neste sentido, Avaliar outras políticas de escalonamento, a fim de verificar seu comportamento sob diferentes condições de carga e em diferentes sistemas computacionais.

Definição de cargas de trabalho voltadas a avaliação do escalonamento em grids computacionais.

Logs podem ser coletados nesses ambientes e utilizados para caracterizar modelos de carga de trabalho.

O grande problema é obter um sistema disponível para tal coleta e que possua uma utilização significativa.

Propor melhorias nas políticas avaliadas.

Um exemplo é adicionar tratamento da comunicação, como na NBSP à política TLBA, que se comportou bem em todos os cenários envolvendo cluster.

Avaliar o custo computacional e de comunicação gasto para coletar e utilizar a informação de carga do sistema nas decisões do escalonamento.

Uma pesquisa interessante seria verificar o impacto de aumentar o tamanho subconjunto de computadores monitorados pela política Lowest e encontrar um valor limite entre esse subconjunto e melhorias no tempo de resposta.

Grande parte dos ambientes de produção mantêm logs da execução de aplicações paralelas com o objetivo de usá-los para avaliar a utilização do ambiente.

Alguns desse logs são disponibilizados para uso por pesquisadores.

Um repositório de logs é o Parallel Workload Archive.

Este apêndice descreve os logs contidos no Parallel Workload Archive.

Os dados coletados podem diferir de log para log.

Entretanto, alguns estão disponíveis em todos, como momento de chegada, início e fim da execução de um job, número de recursos requeridos, usuário.

Alguns dados dependem do escalonador utilizado, como a estimativa de tempo de execução.

O Parallel Workload Archive contém logs bastante detalhados.

Eles foram coletados em ambientes de produção de larga escala de vários países do mundo.

Os logs foram convertidos para o formato padrão para cargas de trabalho.

Além disso eles foram tratados para retirar atividades não representativas, como repetidas submissões de um mesmo job por parte de um usuário.

O trabalho de Tsafrir e Feitelson  detalha as informações que devem ser retiradas e seus efeitos sobre a avaliação de desempenho.

Resume as principais características contidas nos logs do Parallel Workload Archive.

