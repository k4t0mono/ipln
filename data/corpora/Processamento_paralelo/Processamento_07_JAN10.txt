Atualmente, a necessidade de sistemas de computação mais rápidos e eficientes é cada vez maior, tanto na área científica como na área comercial.

A demanda por computação de alto desempenho em áreas diversas como biomecânica, meteorologia e engenharia vem crescendo bastante nos últimos anos.

Existem limites físicos para o aumento da velocidade de um único processador, além do alto custo associado ao desenvolvimento desses processadores mais velozes, o que levou ao surgimento de novas arquiteturas com alto poder computacional.

Estas novas arquiteturas integram vários processadores (o número de processadores varia de dezenas a milhares), razoavelmente rápidos, compondo assim uma máquina de alto desempenho.

Estas máquinas podem ser classificadas em três tipos, Multiprocessadores vetoriais, possuem um pequeno número de processadores vetoriais de alta performance.

Sistemas MPP (Massively Parallel Processors), possuem de centenas a milhares de processadores, com memória distribuída ou compartilhada.

Rede de estações de trabalho, máquinas interligadas por redes que podem trabalhar como uma única máquina virtual paralela.

Para se aproveitar plenamente o poder computacional dessas máquinas, é necessário o desenvolvimento de modelos de programação, de algoritmos e de ferramentas para estes novos ambientes.

Este trabalho se baseia na utilização de estações de trabalho ligadas em rede.

Para isso, será utilizada a biblioteca para passagem de mensagens PVM (Parallel Virtual Machine) para gerenciar o funcionamento da máquina paralela virtual, formada pelas estações, e serão desenvolvidos algoritmos específicos para esta configuração.

Neste trabalho serão apresentados alguns aspectos gerais sobre programação paralela, modelos de organização da memória e modos de programação.

Também será descrita a biblioteca PVM, seu funcionamento e forma de utilização.

São apresentados aspectos gerais sobre a programação paralela, com a descrição da terminologia utilizada, modelos de acesso à memória em ambientes distribuídos e modelos de programação mais utlizados em processamento paralelo.

Terminologia São descritos a seguir alguns termos utilizados em processamento paralelo, Tarefas (ou processos), programas executados concorrentemente, geralmente disparados por um programa mestre.

São as principais unidades do processamento paralelo em um ambiente de computação distribuída, comunicam-se através de troca de mensagens.

Execução seqüencial, execução de um programa em um único processador, com as instruções sendo processadas uma de cada vez.

Paralelização de código, consiste na transformação de um programa seqüencial em paralelo, com a identificação de porções de código que podem ser executadas independentemente.

Exige mudanças no código do programa e, caso necessário, no algoritmo utilizado no programa seqüencial.

Aceleração (speed-up), consiste na comparação entre o tempo de execução do programa em um único processador e o tempo de execução utilizando vários processadores.

Sincronização, coordenação necessária entre processos para a troca de informações.

Pode ser um fator de decréscimo da eficiência do programa, uma vez que alguns processadores podem ficar inativos, esperando pelo término de outros processos.

Granularidade, quantidade de processamento realizado por cada processo, em relação à quantidade de comunicação entre processos.

Quando os processos executam poucas instruções e necessitam se comunicar muito, diz-se que o programa é muito granular.

Quando, ao contrário, os processos executam muitas instruções, com pouca troca de informação, diz-se que o programa é pouco granular.

Um programa com granularidade alta necessita de uma maior sincronização que um programa com menor granularidade, o que afeta o tempo de execução do programa.

Escalabilidade, um sistema computacional paralelo é dito escalável se a aceleração atingida cresce proporcionalmente ao número de processadores utilizados.

Balanceamento de carga, consiste na distribuição equilibrada de tarefas entre os processadores, de forma a garantir uma execução eficiente do programa paralelo.

SPMD (Single Program Multiple Data), modelo de programação onde todos os processadores executam o mesmo programa sobre diferentes conjuntos de dados.

Uma rede de computadores é formada pela interconexão de um conjunto de equipamentos processadores (computadores, impressoras) através de um sistema de comunicação.

O sistema de comunicação é constituído de uma rede de interconexão montada sobre meios físicos de transmissão e um conjunto de regras de comunicação denominadas protocolos.

Uma rede local (Local Area Network LAN) constitui-se de um conjunto de computadores confinado a uma área geográfica limitada por uma faixa de distância de metros a alguns quilômetros.

Rede em estrela.

As topologias mais utilizadas em redes locais são, estrela, anel e barra.

Redes em estrela são mais adequadas quando o sistema computacional paralelo baseia-se em um conjunto de processadores secundários comunicando-se com um processador mestre, o qual controla toda a comunicação ocorrida entre os processadores secundários.

Redes em anel constituem-se basicamente em um conjunto de processadores interconectados por um anel.

Redes em barramento constituem-se em um conjunto de processadores interligados através de um barramento comum a todos os processadores.

Rede em barramento.

A base de transmissão de dados de uma rede é qualquer meio físico que tenha a capacidade de transportar informações eletromagnéticas (dados) entre os componentes da rede.

Os mais utilizados são o par trançado (TP), o cabo coaxial (BNC) e a fibra ótica.

Modelos de organização da memória Existem dois modelos básicos de organização da memória, memória compartilhada e memória distribuída.

Quando se utiliza o modelo de memória compartilhada, todos os processadores têm acesso total (escrita e leitura) a qualquer área da memória.

Neste modelo, a sincronização entre processos é realizada através do controle das operações de escrita e leitura feitas pelos processos.

Tem como vantagem a rapidez de acesso aos dados e, como desvantagem, a limitação no número de caminhos entre os processadores e a memória, o que diminui a escalabilidade do sistema.

Arquitetura de memória compartilhada.

Uma forma de melhorar a escalabilidade do modelo de memória compartilhada consiste em prover cada processador com uma memória local, onde seriam armazenados o programa a ser executado e os dados exclusivos do processo.

Arquitetura de memória compartilhada com memória local nos processadores.

Uma outra variação desse modelo consiste na eliminação total de compartilhamento físico da memória.

Rede de interconexão.

Arquitetura de memória compartilhada somente com memória local nos processadores.

Para se utilizar de maneira correta o modelo de memória compartilhada, deve-se prestar especial atenção no controle sobre o acesso à memória compartilhada pelos processos.

Por exemplo, um dado não pode ser alterado por um processo enquanto um outro processo estiver lendo esse mesmo dado.

O outro modelo básico de organização da memória é o modelo de memória distribuída.

Neste caso, a memória é distribuída fisicamente entre os processadores, sendo de acesso exclusivo do processador ao qual está associada.

As informações são trocadas entre os processadores através do envio de mensagens pela rede de comunicação.

Rede de interconexão.

Arquitetura de memória distribuída.

As vantagens do modelo de memória distribuída são a escalabilidade do sistema, uma maior confiança no sistema devido à duplicação dos dados entre os processadores, com menor probabilidade de ocorrência de falhas, e também a facilidade de se incorporar novos processadores ao sistema, podendo-se utilizar conjuntamente processadores de arquiteturas diferentes.

Modos de programação De maneira geral, os modos de programação paralela podem ser classificados em três modelos, Paralelismo de dados, uma mesma seqüência de instruções é executada por cada processador sobre dados diferentes.

Este é o modo de programação adotado na maior parte dos algoritmos implementados neste trabalho.

Paralelismo de tarefas, o programa é particionado em tarefas cooperativas.

Estas tarefas podem executar procedimentos bastante diferentes entre si, sem necessariamente haver uma sincronização entre as tarefas.

Paralelismo de objetos, neste caso, o paralelismo pode ser realizado de diferentes formas.

Por exemplo, uma função membro de um objeto pode chamar uma função pública de outro objeto remoto ou não.

Ou um tipo abstrato de dados, como um vetor, pode ser implementado de maneira distribuída.

O PVM (Parallel Virtual Machine) é um conjunto integrado de ferramentas de software e bibliotecas que emula uma máquina paralela utilizando computadores interconectados de arquiteturas distintas.

O principal objetivo do PVM é possibilitar a utilização da computação paralela através de um conjunto heterogêneo de computadores ligados em rede.

A unidade básica do paralelismo no PVM é a tarefa, uma seqüência independente de instruções, que se comunica com outras tarefas através da troca de mensagens.

Não há a necessidade de se executar uma tarefa por processador.

O PVM possibilita a execução de múltiplas tarefas em um único processador, ou seja, o modelo computacional do PVM é baseado no processo.

É adotado também um modelo explícito de troca de mensagens, onde várias tarefas, cada uma realizando uma parte do trabalho computacional, comunicam-se entre si utilizando-se de funções de envio e recepção de mensagens.

O tamanho da mensagem é limitado apenas pela quantidade de memória disponível.

O PVM suporta heterogeneidade de máquinas, redes e aplicações.

Permite que um mesmo dado que tenha uma representação diferente em duas máquinas de arquiteturas distintas, possa ser trocado de maneira transparente entre essas máquinas, fazendo a conversão automaticamente.

O conjunto de máquinas pertencentes à máquina virtual paralela pode ser configurado livremente pelo usuário, o qual escolhe quais máquinas deseja utilizar.

A adição ou retirada de máquinas pode ser feita tanto antes de se executar o programa paralelo, quanto durante a execução.

Além disso, os programas podem ver o conjunto de máquinas apenas como uma coleção de processadores idênticos, ou podem explorar as capacidades específicas de cada processador, enviando as tarefas aos computadores mais apropriados.

O PVM é composto de duas partes.

A primeira parte é um daemon (programa residente executado em background), chamado pvmd3, que reside em todos os computadores pertencentes à máquina virtual.

Quando o usuário deseja executar uma aplicação PVM, primeiro deve criar a máquina virtual, inicializando o PVM.

A aplicação PVM pode então ser executada de qualquer uma das máquinas.

A segunda parte do sistema é uma biblioteca de rotinas de interface, contendo um conjunto completo de primitivas que são necessárias para a interação entre as tarefas de uma aplicação.

Esta biblioteca contém rotinas para a passagem de mensagens (envio e recepção), disparo de processos, coordenação das tarefas e modificação da máquina virtual.

Todas as tarefas são identificadas por um número inteiro chamado task identifier (TID).

Mensagens são enviadas e recebidas utilizando-se esse identificador.

Uma vez que esses números devem ser únicos para toda a máquina virtual, eles são definidos pelo daemon local, e não por uma escolha do usuário.

O PVM possui diversas rotinas que retornam valores de TID, possibilitando a identificação das tarefas pela aplicação do usuário.

O sistema PVM suporta as linguagens C, C++ e Fortran.

As rotinas da biblioteca para C e C++ são implementadas como funções, seguindo as convenções gerais da maioria dos sistemas C.

Programas escritos em C e C++ acessam as funções da biblioteca PVM ligando-se a um arquivo de biblioteca (libpvm3 a).

Já para a linguagem Fortran, as rotinas são implementadas como subrotinas, ao invés de funções, e os programas feitos nessa linguagem devem-se ligar a uma outra biblioteca (libfpvm3 a).

O paradigma geral de programação de aplicações utilizando-se o PVM é mostrado a seguir.

Um usuário escreve um ou mais programas seqüenciais em C, C++ ou Fortran que contêm chamadas embutidas à biblioteca PVM.

Cada programa corresponde a uma tarefa.

Esses programas são compilados para cada arquitetura presente na máquina virtual, e os arquivos resultantes são colocados em um local acessível às máquinas pertencentes ao sistema.

Para executar uma aplicação, o usuário geralmente executa uma tarefa (usualmente a tarefa "master" ou de inicialização) manualmente a partir de uma máquina do sistema.

Este processo dispara outras tarefas, resultando em uma coleção de tarefas ativas, as quais executam seqüências de instruções localmente e trocam mensagens entre si para resolver o problema.

A seguir, é mostrado um exemplo simples que ilustra os conceitos básicos da programação PVM.

Basicamente, esse exemplo consiste em um programa "master", executado manualmente, que dispara uma tarefa (hello_other c) e espera pelo retorno de uma mensagem contendo uma string (seqüência de caracteres).

Neste trabalho, foram apresentados aspectos gerais da programação paralela, incluindo a terminologia utilizada, modelos de organização da memória e modos de programação.

Também foram apresentados os diferentes tipos de redes locais de computadores.

Por fim, os princípios e o funcionamento do PVM foram descritos, incluindo um exemplo simples de programa que ilustra os conceitos básicos da programação PVM.

