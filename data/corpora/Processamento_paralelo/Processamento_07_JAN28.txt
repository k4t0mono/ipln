Devido a grande competitividade do mercado, existe uma demanda crescente pela produção de sistemas computacionais modernos cada vez com mais qualidade e em menores prazos.

O tempo para desenvolvimento de novas versões do sistema também é crítico, pois se espera melhor desempenho e mais funcionalidades que a versão atual, com grande expectativa por parte dos clientes em relação ao tempo de liberação.

Em conseqüência das evoluções tecnológicas e com a redução no valor dos processadores e memórias, sistemas modernos com alto desempenho, como os sistemas de processamento paralelo, ganharam espaço e estão sendo cada vez mais requisitados pelos clientes devido ao seu poder computacional para resolver problemas complexos em áreas críticas como médica, militar, energética, simulações e previsões de tempo (MORRISON, 03).

Na área de processamento paralelo, pode-se dizer que existe uma verdadeira corrida por colocar um novo produto e suas versões rapidamente no mercado, permitindo posicioná-lo de maneira vantajosa em relação aos concorrentes e torná-lo uma referência para os clientes, que passam a querer adotá-lo.

Levando-se esses fatos em consideração, o problema pesquisado por esta tese é como melhorar o processo de desenvolvimento de sistemas de processamento paralelo, reduzindo o tempo de desenvolvimento de novas versões destes sistemas e sua colocação no mercado.

A proposta para resolução do problema é reduzir o tempo gasto na atividade de teste, que corresponde a uma parte significativa do tempo total do projeto.

Para diminuir esse tempo, o trabalho apresenta uma estratégia baseada na execução dos testes em paralelo com desenvolvimento.

Esta técnica aplicada a sistemas de processamento paralelo resulta no principal objetivo do trabalho que é reduzir o tempo de desenvolvimento de novas versões destes sistemas através de uma metodologia de testes.

Esta metodologia é usada para testar um dos componentes de um sistema de processamento paralelo, chamado Sistema de Controle, simultaneamente com o desenvolvimento dos outros componentes do sistema.

Para testar a eficiência da solução, a metodologia foi aplicada no desenvolvimento do supercomputador da IBM Blue Gene.

Como resultado, pode-se verificar uma redução de até 41% do tempo total do projeto.

Tempo é uma medida essencial de desempenho no desenvolvimento de software.

Para sistemas comerciais, como softwares de produtividade e sistemas operacionais, o mercado consumidor é muito sensível ao tempo, porque os usuários não esperam por um produto que demora a ser finalizado, quando existe outro disponível.

Um grande número de empresas está trabalhando com foco em reduzir o tempo de liberação de um produto ao mercado.

Em um estudo realizado pela PDMA (Product Development and Management Association), mais de 40% das empresas, que responderam os questionários da pesquisa, informaram que têm acelerado o desenvolvimento de seus produtos nos últimos 5 anos.

Várias pesquisas descritas mostram que empresas como Honda, Xerox, Hallmark, Chrysler conseguiram diminuir o tempo de liberação de seus produtos em até 50%, sem perder qualidade.

Cada vez mais, o mercado de sistemas operacionais, software, hardware e aplicações exige 1 2 maior qualidade e menores custos em seus projetos.

Muitas técnicas e metodologias para otimizar o desenvolvimento são apresentadas, periodicamente, para atingir este objetivo.

Como conseqüência, as empresas sofrem fortes pressões para desenvolver sistemas melhores, com mais funcionalidades e em intervalos de tempo cada vez menores.

O processo de teste é essencial no desenvolvimento de sistemas e suas atividades podem consumir aproximadamente 40% do tempo do projeto.

Assim, o uso de ferramentas de otimização e automação de testes, bem como as técnicas que propõem a aceleração dos testes sem comprometer a qualidade é de grande importância para reduzir o ciclo de vida de desenvolvimento de software (Software Development Life Cycle SDLC).

Os ambientes tecnológicos nos quais estes sistemas são desenvolvidos estão em constante evolução para acompanhar a agilidade e dinamismo de novos requisitos exigidos pelos clientes.

A evolução de novas versões dos programas deve ser constante para melhorar seu desempenho ou adicionar funcionalidades.

Um sistema, que não sofre alterações para aumentar a qualidade e eficiência, está destinado a ser trocado por uma outra solução.

A garantia de continuidade de um software através de versões mais novas é um forte argumento associado à qualidade do produto.

Conseqüentemente, é fundamental que todos os sistemas, do maior ao menor, sejam capazes de evoluir com a mesma ou maior qualidade do que o sistema vigente.

Além disso, as novas versões devem ser feitas no menor intervalo de tempo possível para diminuir os custos e acelerar o posicionamento do novo software no mercado.

Isso significa que o projeto de novas versões do sistema deve ser feito com muito cuidado, preservando a qualidade e dentro do menor tempo de desenvolvimento possível.

Todo sistema precisa sofrer modificações, ou melhorias, para garantir sua evolução.

Cada alteração efetuada no software ou hardware é suscetível a erros e precisa ser muito bem avaliada, para não gerar danos às novas versões.

Em um cenário dinâmico, como o que se vive em termos de novas tecnologias, encontrar um processo sistêmico e eficiente para gerar novas versões é fundamental.

Na geração de novas versões, uma parte significativa de esforço e tempo é gasto com testes para garantir o mesmo nível de qualidade das versões atuais.

Há muitos estudos sobre técnicas de teste, processo de teste formal ou informal, automatização de testes e atividade de testes em paralelo com desenvolvimento.

Esta é uma área que está sendo bem estudada.

Porém, não há tantos trabalhos com a aplicação destas práticas na área de desenvolvimento de sistemas de processamento paralelo.

No processo de inovação das tecnologias, com equipamentos cada vez mais potentes, com mais recursos e mais velocidade, chega-se a um ponto, onde questões como dissipação e consumo de energia se tornam críticos para a sua própria evolução.

Esses são alguns dos motivadores da evolução de arquiteturas de processamento paralelo, como o Blue Gene da IBM.

Já faz algum tempo que as tecnologias com foco em estudar processadores trabalhando em conjunto para elaborar uma mesma tarefa estão ganhando espaço frente aos servidores convencionais.

Por exemplo, podem-se citar os clusters de máquinas, grade de computadores (e-Grid)) ou supercomputadores.

Os sistemas de processamento paralelo são essenciais atualmente e requisitados por aplicações cada vez mais complexas e já não fazem parte apenas de alguns laboratórios de algumas universidades mundiais.

Governos e até empresas comerciais estão investindo nesta tecnologia para ajudar a resolver problemas como os estudos genéticos, estudos proteômicos (das proteínas), desenvolvimento de medicamentos, previsão do tempo, processamento de imagens médicas 4 D (4 Dimensões), suporte a serviços de segurança vinculados à automação bancária, entre outros.

Um campo de pesquisa pouco explorado é como reduzir o ciclo de desenvolvimento de um sistema de processamento paralelo.

A maioria dos trabalhos apresentados nessa área tem com foco principal testar o desempenho de aplicações para sistemas de computação paralela e novas arquiteturas para otimizar processadores e memórias.

Há muito pouco estudo na área de processamento paralelo referente à questão de como reduzir o tempo de desenvolvimento de novas versões destes sistemas.

A aceleração do desenvolvimento de novas versões destes sistemas é importante, pois estão diretamente ligados ao aumento de velocidade de processamento de dados, o que o posiciona em uma melhor qualificação perante os usuários.

O trabalho apresentado auxilia na resolução de um antigo problema da área de Engenharia de Software, reduzir o tempo de projeto de desenvolvimento de software para sistemas de processamento paralelo.

Assim sendo, pode-se dizer que o objetivo deste trabalho é reduzir o tempo de projeto de sistemas de processamento paralelo, com foco na redução do tempo da atividade de teste.

Há diferentes maneiras de reduzir o tempo total de projeto de softwares, como a automatização de testes e a execução de testes em paralelo.

Este trabalho utiliza uma técnica conhecida da Engenharia de Software para acelerar a liberação de softwares, como base para elaborar uma metodologia de testes, aplicada, de forma inovadora, a sistemas de processamento paralelo com o objetivo de reduzir o tempo total de desenvolvimento destes sistemas.

A técnica utilizada é o teste de componentes do sistema em paralelo com o desenvolvimento geral do sistema.

O resultado é a redução do tempo total do projeto, já que o tempo que seria gasto para testar determinados componentes foi economizado no tempo total de desenvolvimento do sistema.

O principal desafio é como preparar e executar todos os testes de integração, antes da conclusão do desenvolvimento final do sistema.

A estrutura principal do trabalho é baseada em uma metodologia de testes para um componente de um sistema de processamento chamado Sistema de Controle (SC).

De maneira genérica, pode-se conceituar um Sistema de Controle como um dispositivo ou um grupo de dispositivos que gerenciam o comportamento de outros dispositivos.

Possui interconexão com os componentes relacionados, de tal maneira a comandar, controlar ou ajustar a si mesmo ou outro sistema.

Aplicando-se esta definição de a sistemas de processamento paralelo, pode-se obter um modelo lógico, que ajuda no planejamento, organização e execução dos testes dos componentes envolvidos no escopo do trabalho.

O modelo lógico é representado através de três componentes comuns aos sistemas de processamento paralelo, Terminal (T), responsável pela entrada de dados do sistema e a apresentação ou registro do resultado final, o Sistema de Controle (SC) corresponde a um software/hardware de controle, que executa tarefas de comunicação entre os outros componentes, monitora e gerencia a Unidade de Processamento, e, por último, a Unidade de Processamento (UP) realiza todo o cálculo e o processamento de dados.

Dentre os três componentes, o mais importante e mais complexo é a Unidade de Processamento que tem como parte principal os processadores e memórias que executam todo o processamento do sistema.

Assim, o tempo de desenvolvimento da Unidade de Processamento é maior que o tempo de desenvolvimento do Terminal e do Sistema de Controle.

A metodologia de testes descrita no trabalho é aplicada em uma fase específica do projeto.

Depois da primeira versão do sistema estar finalizada e em utilização pelos usuários finais, naturalmente há uma evolução onde melhorias são implementadas através de otimização de processos e a introdução de novas funcionalidades.

Na área de sistemas de processamento paralelo, um parâmetro essencial às novas versões é a melhoria de desempenho, medida que é baseada na velocidade de resolução de densos sistemas de equações lineares.

Sendo assim, como um requisito importante da tese, a metodologia proposta para reduzir o tempo total do projeto é aplicada para o teste de novas versões de Sistemas de Controle.

Como o tempo de desenvolvimento da nova Unidade de Processamento é maior que do Sistema de Controle, para testar a integração entre o Sistema de Controle e a Unidade de Processamento, a metodologia define a conexão entre a nova versão do Sistema de Controle e a atual versão da Unidade de Processamento.

Além disso, a metodologia ainda prevê a construção de um software e uma biblioteca básica para testar o Terminal com o Sistema de Controle, caso nenhuma nova versão do Terminal ainda esteja finalizada.

O foco dos testes é referente a nova versão do Sistema de Controle.

A metodologia de testes é aplicada para reduzir o maior número de erros da nova versão do componente Sistema de Controle e nas suas interfaces com os outros componentes, Terminal e Unidade de Processamento, testando também a integração entre eles.

A metodologia apresenta como solução para reduzir o tempo total de desenvolvimento de sistemas de processamento paralelo, antecipar os testes com o novo Sistema de Controle.

Como a UP gasta um tempo maior de desenvolvimento, para antecipar os testes com o novo SC, é necessário conectar esse novo SC a atual Unidade de Processamento.

Para isso, a metodologia prevê a construção de uma interface entre a nova versão do SC e a versão corrente da UP.

Assim, os testes com a nova versão do Sistema de Controle são efetuados em paralelo com o desenvolvimento da nova versão da Unidade de Processamento e o tempo total de desenvolvimento do sistema é reduzido com o paralelismo destas tarefas.

A solução é aplicada a novas versões de sistemas de processamento paralelo que atendam quatro requisitos mínimos, O sistema tem que ser modelo em três componentes, Terminal, Sistema de Controle e Unidade de Processamento.

Os testes com a nova versão do Sistema de Controle devem ser executados antes do término do desenvolvimento da nova versão da Unidade de Processamento, pois caso contrário, o tempo de teste do Sistema de Controle não será reduzido do tempo total do projeto.

A interface do novo Sistema de Controle deve ser compatível com a atual Unidade de Processamento para que seja possível testar o novo SC em paralelo com o restante do desenvolvimento do sistema, como a nova Unidade de Processamento.

Verificar qual o custo associado para que o novo Sistema de Controle seja compatível com a atual Unidade de Processamento.

O custo deve ser menor que o ganho com a aceleração do desenvolvimento do sistema proposto pela metodologia.

O capítulo 2 descreve uma visão geral dos principais conceitos apresentados na tese, incluindo resumo sobre arquitetura e aplicações para sistemas de processamento paralelo, algumas técnicas de teste e a apresentação do padrão IEEE para definição de relatórios, que suportam a atividade de teste.

Além disso, são analisados trabalhos relacionados à tese, referentes à redução de tempo de teste em projetos de desenvolvimentos de sistemas.

O capítulo 3 apresenta detalhadamente o problema a ser estudado na tese e define o cenário utilizado nos testes do Sistema de Controle.

O capítulo 4 mostra em detalhes a solução para testar Sistemas de Controle de um sistema de processamento paralelo.

Há um estudo sobre o tempo gasto em projetos de desenvolvimento de Sistemas de Controle e unidades de processamento, reforçando o lado temporal do problema a ser resolvido.

Também são descritos os requisitos mínimos para a aplicação da metodologia proposta e finalmente, é apresentada a metodologia de teste detalhada para uma nova versão do Sistema de Controle, sem que a nova Unidade de Processamento esteja finalizada, para reduzir o tempo total do projeto de desenvolvimento.

O capítulo 5 traz um estudo de caso aplicando a metodologia apresentada no capítulo 4.

O processo de testes foi desenvolvido em uma nova versão do Sistema de Controle do supercomputador Blue Gene.

A versão corrente do supe orcomputador é o Blue Gene/L (BG/L).

Todos os resultados apurados com os testes também fazem parte deste capítulo.

O capítulo 6 apresenta uma discussão sobre as contribuições e inovações contidas na tese.

O trabalho apresenta metodologia para reduzir o tempo total de testes de uma nova versão de sistema de processamento paralelo que pode ser modelado em três componentes lógicos, Terminal, Sistema de Controle e Unidade de Processamento.

Para acelerar o desenvolvimento destes sistemas de processamento maciço, é otimizado o teste do Sistema de Controle para reduzir seu tempo de teste, e, consequentemente, o tempo total do projeto.

Para otimizar os testes da nova versão do Sistema de Controle, a metodologia de testes define um tipo de conexão com a atual versão da Unidade de Processamento.

Como a Unidade de Processamento é o componente mais complexo e demorado para ser desenvolvido, antecipar os testes de integração com a versão atual da UP é um ganho no tempo total de desenvolvimento do sistema, já que o Sistema de Controle não necessita esperar o fim do desenvolvimento da nova Unidade de Processamento para iniciar seus testes de integração.

Sistema é um conceito importante para este trabalho.

Um sistema pode ser considerado como componentes organizados para execução de um determinando método, procedimento ou controle ao processar dados.

Os componentes podem ser softwares, hardware, pessoas, banco de dados, documentação ou procedimentos.

Como o foco da tese é o teste do Sistema de Controle (SC), e toda sua lógica é baseada em um programa, é assumido que o software é o principal componente do Sistema de Controle.

O capítulo é iniciado com uma apresentação de uma visão geral sobre os diferentes tipos de arquitetura de sistema de processamento paralelo.

Em seguida, o capítulo traz um estudo sobre o processo de testes de software, as técnicas e estratégias de testes existentes na Engenharia de Software, que são base para a metodologia desenvolvida no trabalho, e uma visão da Norma IEEE 829 (IEEE829, 98), que ajuda a definir o planejamento e os documentos necessários para o desenvolvimento dos testes.

Após a discussão sobre o processo de teste, é apresentada uma visão sobre técnicas para redução de tempo do ciclo de vida de testes (Software Test Life Cycle STLC), como testes em paralelo com desenvolvimento ou automação de testes.

Um sistema de processamento paralelo é um conjunto de processadores que trabalham de forma cooperada para resolver algum problema computacional.

Podem-se citar como exemplo, os supercomputadores, computadores em rede formando um cluster e computadores com múltiplos processadores.

Os sistemas de processamento paralelo conectam muitos nós (computadores ou processadores ligados em uma rede) de processamento, de maneira que uma tarefa com grande consumo de processamento possa ser dividida em tarefas menores, e executadas em cada um dos nós.

O requisito para escolha do nó é sua disponibilidade, por exemplo, em alguns modelos de programação, o nó que estiver com o menor processamento é escolhido para dividir a tarefa.

Desta maneira, nós de processamento que já estejam ocupados com alguma tarefa não serão sobrecarregados.

Assim, uma tarefa, pode ser dividida em várias pequenas tarefas e executada simultaneamente, aumentando sua eficiência com a quebra do paradigma de execução seqüencial do fluxo de instruções.

A principal motivação para explicar a necessidade de desenvolvimento da arquitetura de sistemas de processamento paralelo é o desempenho.

Além disso, outros fatores justificam sua evolução

A melhoria no desenvolvimento tecnológico, principalmente com desenvolvimento de chips VLSI (Very-Large-Scale Integration), projetados para conter mais de 10 milhões de transistores por chip.

Desta maneira houve um aumento do poder computacional por chips e, conseqüentemente, um ganho significativo na relação custo por desempenho, se comparado aos antigos supercomputadores.

Introdução e melhorias em componentes de sua arquitetura tais como memória cache dentro dos chips, buffers de instruções maiores, múltiplas instruções por ciclos, multi-threading, execução de instrução fora de ordem.

Necessidade cada vez maior de sistemas tolerantes a falhas.

Por exemplo, sistemas paralelos possuem redundância de hardware, já que, se um processador estiver com algum erro, o sistema redireciona o processamento para algum outro.

A classificação mais popular de arquiteturas de sistemas de processamento paralelo, é a que Flynn fez em 1966.

Seu esquema é baseado em uma relação entre fluxos de instruções e fluxos de dados, executados entre o conjunto de processadores.

O fluxo de instruções equivale a uma seqüência de instruções executadas em um processador.

O fluxo de dados é definido como uma seqüência de dados, incluindo dados de entrada, resultados parciais e intermediários, utilizados pelo fluxo de instruções.

De acordo com a classificação de Flynn, cada instrução ou dado pode ser simples ou múltipla, dividida em quatro categorias, SISD, Fluxo Único de Instruções/Fluxo Único de Dados (Single Instruction Stream/Single Data Stream), convencional modelo von Neumann.

Um processador 5 executa seqüencialmente um conjunto de instruções sobre um conjunto de dados.

Essa classificação representa a maioria dos computadores seriais existentes atualmente.

SIMD, Fluxo Único de Instruções/Fluxo Múltiplo de Dados (Single Instruction Stream/Multiple Data Stream), múltiplos processadores sob o controle de um único Sistema de Controle, também conhecido como unidade central de controle, executando paralelamente a mesma instrução sob grupos de dados diferentes.

Este tipo de arquitetura é usado para desenvolvimento de sistemas de processamento paralelo.

MISD, Fluxo Múltiplo de Instruções/Fluxo Único de Dados (Multiple Instruction stream/Single Data Stream), não há aplicação real.

Envolve múltiplos processadores executando diferentes instruções em um único conjunto de dados.

MIMD, Fluxo Múltiplo de Instruções/Fluxo Múltiplo de Dados (Multiple Instruction Stream/Multiple Data Stream), cada processador tem sua própria unidade de controle e pode executar diferentes instruções em diferentes conjuntos de dados.

Este tipo de arquitetura é o mais usado para desenvolvimento de sistemas de processamento paralelo atualmente.

Os sistemas de processamento paralelo mais antigos utilizam a arquitetura de Fluxo Único de Instruções/Fluxo Múltiplo de Dados SIMD, como ILLIAC IV.

O SIMD, pode ser resumido em uma unidade central de controle que produz e interpreta as instruções e depois as envia para o conjunto de processadores.

O grupo de processadores é um conjunto de elementos de processamento idênticos, com a capacidade de executar simultaneamente a mesma operação em diferentes grupos de dados.

Cada processador tem seu conjunto de memórias próprias, onde o dado distribuído é armazenado enquanto é processado.

O conjunto de processadores é conectado ao bus de memória da unidade central de controle (front-end) e, assim, ela pode acessar de forma aleatória as memórias locais dos processadores, como se fosse outra de suas memórias.

Desta maneira, a unidade central pode enviar instruções que causem algum tipo de operação ou movimentação dos dados.

Essa arquitetura é bastante utilizada para manipulação de matrizes, problemas complexos de álgebra linear, processamento de imagens entre outros.

Fluxo Múltiplo de Instruções/Fluxo Múltiplo de Dados, MIMD é uma arquitetura paralela composta de múltiplos processadores e múltiplos módulos de memória conectados via rede.

Como cada processador tem sua própria unidade de controle, há muito mais flexibilidade em relação ao SIMD, pois é possível executar diferentes instruções em diferentes grupos de dados de maneira paralela.

Eles são divididos em duas categorias, memória compartilhada ou passagem de mensagens.

O modelo de memória compartilhada, é onde os processadores se comunicam através de leituras e escritas em regiões de uma memória compartilhada que é igualmente acessada por todos.

Cada processador pode ter seus buffers, registradores e bancos de memória local, como memórias adicionais.

As principais questões, que merecem atenção neste tipo, de sistema são controle de acesso, sincronização, proteção (para que um processo não acesse a área do outro) e segurança.

Modelo de Arquitetura MIMD de Memória Compartilhada.

No modelo de passagem de mensagem, cada processador tem acesso a sua própria memória local.

A comunicação entre os processadores é feita através de um sistema de passagem de mensagens é executada via operações de envio e recebimento de mensagens em uma rede.

Cada nó da rede é um processador com sua memória local.

Alguns fatores importantes em sua arquitetura são, largura de banda, latência da rede e controle de envio e recebimento de mensagens.

Modelo de Arquitetura MIMD de Passagem de Mensagens.

A relevância das aplicações para sistemas de processamento paralelo é um dos grandes diferenciais da tecnologia, e cada vez mais, participa das soluções do dia a dia das empresas, governos, universidades e laboratórios de pesquisa.

As principais aplicações disponíveis para sistemas de processamento paralelo são, Modelos de Previsões e Simulações Previsão do Tempo.

Simulação de semicondutores.

Previsões oceanográficas.

Simulações astrofísicas, como modelos de buraco negro no espaço e formações astronômicas.

Seqüência de genomas humanos.

Projetos de Engenharia, Automação e Filmes (Imagens) Aerodinâmica.

Processamento de imagem.

Reconhecimento de padrões.

Inteligência Robótica.

Gráficos gerados por computadores, renderização de imagens e animações.

Exploração de Recursos Energéticos Exploração sísmica.

Fusão a Plasma.

Reator nuclear seguro.

Médica, Militar e pesquisas em geral Processamento de imagens médicas.

Desenvolvimento de vacinas.

Problemas de mecânica quântica.

Química de Polímeros.

Projetos relacionados a armas nucleares.

Resolução de problemas de álgebra linear.

Controle de trafego aéreo.

Serviços Financeiros, execução de longos e complexos modelos financeiros, apresentando decisões precisas em tempo real sobre investimentos, por exemplo.

Existem várias definições para o processo de teste, desde a visão intuitiva até uma conceituação formal.

Todas as afirmações, sejam intuitivas ou formais, carregam a mesma essência, teste de um sistema é o processo de executar o software de maneira planejada e controlada com o objetivo de avaliar se o comportamento do sistema está conforme com a especificação e se satisfaz às expectativas do usuário do sistema, ou de uma maneira mais informal, teste é o processo de executar um sistema com o objetivo de encontrar defeitos.

Neste contexto, um defeito é um mau funcionamento do software causado por falhas introduzidas durante o processo de desenvolvimento ou manutenção.

Muitas vezes não é possível testar cada caminho de execução do sistema, pois o número de casos de teste seria tão grande que inviabilizaria o processo de teste ou seria muito custoso, que não valeria a pena gastar tempo e recurso, pois ficaria mais caro testar do que corrigir um erro no futuro.

De acordo com, pode-se definir erro de software como, A diferença entre o valor processado, observado ou medido e o valor definido na especificação.

Um processo ou dado incorreto.

Um resultado ou comportamento inesperado, diferente do especificado.

Uma ação humana que produz um resultado incorreto.

Defeito no projeto do sistema, relacionado à linguagem de programação ou banco de dados.

Problemas de implementação, como códigos e algoritmos programados de forma incorreta.

Técnicas de teste são usadas para que a equipe consiga atingir seus objetivos, que é de encontrar o maior número de falhas em um sistema no menor tempo possível.

Ou seja, realizar testes com eficácia e eficiência.

Trabalhar com os desenvolvedores, analistas e usuários para elaborar os casos de teste pode ajudar a melhorá-los, principalmente se estiverem participando diretamente do projeto de desenvolvimento.

Os principais critérios para seleção são do tipo funcional, também conhecido como teste de caixa preta e o estrutural, ou teste de caixa branca.

Há outros como o teste orientado a objetos e baseado em estados, que não são explorados pela metodologia proposta neste trabalho e não serão detalhados.

O teste funcional (caixa preta) analisa as entradas e as saídas geradas pelo sistema para verificar a existência de falhas, isto é, realiza a verificação do funcionamento do software através de suas interfaces, o que, geralmente, permite checar se todas as funções do sistema estão de acordo com a especificação.

Mesmo que o valor da entrada seja inserido em ordem diferente, o resultado deve ser sempre o mesmo.

No teste funcional, é importante observar que a forma como o sistema está organizado internamente não tem real importância, mesmo que isto possa ter algum impacto na operação de alguma função observada em sua interface.

Os testes funcionais são utilizados para mostrar que as funcionalidades do sistema foram implementadas de acordo com a especificação, observando se as entradas e saídas estão corretas e compatíveis com a especificação, e se a integridade de informações externas é mantida.

Além disso, deve-se garantir que o sistema esteja em um determinando estado conhecido, para que esses testes tenham sucesso.

O teste estrutural (caixa branca) analisa os caminhos internos de execução do sistema para a construção dos casos de teste.

Um teste de caixa branca está relacionado a um exame mais preciso de sua estrutura interna.

Os caminhos lógicos definidos no software são exaustivamente testados, questionando conjuntos bem definidos de variáveis, condições lógicas e laços.

O critério para escolha dos casos de teste pode ser misto, ocorrendo compartilhamento de testes funcionais e estruturais.

Para casos em que a unidade de teste é uma pequena porção de código do sistema, ou um pequeno módulo, é recomendado o uso de testes estruturais.

Com o aumento de complexidade e integrações dos diversos componentes do sistema, os casos de testes passam gradativamente para funcionais.

Outra técnica que é relevante para o presente trabalho é o teste de regressão.

Tem o papel de verificar as modificações em uma nova versão do sistema, servindo para validar uma correção, verificar um possível problema por conseqüência de uma alteração ou testar novas funcionalidades.

Para este teste, casos de testes estrutural e funcional podem se repetir para que a nova versão seja adequadamente testada.

Além disso, é necessário garantir que as partes do software que permaneceram inalteradas continuem dentro das especificações.

O teste de regressão é fundamental para que a nova versão do sistema apresente desempenho igual, ou melhor, que a versão corrente.

O teste de stress é executado para avaliar como o sistema responde a condições anormais.

O stress do sistema pode abranger cargas de trabalho excessivas, memória insuficiente, hardware e serviços indisponíveis, capacidade de processamento esgotada, número elevado de transações, comunicação, e até interação com pessoas.

Por exemplo, pode-se testar um sistema de compra e venda pela Internet através da simulação de um grande volume de transações em um site de comercio eletrônico, observando como ele se comporta e se suporta essa quantidade de usuários ou transações simultâneas.

Se o sistema funcionar adequadamente nos testes, pode ser assumido que irá funcionar de maneira esperada em uma situação normal.

Uma característica importante no teste de stress, que algumas vezes não é considerada, é o fator tempo.

Dependendo do sistema, pode ser uma variável crítica.

Se o teste se comportar, de maneira adequada, com uma grande carga de dados, mas se o sistema demorar um tempo exponencialmente maior para terminar a execução, mesmo que com sucesso funcional, pode ser considerado um problema e mostra que o sistema precisa de melhorias no desempenho.

As estratégias de criação dos casos de teste de software ajudam no desenvolvimento do sistema.

Elas envolvem um amplo conjunto de tarefas que incluem desde o planejamento, análise de requisitos até a execução dos testes, onde as escolhas das técnicas de teste são muito importantes.

Em muitos casos, o teste representa mais esforço que qualquer outra atividade no projeto e começa desde a fase inicial de planejamento até a codificação, isto é, de uma simples função para o sistema como um todo.

A especificação dos testes deve documentar todo o processo de testes, definindo um plano que descreve uma estratégia global e um procedimento, que define passos específicos e os testes que serão conduzidos, além dos resultados esperados.

Vários autores recomendam uma estratégia para a criação dos casos de testes dividida em fases, teste de unidade (incluindo testes de módulos), integração, sistema e aceitação.

Componentes individuais ou uma coleção de componentes são testados independentemente para certificação de que operam corretamente, de acordo com a especificação, que pode conter aspectos funcionais e temporais.

Normalmente, esses testes ajudam a implementar os sistemas e são de responsabilidade dos programadores.

Esses testes comumente adotam o critério estrutural.

Esta é a fase onde os módulos são testados de modo integrado.

Subsistemas podem ser desenhados e implementados independentemente, mas requerem a realização de testes de integração.

Um problema comum em grandes sistemas está na integração das interfaces entre os módulos dos subsistemas, devido à complexidade das interfaces que relacionam cada módulo.

Geralmente são utilizados critérios funcionais em conjunto com estruturais, dependendo muito do sistema, dos tipos de interfaces e do foco dos testes.

É uma técnica que ajuda a construção da estrutura do sistema e, ao mesmo tempo, procura descobrir erros relacionados à interface.

O objetivo é construir a estrutura de interfaces do sistema, a partir dos módulos testados no nível de unidade/módulo.

A integração pode ser incremental ou não-incremental.

A integração não-incremental utiliza a abordagem do big-bang, combinando-se antecipadamente todos os módulos.

Esta técnica não costuma ser muito eficaz, pois torna-se difícil isolar um erro e quando esses são corrigidos, novos erros são gerados na estrutura do programa.

Esse ponto ainda é mais grave, quando o sistema tem interfaces muito complexas.

Por outro lado, a integração incremental é mais eficiente e pode seguir duas abordagens, top-down ou bottom-up.

Na integração top-down, o processo pode ser resumido em cinco tarefas principais, 1) Módulo de controle principal é usado como uma linha guia de teste, recebendo e tratando os dados de alguma maneira, enviando informações para outros módulos e apresentando os resultados.

Alguns programas de simulação (que são similares aos reais nas interfaces, mas executam apenas o mínimo) podem ser usados para substituírem os reais nas integrações entre os módulos.

Dependendo da abordagem de integração escolhida, do programa principal para as demais interfaces, pode haver vários caminhos e os programas simuladores podem ser substituídos, um por vez, pelos programas reais.

Testes são executados a cada substituição de um dos módulos.

Após o término de um teste, outro programa simulador é substituído por um módulo real e um outro teste é realizado.

O teste de regressão é opcional e pode ser realizado no final dos testes para garantir que novas falhas não foram agregadas aos módulos.

A desvantagem desta abordagem é a necessidade de um esforço adicional para o desenvolvimento dos programas simuladores e a resolução das dificuldades de teste, que podem estar associadas a eles.

A integração bottom-up, por outro lado, inicia os testes pelos módulos menores do sistema, isto é, módulos localizados nos níveis inferiores da estrutura do programa.

Como os módulos são testados e integrados do mais simples para o agrupamento mais complexo, não existe a necessidade de serem criados programas simuladores.

Uma estratégia desta técnica pode ser desenvolvida através de quatro passos, 1) Os módulos mais simples são testados e agrupados para executarem funções ou sub-funções específicas do sistema.

Pode haver a necessidade de um programa de controle principal para os testes, que coordena a entrada e saída de cada caso de teste.

Cada conjunto de módulos é testado.

Os programas de controle são removidos e mais módulos ou conjunto de módulos é agregado aos testes, até que todo o sistema tenha sido avaliado.

A desvantagem deste tipo de integração é a necessidade do desenvolvimento de programas de controle e o fato de se ter a noção do teste completo do sistema, do primeiro ao último módulo, só depois de testado o último módulo.

É diferente da técnica top-down, em que se escolhe um caminho completo do módulo principal até o mais simples.

Um problema que precisa ser equacionado na abordagem de teste de integração é o que fazer quando algum dos módulos não estiver finalizado.

Algumas soluções são que os testes podem ficar parados até a finalização do desenvolvimento.

Pode ser desenvolvido um simulador simples que apenas simule as interfaces de entrada e saída do módulo, para que seja incluído na estrutura, e possa receber informações e enviar para o próximo módulo que já pode estar finalizado.

Utilizar algum módulo já existente que execute funções semelhantes e possua interfaces de entrada e saída compatíveis com os módulos adjacentes.

Os subsistemas são integrados para formarem um único sistema.

O processo deste tipo de teste irá detectar uma falha resultante das interações entre subsistemas e componentes de sistema.

Nos testes, o software e outros elementos são considerados como um todo, e os casos de testes de sistema verificam a integração dos diferentes componentes e se eles executam apropriadamente suas funções.

Este é a última fase do processo de testes antes que o sistema seja concluído.

Ele é testado com dados fornecidos pelo usuário final, ao contrário de dados fictícios ou simulados, e com a freqüência em que será usualmente empregado quando estiver finalizado.

Os testes de aceitação revelam principalmente erros e omissões na definição dos requisitos, pois, através do uso de dados reais, o sistema é exercitado de formas variadas.

A Norma IEEE 829 descreve um conjunto de documentos básicos para teste de software.

Um padrão de documentos de testes ajuda na comunicação entre as várias equipes envolvidas no projeto, além de orientar, de maneira organizada, e otimizada uma checagem de todo o processo de teste.

A norma é uma ferramenta útil na formatação da metodologia de testes, pois padroniza como documentar o planejamento e execução dos testes com as novas versões de sistemas de processamento paralelo.

Além de apresentar um conjunto de documentos, que são utilizados ou adaptados para determinados projetos, a norma define um conjunto de informações necessárias para que o teste seja feito com qualidade.

Sua correta utilização auxiliará as pessoas a se concentrar em todas as fases do teste, evitando o problema de apenas pensar no teste após a codificação.

A norma padroniza um conjunto de 8 documentos para as atividades de teste de um sistema, cobrindo as tarefas apresentadas, Plano de Teste, Apresenta o planejamento para execução do teste, incluindo o escopo, abordagem, recursos e cronograma das atividades de teste.

Nesta etapa, são identificados os itens e as funcionalidades a serem testadas, as tarefas a serem realizadas e os riscos associados com a atividade de teste.

Especificação do Projeto de Teste, Refina o processo de teste e a identificação das funcionalidades e características a serem testadas pelo projeto, além de aprimorar a integração entre os testes associados.

Este documento identifica, também, os casos e os procedimentos de teste, se existir, e apresenta os critérios de aprovação.

Especificação de Caso de Teste, Documenta os casos de teste, incluindo dados de entrada, resultados esperados, ações e condições gerais para a execução do teste.

A Especificação de Caso de Teste é separada do Projeto de Teste para permitir o uso dos testes em mais de um projeto e reutilizá-lo em outras situações.

Especificação de Procedimento de Teste, Específica todos os passos requeridos para executar funções do sistema e exercitar um conjunto de casos de teste, incluindo testes de integração.

Os procedimentos de teste estão separados da especificação, pois deve ser documentado passo a passo e com maior nível de detalhe.

Relatório de Item de Teste Transmitido, Reporta o item que está sendo enviado para o teste.

Inclui a pessoa responsável, sua localização física, aprovadores do teste e sua situação (qualquer desvio entre a documentação do teste, o plano de teste e alguma prévia execução do teste).

Diário de Teste, Registra tudo o que ocorreu durante as atividades de testes e a duração de cada uma delas.

Relatório de Incidente de Teste Descreve todo evento ocorrido durante o processo de teste que requer análise futura.

Relatório Resumo de Teste, Documenta, de forma sucinta, os resultados das atividades de teste associadas com uma ou mais especificações de projeto.

Apresenta o fluxo de documentos de teste, que é utilizado na execução de cada uma das fases, os relacionamentos entre estes documentos e o processo de teste descrito na norma.

Relacionamento entre os Documentos e o Processo de teste.

Antes de iniciar os testes, é necessário levantar alguns documentos do projeto, como os manuais de funcionamento do produto, as especificações, os requisitos e os itens que serão utilizados em cada um dos testes.

Outro insumo importante é o grau de familiaridade com o sistema.

É fundamental que as equipes de teste conheçam bem o produto que precisa ser avaliado.

Por isso, algumas vezes, é necessário realizar algumas reuniões com os programadores, analistas de sistemas ou engenheiros responsáveis, ou até incluí-los nas equipes de teste.

Embora a norma IEEE 829 possa ser usada para qualquer tipo de teste, projetos pequenos ou de baixa complexidade podem agrupar alguns documentos, reduzindo o esforço de gerenciamento, os custos de elaboração dos documentos e o nível de detalhe dos documentos.

A equipe responsável pelo teste deverá tomar certas decisões em relação à aplicação da norma em determinados projetos, decidindo, por exemplo, se é mais conveniente elaborar um único plano que englobe os testes de unidade, integração e aceitação, ou um plano para cada uma das fases de teste citadas.

Existem diferentes técnicas na área de engenharia de software que buscam a redução do tempo de ciclo de vida de teste do software (STLC) e, conseqüentemente, a liberação mais rápida do produto final para o cliente.

A diminuição no tempo do projeto não deve implicar a perda de qualidade do sistema e nem o aumento do custo do projeto.

Neste capítulo, serão resumidos alguns trabalhos que mostram como reduzir o tempo de um projeto através da diminuição do tempo gasto na atividade de teste, com técnicas de testes em paralelo, testes contínuos, automação de casos de teste e simulações.

Há alguns autores que discutem como reduzir o período de testes associado à redução de custo dos testes.

Existem 4 maneiras para se diminuir o custo, Testar menos.

Este é o pior caso, pois o sistema final poderá ter uma quantidade muito grande de erros e o custo de manutenção poderá tornar o projeto inviável.

Testar de maneira mais eficiente.

Aplicar métodos que reduzam o tempo dos testes.

Testar de forma diferente.

Usar estratégias diferentes que reduzam o custo e não perca a qualidade.

Reduzir o custo dos testadores.

Através de profissionais com custos mais baixos e, consequentemente, com menos conhecimento.

O presente trabalho mostra como reduzir o tempo da atividade de testes de sistemas de processamento paralelo e, como conseqüência, viabilizar a entrega de um produto ao mercado consumidor com qualidade igual ou maior e em um intervalo de tempo menor.

Além de acelerar o retorno de investimento através da venda antecipada do sistema, pode-se haver uma redução no custo do projeto, através da melhor utilização de recursos ociosos.

Por exemplo, ocupando mais tempo de processamento de CPU (Control Process Unit) e memória de algum equipamento caro que estiver sendo alocado para testes, em vez de deixá-lo ocioso, pode-se aproveitá-lo em outro projeto similar (reduzindo custo com compartilhamento dos recursos).

Outra possibilidade é, através de testes paralelos, aumentar sua ocupação, diminuindo o tempo de teste e liberando o equipamento mais rapidamente.

Para resolver este problema, serão apresentadas algumas estratégias de teste que otimizam a utilização de recursos, aumentam o rendimento da equipe de teste e reduzem o tempo final do projeto.

A técnica de teste em paralelo reduz o ciclo de vida de teste de software (STLC), pois é possível usar o mesmo sistema de teste em mais de uma unidade de teste (Unit Under Test, UUT) de maneira simultânea.

A unidade de teste é o código, programa ou algum módulo do software, que está sendo testado.

Sistema de teste é a ferramenta, o software, hardware ou o procedimento usado para executar o teste.

A pessoa que executa os testes chama-se testador.

A diferença entre executar um mesmo sistema de teste com vários testes e executar dois sistemas de teste em paralelo, é que, no segundo caso, utilizando mais de um sistema de teste, haverá um aumento nos gastos com equipamentos e em pessoas para testar, além de uma concorrência por espaços físicos e recursos utilizados nos testes.

Por exemplo, se o sistema de teste pode ser feito através da execução de um processo em um computador, fazer testes simultâneos é disparar vários processos no mesmo computador.

Já trabalhar com dois sistemas de teste, seria usar dois computadores para fazer os testes.

Testar simultaneamente duas unidades de teste otimiza os testadores, pois geralmente, é possível compartilhar os equipamentos.

A maioria dos testes tem uma utilização de recursos média entre 30% e 50%, pois muitos sistemas executam um teste após o outro, e não utilizam todos os recursos planejados para toda a atividade de teste.

Um testador tradicional trabalha com apenas uma unidade de teste por vez, executando os testes para depois iniciar os testes com a próxima unidade.

Alterando o processo para testes em paralelo podem-se testar duas ou mais unidades de teste simultaneamente.

Na execução dos testes em paralelo, é importante levar em consideração o tempo de ociosidade dos equipamentos.

Há um exemplo da execução de testes simultâneos para reduzir este tempo e finalizar os testes em um menor número de ciclos que no caso de testes seqüenciais.

Neste exemplo, há quatro unidades de teste (UUT) sendo executadas em paralelo.

O processo é composto por um teste de Rádio Freqüência (RF), que pode usar um gerador de sinais e um analisador de espectro de radio freqüência.

Este é o único teste sendo executado no primeiro ciclo de tempo.

Os testes de áudio e digital, que devem usar um digitalizador de áudio e um analisador de protocolo respectivamente, não ocorrem no primeiro ciclo.

O processo de teste é executado em 6 (seis) ciclos de tempo.

Teste em Paralelo em Múltiplas Unidades de Teste).

Para minimizar a ociosidade dos equipamentos, mesmo com testes em paralelo, é possível executar as unidades de testes (UUT), agendando a sua execução de acordo com a desocupação dos equipamentos.

Este cenário é válido caso não haja nenhum tipo de dependência entre os testes.

Teste em Paralelo com Otimização de Recursos Ociosos.

Testes em paralelo, que significa múltiplas unidades de teste (UUT), comparado com teste seqüencial, podem melhorar muito o desempenho dos testes, aumentando o número de tarefas simultâneas, minimizando o tempo ocioso dos equipamentos, de processamento e de pessoas e até reduzindo custos, caso seja compartilhado algum tipo de instrumento com custo significativo por período muito grande.

De acordo com, se comparado com testes seqüenciais, testes em paralelo são técnicas muito mais complexas para serem implementadas em sistemas de teste automático (Automatic Test System, ATS).

Para os testes automáticos, diferentes do modelo tradicional, onde há divergência entre a utilização ou não de padrões formais para testes, existe um consenso de se utilizar técnicas de teste mais modernas desenvolvidas na Engenharia de Software.

O amadurecimento dos testes automatizados com maior precisão é fruto de uma grande variedade de modelos funcionais de testes, que foram desenvolvidos para melhorar o processo de testes, e da expressiva otimização que ferramentas, como sistemas de instrumentação e sistemas de medição, sofreram nos últimos anos.

Estes dois requisitos, diversidade de modelos e melhoria das ferramentas, são fundamentais para automatização dos testes, principalmente em ambientes complexos como o de testes em paralelo.

Muitos sistemas de teste são, tradicionalmente, representados por modelos funcionais.

A questão principal é que modelos funcionais, em alguns casos, são muito simplórios, porque não levam em consideração importantes características internas dos softwares, além de serem mais difíceis de reutilizar ou modificar.

Para endereçar esse problema, o autor propõe um modelo de testes genéricos baseados em orientação a objeto e um modelo para testes em paralelo baseado na orientação a objeto através da Linguagem Unificada de Modelagem (Unified Modeling Language, UML).

O modelo orientado a objeto é baseado no conceito de classes, que possuem atributos e métodos.

Os objetos são instâncias de uma classe.

Cada objeto possui um estado bem definido pelo valor de seus atributos, e um comportamento definido por seus métodos.

Uma classe pode estender outra para incluir ou modificar funcionalidades.

A nova classe herda todos os métodos e atributos da classe original, também chamada de superclasse.

Esse recurso, que permite uma grande reutilização de código, é chamado herança.

A arquitetura de teste em paralelo convencional (sem o conceito de orientação a objetos), pode ser considerada como um grupo de seqüência de componentes reutilizáveis que atuam na atividade de teste.

Estes componentes podem ser conectados através de uma rede de alta velocidade, onde cada nó executa um teste independentemente do outro.

Cada nó opera com apenas uma unidade de teste (UUT) de cada vez e cada um deles, independente, pode ser interpretado como um teste seqüencial tradicional.

Este sistema é muito caro, pois multiplica os equipamentos como computadores, medidores, roteadores, entre outros pelo número de testadores simultâneos.

Uma dificuldade dos sistemas reais de teste paralelo, verificado pelo autor, através de pesquisas e sua experiência, é a possível necessidade de sincronização com precisão dos testes em uma rede.

Modelo Estático de Sistemas de Teste em Paralelo Orientado a Objetos O modelo é baseado em classes, que é o conceito mais importante da orientação a objetos.

As classes são entidades, que possuem atributos e comportamentos.

De acordo com a arquitetura de sistemas de teste em paralelo, é proposto classificá-las em três pacotes de classes obrigatórios e um opcional, Pacote de Classe de Negócio de Teste, descreve os objetos do negócio.

Consistem em classes de teste genérico e testes paralelos.

Este pacote contém classes como, classe teste, classe medidas, classe estação de teste, classe instrumentação, classe unidade de teste, classe critério de referência, classe calibração e classe de junção.

As classes que descrevem os modelos de testes paralelos, são as classes modo de teste, classe de agendamento de teste, classe fila de teste, classe testSwitch e classe multiplexador.

Pacote de Classe Banco de Dados, descreve objetos persistentes, que possuem IDs e são objetos mantidos ao longo de todo o teste, que podem fornecer serviços para todas as classes do pacote de negócios.

A classe persistente dentro deste pacote possui os métodos para salvar os objetos das classes, isto é, salvar tudo referente aos objetos das classes em algum tipo de banco de dados.

Pacote de Classe de Utilidades, classes públicas, como a classe ObjId.

Este pacote de classe é utilizado por todos os outros.

Pacote de Classe Opcional Interface de Usuário, descreve as interfaces gráficas de interação com os usuários O autor descreve, com mais detalhes, alguns pacotes como classes de interface e apresenta os alguns diagramas de como são seus relacionamentos.

Este modelo descreve apenas relacionamentos estáticos de todos os objetos de um sistema de teste em paralelo.

Ele não é suficiente para descrever as interações e colaborações entre eles.

Para resolver o problema, o autor mostra o sistema de modelo de teste dinâmico.

Modelo Dinâmico de Sistemas de Teste Paralelo Orientado A Objetos O modelo dinâmico mostra, passo a passo, os detalhes do fluxo de trabalho de cada caso de uso descrito nos testes em paralelo, tais como, quais mensagens são trocadas pelos objetos, quais são os objetos necessários em cada fluxo, quais são os atores que iniciam os testes, a seqüência de envio de mensagens, e assim por diante.

O autor do teste utiliza um diagrama de seqüências para descrever o modelo dinâmico de testes paralelos.

Mostra o início do fluxo apresentado.

Ela descreve a seqüência de mensagens trocadas entre as classes.

Início do Fluxo de Sistema de Teste Paralelo.

O teste começa quando o usuário aciona um controle para iniciar o sistema de testes paralelos (função Test Paral da classe de interface).

Quando o objeto,Agendam Teste recebe a mensagem para executar os testes, armazena todos os testes no objeto,Fila Teste, através da função Enfilera Teste, e transfere o resultado para o próximo objeto, que é,Fila Teste.

Então, este objeto faz as alterações necessárias e envia uma mensagem para o objeto,Teste para iniciar os testes.

O objeto,Mutex aloca um recurso necessário, de acordo com as tarefas do teste que está sendo executado e, assim por diante, até que o teste seja executado por completo.

Então, é trocado o teste do objeto,Test e enviado os resultados para o usuário, por exemplo.

O modelo foi simplificado neste exemplo, mas muitos objetos podem participar, dependendo do teste, como objeto de medidas e instrumentação.

Por exemplo, no diagrama que foi descrito depois de iniciar o teste pelo objeto,Teste, pode ser necessário algum tipo de medição e o objeto,Teste pode enviar uma mensagem para o objeto,Controle de medidas, que trata de medições e instrumentações.

Então, este objeto lê os dados de alguns instrumentos, que podem ser sinais digitais.

Ele converte, então, este dado em um formato usado pelo objeto,Teste e retorna o resultado para ele.

A atividade de teste tem, como característica, ser executada com certa freqüência durante o ciclo de desenvolvimento do sistema (SDLC) para garantir a confiabilidade e qualidade do software ou hardware, permitindo encontrar previamente os erros.

Entretanto, parar o desenvolvimento, periodicamente, para testar pode implicar na perda de muito tempo no progresso do sistema.

Estudos em projetos reais mostram que essa perda pode chegar a 15% do tempo do projeto apresenta um modelo de comportamento de desenvolvedor que altera metodologias de teste e ferramentas de teste para reduzir o desperdício de tempo de teste no ciclo de desenvolvimento.

Alterando a ordem dos testes pode-se diminuir o tempo de 4% até 41% nos casos estudados.

Outro fator estudado foi a mudança na freqüência da execução dos testes, que pode levar à redução do tempo gasto de 31% até 82%.

A questão importante é que os desenvolvedores não sabem a freqüência ideal até a conclusão dos testes.

O autor apresenta e avalia uma nova técnica, chamada Teste Contínuo, que compartilha CPU (Central Processing Unit CPU) para executar testes em background de forma contínua, detectando falha à medida que o código for sendo desenvolvido.

Nos testes, o autor mostra uma redução de aproximadamente 90% de desperdício do tempo de espera do desenvolvimento, enquanto está sendo executado o processo de teste.

Umas das fontes mais comuns de erros, que desperdiça tempo de desenvolvimento, são os erros recorrentes de sistemas que já estavam corrigidos, mas que foram reintroduzidos, através de uma manutenção ou alguma alteração no código.

Para verificar esse tipo de erro, é necessário executar algum tipo de ferramenta ou script de teste periodicamente durante o desenvolvimento.

Depois de efetuada qualquer alteração, é necessário executar, novamente, os mesmos testes.

Nesta abordagem, tanto o desenvolvedor quanto a CPU ficam com tempo ocioso, esperando a execução dos testes.

Para otimizar esse tempo, pode-se fazer um teste assíncrono disparado pelo desenvolvedor em uma versão, enquanto ele continua trabalhando em outra versão.

Neste caso, seria criado um outro tipo de problema.

As novas alterações ou até correções que o desenvolvedor esteja fazendo na nova versão do código que está sendo testado, não estão sendo detectadas pelo teste, pois o desenvolvedor está trabalhando em outra versão do código, diferente da que está sendo avaliada.

A técnica de Teste Contínuo, apresentada pelo autor, executa testes no código corrente, em que o desenvolvedor estiver trabalhando, de maneira transparente.

O usuário não precisa iniciar nenhum teste de forma explícita.

Para o estudo, é necessário dados do mundo real sobre o comportamento do desenvolvedor e um modelo de seu comportamento, que permitam predições sobre alterações no ambiente de desenvolvimento.

Os dados foram adquiridos a partir da monitoração de dois projetos de desenvolvimento, mostrando as alterações do sistema ao longo do tempo, a execução de testes, a inserção de erros e, posteriormente, a revelação das falhas pelos testes.

O modelo, que é a base do trabalho, é um autômato finito, onde os estados representam se o código que está sendo desenvolvido passou nos testes de regressão e se o desenvolvedor acredita que o teste está correto.

Transições entre os estados são disparadas por eventos como alteração do sistema (introduzindo ou corrigindo erros) e execução de testes.

Testes de regressão informam ao desenvolvedor a ocorrência de um erro.

Este, por sua vez, pode corrigir o sistema ou anotar e resolver o erro futuramente.

De qualquer maneira, como o código está recente, o programador terá mais facilidade em resolvê-lo neste momento, do que esperar o resultado de testes, quando o módulo estiver finalizado e, só depois testá-lo.

Se o desenvolvedor já suspeitar de um erro, o teste apenas confirma sua suspeita, mas não altera seu comportamento.

A notificação do erro é mais útil quando ocorrer um erro acidental ou desconhecido.

O modelo deve levar as duas situações em consideração.

Questionar os desenvolvedores, sobre quantos e quais testes têm mais chance de falhar, pode ser muito improdutivo e tedioso, afetando o comportamento dos desenvolvedores e degradando o nível das respostas.

A abordagem adotada é menos intrusiva.

É feita uma observação moderada do comportamento do desenvolvedor e, então, inferido, a partir das ações da pessoa, se ela acredita que há um erro de regressão presente.

Esta não é uma maneira precisa, entretanto, ela é baseada na intuição dos autores e suas experiências sobre desenvolvimento de software.

O autor propõe dois modelos para o comportamento do desenvolvedor.

O modelo síncrono descreve o comportamento do desenvolvedor, que apenas recebe o resultado do teste depois de executá-lo e espera sua conclusão antes de continuar o desenvolvimento.

O modelo assíncrono seguro estende o modelo síncrono para descrever o comportamento do desenvolvedor quando o resultado dos testes na versão corrente do software é fornecido sem a explicita ação do desenvolvedor, enquanto está programando.

Não está sendo considerado o modelo assíncrono inseguro, onde o desenvolvedor trabalha em um código enquanto os testes são executados em outra versão mais antiga.

Cada modelo é representado por uma máquina de estados finita, onde cada estado indica os objetivos do desenvolvedor e se ele acha que existem erros de regressão ou não.

Transmissão causada por eventos, que são as setas entre os estados, são as ações executadas pelo desenvolvedor ou por seu ambiente.

O modelo síncrono é um caso especial do modelo assíncrono, onde nenhuma notificação de falha no teste é recebida sem o explicito disparo do teste.

O modelo do comportamento do desenvolvedor pode ser usado de duas maneiras, observações e previsão.

Quando usado para observação, eventos direcionam o modelo para estados que indicam a convicção do desenvolvedor sobre a corretude dos testes.

Quando usado como previsão, ambos os estados e ações são reproduzidos dentro do modelo para inferir o comportamento do desenvolvedor sob diferentes condições.

Neste modelo, é usada uma estratégia de teste conhecida como adivinha-e-verifica.

O desenvolvedor altera o código fonte até que ele entenda que está sem erros (estágio de adivinha).

Então é executado o teste e fica-se esperando sua conclusão (estágio verifica).

Se o teste falhar, é sinal que o desenvolvedor introduziu um erro de regressão nesta nova versão do sistema sem perceber.

Ele, então, trabalha com o código e testa até que nenhuma falha seja mais encontrada.

O modelo assume que o desenvolvedor mantém testes automatizados para testar (todo ou parte) o comportamento do sistema.

É possível que os testes estejam incompletos ou errados, mas esses casos não são modelados pelo autor.

O autor também ignora todos os pontos onde um teste não é executável, por exemplo, quando o código apresenta erros de compilação.

O autômato de estado finito não-determinístico, modela o processo de desenvolvimento síncrono para o caso de um teste simples.

Este autômato tem cinco estados, Estável, o teste está sendo executado sem erros e o desenvolvedor sabe disso.

Ele está codificando o sistema, adicionando novas funcionalidades, trabalhando outras partes do sistema ou até não executando nenhuma tarefa.

Alterando, o desenvolvedor está modificando o código temporariamente, causando alguma falha no teste, e tem conhecimento disso.

Ele está no meio de alguma alteração e vai executar o teste no final.

Desconhecimento, um erro de regressão foi inserido em alguma alteração do desenvolvedor sem o seu conhecimento.

O teste está falhando, mas ele não sabe.

Ele continua seu trabalho como se o teste estivesse sem erros.

Esperando Teste, o desenvolvedor iniciou os testes e está esperando sua conclusão.

Corrigindo, devido a um erro nos testes, o desenvolvedor sabe que um erro de regressão foi introduzido no código e está corrigindo-o.

Na falta dos Testes Contínuos, seis eventos podem ser observados no mapa de transição entre os estados, Adiciona Teste, um primeiro teste é inserido e coloca o modelo no estado Estável ou Corrigindo, dependendo se o teste passou com erros ou sem erros.

Para simplificação, está omitindo este evento.

Execução Testes, o desenvolvedor inicia os testes.

Teste Falhou, o teste falhou e o desenvolvedor tem detalhes do teste e do erro.

Passou no Teste, o teste foi executado com sucesso.

Erro, o desenvolvedor, intencionalmente ou inadvertidamente introduziu um erro no sistema.

Corrigido, o desenvolvedor corrigiu o erro intencionalmente.

Mod Síncrono de Comportamento de Desenvolvedor.

O modelo síncrono proíbe comportamentos plausíveis.

Por exemplo, o estado, onde o teste falha e o desenvolvedor acredita que ele está errado, não existe no modelo, pois esse é um estado muito raro.

Outro exemplo é a correção dos erros, que nem sempre ocorre com o conhecimento do desenvolvedor.

Na prática, ele até corrige alguns erros de regressão acidentalmente, mas também é tão incomum que não é tratado pelo autor.

É apresentado este modelo de comportamento do desenvolvedor em um ambiente com Testes Contínuos, no qual as falhas nos testes são mostradas imediatamente ao programador.

Este modelo é usado para inferir o desempenho dos Testes Contínuos.

O modelo difere apenas pela adição da transição de Notificação de Falha nos estados Corrigindo e Alterando.

Esta transição acontece quando o ambiente de desenvolvimento, através dos Testes Contínuos, notifica o desenvolvedor que houve um erro em um teste particular, tornando a falha no sistema conhecida pelo programador.

Modelo de Comportamento de Desenvolvedor com Testes Contínuos, Teste Simples.

Com esse modelo, o autor espera reduzir o tempo desperdiçado em testes de sistemas.

Para isso, o autor define que esse tempo é uma relação entre o tempo de espera no estado de Desconhecimento mais o tempo para tratar erros de regressão, que envolve encontrar os erros e corrigi-los.

Através da imediata noção de que há um erro no código que acabou de ser desenvolvido, o programador pode corrigi-lo de maneira rápida sem perder tempo procurando o erro, entendendo a parte do código em questão, lendo alguma documentação sobre o algoritmo, pois ele tem isso bem recente na memória.

Nos resultados experimentais obtidos pelo autor, foram apresentados números, onde essa abordagem conseguiu reduzir o tempo de ociosidade do desenvolvedor e de CPU em 8%, diminuindo o do processo de teste e conseqüentemente o tempo total do projeto.

O autor faz uma análise sobre os testes descritos no processo de desenvolvimento de sistemas chamado Modelo V e propõe uma melhoria na fase de testes, para reduzir o tempo de projeto.

O modelo é um padrão utilizado pelo Governo Alemão e por muitas outras empresas, desde que se tornou público.

Descreve as atividades e os resultados, que devem ser produzidos ao longo do desenvolvimento de software.

Método Tradicional de Teste de Ciclo de Vida, Modelo V O Modelo V, propõe um tipo de teste relacionado a cada etapa do desenvolvimento.

Modelo V.

O objetivo é melhorar a qualidade do sistema, através do teste durante todo o ciclo de desenvolvimento, para conseguir uma detecção adiantada dos erros.

Cada etapa do processo de desenvolvimento é analisada, verificada e testada.

O processo passa para próxima etapa quando todas as falhas detectadas forem removidas.

O Modelo V introduz a fase de testes durante o ciclo de desenvolvimento do software, ao contrário de outros que só fazem testes no final do ciclo, quando todo o desenvolvimento estiver finalizado.

Cada fase de testes é definida e executada de acordo com um plano de teste.

O modelo mostra a importância do teste do software no início do ciclo de desenvolvimento, como uma maneira eficiente de garantir a qualidade do software, mostrando que o teste não é uma fase, mas uma parte integrante do processo de desenvolvimento do sistema.

Embora existam todos os testes, como teste de unidade, teste de integração das unidades, teste de sistemas e teste de aceitação, a atividade de teste inicia, efetivamente, no momento que o primeiro módulo ou unidade tiver terminado a sua codificação.

O modelo não define que a atividade de teste deve iniciar formalmente depois da codificação, mas, sim, apresenta um mapa da fase de desenvolvimento com os respectivos níveis de teste.

Porém, o ponto principal é como executar testes em conjunto com as fases do diagrama do Modelo V, de modo que o esforço de teste nas fases finais seja reduzido.

O Modelo V propõe ciclos de desenvolvimento mapeados com níveis de teste, mas falha em endereçar como preparar os testes em paralelo com o desenvolvimento, já que a proposta é começar a testar apenas no final do ciclo de vida do desenvolvimento de software (SDLC).

Iniciar os testes, no meio da codificação, faz o tempo de teste ser adicionado ao tempo total do projeto.

Além disso, caso tenha uma equipe de teste independente para o projeto, ela ficará muito tempo ociosa, até a efetiva execução dos testes.
Atividades Paralelas entre Teste e Desenvolvimento Se o teste do software é executado realmente em paralelo com o desenvolvimento, não só a equipe de teste tem mais tempo para dominar o assunto, como também para propor otimizações e tornar os testes mais eficientes.

A especificação de requisitos, o projeto e até as interfaces de testes podem desenvolvidas já na fase de detalhamento do projeto de desenvolvimento (SDLC), pois todos os requisitos já devem estar definidos.

Além disso, nesta mesma fase do SDLC, é possível iniciar configurações de ferramentas para automatização dos testes.

Deve ser possível preparar 50% dos scripts e configurações.

Outra consideração importante sobre a automação, que a maioria dos autores concorda é que a automação de testes torna-os sempre, pelo menos, 90% mais rápido e confiável que testes manuais.

Sendo assim, quanto mais tempo e informações sobre os casos de teste a equipe aproveitar na fase de desenvolvimento, maior o grau de automação dos testes.

Esta atividade pode consumir um tempo muito grande, se for executada apenas na fase de teste (STLC).

Além disso, se iniciada na fase de codificação, os programadores, analistas de sistemas e engenheiros, que criaram os códigos, têm melhores condições de identificar e corrigir o problema.

Há inúmeras ferramentas disponíveis atualmente que ajudam nesta tarefa.

É preciso confiar em alguma e seguir com sua configuração desde a fase de desenvolvimento.

Junto com as ferramentas, é importante também iniciar os testes de unidade paralelamente com a fase de codificação.

As aplicações criadas para automatizar os testes, denominadas pelo autor como clientes de teste, que são desenvolvidos com principal objetivo de suportar testes funcionais, deveriam ser iniciadas na fase de detalhamento do projeto (SDLC).

A equipe de teste deve desenvolver os programas clientes de maneira mais genérica possível, de modo que seja possível reaproveitá-los em outros projetos similares.

Ciclos de Teste de Regressão e Correção de Erros.

Quanto maior os ciclos de teste de regressão e correção de erros, mais tempo de teste são incrementados no projeto.

Desta maneira, se pelo menos 50% dos casos de teste não estiverem automatizados, a cada ciclo, o tempo para execução dos testes aumenta, pois tem que testar todo o código anterior, mais as modificações.

A proposta é que sejam desenvolvidos clientes de teste cobrindo 90% dos testes.

Para isso, são necessários um planejamento eficiente e tempo para todo esse nível de automação.

O autor propõe um novo processo para o teste de software chamado modelo Little Joe, que endereça todas as questões e restrições apresentadas para o Modelo V.

O autor executou as novas atividades em vários projetos para testar seu modelo.

O ciclo de vida de teste do software (STLC) é iniciado antes da atividade de teste proposta no Modelo V.

Logo que a especificação dos requisitos seja finalizada e sejam iniciadas as discussões sobre o projeto, o STLC começa a ser executado em paralelo, com o planejamento dos testes, e caminha junto com o desenvolvimento até o teste de unidade.

Após está fase de ciclo de vida de desenvolvimento do software, iniciam-se as fases do ciclo de vida de teste (STLC) com os testes de integração até os testes de aceitação do produto, com a diferença em relação ao Modelo V, que os testes já têm mais maturidade e estão mais bem preparados.

Com isso, o tempo do STLC consegue ser reduzido e a equipe de teste, ao iniciar esta fase, já tem muitos casos de teste automatizados.

Modelo Little Joe Modelo V.

O modelo proposto pelo autor executa as quatro primeiras atividades de teste (Planejamento da Documentação dos Testes, Planejamento do Projeto de Testes, Geração dos Clientes de Teste e início da Execução dos Clientes) em paralelo com o desenvolvimento do software.

De acordo com o autor, clientes de teste, que automatizam os testes, cobrem de 50% a 70% dos casos de teste no Modelo V e no modelo proposto chegaram a cobrir 95% a 100%, pois são planejados e desenvolvidos ainda no ciclo de desenvolvimento.

Além disso, como a equipe de teste tem mais tempo, os clientes são gerados de forma mais genérica e conseguem ser melhor reaproveitados em outros projetos e em testes de regressão.

Desde a fase de projeto, os clientes de teste ou programa de automação são desenvolvidos e finalizados até a fase de codificação.

Assim, o tempo requerido para preparação dos procedimentos para o teste de integração do STLC é mínimo.

A maior parte do tempo do STLC é gasto na execução dos testes.

Com ferramentas de automação, os testes de sistemas economizam tempo no desenvolvimento dos projetos de software, mantêm os padrões entre os testes nas várias fases e versões, melhorando a qualidade do sistema.

A automação de testes, em muitos trabalhos, está baseada no desenvolvimento de programas ou scripts que testam de forma sistemática, as mesmas entradas, sempre que forem executadas.

Para isso, uma técnica bastante conhecida é a criação de programas auxiliares, que trabalham, de maneira integrada, com o sistema e capturam toda a inserção manual de dados.

Depois, sem a necessidade de intervenção humana, consegue executar os mesmos testes em todas as versões, com os mesmos dados, sendo possível obter o histórico dos resultados esperados.

Conseqüentemente, a automatização dos testes é muito eficaz em testes de regressão, pois como os clientes de teste ou programa de testes já estão desenvolvidos, basta apenas aplicá-los nas novas versões do sistema, para testar as alterações referentes a manutenções.

A maioria das falhas inseridas no sistema, que já foi testada no passado, será automaticamente detectada.

De acordo com, muitas organizações já possui algum nível de automação de testes.

O principal é sempre seguir as melhores práticas para caminhar ao longo do processo evolutivo e amadurecer o nível de automação.

Os quatro níveis de maturidade de automação descritos.
Acidental, a automação não é suportada por processos ou planejamento.

Qualquer melhoria na qualidade é considerada um acidente.

Iniciante, a documentação é criada após a automação, não há uma equipe dedicada para automação, a equipe percebe os benefícios da automação dos testes, gerentes percebem o potencial da automação, existe uma preparação para se mover em direção ao próximo nível de automação.

Intencional, gerentes estão dispostos a investir mais em automação de testes, processos são definidos e gerenciados, agendamento é preparado para automação, gravação e reutilização são predominantemente usadas, o objetivo torna-se testar com menores custo e tempo.

Automação de Testes Maduros, processos estão bem amadurecidos, planos de melhorias dos testes estão automatizados, existem pessoas dedicadas à automação, há gerenciamento separado, todo o processo de testes é efetuado através de programas ou scripts (utilização do sistema, gravação e reprodução posterior através de scripts).

A automação dos testes é muito eficaz para encontrarem falhas em projetos de desenvolvimento de software, desde que se saibam bem as características estruturais e funcionais do software, além de reduzir muito o tempo de testes de regressão.

Entretanto, existem algumas barreiras que precisam ser ultrapassadas, Custo e Tempo, Para que seja possível a automação de testes é necessário gastar recursos e tempo na criação dos clientes de teste, ou scripts que serão desenvolvidos especialmente para o projeto.

Grau de generalização, Os clientes ou scripts de testes devem ser de tal maneira genérica, que possam ser reutilizados em outros projetos.

Entretanto, não pode ser muito, senão acaba não executando o caso de teste necessário para o projeto atual.

Casos de Uso. É necessário que os principais casos de uso já estejam planejados e selecionados, e isso gasta um determinado tempo.

Algumas vezes o projeto não tem esse tempo para esperar.

Outra técnica, que também pode ser utilizada para ajudar na redução do tempo de teste através da redução dos erros nas fases iniciais do projeto é a simulação.

O processo de simulação de sistemas trata também, de muitos outros pontos da estratégia de desenvolvimento de software, desde melhorias no processo até a área de treinamento.

A simulação ajuda em vários aspectos no desenvolvimento de software, estratégia, planejamento, gerenciamento operacional, melhorias no processo, adoções de melhorias tecnológicas com menor risco, conhecimento e treinamento.

Se utilizado desde o início do processo, a simulação pode ajudar a desenvolver modelos complexos, testar determinadas técnicas, otimizar algoritmos, testar e melhorar o desempenho de interfaces entre determinados módulos.

Cada erro encontrado e corrigido pelos simuladores, ajuda a reduzir o tempo final de testes e a diminuir o tempo total do projeto.

Todos os trabalhos têm um objetivo comum que é a redução do tempo total de um projeto de desenvolvimento de sistemas, baseado no argumento que o ciclo de vida de teste (STLC) é uma parte de extrema relevância no processo todo e que precisa ser trabalhada para que se possa reduzir o tempo gasto nesta atividade.

Apesar do objetivo comum, as propostas são bem variadas, mostrando que não existe um consenso sobre como resolver o problema.

As propostas descritas foram, Testes em Paralelo.

Testes Contínuos.

Testes em Paralelo com Desenvolvimento (Planejamento e início da codificação dos testes).

Automatização de testes.

Simulação.

Não existe um consenso absoluto de qual alternativa é a melhor, mas sim, uma expectativa de redução do tempo na atividade de teste, dependendo do tipo de teste, tipo do sistema desenvolvido, valor de orçamento, quantidade de tempo e pessoas disponíveis e a capacidade técnica da equipe.

Um tema, que não foi abordado pelos autores de maneira explícita, foi o teste de integração.

De acordo com a estratégia de testes de vários autores, o teste de integração de módulos, unidades ou sistemas é de fundamental importância na atividade de teste, principalmente com o surgimento de sistemas cada vez mais integrados e complexos.

Como o foco da metodologia é testar o Sistema de Controle e suas integrações com Terminal e Unidade de Processamento, foi adotado o teste funcional, que é mais adequado com testes de integração.

Neste trabalho, está sendo discutida uma metodologia de teste de regressão, já que é aplicada a novas versões dos sistemas de processamento paralelo, e, para reduzir o tempo do projeto, é levada em consideração a existência de uma versão corrente e funcional do sistema.

Os casos de teste que serão definidos na metodologia proposta na tese são baseados em testes de regressão e teste de stress, sendo executados da menor unidade da menor parte do Sistema de Controle, passando pelas integrações com todas as partes do SC, até sua integração com o Terminal e Unidade de Processamento.

A norma IEEE829 auxilia a documentar todo o processo de testes, através de documentos padrão que devem ser elaborados ao longo do processo.

Dentre os trabalhos relacionados, pode-se classificar a solução proposta pela tese como Testes em Paralelo com Desenvolvimento, que foi apresentado pelo modelo V modificado, através do qual a fase de teste é iniciada ainda na fase de desenvolvimento do software.

Da mesma maneira, a metodologia propõe para reduzir o tempo total do projeto, iniciando os testes com o Sistema de Controle em paralelo com o desenvolvimento da Unidade de Processamento.

O capítulo 3 traz a descrição detalhada do problema de reduzir o tempo de desenvolvimento de sistemas aplicado aos sistemas de processamento paralelo.

Como foi dito no capítulo 1, este trabalho propõe uma metodologia para reduzir o tempo de projeto de desenvolvimento de sistemas de processamento paralelo.

Assim sendo, pode-se dizer que o problema que se pretende resolver está relacionado ao desenvolvimento dos componentes de um sistema de processamento paralelo, englobando as fases de especificação, programação e testes.

Para tanto, é importante definir quais são as principais características e interações de um sistema de processamento paralelo, através da descrição do modelo lógico apresentado no capítulo 1, representado através de três componentes, Terminal (T), Sistema de Controle (SC) e Unidade de Processamento (UP).

Este não é um modelo detalhado e focado na arquitetura das máquinas, mas sim um modelo de blocos lógico simplificado, que pode ser atribuído à maioria dos sistemas de processamento paralelo, independente da arquitetura, sistema operacional, hardware ou software.

Levando-se em consideração as duas arquiteturas de processamento paralelo mais relevantes apresentadas no capítulo 2, pode-se entender melhor o modelo dos três componentes.

Para ambas as arquiteturas SIMD e MIMD, o Terminal pode ser considerado como o sistema que envia as instruções e recebe os resultados do processamento maciço de dados para os processadores.

O Sistema de Controle tem a função de configurar, monitorar e iniciar o conjunto de processadores.

Toda a arquitetura descrita faz parte da Unidade de Processamento, que recebe as instruções do Sistema de Controle.

A Unidade de Processamento com arquitetura do tipo SIMD possui uma única unidade central de controle, para gerenciar todo o conjunto de processadores.

Consequentemente, cada processador executa a mesma instrução em cada ciclo de processamento.

Por outro lado, a arquitetura MIMD, mais moderna, possui na Unidade de Processamento, uma unidade de controle para cada processador.

Desta maneira é possível que cada processador execute um fluxo diferente de instruções de forma paralela.

O problema que está sendo estudado no trabalho é reduzir o tempo de desenvolvimento de novas versões de sistemas de processamento paralelo.

A primeira versão do sistema já deve ter sido concluída, e estar disponível para uso do cliente final.

Modelo Simplificado de um Sistema de Processamento Paralelo Versão Atual.

Após a conclusão da primeira versão, é iniciado o desenvolvimento da nova versão do sistema de processamento paralelo, que, devido a sua complexidade, é um projeto longo, que pode demorar muitos meses ou até alguns anos.

Neste período de desenvolvimento da nova versão, devido à diferença de complexidade entre os componentes, os mais simples, mas não menos importantes, são finalizados primeiro, como é o caso do Sistema de Controle.

Modelo Simplificado de um Sistema de Processamento Paralelo, Nova Versão.

Levando-se em consideração o modelo de um sistema de processamento paralelo e a necessidade de aplicar testes em uma nova versão deste sistema, pode-se definir como escopo do problema a ser resolvido por este trabalho, a possibilidade de testar novas versões de Sistemas de Controle, sem a necessidade das novas versões do Terminal e da Unidade de Processamento estarem concluídas.

É importante definir com mais detalhes os três componentes que constituem o modelo, para que se possa entender melhor a metodologia proposta e quais são os benefícios advindos de sua aplicação.

Para a descrição do cenário de testes, como o problema é baseado em sistemas de processamento paralelo, é necessário detalhar o modelo simplificado que servirá de base para o desenvolvimento da metodologia apresentada neste trabalho, Terminal, interface com o usuário ou administrador.

É através do Terminal, que são enviados comandos ou dados para serem processados, e são apresentados os resultados já formatados pelo Sistema de Controle.

A formatação é baseada no protocolo de comunicação entre o Terminal e o Sistema de Controle, pois o resultado gerado pelo processamento realizado pela Unidade de Processamento, pode ser enviado de acordo com outros protocolos e, portanto, formatos.

O Terminal é conectado diretamente ao Sistema de Controle, através de uma rede de controle/dados, que pode ser de vários tipos, dependendo das interfaces do sistema de processamento paralelo, incluindo redes locais como a rede Ethernet.

Para o Terminal acessar a Unidade de Processamento, ele deve implementar algumas funções básicas para enviar instruções e receber resultados, monitorar sensores, gerar alerta sobre limites excedidos na monitoração, enviar instrução para execução de tarefas e receber resultados, enviar instruções de leitura e escrita em registradores (depende da arquitetura da máquina), enviar instrução de reinicialização de dispositivos e enviar instrução de configuração dos processadores.

Uma característica do Terminal é que, como ele é a interface de acesso ao sistema, pode ser implementado inteiramente via software, não necessitando de nenhum hardware proprietário especial.

Ele pode ser um programa que esta sendo executado em uma máquina com sistema operacional Linux, por exemplo.

Sistema de Controle, dispositivo que recebe os comandos, instruções do Terminal, processa essa informação de acordo com o protocolo de comunicação com a Unidade de Processamento, e direciona para o processador ou CPU.

Por outro lado, também recebe os resultados já computados pela Unidade de Processamento, formata as informações, de acordo com o protocolo do Terminal e envia os resultados de volta ao usuário ou administrador.

O Sistema de Controle funciona como um gateway entre os usuários e a Unidade de Processamento.

Ele tem a função de configurar, inicializar e monitorar o sistema.

Como o Terminal e a Unidade de Processamento operam com dados em formatos diferentes, uma das funções do Sistema de Controle é realizar conversão de formato de dados recebidos do Terminal/Unidade de Processamento para o formato de dados a serem transmitidos para a Unidade de Processamento/Terminal.

Toda a formatação é referente aos protocolos de comunicação existente entre o Terminal e o Sistema de Controle e vice-versa.

Por exemplo, o Sistema de Controle pode ter um protocolo proprietário de comunicação com o Terminal e outro protocolo padrão tipo JTAG (Joint Test Action Group) com a Unidade de Processamento.

O Sistema de Controle tem que encaminhar as diferentes instruções para diferentes dispositivos na Unidade de Processamento.

Por exemplo, há instruções de monitoração de sensores ou de ventoinhas e instruções de execução de tarefas nos processadores.

Cada instrução deve ser encaminhada para seu respectivo dispositivo.

Outras funções importantes do Sistema de Controle estão relacionadas ao tráfego da rede que é transmitido do Terminal à Unidade de Controle.

Deve tratar a fila de pacotes de rede, perdas, duplicação, erro ou ordem trocada de pacotes na rede, através de seus protocolos de comunicação.

Unidade de Processamento, pode ser de qualquer tipo de servidor de um sistema de cluster, ou um conjunto de processadores de mercado ou com hardware proprietário.

O processador é o componente principal da UP.

Além dos processadores, também fazem parte as memórias, buffers, placas e interfaces de rede, que suportem os processadores para execução do processamento paralelo.

É responsável por todo o cálculo ou o processamento paralelo entre os vários processadores, que normalmente possuem seus próprios núcleos de memória.

Devido à grande carga de processamento, há sistemas que necessitam de um sistema de energia e refrigeração especial.

Além disso, pode ter sensores de vários tipos, como sensor de temperatura.

Uma discussão relevante para mostrar um dos principais benefícios deste trabalho é a questão dos tempos para desenvolver e testar cada um dos componentes deste modelo lógico de sistema de processamento paralelo.

Em termos dos níveis de complexidade, pode-se classificar o Terminal, implementado com funções básicas, e o Sistema de Controle, como sendo ambos mais simples que a Unidade de Processamento.

Assim, o desenvolvimento do Terminal e do Sistema de Controle, supondo que os três componentes tenham um desenvolvimento em paralelo, termina muito antes que o desenvolvimento da Unidade de Processamento.

Por exemplo, pode-se citar a experiência do projeto do supercomputador Blue Gene, onde o tempo de desenvolvimento da Unidade de Processamento é estimado em aproximadamente 3 a 4 anos e tanto o tempo de desenvolvimento do Terminal quanto o Sistema de Controle em aproximadamente 1 ano.

A Unidade de Processamento é muito mais elaborada que os outros dois componentes do sistema.

Deve executar as funções de comunicação com o Sistema de Controle, receber e armazenar (pode ser por pouco ou muito tempo) os dados, efetuar todo processamento necessário sobre os dados e comandos recebidos, reorganizar e retransmitir para o Sistema de Controle.

É através da eficiência da Unidade de Processamento que todo o conjunto é avaliado, dado sua relevância.

O Sistema de Controle e o Terminal apenas alimentam esta estrutura, de forma a interferir o menos possível nos tempos finais de processamento das informações.

A relação entre os tempos de desenvolvimento e teste do Sistema de Controle e o Terminal não é relevante para o trabalho, pois os dois são menores que o tempo de desenvolvimento e teste da Unidade de Processamento, devido à sua complexidade.

A relevância dos tempos é porque a solução proposta utiliza apenas a premissa que o tempo de desenvolvimento da Unidade de Processamento é maior que o tempo de desenvolvimento do Sistema de Controle, não importando o tempo de desenvolvimento do Terminal.

O cenário principal estudado na tese é o projeto de desenvolvimento de sistemas de processamento paralelo, que podem ser modelados de acordo com a definição dos três blocos lógicos, onde o Sistema de Controle é o componente principal nos testes.

Para que os testes tenham a qualidade esperada, é necessário testar a integração entre o Sistema de Controle e os outros componentes.

No momento em que o desenvolvimento do Sistema de Controle é finalizado, o software do Terminal pode ou não ter sido terminado.

Porém, a Unidade de Processamento, não estará concluída devido a sua complexidade.

Dado o cenário, que representa o modo de funcionamento dos componentes de um sistema de processamento paralelo, podemos sintetizar o problema resolvido neste trabalho como sendo a redução do tempo de desenvolvimento de novas versões de sistemas de processamento paralelo, de modo que eles mantenham ou superem a qualidade da versão atual do sistema de processamento paralelo.

Como existirá uma nova versão do sistema, o usuário final espera que a quantidade de problemas que pode surgir seja menor que da primeira versão, enfatizando a necessidade de testes para as novas versões.

Como já existe um sistema atual (com um Terminal, Sistema de Controle e Unidade de Processamento), que está produzindo resultados, com determinado desempenho, o problema fica mais crítico, pois além da nova versão do Sistema de Controle estar correta, deve ter um rendimento igual ou superior a versão corrente.

O problema apresentado é reduzir o tempo de desenvolvimento de novas versões de sistemas de processamento paralelo, que podem ser modelados em três componentes básicos, Terminal, Sistema de Controle e Unidade de Processamento O capítulo 4 apresenta, de forma detalhada, a solução proposta para testar sistemas de processamento paralelo com o objetivo de reduzir o tempo de desenvolvimento de novas versões destes sistemas e acelerar sua entrega.

Dado o problema descrito no capítulo 3, é proposta uma metodologia de testes para novas versões do Sistema de Controle (SC), onde o tempo total do projeto seja reduzido, acelerando a entrega do produto final para o mercado.

A solução é descrita em três etapas.

A primeira tem como objetivo apresentar a estratégia básica utilizada no processo geral de teste.

A segunda descreve uma análise de otimização de tempo, os requisitos básicos para aplicação da solução e a arquitetura da solução proposta.

A terceira etapa detalha a metodologia de teste proposta.

Após a descrição básica dos testes propostos, é necessário analisar a solução de maneira a mostrar que, se for otimizada a atividade de teste do Sistema de Controle, é realmente reduzida o tempo total de desenvolvimento do sistema.

Para que a metodologia de testes seja aplicada com sucesso, o sistema de processamento paralelo, bem como o próprio ambiente de teste, deve respeitar os requisitos mínimos para aplicação da solução, descritos neste capítulo.

A estratégia para execução dos testes propostos baseia-se na técnica de testes em paralelo com o desenvolvimento do sistema, já que os componentes do modelo de sistema de processamento paralelo são desenvolvidos de modo independente no que diz respeito às fases de especificação, projeto e codificação, dada à natureza de cada componente.

Apesar da modularidade dos componentes, a solução deve tratar das interfaces entre eles, que são planejadas e desenvolvidas com a ajuda de todas as equipes, devido à grande troca de informações que é necessária para seu desenvolvimento.

Através da execução da atividade de teste (incluindo testes de integração) do novo Sistema de Controle simultaneamente com o desenvolvimento da nova versão da Unidade de Processamento, pode-se reduzir o tempo total de um projeto de um sistema de processamento paralelo, como será mostrado neste capítulo.

Conseqüentemente, a proposta para resolução do problema, é uma metodologia de teste para uma nova versão do Sistema de Controle de um sistema de processamento paralelo, sem a existência de uma nova versão da Unidade de Processamento.

Não é relevante para a metodologia se o componente do Terminal (T) já está finalizado ou não.

Caso já esteja, é simplesmente utilizado no teste.

Caso não esteja, a solução prevê que seja necessário desenvolver um componente simples para cumprir as funções básicas do Terminal, para exercitar o Sistema de Controle e algumas funções da Unidade de Processamento (UP).

Para que a solução seja robusta, a metodologia deve incluir principalmente testes de integração entre os componentes do modelo de sistema de processamento paralelo, isto é, deve abranger testes entre o Terminal e o Sistema de Controle, e entre o Sistema de Controle e a Unidade de Processamento.

Como já foi mencionado no capítulo 3, o tempo de desenvolvimento da Unidade de Processamento é muito maior que o tempo de desenvolvimento dos outros dois componentes, devido à sua complexidade.

Assim, a metodologia de teste que é aplicada quando a nova versão do Sistema de Controle é concluída, não encontra problemas para executar testes de integração com o Terminal.

Porém, para a execução dos testes junto com a nova Unidade de Processamento, é necessário um atraso nos testes para que a Unidade de Processamento seja concluída, já que devido à sua complexidade, seu desenvolvimento leva muito mais tempo.

A proposta da metodologia de testes é resolver a questão de que o teste da nova versão do Sistema de Controle deve esperar a nova versão da Unidade de Processamento ser finalizada, antes de testá-los de forma integrada.

A solução é utilizar a Unidade de Processamento corrente para testes em conjunto com a nova versão do Sistema de Controle.

Ao conectar a nova versão do Sistema de Controle à versão corrente da Unidade de Processamento, podem-se executar todos os testes de integração entre eles, e economizar esse tempo no final do projeto.

Nós próximos itens, serão discutidos os requisitos para aplicação da solução proposta, um modelo de otimização de tempo gasto no desenvolvimento de sistemas e a arquitetura da solução, a descrição da metodologia de testes proposta e algumas considerações sobre esta metodologia.

Os requisitos mínimos necessários para aplicação da solução em um cenário como o descrito no capítulo 3, são, O planejamento de todo o processo dos testes, mesmo que sem os detalhes, deve ser feito em primeiro lugar, levando-se em consideração o tempo total gasto em cada etapa e qual o objetivo do teste.

O sistema de processamento paralelo tem que ser modelado de acordo com os três componentes descritos no capítulo 3, Terminal, Sistema de Controle e Unidade de Processamento.

A complexidade, os recursos e o tempo gasto no processo de teste devem ser proporcionais à previsão do tempo do término da Unidade de Processamento.

Se a UP terminar em um curto intervalo de tempo, os testes devem ser mais simples para acabar antes da primeira versão da unidade para testes.

Se os testes não forem suficientes devido ao tempo para manter a qualidade do sistema, deve-se executar o restante após a conclusão da UP, mas sem um benefício importante que é a economia máxima no tempo de teste.

O restante do tempo gasto é somado ao tempo total do projeto.

Ele é menor que o tempo gasto se todos os testes fossem feitos seqüencialmente ao desenvolvimento, mas não é o melhor caso, onde todos os testes são executados em paralelo.

Se toda a nova estrutura estiver disponível, é melhor usar todos os três novos componentes, e testá-las em conjunto.

Os testes devem gerar algum dado comparativo entre o antigo e o novo Sistema de Controle, para que seja medida a eficiência do novo sistema.

Caso seja provado que, para um ou mais parâmetros da análise, a nova estrutura é menos eficiente, como a Unidade de Processamento ainda não está terminada, ainda há algum tempo para tentar melhorar Unidade de Processamento em função dos parâmetros analisados.

A interface da nova Unidade de Processamento com o Sistema de Controle deve ser compatível com a interface da Unidade de Processamento corrente.

É necessário que o novo Sistema de Controle seja capaz de enviar comandos para a antiga estrutura, sem muitas ou com nenhuma alteração no software e/ou hardware.

Verificar se a compatibilização da nova versão do Sistema de Controle e a versão corrente da Unidade de Processamento tem algum custo.

Por exemplo, se para compatibilizar as versões é necessário desenvolver alguma interface de hardware ou software, ou comprar algum tipo de equipamento já existente.

Estimar se o custo da compatibilização de versões não é maior que o ganho em desenvolver o sistema em um tempo menor.

Deve existir uma documentação mínima do novo Sistema de Controle, descrevendo suas funcionalidades e protocolos de comunicação, para servir de base no processo de teste.

O software, que é executado no Terminal, pode ou não existir previamente.

Caso já exista, é parte dos requisitos testar o novo pacote de software do Terminal e o novo Sistema de Controle com o novo pacote de software do Terminal.

Caso contrário, o código do Terminal não é parte dos requisitos da solução, mas sim, seu teste, é um dos resultados gerados no processo.

A proposta apresentada para testes de uma nova versão de um Sistema de Controle, sem que a Unidade de Processamento esteja finalizada, é uma forma de redução do tempo total do projeto.

Contudo, há algumas considerações que precisam ser analisadas, Ajuste de parâmetros de desempenho, como a Unidade de Processamento, que o teste está usando, é a versão corrente, é necessário cuidado ao configurar certos valores de desempenho que podem não ser otimizados para a próxima versão, como por exemplo, os tempos de retransmissão.

Software do Terminal, uma parte do trabalho de desenvolvimento do software do Terminal não será aproveitada, pois são funções específicas associadas à Unidade de Processamento corrente.

Então é necessária uma avaliação de esforço para não gastar tempo e recursos demais em código que não será aproveitado.

Além disso, caso o software do Terminal não seja desenvolvido pensando em reutilização de código para a nova versão, todo o trabalho pode não ser aproveitado.

Tempo de teste, o planejamento deve ser feito para que todo o processo de teste gaste apenas um tempo similar ao tempo de desenvolvimento da Unidade de Processamento e os testes de integração.

Consumo de recursos, o trabalho é focado na execução de testes em paralelo com o desenvolvimento para reduzir o tempo total de projeto, e não para diminuir os custos do projeto.

Todos os recursos que seriam necessários em um projeto com desenvolvimento serial são, também, necessários em um projeto com a estratégia de paralelismo de atividades.

A redução que pode ocorrer, em termos de investimentos, é que se já existir uma equipe especializada em testes ou a empresa possuir algum equipamento que está ocioso, eles podem ser aproveitados mais cedo, aumentando sua produtividade.

Através da análise entre testes executados após o desenvolvimento do sistema de processamento paralelo do sistema de processamento paralelo e testes executados em paralelo com o desenvolvimento, pode-se determinar que a paralelização dos testes da nova versão do Sistema de Controle contribui para a redução geral do tempo do projeto.

Em seguida, é feita uma avaliação dos tempos envolvidos no projeto para mostrar a otimização, levando em consideração os tempos de desenvolvimento e teste Td,t e o tempo t referente à integração dos três componentes, Terminal, Sistema de Controle e Unidade de Processamento.

O primeiro teste foi isolado, com cada componente separadamente.

T = tempo total de um projeto.

Td,t(u)=tempo gasto no desenvolvimento e teste da Unidade de Processamento.

Td,t(s)=tempo gasto no desenvolvimento e teste do Sistema de Controle.

Td,t(t)=tempo gasto no desenvolvimento e teste do software do Terminal.

Este tempo tem um valor mínimo, mas pode crescer muito, à medida que as aplicações do usuário vão evoluindo.

Assim, toma-se o Td,t(t) como sendo o tempo para gerar uma aplicação que exercite as funcionalidades do Sistema de Controle e uma biblioteca básica de funções para acessar o SC.

T(t,s)=tempo gasto para testar a integração entre o software do Terminal e o Sistema de Controle.

T(s,u)=tempo gasto para testar a integração do Sistema de Controle e a Unidade de Processamento.

T(t,s,u)=tempo gasto para testar a integração do software do Terminal com o Sistema de Controle e a Unidade de Processamento.

T(i)=tempo de desenvolvimento de interface entre nova versão do SC e atual versão da UP.

Uma premissa básica que se pode assumir é que o tempo de desenvolvimento e teste da Unidade de Processamento é maior que o tempo gasto com os outros dois componentes do modelo de sistema processamento paralelo, devido a sua complexidade.

Então, tem-se as relações, Td,t(t) << Td,t(u) e Td,t(s) << Td,t(u).

O caso mais simples e menos eficiente ocorre quando cada uma das etapas de desenvolvimento é feita em seqüência.

O projeto é iniciado com o desenvolvimento e teste da Unidade de Processamento.

Em seguida, são realizados o desenvolvimento e o teste do Sistema de Controle e do software do Terminal.

Depois, são testadas as integrações entre o software do Terminal e o Sistema de Controle, o Sistema de Controle e a Unidade de Processamento, e para finalizar, um teste geral com as três partes, com o tempo total igual a T1 (T1 = Td,t(u)+ Td,t(s)+ Td,t(t)+t(t,s)+ t(s,u)+ t(t,s,u)).

Em geral, neste tipo de abordagem seqüencial, não há restrições quanto à ordem do desenvolvimento, já que são feitos e testados de forma separada e não paralela.

Em um nível maior de otimização, ou primeiro nível de otimização, pode-se encontrar uma distribuição de tarefas mais eficiente que o seqüencial T1, onde são paralelizados os três componentes lógicos para reduzir o tempo total.

Este é o método mais comum nos projetos de sistemas em geral, já que o tempo final T2 (T2 = Td,t(u)+ t(s,u)+ t(t,s,u)) é menor que T1, e o produto se torna disponível mais rapidamente.

Neste tipo de abordagem, o desenvolvimento e teste de cada um dos componentes são executados em paralelo.

Como já foi explicado neste capítulo, o tempo é maior para a Unidade de Processamento, então o tempo inicial para desenvolver e testar os três componentes é Td,t(u), já que Td,t(t) << Td,t(u) e Td,t(s) << Td,t(u).

A segunda etapa é referente ao tempo de teste de integração.

O primeiro teste de integração é realizado entre o Terminal e o Sistema de Controle.

O segundo teste é entre a Unidade de Processamento e o Sistema de Controle e o outro teste é geral, entre os três componentes.

É interessante notar que os testes de integração envolvendo todos componentes são iniciados quando o desenvolvimento e teste de cada componente é terminado.

Complexidade do desenvolvimento da Unidade de Processamento.

Então, o t(t,s) está embutido no Td,t(u), pois essas tarefas estão ocorrendo em paralelo.

A última e maior otimização, ou segundo nível de otimização, é uma das contribuições de pesquisa deste trabalho.

O processo inicial é semelhante ao anterior, com o desenvolvimento e teste dos componentes em paralelo.

Para minimizar o tempo deste projeto T3 (T3 = Td,t(u)+ t(t,s,u)) em relação a T2, como descrito na estratégia de testes proposta pela tese, é utilizada a Unidade de Processamento corrente, para testar a integração entre a Unidade de Processamento e o Sistema de Controle, antes que a nova Unidade de Processamento esteja finalizada.

Desta maneira, pode-se executar esta tarefa em paralelo com o tempo de desenvolvimento e teste da nova Unidade de Processamento, reduzindo o tempo de projeto T3.

A metodologia leva em consideração o tempo e custo gasto em t(i), que é o tempo para desenvolvimento de uma interface entre a nova versão do SC e a versão corrente da UP.

Esse tempo e custo devem ser avaliados na etapa de planejamento para verificar a viabilidade do projeto.

Caso o tempo para criação da interface seja muito elevado em relação ao tempo de economia que a metodologia irá economizar no tempo total do projeto, a aplicação da metodologia pode ficar comprometida.

Da mesma maneira é necessária uma análise dos custos, pois caso seja muito elevado em relação aos ganhos obtidos com a antecipação dos testes, a metodologia não deve ser aplicada.

De acordo com os tempos de otimização apresentados, pode-se facilmente identificar que a solução proposta T3 é a que mais reduz o tempo total de projeto.

Analisando os três tempos, pode-se concluir que T1 > T2 > T3.

Dado a descrição da metodologia de testes para novas versões do Sistema de Controle, sem que a nova versão da Unidade de Processamento esteja finalizada, é proposta uma arquitetura mista de teste, entre as versões atuais e novas do sistema processamento paralelo.

Arquitetura da Solução Proposta.

A nova versão do Sistema de Controle deve ser conectada a atual versão da Unidade de Processamento, para que o Terminal possa enviar instruções e dados para serem processados na Unidade de Processamento.

É fundamental que seja possível definir um mapeamento entre os protocolos de comunicação do SC e UP, das duas versões, caso não sejam os mesmos.

Para ajudar na conexão entre o Sistema de Controle e a Unidade de Processamento, uma interface, que pode ser hardware e/ou software, pode ser necessária de modo que os sinais de controle enviados pelo SC atinjam os processadores e outros componentes da Unidade de Processamento corretamente.

Neste cenário, os comandos/instruções 11 ou dados que são trocados (enviados ou recebidos) entre o Terminal, Sistema de Controle e a Unidade de Processamento são bem conhecidos, pois estão definidos na especificação dos componentes.

Todos os componentes da versão atual do sistema são bem conhecidos, visto que já passaram por testes e estão sendo usados pelo cliente final.

Desta maneira, a equipe do projeto conhece seu comportamento na prática, com o sistema em operação diariamente, e pode afirmar com precisão os seus resultados práticos, principalmente seu desempenho.

Isto é, a equipe tem um conhecimento alto sobre o funcionamento da versão atual da Unidade de Processamento, sabendo como ela vai se comportar, dado uma determinada instrução.

Quando conectada a nova versão do Sistema de Controle junto a uma Unidade de Processamento bem conhecida, a equipe de teste sabe qual deve ser o comportamento da UP, quando submetida uma determinada instrução.

A instrução deve ser disparada pelo Terminal, passando pelo novo SC e sendo processada pela atual UP.

Como o valor de retorno da instrução e o tempo para sua execução já é conhecido para a versão atual, é possível comparar os dois ambientes.

Por exemplo, para um comando A enviado pelo Terminal, a Unidade de Processamento deverá piscar uma seqüência de LEDs em uma placa específica.

Caso o comando A seja executado com sucesso, pode-se garantir que todo o caminho pelo qual o comando trafegou, desde o recebimento pelo Sistema de Controle, passando pelo tratamento dos pacotes de rede que são enviados para a UP, até seu recebimento e a interpretação dos comandos está de acordo com o esperado.

Se não for executado com sucesso, sabe-se que existe alguma falha na nova versão do Sistema de Controle, ou no software do Terminal.

Os testes executados dessa maneira devem ser criados em conjunto com os desenvolvedores e engenheiros do Sistema de Controle e alguém da equipe de desenvolvimento da Unidade de Processamento, que sabe exatamente, quais são os casos de testes mais importantes e que irá exercitar quais partes do Sistema de Controle e Unidade de Processamento.

Além disso, com o auxílio dos engenheiros e a especificação do Sistema de Controle, pode-se avaliar se o conjunto de testes propostos é suficiente para o teste do sistema.

Os testes entre o software do Terminal e o Sistema de Controle ou a Unidade de Processamento são tratados como um subconjunto dos testes do Sistema de Controle, já que a função principal do Terminal é interagir com estes componentes, através do envio de instruções e dados e o recebimento dos resultados.

Não é possível a execução de nenhum caso de teste sem que o Terminal esteja envolvido na interação entre a equipe de teste (testadores) e o sistema.

A solução proposta leva esse fato em consideração e também prepara casos de teste, com o apoio dos responsáveis pelo Sistema de Controle e a Unidade de Processamento, para testar o software do Terminal.

Baseado no conhecimento de experientes engenheiros na área de sistemas de processamento paralelo, especialistas em teste destes sistemas e em testes já executados em outros sistemas de processamento paralelo, foi elaborada uma lista de casos de teste que são fundamentais para tratar o Sistema de Controle e suas interfaces com Terminal e Unidade de Processamento.

Os casos de teste fazem parte da metodologia proposta e são apresentados nos próximos itens.

É importante ratificar que todos os casos de teste que são apresentados neste capítulo levam em consideração esta arquitetura, onde a nova versão do Sistema de Controle é conectada à versão atual da Unidade de Processamento.

O processo de testes corresponde a uma seqüência de tarefas que deve ser executada em uma determinada ordem de prioridade e em um tempo específico.

Deve ser baseado na experiência da versão corrente da máquina.

A quantidade e o nível de detalhes dos testes devem ser avaliados pelos desenvolvedores do Sistema de Controle e baseados na sua especificação.

A metodologia aqui proposta baseia-se no teste das funcionalidades do Sistema de Controle tomando, como referência, a sua especificação, além da sua integração com os demais componentes.

Sendo assim, os testes funcionais são mais utilizados que os testes estruturais, ao longo da descrição da metodologia.

Os próprios desenvolvedores já fazem uma primeira análise da estrutura dos sistemas com o objetivo de testar cada parte isoladamente.

A metodologia de testes proposta é dividida em quatro etapas bem delimitadas, que devem fazer parte do teste da nova versão de um Sistema de Controle em sistemas de processamento paralelo.

Fluxo Simplificado de Atividades do Processo de Teste.

Mostra a relação entre as quatro etapas do processo de teste.

É iniciado com o planejamento, depois segue a etapa de adequação do software do Terminal.

Em seguida, a execução do teste é realizada, pode-se voltar a adequação do Terminal, se algum problema é encontrado na sua execução.

Quando o teste é finalizado, os resultados são avaliados perante a especificação e o teste pode, estar correto e o processo termina, ou pode ser encontrado um erro.

Então, é verificado o motivo do erro, que pode estar no Sistema de Controle ou no software do Terminal.

O erro é corrigido e é realizada a execução do teste, até que o resultado esteja de acordo com a especificação.

Caso o erro persista e não seja possível alcançar o resultado esperado, há três possibilidades, A documentação de especificação está errada e deve ser corrigida para o mesmo valor que o teste está apresentado como resultado.

O resultado está incorreto perante a especificação e, tanto o Sistema de Controle como Software do Terminal já foram verificados e nenhum erro foi encontrado.

Neste caso, a especificação do sistema pode ter sido feita de maneira incompatível com a tecnologia ou conhecimento dos arquitetos do sistema, e não são alcançáveis.

Nesse caso, ou são alterados a especificação e as expectativas sobre este item do projeto, ou se investe mais tempo e recurso para refazer o Sistema de Controle.

O caso de teste proposto não pôde ser executado com sucesso, devido a algum problema de incompatibilidade entre a nova versão do Sistema de Controle e a versão corrente da Unidade de Processamento.

Nesse caso é preciso esperar a nova versão da UP ser concluída para, então, executar este caso de teste.

A primeira etapa é o planejamento.

Inicialmente, deve ser especificada uma lista dos testes que se pretende executar, do ponto de vista funcional e de desempenho que, para o Sistema de Controle, são muito importantes para validar sua operacionalidade.

Adequar essa lista com o tempo disponível também é uma tarefa executada nesta etapa.

Além disso, a viabilidade do projeto deve ser avaliada nesta etapa, através da análise dos requisitos mínimos para a aplicação da metodologia.

Por exemplo, verificar se a nova versão do Sistema de Controle é compatível com a versão corrente da Unidade de Processamento.

A segunda etapa deve focar o pacote de software do Terminal.

Seu desenvolvimento pode ter sido iniciado junto com os outros dois componentes, SC e UP.

Nesse caso, é necessária uma análise para verificar se as funcionalidades mínimas para os testes já estão implementadas ou se é necessário adequá-las para o processo de testes.

Caso ainda não tenha sido codificado (essa é uma decisão inicial dos gestores do projeto), esse é o momento para iniciar seu desenvolvimento.

Devem ser implementadas, pelo menos, as principais funcionalidades descritas nos testes.

Nesta fase, já com o conhecimento do pacote de software Terminal, é necessária uma análise para ajustar o planejamento, caso algum teste previsto precise de muito esforço de programação, não compatível com o tempo do projeto.

A terceira etapa é a de execução dos testes, que deve seguir o planejamento elaborado na primeira etapa.

Se for necessária alguma alteração no planejamento dos testes, deve ser avaliado o custo/beneficio (tempo, recurso perante o melhor resultado gerado do novo teste) da mudança.

A quarta e última etapa é a análise dos resultados dos testes.

Os resultados de cada teste executado devem ser avaliados, verificando-se se são consistentes ou não com esperado.

É preciso verificar se nenhuma mudança no teste, ou no próprio Sistema de Controle (mesmo que futuramente), é necessária.

Um exemplo pode ser a alteração de algum tempo de espera (timeout) para melhorar o desempenho do equipamento.

Esta última etapa tem a função de decidir, baseado na especificação, se o teste pode ser finalizado ou não.

Caso o teste não obtenha um resultado esperado, é feito um estudo para identificar a origem do problema, software do Terminal e/ou Sistema de Controle.

Feito isso, o respectivo erro é corrigido e o teste volta para a etapa de execução (Etapa 3).

A metodologia aqui proposta é compatível com os padrões estabelecidos pela norma IEEE 829 (IEEE829, 98) para documentar a atividade de teste.

A adequação é baseada em um conjunto mínimo de informações que devem ser registradas empregando-se a metodologia para execução dos testes.

A norma descreve mais documentos e prevê a documentação de mais itens relacionados aos testes que o estipulado na metodologia.

Esta simplificação deve-se às limitações de tempo as quais a solução está restrita, como apresentado pelos requisitos da solução.

Apesar disso, apresenta o mapeamento das principais tarefas entre a metodologia e a norma IEEE 829.

O planejamento é diretamente dependente da estimativa de tempo que deve ser feita no início desta atividade.

Além disso, de acordo com a norma IEEE829, devem ser definidos nesta etapa, Abordagem, Este item já está definido na metodologia, como sendo o teste em paralelo com as atividades de desenvolvimento.

Escopo, Este item já está definido como sendo testes da nova versão do Sistema de Controle, sendo que a nova versão da Unidade de Processamento não está finalizada.

O software do Terminal também faz parte da metodologia de testes, mas é tratado na segunda etapa da metodologia.

Recursos, A equipe responsável pelos testes deve ter conhecimento em alguns assuntos, as versões nova e atual do Sistema de Controle, as versões nova e atual da Unidade de Processamento e a nova versão do Terminal.

Além disso, é necessário ter conhecimento em programação, para o desenvolvimento do software do Terminal, caso seja necessário.

Os equipamentos, que devem estar disponíveis são, o novo Sistema de Controle e a atual Unidade de Processamento e o ambiente para desenvolvimento do Terminal.

Cronograma de teste, O cronograma de execução dos casos de teste é definido a partir do tempo disponível para toda a atividade dos testes.

A metodologia orienta em qual ordem o teste deve ser executado.

O período de teste pode variar muito de projeto a projeto (de desenvolvimento de sistemas de processamento paralelo), e depende, diretamente, da diferença entre o tempo de desenvolvimento do Sistema de Controle e da Unidade de Processamento.

Esse é o tempo máximo que todo o processo de testes deve utilizar.

Após algum tempo depois que o projeto de desenvolvimento do sistema de processamento paralelo foi iniciado, é finalizado o desenvolvimento do Sistema de Controle.

Estimativa de Tempo para Atividade de Teste.

Assim, o tempo total para a aplicação das quatro etapas da metodologia de testes proposta é bem definido e não pode ser prolongado, a não ser que a conclusão do desenvolvimento da Unidade de Processamento seja atrasada.

Como o tempo é restrito, não é necessário um planejamento complexo para a execução dos testes.

O documento principal é uma lista dos principais casos de testes, com a descrição do teste, seus objetivos e o resultado esperado, de acordo com a especificação.

Lista de Teste Proposto para Verificar o Novo Sistema de Controle.

Esse planejamento mínimo não poderá despender muito tempo, pois o projeto deste processo de testes não deve ser muito longo em relação ao tempo total para execução dos testes.

Por outro lado, deve ser um guia, para que os testes não percam o foco e consigam ser executados de maneira adequada dentro do tempo previsto, de maneira a não comprometer a qualidade da nova versão da Unidade de Processamento.

Analisar se os recursos necessários para todos os testes estão ou estarão disponíveis nas datas previstas faz parte, também, da etapa do planejamento.

Esses recursos incluem placas, cabos especiais, fontes de alimentação, tempo de técnicos e programadores, servidores, processadores, hardwares proprietários, salas e laboratórios.

O processo de teste deve utilizar toda a documentação já existente sobre o Sistema de Controle, como visão geral do novo sistema, descritivo das funcionalidades, descritivo dos protocolos, descritivo sobre os registradores mais operações e sua especificação.

Toda esta documentação deve alimentar o planejamento dos testes e um dos produtos resultantes da atividade de teste deve ser a validação de todos esses documentos, principalmente a especificação da nova versão do Sistema de Controle.

Para testar a nova versão do Sistema de Controle, que deve estar pronto e funcionando, enquanto o restante dos componentes se encontra, ainda, em desenvolvimento, foi definida uma classificação mínima, baseada em experiências passadas da equipe do projeto do supercomputador Blue Gene da IBM Research (IBM, 99) em testes para garantir a qualidade e validação do Sistema de Controle.
Teste apenas do Sistema de Controle (TSC), testar se o próprio Sistema de Controle está de acordo com a sua especificação técnica, sem a necessidade de conexão à Unidade de Processamento.

Esta deve ser a primeira parte dos testes.

A biblioteca de software do Terminal é a principal ferramenta para testar o sistema.

Como subconjuntos do teste básico do Sistema de Controle, têm-se, a-Teste de Rede/Protocolo (TR), verificar a comunicação básica entre o Terminal e Sistema de Controle, e o Sistema de Controle e a Unidade de Processamento, analisando se os protocolos de comunicação estão de acordo com a especificação.

Teste Funcional (TF), verificar todas as principais funcionalidades do Sistema de Controle, como leitura e escrita de registradores.

Teste de Desempenho (TD), comparar alguns parâmetros de operação das versões antiga e nova do Sistema de Controle.

Como exemplo, pode-se comparar o tempo gasto na leitura e escrita de registradores no caso das duas versões do Sistema de Controle.

Teste de integração (TI), testar as integrações entre o Terminal e o SC e o SC e a Unidade de Processamento e verificar se as interfaces estão funcionando de acordo com a especificação.

Todos estes testes podem ser categorizados como um tipo de teste de regressão (que trata de erros inseridos em novas versões dos sistemas, devido a manutenções ou melhorias), pois testam uma nova versão do Sistema de Controle.

A duração e a quantidade de testes serão proporcionais ao tempo entre o final do desenvolvimento do Sistema de Controle e o final do desenvolvimento/testes da Unidade de Processamento.

Este tempo pode ser variável, pois não há precisão absoluta na previsão de tempo de desenvolvimento da Unidade de Processamento.

O processo de testes do Sistema de Controle definido pela metodologia está baseado na estratégia bottom-up, apresentada no capítulo 2, pois se inicia com testes em componentes menores, e vai aumentando a complexidade, agrupando componentes até que todo o sistema tenha sido homologado.

Em uma abstração do teste do projeto completo, o menor componente são os três blocos separados, Terminal, Sistema de Controle e Unidade de Processamento.

Depois deve ser testada, a integração dos componentes, Teste do Terminal com o Sistema de Controle.

Teste do Terminal, sistema de Controle e Unidade de Processamento.

Os projetos de desenvolvimento de sistema de processamento paralelo são, normalmente, complexos.

Se fosse optado por testar direto o sistema como um todo, poderia encontrar problemas, cuja origem (a qual ou a quais componentes pertencem) seria difícil de identificar.

Por exemplo, se for enviado um comando para a Unidade de Processamento, que deve processar 8 bytes e responder com os mesmos 8 bytes, e não se obtiver uma resposta, o problema pode ser do software do Terminal que não está enviando ou tratando dados de forma adequada, ou o problema pode ser do pacote que está se perdendo no Sistema de Controle ou sendo enviado para algum lugar errado, ou pode ser um problema da própria Unidade de Processamento.

A conexão entre a nova versão do Sistema de Controle e a versão corrente da Unidade de Processamento é um requisito importante para o sucesso da metodologia proposta.

Para analisar com mais detalhes esta integração, são definidos os sinais dos dois componentes, Sistema de Controle e Unidade de Processamento, e os sinais de uma possível interface entre eles, Os = Sinais de saída da nova versão do Sistema de Controle.

Is = Sinais de entrada da nova versão do Sistema de Controle.

Ou = Sinais de saída da versão corrente da Unidade de Processamento.

Iu = Sinais de entrada da versão corrente da Unidade de Processamento.

Ii,s = Sinais de entrada da Interface com a nova versão do Sistema de Controle.

Oi,s = Sinais de saída da Interface com a nova versão do Sistema de Controle.

Ii,u = Sinais de entrada da Interface com a versão corrente da Unidade de Processamento.

Oi,u = Sinais de saída da Interface com a versão corrente da Unidade de Processamento.

Para conectar o novo Sistema de Controle à Unidade de Processamento corrente, é necessário encontrar os padrões ou sinais comuns aos dois sistemas, o novo e o corrente (Os I e Is Ou).

Para elaborar essa solução, devem ser conhecidas bem as duas versões, e analisados os sinais da versão corrente Iu e Ou, versus os sinais da nova versão Is e Os.

Deste estudo, podem resultar três possibilidades. Os sinais de saída do Sistema de Controle, Os, são compatíveis entre as duas versões da Unidade de Processamento de forma direta, sem a necessidade de um novo hardware ou software para tratar, ou codificar os sinais que passam do Sistema de Controle Os para a Unidade de Processamento Iu.

Este é o caso menos complicado, onde os sinais são simplesmente enviados e recebidos, sem nenhum tipo de conversão.

Por exemplo, através de um cabo, respeitando apenas a regra Os, Iu e Ou, Is. Os sinais de saída do Sistema de Controle, Os, são compatíveis entre as duas versões de forma indireta, com a necessidade de um novo hardware ou software para tratar, ou codificar os sinais de controle.

Por exemplo, um dos sinais de controle pode ser usado para alimentar uma parte do circuito da Unidade de Processamento.

Se a nova versão tiver essa tensão configurada com valores diferentes da versão corrente, é preciso conectar o sinal do novo Sistema de Controle a um conversor, e depois do conversor, até a versão corrente da Unidade de Processamento.

Os sinais de saída do Sistema de Controle são incompatíveis entre as duas versões.

Neste caso, apenas os testes do próprio Sistema de Controle podem ser executados, os testes de integração entre o Sistema de Controle e a Unidade de Processamento serão feitos apenas quando a nova versão da Unidade de Processamento estiver concluída, sendo necessário um tempo muito maior para a fase de testes do sistema.

Conexão entre o Novo Sistema de Controle e a Unidade de Processamento Corrente.

O próximo passo é de fundamental importância para o projeto, pois trata-se do desenvolvimento/adequação de um software, que pode, também, conter erros.

Assim, esta fase deve ser feita da maneira mais simples possível, testando, em primeiro lugar, a própria camada de software, antes de utilizá-la junto à Unidade de Processamento.

No caso do projeto de desenvolvimento da nova versão do supercomputador Blue Gene, por exemplo, não existia nenhuma versão nova de software do Terminal, apenas a versão corrente.

Desta maneira, foram desenvolvidas todas as principais funções de acesso ao Sistema de Controle.

Com base nessa experiência, pode-se estimar que o tempo gasto nesta etapa foi de 50% do tempo total do teste.

Além disso, depois que a primeira versão do software foi desenvolvida, a cada teste executado, a camada de software era melhorada ou corrigida.

Como já foi mencionado anteriormente, o pacote de software do Terminal pode ser um requisito para os testes, caso ele já tenha sido desenvolvido.

Neste caso, é necessário avaliar se todas as funções básicas descritas na especificação estão presentes na aplicação do Terminal.

Por outro lado, se ainda não existir, deverá ser desenvolvida uma camada de software que atenda ao planejamento descrito no início deste capítulo.

No mínimo, é preciso criar uma API (Application Programming Interface) ou biblioteca básica de comunicação entre o Terminal e o Sistema de Controle, e uma aplicação de testes que utiliza a API para acessar as funções principais do Sistema de Controle.

Mostra um resumo das principais funções que a API de comunicação deve possuir para a atividade de teste.

Principais Funções da API Básica de Comunicação do Terminal.

Uma consideração importante, é que, no desenvolvimento deste software, é recomendável verificar como a antiga aplicação do Terminal foi feita e seguir o mesmo modelo, padrões e linguagem, desde que não atrapalhe o ciclo evolutivo do produto.

Isso facilitará a migração para a nova camada de aplicação, que será desenvolvida no futuro.

Caso o planejamento, adequação ou criação do software do Terminal tenha sido concluído com sucesso, a execução dos testes é a fase mais simples.

Deverá ser apenas um trabalho de paciência e comprometimento com o planejamento, com o disparo de cada teste e o registro dos resultados para serem analisados.

FPGA (Field-Programmable Gate Array), Um FPGA é um dispositivo semicondutor muito utilizado para o processamento de informações digitais.

Ele pode ser programado de acordo com as aplicações do usuário.

Ele é composto por três componentes, blocos de entrada e saída, blocos lógicos configuráveis (Portas Lógicas AND, OR entre outras) e chaves de interconexão.

O FPGA é um chip que suporta a implementação de circuitos lógicos relativamente grandes.

Consiste em centenas ou milhares de células lógicos configuráveis contidos em um único circuito integrado, que se comunicam através de um tipo de roteamento interno.

Nesta etapa, também é feita uma análise dos resultados dos testes, com o intuito de validar cada um deles.

Caso o resultado seja o esperado, a análise não precisa ser aprofundada.

Caso o resultado seja algum valor inesperado, é preciso entender a diferença e verificar o motivo, junto aos especialistas responsáveis.

Os testes devem ser executados na ordem em que foram planejados, apesar de, em certos casos, poder-se alterar a sua seqüência por algum problema em algum teste anterior.

A execução dos testes não precisa ser feita, necessariamente, pelo desenvolvedor do Sistema de Controle.

Os especialistas devem participar da etapa de planejamento e análise dos resultados, e supervisionar a execução dos testes.

A metodologia do processo para testar uma nova versão do Sistema de Controle, utilizando-se uma versão corrente da Unidade de Processamento, é baseada na execução de um determinado conjunto de testes, que são descritos neste item.

Antes de detalhar cada caso de teste com suas características próprias, há alguns parâmetros comuns, que mostram uma descrição mais quantitativa sobre eles.

De acordo com a norma IEEE 829, a descrição dos resultados dos testes, deve apresentar alguns parâmetros, Tempo de realização do teste.

Número médio de pacotes transmitidos (transmissão + recepção) por teste.

Número de vezes que o teste foi realizado.

Número de vezes que o teste deu o resultado esperado.

A relação de casos de teste deve ser executada em uma determinada ordem, que de acordo com a estratégia de teste bottom-up executa os testes do menor componente, através de integração entre os componentes, até o sistema completo.

A ordem que deve ser estabelecida entre os testes é, 1) Teste básico do protocolo entre o Sistema de Controle e o Terminal.

Teste do Analisador de Rede entre o Sistema de Controle e o Terminal.

Teste de Registradores do Sistema de Controle.

Teste do Refletor do Sistema de Controle.

Teste da variação do MTU da rede entre o Terminal e o Sistema de Controle.

Teste de Stress.

Teste de Registrador da Unidade de Processamento.

Teste Geral da Unidade de Processamento.

A abrangência dos casos de testes e como se relacionam com os componentes pode ser observada.

Abrangência dos Casos de Teste.

Testar se o(s) protocolo(s) entre o Sistema de Controle e o Terminal está(ão) de acordo com a especificação, para uma quantidade reduzida de pacotes, como dezena deles.

Este número pode variar de acordo com os protocolos do sistema.

É necessário avaliar o protocolo e estimar uma referência da quantidade de pacotes que precisam ser analisados para verificar se está correto.

Como é uma atividade manual, também não pode ser uma quantidade muito elevada.

Descrição detalhada, este teste deve estar focado apenas no protocolo.

Não é necessário analisar centenas ou milhares de pacotes.

Algumas dezenas já são suficientes, pois através deles é possível realizar uma análise manual para verificar se está de acordo com a especificação.

Na troca de pacotes entre o Sistema de Controle e o Terminal, deve ser registrado, pacote a pacote, tudo que está trafegando.

Desta maneira, são mostrados todos os campos do cabeçalho de forma simplificada, para validar seu conteúdo junto à especificação do Sistema de Controle.

Através da leitura dos pacotes, é possível inferir se há algum erro na sua montagem ou no processamento.

Caso algum problema seja encontrado, é preciso corrigi-lo no Sistema de Controle ou na Unidade de Processamento.

Como o protocolo é baseado em stream, onde é garantida a entrega dos pacotes na ordem, como o TCP (Transmission Control Protocol), os campos mais importantes para esta validação são os que apontam as seguintes informações, número de seqüência do pacote.

Marcas especiais do protocolo, como um bit que marque o primeiro pacote a ser transmitido.

Pacotes perdidos.

Pacotes duplicados.

Características específicas como portas ou endereços.

Por exemplo, verificar se o Sistema de Controle está recebendo o pacote da/na porta correta.

Cada protocolo tem suas características próprias.

Neste tópico são apresentados alguns parâmetros comuns aos protocolos orientados à conexão.

Sendo assim, se o protocolo que for testado não for desta natureza, é necessário levantar seu próprio conjunto de parâmetros para validação do protocolo.

Para exercitar o Sistema de Controle e enviar/receber pacotes, é necessário apenas ter as primeiras funções de leitura e escrita em registradores (por mais simples que sejam) e/ou enviar dados para um dispositivo interno do Sistema de Controle que apenas leia a informação e retransmita de forma idêntica, como um dispositivo tipo Refletor (Wrapper).

Este tipo de teste é importante, não só pela validação do protocolo manualmente, mas para se ter mais certeza sobre a corretude do desenvolvimento, para um futuro teste de automação.

Entrada, especificação do Sistema de Controle com informações sobre o tipo/formato de dado que espera receber do Terminal e da Unidade de Processamento, informação de como o sistema deve processar os dados, para poder comparar com os resultados.

Saída, registro de cada um dos pacotes transmitidos entre as partes (Terminal, SC e SC, UP), para poder verificar se há algum erro na estrutura dos pacotes.

A atividade de teste consiste em enviar dezenas de pacotes do Terminal para o Sistema de Controle, através de algumas instruções, como ler registradores, e receber a informação de volta, depois de processada.

Teste Analisador de Rede (Sniffer ) entre o Sistema de Controle e o Terminal.

Testar se o(s) protocolo(s) entre o Sistema de Controle e o Terminal está(ão) de acordo com a especificação, para uma grande quantidade de pacotes (Ordem de milhares).

Processo de teste Descrição detalhada, este teste é um complemento do teste básico de protocolos.

Depois da verificação manual dos pacotes, é importante obter uma validação com um volume maior de informação.

O próprio programa, que gerou os dados para se trabalhar manualmente, poderia gerar um arquivo com uma quantidade de pacotes muito maior, por exemplo, com milhares de pacotes.

O problema, neste caso, é que o programa poderia estar distorcendo, de alguma maneira, o valor das informações.

Analisador de Rede (Sniffer), Um programa ou equipamento que monitora dados que trafegam em uma rede.

Ele configura a interface de rede em modo promíscuo e captura e analisa todos os pacotes que passam pela rede, mesmo que não sejam enviados diretamente para ele.

Assim, para a automatização e para garantir que os pacotes, que estão sendo analisados, são verdadeiros, é preciso da ajuda de um analisador de redes.

O analisador irá ler todos os pacotes que estão passando na sua interface de rede, e registrar tudo que estiver no cabeçalho e no campo de dados.

Toda a informação coletada deve ser armazenada em um arquivo, no formato que o analisador puder gerar.

Depois, toda a verificação que foi feita manualmente, deve ser inserida em um programa para processar estes dados.

Esta automatização na validação do código é muito valiosa, na medida em que, depois de qualquer alteração futura, sempre é possível revalidar, sem uma nova análise manual.

A automatização não precisa ser um sistema muito elaborado.

Pode ser apenas um script que verifique os campos do cabeçalho e que tenha cadastrado todas as regras do protocolo, como seguir o número de seqüência, determinando qual deve ser o número do próximo pacote, caso ocorra uma perda ou pacote duplicado, entre outros.

Entrada, especificação do Sistema de Controle, com informações sobre o tipo/formato de dado que ele espera receber do Terminal e da Unidade de Processamento, informação de como o sistema deve processar os dados, para poder comparar os resultados com os valores esperados do teste.

Além disso, são necessárias as informações coletadas sobre os pacotes da rede, providas pelo analisador.
Saída, Caso não tenha ocorrido nenhum problema, deve ser emitido, apenas, um aviso de sucesso do teste.

Caso contrário, é preciso receber informações sobre qual regra do protocolo falhou, e em qual pacote.

Para esse teste, o cenário ideal é que se obtenha um analisador externo, seguindo a configuração apresentada.

Cenário Ideal para Teste com Sniffer.

Nessa configuração, o analisador não irá interferir no desempenho das medidas e, além da análise funcional, é possível ter uma visão temporal da transmissão dos pacotes, com uma boa precisão, pois ele apresenta relatórios sobre conteúdo dos pacotes no tempo que foram observados.

O analisador mostra os pacotes pela ordem de data e horário que foram coletados.

Para sistemas onde o tempo entre os pacotes ou o desempenho é crítico, esse é o melhor cenário.

Por outro lado, para esse teste, é preciso ter um switch, que suporte o redirecionamento de pacotes das portas que estão sendo analisadas, para a porta do analisador.

Pode-se utilizar um hub, mas ele tem uma perda muito grande (próxima de 60%) em situações de congestionamento de rede, e poderá interferir nas medidas.

Os switches têm perdas muito menores, com rendimento superior a 70%, por isso são mais indicados para este teste.

Uma configuração mais simples que pode ser utilizada, caso a questão do desempenho não seja tão crítica, como no caso deste teste, é utilizar um analisador no mesmo equipamento do Terminal.

Existem muitos sniffers que são via software, como o Ethereal para o sistema operacional Linux.

Ele irá manter a relação temporal, mas há uma perda de desempenho no sistema.

Além disso, não afetam a verificação individual dos pacotes.

Cenário de Teste com Sniffer no Terminal.

Testar se a leitura e escrita nos registradores mais básicos do Sistema de Controle estão de acordo com a especificação.

O teste deve validar se todo o caminho até os registradores está programado corretamente, além de verificar se o conteúdo dos mesmos está de acordo com a especificação.

Descrição detalhada, o teste de leitura e escrita nos registradores mais básicos é específico do Sistema de Controle em análise, por isso não será especificado quais registradores devem ser acessados.

Se o Sistema de Controle possuir vários blocos, deve-se iniciar o processo de teste com o bloco mais simples e externo ao Sistema de Controle até atingir os mais complexos e internos ao SC.

Deve contemplar pelo menos os registradores mais comuns, por exemplo, registradores que armazenam versão e ID (esses ou alguma variação de registradores mais simples) de cada camada.

O conceito aplicado neste teste consiste em passar para o Sistema de Controle um comando de leitura ou escrita e um endereço do registrador.

Em seguida, deve-se enviar uma instrução para o Sistema de Controle, para efetuar o acesso ao registrador determinado, sendo leitura ou escrita, e retornará um valor, que pode ser o valor lido no caso de leitura ou o valor que foi armazenado no caso de escrita.

O software de teste deve comparar este resultado com o esperado, verificando-se se a operação foi realizada com sucesso.

Caso positivo, o teste é finalizado.

Caso negativo, é necessário corrigir o problema no Sistema de Controle ou no software do Terminal (APIs com funções básicas de acesso ao Sistema de Controle) e refazer o teste.

No processo de leitura e escrita dos registradores, caso o Sistema de Controle seja separado em camadas ou blocos lógicos bem definidos, é necessário testar um bloco por vez, até atingir o último, efetuando as correções necessárias ao longo do processo.

Em um Sistema de Controle de blocos lógicos bem delimitados, além do teste dos registradores, talvez seja necessário mais algum tipo de teste de cada um dos blocos.

Neste caso, entre um teste de registrador e outro, é preciso executar todos os testes de validação em um bloco, antes de iniciar o seguinte.

Um erro em alguma outra parte pode interferir no teste do registrador do próximo bloco.

Para os registradores de escrita, o teste mais adequado é escrever algum dado e ler em seguida, para ter certeza que o valor foi inserido com sucesso.

Entrada, lista de registradores e seus conteúdos (quando for apropriado) e funções do software do Terminal referentes à leitura e escrita nos registradores, passando o endereço do registrador, o tipo de ação (leitura ou escrita), o valor a ser enviado, no caso de escrita, e o valor esperado para verificação.

Saída, comparação entre os valores esperados e os obtidos dos registradores.

Diagrama de Blocos de um Sistema de Controle com Foco em Registradores.

Fluxo do Teste de Leitura e Escrita em Registradores.

OBS, este teste só se aplica aos Sistemas de Controle que tenham o dispositivo Refletor implementado ou para os quais tenha sido desenvolvido algum dispositivo similar.

Objetivo Testar se todos os bits enviados para um determinado dispositivo chamado Refletor no Sistema de Controle, são retransmitidos na mesma ordem e com o mesmo valor, isto é, de forma idêntica.

Processo de teste Descrição detalhada, o dispositivo de Refletor dentro do Sistema de Controle é uma forma bem simplificada de simular a Unidade de Processamento.

Ele ajuda muito no desenvolvimento e na medição do desempenho do Sistema de Controle.

Através dele é possível testar se todo o caminho até um dispositivo, inclusive a multiplexação e a demultiplexação de pacotes entre os dispositivos, foi desenvolvido corretamente.

Para o teste é necessário usar uma função especial no Terminal que trata apenas do Refletor.

Ela pode ser implementada de várias maneiras, mas a idéia básica é enviar um número conhecido de Bytes e analisar a retransmissão para checar se é idêntica.

É importante enviar uma quantidade pequena de dados, para simular o Sistema de Controle tratando apenas um simples comando, e também enviar uma quantidade grande de informações, para testar uma grande transmissão de dados pelo Sistema de Controle.

Há um conceito similar entre os blocos lógicos de registradores e de Refletor.

É possível que um Sistema de Controle, separado por camadas, tenha vários dispositivos de Refletor, sendo um por bloco.

Nesse caso, é necessário testar cada um em separado e entre um teste e outro, pode haver outros testes como o de registradores, por exemplo.

Entrada, programa de teste do Terminal que envia e recebe dados do/para o Refletor.

Saída, Comparação entre os valores recebidos e enviados ao(s) dispositivo(s) de Refletor.

Verificar como a variação do MTU da rede interfere na taxa efetiva de transmissão dos pacotes, visto que o Sistema de Controle pode ter uma interface proprietária de rede, sem nenhum teste prévio sobre o tamanho máximo dos pacotes da rede que conecta o SC e o Terminal.

A pergunta que deve ser respondida é se aumentando o valor do MTU também aumenta o valor da taxa de transmissão.

Processo de teste Descrição detalhada, o teste deve ser executado através do envio constante de uma mesma quantidade de dados.

A escolha do tamanho da stream, que será enviada, deve ser considerada em função do tipo de dado que mais freqüentemente trafega pelo sistema, ou do tipo de dado que está se querendo avaliar.

Se o MTU for muito relevante para o Sistema de Controle, então é preciso repetir o teste com, no mínimo, três tipos de tamanhos diferentes de dados.

Um com um tamanho pequeno, que pode ser o menor pacote em relação ao tipo de tráfego que será transferido, um médio e o de tamanho máximo que será trafegado na rede.

Como a solução é genérica para vários tipos de sistemas de processamento paralelo, o tamanho para referência de pequeno, médio e máximo devem ser avaliadas caso a caso.

O foco do teste é apenas no MTU, isto é, na análise da taxa de transmissão dos pacotes, independente da função que está sendo implementada.

Neste contexto, pode-ser usar qualquer método do Sistema de Controle que já foi testado previamente, como leitura ou escrita em um registrador, ou até usar o recurso do Refletor, onde o mesmo dado que é transmitido e recebido de volta pelo Terminal.

Independente da função que irá transmitir dados pela rede, sempre é necessário verificar se a informação recebida está correta.

Este é um teste que pode ser feito apenas com funções entre o Terminal e o Sistema de Controle, sem a necessidade da conexão da versão corrente da Unidade de Processamento.

Apesar disso, se a Unidade de Processamento estiver conectada, o teste do MTU fica muito mais completo, já que testa a interferência da variação do MTU desde o Terminal até o Sistema de Controle e vice versa.

Para o teste, deve-se executar a função que envia sempre o mesmo número de bytes pela rede, variando-se o MTU entre 100 bytes e o valor máximo que o Sistema de Controle permitir para o MTU.

Cada dispositivo pode ter um valor máximo diferente, dependendo do desenvolvedor.

Alguns já suportam Jumbo Frame (IETF, 99),que chega a 9216 Bytes (9 KB).

Entrada, Programa criado para o teste, que usa as APIs básicas do Terminal, que envia e recebe dados do/para a nova versão do Sistema de Controle e para a Unidade de Processamento corrente, definição da faixa de valores que o MTU da rede poderá ter para medir o tempo ou taxa de pacotes transmitidos.

Saída, tabela ou um gráfico que mostre a taxa ou tempo de transmissão de certa quantidade de dados (que deve ser sempre a mesma), em relação à variação do MTU da rede.

Verificar se o Sistema de Controle suporta a execução de tarefas, sem que ocorra nenhum problema de perda de informação ou troca de dados incorretos, se for exercitado com um número de comandos dez vezes maior que o normal estimado.

O número de vezes que uma operação deve ser executada a mais que a quantidade normal não é um valor exato, e sim uma estimativa.

No mínimo, deve ser testado o dobro de vezes.

Processo de teste Descrição detalhada, para o teste é necessário escolher uma ou mais tarefas para serem executadas de forma constante e automatizadas.

Podem-se mapear todas as tarefas do Sistema de Controle em uma ou mais funções do Terminal.

Assim, o teste de stress pode ser interpretado como um determinando número de funções sendo executado em seqüência, em uma quantidade de dez vezes mais do que o estimado.

Por exemplo, pode-se definir que uma determinada tarefa seja a leitura de alguns registradores e a troca de dados com algum dispositivo.

Para concluir toda a tarefa, as funções são executadas cem vezes.

Neste caso, o teste de stress deve executar a mesma seqüência de instruções mil vezes, de forma seqüencial e ininterrupta e verificar se o resultado continua de acordo com o esperado.

Para que o teste seja mais completo, as tarefas que serão executadas devem contemplar atividades que envolvem a Unidade de Processamento corrente.

Assim, tem-se mais garantia que todo o caminho está sendo testado, e não só até o Sistema de Controle.

Entrada, funções do Terminal que exercitem o Sistema de Controle, um programa que automatize essas funções para serem executadas, de forma contínua, dez vezes mais que o número de vezes que elas seriam executadas em uma situação normal.

O programa também deve verificar de forma automática se os valores de retorno das funções são o esperado.

Saída, para o teste de stress, é apenas verificado se o programa automatizado identificou algum problema na execução de alguma função.

Se retornar algum valor incorreto, o programa deve identificar em qual função e quantas vezes esse comando já foi executado com sucesso.

OBS, Este teste só se aplica à Unidade de Processamento que possuírem registradores de escrita e leitura, e forem acessíveis pelo Sistema de Controle.

Verificar se, através do Sistema de Controle, funções do Terminal são capazes de ler e escrever em registradores da Unidade de Processamento corrente.

Processo de teste Descrição detalhada, o teste verificará se toda a estrutura do Sistema de Controle está de acordo com o esperado.

Para ter acesso aos registradores de leitura e escrita da Unidade de Processamento, as funções do Terminal devem enviar comandos que são recebidos pelo SC, processados, identificados como sendo para um dispositivo da UP e enviados até ele.

Depois, a resposta passa pelo caminho inverso e retorna ao Terminal.

Devem ser escolhidos registradores básicos de leitura para iniciar, como identificadores da Unidade de Processamento, que são fixos e pré-determinados.

Em uma segunda etapa, devem-se fazer alterações em registradores simples, que não sejam críticos para a UP.

Como já foi mencionado, os primeiros registradores testados devem ser simples, ou seja, registradores com poucos bytes e que gerem o menor número possível de pacotes para o sistema.

Caso os testes não apresentem discrepância com os resultados esperados, então o próximo passo é trabalhar com registradores que tiver maior quantidade de bytes e que utilizem comandos mais complexos para seu acesso.

É necessário um cuidado especial, quando for iniciar testes que alteram dados da Unidade de Processamento.

As alterações devem ser analisadas pelos especialistas, pois pode danificar o equipamento, como causar um curto circuito.

Entrada, definição dos registradores mais simples e mais complexos, descrevendo seu endereço, valor de escrita, caso seja necessário, e o resultado esperado.

Se houver algum registrador crítico, que não deve ser alterado na Unidade de Processamento, deve ser marcado para que o teste ignore-o.

Saída, Comparação entre os valores esperados e os obtidos dos registradores.

Testar uma ou mais particularidades da Unidade de Processamento diferente de registradores.

Este é o último teste que deve ser aplicado ao sistema.

O objetivo do teste é verificar se é possível acessar alguma função específica da Unidade de Processamento, como por exemplo, carregar informações em alguma posição de memória, ou iniciar algum chip.

Processo de teste Descrição detalhada, como a solução da metodologia de testes de Sistemas de Controle proposta é genérica, esse teste fica co-relacionado à Unidade de Processamento.

Devem-se verificar as suas características para encontrar funcionalidades que são disparadas por comandos de funções no Terminal.

Depois que a funcionalidade for definida, o teste pode ser iniciado.

Uma função do software do Terminal, que sensibilize essa característica, deve ser escolhida, ou desenvolvida, caso ainda não exista.

A Unidade de Processamento, geralmente possui algum tipo de memória ou alguma FPGA que pode ser carregada pelo Terminal.

Pode ser escolhida qualquer característica da unidade corrente que seja acessível pelo Sistema de Controle.

Além disso, é necessário que haja algum efeito visível ou de fácil monitoração, para que o teste seja validado.

Da mesma forma que a escrita de registradores, este teste também deve ser feito com muito cuidado, já que pode danificar a Unidade de Processamento, alterando alguma configuração interna.

Entrada, definição da função ou funções que serão testadas.

Escolha ou desenvolvimento de métodos que o Terminal irá usar para acessar as funções.

Algum outro tipo de dado pode ser necessário, como algum arquivo de configuração que será carregado na unidade, mas isso depende muito do que será testado.

Saída, cada funcionalidade da Unidade de Processamento deve apresentar um resultado esperado.

Para este teste, a saída será a comparação do resultado obtido com o resultado que já existente, testado e aprovado por toda a estrutura corrente do Sistema de Controle e da Unidade de Processamento.

A análise dos resultados dos testes é um trabalho que exige um grande entendimento dos testes, da nova versão do Sistema de Controle e da atual Unidade de Processamento.

Tais resultados devem ser analisados junto à especificação da nova versão do Sistema de Controle, para verificar se todas as funções são executadas corretamente.

Nesta etapa, os engenheiros e especialistas devem despender mais tempo analisando o relatório final de resultado dos testes que ao longo de sua execução, pois tipicamente não participam de todo o processo de testes.

Toda a documentação utilizada deve ser formalmente ratificada, com os erros encontrados ao longo dos testes.

Caso esses documentos não estejam adequados ou bem detalhados, a experiência adquirida no processo deve ser utilizada para notificar e auxiliar os desenvolvedores sobre as correções necessárias.

A análise dos resultados dos testes pode gerar novas correções no software ou no hardware do Sistema de Controle.

Caso isso ocorra, há a necessidade de se executar uma nova seqüência de testes, para homologar novamente esta versão do Sistema de Controle.

Todos os testes devem ser executados com sucesso, antes de iniciar o teste seguinte.

Os testes devem ser executados na ordem determinada, pois cada caso de teste analisa uma funcionalidade especifica do Sistema de Controle, da mais simples para a mais complexa.

Por exemplo, não é possível executar o teste de número 3, Teste de Registradores do Sistema de Controle, sem que o número 1, Teste do Protocolo de entre o Terminal e o SC esteja finalizado com sucesso, pois com erro no protocolo, ler o registrador seria uma tarefa impossível.

As duas únicas exceções são os testes de desempenho, como o número 5, Teste da Variação do MTU da Rede e o número 6, Teste de Stress.

Esses testes podem gerar resultados não esperados sobre o desempenho do sistema, mas não impede de se continuar os testes.

A metodologia proposta foi apresentada em detalhes para que seja um guia de testes para novas versões de sistemas de processamento paralelo e aumente a qualidade dos Sistemas de Controle de sistemas de processamento paralelo.

Através da análise sobre otimização de tempo de desenvolvimento de sistemas de processamento paralelo, foi mostrado que a estratégia de testes em paralelo com o desenvolvimento reduz o tempo de teste destes sistemas e, conseqüentemente, o tempo total do projeto.

A metodologia de testes define 8 casos de teste para serem executados no Sistema de Controle de novas versões de sistemas de processamento paralelo.

Porém, é possível que algum destes testes seja dividido em mais testes, com o mesmo objetivo, caso seja necessário.

Por exemplo, caso o Sistema de Controle tenha vários componentes internos, cada um com seu conjunto de registradores, o teste de registradores pode ser dividido em um para cada componente.

Essa decisão deve ser tomada no planejamento dos testes.

A metodologia de testes do uma nova versão do Sistema de Controle trabalhando em conjunto com a Unidade de Processamento corrente gera os seguintes benefícios para um projeto de desenvolvimento de sistemas de processamento paralelo, Reduz o esforço futuro e o tempo total do projeto, quando a nova Unidade de Processamento for finalizada.

Com os testes propostos, a probabilidade de se encontrar erros de integração na nova versão do sistema fica bem reduzida, uma vez que eles foram corrigidos com a arquitetura corrente.

Corrige possíveis problemas de erros de hardware e software no Sistema de Controle, antes da nova unidade ser concluída, não gera atraso no teste da própria unidade, e conseqüentemente no projeto.

Além disso, se algum problema mais crítico for encontrado, os engenheiros ainda têm algum tempo para corrigí-lo.

Ajusta alguns parâmetros de desempenho, como tamanho das filas auxiliares que o Sistema de Controle pode utilizar com uma Unidade de Processamento já conhecida, pode acelerar o processo de otimização destes parâmetros.

É mais fácil ajustar os parâmetros de desempenho com a versão corrente, já que se sabe o que esperar do comportamento dela.

Caso a camada de software do Terminal ainda não tenha sido desenvolvida, pelo menos as APIs (Application Programming Interface) mínimas de comunicação são geradas como produto dos testes.

É reduzido, assim, um passo futuro que seriam os testes das APIs quando a aplicação fosse criada.

Quando a nova Unidade de Processamento for testada, haverá uma maior certeza que um determinado problema está na própria unidade, e não na aplicação do Terminal ou no Sistema de Controle, já que estes dois foram testados com a versão antiga da máquina.

As documentações do Sistema de Controle e do software do Terminal são revisadas e corrigidas ao longo do processo de teste.

Como foi apresentado, minimizar os erros de hardware e software da nova versão do Sistema de Controle, que podem surgir quando a nova versão da Unidade de Processamento estiver pronta, irá contribuir muito para reduzir o tempo total do projeto.

Isso mostra que a aplicação da metodologia de testes propostas, baseado em testes da nova versão do Sistema de Controle em paralelo com o desenvolvimento da Unidade de Processamento gera resultados importantes para acelerar a colocação do produto para o mercado consumidor.

Baseando-se nas definições apresentadas no capítulo 2, pode-se dizer que a metodologia apresentada no trabalho, tem casos de teste que abrangem desde testes de unidade, que no caso é o Sistema de Controle, ou partes internadas do SC como registradores, até testes mais complexos de integração de componentes e até do sistema todo, com o Terminal, SC e UP.

O capítulo 5 traz um estudo de caso da aplicação da metodologia de testes proposta no desenvolvimento do supercomputador Blue Gene da IBM.

Para validar a metodologia proposta, foi desenvolvido um estudo de caso com o novo supercomputador da IBM Blue Gene, que está sendo desenvolvido no centro de pesquisas T J Watson.

A versão corrente do supercomputador é a Blue Gene versão L (BG/L).

A metodologia de testes é aplicada à nova versão do Sistema de Controle do Blue Gene com o objetivo de reduzir o tempo total de desenvolvimento do novo supercomputador.

Nos próximos itens, são apresentados um resumo sobre a arquitetura do Blue Gene, o cenário de testes utilizado no projeto, uma descrição do novo Sistema de Controle e seu principal protocolo de comunicação, a execução das quatro etapas descritas na metodologia e algumas considerações sobre a aplicação da metodologia no Blue Gene.

Em 1999, quando a IBM iniciou o projeto do supercomputador, alguns objetivos de projeto foram definidos e merecem ser destacados, arquitetura focada em maximizar o desempenho de aplicações em paralelo, uso de processadores com baixo consumo de energia, baixa freqüência do processador (700 MHz), baixa dissipação de calor e com desenvolvimento de um sistema em um chip ASIC (Application-Specific Integrated Circuit).

A arquitetura do Blue Gene (BG) define um sistema de processamento em paralelo baseado em um chip (Blue Gene chip) com dois processadores.

Dois Blue Gene chips compõem uma placa chamada cartão de cálculo (compute card).

Os cartões de cálculo (compute cards) são combinados em um grande sistema através de sua interconexão via uma rede, como a rede Torus.

O Blue Gene versão L (BG/L) pode ter até 32768 cartões (65536 chips) de cálculo com 4 processadores PowerPC 700 MHz (Power Optimization With Enhanced RISC Performance Computing) cada.

Cada processador apresenta um desempenho de 2,8 GFlop/s.

Cada gabinete do Blue Gene tem ainda oito cartões de conexão (link card), que é usado na conexão entre os gabinetes e 2 cartões de serviço (service card), que distribui o clock para o sistema e possui funções de gerenciamento do Rack.

Podem-se identificar os componentes que fazem parte do supercomputador da IBM Blue Gene.

Um Blue Gene chip tem 2 processadores e um desempenho máximo de 5,6 GFlop/s.

Um cartão de cálculo (compute card) possui 2 Blue Gene chips e 4 processadores e um desempenho máximo de 11,2 GFlop/s.

Uma cartão de nó (Node Board) possui 16 cartões de cálculo, 32 Blue Gene chips e 64 processadores e um desempenho máximo de 179,2 GFlop/s e assim por diante, até chegar no tamanho máximo permitido para o Blue Gene que são 65536 cartões de cálculo e com desempenho de aproximadamente 360 TFlop/s.

Cálculo de Desempenho do Blue Gene.

Supercomputador Blue Gene da M.

De acordo com a classificação de Flynn apresentada no capítulo 2, a arquitetura do Blue Gene/L pode ser considerada do tipo MIMD, pois cada processador pode executar um fluxo diferente de instruções e pode trabalhar em um fluxo diferente dos dados.

O sistema operacional, que gerencia os processadores do BG, corresponde a uma versão customizada de Linux, para otimizar espaço em memória e desempenho dos processadores, com foco em suportar aplicações para computação paralela.

Toda comunicação entre o software do Terminal (T), chamado de Service Node, e as placas e processadores do BG/L, Unidade de Processamento (UP), é feita através do Sistema de Controle (SC) chamado de iDo.

Ele provê funcionalidade de transporte de comandos e instruções para os processadores do BG/L, desde sua iniciação, até envio de jobs (programas desenvolvidos em uma linguagem para aplicações em paralelo), incluindo a monitoração das fontes de energia, sistema de refrigeração e outros sensores.

A nova versão do Blue Gene definiu um novo Sistema de Controle, chamado Icon/Palomino, como sendo a evolução do atual iDo.

Ambos possuem funções semelhantes, mas com mudanças significativas em sua arquitetura, objetivando melhorar o desempenho do novo supercomputador.

As principais diferenças e semelhanças entre o Sistema de Controle atual iDo e o novo Sistema de Controle Icon/Palomino podem ser observadas.

Para a interação com o Blue Gene, como componente Terminal é utilizado um Servidor IBM, onde as instruções de controle e as aplicações para sistemas de processamento paralelo são iniciadas.

Além disso, este servidor é usado, também, como repositório de dados, já que a parte da máquina responsável por todo o processamento, utilizando-se múltiplos processadores e placas proprietárias, não possui nenhum tipo de sistema de arquivos para manter dados permanentes.

É chamado de Service Node, e é usado tanto pelos usuários como pelos administradores do sistema.

A metodologia proposta foi aplicada à nova versão do Blue Gene, pois atende aos principais requisitos da solução, Todo o planejamento dos testes foi executado assim que o SC Icon/Palomino foi concluído.

O Blue Gene possui uma arquitetura que pode ser modelada em três camadas, Terminal com Service Node.

Sistema de Controle com Ido (versão antiga) e Icon/Palomino (nova versão) e Unidade de Processamento com os processadores do Blue Gene.

Através de informações levantadas junto aos gerentes de cada grupo de desenvolvimento do supercomputador, foi possível estimar o tempo total do projeto e 20 I C, é uma via de acesso (bus) usado para conectar periféricos de baixa velocidade a placas mãe, sistemas embarcados (embedded system), ASICs ou até telefone celular.

SPI é um protocolo de comunicação síncrono e opera no modo full-duplex.

Conecta equipamentos no modo Mestre/Escravo, onde o Mestre inicia a comunicação.

Múltiplos equipamentos escravos são permitidos para um Mestre.

Organizar todas as etapas de aplicação da metodologia, do planejamento à execução dos testes.

Foi discutido e analisado com a equipe um parâmetro de comparação entre a nova versão do Sistema de Controle e a versão antiga.

O Blue Gene, na nova e corrente versão, recebe o software para iniciação dos chips pela rede, através do Sistema de Controle.

Assim, foi definido que o tempo para iniciar um chip na nova versão e na versão antiga é um parâmetro importante de comparação, já que a principal funcionalidade do SC é gerenciar a comunicação com a Unidade de Processamento.

Os principais protocolos de comunicação, como JTAG, I C e SPI, entre o Sistema de 2 Controle e a Unidade de Processamento são semelhantes.

Desta maneira, depois de várias discussões com os engenheiros responsáveis pelas duas versões do supercomputador, foi possível definir como efetuar a conexão da nova versão do Sistema de Controle e a versão atual da Unidade de Processamento.

Isto foi feito através de um cabo especial, que liga os sinais de saída do Sistema de Controle aos sinais de entrada da Unidade de Processamento e vice-versa.

O custo para que a nova versão do Sistema de Controle e a atual Unidade de Processamento é o custo para o desenvolvimento de um cabo que conecta os sinais do SC a UP.

Esse é um custo muito baixo, já que o cabo que necessita ser construído é muito simples.

Desta maneira, o custo de compatibilização entre a nova versão e a versão atual é muito pequeno em relação ao ganho de reduzir o tempo de desenvolvimento do projeto.

O novo Sistema de Controle do Blue Gene já possuía alguns manuais, contendo explicações sobre o seu funcionamento e sua especificação, que foram utilizadas nos testes e, depois, atualizadas com as falhas encontradas.

De acordo com a metodologia proposta, é preciso modelar o supercomputador Blue Gene através de três componentes, Terminal, Sistema de Controle e Unidade de Processamento, onde o Sistema de Controle da nova versão é conectado à Unidade de Processamento da versão corrente.

Apresenta o modelo aplicado ao supercomputador Blue Gene.

O novo Terminal foi conectado à nova versão do Sistema de Controle Icon/Palomino através de um switch e este, conectado à versão corrente do BG/L através de um cabo que interliga os sinais do principal protocolo de controle do supercomputador, o protocolo JTAG.

Arquitetura para Testes com o Novo Sistema de Controle do BG/P.

Por opção dos gestores do Blue Gene, o software do Terminal não foi desenvolvido desde o início do projeto, em paralelo com o Sistema de Controle e a Unidade de Processamento.

Assim, de acordo com a metodologia, é preciso desenvolver uma API básica de acesso e um programa de testes para exercer a função do Terminal.

Tanto a API como o programa de testes foram desenvolvidos na linguagem C++ orientada a objetos.

A escolha da linguagem de programação foi motivada pelo conhecimento que as pessoas já possuíam na linguagem e pela experiência da equipe com a versão corrente do software do Terminal (Service Node) do BG/L, que também estava em C++.

Devido às definições referentes à linguagem de programação da versão corrente do software do Service Node, a nova biblioteca de funções foi criada com os mesmos padrões, aumentando-se a compatibilidade da versão corrente com o código dos testes e reduzindo-se o trabalho futuro de uma nova versão (que será baseada na atual).

Conseqüentemente, para testar o novo Sistema de Controle do Blue Gene, o Icon/Palomino, foi criado um novo programa de teste em conjunto com a nova biblioteca de funções, sem a utilização de nenhum código já existente.

Este software foi baseado na documentação feita pelos desenvolvedores, que descreve suas funcionalidades, protocolos e registradores.

A biblioteca foi desenvolvida para o Service Node, um processador PowerPC da IBM com o Linux Fedora core 3.

O Sistema de Controle, Icon/Palomino, é um equipamento com uma interface Ethernet 10/100/1000 Mbps conectada ao Service Node através de um switch e com o cartão de serviço do Blue Gene/L, que é uma placa de circuito impresso que faz parte da Unidade de Processamento corrente.

Para a Unidade de Processamento foi usado um dos cartões do BG/L (versão corrente do supercomputador), com um cartão de serviços (Service Card).

Dentre os três cartões existentes para o BG, cartão de serviços (Service Card), Cartão de Nó (Node Card) e Cartão de Conexão (Link Card), foi escolhido o cartão de serviço pelos seguintes motivos, O cartão de serviço possui um conector físico para acesso direto a uma FPGA (chip programável) através do protocolo JTAG.

Este cartão é o mais simples, em questão de hardware, e possui alguns LEDs que podem ser usados para um teste visual mais rápido do resultado da instrução enviada.

A tensão deste cartão é a mesma que a tensão do Icon/Palomino (12 V).

Assim, não é necessário nenhum tipo de conversor para a conexão entre o SC e o Service Card, já que eles devem trabalhar com a mesma voltagem e possuir o mesmo terra.

Havia disponibilidade deste tipo de cartão para teste.

O teste mais importante para os desenvolvedores era enviar um software para iniciar um chip Altera 77 P0468 programável, que é uma FPGA.

O sucesso no envio desta imagem para a FPGA foi o teste que, realmente, comprovou a eficiência do novo Sistema de Controle para o JTAG.

Este teste mostra que todos os sinais de controle, os cabeçalhos dos pacotes, o processamento destes pacotes e o seu envio são feitos corretamente pelo Icon/Palomino.

Além disso, a medição do tempo do envio desta imagem para a FPGA é o parâmetro previsto nos requisitos da solução de comparação entre o novo Sistema de Controle e o corrente.

Como já se conhece o tempo de iniciação do BG/L (versão corrente), fica mais fácil testar a nova versão e avaliar qual tem o melhor desempenho.

Além disso, esse parâmetro é o resultado de uma tarefa comum do supercomputador, que realmente precisa ser otimizada.

Porém, para executar este teste, foram feitos vários outros de menor complexidade, para ter certeza da qualidade do Sistema de Controle Icon/Palomino e do software do Terminal, como por exemplo, teste de protocolos internos do Icon, seleção de dispositivos pelo Icon, processamento do JTAG pelo Icon e pelo cartão de serviço, lendo seu registrador IDCODE e alguns outros.

O Icon/Palomino trabalha com alguns protocolos para gerenciar a Unidade de Processamento do Blue Gene.

Apesar disso, o protocolo mais importante e o mais usado para seu controle é o JTAG.

É através dele, por exemplo, que os processadores do supercomputador são iniciados.

Por esse motivo, o JTAG foi o protocolo comum usado para a conexão dos ambientes novo e antigo.

Nos próximos itens, é apresentado um breve resumo sobre o Sistema de Controle Icon/Palomino e o detalhamento de todos os testes feitos com o Sistema de Controle, desde o planejamento até os resultados obtidos em todas as etapas.

Cada placa da Unidade de Processamento do Blue Gene, que contém os Blue Gene chips (processadores), memórias e conectores de comunicação possuem um chip do novo Sistema de Controle Icon/Palomino.

Ele é conectado a uma rede Ethernet para receber instruções e dados do Terminal, processar, converter as informações nos protocolos específicos da UP, e enviar para o processador correto.

O novo Sistema de Controle do Blue Gene pode ser dividido em duas partes lógicas.

A primeira, Icon, tem a função de receber e enviar os pacotes, direto da interface Ethernet de/para o Service Node.

A segunda, Palomino, recebe/envia os dados diretamente para a Unidade de Processamento, como cartões do BG, processadores, sensores, fontes de energia, entre outros.

Modelo Simplificado dos Principais Componentes do Sistema de Controle do BG/P O Service Node pode enviar até dois pacotes de 64 bits por vez para o Icon sem a necessidade de uma resposta (ACK), um para a porta 0 e outro para a porta 1.

O Icon/Palomino comunica-se com o Terminal, através da rede Ethernet.

Toda a comunicação é feita, utilizando-se o protocolo UDP (User Datagram Protocol), que não garante a entrega dos segmentos de dados.

Desta maneira, o protocolo de comunicação do Icon implementa seu próprio controle, enviando um pacote ACK de resposta para cada pacote recebido.

O Service Node envia pares de pacotes continuamente até acabar o dado ou a instrução.

O Service Node é que controla quando os pacotes são enviados.

Para cada dois pacotes recebidos, o Icon envia dois ACK de volta.

Já o Icon não consegue iniciar o envio de nenhum pacote para o Terminal, sem que o Terminal tenha enviado algum pacote para ele, isto é, ele só envia um pacote se receber outro pacote.

Quando uma instrução é enviada à Unidade de Processamento, ao chegar no Sistema de Controle, passa primeiro pelo Icon, depois pelo Palomino, até chegar ao seu destino.

Depois que a UP faz o seu trabalho, envia uma resposta de volta para o Palomino, que encaminha para o Icon e de volta ao Terminal.

Para receber essa resposta de volta, como o Icon não envia pacotes sem o recebimento de um outro, é necessário que o Terminal envie continuamente pacotes NULOS para Icon até que toda a informação desejada seja recebida.

O Icon controla pacotes repetidos ou perdidos através de número de seqüência, que é separado para cada porta de recepção, porta 0 e porta 1.

O Service Node envia um par de pacotes com dois números de seqüência, um para cada porta, e espera dois ACKs de volta, nas mesmas portas.

Os ACKs recebidos são considerados válidos, se tiverem o mesmo ou um número de seqüência superior, que os números dos pacotes que foram enviados.

O próximo pacote é enviado pelo Terminal (Service Node) com o mesmo número que recebeu no ACK (que já foi incrementado de 1 pelo SC no pacote recebido anteriormente) e assim por diante.

Os dados recebidos pelo Icon são armazenados em buffers e enviados para o Palomino.

Este, por sua vez, deve processar o cabeçalho do pacote e reenviá-lo, de acordo com o protocolo selecionado, para os processadores do Blue Gene.

Assim, o Sistema de Controle está transformando as instruções que vieram encapsuladas no protocolo UDP que recebeu do Terminal, para o formato dos protocolos que o SC utiliza para se comunicar com a Unidade de Processamento, como é o caso do JTAG.

O Palomino, tem quatro dispositivos principais para controlar, Repetidor (Wrap), SPI (Serial Peripheral Interface), I C (Inter-Integrated Circuit) e JTAG.

Através deles, é possível executar a maioria das funções do Sistema de Controle, como receber e enviar programas e imagens de iniciação, ler e gravar em registradores, monitorar sensores de temperatura, tensão das fontes e sistema de refrigeração.

É através do protocolo JTAG, que as tarefas mais importantes do supercomputador são executadas.

É ilustrada uma parte da Unidade de Processamento, que está conectada ao dispositivo JTAG do Palomino.

A instrução é recebida pelas portas de recepção do Icon, portas 0 e 1, depois enviada para o Palomino que decide qual o dispositivo que será selecionado de qual processador/placa do Blue Gene.

Toda essa informação está no cabeçalho do pacote.

A instrução é processada e sua resposta faz o mesmo caminho de volta, passando pelas portas de transmissão do Icon até ser apresentada no Service Node.

Foi apresentada uma descrição sucinta do Icon/Palomino, pois o novo supercomputador Blue Gene está em desenvolvimento e detalhes sobre este dispositivo devem ser mantidos confidenciais.

O padrão IEEE 11491, Test Access Port and Boundary-Scan, chamado de JTAG (Joint Test Action Group), atualmente já pode ser considerado um método popular de testes em circuitos impressos (CIs).

Devido à grande evolução no aumento de densidade de componentes nas placas, e métodos mais sofisticados de montagem, o JTAG torna-se uma opção muito interessante para a atividade de teste destes CIs.

É muito difícil, fisicamente, apoiar uma ponta de teste em um Circuito Impresso com uma alta densidade de componentes e multicamadas para coletar ou injetar amostras de sinais nos pinos, para execução de um teste.

A técnica de Boundary Scan, que é a base do JTAG, especificada pelo IEEE 1149 (IEEE1149, 01), envolve componentes com registradores de deslocamento posicionados entre cada um de seus pinos e a lógica interna do componente.

Isto é, define pontos de teste ou células em cada Entrada/Saída digital de um circuito impresso, que são os registradores de deslocamento.

Componentes do Boundary Scan.

As células permitem controlar e observar o que acontece com cada pino de entrada e saída.

Quando estas células são conectadas entre si, formam uma cadeia de registradores de dados ou o Registrador Boundary Scan.

De acordo com a norma IEEE 11491 (IEEE1149, 01), a Porta de Acesso de Teste (Test Access Port TAP) endereça os sinais de controle (TMS, Test Mode Select e TCK Test Clock Input) para dentro do Controlador TAP e fornece a entrada e saída serial (TDI, Test Data Input e TDO, Test Data Output).

O Controlador TAP é uma máquina de estados com 16 estados, que pode ser programada pelos sinais de controle TMS e TCK, que controlam o fluxo de bits de dados para o registrador de instruções e o registrador de dados, como IDCODE e USERCODE.

Por exemplo, para se ler o valor do registrador IDCODE é necessário enviar sinais de TMS e TCK que movimentam a máquina de estados do Controlador JTAG e a posicionam sobre o registrador de instrução (IR).

Nesse momento, através de sinais do TDI, é enviado qual o endereço do registrador IDCODE que é necessário acessar.

Depois, mais alguns sinais de TMS e TCK são enviados e a resposta é enviada através do TDO.

O padrão JTAG define vários registradores, como USERCODE/IDCODE, que contém informações sobre a identificação do chip.

O mais importante para o trabalho é o registrador Boundary Scan, que é o conjunto de bits carregados nos pinos de um chip, o.

O Blue Gene define outras centenas de registradores que são mapeados na Unidade de Processamento do Blue Gene, isto é, quando o JTAG acessar esses registradores, estará acessando uma memória de um processador do Blue Gene.

É através da técnica Boundary Scan (JTAG) que a maioria da informação de controle do Blue Gene trafega pela rede, do Sistema de Controle Icon/Palomino, até a Unidade de Processamento.

Cada um destes componentes tem um dispositivo JTAG que gerencia desde a sua iniciazação, monitoração e troca de dados.

Conseqüentemente, o registrador Boundary Scan será alvo da maioria dos testes envolvendo registradores da Unidade de Processamento.

Um requisito muito importante na solução proposta é que seja possível conectar fisicamente a nova versão do Sistema de Controle e a versão corrente da Unidade de Processamento.

No caso do Blue Gene, é preciso conectar o Sistema de Controle Icon/Palomino a um cartão de serviços (service card).

Mostra os três componentes utilizados no teste do Sistema de Controle do Blue Gene.

A Unidade de Processamento, na versão atual do Blue Gene, é utilizada para se conectar ao novo Sistema de Controle Icon/Palomino.

Apenas como ilustração, há alguns LEDs, chaves S86-S84, um chip e o conector JTAG, que foram utilizadas posteriormente nos casos de teste.

Conexão dos Componentes do Blue Gene.

Uma informação importante representada é que a conexão do Terminal (Service Node) com o SC Icon/Palomino é feita por uma rede Ethernet e a conexão entre o Sistema de Controle e o cartão de serviço da Unidade de Processamento do BG/L é feita por protocolos tipo JTAG.

O Icon/Palomino foi conectado ao cartão de serviço através de um cabo feito especialmente para o projeto.

Uma das pontas do cabo foi adequada ao conector do Palomino e a outra a um conector especial, que só o cartão de serviço possuía.

O propósito do cabo era interligar os pinos que suportavam o protocolo JTAG (IEEE1149, 01), de dados (TDI e TDO), controle (TMS) e clock (TCK).

Cartão de Serviço BG Conectado ao novo SC Através de um Cabo Especial.

O cabo JTAG tem a função de conectar os sinais de controle, entrada e saída do JTAG do conector do novo Sistema de Controle Icon/Palomino, com os mesmos sinais do conector do cartão de serviço da Unidade de Processamento atual.

Os sinais de entrada (TDI) de um são ligados à saída (TDO) do outro e vice-versa, e os sinais de controle (TMS e TCK) são interconectados.

Além disso, a alimentação dos dois circuitos deve estar interconectada com um terra comum.

A especificação do cabo está descrita.

Cabo para Conectar Sinais JTAG do Ambiente Corrente e Novo.

Especificação do Cabo JTAG.

Para iniciar o planejamento, foi estimado, junto aos desenvolvedores e gerentes do projeto, qual o tempo que seria necessário até que os cartões e processadores da nova versão do BG estivessem prontos para o teste.

O tempo estimado foi de 8 (oito) meses, que acabou sendo o tempo gasto para os testes com Icon/Palomino.

No final, ainda foram usados por volta de mais 3 (três) meses, pois a entrega do hardware do BG atrasou, e aproveitou-se para estender os testes para outros protocolos, como I C.

Através de várias reuniões com os desenvolvedores e gerentes do projeto, ficou estabelecido que o teste funcional mais importante fosse o envio de um software de inicialização para uma FPGA em um cartão do BG/L, o cartão de serviço, utilizando a nova infra-estrutura.

Essa imagem iria iniciar o chip da FPGA.

Como o tempo de iniciação da FPGA era conhecido no BG/L, foi definido como parâmetro de comparação entre os dois Sistemas de Controle.

Este teste estava sendo muito esperado pelos desenvolvedores, pois o novo Sistema de Controle era muito mais complexo que o antigo, e ninguém tinha realizado testes comparativos entre o novo Sistema de Controle e o corrente (BG/L).

Baseado na experiência dos engenheiros, especialistas e desenvolvedores do Blue Gene, foi elaborado uma série de casos de testes, baseado na metodologia proposta no capítulo 4, especificando-se a descrição de cada teste, seus objetivos e os resultados esperados.

A execução dos testes seguiu a ordem, onde é testado do componente menor até a integração de todos os componentes (abordagem bottom-up).

Resumo dos Testes Efetuados com o Sistema de Controle do BG/P.

Cada teste descrito é a aplicação prática dos casos de testes descritos na solução proposta.

A maioria dos testes segue a aplicação da metodologia proposta, porém, foi necessário dividir dois casos de teste descritos na metodologia em dois testes para o Blue Gene, O teste de registrador do Sistema de Controle foi dividido em dois, porque o sistema Icon/Palomino é separado em duas camadas lógicas com seus registradores próprios.

Assim, para que o teste seja mais preciso, foram criados dois testes, o teste número 3 Teste do registrador do Icon e o número 4 Teste do registrador do Palomino.

O teste geral da Unidade de Processamento é muito particular à arquitetura e às características do sistema alvo.

Para o Blue Gene, foi separado em dois testes, o teste número 9 Teste de escrita do registrador Boundary Scan e número 10 Teste de iniciação de uma FPGA do cartão de serviço.

Antes de iniciar os testes, foi definido, a partir de documentação entregue pelos desenvolvedores, que seria criada uma biblioteca básica de funções, para acessar o Icon/Palomino.

A codificação do software do Terminal, que inclui esta biblioteca ou API (Aplication Programming Interface) e o programa para execução dos testes com o Icon foram feitos em conjunto com os testes.

Para cada método (função) ou grupo de métodos implementados, era feito um teste entre o software Terminal e o Sistema de Controle.

No tempo total dos testes, deve-se levar em consideração o desenvolvimento do software do Terminal.

Para os testes, foram gastos 40% do tempo na geração da biblioteca ou API do Terminal, e 60% na codificação do programa de testes, na execução dos testes e correções.

A metodologia de testes apresentada no capítulo anterior explica sobre as duas possibilidades para o software básico do Terminal.

A primeira, que requer menos esforço de programação, é aproveitar uma biblioteca já desenvolvida, que acessa o novo Sistema de Controle.

A segunda opção, que é o caso de nenhuma API de acesso ter sido desenvolvida ainda para acessar o novo Icon/Palomino, é o desenvolvimento integral da API.

Para o projeto de teste do novo Sistema de Controle do Blue Gene foi desenvolvida uma API inteiramente nova, em C++ orientado a objetos, para ser compatível com o Sistema de Controle corrente do BG/L, pois ainda não havia sido iniciado o desenvolvimento do novo software do Terminal.

Algumas idéias de objetos e pequenos trechos de código foram aproveitados da versão corrente, pois as funcionalidades dos dois sistemas deveriam permanecer a mesma.

Isso não é um requisito da solução, mas, neste caso, as aplicações, que são executadas no BG/L, são semelhantes ao do novo supercomputador.

Assim, a biblioteca de funções, ou API, que o desenvolvedor de aplicações utiliza, deve permanecer igual.

Para qualquer uma das duas opções, ou a API já está desenvolvida ou é necessário seu desenvolvimento, é preciso fazer um programa de teste para executar todos os casos de teste descritos na metodologia.

O programa de teste, que foi desenvolvido, deve usar as funções básicas da API de acesso para sensibilizar o Icon/Palomino e poder executar os testes.

Essa mesma API poderá ser usada pelas aplicações da nova versão do Blue Gene.

Mostra uma possível configuração da estrutura do software, que poderá ser utilizada pela nova versão do software do Terminal do Blue Gene.

O processo de testes focou no desenvolvimento do Programa de Testes e da Biblioteca básica de acesso ao Icon/Palomino, que foi uma das ferramentas usadas para testar o novo Sistema de Controle.

A API de software, que foi desenvolvida, contém funções básicas de acesso ao Sistema de Controle, sem a preocupação, pelo menos neste momento, de implementar funções de alto nível, para que os desenvolvedores de aplicação possam usar no futuro, quando as aplicações do novo Blue Gene forem desenvolvidas.

O programa de teste deve conseguir executar todos os casos de teste no novo Sistema de Controle através da API.

O objetivo desta biblioteca básica é poder acessar o Sistema de Controle e a Unidade de Processamento, através de algumas instruções, para executar as tarefas descritas na metodologia de teste.

Então, pode-se definir o software do Terminal como uma ferramenta usada no processo de teste.

Modelo de Blocos da Arquitetura da Solução Proposta para o BG.

No projeto de testes do novo Sistema de Controle, como ele tem uma arquitetura em camadas lógicas, como o Icon e o Palomino, o software do Terminal foi desenvolvido por partes, baseado nos casos de testes descritos no planejamento.

Cada função escrita era testada e corrigida, antes de iniciar o desenvolvimento e teste de uma nova função.

Poderia ter sido mais eficiente, através do desenvolvimento em paralelo do código, caso tivéssemos mais pessoas trabalhando na equipe.

Depois que todas as camadas do Sistema de Controle foram testadas, a biblioteca de software do Terminal foi direcionada a funções para acessar a Unidade de Processamento através do protocolo JTAG.

As principais funções de acesso descritas na metodologia foram implementadas a partir do protocolo JTAG, na nova versão do Sistema de Controle Icon/Palomino e no cartão de serviço (Service Card) da Unidade de Processamento, EnviarPacoteJTAG.

ReceberPacoteJTAG.

TratarPacoteRecebidoJTAG, TrataPacoteEnviadoJTAG.

CarregarDispositivoServiceCard.

ReinicializarServiceCard, ReinicializarIcon e ReinicializarPalomino.

LerRegistradorIcon, LerRegistradorPalomino e LerRegistradorServiceCard.

EscreverRegistradorIcon, EscreverRegistradorPalomino e EscreverRegistradorserviceCard.

Com o protocolo JTAG foi possível acessar funções do BG/L (versão corrente da Unidade de Processamento) e o novo Sistema de Controle.

Foram adicionadas, à biblioteca de software do Terminal, duas funções básicas, Acesso aos registradores da FPGA do cartão de serviço do BG/L.

Envio de uma imagem de iniciação do cartão de serviço do BG/L Essas funções já são executadas pelo Sistema de Controle corrente do Blue Gene, o iDo.

Como o comportamento e os valores dos registradores eram bem conhecidos pela equipe de projeto, com a troca dos Sistemas de Controle (SC) e as alterações necessárias na API do Terminal, foi possível comparar o novo Sistema de Controle com o corrente, de maneira direta.

O resultado é mostrado na próxima seção com a descrição detalhada dos testes.

Para cada teste realizado, são apresentados uma descrição e o resultado do teste, bem como seus pontos relevantes e algumas falhas que ocorreram ao longo do projeto.

Nem todos os ajustes de desempenho analisados nesta fase foram melhorados, pois a Unidade de Processamento é a corrente e não a futura.

Na descrição dos testes e dos resultados, pode-se observar que algumas características são comuns à maioria dos testes, como o tempo de realização do teste, o número médio de pacotes transmitidos (transmissão e recepção), o número de vezes que o teste foi realizado, e o número de vezes que o teste deu o resultado esperado.

Todos esses parâmetros ajudam a descrever quantitativamente os testes.

Para alguns testes, o tempo estimado foi ultrapassado e para outros foi reduzido.

Isso foi devido a problemas encontrados no Icon/Palomino e na API do Service Node, que levaram o desenvolvedor a gastar mais tempo que o esperado.

Neste caso, foi difícil identificar em qual das partes estava o problema.

A metodologia de teste proposta no capítulo 4 descreve em detalhes como executar cada um dos testes.

Neste item, são apresentadas informações específicas dos testes realizados com o novo Sistema de Controle Icon/Palomino.

Testar se o protocolo entre o Sistema de Controle Icon/Palomino e o software do Terminal (Service Node) está de acordo com a especificação, para um número médio de 70 pacotes.

Esse valor foi estimado, experimentalmente, como sendo adequado para garantir que não havia erros no protocolo.

O teste em questão foi executado em várias oportunidades, já que o Sistema de Controle foi testado por partes (Icon e Palomino separadamente).

Cada etapa foi testada com a maioria dos diferentes tipos de transferência de dados, como o acesso a registradores e a troca de informações entre o Terminal e o Sistema de Controle, através do uso de recursos internos como o Refletor, que para cada bit recebido, envia outro idêntico.

Foi escolhido o recurso do Refletor para exemplificar o teste de análise manual do protocolo do Sistema de Controle.

Ilustra um teste, onde 10 pacotes fazem parte da comunicação entre o Terminal e o Sistema de Controle Icon/Palomino do Blue Gene/P.

Inicialmente, são enviados 2 Bytes do Terminal para o Icon, representados pelos números 1 (request 0) e 2 (request 1) respectivamente.

Ao receber os pacotes, o Icon retransmite, imediatamente, os pacotes 3 (reply0) e 4 (reply1), com informações de payload, que estiverem no buffer de saída, incrementando de um o número de seqüência (h_sequence number), que foi para 1759 e 1692.

Esses números são de um pacote exemplo coletado ao longo do teste, Pode-se notar, então, que já havia trafegado 1759 pacotes por uma porta do Icon e 1692 por outra.

Isso é devido à inicialização do Icon/Palomino.

Para usar o chip é necessário enviar um software para iniciá-lo, pois ele não tem nenhum tipo de memória permanente.

Exemplo de Pacotes do Terminal Sistema de Controle para Análise Manual.

O Terminal recebe os pacotes e analisa várias informações do cabeçalho, como número de seqüência, Dropped Bit (marca se o pacote anterior se perdeu na rede), Count Data (marca o tamanho do pacote em bytes), entre outros.

Envia mais dois pacotes, representados pelos números 5 (request 0) e 6 (request 1), com os mesmos números de seqüência dos pacotes recebidos, que estão incrementados de um dos pacotes mandados anteriormente, de acordo com o protocolo do Icon.

Esse protocolo faz parte do controle de perda de pacotes e de pacotes duplicados do Icon/Palomino.

Com o envio e o recebimento de uma quantidade aproximada de 30 pacotes, verificaram-se vários erros na implementação das funções básicas de acesso e no Sistema de Controle.

A maioria dos erros de implementação foi devido às falhas de interpretação da especificação do protocolo do Icon/Palomino.

Além da correção do software, ocorreram situações de erros no documento de especificação.

Assim, o processo de testes ajudou, também, muito na homologação de toda a documentação do projeto.

Através do programa de teste são registrados os cabeçalhos, sendo possível analisar pacote a pacote e se alguns campos importantes estão com os valores corretos.

Neste caso, os campos analisados foram, porta, número de seqüência, Dropped Bit, Count Data entre outros.

O teste foi repetido em várias fases da atividade de teste, isto é, ao longo de vários outros testes, e muitas vezes foram encontrados erros em alguma parte do protocolo do SC ou no software do Terminal.

Os erros eram corrigidos e, em seguida, os testes eram repetidos novamente.

Esses números são apenas referentes aos testes feitos cada vez que a equipe disponibilizava uma nova versão do software.

Nas 14 vezes em que o teste resultou em valores inesperados foram feitas correções no software do Sistema de Controle, ou no software do Terminal ou até na especificação que não estava adequada.

O número de pacotes transmitidos corresponde a uma média de pacotes enviados por teste.

Em alguns testes, onde ocorriam problemas, enquanto não fosse encontrado um padrão do erro, eram transmitidos quantos pacotes fossem necessários, muitas vezes um número superior a 70.

Às vezes, era necessário analisar mais pacotes para encontrar um erro.

Um requisito que não pode ser esquecido era que o tempo para os testes não podia ser muito grande (tempo do processo de teste deve ser menor que o tempo para finalizar a Unidade de Processamento), e esse tipo de teste manual gastava muito tempo.

Para uma análise de 70 pacotes era gasto uma hora e meia em média.

Entrada A documentação de especificação do Sistema de Controle Icon/Palomino, com informações sobre o tipo/formato de dado que ele espera receber e enviar do/para Terminal e da Unidade de Processamento.

Saída Registro, de cada um dos pacotes transmitidos entre as partes (Terminal, SC e SC, UP), para poder verificar se há algum erro na estrutura dos pacotes.

Testar se o protocolo entre o Sistema de Controle Icon/Palomino e o software do Terminal está de acordo com a especificação, para uma quantidade média de 1000 pacotes.

Descrição Como o teste não visava, prioritariamente, a medida do desempenho do Sistema de Controle com o novo software desenvolvido para o Terminal, junto à Unidade de Processamento corrente do BG/L, foi usado um Sniffer via software, Ethereal, Network Protocol Analyser Version 0106, instalado no próprio servidor onde residia o software do Terminal.

A principal funcionalidade testada foi se o protocolo estava sendo executado de maneira correta, com um grande volume de pacotes, aproximadamente 1000, com a mínima interferência do software do Terminal.

Foi feita uma configuração no sniffer, através de filtros, para que fossem coletados apenas pacotes do Terminal para o Sistema de Controle, eliminando outros tráfegos, como por exemplo, broadcast da própria máquina.

Para automatizar o processo de análise do protocolo do Sistema de Controle, foi desenvolvido um programa em C++ que tivesse, como entrada, um arquivo texto com as informações coletadas pelo Sniffer.

O Ethereal tem, como principal função, ler e formatar o cabeçalho de pacotes, que trafegam pela interface de rede do computador, e apresentar, de forma simples, os dados verificados.

Depois de coletadas, as informações eram exportadas para um arquivo texto, em um formato pré-determinado.

O teste usou o dispositivo Refletor para enviar pacotes e receber exatamente os mesmos bits.

A primeira parte do arquivo, que está selecionado por uma elipse, é o cabeçalho do pacote.

O restante são os dados contidos no pacote.

Foi destacada a seqüência aa bb cc dd 99, pois essa é a cadeia de caracteres que foi enviada para o Refletor, e o Sniffer está coletando a resposta, que deve ser idêntica.

Para este teste de automação, não foi utilizada a saída padrão do software do Terminal, que continha a mesma informação.

Foi empregado um novo recurso, o Sniffer, responsável por coletar diretamente o tráfego da rede entre as partes estudadas (Terminal e Sistema de Controle) como uma garantia a mais da corretude do protocolo.

Se fosse usada a saída direta do Terminal, um possível erro na informação poderia ser mascarado pelo software do Terminal.

Parte de um Arquivo Tipo Texto Exportado pelo Sniffer Ethereal.

No início dos testes, a maioria dos erros encontrados foi no próprio script de análise.

Depois de corrigido o script, apenas em dois testes foram encontrados erros no sistema.

Esse tipo de abordagem foi importante para entender erros esporádicos que ocorriam em uma quantidade maior de pacotes.

Como o teste estava mais automatizado, conseguiu-se executá-lo em paralelo com a execução dos outros testes, cada vez que se percebia algum erro estranho no teste corrente que poderia ser devido a algum erro no protocolo.

Como fomos inserindo mais funções como ler registradores, pudemos avaliar outras seqüências e encontrar alguns erros esporádicos.

Entrada Especificação do Icon/Palomino, com informações sobre o tipo/formato de dado que ele espera receber do Terminal e da Unidade de Processamento, informação de como o sistema deve processar os dados, para poder comparar com os resultados.

Um resultado positivo é a resposta do script que analisou os dados coletados pelo sniffer, com alguns dados estatísticos como número de pacotes com Drop Bit, ou número de pacotes de requisições e retransmissões, entre outros, para verificar o protocolo do Sistema de Controle.

Caso o script retorne negativo, é apresentado o tipo do erro e em qual pacote o erro foi cometido.

Por exemplo, uma saída possível é erro no número de seqüência do pacote.

Depois de encontrado qual pacote está apresentado o problema, é iniciado uma análise manual do processo para corrigir o erro.

Testar se a leitura e escrita nos registradores do Icon, que é a primeira camada do Sistema de Controle, estão respondendo de acordo com a especificação.

Descrição Foi desenvolvida uma função na biblioteca do Terminal para acessar registradores do Icon.

A função recebe como parâmetros, o tipo de acesso (leitura ou escrita), o endereço do registrador e um valor, caso o tipo seja escrita.

O teste foi baseado na leitura de alguns registradores do Icon como device identification, build, Card type, status, Control, PHY Management Port Control, PHY Management Port Status, Identify Control, Identify status entre outros.

Como apenas alguns destes registradores têm acesso de escrita, nem todos foram testados alterando-se seu conteúdo.

A descrição completa dos registradores e suas características fazem parte da especificação do Sistema de Controle.

Como a quantidade de registradores não é muito elevada, aproximadamente 50, foi feita uma conferência manual dos valores de retorno do programa de teste com os valores esperados pela especificação.

Durante os testes, foram detectados muitos valores errados, parte decorrente de erros na própria documentação da especificação, e parte referente a problemas no Sistema de Controle.

Caso houvessem centenas ou milhares de registradores na arquitetura do Sistema de Controle, a conferência deveria ter sido automatizada através do software do Terminal.

O tempo gasto para a execução do teste depende diretamente da taxa de transmissão da rede usada para interconectar o Icon e o Service Node.

A quantidade de vezes que o teste é executado depende da quantidade de registradores e da quantidade de erros encontrados, dos mais variados tipos, desde erros de especificação até erros na lógica do Icon.

Lista de registradores e seus conteúdos (quando for apropriado) e funções do Terminal usadas na leitura e escrita nos registradores, passando o endereço do registrador, o tipo de ação (leitura ou escrita), o valor a ser enviado, no caso de escrita, e o valor esperado para verificação.

Saída O software do Terminal apresenta na tela uma lista de registradores do Icon, para que fosse feita a comparação manual dos valores esperados com os obtidos.

A tela é a mesma, independente do tipo de operação realizada leitura ou escrita, pois nos dois casos é necessário verificar o valor final.

Por exemplo, o registrador para identificar qual o valor adotado pelo Icon para a velocidade da rede é Ethernet Link Speed, que neste caso é 100 Mbps.

Saída do Programa do Terminal Referente à Leitura dos Registradores do Icon.

Testar se a leitura e escrita nos registradores do Palomino, que é a segunda camada do Sistema de Controle, estão respondendo de acordo com a especificação.

Descrição Foi desenvolvida uma função na biblioteca do Terminal para acessar registradores do Palomino.

A função recebe como parâmetros, o tipo de acesso (leitura ou escrita), o endereço do registrador e um valor, caso o tipo seja escrita.

O teste é muito similar ao teste anterior, com os registradores do Icon e valem as mesmas informações e orientações.

Também foram feitos testes de escrita nos registradores, que permitiam esse tipo de operação.

O tempo gasto para a execução do teste depende diretamente da taxa de transmissão da rede usada para interconectar o Sistema de Controle e Service Node.

A quantidade de vezes que o teste é executado depende da quantidade de registradores e da quantidade de erros encontrados, dos mais variados tipos, desde erros de especificação até erros na lógica do Palomino.

Apesar da quantidade de registradores do Palomino ser maior do que do Icon, a quantidade de erros encontrados neste teste foi menor que no teste dos registradores do Icon.

Isso ocorreu devido às correções que foram feitas no primeiro teste, que refletiram diretamente no segundo.

Lista de registradores e seus conteúdos (quando for apropriado) e funções do Terminal usadas na leitura e escrita nos registradores, passando o endereço do registrador, o tipo de ação (leitura ou escrita), o valor a ser enviado, no caso de escrita, e o valor esperado para verificação.

Saída O software do Terminal apresenta na tela uma lista de registradores do Palomino, para que fosse feita a comparação manual dos valores esperados com os obtidos.

A tela é a mesma, independente do tipo de operação de leitura e escrita, pois nos dois casos é necessário verificar o valor final.

Saída do Programa do Terminal Referente à Leitura dos Registradores do Palomino.

Por exemplo, destaca qual a data de alteração dos seus registradores, através do registrador TypeA Build Register Contents que é 07 de Abril de 2005.

Testar se todos os bits enviados para o Refletor do Palomino são retransmitidos na mesma ordem e com o mesmo valor, isto é, de forma idêntica para o software do Terminal.

Esse teste serviu de apoio para os testes de análise de protocolo, desta maneira, foram verificados os pacotes e se o caminho e o roteamento das informações estavam corretos.

O dispositivo de Refletor dentro do Palomino, para o programa teste do Service Node, é uma forma de simular a Unidade de Processamento, já que o Palomino vê o Refletor como mais um dispositivo, como se fosse mais um processador do Blue Gene.

A única diferença é que o Refletor não processa informação nenhuma e só retransmite o que ele recebe.

Para o teste, foram enviadas varias seqüências de valores e foi analisado se os valores recebidos eram sempre idênticos.

Dada um conjunto de caracteres, por exemplo, de ad be aa bb cc dd, e a quantidade de vezes que precisa ser repetido, o programa cria uma cadeia de caracteres e envia para o dispositivo.

Depois, coleta a resposta e imprime na tela.

O tempo gasto para a execução do teste depende diretamente da taxa de transmissão da rede usada para interconectar o Sistema de Controle e o Service Node.

O número de pacotes enviado é calculado pelo programa dependendo da quantidade de bits que o teste vai enviar ao Refletor.

Uma cadeia de dados e a quantidade de vezes que é necessário repetí-la, para que seja enviada e recebida para/de o Refletor, pelo programa de teste do Service Node.

Saída Comparação entre os valores recebidos e enviados ao dispositivo de Refletor do Palomino, através da visualização do retorno dos dados mostrados pelo programa de teste.

Está destacado uma das dez palavras de ad be aa bb cc dd, que foi enviada pelo Terminal ao Palomino e voltou para o Terminal.

Saída do Programa do Terminal Referente ao Dispositivo Refletor do Palominio.

Verificar como a variação da MTU (Maximum Transmission Unit) da rede interfere na taxa de transmissão dos pacotes do Service Node para o Icon/Palomino e vice-versa.

Era esperado pelos engenheiros do Blue Gene, que projetaram o Sistema de Controle, que quanto maior for a MTU da rede, maior seja a taxa efetiva de transmissão dos dados.

Descrição Foi escolhida uma cadeia de caracteres com um tamanho de 335 k Bytes, que é a imagem usada diariamente para reiniciar o Blue Gene / L.

A MTU da rede variou desde 96 Bytes até 4 K bytes, que são os limites inferior e superior suportados pelo Icon/Palomino.

Como a MTU da rede ligada ao Sistema de Controle só pode ser configurada na fase de iniciação do Icon/Palomino, foi criado um programa para executar essa configuração.

Esta configuração é feita através da reinicialização do Sistema de Controle, variando de 8 em 8 bytes a MTU da rede e armazenando os dados coletados do tempo de transmissão da imagem versus o tamanho da MTU.

Para cada MTU, foram enviadas quatro vezes a mesma imagem e calculada uma média para registrar o tempo médio gasto na transmissão.

O tempo gasto para a execução do teste é variável, dependendo da MTU configurada, e o número total de pacotes é fixo, pois o dado transmitido, imagem de inicialização de um chip no Service Card, é sempre o mesmo.

Para cada tamanho diferente configurado de MTU da rede foi registrado seu valor e o tempo gasto na transmissão da mesma imagem.

Variação do MTU da Rede X Tempo de Transmissão.

O teste mostrou que quanto maior a MTU da rede, o Icon/Palomino mais lentamente envia a imagem, apesar de ser um tempo menor que o da versão corrente que gasta em média 800 mseg.

Esse resultado é oposto ao esperado pelos desenvolvedores.

Eles imaginaram que quanto maior a MTU da rede, maior seria a taxa de transmissão da rede.

Após inúmeras análises na lógica do Icon/Palomino, os engenheiros levantaram a hipótese de ser necessário fazer algum ajuste nos buffers internos do SC, alterando o tamanho dos buffers e seu algoritmo de controle, mas que iriam deixar para fazer esse ajuste mais preciso com a nova versão da UP, caso fosse necessário melhorar ainda mais o seu desempenho.

Executar a leitura e escrita de registradores por um tempo maior que a operação normal do Blue Gene, para avaliar o comportamento do sistema.

Foram escolhidas essas operações por serem rotineiras ao supercomputador.

Os desenvolvedores da nova versão do Blue Gene, baseados na experiência das operações realizadas com a versão corrente, propuseram a operação de leitura e escrita em registradores e o período de execução, para ser muito maior que as operações normais do Blue Gene, que fosse aproximadamente 15 horas.

Executar um programa para testar se o Sistema de Controle consegue responder por mais de 15 hs contínuas uma requisição de leitura e escrita de dois registradores via JTAG do cartão de serviço do BG/L.

Esse tempo foi estimado junto aos engenheiros do projeto, considerando-o bastante alto para este tipo de operação do Blue Gene.

O teste foi feito, variando-se entre a leitura e a escrita de dois registradores e recebendo os resultados para validação da sua corretude.

O tempo gasto para a execução do teste foi todo o período que o sistema ficou sob o controle das interações com os registradores.

O número de pacotes é igual ao número total de pacotes transmitidos pela rede, considerando-se todas as operações com os registradores.

Registrador IDCODE (armazena ID do chip) de leitura com o valor padrão para comparação e Registrador Boundary Scan para escrita com um valor fixo que possa ser comparado após a alteração do registro.

O período de tempo estimado pelos engenheiros do Blue Gene.

Os contadores internos do programa registram o número total de operações e o tempo total gasto.

Todas as operações foram executadas com sucesso.

Foi testada a leitura dos registradores IDCODE e USERCODE (ambos registradores de identificação do chip) de um chip FPGA do cartão de serviço.

Através do Service Node, foram lidos esses dois registradores e os valores obtidos foram comparados com os valores definidos pelo fabricante.

O segundo teste foi executado através da leitura do registrador Boundary Scan da mesma FPGA.

Através da lógica do cartão de serviço, três chaves de controle sensibilizavam alguns pinos do chip da FPGA, com valores entre 0 e 1.

Como foi apresentado, o registrador Boundary Scan observa os sinais que estão nos pinos do chip.

O teste foi realizado através da codificação de alguns valores com as chaves de controle.

Após a configuração, é feita a leitura do registrador Boundary Scan para conferir se os valores estão corretos.

Com este teste pode-se ter certeza que uma das principais operações do Sistema de Controle do Blue Gene está funcionando, que é a leitura de registradores.

O tempo gasto para a execução do teste é uma relação entre o tempo (que é fixo como o melhor tempo do protocolo) do JTAG de acesso ao registrador pela rede e o tamanho do registrador que está sendo lido, assim como o número de pacotes é uma relação entre o tamanho do registrador e o tamanho máximo do pacote Icon (64 bits).

O teste necessita do endereço dos registradores IDCODE e USERCODE e seu valor padrão para conferência posterior.

Além disso, é preciso ter o endereço do registrador Boundary Scan e os valores para configurar as chaves de controle, para saber qual valor é inserido em qual pino do chip do cartão de serviço.

Saída O software do Terminal apresenta na tela os valores dos registradores para validação.

Testar a escrita no registrador Boundary Scan do cartão de serviço da Unidade de Processamento corrente do Blue Gene/L.

Através da escrita no registrador Boundary Scan são configurados sinais específicos nos pinos do chip.

Este chip controla uma seqüência de LEDs no cartão de serviço.

Então, através da manipulação do registrador, o chip foi configurado de maneira a sinalizar para os LEDs que piscassem de forma sincronizada.

Com este teste pode-se ter certeza que uma das principais operações do Sistema de Controle do Blue Gene está funcionando, que é a escrita em registradores.

O tempo gasto para a execução do teste e o número de pacotes na rede é relacionado com o tamanho do registrador Boundary Scan que possui 1266 bits e a velocidade do JTAG para acesso ao registrador pela rede.

É preciso do endereço do registrador Boundary Scan e os valores para configurar os pinos do chip corretamente para sensibilizar os LEDs.

Saída Se os LEDs piscarem de maneira controlada, indica-se que o teste foi executado com sucesso.

Verificar o desempenho do novo Sistema de Controle para iniciar um chip FPGA no cartão de serviço, através do envio de uma imagem pelo Service Node.

A versão atual do sistema já executa esta tarefa com o iDo e o tempo de transmissão é 800 mseg.

Através de uma seqüência de instruções, é configurado o JTAG da FPGA em modo de recebimento da imagem para iniciá-la.

Em seguida, a imagem de inicialização de 355 K Bytes é enviada para seu alvo, um chip FPGA no cartão de serviço, pelo Icon/Palomino.

Esse software de imagem de 355 K é o mesmo usado no Blue Gene atual.

Através dele é inicializado todo o cartão de serviço do Blue Gene corrente.

O teste foi executado, com a rede entre o Sistema de Controle e o Service Node, operando a uma taxa de 100 Mbps, 1000 Mbps e 1000 Mbps com um switch Jumbo Frame, para avaliar o 24 tempo de transmissão em diferentes ambientes.

Além disso, a taxa de transmissão do JTAG também foi variada, através da configuração de alguns registradores no Icon/Palomino.

O ajuste final foi feito de modo a obter a taxa que oferece melhor desempenho do JTAG para transmissão da imagem.

O teste foi realizado com essas variações e os valores de tempo de transmissão armazenados, de acordo com a taxa do JTAG e a velocidade da rede do Service Node.

O tempo gasto para a execução do teste é referente a apenas 1 teste executado de cada vez, com um valor fixo do JTAG e da velocidade da rede.

O teste foi executado de forma manual, variando-se esses parâmetros através de configurações manuais no Icon/Palomino e troca de equipamentos de rede.

O arquivo de imagem do chip FPGA que inicia o cartão de serviço do Blue Gene corrente, com tamanho de 355 K e a especificação de configuração dos registradores com as taxas de transmissão/recepção do JTAG.

Através da coleta dos tempos de transmissão da imagem, variando-se a taxa do JTAG e a velocidade da rede do Service Node, foi construída para apresentar o desempenho do Icon/Palomino.

Desempenho do JTAG em Diferentes Redes entre o SC e Terminal.

TCK Freqüência, Taxa de transmissão/recepção do JTAG (Limite da comunicação entre o Service Node e a Unidade de Processamento).

É a taxa do protocolo JTAG.

Através do tamanho exato da imagem de 342709 Bytes, foi feito o cálculo do tempo necessário para sua transmissão.

Exemplo, TCK Freq JTAG = 833 Tempo Transmissão = (1 / 833) * (342709 * 8) = 329 As outras três colunas apresentam o valor de transmissão da imagem, variando-se a velocidade da rede Ethernet com o Service Node.

O resultado mostra que essa variação não tem nenhuma influência na velocidade de transmissão da imagem, pois, dado uma freqüência do JTAG, para as três variações de rede (100 MBps, 1000 Mbps e 1000 Mbps com Jumbo Frame) o valor do tempo de transmissão calculada (ideal) é muito próximo ao valor do tempo de transmissão nas três redes.

Por exemplo, para freqüência JTAG de 16,67 MHz, o tempo de transmissão calculado é 164,52 segundos.

Para a rede de 100 Mbps o tempo verificado foi de 163,30 segundos.

Para a rede de1000 Mbps, o tempo foi de 162,4 segundos e para a rede de 1000 Mbps com Jumbo Frame, o tempo foi de 161,9 segundos.

Uma questão que surge é porque os valores registrados pelo programa do Service Node apresentam valores de transmissão ligeiramente melhores que os valores calculados, que teoricamente são os melhores valores que se pode conseguir na transmissão da imagem.

Depois de análises da lógica interna do Icon/Palomino e do programa de teste, percebeu-se que o Icon envia o último pacote informando o Service Node que a imagem já está entregue com sucesso e esse é o tempo registrado.

Na verdade, o Icon ainda tem que enviar os últimos bytes da imagem para o Palomino, que estão em seus buffers internos, que por sua vez carrega a imagem na Unidade de Processamento.

Quando registramos o tempo através do programa, ainda há dados, a serem enviados para o chip, que estão armazenados temporariamente nos buffers internos do Icon/Palomino.

Isso explica o tempo ligeiramente diferente entre o tempo medido e calculado.

A diferença média entre os tempos é de 1,5 segundo, o que corresponde a 1,5% de erro.

O resultado mais importante do teste é a taxa de transmissão da imagem no melhor caso, pois esse foi o parâmetro adotado pela metodologia para a comparação entre o desempenho do Sistema de Controle corrente do Blue Gene, iDo, e o novo Sistema de Controle Icon/Palomino.

O tempo para essa operação na atual versão do SC é conhecido.

Através dos testes, foi descoberto qual o novo tempo de transmissão da imagem com o novo SC.

A nova versão do Sistema de Controle, Icon/Palomino, transmite em uma velocidade 2,5 vezes mais rápida que a versão corrente do iDo.

Isso significa que a nova versão, comparada com a atual, é mais eficiente.

Este teste é muito valioso pois, pela primeira vez desde que o novo Sistema de Controle foi desenvolvido, foi provado que ele é mais eficiente que a versão corrente.

Tempo para enviar a imagem com iDo em BG/L, 800 mseg.

Tempo para enviar a imagem com Icon/Palomino, 269 mseg.

A metodologia de testes descrita no capítulo 4 foi aplicada no desenvolvimento da nova versão do sistema de processamento paralelo, o supercomputador da IBM Blue Gene para comprovar que a metodologia proposta resolve o problema em estudo, que é a redução do tempo de desenvolvimento de sistemas de processamento paralelo.

As quatro etapas da metodologia foram seguidas de acordo com a descrição do capítulo 4, na primeira etapa foi feito o planejamento, na segunda etapa foi desenvolvido o software do Terminal, na terceira etapa foi feita a execução dos testes, e na quarta e última etapa a análise dos resultados dos testes.

A metodologia propõe que sejam executados 8 testes na nova versão do Sistema de Controle.

Porém, ela prevê que alguns testes sejam divididos em outros testes semelhantes.

Esse foi o caso do teste do registrador do SC, que foi separado em dois, dado que a nova versão do SC tem dois componentes internos, o Icon e o Palomino e precisam de testes isolados dos seus conjuntos de registradores.

O segundo teste que foi dividido foi o teste da Unidade de Processamento.

Para testar a UP, foi definido que eram necessários dois testes, Teste de escrita do registrador Boundary Scan e Teste de iniciação de uma FPGA do cartão de serviço.

Aplicando-se a análise de otimização de tempo de projeto aos tempos gastos no desenvolvimento da nova versão do Blue Gene, depois de aplicado à metodologia de testes proposta, pode-se estimar a redução de tempo total do projeto.

Esse valor é estimado, pois a nova versão do Blue Gene ainda está em desenvolvimento.

Tempos Estimados para o Desenvolvimento do novo Supercomputador Blue Gene.

Com os valores de tempo descritos pode-se calular os três tempos de otimização de desenvolvimento de projetos, tempo de desenvolvimento seqüencial T1, tempo de desenvolvimento com um nível de otimização T2, e tempo de desenvolvimento com um segundo nível de otimização, ou maior nível de otimização T3.

Como resultado da aplicação da metodologia, tem-se o tempo T3.

A economia de tempo de T3 em relação a um projeto de desenvolvimento seqüencial T1, é de 41% e a economia em relação ao primeiro nível de otimização é 13%.

Com isso, pode-se mostrar que com a aplicação da metodologia de testes proposta em sistemas de processamento paralelo pode-se diminuir o tempo total de desenvolvimento do projeto.

São descritas as principais contribuições e inovações sobre a proposta de solução da metodologia de testes para redução de tempo de desenvolvimento de novas versões de sistemas de processamento paralelo.

O trabalho realizado sobre uma metodologia de teste de sistemas de processamento paralelo traz algumas contribuições importantes em uma área de poucos trabalhos.

A contribuição inovadora, que pode ser destacada neste trabalho, é a definição de uma metodologia de testes para sistemas de processamento paralelo.

A solução é baseada na estratégia de testes em paralelo com o desenvolvimento que, como apresentada no capítulo 4, reduz o tempo total de desenvolvimento de sistemas.

Um desafio encontrado nesta estratégia é o teste, foi executar testes de integração entre uma nova versão do Sistema de Controle finalizada, enquanto a nova versão da Unidade de Processamento ainda está em desenvolvimento.

O capítulo 4 endereça esse problema e apresenta uma solução para os testes de integração, que utiliza a versão corrente da Unidade de Processamento.

Para a aplicação efetiva da metodologia, foi importante a modelagem em três componentes bem delimitados, com funções definidas e interfaces de entrada e saída.

Essa é uma tarefa que deve ser feita no inicio do projeto e com muito cuidado, pois sem a definição se é viável separar o Sistema de Controle dos outros componentes, não é possível aplicar a metodologia de testes proposta.

Para ajudar na modelagem do sistema de processamento paralelo, deve-se focar o componente principal da metodologia que é o Sistema de Controle.

Delimitar suas funções e interfaces de entrada e saída é a parte mais complexa, pois é preciso limitar um escopo de atuação do Sistema de Controle.

Por exemplo, o Sistema de Controle pode estar distribuído em alguns chips dentro de um sistema maior.

Entender bem as funcionalidades e interfaces de interação com outros componentes é fundamental para modelar sistemas de processamento paralelo e isolar o Sistema de Controle.

Após o Sistema de Controle estar bem delimitado e os outros componentes definidos, cada um com suas interfaces de entrada e saída, é preciso analisar o tempo de desenvolvimento de cada componente de maneira isolada.

O tempo de desenvolvimento para a finalização da Unidade de Processamento deve ser suficiente para que seja possível aplicar a metodologia de testes na nova versão do Sistema de Controle.

Esta análise é feita durante a etapa de planejamento descrito na metodologia.

No Blue Gene, através de reuniões periódicas com os gerentes de projetos, foi estimado o tempo necessário para finalização da Unidade de Processamento.

Devido a sua complexidade, muitas equipes estavam alocadas para o projeto e através de reuniões com cada equipe foi possível estimar o tempo total para terminar a nova Unidade de Processamento.

Esse tempo é fundamental para a metodologia, pois define o tempo que será gasto para sua aplicação no novo SC.

Ao definir e estimar os tempos de desenvolvimento de cada componente do sistema de processamento paralelo é fundamental que seja viável uma integração entre a nova versão do Sistema de Controle e a atual versão da Unidade de Processamento.

No caso do Blue Gene, juntamente com a estimativa dos tempos, já foi planejado como seria feito a conexão entre a nova versão do Sistema de Controle e a atual versão da Unidade de Processamento.

A equipe de teste se reuniu com os engenheiros responsáveis pelas duas versões do Sistema de Controle.

Depois de analisar detalhadamente os tipos de protocolo que cada versão gerenciava e quais os sinais que eram controlados pelo SC, foi definido que o melhor teste seria utilizar um protocolo comum às duas versões e com papel fundamento no gerenciamento da Unidade de Processamento.

Desta maneira foi escolhido o protocolo JTAG e definido um cabo especial para conexão de todos os sinais de controle, incluindo alimentação elétrica, que é transmitido do Sistema de Controle para Unidade de Processamento.

Para finalizar as definições da etapa de planejamento, foram especificados alguns casos de teste que seriam mais apropriados para testar as funcionalidades do Sistema de Controle.

Na aplicação da metodologia, no capítulo 5, depois de todas as definições da etapa de planejamento, onde os testes com a nova versão do Sistema de Controle são feitos antecipadamente e em paralelo com o desenvolvimento da Unidade de Processamento, foi possível obter uma redução no tempo total do projeto e testar a própria metodologia proposta.

Os resultados mostraram que a metodologia pode ser replicada em sistemas de processamento paralelo, como o supercomputador Blue Gene da IBM, desde que sigam os requisitos da solução descritos no capítulo 4.

Através de dados coletados do projeto Blue Gene, pode-se estimar a economia no tempo total de desenvolvimento do projeto.

Como mostrado no capítulo 5, o tempo médio estimado que seria gasto no projeto Blue Gene caso todo desenvolvimento fosse seqüencial seria de 68 meses.

Com um primeiro nível de otimização, através da execução de alguns componentes em paralelo com o desenvolvimento, o tempo gasto seria de 46 meses.

Depois da aplicação da metodologia, o tempo total gasto com o desenvolvimento foi de 40 meses.

Consequentemente, a porcentagem de redução de tempo total do projeto do Blue Gene, como mostrado no capítulo 5, depois de aplicado à metodologia de testes proposta em relação a um projeto de desenvolvimento seqüencial é de 41% e em relação a um primeiro nível de otimização é de 13%.

O desenvolvimento serial de todos os componentes é o pior cenário, pois gasta mais tempo para ser desenvolvido.

Apesar disso, os recursos necessários para execução do projeto são utilizados de forma mais homogênea, pois só é utilizado um recurso para o desenvolvimento e teste de algum componente, quando o anterior já estiver finalizado.

Com a paralelização das atividades de desenvolvimento e teste dos componentes, apresentado nos dois níveis de otimização de tempo, os recursos devem estar disponíveis de maneira simultânea, desde o inicio do projeto.

Porém, o término do projeto é concluído em um tempo mais curto.

A redução do tempo total de desenvolvimento de sistemas através da redução ou otimização dos testes é um tema bastante polêmico e que possui muitas propostas de solução, como as apresentada no capítulo 2, que são, execução de testes em paralelo, execução de testes em paralelo com o desenvolvimento de sistemas, automação de testes, simulação entre outras técnicas.

Cada técnica é aproveitada de maneira mais otimizada de acordo com o tipo de sistema de precisa ser testada e muitas vezes podem são complementares.

O tipo de teste ou a quantidade de testes que são feitos em sistemas são diretamente relacionados ao custo dos testes, ao tempo que leva para planejamento e execução e a criticidade do sistema.

No projeto do Blue Gene, mais de uma técnica foi adotada para reduzir o tempo total da nova versão do supercomputador.

Além da metodologia apresentada que executa testes em paralelo com o desenvolvimento, também foram adotados simuladores e automação de testes.

Dado a importância do Blue Gene, que é o computador mais rápido do mundo (TOP500, 06), atingindo o desempenho de 2806 TFlop/s, a aplicação da metodologia para testar seu Sistema de Controle pode ser considerada uma contribuição.

Através dos testes, foi possível corrigir muitos erros antecipados no novo Sistema de Controle e colaborar para a redução do tempo final de desenvolvimento do Blue Gene.

Um ponto muito interessante, que resultou do trabalho de testes do Sistema de Controle foi uma homologação detalhada na documentação do Sistema de Controle, desde a especificação do Icon/Palomino, como a documentação do protocolo JTAG, já que todos esses documentos foram necessários para o desenvolvimento do software do Terminal.

Assim, a metodologia apresentada acaba por contribuir com o refinamento e correção da própria especificação do sistema projetado e em teste.

O capítulo 2 apresenta uma análise sobre algumas técnicas de teste com foco em redução de tempo de desenvolvimento de software, baseado na diminuição do tempo de teste, que correspondem a 40% do tempo total do projeto.

O capítulo 5 apresenta uma descrição sobre a arquitetura do Blue Gene e o protocolo JTAG de maneira didática, que podem ser usados pela comunidade acadêmica como fonte de consulta sobre esses assuntos.

Um resultado que também pode ser destacado sobre a pesquisa para reduzir tempo de desenvolvimento de sistemas foi a publicação de um artigo, mostrando o estudo de caso da redução de tempo do desenvolvimento do supercomputador Blue Gene.

A evolução do trabalho apresentado nesta tese pode seguir várias direções.

A primeira é aplicar a metodologia em outros sistemas de processamento paralelo e ajustar os casos de testes, para abranger o maior número de situações de falha possível.

A segunda é adaptar a metodologia para ser usada para melhorar a qualidade dos Sistemas de Controle (SC) de qualquer versão de sistemas de processamento, incluindo a primeira versão.

A terceira é melhorar a estratégia de testes, através da automação total ou parcial dos testes.

A quarta é estender a metodologia a sistemas genéricos que possuem algum tipo de Sistemas de Controle como parte de seus componentes.

A aplicação da metodologia em outros sistemas de processamento paralelo que seguem o mesmo modelo de três componentes, Terminal, Sistema de Controle e Unidade de Processamento, é uma oportunidade de melhorar e ajustar os casos de teste.

Desta maneira, a metodologia fica mais abrangente e pode ser usada em um número maior de projetos.

Uma oportunidade para otimizar a metodologia é estudar alguns ajustes nos casos de testes, para aumentar a qualidade de Sistemas de Controle (SC) em máquinas de processamento paralelo, já na primeira versão.

Não será possível a execução de testes de integração, mas testes referentes ao próprio Sistema de Controle podem ser executados de maneira mais sistêmica, através do guia de testes que a metodologia fornece.

Desta maneira, o conhecimento adquirido com as atividades de teste não fica dependente das pessoas envolvidas em um ou outro projeto, mas está registrado através da metodologia de testes e pode ser replicado com mais eficiência.

A automatização é outra opção interessante para se estudar.

Até que ponto pode-se automatizar os casos de teste descritos na metodologia?

Quais são os ganhos de economia de tempo e qualidade na execução dos testes versus o tempo de automatização?

O tempo deve ser bem estimado, pois há um prazo para execução dos testes que é entre a conclusão do Sistema de Controle e o término do desenvolvimento da Unidade de Processamento.

Testar componentes importantes do sistema de processamento paralelo, como Sistemas de Controle, com antecedência para reduzir o tempo de projeto, pode ser abstraído de maneira genérica, para outros tipos de Sistemas de Controle, sem necessariamente ser um componente de sistemas de processamento paralelo.

A metodologia pode ser expandida para a redução de sistemas que possuam algum tipo de Sistema de Controle com funções semelhantes ao apresentado na tese como controlar a comunicação, monitorar e gerenciar algum tipo de hardware ou software.

Os requisitos da solução devem ser ajustados para se tornarem mais genéricos, mas os critérios básicos para a utilização da metodologia devem ser mantidos.
Modelagem em componentes para que o Sistema de Controle seja testado em separado.
Testes com a nova versão do Sistema de Controle devem ser executados antes do término do desenvolvimento de outros componentes mais complexos, a interface do novo Sistema de Controle deve ser compatível com a atual interface de outros componentes do sistema, executar uma análise para saber se o custo associado para que o novo Sistema de Controle seja compatível com o atual componente, que ainda está em desenvolvimento, é considerado menor que o ganho em aplicar a metodologia.

