Sistemas de memória compartilhada distribuída DSMs podem ser implementados completamente em software.

Esses sistemas conhecidos como software DSMs exibem um baixo custo e portanto representam uma alternativa atraente para computação paralela.

Entretanto software DSMs puros atingem alto desempenho numa classe restrita de aplicações.

O sistema paralelo NCP introduz a segunda geração de computadores de alto desempenho da COPPEUFRJ a qual investiga a utilização de hardware simples e de baixo custo para otimizar software DSMs.

Esse hardware consiste de controladores de pro tocolo programaveis que permitem a implementação de tecnicas de tolerância a latência de comunicação e a overheads de processamento de coerência.

Nossas simulações revelam que os nossos controladores de protocolo melhoram o desempenho de TreadMarks em processadores.

Esses resultados sugerem que o NCP exibira uma otima relação custodesempenho numa grande gama de aplicações proporcionando uma opção tecnológica muito boa para investimentos nacionais em computação de alto desempenho.


Nos ultimosanos temcrescidosignicativamenteo interessepor sistemas dememória compartilhada distribuída DSM.

Esses sistemas permitemintegrar a escalabilidade de memórias distribuídas com a maior facilidade de programação de multiprocessadores tais como DASH e Alewife.


Em constraste com esses multiprocessadores os sistemas denominados software DSMs SWDSMs mantem a coerencia de dados em software e oferecem aos programadores a ilusao de uma memória com partilhada sobre um hardware que so permite troca de mensagens SWDSMs proveem uma alternativa de baixo custo para a computação no modelo de memória compartilhada visto que o sistema pode ser formado por estações de trabalho e sistemas operacionais padrao.

No entanto sao poucas as classes de aplicações que alcancam um bom desempenho nestes sistemas.

Isto se deve a uma alta taxa de comunicação e ao overhead gerado pela manutenção da coerencia dos dados.

O primeiro sistema de computação paralela desenvolvido pela COPPEUFRJ e operacional em pertencia a classe dos multicomputadores.


Alem de representar um marco de referencia no esforco de desenvolvimentocientco e tecnológico nacional a experiencia do NCP I permitiu romper barreiras tec nologicas na area de computação de alto desempenho e proporcionou lições que habilitaram o atual projeto NCP.

Tal como o NCP I o NCP e também um multicomputador mas que adiciona suporte especializado de hardware simples e de baixo custo para suportar SW DSMs ecientemente.

Dessa forma o sistema pode atingir alto desempenho numa variedade maior de aplicações do que um SWDSM puro.

O prototipo atualmente em desenvolvimento incorpora as tecnologias de microprocessadores PowerPC o sistema operacional Unix e uma rede de interconexao Myrinet SWDSMs como TreadMarks.

Estimase que o NCP tera desempenho uma ordem de grandeza superior ao do NCP I.

A organização deste artigo e a seguinte.

A seção da uma visao geral das principais caractersticas de SWDSMs e seus principais overheads.

Na seção descrevemos o hardware e o software do NCP ressaltando a solução inovadora que ele introduz por utilizar nossos controladores de protocolo programaveis.

Na seção comparamos o desempenho de TreadMarks modicado para um sistema semelhanteao NCP com o de TreadMarks puro atraves da simulações de aplicações reais.

Nossos resultados preliminaresmostramque os controladores de protocolo que propomos podem melhorar a performance de TreadMarks em processadores.

A maior parte dos SWDSMs realiza a manuntenção da coerencia a nvel de pagina atraves dos bits de proteção da memória virtual.

Alem disso tendo como objetivo solucionar o problema de falso compartilhamento de paginas DSMs modernos per mitem a escrita simultanea na mesma pagina por varios processadores garantindo a consistencia de memória somente nos pontos de sincronização.

Este adiamento da manutenção da consistencia e denominado consistencia relaxada TreadMarks e um sistema que mantem a consistencia usando Lazy Release Consistency.


Em TreadMarks as invalidações das paginas alteradas por outros processadores ocorrem nos pontos de aquisição de locks.

Entretanto as modicações ou dis das paginas invalidadas so sao requeridas na ocorrencia de um page fault.

Neste momento sao enviados pedidos de modicações aos processadores que escreveram por ultimo na pagina.

As alterações que precisam ser coletadas pelo processador que adquiriu o lock sao determinadas atraves da divisao da execução em intervalos onde cada intervalo e associado a um vetor de timestamps.

Este vetor descreve uma ordem parcial entre intervalos de processadores distintos.

O processador que adquire um lock so pode continuar sua execução depois de coletar todas as atualizações referentes a intervalos cujo vetor de timestamps e menor que o seu.

O ultimo dono do lock e o responsavel pela comparação do seu vetor de timestamps com o do novo acquirer e pelo envio de write notices que indicam a alteração de uma pagina por um processador em um determinado intervalo.

Quando ocorre um page fault o processador percorre sua lista de write notices para determinar quais os dis necessarios a atualização da pagina.

Uma descrição mais detalhada de TreadMarks pode ser encontrada.

Os principais overheads em SWDSMs estao relacionados a latencia de comu nicação e a manutenção de coerencia.

Latencias de comunicação retardam a ex ecução e portanto reduzem o desempenho do sistema.

Ações de coerencia geração e aplicação de dis geração de twins e manipulação de diretorios também po dem afetar o desempenho negativamente ja que elas nao realizam trabalho util e geralmente estao no caminho crtico das aplicações.

O impacto dos overheads de comunicação e coerencia e ampliado pelo fato de que processadores remotos sao envolvidos em todas essas transações.

O sistema NCP segue os princpios gerais de projeto do NCP I.

Ambos os projetos tem como objetivos principais a simplicidade do hardware e a maximização das suas contribuições cientcas e tecnológicas.

No entanto a maior complexidade das tecnologias envolvidas em projetos arquiteturais recentes como o NCP demandam uma maior dependencia de sistemas de desenvolvimento CAD.

Em termos de de sempenho estimase que o NCP sera uma ordem de grandeza mais veloz do que o NCP I.

Esperamos ainda que o modelo de programação mais simples do NCP simplique a implementação de aplicações paralelas complexas em comparação ao NCP I.

Nas proximas seções descrevemos as tecnologias envolvidas no projeto NCP e as principais caractesticas do hardware e do software do sistema.

O projeto NCP contempla o desenvolvimento em tres anos de hardware de dois prototipos com processadores.

O primeiro prototipo do sistema utiliza o micro processador PowerPC MHz SPECint e o SPECfp e o segundo utilizara o PowerPC.

O NCP incorpora ainda o sistema operacional Unix.

AIX enquanto que a rede de interconexao e a Myrinet Mbytess de banda passante e us de latencia.

Alem disso o sistema usa o barramento PCI e a interface SCSI em cada unidade de processamento. 

O projeto licenciou também o SWDSM TreadMarks que sera adaptado ao NCP.


Como mostra a gura o suporte de hardware que propomos e um controlador de protocolos associado a cada no de uma rede de workstations ou de um multicomputa dor.

No nosso sistema tanto o controlador de protocolos como a interface de rede estao conectadas ao barramento PCI.

Como mostra a gura nosso controlador de protocolos inclui um microprocessador ou simplesmente um nucleo RISC inteiro Mbytes de DRAM e dois modulos de hardware especcos a logica para snoop ing do barramento de memória e um dispositivo DMA sosticado.

A comunicação entre o processador e o controlador na maior parte dos casos e realizada atraves da memória local do controlador e o snooping dos acessos de escrita.

O processador principal dispara pedidos explcitos ao controlador local e continua a sua execução normalmente a menos que o atendimento do pedido seja necessario imediatamente.

Os pedidos locais e quaisquer pedidos provenientes de controladores remotos sao enleirados na memória local enquanto aguardam o atendimento.

Transações que necessitam de intervenção de nos remotos sao divididas em tres partes pedido acesso e resposta que podem ser intercaladas com outras transações no controlador de protocolo.

Pedidos podem receber prioridades de tal modo que pedidos com alta prioridade podem passar a frente de pedidos de baixa prioridade.

Este esquema de prioridades e usado para evitar que operações de prefetch atrasem pedidos dos quais o processador depende para prosseguir a execução.

O controlador de protocolos pode se comunicar com o processador principal por interrupção quando for necessario.

Interrupções ao processador principal devem ser evitadas para nao prejudicar o desempenho mas podem ser utilizadas para evitar que operações complexas tenham que atravessar o barramento PCI para alcancar a memória principal.

De fato a relação entre a velocidade do processador principal e a do controlador e uma questao importante um processador principal muito rapido fornece outra justicativa para que nele sejam executadas as partes complexas do codigo de protocolo.

Tanto o processador como o controlador de protocolos realizam snooping no barramento de memória.

O processador realiza snooping para invalidar dados es critos pelo controlador de protocolos diretamente na memória principal no caso da aplicação de um di remoto em uma pagina local por exemplo.

O controlador de protocolos realiza snooping para computar dis dinamicamente.

Isto e conseguido forcando a cache a escrever dados compartilhados no barramento e mantendo um registro na memória do controlador de todas as palavras que foram modicadas em uma pagina.

Este registro e mantido sob a forma de um vetor de bits onde cada bit representa uma palavra de dados.

Sempre que o controlador de protoco los detecta que o processador principal escreveu uma palavra simplesmente ativa o bit correspondente para registrar o evento.

Posteriormente quando e requisitado ao processador o di de uma pagina nosso dispositivo DMA checa quais bits estao ativados le as palavras correspondentes da memória e retorna como resultado do di as palavras modicadas e o vetor de bits.

O di pode ser mantido na memória para uso posterior.

A geração de um di provoca a desativação de todos os bits do vetor.

A aplicação do di também envolve o DMA que e utilizado para armazenar as palavras do di na pagina de destino de acordo com o vetor de bits.

Desta forma nosso dispositivo DMA simplesmente realiza operações scattergather diretamente a partir dos vetores de bits.

O monitor de desempenho permitira que a ecacia do controlador de protocolos seja avaliada em tempo de execução.

Para essa nalidade estatsticas de utilização de suas estruturas basicas incluindo o tamanho medio da FIFO o total de escritas realizadas pelo processador principal e total de ciclos em que o processador princi pal esteve bloqueado serao produzidas.

Alem disso o CP implementara um relogio global para que novos metodos de avaliação de desempenho para sistemas de com putação paralelos sejam desenvolvidos.

Em resumo o hardware que propomos e extremamente simples e suas unicas partes customizadas sao a logica para snooping do barramento de memória e ma nipulação dos vetores de bits e o nosso dispositivo de DMA.

Maiores detalhes sobre o hardware do NCP e como o seu dimensionamento foi realizado podem ser encon trados em.

Com o hardware descrito na seção anterior o controlador de protocolos pode prover o seu processador associado com os mecanismos basicos utilizados por SWDSMs.

Mais especicamente a funcionalidade oferecida pelo controlador que avaliamos nesse artigo e a pedido e envio remoto de pagina b pedido e envio remoto de di c aplicação e geração dinamica de di localmented envio e recepção de mensagem.

As tarefas restantes do processamento relativo ao protocolo geralmente sao mais complexas e portanto sao executadas no processador principal.

Para alcancar tal funcionalidade denimos varias estruturas de dados e comandos pro controlador de protocolos os quais estao descritos sucintamente nas subseções a seguir.


As principais estruturas de dados utilizadas pelo controlador de protocolos com preendem uma tabela de tradução de enderecos umcontador de pedidos pendentes uma tabela de locks de entradas de diretorios uma la de comandos um buer cir cular e algumas variaveis de sincronização.

A tabela de tradução e usada pelo controlador de protocolos para a conversao do endereco virtual para o endereco fsico das paginas compartilhadas.

Nessa tabela também encontram-se varios contadores e bits sinalizadores para cada pagina.

Esses bits sinalizam os pedidos pendentes e os pedidos prontos sem interromper o proces sador.

O contador sinaliza quantos pedidos pendentes relativos a dis paginas ou writenotices existem.

A tabela de locks armazena informações de compartilhamento sobre as paginas em uso.

Alem disso cada entrada nessa tabela contem um pon teiro para uma lista de processadores aguardando acesso a entrada.

O controlador de protocolos recebe os pedidos locais ou remotos atraves da la de comandos.

Os comandos sao enleirados para serem executados pelo controlador de protocolos.

O buer circular armazena temporariamente os dis e paginas recebidos dos proces sadores remotos antes de serem aplicados pelo DMA do controlador de protocolos.

O sincronismo dos acessos concorrentes entreo processador e o controlador as tabelas e a la de comandos e controlado pelas variaveis de sincronização.

Os comandos utilizados na implementação do nosso TreadMarks modicado sao apresentados na tabela.

Em um trabalho mais detalhado observamos que as aplicações sobre TreadMarks apresentam comportamentos comuns como o enorme numero de operações com dis codigos a e o pequeno numero de transferencias de paginas codigos a.

A manipulação de dis e muito custosa e como acontece em grande quantidade em TreadMarks justica o nosso uso de um hardware dedi cado a geração e aplicação de dis.

Alem disso o grande numero de tranferencias de mensagens pela rede codigos e indica a necessidade de implementação de mecanismos ecientes para esse tipo de operação.

Como certos comandos do controlador podem necessitar da assistencia do processador de computação nosso controlador oferece diferentes opções para a interrupção do processador em forma de bits sinalizadores associados aos comandos.

O comando pode pedir a interrupção do processador quando chega ao topo da la de comandos no controlador de protocolos ou logo depois de ser executado.

Uma outra opção e a possibilidade de sinalizar no comando que o controlador de protocolos deve enviar um acknowledgement para o no remoto apos esse comando terminar sua execução.

De forma a avaliar a performance do hardware e do software que propomos como base para o sistema NCP simulamos a execução de TreadMarks modicado para tomar proveito dos nossos controladores de protocolo e comparamos seus resultados com os de TreadMarks puro.

Nessa seção apresentamos esses estudos comecando por uma descrição da metodologia que utilizamosO sistema paralelo que simulamos e bastante semelhante ao NCP mas existem algumas diferencas tais como o fato de simularmos um processador escalar In dependente disso consideramos que nossas simulações permitem que facamos uma avaliação realistica das caractersticas arquiteturais que propomos para o nosso com putador paralelo.

Nosso simulador consiste de duas partes front end Mint que simula a execução dos processadores e back end que simula o sistema de memóriaemdetalhe write buers e caches com tamanhos nitos comportamento de TLBs emulação completa do protocolo custo de transferencia na rede de interconexao incluindo efeitos de contenção e custos de acesso a memória incluindo efeitos de contenção.

Em todas as referencias a dados compartilhados o front end chama o back end que simula as ações do protocolo simulado.

A tabela resume os parametros utilizados nas nossas simulações.

Apresentamos resultados para seis programas TSP Barnes Radix Water Ocean e Emd TSP e da Universidadede Rice e faz parte do pacote do TreadMarks.

As quatro aplicações seguintes sao do conjunto Splash.

Estas aplicações foram executadas com os tamanhos de entrada default para processadores como sug erido pelos pesquisadores de Stanford com excessao de Barnes TSP usa um algoritmo branchandbound para descobrir o custo mnimo de se percorrer cidades Barnes simula a interação de um sistema de K corpos sob a inuencia de forcas gravitacionais para passos usando o metodo BarnesHut hierarchical Nbody Radix e um kernel que ordena numeros inteiros.

O algoritmo e iterativo executando uma iteração por dgito de M chaves Water e uma simulação dinamica de moleculas que calcula forcas entre e intramoleculares em um conjunto de moleculas de agua.

Utilizase um algoritmo On para a computação das interações Ocean estuda movimentos em larga escala de oceanos baseado nas suas correntes.

Simulamos uma grade oceanica de dimensao Emd simula a propagação de ondas eletromagneticas em objetos D.

Simulamos objetos.


Valores Default dos Parametros do Sistema ciclo ns eletricos e magneticos conectados aleatoriamente com uma probabilidade de de que objetos vizinhos residam em nos distintos.

As interações entre objetos e simulada durante iterações.

As guras e apresentam os tempos de execução normalizados para cada uma das aplicações tomando os tempos de TreadMarks puro como base e apresentandoos na barra a esquerda em cada grupo de barras.

Cada barra compreende o tempo gasto pelo processador ocupado busy latencia devido a busca e transferencia de dados remotos pag overheads de sincronização synch overheads de comunicação entre processadores IPC e demais overheads others incluindo tempo de interrupção e latencia devido a falhas na cache.

O impacto dos overheads no desempenho das aplicações sob TreadMarks puro e signicativo e e mostrado nas guras desde a aplicação menos afetada TSP ate a mais afetada.

Nessas duas aplicações nossos controladores de protocolo conseguem reduzir o tempo de execução em e respectivamente Water e a relativamente menos sensvel com redução de enquanto que nas demais aplicações os tempos de execução sao reduzidos em mais de.

Uma analise do desempenho por categoria de overheads mostra que conseguimos reduzir signicativamente o custo de transferencia de dados remotos em Ocean Emd e Radix e menos nas demais.

Em relação aos overheads de sincronização a redução atinge fortemente duas aplicações Barnes e Radix e menos em Ocean e TSP.

O tempo de interferencia entre processadores IPC e drasticamente reduzido em todas as aplicações.

A capacidade da arquitetura que propomos de sobrepor computação util com overheads de ações de comunicação e coerencia explica o otimo desempenho al cancado na maioria das aplicações.

Como mostramos detalhadamente em dentre as tecnicas de sobreposição avaliadas a que obtem maior ganho de desempenho e a geração dinamica de dis em todas as seis aplicações.

A segunda caracterstica mais importante e a capacidade do controlador de protocolos de executar tarefas simples sem interrromper o processador principal contribuindo para o desempenho de quatro aplicações Water Radix Barnes e Emd.

A tecnica de busca antecipada também pode ser empregada com sucesso nas aplicações Emd e Ocean.

Esses multiprocessadores conseguem obter um alto desempenho a custa de projetos complexos com uso intensivo de logica dedicada.

Tais sistemas possuem custos elevados limitando signicativamente o seu uso mais difundido.

Devido a sua simplicidade e utilização de componentes comerciais nosso projeto consegue ter um custo muito menor e também um menor ciclo de desenvolvimento o que nos coloca em uma classe diferente de sistemas de memória compartilhada distribuída.

Nosso trabalho apresenta algumas ideias utilizadas nos projetos pioneiros do computador FLASH de Stanford e de Typhoon de Wisconsin temas buscam prover um compartilhamento eciente de dados ao nvel de linhas de cache.

A transferencia de pequenos blocos de dados exige redes de interconexao com baixa latencia para atingirse este objetivo o que torna esses projetos mais complexos e caros.

Ao contrario destas abordagens nosso protocolo de coerencia baseado em paginas permite o uso de um processador de protocolo mais simples e uma rede de interconexao comercial de baixo custo conectada a um barramento PCI.

Do ponto de vista dos algoritmos nossa pesquisa parte do trabalho realizado por varios sistemas que proveem memória compartilhada e coerencia em software utilizando variantes de consistencia relaxada.

Tanto Munin como TreadMarks foram projetados para execução em redes com estações de trabalho sem nenhum hardware especco de suporte.

Nosso trabalho mostra que uma melhora de desem penho signcativa pode ser obtida com uso de um hardware simples para esconder latencia de comunicação e as perdas com a realização de coerencia em sistemas deste tipo.

O trabalho de Iftode propoe AURC um SWDSM que usa um hard ware especco para atualização automatica de dados compartilhados.

No artigo AURC e comparado a TreadMarks puro usando algumas das mesmas aplicações por nos utilizadas.

Os autores mostram que o AURC supera TreadMarks em todas as aplicações.

O desempenho de aplicações sobre o nosso TreadMarks modicado e igual ou melhor que o de AURC.

O sistema de computação paralela NCP introduz a segunda geração de computa dores de alto desempenho em desenvolvimento na COPPEUFRJ.

O NCP ira implementar um sistema de memória compartilhada distribuída permitindo que aplicações paralelas sejam mais facilmente programadas.

Para alcancar alto desem penho numa classe maior de aplicações paralelas o NCP introduz controladores de protocolo implementados em hardware simples e de baixo custo.

Nossas sim ulações de um sistema semelhante ao NCP indicam que nossos controladores de protocolo permitem melhorar a performance de TreadMarks em ate para processadores.

O primeiro prototipo do NCP com unidades de processamento devera estar operacional ainda esse ano.

Esperamos que o NCP venha a proporcionar uma otima oportunidade tecnológica para investimentos nacionais em computação de alto desempenho 