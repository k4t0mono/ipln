A utilização de concreto projetado como suporte de túneis é uma prática amplamente difundida no mundo inteiro.

Este tipo material possui a característica de começar a agir estruturalmente desde pequenas idades.

Apesar disso, os correntes processos de dimensionamento de suportes negligenciam o desenvolvimento de suas propriedades com o tempo, em acoplamento aos efeitos tridimensionais da região onde se localiza a frente de escavação.

O presente trabalho tem a finalidade de relatar os procedimentos utilizados na análise da influência de alguns parâmetros da interação maciço suporte, sobre os esforços solicitantes finais do suporte de um túnel, tanto para o caso de concreto projetado, com suas propriedades dependentes do tempo, quanto para materiais com propriedades constantes.

São elaboradas soluções adimensionais para o problema da quantificação de esforços solicitantes de compressão e flexão no suporte.

A maioria das simulações realizadas para atingir essa meta foi conduzida com auxílio de técnicas de processamento paralelo.

As quantias referentes à instalação do sistema de estabilização de escavações subterrâneas representam uma parcela substancial do custo total de sua construção.

Perante esta realidade, se faz necessário o desenvolvimento de sistemas de suporte mais eficientes e, além disso, a elaboração de métodos de cálculo cada vez mais fiéis à realidade, que venham a auxiliar no dimensionamento desses suportes, tornando-os mais eficientes e econômicos.

Durante muitos anos, o concreto projetado tem sido amplamente utilizado pela engenharia na estabilização de túneis, seja em estágio primário ou final, como uma opção de suporte econômico e de rápida instalação.

Ele se tornou um elemento de revestimento essencial na construção de túneis, em concordância com os princípios do NATM (Novo Método Austríaco de Construção de Túneis), o qual procura obter a estabilidade da cavidade através de um alívio de pressão controlado, de maneira a transformar o material do maciço circundante, de um mero elemento de carga, em um elemento portante.

Uma das principais características distintivas do suporte de concreto projetado é que ele começa a receber o carregamento oriundo do maciço a pequenas idades, absorvendo cada vez mais carga, à medida que suas propriedades mecânicas estão se desenvolvendo com o tempo e a face do túnel está avançando.

A retirada de material e a instalação de suporte, que são ocasionados por este avanço da frente de escavação, induzem a uma redistribuição tridimensional de tensões no maciço.

Este fenômeno se explica pela ocorrência de arqueamentos transversais e longitudinais do maciço devido à existência de material íntegro adiante da frente de escavação e do suporte já instalado atrás, para suportar os carregamentos desequilibrados gerados pela retirada de material.

NG e LEE  conduziram algumas análises numéricas tridimensionais, considerando o maciço elástico perfeitamente plástico e o suporte elástico linear, a fim de investigar os efeitos da anisotropia de rigidez (Eh/Ev) e do coeficiente de empuxo em repouso (K0) no mecanismo de transferência de carga.

No entanto, essas análises não consideraram a variação das propriedades do suporte de concreto projetado com o tempo e apenas monitoraram o entorno da escavação, sem se preocupar com os esforços que solicitam o suporte.

Atualmente, os procedimentos de cálculo normalmente utilizados no dimensionamento do suporte de túneis, não consideram a dependência do tempo das propriedades do concreto projetado acoplada aos efeitos tridimensionais de transferência de carga para o suporte na região em que se localiza a frente de escavação.

Esses métodos consideram a configuração da escavação, suporte e seus carregamentos, correspondentes a uma situação totalmente estabilizada, o que ocorre aproximadamente dois diâmetros atrás da face do túnel.

Diante dessas hipóteses simplificadoras, que são normalmente consideradas nesses procedimentos usuais e que, normalmente também, conduzem a resultados com pequeno grau de confiabilidade, alguns procedimentos de cálculo foram propostos na tentativa de se reduzir tais simplificações.

Executou simulações das seqüências de avanços da frente de escavação de um túnel em modelos tridimensionais pelo MEF (Método dos Elementos Finitos).

Esses modelos consideraram o maciço elástico linear e propriedades dependentes do tempo para o concreto projetado.

Essas simulações tiveram a intenção de se determinar coeficientes auxiliares para simulações bidimensionais.

Através de análises axissimétricas, apresentou um procedimento para integração no tempo das equações analíticas da interação entre o maciço e o suporte.

Nesse método, as propriedades dependentes do tempo do concreto projetado e do maciço foram consideradas em conjunto.

No caso do maciço foi considerado o modelo visco-elástico de Burger, e para o concreto projetado foi considerado um modelo reológico desenvolvido na Universidade de Leoben.

O mecanismo de transferência de carga adotado, simulando o efeito tridimensional da frente de escavação, foi o de SCHWARTZ e EINSTEIN.

Como entretanto, naquele método foi adotado o suporte com rigidez constante, CELESTINO  reconhece que a carga transferida a um suporte menos rígido junto à frente pode não ser realista.

Ainda na categoria das análises axissimétricas, CHANG  também apresentou um esquema similar ao anterior.

Mas, por sua vez, considerou o maciço como um material elasto-plástico, e os efeitos tridimensionais de suporte da frente de escavação foram simulados pelo alívio de pressão fictícia interna, como foi proposto por PANET.

As simplificações  inerentes  a esta  simulação  do tridimensionalismo, segundo SCHWEIGER, podem introduzir imprecisões no mecanismo de transferência de carga.

GOMES  propôs um método que incorpora alguns procedimentos básicos do método proposto por SCHWARTZ e EINSTEIN, generalizando-o na consideração do comportamento dependente do tempo para o suporte de um túnel, simulando o enrijecimento do concreto projetado ao longo de seu eixo longitudinal.

Neste trabalho, o mecanismo tridimensional de transferência de carga foi simulado em modelos numéricos axissimétricos, reproduzindo-se o avanço longitudinal dos túneis pelas seqüências de escavação e instalação do suporte lance a lance e, simultaneamente, atualizando-se a rigidez de cada anel de concreto projetado de acordo com sua idade.

Todos os cálculos de quantificação dos esforços solicitantes do suporte foram realizados pelo MDF (Método das Diferenças Finitas).

Uma das vantagens desse procedimento foi incorporar em um só gráfico adimensional, a solução para o problema da quantificação dos esforços solicitantes no suporte, independente das rigidezes envolvidas na interação entre o maciço e o suporte, da seqüência de escavação utilizada, e dos demais parâmetros citados, sendo que, as propriedades do suporte podem ser dependentes do tempo ou não.

Eliminou-se assim, a necessidade de se recorrer a diferentes gráficos adimensionais e a equações analíticas, como anteriormente se procedia em outros métodos.

No entanto, a determinação direta desses esforços através do método proposto está limitada a uma certa gama de casos ocasionada por algumas restrições.

Todas essas restrições foram geradas por hipóteses simplificadoras, inerentes às ferramentas de cálculo utilizadas na confecção do método, que poderiam ter sido superadas se não fosse a impossibilidade do momento em se utilizar um software que permitisse a execução de análises tridimensionais para o problema.

A utilização de modelos tridimensionais realistas para simulação numérica dos avanços da frente de escavação se esbarra sempre nas grandes dimensões do problema em contraste com os pequenos passos de avanço.

Este contraste de dimensões gera um alto grau de refinamento da malha do MEF, o que por sua vez ocasiona um alto consumo de memória e uma grande quantidade de tempo, necessários à sua execução.

Atualmente, uma alternativa para a resolução dos problemas descritos acima seria a utilização de computadores de alto desempenho, de forma a reduzir o tempo de processamento.

Os supercomputadores vetoriais possuem todas as qualidades necessárias para o tratamento desses problemas, mas seus preços ainda são muito elevados, impossibilitando a sua utilização.

Desta forma, uma das alternativas mais viáveis seria o uso de multicomputadores, que realizam tarefas baseadas no conceito de concorrência simultânea ou paralelismo de instruções utilizando-se, muitas vezes, de computadores simples conectados em uma rede de alta performance.

No entanto, apesar de ser uma alternativa não tão cara quanto à descrita anteriormente, esta ainda se depara com problemas relativos à sua correta configuração de rede, de carga por processador e de memória distribuída.

O que se propõe neste trabalho é a sumarização dos efeitos do fenômeno de transferência de carga do maciço para o suporte, através da elaboração de expressões adimensionais que relacionam os esforços solicitantes encontrados no suporte com outras características geométricas e físicas do problema.

Estas expressões foram obtidas através de análises estatísticas dos resultados obtidos em simulações numéricas tridimensionais com o auxílio de técnicas de processamento paralelo.

Desta maneira, elimina-se a necessidade de se recorrer, pelo menos numa fase de pré-projeto, às análises tridimensionais, tão onerosas quando se fala em tempo de processamento e dinheiro empenhado.

Com a finalidade de relatar os avanços obtidos na realização destas tarefas, o presente trabalho foi organizado em 10 capítulos e estes são enumerados a seguir e seus conteúdos, sucintamente descritos.

Neste capítulo, com a intenção de se introduzirem alguns conceitos de grande importância ao desenvolvimento deste trabalho é feito um breve histórico do desenvolvimento do "Novo Método Austríaco de Construção de Túneis" e uma descrição em linhas gerais dos princípios envolvidos por este método.

Além disso, o comportamento individual de dois de seus elementos mais importantes, o maciço e o revestimento de concreto projetado, são abordados a fim de que, mais adiante, a interação entre estes elementos possa ser modelada com maior fidelidade aos problemas reais.

O início do desenvolvimento do NATM se deu no período de 1931 a 1936 em que, até o dado momento, o engenheiro civil Ladislaus Von Rabcewicz se empenhava como chefe de construção da Linha Norte da Estrada de Ferro Transiraniana.

Mais tarde, durante o período de 1956 a 1958, quando o então professor Rabcewicz foi contratado pela ONU como especialista para construção de túneis ferroviários e rodoviários na Venezuela, é que o NATM foi utilizado pela primeira vez na construção de túneis, os quais foram executados com o auxílio de um suporte composto por concreto projetado, cambotas leves e ancoragens sistemáticas.

Somente na década seguinte, foi que Rabcewicz apresentou no Colóquio de Geomecânica de 1963, realizado na Áustria.
O "Novo Método Austríaco de Construção de Túneis", que era a concretização de suas idéias no sentido da criação de um sistema de escavação baseado num dimensionamento empírico, após observar que todas as dificuldades e colapsos decorrentes de sua execução eram conseqüências da possibilidade oferecida por outros métodos conhecidos de se permitir afrouxamentos iniciais do maciço sem controle algum e de deixar vazios entre o suporte e o terreno.

A adoção do concreto projetado com acelerador de pega como elemento de suporte, foi feita quando se imaginou que unicamente um material suficientemente plástico no momento da aplicação seria capaz de preencher as cavidades mais irregulares.
E pudesse ser aplicado imediatamente após a escavação, e que oferecesse uma elevada rigidez e resistência em pouco tempo, eliminaria os afrouxamentos iniciais e os vazios na interface ao imobilizar a rocha ou o solo em sua posição relativa.

O concreto projetado atua por forte aderência e coação ao terreno, imobilizando os seus elementos formadores (blocos) e obrigando o maciço a suportar o carregamento em integração com o suporte.

Segundo GOLSER, em resposta às críticas feitas pelo professor Kovári no 42º Colóquio de Geomecânica de Salzburgo, em 1993, que também podem ser vistas em KOVÁRI.
O NATM segue um conceito segundo o qual o maciço (solo ou rocha) circundante à escavação, através da ativação de um anel de suporte, torna-se um elemento de suporte da escavação.

Esclarecendo estas palavras, pode-se dizer que na execução de uma escavação subterrânea, o estado de equilíbrio existente no maciço se modifica, através de uma série de estados intermediários nos quais ocorrem transferências de tensões, num novo estado de equilíbrio secundário.

O NATM tem como escopo principal o controle destes estados intermediários de maneira tecnicamente segura e a mais econômica possível, para que se atinja um estado de equilíbrio final ótimo.

Para que este objetivo seja atingido, é necessário que as deformações do maciço sejam controladas, de maneira que, de um lado essas deformações sejam mantidas pequenas o suficiente para que o maciço não se afaste de modo definitivo de sua resistência inicial, e de outro lado que as deformações sejam grandes o suficiente para ativar a colaboração do maciço como anel de sustentação, otimizando assim os custos de escavação e suporte.

Por ter se mostrado um método versátil e flexível, o NATM vem sendo utilizado e difundido pelo mundo inteiro durante décadas, contudo, vem sendo igualmente incompreendido.

Além de críticas como as feitas por KOVÁRI, o método sofreu críticas mais elaboradas como as de MELLO, que são relacionadas à validade da monitoração de deslocamentos no interior de túneis e outras que diziam respeito à consideração do NATM como um conjunto de técnicas de escavação e suporte, quando na verdade este deveria ser encarado como uma filosofia ou conjunto de conceitos.

Estas últimas críticas foram apresentadas por MÜLLER  e BROWN.

A partir do momento em que se aceita o NATM como uma filosofia, deve-se atentar aos seguintes princípios que o regem, · O principal suporte de um túnel é o maciço que o circunda.

Deve-se mobilizar ao máximo a capacidade portante do maciço circunvizinho à abertura, formando um anel de estabilização em conjunto com a estrutura de suporte.

As deformações do maciço e do suporte devem ser rigorosamente observadas e controladas, evitando-se assim um processo de deterioração e relaxamento do maciço.

O suporte que interage com o maciço deve ser aplicado no tempo correto, ou seja, respeitando as características geomecânicas do maciço.

A extensão a ser deixada sem suporte em qualquer momento durante a construção deve ser a menor possível.

Sempre que possível deve-se avançar o túnel em seção plena (ou com o mínimo de parcializações possíveis), com o menor tempo de ciclo e a mínima perturbação do maciço.

A rigidez do suporte deve ser compatível com o maciço, de maneira a restringir dentro de limites seguros as deformações.

A geometria da escavação dever ser adequada de maneira a evitar mudanças bruscas e cantos vivos, que induzam a elevados esforços de flexão.

Contratante, projetista e construtor devem estar bem entrosados a fim de que seja  possível a adoção de soluções mais rápidas e eficientes.

A operação de escavação de um túnel causa grandes modificações no estado de tensões originais do maciço, seja ele constituído de rocha ou solo, que reagirá à escavação de algum modo.

A passagem da frente de escavação por uma determinada seção transversal do túnel aumenta a velocidade de tais mudanças nos estados de tensões e deformações de suas vizinhanças.

A esta região vizinha, LOMBARDI  deu o nome de "zona de influência da frente de escavação", tentando descrever tais modificações.

Nesta fase de revisão, serão discutidos os efeitos causados pela abertura de túneis em maciços rochosos e de solo.

Primeiramente, serão analisadas as tensões resultantes do processo de escavação e, logo em seguida, as suas deformações resultantes.

A abertura de um túnel em um maciço conduz, nas regiões da vizinhança da frente de escavação, a modificações tridimensionais de tensão.

Como ilustração do caso, a distribuição longitudinal de tensões principais para um meio elástico obtida por simulações axissimétricas do avanço da face de um túnel sem revestimento.

Na parte posterior à face, as direções das tensões principais se encontram inicialmente paralelas ao eixo do túnel, e à medida que a face se aproxima, estas direções são giradas de até 90º.

As maiores mudanças de tensões se localizam a uma distância de aproximadamente 1 a 1,5 vezes o diâmetro do túnel ao redor da face.

A maioria das mudanças tridimensionais de tensão são geralmente estabilizadas a uma distância menor ou igual a dois diâmetros atrás da face e os valores finais se aproximam dos valores encontrados em soluções analíticas do estado plano, como é o caso da solução clássica de Kirsch, o que corrobora o conceito da "zona de influência da frente de escavação".

Distribuição longitudinal das direções principais ao redor da face.

A mesma mudança nas direções principais, mas desta vez em uma seção transversal que foi afetada pela escavação de um túnel.

É o resultado da simulação numérica no estado plano de deformação da retirada de material de uma região circular de um maciço que possui um estado de tensões hidrostático, ou seja, K0=1.

Distribuição transversal das direções principais de uma abertura.

A distribuição longitudinal de tensões tangenciais, obtida de simulações numéricas axissimétricas de túneis sem suporte em meios elásticos.

Por sua análise, pode-se dizer que nas proximidades da face do túnel a tensão tangencial atuante em suas paredes laterais é menor do que quando se afasta desta.

Isto se deve ao "efeito de suporte da frente de escavação", que torna o maciço nas suas imediações menos comprimido na direção tangencial à superfície da abertura.

Distribuição longitudinal de tensões tangenciais obtidas de simulações numéricas com tensões iniciais consideradas hidrostáticas.

LOMBARDI  percebeu que a existência de uma tensão de cisalhamento, rz, que é vertical, perpendicular ao eixo do túnel e próxima à frente de escavação, possui grande importância nas contribuições ao efeito de suporte da frente de escavação.

A distribuição destas tensões é mostrada, na qual pode ser notada a concentração de tensões nos cantos da face e que a "zona de influência da frente de escavação" pode ser determinada por esta zona de tensões de cisalhamento.

Segundo ECKSCHMIDT e CELESTINO, é importante ressaltar que r (tensão radial), (tensão tangencial às paredes) e z (tensão paralela ao eixo do túnel) não são as tensões principais na extensão desta região.

Este fato implica que as tensões cisalhantes, rz, conduzem a tensões desviatórias reais maiores que as obtidas em análises planas, o que exerce grande influência no fluxo plástico quando o material exceder o regime elástico.

Distribuição longitudinal de tensões cisalhantes, rz, ao redor da frente de escavação, a partir de simulações numéricas axissimétricas.

NG e LEE  conduziram uma série de análises numéricas tridimensionais, considerando o maciço elástico perfeitamente plástico e o suporte elástico linear, a fim de investigar os efeitos da anisotropia de rigidez (Eh/Ev) e do coeficiente de empuxo em repouso (K0) no mecanismo de transferência de carga.

Como já dito anteriormente, este fenômeno ocorre devido à presença da frente de escavação, neste caso particular, de um túnel idealizado circular com 9 metros de diâmetro e com 225 m de distância entre a face e a borda do último lance de suporte instalado.

No total, quatro simulações foram realizadas (igualando-se K0 à 10 e 05 e n à 10 e 16), onde foram monitoradas as tensões em alguns dos elementos que discretizam o maciço nas circunvizinhanças do suporte, numa dada seção do túnel, à medida que a frente de escavação avançava.

O mecanismo tridimensional de transferência de carga foi de certa forma demonstrado através da análise de modificações progressivas em tensões normais e cisalhantes segundo as três direções básicas do modelo (x, y e z).

Com o intuito de demonstrar completamente os efeitos dos avanços da frente de escavação, HANAFY  simulou elasticamente as mudanças ocorridas em termos de deslocamentos radiais para um determinado ponto de referência.

Pode ser entendido pela observação, que o início dos deslocamentos ocorre quando a frente de escavação dista de aproximadamente quatro raios do túnel, partindo do ponto tomado como referência.

Uma mudança brusca acontece quando a frente se localizar dentro de uma região de mais ou menos um raio adiante e atrás do referido ponto.

Ao atingir a seção de controle, aproximadamente 30% do deslocamento total tomará lugar, 80% quando a frente estiver distando de um raio adiante desta seção, e quase atingirá 100% do deslocamento total quando esta se localizar a uma distância de dois raios da frente de escavação.

Isto mostra que, para um túnel circular em condições elásticas a "zona de influência da frente de escavação", citada anteriormente, pode ser considerada como uma região de aproximadamente dois diâmetros deste túnel ao redor de sua frente de escavação.

Deslocamentos radiais cumulativos devidos aos avanços da frente de escavação sob condições elásticas em modelos axissimétricos.

PAN, através de simulações numéricas, demonstrou que no caso de um campo de tensões iniciais de um maciço rochoso não fraturado, onde o coeficiente de empuxo em repouso é igual a um, o deslocamento radial elástico das paredes de uma seção distante da face pode ser bem estimado pela particularização da solução clássica de Kirsch para o estado plano, traduzido pela expressão, onde G é o módulo de cisalhamento da rocha, p0 a tensão inicial atuante no terreno e R o raio do túnel.

Ao seguir os mesmos procedimentos anteriores, mas agora simulando condições elasto-plásticas do maciço, LEE  chegou às mesmas conclusões, mas neste caso, comparou o resultado de suas simulações com soluções analíticas que consideram a plastificação do material do maciço, como é o caso da solução analítica proposta por SALENÇON.
PANET  propôs as equações (12) e (13) para a quantificação do perfil de deslocamentos radiais de um túnel circular profundo sem suporte, em avanço num maciço elástico com um estado de tensões hidrostático, que também será tratada com maiores detalhes no Capítulo 7.

Simulações tridimensionais pelo método dos elementos de contorno foram executadas por NIWA, nas quais três configurações de tensões iniciais foram testadas.

Estas configurações indicaram que os deslocamentos radiais são predominantemente causados por tensões iniciais perpendiculares ao eixo do túnel, enquanto a frente de escavação se deforma sensivelmente quando a direção das tensões normais e das tensões de cisalhamento iniciais são paralelas ao mesmo eixo.

A influência do coeficiente de Poisson no que tange aos deslocamentos radiais é pouco evidente, é o que também mostrou NIWA.

A plasticidade vinculada aos maciços rochosos ou de solo tem um impacto substancial nas magnitudes e na distribuição de deslocamentos atrás da frente de escavação.

Comparado com o caso elástico, o deslocamento radial total pode ser muito maior, e este deslocamento atinge seu valor final a uma distância maior da frente.

Foi observado por PANET, através de simulações numéricas, que a deformação é estritamente dependente da extensão do raio de plastificação, ou seja, uma grande extensão do raio de plastificação resulta em grandes deslocamentos e em grandes distâncias da face para que estes atinjam seus valores finais.

A razão dada a este fato é de que a rigidez da face se torna mais baixa quando o maciço ao seu redor se plastifica, desta forma, o efeito de suporte da face diminui.

Com relação às deformações dependentes do tempo, o método de escavação tem uma influência significativa nos deslocamentos, como foi constatado por CELESTINO  e HANAFY.

Estes pesquisadores mostraram que os deslocamentos radiais devidos à fluência do material são, na maioria das vezes, mais importantes do que os de resposta instantânea.

O concreto projetado pode ser definido como uma mistura de areia, brita, cimento Portland e aditivos aceleradores de pega bem homegeneizados, que é impulsionada por uma máquina de projeção rumo à superfície a ser tratada.

Este impulso é dado por meio de uma corrente de ar comprimido ou por uma bomba, que transporta a mistura em alta velocidade através de um tubo flexível, o mangote, até que a mistura atinja a superfície a ser estabilizada.

Neste último momento, a mistura também sofre o efeito de compactação simultânea, reflexo da alta energia cinética dada aos agregados na saída do sistema.

A seguir, algumas informações encontradas na literatura acerca das propriedades do concreto projetado são enumeradas.

Mais tarde, no Capítulo 2, será visto como essas informações foram utilizadas na modelagem do revestimento.

Uma das mais importantes propriedades que descrevem a qualidade do concreto projetado é a sua resistência à compressão simples.

O parâmetro de resistência à compressão é freqüentemente especificado pelo projeto e testado em campo ou laboratório, com o propósito do controle de qualidade do material.

Os ensaios relativos ao concreto projetado a pequenas idades são de difícil execução, pois é muito difícil retirar testemunhos da superfície projetada sem que o material tenha atingido uma resistência à compressão simples de no mínimo 5 a 10 MPa.

Por outro lado, aplicar o concreto em caixas cúbicas, com a finalidade de se moldar diretamente os corpos de prova, não é um procedimento recomendável como maneira de se representar a realidade de aplicação do concreto em túneis, já que as paredes laterais dos moldes podem influenciar no processo de compactação destes.

Devido a estas razões, alguns métodos indiretos foram desenvolvidos para a determinação da resistência à compressão do concreto projetado, como é o caso de dois dos primeiros métodos indiretos que foram concebidos por SÄLLSTRÖN  que, em 1990, foram padronizados pela ÖBV (Sociedade Austríaca do Concreto).

O primeiro consiste em um ensaio de penetração para solos modificado que é realizado logo após a fase de projeção do concreto, em que se procura relacionar a resistência à cravação de uma agulha padrão com a resistência do concreto projetado a pequenas idades.

Este método de ensaio pode ser realizado utilizando dois tipos diferentes de equipamento, o Penetrômetro de Profundidade Constante (PPC) e o Penetrômetro de Energia Constatante (PEC).

O Penetrômetro de Profundidade Constante (PPC) consiste em relacionar a força necessária para a penetração da agulha padrão até uma determinada profundidade.

Este equipamento permite medir a resistência nas primeiras horas até o limite de 0,8 MPa.

Este é um dos métodos mais utilizados em campo e sua eficácia foi analisada por PRUDÊNCIO.

Pode ser observado um esquema do Penetrômetro de Profundidade Constante (PPC).

Em idades onde a resistência varie entre 0,8 MPa e aquela em que se possam realizar extrações sem danificar a amostra de concreto (a partir de 5 MPa), o autor sugere o uso de Penetrômetros de Energia Constante (PEC).

Este equipamento consiste na medida da resistência à cravação de uma agulha a partir da profundidade de cravação desta no concreto quando liberada de uma altura padronizada.

O limitante deste equipamento é a impossibilidade de utilização em obras para medida de resistência nas paredes laterais e no teto.

Esquema de PPC empregado por PRUDÊNCIO.

O segundo método consiste no disparo de um pino sobre a superfície de concreto, certo tempo após sua projeção, onde é medida a profundidade de penetração e em seguida a força necessária para sua retirada.

Contudo, estes dois testes são muito sensíveis a certas características do material que está sendo testado, como é o caso da influência do tamanho dos agregados do concreto no primeiro teste.

A resistência à penetração cresce muito com o aumento do tamanho do agregado utilizado, desta maneira se faz necessária a calibração do método em qualquer situação não usual, o que pode ser demorado e caro para um projeto em andamento.

CHANG  sugere um novo método indireto, que se resume na cravação de uma barra de seção retangular, instantes após o lançamento do material, e na leitura de deslocamentos angulares e no torque aplicado num determinado tempo.

O torque máximo e a rigidez à torção, Kt, podem ser determinados.

Desta forma, a resistência à compressão e o módulo de elasticidade podem ser obtidos pelas relações, são parâmetros determinados por ensaios de calibração de laboratório.

Mas é importante salientar que a confiabilidade do método ainda está sendo estudada.

Método de ensaio para a determinação da resistência à compressão e  do módulo de elasticidade do concreto a pequenas idades.

Quanto ao crescimento da resistência do concreto, CHANG  resume grande número dos resultados de ensaios de compressão simples com concreto projetado realizados por outros pesquisadores, da década de 70 até 1994.
Através da regressão exponencial desses dados expressa pela equação, É importante ressaltar que nestes resultados compilados por CHANG, estão incluídas muitas variações de mistura e do processo para obtenção do concreto projetado, desde a maneira como foi feita a adição de água, até a utilização de aditivos aceleradores, plastificantes e de reforços por fibras.

Apesar de um grande número de dados, estes apresentam também uma grande dispersão.

A Sociedade Austríaca do Concreto  apresenta uma expressão mais completa que faz diferenciação entre o comportamento a 1 dia da evolução a longo prazo.

FERREIRA  compilou outros resultados experimentais na literatura, diferentes daqueles analisados CHANG  e FERREIRA, os quais são confrontados com os modelos para evolução da resistência propostos por CHANG  e ÖBV.

Esses resultados analisados referem-se a dados de compressão simples do concreto projetado em campo fornecidos.

Apresentam-se as curvas obtidas por CHANG, e pela expressão da ÖBV) ajustada aos dados apresentados no gráfico.

Observa-se que há uma grande dispersão nos valores de resistência fornecidos pelos autores independentemente da idade.

A expressão proposta por CHANG, representando a curva média dos resultados analisados pelo autor, se enquadra dentro da dispersão dos resultados, nos limites superiores.

Quanto à expressão da ÖBV, esta parece representativa dos valores médios de resistência à compressão.

Compilação dos resultados de campo relativos à resistência à compressão do concreto projetado.

A grande diferença entre o concreto convencional e o projetado se encontra na compactação imposta pelo método de lançamento.

No concreto convencional a compactação se dá por vibração, enquanto que na projeção esta se deve à energia cinética causada pelo lançamento.

No entanto, ensaios realizados por LITTLE  mostram que os valores de resistência à compressão de laboratório para o concreto projetado segue a tendência da curva geral de resistência do concreto convencional.

A resistência à compressão do concreto projetado em diferentes idades foi estudado por SEZAKI, que apresenta curvas de tensão x deformação a 3, 6 e 12 horas, e a 1, 3, 7 e 28 dias após o lançamento.

Por comparação entre estas curvas pode-se dizer que o concreto se comporta como um material dúctil em idades inferiores a um dia.

Quando a sua resistência é atingida, o material tem ainda uma considerável resistência residual e ruptura completa se dá a uma grande deformação.

Isto significa que este material, quando ainda jovem, tem uma grande habilidade de absorver as deformações do maciço onde se localiza o túnel.

Com a idade, a ruptura torna-se mais frágil, com menores taxas de deformação.

Na pesquisa realizada por AYDAN, são apresentados resultados mais completos sobre o comportamento tensão-deformação do concreto projetado obtidos através de ensaios de compressão simples e triaxial.

Estes ensaios foram realizados em amostras cúbicas, projetadas de maneira semelhante à operação realizada em campo.

Algumas curvas representativas do comportamento tensão-deformação do concreto projetado são apresentadas.

Comportamento tensão deformação do concreto projetado submetido  a ensaios de compressão uniaxiais e triaxiais em diferentes idades.

Ao analisarmos as curvas, dando maior atenção à compressão triaxial, observa-se que o efeito do confinamento afeta substancialmente o comportamento tensão deformação em idades menores que 1 dia.

Em idades acima de 3 dias, o efeito sobre as curvas é pequeno.

No entanto, como era de se esperar, a tensão confinante melhora as propriedades do concreto projetado, pois a ruptura ocorre com maiores níveis de carregamento e deformações, tornando o concreto mais dúctil mesmo quando em idades mais avançadas.

Em contraste a essa enorme quantidade de estudos a respeito da resistência à compressão, apenas  uma  pequena quantidade de informação sobre  o desenvolvimento do módulo de elasticidade do concreto projetado pode ser encontrada na literatura.

Em FERREIRA, é relatada uma grande quantidade de dados de resistência a pequenas idades e muito poucos dados que puderam ser obtidos para a deformabilidade de concretos às mesmas idades, a despeito de grande esforço.

Uma das razões disso se encaixa nas dificuldades anteriormente descritas, e a outra pode ser associada ao fato de que não tenha sido ainda percebida a sua importância no cálculo das tensões e deslocamentos resultantes da escavação de um túnel.

É importante ressaltar que FERREIRA  obteve resultados sobre o módulo de elasticidade medido in situ, com o auxílio de painéis instrumentados submetidos a carregamento crescente com o tempo e conhecido, desde pequenas idades, até 28 dias.

Estes dados são muito valiosos e raros no mundo até hoje.

Utilizando o mesmo procedimento, a compilação de resultados anteriores, CHANG  apresentou uma expressão que descreve a evolução do módulo de elasticidade do concreto projetado em função do tempo.

Essa equação foi obtida pela regressão exponencial de um conjunto constituído pelos raros resultados de ensaios executados por HUBER  e FISCHNALLER, e é descrita como módulo de elasticidade do concreto projetado de referência com e  sem carregamento.

Pela comparação entre curvas c(t)/c28 e Ec(t)/Ec28, que descrevem o crescimento ao longo do tempo de ambas propriedades, pode-se concluir que o módulo de elasticidade tem uma taxa de crescimento maior que a resistência à compressão.

Isto pode gerar grandes problemas no que diz respeito à construção de túneis, pois uma alta rigidez do revestimento resulta geralmente numa alta absorção de carga do maciço suportada por este, em contraste com valores não tão altos de resistência à compressão são necessários para tal função.

Outro fato conflitante neste caso, é a utilização de aceleradores de resistência que promovem além de uma alta resistência a pequenas idades, também resultam numa alta rigidez, neste mesmo período de tempo.

Além da compilação e da análise estatística dos resultados de ensaios de módulos de elasticidade realizados por CHANG, FERREIRA  ampliou esse trabalho, englobando os resultados de KUWAJIMA  e de MÜLLER.

KUWAJIMA  apresenta resultados de módulos de elasticidade obtidos em concretos moldados que apresentavam características semelhantes a concretos projetados a partir de ensaios convencionais e também medidos por método ultrasônico e MÜLLER  apresenta resultados obtidos a partir de corpos de prova produzidos no túnel austríaco Plabutsch, projetado em formas metálicas e extraídos da parede.

Apresenta esses resultados e compara estes valores com a curva de ajuste de CHANG.

Comparação entre o crescimento da resistência à compressão e do  módulo de elasticidade do concreto projetado.

Módulos de elasticidade obtidos por KUWAJIMA  e MÜLLER  emcomparação com a curva ajustada por CHANG.

Observa-se que os resultados de KUWAJIMA  apresentam-se bem abaixo da curva ajustada até 10 dias de idade.

Já os dados de MÜLLER  apresentam uma grande dispersão entre si, justificável pelas diferentes condições de projeção e cura (em formas e na parede do túnel), bem abaixo da curva de CHANG  antes de 10 dias de idade.

Os resultados acima da curva de evolução de resistência correspondem aos valores de módulo de elasticidade obtidos em corpos de prova extraídos da parede do túnel.

Além da curva ajustada por CHANG, o CEB-FIP  apud MESCHKE propôs uma expressão para evolução do módulo de elasticidade do concreto projetado mais complexa.

Segundo FERREIRA, existe uma ressalva quanto à utilização desta equação para concretos projetados em idades de hidratação muito recentes, pois seu comportamento pode não ser descrito de maneira adequada.

Com relação ao coeficiente de Poisson, SEZAKI apresentam a expressão 18 obtida a partir de amostras cúbicas extraídas de painéis verticais.

Os ensaios foram realizados com carregamento perpendicular a direção de projeção, ou seja, carregamento paralelo a laminação do concreto projetado, situação de carregamento mais próxima da realidade Esta expressão foi comparada aos resultados experimentais obtidos por KUWAJIMA  a partir de métodos ultra-sônicos.

FERREIRA  comparou esta expressão com resultados experimentais obtidos por KUWAJIMA  a partir de métodos ultra-sônicos.

Os resultados experimentais de KUWAJIMA  estão muito acima dos valores da expressão obtida no programa de ensaios de SEZAKI, fato este creditado à comparação de valores de coeficiente de Poisson obtidos a partir de ensaios convencionais e ultra-sônicos.

Mesmo assim, observa-se que a curva proposta e a nuvem de pontos têm forma bastante similar.

No entanto, CELESTINO  apresentou valores mais baixos para o coeficiente de Poisson, em média m = 0,11 a 28 dias de idade.

Não foram encontrados quaisquer outros resultados experimentais na literatura, o que dificulta explicar melhor estas diferenças.

Comparação da evolução do coeficiente de Poisson obtido por  SEZAKI e por KUWAJIMA.

Ainda com relação a CELESTINO, pode-se apreciar uma técnica alternativa para medidas de módulos de elasticidade e coeficientes de Poisson de revestimentos de concreto projetado, envolvendo o ensaio de compressão diametral.

Apesar deste ensaio permitir conhecer a anisotropia dessas propriedades, ainda é restrito a concretos projetados a idades mais avançadas, pois, como já comentado em outros casos, tem como limitante o problema da extração das amostras.

Também são propriedades pouco conhecidas do concreto projetado, a resistência à tração (ft) e a tensão de plastificação (fcy).

De acordo com MESCHKE et al, BYFORS  e OLUOKUN pesquisaram a relação entre a resistência à tração e a resistência à compressão do concreto jovem e propuseram a seguinte relação empírica, onde at e bt são parâmetros da equação, admitidas respectivamente como 0,876 e 0,79 para fc em kPa.

Com relação à tensão de plastificação, também de acordo com MESCHKE et al, não há muitas informações disponíveis na literatura e admitem como representativa.

Ainda de acordo com MESCHKE, os concretos projetados de HUBER  apresentaram tensões de plastificação em torno de 2,23 e 1,40 MPa.

Os resultados de ensaios apontados por MOUSA  apud CHANG, mostraram que há uma redução na resistência final à compressão de corpos de prova de concreto que foram submetidos a carregamentos em pequenas idades.

Este fato gera a necessidade de se realizar um controle de qualidade do revestimento, baseado no ensaio de testemunhos retirados do concreto com idades mais avançadas como correção dos parâmetros de projeto.

Os ensaios conduzidos por MOUSA  foram realizados em amostras de 100 mm de diâmetro e 150 mm de altura.

As amostras foram divididas em três grupos, 1º Grupo, as amostras foram ensaiadas a 2, 3, 7 e 14 dias de idade para obter a resistência a compressão fc, 2º Grupo as amostras foram pré-carregadas com 2 dias de idade com um certo nível de tensão, descarregadas e levadas à ruptura a 7 dias de idade.

3º Grupo, as amostras foram pré-carregadas com 3 dias de idade, descarregadas e levadas à ruptura com 14 dias.

Para estudar os efeitos do carregamento precoce sobre o desenvolvimento da resistência, todas as cargas de ruptura foram comparadas entre grupos, resultando num parâmetro de redução de resistência, definido como, onde, fc,t1, fc,t2, resistências à compressão das amostras de referência nos instantes  t1 de pré-carregamento e no instante t2 de ruptura, respectivamente, smáx carga máxima (ruptura) suportada pela amostra pré-carregada.

CHANG  afirma que o desenvolvimento da resistência com o tempo é afetado pelo carregamento precoce.

Em relação ao efeito da taxa de pré-carregamento o/fct,1 e o parâmetro de redução Rd, MOUSSA  apresenta a seguinte correlação, baseado em resultados experimentais, onde so corresponde a tensão de pré-carregamento.

FERREIRA, com base na equação 114, observou que a redução na resistência é desprezível para concretos pré-carregados com menos de 70% da resistência à compressão a pequenas idades.

Para um concreto carregado com uma tensão máxima e descarregado imediatamente, o valor para o parâmetro de redução Rd é cerca de 80%.

CHANG  ainda frisa que, quando MOUSSA  submeteu suas amostras ao pré-carregamento, na idade de 2 dias, o concreto projetado não é tão jovem quando comparado à idade em que este começa a arcar com carregamentos durante a construção de um túnel.

Ensaios em amostras de concreto  mostram que o pré-carregamento de concretos dentro das primeiras 8 horas após a moldagem, exerce grande efeito sob o desenvolvimento da resistência.

Além dos trabalhos anteriores, HUBER  apud MESCKHE apresentou alguns resultados experimentais de concretos projetados onde ocorreram rupturas precoces quando submetidos a carregamentos em idades 5 a 25 h.

Os ensaios foram realizados em amostras de concreto projetado prismáticas com dimensões 10 x 10 x 40 cm, retiradas do Túnel Inntal (Áustria), imediatamente após a concretagem.

Três amostras foram utilizadas em cada ensaio, submetidas a seqüências de carregamentos correspondentes às solicitações típicas de escavações de túneis.

Ainda nesta pesquisa, foi possível observar que as diferentes histórias de carregamento parecem ter influenciado muito a evolução da resistência à compressão, na série em que o carregamento foi muito mais severo, constatou-se uma abrupta mudança na curva de evolução da resistência, a qual passou a evoluir mais lentamente após um carregamento crítico, e a ruptura ocorreu com um carregamento bem abaixo da sua resistência à compressão.

De acordo com METHA e MONTEIRO, os modelos reológicos clássicos, apresentados em ANEXO (Modelos reológicos e sua implementação), têm sucesso limitado quando utilizados para representar o comportamento do concreto projetado.

O motivo desta limitação reside no fato de que o módulo de elasticidade, o coeficiente de Poisson, os limites plastificação e os parâmetros de viscosidade não são constantes ao longo do tempo, mas variam de acordo com o grau de hidratação do material.

Além disso, as deformações sofridas pelo concreto projetado não estão somente relacionadas à imposição de um carregamento.

Ou seja, deformações não são unicamente dependentes de tensões, como foi mostrado em todos os modelos reológicos citados até agora, mas, também são resultantes de ações térmicas e hídricas (deformações independentes de tensões).

Desta forma, a deformação total deste material é a soma, em menor ou maior escala, das parcelas individuais de cada uma destas deformações.

Observa-se na literatura que as parcelas de deformações dependem do refinamento do modelo utilizado na análise.

Vários autores já formularam modelos, com maior ou menor grau de refinamento, na tentativa de melhor representar a evolução dessas deformações, seja com auxílio de retroanálises de medidas de campo ou de ensaios de laboratório, como será mostrado a seguir.

De maneira simplificada, PÖTTLER  e KUWAJIMA  consideraram o  modelo  reológico de  Boltzman  como representativo do comportamento do concreto projetado.

Enquanto KUWAJIMA, em suas simulações bidimensionais, levou em consideração duas parcelas de deformação, uma elástica imediata e a outra dependente do tempo, PÖTTLER, em suas simulações tridimensionais, considerou, além destas, a componente de deformação devido a temperatura.

No entanto, a parcela de deformação por temperatura é T admitida de influência secundária por este autor.

De forma mais refinada, baseado em um método chamado de taxa de fluxo de fluência que foi concebido por ENGLAND e ILLSTON, SCHUBERT  propôs um modelo de comportamento para o concreto projetado.

De acordo com SCHUBERT, e mais tarde aperfeiçoado por GOLSER, ALDRIAN, e GOLSER, a deformação total do concreto projetado é composta pelas seguintes parcelas.
Deformações elásticas  imediatas  totalmente reversíveis  diretamente  relacionadas ao módulo de elasticidade dependente do tempo.

Deformações lentas reversíveis, ou deformação elástica retardada, admitida  independente da idade, e a taxa de fluxo é maior em concretos jovem.

Deformações plásticas lentas, ou fluência, proporcionais ao estado de tensão, e a taxa de fluxo é função da idade do concreto.

Deformações por retração.

Deformações devidas à temperatura.

GOLSER relatam um extenso programa experimental que se encontrava em andamento na Universidade de Leoben.

Esta grande bateria de ensaios foi realizada através da retirada de testemunhos do suporte de 4 túneis em fase de construção na Áustria.

Todos esses ensaios buscavam a definição e calibração de modelos reológicos que comandam o comportamento do concreto projetado jovem para diferentes misturas, considerando variáveis como o seu histórico de carregamentos e de deformações a pequenas idades.

Em GOLSER, a compilação dos resultados desse programa experimental se encontra praticamente concluída, resultando em um modelo de taxa de fluxo plástico.
O primeiro termo da equação anterior se refere à deformação elástica instantânea, na qual o módulo de deformação relativo V*(t,a) é utilizado.

Este módulo de deformação é uma função do tempo e do grau de utilização (intensidade de tensões). 
Intensidade de tensão (tensão aplicada por resistência à compressão),idade do concreto em dias.

A deformação viscosa é representada pelo segundo termo da equação(115), mostrando sua clara dependência pela intensidade de tensão e duração do carregamento.

A deformação viscosa não reversível pode ser descrita.

Os outros termos da mesma equação (115) representam as influências do comportamento visco-elástico, da retração do material e da temperatura.

Com este modelo de taxa de fluxo é possível representar de maneira mais realista o complexo comportamento do concreto projetado jovem e a longo prazo.

Os demais parâmetros desta formulação podem ser encontrados com a ajuda de ensaios de fluência a longo prazo, descritos em detalhes por ALDRIAN.

Outros esforços no sentido de melhorar o entendimento do comportamento do concreto projetado sob a ação de carregamentos são reportados por MÜLLER, que apresenta parâmetros que caracterizam as diferentes parcelas de deformações retroanalizados a partir de ensaios de longa duração.

No entanto, de acordo com FERREIRA, alguns parâmetros deste modelo não foram ainda claramente divulgados nas publicações citadas anteriormente dificultando a sua utilização e conseqüente verificação de sua eficácia.

A partir da teoria da viscoplasticidade, considerando os parâmetros elásticos variáveis em função do tempo, MESCHKE  propôs um modelo em que o efeito da variação do módulo de elasticidade é representado pelo acúmulo das deformações não recuperáveis induzidas pelo envelhecimento em adição às deformações visco-plásticas.

Além disso, este modelo representa de forma mais realista o comportamento de importantes características do concreto projetado, tais como os modos de ruptura sob compressão e tração e faz uso de um número reduzido de parâmetros calibrados por dados experimentais.

Segundo MESCHKE, a decomposição das parcelas de deformação do concreto projetado deve incluir deformações elásticas instantâneas, deformações elásticas retardadas, deformações lentas, deformações resultantes da retração e temperatura.

A formulação geral do modelo tem como hipótese básica os distintos comportamentos do concreto projetado na compressão e na tração, que são governados por mecanismos independentes de endurecimento e amolecimento.

Este modelo consiste em uma formulação tridimensional baseada em multisuperfícies de viscoplasticidade com ajuste dos parâmetros do material em função do tempo.

O comportamento frágil do material à tração é modelado utilizando um critério de tensão máxima, considerando um amolecimento isotrópico.

A ductilidade do concreto sob compressão multiaxial e o endurecimento é feito considerando-se o modelo visco-plástico de Drucker-Praguer, com aceitação relativa para camadas finas de suporte submetido a estado de tensão biaxial.

E a ruptura do concreto projetado é modelada com base na teoria viscoplástica de fluxo isotrópico utilizando o critério de Rankine no contexto tridimensional para determinar a resistência à tração do concreto projetado.

Como foi mostrado no Capítulo 1, a região localizada nas vizinhanças da frente de escavação apresenta estados de tensões e deformações com feições marcadamente tridimensionais, e a única maneira de se representar bem a realidade dos fenômenos de transferência de carga do maciço para o suporte seria lançar mão de análises numéricas, também, tridimensionais.

No entanto, as análises deste tipo ainda não são tão comuns no projeto de escavações subterrâneas, dada a quantidade de tempo e recursos computacionais gastos em sua realização.

Análises deste tipo são justificáveis somente em casos especiais.

Para contornar esse problema, uma opção seria utilizar outros tipos de análises menos dispendiosas, mas em contrapartida menos completas.

Neste capítulo, além das análises tridimensionais, serão abordados alguns métodos de análise numérica alternativos, que têm a intenção de substituí-las em situações menos complexas.

Este tipo de análise pode ser resumido como uma aproximação à situação tridimensional efetuada por uma seqüência de análises bidimensionais das seções transversais de maior interesse no processo de construção de um túnel.

Os trabalhos de PAN  e LEE  mostraram que as simulações bidimensionais do estado plano de deformações conduzem a boas aproximações dos deslocamentos finais de modelos tridimensionais de túneis sem suporte, desde que executadas com certos critérios.

Serão discutidas as características gerais dos três métodos mais utilizados de simulação bidimensional dos efeitos de suporte da face para a determinação de tensões e deformações finais do maciço e do revestimento, e também serão discutidas as vantagens e desvantagens associadas a cada um destes métodos.

PANET e GUELLEC, e mais tarde PANET, com um maior rigor, sugeriram que o processo de escavação de um túnel poderia ser modelado por três etapas distintas, através da aplicação de uma pressão fictícia interna ao perímetro da escavação.

Na primeira etapa, considera-se o maciço como uma abertura não revestida com uma pressão interna igual à tensão in situ do terreno.

Como etapa posterior, antes de se instalar o suporte, a pressão interna é reduzida por uma fração, que também é conhecida como fator de alívio, e o terreno se movimenta radialmente para dentro do túnel de uma quantidade, u0.

Como etapa final, logo após ter-se igualado o deslocamento da abertura não revestida, u0, ao deslocamento obtido de leituras de instrumentação por exemplo, então o suporte é instalado e a pressão fictícia interna é reduzida a zero.

Esclarecendo-se melhor, para um túnel não revestido o efeito de suporte temporário fornecido pela frente de escavação pode ser simulado através de um modelo bidimensional por uma pressão radial interna fictícia, pf, atuando na superfície da escavação.

Esta pressão é tal que, o deslocamento da superfície interna do modelo bidimensional seja igual ao deslocamento obtido de leituras de campo, ao resultado de um modelo tridimensional, ou até mesmo a valores de deslocamento estimados pela experiência em escavações similares.

Contudo, deve ser ressaltado que a pressão fictícia no modelo bidimensional somente mantém o mesmo grau de deformação e tensão das paredes do túnel em situação real, ou em um modelo tridimensional, de modo que as deformações e as tensões que ocorrem dentro do maciço sejam um tanto quanto diferentes.

Todavia, este tipo de aproximação pode ser tomada como razoável, conveniente e precisa sob o ponto de vista prático de engenharia.

Seqüência de passos requeridos pelo método de pressão fictícia.

LAABMAYR e SWOBODA, sugeriram uma seqüência de simulações planas em que, inicialmente, o maciço deve ser considerado intacto.

Antes da escavação do túnel e colocação do suporte, o módulo de elasticidade da região do núcleo, ou seja, a região interna ao eventual perímetro do túnel é reduzido de uma parcela  e o maciço se move radialmente para dentro da abertura, apresentando um deslocamento, u0, no contorno da escavação.

Após isto, ativa-se o suporte e simultaneamente escava-se o túnel, reduzindo-se progressivamente o valor do módulo de elasticidade de seu núcleo até zero.

As etapas acima descritas podem ser melhor entendidas pela seqüência de etapas mostradas.

Deve ser destacado que, caso se reduza apenas o valor do módulo de elasticidade do núcleo sem que seja reduzido o seu peso próprio, podem não ocorrer os deslocamentos desejados se o modelo for analisado pelo MEF.

Ou seja, ao final de uma fase genérica, o maciço se encontra em equilíbrio e a redução do módulo de elasticidade da região escavada não altera mais as forças nodais atuantes, então se faz necessário reduzir o peso próprio do material do núcleo a ser escavado.

Seqüência de passos requeridos pelo método de redução de rigidez.

KOCHEN fazem críticas a este método relacionadas à inexistência de uma metodologia racional para se estimar o fator de redução de rigidez do maciço.

Além do mais, o peso específico do núcleo escavado poderia, em princípio, ser reduzido de uma proporção diferente da adotada para a rigidez do mesmo.

Isto implicaria no fato de ter que se ajustar empiricamente e simultaneamente dois parâmetros do modelo, ao invés de um só.

SCHWEIGER e PÖTTLER  indicam que o método de rigidez do núcleo apresenta algumas discrepâncias com valores medidos em campo, quando seqüências de escavação  um  pouco mais complexas com  materiais de comportamento não linear têm que ser simulados.

Este método pode ser considerado como um método derivado do método de pressão fictícia pois utiliza-se do mesmo principio de aplicação de forças nodais para a simulação dos efeitos de suporte da frente de escavação, apesar de que o processo para obtenção dos resultados finais é completamente diferente.

De acordo com PÖTTLER, este método é constituído essencialmente por três fases.

Primeiramente, determinam-se as tensões existentes na fronteira entre a região a ser escavada e o maciço para um estado de tensões in situ.

Após esta fase, retira-se o carregamento in situ e o material do núcleo, aplicam-se no perímetro da escavação as tensões obtidas na primeira fase, mas com sentido oposto à original e multiplicadas por um fator, até que se atinja o deslocamento desejado, u0.

Como terceira e última etapa, instala-se o suporte e aplicam-se as tensões obtidas na primeira fase com sentido contrário, mas agora multiplicada pelo fator de alívio.

O resultado final da simulação da escavação com a instalação do suporte é a soma dos resultados da simulação da primeira fase com os da terceira.

Este processo é discutido com mais ênfase em GOMES, onde é proposta uma expressão para a quantificação destes fatores de alívio.

Seqüência de operações requeridas pelo método de redução de carregamento.

SCHWARTZ e EINSTEIN  criticam os métodos que se utilizam do recurso de aplicação de tensões no perímetro da escavação, como é o caso deste e do método de pressão fictícia.

Ao se comparar as análises feitas por estes métodos de aplicação de forças nodais, com outras realizadas pelo método de redução de rigidez, eles observaram que todos os métodos são equivalentes quando o coeficiente de empuxo lateral é igual à unidade e o túnel é profundo o suficiente para que se despreze a variação de tensões com a altura da abertura.

No entanto, em situações diferentes (túneis rasos ou K01), os modelos que se utilizam da aplicação de forças nodais perdem um pouco de sua funcionalidade dada a dificuldade em se determinar a distribuição destas forças no perímetro da escavação, que neste instante não são mais uniformes como no caso de túneis profundos com campo de tensões hidrostático.

Segundo TRIGO, para que este método de redução de carregamento possa ser utilizado em análises pelo MEF, devem ser respeitadas as seguintes etapas.
Determinação das forças nodais exercidas pela massa a ser escavada na superfície que a separa do resto do maciço.

Eliminação dos elementos escavados.

Aplicação, na superfície delimitadora da escavação, de forças nodais simétricas às calculadas na 1ª fase multiplicadas por um fator de alívio.

A adição dos valores dos deslocamentos, deformações e tensões, existentes antes da escavação, aos respectivos incrementos ocorridos na fase atual.

Na literatura, as etapas do procedimento acima citado foram sempre utilizadas por vários pesquisadores da mesma maneira, exceto por algumas diferenças de considerações ao se executar a primeira e a segunda etapa.

Para o tipo de elemento mais utilizado nas primeiras aplicações do método dos elementos finitos, no caso o elemento triangular de três nós, a distribuição de tensões no seu interior era constante.

As tensões na sua fronteira e, por conseqüência, as forças nodais equivalentes não eram determinadas diretamente.

Assim, estas forças nodais na fronteira da escavação tinham que ser obtidas através das tensões conhecidas no interior dos elementos, recorrendo a uma média ponderada pelas áreas dos elementos envolvidos.

Portanto, resultava em uma forma não muito rigorosa de quantificação das forças nodais equivalentes na fronteira de escavação.

Foi proposta por CHANDRASEKARAN e KING  uma nova maneira de cálculo das forças nodais equivalentes, algo diferente das formas, até então, apresentadas.

Neste processo, são determinadas as forças nodais equivalentes ao estado de tensão em repouso.

Estas forças são atualizadas após cada fase de escavação, sendo os respectivos incrementos avaliados a partir do produto das matrizes de rigidez dos elementos que se localizam na fronteira de escavação em questão, pelos deslocamentos incrementais ocorridos na fase de escavação anterior.

CELESTINO propuseram um método rigoroso para o cálculo destas forças, que consiste no cálculo das forças nodais equivalentes, exercidas por um elemento a ser escavado nos outros elementos adjacentes, pela expressão, onde {f} designa o vetor das forças nodais equivalentes do elemento, [B] a matriz do elemento que relaciona as deformações e os deslocamentos e {} um vetor com as tensões iniciais do elemento.

Os valores de {} e de [B] são relativos aos pontos de integração de Gauss.

Analisando toda a fronteira da escavação, resulta na equação, na qual {F} representa o vetor das forças nodais exercidas pelos elementos a serem escavados nos nós pertencentes à fronteira da escavação, e M é o número de elementos escavados que têm fronteira comum com os elementos não escavados.

No caso da segunda etapa, a escavação do maciço, pelo que foi encontrado na literatura, pode-se dizer que existem duas maneiras básicas de executá-la.

Em alguns métodos de análise, a simulação é feita através da redução da rigidez dos elementos escavados até valores muito baixos, próximos de zero.

Enquanto que, em outras análises, por uma questão de otimização do tempo e do espaço de memória utilizados, estes elementos são simplesmente eliminados da análise, através da retirada de suas linhas e colunas da matriz de rigidez global.

Ao se considerar o MDF, não existe uma metodologia consolidada igual à mostrada anteriormente para o MEF.

Talvez, uma das explicações para isto se deve ao fato de que em diferenças finitas a região é discretizada por uma nuvem de pontos, dos quais já se tem informações sobre as forças resultantes para cada um destes pontos.

A escolha de qual método bidimensional utilizar, dentre os métodos citados anteriormente, é sempre uma questão de preferência profissional ou dependente das capacidades do software empregado.

Todos os métodos bidimensionais possuem grandes problemas associados às suas simplificações implícitas.

É necessário que se antecipem os fatores de alívio, os quais podem ser conhecidos a priori se alguma experiência para um dado método de construção numa condição específica e equivalente de maciço estiver à disposição.

Estes fatores de alívio poderiam ser determinados através de medidas de campo, mas estas estão disponíveis apenas para ajustes dos modelos numéricos durante a construção e não na fase de projeto.

Segundo SCHWEIGER e PÖTTLER, estes métodos são válidos somente para modelagem de túneis envolvendo apenas poucos passos de escavação  numa seção  transversal.

Paraseqüênciasmais complexas, comumente encontradas na construção de estações subterrâneas, estes conceitos podem não ser aplicáveis com o mesmo grau de confiança e assim os resultados podem ser fortemente dependentes do método utilizado.

ECKSCHMIDT e CELESTINO  ressaltam que, devido à presença de tensões cisalhantes atuantes no plano da seção transversal levarem a tensões desviatórias reais maiores que as obtidas em uma análise plana (em que se desprezam tais tensões pela simples consideração de ser aquele um plano principal), o material pode se plastificar antes e deformar-se mais do que é  mostrado nesse tipo análise.

Na tentativa de contornar este tipo de problema, NEGRO  propôs um método que tem como artifício a diminuição do  módulo de elasticidade do material do maciço na fase final da simulação, tentando reproduzir a plastificação com encruamento positivo deste material.

CELESTINO  mostra que concentrações de tensão junto à frente de  escavação podem gerar danos no material que modificam suas propriedades.

Em outras palavras, se as propriedades do maciço podem ser afetadas pela  trajetória de tensões, o efeito destas concentrações de tensões não será avaliado  em análises planas da seção transversal.

O parâmetro D de dano do maciço  introduzido por HOEK para minorar parâmetros de resistência do  maciço pode estar afetado pela trajetória de tensões, não reproduzido em  análises planas.

É de suma importância, quando são realizadas simulações bidimensionais de escavações subterrâneas, que todas as críticas mencionadas neste capítulo estejam em mente e, além disso, ressalta-se que estes método são apenas uma parte das precauções que devem ser tomadas ao se simular um túnel.

Segundo KULHAWY  existem mais fatores que influenciam muito na avaliação do comportamento de um túnel, estes são divididos em, tensão inicial, simulação da escavação (métodos descritos anteriormente), discretização do domínio, localização dos limites, condições de contorno e modelos constitutivos adotados.

Os demais fatores citados acima não serão discutidos neste trabalho.

A existência de simetria de revolução em relação a um determinado eixo permite simplificar o estudo de problemas tridimensionais, através de métodos análise numérica, utilizando malhas planas.

A condição de axissimetria da estrutura obriga que o modelo tenha infinitos planos de simetria que passem pelo eixo do túnel (eixo de axissimetria) e implica que suas características e carregamentos não variem com o ângulo, ou seja, na direção tangencial.

As simplificações introduzidas permitem não só uma diminuição das dimensões do problema a resolver mas também uma maior facilidade na preparação dos dados e na interpretação dos resultados.

Na verdade, os dados fornecidos são semelhantes aos fornecidos para análises planas, e a avaliação dos resultados é feita com muita facilidade para planos longitudinais que passam pelo eixo do túnel.

Contudo, estas simplificações implicam em algumas restrições como a seção do túnel a ser analisado é circular.

O coeficiente de empuxo lateral, K0, é igual a unidade.

O túnel é suficientemente profundo, ou seja, os efeitos da superfície do terreno são desprezados e a variação da tensão in situ com as dimensões verticais da abertura pode ser negligenciada.

Qualquer heterogeneidade do maciço é simétrica em relação ao eixo do túnel.

A complexidade do problema pode ser reduzida ainda mais se o maciço puder ser considerado linearmente elástico.

Deve-se ressaltar que estas hipóteses simplificam mas não eliminam a não linearidade das análises, o avanço incremental do túnel, ou seja, as mudanças de geometria do problema, são formas de não linearidade geométrica  inerentes  ao  problema.

Assumir o maciço  com comportamento linearmente elástico facilita a determinação numérica do problema além de ajudar muito na interpretação dos resultados.

A hipótese de simetria axial elimina qualquer possibilidade de se estudar os momentos fletores atuantes no suporte, pois estes somente se desenvolvem quando a geometria da seção transversal não é circular, ou quando K01, ou na ocorrência de ambos.

Contudo, esta limitação não é tão séria, pois estes momentos fletores são bem pequenos para a maioria dos sistemas de suporte usualmente utilizados.

Segundo SCHWARTZ e EINSTEIN, estes momentos são realmente significativos apenas em suportes muito rígidos.

Para definir o estado de tensões e de deformações do meio contínuo em condições de axissimetria, adota-se o elemento de volume definido num sistema de coordenadas cilíndricas (r, e z) com tensões normais e tangenciais segundo essas três direções.

As seis componentes de tensão definem o tensor simétrico de segunda ordem.

Elemento axissimétrico infinitesimal.

O equilíbrio de forças neste elemento, sem que sejam consideradas as suas forças de massa, resulta nas equações diferenciais, O motivo da ausência de forças de massa em simulações do avanço da frente de escavação de túneis profundos através de modelos axissimétricos, se deve exclusivamente ao fato de que a consideração da gravidade nestas simulações geraria uma situação irreal de carregamento no modelo.

Para um elemento de volume localizado no contorno do problema, solicitado por forças distribuídas na superfície do contorno (pr, p, pz), em que o vetor normal ao contorno é representado por seus cossenos diretores (nr, n, nz), as equações de equilíbrio.

Considerando-se a hipótese de que as deformações são muito pequenas, estas deformações podem ser relacionadas com os deslocamentos As relações entre tensões e deformações para materiais com comportamento elástico são da forma {} = [D]{}.

Se o material for isotrópico e tiver infinitos planos de simetria que passem pelo eixo de axissimetria (planos 0 rz), a matriz [D] é simétrica e definida por 2 constantes.

Para se contornar a impossibilidade inerente ao problema de se tratar estruturas axissimétricas  mas  com  carregamentos não necessariamente axissimétricos, WILSON  propõe um método em que os três graus de liberdade existentes em cada nó de um elemento finito e seus carregamentos são representados por séries de Fourier com funções harmônicas circulares.

As análises finais são constituídas por uma somatória de uma certa quantidade de análises bidimensionais, conseqüência das propriedades de ortogonalidade que são encontradas nessas funções trigonométricas.

Segundo LOPES, o problema encontrado neste tipo de análise repousa na quantidade de análises necessárias para se determinar cada resultado final do somatório com um grau de precisão satisfatório.

Este fato é de grande importância, pois pode acarretar um aumento excessivo do tempo de processamento, podendo até mesmo superar o tempo gasto por uma análise tridimensional completa.

Além disso, o problema não se resume apenas em uma questão de tempo de processamento, mas também na disponibilidade de software para executar este tipo de tarefa.

De um lado, os métodos bidimensionais têm a desvantagem de sempre necessitarem de alguns artifícios para representar, ainda de forma grosseira, os fenômenos tridimensionais envolvidos no processo de avanço de um túnel.
Além disso, os métodos axissimétricos apenas conseguem representam os aspectos tridimensionais do problema (geometria, condições de carregamento, anisotropia, entre outras) de maneira muito simplificada por outro lado, os modelos tridimensionais contornam estas barreiras permitindo que, · A seção transversal do túnel a ser analisado possa ter qualquer forma geométrica.

O coeficiente de empuxo lateral, K0, possa adquirir qualquer valor.

O túnel a ser analisado possa ser raso ou profundo.

Qualquer heterogeneidade, anisotropia do material, posição e forma das camadas que formam o maciço possa ser representada com facilidade.

Os avanços da frente de escavação possam ser feitos à seção plena ou parcializada.

Os efeitos de concentração de tensões junto à frente são adequadamente simulados, guardando os efeitos trajetória real de tensões no maciço remanescente Contudo, as maiores desvantagens das análises tridimensionais quando comparadas às análises bidimensionais e axissimétricas são as seguintes, · O alto consumo de memória tanto na fase de processamento, quanto no armazenamento dos resultados parciais e finais.

O alto consumo de tempo em seu processamento.

As dificuldades na confecção de malhas de situações complexas no domínio tridimensional convergência de túneis, estações, poços de ventilação.

As dificuldades na interpretação de alguns resultados no espaço 3 D (eg zonas de plastificação).

Com relação ao alto consumo de memória e de tempo no processamento deste tipo de modelo, por hora, pode-se dizer que a principal causa desta ocorrência é o aumento significativo do número de graus de liberdade de cada elemento, que por sua vez, ocasiona um aumento significativo no número de graus de liberdade do modelo.

Contudo, mais adiante, isto será abordado com maior riqueza detalhes no Capítulo 5, quando serão expostos os motivos da utilização de processamento paralelo na simulação tridimensional do processo de avanço de um túnel.

Modelo tridimensional de um túnel com avanço da frente de escavação parcializado.

Detalhe da parcialização da frente de escavação de um modelo tridimensional de um túnel.

Neste capítulo, como finalização da fase de revisão bibliográfica preliminar, são expostos com mais detalhes alguns métodos de análise da interação entre o maciço e o suporte de túneis.

Inicialmente, alguns conceitos do Método de Convergência-Confinamento são introduzidos, pois o conhecimento deste, que é um dos mais simples e antigos métodos de análise da interação, auxiliará na descrição de alguns fenômenos e na explicação de outros métodos expostos a posteriori.

Em segundo lugar, o Método de Análise Simplificado da Interação Maciço Suporte, proposto por SCHWARTZ e EINSTEIN  é exposto com mais ênfase, apesar de o método considerar somente suportes com propriedades constantes ao longo do tempo.

O motivo do alto grau de detalhamento utilizado nesta descrição se deve ao fato de que este método, mais adiante, servirá como base para o desenvolvimento de outros métodos que consideram o comportamento dependente do tempo para o suporte.

Após a descrição destes métodos de análises, considerados básicos, outros métodos mais elaborados como o de PÖTTLER, CELESTINO  e CHANG, que consideram o comportamento dependente do tempo para as propriedades do suporte e, eventualmente, para as do maciço, são abordados.

As curvas características vêm sendo utilizadas há muito tempo como ferramenta auxiliar no desenvolvimento de projetos de túneis.

Nesta seção, será feita uma breve revisão de seus conceitos básicos, a fim de que daqui para frente sejam utilizados como uma maneira de melhor se descrever a interação maciço-estrutura de um túnel revestido de maneira geral.

Aspectos gerais de curvas características.

Curvas características são simplesmente relações entre pressão, P, e deslocamento radial do maciço e do suporte, u.

A curva característica do maciço é construída, primeiramente, por assumir que existe um maciço não perturbado por um túnel escavado sem suporte.

Este possui inicialmente uma pressão interna, Pi, atuante em suas paredes com intensidade igual, mas de sentido contrário, às pressões existentes no maciço antes de sua escavação.

A partir deste momento, a pressão Pi é reduzida de forma que ocorre o aparecimento dos deslocamentos radiais u, e a curva descrita por esta variação de P versus u, nada mais é do que a curva característica do maciço.

Analogamente, a curva característica do suporte é baseada nos deslocamentos que se desenvolvem à mesma proporção que a pressão externa ao suporte é gradualmente acrescida por influência do maciço.

O ponto no qual as curvas do maciço e do suporte se cruzam é chamado de ponto de equilíbrio da interação, Ps será o carregamento final atuante no suporte e us será o seu deslocamento radial final.

Partindo-se da base da técnica convencionada, de que curva característica é uma relação entre pressão no entorno de uma abertura e deslocamento radial desse, deve ser notado que as inclinações das curvas serão basicamente funções das rigidezes do maciço e do suporte.

Sendo assim, o ponto de equilíbrio da interação é fortemente influenciado por uma relação entre as rigidezes em jogo.

Curvas características de suportes com diferentes rigidezes.

Muitos dos principais fenômenos, que ocorrem durante o processo de escavação de um túnel, podem ser facilmente entendidos pela construção de curvas características e pela análise de seus pontos de origem e equilíbrio.

Dentre outros, se destaca o efeito de suporte temporário da frente de escavação nas suas vizinhanças, o qual insere assim características tridimensionais ao problema.

Este efeito diminui à medida que a face se distancia da seção analisada e, consequentemente, o maciço se deformará mais e induzirá um carregamento externo ao suporte, completando a interação maciço-suporte.

A redução da pressão interna, Pi, nada mais é do que a consideração deste efeito, mas de forma bidimensional.

De forma semelhante, o atraso do suporte à face se indica pelo translado da curva característica do suporte de um valor u0, composto por uma parcela devida aos deslocamentos radiais ocorridos antes de a frente de escavação passar pela seção de análise, e por uma outra atribuída aos deslocamentos radiais ocasionados pelo atraso na instalação do suporte.

Outro efeito que pode ser observado, é a influência direta dos processos de escavação e execução do suporte nos pontos de equilíbrio da interação maciço-suporte.

Eessas influências podem ser compreendidas e algumas nuances entre se adotar um suporte com características independentes ou dependentes do tempo podem ser melhor ilustradas.

Esquematização dos efeitos de suporte da face e do atraso do suporte.

A curva característica para um suporte pré-moldado é uma reta partindo de u0 e interceptando a curva do maciço no ponto A.

Se considerarmos um comportamento dependente do tempo para o suporte, veremos que o início da curva característica para um suporte de concreto projetado é a mesma do anterior (conservadas as características geométrica do maciço e do suporte), mas a curva não é reta e intercepta a curva do suporte em B.

O motivo pelo qual não se encontra mais uma reta como curva característica para o suporte, reside no fato de que o concreto não possuir mais uma rigidez constante ao longo do eixo do túnel, mas sim crescente de uma seção que se localiza próxima à face até outra distante.

Podem também ser observadas as diferenças entre distintas seqüências de escavação.

Nos casos anteriores, foram escavados pequenos lances que logo foram revestidos.

Contrariamente, o processo de escavação que consiste na remoção ou desagregação brusca de uma grande quantidade de material do maciço, simulando a ação de se escavar um grande lance sem revesti-lo, foi gerador do ponto de equilíbrio em C.

O ponto C implica na desagregação do maciço.

Comparação gráfica entre diferentes características de dependência do tempo para o suporte e seqüências de escavação do maciço.

EINSENSTEIN e BRANCO  mostraram que o método de convergência e confinamento pode apresentar alguns resultados discrepantes à realidade.

Foram obtidos dados de monitoramento de dois túneis escavados praticamente sob as mesmas condições, exceto por um deles se tratar de túnel raso e o outro profundo.

Os dados de monitoramento do túnel profundo mostraram estar de acordo com os resultados do método de convergência e confinamento, enquanto que os dados do túnel raso não.

Os autores atribuem estas diferenças à inexistência de axissimetria no campo de deformações que se desenvolvem no túnel raso.

O método simplificado de análise, desenvolvido por SCHWARTZ e EINSTEIN, atribui explicitamente aos efeitos de três variáveis como sendo os principais responsáveis pelos esforços solicitantes encontrados em um suporte pela escavação de um túnel.

São elas, a rigidez do suporte em relação ao maciço, a distância entre o último lance revestido e a face (atraso na instalação do suporte) e a plastificação do maciço ao redor da abertura.

Apesar de abranger qualquer combinação de maciço e de suporte, de levar em conta aspectos tridimensionais da escavação e o comportamento físico não-linear do maciço, este método impõe algumas hipóteses simplificadoras, geradas pela ausência de técnicas de análises mais refinadas.

Abaixo, essas hipóteses são enumeradas juntamente com algumas restrições de utilização.

O túnel é único e de seção circular.

Ele é profundo o bastante para que a influência da superfície em seu comportamento seja insignificante, e para que as variações nas tensões do maciço ao longo da altura do túnel sejam desprezíveis, comparadas com a magnitude total de tensões.

Geralmente, uma profundidade de 2 diâmetros é suficiente para atender a esses requisitos.

O maciço é tratado como um meio contínuo, homogêneo e isotrópico.

Na prática, essa limitação inclui em seu conjunto de análise os maciços em solo, os maciços rochosos muito fraturados e os maciços rochosos sem fraturas.

Contudo, exclui totalmente a possibilidade de utilizá-lo em túneis escavados em camadas saprolíticas, ou em maciços nos quais as descontinuidades têm influência marcante em seu comportamento estrutural, seja por promover o escorregamento de grandes blocos, ou no caso de zonas de cisalhamento e falhas que acabam por gerar heterogeneidades e anisotropias no maciço.

Nem o suporte, nem o maciço exibem qualquer comportamento de dependência do tempo nas análises.

A resistência do maciço é aproximadamente simulada utilizando-se o regime elasto-plástico perfeito, mas pode ser facilmente adaptada a qualquer tipo de critério de plastificação ou ruptura.

O suporte é considerado elástico linear.

O suporte possui o seu "invert" completo (anel completamente fechado).

O túnel é escavado a seção plena (sem parcializações), e sem o auxílio de ar comprimido como medida de estabilização do teto e da frente de escavação.

Qualquer efeito de pressão de água nas cargas atuantes do suporte deverá ser tratado de maneira separada.

Segundo SCHWARTZ e EINSTEIN, em sua forma presente, o método não é indicado para tratar situações em que há a necessidade da utilização de tirantes e chumbadores, cambotas metálicas sem arco invertido e túneis múltiplos.

Também não pode ser utilizado para analisar o acréscimo no carregamento de suportes com o tempo para túneis em maciços que possuam pronunciadas características de fluência.

Como já dito antes, o propósito dessas hipóteses limitantes é reduzir o problema complexo, de se avançar com a escavação de um túnel, a seus elementos essenciais, para que ele se torne passível de tratamento pelos métodos de análise disponíveis.

Das três principais variáveis citadas anteriormente, se formam três passos fundamentais para estruturação do método.

Será feito um pequeno resumo de cada um destes passos, indicando os seus parâmetros de entrada, discutindo sua aplicabilidade geral e suas limitações específicas.

Os efeitos da rigidez relativa maciço-suporte no carregamento final, são incorporados no método simplificado através de soluções analíticas fechadas.

As soluções desenvolvidas assumem as condições do estado plano de deformações, de comportamento elástico linear do maciço e do suporte, assim como as convenções ilustradas.

Convenção de sinais positivos utilizada para carregamentos e esforços solicitantes na dedução das soluções fechadas de rigidez relativa.

As soluções fechadas de rigidez relativa consideram explicitamente os efeitos da rigidez do suporte comparada à do maciço, e o estado de tensões iniciais do maciço (consideração do coeficiente de empuxo lateral, K0) na determinação de deslocamentos radiais e esforços solicitantes do suporte como, esforços de compressão e momentos fletores em todos os pontos da abertura.

Mas não consideram os efeitos de atraso e plastificação, que são assuntos para as próximas seções.

Os esforços calculados por estas soluções podem ser pensados como esforços básicos para o desenvolvimento do método.

Os parâmetros de entrada requeridos para esta fase são Módulo de elasticidade e coeficiente de Poisson do maciço.

Módulo de elasticidade e coeficiente de Poisson do suporte.

Área da seção transversal do suporte por unidade de comprimento  longitudinal do túnel.

Momento de inércia da área acima referida em relação a seu eixo  central principal de inércia.

Raio da escavação.

Coeficiente de empuxo lateral do maciço.

Com exceção de K0, todos os demais parâmetros são utilizados na confecção de coeficientes adimensionais de rigidez da escavação.

O coeficiente adimensional de compressibilidade, C*, no qual se estabelece uma medida da rigidez relativa à compressão do suporte em relação ao maciço, é definido como, O coeficiente de flexibilidade, F*, no qual se estabelece uma medida da rigidez relativa à flexão do suporte e do maciço, é definido como, Pela análise dos coeficientes acima, fica clara a relação de C* com os esforços solicitantes de compressão do suporte, e a relação de F* com os momentos fletores.

Se diminuirmos os valores de C* e F* resultariam suportes mais rígidos, comparados aos maciços analisados, assim sendo, esses suportes absorveriam mais carregamentos oriundos do maciço que outros com coeficientes maiores.

Na dedução das expressões, que são soluções analíticas para os esforços solicitantes de compressão, T, e de flexão do suporte, M, são consideradas duas condições limites de transferência de tensões cisalhantes na interface maciço-suporte.

A primeira delas permite o deslizamento total do suporte relativo ao maciço, ou seja, não há transferência de tensões cisalhantes.

As equações obtidas através da consideração da condição de deslizamento relativo impedido, ou de transferência total de esforços cisalhantes na interface entre o maciço e o suporte.

A partir de análises paramétricas executadas com as expressões acima, SCHWARTZ e EINSTEIN  chegaram a algumas conclusões gerais acerca da sensibilidade dos esforços solicitantes à variações nos parâmetros de entrada.

T/P R é fortemente dependente de C* somente dentro do intervalo de 005<C*<50, e é relativamente insensível a variações de F*(para valores práticos de F*).

M/P R2 é próximo de zero para F*>100, e é insensível a variações de C*.

T/P R e M/P R2 são ambos insensíveis a variações de  para o maciço.

T/P R e M/P R2 variam linearmente com K0.

Baseado em considerações teóricas de equilíbrio limite, a maioria das situações reais analisadas pelo método são satisfeitas pela consideração de não se transferir tensões cisalhantes pela interface.

Mesmo nos casos onde a total transferência de cisalhamento é encontrada, as diferenças entre os esforços calculados por ambas as formas são pequenas.

Algumas das hipóteses básicas das soluções de rigidez relativa, apresentadas na seção anterior, admitem que o maciço e suporte são ambos tratados no estado plano de deformação, e que o suporte é instalado simultaneamente à retirada do material.

Nenhuma das duas hipóteses reflete de forma precisa a complicada interação entre o maciço e o suporte nas vizinhanças da frente de escavação.

Como conseqüência direta desses fatos, numa análise, os esforços solicitantes serão superestimados pelas expressões anteriores, para uma dada condição de escavação.

Podem ser vistas algumas mudanças no campo de tensões no plano longitudinal, geradas pelos avanços sucessivos da face de um túnel em uma seqüência real de escavação.

Carregamentos longitudinais gerados pelo avanço de uma escavação.

A remoção de material, necessária ao avanço da frente de escavação, causa mudanças no estado de tensões do maciço, promovendo uma redistribuição de carregamentos no maciço e no suporte, chamada de arqueamento longitudinal e transversal.

A maior parte desta carga redistribuída é transferida para o suporte, mas uma parcela significativa é destinada a uma região adiante da frente de escavação.

Em termos de deslocamentos, estes arqueamentos induzem o maciço a se deformar, como reflexo da ação de suportar uma parcela de carga maior.

Ao redor da abertura, para as porções do maciço que se localizam atrás da face, os movimentos são predominantemente na direção radial, caracterizando um estado plano de deformações.

Nas regiões vizinhas à face, os movimentos têm componentes nas direções radial e longitudinal, atribuindo-lhe feições tridimensionais.

Esta região de transição tridimensional se localiza de 1 a 2 diâmetros de túnel à frente e atrás da frente de escavação.

Os deslocamentos radiais do maciço ocorridos adiante da face, ou seja, bem antes de ser escavado, atingem uma parcela de 20 a 35% dos deslocamentos radiais totais ao redor do túnel.

Deslocamentos radiais ocorridos anterior e posteriormente a passagem da face.

Além desses deslocamentos radiais ocorridos adiante da face, outros são gerados pelo fato de que o suporte não é construído simultaneamente à retirada de material do último lance escavado, restando assim uma região não revestida de comprimento Lu.

A adição de todos os deslocamentos radiais anteriores à instalação do suporte, tem como resultado o valor u0.

Por analisá-lo, chega-se à conclusão de que o maciço acaba por arcar sozinho com parte do carregamento, anteriormente destinado ao suporte nas soluções de rigidez relativa, restando ao suporte uma parcela de carga reduzida.

A redução quantitativa dos carregamentos, ocasionada pela distância entre o último lance de suporte instalado e a frente de escavação, foi determinada por análises numéricas e expressões analíticas.

Essas análises todas assumiram um comportamento elástico linear para o maciço e suporte.

Para condições em que o estado de tensões inicial é hidrostático (K0=1), foram feitas análises axissimétricas com elementos finitos, de tal forma que fossem simulados os sucessivos avanços de um túnel, para se investigar a influência da tridimensionalidade da face e dos atrasos na instalação do suporte nos esforços e deslocamentos de um túnel.

Para condições de K01, os efeitos tridimensionais da face e de atraso do suporte foram aproximados em soluções planas fechadas, pela redução do módulo de elasticidade do núcleo do túnel, simulando a redução do efeito de suporte da frente de escavação.

Os resultados dessas análises foram essencialmente os mesmos para as duas considerações de estado de tensões iniciais, e em ambos os casos a redução nos esforços do suporte é representada por um fator de atraso, chamado de d, que é matematicamente descrito.

Onde o termo T, o qual ignora os efeitos do atraso do suporte, representa o esforço básico de compressão do suporte calculado no primeiro passo, e T' é o esforço de compressão reduzido dos efeitos de atraso do suporte.

O fator d é utilizado para se reduzir os esforços calculados no primeiro passo, como pode ser observado pelas expressões abaixo, nas quais cada subscrito se refere ao número do passo a ser calculado no método.

O segundo passo do método simplificado somente considera os efeitos do atraso, é totalmente independente da rigidez relativa e das variáveis de tensões iniciais tratadas no passo anterior.

Nesta fase, o primeiro parâmetro de entrada é o comprimento de atraso normalizado Ld/R.

O parâmetro Ld se entende como a distância entre a face e o ponto médio do último segmento de suporte executado de comprimento Ls.

Indicação dos parâmetros geométricos utilizados nas análises.

A relação entre d e Ld/R foi determinada pela correlação de forma adimensionalizada entre os esforços solicitantes de compressão resultantes das análises axissimétricas em elementos finitos e a distância à frente de escavação.

A regressão linear entre as variáveis de atraso e esforços solicitantes gerou a equação, Levando-se em conta considerações de limites físicos, d varia entre os extremos de 1, que indica o efeito de se escavar e revestir simultaneamente, até zero, que indica um efeito de não se revestir a abertura ou de se ter um grande atraso na instalação do suporte.

A escavação de um túnel gera um desconfinamento total ou parcial do maciço ao redor da abertura, que por sua vez pode desencadear três estágios básicos de comportamento do material que constitui o terreno escavado.

Primeiramente, ocorre um estágio elástico linear, que parte do estado de tensões iniciais, continuando até que as tensões de cisalhamento atinjam a tensão limite de plastificação do material.

Logo após este limite, uma fase plástica toma lugar, permanecendo até que por deformações excessivas, o túnel entre num estágio de colapso total.

Todos esses estágios podem ser melhor interpretados com a ajuda de curvas características.

A fase elástica é mostrada pela reta que tem origem em (P = Pi), e o final em (P = Py).

A partir desse ponto, a segunda fase começa a vigorar, valendo para o maciço o comportamento plástico, com ou sem variações volumétricas (com e sem dilatância).

Qualitativamente, os acréscimos no carregamento e no deslocamento radial do suporte, causados pela plastificação do maciço ao redor das paredes da escavação e pela consideração das variações volumétricas na plastificação.

Curvas características de diferentes comportamentos do maciço.

Contudo, a precisa determinação dos efeitos de plastificação do maciço é algo complexo, pois os efeitos da rigidez relativa do suporte, o seu atraso de instalação e a plasticidade estão todos acoplados.

Para o caso em que o estado de tensões iniciais é hidrostático, os efeitos combinados destas variáveis foram analisados utilizando-se de técnicas de simulações axissimétricas em elementos finitos, considerando o maciço como um material elástico perfeitamente plástico, e o suporte como elástico linear.

As principais descobertas dessas análises foram plastificações significativas do maciço podem se desenvolver à frente da face do túnel.

Para uma dada resistência do maciço, aumentando-se ambos, atraso e flexibilidade do suporte, a plastificação do maciço será aumentada.

Para o caso mais geral, em que K01, os efeitos de plastificação foram aproximadamente analisados utilizando-se de técnicas de simulações planas elasto-plásticas em elementos finitos.

Nestas análises, os efeitos de suporte da face e do atraso do suporte foram simulados pelo método de redução de rigidez do núcleo.

As conclusões gerais tiradas destes estudos paramétricos corroboram as anteriormente citadas no caso de axissimetria de carregamentos.

Em ambos conjuntos de estudo, um fator de plasticidade, y, foi indicado para representar os efeitos da plastificação do maciço, como demonstra a expressão abaixo, O termo Ps' simboliza a pressão de equilíbrio do sistema maciço-suporte no caso elástico, reduzida pelos efeitos do atraso do suporte por d.

Ps* é a pressão de equilíbrio do suporte no caso de plastificação, nela são incluídos os efeitos de atraso e rigidez relativa.

O fator y possui um limite físico inferior de 1, correspondente ao comportamento completamente elástico do maciço, mas não possui limite superior.

Dessa forma, o terceiro passo do método simplificado é determinar o fator de plasticidade, que é uma função dos parâmetros de resistência do maciço, muito embora, também, seja indiretamente dependente do atraso e da rigidez relativa do suporte.

A pressão de equilíbrio do sistema, Ps*, num maciço elástico perfeitamente plástico, sob condições de K0=1, deve satisfazer equação.

Esta equação pode ser representada graficamente pelas curvas características.

Representação gráfica da equação (317).

Para se calcular o fator de plastificação, a equação (317) deve ser resolvida duas vezes.

Na primeira, se considera o maciço com comportamento elástico e se retira Ps'.

Na segunda vez, considera-se plástico e Ps* é extraído.

Determinadas as pressões de equilíbrio, o fator y é calculado como sendo o coeficiente Ps*/Ps'.

A determinação de y representa o passo final do método simplificado de análise, e o esforço do suporte, T*, o qual é proporcional à magnitude da pressão Ps*, é calculado como sendo, Duas críticas que podem ser feitas a este método são relativas à ausência de um certo rigor nas formas de escolha e abrangência das propriedades, e nas análises finais realizadas em sua elaboração.

Por hora, estas incongruências não serão comentadas com a profundidade devida, contudo, nos dois capítulos subseqüentes, elas serão abordadas com mais detalhes Este método foi proposto com o objetivo de se simular a escavação de um túnel considerando o comportamento dependente do tempo do suporte de concreto projetado e, desta forma, determinar-se a máxima tensão de compressão atuante no suporte e o fator de segurança deste durante o processo de escavação.

O método foi elaborado a partir de análises tridimensionais, que simularam a execução de um túnel em um maciço elástico com sistema de estabilização visco elástico, de onde foram obtidos alguns parâmetros auxiliares para realização de simulações bidimensionais.

Ao invés de se lançar mão de análises tridimensionais demoradas que consideram o avanço da frente de escavação passo a passo, este método permite a utilização de um modelo numérico bidimensional simples e de uma certa eficácia, onde o comportamento do maciço e do concreto projetado são elásticos lineares.

Neste caso, o método de redução de carregamento, descrito no capítulo 2, é utilizado como uma maneira de se considerar os efeitos de transferência de carregamento do maciço para o suporte.

Com o propósito de se levar em conta as propriedades dependentes do tempo do suporte neste modelo bidimensional, um módulo de elasticidade hipotético para concreto projetado foi determinado.

Este módulo hipotético é menor do que o seu módulo de elasticidade aos 28 dias, e buscou representar o histórico de enrijecimento do suporte de concreto projetado, o seu comportamento de fluência e o seu histórico de carregamento devido ao avanço da escavação.

Um estudo paramétrico extensivo revelou uma pequena dispersão deste módulo de elasticidade hipotético, mesmo com uma grande variedade de parâmetros geomecânicos do maciço e tecnológicos do concreto projetado, e pode ser tomado igual a 7000 MPa, quando o módulo de elasticidade ao final de 28 dias é da ordem de 30000 MPa.

Outra constatação de PÖTTLER  é que devido aos processos de relaxação, a tensão no suporte de concreto projetado diminui com o tempo, e esta tensão atinge um valor de aproximadamente 4 MPa aos 14 dias, independentemente das condições de contorno representadas.

POTTLER  admite que o método apresenta algumas falhas quando o maciço apresenta um comportamento elasto-plástico muito pronunciado, e quando as seqüências de escavação exigem muitas parcializações.

Contudo, o comportamento dependente do tempo do maciço não influenciou muito, tanto no que diz respeito ao módulo de elasticidade hipotético, quanto em relação aos valores finais de tensão no suporte, se este comportamento de dependência do tempo não for muito exagerado nos 14 primeiros dias após a instalação do suporte.

Este método foi proposto fomentado pelas constatações feitas por CELESTINO, as quais criticam os métodos usuais de dimensionamento de túneis por considerarem apenas configurações estabilizadas de deformações e tensões, situações que somente ocorrem em seções distantes da face de um túnel.

Em verdade, a maioria dos acidentes em obras subterrâneas ocorre exatamente no intervalo não analisado, ou seja, perto da frente de escavação.

Como exemplos deste tipo de acidente podem ser citados os acidentes ocorridos no Metrô de São Paulo em 1989 e 1990, relatados por CELESTINO e ROCHA.

Para superar estas simplificações no dimensionamento do suporte de túneis, CELESTINO  apresenta um método de cálculo do tipo convergênciaconfinamento que leva em conta os comportamentos dependentes do tempo para o maciço e suporte de concreto projetado, assim como, a consideração dos efeitos tridimensionais da frente de escavação.

O comportamento do maciço é representado através do modelo de Burger,agora expresso pela equação diferencial.

Os efeitos tridimensionais da frente de escavação, que ocasionam a transferência de carregamento do maciço para uma determinada seção transversal, quando a frente do túnel avança entre as posições x1 e x2, são considerados de acordo com a expressão.

O comportamento reológico do concreto projetado novo, foi adotado como sendo o modelo reológico desenvolvido na Universidade de Leoben.

O módulo de elasticidade para um dado tempo, t, expresso em dias de um concreto que, aos 28 dias, possui um módulo de elasticidade igual a E28, é determinado pela expressão proposta pelo CEB FIP.

Os valores de retração em função do tempo em dias são calculados através da expressão proposta pelo ACI em 1978.

Durante a fase de escavação, assumindo que isto cause um decréscimo linear de tensões com o tempo, pode ser obtida uma solução fechada pela integração da equação em condições de axissimetria.

Para a interação com o anel de concreto projetado, um esquema numérico para a integração direta no tempo foi desenvolvido.

Na equação, P assume o valor da expressão, onde Pc é o carregamento externo no anel de concreto projetado.

CELESTINO  compara os resultados de seu método com as observações de instrumentação, obtendo um ajuste regular da curva do modelo numérico com os pontos de instrumentação, após a calibração dos parâmetros elásticos e viscosos do modelo Burger.

Contudo, CELESTINO  reconhece que o mecanismo de transferência de carregamento do maciço para o suporte ainda não representa bem a realidade de escavações suportadas por concreto projetado, pois, como já dito, SCHWARTZ e EINSTEIN  desenvolveram o seu método simplificado para a análise da interação em que o suporte possuía propriedades constantes.

CELESTINO  compara também algumas curvas de esforços de compressão do suporte para diferentes taxas de escavação com curvas de crescimento da resistência a compressão simples do concreto projetado, mostrando possíveis rupturas no suporte de túneis escavados com altas velocidades de avanço.

Desta maneira, ressalta-se a grande necessidade em se compatibilizar a velocidade de avanço da face do túnel com as características físicas e geométricas da escavação.

O escopo principal deste método é a determinação do carregamento atuante num segmento de suporte de concreto projetado e seu fator de segurança.

Isto é obtido ao se estabelecer uma relação entre a pressão atuante no suporte, ps, e a pressão fictícia devida ao efeito de suporte da frente de escavação, pf, através de soluções analíticas da curva característica do maciço com as teorias da elasticidade e elastoplasticidade para problemas que admitam a consideração do estado plano de deformações.

A relação entre estas duas pressões atuantes no suporte é deduzida por CHANG  baseado nas soluções analíticas propostas por STILLE  para túneis circulares em meios elastoplásticos.

O suporte é considerado elástico com rigidez crescente com o tempo.

O método segue quatro passos fundamentais que são descritos sucintamente (sem a formulação analítica).
Assume-se ou determina-se a velocidade de avanço da frente de escavação, x(t).

Determina-se a pressão fictícia devida ao efeito de suporte da face em função da  posição da seção de análise em relação a face do túnel, pf(x).

Determina-se os incrementos de pressão no revestimento, ps, e assim a pressão  total é obtida pelo acúmulo destes incrementos.

O fator de segurança do suporte é então determinado pela comparação entre a  tensão de compressão do suporte gerada pela pressão atuante, ps, e a resistência à  compressão do concreto projetado, c, a cada lance do processo de escavação.

Neste capítulo, com a intenção de se introduzir algumas ferramentas de grande importância ao desenvolvimento deste trabalho é feita uma exposição de conceitos sobre processamento paralelo.

Primeiramente, são expostos os problemas encontrados na simulação do avanço da frente de escavação de túneis, causados pelo aumento significativo no tempo de processamento, e como eliminá-los através de algumas opções de processamento paralelo.

Em seguida são enumeradas algumas definições e considerações básicas acerca de processamento paralelo e alguns alertas sobre os problemas decorrentes da utilização destas técnicas.

Além disso, são discutidos vários tipos de arquiteturas de computadores, um dos principais fatores que influenciam na confecção otimizada de uma aplicação paralela.

A partir dessas arquiteturas, na terceira parte do capítulo, são explicadas as várias técnicas de programação paralela, entrando também no mérito dos níveis de paralelismo e particionamento desses programas.

E, finalmente, são mostradas as formas de se medir o desempenho de computadores e programas paralelos.

A simulação numérica dos processos de avanço da frente de escavação e de instalação do suporte de túneis requer uma grande quantidade de tempo em seu processamento.

Dependendo do caso, este processamento pode durar dias.

Esta alta demanda de tempo é ocasionada por uma combinação de fatores encontrados em simulações numéricas desse tipo de obra geotécnica.

Como exemplo destes citam-se, · A modelação da não-linearidade geométrica intrínseca do problema é feita através de vários passos de escavação e instalação do suporte.

Para uma modelagem fiel ao processo de construção de um túnel, exige-se um alto grau de refinamento na direção de seu eixo longitudinal, em vista das grandes dimensões longitudinais a serem escavadas e dos pequenos passos de escavação e instalação do suporte.

O resultado disso é a solução por reiteradas vezes de um problema com um grande número de incógnitas como será demonstrado adiante.

Se no caso das simulações de escavações profundas de túneis circulares singelos sem parcializações este problema já traz consigo um grande ônus no tempo total de processamento, o que se pode dizer das simulações do avanço de frentes de escavação para estações metroviárias com assimetria de operações.

O aumento significativo no número de graus de liberdade envolvidos na discretização do problema quando se passa de um domínio bidimensional para um tridimensional.

Além do aumento do número de nós por elemento, existe ainda a adição de graus de liberdade em cada nó.

No caso das simulações abordadas neste trabalho são necessários elementos hexaédricos quadráticos isoparamétricos para a discretização do maciço, e elementos quadráticos isoparamétricos do tipo casca para a discretização do suporte, ou da união de alguns elementos hexaédricos na espessura do revestimento para uma razoável determinação dos efeitos de flexão.

Nas simulações tridimensionais, o hexaedro com vinte nós substitui o quadrilátero de oito nós, que é geralmente utilizado em simulações bidimensionais, e o elemento casca de 8 nós substitui o elemento viga de 3 nós.

Assim, há o acréscimo de uma incógnita de deslocamento por nó, no caso de elementos sólidos, e a inclusão de três incógnitas, uma relativa aos deslocamentos e duas outras às rotações por nó, no caso de elementos casca.

Cada lance de escavação é discretizado longitudinalmente por dois elementos quadráticos, afim de que a distribuição de carregamento calculada nesta direção seja fidedigna à realidade, principalmente em regiões próximas da frente de escavação, onde os gradientes de tensão e deformação são os maiores de todo o domínio analisado.

Os lances de escavação são sucessões de planos lineares e quadráticos.

Cada lance é composto por 2 planos quadráticos e dois lineares, sendo que o último lance do domínio possui um plano quadrático a mais a ser considerado.

Detalhe da discretização de um lance de escavação.

Na simulação de um túnel circular singelo com raio de 3 metros, escavado com uma velocidade de 8 metros por dia, são necessários aproximadamente 170 lances de escavação de 1 metro para que as propriedades do revestimento de concreto projetado se estabilizem até um certo patamar que não interfira no perfil longitudinal de carregamento por parte do maciço no suporte.

Além dessa grande dimensão de escavação, são necessários pelo menos 10 raios de túnel (30 metros) posteriores e anteriores a esta região para se descartarem os efeitos de borda do domínio, contabilizando assim um total de 230 lances de escavação, 461 planos quadráticos e 460 planos lineares.

Suponha-se que os planos quadráticos e lineares com baixo grau de refinamento, são os planos que irão compor a malha tridimensional a ser utilizada nas simulações.

Cada plano quadrático possui 40 elementos e 147 nós, e cada plano linear possui o mesmo número de elementos, mas com 51 nós.

Como temos 461 planos quadráticos e 460 planos lineares, temos também 18400 elementos, 91227 nós e 270905 graus de liberdade.

Para uma malha mais refinada estas contas poderiam chegar a valores superiores a um milhão de incógnitas.

Representação das malhas bidimensionais quadrática e linear com  baixo grau de refinamento que compõem o modelo tridimensional.

A modelação da não linearidade física do problema é feita através da adoção  de um critério de plastificação, ou ruptura, acoplado a uma relação  constitutiva não linear, o que resulta em um sistema não linear.

A resolução  de um sistema não linear é feita geralmente através de algoritmos  incrementais iterativos, como é caso do método de Newton-Raphson.

Nesses algoritmos, a solução do sistema não linear  é atingida através de várias linearizações desse sistema e a resolução desses  sistemas lineares resultantes.

São resolvidos vários sistemas lineares  para a solução de um não linear.

Desta forma, optou-se por estudar meios mais produtivos e eficientes de se modelar o problema do avanço de frentes de escavação.

A única forma de se reduzir a grande quantidade de tempo necessária para a resolução desses problemas é aumentar a velocidade de processamento.

Para que se aumente a velocidade de processamento pode-se recorrer a três alternativas.
A utilização de um processador bem mais rápido, contudo, diferente da arquitetura i386, o que geralmente significa um alto custo para sua aquisição e um alto custo em "software" para seu gerenciamento e operação.

A utilização de técnicas de processamento paralelo com memória compartilhada.

Neste caso, os processadores e o "software" não são o problema, contudo as placas-mãe em que estes processadores são acoplados possuem um preço que varia exponencialmente com o número de processadores utilizados.

A utilização de técnicas de processamento paralelo com memória distribuída.

Neste caso, nem os processadores, nem o "software" e nem as placas-mãe são sinônimos de altos preços, e a única desvantagem desse tipo de arquitetura está relacionada a algumas perdas no tempo de comunicação via rede, o que pode ser contornado pela implementação de um programa otimizado para o tipo particular de arquitetura.

Dadas a eficiência e as vantagens econômicas, brevemente expostas, partiu-se para o desenvolvimento de um protótipo de sistema paralelo com memória distribuída.

Como primeiro passo, foi feito um estudo de arquiteturas e, posteriormente, foram estudadas algumas técnicas de programação paralela.

O conceito de processamento paralelo refere-se à aceleração da execução de um programa pela divisão deste em múltiplos fragmentos que possam ser executados simultaneamente.

Sendo assim, um programa, quando é executado em n processadores, poderia até ser n vezes mais rápido que o mesmo programa executado em um processador simples, se não existissem algumas perdas desempenho.

Estas perdas são normalmente geradas pela má exploração da latência e da largura de banda do sistema de comunicação, que serão tratadas mais adiante neste capítulo.

O processamento paralelo pode ocorrer de várias formas, desde a forma mais comum encontrada em computadores pessoais, em que componentes com seus próprios processadores ( placas de vídeo, som, etc), projetados para desempenharem tarefas específicas, são acoplados à placa principal que por sua vez conecta estes processadores ao processador principal.

Pode ocorrer de formas menos usuais, como o caso dos processadores vetoriais que desempenham internamente e de forma concorrente várias operações em vetores de dados.

Além dessas formas de paralelismo, podem ser citados ainda os sistemas SMP (Symmetric Multi-Processing) e os "clusters".

Os sistemas SMP são sistemas em que os múltiplos processadores compartilham dos mesmos endereços de memória e do mesmo barramento (bus), alojados numa única placa mãe.

Já um "cluster" nada mais é do que um grupo de computadores interconectados por uma rede de alta velocidade, onde cada computador possui seu próprio barramento e memória.

No próximo item, para uma melhor compreensão dessas diferentes formas de paralelismo, serão abordadas algumas arquiteturas de computadores juntamente com suas vantagens e desvantagens.

Embora a utilização de múltiplos processadores acelere muitas operações, a maioria das aplicações não pode ainda se beneficiar do processamento paralelo.

Basicamente, o processamento paralelo é apropriado somente se, · as aplicações tiverem um paralelismo suficiente para se fazer um bom uso de múltiplos processadores.

Em parte, esta é uma questão de se identificar porções do programa que podem ser executados independentemente e simultaneamente em processadores diferentes.

Contudo, mais adiante, será mostrado que alguns processos que poderiam ser paralelizados, na verdade, tendem a diminuir a velocidade de execução se estes forem utilizados em sistemas com algumas peculiaridades.

Como exemplo, suponha-se que um programa leva 4 segundos para ser executado em um único processador, este mesmo programa poderia ser executado em apenas um segundo se fosse processado em uma máquina com quatro processadores.

No entanto, nenhum ganho de velocidade de execução seria atingido se ao executá-lo ocorresse uma demora de 3 segundos ou mais para que estas máquinas coordenassem  suas ações, devido a problemas de latência e de largura de banda de  comunicação.

Um programa aplicativo particular já está paralelizado, ou seja, recodificado  para levar vantagens do processamento paralelo, ou deseja-se fazer alguma  modificação neste.

Interessa-se em pesquisar, ou pelo menos em estar familiarizado com tópicos  envolvendo processamento paralelo.

Uma das principais vantagens do processamento paralelo aplicado aos "clusters", quando se deseja executar processamentos de grande porte e complexidade, ou operar em grandes conjuntos de dados, é ter o desempenho de um supercomputador a um preço bem reduzido.

Além disso, o processamento paralelo neste caso é bastante tolerante a falhas e bem escalável.

A arquitetura de computadores engloba tanto o estudo da estrutura isolada de cada um dos componentes de um computador, quanto às interações entre estes.

Com relação à forma de se organizar e interligar esses componentes para realização de instruções, surgiram a partir do início da década de 40, vários paradigmas de organização de instruções para computadores.

Os padrões mais comuns podem ser enumerados como se segue.
Máquina de von-Neumann (Instruções dirigidas), a maioria dos computadores, de alguma forma, foi baseada neste tipo de sistema convencional de computação idealizado por NEUMANN.

Nele, o computador é organizado em cinco unidades, 1 propriedade de se instalar ou remover nós de processamento sem dificuldades.

Entrada,transmite dados e instruções do ambiente para a memória.

Memória, armazena instruções, dados e resultados intermediários.

Unidade lógico-aritmética, executa as operações lógicas e aritméticas.

Controle, interpreta as instruções e providencia a execução.

Saída,transmite os resultados finais para o ambiente exterior.

Esquema da máquina de von-Neumann.

As instruções, neste tipo de paradigma, são realizadas pelo processador seqüencialmente, e cada instrução percorre um ciclo.

Ciclo de execução na máquina de von-Neumann.

Com este tipo de arquitetura, a busca de instruções e/ou dados na memória, que está fora da unidade central de processamento, é um dos fatores mais relevantes para perda de velocidade em um ciclo.

Este obstáculo é conhecido como gargalo de von-Neumann.

Além da máquina de von-Neumann, surgiram ainda outras formas básicas de arquitetura.
Neste tipo de arquitetura as instruções se realizam tão logo os operandos são obtidos ou que estejam prontos para sua utilização, ao contrário do esquema, onde as instruções são realizadas passo a passo.

Este paradigma consiste em realizar as instruções quando os dados são exigidos para os outros cálculos, e não quando os dados estiverem prontos como no caso do fluxo de dados dirigidos.

Como a maioria dos computadores segue o paradigma da máquina de von-Neumann, uma das maneiras imediatas utilizadas para se aumentar o desempenho deste tipo de arquitetura foi tentar diminuir o tempo de ciclo de uma operação no processador.

O estudo do aperfeiçoamento dos processadores e outros componentes é algo que instiga os pesquisadores na área de microeletrônica há anos.

Mais especificamente, nas últimas três décadas, o desenvolvimento tecnológico desta área tem causado um avanço notável em componentes de hardware como circuitos mais rápidos e mais densos e também sistemas de memória cada vez mais potentes.

Contudo, a velocidade da atual forma de transmissão de dados está limitada à velocidade da luz no vácuo da ordem de 3 x108 m/s.

Como exemplo desta limitação física, no período de 1976 a 1985, o avanço no ciclo dos processadores foi de três vezes, enquanto que, no período de 1985 a 1992, o ganho foi de duas vezes.

Mostra-se, então, que procurar obter computadores de alto desempenho apenas com arquitetura otimizada no ciclo de um processador, hoje em dia é uma forma pouco eficiente, restrita e cara de se promover aumento na velocidade de processamento.

Desta maneira, partiu-se para a utilização de modelos de concorrência ou paralelismo para se obter uma maior eficácia desses incrementos na velocidade de computação.

Para esses modelos de concorrência surgiram várias formas de se executar os processos através da utilização de instruções iguais ou diferentes sobre os mesmos ou diferentes dados.

Baseado na questão de se executar tanto iguais como diferentes instruções em dados da mesma natureza foram propostas várias classificações para este subconjunto de arquiteturas.

Uma das classificações mais utilizadas hoje em dia é a taxonomia proposta por FLYNN, que se divide em classes.

Single Instruction stream Single Data stream refere-se ao modelo de execução seqüencial sem qualquer paralelismo, em que se executa uma única instrução em uma única seqüência de dados por ciclo.

Os computadores seqüenciais com paradigma de von-Neumann se enquadram nesta categoria.

SIMD (Single Instruction stream Multiple Data stream), refere-se ao modelo de execução paralela no qual o processador é capaz de executar uma mesma operação de forma simultânea sobre várias seqüências de dados.

Este modelo naturalmente se adequa ao conceito de se realizar a mesma operação sobre os dados de uma tabela, e é por isso freqüentemente associado com manipulação de vetores e tabelas.

As interações entre os processadores SIMD tendem a serem facilmente implementadas por causa do alto sincronismo inerente das operações realizadas por estes.

Dentro desta classe se encontram os supercomputadores vetoriais e os processadores com a tecnologia MMX.

MISD (Multiple Instruction stream Single Data stream), refere-se ao modelo de execução paralela no qual o processador é capaz de executar várias operações de forma simultânea sobre uma única seqüência de dados.

Dentro desta classe se encontram os supercomputadores que operam com técnicas de pipeline e computadores com vários processadores tentando quebrar um código de criptografia.

Esta classe de computadores não possui um representante criado especialmente para este fim, contudo, é possível resolver problemas como este através de um computador da classe MIMD a seguir.

MIMD (Multiple Instruction stream Multiple Data stream), refere-se ao modelo de execução paralela no qual cada processador está essencialmente agindo de forma independente, havendo assim, múltiplos dados e instruções.

Este modelo se assemelha mais naturalmente ao conceito de decompor um programa para execução paralela em bases funcionais, por exemplo, um processador poderia atualizar um arquivo de dados enquanto outro processador geraria uma tela gráfica de uma nova entrada de dados.

Este é um modelo mais flexível que o SIMD, mas tem a desvantagem de oferecer alguns riscos de falhas, chamadas "race conditions", nas quais um programa pode falhar intermitentemente devido a variações na sincronização, desta forma reordenando as operações de um processador relativas às de um outro.

Muito embora a classificação proposta por FLYNN seja conveniente numa primeira aproximação, ela é bastante imprecisa para classificar a grande variedade de computadores com múltiplos processadores.

Partindo destas classes primitivas, foram propostas novas variantes, ou por possuírem restrições àquelas primeiras, ou por serem modelos híbridos de execução paralela.
SPMD (Single Program stream Multiple Data stream), refere-se a um modelo de execução paralela variante e restrita do MIMD, na qual todos os processadores se encarregam de executar o mesmo programa.

De forma diferente do SIMD, cada processador executando o mesmo código pode tomar uma trilha diferente do fluxo de controle do programa.

SWAR (SIMD Within A Register), é um termo genérico para o modelo em que se particiona um registrador em múltiplos campos inteiros e se utiliza de operações de largura máxima de registradores para se realizar computações paralelas do tipo SIMD através desses campos.

Dada uma máquina com k bits de registradores, trilhas de dados e unidades funcionais, sabe-se que as operações simples com registradores podem funcionar como operações paralelas SIMD com n valores de campo de k/n bits.

Embora este tipo de paralelismo possa ser implementado utilizando-se registradores inteiros e instruções simples, muitos microprocessadores modernos têm recentemente adicionando instruções especializadas para aumentar o desempenho desta técnica para tarefas orientadas de multimídia.

Como exemplos de processadores desse tipo, pode-se citar Intel com tecnologia MMX, AMD e Cyrix.

Híbridos, refere-se a modelos onde há a combinação de diferentes arquiteturas como é o caso de multiprocessadores onde cada nó de processamento é um processador vetorial.

Neste caso houve um acoplamento entre arquiteturas do tipo MIMD e SIMD.

Dentro desta variante também se enquadram os processadores acoplados (Attached Processors).

Processadores acoplados são essencialmente sistemas hospedeiros em que cada placa conectada à placa principal desempenha uma tarefa diferente de maneira a acelerar um tipo específico de processamento.

Muitas placas de vídeo e áudio para computadores pessoais contêm processadores acoplados projetados, respectivamente, para acelerar operações gráficas e de processamento digital de som (DSP Digital Sound Processor).

Existe também uma grande quantidade de processadores de vetores acoplados, assim chamados porque são projetados para acelerar operações aritméticas em tabelas.

Dentre os vários paradigmas de paralelismo existentes para computadores de alto desempenho, algumas dessas arquiteturas têm se destacado na resolução de problemas de engenharia.

Primeiramente, os supercomputadores vetoriais de arquitetura SIMD possuem a vantagem de realizarem de uma só vez uma operação numa grande quantidade de dados, ideais para problemas com grande número de operações matemáticas entre matrizes e vetores.

Contudo, a grande dificuldade no desenvolvimento desse tipo de computador reside no fato de que se necessita que as memórias de cache dos processadores sustentem uma alta taxa de fluxo de dados exigida pela velocidade de operações deste sistema vetorial.

Mesmo com o avanço dos componentes de memória, o seu custo ainda é muito alto para o volume de operações exigido hoje em dia.

Além do alto custo de aquisição, outros problemas, relativos à utilização de supercomputadores comerciais, podem ser enumerados alto custo de software proprietário.

Alto custo de manutenção.

Total dependência de fornecedores credenciados.

Dificuldade de atualização e escalabilidade.

Com todos esses empecilhos encontrados para este tipo de processamento, os pesquisadores têm buscado sistemas de computação paralela do tipo MIMD.

A categoria MIMD engloba uma grande gama de modelos de máquina e podem ser entendidas como um conjunto de processadores trabalhando independentemente sob o controle de um único sistema operacional.

A maneira como os processadores e a memória do sistema estão conectados permite a subdivisão da categoria MIMD em computadores com memória compartilhada e com memória distribuída.

Arquitetura MIMD com memória compartilhada Nesta classe, estão incluídas todas as máquinas com múltiplos processadores que compartilham um espaço de endereços de memória comum.

São máquinas onde os processadores se encontram acoplados em uma mesma placa, dividindo os mesmos endereços de memória, e a comunicação entre os processadores é feita através do barramento da placa mãe, ou "bus".

A busca ou a mudança do valor de uma determinada variável é feita por qualquer processador a qualquer momento, desde que seja bem controlada por seus dispositivos internos.

O compartilhamento de dados entre os processo se torna extremamente rápido, sendo esta uma das principais vantagens desta arquitetura.

Em uma arquitetura deste tipo, também chamada de SMP (Symmetric Multprocessing), um processador não fica parado se há trabalho a ser feito.

Serve de ilustração a este tipo de arquitetura paralela.

A memória fisicamente compartilhada pode ter ambas qualidades de alta largura de banda de comunicação e baixa latência, mas isso ocorre somente quando os múltiplos processadores não tentam acessar simultaneamente o barramento da placa.

Contudo, a concepção de memória globalmente compartilhada gera quatro problemas principais, são eles, Esquema de máquina com memória compartilhada.

Alto custo, são computadores bastante caros, mesmo se tratando de máquinas  com o número mínimo de dois processadores.

Além disso, existe um alto  custo para a sua escalabilidade, ou seja, ao aumentar o número de  processadores, os  preços desses computadores  crescem  desproporcionalmente.

Escalabilidade limitada, refere-se à existência de limitações físicas para a  quantidade de processadores em um sistema.

As placas são projetadas para  suportar um número máximo de processadores de um mesmo tipo, sem a  possibilidade de ampliação ou mudança de tipos.

Conflito de software, ocorre quando dois ou mais processadores alteram a  mesma variável sem a devida sincronização das instruções.

Assim, a  sincronização entre os vários processos tem um caráter importante na  erradicação deste tipo de problema, que é conhecido como race condition.

Conflito de hardware, está ligado ao acesso simultâneo de um ou mais  processadores à memória, devendo-se também usar métodos de sincronização para o controle de busca e envio de dados na memória pelos diferentes processadores.

Neste caso, este fator é solucionado por sistemas de controle eletrônicos à memória.

Desta forma, além de ser pouco escalável e de difícil manutenção, esse tipo de arquitetura conduz a situações em que um processador, ao acessar a memória comum, pode entrar em conflito com outros processadores.

A maior ou menor gravidade destes conflitos depende, no que diz respeito ao hardware, da sofisticação do dispositivo usado para interligar os processadores e as unidades de memória.

Também o uso de "caches" associados a cada processador permite diminuir o tráfego no barramento de memória.

Este esquema exige rotinas que assegurem as cópias de blocos de memória principal que estejam simultaneamente em mais de um "cache" em diferentes processadores.

É necessário também que o sistema operacional que esteja sendo usado suporte este tipo de arquitetura e implemente mecanismos mais sofisticados de escalonamento de processos entre os processadores.

Alternativamente, a memória compartilhada de forma lógica pode ser implementada por alguns sistemas, nos quais cada processador tem sua própria memória, através da conversão de cada referenciamento não local de memória em uma comunicação apropriada entre processadores.

Qualquer codificação de programa com a utilização de memória compartilhada é geralmente considerada mais fácil de se implementar do que o modelo de passagem de mensagem.

São máquinas onde os processadores se encontram separados em placas mãe distintas cada qual com sua própria memória local e a comunicação entre os processadores é feita pela troca de mensagens através dos dispositivos de entrada e saída (I/O).

Cada unidade de processamento como esta, é chamada de nó de processamento, e ao conjunto destes nós se dá o nome de multicomputador ou "cluster".

Neste caso não existe qualquer tipo de memória comum entre os nós.

A busca ou a mudança do valor de uma determinada variável é feita apenas pelo nó de processamento que a detém em qualquer momento, e esses valores alterados são comunicados aos outros processadores somente se for necessário.

Com os progressos obtidos nas formas de encaminhamento de dados entre nós, é possível construir "clusters" com milhares de unidades processadoras, eliminando assim qualquer desvantagem no quesito escalabilidade.

Contudo, com relação aos problemas encontrados neste tipo de sistema, pode-se dizer que existem dois principais, · a forma geral de se resolver um problema com este tipo de arquitetura é a  partição dos dados e instruções entre os diversos nós, e a atualização de  variáveis comuns entre eles, e isto é feito através da troca de mensagens.

Contudo, esta troca de mensagens acarreta uma grande perda de tempo no  processo.

Quanto maior for o número de variáveis comuns aos processadores, mais demorado é o processo de envio e recebimento de dados entre os nós de  processamento.

A programação é mais complicada e o paralelismo não é tão intuitivo.

Atualmente, existe pouca disponibilidade de compiladores autoparalelizantes, ou seja, compiladores que investiguem automaticamente na aplicação quais  os pontos que podem ser implicitamente paralelizados.

Esquema de máquina com memória distribuída.

A classe de arquitetura MIMD com memória compartilhada pode ser dividida ainda em duas categorias, Alta Disponibilidade (HA High Availability) e Alto Desempenho Computacional (HPC High Performance Computing).

Um cluster desta categoria tem como função primordial manter um determinado serviço ativo de forma segura durante o maior período de tempo e ao maior número de clientes possíveis.

Nestes clusters, os equipamentos são utilizados em conjunto para replicar os serviços de servidores, o que evita máquinas paradas, ou ociosas, esperando apenas o outro equipamento ou serviço paralisar.

Atualmente, a disponibilidade de um sistema é uma questão essencial para sobrevivência de várias empresas cujo produto é virtual ou é vendido virtualmente.

ALVES  cita como exemplo, uma loja de livros com um sistema de comércio eletrônico, se o sistema parar, a empresa também parará.

De maneira geral, um servidor de boa qualidade apresenta uma disponibilidade de 99,5%, enquanto que uma solução através de clusters de computadores apresenta uma disponibilidade de 99,99%.

O cluster de alto desempenho computacional é uma categoria designada a prover um grande poder de processamento, reduzindo-se assim significativamente a quantidade de tempo gasta em uma tarefa quando realizado em um computador simples.

Esta parte da ciência da computação tem como objetivo o desenvolvimento de supercomputadores, algoritmos de processamento paralelo e a construção de aplicações paralelas.

O cluster HPC é um tipo de sistema para processamento paralelo ou distribuído que consiste em uma coleção de computadores interconectados, trabalhando juntos como um recurso de computação simples e integrado.

Um nó de um cluster pode ser um simples sistema composto por processador, memória local, dispositivos de entrada e saída de dados e um sistema operacional, contudo, o conjunto destes pode fornecer as mesmas características e benefícios encontrados em sistemas com memória compartilhada, como os supercomputadores comerciais.

Um cluster de computadores pode ser visto como uma solução alternativa para universidades e empresas de pequeno a médio porte, para obterem processamento de alto desempenho na resolução de problemas através de aplicações paralelizáveis, a um custo baixo se comparado com os altos valores necessários para a aquisição e manutenção de um supercomputador proprietário com o mesmo poder de processamento.

A vantagem do custo é significativa, pois uma dúzia de estações de trabalho custa muito menos do que o mais barato dos supercomputadores encontrados no mercado.

Outra vantagem é a facilidade em se montar um cluster, tudo o que se precisa são duas ou mais estações de trabalho ou computadores pessoais conectados por uma rede padrão, como a Ethernet por exemplo, e todo o software necessário pode ser obtido em um domínio público através da Internet.

O aumento substancial no desempenho de computadores pessoais, PCs, nestes últimos anos pode ser considerado um dos mais notáveis avanços tecnológicos já presenciados.

A verdade é que o mercado de PCs é bem maior do que o mercado de workstations, permitindo que o preço do PC decresça, enquanto que o seu desempenho computacional aumente, e em muitos casos, ultrapasse o desempenho de estações de trabalho dedicadas.

O potencial de expandir o poder de processamento paralelo com o uso de PCs comuns foi identificado como uma alternativa atraente pela Agência Espacial Norte Americana (NASA), em uma de suas aplicações de missão crítica, por atender aos seus objetivos de forma rápida e barata.

Em 1994, surgia o primeiro cluster de PCs, batizado de Beowulf1.

Naquela época, este cluster veio substituir a compra de um supercomputador comercial que possuía uma velocidade de processamento equivalente, mas custava dez vezes mais caro do que o cluster de computadores pessoais.

No início, foram desenvolvidos dois sistemas Beowulf que, atualmente, são considerados como referências, são eles, 1 Este nome foi inspirado em um personagem de um épico anglo-saxônico escrito entre os séculos sete e dez.

Beowulf era um herói e rei de Geats, o que seria hoje a Suécia, e possuía a força de vinte homens em seu punho.

Beowulf Parallel Workstation, Protótipo Experimental.
Este sistema foi montado em 1994 no CESDIS (Center or Excelence in Space Data and Information) da NASA e era composto por 16 nós de processamento, cada um possuindo, uma placa mãe com processador Intel 80486DX4, barramento local VESA, 16 MB de memória RAM, 16 KB de memória cachê primária (interna ao 486), 256 KB de memória cachê secundária, um disco rígido IDE de 540 MB, duas interfaces de rede padrão Ethernet de 10 Mbps.

Beowulf Parallel Workstation, Sistema de Demonstração.
Este sistema foi montado em 1996 também na NASA e era também composto por 16 nós de processamento, cada um possuindo, uma placa mãe com processador Intel Pentium 100 MHz, barramento local PCI, 32 MB de memória RAM, um disco rígido IDE de 12 GB, duas interfaces de rede padrão Fast-Ethernet de 100 Mbps.

A diferença principal entre os dois modelos foi o emprego, no segundo, da tecnologia Fast-Ethernet, com largura de banda de 100 Mbps, dez vezes maior que a utilizada no primeiro.

Neste segundo modelo, pode se dizer que houve um maior equilíbrio entre a capacidade de processamento e a capacidade de vazão da rede.

Um cluster de computadores pessoais, para ser considerado um Beowulf, precisa atender às seguintes características, nenhum componente pode ser feito sob encomenda, independência de fornecedores de hardware e software, periféricos escaláveis, software livre e de código aberto, uso de ferramentas de computação paralela livremente disponíveis, retorno à comunidade do projeto e melhorias.
As principais vantagens desta classificação estão relacionadas aos aspectos de que nenhum fornecedor possui direitos sobre o produto.

Os sistemas podem ser construídos  utilizando  componentes de diversas origens, graças  à padronização de interfaces, tais como, IDE, PCI, SCSI, etc.

Rápida atualização do sistema devido às rápidas evoluções tecnológicas, a menores preços.

Os sistemas podem ser montados e modificados ao longo do tempo, de acordo com as necessidades e recursos do usuário, sem depender de configurações disponíveis de um vendedor.

Os Beowulfs utilizam sempre software livre, e tão sofisticado, robusto e eficiente quanto o comercial.

Conseqüentemente, uma característica importante de um cluster Beowulf é a utilização de sistemas operacionais que possuem código aberto, e da mesma forma todas as bibliotecas para troca de mensagens são de código aberto.

A partir destas características, foi possível fazer modificações nestes sistemas a fim de facilitar a implementação de aplicações paralelas.

Cluster de estações de trabalho (COW) Um cluster de estações de trabalho é constituído de estações de trabalho de alto desempenho, cada uma com seu monitor, teclado e mouse, ligadas por uma rede.

Todas as máquinas se comunicam entre si, ou seja, a partir de um nó, pode-se acessar outro nó, podendo assim executar tarefas remotamente.

Em um COW podemos ter acesso ao teclado em qualquer nó, o que não acontece em um Beowulf, que só se tem acesso ao teclado do computador principal, e a partir desse acessar os outros nós por acesso remoto.

Além disso, em um COW, quando o computador principal não está participando do processamento paralelo, todos os seus outros nós podem funcionar como postos de trabalho.

Um cluster é dito homogêneo quando todos os seus nós possuem as mesmas características e a mesma rede de comunicação interligando-os.

Por outro lado, um cluster é dito heterogêneo quando seus nós possuem diferentes características ou são interligados por diferentes tipos de conexões de rede.

A característica de um cluster ser, ou não, homogêneo tem implicações importantes no balanceamento de carga das aplicações.

O balanceamento de carga é a divisão imparcial da carga de trabalho entre os recursos computacionais disponíveis em uma rede de computadores.

De forma que, pode-se diminuir a carga de nós sobrecarregados e aumentar a carga de nós mais ociosos.

Geralmente, o desempenho de uma rede é medido em termos de latência e largura de banda.

A latência é uma medida do tempo gasto para se enviar um dado de um computador para outro, incluindo o tempo para o software construir a mensagem, transferir os bits e interpretar a mensagem.

A largura de banda, também chamada de "baudrate", é o número de bits por segundo que podem ser transmitidos de um nó a outro através das conexões de rede.

Como regra geral, se uma aplicação envia um grande número de pequenas mensagens, seu desempenho será afetado pela latência da rede, e se enviar grandes mensagens, seu desempenho será afetado pela largura de banda da rede.

Desta forma, o ideal para uma aplicação paralela desenvolvida para "clusters" é que ela utilize o mínimo possível da rede de comunicação.

Contudo, existem casos em que a comunicação entre nós é imprescindível, e o ideal para o bom desempenho de uma aplicação é ter uma rede com baixa latência e grande largura de banda.

Para que isso ocorra, são necessários protocolos de comunicação eficientes, que minimizem a sobrecarga do software de comunicação, e tecnologias de redes mais rápidas.

Como exemplos de protocolos mais utilizados, podem ser citados os UDP e TCP/IP, que são protocolos comuns para a Internet.

VMCC, U-net, BIP, Active e Fast Messages, que são protocolos de baixa latência.

VIA e InfiniBand, que são protocolos especiais para comunicação de clusters.

E, como exemplos de diferentes tecnologias de redes utilizadas nestes "clusters", enumeram-se, Ethernet, Fast-Ethernet e Gigabit-Ethernet.

Giganet (10 Gigabit Ethernliance).
Myrinet (Myricom).
QsNet (Quadrics Supercomputer World Inc).
ServerNet (Compaq Tandem Labs).
SCI Scalable Coherent Interface (Rutherford Appleton Laboratory).
ATM Asynchronous Transmission Mode (ATM Forum).
Fibre Channel (Fibre Channel Industry Association).
HIPPI High Performance Parallel Interface.
Reflective Memory (Universidade de Ohio).
ATOLL Atomic Low Latency Network (Universidade de Mannheim).

A necessidade de se programar em paralelo é uma conseqüência da inexistência de ferramentas de auxílio ao desenvolvimento de programas que, primeiramente, identifique automaticamente o paralelismo de aplicações genéricas, e em segundo lugar, gerem um código eficiente para estas aplicações.

Portanto, as tarefas dos programadores que se envolvem com este tipo de tecnologia são, encontrar o paralelismo na aplicação, implementar de forma eficiente o código para explorar este paralelismo.

A determinação do paralelismo de uma aplicação é parte mais complexa do trabalho e consiste em determinar o trecho mais demorado da aplicação, determinar ciclos onde iterações possam ser realizadas independentemente, determinar rotinas que possam ser executadas concorrentemente.

Uma das sugestões para se realizar esta operação, seria ter sempre em mente a pergunta, O que deve ser feito para se distribuir uma tarefa entre vários voluntários?

Também deve ser lembrado que a sutileza procurada em uma aplicação paralela é a razão pela qual o compilador não pode fazer a paralelização automaticamente.

A melhor maneira de se explorar o paralelismo é levar em conta a natureza da aplicação e da arquitetura do computador paralelo utilizado.

Antes de se discutir as alternativas de programação paralela, deve-se sempre estudar a arquitetura dos computadores envolvidos, para que se distribua de forma balanceada a carga computacional entre os diferentes processadores.

O problema da falta de compiladores que gerem a concorrência automática de instruções em um sistema de memória distribuída tem sido o alvo de muitas pesquisas no setor de computação de alto desempenho e acredita-se que num futuro próximo já será possível utilizar um desses compiladores.

Contudo, mesmo com a utilização de tais procedimentos implícitos é impossível que se atinja o melhor desempenho esperado para uma aplicação em particular, já que tais ferramentas apenas paralelizariam casos bem óbvios.

Assim, para um ganho superior de desempenho, cabe ao programador decidir qual trecho e como deve ser feita a paralelização.

O programador controla manualmente a comunicação entre os processadores baseados nas características intrínsecas de seu programa.

A este tipo de paralelização manual é dado o nome de paralelização explícita o de alto nível.

Um programa paralelo baseado em um sistema de memória distribuída segue basicamente os passos mostrados no fluxograma.

Primeiramente, ocorre a inicialização do sistema de maneira serial e logo depois é feita a divisão de tarefas para cada processador.

Após a finalização de cada tarefa por cada processador são colhidos os resultados através do envio de mensagens e o programa é finalizado.

Fluxograma básico de um programa paralelo.

O programador tem o controle explícito sobre todas os passos mencionados acima, particionando o problema em tarefas independentes através da decomposição de dados, de controle e mista.

A decomposição de dados é feita pela divisão do domínio do problema entre os diferentes processadores.

Cada um desses processadores executa praticamente o mesmo código, contudo, sobre dados diferentes, o que está totalmente de acordo com o paradigma SPMD, mostrado anteriormente.

Como ilustração a este tipo de abordagem podem ser vistos os esquemas de divisão do domínio de dois casos.

No primeiro caso, tem-se o processo de divisão do domínio computacional de um problema de distribuição de calor numa placa retangular discretizado pelo método das diferenças finitas.

Sabe-se que a parte final da resolução deste problema é a solução de um sistema de equações lineares onde os valores de fronteira deverão ser atualizados entre os diversos processadores.

O segundo exemplo trata do cálculo numérico de integrais onde a divisão é feita por subintervalos de integração que são passados para cada processador.

Os cálculos são realizados sem a necessidade de troca de mensagens nas fronteiras dos subintervalos, sendo necessária a comunicação entre processadores somente no final do processo, na fase de coleta de dados para a soma das subáreas.

Exemplos de problemas com decomposição de dados.

As vantagens deste tipo de decomposição podem ser enumeradas como a possibilidade de divisão do domínio de forma que todos os processadores  realizem a mesma quantidade de computação, ou seja, há um balanço de  carga equilibrado, pouca exigência de comunicação entre tarefas.
Geralmente isso se dá nas fronteiras dos subdomínios, redução do tempo total de processamento apenas pela divisão do domínio, adaptação simples dos problemas de engenharia e física a este método.

Decomposição de controle, nesta técnica, a divisão de tarefas se dá baseada nas funções a serem executadas, o que é útil quando não se conhece a priori o volume total de dados e computação necessários para a resolução de um problema.

Dependendo do problema é bem mais lógico dividi-lo em linhas funcionais.

Como exemplos dessa técnica, citam-se as estruturas mestre escravo e as do tipo pipeline ilustradas.

Na primeira, os escravos recebem as tarefas sob demanda dos usuários através de um mestre.

No segundo caso, cada processador cuida de uma única etapa do processo como se fosse uma linha de produção.

Exemplos de problemas com decomposição de controle.

Os problemas encontrados com a técnica de decomposição de controle são enumerados como não pode ser aplicada de forma tão direta quanto a decomposição de dados, é mais difícil de ser implementada e exige maior coordenação entre os processadores, a adição de mais nós de processamento não é simples.

Uma observação que deve ser feita diante da exposição das técnicas descritas anteriormente, é que a simples decomposição de dados pode não fornecer a distribuição mais equilibrada para um problema.

FORTUNA e TRINDADE JR  ilustram essa situação através do exemplo, suponha-se que é necessário paralelizar um programa de acesso a um dicionário da língua portuguesa dividindo-o em subconjuntos palavras por suas iniciais.

Cada inicial fica a cargo de somente um nó de processamento.

O problema gerado por essa divisão reside no fato de que existem mais palavras que começam pela A do que pela letra Z, e o resultado disso é que alguns processadores ficaram ociosos a maior parte do tempo.

Uma solução imediata para este problema seria a replicação do dicionário para cada nó de processamento de forma que todos os processadores utilizem os mesmos dados de forma local.

O problema desta solução está na grande quantidade de memória despendida no armazenamento dos dados replicados.

Uma boa solução para este problema seria a utilização de uma técnica de decomposição mista, ou seja, replicação de alguns dados e a distribuição de dados e controle (informação verbal).

Informação verbal fornecida pó Fortuna e Trindade durante o curso Programação Paralela no IBM SP2 em São Carlos, em 1997.

O paralelismo de uma aplicação pode se dar em termos de instruções, ciclos, subrotinas, subprogramas e programas.

Quanto menor o nível do paralelismo maior é a intervenção do programador, quanto maior o nível de paralelismo mais importante é o papel do compilador no processo de paralelização da aplicação.

Caminhando do nível de paralelismo mais alto para o mais baixo, temos que as instruções ficam a cargo do compilador, os ciclos são de responsabilidade do compilador e programador, as subrotinas e subprogramas são do programador e os programas fazem parte do trabalho do sistema operacional.

Além  dos  níveis de  paralelismo, existem  tambémos  níveisde particionamento de um programa paralelo que é representado pelo conceito de granulidade.

A granulidade é a quantidade de processamento, ou melhor, execução de instruções, entre as devidas sincronizações entre processos, e é dividida em três categorias, fina, média e grossa.

A execução de um programa paralelo envolve a combinação desses três níveis.

Níveis de paralelismo e particionamento de um sistema paralelo.

Para que em níveis superiores de paralelismo não haja pequenas intercorrências, é necessária a cooperação total entre processos de forma que a troca de dados deve ser realizada na ordem correta, ou seja, com total sincronismo.

O  sincronismo em multicomputadores é obtido pelo posicionamento de barreiras em certas partes do código.

As barreiras nada mais são do que rotinas que transmitem um sinal aos outros processadores indicando o término de uma determinada tarefa.

As barreiras são implementadas baseadas no princípio da troca de mensagens.

A transmissão de mensagem (Message Passing) é um modelo que visa à interação entre processadores de um sistema paralelo.

Em geral, uma mensagem é construída por um software em um processador e é enviada através de uma rede de conexões internas ou externas a outro processador, o qual então deve receber e agir sobre o conteúdo desta mensagem.

Embora o ônus temporal ao manipular cada mensagem (latência) possa ser alto, existem tipicamente poucas restrições a respeito da quantidade de informação que cada mensagem possa conter.

Assim a passagem de mensagem pode se utilizar, dependendo do caso, de altos valores de largura de banda de comunicação gerando uma maneira muito efetiva de se transmitir grandes blocos de dados de um processador a outro.

No entanto, para se minimizar a necessidade de operações de passagem de mensagens robustas, as estruturas de dados dentro de um programa paralelo devem ser espalhadas aos processadores de forma que a maioria dos dados referenciados por cada processador esteja em sua memória local.

A latência é muito importante na programação paralela, pois é ela quem determina a granulidade utilizável, ou seja, o mínimo tempo de execução para um segmento de código para se produzir aceleração através da execução paralela.

Basicamente, se um segmento de código é executado em um tempo menor do que o tempo que é levado para se transmitir seus resultados, logo, executar aquele segmento de código serialmente poderia ser mais rápido do que executá-lo paralelamente.

Uma das maneiras mais simples de se medir o ganho em desempenho de um sistema paralelo é adotar uma relação entre o tempo de execução de uma tarefa seqüencialmente, Ts, e o tempo gasto para realizá-la em paralelo, Tp.

Esta relação pode ser chamada de desempenho relativo, Dr.
Como exemplo de utilização desta medida de desempenho suponhamos que uma determinada tarefa, quando executada em um computador seqüencial, consome 10 minutos, e quando executada em uma máquina paralela com 10 processadores, consome 2 minutos.

Desta maneira, o desempenho deste sistema paralelo é cinco vezes mais rápido do que o seqüencial, ou seja, Dr = 5.

O ideal seria que o valor de Dr fosse sempre igual à quantidade de processadores utilizados.

Contudo, isso é algo quase impossível de se acontecer, pois por mais paralelizado que seja um sistema, sempre haverá frações do código de um programa que serão seqüenciais, e invariavelmente sempre serão necessárias sincronizações entre os processadores e conseqüentemente a latência gerada pela troca de mensagens.

Além desta relação, o conceito de desempenho em computação está intimamente ligado ao termo taxa de execução, ER, que representa o número de operações em ponto flutuante realizadas por segundo por um processador.

Este termo também é conhecido como flops (floating point operation per second) ou seus múltiplos, megaflops e gigaflops.

Esta taxa de execução depende basicamente de três parâmetros, como pode ser visto na expressão, o ciclo indica o período em que estas operações são realizadas pelo processador, e com desenvolvimento cada vez maior do setor de microeletrônicos este período tem diminuído notoriamente.

A multiplicidade se refere ao número de operações que se realiza em um ciclo.

Assim, o quociente entre a multiplicidade e o ciclo define a freqüência do processador e esta, por sua vez, determina a velocidade do processador para executar uma operação.

Finalmente, a concorrência indica o número de instruções que serão realizadas em um mesmo ciclo, ou seja, a quantidade de tarefas realizadas simultaneamente.

Pode-se diferenciar, de maneira simplificada, a multiplicidade da concorrência através do seguinte exemplo, suponha-se que a construção de um muro é a tarefa (instrução) de uma pessoa.

Para a execução deste muro, o operário realiza três operações, pegar o tijolo na pilha, passar massa na sua extremidade inferior e assentá-lo.

Treina-se esta pessoa para que ela realize cada uma destas operações mais rápido, isto é, aumentando-se sua freqüência (multiplicidade por ciclo) em cada operação, assim ela realizará a construção do muro em menos tempo.

Uma outra forma de se otimizar a construção do muro seria acrescentando mais operários, introduzindo assim o conceito de concorrência (paralelismo).

Deve-se lembrar que a rapidez de cada operário está limitada fisicamente, bem como a freqüência de cada processador é limitada pela velocidade da luz no vácuo 1.

No caso de sistemas concorrentes, ou seja, quando se desenvolve uma aplicação paralela, é útil sabermos o quanto seu desempenho se aproxima do ótimo.

Esse valor teórico é uma função da fração seqüencial do código, f, e do número de processadores solicitados, n, e é conhecido como speedup, S.

O speedup mede quantas vezes o código paralelo (com um determinado número de processadores utilizados) fica mais rápido do que a sua versão seqüencial.

A lei de Amdahl, representada pela expressão (43), indica a maneira como este valor ideal é determinado.

A diferença entre o valor ideal e valor obtido na prática aumenta com o aumento do número de processadores.

Isto se deve ao fato de que na lei de Amdahl não se levam em conta os ônus temporais causados pela comunicação entre processadores.

Para todo programa paralelo, há uma quantidade de processadores do qual não se compensa ultrapassar.

Informação verbal fornecida por Fortuna e Trindade durante o curso Programação Paralela no IBM SP2 em São Carlos, em 1997.

No mundo real, os ônus temporais causados pela comunicação entre os processadores (latência) chega até a reduzir o speedup quando se ultrapassa um determinado número de processadores e a obtenção de menos de quatro porcento de código seqüencial é uma tarefa muito difícil.

Outra maneira de se verificar a performance de um programa paralelo é a determinação do valor de desempenho, D, que mede a taxa de utilização dos processadores.

O valor de desempenho se relaciona com o speedup através da relação.
Desta forma, pode-se dizer que quanto maior o desempenho mais os processadores estão trabalhando na resolução do problema, ou seja, menor é a ociosidade do sistema paralelo e o desperdício de dinheiro.

Neste capítulo, são apresentadas as fases de desenvolvimento do protótipo de um sistema paralelo com memória distribuída.

Primeiramente, são mostrados os passos a se configurar o "hardware" do sistema, ou seja, como foram dispostos os componentes eletrônicos para que fosse obtido um "cluster" de computadores.

Na seqüência, são mostradas as etapas de configuração de software do sistema.

Nesta fase, explica-se desde como é feita inicialização de cada nó de processamento, até como os recursos de armazenamento são compartilhados para que no final se obtenha uma máquina virtual.

Entenda-se por máquina virtual, um conjunto de computadores coordenados em um único sistema.

Finalmente, como medida de performance do sistema paralelo, foi estudado o caso particular da resolução de sistemas de equações lineares com técnicas de programação paralelo.

Com todo o conjunto de informações colhidas durante a etapa de revisão bibliográfica, foi possível montar um protótipo de um computador paralelo da classe MIMD com memória distribuída, ou seja, um "cluster" de computadores pessoais.

Este protótipo foi construído através do acoplamento de quatro computadores pessoais que possuíam processadores obsoletos, e portanto, economicamente mais acessíveis, em uma rede exclusiva para esta finalidade.

Como pode ser visto no desenho esquemático, o computador paralelo é basicamente composto por cinco nós escravos, sendo apenas um nó portador de disco rígido, e um mestre para gerenciar as atividades de todos os nós sem disco rígido através de um "hub".

Esquema geral do protótipo de computador paralelo da classe MIMD com memória distribuída.

Cada nó de processamento sem disco deste "cluster" é composto por uma placa-mãe AT, um processador Pentium de 120 MHz, 4 bancos de memória de acesso randômico ("RAM") com 8 MB cada, uma interface de rede "Ethernet" de 10/100 megabites por segundo com um circuito integrado de memória EPROM, e uma fonte de energia de 200 W, economizando assim discos rígidos, placas de vídeo, teclados, "mouses", "drives" e monitores.

Cada um desses nós foi acondicionado em uma gaveta de um móvel de madeira com espaço para 4 gavetas, exclusivamente montada para esta finalidade.

Os detalhes de como estes componentes são dispostos nessas gavetas.

O mestre deste sistema paralelo é um computador da classe MIMD com memória compartilhada entre dois processadores Intel Pentium III de 500 MHz.

Além dos dois processadores, encontram-se instalados neste computador, um disco rígido IDE (responsável por armazenar o sistema do mestre), um disco SCSI (responsável por armazenar o sistema dos nós escravos sem disco), "drives" de CD e discos flexíveis de 3 ½ polegadas, uma placa de vídeo com aceleração 3 D, duas interfaces de rede de 10/100 megabites por segundo (sendo uma para a rede isolada e outra para acesso à Internet), monitor, mouse e teclado.

Com todos esses componentes, ele é o responsável pelas operações de entrada e saída de dados, pela divisão das tarefas, por todas as partições virtuais de disco rígido e pelos núcleos do sistema operacional (kernels) de cada nó sem disco, e pelo armazenamento dos resultados intermediários e finais dos processamentos numéricos.

Pode se observar a disposição geral do "cluster" de computadores.

Vista frontal e traseira da cômoda que acondiciona os 4 nós de  processamento sem disco rígido e do gabinete do nó com disco.

O computador mestre troca mensagens (envio e recebimento de dados e tarefas) com nós escravos através de um "hub" de oito portas, com taxa de transferência de 10/100 megabites por segundo, integralmente dedicado a este propósito, formando assim uma sub-rede isolada.

Pode ser vista uma fotografia deste pequeno "hub" responsável pelas conecções da sub-rede isolada do computador paralelo.

Além das operações citadas no parágrafo anterior, o mestre é o responsável por todas as atualizações, feitas através da Internet, no sistema operacional e nos aplicativos dele próprio e dos nós escravos.

Devido a essa necessidade de atualização, o mestre também é responsável por barrar a entrada e ataques de estranhos a esta rede isolada, realizando esta operação com o auxílio de um "firewall".

Detalhe mostrando a disposição, em uma das gavetas da cômoda, dos  componentes eletrônicos de cada nó de processamento.

Visão geral do "cluster" de computadores formado pelo mestre e os  cinco escravos.

São mostrados alguns detalhes do painel traseiro da cômoda de madeira.

Como pode ser observado, todas as conecções de rede, teclado e de monitoramento de vídeo, pontos de alimentação de energia se localizam neste painel.

É importante ressaltar que todas as conecções de vídeo e de teclado foram utilizadas somente em etapas de configuração do sistema.

A partir do momento que o sistema estiver configurado e permanecer estável, estes componentes podem ser retirados sem nenhuma restrição.

Detalhe mostrando o "hub" de 8 portas e o display de monitoramento.

Além disso, também vale a pena ressaltar que todos os componentes utilizados neste protótipo são componentes obsoletos e de segunda mão, ou adquiridos por preços baixos, ou doados, como foi o caso do nó com disco rígido.

Este nó com disco rígido é de grande importância nos testes de performance, pois serviu como base de comparação de rendimento dos nós sem disco, pois estes perdem desempenho, devido à latência do sistema de comunicação, ao acessar a rede para salvar informações que ultrapassam o seu limite de memória de cada nó.

Detalhes de conectores de rede e pontos de alimentação.

A configuração de uma máquina virtual nada mais é do que a instalação e a sintonização de um conjunto de software que um computador paralelo de memória distribuída necessita para poder trocar mensagens através de sua rede.

Para isso, em primeiro lugar, é necessário que se faça a escolha de um sistema operacional robusto para arcar com, todo o tráfego de informações na rede, o armazenamento dessas informações de forma segura e a execução de instruções dos programas de cálculo, sem riscos de panes no meio de um longo período de processamento.

Foram pesquisados vários sistemas operacionais, como, Windows NT, Slackware Linux, Debian GNU Linux e FreeBSD.

Os três últimos são sistemas gratuitos de código aberto, enquanto que o primeiro é de código proprietário e, portanto, fechado.

Para se realizar a configuração da máquina virtual, optou-se pelo sistema operacional FreeBSD, por se tratar de um sistema bastante estável e de fácil configuração.

Além disso, este pode ser considerado um dos sistemas mais robustos do mundo, responsável pelo serviço e tráfego de informações na rede de sites como o serviço de correio eletrônico da Yahoo, o servidor de rede da Sony Eletronics e da Siemens, e até o Hotmail, que é o serviço de correio eletrônico pertencente à Microsoft, já o utilizou como servidor.

As informações a respeito de quem utiliza e de quanto tempo o sistema se encontra no ar sem falhas podem ser verificadas na página.

As etapas para a configuração da máquina virtual composta por nós sem disco no FreeBSD, foram obtidas através da reunião das informações extraídas do trabalho de BOEGER e do livro FreeBSD Handbook.

Essas etapas são descritas em detalhes a partir do próximo item.

Um máquina FreeBSD pode carregar o sistema operacional através de uma rede e operar sem um disco local, usando um sistema de arquivos virtuais montados em um servidor NFS (Network File System).

Nenhuma modificação drástica no núcleo do sistema é necessária, a não ser algumas modificações em arquivos de configuração padrão.

Tal sistema é de fácil configuração pois todos os elementos necessários estão prontamente disponíveis e configuráveis, como por exemplo, · Existem pelo menos dois métodos possíveis para se carregar o sistema operacional através de conecções de rede, PXE "Intel's Preboot eXecution Environment system" é uma forma de "smart  boot ROM" integrados em algumas placas de rede.

O "etherboot" que produz um código legível para placas de rede que as fazem  procurar o sistema operacional em todos os computadores de uma rede.

O código  pode ser gravado em discos flexíveis de 3 ½ polegadas ou em um circuito  integrado de memória, chamado EPROM, que por sua vez pode ser acoplado a  uma placa de rede simples, ou carregado através de um "drive" local de discos  flexíveis, ou por executar esse código em um sistema MS-DOS.

A vantagem  desse método, com relação ao outro, é que já existe suporte para uma grande  quantidade de modelos de placas de rede.

Um script de exemplo que facilite a criação e a manutenção do sistema de  arquivos raiz do nó de processamento no disco rígido do servidor.

Existem arquivos de "startup" padrão no diretório /etc/ para que se possa detectar  e suportar uma inicialização de sistemas sem disco.

Partição de troca, se necessária, pode ser feita ou para um arquivo NFS ou para  um disco local.

Existem muitas maneiras de se configurar um nó de processamento sem disco, onde muitos elementos estão envolvidos, e a maioria deles pode ser customizada para se adequar às necessidades locais.

A seguir será descrita a configuração de um sistema completo, enfatizando simplicidade e compatibilidade com os scripts padrões de inicialização do FreeBSD.

O sistema a ser descrito tem as seguintes características, os nós de processamento utilizam um sistema de arquivos raiz, "/ ", para cada  nó, com permissão somente para a leitura, e um a partição "/usr", onde se  encontram todos os aplicativos, compartilhada entre todos, inclusive o mestre, com permissão para leitura e gravação.

O sistema operacional é carregado pelo método "etherboot", utilizando os programas residentes em memória ("deamons") "bootpd" e "tftpd".

Como já dito anteriormente, por precaução, por ser um sistema totalmente inseguro e aberto, este será isolado em uma sub-rede isolada pelo "hub" de 8 portas e protegida por "firewall".

Existem dois protocolos que são normalmente utilizados para inicializar uma estação de trabalho que busca suas configurações através da rede, DHCP e BOOTP.

Além disso, eles são utilizados em muitas fases do processo de carga do sistema operacional de cada estação de trabalho.

O PXE utiliza somente DHCP, mas o "etherboot", além de utilizar o DHCP originalmente, pode ser reconfigurado para utilizar o BOOTP, a fim de buscar o sistema no computador remoto.

Além disso, o sistema depois de ser carregado utiliza o BOOTP para ocalizar o seu sistema de arquivos virtual do tipo NFS no discol rígido do servidor.

É possível configurar um sistema para utilizar somente BOOTP já que é um programa incluído no núcleo do sistema operacional do FreeBSD.

Contudo, o DHCP tem algumas vantagens sobre o BOOTP, são elas, os arquivos de configuração são mais legíveis, existem possibilidades de utilização com PXE.

Neste caso foi utilizado o BOOTP pela facilidade de rastreamento de cada nó, por utilizar números IP fixos, quando em utilização e por já estar carregado por "default" no núcleo do sistema operacional.

Configuração utilizando BOOTP Segue-se abaixo o arquivo de configuração do programa BOOTP utilizado.

Este arquivo deve ser encontrado em "/etc/bootptab" do servidor de boot remoto, ou mestre.

É importante lembrar que, o "etherboot" precisa ser compilado com a opção NO_DHCP_SUPPORT de maneira a se utilizar somente o BOOTP.

A vantagem maior do "bootpd" é que ele faz parte da base do sistema, e possui um sistema de endereçamento fixo na sub-rede isolada, como mencionado anteriormente.

Este arquivo é composto por 5 partes, onde a primeira (default) descreve alguns parâmetros constantes a todas as outras 4 partes que representam os parâmetros de configuração dos quatro nós de processamento sem disco.

Informações sobre o tipo de boot remoto, o caminho para se encontrar o arquivo do sistema operacional para os nós de processamento e a raiz do sistema, o servidor de nomes, o "gateway" padrão, a máscara de sub-rede, etc, encontram-se nesta primeira parte do arquivo.

Nas demais, no1, no2, no3 e no4, se encontram as informações particulares de cada nó como, o endereço hexadecimal original de fábrica de cada placa de rede e o número identificação no protocolo de rede.

Primeiramente, é necessário compilar o programa "etherboot".

O código fonte deste programa  pode ser normalmente encontrado no diretório "/usr/ports/net/etherboot".

Com o código compilado e o arquivo executável em mãos, deve-se construir a imagem do programa de boot remoto, utilizando (perl e 'print "\xFF" x 16384', cat bin32/3 c509 lzrom) > 32 kbimage  Este comando gerará uma imagem de 16 Kbytes para que depois possa ser inserida em uma EPROM através de um gravador específico para esta finalidade.

É necessário que se habilite o programa de TFTP (tftpd) no servidor para que os nós encontrem a imagem do sistema operacional alojado neste, com o caminho já fornecido na etapa anterior.

Pode-se colocar o "tftpboot" em qualquer diretório do servidor, desde que seja indicado este local em ambos arquivos de configuração, "/etc/inetd conf" e "/etc/bootptab".

É necessário que se crie um sistema de arquivos raiz para os nós de processamento sem disco no local já especificado no arquivo "/etc/bootptab".

A maneira mais simples de se fazer isto, é utilizar o roteiro de comandos encontrado em "/usr/share/examples/diskless/clone_root".

Este roteiro necessita ser customizado, pelo menos no que diz respeito ao local onde a raiz do novo sistema de arquivos será criado.

Para o caso de um cluster de computadores com finalidade de processamento paralelo de modelos numéricos, a configuração de uma partição de troca (swap) no servidor não é algo interessante de se configurar.

A partição de troca funciona como uma memória virtual onde se guardam dados que excederam o limite da memória "RAM" convencional.

O problema disso no processamento numérico é que tenta-se evitar ao máximo a utilização da rede devido à perda de velocidade causado pela baixa largura de banda e alta latência do sistema de comunicação.

Contudo, neste caso específico, foi necessário criar uma partição de troca de 64 megabytes, pois cada nó de processamento possuía apenas 32 megabytes de memória "RAM", capacidade esta, insuficiente para a realização de algumas simulações numéricas.

Após todos os passos de instalação e configuração, os nós escravos sem disco e do nó com disco podem ser acessados através de um simples terminal "telnet", e qualquer aplicativo que se encontra "/usr" do mestre pode ser executado por estes.

Além da configuração básica do sistema, é imperativo instalar e configurar as bibliotecas de comunicação, PVM, "Parallel Virtual Machine", e MPI, "Message Passing Interface", e outras bibliotecas e aplicativos que tirem vantagem do paralelismo.

O sistema construído permanece bem estável, contudo a sua performance pode ser melhorada pela adição de nós de processamento com processadores mais rápidos, com uma quantidade de memória "RAM" maior, e através da utilização de uma rede mais rápida que a rede de 100 megabites por segundo, utilizada na montagem do computador paralelo.

Atualmente, existem no mercado "switches" e placas de rede com taxas acima de 1 gigabite por segundo por preços acessíveis.

Após as montagens de "hardware", e as instalações e configurações de "software", o sistema paralelo foi submetido a alguns testes simples de desempenho.

De forma geral, os testes de desempenho realizados consistem em comparações entre as medidas de tempo tomadas na execução de uma tarefa em um sistema seqüencial e as medidas em várias configurações paralelas.

Neste caso, a tarefa realizada pelo computador paralelo foi a resolução de um sistema linear, utilizando, para isto, uma biblioteca paralela para resolução de sistemas de equações lineares e não lineares, baseada nos protocolos de comunicação da MPI.

Esta biblioteca também tem o seu código aberto, e é chamada de PETSc, "Portable, Extensible Toolkit for Scientific computation".

Os sistemas resolvidos possuíam de 1000 a 20000 incógnitas.

Com a variação da quantidade de incógnitas de cada sistema, foi possível observar a influência da taxa de transferência e da latência, gerada pela rede de comunicação, na velocidade de processamento.

Pode ser observado um dos gráficos de desempenho do sistema paralelo.

Nas abscissas, é indicada a quantidade de incógnitas do sistema linear que foram determinadas e nas ordenadas é indicado o tempo para sua determinação, dado em segundos.

É importante ressaltar que, neste gráfico, o número máximo de incógnitas calculadas foi igual à máxima carga suportada por apenas um nó, que é oitenta mil.

Acima deste valor, não há mais qualquer espaço de memória, tanto do tipo RAM (memória local do nó), quanto SWAP (remota de troca), para armazenar os ponteiros criados pelo programa no tempo de execução.

Gráfico do tempo versus número de incógnitas calculadas.

Pode ser observado outro gráfico de desempenho do sistema, em que as abscissas, indicam a quantidade de incógnitas que foram determinadas e as ordenadas indicam o fator de desempenho relativo, ou "speed up", já descrito no capítulo anterior.

Este fator de rendimento é expresso pela razão entre as medidas de tempo tomadas na realização de uma tarefa em paralelo e as medidas tomadas na realização da mesma tarefa só que seqüencialmente.

A partir desse fator de rendimento, foi possível observar a influência da taxa de transferência da rede no desempenho do sistema.

Ao analisar os pontos do gráfico com número de incógnitas menor que cinco mil, pode se verificar que, a latência e a taxa de transferência do sistema de comunicação, além de confundirem a interpretação dos resultados de desempenho, impedem que se note alguma melhora na performance do sistema.

Este intervalo pode ser descartado das análises por não apresentar de forma pura a performance do sistema.

No intervalo compreendido pelos números de incógnitas iguais a cinco e dez mil, pode-se observar, tanto uma melhora no rendimento para as várias configurações, quanto uma tendência crescente de desempenho.

A partir do limite superior deste último intervalo, observa-se que o desempenho aumenta de forma significativa, findando a atingir um desempenho quase sete vezes maior que a configuração seqüencial.

Na verdade, este super desempenho reflete o tempo perdido no acesso através rede à partição de troca, SWAP, ao se realizar o processamento com apenas um nó com baixa quantidade de memória.

Neste mesmo intervalo de quantidade de incógnitas, este fato não ocorre ao se realizar o processamento com um número maior de processadores, pois a quantidade de memória RAM total é aumentada pela contribuição de cada nó com sua memória local.

Gráfico de desempenho relativo do protótipo de sistema paralelo.

Pelas razões descritas acima, podemos dizer que o intervalo mais confiável para se determinar o desempenho das quatro configurações paralelas se encontra entre cinco e dez mil incógnitas.

Neste intervalo, o desempenho relativo máximo do sistema foi de 25, obtido para um caso em que todos os quatro nós estavam trabalhando em paralelo.

A quantidade de operações com pontos flutuantes para este caso foi de 25 Mflops/s, o que é razoável ao se comparar com o primeiro Beowulf da NASA que atingiu a marca de 70 Mflops/s, utilizando 16 processadores de 100 MHz.

Contudo, como já foi dito no item anterior, esta performance pode ser melhorada pelo aumento da taxa de transferência das interfaces de rede e pelo aumento da capacidade de memória local de cada nó envolvido no processamento.

Neste capítulo, primeiramente, é brevemente descrita como foi feita a implementação de uma interface paralela para um programa de elementos finitos já existente, quais foram as bibliotecas utilizadas e suas principais características.

Em seguida são feitas algumas comparações entre várias soluções analíticas e os resultados obtidos pelo programa.

Depois de verificada a qualidade dos resultados, foram realizados alguns testes de performance do programa paralelo.

Contudo, desta vez, o programa foi executado em um computador de grande porte paralelo com trinta e dois processadores, disponibilizado pelo INSA-Lyon, França.

Nesta etapa, os esforços foram voltados para a implementação de um programa de elementos finitos que atendesse aos requisitos descritos no item 52, acerca da quantidade de tempo e das dificuldades na simulação de seqüências de escavação e suporte de túneis com revestimento de concreto projetado.

Por essa causa, partiu-se para a elaboração de um programa que fosse, além de rápido, portável, expansível e confiável.

Foram pesquisados vários códigos de programas de elementos finitos, entre eles destacam-se, CONSAX, SAP IV e nonSAP da UC Berkeley (EUA), CALSEF Universitat Politècnica de Catalunya (Espanha), FreeFEM e FreeFEM++ do INRIA (França), VELVET do MIT (EUA) e o TOCHNOG de RODDEMAN.

Além dos programas, foram pesquisadas algumas bibliotecas de classes para a solução de equações diferenciais parciais que são disponibilizadas gratuitamente na rede, entre elas se destacam, a NAO (Numerical Analyses Objects) da IBM e a PETSc (Portable, Extensible Toolkit for Scientific computation) do Argonne National Laboratory.

A fim de se suprirem as necessidades de rapidez e expansibilidade, o programa foi elaborado com base no programa TOCHNOG.

Este programa apresenta o seu código escrito em linguagem C++, padrão ANSI, o que facilitou as modificações e expansões no seu código.

Além disso, C e C++ são as linguagens nativas de sistemas UNIX, como o FreeBSD, o que aumenta a rapidez de compilação e execução do seu código nestes sistemas.

Além das modificações realizadas, foram adicionadas algumas classes da biblioteca PETSc, principalmente as classes relativas à resolução em paralelo de sistemas lineares e não lineares.

Da mesma forma que o TOCHNOG, esta biblioteca é também baseada em conceitos de programação orientada a objetos, mas implementada em linguagem C, padrão ANSI, o que vem suprir as necessidades de portabilidade do sistema.

Assim é possível a sua instalação em qualquer sistema que possua um compilador ANSI C e C++.

A PETSc consiste, na verdade, em um grande conjunto de bibliotecas, onde cada uma é responsável por manipular uma família particular de objetos (como exemplos, vetores e matrizes) e de métodos, ou operações, que são aplicados a estes objetos.

Alguns dos módulos da PETSc lidam com os seguintes tipos de objetos e métodos, vetores, matrizes (geralmente esparsas), indexações, permutações e renumeração de vetores e matrizes, listas distribuídas (úteis para paralelizar modelos), métodos dos sub-espaços de Krylov, pré-condicionadores, "timesteppers" para a resolução de EDPs não-lineares.

Cada um destes módulos consiste em uma interface abstrata (ativada simplesmente por uma seqüência de chamadas), e implementações utilizando uma estrutura de dados particular.

Desta forma, o PETSc fornece um código limpo e eficaz para as várias fases de resolução de uma equação diferencial parcial.

A PETSc utiliza o MPI (Message Passing Interface) como biblioteca base para a comunicação entre processadores.

A MPI é uma biblioteca de passagem de mensagens desenvolvida para ser o padrão de comunicação em ambientes de memória distribuída.

A MPI é formada por um conjunto de rotinas que realiza, além da troca de dados, a sincronização entre os processos ativos na memória do computador.

Ela é portável para qualquer arquitetura, e é composta por aproximadamente 125 funções e ferramentas para análise de performance.

Muitas implementações do padrão MPI têm sido desenvolvidas, sendo que algumas são proprietárias e outras possuem código aberto.

No caso do protótipo descrito no capítulo 5, foi utilizada uma implementação de código livre chamado MPICH, ou MPICHamaleon, do Argonne National Laboratory.

Já no caso computador paralelo do INSA, foi utilizada uma versão comercial da biblioteca.

O Tochnog é um programa de elementos finitos para análises estáticas, quasi-estáticas e dinâmicas.

A entrada de dados é feita de uma maneira simples e desformatada, onde as condições de contorno são aplicadas tanto às entidades físicas (nós e elementos), quanto às entidades geométricas (pontos, linhas, superfícies e volumes).

A saída de dados é feita em variados formatos e para os mais variados programas e bibliotecas de pós-processamento existentes, GiD, Gnuplot, OpenDX, GMV, Matlab, Tecplot e VTK.

São suportados elementos finitos isoparamétricos 1 D, 2 D e 3 D, além da família de elementos lineares simples (barras de 2 nós, triângulos de 3 nós e tetraedros de quatro nós).

O programa dispõe de uma família completa de primeira a quarta ordem de elementos barra, quadriláteros e hexaedros, molas e vigas bidimensionais.

Possui gerador de malhas, onde regiões de diversos formatos são automaticamente discretizadas em elementos finitos.

Além de gerar, pode-se refinar global ou localmente malhas já existentes, resultando em malhas totalmente novas, onde os campos de antigas posições de nós são mapeados e transportados para os novos.

Em adição a estas características, foram introduzidas algumas novas rotinas internas desenvolvidas em linguagem C++ e outras periféricas desenvolvidas em Python, que tiveram por objetivo facilitar as operações de alimentação de dados e de filtragem de resultados finais e intermediários.

É importante salientar que nesta fase, foram modificadas e corrigidas algumas rotinas já existentes no código original, o que gerou ganhos substanciais em performance e na qualidade dos resultados.

A seguir, afim de se suprir a necessidade de confiabilidade, os resultados de soluções analíticas foram comparados com os resultados de simulações realizadas pelo programa de elementos finitos, Tochnog.

A solução clássica de Kirsch para os deslocamentos radiais e o estado de tensões resultantes da retirada de material, na forma de uma circunferência de raio a, de um meio elástico infinito regido por um estado de deformações planas e submetido a um estado de tensões principais iniciais p1 e p2, pode ser representada pelas seguintes equações, Representação gráfica da malha de elementos finitos 2 D utilizada.

Podem ser vistas comparações entre os resultados da solução clássica de Kirsch e os obtidos no processamento de um modelo similar discretizado pelo método dos elementos finitos no programa Tochnog, considerando os seguintes valores, p1 = 10 kPa, a = 5 m, n = 0,3 e E = 10000 kPa.

Os resultados numéricos, tanto de deslocamentos, quanto de tensões, se encontram bem próximos dos resultados obtidos pela solução analítica.

Gráfico comparativo dos deslocamentos obtidos pela solução de Kirsch e pela simulação numérica considerando as tensões iniciais, p1 = p2.

Gráfico comparativo das tensões obtidas pela solução de Kirsch e pela  simulação numérica considerando as tensões iniciais, p1 = p2.

Gráfico comparativo das tensões obtidas pela solução de Kirsch e pela simulação numérica considerando as tensões iniciais, 2 p1 = p2, e q = 0 O.

Gráfico comparativo das tensões obtidas pela solução de Kirsch e pela simulação numérica considerando as tensões iniciais, 2 p1 = p2, e q = 90 O.

Os resultados pós-processados, são os contornos do campo de deslocamentos obtidos na simulação numérica.

O erro cometido no cálculo dos deslocamentos para os pontos da fronteira escavada é bem pequeno, quando comparado com a solução fechada, cerca de 0,3%.

No entanto, quanto mais se distancia da fronteira escavada e se aproxima das fronteiras onde são aplicadas as cargas, esse erro aumenta devido ao fato de que seriam necessários elementos infinitos para simular com fidelidade a continuidade do maciço em todas as direções.

Distribuição de deslocamentos para modelo 2 D com condições similares ao problema solucionado por Kirsch, considerando as tensões iniciais, p1 = p2.

Tanto a tarefa de geração da malha de elementos finitos utilizada nas simulações, quanto a de pós-processamento do campo de deslocamentos, foram realizadas com a ajuda do programa de pré e pós-processamento GiD, da Universitat de Cataluñya, Espanha.

Este programa tem como vantagem a sua flexibilidade de formatação costumizada dos dados de pré-processamento em arquivos ASCII.

Além dos contornos do campo de deslocamentos, neste programa, podem ser visualizados campos de tensões, deformações, valores máximos e mínimos encontrados em um determinado campo, campos vetoriais, geração de gráficos a partir de pontos do modelo, etc.

Para este caso foram repetidos os mesmos passos do caso anterior, com a diferença de que o modelo numérico agora em questão é tridimensional, onde os nós contidos nos planos de fronteira perpendiculares ao eixo z foram impedidos de se deslocarem nesta direção, simulando um estado de deformações planas.

A comparação entre os valores de deslocamento radial nas paredes da escavação obtidos por Kirsch e pelo programa foi feita, e a diferença entre estes valores não ultrapassa 0,5%.

Pode ser observado o campo de deslocamentos obtidos pela simulação tridimensional após ser pós-processada pelo GiD.

Representação gráfica da malha de elementos finitos 3 D utilizada nas  simulações, após a retirada de material.

Distribuição de deslocamentos para modelo 3 D com condições similares à ao problema solucionado Kirsch.

Neste caso, os resultados obtidos pelo Tochnog são comparados com a solução fechada proposta por PANET, que determina os deslocamentos radiais das paredes de túneis circulares ao longo de seu eixo.

Esta solução leva em conta, a presença da frente de escavação, o maciço é considerado elástico e está submetido a um carregamento axissimétrico.

Os deslocamentos radiais obtidos pela simulação numérica de um modelo próximo ao descrito no último parágrafo, considerando neste caso,R = 5 m, 0 = 100 kPa, n = 0,3 e E = 10000 kPa, se ajusta bem aos valores obtidos pela solução de PANET.

As pequenas diferenças se devem ao pouco refinamento dado à malha de elementos finitos na direção longitudinal, cada elemento nesta direção possui 5 metros.

Podem ser vistos com mais detalhes os contornos do campo de deslocamentos próximo à frente de escavação.

Gráfico comparativo dos deslocamentos radias obtidos pela solução  analítica e pelo programa de elementos finitos.

Distribuição de deslocamentos para modelo 3 D com condições  similares ao problema solucionado por PANET.

A solução analítica proposta por SALENÇON para os deslocamentos e as tensões ocorridos em um meio infinito elasto plástico regido pelo critério de Mohr-Coulomb, com um estado de tensões dados por P1 = P2 = P0, ou seja, axissimétrico, e estado de deformações planas, de onde se faz a retirada de material com a forma de um círculo de raio a.
Neste caso, considerando, P0 = 250 kPa, Pa = 0, a = 5 m, n = 0,3, E = 10000 kPa, c = 100 kPa, f = 30º e y = 0 o (sem dilatância) ou y = 30º (com dilatância), foram comparados os deslocamentos radiais e a diferença entre a solução analítica e a numérica não ultrapassou 11%.

Além disso, pode-se verificar a magnitude e a distribuição destes deslocamentos.

Gráfico comparativo dos deslocamentos obtidos pela solução de  SALENÇON e pela simulação numérica considerando nula a dilatância.

Gráfico comparativo das tensões obtidas pela solução de  SALENÇON e pela simulação numérica considerando nula a dilatância.

Gráfico comparativo dos deslocamentos obtidos pela solução de SALENÇON e pela simulação numérica considerando a dilatância igual a 30.

Gráfico comparativo das tensões obtidas pela solução de SALENÇON e pela simulação numérica considerando a dilatância igual a 30.

Distribuição de deslocamentos para modelo 2 D com condições  similares às de SALENÇON.

Para este caso foram repetidos os mesmos passos do caso anterior, com a diferença de que o modelo numérico agora em questão é tridimensional.

A comparação entre os valores de deslocamento radial das paredes da escavação obtidos por SALENÇON e pelo programa de elementos finitos foi feita e a discrepância entre estes valores não ultrapassa 1,5%.

Podem ser observados os contornos do campo de deslocamentos de um dado plano obtidos pela simulação numérica tridimensional de um caso similar ao proposto por SALENÇON.

Apesar de o programa GiD ter custo acessível, é muito mais confortável depender de um programa de código aberto que é mantido por várias pessoas capacitadas ao redor do mundo, como é o caso dos programas livres.

Além das ferramentas de pós-processamento oferecidas pelo GiD, foram pesquisadas novas alternativas de pós-processamento.

Foi encontrado um programa gratuito e de código aberto da companhia IBM capaz de, até o momento, pós-processar os resultados do programa de cálculo.

Este programa é conhecido como OpenDX (Open Data Explorer).

Como exemplo das capacidades de pós-processamento deste programa, pode ser visto, o campo de deslocamentos encontrados em um determinado plano definido pelo usuário.

Além disso, pode-se observar a presença de uma superfície, lugar geométrico dos pontos que possuem o mesmo valor de deslocamento.

A representação destas iso-superfícies pode ser implementada no OpenDX com relativa facilidade.

Detalhe de visualização do campo de deslocamentos de modelo 3 D, com condições similares às de SALENÇON, realizado pelo programa  OpenDX.

A solução de NEWMARK para o acréscimo de tensão vertical causado por uma carga uniformemente distribuída (atuante em uma superfície retangular horizontal de um espaço semi-infinito, elástico linear), aos pontos contidos na reta vertical que passa por um dos vértices do retângulo.

Gráfico comparativo das tensões verticais obtidas pela solução de  Newmark e pela simulação numérica realizada no Tochnog.

Pode ser vista uma comparação entre os acréscimos de tensões verticais obtidos pela solução de NEWMARK e os resultados obtidos pela simulação numérica de condições similares no Tochnog, considerando os seguintes valores, a = 2 m, b = 2 m e 0= 100 kPa.

Nesta figura, pode se observar que exite alguma divergência entre a curva de NEWMARK e os pontos do Tochnoga partir da profundidade de 7 m, isso se explica pela proximidade cada vez maior desses pontos analisados aos contornos do modelo 3 D analisado.

Podem ser observados os limites do domínio estudado, assim como sua discretização.

Ainda nesta figura, observa-se a distribuição de tensões verticais, ou melhor, direção Z, e pode-se notar claramente os bulbos de tensão causados pelo carregamento distribuídos.

Distribuição de tensões verticais para modelo 3 D com condições  similares ao problema solucionado por NEWMARK.

Pode ser vista a mesma distribuição de tensões pós-processada no software comercial GiD, no entanto, agora, pós-processada com a ajuda da biblioteca gráfica VTK (Visualization Tool Kit).

Além desse tipo de visualização, podem ser utilizados outros recursos como aqueles utilizados no programa, também aberto, IBM OpenDX.

A causa principal da diferença entre as distribuições é a quantidade de iso-contornos, o que na última é menor.

Detalhe de visualização do campo de tensões verticais de um modelo 3 D, com condições similares às de NEWMARK, com a biblioteca VTK.

A solução fechada de SCHWARTZ e EINSTEIN para os esforços normais e fletores, que solicitam o arco circular de suporte de uma abertura em um meio infinito, sujeito a um estado de tensões iniciais dado por P e KP, tensões verticais e horizontais, respectivamente.

Neste caso, foram adotados os seguintes valores para as variáveis, P = 80 kPa, R = 5 m, t = 03 m, n = 03, E = 10000 kPa, ns = 03, Es = 100000 kPa.

Aproveitando-se das condições de simetria do problema, a simulação foi realizada em um quadrante do domínio original, assim como em KIRSCH.

Os esforços foram calculados a partir da obtenção dos tensores de tensão (segundo os eixos originais x, y e z) localizados nas fibras internas, médias e externas do suporte, em varias posições angulares.

Em posse destes tensores, foram feitas rotações dos eixos originais, resultando em um sistema coordenado x', y' e z', onde z e z' são coincidentes e o eixo x' tem a mesma direção da espessura do suporte.

Gráfico comparativo dos esforços obtidos a partir de SCHWARTZ  e EINSTEIN  e pela simulação numérica realizada no Tochnog, com K = 1.

Distribuição de tensões principais para modelo 3 D com condições  similares ao problema solucionado SCHWARTZ e EINSTEIN, com K = 1.

Gráfico comparativo dos esforços normais obtidos a partir de SCHWARTZ e EINSTEIN  e pela simulação numérica, com K = 05.

Gráfico comparativo dos esforços fletores obtidos a partir de SCHWARTZ e EINSTEIN  e pela simulação numérica, com K = 05.

Os esforços fletores e normais calculados se mostram bem próximos dos teóricos, com uma diferença de no máximo 4% para os esforços normais, no caso em que K = 05.

Pode-se observar o campo de tensões principais maiores (neste caso equivalente às tensões tangenciais) em que o gradiente de tensões aumenta muito à medida que se aproxima da região onde foi instalado o suporte, como era de se esperar.

Neste caso, foram comparados os resultados de um modelo tridimensional do Tochnog com a solução teórica para momentos fletores de um arco com 38 cm de espessura, 50 cm de largura e 98 m de raio médio (representado por um quarto de uma casca cilíndrica) engastado na base e com um carga na direção y, aplicada na outra extremidade do arco.

Os momentos fletores foram obtidos seguindo os mesmos passos do exemplo anterior e foram plotados no gráfico.

O erro máximo obtido neste caso foi de 45%.

Gráfico comparativo dos momentos obtidos de forma teórica e pela  simulação numérica realizada no Tochnog.

Pode ser observado o campo de tensões na direção y, onde se nota que no engaste estas tensões são mais pronunciadas, e ainda estas tensões variam de valores negativos nas fibras internas a valores positivos nas fibras externas, como normalmente ocorre.

Distribuição de tensões na direção y para modelo 3 D com condições similares ao problema de estrutura em arco engastada.

Neste caso, foram comparados os resultados de um modelo tridimensional do Tochnog com a solução teórica para esforços solicitantes de uma viga engastada com uma carga concentrada na direção y, aplicada em uma de suas extremidades.

Os esforços fletores, normais e cortantes foram obtidos através das equações abaixo e foram plotados no gráfico.

Gráfico comparativo dos esforços solicitantes de uma viga engastada obtidos de forma teórica e pela simulação numérica realizada no Tochnog.

Distribuição de tensões para modelo 3 D com condições similares ao problema de viga engastada (1 elemento na altura da viga).

Distribuição de tensões para modelo 3 D com condições similares ao  problema de viga engastada (5 elementos na altura da viga). Pode-se notar a sensibilidade do modelo ao se variar o número de elementos na altura da seção transversal da viga em questão.

Praticamente, os resultados são os mesmos ao se considerar apenas um ou cinco elementos quadráticos na altura da viga.

Podem ser observadas as malhas utilizadas nas simulações com um e 5 elementos, respectivamente.

Neste caso, não há como comparar exatamente os resultados do Tochnog com alguma solução fechada, pois não existe uma solução analítica com condições similares a esse processo que é evolutivo.

O maciço e o revestimento foram considerados elásticos e isotrópicos, e por se tratar de um túnel profundo, reduziu-se o domínio a apenas um quadrante do domínio original, da mesma forma que foi feito na verificação de PANET.

Representação gráfica do domínio analisado após a última rodada de  escavação e suporte do maciço.

A simulação foi levada a cabo em 24 passos, sendo que, primeiramente, foram instaladas as tensões no maciço, no segundo passo, foi realizada a escavação do primeiro lance com um comprimento de atraso da frente de escavação à borda do segmento de suporte de 1 m.

Deste ponto em diante, foram realizadas sucessivas operações de escavação e suporte do maciço, com comprimentos iguais a 1 m.

O raio da escavação é igual a 3 m e a espessura do suporte é igual a 03 m.

Na região compreendida entre a frente de escavação e o último lance de suporte, pode-se notar que a malha do maciço intacto não possui uma divisão de elementos compatível com a dos elementos utilizados no suporte.

Ou seja, em qualquer modelo, não há a necessidade da malha inicial retratar previamente todas as fases de construção.

Isso se deve ao fato de que, no Tochnog, existem mecanismos para a geração automática de novas malhas em qualquer região do domínio, e o acoplamento dos nós de fronteira destas novas malhas aos nós de fronteira de malhas já existentes.

Além disso, condições de contorno e propriedades dos materiais podem ser mudadas, e tudo isso pode ser realizado à medida que se desenvolvem as fases do processo construtivo na simulação numérica.

Como alternativa de se verificar a qualidade dos resultados deste tipo de análise, optou-se por comparar os valores de tensão normal no suporte com os valores obtidos com a solução analítica proposta por SCHWARTZ e EINSTEIN.

Deve-se ressaltar que, naquela solução o processo construtivo se dá em 2 fases.

Primeiramente, é feita a instalação das tensões iniciais e, em segundo lugar, é feita a remoção do material e instalação do suporte simultaneamente, o que não permite qualquer alívio de tensões do maciço entre as fases de escavação e suporte.

Já na simulação tridimensional, o que ocorre é o seguinte, devido ao alívio de tensões do maciço, estas tensões normais do suporte são sempre menores que as encontradas naquela solução analítica.

Este alívio é basicamente ocasionado pelos deslocamentos ocorridos à frente da face do túnel e na região do vão não suportado, localizado entre a face e o último segmento de suporte instalado.

Pode ser visto um gráfico comparativo dos esforços normais do suporte adimensionalizados pelo esforço normal obtido pela equação de SCHWARTZ e EINSTEIN.

Neste caso, o esforço adimensionalizado, N*, é cerca de 45% do valor do esforço dado pela equação analítica, devido às diferenças de condições do modelo numérico para as condições levadas em conta na dedução da solução fechada, já citadas no parágrafo anterior.

Gráfico comparativo dos esforços normais adimensionalizados.

No Tochnog, a viscoelasticidade é modelada através da associação em paralelo de um certo número modelos viscoelásticos de Maxwell.

Um modelo de Maxwell genérico, i, é composto pela associação em série de uma mola com Módulo de Young igual a Ei e um amortecedor com tempo de relaxação igual a ti.

Ressalta-se que o tempo de relaxação é igual à razão entre a viscosidade e o módulo de elasticidade do modelo.

Desta maneira, ao se montar uma cadeia paralela composta por dois modelos de Maxwell, que têm como parâmetros elásticos, E1 e E2, e viscosos, m1 e m2, e, além disso, admitindo-se que o parâmetro elástico de um dos modelos e o parâmetro viscoso do outro modelo são extremamente altos, recai-se num modelo viscoelástico clássico de Kelvin.

A consideração de valores extremamente altos para esses dois parâmetros torna suas contribuições para a deformação total insignificantes.

Como apresentado em ANEXO, a variação das deformações com o tempo para uma dada tensão constante num modelo de Kelvin.

Para verificar a eficácia do Tochnog, na resolução deste tipo de problema, foi simulado a tração axial de uma barra circular de diâmetro igual a 1 cm e comprimento igual a 10 cm.

O valor da tensão axial aplicada nas extremidades da barra é igual a 1000 kN/m2, o módulo de elasticidade, E2, é igual a 1 GPa, e a viscosidade, m2, é igual a 027 GPa h.

Foram necessários 1440 elementos hexaédricos e 1767 nós para a confecção da malha de elementos finitos utilizada nas simulações que pode ser observada.

Representação gráfica da malha de elementos finitos 3 D utilizada.

Pode ser observada a proximidade entre os resultados da simulação numérica e a solução analítica.

Neste caso, a maior discrepância encontrada é igual a 3,5%, que pode ter sido ocasionada pela impossibilidade de se atribuir valores suficientemente alto aos parâmetros E1 e m2.

Gráfico comparativo entre solução analítica e simulação numérica  da variação de deformação axial com o tempo.

O programa TOCHNOG e a biblioteca PETSc, ambos de código aberto, foram instalado em um grande computador paralelo, mais especificamente em um Alpha Server Sierra da empresa COMPAQ.

Este computador se encontra no CDCSP (Centre pour le Developpement du Calcul Scientifique Parallele) da Université Claude Bernard Lyon1 à disposição de toda a comunidade científica da região.

Do início até o final de 2002, o acesso foi feito por meio de um terminal OpenSSH (Open Secure SHell) num computador pessoal do departamento de Geotecnia do INSA, sob o comando do sistema operacional FreeBSD.

Detalhe frontal de quatro dos 8 nós de processamento e do sistema  de comunicação e armazenamento.

Em 8 nós ES40, cada um com 4 processadores Alpha EV 67/667 MHz, 8 Megabytes de memória de acesso rápido (cache) por processador, 16 Gigabytes de memória RAM, 2 Gigabytes por nó, conecções de rede feitas através de um switch Quadrix com tempo de  latência de 35 nanosegundos, rede de discos SCSI de 10000 rpm conectados por fibra óptica  perfazendo um espaço de memória total de 250 Gigabytes.

O sistema operacional utilizado pelo computador paralelo é o OSF1 versão 50, uma das variantes do sistema Unix desenvolvido pela COMPAQ.

Este sistema operacional estava configurado para controlar o conjunto de hardware de maneira que 4 nós são utilizados para gerenciar o lançamento das tarefas e os outros 28 são responsáveis pelo processamento numérico dessas.

O computador dispunha de bibliotecas de comunicação MPI (Message Passing Interface) e de bibliotecas de álgebra linear CXML, uma versão da biblioteca LAPACK (Linear Algebra Package) desenvolvida pela COMPAQ especialmente para este tipo de arquitetura.

Além dessas bibliotecas, estavam à disposição no sistema, os compiladores Fortran 77/90 e C/C++, o debugger para programas paralelos Total View, os utilitários de análise de códigos paralelos Vampir e VampirTrace e o gerenciador de execução de tarefas LSF.

Para se instalar o programa de código aberto TOCHNOG e configurá-lo para realizar suas tarefas em paralelo, foi necessário primeiramente instalar e configurar a biblioteca de código aberto PETSc (Portable, Extensible Toolkit for Scientific Computation) responsável pela resolução dos sistemas de equações lineares.

Esta biblioteca por sua vez é dependente das bibliotecas MPI e LAPACK.

Por se tratar de um computador desenvolvido e comercializado pela COMPAQ, tanto o sistema operacional quanto as bibliotecas utilizadas são totalmente otimizadas e direcionadas à sua arquitetura de hardware.

No entanto, este tipo de direcionamento e otimização conduz a um certo distanciamento dos padrões normalmente utilizados por parte de alguns programas de código aberto.

Devido a essas diferenças, durante a compilação da biblioteca PETSc, alguns problemas foram encontrados principalmente na utilização das bibliotecas MPI e CXML.

A fim de se contornar estes problemas, tentou-se instalar as versões de código aberto destas bibliotecas, como MPICH e LAPACK usadas anteriormente, mas existiram algumas advertências por parte do administrador do sistema que impossibilitaram levar a finalização dessa operação.

Contudo, através de algumas diretivas de compilação indicadas pelo mesmo administrador do sistema, foi possível finalmente compilar com sucesso a biblioteca PETSc e em seguida o programa de elementos finitos, TOCHNOG.

O programa de elementos finitos foi compilado e instalado em três versões, versão seqüencial, versão paralela utilizando MPI e paralela utilizando SMP (Symmetric Multi-Processing).

A versão seqüencial foi utilizada como ponto de referência nos testes de desempenho do sistema paralelo.

A versão paralela compilada com a biblioteca MPI e a compilada com "Multi-Threads" serviram para comparar o desempenho do sistema utilizando diferentes quantidades de processadores e também comparar o desempenho entre a comunicação via rede e a via barramento interno de cada nó.

Primeiramente, foram realizados os testes de desempenho do computador paralelo levando-se em conta alguns parâmetros como, o número de processadores envolvidos nas tarefas, o número de graus de liberdade do modelo, o número de passos de escavação e suporte, e o número de passos envolvidos na solução dos sistemas lineares.

O desempenho das várias configurações foi medido através de uma razão entre o tempo gasto por um único processador na realização das tarefas e o tempo gasto por uma dada configuração de processadores.

Esta razão exprime número de vezes que uma dada configuração de processadores é mais rápida que a configuração com um processador.

Todas as medidas de tempo foram realizadas pelo menos 3 vezes para uma dada configuração de processadores.

Essa atitude foi necessária pois, dependendo do número de usuários do sistema e do número tarefas agendadas por estes, o desempenho do computador para uma mesma tarefa era significativamente afetado.

Como exemplo, foi presenciado muitas vezes, quando o sistema estava sendo muito solicitado, uma dada tarefa era realizada em até o duas vezes o tempo normal.

Outro problema encontrado, foi o grande período de espera das tarefas que utilizavam mais de 4 processadores em paralelo.

Como exemplo, pode-se citar o caso em que uma tarefa foi submetida a seis processadores, permanecendo bloqueada na agenda de execução do sistema por quase quatro dias e depois disso foi simplesmente cancelada por ter excedido o tempo máximo de espera na fila.

Dos parâmetros de análise citados acima, com certeza o tempo medido com várias configurações de processadores foi o mais sensível às mudanças de configuração.

O desempenho é crescente com o número de processadores utilizados de maneira praticamente linear, salvo algumas variações causadas pela superpopulação do sistema descrita anteriormente.

Gráfico de desempenho ao se comparar o número de passos na resolução do sistema de equações lineares pelo método dos gradientes biconjugados.

Além disso, são comparados os desempenhos de modelos com o mesmo número de graus de liberdade e mesmo número de etapas de simulação, mas com diferentes números de passos por etapa.

O número de passos de cada etapa está relacionado ao método dos gradientes biconjugados para se atingir a convergência na resolução de um sistema de equações lineares.

Apesar da razão de desempenho ser maior quando se utilizam mais passos por etapa, não significa que o tempo de cálculo seja menor quando se utiliza mais passos.

Para se atingir a convergência do sistema são necessários pelo menos 2 passos por etapa.

Ao se comparar o tempo gasto em modelos que possuíam o número de graus de liberdade diferente não houve variações significativas.

Ao contrário do que aconteceu  no protótipo  de computador paralelo desenvolvido  e descrito anteriormente, a quantidade de graus de liberdade não influenciou muito no desempenho do sistema.

Isso se deve à grande quantidade de memória RAM de cada nó e ao baixo tempo de latência do sistema de rede e armazenamento.

Outro parâmetro analisado que demonstrou diferenças significativas no desempenho foi a quantidade de etapas de simulação.

Cada etapa de simulação representa uma fase de escavação e suporte do túnel, ou seja, representa um novo modelo com condições geométricas modificadas.

Como o programa possui ainda várias partes do código que são seqüenciais, isso obriga o fluxo de dados a sair de um regime paralelo para um seqüencial todas as vezes que um modelo é redefinido geometricamente.

Ao se comparar o desempenho do sistema para realizar simulações com números de etapas diferentes nota-se que existem diferenças substanciais que podem chegar a até 50% do desempenho de uma simulação com poucas etapas.

Além dos testes de performance, foram comparados os resultados do programa de código aberto com os resultados do software FLAC3 D para o caso do avanço da frente de escavação de um túnel circular.

As diferenças não foram significativas.

Observa-se que os resultados do TOCHNOG ficaram entre os resultados do FLAC3 D ao se utilizar elementos casca e elementos sólidos do tipo bloco hexaédrico.

Percentualmente, a diferença entre os resultados do TOCHNOG com elementos sólidos e os resultados do FLAC3 D com casca e sólido chegaram ao máximo de 4% e 2%, respectivamente.

Gráfico de desempenho do sistema paralelo ao se comparar o número de etapas de simulação do processo de escavação e suporte.

Gráfico comparativo dos resultados de esforços solicitantes do revestimento entre FLAC3 D e TOCHNOG.

Neste capítulo, é dado início à elaboração do método de análise da interação maciço-suporte proposto neste trabalho.

Primeiramente, é feita uma divisão de conjuntos de análise, baseada em seqüências de escavações reais que adotam sistemas de suporte com propriedades constantes durante todo o processo de execução do túnel ou com propriedades dependentes do tempo.

Cada etapa destas seqüências é descrita com detalhes de modo a facilitar a compreensão da construção do método.

A fim de se considerar os efeitos tridimensionais de transferência de carga, todas as simulações numéricas do avanço da frente de escavação foram realizadas em modelos tridimensionais, ora discretizados pelo método das diferenças finitas (MDF), ora pelo método dos elementos finitos (MEF).

Desta maneira, numa etapa posterior, serão mostradas as formas de tratamento do problema e suas restrições, as combinações entre maciço e suporte analisadas e um sumário de todas as simulações realizadas nesta pesquisa.

As seqüências de avanço da frente de escavação e de instalação do suporte dos túneis que foram simuladas numericamente, como fase intermediária para a estruturação do método aqui proposto, se dividem em dois conjuntos básicos.

Cada conjunto destes representa a análise de alguns dos parâmetros essenciais da interação maciço-suporte, e sua influência no carregamento final absorvido pelo suporte, tenha este propriedades constantes, ou variáveis ao longo do eixo do túnel.

1º Conjunto, o primeiro conjunto de análise é composto pelas simulações tridimensionais do avanço da face de um túnel, que possui um suporte constituído por elementos pré-moldados, ou seja, suporte com propriedades constantes do início até o final da escavação.

Nessas simulações, os únicos parâmetros modificados foram os comprimentos de escavação, Le, e o comprimento atraso inicial, Lui.

Os parâmetros geométricos, Lui e Luf, representam os comprimentos de atraso inicial e final, medidos da frente de escavação à borda do último elemento instalado antes e depois da escavação, respectivamente.

Repete-se aqui, como um dos casos limites de análise, os mesmos tipos de simulações realizadas por SCHWARTZ e EINSTEIN.

Além disto, este conjunto de análise servirá para validar todos os resultados encontrados pelas simulações, e para expor algumas deficiências encontradas no trabalho de SCHWARTZ e EINSTEIN, que serão mostrados nos próximos capítulos.

Nomenclatura dos elementos longitudinais que descrevem as seqüências de escavação do conjunto 1.

A seqüência de operações na modelagem desse problema consiste em se retirar o material do maciço, até que se atinja a desejada distância entre a face e a borda do segmento de suporte recém instalado (comprimento atraso final, Luf = Le + Lui).

Sendo esse requisito atendido, então são efetuados os cálculos pelo MDF ou MEF, para que seja quantificada a transferência de carga para o suporte.

Após o término dos cálculos, é instalado um novo lance de suporte de comprimento Ls (= Ls ) e escavado um novo lance.

Essa rotina é repetida até que sejam estabilizados os deslocamentos e os esforços solicitantes no suporte, para um dado ponto fixo de monitoração.

O segundo conjunto analisado é composto por simulações axissimétricas do avanço da face de um túnel com sistema de suporte em concreto projetado, logo, considerando suas propriedades do suporte dependentes do tempo.

O comprimento de atraso é mantido constante durante todo o processo de escavação em todos os casos.

O único parâmetro variável, dentre os casos analisados, é a taxa média de avanço da face do túnel, ou velocidade média de escavação, V, que geralmente é expressa pelo comprimento escavado e revestido no prazo de um dia.

Nomenclatura dos elementos longitudinais que descrevem as  seqüências de escavação do conjunto 2.

Ao se admitir que existe uma velocidade média de escavação constante durante todo o processo, indiretamente, está-se admitindo que o desenvolvimento do módulo de elasticidade do concreto projetado pode ser expresso como uma função da distância à frente de escavação.

Ou seja, faz-se com que cada segmento de concreto que foi aplicado assuma valores diferentes de rigidez ao longo do eixo do túnel.

Esse processo de cura do concreto projetado, que parte do material ainda fresco, lançado imediatamente após a escavação do último lance, até chegar ao material curado aos seus 28 dias de idade.

A diferença de tempo em dias, ts, na instalação de segmentos de suporte subseqüentes, para uma velocidade de escavação constante, V, dada em unidade de lances por dia, é igual ao inverso dessa velocidade, para qualquer que seja comprimento de segmento de suporte, Ls.

Tomando a frente de escavação como ponto de referência da distância, Z, de um segmento de suporte instalado NL lances de distante do primeiro lance, obtém-se a relação entre E e Z, ao se substituir o tempo na equação (29), proposta por GOLSER, por (71), Admitindo-se diferentes velocidades de avanço, porém constantes para cada simulação, podemos obter as diferentes evoluções do módulo de elasticidade do concreto projetado ao longo do eixo longitudinal do túnel.

Cria-se desta maneira, diferentes configurações de suporte para um túnel.

Cada curva parte de um módulo de elasticidade nulo, indicando concreto projetado fresco, e se estabiliza em diferentes distâncias para as diferentes velocidades de avanço e diferentes comprimentos de escavação.

As simulações do segundo conjunto são realizadas seguindo-se a mesma seqüência de passos existentes na modelagem dos problemas do primeiro conjunto.

Entretanto, leva-se em conta que, após a retirada do material, é simulada a instalação de um novo lance de suporte de comprimento, Ls, e o módulo de elasticidade com idade compatível à razão entre esse comprimento e a velocidade de avanço do túnel.

Gráfico da distribuição do módulo de deformabilidade do suporte ao  longo do eixo do túnel, para diferentes taxas de avanço.

Gráfico da distribuição do módulo de deformabilidade do suporte ao  longo do eixo do túnel, para diferentes taxas de avanço.

Gráfico da distribuição do módulo de deformabilidade do suporte ao  longo do eixo do túnel, para diferentes taxas de avanço.

Desse último segmento instalado para trás, todos os demais módulos são recalculados com um acréscimo de tempo igual à idade do último lance instalado.

E novamente, esse processo é repetido até que sejam estabilizados os valores de rigidez dos segmentos de suporte localizados nestes pontos de monitoramento, os valores de deslocamentos radiais da interface maciço suporte e os de esforços solicitantes do suporte.

Com o intuito de se quantificarem os efeitos do atraso na instalação do suporte e da dependência do tempo de suas propriedades nos esforços solicitantes finais do mesmo e nos deslocamentos radiais da interface, algumas seqüências de escavação foram analisadas através de modelos tridimensionais discretizados pelo MDF e MEF, considerando o maciço e o suporte como materiais elásticos ou elastoplásticos.

Estas análises buscaram reproduzir numericamente o avanço de um túnel passo a passo, através da retirada de material do maciço na região da face do túnel (desativação de zonas ou elementos do modelo numérico), e da instalação do suporte (ativação de novas zonas ou elementos no modelo e a mudança das propriedades destas) em momentos adequados das simulações, seguindo as etapas já descritas no item 71.

O programa comercial Fast Lagrangian Analysis of Continua in 3 Dimensions, e o programa de código aberto TOCHNOG  foram utilizados na modelagem numérica de todas as seqüências de escavação realizadas neste trabalho.

Estes pacotes de software têm como técnica numérica básica para a resolução de equações diferenciais geradas por problemas mecânicos, o método das diferenças finitas e dos elementos finitos, respectivamente.

Nestes pacotes computacionais, as soluções das equações de movimento geradas em cada ponto do domínio discretizado são determinadas de maneira explícita, ou seja, iterativamente através do método de relaxação dinâmica.

O motivo de ter-se escolhido o software FLAC, se deve à vantagem oferecida por este de possuir uma linguagem interna de programação, chamada FISH.

Foi este fator que permitiu, através da implementação de rotinas de cálculo, a automatização das seqüências de escavação e instalação do suporte, principalmente no caso das seqüências do segundo conjunto, onde, depois de se instalar o último lance de suporte, se faz necessária a mudança das propriedades dos demais lances instalados em rodadas anteriores.

Já no caso do programa TOCHNOG, a sua principal vantagem é que ele possui código aberto, ou seja, custo zero, e ainda admite modificações, como mencionado anteriormente.

A maioria das simulações foi executada em 80 rodadas de escavação e instalação de suporte, o que significa resolver o mesmo problema 81 vezes para uma única simulação, somando um tempo de processamento de até 15 dias em algumas simulações.

O domínio do problema, que se estende por 100 metros na direção longitudinal e por 30 metros nas direções contidas no plano transversal ao eixo do túnel, e foi discretizado com aproximadamente 39216 pontos, 34048 zonas e 2816 elementos estruturais (ou 7040 hexaedros adicionais, no caso do TOCHNOG).

Este alto número de zonas se deve ao atendimento dos requisitos geométricos exigidos pelos programas para obtenção de uma solução com um grau de precisão satisfatório.

Além disso, neste tipo de modelagem, é impossível de se fugir de uma malha com alto grau de refinamento, ou seja, de um grande número de elementos, pois sempre existem grandes distâncias a serem escavadas a passos pequenos.

Com relação às grandes extensões do domínio, tentou-se com isso reduzir a influência do contorno na região de monitoramento, deixando-se assim uma extensão longitudinal estável de 50 m para as simulações do processo de escavação.

Esta grande distância longitudinal foi adotada a fim de que as propriedades do concreto pudessem ser estabilizadas até um certo nível quando fossem adotadas as maiores velocidades de escavação, ou seja, distância suficiente para que o concreto projetado atinja a idade de aproximadamente 16 dias.

Durante cada rodada das simulações, foram monitorados e armazenados em tabelas os deslocamentos radiais, u, e as tensões normais tangenciais, encontradas no suporte, em três pontos diferentes do domínio.

No capítulo seguinte, estes dados armazenados pelo programa são expostos em forma de gráficos adimensionalizados.

Além dos detalhes relacionados à densidade de pontos necessários à discretização do problema, pode ser observada uma das principais desvantagens do software TOCHNOG em relação ao FLAC3 D.

O fato deste primeiro não possuir elementos estruturais, acaba por acarretar a utilização de 5 elementos sólidos na espessura do revestimento.

Este tipo de ação é necessário para que se obtenha uma boa estimativa dos esforços de flexão no revestimento.

Todas as análises numéricas foram realizadas para cinco combinações diferentes entre maciço e suporte.

Estas combinações buscaram abranger os vários tipos de maciços existentes e os suportes normalmente utilizados em sua estabilização, como exemplo, as combinações 1 e 2 possuem características de túneis executados em solos de consistência mole a média.
A combinação 3 representa a escavação em solos rijos ou em rochas brandas, a quarta combinação indica túneis executados em rochas de características moderadas a competentes e a quinta combinação se trata de um caso limite, onde o maciço consiste de uma rocha excepcionalmente competente.

Todas as propriedades físicas e geométricas dessas combinações analisadas estão resumidas.

Discretização na região da frente de escavação com a utilização de  somente elementos sólidos pelo TOCHNOG.

Discretização na região da frente de escavação com a utilização de elementos sólidos e elementos estruturais pelo FLAC3 D.

Além dos demais parâmetros geométricos e físicos individuais, apresenta-se o parâmetro, Ta/PR, que se utiliza da rigidez relativa, C, chamado de coeficiente adimensional de compressibilidade, que foi definido por SCHWARTZ e EINSTEIN, como já descrito no Capítulo 3.

Este parâmetro informa a porcentagem de carga que seria transferida do maciço para o suporte se não houvesse consideração do alívio das tensões existentes no maciço, devido aos deslocamentos deste, anteriores à instalação do suporte.

Propriedades físicas e geométricas das combinações maciço suporte consideradas nas analises numéricas.

Deve ser lembrado que as rigidezes individuais, sejam elas do suporte, ou do maciço, não têm muita importância no mecanismo geral de transferência de carregamentos na interação.

Contudo, sua importância é fundamental quando os elementos são considerados em conjunto, como através do parâmetro adimensional de rigidez relativa, C.

Para cada uma das 5 combinações foram simuladas várias seqüências de avanço da frente de escavação, nas quais foram variados os comprimentos atrasos iniciais e os de escavação, quando o suporte possuía propriedades constantes ao longo de todo o processo de escavação, e a velocidade de escavação, em adição a esses comprimentos, quando o suporte apresentava um comportamento dependente do tempo.

Tudo isto em concordância aos passos dos dois conjuntos de análise descritos na seção anterior.

Desta forma, além das combinações maciço-suporte expostas extremos de 050 m a 200 m, velocidades de avanço que variavam de 0 (situação limite relativa ao revestimento com propriedades constantes) a 6 lances/dia, coeficientes de empuxo de 025 a 400 e coberturas de 05 a 4 diâmetros.

Abaixo, são enumerados todos os subconjuntos e seus valores utilizados nas simulações.

Deve ser ressaltado que, no subgrupo dos maciços, quando levados em conta os parâmetros de Mohr-Coulomb, c e f, estes foram variados de forma a representar grupos de solos com características coesivas (f=0), não coesivas (c=0) e solos com ambas características (c0 e 0).

Os comprimentos de atraso Lui, Luf e Ld agora são dados em função dos comprimentos de escavação e suporte, Le e Ls (sendo sempre Le = Ls), de forma diferente da feita por SCHWARTZ e EINSTEIN, já discutido na revisão bibliográfica.

Isso foi introduzido após se constatar que, para modelos com mesmo comprimento de atraso, Ld/R, ainda existem configurações geométricas diferentes e que implicam em diferenças expressivas de carregamentos no suporte.

Como exemplo disso, pode-se citar o caso de um modelo de túnel profundo com raio igual à 3 m e espessura do revestimento, ts, igual à 15 cm, em que o comprimento de atraso, Ld, é fixado em 300 m.

Diante destas condições foi possível gerar quatro configurações geométricas diferentes, apenas por variar o comprimento de escavação e os comprimentos de atraso, Lui e Luf.

Gráfico da distribuição de esforços de compressão no suporte ao longo do eixo do túnel, para comprimentos de atraso, Ld, idênticos.

Os esforços normais apresentam variações significativas com o comprimento de escavação, Le, considerado constante por SCHWARTZ e EINSTEIN.

Nos casos extremos de comprimentos de escavação iguais a 100 m e 200 m, a variação dos esforços normais atingiu a marca de 86% de acréscimo do valor mais baixo para o mais alto.

Este aspecto será discutido com maior riqueza de detalhes em capítulos posteriores.

No total foram realizadas 562 simulações do avanço da frente de escavação com a instalação do revestimento de concreto projetado.

Os gráficos de esforços de compressão no revestimento são mostrados no próximo capítulo.

No início deste capítulo, os resultados obtidos nas simulações numéricas tridimensionais do avanço da frente de escavação são organizados em gráficos adimensionais.

Durante esta fase também, é brevemente explanada a maneira como estes gráficos foram construídos.

A validação desses resultados é feita no próximo capítulo.

Os valores armazenados nas tabelas do programa foram transformados em gráficos dos valores adimensionais dos esforços solicitantes de compressão do suporte, T*, em função da distância relativa à frente de escavação, para o caso em o coeficiente de empuxo em repouso, K0, é igual a unidade.

Já no caso de K0 diferente da unidade, os resultados foram sumarizados em gráficos dos valores adimensionais dos momentos fletores do suporte máximos já estabilizados, M*, em função do vão longitudinal livre entre a frente e o último segmento suporte logo após a escavação, Lui.

O adimensional, T*, é a razão entre o esforço normal à seção transversal do suporte, Ts, obtido nas simulações numéricas, e o esforço de compressão, Ta, obtido pela equação analítica que considera a condição de deslizamento relativo impedido, ou de transferência total de esforços cisalhantes na interface entre o maciço e o suporte, desenvolvida por SCHWARTZ e EINSTEIN.

De maneira análoga, se define também M*.

Desta forma, os valores dos adimensionais de T*e M*.
As curvas de esforços normais resultantes das simulações foram reunidas em dois conjuntos.

O primeiro conjunto de gráficos  representa as simulações em que as propriedades do suporte foram mantidas constantes ao longo do eixo longitudinal do túnel.

O segundo conjunto de gráficos representa as simulações em que as propriedades do suporte foram variadas ao longo do eixo longitudinal do túnel, de acordo com a velocidade de avanço, que variou de um a seis lances escavados por dia.

Além da variação das propriedades do suporte ao longo do eixo longitudinal, foram considerados em cada conjunto, cinco tipos de maciço representados pelas combinações de 1 a 5, cinco valores de comprimentos de escavação, Le, variando de 05 a 20 metros, cinco valores de comprimentos não-suportados iniciais, Lui, variando de zero a duas vezes o comprimento de escavação.

Em um terceiro conjunto, se encontram as curvas dos resultados sumarizados dos esforços de flexão máximos estabilizados das simulações onde as propriedades do suporte são constantes e foram considerados dois coeficientes de empuxo diferentes da unidade (K0 = 2 e 4).

Além disso, foram consideradas, as mesmas 5 combinações maciço suporte, descritas acima, 2 valores de comprimentos de escavação (Le,= 07 m e 10 m), 5 valores da razão entre os comprimentos não-suportados iniciais, Lui, e os de escavação (Lui/Le = 0, 05, 10, 15 e 20).

Gráfico dos esforços normais no suporte versus a distância entre a frente de escavação e o segmento de suporte analisado.

A inexistência de uma maior dispersão nos resultados encontrados, principalmente para os valores mais baixos do comprimento de atraso, é um aspecto que deve ser observado com mais detalhes no gráfico.

Um dos motivos para a ocorrência desta dispersão pode ser explicado pela utilização naquelas simulações de um modelo axissimétrico pouco refinado.

Aquela malha possuía 118 elementos e 225 nós, computando um total de 402 graus de liberdade.

Além de pouco refinada, ela ainda misturava elementos quadráticos (em regiões próximas à escavação) com elementos lineares (regiões mais afastadas).

Um dos problemas encontrados nesta mistura de funções de forma é a sobreposição ou afastamento de porções intermediárias dos elementos na interface entre as regiões quadráticas e lineares, causando descontinuidades e desprezando assim algumas parcelas da energia de deformação.

Em adição a isso, foram realizados somente quatorze passos de escavação, cada um desses com o comprimento de meio raio de túnel.

Foram considerados apenas os oito passos finais de escavação e foram descartados os seis passos iniciais.

As seqüências de escavação e suporte em suas simulações consideram o vão longitudinal máximo sem suporte de uma seqüência real (vide páginas 62, 63 e 64 daquele trabalho).

Em outras palavras, como nas simulações as etapas de escavação e suporte são realizadas simultaneamente, não havendo, como em uma escavação real, uma etapa intermediária, representando somente a etapa de instalação do suporte, o comprimento de atraso, Ld, deve representar o comprimento atingido logo após a fase de escavação na seqüência real.

Os comprimentos de atraso simulados, verifica-se que comprimento de atraso Ld/R = 025 não pode ser considerado como válido.

Este comprimento de atraso indica para as simulações, segundo a convenção adotada, que o suporte está encostado na face logo após a escavação de um novo lance, ou seja, o revestimento é introduzido antes de se escavar o maciço.

Ou ainda que a distância entre a frente de escavação e a borda do revestimento, em uma fase intermediária de uma escavação real, é negativa.

Existem métodos de construção em que o revestimento é instalado à frente da face do túnel por motivos de estabilidade, mas, naquele trabalho não era intenção, simulá-los.

Ainda no gráfico, pode ser observada uma outra incoerência apresentada pela solução adimensional proposta por SCHWARTZ e EINSTEIN, já comentada em capítulo anterior, como sendo fruto da insuficiência de resultados para a realização deste tipo de análise final.

Esta solução adimensional foi obtida através de uma regressão linear com base em três nuvens de pontos.

Estas nuvens são relativas aos três atrasos na instalação do suporte considerados por aqueles pesquisadores, Ld/R = 025, 075 e 125.

No entanto, como já dito acima, a primeira nuvem de pontos, Ld/R = 025, representa uma situação irreal de escavação e deve ser descartada da análise de regressão.

Assim, o que resta são apenas duas nuvens de pontos para o ajuste de uma reta, resultando em uma regressão linear com um grau de significância muito baixo.

Soma-se a isto a inconsistência relativa à má escolha das características dos materiais analisados, já que, naquele trabalho, foram simuladas 3 de 5 combinações, praticamente iguais.

Este fato compromete o nível de precisão atingido pela solução adimensional na quantificação de esforços para qualquer atraso na instalação do suporte.

Que representa a nomenclatura já adotada neste trabalho, podemos extrair facilmente as expressões.

No trabalho de SCHWARTZ e EINSTEIN, como já exposto, foi considerado apenas um comprimento de escavação, Le = 05 R, e desta maneira, baseado nas equações acima, só existe uma configuração geométrica possível para um dado comprimento de atraso, Ld.

Entretanto, ao se modificar o comprimento de escavação, Le, podemos obter mais de uma configuração geométrica na região da frente de escavação.

É importante ressaltar que para túneis em solo escavados por "shield" ou NATM o comprimento de atraso igual a meio raio é muito irreal.

Com a finalidade de se verificar a eficiência do método proposto por SCHWARTZ e EINSTEIN, foram realizadas algumas simulações em que o comprimento de atraso, Ld, foi mantido constante e os comprimentos Le e Lui foram variados de maneira a reproduzir diferentes configurações geométricas.

São mostradas as diferentes configurações geométricas obtidas ao se manter constante o comprimento de atraso, Ld = R, e ao se variar os comprimento de escavação (Le = 0333 R, 05 R e 0667 R) e os comprimentos livres iniciais (Lui = 05 R, 025 R e 0).

Além dessas verificações, foram realizadas outras simulações em que se manteve fixo o comprimento livre final, Luf, também chamado de Lu por RANKEN e GABOUSSI, para que também pudesse ser verificada a sua eficácia ao caracterizar a geometria longitudinal da frente de escavação.

As críticas proferidas por SCHWARTZ e EINSTEIN, de que Lu não era um bom parâmetro, estavam corretas.

A variação de esforços chegou a aproximadamente 43% de aumento ao se variar os comprimentos Le e Lui.

Representação de 3 comprimentos de atraso iguais que geram  condições geométricas diferentes e, conseqüentemente, diferentes carregamentos.

Onde o comprimento de atraso, Ld, foi mantido constante as variações de esforços chegaram a quase 100%.

Destas comparações, pode-se entender que somente os comprimentos de atraso compostos, Ld e Luf, não são suficientes para retratar as características geométricas longitudinais da frente de escavação.

Esses são considerados compostos por se tratarem da união de outros dois comprimentos básicos, ou variáveis independentes, Le e Lui, expostos nas expressões.

É feito o mesmo tipo de comparação, mas agora se levam em conta os comprimentos básicos, Le e Lui.

Gráfico dos esforços de compressão no revestimento em função da distância à frente de escavação para três comprimentos de atraso, Luf, iguais.

Fixou-se o comprimento livre inicial, Lui = 0, e variou-se o comprimento de escavação, Le, de 0167 R a 0667 R.

De forma semelhante, fixou-se o comprimento de escavação, Le = 0333 R, e variou-se o comprimento livre inicial, Lui, de 0 a R.

Observa-se, nestes gráficos, que os esforços compressivos variam em grande proporção ao se fixarem os comprimentos básicos, Le e Lui Gráfico dos esforços de compressão no revestimento em função da  distância à frente de escavação para três comprimentos de atraso, Ld, iguais.

Com relação à dispersão dos resultados deste trabalho encontrada no gráfico, pondera-se que a rigidez da frente de escavação poderia influenciar na variação dos esforços compressivos instalados no revestimento.

O gráfico foi concebido de forma a investigar a influência deste parâmetro.

Cada ponto do gráfico corresponde ao resultado, em termos de esforços compressivos estabilizados, de uma simulação em que se manteve fixo o comprimento de escavação, e cada curva representa a fixação de um comprimento livre inicial.

Desta maneira, pode-se ver nitidamente que a variação de esforços compressivos com o módulo de deformabilidade do maciço é significante, cerca de 60% de acréscimo do maior ao menor valor de deformabilidade do maciço, para a curva em que o comprimento livre inicial fixado como sendo zero.

Este acréscimo do maior para o menor valor de deformabilidade para uma dada curva diminui, à medida que o comprimento livre aumenta.

A partir destas análises, no momento da confecção do gráfico da solução adimensionalisada, deve-se considerar um fator composto, tanto pelos comprimentos de atraso básicos, Le e Lui, quanto pelo módulo de deformabilidade do maciço.

Curvas de variação dos esforços de compressão em função do  comprimento livre inicial, Lui, e da rigidez relativa entre maciço e suporte.

É mostrado como se distribuem os pontos em um espaço definido pelo comprimento de atraso, Le/R, pelo comprimento livre inicial, Lui/R, e pelo esforço de compressão adimensional estabilizado, T*.

Neste gráfico, o módulo de deformabilidade do maciço, Em, foi representado por diferentes cores.

Os pontos pretos representam o menor valor de módulo de deformabilidade do maciço, e por isso são responsáveis pelos maiores valores de esforços compressivos adimensionais, T*, obviamente, mantendo-se fixos os comprimentos adimensionais, Le/R e Lui/R.

Os valores dos esforços decrescem à medida que passamos de um maciço pouco rígido para um mais rígido, ou no caso, quando mudamos do conjunto de cor preta para o de cor vermelha, e deste para o de cor amarela, e assim por diante até chegarmos no conjunto de cor azul, que representa um caso limite teórico, onde o módulo de deformabilidade foi admitido como sendo quatro vezes maior que o do concreto.

Observa-se ainda, neste gráfico, que os pontos se encontram distribuídos de acordo com alguma superfície de tendência, e cada variável parece gerar uma grande influência sobre as demais.

Representação tridimensional dos resultados obtidos nas simulações dos esforços de compressão estabilizados.

Pode-se observar que a superfície gerada pela modificação da equação adimensional proposta por SCHWARTZ e EINSTEIN  não se aproxima bem dos resultados encontrados nas simulações deste trabalho.

Esta equação modificada foi obtida ao substituir o comprimento de atraso, Ld/R, pela soma dos comprimentos, livre inicial e de escavação.

Partiu-se então para o ajuste de outras curvas, como pode ser apreciado na seqüência.

Representação tridimensional dos resultados obtidos comparados com a expressão adimensional proposta por SCHWARTZ e EINSTEIN.

Primeiramente, foi feito o ajuste de uma função linear simples como a mostrada na equação.

Pode ser observado o gráfico de dispersão entre os resultados numéricos e as variáveis consideradas, gerado pelo programa estatístico R.

Pode-se notar que o esforço de compressão adimensional T* varia de maneira não linear com as demais variáveis.

Além disso, os valores de Em parecem estar, de certa forma, condensados em três regiões bem definidas do gráfico T*x Em, demonstrando uma certa tendência logarítmica entre estas grandezas.

Além dos gráficos de dispersão, outras informações podem ser observadas, como algumas características da distribuição de cada variável mostradas, a matriz de correlação entre as variáveis mostrada, algumas características da distribuição de resíduos, e os valores dos coeficientes encontrados na regressão mostrados.

Gráficos da dispersão de pontos obtidos nas simulações numéricas.

Características da distribuição de cada variável.

Matriz de correlação entre variáveis.

Características da distribuição de resíduos.

Valores dos coeficientes encontrados na regressão.

Valor obtido neste ajuste  não foi suficiente, necessitando assim de uma função mais complexa, como é o caso da equação.

A única diferença entre a equação anterior e esta nova reside no fato de que, agora, será considerado o logaritmo do primeiro termo, Em, no ajuste da superfície.

Esta modificação foi baseada em constatações apresentadas em parágrafos anteriores.


Gráficos de dispersão de pontos obtidos nas simulações numéricas.

Características da distribuição de cada variável.

Matriz de correlação entre variáveis.

Valores dos coeficientes encontrados na regressão.

Neste caso, houve um aumento de quase 10% no valor de R da primeira 2 função para esta segunda, no entanto, o ajuste ainda não é satisfatório.

O resíduo máximo atingido neste caso foi de 02080, o que representa cerca de 25% do máximo valor do esforço de compressão adimensional, T*.

Partiu-se então para o ajuste de uma função mais complexa ainda, como é mostrado na expressão, em que foram considerados os logaritmos dos demais termos, além da adimensionalisação de Lui por Le.

Modificação da dispersão dos pontos obtidos nas simulações.

Características da distribuição de cada variável.

Matriz de correlação entre variáveis.

Características da distribuição de resíduos.

Valores dos coeficientes encontrados na regressão.

Neste caso, houve um aumento de quase 8% no valor de R, no entanto, o  2 ajuste ainda não é satisfatório.

O resíduo máximo atingido neste caso foi de 01161, o que representa cerca de 14% do máximo valor do esforço de compressão adimensional, T*.

Partiu-se então para o ajuste de uma outra função, que neste caso, além de aplicar o logaritmo em todas as variáveis, foi feita uma transformação em uma das variáveis.

O comprimento livre inicial, Lui, foi adimensionalizado pelo comprimento de escavação, Le, e neste coeficiente ainda foi adicionado a unidade.

A ação de se adicionar unidade a este coeficiente se deve ao fato de que, como os comprimentos livres sempre partiam de zero, houve a necessidade de uma manipulação do argumento da função logaritmo.

Pode se observar a distribuição dos pontos em um espaço tridimensional composto pelas variáveis adimensionais, T*, Le/R e a variável modificada (Lui/Le+1).

Ainda neste gráfico, pode-se observar melhor a grande influência que cada variável exerce sobre as demais.

Representação tridimensional dos resultados obtidos nas simulações dos esforços de compressão estabilizados.

Desta maneira, a tentativa seguinte foi ajustar uma função do tipo aditiva em que os termos são logarítmicos, e a influência de cada variável nas demais será quantificada através da adoção de termos mistos, ou seja, termos que são produtos entre duas variáveis.

Como exemplo deste tipo de função.

Modificação da dispersão dos pontos obtidos nas simulações.

Características da distribuição de cada variável.

Matriz de correlação entre variáveis.

Características da distribuição de resíduos.

Valores dos coeficientes encontrados na regressão.

Neste caso, a superfície adotada se ajusta muito bem ao conjunto dos pontos.

O valor de R2 é bem próximo da unidade (R2 = 09880), o valor máximo do resíduo gerado é de aproximadamente 5% do máximo valor de T*.

Além disso, pode-se notar que os pontos estão bem ajustados, tanto nos limites inferior e superior da variável Em/Es, quanto na presença da grande maioria deles no interior dessas duas superfícies limite.

Representação tridimensional dos resultados obtidos nas simulações e do limite inferior da superfície ajustada.

Assim, tendo sempre em mente os limites dos comprimentos livre inicial e de escavação analisados, o fenômeno de transferência de carregamento do maciço para o revestimento de um túnel circular profundo escavado em um maciço elástico e isotrópico.

Representação tridimensional dos resultados obtidos nas simulações e dos limites superior e inferior da superfície ajustada.

Seguindo os mesmos passos anteriormente descritos, parte-se agora para a determinação de uma solução adimensional em que também seja considerado o endurecimento do concreto projetado.

Para isso, foram testados vários tipos de superfícies como feito anteriormente.

Modulo de elasticidade do último lance projetado.

A dispersão dos resultados obtidos nas simulações em que também foi considerado o endurecimento do concreto ao longo do eixo do túnel.

Podem ser vistos os valores característicos da distribuição de resíduos após o ajuste de uma função do tipo da proposta no último parágrafo.

Características da distribuição de resíduos.

Contém os valores dos coeficientes encontrados no ajuste da função anteriormente proposta, e abaixo pode ser visto os valores dos coeficientes de correlação da superfície ajustada.

Valores dos coeficientes encontrados na regressão.

Neste caso, a superfície adotada se ajusta muito bem ao conjunto dos pontos.

O valor de R2 é bem próximo da unidade (R2 = 09936), o valor máximo do resíduo gerado é de aproximadamente 35% do máximo valor de T*.

Além disso, ao observar o gráfico encontrado, pode-se notar que os pontos estão bem ajustados, tanto nos limites inferior e superior das variáveis Em/Es e Es/Esu, quanto na presença da grande maioria deles no interior dessas duas superfícies limites.

Representação tridimensional dos resultados obtidos nas simulações e dos limites superior e inferior da superfície ajustada.

Pode se notar a presença de cinco superfícies, cada superfície representa o valor de uma velocidade de avanço diferente.

A superfície superior representa as simulações em que as propriedades do suporte foram mantidas constantes, a inferior representa a velocidade de avanço igual a seis lances por dia, e as demais representam velocidades de um, dois e quatro lances de escavação por dia.

Representação tridimensional dos resultados obtidos nas simulações  e das superfícies ajustadas para diferentes velocidades de avanço.

Para o caso em que foram considerados coeficientes de empuxo diferentes da unidade (K0 = 2 e 4), foram seguidos os mesmos passos, anteriormente descritos, a fim de se ajustar uma superfície aos pontos encontrados.

Assim, foram testados vários tipos de superfícies como feito anteriormente.

Pode se observar a distribuição dos pontos em um espaço tridimensional composto pelas variáveis adimensionais, M*, Le/R e a variável modificada (Lui/Le+1).

Ainda neste gráfico, pode-se observar melhor a influência que cada variável exerce sobre as demais.

É importante ressaltar que, apesar de ter sido considerado apenas dois casos de coeficientes de empuxo em repouso, K0 = 2 e 4, existem ainda os seus valores simétricos 05 e 025, respectivamente.

Estes últimos seriam responsáveis pelos mesmos valores absolutos de momentos fletores, contudo, com sinais contrários, ou seja, pontos de mínimo momento.

Representação tridimensional dos resultados obtidos nas simulações  dos momentos fletores estabilizados.

Além disso, apesar de termos apenas dois conjunto de comprimento de escavação, Le/R = 02333 e 03333, pode se notar que a dispersão dos pontos é bem similar às outras tratadas neste capítulo.

Validando de certa forma, a suposição feita por SCHWARTZ e EINSTEIN  de que o seu ld poderia ser utilizado para a determinação, não somente de esforços normais de compressão, mas também de momentos fletores.

No entanto, deve ser feita uma análise mais criteriosa deste tópico para se obter conclusões mais concretas.

A dispersão dos resultados obtidos nestas simulações pode ser observada.

Podem ser vistos os valores característicos da distribuição de resíduos após o ajuste de uma função do tipo da proposta no último parágrafo.

Gráficos de dispersão de pontos obtidos nas simulações numéricas.

Contém os valores dos coeficientes encontrados no ajuste da função anteriormente proposta, e abaixo pode ser visto os valores dos coeficientes de correlação da superfície ajustada.

Valores dos coeficientes encontrados na regressão.

Mostrou-se, por meio de análises numéricas tridimensionais mais complexas e bem definidas, que a solução proposta por SCHWARTZ e EINSTEIN  para levar em conta o efeito do atraso de instalação do suporte no mecanismo de transferência de carga do maciço para a estrutura incorre em erros significativos ao não levar em conta a dimensão do lance de escavação, e a rigidez do maciço na região da frente de escavação do túnel.

Além disso, há uma incongruência naquela formulação relativa à simulação numérica do menor dos comprimentos de atraso na instalação do suporte.

Uma solução alternativa à de SCHWARTZ e EINSTEIN  foi apresentada, incorporando todos os parâmetros geométricos e físicos relevantes da escavação subterrânea, inclusive o endurecimento do suporte de concreto projetado ao longo do eixo do túnel e a anisotropia de tensões iniciais, com grande vantagem de precisão.

Além disso, foi apresentado de maneira não muito conclusiva que a suposição feita por SCHWARTZ e EINSTEIN, de que o mesmo coeficiente de atraso que determina os esforços normais de compressão seria responsável pela determinação dos esforços de flexão, pode estar correta, pois os pontos mostram dispersões muito semelhantes nos dois casos.

As análises numéricas tridimensionais para esta finalidade consumiram bastante tempo de processamento.

Para solucionar este problema, primeiramente, foi montado um sistema paralelo em um banco de cinco processadores, o que pode ser encarado como um protótipo de um cluster, apenas para verificar a possibilidade de utilização deste sistema em problemas mais simples.

Mais tarde, este sistema foi instalado em um computador paralelo de grande porte onde foram realizadas análises numéricas mais complexas.

No entanto, problemas como, o ajuste fino da configuração do cluster caseiro, e a superpopulação e falta de portabilidade que se encontrou ao utilizar o computador de grande porte, ainda são barreiras que devem ser transpostas para que se utilize o processamento paralelo de maneira mais intensiva.

De qualquer maneira, o processamento paralelo se mostrou uma alternativa muito interessante quando o assunto é a simulação numérica tridimensional de túneis.

Principalmente, quando o que se quer é simular o avanço da frente de escavação com a instalação do suporte, problema de cálculo repetitivo que possui grandes dimensões, mas que também possui pequenos passos de avanço, aumentando em muito a quantidade de incógnitas do modelo.

Com relação às soluções adimensionais, muito ainda pode ser feito.

A análise dos resultados das simulações se restringiu somente aos esforços normais de compressão e aos de flexão que atuam na seção transversal do modelo.

Não foi feito o mesmo tipo de análise para os esforços que atuam na direção longitudinal.

Além disso, as análises enfocaram metade das simulações realizadas, não considerando, desta maneira, aspectos muito importantes como a plasticidade do material que constitui o maciço, e as características geométricas dos túneis rasos.

Outro aspecto importante, que deve ser levado em conta, é que todas as expressões adimensionais foram obtidas a partir do ajuste de superfícies aos pontos obtidos de simulações numéricas, portanto, de maneira estatística, puramente matemática, carente assim de aspectos físicos fundamentais do modelo que define os mecanismos de transferência de carga do maciço para o suporte, que ainda é indeterminado.

Um passo adiante nesta direção, seria desenvolver um modelo de cunho determinístico que explicasse de maneira completa estes mecanismos de transferência de carga, tendo com ponto de partida as simulações existentes e as análises estatísticas realizadas.

Para a análise dos resultados das simulações que consideraram a plastificação do maciço para túneis circulares profundos com isotropia de tensões, sugere-se que no momento de se adimensionalizar os valores de esforços normais de compressão não se proceda da mesma maneira que SCHWARTZ e EINSTEIN.

Estes autores adimensionalizaram os resultados de suas simulações pelos resultados de sua solução fechada para esforços de compressão mostrada em detalhes nos capítulos 3 e 8.

Contudo, aquela solução considera o maciço como sendo elástico linear, fazendo com que fique difícil de se dissociar os efeitos do atraso, ld, dos efeitos da plastificação do maciço, ly.

SCHWARTZ e EINSTEIN  reconhecem que seu método não é muito acurado, quando se necessita determinar os efeitos da plastificação do maciço sobre os esforços solicitantes do suporte.

Para contornar este problema, sugere-se que a adimensionalização dos resultados das simulações seja feita através de uma solução analítica que considere a plastificação do entorno da escavação.

Uma sugestão seria resolver o sistema não linear obtido ao se combinar a solução analítica proposta por SALENÇON, já descrita no capítulo 6, com a solução para esforços normais em tubos de parede delgada.

Para resolvê-lo, primeiramente deve-se igualar os deslocamentos radias de ambas equações, lembrando-se que a pressão interna à escavação da primeira solução é igual à pressão externa da segunda.

É claro que existem algumas dificuldades algébricas na resolução deste sistema que podem ser facilmente contornadas de maneira numérica.

Para a análise dos resultados das simulações que consideraram o maciço elástico linear para túneis rasos, ou seja, com a consideração de variação de tensões com a profundidade, recomenda-se a adimensionalização dos esforços obtidos nas simulações pelos da solução analítica proposta por HARTMANN.

Neste caso, a cobertura do túnel será uma nova variável geométrica que deverá ser incluída nas análises.

Contudo, ainda não foi possível encontrar uma solução analítica que considere a mesma situação da descrita acima, neste parágrafo, além de considerar a plastificação do maciço.

Desta maneira, será difícil dissociar os efeitos da cobertura e da plastificação nos esforços solicitantes.

Neste anexo, é apresentada a conceituação de alguns modelos reológicos e a dedução de suas relações constitutivas que são utilizadas como matéria prima de várias simulações, como no método proposto por CELESTINO, e que, além disso, serviram de ferramentas para a compreensão de alguns fenômenos observados no comportamento do concreto projetado.

Os tópicos estão ordenados de maneira crescente com o nível de dificuldade, partindo de uma descrição detalhada de todos os modelos elementares, até chegar a modelos compostos mais complexos como o viscoelástico de Burger e o elasto-viscoplástico proposto por MUNAIAR NETO e PROENÇA.

Logo após, é feita uma breve explanação da teoria geral da plasticidade e viscoplasticidade e de como estes tipos de não-linearidade são tratados ao se realizar uma análise via técnica numérica dos elementos finitos.

Modelo elástico pode ser representado por uma mola  cuja constante elástica K, razão entre a força aplicada e o deslocamento decorrente, é substituída pelo módulo de elasticidade do material E razão entre a tensão aplicada, e a deformação específica decorrente, resultando na Lei de Hooke, = E.
Ao se aplicar uma tensão no modelo, são geradas deformações imediatas e invariáveis no tempo, sendo que numa fase de descarregamento as deformações são totalmente reversíveis, ou seja, a mola voltará ao seu comprimento original.

Esquema de mola solicitada por uma determinada tensão.

O módulo de elasticidade do material pode ser admitido como constante ou variável (seguindo uma determinada função, em concordância com o estado de deformação em que se encontra), desta maneira divide-se o comportamento elástico em linear e não linear respectivamente.

Curvas elásticas linear e não linear.

O modelo plástico pode ser representado por analogia a um sistema físico composto por um bloco rugoso de peso e área unitários sobre uma superfície sem inclinação e também rugosa.

O bloco é solicitado por uma tensão  paralela à superfície onde repousa, e ele só se deslocará se esta tensão de cisalhamento superar a resistência de atrito estático do sistema.

Desta forma a tensão de escoamento ou plastificação do material, y, fica definida como sendo o limite de tensão na iminência de movimentação do bloco.

Esquema de blocos solicitados por uma tensão.

Uma vez deslocado, o bloco não retornará à sua posição original, ou seja, um material rígido-plástico que foi submetido a uma tensão superior à sua tensão de escoamento se caracterizará pelo aparecimento de deformações irreversíveis (residuais), apesar de imediatas, quando descarregado.

O comportamento plástico de um material pode se dividir em perfeito, ou com encruamento.

Curva do comportamento rígido-plástico perfeito.

Curva do comportamento rígido-plástico com encruamento.

No caso do encruamento positivo do material, acréscimos de tensão são admissíveis com a evolução das deformações plásticas seguindo uma função de encruamento linear ou não.

Assim, faz-se analogia ao coeficiente de atrito estático (na fase rígida) e ao coeficiente de atrito dinâmico (na fase plástica com encruamento).

Contudo, deve-se ressaltar que este caso se trata de um dos mais simples modelos compostos, e que a sua inserção nesta fase apenas se mostrou oportuna, já que na próxima seção são apresentados modelos compostos com graus de complexidade bem maiores.

O modelo viscoso pode ser representado por um pistão com êmbolo perfurado imerso em líquido viscoso, ou amortecedor

Apesar de ser a viscosidade uma característica dos líquidos, nos sólidos ela se manifesta pelo aparecimento de deformações não imediatas e totalmente irreversíveis, que se desenvolvem ao longo do tempo, mesmo que as tensões permaneçam constantes.

A grosso modo, este modelo funciona como um "retardador" de deformações.

Esquema de pistão com êmbolo imerso em líquido viscoso.

O tratamento analítico desse tipo de comportamento consiste em se admitir a tensão  proporcional a uma taxa de crescimento de deformações com o tempo (velocidade de deformação), ao se aplicar uma determinada tensão não ocorrerá de imediato uma deformação.

A simulação de deformação ao longo do tempo pela equação anterior, fica evidenciada pela resolução do caso particular de solicitação onde se admite que  permaneça constante e igual.

Curvas representativas do comportamento viscoso.

A expressão acima permite ainda a consideração de que, retirado o carregamento em um determinado instante, a velocidade de deformação é nula, logo as deformações permanecem constantes.

Isto corrobora a idéia de que as deformações irreversíveis são  características intrínsecas dosmateriais de comportamento totalmente viscoso.

O modelo visco-elástico pode ser representado pela associação em série ou em paralelo dos modelos elementares mola e amortecedor, ou mesmo pela associação desses sistemas em série ou paralelo, como é o caso do Modelo de Burger.

Este modelo tem importância significativa na simulação do comportamento de materiais como solo, rochas e concreto, que mesmo em regime elástico apresentam deformações ao longo do tempo.

Para uma melhor compreensão do comportamento visco-elástico dois conceitos devem ser bem fixados, são eles, o conceito de fluência e o de relaxação.

O primeiro trata da análise do crescimento das deformações sob tensão constante, enquanto que o segundo conceito diz respeito à diminuição das tensões partindo-se de um estado de deformações constante.

Ao se fazer a análise, pode-se notar que primeiramente ocorre uma deformação imediata 0 no instante do carregamento do modelo (t=0).

Logo após, segue-se um regime de fluência primária, fluência secundária e finalmente terciária.

Curvas representativas dos conceitos de fluência e relaxação.

No regime de fluência primária as deformações são totalmente recuperáveis no caso de descarregamento e a variação da deformação com o tempo é decrescente em magnitude tendendo a se estabilizar.

O regime secundário se caracteriza pela total estabilização da velocidade de deformação (d/dt = constante), porém as deformações são irreversíveis quando o material se encontra em situação de descarregamento.

No regime de fluência terciária há uma variação crescente e acelerada da deformação no tempo até que se atinja a ruptura.

Os modelos visco-elásticos possuem dois tipos de associações básicas de mola e amortecedor, que permitem reproduzir as características dos regimes de fluência primária (associação em paralelo ou modelo de Kelvin) e secundária (associação em série ou modelo de Maxwell).

Modelo de Boltzmann  O modelo de Boltzman consiste em se associar em série o modelo elástico e o modelo visco-elástico de Kelvin, citados anteriormente.

Esquema de associação em série de uma mola com o modelo  compostos de Kelvin Modelo de Boltzmann.

Curvas representativas do comportamento de tensões e deformações ao longo do tempo para o modelo de Boltzmann.

Modelo de Burger  O modelo de Burger consiste em se associar em série os modelos visco-elásticos básicos de Maxwell e Kelvin, citados anteriormente.

Esquema de associação em série dos modelos compostos de Maxwell e Kelvin Modelo de Burger.

Sua característica principal é a possibilidade de simulação de dois dos três regimes de fluência do material, a fluência primária e a secundária, características marcantes dos modelos básicos de Kelvin e Maxwell, respectivamente.

Desta forma, é possível obter o diagrama de fluência quase completo, faltando apenas o regime de fluência terciária.

São mostrados os gráficos de tensões e deformações em função do tempo.

Curvas representativas do comportamento de tensões e deformações  ao longo do tempo para o modelo de Burger.

Este modelo elasto-viscoplástico foi proposto por MUNAIAR NETO e PROENÇA, e é basicamente composto pela associação em série do modelo visco-elástico básico de Kelvin com o modelo visco-elastoplástico de OWEN e HINTON, uma associação em paralelo dos três tipos de elementos básicos, um elástico, um plástico e um viscoso.

O objetivo principal do modelo de OWEN e HINTON  é a possibilidade de análise temporal do comportamento de um material elasto-plástico.

Deve-se destacar que, neste modelo, a fase plástica possui comportamento equivalente ao modelo rígido-plástico com encruamento.

Isso permite que ocorra a estabilização da deformação total mesmo após ter sido atingida a tensão de escoamento do material.

Representação do modelo elasto-viscoplástico.

O modelo de Kelvin adicionado tem como função principal considerar o desenvolvimento das deformações ao longo do tempo, mesmo que o material esteja exposto a um nível de tensões abaixo da tensão de plastificação, ou seja, a um nível elástico.

Neste modelo, contudo, não são representadas as deformações viscosas irreversíveis, as quais ocorrem mesmo antes de que se atinja níveis de solicitação que venham a ocasionar a plastificação do material.

A deformação total do sistema é obtida de maneira simples como sendo a soma das parcelas de deformação elástica, visco-elástica e visco-plástica.

Para a análise de tensões no sistema, deve ser admitido que p seja igual a Y (nível de tensão do gatilho plástico após atingida a tensão de escoamento do material, y).

Uma vez que tenha sido atingido o nível de tensão y, d2 será a tensão no amortecedor, ou melhor, uma tensão de valor igual a (-p) dissipando-se ao longo do tempo.

É importante destacar que este modelo possui como casos particulares (evidenciados a partir da prescrição de valores nulos ou extremamente altos para alguns dos parâmetros) alguns dos modelos já descritos, o modelo de Burger (E2 = 0 e Y = 0), o de OWEN e HINTON  (1 ), o modelo misto de Kelvin (1 e Y = 0), elasto-plástico com encruamento (1 e 2 = 1), e também, o modelo elasto plástico sem encruamento (1, 2 = 1 e H = 0).

Curvas representativas da evolução de tensões e deformações ao  longo do tempo para o modelo.

Pela análise simultânea da equação geral do modelo modificado (A28) e da equação (A29) a seguir, que é a equação do modelo de OWEN e HINTON, pode-se notar que as parcelas elásticas e visco-plásticas são idênticas.

Contudo, a parcela visco-elástica de tensão e deformação é a principal diferença entre estes.

Este modelo nada mais é do que a adição em série de um modelo viscoso elementar (amortecedor) ao modelo elasto-viscoplástico de MUNAIAR NETO e PROENÇA.

A adição deste simples componente tem a função de representar o comportamento de materiais que apresentam deformações irreversíveis mesmo quando submetidos a níveis elásticos de tensão.

O modelo modificado pode ser melhor compreendido através de suas representações esquemática e gráfica.

Representação do modelo elasto-viscoplástico de MUNAIAR  NETO e PROENÇA  modificado.

Ainda pela observação, pode-se notar que este modelo, quando submetido a um nível elástico de solicitação, apresenta as mesmas características do modelo de Burger.

O desenvolvimento da formulação matemática deste modelo segue os mesmos passos descritos para o equacionamento do modelo de MUNAIAR NETO e PROENÇA  na seção anterior.

Curvas representativas da evolução de tensões e deformações com  tempo para o modelo de MUNAIAR NETO e PROENÇA  modificado, que, em verdade, é a mesma expressão que representa o modelo de Burger.

Entretanto, ao se resolver a mesma equação diferencial, mas agora, considerando um nível de tensão constante e no mínimo igual à tensão de plastificação do material   Esquema de blocos e mola solicitados por uma tensão.

A deformação total,é composta por uma parcela elástica, e, na mola com  constante elástica, E, e uma parcela plástica, p, no dispositivo plástico ou  elemento de Coulomb.

Por considerações de equilíbrio, a tensão, na mola pode ser expressa por, Parte-se agora para a caracterização da resposta mecânica do elemento de Coulomb como se segue.

Análise da resposta friccional irreversível  Assumindo que, p e  são funções do tempo num intervalo [0,T]  R, e em particular, As mudanças na configuração do dispositivo friccional são possíveis somente se a evolução da deformação plástica com o tempo for não-nula.

Pode-se, então, assumir as seguintes hipóteses físicas.
A tensão no dispositivo de fricção, não pode ser superior, em valor absoluto, a y > 0, Isto significa que a tensão admissível está limitada a sempre recair no intervalo fechado [-y, y]  R.

Para isso é introduzida a notação geral.
Note que, num modelo unidimensional, E é um intervalo fechado, e, portanto, será um conjunto convexo fechado no espaço tridimensional das tensões.

E, deve-se mencionar que E representa os limites deste intervalo num modelo unidimensional e a superfície que delimita um conjunto convexo fechado num modelo tridimensional.

Se o valor absoluto de tensão aplicada, for menor que a tensão de escoamento do material, y, nenhuma mudança em p acontece, ou seja, a taxa de variação da deformação plástica é nula.

A resposta instantânea do conjunto mola-dispositivo plástico é elástica.

Pela hipótese 1, para estados de tensão, tal que f > 0 são considerados inadmissíveis, e a taxa de deformação plástica é nula para f < 0 pela hipótese A.

Uma mudança na deformação plástica, p, pode suceder somente se f = 0.

Se a condição anterior é atingida, o dispositivo de fricção experimenta um deslizamento na direção da tensão aplicada, com uma taxa constante de deslizamento.

Tomando essa taxa de deslizamento como sendo o valor absoluto da taxa de deformação plástica, as hipóteses físicas anteriores As expressões acima podem ser reescritas na simples equação abaixo, que também é chamada de lei de fluxo.

Com as observações feitas acima em mente, demonstra-se que a determinação de p, [0,T]  R pode ser completamente descrita para qualquer tensão admissível, com a simples evolução da equação seguinte, desde que a taxa de deslizamento e a tensão atuante estejam dentro de certas condições unilaterais limitantes.

Uma das primeiras condições é que o estado de tensões é admissível e a taxa de deslizamento precisa ser não negativa.

Em segundo lugar, a taxa de deslizamento só é nula se f < 0, e ela somente se desenvolve se f = 0.

Estas condições podem ser expressas pela equação abaixo, também chamada de condição de Kuhn-Tucker, ou, requerimento de consistência.

Esta condição expressa os requisitos físicos de que o estado de tensões deve ser admissível e que o fluxo plástico somente toma lugar, quando o estado de tensões se localiza na envoltória de plastificação.

Por último, considera-se que {(t), p(t)} são dadas num determinado tempo, t  [0, T], de tal forma que (t) é também conhecida pela lei de Hooke, ou seja, (t) = E[(t) p(t)].

Assumindo-se que todos estes parâmetros são funções contínuas e deriváveis no tempo, pode-se expressar, num determinado tempo, t.

Logo, pode ser facilmente demonstrado que a variação da função f "ponto vazio" acima será sempre não-positiva.

Se esta fosse positiva implicaria em uma violação do estado de tensões admissíveis.

Em termos de notação matemática temos, Logo, tem-se a condição a seguir escrita, que é referida alternativamente como condição de persistência ou de consistência.

Esta corresponde ao requerimento físico de que, para que haja evolução das deformações plásticas, p, ou seja, para que sua variação como o tempo seja não-nula, o estado de tensão, E, deve persistir na envoltória do critério de plastificação, E, de tal forma que a variação de f ((t)) com o tempo seja nula.

Baseado na condição de persistência elaborada acima, e aplicando-se a regra da cadeia naquela expressão quando o valor da taxa de deformação plástica é maior que zero temos que, que mostra que a taxa de deformação plástica é igual à taxa total de deformação do dispositivo.

A lei de fluxo mostrada anteriormente se relaciona com o critério de plastificação através da relação potencial plástico.

Gráfico esquemático do comportamento mecânico de um modelo  unidimensional elasto-plástico perfeito.

Mostra esquematicamente o comportamento mecânico do modelo unidimensional elasto-plástico perfeito frente a um ciclo de carregamento e descarregamento.

Além disso, fica nítido nesta figura o conjunto de estados de tensões considerados admissíveis, E = [-y, y].

Como passo seguinte na dedução do ferramental matemático necessário para o estudo da plasticidade, será discutido o aperfeiçoamento do modelo anterior, de forma que, este novo modelo reproduza um efeito observado experimentalmente em muitos metais, denominado por encruamento por deformação ("strain hardening").

Para o modelo anterior, as deformações plásticas tomaram lugar para um valor constante de tensão aplicada, s.

Um modelo de encruamento isotrópico por deformação, por outro lado, nos conduz a uma curva.

Gráfico esquemático do comportamento mecânico de um modelo  unidimensional elasto-plástico com encruamento.

A diferença essencial entre os dois modelos reside no fato de que para o perfeitamente plástico o intervalo, E, permanece inalterado, enquanto que, para o modelo com encruamento por deformação, o intervalo se expande com a quantidade de deformação plástica acumulada pelo sistema, ou melhor, com a quantidade de fluxo plástico.

As considerações básicas permanecem inalteradas em relação às do modelo anterior.

No novo modelo, a expansão (encruamento) experimentada pelo conjunto dos estados de tensão admissíveis, E, é assumida através da observação de duas condições, 1 O encruamento é isotrópico no sentido de que em qualquer estado de carregamento o centro de E permanece na origem do sistema coordenado tensão-deformação.

Esta primeira condição conduz a um critério de plastificação.

O encruamento é linear com a quantidade de fluxo plástico, ou seja, linear com a taxa de deformação plástica e é independente do sinal desta.

Ilustra os novos parâmetros que foram acrescentados ao modelo.

É importante notar que K foi admitido como sendo linear com a deformação plástica.

Módulo tangente e módulo plástico.

Da mesma forma que no modelo anterior, parte-se para a determinação da taxa de deformação através da condição de persistência.

Admite-se novamente que se a variação de f com o tempo é nula, então deformações plásticas ocorreram neste período.

Fazendo-se todas as substituições e cálculos cabíveis recai-se nas equações, O coeficiente, EK/(E+K), é normalmente referido como módulo elasto-plástico tangente, e ele também pode ser melhor entendido pela observação.

Com a finalidade de melhor representar o comportamento real dos metais, foi elaborado o modelo com encruamento cinemático.

Neste modelo, a posição do centro do intervalo E não permanece constante na origem.

O centro pode deslocar-se de uma certa quantidade, diga-se q, contabilizando-se desta maneira no modelo, o efeito Bauschinger.

Assim, o critério de escoamento é então modificado com a inserção desta nova variável.

A evolução do parâmetro de translação, q, é definido através da regra de Ziegler, como segue.

A seguir, são mostrados 2 algoritmos para determinação de tensões a partir de deformações conhecidas.

Logo após estes mesmos algoritmos são empregados em um algoritmo incremental-iterativo padrão para a solução de problemas de valor de contorno.

A técnica numérica utilizada para isto é o método dos elementos finitos aplicado a problemas elásticos quasi-estáticos com incrementos de carregamento.

Modelo elasto-plástico com encruamento isotrópico.

Dados para uma determinada posição no domínio a deformação plástica, pn, e o coeficiente de encruamento, n, num passo anterior, e um novo campo de deformações totais.

É então computado o estado de tensões de tentativa e depois feito o teste para o carregamento plástico.

Ilustração da violação das condições limites f  0 pelo estado de  tensões de teste.

Modelo elasto-plástico com encruamento cinemático.

Dados para uma determinada posição no domínio a deformação plástica, pn, o coeficiente de encruamento, n, e o coeficiente de encruamento cinemático, qn num passo anterior, e um novo campo de deformações totais.

É então computado o estado de tensões de tentativa e é feito o teste para o carregamento plástico.

A discretização por elementos finitos de uma análise quase-estática de uma estrutura fornece um sistema de equações da forma.

No caso em que a matriz de rigidez |K| é dependente dos valores desconhecidos de deslocamento ou de suas derivadas (como no caso dos problemas de grandes deslocamentos e em problemas em que ocorram fluxo plástico) o sistema de equações é não linear.

O método de Newton-Raphson é um processo iterativo de solução de equações não lineares e pode ser escrito de acordo com as expressões.

O lado direito da equação A58 é o vetor de forças residuais, isto é, uma quantificação do desequilíbrio em que o sistema se encontra.

Uma solução de iteração única é mostrada graficamente para um modelo com um grau de liberdade.

Solução por Newton-Raphson para uma iteração.

Como visto na figura anterior, mais de uma iteração é necessária para se obter a convergência para uma solução mais próxima da realidade.

Um algoritmo genérico para solução deste problema pode ser adiante brevemente descrito pelo algoritmo incremental-iterativo.

Algoritmo incremental-iterativo.

Seja um corpo  discretizado em nel elementos, equilibrado num certo instante, ti, sob a ação de forças bi e i.

Assim, nesse instante a relação fundamental de equilíbrio é verificada.
Gráfico esquemático que representa um algorítmo incremental-iterativo para análises elasto plásticas pelo método dos elementos finitos.

Quando a matriz de rigidez é atualizada a cada iteração o processo é denominado Newton-Raphson.

Alternativamente, a matriz de rigidez pode ser atualizada com menor freqüência usando o método de Newton-Raphson parcialmente modificado, ou, utilizando-se apenas a rigidez inicial do sistema, como se faz no método de Newton-Raphson modificado.

Especificamente, para análises estáticas ou transientes, ela poderia ser atualizada apenas durante a primeira ou segunda iteração de cada incremento de tempo.

O uso do método da rigidez inicial previne qualquer atualização da matriz de rigidez e, desta forma, qualquer problema de singularidade nesta matriz.

O método de Newton-Raphson parcialmente modificado e o modificado gastam mais iterações para convergir do que o método de Newton-Raphson.

Contudo, estes métodos modificados exigem menos reformulações matriciais e inversões.

Esquema de blocos e mola solicitados por uma tensão.
A deformação total, é composta por uma parcela elástica, e, na mola com  constante elástica, E, e uma parcela visco-plástica, vp, no dispositivo visco-plástico.

Por considerações de equilíbrio, a tensão, na mola pode ser expressa por, Parte-se agora para a caracterização da resposta mecânica do elemento visco-plástico como se segue.

Primeiramente, deve-se analisar a taxa de variação da deformação visco-plástica, vp = e.

Para isso, deve-se considerar o conjunto de todos os possíveis estados de tensão atuantes no dispositivo visco-plástico que sejam menores ou iguais à tensão de plastificação, y.

Este conjunto é definido como sendo o intervalo fechado [-y, + y], que pode ser escrito, como já mostrado anteriormente, com a seguinte notação, Além disso, deve-se ressaltar que int(E) e E representam o interior e as fronteiras do intervalo representado em (A35).

De posse dessa notação, pode-se considerar as duas possibilidades seguintes, i.

Se int(E), então f < 0 e não deverá acontecer nenhuma mudança na  deformação visco-plástica, representada matematicamente pela seguinte  expressão.

Se E, então f > 0 e a tensão no gatilho plástico é y e a tensão no  embolo, chamado de tensão extra, será denotado por ex, que é representada.

Baseado na relação existente entre tensões e deformações, pode-se obter a deformação visco-plástica a partir da tensão atuante no embolo, ex, como é mostrado a seguir.
Se a expressão (A67) for combinada à expressão genérica (A68), onde x pode ser até mesmo uma outra função, pode-se obter a relação constitutiva visco-plástica do tipo Perzyna, como é mostrado a seguir na expressão (A69) que é particularmente mais interessante do ponto de vista numérico.

A expressão (A67) ainda pode ser reformulada ao se introduzir uma constante de tempo, chamada de tempo de relaxação, que é dada pela razão entre o coeficiente de viscosidade do embolo e a rigidez do elemento mola.

De maneira análoga ao que foi mostrado no modelo elasto-plástico, procede-se à elaboração de um algoritmo incremental iterativo com integração no tempo.

Detalhes sobre o este algoritmo e a sua elaboração podem ser obtidos em SIMO, KENNEDY e GOVINDJEE.

