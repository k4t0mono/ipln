Uma das tarefas mais importantes na área de Engenharia de Petróleo é a caracterização de reservatórios.

Um bom conhecimento das propriedades dos reservatórios é fundamental para confiáveis previsões de produção e para estudos de possíveis técnicas de recuperação.

Uma das ferramenta mais utilizadas na caracterização de reservatórios é o ajuste de histórico de produção onde parâmetros com maior grau de incerteza são variados até que os resultados da simulação numérica de modelos criados sejam semelhantes aos observados.

Devido ao grande consumo de tempo em processos de ajustes manuais, modelos de ajuste automático foram alvos constantes de profissionais da área mas a complexidade do problema e o grande número de variáveis envolvido no processo fizeram com que estes modelos fossem abandonados bom algum tempo.

Entretanto, o rápido avanço na área de computação principalmente na velocidade das máquinas e em técnicas de computação paralela tem possibilitado novas pesquisas na área de automatização de vários passos do processo de ajuste.

Este trabalho mostra que existem várias linhas de pesquisa que podem agrupar técnicas de computação paralela e distribuída com conceitos de sensibilidade, geoestatística e otimização para automatizar vários passos do ajuste sem excessivo aumento do tempo total do processo.

Esta tarefa é acelerada pela paralelização externa de simulações através da utilização do pacote PVM (Parallel Virtual Machine).

Estes mesmos conceitos podem ser estendidos para qualquer outra aplicação que utilize um número grande de simulações e as vantagens da paralelização podem sem muito significativas, inclusive no gerenciamento de simulações em redes de estações de trabalho.

Uma das tarefas mais importantes da área de Engenharia de Petróleo é a previsão de produção de hidrocarbonetos de reservatórios.

Através dessa tarefa é possível, por exemplo, quantificar reservas, avaliar e priorizar projetos de explotação e dimensionar sistemas de produção.

Existem várias maneiras de se fazer previsões de produção e, atualmente, com a evolução dos computadores e programas, a mais utilizada é a simulação numérica de reservatórios.

Devido a complexidade do problema, métodos analíticos de solução não conseguem representar o escoamento de fluidos em meios porosos e soluções numéricas são normalmente utilizadas.

Existem vários modelos de soluções numéricas e isto esta brevemente descrito no Capítulo 3.

Resultados confiáveis advindos da simulação só podem ser obtidos se o modelo escolhido representar bem o processo físico e se houver uma boa caracterização dos reservatórios, isto é, se houver um bom conhecimento das características da rocha onde está contido o petróleo e dos fluidos cujo escoamento deve ser modelado.

Embora existam hoje muitas técnicas para quantificar as propriedades de meios porosos (perfilagem, sísmica, análise PVT, entre outras), a complexidade do problema, o grande número de variáveis envolvidas no processo e a dificuldade e o custo de obtenção de dados impossibilitam que a caracterização dos reservatórios seja feita com o grau de refinamento desejado.

Além disso, mesmo que isso fosse possível, a descrição de reservatórios normalmente deve ser feita numa escala bem maior devido a limitação dos computadores disponíveis.

Mostra um esquema simplificado das escalas envolvidas no processo de caracterização de reservatórios.

Enquanto o escoamento ocorre na escala de poros, o modelo destinado a sua descrição ocorre em escalas muito maiores.

Vários passos intermediários podem fornecer informações em escalas diferentes mas incertezas sempre estarão presentes no processo.

Por estes motivos, os modelos de reservatórios criados a partir de dados provenientes da engenharia de reservatórios e usados em simulações numéricas normalmente não têm o grau de precisão desejado.

Surge então uma das ferramentas mais utilizadas na caracterização de reservatórios, o ajuste de histórico de produção.

Através do ajuste de histórico de produção, as propriedades do reservatório são modificadas até que os resultados obtidos pelos simuladores sejam semelhantes aos medidos no campo.

Depois de ajustadas as produções dos fluidos e a pressão do reservatório, o modelo resultante pode ser usado para dar maior confiabilidade à fase de previsão de produção.

Dependendo da complexidade do problema e do grau de precisão requerido, o ajuste de histórico pode ser muito lento e muitas vezes pode terminar sem que uma resposta adequada seja encontrada.

Em muitos outros casos, existem várias possíveis soluções, dificultando ainda mais o problema.

Por estes motivos, em geral, essa é uma tarefa que demanda vários etapas e muitas simulações, e é fundamental que cada etapa tenha objetivos bem claros e definidos.

Nas décadas de 70 e 80 vários trabalhos foram publicados na tentativa de se construir modelos de ajuste totalmente automático.

Entretanto, nenhum deles foi bem sucedido pois a complexidade do problema tornava o problema inviável para o poder computacional da época e as simplificações necessárias eram de tal ordem que descaracterizavam o processo.

Desta forma, esse tipo de modelo foi abandonado por algum tempo mas, recentemente, com o avanço dos computadores, de técnicas de computação paralela e técnicas de otimização adequadas, estão surgindo trabalhos na linha de ajuste automático mas com objetivos mais modestos e resultados  mais práticos.

É uma linha de trabalho que tem como proposta a automatização de várias etapas do ajuste, tornando o processo mais rápido, menos frustrante e com melhores resultados.

É nessa linha de pesquisa que vários trabalhos de pesquisa que estão sendo desenvolvidos no Departamento de Engenharia de Petróleo se enquadram.

Todos esses trabalhos, tem um ponto em comum que é o grande número de simulações com um grau de independência tal que torna o processo típico para a aplicação de técnicas de computação paralela.

O objetivo principal desse trabalho é então desenvolver uma metodologia de trabalho para automatização de várias etapas do ajuste de histórico para melhor caracterizar reservatórios e obter previsões de produção mais confiáveis no menor tempo possível, utilizando técnicas de computação paralela e distribuída uma melhor utilização dos computadores disponíveis, proporcionando acelerar o processo sem grandes investimentos.

A técnica de paralelização utilizada neste trabalho é denominada paralelização externa pois não modifica o código dos simuladores existentes mas apenas distribui as simulações nas redes disponíveis de maneira adequada para minimizar o tempo total gasto.

Isso tem duas grandes vantagens, pode-se aproveitar os simuladores comerciais que em geral têm melhores desempenhos mas cujos códigos normalmente não estão disponíveis e  o desenvolvimento dos programas é muito mais simples e pode ser feito em tempo muito menor do que se o código de simuladores fosse paralelizado.

Com um código mais simples, pode-se conseguir maior eficiência nos programas e uma continuidade de trabalhos de pesquisa no desenvolvimento de ferramentas que podem ser utilizadas na prática.

O pacote utilizado na paralelização é o PVM (Parallel Virtual Machine) que é usado para criar a máquina paralela virtual composta por estações de trabalho ligadas em rede.

Através de funções do PVM, foi criado o MPS (Módulo de Paralelização de Simuladores) que é a parte central do programa denominado UNIPAR que é o pacote responsável pela automatização de várias etapas do ajuste de histórico de produção.

O MPS é o módulo do programa responsável pela distribuição eficiente das simulações nas redes disponíveis e pode ser utilizado também com outras finalidades como ainda será mostrado nesse trabalho.

O programa UNIPAR é composto atualmente de cinco módulos, Módulo de Interface Gráfica (MIG), responsável pela interface com o usuário.

Módulo de Paralelização de Simuladores (MPS), responsável pela paralelização eficiente da simulações envolvidas nos outros módulos.

Módulo de Análise de Sensibilidade (ASAHP), para escolha dos parâmetros que serão utilizados no ajuste de histórico.

Módulo de Otimização(MOT), para escolha dos valores dos parâmetros que melhor ajustam o histórico de produção ou pressão.

Módulo de Seleção de Imagens (MSI), para escolha de imagens de propriedades que melhor ajustam o histórico de produção ou pressão.

Outros módulos que utilizam simulações e o MPS estão sendo desenvolvidos mas não serão tratados neste trabalho pois ainda não estão disponíveis e por estarem relacionados a assuntos diferentes, embora envolvam também técnicas de otimização e paralelização.

A descrição deste trabalho está dividido em quatro partes principais.

O Capítulo 2 faz uma breve revisão bibliográfica sobre ajuste de histórico e técnicas de paralelização.

Os Capítulos 3 e 4 mostram como serão utilizadas as ferramentas principais deste trabalho.

O Capítulo 5 mostra como estão construídos cada módulo do programa desenvolvido.

Os Capítulos 6 e 7 mostram os resultados obtidos para algumas aplicações.

Por último, o Capítulo 8 mostra algumas conclusões de um trabalho que pode trazer muitos benefícios para a difícil tarefa de caracterização de reservatórios de petróleo.

Este capítulo tem o objetivo de fazer uma rápida revisão bibliográfica sobre os principais assuntos relacionados com este trabalho.

Desta forma, o capítulo está dividido em duas partes, a primeira relacionada a ajuste de histórico de produção e a segunda relacionada a computação paralela e distribuída na área de Engenharia de Petróleo.

A principal condição para um bom ajuste de histórico de produção é a escolha certa do modelo numérico que deve representar o escoamento de fluidos em reservatórios.

As características dos principais modelos utilizados podem ser encontradas nos trabalhos de Aziz e Settari e Mattax e Dalton São vários os trabalhos relativos a ajuste de histórico de produção sendo que a maioria está relacionada a aplicações práticas usando ajustes manuais.

Estes trabalhos não serão citados no presente trabalho.

Apenas os trabalhos relacionados a ajuste automatizado serão comentados.

Modelos de ajuste automático não tiveram muito sucesso na prática devido a complexidade do problema e número de variáveis envolvidas no processo e por este motivo, várias simplificações eram necessárias devido a limitações relativas aos computadores disponíveis.

Somente no início dos anos 90 é que começaram a surgir novos modelos de ajuste automático.

Dentre os principais trabalhos estão os de Thomas, Ouenes e Weiss e Parish.

Estes trabalhos procuram destacar passos do ajuste que podem ser automatizados, em alguns casos usando técnicas de computação paralela.

No Departamento de Engenharia de Petróleo, são vários os trabalhos nesta linha de pesquisa.

Salazar, Vargas trabalham com técnicas de otimização para determinação de valores de parâmetros que otimizam uma função-objetivo que representa a qualidade do ajuste.

Machado procura definir técnicas de análise de sensibilidade para escolha de quais parâmetros serão utilizadas nos trabalhos anteriores.

Schiozer e Souza procuram otimizar a paralelização que é utilizadas em todos os trabalhos anteriores.

Rodrigues trabalha com técnicas de seleção de imagens de propriedades geradas a partir de estudos geoestatísticos.

As principais conclusões de todos estes trabalhos são, ajuste totalmente automático é inviável para casos práticos, é necessário dividir o processo em etapas para poder automatizar e acelerar o processo, a análise de sensibilidade é essencial seja para ajuste manual ou automático.
Como o problema é um problema inverso e são muitos os parâmetros, existem múltiplas soluções e o processo de determinação de valores de parâmetros deve levar isto em consideração, as possíveis soluções devem ser utilizadas na fase de previsão de produção para reproduzir as incertezas na caracterização do reservatório, na busca de soluções, métodos diretos de otimização parecem ser os mais adequados, e computação paralela pode ser utilizada com grandes vantagens em todo o processo.

O computador é uma das principais ferramentas do engenheiro na solução de problemas do dia a dia.

A facilidade de se implementar modelos matemáticos no computador usando uma linguagem de programação de alto nível tem levado os engenheiros a estudar problemas cada vez mais complexos.

Nem sempre se conhece um algoritmo que seja "eficiente" para todas as instâncias de um certo problema.

A "eficiência" de um algoritmo geralmente é medida pelo seu comportamento assintótico relativo ao tamanho do problema (Cormen ).

Alguns algoritmos demandam muito tempo e usam muitos recursos computacionais para chegar em um resultado.

Se um algoritmo melhor não é conhecido ou se o algoritmo é implementado por um programa comercial que foi adquirido, deve-se recorrer a outros métodos para melhorar o desempenho.

Um desses métodos é a computação paralela.

A idéia por trás do paralelismo é dividir a tarefa principal em sub-tarefas que são executadas simultaneamente em processadores diferentes.

Dependendo da granularidade de cada sub-tarefa, a dependência é maior da velocidade de comunicação entre as sub-tarefas.

O paralelismo interno se dá quando o código de um programa é dividido em rotinas capazes de serem executadas simultaneamente em um computador multiprocessado e isso requer uma velocidade de comunicação muito grande para ser eficiente.

O paralelismo externo é obtido distribuindo-se tarefas inteiras (sem modificação do código), por exemplo, simuladores comerciais, em processadores diferentes ligados em rede.

Essas tarefas devem ser independentes para que a execução possa ser simultânea.

O PVM, Parallel Virtual Machine, é um pacote de software distribuído livremente na Internet que permite que um conjunto de estações numa rede seja tratada como uma grande máquina virtual com diversos processadores.

O PVM obtém o paralelismo externo pondo uma camada de software sobre os protocolos padrão de comunicação da rede para gerenciar o envio de processos para suas máquinas.

O PVM é fornecido como um conjunto de funções agrupadas em uma biblioteca para ser "linkada" com códigos fonte gerados na linguagem C/C++ ou FORTRAN.

Uma das maiores vantagens do uso do paralelismo externo em relação a paralelismo interno é seu baixo custo.

A maioria dos institutos de pesquisa já conta com uma rede (possivelmente heterogênea) de computadores de modo que nenhum investimento extra em hardware é necessário.

Além disso, para fazer uso do paralelismo suportado pela máquina é necessário desenvolver programas paralelos ao nível do código, o que pode exigir mais gastos em treinamento dos programadores da rede.

Outra vantagem do paralelismo externo é que programas não paralelos têm um ciclo de desenvolvimento mais curto.

O paralelismo interno, por sua vez, tem como forte aliada a velocidade e eficiência.

Os processadores de um ambiente multiprocessado estão ligados por um barramento interno cuja velocidade de comunicação é da ordem de 10 9 segundos enquanto a velocidade nominal de comunicação numa rede local típica (padrão Ethernet) é da ordem de 10 segundos, ou seja, 100 vezes mais lento que os barramentos locais.
Isto sem contar com o overhead imposto pelo empacotamento e posterior desempacotamento das mensagens trocadas pela rede (para maiores detalhes sobre protocolos de comunicação de redes, é sugerida a leitura de Tanenbaum ).

Por este motivo, o tempo de comunicação é um fator que pode se tornar crítico na paralelização externa se o tempo de processamento numa máquina não for muito maior que o tempo destinado à comunicação entre os processos paralelos.

O programa de ajuste de histórico de produção automatizado vem passando por várias etapas, envolvendo teses de mestrado nos programas de Engenharia de Petróleo e Geoengenharia de Reservatórios cujos resultados são utilizados na programação dos módulos do UNIPAR (Capítulo 5).

O primeiro trabalho nesta linha de pesquisa foi realizado por Salazar que utilizou o PVM para acelerar o processo de busca do valor de uma propriedade do reservatório que minimizava o ajuste de histórico.

A proposta inicial era de variar um parâmetro por vez num processo iterativo até conseguir o ajuste.

A primeira conclusão deste trabalho foi a necessidade de uma análise de sensibilidade para saber quais propriedades variar e em que ordem.

Foi este o tema tratado por Machado que propôs a criação de índices para facilitar a tarefa de escolha de parâmetros.

Estes índices eram usados para medir a sensibilidade da resposta à variação de propriedades, o afastamento entre as curvas simulada e real e a diferença de forma entre estas duas curvas.

Machado também utilizou Vargas para variar duas propriedades simultaneamente e utilizou simulações em paralelo para encontrar diferentes soluções possíveis já que o problema é um problema inverso e, na maioria das vezes, permite múltiplas soluções dependendo da tolerância usada no processo de otimização.

Isto também ocorre pois o ajuste depende também de outras propriedades além das que estão sendo utilizadas no ajuste.

A idéia era de utilizar mais de uma solução na fase de previsão de produção para determinar também o grau de incerteza da solução.

O trabalho de Leitão segue a mesma linha de pesquisa mas com um número maior de parâmetros e uma pesquisa mais completa de métodos de otimização.

O autor mostra que o problema de múltiplas soluções é mais crítico a medida que cresce o número de parâmetros e a complexidade da função-objetivo no processo de ajuste.

Por este motivo, ele sugere que a análise de sensibilidade seja utilizada como critério de escolha de parâmetros, que não sejam utilizados muitos parâmetros ao mesmo tempo e que a função-objetivo não utilize funções muito diferentes.

Além disso, sugere que os parâmetros sejam divididos em categorias com índices de sensibilidade semelhantes.

Uma boa revisão de métodos de otimização que podem ser aplicados a este tipo de problema pode ser encontrada no trabalho de Box, Davies e Swann.

Rodriguesfoi outro usuário do PVM, utilizando simulações em paralelo no processo de escolha de imagens de propriedades do reservatório, geradas à partir de métodos geoestatísticos.

Nestes três últimos trabalhos o módulo MPS (Seção 54) foi utilizado com sucesso na paralelização das simulações.

Todas estas informações são incorporadas aos módulos do UNIPAR e estão mais detalhadas nos capítulos seguintes.

Neste capítulo procura-se  mostrar a importância do ajuste de histórico de produção na caracterização de reservatórios de petróleo, assim como  esclarecer alguns aspectos básicos do processo de ajuste e  ressaltar a necessidade de se criar procedimentos e programas para acelerar o processo, diminuindo o tempo gasto pelas pessoas encarregadas desta tarefa e aumentando a confiabilidade do modelo encontrado para a previsão de produção.

Em todo o processo de caracterização e de ajuste de histórico de produção, é necessário modelar o escoamento dos fluidos em reservatórios.

A complexidade do problema para a grande maioria das aplicações práticas impossibilita a obtenção de modelos analíticos e a solução numérica aparecem como melhor alternativa.

Dentre os possíveis modelos numéricos existentes na literatura, o de diferenças finitas é o mais utilizado na indústria do petróleo.

Neste tipo de modelo, as leis de conservação de massa de componentes, são escritas onde os três termos representam respectivamente  o fluxo do componente através do volume de controle, o fluxo do componente através de poços e  a variação do componente no volume de controle, y é a fração molar do componente "c" na fase "p" (normalmente óleo, água ou gás), v é a velocidade, é a densidade, S é a saturação, e q é a vazão através do poço, todos da fase w "p", e é a porosidade da rocha.

Para o termo velocidade, v, é utilizada a lei de Darcy, que rege o fluxo em meios porosos, onde k é a permeabilidade, kr é a permeabilidade relativa a cada fase, µ é a viscosidade e D é a profundidade.

O reservatório é então dividido em blocos, como mostra para a direção x, a equação de conservação de massa é discretizada e aplicada a cada componente e cada bloco, resultando num sistema de equações que são resolvidas simultaneamente a cada intervalo de tempo até o tempo final necessário.

Exemplo de divisão do reservatório em blocos considerando uma dimensão Às equações finais são incorporadas algumas equações relativas ao equilíbrio entre as fases, de pressão capilar, e para representar saturações e frações molares diminuindo o número de equações que são resolvidas simultaneamente.

Existem várias opções de tipo de solução, número de componentes, número de fases, tratamento de poços, malha, etc.

Os modelos mais utilizados são os chamado "Black-Oil" onde somente três componentes estão presentes (óleo, água e gás), nesse caso, os componentes são agrupados em três pseudo-componentes para diminuir o tamanho do problema já que normalmente o número de componentes é muito grande.

Soluções totalmente ou parcialmente implícitas são normalmente utilizadas e o número de blocos é normalmente limitado a um máximo de dez mil para que o tempo de computação não seja tão grande.

Outras características deste tipo de modelo são, temperatura constante, equilíbrio instantâneo entre as fases, e sem reações químicas.

O modelo "Black-Oil" está sendo utilizado em todos os exemplos e resultados deste trabalho.

Com algumas manipulações matemáticas e algumas substituições de algumas variáveis das equações anteriores por variáveis que são obtidas em laboratórios, o modelo "Black-Oil" pode ser simplificado para a equação, onde R é a solubilidade do componente "c" na fase "p", é a mobilidade da fase, B é o fator volume de formação, e é o potencial da fase "p".

Essas manipulações são feitas pois as novas variáveis são mais fáceis de serem obtidas na prática, sendo então tabeladas e usadas como dados de entrada para o simulador.

É importante utilizar dados corretos para cada tipo de fluidos em cada exemplo estudado.

A discretização dos três termos da equação acima pode ser representada por, termo de acumulação onde Vp é o volume poroso do bloco que será introduzido em todos os termos.

Termo de fluxo. 

Este termo representa o fluxo entre blocos, onde T representa a transmissibilidade entre o bloco e seus vizinhos.

O tratamento deste termo é muito importante no desenvolvimento de simuladores.

Normalmente, são estabelecidas conecções entre blocos que podem trocar massa e este termo representa a facilidade de transferência de massa em cada conecção.

Este termo normalmente é dependente das variáveis primárias, pressão de uma das fases (fP) e saturações (fS) e da geometria da malha (fG).

Termo de fonte, onde "-" significa condições de reservatório e  condições de superfície (ambos por unidade de volume) Para a solução do sistema de equações resultante é normalmente utilizado o processo de iterativo de Newton-Raphson.

Outros modelos, usados com menor freqüência são  os composicionais, onde mais componentes são considerados aumentando o número de equações e o tempo de solução, e  os térmicos, onde a temperatura varia e equações adicionais relativas à transferência de calor são necessárias para modelar o problema.

Embora estes modelos não tenham sido utilizados nos exemplos deste trabalho, pode-se afirmar que os resultados dos processos de otimização, análise de sensibilidade e paralelização são independentes do modelo usado.

Como resultado de todo este processo, é importante estar ciente de que existem erros e incertezas envolvidas no processo, não só na caracterização dos parâmetros quanto no processo numérico utilizado para resolver o sistema.

Problemas relacionados a dispersão numérica, orientação da malha, erros de truncamento, modelos de poços, entre outros, afetam significativamente a solução e mesmo que o reservatório esteja bem caracterizado, a escolha do modelo e suas características pode levar a resultados que não representam bem o escoamento no reservatório.

Isso tudo reforça a necessidade de se ajustar o modelo escolhido aos dados reais observados para poder confiar na resposta obtida.

Ao fazer qualquer ajuste, é importante reconhecer os erros envolvidos para que o objetivo do ajuste seja viável.

Somente com um objetivo bem definido e dentro da realidade de cada estudo é que o ajuste pode ser automatizado.

A previsão de produção de campos de petróleo obtida através da simulação numérica de reservatórios só pode ser feita depois da fase de caracterização, onde são obtidos valores para todas as propriedades de rochas e fluidos.

Devido à complexidade do problema, tais como quantidade de componentes, heterogeneidade do reservatório, diferentes escalas do problema físico e numérico e às limitações encontradas na simulação numérica, descritas no final as seção anterior, o modelo obtido através da caracterização inicial fica sempre muito distante do modelo real.

A mudança de escala de fluxo multifásico do modelo físico para o numérico é um dos principais desafios da Engenharia de Reservatórios.

Diversas técnicas têm sido estudadas para minimizar este problema mas mesmo que esse objetivo seja alcançado, e que seja possível refinar a malha do modelo numérico ao nível desejado, ainda existem incertezas na caracterização das propriedades devido a dificuldade de obtenção de dados.

Deste modo, para se fazer um bom ajuste, as mudanças no modelo inicial são muitas e, na maioria das vezes, as propriedades são bastante alteradas para que o ajuste seja conseguido.

Por envolver muitas mudanças e por passar por vários estágios relativos à qualidade do ajuste, o processo deve ser dividido em etapas, cada uma com um objetivo bem definido.

Embora cada ajuste tenha características próprias e bem definidas, em geral, pode-se escolher uma estratégia comum a todos os problemas num ajuste denominado de ajuste grosseiro e depois dar um grau de precisão maior ao modelo através de um ajuste fino.

Para definir o objetivo de cada etapa, deve-se levar em consideração, primeiramente, as variáveis a serem ajustadas, que em geral são, vazões de produção dos fluidos do campo e dos poços, pressão do reservatório e dos poços e índice de produtividade dos poços.

Embora pressão e vazão estejam diretamente ligadas, a seqüência mais adequada para a maioria dos ajustes é normalmente, ajuste da pressão do campo, ajuste de vazões do campo, ajuste de pressão dos poços, ajuste de vazões dos poços e ajuste do índice de produtividade dos poços.

Na prática, é muito difícil separar os ajustes de vazões e pressões, assim como não se pode separar o ajuste de vazões do campo do ajuste das vazões dos poços mas isso deve ser feito como primeira tentativa para dividir o processo em duas partes principais, um ajuste grosseiro no campo todo e  um ajuste refinado nos poços.

Para seguir esta seqüência, o procedimento mais utilizado pode ser descrito por, dividir o ajuste em etapas, definir bem o objetivo de cada etapa, não variar as propriedades além dos limites de incerteza, iniciar o ajuste modificando as propriedades com maior incerteza e com maior influência na resposta, alterar inicialmente as propriedades que influenciam mais a distribuição de pressão e menos o fluxo relativo de cada fase.
Iniciar com o ajuste de todo o campo, refinar o modelo com propriedades que podem ser alteradas por regiões, trabalhando em poços isoladamente ou em grupos com poucos poços, e por último ajustar os índices de produtividade dos poços.

A automatização de todo o processo de ajuste é muito difícil devido ao grande número de variáveis envolvidas.

As principais características do problema, ie, propriedades da rocha reservatório ou fluidos, que podem ser alteradas durante o ajuste são, propriedades dos blocos, permeabilidade absolutas nas três direções.

Propriedades dos fluidos em condições de superfície, densidades, compressibilidades, viscosidades, etc.

Propriedades dependentes das variáveis primárias (pressão e saturações), permeabilidades relativas, pressões capilares, solubilidades, fator volume de formação, etc.

Propriedades que alteram a transmissibilidade entre blocos, falhas, fraturas, etc.

Propriedades do modelo, número de blocos, tratamento das variáveis, orientação da malha, etc.

Pode-se observar que é quase impossível construir um modelo totalmente automático mas a automatização das principais partes desta tarefa é viável e, em geral, diminui muito o tempo total até um ajuste dentro dos limites de precisão previamente estabelecidos, principalmente se as simulações necessárias forem feitas em paralelo.

As duas tarefas mais importantes possíveis de automatizações são, medir a sensibilidade do ajuste à variação de cada propriedade e  escolhido um número limitado de propriedades, achar o valor destas propriedades que melhor ajustam o histórico de produção.

Estas duas tarefas são definidas para cada etapa do ajuste e por isso, uma ferramenta que facilite e automatize estes passos é fundamental para acelerar o processo.

Com esse objetivo, o primeiro passo deve ser a definição de uma função-objetivo que representa matematicamente a qualidade do ajuste obtido.

Essa função objetivo pode ser, onde F é a função objetivo da etapa em questão, foi são as funções de cada objetivo específico do ajuste e w é o peso (entre 0 e 1) de cada foi.

As foi são sempre comparações entre uma função obtida na simulação e a mesma função real obtida.

Exemplos dessas funções são, entre outras, curva de pressão média, curva de pressão de um poço, vazão de uma das fases, irrupção de uma das fases e vazão acumulada de uma das fases.

Dependendo da característica da foi ela pode ser calculada de várias formas, tais como  diferença simples, como no caso da irrupção de água ou produção acumulada e  somatório das diferenças ao quadrado, ou somatório dos módulos da diferenças, como no caso de curvas de pressão ou produção.

Existem formas mais adequadas, dependendo do objetivo do estudo mas como isso não influencia diretamente os resultados deste trabalho, isso não será apresentado com detalhes.

Com a função-objetivo definida dessa forma, pode-se compor uma F para cada etapa do ajuste.

Como essa função-objetivo mede sempre a diferença entre os resultados simulados e os reais, essa função deve ser minimizada para que o modelo construído seja o mais próximo possível do real.

O próximo passo importante é definir quais propriedades serão alteradas para atingir o objetivo, ou seja, minimizar F.

Como são muitas as propriedades de rochas e fluidos, como as propriedades podem ser curvas ou valores, e como cada propriedade pode ter um valor diferente para cada bloco da malha de simulação, a automatização das tarefas só é possível após definir os parâmetros (denominados daqui para a frente ßi) que serão alterados no processo.

Alguns exemplos de parâmetros podem ser, propriedades de uma região da malha de simulação (de um bloco até toda a malha), propriedades de fluidos, características de curvas (inclinação de curvas, pontos iniciais de curvas, etc) ou características do modelo numérico escolhido.

Dessa forma, definidos parâmetros (ß) e funções-objetivo (F), a automatização passa a ser um problema de otimização, mais especificamente de minimização.

Quanto mais complexa é a função-objetivo (composta por mais foi) e mais parâmetros envolvidos no processo, mais complicada é a tarefa.

A proposta deste trabalho é utilizar um número reduzido de parâmetros e funções-objetivo e realizar a tarefa por partes, conforme sugerido por Vargas e Leitão.

Ao se trabalhar com um número reduzido de ß e fo, deve-se escolher a composição dessas duas variáveis, Parâmetros (ß) Os parâmetros devem ser escolhidos com base no grau de incerteza da propriedade que aquele parâmetro representa e na influência que ele tem em F.

A confiabilidade do valor atribuído a cada parâmetro no modelo inicial é proveniente de vários estudos e, por isso, é importante uma completa integração das pessoas encarregadas do ajuste e as pessoas que caracterizam o reservatório.

A influência de ß em F, muitas vezes, não é bem conhecida mas pode ser obtida através de uma análise de sensibilidade (Seção 33).

É importante estabelecer limites mínimos e máximos para cada parâmetro pois, caso contrário, até valores fisicamente incorretos podem ocorrer em casos mais complexos Função-objetivo (F) A escolha de F depende diretamente do objetivo de cada etapa.

Em geral, a vazão de óleo é utilizada como parâmetro de entrada e os outros parâmetros como funções a serem ajustadas.

É aconselhável que não se ajuste todas as outras funções ao mesmo tempo para problemas complexos.

O uso de funções (foi) muito diferentes para compor F pode agravar o problema de múltiplas soluções (Seção 36).

Desta forma, pode-se definir uma F para pressão, uma para água e uma para gás.

Essa F pode ser para todo o campo, para um poço ou para um grupo de poços.

A análise de sensibilidade é fundamental para a escolha correta dos parâmetros que serão utilizados no ajuste.

Machado fez um estudo de como essa análise deve ser feita e compôs alguns índices que representam as informações importantes neste tipo de análise.

Os parâmetros eram variados até os seus limites de incerteza para determinar, principalmente, sentido de variação ideal, sensibilidade dos parâmetros e influência cruzada dos parâmetros nas funções-objetivo.

Os parâmetros ideais para cada fase do ajuste são os parâmetros com muita influência na função-objetivo escolhida e pouca influência nas outras funções que ainda devem ser analisadas no processo.

Por exemplo, se ß1 e ß2 estão sendo escolhidos para o ajuste de pressão e ambos têm grande influência na resposta, deve-se selecionar o que tem menor influência no ajuste de vazões que ainda vai ser analisado no processo.

No Capítulo 5 estão descritos mais alguns exemplos.

Uma análise de sensibilidade bem feita proporciona a escolha correta dos parâmetros que serão usados em cada etapa do ajuste e isso pode diminuir muito o tempo total de todo o processo.

O problema de otimização no processo de ajuste envolve a minimização de uma ou mais funções-objetivo.

Em ajustes totalmente automáticos, poder-se-ia compor uma F com todas os objetivos (foi) do ajuste através da Equação (3-1), incluindo todos os ß com alta sensibilidade e utilizar um método de otimização para achar a combinação dos parâmetros que melhor ajustam o histórico.

Entretanto, se isso for feito de uma só vez, a função F fica muito complexa e com um número muito grande de mínimos locais e, até o momento, não existe um método robusto o suficiente para encontrar a solução com um número limitado de simulações.

Mesmo que exista um método capaz de encontrar a solução para casos complexos, existem ainda dois problemas envolvidos.

Primeiro que o número de iterações do problema para estes casos pode ser muito grande e como cada iteração necessita de uma simulação, o tempo total do processo pode ser inviável.

Segundo, que como o grau de refinamento dos modelos de simulação não é igual ao grau de refinamento do problema, a solução sempre será aproximada e, na maioria das vezes, existem mais de uma combinação de parâmetros que minimizam a função F dentro do grau de precisão requerido.

Por estes motivos, é mais viável dividir o processo todo de ajuste em etapas, com funções Fi para cada etapa e trabalhar com um número limitado de parâmetros por etapa.

Desta forma, a otimização fica mais fácil e rápida embora possa envolver algumas iterações entre cada etapa.

Mesmo com todos estes cuidados, o problema de múltiplas soluções pode continuar existindo e deve ser levado em consideração na escolha da maneira como o ajuste deve ser realizado (Seção 36).

Os métodos investigados por Vargas estão descritos a seguir.

Como o objetivo deste trabalho é apenas utilizar estes métodos, será fornecida apenas a descrição geral de cada um.

Mais detalhes podem ser obtidos nos trabalhos destes autores.

O Método de Busca por Regiões (MBR), é uma extensão do método das secantes criado por Vargas onde a região de procura das variáveis vai se reduzindo até um limite preestabelecido.

Embora os resultados obtidos tenha sido satisfatórios para determinação de dois parâmetros do reservatório (como no caso do trabalho de Vargas), a extensão deste método para mais variáveis é de difícil implementação e, por este motivo, ele não foi utilizado na busca de métodos mais gerais que sejam eficientes para um número maior de variáveis.

O Método Politopo (ou Polytope), também conhecido como Simplex Modificado é um método de busca direta que inicia o processo de busca com um politopo de "n+1" lados, sendo "n" o número de parâmetros utilizados na otimização.

Por exemplo, pode-se observar os pontos x1, x2, e x3 que compõem a estimativa inicial da solução.

Cada ponto representado é resultado de uma simulação e da comparação do resultado obtido com o observado.

Se nenhum dos pontos representa um ajuste aceitável, o pior ponto, no caso do exemplo x3, é refletido em relação ao centróide dos demais pontos, obtendo o ponto xR.

Dependendo do valor deste ponto refletido, o politopo pode ser, expandido (xE) se a nova solução é melhor que as anteriores indicando que a direção de busca é correta, contraído (xC2) se a direção de busca deve ser corrigida, quando o ponto refletido tem uma solução intermediária, ou contraído (xC1) com mais intensidade se o ponto refletido é pior que os anteriores indicando que existe um vale e o tamanho do politopo deve diminuir.

Exemplo do algoritmo Politopo em duas dimensões.

Na maioria dos casos estudados, este método foi um dos melhores, sendo robusto em todas as situações mas com convergência lenta nas regiões de vale, resultados também observados por Vargas e Leitão.

Este método, proposto inicialmente em 1961, é um novo método direto para minimização de funções n-dimensionais denominado "busca padrão".

A idéia básica é procurar nas direções das de mínimos da função objetivo, iniciando o processo através de uma "pesquisa exploratória" nas vizinhanças de um ponto inicial x0, variando-se um parâmetro por vez, na busca de um novo ponto com menor valor da função objetivo.

Se a função-objetivo for melhor neste sentido, realiza-se nova busca ao longo desta direção, denominada "pesquisa em linha".

Isso é feito até que não mais se encontre melhores valores da função objetivo.

Neste ponto, repete-se uma nova "pesquisa exploratória" e o processo se repete até que um critério de parada seja atingido.

Assim como o Politopo, esse método apresentou bons resultados na maioria dos exemplos testados.

O desempenho deste método é bem semelhante ao Politopo, inclusive com desempenho pior em regiões de vale onde a convergência fica lenta.

Uma das vantagens em relação ao anterior é a maior facilidade de implementação, principalmente no tratamento de fronteiras e na paralelização pois os passos do Politopo são seqüenciais (com exceção do politopo inicial) enquanto que os processos de busca do Hooke e Jeeves pode ser facilmente paralelizado.

Exemplo de otimização através do Método de Rooke e Jeeves (Leitão ).

Os métodos descritos nas seções anteriores são denominados de métodos diretos pois tomam decisões baseadas na determinação direta da função.

Métodos baseados em derivadas foram testados por Leitão mas com resultados, na grande maioria das vezes, inferiores aos obtidos por métodos diretos.

Este fato se deve a grande irregularidade da típica função-objetivo e consequentemente ao grande número de mínimos locais existentes, dificultando a determinação de derivadas.

Os métodos estudados foram o Método dos Gradientes (Steepest Descent) e o Quase-Newton.

Por este motivo, maior ênfase esta sendo dada aos métodos diretos que são utilizados para a determinação dos resultados mostrados no Capítulo 7.

Outros detalhes dos métodos utilizados e outros métodos poderiam ser descritos neste ponto pois há ainda muito a se pesquisar na busca de métodos de otimização eficientes para este tipo de problema, entretanto, isso foge do tema central deste trabalho.

Mais detalhes sobre este assunto pode ser encontrado nos trabalhos que estão sendo desenvolvidos no Departamento de Engenharia de Petróleo como os já mencionados anteriormente.

Métodos de otimização combinados com funções-objetivo complexas e o tipo de problema envolvido num ajuste de histórico (problema inverso ou de determinação de variáveis) podem levar a respostas fisicamente incoerentes.

É importante que a caracterização inicial e a análise de sensibilidade estabeleçam os limites para cada parâmetro do reservatório e estes não devem ser violados.

Os métodos de otimização devem estar preparados para lidar com estes limites.

As soluções mais utilizadas são, refletir o ponto que ultrapassa os limites de volta para dentro da região de interesse ou utilizar uma função penalidade que multiplica a função-objetivo por uma valor grande fazendo com que a minimização desejada só ocorra dentro da região de interesse.

Para problemas muito complexos, principalmente onde as simulações sejam muito lentas, pode-se ter como objetivo a redução dos limites de incerteza dos parâmetros ao invés da completa minimização da função.

O problema de ajuste é na verdade um problema inverso.

A partir de uma resposta conhecida do sistema, deve-se encontrar a combinação de parâmetros que proporciona um resposta simulada semelhante à observada.

Devido ao grande número de parâmetros e à complexidade do problema, há, na grande maioria dos casos, mais de uma solução para o problema.

O número de soluções aceitáveis logicamente depende da tolerância escolhida.

Em alguns casos, até valores fisicamente impossíveis para os parâmetros podem ser combinados com outros parâmetros para obter respostas aceitáveis em termos de função-objetivo.

Quanto menor o tempo de produção dos campos, maior é a possibilidade de aceitar combinações diferentes.

Um exemplo de múltiplas soluções pode ser observado, que mostra a variação da função-objetivo com relação a dois parâmetros para um exemplo do Campo A (descrito no Apêndice A).

A região escura mostra as regiões onde a função-objetivo está dentro da tolerância aceitável para um bom ajuste.

Este exemplo foi obtido para um caso simples, para uma F composta apenas de vazão de água e com apenas dois parâmetros.

Para casos mais complexos, mínimos locais e múltiplas soluções são ainda mais freqüentes.

Pode-se observar que mesmo para um número pequenos de parâmetros (no caso dois), a função-objetivo pode ser irregular, apresentando vários mínimos locais.

Nesse case, a função objetivo representa uma combinação da vazão de água e pressão.

Influência da variação de dois parâmetros na função-objetivo.

Exemplo da irregularidade da função-objetivo para dois parâmetros (dados obtidos de Leitão ).

Algumas regras devem ser utilizadas para minimizar este problema, conseguir o máximo de dados antes de construir o modelo de simulação, estabelecer limites de incerteza para todos os parâmetros, não variar os parâmetros além dos limites de incerteza preestabelecidos (se isso for necessário, refazer toda a análise para o parâmetro em questão) e variar primeiro os parâmetros com menor confiabilidade.

Entretanto, este problema não pode ser evitado e, por isso, a melhor solução obtida nos trabalhos de Vargas foi a de lançar diferentes métodos de solução ou o mesmo método com diferentes características para encontrar as possíveis soluções.

Com mais de uma solução, a pessoa encarregada do ajuste faria uma escolha ou usaria todas na fase de previsão, obtendo ao invés de uma resposta, uma faixa de incerteza para a produção futura do campo.

Outras grandes vantagens deste tipo de procedimento são, que o número de iterações pode variar bastante e algumas tentativas podem ser abandonadas conforme será descrito na próxima seção e  como os processos de busca de múltiplas soluções são totalmente independentes, eles podem ser paralelizados com eficiência.

O número de processos deve ser função do número e características das máquinas disponíveis.

A idéia de lançar vários processos para encontrar várias respostas para o problema para uma posterior análise, mostra mais uma tarefa que pode ser automatizada pelo processo de ajuste.

Se os processos de otimização são lançados em paralelo, eles podem ter comunicação com um gerenciador global que pode encerrar, lançar ou corrigir os processos em percurso.

Abaixo, estão alguns exemplos possíveis, se um mesmo método é inicializado em regiões diferentes e estão convergindo para mínimos locais com valores bem diferentes, o que está num mínimo local maior pode ser encerrado e lançado em outra região, se um método não está convergindo, ele pode ser encerrado e lançado com outras características.
Se um dos parâmetros está dificultando a convergência por influenciar pouco a função-objetivo, formando longos valeso, ele pode ser eliminado do processo, ou diferentes métodos podem ser lançados ao mesmo tempo e alguns podem ser encerrados ao longo do processo dependendo dos seus comportamentos.

Este gerenciador ainda não está totalmente implementado no programa desenvolvido neste trabalho mas deve ser o próximo passo importante do UNIPAR (Capítulo 5).

Um passo intermediário está descrito através do método proposto para a solução do problema.

Baseado em todos os resultados obtidos neste trabalho e por Vargas e Leitão, as conclusões seguintes são importantes para justificar a escolha do método proposto neste trabalho.
A presença de múltiplas soluções aparece na maioria dos casos e o melhor método encontrado para chegar a essas soluções é através de diferentes estimativas iniciais, em muitos casos o caminho percorrido por algumas dessas diferentes soluções acabam ficando muito próximos e simulações com valores dos parâmetros muito próximos são realizadas,
O grau de precisão desejado para os parâmetros não é, na maioria das vezes, muito grande devido às incertezas envolvidas no processo, pelo fato de que a resposta depende de outros parâmetros além dos que estão envolvidos na análise e pelo fato de que a resposta sempre será aproximada visto que o grau de refinamento do modelo numérico não é o mesmo do modelo real.
Os métodos estudados, em geral, apresentam convergência lenta nas proximidades de mínimos locais, o número de simulações requerido para este tipo de problema pode ser muito grande se a tolerância usada no processo for muito pequena, e mesmo os métodos mais robustos podem apresentar problemas de convergência nos casos mais complexos.

Desta forma, uma alternativa proposta neste trabalho, principalmente para os casos mais complexos é transformar o espaço contínuo das variáveis em questão em um espaço discreto, onde a cada parâmetro são atribuídos os valores mínimo e máximo (limites) e o nível de discretização.

O objetivos deste passo são  evitar que simulações com valores dos parâmetros muito parecidos sejam realizadas já que com valores discretos é possível armazenar os valores da função-objetivo já calculadas.
Limitar o número máximo de simulações já que o problema de oscilação em vales, próximo a mínimos locais diminui e  facilitar o trabalho do gerenciador que pode ser substituído por um simples processo de armazenamento de caminhos, se o caminho percorrido por uma solução já foi percorrido por outra, esta solução pode ser encerrada.

Outras vantagens da discretização do espaço de procura é a maior facilidade de paralelização e de lidar com os limites dos parâmetros.

Este tipo de procedimento pode ser adaptado a qualquer um dos métodos de otimização mas ele foi implementado neste trabalho apenas num método semelhante ao de Hooke e Jeeves denominado em alguns lugares de Busca Linear.

Além de ser o mais adequado por necessitar do menor número de modificações, era o que mais poderia se aproveitar do ambiente paralelo no qual este trabalho foi desenvolvido.

Assim, o Método de Busca Linear em espaços discretizados (MBL), proposto como melhor alternativa, principalmente em casos de reservatórios complexos onde as simulações são lentas, tem as seguintes características.
A cada parâmetro são atribuídos valores mínimo, máximo e número de intervalos, com isso pode-se construir a malha representada, o ponto "1" representa a estimativa inicial, um processo de busca é iniciado através de uma pesquisa exploratória representada pelos pontos "2", uma pesquisa direcional, representada pelos pontos "3" é realizada na melhor direção encontrada no passo anterior, no melhor ponto encontrado, realiza-se nova pesquisa exploratória representada pelos pontos "4".

O processo se repete até que um dos critérios de parada sejam satisfeitos.
Diferentes processos de busca são iniciadas em diferentes regiões da malha, o número de estimativas iniciais pode ser automático dependendo do número de máquinas ou pode ser determinado pelo usuário, simulações relativas a buscas direcionais já realizadas por soluções anteriores não são repetidas desde que o valor da função-objetivo seja armazenado, quando um processo de busca encontra um ponto de pesquisa exploratória de outro processo.

Esse processo é encerrado pois percorreria o mesmo caminho do anterior (esse passo substitui o gerenciador).
Os passos relativos às pesquisas exploratória e direcional podem variar com o tamanho da malha, número de máquinas e estágio da otimização que pode ser refinada a medida que a pesquisa exploratória não apresenta nenhuma direção com solução melhor que a obtida.
E o grau de refinamento da busca não pode ser menor que o determinado pela malha, entretanto, o usuário pode iniciar nova busca com refinamento maior em regiões de interesse, as novas buscas podem até eliminar parâmetros que não estejam influenciando muito a função-objetivo.

Método proposto para dois parâmetros.

Um exemplo típico onde o MBL é bem útil, pode ser visualizado onde um parâmetro com pouca influência na resposta é acrescentado na análise.

Além da dificuldade dos mínimos locais, dois problemas ocorrem nos métodos convencionais.

O primeiro é o fato da solução estar na fronteira de um dos parâmetros (caso que ocorre freqüentemente) o que dificulta a solução.

O segundo é o fato de um vale longo que faz com que os métodos fiquem oscilando aumentando muito o número de simulações.

Estes dois problemas são minimizados com a utilização do MBL.

Após vários teste, pôde ser observado que em funções "bem comportadas", os métodos convencionais podem ter um desempenho melhor que o MBL mas para problemas complexos, o MBL apresenta um número de simulações bem menor e um número de sucessos (encontrar a região com o mínimo global) maior.

A grande vantagem do MBL não é convergir mais rápido mas evitar que simulações parecidas sejam realizadas.

Em todos os métodos, todas as soluções convergem rapidamente para o vale onde ficam oscilando até encontrar a solução, como o MBL tem o espaço dos parâmetros é discretizado, simulações parecidas no vale não são realizadas.

Os detalhes da programação do método (MBL) e da utilização desta solução dependem de vários fatores, entre eles, "tamanho" do problema ou tempo de simulação em relação ao tempo disponível, complexidade da função-objetivo, número de parâmetros, possibilidade de execução de simulações em paralelo, e número de máquinas disponíveis e respectivas velocidades relativas.

Por exemplo, o número de processos lançados para busca de múltiplas soluções deve ser maior para funções mais complexas e para um maior número de parâmetros pois em ambos os casos a probabilidade de insucesso cresce.

Entretanto, se poucas forem as máquinas disponíveis as vantagens da paralelização diminuem pois as simulações serão feitas nas mesmas máquinas.

Exemplo de função com "vale" longo dois parâmetros (dados obtidos de Leitão).

Outro exemplo, cada passo do processo deve levar em conta a disponibilidade de paralelização, a busca exploratória pode ser feita de forma diferente para simulações seqüenciais e paralelas.

Se as simulações são seqüenciais, a primeira direção encontrada que diminui a função-objetivo pode ser escolhida para a busca direcional, se existem várias máquinas disponíveis, as quatro simulações podem ser feitas simultaneamente e a busca direcional feita na direção de menor gradiente.

Como o programa está sendo desenvolvido para um problema que pode produzir funções-objetivo bem diferentes, vários testes intermediários são feitos para otimizar o tempo e o número de máquinas utilizado.

De maneira geral, as maiores diferenças estão no número de simulações feitas nas buscas exploratória e direcional.

No primeiro caso, a procura pode acabar depois da primeira direção encontrada que diminui a função-objetivo, ou as simulações podem ser feitas inicialmente para apenas um sentido de variação dos parâmetros e feitas no outro sentido apenas em caso de não obter sucesso no sentido anterior, ou ainda as simulações podem ser feitas em todas as direções para busca do menor gradiente.

No segundo caso, a busca pode acabar assim que um valor da função-objetivo menor for encontrado, ou as simulações podem ser feitas até que a função-objetivo continue diminuindo, ou ainda as simulações podem ser feitas até a fronteira e o menor valor escolhido para a próxima busca exploratória.

Quanto mais máquinas disponíveis e menor o tempo de simulação, mais o procedimento se aproxima dos passos.

Se as simulações são muito lentas e as simulações são feitas em uma máquina apenas, o procedimento se aproxima do passo.

Novas opções de testes podem ser implementadas para garantir uma metodologia robusta e que busca a solução no menor tempo possível.

Por todo o texto apresentado nas seções anteriores, pode-se notar que um modelo de ajuste totalmente automático é um objetivo ainda distante.

Pode-se visualizar um modelo sofisticado capaz de chegar a respostas automaticamente mas a complexidade do problema ainda faz com que uma análise manual, mesmo que a posteriori, seja necessária.

O melhor cenário possível deve ser  para casos pequenos e médios, uma análise apenas para escolha de algumas entre todas as soluções obtidas pelo programa e  para casos grandes uma diminuição nos limites de incerteza dos parâmetros.

Entretanto, deve ficar claro também que vários passos do ajuste de histórico podem ser totalmente automatizados e paralelizados com relativa simplicidade.

As técnicas de computação paralela e distribuída têm muito a contribuir para viabilizar este processo.

Embora haja um aumento no tempo de processamento, o usuário deste tipo de programa tem o benefício de ter o seu tempo livre para pensar em alternativas para o ajuste.

Este capítulo tem o objetivo de mostrar alguns aspectos fundamentais da computação paralela aplicada neste trabalho e do pacote PVM (Parallel Virtual Machine) que foi utilizado para a paralelização das simulações.

Computadores paralelos estão tendo uma importância crescente na execução de algoritmos que exigem computação intensiva.

O mesmo pode ser dito dos sistemas distribuídos que nada mais são que computadores ligados em rede e utilizados como máquinas paralelas virtuais.

A motivação principal para a utilização de sistemas formados por vários processadores é o baixo custo relativo de processadores derivados de microcomputadores ou estações de trabalho quando comparados com os custos de mainframes tradicionais.

As principais dificuldades normalmente residem nas necessidades de hardware de comunicações e de software para a distribuição de tarefas.

Vencer essas dificuldades é essencial para o uso coordenado de multicomputadores como se fossem um computador único de capacidade potenciada.

A idéia de se dividir tarefas de programas por vários processadores é antiga mas só recentemente vem se tornando viável devido ao rápido avanço de hardware e software.

As máquinas evoluiram muito em velocidade e com o aparecimento de máquinas com vários processadores, a velocidade de comunicação vem apresentando uma grande evolução permitindo que estes processadores troquem informações com rapidez, e os programas que possibilitam esta comunicação vêm mostrando grande aumento de eficiência.

Na área de simulação numérica de reservatórios, a maior parte do esforço computacional é dirigido à solução do sistema de equações resultante do agrupamento das leis de conservação de massa dos componentes em cada bloco e em cada intervalo de tempo como descrito no Capítulo 3.

Como o sistema é resolvido um grande número de vezes, grande parte do tempo computacional é usado nessa tarefa.

Por este motivo, as primeiras tentativas de acelerar o processo usando computação paralela foram voltadas para esta área, dividindo a solução do sistema em partes e paralelizando os cálculos.

Entretanto, essa tarefa exige uma eficiência muito grande nos códigos e uma velocidade de comunicação entre os processadores muito alta o que demanda um alto custo de investimento em máquinas paralelas.

Uma outra linha possível e com custos bem mais baixos é utilizar redes existentes de estações de trabalho e dividir o processo em tarefas maiores que não demandam comunicação com tão alta velocidade.

Esse procedimento é chamado de computação distribuída, paralelização externa ou paralelização de dados.

A grande vantagem deste tipo de sistema é o baixo custo.

A grande desvantagem é a menor velocidade de comunicação e portanto uma menor eficiência da paralelização.

Entretanto, isso pode ser compensado por códigos mais simples e eficientes e pelo fato de que em alguns casos, como o deste trabalho, o tempo de cada processo é grande em comparação com o tempo de comunicação.

É nessa linha que a paralelização utilizada neste trabalho está inserida.

Na maioria dos problemas práticos relacionados com simulação de reservatórios, várias simulações são necessárias, em ajuste de histórico, isso é ainda mais evidente.

Uma eficiente distribuição das simulações nas redes disponíveis é de fundamental importância para que automatizações de tarefas sejam eficazes.

Essa distribuição de simulações, sem alterar o código dos simuladores comerciais é denominada, neste trabalho, Paralelização Externa.

Simulação de fluxo em meios porosos tem sido muito usada na caracterização de reservatórios, em estudos de métodos de recuperação de petróleo, na determinação de reservas, e como ferramenta para se decidir as melhores condições de produção e localização de poços.

Os princípios básicos destes simuladores podem ser encontrados em Aziz e Settari e Mattax e Dalton.

O uso de computação paralela na área de simuladores de reservatório tem um potencial muito grande pois a grande maioria das aplicações demanda várias simulações, seja em ajuste de histórico de produção, em processos de otimização, para comparar alternativas de recuperação, etc.

Se por um lado pode-se questionar a paralelização dos códigos de simuladores devido a relação entre os benefícios e custos de desenvolvimento, a utilização de redes de estações para distribuição de simulações mostra um horizonte promissor.

Com um custo de desenvolvimento relativamente baixo, a utilização de rede de estações pode obter um ganho significativo quando o trabalho desenvolvido depende de um grande número de rodadas do simulador, que é exatamente o caso encontrado nas tarefas de ajuste de histórico de produção.

Além disso, este tipo de trabalho pode tirar um maior proveito de redes de estações que hoje já estão disponíveis nas empresas e em parte do tempo ociosas, sem necessidade de grandes investimentos em máquinas paralelas ou em comunicação.

Desta forma, este trabalho visa a formação de uma base de conhecimentos na área e o desenvolvimento de um sistema capaz de auxiliar os engenheiros em tarefas de decisão em que soluções simultâneas e independentes de variações de um mesmo problema possam ser geradas pelo computador.

A aplicação deste tipo de ferramenta pode ser estendida para outros problemas, usando ou não simuladores numéricos de reservatórios mas isso não será tratado neste trabalho.

Na área de computação paralela ou distribuída, dois avanços tecnológicos tornaram esta alternativa mais atraente, o avanço do uso de meios mais rápidos de comunicação como é o caso do sistema FDDI baseado em fibras óticas e  o desenvolvimento de sistemas de software de comunicação permitem utilização de uma rede de computadores heterogêneos como se fosse uma única máquina virtual.

Dentre os pacotes de comunicação disponíveis para a desenvolvimento deste trabalho, foi selecionado o PVM (Parallel Virtual Machine).

Este sistema foi desenvolvido no ORNL (Oak Ridge National Laboratory), a partir de 1989 e permite que uma rede heterogênea de computadores funcione como uma única máquina virtual com processadores e memórias distribuídas.

O PVM compõe-se basicamente de  processos daemon que residem em todos os computadores configurados pelo usuário para formar a máquina paralela virtual e  uma biblioteca de rotinas desenvolvidas para a transferencia de mensagem, lançamento de processos, coordenação de tarefas e detecção de erros.

No presente trabalho está sendo utilizada a Versão-311 do PVM.

As grandes vantagens do PVM são, é um software de domínio público, tem grande aceitação e é utilizado por um grande número de usuários o que possibilita um desenvolvimento mais rápido, é de fácil instalação e utilização, e  pode ser instalado numa rede heterogênea incluindo computadores paralelos convencionais, estações de trabalho, microprocessadores, mainframes.

O PVM é baseado em um sistema de comunicações conhecido como troca de mensagens que é o sistema normalmente usado em máquinas com memória distribuída como é o caso de uma rede de estações, como as utilizadas no presente trabalho.

O conjunto de rotinas disponível para realizar a comunicação e outras tarefas está disponível para as linguagens FORTRAN e C.

Estas duas linguagens passam a poder suportar operações de programação concorrente que são necessárias para a paralelização dos programas.

Outra grande vantagem do PVM é a portabilidade de programas uma vez que as mesmas versões são utilizadas independente do hardware sobre o qual a máquina virtual é construída.

A tradução para as primitivas específicas de cada máquina é feita automaticamente na implantação do próprio PVM e estas operações são transparentes ao programador, do qual só se requer a familiarização com as extensões correspondes das linguagens C ou FORTRAN.

A programação que utiliza as rotinas do PVM pode ser feita através dos modelos Mestre/Escravo ou SPMD.

No primeiro caso, existe um código referente a um programa mestre que pode executar programas escravos em máquinas diferentes e com códigos diferentes.

No segundo caso, existe um único código e a paralelização é feita internamente através de comandos em FORTRAN ou C.

No presente trabalho, o modelo Mestre/Escravo foi utilizado.

Da mesma forma do que ocorre com computadores paralelos convencionais, com o PVM os programas aplicativos devem ser decompostos em subtarefas com um nível de granularidade relativamente grande, ou seja, as subtarefas devem requerer uma quantidade de cálculos relativamente elevada em relação com o esforço gasto nas comunicações entre subtarefas.

No caso deste trabalho, as tarefas paralelizadas são as simulações, que possuem grande granularidade e, por isso, esse é um problema apropriados para este tipo de solução.

Tais aplicativos enxergam o sistema PVM como um recurso de computação paralela geral como se fosse então uma máquina paralela virtual.

As máquinas ligadas em rede formam um conjunto que pode ser variado dinamicamente, dependendo das tarefas a serem realizadas.

Problemas que levem à falha de algum de seus membros podem ser resolvidos com a inclusão de novos membros ou com a distribuição da tarefa não realizada para um membro já existente.

Isto torna o código mais robusto, mais tolerante a falhas.

Analogamente ao que ocorre com os computadores paralelos convencionais, para o usuário, tudo se passa de maneira transparente, sem a necessidade de conhecer os mecanismos do sistema computacional sobre o qual o PVM foi implantado.

Isto facilita a portabilidade, o que é essencial em fases mais avançadas do desenvolvimento de programas, com a migração de programas para outros ambientes e também possibilita a utilização dos programas por usuários não familiarizados com o próprio PVM.

A biblioteca de rotinas do PVM possibilita a comunicação entre processadores, troca de mensagem, ativação e desativação de processos, verificação de anormalidades, inclusão de novos processadores, sincronização, etc.

Na maioria dos algoritmos, essas propriedades são suficientes para um bom desempenho de programas.

Entretanto, no caso das tarefas necessárias para o presente trabalho, as rotinas do PVM não são suficientes para a eficiente distribuição das simulações na rede e, por este motivo, foi desenvolvido um módulo específico para a paralelização de todas as tarefas descritas neste trabalho, o MPS (Módulo de Paralelização de Simuladores).

Este módulo está descrito no próximo capítulo.

Com o objetivo de aplicar todos os resultados da pesquisa realizada neste trabalho, foi criado um programa denominado UNIPAR que contém vários módulos destinados a várias tarefas relacionadas ao processo de ajuste de histórico de produção e da paralelização eficiente das simulações envolvidas em cada passo.

Neste capítulo, procura-se descrever a metodologia do programa e seus módulos.

Dentre as várias tarefas que utilizam a simulação numérica de reservatórios e que podem se beneficiar da computação paralela, a mais evidente é o ajuste de histórico de produção.

Por este motivo, o programa desenvolvido para este trabalho, denominado UNIPAR, tem como objetivo principal automatizar tarefas relacionadas com ajuste de histórico de produção com a finalidade de obter resultados confiáveis no menor tempo possível através de programas robustos e tolerantes a falhas de máquinas e de usuários.

A incorporação de rotinas para outras tarefas no UNIPAR está sendo desenvolvida mas não está incluída no presente trabalho.

Como o programa está sendo implementado para uso de pessoas não diretamente envolvidas com computação paralela, como é o caso da maioria dos usuários de problemas deste tipo, ele deve ser de fácil utilização, eficiente e livre de falhas.

Uma tarefa fundamental é fazer com que o usuário do programa não se preocupe com a maneira com que as tarefas estão sendo realizadas, nem com a parte de paralelização que deve ser feita de modo automático e transparente.

Essa transparência deve ser ainda maior do que a do próprio PVM.

O programa está sendo desenvolvido em módulos que estão sendo implementados por etapas.

Modificações, melhorias e novas opções estão sendo colocadas em versões posteriores, implementadas conforme sugestões dos usuários.

O módulo central do programa é o MPS (Módulo de Paralelização de Simuladores) que é responsável por toda a paralelização, ou seja, pela distribuição das simulações realizadas pelo UNIPAR.

Os outros módulos realizam tarefas específicas que necessitam de várias simulações e utilizam o MPS para lançar essas simulações na rede.

Os outros módulos descritos neste trabalho são o Módulo de Interface Gráfica (MIG), o Módulo de Análise de Sensibilidade (ASAHP), o Módulo de Otimização (MOT) e o Módulo de Seleção de Imagens (MSI).

A seguir, serão dados alguns detalhes de cada módulo desenvolvido neste trabalho.

Módulos do UNIPAR.

Paralelização do módulos do UNIPAR.

Toda a base da distribuição de processos está baseada nas velocidades relativas das máquinas, número de processos lançados e número de processos restantes.

Outros fatores podem ser levados em consideração como será mostrado posteriormente.

Por este motivo, foi desenvolvido um programa de instalação e configuração capaz de calcular velocidades relativas das máquinas e construir a base para as decisões do MPS.

Este programa de instalação e configuração do UNIPAR é feito também para facilitar a utilização por parte dos usuários e para minimizar problemas de mudança de configuração do programa.

As principais tarefas deste programa são, instalar os módulos desejados, coletar as informações sobre a rede, informar os locais onde estão os executáveis dos simuladores, calcular as velocidades relativas das máquinas, obter informações sobre o histórico de carga das máquinas, e informar os horários disponíveis para cada máquina.

Estas informações são utilizadas pelo MPS para uma eficiente distribuição de tarefas e devem ser atualizadas após mudanças significativas nas máquinas que formam a máquina paralela virtual.

Uma das tarefas mais importantes do sucesso de um programa como o deste trabalho é desenvolver um produto eficiente e de fácil utilização.

A idéia do desenvolvimento de uma interface gráfica tem o objetivo de facilitar a interação entre o usuário e o programa.

A interface UNIPAR está sendo desenvolvida através do pacote TCL/TK que possibilita a criação de programas com interfaces gráficas mas a sua implementação não será discutida neste trabalho por não estar diretamente relacionada com ajuste de histórico de produção e nem com computação paralela.

Mais detalhes deste módulo podem ser encontrados no trabalho de Pollak ou nos manuais do UNIPAR.

O esquema é semelhante ao utilizados pelos simuladores numéricos de reservatórios, o que facilita a utilização por parte de pessoas que já utilizam estes programas, que devem ser também os principais usuários do UNIPAR.

A primeira e mais imediata utilização do UNIPAR, é o módulo que possibilita a execução de simulações em paralelo numa rede de estações.

O MPS foi desenvolvido com o objetivo de gerenciar eficientemente um grande número de simulações de reservatórios de petróleo gerado, principalmente, por problemas de ajuste de histórico de produção e ligados a processos de otimização.

Estes problemas geram procedimentos com importantes propriedades, muitas simulações e com certo grau de independência entre si, cada simulação leva muito mais tempo que o tempo de comunicação entre os processos, e  as simulações têm tempo de execução semelhantes.

O MPS usa um simulador comercial (atualmente com suporte para IMEX, STARS, GEM, ECLIPSE, SIMBEST) para fazer as simulações e é modelado conforme mostrado no esquema.

Modelo de execução do MPS.

O MPS roda a partir de uma das estações da rede (que pode ser heterogênea) e possui uma fila de processos que devem ser distribuídos para as diversas estações da rede.

Ao final da simulação de cada processo, a entrada correspondente da fila de execução é removida.

O processo como um todo termina quando a fila de processos estiver vazia.

Cada entrada na fila de processos corresponde a um arquivo de entrada para o simulador a ser utilizado.

Pode-se observar que o MPS é genérico o suficiente para ser usado com qualquer aplicação cuja entrada de dados seja feita através de um arquivo.

O gerenciamento eficiente desta tarefa é importante pois são várias as combinações possíveis a serem testadas, ie, tempo relativos das simulações, número de máquinas, velocidade relativa das máquinas, memória das máquinas, carga das máquinas, número de processos, número de usuários executando o MPS, e velocidade de comunicação.

Outras considerações podem ser importantes em certas situações, por exemplo, enviar um novo processo para uma máquina lenta que esteja livre pode ser mais demorado que aguardar uma máquina mais rápida desocupar e enviar o processo para esta máquina.

Alguns simuladores possuem um número limitado de licenças, não permitindo que novas instâncias sejam criadas uma vez que este limite é atingido (o programa deve ser capaz de recuperar-se de situações deste tipo).

Outra situação importante ocorre quando uma das máquinas da rede que estava rodando processos de simulação falhe provocando a perda de processos (algum mecanismo deve ser idealizado para detectar e corrigir este tipo de erro).

Uma estação da máquina virtual pode estar tão carregada com processos externos ao MPS que as tentativas de mandar processos de simulação para a máquina falhem por falta de memória (esta situação de erro também deve ser detectada e corrigida).

Todas estas considerações são previstas pelo MPS.

Para os processos do UNIPAR, o procedimento de envio de simulações para a rede assume que os processos têm aproximadamente o mesmo tamanho.

Isso normalmente acontece em todos os módulos com a possível exceção da chamada direta do MPS onde o usuário escolhe os arquivos de entrada que podem ter tempos de execução diferentes.

Entretanto, o MPS está evoluindo para gerenciar todas as simulações da rede e isso torna o problema mais complexo (Seção 5 4 3) Como característica deste tipo de paralelização, o tempo de comunicação entre processos pode ser considerada desprezível em relação ao tempo de simulação.

Isso foi observado para todos os processos simulados, mesmo os que demoravam poucos segundos e na rede de comunicação mais lenta.

Por isso, esses tempos não entram no procedimento de determinação da máquina para a qual será enviada cada simulação pelo MPS.

As combinações restantes são levadas em consideração pelo MPS que automaticamente escolhe a máquina para cada processo de acordo com o número de processos já rodando em cada máquina, número de processos restantes, velocidades relativas das máquinas e memória disponível.

Nas análises a seguir, o termo tempo de execução serial refere-se ao necessário para simular um conjunto de arquivos de entrada padrão para o simulador utilizado de maneira estritamente serial.

O tempo de execução medido é o tempo total de execução (wall clock time) ao invés do tempo de CPU uma vez que o tempo total de execução é o tempo que um usuário tem que esperar depois de disparar uma instância (simulação) do MPS.

Cada estação presente na rede que faz parte da máquina virtual utilizada pelo MPS é denominada host.

O conceito de velocidades relativas entre hosts foi introduzido para auxiliar a decisão sobre para qual host um processo na fila de execução deve ser enviado.

A velocidade relativa é um valor que pode variar de 0 a 1 e é fixado em 1 para o host mais rápido da máquina virtual.

As demais velocidades relativas são uma fração da velocidade do host mais rápido.

Como normalmente uma estação pode rodar mais de uma simulação por vez, a definição de velocidade relativa foi estendida para ser aplicada a um número arbitrário de simulações em um host.

Suponha que o host mais rápido leva S segundos para processar uma simulação padrão e S segundos para processar duas simulações padrão.

Suponha também que um outro host leve, respectivamente, T e T segundos para rodar uma e duas simulações padrão.

Assim, a velocidade relativa de duas simulações padrão neste último host é dado, ou seja, as velocidades relativas estendidas são calculadas comparando-se o tempo obtido com o tempo serial da própria máquina e em seguida com o tempo serial da máquina mais rápida.

Cada instância de simulação que um host pode executar é chamada de célula de execução, ou simplesmente célula.

Antes de poder ser usado numa rede o MPS precisa ser configurado pelo programa de instalação.

Este programa calcula velocidades relativas para as células das máquinas da rede que farão parte da máquina virtual do MPS, conforme a fórmula mostrada na Equação.

O MPS fixa um número máximo para o número de células de um host para permitir a "reserva" de parte da capacidade de processamento da rede para programas externos ao MPS.

Todos esses dados, e mais alguns, são armazenados num arquivo de configuração que é lido pelo MPS a cada nova execução.

É importante citar que se um host possui mais que uma instância do simulador rodando num dado instante (cada instância correspondendo a uma célula de execução), essas instâncias serão processos concorrentes na CPU do host de modo que a ordem de execução dos processos está condicionada ao algoritmo de escalonamento interno do sistema operacional do host e não é mais controlada pelo MPS.

Como o MPS baseia-se em uma matriz de velocidades relativas, um histórico relativo a carga das máquinas, reserva de máquinas em horários determinados ou até mesmo permissão para diferentes categorias de usuários podem ser levados em consideração através de multiplicadores que alteram as velocidades relativas das máquinas mas isto não está sendo discutido no presente trabalho pois depende da administração de cada rede onde o MPS está sendo instalado.

Durante sua inicialização o MPS lê o arquivo de configuração mencionado no item anterior e um arquivo de entrada gerado pelo usuário (um usuário comum ou um programa que faça uso do MPS).

Este arquivo de entrada contém as seguintes informações, quais máquinas farão parte da máquina virtual do MPS, qual simulador deve ser utilizado (o MPS dá suporte a mais de um simulador), quais são os arquivos de entrada para o simulador escolhido e  o valor do time-out do MPS (que será explicado adiante).

Cada um dos processos é então colocado na fila de execução e o processo de simulação passa a seguir o algoritmo descrito no fluxograma da Figura 5-4 que mostra que o MPS lança processos para células de execução desalocadas enquanto isto for vantajoso.

Esta decisão é baseada no número de processos restantes na fila de execução e nas velocidades relativas das células livres (desalocadas).

Suponha que em um dado instante existem n processos na fila de execução.

A expressão é avaliada, onde V é a maior velocidade relativa disponível na máquina virtual e V é a maior velocidade relativa entre as células desalocadas.

Se a expressão acima for verdadeira, isto significa que mesmo que os n-1 processos restantes fossem enviados seqüencialmente para a célula mais rápida na máquina virtual, isto levaria mais tempo que a simulação do processo na célula em questão.

Neste caso, há vantagem em enviar o processo para esta célula, caso contrário, é melhor esperar uma célula mais rápida desocupar e então enviar o processo para esta célula.

O algoritmo mostrado no fluxograma acima está simplificado e não inclui diversas verificações de integridade da máquina virtual que pode estar comprometida por erros provocados por instabilidade nos hosts ou na própria rede de comunicação.

Estes erros precisam ser detectados e alguma ação deve ser tomada no sentido de contornar o problema.

Para detectar corretamente todos os erros que podem ocorrer numa simulação, é necessário ter uma descrição detalhada de todos os códigos de erro dos simuladores suportados.

Sem esta informação torna-se necessário projetar uma rotina padrão para tratar erros.

O MPS adota as seguintes ações para lidar com os erros a seguir, falta de memória no host, a célula em questão é marcada como inutilizável, erro ao lançar um processo para um host, todas as células do host são marcadas como inutilizáveis (o que efetivamente remove o host da máquina virtual), nenhuma licença disponível, a célula corrente é marcada como inutilizável.

Para códigos de erro desconhecidos, o procedimento padrão é remover a célula correspondente, se um host está num estado no qual nenhum processo pode ser iniciado com sucesso, este método eventualmente marcará todas as suas células como inutilizáveis.

O erro mais crítico que pode ocorrer em uma execução do MPS é a perda de processos devido a uma falha em um dos hosts da máquina virtual.

O gerenciamento de processos do MPS é baseado na troca de mensagens entre ele e seus processos filhos.

Se um host, rodando processos do MPS, falha e perde seus processos, o MPS não receberá informações sobre esses processos filhos e assumirá que eles ainda não acabaram.

Um mecanismo de time-out foi instituído para evitar o chamado deadlock que provoca o travamento do programa neste caso.

É importante que o tempo de time-out seja configurado para pelo menos o dobro do tempo de execução do pior caso de simulação para garantir que o MPS não vai encerrar sua execução sem que haja necessidade para tal.

O MPS como descrito até agora, gerencia as simulações dos usuários independentemente dos processos lançados na rede, com exceção do caso de multiplicação das velocidades relativas por uma fator de carga das máquinas.

Entretanto, o mesmo conceito de lançamento das simulações pode ser utilizado para gerenciar todas as simulações lançadas por todos os usuários do MPS.

A maneira mais simples de se fazer isso é através de um arquivo comum a todos os processos que serviria como um contador de simulações na fila e em processamento.

Isso pôde ser feito com facilidade mas o fato de que simulações relativas a usuários diferentes tem tempo de computação muito diferentes, adicionado ao fato de que cada rede pode ter um critério de prioridades diferentes para os usuários ou estudos em questão fizeram com que uma solução mais sofisticada fosse criada.

Este é o próximo passo importante do UNIPAR.

A nova versão do MPS, que se encontra na fase de projeto pretende suprir deficiências encontradas nas versões anteriores.

Entre elas podemos citar, cada instância do MPS rodando na rede não leva em consideração que outras instâncias podem estar rodando de modo que a escolha das melhores máquinas pode ser sub-ótima, não existe um mecanismo de prioridade embutido no algoritmo do MPS, todas as máquinas e usuários tem igual acesso à máquina virtual do MPS.

A idéia é centralizar todas as decisões relativas à escolha de máquinas e avaliação de prioridades num processo servidor que ficará rodando constantemente como um daemon do UNIX, como o sendmail, por exemplo.

Detalhes de conexão e desconexão estão descritos abaixo, 1 O programa MPS mestre possui simulações a fazer e estabelece uma conexão com o servidor MPS.

Após conseguir conexão o programa mestre submete as simulações pendentes para análise pelo servidor MPS.

As simulações são analisadas conforme número de simulações requeridas, prioridades de acesso aos recursos disponíveis dado que se conhece a origem do pedido e horário em que o pedido é feito.

É enviado ao processo mestre o resultado do pedido, listas de simulações aceitas e as respectivas estações destino e a lista das simulações negadas (estas deverão ser submetidas mais tarde).

A conexão com o servidor é encerrada neste momento.

O programa mestre efetivamente envia as simulações para as máquinas determinadas pelo servidor.

Ao término das simulações uma nova conexão é estabelecida com o servidor.

O programa mestre informa o servidor da liberação dos recursos.

O servidor marca os recursos em questão como livres.

O servidor confirma a liberação dos recursos para o programa mestre e encerra a conexão.

O programa mestre verifica se ainda existem simulações pendentes.

Se existem simulações pendentes, o processo descrito é repetido, caso contrário o programa mestre encerra sua execução.

Esta nova arquitetura do módulo MPS permite que diversas instâncias do MPS compartilhem de uma mesma visão da rede além de permitir mudar a política de utilização das máquinas da rede de maneira dinâmica, sem interromper processos já em simulação bastando para isso modificar os arquivos de configuração do servidor e enviando um sinal ao processo servidor informando-o da mudança, neste ponto o processo releria seus arquivos de configuração.

Outro comentário importante é que numa rede onde simulações sejam as principais tarefas, se todos os usuários só puderem lançar as simulações através do MPS, esse gerenciador poderia garantir maior eficiência das simulações na rede e os usuários poderiam ficar livres do processo de escolha da melhor máquina que seria feita automaticamente pelo programa.

O Módulo ASAHP é responsável pela análise de sensibilidade dos parâmetros que representam propriedades do reservatório ou dos fluidos.

Esta etapa é muito importante para selecionar os parâmetros que serão utilizados no ajuste, seja este manual ou automático.

Embora a análise de sensibilidade seja útil em todos os casos, ela é particularmente importante em dois casos, quando há muitas incertezas na caracterização, em especial em campos no início de produção e  em reservatórios muito complexos onde os efeitos da variação dos parâmetros não podem ser determinados sem que sejam feitas simulações.

Os principais objetivos deste tipo de análise são, medir a sensibilidade do ajuste à variação de parâmetros, determinar sentido de variação de cada parâmetro, determinar quais parâmetros e em que ordem serão utilizados para cada tipo de ajuste, e fornecer informações quanto a diferença do formato das curvas simuladas e reais.

Estas informações são fundamentais para o ajuste, seja ele manual ou automático.

Leitão mostra a importância de análise de sensibilidade no processo de escolha dos parâmetros que serão utilizados num processo de otimização utilizado no ajuste automatizado.

O autor afirma que é importante ter as informações acima para evitar um baixo rendimento dos métodos de otimização.

Para a automatização da análise de sensibilidade deve-se criar um modelo inicial de reservatório para que se possa medir variações, sensibilidades e alterações nas respostas.

Este modelo inicial será denominado Modelo Base a partir deste ponto.

Os modelos obtidos a partir de variações nos parâmetros são denominados Modelos Simulados e ainda serão utilizados os resultados reais do modelo que se quer obter, ou do Modelo Real.

Algumas informações são obtidas pela comparação entre os modelos simulados e o real e outras entre os modelos simulados e o base.

Outro passo para a automatização desta análise é a definição de um função-objetivo para medir matematicamente as variações nas respostas.

Esta função pode ser do mesmo tipo da função da Equação (3-1).

Machado criou alguns índices para facilitar a análise.

Estes índices são, Índice de Sensibilidade (IS) que mede a variação dos Modelos Simulados em relação ao Modelo Base.
Índice de Afastamento (IA) que mede a variação dos Modelos Simulados em relação ao Modelo Real.

Índice de Forma (IF) que mede a diferença de forma entre os Modelos Simulados e o Modelo Base.

Para o IS as foi da Equação, onde foS, foB, e foR são as funções dos modelos simulados, real e base que dependendo do objetivo do ajuste, podem ser todas as funções descritas no Capítulo 3.

A automatização destas tarefas passa pelas etapas descritas.

O processamento necessário antes e depois das simulações é feito através de manipulação de arquivos de entrada e saída do simulador.

As simulações são controladas pelo MPS.

O cálculo dos índices é feito através de cálculos das funções-objetivo.

É muito importante, já que as tarefas estão sendo automatizadas, que o programa verifique a condição das simulações antes de fazer o cálculo de índices para evitar problemas como, por exemplo, simulação terminando antes do tempo determinado.

Etapas da Análise de Sensibilidade (ASAHP).

Machado também ressaltou a importância da fácil visualização dos resultados e criou um modo de visualização gráfica que foi incorporado ao UNIPAR e está sendo utilizado neste trabalho (Seção 7 2 1).

O módulo MOT é responsável por encontrar os valores dos parâmetros que mais aproximam os resultados das simulações dos resultados observados, isto é, que minimizam a função-objetivo.

O esquema de cada etapa da otimização é semelhante ao do módulo anterior com a diferença de que para este caso, o processo é iterativo e retorna ao pré-processamento caso convergência não seja atingida.

A convergência é atingida se uma entre as condições for satisfeita, ou seja, se a função objetivo for pequena suficiente, ou se a variação dos parâmetros ou da função-objetivo não estiver mudando significativamente de um passo para outro.

As funções devem ser adimensionalizadas (dividindo por F0 e ß0) para maior controle e padronização das funções.

Logicamente, se o processo pára pelo primeiro critério, a função-objetivo foi alcançada e o ajuste está dentro do esperado.

Os outros dois critérios são utilizados para evitar problemas com processos que não estejam com comportamento adequado, seja porque os parâmetros não esteja evoluindo, seja porque a função-objetivo não esteja evoluindo.

Esses critérios devem ser cuidadosamente escolhidos pois Leitão mostra, em seus exemplos que, em alguns casos, determinadas soluções atingem os dois últimos critérios mas com poucas iterações adicionais ele chegam ao objetivo desejado.

Um número máximo de iterações, ou simulações, deve ser também estipulado pois embora os métodos escolhidos sejam robustos, a função-objetivo pode ser muito mal comportada em alguns casos.

Número máximo de iterações e tolerâncias (1, 2 e 3) podem ser manipulados dependendo do objetivo do ajuste.

O mesmo vale para a tarefa a ser realizada quando um processo é encerrado.

Pode-se finalizar toda a otimização, lançar novos processos, mudar algumas características do processo em questão ou até mudar de método de otimização dependendo do comportamento da função.

A tarefa do gerenciador descrito na Seção 37 é exatamente a automatização desse controle.

Na etapa de caracterização de reservatórios, uma técnica bastante utilizada atualmente é a Geoestatística.

Não é objetivo deste trabalho descrever os detalhes desta técnica mas, em resumo, como resultado da aplicação desta técnica, o usuário tem a descrição de propriedades do reservatório através de imagens com igual probabilidade de ocorrência.

Estas imagens são obtidas através de um conjunto de informações de várias fontes e técnicas para dar o valor da propriedade para cada posição do reservatório.

Dependendo da escala utilizada, pode ser necessário um processo de transferência de escala para dar o valor da propriedade para cada bloco usado na simulação.

Com isso, o usuário tem, na fase de simulação, um conjunto de imagens de algumas propriedades e deve selecionar uma ou mais para a fase de previsão.

Este módulo tem como objetivo escolher uma ou mais imagens que serão utilizadas na fase de previsão de produção.

Da mesma forma que nos módulos anteriores, essa seleção é feita com base em uma função-objetivo, e pode ser feita de uma só vez ou em etapas, dependendo das características do problema.

A seleção por etapas pode ser útil quando características importantes do problema acontecem antes do tempo total de simulação.

Quando isso acontece, a simulação pode ser feita em etapas para eliminar parte das imagens sem que as simulações sejam feitas até o fim.

Por exemplo, quando a irrupção de água ocorre bem antes do final da simulação, a melhor alternativa pode ser seguir os seguintes passos, simular todas as imagens até um tempo ligeiramente maior que o tempo onde ocorre a irrupção de água.
Eliminar as imagens com erros maiores que uma tolerância especificada, simular até o tempo final, eliminar as imagens cujas distâncias entre curvas de produção e produção acumulada simuladas e reais acima de uma tolerância e simular a fase de extrapolação medindo a variação na produção acumulada.

O processo todo envolve 3 fases onde o PVM é muito útil para diminuir o tempo requerido até a escolha das melhores imagens.

Atualmente, as escolhas da função-objetivo e tempo de simulação são feitas diretamente pelo usuário mas numa versão posterior isso pode ser feito automaticamente pelo programa.

Rodrigues utilizou o MPS no processo e relatou grandes vantagens na parte de simulação de fluxo.

Nesse processo, muitas imagens são geradas e o ajuste pode ser utilizado para escolher as melhores imagens e diminuir as incertezas na caracterização do reservatório.

A função-objetivo, para se medir a qualidade do ajuste, foi construída através dos seguintes fatores (foi), para o caso do ajuste de produção de água, irrupção de água (breakthrough), somatório do módulo da distância e produção acumulada Outros módulos estão sendo desenvolvidos no programa UNIPAR mas não estão descritos neste trabalho ou por estarem em estágios iniciais de desenvolvimento ou por não tratarem diretamente do assunto do trabalho.

Neste capítulo procura-se descrever alguns aspectos de algumas das aplicações do trabalho de pesquisa realizado.

Os testes realizados neste trabalho envolvem dois casos de ajuste de histórico de produção e algumas combinações de redes.

O Campo A é um caso simples usado para validação dos testes e o Campo B, um reservatório real.

As diferentes redes foram utilizadas para testar a eficiência da paralelização para diferentes arquiteturas.

O campos e redes foram utilizados para, validar os módulos, medir vantagens da paralelização, executar análises de sensibilidade, utilizar métodos de otimização para escolha do valor de parâmetros que melhor ajustam a produção e selecionar imagens de propriedades geradas a partir de técnicas geoestatísticas.
Ajuste de Histórico de Produção Campo A.
Para alguns exemplos e com a finalidade de validação de testes, o ajuste foi feito em um modelo de reservatório com resposta conhecida que é um exemplo da SPE (SPE First Comparative Solution Problem ).

É um exemplo com dois poços, um produtor e um injetor, com três camadas, 300 blocos e relativamente homogêneo.

A solução original foi utilizada como histórico, ou resultados reais e, então alguns dados forma suprimidos para que o programa pudesse realizar o ajuste.

Os resultados estão no próximo capítulo.

Para as diversas aplicações do programa UNIPAR, foi utilizado um campo real de petróleo cujo nome e características principais não serão divulgados por motivo de segurança, conforme exigido pela empresa que forneceu os dados.

Entretanto, alguns dados necessários para o entendimento básico do problema estão relacionados no Apêndice A.

Cinco tipos de rede foram utilizadas para obter os resultados do Capítulo 7.

Foram utilizadas as redes do Departamento de Engenharia de Petróleo (DEP), do Departamento de Geologia do Petróleo (AGP) e uma da Faculdade de Engenharia Elétrica (FEE).

Na rede do DEP, foram utilizadas duas sub-redes e uma combinação das duas.

Uma breve descrição das máquinas existentes em cada rede estão nas tabelas abaixo.

Antes de apresentar os resultados referentes a paralelização, apresentando as vantagens de se fazer as simulações em paralelo, algumas observações são importantes, MPS Os resultados obtidos e mostrados nesta seção são todos obtidos através da utilização do módulo MPS.

Os tempos medidos e comparados nos gráficos de desempenho do programa são tempos reais (wall-clock time) do início ao final do programa, representando o tempo que o usuário deve esperar pela execução total do programa.

Todos os processos desenvolvidos em paralelo devem ser comparados com os tempos reais para a execução das mesmas tarefas seqüencialmente.

O tempo serial é sempre medido na máquina mais rápida da rede.

Embora isso nem sempre seja o adequado, pois as máquinas mais rápidas não estão sempre disponíveis ao usuário, esse tipo de medida mede a pior condição possível para a paralelização e, portanto, o desempenho desta deve ser sempre melhor ou igual ao que será apresentado nos resultados deste trabalho.

Redes, a maioria dos resultados são referentes a medidas de tempo com a rede desocupada.

Em alguns casos, entretanto, os tempos são medidos com a rede sendo utilizada simultaneamente por outros usuários.

Neste caso, os tempos apresentados são resultantes de uma média de várias simulações, visto que as máquinas possuem tempos de execução diferentes de acordo com a carga momentânea de cada máquina.

Como todos os resultados comparam os tempos obtidos através da paralelização com o tempo serial, em geral, a média é muito semelhante Uma das medidas de desempenho da paralelização é o speedup que mede a relação entre os tempos serial e paralelo.

Um speedup próximo do ideal serial obtido se um processo paralelo com n máquinas fosse n vezes mais rápido que o processo serial.

Isto pode não ocorrer na prática devido, tempo de comunicação entre as máquinas (que no caso deste trabalho é muito pequeno comparado com o tempo das simulações), tempo de espera quando máquinas ou processos têm velocidades diferentes, e dependência entre os processos, o que possibilita que o processo serial tire proveito de resultados anteriores calculados em seqüência.

Comportamento típico do Speedup.

Outra maneira de se medir o desempenho da paralelização é através de um gráfico que mede a economia de tempo obtida pela paralelização do processo.

É interessante observar que este parâmetro tem um objetivo diferente do speedup.

A escolha de um ou outro deve estar baseada na disponibilidade da rede uma vez que o speedup dá a utilização mais próxima da ideal para uma melhor utilização da máquinas enquanto que a economia de tempo deve sempre ser uma curva com inclinação negativa mas o número de máquinas ótimo depende da disponibilidade da rede.

Exemplo de economia de tempo obtida através da paralelização.

Após observações nas redes utilizadas, pôde-se chegar a uma fórmula aproximada para o melhor desempenho possível da paralelização de simulações em redes de estações.

Este cálculo é feito assumindo-se que, o tempo de simulação é muito maior que o tempo de comunicação entre os processos, o que no caso deste trabalho é válido mesmo para simulações pequenas e o tempo das simulações é aproximadamente igual para todos os processos envolvidos na paralelização (o que é válido para os módulos do UNIPAR).

Feitas estas observações, pode-se dizer que, para um número grande de processos, a economia máxima de tempo com a utilização da paralelização é dada pela fórmula, onde ts é o tempo de execução da simulação na máquina mais rápida (onde seria executado o processo serial), im é o número de processos executado ao mesmo tempo em cada uma das Nm máquinas incluídas no processo de paralelização, e tmi é o tempo de execução destes im processos.

A fórmula anterior é válida para máquinas cuja eficiência é maior quanto se executa mais de um processo ao mesmo tempo, o que é o caso das máquinas SUN, conforme observado em testes realizados nas máquinas testadas.

Em outras máquinas, como parece é o caso das máquinas HP e IBM testadas, o tempo da execução de N processos simultâneos é aproximadamente N vezes mais lento que o tempo de execução de um processo e, nesse caso, pode-se rodar um processo por vez em cada máquina.

Outra particularidade da fórmula pode ser feita para o caso de uma rede totalmente homogênea, com Nm máquinas de igual velocidade (tm = ts).

Segue a medida da economia máxima de tempo para algumas redes utilizadas no projeto.

Uma das linhas cheias representa a eficiência máxima para redes homogêneas e outra para redes homogêneas com máquinas que podem rodar 3 processos simultâneos em 60% do tempo de 3 processos em seqüência.

Eficiência máxima de cada rede utilizada no projeto em comparação com a ideal.

Pode-se observar o speedup para as redes investigadas.

É interessante notar, por exemplo, que o speedup e a economia de tempo obtida com a paralelização indicam que se as máquinas antigas do DEP entrarem no processo junto com a rede nova, o ganho será muito pequeno.

Speedup para as redes investigadas.

Este capítulo contém os principais resultados obtidos neste trabalho.

Para facilitar a apresentação, os resultados foram divididos em duas partes, separando os resultados do processo de ajuste obtidos através do programa UNIPAR dos resultados da paralelização basicamente obtidos pelo módulo MPS.

São feitos testes para medir as vantagens da paralelização de simulações e são mostrados algumas vantagens do MPS.

Os testes realizados nessa seção, são avaliados através de dois conceitos, o speedup e da economia de tempo real ao se paralelizar o processo.

Embora o speedup seja um conceito mais utilizado em trabalhos relacionados com computação paralela, o segundo conceito parece mais adequado para a análise dos resultados deste trabalho.

A economia de tempo responde melhor à pergunta, dada uma rede de estações, qual é a maneira de se realizar um processo que utiliza várias simulações da forma mais rápida possível?

O speedup pode fornecer um outro tipo de informação que é, quantas máquinas incluir no processo numa rede compartilhada por vários usuários?

O número de máquinas com speedup mais próximo do ideal deve ser escolhido.

As duas informações são importantes mas já que o MPS controla a distribuição das simulações, o usuário não precisa da informação do melhor número de máquinas para cada processo visto que ele pode incluir todas as máquinas e deixar para o MPS decidir se a inclusão de máquinas aumenta a eficiência do processo.

Dessa forma, embora essas informações estejam incluídas nessa seção o UNIPAR foi desenvolvido para que o usuário não se preocupe com isso, deixando para o programa a decisão de distribuição das simulações.

Para mostrar as vantagens de se realizar simulações em paralelo, são mostrados dois testes descritos a seguir.

Este teste foi realizado na rede da FEE, utilizando o Campo A, com a característica de número de processos igual ao número de máquinas.

Isso pode ocorrer quando o programa ou o usuário tem um número grande de simulações a fazer e um número conhecido de máquinas e quer decidir qual o número de processos realizar por vez.

São feitas medidas relativas a uma rede homogênea e numa rede onde com uma das máquinas cerca de 2 vezes mais rápida que as demais.

Tempo economizado com a paralelização de um número de processos igual ao número de máquinas Teste 1.

Deve-se observar que são também feitas algumas medidas em simulações simultâneas numa mesma máquina.

Esse é um aspecto interessante, que pode tornar o processo de distribuição das simulações um pouco mais complicado pois pode ser vantagem mandar várias simulações simultâneas para a mesma máquina ao invés de enviá-las seqüencialmente.

Esse fato ocorreu para estações SUN Sparc20 e SUN Sparc4.

Nas outras máquinas testadas, o tempo de mandar n simulações simultâneas para a mesma máquina era aproximadamente igual ao de enviar as n simulações em seqüência.

O MPS está preparado para ambos os casos.

Pode-se observar que para esse problema, o speedup é muito próximo do ideal.

Entretanto, à medida que o número de máquinas aumenta, o speedup se afasta ligeiramente do ideal visto que as máquinas têm velocidades um pouco diferentes devido às suas cargas momentâneas e o processo como um todo tem como fator limitante a velocidade da mais lenta.

Este seria o tipo de problema ideal para a paralelização mas à medida que as velocidades das máquinas e os tempos das simulações são variáveis, o problema deve fugir desse comportamento ideal.

No caso de redes heterogêneas, pode-se observar que o comportamento se afasta do ideal por dois motivos, o processo serial é feito na máquina mais rápida e  os processos paralelos têm como limitante a máquina mais lenta.

Entretanto, mesmo tendo um comportamento não tão próximo do ideal, numa rede com 8 estações, pôde-se executar a mesma tarefa com apenas 25% do tempo real.

Conclusões Teste 1.

Em redes com grande número de máquinas, onde é possível ter uma máquina para cada processo (ou simulação), o ideal é usar máquinas com velocidades parecidas.

À medida em que cresce o numero de processos relativamente ao número de máquinas, o tempo economizado pela paralelização tende a se aproximar para os dois tipos de rede.

Nessa rede utilizada, não foi observada quase nenhuma influência do tempo de comunicação no tempo total.

Como o tempo das simulações normalmente é muito maior que os utilizados nesse teste, isso deve ser o caso geral.

Este teste foi realizado também na rede da FEE, utilizando o Campo A, com um número variável de processos.

São feitas as mesmas medidas de tempo do Teste 1.

Para uma rede homogênea, mostra a economia de tempo obtida pela paralelização e mostra o speedup.

O comportamento se aproxima, mais uma vez do ideal.

Entretanto, há uma oscilação em torno do comportamento ideal devido à combinação do número de processo e número de máquinas.

O ideal seria ter um número de processos próximo de um múltiplo do número de máquinas.

Tempo economizado Teste 2 rede homogênea.

Pode-se observar que, com 8 máquinas, pode-se economizar 80% do tempo com a utilização do PVM para este caso.

Speedup Teste 2 rede homogênea.

Quando a rede é heterogênea, o comportamento é, em média menos oscilatório e mais afastado do ideal pelos mesmos motivos mencionados no Teste 1.

Mesmo nesses casos, entretanto, pode-se obter um ganho significativo de tempo total, chegando a uma economia de 70% do tempo para 8 máquinas.

Mostra o speedup que um pouco afastado do ideal pois a máquina onde foram executados os testes seriais é muito mais rápida que as demais.

Uma observação importante está relacionada com redes muito heterogêneas.

Uma máquina muito mais lenta que as demais pode prejudicar muito o desempenho total do processo.

Com o MPS, esse problema não ocorre pois a máquina não é adicionada no processo.

Tempo economizado Teste 2 rede heterogênea.

Speedup-Teste 2 rede heterogênea.

Os resultado mostrados são relativos ao comportamento obtido a partir do MPS que é o responsável pela distribuição das simulações nas redes utilizadas e descritas no capítulo anterior.

Os resultados da paralelização dos outros módulos são apresentados na Seção São mostrados nesta seção os resultados da utilização do MPS em 3 redes com características diferentes.

Rede A uma típica rede homogênea que é formada por 8 estações de trabalho de mesma arquitetura com índices de performance semelhantes.

Esta é a rede nova do DEP.

Rede B uma rede heterogênea formada por 5 estações de trabalho de 2 arquiteturas diferentes, uma das estações tem performance muito superior às demais.

Esta é a rede antiga do DEP.

Rede C outra rede heterogênea formada por 14 estações e duas arquiteturas, contém 9 máquinas rápidas e 6 lentas.

Esta é uma combinação de todas as máquinas do DEP.

Mostra as velocidades relativas das estações das 3 redes utilizadas.

As redes foram testadas em horas de baixa carga de modo que outras aplicações não influíssem nos resultados.

Os resultados foram analisados de duas maneiras diferentes, ambas comparando o tempo paralelo total com o tempo serial total.

A primeira análise mostra a economia de tempo obtida ao variar o número de hosts na máquina virtual apresentando o tempo paralelo como uma porcentagem do tempo serial.

A segunda análise, usa o speedup que é uma medida usada para verificar a performance de sistemas paralelos.

A medida de speedup é importante para mostrar a partir de que número de hosts os ganhos com a paralelização ficam menores.

Comparação das velocidades relativas das estações utilizadas.

Mostram os desempenhos obtidos nas redes A, B e C para 16 processos de simulação.

Pode ser observado que redes homogêneas (rede A) são as que mais se beneficiam com este tipo de paralelização e, neste caso, os melhores resultados são obtidos usando-se todas as 8 estações no processo.

Os resultados da rede B (rede heterogênea) mostram uma eficiência menor porque uma das estações é muito mais rápida que as demais fazendo com que o tempo serial (calculado nesta estação) se aproxime do tempo paralelo.

Mesmo assim, consegue-se até 60% de economia de tempo usando a paralelização externa.

A rede C mostra economias de até 80% mas a análise de speedup mostra que os benefícios de acrescentar uma nova máquina no processo ficam cada vez menores à medida que o número de estações cresce.

O MPS leva isso em consideração automaticamente e não envia simulações para as máquinas mais lentas a não ser que o número de processos na fila de execução seja muito grande.

Economia de Tempo Redes A, B e C.

Speedup Redes A, B e C.

Mostram os mesmos dados limitados à rede A (de melhor performance) fixando o número de estações (8) e variando o número de processos de simulação.

Ambas apresentam uma descontinuidade porque todas as estações têm aproximadamente a mesma velocidade relativa e, quando 9 processos são enviados, a eficiência decresce pois um processo tem que aguardar a liberação de uma máquina ou uma das máquinas estará rodando 2 processos simultaneamente.

Esta descontinuidade somente ocorre em redes homogêneas onde as estações apresentam velocidades relativas que seguem (aproximadamente) a regra, onde v indica a n-ésima velocidade relativa e v indica a velocidade relativa de 1 processo (tempo serial) no host.

Todas as estações da Rede A apresentavam este comportamento, apenas 2 máquinas (lentas) da rede C apresentavam resultados melhores para processos simultâneos que para processos seriais na máquina.

Observando-se todos os resultados é possível concluir que a eficiência da paralelização externa varia com o tipo da rede utilizada e com o número de processos enviados, mas em todos os casos grandes benefícios puderam ser obtidos, especialmente aumentando o número de estações.

A melhor eficiência (tempo paralelo dividido pelo tempo serial) que pode ser obtida para uma certa rede pode ser calculada a partir das velocidades relativas e usando a expressão, onde v é a velocidade da estação mais rápida, v é a velocidade da estação i e n é o número total + i w de estações de trabalho.

Pode ser mostrado que a eficiência de um processo paralelo aproxima-se de e à medida que o número de processos de simulação cresce.

A diferença entre os resultados obtidos pelo MPS e a situação ideal ocorre pelos seguintes motivos, o tempo de comunicação entre os processos e  tempo de espera de estações que não estão sendo utilizadas no processo.

Este último é o que o MPS tenta minimizar.

Todas as aplicações que utilizam várias simulações podem ser mais eficientes através da utilização do MPS.

Em alguns casos, como em análise de sensibilidade e seleção de imagens de propriedades dos reservatórios, as vantagens são muito grandes pois todas as rodadas são independentes e a eficiência é a própria do MPS.

Em outros casos, como em algoritmos de otimização, a eficiência pode ser um pouco menor, dependendo do método utilizado mas mesmo nesses casos pode-se obter tempos de execução bem menores e programas mais robustos.

A busca por múltiplas soluções (Leitão ) é outra aplicação que pode se beneficiar bastante da computação paralela e um algoritmo destinado a gerenciar este tipo de problema pode tirar grande proveito do MPS.

Para aplicações que necessitam de simulações seqüenciais, o MPS pode garantir estabilidade e robustez.

Se todas as simulações de uma rede são lançadas a partir do MPS, maior eficiência pode ser obtida para todos os usuários.

Políticas de rede podem definir prioridades que podem ser incorporadas às velocidades relativas que serão utilizadas pelo programa.

O mesmo pode ocorrer com cargas das máquinas, sejam elas momentâneas, acumuladas ou um histórico de utilização.

As velocidades relativas das máquinas podem ser modificadas para levar em consideração estes aspectos.

Nesta seção, estão apresentados alguns resultados dos módulos do UNIPAR exceto os obtidos pelo uso isolado do MPS.

Ao invés de mostrar as vantagens da paralelização para cada aplicação, este trabalho mostrou as vantagens para paralelização direta pelo MPS na seção anterior.

Outras aplicações utilizam este módulo para distribuir as simulações numa determinada rede para  acelerar o processo ou para garantir estabilidade no processo visto que o MPS lança as simulações até que elas sejam completadas.

Em cada módulo, alguns aspectos da paralelização serão brevemente considerados O módulo ASAHP é o responsável pela análise de sensibilidade descrita na Seção 3 3 A importância deste tipo de análise é muito grande para fornecer base para qualquer outro passo do ajuste de histórico.

Como são muitos parâmetros envolvidos, é preciso facilitar o trabalhos através da criação de índices que auxiliem a tomada de decisões e estes índices devem ser de fácil interpretação (Machado e Schiozer ).

Mostram um exemplo de resultados do ASAHP para o Campo B (Apêndice A).

Mostra o comportamento de pressão, o comportamento da vazão de água para o campo.

Pode-se verificar que a análise gráfica não é tão fácil e fica mais difícil conforme cresce o número de parâmetros analisados.

Comportamento da pressão para diferentes variações nos parâmetros (Machado e Schiozer ).

Os Índices de Afastamento, Sensibilidade e Forma são utilizados respectivamente para escolher o sentido de variação do parâmetro, para avaliar a grau de influência de cada parâmetro na resposta (função-objetivo) e para avaliar o grau de proximidade das formas das curvas simulada e real.

Todos os índices são normalizados para variar de 0 a 1, facilitando a interpretação.

As barras para os dois sentidos indicam variações positivas e negativas nos parâmetros e a barra com cor mais escura indica o sentido ideal de variação dos parâmetros.

Pode-se observar que em alguns casos, o sentido ideal de variação é diferente para diferentes ajustes, no caso ajuste de pressão e vazão.

Este tipo de informação é importante para decidir quais variáveis serão utilizadas no ajuste (seja ele manual ou automático) e em que ordem.

Comportamento da vazão de água para diferentes variações nos parâmetros(Machado e Schiozer ).

Índices de afastamento para diferentes variações nos parâmetros (Machado e Schiozer ).

Índices de sensibilidade para diferentes variações nos parâmetros (Machado e Schiozer ).

Índices de forma para diferentes variações nos parâmetros (Machado e Schiozer ).

Machado mostra ainda que quando os limites de variações dos parâmetros são conhecidos, a variação dos parâmetros deve ser feita até estes limites pois assim a análise de sensibilidade incorpora a incerteza dos parâmetros nos índices de sensibilidade.

As vantagens da paralelização para este tipo de problema são as mesmas apresentadas na Seção 71 pois as simulações são totalmente independentes e a parte comum do código, ou seja, o cálculo de índices é muito pequena quando comparada com as simulações.

O módulo de otimização para determinação de valores de parâmetros que minimizam a função-objetivo que representa matematicamente a diferença entre resultados da simulação numérica do modelo construído e resultados observados vem sendo construído em etapas que envolveram os trabalhos de Salazar e Leitão.

Um bom exemplo de solução pode ser observado onde é observado o comportamento da função-objetivo com dez estimativas iniciais no ajuste do Campo A, usando quatro métodos de otimização.

Em relação a este e outros exemplos testados por Leitão, pode-se fazer os seguintes comentários, em geral, os métodos diretos (Politopo e "Hooke e Jeeves") apresentam melhor desempenho em termos de número de simulações necessárias e são mais robustos que os métodos de gradientes, existem várias combinações de parâmetros que resultam em bons ajustes (múltiplas soluções).

O número de iterações, que foi deixado livre em todos os testes, pode ser muito grande e, por isso, além do critério de parada pela tolerância, devem ser utilizados outros critérios, tais como mínima variação dos parâmetros ou da função objetivo e número máximo de iterações.
Caso mais de uma solução exista, elas devem ser utilizadas na previsão para representar o grau de incerteza da resposta obtida, as soluções por critérios de parada diferentes da tolerância devem ser analisados antes de serem utilizados na previsão.

Todos os métodos testados não são muito eficientes nos vales de mínimos locais, um algoritmo "inteligente" capaz de interromper e lançar novas simulações é necessário para gerenciar os diferentes processos, e a paralelização de várias partes do código aceleram muito o processo.

Outro exemplo é o ajuste de histórico obtido por Leitão para um caso real, que é o do Campo B.

Depois de feita a análise de sensibilidade usando o ASAHP para escolha dos parâmetros, o autor fez uma otimização usando os escolhidos.

Lista de parâmetros otimizados para ajuste da produção de água(Leitão ) Com estes resultados, os ajustes do poços que haviam apresentado problemas após a caracterização inicial e pequenas modificações.

A partir deste ponto, a pessoa encarregada do ajuste pode refinar mais a solução usando novos parâmetros, ou os mesmos parâmetros numa região delimitada pelos novos limites de incerteza.

As vantagens da paralelização neste módulo podem ser menores que a encontrada nos outros módulos pois os melhores métodos de otimização não são totalmente independentes, ou seja, cada passo pode depender dos resultados encontrados no passo anterior.

Entretanto, mesmo com métodos seqüenciais o MPS, pode ser utilizados em vários passos, tais como, simulações iniciais do Politopo, cálculo de derivada, em buscas exploratórias e direcionais e, principalmente, na obtenção de múltiplas soluções.

O MPS é muito útil na fase de programação dos métodos de otimização pois maior atenção pode ser dada aos métodos ótimos de busca de solução sem a preocupação com tempo de execução uma vez que toda a distribuição das simulações é feita de maneira eficiente pelo MPS e não pelo MOT.

A escolha do método, assim como os detalhes de cada método dependem do arquitetura de cada rede utilizada.

O Método de Busca Linear, pode ser otimizado para trabalhar em ambiente paralelo com as seguintes modificações.
Dado um problema com Np parâmetros e uma rede com Nm máquinas disponíveis, todas com velocidade relativa semelhante, dado que todas as máquinas estão disponíveis, a busca exploratória começa com os escolhidos os Nm parâmetros com maior sensibilidade, se Nm é maior que Np todos são escolhidos, se Nm é maior que 2 Np.
A busca é feita nos dois sentidos para todos os parâmetros, depois disso a escolha da direção de busca é feita de acordo com os critérios descritos, na busca direcional, são computados quantos pontos (Npts) existem até a fronteira na direção escolhida.

Se Npts é menor que Nm, todos os pontos são simulados.

Se Npts é maior que Nm, são selecionados Nm pontos e escolhido o menor para a próxima busca exploratória.

Se Npts é muito maior que Nm, pode-se refinar a solução antes de iniciar a busca exploratória.

A opção anterior deve ser escolhida quando a obtenção de uma solução com a função-objetivo abaixo da tolerância for suficiente, nesse caso, o programa lançaria novos processos de busca até encontrar uma solução dado um limite de número de simulações.

Outra possibilidade é programar o método com a maior eficiência assumindo o cálculo seqüencial e deixar a paralelização somente na busca de múltiplas soluções.

Dessa forma, cada busca é realizada em uma máquina e o número de buscas pode ser função do número de máquinas.

Esse seria o caso de reservatórios com muitas incertezas onde soluções diferentes podem ser obtidas e o usuário está interessado em saber como o impacto dessas soluções afeta a produção futura do campo.

Para a generalização do MOT, e facilidade de utilização, o usuário entra com, os parâmetros e seus limites, o grau de discretização da solução, o método de otimização desejado, as tolerâncias, o número de máquinas disponíveis, o número de processos de busca desejado e escolhe entre as opções de levar os processos de busca até o fim ou encerrar o processo quando uma solução for encontrada.

No processo de escolha destas opções, é importante levar em consideração o tempo de cada simulação, e a disponibilidade das máquinas escolhidas para que o tempo total do processo não seja muito grande.

É importante também saber que possibilidade de ocorrência de mínimos locais aumenta com a complexidade do problema (e portanto da função-objetivo), com o número de parâmetros e com a discretização dos parâmetros.

Isso aumenta o número de falhas (processos que não atingem a tolerância desejada) sendo portanto necessário lançar mais processos.

Uma boa opção para estes casos e utilizar o MOT em etapas, separando o processo em funções-objetivo, parâmetros ou usando graus de discretização diferentes nas várias etapas do ajuste.

Foram selecionados dois exemplos para ilustrar a utilização do MOT utilizando o Método de Busca Linear com espaço discretizado.

Exemplo1 Com dois parâmetros, permeabilidade, K, com limites 500 e 1500 mD, variando com intervalo de 20 mD e  inclinação da curva de permeabilidade relativa, Krw, com limites de 15 e 35, variando com intervalos de 0 1 A malha fica então composta de 1071 pontos (51 x21).

Nesse caso, a menor função-objetivo é 16 x10 (mínimo global).

Mostra-se os resultados para dez pontos iniciais aleatoriamente distribuídos dentro dos limites.

Observa-se que 7 processos convergiram para a solução correta e 3 convergiram para mínimos locais.

O número total de simulações foi de 126 sendo que se as soluções fossem independentes (sem registros de simulações já realizadas) esse número cresceria para 180.

Este é um exemplo semelhante ao anterior mas com uma diferente função-objetivo.

Os parâmetros são outros, permeabilidade horizontal, Kh, e vertical,Kv, mas a malha fica do mesmo tamanho 1071 pontos (51 x21) e a menor função-objetivo é a mesma.

Devido às características dessa nova função objetivo, isto é, um longo vale e o mínimo global perto da fronteira, os métodos tradicionais têm dificuldades e o número de falhas cresce bastante.

Com o MBL, isso não acontece e o comportamento é semelhante ao anterior.

Mostra-se os resultados para dez pontos iniciais aleatoriamente distribuídos dentro dos limites.

Observa-se que 7 processos convergiram para a solução correta e 3 convergiram para mínimos locais.

O número total de simulações foi um pouco maior que no caso anterior, 140.

Com quatro parâmetros, permeabilidade horizontal, Kh, com limites 500 e 1500 mD, variando com intervalo de 100 mD, inclinação da curva de permeabilidade relativa, Krw, com limites de 15 e 35, variando com intervalos de 025, porosidade, com limites 025 e 035, variando com intervalo de 0025 e  permeabilidade vertical, Kv, com limites 01 e 1 mD, variando com intervalo de 015 mD.

A malha fica então composta de 3465 pontos (11 x9 x5 x7).

Nesse caso, a menor função-objetivo é 16 x10 (mínimo global).

Mostra-se os resultados para dez pontos iniciais aleatoriamente distribuídos dentro dos limites.

Observa-se que apenas 2 processos convergiram para a solução correta, outras 3 convergiram para mínimos locais abaixo da tolerância (5%) e 5 convergiram para mínimos locais fora da tolerância.

O número total de simulações foi de 119 sendo que se as soluções fossem independentes (sem registros de simulações já realizadas) esse número cresceria para 138.

É importante registrar que o MBL utilizado nestes testes foi o mais simples.

É possível sofisticar o método para que ele saia de mínimos locais mas esse não é objetivo pois a idéia é achar esses mínimos locais que serão comparados posteriormente.

Dependendo dos pontos iniciais escolhidos esses números podem ser modificados mas a média é bem próxima da tabela apresentada.

Foram feitos vários testes com diferentes alternativas de passos no MBL mas os resultados eram melhores para alguns casos e piores para outros e na média, nenhuma modificação mostrou-se muito eficaz.

Um ponto importante a ressaltar na comparação entre esses dois exemplos é a verificação do crescimento do número de falhas com o aumento do número de parâmetros.

Em termos de paralelização, os resultados do Exemplo 2 mostram uma economia de cerca de 70% do tempo se esse processo rodar na rede do DEP com 8 máquinas disponíveis e para o caso de rodar os processos seqüencialmente, ou seja, os processo são paralelos internamente nas buscas exploratórias e direcionais mas os processos são iniciados em seqüência.

Técnicas geoestatísticas são capazes de gerar imagens de propriedades dos reservatórios com igual probabilidade de ocorrer.

O ajuste de histórico pode ser utilizado para selecionar aquelas que mais aproximam os resultados das simulações dos dados reais.

Os detalhes deste processo podem ser encontrados no trabalho de Rodrigues O Módulo de Seleção de Imagens é responsável por esta tarefa no UNIPAR.

As vantagens de se usar o MPS para paralelizar as simulações é muito grande neste caso pois os processos são totalmente independentes.

Mostra um exemplo de como a variação de água para o Campo B (Apêndice A) pode variar, a partir de imagens diferentes da permeabilidade.

Em muitos casos, imagens obtidas a partir de valores constantes ou de imagens krigadas não apresentam bons resultados e algumas imagens apresentam resultados bem melhores. 

São mostradas apenas algumas imagens para visualizar a grande variação possível e pode-se observar que algumas reproduzem muito bem os resultados observados.

Várias alternativas são possíveis neste tipo de análise.

Pode-se trabalhar  com objetivos diferentes, por exemplo produção de água ou gás, produção acumulada, pressão ou até uma combinação destas funções, com tempos de simulação diferentes de acordo com informações importantes da análise, podendo fazer a análise por etapas, com regiões diferentes, como o campo todo, algum poço específico ou um grupo de poços, e com parâmetros diferentes.

A análise pode resultar na escolha de uma imagem mas isso não parece ser a alternativa mais correta pois como o ajuste ainda depende de outras variáveis, podem ocorrer inversões nas imagens, como observado por Rodrigues.

Uma melhor alternativa é a escolha de um conjunto de imagens, selecionadas a partir de uma certa tolerância que resultam em uma redução das incertezas na fase de previsão de produção, ou seja, descartando as piores imagens, pode-se ter um grau de confiabilidade e uma incerteza menor no comportamento futuro do campo.

No caso deste módulo, as vantagens da paralelização também são as mesmas apresentadas na Seção 71 pois as simulações também são independentes e a parte comum do código, ou seja, a seleção das imagens consome pouco tempo quando comparada com as simulações.

As principais conclusões do trabalho de pesquisa realizado estão descritas ao longo dos capítulos anteriores e resumidas neste capítulo.

As principais conclusões relativas ao trabalho de pesquisa relacionado com este trabalho são, Ajuste automatizado, existem vários passos do processo de ajuste de histórico de produção que podem ser automatizados.

O grau de automatização e os critérios de parada dos processos que necessitam convergência devem ser escolhidos com cuidado, dependendo do objetivo do estudo e tamanho do problema.

Com o atual nível de desenvolvimento de hardware e software, é possível desenvolver ferramentas muito úteis não só para acelerar como também para dar maior confiabilidade ao processo de ajuste de histórico de produção.

A principal característica deste tipo de problema, que é um problema inverso, ou de determinação de variáveis, é a multiplicidade de respostas aceitáveis, caracterizado por funções-objetivo com mínimos locais e conseqüente difícil solução.

Na determinação de soluções do processo de ajuste, o número de simulações depende do objetivo do estudo e do tamanho do problema em relação ao tempo computacional requerido.

Não foi encontrado um método de otimização com desempenho muito superior aos demais mas em geral, métodos diretos são mais robustos para este tipo de problema.

Para problemas que envolvem simulações com elevado tempo computacional, é aconselhável a discretização dos parâmetros para que o número de simulações não seja muito grande.

A análise de sensibilidade pode apresentar informações muito importantes para iniciar o processo de ajuste.

A principal vantagem é excluir parâmetros com pequena influência na resposta que, em geral, diminuem a eficiência dos métodos de otimização.

A determinação de várias soluções deve ser utilizada para determinar a incerteza na resposta e a computação paralela pode ser utilizada com grandes vantagens neste processo.

Quase a totalidade de passos do processo de ajuste que podem ser automatizados podem tirar benefícios da computação paralela.

Sendo os principais deles, obtenção de múltiplas soluções, análise de sensibilidade, seleção de imagens de propriedades, otimização através de métodos apropriados ou adaptados.

A melhor metodologia foi obtida através da criação de um programa específico para distribuir as simulações na rede estudada, sendo que todas as outras aplicações utilizam este programa (módulo MPS) central.

A eficiência do MPS depende de vários fatores.
Por exemplo, número de máquinas, número de processos, velocidades relativas das máquinas (e heterogeneidade da rede), grau de ocupação das máquinas, tamanho dos processos, o tempo de comunicação é desprezível para a maioria dos casos que utilizam simulações, nesse caso a eficiência da paralelização é função somente do processo em questão (grau de dependência entre as simulações e diferença entre processos) e da arquitetura da rede disponível (características e ocupação das máquinas).

Em processos com poucas simulações onde os processos têm aproximadamente o mesmo tamanho (caso de quase todas as aplicações relacionadas nesse trabalho) a eficiência é maior para redes homogêneas.

Em processos com muitas simulações, a eficiência de redes heterogêneas também pode ser boa.
A eficiência dos outros módulos é função da eficiência do MPS e do grau de dependência das simulações necessárias.

Quanto mais independentes as simulações, maior é a eficiência da aplicação.

Para qualquer processo que envolva várias simulações, este tipo de programa (MPS) pode ser utilizado com grandes vantagens sendo que até mesmo o gerenciamento de todas as simulações de determinadas redes podem ser feitas usando um programa como o descrito neste trabalho.

Com um pouco mais de trabalho, o programa criado pode gerenciar qualquer fila de processos longos de determinadas redes.

Além da vantagem de diminuição de tempo, o MPS fornece ao usuário um nível mais alto de tolerância a falhas detectando e corrigindo erros, além de poder trabalhar com uma interface uniformizada para todos os simuladores.

O MPS também pode ser usado para impor políticas de utilização de recursos na rede através da manipulação das as velocidades relativas das máquinas no arquivo de configuração do programa.

Cargas momentâneas ou histórico de cargas também podem ser utilizados.

O pacote PVM (Parallel Virtual Machine) mostrou-se bem eficiente e de fácil utilização, o que é fundamental para o desenvolvimento de um programa como o UNIPAR que é dividido em módulos implementados ao longo de pesquisas relacionadas com ajuste de histórico de produção automatizado.

A idéia de agrupar todas as tarefas que envolvem simulações, principalmente as ligadas a ajuste de histórico num só programa com a finalidade de auxiliar as tarefas como a de caracterização de reservatórios foi aplicada neste trabalho através do desenvolvimento do programa UNIPAR.

A modularidade do programa e flexibilidade de aceitar diferentes simuladores comerciais, assim como uma interface de fácil utilização são fundamentais para o bom uso e aperfeiçoamento do programa.

A criação de um módulo específico para a paralelização externa ou distribuição das simulações (MPS) possibilitou maior eficiência e maior modularidade do programa.

O MPS pode ser utilizado por usuário no desenvolvimento de programas que utilizam simulações, tanto para acelerar o processo se simulações simultâneas puderem ser realizadas, quanto para tornar os programas mais robustos visto que se algum erro ocorrer o MPS pode enviar o processo para outras máquinas.

Outras aplicações que se beneficiem de simulações em paralelo podem ser facilmente implementadas como módulos do UNIPAR.

