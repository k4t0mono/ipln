A execução simultânea de instruções possibilita ganhos no tempo final de execução e o melhor aproveitamento das potencialidades das arquiteturas em que executam.

O desenvolvimento de programas capazes de realizar execuções em paralelo podem ser obtidos de duas maneiras.

Uma delas é quando o paralelismo fica a cargo do programador que sabe construir programas paralelos e faz uso de linguagens e ferramentas de programação que lhe oferecem suporte.

Outra forma é fazer uso de compiladores que detectam o paralelismo existente em um código seqüencial gerando código paralelo.

Para que seja possível detectar o paralelismo implícito em uma sequência de instruções faz-se necessária uma análise das dependências de dados entre as instruções.

Se não houverem dependências de dados as instruções podem ser executadas ao mesmo tempo.

Caso contrário, conforme o tipo de dependência existente, o compilador poderá realizar otimizações capazes de melhorar o desempenho final do programa.

Os laços de repetição presentes em códigos sequenciais são potenciais fontes de paralelismo e são foco das análises de compiladores.

A tarefa de paralelização pode ser dividia em três sub-problemas, identificação de regiões com potencial paralelismo, o qual pode ser feito automaticamente pelo programador.

Mapear o paralelismo dentro da arquitetura da máquina alvo e geração e otimização de código paralelo.

Quando os pontos de paralelismo já foram identificados pelo programador, as tarefas de mapeamento e geração de código necessitam de uma detalhada análise do compilador e de transformações no código.

A eficiência dos programas gerados por esse tipo de compiladores depende diretamente da arquitetura da máquina sobre a qual ele será executado.

Existem compiladores para arquiteturas vetoriais que detectam instruções de laços de repetição que podem ser transformadas em instruções vetoriais.

Esse tipo de compilador é conhecido como compilador vetorizador.

Quando se trata de arquiteturas multiprocessadas, os compiladores paralelizadores particionam o conjunto de instruções de um laço entre os processadores da arquitetura para sua execução concorrente.

Para os casos em que as arquiteturas suportam, podem vir a ser empregadas tanto tecnicas de paralelização quanto vetorização conjuntamente.

Este trabalho tem por objetivo apresentar as técnicas empregadas por compiladores capazes de detectar o paralelismo de programas sequências.

Será mostrado como ocorre a identificação e tratamento das dependências de dados entre as instruções.

Os requisitos necessários para a transformação de instruções de laços de repetição em instruções vetorias e os possíveis problemas que podem ser gerados.

Também será apresentado como os compiladores paralelizadores particionam as instruções de laços de repetição e as implicações geradas pela sua execução concorrente.

Alguns exemplos de compiladores vetorizadores/paralelizadores serão mostrados, bem como as peculiaridades relacionadas as arquiteturas ao qual se destinam.

Por fim, será apresentada uma conclusão do trabalho.

A análise das dependências de dados é fundamental para a possibilitar otimizações e detecção de paralelismo implicito em programas sequênciais.

Essa análise oferece as informações necessárias para realizar transformações coerentes capazes de proporcionar melhorias de localização em memória, balanceamento de cargas e escalonamento eficiente.

As informações de dependência de dados são essenciais para detectar iterações de laços que podem ser executadas em paralelo por arquiteturas multiprocessadas e vetorias.

As relações de dependências de dados armazenam a ordenação existente entre os estágios de um programa.

Essa ordem deve ser preservada em qualquer transformação do compilador para garantir a validade do código que será gerado.

As principais classificações de dependências de dados e em que situações elas acontecem serão apresentadas a seguir.

Inicialmente considere o seguinte código.

No código acima as instruções 1 e 2 não podem ser executadas ao mesmo tempo uma vez que a instrução 2 precisa do valor A computado na instrução 1.

Este tipo de dependência é conhecida como dependência verdadeira ou dependência de fluxo ou RAW(Read-After-Write).

A instrução 3 também depende da instrução 1, logo a instrução 1 deve ser a primeira a ser executada.

Como não existe dependência entre 2 e 3, essas duas instruções podem ser executadas em paralelo.

No segundo código apresentado nota-se que a instrução 1 usa o valor de B antes da instrução 2 atribuir um novo valor a B.

Isso implica que a instrução 1 deve ser executada antes da instrução 2 para que possa utiliza o valor antigo de B.

Esse tipo de dependência é chamada de antidependência ou WAR (Write-After-Read).

Nesse terceiro exemplo, tanto a instrução 1 quanto a instrução 3 estão atribuíndo valor a A.

Dependendo da ordem de execução das instruções (3 antes de 1) o valor resultante de A pode ser errado.

Assim, a instrução 1 deve ser executada antes de 3.

Esse tipo de dependência é conhecida como dependência de saída ou WAW(Write-After-Write).

Uma outra situação onde ocorrem dependências é quando ocorrem desvios condicionais em um código.

No exemplo acima, o valor de A utilizado pela instrução 3 tanto pode ser o que foi gerado pela instrução 1 ou pela instrução 2, dependendo do valor de X.

Este tipo de dependência é conhecida como dependência de controle ou dependência procedural.

Considerando as dependências de dados dentro de laços de instruções existe um interesse na dependência entre as instruções e entre os elementos das instruções.

O exemplo acima mostra uma dependência de dados entre a intrução 2 e a instrução 1.

Esta dependência acontece na mesma iteração do laço já que o valor do elemento de A produzido na instrução 1 será utilizado na instrução 2.

Observando agora um exemplo similar de laço de repetição.

Nota-se que a relação de dependencia entre a instrução 2 e 1 permanece existindo.

Porém, para qualquer iteração I a instrução 2 utilizará o valor do elemento de A produzido na iteração anterior.

Um outro exemplo similar também pode ser visto.

Nesse último exemplo, para cada iteração I, a instrução 2 utiliza um elemento de A que será recarregado na iteração seguinte.

Como a instrução 2 utiliza uma valor antigo de A, existe uma relação de antidependência entre 2 e 1.

Em arquiteturas vetoriais as operações são executadas em pipeline.

Cada CPU (Central Processing Unit) vetorial está associada a um tamanho de vetor específico que indida o número máximo de elementos que podem ser iseridos no pipeline.

Um compilador vetorizador identifica instruções de laços de repetição que podem ser convertidas em instruções vetoriais.

Quanto maior o número de laços convertidos em instruções vetoriais, maior será o desempenho do programa sobre a arquitetura.

De modo geral, o processo que envolve a detecção de laços de repetição que podem ser convertidos em instruções vetoriais é seguido por todos os compiladores vetoriais.

O que difere um compilador de outro são as peculiaridade de cada arquitetura vetorial.

Por esse motivo, serão apresentadas as técnicas para conversão de laços empregada pela maioria dos compiladores vetoriais.

Para o caso acima, não existe dependências de dados na instrução o que simplifica o processo de conversão do laço.

Quando existem dependências de dados entre instruções do laço alguns cuidados devem ser tomados.

Abaixo tem-se um exemplo desse tipo.

Observando o código acima, percebe-se uma dependência verdadeira entre a instrução 2 e a 1.

Existe, também, uma antidependência entre 3 e 2, já que a instrução 3 utiliza um valor antigo de C que será atualizado na próxima iteração.

Para este caso, a vetorização das instruções pode ser realizada desde que haja uma reordenação onde a instrução 3 passa a preceder a instrução 2.

Abaixo tem-se o código resultante.

Percebe-se uma dependência verdadeira entre as intruções 2 e 1 e outra entre as instruções 4 e 2.

Existem antidependências entre as instruções 3 e 2, 2 e 4 e entre 1 e 4.

Em situações de dependência mútua como a existente entre as instruções 2 e 4 (depedência verdadeira entre 4 e 2 e antidepedência entre 2 e 4, para este caso) indicam que estas intruções são fortemente conectadas.

Nesses casos, as duas instruções envolvidas devem ser mantidas em um laço serial.

Já as demais instruções podem ser vetorizadas sem problemas.

Veja abaixo como fica o código resultante.

Algumas operações de redução que frequentemente aparecem nos programas também são identificadas pelos compiladores vetorizadores.

Um exemplo desse tipo de operação é a soma, conforme pode ser visto no código abaixo.

O código vetorial gerado para este laço pode ser visto abaixo, onde a função SUM retorna a soma do seu argumento.

A vetorização de operações de redução podem vir a gerar resultados erroneos.

Principalmente quando os dados envolvidos são valores não inteiros.

Por exemplo, alguns métodos produzem a soma vetorial através de acumulações parciais e por fim a adição das partes.

Como as acumulações serão realizadas em ordens diferentes do laço original, os erros de arredondamento podem ser acumulados diferentemente gerando respostas diferentes.

Por esse motivo alguns compiladores vetoriais possibilitam que a vetorização de operações de redução sejam desabilitadas para garantir que será atingida a mesma resposta tanto no código vetorizado quanto no serial.

Os compiladores paralelizadores voltam-se a construção de códigos paralelos a serem executados em arquiteturas multiprocessadas.

Uma forma de utilizar os multiplos processadores disponíveis é particionar o conjunto de iterações de um laço distribuindo-os entre os processadores.

A qualidade do código gerado é diretamente influenciada pelo balanceamento de cargas dos processadores e pelo tempo em que um processador permanece ocioso devido a sincronizações.

O processo de paralelização deve, além de distribuir as iterações entre os processadores, tentar organizar o código a fim de evitar sincronizações ou, no mínimo, diminuir o tempo de espera.

Para a paralelização das instruções de laços de repetição as depedências de dados entre as interações são analisadas.

Caso as instruções não dependam de dados antigo (originados em iterações anteriores) elas poderão ser distribuídas entre os processadores disponíveis.

Caso tais dependências a valores antigos existam serão necessárias comunicações entre os processadores.

Para exemplificar, considera-se o código abaixo.

Nele é possivel perceber que todas as iterações do laço controlado pela variável I são idependentes umas das outras.

Já no laço controlado por J isso não acontece uma vez que na terceira instrução faz-se necessário os valores de A e E das iterações anteriores.

Logo, todas as iterações do laço controlado por I podem ser distribuídas entre os processadores.

Caso existam N processadores disponíveis, cada processador poderá executar uma iteração do laço.

Caso exista um número inferior de processadores, as iterações poderão ser distribuídas entre os processadores de várias formas.

O compilador pode pre-escalonar as iterações entre os P processadores em blocos contínuos onde o primeiro processador recebe as N/P primeiras iterações, o segundo as N/P seguintes e assim por diante.

Outra forma possível é o compilador atribuir ao primeiro processador todas as P+1 iterações, ao segundo as P+2 e assim por diante.

Uma outra alternativa também é possível onde os processadores podem ser auto-escalonados.

Nesse caso, cada processador, ao final de toda iteração entra em uma seção crítica do código para determinar qual será a próxima iteração do laço que ele irá executar.

Esse tipo de escalonamento funciona bem quando a carga de trabalho de cada iteração é relativamente grande mas pode variar entre diferentes iterações devido a códigos condicionais no laço.

Considerando agora um caso onde as iterações não são indenpendetes.

Como pode ser visto, a terceira instrução depende do valor de A encontrado na iteração anterior, logo as iterações não podem ser executadas independentemente.

Para que se obtenha o resultado esperado é necessário que haja uma sincronização capaz de garantir que o valor de A(I-1) já está disponível.

Abaixo pode-se ver o código interno do laço com a inclusão da sincronização.

O compilador pode reordenar as instruções para possiblitar a redução de uso de sincronizações.

Quanto maior o número de sincronizações necessárias maior será o prejuízo para o desempenho do programa.

Nesse ponto vê-se a importância de testes de dependências confiáveis, uma vez que testes mal feitos podem incluir sincronizações desnecessárias influenciando o desempenho final.

Nessa seção serão apresentados alguns exemplos de compiladores, falando sobre a arquitetura a qual se destinam, a linguagem tratada bem como suas peculiaridades.

Tais compiladores são diretamente influenciados pelas características da arquitetura a qual se destina.

Para as arquiteturas em que é possível, os compiladores aplicam técnicas de paralelização e vetorização conjuntamente para obter o melhor aproveitamento do hardware disponível.

Embora as técnicas tenham sido apresentadas separadamente neste texto, nada impede sua aplicação conjunta quando a arquitetura as suporta.

O Oxygen é um compilador paralelizador que gera código paralelo a partir de códigos em Fortran 77.

Para tanto são utilizadas diretivas de compilação que permitem a distribuição de código e dados e suporte a um espaçamento de nomes globais.

Os códigos gerados pelo Oxygen são destinados a arquiteturas paralelas com memória distribuída ou supercomputadores.

O modelo de máquina assumido pelo Oxygen é um torus bi-dimensional de elementos processadores (PE,Processing Elements).

Arquiteturas como Parystec Supercluster SC256, iWarp, o Fujitsu AP1OOO, e simulador K9 implementam este tipo de topologia.

Mostra um modelo de máquina torus bi-dimensional onde cada elemento processador comunica-se através de primitivas send e receive.

O Oxygen portou dois tipos de sistemas com memória distribuída o de comunicação sistólica e o de comunicação por memória.

Na comunicação sistólica não há trocas de mensagens.

Os dados são transmitidos do enviador para o receptor usando transferências entre as filas de memória ou filas de registradores existentes entre os PEs.

Nesse caso, um PE pode se comunicar com seus quatro vizinhos mais próximos.

A comunicação por memória, também chamada comunicação por troca de mensagens, acontece entre primitivas send e receive.

As mensagens podem ser roteadas não só aos vizinhos mais próximos e sim a todos os PEs presentes no torus.

Embora as trocas de mensagens sejam mais confortáveis para programar, o tempo gasto no gerenciamento e na computação do roteamento impõem uma maior latência para a comunicação.

Para o compilador Oxygen, os programas Fortran podem ser decompostos em uma sequência de blocos, os quais podem executar em paralelo em todos os PEs.

Esses blocos podem ser locais ou públicos.

Blocos locais podem ou não serem executados em paralelo, mas em qualquer caso sua computação é local sem a necessidade de comunicação.

Blocos públicos sempre executam em paralelo e com comunicações porque suas operações são sobre estruturas de dados distribuidamente alocadas pelos PEs.

Mostra o modelo de programa para o Oxygen.

A coluna da esquerda mostra a decomposição de um código sequencial, através de diretivas de compilação, em blocos.

A coluna central mostra a estrutura de código gerada pelo Oxygen comum a todos os PEs.

Cada bloco público é dividido em um tratador de símbolos e um executor, como mostrado na coluna da direita.

O tratador de símbolos é uma sequência de análises de consistência de dados e fases de roteamento para descobrir quem são os donos das variáveis compartilhadas.

O executor é uma sequência de fases de computação ligadas por pontos de verificação (comunicação).

A análise de consistência do tratador de símbolos constrói as estruturas de dados que serão usadas pelo executor.

Os pontos de verificação separam os blocos de computação locais dentro do executor fazendo a sincronização dentro do PE e não uma sincronização de toda a máquina.

Sempre em que faltarem dados localmente o compilador insere uma primitiva de comunicação para obtê-los.

Para os programas que apresentam laços de repetição, o tratamento de seus índices acontece similarmente ao tratamento de índices de vetores.

Ambos os índices são particionados e mapeados usando as mesmas diretivas.

O Oxygen possui duas diretivas de mapeamento, ROWWISE e COLWISE, que podem ser usadas nesse caso.

Elas tanto podem mapear índices double aninhando laços no torus, ou então, mapear um único laço em todas as linhas (ou colunas) de PEs.

Para o último caso, todos os PEs de uma mesma linha (ou coluna) realizam a computação para um mesmo índice.

Como exemplo tem-se o código abaixo.

No exemplo acima, os dois laços foram alinhado no torus.

O laço mais externo foi mapeado entre os PEs de uma mesma coluna do torus pela diretiva ROWWISE considerando que n é igual ao número de PEs presentes numa coluna do torus.

Através da COLWISE, o laço interno foi mapeado entre todos os PEs de uma mesma coluna, novamente considerando m igual ao número de PEs de uma coluna do torus.

O compilador OSCAR é o compilador para o OSCAR (Optimally SCheduled Advanced multiprocessoR) CMP (Chip Multiprocessor).

Este compilador trabalha com a linguagem de programação Fortran.

O compilador OSCAR explora, automaticamente, o paralelismo multi-grão sobre a arquitetura CMP.

O paralelismo multi-grão significa o uso hierárquico do paralelismo de tarefas de grão grande entre laços, sub-rotinas e blocos básicos.

O paralelismo de laços entre suas iterações e o paralelismo de tarefas de grão pequeno próximas entre instruções dentro de blocos básicos.

Primeiramente o compilador decompõem o código do programa Fortran em tarefas de granularidade grossa (Macro Tarefas).

Depois, o compilador analiza o fluxo de controle dentro das tarefas um grafo acíclico chamado MFG (MacroFlow-Graph).

O próximo passo em busca do máximo paralelismo entre as Macro Tarefas é a análise das condições iniciais necessárias para a execução de cada uma das Macro Tarefas.

Todas as condições iniciais passam a ser representadas pelo compilador através de um grafo acíclico chamado MTG (MacroTask-Graph).

Por fim, uma Macro Tarefa é associada a um grupo de processadores virtualmente definido pelo compilador em tempo de execução através de rotinas de escalonamento dinâmico.

Uma Macro Tarefa pode ser decomposta em tarefas de grão pequeno desde que o MTG não apresente desvios condicionais ou outras incertezas na execução.

As tarefas de grão fino serão executadas em paralelo pelo processadores dentro de um grupo de processadores.

O compilador analisa as dependências e gera um grafo de tarefas que representa a dependência de dados entre as tarefas de granularidade fina.

Então, o compilador associa estaticamente as tarefas aos processadores desde que somente exista dependências entre as tarefas de grão fino.

Depois de escalonar, o compilador gera código de máquina para cada processador.

Ele insere instruções para associar as tarefas ao processador e instruções para transferência e sincronização nas fases pré-definidas no escalomamento estático.

As informações conhecidas pelo escalonamento estático também permitem que o compilador possa otimizar os códigos gerados.

Apresenta um exemplo simples de uma arquitetura OSCAR CMP.

A arquitetura consiste de múltiplos elementos processadores (PE,Processor Elements) e interconexões de rede.

Uma memória central compartilhada (CSM,Centralized Shared Memory) também está presente.

Cada PE possui um única CPU, uma memória de programa local (LPM,Local Program Memory), uma memória de dados local (LDM,Local Data Memory), uma memória distribuída compartilhada (DSM,Distributed Shared Memory) com duas portas e uma unidade de transferência de dados (DTU,Data Transfer Unit).

O compilador PARADIGM (PARAllelizing compiler for DIstributed memory General-purpose Multicomputers) destina-se a paralelizar e otimizar programas sequenciais para execução eficiente em multicomputadores com memória distribuída.

O PARADIGM aceita códigos sequenciais Fortran 77 o HPF (High Performance Fortran) e produz uma versão paralela com passagem de mensagem.

Mostra a estrutura do compilador PARADIGM.

Inicialmente é realizada uma análise do programa através do uso do Parafrase-2.

O Parafrase divide o programa sequencial em representações intermediárias analizando o código e gerando grafos de fluxos e dependências.

Para a computação regular, o compilador determina automaticamente a distribuição de dados entre os componentes do multicomputador, sempre buscando a melhor distribuição.

De acordo com a distribuição dos dados, o compilador divide a computação em processos e gera comunicações inter-processos para requerir dados não locais.

Nos casos de computação irregular dependências de dados só são conhecidas em tempo de execução.

Para esses casos o PARADIGM combina um flexível ambiente de execução irregular e uma análise em tempo de compilação.

O compilador também pode fazer uso de threads para tornar as comunicações assíncronas e assim melhor aproveitar os ciclos computacionais.

Além disso, as comunicações podem ocorrer através de um conjunto de bibliotecas de comunicação suportadas pelo compilador, entre elas MPI e PVM.

Uma vez que a inclusão da comunicação fica a cargo do compilador, este procura evitar comunicações redundantes, ou seja, evita o envio repetitivo de uma mesma mensagem.

Para as situações onde elementos contíguos de um vetor são necessários, por exemplo em laços de repetição, o compilador vetoriza a mensagem enviando todos os dados.

Na mesma linha, quando um enviador e um receptor necessitam trocar um grande número de mensagens, o compilador agrega as mensagem em uma mensagem maior.

Todas essas otimizações na troca de mensagens buscam diminuir a sobrecarga de comunicação que pode vir a comprometer o desempenho do programa paralelo.

Para os casos em que existem dependências entre iterações de laços e estas iterações possuem granularidade grossa, o PARADIGM possibilita sua execução em pipeline.

Nela, pode ser vista a representação sequencial onde cada iteração depende da iteração anterior e realizam grande quantidade de processamento.

Além de preocupar-se com o paralelismo de dados, o PARADIGM também preocupa-se com o paralelismo funcional.

O compilador mapeia em grafo MDG (Macro Dataflow Graph) tanto o paralelismo funcional quanto o de dados.

Para determinar a melhor estratégia de execução para um determinado programa, é aplicado ao MDG uma aproximação de alocação e escalonamento.

A alocação determina o número de processos usados em cada nó enquanto o escalonamento monta um esquema de execução para os nós alocados em um multicomputador específico.

Os algoritmos empregados pelo PARADIGM para a alocação e o escalonamento são baseados em fórmulas matemáticas para determinar o custo de processamento e redistribuição de dados.

O processo de escalonamento e alocação carecem de um tempo de processamento para a sua determinação e, geralmente, este tempo é pequeno.

Este trabalho buscou apresentar um breve relato sobre compiladores paralelizadores/vetorizadores.

Este tipo de compilador analisa as dependências de dados entre as instruções e explora o paralelismo implícito entre elas.

No texto foi apresentado uma revisão sobre os tipos de dependências de dados entre instruções e a forma como acontece a paralelização e vetorização dos códigos.

Por fim, foram apresentados alguns exemplos de compiladores paralelizadores e como eles funcionam.

O principal alvo na paralelização de códigos são os laços de repetição.

Para arquiteturas vetoriais, laços podem ser convertidos em instruções vetoriais aproveitando melhor a potencialidade da arquitetura.

Já para arquiteturas não vetoriais, as iterações dos laços podem ser distribuídas entre os processadores disponíveis, desde que sejam tomados cuidados quanto a ordenação e dependências entre instruções caso existam.

Os exemplos apresentados no texto são compiladores para a linguagem Fortran.

Esta linguagem é bastante utilizada em aplicações para arquiteturas do gênero e encontram-se bastante iniciativas relacionadas a esta linguagem.

Embora os exemplos de compiladores sejam voltados a arquiteturas específicas que direcionaram as decisões tomadas pode-se destacar alguns pontos em comum.

Questões referentes a distribuição de processos nas arquiteturas paralelas são fundamentais e conforme forem tratadas serão diretamente refletidas no desempenho do programa paralelo.

As otimizações oferecidas pelos compiladores também influencia a qualidade do código gerado.

Em alguns casos, os esforços para as otimizações predomizam predominam no tempo gasto na compilação dos programas.

