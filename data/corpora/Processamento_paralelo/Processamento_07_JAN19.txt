Esse trabalho propõe uma solução de um Data Warehouse distribuído para implementação de um sistema de CRM, Customer Relationship Management, com o objetivo de uso no ambiente bancário possibilitando que ações de relacionamento com clientes sejam planejadas e implementadas.

É proposta uma arquitetura para implementação de um Data Warehouse em ambiente distribuído, utilizando programação paralela.

Com o aumento no volume de dados armazenados nos Data Warehouse, as arquiteturas tradicionais exigem processadores e sistemas de entrada e saída cada vez mais robustos em termos de desempenho.

Isso fica mais bem caracterizado quando são executadas procuras complexas (Ad hoc).

A utilização de ambientes distribuídos em conjunto com programação paralela é uma alternativa para redução de custo e aumento de desempenho.

É apresentada, aqui, uma proposta de arquitetura de Data Warehouse distribuído, integrado ao uso de programação paralela.

Muitas aplicações comerciais e científicas manipulam conjuntos de dados volumosos e muitas vezes ocasionando gargalos no sistema de entrada e saída e até mesmo nos processadores.

Essa questão é melhor caracterizada quando são executadas operações complexas sobre um banco de dados.

A manipulação de grandes bancos de dados, especialmente em Data Warehouses fica com o desempenho comprometido em função do alto nível de utilização dos sistemas de entrada e saída.

Isso ocorre no momento de execução de operações complexas, normalmente, ao atender uma situação bastante especial.

Esses canais de entrada e saída se tornam pontos de estrangulamento do processamento como um todo, esse baixo desempenho pode afetar também os processadores, ou quando não afetam, tornam esses processadores com baixo nível de utilização.

Nos sistemas OLAP (On Line Analytical Processing) voltados para os Data Warehouses, os tipos de operações realizadas nos bancos de dados são, na sua maioria, Ad hoc, ou seja, são específicas, de alta complexidade e muita vezes têm os resultados não previsíveis.

Aliado ao grande volume de dados acontece o comprometimento do desempenho desses sistemas.

Os sistemas OLTP (On Line Transaction Process) podem manipular grandes quantidades de dados, mas suas operações são previsíveis, pois não têm características especiais ou diferenciadas, pois sua natureza de comportamento é sempre semelhante.

Mesmo assim, existem situações nos sistemas OLTP que exigem alto desempenho.

O problema existente é a manipulação de grandes quantidades de dados em ambientes centralizados de Data Warehouse, onde aparecem situações de baixo desempenho devido às operações complexas a serem realizadas em grandes bancos de dados.

Esse tipo de situação ocorre com maior freqüência nos sistemas OLAP.

A motivação para o desenvolvimento de um sistema de Data Warehouse distribuídos está no aumento de desempenho oferecido pelas arquiteturas desse tipo.

Desta forma, será possível reduzir a necessidade de sistema de alto desempenho tradicionalmente utilizada nos sistemas centralizados.

Outro aspecto que contribui para essa solução descentralizada consiste nas aplicações em que os dados a serem carregados nos Data Warehouses já são utilizados de forma distribuída, facilitando a sua implementação.

Na utilização dos sistemas OLTP e OLAP se observa uma concentração no uso dos recursos computacionais, ou seja, falta de recursos num determinado momento do dia ou do mês e ociosidade em outro.

Isto mostra a necessidade de se replicar os dados numa organização de Data Warehouse.

Caso a utilização seja feita em horários distintos, surge a possibilidade de compartilhamento dos recursos computacionais existentes.

Os profissionais de administração das organizações empresariais têm a necessidade de informações gerenciais que o apóiem na tomada de decisão, o que motiva a implementação do Data Warehouse com objetivo de ajudar na administração das empresas.

A utilização dos Data Warehouses na área de relacionamento com clientes possibilita a implementação de sistemas de CRM (Customer Relationship Management) pois concentram as informações históricas desses clientes, permitindo acumulo de informações históricas.

Com um sistema de CRM é possível prever o tipo de produto a ser oferecido a uma determinada pessoa, baseado em informações como sexo, idade, renda, perfil geográfico e perfil econômico.

Além disso, têm-se informações do relacionamento do cliente com a organização tais como, quais meios de contato são utilizados, com que freqüência, quais produtos o cliente já possui, que tipo de reclamações o cliente já efetuou.

A partir destas informações, é possível prever a tendência de uso e de compra e o próprio comportamento para clientes com perfis semelhantes.

Esse trabalho propõe uma solução para um Data Warehouse distribuído.

Para implementar a proposta, escolheu-se desenvolver uma aplicação voltada para um sistema de CRM (Customer Relationship Management) com utilização no ambiente bancário, possibilitando que ações de relacionamento sejam planejadas e implementadas.

Também é objetivo do trabalho pesquisar tecnologias e propor soluções para aplicações de bancos de dados distribuídos, sendo acessados através de rede local ou de longa distância, utilizando programação paralela com o uso da Interface de Passagem de Mensagens.

Esse sistema permite o acesso ao cadastro de relacionamento comercial dos clientes de uma agência bancária, ou de um conjunto de agências.

É uma implementação básica de um sistema de CRM (Customer Relationship Management).

As informações são extraídas dos sistemas transacionais e carregadas em um Data Warehouse, obedecendo a um modelo de dados que permite, através de exploração de dados, criar campanhas para abordagem aos clientes.

A arquitetura proposta permite a criação de relatórios de comportamento dos clientes e informações exploradas no Data Warehouse distribuído que podem ser enviadas ao sistema central para consolidação da visão global dos resultados.

O sistema proposto neste trabalho utilizará conceitos de banco de dados com o processamento paralelo em processadores ligados em rede, permitindo o processamento e acesso a informações em locais remotos através de redes de alta e baixa velocidade.

A solução proposta é abrangente e pode ser aplicada a outros ambientes, permitindo a generalização.

Tanto sistemas OLTP quanto OLAP podem ser adaptados para se utilizarem da solução.

A programação paralela, usando a Interface de Passagem de Mensagens (MPI), é aqui utilizada para aperfeiçoar, minimizar e padronizar as procuras a serem executadas.

A execução dessas atividades em ambiente distribuído permitirá que gargalos em procuras complexas sejam evitados, tornando mais eficientes estas procuras, seja pela redução do tamanho da base ou pelo uso de muitos processadores.

A utilização dos processadores, ligados em rede visa permitir aproveitar a infra-estrutura existente, principalmente no período de baixa demanda, quando os computadores não estão sendo utilizados pelos sistemas transacionais.

A utilização dos sistemas transacionais, on-line é feita normalmente, durante o período diurno, pois no período noturno, esses computadores ficam ociosos.

A implementação do Data Warehouse se inicia a partir da organização dos dados extraídos dos registros de logs dos sistemas transacionais, planilhas e outras fontes de dados, para posterior análise, que se mostram importante, para conhecimento do comportamento dos clientes nos mais variados aspectos.

A solução é abrangente para outros perfis de necessidades, não só para implementações de Data Warehouse.

Os sistemas transacionais do tipo OLTP podem fazer uso de tal solução com o objetivo de aumento de desempenho, principalmente nas operações de leitura, melhorando o desempenho.

O primeiro capítulo apresentou o problema, motivação e os objetivos do trabalho.

O segundo apresentará uma revisão de conceitos de banco de dados, modelagem de dados, Data Warehouse, arquitetura de um Data Warehouse, sistema OLTP e OLAP.

O terceiro desenvolverá conceitos sobre programação paralela usando interface de passagem de mensagens, sistemas paralelos e distribuídos e Comunicação em sistemas multiprocessadores e multicomputadores.

O quarto fará considerações sobre a fase de estratégia para obtenção do sistema, contexto do processo de negócio, o processo atual, o processo proposto, as funcionalidades abordando aspectos de particionamento e dependências do sistema.

São detalhados os modelos estáticos.

O quinto capítulo abordará considerações sobre o estudo de caso do Data Warehouse distribuído, incluindo a apresentação de uma proposta de arquitetura, a solução utilizando passagens de mensagem, as tabelas do banco de dados, os aspectos de procuras complexas e as medidas de desempenho comparativas.

O sexto capítulo abordará os aspectos da implementação do sistema, detalhando o diagrama lógico da solução implementada, as ferramentas utilizadas na implementação, a estrutura da aplicação, o povoamento do ambiente de dados, a execução de consultas específicas, a execução de consultas Ad hoc e a implementação do Portal de relatórios.

O sétimo capítulo trará a conclusão do trabalho.

Um banco de dados nada mais é que uma coleção de dados inter-relacionados, que representa informações sobre um domínio específico.

A tecnologia de banco de dados oferece as facilidades de armazenamento, povoamento, busca e modificação dos dados de um banco de dados.

O banco de dados é formado por um conjunto de dados inter-relacionados e uma coleção de programas para prover o acesso a esses dados.

O objetivo principal de um sistema de banco de dados é possibilitar um ambiente adequado e eficiente para uso na recuperação e armazenamento de informações.

Mostra um esquema simplificado deste ambiente.

O Sistema Gerenciador de Banco de Dados é um software que permite a definição de estruturas para armazenamento de informações e fornecimento de mecanismos para manipulá-las.

As principais características de um Sistema Gerenciador de Banco de Dados são, Integridade, Restrições, Segurança/Privacidade, Restauração, Reorganização, Eficiência.

Os principais objetos de um Sistema Gerenciador de Banco de Dados são, Tabelas, Visões, Índices.

Esquema simplificado de um sistema de banco de dados.

Na modelagem de uma aplicação devem ser construídos modelos conceituais, para representar a compreensão do problema que está sendo estudado, e modelos de implementação, para representar a implementação dos elementos do sistema.

Num sistema computacional, um dos elementos fundamentais é o banco de dados, que deve ser seguro, robusto e íntegro.

Deste modo, um modelo de processo de software deve ser definido para a modelagem das aplicações e do banco de dados.

É uma imagem gráfica de toda a base de informações necessárias para um determinado empreendimento.

É a principal ferramenta gráfica para representação do Modelo de Dados e foi proposta por Peter Chain.

Tem a finalidade de identificar entidades de dados e seus relacionamentos.

Objeto ou evento do mundo real, distintamente identificado e tratado como uma categoria definida, acerca da qual armazenamos dados.

Dentre as tecnologias mais utilizadas de banco de dados está a tecnologia de banco de dados relacional.

Um banco de dados relacional é composto por um conjunto de tabelas e um conjunto de restrições de integridade sobre essas tabelas.

As tabelas são constituídas por registros, que são definidos pelos conteúdos de seus campos.

Um banco de dados relacional tem como base o modelo relacional, que é um modelo de tabelas, onde existe uma técnica matemática poderosa que faz validação, a álgebra relacional, e uma linguagem de banco de dados bastante popular, a linguagem SQL (Structured Query Language).

Os bancos de dados relacionais possuem atributos importantes, tais como, segurança, compartilhamento e integridade dos dados.

Eles são compostos de relações entre entidades, denominadas tabelas.

As tabelas se relacionam por meio de chaves, chamadas de estrangeiras, podem ser simples ou compostas, dependendo se são formadas por um ou vários atributos.

Atributo é a representação de um tipo de informação.

As tabelas de maior hierarquia são chamadas de tabelas pai, que se relacionam com as tabelas filha, numa relação de dependência.

A base de operacionalização do banco de dados relacional são as operações fundamentais da álgebra relacional, seleção, projeção, produto cartesiano, união e diferença entre conjuntos.

Um modelo é considerado relacional se os dados forem armazenados em tabelas e nenhum ponteiro ou ligação for visível ao usuário.

A linguagem de consulta deve ser relacionalmente completa e as consultas podem ser expressas sem uso de iterações ou recursões.

No modelo relacional, os dados são organizados na forma de tabelas.

Cada tabela, ou relação, é descrita por um esquema, que consiste em um conjunto de atributos ou campos.

Cada atributo corresponde a uma coluna da tabela e é associado a um domínio, indicando o conjunto de valores que o atributo pode assumir.

Cada linha de uma tabela é uma tupla ou um registro e é usada para descrever uma entidade do mundo real ou um relacionamento entre entidades.

Para qualquer tupla e qualquer atributo de uma relação, é requerido que o valor do atributo seja atômico, isto é, não pode ser um atributo composto nem multivalorado.

Para cada relação, existe um atributo ou combinação de atributos que apresentam valor único ou combinação única de valores, chamados de superchave da relação.

A uma superchave minimal dá-se o nome de chave.

Uma relação pode apresentar várias chaves.

Uma dessas chaves é escolhida como chave primária, sendo as outras chaves denominadas chaves secundárias.

Considere o banco de dados da rede de agências, com dados de históricos de vendas de produtos bancários para os clientes.

O banco de dados possui as principais relações representadas, porém, vão existir outras tabelas menores e estruturas de acesso especialmente construídas devido a decisões de projeto físico do banco de dados.

Como exemplo, pode-se apresentar um banco de dados de uma rede de agências onde se tem as seguintes tabelas, Agência (idagencia,nomeagencia,diretoriaregional,rua,num_rua,bairro,CEP,gerreg, fone), Cliente (idcli,nomecli,idagencia,dtnasc,gerresp,rua,num_rua,bairro,CEP,fone), Produtos (idproduto,nomeproduto,datacompra, datarenovação,valorlim, valormaxlim) e Utilização (idcanal,idcli,idagencia,produto,ultimautilizacao,numerodeutilizações).

As tabelas Agência, Cliente, Produto e Utilização têm como chave primária os campos idagencia, idcli, idproduto e idcanal, respectivamente.

Pode haver relacionamento entre campos de duas tabelas distintas.

Um desses tipos de relacionamento é a presença da chave de uma relação em outra relação, estabelecendo uma ligação das duas relações.

À chave da relação presente em outra relação, dá-se o nome de chave estrangeira.

O campo idagencia presente em Cliente é uma chave estrangeira, pois faz a ligação de Cliente com Agência e, originalmente, era chave primária da tabela Agência.

Assim, pode-se dizer que o campo idagencia, em Cliente, referencia a chave da tabela Loja, estabelecendo uma restrição de integridade denominada integridade referencial.

Pela mesma razão, os campos idcli, idagencia e idproduto são chaves estrangeiras na tabela Produto, pois fazem as ligações com as tabelas Cliente, Agência e Produto, respectivamente.

A linguagem SQL (Structured Query Language) é a linguagem padrão para os bancos de dados relacionais.

Ela pode manipular dados, definir estruturas de dados e especificar restrições de segurança e integridade.

Os comandos são divididos em 3 subconjuntos da linguagem SQL, definição de dados, manipulação de dados e controle de dados.

A Linguagem de Definição de Dados (Data Definition Language, DDL) é um grupo de declarações que possibilita a definição e modificação das estruturas do banco de dados.

Como exemplo pode-se citar, CREATE TABLE, CREATE INDEX.

A Linguagem de Manipulação de Dados (Data Manipulation Language, DML) permite, através de comandos específicos, efetuarem a manipulação dos dados, buscarem informações no banco de dados, inserirem informações no banco de dados, eliminarem informações.

Como exemplo pode-se citar, SELECT, INSERT, UPDATE.

A Linguagem de Controle de Dados (Data Control Language, DCL) permite o controle de níveis de acesso, garantindo a segurança do banco de dados.

Como exemplo pode-se citar, ALTER PASSWORD, GRANT.

São mostrados alguns dos principais comandos SQL.

Sintaxe dos comandos SQL.

A organização física dos dados em disco é importante para que se obtenha bom desempenho no acesso a um banco de dados.

A parte do banco de dados responsável por armazenar a descrição dos ponteiros de acesso aos dados é denominada catálogo, ou área de metadados, e a porção que armazena os dados propriamente ditos é chamada área de dados.

Apresenta, esquematicamente, a organização de um banco de dados.

Sempre que for preciso recuperar dados num banco de dados, é necessário passar, antes, pela área de metadados.

A área de metadados consiste em um conjunto de tabelas que são povoadas no momento da criação da estrutura do banco de dados.

Estas tabelas são chamadas catálogos, onde são armazenadas informações sobre as tabelas do banco de dados, sobre os campos e sobre restrições de integridade aplicadas às tabelas do banco de dados.

O catálogo está fortemente acoplado ao software do SGBD segundo Elmasri e Navathe.

Este disponibiliza as informações nele armazenadas a usuários e administradores do banco de dados.

O acesso ao catálogo é feito, principalmente, pelos vários módulos do software de SGBD (compilador da linguagem, otimizador de consultas, processador de transações, geradores de relatórios, etc).

Como há muito acesso ao catálogo, ele precisa ser implementado de forma eficiente.

Relacionamento Dados-Metadados.

A normalização é utilizada para remover erros de projeto nos bancos de dados.

O processo de normalização faz uso das formas normais que consiste em dividir as tabelas em tabelas menores.

A primeira forma normal, chamada de 1 NF, estabelece que cada valor do atributo ou coluna deva ser atômico.

Tabela não está na primeira forma normal.

No quadro 1, tem-se uma coluna, produtos, que relaciona os produtos que o cliente possui, portanto, não está na primeira forma normal.

A solução é a criação de uma tabela de produtos Tabela cliente na primeira forma normal.

Tabela produto na primeira forma normal.

Um esquema é considerado na segunda forma normal, 2 NF, se estiver na primeira forma e se todos os atributos que fazem parte da chave primária forem funcionalmente dependentes da chave primária, ou seja, como todos os atributos devem ser dependentes da chave primária, existindo mais do que uma chave primária, todos os atributos devem ser dependentes de ambas.

A terceira forma normal, 3 NF, diz que os atributos só podem depender da chave e nada mais.

Os bancos de dados centralizados possuem um alto custo nas consultas pela soma de dois fatores, o tempo da entrada e saída e o tempo de uso da CPU.

Deve-se encontrar o plano de execução de consulta que leve à execução da consulta num tempo adequado.

Normalmente, o número de planos de execução para uma consulta é determinado por dois fatores, o número de operações na consulta e o número de métodos que podem ser usados para avaliar cada operação.

Em virtude desta dificuldade, para consultas em geral, usam-se heurísticas ou um espaço de busca reduzido para obter-se um plano razoável, não necessariamente o ótimo.

As duas formas de otimização mais usadas são, a otimização baseada em álgebra e a otimização baseada em custo.

A construção de um banco de dados de qualidade e que ofereça bom desempenho exige que, inicialmente, construam-se modelos de qualidade para os dados da aplicação.

Isso se faz com o entendimento do problema e, a partir, daí constrói-se um modelo conceitual dos dados.

A técnica mais utilizada para a construção de modelos conceituais tem sido o Modelo Entidades-Relacionamentos.

Mostra um diagrama E-R resumido para o exemplo que representam agências bancárias com seus respectivos clientes e produtos.

Diagrama Entidade-Relacionamento.

O passo seguinte consiste no desenvolvimento do modelo de implementação dos dados.

Isto é feito executando um procedimento de mapeamento, o modelo conceitual é traduzido no modelo de implementação.

O modelo de implementação mais usado tem sido o modelo relacional.

A modelagem de dados criteriosa é o segredo do bom desempenho de um Data Warehouse, e se inicia com a especificação das estruturas de dados e regras de negócios que representam um conjunto de requerimentos de informações.

A modelagem relacional é muito utilizada nas definições de Data Warehouse.

A partir de um Data Warehouse relacional, utilizando processos de consolidações disponíveis em Sistemas OLAP (On-Line Analytical Processing) é possível chegar a uma modelagem dimensional, conhecida como Modelo Star Schema, que permite fazer uma análise multidimensional da informação, ou seja, a análise muldimensional é uma forma representativa do cruzamento de informações.

Na modelagem dimensional de um Data Warehouse, as informações se relacionam de forma que podem ser representadas como um cubo, sendo possível aprofundar em cada dimensão do cubo, ou eixo, para extrair mais detalhes sobre os processos internos que ocorrem, e assim permitir uma análise melhor dos dados e visualizar dados abstratos de forma simples.

No cubo é possível a análise de várias dimensões da informação, pois as arestas representam as dimensões e cada célula representa uma determinada visão.

A dimensão é uma unidade de análise e representa um eixo principal no estudo dos dados e pode possuir níveis hierárquicos.

Visão é o cruzamento entre uma ou mais dimensões.

Um modelo dimensional conta, basicamente, com uma tabela de fatos central e tabelas dimensionais ligadas diretamente a ela.

Os fatos e dimensões são tabelas do banco de dados que, no modelo dimensional, adquirem nomes de fatos e dimensões de acordo com a função da tabela.

O conceito do modelo estrela ou esquema estrela (Star Schema) é uma estratégia de modelagem utilizada na arquitetura de um Data Warehouse e foi criado pelo Dr Ralph Kimball, ao propor uma visão para a modelagem de base de dados para sistemas de apoio a decisão.

O nome foi adotado devido a semelhança do modelo com uma estrela.

A tabela de fatos fica no centro da estrela, rodeada por tabelas auxiliares, chamadas de dimensões.

A tabela, de fato, conecta-se às demais dimensões por múltiplas junções e as tabelas de dimensões conectam-se com apenas uma junção à tabela de fatos.

As tabelas de dimensão contêm as características de um evento.

A tabela de fatos armazena os fatos ocorridos e as chaves para as características correspondentes, nas tabelas dimensionais.

A consulta às informações ocorre, inicialmente, nas tabelas de dimensão e depois nas tabelas de fatos, assegurando a precisão dos dados por meio de uma estrutura de chaves onde não é preciso percorrer todas as tabelas, garantindo um acesso mais eficiente e com melhor desempenho.

As principais propriedades do Star Schema são, Uma única tabela de fatos contém dados, sem redundância.

Uma tabela por dimensão.

As chaves primárias, da tabela de fatos, são apenas de uma por dimensão.

Cada chave é gerada.

Cada dimensão representa uma única tabela, altamente desnormalizada, ou seja, possue repetição de informação, por não estar normalizada.

No modelo floco de neve, as tabelas dimensionais relacionam-se com a tabela de fatos, mas algumas dimensões relacionam-se apenas entre elas.

Isto ocorre para fins de normalização das tabelas dimensionais, visando diminuir o espaço ocupado por tabelas de dimensões auxiliares.

No modelo floco existem tabelas de dimensões auxiliares que normalizam as tabelas de dimensões principais.

Construindo a base de dados desta forma, passa-se a utilizar mais tabelas para representar as mesmas dimensões, mas ocupando um espaço em disco menor do que o modelo estrela.

Este modelo chama-se floco de neve, pois cada dimensão se divide em várias outras tabelas, onde organizadas de certa forma, lembram um floco de neve.

O modelo floco (Snow Flake) reduz o espaço de armazenamento dos dados dimensionais, mas acrescenta várias tabelas ao modelo, deixando-o mais complexo, tornando mais difícil a navegação pelos softwares que utilizarão o banco de dados.

Um outro fator é que mais tabelas serão utilizadas para executar uma consulta, então, mais JOINS de instrução SQL serão feitos, tornando o acesso aos dados mais lento do que no modelo estrela.

Os Data Warehouses são bancos de dados volumosos, de propósito especial e contêm dados integrados a partir de um número de fontes independentes, dando suporte na identificação de tendências e anomalias.

O processo de análise é usualmente executado com consultas que agregam, filtram e agrupam os dados numa variedade de modos.

Os dados armazenados nos Data Warehouses são provenientes dos sistemas que produzem dados operacionais.

Os dados operacionais têm grande riqueza de informações e são utilizados no dia a dia das operações dos sistemas de informática (OLTP).

Utilizando processos de extração, transformação e carga (ETL, Extract, Transformation and Load) a partir dos dados operacionais, obtêm-se os dados para carregar o Data Warehouse.

Os Data Marts são substratos dos Data Warehouses que agrupam parte das informações, geralmente aplicadas com uma determinada finalidade.

Usualmente são dados referentes a um assunto em especial, por exemplo, venda, engenharia, controladoria ou diferentes níveis de sumarização, tais como, venda anual, venda mensal, venda de cinco anos, que focalizam uma ou mais áreas específicas.

Data Marts extraem e ajustam porções de Data Warehouses aos requisitos específicos de setores ou departamentos de empresas.

O Data Warehousing é um processo estabelecido para criar e gerir repositórios de dados provenientes de diversas origens com o objetivo de ter uma visão detalhada e singular de parte, ou do todo, de um negócio.

O resultado principal conseguido em um projeto de Data Warehousing é o seu Data Warehouse.

A realização de Data Warehousing é considerada um das primeiras etapas para tornar viável a análise de grande quantidade de dados no apoio ao processo decisório.

Existem várias abordagens para a arquitetura de um Data Warehouse, dentre elas pode-se destacar, Data Warehouse Centralizado.

Data Warehouse Virtual.

Data Warehouse Distribuído.

O Data Warehouse Centralizado, é usualmente utilizado quando as organizações ou empresas têm uma definição clara das necessidades de acesso às informações que os usuários precisam e também propiciam que os dados, por estarem centralizados, tenham melhor qualidade e integridade.

Data Warehouse Centralizado.

O Data Warehouse Virtual mostrado provê acesso aos dados operacionais pelo usuário final, ou seja, as procuras para conhecimento do comportamento ou perfil são feitas direto na base operacional.

Essa solução restringe os tipos de busca, pois as bases também são utilizadas pelos sistemas transacionais.

Para facilitar esse acesso, são criadas camadas de software com o objetivo de regulamentar o acesso às bases compartilhadas com as duas finalidades, operacional e de informação.

Como vantagem dessa solução destaca-se o baixo custo de implementação, pois não há duplicidade no armazenamento de dados.

Uma desvantagem é que as procuras complexas são realizadas na base operacional, podendo diminuir a disponibilidade dessa base, pois muitos dos dados podem não estar na forma necessária a ser utilizada pelo usuário final, ou seja, o desenvolvimento foi direcionado para sistemas OLTP e não OLAP.

Data Warehouse Virtual.

Os Data Marts fornecem os dados de interesse de um usuário, setor ou departamento.

Isso permite maior controle por parte do usuário em termos de requisições de dados e manipulações.

Na maioria dos casos, os dados nos Data Marts são mais refinados, ou seja, de interesse maior para o usuário, enquanto que nos Data Warehouse, os dados são detalhados.

Essa característica possibilita que os Data Marts sejam de menor tamanho, aumentando o desempenho das procuras.

A desvantagem dessa técnica é que não existe uma visão global dos dados.

Ilustra a arquitetura dos Data Marts.

Essa arquitetura mostrada é a combinação do Data Warehouse Centralizado com os Data Marts,obtendo-se a vantagem das duas soluções, ou seja, toda a integração do Data Warehouse e as vantagens de acesso aos Data Marts que possibilitam uma visão segmentada das informações, de acordo com determinados critérios.

Os Data Marts fornecem os dados de interesse de um usuário, setor ou departamento.

Isso permite maior controle por parte do usuário em termos de requisições de dados e manipulações.

Data Warehouse e Data Marts.

Existem algumas formas de implementação dos Data Warehouses Distribuídos A proposta de Inmon menciona a existência de Data Warehouse central e local.

Onde os dados são mutuamente exclusivos.

Observar que a extração e carga são feitas também de forma distribuída.

Data Warehouse Distribuído, Inmon.

A proposta de White, conhecida como Two Tier Data Warehouse combina o Data Warehouse Centralizado e Data Marts descentralizados.

Os Data Marts contém dados não normalizados e reduzidos, refletindo aspectos de alguns usuários ou grupos de usuários.

Data Warehouse Distribuído, White.

Os sistemas que utilizam dados operacionais são caracterizados por processar as informações cotidianamente.

Eles são usados como armazenamento para as transações comerciais, tais como, controle de inventário, folha de pagamento, automação bancária.

Os dados de informação são utilizados em sistemas que permitem o planejamento, o gerenciamento das organizações e a previsão de fatos.

Esse conhecimento é obtido a partir dos dados operacionais que são transformados em informação e posteriormente em conhecimento.

Dados, Informação e Conhecimento.

A tabela abaixo faz uma comparação entre os Dados de Data Warehouse e Dados Operacionais.

Dados nos Data Warehouses e Dados Operacionais.

A mineração de dados é uma das fases mais importantes no processo de transformação dos dados operacionais em conhecimento.

Essa transformação é conhecida como descoberta de conhecimento em bancos de dados (KDD Knowledge Discovery in Databases).

Ela procura por uma série de padrões escondidos nos dados.

O objetivo de todo o processo de KDD é tornar os padrões compreensíveis às pessoas, visando facilitar uma melhor interpretação dos dados existentes.

A necessidade de buscar conhecimento nos bancos de dados é conseqüência do crescimento do armazenamento dos dados históricos.

A forma de aproveitar a riqueza contida nesse conjunto de dados foi organizá-la de uma forma que fosse possível identificar padrões que pudessem ajudar na predição de futuras ações.

Com a ajuda de técnicas estatísticas, cria-se um mecanismo para tais realizações.

Outro fator que contribuiu muito para aumento do interesse em mineração de dados foi o desenvolvimento das técnicas de machine learning redes neurais artificiais, entre outras, que tornaram a descoberta de relações interessantes em bases de dados.

Pode-se utilizar várias ferramentas e técnicas para a mineração.

Uma das ferramentas mais utilizadas são aquelas baseadas em consulta a bases de dados, linguagem SQL.

A mineração de dados é parte mais importante de um processo mais abrangente que envolve a descoberta do conhecimento.

O processo de Knowledge Discovery in Databases (KDD) envolve outras etapas,descritas abaixo, Data Warehousing.

Pré-Processamento.

Limpeza, Seleção e Codificação.

Enriquecimento.

Mineração de Dados.

Pós-Processamento.

É mostrada uma visão mais ampla do Processo KDD Knowledge Discovery in Databases.

Processo KDD Knowledge Discovery in Databases.

Os sistemas OLTP On Line Transaction Process são utilizados para suportar as operações transacionais de uma organização utilizadas nos processos de negócio do dia a dia.

Os sistemas OLAP On Line Analytical Processing são utilizados no suporte a tomada de decisões.

Eles permitem aos administradores de uma organização uma visão multidimensional com o propósito de analisar os perfis de negócios existentes, ou seja, criam condições de análise de padrões de comportamento existentes.

As seguintes características diferenciam os sistemas OLTP dos sistemas OLAP, OLTP.

Os dados são atualizados e mostrados em detalhes.

O tamanho dos dados armazenados em OLTP fica na ordem de dezenas de Gigabyte.

Nos sistemas OLTP as procuras são simples e de tipos tais como, insert, retrieve, update.

O principal objetivo é realizar a atualização, normalmente, o mais rápido possível.

O modelo de dados em OLTP é normalizado.

OLAP.

Os dados são históricos e consolidados a partir de várias bases operacionais, abrangendo um longo período.

Tamanho de centenas de Terabytes.

As procuras são complexas, utilizando-se de muitos argumentos nos comandos SQL.

Normalmente não normalizado.

Este capítulo apresentou conceitos de bancos de dados aplicados a Data Warehouses.

As várias alternativas de arquiteturas mostradas anteriormente evidenciam o grande número de opções de implementação dos Data Warehouses, centralizado, virtual e distribuído.

Ainda é possível utilizar o conceito de Data Marts para aumentar a abrangência das soluções.

Fica clara a preocupação com o desempenho nos sistema OLAP, mesmo não tendo o mesmo objetivo das aplicações on-line, como os sistemas OLTP, não se admitem tempos de resposta elevados nas consultas aos Data Warehouses.

Percebe-se a oportunidade de propor arquitetura alternativa às apresentadas no sentido de aumentar o desempenho da solução do ponto de vista do usuário, com otimização do uso dos recursos computacionais.

As aplicações têm cada vez mais necessidade de uso de grandes quantidades de memória e processadores cada vez mais rápidos.

A programação paralela em ambiente distribuído pode proporcionar a obtenção desses requisitos com baixos investimentos, pois podem ser utilizados os recursos computacionais de vários computadores, simultaneamente.

Um dos métodos de programação em computação paralela é o uso de uma biblioteca de passagem de mensagens.

Essa biblioteca transfere dados entre instâncias de programas sendo processados, normalmente sendo processados em múltiplos processadores.

Utilizando esse método é possível ter disponível grandes quantidades de memória e de unidades centrais de processamento (CPU).

Dessa forma, é possível a solução de problemas de alta complexidade que normalmente não seriam possíveis pelos métodos tradicionais, O paralelismo de tarefas pode ser implementado através do paradigma mestre e escravo.

Processo Mestre e Escravo.

Têm-se duas abordagens para escrever um programa usando programação paralela.

Uma delas usa as linguagens tradicionais em conjunto com biblioteca de passagem de mensagens.

A outra utiliza linguagens de programação específicas com diretivas próprias para programação paralela.

O compilador faz o trabalho de distribuição de atividades entre os processadores.

A abordagem de passagem de mensagens é mais flexível, pois o programador faz a distribuição dos dados e do trabalho entre os processadores disponíveis.

MPI, um padrão publicado em 1994, é uma biblioteca de funções em "C" ou sub-rotinas em Fortran que são inseridas no código para permitir a comunicação entre processos.

O aspecto negativo do uso do MPI está relacionado com a latência do tempo de comunicação quando se tem a necessidade de transmissão de grandes volumes de dados, ou mesmo de programas extensos.

O processamento de alto desempenho está presente em vários segmentos da comunidade científica e também nas aplicações comerciais e industriais.

Os investimentos necessários para compra de computadores (máquinas com múltiplos processadores) de alto poder computacional são elevados para a maior parte das empresas.

Por outro lado, existem recursos computacionais ociosos que poderiam ser mais bem aproveitados fazendo uso dos recursos de programação paralela e distribuídos.

Há algum tempo, para os Mainframes, dotados de alta capacidade de processamento, valia a Lei de Grosch, que consiste em uma relação custo versus poder computacional.

Para se obter quatro vezes mais poder computacional, seria pago o dobro do preço.

Essa relação era válida somente para Mainframes, não se aplicando à atual realidade dos processadores de baixo custo.

As máquinas multiprocessadas podem tornar-se um ponto crítico de falhas, pois, apesar de contar com vários processadores, todas as tarefas são centralizadas, dependendo do seu perfeito funcionamento, hardware, software básico e aplicativos.

Se a máquina falhar ou ficar indisponível por um determinado período de tempo, toda a organização terá seu trabalho prejudicado.

Para casos em que o custo de se adquirir uma máquina com alto poder computacional é proibitivo,soluções compostas da agregação de vários processadores de baixo custo tornam-se atrativas e vantajosas.

A organização de clusters, ou aglomerados, é uma alternativa para os multiprocessadores simétricos (SMP).

Ela provê alto desempenho e alta disponibilidade, é uma solução conveniente para servidores.

O cluster pode ser definido como um grupo de computadores completos, tendo-se a impressão de uma única máquina.

De acordo com Brewer são relacionados quatro benefícios que podem ser obtidos com a organização por cluster.

Na escalabilidade absoluta é possível criar um cluster muito poderoso, sendo sua capacidade muito maior do que a da maior máquina individual.

A escalabilidade é explorada com facilidade, expandindo-se de forma incremental.

Cada nó do cluster é um computador individual.

A falha em um nó não significa perda total dos serviços.

É possível obter clusters com capacidade maior do que máquinas poderosas, mas com custo menor.

A conexão desses aglomerados é implementada através de redes de alto desempenho, possibilitando a comunicação rápida e eficiente.

Para o sistema multiprocessador mostrado tem-se a memória principal compartilhada com os vários processadores e a comunicação entre os processos é feita através de variáveis alocadas e sinalizadas como compartilhadas.

Arquitetura de um sistema Multiprocessador.

No sistema multicomputadores apresentado, cada nó é uma máquina autônoma e independente, com memória, disco e processador.

A comunicação entre os diversos nós é feita através de uma rede de comunicação de alta velocidade.

Arquitetura de um sistema de Multicomputadores.

Nos aglomerados de processadores, ou clusters, pode-se ter várias máquinas independentes e autônomas, além de cada uma delas possuir um único processador ou um conjunto de processadores.

A comunicação entre os processadores de um mesmo nó é feitaatravés dos mecanismos de compartilhamento de memória (sistemas multiprocessadores) e a comunicação entre diferentes nós é feita através da rede de comunicação (sistemas multicomputadores).

Arquitetura de um sistema de Aglomerado.

A utilização de Clusters de computadores é extremamente atrativa e vantajosa.

Como vantagem, pode-se citar, Alto poder de processamento com baixo custo, as capacidades de processamento de cada nó, somadas, podem atingir poder de processamento altíssimo, muitas vezes maiores que os sistemas centralizados.

Entretanto, a maior dificuldade na implantação e utilização de Clusters está no desenvolvimento das aplicações que fazem uso de tal infra-estrutura.

As primitivas disponíveis para a comunicação entre processos interferem no funcionamento dos programas.

Considerando o uso de primitivas bloqueantes a primitiva, send (processo, dados), envia um conjunto de dados, geralmente apontados por um ponteiro, para o processo destino, bloqueando o emissor até que a mensagem seja totalmente enviada.

A primitiva receive (processo, dados) bloqueia o processo receptor até que os dados sejam recebidos do processo emissor.

Neste caso, o receptor não continua sua execução enquanto todos os dados não sejam recebidos através da rede de comunicação.

Na forma mais comum de comunicação ponto a ponto, send / receive entre dois processos, o comportamento do sistema depende do tamanho das mensagens enviadas.

A implementação do sistema e o número de tarefas da aplicação determinam um limite máximo para o tamanho das mensagens, de forma que o processo que envia não precise estar necessariamente sincronizado com o processo que recebe.

Se uma mensagem enviada possui tamanho menor ou igual a tal limite, esta é transferida imediatamente para a rede, ficando armazenada no buffer interno do processo receptor.

O processo emissor, assim, é automaticamente liberado.

Envio de Mensagem-Tamanho menor ou igual ao limite.

Por outro lado, se o tamanho da mensagem for superior ao limite comportado pelo sistema em dado momento, o processo emissor fica bloqueado até que o processo receptor esteja sincronizado com o mesmo, ou seja, apto para receber a mensagem.

Durante o envio dos dados pela rede, o processo receptor também fica bloqueado.

Envio de Mensagem-Tamanho maior que o limite.

No modelo mestre-escravo, um programa MPI normalmente segue esta estrutura básica em seu corpo principal.

O processo 0 (rank = 0) é o chamado mestre, que gerencia as tarefas executadas pelos demais processos, ditos escravos.

Tal gerenciamento é feito através da troca de um conjunto de mensagens, pela qual o mestre designa responsabilidades aos escravos e centraliza o recebimento dos resultados obtidos por cada um, como ilustra o exemplo do quadro 5.

Estrutura de um programa Mestre e Escravo MPI.

O programa MPI acima identifica o número de processadores existentes, permitindo, na função IF, a escolha entre o envio das atividades ao processador mestre ou aos processadores escravos.

São utilizados comandos de iniciação e finalização do MPI, tais como MPI_Init e MPI_Finalize.

O comando MPI_Comm_size busca o número total de processadores e o comando MPI_Comm_rank mostra o número de cada um dos processadores.

Se o rank for igual à zero, ele é o mestre.

No caso da aplicação bancária em questão a programação paralela utilizando passagem de mensagens é uma alternativa apropriada para a solução do problema em questão.

É possível escrever programas de forma centralizada no servidor localizado na matriz e distribuir ao longo dos servidores localizados nas agências.

Após sua execução, realizando procuras nos Data Warehouses distribuídos nas agências, os resultados são transmitidos de volta para a matriz e consolidados.

A aplicação desenvolvida está baseada na premissa de que a maior parte do código a ser processado nos servidores das agências é o mesmo, pois os tipos de procuras não variam de agência para agência.

Havendo necessidade de uma aplicação específica para uma agência, o MPI possibilita que sejam implementados programas direcionados a aquela agência, através da identificação do processo.

A proposta de um Data Warehouse distribuído tem várias aplicações possíveis, no cenário acadêmico, empresarial e governamental, pois em muitos casos os dados estão nativamente distribuídos e são utilizados, na maior parte das vezes, de forma local.

Essa característica esta presente no sistema bancário, razão pela qual se escolheu desenvolver a proposta voltada para o ambiente bancário.

O contexto de processo de negócio do sistema bancário brasileiro tem passado por profundas modificações nos últimos anos, depois de um período de inflação alta, onde o principal foco das áreas de informática das instituições financeiras era aumentar o nível de automação dos serviços, possibilitando que um grande número de operações fosse realizado de forma on-line.

Hoje as instituições têm a preocupação de aumento da eficiência, tanto no aspecto de redução de custo como no aumento da rentabilidade.

Os sistemas de informação, baseados em Data Warehouse, são uma fonte inesgotável de conhecimento a respeito dos clientes e do próprio comportamento interno da organização.

Eles provêem informações para a atuação das áreas gerenciais possibilitando o aumento da eficácia das ações comerciais e também ajudando na redução dos custos internos, identificando oportunidades de melhoria nos processos de trabalho.

Dentre os diversos aspectos a serem mencionados, destacam-se a organização geográfica das agências bancárias, no caso do Banco Bradesco são mais de 3000 agências e mais de 5000 pontos de atendimento do Banco Postal, associação entre os Correios e o Bradesco.

No Brasil existem aproximadamente 5560 cidades, o Banco Bradesco está presente com agências em mais do que 2000 cidades diferentes, sendo uma grande parte agências pioneiras, ou seja, uma agência por cidade, ou mesmo somente um único banco nessa cidade.

Pode-se levar em conta os pontos de atendimento chegando a um número maior que 30000 pontos distribuídos pelo país.

Essa descentralização dos pontos de atendimento faz com que parte dos recursos de informática fiquem também distribuídos ao longo do país, possibilitando a implementação de arquiteturas de sistemas distribuídos, pois muitos recursos de informática distribuídos possuem ociosidade na sua utilização.

Esses recursos atendem, na maior parte dos casos, os clientes locais, principalmente em cidades de porte médio e pequenas, havendo ociosidade nos recursos, tem-se a oportunidade de usá-los para outras finalidades além do atendimento on-line dos clientes.

O sistema especificado neste trabalho permitirá que os funcionários das agências tenham acesso às informações de comportamento de clientes e do desempenho comercial de sua agência, possibilitando ações comerciais.

O processo atual de ações comerciais, utilizando as informações do Data Warehouse, está limitado ao produto cartão de crédito.

O histórico das transações do produto cartão de crédito está implementado de forma centralizada.

Os dados operacionais dos sistemas transacionais são extraídos de diversas bases distribuídas, transformados e carregados em um Data Warehouse Centralizado.

Essa carga é feita diariamente com atraso de dois dias.

Esses dois dias são usados na transformação e preparação dos dados a serem carregados.

Essa filosofia de sistema possibilita a implementação de outros produtos.

O acesso às informações dos clientes para uso dos funcionários das agências é feito através de uma ferramenta desenvolvida internamente ao banco e disponível em cada agência.

A ferramenta é muito parecida com uma agenda, onde ficam marcadas as ações e datas a serem realizadas as abordagens comerciais.

Não há possibilidade do funcionário da agência desenvolver uma ação comercial baseada nas informações do Data Warehouse centralizado, pois as ações chegam às agencias prontas e somente através da ferramenta agenda.

Mostra o diagrama dessa solução.

Processo Atual Cartão de Crédito.

Os usuários das agências não acessam esse banco de dados.

O acesso é realizado por um grupo limitado de 30 usuários na matriz que preparam as campanhas de venda do cartão de crédito e publicam as ações na ferramenta agenda.

Nessa arquitetura implementada, Data Warehouse Centralizado, há necessidade de investimentos constantes para atender as demandas de carga de dados, isso será agravado com o aumento no número de produtos a ser tratado por esse Data Warehouse.

Essa forma de trabalho estimula os usuários a manter conjuntos de dados não estruturados, permitindo que ações comerciais sejam realizadas sem coordenação e sem um padrão corporativo.

O processo proposto permitirá a implementação de um sistema de informação gerencial utilizando Data Warehouse distribuído, fazendo com que todos os produtos do banco façam parte dessas bases.

As principais informações para gestão do relacionamento com o cliente farão parte de um conjunto de relatórios definidos com base na experiência de gerentes que atuam nas agências bancárias.

Os principais relatórios gerenciais e os planos de ação de venda e relacionamentos farão parte de um repositório, na matriz, permitindo o acesso através de um portal.

Diariamente esses relatórios serão atualizados em horários de baixa demanda.

O primeiro aspecto a ser resolvido é a quantidade de armazenamento necessário para a implementação do Data Warehouse com todos os produtos do banco.

A implementação atual, somente cartão de credito realizada de forma centralizada, utiliza aproximadamente 4 Terabytes, estima-se que para implementar todos os produtos será necessário 40 Terabytes.

As agências possuem discos, em seus servidores, de capacidade de 100 Gigabytes.

Desse volume, somente 40 Gigabytes são utilizados para os processos transacionais, portanto existe ociosidade de 60 Gigabytes.

O banco tem cerca de 3000 agências, portanto, a área total de armazenamento disponível, nas agências, é de aproximadamente 180 Terabytes, suficiente para implementação de todo o Data Warehouse e ainda com previsão de expansão.

Outro aspecto a ser observado é a distribuição do processamento.

Se a solução adotada fosse expandir o Data Warehouse centralizado para implementação de todos os produtos, seria necessário o aumento da capacidade de processamento além da quantidade de discos.

Essa abordagem para solução do problema viabiliza a implementação do sistema de Data Warehouse distribuído sem a necessidade de investimentos, pois serão utilizados os recursos, discos e processadores, já disponíveis nas agências.

Dentre os objetivos da solução apresentada, está o de oferecer ao funcionário da agência subsídio para que ele possa extrair informações precisas e em tempo hábil, relativas ao andamento de seu negócio, munindo-o adequadamente para correta ação estratégica.

Entre os benefícios daí advindos, direta ou indiretamente, estão, Histórico de transações.

Informações sobre receita e lucratividade.

Valor real, potencial e estratégico de negócio.

Potencial de crescimento, receptividade na abordagem.

Risco.

O conjunto de funcionalidades disponível está relacionado com o número de produtos a ser implementado e os tipos de informações necessárias para realizações de campanhas.

No mercado bancário, as ações comerciais são padronizadas, ou seja, definido um tipo de cliente a ser abordado, é bem caracterizado o tipo de venda a ser feita.

Portanto, definido o conjunto de produtos, definem-se os tipos de abordagem e cria-se o conjunto de relatórios padrão que poderá ser utilizado pelos gerentes para abordagem aos clientes.

Como exemplos, estão listados a seguir, os relatórios do produto cartão de crédito, Relatório de Cartões de Crédito que vencem no mês atual.

Relatório de Cartões de Crédito que possibilitam venda de padrão superior.

Relatório de Cartões de Crédito adicional.

Relatório de Cartões de Crédito não desbloqueado.

Relatório de Cartões de Crédito não ativado.

Relatório de Cartões de Crédito por tipo de bandeira (Amex, Visa, Mastercard).

Relatório de Cartões de Crédito das vendas mensais.

Relatório de Cartões de Crédito das vendas mês atual.

Relatório de Cartões de Crédito de clientes da agência que não possuam cartão.

Relatório de Cartões de Crédito de clientes com bandeira Visa e não Amex.

Relatório de Cartões de Crédito de clientes com bandeira Visa e não Mastercard.

Relatório de Cartões de Crédito de clientes que utilizam crédito rotativo.
Relatório de Cartões de Crédito de clientes inadimplentes.

Relatório de Cartões de Crédito de clientes nacional com potencial internacional.

Esses relatórios têm abrangência por agência, por gerência regional, por diretoria regional ou mesmo com abrangência nacional.

Acima estão descritos os relatórios relativos ao produto cartão de crédito, relatórios semelhantes podem ser prodizidos referente a outros produtos, aumentando a abrangência do sistema com relação ao atual.

O processo proposto vai proporcionar ao gerente, tomador de decisões, informações sobre o andamento dos negócios de sua agência, calcadas em indicadores consistentes e representativos sobre cada momento do cenário de mercado.

A implementação do portal pode ser feita com o auxílio de uma ferramenta de Business Intelligence, baseada no uso de Data Warehouse distribuído com informações consolidadas.

O acesso aos relatórios publicados no portal pode ser via Intranet ou Internet.

Também é possível a gestão corporativa dos indicadores, acesso colaborativo, e diferentes visões do negócio, em função do nível do usuário (operacional, tático e estratégico).

Trazem, em diagramas IDEF0, a visão geral do processo proposto e o primeiro nível de detalhamento dos elementos.

Diagrama IDEF0 nível de contexto.

O diagrama apresenta o primeiro nível de detalhe do sistema a ser desenvolvido.

Primeiro nível de detalhe do processo proposto.

O sistema proposto possui uma arquitetura composta de vários elementos já utilizados de forma isolada, um ponto de atenção é a conexão entre a matriz e as agências que é feita de duas formas, rede terrestre com linhas de comunicação que variam a velocidade de 256 Kbps a 2 Mbps, dependendo do tamanho das agências, e a rede satélite que possui velocidade de 256 Kbps.

O nível de iteratividade dos relatórios solicitados deve ser analisado para não causar impacto no tempo de resposta.

Espera-se um tempo de resposta de 10 a 30 segundos para acesso aos relatórios.

O tempo de retenção dos dados é de 5 anos, salvo algum produto que necessite um período de retenção maior, pode-se citar o produto de previdência privada que tem um período longo de contato com o cliente.

O tempo de disponibilidade do sistema é no horário comercial, fora desse período serão realizadas tarefas de carga nos Data Warehouse das agências, será executada a atualização diária dos relatórios na matriz e o back-up diário incremental, aos finais de semana o back-up completo.

Os servidores possuem sistemas de tolerância à falha, onde as bases transacionais e analíticas estarão instaladas.

O volume de informação armazenada em cada uma das agências será em média 50 Gigabytes, podendo variar nas agências de maior tamanho.

O volume de crescimento anual é de 20%, baseado no crescimento histórico do banco.

Este capítulo apresentou o detalhamento das especificações de requisito do sistema a ser implementado.

O processo atual e o processo proposto evidenciam o potencial de melhoria e de reaproveitamento dos recursos existentes.

A arquitetura proposta busca distribuir os Data Warehouses em pontos distantes que recebem a carga dos dados dos sistemas transacionais localmente.

A partir de um ponto central, são distribuídos programas para serem executados nos pontos distantes.

O resultado desse processamento é retornado ao ponto central e consolidado, sendo armazenado em uma base de dados para posterior consulta.

O sistema proposto, por exemplo, aplicação a um ambiente bancário, permite a criação de relatórios de comportamento dos clientes.

As informações exploradas nos Data Warehouses distribuídos são enviadas ao sistema central para consolidação e proporcionam uma visão global dos resultados.

A utilização de Data Warehouse permite que se organizem as informações extraídas dos registros de logs dos sistemas transacionais, OLTP, para posterior verificação.

Esta análise é importante para o conhecimento do comportamento dos clientes em vários aspectos.

É possível prever o tipo de produto a ser oferecido a um determinado cliente, baseando-se em informações como sexo, idade, renda, perfil geográfico e perfil econômico.

Além disso, existem informações do relacionamento do cliente com a instituição, tais como, quais canais de contato que são utilizados, com que freqüência, quais produtos o cliente já possui, que tipo de reclamações o cliente já efetuou, etc.

A partir dessas informações é possível prever a propensão de uso, de compra e o próprio comportamento dos clientes, sendo possível identificarem clientes com perfis semelhantes, onde os resultados das ações obterão sucesso com menor esforço.

A arquitetura proposta nesse trabalho apresenta semelhanças com a proposta por Inmom.

A principal diferença está no aspecto que não há o Data Warehouse centralizado.

Os dados operacionais são convertidos e armazenados no Data Warehouse local, através das técnicas de extração, transformação e carga.

No ponto central são efetuadas as solicitações aos Data Warehouses distribuídos pelas agências.

Essas solicitações são tratadas através de execução das procuras nos nós de processamento das agências, sendo os resultados retornados ao ponto central, para serem consolidados e armazenados.

Com o objetivo de diminuir os tempos de resposta para solicitações semelhantes realizadas por outros usuários, cria-se um banco de dados no ponto central para armazenamento do resultado das procuras ou mesmo dos relatórios obtidos.

Esses resultados serão consolidados para uso no ponto central, podendo ser consultados pelos pontos remotos, através de um portal.

Arquitetura Proposta.

O banco de dados no ponto central é usado para armazenar temporariamente os relatórios das procuras, não sendo organizado como um Data Warehouse.

O período de armazenagem pode ser muito pequeno, por exemplo, um mês, pois se for solicitado um relatório antigo, uma nova procura nos Data Warehouses distribuídos é efetuada, dessa forma, o volume armazenado é pequeno.

Deve-se estabelecer o tempo de permanência de cada relatório, a fim de evitar sobrecarga na geração dos relatórios, pois se forem solicitados com freqüência haverá diminuição de desempenho.

No ponto central, opcionalmente, pode-se ter um Data Warehouse, mas não com a função de centralização dos dados, mas com finalidade semelhante aos pertencentes às agências.

Um dos métodos de programação em computação paralela é o uso de uma biblioteca de passagem de mensagens.

Essa biblioteca transfere dados entre instâncias de programas, normalmente sendo processados utilizando múltiplos processadores.

Com esse método é possível ter disponível grandes espaços de memória e um número maior de unidades centrais de processamento.

Desta forma é possível viabilizar a solução de problemas de alta complexidade que normalmente não seriam possíveis com os métodos tradicionais.

Na implementação da solução proposta, o paralelismo de tarefas é implementado através do paradigma mestre escravo.

As procuras são requeridas a partir da matriz.

Os resultados que serão utilizados para geração de relatórios retornam das agências para Matriz.

Processo Mestre (Matriz), Escravo (Agência).

Os programas que fazem uso da biblioteca de passagem de mensagens são compostos de programas com múltiplas instâncias que podem se comunicar através das chamadas da biblioteca.

Essas chamadas são divididas em quatro classes, Iniciação, Gerenciamento e término de comunicação.

Comunicação entre par de processos.

Operações de comunicação entre vários processos.

Criação de tipos de dados.

A comunicação é feita utilizando passagem de mensagem.

Um par de processos se comunica executando comandos send e receive e, genericamente, a mensagem é composta de um envelope, indicando a fonte e o destino e um corpo contendo os dados a serem transmitidos.

O processo mestre, executado na matriz, faz tarefas de distribuição para os processos das agências, enviando programas a serem processados.

Cada escravo executa sua tarefa designada pelo mestre devolvendo o resultado.

O mestre, então, faz a consolidação montando os relatórios.

Os programas são escritos em linguagem C, utilizando a biblioteca MPI, Message Passage Interface, para a passagem das mensagens e distribuição do código entre os escravos.

É também utilizada uma biblioteca SQL para a execução dos comandos necessários para acesso aos bancos de dados.

Tanto sistemas OLTP quanto OLAP podem ser adaptados para se utilizar da solução, tornando-a abrangente a várias necessidades.

De fato ela combina o uso de bancos de dados distribuídos com a programação, utilizando passagem de mensagens, sendo possível a sua generalização.

Como estudo de caso foi escolhida a apresentação de uma aplicação bancária, envolvendo conceitos de CRM, Customer Relationship Management.

Essa aplicação envolve os Data Warehouses localizados nas agências.

Na matriz tem-se o ponto de distribuição dos programas a serem executados em todas as agências para pesquisa.

As informações são extraídas dos sistemas transacionais e carregadas no Data Warehouse, um em cada agência, obedecendo a um modelo de dados que permite, através de exploração de dados, a geração de conhecimento para abordagem aos clientes.

Com isso, ações comerciais poderão ser realizadas no âmbito de uma agência, de um grupo, ou mesmo envolvendo todas as agências do banco.

O modelo de dados, nas aplicações de Data Warehouse, é um dos pontos mais importantes para o sucesso da implementação do projeto.

Em sistemas que possuam somente a visão técnica, na sua implementação, o projeto técnico pode ser um sucesso sob o aspecto de desempenho, disponibilidade e segurança, mas nos aspectos de negócios acaba sendo um fracasso e será pouco utilizado pelos usuários, pois não se encontra valor para o negócio que justifique sua utilização em larga escala.

Desta forma, é importante ter bons resultados nos dois aspectos.

No trabalho desenvolvido foi considerada a aplicabilidade prática das informações do modelo de dados.

Cada agência tem o seu Data Warehouse, que é carregado com os dados provenientes dos sistemas transacionais, obedecendo a um modelo de dados.

O modelo é idêntico para todas as agências.

Uma vez armazenadas as informações históricas no Data Warehouse, é possível utilizar ferramentas de exploração de dados para pesquisas locais.

As pesquisas globais, utilizando todos os Data Warehouses das agências são feitas a partir da matriz, através do uso de interface de passagem de mensagens para enviar os comandos de busca para todas as agências.

Após a realização das operações solicitadas pela matriz, os resultados são retornados para consolidação, gerando relatórios que ficam armazenados no banco de dados especificado na arquitetura.

Tais pesquisas são frequentemente requisitadas pelos usuários.

Neste caso, os resultados estarão disponíveis na matriz, podendo ser consultados através de um portal, não sendo necessário nenhuma ferramenta de exploração.

Nessa aplicação, o modelo de dados, possui informações de, nome, endereço, cidade, estado, país, telefone, agência, conta, CPF (Cadastro de Pessoa Física), registro geral, produtos que o cliente possui, canais que o cliente usa, reclamações do cliente e etc.

Modelo Conceitual de Dados.

Integra a arquitetura proposta ao modelo de dados conceitual, mostrando os principais elementos da solução.

Arquitetura Integrada ao Modelo de Dados.

A arquitetura proposta utiliza bancos de dados distribuídos com acionamento a partir de um ponto central.

Ela poderá ser aplicada tanto nos ambientes de dados dos Data Warehouse, como também nos ambientes transacionais, principalmente nos ambientes transacionais de leitura.

A programação paralela padroniza a codificação e minimiza o tempo de execução para determinadas procuras, fazendo uso de paralelismo.

O sistema possibilita visão consolidada das informações, mesmo possuindo bases de dados distribuídas, que é feito através da publicação das principais procuras no portal.

A implementação realizada utiliza uma rede local do tipo Ethenet com velocidade 10 Megabits por segundo.

Essa rede interliga um conjunto de computadores dentre os quais um é usado como servidor de domínio, para permitir que os comandos MPI Message Passage Interface sejam passados aos outros computadores.

Esse conjunto de computadores simula o ambiente do banco.

O servidor de domínio, ponto central de rede, faz o papel do computador da Matriz, de onde são submetidos os programas utilizando comandos MPI e SQL a serem executados nos computadores das agências.

Esse computador também hospeda o site do Portal que concentra os resultados de procuras freqüentes solicitadas pelas agências.

Os demais funcionam como servidores de agências, onde foram carregadas suas respectivas bases de dados.

Interligação dos Computadores.

O trabalho implementado poderá ser transformado em uma aplicação real a ser utilizada no ambiente de produção do banco em questão.

Na prática, a arquitetura do ambiente central é composta por vários Mainframes e por um conjunto de servidores voltados a suas aplicações específicas.

As agências são interligadas por uma rede IP, Internet Protocol, que pode ter sua ligação por linha de comunicação terrestre ou via satélite, podendo variar a velocidade, dependendo da operadora e região do país onde a agência esta localizada.

Mostra o diagrama de blocos dos elementos do ambiente de produção do banco.

Arquitetura de rede do Banco.

Os computadores utilizados para a implementação possuem as seguintes características, Computador representando a Matriz é da marca IBM modelo Netfinity 5100 com as seguintes características, Série, 82 AA7 KB, Processador, PIII 933 MHz (1 processador), Memória, 256 MB, HD, 6 x 91 GB (Raid 5 e 1 hot spare), Sistema Operacional, Windows 2000 Server.

Computador representando a agência número 01 é da marca HP modelo Vectra Vl 410 BRIO, com as seguintes características, Série, BR04240125, Processador, PIII 733 Mhz, HD, 400 GB, Sistema Operacional, Windows 2000, Memória, 128 MB (1 slot ocupado, 1 slot livre), Memória física total, 129520 KB, Memória física disponível, 31288 KB, Memória virtual total, 440008 KB, Memória virtual disponível, 230440 KB, Espaço do arquivo de paginação, 310488 KB, Mean throughput, 19303,2 KB/s.

Computador representando a agência número 02 é da marca HP modelo PC Hp Vectra VE18, com as seguintes características, Série, BR02130259, Processador, PIII 550 Mhz, HD, 200 GB, Sistema Operacional, Windows 2000, Memória, 128 MB (1 slot ocupado, 1 slot livre), Memória física total, 130544 KB, Memória física disponível, 58586 KB, Memória virtual total, 441112 KB, Memória virtual disponível, 253252 KB, Espaço do arquivo de paginação, 310568 KB, Mean throughput,10275,2 KB/s.

Computador representando a agência número 03 é da marca Toshiba satélite 110 CS, com as seguintes características, Série, X81164 B0 A, Processador, Celeron 350 Mhz, HD, 43 GB, Sistema Operacional, Windows 2000, Memória, 64 MB, Memória física total, 65140 KB, Memória física disponível, 3228 KB, Memória virtual total, 215372 KB, Memória virtual disponível, 82040 KB, Espaço do arquivo de paginação, 150232 KB, Mean throughput, 5134,5 KB/s.

Detalhamento do Hardware.

As ferramentas utilizadas foram o Mysql, como gerenciador de banco de dados, o Compilador C++ com a biblioteca MPI e o framework MPICH for Windows, responsável pelo gerenciamento da troca de mensagens.

O Mysql, em sua versão 50, foi o sistema gerenciador de bancos de dados utilizado.

Essa versão possui uma série de facilidades para implementação dos bancos de dados, entre elas, o Query Browser, ferramenta que possibilita a construção de procuras de forma simples e estruturada, o Mysql Administrator, ferramenta de administração do banco de dados possibilitando atuar na sua configuração e gerenciamento, e o Mysql Migration ToolKit, que permite migrar informações de bases entre ambientes heterogêneos.

Todo este conjunto de programas do Mysql é processado em máquinas com sistema operacional Windows, nas versões 2000 Professional e 2000 Server, sendo que o Server roda no gerenciador de domínios e os Professional nas 3 estações que representam as agências.

O protocolo de rede utilizado para comunicação é o TCP/IP e o padrão da rede local é o Ethernet de velocidade 10 Megabits por segundo.

O elemento de rede que faz a interligação entre os computadores é um Hub de velocidade compatível.

A utilização do dispositivo do tipo Hub, baixo desempenho, aumenta o rigor nos testes, pois ele é de baixo desempenho inclusive permitindo colisões em momentos de alto tráfego.

Essa situação não acontece na prática, no ambiente de agências, pois as linhas de comunicação são individuais e a chegada na matriz é feita de forma independente.

O projeto da aplicação tem basicamente 5 módulos O primeiro módulo é responsável pelo povoamento da base de dados.

O segundo módulo é responsável pelas consultas utilizando procuras padrão previamente estabelecidas.

O terceiro módulo possibilita realizar procuras com conteúdo especificado pelo próprio usuário.

Estas procuras atendem a situações específicas que não são satisfeitas pelas procuras do módulo anterior.

O quarto módulo implementa o Portal, onde cada usuário pode consultar as procuras padrão, implementado no segundo módulo.

O quinto módulo implementa a aplicação com os comandos MPI que são executados em cada um dos servidores das agências.

A base de dados foi formada a partir de uma base aleatória de nomes.

Esses nomes foram misturados com a utilização de um programa de apoio para gerar a base de cliente em cada microcomputador da rede.

Cada base foi carregada com os respectivos produtos, cartão, de crédito, capitalização, poupança, conta corrente e outros.

O volume total de dados, em cada computador, chegou ao valor de 370000 clientes e 1000000 de cartões cadastrados, totalizando 205 Megabytes.

Essa base foi replicada para outros computadores, colocando-se um identificador para diferenciá-las.

Depois de criado e povoado o ambiente de dados, a aplicação que permite as consultas pré-estabelecidas foi construída.

Os resultados dessas consultas são armazenados com objetivo da criação do Portal, que permite o compartilhamento dessas informações por todas as agências, ou seja, de forma geral.

O comando SELECT é usado de forma intensiva para essa pesquisa.

Esse é um comando simples e possui pelo menos duas cláusulas, SELECT e FROM.

O SELECT indica o que é procurado e o FROM aonde é procurado.

Pode ter também a cláusula WHERE para definir as condições de procura.

Em geral, restringe o volume de dados resultante.

A clausula ORDER BY ordena o resultado.

O comando SELECT não resolve todas as procuras, mas é usado intensivamente na implementação, como mostrado abaixo.

O Portal foi construído através de programação ASP Active Server Pages, que manipula os arquivos no computador da Matriz e os envia à medida que cada agência faz a sua consulta.

O ASP é uma estrutura de programação em Script que se utiliza de VBScript, Jscript, processadas no servidor para geração de conteúdo dinâmico.

Ele é processado nativamente em servidores Windows, através do servidor web, Internet Information Server (IIS).

Além disso ele poder ser processado em outras plataformas.

Nele representam-se as principais entidades do modelo utilizado na solução.

O detalhamento do modelo de dados encontra-se no apêndice C.

Diagrama de Entidade e Relacionamento do cartão de crédito.

As principais entidades implementadas para o produto cartão de crédito são descritas a seguir.

Foi medido o desempenho de procuras de média complexidade e de alta complexidade, variando-se o tamanho da base e sempre comparado a uma base com "n" vezes o tamanho, mas com o conceito de Data Warehouse centralizado.

O valor de "n" é o número de máquinas usado para realização do teste de modo distribuído.

O conjunto de medidas realizadas para mostrar os resultados do trabalho foi o seguinte, Relatório de clientes das agências.

Relatório de clientes com cartão de crédito das agências.

Relatório de cartões por cliente das agências.

Relatório de cartões de crédito que vencem hoje.

Relatório de cartões de crédito com limite superior.

Relatório de Cartões de Crédito adicional.

Relatório de clientes 150, usado para teste.

Essas medidas foram realizadas tomando como referência o computador de domínio, também chamado de computador da matriz.

É nesse computador que os programas são distribuídos para execução.

Eles são transmitidos através da rede e executados nos computadores das agências, aqui representados como agência, "um", "dois" e "três".

A escolha desse ponto permite efetuar as medições do tempo de resposta de cada solicitação aos computadores das agências.

Dessa forma, pode-se comparar o desempenho de Data Warehouse formado por uma base distribuída em "n" computadores com relação à medida onde o Data Warehouse se encontram totalmente em uma única máquina.

Mostra o exemplo com 2 agências onde é usada a base com 500000 clientes em cada agência e mostra a mesma procura sendo realizada numa única máquina com 1000000 clientes na base.

Essa procura é de média complexidade na base com 500000 clientes em cada agência e montagem do arquivo para o Portal Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 2 agências, totalizando 1000000 de clientes.

Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Medida 1, 30 m54 s, Medida 2, 30 m27 s, Medida 3, 37 m51 s, Medida 4, 30 m32 s, Média das 4 medidas, 32 m26 s.

Essa procura é de média complexidade na base com 1000000 clientes em uma única agência e montagem do arquivo para o Portal.

Como os computadores das 2 agências são diferentes, principalmente com relação ao tempo de resposta do disco, a mesma procura na base de 1000000 de clientes foi feita tanto numa agência quanto na outra.

Foram feitas 4 medidas na máquina "1", a média dos tempos de resposta foi a seguinte, Medida 1, 96 m33 s, Medida 2, 74 m56 s, Medida 3, 76 m06 s, Medida 4, 89 m33 s, Média das 4 medidas, 84 m30 s.

Foram feitas 4 medidas na máquina "2", a média dos tempos de resposta foi a seguinte, Medida 1, 34 m45 s, Medida 2, 32 m58 s, Medida 3, 35 m06 s, Medida 4, 29 m20 s, Média das 4 medidas, 33 m02 s.

Como comentário das medidas, podemos afirmar que as medidas 1, 2, 3 e 4 da arquitetura distribuída, estão dentro do esperado, levando-se em conta à média das medidas.

As medidas de número 3 da arquitetura distribuída e a medida número 4 da arquitetura centralizada na máquina mais rápida apresentam distorções.

Essa diferença pode ser atribuída ao tráfego de rede existente na arquitetura distribuída, o mesmo não acontece na arquitetura centralizada.

A procura é transmitida em pacotes de 255 bytes para a máquina que representa a matriz, onde é gravado o arquivo de resultado que é usado pelo Portal.

Com relação à máquina mais lenta todos os resultados estão dentro do esperado, melhor desempenho na arquitetura distribuída.

Deve-se levar em conta que os dados utilizados em cada agência são extraídos, transformados e carregados na própria agência.

Na arquitetura centralizada têm-se a necessidade de transmitir todos esses dados para o ponto central para que seja efetuado o processamento.

Esse ganho proporcionado pela arquitetura não esta mensurado na tabela acima, pois a extração, transformação e carga não fazem parte desse trabalho.

Essa procura de média complexidade com base de tamanho de 1500000 de cartões de crédito em cada agência, a base de cartões por agência e bem maior que a base de clientes utilizada nos itens 671 e 672.

Neste caso o tráfego de rede para o computador que representa a matriz, onde é montado o Portal, é 3 vezes superior aos itens anteriores.

Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Medida 1, 25 m12 s, Medida 2, 38 m28 s, Medida 3, 56 m58 s, Medida 4, 33 m30 s, Média das 4 medidas, 38 m32 s.

Esta procura média complexidade com base de 3000000 cartões de clientes de uma agência.

Como os computadores das 2 agências são diferentes, principalmente com relação ao tempo de resposta do disco a mesma procura na base de 3000000 de cartões de clientes foi feita tanto numa agência quanto na outra, denominada de agência rápida ou agência lenta.

Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases centralizadas em uma agência com procura de média complexidade com grande quantidade de clientes.

Foram feitas 4 medidas na máquina 1, mais lenta, a média dos tempos de resposta foi a seguinte, Medida 1, 180 m34 s, Medida 2, 186 m27 s, Medida 3, 188 m50 s, Medida 4, 179 m12 s, Média das 4 medidas, 183 m45 s.

Foram feitas 4 medidas na máquina 2, rápida, a média dos tempos de resposta foi a seguinte, Medida 1, 71 m46 s, Medida 2, 76 m39 s, Medida 3, 75 m22 s, Medida 4, 72 m16 s, Média das 4 medidas, 74 m01 s.

Como comentário das medidas pode-se afirmar que as medidas 1, 2, 3 e 4 e a média estão dentro do previsto, ou seja, aumentando-se o tamanho da base na arquitetura centralizada o tempo da procura aumenta muito em relação à distribuída.

Observa-se que o desempenho da medida 1 é melhor em relação à medida distribuída do item 671.

Com relação à máquina mais lenta todos os resultados estão dentro do esperado.

Essa procura é de alta complexidade, usando join na base 1500000 clientes em cada agência e montagem do arquivo para o Portal, Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 2 agências, Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Medida 1, 111 m48 s, Medida 2, 125 m21 s, Medida 3, 122 m40 s, Medida 4, 115 m24 s, Média das 4 medidas, 118 m48 s.

Essa procura é de alta complexidade, usando join na base 3000000 clientes em uma única agência e montagem do arquivo para o Portal, Como os computadores das 2 agências são diferentes, principalmente com relação ao tempo de resposta do disco a mesma procura na base de 3000000 de clientes foi feita tanto numa agência quanto na outra.

Foram feitas 4 medidas na máquina 1, mais lenta, a média dos tempos de resposta foi a seguinte, Medida 1, 206 m42 s, Medida 2, 212 m15 s, Medida 3, 205 m17 s, Medida 4, 210 m39 s, Média das 4 medidas, 208 m43 s.

Foram feitas 4 medidas na máquina 2, rápida, a média dos tempos de resposta foi a seguinte, Medida 1, 148 m06 s, Medida 2, 136 m32 s, Medida 3, 139 m45 s, Medida 4, 146 m51 s, Média das 4 medidas, 142 m48 s.

Como comentário pode-se afirmar que as medidas 1, 2, 3 e 4 da arquitetura distribuída, estão dentro do esperado, tanto na máquina 1 quanto na 2.

Essa procura é de alta complexidade, usando join e com clausula when na base com 1500000 clientes em cada agência e montagem do arquivo para o Portal.

Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 2 agências, Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Medida 1, 121 m24 s, Medida 2, 116 m10 s, Medida 3, 124 m02 s, Medida 4, 122 m57 s, Média das 4 medidas, 121 m08 s.

Essa procura é de alta complexidade, usando join e com clausula when na base 3000000 clientes em uma única agência e montagem do arquivo para o Portal, Como os computadores das 2 agências são diferentes, principalmente com relação ao tempo de resposta do disco a mesma procura na base de 3000000 de clientes foi feita tanto numa agência quanto na outra.

Foram feitas 4 medidas na máquina 2, a média dos tempos de resposta foi, Medida 1, 229 m48 s, Medida 2, 226 m38 s, Medida 3, 227 m19 s, Medida 4, 228 m52 s, Média das 4 medidas, 228 m09 s.

Foram feitas 4 medidas na máquina 2, rápida, a média dos tempos de resposta foi a seguinte, Medida 1, 169 m14 s, Medida 2, 152 m17 s, Medida 3, 167 m49 s, Medida 4, 153 m34 s, Média das 4 medidas, 160 m43 s.

Como comentários das medidas, podemos afirmar que estão dentro do esperado.

Essa procura é de alta complexidade, usando join e com clausula where na base 1500000 clientes em cada agência e montagem do arquivo para o Portal, Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 2 agências.

Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Medida 1, 124 m24 s, Medida 2, 118 m54 s, Medida 3, 125 m29 s, Medida 4, 120 m17 s, Média das 4 medidas, 122 m15 s.

Essa procura é de alta complexidade, usando join e com clausula where na base 3000000 clientes em uma única agência e montagem do arquivo para o Portal, Como os computadores das 2 agências são diferentes, principalmente com relação ao tempo de resposta do disco a mesma procura na base de 3000000 de clientes foi feita tanto numa agência quanto na outra.

Foram feitas 4 medidas na máquina 1 e a média dos tempos de resposta foi a seguinte, Medida 1, 162 m56 s, Medida 2, 170 m31 s, Medida 3, 164 m19 s, Medida 4, 171 m03 s, Média das 4 medidas, 167 m12 s.

Foram feitas 4 medidas na máquina 2 e a média dos tempos de resposta foi a seguinte, Medida 1, 232 m41 s, Medida 2, 238 m00 s, Medida 3, 233 m18 s, Medida 4, 237 m29 s, Média das 4 medidas, 235 m21 s.

Como comentários das medidas, podemos afirmar que estão dentro do esperado.

Nota-se que não há diferença significativa entre os resultados da opção 4 e da opção 5, este fato deve-se a semelhança entre as duas procuras.

Deve-se levar em conta que os dados utilizados em cada agência são extraídos, transformados e carregados na própria agência.

Na arquitetura centralizada têm-se a necessidade de transmitir todos esses dados para o ponto central para que seja efetuado o processamento.

Esse ganho proporcionado pela arquitetura não esta mensurado na tabela acima, pois a extração, transformação e carga não fazem parte desse trabalho, notar que na solução distribuída o tempo de transmissão dos resultados esta considerado, mostrando que a diferença é maior ainda que a mostrada.

Com relação às medidas do relatório de cartões de crédito adicional no ambiente distribuído e centralizado (Opção 6), podemos considerar os resultados semelhantes ao do item anterior.

Essa procura é de média complexidade na base com 300000 clientes em cada agência e montagem do arquivo para o Portal.

Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 4 agências e centralizada, totalizando 1200000 de clientes.

Os equipamentos utilizados nessa medida foram homogêneos, ou seja, todos com as mesmas características de Hardware e Software.

Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Comparação ambiente homogêneo (Opção 1).

Como comentários das medidas, podemos afirmar que o desempenho em relação ao sistema heterogêneo, usado com duas agências, ou seja, dois computadores, os resultados evidenciam ainda mais a superioridade da arquitetura distribuída em relação à centralizada, mostra a arquitetura desta medida.

Deve-se levar em conta, também como na medida heterogenia, que os dados utilizados em cada agência são extraídos, transformados e carregados na própria agência, possibilitando os mesmos ganhos já descritos anteriormente.

Procura com base Centralizada.

Essa procura é de média complexidade na base com 1000000 clientes em cada agência e montagem do arquivo para o Portal.

Abaixo são mostrados os principais resultados das medidas feitas a partir do servidor com as bases distribuídas nas 4 agências e centralizada, totalizando 4000000 de clientes.

Os equipamentos utilizados nessa medidaforam homogêneos, ou seja, todos com as mesmas características de Hardware e Software.

Foram feitas 4 medidas de cada tipo e a média dos tempos de resposta foi a seguinte, Comparação ambiente homogêneo (Opção 2).

Como comentários das medidas, podemos afirmar que o desempenho em relação ao sistema heterogêneo, usado com duas agências, ou seja, dois computadores, os resultados evidenciam ainda mais a superioridade da arquitetura distribuída em relação à centralizada.

Os resultados das medidas de desempenho mostram as vantagens do uso Data Warehouse distribuído com relação ao Data Warehouse centralizado.

Essa caracterização foi feita através de um conjunto de medidas comparando-se a base centralizada com a base do mesmo tamanho, distribuída.

O modelo utilizado para simular o ambiente das agências é mais rigoroso, principalmente no aspecto de rede, pois com o uso de Hub o tráfego de rede fica sujeito a colisões o que não acontece no ambiente real, pois as linhas são individuais o mesmo acontecendo com os equipamentos de rede na entrada da matriz.

O trabalho realizado mostra, através dos resultados, a viabilidade de utilização do Data Warehouse distribuído.

As medidas práticas efetuadas comparam o uso do Data Warehouse centralizado com relação ao distribuído.

O número de clientes usados para comparação nos dois casos foi comparável, ou seja, o centralizado com a quantidade "n" vezes maior do que no distribuído, onde "n" é equivalente ao número de agências, no caso 3.

Para corporações que possuam distribuição geográfica, com recursos de informática nesses locais, têm-se também a vantagem financeira através da otimização e reaproveitamento de equipamentos, processadores, armazenamento secundário.

Normalmente, nas localidades distantes, encontra-se ociosidade tanto nos horários de alta quanto nos de baixa demanda.

Com o aumento crescente da quantidade de dados armazenados e utilizados nas organizações, o uso dos Data Warehouses distribuídos passa a ser muito vantajoso, pois possibilita o aproveitamento dos espaços de armazenamento em disco dos equipamentos de informática localizados distantes da matriz.

A solução implementada supõe que o comportamento dos usuários dos Data Warehouses, no ambiente bancário, está dividido em dois tipos de comportamento.

O primeiro tipo usa um conjunto de relatórios padrão que faz parte da rotina diária de trabalho.

No contexto do trabalho, esse tipo de relatório foi chamado de procuras pré-estabelecidas.

O outro comportamento do usuário do Data Warehouse é aquele que utiliza procuras Ad Hoc.

Esse comportamento também é aplicado a outros tipos de negócios, não só ao bancário.

Com o objetivo de facilitar o uso do sistema, foi implementado um Portal com os resultados das principais procuras pré-estabelecidas, podendo ser realizadas em horários de baixa demanda, aproveitando ainda mais os recursos de informática dos pontos distantes De forma geral, as contribuições deste trabalho estão relacionadas com o aumento de desempenho nas operações de entrada e saída, se valendo do uso de programação paralela para se obter esse resultado.

Foi criado um sistema de relacionamento com clientes, servindo para mostrar a viabilidade e escalabilidade do uso da arquitetura de Data Warehouses distribuídos.

A arquitetura proposta foi implementada num ambiente de laboratório, podendo ser implementada na prática no ambiente de produção.

O desenvolvimento do sistema proposto suporta grande quantidade de alternativas para novas funcionalidades.

Entre elas pode-se destacar, Desenvolvimento do Data Warehouse para o conjunto completo de produtos.

Estudar os aspectos de desempenho sob o ponto de vista da rede de comunicação entre a matriz e as agências.

Implementar um sistema tolerante à falha no ambiente distribuído.

Simulação do ambiente real do Banco, através de geradores de carga.

O diagrama ER representada as principais entidades do modelo a ser utilizado na solução.

A implementação desse modelo contemplando todos os produtos e será realizada num trabalho futuro.

A implementação atual foi feita para o produto cartão de crédito.

O modelo dimensional representa o negócio.

Neste caso, escolheu-se o modelo estrela e não flocos de neve por ser mais simples e ter melhor desempenho.

Escolheu-se também, a estrutura ROLAP (Relacional On Line Analytical Processing) para implementação.

O desempenho do ROLAP e sua flexibilidade são melhores.

As dimensões representam o negócio e a tabela de fatos, OperacaoCartaoCredito, as medidas.

O processo ETL (Extraction Transformation and Load) popula o modelo dimensional, retirando as informações do modelo relacional.

Existem várias ferramentas que geram relatórios como os dados dimensionais.

A seguir está descrito como obter os dados através desses relatórios.

OperacaoCartaoCredito é a tabela de fatos.

CartaCredito, Cliente, Endereço, Tempo, TipoBandeira e LocalCompra são as dimensões que definem o negócio.

Para as consultas pré-estabelecidas o modo de procura é, Relatório de Cartões de Crédito que vencem no mês atual.

