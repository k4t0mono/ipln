Um sistema paralelo é constituído de dois ou mais processos que colaboram para a realização de uma determinada tarefa.

Cada processo pode ser visto como um programa seqüencial em execução.

Os processos cooperam através do uso de memória compartilhada ou de trocas de mensagens.

Nos ultimos anos, tem crescido o interesse pela computação paralela.

Com equipamentos cada vez melhores, e custos relativamente mais baixos, é crescente o uso de processamento paralelo nas empresas e instituições de ensino e pesquisa.

As utilizações de programação paralela encontradas na bibliografia são inúmeras.

Algumas destas utilizações são apresentadas a seguir.

Muitas aplicações científicas e de engenharia com foco em simulações numéricas em que vastas quantidades de dados devem ser processados com o objetivo de criar ou testar um modelo são apropriadas para sistemas de processamento paralelo.

Exemplos deste tipo de uso dos sistemas paralelos são, Simulações da circulação atmosférica.

Circulação sangüínea no coração.
A evolução das galáxias.

Análises aerodinâmicas de componentes de aeronaves.

Movimento de partículas atômicas.

Otimização de componentes mecânicos.

Uma função cada vez mais importante da computação paralela está relacionada à bioinformática, no que diz respeito ao mapeamento de genes dos mais diversos seres vivos, possibilitando um entendimento da biologia nunca antes imaginado.

Pesquisas na area de bioinformática podem auxiliar a prevenir doenças, produzir alimentos mais saudáveis, combater pragas na agricultura, entre inúmeras outras possibilidades.

Outra aplicação significativa é a possibilidade de paralelizar sistemas de gerenciamento de bancos de dados, especialmente em situações com um alto número de transações por segundo ou quando casamentos de padrões complexos em grandes bases de dados estão envolvidos.

Esse tipo de sistema tem se tornado bastante comum nas grandes empresas, que precisam manter bancos de dados cada vez maiores e mais eficientes.

Existem ainda aplicações da programação paralela em inteligência artificial, um vasto campo de pesquisa da ciência da computação.

Algumas das utilizações da programação paralela em IA são, Busca através de regras de um sistema de produção.

Implementação de algoritmos genéticos.

Processamento de redes neurais.

Processamento de visão computacional.

A produção de imagens realistas para a televisão e o cinema também é uma possibilidade de utilização do processamento paralelo.

As aplicações da programação paralela continuam a se expandir para a resolução de diversos problemas nas mais diversas areas tecnológicas e científicas.

Com a diminuição do custo dos equipamentos e a melhoria das tecnologias de comunicação, os clusters tornam-se uma opção interessante para a maioria das aplicações que demandam alto desempenho.

Em comparação com computadores de grande porte, os clusters modernos apresentam custos de instalação e manutenção significativamente menores.

Além disso, pode-se ampliar a capacidade de processamento de um cluster simplesmente acrescentando novos equipamentos ao sistema.

Com a ampla utilização de clusters, o desenvolvimento de programas eficientes para sistemas multiprocessados é fundamental.

Os programas paralelos são naturalmente mais complexos do que os programas seqüenciais.

De acordo com Andrews, em muitos aspectos, os programas paralelos estão para os seqüenciais assim como o jogo de xadrez está para o jogo de damas.

Muitas vezes, centenas ou mesmo milhares de processos diferentes estão ativos no sistema.

Os processos envolvidos precisam trocar mensagens entre si constantemente para realizar suas tarefas.

Nos sistemas sem memória compartilhada a troca de mensagens é a unica forma de comunicação e sincronização entre os processos.

Tal complexidade dificulta significativamente o projeto e implementação das aplicações de processamento paralelo, bem como a identificação de eventuais ineficiências dos programas desenvolvidos.

Weihl ressalta que módulos em sistemas paralelos são mais complexos do que em sistemas seqüenciais.

Um procedimento, por exemplo, pode interagir com processos paralelos lendo e escrevendo em memória compartilhada ou trocando mensagens.

Desta forma, uma simples relação de entradas e saídas não é suficiente para descrever o comportamento de um procedimento ou função em sistemas concorrentes.

Outra característica apontada por Weihl é o equilíbrio entre desempenho e funcionalidade, que deve ser uma preocupação para aqueles que desenvolvem sistemas paralelos.

Uma das questões centrais para análise do funcionamento deste tipo de sistema distribuído baseado em mensagens é a relação entre o tempo de comunicação e o tempo de processamento.

A comunicação é um fator chave por tratar-se de uma operação que consome um tempo excessivamente grande se comparado com as altas freqüências de operação atingidas pelos processadores modernos.

Quando não há um controle sobre essas operações e os momentos em que as mesmas devem ser executadas em um programa, pode-se comprometer demasiadamente a eficiência do programa, diminuindo e, em alguns casos extremos, até anulando as vantagens do processamento paralelo.

Bertsekas e Tsitsiklis dividem o atraso proveniente da comunicação em quatro partes, Tempo de processamento da comunicação, Tempo requerido para preparar a informação para a transmissão.

Tempo de fila, Espera por uma série de eventos tais como, disponibilidade de canais de comunicação, envio de outras mensagens, disponibilidade de recursos como espaço em buffer no destino, retransmissões para correção de erros, etc.

Tempo de transmissão, Tempo requerido para a transmissão de todos os bits da mensagem.

Tempo de propagação, Tempo entre a transmissão do ultimo bit da mensagem pelo emissor e o recebimento do mesmo bit no destino.

A sincronização entre processos é outro fator citado por Bertsekas e Tsitsiklis como fundamental no desempenho de sistemas paralelos.

Sistemas síncronos tendem a sofrer uma diminuição no seu desempenho.

E necessário encontrar o equilíbrio entre sincronização e desempenho apropriado para cada aplicação específica.

Kumar colocam entre as principais questões que envolvem computação paralela os métodos para a avaliação de algoritmos paralelos.

Dado um determinado computador paralelo e um algoritmo paralelo, é necessário avaliar o desempenho do sistema resultante.

Tal avaliação de desempenho deve buscar esclarecer questões sobre a velocidade e eficiência do sistema na solução do problema.

Percebe-se, atualmente, uma tendência para a pesquisa e desenvolvimento de sistemas e aplicações utilizando grids computacionais.

Aplicações paralelas neste tipo de plataforma apresentam um comportamento ainda mais complexo devido a heterogeneidade do sistema.

Uma arquitetura de grid conta com diferentes tipos de equipamentos, sistemas operacionais e tecnologias de comunicação, ao contrário dos clusters que geralmente são mais homogêneos nestes aspectos.

Uma das principais interfaces para comunicação utilizada em sistemas paralelos é a Message Passing Interface (MPI).

Trata-se de um conjunto de rotinas que realizam tarefas de comunicação entre os processos em um sistema paralelo, tais como, envio e recebimento de mensagens, broadcast, multicast e sincronização.

A MPI oferece também uma interface para profiling que simplifica a obtenção de informações a respeito das rotinas de comunicação e sincronização em tempo de execução.

Para Lucas Jr, a avaliação de desempenho é de vital importância na escolha de um determinado sistema entre duas ou mais opções, no desenvolvimento de aplicações e equipamentos, e na análise de equipamentos e softwares em uso.

Desta forma, a comparação do desempenho de diferentes arquiteturas, a avaliação de protótipos em desenvolvimento e o monitoramento do comportamento real de um determinado sistema são os três propósitos gerais da análise de desempenho para Lucas Jr.

Em face a complexidade dos sistemas paralelos, a importância da análise de desempenho e a crescente utilização de concorrência nas mais diversas aplicações, o presente trabalho apresenta os seguintes objetivos, Estudar o problema da análise de desempenho de sistemas distribuídos, com ênfase no processamento paralelo baseado em troca de mensagens.

Apresentar algumas abordagens ao problema encontradas na literatura e em produtos comerciais.

Desenvolver um conjunto de técnicas e metodologias, apoiadas por ferramentas de software, que possam ser utilizadas no profiling de programas paralelos que utilizam a MPI.

Deseja-se atender da melhor forma possível à comunidade científica em suas necessidades de análise de estratégias e algoritmos de programação paralela em um número significativo de plataformas com diferentes configurações de hardware.

Procurar novas formas de visualização da execução de sistemas que evidenciem características fundamentais na análise de desempenho, tais como, a eficiência das comunicações, identificação de gargalos, o funcionamento de algoritmos e o balanceamento da carga de processamento.

A elaboração de formas de visualização apropriadas para a análise de desempenho de sistemas concorrentes representa uma area ainda em desenvolvimento.

Encontram-sé disponíveis ferramentas comerciais e, também, alguns trabalhos acadêmicos na area.

Este trabalho apresenta metodologias e técnicas para o problema da análise de desempenho de sistemas paralelos através do uso de técnicas de profiling e do desenvolvimento de novas formas de visualização da execução de programas paralelos.

No próximo capítulo é demonstrado o processo de profiling.

A seguir, são descritos trabalhos relacionados que também buscam uma avaliação do desempenho de sistemas distribuídos.

São apresentadas as ferramentas de profiling desenvolvidas neste trabalho.

Após a apresentação das ferramentas, são mostrados resultados obtidos através do uso das ferramentas desenvolvidas para analisar o desempenho de algumas aplicações paralelas.

São discutidos, ainda, alguns aspectos da implementação das ferramentas de software.

Por fim, são expostas algumas conclusões do trabalho e suas referências bibliográficas.

Profiling é definido por Bernecky como sendo a análise de um programa em execução a fim de determinar seu comportamento real em comparação ao esperado.

As técnicas de profiling facilitam o acompanhamento de programas computacionais em execução.

Tais técnicas têm por objetivo auxiliar aqueles que desenvolvem as aplicações a compreender melhor o comportamento dos programas.

Como o próprio nome sugere, as ferramentas de profiling buscam traçar um "perfil" do funcionamento do programa, estabelecendo quais as rotinas e operações que consomem o maior tempo, a quantidade de tempo consumido, quais rotinas acionam quais outras, como se dá o fluxo de dados, entre outras características, buscando sempre facilitar a análise do sistema.

As etapas do processo de profiling.

Estas técnicas são especialmente importantes em sistemas com muitos processos, em que mesmo os analistas mais experientes encontram dificuldades para identificar eventuais ineficiências.

Os sistemas distribuídos nos quais existe processamento paralelo costumam apresentar um nível de complexidade considerável, portanto representam uma importante aplicação para sistemas de profiling.

O processo de profiling, em geral, envolve a coleta de um determinado conjunto de dados em tempo de execução e a exibição de tais dados de forma que facilitem a identificação de problemas relativos ao desempenho da aplicação em estudo.

Especialmente em sistemas complexos com muitos processos envolvidos é fundamental uma apresentação dos dados que facilite a identificação de ineficiências.

Pode-se dividir, de maneira geral, um processo de profiling em quatro etapas distintas, definição dos dados a serem coletados, coleta de dados, filtragem ou tratamento dos dados e apresentação gráfica de resultados.

Nas próximas seções são descritas as etapas do processo de profiling.

A primeira etapa consiste na definição dos dados que devem ser coletados, tais como, tempo de processamento, tempo ocioso e tempo de comunicação de cada processo.

E fundamental que sejam definidos os eventos do sistema que são importantes para a análise do desempenho do sistema, para que se possa obter os registros destes eventos nas etapas seguintes.

Define-se um evento como sendo uma mudança de estado de um processo, como o início ou o fim de uma atividade de comunicação ou de uma operação de E/S, por exemplo.

A segunda etapa se dá em tempo de execução dos processos estudados pelo sistema de profiling.

Nesta etapa, deve-se obter os registros dos eventos na medida em que vão acontecendo.

Deve ser registrado o tipo do evento, um rótulo relativo ao tempo em que o mesmo ocorreu (neste ponto, o tempo local do processador em que o evento acontece é suficiente), e alguns dados específicos como o tamanho de uma mensagem, sua origem e destino, por exemplo.

Uma forma comum de se registrar estes dados é através da instrumentação de pontos apropriados dos programas.

A técnica básica utilizada por ferramentas de profiling de sistemas de processamento paralelo é a manutenção de arquivos de trace, que apresentam os tempos de início e final dos eventos a serem considerados em um sistema.

A própria especificação da MPI define uma interface para profiling.

Esta interface pode ser utilizada para a criação de bibliotecas contendo rotinas com o mesmo nome das rotinas da MPI.

Estas, por sua vez, acionam as rotinas originais da MPI, registrando a informação em um buffer antes e/ou depois da chamada a função MPI em tempo de execução.

O buffer é, sempre que necessário, gravado em disco.

Existe inclusive um banco de dados público contendo uma série de arquivos de trace que são de extrema importância para a análise de diferentes problemas.

Esses arquivos públicos podem servir como entradas para as ferramentas de profiling, ampliando assim as possibilidades de seus testes e de seu uso na análise das mais diversas situações, sem necessariamente ter de repetir implementações e experimentos já realizados para se obter uma análise dos respectivos resultados.

E também na etapa da geração dos arquivos de trace que devem estar concentrados os esforços para minimizar a intrusão, já que o registro dos eventos é a unica etapa do profiling que deve, necessariamente, se dar em tempo de execução do sistema analisado.

As demais etapas, em geral, são baseadas na análise posterior destes arquivos de trace, sem concorrer com o processo estudado.

Uma das principais razões para que esta etapa consista apenas em registrar os eventos, minimizando qualquer carga adicional no sistema é justamente minimizar a intrusão, fazendo com que o programa se comporte de forma tão semelhante quanto possível a uma situação real.

O resultado desta etapa é um arquivo contendo dados brutos de cada evento considerado relevante.

Este tipo de arquivo é chamado de arquivo de trace.

Em geral, tais arquivos apresentam uma grande quantidade de dados, sem qualquer filtragem ou otimização que possibilite um estudo adequado do programa.

Tel apresenta três diferenças básicas entre sistemas distribuídos e sistemas centralizados, a falta de conhecimento do estado global do sistema, a falta de uma referência de tempo global e o não determinismo.

Devido a estes aspectos, ordenar os eventos que acontecem em um sistema distribuído não é uma tarefa trivial.

Uma diferença na freqüência dos clocks de dois processadores pode gerar registros de mensagens enviadas em um tempo posterior ao seu recebimento em outro processador, o que é absurdo.

Na terceira etapa do processo de profiling mostrado, tem-se a preocupação de ordenar os eventos de forma correta e buscar uma forma apropriada de estimar o tempo decorrido entre os eventos com o objetivo de analisar o desempenho do sistema.

A ordenação dos eventos pode ser obtida através de técnicas conhecidas como relógios lógicos, mas o tempo transcorrido entre dois eventos em processadores diferentes requer um tempo de referência global para todo o sistema.

Nesta fase, é muito importante o estudo de formas de sincronização e ordenação de eventos do sistema.

Uma das principais metodologias para a ordenação de eventos é o uso de relógios lógicos.

Um relógio lógico se preocupa em determinar relações de causalidade entre eventos que ocorrem em diferentes processos no sistema distribuído.

E definida a relação de causalidade "acontece antes", denotada por.

Assim, se o evento a "acontece antes" do evento b, escreve-se, a b.

Esta relação é transitiva, ou seja, se a b e b c, então a c.

Diagrama de tempo de uma execução distribuída.

Ilustra um diagrama de tempo onde cada linha representa um processo em um sistema distribuído.

Pode-se perceber, por exemplo, que e f e conseqüentemente, e g, e k e e l.

Por outro lado, nada podemos afirmar sobre a relação entre i e g sem uma referência de tempo global.

Eventos que não apresentam relações de causalidade, como i e g são ditos eventos paralelos.

Uma eventual troca na ordem de eventos paralelos não causa alterações em estados futuros do sistema.

Os relógios lógicos ordenam os eventos do sistema, respeitando as relações de causalidade.

Os eventos paralelos recebem valores ordenados de alguma forma arbitrária.

Existem ainda relógios lógicos cujos valores são vetores ou matrizes, e não valores escalares.

Neste tipo de abordagem, cada evento é registrado com o valor de seu tempo lógico local, mais as informações que o processo tinha a respeito dos tempos de outros processadores no momento do evento.

Com esse tipo de relógio lógico é possível, por exemplo, dados os valores de tempo lógico de dois eventos quaisquer, determinar se os mesmos são paralelos ou se obedecem a alguma relação de causalidade, o que não é possível com a utilização de valores de tempo lógico escalar.

Este tipo de algoritmo de sincronização é uma das bases de funcionamento dos sistemas distribuídos, evitando situações de conflito que seriam comuns se não houvesse este tipo de preocupação.

Mesmo com a utilização dos relógios lógicos, não é possível determinar o tempo decorrido entre dois eventos.

Por exemplo, não é possível, sem uma referência de tempo global, determinar quanto tempo se passou entre os eventos e e f.

Maillet e Tron apresentam algoritmos para a implementação de uma referência de tempo global para avaliação de desempenho em sistemas multiprocessados.

A idéia é colher amostras dos tempos individuais de cada processador do sistema antes e/ou depois da execução dos processos em estudo.

A partir destas amostras, identifica-se através de métodos estatísticos uma relação linear entre cada um destes tempos locais e o tempo global (em geral o tempo de um processador escolhido como referência).

Quanto maior for a amostra, mais preciso será o tempo global obtido para os eventos.

Coletar este tipo de amostra envolve um tempo considerável de trocas de mensagens entre os processadores do sistema, e pode tornar o processo de profiling um pouco lento, embora não haja nenhuma intrusão adicional na aplicação em si.

No caso do profiling, evidentemente, é fundamental uma preocupação com a ordenação e com o tempo de cada evento que ocorre no sistema, pois disponibilizar estas informações da maneira mais correta possível é a própria razão de ser das técnicas de profiling nos sistemas distribuídos.

Busca-se a extração de informações relevantes dos arquivos de trace obtidos anteriormente.

Procura-se descobrir quais as informações mais importantes para o analista, o que é necessário para identificar eventuais ineficiências da implementação estudada.

Tendo estipulado quais as informações desejadas, passa-se à implementação de ferramentas que automatizem a extração das informações dos arquivos de trace.

Abordagens conhecidas são a classificação dos eventos de acordo com um padrão determinado previamente como sendo o comportamento normal daquele evento.

Se o evento ocorrido no sistema e registrado no trace apresenta uma diferença significativa em comparação ao padrão, a execução deste evento pode ser classificada como ineficiente.

E importante perceber que o padrão estabelecido deve ser específico para cada arquitetura de hardware e carga de software, para refletir a real característica da situação estudada.

Este padrão pode ser estabelecido, por exemplo, em testes pouco antes da execução do programa que vai gerar o arquivo de trace, para refletir da melhor forma possível as características do sistema.

Também nesta fase são obtidas estatísticas de tempos dos eventos, de atividade de cada processador entre outras informações.

Outra preocupação é tentar identificar no código fonte, as modificações que podem melhorar a performance do programa.

Embora este tipo de abordagem possa requerer arquivos de trace diferenciados, e ferramentas mais sofisticadas.

Tendo os eventos adequadamente ordenados e uma referência global, é necessário identificar as características do sistema.

A ultima etapa consiste em desenvolver formas dé apresentação destes resultados que facilitem a identificação, por parte do usuário, dos pontos cruciais do seu programa que podem melhorar o desempenho.

Esta fase representa um dos maiores desafios do desenvolvimento de técnicas de profiling.

E necessário buscar formas de sintetizar o grande volume de informações produzidos nas etapas anteriores simplificando a tarefa de identificar pontos fortes e fracos do sistema estudado.

Isto é geralmente obtido através de gráficos.

A apresentação gráfica dos resultados facilita bastante a análise dos problemas, especialmente em sistemas grandes e complexos, onde a quantidade de dados é bastante extensa, dificultando a correção de problemas e ineficiências.

A visualização do funcionamento dos programas paralelos através de gráficos e diagramas permite ao usuário um entendimento dos sistemas dificilmente obtidos de outra forma.

Além disso, gráficos podem sintetizar grandes quantidades de dados em uma unica imagem.

Para a geração dos gráficos de análise de desempenho existem opções que vão desde a programação com bibliotecas gráficas como a OpenGL até a utilização de ferramentas de visualização científica existentes.

As ferramentas de visualização científica, apesar de serem idealizadas para a visualização de fenômenos naturais podem ser utilizadas para representar o comportamento de sistemas de computação paralela.

Técnicas bastante utilizadas são gráficos de linha de tempo, ou diagramas de Gannt, que podem ser elaborados diretamente a partir dos arquivos de trace e representam uma visão excelente dos acontecimentos envolvidos no sistema.

Representa um exemplo simples deste tipo de gráfico, com apenas dois processos e as operações MPI_Send e MPI_Recv (envio e recebimento de mensagens, respectivamente).

Observa-se facilmente que a segunda mensagem, enviada do módulo 2 para o módulo 1, foi enviada com atraso, pois o processo de destino está pronto para receber a mensagem muito antes do seu envio.

Em situações onde existem inúmeras atividades e processos a serem considerados, gráficos deste tipo podem ser extremamente uteis.

Exemplo simples de gráfico de linha de tempo com dois processos.

Os diagramas de Kiviat, por exemplo, foram uma das primeiras formas de visualizar a performance de sistemas multiprocessados.

Neste tipo de gráfico, cada processador é representado por um eixo radial em uma circunferência.

O grau de utilização do processador é um ponto no eixo correspondente.

Sendo 0% de utilização representado por um ponto no centro do círculo e 100% de utilização por um ponto no seu perímetro.

Foi gerada por Hackstadt e Malony, utilizando o software Visualization Data Explorer (DX) da IBM.

Na representação utilizada, cada processador é mostrado em uma cor diferente.

Este tipo de diagrama apresenta apenas o estado do sistema em um dado momento.

Pode-se utilizar uma animação para exibir passo-a-passo os diagramas de Kiviat dos processos em execução, mas ainda assim não se tem uma idéia geral do funcionamento do sistema.

É gerado um tubo de Kiviat.

Esta estrutura é desenhada a partir dos dados que geram diagramas de Kiviat, com um eixo perpendicular aos diagramas representando o tempo, possibilitando que se tenha uma visualização do comportamento de toda a execução.

Apresenta um quadro de uma animação que mostra passo-a-passo a execução, possibilitando que se tenha a visão do desempenho do sistema em cada etapa.
Diagrama de Kiviat tradicional, em 2 D.

Tubo de Kiviat formado pelas duas dimensões do diagrama de Kiviat tradicional e o tempo como terceira dimensão.

Quadro de animação de um tubo de Kiviat.

Outro tipo de gráfico bastante util são aqueles que mostram as estatísticas de cada processo.

Através de gráficos circulares em setores, ou em barras, pode-se identificar facilmente características importantes como o tempo consumido pelos processos em cada atividade.

Pode-se ainda apresentar animações representando que atividade cada um dos processadores está executando a cada momento, possibilitando uma análise passo-a-passo do funcionamento do sistema como um todo.

A apresentação gráfica de dados obtidos em profiling e em simulações da execução de sistemas distribuídos ainda é uma area em pleno desenvolvimento, tendo muitas possibilidades a serem exploradas pelos pesquisadores.

O presente trabalho procura encontrar formas adequadas de se conduzir cada uma das etapas descritas.

Busca-se discutir as técnicas encontradas na literatura e em ferramentas comerciais e identificar metodologias eficientes para a análise do funcionamento e do desempenho de sistemas multiprocessados que utilizam trocas de mensagens, mais especificamente o padrão MPI.

Neste capítulo são demonstradas algumas técnicas encontradas na literatura e ferramentas disponíveis para análise de desempenho de sistemas distribuídos.

Em geral, as ferramentas disponíveis utilizam gráficos de linha de tempo como principal forma de visualização das atividades do sistema paralelo.

Gráficos estatísticos também são bastante comuns nas abordagens estudadas.

Vampir (Visualization and Analysis of MPI Resources) e Vampirtrace formam um conjunto de ferramentas comerciais para análise de desempenho de programas paralelos que utilizam a MPI.

O Vampirtrace é o software responsável pela geração de arquivos de trace.

O formato utilizado pelo Vampir é chamado de STF (Structured Trace File Format).

Uma das principais vantagens deste formato, segundo o fabricante, é sua escalabilidade e uma representação dos dados compacta.

O Vampirtrace inclui uma biblioteca de profiling para ser utilizada na geração dos dados do trace.

A partir do trace em formato STF, a ferramenta Vampir apresenta uma série de formas de visualização para programas MPI.

Demonstra um diagrama de linha de tempo, conforme gerado pela ferramenta Vampir.

A ferramenta permite a obtenção de informações adicionais sobre mensagens específicas tais como tamanho da mensagem, tempo de transmissão e comunicador MPI utilizado.

Pode-se ainda identificar a mensagem no código-fonte.

O gráfico em linha de tempo gerado pelo Vampir define diferentes atividades, tais como atividades da MPI e da aplicação.

Cada atividade é representada por uma cor diferente.

Na parte inferior são mostrados quantos processos estão realizando uma determinada atividade em cada instante.

O diagrama de linha de tempo apresenta inicialmente todo o tempo de execução.

A partir da representação inicial, pode-se realizar operações de zoom para que se possa visualizar mais claramente trechos específicos da execução.

Além do diagrama de linha de tempo, a ferramenta Vampir apresenta uma série de possibilidades de visualização diferentes.

Os gráficos estatísticos são bastante uteis na análise de sistemas paralelos.

Demonstra gráficos em setores, também gerados pelo software Vampir.

Estes gráficos permitem que se observe o tempo total consumido pelas diferentes atividades (computação, comunicação, etc) em cada um dos processos.

Todas as operações da MPI são representadas como uma unica atividade denominada MPI.

Esta abordagem impossibilita que o usuário identifique o tempo consumido por cada uma das rotinas individualmente.

O software permite também determinar quais pares de processos trocam maiores quantidades de dados.

Um diagrama como o reproduzido revela este tipo de informação.

O uso de atividades em gráficos estatísticos e de linha de tempo pode, em muitos casos, ser uma generalização inconveniente.

Colocar todas as rotinas MPI como uma unica atividade, por exemplo, inclui operações como broadcast, multicast, mensagens ponto a ponto e operações de sincronização em uma mesma atividade.

O fabricante justifica o uso das atividades como conjuntos de operações pelo fato de o número de operações eventualmente ser muito grande para que se possa representá-lo adequadamente por meio de cores.

O gráfico mostra claramente a quantidade de informação trocada entre os pares de processos, mas não apresenta nenhuma informação referente ao desempenho da comunicação realizada.

Troca de informações entre processos.

O Jumpshot é uma ferramenta de visualização baseada em gráficos de linha de tempo.

A aplicação utiliza arquivos de trace no formato SLOG-2 (Scalable Logfile), obtidos através da extensão a MPI chamada MPE (MultiProcessing Environment).

Este tipo de arquivo também é utilizado pelas ferramentas propostas no capítulo 4.

De forma semelhante a ferramenta Vampir, discutida anteriormente, o Jumpshot permite operações de zoom para a visualização de detalhes da execução.

São mostradas todas as rotinas MPI executadas pela aplicação alvo no diagrama de linha de tempo.

Estados definidos pelo usuário no código-fonte através da MPE também são representados no gráfico.

As mensagens são representadas por setas ligando processos emissores e receptores no diagrama.

A ferramenta Jumpshot.

Em visões mais globais de execução de programas, são utilizados estados e setas especiais (preview states e preview arrows) que representam conjuntos de estados e mensagens.

Com um nível mais detalhado de zoom torna-se possível observar estados e mensagens individuais.

O Paragraph é um conjunto de ferramentas de visualização para programas MPI.

Para a geração dos arquivos de trace é utilizada uma biblioteca chamada PICL (Portable Instrumented Communication Library), posteriormente adaptada para a MPI e denominada MPICL.

A ferramenta apresenta uma série de formas de visualização que podem ser classificadas em três tipos, visualizações de utilização, de comunicação e de tarefas.

As visualizações de utilização classificam os processadores do sistema em ociosos, ocupados ou sobrecarregados (utilizando comunicação).

Tais visualizações incluem gráficos de Gannt, diagramas de Kiviat, contagem de processos em cada estado (ocioso, ocupado ou sobrecarga), entre outras.

As visualizações de comunicação incluem gráficos de linha de tempo, gráficos representando o tráfego de mensagens (curvas representando o total de mensagens ou bytes enviados mas ainda não recebidos pelo tempo), informações referentes a filas de mensagens e animações em grafos e hipercubos representando redes de comunicação.

Visualizações de tarefas demonstram estados definidos pelo usuário através da biblioteca MPICL em gráficos de Gannt, contagens do número de processos em cada tarefa pelo tempo, etc.

Visualizações da ferramenta PVaniM de ferramentas para profiling de aplicações PVM (Parallel Virtual Machine).

A ferramenta apresenta algumas visualizações.

No canto superior esquerdo é apresentada uma lista dos computadores utilizados e a quantidade de tarefas alocadas em cada máquina.

Ao lado, é mostrado um gráfico em barras indicando o número médio de tarefas em execução no nó.

Os gráficos com barras verdes, amarelas e vermelhas representa em verde o tempo consumido com computação, em amarelo o tempo consumido em envio de mensagens e em vermelho o tempo ocioso de espera por comunicações, sendo um gráfico com valores relativos a processadores e o outro com valores relativos a cada tarefa.

O gráfico no canto superior direito da mesma figura representa a memória utilizada pelas tarefas PVM em cada processador.

O gráfico na parte inferior esquerda da figura mostra o número de mensagens e de bytes enviados em um determinado intervalo.

Por fim, a visualização da parte inferior direita mostra a quantidade de mensagens trocadas entre cada par de tarefas.

Existem na literatura ainda outras ferramentas de profiling.

Uma abordagem proposta por Vetter procura classificar as mensagens trocadas no sistema em normais, de recebimento tardio, de envio tardio, entre outras classificações.

Desta forma, o analista pode alterar o programa, retardando ou antecipando as operações que estão sendo executadas antes ou depois de seu tempo ideal.

Segundo o autor, alterações deste tipo podem melhorar significativamente o desempenho de aplicações distribuídas baseadas em troca de mensagens.

Rabenseifner descreve uma solução mais voltada para os administradores de sistemas, apresentando estatísticas semanais e mensais do uso do equipamento pelos diferentes usuários e sistemas, indicando possíveis ineficiências dos programas.

Existem ainda outras soluções que priorizam a carga de processamento de cada processador.

Oliveira e Midorikawa propõem uma metodologia para predição da performance das rotinas MPI.

Tal estudo é bastante relevante em teoria ou em situações próximas do ideal, como em clusters dedicados a uma aplicação específica.

Em casos mais gerais como clusters não dedicados ou em grids torna-se inviável fazer uma previsão confiável do desempenho da comunicação devido a interferência de outras aplicações e usuários no tráfego da rede de comunicações e na carga dos processadores.

Neste capítulo são discutidos brevemente alguns aspectos da coleta de dados utilizada.

A seguir as ferramentas de software de visualização desenvolvidas são apresentadas.

Considera-se fundamental que seja possível através das ferramentas identificar as seguintes características básicas de um sistema paralelo, Desempenho das rotinas de comunicação e sincronização.

Identificação da dependência (espera) entre os processos.

Distribuição de carga entre os processadores.

Comportamento de algoritmos.

Acredita-se que a identificação das características citadas permite a identificação de muitos gargalos e ineficiências de aplicações.

Foram definidos como dados relevantes a serem coletados para que as ferramentas pudessem atingir seu objetivos, A ocorrência de todas as rotinas MPI na aplicação alvo com um rótulo de tempo de acordo com um relógio global, bem como a duração de cada chamada.

Processos emissores e receptores de cada mensagem.

As rotinas MPI associadas a cada mensagem nos processos emissor e receptor.

Rótulos de tempo e duração de trechos do programa definidos pelo usuário.

Informações referentes à utilização (carga) dos processadores.

Durante a pesquisa sobre profiling, percebeu-se que todos os requisitos citados, com exceção das informações sobre a carga dos processadores, eram atendidos pela extensão a MPI denominada MPE (MultiProcess Environment).

O sistema de armazenamento e acesso aos dados da MPE também mostrou-se adequado.

Os formatos de arquivos CLOG e SLOG-2 permitem o armazenamento e a pesquisa dos dados de profiling de maneira bastante escalar.

Desta forma, grandes quantidades de dados podem ser armazenados de forma eficiente e dados específicos podem ser encontrados rapidamente mesmo em arquivos bastante grandes.

O grau de intrusão da MPE também mostrou-se bastante satisfatório.

Os dados referentes aos eventos a serem registrados são armazenados em buffers de memória locais em tempo de execução.

As informações da memória são gravadas em arquivos temporários locais conforme a necessidade.

Os dados dos diferentes processos só são combinados em um unico arquivo após o término da execução da aplicação alvo, de forma que não há operações de comunicação por parte da MPE durante a execução da aplicação alvo.

Assim, a intrusão limita-se a operações de acesso a memória e eventuais operações locais de entrada e saída.

Outro fator favorável ao uso da MPE é sua popularidade.

A biblioteca é distribuída individualmente ou em conjunto com a implementação da MPI chamada MPICH, sempre como software livre.

Já existem versões da biblioteca para uma série de sistemas, incluindo várias versões de Unix, Linux, Windows, plataformas como IBM SP, Intel i860, Delta, Paragon e Cray T3 D.

O relógio global da MPE é extremamente simples.

E utilizado apenas um ponto de sincronização entre os processos ao final da execução e o tempo desta sincronização é tido como referência para o cálculo dos tempos globais de todos os eventos.

Esta abordagem mostrou-se apropriada, embora não seja totalmente confiável em períodos de execução muito longos.

Dado que mecanismos de relógio global mais sofisticados tendem a aumentar a intrusão significativamente ou exigir longos períodos de sincronização antes e depois de cada execução da aplicação alvo, optou-se pelo uso da MPE apesar da limitação da sua implementação de relógio global.

Para obtenção dos dados referentes à carga dos processadores, foi desenvolvida uma aplicação MPI denominada cpustatmpi que, em conjunto com a MPE coleta dados da carga local em cada um dos processadores durante o tempo de execução da aplicação alvo.

Mais detalhes sobre a coleta de dados e os formatos dos arquivos utilizados pela MPE e pelo cpustatmpi são discutidos na seção 6 1 Esta ferramenta apresenta uma animação da execução do sistema.

Cada processo é representado por um quadrado em uma matriz.

A cor de cada processo muda de acordo com seu estado em cada momento da execução.

A legenda na parte direita da figura apresenta todas as rotinas MPI presentes na aplicação, bem como estados definidos pelo usuário através da MPE.

A ferramenta mostra também o tempo representado pelo quadro de animação mostrado, alguns botões de controle e menus.

A ferramenta de animação de processos.

Os botões de controle na interface permitem a exibição da animação em velocidade normal, buscando aproximar-se do tempo real, ou em slow motion.

O slow motion torna mais fácil a visualização do funcionamento de partes específicas da execução.

Botões de avanço e retrocesso rápidos permitem uma navegação eficiente através da animação para que o usuário possa encontrar as partes mais relevantes da execução da aplicação rapidamente.

Um controle deslizante também é disponibilizada para uma navegação ainda mais eficaz.

O número de quadros por segundo de tempo de execução da aplicação alvo pode ser alterado através do menu apropriado.

Este recurso permite que se possa encontrar a melhor relação entre a velocidade da animação e o nível de detalhe com que se deseja trabalhar.

Muitas ferramentas de análise de desempenho para sistemas paralelos, discutidas no capítulo 3, usam gráficos de linha de tempo ou diagramas de Gannt para representar a execução de programas paralelos.

Comparada a este tipo de gráfico, a animação de processos apresenta algumas vantagens, tais como a identificação de estruturas de repetição como loops freqüentemente encontradas em algoritmos distribuídos.

A animação também torna simples a identificação de grupos de processos que se comportam de maneira semelhante.

Também é possível identificar diferenças de comportamento indesejadas entre tais grupos de processos.

A animação torna possível uma visão apropriada de detalhes de uma execução paralela, ao passo que gráficos de linha de tempo permitem uma melhor idéia geral de toda a execução.

Neste sentido, as duas formas de visualização podem ser vistas como complementares.

A ferramenta permite ainda que se altere a topologia da animação.

Através de uma opção em um menu pode-se escolher o número de linhas e colunas de processos representados.

Esta opção é util sempre que uma topologia física ou lógica do sistema é relevanté para a aplicação ou para sua análise.

E possível adaptar a visualização para representar adequadamente características da rede física ou características lógicas definidas pela aplicação.

Uma das maiores questões com relação ao desempenho de sistemas distribuídos é o tempo consumido por cada processo enquanto espera pelos demais.

E proposta uma forma de visualização que torna possível identificar claramente o tempo de espera dos processos por cada um dos demais processos e também o tempo de espera por rotinas de comunicação coletiva e sincronização.

Através da definição de estados de espera como o recebimento de uma mensagem, pode-se calcular quanto tempo um processo espera por cada um dos demais.

Este tempo de espera é comparado a seguir com o tempo total de execução do sistema e com o tempo total de espera do processo em questão.

A representação é feita através de um quadro de tamanho p × p, onde p é o número de processos no sistema.

Cada linha i no gráfico representa um processo.

Cada coluna j representa um processo pelo qual o processo i espera por um determinado tempo.

A cor de cada célula no gráfico representa uma determinada percentagem de tempo consumida por i esperando por j.

Esta percentagem pode ser em relação ao tempo de execução ou em relação ao tempo total de espera, de acordo com a opção escolhida pelo usuário através dos botões de rádio disponíveis na parte inferior da interface.

O gradiente de cores a direita permite uma fácil identificação dos processos que esperam por maiores quantidades de tempo, e por quais processos esperam.

Também é possível identificar quais processos fazem com que outros processos esperem mais tempo.

Desta forma, pode-se identificar gargalos onde um grande número de processos esperam por alguns poucos.

Nestes casos, uma possível solução é redistribuir a carga de processamento, passando algumas das tarefas dos processos ocupados para os processos que esperam muito.

As duas colunas mais a direita no gráfico tem significados especiais.

A penúltima coluna da esquerda para a direita representa o tempo de espera por operações coletivas, como comunicação coletiva broadcast, multicast, etc) e sincronização.

A coluna mais a direita do gráfico representa o tempo de espera total de cada processo.

Tempo de espera relativo ao tempo total de espera.

Demonstra a possibilidade de mostrar os valores como percentagens dos tempos totais de espera.

Esta opção é importante, pois torna possível uma identificação mais precisa das diferenças entre os tempos de espera individuais de cada processo.

Especialmente em casos onde o tempo de espera é pequeno em comparação com o tempo total de execução.

As formas de visualização são complementares.

E possível identificar quais os processos que esperam mais tempo na representação mais geral e, a seguir, verificar a distribuição do tempo de espera de tais processos em mais detalhes conforme mostrado.

Tempos de espera inferiores a 0,1 por cento do tempo de execução e do tempo de espera não são incluídos nas representações.

Isto é feito porque tais tempos de espera geralmente representam trocas rápidas de mensagens que muitas vezes ocorrem em fases de sincronização que tendem a preencher a maior parte das células do gráfico com informação irrelevante.

A exibição de tais dados dificultaria o reconhecimento por parte do usuário da informação realmente importante representada pelos casos em que ocorrem tempos de espera significativos.

Nas ferramentas de profiling pesquisadas não foram encontradas formas de visualização que permitissem este nível de detalhamento dos tempos de espera dos processos.

A ferramenta mostrada apresenta a distribuição de carga das aplicações.

Como na ferramenta de animação de processos, o sistema é representado por uma matriz de processos.

A porcentagem de tempo de uso da CPU é mostrada para cada processo.

Quanto maiores forem as porcentagens de tempo de uso, melhor será o aproveitamento dos recursos computacionais.

E importante notar que a ferramenta mede o uso das CPU's, independentemente das aplicações que estejam sendo executadas no momento da coleta de dados (tempo de execução da aplicação alvo).

Isto significa que a ferramenta mede o uso da CPU por todos os processos ativos no sistema, e não somente pelos processos da aplicação alvo.

Desta forma é possível avaliar a distribuição de carga do sistema em situações reais de utilização, com outras aplicações em execução.

Também é possível estudar o comportamento da aplicação isoladamente, executando apenas a aplicação alvo e os processos básicos do sistema operacional no momento da coleta de dados (geração do arquivo de trace).

A ferramenta também exibe estatísticas totais da distribuição de carga.

Isto é feito através da exibição dos valores médios obtidos durante toda a execução da aplicação alvo.

As cargas totais são mostradas no quadro inicial da ferramenta e podem ser vistas a qualquer momento, sempre que a animação é parada.

Esta ferramenta, assim como a ferramenta de animação de processos, suporta visualizações com diferentes topologias através da definição do número de linhas e colunas em que os processos devem ser organizados na representação.

A ferramenta de distribuição de carga.

Esta animação apresenta o tráfego de mensagens no sistema.

O sistema é representado por uma matriz p×p de conexões entre processos, sendo p o número de processos.

Uma area colorida representa a transmissão de uma mensagem no momento representado.

As linhas representam processos emissores e as colunas, processos receptores de mensagens.

As cores representam a taxa de transmissão efetiva da mensagem, conforme indicada pelo gradiente de cores a direita.

Neste trabalho, considera-se como taxa de transmissão efetiva a quantidade de bits transmitidos dividida pelo tempo transcorrido entre o início do procedimento de envio da mensagem no processo emissor e o final do procedimento de recebimento no processo receptor.

Desta forma, uma chamada tardia a um procedimento de recebimento de mensagem por um processo é uma causa provável para uma taxa de transmissão efetiva baixa.

Através desta taxa de transmissão efetiva, pretende-se refletir tanto o tempo de resposta dos processos receptores quanto o tamanho da mensagem, uma vez que ambos são fundamentais no desempenho das comunicações.

Tráfego de mensagens.

O gradiente de cores auxilia a visualização da eficiência da comunicação.

Tanto um canal de comunicações ruim como recebimentos tardios tendem a reduzir a taxa de transmissão efetiva.

Desta forma, ambos os problemas podem ser detectados através da ferramenta.

Também é possível visualizar, em um gráfico semelhante, a taxa de transmissão efetiva média durante toda a execução entre cada par de processos que se comunicam durante o tempo de execução.

Tal gráfico facilita o reconhecimento de gargalos na comunicação entre processos evidenciando os pares de processos cuja comunicação foi, em média, mais ineficiente ao longo da execução.

Freqüentemente a taxa de transmissão efetiva dos dados mostra uma grande variação.

Isto ocorre por muitas razões, tais como a ocorrência de mensagens de diferentes tamanhos e as diferenças na disponibilidade dos processos para receber mensagens.

Manter um gradiente de cores grande o suficiente para incluir todas as velocidades de transmissão da aplicação é muitas vezes inadequado.

Uma aplicação poderia, por exemplo, conter um subconjunto de mensagens bastante lentas e outro subconjunto contendo mensagens extremamente rápidas.

Cada subconjunto, em um gradiente de cores grande, ficaria próximo a um dos extremos do gradiente, tornando difícil a identificação de diferenças de desempenho dentro de cada subconjunto.

Para resolver este tipo de problema, é possível ajustar os limites do gradiente, definindo os valores máximos e mínimos a serem representados.

Quando as taxas de transmissão efetivas são maiores que o valor máximo do gradiente, a mensagem é representada pela cor branca.

Mensagens com velocidades menores do que o valor mínimo representável aparecem na cor preta.

Também é possível efetuar uma pausa na animação e otimizar o gradiente para o quadro corrente.

Quando um gradiente é otimizado para um quadro de animação, seus valores mínimo e máximo correspondem as taxas de transmissão mínima e máxima representadas no quadro.

De forma análoga, pode-se otimizar o gradiente para toda a execução.

Pode-se acessar uma janela com mais detalhes a respeito de qualquer um dos processos da aplicação através de um clique com o mouse na area que representa tal processo em qualquer uma das ferramentas apresentadas anteriormente.

A informação apresentada inclui a percentagem do tempo de execução consumido em cada estado e esperando por outros processos e por operações coletivas.

Os dados nesta representação são referentes ao tempo total de execução.

Mostra as estatísticas de um determinado processo.

O gráfico de barras a esquerda na figura demonstra a percentagem de tempo consumido na espera por cada processo e por operações coletivas.

O tempo total de espera também é apresentado no gráfico de barras.

O processo representado consome um tempo muito grande esperando pelo processo 49, o qual pode ser um gargalo no sistema em questão.

O gráfico em setores a direita na mesma figura representa a percentagem de tempo consumido por cada rotina MPI.

O processo representado consome a maior parte do seu tempo de execução nas rotinas MPI_Wait e MPI_Recv.

Neste capítulo são apresentados resultados obtidos através do uso das ferramentas desenvolvidas em algumas aplicações paralelas.

Todos os testes descritos foram realizados no cluster do Laboratório de Alto Desempenho (LAD) do Instituto de Computação (IC) da UNICAMP.

O cluster é composto por dois computadores Pentium 4 com 512 megabytes de memória RAM cada e 64 computadores Pentium III de 450 MHz, com 256 megabytes de memória RAM cada.

A tecnologia de rede utilizada na comunicação entre os computadores do cluster é a Fast Ethernet de 100 Mbps com switches ponto a ponto.

A aplicação estudada é um sistema de rastreamento de objetos em imagens obtidas através de câmeras de vídeo em tempo real.

Particularmente, os objetos rastreados são aqueles envolvidos em uma partida de futebol.

O sistema utiliza processamento paralelo devido a grande demanda computacional necessária para rastrear os objetos em tempo real.

A aplicação chama-se SORTTS (Soccer Real-Time Tracking System) e foi desenvolvida no Instituto de Computação da UNICAMP.

A aplicação encontra-se dividida em três módulos, o módulo de leitura, o módulo de rastreamento e o módulo de iniciação e acompanhamento.

O módulo de leitura é responsável pela leitura das imagens a partir das câmeras e por enviar estas imagens ou partes delas para outros processos.

O sistema opera com imagens obtidas por seis câmeras, de modo que o módulo de leitura é composto por seis processos, cada um obtendo imagens de uma câmera diferente.

O módulo de rastreamento envolve processos que realizam rastreamento de objetos em imagens completas e em imagens reduzidas.

O rastreamento de imagens completas também é feito por seis processos, cada um recebendo imagens de um dos processos de leitura.

O módulo de inicialização e acompanhamento é o responsável por iniciar e interromper os rastreadores de imagens reduzidas de acordo com as coordenadas obtidas através dos rastreadores de imagens completas e é formado por um unico processo.

A ferramenta de animação de processos mostrando a execução do SORTTS.

Através da animação dos processos, foi possível identificar os diferentes grupos de processos devido ao seu comportamento diferenciado.

O sistema funciona com os seis primeiros processos no módulo de leitura, os seis processos seguintes no módulo de rastreamento de imagens completas e com o décimo terceiro processo no módulo de iniciação e acompanhamento.

Os demais processos atuam no rastreamento de imagens reduzidas.

A ferramenta permite perceber a constante comunicação entre o módulo de leitura e os rastreadores de imagens reduzidas, bem como a constante atividade do processo que faz a iniciação e o acompanhamento.

Periodicamente pode-se perceber o envio de imagens do módulo de leitura para o módulo de rastreamento de imagens completas.

O envio de um conjunto de imagens completas é a situação retratada.

Em outros momentos da animação é possível perceber a constante atividade de comunicação envolvendo os módulos de leitura, de acompanhamento e de rastreamento de imagens reduzidas.

O maior tráfego de mensagens, ficou entre o módulo de leitura (seis primeiros processos) e os processos responsáveis pelo rastreamento de imagens reduzidas (processos 13 a 43).

Este comportamento deve-se ao fato de o módulo de leitura precisar enviar constantemente imagens reduzidas para os processos 13 a 43.

Salvo algumas exceções, o tráfego observado ficou abaixo de 10 Mbps, em uma rede com capacidade nominal de 100 Mbps.

Esta observação se confirma no gráfico que representa o tráfego agregado de toda a execução.

A comunicação mais eficiente foi dos processos zero a cinco (módulo de leitura) para os processos 6 a 11 (processos que fazem o rastreamento de imagens completas).

A eficiência desta comunicação é justificada pelo fato de que são transmitidas imagens completas, formando mensagens grandes que efetivamente podem aproveitar o potencial da rede.

A velocidade de comunicação efetiva nestes casos ficou em torno de 80 Mbps.

Tráfego de mensagens total da aplicação durante todo o tempo de execução.

Permitem apenas uma idéia aproximada das características do sistema apresentadas.

Convém ressaltar que a observação das animações através das ferramentas possibilita uma percepção muito mais clara das atividades de comunicação do sistema e, conseqüentemente, a identificação das características da aplicação SORTTS discutidas anteriormente.

O tempo de espera mostrado evidencia a centralização das atividades no processador 12 (módulo de inicialização e acompanhamento), sugerindo que possivelmente este processador esteja sobrecarregado.

Alguns processos esperam pelo processo 12 durante cerca de 50% do seu tempo de execução.

Um grande número de processos consome mais de 75% do tempo de espera em função do processo 12.

Novamente, os processos 6 a 11 se destacam por esperar bastante pelos seis primeiros.

Mas, como foi visto que a comunicação está eficiente, o tempo de espera é grande apenas devido ao grande volume de dados transferido.

Estatísticas de tempo de espera mostram vários processos esperando pelo processo 12 por porcentagens significativas do tempo de execução do SORTTS.

Tempo de espera de cada processo relativo ao seu próprio tempo total de espera no SORTTS.

Através do estudo da aplicação SORTTS, pode-se sugerir que o módulo de inicialização e acompanhamento inclua dois ou mais processos em vez de apenas um (o processo 12 na execução apresentada).

Este tipo de modificação provavelmente melhoraria o desempenho como sendo um gargalo do sistema.

A HPL (High-Performance Linpack Benchmark for Distributed-Memory Computers) é uma implementação portável do benchmark Linpack amplamente utilizada para sistemas paralelos.

O benchmark resolve um sistema linear aleatório em precisão dupla em sistemas de memória distribuída.

Ao analisar a HPL, pode-se ver claramente a forma como o algoritmo da aplicação funciona.

É mostrado um quadro da animação do sistema.

Através do ajuste da topologia da representação para uma topologia semelhante a definida na aplicação alvo, pode-se notar que a computação ocorre em uma linha de processadores por vez.

A computação ocorre inicialmente na primeira linha de processos da animação.

Após concluída a computação na primeira linha, pode-se visualizar o início do broadcast dos resultados para as demais linhas.

A seguir é iniciado o processamento na segunda linha e assim sucessivamente.

Demonstra a computação acontecendo na segunda linha de processos.

Os resultados calculados pela primeira linha são enviados das linhas seis e sete para as linhas sete e oito, de acordo com o algoritmo de broadcast utilizado.

É apresentada a animação da distribuição de carga da HPL.

Pode-se perceber nesta animação um comportamento semelhante ao da animação de processos.

Apenas algumas poucas linhas na matriz de processos apresentam atividade intensa a cada instante.

O movimento das linhas em atividade da parte superior para a inferior da matriz lembra bastante o comportamento do algoritmo evidenciado pela animação de processos.

Tal possibilidade de visualizar tão claramente a execução de um programa é bastante util para que os analistas possam avaliar o desempenho dos algoritmos implementados.

Desta forma, torna-se possível aos usuários determinar se a execução de um determinado programa se comporta como o esperado ou não.

Esta aplicação implementa um algoritmo para determinar o fecho transitivo de grafos dirigidos (dígrafos).

A aplicação baseia-se no algoritmo de Warshall.

O dígrafo é representado por uma matriz de adjacências de tamanho n × n, onde n é o número de vértices do grafo.

A matriz é dividida em p faixas horizontais e p faixas verticais, sendo p o número de processos.

Os dados são distribuídos entre os processos de forma que cada processo receba uma faixa horizontal e uma faixa vertical.

Após a distribuição dos dados, cada processo calcula as novas arestas do dígrafo com base nas informações recebidas.

O processo atualiza sua parte da matriz e armazena arestas a serem atualizadas pelos outros processos.

Após a computação das arestas, os processos passam para uma fase de comunicações onde trocam as informações calculadas no passo anterior.

A seguir, o sistema volta a fase de cálculo de novas arestas com base nas informações recebidas no passo de comunicação.

O sistema continua alternando etapas de comunicação e computação até que nenhum processo realize atualizações.

O uso das ferramentas de profiling desenvolvidas permite notar o consumo de um tempo muito grande nas etapas de comunicação.

A animação do sistema apresenta um tempo significativamente grande consumido pela rotina MPI_Alltoallv utilizada nas fases de comunicação.

Detalhes de um processo em uma execução da aplicação original, com comunicação coletiva.

Mostra claramente o tempo de MPI_Alltoallv em um processo típico da aplicação.

O procedimento de comunicação coletiva consome quase a metade do tempo de execução da aplicação.

Somando-se as duas rotinas de comunicação coletiva (MPI_Alltoallv e MPI_Alltoall) chega-se ao total de 74, 3% do tempo de execução do processo mostrado consumido em rotinas de comunicação.

Tendo reconhecido as etapas de comunicação como um gargalo do sistema, foram desenvolvidas algumas alternativas ao procedimento MPI_Alltoallv.

A aplicação foi modificada para utilizar cinco alternativas diferentes ao procedimento de comunicação coletiva original (MPI_Alltoallv).

As cinco alternativas utilizadas foram, uso do procedimento Sendrecv com e sem algoritmo de round-robin, uso de envio de mensagens não bloqueante, uso de recebimento não bloqueante, e uso de ambos envio e recebimento não bloqueantes simultaneamente.

Com exceção da implementação utilizando round-robin, todas as implementações fazem o envio de mensagens em ordem, ou seja cada processo envia primeiro a mensagem para o processo zero, a seguir para o processo 1, e assim por diante.

O recebimento, da mesma forma, é feito em ordem.

Primeiro é recebida a mensagem do processo zero, e segue-se recebendo mensagens de cada um dos processos em ordem crescente.

As quatro implementações deste tipo variam apenas quanto as rotinas de comunicação utilizadas, que podem ser envios e recebimentos bloqueantes, não bloqueantes ou o uso da rotina Sendrecv.

Conforme mostrado a seguir, esta ultima abordagem foi a mais eficiente dé todas.

A abordagem com round-robin também usa Sendrecv, mas faz os envios e recebimentos em uma ordem diferente.

Utiliza-se uma topologia em anel onde cada processo n envia uma mensagem para o processo d a sua direita e recebe outra mensagem do processo e a sua esquerda, a seguir, o processo n envia a mensagem para o nó a direita de d e recebe a mensagem do nó a esquerda de e, e assim por diante, até que o processo n tenha enviado e recebido mensagens de todos os outros processos.

Grafo com 1280 vértices Média de cinco execuções.

Grafo com 1920 vértices Média de cinco execuções.

Demonstram resultados de execuções da aplicação original em comparação as cinco alternativas.

Cada tabela apresenta valores médios de cinco execuções das aplicações.

Apresentam resultados obtidos em execuções de grafos de 1280, 1920 e 2560 vértices, respectivamente.

Foram realizados testes com 8, 16, 32 e 64 processadores.

Apresentam o tempo das três primeiras rodadas de comunicação executadas pela aplicação para resolver o problema do fecho transitivo de grafos de diferentes tamanhos (1280, 1920 e 2560 vértices).

Apenas as versões com 32 e 64 processadores da resolução do problema do grafo de 2560 vértices precisaram de mais de três rodadas para resolver o problema, ainda assim, em ambos os casos a quarta rodada representava o final do algoritmo, não sendo trocada mais nenhuma aresta.

Além dos tempos das três primeiras rodadas em cada conjunto de execuções, também são mostrados os tempos totais de execução das aplicações, para que se avalie o impacto das alterações na aplicação como um todo e não apenas na comunicação em si.

Os percentuais são calculados a partir da diferença entre o tempo da aplicação original e o tempo de cada alternativa em relação ao tempo da aplicação original, de forma que percentuais positivos representam melhorias e percentuais negativos representam pioras da implementação alternativa comparada à original.

Os gráficos apresentam um resumo dos dados apresentados para as execuções com 32 e 64 processadores, respectivamente.

O eixo vertical nos gráficos representa o tempo em segundos consumido por cada fase de comunicação e o eixo horizontal representa o número de arestas trocadas em cada fase.

Deve-se notar que execuções relativas aos três grafos diferentes testados encontram-se representadas nos dois gráficos.

Ambos os gráficos mostram que três das cinco alternativas desenvolvidas são melhores do que a implementação original com comunicação coletiva em todos as rodadas de comunicação significativamente grandes.

A abordagem que utiliza recebimento não bloqueante é pior que a comunicação coletiva em alguns testes, mas aparenta ser mais estável.

Apenas uma das alternativas mostrou um comportamento pior do que a aplicação original em todos os casos testados.

Pode-se comparar um processo da versão original com a versão que utiliza procedimentos MPI_Sendrecv.

Apresenta um total de 74, 8% do tempo de execução consumido por comunicação coletiva.

O tempo total de comunicação cai para 65, 9% do tempo de execução.

Os gráficos em setores mostram que a porcentagem do tempo gasto em computação aumentou e que o tempo consumido pela rotina MPI_Sendrecv é muito menor que o tempo do MPI_Alltoallv correspondente na versão com comunicação coletiva.

Dada a significativa diferença entre o tempo consumido pela rotina MPI_Alltoallv e suas alternativas, uma outra possibilidade que provavelmente melhoraria ainda mais o desempenho da aplicação seria o uso de implementações alternativas também para a MPI_Alltoall.

A execução específica demonstrada foi 27, 68% mais rápida que a versão.

Para uma média de cinco execuções das duas aplicações, tal diferença de desempenho aumenta para 40, 75%.

Pode-se afirmar, em conclusão ao estudo desta aplicação, que para os casos testados foi possível identificar um gargalo do sistema e desenvolver alternativas que melhoraram significativamente o seu desempenho.

Este capítulo apresenta alguns detalhes da implementação das ferramentas apresentadas e avaliadas nos capítulos anteriores.

São feitas algumas considerações sobre a geração dos arquivos de log e, posteriormente, é apresentada a implementação das ferramentas em Java.

Para a maioria das ferramentas descritas neste documento, é utilizada a extensão a MPI chamada MPE.

Esta extensão inclui bibliotecas de profiling e facilidades para a geração de arquivos de trace.

A MPE permite a instrumentação de todas as rotinas MPI automaticamente, sem que se altere o código original.

Também é possível a definição de outros estados e eventos através de chamadas a funções específicas no código da aplicação estudada.

A intrusão da MPE é mínima, pois requer apenas que os eventos sejam gravados em um buffer local a cada processador.

Toda a comunicação e a combinação dos dados obtidos em um unico arquivo são feitos após a execução da aplicação alvo.

A sincronização entre diferentes processadores para determinação de um relógio global também é feita apenas ao final da execução, não ocasionando intrusão.

Para aplicações executadas por períodos muito longos, o modelo de relógio global da MPE pode ser inadequado devido a diferenças entre relógios locais dos processadores.

Com o auxílio da MPE, é gerado um arquivo de trace no formato CLOG.

O formato CLOG é baseado em eventos, ou seja, trata-se de um conjunto de eventos com os respectivos rótulos de tempo.

O arquivo CLOG pode, posteriormente, ser convertido para o formato SLOG-2 com o conjunto de aplicações slog2 sdk.

O formato SLOG-2 é baseado em objetos Java denominados drawables, e não em eventos como o formato CLOG.

Tais objetos podem representar um ou mais estados de processos ou mensagens do sistema.

Um drawable indica, entre outras características, em que processo acontece e quais os tempos de início e fim no caso de tratar-se de um estado ou os processos de origem e destino e os tempos de envio e entrega no caso de mensagens.

O formato foi desenvolvido para ser visualizado por ferramentas de visualização.

Uma característica fundamental do formato SLOG-2 é sua escalabilidade.

E utilizada uma estrutura baseada em arvores binárias que classifica os objetos no arquivo de acordo com sua posição no tempo.

Tal estrutura possibilita uma navegação eficiente mesmo em arquivos de alguns gigabytes de tamanho.

Os arquivos SLOG-2 são processados pelas ferramentas propostas.

Para a ferramenta de distribuição de carga, foi desenvolvida uma aplicação MPI em linguagem C, bastante simples, denominada cpustatmpi, que se comunica diretamente com o kernel do sistema operacional Linux para gerar arquivos de log, conforme especificado a seguir.

Para o uso da ferramenta de distribuição de carga em outras plataformas deve-se desenvolver programas semelhantes que obtenham as informações do sistema operacional específico e gerem os arquivos de trace apropriados.

Para a geração dos arquivos de trace da distribuição de carga são necessárias pequenas modificações na biblioteca de profiling da MPE.

Mais especificamente, é preciso alterar as funções MPI_Init e MPI_Finalize desta biblioteca.

E conveniente ressaltar que toda aplicação MPI executa, obrigatoriamente, estas funções.

A função MPI_Init deve criar um arquivo temporário que será utilizado para sincronização.

Na implementação deste trabalho, convencionou-se o nome deste arquivo como cpuloglock, o qual deve ser criado no diretório /tmp do Linux.

A função MPI_Finalize deve simplesmente apagar o arquivo criado.

O programa cpustatmpi coleta os dados da distribuição de carga em cada processador, gerando um arquivo de log para cada processador.

Os dados são coletados uma vez a cada período de tempo t.

Quanto menor for o valor de t, mais fina será a granularidade e maior será o nível de intrusão.

Valores de t em torno de um segundo permitem uma boa análise da distribuição de carga sem excesso de intrusão.

O programa cpustatmpi coleta os dados durante o tempo de existência do arquivo /tmp/cpuloglock, ou seja, apenas durante a execução da aplicação alvo.

Os dados são mantidos em um buffer na memória e copiados para o arquivo de saída de acordo com a necessidade.

Em alguns casos, o tempo de início da execução pode variar significativamente entre processadores diferentes.

Tal variação também pode ser obtida através do cpustatmpi.

O valor do tempo de início do profiling t é medido em cada processador p com relação a um tempo inicial de referência t obtido através da rotina de sincronização MPI_Barrier.

O menor t entre todos os processadores será considerado posteriormente, nas etapas de visualização, como o início da execução t0.

Os tempos de início de todos os processadores podem então ser determinados com relação a t0.

O formato dos arquivos a serem gerados em cada um dos processadores é extremamente simples.

Na primeira linha do arquivo, deve constar o valor de t em segundos.

A seguir, na segunda linha, o valor do t específico do processador.

As linhas subseqüentes contêm os valores percentuais de tempo ocioso da CPU para cada período t a partir de t, conforme informado pelo kernel através do sistema de arquivos /proc.

Foi desenvolvida ainda uma aplicação em Java que, a partir do conjunto de arquivos de log gerados pelo cpustatmpi, gera um objeto denominado BalanceData e grava este objeto em um arquivo, o qual serve de entrada para a ferramenta de distribuição de carga.

Convencionou-se a extensão deste tipo de arquivo como lb.

O objeto BalanceData e outros objetos Java das ferramentas desenvolvidas são discutidos na próxima seção.

Para a implementação das ferramentas de visualização desenvolvidas foi escolhida a linguagem de programação Java.

A implementação de todas as ferramentas totalizou aproximadamente 3500 linhas de código.

Foi adotado para compilação e testes o J2 SE (Java 2 Platform, Standard Edition) em sua versão 1 4 1 Os principais motivos que levaram a opção pela tecnologia Java foram, Portabilidade, possibilitando que as ferramentas possam ser executadas em qualquer plataforma que possua uma máquina virtual Java.

Compatibilidade com o formato SLOG-2, de forma que as ferramentas possam se integrar de maneira simples e eficiente com os arquivos de log que devem ler.

Adequação da estrutura modular da programação orientada a objetos ao sistema desenvolvido.

Suporte ao desenvolvimento de interfaces gráficas.

Foram desenvolvidos dois pacotes de classes Java para implementar as funcionalidades de todas as ferramentas.

Foram utilizados ainda vários pacotes da biblioteca padrão Java e também alguns pacotes incluídos no slog2 sdk para a leitura e utilização de objetos dos arquivos SLOG-2.

A seguir são detalhados os dois pacotes desenvolvidos.

Mostra o diagrama de classes em UML (Unified Modeling Language) das ferramentas desenvolvidas.

A classe abstrata ProfilingAnimation é a classe base dos três tipos de animação desenvolvidos.

Os tipos de animação são representados pelas classes SysAnim, MsgAnim e LBalanceAnim utilizadas nas ferramentas de animação de processos, de mensagens e de distribuição de carga, respectivamente.

Cada uma das três classes derivadas implementa um método LoadFile diferente para carregar um arquivo.

As classes SysAnim e MsgAnim carregam arquivos SLOG-2 obtendo os dados que necessitam para cada animação específica.

O mesmo método LoadFile na classe LBalanceAnim carrega um arquivo lb.

Um dos principais atributos da classe ProfilingAnimation é um objeto Snapshot.

A classe Snapshot também é abstrata e é progenitora das classes SystemSnapshot, MessagesSnapshot e LBSnapshot, uma para cada tipo de animação.

A classe Snapshot e suas derivações contém uma série de atributos e métodos que descrevem características fundamentais de uma animação em exibição.

Os principais atributos são, tempos corrente, inicial e final, número de processos, tempo de simulação transcorrido entre quadros consecutivos em velocidade normal e rápida (avanço e retrocesso rápidos) e nome do arquivo utilizado.

O principal método de um Snapshot é o método abstrato setTime.

O método SetTime recebe um valor de tempo como parâmetro e gerencia as alterações em atributos e dispara métodos de atualização de componentes (paintComponent) apropriados para exibir o quadro de animação correspondente ao tempo recebido como parâmetro.

A classe Snapshot implementa ainda as interfaces ActionListener e ChangeListener para responder a ações do usuário como cliques com o mouse na animação, em botões e no controle deslizante.

As classes SystemSnapshot e LBSnapshot possuem um atributo e um método para armazenar e alterar o número de colunas de processos a serem mostradas.

Desta forma, pode-se alterar a topologia apresentada nestas animações.

A classe BalanceData armazena alguns dados específicos da ferramenta de distribuição de carga.

O atributo cpuValues armazena todos os valores percentuais de ociosidade de todos os processadores em cada período medido.

A classe deve implementar a interface Serializable, pois seus objetos devem ser salvos em arquivos.

Uma classe muito importante utilizada por, praticamente, todas as ferramentas é chamada ProcessDetails.

Esta classe armazena informações importantes como tempos e tamanhos de mensagens trocadas, número de operações (estados) diferentes dos processos e seus nomes, as rotinas definidas como de espera e de sincronização além de objetos WaitTimes, que armazenam informações referentes a tempos de espera, e DrawableAverage que guardam informações específicas para cada tipo de operação em cada processo.

A classe ProcessDetailsPanel, utiliza um objeto ProcessDetails para exibir os detalhes de processos individuais.

Por fim, a ferramenta de estatísticas de tempo de espera é implementada na classe WTGPanel.

O pacote graphtools foi desenvolvido como um conjunto de classes auxiliares para o pacote profiling.

Este pacote tem por objetivo prover acessórios gráficos utilizados pelo pacote principal.

O diagrama de classes do pacote graphtools é mostrado.

A classe PlayButtonPanel representa um painel que contém os botões de controle da animação que possibilitam exibir a animação, efetuar uma pausa, a exibição em slow motion, avanço e retrocesso rápidos, avanço e retrocesso quadro a quadro, bem como parar a animação.

Além dos botões, a classe disponibiliza também o controle deslizante para navegação e visualização do progresso da animação.

Diagrama de classes do pacote graphtools.

TopologyDialog é uma caixa de diálogo que permite que o usuário altere a topologia através da seleção do número de linhas e colunas de processos a serem apresentadas.

A classe é utilizada sempre que a opção correspondente a mudança de topologia é selecionada na barra de menus de qualquer animação que suporte este recurso.

A classe implementa as interfaces ActionListener e ChangeListener para interagir com o usuário.

As legendas utilizadas em várias ferramentas são implementadas na classe LegendPanel.

A partir de um objeto InputLog disponível em arquivos SLOG-2 obtém-se os nomes das operações que devem ser representadas.

São disponibilizados métodos para obter e para alterar cores que representam os diferentes estados.

O objeto CategoryMap armazena os estados e as respectivas cores.

A classe Gradient armazena as características e métodos referentes aos gradientes de cores utilizados.

Na criação de um Gradient, são informados os valores máximo e mínimo a serem apresentados e a unidade de medida.

Com base nos valores máximo e mínimo, o gradiente utiliza uma escala normal, de quilos, megas ou gigas de acordo com a necessidade na apresentação dos valores.

A classe MMenu possui métodos estáticos que simplificam a criação de menus e é utilizada em todas as ferramentas.

O presente trabalho apresentou o problema da análise de desempenho de sistemas paralelos de computação e desenvolveu algumas metodologias para auxiliar tal análise.

Foram implementadas ferramentas uteis na análise dos algoritmos paralelos.

As metodologias permitem um estudo apropriado dos sistemas distribuídos.

Foram apresentados conceitos básicos de sistemas distribuídos e de análise de desempenho.

Ressaltou-se a importância e as aplicações dos sistemas distribuídos na atualidade.

Algumas abordagens da literatura e de produtos comerciais ao problema proposto foram discutidas.

As ferramentas de software desenvolvidas foram apresentadas detalhadamente.

Tais ferramentas tornam possível um grande detalhamento das comunicações envolvidas nos sistemas.

Pode-se identificar facilmente, através das novas formas de visualização desenvolvidas, as comunicações eficientes e ineficientes em um programa.

As ferramentas permitem a identificação de gargalos e o estudo do comportamento dos processos envolvidos com mais detalhes.

A visualização de gargalos e da eficiência das comunicações, bem como o funcionamento de algoritmos paralelos e a distribuição de carga dos sistemas através das ferramentas foram objetivos alcançados com sucesso.

Algumas das contribuições do trabalho já encontram-se publicadas.

Foram apresentados estudos referentes a aplicações paralelas reais que comprovam a eficiência das ferramentas em atingir seus objetivos.

Especificamente, a discussão da aplicação SORTTS permitiu a identificação de um gargalo naquele sistema, no sistema HPL foi possível visualizar claramente o funcionamento do algoritmo e na aplicação de fechos transitivos de grafos foi possível identificar e melhorar uma ineficiência da comunicação utilizada.

Foram apresentados ainda aspectos da implementação do trabalho.

Tal discussão incluiu aspectos dos arquivos de trace e também a implementação orientada a objetos das ferramentas e suas interfaces.

Pode-se sugerir, como trabalho futuro, a implementação de melhorias no relógio global da MPE.

Isto pode ser feito através de etapas de sincronização periódicas durante a execução ou através de análises estatísticas da variação entre os relógios locais em períodos de teste antes e/ou depois da execução da aplicação alvo.

Este tipo de melhoria permitiria que as ferramentas fossem utilizadas também em execuções de longa duração.

Outra possibilidade é procurar alternativas para que seja possível acompanhar a execução das aplicações em tempo real, e não apenas em análises post-mortem como foi apresentado neste trabalho.

Análises em tempo de execução permitem identificar problemas, como deadlocks por exemplo, em que o programa não termina.

Além disso, a possibilidade de monitorar sistemas em tempo de execução permite que aplicações críticas possam ser monitoradas constantemente de forma que eventuais medidas corretivas possam ser tomadas o mais rapidamente possível.

Evidentemente, o presente trabalho não esgota o assunto de análise de desempenho ou as maneiras de se visualizar a execução de sistemas paralelos.

Formas de visualização são bastante subjetivas no sentido de que cada pessoa pode se sentir mais confortável com um determinado tipo de visualização de um mesmo fenômeno.

Além disso, cada diferente forma de visualização tende a ressaltar determinadas características específicas dos sistemas.

Assim, o presente trabalho atinge seus objetivos através da ampliação da gama de possibilidades de visualização de execuções de sistemas paralelos existentes atualmente.

