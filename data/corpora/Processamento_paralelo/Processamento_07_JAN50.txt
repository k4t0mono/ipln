O Método dos Elementos Discretos tem sido bastante utilizado para simular o comportamento mecânico de corpos descontínuos.

Um dos principais problemas associados à sua utilização é seu alto custo computacional, visto que é necessária a discretização do domínio em um número muito grande de partículas, o que pode inviabilizar a sua utilização em algumas aplicações.

Dentro deste contexto, apresenta-se neste trabalho uma implementação computacional de um simulador em paralelo que utiliza a biblioteca de troca de mensagens MPI.

São mostrados neste artigo, uma breve descrição sobre o tema, a metodologia utilizada, sua implementação, as ferramentas utilizadas, além dos resultados obtidos.

O Método dos Elementos Discretos (DEM) é uma técnica computacional que simula, em geral, o comportamento mecânico de meios descontínuos na escala granular.

Em sua modelagem, as respostas na escala macroscópica resultam do mecanismo de interação mecânica entre cada elemento que constitui o sistema estudado.

Dessa forma, o DEM constitui uma boa ferramenta de pesquisa para o estudo do comportamento destes meios em diversas áreas de conhecimento.

Na engenharia, o método é aplicado na simulação do escoamento de materiais granulares, na modelagem de solos e rochas, em problemas de cravação, fluidos, dentre outros.

Numa simulação que utiliza o Método dos Elementos Discretos, o domínio analisado é discretizado em uma série de partículas, que constituem a unidade básica de análise.

Dessa forma, para que o meio estudado seja representado pelo DEM de forma satisfatória, torna-se necessária a discretização em um número excessivamente grande de partículas, tornando as simulações do DEM extremamente lentas.

Além disso, o número de partículas a ser utilizado em uma simulação pode ser limitado pela memória disponível na máquina onde está sendo executada a aplicação.

Com isso, a utilização da computação de alto desempenho desponta como uma alternativa interessante que pode solucionar o problema de desempenho computacional e de memória requerida por uma aplicação que utilize o DEM.

Tem crescido muito nos últimos anos a utilização de clusters de computadores por ser uma alternativa de baixo custo para a solução de aplicações que requerem um alto custo computacional.

Visto que, pode-se conseguir uma grande redução no tempo de simulação de uma aplicação e um espaço (em memória) maior para armazenamento das informações, através da utilização de vários processadores e de memórias de baixo custo disponibilizados através de um cluster de computadores.

Dentro deste contexto, apresenta-se neste trabalho uma proposta e a implementação de um simulador orientado a objetos em C++ em um ambiente de computação paralela, utilizando a biblioteca de troca de mensagens MPI (Message Passing Interface), bem como alguns resultados de ganho computacional obtido com essa implementação.

O Método dos Elementos Discretos consiste na representação de um meio, contínuo ou descontínuo, por um número excessivamente grande de partículas individuais, em que o comportamento do sistema é determinado pelo movimento e interação destas partículas.

Em geral, suas aplicações envolvem materiais com características inerentemente discretas tais como materiais granulares e particulados encontrados em problemas da engenharia estrutural, geomecânicos e de fluidos.

A utilização do DEM para simulação de meios contínuos e sobretudo de fluidos vem crescendo de forma significativa.

O meio analisado é discretizado em um conjunto de partículas, com propriedades mecânicas particulares e geometrias definidas.

A partir do entendimento dessas propriedades e do comportamento da interação entre as partículas, o DEM permite avaliar de maneira macroscópica o comportamento físico e mecânico do modelo estudado.

Inicialmente, o DEM foi concebido como um modelo numérico capaz de descrever o comportamento mecânico de um conjunto de partículas em forma de discos ou esferas.

Atualmente o método é aplicado também para partículas de várias formas ou mesmo aglomerados de partículas.

No DEM, o meio estudado é avaliado a cada intervalo de tempo requerido pelo algoritmo de integração no tempo utilizado.

De uma forma geral, o equacionamento do método consiste na aplicação da segunda Lei de Newton, obtendo a aceleração de cada partícula a partir das forças que agem na mesma, provenientes do meio externo e da interação entre elas.

Por meio de integrações, é possível obter as velocidades e deslocamentos partir da aceleração.

Além disso, aplicam-se também as Leis de Força-Deslocamento nos contatos, que calculam as forças nos mesmos devido aos deslocamentos relativos entre as partículas.

Para quantificar as forças de interação existentes entre os pares de partículas, são utilizadas técnicas que permitem uma busca otimizada de contatos.

Estas devem ser desenvolvidas de maneira robusta e eficiente, permitindo que todos os contatos possam ser contabilizados sem um alto custo computacional.

Apresenta um esquema resumido das principais etapas de cálculo do Método dos Elementos Discretos.

Algoritmo para o Método dos Elementos Discretos.

O crescente número de sistemas computacionais que vêm sendo desenvolvidos para solucionar problemas de Engenharia tem demandado a utilização de processadores mais velozes e uma grande capacidade de memória dos computadores.

No entanto, a velocidade de processamento requerida dificilmente pode ser alcançada comos processadores convencionais, com o uso de um único processador e com a quantidade de memória disponível numa única máquina.

Geralmente, essas simulações envolvem o processamento de uma quantidade enorme de dados e executam um grande número de iterações.

A computação em paralelo muitas vezes viabiliza algumas dessas aplicações, reduzindo o tempo computacional da simulação.

Geralmente, dois tipos de arquiteturas paralelas são utilizados, máquinas com memória compartilhada e máquinas com memória distribuída.

No primeiro tipo, os processadores operam independentemente, mas compartilham o recurso de uma única memória.

No segundo tipo, cada processador possui sua própria memória e os dados são compartilhados através da rede usando um mecanismo de troca de mensagens (Message Passing).

Atualmente, a arquitetura de memória distribuída tem sido mais utilizada nas indústrias e meios científicos, em virtude do baixo custo dos clusters de computadores que utilizam esse tipo de arquitetura.

O MPI (Message Passing Interface) tem se tornado um padrão quando se utiliza o mecanismo de troca de mensagens para ambientes paralelos, especialmente aqueles com memória distribuída.

Neste modelo, em geral, a execução de uma aplicação compreende a execução de vários processos que se comunicam chamando rotinas de uma biblioteca que gerencia o processo de envio e recebimento de mensagens entre os processos.

O desempenho de programas em paralelo é analisado através de um conjunto de métricas, tais como speed-up e eficiência.

Speed-up é uma medida que indica o beneficio relativo ao se executar um programa em paralelo e é definido como a razão entre o tempo gasto para resolver um problema em um único processador (T ) e o tempo requerido para solucionar o mesmo problema em p processos (Tp ).

Setton S Silveira Eficiência  é definida como a razão entre o speed-up e o número de processos (Np), correspondendo à medida da fração do tempo total de execução que cada processo consome para executar a aplicação.

A implementação computacional tomada como base para o desenvolvimento deste trabalho foi o programa Demoop (Discrete Element Method ObjectOriented Programming).

Este sistema é dividido em três partes distintas responsáveis pelas fases de pré-processamento, processamento e visualização, o que oferece algumas vantagens vinculadas ao relacionamento entre o sistema e os usuários ou programadores.

Na etapa de processamento, o algoritmo de solução utilizado pelo Demoop apresenta uma rotina de repetição de processos que inclui a checagem de contatos entre partículas, determinação das forças atuantes nas partículas, provocadas tanto pelos contatos com outras, quanto pelas ações externas, cálculo das forças internas dos elementos de ligação.

O Demoop foi escrito com o uso da linguagem de programação C++.

Esta escolha baseia-se no pressuposto de que o código do programa possa embasar futuras implementações e de que ele possa ser facilmente expandido, não requerendo mudanças significativas no seu conteúdo.

Mostra um diagrama das classes da aplicação Demoop, destacando, dentre elas, as classes Demoop, responsável por transformar as informações de análise fornecidas pelo arquivo de entrada em um modelo numérico.
A classe Model, responsável pela caracterização do modelo numérico durante todo o processo de análise, classe TimeIntegration, responsável pelo processso de integração numérica temporal, classe ContactSearch, responsável pela checagem de contatos entre partículas do domínio analisado, e classe Particle, responsável pela representação do meio descontínuo, através do estabelecimento de uma definição formal para as entidades sobre qual o DEM opera.

Diagrama de classes do Demoop.

Maria Cecilia R Sena e Eduardo Setton S Silveira.

Para a implementação em paralelo do Método dos Elementos Discretos (P-Demoop) utilizou-se a linguagem de programação C++, a distribuição LAN/MPI e o compilador MPIC++.

Na versão paralela, foi criada uma classe adicional (cMPI), responsável pelo envio e recebimento de dados e pelas informações relacionadas ao processamento paralelo.

A classe cMPI possui como atributos o identificador de cada processo e o número total de processos, além de dispor de métodos que gerenciam o envio e recebimento de mensagens nas várias etapas da simulação.

A implementação em paralelo utiliza o mecanismo de master-slave em que o processo mestre (master) fica responsável pelas tarefas iniciais da aplicação, e para distribuição de algumas informações para os processos escravos (slaves).

O algoritmo paralelo foi desenvolvido através da decomposição do domínio em n-1 subdomínios, onde n é o número de processos.

Divisão do domínio entre os processos.

Após a leitura dos dados de entrada, cada processo executa essencialmente os mesmos cálculos que o algoritmo seqüencial, porém apenas sob as partículas que se encontram na região do seu subdomínio.

Para imprimir os resultados a cada passo de impressão, cada processo cria um arquivo de saída e escreve as posições das partículas que estão no seu domínio.

Quando uma partícula sai da região associada a um processo e entra em outro subdomínio controlado por outro processo, as informações dessa partícula (posição, velocidade, aceleração e força) são enviadas de um processo para outro, através das funções básicas de envio e recebimento de mensagens do MPI (MPI_Send e MPI_Recv).

A partir daí, os dados dessa partícula são atualizados e a mesma passa a ser tratada pelo processo no qual acabou de entrar.

As partículas que se encontram no contorno do domínio de cada processo podem estar em contato tanto com partículas do mesmo processo quanto com partículas do processo vizinho.

Porém, de acordo com o esquema da divisão de domínio apresentada, cada processo só possuiria as informações das partículas que estão no seu domínio, deixando, dessa forma, de computar os contatos entre partículas de processos diferentes.

Para solucionar esse problema, cada processo envia para o processo vizinho da direita as partículas que estão no contorno direito da subdivisão (partículas que se encontram nas faixas hachuradas).

Então, o processo que recebe essas partículas, checa os contatos entre elas e outras partículas do seu domínio, calcula as forças correspondentes, no caso de haver contatos, e as envia para o processo vizinho esquerdo.

Para obtenção dos resultados apresentados nesta seção utilizou-se o cluster, do Laboratório de Computação Científica e Visualização da Universidade Federal de Alagoas (LCCV/UFAL) composto por 44 nós, em arquitetura de memória distribuída.

O nós do cluster estão interligados em uma rede gigabit ethernet.

Cluster do Laboratório de Computação Científica e Visualização.

A análise da eficiência do código paralelo foi realizada através da simulação de um problema relacionado à ancoragem de estruturas offshore, lançamento e penetração da estaca torpedo.

O solo foi discretizado em 5000, 12000 e 20000 partículas circulares.

Esse problema consiste no lançamento de uma estaca torpedo a partir da superfície do mar que, somente pelo efeito da gravidade, ela obtém velocidade necessária para cravar-se em solo marinho, penetrando-o de maneira tal que venha a funcionar como âncora para as linhas de ancoragem da unidade flutuante, empregada no processo de exploração de petróleo, oferecendo capacidade resistiva as solicitações provenientes da mesma.

Em todas as simulações apresentadas neste trabalho (seriais e paralelas) trabalhou com um tempo total de análise de 10 segundos, tempo suficiente para a estaca atingir e penetrar no solo.

Esquematização do esquema de ancoragem.

Os exemplos analisados foram gerados pelo pré-procesador Pre-Demoop e os resultados das simulações podem ser visualizados no pós-processador DemoopView.

Simulação do lançamento e cravação da estaca torpedo.

Os tempos de execução do programa seqüencial e do programa paralelo, com p processadores.

Tempo de processamento em segundos para n particulas e p processadores.

Tempo de Processamento versus número de partículas para 10 segundos de simulação Analisando os valores, pode-se observar a redução no tempo de execução da versão em paralelo em relação à serial.

Essa redução deve ser ainda maior quanto maior for o número de partículas, em função da alta carga de processamento que é executada em único processador, no programa sequencial.

Entretanto, quando o número de processos atinge um valor limite, o tempo de processamento volta a crescer, em função do aumento no tráfego de informações através da rede.

Para ter uma melhor idéia do desempenho do código paralelo, apresentam-se os valores de speed-up obtidos nas simulações.

Speed-up para n particulas e p processadores.

O gráfico de speed-up é mostrado.

Speed-up versus número de partículas para 10 segundos de simulação.

Para o exemplo analisado, o desempenho do processamento em paralelo cresce à medida que aumentarmos o número de partículas do problema, conforme se observa nos gráficos de speed-up.

Esse ganho computacional deve-se ao fato de que quanto maior for o número de partículas, maiores são as tarefas realizadas por cada processo, o que acaba compensando o tempo que é despendido com o tráfego de informações entre os processos através da rede.

Outra informação que se obtém da análise dos gráficos é que, para todos os casos, quando se aumenta o número de processos, o valor do speed-up cresce até atingir um valor máximo e depois torna a decrescer.

À medida que se aumenta o número de processos, diminui-se o tamanho da tarefa que cada processo irá realizar e aumenta-se o tráfego na rede, já que mais processos irão participar dessa comunicação.

Dessa forma, há um momento em que o tempo ganho com o processamento paralelo não é suficiente para compensar o tempo gasto com a transmissão de dados entre os processos.

Eficiência versus número de partículas para 10 segundos de simulação.

A eficiência do processamento paralelo cresce à medida que o número de partículas torna-se maior, o que era de se esperar, já que o speed-up também cresce nesse mesmo sentido.

Analisando os gráficos, observa-se que quando se aumenta o número de processos, a eficiência do algoritmo diminui, mostrando que quando o speed-up está crescendo, este crescimento se dá em uma proporção menor que o crescimento do número de processos.

Ao analisar o desempenho do programa sequencial, verifica-se que 75% do tempo de simulação é gasto na busca de contatos entre as partículas, uma vez que essa etapa do processamento pode chegar a ter operações proporcionais a N², onde N é o número de elementos discretos.

Porcentagem de tempo gasta nas etapas do processamento.

No código em paralelo, como as partículas são distribuídas entre os processos, o número de contatos a serem checados pode ser reduzido à proporção de(N / Np)2, onde Np é o número de processos.

Entretanto, à medida que se aumenta o número de processos, aumenta-se também o tempo de comunicação entre os mesmos.

Mostra a porcentagem de tempo que é gasta na busca de contatos e na comunicação entre os processos para o caso de 5000 partículas.

Tempo gasto em comunicação e busca de contatos para 5000 partículas.

Os resultados obtidos apontam para uma redução significativa no tempo de execução quando se utiliza a implementação em paralelo desenvolvida neste trabalho, comparando-se com o mesmo código na sua versão seqüencial.

Para o exemplo em pauta, o máximo speed-up obtido foi 11 vezes e ocorreu para o caso em que o domínio foi discretizado em 20000 partículas.

Pode-se, entretanto, obter speed-up's ainda maiores se forem simulados problemas com um número mais elevado de partículas, já que nesse caso o tempo gasto na comunicação será compensado pela divisão de um grande volume de dados entre os processos.

Conforme observado,à medida que se aumenta o número de processos ocorre uma redução no tempo de busca de contatos, considerada a etapa mais dispendiosa da simulação.

Em contrapartida, aumenta-se o tráfego de informações na rede, elevando, dessa forma, o tempo gasto em comunicação.

Chega-se um momento em que o aumento no tempo de comunicação não compensa a redução no tempo de processamento, gerando uma decaimento do speed-up.

Esta aplicação está em desenvolvimento, estão sendo investigadas alguns aspectos que podem melhorar ainda mais o speed-up obtido, o que deverá acontecer naturalmente à medida que se aumente o número de partículas.

Estão sendo avaliados casos de maior porte do que o apresentado, considerando modelos com até um milhão de partículas.

Além disso, estão sendo realizados testes com esta aplicação utilizando efetivamente os núcleos do processador Core 2 Duo e também executá-la numa máquina com mais processadores e que utilize o modelo de memória compartilhada, evitando a utilização de uma rede.

