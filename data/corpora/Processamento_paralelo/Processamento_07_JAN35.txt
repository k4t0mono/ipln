A computação paralela, nos moldes atuais, pode ser realizada em diversos ambientes.

Esses ambientes, via de regra, são escolhidos de acordo com a natureza da aplicação paralela a ser executada.

Entretanto, um dos motivos determinantes para a escolha do tipo de arquitetura paralela é o custo.

Uma alternativa ao alto custo apresentado pelos multiprocessadores vem sendo o uso de clusters de computadores pessoais.

Mesmo economicamente mais viáveis e com poder de processamento próximo ao das máquinas paralelas, esse tipo de arquitetura ainda é de propósito específico, utilizada de maneira dedicada, gerando, via de regra, ociosidade de recursos, o que na atual conjuntura é extremamente indesejável.

Uma possível alternativa à diminuição da ociosidade, sem expandir o custo final da arquitetura, seria a utilização de redes de computadores não dedicadas, em conjunto com um sistema operacional de propósito geral (GPOS General Purpose Operating System), comumente instaladas na maioria das organizações.

Entretanto, apenas usar esses elementos não cria um cenário favorável à execução eficiente de programas paralelos.

Isso ocorre devido a várias restrições tecnológicas, principalmente nos GPOSs.

Podem ser citadas como restrições existentes, a política de escalonamento desses sistemas operacionais que destinam quantum para processos ou recorrem apenas ao expediente do uso de prioridades para privilegiar a execução de algumas aplicações em detrimento de outras.

Seus subsistemas de rede são orientados a interrupções, o que pode causar ineficiência no escalonamento de processos, 

Normalmente, as filas de transmissão de pacotes são compartilhadas, não havendo meios para classificação ou priorização dos pacotes.

Os protocolos ora utilizados não tratam com naturalidade serviços diferenciados, e (6) os próprios ambientes de passagem de mensagens (como Parallel Virtual Machine PVM e Message Passing Interface MPI) não geram os seus processos com padrões de qualidade de serviço.

Dessa forma, para viabilizar-se computação paralela de forma não dedicada em redes de propósito geral, sem interferências no seu funcionamento ordinário, é necessário implementar a filosofia de tratamento diferenciado de processos paralelos tanto nos sistemas operacionais das máquinas local e destino quanto no canal de comunicação.

Este artigo apresenta uma proposta de arquitetura, denominada Par_QoS, baseada na inserção do conceito de serviços diferenciados em um GPOS (neste caso o Linux) com o objetivo de permitir computação de alto desempenho em redes tradicionais não dedicadas, ampliando a possibilidade da utilização da Computação Paralela e tornando mais favorável a relação custo/desempenho.

A solução proposta pela adoção do Par_QoS pode ampliar o leque de potenciais usuários de programação paralela, o que impõe um caráter mais universal a esse tipo de computação.

Este artigo está organizado da seguinte maneira.

Apresenta as principais motivações e contribuições da arquitetura Par_QoS.

Mostra os trabalhos relacionados com o apresentado por este artigo.

Descreve a arquitetura proposta, dando ênfase aos elementos do GPOS que atuam diretamente para provisão de QoS, o subsistema de processamento e o subsistema de rede.

Apresenta um estudo de viabilidade da arquitetura por meio de prototipação.

Por fim, destina-se às considerações finais sobre o trabalho.

Este artigo tem como objetivo propor a arquitetura Par_QoS, cuja função básica é fornecer um tratamento diferenciado a processos paralelos MPI em uma rede de propósito geral por meio da adoção do conceito de serviços diferenciados.

A motivação para este projeto vem da constatação de que mesmo tendo uma arquitetura bem mais barata e quase tão eficiente quanto uma máquina paralela real, os clusters, em cenários reais, boa parte dessa arquitetura fica ociosa, aguardando algum processo paralelo e/ou distribuído para executar.

Para evitar essa situação de desperdício, inaceitável principalmente em lugares onde há escassez de recursos, propõe-se uma arquitetura que faça uso de redes não dedicadas, Par_QoS.

Além do motivo citado, outras motivações e contribuições à/da proposta do Par_QoS podem ser relatadas a seguir, Relação custo/desempenho favorável, já que se utilizam ambientes de redes já estabelecidos na maioria das organizações, sem que haja substanciais modificações no hardware e no software (pela adoção de software livre).

O aparato de software adotado na solução possui uma ampla utilização, sendo bastante consolidado (Linux, MPI, TCP/IP).

Solução baseada em redes locais, o que, no atual estado-da-arte, representa, além do relativo baixo custo, uma confiabilidade satisfatória (baixos níveis de perda e retardo de pacotes e bons níveis de segurança).

Tanto programador quanto usuários da rede não são envolvidos na tarefa de alocação/reserva de recursos.

Isto representa um outro aspecto desejável, transparência para o programador e para o usuário final do sistema.

O ambiente do Par_QoS é de fácil reconfiguração nos seus percentuais de reserva de recursos, o que permite uma boa "sintonia fina" entre todos os processos envolvidos.

Isto possibilita que processos não paralelos sem prioridades e processos interativos não morram por inanição (starvation).

Pelas suas características de abertura, transparência e fácil reconfiguração, o Par_QoS é uma ferramenta que pode ser utilizada, de forma didática, no ensino de Computação Paralela.

A literatura especializada apresenta um leque de trabalhos voltados à provisão de serviços diferenciados a tipos diversos de aplicações, tais como as de tempo-real e multimídia, em sistemas operacionais convencionais.

Alguns trabalhos propõem a criação de novos sistemas operacionais.

Entretanto, a grande maioria se concentra em melhorar as técnicas de escalonamento, seja por meio de pequenas alterações no kernel do sistema operacional ou mesmo propor novos métodos de escalonamento a serem inseridos no sistema operacional.

Vale ressaltar que a relação entre o Par_QoS e os trabalhos apresentados a seguir, encontra-se basicamente na proposta de modificações no kernel de um sistema operacional, com o objetivo de aperfeiçoar o escalonamento de processos.

No Par_QoS essas modificações são basicamente para privilegiar processos paralelos MPI, nos demais, essas mudanças beneficiam processos de aplicações tempo-real e/ou interativa.

O trabalho de propõe a implementação do sistema Eclipse/BSD, baseado no FreeBSD para permitir que aplicações soft real-time, multimídia e web obtenham tratamento diferenciado por parte do sistema operacional.

A idéia central do Eclipse/BSD, que é um sistema operacional de tempo-compartilhado, é realizar um compartilhamento de recursos proporcional e hierárquico.

Para isso, um arquivo especial chamado /reserv faz a associação de recursos reservados a objetos compartilhados através de referências.

O escalonador responsável pela CPU utiliza os algoritmos MTR-LS (Move-To-Real List Scheduling) para gerenciar o acesso e uso da CPU por parte dos processos.

Neste esquema, quando um processo é bloqueado (por exemplo, esperando por alguma operação de E/S), o MTR-LS mantém a porção não utilizada da cota do processo na mesma posição na lista de escalonamento.

Desta forma, o processo não é retirado da lista quando se torna pronto para executar novamente.

A conseqüência direta do uso dessa estratégia é a diminuição no tempo de execução de processos I/O bound.

Os algoritmos disponíveis no Eclipse/BSD são, YFQ (Yet another Fair 2 Queuing) responsável pelo escalonamento de disco.

WF Q (Worst-case Fair Weighted Fair Queuing) responsável pelo escalonamento de pacotes na interface de saída da rede e o SRP (Signaled Receiver Processing) responsável pela interface de entrada de pacotes da rede.

O QLinux, proposto por, é um sistema operacional multimídia baseado no GNU/Linux.

Ele dá suporte à QoS para aplicações multimídia, soft-real time e interativa.

O QLinux é formado pelos seguintes elementos, Tanto o escalonador de CPU quanto o escalonador de envio de pacotes à rede utilizado é o Hierarchical Start Time Fair Queuing (H-SFQ).

Usa o subsistema de rede Lazy Receiver Processing para tratar os pacotes que chegam via rede.

Em é apresentada a arquitetura QoSOS que provê QoS adaptável nos subsistemas de rede e de escalonamento de processos multimídia em GPOS.

Em nosso trabalho, também há um arquitetura para provisão de QoS adaptável no Linux.

Entretanto, as alterações nos diversos subsistemas da máquina, como por exemplo, escalonamento de processos e rede de comunicação visam promover a execução de aplicações paralelas MPI com QoS.

Alguns trabalhos estão voltados à provisão de QoS em ambiente de passagem de mensagens, em particular no MPI.

Em há uma proposta de padronização de uma interface de passagem de mensagens em tempo real, o MPI/RT.

Nele a QoS é implementada na camada do ambiente de passagem de mensagens.

A instanciação da interface para provisão de QoS pode ser realizada de duas formas.
As informações são fornecidas explicitamente pelo usuário, como por exemplo, tempo limite de comunicação entre módulos de aplicações paralelas.

Quem optar por definir manualmente esses valores deve ter um prévio conhecimento da aplicação a ser executada, senão corre o risco de prejudicar a execução da aplicação paralela ou de se obter valores não confiáveis.

A entrada de valores segue um padrão fornecido pela própria interface, ou seja, a solicitação, o estabelecimento e a manutenção de contratos de serviços são guiados por parâmetros internos à interface do MPI/RT.

O trabalho proposto por descreve uma extensão para a biblioteca de passagem de mensagens MPICH, a MPICH-GQ, que usa mecanismos de QoS para gerenciar a execução de aplicações paralelas.

Essa extensão é gerenciada por uma arquitetura, denominada GARA, responsável por realizar a reserva de recursos e o controle físico de roteadores e computadores.

Uma das principais contribuições desta proposta em relação aos ambientes MPI/RT e MPICH-GQ está, sobretudo, na transparência de ativação/manipulação do Par_QoS.

Tanto no MPICH-GQ quanto no MPI/RT, houve alterações no código do ambiente de passagem de mensagens, além de impor ao programador a incorporação de funções de QoS no código do programa paralelo.

No Par_QoS não há nenhuma alteração no código das bibliotecas MPI, pois é o sistema operacional que cria todo o ambiente propício ao fornecimento de QoS aos programas paralelos MPI, por meio de alterações no escalonador do Linux e através de novas chamadas de sistemas adicionadas no kernel.

Cabe ao programador da aplicação paralela acionar a utilização de QoS através da inserção das chamadas de sistema no código MPI do programa paralelo.

Uma outra característica de Par_QoS é o fato de que ele procura minimizar os efeitos colaterais do tratamento imediato dos pacotes que chegam via interface de rede.

Esse tratamento se dá por meio de interrupções, o que pode acarretar, por exemplo, problemas de inversão de prioridade.

Visando otimizar essa situação, o Par_QoS utiliza a técnica Lazy Receiver Processing LRP, que realiza o processamento dos pacotes que chegam à medida que a CPU os solicita.

Apresenta uma visão geral da arquitetura Par_QoS.

Este modelo realiza as seguintes etapas para provisão de QoS em tempo de execução.
A aplicação MPI solicita ao sistema que seus processos recebam tratamento diferenciado em relação aos demais.

O sistema operacional recebe as solicitações de serviço dos processos paralelos, como por exemplo, garantias de acesso à CPU e reservas de recursos da rede.

O sistema operacional verifica, por meio do módulo controlador de admissão, a viabilidade da aceitação dos fluxos de processos paralelos.

Caso o controlador de admissão garanta os recursos aos fluxos de processos paralelos, um contrato de serviço é estabelecido e os fluxos são escalonados à CPU ou ao subsistema de rede.

Caso o controlador de admissão não aceite as solicitações da aplicação MPI, o módulo negociador tentará redefinir alguns parâmetros de qualidade para que os processos da aplicação MPI executem satisfatoriamente.

Se mesmo assim o negociador não conseguir reservar os recursos a contento, o contrato de serviço não é estabelecido e uma mensagem é enviada ao usuário para que ele tente mais tarde com os mesmos parâmetros ou redefina imediatamente, para baixo, seus parâmetros de qualidade.

O sistema operacional tem que garantir a manutenção de serviço, ou seja, manter os valores de QoS ao longo da execução do processo.
Realizar as transferências de informações entre processos paralelos, via rede de comunicação com garantias de QoS.

Encerrar o contrato de serviço ao término do processo MPI.

Arquitetura Par_QoS.

O escalonador tradicional do Linux visa ao equilíbrio entre todos os processos, dessa forma não direciona grandes benefícios ou garantias a processos individuais.

Para a implementação da arquitetura Par_QoS, são propostas alterações no escalonador de processos, de tal forma que este seja capaz de prover reserva de recursos para esses processos com QoS.

Para atingir essa meta, o escalonador desenvolvido trata os processos tradicionais e os processos com QoS com algumas diferenças.

Enquanto os processos tradicionais são escalonados exatamente da forma natural do Linux, aqueles processos com QoS são escalonados através de verificações no temporizador do sistema.

O Linux (assim como outros GPOS) utiliza o temporizador como forma de realizar rotinas de verificação, como atualização da hora do sistema ou verificação do término do timeslice de um processo.

No Linux 26, a freqüência do temporizador é de 1000 Hz (ou simplesmente uma interrupção a cada milissegundo) para máquinas da arquitetura i386 (os valores mudam para cada arquitetura).

Para que o Linux reconheça os processos que demandam QoS, foram criadas uma nova estrutura de dados, denominada task_qos, e duas novas chamadas de sistema, denominadas setqospriority e rmvqospriority, com as seguintes funções, task_qos, estrutura de dados em fila circular que referencia um processo que demande reserva de recursos, bem como a quantidade de reserva e próximo momento de entrada no processador.

Setqospriority(int pid, int reserva) insere uma nova entrada na fila dos processos com QoS, instanciando uma task_qos para o processo referenciado.

O rmvqospriority(int pid), retira o processo referenciado da fila com QoS, desalocando a task_qos referente a esse processo.

A proposta Par_QoS consiste em adicionar novas verificações referentes aos processos com QoS na rotina de interrupção do temporizador scheduler_tick.
Se estiver no momento de algum processo com QoS ser processado, sua entrada no processador é forçada e seu timeslice será definido pela porcentagem de reserva requisitada (considerando períodos de 1 segundo, por exemplo, 200 ms para 20% de reserva).

Se um processo com QoS tiver consumido todo seu timeslice, ele é retirado do processador e terá calculado o tick da sua próxima entrada (p ex 800 ms para 20% de reserva), denominado jiffies_to_in.

Após o término do seu timeslice, esses processos com QoS são colocados para esperar na fila junto com outros processos comuns que tiveram seu timeslice esgotado (vetor expirado), entretanto, com a pior prioridade e o menor timeslice definidos pelo Linux.

Essa atitude permite que ao Linux reescalonar esse processo com QoS (para processar sem reserva de recursos) antes que o tick da próxima entrada no escalonador estoure.

Muito embora ele só tenha essa chance caso o processador esteja ocioso, caso contrário, o instante jiffies_to_in acontecerá antes do escalonamento tradicional.

Estas chamadas de sistemas serão adicionadas no programa paralelo, que quando detectada pelo sistema operacional, tratará o processo de maneira diferenciada.

Quando o programa paralelo for executar nas máquinas escravas o usuário local não terá privilegio de negar a requisição ou de cancelar a execução da aplicação, garantindo assim a integridade da máquina paralela virtual.

Na arquitetura Par_QoS o subsistema de rede é organizado em dois módulos, o que trata da recepção de dados e o que versa sobre a entrega de dados à rede.

O mecanismo adotado para controlar a recepção de dados é o Lazy Receiver Processing (LRP), já o mecanismo escolhido para o envio de dados à rede é o algoritmo de escalonamento por prioridade, onde os processos paralelos MPI sempre têm prioridade de envio em relação aos demais processos.

Subsistema de rede do Par_QoS.

No Lazy Receiver Processing (LRP) Processamento tardio do receptor, proposta por, alguns dos problemas de recepção de dados do subsistema de rede dos GPOSs são resolvidos pela seguinte combinação de técnicas, 1 Substituição da fila compartilhada IP por filas de socket, de acesso direto pela interface de rede.

A interface deve, então, demultiplexar os pacotes de entrada colocando-os nas filas apropriadas, de acordo com o socket destino.

O protocolo de recebimento é executado na prioridade do processo receptor.

Para isso, o processamento será executado mais tarde, no contexto da chamada de sistema disparada pelo processo responsável pelo recebimento.

Assim, o processamento do protocolo para um pacote não ocorre até que a aplicação receptora o requisite pela chamada de sistema.

Além disso, esse processamento não mais interrompe o processo em execução no momento da chegada do pacote, a não ser que o receptor tenha maior prioridade no escalonamento que o processo corrente.

Evitam-se, ainda, mudanças de contexto inapropriadas, levando a um significativo aumento do desempenho do sistema.

Para comprovar a viabilidade da proposta do Par-QoS, foi implementado um testbed no qual são executadas diversas aplicações com diferentes prioridades e percentuais de reserva de recursos, que no atual estado de desenvolvimento do Par_QoS limita-se a reserva de CPU.

Os resultados obtidos são apresentados a seguir e comparados entre si.

Descrição do Ambiente Operacional e Softwares Empregados.
Em termos de hardware, o protótipo foi avaliado no Laboratório de Computação Aplicada (LACA) da Universidade Federal do Pará, no qual existem 3 computadores.
Entre estações e servidores interconectados por uma rede local Ethernet, chaveada por um SWITCH 3 COM SUPERSTACK II 1000, cujo suporte de taxa de transferência é de até 155 Mbps As estações utilizadas foram 1 Pentium 4 26 GHz (como máquina mestre) e 2 Athlon 2200 (como escravos), todos com 256 MB de RAM DDR 333 e placas de rede PCI Fast Ethernet 10/100.

Quanto ao software básico, todas as estações utilizadas na avaliação utilizam a distribuição Linux Fedora Core 3, bem como o ambiente de passagem de mensagens LAM-MPI 711.

Para medição do desempenho de aplicações seqüenciais e paralelas, utilizou-se o como benchmark um programa de cálculo que utiliza o Quantum Monte Carlo, já utilizado como benchmark por empresas de desenvolvimento de compiladores.

Para demonstração da validade da arquitetura mesmo em ambientes de produção altamente carregados, utilizaram-se três aplicações seqüenciais de multiplicação de matrizes de alta ordem como geradores de carga nas estações escravas.

Estas aplicações naturalmente ocupam a CPU quase que totalmente, caracterizando-se como aplicações CPU-bound, um atributo pertinente ao teste a ser realizado.

Análise dos resultados obtidos, O primeiro experimento consiste na execução dos três programas seqüenciais nas estações escravas conjuntamente com benchmark paralelo em diferentes situações, quando sobre reserva de CPU de 40%, quando sobre reserva de CPU de 70% e quando não há nenhum tipo de reserva de processamento, em todas as situações o benchmark concorria com os programas de multiplicação de matrizes e a execução do vídeo.

O experimento foi repetido, no mínimo, trinta (30) vezes para composição de uma amostra de uma distribuição Gaussiana.

Média dos tempos de resposta (em segundos) do experimento, seus respectivos Speedups e Eficiência, para quatro situações, seqüencial, paralelo sem reserva, paralelo com reserva de 40% e paralelo com reserva de 70% Para os experimentos realizados, o desempenho da arquitetura Par_QoS foi bastante satisfatório para as situações com reserva de recursos.

Notoriamente, a situação de reserva de 40% de recursos, na qual se obteve um tempo da ordem da sexta parte (1/6) do tempo seqüencial e cerca de 55% do valor obtido com o programa paralelo sem reserva.

Assim, em relação ao tempo da aplicação paralela sem reserva, houve uma redução de tempo de 45% e 61,5% para as situações de reserva de 40% e 70%, respectivamente.

Através da eficiência, responsável por mensurar a utilização dos processadores, pode-se observar que para os programas paralelos com reserva de 40% e 70%, o processador foi melhor utilizado do que na disputa com os outros programas e sem nenhuma reserva.

Pela grande flexibilidade de configuração dos percentuais de reserva, o Par_QoS pode facilmente ser adaptado às especificidades de cada conjunto de aplicações, de maneira a não priorizar demais ou de menos alguma classe de processos.

Um ponto importante na utilização de Par_QoS é a garantia de que as demais aplicações que estão coexistindo na rede não sejam penalizadas (o que poderia levar a uma situação de inanição).

Para garantia de execução satisfatória dos demais processos do sistema, durante o experimento, foi observada uma medida de avaliação de programas seqüenciais, executados concorrentemente com programa paralelo, a fim de observar o grau de atraso inserido nas aplicações.

Como medida definida, foi utilizado o tempo de espera por processamento na fila de processos, e como aplicação seqüencial foi utilizada a execução de um arquivo de vídeo comprimido (não stream) no mesmo ambiente computacional anteriormente citado.

A aplicação foi escolhida por sua alta interatividade e grande utilização de largura de banda.

Dessa forma, um aumento significativo no tempo do processo na fila reduziria em demasia a qualidade da aplicação.

O experimento observou também o tempo de espera na fila para as aplicações de multiplicações de matrizes, utilizadas como geradoras de carga.

Tempo médio (em milissegundos) na fila para a aplicação de vídeo e de multiplicação nas diferentes situações de reserva de recursos do programa paralelo.

Observa-se que, como desejado, o tempo de fila para execução do vídeo aumentou progressivamente, muito embora esse aumento não tenha causado impacto significativo na reprodução do vídeo, já que o mesmo continuou executando sem paradas ou deterioração na qualidade do som, sendo notado apenas a perda de alguns frames.

Entretanto, é importante observar que a relação tempo de fila e aumento de reserva de recursos não é linear, ou seja, o tempo de espera em fila não cresce na mesma proporção do crescimento da reserva de recursos.

Assim, para a passagem do seqüencial para a reserva de 40%, houve cerca de 40% de aumento no tempo de fila para a aplicação de vídeo e cerca de 30% para a aplicação de multiplicação de matrizes.

Já na passagem do seqüencial para a reserva de 70% de recursos, o tempo de espera em fila cresceu cerca de 330% para o vídeo e 250% para a aplicação de multiplicação de matrizes.

Quando a comparação é feita entre as situações de reserva de recursos, também há uma relação não linear.

Assim, com o aumento de 40% para 70% de reserva, ou seja, um acréscimo de 75% na reserva, o tempo de fila aumentou cerca de 250% para a aplicação de vídeo e 200% para a aplicação de multiplicação de matrizes.

Essa análise leva à interpretação de que para cada conjunto de aplicações há um valor ótimo para reserva de recursos, sendo que esse valor é função direta do conjunto das aplicações.

Entretanto, pela grande facilidade de reconfiguração dos níveis de reserva dentro do Par_QoS, essa adaptação é facilmente realizada de acordo com as necessidades do conjunto de aplicações.

Para o experimento, também foi realizada uma análise sob a óptica da taxa de utilização do processador.

Essa análise da taxa de utilização da CPU pelas aplicações seqüenciais de multiplicação de matrizes compara as diferentes situações de reserva com o programa paralelo.

De acordo com o gráfico, nota-se que quando competem somente entre si, as aplicações de multiplicação ocupam cerca de 30% da CPU, cada uma, e cerca de 25% quando competindo entre si e com o programa paralelo sem qualquer tipo de reserva.

Essas duas situações demonstram uma divisão igualitária da utilização da CPU, proporcionada pelo escalonador de processos do Linux.

Entretanto, quando sob o domínio da arquitetura Par_QoS, as taxas de utilização para os programas de multiplicação de matrizes caem para 17% e 9% nas situações de reserva de 40 e 70%, o que denota uma divisão igualitária entre as aplicações seqüenciais, entretanto somente dentro da porcentagem da CPU não reservada.

Portanto, mesmo sob uma situação de alta reserva de recursos para uma aplicação paralela, todas as demais aplicações continuam a ser processadas, ainda que com menor taxa de utilização da CPU, indicando dessa maneira a não ocorrência de situações de inanição que os processos dessas aplicações poderiam vir a sofrer.

Esse fator é um importante indicativo de sucesso da arquitetura Par_QoS na provisão de um ambiente de computação paralela de custo-benefício favorável, o que possibilita que empresas e instituições carentes de recursos, mas com demandas de processamento de alto desempenho, realizem este tipo de computação.

Taxas de utilização da CPU por aplicações CPU-bound.

O gráfico apresenta a evolução dos tempos de espera em fila (Y) para a aplicação de vídeo em função do conjunto de 259 execuções (X).

Comportamento da aplicação de vídeo para as situações, sem reserva de recursos, com reserva de 40% e com reserva de 70%.

Este artigo apresenta uma proposição de arquitetura para prover computação paralela sobre um sistema operacional de propósito geral.

Há uma série de benefícios em adotar-se uma estratégia com o perfil apresentado neste trabalho.

A proposta traz algumas contribuições, destacando-se, viabilização de utilização de aplicações de computação paralela em redes não dedicadas e com sistemas operacionais de propósito geral.

Facilidade de configuração e reconfiguração do ambiente e dos percentuais de reservas, de acordo com o perfil da aplicação, utilização de padrões de direito ou de fato ao longo da arquitetura (MPI, TCP/IP e Linux).

Diminuição dos custos de implementação da plataforma computacional, pela utilização de ferramentas gratuitas e código aberto e infra-estrutura de rede já existente.

Ferramenta que pode ser utilizada, de forma didática, no ensino das disciplinas Sistemas Operacionais, Computação Paralela e Sistemas Distribuídos.

Atualmente, estão sendo definidas classes de aplicações, através de estudos de redes bayesianas, investigando-se parâmetros da aplicação, tais como, utilização de processador e memória, largura de banda necessária, grau de interatividade e tempo de resposta.

