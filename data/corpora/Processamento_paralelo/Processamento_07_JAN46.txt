O teste de software é uma etapa importante no ciclo de desenvolvimento de sistemas.

Com ele é possível identificar erros que por muitas vezes passam despercebidos pelos programadores.

Assim como na programação seqüencial, a programação paralela também necessita de ferramentas de teste que suportem todas as características e problemas desse tipo de ambiente de programação.

Problemas como o não-determinismo, sincronização entre processos e condições de corrida, são questões que impulsionam pesquisadores do mundo todo a trabalharem com pesquisas relacionadas a testes e depuração de programas paralelos.

Neste trabalho é feito um estudo sobre a hipótese de inserção do teste unitário em programas paralelos com o objetivo de tentar estender antigas abordagens utilizadas na programação seqüencial para utilizá-las no teste estrutural de programas paralelos.

Um processo de desenvolvimento de software consiste em inúmeras atividades, métodos e práticas úteis ao desenvolvimento de um produto de software.

Em outras palavras, um processo de software é um conjunto de etapas necessárias para transformar os requisitos de um usuário em software.

A criação de produtos de software tem se caracterizado por uma sobreposição de atividades necessárias para especificar, projetar e testar o retorno dos resultados do software que está sendo criado.

O feedback dessas atividades nos ajuda a compreender o que é necessário para criar um produto, corrigindo falhas, implementando as mudanças e melhorando a usabilidade e o desempenho do sistema.

Como peça chave no processo de ciclo de vida de um software, o teste é considerado uma das etapas mais importantes e difíceis desse ciclo.

Seu objetivo é detectar erros em um programa o mais cedo possível, contribuindo para aumentar a confiança de que o software desempenha as funções especificadas.

Existem várias estratégias e técnicas de teste de software, assim como existem diversos paradigmas de programação que permitem a construção de sistemas diversificados.

Uma classe especial de software é a classe dos programas paralelos.

Estes programas são capazes de realizar diversas execuções simultâneas, interagindo através de comunicações entre os processos.

Ao contrário dos programas seqüenciais que têm o código processado seqüencialmente por um único processador, os programas paralelos têm seu código divido em parcelas menores (divisão do problema), que são executados pelos processadores disponíveis no sistema.

Cada processo calcula então um resultado, e ao finalizarem seus trabalhos, os resultados são coletados representando a saída final do programa paralelo.

A vantagem dos programas paralelos sobre os programas seqüenciais é que devido à divisão do código seqüencial em pedaços menores, estes podem ser distribuídos por diversos processadores, os quais realizam o processamento do problema simultaneamente, resultando em uma execução do programa em um tempo menor e aumentando o desempenho da aplicação em relação à execução do mesmo problema num programa seqüencial.

Para tornar esse paralelismo possível, são necessárias algumas mudanças no ambiente de programação como, o tipo de hardware utilizado (arquiteturas das máquinas) e o tipo de paradigma de programação.

Tipo de Hardware, o programa paralelo deve ser executado em uma arquitetura paralela.

Uma arquitetura paralela consiste em diversos processadores interconectados podendo ser operados simultaneamente em um nodo local ou em nodos distribuídos.

Atualmente existem diversas arquiteturas para computadores paralelos, e a utilização dessas arquiteturas é indispensável para a execução desse tipo de programa.

Tipo de Paradigma, o programa paralelo deve ser implementado de maneira apropriada.

Para isso, existem paradigmas conhecidos que suportam tal desenvolvimento.

Um bom exemplo é o paradigma da troca de mensagens, onde os processos de um programa paralelo se comunicam explicitamente através das primitivas existentes nas linguagens que implementam esse paradigma.

Os programas paralelos, assim como qualquer programa, também estão sujeitos à falhas e precisam de rotinas de teste.

Questões de comunicação entre os processos são uma das maiores dificuldades do paradigma paralelo e têm sido tema de pesquisas acadêmicas em diversos trabalhos.

Nesse trabalho será feito um estudo sobre a hipótese de inserção de teste unitário em programas paralelos com o objetivo de verificar a presença de erros.

O paradigma paralelo utilizado será a troca de mensagens, onde a MPI (Message Passing Interface) será a ferramenta habilitadora para o desenvolvimento de estudos de caso futuros nesse paradigma.

Este trabalho está organizado da seguinte maneira, No capítulo 2 é apresentada uma revisão da área de Teste de Software, onde são discutidas algumas estratégias e técnicas comumente utilizadas.

No capítulo 3 é introduzido o tópico programação paralela, onde são feitas breves revisões sobre a computação paralela, modelos computacionais, programação com troca de mensagens e também o PVM e o MPI como ambientes para programação paralela.

No capítulo 4 são apresentados aspectos relacionados ao teste de software em programas paralelos.

São abordados diversos trabalhos existentes assim como questões relacionadas ao estado da arte do teste de software e depuração de sistemas paralelos.

Finalmente no capítulo 5 são apresentados os resultados e também pretensões de trabalhos futuros.

A fase de teste é usada para determinar o status do software em relação à sua especificação.

Ela determina quando uma aplicação pode ser liberada e também o seu desempenho futuro.

O teste de software visa identificar a maior quantidade possível de erros existentes em um sistema, aumentando assim a sua aceitabilidade, qualidade e confiabilidade.

Um dos problemas do teste de software é o fato de se tratar de um processo caro, chegando a custar mais de quarenta por cento do custo total do sistema.

Entretanto, embora de alto custo, o teste é um processo necessário, pois quanto mais tarde um erro for identificado no processo de desenvolvimento, mais custosa será a correção do mesmo.

As etapas de teste são consideradas fontes importantes de informação, pois fornecem uma forte base de interação entre os participantes do projeto.

Por se tratar de uma etapa de detecção de erros e principalmente erros cometidos por programadores, existem três termos importantes que precisam ser analisados, falha, erro e defeito.

Existe uma relação causa efeito nesses termos onde as falhas são as causas dos erros e os erros são as causas dos defeitos.

Basicamente falhas são violações do comportamento especificado.

Erros são manifestações de falhas nos sistemas, onde o processamento posterior à falha pode levar a um defeito.

E defeitos são estados em que o sistema tem um mal funcionamento causado por algum erro, gerando um desvio do comportamento esperado e sendo incapaz de realizar a função para o qual foi projetado.

A proposta da fase de teste é justamente procurar por falhas em programas.

Um processo relacionado é a depuração, onde o objetivo é localizar as partes do código que causam as falhas para tentar corrigi-las.

A dificuldade do teste faz com seja necessário organizar a aplicação do teste de maneira que este consiga mais facilmente atingir seus objetivos.

O teste de software geralmente é dividido nos seguintes níveis, Teste de Unidade, visa testar pequenas partes ou módulos de um sistema separadamente, com objetivo de garantir que a lógica do programa esteja completa e correta, fazendo com que este trabalhe conforme foi projetado.

O teste de unidade facilita o processo de localizar e corrigir um erro no código de uma aplicação e também adiciona a possibilidade de paralelizar o teste de diversos componentes de um software, diminuindo assim o tempo de teste.

Teste de Integração, como o software geralmente é dividido em módulos para facilitar o seu desenvolvimento, é necessário que a integração desses módulos também seja testada.

O teste de integração tem por finalidade verificar se o sistema depois de integrado se comporta conforme o esperado.

Teste de Validação ou de Sistema, este tipo de teste visa verificar a consistência do software de acordo com seus objetivos iniciais.

O teste de sistema é composto por um grande conjunto de sub-testes, tais como, testes de funcionalidade, volume, usabilidade, segurança, desempenho, compatibilidade, etc.

Embora os níveis de teste organizem e diminuam a complexidade do teste de um sistema, as estratégias de teste é que são responsáveis por encontrar os erros da aplicação.

Basicamente há três estratégias que podem ser aplicadas para a fase de teste, Teste de Caixa Preta (Black Box) ou Funcional, o teste funcional é uma técnica de teste que não leva em consideração o código do programa, ou seja, o código fonte não pode estar disponível.

Também é conhecido como caixa preta e utiliza somente a especificação do programa para a realização do teste, testando apenas o que o software deve fazer.

O teste funcional é baseado nas perspectivas dos dados de entrada verificando se as saídas coincidem com o esperado.

Teste de Caixa Branca (White Box) ou Estrutural, o teste estrutural também chamado de caixa branca, ao contrário do teste funcional, leva em consideração o código fonte do programa dando ênfase ao projeto detalhado.

Este tipo de teste é feito através do conhecimento da estrutura do programa, criando-se testes que exercitem os componentes de software.

Teste Estatístico, o teste estatístico tem o objetivo de avaliar a confiabilidade do sistema, medindo a probabilidade do sistema de operar sem falhas por um determinado período de tempo.

Seu principal benefício é permitir o uso de técnicas de inferência estatística para computar aspectos probabilísticos do processo de teste, como tempo médio para falha (MTTF) e tempo médio entre falhas (MTBF).

Este tipo de teste é baseado em modelos estatísticos de uso, ou seja, dados sobre formas típicas de utilização.

Extreme Programming é uma metodologia de desenvolvimento de software ágil para equipes que trabalham com requisitos em constante mudança.

Segundo os princípios norteadores, essa metodologia deve ser transparente, humana, produtiva, disciplinada, divertida e deve primar pela satisfação do cliente e pela qualidade final do software.

O XP como é conhecido, é focado nos papéis e funções do cliente, do gerente e dos programadores, buscando o sucesso do desenvolvimento de software através de um esforço coletivo e voltado para os seguintes valores, Simplicidade, o projeto do software e o processo em si são simplificados e modificados continuamente.

Comunicação, ao invés de trabalhar com grandes relatórios de requisitos, alterações e bugs, o XP utiliza o tradicional diálogo entre os envolvidos no projeto.

Coragem, é preciso coragem para apontar um problema no projeto, para parar quando se está cansado, e também para pedir ajuda quando necessário.

Feedback, todo problema é evidenciado o mais cedo possível para que possa ser corrigido o mais cedo possível.

Assim é preciso coletar opiniões continuamente.

O XP, além desses valores possui algumas práticas como, Disponibilidade do Cliente, o cliente está sempre disponível para responder dúvidas, alterar o escopo de uma interação e definir prioridades.

Eles expressam a certeza de que o produto desejado irá suprir as suas expectativas.

Tamanho reduzido de versões, todo o produto de software é entregue em pequenas versões, contribuindo para que o cliente possa obter o seu produto mais cedo, ajudando a minimizar riscos.

Prioridades dos testes, primeiro são escritos os testes, depois a implementação e por último trabalha-se no projeto do produto.

Interações contínuas, os diversos módulos do sistema são integrados diversas vezes por dia e todos os testes unitários são executados.

O código só é liberado se alcançar 100% dos testes unitários.

Programação em duplas, todo o código de produção é feito por duas pessoas trabalhando juntas na mesma estação de trabalho.

Como o XP é voltado para o trabalho em equipe, algumas responsabilidades devem ser levantadas em relação aos valores atribuídos aos integrantes da equipe, Clientes, assim como em qualquer outro meio de negócio os clientes são aqueles que têm um problema e precisam de uma solução tão imediata quanto sua necessidade de negócio.

Baseado nessas necessidades os clientes devem expressar a certeza de que essa nova ferramenta irá suprir as suas expectativas, por isso devem se dedicar para o sucesso do projeto.

No XP, os clientes é que definem o andamento do trabalho e os testes que mostram se o sistema cumpre os requisitos propostos.

Além disso, a equipe planeja e constrói software seguindo histórias (cenários) que descrevem o que o sistema precisa para funcionar.

Cada história mostra uma necessidade que o sistema tem que cumprir.

Sendo assim, os programadores precisam entendê-las para poder determinar as dificuldades que terão na construção do sistema além de testá-las individualmente.

A criação das histórias é responsabilidade dos clientes.

Programadores, os programadores são aqueles que definem a arquitetura, modelam, codificam, escrevem os testes e integram o sistema.

Os programadores determinam as dificuldades de todas as histórias e interagem com os clientes sobre o melhor cumprimento destas.

Tudo o que é feito é pensado nas etapas de programação para manter uma alta qualidade no código.

Para ter certeza de que o sistema irá sempre funcionar corretamente, os programadores usam testes unitários sobre o seu trabalho assim como os clientes usam testes de aceitação.

Os testes unitários permitem rápidas mudanças e suporte coletivo a erros individuais dos programadores.

Já os testes de aceitação visam verificar a consistência do software em relação à suas expectativas iniciais.

Gerentes, os gerentes são aqueles que controlam os recursos do projeto, mantendo os clientes e programadores trabalhando juntos e com harmonia.

Os gerentes oferecem todo o suporte para que o time de desenvolvedores seja uniforme, sem diferenças pessoais e conflitos de comportamento.

Eles não fazem o processo, eles mantêm o processo.

Clientes, programadores e gerentes trabalham todos juntos para construir o sistema desejado.

Mais detalhes sobre a Extreme Programming em.

O teste unitário é um teste escrito para uma pequena funcionalidade de uma aplicação, e não é indicado para testar funcionalidades mais abrangentes.

O teste unitário é apenas um pedaço de código que serve para exercitar outro pedaço de código, e com isso determinar se este código exercitado corresponde ao esperado na sua espeificação.

Com esse tipo de teste é possível no momento da criação do programa, verificar se o código está fazendo o que realmente tem que fazer.

Assim, o programador só continua o andamento do projeto após ter garantia que sim, caso contrário se dedica a arrumar os erros encontrados.

Por exemplo, numa rotina para deletar alguns caracteres de uma string, como verificar se os caracteres foram realmente deletados?

Os testes unitários são executados para justamente provar que um pedaço de código faz realmente o que o programador pensa que ele deveria fazer.

No Extreme Programming, os testes unitários são determinísticos, ou seja, nenhuma etapa do desenvolvimento termina sem passar pelo teste unitário.

Os próprios programadores é que escrevem os testes unitários, criando testes para códigos onde a alta complexidade dificulta o entendimento, reduzindo drasticamente a quantidade de tempo gasto com depuração de código.

Um simples teste unitário pode ser escrito para checar se um código comporta-se como o esperado.

Usa-se então uma afirmação, ou seja, uma simples chamada a um método (procedimento ou função) que verificará se algo é verdadeiro.

Por exemplo, o método assertTrue verifica se o parâmetro passado para ele é verdadeiro, caso contrário o teste falha.

Apresenta um trecho simples do código que representa esse teste na linguagem Java.

Teste unitário para verificação de um parâmetro.

É possível usar assertTrue para verificar várias coisas, como por exemplo quando um número é igual a outro.

Neste caso, quando a chamada da função não é verdadeira, o programa é abortado.

Teste unitário para verificação de equivalência de valores.

Quando se deseja criar um código de teste, existem algumas convenções de nomes que devem ser seguidas.

Por exemplo, se existe um método ou uma função ao qual se deseja testar e esta esteja definida como "CriarConta", o método para testar essa função deve se chamar "testeCriarConta", obedecendo-se assim uma nomenclatura padrão para código de teste e para código de produção (código a ser testado).

O código de teste deve chamar o código a ser testado com todos os parâmetros necessários testando assim o seu funcionamento.

É possível que existam vários códigos de teste para se testar um programa.

Código de Teste e Código de Produção.

Mostram um exemplo na linguagem C, onde é possível se verificar essas convenções.

Esse exemplo executa dois testes onde um teste é aprovado e outro reprovado.

O programa exemplo é apenas uma função de teste que retorna 0 (null) se o teste passar, e uma mensagem de erro caso o teste seja reprovado.

A macro "assert" retorna uma string se a expressão passada for falsa.

E a macro "exec_teste" chama outro teste caso o primeiro teste falhe.

Biblioteca de teste verifica h.

Código de teste teste_unitario.

A crescente necessidade por aplicações capazes de oferecer um melhor desempenho tem impulsionado o desenvolvimento de tecnologias na área da computação paralela.

A melhor forma de aumentar esse desempenho consiste na elaboração de técnicas e ferramentas adequadas às arquiteturas paralelas, sejam elas de memória compartilhada ou de memória distribuída.

A correta exploração das características das máquinas paralelas e do paralelismo implícito nas aplicações proporciona a obtenção de melhores tempos de execução, aumentando assim o desempenho dos sistemas.

O aperfeiçoamento das bibliotecas de troca de mensagens, por exemplo, tem ajudado projetistas de sistemas a explorarem melhor este modelo de programação e obterem aplicações mais eficientes.

Além disso, devemos considerar também a crescente necessidade de sistemas computacionais que combinem alto desempenho com baixo custo financeiro.

Neste caso, o emprego de clusters pode representar uma solução alternativa para o desenvolvimento de aplicações que necessitem de alto desempenho ou alta disponibilidade.

Tais máquinas podem ser construídas a partir de um conjunto de estações de trabalho interligadas por uma rede de alta velocidade.

Sendo um cluster um sistema de memória distribuída, eles têm seu potencial explorado adequadamente com a utilização de tecnologias baseadas em troca de mensagens.

O paradigma de programação baseado em troca de mensagens requer o uso de uma biblioteca de funções que ofereça suporte à comunicação entre diferentes processos ou nós de processamento.

Atualmente, o MPI (Message Passing Interface) tem se consolidado como um padrão para o desenvolvimento de aplicações baseadas em trocas de mensagens.

O MPI propõe uma biblioteca de funções específicas, permitindo a realização de diversas operações de comunicação, além de possuir diferentes implementações disponíveis.

Ilustra as principais características da arquitetura de um cluster.

Como podemos observar, o cluster é formado por um conjunto de máquinas conectadas através de uma rede de alta velocidade e um switch, onde é possível a execução tanto de aplicações seqüenciais quanto paralelas.

Cada uma destas máquinas, por exemplo, um PC ou uma estação de trabalho, possui sua própria interface de rede responsável por receber e transmitir pacotes de dados através da rede de interconexão.

A garantia da fidelidade dos dados transmitidos é uma das funções do software de comunicação que está diretamente ligado aos processos de empacotamento e desempacotamento das mensagens transmitidas.

Arquitetura de um Cluster.

A criação da imagem de um sistema de processamento integrado e único é uma característica comumente encontrada em clusters.

Tal imagem é gerada com o suporte de um middleware, que não apenas possibilita o processamento paralelo e distribuído, mas também permite a execução de aplicações seqüenciais.

Desta forma, as máquinas podem trabalhar como um sistema computacional único ou como computadores individuais.

Os computadores paralelos surgiram na década de 80, onde os pesquisadores buscavam encontrar soluções cada vez mais rápidas e que resolvessem problemas com grande quantidade de informação.

Áreas como previsão do tempo, processamento de imagens, inteligência artificial, modelagem e simulação de grandes sistemas sofrem esse tipo de necessidade.

Com a computação paralela a criação de algoritmos modifica-se sensivelmente.

As estratégias utilizadas em algoritmos seqüências para resolver um problema são diferentes das estratégias de algoritmos paralelos, pois os recursos disponíveis na programação paralela são maiores.

Na criação de algoritmos deve-se considerar a natureza dos problemas.

Alguns são inerentemente paralisáveis, outros apresentam um paralelismo menos transparente, exigindo estratégias mais elaboradas na montagem dos algoritmos, e existem aqueles em que o grau de paralelismo é muito baixo ou até mesmo inexistente.

Além disso, no desenvolvimento dos algoritmos deve-se considerar a arquitetura paralela a ser utilizada.

A computação paralela divide uma tarefa em subtarefas que podem ser executadas simultaneamente por diferentes processadores.

O nível de paralelismo, ou granularidade está relacionado com o tamanho médio das subtarefas executadas pelos processadores e pode ser classificada como, fina, média e grossa.

Na granularidade grossa, cada processo contém um grande número de instruções seqüenciais e gasta um tempo considerável para executá-las.

Na granularidade fina, o processo tem poucas instruções, ou até mesmo uma única instrução.

Já a granularidade média representa um grupo intermediário de instruções.

Geralmente, aumenta-se a granularidade para reduzir os custos de comunicação entre os processos, principalmente em ambientes de troca de mensagens.

Deve-se tomar cuidado com o aumento excessivo de granularidade, pois reduz o número de processos concorrentes e também o nível de paralelismo.

A granularidade não está envolvida diretamente com a otimização de algoritmos paralelos, porém as tendências atuais de máquinas paralelas incentivam o uso de algoritmos com granularidade grossa, com o intuito de minimizar a comunicação e aumentar a eficiência.

Um dos fatores que justifica a necessidade do processamento paralelo é a capacidade de aumentar a velocidade de processamento.

Com esse aumento no processamento, aumenta-se também a velocidade com que os processadores chegam a uma solução.

Para quantificar esse desempenho, utiliza-se diferentes parâmetros, entre eles o speedup e o cálculo de eficiência.

O speedup (Sp) pode ser definido como o aumento de velocidade conseguido com a execução de um algoritmo paralelo em relação aos tempos conseguidos com um algoritmo seqüencial.

Um bom speedup é conseguido quando Sp = p (processadores), ou seja, na medida em que se aumenta o número de processadores, aumenta-se diretamente a velocidade de processamento.

O cálculo de eficiência indica em média a utilização dos processadores, o que varia entre 0 (0%) e 1 (100%).

Dificilmente obtém-se eficiência igual a 1, pois sempre haverá perdas na paralelização do algoritmo com a sobrecarga de comunicação e no sincronismo entre os processadores.

Para coordenar as tarefas dos vários processadores que trabalham na solução de um mesmo problema é necessária alguma forma de comunicação entre eles para transportar informações e dados entre os processadores, e para a sincronização de tarefas.

A forma de comunicação e sincronização entre os processadores depende do modo de acesso à memória e afeta diretamente a maneira como os programas paralelos são escritos.

Arquiteturas com Memória Compartilhada Nas arquiteturas de memória compartilhada têm-se múltiplos processadores operando independentemente, mas compartilhando o mesmo espaço de endereçamento, ou seja, um único bloco de memória.

Somente um processador pode acessar a memória por vez, por isso, deve haver por parte do programador um controle para manter os dados consistentes.

Não deve ser permitido que enquanto um processador esteja lendo um dado, um outro processador escreva na mesmo localização de memória.

Este controle é feito utilizando mecanismos como semáforos e monitores.

Como vantagens dessa arquitetura, têm-se, velocidades iguais tanto para a troca de dados entre as tarefas quanto para o acesso à memória, simplicidade, o que permite uma utilização eficiente.

Como desvantagens a memória pode tornar-se o gargalo do sistema, o aumento do número de processadores implica em perda de desempenho se a estrutura de acesso a memória não possuir tamanho de banda necessário, o usuário é responsável pela sincronização.

Nestas arquiteturas, têm-se múltiplos processadores independentes, mas cada um possui uma memória local própria que é acessada somente por esse processador.

Os dados podem ser compartilhados através de uma rede de comunicação utilizando troca de mensagens.

Neste modo de acesso, o programador deve também preocupar-se com a sincronização, que é obtida através da troca de mensagens.

Como vantagens, têm-se, a memória aumenta proporcionalmente com o aumento do número de processadores, cada processador pode acessar rapidamente sua própria memória, sem interferências.

Como desvantagem, o usuário é responsável por enviar e receber dados entre os processos alocados em nodos distintos, o que implica na criação de um controle de fluxo, controle sobre mensagens perdidas e buferização.

Basicamente existem dois aspectos que caracterizam um modelo computacional.

No aspecto operacional, um modelo computacional especifica que tipo de algoritmo pode ser projetado.

Nesse aspecto é descrito sem considerar detalhes de tecnologia e hardware o que o computador pode fazer, ou seja, quais ações primitivas ele é capaz de executar.

Um outro aspecto, mais matemático de um modelo computacional, permite a análise de um algoritmo.

Há mais de quarenta anos a arquitetura dos computadores utiliza o modelo proposto por John von Neumann.

Esta arquitetura é composta por uma unidade central de processamento (UCP) e pela memória principal.

A UCP por sua vez, é composta de uma unidade de controle (UC) e uma unidade lógica e aritmética (ULA).

A memória principal armazena as instruções e os dados do programa que está sendo executado.

A UC controla a execução do programa, buscando uma instrução depois da outra da memória para ser executada pela UCP.

As instruções e os dados trazidos da memória para serem executados, são armazenados nos registrados da UCP.

Os registrados são pequenas memórias de rápido acesso.

A ULA realiza as operações lógicas e aritméticas determinadas pelas instruções do programa.

O gargalo da arquitetura de Von Neumann é a transferência de dados e instruções entre a memória principal e a UCP.

Isto significa que não importa o quanto a UCP seja rápida, a velocidade de execução dos programas é limitada pela velocidade de transferência das instruções dos dados entre a memória e a UCP.

Por esta razão, poucos computadores utilizam atualmente a arquitetura clássica de Von Neumann.

A maioria das máquinas atuais possui uma hierarquia de memória, isto é, possui uma memória intermediária entre a memória principal e os registradores, chamada memória cache.

O acesso à memória cache é mais rápido do que o acesso à memória principal, e mais lento que o acesso aos registradores.

Dessa forma, a arquitetura diminui os efeitos do gargalo de Von Neumann.

O modelo RAM (Random Access Machine) é um modelo conceitual sólido que incorpora as principais características da computação seqüencial.

A grande vantagem deste modelo é sua capacidade de assimilar os aspectos da tecnologia para computadores do tipo Von Neumann.

O modelo PRAM (Parallel Random Access Machine) corresponde a uma coleção de processadores, cada um com uma memória local executando em paralelo e comunicando-se através de uma memória global compartilhada.

Esse modelo é uma extensão natural do modelo seqüencial RAM.

Nele, cada processador pode executar uma instrução distinta daquela executada por qualquer outro processador, em uma mesma unidade de tempo.

O modelo de memória distribuída consiste de um conjunto de processadores onde a memória está distribuída entre os processadores e nenhuma memória global está disponível.

Nesse modelo, a comunicação é feita através da troca de mensagens entre os processadores.

O processo de entrega da mensagem do processador origem para o processador destino é chamado roteamento.

A topologia de interconexão dos processadores é incorporada pelo próprio modelo.

O desempenho dessas topologias é dado em função de dois parâmetros, o diâmetro, que é a distância máxima entre quaisquer dois processadores, e o grau máximo, que corresponde ao número de processadores ligados diretamente e um processador.

As principais topologias usadas no modelo de memória distribuída são, lista linear, anel, grade, árvore binária e hipercubo.

Nos modelos de memória distribuída, geralmente a computação é efetuada usando um número fixo de processadores interconectados numa determinada topologia.

No paradigma seqüencial de programação o programador possui uma visão simplificada da máquina como sendo um único processador acessando certa quantidade de memória.

O programa desenvolvido neste paradigma é portável para qualquer arquitetura seqüencial.

Já o paradigma de troca de mensagens é uma busca da portabilidade para a programação paralela.

Neste paradigma várias instâncias do paradigma seqüencial trabalham juntas.

Isso significa que o programador pode imaginar vários processadores distribuídos e escrever um programa para ser executado em cada um desses processadores.

Mas a programação paralela por definição, requer a cooperação entre os processadores, o que torna necessário a criação de algum meio de comunicação.

A principal característica do paradigma de troca de mensagens é que os processadores comunicam-se através do envio de mensagens entre os processadores cooperantes.

Então, nesse modelo não há o conceito de memória compartilhada.

Um ambiente de troca de mensagem deve prover mecanismos que permitam criar e executar processos.

Os processos podem ser criados de modo estático ou dinâmico.

No modo estático, todos os processos são especificados antes da execução e o sistema executa um número pré-determinado de processos.

Na maioria das aplicações existe um processo especial que controla a execução dos demais processos, denominado processo mestre.

Os demais processos são denominados processos escravos.

No modelo SPMD (single Program, Multiple Data) o código dos diferentes processos são colocados dentro de um único programa onde é possível selecionar diferentes partes para cada processo.

Cada processador carrega uma cópia deste programa na sua memória local para ser executado.

O modelo SPMD implementa um paralelismo de dados.

Já no modo dinâmico, os processos podem ser criados e suas execuções iniciadas durante a execução de outros processos.

Processos também podem ser destruídos.

O modelo mais usado para a criação de processos dinâmicos é o MPMD (Multiple Program Multiple Data), no qual programas diferentes são escritos para processadores diferentes.

Neste modelo também se pode usar o paradigma mestre-escravo, onde um único processador executa o processo mestre e os processos escravos são criados e iniciados, nos demais processadores, pelo processo mestre.

O modelo MPMD implementa um paralelismo funcional.

Envio e Recebimento Existem duas rotinas básicas para o envio e o recebimento de mensagens entre os processadores.

A rotina de envio é usada pelo processo que deseja enviar uma mensagem e a rotina de recebimento é usada pelo processo que deseja receber a mensagem que foi enviada.

Os principais parâmetros utilizados por essas rotinas são o processador destino e a localização dos dados a ser enviado na rotina de envio, e o processador origem e a localização onde o dado recebido será armazenado na rotina de recebimento.

As rotinas de envio e recebimento podem ser bloqueantes ou não-bloqueantes.

O termo bloqueante é usado para descrever rotinas que bloqueiam a execução do processo, isto é não permite que o processo execute a próxima instrução até que a mensagem enviada tenha sido recebida.

Já o termo não-bloqueante é usado para descrever rotinas que não bloqueiam a execução do processo, ou seja, permitem que o processo continue sua execução mesmo que a mensagem enviada ainda não tenha sido recebida.

Nesse caso geralmente é necessário um buffer de mensagens entre os processos origem e destino para armazenar as mensagens que estão sendo enviadas.

Assim, se o recebimento é executado antes do envio, ele encontra o buffer de mensagens vazio e aguarda a chegada da mensagem.

Mas, se o envio é executado antes, uma vez que a mensagem esteja armazenada no buffer, o processo pode continuar a sua execução.

Broadcast, Gather e Scatter Além das rotinas básicas de envio e recebimento existem muitas outras rotinas relacionadas a troca de mensagens.

Uma situação bastante freqüente é a necessidade de um processo enviar a mesma mensagem para mais de um processo destino.

A operação multicast é usada para enviar uma mensagem para um grupo definido de processos.

Uma generalização é dada pela operação broadcast, usada para enviar uma mensagem para todos os processos envolvidos com a solução do problema.

O Processo 0, identificado como o processo raiz, armazena em um buffer o dado que deve ser enviado.

Todos os processos executam a rotina broadcast e recebem o dado numa determinada variável.

O brodcast não será executado até que todos tenham alcançado a sua chamada, e por isso sincroniza a execução dos processos.

A operação scatter é usada para o envio de cada elemento de um vetor, armazenado no processo raiz para diferentes processos.

O conteúdo da i-ésima posição do vetor é enviado para o i-ésimo processo.

Todos os processos executam a rotina scatter, e o processo raiz também recebe um elemento do vetor.

A operação gather é o oposto da operação scatter, O dado do i-ésimo processo é recebido pelo processo raiz e armazena na i-ésima posição do vetor.

Às vezes a operação gather pode ser combinada com um operação aritmética específica ou uma operação lógica.

Por exemplo, os valores podem ser coletados e depois adicionados pela raiz.

O termo reduce é utilizado para definir esta operação.

Operação reduce.

Os ambientes de troca de mensagens foram desenvolvidos com três grandes objetivos, o utilizar o potencial dos sistemas distribuídos para o desenvolvimento de aplicações paralelas, o permitir a união de plataformas heterogêneas, o permitir a portabilidade das aplicações paralelas desenvolvidas.

Baseados nesses objetivos e também devido à diversidade encontrada nos ambientes já existentes, vários grupos foram formados com a finalidade de desenvolver as plataformas de portabilidade de troca de mensagens.

Essas plataformas têm por objetivo tornar os ambientes portáveis, ou seja, permitir que os programas sejam executados em qualquer equipamento para o qual o ambiente foi desenvolvido.

Podemos citar como exemplos dessas plataformas, o PVM (Parallel Virtual Machine) e o MPI (Message Passing Interface).

O PVM é um conjunto integrado de bibliotecas de funções e de ferramentas de software, cuja finalidade é emular um sistema computacional concorrente heterogêneo, flexível e de propósito geral, permitindo que uma coleção de sistemas de computadores heterogêneos possa ser visto como uma única máquina paralela virtual.

O projeto do PVM teve início em 1989 no Oak Ridge National Laboratory ORNL e seu protótipo (versão 10) foi implementado por Vaidy Sunderam e Al Geist (ORNL).

Com a versão 20 deu-se início a disponibilidade pública do código.

A versão mais recente e disponível é a 3,4.

No PVM, um conjunto de computadores heterogêneos emula um grande computador de memória distribuída denominada máquina virtual.

Cada componente desta máquina virtual é denominada host.

Vários usuários podem definir diferentes máquinas virtuais na mesma rede, podendo algumas máquinas fazer parte de mais de uma máquina virtual executando aplicações PVM simultaneamente.

O PVM fornece funções para iniciar a execução de tarefas (tasks) na máquina virtual e também funções para que estas tarefas comuniquem-se e sincronizem-se entre si.

Em termos de implementação, o modelo computacional do PVM é composto por duas partes, um deamon (usualmente denotado por pvmd) e uma biblioteca de rotinas com a interface PVM (usualmente denotada por libpvm).

O usuário que deseja utilizar o PVM deve primeiramente configurar a máquina virtual especificando a lista de hosts e iniciar o deamon em todas as máquinas que fazem parte da máquina virtual.

O pvmd não faz nenhum processamento, somente roteamento e controle de mensagens, ou seja, funciona como um ponto entre os hosts autenticando as mensagens, fazendo o controle de processos e detectando possíveis falhas.

Na libpvm encontram-se as primitivas necessárias à comunicação entre as tarefas de uma aplicação, funcionando como um elo entre uma tarefa e a máquina virtual, ou seja, são rotinas que podem ser chamadas pelo usuário para efetuar troca de mensagens, solicitar a geração de processos, coordenar tarefas e solicitar modificações na máquina virtual.

Os processos podem ser iniciados dinamicamente.

Os programas PVM geralmente utilizam o modelo mestre-escravo, onde o processo mestre é o primeiro a ser executado e todos os outros processos são criados por ele.

Para iniciar a execução de um ou mais processos idênticos, é usada a rotina pvm_spawn.

A comunicação ponto-a-ponto é realizada no PVM através das rotinas pvm_send e pvm_recv.

Todas as rotinas de envio do PVM são não-bloqueantes e as rotinas de recebimento podem ser bloqueantes ou não-bloqueantes.

As rotinas de envio e recebimento de mensagens utilizam um buffer de mensagens.

Se os dados estiverem armazenados no buffer, a rotina de envio é usada para iniciar o envio do conteúdo do buffer de envio através da rede até o buffer de recebimento, preparado pela rotina de recebimento.

Os dados da mensagem a ser enviada devem ser empacotados em um buffer de envio antes de serem enviados.

Existem rotinas especificas para empacotar e desempacotar cada tipo de dados, como por exemplo, pvm_pkint e pvm_upkint.

O buffer de envio padrão deve ser inicializado pelo processo origem através da rotina pvm_initsend.

A rotina pvm_recv cria um novo buffer de recebimento para receber a mensagem.

O PVM também oferece várias rotinas para comunicação coletiva.

Essas rotinas são utilizadas para a comunicação entre os membros de um grupo de processos.

Em geral, os grupos envolvem mais que dois processos.

Essas rotinas implementam as operações coletivas descritas.

As rotinas pvm_bcast, pvm_gather, pvm_scatter e pvm_reduce são as implementações das operações de broadcast, gather, scatter e reduce respectivamente.

Além das rotinas descritas, o PVM oferece outras rotinas necessárias para o desenvolvimento de programas que utilizam a troca de mensagens como forma de comunicação entre os processos.

A descrição dessas rotinas pode ser obtida em.

O MPI é um padrão que tenta definir a sintaxe e a semântica de uma biblioteca de rotinas de mensagens.

A principal vantagem de estabelecer um padrão é a portabilidade.

O MPI foi desenvolvido por um comitê (MPI Committee) composto por cerca de 80 pesquisadores representando mais de 40 organizações que trabalham com processamento paralelo em todo o mundo, especialmente na Europa e Estados Unidos.

O MPI foi desenvolvido de modo a alcançar os seguintes objetivos.
Portabilidade de código fonte, permitindo que uma implementação seja usada em um ambiente heterogêneo sem alterações.

Possibilidade de ser utilizado tanto em sistemas de memória distribuída quanto em memória compartilhada, ou em uma combinação deles.

Definir uma interface semelhante à dos padrões PVM, Express, P4, Linda, etc.

Prover uma interface de comunicação confiável, de tal forma que o usuário não precise se preocupar com falhas na comunicação.

Definir uma interface que possa ser implementada em plataformas diferentes, sem mudanças muito significativas na parte de comunicação e software.

Inicialmente um conjunto básico de rotinas foi definido.

Este conjunto inclui rotinas para comunicação ponto-a-ponto e comunicação coletiva, suporte para grupo de processos, suporte para contexto de comunicação e suporte para topologia de processos.

As principais implementações do MPI são, LAM, executa em redes de estações de trabalho.

Essa implementação foi desenvolvida pela universidade de Ohio (Ohio Supercomputer Center).

MPICH, executa em diferentes plataformas.

A implementação foi desenvolvida no Argonne National Lab e na Universidade de Mississippi.

Assim como o PVM, o MPI provê uma biblioteca de rotinas para troca de mensagens e outras operações relacionadas, conforme apresentado a seguir.

A criação e execução dos processos não estão definidos no padrão MPI e dependem de sua implementação.

O MPI permite a criação estática de processos o que possibilita a utilização do modelo SPMD.

Geralmente, um programa executável é iniciado por linha de comando.

Por exemplo, o mesmo programa pode ser iniciado em diferentes processadores simultaneamente através do comando mpirun programa1 -np 4.

Este comando inicia a execução de quatro cópias do programa.

O Comando não especifica onde as cópias serão executadas.

O mapeamento dos processos nos processadores também não está definido no padrão MPI e depende da implementação.

O mapeamento pode ser feito através de linhas de comandos ou através de um arquivo contendo o nome dos programas e os processadores onde devem ser executados.

Antes que qualquer função MPI seja chamada, a função MPI_Init deve inicializar o MPI, e após todas as funções MPI terem sido chamadas, a função MPI_Finalize deve finalizar o MPI.

Inicialmente, todos os processos pertencem a um único comunicador denominado MPI_COMM_WORLD, e cada processo recebe um único identificador que corresponde a um número entre 0 e n-1, onde n é o número de processos.

Um comunicador define o escopo de uma operação de comunicação, ou seja, o conjunto de processos que podem comunicar-se.

O MPI permite que diferentes escopos sejam criados, isso significa que o programa pode definir diferentes escopos formados por diferentes subconjuntos de processos.

Cada escopo criado é denominado grupo na terminologia MPI.

Cada processo possui um identificador único dentro de um grupo e um processo pode ser membro de grupos diferentes.

A comunicação ponto-a-ponto é feita através das funções de envio e recebimento.

No MPI, essas funções podem ser bloqueantes ou não-bloqueantes.

As rotinas bloqueantes retornam quando estão localmente completas.

O envio bloqueante envia a mensagem e retorna.

Isso não significa que a mensagem tenha sido recebida, mas que o processo pode continuar sua execução sem afetar a mensagem.

O recebimento bloqueante retorna quando a mensagem é recebida.

As rotinas de envio e recebimento bloqueantes no MPI são implementadas pelas funções MPI_Send e MPI_Recv respectivamente.

Uma rotina não-bloqueante retorna imediatamente independente se a rotina está ou não localmente completa.

Por exemplo, o recebimento não bloqueante irá retornar mesmo que a mensagem ainda não tenha sido recebida.

As funções MPI_Isend e MPI_Irecv implementam, respectivamente as rotinas de envio e recebimento não-bloqueantes.

As rotinas de comunicação coletiva envolvem um conjunto de processos, diferentemente das rotinas de comunicação ponto-a-ponto que envolve apenas um processo origem e um processo destino.

O comunicador define o conjunto de processos que irá participar da operação coletiva.

Assim como o PVM, o MPI oferece um conjunto de rotinas que implementam as operações coletivas descritas.

As rotinas MPI_Bcast, MPI_Gather, MPI_Scatter e MPI_Reduce implementam as operações de broadcast, gather, scatter e reduce, respectivamente.

Um dos aspectos mais importantes do MPI é o de prover um padrão para o desenvolvimento de bibliotecas para a programação paralela.

Por se tratar de um padrão, existe uma preocupação constante em manter o MPI atualizado para que ele não se torne obsoleto com o passar do tempo.

O paralelismo tornou-se uma área muito importante para computação moderna.

Com isso, significantes desafios estabelecem barreiras entre as arquiteturas seqüências e paralelas.

Inúmeros esforços vêm sendo aplicados por pesquisadores do mundo todo com o objetivo de desenvolver ferramentas de software para ambientes paralelos similares aos usados em ambientes seqüenciais.

Infelizmente, criar programas paralelos ainda é uma tarefa desafiadora.

Primeiro porque em um único programa paralelo, múltiplas tarefas podem ser executadas paralelamente, resultando em inúmeras linhas de execução, o que dificulta a identificação desses caminhos.

Segundo porque a comunicação de dados e a sincronização entre os processos são freqüentes.

Dessa forma, os programadores têm que considerar não apenas a lógica existente em numa execução, mas também a comunicação e a sincronização entre diferentes processos.

E terceiro devido à ocorrência do não-determinismo, o que pode 4 resultar em execuções diferentes mesmo utilizando-se os mesmo dados de entrada.

Embora o não-determinismo seja um problema que vêm sendo estudado há anos, os erros em programas paralelos nem sempre são causados por esse fenômeno, e podem não ser detectados mesmo quando o programa é depurado várias vezes.

Assim, um dos maiores obstáculos para quem lida com programas paralelos é a falta de ferramentas de teste de software para esses programas.

Diversos pesquisadores vêm propondo metodologias, frameworks, arquiteturas e inúmeras soluções no âmbito do teste de programas paralelos.

Geração automática de casos de teste, depuração de sistemas distribuídos e testes de interface para componentes distribuídos são alguns dos trabalhos mais freqüentes.

Porém, poucos trabalhos sobre teste estrutural de programas paralelos são encontrados nas bibliografias existentes.

Com o objetivo de promover uma análise do que existe nas bibliografias modernas sobre teste de software para programas paralelos, a seguir será apresentada uma revisão de alguns trabalhos relacionados à área.

De modo geral, o teste estrutural de programas seqüências envolve encontrar caminhos que cubram estados do programa baseado em critérios específicos.

Nos programas seqüências, diversas informações relevantes estão localizadas em um único ambiente de execução, ou seja, em um único processo.

Isso já não acontece com os programas paralelos, porque devido ao uso de memória compartilhada ou até mesmo distribuída, essas informações ficam armazenadas em diferentes processos.

Com o objetivo de examinar a possibilidade de estender a metodologia de teste estrutural utilizada em programas seqüenciais para ser utilizada em programas paralelos, em são apresentados critérios básicos necessários para utilizar abordagens dessa mesma metodologia em programas paralelos.

Assim, os autores analisam alguns trabalhos relacionados para a geração de casos de teste para programas paralelos e concluem que este trabalho foi o primeiro esforço para reutilizar abordagens de teste seqüencial em testes de programas paralelos de memória compartilhada.

Com o surgimento de tecnologias para construção de sistemas distribuídos baseados em componentes, como CORBA, DCOM e Java RMI, questões de teste para esses tipos de sistemas e para os componentes em específico, começaram a ser discutidos.

Diversas limitações para esse tipo de tecnologia surgiram e novas metodologias de teste foram propostas.

Em é proposto uma metodologia de teste chamada TDS, que tem o objetivo de limitar os testes somente para condições específicas e necessárias.

Neste trabalho os autores propõem critérios de adequação de teste baseado na interface do componente, onde a redução dos testes depende do tamanho do domínio de cobertura.

Assim, o ponto principal para o sucesso do uso dessa metodologia é a definição precisa da interface do componente.

O progresso desse trabalho é conduzido através de experimentos com CORBA, onde a linguagem para definição de interfaces (IDL) descreve a cobertura da interface do componente.

As áreas de teste e depuração são áreas diferentes, mas com atividades bem relacionadas.

O teste visa revelar a presença de erros, enquanto a depuração localiza e remove os erros encontrados.

Diversos pesquisadores trabalham para resolver desafios relacionados à depuração de programas paralelos, como os problemas encontrados em ambientes onde a comunicação é baseada na troca de mensagens.

Nesse tipo de sistema paralelo, uma vez que um processo termina por causa de um erro inesperado, ele pode propagar o erro pelo resto dos processos em execução através das dependências de comunicação existentes entre processos, resultando em um defeito no sistema.

Em é apresentada a MPI-PreDebugger, uma ferramenta de depuração para sistemas paralelos baseados em troca de mensagens para localizar falhas em processos.

Essa ferramenta distingue o erro original do erro propagado através da verificação dos erros ocorridos com a comunicação durante a execução do programa.

A MPI-PreDebugger foi implementada na linguagem C++ e é basicamente formada por três módulos principais, uma ferramenta de controle, uma biblioteca para erros de execução e uma ferramenta de localização e visualização.

Através dessas ferramentas, é possível substituir as rotinas do código existente por rotinas instrumentadas, que são combinações das rotinas originais do MPI com funções de detecção de erros de execução.

Após esse processo de substituição, é preciso compilar o programa a ser analisado, lincando o código objeto com bibliotecas de detecção de erros.

Ao executar o programa, as rotinas de comunicação entre os processos são monitoradas.

Caso haja a detecção de algum erro nessa comunicação, a execução do programa é interrompida e uma espécie de arquivo de log descrevendo o comportamento dos processos durante a execução do programa é gerado.

Segundo os autores, com isso é possível mapear o comportamento da execução de programas distribuídos baseados na troca de mensagens, reduzindo a quantidade de informações necessárias para a depuração.

Em um outro trabalho também relacionado a ferramentas de depuração, são apresentados estudos para depuração de grandes e complexos sistemas de software paralelos baseados em arquiteturas modernas de hardware.

O autor discute técnicas usadas para depuração em diferentes tipos de sistemas distribuídos, apresentando maneiras de execução de monitoramento de sistemas.

São discutidos também problemas que podem ser encontrados e diferentes abordagens de depuração encontradas na literatura.

Com o surgimento de tecnologias que dêem suporte ao desenvolvimento de programas em ambientes paralelos e distribuídos, surgiram também ferramentas de teste e depuração para esses programas.

Como os ambientes paralelos e distribuídos estão ficando cada vez mais populares, e muito se deve à tecnologia moderna que permite que simples computadores pessoais interligados por uma rede de alta velocidade alcancem desempenhos de programação nunca conseguidos por máquinas isoladas, tanto pesquisadores quanto empresas comerciais estão dedicando seus esforços para esse novo conceito de programação paralela e distribuída.

Como não poderia ser diferente, o teste de software para ambientes paralelos e distribuídos vem evoluindo, e tornando-se uma tecnologia importante no auxilio a programadores e projetistas na construção desses sistemas.

Embora já difundido em ambientes de programação seqüencial, o teste de software em ambientes paralelos ainda tem muito que evoluir, visto que a aceitação desses ambientes é algo recente.

No capítulo 4, foram abordados alguns aspectos interessantes no âmbito do teste de software para programas paralelos.

Tópicos como o não-determinismo, execução de múltiplas tarefas em diferentes processos, testes de interface de componentes e depuração de processos utilizando rotinas de código instrumentadas para detecção de falhas de comunicação em ambientes de trocas de mensagens, são assuntos e problemas atuais das pesquisas modernas.

Inúmeras metodologias, arquiteturas e algoritmos são propostos para resolver esses problemas, mas poucos trabalhos tratam de questões como o teste estrutural para programas paralelos.

Assim, com o objetivo de promover uma análise do que existe nas bibliografias modernas sobre teste de software para programas paralelos e visando a hipótese de inserção de testes unitários nesses programas, os estudos feitos nesse trabalho aumentam as expectativas em relação a essa hipótese, visto que existe mais atenção dos pesquisadores à própria depuração de sistemas paralelos do que para testes tradicionais como o teste estrutural.

Como trabalhos futuros, pretende-se propor um estudo de caso para avaliar a possibilidade de inserção do teste unitário em programas paralelos, a fim de propor também uma metodologia para criação de casos de teste aplicáveis ao processo de desenvolvimento de programas paralelos em linguagem estruturada.

A princípio esse estudo de caso irá utilizar modelos paralelos já testados na disciplina de Programação Paralela tendo o MPI com biblioteca de troca de mensagens.

