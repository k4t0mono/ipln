Na área das Engenharias muitos problemas complexos de soluções extremamente trabalhosas e normalmente impossíveis de serem resolvidos por métodos analíticos exigem soluções numéricas.

O método dos elementos finitos (MEF) é uma abordagem para solução destes problemas encontrados em análise de estruturas, fluídos, eletromagnetismo, modelagem de circuitos integrados, biomédica e transferência de calor que necessitam processamento de alto desempenho e trabalham com grandes volumes de dados.

A computação paralela aparece como uma alternativa viável para a obtenção do desempenho necessário para a solução de problemas através do MEF e a utilização de clusters, como alternativa para a obtenção deste desempenho a baixo custo, se comparados a outros sistemas de computação paralela.

Contudo, em ambientes heterogêneos, para que o paralelismo seja explorado eficientemente é fundamental uma distribuição balanceada da carga de trabalho.

Para isto, se faz necessário o conhecimento detalhado dos custos de execução e comunicação envolvidos no processamento da aplicação paralela, nas diferentes máquinas do ambiente.

Este trabalho tem como objetivo caracterizar o desempenho, através de medições de tempo de execução detalhadas, de um código paralelo para um problema de análise estrutural modelado pelo método dos elementos finitos e resolvido pelo método dos gradientes conjugados (MGC), em um ambiente heterogêneo de PCs.

Através dos resultados obtidos com as medições detalhadas, foi possível estabelecer um balanceamento de carga empírico para o ambiente heterogêneo, mostrando a viabilidade da utilização deste ambiente para a execução do código paralelo do método dos elementos finitos.

A busca por maior velocidade no processamento das informações foi sempre um desafio para a computação e ao mesmo tempo um dos maiores responsáveis pelo seu desenvolvimento.

Não são poucas as situações em que o uso do processamento paralelo de alto desempenho se torna necessário, problemas complexos como modelagem numérica para previsão de tempo, gerência de grandes bancos de dados, e também os problemas de engenharia modelados pelo método dos elementos finitos (MEF), dentre outros.

Na área das Engenharias muitos problemas complexos de soluções extremamente trabalhosas e normalmente impossíveis de serem resolvidos por métodos analíticos exigem soluções numéricas.

O método dos elementos finitos (MEF) é uma abordagem para solução destes problemas encontrados em análise de estruturas, fluídos, eletromagnetismo, modelagem de circuitos integrados, biomédica e transferência de calor que necessitam processamento de alto desempenho e trabalham com grandes volumes de dados.

Por oferecer um elevado poder computacional, a computação paralela aparece como uma alternativa viável para a obtenção do desempenho necessário para a solução de problemas através do MEF e a utilização de clusters, como alternativa para a obtenção deste desempenho a baixo custo, se comparados a outros sistemas de computação paralela.

Um cluster é uma coleção de computadores completos, ou nós, que estão fisicamente interconectados por uma rede de alto desempenho ou uma rede local, LAN.

Tipicamente, cada nó é um servidor SMP, ou uma workstation, ou um PC.

O aspecto mais importante é que todos os nós devem ser capazes de trabalhar coletivamente como um recurso computacional único integrado, além de permitir o uso individual de cada nó por usuários.

Os clusters de PCs têm sido amplamente utilizados como máquinas paralelas.

A disponibilização de bibliotecas de comunicação como o PVM (Parallel Virtual Machine) e o MPI (Message Passing Interface), que permitem a execução de programas paralelos em um conjunto de máquinas conectadas por uma rede local, favoreceu a utilização de clusters.

Um cluster homogêneo tende a se tornar heterogêneo pela adição de máquinas extras, devido à constante evolução e rápida obsolescência tecnológica.

Como em ambientes heterogêneos as máquinas possuem poder computacional distinto, para que o paralelismo seja explorado eficientemente é fundamental uma distribuição balanceada da carga de trabalho.

Para isto, se faz necessário o conhecimento dos custos de execução e comunicação envolvidos no processamento da aplicação paralela, nas diferentes máquinas do ambiente heterogêneo.

As aplicações paralelas estão normalmente relacionadas ao desempenho.

Contudo, muitas vezes os valores de desempenho obtidos não são suficientes para caracterizar o completo funcionamento de uma aplicação paralela.

Este trabalho tem como objetivo caracterizar o desempenho, através de medições de tempo de execução detalhadas, de um código paralelo para um problema de análise estrutural modelado pelo método dos elementos finitos e resolvido pelo método dos gradientes conjugados (MGC), em um ambiente heterogêneo de PCs.

Através dos resultados obtidos com as medições detalhadas, foi possível estabelecer um balanceamento de carga empírico para o ambiente heterogêneo, mostrando a viabilidade da utilização deste ambiente para a execução do código paralelo do método dos elementos finitos.

Neste trabalho, é utilizado como aplicação benchmark um código paralelo aplicado a um problema da engenharia.

O código paralelo é uma solução do método dos elementos finitos aplicado à elasticidade linear, onde o sistema de equações algébricas é resolvido pelo método dos gradientes conjugados.

A aplicação foi implementada na linguagem C, com a utilização da biblioteca de troca de mensagens MPI (Message Passing Interface).

Esta dissertação está dividida como descrito a seguir.

O capítulo 2 apresenta as motivações e conceitos sobre a computação paralela, as vantagens da utilização de cluster de computadores e as preocupações pertinentes à utilização de clusters heterogêneos.

O capítulo 3 apresenta as medidas de desempenho a serem utilizadas neste trabalho.

O capítulo 4 dá uma introdução ao método dos elementos finitos, ao método dos gradientes conjugados e apresenta a aplicação utilizada como benchmark para a avaliação de desempenho do cluster heterogêneo.

O capítulo 5 apresenta os resultados obtidos, com as devidas análises destes.

Finalmente, o capítulo 6 exibe a conclusão do trabalho e os trabalhos futuros.

Em muitas áreas, tais como engenharia e automatização, há uma grande demanda de desempenho computacional.

As aplicações científicas utilizadas nestas áreas ainda são as forças que impulsionam a computação paralela necessária para manipular uma grande quantidade de informações, acelerar a execução do código e resolver problemas que consomem tempo excessivo.

Anteriormente, a busca pelo desempenho computacional obtido com a computação paralela se deu com base na utilização de computadores paralelos específicos, como aqueles com arquiteturas massiçamente paralelas (MPP) e os de memória compartilhada (SMP).

Porém, a arquitetura MPP necessita de um alto investimento inicial, fazendo com que haja uma redução no número de pessoas que possam adquirir tais computadores, o que, por sua vez, faz com que exista pouco suporte de software para esta arquitetura.

Como resultado, as arquiteturas MPP têm um custo elevado e pouca flexibilidade, apresentando dificuldade de atualização e de manutenção.

A arquitetura SMP apresenta uma limitação em relação ao número de CPUs suportadas, devido à utilização da memória compartilhada.

Desta forma, esta arquitetura também apresenta pouca flexibilidade.

Os clusters aparecem como uma tendência na computação de alto desempenho.

Nos clusters, workstations de alto poder computacional e baixo custo e/ou PCs são interligadas através de interfaces de comunicação rápidas para alcançar a computação paralela de alto desempenho.

Os recentes aumentos de velocidade na comunicação e na freqüência de clock, juntamente com a disponibilidade de softwares de domínio público, incluindo sistemas operacionais, ferramentas de compilação e bibliotecas de troca de mensagens, fazem dos clusters uma alternativa economicamente viável para se obter alto desempenho.

As principais características dos clusters, como boa relação de desempenho versus custo, rapidez de processamento, confiabilidade e concorrência, serviram para colocá-los como uma das propostas mais atraentes e viáveis nos mais diversos ambientes.

Existem atualmente vários conceitos a respeito do que vem a ser sistemas distribuídos, sistemas paralelos e sistemas concorrentes.

Esses conceitos de alguma forma acabam se confundindo.

Entre as definições existentes, há somente um ponto que todas elas concordam, todos esses sistemas requerem a presença de múltiplos processadores.

Segundo El-Rewini e Lewis, a computação distribuída é mais geral e universal do que a computação paralela.

A distinção é sutil, mas importante.

Paralelismo é uma forma restrita de computação distribuída.

Computação paralela é uma computação distribuída onde todo o sistema está dedicado à solução de um único problema no menor tempo possível.

Existem basicamente três questões que distinguem a programação distribuída da programação seqüencial, 1 O uso de múltiplos processadores.

A cooperação entre os processadores.

O potencial para falhas parciais, já que os processadores são autônomos, uma falha em um processador não afeta o funcionamento correto dos outros processadores.

Programas distribuídos executam, em paralelo, pedaços de seus códigos em processadores diferentes.

Aplicações de alto desempenho usam este paralelismo para obter aumento de velocidade.

O objetivo é obter o máximo de proveito dos processadores disponíveis, por isso, decisões relativas a quais computações devem ser executadas em paralelo são de grande importância.

Em aplicações tolerantes a falhas, decisões para executar funções em diferentes processadores são baseadas em aumentar a confiabilidade ou a disponibilidade.

Para se conceituar a programação paralela, é preciso inicialmente abordar os conceitos de programa seqüencial e programa concorrente.

Um programa seqüencial especifica a execução seqüencial de uma lista de sentenças.

Esta execução é chamada de processo.

Um programa concorrente é um programa que define ações que podem ser executadas simultaneamente.

O programa concorrente especifica dois ou mais programas seqüenciais que podem ser executados concorrentemente como processos paralelos.

Um programa concorrente pode ser executado permitindo que os processos compartilhem o processador ou que cada processo execute em seu próprio processador.

A primeira abordagem é conhecida como multiprogramação.

A segunda abordagem é conhecida como multiprocessamento, onde os processadores compartilham uma memória comum, ou é conhecida como processamento distribuído, no qual os processadores estão conectados por uma rede de comunicação.

Assim, programa concorrente é um termo genérico usado para descrever qualquer problema envolvendo comportamento paralelo real ou potencial.

Programas paralelos e distribuídos são subclasses de programas concorrentes que são concebidas para execução em ambientes de processamento paralelo específicos.

Como um sistema distribuído tem, por definição, mais de um processador, é possível que se tenha mais de uma parte de um programa executando ao mesmo tempo, o que vem a constituir paralelismo.

Quando um programa expresso de forma concorrente é executado em um único processador, a concorrência envolvida costuma ser chamada de pseudoparalelismo.

Por outro lado, quando ele é executado em mais de um processador, a concorrência é chamada de paralelismo.

No projeto de um sistema distribuído, existem alguns aspectos-chave que devem ser tratados, transparência, flexibilidade, confiabilidade, desempenho e escalabilidade.

A transparência provavelmente é o tópico mais importante de um sistema distribuído e diz respeito ao provimento de uma imagem única do sistema, ou seja, dar ao usuário a ilusão de estar usando um único sistema compartilhado composto por um único processador.

Quanto à flexibilidade, um sistema distribuído deve ser flexível, isto é, novos recursos e serviços podem ser adicionados a ele com facilidade.

Um dos aspectos da confiabilidade é a disponibilidade, que se refere ao período de tempo em que o sistema pode ser utilizado plenamente.

Outro aspecto é a tolerância a falhas, onde o sistema pode mascarar a ocorrência de uma falha.

O desempenho é um dos principais objetivos buscados ao se construir um sistema distribuído, que deve apresentar um ganho em relação aos sistemas monoprocessados.

A escalabilidade se refere à capacidade de ter os recursos melhorados ou aumentados para absorver qualquer demanda de desempenho ou funcionalidade, ou reduzidos para diminuir custos.

Um dos maiores problemas relacionados à implementação de uma aplicação distribuída é a exploração eficiente dos recursos do sistema.

Para atingir este objetivo, é necessário que a aplicação seja subdividida em módulos menores que possam ser distribuídos entre as unidades de processamento de forma a otimizar algum critério pré-estabelecido, que normalmente consiste em minimizar o tempo de execução total da aplicação.

Alguns dos critérios mais utilizados são, Minimização do tempo de execução total da aplicação.

Balanceamento da carga computacional da aplicação.

Maximização da utilização dos recursos do sistema.

Minimização do número de processadores e de recursos adicionais necessários para a execução de um grupo de tarefas em um intervalo de tempo dado.

Maximização do throughput do sistema.

Arquiteturas paralelas têm se tornado o suporte principal para a computação científica, incluindo física, química, biologia, astronomia e engenharias, entre outras.

A engenharia de aplicação das ferramentas para modelar fenômenos físicos hoje em dia é essencial para muitas indústrias, incluindo indústria petrolífera (modelagem de reservatório), indústria automotiva (simulação de colisão, eficiência da combustão), indústria aeronáutica (análise da corrente de ar, eficiência do motor, eletromagnetismo), indústria farmacêutica (modelagem molecular) e outras.

Em quase todas essas aplicações há uma grande demanda pela visualização dos resultados, o que as torna aplicações que necessitam de processamento paralelo.

O desempenho da solução vai depender da quantidade de paralelismo que for identificado no problema.

Muitas vezes o processo de paralelização conduz a seqüências de funções ou operações similares, não necessariamente idênticas, sendo executadas em elementos de grandes estruturas de dados.

É o chamado paralelismo de dados.

Neste caso, é requerido que o programador ofereça informação sobre como os dados serão distribuídos entre os processadores, em outras palavras, como os dados serão particionados entre as tarefas.

Técnicas de decomposição de domínio deverão ser aplicadas sobre os dados sobre os quais se está operando.

Além desse tipo de paralelismo, as aplicações exibem também um paralelismo funcional, também chamado de paralelismo de controle ou paralelismo de tarefas, cálculos totalmente diferentes podem ser executados concorrentemente nos mesmos dados ou em conjuntos de dados distintos.

No paralelismo funcional, o foco está na computação (operação) que está sendo realizada e não nos dados que estão sendo manipulados pela computação.

As computações são divididas em tarefas distintas.

Os dados operados podem ou não ser distintos.

No caso de estes não serem distintos, uma quantia considerável de comunicação será necessária para evitar a replicação dos dados comuns.

Existem várias classificações possíveis para máquinas paralelas.

A taxonomia proposta por Flynn é a mais conhecida.

Taxonomia de Flynn para computadores.

A classificação proposta por Flynn distingue as arquiteturas com base no fluxo de instruções e no fluxo de dados a serem processados simultaneamente.

Segundo a classificação de Flynn, são distinguidas quatro categorias de arquitetura existentes, descritas abaixo, SISD, Single Instruction, Single Data.

Esta categoria representa as máquinas monoprocessadas tradicionais.

Nesta categoria, uma instrução é executada de cada vez, manipulando um único fluxo de dados.

Caracteriza o modelo seqüencial (Arquitetura de von Neumann), cujo princípio básico de funcionamento identifica a grande maioria dos computadores.

SIMD, Single Instruction, Multiple Data.

Caracterizado por um fluxo único de instruções, que são aplicadas sobre múltiplos fluxos de dados.

Todos os processadores executam o mesmo fluxo de instrução em diferentes fluxos de dados.

Constitui uma classe de arquiteturas muito importante na história da computação.

Para certas classes de problemas, este tipo de arquitetura é perfeitamente apropriado para se atingir altas taxas de processamento, pois os dados são separados em diversas partes, e as múltiplas unidades de instrução podem operar sobre elas ao mesmo tempo.

MISD, Multiple Instruction, Single Data.

Não se tem conhecimento de arquitetura de máquinas desta categoria.

Máquinas da categoria MISD possuem múltiplas funções executando independentemente operações num único fluxo de dados.

Abstratamente, uma máquina MISD é um pipeline de múltiplas unidades funcionais de execução independente operando sobre um único fluxo de dados, repassando os resultados de uma unidade funcional para a próxima.

MIMD, Multiple Instruction, Multiple Data.

Esta classe provê simultaneamente múltiplos fluxos de instrução aplicados a múltiplos fluxos de dados, e é a categoria mais geral de todas e o tipo mais comum de computador paralelo.

Por isso, Johnson propôs uma sub-classificação para estas máquinas, baseada em sua estrutura de memória (global ou distribuída) e no mecanismo utilizado para comunicação e sincronização (variáveis compartilhadas ou troca de mensagens).

Taxonomia de Flynn-Johnson para sistemas computacionais.

De acordo com a estrutura de memória e a comunicação/sincronização, a arquitetura MIMD de Flynn pode ser subdividida em quatro sub-classes, GMSV (Global Memory Shared Variable), DMSV (Distributed Memory Shared Variable), DMMP (Distributed Memory Message Passing) e GMMP (Global Memory Message Passing).

A classe GMSV é referenciada como sistemas multiprocessados com memória compartilhada, considerados sistemas fortemente acoplados.

A classe DMMP é conhecida como sistemas multicomputadores com memória distribuída e fracamente acoplados.

A classe DMSV, que se tornou popular por combinar a implementação de uma memória distribuída com a facilidade de programação com variáveis compartilhadas, é conhecida como memória compartilhada distribuída.

A categoria GMMP não é muito utilizada.

Fisicamente os sistemas computacionais podem ser classificados dentro de seis modelos implementáveis de máquinas.
Máquinas SIMD (Single-Instruction, Multiple-Data) Processador Vetorial Paralelo, PVP (Parallel Vector Processor) Multiprocessador Simétrico.
SMP (Symmetric Mutiprocessor) Processador Maciçamente Paralelo.
MPP (Massively Parallel Processor) Cluster de workstations.
COW (Cluster of Workstations) Multiprocessadores com Memória Distribuída Compartilhada, DSM (Distributed Shared Memory).

As máquinas SIMD são, na maioria dos casos, usadas para aplicações de propósito específico.

Todos os outros modelos são máquinas MIMD.

Com exceção do PVP, que possui blocos customizados, a maioria das arquiteturas paralelas modernas é obtida por integração de elementos de prateleira (commodity off-the-shelf).

Processadores vetoriais paralelos.

A estrutura de um PVP típico pode ser visualizada. Estes sistemas contêm um número reduzido de processadores vetoriais customizados.

Uma chave crossbar especificamente projetada e com grande largura de banda conecta os processadores aos módulos de memória compartilhada, o que provê alta velocidade no acesso aos dados.

Estas máquinas normalmente não utilizam caches, mas um grande número de processadores vetoriais e um buffer de instruções.

Um processador vetorial é uma máquina projetada para tratar operações aritméticas sobre elementos de matrizes ou vetores, de forma eficiente.

Processadores vetoriais paralelos.

Multiprocessadores Simétricos.

Diferente de um PVP, um SMP usa microprocessadores com memórias cache on-chip e off-chip.

Estes processadores estão conectados a uma memória compartilhada através de um barramento de alta velocidade.

Em alguns SMPs uma chave crossbar adicional é usada.

Sistemas SMP são muito utilizados em aplicações comerciais, como bancos de dados, sistemas de transações on-line e data warehouses.

Pelo fato de ser simétrico, cada processador tem igual acesso à memória compartilhada, aos dispositivos de E/S e aos serviços do sistema operacional.

Também pelo fato de serem simétricos, um alto grau de paralelismo pode ser alcançado.

Uma das desvantagens dos SMPs, é que por fazerem uso de memória compartilhada e de sistemas de interconexão baseados em chaves crossbar e barramentos, uma vez construídos eles acabam se tornando pouco escaláveis.

Exemplos de SMPs incluem o IBM R-50, o SGI Power Challenge e o servidor DEC Alpha 8400.

Barramento ou chave crossbar Multiprocessador simétrico.

Processadores Maciçamente Paralelos.

O termo MPP se refere a sistemas de computação de grande escala que utilizam microprocessadores standard (commodity) como nós de processamento, que usam memórias fisicamente distribuídas nos nós e que utilizam uma rede de interconexão de alta velocidade de comunicação e baixa latência e podem ser escalados para suportar centenas ou mesmo milhares de processadores.

O programa consiste de múltiplos processos, cada um tendo o seu espaço de endereçamento privado.

Os processos neste modelo, diferente dos PVPs e SMPs, se comunicam através de troca de mensagens.

Rede de interconexão customizada.

Processador maciçamente paralelo.

Multiprocessadores com Memória Distribuída Compartilhada.

As máquinas DSM estão modeladas, baseada na arquitetura Stanford DASH.

O diretório de cache é usado para dar suporte a caches distribuídas coerentes.

A idéia do uso de diretório é manter para cada bloco de memória um registro das memórias cache que atualmente contém uma cópia daquele bloco e dos estados do bloco nestas memórias cache.

Este registro é conhecido como a entrada de diretório para aquele bloco, e normalmente se localiza no mesmo nó onde se encontra o bloco.

A principal diferença entre máquinas DSM e SMP é que a memória está fisicamente distribuída entre os nós do sistema.

Contudo, os sistemas de hardware e software criam a ilusão de um único espaço de endereçamento para as aplicações.

Uma máquina DSM também pode ser implementada utilizando extensões de software em uma rede de workstations.

O objetivo de um sistema DSM é tornar a comunicação entre processos transparente para os usuários finais.

Ao permitir que o programador compartilhe objetos da memória sem ter que tratar o seu gerenciamento, os sistemas DSM pretendem propor um balanço entre a facilidade de programação das máquinas com memória compartilhada e a eficiência e escalabilidade dos sistemas com memória distribuída.

Rede de interconexão customizada.

Multiprocessadores com Memória Distribuída Compartilhada.

Os clusters de workstations (COW) também são um tipo de modelo físico, mas devido à sua relevância para este trabalho, eles serão detalhados na seção 2 6 Com o objetivo de cooperação, os processos executando concorrentemente em processadores distintos precisam se comunicar e sincronizar.

A comunicação permite que a execução de um processo influencie na execução de outro processo.

A comunicação entre processos é baseada no uso de variáveis compartilhadas (variáveis que podem ser referenciadas por mais de um processo) ou é baseada em troca de mensagens entre os processos.

No modelo de programação que utiliza memória compartilhada, as tarefas compartilham um espaço de endereçamento comum, no qual elas lêem e escrevem de modo assíncrono.

Vários mecanismos, como locks e semáforos, podem ser usados para controlar o acesso à memória compartilhada.

Uma vantagem deste modelo do ponto de vista do programador é que não há a noção de posse e, portanto, não há a necessidade de especificar explicitamente a comunicação de dados de produtores para consumidores.

Este modelo pode simplificar o desenvolvimento do programa.

Contudo, entender e gerenciar os conflitos de acessos às posições da memória compartilhada se torna mais difícil e também pode ser mais difícil escrever programas determinísticos.

A troca de mensagens é provavelmente o modelo de programação paralela mais utilizado atualmente.

Programas que utilizam o paradigma de troca de mensagens criam múltiplas tarefas sendo que cada tarefa encapsula seus dados locais.

Cada tarefa é identificada por um nome único e as tarefas interagem enviando mensagens para uma determinada tarefa e recebendo mensagens de uma determinada tarefa.

O modelo de troca de mensagens não impede a criação de tarefas, a execução de múltiplas tarefas pelo processador ou a execução de diferentes programas por diferentes tarefas.

Contudo, na prática, a maioria dos sistemas de troca de mensagens cria um número fixo de tarefas idênticas quando a execução do programa é iniciada e não permite que tarefas sejam criadas ou destruídas durante a execução do programa.

A troca de mensagens é baseada nas primitivas send e receive.

Todos os processadores podem trocar informações com todos os outros processadores.

Múltiplos sends e receives podem ocorrer simultaneamente em um computador paralelo.

As mensagens são passadas entre os processadores através de um protocolo de comunicação.

O modelo funcional de um sistema que utiliza troca de mensagens é representado como um conjunto de processadores que têm sua memória local, mas cujos processos são capazes de se comunicar através do envio e recepção de mensagens.

Vantagens do modelo de troca de mensagem.

A comunicação via troca de mensagem apresenta-se como uma das alternativas mais viáveis, devido a muitas vantagens, tais como, Generalidade (Universalidade), Pode-se construir um mecanismo de passagem de mensagens para qualquer linguagem, como ferramentas de extensão das mesmas (bibliotecas) e sob qualquer tipo de rede (lenta ou rápida), para os mais diferentes tipos de máquinas, que vão desde os supercomputadores aos PCs mais simples.

Aplicabilidade, a adequação a ambientes distribuídos faz deste modelo uma alternativa perfeitamente viável para uma grande gama de aplicações.

Expressividade, o modelo de troca de mensagens tem sido utilizado como um modelo completo para o desenvolvimento dos mais diversos algoritmos para processamento paralelo.

Possibilidade de depuração, considerando-se as características de programação, é perfeitamente possível realizar a depuração no modelo de troca de mensagens, já que ela evita uma das causas mais comuns de erros, a corrida crítica e escrita indevida da memória, devido ao controle explícito do modelo.

Baixo custo, as mais conhecidas bibliotecas de troca de mensagens (PVM (Parallel Virtual Machine) e MPI (Message Passing Interface)) são programas do gênero freeware, ou seja, de domínio público.

Sua instalação requer apenas conhecimentos básicos e, portanto, permitem formar ambientes de processamento paralelo de baixíssimo custo.

Desempenho, finalmente, a mais importante razão permanece sendo a possibilidade de se obter um ganho de desempenho com a utilização de clusters de processamento intercomunicados via troca de mensagens.

Limitações do modelo de troca de mensagem.

Algumas restrições apresentadas pelo modelo de troca de mensagens, Necessidade de programação explícita, Primeiro de tudo, o programador é diretamente responsável pela paralelização.

Isto requer que haja uma mudança na forma algorítmica para desenvolvimento dos programas, de um modelo seqüencial, para uma visão cooperativa (distribuída) do processamento.

Custo de comunicação, Os custos de comunicação podem tornar extremamente proibitiva a transmissão de mensagens em certos ambientes.

Quanto ao bloqueio, os tipos de comunicação podem ser, Comunicação "bloqueante" (blocking communication), Quando a finalização da execução da rotina é dependente de determinados eventos, ou seja, existe uma espera por determinada ação antes de se permitir a continuação do processamento.

Dois casos típicos são a espera pelo esvaziamento de um buffer antes de sua reutilização e a existência de barreiras de sincronização.

Comunicação "não-bloqueante" (non-blocking communication), Neste caso, a finalização da chamada não espera qualquer evento que indique o fim ou sucesso da rotina.

Rotinas de comunicação não bloqueantes não dependem de nenhum evento para que sejam finalizadas, isto é, a execução continua imediatamente após o início da comunicação.

Quanto à sincronização, a comunicação pode ser, Comunicação síncrona, É a comunicação na qual o processo que envia a mensagem, não retorna à execução normal enquanto não houver um sinal do recebimento da mensagem pelo destinatário, isto é, uma confirmação de êxito da rotina.

Corresponde ao modelo mais seguro de transmissão de dados.

Comunicação assíncrona, Quando não existe nenhuma restrição para a confirmação da rotina.

A Interface de Troca de Mensagens, MPI, é uma padronização de um sistema de troca de mensagens proposta por um grupo de pesquisadores.

Ela foi desenvolvida com o intuito de se tornar um padrão para a escrita de programas que utilizam troca de mensagem para se comunicar, tentando estabelecer um padrão prático, portável, eficiente e flexível para troca de mensagens.

Desde que foi finalizada, em junho de 1994, ela foi muito bem aceita e utilizada.

A principal vantagem da interface MPI, assim como da maioria dos padrões, é a portabilidade em máquinas distintas.

Isto significa que o mesmo código-fonte pode ser executado em várias máquinas, desde que a biblioteca MPI esteja disponível.

Outro tipo de compatibilidade oferecida pela MPI é a capacidade de executar de modo transparente em sistemas heterogêneos, ou seja, coleção de processadores que possuem arquiteturas distintas.

Também provê comunicação eficiente e confiável.

MPI oferece uma coleção de rotinas de comunicação ponto-a-ponto e operações coletivas para movimentação de dados, computações globais e sincronização.

Uma aplicação MPI pode ser visualizada como uma coleção de tarefas comunicantes e concorrentes.

As tarefas MPI podem executar no mesmo processador ou em processadores diferentes concorrentemente.

Para um programa aplicativo, enviar uma mensagem a uma tarefa na mesma máquina ou em outra é uma operação transparente.

Duas tarefas executando em um único processador.

Algumas características essenciais das implementações MPI mais utilizadas são apresentadas a seguir, Todo programa MPI deve incluir o arquivo mpi h (ou mpif h para uso com Fortran), que contém o protótipo de todas as funções, constantes e tipos MPI predefinidos que um programa pode necessitar.

A primeira função MPI que um programa deve executar é o MPI_Init.

Esta função permite que os procedimentos de inicialização sejam executados em uma máquina paralela particular ou em um cluster de workstations.

A questão de como um programa MPI é iniciado não é endereçado pelo padrão MPI e pode variar de acordo com o sistema operacional e com a arquitetura.

A última função MPI que um programa deve invocar é o MPI_Finalize.

Ela limpa o estado paralelo antes de sair e nenhuma outra função MPI pode ser chamada depois dela.

O MPI, juntamente com o PVM, é um dos sistemas mais amplamente utilizados hoje em dia para programação paralela com troca de mensagens em clusters de computadores.

O custo elevado e pouca flexibilidade das máquinas do tipo MPP e SMP, a grande oferta de computadores pessoais existentes, os recentes aumentos de velocidade na comunicação e na freqüência de clock, juntamente com a disponibilidade de softwares de domínio público de alto desempenho, incluindo sistemas operacionais, ferramentas de compilação e bibliotecas de troca de mensagens, fazem dos clusters uma alternativa economicamente viável para se obter alto desempenho.

Por apresentar excelente custo-benefício e pela possibilidade de disponibilizar maiores e melhores recursos computacionais para os seus usuários, a cada dia mais organizações têm adotado este paradigma.

Os clusters computacionais objetivam a agregação de recursos computacionais para disponibilizá-los para a melhoria de aplicações.

Segundo Hwang, um cluster é uma coleção de computadores completos, ou nós, que estão fisicamente interconectados por uma rede de alto desempenho ou uma rede local, LAN.

Tipicamente, cada nó é um servidor SMP, ou uma workstation, ou um PC.

O aspecto mais importante é que todos os nós devem ser capazes de trabalhar coletivamente como um recurso computacional único integrado, além de permitir o uso individual de cada nó por usuários.

Cinco conceitos arquiteturais devem estar presentes quando se fala em cluster, interconexão, nós, imagem única do sistema, disponibilidade e desempenho.

Uma arquitetura conceitual de cluster é exibida.

Sterling define um cluster como uma coleção de elementos computacionais fracamente acoplados, isto porque a memória está distribuída nos nós e um nó não tem acesso direto à memória de outro nó.

Na configuração fortemente acoplada, os processadores compartilham uma mesma memória principal.

Gropp define cluster como um computador paralelo construído com componentes de prateleira (commodity components) executando software de prateleira (commodity software).

Um cluster é constituído de nós, contendo um ou mais processadores, memória, que é compartilhada pelos processadores dentro de um mesmo nó e dispositivos periféricos adicionais (como discos), conectados por uma rede que permite a troca de informações entre os nós.

Para Sloan, uma configuração multicomputador, ou um cluster, é um grupo de computadores que trabalham em conjunto.

Um cluster possui três elementos básicos, uma coleção de computadores individuais, uma rede de interconexão conectando esses computadores e um software que possibilita que um computador compartilhe trabalho com os demais computadores via a rede de interconexão.

Cada nó de um cluster possui no mínimo um processador (P) e um módulo de memória cache (C) que se comunicam com uma memória local (ML), através de um barramento de memória (BM).

Além disso, cada nó possui um disco local (DL) e um sistema operacional completo.

Os programas paralelos trocam informações utilizando o paradigma de troca de mensagens.

Para garantir o potencial computacional que o cluster deve oferecer, os nós devem ser conectados através de uma interconexão de baixa latência.

As redes de interconexão podem ser compartilhadas, como Ethernet, Fast Ethernet, Token Ring e FDDI ou as redes de interconexão podem ser dedicadas ponto-a-ponto, como por exemplo, a Myrinet.

Diagrama de blocos de um cluster.

O objetivo principal da utilização de cluster é obter uma configuração de hardware e software que permita conseguir um elevado desempenho a um baixo custo, durante a execução de aplicações paralelas.

Clusters construídos a partir de elementos de prateleira (COTS) permitem flexibilidade de configuração.

O número de nós, a capacidade de memória por nó, o número de processadores por nó e a topologia de interconexão são parâmetros da estrutura do sistema que podem ser especificados de forma detalhada.

Ainda, a estrutura do sistema pode ser facilmente modificada ou acrescida de acordo com a necessidade sem perda do investimento já feito.

Os clusters também permitem uma resposta rápida às melhorias da tecnologia.

Assim que novos dispositivos, incluindo processadores, memória, discos e rede se tornam disponíveis, estes já podem ser integrados aos nós permitindo que o cluster possa usufruir dos avanços tecnológicos.

Outro motivo para se utilizar cluster é prover tolerância a falhas, ou seja, garantir que o poder computacional esteja sempre disponível.

Pelo fato do cluster ser construído a partir de muitas cópias dos mesmos componentes ou de componentes similares, a falha de uma parte somente reduz o poder computacional do cluster.

A tolerância a falhas pode ser interpretada de várias maneiras.

Para um servidor Web, o cluster pode ser considerado disponível (up) contanto que haja processadores suficientes e que a capacidade da rede possa suprir a demanda.

Para aplicações científicas, a interpretação de disponibilidade (uptime) é diferente.

Para clusters usados em aplicações científicas, particularmente aqueles usados para prover capacidade de memória adequada, a disponibilidade (uptime) é medida com relação ao tamanho mínimo do cluster (por exemplo, o número de nós) que permite que a aplicação execute.

Muito esforço foi aplicado anteriormente na construção de cluster de pequenas máquinas, tipicamente workstations, para se obter computadores paralelos de baixo custo.

Mas, o projeto que verdadeiramente popularizou os clusters foi o projeto Beowulf do centro NASA Goddard Space Flight.

Em 1994, Thomas Sterling, Donald Becker e outros construíram um cluster de PCs com 16 máquinas Intel 80486-based de 100 MHz.

A classe Beowulf é uma categoria especial de cluster, construído a partir de PC's e dispositivos facilmente encontrados no mercado (COTS).

No cluster Beowulf os ambientes de programação paralela, como MPI normalmente são utilizados para a construção de aplicações paralelas baseadas em troca de mensagens.

Sistemas operacionais de distribuição livre, como Linux, normalmente são usados em arquiteturas Beowulf.

A principal característica de um commodity cluster é seu baixo custo, sendo construído a partir de componentes facilmente encontrados no mercado (COTS).

O cluster Beowulf é um commodity cluster.

O commodity cluster obtém vantagem de dois componentes de prateleira, CPUs rápidas projetadas principalmente para computadores pessoais e as redes de interconexão projetada para conectar computadores pessoais (LAN).

Devido a estes componentes de prateleira, seu custo é relativamente baixo.

Gropp afirma que, através de algumas medidas, incluindo velocidade de processamento, capacidade de memória, espaço disponível em disco e largura de banda, um único PC atual é mais poderoso do que os supercomputadores do passado.

Também referido como Linux clusters ou PC clusters, o Beowulf é talvez mais amplamente utilizado que qualquer outro tipo de computador paralelo devido ao seu baixo custo, flexibilidade e acessibilidade.

Os nós de um cluster podem incorporar um único processador ou múltiplos processadores numa configuração SMP.

Nos commodity clusters os nós são PCs ou pequenos SMPs de PCs interligados por uma rede de baixo custo e o sistema operacional utilizado é de código aberto, como Linux.

Vantagens da utilização de um commodity cluster, O uso de componentes de facilmente encontrados no mercado.

Possibilidade de obter uma configuração de baixo custo, que atenda a necessidade da aplicação.

Escalabilidade, oferecendo a possibilidade de acrescentar mais máquinas ao cluster caso haja a necessidade de mais poder de processamento.

O commodity cluster enquadra-se na taxonomia de Flynn como MIMD (Multiple Instruction Multiple Data), do tipo multicomputador ou hardware fracamente acoplado, baseado no código monolítico Linux, utilizando a comunicação através de troca de mensagens.

Este cluster é especificamente dedicado ao processamento paralelo, com uma rede de comunicações dedicada exclusivamente para a troca de mensagens.

Os clusters comerciais, diferentemente dos commodity clusters, utilizam computadores e software proprietários.

Um exemplo é o SUN Ultra, que é um cluster proprietário.

Em clusters proprietários, o software é fortemente integrado dentro do sistema.

A principal desvantagem destes clsuters é o seu alto custo.

A lista do Top500 representa duas classes de clusters, cluster-NOW e constelações.

Ambas as classes são clusters não proprietários (commodity clusters) distinguidas pelo nível dominante de paralelismo.

O primeiro nível é o número de nós conectados pela rede de comunicação global, na qual um nó contém todos os processadores do cluster e os recursos de memória.

O segundo nível é o número de processadores em cada nó, normalmente configurado como um multiprocessador simétrico (SMP).

Se um cluster não proprietário possui mais nós do que microprocessadores em cada um de seus nós, então o modo dominante de paralelismo é o primeiro nível (a categoria cluster-NOW).

Se um nó tem mais microprocessadores do que os nós do cluster, o modo dominante de paralelismo é o segundo nível (uma constelação).

Esta distinção não é arbitrária e pode levar a um sério impacto na programação.

Um cluster-NOW, por exemplo, é programado quase que exclusivamente com interface de troca de mensagem (MPI), enquanto que uma constelação é programada, pelo menos em parte, com OpenMP usando um modelo de treads.

Muito freqüentemente, uma constelação tem compartilhamento de espaço (space-shared) e não compartilhamento de tempo (time-shared), com cada usuário tendo seu próprio nó.

Atualmente é comum efetuar a classificação dos tipos de clusters através de alguns de seus aspectos, limite geográfico, modo de utilização dos nós, tipo de hardware e conexão entre os nós, requerimento dos recursos solicitados pelas aplicações e tipo dos nós que constituem a configuração.

Limite geográfico.

O nós do cluster podem estar distribuídos de forma compacta ou distribuída.

Em um cluster compacto, os nós estão proximamente conectados, como por exemplo, dentro de uma sala e os nós não possuem periféricos.

Em um cluster distribuído, os nós são estações completas, possuindo os periféricos e podem estar localizados em salas diferentes, prédios diferentes, mesmo em regiões geográficas diferentes.

O empacotamento afeta diretamente a comunicação e a seleção da tecnologia de intercomunicação.

Enquanto um cluster compacto pode utilizar uma rede de comunicação com alta largura de banda e baixa latência, que é sempre proprietária, os nós de um cluster distribuído normalmente são conectados através de LANs ou WANs padrões.

Utilização dos nós.

A participação dos nós do cluster pode ser dedicada ou não-dedicada.

Fatores como as políticas de gerenciamento, segurança, alta disponibilidade, escalonamento de processos, balanceamento de carga e o tipo de middleware do sistema de imagem única estão relacionados diretamente à forma de utilização dos nós.

Tipo de hardware.

Os tipos de hardware empregados nos clusters têm sido classificados de uma forma empírica como NOWs (Network of Workstations), COWs (Cluster of Workstations) e Clumps (Cluster of SMPs).

As NOWs são caracterizadas pela utilização de estações de trabalho distribuídas em uma rede local como elementos de hardware para compor os ambientes de cluster.

Os COWs são geralmente constituídos de máquinas homogêneas e dedicadas à execução de aplicações específicas.

Estas configurações dispõem de uma rede específica para conectar as máquinas.

Os Clumps são clusters compostos de máquinas com arquitetura SMP.

Aplicações alvo.

Existem dois alvos principais de requisitos para o uso de clusters.

A primeira classe se refere às aplicações que necessitam de alto desempenho.

Os clusters, por disponibilizar vários processadores, grande quantidade de memória e espaço em disco, se apresentam como um ambiente ideal para essas aplicações.

A segunda classe são aplicações essenciais que não podem sofrer interrupções, sendo denominadas aplicações de alta disponibilidade.

Tipo dos nós.

Esta classificação distingue os clusters entre homogêneos e heterogêneos, dependendo da similaridade de hardware e de software dos nós.

Em um cluster homogêneo, todos os computadores possuem arquiteturas semelhantes como, por exemplo, PCs e SMPs e o mesmo sistema operacional.

Os clusters heterogêneos possuem nós de arquiteturas distintas e/ou sistemas operacionais distintos.

Os sistemas de imagem única, SSI (Single System Image), podem ser considerados middlewares que provêm uma abstração para os usuários de clusters quanto à sua configuração física e dos pacotes de software instalados no sistema.

A principal motivação da propriedade de unificação da imagem do sistema é fazer com que todos os recursos do sistema sejam vistos como um único recurso computacional.

Esta propriedade pode ser definida como sendo uma ilusão criada por hardware ou por software, que apresenta uma coleção de recursos que atuam como se fossem um único componente.

A SSI é considerada uma camada middleware, que reside entre o sistema operacional e o ambiente do usuário.

Além da subcamada de infra-estrutura de SSI, o middleware deve também conter a subcamada de infra-estrutura de disponibilidade.

O sistema de disponibilidade disponibiliza serviços de clusters tais como checkpoint, recuperação e tolerância a falhas para todos os nós do cluster.

Alguns benefícios da SSI são, Transparência na execução das aplicações.

Transparência da localização dos dispositivos físicos.

Redução na gerência do sistema.

Alta disponibilidade pelo fato de o sistema ter a possibilidade de manter cópias de recursos em vários nós.

Aumento da robustez da configuração pelo fato de que a SSI reduz a intervenção de operadores.

Embora anteriormente os sistemas multicomputadores fossem, em sua maioria, homogêneos, atualmente vários destes sistemas são heterogêneos.

Pelo fato de os clusters permitirem flexibilidade de configuração, mais cedo ou mais tarde, um cluster homogêneo, quando for ampliado, adicionando-se máquinas extras ao cluster ou dispositivos mais atualizados, certamente se tornará heterogêneo, salvo alguns casos onde o cluster não mais será modificado e/ou se encontrarem máquinas exatamente iguais para se fazer a ampliação, algo quase impossível devido ao grande avanço tecnológico pelo qual a informática passa.

Em um sistema heterogêneo, os nós podem diferir na arquitetura, no software, na velocidade, etc.

A característica de um cluster ser ou não homogêneo tem implicações importantes no balanceamento de carga das aplicações.

Para explorar de modo eficiente o poder computacional dos clusters de computadores heterogêneos, uma questão importante é como associar as tarefas aos computadores de modo que a carga fique balanceada e que o tempo total de computação seja minimizado.

No caso do particionamento de uma tarefa, ao se balancear a carga em um cluster homogêneo todos os computadores deverão receber cargas iguais, pois cada um deles possui as mesmas características e, conseqüentemente, a mesma capacidade de processamento.

Em um cluster heterogêneo é necessário ter uma preocupação maior com a distribuição da carga que cada nó deve receber.

Deve ser feita uma análise levando-se em consideração as diferentes capacidades de processamento de cada uma das máquinas do ambiente.

Após essa análise, cada nó deverá receber uma carga de trabalho compatível com a sua capacidade de processamento.

As redes de computadores heterogêneas são uma arquitetura de memória distribuída promissora.

No caso mais geral, uma rede heterogênea inclui PCs, workstations, servidores multiprocessados, clusters de workstations e até mesmo supercomputadores.

Diferente das plataformas homogêneas tradicionais, a arquitetura paralela heterogênea utiliza processadores que executam em diferentes velocidades de processamento.

Portanto, algoritmos paralelos tradicionais, com computações distribuídas uniformemente entre os processadores, não balancearão a carga entre os processadores com diferentes velocidades numa rede heterogênea.

Os processadores mais rápidos executarão mais rapidamente suas partes e ficarão esperando por aqueles mais lentos nos pontos de sincronização.

Uma abordagem natural para o problema é distribuir os dados entre os processadores de maneira não uniforme para que cada processador execute o volume de computação proporcional à sua velocidade.

Obter um bom desempenho, contudo, pode ser um desafio.

Além dos problemas encontrados no balanceamento de carga em sistemas homogêneos, precisa-se ainda levar em conta as velocidades diferentes dos processadores e suas arquiteturas e capacidades de memória diferentes, o que pode impactar significantemente no desempenho.

Além disso, as cargas e disponibilidade das máquinas serão impossíveis de serem previstas, de forma que é difícil de saber com antecedência qual será a velocidade efetiva de cada máquina.

Os métodos de análise de desempenho de algoritmos paralelos homogêneos são bem estudados.

Eles se baseiam em modelos e computadores paralelos, incluindo a Parallel Random Access Machine (PRAM), o modelo Bulk-Synchronous Parallel (BSP) e o LogP model.

Todos os modelos assumem um computador paralelo como um multiprocessador homogêneo.

A análise teórica de um algoritmo paralelo homogêneo normalmente é acompanhada por um número relativamente pequeno de experimentos em um sistema paralelo homogêneo.

O propósito destes experimentos é mostrar que a análise está correta e que o algoritmo analisado realmente é mais rápido do que suas contrapartes.

Uma análise teórica de desempenho para algoritmos paralelos heterogêneos é uma tarefa muito mais difícil do que a análise para algoritmos paralelos homogêneos.

Enquanto algumas pesquisas nesta direção têm sido feitas, ainda não há nenhum modelo prático adequado para redes de computadores heterogêneas, o qual seria capaz de predizer o tempo de execução de algoritmos paralelos heterogêneos com uma precisão satisfatória.

O problema de uma distribuição de dados ótima numa rede heterogênea foi provado ser NP-completo até mesmo para uma álgebra linear simples como multiplicação de matrizes em redes heterogêneas.

Desta forma, algoritmos paralelos heterogêneos práticos são sub-ótimos.

Uma aproximação típica para a avaliação de um algoritmo paralelo heterogêneo é a sua comparação experimental com alguma contraparte homogênea em uma ou em várias plataformas heterogêneas.

Os algoritmos heterogêneos distintos são também comparados principalmente experimentalmente.

Devido à natureza complexa e irregular de redes heterogêneas, a avaliação experimental de algoritmos paralelos heterogêneos não é tão convincente como para as redes homogêneas.

Pode-se facilmente discutir que a demonstração da vantagem de um algoritmo sobre outro em uma ou várias redes heterogêneas não prova que a situação não mudará se você executar os algoritmos em outras redes de computadores, com a diferença em relação à velocidade dos processadores e as diferentes estruturas e velocidade da rede de comunicação.

A meta de usar a computação paralela através de multicomputadores ou multiprocessadores é obter alto desempenho, pois o desempenho é uma questão central na computação paralela.

Uma das principais motivações do processamento paralelo é resolver rapidamente problemas que exigem um processamento computacional elevado.

Considerando o tempo de execução e o tamanho do problema, o que nós buscamos no processamento paralelo é velocidade, a qual é definida como trabalho dividido pelo tempo.

A avaliação de desempenho não é somente uma questão de medir o custo de uma computação específica, mas um processo de coletar informação sobre um conjunto de computações que informarão que decisão tomar para uma determinada meta.

Uma das metas mais comuns é a velocidade.

Contudo, as tendências recentes no processamento paralelo sugerem que a questão de predição de desempenho está se tornando mais complexa e difícil.

Os cientistas têm introduzido várias arquiteturas e algoritmos para fornecer escalabilidade de desempenho com a utilização de muitos processadores.

Ao mesmo tempo, com várias arquiteturas e algoritmos disponíveis, a medição de desempenho está se tornando crítica na escolha de uma combinação apropriada de máquina-algoritmo para uma aplicação, principalmente quando a máquina tem uma arquitetura hierárquica sofisticada.

A análise de desempenho de aplicações paralelas é um desafio.

Muitos fatores influenciam o desempenho e é difícil avaliar se e onde as aplicações experimentaram desempenho pobre.

O desempenho alcançado por uma aplicação paralela é o resultado de interações complexas entre os recursos de hardware e de software do sistema onde a aplicação está sendo executada.

As características da aplicação, como a estrutura algorítmica, os parâmetros de entrada, o tamanho do problema, influenciam estas interações determinando como a aplicação explora os recursos disponíveis e os processadores alocados.

Assim como em sistemas monoprocessados, a maioria das questões sobre desempenho pode ser dirigida por técnicas algorítmicas e de programação, ou por técnicas arquiteturais ou por ambas.

Entender as técnicas de programação e as interdependências é importante não somente para projetistas de software paralelo, mas também para arquitetos.

Além de nos ajudar a entender os programas paralelos, também nos ajuda a entender a relação entre o hardware e o software, isso é, em quais aspectos a arquitetura do sistema pode assistir e quais aspectos devem ser deixados para o software.

As interdependências entre programa e sistema são mais complexas e têm maior impacto de desempenho em multiprocessadores do que em monoprocessadores, portanto, entende-se que são muito importantes para a nossa meta de desenvolver sistemas de alto desempenho que reduzam custo e esforço de programação.

Uma vez que um programa paralelo tenha sido escrito e que seus erros tenham sido eliminados, os programadores geralmente voltam a sua atenção para o desempenho do programa.

A maioria dos programadores mede o desempenho de seus programas pelo tempo de turnaround e não por throughput.

As ferramentas para medir o desempenho existem para ajudar os programadores a entender o motivo de seus programas não executarem rápido o suficiente.

A operação fundamental da avaliação de desempenho de programa é medir o tempo requerido para executar a computação.

Embora esta operação seja conceitualmente simples, o processo de medida está sujeito a muitos imprevistos.

Para evitá-los os cuidados de que o programador precisa tomar são três, Conhecer as ferramentas.

Conhecer o programa.

Conhecer o ambiente de execução.

As métricas de desempenho podem ser definidas como qualquer estatística sobre computação paralela projetada para ajudar os programadores a reduzirem o tempo de execução de seus programas.

As métricas de desempenho iniciaram na programação seqüencial como um simples profile do tempo de CPU que era consumido por cada procedure em um programa.

Uma extensão lógica desta técnica para programas paralelos é agregar os profiles do tempo de CPU de cada processo (ou thread) para prover um único profile para um programa paralelo.

O grande número de gargalos em potencial possíveis na programação paralela aumenta dramaticamente a necessidade de ferramentas de análise de desempenho se comparado às máquinas seqüenciais.

As máquinas paralelas não só têm muitas instâncias dos recursos (CPU, registradores, sistemas de entrada e saída) que podem causar gargalos em programas seqüenciais, como também incluem características únicas como redes de interconexão e protocolos de coerência que podem contribuir para os problemas de desempenho.

No que se refere ao ambiente, uma questão que deve ser levada em conta são os efeitos arquiteturais.

Muito mais do que em sistemas monoprocessados, o desempenho de máquinas paralelas depende de uma quantidade indefinida de questões arquiteturais envolvendo comunicação e compartilhamento de recursos.

O programador que está desenvolvendo para uma máquina paralela deve ser cauteloso principalmente com as situações envolvendo quantidades diferentes de dados, computação ou comunicação.

Embora o processamento paralelo tenha se tornado uma abordagem comum para obter alto desempenho, as técnicas de avaliação de desempenho são fracas.

Não existe nenhuma métrica bem estabelecida para medir o ganho de desempenho.

Simplesmente estender as métricas seqüenciais para os programas paralelos não é suficiente porque, em um programa paralelo, melhorar o procedimento que consome a maior quantidade de tempo pode não melhorar o tempo total de execução do programa.

As dependências que existem entre os processos em um programa paralelo influenciam no momento de saber quais procedimentos são importantes para o tempo de execução do programa.

As diferenças entre as métricas de desempenho de um programa paralelo podem ser notadas através do modo como elas respondem a estas dependências entre os processos.

O maior problema em ter muitas métricas é saber qual delas usar.

Hollingsworth e Miller compararam várias métricas distintas e concluíram que não havia uma métrica única que fosse a melhor.

Na verdade, as orientações de várias métricas coincidiram.

Contudo, eles foram capazes de caracterizar os tipos de programas onde cada métrica seria útil.

Esta informação é valiosa ao programador, e poderia ajudá-lo a selecionar as métricas apropriadas.

Além disso, métricas diferentes têm custos de computação diferentes.

Algumas vezes uma métrica mais barata (como uma prova) é suficiente e então não há a necessidade de calcular métricas complexas.

As métricas de desempenho provêm uma direção útil para se descobrir alguns tipos de gargalos, contudo, como métricas diferentes são requeridas para tipos diferentes de gargalos é deixada para o usuário a escolha de qual métrica utilizar.

A melhoria do desempenho de uma aplicação paralela pode ser visto como um processo iterativo consistindo de vários passos, envolvendo a identificação e localização de insuficiências, seus consertos e a verificação e validação do desempenho alcançado.

O objetivo é definir as métricas de desempenho e um critério para explicar as propriedades e o comportamento de uma aplicação, identificando e localizando suas insuficiências de desempenho.

Durante o processo de medir o desempenho de uma aplicação, vários tipos de parâmetros podem ser medidos.

Eles incluem parâmetros de medição de tempo, como, wall clock times, bem como parâmetros de contagem, como número de operações de entrada/saída, número de bytes lidos/escritos, número de acessos à memória, número de bytes enviados/recebidos.

Estes parâmetros podem ser medidos em diferentes níveis de granulosidade, quer dizer, eles podem se referir à aplicação inteira, com suas atividades, por exemplo, computação, comunicação, acessos à memória, operações de E/S ou podem ser referir às suas regiões de código, por exemplo, laços de repetição, rotinas e declarações de código.

Um erro comum tanto na análise de programa serial como na análise de programa paralelo é medir o programa em um conjunto de dados e assumir que isso representa todos os conjuntos de dados.

Para muitos programas, a velocidade pode depender fortemente dos dados de entrada.

Neste caso, um programador pode desejar fazer execuções suficientes variando os dados de entrada para alcançar uma estimativa que seja estatisticamente útil do tempo de execução, ou pode tentar determinar o desempenho valendo-se do pior caso e do melhor caso das entradas.

Uma boa medida para o processamento paralelo é a velocidade média, a qual pode ser definida como sendo a velocidade alcançada de um dado sistema computacional dividida pelo número de processadores.

Idealmente, a velocidade média se mantém constante à medida que o tamanho do sistema cresce.

O pico de desempenho do hardware especificado pelos vendedores normalmente está baseado nesta suposição ideal.

Contudo, se o tamanho do problema é fixo, a situação ideal provavelmente não ocorre.

O motivo é que para um problema que tenha o tamanho fixo, a razão comunicação/computação provavelmente cresce com o aumento do número de processadores, então, a velocidade média diminui com o aumento do tamanho do sistema.

Por outro lado, se o tamanho do sistema é fixo, a razão comunicação/computação provavelmente decresce com o aumento do tamanho do problema para a maioria dos algoritmos práticos.

Para estes algoritmos, aumentar o tamanho do problema proporcionalmente ao tamanho do sistema pode manter a velocidade média constante.

Suponha que tenha sido escolhido um programa paralelo com uma determinada carga de trabalho e que se queira usá-lo para avaliar uma máquina.

Para uma máquina paralela, há duas coisas que é necessário medir, o desempenho absoluto e a melhoria de desempenho devido ao paralelismo.

Esta última é tipicamente conhecida como speedup, que é definida como o desempenho absoluto obtido com a utilização de p processadores dividido pelo desempenho obtido com a utilização de um único processador.

O desempenho absoluto (juntamente com o custo) é mais importante para o usuário final ou para a pessoa que vai adquirir a máquina.

Contudo, ele sozinho não diz muito sobre o aumento de desempenho com a utilização do paralelismo e a efetividade de comunicação da arquitetura se comparado ao desempenho de um único processador.

O speedup diz isto e é a métrica de desempenho mais comumente utilizada para o processamento paralelo.

O desempenho absoluto será novamente abordado na Seção.

Tendo como medida de desempenho o tempo de execução, nós poderemos simplesmente executar o programa com uma mesma configuração de entrada em 1 e em p processadores e medir a melhora ou speedup como Já foi discutida a utilidade da melhoria de desempenho ou speedup para obter insights dentro da análise de desempenho de uma máquina paralela.

A questão que ficou em aberto na medida de speedup para qualquer modelo escalar é o que o denominador na fração do speedup, desempenho em um processador, deveria realmente medir.

Existem quatro escolhas, 1 Desempenho do programa paralelo em um processador da máquina paralela.

Desempenho de uma implementação seqüencial do mesmo algoritmo em um processador da máquina paralela.

Desempenho da implementação do "melhor" algoritmo seqüencial em um processador da máquina paralela.

Desempenho do "melhor" programa seqüencial numa máquina padrão de acordo.

A diferença entre as opções 1 e 2 é que o programa paralelo incorre em overheads mesmo quando executado em um único processador, já que ele ainda executa sincronização, instruções de gerenciamento de paralelismo ou particionamento de código, ou testes para omitir estes.

Estes overheads podem ser significantes algumas vezes.

A diferença entre as opções 2 e 3 é que o melhor algoritmo seqüencial pode não ser possível ou pode não ser fácil de ser efetivamente paralelizado, assim, o algoritmo utilizado no programa paralelo pode ser diferente do melhor algoritmo seqüencial.

Utilizar desempenho como definido pela opção 3 claramente leva a uma métrica de speedup melhor e mais honesta do que os das opções 1 e 2.

Do ponto de vista do arquiteto, contudo, em muitos casos pode-se usar a definição 2.

A definição 4 resulta na métrica de comparação que é similar ao desempenho absoluto.

De acordo com as opções acima citadas, o speedup tem sido definido de forma distinta.

Uma das definições foca em quão mais rápido um problema pode ser resolvido com a utilização de p processadores.

Assim, ele compara o melhor algoritmo seqüencial com o algoritmo paralelo que está sendo considerado.

Esta definição é referenciada como speedup absoluto.

O speedup absoluto tem duas definições distintas, dependendo do fato de considerar ou não os recursos da máquina.

No caso da independência da máquina, este speedup é definido como a razão do tempo decorrido do melhor algoritmo seqüencial em um processador sobre o tempo decorrido do algoritmo paralelo em p processadores.

No caso da dependência da máquina, o speedup absoluto é definido como a razão do tempo decorrido do melhor algoritmo seqüencial na máquina seqüencial mais rápida sobre o tempo decorrido do algoritmo paralelo na máquina paralela.

Outro speedup, chamado speedup relativo, lida com o paralelismo inerente do algoritmo paralelo que está em consideração.

Ele é definido como a razão do tempo decorrido do algoritmo paralelo em um processador sobre o tempo decorrido do algoritmo paralelo em p processadores.

A razão de se utilizar o speedup relativo é que o desempenho de algoritmos paralelos varia de acordo com o número de processadores disponíveis.

Comparar o algoritmo em si com números diferentes de processadores, dá a informação das variações e das degradações de paralelismo.

O speedup absoluto e o speedup relativo são duas medidas de speedup freqüentemente utilizadas.

Entre todos os speedups definidos, o speedup relativo provavelmente seja o que tem tido a maior influência no processamento paralelo.

Duas formulações bem conhecidas de speedup foram propostas baseadas no speedup relativo.

Uma delas é a lei de Amdahl e a outra é o speedup escalável de Gustafson.

Estas duas formulações de speedup usam um único parâmetro, a parte seqüencial do algoritmo paralelo.

A lei de Amdahl fixa o tamanho do problema e está interessada em quão rápido pode ser o tempo de resposta.

Ela sugere que o processamento maciçamente paralelo pode não alcançar um speedup elevado.

Gustafson aborda o problema de outro ponto de vista.

Ele fixa o tempo de resposta e está interessado em quão grande um problema pode ser para ser resolvido dentro deste tempo fixado.

O argumento de Gustafson é que o tamanho do problema poderia aumentar até alcançar o poder computacional disponível para obter melhores resultados.

Os resultados experimentais mostram que o speedup poderia aumentar linearmente com o número de processadores disponíveis, baseado neste argumento.

Uma medida de custo, útil para as máquinas paralelas, é o número de processadores utilizados.

Pode-se definir a medida de eficiência como onde Sp(n) é o speedup e p é o número de processadores.

A eficiência é o parâmetro de desempenho que mede a utilização média do processador, sendo definida como a razão do speedup sobre o tamanho do sistema.

De acordo com a definição de diferentes speedups, tem-se diferentes definições para a eficiência, como a eficiência absoluta e a eficiência relativa.

O valor obtido com a expressão da eficiência (Equação 33) normalmente se encontra entre o intervalo e é freqüentemente transformado em um valor percentual.

A Lei de Amdahl tem sido amplamente utilizada por projetistas e pesquisadores para alcançar uma estimativa inicial da melhoria de desempenho quando projetos e implementações variadas são experimentados.

A formulação original da lei de Amdahl define o impacto da porção inerentemente seqüencial de uma tarefa no speedup durante o multiprocessamento.

Suponha que f represente a fração da tarefa que é inerentemente seqüencial, então, utilizando N processadores o speedup é dado por Este relacionamento gera um pessimismo em relação à viabilidade do processamento maciçamente paralelo especialmente se nós superestimamos o valor da fração f.

Mas, os pesquisadores na comunidade de computação paralela começaram a suspeitar da utilidade e da validade da lei de Amdahl após observar speedups lineares impressionantes em algumas aplicações grandes.

Gustafson obteve speedups quase lineares, em um hipercubo com 1024 processadores, para três aplicações práticas, análise de tensão de viga, simulação de onda de superfície, e fluxo de fluido instável.

Isto o levou a suspeitar da natureza da formulação inicial de Amdahl e pareceu ter "quebrado" a lei de Amdahl e ter justificado o processamento maciçamente paralelo.

Por exemplo, Gustafson discute que a lei de Amdahl é imprópria para as abordagens correntes de processamento maciçamente paralelo e sugere uma medida de speedup escalável para substituí-la.

E Barsis propôs uma fórmula de speedup escalável, que é freqüentemente referenciada como a lei de Gustafson.

Ela é enunciada como, se a fração de tempo gasta pela parte seqüencial no sistema paralelo é g, então com N processadores o speedup escalável é um relacionamento linear simples.

Em 1967, a lei de Amdahl foi usada como um argumento contra o processamento maciçamente paralelo.

Já em 1988 a lei de Gustafson foi utilizada para justificar o processamento maciçamente paralelo.

Yuan Shi mostrou que a lei de Gustafson e a lei de Amdahl não são duas leis separadas e, de fato, provou a equivalência das duas leis.

Yuan Shi concluiu que o uso do conceito de "porcentagem seqüencial" na avaliação de desempenho em ambiente paralelo é que conduz ao engano.

Isto causou confusão na comunidade de processamento paralelo durante quase três décadas.

Esta confusão desaparece quando os tempos de processamento são usados nas formulações.

O que Yuan Shi sugeriu foi que as formulações baseadas em tempo seriam mais apropriadas para avaliação de desempenho paralelo.

Em 1967, a lei de Amdahl foi usada como um argumento contra o processamento maciçamente paralelo.

Já em 1988 a lei de Gustafson foi utilizada para justificar o processamento maciçamente paralelo.

Yuan Shi mostrou que a lei de Gustafson e a lei de Amdahl não são duas leis separadas e, de fato, provou a equivalência das duas leis.

Yuan Shi concluiu que o uso do conceito de "porcentagem seqüencial" na avaliação de desempenho em ambiente paralelo é que conduz ao engano.

Isto causou confusão na comunidade de processamento paralelo durante quase três décadas.

Esta confusão desaparece quando os tempos de processamento são usados nas formulações.

O que Yuan Shi sugeriu foi que as formulações baseadas em tempo seriam mais apropriadas para avaliação de desempenho paralelo.

Pela conclusão de Yuan Shi, Gustafson tinha, erroneamente, utilizado o valor de g como o valor de f na lei de Amdahl e suspeitou incorretamente da lei de Amdahl.

As duas frações, f e g, são relacionadas em Por exemplo, Gustafson usou g = 0004 e calculou o speedup escalável como 1020 com N = 1024, mas utilizando-se a lei de Amdahl obteve um speedup de 201, usando o valor de g para f.

Se ele tivesse utilizado o valor correto de f correspondente a g = 0004, que é 00000039, então ele teria obtido o mesmo speedup de 1020 utilizando a lei de Amdahl.

Assim, não há nada pessimista na lei de Amdahl.

Na prática, para várias aplicações, a fração da parte serial é muito pequena, conduzindo à aproximação de speedups lineares.

Sabe-se que, dada uma arquitetura paralela e um problema de um tamanho fixo, o speedup de um algoritmo paralelo não continua a aumentar com o aumento do número de processadores, mas ele tende a saturar ou alcançar o cume com certo tamanho de sistema.

Desta forma, existem três relacionamentos possíveis entre um speedup e o número de processadores (P), Como todo programa paralelo prático deve consolidar a(s) resposta(s) final (is) em um programa, a porcentagem seqüencial na lei de Amdahl nunca é zero, na prática.

Assim, teoricamente speedups linear e super linear não são possíveis.

Na realidade, contudo, há dois fatores que podem ser utilizados para produzir speedups lineares ou super lineares, O uso de uma execução seqüencial com recursos limitados como a base para o cálculo do speedup.
O uso de uma implementação paralela que pode deixar de executar uma grande quantidade de passos de cálculos e ainda assim produzir a mesma saída do algoritmo seqüencial correspondente.

Em foi mencionado que speedups super lineares foram reportados por operações de busca, como algoritmos genéticos paralelos, etc.

Obviamente, speedups super lineares podem também ser produzidos, especialmente em workstations modernas com memórias caches externas grandes, ou seja, se executar o programa em uma única workstation, o computador utiliza memória principal e talvez até mesmo memória swap, se executar em muitos computadores, a aplicação inteira executa na memória principal, talvez até mesmo execute integralmente na cache externa.

Assim, poderá ter o speedup super linear.

Segundo Hwang e Xu, um sistema computacional, incluindo todos recursos de hardware e software, é dito escalável se ele pode ter seus recursos melhorados/aumentados para absorver qualquer demanda de desempenho ou funcionalidade, ou reduzidos para diminuir custos.

Para, uma combinação algoritmo-máquina é escalável se a velocidade média alcançada por um algoritmo em uma dada máquina pode permanecer constante com o aumento do número de processadores, contanto que o tamanho do problema possa ser aumentado com o aumento do tamanho do sistema.

Como máquinas paralelas com mais e mais processadores têm se tornado disponível, a escalabilidade da métrica para desempenho está se tornando ainda mais importante.

Escalabilidade mede como um algoritmo se comporta quando o tamanho do problema é aumentado linearmente com o número de processadores.

Seja T(p, W) o tempo de execução para resolver um problema cujo trabalho é W (tamanho do problema) em p processadores.

Na situação ideal, o número de processadores e a quantidade de trabalho podem ser aumentados N vezes, enquanto o tempo de execução permanece inalterado, A equação (37) é verdadeira se e somente se a velocidade média do sistema computacional for constante, onde a velocidade média é definida como o quociente da velocidade alcançada do dado sistema computacional e o número de processadores.

A escalabilidade é formalmente definida como a capacidade de manter uma dada velocidade média.

Contudo, a escalabilidade não é sinônimo de tornar-se grande (scale-up).

Envolve também a habilidade de reduzir (scale down).

Dizer que um sistema é escalável envolve três pontos, Funcionalidade e desempenho, O sistema escalável deve oferecer ou mais funcionalidade ou melhor desempenho.

A potência total de processamento do sistema deve crescer proporcionalmente ao acréscimo de recursos.

Escalabilidade do custo, O custo pago para escalar o sistema deve ser razoável.

Regra prática, um escalonamento de n vezes não deve acarretar um custo superior a n ou n log n vezes.

Compatibilidade, os mesmos componentes incluindo harware, software de sistema e software de aplicação precisam continuar utilizáveis com pequenas alterações.

As melhorias devem ser compatíveis com o resto do sistema, memórias, discos, interconexões, periféricos devem permanecer úteis.

A escalabilidade de recurso se refere ao ganho de desempenho ou funcionalidade obtido com o aumento do tamanho da máquina (número de processadores), com o aumento da capacidade de armazenamento (cahe, memória principal, discos), com a melhoria do software, etc.

Escalabilidade de tamanho da máquina significa fazer a máquina mais (ou menos) poderosa.

Como o interesse aqui é o paralelismo, o tamanho da máquina é definido como o número de processadores.

A maneira mais imediata de escalonar um sistema é aumentar o tamanho da máquina (número de processadores).

A escalabilidade de tamanho mede o número máximo de processadores que um sistema pode suportar.

Na escalabilidade de recursos pode-se manter o mesmo número de processadores e investir em mais memória, caches maiores, discos maiores, melhoria na arquitetura de comunicação ou no sistema de entrada/saída.

Na escalabilidade de software, o software de um sistema pode ser melhorado, nova versão do SO, melhor compilador, bibliotecas mais eficientes, aplicativos mais eficientes, ambientes amigáveis, etc.

Para explorar completamente o potencial de computadores paralelos escaláveis, os programas aplicativos também devem ser escaláveis.

Isto significa que o mesmo programa deve executar com um desempenho proporcionalmente melhor num sistema melhorado.

A escalabilidade do tamanho do problema indica a capacidade do sistema em suportar problemas maiores, tamanho de dados maiores, maior carga de trabalho.

A escalabilidade tecnológica se aplica a um sistema escalável que se adapta a mudanças tecnológicas.

Pode ser dividido em três categorias, escalabilidade de geração, escalabilidade de espaço e heterogeneidade.

Na escalabilidade de geração (temporal), um sistema pode ser melhorado utilizando componentes de nova geração, tais como processador mais rápido, memória mais rápida, nova versão do sistema operacional, compilador com mais recursos, entre outros.

Novamente, o poder computacional deveria aumentar quando o sistema migrasse para uma próxima geração.

O restante do sistema deveria permanecer utilizável com o mínimo de modificações possíveis.

A escalabilidade de espaço se refere à habilidade de um sistema escalonar de múltiplos processadores em um gabinete, numa sala, num prédio, múltiplos prédios e regiões geográficas.

Neste sentido, a Internet tem uma excelente escalabilidade de espaço.

A heterogeneidade é uma propriedade se refere à quão bem um sistema pode ser melhorado com a integração de componentes de hardware e software vindos de diferentes origens.

Na área de software isto é chamado de portabilidade.

Existem as seguintes distinções e relacionamentos entre a escalabilidade e o speedup tradicional.

Tanto a escalabilidade quanto o speedup dependem dos tamanhos iniciais do problema e do sistema e não são quantitativamente dimensionáveis, diferentemente das métricas de desempenho, tempo de execução, velocidade, etc.

Quando o tamanho do sistema aumenta, o speedup provê a razão da variação da métrica de desempenho escolhida e a escalabilidade indica a capacidade do sistema para manter a métrica de desempenho escolhida.

Speedups tradicionais requerem que o tamanho do problema seja fixo, mas a escalabilidade exige que o tamanho do problema seja escalável.

Speedup mede o ganho de desempenho do processamento paralelo versus o processamento serial, enquanto a escalabilidade mede a degradação de desempenho de sistemas paralelos maiores versus sistemas paralelos menores.

As etapas de particionamento, decomposição e atribuição, são em grande parte independente da arquitetura subjacente ou da abstração da comunicação e tem maior preocupação com questões de algoritmo que dependem somente de propriedades inerentes ao problema.

Em particular, estas etapas vêm o multiprocessador simplesmente como um conjunto de processadores que comunicam um com o outro.

Para estas etapas a máquina pode ser visualizada simplesmente como um conjunto de processadores cooperantes, ignorando seu modelo de programação e sua organização.

Tudo o que se sabe neste estágio é que a comunicação entre os processadores é cara em termos de custo de processamento.

As três questões algorítmicas que precisam ser consideradas para o particionamento são, balancear a carga de trabalho e reduzir o tempo gasto na espera por sincronização de eventos, reduzir comunicação e reduzir o trabalho extra feito para determinar e gerenciar uma boa atribuição de tarefas a processadores.

Infelizmente, estas três metas algorítmicas primárias estão em contrariedade umas com as outras.

Uma meta singular de minimizar a comunicação seria satisfeita executando o programa num único processador, mas isso resultaria no desbalanceamento final da carga.

Por outro lado, a aproximação de um balanceamento de carga perfeito poderia ser obtida a um grande custo de comunicação.

Para diminuir a penalidade de gerenciamento de tarefas, pode-se fazer de cada operação primitiva no programa uma tarefa e associar as tarefas aleatoriamente aos processadores.

Em muitas aplicações complexas, o balanceamento de carga e a comunicação podem ser melhorados se for gasto mais tempo determinando uma boa atribuição de tarefas a processadores.

A meta de uma decomposição e atribuição é obter um compromisso entre estas demandas conflitantes.

Em sua forma mais simples, balancear a carga de trabalho significa assegurar que cada processador faça a mesma quantidade de trabalho.

Isso implica combinar concorrência suficiente com atribuição apropriada e redução de serialização, resultando no seguinte limite simples de speedup potencial, Trabalho, neste contexto, deveria ser interpretado liberalmente, porque o que importa não é somente quantas operações de cálculo são feitas, mas o tempo gasto para executá-las, o que envolve acesso a dados e comunicação.

De fato, balanceamento de carga é um pouco mais complicado do que simplesmente igualar o trabalho.

Não significa somente os processadores distintos executarem a mesma quantidade de trabalho, mas estes devem estar trabalhando ao mesmo tempo.

O ponto extremo seria se o trabalho fosse dividido igualmente entre os processos, mas somente um processo estivesse ativo por vez, assim, não haveria nenhum speedup.

A meta real do balanceamento de carga é minimizar o tempo que os processos gastam esperando por pontos de sincronização, incluindo os implícitos no fim do programa.

Isto também envolve minimizar a serialização de processos devido à exclusão mútua (espera para entrar em seções críticas) ou dependências.

O balanceamento de carga ótimo é computacionalmente caro e iria requerer um conhecimento prévio das características da carga de trabalho do sistema, durante o tempo de execução.

Alternativamente, é desejável ter um algoritmo sub-ótimo que exija menos informação sobre a carga de trabalho, que possa lidar com a imperfeição do conhecimento sobre o estado do sistema e que não seja tão caro para ser utilizado.

O balanceamento de carga pode ser um mecanismo centralizado ou descentralizado.

No mecanismo centralizado, a decisão de alocar processos aos hosts diferentes na rede é feita por um controlador central onde o estado do sistema é mantido.

No mecanismo descentralizado, os processos são escalonados nos hosts de chegada.

Esta abordagem é mais rápida na tomada de decisões, contudo ela requer maior custo de comunicação para atualizar todos os hosts com o estado do sistema.

A política de balanceamento de carga pode ser estática ou dinâmica.

Nas políticas de balanceamento de carga estáticas, a alocação de processos aos hosts é feita com base em um comportamento médio predeterminado da rede e não no estado corrente do sistema.

Alternativamente, nas políticas dinâmicas, a alocação de processos aos hosts é feita baseada na estimativa atual do estado do sistema.

Estas políticas associariam o processo na criação ou na chegada de um host externo para o host que pareça ser o melhor naquele momento.

Existem quatro etapas para balancear a carga de trabalho e reduzir o tempo de espera por sincronização, Identificar concorrência suficiente durante a decomposição, e superar a Lei de Amdahl.

Decidir como gerenciar a concorrência (estaticamente ou dinamicamente).

Determinar a granulosidade na qual se possa explorar a concorrência.

Reduzir os custos de serialização e de sincronização.

O balanceamento de carga é por si só conceitualmente fácil desde que a aplicação tenha recursos para prover concorrência suficiente.

Talvez o mais importante tradeoff com o balanceamento de carga seja reduzir a comunicação entre os processadores.

Decompor um problema em múltiplas tarefas normalmente implica em ter-se comunicação entre as tarefas.

Se estas tarefas estão associadas a diferentes processos, podemos incorrer em comunicação entre os processos e, portanto, comunicação entre processadores.

Nós focamos aqui na redução da comunicação que é inerente ao programa paralelo, isto é, um processo produz um dado de que outro necessita, enquanto ainda seja preservado o balanceamento de carga, retendo nossa visão da máquina como um conjunto de processadores cooperantes.

O impacto da comunicação é mais bem estimado não pela quantidade de comunicação, mas por uma quantidade chamada de razão entre comunicação e computação.

Isto é definido como a quantidade de comunicação (que pode ser em bytes) dividida pelo tempo de computação, ou pelo número de instruções executadas.

Por exemplo, um gigabyte de comunicação tem um impacto muito maior no tempo de execução e na ocupação da banda de comunicação de uma aplicação se o tempo requerido para que a aplicação execute é de 1 segundo do que o impacto se o tempo requerido para que a aplicação execute é de 1 hora.

A razão entre a comunicação e a computação pode ser calculada como um número por processo, ou pode ser acumulado por todos os processos.

A comunicação inerente à razão da computação é primariamente controlada pela atribuição de tarefas a processos.

Para reduzir a comunicação, nós deveríamos tentar assegurar que as tarefas que acessem os mesmos dados ou que necessitem se comunicar muito sejam atribuídas ao mesmo processo.

Por exemplo, numa aplicação de banco de dados, a comunicação seria reduzida se as consultas e as atualizações que acessem os mesmos registros do banco de dados fossem atribuídas ao mesmo processo.

Em adição à redução do volume de comunicação, é também importante manter a comunicação balanceada entre os processadores, não somente a computação.

Já que a comunicação tem um alto custo, desbalanceamentos na comunicação podem-se traduzir diretamente em desbalanceamentos no tempo de execução dos processadores.

Incluir a comunicação como um custo explícito de desempenho refina nosso limite básico de speedup para, A discussão da decomposição de domínio mostra que quando uma computação é irregular, computar uma atribuição eficiente que forneça um balanceamento de carga e que reduza a comunicação pode ser bastante cara.

Este trabalho extra não é requerido na execução seqüencial e é um overhead.

Outro exemplo de trabalho extra é computar valores de dados redundantemente ao invés de ter um processo que os compute e comunique aos demais, o que vem a ser um tradeoff favorável quando o custo de comunicação é alto.

Finalmente, muitos aspectos existentes em programas paralelos, tais como criar processos, gerenciar tarefas dinâmicas, distribuir código e dados ao longo da máquina, executar operações de sincronização e instruções de controle de paralelismo, estruturar a comunicação apropriadamente para a máquina, empacotar e desempacotar dados para e das mensagens de comunicação, envolvem trabalho extra.

Torna-se necessário considerar cuidadosamente os tradeoffs entre o trabalho extra, o balanceamento de carga e a comunicação quando vamos tomar nossas decisões de particionamento.

A arquitetura pode nos ajudar a reduzir o trabalho extra ao fazer de modo mais eficiente a comunicação e o gerenciamento das tarefas e, portanto, reduzir a necessidade por trabalho extra.

Baseado somente nessas questões algorítmicas, o limite de speedup pode ser refinado para, Desempenho absoluto é mais bem medido como trabalho executado por unidade de tempo.

Para um usuário de um sistema o desempenho absoluto é a medida mais importante.

Suponha que o tempo de execução seja a nossa métrica de desempenho absoluto.

O tempo pode ser medido de diferentes modos.

Primeiro, existe uma escolha entre o tempo do usuário (user time) e o wall-clock time para uma carga de trabalho.

O user time é o tempo que a máquina gasta executando o código de uma carga de trabalho particular ou um programa, excluindo, assim, atividade do sistema e outros programas que podem também compartilhar do tempo de processamento, enquanto o wall-clock time é o tempo total decorrido para a execução da carga de trabalho, incluindo todas as atividades que possam intervir, medido por um relógio que se encontra na parede.

Segundo, há a questão de se deve ser utilizado o tempo de execução médio ou o máximo de todos os processos do programa.

Como, finalmente, o que importa aos usuários é o wall-clock time, nós devemos medir e apresentar este tempo na comparação de sistemas.

Contudo, se outros programas de usuários, não somente o sistema operacional, interferir na execução do programa em decorrência da multiprogramação, então o wall-clock time não vai nos ajudar a entender os gargalos de desempenho naquele programa particular em que estamos interessados.

Note que o user time para aquele programa pode não ser também muito útil neste caso, uma vez que a execução intercalada com processos sem conexão rompe com as interações do programa, assim como sua sincronização e balanceamento de carga, no sistema de memória.

Nós deveríamos, então, apresentar o wall-clock time e descrever o ambiente de execução (batch ou multiprogramado), se ou não nós apresentamos informações mais detalhadas para realçar a compreensão.

Similarmente, como um programa paralelo não termina até que o último processo tenha terminado, é o tempo deste ponto que é importante, e não o tempo médio dos processos.

Claro, se nós realmente queremos entender os gargalos de desempenho nós precisaríamos verificar os perfis de execução de todos os processos, ou como um exemplo, quebrar em componentes de tempo distintos.

Em resumo, do ponto de vista do usuário na comparação de máquinas a medida de desempenho de maior interesse é o tempo de execução wall-clock (havendo, claro, questões de custos a serem consideradas).

Contudo, do ponto de vista de um arquiteto, para um programador entender o desempenho de um programa ou para um usuário mais interessado no desempenho de uma máquina, é melhor utilizar o tempo de execução e o speedup.

A aplicação utilizada como benchmark neste trabalho para analisar o desempenho do ambiente heterogêneo é um código paralelo para uma solução do método dos elementos finitos (MEF) aplicados à elasticidade linear, onde o sistema de equações algébricas é resolvido por uma versão paralela do método dos gradientes conjugados (MGC).

A Engenharia Mecânica utiliza-se de uma enorme gama de materiais para as várias construções e experiências profissionais.

Dentre esses materiais, as placas, metálicas ou não, possuem grande utilização, desde desenvolvimentos mais resistentes como caçambas, caldeiras, autoclaves até peças sensíveis como próteses humanas, placas para controle, entre outros.

Para o desenvolvimento de tais peças é necessária uma grande quantidade de testes preliminares com as placas utilizadas, prevendo o desgaste e possíveis falhas na fabricação e no decorrer do uso.

Tais testes demandam grande custo financeiro e na maioria das vezes um tempo vasto nas experiências.

O Método dos Elementos Finitos (MEF) foi desenvolvido como um meio de baratear os custos e diminuir o tempo de teste.

No âmbito da Engenharia de Estruturas, o Método dos Elementos Finitos tem como objetivo a determinação do estado de tensão e de deformação de um sólido de geometria arbitrária sujeito a ações exteriores.

O método dos elementos finitos se tornou uma das mais poderosas ferramentas de análise para solução de problemas de engenharia.

Um número muito grande de autores tem tratado das formulações, aplicações e implementações computacionais desta técnica nos últimos 50 anos.

Na análise estrutural, área onde mais tem se desenvolvido, a base do método de elementos finitos consiste em transformar o sólido contínuo em uma associação de elementos discretos e escrever equações de equilíbrio e compatibilidade entre eles, admitindo funções contínuas capazes de representar o campo de deslocamentos no domínio do elemento.

A partir de então, obtém-se o estado de deformações e, através de relações constitutivas chega-se ao estado de tensões nos elementos.

Pelo método dos elementos finitos um modelo matemático descrito por equações diferenciais em um domínio contínuo, é convertido em um modelo discreto de pequenos elementos, com um número finito de graus de liberdade (GLs), pelo uso de algum método variacional.

O advento da computação digital motivou a aplicação dos métodos numéricos na solução dos problemas de engenharia.

Através de métodos como elementos finitos, equações algébricas são obtidas para estimar, em um número finitos de pontos, a solução analítica.

Esta estimativa pode ser aprimorada com o aumento do número de equações.

A formulação matemática do método dos elementos finitos pode ser obtida através de métodos variacionais ou de métodos de resíduos ponderados.

Todas estas técnicas permitem transformar o conjunto de equações diferenciais parciais em um sistema de equações algébricas.

A abordagem usada na aplicação é fundamentada em um método variacional, o Princípio dos Trabalhos Virtuais e está baseada na forma adotada por Bathe.

A área da mecânica computacional resolve problemas específicos por simulação através de métodos numéricos implementados em computadores digitais.

Dentre os ramos da mecânica computacional que podem ser distinguidos de acordo com a escala física do foco de atenção, nossa atenção será voltada para a mecânica do contínuo.

Grande parte dos problemas de engenharia pode ser formulada através dos princípios gerais da mecânica do contínuo.

Este ramo da mecânica trata a matéria como sendo um meio contínuo, sem vazios interiores, desconsiderando sua estrutura molecular.

Na mecânica do contínuo, os princípios da física são escritos sob a forma de equações diferenciais.

Os efeitos da constituição interna molecular dos materiais são levados em conta de forma macroscópica através das equações constitutivas do material.

A mecânica do contínuo estuda os corpos ao nível macroscópico, utilizando modelos contínuos nos quais a micro-estrutura é homogeneizada por médias calculadas do fenômeno.

As duas áreas tradicionais de aplicação da mecânica do contínuo são a mecânica dos sólidos e a dos fluidos.

A primeira inclui as estruturas que, por razões óbvias, são fabricadas com sólidos.

A mecânica computacional dos sólidos tem uma abordagem científica aplicada, considerando que a mecânica computacional estrutural enfatiza aplicações tecnológicas para a análise e modelagem de estruturas.

A mecânica computacional dos fluidos lida com problemas que envolvem o equilíbrio e o movimento de líquidos e gases.

O Método dos Elementos Finitos (MEF) é seguramente o processo que mais tem sido usado para a discretização de meios contínuos.

A discretização de sistemas contínuos tem como objetivo particionar o domínio o sistema em componentes cujas soluções são mais simples e, depois, é necessário unir as soluções parciais para obter a solução do problema.

Quando surge a necessidade de resolver um problema de análise de uma estrutura, a primeira questão que se coloca é a sua classificação quanto à geometria, modelo do material constituinte e ações aplicadas.

O modo como o MEF é formulado e aplicado depende, em parte, das simplificações inerentes a cada tipo de problema.

Análise dinâmica e análise estática.

As ações sobre as estruturas são em geral dinâmicas, devendo ser consideradas as forças de inércia associadas às acelerações a que cada um dos seus componentes fica sujeito.

Por este motivo, seria de esperar que a análise de uma estrutura teria, obrigatoriamente, que considerar os efeitos dinâmicos.

Contudo, em muitas situações é razoável considerar que as ações são aplicadas de um modo suficientemente lento, tornando desprezáveis as forças de inércia.

Nestes casos a análise se caracteriza como estática.

Somente serão considerados os problemas que se encaixem na análise estática.

Análise linear e análise não linear.

Os problemas estáticos podem ser classificados em lineares e não lineares.

A análise estática linear lida com problemas estáticos nos quais a resposta é linear no sentido de causa e efeito, ou seja, ao nível do material que constitui a estrutura, a relação entre tensões e deformações é linear.

Por exemplo, se as forças aplicadas são dobradas, os deslocamentos internos também dobram.

Materiais metálicos, quando sujeitos a tensões suficientemente pequenas, exibem comportamento elástico linear e apresentam valores de deformações e deslocamentos diretamente proporcionais às forças aplicadas.

A forma geral de uma equação constitutiva para materiais elásticos lineares é As constantes de proporcionalidade são determinadas experimentalmente.

Os problemas fora deste domínio são classificados como não linear.

Somente serão considerados os problemas que se encaixem na análise linear.

O conceito de MEF será parcialmente ilustrado através de um exemplo bem antigo, encontrar o perímetro L de um círculo de diâmetro d Como L = d, isto é equivalente a obter um valor numérico para.

Mostra o desenho de um círculo de raio r e diâmetro d = 2 r.

Mostra a inscrição de um polígono regular de n lados, onde n = 8.

Renomeando os lados do polígono como elementos e os vértices como nós, numerando os nós com inteiros de 1,8, um elemento típico, por exemplo o segmento que une os vértices 4 e 5 pode ser extraído.

O comprimento do elemento é Li = 2 r sen(/n).

Como todos os elementos têm o mesmo comprimento, o perímetro do polígono é dado por Ln = nLi, de onde a aproximação j para é n= Ln / d = n sen(/n).

O problema de "encontrar o ", tratado com os conceitos do MEF, objeto contínuo, uma aproximação discreta por polígonos regulares, elemento desconectado, elemento genérico.

Algumas idéias chaves por trás do MEF podem ser identificadas neste exemplo.

O círculo, visto como um objeto matemático fonte, é substituído por polígonos.

Estes são aproximações discretas para o círculo.

Os lados, aqui chamados de elementos, são especificados por seus nós.

Os elementos podem ser separados desconectando nós, um processo chamado de separação (desmontagem) no MEF.

A separação (desmontagem) de um elemento genérico pode ser definida, independentemente do círculo original, pelo segmento que conecta dois nós i e j.

A propriedade relevante do elemento, o comprimento do lado Li, pode ser computado j no elemento genérico independentemente dos outros, uma propriedade chamada de suporte local no MEF.

A propriedade alvo, o perímetro do polígono é obtido reconectando-se n elementos e adicionando seus comprimentos, os passos correspondentes à montagem e solução no MEF, respectivamente.

A mesma técnica pode ser utilizada para o plano.

O exemplo não ilustra o conceito de graus de liberdade, quantidades conjugadas e coordenadas local-global.

Pode-se discutir o fato de que um círculo é um objeto mais simples do que um polígono de 128 lados, por exemplo.

Apesar destas falhas o exemplo é útil em um respeito, mostrar uma escolha na substituição de um objeto matemático por outro.

Esta é a raiz do processo de análise do MEF.

O processo de discretização pelo método dos elementos finitos leva ao estabelecimento e à solução de um conjunto de equações algébricas da forma, que aparece na análise de estruturas.

Para problemas lineares, A é matriz de rigidez uma matriz quadrada, positiva definida e simétrica, x é o vetor de deslocamentos nodais e b é o vetor de forças aplicadas aos nós.

Para resolver esse sistema de equações, duas classes de algoritmos podem ser identificadas, os métodos diretos e os métodos iterativos.

Neste capítulo são descritos estes dois métodos e o método dos gradientes conjugados (MGC) é descrito mais detalhadamente por se tratar do método utilizado neste trabalho para solucionar o sistema de equações e também por ser o método mais popular para resolver sistemas de equações lineares como os descritos na Equação (42).

Quando o processo de solução de um sistema de equações lineares envolve a decomposição da matriz dos coeficientes, obtendo-se a solução sem o uso de iterações, este processo é conhecido como método direto.

A solução do sistema é alcançada em um número conhecido de operações, ao contrário dos métodos iterativos.

A principal desvantagem desses métodos, quando aplicados a matrizes esparsas e de ordem elevada, é a grande quantidade de memória requerida e um aumento exagerado da quantidade de trabalho computacional.

Dois exemplos de métodos diretos de solução que podem ser citados são o método de Crout e o método de Cholesky.

Basicamente há três passos durante o processo de solução por um método direto.

Uma fatoração simbólica para determinar o padrão de esparsidade (sparsity pattern) do fator, uma fatoração numérica e retro-substituições (back-substituition) triangulares.

A implementação paralela dos métodos diretos é difícil devido principalmente à característica seqüencial inerente dos processos de decomposição e retro-substituição.

Esses procedimentos requerem uma grande quantidade de comunicação entre processos, além de apresentar dificuldade na distribuição da carga de trabalho entre os processadores, principalmente quando a matriz apresenta um perfil muito irregular.

O termo método iterativo se refere às técnicas que utilizam aproximações sucessivas para obter, a cada passo, soluções mais acuradas para o sistema de equações lineares.

Os métodos iterativos consistem basicamente na geração de uma seqüência de soluções aproximadas do sistema de equações.

Esses métodos partem de uma estimativa inicial para a solução da Equação (42) e realiza, então, sucessivas aproximações até que a convergência seja alcançada.

A convergência não é garantida para todos os métodos e alguns métodos convergem mais rapidamente do que outros para um problema específico.

Ao utilizar a maioria dos métodos iterativos, não se conhece previamente o número de iterações necessárias para alcançar a solução.

Para alguns métodos, entretanto, o número máximo de iterações até se obter a solução é conhecido.

Para que os métodos iterativos sejam eficientes é necessário que a convergência seja obtida com o menor número possível de iterações.

O número de condição da matriz A afeta a taxa de convergência da iteração.

O número de condição da matriz A é definido como onde max e min são, respectivamente, o maior e o menor autovalor (eigenvalue) da matriz A.

Quanto mais próximo da unidade estiver o número de condição da matriz A mais rapidamente irão convergir os algoritmos iterativos.

A quantidade de trabalho computacional necessária por iteração geralmente é linear ou quadrática em relação ao número de incógnitas, enquanto nos métodos diretos esta relação geralmente é cúbica.

Portanto, os métodos iterativos são mais apropriados quando o número de incógnitas é grande.

De um modo geral, a solução iterativa da Equação 42 tem a seguinte forma onde k é o contador de iterações e G e c são, respectivamente, uma matriz e um vetor, os quais são definidos pelo método a ser utilizado e não dependem de k.

Esta matriz e este vetor podem ser expressos em termos de uma matriz não singular Q tal que onde I é a matriz identidade.

Geralmente, esses métodos efetuam uma decomposição da matriz A da seguinte forma onde Ds é uma matriz diagonal, Ls é uma matriz triangular inferior com os elementos da diagonal nulos e Us é uma matriz triangular superior com os elementos nulos na diagonal principal.

Esta decomposição tem um custo computacional mínimo em relação às decomposições efetuadas pelos métodos diretos.

Além disso, a matriz A é simétrica e, portanto, U = L.

Alguns métodos iterativos básicos são descritos e comentados a seguir.

Método de Richardson Este é o mais básico dos algoritmos iterativos.

A matriz Q para este método é definida como portanto, G = I A e c = b.

Apesar da facilidade de implementação, este algoritmo converge apenas quando o autovalor da matriz A é menor do que 2, impossibilitando o seu uso para a maioria dos problemas que aparecem na análise de estruturas.

Método de Jacobi Neste método as matrizes são definidas como portanto, G = D (L +U ) e c = D b.

O método de Jacobi converge sempre que o raio espectral da matriz A for menor do que 1.

Esta condição é frequentemente respeitada na análise de estruturas, mas a sua ocorrência não é garantida.

Define-se raio espectral da matriz A como o maior autovalor de A em valor absoluto, ou seja, max{|(A)|}.

Como apenas uma matriz diagonal deve ser invertida, todas as equações podem ser resolvidas independentemente a cada iteração, o que é apropriado para a implementação em paralelo.

O método de Jacobi examina cada uma das equações do sistema Ax = b isoladamente e independente de ordem.

Por esta razão, este método é também conhecido como o método de deslocamentos simultâneos.

Se cada processo ficar responsável por uma parte do sistema total, as trocas de informações necessárias devem corresponder apenas à montagem da matriz A no inicio da iteração, à troca da solução x com os processos vizinhos após cada iteração e a passagem de escalares durante a checagem da convergência.

Método de Gauss-Seidel Neste método as matrizes têm a seguinte forma portanto, O método de Gauss-Seidel sempre converge se as matrizes A e Ds forem simétricas e positivas definidas.

Como a matriz (Ls + Ds) é invertida, em cada iteração do método de Gauss-Seidel é necessária uma operação de retro-substituição e esta operação é essencialmente seqüencial e requer um grande número de comunicação entre os processos, além de apresentar dificuldade na distribuição equilibrada do trabalho entre os processadores.

Pelo fato da existência de dependência entre as iterações, este método é também conhecido como método de deslocamentos sucessivos.

Este método incrementa as propriedades de convergência do método de Gauss-Seidel, multiplicando a solução encontrada em cada iteração por um escalar, cujo valor deve ficar entre 0 e 1 se a solução deve sofrer uma sub-relaxação ou, o que é mais comum, entre 1 e 2 se se a solução deve sofrer uma sobre-relaxação (a convergência é garantida somente para 0 < < 2).

Existem vários procedimentos para estimar o valor de relaxação apropriado, entretanto, não existe um que seja ideal para todas as aplicações.

As matrizes, neste caso, possuem a seguinte forma portanto, Assim como o método de Gauss-Seidel, neste método também aparecem operações essencialmente seqüenciais durante cada iteração, o que torna este método inapropriado para o ambiente paralelo.

Para matrizes simétricas positivas definidas, o método dos gradientes conjugados (MGC) é efetivo e o método iterativo mais popular para resolver sistemas grandes de equações lineares.

Este método foi desenvolvido por Hestenes e Stiefel no início da década de 50.

A competitividade do MGC considerando os métodos diretos é baseada na necessidade de pouca memória para armazenamento, na pouca quantidade de trabalho computacional necessária por iteração e no fato de ser um algoritmo que possui um paralelismo implícito.

Uma dificuldade associada a vários métodos iterativos é o fato deles, muitas vezes, dependerem de parâmetros que são difíceis de serem escolhidos apropriadamente.

Um exemplo é o método da sobre-relaxação sucessiva, apresentado anteriormente, no qual é necessário estimar um valor para a relaxação adequado ao problema em análise.

Entretanto, não existe a garantia de que o procedimento utilizado para estimar este valor seja o mais apropriado.

O método dos gradientes conjugados, por sua vez, não apresenta este tipo de dificuldade, o que é uma vantagem em relação aos demais métodos iterativos.

Neste trabalho, o método dos gradientes conjugados é utilizado para solucionar o sistema de equações, discretizado através do método de elementos finitos e esta seção é dirigida ao entendimento da solução do método dos gradientes conjugados (MGC) em suas formulações seqüencial e paralela.

O método dos gradientes conjugados garante que o número de iterações necessárias até que a solução correta seja alcançada seja, no máximo, igual ao número de equações do sistema (Neq).

Entretanto, essa garantia existe numa máquina ideal, na qual não ocorrem erros de arredondamento durante as iterações.

Dessa forma, principalmente quando o número de condição do sistema for elevado (10 a 10 ), ou seja, quando o sistema apresenta-se mal condicionado, os erros de arredondamento podem dificultar a convergência do método, podendo ocorrer casos onde o número de iterações ultrapasse bastante o Neq até que a precisão desejada seja alcançada.

Técnicas de pré-condicionamento, apesar de não incluídas na implementação realizada, são empregadas para aumentar a taxa de convergência.

A Equação 42 pode ser reescrita como, onde A é uma matriz de dimensão n x n, x e b vetores de dimensão n.

Shewchuk afirma que uma forma quadrática é uma função quadrática, escalar de um vetor que tem a seguinte forma, onde A é uma matriz, x e b são vetores e c é um escalar.

Shewchuk mostra ainda que se A é simétrica e positiva definida, então f(x) é minimizado pela solução para Ax = b.

Assumindo, por exemplo, os seguintes valores para A, b e c.

A solução do sistema de equações, neste caso, é de fácil obtenção e o vetor x é igual.

Forma quadrática f(x), x1 e x2 são as componentes do vetor x.

Pode-se visualizar que a solução do sistema apresentado é o ponto de mínimo do parabolóide.

Ainda pode ser observado que, sendo A uma matriz positiva definida, a superfície determinada por f(x) tem a forma de um parabolóide com concavidade para cima.

O gradiente da forma quadrática é definido por, O gradiente é um campo vetorial que, para um dado ponto x, aponta para a direção de maior crescimento da função f (x).

No ponto inferior do parabolóide o gradiente é nulo.

Pode-se minimizar a função f (x) impondo que f '(x) seja igual a zero.

Aplicando a Equação 414 à Equação 412 obtém-se, sendo A simétrica, a Equação 414 pode ser reescrita na forma Atribuindo-se zero ao gradiente, obtém-se a equação 41, que é o sistema linear que se deseja resolver.

Portanto, a solução para Ax = b é o ponto crítico de f(x).

Se A é positiva definida além de ser simétrica, então esta solução é um mínimo de f(x), assim Ax = b pode ser resolvido encontrando-se um x que minimize f(x).

No método dos gradientes conjugados a busca pela solução se inicia em um ponto arbitrário x0 e iterativamente procura-se o ponto de mínimo de f (x), solução do sistema.

Para tanto é realizada uma série de passos x0, x1, x2, até que o valor de xk esteja próximo o suficiente da solução x.

Pode-se definir, erro, resíduo e direção de busca através das Equações 417, 418 e 419, respectivamente, onde xk é o ponto em análise, ek é o erro relativo a xk e x é a solução.

Onde r0 é o vetor resíduo do ponto de partida x0.

O comprimento do deslocamento na direção de busca é obtido por meio do seguinte cálculo O resíduo r é atualizado pela seguinte relação, Para se aproveitar o paralelismo para a solução do sistema de equações lineares Ax = b, tanto a matriz A quanto o vetor de incógnitas x e o vetor de termos independentes b estão particionados e distribuídos entre os processadores.

O algoritmo paralelo do método dos gradientes conjugados implementado em e utilizado neste trabalho tem como referência os trabalhos publicados por.

Para paralelizar a solução, a geometria discretizada pelo método dos elementos finitos é particionada em subdomínios e estes, então, são distribuídos entre os processos (tarefas).

Cada tarefa resolve, então, as equações para os elementos que pertencem subdomínio pelo qual ficou responsável durante o particionamento.

Desta forma, os elementos da matriz A, da Equação 42, ficam distribuídos entre as várias tarefas.

Existem graus de liberdade que são compartilhados por mais de uma tarefa, chamados graus de liberdade de fronteira e outros contidos apenas em um único subdomínio, denominados graus de liberdade internos (ou privados).

A matriz A deve ser reestruturada de maneira que os valores dos produtos necessários para a solução do MGC não se alterem.

A ] ilustra uma malha discretizada em elementos e particionada em subdomínios.

Partição de uma malha em 5 outras sub-malhas.

Assim, a matriz A de cada subdomínio computacional é desmembrada em quatro outras, que são Ap, As, Bp e Bp.

Ap é uma matriz quadrada com dimensão igual ao número de graus de liberdade internos de cada subdomínio, na qual, estão armazenados os valores de rigidez referentes aos graus de liberdade internos.

Os graus de liberdade internos são aqueles que pertencem a um único subdomínio.

A matriz As também é quadrada e seu tamanho é definido pelo número de graus de liberdade que estão na fronteira de cada partição.

Em As estão os valores da matriz de rigidez pertinentes aos graus de liberdade de fronteira.

Os graus de liberdade de fronteira são aqueles que pertencem a dois ou mais subdomínios.

A dimensão da matriz Bp é função tanto dos graus de liberdade internos quanto dos de fronteira.

Nesta, estão os valores de rigidez que relacionam os graus de liberdade privados com os de fronteira.

Bp é T a matriz transposta de Bp.

Durante o processo de partição das malhas, os nós e os graus de liberdade são renomeados de forma a permitir que cada tarefa veja seu subdomínio como um domínio, sem perder a relação com o domínio original.

Devido à reestruturação da matriz A, os vetores x e b também são reformulados.

Cada um deles é separado em outros dois.

O vetor b é desmembrado em bp e bs, sendo que o primeiro tem dimensão igual aos graus de liberdade internos e o segundo aos de fronteira.

O mesmo procedimento é feito para o vetor x.

Inspecionando este algoritmo é possível observar que cada processo (tarefa) i, para i = 0 até p-1 (onde p é o número de processos (tarefas)) executa exatamente o mesmo algoritmo.

Pode-se observar também que a comunicação entre as tarefas ocorre somente em dois subprogramas, Atualização e Produto Interno.

Cada passo realizado dentro do laço de solução do MGC é chamado de módulo (M1 até M12).

Algoritmo de solução do gradiente conjugado paralelo.

A função Produto Interno é usada para calcular o produto interno entre dois vetores que se encontram distribuídos entre as tarefas e requer uma comunicação global.

Esta comunicação é uma redução que determina a soma do produto interno de cada tarefa e então fornece a cada processo uma cópia desta soma.

Neste caso, todas as tarefas enviam a variável e a soma de todos é retornada para todas as tarefas.

A função Atualização utiliza comunicações ponto-a-ponto entre os processos que compartilham graus de liberdade.

O propósito desta função é permitir que os valores dos graus de liberdade dos nós de fronteira possam ser montados.

O código da aplicação benchmark foi escrito na linguagem C, utilizando a biblioteca de comunicação MPI.

O pré-processamento e o pós-processamento do programa desenvolvido são realizados através de exportação e importação de arquivos entre este e o aplicativo GID.

Sendo assim, numa primeira etapa em uma única malha, é gerado o modelo de elementos finitos, que envolve o desenho da geometria alvo, a geração da malha de elementos finitos e a aplicação das condições de contorno do problema.

Por meio do aplicativo são organizados os dados de entrada para o programa.

A estrutura de dados gerada pelo aplicativo GID é armazenada em um arquivo compartilhado por todas as máquinas do cluster, assim cada processador (ou tarefa) pode acessar e trabalhar estas informações.

Em seguida, o programa executa o particionamento da malha em subdomínios, realizado através do programa METIS.

Esta decomposição de domínio é feita em paralelo por todas as tarefas.

Como as partições possuem aproximadamente o mesmo número de elementos, cada tarefa efetua basicamente o mesmo número de operações.

Neste momento, cada tarefa já conhece o subdomínio que lhe pertence e, portanto, quais elementos lhe pertence e, então, cada tarefa cria suas matrizes de elementos Ap, As, Bp e Bp.

Finalmente, T o programa resolve o sistema de equações algébricas gerado pelo método dos gradientes conjugados.

Quando o aplicativo METIS efetua o particionamento da malha entre as tarefas, vão existir nós de alguns elementos finitos que estarão compartilhados entre mais de uma tarefa e, portanto, os graus de liberdade destes nós estarão também compartilhados (graus de liberdade de fronteira).

Apresenta uma geometria discretizada dividida em subdomínios.

Para que o sistema de equações algébricas possa ser corretamente solucionado pelo método dos gradientes conjugados, é necessário que ocorram comunicações entre as tarefas que compartilham graus de liberdade para que sejam trocadas informações a respeito destes graus de liberdade de fronteira.

Apresenta uma malha de elementos finitos tridimensional decomposta em duas, quatro e oito partes.

Estas partições foram definidas pelo programa METIS e a visualização gerada pelo programa PMVis (Partitioned Mesh Visualizer).

Mostra resumidamente o funcionamento do programa.

Esquema resumido do funcionamento do programa.

A aplicação utilizada neste trabalho foi implementada em, com o objetivo de verificar o ganho de desempenho obtido com a paralelização do algoritmo do método dos gradientes conjugados.

Entretanto, o foco do trabalho realizado em foi apresentar os resultados baseados nos tempos totais de execução da aplicação.

Além disso, a aplicação foi executada somente em ambiente distribuído homogêneo.

Neste trabalho, o objetivo é apresentar uma medição de tempo de execução mais detalhada, através da inserção de diversos pontos de leitura de tempo de execução.

Esta medição detalhada tem a intenção de caracterizar o tempo gasto por cada uma das principais atividades desempenhadas pela aplicação.

Desta forma, foi possível identificar o percentual do tempo total de execução que é gasto com comunicação e o ganho de desempenho obtido com a concorrência existente em máquinas SMP, quando comparado a máquinas monoprocessadas.

Além disso, a aplicação foi executada em ambiente heterogêneo, com o objetivo de verificar a viabilidade da utilização destes ambientes para a simulação do método dos elementos finitos aplicado à elasticidade linear, para a solução de problemas estruturais.

Com base nos tempos obtidos através da medição detalhada, foi possível estabelecer um balanceamento de carga empírico para o ambiente heterogêneo no qual a aplicação foi executada.

Este capítulo apresenta os resultados obtidos de medições efetuadas em pontos que demandam maior quantidade de tempo em suas execuções, dentro do código da aplicação benchmark, objetivando a caracterização de desempenho desta aplicação.

Os valores obtidos provêm da execução da aplicação em dois clusters distintos de PCs e no ambiente heterogêneo formado por máquinas destes dois clusters.

Uma maneira de obter os tempos é capturar diretamente a hora do sistema.

Neste caso, a precisão do tempo capturado obtida é dependente do sistema operacional e existe um delay que corresponde ao intervalo de tempo necessário para que um processo requisitado para execução pelo sistema operacional seja atendido pelo processador.

A outra maneira de capturar o tempo é indiretamente, através da utilização de ciclos de clock e posterior divisão destes pela freqüência do processador no qual o programa está sendo executado.

Utilizando ciclos de clock, é possível capturar o tempo no nível do hardware e, portanto, o tempo capturado tende a ser mais rápido e mais preciso.

A utilização da instrução assembly rdtsc provida pelas máquinas Intel desde o Pentium II elimina o overhead de chamadas de funções, otimizando o desempenho.

A contagem dos ciclos de clock que ocorrem no processador é armazenada no contador de time-stamp e para acessar este contador, é utilizada a instrução assembly rdtsc (read timestamp counter).

Nos processadores Intel o contador de time-stamp é um registro de 64 bits, que é incrementado a cada ciclo de clock do processador.

O contador é reinicializado a cada vez que a máquina é reiniciada.

A existência do registro TSC permite uma monitoração de tempo independente do compilador utilizado, pois se trata de uma contagem por hardware.

Assim, a temporização de um determinado evento pode ser realizada de forma bem precisa.

Foram comparadas as seguintes funções (ou instruções) que capturam tempo, direta ou indiretamente, a função gettimeofday, provida pelo sistema operacional Linux, que retorna o tempo decorrido, expresso em segundos e micro-segundos.
A função MPI_Wtime, que é um comando da biblioteca MPI que retorna, em segundos, o tempo decorrido desde um tempo arbitrário no passado, a função rdtscll( ) que retorna um time stamp, em ciclos de clock e a instrução assembly rdtsc, que retorna a contagem dos ciclos de clock que ocorrem no processador, armazenada no contador time-stamp.

Para efetuar as comparações, foram implementados quatro programas na linguagem C que fazem chamadas a cada uma das funções e/ou instruções acima.

Cada programa faz cem chamadas a uma das funções ou instrução acima e entre estas chamadas são colocadas intruções assembly rdtsc com o objetivo de medir, em ciclos de clock, o custo de execução de cada uma das cem chamadas de cada função ou instrução.

Estes programas foram executados em 3 máquinas com processadores distintos e com distintas capacidades de memória.

O objetivo desta comparação é descobrir qual das funções ou instrução tem menor custo de execução durante sua chamada para ser utilizada nas medidas dos tempos de determinadas operações dentro do código da aplicação benchmark.

Os valores obtidos, em ciclos de clock, como resultados das execuções dos quatro programas nas diferentes máquinas são apresentados. 

Apresenta os valores médios convertidos para milisegundos e apresenta graficamente os valores expostos. 

Valores obtidos, em ciclos de clock, para as execuções da instrução assembly.

Valores médios convertidos em milisegundos, para as execuções da instrução Custos de execução obtidos, em ciclos de clock, para a instrução assembly rdtsc e para as funções rdtsc( ), gettimeofday( ) e MPI_Wtime( ) na Máquina 1.

Custos de execução obtidos, em ciclos de clock, para a instrução assembly rdtsc e para as funções rdtsc( ), gettimeofday( ) e MPI_Wtime( ) na Máquina 2.

Melhor caso Pior caso Média Custos de execução obtidos, em ciclos de clock, para a instrução assembly rdtsc e para as funções rdtsc( ), gettimeofday( ) e MPI_Wtime( ) na Máquina 3.

Tempos médios de execução obtidos, em milisegundos, para as execuções da instrução assembly rdtsc e das funções rdtsc( ), gettimeofday( ) e MPI_Wtime( ), nas máquinas 1, 2 e 3.

Como pode ser observado, o número de ciclos de clock e também os tempos gastos para a execução da instrução assembly rdtsc é consideravelmente o menor em todas as três máquinas e em todos os três casos, melhor, pior e média, sendo, portanto, a menos intrusiva para ser colocada dentro do código da aplicação benchmark de modo a obter os custos de execução de todo o código ou de trechos deste.

Como o objetivo deste trabalho é caracterizar o desempenho de uma aplicação, será utilizado predominantemente, para a captura dos tempos de execução do código paralelo ou de trechos deste, os ciclos de clock (capturados com a utilização da instrução assembly rdtsc), os quais serão convertidos para unidade de tempo.

Estes são mais precisos que a hora do sistema, pois eliminam o delay ocasionado pelo sistema operacional na requisição de processos (tempo de requisição, espera e concessão para execução) ao processador, criando uma independência do tipo de sistema operacional.

A instrução assembly rdtsc evita o risco de as medidas de tempo serem afetadas pelo sistema operacional.

A aplicação benchmark foi executada em máquinas pertencentes a dois clusters de computadores localizados no IE, Instituto de Ciências Exatas da Universidade de Brasília.

As características dos dois clusters estão relacionada.

Características dos clusters utilizados durante as execuções.

Cada uma das oito máquinas do primeiro cluster possui dois processadores.

A geometria das malhas escolhidas para execução da aplicação é o paralelepípedo mostrado na uma malha de elementos finitos correspondente com as condições de contorno aplicadas é apresentada.

Geometria tridimensional utilizada para execução do código, onde O ensaio consistiu em restringir uma das faces do paralelepípedo e aplicar uma carga concentrada de 500 N, na direção negativa do eixo y, em um nó localizado em um dos vértices, de forma a provocar uma flexão.

As condições de contorno aplicadas estão indicadas.

Geometria com as condições de contorno aplicadas.

As principais características das três malhas de elementos finitos utilizadas para análise de desempenho são apresentadas.

Os valores aqui exibidos se referem à execução do código da aplicação utilizando a biblioteca de comunicação MPI (mpich-1 2 6), para uma tolerância de convergência do método dos gradientes conjugados de 1 x 10-6 Todos os valores de tempos de execução apresentados resultam da média dos valores obtidos a partir de todas as tarefas em execução para que possa haver uma maior precisão destes.

Inicialmente, foram medidos os tempos de execução expressos em milisegundos para três etapas do programa, particionamento da malha, montagem das matrizes de elementos e solução do sistema de equações pelo método dos gradientes conjugados.

Nesta execução, cada tarefa foi alocada a um nó distinto, nos clusters 1 e 2.

Estas medidas, juntamente com a medida de tempo total de execução são apresentadas.

Como pode ser observado pelos resultados obtidos, os tempos de particionamento tendem a aumentar com o aumento do número de tarefas.

Isto ocorre porque aumentando o número de tarefas, o número de partições aumenta, fazendo com que o aplicativo Metis despenda uma maior quantidade de tempo realizando a partição da malha computacional em subdomínios.

Este tempo também tende a crescer com o aumento do tamanho da malha utilizada durante a execução, pois quanto maior a malha maior o número de elementos que terão que ser distribuídos entre as tarefas.

Os valores medidos do tempo de montagem da matriz decaem com o aumento do número de tarefas, pois fica atribuída a cada tarefa uma menor quantidade de graus de liberdade e, consequentemente, um menor número de equações para serem resolvidas.

O tempo de montagem tende a aumentar com o aumento do tamanho da malha devido ao fato de aumentarem os números de graus de liberdade atribuídos às tarefas.

O tempo de solução dos gradientes conjugados é o tempo gasto na solução do sistema de equações.

É nesta etapa onde ocorrem as comunicações ponto-a-ponto (send e receive) e as comunicações globais (allreduce).

É possível observar que o tempo solução dos gradientes conjugados tem um maior decréscimo quando o número de tarefas passa de 1 para 2.

Quando o número de tarefas passa de 2 para 4 o decréscimo é menor para todas as três malhas e para os dois clusters.

Tal fato ocorre porque com o aumento do número de tarefas, aumentam os graus de liberdade compartilhados entre as tarefas, aumentando, consequentemente, também as comunicações.

O tempo total para todas as malhas e em ambos os clusters diminuiu com o aumento do número de tarefas.

Cada nó do Cluster 1 é um multiprocessador simétrico (SMP), conforme já foi descrito na Seção 5 2 Foram executadas 1, 2, 4 e 8 tarefas em um único nó dual processado (SMP) e também foram executadas 1, 2, 4 e 8 tarefas neste mesmo nó monoprocessado, no Cluster 1.

As medidas obtidas destas execuções, para as etapas de particionamento da malha, montagem das matrizes de elementos e solução do método dos gradientes conjugados.

Em algumas execuções, os valores de tempo de montagem da matriz de rigidez são superiores quando executados no nó dual processado (SMP).

Isso é explicado pelo fato de que, durante a etapa de montagem da matriz, o acesso à memória compartilhada no modo SMP acaba se tornando um gargalo, fazendo com que seja gasto mais tempo para a execução desta etapa.

Para a simulação utilizando a Malha 1 e o nó dual processado, o menor valor do tempo de solução do MGC e do tempo total ocorre com a execução de 4 tarefas, com 8 tarefas o tempo já aumenta quase três vezes.

Com o nó monoprocessado, o tempo de solução do MGC já começa a aumentar com 4 tarefas em execução e o tempo total já aumenta a partir de 2 tarefas em execução, mostrando que o ideal neste caso, é que se execute apenas uma tarefa em cada nó monoprocessado.

Para a Malha 2, o decréscimo de tempo vai se tornando menos significativo à medida que o número de tarefas vai aumentando, principalmente quando passa de 4 para 8 tarefas em execução.

O tempo de execução tende a aumentar quando o número de tarefas ultrapassa 8 tarefas.

O mesmo comportamento pode ser observado para a Malha 3.

Conforme já mostrado, a Malha 3 possui um maior número de nós e um maior número de elementos do que a Malha 2, e esta possui um maior número de nós e um maior número de elementos do que a Malha 1.

Este maior número de nós resulta em um maior número de equações a serem solucionadas.

Com isto, a Malha 3 é beneficiada pela distribuição do domínio em um maior número de tarefas, já que a redução do tempo gasto na solução das equações vai compensar o tempo gasto na comunicação entre as tarefas.

Por outro lado, a Malha 1 já não apresenta um bom desempenho quando o número de tarefas ultrapassa 4 tarefas, pois, por possuir um número menor de equações, o custo de comunicação terá uma maior influência no tempo total de execução, mesmo que a comunicação esteja ocorrendo na mesma máquina.

Para um maior detalhamento do comportamento da execução do programa dentro de um nó, apresenta, em ordem cronológica, as etapas de particionamento, montagem e os primeiros eventos de send e receive entre duas tarefas em execução em um mesmo nó, sendo este nó dual processado, node8 do Cluster 1.

Se refere à execução de uma tarefa em um nó monoprocessado.

Foram colocadas instruções assembly rdtsc dentro do código para capturar os times stamps dos eventos ocorridos.

A malha utilizada nesta simulação foi a Malha 1.

Ordem cronológica para execução de duas tarefas no node8 (SMP).

Ordem cronológica para execução de duas tarefas no node8 (monoprocessado).

É possível verificar uma justificativa para o fato de os tempos totais de execução são sempre maiores para o caso de os nodos monoprocessados quando comparados aos nodos SMP, visto que as duas tarefas executam concorrentemente quando na execução no nó dual processado.

Apresenta a relação entre o número de equações e o número de iterações realizadas durante a solução do MGC para as três malhas testadas.

É possível observar que o número de iterações aumenta com o aumento do número de equações.

Número de iterações do MGC para as três malhas.

Conforme pode ser observado através das medidas já exibidas até aqui, a solução das equações pelo MGC é a etapa da aplicação que mais consome tempo de execução, consumindo, em média, cerca de 90% do tempo total da aplicação.

Por esse motivo, esta etapa do programa foi medida mais detalhadamente, medindo, principalmente, os tempos gastos com comunicações ocorridas dentro da mesma.

Nesta execução, cada tarefa foi alocada a um nó distinto, nos clusters 1 e 2, sendo os nós do Cluster 1 multiprocessadores simétricos (SMP).

As medidas obtidas com o custo de comunicação, juntamente com o custo da etapa de solução do MGC e o percentual do tempo de solução do MGC ao qual o tempo de comunicação corresponde.

Custo de comunicação para a Malha 1 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 1 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Custo de comunicação para a Malha 1 no Cluster 2, sendo cada tarefa alocada a um nó distinto.

Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 1 no Cluster 2, sendo cada tarefa alocada a um nó distinto.

Custo de comunicação para a Malha 2 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 2 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Custo de comunicação para a Malha 2 no Cluster 2, sendo cada tarefa alocada a Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 2 no Cluster 2, sendo cada tarefa alocada a um nó distinto.

Custo de comunicação para a Malha 3 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 3 no Cluster 1, sendo cada tarefa alocada a um nó (SMP) distinto.

Custo de comunicação para a Malha 3 no Cluster 2, sendo cada tarefa alocada a um nó distinto.

Percentual do custo de comunicação em relação ao tempo de solução do MGC da Malha 3 no Cluster 2, sendo cada tarefa alocada a um nó distinto.

Para as execuções das três malhas nos dois clusters, o comportamento foi o mesmo, houve um acréscimo do tempo de comunicação com o aumento do número de tarefas, ou seja, o percentual do custo de comunicação em relação ao tempo de solução do Método dos Gradientes Conjugados aumentou à medida que mais tarefas foram executadas.

Para a execução em ambos os clusters, utilizando a Malha 1, o custo de comunicação representa um percentual elevado em relação ao tempo de solução das equações pelo MGC.

Este percentual elevado se deve ao fato desta malha não possuir um número muito elevado de equações a serem resolvidas, fazendo com que o custo de comunicação tenha uma influência significativa no tempo de solução do MGC, ou seja, para a simulação desta malha, a comunicação aparece como um gargalo.

Para as outras duas malhas, Malha 2 e Malha 3, o tempo de comunicação já não representa um percentual tão significativo em relação ao tempo de solução das equações pelo MGC.

Isto porque estas duas malhas possuem um número maior de equações a serem resolvidas, o que faz com que o custo de comunicação não seja representativo.

Uma outra verificação interessante ao comparar as execuções de uma mesma malha nos dois clusters é o fato de os valores percentuais do custo de comunicação serem sempre menores no Cluster 2 do que no Cluster 1.

Este comportamento pode ser explicado pelo menor poder computacional do Cluster 2 (nós com processador de menor freqüência e memória RAM com menor capacidade de armazenamento) em relação ao Cluster 1, o que faz com que o maior tempo gasto na etapa de solução do MGC seja na solução das equações, sendo o custo de comunicação pouco significativo no Cluster 2.

Já no Cluster 1, a comunicação para alguns casos pode ser considerada um gargalo, já que este cluster tem um maior poder computacional e resolve mais rapidamente as equações.

Visualizações gráficas da relação entre a comunicação e o número de tarefas são apresentadas, para Clusters 1 e 2.

Nesta execução, mais de uma tarefa foi alocada ao node8 do Cluster 1 e a malha utilizada foi a Malha 2.

Exibem as medições de tempos gastos com comunicações ponto a ponto (send e receive).

Os tempos de comunicação são acrescidos com o aumento do número de tarefas, mesmo com as tarefas sendo executadas em uma única máquina.

Uma observação interessante é o fato de o tempo de receive ser sempre maior do que o de send.

Tal fato ocorre porque o receive fica sempre um tempo a mais esperando pelo send correspondente.

A Tarefa 0 ficou em execução até iniciar o receive.

Como não havia nenhum send enviado pela Tarefa 1, a Tarefa 0 fica parada esperando e a Tarefa 1 inicia sua execução realizando o seu send.

Só depois de a Tarefa 1 ter enviado o send é que a Tarefa 0 poderá concluir o seu receive.

Através dos resultados já apresentados e analisados, pode-se perceber que os valores de tempos de execução no Cluster 1 são sempre inferiores aos valores de tempos de execução no Cluster 2, como era de se esperar pelas características das máquinas constituintes de cada um dos dois clusters.

Exibem os valores totais dos tempos obtidos a partir da execução da aplicação para as três malhas numa única máquina de cada um dos dois clusters.

Foram executadas 1, 2, 4 e 8 tarefas em cada uma das máquinas de forma independente.

Como pode ser observado nas duas tabelas, o tempo gasto no Cluster 2 para a execução de 1 tarefa é, em média, 7,7 vezes maior do que o tempo gasto no Cluster 1 para a execução de 1 tarefa.

Para 2 tarefas, o tempo gasto no Cluster 2 é, em média, 12,1 vezes maior do que o tempo gasto no Cluster 1.

Para 4 tarefas, este valor é, em média, 11,7 vezes maior e para 8 tarefas, 9,2 vezes maior, em média.

O decréscimo deste último valor se deve ao fato de que a execução da Malha 1 com 8 tarefas, em ambos os clusters, apresenta uma queda de desempenho devido à grande influência do custo de comunicação, como explicado anteriormente.

Se forem desconsiderados os tempos obtidos para a execução da Malha 1 com 8 tarefas, o tempo gasto no Cluster 2 para a execução com 8 tarefas é, em média, 11,5 vezes maior do que o tempo gasto no Cluster 1, aproximando-se dos valores anteriores.

Para a caracterização de desempenho da aplicação benchmark no ambiente heterogêneo, foram feitas execuções utilizando uma máquina (node8) do Cluster 1 e uma máquina (node00) do Cluster 2 interligadas, formando um cluster heterogêneo.

Variou-se o número de tarefas alocadas a cada máquina.

Apresentam os valores de tempos, em segundos, obtidos das execuções detalhadas acima Valores dos tempos de execução no cluster heterogêneo.

O menor valor obtido para a Malha 1 no cluster heterogêneo foi com a Execução 2 (1 tarefa executando no node00 e 3 tarefas executando no node8) e o maior valor foi com a Execução 11 (7 tarefas executando no node00 e 1 tarefa executando no node8).

De modo geral, para esta malha, os melhores valores obtidos foram com as execuções de 4 tarefas no total, distribuídas entre as duas máquinas do ambiente heterogêneo, o que é explicado pelo tamanho pequeno desta malha, conforme já discutido.

Com o total de 8 tarefas em execução, a simulação desta malha não apresenta um bom desempenho, a não ser com a Execução 3.

Para as malhas 2 e 3, o menor valor obtido foi com a Execução 3 (1 tarefa executando no node00 e 7 tarefas executando no node8) e o maior valor foi com a Execução 1 (1 tarefa executando no node00 e 1 tarefa executando no node8).

O menor valor obtido com a Execução 3 se deve ao fato da menor influência da comunicação com a máquina mais lenta (node00), já que somente uma tarefa foi alocada a esta máquina.

O pior valor obtido com a Execução 1 é justificado pelos tamanhos das malhas 2 e 3, o que faz com que apenas duas tarefas em execução não sejam suficientes para obter um bom tempo de execução, e também é justificado pela influência da comunicação entre as duas máquinas.

Haverá muita comunicação entre as duas tarefas e a máquina mais lenta do ambiente heterogêneo (node00) influencia no custo de comunicação.

Pode-se observar que o tamanho da malha que está sendo simulada influencia nos valores dos tempos de execução tanto para os clusters homogêneos 1 e 2 quanto para o ambiente heterogêneo.

No ambiente heterogêneo, para uma malha que tenha um maior número de equações a serem resolvidas, quanto maior o número de tarefas alocadas à máquina com maior poder de processamento, neste caso o node8 do Cluster 1, melhor o desempenho do cluster heterogêneo.

Este fato se explica por dois motivos.

O primeiro deles é que mesmo havendo custo de comunicação entre tarefas alocadas a um mesmo nó este custo não se apresenta tão relevante para as malhas com um grande número de equações, quando comparado ao custo de comunicação entre o node8 e o node00.

O segundo motivo é o próprio número de tarefas em execução.

Ao dividir o domínio em maior quantidade de subdomínios cada tarefa fica com um menor número de equações para resolver.

No caso das malhas 2 e 3, o melhor desempenho foi alcançado ao alocar 7 vezes mais tarefas para a máquina do Cluster 1 do que para a máquina do Cluster 2, estando de acordo com o valor obtido.

Apresentam os valores das comparações das execuções de duas tarefas em duas máquinas (uma tarefa alocada a cada um das máquinas) nos clusters 1, 2 e no cluster heterogêneo, para as três malhas.

Tempos de execução nos clusters 1 e 2 e no cluster heterogêneo para as malhas 1, 2 e 3.

Comparando as execuções de duas tarefas alocadas a duas máquinas do Cluster 1 e duas tarefas alocadas a duas máquinas do cluster heterogêneo, percebe-se que os tempos apresentam valores superiores quando executados nas máquinas do cluster heterogêneo, ou seja, há uma degradação no desempenho, como esperado.

Isto porque as duas máquinas do Cluster 1 oferecem maior capacidade de processamento em relação a uma das máquinas do cluster heterogêneo.

Assim, não é lucrativo, em termos de desempenho, tornar um cluster heterogêneo com a adição de máquinas mais lentas, pois estas farão com que haja perda de desempenho.

Comparando as execuções de duas tarefas alocadas a duas máquinas do Cluster 2 e duas tarefas alocadas a duas máquinas do cluster heterogêneo, ocorre uma diminuição nos tempos de execução para o cluster heterogêneo, ou seja, uma melhora no desempenho.

Este fato se deve ao ganho no poder de processamento obtido com a adição da máquina do Cluster 2 ao cluster heterogêneo.

A diminuição nos tempos de execução é muito pequena devido ao atraso na comunicação.

O modo como o Metis efetua o particionamento do domínio influencia na quantidade de comunicação a ser executada.

Espera-se que haja um ganho maior de desempenho à medida que mais máquinas do Cluster 1 sejam adicionadas ao cluster heterogêneo.

Conforme será mostrado em seguida, o Metis divide o domínio de maneira que cada subdomínio resultante da partição fique com aproximadamente o mesmo número de elementos e com o mesmo número de graus de liberdade compartilhados.

Dessa forma, todas as tarefas efetuarão aproximadamente a mesma quantidade de comunicação.

Por este motivo, quando somente duas tarefas estão em execução no cluster heterogêneo, haverá muita comunicação entre estas tarefas e a máquina com menor poder computacional vai causar um custo de comunicação alto, degradando o desempenho.

Apresentam as quantidades de elementos e as quantidades de graus de liberdade compartilhados entre tarefas após a etapa de particionamento.

Pode-se perceber que o número de graus compartilhados é aproximadamente o mesmo para cada tarefa.

Comparando os valores é possível verificar o aumento do número de graus de liberdade compartilhados com o aumento do número de tarefas, justificando o aumento da comunicação com o aumento do número de tarefas, conforme mostrado anteriormente.

Ainda, verifica-se a diminuição do número de elementos para cada tarefa com o aumento do número de tarefas.

Para calcular os valores de speedup para as Malhas 1, 2 e 3, foram tomados os valores dos tempos de execução com 1 tarefa de cada uma das máquinas do cluster heterogêno.

Estes valores foram divididos pelos valores dos tempos das Execuções 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 e 11 quando se apresentavam menores do que os valores dos tempos de execução com 1 tarefa.

Este speedup calculado e aqui utilizado é o speedup relativo.

Houve um ganho de desempenho para quase todas as execuções (acima detalhadas) efetuadas no cluster heterogêneo.

Para as Malhas 2 e 3, o maior valor de speedup obtido foi na Execução 3 como esperado, uma vez que esta execução apresentou os menores tempos.

Eficiência obtida nas execuções no cluster heterogêneo Os valores de eficiência obtida com as execuções das Malhas 1, 2 e 3 no cluster heterogêneo são mostrados.

A eficiência é a relação entre o speedup e o número de tarefas utilizadas na execução.

Neste trabalho são apresentados resultados que caracterizaram o desempenho de uma aplicação paralela para simulação do método dos elementos finitos aplicado à elasticidade linear, para a solução de problemas estruturais, que utiliza o método dos gradientes conjugados para a solução do sistema de equações lineares.

Para captar os tempos das medições neste trabalho, foi utilizada a instrução assembly rdtsc, que retorna o contador de time stamp em ciclos de clock.

Isto porque pôde ser observado, através de execuções em três máquinas distintas, que o número de ciclos de clock gastos para a execução da instrução assembly rdtsc é consideravelmente menor quando comparado aos números de ciclos de clock gastos pelas funções rdtsc( ), gettimeofday( ) e MPI_Wtime ( ).

Os valores resultantes das medidas tomadas dentro da aplicação e aqui apresentados foram produzidos por execuções paralelas da aplicação, para simulação de três malhas, em dois clusters homogêneos de PCs e num ambiente heterogêneo, sendo este formado a partir da interligação de máquinas dos clusters homogêneos.

Para uma melhor caracterização de desempenho foram exibidos os valores dos tempos de execução das três principais etapas do programa, particionamento, montagem da matriz e solução do método dos gradientes conjugados e também foram apresentados os valores totais de tempo de execução, os valores de speedup e eficiência.

Foi possível observar que há um ganho de desempenho com a execução paralela do código.

Na maioria das simulações efetuadas o tempo total de execução decresce com o aumento do número de tarefas, mesmo havendo um maior custo de comunicação.

Neste caso a maior distribuição do domínio compensa o tempo de comunicação.

Somente para o caso da simulação com a Malha 1 é que a execução com 8 tarefas apresentou um acréscimo no tempo em relação à execução com 4 tarefas.

Este comportamento demonstrou que o ganho de desempenho obtido com a partição do domínio tende a saturar num determinado número de tarefas e que este número depende do tamanho da malha.

Quando a malha possui um número pequeno de equações a serem solucionadas, o custo de comunicação acaba superando mais rapidamente o ganho obtido com o particionamento.

A etapa de solução do método dos gradientes conjugados foi medida mais detalhadamente para que fosse verificado o custo de comunicação entre as tarefas que compartilham graus de liberdade e foi constatado que, percentualmente, este custo tem maior influência quando a execução ocorre no Cluster 1 do que quando ocorre no Cluster 2.

Esta maior influência pode ser explicada pelo menor poder computacional do Cluster 2 (nós com processador de menor freqüência e memória RAM com menor capacidade de armazenamento) em relação ao Cluster 1, o que faz com que o maior tempo gasto na etapa de solução do MGC seja na solução das equações, sendo o custo de comunicação pouco significativo no Cluster 2.

Já no Cluster 1, a comunicação para alguns casos pôde ser considerada um gargalo, já que este cluster tem um maior poder computacional e resolve mais rapidamente as equações.

Verificou-se que os valores de tempos de execução no Cluster 1 são sempre inferiores aos valores de tempos de execução no Cluster 2, como era de se esperar pelas características das máquinas constituintes de cada um dos dois clusters.

As medidas obtidas com as execuções no ambiente heterogêneo demonstraram um ganho de desempenho quando comparadas às execuções realizadas no Cluster 2.

Ficou evidente que a utilização de clusters heterogêneos é uma alternativa viável, econômica e eficiente para a solução de um problema de elasticidade utilizando o método dos elementos finitos.

Os valores de speedup obtidos confirmam o ganho de desempenho alcançado.

Como sugestões para trabalhos futuros é possível citar a implementação de uma modelagem que permita predizer o desempenho em ambientes heterogêneos, através da utilização de balanceamento de carga, aplicando a mesma metodologia apresentada neste trabalho para um número maior de máquinas no ambiente heterogêneo.

