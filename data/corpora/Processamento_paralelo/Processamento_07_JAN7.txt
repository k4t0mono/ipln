A modelagem avançada da propagação das ondas sísmicas, ou seja, a geração de sismogramas sintéticos, é uma ferramenta muito útil na sismologia.

Ao interpretar as seções em tempo (sismogramas), dados sintéticos podem ser comparados a dados de campo para determinar onde e como o modelo geológico utilizado tem de ser modificado para se obter uma boa concordância entre dados sintéticos e dados observados.

A modelagem avançada pode também fornecer uma visão útil da propagação da onda em meios complexos.

Os métodos das diferenças finitas são as técnicas mais diretas para se efetuar este tipo de modelagem, pois oferecem uma descrição completa do campo de ondas num meio complexo com variações nas propriedades dos materiais.

Entretanto, a maior limitação do método é o grande volume de computação e memória necessárias, causando restrições no tamanho dos modelos realísticos 3 D que podem ser processados, exceto se forem utilizados supercomputadores.

Neste trabalho demonstramos um método de discretização por diferenças finitas para a equação da onda acústica 1 D adaptado à paralelização distribuída.

O modelo é dividido entre dois e três processadores e a equação da onda é resolvida simultaneamente em cada um deles, para suas respectivas partes do modelo.

A comunicação simultânea dos dados de fronteira, entre processadores adjacentes, garante a continuidade do campo de ondas através da mesma.

O algoritmo utilizado é geral, ou seja, pode ser aplicado também para outros problemas mais complexos, como para os casos da onda elástica e viscoelástica.

Este algoritmo foi implementado utilizando-se a biblioteca do PVM (Parallel Virtual Machine), e discutimos neste trabalho sua performance baseada em análises relativas de tempos de processamento entre os modelos paralelo (dois e três processadores) e sequencial (somente um processador), associando as medidas de desempenho do método com recursos tecnológicos disponíveis (largura de banda da rede a que estão conectados os PCs, processadores utilizados, etc).

Entretanto, mesmo com pequena largura de banda da rede uma modelagem realística, que requer grande volume de memória computacional, pode ser executada usando este algoritmo, já que se dispõe de dois (ou mais) nós computacionais que agregam as memórias.

Os resultados demonstram a viabilidade de se fazer uma modelagem acústica paralela distribuída, através do método das diferenças finitas, em redes de estações de trabalho (network workstations).

A computação paralela vem se tornando, cada vez mais, uma aliada dos cientistas e engenheiros, que necessitam resolver problemas complexos na área de modelagem e simulação de processos físicos.

Tais problemas apenas poderiam receber uma abordagem computacional adequada em instituições que dispusessem de caríssimos supercomputadores.

A introdução de redes de computadores pessoais comuns, trabalhando em paralelo para resolver um mesmo problema, vem mudando bastante esta realidade nos últimos tempos.

Tais redes são muito mais baratas que os computadores comerciais mais sofisticados, porém são capazes de executar as mesmas tarefas.

Redes de PCs podem ser construídas sem muitas dificuldades pelo próprio usuário, além disto têm a vantagem adicional de possuir um custo operacional e de manutenção muito baixo.

Existe também uma vasta gama de aplicativos de domínio público que auxiliam na administração, gerenciamento e programação destas redes, como é o caso do popular PVM (Paralell Virtual Machine) que permite que uma rede comum e heterogênea de computadores seja usada para solução de problemas complexos.

A introdução da computação paralela nestas redes vem causando uma verdadeira revolução na sísmica de exploração de petróleo, pois este é um método geofísico que gera uma quantidade enorme de dados que necessitam de um grande poder computacional para serem processados.

Devidos aos custos computacionais, antes não era possível extrair toda informação que estes dados poderiam nos fornecer.

Porém as redes de PCs agora abrem a possibilidade de que técnicas mais sofisticadas, como modelagem por solução da equação da onda, migração em profundidade, pré-empilhamento 3D e inversão em larga escala possam ser rotineiramente aplicadas em dados reais.

A tendência é que isto gere uma revolução sem precedentes na qualidade final dos dados sísmicos, tornando a atividade exploratória muito menos arriscada.

Os métodos das diferenças finitas são as técnicas mais diretas para se efetuar uma modelagem sísmica realística em meios complexos e para se obter descrição completa do campo de ondas com variações nas propriedades dos materiais.

Para uma modelagem detalhada e precisa (incluindo ondas de superfície e difrações), os métodos diretos, como as diferenças finitas, são a única possibilidade.

Entretanto, a maior limitação do método, como citado anteriormente, é o grande volume de computação e memória necessárias em malhas finas suficientes para atender às condições mínimas de precisão, estabilidade e dispersão.

Como exemplo, podemos considerar um modelo sísmico típico com as dimensões 3 km x 3 km x 3 km, com velocidades de propagação da onda variando de 1,5 a 4,5 km/s, e comprimento de onda dominante de 60 m (fonte com pico de freqüência de 25 Hz, para velocidade mais lenta do modelo).

Com isso teremos as dimensões do modelo, em termos de comprimentos de onda, iguais a 50 x 50 x 50.

Para uma modelagem acústica em 4 s, utilizando algoritmo com aproximação explícita de 4 a ordem em diferenças finitas e 12 pontos da malha comprimento de onda, precisaremos de uma malha com 600 x 600 x 600 pontos e 7200 passos de tempo.

Isto dá um total de 1,5 x 10 12 pontos.

Se considerarmos que para calcular cada ponto da malha são necessários 25 operações de ponto flutuante, teremos um total de 38 x 10 12 operações de ponto flutuante, o que significa um tempo de 38 x 10 s (mais de 4 dias) para cada fonte 5 rodando numa estação de trabalho de 100 Mflop.

Neste trabalho buscamos entender os princípios da computação paralela e adquirir prática em elaborar programas usando esta técnica.

O objetivo primordial é a paralelização de códigos destinados à modelagem sísmica e elaboração de testes de benchmark, para comparar os resultados do método paralelo com o método seqüencial, comprovando as vantagens da utilização do primeiro.

O modelo utilizado primeiramente foi da propagação da onda acústica 1 D num meio homogêneo como passo inicial para execução em problemas mais complexos, em que foram elaborados o algoritmo seqüencial e o algoritmo paralelo, para uma arquitetura de dois e três PC's na qual cada CPU ficava responsável por uma metade do modelo e sincronizavam dados adjacentes entre si.

A metodologia aplicada está descrita adiante, bem como os resultados obtidos.

Uma vez verificada a aplicabilidade do método de paralelização se poderá, posteriormente, utilizar o mesmo estudo em modelos com volume de dados muito maiores, mais condizentes com modelos reais.

O computador é uma das principais ferramentas do engenheiro na solução de problemas do dia a dia.

A facilidade de se implementar modelos matemáticos no computador usando uma linguagem de programação de alto nível tem levado os engenheiros a estudar problemas cada vez mais complexos.

Nem sempre se conhece um algoritmo que seja "eficiente" para todas as instâncias de um certo problema.

A "eficiência" de um algoritmo geralmente é medida pelo seu comportamento assintótico relativo ao tamanho do problema.

Alguns algoritmos demandam muito tempo e usam muitos recursos computacionais para chegar em um resultado.

Se um algoritmo melhor não é conhecido ou se o algoritmo é implementado por um programa comercial que foi adquirido, deve-se recorrer a outros métodos para melhorar o desempenho.

Um desses métodos é a computação paralela.

Computadores paralelos estão tendo uma importância crescente na execução de algoritmos que exigem computação intensiva.

O mesmo pode ser dito dos sistemas distribuídos que nada mais são que computadores ligados em rede e utilizados como máquinas paralelas virtuais.

A motivação principal para a utilização de sistemas formados por vários processadores é o baixo custo relativo de processadores derivados de microcomputadores (PC's) ou estações de trabalho quando comparados com os custos de mainframes tradicionais.

As principais dificuldades normalmente residem nas necessidades de hardware de comunicações e de software para a distribuição de tarefas.

Vencer essas dificuldades é essencial para o uso coordenado de multicomputadores como se fossem um computador único de capacidade potenciada.

A idéia de se dividir tarefas de programas por vários processadores é antiga, mas só recentemente vem se tornando viável devido ao rápido avanço de hardware e software.

As máquinas evoluíram muito em velocidade e com o aparecimento de máquinas com vários processadores, a velocidade de comunicação vem apresentando uma grande evolução permitindo que estes processadores troquem informações com rapidez, e os programas que possibilitam esta comunicação vêm mostrando grande aumento de eficiência.

As primeiras tentativas de se acelerar um processo usando computação paralela consistiam na divisão da solução do sistema em partes e paralelização dos cálculos.

Os multiprocessadores, ou computadores de memória compartilhada MIMD, são talvez as mais bem conhecidas arquiteturas de computadores paralelos.

O termo MIMD (Multiple Instruction Multiple Data) significa que cada processador executa instruções separadas em seus próprios dados, e memória compartilhada denota que todos os processadores compartilham o acesso a uma memória comum, geralmente muito grande.

Os computadores de memória distribuída MIMD compõem outra importante classe de sistemas paralelos, na qual a memória é distribuída entre os processadores, ao invés de estar localizada numa central.

Cada nó executa seu próprio programa, que pode acessar a memória local e enviar e receber mensagens dos outros nós, para que haja comunicação entre os nós.

Mostram um esquema comparativo entre os sistemas de memória compartilhada e memória distribuída.
Arquitetura de memória distribuída.

Entretanto, esse tipo de arquitetura exige uma eficiência muito grande nos códigos e uma velocidade de comunicação entre os processadores muito alta o que demanda um alto custo de investimento em máquinas paralelas.

Uma classe mais especializada de arquitetura de memória distribuída é a SIMD (Single Instruction Multiple Data), na qual todos os processadores executam as mesmas instruções em diferentes partes do modelo.

Esta arquitetura é mais adequada para problemas com alto grau de regularidade.

Uma outra linha possível e com custos bem mais baixos é utilizar redes existentes de estações de trabalho e dividir o processo em tarefas maiores que não demandam comunicação com tão alta velocidade.

Esse procedimento é chamado de computação distribuída, paralelização externa ou paralelização de dados.

Além das vantagens de portabilidade (devido ao alto grau de padronização nos sistemas Unix, que permite à computação distribuída trabalhar em uma rede heterogênea) e escalabilidade de softwares (novos recursos tecnológicos que são disponibilizados melhoram a performance da aplicação) para este tipo de sistema, a maior delas é o baixo custo.

A grande desvantagem é a menor velocidade de comunicação (devido às redes que interligam as estações) e, portanto uma menor eficiência da paralelização.

Entretanto, isso pode ser compensado por códigos mais simples e eficientes e pelo fato de que em alguns casos o tempo de cada processo é grande em comparação com o tempo de comunicação.

Dentre os pacotes de comunicação disponíveis para o desenvolvimento deste trabalho, foi selecionado o PVM (Parallel Virtual Machine).

Este sistema foi desenvolvido no ORNL (Oak Ridge National Laboratory), a partir de 1989 e permite que uma rede heterogênea de computadores funcione como uma única máquina virtual com processadores e memórias distribuídas.

O PVM compõe-se basicamente de  processos daemon que residem em todos os computadores configurados pelo usuário para formar a máquina paralela virtual e  uma biblioteca de rotinas desenvolvidas para a transferência de mensagem, lançamento de processos, coordenação de tarefas e detecção de erros.

No presente trabalho foi utilizada a Versão-311 do PVM.

As grandes vantagens do PVM são que, é um software de domínio público, tem grande aceitação e é utilizado por um grande número de usuários o que possibilita um desenvolvimento mais rápido, é de fácil instalação e utilização, e  pode ser instalado numa rede heterogênea incluindo computadores paralelos convencionais, estações de trabalho, microprocessadores, mainframes.

O PVM é baseado em um sistema de comunicações conhecido como troca de mensagens que é o sistema normalmente usado em máquinas com memória distribuída como é o caso de uma rede de estações.

O conjunto de rotinas disponível para realizar a comunicação e outras tarefas está disponível para as linguagens FORTRAN e C.

Estas duas linguagens passam a poder suportar operações de programação concorrente que são necessárias para a paralelização dos programas.

Neste trabalho foi utilizada a linguagem de programação C++, derivada da linguagem C, devido ao conhecimento prévio satisfatório de minha parte.

Mostra um diagrama exemplar do modelo computacional do PVM.
Exemplo de modelo computacional do PVM.

Outra grande vantagem do PVM é a portabilidade de programas uma vez que as mesmas versões são utilizadas independente do hardware sobre o qual a máquina virtual é construída.

A tradução para as primitivas específicas de cada máquina é feita automaticamente na implantação do próprio PVM e estas operações são transparentes ao programador, do qual só se requer a familiarização com as extensões correspondentes das linguagens C ou FORTRAN.

Mostra uma visão da arquitetura do sistema PVM, enfatizando a heterogeneidade de plataformas computacionais.
Exemplo de arquitetura do sistema PVM.

A programação que utiliza as rotinas do PVM pode ser feita através dos modelos Mestre/Escravo ou SPMD.

No primeiro caso, existe um código referente a um programa mestre que pode executar programas escravos em máquinas diferentes e com códigos diferentes.

No segundo caso, existe um único código e a paralelização é feita internamente através de comandos em FORTRAN ou C.

No presente trabalho, o modelo Mestre/Escravo foi utilizado.

Da mesma forma que ocorre com computadores paralelos convencionais, com o PVM os programas aplicativos devem ser decompostos em subtarefas com um nível de granularidade relativamente grande, ou seja, as subtarefas devem requerer uma quantidade de cálculos relativamente elevada em relação ao esforço gasto nas comunicações entre subtarefas.

No caso deste trabalho, as tarefas paralelizadas são partes do processamento de dados sísmicos, que possuem grande granularidade e, por isso, esse é um problema apropriado para este tipo de solução.

Tais aplicativos enxergam o sistema PVM como um recurso de computação paralela geral como se fosse então uma máquina paralela virtual.

As máquinas ligadas em rede formam um conjunto que pode ser variado dinamicamente, dependendo das tarefas a serem realizadas.

Problemas que levem à falha de algum de seus membros podem ser resolvidos com a inclusão de novos membros ou com a distribuição da tarefa não realizada para um membro já existente.

Isto torna o código mais robusto, mais tolerante a falhas.

Analogamente ao que ocorre com os computadores paralelos convencionais, para o usuário, tudo se passa de maneira transparente, sem a necessidade de conhecer os mecanismos do sistema computacional sobre o qual o PVM foi implantado.

Isto facilita a portabilidade, o que é essencial em fases mais avançadas do desenvolvimento de programas, com a migração de programas para outros ambientes e também possibilita a utilização dos programas por usuários não familiarizados com o próprio PVM.

Um problema básico em sismologia e em muitas outras aplicações é a determinação do comportamento de meios não homogêneos (acústicos ou elásticos) em virtude da propagação de ondas mecânicas provindas de uma fonte de impulso.

O problema que trabalhamos aqui consiste na aplicação da computação paralela na modelagem sísmica utilizando para isso um método de aproximação em diferenças finitas.

A seguir descreveremos como foi feita a modelagem deste comportamento sísmico para o caso da onda acústica unidimensional através de um meio homogêneo (uma corda, de comprimento L) como passo inicial para execução em problemas mais complexos (meios heterogêneos, inconformidades, etc).

É importante salientar que, em se tratando de um modelo 1 D, cuja equação da onda tem solução algébrica relativamente simples, poder-se-ia efetuar a definição do campo de ondas de maneira mais direta, através da solução exata da equação da onda 1 D em meio acústico.

Uma vez verificada a aplicabilidade do método de paralelização se poderá, posteriormente, utilizar o mesmo estudo em modelos com volume de dados muito maiores, mais condizentes com modelos reais.

Tomando a Equação da Onda Acústica unidimensional.

Onde P=f(x,t) é a pressão, c é a velocidade da onda no meio (constante ou de variação desprezível), x é a coordenada do plano cartesiano (representando uma das três dimensões) e t é o tempo.

Neste trabalho as condições iniciais são, onde L é o comprimento da corda, que representa o meio de propagação da onda acústica, e é um parâmetro que depende do comprimento da corda, cujo valor tem grande influência na forma do pulso.

Inicialmente foi sugerido o valor de =10/L, porém2 observei que este oferecia um pulso cuja forma era inadequada, pois assim o mesmo teria uma duração alta, se comparado com o comprimento utilizado, de 10 m.

Além disto, as extremidades da corda estariam em desacordo com as condições de contorno do problema, que serão descritas a seguir.

Levando em consideração estes aspectos, fiz a devida alteração para que se obtivesse um pulso com forma mais aceitável, chegando a =100/L.

Mostra com clareza o efeito deste parâmetro sobre a forma do pulso.

Influência do parâmetro na forma do pulso.

Neste modelo, foi assumido que as extremidades da corda são presas.

Com isso, as condições de contorno para a equação utilizada são, P(0,t)=P(L,t)=0.

Para o caso de as extremidades serem livres as condições de contorno seriam diferentes, tais como Px(0,t)= Px(L,t)=0, porém não serão aplicadas neste trabalho.

Com isso, a função que usamos como condição inicial representa um pulso deslocado da origem pela metade do comprimento L da corda, no início da propagação da onda através do meio.

Pulso representando a configuração da corda no início do deslocamento da onda.

IV11) Discretização do modelo O modelo (a corda) foi dividido em N pontos e a distância entre dois pontos chamada de x.

Assim, temos que x = ix, onde i = 0,1,2,3,N-1.

Considerando que t é um incremento no tempo, então t = jt, onde j = 1,2,3, Logo, P(x,t) = P(ix, jt) = Pi,j.

Dada esta discretização, podemos seguir para uma aproximação da solução da equação da onda acústica unidimensional em um esquema de diferenças finitas.

IV12) Solução numérica da equação da onda acústica Vamos considerar uma aproximação de segunda ordem em diferenças finitas para a segunda derivada espacial e para a segunda derivada temporal na equação da onda.

Com isso temos que as derivadas contínuas de segunda ordem encontradas na Equação 41 podem ser aproximadas numericamente, considerando-se o erro de truncamento neste tipo de aproximação, da seguinte maneira.
Substituindo estes operadores na Equação 41 e efetuando as etapas necessárias de manipulação dos termos, obtemos uma fórmula explícita para os valores do campo de ondas no passo de tempo j+1, tal que onde Pi,j é o valor da pressão no tempo t= jt na posição x= ix, e que é o fator de multiplicação presente na Equação 45 que tem suma importância no que se refere à convergência da aproximação numérica para a solução real do problema.

Com isso, temos uma aproximação de segunda ordem da solução da equação da onda unidimensional em diferenças finitas.

Há muitas questões que envolvem a escolha dos parâmetros na etapa de discretização.

A primeira delas diz respeito a condições que devem ser obedecidas para manter o modelo numericamente estável (condição de estabilidade), ou seja onde µ é uma constante que depende da ordem utilizada no método, que neste caso será µ= 0,5 (segunda ordem).

Esta expressão é conhecida como Condição de Courant e significa que a razão t/x deve ser pequena, ou melhor, determina o incremento de tempo mais largo que pode ser usado para manter a estabiliadade.

Porém a condição de estabilidade apesar de necessária, não é suficiente para a convergência da aproximação numérica para a solução real.

Para se garantir a convergência deve-se observar a condição de consistência onde Er representa o erro de truncamento cometido na aproximação de segunda ordem para a derivada segunda na equação da onda.

A segunda questão envolvendo a escolha dos parâmetros de discretização é a dispersão numérica, visto que os esquemas de solução da equação da onda por diferenças finitas apresentam esta característica.

Define-se dispersão como a variação da velocidade de fase dos componentes espectrais de uma onda durante a sua propagação ou, por conveniência, a variação da constante de propagação k (também conhecida como o número de onda) com a freqüência angular.

Significa que cada componente de freqüência do sinal tende a viajar com uma velocidade diferente, sendo necessário o ajuste da largura da malha.

A maneira de se resolver este problema é utilizar comprimentos de onda de magnitude maior do que a largura da malha.

Para este trabalho foi considerado que 10 x, ou seja, o menor comprimento de onda envolvido no esquema computacional deve ser ao menos igual a dez vezes a largura da malha considerada, para uma discretização de segunda ordem.

Isto mantém a dispersão numérica em valores suficientemente baixos.

Por fim, a precisão e eficiência do presente método numérico, onde fontes de erro surgem devido à substituição das derivadas contínuas por operadores de diferenças finitas, são diretamente dependentes da amostragem temporal e espacial.

Isto refletirá nas aplicações geofísicas típicas.

Este capítulo contém os detalhes da formulação do algoritmo seqüencial e do algoritmo paralelo, este último consistindo de duas etapas, a decomposição do modelo e a comunicação entre processadores.

Esta metodologia pode ser aplicada para qualquer problema que envolva diferenças finitas em um ambiente paralelo, ou melhor, qualquer problema que envolva decomposição no domínio do espaço com o objetivo da paralelização.

Esses algoritmos foram construídos em linguagem de programação C++.

Aqui mostraremos o algoritmo seqüencial utilizado para extrapolação do campo de ondas.

Inicialmente propus que se utilizassem matrizes de dados para decomposição de todo modelo, onde as linhas representariam os passos de tempo correspondentes e as colunas representariam cada ponto discretizado da corda.

Assim, cada linha da matriz seria atualizada a cada loop efetuado pelo processador, representando a nova situação do campo de ondas na corda.

Porém, esta metodologia iria requerer um volume de dados e, conseqüentemente, de memória muito grande.

Uma outra metodologia consistia na utilização de vetores de dados para representar o campo de ondas.

Cada vetor representaria o perfil do campo de ondas num determinado passo de tempo.

A princípio se utilizariam 3 vetores em que a cada tarefa realizada pelo processador (cálculo do campo de ondas para um passo de tempo consecutivo) se efetuaria um loop para atualização dos vetores.

Molécula computacional para algoritmo com 3 vetores de dados.

Apesar de melhor do que a utilização de matrizes esta metodologia apresentava o problema da necessidade do loop após cada tarefa realizada, como citado e mostrado acima.

Para se otimizar o algoritmo foi, então, elaborado um segundo que se processaria com 2 vetores de dados, de forma que não seria necessário efetuar atualização dos mesmos, uma vez que a cada tarefa (calcular o campo de ondas para um passo de tempo consecutivo) os dados dos vetores seriam substituídos automaticamente.

A molécula computacional para esta metodologia é mostrada abaixo.

Molécula computacional para algoritmo com 2 vetores de dados.

O algoritmo para metodologia de 2 vetores de dados ficou assim.
Com isso, além de não ser necessário efetuar loop, o número de passos de tempo foi reduzido pela metade.

Fazer a decomposição do modelo físico utilizado (corda) significa associar a cada processador um conjunto de pontos da malha, ou subdomínio, para o qual será resolvida a equação da onda simultaneamente com os outros subdomínios.

A regularidade inerente da aplicação de diferenças finitas facilita essa decomposição, mais evidente ainda em esquemas explícitos (como o deste trabalho).

Para o nosso caso, propagação da onda unidimensional, a corda será decomposta em subdomínios, associando a cada um, uma tarefa.

Entre esses subdomínios há uma fronteira de pontos que tem suma importância durante o processamento dos dados.

Decomposição da corda em dois subdomínios de mesmo tamanho.

Cada um será atualizado pela tarefa a que está associado em um nó computacional (CPU) distinto.

Para o caso da onda 2 D e 3 D (mais próximo de um caso real) têm-se diferentes tipos de decomposições dos modelos, oferecendo diferentes condições de computação e comunicação entre os subdomínios.

Por exemplo, para um modelo 3 D podemos ter as decomposições em uma dimensão ou em duas dimensões.

A primeira apresenta uma área de superfície grande em relação ao seu volume (o que interfere na razão computação/comunicação requerida), para cada subdomínio, diferentemente da segunda.

Dependendo de alguns fatores, tais como o modo de comunicação entre hardwares, cada tipo de decomposição terá preferência em ser aplicada.


Em estudos posteriores poderão ser observadas estas considerações.
Dois diferentes tipos de decomposição para uma malha 3 D.

Para o tipo de decomposição aplicado cada tarefa individual, executada em uma CPU distinta, aproxima o valor do campo de ondas para cada ponto da malha em seu subdomínio, para o passo de tempo j+1, baseada nos valores de cada ponto nos passos de tempo j e j-1 e em seus pontos adjacentes vizinhos.

Os subdomínios podem ser atualizados simultaneamente, exceto os seus pontos de borda.

Neste caso o valor do campo de ondas na região de fronteira de um subdomínio tem de ser replicado para o seu vizinho, a fim de definir totalmente o campo de ondas do modelo físico.

Nisso se baseia o algoritmo paralelo, onde, a cada passo de tempo as fronteiras dos dois subdomínios que utilizamos trocam informações entre si.

Se utilizarmos vários subdomínios (mais que dois), alguns terão de trocar dados entre dois subdomínios adjacentes.

A arquitetura aqui utilizada consiste em diferentes processadores que executam as mesmas tarefas para seus respectivos subdomínios.

Entre os processadores há uma relação mestre/escravo, em que uma CPU "coordena" e distribui os subdomínios para as demais.

Por isso, foram elaborados dois algoritmos, um para a CPU mestre (distribui os subdomínios, recebe e armazena os dados processados) e outro para os escravos (executam as tarefas sobre seus respectivos subdomínios, sincronizam dados entre si e enviam os dados de saída para o mestre).

Considerando as informações contidas acima podemos apresentar os pseudocódigos do mestre e dos escravos.

Como pode ser observado nos pseudocódigos descritos acima, o programa mestre promove o cálculo do tempo desde o envio das informações pelo mestre até o recebimento dos dados, passando pelo processamento dos escravos.

Este tempo é utilizado para comparação do tempo de processamento do programa seqüencial.

Neste trabalho foi desenvolvida uma paralelização na qual o problema proposto manteve o mesmo tamanho todo o tempo, ou seja, o aumento do número de CPU's trabalhando em paralelo faz com que o volume de computação para cada uma delas decresça.

Se, por exemplo, tivermos uma malha com 30000 pontos para o processamento seqüencial (1 CPU), numa paralelização com 2 CPU's teremos 15000 pontos para cada CPU, e 10000 para cada uma no caso de paralelização com 3 CPU's.

Esta configuração deixa a desejar no aspecto da avaliação do desempenho da comunicação entre CPU's, pois a razão computação/comunicação não se mantém constante.

Foram efetuadas análises de velocidades para 1 CPU (seqüencial) e paralelização utilizando 2 CPU's e outra com 3 CPU's.

No modelo 1 D, dividimos a corda em 200 pontos e, no caso da paralelização com 2 CPU's, cada processador ficava responsável por uma metade (100 pontos) da corda.

Os parâmetros utilizados foram mantidos constantes durante todo o processo, tais como velocidade de propagação da onda de 100 m/s, incremento de tempo de 0,4 ms, e 0,05 m de incremento espacial.

Com isso o comprimento da corda era de 10 m.

Foi feita uma simulação da propagação da onda na corda durante o tempo de 0,2 s (500 passos de tempo).

Mostra a configuração do campo de ondas na corda para diferentes tempos de propagação, considerando as condições iniciais e de contorno do problema, após o processamento seqüencial e paralelo.

Campo de ondas na corda após simulação da propagação da onda nos tempos de 0 s, 0,04 s,0,08 s, e 0,1 s, nos gráficos a, b, c e d, respectivamente.

Isso mostra que os gráficos acima obtidos estão de acordo com o esperado para uma propagação da onda unidimensional através de uma corda de extremidades fixas e velocidade de 100 m/s.

Para comparar o desempenho do programa paralelo com o programa seqüencial são necessárias análises de speedup (benchmark) que medem a relação entre os tempos seqüencial e paralelo.

Um speedup próximo do ideal seria obtido se um processo paralelo com n máquinas fosse n vezes mais rápido que o processo seqüencial.

Isto pode não ocorrer na prática devido ao tempo de comunicação entre as máquinas, tempo de espera quando máquinas ou processos têm velocidades diferentes, e  dependência entre os processos, o que possibilita que o processo seqüencial tire proveito de resultados anteriores calculados em seqüência.

Comportamento típico de um speedup, em vermelho, comparado com o comportamento ideal esperado, em azul.

Outra maneira de se medir o desempenho da paralelização é através de um gráfico que mede a economia de tempo obtida pela paralelização do processo.

É interessante observar que este parâmetro tem um objetivo diferente do speedup.

A escolha de um ou outro deve estar baseada na disponibilidade da rede uma vez que o speedup dá a utilização mais próxima da ideal para uma melhor utilização das máquinas enquanto que a economia de tempo deve sempre ser uma curva com inclinação negativa mas o número de máquinas ótimo depende da disponibilidade da rede.

Exemplo de um gráfico de economia de tempo numa paralelização, onde a razão tempo paralelo / tempo seqüencial decresce com o acréscimo do número de máquinas trabalhando em paralelo.

A análise de speedup para a paralelização com 2 e 3 CPU's é mostrada.

Observa-se que a eficiência da paralelização decresce com o aumento do número de máquinas envolvidas.
Speedup obtido numa paralelização com 2 e outra com 3 CPU's, mostrando o comportamento real, em vermelho, comparado com o ideal, tracejado.

Observa-se uma queda da eficiência com o aumento do número de máquinas em paralelo.

Levando em consideração que as simulações efetuadas se deram em uma arquitetura máxima de 3 CPU's em paralelo (devido a fatores logísticos não foi possível se fazer uma paralelização para arquiteturas superiores), o que oferece limitações em termos de conclusões acerca da aplicação da computação paralela em situações reais de processamento.

E de posse dos dados obtidos podemos chegar a algumas ponderações, 9 Segundo mostrado e analisando bibliografias relativas a este trabalho, podemos concluir que o aumento do número de máquinas envolvidas na paralelização do código causa redução na eficiência da paralelização, ao contrário do esperado.

Isto, provavelmente, está relacionado a um maior requerimento de comunicação entre as máquinas, além da redução do volume do subdomínio para cada CPU, quanto maior a paralelização (a razão computação/comunicação diminui), o que afeta sensivelmente o tempo de processamento dos dados.

A qualidade da rede de comunicação entre as máquinas (largura de banda) é um fator de extrema importância na eficiência do método.

Com isso pode-se esperar uma melhor eficiência se a qualidade da rede for melhorada.

Esta simulação para propagação acústica da onda 1 D oferece base para simulações posteriores utilizando modelos 2 D e 3 D (com carga computacional superior) e para propagação elástica da onda (problemas mais complexos).

Os algoritmos aqui demonstrados podem ser facilmente alterados para se adaptarem a essas possíveis novas configurações.

Finalizando, algumas recomendações e observações, 9 Análises posteriores da influência de diferentes geometrias (decomposições) para modelos 2 D e 3 D seriam de grande importância na otimização da metodologia a ser aplicada.

A escolha da ordem de decomposição influencia na razão computação/comunicação e, conseqüentemente, na eficiência da paralelização.

Análises do efeito da ordem de aproximação de diferenças finitas podem gerar importantes conclusões acerca da eficiência da paralelização.

Como o algoritmo paralelo aqui apresentado tratava o modelo físico como de tamanho fixo (volume de dados de cada CPU reduzindo com aumento do número de máquinas em paralelo), seriam interessantes novos estudos para um modelo físico de tamanho ajustável (volume de dados de cada CPU constante independente do número de CPU's em paralelo), podendo-se analisar, principalmente, o efeito da comunicação entre as CPU's na eficiência da paralelização.

Um importante dado pode ser obtido em futuros estudos, o número ótimo de máquinas trabalhando em paralelo, que depende do tipo de arquitetura computacional.

