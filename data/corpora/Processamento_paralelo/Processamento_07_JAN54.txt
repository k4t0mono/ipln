Protocolos de checkpointing são responsáveis pelo armazenamento de estados dos processos de um sistema distribuído em memória estável para tolerar falhas.

Os protocolos síncronos minimais induzem apenas um número minimal de processos a salvarem checkpoints durante uma execução do protocolo bloqueando os processos envolvidos.

Uma versão não-bloqueante desta abordagem garante a minimalidade no número de checkpoints salvos em memória estável com o uso de checkpoints mutáveis, checkpoints que podem ser salvos em memória não-estável.

Porém, a complexidade deste protocolo e o fato de ele tolerar apenas a presença de uma execução de checkpointing a cada instante nos motivou a procurar soluções para estes problemas na teoria desenvolvida para os protocolos quase-síncronos.

A nova abordagem nos permitiu fazer uma revisão de alguns protocolos síncronos bloqueantes existentes na literatura que até então eram considerados minimais.

Nesta mesma linha, obtivemos novos resultados na análise de minimalidade dos protocolos síncronos não-bloqueantes, ao considerarmos a aplicação como um todo e também a existência de execuções concorrentes de checkpointing.

Ao estabelecermos esta ponte entre as abordagens para checkpointing, conseguimos desenvolver dois novos protocolos síncronos não-bloqueantes.

Ambos fazem uso de checkpoints mutáveis, permitem execuções concorrentes de checkpointing e possuem um mecanismo simples de coleta de lixo.

No entanto, o fato de cada um dos protocolos derivar de classes diferentes de protocolos quase-síncronos leva a comportamentos distintos, como evidenciado por resultados de simulação.

Um sistema computacional distribuído é composto por uma coleção de computadores autônomos interligados por uma rede de comunicação e é visto pelos usuários como um unico sistema coerente.

Sistemas distribuídos estão evoluindo e se diversificando com o advento de novas tecnologias como computação móvel, grades e aglomerados computacionais.

Nestes ambientes podem ser executadas aplicações relacionadas a várias areas, dentre as quais podemos citar otimização combinatória, genômica, processamento de imagens, controle aéreo ou pesquisas que derivam suas conclusões de simulações de longa duração.

Estas aplicações podem se beneficiar de melhor desempenho, escalabilidade e compartilhamento transparente de recursos existentes no sistema, porém estão mais suscetíveis a falhas.

Assim, o desafio de fornecer mecanismos de tolerância a falhas nessas aplicações se torna cada dia mais importante.

Na ocorrência de uma falha em um processo, o sistema deve encontrar uma maneira de prosseguir sua execução de forma coerente.

Na recuperação por avanço, a aplicação deve possuir códigos específicos para ser capaz de contornar inconsistências e prosseguir seu processamento.

Este mecanismo é dependente de aplicação e de um conjunto de falhas previstas.

Na recuperação por retrocesso o sistema grava periodicamente o estado dos processos em memória estável e é capaz de retroceder para um estado consistente quando necessário.

Este mecanismo é mais geral, independente de aplicação e ele é o foco do nosso trabalho.

Um estado de um processo salvo em memória estável é chamado de checkpoint um checkpoint global é formado por um checkpoint por processo do sistema.

Como os processos se comunicam via troca de mensagens, um checkpoint global da aplicação só é consistente se, para todo evento de recepção de mensagem foi também anotado o seu envio.

Se os checkpoints dos processos de uma aplicação distribuída forem escolhidos aleatoriamente, haverá o risco de que não se consiga formar um estado consistente.

Em português, ponto de recuperação ou ponto de controle.

Adotamos o termo em inglês por ser mais resumido e amplamente utilizado.

Os protocolos para checkpointing são responsáveis pela seleção de checkpoints e apresentam características muito distintas de acordo com a abordagem utilizada.

Uma dessas características é a facilidade com que a coleta de lixo pode ser realizada, ou seja, o descarte dos checkpoints obsoletos que não serão usados para recuperação devido ao progresso da aplicação.

Os protocolos para checkpointing são classificados como, assíncronos, quase-síncronos e síncronos.

Na abordagem assíncrona, os processos têm autonomia na escolha de seus checkpoints, porém alguns desses checkpoints, chamados de checkpoints inúteis, podem não fazer parte de nenhum checkpoint global consistente.

Além disso, não há garantias de que seja possível formar um checkpoint global consistente a partir dos checkpoints salvos.

Portanto, pode ocorrer o efeito dominó, ou seja, a aplicação pode ser obrigada a retornar ao estado inicial em caso de falha.

Os protocolos assíncronos não utilizam mensagens de controle nem necessitam enviar informações de controle junto com as mensagens da aplicação e devem ter mecanismos separados para construir checkpoints globais consistentes e para a coleta de lixo.

Os protocolos quase-síncronos (ou induzidos por comunicação) propostos na literatura reduzem ou eliminam o número de checkpoints inúteis, induzindo o armazenamento de checkpoints adicionais aos checkpoints do protocolo assíncrono.

Nesta abordagem, os processos salvam seus checkpoints livremente, chamados checkpoints básicos e podem ser induzidos a armazenarem checkpoints adicionais, chamados checkpoints forçados, segundo predicados avaliados sobre informações de controle propagadas via piggybacking pelas próprias mensagens da aplicação.

Posteriormente, checkpoints globais consistentes podem ser formados a partir dos checkpoints selecionados e a coleta de lixo pode ser realizada.

Portanto, três protocolos distintos são necessários, um para a seleção de checkpoints, um para a construção de checkpoints globais consistentes e um para a coleta de lixo.

Há um compromisso entre a autonomia dos processos para a escolha dos checkpoints e as garantias oferecidas para a formação de checkpoints globais consistentes.

Em contraste com as duas classes de protocolos já mencionadas, os protocolos síncronos constroem checkpoints globais consistentes utilizando fases de troca de mensagens de controle que sincronizam processos sinalizando o momento de início e término da execução do protocolo.

O início é determinado pela invocação por algum dos processos, o iniciador, do protocolo.

O término é determinado pela verificação de uma condição que indica que todos os processos envolvidos na execução já armazenaram seus checkpoints.

A execução do protocolo, desde o início até seu término é denominada construção consistente.

Ao final de uma construção consistente, o checkpoint global consistente representado pelos ultimos checkpoints locais é o checkpoint global consistente mais recente, e portanto, em cada processo, a coleta de lixo restringe-se ao descarte do checkpoint anterior a este.

Os primeiros protocolos síncronos propostos na literatura fazem com que todos os processos da aplicação salvem seus checkpoints de forma coordenada para a construção de um checkpoint global consistente.

O alto número de mensagens de controle somado ao alto custo do armazenamento de checkpoints gerado por estes protocolos motivou o desenvolvimento de protocolos que reduzem o número de mensagens de controle e o número de checkpoints salvos durante uma construção consistente.

Chamamos de protocolos minimais os protocolos que determinam o conjunto minimal de processos que devem gravar um checkpoint para garantir a construção de um checkpoint global consistente.

Cao e Singhal demonstraram que todo protocolo minimal precisa ser bloqueante, ou seja, para armazenar um número minimal de checkpoints durante uma construção consistente é necessário que os processos envolvidos suspendam suas atividades da computação sob o ponto de vista da aplicação.

Porém, a suspensão da aplicação reduz o desempenho do sistema.

Na tentativa de se obter um desempenho melhor para a aplicação, os protocolos síncronos não-bloqueantes permitem que todos os processos gravem checkpoints a cada construção consistente sem suspender as atividades da computação.

Cao e Singhal propuseram um novo tipo de checkpoint, chamado de checkpoint mutável, que é facilmente manipulado pois pode ser salvo em memória não-estável.

Os checkpoints mutáveis são armazenados para evitar a formação de checkpoints globais inconsistentes e são transferidos para memória estável apenas quando são necessários para uma construção consistente, garantindo assim a minimalidade no número de checkpoints em memória estável (checkpoints estáveis).

Estes protocolos são baseados em protocolos minimais e são muito complexos, pouco eficientes e permitem apenas uma construção consistente a cada instante de tempo.

Até este momento, os protocolos quase-síncronos e síncronos propostos na literatura foram desenvolvidos e analisados utilizando modelos distintos, apesar do conceito de consistência de um checkpoint global ser unico para os dois modelos (para todo evento dé recepção de mensagem incluído no checkpoint global deve ser também anotado o seu envio).

No modelo quase-síncrono, os protocolos evitam a formação de certas classes de zigzag paths.

As zigzag paths são sequência de mensagens que indicam as condições necessárias e suficientes para que um par de checkpoints possa fazer parte de um mesmo checkpoint global consistente.

A z-dependência é a dependência entre processos em intervalo de checkpoints e indicam se um processo deve salvar um checkpoint no momento da recepção de uma mensagem de requisição de uma construção consistente.

Este trabalho propõe o uso dos conceitos e da teoria existentes para os protocolos quase-síncronos para analisar e desenvolver protocolos síncronos.

Desta forma, obtivemos as seguintes contribuições.

Verificação da relação de continência do conceito de z-dependência proposto para os protocolos síncronos na relação de z-precedência utilizada pelos protocolos quase-síncronos.

A z-precedência é uma outra interpretação do conceito de zigzag paths e foi adotado na maioria das provas descritas nesta tese.

Prova de que protocolos minimais que anotam a recepção de mensagens, mas não os intervalos de origem dessas mensagens, não têm informação suficiente para garantir minimalidade no número de checkpoints.

Mostramos que os protocolos propostos em não são minimais e propomos dois novos protocolos minimais, chamados de VD-minimal para corrigir os problemas encontrados.

Prova da impossibilidade de um protocolo síncrono não-bloqueante garantir um número mínimo de checkpoints estáveis durante toda a execução da aplicação, mesmo na presença de um unico iniciador a cada instante.

Prova da impossibilidade de um protocolo síncrono não-bloqueante salvar um número minimal de checkpoints estáveis na presença de iniciadores concorrentes.

Proposta de dois novos protocolos síncronos não-bloqueantes baseados em protocolos quase-síncronos, RDT-NBS e BCS-NBS.

Estes protocolos foram baseados em classes distintas de protocolos quase-síncronos e obtivemos como resultado protocolos mais simples que os existentes e que permitem iniciadores concorrentes.

Experimento inicial de simulação obtidos com o uso do ChkSim que contrastam o comportamento dos protocolos quase-síncronos FDAS e BCS e suas respectivas versões síncronas não-bloqueantes RDT-NBS e BCS-NBS.

Apresenta o modelo computacional considerado em todos os protocolos descritos neste trabalho.

Neste capítulo são descritas as definições de checkpoint e checkpoint global consistente e os mecanismos existentes para rastrear as dependências entre checkpoints.

Em seguida mostramos que a definição de z-dependência do modelo síncrono está contida na noção de z-precedência utilizada na teoria dos protocolos quase-síncronos.

Descreve em detalhes as classes de protocolos de checkpointing existentes na literatura.

Os protocolos quase-síncronos podem ser classificados de acordo com os conceitos de zigzag path e zigzag cycle, Strictly Z-Path Free (SZPF), Z-Path Free (ZPF), Z-Cycle Free (ZCF), Partially Z-Cycle Free (PZCF), sendo a classe SZPF a mais restritiva e a PZCF a menos restritiva.

Os protocolos síncronos analisados nesta tese garantem a construção de checkpoints globais consistentes reduzindo o número de checkpoints salvos durante uma execução de checkpointing e podem ser bloqueantes ou não-bloqueantes.

Os protocolos minimais são bloqueantes e podem induzir um número minimal de checkpoints enquanto os protocolos não-bloqueantes não suspendem as atividades da computação nos processos porém não garantem a minimalidade no número de checkpoints.

Descreve as características de um protocolo minimal na presença de um unico e de iniciadores concorrentes.

Provamos que a minimalidade no número de checkpoints não pode ser garantida anotando-se apenas a recepção de mensagens.

Encontramos na literatura, duas abordagens na construção de protocolos minimais, broadcast e em níveis.

Propomos um protocolo minimal com a abordagem broadcast que corrige um erro encontrado na literatura.

Em seguida, propomos um protocolo minimal com a abordagem em níveis que utiliza vetores de dependências e permite iniciadores concorrentes.

Descreve as características de um protocolo não-bloqueante que reduz o número de checkpoints durante uma execução na presença de um unico iniciador é de iniciadores concorrentes.

Estes protocolos podem garantir um número minimal de checkpoints em memória estável utilizando checkpoints mutáveis.

Notamos que a minimalidade no número de checkpoints estáveis depende do ponto de execução em que os checkpoints mutáveis são salvos e provamos que não é possível garantir um número mínimo de checkpoints estáveis durante toda a execução da aplicação.

Além disso, provamos que é impossível garantir minimalidade no número de checkpoints estáveis na presença de iniciadores concorrentes.

Neste capítulo, mostramos que é possível desenvolver protocolos não-bloqueantes baseados em protocolos quase-síncronos.

Propomos dois novos protocolos, RDT-NBS baseado no protocolo FDAS da classe RDT e BCS-NBS baseado no protocolo BCS da classe ZCF e apresentamos resultados de simulação para comparar esses protocolos.

Na ocorrência de uma falha é necessário que o sistema estabeleça um estado global recuperável formado por checkpoints pertencentes a cada processo da aplicação distribuída.

No entanto, a troca de mensagens da aplicação dificulta a construção de checkpoints globais consistentes pois causa dependência entre eventos.

Lamport definiu o conceito de precedência causal para a ordenação parcial dos eventos.

Assim, podemos afirmar que um checkpoint global é formado por um checkpoint por processo e é consistente se não existe relação de causalidade entre os checkpoints do conjunto.

Neste capítulo, apresentamos as definições e conceitos utilizados na teoria de checkpointing necessários para a compreensão dos resultados deste estudo.

Inicialmente, apresentamos o modelo computacional adotado por qualquer protocolo proposto nesta tese.

Em seguida, apresentamos a estrutura de um processo e o conceito de precedência causal.

Na Seção 24 descrevemos o conceito zigzag paths e mostramos que o conceito de z-dependência está contido no conceito de z-precedência.

Na sequência, apresentamos o conceito de checkpoints globais consistentes.

Um sistema distribuído é composto por n processos sequenciais e autônomos que executam eventos internos, de envio e de recepção (troca) de mensagens.

A troca de mensagens é o unico mecanismo de comunicação utilizado pelos processos.

Consideramos que a rede dé comunicação é fortemente conexa (nenhum processo é isolado), mas não necessariamente completa (a comunicação entre um par de processos pode se dar por processos intermediários).

Os canais de comunicação são unidirecionais e confiáveis, ou seja, há garantia de entrega de mensagens, mas estas podem sofrer atrasos arbitrários e chegar aos seus destinos fora de ordem.

Em alguns poucos protocolos neste texto é necessária a propriedade FIFO (First-In First-Out) nos canais de comunicação entre pares de processos.

Consideramos que não existem mecanismos para compartilhamento de memória, acesso a um relógio global, sincronização de relógios locais ou conhecimento a respeito das diferenças de velocidade entre os processadores.

A memória estável é suficiente para gravar todos os checkpoints necessários à computação, garantindo a correta recuperação de seu estado em caso de falha.

Os processos podem sofrer falhas do tipo crash nas quais param e perdem o seu estado atual de execução.

Quando um processo falha, algum outro processo deverá detectar a falha e informar os outros processos em um tempo finito.

Assumimos que as falhas dos processos nunca particionam a rede de comunicação.

Uma computação distribuída pode ser representada por um diagrama espaço-tempo.

As linhas do diagrama representam a execução dos processos ao longo do tempo e progridem da esquerda para a direita.

Uma aresta liga o evento de envio ao evento de entrega de uma mensagem.

Diagrama espaço-tempo para uma computação distribuída.

Uma aplicação que utiliza um protocolo de checkpointing deve implementar em cada processo, uma camada responsável pelo armazenamento de checkpoints.

Uma estrutura geral de um processo que permite a implementação de qualquer protocolo de checkpointing abordado nesta tese é apresentada.

A aplicação implementa primitivas de envio e entrega de mensagens para a comunicação entre processos e pode requisitar por salvar o estado do processo de tempos em tempos e/ou após um processamento relevante à execução da computação.

A camada de checkpointing grava os checkpoints após uma requisição da aplicação ou de acordo com predicados de um protocolo de checkpointing.

O sub-sistema de checkpointing intercepta as mensagens enviadas e recebidas pela aplicação podendo inserir informações adicionais as mensagens (informações de controle) ou gerar novas mensagens (mensagens de controle).

A camada de rede é responsável pelo envio e recepção de mensagens por meio dos canais de comunicação.

A execução de um processo p é modelada como uma sequência possivelmente infinita de eventos (e, e), onde e 0 1 representa o ésimo evento executado por p.

Os eventos de um processo podem ser classificados como internos ou de comunicação.

Os Estrutura de um processo.

Eventos internos são as ações executadas espontaneamente pelo processo e os eventos de comunicação são os eventos de envio e entrega de mensagens.

Em um sistema distribuído, nem sempre é possível determinar entre dois eventos, qual ocorreu primeiro.

A verificação de tempo para cada evento por relógios reais não é possível pela dificuldade de sincronizar perfeitamente o tempo preciso dos relógios.

Nesta seção, mostramos como é possível definir a ordenação de eventos em uma aplicação distribuída sem o uso de relógios físicos.

Este conceito é também utilizado para determinar a or-denação de checkpoints que é fundamental para apresentar a noção de estado consistente de um sistema distribuído.

A relação de precedência causal foi proposta por Lamport com o objetivo de definir a ordenação parcial dos eventos em uma aplicação distribuída.

Quando não existe precedência causal entre dois eventos e e e, dizemos que esses eventos são concorrentes (e || e ).

Um evento e não precede causalmente ele mesmo.

A relação de precedência causal entre eventos dos processos pode ser capturada com o uso de relógios lógicos 1(RL), um mecanismo proposto por Lamport que independe do relógio físico dos processos.

Os relógios lógicos indicam quando um evento ocorreu antes de outro na computação distribuída.

Em um modelo de sistema que utiliza relógios lógicos, cada processo possui um contador que atribui um número para os eventos do processo e é incrementado entre quaisquer dois eventos consecutivos.

O número atribuído indica o tempo lógico em que cada evento ocorreu.

Relógio Lógico,Um relógio lógico RL de um processo p é uma função que atribui um valor RL  para todo evento e de p respeitando as seguintes regras.
O cenário ilustra o uso de relógios lógicos implementados por números inteiros.

Todos os processos possuem um relógio lógico, inicialmente igual a zero.

Os relógios lógicos vão sendo incrementados de acordo com as regras.

O mecanismo de relógios lógicos tem uma relação direta com precedência causal, ou seja, para dois eventos e e e, se e e, então RL < RL.

A comparação entre relógios lógicos de dois eventos não implica necessariamente na existência da relação de precedência causal entre esses eventos.

Porém e Para capturar completamente as precedências causais é necessário acrescentar para cada evento, informação sobre os relógios lógicos de outros eventos dos demais processos.

Estas informações são mantidas e propagadas pelos processos por meio de vetores, chamados de vetores de relógios 2 (VR), de tamanho n, onde n é o número de processos do sistema distribuído.

A entrada VR do processo p representa o relógio lógico de p e é incrementada a cada novo evento local.

As demais entradas são atualizadas no momento da recepção de uma mensagem m efetuando-se a operação de máximo para cada entrada do vetor recebido na mensagem e do vetor de p.

Apresenta o uso de vetores de relógios para o mesmo padrão de mensagens.

Ao compararmos os relógios vetoriais de dois eventos e e e, é possível afirmar se e e ou e e ou ainda se e || e.

A relação entre vetores de relógios e precedências causais é dada por, Um checkpoint é um evento interno que armazena o estado do processo e pode ser utilizado como ponto de recuperação na ocorrência de falhas.

Os checkpoints podem ser salvos em memória estável (disco em um servidor) ou não-estável (memória local ou disco local) de acordo com o protocolo de checkpointing e todo checkpoint salvo em memória não-estável pode ser transferido para memória estável em algum momento da computação.

O custo de armazenamento em memória estável é mais alto comparado ao custo de armazenamento em memória não-estável, porém, apenas os checkpoints em memória estável representam pontos recuperáveis pelo processo falho.

Consideramos que todo processo armazena um checkpoint inicial imediatamente antes de iniciar sua computação e um checkpoint final imediatamente antes do término da computação.

Utilizamos c para denotar o ésimo checkpoint gravado pelo processo p, sendo que = 0 representa o checkpoint inicial.

Um intervalo entre checkpoints é o conjunto de eventos ocorridos entre dois checkpoints consecutivos do mesmo processo.

Intervalos de checkpoint podem ser rotulados de duas maneiras, à esquerda e à direita.

Nesta tese, utilizamos a rotulação à esquerda, ou seja, o intervalo entre ce c+1 é rotulado como I.

O conjunto de todos os checkpoints e mensagens trocadas entre processos de uma computação distribuída forma um padrão de checkpoints e mensagens.

Dizemos que c precede c (c c ) se o evento que originou c precede o evento que originou c.

Um checkpoint c precede diretamente um checkpoint c se o processo p enviou uma mensagem m para p após o armazenamento de c e p recebeu m antes de salvar c.

Uma precedência transitiva de c para c é formada por uma sequência de mensagens iniciada por p após c e terminada em p antes de c.

Ilustra um diagrama espaço-tempo para três processos e os checkpoints de cada processo são representados por quadrados preenchidos.

Temos que o checkpoint c precede diretamente o checkpoint c +1 (c c +1) e precede transitivamente o checkpoint c +1 (c c +1).

As precedências causais entre checkpoints podem ser rastreadas durante uma computação distribuída por meio do uso de vetores de dependências 4 (VD).

O mecanismo de vetores de dependências é semelhante ao de vetores de relógios, porém os vetores de dependências armazenam informações sobre as precedências causais entre checkpoints.

Precedência causal entre checkpoints.

Cada processo p mantém e propaga um vetor de dependências VD com n entradas, todas iniciadas com 0 e a entrada VD é incrementada imediatamente após a retirada de um checkpoint, incluindo o checkpoint inicial.

A entrada VD indica o intervalo corrente de p e as outras entradas VD, j 6= i, indicam o índice do ultimo intervalo de p que p conhece.

Ao enviar uma mensagem m, o vetor de dependências VD do processo p é agregado à mensagem, denotado por m VD.

Quando p recebe uma mensagem m, p atualiza o vetor VD fazendo uma operação de máximo para cada entrada do vetor recebido na mensagem e do vetor de p, VD, m VD), para todos j 6= i.

Ilustra uma computação distribuída com vetores de dependências.

Vetores de dependências.

Dado c o ésimo checkpoint do processo p e c o ésimo checkpoint do processo p, temos as seguintes propriedades para vetores de dependência, Utilizando as Propriedades 4 e 5 do vetor de dependências é possível rastrear todas as dependências entre os checkpoints obtidos pelos processos da aplicação.

O conceito de zigzag path introduzido por Netzer e Xu é uma generalização do conceito de precedência causal introduzido por Lamport.

Zigzag Path,Existe uma zigzag path a partir de um checkpoint c a um checkpoint c se existe uma sequência de mensagens tal que, é enviada pelo processo pa após é recebida pelo processo p, então m é enviada por p no mesmo ou no intervalo de checkpoints posterior a recepção de m, e m é recebida pelo processo p antes de c.

Existem dois tipos de zigzag paths, causais e não-causais.

Uma zigzag path é causal se a recepção de toda mensagem, ocorre sempre antes do envio de m.

Uma zigzag path é não-causal se a recepção de alguma mensagem, ocorre após o envio de m i+1.

Existe uma zigzag path não-causal de c a c.

Zigzag path não-causal entre checkpoints.

Uma zigzag path causal a partir de c a c, formada por uma sequência de mensagens, equivale à precedência causal.

Representa uma zigzag path não-causal entre c e c e, portanto, pelo menos uma das mensagens m que compõem a zigzag path foi recebida após o envio da mensagem subsequente m i+1.

Quando uma zigzag path conecta um checkpoint a si próprio, temos uma zigzag cycle (Z-cycle).

Este tipo especial de zigzag path impede que o checkpoint envolvido faça parte Zigzag paths, de qualquer checkpoint global consistente.

Um checkpoint que não faz parte de nenhum checkpoint global consistente é chamado de checkpoint inútil.

O checkpoint c é inútil pois existe uma zigzag path de c a c+1 e outra de ca c que forma um z-cycle que envolve c.

Zigzag cycle.

A relação de z-precedência entre checkpoints equivale ao conceito de zigzag path, mas tem sua definição baseada em precedências causais e não em sequência de mensagens.

Nesta tese, utilizamos o símbolo para indicar a existência de uma zigzag path ou de uma z-precedência entre dois checkpoints.

Cao e Singhal introduzem o conceito de z-dependência para expressar uma relação de dependência entre processos em dois intervalos de checkpoints.

Z-Dependência,Se um processo p envia uma mensagem para o processo p durante o seu ésimo intervalo de checkpoints I e p recebe a mensagem durante o seu ésimo intervalo de checkpoints I, então p z-depende de p durante I e I (p p ).

A z-dependência entre processos pode ser construída também de forma transitiva.

O conceito de z-precedência é baseado na noção de causalidade e foi proposto para relacionar os checkpoints.

Cao e Singhal introduzem o conceito de z-dependência para definir a relação de dependência entre processos e afirmam que é impossível utilizar zigzag paths para mapear dependências dos protocolos síncronos.

A relação de z-precedência entre checkpoints equivale ao conceito de zigzag path.

Nesta seção, provamos que o conceito de z-dependência está contido no conceito de z-precedência sendo a relação de z-precedência mais abrangente e portanto pode ser utilizada também para a teoria dos protocolos síncronos.

Se p z-depende de p durante I e I então, c z-precede c +1, isto é, Prova, A relação p p pode ser expressa por um conjunto de relações de z-dependências diretas.

A prova será feita por indução no número de z-dependências diretas que forma a z-dependência entre os processos p e p.

Neste caso, m foi enviada após c e recebida antes de c +1 e portanto, c c +1.

Sabemos que existe uma z-dependência direta que indica que p z-depende de p durante I e podemos concluir que p p c +1.

A existência da relação de z-precedência não implica na existência da relação de z-dependência.

Porém, não existe relação de z-dependência entre c e c+1 pois a mensagem m a b foi enviada no intervalo de checkpoints I +1.

Existência de z-precedência não implica em z-dependência.

Um checkpoint global consistente é um estado do sistema que pode ser restabelecido de forma segura não permitindo que o evento de entrega de uma mensagem ocorra antes do evento de envio da mesma.

Um checkpoint global é formado por um conjunto de checkpoints, um por processo, e é consistente se não existe relação de causalidade entre os checkpoints do conjunto.

Checkpoint global consistente,Um checkpoint global = {c, c} é consistente se, e somente se, i,j, 0 i,j < n, c 6 c.

Informalmente, um estado global em um diagrama espaço-tempo é consistente se, ao traçar uma linha que une os checkpoints do conjunto, nenhuma aresta tem início no lado direito e termina no lado esquerdo dessa linha.

A linha forma um checkpoint global inconsistente pois o primeiro checkpoint de p0 precede o segundo checkpoint de p1.

A linha 0 mostra um checkpoint global consistente.

Dizemos que dois checkpoints são consistentes se eles podem fazer parte de um mesmo checkpoint global consistente.

As condições necessárias e suficientes para determinar a consistência entre dois checkpoints podem ser definidas por meio de zigzag paths.

Checkpoints consistentes,Os checkpoints c e csão consistentes se, Consistência em checkpoints globais.

Duas operações importantes sobre checkpoints globais são de união e de intersecção.

A união de dois checkpoints globais resulta em um checkpoint global constituído pelos checkpoints mais recentes de cada processo, que está presente em um dos dois checkpoints globais.

Analogamente, a intersecção de dois checkpoints globais é dada pelo checkpoint menos recente em cada processo.

União e intersecção de checkpoints globais.

União de Checkpoints Globais.
A união de dois checkpoints globais e 0 é dada.

Intersecção de Checkpoints Globais.

A intersecção de dois checkpoints globais e 0 é dada por, A união e a intersecção de dois checkpoints globais consistentes resulta sempre em outro checkpoint global consistente.

A necessidade de determinar a ordem em que os eventos ocorrem sem o uso de relógios físicos ou um relógio global em um sistema distribuído, fez com que surgisse a idéia de tempo lógico.

Pelo conceito de precedência causal é possível determinar se um evento ocorreu antes de um outro evento ou se eles são concorrentes (não existe dependência entre os eventos).

Esse conceito é de suma importância na utilização de checkpoints, que são eventos internos de um processo, pois é por meio desta relação que definimos checkpoint global consistente, ou seja, um checkpoint global que pode ser utilizado como ponto de recuperação na ocorrência de uma falha.

Mais tarde, Netzer e Xu introduzem o conceito de zigzag paths que determina as condições necessárias e suficientes para que um conjunto de checkpoints façam parte de um mesmo checkpoint global consistente.

E possível relacionar os checkpoints de maneira equivalente ao conceito de zigzag paths por meio da relação de z-precedência.

O conceito de z-dependência foi proposto por Cao e Singhal para relacionar dois processos em seus respectivos intervalos de checkpoint.

Neste capítulo, provamos que o conceito de z-dependência está contido no conceito de z-precedência.

Nos próximos capítulos, mostraremos que os conceitos definidos e adotados pelos protocolos quase-síncronos podem ser utilizados pelos protocolos síncronos.

Os protocolos de checkpointing são responsáveis pela seleção dos checkpoints salvos em memória estável.

Em caso de falha, o sistema deve ser restabelecido a partir de um estado consistente.

Além disso, é necessário um protocolo de coleta de lixo para remover os checkpoints que não serão utilizados por nenhum protocolo de recuperação liberando espaço de armazenamento.

Na literatura, existem três abordagens para a seleção de checkpoints, assíncrona, quase-síncrona e síncrona.

Nos protocolos assíncronos, os checkpoints são salvos arbitrariamente e não há garantia da formação de checkpoints globais consistentes.

Na abordagem quase-síncrona, informações de controle são propagadas com as mensagens da aplicação de maneira que checkpoints adicionais podem ser induzidos pelo protocolo para garantir a formação de checkpoints globais consistentes.

A recuperação e a coleta de lixo devem ser implementadas separadamente.

Os protocolos síncronos utilizam mensagens de controle para sincronizar as atividades de seleção de checkpoints garantindo a existência de um checkpoint global consistente para cada checkpoint requisitado pela aplicação.

Um protocolo síncrono que salva apenas um número minimal de checkpoints a cada execução é chamado de minimal.

Os protocolos não-bloqueantes podem garantir um número minimal de checkpoints salvos em memória estável quando utilizam também memória não-estável para o armazenamento de checkpoints.

A coleta de lixo é normalmente embutida nesses protocolos.

As Seções seguintes estão divididas como a seguir.

As Seções 31, 32 e 33, descrevem respectivamente as classes de protocolos de checkpointing assíncrona, quase-síncrona e síncrona, sendo que, para esta ultima, é dada a ênfase em protocolos minimais.

Em seguida, discutimos como é possível restabelecer o sistema após a ocorrência de uma falha (Seção 34).

Por ultimo, descrevemos alguns mecanismos de coleta de lixo.

Na abordagem assíncrona, os processos têm autonomia na escolha de seus checkpoints, (cada processo salva um checkpoint quando for mais conveniente), porém alguns desses checkpoints, chamados de checkpoints inúteis, podem não fazer parte de nenhum checkpoint global consistente.

Além disso, não há garantias de que seja possível formar um checkpoint global consistente a partir dos checkpoints salvos.

Portanto, pode ocorrer o efeito dominó, ou seja, a aplicação pode ser obrigada a retornar ao estado inicial em caso de falha.

Os protocolos desta classe não necessitam de nenhum recurso adicional ao armazenamento de checkpoints, como propagação de informações de controle, porém devem ter mecanismos separados para verificar a formação de checkpoints globais consistentes que são utilizados em caso de falha e para a coleta de lixo.

Ilustra um exemplo de padrão de checkpoints e mensagens gerado por um protocolo assíncrono.

Apenas os checkpoints requisitados pela aplicação (checkpoints básicos) são salvos em memória estável.

Neste cenário, o checkpoint global consistente mais recente é representado.

Portanto, na ocorrência de uma falha, os processos deverão retroceder e se estabelecer a partir desse ponto, ou seja, os processos, exceto p3, deverão retroceder ao início da aplicação.

Este mesmo cenário será utilizado para exemplificar protocolos de checkpointing de outras classes descritos neste capítulo.

A classe de protocolos assíncronos não garante a formação de checkpoints globais consistentes e portanto, não será discutida em maiores detalhes.

Exemplo do padrão gerado por um protocolo assíncrono.

Os protocolos quase-síncronos (ou induzidos por comunicação) propostos na literatura reduzem ou eliminam o número de checkpoints inúteis na tentativa de garantir que cada checkpoint faça parte de um checkpoint global consistente.

Este objetivo foi atingido induzindo-se o armazenamento de checkpoints adicionais aos checkpoints do protocolo assíncrono.

Nesta abordagem, os processos salvam seus checkpoints livremente, chamados checkpoints básicos e podem ser induzidos a armazenarem checkpoints adicionais, chamados checkpoints forçados, segundo predicados avaliados sobre informações de controle propagadas pelas mensagens da aplicação.

Posteriormente, checkpoints globais consistentes são formados a partir dos checkpoints selecionados e a coleta de lixo é realizada.

Esta abordagem apresenta um compromisso entre a autonomia dos processos para a escolha dos checkpoints e as garantias oferecidas para a formação de checkpoints globais consistentes.

Os protocolos quase-síncronos podem ser classificados de acordo com os conceitos de zigzag path e zigzag cycle.

A primeira classe Strictly Z-Path Free (SZPF) é a mais restritiva e impede a formação de zigzag paths não-causais entre checkpoints.

A segunda classe Z-Path Free (ZPF) impede a existência de zigzag path não-causais não duplicadas causalmente.

A terceira classe Z-Cycle Free (ZCF) não permite a existência de zigzag cycle garantindo assim, a ausência de checkpoints inúteis.

A Classe Partially Z-Cycle Free (PZCF) é a menos restritiva e apenas tenta quebrar algumas Z-cycles, aumentando as chances de existir, mas sem garantir, os checkpoints globais consistentes.

A hierarquia entre essas classes é apresentada e detalhada a seguir.

Classes de protocolos quase-síncronos.

A Classe SZPF gera um padrão de checkpoints e mensagens apenas com zigzag paths causais.

Os protocolos desta classe garantem a inexistência de checkpoints inúteis e permitem que todas as dependências entre checkpoints possam ser rastreadas utilizando vetores de dependências.

Estes protocolos são simples e possuem baixo overhead nas mensagens da aplicação, porém apresentam um número excessivo de checkpoints forçados, podendo degradar o desempenho do sistema.

O protocolo CAS (Checkpoint-After-Send) é um exemplo de protocolo pertencente à classe SZPF.

Este protocolo induz um checkpoint forçado após cada mensagem enviada.

Ilustra um padrão de checkpoints e mensagens gerado pelo protocolo CAS.

Neste cenário, o checkpoint global consistente mais recente é representado.

Exemplo de padrão gerado pelo protocolo CAS.

Outros protocolos da Classe SZPF identificados por Wang são, CASBR (Checkpoint-After-Send-Before-Receive).

CBR (Checkpoint-Before-Receive).

NRAS (No-Receive-After-Send).

A descrição destes protocolos pode ser encontrada nas Seções A1, A2 e A3, respectivamente.

Os protocolos da Classe ZPF garantem que todas as dependências entre checkpoints são causais.

Neste padrão, se existe uma zigzag path não-causal entre c e c, então esta Os protocolos desta classe propostos na literatura utilizam vetores de dependências para identificar a ocorrência de uma nova precedência e impedir a existência de checkpoints inúteis.

Wang identificou uma propriedade interessante presente nos padrões ZPF e SZPF chamada Rollback-Dependency Trackability (RDT), que permite, em tempo de execução, rastrear as dependências entre checkpoints por meio do uso de vetores de dependências.

Notamos na literatura um esforço em tentar diminuir o número de checkpoints forçados em busca de uma caracterização minimal dos padrões de checkpoints e mensagens que satisfazem a propriedade RDT.

Porém, um checkpoint forçado salvo em um determinado momento pode diminuir a necessidade de armazenar outros checkpoints no futuro.

Ou seja, um protocolo que deixa de salvar um checkpoint forçado desnecessário em um determinado momento pode ter que salvar mais checkpoints forçados no futuro.

Com base nesses argumentos, Tsai formaliza a prova de que é impossível desenvolver um protocolo que armazena apenas um número mínimo de checkpoints forçados para todos os padrões de checkpoints e mensagens possíveis.

Um protocolo simples e bastante conhecido da classe ZPF é o protocolo FDAS (Fixed-Dependency-After-Send).

Este protocolo utiliza o mecanismo de vetores de dependências e cada processo não modifica o seu vetor após enviar uma mensagem da aplicação durante um intervalo de checkpoints.

Ou seja, se a mensagem da aplicação enviada por p e recebida por p carrega uma informação não conhecida por p, p salva um checkpoint forçado imediatamente antes de receber a mensagem.

Uma otimização na condição de indução de checkpoints forçados foi proposto em e sua descrição é apresentada.

Ilustra um padrão de checkpoints e mensagens gerado pelo protocolo FDAS.

Neste cenário, o checkpoint global consistente mais recente é representado.

Exemplo de padrão gerado pelo protocolo FDAS.

O custo associado as mensagens da aplicação é, em geral, a propagação do vetor de dependências.

Resultados de simulação mostram que estes protocolos salvam um alto número de checkpoints forçados comparados aos protocolos da Classe ZCF.

Outros exemplos de protocolos da Classe ZPF são, FDI (Fixed-Dependency-Interval).

RDT-Partner, e são descritos respectivamente nas Seções A4, A5 e A6.

O protocolo BHMR (Baldoni, Helary, Mostefaoui, Raynal) pertence à esta classe porém seu código não é apresentado, pois possui um comportamento equivalente ao do protocolo RDT-minimal.

Este padrão garante a ausência de checkpoints inúteis impedindo a ocorrência de zigzag cycles.

Assim, todo checkpoint salvo por um protocolo ZCF irá fazer parte de algum checkpoint global consistente.

Um dos protocolos mais citados desta classe foi proposto por Briatico, Ciuffoletti e Simoncini e é chamado de BCS.

Neste protocolo, cada processo mantém e propaga apenas um índice que é incrementado a cada novo checkpoint.

Um novo checkpoint é induzido imediatamente antes da recepção de uma mensagem da aplicação se o índice da mensagem for maior do que o índice mantido pelo processo.

Entre os protocolos quase-síncronos que livram o padrão de checkpoints e mensagens de Z-cycles, o BCS produz o máximo de n,1 checkpoints forçados para cada checkpoint básico.

Um mecanismo de otimização que impede a indução de checkpoints se nenhuma mensagem foi enviada no mesmo intervalo de checkpoints foi apresentado em e este protocolo passou a ser chamado de BCS-Aftersend.

O Protocolo 33 descreve o protocolo BCS-Aftersend.

Um exemplo de padrão de checkpoints e mensagens gerado por este protocolo é apresentado.

Neste cenário, o checkpoint global consistente mais recente é representado.

Exemplo de padrão gerado pelo protocolo BCS-Aftersend.

Outro protocolo ZCF altamente custoso proposto na literatura por Baldoni, Quaglia e Ciciani (BQC), controla a indução de checkpoints por meio da propagação de matrizes de relógios.

Os protocolos da Classe PZCF não garantem a ausência de Z-cycles, porém existe um esforço para que pelo menos uma parte dos checkpoints sejam uteis.

Normalmente, esses protocolos são simplificações dos protocolos das Classes ZPF e ZCF.

Esta é a classe menos restritiva e se aproxima dos protocolos assíncronos pois há dificuldade para a obtenção de checkpoints globais consistentes e está sujeita ao efeito dominó.

Um exemplo de protocolo desta classe é chamado de WF e foi proposto por Wang e Fuchs.

Este protocolo é baseado no protocolo BCS, porém, a indução de checkpoints forçados só ocorre para índices múltiplos de um determinado valor.

Apenas o conjunto de checkpoints múltiplos de podem garantidamente fazer parte de um checkpoint global consistente.

Ilustra um padrão de checkpoints e mensagens gerado pelo protocolo com = 2.

Neste cenário, o checkpoint global consistente mais recente é representado.

Exemplo de padrão gerado pelo protocolo WF com = 2.

Em contraste com as classes de protocolos de checkpointing assíncronos e quase-síncronos, os protocolos síncronos utilizam fases de troca de mensagens de controle para sincronizar o armazenamento de checkpoints nos processos e construir checkpoints globais consisten-tes.

O início é determinado pela invocação por um dos processos, chamado iniciador, e o término é determinado pela a verificação de uma condição que indica que todos os processos envolvidos na execução já armazenaram seus checkpoints.

A execução do protocolo, desde o início por um dos processos até o seu término é denominada nesta tese apenas de construção consistente.

Construção Consistente,Uma construção consistente é a execução de um protocolo síncrono desde o momento em que o processo iniciador armazena um checkpoint até o momento em que um novo checkpoint global consistente é construído e todas as mensagens de controle propagadas para esta execução são entregues.

Quando um processo p requisita o armazenamento de um checkpoint c, um protocolo síncrono é invocado e inicia-se um procedimento coordenado para sincronizar as atividades de checkpointing.

Após a execução do protocolo síncrono, c é consistente ini com o ultimo checkpoint de cada processo.

Esse procedimento é normalmente executado em três fases.

Na primeira fase, também chamada de fase de requisições, o iniciador p armazena um checkpoint local, chamado de checkpoint provisório e envia mensagens de requisição para os processos com o objetivo de construir um checkpoint global consistente.

Cada processo que recebe uma mensagem de requisição é chamado de participante da construção consistente e, para atender a requisição, grava um checkpoint provisório e envia uma mensagem de resposta para p.

A segunda fase, conhecida como fase de respostas, é composta pelo envio e recepção de mensagens de respostas e é utilizada para detectar se um novo checkpoint global consistente foi construído.

A terceira fase, chamada de fase de liberações é iniciada após p receber uma mensagem de resposta de cada um dos processos participantes.

Nesse ini momento, p transforma seu checkpoint provisório em permanente e envia uma mensagem de liberação para todos os processos participantes.

Um processo, ao receber uma mensagem de liberação, transforma seu checkpoint provisório em permanente.

Ao final de uma construção consistente, o checkpoint global consistente representado pelos ultimos checkpoints permanentes de cada processo forma o checkpoint global consistente mais recente existente até o momento, e portanto, em cada processo, a coleta de lixo restringe-se ao descarte do checkpoint anterior a este.

No início da execução de qualquer sistema distribuído, todo processo pode armazenar um checkpoint inicial e o conjunto formado por esses checkpoints representa um checkpoint global consistente.

A cada invocação de um protocolo síncrono, um novo checkpoint global consistente é construído.

Nesta seção, mostramos que para se construir um checkpoint global consistente que inclui o checkpoint do processo iniciador de um protocolo síncrono, nem sempre é necessário induzir checkpoints em todos os processos.

Vamos supor que existe um checkpoint global consistente e o processo p inicia uma construção consistente.

O processo p, ao requisitar o armazenamento de um checkpoint c, deve propagar mensagens de requisição com o objetivo de induzir checkpoints para formar um novo checkpoint global consistente 0.

Porém, se p não trocou mensagens da aplicação durante o seu ultimo intervalo de checkpoints, c é consistente com os checkpoints pertencentes a e portanto, 0 pode ser formado pelos checkpoints de substituindo o checkpoint de p por c.

Mesmo que ocorra troca de mensagens durante o ultimo intervalo de checkpoints do processo iniciador p, é possível caracterizar um protocolo minimal, protocolo que induz um número minimal de checkpoints para construir um checkpoint global consistente, utilizando o conceito de zigzag paths.

Considere o checkpoint global consistente existente antes da execução do protocolo síncrono iniciado por p e 0 o checkpoint global consistente que inclui o checkpoint c salvo por p durante sua construção consistente C.

Um checkpoint c faz parte de 0 se c 6 c.

Note que c c é impossível pois estamos considerando que p não envia mensagens da aplicação durante C.

Observe também que c pode ter sido salvo antes ou durante C.

Portanto, o conjunto 0 contém o Construção consistente limitada a c.

checkpoint salvo pelo iniciador, os checkpoints salvos durante a construção consistente C e pode incluir alguns checkpoints.

Protocolo Minimal,Seja o checkpoint global consistente mais a direita formado pelos checkpoints salvos antes da execução de um protocolo síncrono C.

Se o processo p possui um checkpoint que faz parte do conjunto e que z-precede o checkpoint salvo pelo iniciador de C, então p deve armazenar um novo checkpoint durante C para compor 0.

O protocolo é minimal se apenas esses processos salvam checkpoints durante C.

Ilustra um cenário de execução de um protocolo síncrono não-minimal pois 0 engloba um checkpoint salvo por p2 durante a construção consistente porém o checkpoint inicial de p2 que pertence a não z-precede o checkpoint do iniciador.

Ilustra uma execução de um protocolo síncrono minimal pois o checkpoint inicial de p2 z-precede o checkpoint do iniciador e portanto, p2 salva um checkpoint durante a construção consistente de p0.

Protocolos síncronos.

Os protocolos minimais são bloqueantes, ou seja, durante uma construção consistente, os processos envolvidos devem permanecer bloqueados.

O bloqueio de um processo implica na suspensão da execução das atividades da aplicação, sem interromper o mecanismo de troca de mensagens de controle.

O desbloqueio do processo permite que o processo volte à execução de sua computação normal.

Dado um padrão de checkpoints e mensagens, todos os protocolos síncronos minimais constroem os mesmos checkpoints globais consistentes e o número de checkpoints induzidos por qualquer um desses protocolos será mínimo para esse padrão.

Um dos primeiros protocolos minimais foi proposto por Koo e Toueg.

Este protocolo considera canais confiáveis FIFO (First-In First-Out).

Neste protocolo, atribui-se índices as mensagens da aplicação possibilitando assim o rastreamento das precedências diretas entre os checkpoints no seu ultimo intervalo.

Cada processo possui um índice unico de mensagens da aplicação, sendo que a primeira mensagem enviada pelo processo propaga o valor 1, a segunda propaga 2 e assim sucessivamente.

Cada processo mantém dois vetores de inteiros com n entradas, uma para armazenar o índice da ultima mensagem recebida de cada processo e outra para armazenar o índice da primeira mensagem enviada para cada processo.

A descrição do protocolo é apresentada pelo Protocolo 3 5 Consideramos que todo procedimento deste protocolo é executado de forma atômica.

Protocolo 35 Koo e Toueg (declarações).

A construção consistente é iniciada por um processo iniciador p que armazena um checkpoint provisório, fica bloqueado e envia mensagens de requisição para todos os processos dos quais recebeu mensagem no seu ultimo intervalo de checkpoints.

Um processo p não bloqueado, ao receber a mensagem de requisição de p, verifica se o valor do índice da requisição é maior ou igual ao índice da primeira mensagem enviada por p para p no seu ultimo intervalo de checkpoints.

Se esta condição é falsa, o processo simplesmenté envia uma mensagem de resposta para emissor da requisição.

Senão, o processo grava um checkpoint provisório, propaga a mensagem de requisição de forma semelhante ao iniciador e fica bloqueado.

Um processo p participante da construção consistente deve aguardar uma mensagem de resposta de cada um dos processos para os quais enviou uma mensagem de requisição e só então, deve enviar uma mensagem de resposta ao processo do qual recebeu uma mensagem de requisição.

O iniciador, ao receber todas as mensagens de resposta que aguardava, inicia a fase de liberações, transforma seu checkpoint provisório em permanente, é desbloqueado e a mensagem de liberação é propagada de forma semelhante as mensagens de requisição.

Ilustra um padrão de checkpoints e mensagens gerado pelo protocolo de Koo e Toueg.

O bloqueio é representado por pontilhados na linha de execução de cada processo.

Os checkpoints representados como provisórios são transformados em permanentes no final de cada construção consistente.

Neste cenário, o checkpoint global consistente mais recente é representado.

Exemplo do padrão gerado pelo protocolo de Koo e Toueg.

Um protocolo minimal baseado no protocolo de Koo e Toueg foi proposto por Leu e Bhargava.

Este protocolo requer uma fase adicional de mensagens de controle para a formação de uma arvore que indica as precedências entre os processos que serão participantes nesta construção consistente.

O número de mensagens de controle é reduzido no protocolo proposto por Prakash e Singhal por meio da utilização da detecção de terminação proposta por Huang e da propagação de um vetor (vetor de participantes) que indica quais os processos que já estão participando da construção consistente.

Cao e Singhal propuseram uma nova abordagem, a qual chamamos de abordagem broadcast, que permite a um unico processo (o iniciador) decidir quais os processos qué devem armazenar checkpoints durante uma construção consistente.

Neste protocolo, todos os processos devem ficar bloqueados para a aplicação enquanto o iniciador toma essa decisão.

Provaremos na Seção 4 1 2 que estes dois ultimos protocolos não são minimais.

Um dos primeiros protocolos de checkpointing síncronos não-bloqueantes foi proposto por Chandy e Lamport e requer que todos os processos da aplicação armazenem seus checkpoints durante uma construção consistente.

Recentemente, outros protocolos síncronos não-bloqueantes baseados nos protocolos síncronos bloqueantes minimais foram propostos com o objetivo de diminuir o número de checkpoints a cada construção consistente.

Notamos que esta abordagem apresenta um compromisso entre a sincronia no armazenamento de checkpoints como nos protocolos síncronos e as garantias oferecidas para a formação de checkpoints globais consistentes como nos protocolos quase-síncronos.

No Capítulo 5, mostramos que é possível desenvolver protocolos síncronos não-bloqueantes baseando-se em protocolos quase-síncronos.

De maneira análoga aos protocolos síncronos bloqueantes, os protocolos síncronos não-bloqueantes utilizam as três fases (fase de requisições, respostas e liberações) para sincronizar o armazenamento dos checkpoints e construir um checkpoint global consistente.

Porém, a característica não-bloqueante desses protocolos permite que os processos continuem enviando e recebendo mensagens da aplicação, antes mesmo do término da construção consistente, podendo gerar uma inconsistência.

O iniciador p1 envia mensagens de requisição para p0 e p2.

O processo p0 salva o checkpoint c 1 e envia uma mensagem da aplicação m para p2 que recebe m antes da mensagem de requisição.

Quando p2 recebe a mensagem de requisição, armazena um checkpoint gerando uma inconsistência, {c, c, c } forma um checkpoint global inconsistente pois engloba a recepção da mensagem m mas não o seu envio.

Este problema pode ser solucionado pelo armazenamento de um checkpoint imediatamente antes da recepção de m.

Ilustra o mesmo padrão de checkpoints e mensagens, porém p2 salva um checkpoint provisório imediatamente antes de receber m.

Quando p2 recebe a mensagem de requisição de p1, p2 inclui c 1 na construção consistente iniciada por p1.

No final da construção consistente de p1, o conjunto de checkpoints permanentes {c,c,c } forma um checkpoint global consistente.

Uma observação importante neste ponto é notar que apenas as mensagens da aplicação geram precedência causal entre os checkpoints, ou seja, mensagens geradas pelo protocolo de checkpointing (mensagens de controle) não introduzem a relação de precedência causal entre checkpoints.

O primeiro protocolo síncrono que tentou combinar a característica não-bloqueante e minimalidade no número de checkpoints foi proposto por Prakash e Singhal e sua descrição se encontra na Seção C1.

Porém, Cao e Singhal mostraram que este protocolo pode resultar em inconsistências e propuseram uma correção para o protocolo de Prakash e Singhal.

Cao e Singhal introduziram o conceito de checkpoints mutáveis e propuseram então um protocolo que relaxa a condição de minimalidade, garantindo apenas um número minimal de checkpoints salvos em memória estável.

Um checkpoint mutável é salvo em memória não-estável e pode ser facilmente manipulado.

Os checkpoints mutáveis são induzidos no momento da recepção de uma mensagem da aplicação de acordo com predicados do protocolo e podem ser transferidos para memória estável durante Impedindo a geração de checkpoints inconsistentes e uma construção consistente.

Por exemplo, ao introduzirmos checkpoints mutáveis no padrão de checkpoints e mensagens, p2 salva um checkpoint mutável c1 imediatamente antes de receber m.

Quando p2 recebe uma mensagem de requisição do iniciador p1, p2 transforma c 1 em provisório e ao receber uma mensagem de liberação, c 1 é salvo como permanente.

Este protocolo considera que qualquer processo pode iniciar uma construção consistente, porém permite a presença de apenas um unico iniciador a cada instante de tempo.

No protocolo de Cao e Singhal, se nenhum processo está envolvido em uma construção consistente, então, nenhum checkpoint é induzido.

Um processo p salva um checkpoint mutável imediatamente antes de receber uma mensagem da aplicação de p se p não conhece nem o índice do ultimo checkpoint de p nem a informação do iniciador conhecido por p e p enviou uma mensagem durante o intervalo de checkpoints corrente.

Este checkpoint mutável é transformado em provisório se p recebe uma mensagem de requisição da construção consistente atual.

Caso contrário, esse checkpoint mutável é descartado na fase de liberações.

A detecção da terminação de uma construção consistente é baseada no protocolo proposto por Huang.

A descrição do protocolo de Cao e Singhal é apresentada pelo Protocolo.

Ilustra um padrão de checkpoints e mensagens gerado pelo protocolo de Cao e Singhal.

O checkpoint mutável salvo por p1 é transformado em provisório no momento em que p1 recebe uma mensagem de requisição de p0.

Os checkpoints representados como provisórios são transformados em permanentes no final da construção consistente iniciada por p3 e o checkpoint global consistente mais recente está representado por.

Exemplo de padrão gerado pelo protocolo de Cao e Singhal.

O protocolo de Cao e Singhal, como originalmente escrito, pode gerar uma inconsistência.

Neste cenário, quando p2 recebe uma mensagem de requisição de p0, p2 não salva um checkpoint provisório, pois p0 não conhece o índice do ultimo checkpoint permanente de p2.

Quando p2 recebe uma mensagem da aplicação de p0, p2 não salva um checkpoint mutável, pois p2 já tem conhecimento sobre o índice do ultimo checkpoint de p0.

Quando p2 recebe uma mensagem de requisição dé p, p2 salva um checkpoint provisório pois p1 conhece o índice do seu ultimo checkpoint permanente e p2 não salvou nenhuma informação sobre a construção consistente de p0, o que gera a inconsistência.

Como as mensagens de controle não geram inconsistências, a Figura apresenta o mesmo cenário sem as mensagens de controle, possibilitando visualizar melhor a inconsistência gerada por este protocolo.

Esta inconsistência pode ser facilmente corrigida, alterando na recepção de uma mensagem de requisição, o momento em que o processo atualiza a informação sobre o índice do ultimo checkpoint do emissor da mensagem de requisição.

O procedimento da recepção da mensagem de requisição com esta pequena correção é descrito pelo Protocolo 3 7 Um protocolo de checkpointing não-bloqueante não garante um número minimal de checkpoints para uma determinada construção consistente.

Cao e Singhal introduziram o conceito de checkpoints mutáveis para armazenar um número minimal de checkpoints em memória estável.

Uma das contribuições desta tese é mostrar que isso só é possível se considerarmos um unico iniciador a cada instante (Capítulo 5).

Inconsistência gerada pelo protocolo de Cao e Singhal.

As aplicações distribuídas possuem melhor desempenho, são escaláveis e permitem compartilhamento transparente de recursos existentes no sistema, porém estão mais suscetíveis a falhas.

Na ocorrência de falhas, o mecanismo de recuperação é iniciado com o objetivo de evitar perda de computação.

A recuperação de falhas pode ser realizada por dois mecanismos, forward, quando existe a possibilidade de remover os erros do estado corrente para então habilitar o processo a prosseguir com sua computação.


Backward, o estado sem erros do processo salvo anteriormente é utilizado para restabelecer o processo.

Este mecanismo é mais conhecido como recuperação por retrocesso.

A recuperação por retrocesso é classificada como baseada em checkpoint que é menos restritiva e mais simples de implementar, ou baseada em log, onde todos os eventos são identificados e escritos na forma de logs em memória estável.

A recuperação por retrocesso baseada em checkpoint garante o armazenamento de estados corretos em memória estável.

Para garantir a recuperação de um sistema distribuído com qualquer padrão de comunicação é necessário que o sistema retroceda para o estado global consistente mais recente.

Em caso de falha global, basta que o mecanismo de recuperação selecione o ultimo checkpoint global consistente formado por checkpoints estáveis e indique a cada processo para qual estado deve retroceder.

Em caso de falha parcial, ou seja, apenas uma parte dos processos sofreram falhas, os estados correntes dos processos não-falhos também podem ser utilizados como estado correto para formar um novo checkpoint global consistente garantindo assim, o mínimo de perda de computação possível (menor custo de retrocesso).

O conjunto de estados utilizados para restabelecer o sistema é chamado de linha de recuperação.

Portanto, uma linha de recuperação é o checkpoint global mais recente (podendo incluir estados correntes do sistema), tendo em vista as dependências existentes entre checkpoints.

Existem duas abordagens para a execução do mecanismo de recuperação, síncrona e assíncrona.

Na abordagem síncrona, um processo iniciador é responsável por calcular a linha de recuperação por meio das dependências entre os checkpoints existentes e controlar o retrocesso dos processos.

Quando o mecanismo de retrocesso é iniciado, o iniciador faz um broadcast para requisitar as dependências entre checkpoints mantidas pelos processos.

Um processo, ao receber essa mensagem de requisição, fica bloqueado e envia uma mensagem de resposta ao iniciador com as informações requisitadas.

Pelas dependências recebidas por todos os processos, o iniciador calcula a linha de recuperação, possivelmente construindo um grafo de dependências de retrocesso, ou R-graph.

Então, o iniciador envia uma mensagem para cada processo indicando para qual estado ele deve retroceder e todo processo deve obedecer as instruções contidas nessa mensagem.

No mecanismo de retrocesso assíncrono, o processo falho p retrocede ao seu ultimo estado salvo em memória estável e faz um broadcast avisando a todos os processos para qual estado ele retrocedeu.

Todo processo ao receber a mensagem de p, continua sua execução se seu estado atual é consistente com o estado de p ou retrocede para garantir a consistência do estado global da computação distribuída e também distribui o aviso de seu retrocesso.

Esse procedimento é repetido até que um checkpoint global consistente seja recuperado.

Estes protocolos são complexos e muitas vezes menos eficientes.

O mecanismo de recuperação deve tratar também as mensagens que se encontram em trânsito.

Para isso, é necessário que as informações sobre os eventos de envio e recepção de mensagens sejam gravadas em memória estável na forma de logs.

Assim, ao recomeçar a execução, os processos podem ser requisitados a reenviar as mensagens ou podem ser replicadas no receptor garantindo que elas não sejam perdidas.

Checkpoints e logs de eventos consomem recursos de armazenamento e quanto mais a aplicação progride, mais informações de recuperação devem ser armazenadas.

O mecanismo de coleta de lixo identifica e remove os checkpoints obsoletos, ou seja, checkpoints que não serão utilizadas por nenhuma linha de recuperação.

Um algoritmo para coleta de lixo é otimo se é capaz de identificar e eliminar todos os checkpoints obsoletos de um padrão de checkpoints e mensagens.

Um checkpoint que está no passado de um checkpoint global consistente formado por apenas checkpoints estáveis é um checkpoint obsoleto.

Esta condição é suficiente para a implementação de um algoritmo simples de coleta de lixo, conhecido como coleta de lixo ingênua.

Este algoritmo verifica qual o checkpoint global consistente mais recente formado apenas por checkpoints estáveis para remover os checkpoints que estão em seu passado.

Este mecanismo é facilmente implementado por protocolos de checkpointing síncronos que durante sua execução, requerem que cada processo mantenha, no máximo, dois checkpoints estáveis garantindo assim a existência de pelo menos um checkpoint global consistente.

Apenas quando todos os checkpoints de um novo checkpoint global consistente foram induzidos e salvos em memória estável é que os checkpoints anteriores tornam-se obsoletos e podem ser removidos.

Uma atenção especial deve ser dada aos protocolos síncronos não-bloqueantes.

Esses protocolos induzem checkpoints adicionais no intervalo de duas execuções do protocolo para garantir consistência.

Portanto, um número maior de checkpoints devem ser mantidos pelos processos e os checkpoints são removidos apenas no final de uma construção consistente.

A coleta de lixo ingênua também pode ser utilizada em aplicações que implementam protocolos de checkpointing quase-síncronos ou assíncronos.

Neste caso, a verificação do checkpoint global consistente mais recente pode ser feita de forma semelhante ao algoritmo de recuperação por retrocesso síncrono.

Escolhe-se um processo inicial que requisita pelas dependências entre checkpoints conhecidas por todos os processos e por meio dessa informação, calcula-se a linha de recuperação formada por checkpoints estáveis, possivelmente utilizando R-graph.

O resultado é propagado para todos os processos de forma que eles possam remover os checkpoints salvos no passado da linha de recuperação obtida.

Outra maneira de realizar a coleta de lixo ingênua é implementando-se um monitor da computação distribuída.

Quando um checkpoint é salvo, suas informações são enviadas ao monitor que constrói a linha de recuperação progressivamente.

A cada novo checkpoint global consistente detectado pelo monitor, os processos são avisados para que possam efetuar a coleta.

A coleta de lixo ingênua é simples, porém requer conhecimento global do sistema distribuído para o cálculo da linha de recuperação.

Além disso, não existe um número máximo de checkpoints não coletados, ou seja, não existe limite máximo de checkpoints que o processo deve manter em memória estável.

O mecanismo de coleta de lixo otimo deve remover, não somente os checkpoints que estão no passado de uma linha de recuperação, mas também os checkpoints que não serão usados por nenhuma outra linha de recuperação, mesmo que estes estejam no futuro do checkpoint global consistente mais recente formado por checkpoints estáveis.

O algoritmo de coleta de lixo otimo constrói o R-graph de forma semelhante ao algoritmo de recuperação por retrocesso síncrono para identificar os checkpoints estáveis que fazem parte de alguma linha de recuperação e não apenas do checkpoint global consistente mais recente.

Todos os outros checkpoints são obsoletos.

Em particular, a coleta de lixo ingênua ou a otima em padrões de checkpoints e mensagens que satisfazem a propriedade RDT podem ser simplificadas.

Neste caso, os processos devem manter, no máximo, n checkpoints e a linha de recuperação pode ser calculada apenas com informações locais sem a necessidade de troca de mensagens ou bloqueio dos processos durante sua execução.

Uma possível maneira de evitar perda de computação na recuperação de um sistema distribuído após a ocorrência de uma falha é implementar um mecanismo que envolve, seleção de checkpoints, onde e como armazenar o estado corrente de um processo, garantia da existência de checkpoints globais consistentes, recuperação a partir de um checkpoint global consistente e coleta de lixo.

Os protocolos de checkpointing são responsáveis pela seleção de checkpoints e são classificados como assíncronos, quase-síncronos e síncronos.

Na abordagem assíncrona, apenas os checkpoints requisitados pela aplicação são salvos em memória estável e não há garantia da formação de checkpoints globais consistentes, ou seja, as aplicações que implementam protocolos desta classe estão sujeitas ao efeito dominó.

Em geral, os protocolos quase-síncronos adicionam informações de controle as mensagens para detectar a existência de zigzag paths entre os checkpoints dos processos emissor e receptor da mensagem.

Assim, na recepção de uma mensagem da aplicação, o protocolo pode salvar ou não um checkpoint antes de entregar a mensagem para garantir a posterior formação de checkpoints globais consistentes.

A maioria dos protocolos desta classe considera que o sistema possui meio de armazenamento estável suficiente para gravar todos os checkpoints requisitados.

Na prática, aplicações que implementam protocolos quase-síncronos devem implementar também um protocolo de coleta de lixo para remover os checkpoints obsoletos que não serão utilizados para recuperação.

Os protocolos síncronos utilizam mensagens de controle adicionais para sincronizar o armazenamento dos checkpoints garantindo a construção de um checkpoint global consistente para cada checkpoint requisitado pela aplicação.

Uma maneira simples de coordenar o armazenamento de checkpoints é propagar mensagens de controle para que todos os processos salvem seus checkpoints suspendendo os procedimentos de entrega de mensagens para a aplicação e de envio de mensagens para o subsistema de rede de comunicação durante sua execução.

Para reduzir o custo de armazenamento de checkpoints, protocolos síncronos minimais induzem apenas um número minimal de processos a armazenarem checkpoints durante sua execução.

A coleta de lixo normalmente é implementada pelo próprio protocolo de checkpointing síncrono que, em sua fase final (após armazenar os checkpoints estáveis que fazem parte de um checkpoint global consistente) remove os checkpoints salvos anteriormente.

Nestes protocolos, os processos mantêm, no máximo, dois checkpoints em memória estável para garantir tolerância a falhas durante uma execução do protocolo.

Os protocolos síncronos não-bloqueantes permitem que a aplicação continue sua computação mesmo durante uma execução de checkpointing.

O primeiro e mais conhecido protocolo síncrono não-bloqueante utiliza canais de comunicação FIFO confiáveis e o envio de controle por todos os canais de comunicação para que todos os processos armazenem seus checkpoints na formação de um checkpoint global consistente.

Recentemente, foram propostos protocolos síncronos não-bloqueantes que reduzem o número de checkpoints salvos em memória estável e ainda assim, garantem a formação de checkpoints globais consistentes.

Estes protocolos originalmente foram baseados em protocolos síncronos existentes, porém notamos que estes possuem não somente características de protocolos síncronos, como sincronizar o armazenamento de checkpoints.
Mas também necessitam propagar informações de controle com as mensagens da aplicação para induzir ou não checkpoints forçados impedindo inconsistências, ou seja, os protocolos síncronos não-bloqueantes necessitam de mecanismos como os propostos pelos protocolos quasesíncronos.

Nos próximos capítulos, mostraremos que além de ser possível desenvolver protocolos síncronos baseados em protocolos quase-síncronos, esses protocolos são mais simples, permitem iniciadores concorrentes e não requerem que todos os processos salvem checkpoints durante uma execução do protocolo.

Os protocolos síncronos simplificam a recuperação de uma falha e evitam o efeito dominó mantendo checkpoints globais consistentes em memória estável.

Para reduzir o custo de armazenamento a cada construção consistente, os protocolos minimais bloqueiam os processos para induzir apenas um número minimal de processos a armazenarem checkpoints.

Na literatura, existem dois protocolos que foram propostos com o objetivo de alcançar um número minimal de checkpoints, porém provamos por meio de contra-exemplos, que estes protocolos não são minimais.

Notamos que a estrutura de dados utilizada por ambos os protocolos não é suficiente para garantir a minimalidade no número de checkpoints.

Este problema nos motivou a procurar um novo mecanismo de rastreamento, baseado no uso de vetores de dependências, para propor novos protocolos.

Este capítulo é dividido em duas partes, a Seção 41 considera um unico iniciador é a Seção 42 considera iniciadores concorrentes.

Para cada uma delas, descrevemos suas características e discutimos sobre a questão da minimalidade no número de checkpoints e propomos novos protocolos, Broad-minimal que permite apenas um unico iniciador a cada instante e VD-minimal que permite a execução de iniciações concorrentes.

Nesta Seção, consideramos a presença de um unico iniciador a cada instante de tempo.

Isto significa que, uma nova construção consistente não inicia enquanto todas as mensagens de controle da construção consistente anterior não tiverem sido entregues.

A busca pela minimalidade no número de checkpoints salvos durante uma construção consistente gerou duas abordagens para a organização dos processos nos protocolos síncronos minimais, em níveis e broadcast.

A abordagem em que os processos se organizam em níveis bloqueia apenas os processos participantes da construção consistente e a decisão de salvar um checkpoint ou não é determinada pelos processos participantes.

Em contraste, a abordagem baseada em broadcast bloqueia todos os processos e transfere exclusivamente para o iniciador a tarefa de determinar quais processos devem armazenar checkpoints durante uma construção consistente.

Protocolos Minimais com Abordagem em Níveis.

Na abordagem em níveis, cada processo deve capturar e manter as precedências causais entre checkpoints formadas no seu ultimo intervalo de checkpoints.

Quando o iniciador p salva um checkpoint para iniciar uma construção consistente de um protocolo minimal, ini p utiliza o seu conhecimento sobre as precedências causais para selecionar os processos ini participantes e propagar-lhes mensagens de requisição (primeiro nível).

Cada processo que recebe uma mensagem de requisição também é capaz de selecionar os processos de interesse formando outros níveis de propagação de mensagens de requisição.

Na literatura, notamos diferentes mecanismos para rastrear as dependências entre checkpoints, índices nas mensagens da aplicação este mecanismo é utilizado pelo protocolo minimal proposto por Koo e Toueg.

Cada processo mantém um contador unico para as mensagens da aplicação e dois vetores para anotar o índice da primeira mensagem enviada e da ultima recebida pelos processos.

A entrada a do vetor dé mensagens recebidas de p indica o índice da ultima mensagem enviada por p e da primeira mensagem enviada por p para p no ultimo intervalo de checkpoints.

Assim, quando p recebe uma mensagem de requisição do iniciador p, p verifica no seu vetor de primeiras mensagens enviadas se a dependência foi formada após o seu ultimo checkpoint, ou seja, se p conhece o índice da primeira mensagem que p enviou para p.

Neste caso, p salva um checkpoint e propaga mensagens de requisição para todos os processos dos quais recebeu mensagens no seu ultimo intervalo de checkpoints.

Essa propagação das mensagens de requisição em níveis é feita até que todos os participantes da construção consistente tenham recebido pelo menos uma mensagem de requisição.

O vetor com o índice das primeiras mensagens enviadas e das ultimas mensagens recebidas são representados por ( ) e ( ), respectivamente.

Rastreamento de dependências por meio de índices nas mensagens.

Índices dos checkpoints este mecanismo é semelhante ao mecanismo de relógios lógicos e é utilizado por Leu e Bhargava.

Cada mensagem da aplicação propaga o índice do ultimo checkpoint salvo pelo seu emissor.

O processo que recebé a mensagem da aplicação mantém um vetor com o maior índice recebido pelos processos.

Quando um processo iniciador p salva um checkpoint, uma arvore virtual representando as dependências estabelecidas no intervalo de checkpoints corrente é construída.

Assim, os índices maiores que zero do vetor do iniciador, dos quais recebeu informação sobre um novo índice após seu ultimo checkpoint indicam seus potenciais filhos, para os quais envia uma mensagem de requisição.

Se o índice do ultimo checkpoint do processo p que recebeu a requisição é menor ou igual ao índice conhecido pelo pai p, então p envia uma mensagem de confirmação positiva ao pai p e p inclui p como seu filho e p propaga a mensagem de requisição de forma semelhante a p.

A arvore construída é utilizada para propagar as mensagens de resposta e liberação.

Rastreamento de dependências por meio de índices dos checkpoints.

Vetores de bits,neste mecanismo, cada processo p mantém um vetor de bits que, quando ativo na posição i, indica que p recebeu pelo menos uma mensagem de p em seu ultimo intervalo de checkpoints.

Assim, todos os processos mantêm informações de quais processos receberam mensagens após o seu ultimo checkpoint.

Quando o iniciador salva um checkpoint, envia mensagens de requisição para todos os processos dos quais recebeu pelo menos uma mensagem no seu ultimo intervalo de checkpoints.

Neste capítulo, mostramos que o uso deste mecanismo não garante a minimalidade no número de checkpoints.


Rastreamento de dependências por meio de vetores de bits.

Vetores de dependências,o rastreamento das precedências causais também pode ser realizado por meio do uso de vetores de dependências.

Os vetores de dependências capturam precedências causais transitivas e, portanto, se existe uma zigzag path causal a partir do ultimo checkpoint de páté o checkpoint do iniciador, então p receberá uma mensagem de requisição do iniciador no primeiro nível.

Assim, os protocolos que utilizam vetores de dependências para capturar as precedências causais podem utilizar um número menor de níveis, comparado aos protocolos que utilizam captura de precedências diretas, para atingir todos os participantes de uma construção consistente.

Rastreamento de dependências por meio de vetores de dependências.

As principais características de cada um dos mecanismos citados podem ser resumidas da seguinte maneira, Diferentes mecanismos para detecção da formação de um novo checkpoint global consistente são utilizados pelos protocolos síncronos.

A determinação de para quais processos as mensagens de resposta devem ser enviadas e o número de mensagens de resposta e de liberação dependem do mecanismo de detecção de terminação utilizado.

Uma maneira simples de detectar a terminação de uma construção consistente é permitir que um processo só envie a mensagem de resposta ao processo do nível anterior após receber mensagens de respostas de todos os processos do nível posterior.

Outros mecanismos foram baseados em protocolos de detecção de terminação em computação por difusão.

Os protocolos minimais propostos na literatura que utilizam a abordagem em níveis são executados em três fases, 1 fase de requisições, um processo iniciador, ao invocar o protocolo síncrono, armazena um checkpoint provisório, fica bloqueado e propaga as mensagens de requisição.

No primeiro nível, o iniciador envia mensagens de requisição para os processos que possuem um checkpoint que precede causalmente o seu ultimo checkpoint.

No segundo nível, os processos, ao receberem uma mensagem de requisição do iniciador, verificam a necessidade de armazenar um checkpoint provisório para então ficarem bloqueados e propagarem mensagens de requisição formando os níveis subsequentes.

Se existe uma zigzag path do ultimo checkpoint de p até o checkpoint do iniciador de tamanho n,1 no qual cada par de mensagens é formado por uma zigzag path não-causal, então p receberá uma mensagem de requisição no (n,1)-ésimo nível b de propagação de requisição.

Note que n,1 é o número limitante para o número de níveis em um protocolo minimal.

Fase de respostas, todo processo participante da construção consistente envia uma mensagem de resposta de acordo com o protocolo de detecção de terminação escolhido.

Fase de liberações, quando o predicado de terminação de uma construção de um checkpoint global consistente é satisfeito, o iniciador passa para a terceira fase, propagando mensagens de liberação.

Todo processo que recebe uma mensagem de liberação, transforma o seu checkpoint provisório em permanente, é desbloqueado e volta à sua computação normal.

Ilustra as fases de um protocolo minimal com a abordagem em níveis.

O processo p3 é o iniciador e envia uma mensagem de requisição para p2 no primeiro nível.

No segundo nível, p2, após salvar um checkpoint, envia uma mensagem de requisição para p 1 e para p0.

Note que nem todos os processos necessitam armazenar checkpoints em uma construção consistente.

Os processos que armazenam checkpoints ficam bloqueados e propagam a mensagem de requisição.

Todo processo que recebe uma mensagem de requisição, envia uma mensagem de resposta ao iniciador que encerra a construção consistente por meio do envio das mensagens de liberação.

Protocolo minimal com abordagem em níveis.

Cao e Singhal propuseram uma nova abordagem, a qual chamamos de abordagem broadcast, que permite a um unico processo (o iniciador) decidir quais processos devem armazenar checkpoints durante uma construção consistente.

Esta abordagem utiliza duas fases adicionais iniciais para que o iniciador receba informações sobre as dependências conhecidas pelos processos e verifique quais processos devem participar de sua construção consistente.

Todos os processos devem ficar bloqueados enquanto o iniciador toma essa decisão.

As fases utilizadas por protocolos minimais com abordagem broadcast são descritas a seguir, 1 fase de broadcast, o iniciador salva um checkpoint provisório, faz um broadcast da mensagem de bloqueio requisitando informações de controle e fica bloqueado.

Fase de respostas ao bloqueio, todo processo que recebe uma mensagem de bloqueio envia ao iniciador uma mensagem de resposta ao bloqueio com suas informações de dependência entre checkpoints e fica bloqueado.

Fase de requisições, o iniciador verifica quais os processos cujo ultimo checkpoint z-precede o seu ultimo checkpoint provisório, ou seja, os processos que devem armazenar checkpoints para a construção de um checkpoint global consistente garantindo apenas um número minimal de checkpoint salvos.

O iniciador envia uma mensagem de requisição para cada processo que deve salvar um checkpoint e uma mensagem de liberação aos outros processos.

Fase de respostas, todo processo participante da construção consistente deve, após salvar um checkpoint provisório, enviar uma mensagem de resposta ao iniciador.

Fase de liberações, o iniciador, após receber mensagens de resposta de cada processo participante, transforma seu checkpoint provisório em permanente, é desbloqueado e envia uma mensagem de liberação aos participantes da construção consistente.

Os processos que recebem uma mensagem de liberação transformam seus checkpoints provisórios em permanentes e são desbloqueados.

Nesta abordagem, todos os processos ficam bloqueados em um primeiro momento, porém apenas os processos que necessitam armazenar checkpoints permanecem bloqueados até o fim da construção consistente.

Além disso, as mensagem de controle são propagadas diretamente do iniciador aos participantes da construção consistente, e nenhum processo recebe duas ou mais mensagens de controle do mesmo tipo.

Um exemplo de execução da abordagem broadcast é ilustrado.

Na seção anterior, descrevemos algumas características dos protocolos síncronos minimais em função das fases e estratégias de troca de mensagens utilizadas para a obtenção de checkpoints globais consistentes.

Nesta seção, descrevemos esses protocolos sob o ponto de vista da busca pela minimalidade.

Um protocolo minimal pode deixar de ser correto durante a construção consistente se, deixa de incluir entre os participantes um processo cujo ultimo checkpoint z-precedé o checkpoint armazenado pelo iniciador e/ou, inclui no conjunto de participantes um processo que salva novo checkpoint, porém seu ultimo checkpoint não z-precede o checkpoint armazenado pelo iniciador.

Um protocolo que exibe o primeiro defeito, obterá ao final da construção consistente um checkpoint global inconsistente.

Um protocolo que exibe apenas o segundo defeito deixa de ser minimal porque incluiu no conjunto de participantes um processo que salva um novo checkpoint desnecessariamente, porém constrói um checkpoint global consistente.

Prakash e Singhal propuseram um protocolo com abordagem em níveis que utiliza vetores de bits para rastrear as dependências entre checkpoints (Seção B).


Nesta figura, p1 armazena um checkpoint por causa da requisição enviada por p0 e, na recepção da requisição de p2 armazena novamente outro checkpoint, sem ter enviado ou recebido nenhuma mensagem da aplicação durante esse intervalo.

A união dos checkpoints requisitados pelo iniciador p2 é um checkpoint global consistente mas não minimal.

Não-minimalidade do protocolo proposto por Prakash e Singhal.

Outro protocolo sem êxito no objetivo de alcançar a minimalidade no número de checkpoints foi proposto por Cao e Singhal (Seção B3).

Este protocolo possui abordagem broadcast e também utiliza vetores de bits para rastrear as dependências entre checkpoints.

Provamos que este protocolo também não é minimal.

Nesta figura, quando p0 inicia uma construção consistente, p0 envia uma mensagem de requisição para p1 e p1 salva um novo checkpoint d, porém, o checkpoint b de p1 é consistente com o checkpoint salvo pelo iniciador p0.

Não-minimalidade do protocolo proposto por Cao e Singhal.

A seguir, mostramos que os protocolos que anotam a recepção de mensagens, mas não os intervalos de origem dessas mensagens podem incluir no conjunto de participantes um processo cujo ultimo checkpoint não z-precede o checkpoint armazenado pelo iniciador, deixando portanto, de serem minimais.

Isto ocorre pois um processo que recebe uma mensagem de requisição, não tem como avaliar se a precedência reconhecida foi estabelecida após o armazenamento do seu ultimo checkpoint.

Protocolos que anotam a recepção de mensagens, mas não os intervalos de origem dessas mensagens não têm informação suficiente para serem minimais.

Prova, Por contradição, vamos supor que anotando apenas a recepção de mensagens é suficiente para desenvolver um protocolo minimal.

Sabemos que um protocolo minimal induz checkpoints apenas nos processos cujo ultimo checkpoint z-precede o checkpoint do iniciador.

Quando uma mensagem da aplicação m é enviada de p para p, nenhuma informação de controle necessita ser propagada e o processo p deve anotar a recepção de m após o armazenamento do seu ultimo checkpoint.

Portanto, se p inicia uma construção consistente após receber m, p salva um checkpoint e envia uma mensagem de requisição para p.

Se p salva um checkpoint neste ponto, então o protocolo não é minimal.

Concluímos que a abordagem utilizada para rastrear as precedências entre checkpoints por alguns protocolos não garante minimalidade como descritos na literatura.

A seguir, propomos dois novos protocolos, um com a abordagem em níveis e outro com abordagem broadcast.

Esses protocolos utilizam vetores de dependências para rastrear as precedências e garantir um número minimal de checkpoints salvos durante uma construção consistente.

A abordagem broadcast foi proposta originalmente por Cao e Singhal.

Este protocolo tenta reduzir o tempo de bloqueio nos processos fazendo do iniciador o unico responsável em decidir quais processos devem induzir checkpoints para a construção de checkpoints globais consistentes.

A não-minimalidade deste protocolo (Seção 4 1 2) nos motivou a propor um novo protocolo, chamado de Broad-minimal que garante um número minimal de checkpoints e considera que há um unico iniciador a cada instante de tempo.

Quando um processo p inicia sua construção consistente, armazena um checkpoint provisório e faz um broadcast de mensagens de bloqueio a todos os processos do sistema.

Cada processo, ao receber a mensagem de bloqueio, fica bloqueado e envia seu vetor de dependências e seu vetor de participantes (informação de precedências causais do ultimo intervalo de checkpoints do processo) para o iniciador.

O iniciador, ao receber mensagens de resposta ao bloqueio de todos os processos, define o conjunto de processos que devem salvar checkpoints para induzir um número minimal de checkpoints e construir um checkpoint global consistente.

Os processos selecionados recebem mensagens de requisição e os outros processos recebem mensagens de liberação.

Um processo que recebe uma mensagem de requisição, salva um checkpoint e envia uma mensagem de resposta ao iniciador.

O iniciador, após receber mensagens de resposta de todos os participantes, propaga mensagens de liberação.

Todo processo que recebe uma mensagem de liberação, transforma seu checkpoint provisório em permanente (se este existir) e é desbloqueado.

Variáveis do processo As variáveis utilizadas por este protocolo são descritas a seguir, 

VD, vetor de dependências mantido pelo processo p para capturar as dependências as mensagens da aplicação e quando p recebe uma mensagem, seu vetor é atualizado da seguinte maneira, perm VD, vetor de dependências salvo com o checkpoint permanente mantido pelo processo p.

VP, vetor de participantes que indica se p recebeu uma mensagem com informação de novo checkpoint dos processos durante o seu intervalo de checkpoints corrente.

Este vetor é atualizado da seguinte maneira.
MVD, matriz de vetores de dependências atualizada pelo iniciador.

A linha i de MVD contém o vetor de dependências de p, informação recebidas com a resposta ao bloqueio enviada por p.

Quando o iniciador recebe mensagens de resposta ao bloqueio de todos os processos, deve verificar se as precedências foram estabelecidas no ultimo intervalo de checkpoints dos processos.

Assim, a matriz MVP é atualizada.

MVP, matriz de vetores de participantes atualizada pelo iniciador.

A linha i de MVP contém o vetor de participantes de p, informação recebida com a resposta ao bloqueio enviada por p.

O iniciador verifica quais são os participantes de sua construção consistente da seguinte maneira, repita até que os valores de MVP não se alterem respostas, vetor mantido pelo iniciador para detecção da terminação da construção consistente.

Início da construção consistente Um processo p, ao iniciar uma construção consistente, armazena um checkpoint provisório.

Se p não recebeu nenhuma mensagem no ultimo intervalo de checkpoints, o checkpoint provisório é transformado em permanente e a construção consistente é encerrada.

Caso contrário, p fica bloqueado e faz um broadcast da mensagem de bloqueio.

Recepção da mensagem de bloqueio Quando um processo recebe uma mensagem de bloqueio, fica bloqueado e envia o seu vetor de dependências VD e seu vetor de participantes VP ao iniciador por meio da mensagem de resposta ao bloqueio.

Recepção da mensagem de resposta ao bloqueio O iniciador p constrói as matrizes MVD e MVP a partir dos vetores VD e VP, respectivamente, recebidos de todos os processos.

Após receber mensagens de resposta ao bloqueio de todos os processos, p utiliza as matrizes MVD e MVP para selecionar os participantes de sua construção consistente.

Após executar os cálculos descritos anteriormente, se entrada i do vetor MVP é igual a 1, então p envia uma mensagem de requisição a p.

Caso contrário, p envia uma mensagem de liberação a p.

Recepção da mensagem de requisição Todo processo que recebe uma mensagem de requisição, salva um checkpoint provisório e envia uma mensagem de resposta ao iniciador.

Recepção da mensagem de resposta O iniciador, após receber uma mensagem de resposta de cada um dos participantes, passa para a ultima fase de sua construção consistente, transforma seu checkpoint provisório em permanente, envia uma mensagem de liberação para todos os participantes e volta a processar a aplicação.

Recepção da mensagem de liberação Todo processo que recebe uma mensagem de liberação, transforma seu checkpoint provisório em permanente, fica desbloqueado voltando à sua computação normal.

A descrição do protocolo Broad-minimal é apresentada pelo Protocolo 4 1 Consideramos que todo procedimento deste algoritmo é executado de forma atômica.

Uma possível execução deste protocolo é ilustrada.

Neste cenário, a construção consistente iniciada por p2 é encerrada após p2 salvar um checkpoint, pois p2 não recebeu mensagens no ultimo intervalo de checkpoints e portanto não tem participantes.

A construção consistente de p0 é iniciada quando p0 salva um checkpoint e faz um broadcast da mensagem de bloqueio.

Ao receber a mensagem resposta ao bloqueio de todos os processos, p0 possui as matrizes de Vetores de Dependências MVD e de Vetores de Participantes MVP.

Exemplo de padrão gerado pelo protocolo Broad-minimal.

Para obter um número minimal de processos participantes, o iniciador desconsidera as precedências estabelecidas antes do ultimo intervalo de checkpoints de cada processo analisando a matriz MVD.

No exemplo, temos MVP, o que indica que a dependência conhecida por p1 foi estabelecida em um intervalo anterior ao ultimo intervalo de checkpoints de p2 e portanto, deve ser desconsiderada.

Para determinar o conjunto de seus participantes, p0 multiplica recursivamente seu vetor de participantes MVP pela matriz de vetores de participantes MVP até que não haja mudança no vetor de participantes.

Este cálculo feito pelo iniciador p0 é descrito.

Ao final da multiplicação das matrizes, temos como resultado que p1 é participante da construção consistente iniciada por p0 e portanto, p0 envia uma mensagem de requisição a p1 e envia mensagens de liberação aos outros processos.

Prova de Correção Nesta seção, mostramos que o protocolo Broad-minimal é correto e é minimal.

Matrizes construídas pelo iniciador.

Lema 1 No protocolo Broad-minimal, caso o iniciador, após atualizar MVP, obtenha como resultado MVP = 1, então p enviou uma mensagem m após o seu ultimo checkpoint e p recebeu m no seu ultimo intervalo de checkpoints.

Prova, Vamos supor que c é o ultimo checkpoint de p.

No protocolo Broad-minimal, o processo iniciador recebe os vetores de dependências de todos os processos.

O vetor VP indica de quais processos p recebeu mensagem após o seu ultimo checkpoint, ou seja, MVP = 1 se p enviou uma mensagem m e p recebeu m no seu ultimo intervalo de checkpoints.

Se c não fosse o ultimo checkpoint de p, essa precedência seria desconsiderada pelo iniciador (MVP 0) pois o índice do ultimo checkpoint de p seria maior do que o índice de p conhecido por p (MVD).

Portanto, o checkpoint c é o ultimo checkpoint de p.

Lema 2 No protocolo Broad-minimal, MVP = 1 se, e somente se, c c, onde c é o ultimo checkpoint de p e c é o checkpoint provisório do iniciador p.

Prova, Seja c o checkpoint salvo pelo iniciador p e seja c o ultimo checkpoint salvo por p.

Necessidade, Vamos provar que se MVP = 1, então c c.

Vamos supor que MVP e MVP.

Base (k = 0), Pelo Lema 1, p enviou uma mensagem m para p após c e p recebeu m durante o seu ultimo intervalo de checkpoints.

Assim, c c e portanto c c Passo (k > 0), Suponha que após k-1 passos da multiplicação, o valor de MVP foi c.

No passo k, se MVP = 1.

Portanto, p enviou uma mensagem para p após ce p recebeu m durante o seu ultimo intervalo de checkpoints.

Assim, podemos concluir que c c.

Suficiência, Vamos provar que se c c então MVP = 1.

Sabemos que se c c então existe uma sequência de mensagens m1, mk tal que m1 foi enviada por p após c e m foi recebida por p antes de c.

Base (k = 1), m1 foi enviada por pa após c e recebida por p antes de armazenar c.

Portanto, p anotou no seu vetor de participantes que recebeu uma mensagem de p no seu ultimo intervalo e a matriz MVP = 1.

Sabemos que a união dos checkpoints iniciais representa um checkpoint global consistente.

Desta forma, para provar que o protocolo é correto, basta provar que após a execução de uma construção consistente, a união dos ultimos checkpoints de cada processo formará um novo checkpoint global consistente.

Suponha que uma invocação do protocolo Broad-minimal foi iniciada a partir de um checkpoint global consistente.

Imediatamente após o fim desta construção consistente, a união dos ultimos checkpoints de cada processo formará um novo checkpoint global consistente.

Prova, Sabemos que os ultimos checkpoints dos processos que não armazenaram checkpoints durante a construção consistente são consistentes.

Pelo Lema 2, se existe zigzag path entre o ultimo checkpoint de um processo p e o checkpoint do iniciador, então MVP = 1 e portanto, p envia uma mensagem de requisição para p e p salva um checkpoint durante sua construção consistente.

Além disso, não existe zigzag path entre o ultimo checkpoint c de um processo não participante p e um processo participante dessa construção consistente, pois senão c z-precede o checkpoint do iniciador e p deveria também ser participante.

Podemos concluir portanto que não existe zigzag path entre o ultimo checkpoint de cada processo formando assim um checkpoint global consistente.

Para provar que o protocolo Broad-minimal é minimal, basta provar que um processo p armazena um checkpoint durante a construção consistente de p apenas se existe uma zigzag path entre o ultimo checkpoint de p salvo antes da construção consistente de p e o checkpoint do iniciador p.

No protocolo Broad-minimal, esta é a condição para p ser participante da construção consistente de p (Lema 2).

Portanto, o protocolo Broad-minimal é minimal.

O protocolo Broad-minimal termina corretamente uma construção consistente.

Prova, O iniciador envia uma mensagem de requisição para todos os processos participantes de sua construção consistente e uma mensagem de liberação aos outros processos.

Cada participante, após armazenar um checkpoint, envia uma mensagem de resposta ao iniciador.

O iniciador, ao receber mensagens de respostas de todos os participantes envia uma mensagem de liberação a cada participante.

Portanto, todos os processos da aplicação recebem em algum momento uma mensagem de liberação e voltam à sua computação normal.

A maioria dos protocolos minimais são propostos para permitir um unico iniciador a cada instante sendo extensíveis, por meio de diferentes estratégias, para permitir a presença de iniciadores concorrentes.

O protocolo de Koo e Toueg, por exemplo, aborta uma das construções consistentes toda vez que mais de um iniciador inicia sua construção consistente concorrentemente.

Leu e Bhargava propõem a construção de um checkpoint global consistente a partir da intersecção dos checkpoints salvos pelos processos envolvidos.

Outra opção para permitir iniciadores concorrentes é a implementação do protocolo que obtém como resultado um checkpoint global consistente a partir da união dos checkpoints salvos durante as construções consistentes concorrentes.

As características descritas para os protocolos minimais com um unico iniciador também são válidas na presença de iniciadores concorrentes.

Nesta Seção, avaliamos e descrevemos algumas considerações adicionais que devem ser respeitadas pelos protocolos síncronos minimais na presença de iniciadores concorrentes.

Na presença de iniciadores concorrentes, é interessante identificar de qual construção consistente uma determinada mensagem de controle faz parte.

Na fase de requisições, se um processo recebe duas mensagens de controle de duas construções consistentes concorrentes, o processo deve salvar apenas um checkpoint, porém deve propagar as mensagens de requisição para cada uma das construções consistentes.

Por exemplo, o processo p2 recebe uma mensagem de requisição de p1 e propaga a mensagem de requisição para p3.

Posteriormente, p2 recebe uma mensagem de requisição de p0 e não salva um checkpoint pois o seu ultimo checkpoint não é conhecido por p0.

Nesse momento, se p2 apenas envia uma mensagem de resposta para p0, p0 pode concluir sua construção consistente antes de ter obtido um checkpoint global consistente, pois a mensagem de requisição enviada por p2 pode não ter sido recebida por p3.

Inconsistência, p2 não repropaga mensagem de requisição.

Para evitar esse problema, p2, ao receber a mensagem de requisição de p0, deve repropagar a mensagem de requisição para p3 incluindo p3 como participante da construção consistente de p0 e portanto p0 não deve encerrar sua construção consistente antes de receber uma mensagem de requisição de p3 garantindo o checkpoint global consistente.

Note que não basta p2 enviar uma mensagem de resposta para p0 incluindo 3 como participante sem enviar uma mensagem de requisição para p3, pois p3 também pode incluir outros participantes para essa construção consistente.

Analisando o cenário descrito acima, sabemos que se um processo p recebe duas mensagens de requisição de diferentes construções consistentes, este receberá também duas mensagens de liberação.

Notamos que, como o processo p repropaga as mensagens de requisição, quando p recebe uma mensagem de liberação da construção consistente iniciada por p, todos os processos que p incluiu como participantes já enviaram mensagens de resposta para p e portanto, possuem checkpoints consistentes com o checkpoint salvo Repropagação das mensagens de requisição.

Portanto, p não necessita aguardar por todas as mensagens de liberação de todas as construções consistentes que participa para ficar desbloqueado.

Os processos p2 e p3 ficam desbloqueados ao receberem a mensagem de liberação de p1, ou seja, antes de receberem a mensagem de liberação de p0.

A unica precaução que devé ser tomada na fase de liberações é na recepção de mensagens atrasadas.

Se um processo recebe uma mensagem de liberação que indica a conclusão de uma construção consistente que inclui um checkpoint anterior ao seu ultimo checkpoint, então essa mensagem devé ser ignorada.

A minimalidade no número de checkpoints pode ser garantida se, na ocorrência de execuções concorrentes em um instante de tempo, cada processo envolvido salvar no máximo, um checkpoint.

O cenário ilustra a execução de duas construções consistentes iniciadas por p0 e p3.

Apenas o processo p1 é participante da construção consistente iniciada por p0 e portanto, os checkpoints salvos durante essa construção consistente e os checkpoints iniciais de p2, p3 e p4 formam o checkpoint global consistente construído por p0.

O processo p3 inicia uma construção consistente concorrente com a construção consistente de p0.

O processo p3 envia uma mensagem de requisição para p2 que salva um checkpoint e envia uma mensagem de requisição para p1.

Quando p1 recebe a mensagem de requisição de p2, p1 está bloqueado (já está participando de outra construção consistente) e possui um checkpoint não conhecido por p2.

Portanto, p1 pode aproveitar o seu ultimo checkpoint salvo para fazer parte também da construção consistente iniciada por p3.

Neste caso, p1 apenas envia uma mensagem de resposta ao iniciador p.

Note que, como vimos na seção anterior, esse seria o caso em que um processo deve repropagar mensagens de requisição, porém, p1 não necessitou enviar nenhuma mensagem desse tipo.

Outra observação é que mesmo com as duas construções consistentes, o processo p4 não necessitou salvar checkpoint, ou seja, apenas um número minimal de processos salvam checkpoints em cada construção consistente em execução.

Quando am-bas as construções consistentes terminam, a união dos checkpoints globais consistentes construídos pelas construções consistentes forma um checkpoint global consistente.

Minimalidade na presença de iniciadores concorrentes.

O protocolo VD-minimal é um protocolo síncrono minimal baseado na abordagem em níveis e permite iniciadores concorrentes.

Este protocolo utiliza vetores de dependências para rastrear as precedências entre os checkpoints do sistema e garantir um número minimal de checkpoints na construção de checkpoints globais consistentes.

Além disso, utilizamos um novo mecanismo de detecção de terminação que requer um número menor de mensagens de controle comparado aos protocolos similares existentes na literatura.

O mecanismo de terminação descrito nesta tese corrige um problema encontrado no artigo.

O protocolo VD-minimal utiliza vetores de dependências para capturar as precedências causais entre os checkpoints dos processos.

Quando um processo inicia sua construção consistente, verifica para quais processos deve propagar mensagens de requisição de acordo com as precedências causais estabelecidas no seu ultimo intervalo de checkpoints.

As mensagens de requisição são propagadas pelos processos participantes de forma semelhante ao iniciador.

Todo processo que recebe uma mensagem de requisição pode salvar um checkpoint provisório e deve enviar uma mensagem de resposta ao iniciador.

O iniciador, ao receber uma mensagem de resposta de cada participante da construção consistente, encerra a execução do protocolo enviando uma mensagem de liberação aos participantes.

Esta implementação de detecção de terminação necessita de O(n) mensagens de respostas, enquanto outros mecanismos utilizados em protocolos semelhantes requerem On2 mensagens na fase de respostas, onde representa o número de construções consistentes.

A seguir, descrevemos cada procedimento do protocolo.

Variáveis do processo As variáveis utilizadas por este protocolo são descritas a seguir, Início da construção consistente Um processo p, ao iniciar uma construção consistente C, armazena um checkpoint provisório, incrementa o índice do seu checkpoint e atualiza o seu vetor de participantes VP.

Se p não possui participantes, C é encerrada.

Caso contrário, p envia uma mensagem de requisição para cada um dos participantes e fica bloqueado.

Cada mensagem de requisição propaga o índice do iniciador p (reqiind) e seu VP.

Recepção da mensagem de requisição Ao receber uma mensagem de requisição de p, o processo p, se não está bloqueado e p conhece o índice atual de p, então p armazena um checkpoint provisório, fica bloqueado, e propaga mensagens de requisição aos seus participantes não conhecidos por p, se está bloqueado e p conhece o índice do seu ultimo checkpoint permanente, então p já participa de uma construção consistente.

Neste caso, se p não conhece o índice do iniciador de C, então p deve repropagar mensagens de requisição para os seus participantes não conhecidos por p (Seção 4 2 1).

Para qualquer outro caso, p apenas atualiza a informação do iniciador de C, se necessário.

Após analisar a necessidade em armazenar um checkpoint provisório, p envia uma mensagem de resposta ao iniciador p com o seu VP.

Recepção da mensagem de resposta A terminação do protocolo é garantida utilizando-se dois vetores, VP (que indica o índice do checkpoint dos processos participantes da construção consistente) e respostas (que indica o índice do checkpoint dos processos que já enviaram mensagens de resposta ao iniciador).

Quando p recebe uma mensagem de resposta de p, p inclui no seu vetor VP todos os participantes conhecidos por p e anota que já recebeu uma mensagem de resposta de p no vetor respostas.

Quando o vetor respostas tem valores maiores ou iguais ao vetor VP para todas as entradas, todos os participantes já armazenaram os checkpoints com o índice esperado e p recebeu mensagens de respostas de todos eles.

Então, p transforma se checkpoint provisório em permanente, envia mensagens de liberação para todos os processos participantes, atualiza o vetor perm VD e fica desbloqueado.

Recepção da mensagem de liberação Todo processo que recebe uma mensagem de liberação, transforma seu checkpoint provisório em permanente e atualiza as variáveis de forma semelhante ao iniciador e fica desbloqueado.

A descrição do protocolo VD-minimal é apresentada pelo Protocolo 4 2 Consideramos que todo procedimento deste algoritmo é executado de forma atômica.

A versão simplificada deste protocolo para apenas um unico iniciador a cada instante de tempo foi originalmente chamada de VR-minimal simples.

Este código apresenta um erro que foi corrigido na Seção B4.

Não existem participantes para o iniciador p0 e sua construção consistente é encerrada sem a necessidade de propagar mensagens de controle.

O iniciador p3 grava um checkpoint provisório e envia mensagens de requisição para os seus participantes p1 e p2.

O processo p1, ao receber uma mensagem de requisição de p3, grava um checkpoint provisório pois req VP, propaga uma mensagem requisição para o seu participante p0 e envia uma mensagem de resposta para o iniciador p3.

De forma semelhante, o processo p2 salva um checkpoint, envia uma mensagem de requisição para p0 e uma mensagem de resposta para p3.

O processo p0, ao receber a mensagem de requisição de p1, apenas atualiza o índice do iniciador pois req VP e envia uma mensagem de resposta ao iniciador p3.

A mensagem de requisição enviada por p2 é ignorada por p0 pois p0 conhece o índice do iniciador naquele instante, o que implica que 0 já enviou uma mensagem de resposta ao iniciador.

O iniciador, após receber respostas de todos os processos participantes, retorna-lhes uma mensagem de liberação.

Ilustramos a execução do protocolo VD-minimal na presença de iniciadores concorrentes.

Neste cenário, p0 salva um checkpoint ao receber uma mensagem de requisição de p1.

Quando p1 recebe a mensagem de requisição de p2, p1 repropaga a mensagem de requisição para p0.

Já quando p1 recebe a mensagem de requisição de p, p1 apenas envia uma mensagem de resposta ao iniciador p3, pois o ultimo checkpoint conhecido por p3 é anterior ao ultimo checkpoint salvo antes das construções consistentes correntes de p1.

Neste caso, p1 descarta a mensagem de liberação de p3 e fica bloqueado aguardando pela mensagem de liberação de p2, ou pela mensagem de resposta de p0.

Protocolo VD-minimal na presença de iniciadores concorrentes.

Lema 3 Se não existe nenhuma construção consistente na fase de liberações, então o conjunto dos checkpoints permanentes dos processos forma um checkpoint global consistente.

Prova, Sabemos que o checkpoint inicial é um checkpoint permanente.

Pelo protocolo VD-minimal, um checkpoint permanente é removido somente quando um novo checkpoint permanente é salvo em memória estável, o que implica que todo processo possui um checkpoint permanente.

Vamos supor que c é o checkpoint permanente de p e cé o checkpoint permanente de p e c c.

Sabemos também que p salvou o checkpoint c durante uma construção consistente C.

Portanto, p é participante de C e quando salvou o checkpoint c como provisório, propagou uma mensagem de requisição para p, pois p capturou informações sobre c no seu ultimo intervalo de checkpoints.

Portanto, p também é um processo participante de C.

Mas como não há construção consistente na fase de liberações, C está encerrada e portanto, p deveria ter salvo um checkpoint c +1 posterior a c durante C e c +1 deve ser um checkpoint consistente com c.

O protocolo VD-minimal garante que, a qualquer momento, existe um checkpoint global consistente formado por checkpoints estáveis.

Sabemos que se nenhuma construção consistente está em andamento, então os checkpoints permanentes dos processos formam um checkpoint global consistente.

Vamos então supor que existe pelo menos uma liberação pendente, ou seja, o processo p não recebeu a mensagem de liberação e possui um checkpoint permanente c inconsistente com os checkpoints permanentes dos demais processos.

Mas se p é participante de uma construção consistente C em fase de liberações, então p possui um checkpoint provisório consistente com os checkpoints salvos durante C.

Portanto, para todo processo que ainda não recebeu mensagem de liberação, basta trocar o checkpoint permanente pelo provisório correspondente.

Na presença de um unico iniciador a cada instante de tempo, o protocolo VD-minimal é minimal.

Seja c o checkpoint salvo pelo iniciador p e seja co ultimo checkpoint dé p armazenado antes da construção consistente C de p.

Um protocolo minimal induz um processo p a salvar o checkpoint c +1 se, e somente se, existe uma zigzag path de c a c (c c ).

Sabemos que se existe uma zigzag path entre o ultimo checkpoint de p c a c, então p armazena o checkpoint c +1 durante C, pois quando C encerra, os checkpoints salvos durante C são consistentes.

Para provar que o protocolo VD-minimal é minimal, basta provar que apenas os processos cujo ultimo checkpoint forma uma zigzag path com o checkpoint do iniciador armazenam checkpoint durante C.

Por contradição, vamos supor que p salva um checkpoint c +1 durante C, mas c 6 c.

Vamos supor também que p armazena c +1 durante C.

Se um processo p é incluído como participante quando p salva c +1, então uma mensagem m foi enviada por p e recebida por p antes de c +1.

Se m foi enviada por p após o armazenamento de c, então c c.

Caso contrário, a informação conhecida por p sobre p é menor que e portanto, p não salva um checkpoint durante C.

O protocolo é encerrado quando todos os participantes da construção consistente recebem uma mensagem de liberação do iniciador.

O iniciador por sua vez, só envia mensagens de liberação quando todos os participantes enviam-no mensagens de resposta.

O iniciador detecta que a construção consistente pode ser encerrada quando seu vetor de respostas possui índices maiores ou iguais aos conhecidos pelos participantes.

Sabemos que todo processo participante envia uma mensagem de resposta ao iniciador.

Para provar que o protocolo termina corretamente basta provar que o iniciador conhece todos os participantes de sua construção consistente antes de enviar as mensagens de liberação.

O protocolo VD-minimal termina corretamente uma construção consistente.

Prova, Suponha que o iniciador p encerrou sua construção consistente antes do participante p salvar um checkpoint consistente com o checkpoint de p.

O processo p portanto recebeu uma mensagem de requisição de um processo p que é participante conhecido por p.

Então, p recebe uma mensagem de resposta de p antes de encerrar a construção consistente.

Mas a recepção da mensagem de resposta de p faz com que p inclua no seu vetor de participantes o índice do checkpoint de p conhecido por p.

Neste caso, p não passa para a fase de liberações enquanto não recebe uma mensagem de resposta de p com a informação de um índice de checkpoint maior ou igual ao índice conhecido por p.

Nos protocolos síncronos, o armazenamento de um checkpoint requisitado pela aplicação implica na construção de um novo checkpoint global consistente mais recente até aquele momento formado por checkpoints estáveis.

Em aplicações com um número excessivo de troca de mensagens, pode haver comunicação de todos os processos para todos os processos durante um intervalo de checkpoints.

Neste caso, todos os processos deverão salvar checkpoints durante uma construção consistente.

No entanto, se só um subgrupo de processos se comunicou com o processo iniciador do protocolo síncrono no seu ultimo intervalo de checkpoints, o novo checkpoint global consistente pode ser construído mesmo que apenas os processos desse subgrupo armazenem checkpoints durante a construção consistente, pois os outros processos já possuem checkpoints estáveis consistentes com o checkpoint salvo pelo iniciador.

Quando somente um número minimal de processos é induzido a armazenar checkpoints durante uma construção consistente, o protocolo é dito síncrono minimal.

Os protocolos minimais reduzem o custo de armazenamento de checkpoints, porém precisam ser bloqueantes, ou seja, os processos envolvidos devem permanecer bloqueados durante uma construção consistente.

Na literatura, existem duas abordagens para a construção de protocolos síncronos minimais, em níveis e, broadcast.

Na abordagem em níveis, o iniciador envia mensagens de requisição a um subgrupo de participantes que recursivamente propagam mensagens de requisição para outros processos até que todos os participantes da construção consistente recebam a mensagem de requisição.

Notamos na literatura, um esforço em tentar reduzir o número de mensagens de controle trocadas durante uma construção consistente nos protocolos com a abordagem em níveis.

Na abordagem broadcast, todos os processos são bloqueados num primeiro momento até que o iniciador decida quais os processos são participantes de sua construção global.

Esta abordagem tem como objetivo a redução do tempo de bloqueio dos processos durante uma construção consistente.

Os protocolos minimais requerem a propagação de informação de controle com as mensagens da aplicação e mensagens de controle adicionais durante uma construção consistente.

Para reduzir o custo nas mensagens da aplicação, alguns protocolos propostos na literatura anotam a recepção de mensagens, mas não o intervalo de origem dessas mensagens.

Porém, provamos que estes protocolos não possuem informação suficiente para serem minimais.

Notamos que a redução no número de mensagens de controle trocadas durante uma construção consistente depende da maneira como as informações de dependência entre checkpoints são capturadas (afeta diretamente na maneira como as mensagens de requisição são propagadas) e do mecanismo de detecção de terminação do escolhido (determina para quais processos as mensagens de resposta e liberação devem ser enviadas).

Neste capítulo, propomos e descrevemos dois protocolos síncronos minimais, Broadminimal, baseado na abordagem broadcast e, D-minimal, baseado na abordagem em níveis.

Em nosso conhecimento, o unico protocolo síncrono minimal com abordagem broadcast é o Broad-minimal.

A idéia do broadcast na construção de protocolos síncronos minimais foi proposta originalmente por Cao e Singhal.

Porém, o protocolo proposto por eles, apesar de construir checkpoints globais consistentes, não é minimal, conforme demonstrado neste capítulo.

O protocolo VD-minimal utiliza vetores de dependências para capturar as dependências entre checkpoints e garantir a minimalidade no número de checkpoint de uma construção consistente.

Além disso, propomos um novo mecanismo de detecção de terminação que necessita propagar um vetor de inteiros, mas reduz o número de mensagens de respostas para O(n), onde representa o número de construções consistentes.

Este protocolo permite a presença de iniciadores concorrentes.

O problema de baixo desempenho dos protocolos minimais causado pelo bloqueio da aplicação foi amenizado pelos protocolos de checkpointing síncronos não-bloqueantes que permitem o progresso da computação durante uma construção consistente.

O relaxamento da condição de bloqueio impede a construção de protocolos minimais.

Uma solução para este problema é o uso de checkpoints mutáveis que podem ser salvos em memória não-estável com o objetivo de garantir a minimalidade no número de checkpoints em memória estável.

Notamos porém que esta minimalidade está diretamente relacionada ao momento em que os checkpoints mutáveis são armazenados e mostramos que, mesmo na presença de um unico iniciador a cada instante de tempo, é impossível garantir o número mínimo de checkpoints estáveis durante toda a execução da aplicação.

Além disso, provamos que é impossível desenvolver um protocolo síncrono não-bloqueante que salva um número minimal de checkpoints estáveis na presença de iniciadores concorrentes.

Com base na análise realizada, propomos dois novos protocolos síncronos não-bloqueantes baseados em protocolos quase-síncronos de classes distintas, RDT-NBS baseado no protocolo FDAS (Seção 3 2 2) e BCS-NBS baseado no protocolo BCS (Seção 3 2 3).

Esses protocolos permitem a presença de iniciadores concorrentes, reduzem o número de checkpoints estáveis a cada construção consistente, mas diferem no mecanismo de armazenamento de checkpoints mutáveis.

Um experimento inicial de simulação foi realizado por meio da implementação desses protocolos com o uso do ChkSim.

As próximas seções estão divididas como a seguir.

Descreve as características de um protocolo síncrono não-bloqueante.

Discute a questão da minimalidade no número de checkpoints para esta classe de protocolos.

Em seguida, descrevemos o protocolo RDT-NBS na Seção 53, o BCS-NBS na Seção 54 e os resultados de simulação são apresentados na Seção 5 5 Um checkpoint básico é requisitado no momento de interesse da aplicação.

Se um protocolo de checkpointing síncrono permite apenas um unico iniciador a cada instante, um processo poderá não ter permissão para salvar o seu checkpoint no momento que necessita por existir uma outra construção consistente em andamento.

Além disso, todo protocolo que permite apenas um unico iniciador deve implementar um mecanismo para controlar qual processo pode iniciar uma construção consistente e determinar quando todas as mensagens de controle enviadas durante essa execução foram entregues.

Nesta seção, analisamos as características dos protocolos síncronos não-bloqueantes que reduzem o número de checkpoints salvos durante uma construção consistente na presença de um unico iniciador a cada instante de tempo e de iniciadores concorrentes.

Os principais aspectos que devem ser considerados ao se desenvolver protocolos síncronos não-bloqueantes com um unico iniciador a cada instante são descritos a seguir.

E importante ressaltar que estamos considerando protocolos que têm como objetivo induzir o menor número de checkpoints durante uma construção consistente.

Como visto na Seção 3 3 2, os protocolos de checkpointing síncronos não-bloqueantes propagam informação de controle com as mensagens da aplicação para que, quando necessário, um checkpoint seja induzido imediatamente antes de receber uma delas evitando inconsistências.

Esses checkpoints poderão vir a fazer parte de um checkpoint global consistente formado por uma construção consistente.

Portanto, quando um processo, recebe uma mensagem de requisição, deve primeiro verificar se já possui um checkpoint consistente para esta construção consistente.

Para reduzir o custo de armazenamento em memória estável, os checkpoints induzidos por mensagens da aplicação podem ser salvos como checkpoints mutáveis.

Um checkpoint mutável é armazenado em memória não-estável e é transferido para memória estável somente se faz parte de um checkpoint global consistente construído durante uma construção consistente.

Quando o processo que possui um checkpoint mutável não recebe mensagens de requisição e portanto, não necessita do checkpoint mutável para nenhuma construção consistente, então este é descartado.

P0 salva um checkpoint provisório ao receber a mensagem de requisição de p1 e envia uma mensagem da aplicação m para p.

O processo p2 salva um checkpoint mutável antes de receber m.

Quando p2 recebe a requisição de p1, p2 transfere c para memória estável e este checkpoint é usado para formar o checkpoint global consistente da construção consistente iniciada por p1.

Checkpointing síncrono com checkpoints mutáveis.

O efeito avalanche ocorre quando um checkpoint induz outro checkpoint que induz um terceiro checkpoint e assim sucessivamente, podendo não ter fim.

Quando as regras do protocolo de checkpointing permitem que um checkpoint mutável induza outro checkpoint mutável, então pode ocorrer o efeito avalanche de checkpoints mutáveis.

Cao e Singhal eliminam esta possibilidade permitindo a cada processo salvar no máximo um checkpoint mutável durante uma construção consistente e nenhum checkpoint mutável é induzido se não existe uma construção consistente em andamento.

Efeito avalanche de checkpoints mutáveis.

Como visto na Seção 35, a coleta de lixo otima em protocolos síncronos é bem simples bastando remover os checkpoints salvos anteriormente aos checkpoints pertencentes a construção consistente encerrada.

Nos protocolos síncronos não-bloqueantes com um unico iniciador, a coleta de lixo deve remover, não somente os checkpoints dos participantes de uma construção consistente, mas também os checkpoints mutáveis que foram induzidos e não foram aproveitados para a formação do checkpoint global consistente construído.

Apresenta uma construção consistente iniciada por p1 que, após encerrar, elimina os checkpoints c0 e c0 pois p1 e p2 salvaram novos checkpoints que fazem parte desta construção consistente e p0 removeu c 1 pois este foi induzido, mas não foi utilizado.

Note que c 1 poderia ter sido utilizado para a formação do checkpoint global consistente que inclui o checkpoint iniciador p1, mas como temos como objetivo salvar o menor número possível de checkpoints estáveis durante uma construção consistente, o checkpoint c 1 é ignorado.

Na ultima fase de execução do protocolo de Cao e Singhal, a mensagem de liberação é enviada para todos os processos para que os processos não participantes da execução eliminem, caso necessário, seus checkpoints mutáveis.

Coleta de lixo.

Os principais aspectos que devem ser considerados ao se desenvolver protocolos síncronos não-bloqueantes que permitem iniciadores concorrentes são descritos a seguir.

E importante ressaltar que estamos considerando protocolos que têm como objetivo reduzir o número de checkpoints durante uma construção consistente.

Propagação das Mensagens de Requisição.

Em um protocolo síncrono não-bloqueante com iniciações concorrentes é natural que, em um determinado instante, dois processos iniciadores estejam com suas construções consistentes em andamento.

Um processo, ao receber duas mensagens de requisição de construções consistentes distintas, deve definir para cada uma delas, o conjunto de processos para os quais deve propagar mensagens de requisição.

Nenhuma das construções consistentes deve ser encerrada antes que todos os processos participantes armazenem seus checkpoints.

Por exemplo ao receber uma mensagem de requisição de p, salva um checkpoint provisório e envia uma mensagem de requisição para p1.

Quando 2 recebe a mensagem de requisição de p0, p2 já possui um checkpoint estável consistente com o checkpoint de p0, portanto não é necessário p2 armazenar outro checkpoint provisório.

Neste momento, se p2 simplesmente envia uma mensagem de resposta para p, do ponto de vista de p0, o unico processo participante em sua execução é o processo 2 e portanto p0 passa para a fase de liberações.

Apesar de p0 concluir sua construção consistente, não existe um checkpoint global consistente que inclui o checkpoint salvo por 0 pois p1 ainda não recebeu a mensagem de requisição enviada por p2.

O conjunto representa um checkpoint global inconsistente construído pelo iniciador p0.

Problemas na recepção concorrente de requisições distintas.

Vamos supor que p salvou o checkpoint c durante uma construção consistente C.

Quando p recebe uma mensagem de liberação correspondente à C, todos os processos para os quais p enviou mensagens de requisição devem possuir um checkpoint estável consistente com o c.

Uma maneira de prevenir que o protocolo encerre uma construção consistente precipitadamente na presença de múltiplos iniciadores é adiar o envio de uma mensagem de resposta ao iniciador se o processo já estiver aguardando uma mensagem de liberação de uma outra construção consistente em andamento.

Por exemplo, se o processo p2 aguardasse a mensagem de liberação de p3 para então enviar a mensagem de resposta para p0, tanto o iniciador p3 quanto o iniciador p0 encerrariam suas construções consistentes corretamente.

Esta solução porém, não é recomendada pois pode levar o sistema a um estado de deadlock.

P0 envia uma mensagem de requisição para p1 que salva um checkpoint provisório e envia uma mensagem de requisição para p2.

Já o processo p2 recebe uma mensagem de requisição do iniciador p3, salva um checkpoint provisório e envia uma mensagem de requisição para p1.

Quando p1 recebe a mensagem de requisição de p2, p1 espera pelo fim da construção consistente de p0 para enviar uma mensagem de resposta ao iniciador p3.

Da mesma forma, p2 espera pelo fim da construção consistente de p 3 para enviar resposta para p1.

Porém, o iniciador p0 não pode concluir sua construção consistente enquanto não receber uma mensagem de resposta de p2 e, p3 fica aguardando uma mensagem de resposta de p1.

Neste caso, p0 aguarda uma mensagem de resposta de p que por sua vez, aguarda uma mensagem de liberação de p3 que aguarda uma mensagem 2 de resposta de p1 que aguarda uma mensagem de liberação de p0, o que caracteriza uma situação de deadlock.

Deadlock na espera de liberação.

Para que não ocorra deadlock no sistema, sugerimos a repropagação das mensagens de requisição.

Isto é, um processo p, ao receber uma mensagem de requisição, verifica se deve salvar ou salvou um checkpoint provisório para o iniciador da mensagem de requisição.

A partir do checkpoint provisório, p deve (re) propagar mensagens de requisição para todos os processos que possuem checkpoints que precedem o seu checkpoint provisório desde o seu ultimo checkpoint permanente.

O processo p2, ao receber a mensagem de requisição de p0, deve repropagar a mensagem de requisição ao processo p 1 e então enviar uma mensagem de resposta para o processo p0.

Quando o processo p0 recebe a mensagem de resposta de p2, p0 não conclui sua construção consistente pois sabe que existe um outro processo participante do qual ainda não obteve resposta.

Assim, p1 salva um checkpoint ao receber a primeira mensagem de requisição e envia uma mensagem de resposta para cada mensagem de requisição recebida e os iniciadores p0 e p3 encerram corretamente suas construções consistentes.

O efeito avalanche de checkpoints mutáveis pode ocorrer independentemente se o protocolo permite ou não iniciadores concorrentes.

Note que o armazenamento de checkpoints mutáveis depende da regra adotada na recepção das mensagens da aplicação.

Se esta regra é conhecida (por exemplo, baseada em um protocolo quase-síncrono) é possível prever o seu comportamento.

Na presença de um unico iniciador a cada instante, cada processo necessita manter um checkpoint permanente e no máximo mais um checkpoint estável quando uma construção consistente está em andamento.

Porém, quando mais de uma iniciação concorrente é permitida, os processos necessitam armazenar uma lista de checkpoints estáveis que conterá no máximo, um checkpoint provisório por construção consistente.

Portanto, se considerarmos que um processo só inicia uma construção consistente após o término de sua construção consistente anterior, então o número máximo de checkpoints provisórios no sistema é O(n ).

Para cada processo, é necessário manter apenas um checkpoint permanente, pois quando um novo permanente é salvo, o anterior pode ser removido.

O processo p1 salva o seu primeiro checkpoint provisório para a construção consistente iniciada por p0.

Quando p1 recebe a mensagem de requisição de p2, p1 ainda não recebeu uma mensagem de liberação de p0 e portanto não pode transformar o seu checkpoint provisório em permanente, mas necessita armazenar outro checkpoint provisório para a construção consistente de p2.

Lista de checkpoints estáveis.

O processo envolvido deve ter informação suficiente para ignorar mensagens de requisição atrasadas.

Para ilustrar possíveis problemas, p3 salva um checkpoint provisório para a construção consistente de p0.

Quando p3 recebe a mensagem de requisição de p2, que também é uma requisição da construção consistente de p0, p3 não necessita armazenar outro checkpoint provisório.

Mas se p3 salvou o seu checkpoint permanente para a construção consistente de p4 e não possui informações suficientes para ignorar a mensagem de requisição enviada por p2, então temos dois resultados não adequados, p 3 estará armazenando mais que um provisório para a mesma construção consistente, mas um dos objetivos do protocolo é reduzir o número de checkpoints estáveis.

Se p3 salva um novo checkpoint provisório, p3 deve propagar a mensagem de requisição para p4, mas p3 já enviou uma mensagem de resposta para p0 quando armazenou o checkpoint provisório anterior e portanto, p0 pode concluir sua construção consistente antes da formação de um checkpoint global consistente.

Recepção de uma mensagem de requisição atrasada.

Cao e Singhal provaram que é impossível desenvolver um protocolo síncrono não-bloqueante que armazena um número minimal de checkpoints para cada construção consistente.

Eles introduzem o conceito de z-dependência para descrever essa prova e afirmam que esta não pode ser descrita utilizando somente o conceito de zigzag path introduzido por Netzer e Xu.

Na Seção 2 4 3, mostramos que esses dois conceitos estão relacionados.

Nesta Seção, descrevemos a prova da inexistência de um protocolo síncrono não-bloqueante e minimal utilizando apenas o conceito de zigzag paths.

Além disso, provamos também que não é possível garantir um número mínimo de checkpoints durante toda a execução da aplicação.

A participação de um processo em uma construção consistente se dá por meio do envio e recepção de mensagens de controle e/ou o armazenamento de checkpoints.

Chamamos de processo participante, o processo que envia e recebe mensagens de controle.

Lema 4 Seja p o iniciador de um protocolo não-bloqueante minimal e p e p dois processos que salvam novos checkpoints durante a construção consistente C iniciada por p.

Se p enviou uma mensagem m após ter salvo o checkpoint durante C e p recebeu m e ainda não armazenou um checkpoint durante C, então p deve armazenar um checkpoint imediatamente antes da recepção de m.

Prova, Por contradição, vamos supor que p salva um checkpoint durante a construção consistente C iniciada por p, após receber a mensagem m de p.

Sabemos que em um protocolo minimal, p salva um checkpoint durante uma construção consistente se seu ultimo checkpoint z-precede o checkpoint de p.

Portanto, se p salva seu checkpoint após processar m, nem o seu checkpoint anterior, nem o checkpoint salvo durante C fazem parte do checkpoint global consistente que contém o checkpoint do iniciador.

Ilustra um cenário em que p e p salvam checkpoints durante C e p não salva um checkpoint antes de receber a mensagem de p.

Note que, neste caso, p não possui checkpoint consistente com o checkpoint salvo pelo iniciador.

O processo p não possui checkpoint consistente com c.

Lema 5 Em um protocolo não-bloqueante e minimal, não há informação suficiente na recepção de uma mensagem m, enviada por um participante durante uma construção consistente C, para decidir se existe uma zigzag path entre o ultimo checkpoint do processo que recebeu m e o checkpoint salvo pelo iniciador de C.

Prova, Em um protocolo não-bloqueante, os processos não suspendem suas atividades durante uma construção consistente.

Suponha que o processo p, participante de uma construção consistente C, após armazenar seu checkpoint durante C, envia uma mensagem m para o processo p.

Sabemos que, em um protocolo minimal, o processo p deve salvar um checkpoint imediatamente antes de receber m somente se o ultimo checkpoint de p z-precede o checkpoint do iniciador de C (Lema 4).

Vamos provar que é impossível para p decidir, no momento da recepção de m, se deve ou não salvar um checkpoint para garantir minimalidade no número de checkpoints.

Vamos analisar o cenári onde o iniciador p envia uma mensagem m para p antes de encerrar sua construção consistente.

Temos que c 0 c 1 e portanto p deve armazenar um checkpoint imediatamente antes da recepção de m.

Já no caso do cenário, p não é participante da construção consistente de p pois p possui um checkpoint consistente com o checkpoint do iniciador que foi salvo antes da recepção de m2.

Portanto, pb não deve salvar um checkpoint na recepção da mensagem m.

Porém, p pode receber informações sobre os eventos p aaté o envio da mensagem m1 por informações de controle adicionados as mensagens da aplicação.

O que ocorre após o envio de m1 só seria conhecido por outros processos, inclusive por p, se p tivesse enviado uma mensagem com os eventos ocorridos após m1.

Mas no momento da recepção de m é impossível para pb saber se existe ou não um checkpoint armazenado por p a após o envio de m1 e antes da recepção de m2.

Inexistência de um protocolo não-bloqueante minimal.

Um protocolo não pode ser não-bloqueante e minimal.

Sabemos que um processo, ao receber uma mensagem durante uma construção consistente, precisaria saber se existe uma zigzag path a partir do seu ultimo checkpoint até o checkpoint salvo pelo iniciador.

Porém, pelo Lema 5 é impossível obter essa informação no momento da recepção da mensagem.

Portanto, um protocolo não pode ser não-bloqueante e minimal.

Os checkpoints mutáveis foram introduzidos para garantir a minimalidade no número de checkpoints estáveis em protocolos de checkpointing síncronos não-bloqueantes.

Checkpoints mutáveis são checkpoints que podem ser salvos em memória não-estável e reduzem o custo de transferência do estado para armazenamento estável (Seção 3 3 2).

Notamos que a minimalidade no número de checkpoints estáveis nos protocolos de checkpointing síncronos não-bloqueantes depende do momento em que os checkpoints mutáveis são salvos.

Por exemplo, nenhum checkpoint mutável foi salvo e portanto, quando p iniciou uma construção consistente, o protocolo minimal induziu novos checkpoints em p e p para formar um checkpoint global consistente.

Todas as zigzag paths não-causais são evitadas por meio da indução de checkpoints mutáveis e, portanto, p salvou um checkpoint mutável antes de receber uma mensagem de p.

Quando p recebe uma mensagem de requisição de p, p pode transformar esse mutável em estável e o protocolo minimal não induzirá um novo checkpoint em p.

Minimalidade no número de checkpoints estáveis.

Se todas as zigzag paths não-causais são evitadas, então cada execução de um protocolo de checkpointing síncrono não-bloqueante constrói um checkpoint global consistente mais à esquerda.

Porém, o armazenamento de checkpoint em um determinado instante de tempo pode reduzir a necessidade de checkpoints no futuro.

Assim, concluímos que a construção de um checkpoint global consistente por um protocolo síncrono não-bloqueante depende do momento em que os checkpoints mutáveis são salvos.

A seguir, provamos que não existe um protocolo síncrono não-bloqueante que garante um número mínimo de checkpoints durante toda a execução da computação distribuída.

A descrição desta prova utiliza uma abordagem semelhante ao proposto por Tsai e outros para os protocolos quase-síncronos RDT.

Nenhum protocolo de checkpointing síncrono não-bloqueante garante o número mínimo de checkpoints estáveis para todos os possíveis padrões de checkpoints e mensagens.

Armazena checkpoints mutáveis somente se uma construção consistente está em andamento, conforme proposto por Cao e Singhal.

Armazena checkpoints mutáveis para garantir a propriedade RDT, evitando todas as zigzag paths não-causais não duplicadas causalmente.

Devemos observar também que para cada construção consistente apenas um número minimal de checkpoints estáveis deve ser salvo.

Vamos considerar o cenário até o tempo t, ou seja, vamos analisar apenas a construção consistente iniciada por p0.

P1 e p2 devem salvar checkpoints estáveis para construir o checkpoint global consistente representado por 1, enquanto que apenas p1 deve transformar seu checkpoint mutável em estável para construir o checkpoint global consistente 3.

Assim, o armazenamento de um checkpoint mutável salvo, mesmo enquanto não havia nenhuma construção consistente em andamento, possibilitou o número mínimo de checkpoints.

Vamos agora analisar a execução após as construções consistentes iniciadas por p0 e por p3.

Note que p3 inicia sua construção consistente após o término da construção consistente de p0, ou seja, as iniciações não são concorrentes.

Mostra que os checkpoints salvos durante a construção consistente iniciada por p0 também são consistentes com o checkpoint salvo por p3.

Porém, p1 salvou o checkpoint antes da recepção de m e portanto, p1 e p2 devem salvar novos checkpoints durante a construção consistente iniciada por p3 para construir um checkpoint global consistente.

Impossibilidade do número mínimo de checkpoints estáveis.

Um protocolo síncrono salva um número minimal de checkpoints durante uma construção consistente C se, para cada checkpoint estável salvo durante C não existe um checkpoint estável anterior que possa fazer parte do checkpoint global consistente construído pela construção consistente.

Um protocolo síncrono não-bloqueante que permite iniciadores concorrentes e que tem como objetivo armazenar um número minimal de checkpoints estáveis deve considerar os checkpoints estáveis salvos pelos iniciadores concorrentes e os checkpoints salvos durante as construções consistentes.

Isto é, pode-se formar um unico checkpoint global consistente que inclui os checkpoints salvos pelos iniciadores das construções consistentes.

Portanto, para um mesmo padrão de checkpoints e mensagens, checkpoints globais consistentes diferentes podem ser construídos pelo protocolo na presença de um unico iniciador e com iniciadores concorrentes.

Mostra um cenário com os iniciadores p0 e p3, mas p0 inicia sua construção consistente somente após o término da construção consistente de p3.

Quando p1 recebe uma mensagem de liberação de p3, p1 pode remover o seu checkpoint mutável já que este não foi necessário para a construção consistente de p3.

Neste caso, p1 e p2 precisam salvar novos checkpoints para formar um checkpoint global consistente que inclui o checkpoint salvo pelo iniciador p0.

Minimalidade e um iniciador a cada instante.

Um cenário semelhante em que os iniciadores p0 e p3 iniciam suas construções consistentes concorrentemente, armazena um número minimal de checkpoints transformando o checkpoint mutável salvo por p1 em checkpoint provisório.

Note que o processo p1 salvou um checkpoint mutável para a construção consistente de p3 e recebe uma mensagem de requisição do iniciador p0.

Neste caso, p1 não necessita propagar uma mensagem de requisição para p2.

Representa o checkpoint global consistente inclui os checkpoints salvos pelos iniciadores e induz um número minimal de checkpoints.

Neste cenário, quando p1 recebe uma mensagem de requisição de p0, p1 deve decidir apenas com informação local entre armazenar um novo checkpoint provisório com as informações do iniciador p0 ou aproveitar um mutável salvo com informações de uma outra construção consistente em andamento.

Porém, concluímos que um processo não tem informação suficiente para tomar essa decisão e garantir um número minimal de checkpoints estáveis salvos para as construções consistentes concorrentes.

Minimalidade e iniciadores concorrentes.

Não existe um protocolo síncrono não-bloqueante que armazena um número minimal de checkpoints estáveis na presença de iniciadores concorrentes.

Prova, Esta prova é baseada no cenário em que um processo p possui dois checkpoints mutáveis e não tem informação suficiente para decidir qual checkpoint mutável deve transformar como estável para garantir um número minimal de checkpoints estáveis.

P salvou o checkpoint c aantes de receber uma mensagem da aplicação com informações sobre a construção consistente de p.

Da mesma forma, c b foi salvo ao receber informações sobre a construção consistente de p.

Quando p recebe a mensagem de requisição referente à construção consistente de p, se p opta em transferir para memória estável o checkpoint, c pode receber posteriormente uma mensagem de requisição da construção consistente de p e, neste momento, deverá transformar o checkpoint c b em estável.

Neste caso, seria melhor salvar c b como estável na recepção da mensagem de requisição de p e descartar ca.

Portanto, o protocolo não pode ser minimal transformando sempre c a em estável.

O processo p pode não receber uma mensagem de requisição da construção consistente de p.

Quando p transforma c b em checkpoint estável, p envia uma mensagem de requisição para todos os processos que possuem um checkpoint que precede c b induzindo novos checkpoints.

Porém, c b não z-precede o checkpoint salvo pelo iniciador p durante sua construção consistente.

Portanto, para este caso, um checkpoint global consistente com um número minimal de checkpoints é formado transformando-se c aem provisório e descartando c.

Assim, o protocolo também não pode ser minimal ao transformar sempre c b como estável.

No momento em que p recebe a mensagem de requisição de p, p não tem como saber se c b será necessário para a construção consistente iniciada por p.

Então, p não tem como decidir qual dos checkpoints (c a ou c ) salvar como provisório para garantir o número minimal de checkpoints para as construções consistentes concorrentes.

Portanto, não existe um protocolo síncrono não-bloqueante com um número minimal de checkpoints estáveis na presença de iniciadores concorrentes.

A idéia do protocolo RDT-NBS, proposto em, é adicionar mensagens de controle ao protocolo de checkpointing quase-síncrono FDAS (Fixed Dependency After Send) com o objetivo de desenvolver um protocolo de checkpointing síncrono não-bloqueante que utiliza checkpoints mutáveis.

No protocolo quase-síncrono FDAS, um processo não modifica seu vetor de dependências (VD) após enviar uma mensagem da aplicação garantindo assim a presença da propriedade RDT.

O protocolo RDT-NBS induz checkpoints mutáveis da mesma maneira que o FDAS induz checkpoints forçados, prevenindo a existência de zigzag paths não-causais entre checkpoints.

Além disso, o uso de VDs permite o rastreamento on-line das dependências entre checkpoints.

Escolhemos o protocolo quase-síncrono RDT chamado FDAS por sua simplicidade, porém RDT-NBS pode ser facilmente reescrito usando qualquer outro protocolo RDT.

Por exemplo, nas Seções C4 e C3 encontram-se os protocolos síncronos não-bloqueantes RDT-Minimal-NBS e RDT-Partner-NBS baseados nos protocolos quase-síncronos RDT-Minimal e RDT-Partner.

O protocolo FDAS é um protocolo quase-síncrono que possui a propriedade RDT.

Neste protocolo, um processo não altera o seu vetor de dependências após o envio de uma mensagem da aplicação durante um intervalo de checkpoints.

Uma otimização na condição de indução de checkpoints foi proposta em e sua descrição é apresentada na Seção 3 2 2 Em um padrão RDT, o checkpoint global consistente mínimo que contém um checkpoint c pode ser calculado a partir do vetor de dependências de c.

Quando um iniciador p salva um checkpoint provisório, p envia uma mensagem de requisição para todos os processos participantes.

Um processo p é participante de p se VD foi alterado desde o ultimo checkpoint permanente de p, ou seja, existe uma precedência causal entre um checkpoint permanente de p ao checkpoint provisório salvo por p (Seção 2 3 2).

Todo processo que recebe uma mensagem de requisição atende uma de três condições, já possui um checkpoint estável consistente com o checkpoint do iniciador, ou transforma um checkpoint mutável em provisório, ou salva um novo checkpoint provisório.

Em qualquer caso, uma mensagem de resposta deve ser enviada para p.

Quando p recebe uma mensagem de resposta de cada um dos seus participantes, p envia mensagens de liberação aos processos participantes finalizando sua construção consistente.

O protocolo RDT-NBS permite a presença de iniciadores concorrentes.

Neste protocolo, as mensagens de controle são enviadas do iniciador aos participantes e dos participantes ao iniciador, de forma direta, isto é, apenas o iniciador propaga mensagens de requisição e liberação para no máximo, n,1 processos participantes e cada processo participante envia exatamente uma mensagem de resposta ao iniciador.

Portanto, este protocolo necessita de no máximo O(n) mensagens de controle em cada uma das fases de checkpointing.

Além disso, o problema da repropagação das mensagens de requisição foi facilmente resolvido neste protocolo pois cada iniciador conhece todos os participantes de sua construção consistente.

E importante observar que na fase de liberações não é feito um broadcast da mensagem de liberação.

As variáveis utilizadas por este protocolo são descritas a seguir. 

Enviou, indica se o processo enviou pelo menos uma mensagem durante o intervalo de checkpoints corrente.

VD, vetor de dependências mantido pelo processo p para capturar as precedências causais entre checkpoints.

VP, vetor com os índices dos processos participantes atualizado pelo iniciador p a cada início de uma construção consistente.

Um processo p é inserido como participante da construção consistente pelo iniciador p se VD foi alterado desde o primeiro checkpoint permanente mantido por p.

Seja p o primeiro checkpoint permanente mantido p.

Então, VP se VD > pVD.

Para iniciar uma construção consistente, um processo p armazena um checkpoint provisório e envia mensagens de requisição para cada um dos seus participantes.

O conteúdo de VD é propagado com a mensagem de requisição enviada para p (reqind).

Quando um processo p recebe uma mensagem de requisição de p, p compara o seu índice atual com o índice da requisição.

Se req ind VD, então p salva um checkpoint provisório.

Senão, p procura pelo primeiro checkpoint com índice maior que reqind e, caso esse checkpoint seja um checkpoint mutável, ele é transformado em provisório.

Em qualquer um dos casos, p envia uma mensagem de resposta para p.

Um processo p processa uma mensagem de resposta apenas se a construção consistente que iniciou não foi encerrada, ou seja, se possui um checkpoint provisório com o índice da construção consistente.

O iniciador p, após receber uma mensagem de resposta de cada um dos seus participantes, transforma o seu checkpoint provisório em permanente, remove os checkpoints anteriormente salvos e envia uma mensagem de liberação para todos os participantes de sua construção consistente.

Um processo, ao receber uma mensagem de liberação, transforma o checkpoint correspondente em permanente e remove todos os checkpoints anteriores a ele.

A descrição do protocolo RDT-NBS é apresentada pelo Protocolo 5 1 Consideramos que todo procedimento deste protocolo é executado de forma atômica.

Um exemplo de execução do protocolo RDT-NBS é ilustrado.

Neste cenário, o iniciador p2 envia uma mensagem de requisição ao processo p3 e uma mensagem da aplicação para p1.

O processo p1 salva um checkpoint mutável imediatamente antes de processar a mensagem e então envia uma mensagem para p3.

O processo p3 recebe a mensagem de p1 e salva um checkpoint mutável antes de processar a mensagem.

Quando 3 recebe a mensagem de requisição de p2, p3 já possui um checkpoint mutável com índice igual ao índice conhecido por p2 e portanto, p3 transforma esse checkpoint mutável em provisório.

No final da construção consistente de p2, os checkpoints provisórios de p2 e 3 são transformados em permanentes e formam um checkpoint global consistente com os checkpoints iniciais de p0 e p1.

Na construção consistente de p0, os checkpoints mutáveis de p1 e p2 são transformados em provisórios e posteriormente em permanentes.

Note que o primeiro checkpoint mutável de p1 só é descartado quando o segundo é transformado em permanente.

A linha representa o checkpoint global consistente construído por p0.

Exemplo de padrão gerado pelo protocolo RDT-NBS.

Nesta seção, analisamos o comportamento do protocolo RDT-NBS na presença de um unico e múltiplos iniciadores concorrentes.

Provaremos que este protocolo salva um número minimal de checkpoints estáveis na presença de um unico iniciador e que mantém um checkpoint global consistente a qualquer instante de sua execução.

Na presença de um unico iniciador a cada instante de tempo, o protocolo RDT-NBS salva um número minimal de checkpoints estáveis durante uma construção consistente.

Prova, Por contradição, suponha que o processo p salva o checkpoint estável c durante a construção consistente C iniciada por p e c-16 c, onde c é o checkpoint salvo pelo iniciador p para C.

Se p salva c como estável durante C, então p recebeu uma mensagem de requisição de p.

Então, p modificou a entrada VD(c ) do seu vetor durante seu ultimo intervalo de checkpoints que implica que o checkpoint salvo antes dé c precede causalmente c (c-1 c ).

Lema 6 Seja c o checkpoint mais a esquerda de p.

Se VD(c ) =, então c é um checkpoint estável.

Prova, Sabemos pela política de coleta de lixo que o primeiro checkpoint mantido por um processo é permanente e portanto, c é um checkpoint permanente.

Por contradição, suponha que c é um checkpoint mutável ou c não foi armazenado por p.

Sabemos que, se c é o checkpoint mais à esquerda de p, então p participou de uma construção consistente C que já foi finalizada, o uso de vetores de dependências permite o rastreamento das dependências causais, o protocolo RDT-NBS garante a ausência de zigzag paths não duplicadas causalmente por meio da indução de checkpoints mutáveis.

Então, c 1 precede causalmente o checkpoint do iniciador da construção consistente C e portanto, p é participante de C.

Assim, no momento em que p recebe uma mensagem de requisição, temos duas possibilidades, p salva c provisório ou p já possui o checkpoint c estável salvo antes de C.

O protocolo RDT-NBS garante que, a qualquer momento, existe um checkpoint global consistente formado por checkpoints estáveis.

Prova, Sabemos que o vetor de dependências salvo com um checkpoint c indica o índice dos checkpoints que forma um checkpoint global consistente que inclui c.

Sabemos também que a união de checkpoints globais consistentes tem como resultado um checkpoint global consistente.

Seja c ao checkpoint mais à esquerda de p.

Seja o máximo de VD(c ), j.

Então, um checkpoint global consistente pode ser formado por, O protocolo BCS-NBS é baseado no protocolo quase-síncrono da classe ZCF, chamado BCS acrescido do mecanismo semelhante ao FDAS que impede a indução de checkpoints se nenhuma mensagem foi enviada no mesmo intervalo de checkpoints.

Este protocolo requer a propagação de apenas um inteiro com as mensagens da aplicação.

Além disso, este protocolo não sofre do efeito avalanche de checkpoints mutáveis e permite a presença de iniciadores concorrentes.

Uma versão mais simples deste protocolo que não utiliza checkpoints mutáveis foi proposta em.

Este protocolo utiliza relógios lógicos semelhantes ao mecanismo proposto por Lamport, mas ao invés de enumerar todos os eventos dos processos, apenas os checkpoints recebem um índice que é incrementado a cada novo armazenamento e pode ser atualizado no momento da recepção de mensagens.

Quando um processo p recebe uma mensagem com índice maior que o índice mantido por p e p enviou uma mensagem no intervalo atual, um checkpoint mutável é induzido imediatamente antes de processar a mensagem e p atualiza o seu índice como sendo igual ao índice recebido na mensagem.

Quando uma nova construção consistente é iniciada por p, p salva um checkpoint provisório, e envia uma mensagem de requisição para p se p recebeu uma mensagem de p com novo índice durante o seu ultimo intervalo de checkpoints.

O índice do checkpoint provisório salvo por p é o índice da construção consistente.

Um processo p, ao receber uma mensagem de requisição de p, verifica se é necessário armazenar um checkpoint provisório (novo ou pela transformação de um checkpoint mutável) e propaga mensagens de maneira semelhante ao iniciador, porém, não necessita enviar mensagens de requisição para os processos que já são participantes da construção consistente.

Além disso, se o índice atual de p é menor que o índice da construção consistente e p enviou uma mensagem no intervalo, p salva um novo checkpoint mutável para atualizar o seu índice.

No final da construção consistente, um novo checkpoint global consistente é construído e todos os processos envolvidos estão com o índice maior ou igual ao do iniciador p.

As variáveis utilizadas por este protocolo são descritas a seguir.

Enviou, indica se o processo enviou pelo menos uma mensagem durante o intervalo de checkpoints corrente.

VI, vetor deíndices mantido pelo processo p para capturar as precedências causais diretas entre checkpoints.

A entrada VI indica o índice atual de p.

Quando p recebe uma mensagem de p, p atualiza em seu vetor o índice propagado por p (VI = max(mind, VI )).

VP, vetor com os índices dos participantes de uma construção consistente.

Um processo p é inserido como participante da construção consistente por p se p recebeu uma mensagem com novo índice de p desde o seu primeiro checkpoint permanente.

Seja p o primeiro checkpoint permanente mantido p.

Então, VP é atualizado com o valor de VI > pVI.

Respostas, vetor mantido pelo iniciador para detecção da terminação da construção consistente.

Uma construção consistente é iniciada por um processo p quando este armazena um checkpoint provisório e envia mensagens de requisição para os processos selecionados em VP.

A mensagem de requisição propaga o índice do checkpoint salvo por p (índice da construção consistente) e seu VP.

Recepção da mensagem de requisição Quando um processo p recebe uma mensagem de requisição de p, p procura por um checkpoint c consistente com o ultimo checkpoint salvo por p, isto é, o checkpoint com índice maior ou igual ao índice que p conhece de p. 

Se p não possui c, então um novo checkpoint provisório é salvo, possui c e c é um checkpoint mutável, então c é transformado em provisório.

Após salvar um checkpoint provisório, o processo p calcula o conjunto de participantes VP.

Para reduzir o número de mensagens de requisição, p envia uma mensagem de requisição para p se p faz parte de VP e req VP, ou seja, p ainda não faz parte do conjunto de participantes da construção consistente com o índice conhecido por p.

Note que se c é permanente, VP não inclui nenhum processo como participante e não é necessário propagar requisição.

Todo processo que recebe uma mensagem de requisição, envia uma mensagem de resposta ao iniciador com a informação de quais processos foram adicionados como seus participantes e o índice do seu checkpoint provisório.

Recepção da mensagem de resposta Um processo p processa uma mensagem de resposta apenas se a construção consistente que iniciou não foi encerrada, ou seja, se possui um checkpoint provisório com o índice da construção consistente.

Ao receber uma mensagem de resposta de p, p atualiza o seu vetor respostas com o índice recebido por p e atualiza o seu vetor VP fazendo a união de seus participantes com os participantes conhecidos por p.

Enquanto um processo participante p não enviar mensagem de resposta ao iniciador com o índice esperado a construção consistente não é encerrada.

Assim, quando p recebe mensagens de todos os participantes de sua construção consistente, p transforma seu checkpoint provisório em permanente, propaga mensagens de liberação e remove todos os checkpoint salvos antes do novo checkpoint permanente.

Um processo p, ao receber uma mensagem de liberação, transforma o seu checkpoint i provisório em permanente e remove os checkpoints salvos antes dele.

A descrição do protocolo BCS-NBS é apresentada pelo Protocolo 5 2 O protocolo BCS-NBS utiliza um mecanismo semelhante a relógios lógicos para sincronizar as atividades de checkpointing e garantir a construção de checkpoints globais consistentes.

Ilustra um exemplo de execução do protocolo BCS-NBS.

O processo p3 inicia uma construção consistente e salva o seu checkpoint como permanente, pois não necessita propagar mensagens de requisição.

Quando p1 recebe a mensagem da aplicação de p3, p 1 induz um checkpoint mutável utilizando a mesma regra que protocolo quase-síncrono BCS-Aftersend usa para salvar um checkpoint forçado.

Da mesma maneira, p0 salva um checkpoint mutável.

Quando p0 inicia uma construção consistente, salva um checkpoint provisório e envia mensagens de requisição para p1 e p2.

Tanto o processo p1 quanto o processo p2 salvam um checkpoint provisório e enviam uma mensagem de requisição para p.

O processo p3 recebe a mensagem de requisição de p2 e como o ultimo checkpoint permanente de p3 não é conhecido por p2, p3 não salva um novo checkpoint provisório.

Porém, como o índice do iniciador é maior que índice de p3, p3 salva um checkpoint mutável e atualiza o seu índice com o índice do iniciador.

Quando p3 recebe a mensagem de requisição de p1, p3 transforma o seu checkpoint mutável em provisório e envia uma mensagem de resposta ao iniciador.

O iniciador p0 encerra sua construção consistente após receber as mensagens de resposta de p1, p2 e p3 (com o índice do novo checkpoint provisório).

O checkpoint global consistente formado pela construção consistente iniciada por p0 é representada pela linha.

Exemplo de padrão gerado pelo protocolo BCS-NBS.

O protocolo BCS-NBS garante que, a qualquer momento, existe um check-point global consistente formado por checkpoints estáveis.

Por contradição, vamos supor que, em um determinado instante, não existe um checkpoint global consistente formado por checkpoints estáveis.

Então, existem c e c tais que c é o ultimo checkpoint estável de p, c é o primeiro checkpoint estável de p e c c devido a uma mensagem m.

Sabemos pela política de coleta de lixo que o primeiro checkpoint mantido por um processo é permanente e portanto, c é permanente.

Então c foi salvo durante uma construção consistente C.

Quando c foi salvo por p, p propaga uma mensagem de requisição para p ou um outro processo participante de C que conhece c já enviou uma mensagem de requisição para p.

Portanto, p é um participante de C e como c é um checkpoint permanente, p já recebeu uma mensagem de requisição após o envio de m.

Pela Propriedade 1, se c c então o índice do checkpoint c é maior que o índice de c.

Portanto, quando p recebe a mensagem de requisição durante C, p salva um novo checkpoint provisório ou possui um checkpoint provisório salvo após o envio de m.

Podemos concluir então que c não é o ultimo checkpoint estável de p, o que contradiz a hipótese.

O simulador de protocolos de checkpointing ChkSim foi utilizado como experimento inicial para comparar os protocolos propostos nesta tese e os existentes na literatura.

Este simulador foi originalmente proposto para comparar o desempenho dos protocolos quase-síncronos.

O simulador gera uma sequencia de eventos de comunicação (envio e recepção de mensagens) e checkpoints da aplicação.

Adicionando-se mensagens de controle, foi possível simular os protocolos síncronos não-bloqueantes.

O resultado foi obtido simulando-se um sistema com 16 nós interligados por meio de um grafo de comunicação não completo, após a execução de 12000 eventos por processo.

As amostras foram obtidas com intervalos de checkpoints da aplicação a cada 4 a 112 eventos de comunicação e cada protocolo foi executado 10 vezes.

Topologia utilizada na simulação.

Dentre as várias topologias testadas, esta foi escolhida pois simula o comportamento de uma rede em que a comunicação ocorre entre grupos de processos.

Redes em que existe troca de mensagens frequentes entre todos os processos da aplicação levariam a adoção de um protocolo global e não minimal.

O unico protocolo síncrono não-bloqueante que utiliza checkpoints mutáveis existenté na literatura, chamado nesta Seção de Cao03, não permite a presença de iniciadores concorrentes.

A comparação do protocolo Cao03 com os protocolos não-bloqueantes RDT-NBS e BCS-NBS propostos nesta tese foi realizada implementando-se o mecanismo de passagem de ficha para garantir que apenas o processo que possui a ficha possa iniciar uma construção consistente (uma unica iniciação a cada instante).

Porém, notamos qué os diferentes mecanismos na propagação das mensagens de controle influenciou os pontos de armazenamento dos checkpoints dos iniciadores.

Portanto, não conseguimos comparar estes protocolos utilizando o mesmo padrão de checkpoints e mensagens.

Assim, todos os valores mostrados a seguir são proporcionais ao número de construções consistentes executados a cada protocolo.

Mostra o número de checkpoints salvos pelos protocolos.

O protocolo BCS-NBS apresentou um número menor de checkpoints mutáveis em relação ao protocolo RDT-NBS.

Este resultado é esperado já que simulações dos protocolos quase-síncronos mostram que o protocolo BCS-Aftersend salva menos checkpoints forçados que o protocolo FDAS.

Já o protocolo Cao03 induziu um baixo número de checkpoints mutáveis pois este protocolo salva checkpoints mutáveis apenas quando uma construção consistente está em andamento e uma mensagem da aplicação com informação sobre construção consistente chega antes da mensagem de requisição.

Mostra que o protocolo Cao03 salva um número menor de checkpoints estáveis seguido pelo BCS-NBS e então pelo RDT-NBS.

A comparação dos protocolos RDT-NBS e BCS-NBS que permitem iniciações concorrentes foi realizada utilizando-se exatamente os mesmos padrões de checkpoints e mensagens.

Assim como o protocolo BCS-Aftersend salva menos checkpoints forçados comparado ao FDAS, o protocolo BCS-NBS apresentou um número menor de checkpoints mutáveis em relação ao protocolo RDT-NBS.

Porém o número de checkpoints salvos em memória estável (checkpoints provisórios e checkpoints mutáveis transformados em provisórios) por ambos os protocolos foi praticamente o mesmo.

Checkpoints salvos na presença de iniciadores concorrentes.

As mensagens de controle são compostas por mensagens de requisição, resposta e liberação.

Apesar do protocolo RDT-NBS enviar as mensagens de controle diretamente do iniciador aos participantes de uma construção consistente, o número de mensagens de controle utilizadas por esse protocolo foi maior comparado ao protocolo BCS-NBS.

Devemos lembrar que esses dois protocolos salvam checkpoints mutáveis em pontos diferentes, o que influencia o conjunto de participantes para a construção de checkpoints globais consistentes (Seção 52).

O simulador nos permitiu comparar também os protocolos síncronos não-bloqueantes RDT-NBS e BCS-NBS com os respectivos protocolos quase-síncronos FDAS e BCS-Aftersend.

Nos protocolos síncronos não-bloqueantes é permitida a presença de iniciadores concorrentes e para cada checkpoint básico armazenado por um protocolo quase-síncrono, uma nova construção consistente é iniciada pelo protocolo síncrono.

Mensagens de controle na presença de iniciadores concorrentes.

Ilustra o número de checkpoints forçados armazenado pelos protocolos quase-síncronos e o número de checkpoints induzidos (mutáveis e estáveis) pelos protocolos síncronos.

Os protocolos síncronos apresentam um número maior de checkpoints induzidos comparados com os respectivos protocolos quase-síncronos pois para cada checkpoint básico salvo, um novo checkpoint global consistente é construído.

Assim, os protocolos síncronos não-bloqueantes mantêm checkpoints globais consistentes mais recentes que os protocolos quase-síncronos.

Apesar dos protocolos síncronos salvarem mais checkpoints que os respectivos protocolos quase-síncronos, a maioria dos checkpoints são salvos primeiro como mutáveis e apenas alguns são utilizados para formar checkpoints globais consistentes, ou seja, são transformados em estáveis.

Mais da metade dos checkpoints mutáveis são descartados antes de serem transformados em estáveis o que implica que os protocolos síncronos armazenam um número menor de checkpoints estáveis.

Mostra o número total de checkpoints estáveis salvos por esses protocolos.

Podemos notar que os protocolos síncronos não-bloqueantes salvam um número menor de checkpoints em memória estável.

Os protocolos síncronos descartam checkpoints após a execução de uma construção consistente enquanto os protocolos quase-síncronos requerem a implementação de um protocolo independente para a coleta de lixo.

Para qualquer protocolo RDT, incluindo o Checkpoints induzidos.

Checkpoints mutáveis.

Checkpoints estáveis.

FDAS, pode-se usar o protocolo de coleta de lixo proposto por Schmidt.

Os protocolos síncronos mais simples requerem que todos os processos armazenem checkpoints durante uma construção consistente.

Na tentativa de reduzir o overhead associado aos protocolos síncronos, os protocolos síncronos minimais induzem apenas um número minimal de processos a salvarem checkpoints.

Porém os protocolos minimais são bloqueantes, ou seja, os processos envolvidos devem suspender suas aplicações durante a construção consistente.

Alguns protocolos síncronos que reduzem o número de checkpoints a cada construção consistente e não requerem o bloqueio dos processos foram propostos na literatura.

Esses protocolos são baseados em protocolos síncronos minimais e não permitem a presença de iniciadores concorrentes.

Recentemente, Cao e Singhal introduziram um novo tipo de checkpoint armazenado em memória não-estável (checkpoint mutável) para desenvolver um protocolo que garante um número minimal de checkpoints em memória estável.

Notamos que a minimalidade no número de checkpoints estáveis depende do ponto de execução onde os checkpoints mutáveis são salvos e provamos que não é possível garantir um número mínimo de checkpoints durante toda a execução da aplicação.

Além disso, provamos que é impossível garantir minimalidade no número de checkpoints estáveis na presença de iniciadores concorrentes.

Neste Capítulo, apresentamos as características dos protocolos síncronos não-bloqueantes e notamos que várias dessas características são semelhantes as dos protocolos quase-síncronos.

Assim, mostramos que é possível desenvolver protocolos síncronos não-bloqueantes baseando-se em protocolos quase-síncronos.

Esses protocolos permitem a presença de iniciadores concorrentes, já que em protocolos quase-síncronos não existe o conceito de um unico iniciador, pois os processos têm autonomia para salvar checkpoints da aplicação.

O protocolo RDT-NBS é um protocolo síncrono não-bloqueante baseado no protocolo quase-síncrono FDAS, porém pode ser facilmente modificado baseado-se em qualquer protocolo da classe RDT.

Este protocolo utiliza vetores de dependências para rastrear as dependências entre checkpoints.

Assim, o iniciador conhece todos os participantes de sua construção consistente e as mensagens são enviadas diretamente do iniciador aos participantes e dos participantes ao iniciador, o que permitiu o desenvolvimento de métodos simples em todas as fases de checkpointing.

O protocolo BCS-NBS é um protocolo síncrono não-bloqueante baseado no protocolo quase-síncrono BCS.

Este protocolo requer a propagação de apenas um inteiro com as mensagens da aplicação e número de checkpoints induzidos é menor do que qualquer protocolo baseado em protocolos quase-síncronos da classe RDT.

Este protocolo leva em consideração todas as características citadas na Seção 5 1 2 e não sofre o efeito avalanche de checkpoints.

Um simulador foi utilizado para comparar esses dois protocolos.

O protocolo BCS-NBS apresentou um número menor de checkpoints mutáveis em comparação ao protocolo RDT-NBS, porém, o número de checkpoints estáveis armazenados por ambos os protocolos foi praticamente o mesmo.

Apesar dos protocolos síncronos não-bloqueantes salvarem um número maior de checkpoints comparado aos seus respectivos protocolos quase-síncronos, notamos que mais da metade dos checkpoints salvos como mutáveis são descartados antes de serem transferidos para memória estável e o número de checkpoints salvos em memória estável pelos protocolos síncronos é menor.

Além disso, os protocolos síncronos implementam um protocolo de coleta de lixo simples enquanto os protocolos quase-síncronos necessitam de um protocolo de coleta de lixo independente ao protocolo de checkpointing.

Checkpointing é um mecanismo utilizado para garantir tolerância a falhas em sistemas distribuídos.

Um protocolo de checkpointing é responsável pelo armazenamento de estados em memória estável, chamados de checkpoints, que podem ser utilizados para o restabelecimento da computação após a ocorrência de uma falha.

Os protocolos de checkpointing podem ser classificados como assíncronos, quase-síncronos ou síncronos.

Nesta tese, mostramos que é possível aplicar alguns conceitos utilizados na teoria dos protocolos quase-síncronos para analisar e desenvolver protocolos síncronos, especialmente protocolos síncronos não-bloqueantes que reduzem o número de checkpoints a cada construção consistente e permitem a presença de iniciadores concorrentes.

Os protocolos de checkpointing síncronos que induzem um número minimal de processos a armazenarem checkpoints durante uma construção consistente são chamados de minimais.

O primeiro protocolo minimal proposto necessita manter os processos bloqueados durante uma construção consistente e requer um alto número de mensagens de controle.

Notamos na literatura, um esforço em tentar reduzir o número de mensagens de controle nos protocolos minimais ou eliminar o mecanismo de bloqueio dos processos.

Existem duas abordagens para o desenvolvimento de protocolos minimais.

Na primeira abordagem, um processo iniciador salva um checkpoint e envia mensagens de requisição para um conjunto de processos.

Cada processo que recebe uma mensagem de requisição, salva um checkpoint e propaga mensagens de requisição para um novo conjunto de processos formando assim, uma propagação da mensagens de requisição em níveis.

Na segunda abordagem, o iniciador faz um broadcast de mensagens de bloqueio e, em um primeiro instante, todos os processos ficam bloqueados até o iniciador definir quais processos devem armazenar checkpoints para a construção de um checkpoint global consistente.

Independente da abordagem escolhida para propagar as mensagens de requisição, os protocolos minimais devem utilizar um mecanismo para rastrear as dependências entre checkpoints.

Provamos que protocolos minimais que anotam apenas a recepção de mensagens, mas não os intervalos de checkpoints de origem dessas mensagens não garantem minimalidade no número de checkpoints.

Os protocolos síncronos minimais propostos nesta tese utilizam vetores de dependências para rastrear as dependências entre checkpoints e garantir um número minimal de checkpoints.

O primeiro protocolo, chamado de VD-minimal, requer um número menor de mensagens de controle e utiliza um novo mecanismo de detecção de terminação.

O protocolo Broad-minimal utiliza a abordagem broadcast para garantir um número minimal de checkpoints e é uma correção de um protocolo existente na literatura.

Os protocolos minimais são bloqueantes, ou seja, é impossível desenvolver um proto-colo síncrono não-bloqueante que armazena um número minimal de checkpoints a cada construção consistente.

Para amenizar este problema, Cao e Singhal propuseram um novo tipo de checkpoint chamado de checkpoint mutável.

Um checkpoint mutável é um checkpoint que pode ser armazenado em memória não-estável e é utilizado para reduzir a quantidade de dados que devem ser transferidos para memória estável.

Utilizando checkpoints mutáveis é possível garantir um número minimal de checkpoints estáveis a cada construção consistente.

Porém, provamos que na presença de iniciadores concorrentes não é possível garantir minimalidade no número de checkpoints estáveis.

Além disso, provamos que é impossível garantir número mínimo de checkpoints estáveis em um protocolo não-bloqueante que usa checkpoints mutáveis durante toda a execução da aplicação.

Notamos que muitas das características de um protocolo síncrono não-bloqueante que utiliza checkpoints mutáveis são semelhantes as características de protocolos quase-síncronos.

Ao utilizarmos protocolos quase-síncronos para desenvolver protocolos síncronos não-bloqueantes com checkpoints mutáveis, obtivemos protocolos simples, de fácil compreensão e que permitem iniciadores concorrentes.

Além disso, as provas de correção foram escritas baseando-se no conhecimento da teoria dos protocolos quase-síncronos.

O protocolo RDT-NBS é um protocolo síncrono não-bloqueante baseado no protocolo FDAS da classe RDT do modelo quase-síncrono.

Este protocolo é simples em todas as fases de checkpointing, porém requer a propagação de um vetor de inteiros com as mensagens da aplicação e armazena um alto número de checkpoints mutáveis.

Já o protocolo BCS-NBS é baseado no protocolo BCS da classe ZCF do modelo quase-síncrono.

Este protocolo possui a fase de requisições mais complexa que o protocolo RDT-NBS, pois a propagação das mensagens de requisição é feita em níveis.

Porém, o protocolo BCS-NBS requer a propagação de apenas um número inteiro com as mensagens da aplicação e armazena um número menor de checkpoints mutáveis comparado ao protocolo RDT-NBS.

Testes em um simulador foram realizados para validar esses resultados.

Os protocolos síncronos não-bloqueantes requerem o armazenamento de um número maior de checkpoints comparado aos protocolos quase-síncronos, pois induzem checkpoints na construção de checkpoints globais consistentes.

Porém, a maioria dos checkpoints salvos por esses protocolos são checkpoints mutáveis descartados antes de serem transferidos para memória estável.

Por esse motivo, os protocolos síncronos armazenam um número menor de checkpoints estáveis em relação aos seus respectivos protocolos quase-síncronos.

Os protocolos síncronos implementam uma coleta de lixo bem simples, já que para cada checkpoint requerido pela aplicação, um novo checkpoint global consistente é construído e os checkpoints salvos anteriormente podem ser removidos.

Assim, esses protocolos mantêm um menor número de checkpoints em memória estável.

Em especial, em protocolos síncronos bloqueantes, um processo necessita manter no máximo, dois checkpoints em memória estável em um determinado instante de tempo.

Além disso, os protocolos síncronos garantem checkpoints globais consistentes mais recentes que os protocolos quase-síncronos.

Nesta mesma linha de pesquisa, alguns pontos ainda podem ser investigados.

Outros protocolos síncronos não-bloqueantes baseados em diferentes protocolos quase-síncronos poderiam ser desenvolvidos para analisar e avaliar o desempenho e custo desses protocolos.

Além disso, o simulador poderia ser modificado para permitir também os protocolos síncronos bloqueantes.

Acreditamos que se desacloplarmos a detecção da terminação em protocolos síncronos não-bloqueantes e implementarmos um protocolo de coleta de lixo, poderemos obter protocolos mais simples e com menor número de mensagens de controle.

Nesta seção, apresentamos os protocolos quase-síncronos analisados durante o desenvolvimento deste estudo.

O protocolo CASBR (Checkpoint-After-Send-Before-Receive) pertence à classe SZPF dos protocolos quase-síncronos.

Nesta seção, apresentamos os protocolos síncronos minimais analisados durante o desenvolvimento deste trabalho.

O protocolo proposto por Leu e Bhargava garante minimalidade por meio da construção de uma arvore que representa as dependências entre checkpoints do intervalo de checkpoints corrente.

O protocolo proposto por Prakash e Singhal utiliza vetores de bits para rastrear as dependências entre checkpoints.

Este protocolo não garante a minimalidade no número de checkpoints.

Este protocolo proposto por Cao e Singhal foi o primeiro protocolo a utilizar a abordagem broadcast para definir o conjunto de processos participantes de uma construção consistente.

Porém, este protocolo não garante minimalidade no número de checkpoints.

O protocolo VD-minimal utiliza vetores de dependências para rastrear as dependências entre checkpoints e garantir um número minimal de checkpoints a cada construção consistente.

Apresentamos aqui uma versão simplificada do protocolo que permite apenas um iniciador a cada instante de tempo.

Nesta seção, apresentamos os protocolos síncronos não-bloqueantes, que reduzem o número de checkpoints a cada construção consistente, analisados durante o desenvolvimento deste trabalho.

O protocolo proposto por Prakash e Singhal considera canais confiáveis FIFO (First-In-First-Out) e foi o primeiro protocolo que une as características de minimalidade e nãobloqueio.

Porém, este protocolo pode gerar inconsistências.

O protocolo proposto por Cao e Singhal corrige o problema encontrado no protocolo de Prakash e Singhal descrito na seção anterior.

