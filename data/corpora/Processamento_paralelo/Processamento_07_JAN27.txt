A alta velocidade das redes de comunicação e o aumento no desempenho dos microprocessadores têm feito das redes de estações de trabalho um importante meio de computação paralela a um custo relativamente baixo.

Um dos objetivos deste trabalho consiste em conceber um ambiente de programação paralela para uma rede de estações de trabalho, que torne mais fácil a atividade de programação.

Para isso, o modelo concebido é SPMD (single program multiple data) e utiliza memória virtual distribuída para uma rede heterogênea de estações de trabalho.

No modelo definido, um programa paralelo é escrito de forma semelhante a um programa multithreaded e a comunicação é através de memória compartilhada.

Os processos são criados dinamicamente e podem ser mapeados em qualquer nodo da rede.

A sincronização nesse ambiente é através de semáforos e barreiras.

Outro objetivo do trabalho é a implementação do sistema numa rede de estações de trabalho, para servir de base para projetos de pesquisa e ensino também em outras instituições.

O sistema é baseado no modelo cliente-servidor, onde os serviços são oferecidos por servidores especializados.

Uma qualidade importante desse esquema é que ele funciona independentemente da localização do cliente e do servidor.

Se eles são localizados na mesma máquina, a comunicação ocorrerá localmente, senão ela se realizará através da rede.

Para permitir a integração desses elementos, o sistema desenvolvido,MDX possui, em sua camada de mais baixo nível, um núcleo de comunicação capaz de receber e emitir mensagens locais e distantes.

A nível usuário, o MDX conta com um interpretador de comandos, para o qual a rede de estações é vista como uma única máquina.

Uma requisição de usuário poderá desencadear uma operação global e ao mesmo tempo tudo ocorrerá como se o procedimento fosse local.

As redes locais de alto desempenho têm recebido grande atenção principalmente pelo constante aprimoramento e o baixo custo que apresentam, se comparadas às máquinas paralelas.

Uma rede de estações de trabalho apresentava um desempenho inferior em relação às máquinas paralelas devido à velocidade de comunicação.

Isso tem diminuído sensivelmente com o surgimento de novas tecnologias, como ATM, Myrinet, dentre outras.

Diferentemente do hardware, o software ainda não atingiu o estágio de evolução esperado, principalmente pela complexidade de se projetar e implementar sistemas distribuídos para esse tipo de arquitetura.

A nova geração de sistemas paralelos e distribuídos tem a tendência de integrar máquinas paralelas com redes de estações de trabalho.

Um grande esforço tem sido feito nos últimos anos para oferecer ao programador o mesmo ambiente de programação em ambas plataformas, principalmente através do uso de mecanismos disponíveis em bibliotecas C (TCP/IP ), bibliotecas multithreaded e de comunicação utilizando troca de mensagens (PVM ) ou uma abstração de uma memória virtual compartilhada para uma rede de estações de trabalho, (Munin e TreadMarks ).

Um dos grandes problemas das novas interfaces de comunicação e da arquitetura das estações de trabalho é a necessidade do programador usar um protocolo específico de comunicação e conhecer bem a arquitetura básica da rede, para obter uma boa performance.

Esse problema também é encontrado na utilização de máquinas com multiprocessadores, onde as aplicações necessitam de um núcleo de comunicação multithreaded para usar os múltiplos processadores ao mesmo tempo.

Isso tem gerado a necessidade de integrar multithread e comunicação com o intuito de oferecer um nível de abstração para execução paralela onde os mecanismos de comunicação e multithreaded são agrupados.

A abstração visa maximizar o desempenho da comunicação e esconder o nível de hardware e software da comunicação.

Um núcleo de comunicação normalmente proporciona um paradigma de troca explícita de mensagens, para a comunicação de dados entre os nodos através de uma Chamada Remota de Procedimentos (RPC) ou de uma Requisição Remota de Serviços (RSR), com a finalidade de criar remotamente as threads de controle e estruturar a computação distribuída.

Há restrições quanto ao uso dos paradigmas RPC e RSR, pois fazem com que o paralelismo explícito e a distribuição sejam difíceis de serem tratados por um usuário final, que prefere focar toda sua atenção no problema envolvido ao invés de gastar seu tempo aprendendo um novo paradigma ou linguagem, capaz de paralelizar seus programas e particionar os dados.

Por outro lado, os modelos que utilizam memória distribuída compartilhada (DSM) sobre redes de estações de trabalho, através de bibliotecas ou compiladores, apresentam uma menor complexidade para o programador, se comparado com a programação por troca de mensagens, devido a maior semelhança com um programa seqüencial.

Assim, o programador não precisa ter grandes preocupações com a comunicação e com o gerenciamento do particionamento do conjunto de dados, já que os acessos compartilhados são automaticamente convertidos em primitivas de coerência e sincronização.

Atualmente o desenvolvimento de software para processamento distribuído e paralelo precisa permitir ao programador usar todo o poder de processamento distribuído da forma mais fácil e eficiente possível, de modo que possa acessar todos os recursos do ambiente, sem ter a necessidade de conhecer os detalhes da comunicação e do sistema operacional.

Diferentes tipos de ferramentas e linguagens que auxiliam o desenvolvimento de software para sistemas distribuídos têm sido desenvolvidas, principalmente utilizando os paradigmas de memória compartilhada e RPC, cuja principal vantagem é a independência de localização dos processos.

Nesse contexto, surgiram vários projetos como o projeto MDX envolvendo a PUCRS, a UCS e a URI, TreadMarks, dentre outros.

Este trabalho tem como objetivo principal a definição de um ambiente de programação paralela, baseado em memória virtual compartilhada.

Este modelo foi escolhido porque isenta o programador de conhecer detalhes da arquitetura do sistema, facilitando a programação.

Para atingir esse objetivo, são definidos o modelo de programação e as primitivas do sistema.

O segundo objetivo é implementar o ambiente de programação distribuído em uma rede de estações de trabalho.

Para isso, deve ser implementado um ambiente que suporte a execução de programas escritos com o uso das primitivas definidas.

Este volume está organizado em 7 capítulos.

No capítulo 2 são revistos alguns conceitos envolvendo a programação paralela, como modelos de programação e formas de paralelização de programas.

O capítulo 3 apresenta alguns sistemas semelhantes, analisando as características e funcionalidades que cada um oferece, aprofundando um pouco mais no sistema TreadMarks, que utiliza memória virtual compartilhada.

A definição do sistema MDX é apresentado no capítulo 4, onde é descrito o modelo de programação e definidas as primitivas do sistema, enquanto o estudo comparativo entre este modelo e TreadMarks é realizado no capítulo 5.

No capítulo 6 é apresentada a arquitetura do sistema.

Neste capítulo é mostrado, de maneira detalhada, o núcleo de comunicação e cada um dos servidores que compõem o ambiente, juntamente com a descrição do modo de funcionamento de cada primitiva do sistema.

Por fim, na conclusão o modelo desenvolvido é discutido e são abordados os aspectos mais relevantes do ambiente MDX e da implementação do protótipo.

Neste capítulo também são apontados trabalhos futuros no sentido de dar continuidade ao projeto.

Um ambiente de programação paralela é formado pelo conjunto de ferramentas que permitem o desenvolvimento de programas paralelos, tais como, editores inteligentes, capazes de detectar e especificar automaticamente seqüências de código que podem ser executados em paralelo, depuradores de programas e bibliotecas de funções.

Um ambiente de execução paralela é formado por uma ou mais máquinas conectadas por uma rede física que fornece o suporte de execução aos programas paralelos.

O ambiente, portanto, é responsável pela implementação dos mecanismos que permitem a comunicação, a sincronização, a gerência de processos, dentre outros.

Diversas taxonomias para arquiteturas paralelas foram propostas.

Visando abranger os computadores escaláveis, Gordon Bell apresentou uma taxonomia classificando as arquiteturas como segue, As máquinas da categoria classificadas como fluxo único de instruções se caracterizam pela execução de um único fluxo de instruções em cada processador.

Estão incluídos desde os computadores CISC até computadores com palavras de instruções bem longas, como os superescalares VLIW RISC, e computadores multithreaded, onde múltiplas threads processam o mesmo fluxo de instruções.

A categoria denominada de MIMD Múltiplas Instruções Múltiplos Dados é caracterizada pela execução de múltiplos fluxos instruções sobre fluxos distintos de dados, pelos seus múltiplos processadores.

São classificados em duas classes, conforme a forma de comunicação entre os processadores, os multicomputadores e os multiprocessadores.

Um multicomputador é formado por vários computadores, compostos por processador e memória ligados por uma rede de interconexão.

Multicomputador.

Neste modelo, cada computador executa seu próprio programa, e o mesmo acessa a memória local diretamente e pode enviar e receber mensagem sobre a rede.

As mensagens são usadas para a comunicação entre um processador e outro ou para ler e escrever na memória remota.

O custo para acessar a memória local é menor que para acessar a memória remota.

O custo de enviar uma mensagem é independente da localização do nodo e de outros tráfegos na rede, mas depende do tamanho da mensagem.

Um multicomputador pode ter seus nodos contidos em uma mesma placa, como nos multicomputadores compostos por uma rede de transputer, em placas ligadas por barramentos ou chaveadores contidos em um único gabinete, como o sistema Intel Paragon e o Meiko CS2 ou ainda numa rede local de estações de trabalho.

Neste tipo de máquina (MIMD Múltiplas Instruções Múltiplos Dados), cada processador pode executar um diferente conjunto de instruções em seus dados locais.

A memória distribuída pode estar em cada processador ou em uma localização central.

A principal diferença entre este tipo e o multicomputador é que neste modelo, o custo de enviar uma mensagem não é independente da localização do nodo e de outros tráfegos na rede.

Computador MIMD.

Um multiprocessador é um computador SIMD Simples Instruções Múltiplos Dados com memória compartilhada.

Todos os processadores compartilham acesso a uma memória comum através de um barramento.

No modelo idealizado PRAM Parallel Random Access Machine qualquer processador pode acessar qualquer elemento de memória num mesmo intervalo de tempo.

O uso na prática desta arquitetura introduz alguma forma de hierarquia de memória.

A freqüência com que a memória distribuída é acessada pode ser reduzida armazenando-se cópias de dados numa cache associada a cada processador.

Neste modelo a localização é importante.

A diferença entre multiprocessadores e multicomputadores é a questão da hierarquia da memória.

Os programas desenvolvidos para multicomputadores podem executar eficientemente em multiprocessadores, pois a memória compartilhada permite uma implementação eficiente de troca de mensagens.

Apresenta o modelo de um multiprocessador.

Multiprocessador.

De acordo com o tipo de acesso à memória, os multiprocessadores podem ser classificados em, Acesso à Memória Uniforme UMA, ou em Acesso à Memória Não Uniforme NUMA.

A cache é caracterizada pelo seu acesso rápido.

Os multiprocessadores classificados como Somente Cache (COMA) são um tipo de NUMA, onde a memória local de cada nodo é transformada em memória cache.

Uma subclasse de NUMA classificada como "coerência de memória" é caracterizada por uma cache pequena, utilizada para acessos a dados presentes na memória de outro nodo.

Esta hierarquia de acesso (NUMA) deve ser explorada pelos compiladores e programadores para reduzir o custo de comunicação.

Este tipo de computador é uma classe bem especializada de computadores paralelos em que todos os processadores executam o mesmo conjunto de instruções sobre diferentes dados.

Os processadores vetoriais SIMD são o núcleo dos supercomputadores e são largamente utilizados em aplicações com uso intenso de ponto flutuante.

Este modelo reduz a complexidade do software e do hardware sendo apropriado somente para problemas especializados com alto grau de regularidade como processamento de imagens e simulações numéricas.

A computação paralela sobre uma rede de estações de trabalho tem recebido muita atenção nos últimos anos, devido ao alto desempenho que as redes locais tem proporcionado, bem como o baixo custo das mesmas, se comparadas aos supercomputadores.

Os computadores com um processador interconectados por uma rede Ethernet ou ATM podem ser vistos como uma máquina paralela.

Neste modelo exige-se mecanismos de segurança para garantir a confiabilidade da comunicação.

Este modelo, pode ser visto como um multicomputador.

WAN ou LAN como máquina paralela.

A tendência atual é de não utilizar um único sistema operacional para formar um ambiente de execução paralela, mas utilizar um sistema que integra todos os demais numa rede heterogênea.

Existe também uma tendência geral para a proliferação de ambientes heterogêneos que, além de permitirem a execução em diferentes sistemas operacionais, tiram proveito desse fato, permitindo um melhor balanceamento de carga do mesmo, através da execução de determinados processos em máquinas com maior poder de computação e memória disponível.

Como não existe uma memória fisicamente compartilhada numa rede de estações de trabalho, toda a comunicação entre os processos precisa ser efetuada através de mecanismos de comunicação entre processos, como por exemplo a troca de mensagens.

Dada a diversidade de arquiteturas paralelas, visando gerenciar o paralelismo, foram propostas diversas linguagens, compiladores e bibliotecas especiais.

O paralelismo em um programa pode ser explorado implicitamente através de compiladores paralelizantes, como o Parafrase2, que paralelizam automaticamente programas escritos em C, ou então explicitamente, através de primitivas inseridas no programa, ou através de uma linguagem de programação, como C Concorrente.

A experiência tem mostrado que a programação paralela é significativamente mais difícil que a programação seqüencial, principalmente porque envolve a necessidade de sincronização entre tarefas, como também a análise de dependência de dados.

A utilização de um sistema paralelizante minimiza estas dificuldades, e permite também o reaproveitamento de programas seqüenciais já implementados.

Por outro lado, o paralelismo explícito permite que fontes não passíveis de detecção por um sistema paralelizante possam ser exploradas.

O paralelismo expresso pelo usuário pode ser especificado em um programa através de comandos específicos de uma linguagem de programação paralela, por chamadas a rotinas de uma biblioteca que gerencia os recursos de paralelismo da máquina ou pelo uso de diretivas do compilador.

Entre estas formas, a utilização de uma linguagem de programação paralela é a que oferece um ambiente mais adequado de programação.

As bibliotecas específicas também têm sido uma forma muito utilizada de implementar programas.

Existem várias bibliotecas específicas para multiprocessadores como a oferecida pelo sistema Balance da Sequent, PVM Parallel Virtual Machine.

Essas bibliotecas utilizam troca de mensagem.

As bibliotecas do sistema Quarks e do sistema Treadmarks oferecem uma memória virtual compartilhada.

Um dos aspectos mais importantes da paralelização de programas está relacionado com as operações de gerenciamento de processos, principalmente a criação e o término dos mesmos.

Em um programa paralelo, os processos podem ser criados de maneira implícita ou explícita.

Na criação implícita os processos são associados a um tipo de dado e são instanciados com a declaração de uma variável desse tipo no programa.

A criação explícita de processos é realizada por uma função, designada especialmente para realizar esta tarefa.

A criação de processos também pode ser estática ou dinâmica.

Na criação estática, o conjunto de processos que irão compor o programa paralelo deve ser definido antes da execução, e não pode ser alterado até o final do programa.

Este tipo de criação apresenta a desvantagem de exigir que o número total de processos seja conhecido antecipadamente.

Já na criação dinâmica, os processos podem ser instanciados a qualquer momento durante a execução do programa, sendo portanto, mais flexível que a criação estática.

O término de processos é uma questão importante e ligada diretamente à criação.

Quando um processo termina, podem ocorrer dois tipos de situação, o término do processo causa automaticamente a morte de todos os seus processos filhos ou então o processo fica bloqueado, aguardando que os processos filhos também terminem.

Todos os processos criados em um programa paralelo devem ser associados a algum processador do sistema.

Esta associação de processos a processadores é chamada de mapeamento.

O mapeamento deve levar em conta o número de processadores disponíveis e a maneira de distribuir os processos sobre os mesmos, de forma a se obter o maior desempenho possível.

Quando a criação de processos é estática, o mapeamento é definido no momento da carga do programa na máquina paralela.

Quando os processos são criados dinamicamente, o mapeamento é feito em tempo de execução.

O mapeamento pode ser implícito, quando o sistema efetua a associação dos processos aos processadores, utilizando normalmente uma política de balanceamento de carga.

Como o mapeamento implícito nem sempre apresenta bons resultados, o mapeamento pode ficar a cargo do programador (explícito), que decide, com base no conhecimento que possui da aplicação, a melhor maneira de mapear os processos.

As linguagens de programação podem ser classificadas em, Linguagens Imperativas Linguagens procedurais Linguagens orientadas a objetos Linguagens Declarativas Linguagens funcionais Linguagens lógicas.

As linguagens imperativas caracterizam-se por modificar um estado implícito do programa através de comandos.

Na programação imperativa os comandos lêem valores de entrada, manipulam e escrevem os valores de saída.

Os comandos que compõem um programa têm influência uns com os outros por meio dos valores armazenados por variáveis.

Incluem-se nesta classe as linguagens procedurais e orientadas a objeto.

As linguagens declarativas são caracterizadas por uma programação realizada através de expressões.

Nesta classe estão incluídas as linguagens funcionais e lógicas.

As linguagens procedurais são caracterizadas por subdividir o programa em subprogramas, que podem ser rotinas, subrotinas ou procedimentos.

As linguagens C e Pascal são exemplos desta classe.

Dados os efeitos colaterais que podem ser gerados, como a alteração em um procedimento de dados que são lidos em outros procedimentos, a análise de dependência de dados torna-se uma tarefa complexa.

Existe uma dependência de dados entre dois comandos, quando um deles altera um dado que é lido ou escrito pelo outro.

Neste caso os dois comandos não podem ser executados simultaneamente.

Na programação através de uma linguagem que permite que o usuário expresse o paralelismo, este deve efetuar uma análise de dependência de dados.

No caso de existir uma dependência de dados, mecanismos de exclusão mútua devem ser utilizados, envolvendo o acesso ao dado.

Como as linguagens procedurais são largamente utilizadas, várias extensões de linguagens conhecidas foram propostas, dentre as quais podem ser citadas a Concurrent C, para a linguagem C e a linguagem Fortran D, para a linguagem Fortran.

O encapsulamento das informações em objetos, fornecido pelo paradigma de orientação a objetos, e seu acesso apenas através de chamadas a seus métodos, é a principal característica que torna este paradigma atraente para a programação paralela.

Devido a este encapsulamento é garantida a inexistência de dependência de dados entre objetos, existindo, desta forma, um paralelismo implícito entre eles.

Paralelismos entre métodos do mesmo objeto podem ser explorados.

Entretanto, neste caso como acessos a um mesmo dado podem ocorrer, deve ser efetuada uma análise de dependência entre os métodos.

Caso haja acessos a um mesmo dado, mecanismos de exclusão mútua devem ser utilizados.

Várias linguagens para arquiteturas paralelas com memória compartilhada ou distribuída foram propostas, podendo ser citadas a COOL, a Mentat.

Nos programas escritos em linguagens funcionais as funções comportam-se como funções matemáticas, onde o resultado obtido depende apenas de seus argumentos.

Neste tipo de linguagens não são gerados efeitos colaterais, pois não é permitido que uma função interaja na execução de outra através de variáveis globais ou do uso de ponteiros.

Esta ausência de efeitos colaterais é uma característica relevante para a programação paralela, pois não existe dependência entre as funções, proporcionando um paralelismo implícito entre elas.

Entretanto, quando uma função utiliza o resultado retornado por uma outra, é obrigada a esperá-lo, onerando o desempenho do programa.

Embora, possa existir uma grande quantidade de paralelismos, podem estar incluídas paralelizações de granularidades muito finas.

Devido ao custo da implementação do paralelismo, tem-se que quanto maior a granularidade das porções de código paralelas, maior é o desempenho obtido.

Para não permitir a ocorrência de paralelizações de granularidades muito finas é necessário dispor de uma forma para indicar as expressões que serão processadas paralelamente.

A programação lógica é um paradigma de programação onde os programas são expressos como regras lógicas.

Uma propriedade das linguagens de programação lógica presente em sua semântica é a independência da ordem em que são processadas diferentes operações durante a execução do programa.

Esta independência permite que estas operações sejam executadas paralelamente.

Algumas propostas de linguagens lógicas para processamento paralelo têm sido apresentadas, explorando implicitamente o AND-paralelismo e o OR-paralelismo.

Um programa seqüencial especifica a execução de uma lista de comandos.

A execução de um programa seqüencial pode ser definido como sendo um processo.

A comunicação entre processos que podem ser atribuídos aos múltiplos processadores pode ser efetuada através de variáveis compartilhadas ou por troca de mensagem.

Modelos de programação baseados em variáveis compartilhadas permitem implementações com menor complexidade em relação aos modelos com troca de mensagem.

Entretanto, as leituras e escritas dessas variáveis devem ser feitas, considerando algumas restrições, já que uma leitura e escrita ou múltiplas escritas não podem ser executadas simultaneamente.

Isto exige a utilização de uma seção crítica envolvendo o acesso a variáveis compartilhadas.

Neste modelo de programação o paralelismo pode ser explorado em diversas fontes e apresentar uma granularidade grossa, média ou fina, de acordo com a fonte de paralelismo, que pode ser através de subrotinas, laços, blocos básicos, comandos, operações ou instruções.

As subrotinas são módulos independentes de computação que podem ser implementados como subrotinas independentes, e serem executadas paralelamente.

Estes módulos podem ser especificados como macrotarefas, e apresentam um paralelismo de granularidade grossa.

As iterações de laços independentes podem ser executadas paralelamente.

Dependendo do processamento envolvido em cada iteração tem-se um paralelismo de granularidade grossa ou média.

Os blocos básicos podem ser executados paralelamente se não existirem dependências entre os mesmos.

Um bloco básico é uma seqüência de comandos que não contém desvios.

Conforme os processamentos envolvidos tem-se um paralelismo de granularidade grossa ou média.

Os comandos ou operações podem ser processados simultaneamente, através de um paralelismo de granularidade fina.

A execução paralela de múltiplas instruções é usualmente providenciada dentro de cada processador através de múltiplas unidades funcionais pipelining, apresentando um paralelismo de granularidade fina.

A paralelização de um programa pode ser realizada particionando-o em múltiplos subprogramas, sendo esta denominada multitasking ou macrotasking.

Várias linguagens têm sido propostas oferecendo este modelo.

Ilustra esse modelo, que apresenta uma granularidade média ou fina, ultitarefas ou Macrotarefas.

Uma paralelização do programa em uma granularidade mais fina é oferecida pelo modelo que utiliza a técnica denominada microtasking, que divide o trabalho a ser executado em microtarefas.

Esta paralelização está presente nos laços paralelos e blocos paralelos oferecidos por algumas linguagens de programação paralela.

Abaixo ilustra o modelo que utiliza microtarefas.

Microtarefas.

Uma outra alternativa é particionar um programa em múltiplas tarefas, sendo cada uma particionada em múltiplas microtarefas.

Este modelo combina multitasking com microtasking.

Macrotarefas e Microtarefas.

O modelo que utiliza memória compartilhada distribuída apresenta uma menor complexidade para o programador, se comparado com a programação por troca de mensagens, devido à semelhança com um programa seqüencial.

Assim o programador não tem nenhuma preocupação com a comunicação e com o gerenciamento do particionamento do conjunto de dados, podendo focar toda a sua atenção única e exclusivamente no desenvolvimento dos algoritmos do problema.

Três abordagens têm sido utilizadas na implementação de sistemas que utilizam memória virtual compartilhada, Implementação por hardware, estendem técnicas tradicionais de caching para arquiteturas escaláveis.

Implementação de bibliotecas e pelo sistema operacional, o compartilhamento e a coerência são obtidos através de mecanismos de gerenciamento de memória virtual.

Implementação pelo compilador e bibliotecas, acessos compartilhados são automaticamente convertidos em primitivas de coerência e sincronização.

Levando em conta que muitos programas paralelos definem seus próprios requisitos de consistência de mais alto nível, requisitos de consistência de memória podem ser relaxados.

Para a construção correta de um programa em um sistema com memória compartilhada distribuída, o programador deve conhecer sobre como as atualizações são propagadas no sistema.

Este modelo pode migrar ou replicar dados compartilhados para permitir uma maior eficiência no acesso das mesmas.

Em sistemas multicomputadores, cópias nas memórias locais dos dados compartilhados permitem que seus acessos sejam efetuados eficientemente.

Esta abordagem, chamada caching, cria entretanto, o problema denominado consistência de cache, que ocorre quando um processador atualiza um dado compartilhado.

Como cópias deste dado podem estar presentes em outros nós, estes devem ser mantidos consistentes com a versão do dado mais recente, não permitindo que um processador obtenha um valor que não foi atualizado.

Os modelos de consistência de memória, de acordo com podem ser, Consistência estrita, uma leitura retorna o valor mais recente.

Consistência seqüencial, Os acessos devem ser ordenados de acordo com os acessos de todos os processadores.
Consistência fraca, os acessos aos dados são tratados separadamente da sincronização, mas requerem que todos os acessos aos dados anteriores sejam feitos antes que uma sincronização seja efetuada.

Cargas e armazenagens entre sincronizações são livres de ordenação.

Consistência release, é uma consistência fraca com dois tipos de operadores, acquire e release implementados numa seção crítica.

O operador acquire em um outro nó garante que todas as atualizações realizadas pelo processador estejam consistentes antes que a variável de sincronização tenha sido obtido.

É usado pelos sistemas Quarks e Dash.

Consistência lazy release, é um tipo de consistência release que busca reduzir o número de mensagens e a quantidade de dados exportados por acessos remotos à memória.

Neste modelo os dados são exportados apenas quando ocorre um acesso aos dados através do operados acquire.

Esta consistência garante apenas que um processador verá todas as modificações que precedem o acquire.

O sistema TreadMarks oferece este modelo de consistência.

Consistência entry, é utilizada a relação entre variáveis de sincronização que protegem as seções críticas e os acessos aos dado compartilhados.

São permitidos múltiplos acessos a dados compartilhados para leitura, através dos acessos de sincronização que podem ser exclusivos e não exclusivos.

Uma vantagem em relação ao modelo release é que somente os acessos guardados pela variável de sincronização é que precisa ser liberado, enquanto que na release todas as atualizações devem ser efetuadas.

Outra vantagem deste modelo é a redução de comunicações, pois apenas os processadores que utilizarão os dados é que receberão as atualizações.

Não se tem esta vantagem em relação à consistência lazy release, pois neste modelo as modificações também são importadas quando necessárias.

Para reduzir o custo de latência das informações neste modelo são adicionados mecanismos de pré-busca (pre-fechting).

A escolha do modelo de consistência depende de dois fatores opostos, o desempenho e a segurança na informação.

Quanto mais relaxada for a consistência, melhor será o desempenho, mas a integridade dos dados pode ficar comprometida.

Quanto mais forte for a consistência, mais mensagens são enviadas pela rede para garantir a integridade dos dados, o que acaba comprometendo o desempenho.

Os sistemas com memória compartilhada distribuída desenvolvidos, como IVY provêem uma abstração de memória compartilhada em redes de estações de trabalho.

A facilidade que os sistemas de memória compartilhada proporcionam para o programador tem um custo que é, normalmente, um desempenho inferior ao dos sistemas com troca de mensagens.

Os sistemas de memória compartilhada precisam replicar os dados para realizar as operações de leitura mais rápidas, o que resulta em mensagens adicionais sobre a rede para manter a consistência dos mesmos nas operações de escrita.

Outro problema enfrentado por este modelo é a baixa escalabilidade, ficando difícil conseguir um bom desempenho à medida que se aumenta o número de processadores no sistema.

Memória virtual compartilhada, cada processador acessa a memória compartilhada.

Apresenta o modelo de programação que utiliza memória distribuída compartilhada, onde cada processador acessa uma memória compartilhada que pode ser local ou distante.

Para que um programa possa ser executado por um computador paralelo com memória distribuída é necessário distribuir trechos de seu código entre os processadores.

Algumas bibliotecas de programação utilizam o modelo SPMD (Single Program Multiple Data), enquanto que outras permitem que trechos heterogêneos de código sejam distribuídos pelos processadores.

Neste modelo os processadores encontram-se distribuídos fisicamente sobre a rede e podem acessar somente a sua própria memória local.

Todos os nodos estão ligados por algum barramento ou sistema de interconexão, através do qual se pode enviar e receber mensagens.

A comunicação por troca de mensagens envolve pelo menos dois processos, o transmissor e o receptor, sendo que podem haver vários transmissores e vários receptores.

A comunicação se procede pelas primitivas send e receive, através das quais um processo envia uma mensagem para outro processo ou para um grupo de processos.

Atualmente, o modelo de programação predominante para a programação sobre uma rede de estações de trabalho é a troca de mensagens.

Diversas bibliotecas foram desenvolvidas por instituições de pesquisa, como PVM.

Com a troca de mensagens, a memória fisicamente distribuída é completamente exposta para o programador, que precisa decidir e conhecer a localização de todos os processos e dos dados, bem como efetuar explicitamente todas as comunicações entre eles, enviando e recebendo mensagens e sincronizando cada um dos processos.

Isto torna o modelo de programação com troca de mensagens bastante pesado para o programador, principalmente para aplicações grandes e com estruturas de dados complexas.

A grande vantagem deste paradigma é a escalabilidade oferecida.

O problema deste modelo é quanto à dificuldade de localização das threads criadas dinamicamente, já que o programador precisa conhecer a localização das mesmas para enviar e receber mensagens.

O conceito de chamada remota de procedimento (RPC) foi introduzido por Andrew Birèll e Bruce Nelson em 1983 e tem sido muito estudado.

Muitos trabalhos de pesquisa propuseram modelos que visam melhorar o modelo cliente-servidor, tradicional tornando-o mais transparente.

Este modelo elimina a designação explícita do servidor e a administração de recebimentos de mensagens do lado do cliente.

Ao invés de enviar uma requisição utilizando uma mensagem para um servidor e receber um resultado através de uma mensagem, este modelo utiliza uma chamada a um procedimento que pode estar situado em qualquer nodo da rede, da mesma maneira que seria chamado se o procedimento fosse local.

A chamada remota de um procedimento, é baseada no envio de uma mensagem de pedido para o servidor por uma função intermediária, chamada stub cliente.

Do outro lado, a operação se completa.

A requisição é desempacotada  e o procedimento é executado.

O resultado é enviado de volta através de uma mensagem para a stub cliente.

Os resultados são desempacotados  e o processo é desbloqueado.

Chamada Remota de Procedimento.

Todo o poder e elegância do mecanismo do RPCs residem em funções que podem ser chamados de modo implícito e transparente.

Existem alguns problemas que o mecanismo tem que resolver, como por exemplo a localização do servidor de processo ou o servidor de nomes.

Vários sistemas se baseiam no modelo RPC com algumas variações e aperfeiçoamentos que foram desenvolvidos para melhorar o seu desempenho, como comunicação assíncrona, onde os processos clientes e servidores não ficam bloqueados ao enviarem e receberem mensagens.

Os sistemas Nexus, que utiliza execução remota de serviços, PM 2, que utiliza LPRC (Chamada Remota de Procedimentos Leves) e Athapascan, baseado em RPC assíncrono são exemplos de ambientes que permitem a execução de aplicações paralelas em arquiteturas distribuídas que utilizam um modelo de chamada remota de procedimentos.

Este modelo tem sido proposto para tentar solucionar os problemas apresentados pela programação com troca de mensagens (localização das threads criadas dinamicamente) bem como para amenizar o problema do modelo que implementa memória compartilhada (baixa escalabilidade e conseqüentemente o baixo desempenho quando se utilizam vários processadores).

O paradigma de programação paralela baseada no paralelismo de dados representa uma forma de exploração de operações simultâneas sobre grandes conjuntos de dados, ao invés de especificar várias tarefas paralelas de controle.

Este estilo de programação é adotada em máquinas contendo de centenas a milhares de processadores.

A concorrência não é especificada na forma de diferentes operações simultâneas, mas na aplicação da mesma operação sobre múltiplos elementos de uma estrutura de dados.

Um exemplo de uma destas operações é a soma de 3 sobre todos os elementos de uma determinada matriz.

Um programa paralelo baseado no paralelismo de dados é um conjunto de operações semelhantes a esta.

Este paradigma apresenta uma granularidade fina, já que cada operação é uma unidade computacional distinta das demais.

Exemplo de uma operação com paralelismo de dados.

Este estilo de programação é adotado em máquinas paralelas do tipo SIMD, ou MIMD programadas sob o estilo SPMD.

Como exemplos de linguagens de programação que suportam o paralelismo de dados podem ser citados o DataParallel C, o pC++ e o HPF.

O alto desempenho das redes de estações de trabalho aliado ao desempenho dos microprocessadores tem feito das redes de estações de trabalho um importante meio de computação paralela.

Uma rede de estações de trabalho pode ser vista como um conjunto de processadores dedicados que realizam ciclos de computação acessando uma área de memória local a cada processador, interconectados por uma rede física.

Abstraindo-se esta rede de estações de trabalho, podemos compará-la a um multicomputador, onde cada computador executa seu próprio programa.

Os programas acessam a memória local e podem enviar e receber mensagens sobre a rede.

As mensagens são usadas para ler ou escrever na memória remota.

Em termos de performance, as redes de estações de trabalho aproximam-se ou até mesmo excedem a performance de supercomputadores em algumas aplicações.

O aproveitamento de uma rede de estações de trabalho para a computação paralela tem ainda uma grande vantagem, que é a inexistência de custos para sua implementação.

Os nodos da rede provêem um conjunto dinâmico de processadores que são utilizados quando as máquinas estão ligadas à rede, sem estarem executando nenhum processo.

A abstração de uma rede de estações de trabalho para ser usada como um multicomputador têm sido objeto de estudo de vários grupos de pesquisa.

Vários sistemas e bibliotecas que permitem a programação paralela sobre uma rede de estações de trabalho foram e continuam sendo desenvolvidos, utilizando os modelos de memória compartilhada, chamada remota de procedimentos ou troca de mensagens, sobre uma rede homogênea ou heterogênea.

Dentre eles podem ser destacados, A seguir serão apresentados os sistemas mais significativos (Nexus, Athapascan e TreadMarks), tendo em vista a concepção de um sistema que utiliza memória virtual distribuída, como é o caso do MDX.

Nexus é um ambiente multithreaded que permite a execução de aplicações paralelas em arquiteturas distribuídas que originou-se dos trabalhos de pesquisa de Ian Foster, Steven Tuecke (Argonne National Laboratory, Argonne) e Carl Kesselman (California Institute of Technology, Pasadena) em 1993.

Nexus tem o objetivo de servir como compilador para algumas linguagens paralelas que são usadas diretamente pelos programadores de aplicações paralelas, incluindo nPerl, Fortran M e Compositional C++.

Nexus é um ambiente portável e eficiente, que permite construir aplicações que usam diversas linguagens de programação.

Nexus não provê a abstração de uma máquina virtual para as camadas superiores, mas provê um conjunto de funcionalidades que pode ser usado em complemento às ferramentas providas para o sistema operacional.

Entre estas funcionalidades, o multithreading e as ferramentas de comunicação evidentemente se destacam.

A maneira pela qual estas duas funcionalidades foram integradas é o centro da concepção de Nexus.

A interface de Nexus é organizada em torno de cinco abstrações, nodos, contextos, processos leves, os ponteiros globais e requisição remota de serviço.

Um processo leve executa uma requisição remota de serviço não importando o contexto em que o ponteiro global foi designado.

A execução de uma aplicação consiste em um conjunto de processos leves que executam dentro de seus espaços de endereçamento, chamado contextos, que estão alocados nos nodos da arquitetura subjacente.

Os processos leves de um mesmo contexto podem comunicar-se diretamente entre si pela memória compartilhada.

Os processos leves também podem executar requisições de serviços distantes que provocarão a execução de procedimentos em outros contextos, usando algum ponteiro global.

Nodos, contextos, ponteiros globais e processos leves resumem tudo que pode ser criado e destruído dinamicamente.

Nodos, Um nodo é a abstração mais básica no Nexus.

Um nodo representa um recurso físico de processamento, conseqüentemente, o conjunto de nodos alocados pelo programa determina o poder total de processamento disponível.

Quando um programa que usa Nexus inicia, um conjunto inicial de nodos é criado, sendo que os nodos podem ser criados e removidos dinamicamente.

Nexus provê um conjunto de rotinas para criar nodos sobre os recursos computacionais nomeados.

Um nodo especifica somente um recurso computacional e não corresponde a qualquer meio de comunicação ou protocolo.

Contextos, o processamento toma lugar dentro de um contexto.

Cada contexto relata um código executável e um ou mais segmentos de dados para um nodo.

Vários contextos podem ser mapeados sobre um único nodo e os contextos não podem ser migrados entre os nodos.

Os contextos são criados e destruídos dinamicamente, sendo que são criados inúmeros contextos durante a execução dos programas, visto que a criação de contextos é uma operação de baixo custo operacional.

Um código de inicialização é executado automaticamente pelo Nexus quando um contexto é criado.

Uma vez inicializado, um contexto fica inativo até que uma thread é criada explicitamente por uma requisição remota de serviço para o contexto.

A operação de criação é sincronizada para garantir que um contexto não seja utilizado antes da sua completa inicialização.

Todas as threads de controle em um contexto são equivalentes e todo o processamento é assíncrono.

Processos Leves Threads, o processamento toma lugar em uma ou mais threads de controle.

Uma thread de controle precisa ser criada dentro de um contexto.

Podem ocorrer a criação de threads dentro do mesmo contexto da thread corrente que está executando e em diferente contexto da thread corrente.

O número de threads que podem ser criadas dentro de um contexto é limitado apenas pelo recurso disponível.

As rotinas de manipulação de threads do Nexus são modeladas a partir de um subconjunto da especificação POSIX Threads e incluem a criação e terminação das mesmas.

Mutexes e variáveis de condição são utilizadas para prover a sincronização entre threads dentro de um mesmo contexto.

Ponteiros Globais, Nexus provê o compilador com um espaço de nomes global, permitindo que um nome global possa ser criado para qualquer endereço dentro de um contexto.

Este nome é chamado ponteiro global.

Um ponteiro global é um nome que designa alguns dados de endereço de memória em um determinado contexto.

É uma generalização do ponteiro tradicional para as arquiteturas distribuídas.

Um ponteiro global pode ser movido de um contexto a outro, o que permite construir estruturas de dados distribuídas, por exemplo, em vários nodos.

Requisição Remota de Serviços, Uma thread pode requisitar que uma ação seja realizada num contexto remoto emitindo uma requisição remota de procedimento.

Os ponteiros globais foram introduzidos em Nexus para representar o papel de destinatário para as comunicações.

Estas comunicações seguem uma lógica de chamada remota de procedimentos.

Elas são chamados requisição remota de procedimento em Nexus.

Assim, um processo pode, durante a sua execução, ativar a execução de um processamento distante ao ativar uma requisição remota de procedimento.

Os objetivos de contexto são designados por um ponteiro global passado como argumento, no momento da chamada.

A diferença radical com chamadas remotas de procedimentos é que não há resultado devolvido.

A requisição remota de serviços representa o único mecanismo de comunicação presente em Nexus.

A requisição remota de serviços é inicializada por prover um ponteiro global para um endereço no contexto de destino e o identificador para o handler no contexto remoto.

Um buffer é retornado da operação de inicialização.

Os dados a serem passados para o handler remoto são colocados no buffer que usa o ponteiro global como inicialização para determinar se é necessária alguma conversão ou codificação de dados.

Ao realizar a requisição remota de serviços, Nexus usa o ponteiro global como inicialização para determinar qual protocolo de comunicação pode ser usado para a comunicação com o nodo em que o contexto reside.

Para suportar a heterogeneidade, Nexus implementa funções encapsuladas de threads e comunicação em módulos de threads, utilizando POSIX, DCE, C e Solaris threads e módulos de protocolos de comunicação, utilizando sockets com TCP e Intel NX Message-Passing.

Atualmente, Nexus está disponível em multiprocessadores de arquiteturas IBM SP2/Aix e Intel Paragon/MP, como também em redes de estações de trabalho Sun/Solaris.

Nexus não introduz nenhuma semântica particular, como para o funcionamento do escalonamento de processos leves.

Assim, de uma arquitetura para outra, a implementação de Nexus poderá variar de um escalonamento sem preempção para um escalonamento preemptivo com prioridades, aumentando a portabilidade do ambiente.

A tabela 31 a seguir apresenta de forma resumida as principais características do sistema Nexus.

Principais características do Sistema Nexus.

Athapascan é um sistema de execução paralela baseado na linguagem C, formado por um conjunto de primitivas agrupados numa biblioteca de funções, que são compiladas e ligadas através do compilador padrão.

Athapascan roda sobre um ambiente tipo Unix, e utiliza MPI para efetuar a comunicação.

Athapascan é um ambiente multithreaded portável e está implementado para as máquinas IBM SP1, SP2 com AIX, Sun Sparc/M68 K com Sun OS4, Data General AViiON com DGUX e PC compatíveis com Linux.

O modelo de programação de Athapascan explora dois níveis de paralelismo.

O primeiro nível é o paralelismo entre computadores, implementados com processos de sistema.

É um paralelismo de grossa granularidade, devido ao sistema operacional sobre o qual executa, a falta de memória fisicamente compartilhada e a baixa velocidade da rede de estações de trabalho.

O segundo nível de paralelismo aparece dentro de um computador, entre um processador de computação e seu processador de comunicação fixo ou entre processadores em uma máquina de multiprocessador simétrica.

Para alcançar desempenho melhor, uma boa granularidade deve ser implementada através de mecanismos baratos.

Athapascan usa threads como base para a execução de um processo, com funções de controle de threads locais e remotas.

Com isto, um algoritmo irregular é expresso como uma rede dinâmica de threads comunicantes.

A execução de Athapascan baseia-se num núcleo de comunicação para executar os seguintes processos, Administração de Processos Virtuais, Os processadores físicos componentes da Máquina Virtual de Athapascan não são diretamente visíveis pelo programador, sendo que este tem somente a noção de processador virtual.

Um processador virtual é associado a uma máquina física, sem possibilidade de migração, e é de responsabilidade do núcleo de comunicação realizar esta associação.

Da mesma maneira, o núcleo de comunicação tem que prover uma identificação global única para cada processador virtual.

Comunicação ponto a ponto, O núcleo de comunicação realiza o envio de mensagens confiáveis, entre dois processadores virtuais.

A emissão é normalmente assíncrona, e a recepção bloqueante e não seletiva, com buferização.

Gerência da heterogeneidade, athapascan gera um identificador na mensagem que permite empacotar e desempacotar corretamente cada tipo de dado, utilizando MPI como meio de comunicação.

Ambiente de Execução, o ambiente multithreaded de execução permite a criação de um número indefinido de processos preemptivos e precisa associar um contexto à cada thread de execução.

O ambiente multithreaded de execução oferece também um meio para a utilização de semáforos, barreiras e signals.

A execução de um programa Athapascan envolve muitos objetos que implementam os conceitos acima mencionados.

Alguns destes objetos existem no momento da inicialização, outros devem ser criados explicitamente e devem ser destruídos.

Alguns objetos também requerem um identificador uniforme por todos os nodos.

Os objetos são, Nodos, são os processos pesados.

O conjunto de nodos é especificado no momento da inicialização e não pode ser modificado.

Eles são numerados de 0 ao número total de nodos menos 1.

Threads são os processos leves.

Uma thread inicial começa a executar a função principal do programa em todo nodo.

Podem ser criadas diretamente threads locais adicionais em um nodo, ou indiretamente podem ser criadas em outros nodos threads remotas, que começam um serviço distante.

Serviços, as funções começam executando um serviço distante.

Devem ser registrados os serviços executados remotamente em um nodo distante.

O procedimento de inscrição é idêntico em todos os nodos.

Portas são os endereços de comunicações.

Para enviar mensagens, eles devem ser enviados a uma porta de um nodo distante.

Só as threads que executam no nodo podem receber mensagens da porta referida, mas a porta pode ter sido criado em qualquer nodo.

O algoritmo de criação de portas pode controlar se as mesmas foram criadas, por um nodo diferente ou não das portas criadas por outros nodos.

Pedidos, são o estado de uma comunicação.

Mensagens enviadas ou recebidas e criações de threads remotas têm um pedido associado.

Essas operações podem ser bloqueantes ou não.

O pedido é usado para esperar ou testar a terminação da comunicação, no caso em que são exigidas operações não bloqueantes.

O mesmo pedido também pode ser usado para verificar a terminação correta de uma comunicação.

Um procedimento de inicialização permite para o programador inicializar os objetos seguramente.

Este procedimento garante para todos os nodos um esquema coerente de nomeação de objetos.

A seguir apresenta de forma resumida as principais características do sistema Athapascan.

Principais características do Sistema Athapascan.

O sistema TreadMarks utiliza a memória distribuída compartilhada para permitir que os processos assumam uma memória virtual globalmente compartilhada, executando em nodos que não compartilham memória fisicamente.

TreadMarks provê a abstração de uma memória globalmente compartilhada, em que cada processador pode acessar qualquer item de dados, sem que o programador tenha a preocupação com a localização dos dados ou da forma como acessar seu valor.

A memória compartilhada é implementada como uma seqüência linear de bytes, baseado no modelo de consistência release.

A implementação de TreadMarks usa o hardware da memória virtual para detectar acessos, bem como um protocolo de múltipla-escrita para diminuir problemas causados por diferentes tamanhos de página de memória e granularidade das aplicações.

A interface de programação de aplicação (API) de TreadMarks é simples, e poderosa, provendo facilidades para criação e destruição de processos, sincronização e alocação de memória compartilhada.

As duas primitivas de sincronização de TreadMarks, barreiras e bloqueio exclusivo, têm um papel importante para a programação com TreadMarks, pois permitem gerenciar o acesso concorrente às variáveis globais compartilhadas, evitando os conflitos no acesso das mesmas.

TreadMarks pode migrar ou replicar dados para implementar a abstração de memória compartilhada.

TreadMarks é executado no nível de usuário em redes Unix de estações de trabalho, sem modificações no kernel ou privilégios especiais, juntamente com a interface padrão e compiladores do Unix.

Por esse motivo, o sistema é largamente portável para várias plataformas, por exemplo IBM RS-6000, SP-1 e SP-2, DEC Alpha e DEC-Station, bem como Hewlett-Packard, Silicon Graphics e Sun.

Programas escritos em C e C++ ou Fortran são compilados e ligados com a biblioteca TreadMarks, usando qualquer compilador padrão para a linguagem, o que garante a grande portabilidade de TreadMarks.

TreadMarks implementa a comunicação entre as estações de trabalho usando UDP/IP através da interface de sockets de Berkeley.

Como UDP/IP não garante entrega confiável, TreadMarks usa operações específicas de protocolo a nível de usuário para garantir a entrega segura das mensagens.

Cada mensagem enviada por TreadMarks é uma requisição ou uma resposta.

Mensagens de requisição são enviadas como um resultado de uma chamada explícita para uma rotina da biblioteca TreadMarks ou uma falta de página.

Quando uma máquina envia uma mensagem de requisição, ela fica bloqueada até que a mensagem de resposta chega.

Se a resposta não chegar dentro de um determinado tempo, a mensagem original é retransmitida.

Após receber uma mensagem de requisição, o manipulador realiza a operação específica e envia a mensagem de resposta, retornando para o processo interrompido.

Para implementar o protocolo de consistência, TreadMarks usa uma chamada de sistema para controlar o acesso para as páginas compartilhadas.

Qualquer tentativa para adquirir acesso restrito para uma página compartilhada gera um SIGSEGV signal.

A rotina manipuladora examina a estrutura de dados local, para determinar o estado da página e examina a pilha de exceções para determinar se a referência é leitura ou escrita.

Se a referência é uma leitura, a proteção de página é acertada para somente leitura.

Para uma escrita, o manipulador cria uma cópia das páginas livres, da mesma forma que ocorre em resposta para uma falta causada por uma escrita para uma página em modo somente leitura.

A seguir o manipulador atualiza os direitos de acesso para a página original e retorna.

A seguir apresenta um exemplo de um programa que implementa o algoritmo de Iteração de Jacobi utilizando a API de TreadMarks.

Programa que implementa o algoritmo de Iteração de Jacobi utilizando a API de TreadMarks.

Apresenta um resumo das principais características de TreadMarks.

Principais características do Sistema TreadMarks.

O sistema DEFINIÇÃO DO SISTEMA MDX MDX destina-se às aplicações paralelas que necessitam de criação dinâmica de threads, oferecendo a abstração de uma memória virtual compartilhada.

A idéia principal é de permitir que o programador escreva um programa multithreaded no qual as threads são criadas na rede de processadores, e o compartilhamento dos dados se dá através de uma memória virtual distribuída.

O ambiente MDX é um sistema que executa sobre uma rede heterogênea de estações de trabalho, abstraindo-a como uma máquina virtual paralela, onde cada nodo da rede representa um computador, composto por um ou mais processadores e uma memória local, interconectados por uma rede física, sobre os sistemas operacionais Windows, OS/2, Linux, Solaris.

O sistema é baseado no modelo cliente-servidor.

Nesse modelo, os serviços do sistema são oferecidos por servidores especializados.

Um programa cliente solicita a realização de um serviço por um servidor enviando os parâmetros adequados.

O cliente é suspenso e a execução do serviço começa.

Ao término da execução do serviço os resultados são enviados para o programa cliente, que é acordado.

Uma qualidade importante deste esquema é que ele funciona independentemente da localização do cliente e do servidor.

Se eles são localizados na mesma máquina a comunicação ocorrerá localmente, senão, ela se realizará através da rede.

A programação no ambiente MDX é realizada utilizando o modelo de memória distribuída compartilhada com a programação SPMD (Single Program Multiple Data), com o mesmo programa replicado em todos os nodos da rede e execução de um determinado trecho de código (thread) em cada um deles.

A sincronização é feita com o uso de semáforos e barreiras.

O ambiente MDX tem como principais características a criação dinâmica de threads em qualquer processador, a sincronização com semáforos e barreiras, a comunicação através de uma memória virtual distribuída e a implementação baseada no modelo cliente-servidor com a utilização de RPC.

A escolha desse modelo se deve a um dos objetivos principais do projeto MDX, que é facilitar a atividade de programação e execução de programas paralelos, de modo que qualquer programador possa portar um programa multithreaded concorrente para um programa paralelo a ser executado no ambiente MDX.

Esta opção adotada no ambiente MDX, isenta o programador de toda a comunicação entre os processos.

A única preocupação que ele deve ter é em relação à sincronização dos processos, da mesma forma que necessita um programa concorrente convencional, principalmente para contornar o problema do não-determinismo e da manutenção da seção crítica nos programas paralelos.

A programação no ambiente se dá através de um conjunto de primitivas de uma biblioteca portável desenvolvida em C e C++, que deve ser compilada e ligada com o programa através dos compiladores de cada sistema operacional nativo.

A biblioteca LMDX é formada por dois grupos de primitivas, as primitivas a nível de usuário e a nível de sistema.

As primitivas a nível de usuário são aquelas que o programador usa no momento do desenvolvimento do programa paralelo, ou seja, são aquelas primitivas que são usadas no lugar das primitivas convencionais, necessárias para expressar a concorrência e sincronização em programas multithreaded.

As primitivas a nível de sistema são primitivas e funções que são inseridas no código pelo pré-processador e que são compiladas e ligadas ao código do programa, sendo responsáveis pela comunicação com os gerenciadores de memória distribuída, de sincronização e de execução.

A seguir serão apresentadas as primitivas a nível de usuário, que permitem a declaração de variáveis compartilhadas, a criação e utilização de semáforos e barreiras num ambiente distribuído, a criação, sincronização e destruição de threads locais e remotas, Especifica o compartilhamento da variável entre todos os processos, var_name é o nome da variável compartilhada, que pode ser de qualquer tipo predefinido pela linguagem C (int, float, char, etc).

Esta primitiva inicializa uma barreira identificada com um nome e um número que indica a quantidade de processos a serem sincronizados na barreira, barrier_name é o nome da barreira, n_proc é a quantidade de processos que deverão sincronizar na barreira.

Esta primitiva sincroniza os processos através de uma barreira, identificada pelo nome passado como argumento.

Deve ser efetuada uma inicialização com o número de processos que deverão sincronizar na barreira, através da primitiva LMDX_barrier_init, antes de se usar esta primitiva, barrier_name é o nome da barreira.

Esta primitiva inicializa um semáforo identificado com um nome e um número de inicialização do mesmo, sema_name é o nome do semáforo, init_value é a o valor de inicialização do semáforo.

Esta primitiva decrementa o valor do semáforo e se o mesmo for menor ou igual a zero o processo ficará bloqueado numa fila, sema_name é o nome do semáforo.

Esta primitiva incrementa o valor do semáforo desbloqueando o processo que está na fila, se existir, sema_name é o nome do semáforo.

Esta primitiva declara uma thread do sistema MDX.

Esta thread será executada em qualquer um dos nodos do sistema MDX com a chamada da primitiva LMDX_start_thread ou LMDX_start_dthread, thread_name é o nome da thread que está sendo declarada, arg é um ponteiro void para o argumento a ser passado para a thread.

Esta primitiva declara um identificador de uma thread do sistema MDX.

Thread_id é o nome do identificador da thread.

Esta primitiva cria e executa uma thread identificada por um nome num nodo do sistema MDX.

Esta primitiva faz com que a thread criada não libere os descritores da mesma ao finalizar a sua execução com a chamada da primitiva LMDX_exit_thread, exigindo a chamada da primitiva LMDX_join_thread para liberar os identificadores, thread_name é o nome da thread.
Esta primitiva cria e executa uma thread identificada por um nome num nodo do sistema MDX.

Esta primitiva faz com que a thread criada libere todos os descritores ao finalizar a sua execução com a chamada da primitiva LMDX_exit_thread, thread_name é o nome da thread.

Esta primitiva sincroniza uma thread identificada por um nome, criada com a primitiva LMDX_start_thread e libera todos os descritores da mesma em qualquer nodo do sistema MDX, thread_name é o nome da thread.

Esta primitiva destrói uma thread do sistema MDX em execução, independente da sua localização, liberando todos os descritores da mesma, thread_name é o nome da thread.

Esta primitiva finaliza uma thread (na própria thread) que estava sendo executada em qualquer nodo da rede.

O descritor é liberado através de uma mensagem para o gerenciador de execução.

Esta primitiva aloca dinamicamente uma área de memória compartilhada identificada por um nome, var_name é o nome da variável compartilhada e pode ser de qualquer tipo predefinido pela linguagem C.

Esta primitiva libera a área previamente alocada para uma variável compartilhada através da primitiva LMDX_malloc, var_name é o nome da variável compartilhada que identifica uma área previamente alocada.

A seguir serão apresentadas as primitivas a nível de sistema, que fazem com que o as variáveis sejam compartilhadas, os semáforos e barreiras sejam acessados num ambiente distribuído, as threads sejam criadas, sincronizadas e destruidas.

Esta primitiva inicializa o ambiente MDX para a execução de um programa paralelo.

Esta primitiva faz com que o gerenciador de execução execute as operações necessárias para a inicialização do programa.

Esta primitiva finaliza o ambiente MDX após a execução de um programa paralelo, enviando uma mensagem de finalização do programa que é replicada para cada gerenciador de execução.

Esta primitiva faz o mapeamento da saída padrão de qualquer processo, em qualquer nodo, para a console do programa principal, no nodo em que foi executado o programa.

Esta primitiva cria uma variável compartilhada, com nome e tipo passados como argumento.

Esta primitiva faz com que o gerenciador de memória virtual distribuída aloque uma área de memória que será utilizada para as variáveis compartilhadas.

Esta primitiva retorna o valor de uma variável compartilhada.

Se for uma matriz, os índices que identificam o elemento devem seguir o nome da variável, var_name corresponde ao nome da variável compartilhada.

Esta primitiva atualiza o valor de uma variável compartilhada.

Se for uma matriz, os índices devem seguir o nome da variável, var_name corresponde ao nome da variável compartilhada, valor corresponde ao novo valor da variável Esta primitiva cria uma thread identificada por um nome num nodo específico do sistema MDX.

Esta primitiva faz com que a thread criada não libere os descritores da mesma ao finalizar a sua execução com a chamada da primitiva LMDX_exit_thread, exigindo a chamada da primitiva LMDX_join_thread para liberar os identificadores, thread_name é o nome da thread.

Esta primitiva cria uma thread identificada por um nome num nodo específico do sistema MDX.

Esta primitiva faz com que a thread criada libere os descritores da mesma ao finalizar a sua execução com a chamada da primitiva LMDX_exit_thread, não exigindo a chamada da primitiva LMDX_join_thread, thread_name é o nome da thread.
Esta primitiva retorna um identificador do serviço a ser executada no programa.

A seguir são apresentados dois exemplos de programas em LMDX, a iteração de Jacobi que utiliza barreiras e um produtor-consumidor, que utiliza semáforos.

Jacobi é um método para solucionar equações diferenciais.

Nesse exemplo são utilizadas duas matrizes.

Durante a iteração, cada elemento da matriz é atualizado através do cálculo da média dos elementos mais próximos, a saber, acima, abaixo, à direita e à esquerda.

Para solucionar o problema é usada uma matriz auxiliar para armazenar os novos valores da iteração.

Na versão paralela, cada processador atua sobre diferentes linhas da matriz.

O programador escreve um programa paralelo para o ambiente MDX utilizando a linguagem C ou C++ padrão e utiliza as funções do ambiente de programação MDX, da mesma forma que utilizaria as funções para escrever um programa concorrente multithreaded.

A seguir é um exemplo do programa que implementa o algoritmo de Iteração de Jacobi utilizando as funções do ambiente MDX de programação.

Programa que implementa o algoritmo de Iteração de Jacobi utilizando as funções do ambiente MDX O programa inicia com a declaração de uma matriz grid compartilhada e uma matriz scratch local com 1024 linhas e 1024 colunas, as variáveis locais i e j são usadas para manipular as matrizes, a inicialização da matriz (initialize_grid) não está implementada neste exemplo, pois não tem importância na demonstração das primitivas.

Para a sincronização dos processos, são inicializadas duas barreiras a e b, para sincronizar 2 e 3 processos respectivamente.

A partir do programa principal as threads th1 e th2 são criadas.

Cada thread trabalha sobre uma metade distinta da matriz, atualizando a cópia local da matriz auxiliar baseadas nos valores da matriz compartilhada e sincronizam entre si após gerar a matriz local scratch.

Após a sincronização, elas atualizam a matriz compartilhada e sincronizam novamente entre si e com o programa principal.

A partir do programa principal a matriz grid atualizada é exibida na tela.

Antes da compilação, o código de um programa para o ambiente MDX passa por um pré-processador que transforma as chamadas de funções e acessos à memória compartilhada em chamadas de funções que gerenciam a criação remota de threads e implementam o modelo cliente-servidor, transformando as leituras e escritas em requisições para o gerenciador de memória compartilhada.

A seguir apresenta o código após o pré-processamento do algoritmo de Iteração de Jacobi.

Programa que implementa o algoritmo de Iteração de Jacobi após o pré-processamento.

O pré-processador transforma o programa escrito pelo programador inserindo as primitivas a nível de sistema.

O programa principal passa a ser uma rotina do sistema MDX que fica num laço aguardando uma mensagem do gerenciador de execução para criar localmente uma thread ou encerrar a execução.

As threads são ordenadas e identificadas com um número seqüencial de forma que a thread que contém o código do programa principal escrito pelo programador é identificada com o número zero.

O que era o programa principal escrito pelo programador passa a ser a thread LMDX_main e contém inicialmente a primitiva LMDX_init que é uma requisição para o gerenciador de execução executar uma cópia do programa em cada nodo do sistema.

A declaração de uma matriz grid compartilhada é transformada numa requisição LMDX_make_dsm para o gerenciador de memória criar a matriz.

Duas barreiras são inicializadas, sendo a primeira para sincronizar as duas threads nas operações de atualização da matriz para a leitura da matriz compartilhada, sendo esta última inicializada para sincronizar também com o programa principal.

As primitivas LMDX_start_thread enviam uma requisição ao gerenciador de execução que decide em que nodo as mesmas serão criadas e envia a mensagem de criação de thread para o programa do nodo escolhido que está bloqueado na primitiva LMDX_get_execution_service.

O programa bloqueia na barreira, aguardando a execução das duas threads e a seguir mostra a matriz atualizada, acessando a matriz compartilhada através da primitiva LMDX_get_dsm.

As duas threads th1 e th2 apresentam operações semelhantes, diferenciando apenas no fato de que cada uma manipula uma metade distinta da matriz compartilhada.

As threads atualizam a matriz local scratch baseadas no valor da matriz compartilhada grid acessados através da primitiva LMDX_get_dsm e sincronizam entre si, na barreira a, após atualizarem completamente a matriz local.

A matriz compartilhada é então atualizada com os mesmos valores da matriz local com o uso da primitiva LMDX_put_dsm e sincronizadas na barreira b com o programa principal, que apresenta a matriz compartilhada atualizada.

O problema do produtor-consumidor consiste em se ter um buffer de tamanho fixo compartilhado por dois processos.

Um processo chamado produtor produz informações e armazena no buffer.

Outro processo chamado consumidor retira as informações do mesmo.

O problema consiste em controlar o acesso à seção crítica, que neste exemplo é o trecho de código que implementa o buffer.

O produtor deve ser bloqueado quando o buffer estiver cheio até que o processo consumidor libere o mesmo.

O consumidor também deve ser bloqueado no caso do buffer estar vazio, até que o produtor produza alguma informação.

Para solucionar o problema é usado um vetor compartilhado para implementar uma fila circular e três semáforos.

A seguir é um exemplo do programa que implementa o algoritmo do produtor-consumidor utilizando as funções do ambiente MDX de programação.

Programa que implementa o algoritmo do produtor-consumidor utilizando as funções do ambiente MDX.

O programa inicia com a declaração do vetor compartilhado que implementa a fila (buffer) e com a declaração das duas funções (prod e cons) que serão executadas sob a forma de threads em qualquer processador do sistema.

O programa inicia criando os semáforos "s" que controla a seção crítica, "n" que representa o número de informações que podem ser consumidas, e "e" que representa a quantidade de informações que podem ser produzidas.

As threads são criadas através das primitivas LMDX_start_thread.

O programa bloqueia nas primitivas LMDX_join_thread até que as threads encerrem a execução.

A thread produtor (prod) utiliza uma variável de controle (re) que representa a posição do buffer (ré da fila circular), onde deve inserir a informação produzida.

Ela fica num laço infinito produzindo informações.

Quando o buffer estiver cheio, ela fica bloqueada no semáforo até que a thread consumidor libere espaço no buffer.

A thread consumidor (cons) utiliza uma variável de controle (fr) que representa a posição do buffer (frente da fila circular) de onde ela deve retirar a informação a ser consumida.

Ela fica num laço infinito consumindo informações.

Quando o buffer estiver vazio, ela fica bloqueada no semáforo até que a thread produtor insira novas informações.

Antes da compilação, o código do programa para o ambiente MDX passa por um pré-processador.

A seguir, apresenta o código após o pré-processamento do programa produtor-consumidor.

Código do programa que implementa o algoritmo do produtor-consumidor após o pré-processamento.

O pré-processador transforma o programa escrito pelo programador inserindo as primitivas a nível de sistema (LMDX_make_dsm, LMDX_get_dsm e LMDX_put_dsm, para criar, acessar e atualizar o valor da variável compartilhada.

Da mesma forma que no exemplo anterior o programa principal passa a ser uma rotina do sistema MDX, que fica num laço aguardando uma mensagem do gerenciador de execução, para criar localmente uma thread ou encerrar a execução.

Uma das principais diferenças dos sistemas de memória distribuída compartilhada é o modelo de consistência implementado, que afeta tanto o desempenho do mesmo como a confiabilidade de acesso aos dados.

Os sistemas TreadMarks e MDX utilizam a memória distribuída compartilhada para permitir que os processos assumam uma memória virtual globalmente compartilhada, executando em nodos que não compartilham memória fisicamente.

A interface de programação de aplicação (API) tanto do sistema MDX quanto de TreadMarks é simples e poderosa, através de primitivas que permitem a criação e destruição de processos, a sincronização e a alocação de memória compartilhada.

TreadMarks apresenta duas primitivas de sincronização, que são barreiras e bloqueio exclusivo, ao passo que MDX apresenta semáforos e barreiras.

Ambas têm um papel importante para a programação com TreadMarks e MDX, pois permitem gerenciar o acesso concorrente às variáveis compartilhadas, evitando os conflitos no acesso das mesmas e a sincronização de processos.

Tanto TreadMarks quanto MDX podem migrar ou replicar dados para implementar a abstração de memória compartilhada, já que vários sistemas de memória compartilhada replicam dados para melhorar o desempenho da maioria das aplicações.

A forma de acesso à memória compartilhada em TreadMarks é através de páginas do sistema operacional nativo.

No sistema MDX o acesso à memória compartilhada é através de um servidor especializado que implementa uma abstração de memória.

A comunicação entre as estações de trabalho em TreadMarks é implementada usando UDP/IP através da interface de sockets de Berkeley.

Como UDP/IP não garante entrega confiável, TreadMarks usa operações específicas de protocolo a nível de usuário para garantir a entrega segura das mensagens.

No sistema MDX a comunicação é implementada usando TCP/IP através da interface de sockets de Berkeley para garantir a entrega confiável das mensagens.

A principal diferença entre o sistema MDX e TreadMarks é no que se refere à forma de escrever o programa.

Em TreadMarks o programador escreve um programa SPMD, no qual cada processo tem um identificador único baseado no qual realiza diferentes computações.

O mesmo programa é replicado em cada nodo do sistema, substituindo apenas a troca explícita de mensagens por operações sobre variáveis de memória virtual compartilhadas.

Já no sistema MDX, o programador escreve o programa como se ele fosse um programa multithreaded convencional, substituindo as primitivas de criação, junção e destruição de threads, bem como as primitivas de sincronização de processos, pelas primitivas do sistema MDX.

Isto garante uma vantagem adicional ao sistema MDX que é a possibilidade de criação e destruição dinâmica de threads em qualquer nodo do sistema.

TreadMarks executa no nível de usuário em redes Unix de estações de trabalho, sem modificações no kernel ou privilégios especiais, juntamente com a interface padrão e compiladores do Unix.

O MDX também executa no nível usuário, mas apresenta uma vantagem em relação à TreadMarks, já que executa em redes heterogêneas de estações de trabalho, incluindo Unix (Linux, Solaris, AIX), Windows e OS/2.

A forma de criação de processos em TreadMarks é estática, enquanto que no sistema MDX a criação e o término de processos é dinâmica.

O mapeamento no sistema MDX pode ser estático ou dinâmico, permitindo que técnicas de balanceamento de carga sejam desenvolvidas e adicionadas nesse sistema.

Apresenta um comparativo das principais características de TreadMarks e MDX.

Comparações de características de TreadMarks com MDX.

O Sistema MDX executa sobre um núcleo de comunicação.

É formado por um Servidor de Nomes (SN), um Gerenciador de Memória Virtual Distribuída (GM), um Gerenciador de Compilação (GC), um Gerenciador de Execução (GE), um Gerenciador de Sincronização (GS) e um Gerenciador de Programas.

Visão geral do sistema MDX.

A arquitetura básica do sistema MDX é apresentada.

Arquitetura básica do sistema MDX sobre uma rede de estações de trabalho.

A seguir serão apresentados o núcleo de comunicação e os demais servidores do sistema MDX.

O núcleo de comunicação é um componente fundamental num ambiente de execução paralela e distribuída, implementado de acordo com um protocolo cliente-servidor, permite a independência de localização dos processos, interligando todos os clientes e todos os servidores de maneira transparente, rápida e confiável.

O núcleo de comunicação é compreendido por duas camadas, protocolo e encaminhamento de mensagens.

A camada protocolo implementa um protocolo cliente-servidor de base.

Todos os outros protocolos de comunicação do ambiente de programação paralela são implementados por servidores específicos.

Esse protocolo mínimo é uma variante do protocolo RPC.

Essa solução adotada é a mais simples porque simplifica a camada protocolo, facilitando a implementação do núcleo de comunicação.

Nos sistemas tradicionais, o nível usuário solicita um serviço ao núcleo que o executa e retorna os resultados, por exemplo, utilizando os registradores da máquina.

Na organização baseada em microkernel, o núcleo de comunicação transmite somente o pedido e a resposta.

O serviço é realizado por um servidor específico.

Utilizando as vantagens da programação multithreaded, pode-se dividir as tarefas do núcleo em threads, permitindo que as mesmas executem em paralelo.

O único protocolo implementado na camada protocolo é um protocolo RPC.

Os demais são implementados por servidores específicos.

As mensagens de clientes locais ou distantes recebidas pelo servidor são armazenadas na sua fila.

Para executar uma requisição o servidor executa um procedimento que retira a primeira mensagem da fila ou o bloqueia, se a mesma estiver vazia.

Essa camada permite ao cliente enviar a requisição e receber o resultado, e ao servidor receber a requisições e enviar os resultados.

Do lado do cliente, ele faz a emissão de uma mensagem através do núcleo de comunicação.

Do lado do servidor, um procedimento recupera a primeira mensagem da fila, faz o tratamento e envia o resultado ao cliente.

A camada protocolo é organizada, portanto, em torno de quatro funções básicas, envio de uma requisição por um cliente, recepção da requisição por parte do servidor, envio da resposta pelo servidor e recepção da mesma pelo cliente.

Nesta camada, o núcleo de comunicação examina a mensagem e identifica se ela é uma requisição ou uma resposta e a quem ela se destina.

A camada encaminhamento de mensagens é composta por dois processos que fazem a recepção, o roteamento e o envio das mensagens, sendo um para as mensagens de servidores e outro para as mensagens dos clientes.

A implementação dessa camada se reduz a realização da função de localização dos processos clientes e servidores, e o envio das mensagens.

Quando uma mensagem chega, ela deve ser transmitida a um servidor, no caso de ser uma requisição, ou a um cliente, no caso de ser uma resposta, podendo ser transmitida através de outro núcleo de comunicação distante.

Se a mensagem for uma requisição, o processo receptor identifica o servidor destinatário na tabela de servidores local e envia a mensagem para o mesmo.

Se o servidor é distante, a requisição é enviada através de um núcleo de comunicação distante.

Se o servidor é replicado no sistema, o endereço IP do nodo em que ele se encontra deve ser informado no cabeçalho da mensagem.

Caso contrário, o núcleo de comunicação encontra o endereço do servidor, consultando inicialmente a tabela de localização de nomes local e, não encontrando, o núcleo requisita um serviço ao servidor de nomes do sistema.

No caso de ser uma resposta, o cabeçalho da mensagem contém a identificação do cliente que está bloqueado esperando a mesma, permitindo ao processo enviá-la, diretamente ou através de outro núcleo de comunicação distante, ao cliente desbloqueando-o.

As diferentes localizações dos processos servidores não são percebidas pelos processos clientes, que enviam todas as requisições de serviços para o núcleo de comunicação.

Isto garante a todos os processos clientes e a todos os processos servidores o envio e recepção somente de mensagens locais, transferindo para o núcleo de comunicação a tarefa de localizar o servidor e realizar o envio e a recepção de mensagens locais ou distantes.

As mensagens enviadas entre clientes e servidores através do núcleo de comunicação são formadas por um cabeçalho com as informações básicas necessárias para o correto encaminhamento das mensagens.

As requisições possuem a estrutura apresentada as respostas possuem a estrutura apresentada.

Cabeçalho das Mensagens de Requisições.

Cabeçalho das Mensagens de Resposta.

A função do núcleo de comunicação é permitir a comunicação de todos os processos clientes com os processos servidores, que podem ser locais ou distantes, de maneira rápida, confiável e transparente, independente da localização dos mesmos.

O núcleo de comunicação tem a função de receber todas as mensagens de requisição de serviços dos processos clientes, identificar o servidor a quem se destina a mensagem, descobrir a localização do mesmo e enviar a requisição do serviço.

Para cada cliente é criada dinamicamente uma thread para enviar as requisições ao servidor.

Essa thread fica esperando requisições do cliente enquanto ele está em execução.

Além de atender todos os processos clientes locais, o núcleo de comunicação tem a função de atender as requisições dos clientes distantes para os servidores locais.

O núcleo cria uma thread para atender os clientes de cada nodo distante, recebendo as mensagens de requisição para os servidores locais, através do núcleo de comunicação distante.

O núcleo de comunicação também recebe todas as mensagens de resposta dos servidores, encaminhando-as para o cliente.

Para cada servidor local é criada dinamicamente uma thread para enviar as respostas.

Essa thread fica aguardando respostas enquanto o servidor está ativo.

Da mesma forma que acontece com os clientes, o núcleo de comunicação cria uma thread para atender os servidores de cada nodo distante, recebendo as mensagens de respostas para os clientes locais através do núcleo de comunicação distante.

O núcleo tem a função de registrar os processos servidores locais no Servidor de Nomes do sistema, através de um serviço server_register, sendo este o único serviço atendido pelo núcleo.

O processo servidor, quando inicializado, envia a requisição do serviço ao núcleo de comunicação local, que registra o servidor na tabela local e faz uma requisição ao servidor de nomes para o registro no sistema.

O núcleo de comunicação é formado por um processo que fica executando em cada um dos nodos da rede.

É composto por duas threads estáticas, várias threads criadas dinamicamente para garantir o paralelismo, e por uma tabela de localização de nomes de servidores acessados pelo núcleo.

As threads do núcleo de comunicação trocam mensagens locais entre si e com os processos clientes e servidores.

A comunicação entre os processos é através de send e receive implementados com o uso de sockets, através de conexões no domínio Internet orientadas a conexão com entrega confiável de mensagens através do protocolo TCP/IP.

Quando um servidor ou um cliente são inicializados, eles enviam uma mensagem ao núcleo, que cria uma thread para receber e encaminhar todas as mensagens dos mesmos.

Essa thread criada dinamicamente fica em execução durante todo o tempo em que o servidor ou o cliente também estiverem.

Se as requisições de um nodo A forem destinadas a servidores distantes num nodo B, é criada uma thread no nodo B para atender todos os clientes do nodo A.

Da mesma forma, é criada uma thread no nodo A para atender todos os servidores do nodo B.

Essas threads criadas para atender vários clientes e vários servidores de outro nodo são criadas uma única vez e não são destruídas.

O núcleo é formado por uma tabela de localização de nomes de servidores acessados pelo núcleo, por duas threads que aceitam novas conexões dos clientes e servidores e por várias instâncias criadas dinamicamente das threads que recebem mensagens de clientes e servidores, conforme a O Núcleo de Comunicação do Sistema MDX, A seguir serão descritas as threads componentes do núcleo de comunicação, ThASC Thread que aceita conexões de servidores.

A thread Accept Server Connection é criada dinamicamente para receber as respostas do servidor local ou as respostas dos servidores de um nodo distante e entregar ao cliente.

Esta thread fica executando um loop para aceitar novas conexões de processos servidores locais ou de servidores distantes, através do uso de sockets numa porta pré-estabelecida.

Se a conexão for de um servidor local, essa thread registra o servidor no Servidor de Nomes e na Tabela Local de Nomes (NLT) e cria dinamicamente uma instância da thread ThRSR para atender o servidor enquanto ele estiver em execução.

Se for de um servidor distante, uma instância da thread ThRSR é criada para atender todos os servidores daquele nodo.

ThRSR-Thread que recebe as respostas dos servidores.

Uma instância desta thread é criada dinamicamente e é responsável por receber as respostas do servidor local ou dos servidores distantes.

A thread ao receber a mensagem, identifica a localização do cliente e se for local, envia diretamente ao cliente.

Se for distante, envia para o cliente através de outra instância dessa thread criada no nodo em que está o cliente.

Se a thread foi criada para atender um servidor local, ela é destruída quando o servidor é finalizado.

Se ela foi criada para atender todos os servidores de um nodo distante, ela somente é destruída quando o núcleo de comunicação é finalizado.

ThACC Thread que aceita conexões de clientes.

A thread Accept Client Connection aceita conexões de clientes locais ou distantes e cria uma instância da ThRCR para atender o cliente local ou os clientes de um nodo distante.

Esta thread fica executando um loop para aceitar novas conexões de processos clientes locais ou distantes, através do uso de sockets numa porta pré-estabelecida.

Se a conexão for de um cliente local, essa thread cria dinamicamente uma instância da thread ThRCR para atender o cliente enquanto ele estiver em execução.

Se for distante, uma instância da thread ThRCR é criada para atender todos os clientes daquele nodo.

ThRC-Thread que recebe as requisições dos clientes.

Uma instância desta thread é criada dinamicamente e é responsável por receber as requisições do cliente local ou dos clientes distantes.

A thread ao receber a mensagem, identifica a localização do servidor através da Tabela Local de Nomes ou do Servidor de Nomes, e se for local, envia diretamente ao servidor.

Se for distante, envia para o servidor através de outra instância dessa thread criada no nodo em que está o servidor.

Se a thread foi criada para atender um cliente local, ela é destruída quando o cliente é finalizado.

Se ela foi criada para atender todos os clientes de um nodo distante, ela somente é destruída quando o núcleo de comunicação é finalizado.

NLT Tabela Local de Nomes.

A tabela local de nomes de servidores acessados pelo núcleo tem a função de armazenar a localização dos servidores locais, bem como a localização dos servidores que já foram acessados pelo núcleo de comunicação, para evitar a requisição de um serviço ao servidor de nomes por parte do núcleo de comunicação, toda vez que um cliente requisita um serviço de um servidor que não é local.

Essa tabela tem inicialmente a informação da localização do servidor de nomes e dos servidores locais.

Quando um cliente local requisita um serviço a um servidor distante pela primeira vez, sua localização é armazenada nessa tabela.

Além da localização do servidor, também é armazenado o socket no qual a mensagem deve ser enviada.

Ela armazena as informações do servidor, Informações de Servidores Acessados na Tabela Local de Nomes.

Além da informação dos servidores acessados pelo núcleo, também são armazenadas informações de clientes de nodos distantes acessados pelo núcleo.

Como existe uma única instância da thread ThRCR para atender todos os clientes de um nodo distante, é necessário armazenar a localização da mesma e o socket no qual a requisição deve ser enviada.

Informações dos Clientes Distantes na Tabela Local de Nomes.

A comunicação entre os processos clientes e servidores se dá sempre através do núcleo de comunicação, que identifica a requisição ou resposta.

Se for uma requisição o núcleo verifica se foi informado o endereço IP do servidor a que se destina a mensagem.

Se for, o núcleo envia a requisição diretamente ou através de um nodo distante.

Se o endereço IP do servidor não foi informado o núcleo consulta primeiramente na tabela local de nomes (cache) e, se o servidor é desconhecido, faz uma requisição para o servidor de nomes do sistema para descobrir a localização do mesmo.

Se for uma resposta, o núcleo identifica o endereço IP do cliente no cabeçalho da mensagem e envia a resposta diretamente ou através de um núcleo distante para o cliente que está aguardando.

Desta forma, podem ocorrer as seguintes situações no núcleo, Inicialização do Servidor de Nomes.

A inicialização do servidor de nomes envolve quatro operações.
Servidor de Nomes faz uma conexão com o núcleo através da ThASC numa porta pré-estabelecida.
ThASC atualiza a Tabela Local de Nomes.

ThASC cria dinamicamente a ThRSR e um novo socket (socket 2).

As mensagens são enviadas para o Servidor de Nomes através do socket 2 e a ThRSR fica bloqueada atendendo o Servidor de Nomes enquanto ele estiver em execução, para retirar as mensagens da fila (socket 2) e entregar para o cliente.
Um processo servidor é inicializado, conforme inicialização de um processo servidor.

A inicialização de um processo servidor envolve as seguintes operações.
Um novo servidor faz uma conexão com o núcleo através da ThASC numa porta pré-estabelecida.

ThASC requisita um serviço do Servidor de Nomes, fazendo uma conexão com a ThACC numa porta pré-estabelecida.

ThACC cria dinamicamente a ThRCR e um novo socket (socket 5).

A mensagem de registro do servidor é enviada para o Servidor de Nomes através do socket 2, que faz o registro e envia a resposta pelo mesmo socket.
A ThRSR que atende o Servidor de Nomes e estava bloqueada recebe a resposta, identifica o socket e envia a resposta (socket 5) para a ThASC.

A ThASC atualiza a Tabela Local de Nomes.

A ThASC cria dinamicamente a ThRSR que atenderá o novo servidor e um novo socket (socket 4).

Um processo cliente é inicializado, conforme Inicialização de um processo cliente.

A inicialização de um processo cliente envolve as seguintes operações.
Um novo cliente faz uma conexão com o núcleo através da ThACC numa porta pré-estabelecida.

ThACC cria dinamicamente a ThRCR que atenderá o novo cliente e um novo socket (socket 5).

Um processo cliente faz uma requisição a um servidor local, Requisição de um cliente a um servidor local.

A requisição de um cliente a um servidor local envolve as seguintes operações.
Cliente envia uma requisição.

A ThRCR que foi criada para atender esse cliente retira a mensagem da fila, identifica o servidor, consulta a Tabela Local de Nomes para descobrir a localização e o socket do servidor.

A ThRCR envia a mensagem no socket do servidor.

O servidor processa a mensagem e devolve a resposta no mesmo socket.

A ThRSR que foi criada para atender esse servidor retira a mensagem da fila, identifica a localização do cliente e o respectivo socket (socket 5) e envia a resposta para o cliente.

Um processo cliente faz uma requisição a um servidor distante.

A requisição de um cliente a um servidor distante envolve as seguintes operações.
Cliente envia uma requisição.

A ThRCR que foi criada para atender esse cliente retira a mensagem da fila, identifica o servidor, consulta a Tabela Local de Nomes (se o servidor não for encontrado na Tabela Local de nomes é feita uma requisição para o Servidor de Nomes, sendo a ThRCR um novo cliente local) para descobrir a localização e o socket onde deve enviar a requisição e envia a mensagem no socket com o núcleo distante, criado para o envio de todas as requisições.

A ThRCR que foi criada para atender as requisições de clientes do núcleo distante retira a mensagem da fila, identifica o servidor, consulta a Tabela Local de Nomes para descobrir a localização e o socket onde deve enviar a requisição.

A ThRCR envia a mensagem no socket do servidor.

O servidor processa a mensagem e devolve a resposta no mesmo socket.
A ThRSR que foi criada para atender esse servidor retira a mensagem da fila, identifica a localização do cliente e o socket no qual deve enviar a resposta (Socket 7) e envia a resposta para o núcleo distante.

A ThRSR que foi criada para atender os servidores do núcleo distantes retira a mensagem da fila, identifica a localização do cliente e o socket no qual deve enviar a resposta (Socket 5) e envia a resposta para o cliente.

O ambiente MDX é formado por servidores especializados.

O servidor ao receber uma mensagem executa um conjunto de serviços, podendo ou não devolver uma resposta para o cliente que solicitou.

Para cada serviço requisitado, pode ser criada uma thread para a execução do mesmo, de modo a permitir a execução em paralelo.

Os servidores podem ser replicados ou centralizados.

Um servidor deve ser replicado para garantir um desempenho satisfatório, ou para executar serviços em mais de um nodo da rede.

Por outro lado, um servidor pode ser centralizado para garantir a atomicidade da operação.

Um servidor deve ser inicializado no ambiente MDX e ficar num laço infinito recebendo requisições dos clientes, processando, preenchendo o cabeçalho de resposta e enviando a resposta para o cliente.

O servidor é finalizado quando recebe uma requizição para finalizar.

Apresenta a estrutura dos servidores no MDX.

O servidor de nomes é responsável pelo armazenamento das informações relativas aos servidores que compõem o ambiente, como a sua localização e o socket de comunicação no qual aguardam uma requisição.

Quando um servidor é inicializado, a primeira operação que deve realizar é enviar uma requisição ao núcleo de comunicação do nodo em que se encontra para efetuar o serviço de registro de servidor.

O núcleo identifica a mensagem e envia para o servidor de nomes a identificação do servidor, a sua localização e o socket em que o mesmo aguarda as requisições.

Quando um processo cliente deseja fazer uma requisição para um servidor, ele simplesmente envia a requisição para o núcleo de comunicação do nodo em que se encontra.

O núcleo, por sua vez, envia uma outra requisição ao servidor de nomes solicitando a localização do mesmo e o socket em que deve enviar a requisição do cliente.

Existe um único servidor de nomes, cuja localização deve ser conhecida por todos os núcleos de comunicação.

Todas as requisições de localização devem ser enviadas para este servidor de nomes.

Ao receber a resposta de uma localização, esta é armazenada numa tabela local de nomes no núcleo de comunicação, de modo que as informações do servidor de nomes passam a ficar replicadas em todos os nodos da rede.

O servidor de nomes implementa três serviços, REGISTER_SERVER, Este serviço é responsável pela inclusão de um servidor no servidor de nomes, e é sempre solicitado pelo núcleo de comunicação do nodo em que se encontra o servidor.

Devolve como resposta para o núcleo de comunicação, REG_SERVER_OK ou REG_SERVER_ERROR.

GET_SERVER_LOC, Este serviço retorna para o núcleo de comunicação que solicitou a informação o endereço IP do nodo em que se encontra o servidor solicitado.

Se o servidor é replicado no sistema, este serviço devolve o endereço do primeiro servidor registrado no servidor de nomes.

Devolve como resposta para o núcleo de comunicação LOCATE_SERVER_OK ou LOCATE_SERVER_ERROR.

GET_SERVER_MULTIPLE_LOC, Este serviço devolve para o cliente ou servidor que solicitou a informação os endereços IP dos nodos em que se encontram o servidor solicitado.

Este serviço deve ser utilizado quando um servidor é replicado no sistema.

A resposta contém a quantidade de servidores registrados no servidor de nomes e seus respectivos endereços IP.

O gerenciador de memória compartilhada (GM) é um servidor que roda a nível de usuário, sendo o componente do Ambiente MDX responsável pela implementação da memória virtual compartilhada.

O gerenciador de memória compartilhada recebe as requisições do programa que está em execução e realiza as atividades de criação de variáveis compartilhadas, atualização e consulta de valores.

A seguir apresenta as primitivas implementadas pelo gerenciador de memória, A primitiva LMDX_malloc faz com que o gerenciador de memória aloque dinamicamente uma área de memória compartilhada e a identifique com o nome e com o tipo da variável passada como parâmetro.

Esta primitiva é subdividida em vários serviços de acordo com cada tipo de dado (int, float, double, char).

A primitiva LMDX_freemem faz com que o gerenciador de memória libere uma área de memória compartilhada previamente alocada com a primitiva LMDX_malloc.

A primitiva LMDX_create_dsm faz com que o gerenciador de memória aloque uma área de memória compartilhada e a identifique com o nome e com o tipo da variável passada como parâmetro.

Esta primitiva cria as variáveis compartilhadas que serão usadas no programa.

Esta primitiva é subdividida em vários serviços de acordo com cada tipo de dado (int, float, double, char).

Os argumentos passados como parâmetro nas primitivas LMDX_malloc, LMDX_freemem e LMDX_create_dsm são empacotados numa única string pelo pré-processador, substituindo no programa fonte.

Isto faz com que o programador escreva o programa com a primitiva usando vários argumentos.

Porém no momento da compilação, todos são agrupados numa única string, que é enviada para o GM.

A primitiva LMDX_get_dsm faz com que o gerenciador de memória recupere um valor de uma variável compartilhada.

Esta primitiva também é subdividida em vários serviços de acordo com cada tipo de dado (int, float, double, char).

A primitiva LMDX_put_dsm faz com que o gerenciador de memória atualize um valor de uma variável compartilhada.

Esta primitiva também é subdividida em vários serviços de acordo com cada tipo de dado (int, float, double, char).

Os argumentos passados como parâmetro nas primitivas LMDX_put_dsm e LMDX_get_dsm são empacotados numa única string pelo pré-processador, substituindo no programa fonte, para serem enviados para o GM.

O gerenciador de memória utiliza uma tabela dinâmica que armazena o identificador (gerado pelo gerenciador de programas) do programa, que está em execução utilizando memória compartilhada.

Para cada programa é associada uma lista com as variáveis do mesmo, contendo o nome das variáveis utilizadas e o valor armazenado.

Cada variável é associada a um único programa em execução no ambiente MDX.

O gerenciador de memória implementa um serviço RELEASE para remover um programa da tabela de programas em execução, juntamente com todas as variáveis associadas ao mesmo.

Este serviço é executado quando o gerenciador de execução envia a requisição, no momento em que o programa é encerrado.

Existem várias opções de implementação da memória compartilhada e, podendo ser centralizada ou replicada em todos os nodos, e, ser for replicada, qual o modelo de coerência que mais se ajusta ao ambiente, quando se busca um alto desempenho aliado a um alto grau de confiabilidade.

No ambiente MDX, será utilizada uma memória compartilhada distribuída com replicação em todos os nodos da rede com um modelo de coerência que garanta a consistência dos dados e a completa transparência para o programador.

Por questões de simplicidade, foi implementado um gerenciador de memória centralizado, apenas para validar o trabalho e para poder testar as primitivas do sistema.

Como um gerenciador de memória centralizado não apresenta um bom desempenho, não foram feitas medidas de desempenho e comparações com outros sistemas, como TreadMarks.

O gerenciador de sincronização (GS) é um servidor que roda a nível de usuário, sendo o componente do Ambiente MDX responsável pela implementação das primitivas de sincronização de processos distribuídos.

O gerenciador de sincronização recebe as requisições do programa que está em execução e realiza as atividades de criação e inicialização de barreiras e semáforos, bem como todas as operações sobre os mesmos, bloqueando e liberando os processos.

Para criar e manipular barreiras e semáforos o GS mantém uma tabela (lista encadeada) com uma lista de todos os programas que estão em execução, representados pelo identificador gerado pelo gerenciador de programas, e, para cada programa, uma lista com todas as barreiras e semáforos do mesmo, identificados pelo nome.

Para cada barreira existe uma variável de controle que armazena a quantidade de processos que devem sincronizar na barreira (valor da barreira), uma variável que armazena a quantidade de processos que estão bloqueados e uma lista com as informações dos processos bloqueados (endereço IP e socket), aguardando a liberação.

Para cada semáforo existe uma variável de controle, com o valor do semáforo, e uma lista com as informações dos processos que estão bloqueados (endereço IP e socket), aguardando a liberação.

A seguir apresenta as primitivas implementadas pelo gerenciador de sincronização, A primitiva LMDX_barrier_init faz com que o gerenciador de memória inicialize uma barreira identificada com um nome e com a quantidade de barreiras que deve sincronizar.

Uma área de memória é alocada e incluída na lista de barreiras referente ao programa.

O valor da inicialização é armazenado na variável que controla a quantidade de processos que devem sincronizar.

Uma fila, inicialmente vazia, é associada a cada barreira para armazenar informações dos processos bloqueados.

Esta primitiva não retorna nenhuma resposta para o processo que a executou.

A primitiva LMDX_barrier sincroniza os processos que executam essa operação.

O servidor de sincronização ao receber uma mensagem desse tipo realiza uma comparação, Se a quantidade de processos bloqueados somada com o processo que executou a barreira for menor que o valor da barreira, a variável que armazena a quantidade de processos bloqueados é incrementada e as informações do processo, como o endereço IP do nodo em que se encontra e o socket no qual aguarda a resposta, são colocados no final da lista de processos bloqueados.

Se a quantidade de processos bloqueados somada com o processo que executou a barreira for igual ao valor da barreira, a variável que armazena a quantidade de processos bloqueados é zerada e é enviada a resposta da requisição (liberação) para cada um dos processos que se encontram na lista de processos bloqueados, liberando-os do bloqueio.

A lista é então esvaziada.

A primitiva LMDX_sema_init faz com que o gerenciador de sincronização crie um semáforo geral identificado por um nome e por um valor de inicialização.

Uma área de memória é alocada e incluída na lista de semáforos referente ao programa que está em execução.

O valor da inicialização é armazenado na variável que controla o semáforo.

Uma fila, inicialmente vazia, é associada a cada semáforo e armazenará as informações dos processos bloqueados.

Esta primitiva não retorna nenhuma resposta para o processo que a executou.

A primitiva LMDX_sema_P faz com que o gerenciador de sincronização decremente o valor do semáforo referente ao programa que está em execução, identificado por um nome.

Se o valor do semáforo for maior que zero, uma resposta (liberação) é enviada para o processo que executou a operação P.

Se o valor do semáforo for menor ou igual a zero, o GS armazena as informações do processo, com o endereço IP e o socket no qual ele está esperando a resposta (liberação) numa fila de processos bloqueados.

A primitiva LMDX_sema_V faz com que o gerenciador de sincronização incremente o valor do semáforo identificado por um nome.

Antes de incrementar o valor do valor o GS faz um teste, Se o valor do semáforo for igual a zero, o gerenciador de sincronização envia um sinal (mensagem de liberação) para o primeiro processo da fila que estava bloqueado, após ter efetuado uma operação LMDX_sema_P, liberando-o do bloqueio.

Se o valor do semáforo for diferente de zero, o GS simplesmente incrementa o valor do semáforo, não tendo a necessidade de liberar nenhum processo.

O GS implementa um serviço RELEASE para remover um programa da tabela de programas em execução, juntamente com todas as barreiras e semáforos associados ao mesmo.

Este serviço é executado quando o gerenciador de execução envia a requisição, no momento em que o programa é encerrado.

O gerenciador de compilação é um processo servidor responsável pela compilação de um programa fonte em cada um dos nodos da rede, de acordo com o sistema operacional nativo do mesmo.

O gerenciador de compilação utiliza um pré-processador para transformar o programa fonte desenvolvido de acordo com o modelo de programação MDX, em requisições ao gerenciador de memória e ao gerenciador de execução.

Cada variável compartilhada pelo programador no programa fonte, bem como as primitivas de sincronização são substituídas pelo pré-processador por uma requisição ao gerenciador de memória, que pode ser para criar, gravar ou ler um valor.

O pré-processador também é responsável por inserir as requisições ao gerenciador de execução, para a criação e destruição das threads, e de efetuar a substituição da saída padrão por uma requisição para o gerenciador de execução.

Depois de pré-processar o programa-fonte, o gerenciador de compilação envia o mesmo para todos os nodos da rede e faz a compilação local, utilizando o compilador C ou C++ padrão de cada sistema operacional, gerando uma cópia do programa executável em cada nodo do ambiente de execução.

Ao compilar um programa no ambiente MDX, o gerenciador de compilação utiliza um pré-processador para transformar o código fonte em um código intermediário contendo as primitivas a nível de sistema do MDX.

O código é replicado em todos os nodos do sistema.

É gerado então um programa executável utilizando o compilador nativo em cada nodo do sistema.

As alterações no programa fonte efetuadas pelo pré-processador são, Remover as declarações de variáveis compartilhadas, feitas através da primitiva LMDX_shared, localizadas fora do programa principal e inserir a primitiva a nível de sistema LMDX_make_dsm com os argumentos empacotados numa única string.

Por exemplo, a declaração de uma matriz de inteiros M com 1024 linhas com 1024 colunas, o programador deve fazer da seguinte maneira, LMDX_shared int M.

O pré-processador remove esta linha e insere dentro da rotina correspondente ao programa principal a primitiva LMDX_make_dsm("int M"), empacotando os argumentos como uma única string.

Transformação do argumento que representa o nome da barreira, em uma string, na primitiva LMDX_barrier_init e na primitiva LMDX_barrier.

O programador inicializa, por exemplo, uma barreira B com o valor 5 da seguinte maneira, LMDX_barrier_init( B, 5).

O pré-processador transforma o identificador em uma string, da seguinte maneira, LMDX_barrier_init( "B", 5), ou ao utilizar a barreira, transformando LMDX_barrier( B ), em LMDX_barrier( "B" ).

Transformação do argumento que representa o nome do semáforo, em uma string, na primitiva LMDX_sema_init e nas primitivas LMDX_sema_P e LMDX_sema_V.

O programador inicializa, por exemplo, um semáforo S com o valor 5 da seguinte maneira, LMDX_sema_init( S, 5).

O pré-processador transforma o identificador em uma string, da seguinte maneira, LMDX_sema_init( "S", 5), ou ao utilizar o semáforo, transformando LMDX_sema_P ( S ) ou LMDX_sema_V ( S ) em LMDX_sema_P ( "S" ) e LMDX_sema_V ( "S" ) respectivamente.

O pré-processador transforma todas as utilizações de printf usado pelo programador em uma string formatada, inserindo a primitiva LMDX_printf com a string formatada como argumento.

O pré-processador insere no programa principal uma variável lmdx_service que armazenará o serviço a ser executado pelo programa principal, após a utilização da primitiva LMDX_get_execution_service.

O programa principal escrito pelo programador passa a ser uma thread chamada MDX_main e o novo programa principal é gerado pelo pré processador com a seguinte estrutura, O programa fica em um loop bloqueado aguardando uma mensagem do gerenciador de execução, na primitiva LMDX_get_execution_service, que identifica o serviço a ser executado, até que seja enviada uma mensagem com o identificador de serviço EXIT.

Se o identificador do serviço a ser executado for igual a 0 (zero), o programa deve criar e executar a thread MDX_main.

Se o valor for 1 (um) o programa deve criar e executar a primeira thread declarada e implementada.

Se o valor for 2 (dois) o programa deve criar e executar a segunda thread declarada e implementada e assim sucessivamente, de acordo com o número de threads do programa.

Se o identificador do serviço for LMDX_THREAD_KILL o programa deve destruir a thread que possui o identificador passado como parâmetro.

Na thread MDX_main o pré-processador insere no início do código, as declarações das variáveis locais.

Logo após ele insere as chamadas de todas as criações de variáveis compartilhadas, através da primitiva LMDX_make_dsm, as inicializações das barreiras, através da primitiva LMDX_barrier_init e dos semáforos, através da primitiva LMDX_sema_init.

No programa principal o pré-processador insere no início do código, logo após as declarações das variáveis locais, a primitiva LMDX_init.

Ao final do programa o pré-processador insere a primitiva LMDX_exit.

O gerenciador de execução é um servidor integrante do ambiente MDX responsável pela execução dos programas desenvolvidos no Ambiente de Programação MDX.

O programa compilado no ambiente MDX é dividido em threads e o gerenciador de execução carrega o programa para a memória em cada nodo do sistema.

Parâmetros específicos indicam o segmento de código (threads), de acordo com o modelo SPMD, que serão executados nos diferentes nodos do sistema.

O servidor de execução também é responsável pelo mapeamento da saída padrão de cada nodo para o nodo onde o programa foi disparado.

O gerenciador de execução é encarregado de fazer o mapeamento dos processos a serem executados nos diversos nodos da rede e de gerenciar a criação, sincronização e destruição das tasks e threads componentes de cada programa.

Apresenta as primitivas implementadas pelo gerenciador de execução.

Primitivas implementadas pelo gerenciador de execução.

A primitiva LMDX_init faz com que o gerenciador de execução inicialize o programa que foi previamente compilado e replicado em todos os nodos da rede.

A primitiva LMDX_exit faz com que o gerenciador de execução finalize a execução do programa em todos os nodos da rede.

Esta primitiva faz o gerenciador de memória liberar a memória compartilhada referente ao programa e o gerenciador de sincronização liberar todas as barreiras e semáforos do mesmo.

A primitiva LMDX_thread declara uma função como sendo uma thread do sistema MDX que será executada em qualquer nodo da rede quando for criada pela primitiva LMDX_start_thread.

Esta primitiva é simplesmente substituída pelo pré-processador pela declaração de thread do sistema operacional no qual o programa será compilado.

A primitiva LMDX_start_thread cria e executa uma thread em qualquer nodo da rede em que o programa esteja executando.

Esta primitiva exige o uso de LMDX_join_thread para liberar os descritores da thread.

A criação de uma thread é feita, através de uma requisição para o GE.

Este, utilizando um algoritmo de distribuição de carga, descobre o nodo em que a thread deve ser criada e executada.

O GE envia para o programa uma requisição de serviço, que é a criação de uma thread específica.

O programa recebe a requisição pela primitiva LMDX_get_execution_service, criando e executando a thread correspondente e enviando o identificador da thread criada para o GE, que cria um identificador único no sistema MDX, armazenando o nodo (endereço IP) e o identificador da thread.

A primitiva LMDX_start_dthread cria e executa uma thread em qualquer nodo da rede em que o programa esteja executando.

Esta primitiva libera os descritores da thread ao ser finalizada.

O modo de funcionamento desta primitiva é o mesmo que o da primitiva LMDX_start_thread A primitiva LMDX_join_thread sincroniza uma thread que executa em qualquer nodo da rede em que o programa esteja rodando e libera os descritores da mesma.

Esta primitiva faz com que o programa fique bloqueado aguardando a finalização de uma thread.

Quando a thread é finalizada, o GE libera os descritores da thread e envia uma mensagem para o programa, liberando-o do bloqueio.

A primitiva LMDX_kill_thread destrói uma thread que está executando em qualquer nodo da rede, juntamente com os descritores e as threads filhas da mesma.

Esta primitiva envia uma mensagem para o GE com o identificador do sistema MDX.

O GE envia uma outra mensagem para o programa no nodo em que a thread a ser destruída está executando.

O programa recebe a requisição através da primitiva LMDX_get_execution_service, destruindo a thread correspondente A primitiva LMDX_exit_thread finaliza uma thread que estava sendo executada em qualquer nodo da rede permitindo que ela seja sincronizada e que seus descritores sejam liberados através de uma mensagem para o gerenciador de execução.

O programa envia uma mensagem para o GE, que por sua vez consulta os descritores da thread.

Se ela foi criada através da primitiva LMDX_start_thread, os descritores são liberados.

Se ela foi criada através da primitiva LMDX_start_dthread, uma mensagem é enviada para o programa que está bloqueado na primitiva LMDX_join_thread, liberando-o do bloqueio.

Após a liberação, os descritores da thread são liberados.

A primitiva LMDX_get_execution_service faz com que o programa receba do GE uma requisição de execução de um serviço.

O gerenciador de execução envia para o programa que está executando em um nodo do sistema um identificador de serviço que deve ser executado.

Os serviços que o GE requisita ao programa são, criação e execução de uma thread, destruição de uma thread e finalização do programa.

A primitiva LMDX_create_thread cria uma thread num nodo específico da rede, após receber uma requisição através do LMDX_get_execution_service, usando a biblioteca do sistema operacional nativo.

Esta primitiva exige o uso de LMDX_join_thread para liberar os descritores da thread.

A primitiva LMDX_create_dthread cria uma thread num nodo específico da rede, após receber uma requisição através do LMDX_get_execution_service, usando a biblioteca do sistema operacional nativo.

Esta primitiva não exige o uso de LMDX_join_thread para liberar os descritores da thread.

A primitiva LMDX_printf faz com que o gerenciador de execução faça o mapeamento da saída padrão de cada nodo em que o programa está sendo executado para o terminal do nodo em que o programa foi executado.

O programa envia a mensagem, que foi empacotada numa única string formatada pelo pré-processador, para o GE do nodo em que o programa foi executado pelo usuário.

O GE então escreve na sua saída padrão a mensagem formatada, que foi enviada pelo programa do nodo distante.

O gerenciador de programas (GP) é um servidor do sistema MDX e é responsável por gerar um número único de identificação de cada programa no sistema.

O GP tem a finalidade de centralizar o controle de identificação de programas, já que o gerenciador de execução é replicado e um programa pode ter várias instâncias executando.

A identificação de cada programa se dá através da identificação do programa e do endereço IP do nodo em que ele foi disparado.

Se duas instâncias do mesmo programa forem executadas simultaneamente, cada uma delas terá um identificador próprio.

Um programa que está em execução no sistema MDX pode estar replicado e executando várias threads em cada nodo, porém todos as instâncias do programa possuem o mesmo identificador no sistema MDX.

O gerenciador de programas implementa um serviço que devolve para o gerenciador de execução um identificador do programa, quando um novo programa é executado.

Um interpretador de comandos paralelo shell paralelo é a interface que o usuário do ambiente MDX tem para interagir com o sistema.

O shell paralelo é responsável por informações da máquina virtual paralela, composta por todos os nodos da rede.

O shell paralelo apresenta primitivas que permitem ao usuário analisar os processos em execução, a carga do sistema, destruir processos, compilar e executar os programas paralelos.

Os comandos de interação com o ambiente são requisições para cada um dos servidores específicos, como o Núcleo de Comunicação, o Servidor de Nomes, o Gerenciador de Memória Compartilhada, o Gerenciador de Compilação e o Gerenciador de Execução.

A execução de um programa no ambiente MDX se dá através do comando MDXrun seguido do nome do programa.

Isto faz com que o gerenciador de execução execute o programa em todos os nodos em que o ambiente estiver inicializado.

Se o usuário desejar executar o programa em somente algumas máquinas da rede, o usuário utiliza o comando MDXrun seguido do nome do programa e dos nomes das máquinas que ele deseja utilizar.

Neste trabalho foi apresentada a definição de um ambiente de programação paralela, baseado em memória virtual compartilhada.

Este modelo é interessante, pois libera o programador de conhecer detalhes da arquitetura do sistema, facilitando a programação, já que o mesmo não precisa se preocupar com o particionamento dos dados.

Neste ambiente de programação apresentado, foram definidos o modelo de programação e as primitivas do sistema.

O modelo de programação utilizado é SPMD (Single Program Multiple Data), com o programa replicado em todos os nodos da rede e cada um executando um determinado trecho do código, sob a forma de thread, sendo que os processos são criados dinamicamente em qualquer nodo da rede.

As primitivas do sistema MDX devem ser usadas em lugar das operações de criação e destruição de threads e de sincronização de processos, além de proverem uma abstração de memória virtual distribuída.

Um programa deve ser escrito de forma semelhante a um programa multithreaded convencional (concorrente) para estações de trabalho que possuem um único processador.

As primitivas do sistema efetuam a criação e execução remota de threads e permitem o acesso a memória virtual compartilhada.

Uma característica importante do ambiente desenvolvido é que ele foi concebido para uma rede heterogênea de estações de trabalho, podendo ser implementado sobre vários sistemas operacionais, dentre eles, Solaris, AIX, Linux, OS/2 e Windows.

Essa portabilidade é devido à escolha dos mecanismos básicos de comunicação (sockets utilizando TCP/IP) e criação de processos leves (threads) utilizando o sistema operacional nativo.

Outra característica importante desse ambiente é a sua portabilidade, já que ele utiliza uma abstração de memória virtual compartilhada implementada por um servidor específico, o que possibilitará, no futuro, sua utilização com memória fisicamente compartilhada, bastando para isso, apenas a adaptação do gerenciador de memória, para utilizar o hardware como forma de manter a integridade e coerência dos dados, melhorando sensivelmente o seu desempenho.

O ambiente de programação paralela foi implementado sobre uma rede de estações de trabalho que utilizam Linux.

O protótipo está operante e oferece o suporte à execução de programas escritos com o uso das primitivas do MDX.

A implementação de um protótipo do ambiente MDX foi feita somente sobre o sistema operacional Linux, porque o ambiente exigiu a implementação de vários servidores, especialmente o núcleo de comunicação, o gerenciador de memória, o gerenciador de sincronização e o gerenciador de execução.

Como a comunicação é feita diretamente através do uso de sockets e as ferramentas de desenvolvimento de programas multithreaded possuem depuradores e visualizadores que não são eficientes neste tipo de programação, o tempo para a implementação desse tipo de sistema é de difícil previsão.

Esta foi uma das dificuldades encontradas no desenvolvimento desse trabalho, já que a correção de um erro no programa podia levar vários dias.

Por fim, no trabalho apresentado, pode-se destacar como principais contribuições, a concepção e de um modelo para programação paralela que facilita a estruturação dos programas, utilizando para isso, memória virtual compartilhada com criação dinâmica de processos, para uma rede de estações de trabalho e o desenvolvimento de um protótipo do sistema, que servirá de base para a pesquisa e para o projeto MDX, pelas instituições de ensino PUCRS, UCS e URI.

Todos esses servidores deverão ser desenvolvidos e otimizados para compor o ambiente MDX, no qual o usuário utilizará de um interpretador de comandos (shell paralelo) para efetuar a compilação e a execução dos programas paralelos, bem como para monitorar o ambiente e seus processos em execução.

O controle do sistema sobre a aplicação em execução, como o balanceamento de carga, o mapeamento dinâmico da criação de threads e a migração de processos, bem como o shell paralelo são características que devem ser adicionadas ao sistema, mas que não fazem parte do escopo desse trabalho, sendo portanto, funcinalidades a serem implementadas em trabalhos futuros.

Para melhorar o desempenho do ambiente MDX, é necessário que o gerenciador de memória seja distribuído.

Para isso, deve ser feito um estudo sobre a forma como os dados estarão distribuídos sobre a rede e o modelo de coerência dos dados a ser adotado.

Este trabalho, portanto, é fundamental para que se possa fazer medidas de desempenho e comparações do ambiente MDX com outros similares.

