No presente trabalho, estudamos alguns conceitos relacionados ao desenvolvimento de programas paralelos, algumas formas de aplicar computação paralela em métodos de otimização contínua e dois métodos que envolvem o uso de otimização.

O primeiro método que apresentamos, chamado PUMA (Pointwise Unconstrained Minimization Approach), recupera constantes oticas e espessuras de filmes finos a partir de valores de transmitância.

O problema de recuperação é modelado como um problema inverso e resolvido com auxílio de um método de otimização.

Através da paralelização do PUMA viabilizamos a recuperação empírica de constantes e espessuras de sistemas compostos por até dois filmes sobrepostos.

Relatamos aqui os resultados obtidos e discutimos o desempenho da versão paralela e a qualidade dos resultados obtidos.

O segundo método estudado tem o objetivo de obter configurações iniciais de moléculas para simulações de dinâmica molecular e é chamado PACKMOL.

O problema de obter uma configuração inicial de moléculas é modelado como um problema de empacotamento e resolvido com o auxílio de um método de otimização.

Construímos uma versão paralela do PACKMOL e mostramos os ganhos de desempenho obtidos com a paralelização.

Desde a criação dos primeiros computadores busca-se a melhoria de seu desempenho através do desenvolvimento de processadores mais velozes.

Em 1965 Gordon E Moore, um dos fundadores da Intel, afirmou que possivelmente nos 10 anos seguintes a quantidade de transistores em um chip, de forma a se obter um custo mínimo por componente, dobraria a cada ano.

Essa afirmação aos poucos se tornou uma espécie de lei para a indústria de microprocessadores, que passou a buscar sempre dobrar a capacidade de processamento de seus processadores a cada ano, ou a cada dois anos.

Porém, recentemente, esse otimismo vem mudando e acredita-se que estamos muito próximos de limites físicos que impedirão o crescimento da capacidade de processamento de forma indefinida.

Uma maneira de contornar o problema e continuar aumentando a capacidade de processamento dos computadores é através de computadores paralelos.

Grandes membros da indústria de processadores já estão trabalhando em chips com múltiplos núcleos, capazes de realizar operações em paralelo.

Recentemente a Intel lançou um microprocessador com quatro núcleos.

Essa mesma empresa tem investido na pesquisa e desenvolvimento de um processador com 80 núcleos e com poder computacional de um teraflop que potencialmente estará disponível comercialmente em cinco anos.

Outra forma de se conseguir maior poder computacional é através da conexão de diversos computadores, com a finalidade de trabalharem em conjunto para realizar uma tarefa.

Muitos dos chamados supercomputadores atuais são construídos dessa forma.

Atualmente o supercomputador mais poderoso que se tem notícia é conhecido por BlueGene da IBM, localizado no laboratório nacional de Lawrence Livermore, em Livermore nos Estados Unidos.

Ele possui 131072 processadores, atingindo uma taxa de processamento de 360 TeraFlops.

Essa busca por poder computacional tem o objetivo de permitir a resolução de problemas computacionais cada vez maiores e, conseqüentemente, mais difíceis.

Alguns exemplos de areas qué têm se beneficiado com o uso de técnicas de paralelismo são, algebra linear, simulação de sistemas físicos, imageamento sísmico, bioinformática, entre outros.

Nossa intenção nesse trabalho é estudar como a computação paralela pode nos ajudar a resolver alguns problemas de otimização contínua.

Estudamos uma aplicação de otimização contínua, o PACKMOL e um método de otimização, o PUMA e como paralelizá-los.

O PUMA (Pointwise Unconstrained Minimization Approach) é um método para recuperar constantes oticas e espessuras de filmes finos a partir de valores de transmitância.

O problema dé recuperação é modelado como um problema inverso e resolvido com auxílio de um método de otimização.

Através da paralelização do PUMA viabilizamos a recuperação empírica de constantes e espessuras de sistemas compostos por até dois filmes sobrepostos.

Relatamos aqui os resultados obtidos e discutimos o desempenho da versão paralela e a qualidade dos resultados obtidos.

O PACKMOL tem o objetivo de obter configurações iniciais de moléculas para simulações de dinâmica molecular.

O problema de obter uma configuração inicial de moléculas é modelado como um problema de empacotamento e resolvido com o auxílio de um método de otimização.

Construímos uma versão paralela desse método e mostramos os ganhos de desempenho obtidos com a paralelização.

O segundo capítulo deste trabalho apresenta alguns conceitos básicos relacionados ao desenvolvimento de aplicações paralelas e de que forma podemos desenvolver algoritmos de otimização contínua paralelos.

O terceiro capítulo detalha nosso trabalho com o PUMA.

O quarto capítulo expõe nosso trabalho com o PACKMOL.

O quinto capítulo resume nossas conclusões gerais e acresce linhas para trabalhos futuros.

A computação paralela é a execução simultânea de processos computacionais em múltiplos processadores a fim de resolver um mesmo problema computacional de forma mais rápida.

Nesse capítulo, fortemente baseado nos trabalhos, daremos uma breve introdução as diferentes arquiteturas de computadores paralelos e distribuídos, aos modelos de computação paralela e a algumas técnicas para a avaliação de desempenho de um algoritmo paralelo.

Há cerca de 60 anos a grande maioria dos computadores possui virtualmente a mesma arquitetura, chamada de arquitetura de von Neumann.

Nela os computadores são divididos basicamente em unidade de processamento e memória.

Os programas e os dados são localizados na memória.

A unidade de processamento lê instruções de um programa e dados contidos na memória, decodifica as instruções e seqüencialmente as executa.

Nesse caso, temos uma unica unidade de processamento que acessa a memória buscando sempre um conjunto de dados, não havendo nenhum tipo de paralelismo.

Quando tratamos de computadores paralelos é necessário entender os modelos de organização dessas máquinas para podermos modelar e implementar algoritmos ou aplicações paralelas.

Segundo Ian Foster em, um computador paralelo é um conjunto de processadores interconectados, capazes de trabalhar de forma simultânea e cooperativa a fim de resolver um problema computacional.

Essa definição é suficientemente ampla para incluir supercomputadores paralelos que possuem centenas ou milhares de computadores, redes locais de computadores, estações de trabalho com múltiplos processadores, entre outros.

Uma ampla classificação das arquiteturas de máquinas paralelas foi oferecida por Flynn em  e é até hoje considerada importante para a compreensão do assunto.

Segundo Flynn os computadores podem ser classificadas da seguinte maneira, SISD (Single Instruction stream and Single Data stream).
Arquitetura onde uma unidade de  processamento pode executar uma unica instrução em um unico conjunto de dados, não há  paralelismo.

Corresponde à arquitetura de von Neumann.

Há aproximadamente uma década  essa arquitetura tem deixado de ser o padrão na construção de computadores, sendo substituída  por máquinas do tipo SIMD e MIMD.

SIMD (Single Instruction stream and Multiple Data stream).
Arquitetura onde uma unidade  de processamento pode executar uma mesma instrução e operar em múltiplos conjuntos de  dados.

Aplicações que precisam executar a mesma operação em grandes vetores ou matrizes  podem tirar vantagem desse tipo de arquitetura.

Um exemplo popular e recente de máquinas  que seguem essa arquitetura é a tecnologia MMX da Intel ou a 3 dNow da AMD.

Apesar dos  processadores com essa tecnologia serem capazes de se comportar de acordo com a arquitetura  SISD, um subconjunto de instruções operam de acordo com a arquitetura SIMD.

MISD (Multiple Instruction stream and Single Data stream).
Arquitetura onde múltiplas unidades de processamento executam diferentes instruções simultaneamente em um mesmo conjunto de dados.

Não se conhece muitos exemplos de máquinas desse tipo e ele é citado apenas  por uma questão de completude.

MIMD (Multiple Instruction stream and Multiple Data stream).
Arquitetura onde múltiplas  unidades de processamento executam diferentes instruções simultaneamente em diversos conjuntos de dados diferentes.

A categoria MIMD citada na seção anterior abrange diversos subtipos de arquiteturas.

A classificação de Flynn é habitualmente considerada incompleta por não apresentá-los.

Outros pesquisadores estenderam essa classificação completando-a.

Vamos citar aqui três arquiteturas do tipo MIMD que diferem com relação à organização da memória.

Memória compartilhada.
Computadores com memória compartilhada possuem mais de um  processador e uma area de memória comum a todos.

Os processadores executam de forma  independente uns dos outros, mas têm acesso aos mesmos endereços de memória, de forma  que mudanças na memória realizadas por um sejam imediatamente visíveis a todos os demais  processadores.

Os computadores com memória compartilhada podem ser divididos em duas  grandes classes, Unified Memory Access (UMA) e Non-Unified Memory Access (NUMA).

UMA diz respeito a computadores com memória compartilhada onde os processadores são  idênticos e possuem acesso e tempo de acesso à memória iguais.

NUMA refere-se à computadores com processadores que possuem diferentes tempos de acesso a memória.

Memória distribuída.
Sistemas com memória distribuída geralmente são compostos por diversas unidades de processamento conectadas por uma rede de dados, onde cada processador  possui uma area de memória local apenas.

Os processadores podem operar independentemente uns dos outros e se precisarem acessar endereços de memória não-local geralmente  esses dados devem ser transferidos pela rede de uma area de memória para outra.

Sistemas híbridos.
São sistemas onde ambas formas de organização de memória estão presentes.

São comuns em sistemas distribuídos, onde cada computador presente no sistema possui  duas ou mais unidades de processamento que compartilham endereços de memória entre si.

A  grande maioria dos supercomputadores possuem arquitetura híbrida de memória.

Desenvolver algoritmos paralelos é uma tarefa mais complexa que desenvolver algoritmos seqüenciais.

Além de todas as abstrações usadas no modelo seqüencial de programação, os modelos paralelos usam outros conceitos como, comunicação entre tarefas, concorrência, escalabilidade e localidade.

A comunicação entre tarefas diz respeito à necessidade de troca de dados entre duas tarefas.

Dependendo do modelo de programação considerado, as tarefas não possuem acesso direto a todos os dados relacionados ao problema e é necessário que dados sejam trocados entre elas.

A localidade diz respeito a quais dados são locais (ie, diretamente acessíveis) a cada tarefa ou não.

A escalabilidade é a capacidade da aplicação ser eficiente a medida que ocorrem acréscimos na quantidade de processadores em que ela é executada.

A concorrência é quando há o acesso simultâneo por duas ou mais tarefas a um recurso do sistema, como um endereço de memória por exemplo.

A seguir daremos uma introdução aos modelos de programação paralela mais usados.

O modelo de troca de mensagens é um dos mais populares modelos para programação paralela.

Nele uma aplicação paralela é formada por diversas tarefas independentes que se comunicam umas com as outras através de troca de mensagens a fim de coordenar suas ações, ou compartilhar dados.

Uma forma de visualizar esse modelo é através de um grafo direcionado, onde cada vértice representa uma tarefa e cada aresta direcionada representa uma comunicação entre duas tarefas.

Cada tarefa pode realizar operações de leitura ou escrita em sua memória local, operações aritméticas, chamadas de funções locais e enviar ou receber mensagens.

Normalmente o envio de uma mensagem é instantâneo e ocorre de forma assíncrona, enquanto o recebimento ocorre de forma síncrona e bloqueia o fluxo de execução da tarefa até que a mensagem seja recebida.

Esse modelo considera que um grupo de tarefas é criado no início da aplicação e cada uma é atribuída a um processador.

As tarefas representam diferentes fluxos de execuções e isso permite que o modelo de troca de mensagens seja visto como um modelo multiple program multiple data (MPMD).

O modelo MPMD claramente se relaciona com a arquitetura do tipo MIMD, já que nessa arquitetura cada processo pode ser executado por uma unidade de processamento diferente, permitindo uma execução mais rápida do programa paralelo.

Seguindo esse raciocínio, é interessante que programas paralelos com a estrutura MPMD sejam executados em máquinas do tipo MIMD.

A MPI ou Message Passing Interface é a especificação de uma interface para programação paralela com troca de mensagens, independentemente de linguagem ou protocolo de comunicação.

Existem implementações dessa interface para as principais linguagens de programação como C, C++ ou Fortran.

A MPI foi criada com o objetivo de permitir alto desempenho, escalabilidade e portabilidade.

Apesar de ser bem sucedida nesses objetivos, é bastante criticada por ser considerada uma interface de baixo nível que expressa o paralelismo explicitamente.

No modelo de memória compartilhada as tarefas compartilham um espaço de endereçamento de memória onde podem ler e escrever de forma assíncrona.

Nesses sistemas a programação pode ser simplificada pela ausência da necessidade de troca explícita de dados entre as tarefas, porém fica mais complicado controlar a localidade das ações em memória.

Freqüentemente é necessário o uso de semáforos ou travas (locks) para controlar o acesso de escrita na memória.

As tarefas podem, eventualmente, ser independentes umas das outras e trabalhar com diversos conjuntos de dados diferentes, apesar de compartilharem um mesmo espaço de endereçamento.

Por isso, esse modelo de programação também é considerado um modelo MPMD.

Uma API para programação em ambientes de memória compartilhada é o OpenMP (Open MultiProcessing).

Considerado um padrão pela indústria de computação, o OpenMP foi desenvolvido por um grupo de pesquisadores que formam o OpenMP Architecture Review Board (ARB) e foi lançado em outubro de 1997.

Consiste na especificação de algumas diretivas de compilação e funções para permitirem a programação com memória compartilhada.

Sua especificação contempla as linguagens C, C++ e Fortran (77, 90 e 95).

Diversos compiladores já possuem suporte a esta API.

Dentre eles, podemos citar compiladores da Intel, Sun Studio, Visual C++ e GCC.

O Bulk Synchronous Parallel ou BSP  é um modelo para programação paralela proposto por Valiant em 1990.

Esse modelo é caracterizado por unidades de processamento com memória local e uma rede de comunicação que permite o acesso de diferentes processadores à memória dos demais.

Essa rede de comunicação pode ser um barramento de alta velocidade, ou uma rede de velocidade reduzida, como uma rede ethernet por exemplo, dependendo da arquitetura de hardware considerada na implementação do modelo.

Uma aplicação BSP é definida por conjuntos de super passos (superstep).

Cada super passo é uma coleção de ações, envolvendo computação local e/ou comunicação entre tarefas, seguidas de uma barreira de sincronização.

Na barreira de sincronização, as tarefas que já terminaram suas ações de computação ou comunicação, aguardam até que todas tenham terminado o programado para o super passo em questão.

Quando todas a tarefas terminam suas ações, prosseguem para o próximo super passo.

Existe uma especificação de uma API, para a linguagem C, que define funções para a programação paralela usando o modelo BSP chamada BSPLib.

O sítio  contém informações sobre implementações dessa especificação.

Neste modelo, o trabalho a ser realizado em paralelo consiste principalmente em operações de leitura e escrita na memória.

Os dados são geralmente organizados em uma estrutura como vetor ou matriz.

Todas as tarefas operam sobre esta estrutura, acessando conjuntos disjuntos de dados evitando concorrência pelo acesso à mesma area da memória.

As tarefas possuem a restrição dé realizarem sempre as mesmas ações, só que em conjuntos distintos de dados.

Aplicações onde possa-se realizar a decomposição de domínio de dados, ou seja, o particionamento dos dados em grupos para que sejam realizadas operações sobre eles, encaixam-se bem nesse modelo.

Um exemplo é a multiplicação de matrizes.

As matrizes são divididas de modo uniforme e cada tarefa opera sobre uma porção dos dados de forma paralela.

No modelo de threads, as tarefas têm uma area de memória local e podem executar de forma independente umas das outras por isso esse modelo é visto como um modelo MPMD.

Em alguns casos duas ou mais tarefas podem compartilhar uma area de endereçamento de memória de forma similar ao modelo de memória compartilhada.

Tarefas podem ser criadas ou destruídas dinamicamente a medida que o programa é executado.

Aplicações onde se possa realizar a decomposição funcional, ou seja, o particionamento da aplicação em grupos de tarefas distintas, encaixam-se bem nesse modelo.

Dentre as bibliotecas de funções mais populares para programação baseada em threads, temos o OpenMP, citado na Seção 2 2 2 e ainda POSIX Threads (PThreads).

PThreads é um padrão que define uma API para criação e manipulação de threads desenvolvido pelo The Open Group e pelo IEEE.

Para avaliar o desempenho empírico de um algoritmo paralelo podemos usar as medidas de aceleração (ou speedup) e eficiência.

Speedup refere-se a quão mais rápido um algoritmo paralelo é em relação à sua versão seqüencial.

A medida de speedup é dada por 1 é o tempo de execução da versão seqüencial do algoritmo para uma instância.

Pode ser  o tempo de execução de uma implementação seqüencial, ou o tempo de uma implementação  paralela sendo executada com um unico processo, é o tempo de execução da versão paralela do algoritmo para a mesma instância usada para  medir.

E considerado um speedup ideal, também chamado de linear, quando S =.

Em alguns casos o valor do speedup pode ser superior à quantidade de processadores utilizados.

Nesses casos anômalos, o speedup chamado de super linear.

Existem algumas causas para esse fenômeno, uma bastante comum é a agregação de memória cache dos vários processadores presentes no sistema.

Esse efeito pode reduzir significativamente o tempo de acesso à memória e tornar a execução muito mais rápida.

A eficiência de um algoritmo paralelo é dado pela fórmula,onde a quantidade de processadores, S é o speedup.

Essa medida é sempre um valor entre 0 e 1 considerando teoricamente que S, que estima quão bem utilizados estão sendo os processadores em relação aos custos com comunicação e sincronização.

Outro conceito importante relacionado ao desempenho de algoritmos paralelos é a lei de Amdahl.

Essa lei fornece o speedup máximo esperado de um algoritmo quando apenas uma porção dele é paralelizada.

O valor do speedup máximo esperado é dado, pode ser considerada uma limitação à aplicação da computação paralela.

Porém, segundo Ian Foster em seu livro.
Nos primórdios da computação paralela acreditava-se que este efeito limitaria a utilidade da computação paralela a um pequeno número de aplicações especializadas.

Contudo, a experiência prática demonstra que esta maneira inerentemente seqüencial de pensar é de pequena relevância em problemas reais.  

Fatores como quantidade de operações de entrada e saída (E/S), necessidade de sincronização entre processos e efeitos de cache, influenciam o desempenho de um algoritmo paralelo.

A quantidade de operações de E/S e sincronizações entre processos tem efeito negativo sobre o speedup.

As operações de E/S mais comuns em programas paralelos são acesso ao disco e comunicação através de uma interface de rede.

Tais operações são bastante custosas e se realizadas em grande quantidade podem prejudicar o desempenho do programa.

A sincronização entre processos, em geral, faz com que alguns processos fiquem parados enquanto outros processam, antes que uma determinada ação possa continuar.

Dessa forma, implica em desperdício de recursos computacionais.

Outro fator negativo da sincronização é que ela pode envolver também a realização de operações de E/S para conseguir um estado consistente dos processos.

Por isso, sincronizações devem ser utilizadas com cautela para não prejudicar muito o speedup.

A quantidade de níveis de memória cache e o tamanho de cada nível podem influenciar positivamente o speedup da execução de um algoritmo paralelo.

Em caches grandes, potencialmente, todos os dados são carregados na memória cache.

Em programas paralelos, cada processo deve processar um conjunto menor de dados, em relação ao programa seqüencial.

Considerando isso e o fato de que os dados podem ser lidos mais rapidamente da memória cache que da memória principal, a computação pode ser acelerada, propiciando maiores valores de speedup.

Diversos profissionais lidam diariamente com problemas de otimização.

Seja reduzir o custo de uma linha de produção, projetar estruturas mecânicas, ou identificar estruturas protéicas, o que interessa é obter uma solução que minimize ou maximize determinados fatores.

H são funções definidas em R, x é um vetor de n componentes e, u 2 R são respectivamente os limitantes superiores e inferiores para x.

O objetivo do problema acima é encontrar variáveis x, x  1 n que satisfaçam g (x)  0, h (x) = 0 e x  u e que minimizem a função f, conhecida por função objetivo, ou função  de mérito.

As inequações g (x) e as equações hi(x) são chamadas de restrições de desigualdade e  igualdade respectivamente.

As restrições x  u são chamadas restrições de caixa.

Os pontos x que as satisfazem são chamados de soluções viáveis.

O problema de otimização acima pode ser compreendido como um problema de encontrar um ponto viável x tal que f(x )  f(x) para todo ponto viável x.

A motivação por trás do interesse em computação paralela aplicada em otimização contínua está em resolver, de forma eficiente, problemas que são computacionalmente caros.

Robert Schnabel, em seu artigo, explica que em geral a origem do grande consumo de processamento dos algoritmos de otimização pode estar.
No custo individual de avaliação da função objetivo, restrições e/ou suas derivadas.

Na quantidade de restrições ou variáveis que, caso sejam muito grandes, podem aumentar consideravelmente o custo de cada iteração. 

Na necessidade de realizar muitas avaliações das funções ou suas derivadas.

Na necessidade de realizar muitas iterações do método.

Segundo, essas fontes de consumo de processamento nos levam à três maneiras de paralelizar esse tipo de algoritmo.
Paralelizam-se as operações de algebra linear utilizadas pelo algoritmo.
Já existe bastante trabalho envolvendo paralelismo e algebra linear, inclusive existem pacotes gratuitos que implementam algoritmos paralelos para diversas operações (PBLAS, ScaLAPACK, entre outros).

Paraleliza-se a avaliação da função objetivo, restrições e/ou suas derivadas.
Essa opção é dependente do problema que se quer resolver.

Necessita que a função objetivo e/ou restrições possuam uma estrutura capaz de ser paralelizada.

Paraleliza-se um método de otimização.
Obter um método para resolver o problema de otimização em sua forma genérica, ou em alguma outra forma mais específica, é interessante por permitir a resolução de todas as instâncias de problemas formulados de tal maneira.

Nesse caso pode-se tentar partir de um método seqüencial, buscando oportunidades de ganho de eficiência através de paralelismo, ou tentar desenvolver um método completamente novo e intrinsecamente paralelo.

Nesta dissertação propomos investigar duas das três formas que Schnabel sugere para paralelizar algoritmos de otimização contínua.

A primeira consiste na paralelização da avaliação da função objetivo de um problema de empacotamento de moléculas resolvido através de um método de otimização.

A segunda consiste na paralelização da estrutura de um método de otimização aplicado a resolução de um problema inverso para estimar constantes oticas de filmes finos.

O PUMA (Pointwise Unconstrained Minimization Approach)  é um método que recupera os valores de espessuras e constantes oticas de filmes finos.

A partir de medições da transmitância de um sistema composto por filmes e um substrato transparente.

Um filme fino é uma fina camada de material de espessura normalmente inferior a um mícron.

Um sistema de filmes finos é dado por camadas de filmes finos sobrepostos sob e/ou sobre um substrato.

A medida de transmitância é a relação entre a quantidade de luz que atravessa o sistema e a quantidade de luz incidente.

A transmitância pode ser obtida com o uso de um espectrofotômetro.

Temos a ilustração de um sistema de filmes finos com dois filmes na configuração filme-substrato-filme.

Temos um exemplo de como é feita a medição da transmitância.

As constantes oticas que são recuperadas pelo método são o índice de refração e os coeficientes de absorção de cada filme no sistema.

Esses valores são de extrema importância em diversas aplicações modernas de filmes finos, como a produção de semicondutores, revestimentos de diversos materiais, biotecnologia e a geração e conservação de energia (painéis solares).

A grande inovação do PUMA é permitir, a partir de um modelo de programação não-linear, a recuperação dessas constantes independentemente da existência de qualquer padrão de interferência, o que não ocorria com as soluções propostas anteriormente.

A maior desvantagem do PUMA é o custo computacional exigido para resolver o problema de programação não-linear.

Nosso objetivo aqui foi o de permitir, através da paralelização do método, a identificação de constantes de sistemas com vários filmes.

Tal recuperação não era possível antes, dado o tempo de processamento consumido por algumas instâncias que chegava a cerca de um mês.

Isso tornava impraticável sua avaliação e uso.

Os tópicos abordados neste capítulo são, o modelo matemático do problema, a técnica de otimização utilizada, a estratégia de paralelização e, por fim, diversos experimentos numéricos ilustrando os resultados obtidos.

Fisicamente estamos lidando com uma pilha de filmes finos depositados em ambos os lados de um substrato transparente.

Definimos como "topo" da pilha o lado em que incide a luz.

Claramente, a "base" é o lado oposto.

Medidas da transmitância são realizadas utilizando-se um espectrofotômetro.

Essas medidas estão disponíveis para um intervalo de comprimento de onda que varia de até min nanômetros.

O índice de refração s do substrato é conhecido.

Sua espessura também, porém, ela não influencia os cálculos uma vez que o substrato é transparente e sua espessura é muito maior que a dos filmes.

Para cada filme temos como valores desconhecidos, a espessura, o índice de refração e o coeficiente de atenuação.

Esses dois ultimos são funções do comprimento de onda.

Considere que m  0 filmes estão depositados acima do substrato e mb  0 abaixo dele.

Para cada comprimento de onda  temos que, a transmitância teórica é função da espessura, índices de refração e coeficientes de atenuação.

Assim, podemos reescrever (31) como, Se m = 1 e m = 0, a fórmula teórica da transmitância é a fornecida e usada em para recuperar parâmetros de um unico filme depositado sobre um substrato transparente.

A transmitância de um par de filmes diferentes depositados sobre um substrato transparente pode ser expressada de forma compacta.

Se dois filmes forem depositados na mesma face do substrato, a fórmula compacta da transmitância é dada por, Se dois filmes são depositados em lados diferentes do substrato, a fórmula compacta para a transmitância é dada por ambas as formulações equivalem à formulação de Swanepoel  quando zeramos a espessura de um dos filmes.

N, os parâmetros reais devem satisfazer a equação.
Entretanto, este é um sistema com (mt + mb)(2 N + 1) variáveis e apenas N equações, o que o torna indeterminado.

Mais ainda, os valores obtidos empiricamente estão sujeitos a erros de medida e o modelo não é completamente adequado à realidade, já que suposições como homogeneidade, transparência total do substrato e paralelismo de interfaces entre os filmes são difíceis de serem satisfeitas exatamente.

Os muitos graus de liberdade que são inerentes a esse problema nos levam a introduzir restrições físicas e fenomenológicas que devem ser satisfeitas pelos parâmetros dos filmes em consideração.

Veja  para a aplicação desta metodologia ao problema de estimação com um unico filme.

Ao invés de considerarmos o sistema não-linear em (32), definimos o seguinté problema de otimização.
No caso de um unico filme, essa estratégia foi usada com sucesso diversas vezes no projeto PUMA.

Aqui usamos as mesmas restrições do caso com um unico filme, que são adequadas a filmes finos a-semicondutores amorfos na vizinhança do pico de absorção fundamental dos a-semicondutores.

Essas restrições são descritas a seguir.

Consideramos que n é o índice de refração e  é o coeficiente de atenuação de um filme genérico na pilha.

Como em, eliminamos as restrições do problema realizando uma troca de variáveis.
Considerando um cenário real, onde os dados são fornecidos por um conjunto de N pontos igualmente espaçados no intervalo, definimos.
Usaremos a notação n, w e z para as estimativas de n(i), (i), w(i) e z(i), para todo i = 1.

Discretizando obtemos.
E importante frisar que os índices de refração e os coeficientes de absorção de todos os filmes devem satisfazer essas restrições.

O problema com as restrições definidas por é um problema de otimização com (mt + mb)(2 N + 1) variáveis.

As restrições são representadas pela não-negatividade das espessuras e o fato de que os pontos de inflexão  infldevem estar no intervalo.

As demais variáveis são irrestritas e adimensionais.

Essas são as razões principais para tratá-las de forma diferente das espessuras e pontos de inflexão.

Nossa estratégia é definir, para cada conjunto de pontos de inflexão e cada conjunto de espessuras, um problema de otimização contínua irrestrito, onde as variáveis são definidas pelos índices de refração e coeficientes de atenuação.

Como em, o problema será resolvido usando o método do gradiente espectral.

Uma abstração de alto-nível da estratégia de solução é dada a seguir.
Passo 1.
Definir uma grade de granularidade grossa com respeito as variáveis espessura e ponto de inflexao.

Passo 2.
Resolver o problema para cada ponto da grade onde as variáveis espessura e ponto de inflexao estão fixadas.

Obter o conjunto de espessuras e o melhor conjunto de pontos de inflexão da grade de forma que, depois de resolver os problemas de otimização, tenha-se a menor soma quadrática.

Passo 3.
Definir uma nova grade, de granularidade menor, na vizinhança das melhores espessuras e pontos de inflexão obtidos no Passo 2.

Passo 4.
Resolver os problemas de otimização definidos por cada ponto da nova grade.

Adotar como solução aqueles valores que fornecerem a menor soma quadrática.

Em sistemas com dois filmes, a grade inicial para a espessura é dada pelos pontos na caixa d1, onde d i e di  são (para o i-ésimo filme) os limitantes inferior e superior para a espessura do filme.

Com relação ao ponto de inflexão, existem duas opções.

A primeira consiste em fixar o ponto de inflexão no valor de  e deve ser usada caso o coeficiente de absorção seja convexo no intervalo  considerado.

A segunda, consiste em agir de forma análoga ao caso da espessura.

Constrói-se uma grade de alta granularidade dada pelos pontos na caixa [Q  1 Q 1  2  2  Q i e Q i são (para o i-ésimo filme) os limitantes inferior e superior para os pontos de inflexão, respectivamente.

Vale mencionar que de acordo com a estratégia adotada pelo PUMA, o problema de minimização deve ser resolvido para cada conjunto.

Mais ainda, para cada conjunto de espessuras e pontos de inflexão, o método de otimização necessita de estimativas iniciais para n e.

De fato, o método resolve o problema de otimização partindo de diversas aproximações iniciais para n e.

A geração de cada estimativa inicial é baseada na aproximação de n e  por funções lineares por partes e segue um processo similar ao explicado em.

A maior diferença fica na geração da aproximação do.

A aproximação era feita por dois segmentos de reta, aqui usamos três segmentos, conseguindo uma melhor aproximação da função real Comprimento de onda (nm).

Ilustração da aproximação do silício por funções lineares por partes usando 2 segmentos e usando 3 segmentos.
A metodologia de solução adotada demanda um esforço computacional muito grande, que aumenta exponencialmente de acordo com a quantidade de filmes presentes no sistema.

Examinaremos a quantidade de vezes que o problema é resolvido no caso de um sistema com dois filmes, com espessuras 100 nm e 600 nm, respectivamente.

Ao variarmos as espessuras entre 10 nm e 200 nm e entre 300 nm e 900 nm, respectivamente (com passo de 10 nm em ambos os casos), resultando em 420 pares de espessuras.

Considerando o intervalo espectral nm teremos 11 pontos de inflexão (obtidos com um tamanho de passo de 100 nm) para cada filme.

Isso resulta em 50820 instâncias do problema.

Como cada instância é resolvida para 6 pares de estimativas iniciais  diferentes de n e  para cada filme, teremos 1829520 processos de otimização.

Assim, a paralelização do método é essencial para que sua implementação tenha uma utilidade prática.

A estratégia de paralelização é bem simples e consiste em distribuir a resolução dos diversos problemas, obtidos variando-se os parâmetros de (33),(315)-(319), entre os processadores disponíveis.

Por tratar-se de problemas independentes, praticamente inexiste comunicação entre processos, exceto pela necessidade de informar o resultado de cada problema a um processo coordenador, que escolherá o resultado adequado como solução do método.

Tal estrutura é conhecida como bag-of-tasks ou sacola de tarefas.

Funcionamento do PUMA paralelo entre o processo mestre  e um escravo.

O modelo de paralelismo utilizado foi o de troca de mensagens.

Esse modelo é bastante apropriado para aplicações bag-of-tasks, já que existe um paralelismo de alta granularidade e pouca comunicação entre tarefas, maximizando a eficiência da paralelização.

Considere que temos P processos, numerados de 1 até P.

O processo 1 é responsável por gerar e distribuir os problemas, bem como armazenar o melhor resultado.

Os demais processos têm a tarefa de resolver os problemas e fornecer seus resultados ao processo 1.

Mais detalhadamente, o processo 1 lê os parâmetros de entrada do algoritmo (para maiores detalhes sobre os parâmetros de entrada, veja ) e gera as diferentes combinações de espessura, pontos de inflexão, n e  que caracterizam cada problema.


P requisita uma instância do problema (33),(315-319) ao processo 1, resolve e envia o valor do erro quadrático e os demais valores que caracterizam o ponto otimo ao processo 1.

Ao receber um resultado de um processo, o processo 1 compara o valor do erro quadrático recebido com o menor valor já obtido até então.

Se o resultado recebido for menor, é mantido (substitui-se a antiga melhor solução pela recebida), caso contrário é descartado.

Ilustra o funcionamento da versão paralela do PUMA.

Pode-se argumentar que o processador onde o processo 1 será executado permanecerá a maior parte de seu tempo de execução ocioso, desperdiçando recursos computacionais.

Para contornar esse problema, pode-se iniciar a aplicação com P = Nproc + 1 processos, onde Nproc é a quantidade de processadores disponíveis e iniciar o processo adicional no mesmo processador em que o processo 1 foi iniciado.

Através da versão paralela do PUMA foi possível recuperar as contantes oticas e espessuras dé sistemas compostos por dois filmes finos, feito impraticável de ser realizado antes deste trabalho.

Os experimentos apresentados a seguir foram realizados em três ambientes diferentes.

Utilizamos a grade do LCPD (Laboratório de Computação Paralela e Distribuída), o aglomerado Revoada do grupo InteGrade e o aglomerado do grupo de otimização contínua.

A grade do LCPD é composta por sete máquinas.

Uma máquina Intel(R) Xeon(TM) CPU 300 GHz de 32 bits com Hyper-threading e 2 GB de RAM.

Seis máquinas AMD Athlon(tm) XP 2800+ 225 GHz de 32 bits com 1 GB de RAM.

O aglomerado Revoada possui oito máquinas com processador Intel(R) Pentium(R) 4 300 GHz de 32 bits com 1 GB de RAM.

O aglomerado do grupo de otimização contínua possui quatro máquinas com processador Intel(R) Core 2 Quad 240 GHz de 64 bits e 4 GB de RAM.

Alguns testes anteriores, com a intenção de calibrar o método, foram realizados na grade do projeto GRID 5000.

Utilizamos também, para a realização de testes preliminares, o cluster Alcatéia do LCCA (Laboratório de Computação Científica Avançada), que conta com 32 nós Intel Xeon 24 GHz biprocessadas e com 25 GB de memória RAM por nó.

O PUMA paralelo foi implementado em linguagem C, usando funções da Message Passing Interface.

Os binários utilizados em nossos experimentos foram obtidos através do compilador gcc (versão 4 2 1, parte integrante da projeto GNU Compiler Collection) e ligados com a biblioteca LAM MPI (versão 7 1 2).

Nosso código também foi testado com a biblioteca MPICH2 (versão 14 e versão 15 modificada para o middleware InteGrade ).

Em nossos experimentos, consideramos que infl= min.

Denominaremos de A, B, C e D os filmes gerados computacionalmente e introduzidos em.

Suas constantes oticas podem ser encontradas no Anexo A.

Trabalhamos com sistemas de dois filmes e um substrato de vidro.

Referiremos ao substrato de vidro usando a letra v, assim, AvB será um sistema composto por, Filme A, substrato de vidro e Filme B.

Relataremos alguns resultados obtidos com sistemas de filmes idênticos (filme 1 = filme 2) e com sistemas de filmes diferentes (filme 1 6= filme 2).

Para os experimentos com filmes idênticos gerados computacionalmente, usamos o filme A e consideramos as seguintes configurações, AAv, AvA, vAA.

O intervalo espectral utilizado no processo de recuperação foi 570  1560 nm.

O valor de min corresponde ao menor comprimento de onda tal que a transmitância medida do sistema é maior ou igual a 10 4.

O valor de  corresponde a  min  + 990 nm, de forma que possamos considerar 100 medidas da transmitância com 10 nm de distância entre cada uma delas.

Nossas três configurações (AAv, AvA e vAA) podem ser resumidas em dois casos, Filmes depositados do mesmo lado do substrato (AAv e vAA) e filmes depositados em lados diferentes do substrato (AvA).

Quando os filmes estão depositados do mesmo lado do substrato, o PUMA encontra diversos pares de espessuras d e d com d + d2  200 nm correspondentes a um sistema  com a transmitância próxima à medida.

No caso do sistema com um filme de cada lado do substrato, a indeterminação, embora existente, não está relacionada com a soma das espessuras dos dois filmes de silício.

Dependendo da espessura recuperada, n e  se ajustam para definir precisamente a transmitância no intervalo de comprimento de onda considerado.

Por outro lado, caso seja informada a espessura real de um dos filmes, ou informado que ambos os filmes possuem a mesma espessura o PUMA é capaz de recuperar os valores esperados em ambos os casos.

Mostra que se fosse utilizada como informação adicional uma das seguintes, d = 1 100 nm, d2 = 100 nm ou d1 = d2, a indeterminação seria removida.

Mostra os valores recuperados usando d = d2.

E interessante notar que o método recupera uma aproximação razoável mbos os filmes.

Fizemos uma média dos valores do índice de refração recuperados para ambos os filmes e notamos que os valores obtidos representam uma recuperação mais precisa da função verdadeira.

Usando a informação adicional de que d 1 = d2 com as recuperações envolvendo os sistemas AvA e vAA obtivemos recuperaçoes similares ao caso AAv.

Mostra as espessuras recuperadas e os erros quadráticos correspondentes para os experimentos com os três sistemas.

O motivo da recuperação das espessuras e constantes oticas ser ruim para o caso AvA é explicado.

Nela podemos observar a variação da função de transmitância em relação as espessuras dos filmes.

Note a pequena variação dos valores de transmitância com a alteração nas espessuras para o caso de filmes de mesma natureza.

A razão da recuperação não funcionar bem para os casos AAv e vAA deve-se também a um fenômeno relacionado com as transmitâncias desses sistemas.

Para casos em que dois ou mais filmes são sobrepostos no mesmo lado de um substrato, os valores de transmitância obtidos são idênticos aos obtidos no caso de termos um unico filme, na mesma posição, com espessura igual à soma das espessuras dos filmes sobrepostos.

Dessa forma, a transmitância do sistema AAv, por exemplo, é idêntica à transmitância do sistema com um unico filme de silício com 200 nm posicionado acima do substrato.

Mais ainda, é igual à transmitância de qualquer sistema com dois filmes de silício sobrepostos acima do substrato cuja soma de espessuras igual à 200 nm.

Erro quadrático do processo de minimização em função das espessuras testadas para o primeiro e segundo filme do sistema AAv.

O método não foi capaz de recuperar a espessura verdadeira já que valores pequenos e bem próximos aparecem para qualquer par de espessuras que somem aproximadamente 200 nm.

Erro quadrático do processo de minimização em função das espessuras testadas para o primeiro e segundo filme do sistema AvA.

O método não foi capaz de recuperar a espessura verdadeira já que valores pequenos e bem próximos aparecem para diversos pares de espessuras.

Porém, diferentemente do sistema AAv, elas não somam aproximadamente 200 nm.

Independentemente disso, adicionando a informação de que a espessura de um dos dois filmes é conhecida, ou que ambos os filmes possuem a mesma espessura, os valores verdadeiros podem ser recuperados.

A esquerda a espessura é variada com passo 10 nm, enquanto que a direita esse valor é refinado para 1 nm.

Os gráficos  representam o caso em que fixamos a espessura do primeiro filme em 100 nm.

Os gráficos representam o caso em que fixamos a espessura do segundo filme em 100 nm.

Já os gráficos representam o caso em que a informação adicional utilizada é o fato das espessuras serem iguais.

Em todos os casos vemos que a informação adicional foi suficiente para a recuperação correta das espessuras de ambos os filmes.

Correspondem à sistemas com dois filmes depositados em diferentes lados de um substrato de vidro com espessuras d1 + d2 = 1000 nm.

A primeira "coluna" corresponde aos filmes com mesmo material (aSiH) e mesma espessura (d1 = d2 = 500 nm).

A segunda coluna corresponde aos filmes com mesmo material (aSiH) espessuras diferentes (d1 = 200 nm e d2 = 800 nm).

A terceira coluna corresponde aos filmes com material diferente (aSiH e aGeH) e mesma espessuras (d1 = d2 = 500 nm).

Os gráficos da primeira "linha"¯ correspondem as transmitâncias geradas variando d1 2 fd110 nm, d1, d1+10 nmg (lembre-se que d1+d2 = 1000 nm).

As duas "linhas" seguintes correspondem à variação de d1 em um intervalo maior.

Observe que nos casos de filmes com mesmo material e espessuras próximas, a variação na transmitância é menor que nos demais casos.

Uma possível explicação para isso é a simetria nos gráficos da transmitância, que não ocorre nos outros casos.

Valores verdadeiros e recuperados para a transmitância, o índice de refração e o coeficiente de absorção do sistema de filmes finos AAv.

Mostra que embora a recuperação do índice de refração dos dois filmes seja apenas satisfatória, os valores obtidos fazendo a média dos índices recuperados para ambos os filmes é muito boa.

Valores verdadeiros e recuperados paraa transmitância, o índice de refração e o coeficiente de absorção do sistema de filmes finos AvA.

O gráfico  mostra que embora a média dos valores dos índices de refração dos dois filmes seja melhor que as recuperações em separado, os valores obtidos individualmente foram melhores que no caso AAv.

Recuperações para sistemas de filmes idênticos no intervalo 540-1530 nm, usando a informação adicional de que ambos os filmes são idênticos, a fim de resolver o problema da indeterminação.

Sistemas com filmes gedanken de espessura e/ou material distintos Nos testes com filmes diferentes gerados artificialmente, usamos sistemas de dois filmes combinando filmes de silício e germânio depositados em lados opostos de um substrato de vidro.

Os sistemas considerados são, AvB,BvD, CvB e CvD.

Os intervalos espectrais utilizados no processo de recuperação das espessuras e constantes oticas dos filmes de cada sistema foram 631  1621 nm, 934  1924 nm, 817  1807 nm e 945  1935 nm, respectivamente.

Nesses sistemas, não houve casos de indeterminação das espessuras como nos sistemas com filmes idênticos.

As espessuras são inequivocadamente determinadas e o PUMA é capaz de recuperá-las corretamente.

Mostra os gráficos das curvas de nível do erro quadrático do processo de minimização em função das espessuras dos filmes.

Poder-se-ia argumentar que ainda existe alguma indeterminação nos exemplos mostrados, causada provavelmente por erros de natureza numérica.

Apesar disso, a região que possui menor erro quadrático assemelha-se mais a uma "pequena bola" ao redor da espessura verdadeira, bem diferente dos gráficos de erro quadrático obtido para os sistemas com filmes do mesmo tipo mostrados anteriormente.

Mostram os valores recuperados para os sistemas AvB, BvD, CvD e CvD, respectivamente.

Resume as espessuras recuperadas bem como os valores de erro quadrático correspondentes.

Nos sistemas com filmes de mesmo material e espessuras diferentes (AvB e CvD), o coeficiente de absorção foi bem recuperado para valores altos o suficiente de  para produzir uma variação na transmitância.

Os índices de refração de ambos os filmes foram bem recuperados no intervalo considerado.

No sistema de filme de materiais diferentes e mesmas espessuras (BvD) o coeficiente de absorção só só foi recuperados corretamente para o filme de germânio, mais opaco e que possui maior influência na transmitância.

Os índices de refração de ambos os filmes foram bem recuperados no intervalo considerado.

No sistema de filme de materiais e espessuras diferentes (CvB) os coeficientes de absorção de ambos os filmes não puderam ser recuperado corretamente.

Uma possível explicação para isso é o fato do filme de material mais opaco ser mais fino e dessa forma produzir uma influência pequena e similar à influência causado pelo filme de material mais transparente na transmitância.

Os índices de refração de ambos os filmes foram bem recuperados no intervalo considerado.

Espessuras e erros quadráticos obtidos para os sistemas AvB, BvD,CvB e CvD.

Gráficos do erro quadrático em função das espessuras dos filmes dos sistemas AvB, BvD, CvB e CvD.

Valores verdadeiros e recuperados da transmitância, do índice de refração e do coeficiente de absorção do sistema AvB.

Valores verdadeiros e recuperados da transmitância, do índice de refração e do coeficiente de absorção do sistema BvD.

Valores verdadeiros e recuperados da transmitância, do índice de refração e do coeficiente de absorção do sistema CvB.

Valores verdadeiros e recuperados da transmitância, do índice de refração e do coeficiente de absorção do sistema CvD.

Chamaremos de E e F aos filmes reais cujos dados de transmitância foram obtidos através de um espectrofotômetro.
O substrato de silício cristalino é chamado de s.

Foram criados sistemas com um e dois filmes.

Nos sistemas com um filme, consideramos filmes de silício e germânio depositado sobre o substrato de silício cristalino.

Nos sistemas com dois filmes, consideramos filmes de silício e germânio depositados um sobre o outro, no mesmo lado de um substrato de silício cristalino.

Resumidamente, os sistemas considerados são, Es,Fs, e EFs.

A preparação dos filmes reais consistiu no uso de um sistema rf-sputtering usando argônio (Ar) como gás ionizador.

A taxa de depósito dos filmes sobre o substrato de silício foi de 01 nm/seg e o substrato foi mantido a cerca de 200 C durante todo o processo.

Os tempos de depósito dos filmes  o foram de 110 minutos para o filme de germânio e 180 minutos para o filme de silício.

As espessuras foram estimadas mecanicamente através do uso de um Talystep (instrumento utilizado para realizar medições de espessuras de materiais).

Uma justificativa para não se usar sempre o Talystep para realizar este tipo de medição é que esta ferramenta pode danificar a estrutura do filme fino medido.

Os valores 1150 nm para o filme E e 800 nm para o filme F foram obtidos através de uma média de medições realizadas em diferentes pontos da superfície dos sistemas.

E importante notar que  as medições estão sujeitas a erros mecânicos e variações estruturais dos sistemas (dependendo da ordem em que os filmes são depositados, a estrutura final dos filmes pode ser alterada).

Devido a esses erros e variações, a espessura de ambos os filmes sobrepostos possui uma pequena diferença em relação à soma das espessuras obtidas ao medir os sistemas com um unico filme.

Antes de falarmos a respeito da recuperação das constantes oticas, observaremos os resultados relativos à recuperação das espessuras na Tabela 3 3 Os dados reais medidos da transmitância de um substrato de silício cristalino e de cada um dos três sistemas Es,Fs, e EFs possuem um pouco de ruído e, a fim de obter uma boa recuperação com o PUMA, optamos por suavizar os dados das transmitâncias.

Mostra as curvas originais e suavizadas do índice de refração do substrato e da transmitância dos três sistemas de filmes.

O índice de refração foi obtido partir das medições da transmitância do substrato (usando uma versão simplificada da equação (31) onde o n e o  dos filmes foram substituídos pelos do ar).

A transmitância do substrato de silício (c-Si) e do sistema EFs, bem como o intevalo em que foi realizada a recuperação, e  a transmitância dos sistemas Es e Fs.

Para a recuperação das constantes oticas, consideramos apenas o intervalo de energia do fóton determinado pelas linhas verticais pontilhadas, ou seja, o intervalo espectral 1200  2190 nm.

Também é possível notar que a transmitância do sistema com dois filmes sobrepostos é estruturalmente mais parecida com a transmitância do filme de germânio.

Isso ocorre pois o filme de germânio é mais denso e menos transparente que o de silício.

Recuperação da espessura dos filmes E e F, nos sistemas com um filme e com dois filmes sobrepostos, pelo PUMA e pelo método mecânico.

Mostram os gráficos do erro quadrático em função da espessura de cada filme, obtidos durante a recuperação de espessuras e constantes oticas dos filmes E e F nos sistemas Es, Fs e EFs, respectivamente.

Durante a recuperação, após o Passo 2 do Algoritmo 31, obtivemos pontos com erro quadrático muito próximos.

As regiões demarcadas indicam as espessuras candidatas à solução obtidas.

Após uma varredura fina em cada uma das regiões foi escolhida como solução a espessura associada ao menor erro quadrático.

Para os sistemas Es, Fs e EFs, os menores erros quadráticos obtidos foram respectivamente 8237549  1005, 1187394  10  06 e 1881044  10 06.

Compara as constantes oticas recuperadas dos filmes de silício e germânio isolados com aquelas recuperadas a partir do sistema EFs.

Sobre os experimentos com filmes reais, podemos notar que temos claramente a recuperação de dois filmes distintos, com diferentes constantes oticas.

A recuperação das espessuras foi muito boa.

Também indica que a recuperação das constantes é melhor para o filme de germânio, em comparação com o de silício (já que é ele que possui maior influência na transmitância do sistema).

A versão paralela do PUMA atingiu nossas expectativas, mostrando-se eficiente e escalável.

Mostra dois gráficos de speedup do PUMA para o uso de até 7 e 16 processadores em paralelo.

O speedup foi obtido executando-se o método para uma mesma instância do problema (33),(315-319).

A cada execução era variada apenas a quantidade de processos em paralelo.

Cada execução foi repetida três vezes e então feita uma média nos tempos obtidos.

Essa metodologia fornece uma medida mais precisa do tempo de execução do método, atenuando possíveis flutuações na medida dos tempos de execução.

Esperávamos obter um speedup praticamente linear, uma vez que existe pouca comunicação entre os processos.

Podemos ver que mesmo usando 16 processadores, o speedup ainda se mantém próximo do esperado.

Transmitâncias do substrato c-Si e do sistema de dois filmes EFs (acima) e dos sistemas de um unico filmé Es e Fs (abaixo).

Constantes oticas dos filmes E e F recuperados através do PUMA, a partir do sistema de dois filmes e dos sistemas de um unico filmé  Temos a curva do índice de refração do substrato original e suavizado.

Temos as transmitâncias do sistema com filme de silício, germânio e ambos respectivamente.

Gráfico do erro quadrático para o sistema Es e a tabela com os valores encontrados em cada região demarcada.

Gráfico do erro quadrático para o sistema Fs e a tabela com os valores encontrados em cada região demarcada.

Gráfico do erro quadrático para o sistema EFs e a tabela com os valores encontrados em cada região demarcada.

Curva de speedup do método usando até 7 processadores e até 16 processadores.

Os experimentos foram realizados na grade do LCPD e em  no aglomerado do grupo de otimização contínua.

Sobre as recuperações, podemos concluir que a recuperação das propriedades oticas torna-se muito difícil, quando o sistema é composto por filmes de mesma natureza e espessura.

Para sistemas com filmes do mesmo material, porém com espessuras diferentes o PUMA recupera adequadamente as espessuras e constantes oticas.

A recuperação das espessuras nos casos de filmes de diferentes materiais também é muito boa.

Conforme pode ser observado nos gráficos de erro quadrático, a indeterminação foi reduzida drasticamente.

Isso mostra que as restrições físicas reduzem o espaço de busca de forma eficiente para sistemas com filmes de natureza distintas.

De uma forma geral, no caso de filmes diferentes, a recuperação do coeficiente de absorção é melhor nos filmes mais densos, que possuem maior influência na transmitância.

Já os índices de refração são bem recuperados em todos os casos, especialmente nas regiões de baixa absorção no espectro considerado.

E bastante surpreendente que um problema inverso com tão alto grau de indeterminação possa  ser corretamente resolvido com um algoritmo de minimização.

A paralelização do método demonstrou um speedup linear e possibilitou a recuperação das constantes oticas e espessuras de filmes finos em sistemas com dois filmes, feito que não era empirica-mente possível com a versão seqüencial do método.

PACKMOL  é um método criado para resolver o problema de posicionar conjuntos de diferentes moléculas em uma região fechada no espaço tridimensional, respeitando uma distância mínima e algumas restrições de posicionamento entre as moléculas.

Este método tem a finalidade de obter configurações iniciais de moléculas para simulações de dinâmica molecular.

Neste capítulo temos o objetivo de descrever como foi construída a versão paralela do PACKMOL e os resultados obtidos com a paralelização.

Os tópicos abordados a seguir são, o modelo matemático do problema, a implementação do método em sua versão seqüencial, a paralelização do método e a implementação da versão paralela, incluindo os experimentos numéricos.

Nesta seção consideramos o problema de posicionar moléculas em uma região limitada do espaço, de forma que seja respeitada uma distância mínima entre seus atomos sujeitos ou não à restrições de posicionamento.

Uma molécula é uma estrutura rígida, representada pelas coordenadas cartesianas de seus atomos.

Por estrutura rígida, entende-se que atomos de uma mesma molécula devem manter uma mesma posição relativa entre si, não podendo ser posicionados independentemente uns dos outros.

Cada molécula e cada atomo possuem um índice associado para permitir sua identificação.

Nesté capítulo usaremos i e j para denotar respectivamente os índices de moléculas e atomos.

A quantidadé total de moléculas é expressada por M e a quantidade de atomos de uma molécula de índice i e denotada por A.

O centro geométrico de uma molécula é o ponto caracterizado pela média aritmética das coordenadas de seus atomos.

Vamos considerar que todas as moléculas são posicionadas com seus centros geométricos na origem do eixo cartesiano.

As coordenadas cartesianas iniciais de cada um dos atomos.

Aplicação de translação e rotação a uma molécula.

Cada atomo pode sofrer uma rotação e uma translação a partir do ponto de origem.

E importante lembrar que moléculas são estruturas rígidas, e assim, todos os atomos de uma mesma molécula sofrem as mesmas transformações.

Representam respectivamente uma translação e uma rotação a serem aplicadas à cada um dos A atomos de cada uma das M moléculas.

Onde d > 0 é a distância mínima entre os atomos e a norma usada é a euclidiana.

Os valores representam, respectivamente, os limitantes inferiores e superiores que definem a caixa onde as moléculas devem ser posicionadas.

As inequações denotadas em (43) impõem uma distância mínima d entre os atomos de diferentes moléculas.

Também é possível atribuir a cada atomo uma ou mais restrições de posicionamento (RP).

Tais restrições permitem limitar o posicionamento de conjuntos de atomos a determinadas regiões do espaço, como por exemplo, impor que os atomos de todas as moléculas de um determinado tipo só possam ser posicionadas dentro dé uma esfera ou cubo.

Ilustra um exemplo desse tipo de restrição.

Uma explicação detalhada de cada um dos 12 tipos de restrições do posicionamento pode ser encontradas no Anexo B.

Exemplo de restrição no posicionamento de moléculas.

Um grupo de lipídios é limitado a formar uma esfera no centro da região de empacotamento.

Um grupo de moléculas de agua é limitado ao interior da esfera e outro ao exterior.

Uma forma de resolver o problema de encontrar angulos de rotação, que respeitem (43), (44) e as RP é escreve-lo como um problema de minimização.

Vamos escrever a função de mérito da seguinte forma.
A função objetivo f é contínua e diferenciável.

O número de variáveis do Problema (47) é 6 M (três angulos e uma translação no espaço tridimensional por molécula).

O foco de nosso trabalho é a construção de uma versão paralela do PACKMOL.

Antes de explicar os detalhes envolvidos na construção da versão paralela, é importante explicar alguns aspectos da implementação da versão seqüencial do método, que foi utilizada como base para nosso trabalho.

A seguir discutiremos a respeito da implementação seqüencial do PACKMOL, incluindo algumas estratégias utilizadas para avaliar a função de mérito e seu gradiente de f, calcula as distâncias entre todos os pares de atomos de moléculas distintas existentes em  dist uma dada instância do problema.

Calcular a distância de cada atomo com todos os demais e custoso e desnecessário.

Note que nem todos os pares de atomos contribuem para o somatório da função.

Se dois atomos estão posicionados a mais de d unidades de distância um do outro, ¯ unidades um do outro e sua distância não precisa ser calculada.

Assim, os unicos atomos que devem ser levados em consideração no cálculo da soma são os que estão na mesma caixa ou em caixas adjacentes.

Exemplifica o que foi dito acima usando apenas duas dimensões, a fim de facilitar a compreensão.

O algoritmo abaixo mostra como calcular a função f (46) usando as subcaixas para evitar o dist cálculo desnecessário de algumas distâncias.
Neste exemplo, em duas dimensões, é ilustrado como a avaliação da função (46) é simplificada.

É ilustrada a divisão da caixa em subcaixas menores com lado de tamanho d dentro da região, aqui denominada, definida  ¯ em (44).

É ilustrada uma das etapas do cálculo das distâncias.

Os atomos estão desenhados como esferas cinzas.

Note que apenas são consideradas as distâncias (linhas cinzas) do atomo a, no interior da caixa cinza escuro, com os demais atomos de sua caixa e das caixas adjacentes à sua.

Listas usadas para codificar a estrutura de caixas.

Uma molécula, possui três atomos na caixa (0, 0, 0).

Outra molécula possui um atomo na caixa (0, 1, 1) e dois na (1, 1, 1).

Para cada uma das oito caixas temos uma lista correspondente.

Como apenas três caixas possuem atomos, somente três listas possuem elementos e são indicadas na lista de caixas não vazias.

Em cada posição das listas não nulas temos o par (i, j) onde i é o índice de uma molécula e j o índice de um atomo.

Em ambas as figuras, a região demarcada com a cor cinza escuro representa a caixa que está sendo analisada.

A região cinza clara representa uma de suas adjacências.

Uma das distâncias que o método deve computar é entre os atomos (1,1) e (2,1).

Que representa algumas iterações adiante, uma das distâncias que o método vai computar é novamente entre os atomos (2,1) e (1,1).

Dessa forma, usando a estratégia das caixas adjacentes, o método computa duas vezes uma mesma distância.

Para evitar isso, reduzimos a quantidade de caixas adjacentes que são consideradas no cálculo das distâncias.

Para cada caixa c consideramos como sua vizinhança apenas as caixas com índices mostra quais caixas adjacentes devem ser consideradas de forma a impedir o cálculo duplicado de distâncias para atomos que estão em caixas diferentes.

Ilustração da estratégia de redução da vizinhança.

Temos a ilustração em três dimensões e temos uma projeção em duas dimensões para facilitar a compreensão.

A avaliação do gradiente da função de mérito conta com alguns artifícios adicionais para torná-la mais eficiente.

Apenas o cálculo de um dos termos é necessário, bastando inverter o sinal de um para obter o outro.

Para obter  f, calcula-se para todos os pares de atomos que contém o atomo de índice j da molécula de índice i.

Por outro lado, a implementação deste cálculo conta com a estratégia de considerar apenas os atomos nas caixas vizinhas.

Outras derivadas parciais possuem resultados conhecidos que não precisam ser calculados.
Na implementação do PACKMOL, o método de otimização utilizado para resolver o problema de minimização (47) é o GENCAN.

Trata-se de um método baseado em restrições ativas para resolver problemas de otimização contínua com restrições de caixas.

Para uma introdução as técnicas básicas de otimização e aos métodos de restrições ativas, sugerimos.

GENCAN adota como critério para abandono de face o critério descrito em, que utiliza os gradientes espectrais projetados definidos em.

Para a minimização interna as faces, GENCAN utiliza um algoritmo de busca linear que combina backtracking e extrapolação.

GENCAN utiliza, também, um método de Newton Truncado para escolher uma direção de busca a cada passo no interior das faces.

Uma descrição detalhada do método pode ser encontrada em.

O GENCAN pode ser obtido na página web do projeto TANGO  do qual ele faz parte.

A implementação seqüencial do PACKMOL foi construída usando as estratégias descritas nessa seção a fim de obter-se uma maior eficiência.

A seguir falaremos sobre a versão paralela do PACK-MOL, cuja implementação foi baseada na versão seqüencial do método e incorpora algumas das estratégias citadas.

Um dos objetivos do nosso trabalho é construir uma versão paralela do PACKMOL.

Para isso, optamos por paralelizar a avaliação da função de mérito e seu gradiente.

Baseamos tal decisão no fato de tais funções consumirem cerca de 85% do tempo de execução do PACKMOL.

Nesta seção, falaremos a respeito da paralelização da função de mérito e de seu gradiente.

A estratégia usada para paralelizar a função de mérito consiste em atribuir a tarefa de calcular as distâncias entre um atomo e aqueles posicionados na mesma caixa e nas caixas vizinhas, pertencentes à diferentes moléculas, a processos distintos.

Ao término desses cálculos, os resultados individuais de cada processo são combinados, resultando na soma desejada.

O modelo de paralelismo adotado envolve o uso de threads (processos leves) e memória compatilhada.

Uma justificativa para tal decisão é a necessidade de minimizar os custos com operações de E/S e sincronização entre processos.

O fato de todos os processos terem acesso a uma mesma região de memória contendo os dados sobre as moléculas e suas posições nos permite construir uma versão paralela eficiente do PACKMOL.

Nossa primeira versão paralela da implementação da função (46) seguiu exatamente esta estratégia.

Construímos-na a partir da implementação seqüencial e procuramos realizar o menor número possível de modificações na implementação original.

Veja a seguir um algoritmo ilustrando seu funcionamento.
Nossa primeira versão possui um inconveniente.

Ao variarmos a quantidade de processos, obtemos resultados diferentes para a resolução de uma mesma instância do problema.

Isso acontece porque não é imposta uma ordem na realização da soma dos termos da função de mérito.

Executar o método usando diferentes números de processos significa realizar a soma em ordens diferentes.

Isso resulta em avaliações de função com valores distintos (é importante lembrar que, computacionalmente, uma alteração na ordem dos elementos a serem somados pode alterar o resultado final de uma soma), levando o método a convergir para pontos diferentes.

O fato do método poder encontrar soluções diferentes para um mesmo problema, além de ser extremamente indesejável para o usuário, dificulta a medição do impacto da paralelização da função na execução do método.

Esse inconveniente nos levou a considerar a necessidade de impor uma ordem na soma das distâncias de forma que o resultado final fosse sempre o mesmo, independentemente da quantidade de processos ou da forma de distribuir os atomos entre eles.

Nossa solução para tal problema consiste em computar e armazenar resultados parciais da avaliação da função (46).

Esses resultados parciais são computados sempre da mesma forma, independentemente da quantidade de processos.

Depois, são somados seqüencialmente, sempre seguindo  uma mesma ordem, a fim de obtermos um valor que corresponda à avaliação da função em um dado ponto.

Esses resultados parciais são chamados de somas parciais.

Abaixo temos um algoritmo ilustrando a avaliação da função (46) usando as somas parciais, importante ressaltar que cada soma parcial é computada inteiramente por um mesmo processo.

Para um exemplo ilustrado de todo esse procedimento.

Avaliamos também a possibilidade de realizar a soma dos resultados parciais em paralelo.

A necessidade de impor uma ordem nas operações, para que a soma resulte sempre em um mesmo valor, independentemente da quantidade de processos envolvidos, foi o maior obstáculo a ser superado.

Identificamos um algoritmo recursivo para realizar tal operação.

Ele consiste em duas fases.

Na primeira, o vetor de somas parciais é dividido pela metade em dois outros vetores, que são distribuídos entre dois processos.

Essa divisão e distribuição é feita recursivamente até que o vetor distribuído possua apenas dois elementos.

Na segunda fase, cada processo deve então somar esses dois valores, resultando em um vetor apenas com a soma.

Os resultados devem ser distribuídos de forma que metade dos processos anteriores possuam vetores com dois elementos.

A soma e concatenação são repetidos até que todos os números sejam somados em relação aos elementos originais.

E importante mencionar que nesse processo de soma e concatenação, é necessário manter as posições relativas dos elementos somados.

Ilustram o processo de ordenação e paralelização de operações da função objetivo em um cenário com dois processos.

A cada processo é atribuído um conjunto de caixas.

São ilustradas as caixas envolvidas na computação das somas parciais das caixas 1 e 4 respectivamente.

Temos o cálculo do valor da função objetivo a partir das somas parciais pelo processo 1.

Segue uma versão iterativa do algoritmo de soma dos elementos de um vetor em paralelo.
No final desse algoritmo, w conterá o resultado desejado.

Independentemente da quantidade de processos disponíveis, a soma final será sempre a mesma, já que as somas são realizadas sempre na mesma ordem.

Esse algoritmo pode atingir um desempenho de O(log(C)).

Para isso, é necessário que a quantidade de processadores seja pelo menos C.

Dessa forma, todas as somas são sempre realizadas  em paralelo.

Usando apenas 4 processadores, o que temos disponível atualmente, o desempenho da soma paralela é muito inferior ao desempenho obtido por uma soma seqüencial para qualquer problema real resolvido pelo PACKMOL.

Por esse motivo, acabamos descartando a idéia.

Resumidamente, a avaliação paralela da função (46) funciona da seguinte forma.
Passo 1 Cada processo recebe um conjunto de índices de caixas.

Passo 2 Para cada caixa c cada processo computa a soma parcial e armazena o resultado em uma  posição correspondente em w.

Passo 3 Se houver caixas que ainda não foram distribuídas, vá para o Passo 1.

Passo 4 O processo 1 percorre w e computam a soma de todos seus elementos, em paralelo, obtendo  o valor da função.

Em relação ao gradiente da função (46), na nossa primeira versão paralela, onde dividimos os cálculos sem nos preocupar com a ordem das somas dos resultados obtidos por cada processo, tivemos o mesmo inconveniente de obter resultados diferentes para avaliações do gradiente com diferentes quantidades de processos.

Para resolver isso, novamente precisamos impor uma ordenação no cálculo de somas.

Dessa vez trata-se das somas para obter as derivadas parciais descritas pela equação (411).

Nossa primeira abordagem foi tentar isolar conjuntos de operações através de somas parciais de forma similar aquela feita na avaliação da função de mérito.

Para isso foi necessário o uso intensivo de listas e memória.

Combinar os resultados também representou um problema, já que para isso era necessário quase o mesmo esforço que o consumido para efetuar os cálculos de forma seqüencial.

Depois de alguns testes e tentativas mal sucedidas de melhorar o desempenho, descartamos essa estratégia.

Nossa segunda abordagem foi modificar a forma como o gradiente era avaliado.

Precisávamos criar uma estrutura que fosse mais fácil de se paralelizar, considerando a restrição de que as operações matemáticas precisavam ser feitas sempre em uma mesma ordem.

Notamos que a maior dificuldade em isolar os cálculos se devia ao já mencionado fato da implementação do gradiente aproveitar o cálculo de algumas parcelas da soma para obter outras.

De acordo com a equação (413) é do vetor gradiente também.

No caso da divisão da tarefa de computar o gradiente entre vários processos, os acessos concorrentes a diversas posições do vetor gradiente nos impedem de impor uma ordem na realização dos cálculos sem que o desempenho paralelo seja severamente prejudicado.

Remover tal artifício computacional teve o impacto de aumentar o custo de avaliação do gradiente.

Por outro lado, permitiu facilmente isolar e dividir algumas operações de forma a permitir-nos construir uma versão paralela da avaliação do gradiente que de fato fosse eficiente e que obtivesse resultados idênticos independentemente da quantidade de processos.

A versão paralela da avaliação do gradiente funciona da seguinte forma.
Dessa forma conseguimos que a avaliação paralela do gradiente da função (46) em um determinado ponto forneça sempre o mesmo resultado, independentemente da quantidade de processos envolvidos na computação.

Além de paralelizar os cálculos que mais consumiam tempo na avaliação da função objetivo e seu gradiente, optamos por paralelizar alguns laços que inicializam vetores e a avaliação das restrições de posicionamento.

Conforme foi dito na Seção 42, o PACKMOL fornece a possibilidade de restringir o posicionamento de grupos de moléculas a regiões específicas.

A paralelização da avaliação dessas restrições resumiu-se em dividir as moléculas entre os processos disponíveis e computar tais penalizações em paralelo.

Para evitar o problema de somar as penalizações em ordem arbitrária, usamos a estratégia de calcular as somas parciais. 

Até agora nada foi dito sobre o modelo de paralelismo utilizado.

Inicialmente consideramos a possibilidade de usar o modelo de troca de mensagens para a implementação da versão paralela do PACKMOL.

Após alguns experimentos, percebemos que o custo das operações de E/S necessárias para transmitir os dados (referentes as posições dos atomos) entre os processos é muito alto e prejudica drasticamente o desempenho da versão paralela.

Pensando em eliminar o custo de transmitir os dados, optamos pelo modelo de threads com memória compartilhada.

Dessa forma, todos os cálculos são feitos em uma região de memória compartilhada por todos os processos e há menor sobrecarga com sincronização dos estados dos mesmos.

Com a popularização de computadores com múltiplos núcleos ou com diversos processadores compartilhando uma mesma memória principal, o uso desse modelo vem tornando-se interessante do ponto de vista prático.

Nossos experimentos numéricos tem o objetivo de avaliar a eficiência da paralelização da avaliação da função objetivo e de seu gradiente e o impacto dessa paralelização na execução do método.

Na implementação usamos a API OpenMP  e o código foi todo escrito em Fortran 77.

Os binários foram obtidos através do compilador gfortran (parte integrante da projeto GNU Compiler Collection) versão 42 para Linux.

A unica opção de compilação usada foi O3''.

A máquina onde os testes foram rodados possui um processador Intel(R) Core 2 Quad de 240 GHz, 4 MB de cache e 4 GB de RAM.

Nos experimentos aqui realizados consideramos cinco problemas diferentes.
Inicialmente comparamos o desempenho da versão seqüencial com o desempenho da versão paralela executada com um unico processo, concluindo que esta ultima é cerca de 1, cinco vezes mais lenta que a primeira.

Em seguida, fizemos uma análise da aceleração da versão paralela.

Nesse caso, escolhemos como  o tempo de execução da versão paralela executada com um unico processo.

Os tempos dé execução relatados aqui correspondem sempre à média dos tempos de três execuções.

Para medir o ganho com a paralelização na avaliação da função objetivo e seu gradiente, executamos o método fixando uma instância do problema de empacotamento e variando a quantidade de processos em paralelo (de 1 até 4).

Nessas execuções, contabilizamos o tempo gasto apenas pelos trechos paralelizados.

O resultado foi próximo do esperado apenas para os problemas D e E.

Com os problemas A, B e C, não obtivemos um speedup linear, conforme esperado.

Uma possível explicação para esse fenômeno é a pequena quantidade de atomos associada ao custo computacional de inicialização e gerenciamento do ambiente paralelo (rotinas para criação e destruição de threads, divisão dinâmica de dados, entre outras) a cada avaliação da função objetivo e seu gradiente.

A pequena quantidade de atomos faz com que o custo das ações a serem realizadas em paralelo seja próximo ao custo computacional exigido pelas rotinas envolvidas na gerência do ambiente paralelo, o que prejudica o desempenho do método.

Outros fatores que podem prejudicar o desempenho são a quantidade de restrições de posicionamento e a quantidade de atomos das moléculas as quais as restrições são aplicadas.

Estes fatores explicam o melhor desempenho obtido com o problema A em relação ao C.

Apesar de possuírem quantidades de atomos parecidas, têm uma diferença relevante, o problema A não impõe qualquer restrição dé posicionamento, enquanto que o C restringe o posicionamento de grupos de moléculas de agua e  lipídios.

De forma similar, o problema D, apesar de possuir mais atomos que o E, possui também um conjunto menos uniforme de moléculas.

Uniformidade de moléculas significa moléculas diferentes mas com aproximadamente a mesma quantidade de atomos entre si.

Por esse motivo, o melhor desempenho é obtido com E.

Para avaliar o impacto da paralelização da função objetivo e seu gradiente na execução do método, medimos tempo total de execução do método com até 4 processos em paralelo.

A Tabela 41 mostra os tempos de execução do método para cada problema.

Tempos consumidos pelo método ao ser executado com os problemas A, B, C, D e E, usando de 1 até 4 processos em paralelo.

Para avaliar os ganhos obtidos com a paralelização do método, decidimos comparar o speedup teórico, calculado a partir de dados obtidos através de um profiling do PACKMOL original, com o speedup obtido a partir dos dados mostrados na Tabela 4 1 O profiling consistiu em medir o consumo de processamento de cada função do método ao resolver diferentes instâncias do problema de empacotamento.

Para realizar o profiling usamos o programa gprof e contabilizamos dados da execução do método com 5 instâncias diferentes.

Dessa forma, descobrimos que a parte paralelizada equivale a aproximadamente 85% do tempo de execução do método.

Considerando esse dado, podemos obter o speedup teórico para uma execução com 4 processos.
Os gráficos do speedup medido comparado com o teórico calculado.

Para os casos A, B e C, a versão paralela tem um desempenho bem inferior ao teórico.

Tal desempenho já era previsto, uma vez que o speedup obtido para esses mesmos problemas, ao contabilizar apenas o tempo dos trechos paralelizados da função de mérito e seu gradiente, também é inferior ao teoricamente suposto.

Nos casos D e E, a versão paralela comporta-se aproximadamente conforme esperado.

Gráficos do speedup da avaliação da função objetivo.

Gráficos do speedup da avaliação do gradiente da função objetivo.

Gráfico do speedup real do método comparado com o speedup teórico para cada um dos experimentos.

Neste trabalho, apresentamos a motivação no uso de computação paralela em otimização contínua, alguns conceitos básicos da area de computação paralela e da area de otimização contínua.

Falamos também a respeito de uma aplicação de otimização contínua para a obtenção de configurações iniciais para simulação de dinâmica molecular (PACKMOL) e um método de otimização específico para estimar espessuras e constantes oticas de filmes finos (PUMA), em suas versões seqüenciais é paralelas, incluindo a avaliação dos ganhos com a paralelização.

A versão paralela do PACKMOL foi construída usando-se um modelo misto de memória compartilhada e threads.

Obtivemos, na prática, um speedup próximo ao previsto teoricamente, apenas para instâncias com um grande número de moléculas.

A versão paralela do PUMA foi construída usando-se o modelo de troca de mensagens.

Por se tratar de uma aplicação com estrutura bag-of-tasks, conseguimos excelente desempenho e escalabilidade.

A versão paralela permitiu usar o método para recuperar as espessuras e constantes oticas de sistemas com dois filmes finos e um substrato.

Teoricamente isso já era possível, porém era impraticável usar o PUMA com esse tipo de sistema, devido ao longo tempo de espera necessário para cada etapa do método.

Com a paralelização, conseguimos recuperar os dados de sistemas com dois filmes com sucesso e desenvolvemos uma metodologia de uso similar ao que já era usado para os sistemas com um unico filme, para obter os dados nos sistemas duplos.

Sobre a qualidade das recuperações, identificamos os casos em que as espessuras ou as constantes oticas são naturalmenté indeterminadas.

No caso das espessuras, apresentamos alternativas para resolver as indeterminações.

Também identificamos a necessidade de alterar a forma do método obter a aproximação inicial do  de cada filme.

Trocamos de um aproximação linear por partes usando dois segmentos, para uma aproximação melhor usando três segmentos.

O conhecimento prático e teórico adquirido ao longo da elaboração desse trabalho, nos permite concluir que o uso de computação paralela em algoritmos de otimização contínua garante um melhor aproveitamento de processadores com múltiplos núcleos e computadores multiprocessados, ou grades e aglomerados de computadores, que estão a cada dia mais acessíveis.

Conseqüentemente, também permite a resolução mais rápida de problemas, ou até mesmo a solução problemas que antes não podiam ser resolvidos.

