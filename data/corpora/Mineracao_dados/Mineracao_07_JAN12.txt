A qualidade das hipóteses induzidas pelos atuais sistemas de Aprendizado de Máquina depende principalmente da quantidade e da qualidade dos atributos e exemplos utilizados no treinamento.

Frequentemente, resultados experimentais obtidos sobre grandes bases de dados, que possuem muitos atributos irrelevantes, resultam em hipóteses de baixa precisão.

Por outro lado, muitos dos sistemas de aprendizado de máquina conhecidos não estão preparados para trabalhar com uma quantidade muito grande de exemplos.

Assim, uma das áreas de pesquisa mais ativas em aprendizado de máquina tem girado em torno de técnicas que sejam capazes de ampliar a capacidade dos algoritmos de aprendizado para processar muitos exemplos de treinamento, atributos e classes.

Para que conceitos sejam aprendidos a partir de grandes bases de dados utilizando Aprendizado de Máquina, pode-se utilizar duas abordagens.

A primeira realiza uma seleção de exemplos e atributos mais relevantes, e a segunda e a abordagem de ensembles.

Um ensemble e um conjunto de classificadores cujas decisões individuais são combinadas de alguma forma para classificar um novo caso.

Ainda que ensembles classifiquem novos exemplos melhor que cada classificador individual, eles se comportam como caixas pretas, no sentido de não oferecer ao usuário alguma explicação relacionada a classificação por eles fornecida.

O objetivo deste trabalho é propor uma forma de combinação de classificadores simbólicos, ou seja, classificadores induzidos por algoritmos de AM simbólicos, nos quais o conhecimento e descrito na forma de regras if-then ou equivalentes, para se trabalhar com grandes bases de dados.

A nossa proposta é a seguinte, dada uma grande base de dados, divide-se esta base aleatoriamente em pequenas bases de tal forma que e viável fornecer essas bases de tamanho menor a um ou vários algoritmos de AM simbólicos.

Logo após, as regras que constituem os classificadores induzidos por esses algoritmos são combinadas em um único classificador.

Para analisar a viabilidade do objetivo proposto, foi implementado um sistema na linguagem de programação lógica Prolog, com a finalidade de avaliar regras de conhecimento induzidas por algoritmos de Aprendizado de Máquina simbólico e avaliar diversas formas de combinar classificadores simbólicos bem como explicar a classificação de novos exemplos realizada por um ensemble de classificares simbólicos.

A finalidade e implementada pelo Módulo de Análise de Regras e a finalidade pelo Módulo de Combinação e Explicação.

Esses módulos constituem os módulos principais do R S ule ystem.

Neste trabalho, são descritos os métodos de construção de ensembles e de combinação de classificadores encontrados na literatura, o projeto e a documentação do R S ule ystem, a metodologia desenvolvida para documentar o sistema R S ule ystem, a implementação do Módulo de Combinação e Explicação, objeto de estudo deste trabalho, e duas aplicações do Módulo de Combinação e Explicação.

A primeira aplicação utilizou uma base de dados artificiais, a qual nos permitiu observar necessidades de modificações no Módulo de Combinação e Explicação.

A segunda aplicação utilizou uma base de dados reais.

A qualidade das hipóteses induzidas pelos atuais sistemas de Aprendizado de máquina (AM) depende principalmente da quantidade e da qualidade dos atributos e exemplos (ou casos) utilizados no treinamento.

Frequentemente, resultados experimentais obtidos sobre grandes bases de dados, nas quais muitos atributos irrelevantes estão presentes, resultam em hipóteses de baixa precisão.

Por outro lado, muitos dos sistemas de aprendizado de máquina conhecidos não estão preparados para trabalhar com uma quantidade muito grande de exemplos.

Assim, uma das áreas de pesquisa mais ativas em aprendizado de máquina tem girado em torno de técnicas que sejam capazes de ampliar a capacidade dos algoritmos de aprendizado para processar muitos exemplos, atributos e classes.

Esses problemas são típicos da área de mineração de dados em grandes bases (Data Mining).

Para que os conceitos sejam aprendidos a partir de grandes bases de dados, utilizando AM, pode-se utilizar duas abordagens.

A primeira realiza uma seleção de exemplos e atributos mais relevantes, e a segunda e a abordagem de ensembles, a qual é o foco principal de nosso trabalho.

Nessa abordagem, primeiramente são retiradas, por exemplo, L amostras (subconjuntos) do conjunto de exemplos disponível para realizar o aprendizado (exemplos de treinamento).

Logo após, cada um desses L subconjuntos e submetido a algum algoritmo de AM induzindo assim L classificadores, os quais podem ser construídos em paralelo.

Um ensemble e um conjunto de classificadores cujas decisões individuais são combinadas de alguma forma para classificar um novo caso.

Deve ser observado que a abordagem de ensembles pode ser utilizada com pequenas bases de dados.

Na realidade, ensembles foram inicialmente propostos para melhorar a precisão de algoritmos de aprendizado de máquina.

Apesar de melhorar o poder de predição dos algoritmos de aprendizado, os métodos de construção de ensembles normalmente geram classificadores grandes, o que pode ser indesejável.

Por exemplo, usando o conjunto de dados Frey-Slater com 16 atributos numéricos e 16000 exemplos, é possível obter uma boa precisão no conjunto de testes com 4000 exemplos utilizando 200 hipóteses unindo-as com votação.

Incluindo o conjunto de treinamento e o conjunto de testes, o conjunto de dados requer aproximadamente 700 Kbytes.

Todavia, cada classificador ocupa 295 Kbytes de memória, o que implica que o ensemble de 200 classificadores requer 58 Mbytes-mais de 85 vezes o tamanho do conjunto de dados completo!

É explorado o algoritmo de Boosting com pequenos conjuntos de classificadores, por motivos, É mais fácil analisar o conhecimento de ensembles pequenos e assim fazer uma análise do funcionamento interno da técnica de Boosting.

Ensembles com baixo número de classificadores são mais baratos, computacionalmente falando, fazendo com que haja uma melhora nas taxas de erro de predição de novos exemplos requerendo poucos recursos adicionais.

Neste trabalho, foram considerados ensembles com pequeno número de classificadores (nos experimentos realizados, foram utilizados, no máximo, 7 classificadores).

Isso se dá porque, tomadas três hipóteses (classificadores) h não correlacionadas, se combinadas com uma votação simples sem peso, por exemplo, a taxa de erro das hipóteses combinadas e menor que as taxas de erro de cada uma das três hipóteses.

Isso indica que em um pequeno número de hipóteses pode-se ter uma melhora na precisão, desde que essas hipóteses sejam independentes.

Em Aprendizado de Máquina, o que se faz é construir hipóteses com correlação mínima entre elas.

Ainda que ensembles classifiquem novos exemplos melhor que cada classificador individual, eles se comportam como caixas pretas, no sentido de não oferecer ao usuário alguma explicação relacionada a classificação por eles fornecida.

Observa-se, também, que alguns algoritmos de aprendizado de máquina induzem classificadores que não tem condições de oferecer uma explicação que justifique a classificação de novos casos.

Em algumas situações, essas explicações são obrigatórias.

Por exemplo, em certos países, para dizer ao cliente de um banco se seu crédito foi aprovado ou não, existe a necessidade legal de se justificar o motivo de sua aprovação ou negação.

Nesses casos, algoritmos de aprendizado de máquina que induzem classificadores com comportamento do tipo caixas pretas não podem ser utilizados.

Assim, perante a necessidade da explicação de classificação em situações em que se faz o uso de aprendizado de máquina, surgiu a idéia de, dado um conjunto de classificadores simbólicos, ou seja, classificadores que podem ser escritos em forma de regras if-then, construir outro classificador simbólico que consiste das melhores regras desse conjunto de classificadores inicial.

Para essa seleção, diferentes critérios podem ser utilizados, como medidas de avaliação de regras, por exemplo.

No LABIC-Laboratorio de Inteligencia Computacional, encontra-se em desenvolvimento um projeto de grande porte denominado DISCOVER.

O projeto DISCOVER tem como objetivo fornecer um ambiente integrado para apoiar as etapas do processo de descoberta de conhecimento, oferecendo funcionalidades voltadas para Aprendizado de Máquina (AM), Mineração de Dados (Me Mineração de Textos (MT).

As funcionalidades voltadas para AM consideram, entre outros, um formato padrão para as regras induzidas por algoritmos de AM simbólico, denominado PBM bem como um formato padrão para os exemplos utilizados.

No intuito de testar algumas idéias, que poderão futuramente ser implementadas no ambiente DISCOVER, dentre elas a idéia de combinar classificadores simbólicos.

Foi implementado um sistema computacional, denominado R S ule ystem, composto de dois módulos principais, os quais são, Módulo de Análise de Regras (MAR), com o objetivo de analisar diversas medidas de avaliação de regras propostas na literatura para avaliar regras induzidas por algoritmos de AM simbólico.

Módulo de Combinação e Explicação (MCE), com o objetivo de construir, dado um conjunto de classificadores simbólicos, um outro classificador simbólico que contenha regras desse conjunto de classificadores que sejam as "melhores" segundo as diversas medidas de qualidade de regras implementadas no MAR.

Outro objetivo deste módulo é fornecer ao usuário, dado um conjunto de classificadores simbólicos e um exemplo do domínio dos classificadores, quais as regras que foram disparadas nesses classificadores e qual a "melhor" regra, segundo, também, alguma das diversas medidas de avaliação de regras implementadas no MAR.

Em outras palavras, fornecer ao usuário uma explicação da classificação.

Foi decidido implementar o R Sule ystemna linguagem de programação lógica Prolog, mais especificamente em LPA-PROLOG.

A escolha da linguagem Prolog deve-se ao fato de ser uma linguagem apropriada para o desenvolvimento de protótipos nos quais novas idéias possam ser facilmente testadas antes de serem implementadas em um sistema de grande porte.

Uma outra característica importante de Prolog é a possibilidade de realizar consultas para obter informações que não ficam restritas aquelas pré-definidas no sistema.

Os dados de entrada para o R S ule ystemconsistem de, um ou vários conjuntos de regras, induzidas por algoritmos de AM simbólico, e um conjunto de exemplos.

Ambos os dados de entrada estão na sintaxe padrão em Prolog, que e equivalente a sintaxe padrão PBM de regras e exemplos adotada no projeto DISCOVER.

O objetivo deste trabalho é propor uma forma de combinação de classificadores para se trabalhar com grandes bases de dados.

Dada uma grande base de dados, divide-se esta base aleatoriamente em pequenas bases de tal forma que é viável fornecer essas bases de tamanho menor a um ou vários algoritmos de AM.

Para analisar a viabilidade desta proposta, foram realizadas as seguintes tarefas, descritas neste trabalho.
Definições relacionadas a aprendizado de máquina supervisionado e a ensembles de classificadores, são descritos alguns métodos de construção de ensembles, que podem ser utilizados com diferentes algoritmos de AM, e são descritas as formas de se combinar classificadores para gerar ensembles.

É descrito o R S ule ystem, sua documentação e a metodologia desenvolvida para documenta-lo.

São descritos os conversores de formato, que convertem conjuntos de regras e exemplos na sintaxe padrão PBM para a sintaxe padrão em Prolog.

É descrito o módulo de Combinação e Explicação pertencente ao R S ule ystem.

É abordado um exemplo de utilização do MCE utilizando um conjunto de dados artificial.

É descrito um estudo de caso utilizando o MCE e um conjunto de dados do mundo real, os experimentos realizados, os resultados obtidos e é feita uma análise desses resultados.

São abordadas algumas definições e conceitos de aprendizado de máquina supervisionado e de ensembles de classificadores.

Ensembles de classificadores, teoricamente, são mais precisos que os classificadores que o compõem.

Para que isso ocorra, algumas condiçõoes são necessarias, como a independência entre os classificadores que compõem o ensemble, e esses classificadores serem precisos.

Assim, na Seção 2são discutidas as condições para que um ensemble seja mais preciso que seus componentes individuais, e as razões que motivam a construir um ensemble.

Também são abordados os métodos de construção de ensembles e os métodos de combinação de classificadores, respectivamente.



Conjunto de Exemplos no Formato Atributo-Valor.

Dado um conjunto S de exemplos de treinamento a um algoritmo de AM, um classificador h sera induzido.

O classificador consiste da hipótese feita sobre a verdadeira, mas desconhecida função f.

Dados novos exemplos x, o classificador, ou hipótese, h prediz o valor correspondente y.

Algoritmos de AM simbólicos induzem o classificador h de tal forma que o conceito descrito por h e facilmente interpretável por seres humanos e, geralmente, pode ser transformado em conjuntos de regras if-then, ou seja, regras do tipo Corpo Cabeça ou Body Head.

Uma regra R pode então ser resumidamente denotada como B H.

Quando essa u transformação acontece, o classificador composto por regras possui uma regra especial a regra default, a qual possui Corpo vazio e a Cabeça e dada pela classe que possui maior distribuição de exemplos no conjunto de treinamento.

Dado um exemplo x e uma regra R, se o Corpo de R e verdade para esse exemplo, então R cobre x.

Pode-se medir um conjunto de regras de um classificador simbólico h dado um conjunto de exemplos S.

Neste caso, h consiste de um conjunto de regras com NR regras.

Ou seja, além de medir a precisão de h como um todo, isto é, como um classificador tipo caixa preta, é possível avaliar separadamente cada uma das regras que constituem h.

Várias medidas de avaliação de regras tem sido propostas na literatura.

Neste trabalho, serão utilizadas medidas de avaliação de regras propostas por Lavrac, as quais podem ser divididas em três categorias distintas, Medidas genéricas de avaliação de regras.
Medidas relativas de avaliação de regras.

Medidas relativas de avaliação de regras com peso.

No Anexo A, encontra-se uma descrição das medidas pertencentes a cada uma dessas categorias.

O módulo de Combinação e Explicação descrito neste trabalho usa somente as medidas genéricas de avaliação de regras, as quais estão descritas sucintamente, bem como o nome pelo qual cada uma dessas medidas é referenciada nos procedimentos do MCE.

Medidas genéricas de Avaliação de Regras.

Uma das áreas ativas em aprendizado de máquina supervisionado estuda métodos de construção de ensembles de classificadores.

Um ensemble é um conjunto de classificadores cujas decisões individuais são combinadas de alguma forma para classificar um novo caso.

Um resultado interessante é que ensembles de classificadores podem ser mais precisos que os classificadores individuais que compõem o ensemble.

Uma condição para que um ensemble de classificadores seja mais preciso que seus componentes é que os classificadores que compõem o ensemble sejam distintos.

Um classificador preciso é um classificador que faz a predição da classe de um novo exemplo x com uma margem de erro menor do que simplesmente adivinhar o valor de y dado x.

Dois classificadores são distintos se cometem erros diferentes em novos conjuntos de exemplos.

Para melhor compreender essa condição, considera-se um ensemble de três classificadores h,h,h e um novo caso (ou exemplo) x.

Esse novo exemplo x sera classificado por cada classificador h,h e h com uma das classes do conjunto discreto de classes.

Seja h (x) a classificação atribuída a esse novo exemplo x pelo classificador h, h (x) pelo classificador h e h (x) pelo classificador h.

Se os três classificadores são identicos então, quando h (x) esta errado, h (x) e h (x) tambem estão.

Entretanto, se os erros cometidos pelos classificadores forem não correlacionados, então quando h (x) está errado, h (x) e h (x) podem estar corretos, de forma que o voto majoritário pode classificar corretamente o exemplo x.

Em geral, dado um ensemble composto por L classificadores h,h, para cada novo exemplo x a ser classificado por esses classificadores, tem-se uma série de L ensaios.

Considerando que cada um desses ensaios é independente e que cada ensaio é um sucesso na classificação de x com probabilidade p ou uma falha com probabilidade 1 p, então a probabilidade do número de sucessos ser l em L ensaios e dada por 1 E considerado que essa probabilidade e a taxa de erro do ensaio, ou seja, da hipótese h.

Mais precisamente, se as taxas de erro de L classificadores h,h são todas iguais a p < 1 e se os erros são independentes, então a probabilidade do voto majoritário estar errado, ou seja, a probabilidade do ensemble ter mais de 50% de classificadores que falharam.

Dada por que corresponde a area sob o grafico da distribuição binomial na qual mais que L, são mostrados ensembles ideais formados com hipóteses independentes, todas com taxas de erro de 03, 0e 045 respectivamente.

Pode ser observado que quanto maior o valor da taxa de erro das hipóteses, maior é a taxa de erro do ensemble, mas ainda assim a taxa de erro do ensemble é menor que a taxa de erro de cada hipótese que o compõe.

Por exemplo, para um ensemble simulado com 21 hipóteses, cada uma delas possuindo uma taxa de erro de 03, a area de curva para 11 ou mais hipóteses simultaneamente incorretas e 0026, o qual é muito menor que a taxa de erro das hipóteses individuais.

Observa-se também que quanto maior o número de hipóteses, menor é a taxa de erro do ensemble.

Por outro lado, se as hipóteses individuais tem erros não correlacionados mas com taxas de erro excedendo 05, então a taxa de erro do ensemble aumentara como resultado da votação.

Mostra a curva do erro de um ensemble ideal composto por hipóteses independentes, todas com taxa de erro de 07.

Pode ser observado que incrementando o número de hipóteses, maior e o erro cometido pelo ensemble.

Para concluir, considerando a probabilidade do voto majoritário estar errado no modelo ideal de ensembles, a chave para o sucesso dos métodos de criação de ensembles está em construir classificadores individuais com taxas de erro abaixo de 05.

Uma observação e que as simulações mostradas tratam situações ideais, nas quais todas as hipóteses que compõem o ensemble são ensaios independentes, ou seja, não correlacionados.

Em aprendizado de máquina, o que se tenta fazer e tornar os ensaios (as hipóteses) não correlacionados, ou, se a correlação existir-e, na prática, geralmente essa correlação existe-, torna-la mínima.

Os ensembles são construídos para tentar melhorar o poder de predição dos algoritmos de AM.

Mas quais as razões que levam a construir bons ensembles?

Uma ilustração dessas razões pode ser vista, as quais são fundamentalmente três, Estatística.

Um algoritmo de aprendizado pode ser visto como um algoritmo de busca no espaço de hipóteses H para identificar a melhor hipótese.

O problema estatístico aparece quando a quantidade de dados disponíveis para treinamento é muito pequena comparada ao tamanho do espaço de hipóteses.

Sem dados suficientes, o algoritmo de aprendizado pode encontrar muitas hipóteses diferentes em H, as quais tem a mesma precisão sobre os dados de treinamento.

Construindo um ensemble com todos estes classificadores, o algoritmo pode calcular a média de seus votos e reduzir o risco de escolher o classificador errado.

A curva externa denota o espaço de hipóteses H e a interna denota o conjunto de hipóteses que tem uma boa precisão sobre o conjunto de treinamento.

O ponto rotulado com a letra f e a hipótese verdadeira, onde pode-se observar que tirando a média da precisão das hipóteses, podemos encontrar uma boa aproximação de f.

Computacional.

Muitos algoritmos de aprendizado trabalham fazendo alguma busca local a qual pode parar em algum ótimo local, por exemplo, alguns algoritmos de redes neurais e algoritmos de árvores de decisão.

Alguns algoritmos de redes neurais utilizam métodos de busca local-como gradiente descendente-para encontrar pesos localmente ótimos para a rede.

Algoritmos de árvore de decisão aplicam regras gulosas de particionamento para induzir as árvores.

Nos casos nos quais ha quantidade suficiente de dados de treinamento, o que indica que não ha problema estatístico, e computacionalmente difícil para o algoritmo de aprendizado encontrar a melhor hipótese.

De fato, o problema de encontrar a menor árvore de decisão que seja consistente com um conjunto de treinamento e NP-hard.

Similarmente, encontrar os pesos para a menor rede neural possível consistente com os exemplos de treinamento e tambem NP-hard.

Por outro lado, construindo um ensemble executando varias vezes o algoritmo de busca local partindo, a cada iteração, de diferentes pontos, pode-se obter uma melhor aproximação da verdadeira, e desconhecida função f que seja mais precisa que qualquer um dos classificadores individuais.

Representacional.

Às vezes, não é possível representar a verdadeira função f pelas hipóteses em H.

Entretanto, simplesmente unindo as hipóteses ou dando pesos a cada uma delas e unindo-as posteriormente, pode ser possível expandir o espaço das funções representáveis.

Muitos métodos de construção de ensembles tem sido desenvolvidos.

Esses métodos podem ser dividos, basicamente, em cinco métodos de propósitos gerais, os quais são, enumerando o espaço de hipóteses H, manipulando os exemplos de treinamento S, manipulando o conjunto de atributos X, manipulando o conjunto de classes C, ou inserindo aleatoriedade nos algoritmos de Aprendizado de máquina.

Neste capítulo, são descritos cada um desses métodos, que podem ser aplicados a diferentes algoritmos de Aprendizado de máquina em problemas de classificação.

Na notação probabilística Bayesiana, é considerado que cada hipótese h H define uma distribuição de probabilidade condicional, Dado um novo exemplo x e uma amostra de treinamento S, o problema de predizer o valor de f(x) pode ser visto como o problema de computar.

A Equação 2pode ser reescrita como a soma com peso sobre todas as hipóteses h em H, Pode-se enxergar esta equação como sendo um método de construção de ensemble, o ensemble consiste de todas as hipóteses h H, sendo que cada uma delas possui um peso-sua probabilidade posterior.

Pelo teorema de Bayes, a probabilidade posterior é proporcional a probabilidade dos dados de treinamento dada a hipótese anterior e sua probabilidade. Em alguns problemas de aprendizado, é possível enumerar completamente cada hipótese h H, computando os valores, e (após a normalização), avaliar o ensemble (ou comitê) Bayesiano.

O esquema de votação Bayesiano considera primeiramente a componente estatística dos ensembles.

Quando o conjunto dos exemplos de treinamento é pequeno, muitas hipóteses h H terão um valor significativamente alto de probabilidade posterior P(h|S) e o processo de votação pode, na media, aproximar essas hipóteses da função f.

Quando o conjunto de treinamento é grande, é típico que somente uma hipótese tenha probabilidade posterior substancial, e o ensemble efetivamente tende a conter somente uma hipótese h.

Em problemas complexos onde o conjunto de hipóteses H não pode ser enumerado, ha a possibilidade de aproximar a votação Bayesiana retirando uma amostra randomica de hipóteses.

Alguns trabalhos em métodos de cadeias de Markov Monte Carlo visam desenvolver um conjunto de ferramentas para resolver este problema.

O aspecto mais idealizado da análise Bayesiana é a confiança anterior P(h).

Se essa confiança captura completamente todo o conhecimento que se tem sobre f antes de obter S, então, pela definição, não se pode fazer melhor do que foi feito-o ótimo do algoritmo foi alcançado.

Mas, na prática, é muitas vezes difícil construir um espaço H de hipóteses e atribuir a probabilidade P(h) que captura adequadamente nosso conhecimento prévio.

De fato, muitas vezes H e P(h) são escolhidos levando-se em conta somente a conveniencia computacional, ainda que essas escolhas são reconhecidamente inadequadas.

Nesses casos, o comitê Bayesiano não e ótimo, e outros métodos de construção de ensembles podem produzir melhores resultados.

Deve ser ressaltado que o paradigma Bayesiano não trata dos problemas computacionais e representacionais de um modo significante.

O segundo método de construção de ensembles se dá manipulando os exemplos de treinamento para induzir hipóteses.

Neste caso, executa-se o algoritmo de aprendizado várias vezes, cada vez com um subconjunto de treinamento diferente.

Esta técnica trabalha especialmente bem quando se utilizam algoritmos de aprendizado instáveis.

Algoritmos instáveis são aqueles que induzem classificadores bastante diferentes mesmo ocorrendo pequenas alterações no conjunto de treinamento, ou seja, não é necessario que grandes alterações ocorram no conjunto de treinamento para que classificadores diferentes sejam induzidos.

Algoritmos de aprendizado de árvores de decisão, de redes neurais e de regras são instáveis, enquanto que algoritmos de regressão linear, vizinho mais próximo (nearest neighbor) e linear threshold são geralmente bastante estáveis.

As principais técnicas que manipulam o conjunto de treinamento para a construção de um ensemble podem ser divididos em duas famílias, Família P &C técnicasP&C-Perturb and Combine (Perturbar e Combinar)-"perturbam" o conjunto de treinamento ou o método de construção da hipótese para induzir diferentes hipóteses as quais são combinadas para gerar o ensemble.

Técnicas pertencentes a esta família são Bagging, Wagging e Cross-validated Committees.

Família ARC ARC-Adaptively Resample and Combine (Reamostrar e Combinar Adaptativamente)-refere-se a família de algoritmos que combinam e refazem a amostra de exemplos de treinamento adaptativamente.

Técnicas pertencentes a esta família são Boosting, Arcing e Windowing.

Durante o desenvolvimento deste trabalho, foram feitos alguns experimentos com a técnica de Boosting, para uma melhor compreensão dessa técnica.

O terceiro método para gerar multiplos classificadores e manipulando o conjunto de atributos disponíveis para o algoritmo de aprendizado.

A seguir são descritas sucintamente duas técnicas que manipulam os atributos do conjunto de treinamento.

Dividindo Aleatoriamente o Conjunto de Atributos.

Esta técnica consiste em dividir aleatoriamente o conjunto de atributos em diferentes subconjuntos de atributos e, para cada subconjunto de atributos, construir uma hipótese diferente.

Os exemplos considerados são os mesmos para cada hipótese.

Esta técnica trabalha muito bem quando o conjunto de atributos é altamente redundante.

Seleção de Atributos Utilizando Algoritmos genéticos.

O algoritmo GEFS-Genetic Ensemble Feature Selection-criado por Opitz utiliza algoritmos genéticos para induzir um conjunto preciso e diverso de classificadores.

Inicialmente o algoritmo cria uma população de classificadores, cada um deles rotulado com um valor inteiro.

Esta população inicial e criada com um subconjunto de atributos.

Para cada classificador o tamanho de cada subconjunto de atributos é independentemente escolhido de uma distribuição uniforme.

Esses subconjuntos F são replicações bootstrap do conjunto inicial F.

Cada atributo tem sua codificação genética e, assim, os melhores atributos sobrevivem.

O quarto método para construir um bom ensemble de classificadores é manipulando os valores do atributo classe dado ao algoritmo de aprendizado.

É descrita uma técnica chamada correção de erro do valor de saída, Error Correct Output Coding-ECO.

Considerando que o número de classes NCl e muito grande, então novos problemas de aprendizado podem ser construídos particionando-se randomicamente o conjunto de classes em dois subconjuntos A e B.

Os dados de entrada podem ser então rotulados como pertencentes ao subconjunto A (sua classe e 0 (zero)) ou ao subconjunto B (sua classe e 1 (um)).

Este conjunto com um novo valor de classe é dado ao algoritmo de aprendizado o qual cria uma hipótese h.

Repetindo esse processo L vezes (induzindo diferentes conjuntos A e B), obtem-se um conjunto de L hipóteses.

Agora, dado um novo exemplo x, ele deve ser classificado por cada hipótese h.

Então todas as classes pertencentes ao subconjunto A recebem um voto, caso contrário, todas as classes pertencentes ao subconjunto B recebem um voto.

Ao final, x é rotulado com a classe que tem o maior número de votos.

Para problemas com mais de duas classes, ECOC pode construir bons ensembles.

Todavia, devido ao ECOC encontrar dificuldades em problemas de classificação com somente duas classes, é importante que o conjunto de treinamento seja bastante expressivo para este algoritmo.

Este é o ultimo método de propósito geral para gerar ensembles de classificadores-inserindo aleatoriedade nos algoritmos de AM.

Por exemplo, ha dois algoritmos de AM onde se pode inserir aleatoriedade, o de backpropagation, que induz uma função matemática que representa uma rede neural, e o C45, que induz árvores de decisão.

No algoritmo de backpropagation, para gerar uma rede neural, são atribuídos pesos iniciais aleatórios.

Se o algoritmo é aplicado ao mesmo conjunto de treinamento mas com pesos iniciais diferentes, podem ser induzidas hipóteses bastante diferentes.

Com estas diferentes hipóteses, pode-se gerar um ensemble de redes neurais da forma mais simples possível.

Apesar desta técnica ser a mais simples, manipulando o conjunto de treinamento pode-se gerar bons resultados.

No algoritmo C45, quando se faz a seleção dos possíveis atributos para gerar os nós da árvore, seleciona-se aleatoriamente o melhor dentre os m melhores atributos.

São induzidas, assim, L hipóteses diferentes, as quais são combinadas para gerar um ensemble de classificadores.

Esta técnica é denominada Randomization.

Dado um conjunto (ensemble) de classificadores, muitos métodos tem sido explorados para se combinar as decisões individuais de cada um dos classificadores que constituem o ensemble.

Para problemas de classificação, esses métodos podem ser divididos em Votação sem Peso, Votação com Peso e Stacking.

Este é o método mais simples de combinação de classificadores.

Bagging, ECOC, e muitas outras técnica utilizam esse método de combinação.

Pode parecer que esquemas de votação mais inteligentes poderíam ser melhores, mas na verdade a experiência mostra que a votação sem peso é bastante robusta.

Um refinamento na simples votação pela maioria e apropriado quando cada classifidador pode produzir uma estimativa da probabilidade da classe ao invés de uma simples decisão de classificação.

Pode-se combinar a probabilidade da classe de todas as hipóteses e, assim, a probabilidade do ensemble será a classe predita de x e tomada como a classe que tem a maior probabilidade.

Muitos métodos diferentes de votação com peso têm sido desenvolvidos para ensembles, tanto para problemas de regressão quanto para problemas de classificação.

Para problemas de regressão, aplicam o método dos mínimos quadrados para encontrar pesos que maximizam a precisão do ensemble no conjunto de treinamento.

O peso aplicado a h deve ser inversamente proporcional a estimativa da variancia de h.

Entretanto, uma das dificuldades encontradas com o uso do método de mínimos quadrados e que as hipóteses podem ser altamente correlacionadas.

Assim, propõem-se alguns métodos para selecionar do conjunto de hipóteses um subconjunto com pouca correlação ao qual é aplicado o método dos mínimos quadrados para determinar os pesos desse subconjunto de hipótese que constituirá o ensemble.

Para problemas de classificação, os pesos são usualmente obtidos medindo a precisão de cada classificador individual h no conjunto de treinamento ou de teste, construindo pesos que são proporcionais a essas precisões.

Descreve-se um metodo, chamado likelihood combination, o qual aplica o algoritmo de Naive Bayes para aprender pesos dos classificadores.

No AdaBoost, o peso de cada classificador h é computado utilizando sua precisão no conjunto de treinamento com os pesos que foram usados para induzir h.

Este método requer a definição de uma probabilidade prévia a qual é multiplicada para estimar a probabilidade de cada h.

Este método combina diferentes hipóteses induzidas por diferentes algoritmos de AM da seguinte forma, Supondo um conjunto de algoritmos diferentes A,A e um conjunto de treinamento S conforme já descrito, aplica-se cada um destes algoritmos ao conjunto de treinamento S para induzir o conjunto de hipóteses.

A meta do método Stacking é encontrar uma boa combinação desse conjunto de hipóteses, denominada h.

O seguinte esquema foi proposto para aprender h usando uma forma de leave-one-out cross validation, Considere h como sendo a hipótese construída pelo algoritmo de aprendizado A utilizando como conjunto de treinamento todos os N exemplos de S com exceção do i-esimo exemplo x.

Ou seja, cada algoritmo é aplicado ao conjunto de treinamento N vezes, deixando de fora um exemplo de treinamento de cada vez.

Aplique cada classificador h ao exemplo x para obter a classe predita y.

Esse procedimento constrói um novo conjunto de dados contendo exemplos no "nível 2" cujos atributos são as classes preditas por cada um dos L classificadores.

Finalmente, aplica-se algum algoritmo de aprendizado a este novo conjunto de treinamento S para aprender h.

Aplicou-se este método combinando diferentes formas de regressões lineares e obteve-se bons resultados.

Neste capítulo, foram abordadas definições de AM supervisionado e de ensembles de classificadores, bem como as principais razões para construir ensembles.

Também, foram abordados os diferentes métodos de construção de ensembles e foram descritos métodos de combinação de classificadores que resolvem problemas de classificação, objeto de estudo deste trabalho.

Para problemas de regressão, existem outros métodos interessantes de combinação, tais como Funções de Ganho.

Os métodos de construção de ensembles e combinação de classificadores descritos são bons métodos quando se utiliza os classificadores como caixas-pretas.

A proposta deste trabalho é combinar classificadores simbólicos, utilizando um critério, medida de avaliação de regra para selecionar as regras que formam o classificador final, bem como para selecionar as regras do ensemble que melhor explicam a classificação de novos exemplos.

Portanto, ha a necessidade de se utilizar as regras dos classificadores individualmente, fazendo com que esses classificadores deixem de ser caixas-pretas.

Assim, os métodos descritos neste capítulo não serão utilizados.

Para testar essa ideia, ou seja, a ideia de construir um classificador simbólico, resultante da seleção das melhores regras de classificadores iniciais utilizando um critério de seleção de regras, foi implementado o sistema R S ule ystem, descrito no proximo capítulo.

Para testar as ideias de explicação de ensembles e combinação de classificadores simbólicos utilizando medidas de avaliação de regras, foi implementado um sistema na linguagem de programação logica Prolog, denominado R S ule ystem.

A seguir, é descrita a metodologia desenvolvida para documentar a arquitetura do R S ule ystem e o sistema propriamente dito.

Os dois módulos principais (MAR e MCE) consistem de um conjunto de procedimentos Prolog específicos de cada módulo.

O módulo Auxiliar, M contem procedimentos para ler arquivos especificados pelo usuário-arquivos que contém conjuntos de regras e o conjunto de exemplos na sintaxe padrão em Prolog-, bem como uma biblioteca de procedimentos Prolog auxiliares, os quais são compartilhados pelos procedimentos pertencentes ao MAR e ao MCE.

Deve ser observado que o usuário não tem acesso aos procedimentos auxiliares do MA.

A Base de Fatos (BF) é utilizada para armazenar os dados de entrada (um ou mais conjuntos de regras e um único conjunto de exemplos) bem como para armazenar informações adicionais, resultantes da execução de algum procedimento ativado pelo usuário.

É importante observar que o R S ule ysteme um sistema interativo, guiado pelas necessidades do usuário, ou seja, o usuário pode ativar os procedimentos principais de cada um dos três módulos.

A ostra os procedimentos principais (<nome do procedimento>/<aridade>) acessíveis ao usuário, implementados em cada módulo do R S ule ystem.

Para a maioria desses procedimentos, ha um conjunto de pré-condições que devem ser satisfeitas para sua correta execução.

Também, vários desses procedimentos apresentam um conjunto de pós-condições.

Com o objetivo de documentar o R S ule ystem, foi por nós desenvolvida uma metodologia específica, descrita a seguir.

Quando foi iniciada a implementação do R S ule ystem foram pesquisadas na literatura algumas metodologias que pudessem servir para documentar o sistema.

Entretanto, nenhuma das metodologias pesquisadas foi suficientemente adequada para atender as especificidades de representação de pré e pós condições de procedimentos em fluxo de execução.

Assim, foi decidido propor uma metodologia de representação na forma de um Diagrama de Fluxo de Execução de Procedimentos (PEFD-Procedures Execution Flow Diagram), para documentar o R S ule ystem.

Os componentes do PEFD são 3, Procedimentos, Condições e Fluxos de Execução.

Cada um desses componentes é descrito a seguir.

Um procedimento é representado por um retângulo identificado com o nome do procedimento.

O módulo ao qual pertence esse procedimento encontra-se no canto superior direito, dentro de um retângulo menor.

No caso do R S ule ystem, são os módulos-MA, MAR e MCE.

Representação do procedimento evaluateAllSetOfRulesFrequency/1 do módulo de Analise de Regras.

Quando não for permitido ao usuário disparar um procedimento, o retângulo que se refere a esse procedimento encontra-se preenchido com um tom de cinza claro.

Por exemplo, pode-se visualizar que os procedimentos listOfExamples/1 e dictionary/não são acessíveis ao usuário.

Exemplo de Representação de um Procedimento.

As pré-condições necessárias para a execução de um procedimento, armazenadas previamente na Base de Fatos, bem como as pós-condições de um procedimento, armazenadas na BF após a sua execução, são representadas por círculos identificados por letras, letras seguidas de números, ou números.

Letra nomeia um conjunto de condições, <letra><numeros> nomeia a condição <numeros> que pertence ao conjunto de condições nomeado <letra>, e <número> nomeia uma única condição que não pertence a nenhum conjunto de condições.

Uma descrição dos fatos relacionados a cada condição que pertence ao conjunto de condições E é encontrada.

Analogamente, uma descrição dos fatos relacionados a cada condição que pertence ao conjunto de condições R é encontrada.

Quando é necessário representar um subconjunto de um conjunto de condições, esse subconjunto e identificado pelas varias condições que o compõem, separadas por vírgula.

Um exemplo pode ser visualizado, onde é ilustrado o subconjunto.

Foram também definidos os seguintes dois símbolos de representação do estado de uma condição, na Base de Fatos, em um dado instante, para indicar uma pré-condição atualizada pelo procedimento.

Isto é, a pré-condição aparece também como pós-condição do procedimento, mas com diferentes informações.

Por exemplo a pré-condição R7 será atualizada para a pós-condição R7* após a execução do procedimento indica a eliminação ou inexistencia da condição na Base de Fatos.

Um exemplo é a inexistencia ou eliminação do conjunto de condições R que aparece ao lado do procedimento.

Nesse caso, o conjunto de condições R não existe no estado inicial da base ou foi excluído após a execução de abolishRules/0.

O mesmo vale para as condições e 5.

Além disso, pos-condições de alguns procedimentos podem ser pre-condições para outros procedimentos.

Assim, a execução desses procedimentos deve obedecer um fluxo temporal, detalhado a seguir.

Fluxo de Execução.

O fluxo temporal é representado através de linhas de tempo as quais são somente aplicáveis a procedimentos representados dentro de um retângulo tracejado.

Procedimentos fora desse retângulo tracejado são atemporais, ou seja, podem ser executados a qualquer momento.

No caso do R S ule ystem, foram identificadas cinco linhas de tempo. Pode ser observado que os procedimentos abolishRules/0 e abolishExamples/0 encontram-se fora do retangulo tracejado, o que indica que eles podem ser executados a qualquer momento.

Em outras palavras, são procedimentos atemporais.

Considerando os procedimentos representados dentro do retângulo tracejado, pode-se observar que os procedimentos loadRules/0 e loadExamples/0 na linha t devem ser executados antes que os procedimentos verifyBase/0, listOfExamples/1 e dictionary/2, na linha t.

Analogamente, esses procedimentos na linha t devem ser executados antes que os procedimentos na linha t, e assim sucessivamente.

Outro aspecto a ser observado é que podem ocorrer relacionamentos entre um conjunto de condições e um procedimento, ou entre um conjunto de condições e um subconjunto desse conjunto de condições.

Esses relacionamentos são representados por meio de uma linha, contínua ou tracejada, denominada barramento.

Existem três tipos de barramento, contínuo ou fortemente conectado indica que, se uma pre-condição for apagada da Base de Fatos, todas as pos-condições oriundas de procedimentos relacionados com essa pré-condição devem também ser apagadas da BF.

Tracejado ou fracamente conectado indica que, se uma pre-condição for apagada da BF, as pos-condições oriundas de procedimentos relacionados com essa pre-condição não são apagadas da BF.

Duplo ou atemporal indica que, ao executar um procedimento relacionado com esse tipo de barramento, todas as condições relacionadas serão apagadas da BF indistintamente.

Quando se relaciona um conjunto de condições a um procedimento, pode-se ter a necessidade de especificar qual é o subconjunto de condições que realmente faz parte do conjunto de pré-condições do procedimento.

Para se detalhar esse tipo de informação, substitui-se o relacionamento entre o conjunto de condições e o procedimento por um relacionamento entre o conjunto de condições e o subconjunto de pré-condições.

Posiciona-se o círculo que representa esse subconjunto de pré-condições sobre o retângulo que representa o procedimento.

Por exemplo, o procedimento verifyBase/0 somente necessita da pré-condição R7 do conjunto de condições R e do subconjunto {E2, E3} de condições do conjunto de condições E.

Para um melhor entendimento do PEFD do R S ule ystem, aqui é apresentada uma descrição do fluxo de execução dos procedimentos principais implementados nesse sistema.

O estado inicial e caracterizado pela ausencia de todas as condições que podem estar presentes na BF, ou tambem, pela exclusão de todas essas condições.

Dessa forma, os procedimentos abolishRules/0 e abolishExamples/0 são responsáveis por excluir, respectivamente, as condições R, e 5 e E, 1, e 3.

A ausência ou a exclusão dessas condições é representada por meio do traço que corta o círculo contendo a identificação de cada condição.

Considerando que nenhuma condição está presente na Base de Fatos, o início do fluxo de execução do R Sule ystem dá-se no instante t, quando podem ser executados seguidamente, em qualquer ordem, os procedimentos loadRules/0 e loadExamples/0.

Por exemplo, na execução de loadRules/0 o conjunto de condições R é gravado na BF.

Esse conjunto de condições é fortemente conectado ao barramento atemporal e pode ser removido da BF somente pela execução do procedimento abolishRules/0.

Ao ser executado o procedimento loadExamples/0, o conjunto de condições E é gravado na BF.

Esse conjunto de condições também é fortemente conectado ao barramento atemporal e apenas a execução do procedimento tt abolishExamples/0 pode apagar esse conjunto de condições da BF.

Seguindo para o instante t, os procedimentos verifyBase/0, listOfExamples/1 e dictionary/podem ser executados seguidamente.

O procedimento verifyBase/0 tem como pré-condições subconjuntos de R e E aos quais encontram-se fortemente conectados.

Especificamente, a pré-condição R7 do conjunto de condições R e o subconjunto de condições Ee Edo conjunto de condições E.

A conexão forte indica que essas pré-condições específicas serão apagadas da BF se o conjunto R e E de condições for apagado da BF.

Ainda no instante t, os procedimentos listOfExamples/1 e dictionary/podem ser executados seguidamente em qualquer ordem.

Como pode ser observado, os retângulos que identificam esses procedimentos estão preenchidos com um tom de cinza claro, o que significa que não podem ser acessados pelo usuário.

Após serem executados, esses procedimentos gravam na BF, respectivamente, as condições 1 e 2.

Essas duas condições estão fortemente conectadas ao barramento atemporal, portanto elas podem ser apagadas somente através da execução do procedimento abolishExamples/0.

Partindo para o instante t, os procedimentos evaluateAllSetOfRulesFrequency/1, indAttSurp/1 e rco/podem ser executados em qualquer ordem.

O procedimento evaluateAllSetOfRulesFrequency/1 está fortemente conectado ao conjunto de condições R e fracamente conectado ao conjunto de condições E e as condições 1 e 2.

O procedimento indAttSurp/1 está fortemente conectado ao conjunto R e fracamente conectado ao conjunto E, e, por fim, rco/está fortemente conectado ao conjunto R e fracamente conectado as condições 1 e 2.

Por exemplo, o procedimento evaluateAllSetOfRulesFrequency/1 está fracamente conectado as pre-condições 1 e 2, fortemente conectado a condição R através do subconjunto de pre-condições R1, R4, R7 e fracamente conectado com a pre-condição E através da pre-condição E1.

Após sua execução, esse procedimento modifica a pre-condição R7 gravando a pos-condição R7 na BF.

Isso implica que, se 1, ou E forem apagadas da BF, a pos-condição R7 continua válida.

R7 so pode ser apagada pela execução do procedimento abolishRules/0.

O fluxo de execução do PEFD do R Sule ystem nos instantes t e t e semelhante ao descrito no instante t.

Em qualquer dos instantes os procedimentos atemporais abolishRules/0 e abolishExamples/0 podem ser executados.

Por exemplo, se abolishExamples/0 for executado no instante t, todas as condições presentes na BF até aquele instante e conectadas ao barramento atemporal serão excluídas, no caso, serão excluídas as condições E, 1 e 2.

Deve ser observado que os procedimentos atemporais abolishRules/0 e abolish-Examples/0 retornam a BF ao seu estado inicial, ou seja, as condições ligadas a esses procedimentos são apagadas da BF por meio do barramento fortemente conectado.

Neste capítulo, foi detalhada a documentação do R S ule ysteme a metodologia desenvolvida para essa documentação.

No proximo capítulo, são descritos os conversores de sintaxe, que tomam como dados de entrada conjuntos de regras e exemplos na sintaxe padrão PBM do projeto DISCOVER e convertem esses conjuntos, respectivamente, para conjuntos de regras e exemplos na sintaxe padrão em Prolog.

A sintaxe padrão em Prolog e a sintaxe padrão de conjuntos de regras e exemplos aceitos como dados de entrada do R S ule ystem.

Neste capítulo, é descrita a sintaxe padrão PBM do projeto DISCOVER e a forma como se dá a conversão da sintaxe padrão PBM para a sintaxe padrão na linguagem de programação lógica Prolog dos conjuntos de regras e exemplos a serem armazenados na Base de Fatos do R S ule ystem.

A conversão de regras e exemplos no formato padrão PBM para a sintaxe padrão de regras e exemplos na linguagem de programação lógica Prolog foi implementada através de scripts Perl.

Ilustra a interação desses scripts na conversão da sintaxe de diferentes conjuntos de regras e de exemplos, no formato padrão do DISCOVER (PBM), para a sintaxe padrão em Prolog.

A sintaxe padrão de exemplos proposta é uma extensão do formato dos arquivos de nomes e dados do C45 e utiliza arquivos do tipo texto para declarar os nomes dos atributos (e seus respectivos domínios) bem como os valores que esses atributos assumem no conjunto de exemplos.

Os nomes dos atributos são declarados em um arquivo de nomes.

Mostra a gramática que define a sintaxe do arquivo de nomes.

Os valores que esses atributos assumem no conjunto de exemplos são declarados no arquivo de dados, designados com a extensão data.

Um conjunto de exemplos somente está na sintaxe padrão se estiverem presentes os dois arquivos que devem possuir o mesmo nome, se diferenciando apenas pela extensão.

Os atributos declarados em um arquivo de nomes podem assumir qualquer um dos seguintes tipos de dados, Nominal, O tipo de dado nominal é utilizado para declarar um atributo discreto, ou seja que pode assumir um conjunto finito de valores.

Enumerated, O tipo de dado enumerated é muito semelhante ao tipo de dado nominal.

A principal diferença é que com o tipo enumerated é possível identificar uma ordem entre os valores que o atributo pode assumir.

Entretanto, não existe uma definição clara de distância entre esses valores.

Um exemplo de tipo enumerated é um atributo que pode assumir, por exemplo, os valores pequeno, médio e grande.

Integer, O tipo de dado integer e utilizado para declarar um atributo que pode assumir valores inteiros.

Real, O tipo de dado real é semelhante ao tipo de dado integer, com a diferença que um atributo real pode assumir números com ou sem parte fracionaria.

String, Um atributo string pode assumir como valor um string de tamanho indefinido o qual pode conter quaisquer caracteres incluindo quebra de linha (\n).

Para identificar os limites de um string e necessario inserir o símbolo de aspas (") antes e depois do string.

Date, O tipo de dado date permite declarar um atributo que pode conter uma data (dia, mes e ano).

A princípio, os valores das datas devem estar no formato "aaaa/mm/dd" (formato utilizado pela maioria dos sistemas de gerenciamento de bancos de dados).

Time, O tipo de dado time permite declarar um atributo que pode conter um horário(hora, minuto e segundo).

A princípio, os valores dos horários devem estar no formato "hh,mm,ss".

A primeira declaração em um arquivo de nomes define qual deve ser o nome do atributo classe.

O atributo classe pode ser qualquer atributo presente no conjunto de exemplos.

Após a declaração do atributo classe, são declarados os demais atributos.

O arquivo de dados correspondente a um arquivo de nomes contem n exemplos, um exemplo em cada linha.

Cada exemplo i consiste nos valores dos atributos desse exemplo, separados por vírgula, que devem pertencer ao domínio correspondente aos atributos especificados no arquivo de nomes.

Valores "desconhecidos" são representados por um ponto de interrogação e valores "não-se-aplica" são representados com um ponto de exclamação.

No intuito de unificar a linguagem de representação do conhecimento induzido (classificador) por diferentes algoritmos de AM simbólico, foi proposto em o formato padrão de regras PBM, do projeto DISCOVER.

Um classificador simbólico é qualquer classificador que possa ser transformado num conjunto de regras.

Para realizar essa transformação, foi implementada uma biblioteca composta por uma série de scripts Perl.

Logo após, derivadas de uma tabela de contingência, foi definido um conjunto mínimo de informações que permitem calcular medidas de avaliação de regras.

Esse conjunto de informações é obtido através da avaliação de cada uma das regras do conjunto de regras que constituem o classificador, no formato padrão de regras PBM, utilizando um conjunto de exemplos fornecido pelo usuário.

Como uma extensão do formato PBM,após serem calculadas, essas informações são adicionadas ao final de cada uma das regras.

Usando a notação de regra Body Head ou resumidamente B H, o formato padrão proposto para as informações adicionais é o seguinte, onde n e o número total de exemplos e f representa a frequência relativa de, hb número de exemplos para os quais B é verdade e H é verdade.

Bh número de exemplos para os quais B e verdade e H e falso.

Bh número de exemplos para os quais B e falso e H e falso.

Bh número de exemplos para os quais B e falso e H e verdade.

O formato PBM estendido é definido pela gramática.

Esse formato padrão de regras contem as frequências relativas, além do número de exemplos, utilizado no cálculo das métricas de avaliação de regras.

Deve ser observado que tanto valores conhecidos como valores desconhecidos nos exemplos são considerados no cálculo dessas métricas.

Valores absolutos das medidas também podem ser facilmente obtidos multiplicando as frequências relativas por n.

Partindo da sintaxe padrão PBM do projeto DISCOVER, a conversão de um conjunto de exemplos nessa sintaxe padrão para a sintaxe padrão em Prolog é feita através de um script Perl.

Por sua vez, esse script utiliza uma biblioteca que implementa um grupo de subrotinas de manipulação de conjuntos de dados na sintaxe padrão.

Apresenta a gramática que define a sintaxe padrão em Prolog para um conjunto de exemplos.

Como visto anteriormente, um conjunto específico de exemplos na sintaxe padrão está definido através das informações contidas nos arquivos data e names.

Assim, o predicado ex/é utilizado para representar em Prolog cada um dos exemplos contidos no arquivo data.

Os dois argumentos do predicado ex/são, <arg-1> posição (ou numero) do exemplo no arquivo data, começando a partir de 0 (zero) <arg-2> lista com os valores que cada atributo pode assumir.

A ordem desses valores na lista está dada pela ordem em que os atributos estão declarados no arquivo names.

Os predicados feature/e classFeature/1 são utilizados para representar em Prolog as informações sobre os atributos contidos no arquivo.

Os dois tipos básicos na sintaxe padrão em Prolog, numeric e nominal.

O tipo de dados numeric abrange os tipos de dados inteiro e real da sintaxe padrão.

O tipo de dados nominal abrange os tipo de dados nominal e enumerated da sintaxe padrão.

Os tipos date e time da sintaxe padrão de exemplos não são suportados na sintaxe padrão em Prolog.

Desta forma, o conversor entre as duas sintaxes é responsável por converter os atributos previamente dos tipos date e time em atributos do tipo numeric.

O argumento do predicado classFeature/1 é simplesmente o nome da feature que corresponde a classe.

A sintaxe padrão em Prolog de regras por nós proposta é definida pela gramática.

Foi implementado um script Perl, denominado Conversor de Regras, que aceita como dado de entrada um arquivo contendo regras de classificação no formato PBM estendido e o converte para um arquivo de regras na sintaxe padrão em Prolog.

No R S ule ystem, diversos conjuntos de regras podem ser armazenados na Base de Fatos simultaneamente, conforme dito anteriormente.

Assim, é necessário identificar cada um desses conjuntos que provém de diferentes experiências.

Isso é realizado de forma automática pelo Conversor de Regras através do identificador utilizado como primeiro argumento nas cláusulas unitárias Prolog inducer/2, inputFile/2, dAte/3, evaluatedAs/3, namesFile/2, dataFile/e rule/6.

O valor de X é gerado como o valor da seguinte função hash. Os valores de <day>, <year>, <hour>, <minute> e <second> são retirados da terceira linha do arquivo no formato PBM estendido que formam as informações que identificam quando foi realizada essa experiência.

Já os valores de <valor week day> e <valor_month> são primeiramente mapeados em números inteiros a partir dos valores dos símbolos terminais <month> e <week_day>, também retirados da terceira linha do arquivo no formato PBM estendido, para finalmente calcular o valor de X.

As informações contidas em cada um dos predicados produzidos pelo símbolo não-terminal <header> são listadas a seguir, Conforme mencionado anteriormente, além do formato PBM estendido, o Conversor de Regras também suporta regras no formato PBM, neste caso, <arg-5> e <arg-6> são sempre listas vazias na sintaxe padrão em Prolog.

Foram descritos os conversores de sintaxe, que convertem conjuntos de regras e exemplos da sintaxe padrão PBM do projeto DISCOVER para a sintaxe padrão em Prolog do R S ule ystem.

Regra default é uma regra especial que possui o Corpo vazio e sua Cabeça é definida pela classe que possui a maior quantidade de exemplos no conjunto de exemplos de treinamento.

Deve ser lembrado que todo classificador escrito no formato de regras if-then possui uma regra default, essa regra só é disparada quando nenhuma outra regra do classificador cobre o exemplo a ser classificado.

Módulo de Combinação e Explicação.

Um dos módulos principais do R System, o MCE, por nós implementado, responsável por.

Construir, dado um conjunto de classificadores simbólicos, um outro classificador simbólico que contenha regras desse conjunto de classificadores que sejam as "melhores" segundo as diversas medidas de qualidade de regras implementadas no módulo de Análise de Regras.

Fornecer ao usuário, dado um conjunto de classificadores simbólicos e um exemplo do domínio dos classificadores, quais as regras que foram disparadas nesses classificadores e qual a "melhor" regra, segundo, também, alguma das diversas medidas de avaliação de regras implementadas no MAR.

Em outras palavras, fornecer ao usuário uma explicação da classificação.

Para realizar as tarefas de responsabilidade do MCE, neste módulo estão implementados cinco procedimentos principais relacionados com, Classificação de Exemplos-classifyExample/4.

Determinação da Matriz de Confusão-confusionMatrix/2.

Explicação de Ensembles-classifyExampleByEnsemble/6.

Combinação de Classificadores simbólicos-rco/e kFoldCrossValidation/4.

A instanciação de cada um dos i argumentos de um procedimento de aridade i é descrita utilizando a notação padrão para documentar programas Prolog, ou seja, Dada uma hipótese h e um exemplo x, o procedimento classifyExample/e responsavel pela classificação desse exemplo segundo a hipótese h.

A forma de avaliação é determinada pelo algoritmo de aprendizado de máquina que induziu h.

Assim, após determinada a forma de avaliação, através do <arg-1>, classifyExample/ativa o procedimento responsável pela avaliação correspondente.

No caso de avaliação ordered, existe um else implícito entre as regras induzidas pelo algoritmo de AM.

Assim, a avaliação ordered é muito simples, o conjunto de regras da hipótese h deve ser varrido até encontrar a primeira regra R cujo Corpo cobre o exemplo x.

O Algoritmo 1 descreve a forma de avaliação ordered.

O Algoritmo descreve a forma de avaliação unordered por nós realizada.

Ele varre todas as regras da hipótese h e inclui no conjunto Rules as regras R cujo Corpo não vazio cobre o exemplo x, ou seja, não é considerada a regra default.

Para encontrar a classificação do exemplo, na implementação por nós realizada, consideramos que a regra do conjunto Rules com maior cobertura define a classe do exemplo x.

No caso do conjunto Rules ser o conjunto vazio, então o exemplo e classificado pela regra default.

Na realidade, a instanciação dos argumentos dos procedimentos aqui descrita refere-se a instanciação na execução padrão realizada por um usuário do sistema.

Entretanto, para o implementador do sistema, a instanciação do tipo + pode, as vezes, ser substituída por uma instanciação do tipo, e a do tipo pode sempre ser substituída por uma instanciação do tipo ?

Esta característica de Prolog permite verificar resultados específicos além de auxiliar ao implementador a realizar rapidamente a depuração dos procedimentos.

Observar que qualquer que seja a forma de avaliação, sempre existirá uma classificação para o exemplo x devido a existência da regra default. Como mencionado anteriormente, a regra default de uma hipótese somente é disparada quando nenhuma outra regra da hipótese cobre o exemplo a ser classificado.

É uma regra especial cujo Corpo é vazio e sua Cabeça é definida geralmente pela classe com maior frequência no conjunto de exemplos utilizado para a construção dessa hipótese.

Deve ser observado que esta não é a forma de avaliação de regras unordered utilizada pelo algoritmo CN2, por exemplo.

Entretanto, os resultados esperados são similares para a maioria dos conjuntos de dados naturais e do mundo real.

Finalmente, será tratada a forma de avaliação interclass.

Quando a avaliação de regras de uma hipótese é interclass, a avaliação é do tipo ordered entre as classes, mas a avaliação do conjunto de regras que prediz a mesma classe é unordered.

É importante observar que existe um else implícito entre cada um desses subconjuntos de regras e que esses subconjuntos de regras são formados conforme a ordem em que o algoritmo de AM induz as classes que compõem a hipótese h.

Como cada elemento de h é uma hipótese (conjunto de regras) com regras que predizem a mesma classe e avaliadas de forma unordered, cada um desses elementos deve ser fornecido ao algoritmo de avaliação unordered.

O processo pára assim que o algoritmo encontrar um conjunto de regras Rules não vazio para algum elemento.

Caso contrário, se todo o conjunto h for varrido e nenhum elemento de h satisfizer a condição Rules, o exemplo x é classificado segundo a regra default de h.

É importante observar que todas as formas de avaliação retornam a classificação do exemplo x e o conjunto de regras Rules com todas as regras de h que cobrem o exemplo x.

Dado um conjunto de hipóteses, um exemplo a ser classificado x é uma opção Measure, o procedimento classifyExampleByEnsemble/6 é responsavel por decidir a classificação de x dadas as classificações feitas.

Se Measure não estiver instanciado, o procedimento classifica x com votação por maioria sem fornecer uma explicação para essa classificação.

Se Measure for instanciado com uma das medidas de avaliação de regras descritas então, dentre as regras do conjunto de hipóteses H que cobrem x, a regra que tiver a melhor medida é utilizada para classificar H.

Além disso, o procedimento retorna todas as regras em H que cobrem x tanto se Measure estiver instanciado ou se estiver desinstanciado.

Os seis argumentos do procedimento classifyExampleByEnsemble/6 são,O Algoritmo descreve como a decisão de classificação do exemplo x e tomada.

Primeiro o algoritmo executa o procedimento classifyExample/para x e cada h.

Depois, se Measure estiver desinstanciado, considera a classe com maior quantidade de votos como sendo a classificação de x, ou seja, faz votação por maioria para decidir a classificação de x.

Caso contrário, toma, dentre as regras disparadas nas hipóteses a regra Rule com maior medida Measure.

A classificação de x é dada pela Cabeça de Rule.

Em ambos os casos, o algoritmo retorna a classificação de x e todas as regras que cobrem x.

O Algoritmo 5 mostra como essa nova hipótese é construída.

O algoritmo faz inicialmente uma cópia das regras de todas as hipóteses e cria o cabeçalho da hipótese a ser construída.

Nesse cabeçalho, constam os fatos relacionados as condições R1 ate R6, descritas.

Depois do cabeçalho criado, o algoritmo segue os seguintes passos, Ao sair da iteração, segundo qualquer dos dois critérios de parada, o algoritmo constrói a regra default.

A regra default possui Corpo vazio e sua Cabeça é definida pela classe com maior distribuição nos exemplos do conjunto de exemplos inicial.

Deve ser observado que, além da hipótese construída, o usuário pode visualizar as regras do conjunto de hipóteses que não foram utilizadas pelo algoritmo para construir a nova hipótese.

Após, o conjunto de hipóteses original é recuperado.

O algoritmo RCO (Rule Combination) pode ser visualizado, onde se pode observar que os dados de entrada para o algoritmo RCO consistem de L classificadores e um conjunto de exemplos de treinamento.

Com esses dados de entrada, uma nova hipótese é construída e, com um conjunto de teste, pode-se medir a precisão e/ou erro dessa hipótese.

Deve ser observado que, para que o algoritmo funcione corretamente, o conjunto de dados de treinamento de ser diferente dos conjuntos de dados de 1 a L e, para que a medida de precisão ou erro do classificador não seja otimista, o conjunto de dados de teste deve ser independente do conjunto de dados de treinamento e do conjunto de dados de 1 a L.

No entanto, se o número de exemplos for pequeno, a independência entre os conjuntos de dados pode não ser possível.

Avaliar hipóteses induzidas ou construídas por algoritmos de AM é fundamental.

Para medir a precisão/erro de hipóteses construídas pelo RCO, é utilizada a técnica de estimativa k-fold cross validation, a qual é implementada no procedimento kFoldCrossValidation/4.

Esse procedimento e descrito a seguir.

Dado um conjunto de hipóteses, um conjunto de treinamento, um númerod e partições K e uma medida de avaliação de regras Measure, o procedimento kFoldCrossValidation/é responsável por estimar o erro e e o desvio padrão SD da hipótese construída pelo algoritmo rco/4, utilizando a estimativa k-fold cross validation.

Os quatro argumentos do procedimento kFoldCrossValidation/são, Neste capítulo, foram descritos os procedimentos principais do módulo de Combinação e Explicação do R S ule ysteme os algoritmos implementados.

Dentre esses algoritmos, destaca-se o RCO, responsável pela geração de um novo classificador através da combinação de classificadores induzidos por algoritmos de AM simbólicos.

No próximo capítulo, é mostrado um exemplo de utilização do módulo de Combinação e Explicação, utilizando um conjunto de dados artificiais.

Um Exemplo de Aplicação do MCE.

Para melhor ilustrar os procedimentos do módulo de Combinação e Explicação, neste capítulo são descritos alguns experimentos realizados sobre um conjunto de exemplos artificial, ou seja, um conjunto de exemplos gerados a partir de uma função verdadeira f.

Deve ser ressaltado que os resultados desses experimentos permitiram melhorar o critério de seleção de regras inicialmente implementado no RCO.

Esses experimentos encontram-se descritos com maiores detalhes.

O conjunto de exemplos utilizado corresponde a função verdadeira f, ou hipótese verdadeira, definida por para att 1,att R.

Os retângulos contornados por uma linha tracejada correspondem a classe o, e os retângulos contornados por uma linha contínua correspondem a classe x.

Essa função verdadeira f foi gerada pensando nas regiões retangulares formadas pelas regras induzidas sobre um domínio com dois atributos e uma classe, as quais pode ser facilmente visualizaveis no espaço bidimensional.

Dada a verdadeira função f, infinitos conjuntos de exemplos podem ser gerados.

Para realizar os experimentos aqui apresentados, foram gerados 8 conjuntos de exemplos diferentes.

Cada um desses conjuntos possui 120 exemplos, gerados aleatoriamente, onde o número de exemplos em cada classe é balanceado, ou seja, 50% dos exemplos pertencem a classe o e 50% dos exemplos pertencem a classe x.

Os sete primeiros conjuntos foram utilizados para induzir 7 (sete) hipóteses, denominadas com dois algoritmos de aprendizado de máquina, o CNe o See5.

O CNinduz hipóteses com regras não-ordenadas e ordenadas, unordered e ordere, e o See5 induz árvores de decisão e regras não-ordenadas.

As sete hipóteses foram induzidas como regras não-ordenadas.

Para ilustrar a forma como as hipóteses induzidas se comportam em relação a verdadeira função f, foram gerados graficos da seguinte forma.
Cada regra é representada por uma região retangular preenchida com um tom de cinza.

As regras que classificam um exemplo como sendo da classe o são plotadas como retângulos preenchidos com cinza claro, as regras que classificam um exemplo como sendo da classe x são plotadas como retângulos preenchidos com cinza escuro.

Uma hipótese h composta por NR regras tem suas regras plotadas em ordem inversa, ou seja, a primeira regra a ser plotada é a regra R (regra default), e a última regra a NR ser plotada e a regra R, havendo, assim, uma sobreposição de retângulos e, portanto, 1 das regras.

Deve ser observado que essa forma de representação facilita a visualização de como as hipóteses cobrem os exemplos do domínio.

Assim, a forma como as hipóteses induzidas pelo se comportam em relação a função verdadeira f pode ser vista, a forma como as hipóteses induzidas se comportam em relação a função verdadeira f pode ser vista.

Utilizando as hipóteses induzidas e o conjunto de exemplos S, foram realizados 3(três) experimentos diferentes para combinação de regras utilizando o procedimento que implementa o algoritmo RCO.

Em cada experimento, foram construídos 6(seis) classificadores diferentes, cada um utilizando um critério, medida de avaliação de regra.

São vários os objetivos desses experimentos, dentre eles.

Verificar qual o erro aparente das hipóteses construídas pelo RCO e o número de exemplos não cobertos por essas hipóteses, ou seja, exemplos que são somente cobertos pela regra default.

Verificar o erro dessas hipóteses em um conjunto de dados de teste independente S.

Erro aparente e o erro cometido por uma hipótese sobre os exemplos utilizados para induzir esta hipótese.

Verificar as diferenças entre os resultados obtidos pelas hipóteses construídas pelo RCO com as hipóteses induzidas por CNe See5 quando todos os conjuntos de exemplos de treinamento são utilizados por esses dois indutores.

Analisar cada uma dessas hipóteses internamente, ou seja, as regras que constituem essas hipóteses.

O conjunto S mencionado foi gerado com 1000(mil) exemplos, também balanceado, teste independente dos conjuntos gerados anteriormente.

Para realizar as comparações, os experimentos podem ser divididos em duas fases, Verificar as hipóteses induzidas por CNe See5 utilizando todos os exemplos.

Verificar as hipóteses construídas por RCO.

A seguir, é feita uma descrição dos três experimentos.

Deve ser observado que as hipóteses foram induzidas uma única vez, e se aparecem como induzidas uma ou mais vezes, o único motivo é para facilitar a visualização.

Na fase 1 do experimento 1, foram induzidas 2(duas) hipóteses, uma com o CNe outra com o See5, utilizando como conjunto de exemplos a uniao dos conjuntos.

Para cada uma das hipóteses, foi medido o erro aparente e utilizou-se a técnica de fold cross validation para estimar a taxa de erro e desvio padrão de cada hipótese, bem como o número de regras induzidas utilizando todos os exemplos.

Deve ser observado que nesta primeira fase, ambos os indutores têm acesso a todos os exemplos utilizados no experimento.

Assim, poderia se supor que cada indutor induziu a hipótese mais precisa nesta primeira fase do experimento.

Analogamente, na fase 1 do experimento 2, foram induzidas 2(duas) hipóteses, uma com o CNe outra com o See5, mas, como conjunto de exemplos, foi utilizada a união dos conjuntos.

De forma semelhante, na fase 1 do experimento 3, foi utilizado como conjunto de exemplos a uniao dos conjuntos para a indução das duas hipóteses utilizando o CNe o See5.

Para a realização da fase dos experimentos 1, e 3, foram induzidas as hipóteses utilizando como conjuntos de exemplos os conjuntos respectivamente, conforme dito anteriormente.

O erro aparente de cada hipótese e o número de regras induzidas bem como a estimativa da taxa de erro e desvio padrão utilizando a técnica de fold cross validation são mostrados.

Apesar das regras que constituem as hipóteses h e h induzidas por CNnão terem influência nas hipóteses construídas por RCO, essas duas hipóteses foram mantidas no experimento pois os exemplos utilizados para induzi-las são também utilizados por CNe See5 na fase 1 do experimento, influenciando no cálculo do erro e desvio padrão dos classificadores induzidos por esses dois algoritmos de AM.

Para isso, foram utilizadas as accR covR satR sensR specR supR hipóteses h,h e o conjunto de exemplos S.

Observando os conjuntos de regras construídos pelo RCO nesse experimento, apenas a hipótese h apresentou uma pequena diferença em relação a h e h.

Todas as outras hipóteses são idênticas as hipóteses construídas nos experimentos anteriores.

Esses resultados não são os esperados, isto é, obter as mesmas hipóteses nos diversos experimentos.

Assim, foi decidido investigar cuidadosamente o motivo das hipóteses construídas por RCO não serem distintas quando o conjunto de hipóteses H e incrementado com novas hipóteses.

A explicação é simples e está intimamente ligada ao critério de desempate, por nós implementado, para escolher a melhor regra.

O critério de desempate utilizado é descrito pelos passos 1 e a seguir.

Sejam as hipóteses h,h,h, nessa ordem, os dados de entrada do RCO.

Então, se em uma iteração do RCO existirem duas regras R e R, com R h e R h, i < j, ambas com a mesma melhor medida segundo o critério implementado, o RCO escolhe a regra R, pois i < j.

Em outras palavras, se a hipótese h precede a hipótese h então, em caso de empate, as regras que constituem h tem precedencia sobre as regras de h.

Supondo que existam, em uma iteração do RCO, duas (ou mais) regras R e R nessa ordem, todas com a mesma melhor medida segundo o critério implementado, então, independente de pertencer a mesma hipóteses ou a hipóteses diferentes sempre sera escolhida a regra R e, no caso desta regra não cobrir nenhum exemplo, a iteração do RCO.

Como pode ser observado, esse critério de desempate favorece a escolha das regras das primeiras hipóteses.

Em outras palavras, RCO não "enxerga" as regras das hipóteses posteriores.

Isso explica o motivo de RCO construir a mesma hipótese quando é utilizado o conjunto de hipóteses {h,h,h } ou o conjunto {h,h}.

Neste caso específico, nenhuma das regras das hipóteses h e h foi considerada por RCO.

Uma forma de diminuir esse bias e escolher aleatoriamente a melhor regra a ser utilizada na hipótese construída pelo RCO.

Assim, foi decidido revisar o critério utilizado para escolher a melhor regra em caso de empate.

O novo critério e tal que, em cada iteração, seleciona-se, de forma aleatória, uma regra do subconjunto de regras que contem as regras com a mesma melhor medida.

Se a regra selecionada não cobre nenhum exemplo, seleciona-se aleatoriamente outra regra desse subconjunto.

O processo continua até que alguma regra selecionada cubra ao menos um exemplo do conjunto de exemplos disponível na iteração, ou até que esse subconjunto de regras esteja vazio.

O bias de um algoritmo de aprendizado de máquina mede o quanto, na média, as hipóteses induzidas pelo algoritmo de aprendizado sobre todos os possíveis conjuntos de treinamento de um dado tamanho se aproxima da hipótese verdadeira.

Um Exemplo de Aplicação do MCE.

Com o RCO revisado, o experimento foi repetido 3(três) vezes, com as mesmas hipóteses de entrada h,h e o mesmo conjunto de exemplos S, com o intuito de verificar se as hipóteses construídas são distintas e melhores que as anteriores.

Com os critérios de avaliação de regra covR e sensR, foram induzidas hipóteses idênticas nos experimentos.

Entretanto, foi observado que há uma diferença na ordem em que as regras foram selecionadas.

Para o critério supR, foram selecionadas regras diferentes no experimento 4, somente.

Para os outros critérios-accR, satR e specR-, as regras selecionadas foram diferentes nos experimentos, alguns dados apresentados podem ser iguais, mas foi observado que as hipóteses construídas por RCO não são idênticas.

Esses resultados mostram que, com o novo critério de desempate implementado, o RCO consegue "enxergar" e utilizar as melhores regras de todas as hipóteses, independentemente da ordem dessas hipóteses.

Observa-se que, conforme esperado, o erro e o desvio padrão de CNe See5 tendem a se estabilizar quanto maior e o número de exemplos disponíveis para indução de hipóteses.

Também confirma que CNinduz mais regras que See5.

Com a revisão do RCO, verificou-se que, para as medidas covR, sensR e supR, não existem regras no conjunto de hipóteses de entrada com alto valor nessas medidas que cobrem exemplos da classe x.

Isso se observa quando se olha para os exemplos que restaram na construção das hipóteses, cobertos pela regra default, todos os exemplos são da classe x.

Deve ser lembrado que a regra default classifica os exemplos como pertencentes a classe x, o que explica o erro relativamente baixo em S, ainda no teste caso de muitos exemplos não terem sido cobertos durante a construção da nova hipótese.

No futuro, esta característica do RCO será melhor investigada utilizando outros conjuntos de dados artificiais com mais de duas classes.

Se forem comparadas as taxas de erro em S obtidas nos experimentos 4, 5 e 6 com as taxas de erro e desvio padrão obtidas por CNe See5 na fase 1 do experimento 3, e possível observar que, como esperado, as hipóteses induzidas por CNe See5 são melhores que as construídas por RCO.

Entretanto, considerando que o número de regras selecionadas (incluindo a regra default) por RCO e menor que o número total de regras disponíveis em cada experimento (60 regras), e observando que as hipóteses construídas por RCO apresentam um erro menor que o erro da classe majoritaria, pode ser considerado que os resultados são positivos.

É importante notar que as hipóteses de entrada são as mesmas nos experimentos 4, 5 e 6.

Outro fato importante e que as hipóteses induzidas pelo CNsão distintas umas das outras, com algumas semelhanças entre as hipóteses h e h e as hipóteses h e h.

Quanto as hipóteses h e h induzidas pelo See5, notou-se uma grande semelhança entre elas.

Esse fato indica que as duas hipóteses juntas tem praticamente o mesmo efeito de ter somente uma delas como hipótese de entrada do RCO.

Ainda assim, o número de regras distintas continua sendo grande em relação ao número de regras selecionadas.

Foram relatados os experimentos realizados utilizando o módulo de Combinação e Explicação e um conjunto de dados artificiais.

Esses experimentos mostraram a utilidade de se usar dados artificiais, pois os experimentos são bastante controlados.

Com isso, foi possível notar a importância de se reconsiderar casos de empate na seleção de regras, o que talvez não fosse possível com outros conjuntos de dados.

Assim, o RCO foi melhorado.

Porém, ainda devido a utilização de um conjunto de dados artificiais, outras possíveis melhorias podem ser realizadas, as quais serão relatadas nas conclusões deste trabalho, como proposta de trabalhos futuros.

Estudo de Caso-Processamento de Semen Diagnostico.

Neste capítulo é descrito um estudo de caso do mundo real utilizando o módulo de Combinação e Explicação.

O estudo de conjuntos de dados reais envolve uma série de problemas que não são enfrentados quando os experimentos são realizados utilizando conjuntos de dados obtidos de repositorios como o Repositorio de Dados da UCI ou conjuntos de dados artificiais, como o utilizado no capítulo anterior.

Esses problemas envolvem o trabalho de coleta, preparação e limpeza dos dados, trabalhos quais realizados por Huei Diana Lee, ex-integrante e atual colaboradora do LABIC.

Na medicina, frequentemente existem exames e processos importantes, mas apresentam um alto custo para sua realização.

Em muitos casos, é desejável que os mesmos resultados, ou alguns resultados parciais, possam ser obtidos por métodos menos custosos.

Um exemplo desse caso é o processamento de semen.

O estudo de caso sobre processamento de semen diagnostico teve seu início, onde é descrita a importância desse processamento no tratamento para a reprodução assistida.

Esse exame permite quantificar com precisão a qualidade do semen (processamento de semen diagnostico).

Recuperar a maior quantidade possível de espermatozóides para a utilização na reprodução assistida (processamento de semen terapeutico).

A quantidade de espermatozóides recuperados pelo processamento de semen influencia na escolha da técnica que sera utilizada no tratamento.

São utilizadas três técnicasno tratamento para a reprodução assistida, Inseminação Intra Uterina-IUI.

Fertilização In Vitro-FIV.

Injeção Intracitoplasmatica do espermatozóide no Oocito-ICSI.

Deve ser observado que o processamento de semen é bastante custoso.

A realização do processamento de semen pode elevar o custo do exame em aproximadamente 80% do valor de um espermograma.

Essa elevação de custo se deve principalmente a três fatores, necessidade de equipamentos especiais, mão de obra qualificada e tempo gasto para a realização do exame.

Assim, um dos interesses do estudo desse tema é tentar predizer qual será a quantidade de espermatozóides recuperados pelo processamento de semen antes mesmo da realização desse exame, a partir de exames menos custosos, como o espermograma.

Dessa forma, dependendo da qualidade da predição, o especialista poderia decidir por uma técnica sem a necessidade da realização do processamento de semen.

Um outro interesse para o estudo desse tema é a extração e avaliação do conhecimento adquirido.

O processamento de semen, através do fornecimento de melhores condições, permite que o maior número de espermatozóides móveis (motilidade) seja recuperado.

Os espermatozóides são classificados em graus A, B, C e D dependendo de sua motilidade, grau A, espermatozóides que apresentam o maior grau de motilidade, grau B, espermatozóides que apresentam um menor grau de motilidade, grau C, espermatozóides que se movem em círculos, grau D, espermatozóides que são imóveis.

Os graus de motilidade são atributos medidos tanto no espermograma (exame de baixo custo) quanto no processamento de semen (exame de alto custo).

Os atributos medidos durante o processamento de semen são utilizados para a determinação das classes e os atributos medidos através do espermograma são fornecidos como atributos ao algoritmo de indução.

Em outras palavras, os valores dos atributos de cada exemplo (paciente) são medidos utilizando um exame pouco custoso (espermograma, neste caso) enquanto que as classes desses exemplos são determinadas através de um outro exame mais custoso (processamento de semen, neste trabalho).

A ideia é tentar verificar se é possível descobrir um relacionamento entre eles tal que, pelo menos para novos pacientes, a necessidade de realizar o exame mais custoso seja minimizada.

Como já mencionado, este é um procedimento frequentemente utilizado na area de medicina a fim de tentar diminuir, mas com segurança, o custo de um tratamento.

O especialista sugeriu duas possíveis opções para os valores considerados na classificação dos exemplos, A, considerar apenas a percentagem de espermatozóides classificados como de motilidade grau A no processamento de semen ou AB, considerar a percentagem de espermatozóides classificados como de motilidade grau A e grau B no processamento de semen.

Assim, foram definidas três classes, baseadas nas técnicas que são utilizadas no tratamento para a reprodução assistida, onde x representa milhões de espermatozóides por mililitro (ml).

Foram calculados para cada caso os valores A e AB, gerando dois conjuntos de dados, Proc-a e Proc-ab, respectivamente, cada um com 231 exemplos.

Diversos experimentos foram conduzidos considerando-se esses dois conjuntos separadamente.

Com o decorrer do trabalho, foi necessário criar novos atributos como combinação de atributos originais, criando, assim, diferentes conjuntos de dados.

Um desses conjuntos de dados que mostrou um bom resultado com relação a precisão dos classificadores induzidos foi o denominado Proc-a-gmg-d, o qual considera somente os exemplos em que o processamento de semen é diagnóstico.

Posteriormente, ao conjunto de exemplos Proc-a do trabalho inicial foram acrescentados novos casos.

Tomando desse conjunto de exemplos maior somente os exemplos em que o processamento de semen e diagnostico, foi obtido um segundo conjunto de exemplos Proc-a-gmg-d, semelhante ao construído com os exemplos Proc-a do trabalho inicial, mas incluindo os novos casos.

Mostra-se o número de exemplos (#Exemplos), número e porcentagem de exemplos com valores duplicados (que aparecem mais de uma vez) ou conflitantes (que possuem o mesmo atributo-valor mas tem diferentes classificações), número de atributos (# Atributos) contínuos e nominais, distribuição de classes, o erro majoritário e se o conjunto de dados tem ao menos um valor desconhecido.

Escreve os atributos, exceto o atributo classe, do conjunto de dados utilizado-Proc-a-gmg-d.

O experimento conduzido tem por objetivo gerar um novo classificador simbólico utilizando vários classificadores simbólicos previamente induzidos pelo algoritmo de aprendizado de máquina CN2, através de diferentes critérios implementados pelo RCO para eleger as regras que farão parte desse novo classificador.

Logo após, verificar o erro cometido pelo classificador assim construído com os erros cometidos pelos classificadores individuais, bem como verificar o conjunto de regras que constituem esse novo classificador.

Uma ilustração do experimento realizado pode ser visualizada.

Inicialmente, foi induzido um único classificador com o CN2, utilizando todo o conjunto de exemplos S disponível, ou seja, os 240 exemplos, e foi medido o erro aparente desse classificador.

Após, foi utilizada a técnica de fold cross validation para estimar o erro verdadeiro e o desvio padrão desse classificador, bem como o erro de classificação em cada classe.

Num passo seguinte, o conjunto total de exemplos S, com 240 exemplos, foi dividido aleatoriamente em quatro subconjuntos disjuntos S, S, S e S de exemplos com o mesmo número de exemplos em cada um deles-60 exemplos.

Utilizando cada um dos subconjuntos de exemplos S, S e S, foram induzidos três classificadores h, h e h, respectivamente, com o indutor CN2.

Para esses três classificadores foi também calculado o erro aparente, a estimativa do erro verdadeiro e desvio padrão, bem como a estimativa do erro e desvio padrão em cada classe através de fold cross validation.

Com as hipóteses induzidas h,h,h e o conjunto de exemplos S, foram construídos seis classificadores utilizando o algoritmo RCO.

Cada um desses seis classificadores foi construído utilizando um critério, medida diferente de avaliação de regra para eleger a melhor regra em cada iteração.

As medidas de avaliação de regra utilizadas neste experimento são as mesmas medidas utilizadas nos experimentos com o conjunto de dados artificiais.

As hipóteses construídas pelo RCO neste experimento são denominadas h.

Finalmente, foi calculado o erro para cada um dos seis classificadores construídos por RCO utilizando os subconjuntos de exemplos.

Ainda que neste experimento os exemplos contidos em S, S e S não foram utilizados por RCO para construir os classificadores, eles foram utilizados para induzir as hipóteses h, h e h, utilizadas pelo RCO.

O ideal seria estimar o erro cometido pelos classificadores construídos por RCO em um conjunto de exemplos independente.

Neste trabalho utilizamos a primeira opção devido ao número limitado de exemplos disponíveis.

Assim, deve ser ressaltado que o erro por nós estimado utilizando os exemplos contidos nos subconjuntos S, S e S tende a ser otimista.

Foi medido o erro aparente com o subconjunto de exemplos S.

Deve ser lembrado que, para gerar um novo classificador, o algoritmo RCO para em duas condições durante a iteração que executa.

Não há mais exemplos a serem cobertos.

As regras restantes atingiram seu mínimo (ou maximo) absoluto, relacionado a medida sendo considerada.

São mostrados os resultados obtidos, onde a ultima coluna mostra o número de exemplos restantes na construção do novo classificador.

Ou seja, em todos os casos o segundo critério de parada foi utilizado pelo algoritmo RCO.

Isso significa que esses exemplos foram classificados pela regra default da hipótese construída, a qual prediz a classe 1.

Quanto ao número de regras selecionadas pelo RCO para a construção das hipóteses, pode ser observado que esse número é geralmente menor que o número de regras que constituem cada um dos classificadores h, h e h.

Entretanto, este resultado é esperado já que, para este conjunto de exemplos, o segundo critério de parada foi sempre utilizado por RCO.

Com relação ao erro dos classificadores construídos por RCO, todos eles são muito mais altos que o erro das hipóteses induzidas por CN2.

Ainda que o erro em S seja semelhante ao erro obtido pelas hipóteses induzidas por CNutilizando fold cross validation, essa comparação não é válida, pois o erro é muito otimista, enquanto que o erro obtido utilizando fold cross validation é uma boa estimativa de erro verdadeiro.

Porém, deve ser observado que o objetivo de utilizar RCO com as medidas consideradas não é, necessariamente, o de construir um bom classificador no sentido de classificar relativamente bem qualquer exemplo.

Na realidade, o classificador construído por RCO é aquele que possui regras selecionadas segundo um critério, medid utilizado.

Dessa forma, é interessante observar qual o comportamento dessas melhores regras.

Para verificar o comportamento das regras que constituem as hipóteses construídas pelo RCO, devem ser analisados o número de regras de cada hipótese e os exemplos cobertos pela regra default.

Consta, para cada hipótese construída pelo RCO, o número de exemplos do conjunto S classificados pela regra default, e consta o númerocde regras selecionadas por RCO para cada classe do domínio.

Como pode ser observado, a classe mais crítica e a classe 2.

O conjunto de exemplos S possui 16 exemplos de classe 2.

Assim, quando não há nenhuma regra que prediz essa classe, como no caso das hipóteses, então os 16 exemplos são cobertos pela regra default.

Como essa regra prediz a classe 1, todos esses exemplos são classificados erroneamente, incrementando o erro dos classificadores construídos pelo RCO.

Pode-se assim concluir que não há "melhores" regras para predizer a classe utilizando esses quatro critérios.

Já para a classe 3, observa-se em geral uma pequena quantidade de exemplos cobertos pela regra default, no entanto, as regras selecionadas que classificam exemplos como sendo pertencentes a essa classe não os cobrem corretamente.

Número de Regras Selecionadas por Classe de exemplos da classe prevista pela Cabeça cobertos pela regra.

E definida pela propriedade de o Corpo ser falso dado que a Cabeça e falsa.

Isso implica que, se a Cabeça da regra não coincide com a classe do exemplo então ela não cobre o exemplo, o que é equivalente dizer que uma regra com alta especificidade, quando cobre um exemplo, ela o faz corretamente.

Se for observada, há somente 11 exemplos não cobertos pela regra default, dos quais 2(dois) exemplos são da classe e 9(nove) exemplos são da classe 1.

Como os exemplos restantes são classificados pela regra default e a regra default classifica os exemplos como sendo pertencentes da classe 1, o erro cometido por esse classificador foi alto para estes exemplos.

Para a classe 2, o erro cometido foi de 100%, e o mesmo não aconteceu para a classe porque existe uma regra na hipótese que cobre corretamente exemplos pertencentes a essa classe.

Deve ser observado que o erro para a classe 1 foi de 0% porque os exemplos cobertos pelas regras da hipótese cobrem corretamente os exemplos da classe 1, e o restante dos exemplos e coberto (corretamente) pela regra default.

Quanto as regras selecionadas pelo RCO para os 6(seis) critérios utilizados, foi observado que foram selecionadas um total de 17 regras diferentes que participam dos classificadores construídos pelo RCO.

Nas hipóteses construídas, essas 17 regras aparecem em ordens diferentes nas hipóteses ou aparecem em algumas hipóteses e não aparecem em outras.

Esse fato foi observado quando se deu a comparação das hipóteses construídas com algumas hipóteses analisadas pelo especialista.

Mostra o corpo e a cabeça (classe) das regras pertencentes as hipóteses construídas pelo RCO, na sintaxe padrão em Prolog, o número de vezes que a regra foi selecionada utilizando esses seis critérios, é a opiniao do especialista em relação a regra, N se não faz sentido, OK se a regra faz sentido.

Se a regra não foi analisada pelo especialist.

Quando a regra foi rotulada por N na opinião do especialista, também contem o índice do motivo que o levou a dizer que a regra não faz sentido.

Observa-se que das regras analisadas pelo especialista, 50% das regras Regras Selecionadas pelo RCO.

Motivos do Especialista para considerar que uma Regra não Faz Sentido segue o raciocínio que o especialista utiliza para analisar um caso.

Os outros 50% não fazem sentido ora porque o Corpo da classe possui condições falsas, ora porque utiliza atributos que o especialista não utiliza para a análise.

As 3(três) primeiras regras da oram selecionadas pelos critérios accR, satR e specR como as primeiras regras com melhor valor nessas medidas.

No entanto, para o especialista, elas não fazem sentido, o que mostra que essas medidas devem ser melhor analisadas para utiliza-las como critério de seleção de regras para a construção de uma hipótese, utilizando o RCO.

Com os resultados obtidos nesse experimento e nos experimentos realizados com o conjunto de dados artificiais, foi possível concluir que a ideia de combinar classificadores simbólicos para formar um único classificador é válida, porém muito se pode fazer para melhorar o algoritmo RCO.

As idéias que surgiram são descritas no próximo capítulo, onde constam as conclusões de todo o trabalho realizado.

Neste trabalho é proposta a combinação de classificadores induzidos por algoritmos de AM simbólicos para gerar um novo classificador, bem como explicar a classificação de novos exemplos realizada pelo ensemble formado por esses classificadores simbólicos.

Para analisar a viabilidade dessa proposta, foi implementado o sistema R Sule ystemna linguagem de programação logica Prolog.

A prototipagem rápida oferecida pela linguagem Prolog agilizou o processo de implementação do sistema R S ule ystem.

O maior problema encontrado foi para documentar o sistema, já que não foi encontrada uma metodologia que atendesse as necessidades de documentação das especificidades do sistema.

Para isso, foi desenvolvida uma metodologia de representação na forma de um Diagrama de Fluxo de Execução de Procedimentos, PEF, a qual atendeu as necessidades de documentação do sistema implementado.

Em relação ao módulo de Combinação e Explicação, detalhado neste trabalho, o exemplo utilizado para mostrar o funcionamento do algoritmo RCO mostrou que as ideias propostas para combinação de classificadores funcionam.

Deve ser lembrado que o objetivo principal de todo o trabalho realizado é propor uma forma de combinação de classificadores para se trabalhar com grandes bases de dados.

Dada uma grande base de dados, divide-se esta base aleatoriamente em pequenas bases de tal forma que é viável fornecer essas bases de tamanho menor a um ou vários algoritmos de AM.

Assim, com o trabalho realizado, verificou-se que se todas essas bases são mostradas ao(s) algoritmo(s) e para cada uma delas uma hipótese e induzida, uma seleção das melhores regras segundo algum critério de avaliação de regra pode ser realizada e, a partir da nova hipótese construída, pode-se utilizá-la para extrair conhecimento ou para classificar novos exemplos.

Através dos experimentos realizados utilizando um conjunto de dados artificiais, foi possível observar a necessidade de melhorar o critério de seleção de regras do algoritmo RCO em caso de empate.

Esse fato mostrou a importância de se utilizar bases de dados artificiais pois, dessa forma, os experimentos são bastante controlados.

Em experimentos controlados, há a facilidade de melhorar alguns critérios dos algoritmos envolvidos nos experimentos bem como motivar novas ideias.

Assim, o critério de desempate utilizado por RCO foi revisto e foi observado que,após a revisão ocorrida no RCO, houve uma melhora significativa na eleição das regras.

Futuramente, outros critérios serão investigados e implementados no RCO, permitindo ao usuário realizar a escolha do critério mais apropriado para o domínio em questão.

Existem inúmeros critérios de seleção da melhor regra de uma hipótese h.

Um dos possíveis critérios consiste em escolher a regra com o melhor grau de adequação (rule fitness) para o problema em questão.

Dada uma regra R, representada por B H, o grau de adequação de R pode ser denotado por rf(B H).

O critério de seleção rf escolhe a melhor regra como sendo aquela que possui maior valor de rf.

Existem três possíveis critérios que permitem estimar o grau de adequação de uma regra, Confiabilidade Positiva, O primeiro e a confiabilidade positiva, a qual utiliza a precisão de regra (accR).

Entretanto, a confiabilidade positiva possui uma propriedade indesejada.

Por exemplo, dadas duas regras R e R, supondo que para a regra R, o valor de accR seja 1, e para a regra R, o valor de accR seja 098, segundo o critério atual de RCO, a regra R e melhor que a regra R.

Entretanto, se a regra R cobre somente um exemplo e a regra R cobre 200 exemplos (portanto, deles são cobertos erroneamente), a regra que deveria ser eleita como a melhor regra seria a regra R.

Precisão de Laplace.

Uma solução para o problema apresentado pela confiabilidade positiva (accR) consiste em substituí-la pela precisão de Laplace, definida pela Equação, onde NCl e o número de classes do conjunto de exemplos, bh e o número de exemplos cobertos corretamente pela regra e bh e o número de exemplos cobertos incorretamente pela regra.

Considerando esse critério, quanto maior o valor da precisão de Laplace, melhor é a regra.

Assim, ainda considerando o exemplo anterior em um problema com classes, indicando que a regra R e melhor que a regra R.

Assim como a confiabilidade positiva, a precisão de Laplace assume valores no intervalo.

Novidade, Esta medida de avaliação de regra está implementada no módulo de Analise de Regras, outro módulo principal do R S ule ystem.

Futuramente, devera ser investigado se os dois ultimos critérios-precisão de Laplace e novidade-oferecem bons resultados quando utilizados com o RCO.

A ideia de combinar diversos classificadores bem como utilizar melhores heurísticas para seleção de regras e reforçada quando se analisa os resultados obtidos no experimento utilizando o conjunto de dados reais.

Das regras selecionadas pelo RCO neste experimento e analisadas pelo especialista do domínio, 50% delas não são boas regras do ponto de vista do especialista.

Entretanto, 50% delas o são, o que mostra que a ideia é viável mas precisa ser melhorada.

O erro obtido pelos classificadores construídos utilizando a versão atual do RCO deixa a desejar em todos os experimentos realizados.

Deve ser observado que não necessariamente bons classificadores são construídos, mas sim classificadores com as melhores regras induzidas por diferentes algoritmos de aprendizado de máquina, ou induzidas por um mesmo algoritmo de aprendizado de máquina mas com diferentes conjuntos de exemplos, como dito anteriormente.

No início da implementação do MCE, pensava-se que o algoritmo de fold cross validation utilizado para estimar o erro e o desvio padrão das hipóteses construídas pelo RCO fosse válido.

Depois, percebeu-se que o algoritmo deveria também induzir novamente as hipóteses de entrada do RCO a cada iteração do algoritmo de fold cross validation.

Futuramente, essa implementação mais completa será incluída no MCE.

Finalizando, pode-se concluir que a ideia utilizada pelo RCO para construir a hipótese como um conjunto das "melhores" regras que constituem outras hipóteses e valida.

Entretanto, as diversas medidas consideradas apresentam, do ponto de vista de exemplos não cobertos, comportamentos bem diferentes, o que pode influenciar no erro em S, no caso teste do número de classes ser maior que dois.

Este tema será melhor investigado no futuro.

Com relação a implementação da explicação de ensembles, o que o MCE faz para explicar a classificação feita por um conjunto de classificadores a um exemplo x e selecionar, do conjunto de hipóteses H, um conjunto de regras R com as regras que cobrem o exemplo x.

Depois, selecionar de R a regra R com a melhor medida segundo algum critério implementado e escolhido pelo usuário, e retornar essa regra como sendo a explicação da classificação.

Futuramente, deve-se analisar como as outras regras do conjunto R cobrem o exemplo x e deve-se tentar criar uma unica regra R a partir do conjunto de regras R.

Se R for construída, essa será a regra fornecida ao usuário para explicar a classificação de x.

Análise Qualitativa de Regras.

Sob o aspecto qualitativo, regras são avaliadas com o objetivo de saber quais são aquelas melhor sustentadas pelos dados.

A análise qualitativa de regras pode ser efetuada por meio de procedimentos que implementam medidas de avaliação de regras.

Dada uma regra R, denotada por B H, onde B e o corpo da regra e H e a cabeça da regra e dado um exemplo x rotulado por y, a avaliação da regra é feita através de um procedimento que determina se B e verdadeiro ou falso e se H e verdadeiro ou falso para esse exemplo.

Por meio desse procedimento e possível determinar, para cada regra R de u um classificador simbólico, as seguintes informações, No cálculo dessas informações deve ser considerado a forma que as regras do classificador simbólico h foram induzidas pelo algoritmo de AM.

O módulo de Analise de Regras calcula essas informações para regras unordered, ordered e interclass, conforme descrito a Para um conjunto de regras unordered, essas informações são calculadas verificando a cobertura de cada regra do classificador simbólico em todo conjunto de exemplos S.

O Algoritmo 8 mostra como e realizado o calculo dessas informações para um conjunto de regras unordered.

Algoritmo 8 Cálculo de Informações para Avaliação de Regras Unordered Require, Conjunto de Regras Unordered. A função cobertura retorna um número inteiro no intervalo que é usado como índice para realizar o elemento correspondente da lista L.

O índice 1 corresponde a hb, a hb, a hb, a hb.

Ordered No caso de regras ordered existe um else implícito entre cada regra, assim o exemplo deve ser aplicado a partir da primeira regra, ate que uma delas cubra esse exemplo (B é verdade para o exemplo).

Esse exemplo deve ser coberto apenas por essa regra.

Para as regras seguintes aquela que cobre o exemplo, as informações devem ser atualizadas incrementando-se os valores de bh e bh conforme a classe C do exemplo.

O Algoritmo 9 mostra como e realizado o calculo dessas informações para um conjunto de regras ordered.

A variavel first esta associada a cada exemplo e recebe false se o exemplo não foi coberto por uma regra ou true se ja foi coberto.

Interclass As regras interclass são separadas em C blocos para cada uma das diferentes classes, existindo um else implícito entre cada um desses blocos.

Para regras em um mesmo bloco C, as informações são calculadas como descrito anteriormente para regras unordered.

Ao ser encontrada uma regra que cubra o exemplo em um bloco C, as informações extraídas das regras subsequentes devem ser atualizadas como descrito anteriormente para regras ordered, nos CNCl-v blocos seguintes.

Simbólico h, os valores encontrados podem ser expressos sob a forma de frequencias relativas, as quais são utilizadas nesse trabalho como uma estimativa de probabilidade.

Por exemplo, considerando a informação hb, a probabilidade pode ser determinada da seguinte forma, onde N é o número total de exemplos utilizados para calcular a informação hb.

De forma semelhante podem ser determinados os valores das probabilidades.

Conhecidas essas probabilidades, os valores podem ser determinados.

Por exemplo, frequência no conjunto de exemplos.

Assim, uma hipótese h sempre irá classificar um exemplo devido a existência da regra default.

Se R e a regra default, então as informações não são calculadas para essa R h.

Neste trabalho, essas probabilidades são utilizadas para calcular as medidas de avaliação de regras.

Medidas de Avaliação de Regras.

No framework algumas medidas de avaliação encontradas na literatura foram unificadas, considerando uma regra R na forma B H.

Essas medidas podem ser divididas nas seguintes categorias:

Medidas genéricas de avaliação.

Medidas relativas de avaliação.

Medidas relativas de avaliação com peso.

Baseada na medida de novidade, as medidas relativas de avaliação com peso são iguais entre si e iguais a medida de novidade da regra.

Geralmente, medidas de avaliação são uteis para determinar quais são as "melhores" regras de um classificador simbólico h.

As "melhores" regras podem ser aquelas que apresentam o maior (ou menor) valor para uma determinada medida de avaliação.

Por exemplo, pode ser considerado que as "melhores" regras R de um classificador simbólico h, são aquelas que possuem maior valor para a medida de Precisão (ou menor valor para a medida de Erro).