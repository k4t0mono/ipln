Algoritmos de aprendizado de máquina são frequentemente os mais indicados em uma grande variedade de aplicações de mineração dados.

Entretanto, a maioria das pesquisas em aprendizado de máquina refere-se ao problema bem definido de encontrar um modelo (geralmente de classificação) de um conjunto de dados pequeno, relativamente bem preparado para o aprendizado, no formato atributovalor, no qual os atributos foram previamente selecionados para facilitar o aprendizado.

Além disso, o objetivo a ser alcançado é simples e bem definido (modelos de classificação precisos, no caso de problemas de classificação).

Mineração de dados propicia novas direções para pesquisas em aprendizado de máquina e impõe novas necessidades para outras.

Com a mineração de dados, algoritmos de aprendizado estão quebrando as restrições descritas anteriormente.

Dessa maneira, a grande contribuição da área de aprendizado de máquina para a mineração de dados é retribuída pelo efeito inovador que a mineração de dados provoca em aprendizado de máquina.

Nesta tese, exploramos alguns desses problemas que surgiram (ou reaparecem) com o uso de algoritmos de aprendizado de máquina para mineração de dados.

Mais especificamente, nos concentramos seguintes problemas, Novas abordagens para a geração de regras.

Dentro dessa categoria, propomos dois novos métodos para o aprendizado de regras.

No primeiro, propomos um novo método para gerar regras de exceção a partir de regras gerais.

No segundo, propomos um algoritmo para a seleção de regras denominado ROCCER.

Esse algoritmo é baseado na análise ROC.

Regras provêm de um grande conjunto externo de regras e o algoritmo proposto seleciona regras baseado na região convexa do gráfico ROC.

Proporção de exemplos entre as classes.

Investigamos vários aspectos relacionados a esse tópico.

Primeiramente, realizamos uma série de experimentos em conjuntos de dados artificiais com o objetivo de testar nossa hipótese de que o grau de sobreposição entre as classes é um fator complicante em conjuntos de dados muito desbalanceados.

Também executamos uma extensa análise experimental com vários métodos (alguns deles propostos neste trabalho) para balancear artificialmente conjuntos de dados desbalanceados.

Finalmente, investigamos o relacionamento entre classes desbalanceadas e pequenos disjuntos, e a influência da proporção de classes no processo de rotulação de exemplos no algoritmo de aprendizado de máquina semi-supervisionado Co-training.

Novo método para a combinação de rankings.

Propomos um novo método, chamado BORDARANK, para construir ensembles de rankings baseado no método de votação borda count.

BORDARANK pode ser aplicado em qualquer problema de ordenação binária no qual vários rankings estejam disponíveis.

Resultados experimentais mostram uma melhora no desempenho com relação aos rankings individuais, alem de um desempenho comparável com algoritmos mais sofisticados que utilizam a predição numérica, e não rankings, para a criação de ensembles para o problema de ordenação binária.

ESTA tese de doutoramento tem como tema aprendizado de máquina e uma de suas mais diretas aplicações, a descoberta de conhecimento a partir de dados.

Neste capítulo é apresentada uma descrição da tese, com o intuito de fornecer ao leitor uma visão geral dos assuntos abordados neste trabalho, bem como algumas das soluções propostas.

Este capítulo está organizado da seguinte maneira, na Seção 11 é apresentada a motivação deste trabalho, destacando os principais desafios para a utilização de aprendizado de máquina para a descoberta de conhecimento.

Na Seção 1são apresentados os objetivos desta tese de doutoramento.

Na Seção 1são destacadas as principais contribuições, as quais serão abordadas mais profundamente nos capítulos seguintes.

Finalmente, na Seção 1é apresentada a organização do trabalho, com uma breve descrição do conteúdo de cada capítulo.

É freqüente encontrar definições (ao menos informais) de que Mineração de Dados (M é uma aplicação de Aprendizado de Máquina (AM).

Uma das possíveis razões para essa confusão de conceitos é que muitas das feramentas utilizadas em MD estão baseadas em algoritmos de AM.

Neste sentido é inegável que AM forme o núcleo do que se convencionou denominar por MD.

Em contrapartida, devido a esse massivo uso de algoritmos de AM, mineração de dados é hoje uma das grandes vitrines para aprendizado de máquina.

Por esse simples motivo, é inegável a existência de uma forte e sinergética sobreposição entre as duas áreas.

Entretanto, apesar das duas áreas terem uma grande semelhança e até mesmo compartilharem um sem número de métodos, práticas e objetivos, elas são áreas distintas, cada qual com seus avanços, limitações e desafios a serem superados.

Essa sobreposição não pode ser vista simplesmente como uma relação de dependência de uma para com a outra.

Ao menos do ponto de vista de áreas de pesquisa, o elemento comum a ser explorado reside no fato de que mineração de dados representa uma genuína fonte para alimentar as pesquisas em aprendizado de máquina, e vice-versa.

Em linhas gerais, aprendizado de máquina pode ser caracterizado por uma série de práticas voltadas para a solução de problemas para os quais geralmente não se conhece a priori uma solução ou modelagem capaz de resolvê-los.

O que se conhece é um conjunto finito de fatos (também conhecidos como casos ou exemplos) que descrevem objetos, processos, situações, ou ambientes e o objetivo é encontrar alguma solução a partir desses fatos.

Essas práticas incluem, entre outros, generalização a partir de um conjunto de casos cujas classes são conhecidas, reconhecimento de padrões, identificação de agrupamentos e correlações, refinamento de teorias a partir de métodos de aprendizado e aprendizado por realimentação dos estados do ambiente.

Aprendizado de máquina tem uma grande sobreposição com estatística, uma vez que ambas as áreas estudam a análise de dados.

Entretanto, diferentemente da estatística, que foca-se principalmente em modelos teóricos bem definidos e ajustamento de parâmetros a esses modelos, aprendizado de máquina tem um foco mais algorítmico, utilizando representações de modelos mais flexíveis e heurísticas para a realização de busca.

Por exemplo, uma análise estatística pode determinar distribuições, covariâncias e correlações entre os atributos que descrevem os fatos, mas não é capaz de caracterizar essas dependências em um nível abstrato e conceitual como os humanos fazem, nem prover uma explicação causal do porque essas dependências existem.

Enquanto uma análise estatística dos dados pode determinar as tendências centrais e variâncias de determinados fatores, ela não pode produzir uma descrição qualitativa das regularidades, nem tão pouco determinar as dependências em fatores não providos explicitamente com os dados.

A flexibilidade dos métodos de aprendizado de máquina os torna apropriados para situações nas quais existe pouco conhecimento a priori sobre o domínio, e/ou esse conhecimento a priori é de difícil elicitação, dificultando a escolha de modelos estatísticos.

Essa flexibilidade também significa que algoritmos de AM são freqüentemente capazes de aprender com dados que não foram coletados a partir de um rigoroso processo experimental controlado, mas obtidos a partir de um processo qualquer cujo principal objetivo não seja a descoberta de conhecimento.

O preço a pagar por essa flexibilidade é a falta de um poder analítico-teórico que a utilização dos modelos estatísticos pré-definidos possuem.

Outro ponto importante a ser ressaltado é que não existe um método de aprendizado de "propósito-geral".

Cada método tem a sua utilidade comprometida pelas suas suposições e particularidades, e cada aplicação requer atenção especial para a definição dos métodos a serem utilizados.

Além disso, análises teóricas de métodos de aprendizado são muito difíceis, e dificilmente se têm garantias de que os resultados estão corretos.

Em contrapartida, aprendizado de máquina faz uso intensivo do poder computacional para validar experimentalmente seus métodos e resultados, utilizando métodos estatísticos de reamostragem, tal como a validação cruzada, além da validação experimental em conjuntos de dados de benchmark e experimentação com conjuntos de dados especialmente designados para testar hipóteses específicas.

Representações de modelos construídos por algoritmos de aprendizado incluem várias formas de representação equivalentes à lógica proposicional e relacional, agrupamentos, hierarquias de conceitos, redes probabilísticas, entre outras.

Métodos de busca geralmente utilizados incluem busca em feixe, gradiente descendente, maximização das expectativas, algoritmos genéticos e busca em profundidade, entre outros.

Para se entender melhor o que é mineração de dados, é importante diferenciar MD do uso tradicional de computadores para o tratamento e análise de dados.

Atualmente, dados são armazenados e organizados em sistemas gerenciadores de Bases de Dados B.

Consultas e relatórios são ferramentas simples e práticas que podem ser utilizadas para explorar esses dados em vários níveis.

Ferramentas de consultas a BDs recuperam a informação enquanto que ferramentas de relatórios apresentam essa informação de uma maneira clara e organizada.

Mineração de dados, em contrapartida, é utilizada para extrair informações interessantes ocultas nos dados.

A principal diferença é que, ao contrário da mineração de dados, o critério para a realização da consulta a uma BD é estabelecido previamente.

Mineração de dados, ao contrário, procura por relações e associações entre eventos que não são necessariamente conhecidas a priori.

Para entender melhor a diferença, considere o exemplo a seguir.

O departamento de marketing de uma empresa quer saber se existe algum relacionamento entre dois produtos A e B.

Para tanto, eles consultam as bases de dados de vendas dos produtos A e B separadamente e em conjunto por meio de uma consulta tal como, "Quantas vezes o produto A com o produto B foram comprados em conjunto ".

Quantas vezes o produto A foi comprado.

Quantas vezes o produto B foi comprado.

Com essas informações, é possível determinar se há um relacionamento entre esses dois produtos A e B, mas somente entre eles.

Essa consulta baseia-se na suposição de que existe alguma conexão entre a compra conjunta de A e B.

Essa suposição deve ser formulada antes que a consulta seja feita.

Compare com um exemplo típico de MD.

A pergunta agora é, "Quais são os produtos que apresentam alguma conexão ", ou seja, quais produtos são mais freqüentemente comprados juntos.

Nesse caso, serão encontradas as conexões mais freqüentes entre todos os pares de produtos na BD, já que nenhuma suposição foi feita a priori com relação aos produtos a serem consultados.

Nesse caso, observe que a conexão entre os produtos A e B pode ou não ser encontrada, dependendo da freqüência com que esses produtos são adquiridos em conjunto.

É claro que essas funcionalidades podem ser implementadas dentro de um gerenciador de bases de dados utilizando uma composição de consultas.

Entretanto, essa não é uma consulta trivial e nem a atividade principal para a qual esses sistemas foram projetados.

Por prover os conjuntos de dados reais, mineração de dados é uma fonte natural para a aplicação de algoritmos de aprendizado de máquina.

Muitos dos métodos de aprendizado de máquina mais poderosos têm suas aplicações mais visíveis em bases de dados reais disponíveis hoje em dia, as quais não estavam disponíveis quando os métodos foram originalmente propostos.

Entretanto, a maioria das pesquisas em aprendizado de máquina relatadas na literatura está delimitada a problemas bem definidos, como criar um modelo de classificação dado um conjunto de dados simples, pequeno, relativamente bem preparado em uma tabela no formato atributo-valor, no qual os atributos foram previamente selecionados para facilitar o aprendizado e a meta é simples e bem definida, geralmente expressa como taxa de acerto de classificação.

Em mineração de dados, no entanto, aprendizado é raramente um processo isolado, mas uma série de atividades, que vão desde a definição do problema, preparação dos dados, aprendizado, até a utilização dos resultados obtidos.

Nesse sentido, mineração de dados permitiu que aprendizado de máquina estendesse suas idéias e motivações em novas direções.

Com o advento da mineração de dados, pesquisas em aprendizado de máquina obtiveram um incentivo para quebrar muitos dos paradigmas, restrições e limitações existentes até então.

Dessa maneira, as valiosas contribuições do aprendizado de máquina para a mineração de dados têm a reciprocidade pelo inerente caráter revigorante da mineração de dados.

Nesta tese, procuramos explorar o benefício mútuo da interação entre essas duas áreas.

Muitos métodos de AM assumem que os exemplos (casos) não contêm erros, que todos os valores dos atributos são conhecidos, que todos os exemplos provém de uma mesma base de dados e que existe um conceito preciso a ser aprendido que não muda com o tempo.

Em muitas situações, muitas dessas restrições não são aplicáveis, uma vez que os dados disponíveis são dados reais.

Esse fato leva a uma série de problemas não contemplados em algoritmos de aprendizado de máquina tradicionais, e à necessidade do desenvolvimento de uma grande variedade de métodos para resolvê-los.

Esses problemas incluem, Aprendizagem a partir de exemplos com ruído para tratar de exemplos que contenham uma certa quantidade de erros ou ruído.

Esses problemas são de grande importância em AM uma vez que dados reais freqüentemente contêm quantidades consideráveis de ruído.

Aprendizagem a partir de dados incompletos no qual deve-se levar em consideração exemplos para os quais os valores para alguns dos atributos são desconhecidos.

Aprendizagem com atributos irrelevante/reduntantes no qual deve-se levar em consideração atributos que ou são irrelevantes, não contribuem na definição do conceito ou redundantes, existes atributos similares com um poder de descrição parecido Lee.

Liu & Motoda.

Aprendizagem com mudanças de conceito no qual o conceito meta a ser aprendido não é estático, mas pode mudar com o tempo.

Essa mudança se dá ou aleatoriamente ou em alguma direção específica.

Um exemplo típico de mudança de conceito é a previsão do tempo, no qual o conceito pode mudar radicalmente de acordo com a estação do ano.

Aprendizagem incremental na qual os exemplos chegam em um fluxo contínuo de dados e o modelo que os caracteriza pode necessitar de ajustes conforme chegam os dados.

Aprendizagem com dados distribuídos temporal e espacialmente a maioria dos algoritmos de aprendizado não é capaz de lidar com dados que são distribuídos temporal ou espacialmente.

Nesses casos, os dados devem ser considerados em conjunto e as relações entre eles devem ser exploradas.

Aprendizagem com dados viciados a maioria dos dados reais não foram coletados com o intuito de se utilizar métodos de aprendizado.

Dessa maneira, a suposição usual de dados independentes e identicamente distribuídos não é necessariamente verdade.

Uma importante direção de pesquisas esta relacionada ao fato que a amostra não é independente e que dados do passado, presente e futuro não são necessariamente da mesma população.

Aprendizagem com custos a maioria dos algoritmos de aprendizado assume que todos os erros têm um mesmo custo, mas isso raramente acontece na prática.

Um problema relacionado é o de classes desbalanceadas, uma vez que é fácil obter altas taxas de acerto favorecendo as classes mais freqüentes.

Aprendizagem de padrões isolados a meta tradicional de criar um modelo global do processo que representa os dados, muitas vezes deve ser trocada pela procura por padrões localizados ou desvios com relação a um padrão pré-estabelecido.

Como visto na seção anterior, aprendizado de máquina contribui com mineração de dados com a flexibilidade e expressividade na representação de modelos, a importância das validações empíricas e com o grande poder algoritmico-computacional baseado nos mais diferentes métodos e heurísticas de busca.

Em contrapartida, mineração de dados requer que algoritmos de aprendizado sejam capazes de lidar com várias questões práticas, tais como a escalabilidade a grandes bases de dados, utilização de custos no processo de aprendizagem, ambientes dinâmicos e conceitos que possam evoluir com o tempo, capacidade de lidar com classes de exemplos pouco freqüentes e novas formas de representação e organização de conhecimento.

Em suma, mineração de dados abriu várias novas direções para pesquisas em aprendizado de máquina.

Além disso, em vários aspectos, ela propicia uma visão renovada em problemas que receberam algum tratamento na área, mas que tiveram uma diminuição de interesse devido principalmente à falta de dados reais relevantes.

O principal objetivo desta tese é explorar alguns desses problemas que surgiram (ou reaparecem) com o uso de algoritmos de aprendizado de máquina para mineração de dados.

Mais especificamente, durante o desenvolvimento desta tese, nos concentramos nos seguintes problemas, Podemos explorar alguma representação alternativa para a indução de modelos Como incorporar essa representação em um algoritmo de aprendizado Preferencialmente, representações que sejam mais facilmente entendíveis por seres humanos.

Podemos explorar algum método de busca alternativo na geração de conjuntos de regras de conhecimento.
Como o desempenho desse método se compara com outros métodos.
Conjuntos de dados com classes desbalanceadas podem piorar o desempenho de algoritmos de aprendizado.
Em que condições podemos compensar o problema causado pelas classes desbalanceadas.
Como combinar diversos rankings de tal maneira a construir um ranking final com melhor desempenho que os rankings originais para o problema de ordenação binária.
Como o desempenho desse ranking se compara com outras abordagens.
Como utilizar rankings para derivar modelos de classificação.
As principais contribuições desta tese podem ser reunidas nos seguintes três grandes grupos.
Novas abordagens para a geração de regras de exploração de problemas relacionados à de proporções de exemplos entre as classes, principalmente proporções muito desbalanceadas dentro do contexto de aprendizado de máquina e um novo método para a combinação de rankings em problemas de ordenação binária Todas as contribuições foram amplamente divulgadas à comunidade científica em diversos veículos.

No primeiro grupo destacam-se duas abordagens, na primeira delas, foi proposto um novo método para a geração de regras de exceções a partir de regras gerais.

Esse método está baseando em um princípio muito simples, primeiramente um algoritmo de aprendizado de máquina tradicional é utilizado para a indução de regras gerais.

Após, procuramos nas regras com altas taxas de erro por associações entre os exemplos incorretamente classificados e as classes diferentes daquela prevista pela regra geral.

Se associações fortes são encontradas, elas são consideradas como exceção à regra geral.

Na segunda abordagem para geração de regras, foi proposto o algoritmo ROCCER, que faz seleção de regras baseado na análise ROC.

O princípio por trás do algoritmo também é simples, uma nova regra é inserida somente se ela leva a um ponto que está fora da curva formada pela região convexa das regras que compõem o modelo.

O algoritmo também possui outras qualidades, como um mecanismo implícito de backtracking.

Em Batista comparamos o desempenho do ROCCER com um algoritmo que também faz seleção de regras, mas utilizando um algoritmo genético cuja função de aptidão é a área abaixo da curva ROC AU.

Quanto à proporção de exemplos entre as classes, primeiramente exploramos a hipótese de que o grau de desproporção entre as classes não é o único fator para a queda de desempenho em conjuntos de dados com classes desbalanceadas, mas também participam o grau de sobreposição entre as classes e a quantidade absoluta de exemplos na classe minoritária.

Após, apresentamos resultados experimentais com vários métodos diferentes de balanceamento artificial de classes, dentre eles alguns por nós propostos.

Também reportamos resultados para averiguar o relacionamento entre classes desbalanceadas e pequenos disjuntos.

Um outro resultado obtido está relacionado com a sensitividade do algoritmo de aprendizado semi-supervisionado multi-visão Co-training à proporção de exemplos em cada classe que são rotulados em cada iteração do algoritmo.

Finalmente, desenvolvemos um método para a combinação de rankings em um ranking final para problemas de ordenação binária denominado BORDARANK.

Esse método está baseado no método de votação por preferências borda count.

Em linhas gerais, o método tem como entrada vários rankings e computa o ranking médio de cada caso.

Essa abordagem, apesar de muito simples, mostrou-se competitiva com métodos mais sofisticados.

Em Lee exploramos a idéia de utilizar rankings para a avaliação de métodos de seleção de atributos.

Como a avaliação de métodos de seleção de atributos é uma tarefa multi-objetivos, sendo que cada objetivo é geralmente medido em escalas diferentes (taxa de erro de classificação e porcentagem de atributos selecionados) a utilização de rankings provê uma maneira natural de combinar a avaliação desses objetivos.

Além disso, a utilização de rankings permite uma fácil incorporação de outros objetivos, tais como complexidade sintática dos modelos induzidos.

Além desses, outros trabalhos relevantes foram publicados.

Em Bernardini, propomos um método simbólico para a construção de ensembles de modelos de classificação.

Nossa principal constatação nesse trabalho é que um ensemble construído a partir da melhor regra de um conjunto de regras, segundo alguns critérios de qualidade de regras pré-estabelecidos, tem um desempenho comparável, nos conjuntos de dados testados, a um ensemble construído levando-se em consideração todo o conjunto de regras.

Essa constatação é importante no sentido de que as regras podem ser exploradas para explicar a decisão do ensemble em classificar um dado exemplo em uma certa classe, já que essa explicação é muito mais difícil levando-se em consideração todo o conjunto de regras.

Além das publicações científicas, também produzimos trabalhos de caráter mais didáticos.

Em Monard & Prati, publicamos um texto introdutório de aprendizado de máquina simbólico a partir de exemplos para mineração de dados.

Em Prati, submetemos um artigo a respeito da análise ROC, no qual está baseado o Capítulo desta tese.

Alguns termos que aparecem no texto dessa tese, tais como benchmark, marketing, ranking, backtracking, ensemble, shell, insights e kernel não foram traduzidos para o portugues.

Optamos por deixá-los em inglês pois é difícil encontrar uma tradução adequada que expresse o mesmo significado do temo em inglês.

Outros termos foram traduzidos para o português, mas os acrônimos utilizados, tais como ILP, tpr, fpr, ROC, kNN, são os que correspondem aos termos em inglês.

Esses acrônimos foram mantidas nessa forma por serem amplamente utilizados pela comunidade.

A utilização desses termos e acrônimos não representa de forma alguma desconsideração à lingua portuguesa, e somente foram utilizados pelos motivos acima apresentados.

NESTE capítulo é feita uma introdução ao aprendizado de máquina, tema ao qual está relacionada esta tese.

Ele está organizado da seguinte maneira, na Seção 21 são apresentadas algumas considerações iniciais sobre o tema.

Na Seção 2são apresentados os três métodos de inferência comumente utilizados em inteligência artificial.

Aprendizado de máquina é contextualizado dentre esses métodos de inferência e na Seção 2são apresentadas as principais características dos sistemas de aprendizado.

Na Seção 2é formalizado o problema de aprendizado.

Finalmente, na Seção 25, são apresentadas as considerações finais deste capítulo.

A construção de máquinas capazes de aprender por experiência tem sido, por um longo período, objeto de discussões tanto técnicas quanto filosóficas.

O aspecto técnico desse debate vem recebendo grandes impulsos a partir do advento dos computadores eletrônicos.

Relevantes pesquisas nessa área têm demonstrado que máquinas podem mostrar um significante nível de aprendizagem, mesmo não estando claramente definidas as fronteiras dessa habilidade de aprendizado.

A disponibilidade de sistemas de aprendizagem confiáveis é de suma importância, pois existem muitos problemas que não podem ser resolvidos por métodos clássicos de programação, uma vez que não é possível modelar esses problemas matematicamente ou algoritmicamente.

Não se sabe, por exemplo, como escrever um programa de computador que reconheça caracteres escritos à mão.

Entretanto, existe uma grande quantidade de exemplos disponíveis de caracteres escritos à mão e a sua representação eletrônica equivalente.

É natural, de certa maneira, perguntar se é possível escrever um programa que aprenda por meio de exemplos a reconhecer um caractere manuscrito, uma vez que é de maneira semelhante que humanos aprendem a reconhecer o alfabeto.

O mesmo raciocínio pode ser aplicado à procura de genes em uma seqüência de DNA, filtragem de correspondência eletrônica, detecção ou reconhecimento de objetos em visão computacional, entre outros.

Resolver algum desses problemas pode resultar em significativos avanços nas respectivas áreas e, se pudermos entender como programar computadores para resolvê-los, assim como para outros problemas de difícil solução e igual importância, poderemos obter resultados importantes na ciência da computação.

A solução dessas tarefas complicadas está claramente à margem das habilidades mesmo dos melhores programadores.

Entretanto, o que pode ser feito é construir sistemas que, de certa maneira, tem a habilidade de aprender pela experiência.

Neste capítulo são discutidos alguns aspectos relacionados ao aprendizado de máquina a partir de exemplos.

A aprendizagem está relacionada à correta manipulação de conhecimento prévio e novas observações que possam levar a novos conhecimentos.

Essa manipulação está relaciona a métodos de inferência lógica.

Em geral, os métodos de inferência lógica podem ser agrupados em três classes, descritas a seguir.

Dedução Dedução poder ser definida como uma forma de inferência logicamente correta, isto é, a conclusão obtida a partir de um conjunto de premissas iniciais verdadeiras sempre preserva a verdade.

Entretanto, a inferência dedutiva pode ser aplicada somente para obter informa-que já estão contidas, de forma implícita, nas premissas.

Na aprendizagem por dedução, o aprendiz adquire conceitos por meio da inferência dedutiva sobre as premissas.

Em outras palavras, essa abordagem inclui qualquer processo no qual o conhecimento aprendido é o resultado de transformações sobre o conhecimento existente, preservando a veracidade.

Em geral, na aprendizagem por dedução, realiza-se uma seqüência de deduções e cálculos a respeito das informações presentes, visando a elicitação do conhecimento oculto, mas já existente nessas premissas.

Abdução Enquanto o resultado da inferência dedutiva não ultrapassa as premissas, em abdução estamos interessados em inferir um conhecimento particular a partir de observações e outras informações conhecidas.

Possíveis hipóteses abdutivas são construídas a partir de um conjunto de predicados específicos não observados.

Dessa maneira, hipóteses abdutivas são aquelas que trabalham com conhecimento incompleto, completando o conhecimento a respeito de um caso particular sobre um determinado indivíduo.

Em uma inferência abdutiva típica, assumimos que a descrição D do domínio de um problema é suficiente, no sentido de que com a quantidade de informação disponível é possível aplicar inferências sobre ela.

Na prática, isso significa que a parte incompleta da teoria pode ser isolada em alguns predicados não observados, que são chamados de predicados abdutíveis (ou abertos).

Podemos então entender a teoria como a representação de todas as suas possíveis extensões abdutivas T 4, para cada possível hipótese abdutiva 4.

Uma enumeração de todas essas fórmulas fornecem o conjunto das possíveis extensões abdutivas de T.

A implicação abdutiva sobre T é então definida por implicações dedutivas em cada uma das extensões abdutivas.

A veracidade da inferência está condicionada à veracidade das extensões.

Indução Indução é uma forma de inferência lógica que permite extrapolar as premissas, obtendo conclusões genéricas a partir de exemplos particulares.

Nesse sentido, a indução pode ser caracterizada como uma forma de raciocínio que parte de um conceito específico e o generaliza, ou seja, da parte para o todo, do particular para o universal.

Ao contrário do que ocorre com a inferência dedutiva a partir de premissas válidas, o resultado da aplicação de inferência indutiva não preserva, necessariamente, a verdade, mesmo que o conjunto de premissas utilizado na inferência seja verdadeiro.

Por esse motivo, o resultado da inferência indutiva é geralmente chamado de hipótese.

Mesmo que não possamos garantir a validade de uma hipótese, pode-se atribuir a ela um certo grau de confiança, baseado na quantidade e qualidade das premissas, ou seja, quando as premissas utilizadas em uma inferência indutiva são verdadeiras, e existe uma quantidade suficiente de premissas, é possível dizer que uma hipótese é provavelmente verdadeira.

O aspecto essencial da indução aplicada a aprendizado de máquina refere-se à chamada inferência amostra-para-população, exemplificada pelo seguinte modelo, usualmente chamado de generalização indutiva, Todos os objetos de uma amostra satisfazem a propriedade (x).

Dessa maneira, todos os objetos na população satisfazem a propriedade (x).

Dessa forma, a inferência indutiva assume esse tipo de hipótese como válida e, similarmente a abdução, aplica inferência dedutiva para gerar novos conhecimentos.

A diferença básica entre abdução e indução reside no fato de que essas hipóteses não estão limitadas a um subconjunto particular de predicados que são incompletamente especificados na representação do domínio do problema pela teoria T, mas elas são limitadas apenas pela própria linguagem da teoria T.

Ao se acrescentar novas premissas a um argumento dedutivo válido, não se afeta a validade do argumento.

No entanto, no caso de inferência indutiva, ao se acrescentar premissas adicionais pode ocorrer uma mudança no grau de confiança do argumento.

Nesse caso, a adição de uma nova premissa pode aumentar ou diminuir a confiança de um argumento indutivo, ou até mesmo invalidá-lo.

Dedução é um dos métodos mais utilizados em IA.

Resolução, por exemplo, é um dos mecanismos de inferência lógica mais utilizados em shells de sistemas especialistas e é a base do motor de inferência da linguagem de programação lógica PROLOG.

Entretanto, dada uma teoria incompleta (ou mesmo uma teoria vazia como em muitas aplicações de mineração de dados) existem ocasiões nas quais a inferência dedutiva não é suficiente para resolver um problema.

Notadamente, podemos destacar duas classes de tarefas, a, a procura por qual porção de informação pode ser verdadeira de acordo com uma teoria geral que descreve um domínio de interesse, e b, a construção de novas teorias que descrevem o comportamento presente de um determinado processo e possam prever o seu comportamento futuro.

Claramente, para essas duas classes de problemas, inferência não-dedu-tiva é necessária para suprir a necessidade de explicação e generalização.

Devido ao seu inerente poder de explicação (utilizando uma teoria T e assumindo uma suposição 4), abdução é freqüentemente utilizada em diagnóstico e planejamento.

Em compensação, o processo de indução é um dos principais meios para se inferir novos conhecimentos e, por esse motivo, indispensável no processo de aquisição e descoberta de conhecimento.

Nesse sentido, indução é uma das formas de inferência mais utilizadas em aprendizado de máquina.

Um sistema de aprendizagem é um programa de computador que toma decisões baseadas em experiências acumuladas por meio da solução de problemas anteriores.

Os sistemas de AM possuem características particulares e comuns que possibilitam uma certa classificação quanto à linguagem de descrição, modo, paradigma, tarefa e forma de aprendizagem utilizadas nesses sistemas, resumidos na sucintamente descritos a seguir.

Características gerais de sistemas de aprendizado de máquina Segundo, para alguns sistemas de aprendizagem é necessário predizer se uma certa ação irá fornecer uma certa saída.

Nesse sentido, é possível classificar os sistemas de AM nos seguintes modos, Aprendizagem supervisionada, no qual dado um conjunto de observações ou exemplos rotulados, isto é, conjunto de observações em que a classe, denominada também atributo meta, de cada exemplo é conhecida, o objetivo é encontrar uma hipótese capaz de classificar novas observações entre as classes já existentes.

Aprendizagem não-supervisionado, no qual dado um conjunto de observações ou exemplos não rotulados, o objetivo é tentar estabelecer a existência de grupos ou similaridades nesses exemplos.

Aprendizagem semi-supervisionado, no qual dado um pequeno conjunto de observações ou exemplos rotulados e um conjunto de observações ou exemplos não rotulados, o objetivo é utilizar ambos os conjuntos para encontrar uma hipótese capaz de classificar novas observações entre as classes já existentes.

Aprendizagem semi-supervisionada é um meio termo entre aprendizagem supervisionada e não-supervisionada.

Aprendizagem por reforço, no qual o agente aprendiz interage com o meio ambiente que o cerca e aprende uma política ótima de ação por experimentação direta com o meio.

Dependendo de suas ações, o aprendiz é recompensado ou penalizado.

O objetivo do aprendiz é desenvolver uma política ótima que maximize a quantidade de recompensa recebida ao longo da sua execução.

Atualmente, já foram propostos diversos paradigmas de AM.

Nesta seção são apresentados brevemente alguns deles, tais como o paradigma simbólico, estatístico, baseado em protótipo, conexionista e genético.

Os sistemas de aprendizagem simbólica buscam aprender construindo representações simbólicas de um conceito por meio da análise de exemplos e contra-exemplos desse conceito.

As representações simbólicas estão tipicamente representadas na forma de alguma expressão lógica, árvore de decisão, regras de produção ou rede semântica.

Atualmente, entre as representações simbólicas mais estudadas estão as árvores e regras de decisão.

Métodos de indução de árvores de decisão a partir de dados empíricos, conhecidos como particionamento recursivo, foram estudados por pesquisadores da área de Inteligência Artificial e Estatística.

Os sistemas ID e C para indução de árvores de decisão tiveram uma importante contribuição sobre a pesquisa em IA.

O sistema de classificação de árvores de regressão CART foi desenvolvido por estatísticos, durante praticamente o mesmo período que o ID3, no final dos anos 70.

Os trabalhos com indução de regras de decisão surgiram com a família de algoritmos AQ, e precederam algoritmos como o CN2.

Uma outra abordagem surgiu da simples tradução das árvores de decisão para regras, com um posterior refinamento, resultando no algoritmo C45 rules.

Aprendizado simbólico de regras é discutido em maiores detalhes no Capítulo 3.

Pesquisadores em estatística têm criado diversos métodos de classificação, muitos deles semelhantes aos métodos empregados pela comunidade científica em aprendizado de máquina.

Por exemplo, o método CART, mencionado anteriormente, é um sistema muito conhecido para construir árvores de decisão, desenvolvido por estatísticos.

Como regra geral, técnicas estatísticas tendem a focar tarefas em que todos os atributos têm valores contínuos ou ordinais.

Muitos desses métodos também são paramétricos, assumindo algum modelo pré-estabelecido, e então ajustando valores apropriados para os parâmetros do modelo a partir dos dados.

Por exemplo, um modelo de classificação linear assume que as classes podem ser expressas como combinação linear dos valores dos atributos, e então procura uma combinação linear particular que fornece a melhor aproximação sobre o conjunto de dados.

Os modelos estatísticos freqüentemente assumem que os valores de atributos estão normalmente distribuídos, e então usam os dados fornecidos para determinar média, variância e co-variância da distribuição.

Alguns autores têm considerado redes neurais como métodos estatísticos paramétricos, uma vez que treinar uma rede neural geralmente significa encontrar valores apropriados para pesos pré-determinados.

Uma forma de classificar um caso é lembrar de um caso similar cuja classe é conhecida e assumir que o novo caso terá a mesma classe.

Essa filosofia exemplifica os sistemas baseados em protótipos, que classificam casos nunca vistos utilizando casos similares conhecidos.

Em sua forma mais simples, sistemas que empregam esse paradigma armazenam todos os exemplos de treinamento.

A classificação é dada pela maior quantidade de exemplos vizinhos de uma dada classe.

Essa abordagem é conhecida como k-vizinhos-mais-próximos (kNN, do inglês k-nearest-neighbours).

Outras abordagens empregam heurísticas para selecionar os exemplos armazenados.

Saber quais casos de treinamento devem ser memorizados é importante para evitar dificuldades e lentidão de manuseio por parte do modelo de classificação.

O ideal é reter apenas os casos com os quais seja possível resumir toda a informação.

Em Aha estão descritas algumas estratégias para decidir quando um novo caso deve ser memorizado.

A medida de similaridade para os casos nos quais todos os atributos são contínuos pode ser calculada por meio de alguma distância entre esses atributos.

Na presença de atributos ordinais essa medida se torna complicada, bem como na presença de atributos irrelevantes, os quais podem fazer com que dois casos similares sejam interpretados como muito diferentes.

Métodos sensíveis ao contexto, que alterem a escala dos atributos, podem melhorar estas medidas.

Raciocínio baseado em casos é uma outra família de algoritmos de aprendizado que se enquadra nesse paradigma.

Nessa abordagem, casos protótipos são construídos e exemplos são classificados com base na similaridade com esses casos protótipos.

Redes neurais são construções matemáticas relativamente simples, que foram inspiradas em modelos biológicos do sistema nervoso.

A representação de uma rede neural envolve unidades altamente interconectadas e, por esse motivo, o nome conexionismo é utilizado para descrevê-las.

As pesquisas em redes neurais foram iniciadas com o trabalho pioneiro de McCulloch & Pitts.

McCulloch era um psiquiatra e pesquisou por 20 anos uma forma de representar um evento no sistema nervoso.

Pitts era um jovem pesquisador e começou a trabalhar com McCulloch em 1942.

Praticamente 15 anos após a publicação de McCulloch e Pitts, Rosenblatt apresentou o perceptron, cuja grande contribuição foi a prova do teorema de convergência.

Mas Minsky & Papert demonstraram a existência de limites fundamentais nos perceptrons de apenas uma camada.

A pesquisa na área ficou praticamente estática até que Hopfield utilizou a idéia de uma função de energia para formular uma nova forma de compreender os cálculos realizados em redes recorrentes com conexões sinápticas simétricas.

O artigo de Hopfield em 198e o livro de Rumelhart & McClelland foram às publicações que mais influenciaram no ressurgimento do interesse sobre redes neurais na década de 80.

Redes neurais tiveram um longo caminho desde McCulloch e Pitts, e continuam a crescer em teoria, projetos e aplicações.

A metáfora biológica com as conexões neurais do sistema nervoso tem interessado muitos pesquisadores e tem subsidiado discussões sobre os méritos e as limitações dessa abordagem de aprendizagem.

Em particular, as analogias com a biologia têm levado muitos pesquisadores a acreditar que as redes neurais possuem um grande potencial na resolução de problemas que requerem intenso processamento sensorial humano, tal como visão e reconhecimento de voz e imagens.

Este formalismo de classificação é derivado do modelo evolucionário de aprendizagem.

Um modelo de classificação genético consiste de uma população de elementos de classificação que competem para fazer a predição.

Elementos que possuem um desempenho fraco são descartados, enquanto os elementos mais fortes proliferam, produzindo variações de si mesmos.

Este paradigma possui uma analogia direta com a teoria de Darwin, na qual sobrevivem os mais bem adaptados ao ambiente.

Alguns operadores genéticos básicos que aplicados a uma população geram novos indivíduos são Reprodução, Cruzamento, Mutação e Inversão.

Esses operadores atuam no controle da quantidade de cópias produzidas de um indivíduo, na troca de material genético, na preservação de uma espécie e na manutenção de uma certa diversidade na nova população.

Qualquer que seja o tipo de aprendizagem é necessário uma linguagem para descrever objetos (ou possíveis eventos), uma linguagem para descrever conceitos, ou hipóteses, e uma linguagem para descrever conhecimento de fundo.

AM utiliza vários tipos de linguagem de descrição, entre elas representações equivalentes à lógica proposicional e relacional, agrupamentos, hierarquias de conceitos e redes probabilísticas.

Mais detalhes sobre linguagens de descrição são apresentados na Seção 31.

Os algoritmos de aprendizagem podem ser classificados de duas maneiras, segundo o modo em que os exemplos são apresentados não incremental que necessita que todos os exemplos estejam disponíveis simultaneamente para que seja induzido um conceito.

É vantajoso usar esses algoritmos para problemas de aprendizagem nos quais todos os exemplos estão disponíveis e, provavelmente, não irão ocorrer mudanças incremental que revê a definição do conceito corrente, se necessário, em resposta a cada novo exemplo observado.

Os exemplos observados são considerados um a um pelo sistema, isto é, o sistema considera o primeiro exemplo e, de acordo com esse exemplo constrói uma determinada hipótese.

A seguir considera um segundo exemplo, que pode ou não modificar a primeira hipótese, baseando-se em como ela classifica o segundo exemplo.

Dessa forma, o sistema continua modificando o conceito à medida que mais exemplos são a ele apresentados.

Uma das vantagens de usar um algoritmo incremental é que o conhecimento pode ser rapidamente atualizado a cada nova observação.

Porém, eventualmente, pode ser mais eficiente revisar uma hipótese existente do que gerar uma nova hipótese cada vez que um novo exemplo é observado.

Em geral, em problemas de aprendizado supervisionado, cada exemplo é descrito por um vetor de valores de características e por um atributo especial que descreve uma característica de interesse na qual estamos interessados em criar o modelo.

Esse atributo pode ser discreto, ordinal ou contínuo.

No caso do atributo discreto, o problema é conhecido como problema de classificação, e o objetivo é classificar futuros casos em cada uma das classes pré-estabelecidas.

Caso o atributo seja contínuo, o problema é geralmente conhecido como problema de regressão, e o objetivo é prever o valor desse atributo com base nas características dos exemplos.

No caso do atributo meta ser ordinal, o problema é conhecido como ordenação ou regressão logística, e o objetivo é ordenar um conjunto de casos de acordo com uma característica de interesse.

Note que mesmo que os problemas sejam definidos de acordo com o tipo do atributo meta, é possível utilizar variáveis de outros tipos para cumprir a tarefa.

Por exemplo, é possível discretizar um atributo meta contínuo e prever uma faixa de valores (o atributo discretizado) ao invés de um valor contínuo.

Também é possível prever um valor contínuo para um problema com atributo meta discreto.

Nesse caso, cada classe pode ser associada a uma faixa de valores contínuos.

Além disso, é possível "calibrar" essas faixas, para melhorar o desempenho.

No capítulo 8, essa idéia é aplicada na ordenação de exemplos em problemas de classificação ordenação binári.

O objetivo principal das pesquisas em AM é construir máquinas capazes de aprender por experiência.

Neste trabalho, utilizaremos a definição de AM dada por Mitchell, que inclui qualquer programa de aprendizagem que melhora o seu desempenho em uma dada tarefa utilizando alguma experiência.

Mais precisamente, "Diz-se que um programa de computador aprende a partir da experiência E com respeito a algumas classes de tarefas T e uma dada medida de desempenho P se o seu desempenho nas tarefas T, medidas por P, melhoram com a experiência E" Por exemplo, um programa de computador capaz de aprender a jogar xadrez pode ter como medida de desempenho a sua habilidade em vencer no que se refere à classe de tarefas jogar xadrez, utilizando como experiência jogos de xadrez contra si próprio.

A questão da aprendizagem é essencial em IA, uma vez que ser ou não capaz de aprender é uma habilidade essencial para um sistema apresentar qualquer comportamento inteligente.

Em AM, estudam-se métodos computacionais capazes de melhorar o seu desempenho pela aquisição de novos conhecimentos, novas habilidades e novos meios de organizar o conhecimento já existente.

O estudo de métodos de aprendizagem pode levar a um melhor entendimento da nossa própria inteligência e do nosso excepcional processo de aprendizagem, inferência, adaptação e indução.

Em AM, estuda-se como modelar o processo de aprendizagem.

Em qualquer processo de aprendizagem, o aprendiz deve utilizar os conhecimentos que possui pra obter novos conhecimentos.

Neste trabalho nos concentramos em aprendizagem simbólico supervisionado utilizando classificação e ordenação binária.

O termo simbólico indica que os modelos induzidos devem ser legíveis e interpretáveis por humanos.

O termo supervisionado sugere que algum processo, algumas vezes denominado agente externo ou professor, previamente rotulou os dados disponíveis para a aprendizagem.

Finalmente, o termo classificação denota o fato que o conceito meta (o atributo rotulado) a ser aprendido é discreto, ou seja, ele consiste de valores nominais, e o termo ordenação binária significa que queremos ordenar os exemplos da classe de interesse à frente dos outros exemplos.

Na aprendizagem supervisionada por exemplos, geralmente, o aprendiz induz uma hipótese H que descreve um conceito C a partir de um conjunto de exemplos e contra-exemplos E.

Por exemplo, o conceito "é verde" divide o mundo em todos os objetos que são e os que não são verdes.

Ao algoritmo de aprendizagem são apresentados exemplos do conceito, e, para cada exemplo, é dito se ele é um exemplo positivo ou negativo do conceito.

Ao universo de objetos para os quais são apresentados exemplos ao aprendiz é chamado de domínio D (ou espaço de descrição dos exemplos) e cada objeto do domínio representa um exemplo.

No caso do conceito "é verde", o domínio pode consistir de todas as frutas do planeta, e os exemplos apresentados ao aprendiz seriam a descrição de algumas frutas conhecidas.

Esse descrição é normalmente realizada utilizando um conjunto de atributos que descrevem características particulares de cada exemplo.

No caso das frutas, haveriam atributos como tamanho, forma, origem, quantidade de sementes, etc.

Dentre esses atributos, o atributo meta aprendizagem supervisionad distingue os exemplos positivos dos negativos.

No caso das frutas, o atributo meta seria a cor da casca.

Também podem ser fornecidos ao aprendiz algum conhecimento prévio a respeito do domínio, com o objetivo de guiar/direcionar a indução do conceito meta.

Por exemplo, poderia ser dada informação que algumas frutas, antes de amadurecerem são verdes, mas que posteriormente mudam a cor.

A tarefa do aprendiz é induzir uma hipótese capaz de distinguir os exemplos positivos (valor do atributo meta "é verde") dos negativos.

Bratko formaliza o problema de aprendizagem como, Seja U o conjunto universal dos objetos, isto é, todos os objetos que o aprendiz pode encontrar.

Não existe limites, a princípio, para o número de exemplos de U.

Um conceito C pode ser formalizado como sendo um subconjunto de objetos de U, ou seja, C U.

Aprender um conceito C significa aprender a reconhecer objetos em C.

Ou seja, uma vez que o conceito C é aprendido, para qualquer objeto x U, o sistema deve ser capaz de reconhecer se Esse descrição pode ser estendida para problemas de mais de duas classes (conhecidos como problemas multi-classe) ou para atributos metas contínuos ou ordenação.

No caso de problemas multi-classe, pode-se relaxar a definição do conceito C para representar um conjunto discreto de n classes C {c,c,c }, de tal maneira que o objetivo é reconhecer se um objeto x pertence a uma das n classes.

No caso de regressão, relaxamos mais uma vez a definição do conceito C para representar um valor numérico C R, e o objetivo é predizer esse valor numérico.

Da mesma maneira, no caso de ordenação, relaxamos a definição do conceito C para um valor numérido C N.

Considerando essas extensões, podemos redefinir o problema de aprendizagem como, Seja D o domínio do conjunto universal de objetos U e C o domínio do conceito C a ser aprendido.

O objetivo da aprendizagem é encontrar uma função H, D C, que represente uma hipótese H, que aproxime a função F desconhecid que mapeia U em C, ou seja, F, D C.

Para determinar se o aprendiz teve sucesso em "aprender" o conceito, pode ser feito um teste, é apresentado um conjunto de exemplos cujos valores do atributo meta são conhecidos, mas omitidos para fins de avaliação, e verifica-se o quão apropriadamente a hipótese H aproxima F.

Um outro fator importante que deve ser considerado quanto à avaliação de hipóteses é que elas devem fornecer uma descrição mais compacta do conceito embutido nos exemplos.

Ou seja, supondo um conjunto de exemplos com cardinalidade M, espera-se que o modelo induzido tenha uma descrição menor do que M, pois, caso contrário, os dados descreveriam melhor a si próprios e de forma mais compacta.

O tamanho do modelo influencia no quão compreensível é um modelo para os humanos.

Além do tamanho do modelo, um outro fator que influencia na compreensão de modelos é a linguagem de descrição das hipóteses.

De acordo com, modelos de classificação podem ser agrupados em duas grandes categorias, 1 sistemas caixa-preta, que desenvolvem sua própria representação do conceito, isto é, sua representação interna pode não ser facilmente interpretada por humanos e não fornecem nem esclarecimento nem explicação do processo de reconhecimento de novos exemplos.

Sistemas orientados a conhecimento, que objetivam a criação de estruturas simbólicas que sejam compreensíveis por humanos.

Na realidade, uma distinção interessante dessas duas categorias foi formulada por Michie em termos de três critérios, critério fraco, o sistema usa exemplos para manter uma base atualizada para a melhoria do desempenho em exemplos subseqüentes.

Métodos baseado em protótipos satisfazem este critério, critério forte, o critério fraco é satisfeito.

Além disso, o sistema é capaz de comunicar sua representação interna em forma simbólica explícita.

Critério ultra-forte, os critérios fraco e forte são satisfeitos.

Além disso, o sistema é capaz de comunicar sua representação interna em forma simbólica explícita, a qual pode ser usada por um humano sem a ajuda de um computador, ou seja, utilizando apenas a mente humana.

Neste trabalho nos focalizamos na aprendizagem de conceitos, cujo interesse principal consiste em obter descrições simbólicas que sejam facilmente compreendidas por seres humanos, utilizando apenas modelos mentais.

Mais precisamente, nos concentraremos no estudo de sistemas orientados a conhecimento e que satisfazem os critérios forte ou ultra-forte, ou seja, sistemas de aprendizagem que aprendem no nível de conhecimento.

Inferência lógica é um dos recursos mais utilizados em IA para manipular conhecimento.

Inferência indutiva é capaz de a partir de um conjunto de observações que especificam um conhecimento incompleto (geralmente ex-tensional) sobre as observações, generalizá-las em novos conhecimentos a respeito das observações.

Por esse motivo, inferência indutiva é largamente utilizada em aprendizado de máquina.

Neste capítulo foi apresentada uma breve introdução ao aprendizado de máquina a partir de exemplos.

Primeiramente foram apresentadas algumas considerações sobre inferência lógica e aprendizado de máquina.

Também foram apresentadas as principais características de sistemas de aprendizado.

No próximo capítulo é apresentado em maiores detalhes a indução de regras a partir de exemplos.

UMA das contribuições desta tese está relacionada à indução de regras, descritas no Capítulo 5.

Para fornecer ao leitor um plano de fundo à leitura desta tese, neste capítulo é apresentada uma introdução à indução de regras.

Na Seção 32, aprendizado de regras é formalizado como um problema de busca.

Nas Seções 3e 3são apresentados, respectivamente, o aprendizado de uma única regra e de um conjunto de regras.

Na Seção 35 é apresentada a indução de árvores de decisão.

Na Seção 36 são descritas algumas medidas de avaliação de regras.

Finalmente, na Seção 37 são apresentadas as considerações finais do capítulo.

Qualquer que seja o tipo de aprendizado, é necessária uma maneira de descrever exemplos, modelos e conhecimento do domínio.

Para descrevê-los, as seguintes linguagens de representação (ou linguagens de descrição são usadas), Linguagens de descrição de exemplos.

Linguagens de descrição de hipóteses.

Linguagens de descrição de conhecimento do domínio.

A seguir são descritas algumas linguagens de representação freqüentemente utilizadas em AM simbólico em ordem crescente de complexidade e força expressiva.

No caso de AM simbólico, as linguagens de descrição mais freqüentemente utilizadas, em ordem crescente de complexidade e força expressiva, são, de ordem zero, baseada em atributos e baseada em lógica de primeira ordem.

Lógica de Ordem Zero ou Proposicional Na lógica de ordem zero ou cálculo proposicional, o item a ser representado é descrito por conjunções, disjunções e negações de constantes booleanas que representam atributos individuais.

Por exemplo, Esta linguagem tem um baixo poder descritivo, não sendo capaz de descrever objetos sobre os quais relações são observadas.

Lógica de Atributos De forma a representar itens, vários algoritmos proposicionais utilizam uma linguagem baseada em atributos.

Formalmente, a lógica de atributos é equivalente à lógica proposicional, mas emprega uma notação mais poderosa e flexível.

Essa forma de notação é comumente conhecida como formato atributo-valor.

A melhoria ocorre pois os atributos são tratados como variáveis que podem assumir diversos valores.

Por exemplo, sexo=feminino idade=adulta classe=pode_ter_filhos Embora a maioria dos algoritmos de AM utilize a lógica de atributos para descrever exemplos e hipóteses, sua baixa capacidade de expressão impede a representação de objetos estruturados, assim como as relações entre objetos ou entre seus componentes.

Dessa maneira, aspectos relevantes dos exemplos que, de alguma maneira poderiam caracterizar o conceito sendo aprendido, podem não ser representados.

Lógica de Primeira Ordem Para superar as limitações de representação impostas por uma linguagem de atributos, o aprendizado utilizando representações que possuem maior poder, tais como algumas variada lógica de primeira ordem, tem recebido maior atenção.

A lógica de primeira ordem permite descrever e raciocinar sobre objetos e predicados que especificam propriedades de objetos ou relacionamentos entre objetos do domínio.

Um subconjunto importante da lógica de primeira ordem é composto pelas cláusulas de Horn.

Uma cláusula de Horn consiste em uma regra cuja cabeça contém um único predicado e um corpo com zero, um ou mais predicados.

O seguinte exemplo, na sintaxe proposta por para a linguagem de programação lógica PROLOG, descreve que uma pessoa X é irmão da pessoa Y se X é homem e ambos X e Y possuem o mesmo pai Z, na qual X, Y e Z são variáveis que representam objetos.

O elemento à esquerda do símbolo,-é a cabeça e o que está direita do símbolo é o corpo ou caud da cláusula.

O símbolo,-é equivalente à implicação lógica e é denominado neck.

As vírgulas separando cada predicado significam conjunções lógicas.

Além disso, todas as variáveis estão sempre universalmente quantificadas, ou seja, no exemplo acima, a cláusula é verdadeira para todo X,Y,Z D.

As variáveis entre parênteses são chamadas de argumentos.

Nota-se que se todos os predicados não possuem argumentos, a linguagem se reduz à lógica de ordem zero e se todos os predicados possuem um único argumento constante, a linguagem se reduz à lógica de atributos.

Neste trabalho trataremos de algoritmos que usam linguagens baseadas em atributos para descrever os exemplos e as hipóteses por eles induzidas.

Deve ser observado que apesar da maioria dos sistemas de aprendizado utilizarem lógica de atributos, eles são limitados devido à pouca expressividade do formalismo representacional e a capacidade limitada de utilizar conhecimento do domínio.

Em contrapartida, algoritmos simbólicos que usam linguagens baseadas em lógica de primeira ordem ou superiores, chamados de sistema de aprendizado relacional, dentre os quais destacam-se os algoritmos de Programação Lógica Indutiva (ILP), possuem uma alta expressividade para representar conceitos e a habilidade de representar conhecimento do domínio.

Entretanto, eles são mais complexos e exigem um alto poder computacional para a resolução de problemas reais.

Um algoritmo para a indução de regras de classificação recebe como entrada um conjunto de casos ou exemplos cuja classificação é conhecida.

Um caso é descrito por um conjunto fixo de atributos, A, i {1,n }.

Um atributo pode tanto assumir um conjunto finito de valores (atributo discreto ou qualitativo) ou um número real (atributo contínuo ou quantitativo).

Um exemplo e é um vetor de valores de atributos rotulado com a sua respectiva classe, ou seja, e = (v,v,c), no qual cada v é um possível valor do atributo A e c é uma dos n possíveis valores do atributo classe.

Um conjunto de dados de cardinalidade n é um conjunto contendo Conjunto de exemplos no formato atributo-valor.

Para induzir um modelo de classificação, o algoritmo de aprendizado supervisionado utiliza uma amostra de exemplos ou casos para os quais se conhece a classificação verdadeira.

Cada caso é descrito por um conjunto de atributos.

Para se distinguir casos entre as possíveis classificações, cada caso é rotulado com um atributo especial, denominado classe, cujos valores se referem à classificação verdadeira dos casos.

Casos rotulados são chamados de exemplos, e a amostra é geralmente chamada de conjunto de exemplos de treinamento.

Suponha que se tenha um conjunto de dados de registros de pacientes com os respectivos diagnósticos, com o qual queiramos induzir um conjunto de regras para um diagnóstico ou prognóstico.

Neste tipo de problema, é comum que cada registro de paciente seja descrito por alguns atributos que podem ser contínuos (por exemplo a idade) ou discretos (por exemplo o sexo do paciente, que pode ser masculino ou feminino).

Na stão contidas informações simplificadas do problema de prescrição de lentes de contato.

Nessa tabela, os pacientes são descritos por quatro atributos, Idade, tipo de lentes prescritas, Astigmatismo e taxa de produção de lágrimas (Produção lacrimal).

Os registros dos pacientes são rotulados com três possíveis rótulos de classes, denotando o tipo de lentes de contato prescritas a um dado indivìduo, C = {nenhuma, macia, dura}.

Conjunto de dados de lentes de contato.

É importante observar que este conjunto de dados é completo, no sentido de que todas as possíveis combinações de valores de atributos estão presentes.

Neste caso, o algoritmo de aprendizagem não pode generalizar além da classificação que já está presente no conjunto de treinamento.

Na prática, o objetivo da aprendizagem neste caso pode ser entendido como a transformação dos dados em uma forma mais compacta, sem perder o poder de classificação.

Além disso, deve ser observado que todos os quatro atributos da tabelapossuem valores discretos.

Para três dos quatro atributos, Spectropia, Astigamatismo e Produção lacrimal, esta é a representação mais natural.

Por sua vez, Idade seria naturalmente melhor representado por um atributo numérico.

Por simplicidade, esse atributo foi discretizado em três valores, jovem, pre-presbiotico e presbiotico.

Essa discretização foi feita por um especialista, para indicar as categorias de idade que se encaixam os pacientes com características específicas.

Esses valores também poderiam ser discretizados em intervalos tanto no processamento dos dados ou no próprio processo de indução de regras.

A discretização de atributos é uma caracteristica muito importante na representação do conhecimento, mas foge do escopo deste trabalho.

Dado um conjunto de exemplos classificados, um algoritmo de aprendizagem de regras constrói um conjunto de regras do tipo if-then.

Uma regra if-then tem o formato, A última forma é geralmente utilizada em lógica de predicados como uma forma geral de regras na qual o Corpo (também chamado de antecedente) é uma conjunção de condições ou literais, e a Cabeça é o conseqüente que, no caso de regras if-then, é um simples literal (no caso geral, ela também pode ser uma disjunção de literais).

Um exemplo de um conjunto de regras induzidas utilizando o CNClark & Niblett.

Clark & Boswell para o domínio de prescrição de lentes de contados é mostrado no Exemplo 31.

Os números entre colchetes indicam a quantidade de exemplos do conjunto de treinamento, para cada uma das classes, cobertos pela regra.

A classe com mais exemplos cobertos corresponde àquela prevista pela regra.

A primeira e a terceira regra são consistentes, enquanto que as outras duas regras classificam erroneamente um exemplo cada uma.

Em geral, simplesmente ignoram-se os números correspondentes à distribuição de exemplos cobertos entre as classes, sendo as regras interpretadas categoricamente.

Os números correspondentes à distribuição de exemplos cobertos entre as classes podem ser utilizados para medir a confiança ou significância de uma dada regra.

Por exemplo, pode-se considerar a quarta regra do Exemplo 31 pouco confiável pois a diferença entre o número de exemplos entre as duas classes mais cobertas nenhuma e dur é de apenas 1 exemplo.

Mais detalhes sobre a avaliação de regras são discutidos na Seção 36.

Além disso, esses números também poder ser utilizados como estimativa de probabilidade sobre todas as classes, ao invés de fazer apenas uma predição categórica.

Por exemplo, se a descrição do paciente satisfaz a condição da segunda regra, pode-se utilizá-la para predizer uma lente macia com probabilidade 5/6 = 0833 ou nenhuma lente com probabilidade 1/6 = 01666 É importante ressaltar que, na segunda regra, a condição Produção lacrimal = normal é a negação da condição da primeira regra, e que essa restrição é incluída em todas as outras regras subseqüentes.

Da mesma maneira, a condição Astigmatismo = sim presente na terceira regra é a negação da segunda condição na segunda regra, e assim em diante.

Neste sentido, o conjunto de regras pode ser equivalentemente representado por uma lista de decisão, como mostrado no Exemplo 32.

Alternativamente, toda a hipótese pode ser vista como uma árvore binária na qual cada ramo da esquerda leva a uma folha.

Conjuntos de regras, listas e árvores de decisão são formas de representação fortemente correlacionadas e todas elas são utilizadas em AM simbólico.

Em geral, essas três formas de representação compartilham muitas semelhanças.

Entretanto, existe uma diferença fundamental entre listas e árvores de decisão e conjuntos de regras não ordenados.

Listas e árvores Note que, no caso geral, isso não necessariamente ocorre de decisão dividem o conjunto de exemplos em regiões disjuntas.

Esse fator implica que cada exemplo é classificado por somente uma única regra no caso da lista de decisão, a primeira regra disparad ou ramo da árvore.

Essa disjunção não ocorre, necessariamente, em conjuntos de regras não ordenados.

Para regras não ordenadas, no caso de mais de uma regra disparar para um dado exemplo, as suas previsões precisam ser combinadas, por exemplo, utilizando algum esquema de votação.

Além disso, assim como uma lista de decisão pode ser representada como uma árvore binária, uma árvore de decisão também pode ser representada como um conjunto de regras.

Entretanto, regras não ordenadas não podem ser representadas como árvores, apenas como grafos.

Como dito na seção 312, regras geralmente assumem o formato if Condições then Conclusão, no qual Condições representa um conjunção de restrições sobre os atributos e Conclusão tem a forma Classe = c.

Representações alternativas para uma regra são Classe Condições, ou Cabeça Corpo.

Um algoritmo de aprendizagem produz uma hipótese ou modelo representado como um conjunto de regras.

A construção dessa hipótese geralmente envolve quatro estágios, Construção da hipótese.

Para construir uma hipótese, o sistema de aprendizagem deve encontrar um conjunto de regras.

Em aprendizagem envolvendo linguagens de representação de hipóteses equivalentes a lógica proposicional, esse estágio pode ser simplificado pela indução de regras seqüencialmente e independentemente, por exemplo, aplicando um algoritmo de cobertura.

Em aprendizagem envolvendo linguagens de representação equivalente à lógica de primeira ordem a situação passa a ser um pouco mais complexa no caso da recursão ser empregada, pois as regras não podem ser induzidas independentemente.

Construção da regra.

Uma regra individual no formato Cabeça Corpo é geralmente construída fixando-se a cabeça para um dado valor de Classe = c e, a partir daí, heuristicamente buscar pelo melhor corpo da regra.

Construção do corpo da regra.

Tipicamente, o corpo da regra é uma conjunção de condições.

Para regras com o poder de representação equivalente à lógica proposicional, a construção do corpo da regra é geralmente feita pelo seu refinamento, adicionando condições ao corpo inicialmente vazio.

Construção de cada condição da regras No caso mais simples, como mencionado anteriormente, condições têm o formato de simples literais A = v, no qual A é um atributo e v é um dos possíveis valores que atributo pode assumir.

No caso de atributos numéricos ou ordinais, pode-se também considerar desigualdades da forma A < v ou A > v, no qual v é um limiar a ser construído (isto é, ele pode assumir um valor não diretamente observado nos dados de treinamento).

Entretanto, outras formas de construção de condição podem ser encontradas na literatura.

Surpreendentemente, a tarefa crucial de construção das condições de cada uma das regras não é muito explorada na literatura relativa à indução de regras.

Entretanto, existem trabalhos na literatura a respeito da construção de atributos.

A construção de condições pode ser vista como um caso particular da construção de atributos (imagine que cada condição é um atributo binário, com valor verdadeiro se esse atributo satisfaz a condição e falso caso contrário).

Induzir um conjunto de regras de classificação pode ser entendido como um problema de busca, no qual o espaço de possíveis hipóteses é determinado pela linguagem de descrição de hipóteses utilizada.

Em aprendizagem de regras do tipo if-then, o espaço de hipóteses é limitado por todas as possíveis regras no formato Classe Condições, com a Classe assumindo um dos seus possíveis valores, e Condições sendo uma conjunção de restrições para alguns atributos, como descrito anteriormente.

Por simplicidade, nesta seção, nos restringiremos a condições do tipo A = v (a igualdade pode também ser substituída por desigualdades quando o atributo A é contínuo).

Considerando o aprendizado de regras como um problema de busca, um critério de avaliação (por exemplo a taxa de acerto ou significância-Seção 3precisa ser definida para se decidir quando uma regra candidata (ou um conjunto de regras) é a solução encontrada para um dado problema.

Enumerar todo o espaço de possíveis regras é claramente ineficiente e, dessa maneira, é necessário uma estrutura que permita explorar somente parte do espaço de hipóteses.

A maioria dos algoritmos de aprendizagem indutiva simbólica estrutura o espaço pela utilização de uma noção dual de generalização e especialização.

Uma das maneiras de definir generalidade é em termos de cobertura.

Seja a função cobertos(R) definida como o conjunto de exemplos cobertos pela regra R.

Pode-se definir a regra R como sendo mais geral que a regra R' se, i-ambas têm o mesmo conseqüente e, -cobertos(R) cobertos(R').

Essa definição é normalmente chamada de noção semântica da generalidade, uma vez que ela requer que sejam avaliadas regras com relação a um dado conjunto do dados.

Entretanto, para o aprendizado regras do tipo if-then atributo-valor, pode-se utilizar uma simples noção sintática, dada um mesmo conseqüente, uma regra R é mais geral que uma regra R' se o antecedente de R' impõe, pelo menos, as mesmas restrições que R.

Também se diz que R' é mais específica que R.

Para exemplificar esse conceito, considere duas regras induzidas a partir do conjunto de exemplos lentes de contato-Exemplo 31, na página 33.

Claramente, a segunda regra impõe pelo menos as mesmas restrições que a primeira e é, dessa maneira, mais específica.

Em termos de cobertura, enquanto a primeira regra cobre 6 exemplos da tabela, a segunda cobre apenas 3.

No caso de atributos contínuos, condições envolvendo desigualdades são comparadas da maneira óbvia, por exemplo, a condição Idade < 30 é mais geral que a condição Idade < 20, que por sua vez é mais geral que a condição Idade < 10.

Note que a generalidade ignora o rótulo da classe de cada exemplo.

Em contrapartida, uma vez que uma regra mais específica cobrirá o mesmo conjunto ou um subconjunto dos exemplos de cada classe cobertos por uma regra mais geral, tornar uma regra mais específica ou especializá-l é uma maneira de obter uma regra mais consistente que cubra exemplos somente de uma classe.

Por exemplo, em comparação com a primeira regra acima, a segunda regra é capaz de remover os dois exemplos incorretamente cobertos pela primeira, mas pagando o preço de cobrir menos um exemplo corretamente coberto do que a primeira regra.

O aprendizado de regras pode ser visto como um meio termo entre precisão (a proporção de exemplos corretamente cobertos) e a cobertura (a proporção de exemplos cobertos).

No aprendizado de uma única regra, a maiorias dos algoritmos de aprendizado utiliza umas das seguintes estratégias, Geral-para-específico ou abordagem top-down.

Nessa categoria, os algoritmos iniciam pela regra mais geral e repetidamente especializam essa regra enquanto ela cobrir exemplos negativos.

A especialização termina quando a regra não é mais inconsistente, não cobre exemplos negativos.

Durante a busca, algoritmos geral-para-específico asseguram que as regras induzidas cobrem pelo menos um exemplo positivo.

Enquanto constroem a regra, os algoritmos utilizam um operador de refinamento que computa uma série de especializações sobre a regra.

Específico-para-geral ou abordagem botom-up.

Os algoritmos que estão nessa categoria começam pela regra mais específica que cobre um dado exemplo positivo.

Então generalizam a regra até que ela não possa mais ser generalizada sem cobrir exemplos negativos.

A primeira abordagem geralmente induz regras mais gerais do que aquelas induzidas pela segunda abordagem.

A busca geral-para-específico é apropriada para o aprendizado na presença de ruído porque ela pode ser facilmente guiada por heurísticas.

A busca específico-para-geral é geralmente aplicável em situações nas quais poucos exemplos estão disponíveis ou para aplicações de aprendizado incremental.

Na abordagem geral-para-específico, o conceito de operador de refinamento é de fundamental importância.

Em aprendizado a partir de exemplos no formato atributo-valor, para uma regra R do tipo if Condições then Conclusão, um refinamento R' de R é obtido pela adição de uma condição Nova Condição à conjunção de condições no corpo da regra, de tal maneira que a regra R' torne-se if Condições and Nova Condição then Conclusão.

Utilizando o operador de refinamento, é fácil definir um procedimento de busca geral-para-específico para a indução de regras gerais.

O algoritmo é descrito brevemente no Algoritmo 31.

Esse algoritmo utiliza uma heurística para selecionar o melhor refinamento da regra atual a cada iteração.

Algumas heurísticas comumente usadas incluem precisão de Laplace, entropia ou cobertura, discutidas na Seção 36.

Essa estratégia é uma clássica busca em feixe do tipo hill-climbing.

Algoritmos que utilizam ambas as estratégias geral-para-específico e específico-para-geral repetem o procedimento de induzir uma única regra em um conjunto reduzido de exemplos no caso da regra construída não cobrir todos os exemplos positivos.

Dessa maneira, esses algoritmos utilizam um processo iterativo para construir uma hipótese disjuntiva consistindo de um conjunto regras.

Um das abordagens mais utilizadas para se construir esse conjunto é o algoritmo conhecido como cobertura de conjunto, juntamente com busca geral-para-específico, mostrado no Algoritmo 32.

O algoritmo de cobertura de conjunto constrói repetidamente uma nova regra até que todos os exemplos positivos E da classe c sejam cobertos pelo conjunto de regras, ou algum outro critério de qualidade pré-definido é satisfeito.

Uma vez que uma regra é adicionada ao modelo, todos os exemplos positivos cobertos por aquela regra são removidos do conjunto de exemplos positivos.

Para encontrar a melhore regra, o procedimento APRENDA UMA REGRA é aplicado.

Procedimento APRENDACONJUNTODEREGRAS.

O algoritmo de cobertura de conjunto pode ser entendido da seguinte maneira, cada regra no conjunto de regras cobre uma região do espaço de exemplos e atribui a essa região uma classe.

O papel de um exemplo positivo (para uma dada classe) é forçar a atenção do algoritmo de aprendizado para uma área particular do espaço de exemplos.

Já o papel dos exemplos negativos é previnir uma super-generalização, assegurar que outras áreas do espaço de exemplos não sejam cobertas pela regra.

Exemplos positivos devem ser cobertos por pelo menos uma regra, enquanto que exemplos negativos não deveriam ser cobertos por nenhuma regra.

Esse fato explica porque quando se constrói uma nova regra somente os exemplos positivos são removidos.

Os exemplos negativos são deixados para previnir super-generalização na construção de novas regras.

Deve ser notado que a remoção de exemplos durante o treinamento distorce as estatísticas do conjunto de aprendizado e introduz uma certa dependência de ordem entre as regras.

Por exemplo, a última regra aprendida é muito dependente das regras previamente aprendidas e os exemplos positivos que elas cobrem.

Essa última regra pode não ser estatisticamente significante, pois foi induzida com poucos exemplos.

Uma variação do algoritmo de cobertura de conjunto pode ser obtida pela introdução de pesos aos exemplos, os quais decrescem a medida que o número de regras cresce.

O procedimento descrito anteriormente é apropriado para a resolução de problemas com classes binárias.

Ele induz regras somente para a classe positiva, e se uma delas dispara, o exemplo é classificado como positivo.

Se nenhuma das regras disparar, ele é classificado como negativo.

Para problemas multiclasse, para se induzir regras para todas as classes c, i = 1 n o procedimento APRENDACONJUNTODEREGRAS é repetido para cada uma das classes.

A cada iteração uma das classes é designada como positiva e o restante das classes são agrupadas na classe negativa.

Dessa maneira, são criados vários conjuntos de regras para cada uma das classes.

Esses conjuntos de regras são então reunidos em um único conjunto para formar o conjunto final de regras.

Esse procedimento é conhecido como indução de regras não ordenadas.

Quando da classificação de um novo exemplo, todas as regras são testadas e a predição de todas as regras que cobrem o exemplo são coletadas.

Um mecanismo de votação é geralmente utilizado para decidir qual é a classificação final do exemplo.

Por exemplo, no sistema CN, as classificações conflitantes são resolvidas levando-se em consideração o número de exemplos de cada classe utilizados para induzir o modelo coberto por cada uma das regras.

Por exemplo, considere que tenhamos um problema de três classes e as duas regras que cobrem um determinado exemplo que se queira classificar têm a seguinte cobertura de exemplos no conjunto de treinamento, e, a primeira regra cobre 10 exemplos da primeira classe, um da segunda e dois da terceira e a segunda regra cobre exemplos da primeira classe, 15 da segunda e nenhum da terceira.

A cobertura "somada" seria e o exemplo seria classificado como sendo da segunda classe, pois ela é a mais freqüente na cobertura "somada".

Uma outra abordagem comum para alguns algoritmos de aprendizado de regras é a indução de regras não ordenadas ou listas de decisão.

Quanto ao algoritmo que induz a lista de decisão, a maior diferença com relação ao Algoritmo 3está no fato de que ao invés de remover apenas os exemplos corretamente cobertos pela regra, todos os exemplos cobertos por ela são removidos.

A razão está relacionada ao fato que a classificação de um novo exemplo em uma lista de decisão é dada pela primeira regra que cobre àquele exemplo.

Dessa maneira, não é possível que novas regras cubram os exemplos incorretamente cobertos pela regra, e não há a necessidade de deixá-los no conjunto de treinamento.

Árvore de Decisão A é um dos métodos mais consagrados em aprendizado de máquina simbólico supervisionado.

Algoritmos que induzem árvores de decisão pertencem à família de algoritmos Top Down Induction of Decision Trees (TDIDT).

É mostrado um exemplo de uma árvore de decisão induzida a partir do conjunto de dados.

Uma árvore de decisão é uma estrutura de dados definida recursivamente como, Exemplo de árvore de decisão.

Um nó folha que corresponde a uma classe ou um nó de decisão que contém um teste sobre algum atributo (condição).

Para cada resultado do teste existe uma aresta para uma subárvore.

Cada subárvore tem a mesma estrutura que a árvore.

Para classificar um novo exemplo, basta começar pela raiz da árvore (nó inicial da árvore), seguindo cada nó de decisão de acordo com o valor do atributo do novo exemplo até que uma folha seja alcançada.

Quando uma folha é alcançada, a classificação é dada pela classe correspondente ao nó folha.

O método para a construção de uma árvore de decisão a partir de um conjunto de treinamento E é surpreendemente simples.

Assumindo que as classes do conjunto de exemplos de treinamento são {c,c,c }, os seguintes passos devem ser seguidos, E contém um ou mais exemplos, todos pertencentes à mesma classe c.

Nesse caso, a árvore de decisão para E é um nó folha rotulado pela classe c.

E não contém exemplos.

Novamente, nessa situação, a árvore é uma folha mas a classe associada à folha deve ser determinada a partir de informação além de E.

Por exemplo, a classe mais freqüente para o nó-pai desse nó pode ser utilizada.

E contém exemplos que pertencem a várias classes.

Nesse caso, a idéia é dividir E em subconjuntos de exemplos que são (ou aparentam ser) conjuntos de exemplos mais "puros", conjuntos com um número maior de exemplos de uma única classe.

Normalmente, um teste é escolhido baseado em um único atributo que possui resultados mutuamente exclusivos (na realidade, cada sistema tem sua própria forma de escolher o atributo que será utilizado no teste).

Sejam os possíveis resultados do teste denotados por {O,O,O }.

E é então particionado em subconjuntos E, E.
E, nos quais cada E contém todos os exemplos em E que possuem como resultado daquele teste o valor O.

A árvore de decisão para E consiste em um nó interno identificado pelo teste escolhido e uma aresta para cada um dos resultados possíveis.

Os passos 1, e são aplicados recursivamente para cada subconjunto de exemplos de treinamento de maneira que, em cada nó, as arestas levam para as subárvores construídas a partir do subconjunto de exemplos E E.

O ponto principal de um algoritmo de aprendizado por AD, algoritmos que usam AD como linguagem de descrição de hipóteses, depende do critério utilizado para escolher o atributo que particiona o conjunto de exemplos em cada iteração.

Algumas possibilidades para escolher esse atributo são, aleatória seleciona qualquer atributo aleatoriamente.

Menos valores seleciona o atributo com a menor quantidade de valores possíveis.

Mais valores seleciona o atributo com a maior quantidade de valores possíveis.

Ganho máximo seleciona o atributo que possui o maior ganho de informação esperado, seleciona o atributo que resultará no menor tamanho esperado das subárvores, assumindo que a raiz é o nó atual.

Índice Gini seleciona o atributo baseado na estatística Gini, utilizado no sistema CART e razão de ganho seleciona o atributo ponderando o ganho de informação esperado em relação ao nó pai, utilizado no sistema C45.

Após a construção da árvore de decisão, é possível que a árvore induzida seja muito específica para o conjunto de treinamento.

Nesse caso, diz-se que a AD superajustou os dados de treinamento, ou seja, ocorreu um overfitting.

Como os exemplos de treinamento são apenas uma amostra de todos os possíveis exemplos, é possível adicionar na árvore arestas que melhoram seu desempenho nos dados de treinamento, mas que piora seu desempenho em um conjunto de teste.

Para tentar solucionar o problema de superajuste dos dados, alguns sistemas podam a AD depois de induzí-la.

Esse processo reduz o número de nós internos, reduzindo a complexidade da árvore e, possivelmente, melhorando o desempenho da árvore original.

Esse tipo de poda é chamado de pós-poda uma vez que ele ocorre após a indução da AD.

Existem vários métodos de pós-poda, incluindo complexidade do erro e erro pessimista.

É também possível utilizar pré-poda na AD.

Esse processo é efetuado enquanto a AD é induzida.

Entretanto, a pré-poda sofre um efeito colateral, conjunções de teste podem ser a melhor forma de particionar os exemplos, mas seus atributos individuais podem não distinguir muito bem os exemplos.

Assim, a pré-poda pode evitar que determinados tipos de conjunções apareçam na árvore.

Uma AD pode ser facilmente mapeada em um conjunto de regras, transformando cada ramo da árvore cada caminho da raiz até cada um dos nós-folh em uma regra.

As regras transcritas de uma árvore de decisão são disjuntas, isto é, apenas uma única regra dispara quando um novo exemplo é classificado.

Várias medidas podem ser usadas para avaliar o desempenho de um modelo de classificação, sendo a precisão a mais comum.

Entretanto, em problemas do mundo real, nem sempre é possível encontrar um modelo que tenha uma boa precisão para classificar novos exemplos.

Quando as regras são analisadas individualmente, freqüentemente algumas dessas regras cobrem muita bem uma parte do espaço de exemplos.

Nesse caso, além de medir a precisão do modelo como um todo, é possível avaliar separadamente cada uma das regras que constituem o modelo.

Nesse contexto, regras podem ser avaliadas com o objetivo de saber quais são aquelas melhor sustentadas pelos dados ou, ainda, podem ser avaliadas com o intuito de selecionar aquelas que possam trazer algum conhecimento surpreendente ou inesperado.

A maioria das medidas de avaliação de regras estão baseadas na matriz de contingência para cada regra.

Nessa tabela, B denota o conjunto de exemplos para os quais a condição da regra é verdadeira e seu complemento B denota o conjunto de exemplos para os quais a condição da regra é falsa, analogamente para H e H.

BH denota o conjunto de exemplos B H no qual ambos B e H são verdadeiros, BH representa o conjunto de exemplos B H no qual B é verdadeiro e H é falso e assim por diante.

Por generalidade, denota-se a cardinalidade de um conjunto A por a, ou seja, a = |A|.

Assim, b denota o número de exemplos no conjunto B, ou seja, b = |B|, h denota o número de exemplos no conjunto H, ou seja h = |H|, bh denota o número de exem-plos no conjunto BH, ou seja, bh = |BH| e assim por diante, e n indica o número total de exemplos.

Matriz de contingência para uma regra.

Utilizando como base a matriz de contingência, é possível definir a maioria das medidas sobre regras, como, a precisão (Ac, erro, confiança negative (NegRel), sensitividade, especificidade, cobertura (Cov) e suporte, definidas na tabela.

Medidas simples de avaliação de regras.

A precisão de uma regra, também chamada de confiança, é uma medida do quanto essa regra é específica para o problema.

O erro de uma regra é o complemento da precisão.

A confiança negativa de uma regra é o correspondente à precisão, mas para os exemplos que não são cobertos pela regra.

A sensitividade de uma regra é semelhante ao recall de casos positivos usados em recuperação de informação.

Também conhecida como completeza, é uma medida do número (relativo) de exemplos da classe prevista em H cobertos pela regra.

A especificidade de uma regra é o correspondente à completeza, mas para os exemplos que não são cobertos pela regra.

A cobertura de uma regra é uma medida do número (relativo) de exemplos cobertos pela regra.

O suporte de uma regra é uma medida do número (relativo) de exemplos cobertos corretamente pela regra.

Cada uma das medidas apresentadas na seção anterior tem como objetivo avaliar um aspecto de uma regra.

A precisão, por exemplo, tem como objetivo minimizar o número de exemplos incorretamente cobertos pela regra.

Entretanto, isso pode levar a casos patológicos, como uma regra muito precisa que cobre apenas um único exemplo.

Além disso, dadas duas regras com a mesma precisão, a regra mais geral das duas, ou seja, a que cobre mais exemplos, é a mais preferível.

Nenhuma das medidas apresentadas na seção anterior são capazes de fazer essa distinção.

Uma das maneiras de gerenciar o compromisso entre precisão e generalidade é derivar medias compostas.

Geralmente, escolhe-se medidas "ortogonais", tais como a precisão e sensitividade, que dão origem à medida F, definida pela Equação 32.

Essa medida tem um parâmetro que indica a importância relativa de cada uma das duas medidas.

Uma outra medida comumente utilizada para ponderar precisão e cobertura é a cobertura relativa com pesos, também conhecida como novidade.

Essa medida é apresentada na Equação 33.

Essa medida tem a propriedade de preferir regras um pouco menos precisas, mas com uma maior cobertura do que uma regra muito precisa mas que cobre somente alguns exemplos Alternativamente, regras podem ser representadas em gráficos do tipo precisão-sensitividade (precision-recall como são mais conhecidos) ou gráficos ROC, que permitem comparar regras e determinar as condições em que uma determinada regra é melhor ou pior que outra.

Análise ROC é apresentada no Capítulo 4.

As regras são geralmente avaliadas em um conjunto de treinamento.

No entanto, estamos geralmente interessados em estimar o seu desempenho em toda a população.

Anteriormente foi assumido por simplicidade que as estimativas eram realizadas utilizando-se freqüências.

Essa abordagem pode, no entanto, gerar estimativas pouco confiáveis.

Dois métodos são geralmente descritos na literatura como alternativas para estimar probabilidades, a correção de Laplace e a correção m.

Ambas aplicam uma correção à freqüência relativa, que pode ser interpretada como se houvesse uma distribuição de exemplos a priori sobre a variável sendo estimada.

Na correção de Laplace, essa distribuição é uniforme e na correção m é uma generalização que é capaz de levar em consideração uma certa probabilidade a priori a respeito das classes.

Por simplicidade, a seguir nos restringimos à discussão da precisão de uma regra, mas o procedimento é aplicado a casos arbitrários no qual a probabilidade deve ser estimada a partir de freqüências.

Suponha que uma regra cubra pos exemplos positivos e neg exemplos negativos.

A estimativa da precisão com freqüências pode ser computada como pos.

Por exemplo, pos+neg se a regra cobre apenas um exemplo positivo corretamente, essa estimativa não é muito robusta pois qualquer alteração, mesmo que pequena, digamos um exemplo positivo ou negativo coberto pela regra, provocará uma grande mudança na estimativa.

A correção de Laplace é obtida pela inserção de um exemplo "fictício" ou "virtual" para cada classe.

Dessa maneira, a precisão estimada a partir da correção de Laplace torna-se pos+1, na qual k é o número de classes.

Por pos+neg+k exemplo, em um problema de duas classes, a precisão para pos = 1, neg = 0 estimada a partir das freqüências é 100,00%.

Com a correção de Laplace, a precisão estimada é de 66,66%.

Imagine que a cobertura de exemplos negativos dessa regra seja 1 e não zero, neg = 1.

A estimativa por freqüências, que era de 100%, cai drasticamente para 50%.

Já a correção de Laplace, também de 50%, oscila menos (de 6666% para 50%).

A medida que a cobertura da regra aumenta, tanto a estimativa por freqüência quanto a corrigida tendem a valores semelhantes.

A correção m generaliza a correção de Laplace assumindo uma probabilidade a priori pos para cada classe c.

A correção m é igual a pos+m×pos, no qual m é um parâmetro.

Isso é equivalente a adicionar m exemplos virtuais distribuídos de acordo com a probabilidade a priori das classes.

Observe que a correção de Laplace é um caso especial da correção m, no qual m = k e pos = 1/k para todas as classes.

O parâmetro m controla o papel das distribuições de probabilidade e das evidências provenientes dos exemplos, altos valores de m dão um maior peso às probabilidades à priori e menos aos exemplos.

Altos valores de m são aconselháveis para conjuntos de dados com muito ruído.

A probabilidade a priori pos pode ser estimada a partir do conjunto de treinamento utilizando-se as freqüências relativas de cada classe.

Neste capítulo foi feita uma introdução ao aprendizado de regras proposicionais, utilizado no desenvolvimento deste trabalho.

Foram abordadas as duas principais maneiras de se induzir regras, indução de regras diretamente e indução de árvores de decisão.

A indução de regras é também conhecida como abordagem separar-para-conquistar pois, uma vez aprendida uma regra, os exemplos por ela cobertos são removidos.

A indução de árvores de decisão é também conhecida como estratégia dividir-para-conquistar, pois o conjunto de exemplos é recursivamente dividido à medida que a árvore é induzida.

Aprendizado de regras tem uma longa história dentro da área de aprendizado de máquina.

Representantes da família separar-para-conquistar aparecem na literatura desde que aprendizado de máquina se firmava como área de pesquisa.

A principal razão para o interesse em aprendizado de regras está relacionado à atratividade de regras como um formalismo de representação de conceitos facilmente compreensíveis.

VÁRIOS dos trabalhos desenvolvidos durante o doutoramento estão relacionados à análise ROC, seja na avaliação ou na construção de modelos.

Neste capítulo é apresentada uma breve introdução à análise ROC.

Este capítulo está organizado da seguinte maneira, na Seção 41 são apresentadas algumas considerações iniciais sobre a análise ROC.

Na Seção 4é apresentado o gráfico ROC.

Finalmente, na Seção 43, são apresentadas as considerações finais deste capítulo.

Análise ROC-do inglês Receiver Operating Characteristic-é um método gráfico para avaliação, organização e seleção de sistemas de diagnóstico e/ou predição.

Gráficos ROC foram originalmente utilizados em detecção de sinais, para se avaliar a qualidade de transmissão de um sinal em um canal com ruído.

Gráficos ROC também são muito utilizada em psicologia para se avaliar a capacidade de indivíduos distinguirem entre estímulo e não estímulo.

Em medicina, para analisar a qualidade de um determinado teste clínico.

Em economia (onde é conhecida como gráfico de Lorenz), para a avaliação de desigualdade de renda e em previsão do tempo, para se avaliar a qualidade das predições de eventos raros.

Recentemente, a análise ROC foi introduzida em aprendizagem de máquina e mineração de dados como uma ferramenta útil e poderosa para a avaliação de modelos de classificação.

Ela é particularmente útil em domínios nos quais existem uma grande desproporção entre as classes ou quanto deve-se levar em consideração diferentes custos/benefícios para os diferentes erros/acertos de classificação.

Análise ROC também tem sido utilizada para a construção e refinamento de modelos.

A seguir, restringiremos nossa discussão a problemas binários de classificação, que tenham somente duas classes.

Sem perda de generalidade, denominaremos cada uma das classes como positiva e negativa.

Uma maneira natural de apresentar as estatísticas para a avaliação de um modelo de classificação é por meio de uma tabulação cruzada entre a classe prevista pelo modelo e a classe real dos exemplos.

Essa tabulação é conhecida como tabela de contingência (também chamada de matriz de confusão).

Na tabelaé mostrada uma matriz de contingência com freqüências absolutas (contagem).

Nessa tabela, TP, FP, FN e TN correspondem, respectivamente, as quantidade de verdadeiro/falso positivo/negativo.

PP, PN correspondem ao número de exemplos preditos como positivos/negativos e POS/NEG ao número de exemplos reais positivos/negativos.

N é o tamanho da amostra.

Note que essa matriz é similar a apresentada na tabela, só que ela refere a um modelo completo, enquanto que a da tabelarefere-se a apenas uma regra.

Matriz de contingência para modelos de classificação.

Se dividirmos cada entrada na matriz mostrada na tabelapelo tamanho da amostra, cada entrada dessa matriz representa uma estimativa 1 Quando um exemplo cuja classe real é positiva é classificado como positivo, ele é denominado verdadeiro positivo.

Caso a classe real seja negativa e ele é classificado como positivo, ele é denominado falso positivo.

Notação similar é empregada no caso dos exemplos negativos da probabilidade conjunta da classe real do exemplo e da predição dada pelo modelo.

Essa nova matriz é mostrada na tabela, na qual X representa a variável aleatória classe real do exemplo = positiva e Y representa a variável classe predita do exemplo = positiva.

X e Y representam a negação de X e Y.

Como a matriz mostrada na tabelaé apenas uma re-escala da matriz mostrada na tabela, elas são equivalentes.

Além disso, toda a informação necessária para avaliar o modelo está contida nessas matrizes.

No entanto, uma análise mais refinada pode ser feita pela decomposição das probabilidades conjuntas em probabilidades condicionais e marginais.

Probabilidades condicionais podem ser obtidas a partir das leis básicas de probabilidade, na qual P(X|Y), como mencionado anteriormente, é a probabilidade condicional de X ser verdade, dado que Y é verdade, sendo que P(X,Y) = P(Y,X), mas P(X|Y) 6= P(Y |X).

Dado um conjunto de exemplos, todas essas probabilidades podem ser estimadas como proporções.

Mais especificamente, Essas probabilidades condicionais também podem ser calculadas para as quatro entradas da matriz, e também podem ser representadas como matrizes.

P(X|Y) é importante para o usuário do modelo, uma vez que ela dá a probabilidade de que a classe seja X, dado que a previsão feita pelo modelo é Y.

Essa probabilidade também é conhecida como confiança.

Entretanto, em termos de avaliação do modelo, P(Y |X) é muito mais útil.

Uma das vantagens da fatoração de P(X,Y) em P(Y |X) e P(X) é que P(Y |X) é condicional ao valor de X, i e, é condicional à proporção de exemplos entre as classes.

Essa probabilidade condicional é freqüentemente conhecida como crença ou verossimilhança, uma vez que ela especifica a probabilidade de que uma predição particular é feita dado a ocorrência de uma observação específica.

Essa probabilidade indica o quanto um modelo é capaz de discriminar os casos entre as possíveis classes.

Além disso, as probabilidades marginais de X são as únicas que não envolvem, de maneira alguma, as previsões do modelo.

Por esse motivo, Para se obter uma estimativa mais confiável, em amostras grandes é recomendável a utilização de um conjunto independente de exemplos de teste.

Caso o tamanho da amostra seja pequena, geralmente utiliza-se métodos de re-amostragem, tal como validação cruzada.

A distribuição de X é geralmente assumida como uma característica do domínio e não dependente do modelo.

Feita essa assumpção, somente dois valores são necessários para descrever a matriz de contingência, pois P(Y |X) = 1 P(Y |X) e P(Y |X) = 1 P(Y |X).

Essas duas probabilidades são independentes da proporção de exemplos a priori entre as classes.

Como será abordado na Seção 412, essa é uma propriedade importante na avaliação de modelos em domínios com classes desbalanceadas e/ou diferentes custos de classificação.

A avaliação de um modelo de classificação é baseada na análise da matriz de contingência (ou de suas derivações).

Uma das maneiras mais comuns de avaliar modelos é a derivação de medidas que, de alguma maneira, tentam medir a "qualidade" do modelo.

Reduzir a matriz de contingência a uma única medida tem algumas vantagens aparentes.

A principal delas é que é mais fácil escolher o "melhor" em termos de um único valor.

Entretanto, é comum encontrar casos em que uma dada medida é apropriada para um problema, mas ela é irrelevante para outros.

Também, é comum encontrar situações em que a avaliação é um problema de múltiplas faces, nas quais é possível definir várias medidas, sendo perfeitamente possível que um modelo seja melhor que outro para algumas dessas medidas, mas seja pior com relação a outras medidas.

Nesses casos, utilizar uma única medida pode dar a falsa impressão de que o desempenho pode ser avaliado utilizando apenas essa medida.

Tomemos como exemplo a taxa de erro de classificação-uma das medidas mais comuns utilizadas em aprendizado de máquina.

Existem várias situações em que a taxa de erro de classificação não é apropriada para a avaliação de modelos de classificação.

Uma situação comum se dá quando o número de exemplos em cada uma das classes é muito desbalanceado.

Por exemplo, suponha que em um dado domínio o número de exemplos de uma das classes seja 99%.

Nesse caso, é comum se obter baixas taxas de erro-um modelo que sempre retorna a classe majoritária terá uma taxa de erro de apenas 1%.

No entanto, esse modelo que sempre classifica um novo exemplo na classe majoritária não irá acertar nenhuma classificação de exemplos da classe minoritária.

Além disso, a taxa de erro assume custos iguais para os erros em ambas as classes.

Em muitos domínios é comum haver diferentes custos de classificação para as diferentes classes.

Em medicina, por exemplo, o custo de classificar incorretamente um paciente doente como sadio para uma dada doença grave é muito maior do que classificar um paciente sadio como doente pois, no primeiro caso, a falha no diagnóstico pode levar à morte do paciente.

Em se conhecendo os custos de classificação, esse problema pode ser remediado pela substituição da taxa de erro pelo custo médio esperado.

Entretanto, esses custos geralmente não são conhecidos, ou até mesmo podem variar, dependendo de fatores externos.

Um outro problema é que tanto a taxa de erro quanto o custo médio esperado são dependente da distribuição de exemplos entre as classes.

Na maioria das aplicações de AM e MD assume-se que os exemplos disponíveis para o treinamento representam uma amostra natural da população de casos.

Por amostragem natural entende-se que a proporção de exemplos amostrados para cada uma das classes é representativa com relação à população de interesse.

Em outras palavras, assume-se que não existe nenhum vício na amostra e que a proporção de exemplos para cada uma das classes aproxima bem a proporção de casos na população da qual os exemplos foram amostrados.

Essa assumpção, mesmo que plausível, não é, necessariamente, correta.

Suponha que queiramos construir um modelo para reconhecer se uma dada seqüência de aminoácidos corresponde ou não a um gene humano.

Nesse caso, a amostra não pode ter a proporção real de exemplos, pois não se conhece o número total de genes que formam o genoma humano.

Nesse caso nem a taxa de erro nem o custo médio esperado têm o significado a eles atribuídos, pois variações na proporção de exemplos (diferente estimativas do número de genes) irão alterar os valores das medidas de desempenho, mesmo que o desempenho global do modelo não mude.

Essas deficiências não são exclusivas da taxa de erro.

Qualquer medida que tenha como objetivo reduzir a avaliação de um modelo de classificação a um único valor terá, em maior ou menor grau, uma perda de informação.

Geralmente, a não ser que se tenha domínios com critérios para avaliação claramente definidos e estáticos, a avaliação de um modelo utilizando uma única medida pode levar a conclusões errôneas.

Em outras palavras, não existe uma única medida boa, a não ser que seja possível definir, para aquele domínio, o significado de bom.

Ainda que consideremos apenas o caso em que tanto observações quanto previsões são binárias, muitos sistemas de aprendizado fornecem um valor contínuo para as previsões, mesmo no caso em que as classes são discretas.

Por exemplo, redes neurais geralmente produzem valores entre zero e um.

Para se obter uma classificação, geralmente coloca-se um limiar na variável de predição.

Todas as predições acima desse limiar são atribuídas a uma das classes, e as predições abaixo são atribuídas à outra.

Dessa maneira, Esse número já foi estimado em 100000, 70000 e 50000, entre outros.

A estimativa atual é entre 30000 e 40000.

Para um dado limiar, é possível se obter uma previsão binária pela discretização da previsão contínua.

Essa discretização contribui com um outro problema para a avaliação do modelo de classificação, a escolha do limiar é arbitrária e geralmente baseada na taxa de erro.

Assim, cada possível limiar produz uma matriz de contingência diferente, e, por conseqüência, diferentes valores para as medidas.

Em termos de avaliação, ao invés de estabelecer um limiar de classificação e avaliar o modelo de classificação derivado desse limiar, é mais interessante avaliar como o modelo ordena os exemplos.

Um bom modelo deve ordenar os exemplos de tal forma que, observando-se a variável de predição, exemplos de classes semelhantes sejam agrupados em faixas contínuas de valores.

É importante ressaltar que, como é possível derivar uma classificação colocando-se um limiar na variável contínua, avaliar como os exemplos são ordenados é mais vantajoso pois é independente do limiar e engloba a avaliação da classificação.

Também é importante ressaltar que, assim como na taxa de erro (e outras medidas), é possível derivar estatísticas a respeito da qualidade da ordenação.

Uma dessas estatísticas é o teste de ordenação de Wilconxon.

Como será visto na Seção 42, essa estatística tem uma correlação com a análise ROC.

Entretanto, é importante ressaltar que, da mesma maneira que as medidas para se avaliar o modelo de classificação, avaliar a ordenação dos exemplos com uma única medida também tem as suas desvantagens.

Uma alternativa à avaliação utilizando medidas é uso de gráficos e/ou diagramas.

Gráficos permitem uma melhor visualização da multidimensionalidade do problema de avaliação.

O gráfico ROC é baseado na probabilidade de detecção, ou taxa de verdadeiros positivos (tpr = P(Y |X)) e a probabilidade de falsos alarmes, ou taxa de falsos positivos (fpr = P(Y |X)).

Para se construir o gráfico ROC plota-se fpr no eixo dos ordenadas-eixo x-e tpr no eixo das abscissas-eixo y.

Um modelo de classificação é representado por um ponto no espaço ROC.

Alguns pontos no espaço ROC merecem destaque.

O ponto (0,0) representa a estratégia de nunca classificar um exemplo como positivo.

Modelos que correspondem a esse ponto não apresentam nenhum falso positivo, mas também não conseguem classificar nenhum verdadeiro positivo.

A estratégia inversa, de sempre classificar como positivo, é representada pelo ponto (100%,100%).

O ponto (100%,0) representa o modelo perfeito, todos os exemplos positivos e negativos são corretamente classificados.

O ponto (100%,0) representa o modelo que sempre faz predições erradas.

Modelos próximos ao canto inferior esquerdo podem ser considerados "conservativos", eles fazem uma classificação positiva somente se têm grande segurança na classificação.

Como conseqüência, eles cometem poucos erros falsos positivos, mais freqüentemente têm baixas taxas de verdadeiros positivos.

Modelos próximos ao canto superior direito podem ser considerados "liberais", eles predizem a classe positiva com maior freqüência, de tal maneira que eles classificam a maioria dos exemplos positivos corretamente, mas, geralmente, com altas taxas de falsos positivos.

A linha diagonal ascendente (0,0) (100%,100%) representa um modelo de comportamento estocástico, cada ponto (p,p) pode ser obtido pela previsão da classe positiva com probabilidade p e da classe negativa com probabilidade 100% p.

Pontos pertencentes ao triângulo superior esquerdo a essa diagonal representam modelos que desempenham melhor que o aleatório e pontos pertencentes ao triângulo inferior direito representam modelos piores que o aleatório.

A diagonal descendente (0,100%) (100%,0) representa modelos de classificação que desempenham igualmente em ambas as classes (tpr = 1 fpr = tnr).

À esquerda dessa linha estão os modelos que desempenham melhor para a classe negativa em detrimento da positiva e, à direita, os modelos que desempenham melhor para a classe positiva.

O espaço ROC está representado esquematicamente.

É mostrado um gráfico ROC com 5 modelos de classificação induzidos por 5 sistemas de aprendizado diferentes (C45, CN2, Ripper, Support Vector Machine SVM, e Naïve Bayes).

Uma rápida inspeção visual permite algumas constatações.

Neste caso, CNé o mais conservativo e SVM é o mais liberal.

Além disso, é fácil de perceber que um ponto no espaço ROC é melhor que outro se e somente se ele está acima e a esquerda do outro ponto, tem uma maior taxa de verdadeiros positivos e uma menor taxa de falsos positivos.

Modelos de classificação no espaço ROC Além disso, é possível mostrar que os modelos que se encontram na região convexa que mais se aproxima ao ponto (0,1), são os modelos que podem ser considerados ótimos, dada uma certa condição operacional.

Os outros modelos que não fazem parte da região convexa podem ser descartados.

Isso se deve ao fato de que cada condição operacional define a inclinação de uma linha no espaço ROC, chamada de linha de iso-desempenho.

Ela recebe esse nome pois todos os pontos que fazem parte dessa linha têm uma característica em comum, a taxa de erro (ou custo médio esperado) é a mesma.

A inclinação desta linha está relacionada ao quanto um determinado erro é relativamente mais importante que o outro.

O modelo ótimo para uma dada condição operacional deve estar em uma linha com essa inclinação.

Além disso, o modelo ótimo deve estar o mais próximo possível do ponto (0,100%).

Essas duas propriedades implicam que os modelos ótimos estejam na região convexa-uma prova detalhada pode ser encontrada em.

Isso é equivalente a dizer que se essa linha representar a condição operacional real à proporção de exemplos entre as classes (ou o custo de classificar erradamente um exemplo positivo ou negativo) são iguais.

Nessas condições, o modelo induzido pelo C45 irá apresentar a menor taxa de erro (ou o menor custo de classificação).

Se essa linha representar as condições operacionais verdadeiras, a classe positiva é duas vezes mais populosa (ou o custo de classificar erradamente um exemplo da classe positiva é duas vezes maior) que a classe negativa.

Nessas condições, ambos os modelos induzidos pelo C45 e SVM são ótimos, tem a mesma taxa de erro/custo de classificação global.

Note que, no entanto, as taxas de erros separadas por classes são diferentes para cada um desses algoritmos.

Uma outra vantagem de se utilizar a curva ROC está na avaliação da ordenação dos exemplos, ao invés da classificação.

Nesse caso, como descrito na Seção 412, o sistema de aprendizagem não prediz a classe, mas um valor contínuo ou ordinal, e, para se criar o modelo de classificação, esse valor contínuo pode ser binarizado pela escolha de um limiar de classificação.

Entretanto, quando se estabelece um limiar específico, assume-se um certo compromisso entre os acertos e os erros.

Esse compromisso pode ser avaliado utilizando a análise de curvas ROC.

Ao invés de se escolher um limiar arbitrário e representar o desempenho do sistema para um dado domínio como um único ponto no espaço ROC, O termo condição operacional engloba fatores como proporção de exemplos a priori entre as classes e/ou custos/benefícios de classificação.

Diferentes linhas de iso-desempenho implicam em diferentes modelos ótimos.

Pode-se "simular" a escolha de vários limiares.

Nesse caso, varia-se o limiar em todo o seu espectro, desde o valor mais restritivo até o valor mais liberal.

O desempenho do sistema é então representado por uma curva no espaço ROC-a curva ROC.

Dessa maneira, a análise é feita independentemente da escolha do limiar.

Quanto mais distante a curva estiver da diagonal principal, melhor será o desempenho do sistema de aprendizado para aquele domínio.

Ao se comparar duas (ou mais) curvas, caso não haja nenhuma interseção, a curva que mais se aproxima do ponto (0,100%) é a de melhor desempenho.

Caso haja intersecções, cada um dos sistemas tem uma faixa operacional na qual é melhor que o outro.

Idealmente, a curva deve ser convexa e sempre crescente.

São mostrados alguns exemplos de curvas ROC.

Não há intersecções entre as curvas.

Nesse caso, modelos de classificação derivados a partir da curva mais próxima do ponto (0,1) serão sempre melhores do que os modelos derivados a partir da outra curva, independentemente das condições operacionais.

Já no caso da Figura(em que há uma interseção entre as curvas perto do ponto (40%,70%), os medelos de classificação derivados à esquerda deste ponto serão os melhores se forem derivados da curva que sobe mais próxima do eixo y, e da outra curva se forem derivados à direita.

Caso um único modelo seja realmente necessário, a sua derivação pode ser feita com base na análise da curva ROC, analisando-se os possíveis compromissos entre as classificações positivas e negativas.

A idéia básica é a mesma das linhas de iso-desempenho.

Dada uma condição operacional (e por conseqüência uma linha de iso-desempenho), é possível derivar o limiar apropriado para aquela condição operacional.

Dessa maneira, é possível calibrar o modelo para as condições operacionais reais, ao invés daquelas utilizadas durante a indução.

Esse fato é o segundo grande chamativo da análise ROC.

Em suma, a primeira vantagem da análise ROC é que pode-se fazer uma análise independentemente de certas condições, tais como o limiar de classificação, os custos relacionados à classificações errôneas e à distribuição a priori das classes.

Essa análise é realizada visualizando-se o compromisso entre tpr e fpr em um gráfico bi-dimensional.

A segunda vantagem é que a análise ROC pode ser utilizada para a calibração e ajuste de modelos de classificação, quando necessário.

Essas duas propriedades são às vezes mal interpretadas.

É comum encontrar afirmativas de que a análise ROC é independente da distribuição de exemplos entre as classes.

Na realidade, essa não é uma característica da análise ROC em si, mas uma conseqüência da aplicação das leis básicas da probabilidade citadas na Seção 411.

Ela somente é verdadeira se, como dito na Seção 411, assumirmos a distribuição de X como característica do domínio.

A análise ROC é sim invariante a proporção de exemplos entre as classes desde que essa assumpção seja verdadeira.

Entretanto, essa propriedade não é válida em casos em que essa assumpção não é válida.

Muitas vezes, essa confusão é empregada como uma crítica a análise ROC.

No entanto, essa má interpretação está relacionada muito mais com a metodologia (decorrente de considerar verdadeira uma falsa assumpção) do que no método.

Quando propriamente utilizada, a análise ROC é uma ferramenta poderosa para a avaliação de sistemas, principalmente em domínios para os quais não se pode definir as condições operacionais com precisão.

Uma outra conexão entre a curva ROC e a ordenação dos exemplos está relacionada com a área abaixo da curva ROC-AUC (do inglês Area Under Curve).

Uma vez que a área abaixo da curva ROC é uma fração da área de um quadrado de lado um, o seu valor está sempre entre 0 e 1.

Hanley & McNeil mostraram que essa área é numericamente equivalente à estatística de Wilcoxon.

Além disso, AUC também é numericamente igual a probabilidade de, dados dois exemplos de classes distintas, o exemplo positivo seja ordenado primeiramente que um exemplo negativo.

AUC também está correlacionada com o coeficiente Gini.

A AUC vem gradativamente ganhando espaço como medida de avaliação de modelos em aprendizado de máquina e mineração de dados.

Apesar de, como discutida na Seção 412, a avaliação de um modelo por uma única medida não ser a mais apropriada, AUC tem menos deficiências do que a taxa de erro de classificação.

Entretanto, sempre que possível, é recomendável plotar e analisar a curva dos modelos.

Também é importante ressaltar que, assim como a taxa de erro de classificação, ambos AUC e a curva ROC são variáveis aleatórias e, portanto, devem ser estimadas e acompanhadas de alguma medida de variação.

AUC é normalmente estimada da mesma maneira que a taxa de erro normalmente utilizando-se validação cruzad.

Estimar a curva em si é um pouco mais complexo, uma vez que ela é bi-variada.

Nesse caso, pode-se calcular tanto a variância com relação a tpr, fpr, ou ambos.

Fawcett apresenta uma descrição desses três métodos para se estimar a curva média.

É mostrada uma curva ROC com estimava de variância feita com o pacote ROCR, desenvolvida para o software R.

A linha contínua é a média das linhas pontilhadas, na qual a média foi calculada com relação à tpr.

As barras de erro indicam intervalos de 1 desvio padrão.

A curva ROC com variância.

Uma das principais desvantagens de se utilizar gráficos ROC é a sua limitação para apenas duas classes.

Apesar dos princípios básicos serem os mesmos, o número de eixos cresce exponencialmente com o número de classes.

No entanto, algumas aproximações são possíveis, como a umcontra-todos, proposta por Hand & Till.

Gráficos ROC constituem uma ferramenta muito útil para a visualização e avaliação de modelos de classificação.

Gráficos ROC também são utilizados para se avaliar como um sistema de aprendizado é capaz de ordenar os exemplos, permitindo uma análise independente do limiar de classificação.

Caso seja necessário derivar um modelo de classificação, a análise ROC também permite que seja feita a calibração, por meio de linhas de iso-desempenho, para as condições operacionais mais apropriadas ao domínio da aplicação.

A análise ROC provê uma avaliação mais rica do que simplesmente avaliar o modelo de classificação a partir de uma única medida.

Entretanto, para a sua correta utilização, é necessário que se conheçam suas características e limitações.

Neste capítulo foi feita uma introdução à análise ROC dentro do contexto de aprendizado de máquina, bem como foram destacadas e exemplificadas algumas de suas limitações e erros de interpretação.

NESTE capítulo são descritos os trabalhos desenvolvidos relacionados à aprendizagem de regras.

Na Seção 51 é aprensentada uma abordagem para a extração de excea partir de regras gerais.

Na Seção 5é apresentado o algoritmo ROCCER, um algoritmo que faz seleção de regras baseado em análise ROC.

Finalmente, na Seção 53, são apresentadas as considerações finais deste capítulo.

Algoritmos clássicos de indução de regras são projetados principalmente para induzir conjuntos de regras com objetivos de classificação ou predição, cuja função é prever ou classificar novos casos com uma alta precisão.

Em outras palavras, esses algoritmos tendem a induzir regras com um alto valor de suporte e precisão, de maneira que essas regras induzidas possam formar um modelo para a classificação que apresente uma boa precisão.

Um dos problemas com essa abordagem é que muitas das regras induzidas pelos algoritmos de AM podem ser regras tanto triviais quanto difíceis de entender, pois esses algoritmos usam heurísticas e preferências independentes do domínio da aplicação em questão para induzir as regras que compõem o modelo.

A abordagem tradicionalmente utilizada para descobrir conhecimento novo é tratar as regras que compõem o modelo individualmente, filtrando o conjunto de regras e selecionando apenas as mais interessantes segundo algum critério pré-estabelecido.

Entretanto, por terem sido induzidas com o objetivo de formarem um modelo, muitas dessas regras são regras gerais, que na maioria das vezes expressam um conhecimento de senso comum.

Mesmo que regras gerais sejam usualmente consistentes com as expectativas dos especialistas, em certas atividades de mineração de dados pode ser mais interessante procurar por outros tipos de regras além das gerais.

Um outro ponto a ser considerado é quanto à interpretação e o entendimento das regras induzidas, como visto no Capítulo 3.

Os conjuntos de regras induzidos pelos algoritmos de AM podem ser tanto de regras com sobreposição quanto de regras disjuntas.

Regras com sobreposição podem ser tanto ordenadas (listas de decisão) quanto não-ordenadas (regras independentes).

Listas de decisão impõem uma ordem no conjunto de regras.

Do ponto de vista da extração e análise de conhecimento, uma regra extraída de uma lista de decisão é difícil de ser entendida pelo especialista, pois ela é significativa somente no contexto de todas as regras precedentes.

Em contrapartida, as regras extraídas de conjuntos não-ordenados ou disjuntos podem ser analisadas individualmente, sendo alternativas mais viáveis do que listas de decisão.

Porém, as regras desses conjuntos não têm nenhuma relação entre si.

Em muitas tarefas de MD, um relacionamento entre essas regras é muito importante para o entendimento global das relações implícitas do domínio.

Em contrapartida, o uso de regras de conhecimento isoladas pode dificultar um entendimento global do domínio.

Como pode ser observado, esses fatores implicam em uma dificuldade na utilização de algoritmos de aprendizado em muitas aplicações práticas de mineração de dados.

Essa dificuldade reside tanto na busca de regras quanto na forma de representação utilizadas pelos algoritmos de aprendizado.

Uma das principais características de regras gerais é que essas regras apresentam exceções.

Intuitivamente, exceções contradizem uma regra mais geral ou de senso comum.

Também é geralmente aceito que exceções têm um pequeno suporte, mas têm uma confiança similar às regras de senso comum.

Como descrito na Seção 36, Suporte é uma medida do número (relativo) de exemplos cobertos corretamente pela regra, enquanto que confiança é uma medida do quanto uma regra é precisa.

Neste trabalho, usamos o conceito de exceção apresentado em, que estruturalmente define exceções como mostrado na tabela, na qual B também representa disjunções não vazias de restrições sobre os atributos.

Estrutura de regra com exceções.

Por exemplo, se houver uma regra de senso comum "se a pessoa está desempregada não lhe é dado crédito", uma exceção seria "se a pessoa está desempregada mas o cônjuge está empregado, então lhe é dado crédito".

Um ponto importante sobre exceções é que elas podem auxiliar no problema do entendimento do conhecimento induzido.

Um conjunto de regras isoladas é pouco intuitivo para o especialista, pois as pessoas geralmente expressam conhecimento em termos de padrões gerais e casos especiais.

O conceito implícito de localidade uma exceção é aplicada somente se a sua regra geral é válid torna o par regra geral, regras de referênci, que formam as exceções, mais confortável para as necessidades do especialista, regras gerais são expressas primeiro, e exceções à essas regras são modeladas como um posterior refinamento da hipótese.

Um outro ponto importante à respeito de exceções refere-se ao problema da indução de regras interessantes ou úteis.

Por contradizerem regras de senso comum, exceções são geralmente mais interessantes e mais úteis para o usuário.

Exceções podem, por exemplo, representar um importante nicho em um determinado mercado de consumidores.

Reconhecer esse nicho como uma exceção pode conduzir a uma campanha de marketing específica à esses consumidores.

Esse conjunto contém exemplos descritos por dois atributos, A1 e Ae duas classes, N e.

O domínio de A1 é {a,b,c,d} e o domínio de Aé {x,y}.

Algoritmos de indução de regras ou generalizam, formulando uma hipótese do tipo A= x N e A= y, ou especificam, formulando uma hipótese para cada exemplo do tipo A= xA1 = a N, e assim por diante.

Entretanto, uma maneira mais intuitiva de descrever o conceito é generalizar, permitindo que primeiro se tenha uma idéia geral do conceito, e Novas abordagens para a geração de regras.

O espaço de dados de exemplo, depois especificar localmente, tratando exceções e casos especiais.

Nesse caso, a hipótese seria Diversos métodos foram propostos na literatura para extrair exceções.

Entretanto, esses métodos são geralmente voltados para geração de regras de associação, e poucos desses métodos podem ser aplicados para extrair exceções a partir de regras de classificação.

A seguir é descrito um método para encontrar exceções a partir de regras de classificação.

Essa abordagem baseia-se nos seguintes princípios, Um algoritmo de aprendizado pode sumarizar dados e induzir regras.

Algoritmos de aprendizado geralmente dão preferência à indução de regras com alto suporte.

Exceções devem ter um suporte pequeno em toda a amostra de dados, caso contrário seria uma regra de senso comum.

Os três princípios acima implicam em uma dificuldade em encontrar exceções a partir de algoritmos de aprendizado de máquina tradicionais.

Extrair exceções diretamente a partir dos dados não é uma tarefa fácil, pois, como mencionado anteriormente, os algoritmos de aprendizado têm heurísticas e preferências que privilegiam regras gerais.

Mesmo que essas preferências sejam relaxadas, o conhecimento induzido é fragmentado no conjunto de regras, perdendo-se o conceito de localidade da exceção.

Assim, considerando essas dificuldades, a abordagem proposta neste trabalho para encontrar exceções considera duas etapas, descritas a seguir, indução de regras de senso comum.

Nessa etapa, é utilizado um algoritmo de aprendizado de máquina tradicional para a indução de regras de classificação.

Normalmente, o usuário pára aqui a atividade de extração de regras, avaliando e analisando as regras induzidas.

Na abordagem proposta, estamos especialmente interessados na indução de regras gerais ou de senso comum.

Em outras palavras, a idéia é não permitir, nesta etapa, a indução de regras muito especializadas.

Isso é conseguido manipulando apropriadamente os parâmetros do algoritmo de aprendizado.

Após, cada uma das regras B H presentes no conjunto de regras que constituem o modelo de classificação é avaliada utilizando um conjunto de n exemplos para construir a sua matriz de contingência.

Como descrito na Seção 36, a matriz de contingência computa, para cada regra, os valores para os quais B e H são verdadeiros, B e H são falsos, B é verdadeiro e H é falso e B é falso e H é verdadeiro.

Para facilitar a leitura, na mostrada novamente a matriz de contingência, mas diferentemente da matriz apresentada na tabela, na qual os valores foram apresentados como valores absolutos, na ada entrada f representa a freqüência relativa do evento x.

Essa matriz é utilizada no passo seguinte para selecionar as regras que serão consideradas para procurar por exceções.

Somente esses exemplos são selecionados para compor um novo subconjunto de exemplos no qual as exceções serão procuradas.

Dentro desse subconjunto, associações entre os atributos desse exem- plo e a(s) classe(s) negativa(s) H são procuradas nesse subconjunto.

No caso de existirem mais de duas classes, o conjunto das classes não previstas por H constituem as classes negativas H.

Se essas associações têm valores de suporte e confiança aceitáveis dentro do subconjunto, elas são regras de referência, e o par regra geral, regras de referênci representa uma regra de exceção.

Deve ser ressaltado que mesmo que a regra de referência tenha um alto suporte dentro do subconjunto de exemplos utilizado para procurar por exceções, elas têm um suporte pequeno em todo o conjunto de exemplos.

Essa abordagem, além de permitir a extração de exceções a partir de regras de classificação, também preserva a localidade da exceção.

Para testar o método proposto, foi escolhido um conjunto de dados reais, referente à clivagem de proteínas virais por proteases virais para o vírus da AIDS (HIV).

Esse conjunto de dados foi também utilizado em Narayanan.

Na ão apresentadas as principais características do conjunto de dados HIV.

Descrição do conjunto de dados HIV utilizado para procurar exceções.

A protease viral desempenha um papel importante no ciclo de vida viral, uma vez que é responsável por quebrar a poliproteína (o substrato) em sítios específicos, a medida que essa poliproteína deixa o ribossomo da célula hospedeira como uma seqüência longa.

Em outras palavras, a protease é responsável pela pós-tradução de cadeias peptídicas em proteínas e enzimas virais que criarão novos vírus.

Deve ser ressaltado que um bom entendimento desse processo é de fundamental importância no estudo de drogas que possam vir a inibir esse processo de clivagem.

O conjunto de exemplos é formado por subseqüencias de aminioácidos de tamanho 8 e da informação (classe) relacionada à subseqüencia representar ou não um sítio de clivagem.

O tamanho da subseqüência corresponde ao tamanho da seqüencia de aminoácidos da protease que se liga ao substrato, em um esquema "chave-e-fechadura", ou seja, quando a seqüencia da protease casa com a seqüência do substrato ocorre a clivagem, e vice-versa.

No caso do HIV, a clivagem ocorre entre a posição e a posição 5 da seqüência.

Resultados de experimentos realizados com esse mesmo conjunto de dados, utilizando validação cruzada com 10 partições, uma rede neural MLP treinada com o algoritmo backpropagation do simulador SNNS e o indutor de árvores de decisão See5 estão reportados em, e são transcritos na tabela, na qual os valores entre parênteses referem-se ao desvio-padrão.

Taxas de erro de uma rede neural e do See5 no conjunto de dados HIV.

Para verificar a possível ocorrência de um superajustamento das exceções sobre o conjunto de dados, a metodologia proposta para encontrar exceções foi repetida três vezes com amostragens diferentes de treinamento e teste.

O conjunto de dados foi particionado em três subconjuntos, e, em cada aplicação, duas partições foram usadas para treinamento e a outra para teste.

Para a aplicação da primeira etapa do método proposto, foi utilizado o programa para induzir árvores de decisão See5, com a opção de gerar subconjuntos de valores nos nós de decisão.

Como o número de regras foi pequeno em cada execução, todas as regras induzidas na primeira etapa foram selecionadas para a aplicação da segunda etapa.

Na segunda etapa, cada uma das regras define o subconjunto de dados a ser utilizado para procurar por exceções.

Como mencionado, esse subconjunto é composto pelos exemplos cobertos pela regra mas que não são da mesma classe por ela prevista.

Nesses subconjuntos foi aplicado o algoritmo de geração de regras de associação Apriori.

Somente as regras que apresentam associações entre os atributos e a classe negativa, e com suporte maior que 0,5 foram selecionadas como possíveis exceções.

Se a exceção apareceu em regras semelhantes em pelo menos das execuções, essa exceção foi assumida como válida.

As regras transcritas da árvore de decisão na primeira execução são mostradas na tabela.

Os números entre parênteses indicam, respectivamente, o número de exemplos cobertos e o número de exemplos cobertos incorretamente pela regra.

Dos 149 exemplos cobertos pela regra R11 no conjunto de treinamento, 16 pertencem à classe cleavage.

Nesse subconjunto de 16 exemplos, foi aplicado o algoritmo de geração de regras de associação.

Apenas uma regra com os requisitos exigidos foi gerada, if pos6 = E then cleavage, que cobre 9 exemplos desse subconjunto.

No conjunto de teste, essa exceção cobriu corretamente o único exemplo que era coberto erroneamente pela regra, mas outros dois exemplos cobertos corretamente passaram a ser erroneamente cobertos.

O mesmo procedimento foi aplicado à regra R21 e R31.

Para a regra R21, exemplos pertencem à classe cleavage.

Para essa regra, também foi gerada pelo Apriori a regra, if pos6 = E then cleavage, que cobre todos os exemplos no conjunto de treinamento.

No conjunto de teste, dos 7 exemplos cobertos por essa regra, 5 foram erroneamente cobertos pela regra R21.

A exceção passou a cobrir corretamente desses 5 exemplos.

Para a regra R31, dos 15 exemplos cobertos erroneamente no conjunto de treinamento, não foram encontradas associações que satisfizessem o critério mínimo de suporte.

As regras extraídas da árvore de decisão na segunda execução são mostradas na tabela.

Dos 158 exemplos cobertos pela regra R12, 15 pertencem à classe cleavage.

Nesse subconjunto de exemplos foi aplicado o algoritmo de geração de regras de associação e a mesma regra (if pos6 = E then cleavage) foi encontrada.

Dos 15 exemplos do subconjunto, 8 são cobertos pela regra.

No conjunto de teste, a exceção passou a cobrir corretamente todos os 5 exemplos que eram erroneamente cobertos, e passou a cobrir erroneamente 1 exemplo que era coberto corretamente pela regra R12.

Nenhuma exceção que satisfizesse os critérios estabelecidos foi encontrada para a regra R22.

Transcrição em regras da árvore de decisão induzida pelo See5.

As regras extraídas da árvore de decisão na terceira execução são mostradas na tabela.

Dos 15exemplos cobertos pela regra R13, 1pertencem à classe cleavage.

Como nas execuções 1 e 2, nesse subconjunto de exemplos foi aplicado o algoritmo de geração de regras de associação e a mesma regra (if pos6 = E then cleavage) foi encontrada.

Dos 1exemplos do subconjunto, 7 foram cobertos pela regra.

No conjunto de teste, a exceção passou a cobrir corretamente dos 5 exemplos que eram erroneamente cobertos.

Nenhum dos exemplos que foram cobertos corretamente pela regra R1passaram a ser erroneamente cobertos.

Nenhuma exceção que satisfizesse os critérios estabelecidos foi encontrada para a regra R23.

Transcrição em regras da árvore de decisão induzida pelo See5.

Para verificar se a taxa de erro média das três execuções obtida pela nossa abordagem é comparável à obtida pelo See5, aplicamos o teste t student pareado para testar a seguinte hipótese, A taxa de erro média obtida pelo See5 é de 14,63% com um desvio padrão de 595.

Utilizando a nossa abordagem, a taxa de erro é de 13,53% com um desvio padrão de 624.

Com esses valores é possível rejeitar a hipótese H com 95% de confiança.

Além da taxa de erro, também aplicamos o teste t-student na sensitividade média (taxa de verdadeiros positivos) para testar a seguinte hipótese, A sensitividade média alcançada pelo See5 foi de 85,09% com 7,60 de desvio padrão.

Nossa abordagem teve uma sensitividade média de 93,86% com um desvio padrão de 402.

Com esses valores também é possível rejeitar a hipótese H com 95% de confiança.

As três aplicações da metodologia proposta encontraram a mesma exceção para regras que tinham como previsão non-cleavage.

Esse fato fornece um forte indício que ela representa realmente uma exceção, e não uma mera casualidade nos dados.

Para potencializar a ação da metodologia proposta na descoberta de conhecimento, uma quarta aplicação foi feita, desta vez com todos os exemplos disponíveis.

Na regra R1, mostrada na tabela, que é muito similar às regras gerais das três primeiras aplicações, novamente foi encontrada a exceção if pos6 = E then cleavage.

A hipótese final, com as exceções adicionadas à regras R1, é transcrita na tabela.

Dos 229 exemplos cobertos pela regra R1, 17 foram erroneamente cobertos.

Com a adição da exceção à regra R1, 10 desses exemplos passaram a ser corretamente cobertos.

No entanto, 6 dos exemplos corretamente cobertos passaram a ser cobertos de maneira errada.

Hipótese final com exceções encontrada pela metodologia proposta.

As regras gerais confirmam a importância dos aminoácidos na posição e 5 no processo de clivagem do substrato protéico.

Esse ponto é justamente o ponto onde ocorre a catálise na ligação que irá ser clivada (ligação scissile).

As exceções geradas mostram a importância da posição 6 no processo de clivagem.

Esse fato também foi destacado em.

Em uma tentativa de capturar as exceções utilizando somente um algoritmo de aprendizado tradicional (no caso, o See5, com a opção de gerar conjuntos de regras e sem a opção de agrupar subconjuntos de valores), relaxamos o fator de confiança até o valor de 60% (o procedimento utilizado foi relaxar o fator padrão, que é 25%, de 5 em 5 pontos percentuais até que o atributo pos6 aparecesse em pelo menos uma regra do conjunto de regras).

Essa configuração resultou em um conjunto com 3regras.

O atributo pos6 = E apareceu na regra 29, if pos6 = E then cleavage.

Entretanto, essa regra deve ser analisada com cuidado, uma vez que o See5 com a opção de gerar conjuntos de regras agrupa suas regras em blocos, de acordo com a classe.

Uma regra só tem sentido se nenhuma regra do bloco anterior for disparada.

Essa regra 29 pertence ao segundo bloco de regras e, portanto, só é valida se o exemplo em questão não for coberto por nenhuma regra do primeiro bloco.

Traçando um paralelo com exceções, as regras do bloco podem ser pensadas como exceções às regras do bloco 1.

Entretanto, o conceito de localidade da exceção é perdido, uma vez que as regras são apresentadas em blocos, e uma regra de um bloco não tem nenhuma relação com as dos outros blocos, a não ser no que se refere à ordenação dos blocos.

O mesmo procedimento foi utilizado com o See5, desta vez sem a opção de gerar conjuntos de regras e sem a opção de agrupar subconjuntos de valores.

Nesse caso, o resultado é a indução de uma árvore de decisão, que pode ser transcrita em regras disjuntas.

Novamente o fator de confiança para o qual apareceu o atributo pos6 em pelo menos um dos nós da árvore foi de 60%.

O tamanho da árvore induzida é de 55 nós folhas, que corresponde a 55 regras.

Duas dessas 55 regras apresentam o atributo pos6 = E (if pos= L and pos6 = E then cleavage e if pos= M and pos6 = E then cleavage).

Entretanto, perde-se o conceito de localidade da exceção, pois ela fica fragmentada entre as regras do conjunto de regras.

Esses exemplos ilustram a utilidade do método aqui proposto para procurar por exceções, pois além das regras induzidas por algoritmos tradicionais de AM não preservarem o conceito de localidade, ao relaxar-se o fator de confiança pode-se estar super-ajustando o algoritmo ao problema.

Como visto no Capítulo 3, algoritmos de indução de regras de classificação podem ser divididos em duas famílias, dividir-para-conquistar e separarpara-conquistar.

As duas famílias têm várias características em comum, entre elas a suposição que o espaço de exemplos contém regiões contínuas de exemplos de uma mesma classe.

Recordando, nos algoritmos da família separar-para-conquistar, o algoritmo de busca geralmente utilizado é um procedimento iterativo de busca em feixe para a cobertura do conjunto de exemplos que, a cada iteração, encontra a melhor regra (de acordo com os critérios de busca estabelecidos pelo algoritmo) e remove os exemplos cobertos.

O processo é recursivamente aplicado aos exemplos restantes até que o conjunto de treinamento esteja vazio.

Para formar o modelo de classificação, as regras podem ser arranjadas ou em uma lista ordenada de regras (lista de decisão) ou em um conjunto de regras.

Nesse último caso, deve haver um critério adicional para decidir a classificação de um exemplo, no caso em que mais de uma regra que predigam classes diferentes sejam disparadas.

Em contrapartida, na família dividir-para-conquistar, ao invés de se gerar um modelo de classificação que recursivamente separa uma porção dos exemplos, um modelo global é criado por recursivos refinamentos do modelo atual.

A cada iteração, o conjunto de exemplos é particionado em conjuntos disjuntos.

O resultado é geralmente expresso como uma árvore de decisão que divide completamente o espaço de exemplos em regiões hiper-retangulares não sobrepostas e paralela aos eixos.

Apesar das árvores de decisão serem muito utilizadas na prática, em muitas aplicações é preferível utilizar algoritmos da família separar-paraconquistar.

Isso se deve ao fato de que, pela necessidade de criar modelos completos e com regras disjuntas, em domínios complexos, árvores de decisão tendem a serem de grandes dimensões.

Em contrapartida, como os algoritmos do tipo separar-para-conquistar podem induzir regras com sobreposição, os conjuntos de regras podem ser mais simples.

Entretanto, um dos problemas com a abordagem de cobertura de conjunto utilizada na maioria dos algoritmos da família separar-para-conquistar é que as regras são induzidas isoladamente, mesmo que elas sejam utilizadas em conjunto com outras regras dentro do modelo de classificação.

Além disso, como o número de exemplos é reduzido a cada iteração, cada vez menos exemplos estão disponíveis para a indução de novas regras.

Em muitos casos ocorre uma fragmentação do conjunto de treinamento e a indução de regras com um baixo suporte estatístico.

Além disso, cada nova regra é construída em completa ignorância das demais e dos exemplos já cobertos.

Se uma regra ruim for introduzida no conjunto de regras, não há como procurar por uma regra melhor que cubra aqueles exemplos por ela cobertos i e, não existe backtracking.

Para suprir algumas das deficiências da abordagem de cobertura de conjunto desenvolvemos o algoritmo ROCCER.

A abordagem do ROCCER para a geração de regras consiste em utilizar a análise ROC para a seleção de regras que irão compor o modelo.

Como descrito no Capítulo 4, gráficos ROC são curvas da porcentagem de exemplos positivos classificados incorretamente-taxa de falsos positivos (fpr)-no eixo x e a porcentagem de exemplos positivos corretamente classificados-taxa de verdadeiros positivos (tpr)-no eixo y.

É importante ressaltar que se pode representar em um gráfico ROC apenas uma regra isoladamente, um modelo de classificação formado por conjunto de regras ou apenas parte do modelo, formado por um subconjunto das regras que o compõem.

Para modelos em que a predição está associada não somente a uma classe, mas também a um valor contínuo, de tal maneira que seja possível ajustar o limiar de classificação, é possível obter vários pontos (fpr,tpr) pela variação do limiar.

Conectando-se os pontos obtém-se uma curva no espaço ROC que representa o comportamento do modelo sobre todas as possíveis escolhas do limiar de classificação.

Dentro de contexto de aprendizado de regras, Fürnkranz & Flach mostram que o aprendizado de regras utilizando a abordagem de cobertura de conjunto pode ser vista como o traço de uma curva no espaço ROC.

Para entender o porquê, assuma que tenhamos uma lista de decisão vazia, representada pelo ponto (0,0) no espaço ROC.

Ao adicionarmos uma nova regra R à lista de decisão, movemos do ponto inicial (0,0) para o ponto (fpr,tpr).

Adicionando a regra R, movemos do ponto (fpr,tpr) para o ponto (fpr,tpr), no qual fpr e tpr são as tpr e fpr da lista de decisão parcial contendo todas as regras induzidas até agora, incluindo R.

Uma curvar pode então ser traçada plotando-se todas as listas de decisão parciais (fpr,tpr), para j variando de 0 ate o número n de regras na lista de decisão final, na ordem em que elas são lidas.

Para se completar a curva, podemos imaginar a adição de uma regra padrão que sempre prediz a classe positiva ao final da lista de decisão, conectando o ponto (fpr,tpr) ao ponto (1,1).

A nossa abordagem é baseada nesse mecanismo e no fato de que, em modelos em que é possível ajustar o limiar de classificação, os pontos que representam os limiares ótimos para diferentes condições residem na região convexa mais externa à curva ROC.

Em nossa abordagem, as regras provêm de um extenso conjunto de regras externo (em nossa implementação, utilizamos o algoritmo Apriori para a geração de regras de associação, fixando a cabeça da regra em cada possível valor do atributo classe) e aplicamos um passo de seleção de regras baseado na análise ROC.

A idéia básica é de somente inserir uma regra na lista de decisão se, e somente se, essa inserção está fora da região convexa com as regras que já foram inseridas na lista de decisão.

Em outras palavras, uma regra é inserida somente se ela aumenta a região convexa das regras já existentes na lista de decisão.

Caso contário, a regra é descartada.

Para se entender melhor o funcionamento do algoritmo, ele será introduzido utilizando um exemplo.

Regras são selecionadas separadamente para cada uma das classes e são armazenadas em uma lista de decisão.

Para tratar problemas com várias classes, o procedimento é repetido para cada uma das classes.

Para facilitar a explicação, designamos a classe para a qual estamos selecionando regras como positiva e como negativa (a conjunção de) os exemplos na(s) outra(s) classe(s).

Considere (fpr, tpr) como as taxas de verdadeiros positivos e falsos positivos de uma dada regra R no espaço ROC, (tpr, fpr) como um ponto i na curva ROC que corresponde ao modelo construído como uma lista de decisão com i regras.

Primeiramente, inicializamos a lista de decisão com a regra R padrão, que sempre prediz a classe positiva.

A região convexa da curva ROC é então formada por pontos, (0,0) e (1,1).

Esses dois pontos têm as seguintes interpretações, "ignore a regra padrão (classifique todo mundo como negativo)" ou "use a regra padrão (classifique todo mundo como positivo)".

Suponha agora que queiramos inserir uma nova regra R.

Como a região convexa atual da curva ROC é formada somente pelo segmento de reta (0,0) (1,1), R somente será inserido se o ponto correspondente a regra no espaço ROC (fpr,tpr) está acima da região convexa.

Assumamos que R é inserido.

Então, a região convexa atual é atualizada, e passa a conter os pontos (0,0),(fpr,tpr),(1,1), no qual fpr = fpr e tpr = tpr.

Essa inserção corresponde a um ponto fora da região convexa (diagonal principal) e é inserida na lista de decisão.

Suponha agora que queiramos inserir uma segunda regra R.

Como dito anteriormente, na abordagem tradicional de cobertura de conjunto o aprendizado de uma nova regra não leva em consideração as regras anteriormente aprendidas.

Em nossa abordagem, tentamos contornar essa deficiência utilizado o gráfico ROC para analisar interações entre as regras.

Para esse fim, comparamos a regra que estamos tentando inserir com a inclinação de cada segmento de reta na região convexa do gráfico ROC.

No exemplo que estamos tratando, se a inclinação do ponto formado pela origem e o ponto (fpr,tpr) está acima da inclinação do segmento formado pela origem e o ponto (fpr,tpr), R está acima da região convexa do gráfico ROC e, portanto, deve ser inserido na lista de decisão antes de R.

Esse fato é equivalente a R ter sido induzida antes de R na abordagem tradicional de cobertura de conjunto.

Uma vez que o algoritmo por nós proposto compara cada nova regra a ser inserida com as regras que compõem a lista de decisão, nosso algoritmo provê um mecanismo implícito de backtracking.

Também é importante notar que a inserção de R irá provocar mudanças nos outros pontos da curva ROC.

O primeiro ponto não trivial do gráfico ROC passará a ser (fpr,tpr).

Se as regras R e R não têm nenhuma sobreposição, o segundo ponto será (fpr +fpr,tpr +tpr).

Entretanto, se houver alguma sobreposição entre R e R, deve-se remover os exemplos cobertos por ambas as regras para se calcular o segundo ponto.

Se R não for inserido na primeira iteração, continuamos a comparação com os segmentos de retas remanescentes na região convexa do gráfico ROC.

Antes de comparar com o próximo segmento de reta, atualizamos os valores de fpr e tpr de R removendo os exemplos já cobertos por R (os 1 exemplos para os quais o antecedente de R é verdadeiro).

Isso é equivalente a "interpretar" R como ¬R R.

Se a nova posição de R está além da região convexa, a inclinação do segmento de reta formado por (fpr,tpr) e (fpr,tpr) é maior do que a inclinação do segmento de reta formado por R até R, R é inserido na lista de decisão depois de R.

Caso contrário, uma vez que não existem mais regras na lista de decisão R, é descartado.

O pseudo-código do algoritmo ROCCER é mostrado na Algoritmo 51.

R não está fora da região convexa mas está quando comparado com a quando comparado com R R.

Devido à sobreposição entre as regras, esse procedimento não leva necessariamente a uma curva convexa.

A inserção de uma nova regra na lista de decisão pode introduzir concavidades antes ou depois do ponto de inserção.

Se uma concavidade ocorrer depois da inserção, a regra inserida cobre exemplos originalmente cobertos por regras subseqüentes.

Além disso, a regra inserida cobre com uma melhor precisão os exemplos cobertos pelas regras subseqüentes.

Nesse caso, remove-se as regras em que a concavidade ocorre.

No caso em que a concavidade ocorrer antes da regra inserida, tanto a nova regra quanto a regra que já está na lista de decisão compartilham uma região na qual ambas classificam mal uma porção dos exemplos.

Nesse caso, é injustificável excluir a regra que já estava na lista de decisão e manter somente a nova regra, pois elas se complementam mutuamente.

Nossa abordagem para esse caso é de construir a disjunção das duas regras e tratá-las como uma regra única.

Em nossa implementação, o conjunto inicial de regras apresentado ao ROCCER é inicialmente ordenado utilizando-se a distância ao ponto (0,1) no espaço ROC.

Entretanto, como o ROCCER permite que regras sejam removidas e também provê um mecanismo de backtracking, essa ordenação é mais uma conveniência para acelerar a execução do algoritmo.

É importante ressaltar que a dependência com relação à ordem em que as regras são induzidas é muito menor do que o algoritmo de cobertura de conjunto, utilizado na maioria dos algoritmos que induzem listas de decisão.

Somente em casos de empate com uma regra previamente inserida é que essa pré-ordem é importante, pois a regra que já foi previamente inserida na lista de decisão será mantida e a nova descartada.

No entanto, novos experimentos com diferentes pré-ordenações podem ser interessantes para testar se é possível diminuir o tempo de execução do algoritmo.

Concluímos assim a descrição da fase de treinamento do ROCCER.

Para decidir a classe de um novo exemplo, também utilizamos um método baseado em gráficos ROC.

O teorema de Bayes afirma que as chances de um modelo de classificação classificar corretamente um novo exemplo (chances a posteriori) é dada pela razão da verossimilhança multiplicado pelas chances do novo exemplo ser da classe predita (chances a priori).

No espaço ROC, a razão de verossimilhança é dada por.

Relembre que as regras são selecionadas separadamente para cada uma das classes.

Dessa maneira, temos uma lista de decisão e uma região convexa para cada uma das classes.

Para classificar um novo exemplo, também consideramos cada classe em separado, e, para cada classe, selecionamos a primeira regra daquela classe que cobre o exemplo note que se nenhuma regra cobrir o exemplo, a regra R para aquela classe é disparad e a sua respectiva inclinação no espaço ROC.

Essa inclinação é justamente a razão de verossimilhança.

As chances a posteriori são então convertidas em probabilidades (para ranking) ou selecionamos a classe com maior probabilidade (para classificação).

Para avaliar empiricamente a nossa proposta conduzimos uma avaliação experimental utilizando 16 conjuntos de dados provenientes do repositório de dados da Universidade da Califórnia, campus de Irvine-UCI.

Restringimos os conjuntos de dados a conjuntos sem valores desconhecidos nos atributos pois o algoritmo Apriori, utilizado para a geração das regras de associação que usamos como entrada para o ROCCER no experimento, não trata atributos com valores desconhecidos.

Na mostrado um sumário das principais características dos conjuntos de dados utilizados no experimento.

Nessa tabela é mostrado, para cada conjunto de dados, o número de atributos (n), o número de exemplos (n), e a porcentagem de exemplos na classe majoritária.

Para os conjuntos de dados com mais de duas classes, a classe com menos exemplos foi designada como classe positiva e o restante dos exemplos foram agrupados na classe negativa.

Os resultados obtidos pelo ROCCER foram comparados com os seguintes sistemas de aprendizado de regras, CNEsse sistema é uma implementação clássica da família de algoritmos separar-para-conquistar.

Em sua primeira versão Clark & Niblett, Descrição dos conjuntos de dados utilizado no experimento com o ROCCER.

Slipper A principal diferença com relação ao Ripper é a utilização de pesos para ponderar os exemplos já cobertos, ao invés de simplesmente removê-los.

C45 O sistema C45 é um membro da família de algoritmos dividir-para-conquistar.

Ele utiliza o ganho de informação como um medida de qualidade para construir uma árvore de decisão e um sistema de pós-poda baseado na redução do erro.

Cada ramo da árvore pode ser considerado como uma regra.

Ripper e Slipper foram utilizados com a opção a habilitada para gerar regras para ambas as classes.

CNfoi utilizado em suas duas versões, com a indução de regras ordenadas (CNOR) e regras não ordenadas (CN2).

Também foram utilizadas ambas as árvores induzidas pelo C45, a árvore podada (C4e a árvore não podada (C45 NP).

Todos os outros parâmetros foram definidos com seus valores padrão.

Para se calcular a área abaixo da curva ROC, probabilidades associadas a cada regra foram calculadas utilizando a correção de Laplace.

Na versão não ordenada do CN2, as probabilidades foram calculadas levando-se em consideração todas as regras disparadas.

Os valores da AUC foram estimados utilizando a regra do trapézio.

Foi utilizada a implementação do Apriori implementada por Borgelt & Kruse.

Os parâmetros do Apriori foram inicializados com 50% de confiança e 1/da porcentagem da classe minoritária como suporte.

Para o ROCCER, as probabilidades foram estimadas utilizando chances a posteriori, como descritos na Seção 521.

Nossa abordagem também foi comparada com um modelo de classificação composto por todas as regras geradas pelo Apriori.

Os experimentos foram executados utilizando-se validação cruzada com 10 partições (fold cross validation).

O experimento é pareado, isto é, para todos os sistemas foram fornecidos os mesmos conjuntos de treinamento e teste.

A média dos valores da AUC, bem como os respectivos desvios padrão entre parênteses, são mostrados na tabela.

Para a realização de testes estatísticos foi utilizado o teste bicaudal de Dunnet Hochberg & Tamhane.

Hsu, que é indicado para múltiplas comparações com um controle.

Para a realização desse teste, ROCCER foi utilizado como controle.

Dessa maneira, para cada conjunto de dados, testamos a seguinte hipótese, O teste de hipótese foi realizado com um nível de confiança de 95%.

Na tabela, algoritmos cujo desempenho, medidos em termos da área abaixo da curva ROC AU, foram estatisticamente melhores que o ROCCER estão representados por uma célula de cor cinza escuro.

Para os algoritmos cujo desempenho é pior que o ROCCER, as células foram coloridas de cinza claro.

Na tabela são mostradas relativamente poucas diferenças estatisticamente significantes.

Comparando com C45, ROCCER foi melhor quatro vezes e pior uma vez.

Tem-se o mesmo resultado quando comparamos ROCCER com o Ripper.

Comparando-se com o Slipper, o resultado é que ROCCER foi melhor cinco vezes e nenhuma vez pior.

Quando se compara com C45 sem poda e ambas as versões do CN2, ROCCER foi duas vezes pior e nenhuma vez melhor.

Uma possível explicação para esses casos pode ser a grande desproporção de exemplos entre as classes nesses conjuntos de dados.

Para que o Apriori possa encontrar associações válidas para ambas as classes nesses domínios, o parâmetro de suporte do algoritmo deve ser definido com um valor muito baixo.

Nesse caso, o número de regras geradas para a classe majoritária é muito grande, mas para a classe minoritária é muito pequeno.

Uma possível solução para esse problema é, por exemplo, colocar um suporte mínimo diferente para cada classe.

Levando em consideração todos os algoritmos de aprendizado de regras, ROCCER foi 1vezes estatisticamente melhor que esses algoritmos e em 9 casos teve um desempenho pior.

Quando comparamos com todas as regras geradas pelo Apriori, ROCCER foi estatisticamente melhor em 6 ocasiões, e não foi pior em nenhum dos casos.

Em outras palavras, é possível afirmar que o mecanismo de seleção de regras do ROCCER é responsável por um ganho de desempenho com relação ao conjunto inicial de regras e que ROCCER tem desempenho ao menos comparável com algoritmos clássicos de indução de regras.

Os bons resultados com ambas as versões do CNe os valores relativamente baixos da AUC do Ripper e do Slipper podem ser explicados pela não existência de mecanismo de poda nesses dois últimos algoritmos.

Resultados já reportados na literatura mostram que árvores não podadas são melhores para ordenar exemplos e, por esse motivo, produzem resultados melhores em termos da AUC.

É possível que o mesmo fenômeno também ocorra em algoritmos da família separar-para-conquistar.

Também analisamos o tamanho dos modelos gerados.

Na tabela são apresentados o tamanho do conjunto de regras para cada domínio e para cada algoritmo.

Tamanho 0 significa que o modelo é formado apenas pela regra padrão que geralmente classifica todos os exemplos na classe majoritári.

Para a realização de testes estatísticos foi novamente utilizado o teste bicaudal de Dunnet.

Dessa maneira, para cada conjunto de dados, testamos a seguinte hipótese, O teste de hipótese foi realizado com um nível de confiança de 95%.

Assim como na tabela, algoritmos cujo desempenho foram estatisticamente melhores que o ROCCER estão representados por uma célula de cor cinza escuro.

Para os algoritmos cujo desempenho é pior que o ROCCER, as células foram destacadas com a cor cinza claro.

Nesse caso, a vantagem do ROCCER sobre os outros algoritmos é destacada.

Afora alguma exceções, ROCCER produziu conjuntos de regras menores que o C45 sem poda, que o CNem ambas as versões e que o Slipper.

Em contrapartida, o Ripper produziu conjuntos significativamente menores em 7 dos 16 domínios, contra somente um significativamente menor produzido pelo ROCCER.

Analisando ambas as tabelas é possível concluir que, de maneira geral, ROCCER combina o melhor dos dois mundos, ele é capaz de gerar modelos com uma AUC comparável com os melhores algoritmos de indução de regras mas com um tamanho consideravelmente melhor que esses algoritmos.

Finalmente, na tabelasão apresentadas estatísticas a respeito das regras individuais que compõem cada modelo, o que também monstra uma outra vantagem do ROCCER.

As estatísticas apresentadas nessa tabela são ao respeito do suporte, taxa de acerto relativa ponderada (WRAc e razão de chances (odds ratio).

O suporte varia de 0 a 100% e é uma medida da cobertura relativa de cada regra.

A taxa de acerto relativa ponderada, também conhecida como novidade, varia entre025 e 025 e mede a significância de uma regra em termos da diferença entre o número observado e esperado de verdadeiros positivos, como descrito na Seção 36.

A razão entre chances varia entre 0 até e é uma medida da força entre a associação das duas partes da regra.

Ela é definida como a razão entre as duas diagonais da matriz de contingência.

Analisando essa tabela fica evidente que o ROCCER tem valores consideravelmente altos para todas essas medidas.

Esse fato é um indicativo que as regras selecionadas pelo ROCCER têm isoladamente um maior significado que as regras induzidas pelos outros algoritmos.

Com respeito à complexidade, ROCCER é computacionalmente mais custoso que os outros algoritmos.

No pior caso, a complexidade é da ordem de O(n), na qual n é dado pelo número de regras utilizadas como entrada ao algoritmo.

Entretanto, na média, o número de iterações é da ordem de (mn), no qual m é o número de regras selecionadas pelo algoritmo.

Para a maioria dos conjuntos de dados, o tempo de execução variou entre alguns poucos segundos até 5 minutos para cada partição (em um computador Pentium 2Ghz com 51MB de RAM).

Para esses conjuntos de dados, o número de regras utilizado como entrada foi de até 1000 regras.

Para alguns poucos domínios (Kr-vs-kp e Satimage) o número de regras gerados pelo Apriori foi muito alto.

Nesses casos, o tempo de execução ficou na ordem de 1,5 horas para cada partição.

Suporte, precisão relativa ponderada e razão de chances médias de todas as regras induzidas As duas principais contribuições descritas neste capítulo são as duas novas abordagens para a geração de regras.

Na primeira delas, é possível extrair exceções a partir de regras gerais de classificação.

Essa abordagem permite que haja uma melhor intepretação semântica das regras geradas.

A segunda abordagem baseia-se no uso da análise ROC para selecionar regras a partir de um conjunto maior de regras.

As regras selecionadas formam uma lista de decisão.

Em geral, o algoritmo tem um desempenho comparável, medido em termos da AUC, a vários algoritmos de aprendizado de regras descritos na literatura.

Um aspecto no qual o ROCCER se destaca tem a ver com o número de regras selecionadas que, na maioria das vezes, é sistematicamente inferior ao número de regras induzidas pelos outros algoritmos.

NESTE capítulo é apresentada uma introdução ao problema de classes desbalanceadas.

Na Seção 61 é feita uma introdução ao problema, no qual algumas das classes são geralmente muito mais representadas no conjunto de exemplos que outras.

Na Seção 6são apresentados experimentos realizados com conjuntos de dados artificiais com o intuito de ganhar um melhor entendimento a respeito do problema de classes desbalanceadas e confirmar nossa hipótese de que a sobreposição de exemplos entre as classes é um fator complicante desse problema.

Finalmente, na Seção 6são apresentadas as considerações finais deste capítulo.

Muitos aspectos podem influenciar o desempenho de um modelo de classificação criado por um sistema de aprendizado supervisionado.

Um desses aspectos está correlacionado com a diferença entre o número de exemplos pertencentes a cada uma das classes.

Quando essa diferença é grande, os sistemas de aprendizado podem encontrar dificuldades em induzir o conceito relacionado à classe minoritária.

Nessas condições, modelos de classificação que são otimizados em relação à precisão têm tendência de criar modelos triviais, que quase sempre predizem a classe majoritária.

Entretanto, em muitos dos problemas reais, uma grande desproporção no número de casos pertencentes a cada uma das classes é comum.

Por exemplo, na detecção de fraudes em chamadas telefônicas e transações realizadas com cartões de crédito, o número de transações legítimas é muito maior que o de transações fraudulentas.

Na modelagem de risco de seguros, apenas uma pequena porcentagem dos segurados reclama suas apólices em um dado período.

Outros exemplos de domínios com um desbalanceamento intrínseco entre as classes podem ser encontrados na literatura.

Além disso, em muitas aplicações, não se sabe qual é a proporção exata de exemplos pertencentes a cada classe ou se essa proporção pode variar no tempo.

Muitos sistemas de aprendizado, nessas circunstâncias, não estão preparados para induzir modelos de classificação que possam predizer acertadamente as classes minoritárias.

Freqüentemente, esses modelos têm uma boa precisão na classificação da classe majoritária, mas a precisão para a classe minoritária não é aceitável.

O problema é ainda maior quando o custo associado a uma classificação errônea para a classe minoritária é muito maior que o custo de uma classificação errônea para a classe majoritária.

Infelizmente, esta é a norma e não a exceção para a maioria das aplicações com conjuntos de dados desbalanceados, pois geralmente a classe minoritária é a de maior interesse.

Vários pesquisadores têm analisado o problema de aprender a partir de conjuntos de dados com classes desbalanceadas.

Além disso, ocorreram dois whorkshops internacionais relacionados a esse tema, um deles patrocinado pela Associação Americana de Inteligência Artificial-American Association for Artificial Intelligence (AAAI), e o outro acontecido em conjunto com a vigésima Conferência Internacional de Aprendizado de Máquina-International Conference on Machine Learning ICML'0.

Também, a revista do grupo de estudos em mineração de dados da ACM, SIGKDD Explorations, dedicou uma edição especial ao tema.

Dentre os diversos métodos propostos nesses trabalhos, três abordagens principais têm sido utilizadas com maior freqüência.

São elas, Atribuição de custos de classificação incorreta.

Em muitos domínios de aplicação, classificar incorretamente exemplos da classe minoritária é mais custoso do que classificar incorretamente exemplos da classe majoritária.

Para esses domínios, é possível utilizar sistemas de aprendizado sensíveis ao custo de classificação.

Esses sistemas objetivam minimizar o custo total ao invés da taxa de erro de classificação.

A principal restrição ao uso desses sistemas é que o custo de classificação incorreta de cada classe deve ser previamente conhecido e deve ser um valor constante.

Remoção de exemplos das classes majoritárias.

Essa abordagem é geralmente chamada de under-sampling.

Uma forma bastante direta de solucionar o problema de classes desbalanceadas é balancear artificialmente a distribuição das classes no conjunto de exemplos.

Os métodos de under-sampling visam balancear o conjunto de dados por meio da remoção de exemplos das classes majoritárias.

Inclusão de exemplos das classes minoritárias.

Métodos dessa categoria são geralmente conhecidos como métodos de over-sampling.

Os métodos de over-sampling são similares aos métodos de under-sampling.

Entretanto, esses métodos visam balancear a distribuição das classes por meio da replicação de exemplos da classe minoritária.

A atribuição de custos e a inclusão ou remoção de exemplos estão fortemente ligados.

Uma forma de aprender com conjuntos com classes desbalanceadas é treinar um sistema sensível ao custo, com o custo da classe minoritária maior do que o da classe majoritária.

Uma outra forma de fazer com que um sistema de aprendizado se torne sensível ao custo é alterar intencionalmente a distribuição das classes no conjunto.

Por exemplo, para sistemas que não são capazes de lidar com custos, Breiman propõem um método simples e geral para torná-los sensível ao custo para um problema de duas classes.

Esse método baseia-se em modificar a distribuição das classes no conjunto de treinamento de forma a aumentar o número de exemplos da classe mais custosa.

Suponha que a classe positiva é cinco vezes mais custosa que a classe negativa.

Se o número de exemplos positivos for artificialmente aumentado por um fator de cinco, então o sistema de aprendizado, visando reduzir os custos de classificação, irá induzir um modelo que tenda a evitar cometer erros na classe positiva, uma vez que qualquer erro nessa classe é penalizado cinco vezes mais.

Domingos expande essa idéia e apresenta um método geral para tornar qualquer sistema de aprendizado sensível ao custo.

Esse método possui a vantagem de ser aplicável a problemas que possuem qualquer número de classes.

Elkan demonstra um teorema que permite encontrar a proporção de exemplos positivos e negativos de forma a fazer classificações sensíveis ao custo ótimas para um problema de duas classes.

Em suma, a maioria dos métodos que tratam conjuntos de dados com classes desbalanceadas visam melhorar o desempenho da classe minoritária por meio do balanceamento de classes do conjunto de dados ou atribuição de custos.

Como essas duas abordagens estão ligadas, incrementando o número de exemplos da classe minoritária torna essa classe mais custosa, e pode-se esperar que ela será melhor classificada.

Paralelamente, atribuir um custo maior aos exemplos da classe minoritária faz com que os sistemas tendam a se focar nesses exemplos para melhorar a sua função objetivo (que passa a ser o custo total e não mais a taxa de erro de classificação) e espera-se que a classe minoritária seja melhor classificada.

Muitos trabalhos com classes desbalanceadas apontam esse problema como o maior responsável pelo baixo desempenho de algoritmos de aprendizado em domínios nos quais algumas classes são pouco representadas.

Entretanto, algoritmos de aprendizado têm um desempenho surpreendentemente bom, com taxa de acerto e AUC próximos de 100%, mesmo em domínios altamente desbalanceados.

Esse fato é um bom indicativo de que a proporção de exemplos entre as classes não é sempre a responsável pelo mau desempenho dos algoritmos de aprendizado em domínios com um desbalanceamento natural das classes.

Em outras palavras, mesmo que em alguns domínios com classes desbalanceadas algoritmos de aprendizado tenham um desempenho ruim, o desbalanceamento não é, necessariamente, o culpado por esse mau desempenho.

Para ilustrar o problema, considere um problema de decisão muito simples.

O problema está relacionado a construir um modelo de classificação para um problema de apenas um atributo e duas classes, positiva e negativa.

As probabilidades condicionais para ambas as classes são dadas por funções Gaussianas unidimensionais com variância um.

O valor médio de atributo para a classe negativa está uma unidade deslocado para a direita.

O objetivo é construir um modelo de classificação bayesiano assumindo um perfeito conhecimento com respeito às distribuições de probabilidade.

Nesse caso, é possível construir o modelo de classificação ótimo de Bayes.

A linha vertical representa a divisão ótima entre as classes, segundo o critério de Bayes.

Nessas condições, o modelo ótimo não é alterado, não importando o quão desbalanceado é o conjunto de exemplos.

É apresentado o mesmo problema, só que agora não se conhece de antemão as distribuições a priori.

Em outras palavras, as distribuições devem ser estimadas a partir dos dados.

Caso haja uma grande desproporção entre as classes, é provável que os algoritmos de aprendizado produzam estimativas ruins para as classes com poucos exemplos.

A variância é superestimada em 1,5 linha contínu ao invés da variância real 1 linha tracejad.

Ou seja conhecendo-se de antemão as probabilidades condicionais (uma restrição dificilmente aplicável em problemas do mundo real) de maneira que seja possível construir o modelo ideal de Bayes, a distribuição de exemplos entre as classes não representa um problema.

Em contrapartida, quando se utiliza somente os dados disponíveis para estimar os parâmetros, e esses dados não são suficientes para gerar estimativas confiáveis, classes desbalanceadas podem ser um problema na indução de modelos para a classificação de exemplos.

O algoritmo tem completa informação Somente os dados disponíveis são sobre o domínio utilizados para a indução do modelo.

Um problema com grande sobreposição de classes.

Consideremos agora um problema ligeiramente diferente.

Novamente, o problema é composto por um único atributo e duas classes que seguem uma distribuição Gaussiana, mas a média dos valores desse atributo para a classe negativa está agora quatro ao invés de um unidades à direita da classe positiva.

É representado o cenário em que completo conhecimento sobre as distribuições de probabilidades é assumido.

É representado o cenário em que o algoritmo de aprendizado deve estimar esses valores somente com os dados disponíveis.

Pelas mesmas razões descritas anteriormente, quando é assumido perfeito conhecimento a respeito das distribuições, o modelo ótimo de Bayes não é afetado pela distribuição de exemplos entre as classes.

Entretanto, no caso em que não se conhece a priori essas distribuições, o modelo final é afetado.

Note que, uma vez que as médias dos valores do atributo para as duas classes estão mais distantes, as classes estão mais separadas.

Isso é equivalente a dizer que existe uma menor sobreposição entre as classes.

Observe que, por esse motivo, o efeito do desbalanceamento entre as classes é menor do que no caso com uma maior sobreposição de classes.

Um problema com pequena sobreposição de classes.

Note também que mesmo que a distância entre as linhas verticais pontilhada e contínua seja semelhante, a área entre elas e a curva que representa a curva de distribuição de probabilidade é maior.

Isso é equivalente a dizer que o número de exemplos classificados incorretamente no primeiro caso é maior do que o número de exemplos classificados incorretamente no segundo caso.

Esse é um indicativo que o desbalanceamento entre as classes não é o único responsável pelo baixo desempenho em problemas desbalanceados, mas também o grau de sobreposição entre as classes.

Na Seção 6é apresentada uma série de experimentos com conjuntos de dados artificiais com o intuito de confirmar essa hipótese.

Como mencionado previamente, além de atribuir custos diferentes às classes, uma das maneiras mais diretas de lidar com classes desbalanceadas é alterar a distribuição dessas classes de forma a tornar o conjunto de dados mais balanceado.

Nesta seção são descritos os métodos para balancear artificialmente os conjuntos de dados utilizados neste trabalho.

Existem dois métodos básicos para balancear a distribuição das classes, remover exemplos das classes mais populosas e inserir exemplos nas classes menos populosas.

Em suas versões mais simples, essa adição/remoção é feita de maneira aleatória.

Nesses casos, os métodos são geralmente chamados de over-sampling aleatório e under-sampling aleatório, Over-sampling aleatório é um método não heurístico que replica aleato riamente exemplos da classe minoritária.

Em nossa implementação, essa replicação é feita sem reposição.

Under-sampling aleatório também é um método não heurístico que elimina aleatoriamente exemplos da classe majoritária.

Por serem aleatórios, ambos os métodos possuem limitações conhecidas.

Under-sampling aleatório pode eliminar dados potencialmente úteis, e oversampling aleatório pode aumentar as chances de ocorrer superajustamento aos dados, uma vez que cópias exatas dos exemplos pertencentes à classe minoritária são duplicados.

Dessa maneira, em um modelo simbólico, por exemplo, pode-se construir regras que são aparentemente gerais, mas que na verdade cobrem um único exemplo replicado.

Alguns trabalhos recentes têm tentado superar as limitações existentes desses métodos.

Esses métodos geralmente utilizam heurísticas para selecionar os exemplos a serem acrescentados/removidos, cujo principal objetivo é tentar minimizar a quantidade de dados potencialmente úteis descartados.

Algumas dessas heurísticas exploram os exemplos em uma das seguintes categorias, ruído são casos que estão do lado errado da borda de decisão.

Redundantes são casos que podem ser representados por outros casos que estão presentes no conjunto de treinamento.

Próximos à borda são casos que estão próximos da borda de decisão.

Seguros são casos que não são ruído, não estão excessivamente próximos à borda de decisão e, também, não estão muito distantes dela.

Ruído é indesejável em qualquer condição de aprendizado.

Exemplos redundantes não acrescentam muita informação ao sistema de aprendizado e casos próximos à borda são pouco confiáveis pois não se tem certeza sobre o verdadeiro local da fronteira entre uma classe e outra.

Por exemplo, uma pequena quantidade de ruído pode mover esses exemplos para o lado errado da fronteira de decisão.

Os métodos utilizados neste trabalho são descritos a seguir, 1 Os métodos descritos nesta seção foram implementados na biblioteca DOL, que é parte do sistema para descoberta de conhecimento DISCOVER, que vem sendo desenvolvido em nosso laboratório de pesquisa.

Ligações Tomek Casos próximos à borda e ruído podem ser identificados por meio das ligações Tomek, e removidos do conjunto de dados.

Uma ligação Tomek pode ser definida da seguinte maneira, Sejam e e e dois exemplos de classes diferentes.

Seja d uma função de distância entre exemplos.

Um par de exemplos constitui uma ligação Tomek se não existe um exemplo e, tal que a distância d < d ou d < d.

Se dois exemplos formam uma ligação Tomek, então, ou e e e são exemplos próximos à borda de decisão, ou um desses exemplos é possivelmente ruído.

No uso de ligações Tomek para o balanceamento de conjuntos de dados, apenas os exemplos da classe majoritária que possuem ligações Tomek são removidos.

Regra do vizinho mais próximo condensada Parte dos casos redundantes pode ser removida por meio da identificação de um subconjunto consistente.

Um subconjunto E E é consistente com E se utilizando o algoritmo do vizinhos-mais-próximo (NN) ele classifica corretamente os casos em E.

Essa abordagem é geralmente conhecida como regra do vizinho mais próximo condensada, CNN (Condensed Nearest Neighbor Rule).

Um algoritmo para a geração de subconjunto consistente consiste nos seguintes passos, Primeiramente é selecionado aleatoriamente um exemplo da classe majoritária e todos os exemplos da classe minoritária, que são inseridos em E.

A seguir, usa-se o algoritmo NN sobre o conjunto E para classificar os exemplos em E.

Todo exemplo incorretamente classificado de E é movido para E.

A idéia por detrás desse algoritmo é remover exemplos que estão muito distantes da fronteira de decisão, uma vez que esses exemplos são geralmente considerados menos importantes no processo de aprendizagem.

Também é importante notar que esse algoritmo não encontra o conjunto consistente ótimo a partir de E.

Seleção unilateral é um método que consiste da aplicação do algoritmo para a identificação de ligações Tomek seguido da aplicação do CNN.

Essa abordagem é conhecida como seleção unilateral.

Ligações Tomek são utilizadas para identificar exemplos da classe majoritária que se sobrepõem à classe minoritária e CNN é utilizado para remover exemplos muito distantes da fronteira de decisão.

O restante dos exemplos, exemplos da classe majoritária "seguros" e todos os exemplos da classe minoritária, são utilizados para a aprendizagem.

CNN + ligações Tomek em propomos a inversão dos passos da seleção unilateral.

Como a identificação de ligações Tomek é computacionalmente custosa, ela é computacionalmente mais efetiva se aplicada em um conjunto reduzido.

Regra de limpeza da vizinhança o método da limpeza do vizinho -NCL (Neighborhood Cleaning Rule)-utiliza a regra do vizinho mais próximo ENN de Wilson para remover exemplos da classe majoritária.

ENN remove exemplos cuja classe difere da classe por, pelo menos, dos seus vizinhos mais próximos.

SMOTE Chawla propõem um método que não replica os exemplos de treinamento.

Nesse trabalho, o método de over-sampling cria novos exemplos da classe minoritária por meio da interpolação de diversos exemplos dessa classe que se encontram próximos.

Esse método é chamado de SMOTE (Synthetic Minority Over-sampling Technique).

SMOTE + ligações Tomek mesmo que os métodos de over-sampling possam balancear a distribuição de exemplos entre as classes, outros problemas presentes em conjuntos de dados desbalanceados não são resolvidos.

Frequentemente, os exemplos que compõem a classe minoritária não estão bem agrupados e pode haver uma grande sobreposição entre as classes.

Com o objetivo de melhorar a definição dos agrupamentos de dados no conjunto de treinamento, em propomos a aplicação do método para a identificação de ligações Tomek após a aplicação do método SMOTE.

Diferentemente da aplicação de ligações Tomek como método de under-sampling, nesse caso (como o conjunto de dados foi previamente balanceado com exemplos "sintéticos") removemos exemplos de ambas as classes.

SMOTE + ENN também propomos a aplicação do método ENN após a aplicação do método SMOTE.

A motivação é similar a do método SMOTE + ligações Tomek.

Entretanto, ENN tende a remover mais exemplos do que as ligações Tomek, promovendo uma maior limpeza no conjunto de dados.

Similarmente ao método SMOTE + ligações Tomek, ENN é utilizado para remover exemplos de ambas as classes.

Apesar de extremamente utilizados para a validação empírica de estudos em aprendizado de máquina, a realização de estudos com conjuntos de dados naturais muitas vezes não são apropriados para se fornecer insights a respeito das causas do porque uma abordagem é melhor que a outra.

Isso se deve ao fato que não se conhece o processo que gera tais dados.

Insights são geralmente obtidos pela execução de experimentos em conjuntos de dados artificiais, especialmente desenvolvidos para se testar uma hipótese específica.

A importância de se utilizar conjuntos artificiais está relacionada ao fato de que eles permitem que se variem sistematicamente as características do domínio de interesse, tais como o número de atributos relevantes ou irrelevantes, quantidade de ruído, número de classes, desbalanceamento de classes, complexidade do conceito, e outros.

Dessa maneira, eles permitem que os pesquisadores testem hipóteses a respeito do desempenho de cada método.

Nesta seção é descrita uma série de experimentos realizados com conjuntos de dados artificiais, com o objetivo de procurar um melhor entendimento do problema de desbalanceamento entre as classes.

Para realizar nossos experimentos foram gerados 10 domínios artificiais.

Esses domínios são compostos por dois agrupamentos, um representando a classe majoritária e o outro representando a minoritária.

Os exemplos gerados no experimento têm dois parâmetros controlados.

O primeiro é a distância entre os centros dos agrupamentos de cada uma das classes e o segundo é a proporção de exemplos em cada uma das classes.

A distância entre os centros dos agrupamentos nos permite controlar o "grau de dificuldade" de classificar corretamente as duas classes.

A proporção de exemplos em cada classe nos permite analisar o desempenho de algoritmos de aprendizado em diferentes condições de proporções de exemplos para cada uma das classes.

Cada domínio é composto por 5 atributos.

Os atributos são independentes entre si, e cada atributo é proveniente de uma distribuição Gaussiana com variância 1.

Além disso, cada domínio tem duas classes, designadas pelo rótulo genérico positivo classe minoritári e negativo classe majoritári.

Para o primeiro domínio, o centro de cada Gaussiana é o mesmo para ambas as classes.

Para os domínios restantes, é incrementado o centro médi de cada atributo em uma unidade, até o máximo de nove.

Para cada domínio foram gerados catorze conjuntos de dados.

Cada conjunto tem 10000 exemplos com diferentes proporções de exemplos em cada classe, variando-a de 1% até 45% os exemplos pertencentes à classe positiva.

O restante dos exemplos pertencem à classe negativa.

As proporções utilizadas foram as seguintes, 1%, 25%, 5%, 75% 10%, 125%, 15%, 175%, 20%, 25%, 30%, 35%, 40% e 45%.

Também incluímos um conjunto de dados de controle com a mesma distribuição de exemplos em ambas as classes.

Mesmo que a complexidade dos domínios gerados seja aparentemente simples (geramos conjuntos de dados com somente 5 atributos, duas classes e cada classe agrupada em somente um grupo), essa situação é freqüentemente enfrentada por algoritmos de aprendizado supervisionado, uma vez que a maioria desses algoritmos utiliza abordagens recursivas (como as estratégias dividir-para-conquistar ou separar-para-conquistar).

Além disso, a distribuição Gaussiana pode ser utilizada como aproximação de várias outras distribuições estatísticas.

A utilização de funções Gaussianas também nos permite calcular facilmente valores teóricos da AUC para o modelo ótimo de Bayes.

A AUC pode ser calculada utilizando-se a Equação 61, na qual é a distribuição normal cumulativa padrão, é a distância euclidiana entre os centros das duas distribuições, e e são, respectivamente, o desvio padrão do centróide das classes positivas e negativas.

Para executar os experimentos utilizamos o algoritmo C45 para a indução de árvores de decisão.

Dois motivos nos levaram a escolher o C45.

Primeiramente, a indução de árvores é um dos métodos mais utilizados na construção de modelos de classificação.

Além disso, C45 é muito utilizado na avaliação de algoritmos de aprendizado em domínios com classes desbalanceadas.

Modificamos a árvore induzida pelo C45 para predizer probabilidades ao invés de predizer somente a classe, como proposto por.

Os resultados foram avaliados utilizando-se a AUC.

Todos os experimentos foram realizados utilizando-se validação cruzada com 10 partições.

Deve ser observado que, apesar do baixo desempenho em alguns conjuntos de dados desbalanceados, para alguns domínios em que esse problema ocorre algoritmos de aprendizado têm um desempenho surpreendentemente bom.

Esse fato nos levou a conjectura de que o desbalanceamento entre as classes não é sempre um fator determinante para o baixo desempenho de algoritmos de aprendizado em domínios em que esse problema ocorre.

Em, como descrito na Seção 611 consideramos a hipótese de que o grau de sobreposição entre as classes é um fator que colabora para um baixo desempenho em domínios com classes desbalanceadas.

Estão sumarizados os principais resultados de nosso trabalho.

Para uma melhor visualização, omitimos algumas proporções e distâncias entre os centros das classes.

Entretanto, as linhas omitidas são muito similares àquelas cujas distâncias entre os centros dos agrupamentos de cada classe estão separados 9 unidades entre si e a proporção de exemplos é de 50% em cada classe.

Estão representadas a porcentagem de exemplos pertencentes à classe positiva no conjunto de dados versus a AUC dos modelos induzidos pelo C45 para diferentes distâncias entre os centróides da classe positiva e da classe negativa.

Considere a curva em que a classe positiva está duas unidades deslocada da classe negativa.

Observe que os modelos induzidos para essa distância têm um ótimo desempenho, com AUC maior que 90%, mesmo que a proporção de exemplos da classe positiva seja de somente 1% dos exemplos.

Estão representadas a variação do centróide da classe positiva versus a AUC dos modelos induzidos pelo C45 para diferentes proporções de exemplos entre as classes.

Nesse gráfico pode ser observado que a maior degradação no desempenho dos modelos ocorre principalmente quando a diferença entre os centróides das classes positiva e negativa é de uma unidade.

Nesse caso, a degradação é significativamente alta para conjuntos de dados muito desbalanceados, mas diminui conforme a distância entre os centróides aumenta.

A diferença entre o desempenho do algoritmo para domínios com distância entre os centróides maior que três unidades é estatisticamente insignificante, independentemente de quantos exemplos pertencem à classe positiva.

Esses resultados estão de acordo com a nossa hipótese de que o problema de desbalanceamento entre as classes é maior quando existe uma alta sobreposição entre as classes.

Um experimento similar, também com conjuntos de dados artificiais, mas gerados de maneira diferente do reportado neste trabalho, também chegou à conclusão de que o desbalanceamento entre as classes não é sempre o responsável pela degradação de desempenho em algoritmos de aprendizado.

Japkowicz conclui que o problema depende tanto da "complexidade do conceito", na qual complexidade do conceito corresponde ao número de subgrupos em que as classes estão divididas, e do tamanho do conjunto de Proporção de exemplos positivos.

Variação na proporção de exemplos positivos versus AUC.

Distância entre os centróides.

Variação no centróide da classe positiva versus AUC.

Resultados experimentais do C45 aplicado a conjuntos de dados com diversos graus de sobreposição e desbalanceamento entre as classes.

Nossa conclusão é similar a essa, mas em nosso caso "complexidade do conceito" é medida como o grau de sobreposição entre as classes.

Verificada empiricamente a nosso hipótese de que a sobreposição de exemplos entre as classes é um fator que potencializa o problema de classes desbalanceadas, em analisamos o comportamento de métodos que artificialmente promovem o balanceamento do conjunto de treinamento em conjuntos de dados com sobreposição entre as classes.

Como os conjuntos de dados cujas distâncias entre os centróides da classe positiva e negativa são maiores do que unidades não apresentam diferenças significativas em termos da AUC, nesta seção nos focalizamos em conjuntos de dados com distância entre os centróides menor que 3.

Além disso, geramos novos domínios com as mesmas características dos descritos na Seção 621, mas com distância entre os centróides variando em 0,5.

Dessa maneira, nesse experimento analisamos 7 domínios, com as seguintes distâncias entre os centróides das classes, 0, 0,5, 1, 1,5, 2, 2,5 e 3.

Os resultados dos valores teóricos da AUC para essas distâncias são mostrados na tabela.

Como estamos interessados na interação entre conjuntos de dados com um alto grau de desbalanceamento e sobreposição de classes, também restringimos a análise para domínios com até 20% de exemplos na classe positiva, e comparamos os resultados com o conjunto de dados naturalmente balanceado.

Valores teóricos da AUC para os conjuntos de dados artificiais gerados.

Nesse experimento, utilizamos os métodos de balanceamento SMOTE, SMOTE + ENN, NCL, over-sampling aleatório e under-sampling aleatório-Seção 612.

Nossa implementação do SMOTE, over-sampling aleatório e under-sampling aleatório têm parâmetros internos que permitem especificar a proporção final de exemplos entre as classes obtida depois da aplicação desses métodos.

Decidimos adicionar/remover exemplos até que a proporção de exemplos entre as classes seja igualada.

Essa decisão foi motivada por resultados experimentais apresentados em que afirmam que, na média, quando se usa AUC como medida de avaliação, a melhor distribuição de exemplos para induzir árvores de decisão tende a ser a balanceada.

Para uma melhor visualização dos resultados, eles são apresentados graficamente.

São apresentados os resultados dos experimentos para distâncias entre os centróides 0, 0,5, 1 e 1,5.

Note que, para uma melhor visualização dos resultados, a escala dos eixos não é a mesma em todos os gráficos.

Esses gráficos mostram, para cada distância entre os centróides, a AUC média (calculada utilizando-se validação cruzada com 10 partições) versus a proporção de exemplos positivos nos conjuntos de dados de treinamento.

Como esperado, os valores da AUC para essa distância oscilam (devido a variações aleatórias) em torno do desempenho aleatório (AUC = 50%).

Nos experimentos, a maior influência do desbalanceamento entre as classes ocorre quando a distância entre os centros é de 05.

Nesse caso, o valor teórico da AUC é de 7854%, mas com 15% dos exemplos positivos no conjunto de treinamento a AUC está abaixo dos 65%.

Proporção versus AUC para distância Proporção versus AUC para distância Proporção versus AUC para distância Proporção versus AUC para distância Resultados experimentais para as distâncias entre os centróides Na maioria dos casos, os métodos de balanceamento foram capazes de melhorar o desempenho dos algoritmos de aprendizado, medidos em termos da AUC.

Como pode ser observado, under-sampling aleatório e NCL apresentam uma pequena melhora sobre o conjunto de dados original.

Entretanto, essa melhora é menor do que a obtida com os métodos de over-sampling.

Os métodos que adicionam exemplos à classe positiva geralmente produziram os melhores resultados, com os métodos baseados no SMOTE obtendo um desempenho quase que constante para todas as distribuições de exemplos.

O método SMOTE + ENN apresentou melhores resultados que os outros métodos na maioria das distribuições de exemplos.

Esse fato pode ser explicado pela aplicação do método de limpeza de dados, que tendem a ser mais eficientes em regiões mais sobrepostas.

O método de limpeza ENN é menos efetivo conforme a distância aumenta, uma vez que existem menores regiões sobrepostas a serem limpas quando a distância entre os grupos de exemplos de cada classe aumentam.

Desse maneira, quanto mais distantes os centróides das classes, mais os métodos SMOTE e SMOTE+ENN tendem a apresentar resultados similares.

Para a distância 1,5, a maioria dos métodos apresentou bons resultados, com os valores da AUC superiores a 90%.

O método over-sampling aleatório teve uma AUC em torno de 97%.

Entretanto, os métodos baseados no SMOTE apresentaram resultados quase que constantes para todos as distribuições de exemplos, mesmo quando os conjuntos de exemplos eram extremamente desbalanceados.

Proporção versus AUC para distância Proporção versus AUC para distância Resultados experimentais para as distâncias entre os centróides.

São apresentados os resultados para os conjuntos de dados cuja distância entre os centróides está entre 2, 2,5 e 3.

Para essas distâncias, os métodos que incrementam o número de exemplos da classe positiva também obtiveram os melhores resultados, especialmente para os conjuntos de dados muito desbalanceados.

Os resultados do SMOTE e SMOTE+ENN são ligeiramente melhores que over-sampling aleatório.

Entretanto, a limpeza de dados feita pelo ENN é pouco efetiva e os resultados de SMOTE e SMOTE+ENN são muito semelhantes.

Observe que os métodos baseados no SMOTE obtiveram uma AUC quase que constante e com valores próximos a 100% para todas as distribuições de exemplos entre as classes.

É interessante notar o baixo desempenho do método over-sampling aleatório para conjuntos de dados altamente desbalanceados.

Como o oversampling aleatório replica identicamente os exemplos da classe positiva, esse fato pode ser devido a um superajustamento do algoritmo a esses exemplos replicados.

Para concluir as análises desta seção, é importante notar que estamos geralmente interessados em métodos que produzem os melhores resultados em conjuntos de dados muito desbalanceados.

Para analisar esse problema em maiores detalhes,são mostrados os resultados obtidos variando-se a distância entre o centróide de cada classe para as distribuições de exemplos entre as classes mais desbalanceadas, 1%, 2,5% e 5% dos exemplos positivos.

Esses gráficos mostram claramente que os métodos que aumentam o conjunto de exemplos positivos, e os métodos baseados no SMOTE em particular, apresentam os resultados mais significativos.

Neste capítulo foi apresentada uma introdução ao problema de aprendizado com classes desbalanceadas.

Esse problema ocorre quando o número de exemplos disponíveis para algumas das classes é muito pequeno.

Com base na hipótese de que a sobreposição de exemplos entre as classes é um fator complicante ao aprendizado com classes desbalanceadas três novos métodos de balanceamento artificial de conjuntos de dados foram propostos, CNN + Tomek, SMOTE + Tomek e SMOTE + ENN.

Também realizamos uma série de experimentos para confirmar a nossa hipótese que o problema de classes desbalanceadas se agrava na presença de uma grande sobreposição de exemplos entre as classes.

Nessa série de experimentos utilizamos conjuntos de dados gerados artificialmente para verificar a nossa hipótese.

Também verificamos que, nessas condições, métodos de over-sampling têm melhores resultados pois lidam mais diretamente com o problema.

No próximo capítulo, o problema de classes desbalanceadas é investigado em mai-ores detalhes com conjuntos de dados reais provenientes da UCI, além da investigação de outros problemas relacionados à proporção de exemplos entre as classes.

Variação do centro versus AUC para a Variação do centro versus AUC para a proporção de 1% de exemplos positivos proporção de 2,5% de exemplos positivos Resultados experimentais para as proporções 1%, 25% e 5%.

NESTE capítulo são investigados outros problemas relacionados ao aprendizado com diferentes proporções de exemplos entre as classes.

Na Seção 71 são apresentados experimentos em conjuntos de dados naturais provenientes do repositório de dados da UCI para testar a eficiência de métodos de balancemento artificial de conjuntos de dados desbalanceados, três deles propostos nesse trabalho.

Na Seção 7são brevemente apresentados trabalhos relacionados ao problema de classes desbalanceadas e pequenos disjuntos, e no processo de rotulação de exemplos em aprendizado semi-supervisionado multi-visão utilizando Co-training.

Finalmente, na Seção 7são apresentadas as considerações finais deste capítulo.

Além dos experimentos com conjuntos de dados artificiais, descritos no capítulo anterior, também realizamos uma série de experimentos com conjuntos de dados naturais provenientes do repositório da UCI.

Esses experimentos estão reportados a seguir.

Aprendizado e a proporção de exemplos entre as classes Nesta Seção são descritos os experimentos reportados em, com o intuito de comparar vários métodos de balanceamento de conjuntos de dados naturais e averiguar a eficácia desses métodos em problemas reais com desbalanceamento entre as classes.

Para realizar essa comparação, escolhemos treze conjuntos de dados com diferentes graus de desbalanceamento do repositório de dados da UCI.

Na ão sumarizadas as características dos conjuntos de dados utilizados no estudo.

Os conjuntos de dados estão ordenados em ordem crescente de desbalanceamento.

Como os conjuntos Letter e Splice têm um número de exemplos similar nas classes minoritárias, criamos dois conjuntos de dados para cada um, Letter-a e Letter-vogais, nos quais as classes minoritárias são "a" e "todas as vogais", respectivamente, e Splice-ie e Splice-ei, nos quais as classes minoritárias são "ie" e "ei", respectivamente.

Descrição dos conjuntos de dados utilizados em experimentos Novamente os experimentos foram executados com o algoritmo C45.

Os experimentos foram executados utilizando-se validação cruzada com 10 partições.

Os resultados são mostrados na tabela.

Nessa tabela, para cada conjunto de dados, é mostrada a AUC da aplicação do C45 no conjunto de dados original, bem como dos diversos métodos para o balanceamento dos conjuntos de dados, na ordem, under-sampling aleatório, CNN, CNN + Tomek, Tomek, Tomek + CNN, NCL, over-sampling aleatório, SMOTE, SMOTE + ENN e SMOTE + Tomek.

Além disso, para cada conjunto de dados, são apresentados os resultados da árvore construída utilizando os parâmetros padrão do C45 poda com 25% de confiança e sem poda.

Para facilitar a análise dos resultados apresentados na tabela, derivamos vários gráficos baseados nesses resultados.

Nessa figura estão representados o valor médio da AUC versus a proporção de exemplos negativos/positivos para os conjuntos de dados originais.

Nessa figura fica evidente que nem sempre o desbalanceamento nos conjuntos de dados leva a uma degradação de desempenho, uma vez que conjuntos extremamente desbalanceados, tais como o Letter-a e Nursery, obtiveram AUC muito próximas de 100%.

Proporção de exemplos positivos/negativos versus AUC.

Esses resultados obtidos nos experimentos com os conjuntos de dados da UCI são compatíveis com os experimentos em conjuntos de dados artificiais, reportados na Seção 622.

Em outras palavras, esses resultados corroboram com a hipótese de que o desbalanceamento entra as classes não é sempre um problema para algoritmos de aprendizado.

Quanto ao tamanho do conjunto de treinamento na presença de conjuntos de dados desbalanceados e a degradação de desempenho (reportado em Japkowicz como um fator que potencializa o problema do desbalanceamento entre as classes), nossos experimentos mostram que o problema pode estar relacionado com a baixa presença de exemplos da classe minoritária no conjunto de treinamento.

Conjuntos de dados pequenos aliados a um desbalanceamento entre as classes implicam em um número reduzido de exemplos na classe minoritária, e esse número reduzido de exemplos pode ser insuficiente para se aprender o conceito relacionado àquela classe.

Para conjuntos maiores, o efeito desse fator complicante tende a ser menor, uma vez que mesmo que o conjunto de dados seja muito desbalanceado, a classe minoritária pode estar melhor representada.

Essa tendência é confirmada no gráfico apresentado, que mostra como a AUC é afetada pelo número (absoluto) de exemplos positivos no conjunto de treinamento.

Número absoluto de exemplos positivos versus AUC.

Também analisamos o relacionamento da poda da árvore de decisão e o desbalanceamento entre as classes.

Alguns trabalhos apontam que a poda pode ser útil em alguns casos.

No entanto, outros trabalhos concluem que quando se quer estimativas de probabilidade mais confiáveis, ou quando os custos de classificação ou a distribuição de exemplos entre as classes é desconhecida, a poda deve ser evitada.

Uma das razões para se evitar a poda é que vários dos métodos de poda, incluindo o usado pelo C45, têm como finalidade minimizar o erro.

Esse fato pode prejudicar as classes minoritárias, uma vez que reduzindo o erro da classe majoritária (cortando ramos que predizem a classe minoritária, por exemplo) tem-se um maior impacto na taxa de erro global.

Além do mais, mesmo que, via de regra, os sistemas que induzem árvore de decisão realizem poda, a questão de se podar ou não uma árvore na qual o conjunto de treinamento foi modificado para se tentar balancear artificialmente o conjunto de dados parece ser um problema em aberto.

Um argumento contra a poda, nesses casos, é que se ela for realizada nessas condições, o sistema de aprendizado poderia podar com uma falsa suposição, que a distribuição de exemplos no conjunto de treinamento é a mesma na qual ele será aplicado.

É mostrada uma comparação do efeito da poda nas árvores de decisão induzidas a partir dos conjuntos de dados originais e artificialmente balanceados.

A linha diagonal x = y representa AUC idênticas para a árvore podada e não podada.

Pontos acima dessa linha representam o fato que árvores não podadas obtiveram resultados melhores e pontos abaixo dessa linha indicam o oposto.

Podemos concluir que a poda raramente melhora o desempenho medido em termos da AU da árvore induzida, tanto para conjuntos de dados com distribuições originais quanto para conjuntos de dados artificialmente balanceados.

AUC das árvores podadas versus árvores sem poda para os conjuntos de dados originais e artificialmente balanceados.

Para facilitar a análise dos métodos de balanceamento, as células que contêm os valores de AUC mais altos para cada conjunto de dados e para ambas as árvores podadas e não podadas na tabela, estão coloridas de cinza claro.

Note que a maioria dos melhores resultados se concentra nos métodos que aumentam o conjunto de dados, com alguns poucos para a distribuição original de exemplos.

Para uma melhor visualização dos resula uma ordenação dos métodos com relação à AUC para árvores podadas e não podadas, respectivamente.

As células que contêm os resultados para os métodos de over-sampling estão destacadas com uma cor cinza claro.

As células que contêm os resultados para os conjuntos de dados originais estão destacadas com cinza escuro.

Note que, em geral, os métodos de under-sampling aparecem depois dos métodos de over-sampling.

Para realizar inferências a respeito dos métodos de balanceamento, aplicamos o teste de múltiplas comparações com o melhor de Hsu -Multiple Comparison with the Best MC-para testar, para cada conjunto de dados, se existem diferenças significativas entre a AUC máxima e as demais.

Dessa maneira, testamos para cada conjunto de dados a seguinte hipótese, o teste foi realizado com um grau de confiança de 95%.

Os resultados da aplicação do teste estão sumarizados nas Tabelas 7e 74.

Os métodos nos quais foi possível rejeitar H, métodos que obtiveram um AUC significativamente menor que o melhor método, com um nível de confiança de 95%, estão marcados com o símbolo r.

Em contrapartida, os métodos de over-sampling em geral, e o over-sam-pling aleatório em particular, estão bem ordenados entre os outros métodos.

Esses resultados estão em discordância com alguns outros trabalhos publicados na literatura.

Drummond & Holte, por exemplo, reportam que quando é usado C45 com os seus parâmetros padrão, over-sampling é aparentemente ineficiente, muitas vezes produzindo poucas alterações no desempenho em resposta a mudanças nos custos de classificação ou distribuição de exemplos entre as classes.

Além disso, eles notam que após a aplicação de over-sampling, as árvores tendem a ser menos podadas do que quando se aplica under-sampling, e que a generalização é menor (tamanho da árvore é maior) quando se aplica over-sampling.

Nossos experimentos mostram que, na maioria dos casos, over-sampling aleatório aparentemente não está se super-ajustando aos dados, mesmo em árvores não podadas, como pode ser notado levando-se em consideração os altos valores da AUC obtidos por esse método.

Além disso, os métodos de under-sampling não apresentaram bons desempenhos, mesmo quando se utiliza heurísticas para remover casos da classe majoritária.

Outros resultados contraditórios incluem Domingos, que reporta que em problemas binários, o algoritmo C45 Rules produz modelos com menores custos de classificação utilizando-se under-sampling do que aqueles obtidos utilizando-se over-sampling.

Ling & Li comparam oversampling e under-sampling aleatório para uma versão do C45 com aplicação de boosting e reportam que under-sampling leva a melhores índices lift, mas com over-sampling extremo, se a classe minoritária é muito incrementada, tendo um comportamento similar.

Em contrapartida, Japkowicz & Stephen comparam vários métodos diferentes de over-sampling e under-sampling em uma série de conjuntos de dados artificiais, e concluem que over-sampling é mais efetivo que under-sampling na redução do erro.

Versão modificada do C45 que extrai regras a partir da árvore originalmente induzida.

Lift é uma media que indica o quanto uma predição é mais correta do que um modelo trivial que sempre classifica aquela classe.

Ela é definida como a taxa de acerto dividida pela porcentagem de exemplos da classe positiva.

Em nossa opinião, os bons resultados de over-sampling não são completamente inesperados.

Como visto anteriormente, existem evidências que o baixo desempenho está diretamente associado a uma baixa representatividade dos exemplos das classes minoritárias, em conjunção com outros fatores complicantes, como o grau de sobreposição entre as classes.

Os métodos de over-sampling são aqueles que atacam o problema da falta de exemplos da classe minoritária mais diretamente.

Como os resultados dos métodos de over-sampling apresentaram os melhores resultados, assim como as árvores não podadas, conduzimos uma análise para verificar o tamanho das árvores geradas, medido considerando o número de ramos e altura da árvore.

Nas Tabelas 75 e 76 são mostrados, respectivamente, o número médio de ramos e a altura média da árvore para os métodos de over-sampling e as árvores originais não podadas.

Os melhores resultados (menos ramos e menor altura da árvore) são mostrados em negrito, e as células que contêm os melhores resultados, não se levando em consideração o conjunto de dados original, são destacadas em cinza claro.

Número de regras (ramos) para o conjunto de dados originais e após a aplicação de over-sampling para as árvores podadas.

Valores em negrito indicam menor número de regras.

Células destacadas em cinza claro indicam menor número de regras sem levar em consideração o conjunto original de exemplos.

Nessa figura pode-se observar que os métodos de over-sampling levam geralmente a árvores maiores, se comparados com as árvores induzidas a partir do conjunto de dados original.

Esse resultado é esperado, uma vez que a aplicação desses métodos leva a um incremento do conjunto de treinamento, o que geralmente leva a árvores de decisão maiores.

Comparando o número médio de ramos obtidos nas quais foram Número de regras (ramos) para o conjunto de dados originais e após a aplicação de over-sampling para as árvores não podadas.

Valores em negrito indicam menor número de regras.

Células destacadas em cinza claro indicam menor número de regras sem levar em consideração o conjunto original de exemplos.

Aplicados os métodos de over-sampling, SMOTE + ENN e over-sampling aleatório são os métodos que levaram a um menor aumento no tamanho da árvore.

O fato de over-sampling aleatório estar entre os métodos de oversampling que produziram as menores árvores é, no entanto, surpreendente, principalmente com relação aos métodos em que SMOTE é associado com ENN e Tomek.

Essa associação foi proposta com o intuito de eliminar ruídos e exemplos junto à borda e, conseqüentemente, simplificar a árvore de decisão.

Número médio de condições por regra para os conjuntos originais e balanceados e árvores podadas.

Nesse gráfico é possível interpretar mais facilmente os resultados com respeito à altura da árvore.

O método SMOTE + ENN teve resultados muito bons, na maioria das vezes apresentado a árvore com menor altura.

Esse método foi capaz inclusive de obter árvores com menor altura do que aquelas obtidas a partir do conjunto original de exemplos em 6 conjuntos de dados.

Número médio de condições por regra para os conjuntos originais e balanceados e árvores não podadas.

Em uma outra série de experimentos desenvolvemos um estudo experimental para avaliar o comportamento que várias proporções diferentes de exemplos entre as classes têm sobre algoritmos de aprendizado.

Utilizamos os dois métodos de amostragem aleatória, over-sampling e under-sampling.

Nesse experimento, utilizamos 15 conjuntos de dados do repositório da UCI.

Nesses conjuntos de dados, aplicamos os métodos de over-sampling e undersampling aleatório até atingirmos treze diferentes distribuições de exemplos entre as classes pré-fixadas.

Na ão apresentadas as principais características dos conjuntos de dados utilizados nesse experimento.

Similarmente aos outros conjuntos utilizados neste trabalho, para conjuntos de dados com mais de duas classes, a classe com menos exemplos foi designada como positiva e o restante foi agrupado na classe negativa.

Nesse experimento removemos ou duplicamos exemplos do conjunto de treinamento aleatoriamente até atingirmos as seguintes distribuições de exemplos entre as classes, 5%, 75%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 925% e 95%.

Proporções maiores que 50% significam Descrição dos conjuntos de dados utilizados para a avaliação da variação da proporção de exemplos entre as classes n é o número de exemplos, n é o número de atributos.

Valores entre pararêntesis indicam o número de atribudos discretos e contínuos, respectivamente.

Classe maj é porcentagem de exemplos na classe majoritária que os métodos de over-sampling e under-sampling tornaram a classe positiva minoritária mais freqüente do que a classe negativa.

Além disso, para atingirmos distribuições mais desbalanceadas, duplicamos exemplos da classe negativa majoritári ou removemos exemplos da classe negativa, dependendo do método que estava sendo utilizado.

Neste experimento também foi utilizado o C45 com parâmetros padrão.

Para obter estimativas de probabilidade mais confiáveis para cada folha, utilizamos o método de correção de probabilidades m, apresentada na Seção 36.

O parâmetro m foi ajustado de tal maneira que b × m = 10, como sugerido por Elkan, na qual b é a proporção de exemplos a priori no conjunto de treinamento da classe positiva.

Na ão apresentados o valor médio da AUC para as árvores de decisão induzidas pelo C45 nos conjuntos de dados depois da aplicação do over-sampling e under-sampling aleatório.

A primeira coluna da tabela contêm o número do conjunto de dados.

A coluna seguinte apresenta a proporção natural de exemplos positivos e negativos, seguida pelo valor médio da AUC para essa distribuição.

As próximas treze colunas apresentam os valores médios da AUC para as proporções de exemplos pré-fixadas.

Cada uma das linhas foi dividida em duas, sendo que cada primeira linha da divisão contêm os resultados da aplicação de over-sampling e a outra de under-sampling.

Todos os valores dessa tabela foram obtidos utilizando-se validação cruzada com 10 partições e os valores entre parêntesis referem-se aos respectivos desvios-padrão.

Para a realização de testes estatísticos foi utilizado o teste bicaudal de Dunnet, que, como já mencionado, é indicado para múltiplas comparações com um controle.

Para a realização desse teste, as árvores induzidas com a distribuição original de exemplos foram utilizadas como controle.

Dessa maneira, para cada conjunto de dados, testamos a seguinte hipótese, O teste de hipótese foi realizado com um nível de confiança de 95%.

Na tabela, para as distribuições nas quais foi possível rejeitar H, para distribuições em que há diferenças significativas entre os valores médios da AUC entre a árvore induzida com a distribuição original e as árvores induzidas com as distribuições artificiais, as células correspondentes estão destacadas em diferentes tons de cinza.

As distribuições nas quais a AUC das árvores induzidas com as distribuições modificadas foram estatisticamente piores do que a árvore induzida com a distribuição original estão representadas por uma célula de cor cinza claro.

Nas distribuições cujo desempenho das árvores induzidas com as distribuições artificiais são significativamente melhores do que as árvores induzidas com a distribuição original, as células foram coloridas de cinza escuro.

Observando essa tabela fica claro que o over-sampling e o under-sampling aleatório têm um comportamento muito diferente.

Enquanto over-sampling não mostrou nenhuma diferença significativa com relação à distribuição original, under-sampling apresenta vários resultados em que a árvore induzida a partir do conjunto de dados em que esse método é aplicado é estatisticamente pior do que a distribuição original.

A maioria desses resultados estão associados à distribuições muito desbalanceadas, com uma pequena tendência à esquerda, na qual a proporção de exemplos da classe positiva é maior.

Outra importante diferença entre over-sampling e under-sampling aleatório é que os valores médios da AUC são bastante similares para várias distribuições e para vários conjuntos de dados.

Entretanto, os melhores resultados do under-sampling aleatório concentram-se em distribuições mais balanceadas.

Por exemplo, nas Figuras 76e 76são mostradas as AUC obtidas pelos métodos de over-sampling e under-sampling variando-se a proporção de exemplos para os conjuntos de dados Breast e Pima, respectivamente.

Note que, em ambas as figuras, os valores da AUC para o método de over-sampling estão bastante estáveis.

No entanto, para o método de under-sampling, a linha pende para baixo nas pontas.

Comparando-se o desempenho dos métodos de over-sampling e undersampling aleatório apresentados na tabela, fica evidente que o oversampling tem um desempenho geralmente melhor.

Comparando-se os resultados em pares para cada conjunto de dados e para cada proporção de exemplos, over-sampling obteve resultados melhores em 16dos 195 pares de resultados.

Para 6 conjuntos de dados (bupa, ionosphere, breast, tic-tac-toe, vehicle e glass), over-sampling obteve valores de AUC superiores aos de under-sampling para todas as proporções.

Para 11 dos 15 conjuntos de dados (sonar, bupa, ionosphere, breast, tic-tac-toe, german, post-operative, vehicle, ecoli, flag e glass), o valor mais alto da AUC foi obtido por uma das distribuições na qual over-sampling foi aplicado.

As diferenças entre os dois métodos podem ser explicadas se levarmos em consideração que over-sampling duplica exemplos presentes no conjunto de dados, dessa maneira não removendo as informações associadas a esses exemplos no conjunto de dados.

Em contrapartida, under-sampling aleatório remove exemplos para atingir a proporção de exemplos desejada, e as informações associadas aos exemplos removidos não é levada em consideração na indução do modelo porções e exemplos entre as classes.
Nesta seção são apresentados alguns outros trabalhos desenvolvidos relacionados com a proporção de exemplos entre as classes.

Em investigamos o relacionamento entre dois importantes tópicos alvos de recentes pesquisas em AM, aprendizado com classes desbalanceadas, já discutido nas seções anteriores deste capítulo, e pequenos disjuntos.

Em linhas gerais, pequenos disjuntos podem ser entendidos como regras que cobrem corretamente um número reduzido de exemplos.

Como visto anteriormente, o desbalanceamento entre as classes, associado a alguns outros fatores, pode levar a um baixo desempenho de algoritmos de aprendizado.

Em contrapartida, pequenos disjuntos são freqüentemente reportados na literatura como tendo maiores taxas de erro do que grandes disjuntos.

Weiss sugere que existe uma relação entre pequenos disjuntos e o problema de desbalanceamento entre as classes.

Além disso, Japkowicz concorda com essa hipótese e afirma que o problema de desbalanceamento entre as classes é potencializado quando o algoritmo se depara com pequenos disjuntos.

Mesmo que esses trabalhos apontem uma conexão entre esses dois problemas, o relacionamento entre eles ainda não está bem estabelecido.

A seguir reportamos alguns experimentos que realizamos tentando explorar esse relacionamento.

Uma conexão direta entre os temas pode ser traçada se observarmos que, uma vez que as classes minoritárias têm poucos exemplos associados a elas, regras que cobrem essas classes cobrirão um pequeno número de exemplos.

Além disso, essas regras provavelmente terão taxas de erro mais altas, uma vez que em problemas com classes desbalanceadas o número de exemplos da classe minoritária também é pequeno nos conjuntos de teste.

No entanto, em presença de desbalanceamento de classes, como uma das estratégias mais utilizadas é maximizar o erro global, algoritmos de aprendizado podem "ignorar" classes com poucos exemplos por exemplo, utilizando métodos de pod e favorecer a indução de disjuntos maiores.

Em outras palavras, problemas com classes desbalanceadas podem, dependendo de vários fatores, tentar favorecer a indução de pequenos quanto de grandes disjuntos.

Também é importante apontar as diferenças entre os dois problemas, classes com poucos exemplos existem na população em que os exemplos de treinamento são retirados, mas pequenos disjuntos podem ser uma conseqüência de algumas preferências do algoritmo.

Na verdade, como dito anteriormente, classes desbalanceadas podem ou não formar pequenos disjuntos, mas pequenos disjuntos podem aparecer mesmo que a proporção de exemplos entre as classes seja igualmente balanceada.

Curva de concentração de erro Para avaliar o grau em que erros estão concentrados nos pequenos disjuntos, Weiss propõe o uso da curva de concentração de erro.

Para cada disjunto de tamanho n, para n variando de 1 até o tamanho máximo dos disjuntos, constrói-se um gráfico com a porcentagem de erros no conjunto de teste versus a porcentagem de acertos.

A linha y = x corresponde a modelos nos quais os erros estão igualmente distribuídos pelos disjuntos.

A concentração de erro é definida como a porcentagem da área total entre a linha y = x e a curva da concentração de erro, sendo que valores abaixo dessa linha são negativos.

A medida EC varia ent 100% até 100%.

Um valor negativo indica que os erros estão concentrados nos grandes disjuntos, enquanto que valores positivos indicam o contrário.

Experimentos Para avaliar o relacionamento entre as classes desbalanceadas e pequenos disjuntos, realizamos uma série de experimentos com vários conjuntos de dados da UCI.

Assim como nas seções anteriores, na ão apresentadas as principais características dos conjuntos de dados utilizados nesse experimento.

Nessa série de experimentos, também utilizamos o algoritmo C45.

Para cada conjunto de dados, calculamos a AUC e o EC para ambas as árvores podadas e não podadas, utilizando validação cruzada com 10 partições.

Na Descrição dos conjuntos de dados utilizados para averiguar a relação entre pequenos disjuntos e a proporção de exemplos entre as classes.

N é o número de exemplos.

N é o número ex atr de atributos.

Valores entre pararêntesis indicam o número de atribudos discretos e contínuos, respectivamente.

Classe maj.

Porcentagem de exemplos na classe majoritária.

Valores da AUC e da EC para as árvores podadas e não podadas no conjunto original de exemplos.

tabela são apresentados os resultados desse experimento.

Os valores entre parêntesis indicam os respectivos desvios padrão.

Para dois dos conjuntos de dados, Sonar e Glass, o C45 não podou a árvore.

Consideramos ambas as árvores podadas e não podadas pois estamos interessados em analisar se a poda é efetiva para tratar o problema de pequenos disjuntos na presença de desbalanceamento entre as classes.

Poda é geralmente reportado na literatura como um método efetivo para a remoção de pequenos disjuntos indesejados.

No entanto, como discutido nas seções anteriores, a poda não é benéfica na presença de classes desbalanceadas ou quando os custos de classificação são desconhecidos.

Analisando os valores da AUC na tabela notamos que as árvores não podadas sistematicamente apresentam resultados melhores do que as árvores podadas.

Entretanto, também é possível observar que os valores da EC também aumentam para quase todas as árvores não podadas, os erros de clasValores da AUC e da EC para as árvores podadas e não podadas após a aplicação de over-sampling aleatório e SMOTE.

Nesse caso tendem a se concentrar nos pequenos disjuntos.

Esses resultados apontam um compromisso entre podar ou não a árvore, por um lado, podar a árvore leva a disjuntos maiores e a uma menor concentração de erro, por outro lado, não podar a árvore e reter os pequenos disjuntos leva a um ganho de desempenho em termos da AUC.

Em outras palavras, a poda prioriza regras gerais que tendem a predizer a classe majoritária, enquanto que a não poda prioriza regras menores mas que cobrem melhor os exemplos da classe minoritária.

Dando continuidade ao experimento, analisamos o comportamento dos métodos de balanceamento artificial do conjunto de dados e pequenos dis-juntos.

Weiss também investiga esse problema aplicando o método de under-sampling aleatório para balancear artificialmente os conjuntos de treinamento.

Seus resultados mostram que as árvores induzidas a partir de conjuntos balanceados daquela maneira tendem a produzir menores valores da EC, com um pequeno ganho em termos da AUC.

Essa redução no valor da EC pode ser explicada pela redução no número de disjuntos induzidos, o que é uma característica dos métodos de under-sampling.

Entretanto, assim como a poda, essa abordagem pode remover do modelo pequenos disjuntos que sejam interessantes.

Além disso, como discutido nas seções anteriores, os métodos de over-sampling tendem a produzir melhores resultados do que os métodos de under-sampling em termos da AUC.

Por esses motivos, em nossos experimentos, aplicamos métodos de over-sampling para testar o comportamento desses métodos com relação à EC.

Na tabela são mostrados os valores da AUC e da EC para dois métodos de over-sampling propostos na literatura, aleatório e SMOTE.

Os resultados mostrados na tabela são reportados para árvores não podadas.

Esses resultados apresentam as mesmas tendências daqueles apresentados na tabela.

Os valores da AUC são em geral maiores do que aqueles obtidos a partir da árvore podada construída a partir do conjunto de dados original, mas com maiores EC.

Entretanto, apesar da tendência no aumento da EC quando se aplica over-sampling, esses valores são menores do que o EC da árvore não podada induzida a partir do conjunto original de exemplos.

Além disso, em três conjuntos de dados Sonar, Bupa e New-thyroi, SMOTE produziu EC menores do que a árvore podada induzida no conjunto original.

Esses resultados podem ser explicados observando-se que, uma vez que o SMOTE utiliza um método de interpolação, SMOTE pode ajudar na definição das fronteiras de decisão para cada uma das classes.

Entretanto, esse método de interpolação pode introduzir ruído no conjunto de dados, levando a um aumento no número de pequenos disjuntos indesejáveis.

Em outras palavras, mesmo que o SMOTE ajude a superar o problema com o desbalanceamento entre as classes, ele pode aumentar o problema dos pequenos disjuntos.

Nesse sentido, também investigamos como a associação dos métodos de limpeza de dados ao SMOTE, SMOTE + ENN e SMOTE + Tomek, por nós propostos em Batista, se comportam com relação à EC.

Nossa suposição é que os métodos de limpeza de dados poderiam ajudar a remover pequenos disjuntos indesejáveis, além da melhora de desempenho em termos da AUC.

Na tabelasão mostrados os resultados desses métodos nos mesmos conjuntos de dados.

Comparando ambos os métodos, pode ser observado que SMOTE + Tomek produziu um AUC maior em cinco conjuntos de dados e o SMOTE + ENN é melhor em dois conjuntos (Bupa e Glass).

Para os outros conjuntos, o desempenho dos dois métodos é comparável (com uma diferença menor que 1%).

Além disso, pode ser observado que em conjuntos de dados (New-thyroid, Satimage e Glass) SMOTE+Tomek obteve resultados idênticos ao SMOTE.

Nesses casos não foram encontradas ligações Tomek.

Para uma melhor comparação dos resultados, é mostrado um ranking dos valores da AUC e EC obtidos para todos os métodos de over-sampling e árvores não podadas.

Nessa tabela, O indica o conjunto original.

R e S representam respectivamente over-sampling aleatório e SMOTE e S+E e S+T representam SMOTE + ENN SMOTE + Tomek, indica que o método teve o melhor resultado e o segundo melhor para o conjunto de dados correspondente.

Resultados com diferenças menores que 1% aparecem em conjunto.

Note que o método conjugado SMOTE + Tomek teve resultados de AUC entre os melhores para 7 conjuntos de dados (sonar, pima, haberman, new-thyroid, e-coli, satimage e flag).

Além disso, em outros dois conjuntos, o seu desempenho ficou entre os segundo melhores (german e glass).

Esse método Valores da AUC e da EC para as árvores podadas e não podadas após a aplicação de SMOTE + ENN e SMOTE + Tomek.

Ranking da AUC e da EC para as árvores não podadas.

Não ficou nenhuma vez entre as menores EC, mas para 6 conjuntos (sonar, bupa, pima, haberman, newthyroid e glass) ele ficou entre os segundos melhores valores da EC, sendo que em quatro desses conjuntos SMOTE + Tomek teve a maior AUC.

Outro resultado interessante foi o conseguido pelo over-sampling aleatório de exemplos do algoritmo Co-training.
Aprendizado semi-supervisionado surgiu recentemente como uma alternativa para problemas nos quais não se tem um número razoável de exemplos para se realizar aprendizado supervisionado.

Nesse tipo de aprendizado, é fornecido aos algoritmos uma pequena quantidade de exemplos rotulados e vários exemplos não rotulados o objetivo é utilizar os exemplos não rotulados para melhorar os modelos induzidos.

Um dos principais algoritmos de aprendizado semi-supervisionado é o algoritmo Co-training, proposto por Blum & Mitchell.

O método utilizado pelo Co-training consiste da indução de dois modelos, cada um deles induzido utilizando uma visão diferente dos exemplos, os quais cooperam entre si.

Exemplos são rotulados somente se esses modelos tiverem um alto grau de certeza a respeito da classificação desses exemplos.

Esses novos exemplos rotulados são então adicionados ao conjunto original de exemplos rotulados de ambos os algoritmos e o processo é repetido até não ser possível rotular exemplos com um alto grau de certeza.

Um parâmetro muito importante do algoritmo Co-training refere-se à proporção de exemplos de cada classe que são rotulados em cada iteração do algoritmo.

Uma suposição muito comum nos algoritmos de aprendizado é que o conjunto de treinamento possui a mesma proporção de exemplos encontrada no mundo real.

Essa proporção é geralmente estimada a partir do conjunto de exemplos de treinamento.

Entretanto, em aprendizado semi-supervisionado, o conjunto de exemplos rotulados é pequeno.

Dessa maneira, estimar a proporção de exemplos entre as classes usando somente esse pequeno número de exemplos é muito arriscado e, dificilmente, será obtida uma boa aproximação.

Em foram feitos alguns experimentos variando a proporção de exemplos rotulados em cada classe a cada iteração do algoritmo Co-training.

Para essa avaliação foram utilizados três diferentes conjuntos de textos, um subconjunto de artigos de notícias do UseNet, resumos de artigos científicos, títulos e referências coletados da série Lecture Notes in Artificial Intelligence e páginas web e links relacionados a cursos de ciência da computação.

Para o primeiro conjunto de textos foram extraídos um subconjunto de 100 textos dos grupos de notícias sci crypt, sci electronics, sci med, sci space, talk politics guns, talk politics mideast, talk politics misc e talk religion misc.

Os textos dos primeiros grupos de notícias foram agrupados na classe sci (400 50%) e os textos dos outros grupos foram agrupados na classe talk (400 %50).

O conjunto LNAI contêm textos de 396 artigos de Case Based Reasoning (277 70%) e Inductive Logic Programming (119 30%).

As duas visões para esses conjuntos foram obtidas utilizando-se a ferramenta PRETEXT, sendo que a primeira visão consiste em palavra stemizadas simples e a segunda em palavras duplas.

O conjunto de dados COURSE consiste de 1038 páginas web coletadas de vários sítios de departamentos de ciência da computação.

As duas visões que compõem esse conjunto consistem nas palavras que aparecem na página e nas palavras que aparecem nas ligações que apontam para aquela página.

As páginas são classificadas como course (221 20%) e non-course (817 80%).

As principais características desses conjuntos de textos, o erro médio obtido pelo algoritmo Naïve Bayes em cada classe, bem como o erro médio geral calculado utilizando-se validação cruzada com 10 partições, são mostrados na tabela.

Descrição dos conjuntos de textos utilizados no experimento com Co-training.

Todos os experimentos foram conduzidos com o mesmo número de exemplos no conjunto inicial de exemplos rotulados (30 exemplos) igualmente distribuídos entre as classes (15 exemplos de cada classe).

A cada iteração, até 10 exemplos poderiam ser utilizados para incrementar o conjunto de exemplos rotulados.

Utilizamos o limiar de 60% de confiança para rotular um exemplo em ambas as visões.

Para analisar o impacto da proporção em que exemplos são rotulados em cada iteração, exemplos foram rotulados nas seguintes proporções de exemplos em classes, 2/8, 3/7, 5/5, 7/e 8/Na tabela são mostrados os resultados médios obtidos no experimento.

Todos os resultados foram obtidos utilizando-se validação cruzada com 10 partições.

Para cada conjunto de textos, nessa tabela, as quatro primeiras linhas mostram o número de exemplos por classe que foram incorretamente (I) e corretamente rotulados.

L é o tamanho do conjunto final de exemplos rotulados.

U' é o número de exemplos não rotulados pelo algoritmo.

Erro e AUC são, respectivamente, o erro médio e a AUC do modelo final e Errados é o número total de exemplos rotulados incorretamente.

O melhor resultado para cada um desses valores está destacado em negrito.

Resultado da aplicação do Co-training para os conjuntos de dados NEWS, LNAI e COURSE.

O melhor resultado de Erro, AUC e Errados está em negrito.

Os resultados da aplicação do Co-training variando-se a proporção de exemplos entre as classes rotulados a cada iteração mostra um padrão interessante.

Para o conjunto de dados naturalmente balanceado (NEWS), aumentando a proporção de exemplos rotulados na classe talk, rotulando-se exemplos na classe talk nas proporções, 7/e 8/não diminui em muito o desempenho.

No entanto, aumentando-se a proporção de exemplos rotulados para a classe sci, o erro (de 188 na proporção 5/5 para 1900 na proporção 8/2) bem como o número de exemplos incorretamente rotulados Aprendizado e a proporção de exemplos entre as classes sobe drasticamente.

Para os conjuntos que são desbalanceados, o padrão é mais claro, tanto a taxa de erro e o número de exemplos incorretamente rotulados aumentam quando a proporção de exemplos rotulados tende para proporções muito diferentes da natural.

Um outro resultado interessante está relacionado com a AUC.

Para os conjuntos de dados com AUC altas, próximas de 100%-NEWS e LNAI, a degradação no desempenho é menor do que no outro conjunto (COURSE).

Esse fato pode ser explicado pelo fato que uma AUC próxima de 100% é um forte indicativo de uma boa separação entre as classes, sendo dessa maneira mais fácil para o algoritmo construir modelos mais precisos.

Neste capítulo foram apresentados diversos experimentos relacionados à porporção de exemplos entre as classes.

Primeiramente, foram reportados experimentos com conjuntos de dados naturais e uma série de métodos que visam balancear artificialmente os conjuntos de dados.

Nossos experimentos mostram que métodos de over-sampling tendem a ter um melhor desempenho, medido em termos da AUC, do que os métodos de under-sampling.

Também verificamos que o método de over-sampling aleatório, apesar de extremamente simples, é bem competitivo na maioria dos casos com outros métodos de over-sampling mais sofisticados.

Realizamos também uma série de experimentos variando-se artificialmente a proporção de exemplos dos conjuntos de dados, utilizando over-sampling e under-sampling aleatório.

Mais uma vez o método de over-sampling teve melhor desempenho.

O melhor desempenho dos métodos de over-sampling pode ser explicado principalmente devido ao fato que, por descartarem exemplos, os métodos de under-sampling tendem a descartar informações potencialmente contidas nesses exemplos.

Também verificamos experimentalmente que, em geral, a poda da árvore de decisão leva a resultados com uma menor AUC, principalmente em conjuntos de dados desbalanceados.

Também conduzimos uma série de experimentos para explorar o relacionamento entre pequenos disjuntos e classes desbalanceadas.

Em linhas gerais, pode-se concluir que os métodos de over-sampling, que mais diretamente tratam o problema de classes desbalanceadas, levam a um aumento no número e na concentração de erro dos pequenos disjuntos.

Além disso, a poda, que é normalmente recomendada para diminuir a incidência de pequenos disjuntos, leva a uma diminuição da AUC para problemas com classes desbalanceadas.

Um dos métodos por nós proposto, SMOTE + Tomek, teve uma pequena melhora no desempenho conjunto tanto na AUC quanto na concentração de erro.

Com um outro experimento mostramos empiricamente que a proporção de exemplos de cada classe rotulados a cada iteração do algoritmo semisupervisionado Co-training é um parâmetro muito importante desse algoritmo, fato normalmente negligenciado na literatura.

A maioria dos experimentos com Co-training reportados na literatura refere-se a simulações nas quais a classe associada a cada exemplo é conhecida.

Nesses experimentos, a proporção é normalmente ajustada à proporção de exemplos do conjunto de dados.

Entretanto, essa informação é, a princípio, desconhecida.

N ESTE capítulo é descrita uma nova abordagem para a criação de ensembles de rankings.

Este capítulo está organizado da seguinte maneira, na Seção 81 são apresentadas algumas considerações iniciais ao tema.

Na Seção 8é apresentado o problema de ranking tratado neste trabalho.

Na Seção 8são apresentados alguns métodos de votação comumente utilizados.

A nossa abordagem é inspirada em um desses métodos.

Na Seção 8são brevemente apresentados alguns trabalhos correlacionados.

Nossa abordagem é descrita na Seção 85.

Experimentos para a validação da abordagem proposta são descritos na Seção 86.

Finalmente, na Seção 87 são apresentadas algumas considerações finais do capítulo.

Vários métodos foram propostos na literatura para agregar a classificação de vários modelos de classificação em uma única classe.

Esses métodos são geralmente conhecidos como ensembles, e cada modelo que compõe o ensemble é conhecido como modelo base.

Em certas condições, ensembles proporcionam um ganho de desempenho com relação aos modelos base considerando a taxa de acerto de classificação.

Alguns exemplos de métodos de ensemble incluem bagging e boosting, entre outros.

Bagging está baseado na geração de várias versões de um modelo, e na utilização dessas versões para se criar um modelo agregado.

Geralmente utiliza-se um método de votação para combinar as predições.

As versões do modelo são geralmente obtidas por métodos de amostragem com reposição do conjunto de exemplos de treinamento.

Boosting, em contrapartida, é um algoritmo iterativo no qual a construção da combinação de modelos ocorre em estágios.

A cada estágio, um modelo é induzido a partir dos dados.

Esse modelo é então adicionado ao modelo combinado, com um peso proporcional ao quão preciso é o modelo.

Também são atribuídos pesos aos exemplos, de maneira que os exemplos nos quais o modelo corrente erra a classificação recebem um peso maior-são "ampliados" booste-de tal maneira que o próximo modelo a ser induzido tente classificar corretamente esses exemplos.

Mesmo que ensembles sejam largamente utilizados para melhorar modelos de classificação, pouco trabalho tem sido feito em métodos que constróem ensembles de rankings.

Neste capítulo descrevemos um novo método que propomos para combinar vários rankings em um ensemble.

O método é chamado BORDARANK e é baseado no método de votação por preferências múltiplas denominado borda count.

Resultados experimentais, medidos em termos da AUC, mostram que BORDARANK tem um ganho de desempenho com relação aos rankings individuais que compõem o modelo.

Além disso, BORDARANK é competitivo com métodos mais sofisticados que combinam predições contínuas, ao invés de apenas o ranking dos exemplos.

Esse fato é uma das vantagens de BORDARANK, pois ele pode ser aplicado em problemas nos quais somente uma ordenação dos casos esteja disponível.

Neste trabalho, um ranking é definido como, dado um conjunto de casos e uma propriedade de interesse, geralmente relacionada a um atributo classe em problemas de classificação, um ranking é uma completa ordenação desses casos do mais provável ao menos provável de pertencer à classe de interesse.

Em outras palavras, estamos interessados em ordenação binária, na qual gostaríamos de colocar o maior número possível de exemplos da classe de interesse no topo dos elementos ordenados.

O problema de ranking é muito comum em aplicações reais, nas quais é necessário ordenar casos ao invés de apenas classificá-los.

Um exemplo é um sistema de recomendação, no qual o objetivo é obter uma lista ordenada de mercadorias-digamos livros ou filmes-que um consumidor gostaria de comprar, basedo em suas preferências.

Outro exemplo é campanha de marketing direto ao consumidor por meio de catálogo de compras, na qual o vendedor gostaria de ter um lista ordenada de consumidores em potencial.

Essa lista poderia ser utilizada para enviar correspondência a somente os consumidores que aparecem no topo da lista, maximizando o lucro esperado.

Recuperação de informação também utiliza métodos de ranking, na qual o objetivo é ordenar um conjunto de documentos de acordo com algum critério de busca.

O objetivo é colocar o maior número possível de documentos que casam com o critério de busca no topo da lista de documentos.

Ordenação é um meio termo entre classificação e regressão.

Uma maneira direta de criar um ranking é utilizar algum algoritmo de aprendizado que prediga um valor contínuo, que de alguma maneira estime a confiança ou as chances de um certo caso pertencer à classe de interesse.

O valor predito por esse algoritmo para cada um dos exemplos pode ser utilizado para ordenar os casos.

Como o valor contínuo predito por esses algoritmos pode ser escalado para representar probabilidades, esses modelos são freqüentemente chamados de modelos de classificação probabilístico, mesmo que, estritamente falando, eles não predigam nem uma classe nem probabilidades.

Para a ordenação, no entanto, os valores numéricos não são de interesse, uma vez que somente a ordem que eles definem é levada em consideração.

Uma outra maneira de resolver o problema de ordenação é utilizar pares de exemplos de treinamento.

No entanto, essa abordagem aumenta a complexidade dos dados de O(n) para O(n), na qual n é o número de exemplos a serem ordenados.

Outra abordagem é utilizar regressão ordinal, cujo objetivo é mapear os casos para um conjunto ordenado de posições numéricas.

Como descrito no Capítulo 4, uma propriedade interessante de rankings construídos dessa maneira é que eles podem ser facilmente transformados em modelos de classificação utilizando-se uma regra de ponto de corte, ou predizendo os x por cento casos do topo como da classe positiva, como 1 no exemplo de correspondência direta ao consumidor, ou selecionandose apropriadamente um limiar de classificação utilizando-se análise ROC.

Além disso, também como descrito no Capítulo 4, a área abaixo da curva ROC, AUC, é numericamente equivalente ao teste de Wilcoxon e pode ser interpretada como a probabilidade que, dados dois casos, um de cada classe, 1 Nesse capítulo, classe positiva designa os casos que têm a propriedade de interesse.

O restante dos casos pertence à classe negativa selecionados aleatoriamente, o exemplo da classe positiva apareça primeiro no ranking do que o exemplo da classe negativa.

O conceito de votação é bem conhecido em ciências sociais, tais como política e economia.

Métodos de votação incluem tanto escolha simples quanto escolha múltipla.

Um dos métodos mais utilizados é a votação simples com pluralidade, no qual cada eleitor pode votar em um dos candidatos e o vencedor é aquele com mais votos.

Variações incluem votação por maioria, na qual a eleição somente tem um vencedor no caso de um dos candidatos receber mais da metade dos votos e votação em turnos, na qual os dois candidatos com mais votos no primeiro turno avançam para o segundo.

Um método de votação um pouco diferente é a votação ponderada, na qual eleitores expressam o seu grau de preferência por um candidato atribuindo um peso ao seu voto.

Quanto mais alto o grau de confiança, mais o candidato é preferido pelo eleitor.

Métodos que combinam modelos de classificação consideram cada um dos modelos como um eleitor e as possíveis classes como candidatos.

Na votação por escolha simples, ensembles de modelos de classificação usam amplamente votação por pluralidade ou votação ponderada.

O vencedor da eleição é a classificação final do caso dada pelo ensemble.

Na votação por pluralidade, cada modelo-base simplesmente vota em uma classe e na votação ponderada cada voto é ponderado com um peso que geralmente representa probabilidades ou distâncias.

Para votações de escolha múltipla, ao invés de cada eleitor selecionar apenas um candidato, eles são permitidos a expressar suas preferências para todos os candidatos.

Isso pode ser feito de duas maneiras, ou expressando o grau de confiança (com um peso) para cada candidato ou simplesmente ordenando os candidatos, do mais ao menos preferido.

Esses dois métodos, múltiplas preferências por pesos ou ordenação, necessitam de diferentes maneiras de selecionar um vencedor.

Para o caso em que se utilizam pesos, calcula-se geralmente a soma ou produto dos pesos, e o vencedor é o candidato com o maior valor dessa soma ou produto.

Quando se ordena os candidatos, um dos métodos mais utilizados para se eleger o vencedor é o borda count, no qual a posição média de todos os candidatos é calculada.

Os candidatos são então reordenados pela suas posições médias e o candidato mais bem posicionado ganha a eleição.

Na combinação de modelos de classificação, para um dado exemplo, cada modelo ou ordena as possíveis classes (no caso de votação por ordenação) ou expressa o seu grau de confiança para todas as classes (em votação por múltiplas preferências por pesos).

A posição média ou os pesos combinados, respectivamente, são então utilizados para classificar o exemplo.

Métodos de múltiplas preferências por ordenação, como o borda count, utilizam mais informação que métodos de preferência simples.

Entretanto, como eles consideram a confiança entre os candidatos em proporções fixas (as posições), eles não levam em consideração o grau de preferência entre os candidatos como os métodos de combinação de múltiplas preferências com pesos fazem.

Dessa maneira, quando comparados com os métodos de múltiplas preferências com pesos, isso significa que existe uma perda de informação.

Entretanto, métodos de ordenação são preferidos nos casos em que diferentes escalas são utilizadas para graduar candidatos, uma vez que eles evitam os problemas de incompatibilidade e escala entre os eleitores.

Cohen propõem um método para a combinação de rankings que minimiza diretamente o número de ordenações incorretas.

O problema é transformado em um problema combinatorial de otimização de combinação de grafos de preferências, construídos a partir dos rankings.

RankBoost é uma adaptação do algoritmo clássico de boosting AdaBoost para problemas de ranking.

Ele também usa grafos de preferências, mas tenta evitar a intratabilidade da otimização combinatorial do trabalho de Cohen.

Recentemente Rudin mostraram que para o problema de ranking de ordenação binária bi-partida, como a discutida nesta trabalho, AdaBoost e RankBoost são muito semelhantes.

Em outras palavras, eles mostraram que os desempenhos de AdaBoost e RankBoost tendem a ser parecidos neste tipo de problema.

Além disso, eles mostraram que se um modelo de classificação que sempre prediz uma das classes for adicionado aos modelos que formam a base do AdaBoost, AdaBoost e RankBoost têm um comportamento idêntico.

Huang & Ling propuseram um método para reconstruir ensembles selecionando um subconjunto dos modelos que compõem o ensemble.

Cada modelo é ponderado utilizando-se uma variação da AUC como peso, e aqueles com baixos valores de AUC são removidos do ensemble.

Vários trabalhos exploram diferentes métodos de votação para combinar modelos de classificação na construção de ensembles.

Van Erp comparam 10 métodos de votação em conjuntos de dados, entre eles votação por pluralidade, maioria, soma e produto de pesos e borda count para a escolha da melhor classificação de um exemplo em um ensemble do tipo bagging.

Soma e produto de pesos tiveram bons resultados para ensembles pequenos e borda count foi melhor em ensembles de tamanho maior.

Outros trabalhos conduziram um experimento mais extenso em 39 conjuntos de dados da UCI e com 5 métodos de votação diferentes, incluindo votação por pluralidade e borda count.

Suas conclusões afirmam que diferentes métodos de votação podem melhorar o desempenho de ensembles, mas seus resultados não apontaram um único método de votação como melhor.

Apesar disso, borda count teve bons resultados em domínios com ruído.

Mesmo que utilizados previamente em problemas de combinação de modelos de classificação, não é de nosso conhecimento a utilização de métodos de votação para a combinação de rankings.

Na próxima seção apresentamos o algoritmo BORDARANK, um método para a construção de ensembles a partir de rankings inspirado no método de votação borda count.

Para adaptar o borda count ao problema de rankings, ao invés de considerarmos cada uma das classes como candidatos, como em, nosso método considera cada caso como um candidato.

Após, aplicamos um método semelhante ao borda count para combinar os rankings individuais.

Sempre que o borda count é utilizado para construir ensembles de modelos de classificação, cada uma das classes é um candidato.

Eleitores são os modelos base e devem prover uma ordenação de preferências das classes para cada um dos casos e borda count é utilizado para escolher a classificação final para um caso em particular.

Nossa abordagem, denominada BORDARANK, utiliza um método similar ao borda count para combinar vários rankings em um ensemble de rankings.

Ao invés de considerar cada classe como candidato, nossa abordagem leva em consideração todos os casos a serem ordenados como possíveis candidatos.

Cada eleitor é um ranking base que deve fornecer uma ordenação a respeito das chances de cada caso pertencer à classe de interesse, para todos os casos.

Em caso de empates, uma posição média é atribuída para todos os casos empatados.

Após isso, BORDARANK aplica uma abordagem similar ao borda count para combinar os rankings de todos os eleitores.

BORDARANK trabalha da seguinte maneira, ao invés de um conjunto de modelos base de classificação, temos um conjunto base de rankings.

Assuma que queiramos construir um ensemble de m ranking base tendo n casos ordenados em cada ranking base.

O resultado pode ser representado em uma tabela de n × m posições.

Nessa tabela, a j-ésima coluna dá as posições do j-ésimo ranking base.

Dessa maneira, a célula (i,j) dá a posição do caso i ordenado pelo ranking j.

Para cada caso i, é calculada a média das suas posições individuais i.

Finalmente, os casos são reordenados de acordo com as suas posições médias.

A aplicação de nossa abordagem é explicada no seguinte exemplo, suponha que queiramos combinar rankings com 10 casos a serem combinados, como mostrado na tabela.

Nessa tabela, a primeira coluna (# caso) é o número do caso (que não reflete a ordenação verdadeira dos exemplos).

A segunda coluna mostra a classe verdadeira de cada exemplo se o caso pertence à classe positiva, ele é rotulado como + caso contrário.

As colunas três a seis mostram, respectivamente, as posições dadas por quatro diferentes rankings.

A coluna sete mostra a soma das posições e a coluna oito mostra a média das posições.

Finalmente, a última coluna mostra a nova ordenação dos casos.

Calculando o ranking médio Como pode ser visto na tabela, cada ranking base deixa ao menos um exemplo negativo nas 5 primeiras posições do ranking.

Por exemplo, o caso c, que é negativo, está posicionado na 5, 5 e posições, respectivamente, pelos rankings base 1, e 3.

Já o caso c aparece na 5 posição no ranking base 4.

Além disso, cada um dos rankings base posiciona um exemplo positivo nas 5 últimas posições do ranking.

Os rankings base 1, e têm uma AUC de 96%, e o ranking base tem uma AUC de 92%.

Além disso, modelos de classificação que predigam os 5 primeiros exemplos como positivos têm uma taxa de acerto de 80%.

Entretanto, quando se computa a posição média, as ordenações erradas são corrigidas e o ranking combinado pelo BORDARANK tem uma AUC de 100%, também como o modelo de classificação que prediz os 5 primeiros exemplos como positivos tem uma taxa de acerto de 100%.

A suposição chave do método proposto é que, dado um número suficiente de rankings independentes, os possíveis posicionamentos errados dados pelos rankings individuais são corrigidos quando calculamos a posição média para cada caso.

Em outras palavras, considerando a posição de um caso em particular como uma variável aleatória, quando mais rankings são adicionados ao ensemble mais a variância do ranking médio tende a zero, e a média das posições tende aos valores esperados associados de suas variáveis aleatórias.

Nesta seção são mostrados resultados experimentais utilizando 18 conjuntos de dados da UCI.

Na ão apresen-tadas as principais características dos conjuntos de dados utilizados neste estudo.

Descrição dos conjuntos de dados utilizados no experimento com BORDARANK.

N é o número de exemplos.

N é o número de atributos.

Valores entre pararêntesis indicam o número de atribudos discretos e contínuos, respectivamente.

Classe maj.

Porcentagem de exemplos na classe majoritária.

Para validar nossa proposta, dividimos nossos experimentos em três estágios.

Primeiramente, avaliamos se BORDARANK poderia melhorar o desempenho com relação a cada um dos rankings base.

Para tanto, utilizamos vários modelos de classificação que predizem um valor contínuo (ou adaptamos algoritmos quando eles não predizem um valor continuo) e utilizamos esses valores para ordenar os casos.

Após essa etapa, aplicamos BORDARANK para combinar esses rankings e realizamos testes estatísticos.

No segundo estágio de nossos experimentos, comparamos BORDARANK com vários métodos de combinar os valores contínuos preditos pelos algoritmos base para testar se BORDARANK é competitivo com essas abordagens.

Finalmente, calculamos a precisão e a sensitividade dos modelos de classificação derivados utilizando os 5%, 10%, 20% e 30% dos casos que aparecem no topo dos rankings.

Para o primeiro estágio dos experimentos, para termos uma maior variabilidade nos resultados, selecionamos algoritmos com diferentes preferências de indução.

Esses algoritmos são descritos a seguir, C45 Como já mencionando, o sistema C45 é um membro da família de algoritmos dividir-para-conquistar.

Modificamos a árvore induzida para estimar probabilidades em cada folha utilizando a correção de Laplace, e essas probabilidades foram utilizadas para ordenar os casos.

Utilizamos tanto a árvore não podada quanto a podada, treinada com parâmetros padrão.

CNAssim como com o C45, utilizamos a correção de Laplace para estimar probabilidades e ordenar casos, mas nesse caso as probabilidades foram calculadas para todas as regras que cobrem um dado exemplo.

Redes neurais to tipo MLP e RBF Utilizamos uma rede neural do tipo perceptron multi-camada (MLP) e também do tipo função de base radial (RBF), treinadas utilizado o algoritmo de backpropagation, com camadas de entradas e oculta com o número de nós equivalente ao número de atributos no conjunto de dados.

O coeficiente de momento foi ajustado para 0,2, a taxa de aprendizado para 0,e o número máximo de épocas foi ajustado para 500.

O valor contínuo predito pelas redes neurais foi utilizado para ordenar os casos.

SVM Utilizamos a implementação SV M light das máquinas de vetores de suporte.

Utilizamos tanto a versão para classificação-SVM-e a adaptada para ordenar casos utilizando pares de exemplos.

Em ambos os casos, as SVMs foram treinadas utilizando kernel linear e parâmetros padrão.

A distância até às margens dos vetores de suporte foi utilizada para ordenar os casos.

Naïve Bayes Também utilizamos o Naïve Bayes-NB.

As probabilidades a posteriori fornecidas pelo NB foram utilizadas para ordenar os casos.

Executamos os experimentos 10 vezes e a cada execução foi utilizada a validação cruzada com 10 partições (10×cv).

Para cada partição da validação cruzada, 90% dos exemplos foram utilizados para treinamento e o restante foi utilizado para a ordenação.

O experimento é pareado, para todos os algoritmos foram fornecidos os mesmos conjunto de treina mento e teste.

Na ão apresentados, para cada conjunto de dados e para cada ranking base, assim como para o BORDARANK, o valor médio da AUC de todas as execuções.

Desvios padrão são mostrados entre parêntesis.

Para uma melhor visualização, a célula com o valor mais alto da AUC obtido para cada um dos conjuntos de dados está destacada por uma cor cinza-escuro, e a segunda melhor AUC com a cor cinza-claro.

Para testar se existem diferenças entre os algoritmos, executamos o teste de Friedman, que é uma versão equivalente não paramétrica à ANOVA, com a hipótese nula que o desempenho de todos os algoritmos, medidos em termos da AUC são comparáveis.

Dessa maneira, testamos a seguinte hipótese, Segundo a estatística de Friedman, a hipótese nula H pode ser descartada com 95% de confiança.

Como a hipótese nula foi rejeitada, podemos prosseguir com um teste para detectar se as diferenças entre os algoritmos são significativas.

Executamos o teste de múltiplas comparações com um controle de Bonferroni-Dunn, utilizando BORDARANK como controle.

Em outras palavras, testamos a seguinte hipótese Com 95% de confiança, podemos rejeitar a hipótese nula de que BORDA-RANK tem um desempenho comparável aos seguintes algoritmos, C45, C45(NP), NB, CN2, SVMe RBF.

Isso é equivalente a dizer que BOR-DARANK é significativamente melhor que esses rankings base com 95% de confiança.

Mesmo que o teste não tenha detectado diferenças significativas quando BORDARANK é comparado à SVM(R) e MLP, as diferenças entre os resultados de BORDARANK, SVM(R) e MLP são próximas à diferença crítica entre os resultados para a rejeição da hipótese nula (BORDARANK, MLP e SVM(R) tiveram um número de pontos 214, 369 e 419 respectivamente.

A diferença entre BORDARANK e MLP é de 150 e entre BORDARANK e SVM(R) é de 205.

A hipótese nula pode ser rejeitada com 95% de confiança se a diferença entre o número de pontos entre os dois algoritmos é maior que 228.

Os resultados apresentados até aqui nos permitem afirmar que BORDA-RANK melhora sensivelmente com relação aos rankings base.

Mesmo que o teste de Bonferroni-Dunn não tenha mostrado diferenças significativas com relação a SVM(R) e MLP, uma inspeção da ostra que a coluna correspondente ao BORDARANK concentra a maior parte dos melhores ou segundo melhores valores da AUC.

Além disso, em dois dos quatro conjuntos nos quais BORDARANK não obteve o melhor ou o segundo melhor resultado em termos da AUC (#1New-thyroid e #16 tic-tac-toe), existe um algoritmo com AUC igual a 100%, e não há como melhorar com relação a esse valor.

No mais, para os outros dois conjuntos de dados nos quais BORDARANK não teve o melhor ou o segundo melhor valor da AUC (#5 flag e #6 fare), a maioria dos algoritmos obteve valores de AUC menores que 65%, e somente alguns algoritmos obtiveram AUC maior do que esse valor.

Como BORDARANK é uma combinação desses rankings base, os rankings com baixo desempenho não estão contribuindo para a melhoria de BORDA-RANK.

No segundo estágio do experimento, comparamos BORDARANK com vários métodos para combinar o valor contínuo predito pelos algoritmos de aprendizado utilizados como ranking base no primeiro estágio dos experimentos.

Para prevenir problemas de escala, todos os valores foram ajustados entre zero e um.

Os métodos utilizados neste estágio do experimento são discutidos em, e são brevemente descritos a seguir.

Média dos valores preditos Calcula-se a média de todos os valores predi tos para um dado caso, e os casos são reordenados com relação a essa média.

Esse método é similar à regra da soma, discutida na Seção 83.

Produto dos valores preditos Calcula-se o produto de todos os valores preditos para um dado caso, e os casos são reordenados com relação a esse produto.

Esse método é similar à regra do produto, discutida na Seção 83.

Média aparada dos valores preditos Os dois melhores e os dois piores valores da AUC para cada caso são removidos e a média dos quatro valores restantes da AUC é calculada.

A média aparada tem o objetivo de prevenir problemas causados pela distorção de valores muito altos ou muito baixos que podem afetar a média aritmética.

Combinação utilizando uma rede neural tipo MLP Utilizamos uma rede neural do tipo MLP como um meta-algoritmo-Meta(MLP)-para aprender uma função que combine os valores individuais preditos para os casos do conjunto de treinamento.

A rede treinada é então utilizada para combinar os valores preditos para os casos do conjunto de teste, e os casos são então ordenados utilizando a função combinada.

A topologia da rede inclui duas camadas ocultas com 5 neurônios cada.

Ela foi treinada utilizando o algoritmo de backpropagation padrão, o coeficiente de momento foi ajustado para 0,2, a taxa de aprendizado para 0,e o número máximo de épocas foi ajustado para 1000 Combinação utilizando Naïve Bayes Como no item anterior, mas utilizando o algoritmo Naïve Bayes-MetaN-como meta-algoritmo.

Combinação utilizando SVM Como no item anterior, mas utilizando o algoritmo SVM-Meta-como meta algoritmo.

SVMs foram treinadas utilizando kernel linear e com parâmetros padrão.

Na ão apresentados os valores médios da AUC de todas as execuções para esses seis métodos de combinação da predição dos algoritmos base.

Para facilitar a comparação, os resultados do BORDARANK estão repetidos.

Assim como mostrado na tabela, as células com melhores valores de AUC estão destacadas utilizando-se uma cor cinza-escuro.

De maneira similar à primeira série de experimentos, executamos o teste de Friedman para testar a hipótese nula de que o desempenho dos métodos de combinação das predições são comparáveis em termos da AUC.

Dessa maneira, testamos a seguinte hipótese, Segundo a estatística de Friedman, a hipótese nula H pode ser descartada com 95% de confiança.

Como a hipótese nula foi rejeitada, podemos executar novos testes para verificar como BORDARANK é comparável com os métodos de combinação de predições.

Também executamos o teste de Bonferroni-Dunn, com BORDARANK como controle.

Em outras palavras, testamos a seguinte hipótese, O teste mostra que BORDARANK é estatisticamente melhor, com um grau de confiança de 95%, do que o produto dos valores preditos e a combinação construída com a rede neural MLP (Meta(MLP)) e Naïve Bayes (Meta(N).

Nenhuma diferença significativa foi encontrada com relação à média e média aparada dos valores preditos e a combinação construída pelo SVM (Meta).

Os resultados mostram que BORDARANK é competitivo com a média, média aparada e a combinação construída utilizando SVM.

Eles também mostram que BORDARANK, assim como média, média aparada e Meta são melhores que o produto das predições, do Meta(N e Meta(MLP).

Esses resultados são muito interessantes uma vez que BORDARANK somente utiliza a ordenação dos casos, enquanto que os outros algoritmos utilizam as predições numéricas individuais produzidas pelos rankings base.

Em outras palavras, BORDARANK pode ser utilizado em casos que somente rankings de casos estejam disponíveis, tal como em aplicações em que somente preferências de usuários estejam disponíveis, mas com um desempenho comparável com abordagens mais sofisticadas que utilizam valores contínuos.

Para concluir a avaliação experimental, no terceiro estágio da avaliação, para simular o uso do ranking combinado para derivar modelos de classificação, derivamos modelos que predizem os exemplos que aparecem nas 5%, 10%, 20% e 30% primeiras posições dos respectivos rankings.
E avaliamos precisão (número de exemplos positivos nas n% primeiras posições dividido pelo número total de exemplos nas n% primeiras posições) e sensitividade (número de exemplos positivos nas n% primeiras posições dividido pelo número total de exemplos positivos).

Para uma melhor visualização, apenas a comparação dos resultados também utilizando o teste Bonferroni-Dunn com 95% de confiança.

Além disso, incluímos apenas abordagens ques não tiveram uma melhora significativa em termos da AUC com relação ao BORDARANK (média e média aparada dos valores preditos, Meta, SVM(R) e MLP).

Em cada gráfico dessa figura, a linha mais grossa marca o intervalo de uma diferença crítica (como descrito em), à direita e à esquerda, quando comparado com BORDARANK.

Valores à esquerda (diret dessa linha são significativamente melhores (piores) do que BORDARANK.

Mesmo que os gráficos não mostrem muitas diferenças significativas, podemos identificar dois grupos de algoritmos, a média e a média aparada, juntamente com BORDARANK, quase sempre aparecem juntos, alternando os melhores resultados.

Já SVM(R), MLP e Meta formam outro grupo, alternando os piores resultados.

Essa é uma outra evidência que BORDARANK produz resultados que são comparáveis à média e a média aparada, mesmo que BORDARANK utilize somente as posições no ranking para construir o ensemble final.

Estamos simulando uma tarefa similar à recuperação de informação, na qual estamos geralmente interessados em quão bem classificamos exemplos da classe positiva.

Se estivéssemos interessados na derivação de modelos de classificação para ambas as classes, uma abordagem mais aconselhável é classificar como positivos uma porcentagem igual à proporção natural de exemplos na população, e avaliar a taxa de erro de classificação.

Comparação da precisão e sensitividade com 5%, 10%, 20% e 30% dos exemplos classificados como positivos.

O problema de ordenação de exemplos vêm recebendo uma grande atenção da comunidade de AM nos últimos anos.

Além disso, a construção de ensembles é um método muito aplicado e com bons resultados para melhorar o desempenho de modelos de classificação.

Entretanto, pouco trabalho tem sido feito na combinação desses dois métodos.

Neste capítulo apresentamos um método simples, inspirado na votação por preferências múltiplas com ordenação borda count.

Os resultados experimentais mostraram um ganho de desempenho com base nos rankings individuais que compõem o ensemble.

Além disso, BORDARANK é competitivo com vários outros métodos de combinar os valores contínuos preditos pelos modelos induzidos pelos algoritmos de aprendizado.

Como BORDARANK precisa apenas da ordenação dos exemplos e não desse valor contínuo para fazer a combinação, ele tem uma gama maior de possíveis aplicações.

N ESTE capítulo é apresentada a conclusão deste trabalho.

Na Seção 91 é feito um paralelo entre os objetivos desta tese e os resultados obtidos.

Na Seção 9são discutidas as limitações dos resultados apresentados neste trabalho.

Finalmente, na Seção 9são apresentadas as direções de trabalhos futuros.

A intersecção entre as áreas de aprendizado de máquina e mineração de dados tem-se mostrado uma rica fonte de pesquisas.

Por um lado, mineração de dados tem uma grande necessidade de novas abordagens para resolver problemas práticos do mundo real.

Do outro lado, aprendizado de máquina provê o núcleo da maioria das práticas de mineração de dados.

Nesta tese, exploramos algumas das limitações ou restrições de algoritmos de aprendizado que vieram à tona com as suas aplicações em mineração de dados com o intuito de aliviar essas limitações propondo novas abordagens, métodos e algoritmos dentro da área de aprendizado de máquina.

A seguir, reproduzimos os objetivos apresentados na introdução desta tese e contextualizamos os resultados apresentados ao longo dela dentro desses Podemos explorar alguma representação alternativa para a indução de modelos Como incorporar essa representação em um algoritmo de aprendizado Preferencialmente, representações que sejam mais facilmente entendíveis por seres humanos.

Com relação a esse objetivo, propomos um método para a geração de execeções a partir de regras gerais.

Com essas exceções, contextualizamos o conhecimento adquirido pelo par (regra geral, exceção).

A contextualização provida pelo par regra geral e exceção é uma maneira muito natural de humanos expressarem conhecimento.

Os resultados obtidos foram publicados em.

Podemos explorar algum método de busca alternativo na geração de conjuntos de regras Como o desempenho desse método se compara com outros métodos Para esse objetivo, propomos o algoritmo de seleção de regras ROCCER, que utiliza a região convexa da curva ROC para selecionar regras.

Os resultados mostraram um desempenho comparável a algoritmos clássicos de indução de regras, mas com um número de regras muito menor do que aqueles apresentados por esses algoritmos clássicos.

Nossa abordagem é diferente da abordagem tradicional de cobertura de conjunto pois o ROCCER provê um mecanismo natural de backtracking, o que possibilita a exclusão de uma regra previamente inserida à lista de decisão ou re-ordenação dessas regras.

Os resultados obtidos foram publicados em.

Conjuntos de dados com classes desbalanceadas podem piorar o desempenho de algoritmos de aprendizado Como Em que condições Podemos compensar o problema causado pelas classes desbalanceadas Como Esta tese apresenta várias contribuições com respeito a esses objetivos.

Primeiramente, constatamos experimentalmente a nossa hipótese de que o desbalanceamento entre as classes não é sempre um problema, mas é um agravante quando relacionado a outros, tais como uma grande sobreposição de classes.

Também constatamos experimentalmente que, dentro do contexto de árvores de decisão, poda geralmente é prejudicial ao desempenho de algoritmos de aprendizado na presença de desbalanceamento entre as classes.

Também constatamos que métodos de over-sampling têm, em geral, um desempenho melhor do que métodos de under-sampling no balanceamento artificial de conjuntos de dados.

Isso se deve ao fato que under-sampling pode descartar exemplos potencialmente úteis para o aprendizado.

Uma outra constatação experimental é que métodos de balanceamento artificial de conjuntos de dados tendem a piorar o problema de pequenos disjuntos.

Um dos métodos por nós proposto contribui para a diminuição desse problema, apesar da concentração de erro nos pequenos disjuntos ainda ser alta.

Finalmente, verificamos que a proporção em que rotulamos exemplos no algoritmo de aprendizado semi-supervisionado Co-training é um parâmetro de fundamental importância, fato muitas vezes ignorado pela comunidade.

Os resultados obtidos foram publicados em Como combinar diversos rankings de tal maneira a construir um ranking final com melhor desempenho que os rankings originais para o problema de ordenação binária Como o desempenho desse ranking se compara com outras abordagens Como utilizar rankings para derivar modelos de classificação Para esse objetivo, propomos um algoritmo para a combinação de vários rankings em um ranking final, abordagem conhecida como ensemble de rankings.

Nosso algoritmo, denominado BORDARANK, calcula a média dos rankings e depois reordena os casos com base nessa média.

Os resultados mostram uma melhora de desempenho, em termos da AUC, com relação aos rankings individuais, além de um desempenho comparável com métodos que utilizam mais informação (os valores numérios das predições dos modelos gerados pelos algoritmos de AM) para o mesmo fim.

Uma vantagem clara é que, uma vez que nossa abordagem utiliza apenas as posições das ordenações dos exemplos, ela é mais geral e aplicável em situações em que somente vários rankings de casos estejam disponíveis.

Nesta seção destacamos as principais limitações das soluções propostas relacionadas aos objetivos desta tese.

A abordagem para encontrar exceções foi validada com um estudo de caso.

Entretanto, seria interessante avaliar a proposta com um número maior de conjuntos de dados.

Porém, um problema quanto à essa avaliação é que ela compromete um aspecto importante da avaliação, àquele relacionado à interpretação das regras que compõem o modelo, uma vez que uma análise desse tipo implica em executar o algoritmo várias vezes para um mesmo conjunto de dados validação cruzad, gerando um grande número de modelos, o que dificulta a avaliação "semântica" desses modelos.

Uma das desvantagens do algoritmo ROCCER é que ele gera listas de decisão.

Como dito no Capítulo 5, listas de decisão são de difícil compreensão, pois as regras são válidas somente no contexto das anteriores.

Uma outra desvatagem é o tempo de execução que, em alguns casos, é alto.

Esse fato pode ser contornado pela manipulação dos parâmetros suporte e confiança do algoritmo Apriori.

Uma boa heurística para ajustar esses parâmetros, no entanto, seria desejável.

Quanto aos experimentos reportados no Capítulo 6, uma das principais limitações está relacionada ao uso de apenas um algoritmo de aprendizado para a realização dos experimentos.

Além disso, as análises foram baseadas somente em termos da AUC.

Para se ter um melhor entendimento do desempenho dos métodos de balanceamento artificial de conjuntos de dados, seria interessante analisar o comportamento das curvas ROC em todo o seu espectro.

Quanto ao algoritmo BORDARANK, o método descrito é na realidade um procedimento geral, que pode ser aplicado a qualquer conjunto de fun-que mapeiem os casos a um conjunto ordenado de casos.

No experimento desenvolvido no Capítulo 8, em particular, para criar essas funções utilizamos diferentes algoritmos de aprendizado de máquina que predizem um valor contínuo, o qual pode ser entendido como uma estimativa das chances de um caso pertencer à uma classe.

Essa escolha não é, necessariamente, a melhor.

Uma outra possível escolha seria, por exemplo, utilizar variações dos parâmetros de um mesmo algoritmo.

Também seria interessante uma alternativa para descartar modelos muito ruins do ensemble final.

Finalmente, uma comparação direta com algoritmos desenvolvidos para o mesmo fim (como o RankBoost) é desejável.

Essa comparação será realizada em trabalhos futuros, como descrito a seguir.

Várias extensões podem ser exploradas relaciondas aos trabalhos realizados.

Uma das possíveis extensões é explorar as interconexões entre os diversos temas tratados nesta tese.

Seria interessante, por exemplo, unificar as duas novas abordagens para a geração de regras.

Uma concavidade na curva ROC pode representar um exceção e esse fato poderia ser explorado para unificar as duas abordagens.

Um outro trabalho interessante é verificar o comportamento dessas abordagens no problema de classes desbalanceadas.

Exceções, por exemplo, poderiam ser utilizadas para melhorar a classificação das classes minoritárias.

Ou, ainda, fornecer ao ROCCER um número maior de regras da classe minoritária (relaxando o critério de suporte do Apriori somente para essa classe) e verificar o seu desempenho em domínios com esse problema.

Também seria interessante averiguar o desempenho do BORDARANK com os problemas de classes desbalanceadas.

Nesse caso, o objetivo seria ordenar os exemplos da classe minoritária à frente dos exemplos da classe majoritária.

Quanto ao ROCCER, como ele é um procedimento genérico de seleção de regras, ele pode ser explorado de várias maneiras.

Seria interessante, por exemplo, verificar o comportamento do ROCCER para combinar regras de diferentes algoritmos de aprendizado, em uma abordagem parecida com a descrita em.

Ou, ainda, como uma estratégia de poda de regras, na qual um conjunto inicial de regras induzidas por outro algoritmo de indução de regras é utilizado como entrada para o ROCCER.

Uma outra aplicação interessante do ROCCER está relacionada ao aprendizado em fluxo contínuo de dados.

Como ROCCER provê um mecanismo de backtracking, ele pode ser facilmente adaptado para condições de fluxo contínuo de dados.

Nesse caso, seria utilizado como entrada a ser fornecida ao algoritmo uma adaptação de Apriori para fluxos contínuos de dados.

Finalmente seria interessante investigar maneiras de transformar a lista de decisão em um conjunto de regras, com o objetivo de propiciar um melhor entendimento das regras geradas pelo ROCCER.

Um outro trabalho futuro interessante é utilizar diferentes algoritmos de aprendizado e repetir as experiências com classes desbalanceadas reportadas no Capítulo 6.

Também seria interessante utilizar, ao invés dos métodos de amostragem, custos para modificar os pesos relativos de cada classe.

Dessa maneira, em um método de over-sampling, ao invés de duplicar os exemplos da classe minoritária em n vezes, aumentaríamos o custo de cometer um erro nessa classe em n unidades.

Uma possível limitação dessa abordagem é que muito dos algoritmos atuais de aprendizado não são preparados para lidar com custos.

Ainda, os que são preparados tratam uniformemente os custos de cada classe, e não é possível utilizar métodos heurísticos que aumentariam os custos de apenas alguns dos exemplos, como os métodos heurísticos de amostragem fazem.

Finalmente, quanto ao BORDARANK, gostaríamos de compará-lo com o RankBoost.

Essa comparação depende de uma implementação desse algoritmo (já que a versão original não foi disponibilizada pelos autores).

Uma possível extensão desse algoritmo seria primeiramente criar vários "pequenos" ensembles com todos os possíveis pares de rankings.

Após, também criaríamos ensembles combinando os rankings três a três, e assim sucessivamente até a combinação de n 1 rankings, construindo o ranking final a partir dos rankings originais e dos "pequenos" ensembles construídos.

Essa abordagem é computacionalmente simples e econômica, e poderia resultar em um ganho de desempenho.

Além disso, pretendemos continuar investigando o uso de rankings para avaliar algoritmos de aprendizado segundo multiplos critérios, como recentemente por nós proposto em, explorando as vantagens de considerar apenas as ordenações das medidas obtidas, o que nos permite considerar diferentes medidas em diferentes escalas.

Essas medidas podem então ser combinadas em um ranking final.

Aliás, vale salientar que ainda que rankings seja um método bem conhecido na área de estatística não-paramétrica, ele tem sido pouco explorado na área de aprendizado de máquina.

