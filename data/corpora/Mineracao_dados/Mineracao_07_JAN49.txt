Sistemas de informações geográficas permitem a manipulação de dados espaço-temporais, sendo bastante utilizados como ferramentas de apoio à tomada de decisão.

Um SIG é formado por vários módulos, dentre os quais o banco de dados geográficos (BDG), o qual é responsável pelo armazenamento dos dados.

Apesar de representar, comprovadamente, uma fase importante no projeto do SIG, a modelagem conceitual do BDG não tem recebido a devida atenção.

Esse cenário deve-se principalmente ao fato de que os profissionais responsáveis pelo projeto e implementação do SIG, em geral, não possuem experiência no uso de metodologias de desenvolvimento de sistemas de informação.

O alto custo de aquisição dos dados geográficos também contribui para que menor atenção seja dispensada à etapa de modelagem conceitual do BDG.

A utilização de padrões de análise tem sido proposta tanto para auxiliar no projeto conceitual de BDG quanto para permitir que profissionais com pouca experiência nessa atividade construam seus próprios esquemas.

Padrões de análise são utilizados para documentar as fases de análise de requisitos e modelagem conceitual do banco de dados, representando qualquer parte de uma especificação de requisitos que tem sua origem em um projeto e pode ser reutilizada em outro(s).

Todavia, a popularização e o uso de padrões de análise para BDG têm sido prejudicados principalmente devido à dificuldade de disponibilizar tais construções aos projetistas em geral.

O processo de identificação de padrões (mineração de padrões) não é uma tarefa simples e tem sido realizada exclusivamente com base na experiência de especialistas humanos, tornando o processo lento e subjetivo.

A subjetividade prejudica a popularização e a aplicação de padrões, pois possibilita que tais construções sejam questionadas por especialistas com diferentes experiências de projeto.

Dessa forma, a identificação ou o desenvolvimento de técnicas capazes de capturar a experiência de especialistas de forma menos subjetiva é um passo importante para o uso de padrões.

Com esse objetivo, este trabalho propõe a aplicação do processo de descoberta de conhecimento em banco de dados (DCB para inferir candidatos a padrão de análise para o projeto de BDG).

Para tanto, esquemas conceituais de BDG são usados como base de conhecimento.

DCBD é o processo não trivial de descoberta de conhecimento útil a partir de uma grande quantidade de dados.

Durante o desenvolvimento da pesquisa ficou claro que a aplicação do processo de DCBD pode melhorar o processo de mineração de padrões, pois possibilita a análise de um maior número de esquemas em relação ao que é realizado atualmente.

Essa característica viabiliza que sejam considerados esquemas construídos por diferentes especialistas, diminuindo a subjetividade dos padrões identificados.

O processo de DCBD é composto de várias fases.

Tais fases, assim como atividades específicas do problema de identificar padrões de análise, são discutidas neste trabalho.

Sistemas de informação geográfica são sistemas baseados em computador que permitem a captura, armazenamento, manipulação, recuperação, análise e apresentação de dados referenciados espacialmente em relação à superfície da Terra.

Tais ferramentas têm sido amplamente utilizadas para auxiliar no processo de tomada de decisão em áreas como, por exemplo, saúde, segurança, planejamento urbano e controle ambiental.

De modo geral, um software de SIG é um sistema formado por quatro grandes componentes, os quais são responsáveis pela captura, armazenamento, análise e apresentação de dados.

O módulo de armazenamento, denominado banco de dados geográficos (BDG), estrutura e armazena os dados geográficos.

Dados geográficos ou geo-referenciados são comumente caracterizados a partir de suas componentes não-espacial, espacial e temporal.

A componente não-espacial descreve o fenômeno da realidade através de variáveis de interesse (tais como nome, extensão e vazão de um rio).

A componente espacial refere-se tanto à localização espacial quanto às propriedades geométricas e topológicas da entidade ou fenômeno da realidade (coordenadas e geometria do rio, por exemplo).

A data de coleta dos dados e o período de validade dos mesmos são indicados através da componente temporal.

Em virtude das características próprias dos dados geográficos, os projetos e a implementação de um BDG são mais complexos do que os de um banco de dados puramente não-espaciais.

Assim como esse último, um BDG deve ser projetado, a fim de viabilizar e facilitar tanto sua compreensão, manipulação, manutenção e extensão quanto o processo de integração de dados.

O projeto de BDG ocorre em várias etapas, dentre as quais destaca-se a modelagem conceitual.

Essa fase é voltada à compreensão da realidade, onde somente os elementos essenciais são enfatizados.descartando-se os elementos irrelevantes através do processo de abstração.

Como resultado, as entidades do mundo real, seus relacionamentos e regras de integridade são representados através do esquema conceitual de BDG.

Esquemas conceituais são criados com o objetivo de documentar os tipos de dados armazenados assim como seus relacionamentos, fornecendo uma visão geral e completa das informações disponíveis para o usuário no banco de dados.

A principal característica do esquema conceitual consiste na sua independência em relação ao sistema computacional a ser utilizado, possibilitando que a definição do hardware e do software de gerência do banco de dados seja postergada até a conclusão da modelagem conceitual.

A criação de esquemas conceituais é baseada em modelos de dados conceituais, os quais apresentam os construtores necessários para modelar a realidade, além das regras de utilização dos mesmos.

Os elementos de um esquema são, dessa forma, instâncias de uso dos construtores definidos no modelo de dados adotado.

Embora represente uma fase importante no projeto de um SIG, a modelagem conceitual de BDG tem sido, comumente, negligenciada.

Esse cenário deve-se principalmente, à concepção do esquema conceitual não ser trivial, podendo implicar em decisões complexas, onde más escolhas conduzem a sistemas frágeis e difíceis de manter, compreender e estender ao fato de a equipe responsável pela implantação do SIG ser, em geral, composta por profissionais que não possuem formação em informática, mas em áreas como engenharia, arquitetura, cartografia, geografia, entre outras.

Esses profissionais, de modo geral, não conhecem metodologias de desenvolvimento de sistemas de informação ou são inexperientes no uso das mesmas e ao alto custo de aquisição dos dados geográficos, levando a que maior atenção seja dispensada a essa etapa do desenvolvimento do SIG em detrimento das demais.

Sendo conhecidas as dificuldades em relação à modelagem conceitual de banco de dados, se propõe uma série de heurísticas para auxiliar no desenvolvimento dessa atividade.

Paralelamente, outra abordagem que vem sendo bastante explorada na solução de problemas complexos, principalmente na área de engenharia de software, consiste na utilização de padrões.

Padrão, nesse escopo, consiste em uma combinação de elementos recorrentes que apresentam a essência de uma solução para problemas análogos em contextos específicos.

Como são elementos de reutilização, a aplicação de padrões permite que o projeto não seja iniciado do zero, contribuindo para a redução do seu tempo total de execução.

Além disso, são reutilizadas soluções consolidadas, desenvolvidas por especialistas, o que implica no aumento da qualidade dos produtos e na maior facilidade de atualização dos mesmos.

Padrões são definidos em vários níveis de abstração, a fim de serem aplicados nas diferentes etapas de desenvolvimento de software e de projeto de banco de dados.

Padrões de análise são utilizados para documentar, especificamente, a análise de requisitos e a modelagem conceitual de banco de dados.

Um padrão de análise representa qualquer parte de uma especificação de requisitos que se origina em um projeto e pode ser reutilizada em outro(s).

Cada padrão de análise consiste em um conjunto de classes e associações que têm algum significado no contexto de um grupo de aplicações.

Em um nível mais baixo de abstração, um padrão de análise consiste em um subesquema conceitual de bancos de dados freqüentemente utilizado na modelagem conceitual de aplicações distintas.

Esse tipo de padrão é particularmente útil durante o projeto de BDG, pois a estrutura conceitual dos tipos de dados que compõem a chamada cartografia básica dos SIG é bastante semelhante para a maioria das aplicações.

Essa característica ainda é mais acentuada quando se considera o intercâmbio de dados espaciais, prática que vem se tornando cada vez mais comum devido ao alto custo de aquisição de tais dados.

Uma vez que a utilização de padrões tende a diminuir o tempo de projeto e aumentar a qualidade do produto final, a sua aplicação no projeto de BDG tem sido muito bem aceita pela comunidade de SIG.

Todavia, o uso de padrões de análise no projeto de BDG tem sido prejudicado, principalmente, devido à dificuldade de disponibilização dessas construções aos projetistas em geral.

A fim de atender a essa demanda, a criação de um catálogo de padrões de análise, específico para BDG, mostra-se de extrema utilidade.

Catálogo de padrões é uma coleção de padrões relacionados entre si, servindo de guia de referência para a utilização dessas construções.

A criação e utilização de catálogos voltados para o reuso deve considerar três aspectos, aquisição de conhecimento para sua criação, atualização do catálogo, de modo que ele sempre reflita as necessidades dinâmicas, inerentes às organizações e ao desenvolvimento de software e desenvolvimento de técnicas para consultar o catálogo e recuperar os padrões de modo eficaz e eficiente.

O problema de consultar catálogos, a fim de localizar construções relevantes é, há muito, tratado como tema importante de pesquisa.

Entretanto, afirma-se que as duas outras questões não recebem a mesma atenção.

Nesse contexto, este trabalho aborda o problema referente à aquisição de conhecimento para criação de catálogos, formados, especificamente, por padrões de análise para BDG.

A tarefa de procurar e localizar padrões a fim de documentá-los é conhecida como pattern mining ou mineração de padrões.

Pesquisadores descrevem vários métodos e procedimentos utilizados com essa finalidade.

No entanto, as diversas abordagens propostas são centradas na experiência prática de especialistas no domínio da aplicação, tornando o processo lento e subjetivo.

Lento, pois a tarefa não é trivial e requer a análise de vários projetos previamente desenvolvidos.

Subjetivo em decorrência da definição de um padrão ser baseada nos conceitos de "solução bastante testada" e "problema recorrente", cuja avaliação depende da experiência de cada indivíduo.

Padrões identificados por técnicas baseadas no conhecimento humano têm sua popularização prejudicada, pois refletem a experiência de apenas um pequeno grupo de especialistas.

Essa característica permite que os padrões propostos sejam contestados por outros especialistas com diferentes experiências de projeto.

Diante de tais dificuldades, seria promissora a utilização de uma estratégia capaz de identificar padrões de modo menos subjetivo, a qual levasse também em consideração o conhecimento de um grupo maior de indivíduos.

Nesse contexto, o processo de Descoberta de Conhecimento em Banco de Dados (DCB apresenta-se como alternativa).

DCBD é o processo não-trivial de extração de conhecimento a partir de um grande volume de dados.

Sua principal característica consiste na automatização, ao menos parcial, da tarefa de análise de dados.

Acredita-se que o processo de DCBD possa ser utilizado para auxiliar na tarefa de mineração de padrões, pois é capaz de analisar um maior número de esquemas conceituais de diferentes especialistas em relação ao que vem sendo feito pelos métodos atualmente conhecidos.

Essa característica viabiliza a identificação de padrões baseados na experiência de um número maior de especialistas em relação aos atualmente propostos.

Além disso, a análise automatizada dos esquemas implica em que novos padrões podem ser identificados mais rapidamente.

Com base nessas características, esse trabalho investiga a aplicação do processo de DCBD como alternativa à solução do problema de identificação de padrões de análise para projeto de BDG, utilizando esquemas conceituais de BDG como ponto de partida.

Estratégias para identificação de padrões são descritas.

Todas são, no entanto, centradas no conhecimento do especialista.

Não foi possível localizar na literatura consultada qualquer esforço no sentido de automatizar a identificação de padrões de análise.

Estão disponíveis diversos trabalhos voltados à criação de repositórios contendo outros tipos de construção, além de pesquisas que visam, principalmente, à identificação de instâncias de padrões de projeto.

Alguns dos trabalhos consultados são descritos a seguir.

Alternativas para a identificação automática de instâncias de padrões de projeto.

As três abordagens baseiam-se em códigos fonte de sistemas orientados a objetos e visam identificar estruturas implementadas com base nos padrões de Gamma.

É apresentada a ferramenta DP++, a qual automatiza a detecção, identificação e classificação de padrões de projeto em programas escritos na linguagem C++.

A ferramenta analisa o código fonte e, baseada nos relacionamentos estruturais entre classes e objetos, identifica instâncias de alguns padrões de projeto.

O trabalho é bastante semelhante ao citado anteriormente, sendo aplicado, todavia, para a análise de códigos escritos na linguagem Smalltalk.

Tem como principal objetivo criar bases de padrões de projeto personalizadas para cada empresa, de modo que os padrões são empiricamente validados para o ambiente em questão.

Como primeiro passo nesse sentido, foi desenvolvido um método indutivo chamado BACKDOOR.

O método é iterativo e, a partir de projetos já existentes, localiza tanto novos padrões quanto ocorrências de padrões já definidos.

Se novas instâncias de padrões já conhecidos são localizadas nos projetos pesquisados, elas são utilizadas para atualizar métricas que avaliam a usabilidade do padrão.

Por outro lado, padrões já conhecidos são empregados para deduzir características estruturais, as quais são posteriormente analisadas como potenciais padrões.

Na primeira iteração, a base está vazia, sendo utilizados os padrões definidos por Gamma.

O trabalho apresenta apenas uma parte de todo o processo, de modo que o autor mostra somente a detecção de instâncias de uso dos padrões de projeto definidos por Gamma, não detalhando o processo de identificação de novos padrões.

Busca-se uma alternativa para construir repositórios de componentes reutilizáveis, apresentando uma espécie de "ciclo de vida" de repositórios.

O autor descreve os problemas de indexação e recuperação de componentes, além de apresentar ferramentas projetadas para suportar o refinamento incremental do repositório.

No que diz respeito à população do repositório, o autor afirma que, nos estágios iniciais, ela é realizada utilizando-se, inclusive, componentes que não foram projetados com o objetivo explícito de serem reutilizados.

O protótipo apresentado no trabalho extrai componentes a partir de arquivos texto de forma semi-automática, requerendo alguma intervenção do usuário.

No entanto, a ênfase da pesquisa não consiste em especificar quais componentes serão utilizados, mas sim como eles são representados de modo a possibilitar a sua posterior recuperação.

Em outro contexto, Michail busca identificar padrões de reuso de classes de bibliotecas específicas, a fim de facilitar a seleção e utilização de componentes disponíveis em uma biblioteca de classes.

Para atingir o objetivo, o autor aplica o algoritmo de mineração de dados de identificação de regras associativas baseado no uso de taxonomias.

O algoritmo é empregado visando à identificação de classes e funções de classes da biblioteca geralmente utilizadas em conjunto em aplicações distintas.

Ainda que vários trabalhos busquem automatizar o processo de identificação de padrões ou a criação de repositórios, não foi encontrada qualquer pesquisa específica para auxílio à identificação de padrões de análise.

A partir da necessidade de identificar padrões de análise para BDG com base em técnicas que reduzam a influência e o esforço do especialista, o principal objetivo desse trabalho consiste em verificar a viabilidade da aplicação do processo de Descoberta de Conhecimento em Banco de Dados (DCB para esse fim).

Nesse caso, a base de conhecimento utilizada é formada por esquemas conceituais de BDG.

Acredita-se que a aplicação do processo de DCBD na identificação de padrões de análise para BDG possa diminuir a subjetividade comum à seleção dos padrões, pois esse processo possibilita a obtenção de conhecimento a partir de grandes volumes de dados.

A pesquisa também busca identificar atividades específicas a serem realizadas nas várias etapas do processo de DCBD de modo a viabilizar sua aplicação no problema proposto.

Introdução ao projeto de banco de dados geográficos e a padrões.

Breve revisão do processo de descoberta de conhecimento em banco de dados.

É apresentada a seleção da técnica de mineração de dados utilizada no trabalho, assim como aspectos referentes à preparação dos esquemas conceituais utilizados na mineração.

Pós-processamento das regras associativas geradas pelo algoritmo de MD.

São listadas alguns tipos de regras de interesse, além de filtros utilizados com o objetivo de reduzir o número total de regras a serem analisadas pelo especialista humano.

São descritos os testes realizados com o objetivo de verificar a adequação do processo de DCBD ao problema de identificar padrões de análise para BDG.

Sistemas de informação geográfica são sistemas baseados em computador que permitem a captura, armazenamento, manipulação, recuperação, análise e apresentação de dados referenciados espacialmente em relação à superfície da Terra.

Um SIG é formado por vários módulos, dentre os quais o banco de dados geográficos (BDG).

Componentes de um SIG.

O BDG é o módulo do SIG responsável por estruturar e armazenar os dados de modo a possibilitar a realização das operações de análise e consulta.

Nesse contexto, o projeto de banco de dados (B está inserido no processo de concepção do SIG como a etapa onde as estruturas estáticas do sistema são definidas, de modo a satisfazer as necessidades de usuários e aplicações).

O projeto do banco de dados é importante, pois viabiliza e facilita atividades como manutenção, extensão e integração de bancos de dados.

No caso específico de BDG, o projeto mostra-se ainda mais necessário em função da prática de intercâmbio de dados geográficos, além da maior complexidade inerente aos dados manipulados por esses sistemas.

O projeto de BD é dividido nas seguintes fases ou etapas, coleta e análise de requisitos, projeto conceitual, seleção do sistema gerenciador de banco de dados, projeto lógico, projeto físico e implementação do BD.

A primeira fase, coleta e análise de requisitos, envolve a identificação e especificação dos requisitos dos usuários.

Essa etapa consiste no primeiro passo no sentido de entender os dados a serem armazenados e as regras de integridade inerentes a eles.

Nesse momento, o aspecto abordado refere-se a quais dados devem ser armazenados e como eles serão processados.

Essa fase não dispõe de ferramentas de apoio formais e é, geralmente, realizada com base em entrevistas com os usuários, revisão de documentos já existentes, questionários e análise do ambiente atual.

A partir dos requisitos do usuário, o projeto ou modelagem conceitual do BD é realizado com o objetivo de produzir uma visão em alto nível do problema.

O produto resultante dessa fase é o esquema conceitual do banco de dados, o qual apresenta a estrutura dos dados a serem armazenados de forma completamente independente do sistema computacional.

Na etapa de projeto lógico, o esquema conceitual criado na segunda fase é mapeado para o modelo de dados do SGBD escolhido.

O resultado é o esquema lógico do BD, que, diferentemente do esquema conceitual, é dependente do SGBD.

O projeto físico do BD, por sua vez, define suas características em termos das estruturas físicas de armazenamento e caminhos de acesso.

Esse é o nível mais baixo do projeto, onde as características do SGBD devem ser muito bem conhecidas.

A última etapa do projeto consiste na criação, propriamente dita, do banco de dados.

Para tanto, é utilizada a linguagem de descrição de dados (Data Description Language DDL) do SGBD.

Dentre todas as etapas do projeto de BD, a modelagem conceitual é considerada a mais complexa, pois os produtos das demais fases podem ser obtidos através da aplicação de regras de transformação sobre o esquema conceitual.

Modelagem de dados é o processo de abstração através do qual apenas os elementos essenciais da realidade observada são enfatizados, descartando-se os irrelevantes.

A modelagem (ou projeto) conceitual do BD compreende a descrição dos tipos de dados, além das estruturas e regras a eles aplicáveis, independente de como estes dados serão armazenados no computador.

Sua importância, do ponto de vista do projetista, deve-se às seguintes características, torna o projeto final mais estável, retarda a escolha do SGBD, pois é independente do sistema escolhido, facilita a manutenção do BD, facilita a integração entre bancos de dados, facilita tanto a comunicação entre os projetistas quanto a comunicação entre os projetistas e o usuário, e aumenta a possibilidade de convergência do projeto para o produto final esperado.

Essa etapa do projeto é baseada em um modelo conceitual de dados, o qual fornece a base formal para ferramentas e técnicas que suportam a modelagem.

Modelos de dados compreendem um formalismo e uma linguagem de descrição.

O formalismo provê um conjunto de conceitos e regras que são utilizados no processo de modelagem da realidade.

A linguagem de descrição, por sua vez, fornece a gramática e a notação para a apresentação do esquema conceitual resultante dessa etapa do projeto.

As seguintes características são requeridas em um modelo de dados.

Expressividade, o modelo deve ser capaz de diferenciar diversos tipos de dados, relacionamentos e restrições.

Simplicidade, o modelo deve ser facilmente compreendido pelo usuário final.

Minimidade, deve apresentar um número reduzido de construtores básicos, distintos entre si e semanticamente excludentes.

Representação simples, deve possuir uma representação diagramática de fácil interpretação.

Formalidade, os conceitos do modelo devem ser definidos de forma rígida e não-ambígua.

Um formalismo bastante popular, muito empregado como modelo conceitual de bancos de dados, é o Entidade-Relacionamento.

Todavia, apesar de estar consolidado e possuir grande aceitação, o modelo ER não se mostra adequado para a modelagem de aplicações ditas não-convencionais, tais como BDG, bancos de dados multimídia, entre outros.

Além disso, a necessidade de que o modelo represente a aplicação de maneira mais próxima a seus elementos de origem, em vez de adaptar a realidade às estruturas rígidas do computador, vem aumentando a utilização de modelos baseados no formalismo da orientação a objetos.

Com base no paradigma, vários modelos e linguagens foram definidos para serem utilizados nas diversas etapas do ciclo de vida de software.

O modelo que representa as estruturas estáticas e, portanto, é utilizado durante a modelagem conceitual de banco de dados, é o diagrama de estrutura estática ou diagrama de classes.

Apesar de apresentar vantagens em relação ao modelo ER, os modelos tradicionais da orientação a objetos também não são completamente adequados para tratar características específicas dos dados geográficos.

Dados geográficos ou geo-referenciados referem-se a entidades e fenômenos da realidade associados a sua localização referenciada espacialmente em relação à superfície da Terra.

Tais dados são comumente caracterizados por suas componentes.

Não-espacial descreve a entidade ou fenômeno da realidade através de variáveis de interesse (por exemplo, nome do rio).

Espacial informa a localização espacial do fenômeno, assim como suas propriedades geométricas e topológicas (as coordenadas e a geometria do rio, por exemplo).

Temporal indica a data de coleta e o período de validade dos dados.

Além das particularidades dos dados geográficos, outro aspecto que deve ser considerado durante a modelagem conceitual de BDG refere-se às diferentes percepções da realidade geográfica.

Esta última pode ser observada segundo as visões de campo e de objeto.

A realidade percebida na visão de campo é modelada por variáveis que possuem uma distribuição contínua no espaço como, por exemplo, pressão atmosférica, temperatura e altitude.

Na visão de objetos, a realidade é constituída por entidades individuais e bem definidas, tais como edificações, vias e rios, por exemplo.

As entidades percebidas segundo essa visão possuem propriedades e ocupam lugar específico no espaço, o qual não está, necessariamente, totalmente ocupado.

Além disso, diferentemente do que ocorre na visão de campo, na visão de objetos, duas ou mais entidades podem estar situadas em uma mesma posição.

Em função dessas e de outras características não serem suportadas por modelos tradicionais, modelos conceituais de dados têm sido adaptados, a fim de possibilitar a modelagem de dados geográficos.

Atualmente, se tem disponível uma série de modelos de dados geográficos, em sua maioria, baseados no paradigma da orientação a objetos.

Dentre eles, destacam-se o padrão SAIF, o MADS, o UML-GeoFrame, o GEOOA e o GEO-OMT.

Comparações detalhadas entre esses modelos estão descritas.

Apesar da existência de ferramentas específicas para a modelagem conceitual de BDG, essa etapa do ciclo de vida do SIG tem sido, comumente, negligenciada devido, principalmente, aos seguintes fatores, a concepção do esquema conceitual não é trivial, podendo implicar em decisões complexas, onde más escolhas conduzem a sistemas frágeis e difíceis de manter, compreender e estender.

Em geral, a equipe responsável pelo desenvolvimento do SIG é composta por profissionais que não possuem formação em informática, mas em áreas como engenharia, arquitetura, cartografia, geografia, entre outras.

Esses profissionais, de modo geral, não conhecem metodologias de desenvolvimento de sistemas de informação ou são inexperientes no seu uso, e o alto custo de aquisição dos dados geográficos acarreta que maior atenção seja dispensada a essa etapa do desenvolvimento do SIG em detrimento das demais.

Sendo conhecidas as dificuldades em relação à modelagem conceitual de banco de dados e em virtude da importância desta fase do projeto de BDG, uma série de heurísticas foram propostas em e com objetivo de auxiliar no desenvolvimento dessa atividade.

As diretrizes apontadas por esses e outros autores são bastante úteis no sentido de esclarecer dúvidas em relação a conceitos apresentados pelos modelos de dados e até mesmo na decisão de qual construtor utilizar na representação de certos aspectos da realidade.

Todavia, as mesmas não garantem a criação de esquemas ótimos.

Paralelamente, outra abordagem que vem sendo bastante explorada para melhorar a qualidade dos projetos, principalmente na área de engenharia de software, consiste na utilização de padrões.

Padrão, nesse contexto, é uma combinação de elementos de modelagem recorrentes em diferentes projetos e que apresentam a essência de uma solução para problemas análogos em contextos específicos.

A característica que torna o uso de padrões bastante interessante, tanto no contexto da engenharia de software quanto no projeto de banco de dados, é que essas construções são elementos de reutilização.

Como tal, o emprego de padrões, além de agilizar o projeto e facilitar a comunicação entre seus integrantes, possibilita a disseminação de conhecimento e a troca de experiências entre projetistas, contribuindo para o aumento da qualidade do produto final.

A reutilização de soluções conhecidas para resolver problemas novos há muito vem sendo realizada, de forma "não declarada", nas várias etapas de desenvolvimento de software.

Programadores e analistas, instintivamente, recordam experiências vividas em outros projetos e reutilizam soluções bem sucedidas.

No entanto, nas duas últimas décadas, essas construções reutilizáveis tornaram-se explícitas e tangíveis.

Na ciência da computação, o processo de documentar padrões teve início em 1987, quando especialistas em projeto de sistemas orientado a objetos, desenvolveram uma linguagem de padrões para projetar interfaces gráficas em Smalltalk.

Em 1992, foi publicado o livro como resultado da catalogação de padrões para C++.

Com a publicação da primeira edição do livro, o tema passou a ser mais discutido e divulgado na comunidade.

A partir da popularização do conceito, foram propostos padrões em vários níveis de abstração, a fim de serem aplicados nas diferentes etapas de desenvolvimento de software e de projeto de banco de dados.

Padrões de análise são utilizados para documentar as etapas de análise de requisitos e modelagem conceitual.

Esse tipo de padrão representa qualquer parte de uma especificação de requisitos que se origina em um projeto e pode ser reutilizada em outro(s), sendo formado por um conjunto de classes e associações que têm algum significado no contexto de uma aplicação.

Em última instância, para o projeto conceitual de BD, padrões de análise são subesquemas conceituais freqüentemente (re)utilizados na modelagem conceitual de aplicações distintas Segundo Fernandez, padrões de análise prestam maior contribuição para o aumento da qualidade do software se comparados aos padrões de projeto, ainda que, historicamente, maior atenção seja dispensada a esses últimos.

Padrões de projeto apresentam inúmeras vantagens quando aplicados na fase de projeto de aplicações.

No entanto, não evitam erros na etapa de análise de requisitos, nem facilitam a construção de modelos conceituais, importantes para a compreensão da realidade.

Esse fato implica em que erros cometidos em etapas anteriores ao projeto do software sejam propagados ainda que padrões de projeto sejam utilizados.

No caso específico de SIG, padrões de análise são particularmente úteis, pois a estrutura conceitual dos tipos de dado que compõem a cartografia básica desses sistemas é bastante semelhante para a maioria das aplicações.

Essa característica é ainda mais valorizada se considerado o intercâmbio de dados espaciais.

Para que padrões sejam disponibilizados e utilizados pela comunidade, é necessário que estejam documentados e descritos de forma que os projetistas possam compreender sua aplicabilidade e a solução que representam.

No entanto, apesar da importância de se estabelecer critérios para a descrição de padrões, ainda não existe um modelo universal para este fim.

Em geral, cada autor ou grupo que propõe novos padrões opta por um modelo específico, o qual contempla os aspectos por eles julgados importantes.

Utiliza-se um modelo de descrição bastante extenso e rico em informações, que variam desde a motivação para aplicação do padrão até a apresentação de seu diagrama de classes de projeto.

Utiliza-se uma forma mais simples e compacta para a descrição, a qual divide um padrão em quatro partes principais, quais sejam, seu nome, contexto onde o problema foi identificado e para o qual foi proposta a solução, problema que resolve, forças (restrições) que influenciaram na solução do problema, e solução, descrita na forma de diagrama de classes acompanhado por um texto explicativo.

Os padrões são descritos através dos elementos, nome, problema, solução, e conseqüências.

Sendo que esse último descreve os resultados obtidos com a utilização do padrão.

Modelo para descrição de padrões de análise onde são especificados o problema resolvido, as forças que influenciaram na solução, a solução propriamente dita, as conseqüências do uso do padrão, casos conhecidos onde ele foi aplicado, e padrões relacionados.

No primeiro, os padrões são descritos através da trinca problema, contexto e solução.

No segundo, os autores sugerem que o par padrão-contexto, em geral, é suficiente, mas não descartam a inclusão de informações mais específicas em algumas situações.

Apesar de não existir consenso em relação às informações que devem ser utilizadas para descrever um padrão, a própria definição do termo sugere que, no mínimo, sejam descritos o problema, o contexto e a solução.

Um catálogo de padrões é uma coleção de padrões relacionados entre si, servindo de guia de referência para utilização dessas construções.

O catálogo é uma forma de organizar e disponibilizar padrões de modo a facilitar sua aplicação.

Um catálogo de padrões geralmente subdivide essas construções em categorias e inclui referências cruzadas entre as mesmas.

O catálogo impõe certa estrutura e organização a uma coleção de padrões de forma menos rígida do que as encontradas em um sistema de padrões.

Esse último consiste em um conjunto coeso de padrões relacionados que trabalham em conjunto para suportar a construção e manutenção de arquiteturas completas.

O website de padrões disponível na Internet apresenta uma listagem de vários catálogos utilizados para diversos fins.

Além desses, o livro "Padrões de Projeto, soluções reutilizáveis de software orientado a objetos", possivelmente representa hoje o catálogo de padrões mais conhecido e utilizado pela comunidade da engenharia de software orientado a objetos.

A criação e utilização de catálogos voltados para o reuso deve considerar três aspectos, aquisição de conhecimento para sua criação, atualização do catálogo, de modo a refletir as necessidades dinâmicas inerentes às organizações e ao desenvolvimento de software, e desenvolvimento de técnicas para consultar o catálogo e recuperar os padrões de modo eficaz e eficiente.

A aquisição de conhecimento é uma atividade crítica para a criação do catálogo.

Essa fase inclui a identificação dos artefatos reutilizáveis, seguida de sua compreensão e representação em um formalismo capaz de denotar suas funcionalidade e semântica.

Além disso, essa etapa pode incluir generalizações, a fim de que a construção possa ser aplicada em um escopo maior.

A atualização do catálogo tem o objetivo de, permanentemente, refletir o conhecimento atual, já que as necessidades de usuários e aplicações mudam ao longo do tempo.

O desenvolvimento de técnicas de consulta, por sua vez, é imprescindível.

Um catálogo deve conter construções suficientes para auxiliar os projetistas.

No entanto, quando muitos exemplos estão disponíveis, procurar e escolher os mais apropriados se torna um problema.

Dentre os três aspectos citados, o problema de consultar catálogos, a fim de localizar construções relevantes vem sendo abordado por diversos autores.

Entretanto, as duas outras questões não recebem a mesma atenção.

A próxima seção aborda o problema da identificação de padrões, cuja solução é o objetivo deste trabalho.

A tarefa de procurar e localizar padrões a fim de documentá-los é conhecida como pattern mining ou mineração de padrões.

Não tem sido dedicado muito esforço no sentido de localizar e formalizar padrões, algumas alternativas foram encontradas na literatura.

Técnicas empregadas com o objetivo de identificar padrões dentro de uma organização.

Dentre elas, destacam-se, mineração por entrevistas, consiste em entrevistar especialistas em desenvolvimento de software e listar as informações obtidas no formato de padrões.

Os principais problemas dessa abordagem consistem em que ela é lenta e difícil de realizar.

Os especialistas geralmente estão envolvidos em projetos e não possuem tempo disponível para as entrevistas.

Além disso, torna-se necessário o domínio de técnicas de entrevista, a fim de que seja possível capturar todo o conhecimento que esses profissionais têm a compartilhar.

Mineração através de compartilhamento, é uma técnica útil quando utilizada por empresas do mesmo ramo que podem compartilhar informações.

Através do compartilhamento, é possível observar soluções comuns às aplicações de empresas da mesma área de atuação.

O problema dessa abordagem consiste na disposição das empresas em compartilhar informações.

Mineração em workshops, consiste em reunir desenvolvedores, apresentar um problema e capturar as soluções propostas.

Tais soluções, sumarizadas, consistem na essência da solução do problema, ou seja, são padrões.

Mineração da própria experiência, consiste em recordar experiências passadas na busca de pedaços de soluções para serem documentadas e compartilhadas.

Conjunto de atividades que podem ser realizadas no sentido de identificar novos padrões.

São elas, Localizar, pelo menos, três exemplos onde um problema de projeto é recorrente e é resolvido de forma eficiente, usando a mesma solução.

Os exemplos devem ser de aplicações reais desenvolvidas por diferentes equipes.

Extrair a solução abstraindo detalhes específicos das aplicações.

Descrever o problema resolvido e as forças a ele associadas.

Listar os exemplos a partir dos quais a solução foi originada.

Declarar a solução como sendo um candidato a padrão.

Promover um workshop para melhorar a descrição do candidato a padrão e compartilhá-lo com outros projetistas.

Aplicar o candidato a padrão em projetos reais.

Promover o candidato a padrão, se a aplicação for bem sucedida.

Caso contrário, melhorar sua descrição e testá-lo novamente ou descartá-lo.

Uma característica destacada por Fowler, que pode ser observada tanto no trabalho de Rising quanto no de Buschman, consiste na forte dependência dos padrões em relação à experiência de especialistas.

Por ser fortemente dependente do conhecimento do ser humano e ser realizado de modo manual, o processo de identificação de padrões tem se mostrado lento e subjetivo.

O processo é lento, porque requer do analista habilidade, experiência e capacidade de abstração, além de conhecimento de vários projetos anteriores.

O processo é subjetivo em decorrência da definição de padrão, baseada nos conceitos de "solução bastante testada" e "problema recorrente", os quais estão diretamente relacionados com as experiências de projeto de cada especialista.

Tais características prejudicam a popularização e a aplicação de padrões, contribuindo para a escassez de soluções reutilizáveis.

O caráter subjetivo é particularmente prejudicial, pois possibilita que os padrões propostos por um especialista (ou grupo de especialistas) sejam contestados por outros com diferentes experiências de projeto.

Esse cenário é verificado inclusive nas áreas de engenharia de software e projeto de BD, as quais apresentam uma enorme quantidade de informação (códigos fonte, esquemas de banco de dados) a partir da qual é possível obter componentes reutilizáveis.

Em contraste à escassez de padrões, se cada especialista apontar pelo menos uma construção a qual julga útil, correta e recorrente, o número de padrões crescerá tão rapidamente que se tornará impossível saber quais existem e quais problemas cada um deles soluciona.

Se por um lado, a maneira como o processo de identificação de padrões vem sendo conduzido não se mostra eficiente, por outro não se tem visto muito esforço no sentido de desenvolver métodos alternativos capazes de realizar essa atividade de forma automática e menos dependente do conhecimento do especialista humano.

Diante desse cenário, o presente trabalho tem como objetivo verificar a viabilidade de utilização do processo de DCBD para identificar padrões de análise para BDG que levem em consideração o conhecimento de um número maior de especialistas em relação aos métodos atualmente empregados.

O capítulo seguinte apresenta uma breve descrição do processo de DCBD.

A crescente massa de dados armazenada pelas organizações e o grande número de variáveis a serem consideradas durante as análises de dados consistem na principal motivação para o desenvolvimento e a aplicação de técnicas de Descoberta de Conhecimento em Banco de Dados (DCB).

DCBD é o processo não-trivial de extração de conhecimento a partir de um grande volume de dados.

O processo é considerado não-trivial, pois o conhecimento está representado de forma implícita, não sendo possível obtê-lo diretamente, a partir de consultas convencionais em SQL, por exemplo.

Assim, DCBD busca desenvolver métodos e técnicas capazes de obter conhecimento a partir de dados brutos, automatizando, ao menos parcialmente, a tarefa de análise dos dados.

Fayyad apresenta o problema da descoberta de conhecimento como o mapeamento de dados em baixo nível (registros de BD, por exemplo) para outra forma mais compacta, abstrata ou útil (como, por exemplo, modelos ou regras).

O processo de DCBD é interativo e iterativo.

Para ser empregado, requer a perfeita compreensão do domínio da aplicação e dos objetivos a serem alcançados.

O processo pode ser dividido nas fases de preparação de dados, mineração de dados e pós-processamento.

Cada fase é formada por etapas, as quais incluem a realização de várias atividades, voltadas a atingir objetivos específicos.

Decomposição desse processo.

Fases, etapas e atividades inerentes ao processo de DCDB.

Alguns autores tratam a mineração de dados (M como sinônimo de descoberta de conhecimento em banco de dados, enquanto existe uma corrente que diferencia os dois conceitos e define a mineração de dados como uma etapa do processo completo de DCBD).

No contexto desse trabalho, será utilizada essa última abordagem.

As seções a seguir descrevem cada uma das fases do processo de DCBD, assim como suas etapas e algumas das atividades que podem ser realizadas.

Maior ênfase é dispensada à MD, pois, além de ser um dos focos principais do trabalho, essa fase pode ser estudada de forma independente da aplicação.

A fase de pós-processamento e algumas das etapas da preparação de dados também foram estudadas em detalhes.

Todavia, como nesses últimos casos as atividades e decisões estão diretamente relacionadas à aplicação.

Na fase de preparação de dados são realizadas atividades que visam tanto a aumentar a qualidade dos dados quanto a dispor os mesmos de modo que a extração de conhecimento seja facilitada.

A principal contribuição dessa fase deve ser o aumento da acurácia e da eficiência na etapa de mineração de dados.

A preparação de dados é uma fase muito importante para o sucesso da aplicação de DCBD, pois a qualidade das decisões está diretamente relacionada aos dados nos quais elas se baseiam e os bancos de dados disponíveis estão, geralmente, incompletos, com erros e inconsistentes.

Além disso, uma vez que o projeto do banco de dados não é realizado visando à aplicação do processo de DCBD, algumas de suas características dificultam a mineração de dados.

A fase de preparação de dados é composta das etapas de seleção, pré-processamento, limpeza e transformação de dados.

Cada uma dessas etapas envolve a aplicação de uma ou várias técnicas que visam preparar melhor os dados para serem minerados.

Na etapa de seleção de dados, busca-se criar a base a ser utilizada durante o processo, através da identificação dos dados relevantes para atingir os objetivos do usuário.

Não é raro que sejam utilizadas mais de uma fonte de dados.

Nesse caso, torna-se necessário que os dados das diferentes fontes sejam integrados em um único repositório, a fim de serem combinados de modo consistente.

A integração de dados, em geral, não é uma atividade simples e visa resolver uma série de problemas como redundância e ocorrência de sinônimos, homônimos e parônimos.

Outro aspecto considerado refere-se à quantidade de dados.

Uma vez que a análise de enormes volumes de dados pode ser impraticável, técnicas de data reduction são utilizadas com o objetivo de reduzir o volume de dados, obtendo uma representação que mantém a integridade dos dados originais.

A etapa de pré-processamento visa identificar erros nos dados selecionados, localizando problemas como atributos com nomes errados, atributos obrigatórios sem valor, registros contendo uma mesma informação codificada de forma diferente e/ou registros duplicados.

Após a identificação dos erros, é realizada a "limpeza" dos dados, a fim de resolver os problemas identificados.

Para tanto, são fundamentais a ajuda de um especialista no domínio da aplicação e a compreensão do uso que será feito do conhecimento adquirido.

Durante a etapa de transformação, os dados são modificados em função dos objetivos da aplicação do processo de DCBD e do formato requerido pela técnica de mineração de dados a ser utilizada.

Essa etapa é necessária, pois, em geral, as bases de dados não são criadas com objetivo de serem utilizadas para descoberta de conhecimento, o que as torna, em geral, inadequadas para o processo de DCBD.

Essa fase do processo é dividida em duas etapas.

A primeira visa à avaliação das técnicas de mineração de dados, a fim de verificar qual é a mais adequada para os objetivos da utilização do processo de DCBD.

Depois de selecionada a técnica, passa-se à etapa também denominada de mineração de dados, na qual algoritmos que implementam a técnica escolhida são aplicados sobre os dados pré-processados para identificar padrões interessantes existentes na base.

Nesse contexto, padrão é a expressão que descreve ou apresenta um subconjunto, formado por fatos.

E caracteriza-se por ser mais simples que a enumeração de todos os fatos.

A etapa de mineração de dados consiste na utilização de algoritmos de análise para identificar regras ou modelos estatísticos os quais representam conhecimento implícito em uma grande quantidade de dados.

Esse processo, geralmente, envolve aplicações interativas e iterativas de um método particular com o objetivo de produzir conhecimento novo de interesse do usuário.

Essa etapa do processo de DCBD visa única e exclusivamente encontrar padrões, cabendo às demais etapas garantir a qualidade e a utilidade do conhecimento adquirido.

O uso de técnicas de MD com o objetivo de substituir o trabalho do especialista traz como benefícios, geração de modelos com menor esforço manual, tornando o processo mais eficiente, a possibilidade de geração e avaliação de um número maior de modelos, aumentando a probabilidade de encontrar o melhor deles, e pode ser utilizada por analistas menos experientes, uma vez que algumas atividades são automatizadas.

Os objetivos de mais alto nível da mineração de dados são predição e descrição.

A predição baseia-se em um conjunto de variáveis conhecidas, as quais são usadas para prever valores futuros de outras variáveis de interesse, gerando modelos do tipo preditivo.

A descrição, por outro lado, visa encontrar padrões que descrevam os dados e sejam interpretáveis pelo ser humano, através da criação de modelos descritivos.

Para gerar os modelos, várias técnicas estão disponíveis, cada uma mais adequada à realização de uma tarefa específica.

Dentre as tarefas realizadas pela MD, destacam-se classificação, regressão, agrupamento e análise de associações.

No que se refere à etapa de seleção da técnica de mineração de dados, alguns fatores devem ser levados em consideração, dentre os quais destaca-se o objetivo do usuário.

Um aspecto determinante na escolha da técnica é a identificação da tarefa a ser realizada, sendo de fundamental importância que a técnica seja compatível e aplicável à sua realização.

Se o objetivo do usuário é prever o comportamento de seus clientes, por exemplo, não será útil aplicar técnicas cujos modelos gerados simplesmente descrevam os dados.

Outros fatores como o tipo de repositório a ser minerado e o formato de representação do conhecimento adquirido também devem ser levados em consideração durante a seleção da técnica de MD.

Na fase de mineração de dados, a etapa que demanda maior esforço consiste na seleção da técnica, uma vez que após essa escolha e a preparação dos dados, sua aplicação é trivial.

Vários fatores são levados em consideração durante a escolha da técnica de MD, destacando-se, tipo de modelo gerado, tipo de aprendizado (supervisionado/não-supervisionado em lote/incremental), tarefa a ser realizada, tipo de repositório a ser minerado, e formato de representação do conhecimento.

As próximas seções apresentam cada um dos aspectos acima relacionados, assim como a descrição de algumas técnicas estudadas com base nesses elementos.

Conforme citado anteriormente, a mineração de dados é aplicada para gerar regras ou modelos estatísticos os quais representam conhecimento implícito em uma grande quantidade de dados.

Os dois principais tipos de modelos gerados são o preditivo e o descritivo.

Um modelo preditivo é gerado a partir de um conjunto de variáveis conhecidas, utilizadas para prever valores futuros de outras variáveis de interesse.

Para obter um modelo preditivo é necessária a existência de um banco de dados contendo vários exemplos que disponibilizem, inclusive, o valor já apresentado no passado das variáveis a serem previstas.

De posse de um modelo desse tipo é possível responder a perguntas como "Es sa transação é fraudulenta " ou "Quanto esse cliente irá produzir de lucro ".

Modelos do tipo descritivo, por sua vez, descrevem os dados e devem ser interpretáveis pelo ser humano.

Esse tipo de modelo disponibiliza informações a respeito do relacionamento entre os dados como, por exemplo, "peso e idade, em conjunto, são os principais fatores de ocorrência da doença.

Um modelo puramente preditivo busca a acurácia, enquanto um puramente descritivo tem seu foco na compreensão da realidade.

A fase em que o modelo é construído é comumente chamada de aprendizado, podendo ser classificado segundo o grau de intervenção humana e quanto à forma de manipulação dos dados de entrada.

De acordo com o primeiro critério, grau de intervenção humana, o aprendizado é dito supervisionado ou não supervisionado.

Aprendizado supervisionado é baseado em exemplos e, geralmente, é utilizado por técnicas que realizam predição.

Nesse caso, os dados de entrada são previamente classificados por um especialista no domínio da aplicação e são utilizados como exemplos pelo algoritmo de MD.

O algoritmo "analisa" todos os exemplos de cada classe informada pelo especialista e procura um modelo que descreva esses dados de modo a classificar corretamente o maior número de casos possível.

O aprendizado não-supervisionado, por sua vez, é utilizado para descrição e busca identificar como os dados estão relacionados, quais itens são similares, quais são diferentes e de que forma.

Algoritmos cujo aprendizado é do tipo não-supervisionado agrupam padrões apresentados na entrada de acordo com a similaridade existente entre eles.

Nesse caso, nenhuma classe é predefinida, cabendo ao próprio algoritmo manipular os dados de modo a determiná-las.

No que se refere à estratégia de manipulação dos dados de entrada, o aprendizado pode ser em lote ou incremental.

Algoritmos de aprendizado em lote consideram todo o conjunto de dados de uma única vez.

A modificação do arquivo de entrada implica na necessidade de execução de todo o processo de DCBD novamente.

Algoritmos baseados em aprendizado incremental não desconsideram resultados de minerações anteriores quando o arquivo de entrada é modificado.

Para que a aplicação do processo de DCBD seja satisfatória e leve aos objetivos esperados, é imprescindível que o problema e o domínio da aplicação sejam muito bem conhecidos.

Apenas após a compreensão do problema, é possível verificar qual técnica de MD se aplica na sua solução.

Por isso, a identificação da tarefa a ser realizada é o principal aspecto considerado durante a escolha da técnica de MD.

Abaixo são descritas algumas das principais tarefas nas quais a MD se aplica.

Classificação consiste em aprender uma função que mapeia (classifica um item para uma dentre várias classes pré-definidas).

É uma das aplicações mais comuns da mineração de dados, sendo utilizada nas áreas de marketing, mercado financeiro, telecomunicações, seguros, medicina, entre outras.

Técnicas de classificação são baseadas em aprendizado supervisionado e geram modelos do tipo preditivo.

A acurácia do modelo é verificada na fase de testes, a partir do cálculo do percentual de casos do conjunto de dados de teste corretamente classificados pelo modelo gerado.

Durante esse processo, o resultado também é verificado a fim de detectar se o mesmo não está "condicionado", ou seja, específico para os dados usados no treinamento.

Exemplo típico dessa tarefa é a classificação de clientes que buscam concessão de crédito em baixo, médio ou alto risco.

Regressão é muito semelhante à classificação, sendo as duas diferenciadas pelo tipo de dado retornado como saída.

No caso da regressão, não são obtidos valores discretos, representando rótulos de classe, mas sim valores contínuos.

Por este motivo, técnicas desse tipo são utilizadas quando a saída da previsão encontra-se em um intervalo de valores e não é uma classe categórica.

Técnicas de regressão são utilizadas com vários objetivos, tais como estimar a probabilidade de sobrevivência de um paciente com base em testes de diagnóstico, prever a demanda por um novo produto como uma função dos gastos com propaganda ou prever a quantidade de biomassa existente em uma floresta a partir de medidas de microondas.

O arquivo de treinamento utilizado na regressão é semelhante ao da classificação.

No entanto, os exemplos estão associados a um valor numérico específico conhecido previamente.

O tipo de aprendizado é supervisionado e o modelo gerado é preditivo.

Assim como em algumas outras tarefas, o valor da predição é geralmente menos importante do que a estrutura da descrição aprendida, expressa em termos de como os atributos importantes estão relacionados para atingir o valor da saída.

Agrupamento, técnicas de agrupamento geram modelos descritivos que buscam agrupar objetos em classes de objetos similares.

Os dados de entrada são analisados de modo a identificar classes naturais (ou grupos), onde elementos pertencentes a uma mesma classe possuem grande similaridade entre si e elementos de classes diferentes são pouco semelhantes.

Cabe ao usuário determinar o significado de cada classe encontrada.

Técnicas que realizam essa tarefa normalmente não são baseadas em exemplos previamente rotulados, sendo caracterizadas, portanto, por utilizarem aprendizado do tipo não-supervisionado.

O sucesso do agrupamento é medido subjetivamente com base no quanto o resultado é útil ao usuário humano.

Exemplos de aplicação de agrupamento são a identificação de diferentes grupos de clientes de uma loja, a categorização de genes com funcionalidades similares ou a identificação de áreas cujo uso do solo é comum.

O resultado dos algoritmos de agrupamento é um diagrama que mostra a distribuição das instâncias pelos grupos.

A tarefa de agrupamento geralmente é realizada antes da utilização de outra técnica de MD ou modelagem, o que torna o agrupamento apenas um passo no sentido de descrever os dados.

Técnicas que realizam agrupamento são muito subjetivas, devido à necessidade de se definir medidas de distância.

Análise de Associações busca encontrar relacionamentos interessantes entre itens de um grande conjunto de dados de um domínio específico.

Os relacionamentos identificados representam padrões de comportamento e são descritos através de regras associativas (ou regras de associação).

Técnicas que realizam esse tipo de tarefa são baseadas em aprendizado não-supervisionado e são utilizadas tanto para descrição quanto para predição.

Esse tipo de análise é muito utilizado no problema da cesta de compras (market basket analysis), cujo objetivo é verificar os hábitos de consumo dos clientes de uma loja, através da verificação de quais grupos de produtos são normalmente adquiridos em uma visita ao estabelecimento.

Apesar de essa ser a aplicação mais famosa, essa tarefa também é utilizada em aplicações médicas para verificar, por exemplo, que a ocorrência de uma dada enfermidade está associada à ocorrência de outra.

Em tese, a mineração de dados pode ser aplicada sobre qualquer tipo de repositório de dados, mas os algoritmos e dificuldades de implementação, em geral, diferem de acordo com o tipo de repositório.

Os principais tipos de repositório utilizados para mineração são os bancos de dados relacionais, data warehouses (DW), bancos de dados transacionais, bancos de dados orientados a objetos, bancos de dados objeto-relacionais, bancos de dados geográficos, banco de dados temporais, banco de dados de texto, bancos de dados multimídia e a World Wide Web (WWW).

Os bancos de dados relacionais e transacionais e os data warehouses são os repositórios mais freqüentemente utilizados para MD.

A aplicação de MD sobre os demais tipos de repositório citados é considerada desafio na área.

A mineração de data warehouses é facilitada, pois durante a criação do DW algumas das atividades comuns à etapa de preparação de dados da DCBD já são realizadas.

A MD em bancos de dados orientado a objetos e em bancos de dados objeto-relacionais é muito semelhante.

No entanto, se comparada à mineração realizada sobre bancos de dados relacionais, novas técnicas devem ser desenvolvidas, a fim de lidar com os novos conceitos inerentes a esses repositórios.

Em bancos de dados geográficos podem ser aplicados algoritmos de MD com o objetivo de identificar padrões que levam em consideração a referência espacial das informações.

Por exemplo, descrição das características de casas localizadas próximo a parques ou praças.

Técnicas de MD são aplicadas sobre os dados armazenados em bancos de dados temporais, a fim de encontrar características referentes à evolução dos objetos ao longo do tempo ou padrões de mudanças de objetos.

No que se refere à mineração de dados na WWW, essa aplicação consiste em uma das mais pesquisadas atualmente, em virtude da grande quantidade de dados disponível na web e na crença de que existe uma enorme quantidade de conhecimento disperso pela rede.

Os padrões identificados por técnicas de MD podem ser representados em diversos formatos, os quais são classificados em caixa preta ou caixa transparente.

Os dois tipos de formato podem fazer boas predições, diferindo entre si pela forma de representação dos padrões.

Formatos do tipo caixa transparente representam os padrões em termos de uma estrutura que pode ser examinada, sobre a qual é possível raciocinar e que pode ser usada para guiar decisões futuras.

Os do tipo caixa preta, por sua vez, não apresentam a estrutura do padrão de modo explícito.

Independente do tipo, o formato de representação dos padrões está diretamente relacionado com a técnica utilizada.

A seguir são apresentados alguns formatos de representação de conhecimento, comumente utilizados.

É a forma mais rudimentar de representar o que foi aprendido pela máquina.

A sua interpretação é simples, mas a criação envolve a seleção dos atributos que devem ser apresentados.

Quanto menor o número de atributos, mais simples e legível é a tabela.

No entanto, essa escolha não é simples e consiste no ponto crítico da criação da mesma.

A um exemplo de uma tabela de decisão.

Sua interpretação é bastante direta, para verificar se a atividade "jogar" é realizada, é necessário apenas analisar as condições determinadas pelos demais atributos.

Exemplo de tabela de decisão.

Árvore de Decisão é uma estrutura de decisão baseada em árvore onde os nós correspondem a atributos a serem testados e as folhas são as classes do problema.

Os arcos apresentam os valores que os atributos podem assumir.

Em geral, cada teste em um nó compara um valor de atributo com uma constante.

Cada folha corresponde à classe de todas as instâncias que a atingem.

A classificação de novas instâncias se dá percorrendo a árvore de cima para baixo, de acordo com os valores dos atributos testados, até atingir uma folha.

Exemplo de árvore de decisão, representando as informações.

Exemplo de árvore de decisão.

Regras de Classificação são uma alternativa às árvores de decisão.

O antecedente consiste em uma série de testes e o conseqüente, indica a classe ou classes na(s) qual(is) as instâncias cobertas pela regra se enquadram.

Em geral, as pré-condições apresentadas no antecedente da regra devem ser todas satisfeitas para que a mesma se aplique.

A geração de regras de classificação a partir de árvores de decisão é direta.

Para cada folha da árvore é gerada uma regra.

O conseqüente da regra é a classe designada pela folha, enquanto seu antecedente inclui as condições (ligadas pelo conectivo lógico "e") de todos os nós entre a raiz da árvore e essa folha específica.

Exemplos de regras de classificação geradas a partir da árvore de decisão, Regras Associativas, Regras associativas são formadas por condições atributo-valor que ocorrem simultaneamente com bastante freqüência.

São muito semelhantes às regras de classificação.

No entanto, predizem o valor de qualquer atributo e não apenas o que corresponde à classe.

Isto é, os itens do conseqüente das regras associativas correspondem a qualquer atributo da tabela.

A mineração de regras de classificação não permite identificar, em um único processamento, as duas regras anteriormente apresentadas.

Para alterar a classe, torna-se necessário realizar a MD novamente.

A flexibilidade das regras associativas em relação às regras de classificação implica em que, para o mesmo conjunto de dados, seja gerado um número muito maior de regras associativas do que de regras de classificação.

Sendo assim, para limitar a quantidade de regras encontradas, são consideradas apenas aquelas aplicáveis sobre um número significativo de instâncias e que possuem grande acurácia.

Medidas objetivas são definidas para avaliar essas características.

São elas, o suporte e a confiança.

O suporte de uma regra corresponde ao percentual de transações apresentadas na entrada que contém todos os itens apresentados tanto no conseqüente quanto no antecedente da mesma.

A confiança da regra é a relação entre o número de transações que contém todos os seus itens e o número de transações que contém, pelo menos, os itens do seu antecedente.

Apenas são apresentadas no resultado regras com valores de suporte e confiança maiores do que os mínimos especificados pelo usuário.

Regras associativas que apresentam mais de um atributo no conseqüente devem ser interpretadas com cuidado.

O suporte das três regras é o mesmo, pois é calculado com base em todos os atributos.

No entanto, não se pode afirmar que a confiança das duas últimas regras apresentadas é a mesma da primeira, pois tanto o conseqüente quanto o antecedente das regras são diferentes entre si.

Com base na primeira regra, é possível afirmar que a regra também se aplica e o valor de sua confiança é, com certeza, igual ou superior ao da primeira.

Centróide, O centróide geralmente é criado por técnicas de agrupamento, podendo ser alterado e refinado durante a formação dos grupos ou na inclusão de novos elementos.

O centróide é uma média das características dos elementos do grupo, utilizado para representar todos os objetos do grupo.

Por esse motivo, ele não é capaz de representar fielmente todas as características do grupo, nem cada elemento individualmente.

Em geral, ele é representado por um vetor de valores.

Várias são as técnicas de MD disponíveis para serem aplicadas nas diversas tarefas anteriormente citadas.

Algumas das técnicas estudadas no decorrer deste trabalho são discutidas a seguir.

Técnicas de indução de árvore de decisão são utilizadas para construir árvores de decisão a partir de uma base de dados de treinamento.

O processo de construção da árvore é guiado heuristicamente pela escolha do atributo mais significativo a cada passo.

A seleção do atributo busca sempre minimizar a profundidade da árvore e, conseqüentemente, a quantidade de testes necessários para obter o resultado da classificação.

O método de construção da árvore e o resultado final dependem diretamente da escolha do algoritmo de indução.

Vários algoritmos estão disponíveis para a indução de árvores de decisão.

Um dos primeiros e mais conhecidos é o ID3.

Após ele, surgiram ainda o CART, o CHAID e o C45.

A aplicação desses algoritmos gera modelos do tipo preditivo.

Apesar de também realizar análise de associações, técnicas de indução de árvores de decisão são tipicamente utilizadas para classificação.

O conhecimento adquirido pela aplicação da técnica é representado em forma de árvore de decisão, a partir da qual são geradas regras de classificação.

A técnica de identificação de regras associativas, por sua vez, tem como objetivo descrever relacionamentos freqüentes entre os dados.

O arquivo de entrada do algoritmo consiste em um conjunto de transações contendo, cada uma, uma relação de itens.

A partir desses dados, busca-se identificar a relação de dependência existente entre um item (ou conjunto de itens) e outro.

Técnicas de identificação de regras associativas geram modelos descritivos e preditivos.

O resultado da aplicação da técnica consiste em um conjunto de regras associativas, as quais apresentam a maneira pela qual os dados estão relacionados.

Outra característica dessa técnica consiste em que ela utiliza aprendizado do tipo não-supervisionado.

O outro tipo de técnica estudada, as redes neurais artificiais (RN, ou simplesmente redes neurais (RN), são resultado de uma metáfora computacional para o funcionamento do cérebro humano.

Elas surgiram em 1943, e foi a primeira tentativa de simular, no computador, o comportamento do neurônio biológico.

Outros modelos surgiram posteriormente, no entanto, por serem limitados no que diz respeito à capacidade de aprendizado e só conseguirem resolver problemas linearmente separáveis, as pesquisas na área foram desaceleradas.

Um novo impulso só foi dado em meados da década de 80, quando foi apresentada a solução para as limitações detectadas.

A partir de então, as RNA tornaram-se uma tecnologia largamente utilizada para resolver problemas tanto de classificação quanto de agrupamento, de modo que uma série de arquiteturas foram propostas para esses fins.

Nesse contexto, foram estudados o algoritmo backpropagation e o Modelo Neural Combinatório (CNM Combinatorial Neural Model).

O algoritmo backpropagation é utilizado para atualizar os pesos da rede Multilayer Perceptron (MLP), bastante aplicada na tarefa de classificação.

O backpropagation utiliza vetores de exemplo associados a rótulos de classe para modificar os pesos.

Cada um dos vetores de exemplo é apresentado na entrada da rede e a saída resultante é comparada com o rótulo de classe associado ao vetor.

A diferença entre o valor encontrado pela rede e a saída desejada é utilizada para atualizar os pesos.

O conhecimento da rede está distribuído pelos pesos, por isso diz-se que a representação é do tipo caixa preta.

O modelo neural combinatório é uma rede neural que utiliza o conceito de predicado, a fim de tratar informações categóricas.

O CNM possui uma arquitetura conectada adiante com três ou mais camadas e visa encontrar regras de produção que associem evidências de entrada a hipóteses de saída.

Os neurônios da camada de entrada correspondem aos predicados e representam as evidências do domínio da aplicação.

As camadas intermediárias são chamadas combinatórias porque representam as diferentes combinações dos dados de entrada.

A camada de saída contém neurônios os quais representam as diferentes hipóteses (classes) do domínio do problema.

O CNM gera modelos do tipo preditivo e pode ser aplicado tanto para classificação quanto para análise de associações.

Assim como outras técnicas que realizam classificação, o aprendizado é do tipo supervisionado e o conhecimento é representado através de regras de classificação.

A técnica näive-bayes tem por objetivo identificar relacionamentos entre variáveis, a fim de gerar um modelo de classificação.

A técnica baseia-se no teorema de Bayes para calcular as probabilidades de uma nova ocorrência pertencer a cada uma das classes.

A aplicação dessa técnica implica em que todas as variáveis utilizadas sejam estatisticamente independentes entre si, o que nem sempre é real.

No entanto, segundo, mesmo com esse problema, a técnica produz bons resultados na identificação de relacionamentos simples.

A näive-bayes caracteriza-se por gerar modelos preditivos, voltados, principalmente, para a classificação.

O resultado gerado é representado por regras de classificação e o tipo de aprendizado da técnica é supervisionado.

K-médias é uma das técnicas de clustering mais conhecidas, sendo empregada para identificar agrupamentos em dados do tipo numérico (valores contínuos).

Essa técnica é baseada em centróide, o qual representa o valor médio dos objetos de cada grupo.

A técnica é implementada de modo que primeiramente é realizada a seleção aleatória de k objetos do arquivo de entrada, cada um representando o centro de um agrupamento.

Para cada grupo, são designados os objetos mais similares com base na distância entre os objetos e o centro do grupo.

Em seguida, uma nova média é computada para cada grupo e o processo é executado recursivamente.

O algoritmo de agrupamento demográfico também é utilizado para encontrar agrupamentos.

No entanto, diferentemente do k-média, ele é aplicado sobre dados categóricos.

Os agrupamentos são criados a partir da comparação de cada objeto com todos os agrupamentos criados.

O algoritmo utiliza voto simples para medir a distância entre os objetos e designá-los ao agrupamento específico.

Uma vantagem do agrupamento demográfico em relação ao k-médias consiste em que o primeiro possui habilidade para determinar automaticamente o número de grupos a serem gerados.

A presenta as técnicas estudadas e suas características de acordo com os critérios utilizados.

Comparação de técnicas de MD.

Nesta fase do processo de DCBD, os padrões identificados durante a MD são avaliados quanto à sua utilidade.

Um sistema de MD é capaz de gerar centenas ou até milhares de padrões ou regras, dos quais apenas uma pequena fração é realmente de interesse.

Por esse motivo, na etapa de pós-processamento os padrões ou regras identificados são interpretados e compreendidos, a fim de verificar quais são realmente úteis.

São considerados de interesse padrões que validam uma hipótese que o usuário deseja confirmar, são facilmente compreendidos por humanos, são válidos para novos dados com algum grau de certeza, são potencialmente úteis e são novos.

Nessa etapa do processo também é verificado se os padrões detectados são genéricos o suficiente ou se são válidos apenas para a base de dados utilizada na mineração.

Além disso, é avaliado se os padrões são válidos para os objetivos da aplicação e se apresentam informação útil e nova.

A fim de verificar o quão interessante é cada regra ou padrão identificado, são utilizadas medidas objetivas, as quais são geralmente baseadas na estrutura dos padrões e em estatísticas a ela inerentes.

Em geral, essas medidas são verificadas pelos próprios algoritmos de MD e cada uma está associada a um valor mínimo definido pelo usuário.

Todavia, medidas objetivas, isoladamente, são insuficientes para identificar padrões interessantes, sendo necessário que sejam combinadas com medidas subjetivas, as quais refletem as necessidades e interesses particulares do usuário.

Medidas subjetivas são baseadas no conhecimento do especialista a respeito do domínio da aplicação e no quê o usuário espera obter a partir dos dados.

Alguns padrões considerados interessantes com base em medidas objetivas podem ser descartados pelo especialista.

Além da validação dos padrões identificados, nessa etapa do processo de DCBD as regras e modelos extraídos podem ser traduzidos para uma linguagem inteligível pelo usuário, caso não sejam diretamente aplicáveis aos objetivos do mesmo.

Após a apresentação de uma visão geral do processo de DCBD de modo genérico, os próximos dois capítulos tratam a aplicação do processo na identificação de padrões de análise.

Para tanto, são verificadas características específicas da aplicação, as quais devem ser levadas em consideração durante cada uma das fases do processo.

A identificação de padrões para reuso requer o conhecimento de vários projetos e envolve a localização de uma solução eficiente, utilizada para resolver um problema recorrente.

Os detalhes específicos da aplicação são abstraídos da solução reutilizada nos vários projetos.

Essa construção resultante do processo de abstração é aplicada a novos projetos e testada, para, posteriormente, ser considerada um padrão.

Durante esse processo, com o objetivo de diminuir a interferência do especialista, acredita-se que a DCBD possa ser utilizada para auxiliar na localização de soluções recorrentes através da análise automatizada de esquemas conceituais de BDG.

Dessa forma, pode ser considerado um número muito maior de esquemas em relação ao que vem sendo realizado pelos métodos atualmente conhecidos, possibilitando a análise conjunta de esquemas criados por diferentes especialistas.

Essa característica, por conseqüência, potencializa a identificação de padrões baseados na experiência de um número maior de especialistas se comparados aos padrões que vêm sendo atualmente propostos.

Utilizar apenas esquemas conceituais de BDG como base de conhecimento para identificar padrões de análise, todavia, não possibilita a verificação de todos os elementos necessários à descrição de padrões, ainda que sejam consideradas as formas de descrição mais simples.

Conforme visto na seção 22, a descrição de um padrão requer, no mínimo, a definição de um problema ou contexto e, posteriormente, a explicação de como tal problema pode ser resolvido.

Sendo assim, a aplicação do processo de DCBD visa apontar soluções reutilizadas que, posteriormente analisadas por especialistas, podem ser eleitas padrões.

Assim como ocorre tradicionalmente, um especialista no domínio da aplicação deve validar as construções freqüentes encontradas a partir do processo de DCBD, a fim de que estas sejam ou não eleitas padrões de análise.

A essas construções freqüentes, ainda não validadas, convencionou-se chamar de candidatos a padrão de análise.

A fim de que o processo de DCBD seja aplicado na identificação de candidatos a padrão de análise, as atividades previstas para serem desenvolvidas no seu decorrer devem levar em consideração as peculiaridades inerentes a essa aplicação.

Não faz parte do escopo desse trabalho explorar, em detalhes, todas as atividades do processo, algumas das quais são apresentadas.

A ênfase do trabalho corresponde às atividades mostradas.

Processo de DCBD para identificar candidatos a padrão de análise de BDG.

A escolha da técnica de MD a ser empregada durante o processo deve anteceder a preparação dos dados, pois seu conhecimento prévio é necessário à realização de algumas atividades dessa outra fase.

Por exemplo, algumas técnicas de MD não manipulam valores contínuos, sendo necessário a sua discretização.

No caso da mineração de esquemas de BDG, como eles não estão armazenados em um formato compatível com nenhuma das técnicas pesquisadas, o conhecimento prévio da técnica a ser aplicada permite o direcionamento desse armazenamento de modo a tirar maior proveito da aplicação da MD.

O primeiro passo para a aplicação do processo de DCBD na identificação de candidatos a padrão de análise para BDG foi a escolha da técnica de MD a ser utilizada.

Essa decisão foi tomada com base nos critérios apresentados na seção 321, os quais são analisados a seguir com base nas necessidades da aplicação.

Tipo de Modelo, a aplicação requer a geração de um modelo do tipo descritivo, pois visa à compreensão dos dados e não à previsão.

Tipo de aprendizado, o objetivo da utilização do processo de DCBD na identificação de candidatos a padrão de análise consiste em diminuir a interferência do ser humano no processo.

Desse modo, devem ser aplicadas técnicas cuja dependência do especialista seja a menor possível.

Tal requisito é atendido por técnicas que utilizem aprendizado do tipo não-supervisionado.

No que se refere ao volume de dados, não é possível mensurar a quantidade de esquemas de BDG que estarão disponíveis para mineração.

Além disso, novos esquemas devem ser considerados e esquemas antigos podem ser atualizados.

Nesse contexto, uma técnica capaz de manipular os dados de entrada de forma incremental mostra-se mais adequada.

Tarefa a ser realizada, acredita-se que a identificação de subesquemas recorrentes pode ser realizada a partir da identificação de associações freqüentes entre elementos de modelagem de esquema.

Por exemplo, se é possível identificar que o relacionamento de continência entre um Pacote P e uma classe C ocorre frequentemente, dado um determinado conjunto de esquemas de BDG, então o subesquema formado pela classe juntamente com o pacote pode ser considerado recorrente no conjunto considerado.

Esse tipo de análise vem sendo realizado em outros domínios a partir da aplicação de técnicas de MD que realizam a tarefa de análise de associações.

Tipo de repositório a ser minerado, apesar de consistir em um aspecto importante a ser avaliado durante a seleção da técnica de MD, essa característica não foi determinante no desenvolvimento deste trabalho, pois os esquemas de BDG não estão disponíveis em nenhum dos formatos atualmente aceitos por ferramentas de MD.

Por outro lado, com base na técnica a ser aplicada, foi possível elaborar as estratégias de organização e armazenamento dos esquemas de BDG de modo a facilitar a MD.

Formato de representação do conhecimento, para a identificação de candidatos a padrão de análise, o resultado da MD deve ser facilmente compreendido e é imprescindível que seja capaz de descrever padrões.

Assim, é desejável que o formato de representação dos padrões seja do tipo caixa transparente.

O estudo das técnicas com base nos critérios acima descritos permite crer que a identificação de regras associativas, dentre as técnicas estudadas, é a que melhor se aplica na solução do problema de identificar padrões de análise para BDG a partir de esquemas conceituais.

As principais características da técnica que levam a essa conclusão são que a técnica é baseada em aprendizado não-supervisionado, dispensando, portanto, a classificação prévia dos dados de entrada e a interferência do especialista nessa atividade.

As regras associativas são facilmente compreendidas pelo ser humano (com sintaxe e semântica simplificadas), além de serem utilizadas para representar associações empíricas.

Tais características as tornam uma linguagem apropriada para a descrição de padrões.

Existem algoritmos que manipulam os dados de entrada de forma incremental, ou seja, a inclusão de novos esquemas não implica na perda dos resultados já obtidos por minerações anteriores.

Pode-se garantir a completude da mineração através do uso de medidas de interesse, e a tarefa realizada pela técnica, dentre as estudadas, é a mais adequada à solução do problema proposto.

A seção seguinte apresenta a técnica de identificação de regras associativas em detalhe.

A técnica de identificação de regras associativas utiliza como dados de entrada um conjunto de transações, cada uma composta por um identificador e um conjunto de itens pertencentes ao domínio da aplicação.

Dependendo da aplicação, os itens podem representar, por exemplo, produtos comprados em uma loja ou doenças apresentadas por um paciente.

A partir desses dados, o algoritmo identifica a relação entre os itens.

Por exemplo, no caso de produtos, poder-se-ia estar buscando aqueles que são comprados juntos.

Já no caso das doenças, a busca poderia ser por aquelas de ocorrência simultânea.

No que se refere à organização dos dados, as transações podem ser dispostas de forma horizontal ou vertical.

Na organização horizontal, cada transação corresponde a uma linha do arquivo e existe uma coluna para cada item distinto.

A organização vertical, por sua vez, dispõe cada item de transação em uma linha própria.

O arquivo é composto por duas colunas, uma usada para identificar a transação e outra para discriminar o item.

Nesse caso, a estrutura do arquivo (número de colunas) não é modificada quando um novo item é considerado.

Por outro lado, uma mesma transação ocupa mais de uma linha e só pode ser recuperada através de seu identificador.

Exemplo de tabela com organizada horizontalmente.

As ferramentas que implementam a técnica de identificação de regras associativas, em geral, trabalham com as duas formas de organização.

As relações identificadas entre os itens de transação são expressas em forma de regras associativas, formadas por itens do arquivo de entrada.

O conseqüente das regras é um conjunto unitário ou um conjunto com elementos.

À cada regra identificada estão associados o suporte e a confiança.

As regras associativas são classificadas em vários tipos, segundo diferentes critérios.

Exemplo de tabela com organizada verticalmente.

Quanto aos tipos de valores presentes nas regras, elas são ditas quantitativas ou booleanas.

As primeiras descrevem associações entre itens que apresentam valores quantitativos, os quais são particionados em intervalos.

Regras booleanas, por sua vez, indicam a presença ou ausência de itens.

A regra R1 apresentada abaixo é um exemplo de regra quantitativa enquanto Ré uma regra booleana.

No que se refere à dimensão dos dados, as regras são classificadas em uni ou multidimensionais.

Regras unidimensionais referem-se a uma única dimensão, como em R2, onde a dimensão é o atributo compra.

Regras multidimensionais, como R1, referem-se a duas ou mais dimensões, nesse exemplo, os atributos idade, renda e compra.

Foi proposta a identificação de regras associativas baseadas em taxonomias, sendo possível encontrar regras em diferentes níveis de abstração.

Por exemplo, " computador impressora" e " laptop zipdrive", laptop é uma especialização de computador e encontra-se em um nível de abstração mais baixo.

Tais regras são importantes, pois, em alguns casos, as regras definidas em mais baixo nível de abstração não atingem os valores de suporte e/ou confiança mínimos, mas a regra mais genérica sim.

Outro tipo de regra bastante interessante são as regras associativas negativas.

Regras desse tipo, ao contrário das convencionais, especificam quais itens não ocorrem em conjunto com outros.

Assim, elas disponibilizam, por exemplo, informações do tipo "consumidores de cerveja não compram refrigerante".

Nesse trabalho foi utilizado o tipo mais simples de regra associativa que é a booleana unidimensional, pois seu poder de expressão é suficiente para a descrição de padrões de análise.

Para identificar esse tipo de regra, Agrawal decompôs o problema em duas grandes fases, geração de todas as combinações de itens que possuem suporte acima do limite especificado.

Tais combinações são chamadas de large itemsets.

Para um dado large itemset, geração de todas as regras que usem itens do conjunto e cálculo do valor de sua confiança.

A etapa com maior custo computacional refere-se à geração dos conjuntos de itens freqüentes.

Uma característica bastante importante para a qual Agrawal chama a atenção, nessa atividade, é que se é um large itemset, então todos os seus subconjuntos não-vazios também o são (propriedade Apriori).

O suporte e a confiança são utilizados para fazer o ranking das regras geradas, sendo consideradas mais "fortes" aquelas com maior suporte e confiança.

Os princípios expostos acima são a base do algoritmo apriori, bastante utilizado na obtenção de regras associativas booleanas.

Posteriormente à sua publicação, vários outros algoritmos foram propostos com o objetivo de melhorar a performance do apriori e/ou gerar regras menos redundantes entre si.

O próprio algoritmo apriori, todavia, pode ser aplicado na identificação de padrões de análise para BDG.

Nesse caso, o suporte da regra corresponde ao suporte do padrão por ela identificado, ou seja, ao percentual de ocorrência do padrão nos esquemas analisados.

Sendo assim, o suporte mínimo especificado pelo usuário deve corresponder ao percentual mínimo em que uma construção deve estar presente nos esquemas analisados para que seja considerada um padrão.

As construções pouco freqüentes (com valor de suporte inferior ao mínimo especificado) são eliminadas na fase de MD.

Embora bastante utilizada nas aplicações convencionais da técnica de identificação de regras associativas, a confiança não se mostra tão importante no contexto da identificação de candidatos a padrão de análise.

Esse fato ocorre, pois, a confiança é uma medida utilizada para verificar o número de instâncias preditas corretamente pela regra e a tarefa de identificar padrões de análise não envolve predição.

Além disso, a definição de padrão indica que uma construção pode ser classificada como tal se ela é bastante utilizada.

Nesse contexto, não é relevante o fato de elementos dessa construção terem sido aplicados em alguns projetos de modo diferente do indicado pelo padrão.

Por exemplo, se o esquema é freqüentemente reutilizado é irrelevante o fato de que a classe "Lago" e o pacote "Hidrografia" tenham sido definidos separadamente em alguns dos esquemas analisados.

Exemplo de padrão de análise Uma vez que a confiança não é um parâmetro utilizado durante a identificação de padrões de análise, o valor mínimo especificado no algoritmo deve corresponder ao valor mínimo especificado para o suporte.

Dessa forma, nenhuma regra é eliminada por não obter a confiança mínima.

No contexto deste trabalho, algumas atividades da etapa de preparação de dados são tidas como já realizadas.

Não obstante, uma visão geral das atividades mais importantes dessa fase do processo é apresentada a seguir.

Nas próximas seções, são tratados com maior cuidado alguns aspectos específicos da aplicação, os quais foram estudados por serem considerados parte fundamental na verificação da adequação da técnica escolhida à aplicação em questão.

A seleção dos esquemas a serem minerados é a primeira atividade desta etapa e deve ser baseada em critérios específicos, a fim de que padrões não sejam desprezados devido a bases de conhecimento mal projetadas.

Misturar esquemas de áreas de aplicações distintas pode acarretar a não identificação de padrões de áreas cuja amostragem é pequena.

Por outro lado, escalonar a mineração de acordo com uma área de aplicação específica pode impossibilitar a verificação de padrões formados por construções pertencentes a áreas de aplicação distintas.

Por exemplo, considere uma base composta de 100 esquemas, onde 70 deles abordam aspectos referentes à hidrologia e 30 referem-se a sistema viário.

Se o suporte mínimo para que uma estrutura seja aceita como candidata a padrão é de 50%, então nenhum subesquema utilizado na modelagem de sistema viário será classificado como tal, ainda que seja recorrente na maioria dos esquemas que descrevem esse aspecto da realidade.

Por outro lado, se os esquemas das duas áreas de aplicação forem minerados isoladamente, não será possível identificar subesquemas formados por entidades de áreas distintas relacionadas entre si, como ruas e rios, por exemplo.

No que se refere ao pré-processamento e à limpeza de dados, um importante aspecto a ser observado consiste na verificação de nomes.

Casos de sinônimos, antônimos e parônimos devem ser resolvidos, proporcionando a unificação de termos, para que candidatos a padrão sejam corretamente identificados.

No caso particular de esquemas conceituais de BDG, também se deve observar que os esquemas considerados podem ter sido criados com base em diferentes modelos de dados.

Nesse caso, não é possível minerá-los em conjunto.

Esse problema vem sendo tratado em, onde é proposta a criação de um conjunto união de conceitos, formado pelos construtores dos principais modelos de dados geográficos e cujo objetivo é unificar os esquemas quanto ao modelo de dados.

Também na fase de preparação de dados, os seguintes problemas devem ser tratados, a decomposição de esquemas em subesquemas menores, com maior probabilidade de serem considerados candidatos a padrão, e a organização dos subesquemas em um formato compatível com aquele utilizado pela técnica de MD escolhida.

Abaixo serão abordadas, em detalhe, as estratégias de decomposição de esquemas e a organização dos dados, uma vez que são atividades essenciais para que seja possível verificar a adequação da técnica de mineração à aplicação.

Para identificar candidatos a padrão de análise para BDG, através da técnica de identificação de regras associativas, esquemas conceituais de BDG são definidos como transações no arquivo de entrada.

Cada esquema conceitual é, recursivamente, decomposto em subesquemas, pois quanto menor o número de elementos que formam um subesquema, maior a chance dessa estrutura se repetir em esquemas de aplicações distintas.

Cada subesquema resultante da decomposição corresponde a um item de transação no arquivo de entrada.

O processo de decomposição deve levar em consideração as regras de definição e de uso dos construtores do modelo de dados geográficos.

Para facilitar a compreensão, os construtores dos modelos foram classificados em fortes e fracos.

Construtores fortes são aqueles que, isoladamente, constituem um subesquema válido (que obedece as regras definidas no modelo de dados), como pacote e classe na UML, por exemplo.

Construtores fracos, por sua vez, não existem sozinhos no esquema, ou seja, individualmente não formam subesquemas válidos.

Sua definição dependente do seu relacionamento com um construtor forte, como ocorre, por exemplo, com atributos e associações.

Desse modo, para ser considerado válido, um subesquema que contém uma instância de construtor fraco deve apresentar também a instância do construtor forte do qual a instância do construtor fraco depende.

Ainda que consideradas as regras de modelagem impostas pelos modelos de dados, o processo de decomposição gera um grande número de tipos de subesquema, sendo que nem todos são utilizados durante a mineração de dados.

A definição dos tipos a serem considerados depende, basicamente, de três fatores, os construtores que formam os tipos de padrão a serem identificados, a granularidade dos padrões buscados, e a expressividade do formato de representação do conhecimento.

O primeiro aspecto guia a seleção dos subesquemas no sentido de desconsiderar aqueles que apresentam construtor não utilizado pelos tipos de padrão buscados.

No escopo desse trabalho, é utilizado o subconjunto dos construtores do UML-GeoFrame formado por pacote, classe, atributo definido em classe e associação binária simples.

Esse subconjunto foi selecionado, pois se entende que ele compreende os construtores genéricos da orientação a objetos, utilizados na maioria, se não na totalidade, dos modelos de dados para BDG.

Os subesquemas são, ainda, caracterizados pelo fato de, atributos serem considerados apenas com nome, independente do domínio, associações binárias serem representadas sem cardinalidade, e a representação espacial dos objetos geográficos ser tratada como um atributo da classe.

Os tipos de padrão que se deseja identificar são definidos em diferentes níveis de granularidade, pois visam a auxiliar projetos baseados tanto na abordagem bottom-up, quanto na top-down.

Sendo assim, os padrões podem ser formados por um ou vários elementos.

No primeiro caso, são constituídos de uma instância de classe ou de pacote.

Padrões formados por dois ou mais elementos os apresentam relacionados entre si através de associação binária entre classes, relação de continência entre pacote e classe ou relação de dependência entre atributo e classe.

A granularidade dos padrões e a expressividade do formato de saída determinam os subesquemas a serem considerados de acordo com o grau de desagregação dos elementos que os formam.

Um padrão é tanto mais simples quanto menor for o número de elementos que o compõem.

A medida em que aumenta a variação de granularidade entre o tipo de padrão mais simples e o mais complexo, maior é a quantidade de tipos de subesquema a serem processados.

Por outro lado, quanto maior a expressividade do formato de representação do conhecimento, menor esse número.

As regras associativas permitem expressar associações empíricas entre os itens de transação.

Além disso, por possuírem um grande poder de expressão, para identificar os tipos de padrão buscados é suficiente considerar apenas alguns subesquemas formados por um, dois ou três elementos.

Subesquemas não considerados nessa fase, assim como aqueles mais complexos, podem ser inferidos com base nas relações entre essas estruturas mais simples.

Tais relações são identificadas durante a MD e expressas através das regras geradas, de modo que o conjunto dos tipos de subesquema considerado após a decomposição é o mínimo suficiente e necessário o qual permite identificar todos os tipos de padrão buscados.

Analisados os aspectos importantes referentes à decomposição de esquemas, segue a descrição de cada tipo de subesquema utilizado.

Tais tipos são denominados de acordo com os construtores que utilizam e com o número de instâncias de cada construtor.

Os subesquemas estão separados em grupos definidos de acordo com o número de elementos que os formam.

Tipos de subesquemas com um elemento, Pacote(1), apresenta apenas uma instância do construtor pacote, representado independente da(s) classe(s) nele definida(s).

Cada elemento pacote presente no esquema gera um subesquema desse tipo.

Classe(1), apresenta uma instância de classe, representada independente do pacote onde está inserida ou dos atributos e associações que a caracterizam.

É criado um subesquema desse tipo para cada elemento classe presente no esquema.

Tipos de subesquemas com dois elementos, Atributo(1)-Classe, apresenta os elementos atributo existentes no esquema.

Como esse construtor é do tipo fraco e, no caso deste trabalho, está sempre associado a uma classe, ele é especificado juntamente com a classe onde foi definido.

Cada elemento atributo presente no esquema origina um subesquema desse tipo.

São considerados apenas os subesquemas formados por classe e um único atributo.

Subesquemas compostos por classe com mais de um atributo não são considerados para efeito de MD, mas podem ser inferidos a partir da interpretação das regras na etapa de pós-processamento.

Classe(1)-Pacote, apresenta uma instância de classe, juntamente com o pacote no qual ela está contida.

Esse tipo de subesquema possibilita a identificação de padrões formados por classes contidas em pacote.

Cada classe definida dentro de um pacote gera um subesquema desse tipo.

Subesquemas constituídos por várias classes pertencentes a um mesmo pacote não são considerados nessa fase, sendo obtidos, aposteriori, através da interpretação das regras.

Tipos de subesquemas com três elementos, Associação, apresenta as associações binárias.

Como esse é um construtor fraco, uma associação é sempre definida juntamente com as classes que a forma.

Cada associação binária do esquema gera um subesquema desse tipo.

Auto-relacionamentos do tipo associação binária fazem parte deste grupo.

Atributo(1)-Classe-Pacote, apresenta um elemento atributo, agregando a informação do pacote que contém a classe onde esse atributo foi definido.

Existe um subesquema desse tipo para cada atributo definido em classe contida em pacote.

Assim como no tipo Atributo(1)-Classe, apenas são considerados os subesquemas formados por um único atributo.

Esse tipo de subesquema é utilizado para identificar tanto os atributos das classes quanto o pacote no qual cada uma delas está definida.

A presenta os subesquemas gerados com base no esquema.

Exemplo de esquema conceitual, baseado no UML-GeoFrame.

Subesquemas considerados após a decomposição do esquema.

Usualmente, os algoritmos que implementam a técnica de identificação de regras associativas acessam os dados de entrada em arquivos planos ou tabelas.

O formato tabular dos bancos de dados relacionais mostra-se ineficiente, pois as regras associativas geralmente são utilizadas em situações onde o domínio dos atributos é binário (o atributo está presente ou não) e apenas uma minoria dos atributos está presente em cada transação.

Em função dessas características e do fato de que é irrelevante, para o objetivo deste trabalho, armazenar os esquemas de maneira eficiente para serem consultados no futuro, decidiu-se por armazenar os esquemas de BDG em um arquivo plano (flat file) para fins de mineração.

Cada esquema é armazenado nesse arquivo como uma seqüência de registros.

O arquivo é formado por vários esquemas, cada um correspondendo a uma transação.

Cada transação é composta por um ou mais itens de transação e por uma "marca de esquema".

Os itens de transação consistem em subesquemas resultantes da decomposição do esquema original.

A "marca de esquema" é utilizada para facilitar a interpretação das regras, no sentido de identificar padrões formados por um único elemento, conforme detalhado na seção 51.

O formato do arquivo, com base no formalismo EBNF, é mostrado a seguir.

No que se refere à organização dos dados para o caso específico da mineração de esquemas de BDG, sugere-se que a organização vertical seja adotada em virtude de sua flexibilidade e da grande quantidade de itens gerados após a decomposição de esquemas.

Outra preocupação quando se trata de organizar e armazenar esquemas de BDG para serem minerados, consiste em garantir a semântica de cada elemento, de modo a preservar suas características no decorrer do processo.

Deve ser possível, ao obter o resultado da mineração, identificar o tipo de cada elemento.

Para isso, os dados de entrada são descritos segundo notação própria, a qual é mostrada a seguir, com base na EBNF, Um exemplo de esquema, no formato do arquivo de entrada para mineração, com base no subesquema.

Armazenamento do esquema.

Uma vez que o nome da associação não foi definido no esquema, é representada apenas a sua ocorrência.

Após terem sido armazenados no formato proposto, os esquemas de BDG são submetidos a uma ferramenta de MD que gera regras associativas, tal como o IBM Intelligent Miner for Data.

O resultado da mineração, por sua vez, consiste em um conjunto de regras associativas, tais como R5, por exemplo, formadas pelos subesquemas apresentados no arquivo de entrada.

Essas regras são, então, pós-processadas de acordo com os critérios apresentados no próximo capítulo.

Na etapa de pós-processamento, as regras identificadas durante a mineração de dados são interpretadas e avaliadas quanto à sua relevância para o domínio da aplicação.

Para tanto, é de fundamental importância o auxílio de um especialista que examine, manualmente, as regras associativas geradas, verificando quais são realmente significativas.

Um problema inerente ao processo de mineração consiste em que os algoritmos que implementam a técnica de identificação de regras associativas tendem a encontrar um número excessivo de regras, tornando a avaliação do resultado quase tão trabalhosa quanto a própria mineração dos dados.

No que diz respeito à aplicação específica de identificar candidatos a padrão de análise para BDG, verificou-se que este problema é ainda maior.

Isso ocorre, porque cada padrão formado por mais de um elemento apresenta, implicitamente, outros padrões de granularidades menores, identificáveis a partir da decomposição do padrão inicial.

Devido a essa característica, além de serem geradas regras que levam à identificação do padrão mais complexo, também são geradas aquelas que permitem inferir todos os seus subesquemas válidos, os quais são tão ou mais freqüentes do que o padrão mais complexo.

Exemplo de padrão formado por mais de um elemento.

Alguns padrões implícitos no padrão.

Outra característica própria da aplicação e que contribui para a geração de regras desnecessárias consiste na repetição de elementos nos vários tipos de subesquemas considerados.

Tal problema ocorre, por exemplo, entre subesquemas dos tipos Classe(1) e Atributo(1)-Classe.

Sempre que um subesquema do tipo Atributo(1)-Classe estiver presente em uma regra, existirá pelo menos uma outra regra formada por ele juntamente com o subesquema do tipo Classe(1) que representa a instância da classe em questão.

Desse modo, quanto maior o número de tipos de subesquemas contidos em outros, maior o número de regras identificadas durante a MD.

Optar pelos subesquemas mais complexos ou pelos mais simples como alternativa para resolver o problema não é viável, pois se algum desses tipos de subesquemas não é considerado, não é possível a identificação de alguns tipos de padrão buscados.

Dentre os tipos de subesquema considerados, aqueles que contêm outros são indicados a seguir.

Classe(1)-Pacote, esse tipo de subesquema contém os tipos Classe(1) e Pacote(1), os quais são essenciais na identificação de padrões formados por um único elemento, não podendo ser descartados.

Se não forem utilizados subesquemas do tipo Classe(1)-Pacote, não é possível afirmar se a(s) classe(s) que compõe(m) o padrão está(ão) descrita(s) em um pacote.

A partir de regras que combinam subesquemas dos tipos Classe(1) e Pacote(1) é possível verificar quais instâncias desses construtores são freqüentemente utilizadas em conjunto, não sendo possível garantir, porém, o relacionamento de continência entre elas.

Atributo(1)-Classe, subesquemas desse tipo contêm aqueles do tipo Classe(1), os quais, conforme explicação no item "a", não podem ser desprezados.

Subesquemas do tipo Atributo(1)-Classe, por sua vez, são o tipo mais simples que permite identificar atributos em classes.

Atributo(1)-Classe-Pacote, contém subesquemas dos tipos Atributo(1)-Classe e Classe(1)-Pacote, além de Classe(1) e Pacote(1).

A utilização de subesquemas desse tipo é importante, pois ele apresenta tanto o relacionamento de continência entre classe e pacote quanto o relacionamento de dependência entre atributo e classe.

Através desse tipo de subesquema, é possível identificar além do(s) atributo(s) que caracteriza(m) as classes, o pacote ao qual cada classe pertence.

Esse conhecimento não pode ser obtido a partir da combinação de subesquemas dos tipos Atributo(1)-Classe e Classe(1)-Pacote, pois, nesse caso, não é possível garantir que as ocorrências da classe no pacote e do atributo na classe são válidas em um mesmo esquema.

Uma vez que não foi possível reduzir nem o número de subesquemas considerados nem o número de regras geradas, os tipos de regra resultantes ao final da mineração foram analisados, trabalho parcialmente disponível em.

Com base nesse estudo foi possível verificar que, apesar de cada padrão ser identificável por uma única regra, cada padrão está contido em várias regras, um subconjunto das regras geradas é suficiente para identificar todos os candidatos a padrão existentes nos esquemas minerados, e algumas regras estão contidas em outras.

Com base nessas constatações e no conhecimento dos tipos de padrão que se deseja identificar, foi possível isolar dois subconjuntos de regras.

O primeiro formado por regras úteis à identificação de padrões e o segundo, por aquelas que, comprovadamente, não levam à inferência de nenhum padrão buscado.

A partir dessa atividade foi possível reduzir, automaticamente, na fase de pós-processamento, a quantidade de regras a serem posteriormente avaliadas pelo especialista humano.

Conforme citado, nessa fase do processo são consideradas apenas as regras cujo suporte e confiança são maiores que os respectivos valores mínimos especificados pelo usuário.

Portanto, todas as regras são formadas por elementos freqüentes nos esquemas analisados.

Todavia, conforme anteriormente citado, a análise das regras geradas indica que nem todas são úteis à identificação de candidatos a padrão.

O subconjunto das regras úteis foi denominado "regras de interesse".

Assim, a fase de pós-processamento das regras associativas visando à identificação de candidatos a padrão de análise para BDG consiste em destacar regras de interesse da aplicação.

Eliminar, de forma automática, regras, comprovadamente, não relevantes e apresentar ao especialista humano o resultado dos passos anteriores, para que ele confirme ou não os candidatos a padrão identificados pelas regras de interesse e avalie as regras restantes quanto à sua utilidade.

Parte do processo de seleção das regras de interesse consiste em identificar quais tipos de regras, de fato, podem ser utilizados na identificação dos padrões buscados.

Essa atividade se mostra importante, pois permite a eliminação de regras que, apesar de serem formadas por construções freqüentes, não levam a padrões úteis ou relevantes dentro do que é proposto neste trabalho.

Para reduzir a quantidade de regras, foram verificados, em primeiro lugar, os tipos de padrão que se deseja encontrar (aqueles constituídos de uma instância de classe ou de pacote ou aqueles formados por dois ou mais elementos relacionados entre si).

Para cada tipo de padrão, verificou-se uma forma intuitiva de descrevê-lo no formato de regras associativas.

Em seguida, esse formato foi generalizado, tornando-se um tipo de regra de interesse.

Identificadas as regras de interesse, foram verificados alguns tipos de regra que, comprovadamente, não são úteis à identificação de nenhum dos padrões buscados.

Com base no resultado desse trabalho, foi possível, então, automatizar a eliminação das regras irrelevantes, de modo que o especialista pode facilmente identificar as regras de interesse no conjunto restante.

No contexto desse trabalho, para simplificar tanto a interpretação quanto a validação das regras, são consideradas apenas aquelas cujo conseqüente é formado por um único item.

Nas próximas seções, são apresentados o conjunto de regras de interesse, assim como a estratégia de redução do número de regras.

Durante a análise das regras para a identificação dos tipos de regra de interesse, verificou-se que a estratégia de decomposição e organização de esquemas proposta não favorece o processo de inferência de candidatos a padrão formados por um único elemento (instância de pacote ou classe), não tendo sido possível identificar nenhuma forma intuitiva de combinar os subesquemas considerados de modo a inferir os tipos de padrão em questão.

Como alternativa para minimizar esse problema, o item "marca de esquema" foi incorporado ao arquivo de entrada.

A "marca de esquema" não representa um subesquema gerado a partir da decomposição dos esquemas de BDG, mas visa registrar a ocorrência de um esquema qualquer.

Todo esquema apresentado na entrada possui um item correspondente a "marca de esquema".

Assim, o suporte das regras cujo antecedente é formado apenas por esse item indica o percentual de esquemas analisados que contém a construção presente no seu conseqüente.

Se, por um lado, a "marca de esquema" facilita a identificação de padrõe s formados por um único elemento, sua incorporação obrigatória ao arquivo de entrada implica em aumento significativo no número de regras geradas na MD, pois, para cada padrão identificado, várias regras contendo esse elemento são geradas desnecessariamente.

Assim, para ser considerada de interesse, a regra deve atender a dois requisitos que visam tornar mais natural tanto a leitura quanto a interpretação das mesmas, além de restringir o número de regras a ser analisado pelo especialista.

Os requisitos são, R1, o padrão identificado pela regra é formado apenas por construtores presentes no seu conseqüente, exceto quando o conseqüente for um subesquema do tipo Associação.

Nesse caso, a regra também pode ser utilizada para identificar padrões mais complexos e R2, elementos fortes (instâncias de construtor forte) que formam o subesquema do conseqüente devem pertencer ao conjunto dos elementos presentes no antecedente da regra, exceto quando o conseqüente for formado por um subesquema do tipo Classe(1) ou Pacote(1).

Nesse caso, o antecedente da regra deve conter apenas o item "marca de esquema".

O requisito R1 visa padronizar o tipo de regra a ser utilizado na identificação de cada tipo de padrão buscado.

Com base nele, é possível manter apenas uma das regras entre aquelas formadas pelos mesmos elementos de esquema, como R6 e R7, por exemplo.

Nesse caso, as duas regras poderiam ser utilizadas para identificar o padrão formado pela classe Município qualificada pelo atributo Polígono.

A definição do requisito R1, todavia, permite a eliminação da regra R7 e garante que, ainda assim, o padrão será identificado.

Resumo dos tipos de padrão identificáveis com base no tipo de subesquema presente no conseqüente da regra.

Relação entre tipo de padrão e subesquema do conseqüente das regras.

Estrutura do tipo de candidato a padrão identificado conseqüente da regra R2, por sua vez, visa tanto tornar mais intuitiva a leitura das regras quanto garantir que os padrões identificados são formados por elementos relacionados entre si.

Essa restrição não elimina regras de interesse, pois, para todos os conseqüentes formados por mais de um elemento (ou seja, que contêm um elemento fraco), com certeza, existe uma regra que apresenta os elementos fortes desse subesquema no seu antecedente.

Isso ocorre, pois a estratégia de decomposição dos esquemas garante que os elementos fortes, individualmente, também serão considerados na mineração e, por serem mais simples, estes são tão ou mais freqüentes que o subesquema que contém também o elemento fraco.

Esse requisito implica em que, para inferir o padrão formado pela classe Município contendo o atributo Polígono, a regra R6 (anteriormente apresentad será utilizada no lugar da regra R8, por exemplo).

Ainda para efeito de interpretação, as regras foram classificadas em simples e complexas.

Uma regra simples apresenta o candidato a padrão integralmente no seu conseqüente e não requer qualquer conhecimento especialista para a identificação dessa estrutura.

Regras simples caracterizam-se por apresentar, no conseqüente, todos os elementos fortes presentes no seu antecedente.

Além disso, não existe elemento fraco no antecedente de uma regra simples.

As regras complexas, por sua vez, podem apresentar elementos fracos no antecedente e nem todos os elementos fortes do antecedente estão presentes no conseqüente da regra.

Sua interpretação combina informações tanto do antecedente quanto do conseqüente para identificar o candidato a padrão, exigindo a aplicação do conhecimento objetivo do especialista em projeto de BDG, ou seja, domínio dos construtores dos modelos de dados e das regras de combinação dos mesmos.

A partir deste tipo de regra é possível inferir candidatos a padrão mais complexos do que o subesquema apresentado no conseqüente da regra e do que os subesquemas considerados durante a preparação dos dados.

A ostra a relação entre os tipos de regras e o conhecimento especialista necessário, tanto para sua interpretação quanto para validação dos candidatos a padrão.

Relação entre o tipo de regra e o tipo de conhecimento especialista.

Na seção a seguir, são apresentados alguns tipos de regra de interesse, descritos a partir dos tipos de padrão que podem ser inferidos por eles.

A estrutura das regras é apresentada segundo a EBNF, onde "S" é o suporte e "CF", a confiança da regra.

Devido ao exposto, a confiança não é considerada para fins de inferência do padrão.

A informação que precede o ponto corresponde ao tipo da regra e a informação que sucede esse símbolo indica a qual parte da regra (antecedente ou conseqüente) a descrição se refere.

Os exemplos descrevem os itens na notação UML, onde a "marca de esquema" é representada, sugerindo um esquema completo.

Representação gráfica do elemento "Marca de esquema".

A interpretação desse tipo de regra é bastante trivial e não requer conhecimento do especialista, uma vez que o padrão está completamente descrito no seu conseqüente.

Abaixo são detalhados os tipos de regra simples identificados como de interesse.

Para cada tipo é fornecido um exemplo de tipo de padrão que pode ser inferido a partir do tipo de regra em questão.

Tipo S1, utilizado para identificar padrões formados por uma única instância de classe.

Esse tipo de regra indica que a instância da classe presente no seu conseqüente é utilizada em S% dos esquemas apresentados na entrada.

Um exemplo desse tipo de regra e o padrão por ela identificado podem ser visualizados.

Exemplo de regra simples tipo S1.

Padrão inferido a partir da regra.

Tipo S2 permite inferir padrões formados por uma única instância de pacote, sua estrutura é mostrada a seguir.

Esse tipo de regra indica que a instância de pacote presente no seu conseqüente é utilizada em S% dos esquemas apresentados na entrada.

Exemplo desse tipo de regra, assim como o padrão por ela identificado são mostrados.

Exemplo de regra simples tipo S2.

Padrão inferido a partir da regra.

Identifica padrões formados por uma única instância de classe, qualificada por um único atributo.

Esse tipo de regra indica que, em S% dos esquemas considerados, a classe do seu antecedente foi utilizada e qualificada pelo atributo apresentado no conseqüente.

Um exemplo desse tipo de regra e o padrão por ela identificado são apresentados.

Exemplo de regra simples tipo S3.

Padrão inferido a partir da regra.

Tipo S4, utilizado para identificar padrões formados por uma única instância de classe, definida em um pacote.

A partir desse tipo de regra é possível detectar que a classe e o pacote presentes no antecedente da regra são utilizados em S% dos esquemas.

Além disso, a classe está contida no pacote.

Um exemplo desse tipo de regra e o padrão inferido são apresentados nas figuras 510 e 511.

Exemplo de regra simples tipo S4.

Padrão inferido a partir da regra.

Tipo S5, permite a inferência de padrões formados por uma única instância de classe, qualificada por um único atributo, dentro de pacote.

A regra indica que se a classe do antecedente está presente no esquema e é definida no pacote também apresentado no antecedente da regra, então ela é qualificada pelo atributo mostrado no conseqüente.

Isso ocorre em S% dos esquemas apresentados na entrada.

Exemplo desse tipo de regra e o padrão identificado são mostrados.

Exemplo de regra simples tipo S5.

Padrão inferido a partir da regra.

Tipo S6, Utilizado para identificar padrões formados por duas classes relacionadas entre si através de uma associação binária.

Esse tipo de regra indica que as classes do antecedente estão presentes em S% dos esquemas apresentados na entrada e, além disso, estão relacionadas através de uma associação binária.

Um exemplo desse tipo de regra e o padrão por ela identificado são mostrados nas figuras 51e 515.

Exemplo de regra simples tipo S6.

Padrão inferido a partir da regra.

Tipo S7, utilizado para identificar padrões formados por uma classe com auto-relacionamento do tipo associação binária.

Esse tipo de regra indica que a classe do antecedente está presente em S% dos esquemas apresentados na entrada e, além disso, possui um auto-relacionamento do tipo associação.

Um exemplo desse tipo de regra e o padrão por ela identificado são mostrados nas figuras 516 e 517.

Exemplo de regra simples tipo S7.

Padrão inferido a partir da regra.

Regras complexas são utilizadas para inferir padrões de interesse mais complexos do que os tipos de subesquema considerados durante a preparação de dados.

Nesses tipos de regra, nem todos os elementos do antecedente estão presentes no conseqüente da regra.

Para serem consideradas de interesse, as regra complexas devem atender a uma das condições, os elementos fortes mostrados no antecedente da regra estão presentes no seu conseqüente ou os elementos fortes presentes no antecedente da regra estão relacionados entre si através de associação binária entre classes.

Relação de continência entre pacote e classe e/ou relação de dependência entre atributo e classe.

As condições acima descritas garantem que todos os elementos presentes na regra estão relacionados entre si de alguma maneira.

Essa restrição é importante, pois despreza regras que apresentam elementos não relacionados a nenhum outro, as quais não são úteis à identificação dos padrões buscados.

Tais regras contêm outras mais simples (com menos elementos) as quais permitem a inferência de tais padrões.

A seguir são apresentados alguns tipos de regras complexas identificados como de interesse.

Outros tipos de regras complexas podem ser encontrados no Anexo 1.

Identifica padrões formados por duas ou mais classes não associadas, definidas em um mesmo pacote.

Além da classe do conseqüente, outra(s) classe(s) apresenta(m) um ou mais atributos.

Todos os pacotes devem ser iguais.

Nesse caso, com exceção da classe do conseqüente, todas as classes que apresentam atributo devem ser apresentadas no antecedente apenas em subesquemas do tipo Atributo(1)-Classe-Pacote.

Se a classe do conseqüente possui mais de um atributo, deve ser apresentada no antecedente em item do tipo Atributo(1)-Classe-Pacote e não em Classe(1)-Pacote.

Classes sem atributo ou classe do conseqüente com apenas um atributo são apresentadas no antecedente em item do tipo Classe(1)-Pacote.

A partir desse tipo de regra é possível inferir que S% dos esquemas apresentados na entrada possuem o pacote especificado na regra, definido com as várias classes sem relacionamentos entre si.

Além disso, as classes são qualificadas pelos atributos, conforme apresentados na regra.

Exemplo desse tipo de regra e o padrão por ela identificado são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Utilizado para identificar padrões formados por duas classes definidas em um mesmo pacote e relacionadas entre si através de associação binária.

Os pacotes, nesse tipo de regra, são obrigatoriamente iguais.

Esse tipo de regra indica que, em S% dos esquemas analisados, as classes do antecedente da regra estão relacionadas entre si através de uma associação binária.

Além disso, as duas classes encontram-se definidas no pacote apresentado.

Um exemplo desse tipo de regra e o padrão por ela identificado são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Utilizado para inferir padrões que consistem em duas classes relacionadas entre si através de uma associação, onde pelo menos uma das classes possui atributo e está definida em pacote.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Identifica padrões formados por várias classes associadas entre si, onde pelo menos uma delas é qualificada por, no mínimo, um atributo e uma delas é definida dentro de pacote.

Inclui classe(s) com atributo(s), definida(s) em pacote.

O item do tipo Classe(1) só deve estar presente na regra se uma das classes do conseqüente não possui outra associação, não é qualificada por atributo(s) e não está definida em pacote.

A leitura desse tipo de regra indica que em S% dos esquemas, as classes presentes na regra possuem associações entre si, são qualificadas por atributo(s) e definidas em pacote, conforme descrito na regra.

Exemplos desse tipo de regra e os padrões por elas identificados são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

A partir da identificação de regras de interesse, é possível isolar um conjunto de regras que não são úteis à identificação de nenhum dos tipos de padrão buscados.

Para isso, são considerados tanto os requisitos definidos para facilitar a interpretação das regras quanto as características próprias da aplicação, as quais são responsáveis pela geração de regras redundantes ou sem significado.

São consideradas desprezíveis regras que não atendem ao requisito, não atendem a nenhuma das condições descritas, ou apresentem no seu antecedente item(ns) que contém(êm) outro(s).

As regras que não atendem ao requisito Rpodem ser substituídas por outra(s) que atende(m), a(s) qual(is), com certeza, também fará(ao) parte do conjunto de regras geradas.

As que não atendem às condições são descartadas, pois os padrões buscados são formados sempre por um único elemento ou por mais de um elemento relacionados entre si.

As regras do terceiro grupo, por sua vez, contêm outras mais simples, as quais são suficientes para identificar o padrão buscado.

Um exemplo de regra descartada por este motivo é apresentado.

A regra que a substitui e o padrão buscado serão ilustrados

Exemplo de regra descartada.

A partir da identificação dos tipos de regras que não são de interesse, torna-se possível reduzir o número de regras de forma controlada e automática.

Esse processo consiste, basicamente, em classificar cada regra de acordo com o tipo do subesquema presente em seu conseqüente e verificar se, estão presentes no antecedente da regra os elementos mínimos necessários à inferência de padrões do tipo que a regra identifica, conforme determina o requisito R2, e não existe mais itens e/ou elementos no antecedente da regra do que o mínimo necessário.

Com base nesses princípios, são definidos filtros usados para eliminar as regras que não são relevantes para identificação de padrões.

Os filtros podem ser separados em dois grupos, os genéricos e os específicos por tipo de subesquema do conseqüente da regra.

Filtros genéricos se aplicam a vários tipos de regras, enquanto os filtros específicos são definidos de acordo com o tipo de subesquema presente no conseqüente da regra.

É importante ressaltar que essa estratégia parte do princípio de que toda regra é de interesse, a menos que seja descartada por algum dos filtros definidos.

Após a aplicação dos filtros, algumas regras ainda podem ser descartadas pelo especialista humano.

A seguir são descritos os filtros identificados durante o desenvolvimento desse trabalho.

Para cada filtro, são apresentadas a estrutura das regras por ele eliminadas assim como exemplos de tais regras, em notação UML.

É importante ressaltar que as medidas suporte e confiança não são utilizadas nesses filtros, pois já foram previamente aplicadas durante a MD.

Filtro F1, elimina regras cujo conseqüente é um item do tipo "marca de esquema".

Esse tipo de regra não apresenta informação relevante, pois a "marca de esquema" só é utilizada na identificação de padrões formados por apenas uma classe ou apenas um pacote.

A presença desse item só tem relevância no antecedente da regra.

Exemplo de regra eliminada pelo filtro é mostrado.

Exemplo de regra eliminada pelo filtro F1.

Filtro F2, elimina regras cujo antecedente possui o item "marca de esquema" e cujo item do conseqüente não é do tipo Classe(1) ou Pacote(1).

Uma vez que o item "marca de esquema" só utilizado em regras simples para identificar padrões formados por uma única instância de classe ou de pacote, qualquer outro tipo de subesquema presente no conseqüente da regra não representa informação relevante.

A estrutura das regras descartadas por esse filtro é F2.

Exemplo de regra descartada por esse filtro é mostrado.

Exemplo de regra eliminada pelo filtro F2.

Filtro F3 elimina regras cujo antecedente possui o item "marca de esquema" acompanhado de outro(s) item(ns).

Para identificar candidatos a padrão formados apenas por uma instância de classe ou de pacote, não é necessário nenhum outro item no antecedente da regra além da "marca de esquema".

Exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F3.

Filtro F4, elimina regras cujo subesquema do conseqüente não é do tipo Associação e cujo antecedente apresenta subesquema(s) desse tipo.

Item do tipo Associação é utilizado no antecedente da regra apenas para identificar padrões formados por mais de uma associação binária.

Esse tipo de padrão, por sua vez, só é inferido por regras cujo conseqüente é subesquema do tipo Associação.

Mostra um exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F4.

Filtro F5 elimina regras cujo subesquema do conseqüente não é do tipo Associação e seu antecedente, além de apresentar mais de um item, só possui subesquemas do tipo Classe(1).

Regras cujo antecedente possui apenas subesquema(s) do tipo Classe(1) são utilizadas para identificar padrões de dois tipos, aquele formado por uma classe com um atributo ou o composto por uma associação binária.

Para identificar padrões formados por classe com atributo, é suficiente apenas um item no antecedente, correspondente à instância da classe do conseqüente.

Padrões que possuem associação binária, por sua vez, são identificados através de regras cujo conseqüente é subesquema do tipo Associação.

A estrutura das regras eliminadas por esse filtro é mostrada a seguir.

Descarta regras cujo antecedente possui apenas subesquemas do tipo Pacote(1).

Subesquemas desse tipo são considerados apenas para identificação de padrões formados por uma única instância de pacote.

Nesse caso, esse tipo de item é apresentado no conseqüente da regra.

Exemplo de regra eliminada pelo filtro F6.

Filtro F7 elimina regras cujo antecedente não é formado exclusivamente pelo item "Marca de esquema".

Regras cujo conseqüente é subesquema do tipo Classe(1) são utilizadas para identificar candidatos a padrão formados apenas por uma classe, sendo necessário, para tanto, apenas a ocorrência do item "marca de esquema" no antecedente da regra.

Exemplo de regra eliminada pelo filtro F7.

Filtro F8 análogo ao filtro F7, elimina regras cujo antecedente não é formado exclusivamente pelo item "marca de esquema".

Regras cujo conseqüente é subesquema do tipo Pacote(1) são utilizadas para identificar candidatos a padrão formados apenas por uma instância de pacote.

Para inferir esse tipo de padrão é necessária apenas a ocorrência do item "Marca de esquema" no antecedente da regra.

Exemplo de regra descartada por esse filtro é mostrado.

Exemplo de regra eliminada pelo filtro F8.

Filtro F9 são eliminadas regras cujos antecedentes não são formados apenas por subesquemas dos tipos Classe(1) e/ou Atributo(1)-Classe.

Além disso, são descartadas regras que possuem pelo menos uma classe no antecedente diferente da classe do conseqüente.

Regras com conseqüente do tipo Atributo(1)-Classe são utilizadas para identificar candidatos a padrão formados por classe com atributo(s).

Se a classe só possui um atributo, então é suficiente a existência, no antecedente, de um item com a mesma classe do conseqüente.

Se a classe possui mais de um atributo, então são apresentados os outros atributos da mesma classe, no antecedente da regra.

Exemplo de regra descartada por esse filtro é mostrado.

Exemplo de regra eliminada pelo filtro F9.

Filtro F10, Elimina regras cujo antecedente apresenta redundância entre instâncias de classe.

Esse tipo de regra é gerado quando o candidato a padrão a ser identificado possui mais de um atributo.

Além disso, o antecedente da regra é formado por subesquemas dos tipos Atributo(1)-Classe e Classe(1).

Nesse caso, o subesquema do tipo Classe(1) não agrega conhecimento e o mesmo padrão pode ser inferido a partir de uma regra sem esse item, a qual é mais simples e, portanto, com certeza também é gerada durante a MD.

Exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F10.

Filtro F11, Elimina regras que não possuem no antecedente, pelo menos uma instância da classe e uma instância do pacote presentes no conseqüente da regra.

Esse filtro mantém apenas as regras cujo conseqüente é do tipo Classe(1)-Pacote e que atendem ao requisito R2.

Exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F11.

Descarta regras cujo antecedente possui item(ns) do tipo Atributo(1)-Classe-Pacote.

Subesquemas desse tipo não são utilizados na inferência de candidatos a padrão formados por classes em pacote.

Exemplo de regra descartada por esse filtro é mostrada.

Exemplo de regra eliminada pelo filtro F12.

Filtro F13, Elimina regras que apresentam, em seu antecedente, itens que possuem instância de pacote diferente da existente no conseqüente da regra.

Regras cujo conseqüente é subesquema do tipo Classe(1)-Pacote são utilizadas para identificar padrões formados por uma ou mais instâncias de classe definidas em um mesmo pacote.

Exemplo de regra descartada por esse filtro é mostrada.

Exemplo de regra eliminada pelo filtro F13.

Filtro F14, elimina regras cujo antecedente não é formado apenas por itens do tipo Classe(1)-Pacote e/ou Atributo(1)-Classe-Pacote.

Esse tipo de regra identifica construções freqüentes formadas por classe(s), com atributo(s), definidas em um único pacote.

Se todas as classes do padrão estão definidas em pacote, o tipo de subesquema mais simples a ser encontrado na regra é Classe(1)-Pacote.

Subesquemas como Classe(1) ou Pacote(1), representam informação redundante.

Exemplo de regra eliminada pelo filtro F14.

Filtro F15, de modo análogo ao filtro F13, elimina regras que apresentam, em seu antecedente, itens com instância de pacote diferente da existente no conseqüente da regra.

Regras cujo conseqüente é subesquema do tipo Atributo(1)-Classe-Pacote são utilizadas para identificar padrões formados por uma ou mais instâncias de classe definidas em um mesmo pacote.

Exemplo de regra descartada por esse filtro é mostrada.

Exemplo de regra eliminada pelo filtro F15.

Filtro F16, se a associação do conseqüente não é um auto-relacionamento, elimina regras que não possuem no antecedente, no mínimo, as duas classes envolvidas no relacionamento do conseqüente.

Esse filtro elimina regras que não atendem ao requisito R2.

Exemplo de regra descartada por esse filtro é mostrada.

Exemplo de regra eliminada pelo filtro F16.

Filtro F17 elimina regras que apresentam no antecedente item do tipo Classe(1) com a instância da classe diferente daquelas apresentadas no conseqüente.

Instâncias de classe diferentes da apresentada no conseqüente só consistem em informação útil se estiverem representadas através de subesquemas dos tipos Classe(1)-Pacote (determina o pacote no qual a classe está definid, Atributo(1)-Classe (especifica um atributo da classe) ou Atributo(1)-Classe-Pacote (combina as duas informações anteriores).

Exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F17.

Filtro F18, Elimina regras cujo antecedente apresenta item(ns) do tipo Atributo(1)-Classe, Classe(1)-Pacote e/ou Atributo(1)-Classe-Pacote, se as instâncias de classe desse(s) item(ns) não forem iguais a nenhuma das classes presentes no conseqüente e a nenhuma classe de um relacionamento presente no antecedente da regra.

Esses tipos de subesquema apresentam informação adicional a respeito de classes envolvidas em associações binárias.

Portanto, são significativos apenas quando representam instância de classe participante desse tipo de relacionamento.

Exemplo de regra descartada por esse filtro.

Exemplo de regra eliminada pelo filtro F18.

Para verificar a aplicabilidade do processo de DCBD na identificação de candidatos a padrão de análise para BDG é necessário observar se a técnica utilizada aponta construções freqüentes dentro de uma grande massa de dados.

Para tanto, foram realizados testes em um ambiente controlado, onde as construções freqüentes são previamente conhecidas.

Os esquemas utilizados nos testes são fictícios e foram gerados automaticamente, pois, a utilização de esquemas reais de BDG é dificultada, uma vez que nem todos os aspectos referentes à etapa de preparação de dados foram tratados nesse trabalho.

A criação de dados fictícios facilita o controle do processo.

O objetivo dos testes consiste em verificar a adequação do processo de DCBD na solução do problema proposto (identificar candidatos a padrão de análise para BDG), não sendo objetivo do presente trabalho identificar verdadeiros padrões, os quais são comprovadamente utilizados durante a modelagem de sistemas reais.

O programa de geração de esquemas foi desenvolvido na linguagem Pascal, pois a mesma apresenta todos os operadores necessários à criação do algoritmo, além de ser de fácil utilização.

Para manter total controle sobre os esquemas e construções mais freqüentes geradas pelo algoritmo, alguns parâmetros devem ser informados.

São eles número total de esquemas a serem gerados.

Associações binárias freqüentes entre classes, assim como a freqüência de cada uma delas.

Atributos definidos em classes envolvidas em associações freqüentes e o pacote onde cada uma dessas classes está definida.

Quantidade máxima de classes que cada esquema gerado apresenta.

Quantidade máxima de atributos que podem ser definidos em cada classe e o nome do arquivo de saída no qual devem ser armazenados os esquemas gerados.

A partir desses parâmetros, são gerados os esquemas.

Para cada esquema, primeiramente, são armazenadas as classes envolvidas em associações freqüentes.

As demais classes são criadas randomicamente até que seja atingido o número máximo de classes/esquema especificado pelo usuário.

Após armazenar todas as classes do esquema, o programa cria os subesquemas do tipo Atributo(1)-Classe.

Primeiramente são armazenados os atributos especificados pelo usuário e, em seguida, o algoritmo gera outros atributos.

O número de atributos por classe é determinado aleatoriamente pelo algoritmo, mas é sempre menor ou igual ao número máximo de atributos/classe especificado pelo usuário.

A etapa seguinte consiste em armazenar os subesquemas dos tipos Classe(1)-Pacote e Atributo(1)-Classe-Pacote, de acordo com os pacotes onde cada classe está definida.

No último passo do algoritmo, são armazenadas as associações.

Além das associações mais freqüentes especificadas pelo usuário, outras associações são geradas aleatoriamente pelo algoritmo, de modo que cada classe está envolvida em pelo menos um relacionamento desse tipo.

Os esquemas gerados são decompostos, conforme especificado na seção 411 e armazenados e organizados como descrito.

Detalhes do algoritmo de geração dos esquemas são apresentados.

Após a criação dos dados de entrada, o algoritmo de identificação de regras associativas disponível na ferramenta IBM Intelligent Miner for Data é executado.

Esta ferramenta foi utilizada em virtude de sua disponibilidade no PPGC-UFRGS e sua facilidade de utilização.

Nessa etapa, os parâmetros são informados de modo a permitir a identificação de todas regras possíveis, não havendo limitação do número de itens que compõem seu antecedente.

Essa ferramenta identifica regras cujos conseqüentes são compostos apenas por um item.

O arquivo de regras identificadas pela ferramenta é, então, pós-processado de forma automatizada, através de um algoritmo implementado para automatizar a aplicação dos filtros apresentados.

O algoritmo que automatiza o pós-processamento das regras está disponível no Anexo 3.

As regras não eliminadas pelos filtros são analisadas manualmente, a fim de verificar se apresentam a descrição das construções freqüentes existentes no arquivo de entrada.

O procedimento acima apresentado foi realizado três vezes.

Para cada um dos estudos de caso foram gerados 9000 esquemas com 15 classes cada um.

Os estudos de casos apresentados nas seções a seguir diferem entre si pelas construções mais freqüentes especificadas pelo usuário.

Na primeira instanciação do processo, foram gerados 9000 esquemas, compostos por 15 classes, cada um.

A construção está presente em 70% dos esquemas.

Construção freqüente do estudo de caso 1.

A ferramenta Intelligent Miner for Data foi utilizada, com suporte especificado em 65%.

Durante a execução, 1016 regras foram geradas.

Sobre o arquivo de regras resultante, foi executado o algoritmo de pós-processamento.

O número total de regras após a aplicação dos filtros é 13, dentre as quais 10 identificam algum tipo de padrão implícito na construção freqüente apresentada na entrada do algoritmo de MD.

A regra que apresenta o padrão completo é do tipo C7.

Na segunda execução do processo, foram gerados 9000 esquemas compostos por 15 classes, cada um.

A construção está presente em 70% dos esquemas, enquanto a da figura encontra-se em 80%.

Construção com freqüência de 70% no estudo de caso 2.

Construção com freqüência de 80% no estudo de caso 2.

O suporte mínimo especificado na ferramenta Intelligent Miner for Data foi de 65%.

Ao final da execução 5110 regras foram apresentadas.

A execução do algoritmo de pós-processamento sobre o arquivo resultante da MD resultou em um total de 5regras, das quais 21 podem ser interpretadas como candidato a padrão de análise.

Dentre as regras remanescentes, destacam-se as mostradas nas figuras 65 (regra complexa do tipo C10 e 66 (regra simples do tipo S4), as quais indicam os padrões mostrados, respectivamente, nas figuras 6e 64.

Para o terceiro estudo de caso, novamente, foram gerados 9000 esquemas compostos por 15 classes, cada um.

As construções mostradas nas figuras 67 e 68 estão presentes no arquivo de entrada em 60% e 70% das transações, respectivamente.

Construção com ocorrência de 60% no estudo de caso 3.

Construção com 70% de ocorrência no estudo de caso 3.

A mineração de dados foi executada três vezes, utilizando o mesmo arquivo de entrada.

Na primeira execução, o suporte mínimo foi especificado em 55%.

A mineração de dados resultou em mais de 1 milhão de regras, as quais foram reduzidas para pouco mais 11 mil, após a aplicação dos filtros no pós-processamento.

Exemplos de regras interessantes, mantidas após o pós-processamento dos dados.

A segunda execução do algoritmo de MD foi realizada com suporte especificado em 65%.

Ao final do processamento, 2295 regras foram apresentadas.

Esse número foi reduzido para 12, após a execução do algoritmo de pós-processamento.

Dentre as regras remanescentes, 11 possuem significância no contexto da aplicação, dentre as quais está aquela apresentada.

A terceira mineração de dados foi realizada com suporte especificado em 75%.

Nenhuma regra foi gerada como resultado, devido ao alto valor do suporte mínimo especificado.

O emprego de padrões de análise tem sido apresentado como alternativa no sentido de estimular e facilitar a modelagem conceitual de BDG, pois simplifica a criação e atualização de esquemas conceituais.

A fim de facilitar tanto a disponibilização quanto a recuperação dessas construções, padrões são organizados em catálogos.

A criação de um catálogo de padrões leva em consideração três aspectos principais, aquisição de conhecimento, atualização e consulta.

O problema abordado nesse trabalho consiste na aquisição de conhecimento, uma vez que, as demais questões são comumente objetivo de estudo.

Além disso, o processo de identificação de padrões tem se mostrado um entrave na popularização do uso dessas construções.

As técnicas atualmente utilizadas com o objetivo de identificar padrões de análise são centradas no conhecimento de especialistas, tornando o processo lento e subjetivo.

A subjetividade é especialmente prejudicial, pois possibilita que os padrões propostos por um especialista sejam refutados por outros com diferentes experiências de projeto.

Se por um lado essas metodologias dificultam a identificação de novos padrões, por outro, elas possibilitam que sejam propostos padrões de forma descontrolada.

Nesse contexto, o presente trabalho propôs a aplicação do processo de DCBD como alternativa às metodologias de identificação de candidatos a padrão de análise baseadas exclusivamente no conhecimento de especialistas.

Esta proposta, todavia, também pode ser utilizada como ferramenta de apoio ao especialista que segue tais metodologias.

A partir de esquemas conceituais de BDG, técnicas de mineração de dados são aplicadas com o objetivo de identificar as construções freqüentemente utilizadas na modelagem da realidade.

O pós-processamento dos resultados viabiliza a análise das regras resultantes por parte de um especialista, o qual confirma ou não o candidato inferido como padrão de análise para BDG.

O processo de DCBD foi utilizado, pois tem como objetivo automatizar (ou pelo menos, semi-automatizar) a análise de grandes volumes de dados.

Desse modo, sua aplicação possibilita a análise de um número muito maior de esquemas em relação ao que é realizado pelos métodos tradicionalmente empregados, sendo possível comparar esquemas de diferentes especialistas.

O trabalho apresenta a aplicação da técnica de identificação de regras associativas como alternativa à análise realizada pelo especialista a fim de identificar candidatos a padrão de análise para BDG.

A escolha dessa técnica leva em consideração os critérios citados na bibliografia consultada, dentre os quais destacam-se a sua adequação ao objetivo da aplicação do processo e o formato de representação do resultado.

A fim de possibilitar a mineração, investigou-se como devem ser conduzidas as atividades referentes à preparação dos esquemas conceituais de BDG a serem minerados.

No que se refere a esse aspecto, maior ênfase é dada às atividades de decomposição de esquemas e armazenamento em formato compatível com aquele utilizado pela técnica de MD selecionada.

Além disso, foi realizado um estudo a respeito dos resultados obtidos durante a mineração, quais sejam, todas as regras geradas são formadas por construções freqüentes, cada padrão está implícito em mais de uma regra, um subconjunto das regras geradas é suficiente para identificar todos os candidatos a padrão existentes nos esquemas minerados, e algumas regras estão contidas em outras.

Com base no conhecimento obtido, foi possível identificar um subconjunto de regras de interesse e um subconjunto de regras que, apesar de serem formadas por construções freqüentes, são redundantes ou não agregam informação útil para a identificação dos padrões de análise buscados.

Esse levantamento possibilitou a criação de um programa de computador que elimina, de forma automática, regras que não agregam informação útil ao objetivo final do processo.

Por fim, a execução de testes mostra que, de fato, a utilização da técnica de identificação de regras associativas é um grande passo no sentido de agilizar a detecção de novos padrões de análise.

O algoritmo de pós-processamento também se mostrou útil no sentido de diminuir a quantidade de regras identificadas, facilitando a análise manual a ser realizada pelo especialista.

Além disso, a estratégia de decomposição de esquemas, que considera apenas alguns poucos tipos de subesquema, mostrou-se adequada às necessidades da aplicação.

Durante os testes também foi possível detectar que, para a identificação de padrões de análise para BDG, não é apenas o valor do suporte que determina a quantidade de regras geradas.

Nesse caso, além do valor do suporte mínimo, especificado pelo usuário, a complexidade do(s) padrão implícito(s) nos esquemas analisados também tem influência sobre a quantidade de regras geradas.

Essa constatação foi possível através de resultados de testes, onde foi possível observar que a variação da construção freqüente e do número de itens nas regras alteram a quantidade de regras geradas pelo algoritmo de MD.

Obviamente, se for especificado um valor de suporte mínimo maior do que o número de ocorrências da construção, a quantidade de regras também é reduzida.

Vale ressaltar ainda que o estudo apresentado pode ser aplicado em diversas outras áreas e não apenas em SIG.

Embora os resultados da pesquisa tenham sido satisfatórios, alguns aspectos ainda devem ser considerados em trabalhos futuros, dentre os quais destacam-se que outros construtores do modelo de dados devem ser considerados, devem ser definidos critérios para seleção de esquemas a minerar.

Problemas de sinônimos, antônimos e parônimos devem ser tratados nos dados de entrada.

Testes, utilizando esquemas de aplicações reais, devem ser realizados.

Novos filtros devem ser investigados e implementados, a fim de que um número maior de regras seja descartado de forma automática e candidatos a padrão inferidos a partir de regras já identificadas como de interesse devem poder ser apresentados em um formato mais inteligível pelo especialista como na forma de diagrama de classe da UML.

Do ponto de vista dos algoritmos de MD, trabalhos futuros podem verificar os resultados gerados por outras técnicas de MD e compará-los aos resultados obtidos neste trabalho.

Investigar a utilização de taxonomias, com o objetivo de serem identificadas menos regras e utilizar ou implementar um algoritmo de identificação de regras associativas que mantenha no resultado apenas aquelas mais abrangentes, eliminando regras contidas em outras desde que seus valores de suporte e confiança sejam iguais aos da regra mais completa.

Essa medida também deve diminuir a quantidade de regras geradas durante etapa de MD.

Agrupamento, técnicas de agrupamento geram modelos descritivos que buscam agrupar objetos em classes de objetos similares.

Os dados de entrada são analisados de modo a identificar classes naturais (ou grupos).

Análise de Associações, busca encontrar relacionamentos interessantes entre itens de um grande conjunto de dados de um domínio específico.

Os relacionamentos identificados representam padrões de comportamento.

Aprendizado em Lote, considera todo o conjunto de dados de uma única vez.

A modificação do arquivo de entrada implica na necessidade de execução da técnica de MD novamente.

Aprendizado Incremental, não desconsidera resultados de minerações anteriores quando o arquivo de entrada é modificado.

Aprendizado Não-supervisionado, utilizado para descrição e busca identificar como os dados estão relacionados, quais itens são similares, quais são diferentes e de que forma.

Nesse caso, nenhuma classe é predefinida, cabendo ao algoritmo manipular os dados de modo a determiná-las.

Aprendizado Supervisionado, é baseado em exemplos e, geralmente, é utilizado por técnicas de MD que geram modelos preditivos.

Utiliza dados de entrada previamente classificados por um especialista no domínio da aplicação.

Caixa Preta (Representação do conhecimento do tipo), não apresentam a estrutura do padrão de modo explícito.

Caixa Transparente (Representação do conhecimento do tipo), representam os padrões em termos de uma estrutura que pode ser examinada, sobre a qual é possível raciocinar e que pode ser usada para guiar decisões futuras.

Candidato a Padrão de Análise, construção freqüente, ainda não validada, dado um conjunto de esquemas de BDG.

Classificação, tarefa realizada pela MD que consiste em aprender uma função que mapeia (classifica um item para uma dentre várias classes pré-definidas).

 confiança (da regra, é a relação entre o número de transações que contém todos os itens da regra e o número de transações que contém, pelo menos, os itens do seu antecedente.

Conhecimento Objetivo do Especialista, domínio dos construtores dos modelos de dados e das regras de combinação dos mesmos.

Conhecimento Subjetivo do Especialista, experiência adquirida durante a concepção de esquemas de banco de dados.

Construtor, conceito definido em um modelo de dados utilizado para modelar a realidade.

Construtor Fraco, construtor do modelo que não pode ser definido isoladamente no esquema, pois individualmente não formam subesquemas significativos.

Sua definição dependente do seu relacionamento com um construtor forte, como ocorre com atributos e associações.

Construtor Forte, é um construtor do modelo que, isoladamente, constitui um subesquema significativo, como pacote e classe na UML.

Elemento, instância de construtor utilizada em um esquema específico.

Elemento Forte, instância de construtor forte do modelo.

Elemento Fraco, instância de construtor fraco do modelo.

Large itemset, combinação de itens do arquivo de entrada que possue suporte acima do limite especificado.

Marca de esquema, item criado com o objetivo de registrar a ocorrência de um esquema qualquer, não representando nenhum tipo de subesquema gerado a partir da decomposição.

Regras cujo antecedente é formado apenas por esse item indicam que a criação de esquemas implica na utilização da construção presente no seu conseqüente.

Modelo Descritivo, tipo de modelo gerado por técnicas de MD.

Visa encontrar padrões que descrevam os dados e sejam interpretáveis pelo ser humano.

Esse tipo de modelo disponibiliza informações a respeito do relacionamento entre os dados, como, por exemplo "peso e idade, em conjunto, são os principais fatores de ocorrência da doença Modelo Preditivo, tipo de modelo gerado pelas técnicas de MD.

É criado a partir de um conjunto de variáveis conhecidas e é utilizado para prever valores futuros de outras variáveis de interesse.

A partir desse tipo de modelo é possível responder a perguntas como "Essa transação é fraudulenta " ou "Quanto esse cliente irá produzir de lucro " Regra Complexa, utilizadas para inferir candidatos a padrão mais complexos do que o subesquema apresentado no conseqüente da regra.

Podem apresentar elementos fracos no antecedente e nem todos os elementos fortes do antecedente estão presentes no conseqüente da regra.

Sua interpretação combina informações tanto do antecedente quanto do conseqüente para identificar o candidato a padrão, exigindo a aplicação do conhecimento objetivo do especialista em projeto de BDG, ou seja, domínio dos construtores dos modelos de dados e das regras de combinação dos mesmos.

Regra Simples, apresenta no conseqüente todos os elementos fortes presentes no seu antecedente.

Além disso, não existe elemento fraco no seu antecedente.

O candidato a padrão encontra-se integralmente descrito no conseqüente da regra.

Regras de Interesse, subconjunto das regras resultantes da MD consideradas úteis.

Regressão, tarefa executada pela MD muito semelhante à classificação.

As duas são diferenciadas apenas pelo tipo de dado retornado como saída.

No caso da regressão, não são obtidos valores discretos, representando rótulos de classe, mas sim valores contínuos.

Suporte (da regra, corresponde ao percentual de transações apresentadas na entrada que contém todos os itens apresentados tanto no conseqüente quanto no antecedente da regra).

Outros tipos de Regras Complexas de Interesse.

A seguir são apresentados outros tipos de regras complexas consideradas de interesse, complementarmente àquelas mostradas.

Tipo C1, identifica padrões formados por um pacote contendo duas ou mais classes.

Onde a classe do item Classe(1) e o pacote do(s) item(ns) Classe(1)-Pacote devem ser os mesmos apresentados no conseqüente da regra.

Esse tipo de regra indica que em S% dos esquemas analisados o pacote apresentado contém as classes mostradas na regra.

Exemplo desse tipo de regra e do padrão inferido podem ser vistos nas figuras A11 e A12, respectivamente.

Exemplo de regra complexa tipo C1.

Padrão inferido a partir da regra da figura A11.

Tipo C2, utilizado para inferir padrões formados por uma única instância de classe, qualificada por dois ou mais atributos.

Onde as classes do antecedente devem ser, obrigatoriamente, iguais a do conseqüente da regra.

A interpretação desse tipo de regra indica que S% dos esquema analisados apresentam os atributos mostrados na regra, definidos na classe especificada.

Exemplo desse tipo de regra e do padrão inferido podem ser vistos nas figuras A1e A14, respectivamente.

Exemplo de regra complexa tipo C2.

Padrão inferido a partir da regra.

Tipo C3 identifica padrões formados por uma única instância de classe, contida em pacote e qualificada por dois ou mais atributos.

Nesse caso, os pacotes e as classes do antecedente da regra devem ser iguais aos do seu conseqüente.

Esse tipo de regra indica que S% dos esquemas analisados apresentam a classe mostrada na regra definida no pacote especificado, com os atributos apresentados.

Exemplo desse tipo de regra e do padrão inferido podem ser vistos nas figuras A15 e A16, respectivamente.

Exemplo de regra complexa tipo C3.

Padrão inferido a partir da regra.

Tipo Ca, utilizado para identificar padrões formados por duas ou mais classes não relacionadas entre si e definidas em um mesmo pacote.

A classe do conseqüente da regra apresenta um atributo.

Nesse caso, todos os pacotes presentes na regra devem ser iguais e pelo menos uma das classes do antecedente deve ser igual àquela apresentada no conseqüente da regra.

A partir desse tipo de regra, é possível inferir que S% dos esquemas apresentados na entrada do algoritmo de MD possui o pacote especificado na regra, definido com as várias classes sem relacionamentos entre si.

Além disso, a classe do conseqüente possui o atributo apresentado na regra.

Exemplo desse tipo de regra e do padrão por ela identificado são mostrados, na notação UML.

Padrão inferido a partir da regra.

Tipo Cb identifica padrões formados por duas ou mais classes não relacionadas, definidas em um mesmo pacote.

A classe do conseqüente da regra apresenta mais de um atributo.

Nesse caso, todos os pacotes presentes na regra devem ser iguais.

As classes dos subesquemas "Atributo (1)-Classe-Pacote" devem ser iguais a do conseqüente.

As classes dos subesquemas "Classe (1)-Pacote" devem ser diferentes da apresentada no conseqüente da regra.

Esse tipo de regra indica que, em S% dos esquemas apresentados na entrada, o pacote especificado na regra contém as várias classes especificadas, sem relacionamentos entre si.

Além disso, a classe do conseqüente é qualificada pelos atributos apresentados na regra.

Exemplo desse tipo de regra e do padrão por ela identificado são mostrados nas figuras A19 e A110.

Exemplo de regra complexa tipo Cb.

Padrão inferido a partir da regra da figura A19.

Tipo C5 b, a partir desse tipo de regra é possível identificar padrões formados por duas classes, definidas em pacotes diferentes e relacionadas entre si através de associação binária.

Nesse caso, os pacotes do antecedente da regra são, obrigatoriamente, diferentes.

Esse tipo de regra indica que em S% dos esquemas analisados as classes do antecedente da regra estão relacionadas entre si através de uma associação binária.

Além disso, as duas classes encontram-se definidas nos pacotes conforme apresentados na regra.

Exemplo desse tipo de regra e do padrão por ela identificado são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Tipo C6 a, utilizado para identificar padrões formados por duas classes relacionadas entre si através de uma associação.

Uma das classes possui um ou mais atributos.

As classes presentes nos itens do tipo "Atributo (1)-Classe" são iguais.

Esse tipo de regra indica que em S% dos esquemas as classes do antecedente estão relacionadas entre si através de uma associação.

Além disso, uma das classes é qualificada pelo(s) atributo(s) definido(s) no antecedente.

Exemplos desse tipo de regra e dos padrões por elas identificados são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

A partir desse tipo de regra é possível identificar padrões formados por duas classes relacionadas entre si através de uma associação.

As duas classes são qualificadas por um ou mais atributos.

A leitura desse tipo de regra consiste em que S% dos esquemas apresentados na entrada possui as classes do antecedente relacionadas entre si através de uma associação e são qualificadas pelo(s) atributo(s) definido(s) no antecedente.

Exemplo desse tipo de regra e do padrão por ela identificado são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Tipo C8 utilizado para identificar padrões formados por três classes e duas associações binárias.

Nesse caso, uma das classes do item Associação presente no antecedente da regra, deve ser igual a uma das classes do conseqüente.

Esse tipo de regra indica que em S% dos esquemas as duas classes do conseqüente estão associadas entre si, além disso uma delas possui uma segunda associação com outra classe.

Exemplo desse tipo de regra e do padrão por ela identificado é mostrado.

Exemplo de regra complexa tipo C8.

Padrão inferido a partir da regra.

Exemplo de regra complexa tipo C9.

Padrão inferido a partir da regra.

Exemplo de regra complexa tipo C9.

Padrão inferido a partir da regra.

Exemplo de regra complexa tipo C10 a.

Padrão inferido a partir da regra.

Exemplo de regra complexa tipo C10 a.

Padrão inferido a partir da regra.

Tipo C10 b identifica padrões formados por várias classes associadas entre si, onde pelo menos uma delas é qualificada por, no mínimo, um atributo.

O item do tipo Classe(1) só deve estar presente na regra se uma das classes do conseqüente não possui outro relacionamento e não é qualificada por atributo(s).

Esse tipo de regra indica que em S% dos esquemas as classes presentes na regra possuem associações entre si e são qualificadas por atributos conforme descrito na regra.

Exemplos desse tipo de regra e dos padrões por elas identificados são mostrados.

Exemplo de regra complexa.

Padrão inferido a partir da regra.

Exemplo de regra complexa tipo C10 b.

Padrão inferido a partir da regra.

O algoritmo foi desenvolvido na linguagem pascal, pois já se tinha domínio da mesmo, o que facilitou e agilizou o desenvolvimento.

O objetivo do algoritmo consiste em gerar dados de entrada para uma ferramenta de mineração de dados que busque identificar associações entre itens freqüentes.

Tais dados, no contexto desse trabalho, consistem em esquemas de bancos de dados.

Para verificar se a ferramenta de mineração de dados realmente indica o número de ocorrências correto para os itens freqüentes dentro do arquivo de entrada da ferramenta (que corresponde ao arquivo de saída do algoritmo), alguns conjuntos de itens, juntamente com sua freqüência, devem ser informados pelo usuário.

Assim, são passados como parâmetros de entrada, Total de esquemas, corresponde ao número total de esquemas a serem gerados.

Relacionamentos freqüentes, especificação de, no máximo, dez relacionamentos que devem aparecer com uma freqüência mínima, especificada pelo usuário.

Número de classes/esquema, quantidade máxima de classes que cada esquema possui.

Número máximo de atributos/classe, quantidade máxima de atributos que cada classe possui.

Nome do arquivo de saída, nome do arquivo que conterá os dados gerados.

A informação sobre os relacionamentos freqüentes é composta pela definição do relacionamento e a freqüência com que ele ocorre no arquivo de saída.

O relacionamento deve possuir, no máximo, cinco classes e é indicado em uma notação própria.

Como só estão sendo tratados relacionamentos de associação, a ordem de apresentação das classes não modifica a semântica, por este motivo, os relacionamentos gerados na saída serão apresentados com as classes em ordem alfabética.

Apesar de aceitar, como parâmetro de entrada, relacionamentos entre três classes, o algoritmo gera, no arquivo de saída, sempre relacionamentos dois a dois, isto é, na saída só serão apresentados relacionamentos entre duas classes.

A lógica de construção dos relacionamentos consiste em associar a primeira classe com a segunda e esta com a terceira, por exemplo, A freqüência dos relacionamentos deve ser informada em termos de percentual.

Caso o relacionamento que está sendo especificado contenha outro, deve ser informado também o índice do vetor correspondente ao relacionamento contido nele.

Se ele estiver contido em outro, o relacionamento que o contém deve ser especificado.

Esta característica restringe que cada relacionamento contenha apenas um outro ou esteja contido em apenas um relacionamento.

Se for necessário especificar, no parâmetro de entrada, um relacionamento entre um número menor que cinco classes, o nome das demais classes é omitido, da seguinte forma, Para cada esquema, primeiro são incluídas as classes que fazem parte de relacionamentos freqüentes.

O algoritmo ainda gera, randomicamente, novas classes, desde que o número total não exceda ao máximo de classes/esquema especificado pelo usuário.

Para adicionar as classes que fazem parte de relacionamentos freqüentes ao esquema, o algoritmo verifica, na ordem em que foram informados, todos os relacionamentos freqüentes e adiciona cada classe ao esquema até atingir o número máximo de classes/esquema ou até que todas as classes dos relacionamentos freqüentes já tenham sido colocadas no esquema.

Com isso, os primeiros esquemas gerados possuirão, em geral, mais de um relacionamento freqüente, dentre os especificados pelo usuário.

Após identificar todas as classes do esquema, o algoritmo gera, randomicamente, para cada classe, seus atributos.

O número de atributos por classe é determinado randomicamente pelo algoritmo, obedecendo apenas o número máximo de atributos/classe especificado pelo usuário.

De posse de todas as classes com seus atributos, são gerados os relacionamentos entre as classes do esquema.

O algoritmo insere os relacionamentos freqüentes correspondentes às classes que os compõem e associa as classes geradas randomicamente, pegando sempre a do índice atual com a do índice seguinte no vetor de classes do esquema.

Por exemplo, Os dados de saída são gerados em duas colunas, a primeira corresponde ao número do esquema e a segunda contém os itens da transação.

Um único esquema gera várias transações.

O arquivo de saída é organizado no formato de entrada da ferramenta Intelligent Miner for Data.

Assim, uma transação ocupa várias linhas do arquivo e o nome das colunas não é especificado.

Como requisito da ferramenta, o tamanho das colunas é fixo e, por isso, o algoritmo preenche os espaços deixados pelos itens com brancos.

As colunas são separadas por espaços em branco sem vírgulas e a primeira coluna (com o identificador do esquem é usada como identificador da transação).

