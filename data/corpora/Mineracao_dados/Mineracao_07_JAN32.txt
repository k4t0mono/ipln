A análise de séries temporais gera muitos desafios para profissionais em um grande número de domínios.

Várias soluções de visualização integrada com algoritmos de mineração já foram propostas para tarefas exploratórias em coleções de séries temporais.

A medida que o conjunto de dados cresce, estas soluções falham em promover uma boa associação entre séries temporais similares.

Neste trabalho, é apresentada uma ferramenta para a análise exploratória e mineração de conjuntos de séries temporais que adota uma representação visual baseada em medidas de dissimilaridade entre séries.

Esta representação é criada usando técnicas rápidas de projeção, de forma que as séries temporais possam ser visualizadas em espaços bidimensionais.

Vários tipos de atributos visuais e conexões no grafo resultante podem ser utilizados para suportar a exploração dessa representação.

Também é possível aplicar algumas tarefas de mineração de dados, como a classificação, para apoiar a busca por padrões.

As visualizações resultantes têm se mostrado muito uteis na identificação de grupos de séries com comportamentos similares, que são mapeadas para a mesma vizinhança no espaço bidimensional.

Grupos visuais de elementos, assim como outliers, são facilmente identificáveis.

A ferramenta é avaliada por meio de sua aplicação a vários conjuntos de séries.

Um dos estudos de caso explora dados de vazões de usinas hidrelétricas no Brasil, uma aplicação estratégica para o planejamento energético.

Nos ultimos dois anos houve um crescimento dramático na armazenagem de informação em todos os tipos de mídias, principalmente as mídias digitais.

Esse crescimento é decorrente de dois fatores, o crescimento da produção intelectual da humanidade, proporcionada pela automação das atividades em inúmeras areas e o aumento na capacidade de armazenagem das bases de dados, sustentada pelo avanço tecnológico.

Esses dados são colecionados porque são fontes potenciais de informações valiosas, provendo uma vantagem competitiva para quem detem essa informação.

No entanto, identificar informação util de conjuntos de dados tão massivos é uma tarefa difícil, e se nenhuma informação for extraída o armazenamento dos dados terá sido inútil.

Com objetivo de automatizar e auxiliar a extração de informações de grandes bases de dados surgiu a área conhecida como mineração de dados.

Essa area é voltada ao processo de extração de conhecimento util e previamente desconhecido em dados, por meio da aplicação de algoritmos, que extraem modelos e padrões representativos desse.

No entanto, a aplicação de algoritmos de mineração tornar-se-á inútil se o usuário não conseguir analisar os padrões extraídos, ou não entender o processo relativo ao algoritmo aplicado.

Nesse ultimo caso, o usuário pode ser incapaz de ajustar os parâmetros para obter os melhores resultados.

Dessa forma, para que a mineração de dados seja efetiva é importante que este seja um processo interativo com a participação do ser humano.

Paralelamente ao desenvolvimento de algoritmos de mineração de dados, surgiu a área de visualização focada em explorar a sofisticada capacidade visual do ser humano para identificar padrões nos dados.

Uma abordagem que combina essas duas linhas de pesquisa é a área conhecida como mineração visual de dados, que busca tornar o processo de mineração mais interativo e eficaz por meio da inserção da visualização em seu processo.

Essa combinação oferece muitas possibilidades, pois é capaz de apresentar padrões obtidos pela mineração de dados visualmente, apoiando a extração do conhecimento dirigida pelo usuário, que pode incorporar o seu conhecimento do domínio e experiência.

Séries temporais são um tipo de dado recorrente, o que é altamente esperado, já que elas são obtidas como resultado em várias areas, como em biologia, finanças, geologia, análise de movimentos humanos, entre outras.

A larga presença em várias áreas de aplicação garante a esse tipo de dado uma alta importância.

Já que uma série temporal pode ser definida como um conjunto de observações sequenciadas no tempo, esta também pode ser interpretada como um ponto definido em um espaço dimensional.

Essa alta dimensionalidade dificulta a análise de dados dessa natureza em sua forma bruta.

Este trabalho se insere neste contexto, propondo o estudo e implementação de uma ferramenta de mineração visual de dados orientada especificamente a dados expressos na forma de séries temporais.

Após um levantamento de trabalhos relacionados em visualização de séries temporais, e a identificação de tarefas típicas de mineração de dados dessa natureza, diversas funcionalidades foram implementadas e incorporadas a esse ambiente.

Técnicas denominadas projeções multidimensionais são adotadas como arcabouço para a geração de representações visuais.

Essas técnicas buscam projetar os dados definidos em um espaço de dimensionalidade alta para um espaço dimensional, na medida do possível retendo, no espaço projetado, as relações de similaridade observadas entre os itens de dados no espaço original.

O ambiente também incorpora funcionalidades que apóiam a execução de tarefas de mineração, que auxiliem na descoberta de padrões.

Dessa forma utilizando essas abordagens, apresentamos neste projeto uma ferramenta de mineração visual de dados util para apoiar a análise de conjuntos de séries, proporcionando ao analista uma visão geral dos dados que favorece a identificação de elementos com padrões similares/dissimilares, provendo um ponto de partida para explorações mais detalhadas.

Esta dissertação está organizada da seguinte maneira, É apresentada uma revisão bibliográfica sobre a area de visualização de informação aplicada a séries temporais.

Neste capítulo também são apresentadas técnicas de projeção multidimensional como forma de gerar representações visuais de conjuntos de dados.

Revisão bibliográfica sobre mineração de dados aplicada a séries temporais.

Neste capítulo também são apresentados conceitos e tarefas de mineração utilizadas para o desenvolvimento deste projeto.

Ferramenta proposta e implementada, e os resultados obtidos com o seu uso em diferentes conjuntos de séries.

Por fim, apresenta-se as conclusões desse projeto de mestrado, caracterizando as contribuições e limitações do trabalho, bem como sugestões de desenvolvimentos futuros desta abordagem.

Seres humanos estão sempre procurando por estruturas, características, padrões, tendências, anomalias, e relacionamentos em dados.

No entanto, esta nem sempre é uma tarefa fácil, o que motivou o surgimento de uma nova area conhecida como visualização, que procura na visão humana um auxílio para esta busca.

A visualização tem por objetivo a criação de modelos gráficos e representações visuais de dados, com o objetivo de apoiar a interação do usuário com estes dados, facilitando a exploração e aquisição de informações uteis neles contidas.

Visualização é uma sequência de mapeamentos ajustáveis de dados para uma representação visual, de modo a possibilitar a interação do usuário com o espaço de informação, objetivando o que foi chamado de cristalização do conhecimento.

Esta sequência de mapeamentos encontra-se reproduzida.

Esse modelo de referência busca retratar os componentes essenciais de uma visualização.

No primeiro passo os dados brutos (coletados ou gerados por algum processo) são transformados num conjunto de relações, que são estruturadas e mais facilmente mapeadas para formas visuais.

Um segundo passo prevê a escolha de estruturas visuais para mapear essas tabelas de dados, que utilizam marcas e propriedades gráficas para mapear a informação contida nos dados.

Para finalizar, o usuário deve ser capaz de interagir com as visões para controlar a quantidade de informação exibida na tela e para alterar as propriedades da visualização.

A interação do usuário com o espaço de informação retratado pelas visões apóia a percepção de estruturas interessantes, favorecendo a aquisição de conhecimento.

Modelo de referência de visualização de Card.

E possível destacar duas linhas na area de visualização, a Visualização Científica e a Visualização de Informação.

A Visualização Científica, em geral, cria modelos gráficos de dados do mundo físico o corpo humano, a terra, moléculas, e outros.

Mesmo que a visualização gerada mostre alguma abstração do espaço físico, a informação é inerentemente geométrica.

Como exemplo, pode-se citar uma visualização da concentração de ozônio na atmosfera, que pode ser baseada numa representação física D da Terra.

As informações de natureza não-física, como dados financeiros, informações de negócio, coleções de documentos, e outras concepções abstratas, também podem ser representadas por modelos gráficos.

A Visualização de Informação manipula tipos de dados que não possuem um mapeamento espacial obvio.

Assim, um desafio da Visualização de Informação é criar novas metáforas visuais capazes de representar esses dados abstratos.

A visualização de séries temporais enquadra-se na área de Visualização de InformaÇão, pois requer a criação de metáforas visuais.

Atualmente, existem várias técnicas de visualização de séries temporais.

Isso é plausível e altamente esperado já que elas ocorrem várias areas, como em biologia, finanças, geologia, análise de movimentos humanos, entre outras e, consequentemente, é um tipo de dado de grande importância.

No entanto, a visualização de séries temporais é de extrema dificuldade pela alta dimensionalidade desses dados.

Técnicas de visualização de séries temporais encontradas na literatura.

É apresentado o conceito de projeções multidimensionais, abordagem utilizada neste projeto para criar metáforas visuais para conjuntos de séries temporais.

Uma das formas mais simples e antiga de visualizar séries temporais é o gráfico de linha, obtido pela ligação de segmentos de reta unindo os pontos que representam os dados.

Gráficos comunicavam informações melhor do que tabelas de dados.

Gráficos de séries que registram a importação e exportação da Inglaterra versus Dinamarca e Noruega entre 1700 a 1780.

A área entre as curvas foi enfatizada para representar o balanço comercial.

Balanço comercial da Inglaterra vs.

Dinamarca e Noruega durante 1700 a 1780.

Mas, essa aplicação da visualização nem sempre é fácil ou direta.

Muitas das técnicas tradicionais, como o gráfico de linha, não são escaláveis, do ponto de vista visual, para volumes de dados muito grandes.

O problema é ilustrado e mostra uma visualização de séries pelo tradicional gráfico de linhas, a sobreposição de elementos visuais é tão grande que inviabiliza a sua interpretação.

Entre os problemas associados ao uso de técnicas de visualização para conjuntos de dados volumosos estão, Visualização do preço de 1430 ações durante 5semanas.

Perda de velocidade e interação Como boa proporção do tempo de computação é gasto na visualização dos elementos, quando o conjunto de dados cresce o tempo necessário para completar o desenho desses elementos cresce proporcionalmente, o que reduz o tempo de resposta da aplicação e dificulta o uso de técnicas de interação.

Oclusão visual A oclusão ocorre quando dois ou mais elementos visuais se sobrepõem, obstruindo sua percepção, dificultando a interpretação da visualização e impedindo o reconhecimento de relações e detalhes.

A oclusão é agravada proporcionalmente a quantidade de itens exibidos.

Outra questão é a necessidade de evidenciar certas características ou padrões nas séries, o que nem sempre é fácil em técnicas como o gráfico de linhas.

Em vista destas dificuldades e interesses existem diversos trabalhos para visualização de séries temporais, que serão destacados nas seções seguintes.

Espirais têm sido utilizadas para evidenciar padrões periódicos em séries temporais.

Uma primeira técnica usou espirais para destacar atributos seriais ao longo do eixo espiral e periódicos ao longo do eixo radial.

Estruturas como círculos ou barras tridimensionais são dispostas nas intersecções dos eixos espiral e radial.

A técnica é ilustrada em dados sobre o consumo da planta chamada Baphia Capparidifolia por chimpanzés em uma reserva na Tanzânia, durante os anos de 1980 a 1988.

Cada volta na espiral representa um ano e cada eixo radial um mês.

O mês de Janeiro começa no que seria horas em um relógio, e o sentido é anti-horário.

A área dos círculos é proporcional ao consumo daquele mês.

Nota-se um maior consumo da planta no período chuvoso, que vai aproximadamente de outubro a abril.

No entanto, essa técnica faz um uso exagerado de estruturas tridimensionais em sua extensão para visualizar mais de uma série temporal.

Ela também não é adequada para séries muito longas e pode gerar oclusão visual para séries com ciclo periódico longo.

A técnica Spiral Graphs também utiliza espirais para visualização de séries.

Nesta técnica, atributos como cor, textura e espessura das linhas da espiral são utilizados para mapear os valores dos dados.

Se o tamanho do cilo periódico da série é desconhecido é possível animar a espiral, mudando continuamente o tamanho do ciclo, usando a habilidade visual para detectar o tamanho do período.

Já a extensão chamada Multiple Spiral Graphs visa suportar a comparação de múltiplas séries.

Esta técnica para visualização de dados que registram o consumo de energia de uma cidade da Holanda a cada 15 minutos durante o ano de 1997.

Cada volta da espiral representa o período de uma semana.

As cinco areas mais densas na espiral representam o aumento do consumo de energia durante os dias uteis da semana.

Esta segunda técnica é mais adequada para séries longas e/ou com ciclos periódicos longos.

Uso de espirais para visualização de séries temporais.

Apesar do uso de espirais ser muito interessante para a visualização de séries, essa abordagem somente é adequada para séries temporais periódicas.

O projeto TimeSearcher for Time-Series Data desenvolvido no laboratório de Interação Humano-Computador da Universidade de Maryland, busca desenvolver ambientes de consulta e exploração interativa de conjuntos de séries.

Duas ferramentas desenvolvidas no ambito deste projeto são descritas a seguir.

O TimeSearcher1 é uma ferramenta de visualização exploratória de séries, cujo principal atrativo é o uso de timeboxes.

Timeboxes são regiões de consultas visuais retangulares desenhadas diretamente sobre o gráfico de linha das séries.

A extensão do eixo x especifica o período de tempo de interesse, e a extensão do eixo y especifica o intervalo de valores permitidos para aquele período de tempo.

Múltiplos timeboxes podem ser utilizados para especificar consultas conjuntivas.

Séries devem obedecer a todas as restrições estabelecidas pelos timeboxes para serem inclusas no resultado.

Uso de múltiplos timeboxes regiões em verde agu na ferramenta TimeSearcher1.

Ao contrário de algoritmos convencionais de busca por similaridade em séries, que precisam que uma série de consulta inteira seja fornecida, esta ferramenta permite a flexibilidade de se especificar o comportamento desejado somente em algumas regiões de interesse.

A principal extensão de uma segunda ferramenta, chamada TimeSearcher2, em relação a primeira, é a busca por padrões internos as séries, especificada por uma estrutura chamada searchbox.

O usuário seleciona um padrão, primeiro selecionando uma unica série temporal, e então desenhando uma searchbox (região em vermelho) que confina o padrão.

A searchbox também é associada a um slider de tolerância.

Ativada a busca, a ferramenta irá procurar por padrões similares ao padrão de consulta, conforme a tolerância permitida, em todas as séries do conjunto.

No entanto, essa busca não é eficiente, pois é sequencial e a medida que quantifica a similaridade entre dois padrões é a distância Euclidiana.

Como discutido no próximo capítulo, essa distância é sensível a artefatos como ruído e distorções no eixo temporal.

O grande problema da abordagem dessas ferramentas é a necessidade de conhecimento prévio sobre o conjunto de dados, pois o usuário deve saber qual seria um padrão interessante a ser procurado.

O trabalho chamado Cluster and Calendar based Visualization of Time Series Data busca apresentar padrões presentes nos dados por meio de um calendário.

Primeiramente, os dados a serem analisados devem ser subdivididos de forma que cada série resultante englobe somente uma escala no calendário diária, semanal, mensal, et.

Um segundo passo aplica um clustering para agrupar series similares.

Os padrões encontrados pelo clustering são, então, visualizados.

Nesta visualização cada cluster é representado pela série média das séries que o compõem, e a cor de cada dia irá mapear o cluster ao qual a série daquele dia pertence.

Visualização baseada em clustering e calendário para séries temporais que registram o número de empregados presentes em uma determinada hora do dia em uma empresa holandesa.

Essa técnica é limitada a dados que apresentam alguma regularidade imposta por dependência social ou financeira ao calendário.

Essa proposta também é de pouca utilidade para dados cujos padrões não são apresentados em uma escala específica (diária, por exemplo).

Outra desvantagem é a necessidade de algum conhecimento prévio sobre os padrões presentes nos dados para escolher, por exemplo, o número de clusters a serem encontrados.

Técnicas de projeção geométrica suportam usuários na tarefa de procura por projeções informativas de conjuntos de dados multi-dimensionais.

A técnica clássica chamada Coordenadas Paralelas mapeia o espaço m-dimensional dos dados em um display bidimensional pelo uso de m eixos equidistantes, paralelos a um dos eixos do display.

Os eixos correspondem aos atributos, e são linearmente escalados do mínimo para o máximo valor do atributo correspondente.

Cada instância do conjunto de dados é apresentada como uma linha poligonal, que intercepta cada um dos eixos no ponto correspondente ao valor daquele atributo.

Apesar do conceito básico ser bastante simples, essa é uma poderosa técnica para a identificação da distribuição dos dados e de correlações entre atributos.

Cruzamentos de linhas poligonais no formato de um "X", por exemplo, indicam uma correlação inversa entre os atributos.

No entanto, como as linhas poligonais podem se sobrepor, o número de elementos que podem ser exibidos simultaneamente sem oclusão visual é limitado a cerca de 1000 itens.

Para minimizar este problema, podem ser usadas funcionalidades como cores para destacar itens de dados, ou técnicas de interação, como zoom, e de filtragem.

Outro problema relevante é determinar uma ordenação representativa dos eixos.

Séries temporais também podem se beneficiar de visualizações geradas por Coordenadas Paralelas.

Para tal, cada eixo deve mapear um instante do eixo temporal das séries, e estes eixos devem seguir a ordenação natural do eixo temporal.

No entanto, séries temporais têm, em geral, uma alta dimensionalidade, o que torna inviável a aplicação direta de técnicas de projeção geométrica as séries temporais.

A técnica D Time Wheel busca superar tais problemas.

Essa técnica visa à análise de séries multivariadas, cuja característica é a presença de múltiplos atributos.

Uma série multivariada sobre condições meteorológicas, por exemplo, pode conter três atributos multivariados para um mesmo instante no eixo temporal, temperatura, umidade e quantidade de chuva.

O eixo central representa o atributo temporal de referência, e os atributos dependentes são arranjados ao redor dele.

De forma similar a técnica Coordenadas Paralelas, um segmento de linha colorido entre dois eixos faz a conexão entre um instante no tempo e o valor correspondente para um atributo naquele instante.

Os eixos dos atributos também possuem um marcador (pequeno disco em azul) que oferece uma indicação visual da média dos valores daquele atributo.

Também é possível dispor os planos de forma que dois deles fiquem com um ângulo de 180.

A análise desses atributos adjacentes torna-se mais fácil com essa disposição.

O D Time Wheel promove a identificação da distribuição de valores para um determinado atributo e de relações entre os atributos.

No entanto, permite visualizar uma série multivariada por vez.

Utiliza-se o conceito de layouts baseados na ìmportância da série temporal para visualização de grandes coleções de séries.

Séries individuais são visualizadas como gráficos de barras, já os conjuntos delas são arranjadas num layout de preenchimento de espaço que reflete a importância relativa de uma série dentro da coleção.

A percepção de importância de uma série no layout é mapeada para duas propriedades, posição e tamanho.

Séries temporais no topo e a esquerda são ditas mais importantes, e quanto maior a area reservada para a série maior a sua importância.

A medida de importância de uma série é dependente da aplicação e deve ser selecionada por um especialista do domínio.

No entanto, os autores implementaram algumas medidas de importância básicas, como agregações (média, soma, mínimo, máximo), que são adequadas para diversas aplicações.

Esse trabalho pode visualizar também coleções estruturadas de séries, que possuem uma organização hierárquica.

A abordagem de preenchimento de espaço garante a não sobreposição das séries, mas o número de séries que podem ser inspecionadas simultaneamente ainda é limitado.

Layout gerado por esta técnica para séries referentes a vendas de produtos.

Técnica de mapeamento em layouts baseados em importância para 19 séries sobre vendas de um produto.

O produto A tem a maior média de vendas, importância de acordo com este contexto, sendo mapeado no topo.

Neste projeto de mestrado foi utilizada a abordagem de projeções multidimensionais para criar mapas para conjuntos de séries temporais.

A representação visual gerada por projeções multidimensionais é capaz de descrever visualmente e eficientemente a distribuição de dados multidimensionais volumosos.

Uma série temporal consistindo de m observações pode ser interpretada como um ponto definido em um espaço m-dimensional.

Uma forma de visualizar um conjunto desses pontos consiste em projetá-los em um espaço de dimensionalidade ou 3, construindo, a partir da projeção, uma representação visual do conjunto de séries.

Existem diversas técnicas de projeção multidimensional, sendo que todas elas buscam projetar os dados definidos em um espaço de dimensionalidade alta para um espaço dimensional, na medida do possível retendo, no espaço projetado, as relações de distância observadas entre os itens de dados no espaço original.

A seguir tem-se a definição formal de uma técnica de projeção multidimensional, para o caso específico.

Projeção Multidimensional, um conjunto de dados m-dimensional e uma medida de dissimilaridade entre instâncias m-dimensionais dos dados.

O resultado da projeção é um conjunto de pontos, cada um representando uma instância dos dados, cujas coordenadas podem ser usadas para gerar uma representação gráfica.

A similaridade é expressa por meio da vizinhança espacial entre os elementos na projeção, permitindo utilizar nossa habilidade de interpretação visual para analisar os dados.

Essas representações fornecem uma visão geral dos dados que favorece a identificação de elementos com padrões similares/dissimilares, provendo um ponto de partida para uma exploração mais detalhada.

No entanto, visualizar os dados projetados como pontos no plano pode comprometer a interpretação e exploração de dados similares.

Para ressaltar a percepção de vizinhança é possível conectar os pontos segundo algum critério, ou gerar uma triangulação.

Outro recurso visual interessante é o mapeamento de informações adicionais, que por exemplo se existir uma classificação dos dados pode-se mapear a classe para a cor ou o tamanho dos marcadores gráficos, que representam os pontos.

Representação gráfica de uma projeção multidimensional do conjunto de séries Cylinder-Bell-Funnel (CBF).

A cor dos círculos mapeia a classe a qual a série pertence e a triangulação de Delaunay dos pontos foi utilizada.

Ilustra-se a utilidade de projeções para identificar visualmente a distribuição de padrões nos dados, pois o grau de proximidade física entre dois pontos representa o grau de similaridade entre os dois itens de dados por eles representados.

Um fato interessante é a localização de uma série temporal da classe cylinder junto às séries da classe funnel.

Fato explicado pelo declive com certo grau de suavidade (característica da classe funnel), onde deveria ser encontrada uma queda brusca (característica da classe cylinder).

Como discutido, as projeções multidimensionais oferecem grandes possibilidades na visualização de conjuntos de séries.

É necessário fornecer uma medida de dissimilaridade entre as instâncias m-dimensionais.

Dessa forma, a matriz de distâncias é a base para a projeção.

Dado um conjunto de séries, uma matriz de distância contém a distância entre os pares de séries.

Nesta tabela a expressão representa a distância entre as séries temporais de índices, segundo alguma métrica de dissimilaridade.

A definição de funções de distância para 1 O CBF é um conjunto de séries temporais classificadas em três classes, cylinder, bell e funnel.

Contém 100 séries, de tamanho 128, de cada classe.

Projeção multidimensional para o conjunto de séries CBF, cor das classes, cylinder (azul), bell e funnel.

Séries temporais é tratada no próximo capítulo, sendo que sua escolha é determinante para a qualidade da projeção.

No ambito de nosso grupo de pesquisa diversas técnicas de projeção multidimensional vêm sendo investigadas e incorporadas à ferramenta denominada Projection Explorer (PEX), inicialmente desenvolvida para visualização exploratória de coleções de documentos.

A seguir são apresentadas duas técnicas desenvolvidas para a ferramenta PEX, que foram utilizadas neste trabalho, Interactive Document Map (IDMAP) e Least Square Projection (LSP).

A maior vantagem dessas técnicas em comparação a abordagens anteriores é o balanço obtido entre escalabilidade e precisão.

Elas são rápidas o suficiente tratar conjuntos de dados grandes a taxas interativas, enquanto retêm alta precisão.

A técnica Interactive Document Map (IDMAP) gera projeções multidimensionais segundo uma abordagem em duas etapas, Projeção inicial dos dados com uma técnica de projeção rápida.

Duas alternativas foram utilizadas, as técnicas Fastmap e NNP, descritas a seguir.

Aperfeiçoamento da projeção, recuperando parte da informação perdida na primeira etapa com a técnica Force Scheme.

Apesar de geralmente apresentar bons resultados, a IDMAP possui um custo computacional alto.

A técnica de projeção multidimensional Fastmap busca projetar os pontos em um espaço m-dimensionais, em p direções mutuamente ortogonais.

Essa técnica projeta recursivamente os objetos em p hiperplanos ortogonais.

A idéia central é projetar os objetos em uma linha selecionada.

Primeiramente, para cada hiperplano é necessário selecionar dois objetos pivôs.

Os objetos serão projetados na linha definida por esses objetos pivôs.

A projeção de um objeto nesta linha é calculada pela Lei dos Cossenos, Definição 22.

Lei dos cossenos, Em qualquer triângulo, a lei dos cossenos afirma que, Ilustração da lei do cosseno.

A Equação 21 pode ser manipulada para determinar a posição, a coordenada do objeto para aquele hiperplano, A Equação 2permite mapear os objetos O na linha, preservando as relações de distância do espaço original.

Se o objeto estiver mais próximo do pivô terá um valor pequeno.

Caso contrário, terá um valor maior.

A escolha dos pivôs é baseada na matriz de distâncias.

Esses objetos devem ser o mais distante possível entre si para obter boas projeções.

Apesar da busca pela maior distância possuir complexidade, os autores propuseram uma heurística que executa uma busca aproximada com complexidade, um objeto qualquer é inicialmente escolhido.

Em seguida procura-se o objeto mais distante dele de acordo com a matriz de distância, utilizado esse objeto encontrado procura-se o mais distante dele.

Esses dois ultimos objetos serão os pivôs.

A Equação reduz a dimensionalidade.

Desta forma, basta aplicar recursivamente esta equação para obter a dimensionalidade desejada.

As coordenadas armazenam as coordenadas do objeto para cada dimensão da recursão.

Falta determinar como as novas dissimilaridades são calculadas entre os objetos projetados num hiperplano, para aplicar a recursão.

Projeção no hiperplano.

A dissimilaridade é calculada da Equação, A Equação permite atualizar os valores da matriz de projeção, que agora armazena as dissimilaridades a serem utilizadas na próxima recursão.

Essa nova dissimilaridade permite a projeção em uma segunda linha no hiperplano H, ortogonal.

Portanto é possível aplicar estes passos recursivamente quantas vezes forem necessárias para qualquer valor.

O Algoritmo básico da técnica Fastmap é apresentado em Algoritmo 1.

Apesar do Fastmap apresentar complexidade, há uma perda de informação considerável quando usada para criar projeções bidimensionais.

A técnica de projeção multidimensional Nearest Neighbors Projection (NNP) busca preservar as relações entre vizinhos locais no espaço multidimensional no espaço projetado.

Para preservar essa vizinhança local, as posições dos dois vizinhos mais próximos no espaço projetado já projetados, determinam a posição projetada do novo ponto.

Seja o subconjunto de pontos já projetados.

No caso dos círculos serem tangentes, o unico ponto de intersecção é utilizado.

Quando duas intersecções existem, escolhe-se aleatoriamente uma delas.

Quando não existem intersecções, um ponto intermediário entre os centros é utilizado, o qual é determinado pelo raio dos dois círculos e pela posição relativa entre eles.

Casos possíveis para a inexistência de intersecções.

O Algoritmo mostra o algoritmo básico para esta técnica.

Casos de intersecção na projeção NNP.

Para um conjunto de dados com instâncias, essa técnica possui complexidade quando a busca pelo vizinho mais próximo é sequencial.

Se forem utilizadas estruturas de dados para acelerar essa busca, a complexidade pode cair.

Algoritmo Nearest Neighbors Projection (NNP).

A técnica chamada Force Scheme para melhorar as projeções por meio de uma métrica para avaliar a qualidade da projeção.

Essa abordagem busca estabelecer uma relação constante entre as distâncias no espaço original e no espaço projetado para todos os pares de pontos, usando forças de atração e repulsão entre os pontos.

A base para essa abordagem é a seguinte, para cada ponto projetado, calcula-se um vetor.

A força dessa pertubação depende da relação entre as distâncias no espaço original e no espaço projetado para o par de pontos e é expressa pela Equação, onde representam a máxima e a mínima distância entre os objetos no espaço original.

No entanto, é necessário trabalhar com distâncias normalizadas para evitar inconsistências derivadas da diferença entre as faixas de valores do espaço multidimensional original e do espaço projetado.

Para melhorar o desempenho, o processo de normalização é aplicado somente uma vez para o espaço original e uma vez para o espaço projetado, para cada iteração.

O Algoritmo mostra os passos do Force Scheme.

A principal desvantagem desse método é sua complexidade, pois o posicionamento de cada ponto é alterado.

Apesar disso, a abordagem acaba convergindo em um número baixo de iterações, pois os pontos já foram projetados com uma técnica rápida e que busca preservar as distâncias (Fastmap ou NNP).

Quando conjuntos de dados possuem um agrupamento inerente, considerar relacionamentos entre objetos pertencentes a diferentes grupos no processo de projeção pode distorcer a projeção final.

A técnica Least Square Projection (LSP) busca superar este problema, definindo uma vizinhança para os objetos no espaço, a qual é utilizada para projetar um objeto no espaço, de modo que ele seja posicionado no centro de gravidade das projeções dos seus vizinhos mais próximos no espaço. Essa abordagem é realizada em três passos.

Primeiro, define-se uma relação de vizinhança entre os objetos.

Depois, uma lista de pontos, chamada de pontos de controle, é projetada por um método de projeção convencional como o Fastmap.

Por fim, constrói-se um sistema linear esparso baseado nas relações de vizinhança e nas coordenadas cartesianas dos pontos de controle projetados.

A construção desse sistema linear, bem como a definição dos pontos de controle e da vizinhança dos objetos, são discutidos a seguir.

Uma vizinhança define uma lista de objetos vizinhos para cada objeto.

Cada lista é criada com o algoritmo vizinhos mais próximos, que busca os (parâmetro fornecido pelo usuário) objetos mais próximos do objeto, segundo a função de distância no espaço multidimensional.

No entanto, é necessário estabelecer a vizinhança dos objetos de forma a assegurar a seguinte condição de sobreposição, Definição 23.

Condição de Sobreposição.

Essa condição assegura propriedades sobre as relações de vizinhança como se a mesma fosse uma malha com um unico componente conexo.

Se as relações de vizinhança forem examinadas e perceber-se que algum objeto está desconexo dos demais, deve-se incluir na sua lista de vizinhos um novo vizinho que faça parte do componente conexo principal.

Observa-se que o valor não deve ser muito alto, para que objetos distantes não sejam considerados na projeção de um ponto qualquer, contrariando a idéia de vizinhança.

Definidas as relações de vizinhança constrói-se um sistema linear, como segue.

As coordenadas da projeção podem ser calculadas pela seguinte equação, Segundo a Equação 25, a projeção de cada objeto será o centróide das projeções dos objetos de sua vizinhança (outras propriedades podem ser encontradas em Floater).

A equação pode ser expressa como um conjunto de sistemas lineares, cujas soluções são as coordenadas dos objetos projetados, onde são vetores de tamanho que contém as coordenadas dos objetos projetados para cada uma das dimensões, e é a matriz cujas entradas são dadas, onde as entradas l juntas representam a Equação 25.

No entanto, a matriz não contém nenhuma informação geométrica, impossibilitando usar soluções do sistema linear para obter as coordenadas dos objetos projetados.

De forma a possibilitar esse uso, a informação geométrica é adicionada por meio de pontos de controle.

As coordenadas projetadas desses pontos são obtidas por técnicas como o IDMAP.

Os nc (parâmetro definido pelo usuário) pontos de controle são inseridos no sistema como novas linhas na matriz.

As coordenadas geométricas da projeção dos pontos de controle são adicionadas do lado direito do sistema, gerando um vetor não-nulo b.

Dessa forma, reescreve-se a Equação 26 na forma da Equação 28, onde é uma das coordenadas da projeção do ponto de controle.

Esse sistema linear pode ser resolvido aplicando-se a técnica dos mínimos quadrados, que tenta minimizar o valor.

A solução que minimiza esse valor é dada, que é um sistema simétrico e esparso, o que facilita sua solução.

A escolha do conjunto dos nc pontos de controle deve ser cuidadosa, pois afeta a qualidade da projeção.

Eles devem ser escolhidos de forma a gerar uma boa representação da distribuição dos agrupamentos dos objetos.

A escolha pode ser feita de duas formas, aleatória ou baseada em agrupamentos.

A abordagem aleatória é mais rápida, porém não traz bons resultados.

Já a outra abordagem divide o conjunto de objetos em nc agrupamentos, e escolhe o medóide (objeto mais próximo do centróide) de cada agrupamento como sendo o ponto de controle.

Apesar da maior complexidade, os pontos de controle assim definidos representam melhor os dados.

O LSP emprega o método de k-medoids no agrupamento, que ao contrário do k-means não é afetado pela existência de outliers, pois, o agrupamento é representado por um de seus objetos, e não pelo seu centróide.

Outra vantagem é que somente as distâncias entre os objetos e os medóides são necessárias, informação já presente na matriz de distância.

Após obter o conjunto de pontos de controle, estes devem ser projetados no espaço para que as coordenadas dessas projeções sejam usadas na construção dos sistema linear.

A qualidade da projeção gerada com o LSP é fortemente afetada pelo posicionamento desses pontos de controle, pois as coordenadas das projeções desses pontos serão usadas para projetar os demais objetos.

Nesta seção prossegue-se com a análise do conjunto de dados CBF, para efeito de comparação entre as técnicas IDMAP e LSP.

Uma das principais diferenças entre ambas é a formação de agrupamentos.

A LSP tende a favorecer a formação de agrupamentos, por projetar os dados com base em relações de vizinhança locais e pontos de controle, que evidenciam a distribuição dos dados.

Já a IDMAP não evidencia as fronteiras entre possíveis agrupamentos nos dados, o que a torna mais indicada para dados que não estão necessariamente divididos em grupos.

Tendência da LSP de formar agrupamentos.

Formação de agrupamentos, projeção multidimensional para o conjunto de séries CBF.

As técnicas também se diferenciam no tratamento outliers, que são instâncias que apresentam uma grande distância em relação às demais.

Mostra-se uma série que apesar de classificada como sendo da classe cylinder, não apresenta o comportamento típico deste tipo de classe.

A técnica IDMAP mostrou-se sensível a este outlier, ao contrário da técnica LSP.

A tolerância a presença de outliers pela LSP se explica pelo uso de relações de vizinhança locais e pontos de controle no processo de projeção, pois dessa forma esse outlier só é comparado aos seus vizinhos mais próximos.

A tendência de formar agrupamentos e a tolerância a outliers torna a LSP superior na maioria das aplicações de projeções.

No entanto, a IDMAP é mais indicada quando o usuário não busca identificar agrupamentos nos dados.

Quanto a velocidade, a técnica LSP é superior, pois a técnica IDMAP possui complexidade.

Projeção multidimensional para o conjunto de séries CBF com presença de outlier.

Este capítulo fornece uma introdução a área de Visualização de Informação aplicada a análise de séries temporais.

Também é apresentada a abordagem de projeções multidimensionais adotada neste projeto para gerar visualizações de conjuntos de séries.

No próximo capítulo, será apresentada a análise de séries temporais sob o enfoque de Mineração de Dados.

Séries temporais podem ser entendidas como uma coleção de observações sequenciadas no tempo.

Elas são extremamente comuns, podendo ser encontrados em diversos domínios, como na biologia, finanças, geologia, robótica, e outras areas.

No entanto, existem várias dificuldades em se tratando de manipular séries temporais, Alta dimensionalidade, Séries temporais possuem uma dimensionalidade inerente, equivalente ao seu tamanho.

Quanto mais longa uma série, mas difícil é a sua análise, principalmente se o usuário está interessado em analisar um grande número de séries longas.

Grandes conjuntos de dados, Séries temporais também são conhecidas por seu volume.

Conjuntos de séries com vários gigabytes são comuns.

Como um exemplo típico, considere o projeto de astrofísica MACHCO, que contém mais de um terabyte de dados, e é atualizado a uma taxa de vários gigabytes por dia.

Subjetividade, Como será discutido, a definição de similaridade entre séries temporais distintas depende do usuário, do domínio e da tarefa em questão, e deve ser possível lidar com essa subjetividade.

Diversidade, Séries temporais podem ser encontradas em diferentes formatos, registradas com diferentes taxas de amostragem, com ruído, valores ausentes, etc.

Essas características as tornam bastante diversas, dificultando a manipulação.

Em vista destas dificuldades, a mineração de séries temporais tem sido largamente empregada para extrair conhecimento de tais tipos de dados.

Neste capítulo serão apresentados conceitos, tarefas e aplicações em mineração de séries temporais.

É apresentada a grande área chamada Mineração de Dados M.

Introduzida a grande area, as seções seguintes são dedicadas a especificar a aplicação de MD para séries temporais.

Desta forma, são apresentados conceitos referentes a séries temporais.

Já na Seção 3são descritas operações de pré-processamento típicas.

Na Seção 35 são apresentadas diferentes métricas para quantificar a similaridade entre séries.

Por fim, na Seção 36 são descritas algumas tarefas de MD para extração de padrões em séries.

Dados provenientes de vários domínios são frequentemente gravados, capturados e armazenados, esperando-se que algum conhecimento possa ser obtido deles, seja procurando por estruturas, características, padrões, anomalias ou relacionamentos.

Devido ao avanço tecnológico que permite armazenar quantidades cada vez maiores de dados, as bases de dados não param de crescer.

No entanto, extrair conhecimento é uma tarefa difícil, e se isto não for feito, o armazenamento torna-se inútil.

A dificuldade em analisar e compreender grandes quantidades de dados motiva diversos estudos sobre processos automáticos de extração de conhecimento de bases de dados, os quais se inserem na area de pesquisa chamada Mineração de Dados M.

O processo de descoberta de conhecimento é intensamente interativo e iterativo, e demanda muitas decisões importantes do usuário.

Uma das definições de MD mais aceitas por pesquisadores da área e de Fayyad, "Extração de conhecimento de bases de dados é o processo de identificação de padrões válidos, novos, potencialmente uteis e compreensíveis embutidos nos dados".

Considerando essa definição, dividiu-se este processo em três grandes etapas pré-processamento, extração de padrões e pós-processamento.

Essa divisão também inclui uma fase anterior ao processo de MD, composta pela identificação do problema, e uma fase posterior, composta pela utilização do conhecimento.

Essa divisão do processo de MD é mostrada e, como pode ser visto, podem ocorrer múltiplos ciclos envolvendo as três etapas principais, justamente o que confere o caráter iterativo ao processo.

Etapas do processo de Mineração de Dados.

A fase de identificação do problema requer um estudo do domínio, que é imprescindível a fim de adquirir um conhecimento inicial e subsidiar todas as etapas posteriores do processo de MD.

Nesta fase também devem ser definidos os objetivos e metas a serem alcançados no processo de extração de conhecimento.

Já na etapa de pré-processamento os dados devem ser organizados para a extração de conhecimento.

Os dados podem prover de diferentes fontes, o que torna necessário a sua unificação em uma unica fonte, bem como sua adequação ao formato esperado pelos algoritmos da próxima etapa, a extração de padrões.

Outra atividade necessária é a limpeza, para retirar valores incorretos ou ausentes.

Os dados também podem conter ruído que deve ser removido, ou pode ser necessário transformá-los para salientar certas características de interesse.

Por ultimo, também pode ser necessário escolher um subconjunto representativo, reduzindo o número de instâncias e atributos, de acordo com restrições de espaço em memória ou tempo de processamento.

As atividades dessa etapa devem ser realizadas cuidadosamente, pois é fundamental garantir que as informações presentes nos dados brutos se mantenham nos dados amostrados.

A extração de padrões é a principal etapa do processo de MD, e é direcionada ao cumprimento dos objetivos definidos na etapa de identificação do problema.

Nesta etapa é realizada a escolha, a configuração e execução de um ou mais algoritmos para a extração de conhecimento.

Assim, essa etapa é dividida em três atividades, escolha da tarefa de MD a ser executada, escolha do algoritmo e extração dos padrões.

A escolha da tarefa é direcionada pelos objetivos do problema.

Em seguida é escolhido o algoritmo a ser utilizado, e seus parâmetros configurados, o que deve ser feito de forma bastante criteriosa para garantir a geração de um bom modelo de representação dos dados.

A ultima atividade, extração de padrões, consiste em aplicar o algoritmo de MD escolhido.

Na ultima etapa, o pós-processamento, os padrões obtidos na etapa anterior são analisados de forma a fornecer ao usuário somente os padrões mais interessantes.

Nesta etapa o usuário pode decidir extrair outros padrões, executando novamente o ciclo principal do processo de MD, eventualmente mudando a escolha de algoritmos e parâmetros.

Na fase de utilização do conhecimento, o conhecimento extraído nas etapas anteriores pode ser incorporado a algum Sistema Inteligente, ou ser utilizado diretamente pelo usuário final em algum processo de tomada de decisão.

Nesta seção são apresentadas as definições utilizadas ao longo deste trabalho.

A seguir tem-se a definição e notação de série temporal, sob um ponto de vista estatístico.

Variável aleatória, Uma variável aleatória é definida como uma função mensurável de um espaço de probabilidade para um espaço mensurável.

Espaço de probabilidade, Em teoria da probabilidade, o espaço de probabilidade é uma tripla na qual,O espaço amostral é um conjunto não vazio de todos os resultados possíveis de um experimento.

Certos subconjuntos do espaço amostral de um experimento são referidos como eventos.

Conjuntos de resultados sobre os quais é possível definir uma probabilidade.

A medida de probabilidade é uma função definida, que atribui a cada evento uma probabilidade.

Em termos práticos, uma variável aleatória é uma função determinística, que a realização de certo acontecimento aleatório associa um valor numérico.

Esse valor numérico adquire assim um caráter aleatório porque depende de uma tiragem aleatória.

Processo estocástico, Um processo estocástico é uma família de variáveis aleatórias sobre um espaço de probabilidade, indexada sobre elementos de um conjunto de parâmetros.

Processo com parâmetro discreto, processo com parâmetro contínuo.

O processo estocástico é uma variável aleatória, trata-se de uma função de dois argumentos.

Essa dependência indica que para cada fixo, obtém-se uma variável aleatória.

Por outro lado, para cada fixo, obtém-se uma função, ou seja, uma realização ou trajetória do processo, ou ainda, uma série temporal.

Ilustra-se três trajetórias estocásticas em instantes diferentes.

Um processo estocástico interpretado como uma família de séries temporais.

Em geral, as observações que caracterizam uma série temporal (realização) são igualmente espaçadas no tempo e assumem valores reais.

Essas realizações são normalmente designadas.

Porém, utilizaremos a notação para especificar uma série temporal discreta. No entanto, o interesse em mineração de séries temporais geralmente não está em propriedades globais das séries, mas em subseções locais, conhecidas como subsequências.

Abaixo tem-se a definição de subsequências.

Subsequência, Dada uma série temporal de tamanho, uma subsequência é uma amostragem de tamanho de posições contíguas.

Para extrair todas as subsequências de uma série temporal, utiliza-se uma janela de deslizamento.

Janela de Deslizamento, Dada uma série temporal, e o tamanho m das subsequências a serem extraídas, todas as possíveis subsequências podem ser extraídas pelo deslizamento de uma janela de tamanho, obtendo-se um conjunto de subsequências cujos offsets variam.


Uma série temporal T de tamanho 128, uma subsequência C.

A necessidade de quantificar a similaridade entre séries temporais ou subsequências é bastante recorrente em várias tarefas de mineração, e requer uma medida de dissimilaridade.

Medidas de dissimilaridade também são referenciadas na literatura como função de distância, definida a seguir, Definição 36.

Medida de dissimilaridade, D é uma função que tem como parâmetros C e M, duas séries temporais ou duas subsequências, e retorna um valor não-negativo R, que quantifica a dissimilaridade ou distânci de M para C.

Quanto menor o valor de R, maior a similaridade entre C e M.

Para as próximas definições é necessário que a função D seja simétrica, ou seja, D(C,M) = DM.

Existem vários tipos de medidas de dissimilaridade.

A mais clássica é a distância Euclidiana.

Esta medida exige que as duas séries C e M possuam o mesmo tamanho.

No entanto, outros tipos de distância permitem o cálculo da dissimilaridade entre séries de diferentes tamanhos.

Esta e outras funções são melhores apresentadas na Seção 35.

A função de distância permite identificar exatamente que subsequência é similar a outra subsequência, idéia expressa na definição de casamento elaborada por Lin Definição 37.

Casamento (match), Dado um número real positivo (chamado tolerânci e uma série temporal T contendo uma subsequência C começando na posição p e uma subsequência M começando em q, se D(C,M) então M é chamado de casamento da subsequência C.

Ao medir a distância entre duas séries temporais em sua forma original, sem um pré-processamento, pode-se obter resultados não-intuitivos, devido à presença de distorções nos dados.

No entanto, para a maioria dos problemas essas distorções não são significativas, e devem ser removidas por meio de um pré-processamento.

Nesta seção são discutidas três operações de pré-processamento para séries temporais.

Séries temporais podem oscilar tão rapidamente que tendências e outras características, se existirem, não são visíveis.

Técnicas de suavização são utilizadas para reduzir irregularidades (ruído) evidenciando o comportamento da série.

Uma das formas mais simples de suavização chamada Médias Móveis Simples (MMS) suaviza uma observação na série temporal calculando uma média aritmética da observação e das observações vizinhas, Na prática, o método de móveis simples não é utilizado frequentemente.

A MMS aplica pesos iguais as observações independente delas serem recentes ou não e requer a definição dos limites da vizinhança.

Este método também reduz o tamanho da série a ser suavizada em observações.

A Suavização Exponencial Simples é um método de suavização que aplica pesos exponencialmente decrescentes.

A atribuição de pesos a observações passadas decresce exponencialmente, atribuindo mais importância para observações recentes, sem descartar por completo observações antigas.

A Suavização Exponencial Simples pode ser descrita matematicamente pela Equação.onde é denominado valor exponencialmente suavizado, e é a constante de suavização, Quanto menor o valor de, maior será a suavização da série, pois um baixo valor de implica em atribuir pesos maiores às observações passadas, e qualquer função aleatória, no presente, exercerá um peso menor no cálculo da série suavizada.

Efeito da aplicação deste método.

Suavização Exponencial Simples.

A SES é muito utilizada, pois é de fácil entendimento.

Tem complexidade linear, oferece grande flexibilidade pela variação da constante de suavização.

A normalização é uma das tarefas de pré-processamento mais necessárias utilizadas, pois medidas de distância entre séries não-normalizadas produzir resultados errôneos.

Intuição visual da necessidade de normalizar as séries temporais antes de medir a distância entre elas.

As séries são similares em formato, mas possuem diferentes offsets.

Dessa forma, pequenas variações no offset rapidamente ofuscam qualquer informação sobre o formato das séries.

A distância computada entre séries não-normalizadas compara somente a média entre elas.

Já a distância computada entre séries normalizadas compara a similaridade entre o formato das séries.

Normalização de séries temporais.

As linhas em cinza representam a distância Euclidiana.

A normalização de uma série temporal consiste em subtrair de cada observação da série a sua média, e dividir pelo seu desvio padrão.

Após o que, a distribuição de frequência terá média zero e desvio padrão igual a 1.

A média de uma série temporal é estimada pela Equação.

Já o desvio padrão é estimado pela equação.

Um conceito importante sobre séries temporais é a sazonalidade, que pode ser definida da seguinte maneira, os dados de uma série apresentam padrões de comportamento que se repetem periodicamente.

Um exemplo é o aumento de temperatura nos meses de verão em uma série que registra temperaturas mensais.

O aumento de temperatura, neste caso, provavelmente vai se repetir em todos os meses de verão, independente do ano, refletindo a sazonalidade do clima.

A remoção dessa sazonalidade muitas vezes é um procedimento necessário, pois a presença de movimentos sazonais ofusca outros padrões não-sazonais importantes.

O Método dos Momentos Sazonais é um método não paramétrico para estimar e remover a componente sazonal de uma série.

Neste método os dados são arranjados em uma tabela, onde cada linha corresponde as observações de um ciclo sazonal e as colunas são as observações dentro daquele ciclo, como ilustrado.

Estimação não paramétrica da sazonalidade.

A partir da notação estima-se as médias mensais e os desvios padrões mensais, da seguinte forma, Para obter a série livre de sazonalidade deve-se subtrair de cada observação da série a sua média mensal, e dividir pelo desvio padrão mensal, A série apresenta, aproximadamente, média zero e variância unitária.

Dessa forma, esse método também promove a normalização das séries.

Aplicação desse método a uma série sazonal que representa a vazão média mensal da usina hidrelétrica de Furnas.

Método de Momentos Sazonais.

A maioria das tarefas de mineração em séries temporais envolve quantificar a semelhança entre séries temporais e subsequências, o que requer uma função para medir a (dis)similaridade entre duas sequências, de acordo com a Definição 36.

A seguir são apresentadas duas métricas de dissimilaridade muito utilizadas por pesquisadores da area, a distância Euclidiana e o Dynamic Time-Warping (DTW).

Também é apresentada uma terceira métrica, chamada Compression-based Dissimilarity Measure (CDM), utilizada para identificar similaridades estruturais.

Muitos trabalhos em séries temporais adotam a distância Euclidiana como medida de dissimilaridade.

A distância Euclidiana só pode ser medida em séries do mesmo tamanho, consistindo no cálculo da distância entre pares de pontos das duas sequências.

Distância Euclidiana, Dadas duas séries temporais de mesmo tamanho, a distância Euclidiana entre elas é definida como, Noção intuitiva da distância Euclidiana, que pode ser vista como a soma das linhas cinzas entre os pares de pontos.

O cálculo da distância Euclidiana tem complexidade, mas pode ser acelerado.

Quando ela é utilizada como sub-rotina em algoritmos de mineração como o de classificação, por exemplo, o interesse pode estar em conhecer a verdadeira distância entre duas séries somente quando ela é menor do que alguma tolerância.

Neste caso, pode-se acelerar o cálculo praticando o "abandono prematuro".

Abandono Prematuro, Durante o cálculo da distância Euclidiana, se a soma atual das diferenças quadradas entre os pares de observações exceder o valor de, então é possível abandonar o cálculo da distância, com a certeza de que o valor exato da distância excederia.

Abandono prematuro do cálculo da distância Euclidiana.

Apesar de ser simples de calcular, a distância Euclidiana produz resultados errôneos para séries temporais que são similares, mas que apresentam distorções no eixo do tempo.

DTW é uma medida de dissimilaridade mais eficiente nesse caso.

Ao contrário da distância Euclidiana, o DTW é baseado na idéia de alinhamentos não-lineares entre séries.

Alinhamentos não-lineares há muito são utilizados pelas comunidades de bioinformática e reconhecimento de fala.

Apesar das duas séries terem formas similares, elas não estão alinhadas no eixo do tempo.

A distância Euclidiana gera uma medida de dissimilaridade pessimista, já o DTW produz uma medida de dissimilaridade mais intuitiva devido aos alinhamentos não-lineares.

A seguir é apresentada uma breve revisão da idéia do DTW.

Para alinhar essas duas séries usando o DTW, constrói-se uma matriz de tamanho na qual o elemento de índice contém a distância entre as observações e Matriz de alinhamento para o cálculo do DTW.

A area em cinza mostra uma janela de alinhamento.

Dada essa matriz, o interesse é achar um caminho de alinhamento.

Caminho de alinhamento, O caminho de alinhamento P é um conjunto de elementos contíguos da matriz que definem um mapeamento.

Este caminho de alinhamento está sujeito a diversas restrições, Monotonicidade.

O caminho de alinhamento não pode voltar.

Continuidade.

Os elementos do caminho devem ser células adjacentes (incluindo células diagonalmente adjacentes).

Como consequência dessas duas restrições, a seguinte relação entre dois elementos consecutivos é assegurada, Restrição de limite.

Esta restrição garante que o caminho de alinhamento comece e termine nas células dos cantos diagonalmente opostos da matriz.

Além dessas restrições, uma prática comum é limitar o quanto o caminho de alinhamento pode se afastar da diagonal.

Janela de alinhamento.

Subconjunto de elementos da matriz.

O uso de janelas de alinhamento considera o fato de que distorções no eixo do tempo usualmente não são muito excessivas.

Existem várias razões para o seu uso, uma é que elas aceleram o cálculo do DTW.

No entanto, a mais importante é prevenir alinhamentos patológicos, nos quais uma pequena porção de uma série é mapeada para uma grande porção da outra série.

Duas janelas de alinhamento mais utilizadas, a Banda de Sakoe-Chiba e o Paralelogramo de Itakura.

A janela Banda de Sakoe-Chiba restringe os índices do caminho de alinhamento em que é uma constante que define o alcance da janela de alinhamento.

A area cinza da matriz representa a janela de alinhamento de Sakoe-Chiba.

Já o Paralelogramo de Itakura estabelece a região que o caminho de alinhamento pode visitar como sendo aquela formada pelas relações, é a expansão máxima da diagonal do paralelogramo.

Assim o alcance da janela de alinhamento formada pelo Paralelogramo de Itakura é uma função baseada nas Equações 31e 315, sendo denotada por R.

Janelas de alinhamento.

Existe um número exponencial de caminhos que obedecem as restrições e as janelas de alinhamento mencionadas acima.

No entanto, o interesse é achar apenas o caminho otimo, que minimize o total cumulativo da distância entre as séries.

Distância DTW, Dadas duas séries temporais, a distância DTW entre elas é o custo mínimo de todos os caminhos de alinhamento, Esse caminho otimo pode ser encontrado usando programação dinâmica, que estabelece uma relação de recorrência.

Essa relação define que a distância cumulativa é a soma da distância da célula atual e distância mínima cumulativa das células adjacentes, Além de detectar séries similares com distorções no eixo do tempo, o DTW também é capaz de calcular a distância entre séries de diferentes tamanhos.

No entanto, sua grande exatidão tem um preço.

Dependendo do tamanho das séries, o DTW pode ser centenas ou milhares de vezes mais lento que a distância Euclidiana, devido à sua complexidade computacional quadrática.

Devido ao custo elevado muitos trabalhos visam obter uma estimativa para a distância DTW, cujo cálculo não seja demorado, questão abordada na próxima seção.

Vários autores buscam maneiras de estimar a distância DTW de uma forma eficiente.

No entanto, qualquer estimativa para uma medida de similaridade deve atender duas características fundamentais, Deve ser fácil de calcular.

Uma estimativa que leva mais tempo para calcular do que a medida original obviamente não tem utilidade.

Deve obedecer a propriedade chamada limite inferior, que é extremamente importante e garante a qualidade da estimativa.

Limite Inferior, A estimativa para uma medida de similaridade entre duas séries temporais deve ser menor e o mais próxima possível da verdadeira distância entre as mesmas séries.

A relação apresentada garante a inexistência de falsos dissimilares no processo de busca.

Falsos dissimilares são séries que se qualificariam como similares segundo a distância original, mas que são distantes segundo a medida estimada.

Falsos dissimilares não são aceitáveis, pois ignoram séries possivelmente similares, comprometendo a qualidade do resultado.

No entanto, o limite inferior não garante a inexistência de falsos alarmes, que ocorrem quando séries indicadas como sendo similares segundo a medida estimada estão, na verdade, distantes.

Como falsos alarmes podem ser removidos posteriormente, eles podem ser tolerados, contanto que não sejam muito frequentes.

Quanto mais próxima for a estimativa da medida original desde que inferior à el, menor o número de falsos alarmes.

Resumindo, para buscar uma série de consulta em uma base de séries de acordo com uma tolerância usando uma estimativa da distância, realiza-se uma pré-seleção para obter um conjunto de possíveis resultados.

Uso de medidas de limite inferior para buscar séries similares a uma série de consulta dentro de uma base de dados.

Falsos alarmes são eliminados em uma fase de pós-processamento, na qual sua distância exata será calculada.

Portanto, um significativo aceleramento é alcançado calculado a distância exata (de cálculo demorado) somente para um subconjunto dos dados.

Com essa idéia em mente, definiu-se uma estimativa para o DTW, chamada LB Keogh, e comprovaram matematicamente que essa estimativa obedece a propriedade de limite inferior.

Os autores também comprovaram, por meio de avaliações em bases de dados, que essa estimativa se aproxima mais da distância DTW exata do que outras publicadas anteriormente.

Devido a essas características ela foi adotada neste trabalho.

A seguir é apresentada uma breve revisão da estimativa LB Keogh.

Dada uma série, são calculadas duas séries temporais.

No caso da banda de Sakoe-Chiba, é uma constante.

Já no caso do Paralelogramo de Itakura, é uma função baseada nas relações descritas.

Dessa forma, as séries U e L podem ser construídas com base em uma dessas janelas de alinhamento, e devem obedecer a propriedade criando um LB Keogh.

Envelopes para cálculo da estimativa.

Definidos, a estimativa de limite inferior LB Keogh é definida.

Esta função pode ser visualizada como a distância Euclidiana entre partes da série e o envelope.

Essa distância Euclidiana só será calculada para partes da série que não se encontrem dentro do envelope.

Função de Limite Inferior LB Keogh.

Métricas de dissimilaridade como a distância Euclidiana e o DTW não conseguem tratar todas as aplicações de séries temporais, pois detectam diferenças entre os formatos locais das séries.

Existem aplicações em que o interesse é em similaridades estruturais, que se manifestam nos padrões globais das séries.

Métricas de dissimilaridade estruturais, como o CDM, são adequadas para esse tipo de aplicação.

A medida CDM é baseada na complexidade de Kolmogorov, que busca quantificar a complexidade (quantidade de informação) de strings e outros objetos de forma objetiva e absoluta.

No entanto, a complexidade de Kolmogorov não é uma função computável.

Para definir a distância CDM, nos baseamos no fato de que algoritmos de compressão são capazes de fornecer um limite superior para a verdadeira complexidade.

Além de um algoritmo de compressão, para calcular essa medida entre duas séries é necessário, primeiramente, convertê-las para uma representação discreta.

A representação sugerida pelos autores é conhecida como Symbolic Aggregate approXimation, que converte uma série temporal em uma sequência de caracteres.

O SAX será apresentado, e assumindo um algoritmo de compressão e essa representação, define-se a seguir a medida de dissimilaridade CDM.

Um algoritmo de compressão é definido como o tamanho em bytes da compressão da string.

Essa distância é próxima de 1 quando são dissimilares, e próxima quando são similares.

Quanto melhor o algoritmo de compressão, melhor a aproximação para a verdadeira complexidade de Kolmo-CDM gorov.

A distância CDM tem a vantagem de ser extremamente rápida, mas requer séries temporais longas para produzir bons resultados.

Outra vantagem é que essa métrica é livre de parâmetros.

Nas seções seguintes são apresentadas algumas tarefas de mineração em séries temporais utilizadas neste projeto, representações de séries temporais, classificação e consulta por conteúdo.

Essas tarefas são muito utilizadas no processo de descoberta de conhecimento, como validação experimental ou como componentes em algoritmos complexos.

Alguns algoritmos e estruturas de mineração de dados escalam pobremente para dados com alta dimensionalidade.

Esse é o caso de séries temporais, cuja dimensionalidade é igual ao número de pontos amostrados no tempo (tamanho da série).

Tamanhos muito grandes tornam impraticável, em teoria, a aplicação de muitos algoritmos de mineração de dados.

Para resolver este problema muitas vezes gera-se uma representação de alto nível da série, de dimensionalidade menor do que a original, mas que suporte a execução das demais tarefas de mineração.

Uma definição formal encontra-se abaixo, Definição 314.

Representação de séries temporais, Dada uma série temporal contendo pontos, constrói-se um modelo com segmentos.

O principal objetivo é obter um modelo de representação, de menor dimensionalidade, mas que preserve as características da série original.

As representações são mais fáceis de armazenar, transmitir e analisar.

A escolha da representação afeta fortemente a eficiência das tarefas de mineração, de modo que um grande número de representações já foi proposto na literatura.

Uma visualização e breve descrição das principais representações para séries temporais podem ser vistas.

Representações de séries temporais.

A série original está em azul, e a representação em vermelho.

A maioria das representações apresentadas fornece valores contínuos, o que limita os algoritmos, estruturas de dados e definições aplicáveis.

Principais representações de séries temporais.

Na detecção de anomalias não é possível definir a probabilidade de observar uma determinada ocorrência, já que a probabilidade de observar qualquer número real é zero.

Tais limitações incentivam pesquisadores a considerar o uso de representações simbólicas para séries temporais, discretizando-as.

A representação discreta SAX é apresentada em detalhes a seguir.

Ela foi utilizada neste trabalho para calcular a medida de dissimilaridade CDM.

O SAX é um método de representação simbólica de séries temporais.

Essa representação transforma as séries, que possuem valores reais, em sequências de caracteres, preservando as características da série original.

O SAX permite que uma série de tamanho arbitrário seja reduzida a uma string de tamanho.

A representação simbólica é obtida por meio de três etapas, normalização, PAA e discretização.

A etapa de normalização consiste em aplicar a operação de pré-processamento discutida, obtendo-se séries temporais com média igual a 0 e desvio padrão igual a 1.

Já a segunda etapa, chamada PAA, é de fato outro algoritmo de representação de séries.

E nesta representação intermediária que acontece a redução de dimensionalidade.

A idéia básica é dividir uma série temporal de tamanho em segmentos de igual tamanho, reduzindo dimensionalidade.

Então, é calculada a média aritmética dos valores da série que estão dentro de cada segmento, e o vetor dessas médias torna-se a representação PAA.

Para calcular o vetor de segmentos para uma série temporal usa-se a Equação 323, A escolha do valor é extremamente importante, pois determina o grau da redução de dimensionalidade.

Como uma série que antes tinha dimensão terá uma representação de tamanho, tem-se um fator de agregação.

Quanto menor o valor, maior o fator de agregação e maior a redução de dimensionalidade.

Tendo transformado uma série na representação PAA, aplica-se a etapa de discretização para obter uma representação discreta, a representação do SAX.

Nesta etapa, cada segmento da representação PAA é transformado numa letra equiprovável.

Para gerar dessas letras equiprováveis deve-se escolher o tamanho a do alfabeto, que determina quais letras serão usadas no processo de discretização.

O tamanho do alfabeto é um inteiro arbitrário.

Para determinar que segmentos serão mapeados em que letras cria-se uma lista de breakpoints, de acordo com a Definição 315.

Dado que séries temporais normalizadas têm uma curva de distribuição de probabilidade Gaussiana, é possível definir a areas de igual tamanho sob a curva de distribuição.

Definição 315.

Breakpoints, é uma lista ordenada de números tal que a area sob a curva Gaussiana seja igual de forma a gerar símbolos equiprováveis.

Valores da lista de breakpoints.

Uma vez obtidos os breakpoints determina-se o mapeamento de segmentos em símbolos.

Os breakpoints dividem o eixo, e os segmentos contidos antes do primeiro breakpoint serão mapeados.

Já os segmentos que ocorrem após são mapeados.

Tabela de breakpoints para a etapa de discretização, com o tamanho do alfabeto variando de a 10.

A concatenação das letras obtidas por este processo de discretização dos segmentos é chamada de palavra.

Segue uma definição formal deste processo, Definição 316.

Depois uma lista de breakpoints é usada para mapear os coeficientes em letras.

Neste exemplo, a série é discretizada para a string.

A transformação da representação para uma representação discreta gera uma sequência de letras para representar a série temporal.

A principal vantagem do SAX é obter um modelo de representação, que reduz a dimensionalidade, mas preserva as características da série original.

Outra motivação para ter uma representação discreta é que ela permite aplicar algoritmos para dados discretos originários das comunidades de processamento de texto e biológica.

As comunidades da area biológica, por exemplo, algoritmos para o tratamento e manipulação de sequências de DNA, que nada mais são do que sequências de caracteres.

A tarefa de mineração de dados chamada classificação pode ser definida como segue, Definição 317.

Classificação, Dado um conjunto de dados, cujas classes são conhecidas, o objetivo da classificação é o aprendizado de uma função que mapeie um objeto para a sua classe.

A função é conhecida como modelo de classificação.

Uma abordagem geral para o aprendizado deste modelo consiste, primeiramente, em fornecer dados de treinamento, cujas classes são conhecidas.

Os dados de treinamento são, então, usados para gerar o modelo de classificação, que é posteriormente aplicado aos dados de teste, cujas classes são desconhecidas.

O objetivo é criar um modelo capaz de categorizar corretamente tanto os dados utilizados em seu treinamento, como dados nunca vistos antes, ou seja, um modelo com boa capacidade de generalização.

O interesse principal na classificação está na precisão do resultado obtido, cuja avaliação é baseada na contagem do número de objetos classificados corretamente (acuráci ou incorretamente (taxa de erro).

A velocidade e o consumo memória do processo são dois aspectos importantes, além de uma boa generalidade.

Se dados de treinamento impróprios (insuficientes, ausentes ou incorretos) forem fornecidos, o modelo resultante poderá ter uma boa precisão para o conjunto de treinamento, mas um desempenho ruim para novos exemplos.

Diz-se, então, que o modelo é específico para o conjunto de treinamento, ocorrendo o overfitting.

Existem muitos domínios de aplicação da classificação de séries temporais, reconhecimento de fala, análise de sinais médicos, reconhecimento de gestos, entre outros, e muitos algoritmos têm sido propostos.

O foco é a produção de um modelo de classificação mais compreensível, baseado em arvores de decisão.

Mas, quando o foco é a acurácia, a simples combinação do algoritmo do vizinho mais próximo com o DTW apresenta ótimos resultados.

Este algoritmo atribui a um objeto não-classificado a classificação do objeto mais próximo dentro de um conjunto de objetos previamente classificados.

Mas devido ao uso do DTW, tal abordagem é muito lenta computacionalmente para aplicações reais.

No entanto, o cálculo pode ser acelerado utilizando a estimativa LB Keogh como explicado pelo Algoritmo 4.

Classificação com DTW, usando a medida de limite inferior LB Keogh.

Neste algoritmo, a verdadeira distância DTW somente é calculada para as séries que possuírem uma estimativa LB Keogh inferior a menor distância computada até o momento entre a série temporal que está sendo testada e as séries de treinamento.

Para ilustrar a velocidade e acurácia deste algoritmo é usado o conjunto de dados CBF, cujas séries são classificadas em três classes, cylinder, bell e funnel.

O conjunto de teste possui 900 séries, e o de treinamento, possui 30 séries.

Todas as séries possuem tamanho 128.

Tempo, em segundos, e a taxa de erro, para a classificação do conjunto CBF, segundo diferentes medidas de dissimilaridade.

Exemplo das classes do conjunto de dados Cylinder-Bell-Funnel (CBF).

A abordagem de classificação que apresenta melhores resultados é aquela apresentada pelo Algoritmo 4, que apresenta melhor combinação de taxa de erro e tempo de processamento.

Comparação de Medidas de Similaridade para Classificação.

A partir das medidas de dissimilaridade apresentadas, uma tarefa interessante chamada consulta por conteúdo é achar, em um conjunto de séries temporais, quais se assemelham a uma série de consulta Q, de acordo com alguns parâmetros definidos pelo usuário.

Existem dois métodos de busca adequados para realizar consulta por conteúdo em um conjunto de séries temporais, busca por alcance e busca pelos k-vizinhos mais próximos.

A definição desses métodos é apresentada a seguir.

Definição 318.

Busca por alcance, Dado um conjunto de séries temporais e uma série de consulta, uma busca por alcance irá retornar um subconjunto, onde é uma medida de dissimilaridade e é uma tolerância (alcance).

A escolha do valor da tolerância pode ser um problema, já que esse parâmetro afeta o resultado da busca.

Os autores contornam este problema definindo a tolerância como uma porcentagem de erro máxima permitida, depois de normalizar as distâncias obtidas para que seus valores fiquem entre 0 e 1.

Definição 319.

K-Vizinhos Mais Próximos, Dado um conjunto de séries temporais, uma série de consulta e uma medida de dissimilaridade, uma busca pelos k-vizinhos mais próximos irá retornar um subconjunto com cardinalidade.

Ainda existem duas variações dos métodos acima, Casamento Inteiro, Todas as séries a serem comparadas tem o mesmo tamanho da série de consulta.

Casamento de Subsequências, A série de consulta possui um tamanho menor.

Dessa forma, a consulta é feita deslizando-se e comparando-se contra as subsequências das séries.

No entanto, um importante fenômeno é observado no casamento de subsequências.

Quando procura-se por subsequências similares em um conjunto de dados, tipicamente os melhores casamentos para uma subsequência tendem a ser as subsequências.

Em outras palavras, os melhores casamentos tendem a ser versões levemente deslocadas da subsequência de interesse, conhecidas como casamentos triviais.

Uma definição mais exata de casamento trivial foi fornecida.

Casamento Trivial (trivial match), Dada uma série temporal, contendo uma subsequência começando na posição, e uma subsequência, diz-se que é um casamento trivial.

Para quase toda subsequência em uma série temporal, as subsequências mais similares são as subsequências imediatamente a esquerda e à direita.

Esses casamentos triviais devem ser excluídos quando realiza-se casamento de sub-sequências.

Essa exclusão é crítica, pois como discutido, casamentos triviais não têm sentido e podem levar a interpretações erradas.

Definidos os interesses em cada uma das buscas surge a questão em como resolver estas consultas.

A abordagem bruta seria uma busca sequencial, que requer a comparação da série temporal de consulta Q contra todas as séries ou subsequências no conjunto de dados, mantendo-se um registro dos melhores casamentos.

No entanto, tal abordagem é inapropriada para grandes conjuntos de dados.

Uma abordagem mais eficiente é utilizar uma estrutura de indexação.

Esses índices são estruturas hierárquicas que direcionam a busca para a parte mais promissora do conjunto de dados, eliminando a necessidade de examinar uma grande porção dos objetos.

Existem vários tipos dessas estruturas, sendo que as mais usadas são as árvores-R, uma variação das arvores-B para dados multidimensionais, e suas variantes.

No entanto, a maioria dessas estruturas degrada rapidamente para um número maior do que 8 dimensões, passando a fazer busca sequencial.

Para resolver este problema adota-se uma etapa anterior de segmentação para reduzir a dimensionalidade dos dados de um valor n para um valor N, que possa ser eficientemente manipulado pela estrutura de indexação escolhida.

Tal abordagem, que usa uma técnica de redução de dimensionalidade para representar as séries e indexa essas representações em uma estrutura, foi explorada eficientemente no arcabouço GEMINI (GEneric Multimedia INdexIng) Faloutsos.
Neste capítulo discutiu-se a aplicação de mineração para séries temporais, focando nas diferentes etapas deste processo, estudo do domínio de interesse, as atividades de pré-processamento, definição medidas de dissimilaridade necessárias a tarefas clássicas de mineração para séries temporais.

No próximo capítulo será apresentada a ferramenta desenvolvida durante este projeto, que utiliza parte dos conceitos apresentados até o momento.

Também serão apresentados os resultados obtidos.

Uma vez definidas medidas de dissimilaridade apropriadas é possível aplicar técnicas de projeção multidimensional para gerar representações visuais de grandes coleções de dados.

Essas representações fornecem uma visão geral dos dados que favorece a identificação de elementos com padrões similares/dissimilares, provendo um ponto de partida para uma exploração mais detalhada.

A aplicação de tarefas de mineração de dados que extraiam automaticamente informações uteis dos dados é outro campo promissor.

Desta forma, estudamos a aplicação de técnicas de projeção multidimensional em conjunto com tarefas de mineração para a mineração visual de conjuntos de séries temporais.

Com este intuito, propomos e desenvolvemos uma ferramenta que implementasse recursos de mineração visual de séries, a ferramenta Temporal-Projection Explorer (Temporal-PEx).

Na Seção 4são apresentadas as características e funcionalidade da Temporal-P Já na Seção 4são apresentados alguns cenários de análise de conjuntos de séries, e os resultados correspondentes obtidos.

A Seção 4exibe uma visão geral das técnicas de projeção e das medidas de dissimilaridade disponíveis, estabelecendo suas vantagens e desvantagens.

Por fim, a Seção 45 fornece os tempos de processamento necessários para a geração das projeções exibidas na seção de resultados.

Visão geral do processo para projeção de séries temporais aplicado pela ferramenta Temporal-P O processo geral para criar uma projeção de séries temporais utilizando o Temporal-PEx é composto por cinco etapas principais, 1 Especificação do Arquivo Fonte de Séries Temporais O formato de entrada das séries para a ferramenta Temporal-PEx chama-se TSD.

Este formato assemelha-se ao formato Comma-Separated Values (CSV) com algumas informações adicionais no cabeçalho, a descrição do conjunto de séries.

Onúmero de séries temporais.

Presença ou não de sazonalidade, e o tamanho do ciclo sazonal.

Possível classificação prévia das séries e eixo temporal no qual elas ocorrem.

Após este cabeçalho, as séries são fornecidas usando-se um rótulo seguido pelos valores da série.

A descrição formal da construção de arquivos nesse formato encontra-se disponível juntamente com a distribuição da ferramenta.

A ostra um exemplo do uso desse formato para descrever o conjunto de séries Cylinder-Bell-Funnel, que foi apresentado na Seção 23.

Nesse formato, o caractere # é usado para indicar comentário.

Pré-processamento Se tentarmos medir a similaridade entre duas séries temporais em sua forma original, sem um pré-processamento, podem-se obter resultados Exemplo do formato TSD não intuitivos devido a distorções nos dados.

Foram implementadas três funcionalidades de pré-processamento, que podem ser utilizadas a critério do usuário (ver Seção 34), normalização, suavização e remoção de sazonalidade.

Cálculo da Matriz de Distâncias Dado um conjunto, uma matriz de distância contém as distâncias entre todos os pares de séries.

Na expressão representa a distância entre as séries temporais de índices i e j, segundo alguma medida de dissimilaridade.

A matriz de distância é a base para a projeção de um conjunto de dados.

A ferramenta Temporal-PEx incorpora três medidas de dissimilaridade, a distância Euclidiana, o DTW e o CDM.

Matriz de distância.

Projeção e Conexão entre Pontos O Temporal-PEx incorpora duas técnicas de projeção multidimensional, que eram originalmente da ferramenta PEX, IDMAP e LSP.

A IDMAP não necessita de parâmetros.

Já no caso da LSP é necessário fornecer dois parâmetros, o número de pontos de controle n e o número de vizinhos (k).

A ferramenta sugere valores para ambos os parâmetros, baseando-se no número de séries.

O número sugerido de pontos de controle n é igual a 10% do número de séries.

E o valor sugerido para o número de vizinhos (k) é igual a 10 para coleções com menos de 1500 séries, ou 15 caso contrário.

Uma vez projetadas as séries é possível gerar um grafo ou uma triangulação, ambas representações convenientes para ressaltar a percepção de vizinhança (proximidade) entre os pontos.

Três tipos de conexão entre os pontos estão disponíveis, que também foram incorporados da ferramenta PEX, Triangulação de Delaunay Gera uma triangulação entre os pontos X, 0 T(X), de tal forma que nenhum ponto de X esta dentro do circuncírculo de qualquer triângulo de T(X).

A triangulação de Delau-nay maximiza o angulo mínimo de todos os ângulos de todos os triângulos na triangulação, evitando ao máximo triângulos com angulos pequenos.

Essa triangulação foi inventada em 193por Boris Delaunay.

Triangulação de Delaunay.

KNN-RM-1 Arestas do grafo representam conexões entre os vizinhos mais próximos no espaço original, R.

KNN-R1 Arestas do grafo representam conexões entre os vizinhos mais próximos no espaço projetado, R.

Mapeamento de Informações Adicionais Apesar de opcional, esta etapa fornece recursos visuais interessantes que representam características dos dados.

Informações das séries podem ser mapeadas para a cor e/ou tamanho dos círculos que as representam, a média, a variância, o valor mínimo, o valor máximo.

Se existir uma classificação das séries, também é possível mapear a classe.

Janela principal da ferramenta Temporal-P O conjunto de dados exibido é o Cylinder-Bell-Funnel discutido na Seção 23.

A ferramenta embute um assistente de criação de projeções que guia o usuário nas etapas do processo.

Também possui outras funcionalidades, referentes a interações sobre três painéis complementares à projeção com recursos para auxiliar a descoberta de padrões nos dados, Painel de projeção (central) Esse painel exibe a projeção, na qual cada círculo representa uma unica série.

Um clique duplo sobre um círculo irá abrir uma janela que mostra o gráfico correspondente aquela série.

Um clique com o botão direito do mouse sobre outro ponto faz com que o gráfico desta série seja anexado à outra janela existente, permitindo a comparação entre múltiplas séries.

Painel dos rótulos das séries (lado esquerdo superior) Esse painel mostra os rótulos descritivos associados a cada uma das séries no conjunto de dados, e que foram informados juntamente com o arquivo fonte.

Painel detalhes-sob-demanda (lado esquerdo inferior) Já esse painel mostra em suas abas três tipos de informação relativos as séries, os valores da série, a relação de vizinhança entre os círculos, ou seja, quais são as séries mais similares a uma determinada série selecionada, e informações estatísticas (média, variância, valor mínimo e valor máximo).

Esse três painéis são altamente integrados, a seleção de um círculo na projeção causa a seleção do rótulo da série temporal correspondente no painel de rótulos e a exibição das informações relativas a série no painel de detalhes-sob-demanda.

Outras funcionalidades, Salvar e carregar projeções em arquivos no formato eXtensible Markup Language (XML), incluindo os valores das séries temporais.

Relatório das técnicas e parâmetros usados na projeção.

Salvar, imprimir e interagir (zoom interativo e pan) com gráficos de séries temporais.

A visualização da distribuição das séries no conjunto dá ao usuário um ponto de partida para a busca por padrões de interesse.

Para auxiliar na busca por esses padrões estão disponíveis na ferramenta duas atividades de mineração, que são descritas nas seções seguintes.

Dado um conjunto de séries temporais, uma tarefa interessante é achar quais séries contém subsequências que se assemelham a uma subsequência de consulta Q, ou seja, realizar uma busca por padrões internos às séries, considerando que a projeção já fornece uma visão comparativa dos padrões globais.

Para executar essa busca, primeiramente é necessário selecionar uma subsequência Q, contida em uma série de interesse selecionada, pela qual estamos procurando.

Os usuários especificam essa subsequência de consulta desenhando interativamente, com o mouse, uma caixa que a delimite no gráfico da série.

Selecionada a subsequência de consulta é necessário definir dois parâmetros, a porcentagem de diferença permitida e se uma normalização deve ser aplicada.

A porcentagem de diferença indica o quão similares a original (alvo) as subsequências devem ser, ou seja, uma definição de tolerância.

Quanto menor este valor, maior a similaridade.

Se a normalização for aplicada estaremos ignorando diferenças na magnitude das subsequências, mas buscando similaridade em seu formato.

Definidos esses parâmetros, a execução do casamento de subsequências retorna uma janela de resultados, que contém todas as subsequências do conjunto de dados que são similares a Q e atendem aos parâmetros especificados.

As subsequências similares são listadas por ordem decrescente de similaridade.

Casamento de subsequências interativo.

Subsequência de consulta selecionada interativamente por meio do mouse, e destacado em vermelho.

Porcentagem de diferença máxima = 10%.

Com normalização.

Casamentos triviais são excluídos, incluindo casamentos triviais entre os próprios resultados para não se obter subsequências levemente deslocadas que representam o mesmo padrão.

Salienta-se que a distância Euclidiana foi empregada para esta atividade.

A Seção 4341 ilustra uma aplicação deste tipo de busca, mostrando inclusive como os resultados são mostrados.

A classificação de séries no Temporal-PEx adota o paradigma baseado em exemplos(ver Seção 362), que classifica séries nunca vistas antes a partir de séries similares cujas classes são conhecidas (conjunto de treinamento).

Esta tarefa compreende em três etapas, 1 Definição do conjunto de treinamento Também deve ser fornecido no formato TSD.

E importante que o conjunto de treinamento seja representativo em relação a distribuição dos dados.

O usuário também pode aplicar atividades de pré-processamento ao conjunto de treinamento.

Escolha da medida de dissimilaridade São disponibilizadas duas medidas de dissimilaridade para classificação das séries, Distância Euclidiana Apesar de simples, essa medida pode ser eficaz para alguns conjuntos de dados, especialmente se estes estiverem pré-processados devidamente.

O conceito de "abandono prematuro" foi empregado para acelerar ainda mais a classificação com essa medida.

DTW Essa medida é altamente eficaz na classificação de séries pela capacidade de lidar com desvios no eixo do tempo.

No entanto, ela possui um custo computacional quadrático.

Para superar essa limitação, o limite inferior LB Keogh foi usado para acelerar a classificação, como apresentado no Algoritmo da Seção 362.

Resultados Os resultados incluem o tempo de processamento necessário para realizar a classificação.

Se as séries possuírem uma classificação prévia, a taxa de erro e a matriz de confusão da classificação obtida por este processo em comparação a classificação prévia, supondo que esta ultima estava correta, também são disponibilizadas.

Uma barra de progresso informa o andamento da classificação, já que, dependendo do tamanho do conjunto de séries, esse processo pode ser lento.

Após o término da classificação, os círculos das séries na projeção são coloridos segundo a nova classificação obtida.

Um exemplo prático do uso da classificação é dado na Seção 432.

As próximas seções são dedicadas a apresentar alguns cenários de análise de conjuntos de séries temporais de diferentes domínios utilizando a ferramenta Temporal-PEx e os resultados obtidos.

Esse conjunto de dados contém 600 séries temporais geradas sinteticamente pelo processo descrito por Alcock e Manolopoulos, as quais estão classificadas em seis classes, Normal,Cyclic, Increasing trend, Decreasing trend, Upward shift e Downward shift.

Cada classe é representada por 100 séries temporais, cada uma com 60 observações.

O conjunto de dados encontra-se disponível em Hettich e Bay.

Abordagens convencionais de classificação e clustering demonstram dificuldade em agrupar essas séries com precisão, pois os pares de classes Normal/Cyclic, Decreasing trend/Downward shift e Increasing trend/Upward shift tendem a se misturar.

Projeções geradas para esse conjunto de dados com a técnica de projeção IDMAP.

Nessas projeções as cores dos círculos estão mapeando as classes, usando a mesma referência de cores.

Percebe-se a dificuldade da distância Euclidiana em separar corretamente as classes, pois os pares de classes encontram-se misturados.

O DTW gera uma projeção mais precisa tendo sido capaz de promover uma melhor separação entre os pares de classes.

Esse exemplo foi incluído com o objetivo de ilustrar o potencial da ferramenta Temporal-PEx em apresentar um visão geral do conteúdo do conjunto de séries, que reflete a simi-laridade no comportamento de seus conjuntos de séries.

O conjunto de dados Gun-Point pertence ao domínio de vídeo vigilância, e encontra-se disponível em Keogh.

Os dados foram gerados utilizando dois atores, e rastreando o centróide da mão direita dos atores no eixo Y, gerando séries de tamanho igual a 150.

Esse conjunto possui duas classes, Classes do conjunto de dados Synthetic Control Chart.

Cada classe é representada por sua série temporal média.

Conjunto de dados Synthetic Control Chart projetado com a técnica IDMAP.

Point Os atores têm inicialmente suas mãos ao lado de seus corpos.

Eles então apontam seus dedos indicadores para um alvo por aproximadamente um segundo, e depois retornam as mãos para a posição inicial.

Essa classe contém 7séries.

Gun Os atores estão com suas mãos ao lado de seus corpos.

Eles então tiram uma réplica de uma arma de um coldre preso à cintura, e apontam para um alvo por aproximadamente um segundo, e então retornam a arma para o coldre, e depois mãos para a posição inicial.

Essa classe contém 76 séries.

Conjunto de dados Gun-Point.

As duas classes de séries obtidas possuem comportamento similar.

No entanto, é possível classificar as séries visualmente com grande acurácia, notando-se que o ator deve levantar sua mão acima do coldre quando pega a arma.

Tal fato cria uma leve distinção no começo e no fim dos picos das classes.

A combinação da medida de dissimilaridade DTW e da técnica de projeção LSP foi escolhida para gerar a projeção dos dados.

O DTW é mais indicado nesse caso, pois os atores podem levantar suas mãos em momentos diferentes.

Foi utilizada a janela de alinhamento Sakoe-Chiba com R = 10% para melhorar o desempenho e a acurácia do DTW.

Já a LSP foi escolhida por sua tendência de ressaltar a formação de agrupamentos.

Na etapa de pré-processamento, aplica-se a normalização para compensar a diferença de altura entre os atores.

A projeção resultante é apresentada.

Projeção do conjunto de dados Gun-Point com a técnica LSP e a medida de dissimilaridade DTW.

Classe point em azul, e classe gun em vermelho.

A projeção desse conjunto de dados gerou duas áreas na projeção, uma região inferior em que a separação das classes foi maior e outra superior em que o nível de separação foi menor.

A menor separação das classes em uma das areas foi causada por um movimento mais sutil do ator, quando ele retira a arma do coldre para a classe gun.

Outra tarefa interessante nesse domínio é a classificação desses dados, pois detectar se uma pessoa representa uma ameaça séria a segurança de um local é de extrema importância.

Entretanto a classificação errada de uma série em qualquer das classes é grave, ignorando-se uma ameaça grave ou gerando um alerta errado contra uma pessoa.

Dessa forma, deseja-se que a taxa de erro seja a menor possível na classificação.

Um conjunto de treinamento com 50 séries (2da classe gun e 26 da classe point) foi fornecido para a classificação.

Também foi aplicada a normalização ao conjunto de treinamento, e a medida DTW foi escolhida para quantificar a similaridade entre as séries a serem classificadas (teste) e as de treinamento.

Comparação de medidas de similaridade para classificação das séries do A ostra a matriz de confusão para a classificação resultante dessas séries.

Esse tipo de matriz é uma medida mais efetiva da classificação obtida, pois mostra o número de classificações corretas versus as classificações preditas para cada classe, sobre o conjunto de dados.

Os resultados são dispostos em duas dimensões, classes verdadeiras e classes preditas.

Cada elemento (i,j) da matriz representa o número de séries que realmente pertecem à classe C, mas foram classificadas como sendo da classe C.

O número de acertos, para cada classe, localiza-se na diagonal principal da matriz.

Os demais elementos, para i 6= j, representam erros na classificação.

Matriz de confusão para a classificação dos dados gun-point.

Apesar da taxa de erro para classe Gun ter sido maior (7,8%), a taxa de erro total de 6% indica o bom resultado geral obtido pela classificação.

O conjunto de dados apresentado nesta seção refere-se ao preço médio das ações de 1430 empresas registrado durante 5semanas, e foi apresentado por Hochheiser e Shneiderman.

Esse é o mesmo conjunto de séries que foi apresentado.

Para a projeção deste conjunto de dados foi utilizada a técnica IDMAP em associação com a distância Euclidiana.

A normalização não foi aplicada as séries, pois o interesse reside na diferença de magnitudes entre elas.

Projeção das séries, cuja apresentação utiliza a conexão do tipo KNN-RM-1 foi utilizada, ou seja, cada ponto foi conectado por uma aresta ao seu vizinho mas próximo no espaço original.

Um primeiro fator na escolha de uma empresa para se investir pode ser baseado no valor médio das suas ações, uma vez que altos valores de ações são um forte indicativo de empresas lucrativas.

Baseando-se nesse fato, a escolha obvia seria a empresa chamada BHC Communications Inc, que na projeção é associada a cor verde associada.

O valor médio de ações dessa empresa é de aproximadamente U$ 153, muito maior do que a média apresentada de U$ 39,25 para o conjunto inteiro.

No entanto, existem riscos provenientes da oscilação do preço das ações que devem ser considerados na escolha de uma empresa.

O valor das ações de uma empresa é reflexo das percepções e estimativas dos investidores sobre o seu desempenho e o desempenho da economia.

Dessa forma, não há nenhuma garantia para os valores das ações, existindo chances de que um investimento contabilize tanto ganho como prejuízo.

Para calcular o risco de um investimento pode-se utilizar a variância como medida de dispersão.

Projeção com o uso da variância para mapear a cor dos círculos, na qual percebe-se que a empresa BHC Communications Inc possui alta variância cor vermelhindicativo de alto risco associado.

Essa empresa teve uma forte queda na 19 semana.

Assim, um investidor cauteloso selecionaria uma empresa que tivesse média alta (cor verde), porém uma baixa variância cor verde-azulad.

Já o investidor"corajoso"aplicaria na empresa BHC Communications Inc em sua queda, e venderia as ações nas ultimas semanas, quando o valor voltou a subir.

O trabalho cardíaco produz sinais elétricos que passam para os tecidos vizinhos e chegam a pele, de modo que a colocação de eletrodos no peito, permite gravar as variações de ondas elétricas emitidas pelas contrações do coração.

O ECG é um exame médico na area de cardiologia no qual é feito o registro da variação dos potenciais elétricos gerados pela atividade elétrica do coração.

O conjunto de séries temporais de eletrocardiogramas a ser estudado nesta seção encontra-se disponível em Keogh, que o construiu a partir do banco de dados PhysioBank.

Cada uma das séries temporais foi extraída do eletrocardiograma de quatro pacientes diferentes, Primeiro paciente (chf02), Este paciente sofre de Insuficiência Cardíaca Congestiva IC severa, que é uma condição na qual o coração não consegue bombear sangue Séries com valores médios semanais de ações de 1430 empresas durante 26 semanas.

Projeção gerada com técnica IDMAP e distância Euclidiana a uma taxa suficiente para os orgãos.

O eletrocardiograma completo desse paciente encontra-se na base de dados BIDMC Congestive Heart Failure do PhysioBank.

Segundo paciente (chf15), Este paciente também sofre de ICC severa.

O eletrocardiograma completo desse paciente também encontra-se na base de dados BIDMC Congestive Heart Failure.

Terceiro paciente, Este paciente possui alterações no segmento ST do eletrocardiograma, que constituem um bom preditor de infarto do miocárdio e morte súbita.

O eletrocardiograma completo encontra-se na base de dadosLong Term ST do PhysioBank.

Quarto paciente (118 e6), Este paciente sofre de arritmia, que é um nome genérico para diversas perturbações que alteram a frequência cardíaca.

No entanto, foi adicionando ruído ao eletrocardiograma desse paciente para testar a tolerância de detectores de arritmia a ruído.

O eletrocardiograma completo encontra-se na base de dados MIT-BIH Noise Stress Test do PhysioBank.

A partir de cada um desses quatro eletrocardiogramas foram extraídas cinco séries temporais de tamanho 10000, todas começando nos índices 0, 82, 150, 200 e 250, totalizando 20 séries temporais de tamanho 10000, oriundas de quatro pacientes diferentes.

O interesse aqui é agrupar as séries temporais segundo o paciente da qual elas foram extraídas.

Exemplos de séries temporais de cada um dos pacientes.

A técnica de projeção LSP foi escolhida para projetar esse conjunto de dados, utilizando-se 8 pontos e de controle e 5 vizinhos para definição das relações de vizinhança.

As séries foram normalizadas na etapa de pré-processamento para evitar influência das diferenças de voltagem entre os pacientes.

Projeção gerada com a distância Euclidiana, projeção gerada com a distância CDM.

A distância CDM conseguiu agrupar as séries eficientemente, ao contrário da distância Euclidiana.

Essa superioridade é devido a alta dimensionalidade dessas séries e suas diferenças estruturais.

Os círculos foram conectados com a conexão entre arestas do tipo KNN-RM-1, ou seja, a conexão ocorre entre os vizinhos mais próximos no espaço original.

Os eletrocardiogramas nesse exemplo também foram retirados do banco de dados Physi-oBank, e pertencem a base da dados MIT-BIH Arrhythmia Database, que disponibiliza eletrocardiogramas com episódios de arritmia anotados por especialistas.

A contração Exemplos de séries temporais extraídas de cada um dos quatro pacientes.

Projeção do conjunto de eletrocardiogramas por meio da técnica LSP.

Cada cor indica um paciente ventricular prematura (CVP) é um tipo de batimento anormal, no qual o ventrículo contrai prematuramente.

Isto resulta em um "batimento pulado" seguido por um batimento forte.

Esse tipo de batimento anormal é comum, e pode ocorrer tanto em pacientes normais como em pacientes com doenças cardíacas.

No entanto, contrações ventriculares prematuras podem diminuir a capacidade do coração bombear sangue para os outros orgãos diminuindo a capacidade cardíac, resultando em uma baixa pressão sanguínea.

Pacientes com mais de três CVPs consecutivos têm taquicardia ventricular que pode culminar em uma fibrilação ventricular, que é um ritmo cardíaco fatal.

Eletrocardiograma de paciente com arritmia.

Anotações, V contração ventricular prematura e batimento normal.

Para esta análise selecionou-se o ECG de um homem (número do registro, 200) de 6anos, com duração de 1 minuto.

A taxa de amostragem desse ECG é de 360 valores por segundo, totalizando uma série temporal de tamanho 21600.

Para entrar com este ECG na ferramenta Temporal-PEx a série inteira foi decomposta em 1séries menores, cada uma contendo 5 segundos e aproximadamente 7 batimentos.

Segundo as anotações fornecidas pelos especialistas, o primeiro batimento registrado é um CVP.

Dessa forma, utiliza-se esse batimento como subsequência de consulta para encontrar as demais ocorrências.

Adotando uma tolerância de 30% e normalizando as subsequências, a ferramenta localizou corretamente os 27 CVPs existentes no ECG.



A tela que mostra simultaneamente os gráficos de todas as subsequências retornadas, observa-se que os resultados exibem o formato padrão do CVP, e que a Temporal-PEx indentificou inclusive CVPs com diferentes amplitudes.

Também é possível exibir a série a qual pertence a subsequência sendo analisada, destacando-se sua localização.

Casamento de subsequências para busca por batimentos anormais em um ECG.

Uma vez que o sistema brasileiro de distribuição de energia elétrica é predominantemente hidroelétrico, a análise de vazões é de particular importância.

As vazões registradas nos rios, isto é, a quantidade de agua disponível em um determinado período de tempo em um ponto do rio, constituem o insumo básico para os reservatórios das usinas hidrelétricas.

Quanto maior a vazão disponível, mais energia elétrica poderá ser produzida em uma usina, limitada apenas pela sua potência instalada e pela capacidade de engolimento das turbinas.

Essas vazões dependem apenas de dois fatores, condições geológicas do rio, como largura, inclinação, tipo de solo, obstáculos e quedas e índice pluviométrico da região.

Essa dependência em relação à quantidade de chuvas confere um caráter sazonal as vazões, acarretando grande variação na capacidade de produção de energia ao longo do ano.

A análise de vazões de diferentes bacias hidrográficas colecionadas durante anos tem papel estratégico no planejamento e operação do sistema nacional de distribuição, já que todo o sistema deve ser ajustado para operar corretamente durante os períodos chuvosos e secos.

Ademais, qualquer plano para expansão do sistema elétrico deve considerar algumas restrições em relação ao risco de déficit no suprimento de energia, que podem ser estimadas por meio da simulação de operação com base em vazões representativas registradas.

O conjunto de dados analisado nesta seção é um dos resultados do projeto "Vazões Médias Mensais nos Aproveitamentos Hidrelétricos Período 1931 a 2005", que abordou estudos de consistência e reconstituição das séries históricas de vazões.

A função de planejamento e programação da operação do Sistema Interligado Nacional sistema de produção e transmissão de energia elétrica do Brasil está sob a responsabilidade do Operador Nacional do Sistema Elétrico (ONS), que disponibiliza os dados referentes as vazões utilizadas para seu planejamento na forma de séries temporais.

Dessa forma, a otimização da operação energética, em qualquer horizonte temporal, depende essencialmente da quantidade e qualidade das informações que podem ser extraídas dessas séries de vazões.

Essas séries se destinam aos modelos de planejamento de médio e curto prazo para operação das usinas hidrelétricas.

Devido ao horizonte de planejamento, que se estende até o ano de 2011, as séries de vazões devem estar disponíveis não só para as usinas em operação, como também para as usinas em expansão, aquelas que não estão construídas, mas que têm o início de seu enchimento previsto até 2011.

O ONS obteve essas séries por um processo de reconstituição para que os dados de vazões estivessem disponíveis para todo o período de 1931 a 2005.

Para usinas em operação esse processo é baseado em dados operativos fornecidos pelas concessionárias de energia elétrica.

Já para as usinas em expansão, toma-se como base dados de estações pluviométricas da bacia em que será instalada a usina, bem como as séries de usinas em operação que tenham influência direta sobre a usina em expansão.

Dessa forma, o conjunto de dados inclui uma série temporal para cada usina, a qual registra a vazão média mensal na usina por um período de 75 anos, de 1931 a 2005, em um total de 900 valores, coletados ou estimados.

As séries de vazões médias mensais estão disponíveis para 151 usinas hidrelétricas do SIN.

Gráfico da série temporal relativa a usina Furnas.

Esta mesma série pode ser dividida em períodos anuais, obtendo-se 75 séries temporais que descrevem o comportamento anual desta usina.

Sazonalidade dessas séries.

Usinas Hidrelétrica de Furnas.

O comportamento das vazões das usinas também está altamente relacionado à região hidrográfica onde elas estão localizadas.

Atualmente, o Conselho Nacional de Recursos Hídricos divide o Brasil em 1regiões hidrográficas, Amazônica, Tocantins/Araguaia, Atlântico Nordeste Ocidental, Parnaíba, Atlântico Nordeste Oriental, São Francisco, Atlântico Leste, Atlântico Sudeste, Paraná, Paraguai, Uruguai e Atlântico Sul.

Localização dessas regiões, juntamente com a média anual de contribuição hídrica da região, em km.

Quanto maior a contribuição hídrica da região, maior o seu potencial hidrelétrico.

A usina de Furnas, por exemplo, pertence a região hidrográfica do Paraná.

Regiões hidrográficas do Brasil.

A detecção de anos chuvosos e secos é um tema crítico no planejamento de produção de energia no Brasil, já que uma sequência de anos secos representa uma ameaça potencial a operação do sistema inteiro.

Nesta análise utilizamos as séries obtidas pela divisão dos dados de vazão em períodos anuais, como exemplificado.

Projeção gerada na ferramenta Temporal-PEx, relativa as séries anuais referentes a usina Furnas.

Esta projeção foi gerada com a técnica IDMAP e com a medida de distância Euclidiana.

O valor médio das séries anuais foi mapeado para a cor.

O mapeamento de cores segue a escala do arco-íris, com tons próximos ao vermelho representando médias menores de vazão, e tons próximos ao azul representando médias maiores.

Nenhuma normalização foi aplicada às séries antes da projeção, visto que o interesse é comparar a magnitude das vazões para identificar, por exemplo, períodos críticos como anos muito secos.

Identificam-se três areas principais na projeção, uma correspondendo a vários anos secos (representados em vermelho), outra representando anos médios (verde-amarelado) e uma terceira correspondendo a anos chuvosos, representados por círculos verdes.

De fato, o período de 195a 1956 é conhecido como o mais seco entre os registrados.

Projeção das séries de vazões anuais da usina Furnas ao longo dos anos de 1931 a 2005.

Projeção criada com a técnica IDMAP e com a distância Euclidiana.

O ano de 2001, que também foi um ano muito seco, foi marcado por uma séria crise energética, uma vez que o sistema de produção de energia elétrica brasileiro não conseguiu atender a demanda de energia.

Já o ano de 198 é um ano atípico, caracterizado por ter sido extremamente chuvoso a vazão média para este ano é de 2,25m /s, que é bem acima da vazão anual média típica de 927 m /s.

A projeção das séries anuais conseguiu agrupar os anos conforme o comportamento (seco, normal, chuvoso), bem como realçar a ocorrência de um ano atípico.

A detecção de anos secos é importante para o planejamento operacional do sistema hidrelétrico, já que a energia mínima disponível para uma usina energia firme é calculada com base nesses anos.

O planejamento é tipicamente baseado no pior cenário visto, buscando evitar a dependência de chuvas.

Quando a demanda energética excede a energia firme estimada, o risco de déficit cresce a crise energética de 2001 surgiu de um cenário como este.

Apesar da região hidrográfica Amazônica ter o maior potencial hidrelétrico, o maior aproveitamento hidrelétrico corresponde ao da região hidrográfica do Paraná, que abriga a usina de Itaipu, entre outras.

A região do Paraná sofreu maior número de represamentos para geração de energia, visando atender a demanda energética da região Sudeste.

Nesta região destacam-se as sub-bacias denominadas Grande, Iguaçu, Paraná, Paranaíba, Paranapanema e Tietê.

Para esta análise foram extraídas do conjunto de dados as séries de vazões das usinas localizadas na região hidrográfica do Paraná, que são 76 no total.

Nem todas se encontram em operação, algumas estão em construção e outras em planejamento como discutido, os dados relativos a essas usinas não foram coletados, mas sim estimados.

Cada série foi classificada de acordo com a sub-bacia na qual a usina associada está inserida.

Diagrama esquemático da localização geográfica dessas usinas de acordo com as sub-bacias mencionadas.

Como o interesse não é compará-las em sua magnitude e sim quanto as suas características estocásticas variabilidade, correlação temporal, et, as séries de vazões devem ser normalizadas na etapa de pré-processamento.

A normalização garante que séries relativas a usinas como Itaipu, cuja vazão média anual é de 131105,475 m /s, não se destaquem das demais.

Como mencionado anteriormente, as séries de vazões também são sazonais.

Para efetuar a normalização das séries e remover essa sazonalidade foi aplicado o Método dos Momentos Sazonais às séries de vazões na etapa de pré-processamento.

Projeção das séries pré-processadas gerada com a técnica de projeção IDMAP e a distância Euclidiana.

E possível observar que a projeção conseguiu agrupar as usinas de acordo com suas sub-bacias ou seja, usinas pertencentes a uma mesma sub-bacia permanecem próximas na projeção.

A cor e a numeração que rotula os círculos são as mesmas utilizadas no diagrama, e permitem identificar a qual usina a série (representada pelo círculo) pertence.

Observando mais atentamente a projeção é possível identificar outras características do sistema, como o papel de reservatórios na regularização das vazões.

Reservatórios regularizam a vazão ao longo do rio, armazenando o excesso de água em períodos chuvosos para que esta reserva esteja disponível durante os períodos secos.

Quando um rio tem uma usina com reservatório, as usinas subsequentes se beneficiam dessa regularização da vazão e apresentam comportamento similar entre si.

Como exemplo, pode-se mencionar as usinas Estreito (4), Jaguará (10), Igarapava (8), Volta Grande (14) e Porto Colômbia (1 da sub-bacia do Grande, que na projeção estão localizadas perto da usina de Mascarenhas de Moraes (12), que possui um reservatório.

Também é possível observar que as usinas localizadas na sub-bacia do Paraná (usinas de Ilha Solteira (26), Itaipu (27), Jupiá (2e Porto Primavera (29)) estão localizadas Diagrama da localização geográfica das usinas da região hidrográfica do Paraná.

Projeção para a Região Hidrográfica do Paraná no centro da projeção.

As demais sub-bacias deságuam no rio Paraná, influenciando nas vazões dessas usinas.

Outro fato interessante foi a divisão da bacia do Paranaíba em dois grupos distintos.

O primeiro grupo é composto pelas usinas dos rios Correntes, Verde e Claro.

Já o segundo grupo é composto pelas usinas dos rios Corumbá, São Marcos, Paranáiba e Araguari.

Essa distinção é explicada pela distância geográfica entre esses grupos de rios, o que se reflete em diferenças climáticas e de padrões de chuva.

Nesta terceira análise sobre o conjunto de dados de vazões, o comportamento climático das sub-bacias da região do Paraná ao longo de um ano é investigado.

Séries temporais compostas pelas vazões do ano de 1982, para cada usina, foram selecionadas para este propósito.

Projeção desses séries usando a técnica IDMAP e a distância Euclidiana.

As séries foram normalizadas antes da projeção.

Séries médias que representam o comportamento climático no ano de 198das sub-bacias da região hidrográfico do Paraná.

Usinas localizadas na região central do Brasil, nas sub-bacias do Paranaíba e do Grande, apresentam um comportamento bem definido, no qual o período chuvoso ocorre nos meses de Novembro a Abril.

O mesmo não ocorre na região sul, nas sub-bacias do Iguaçu e do Paranapanema, que exibem um comportamento distinto característico do clima subtropical.

Essa região possui um regime hidrológico indefinido, no qual cheias podem ocorrer tanto no verão como no inverno.

Já as usinas localizadas na sub-bacia do Tietê apresentam um comportamento transitório.

Esse tipo de projeção é interessante para futuras aplicações, pois uma animação de projeções desse tipo, mapeando o comportamento de diferentes anos pode revelar, por exemplo, mudanças climáticas ao longo dos anos.

A escolha da técnica de projeção e da medida de dissimilaridade para gerar projeções é extremamente dependente das características do conjunto de séries a ser projetado e de que tipo de informação deseja-se destacar na projeção.

Sendo assim, as Tabelas 45 e 46 mostram, em linhas gerais, as vantagens e desvantagens das técnicas de projeção e das medidas de dissimilaridade disponíveis, respectivamente.

Essas tabelas fornecem uma Projeção IDMAP e distância Euclidian das séries de vazões registradas no ano de 1982, nas usinas da região hidrográfica do Paraná.

Cada cor identifica uma sub-bacia.

Visão geral das características das técnicas e das medidas, nas quais o usuário pode-se basear para sua escolha.

Técnicas de projeção, vantagens e desvantagens A ostra o tempo de processamento para gerar as projeções apresentadas neste capítulo.

Os tempos de processamento apresentados foram calculados em um computador com processador Intel Pentium 3GHz e com 1 GB de RAM, e incluem todas as etapas do processo apresentado.

Para a geração de uma projeção, por exemplo, os tempos incluem leitura do arquivo fonte, pré-processamento, cálculo da matriz de distância, projeção dos dados e exibição do resultado na tela.

A mineração visual aplicada a séries temporais é de extrema dificuldade pela alta dimensionalidade desses dados, determinada pelo número de pontos de observação no eixo do tempo.

A ferramenta Temporal-PEx, desenvolvida neste projeto, visa abordar o problema de mineração visual de séries temporais.

A aplicabilidade da ferramenta para a análise de séries foi ilustrada por meio de estudos de caso em conjuntos de dados de diferentes domínios, segurança, ações de empresas, eletrocardiogramas e vazões de usinas Medidas de Dissimilaridade, vantagens e desvantagens hidrelétricas, selecionados para ilustrar o potencial da ferramenta e suas funcionalidades.

O ultimo conjunto de dados, vazões de usinas hidrelétricas, foi explorado mais a fundo com a colaboração de um especialista no estudo de séries de vazões.

O Temporal-PEx revelou-se uma boa ferramenta exploratória, na qual o usuário ganha um conhecimento sobre o conjunto de dados, e a partir desse conhecimento direciona sua busca por padrões de interesse por meio de interações e tarefas de mineração de dados.

Tempo de processamento.

Neste capítulo são apresentadas as principais contribuições deste trabalho para a análise de séries temporais, bem como suas limitações.

Tambéms são apresentados desenvolvimentos futuros que podem dar continuidade à abordagem proposta, superando algumas limitações e gerando outras contribuições.

O principal objetivo deste trabalho de mestrado foi a geração de uma abordagem para a análise de séries temporais.

Isso motivou o estudo em duas áreas, Visualização de Informação e Mineração de Dados, e especificamente visualização e mineração de series.

O conhecimento adquirido com esses estudos motivou a proposta e desenvolvimento de uma ferramenta chamada Temporal-PEx, que gera uma representação visual que reflete a distribuição interna das séries dentro da coleção, oferecendo um ponto de partida para a busca de padrões de interesse.

A busca por padrões também é auxiliada por duas tarefas de mineração de dados, casamento de subsequências e classificação.

O emprego efetivo da ferramenta para gerar projeções de séries temporais, requer certo conhecimento prévio sobre as técnicas de projeção e medidas de dissimilaridade disponíveis.

No entanto, esse conhecimento pode ser facilmente adquirido com o uso da ferramenta, gerando e observando projeções resultantes do mesmo conjunto de séries de diferentes combinações dessas opções.

Uma visão geral das características dessas técnicas de projeção e dessas medidas de dissimilaridade também pode ser obtida consultando um pequeno arquivo de instruções que acompanha a ferramenta.

O arquivo de instruções traz, entre outras informações, um descrição do formato do arquivo entrada Time Series Data-file TS.

Entre as limitações também encontra-se a falta de capacidade da ferramenta de analisar séries com mais de uma informação associada a cada ponto.

Séries sobre dados metrológicos, por exemplo, podem conter informações sobre temperatura e umidade para um mesmo instante no tempo.

A ferramenta atualmente também não é capaz de incorporar informações geográficas das séries a representação visual gerada.

As séries de vazões de usinas, por exemplo, possuem associadas a si a localização geográficas das usinas.

Outra dificuldade é o tamanho da coleção que a ferramenta consegue lidar atualmente.

Foram geradas coleções de séries aleatórias, em caráter de teste, para determinar o tamanho máximo da coleção que a ferramenta suporta.

O limite máximo foi atingido por um conjunto com 75 séries de tamanho 10000 cada, totalizando 750000 valores.

Quanto a exibição das séries, o círculo é a atual forma de exibição de uma série dentro da projeção, que permite o mapeamento de informações somente para a cor e o tamanho.

O círculo é uma forma ideal por ocupar pouco espaço, se considerarmos o aproveitamento da tela.

No entanto, seria extremamente interessante fornecer a opção de usar formas alternativas de exibição das séries, que utilizem a idéia da projeção, mas que consigam transmitir mais informação sobre o comportamento individual das séries.

As limitações mencionadas na seção anterior e outras características desejáveis indicam os principais desenvolvimentos futuros a serem seguidos.

Dentre eles destacam-se, Escalonamento da ferramenta para lidar com conjuntos de dados maiores.

Incorporação de mais tarefas de mineração de dados, como dectção de anomalias e descobrimento de motifs padrões frequentes previamente desconhecidos.

Capacidade de lidar com séries multivariadas, que contém mais de um atributo para o mesmo eixo temporal.

Identificando, por exemplo, correlações entre os atributos.

Incorporação de formas alternativas de exibição das séries.

Um possibilidade seria o uso da técnica Intelligent Icons, que constrói ícones de forma que séries similares apresentem ícones similares.

Cooperação com a Prof Dra Wu-Shin Ting, prosseguindo com o processo de validação e aperfeiçoamento da ferramenta por meio da sua utilização mais extensiva em diversos dominós de aplicação.

Adaptação da técnica de projeção LSP para incorporar informações geográficas associadas as séries no processo de projeção, de modo que o posicionamento dos pontos também leve em consideração essa informação geográfica.

Adição de outras atividades de pré-processamento, como a remoção de tendência.

Detecção automática da presença de sazonalidade nas séries, e do tamanho do ciclo sazonal.

Incorporação de mais interações com a ferramenta por parte do usuário.

Por exemplo, coordenação entre projeções diferentes do mesmo conjunto de dados.

