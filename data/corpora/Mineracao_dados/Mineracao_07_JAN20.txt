Esse trabalho visa estudar a aplicabilidade e o desempenho de Web Services como uma materialização do modelo de arquitetura orientada a serviços Service Oriented Architecture, SO, com um estudo de caso em uma arquitetura orientada a serviços real.

Nesse aspecto, a contribuição principal foi mostrar os passos necessários para a concepção e o desenvolvimento de aplicações baseadas em serviços, apontando dificuldades e possíveis soluções para questões que fazem parte desse novo modelo de programação.

Como aplicação real para o estudo de caso, optou-se por construir um sistema de mineração de dados interativa e multi-usuária, o Tamanduá.

Aplicações de mineração de dados e descoberta de conhecimento vêm se tornando muito importantes.

A construção de um ambiente distribuído para a mineração de grandes bases inclui diversos requisitos interessantes, como localização e uso dinâmico de serviços remotos, que podem ser mapeados no modelo de SOA.

O resultado foi um sistema baseado em Web Services que atende aos requisitos necessários para a mineração de dados de distribuída.

A extensibilidade e escalabilidade da plataforma foram medidas para demonstrar a viabilidade e as potencialidades desse tipo de sistema e a vantagem do modelo SOA.

A plataforma Tamanduá está em operação e os experimentos apresentados mostram que ela possui desempenho satisfatório e pode ser expandida para atender ao aumento da demanda de usuários.

A análise de desempenho realizada serve também de apoio a novos trabalhos na área de Web Services.

Esse trabalho visa estudar a aplicabilidade e o desempenho de Web Services como uma materialização do modelo de arquitetura orientada a serviços Service Oriented Architecture, SO, com um estudo de caso em uma arquitetura orientada a serviços real.

Nesse aspecto, a contribuição principal foi mostrar os passos necessários para a concepção e o desenvolvimento de aplicações baseadas em serviços, apontando dificuldades e possíveis soluções para questões que fazem parte desse novo modelo de programação.

Como aplicação real para o estudo de caso, optou-se por construir um sistema de mineração de dados interativa e multi-usuária, o Tamanduá.

Aplicações de mineração de dados e descoberta de conhecimento vêm se tornando muito importantes.

A construção de um ambiente distribuído para a mineração de grandes bases inclui diversos requisitos interessantes, como localização e uso dinâmico de serviços remotos, que podem ser mapeados no modelo de SOA.

O resultado foi um sistema baseado em Web Services que atende aos requisitos necessários para a mineração de dados de distribuída.

A extensibilidade e escalabilidade da plataforma foram medidas para demonstrar a viabilidade e as potencialidades desse tipo de sistema e a vantagem do modelo SOA.

A plataforma Tamanduá está em operação e os experimentos apresentados mostram que ela possui desempenho satisfatório e pode ser expandida para atender ao aumento da demanda de usuários.

A análise de desempenho realizada serve também de apoio a novos trabalhos na área de Web Services.

O conceito de Serviços Internet é muito amplo e tem origem nos sistemas cliente/servidor das décadas de 70 e 80.

Esse modelo emergiu da convergência entre computadores e redes de comunicação que permitiu o uso de computadores simples, apenas com interface gráfica (GUI) e menor poder de processamento, e portanto mais disponíveis para a realização de tarefas complexas, numa interação mais dinâmica com o usuário final.

Isso foi possível porque as aplicações cliente/servidor são normalmente divididas em camadas, como interface com o usuário, camada de negócio e camada de persistência.

Dessa forma, torna-se possível a execução na máquina do cliente apenas da interface, que se comunica pela rede com as demais camadas que podem estar em máquinas com mais recursos computacionais.

O usuário (ou cliente), com uma aplicação "leve", pode comandar execuções que exigem muito processamento em máquinas remotas com maior capacidade.

Além disso, trazendo parte da computação para próximo do usuário e provendo uma interface mais flexível e fácil de usar, sistemas cliente/servidor podem aumentar a produtividade, incrementar a satisfação do usuário e reduzir significativamente custos de treinamento.

Com o advento da Internet e a popularização da World Wide Web (WWW), um caso especial e importante de sistema cliente/servidor, um número crescente de empresas, órgãos governamentais e até mesmo programadores têm disponibilizado na web as mais diversas aplicações.

Um unico tipo de aplicação, o navegador web, é suficiente para o acesso a bibliotecas e museus virtuais, comércio eletrônico (onde se pode comprar de livros a carros, entre diversos produtos), clientes de e-mail na WWW (webmails), jornais e revistas, serviços de pesquisa e localização em mapas, sites de relacionamento e milhares de outras opções que se encontram disponíveis na rede mundial.

O crescimento da WWW levou à criação de um órgão normativo, o World Wide Web Consortium.

Inicialmente, a WWW era feita apenas de recursos estáticos, porém novas aplicações e serviços exigiram tecnologias para a construção dinâmica de páginas e documentos.

Nesses sistemas, as páginas devem ser criadas a partir da interação com o usuário, ou seja, geradas a partir de parâmetros baseados nas ações do mesmo.

Um exemplo simples disso é um sistema de buscas, onde a lista de resultados deve ser criada baseada nas palavras chave selecionadas pelo usuário, diferente dos antigos catalogadores de páginas, que eram serviços estáticos onde o usuário procurava um endereço baseado em categorias, onde as páginas não dependiam de entrada dos usuários.

Diversas tecnologias surgiram para permitir a criação dinâmica de páginas WWW na Internet, como CGI, PHP, JSP, ASP e outras.

Cada uma tem suas qualidades e defeitos, mas todas se comunicam diretamente com o usuário através de uma linguagem (não padronizad de descrição de interfaces web, o Hypertext Markup Language (HTML).

Apesar de o HTML ter sido um dos grandes responsáveis pela popularização da WWW e da Internet, a falta de padronização e a sua natureza voltada para a formatação da interface com o usuário torna muito difícil a interação entre aplicações.

Interoperabilidade entre aplicações é capacidade de dois programas de computador interagirem entre si, trocando informações e serviços de maneira a atingir os resultados esperados por ambos.

A comunicação entre empresas e instituições de forma automatizada é muito importante no mundo globalizado e dinâmico de hoje.

As empresas informatizadas necessitam que seus programas comuniquem-se diretamente com seus clientes, fornecedores e outras unidades, sem a intervenção humana.

Por exemplo, compras e solicitações de produtos podem ser processadas pela aplicação de controle de estoques da empresa diretamente ao serviço de recebimento de pedidos do fornecedor, sem a necessidade da intervenção de um funcionário.

Um sistema de cartões de crédito pode consultar outros sistemas sobre o valor de moedas estrangeiras, evitando a necessidade de um usuário para a inserção dessa informação.

A interoperabilidade através da rede é um objetivo com uma longa história mas apenas sucessos parciais, como o Distributed Component Object Model (DCOM), o Common Object Request Broker Architecture (CORBA) e o Java Remote Method Invocation (RMI) sobre o Internet Inter-ORB Protocol (OP).

Essas soluções são normalmente específicas para uma linguagem ou tecnologia proprietária e trazem vários problemas para a comunicação cliente/servidor na Internet.

Para solucionar esses problemas o WC, com o apoio de diversas empresas, criou um padrão de comunicação entre aplicações baseado em tecnologias conhecidas e padronizadas, os Web Services.

Essa solução tenta tornar a comunicação entre aplicações tão fácil quanto a Web tornou a publicação de documentos.

Definindo um conjunto de formatos de dados estruturados e legíveis por humanos e fazendo-os abertos e independentes de qualquer linguagem ou plataforma particular, os projetistas de Web Services esperam criar um arcabouço para interoperabilidade programa-a-programa.

Isso permite a criação de aplicações distribuídas com vários componentes espalhados pela Internet, trabalhando em cooperação para a realização de tarefas.

Os cenários para a utilização dessas tecnologias são os mais variados, livrarias virtuais e outros serviços de comércio eletrônico podem receber pedidos de compras diretamente das aplicações de controle de estoque de seus clientes, consultando o valor do transporte na empresa responsável.

Sites podem implantar busca na web ou em dicionários, usando o processamento de serviços já conhecidos.

Tudo sem a necessidade de saber nenhum detalhe sobre como foram implementados esses serviços.

Outra característica visível de Web Services é a possibilidade de criar novas aplicações e serviços apenas compondo e combinando serviços já existentes.

Vários são os serviços já disponíveis na Internet para realizar as mais diferentes tarefas, como consultar endereços, converter arquivos entre formatos diferentes, checar valor de câmbio e ações em bolsas de valores, consultar clima de determinadas regiões, entre outros.

Qualquer um pode tornar público um serviço para que outras aplicações o utilizem seguindo os padrões definidos.

O objetivo de web services é que esses serviços possam ser facilmente compostos para gerar novas aplicações, sem que código precise ser desenvolvido para recompor essas operações.

A idéia de aplicativos que usam massivamente serviços independentes espalhados pela rede constituem o paradigma denominado Computação Orientada a Serviços (SOC, Service Oriented Computing).

O modelo de SOC se baseia em arquiteturas de software orientadas a serviços (SOA, Service Oriented Architecture), que é uma maneira de reorganizar aplicações e infraestruturas de software em um conjunto de serviços interativos.

A idéia de SOA é relativamente nova, apesar de o conceito de serviço ser mais antigo.

Esse estilo arquitetônico de fazer software promove o pouco acoplamento entre os componentes e a independência de tecnologias específicas para que eles sejam reutilizáveis.

Algumas vantagens do uso de SOA são a adaptação das aplicações a tecnologias em constante evolução, a fácil integração de aplicações com outros sistemas, o reaproveitamento de investimentos em aplicações legadas e a criação prática e rápida de novos processos a partir de serviços existentes.

Como serviços provêem uma forma uniforme e largamente disponível (ubíqu de distribuir informações para uma grande quantidade de dispositivos computacionais (como notebooks, PDAs, telefones celulares, entre outros) e plataformas de software (como UNIX ou Windows), eles constituem o próximo grande passo em computação distribuída.

O paradigma SOC/SOA pode ser aplicado para solucionar problemas nas mais variadas áreas de conhecimento.

Um uso comum de SOA é na criação de aplicações com partes bem distintas, que interagem entre si e podem ser executadas em máquinas diferentes, como no caso da mineração de dados, que usaremos para ilustrar esse paradigma.

Mineração de dados, como veremos em detalhes posteriormente, é o processamento de um conjunto de dados para a obtenção de conhecimento util ao usuário.

O principal gargalo em mineração de dados é o elemento humano envolvido na análise dos dados, o que torna necessário o desenvolvimento de técnicas para gerenciar eficientemente esse processo, reduzindo o tempo para se chegar a descobertas uteis.

Esse é o objetivo da criação da plataforma Tamanduá, apresentada neste documento.

A separação do sistema em entidades identificadas no processo de mineração responsáveis pela gerência de bases de dados (originais e derivados), processamento de algoritmos e visualização de dados mostra-se adequada para a aplicação dos princípios de SOC/SOA.

Uma melhor organização e distribuição dessas "tarefas" na forma de serviços oferecidos independentemente possibilita a configuração dinâmica e a flexibilização desse processo interativo.

Tendo em vista a discussão anterior, o objetivo deste trabalho é estudar arquiteturas orientadas a serviços SO usando Web Services e as novas tecnologias que têm surgido para dar suporte a aplicações baseadas nesse paradigma.

A criação sistemas desse tipo depende do estudo e avaliação de diversas plataformas, padrões e especificações existentes para que se possa escolher quais utilizar.

E importante conhecer as várias opções e entender o seu funcionamento para proporcionar ao usuário a melhor experiência possível com o sistema.

Essa dissertação visa estudar a aplicabilidade e o desempenho de Web Services com um estudo de caso em uma arquitetura orientada a serviços real.

A contribuição principal será a ilustração dos passos necessários para a concepção e o desenvolvimento de aplicações baseadas em serviços, apontando dificuldades e possíveis soluções para questões que fazem parte desse novo modelo de programação.

Aplicações de mineração de dados e descoberta de conhecimento vêm se tornando mais importantes a cada dia.

Como veremos em posteriormente, a construção de um ambiente distribuído para a mineração de grandes bases de dados define diversos requisitos interessantes, como localização e uso dinâmico de serviços remotos, que podem ser mapeados no modelo SOA.

Com base nessa observação, o caso de uso utilizado será o Tamanduá, serviço implementado com uma uma arquitetura baseada em Web Services que atende aos requisitos necessários para a mineração de dados de forma distribuída.

Essa plataforma já se encontra em operação e a sua extensibilidade e escalabilidade serão medidas para demonstrar a viabilidade e as potencialidades desse tipo de sistema.

O Tamanduá é, então, um dos resultados mais visíveis desta dissertação, uma plataforma de mineração de dados baseada em Web Services sendo usada para minerar dados reais em projetos do governo e ligados à UFMG.

A implantação do Tamanduá se mostrou complexa devido a requisitos específicos do problema, porém novas técnicas de desenvolvimento têm surgido para auxiliar a tarefa do programador.

Este ainda não é um sistema completo de descoberta de conhecimento em bases de dados, porém demonstra o grande potencial do uso de SOA e Web Services.

A estruturação do sistema permite a duplicação de servidores para melhorar o desempenho e a extensão da plataforma com a adição de novos serviços.

A plataforma Tamanduá está em operação e os experimentos apresentados na seção 5mostram que ela possui bom desempenho e pode ser escalonada para atender ao aumento da demanda de usuários.

A análise de desempenho realizada aqui serve também de apoio a novos trabalhos na área de Web Services.

Neste capítulo são apresentados alguns conceitos importantes para o bom entendimento do texto.

Para atingirmos nosso objetivo de discutir o uso de Web Services e SOA para a construção de aplicações distribuídas, falaremos de algumas das necessidades para a implementação de Web Services e das ferramentas utilizadas.

Além disso, discutiremos outras tecnologias existentes, como grades computacionais, e como elas se inserem no conceito de arquiteturas orientadas a serviços.

Mostraremos também uma visão geral sobre mineração de dados, que será utilizada como motivação para a construção da aplicação baseada em SOA, apresentada no capítulo 4.

Como estamos discutindo a criação de serviços na Internet, primeiro é necessário entender o que é um serviço.

Serviço é um recurso abstrato que representa a capacidade de executar tarefas que possuam uma funcionalidade coerente na visão do provedor e do consumidor.

De forma geral, um serviço computacional (implementado por um programa de computador) pode ser oferecido através de uma interface com o usuário, como um aplicativo ou site Web, ou pode ser implementado e disponibilizado por um componente de software para ser usado por outros componentes, como um serviço de impressão utilizado por diversos aplicativos.

Assim como a interface com o usuário deve ser de fácil entendimento, um serviço prestado a outro programa deve ter uma interface e um protocolo de comunicação bem definidos para que os clientes possam utilizá-lo.

Uma interface é uma especificação que existe entre componentes de software que define as formas de interação entre eles, muitas vezes chamada de contrato.

Uma interface pode definir, por exemplo, métodos, constantes e tipos de dados.

O protocolo de comunicação é uma especificação do conjunto de mensagens quais as mensagens e qual o formato de cada um trocadas entre os aplicativos.

Erroneamente, pode-se considerar que serviço é um outro termo para denominar componentes.

Muitas das boas práticas das metodologias de desenvolvimento e integração baseado em componentes são relevantes na definição de serviços, mas esses ultimos são independentes de arcabouços técnicos específicos de linguagens ou plataformas.

Algumas definições sugerem que serviços é um outro termo para interfaces.

Um serviço pode incluir uma interface, mas ele não assume que o consumidor pode utilizar mecanismos de implementação da maneira como interfaces vêm sendo tradicionalmente utilizadas.

Consideraremos então que serviços são funcionalidades expostas por componentes, através de um contrato (ou interface), para serem utilizados por outros componentes.

Essa definição exclui serviços oferecidos diretamente ao usuário final, que serão chamados aqui de aplicativos ou programas.

Para se aplicar os conceitos de Web services é preciso entender as idéias por trás da sua criação e conhecer as principais tecnologias e padrões envolvidas na sua criação.

Como mencionado anteriormente, há uma grande demanda por soluções que viabilizem a integração entre programas de computador implementados por diferentes empresas e implantados em lugares distintos.

Para que isso seja possível é necessário que aplicações diferentes, nas mais diversas plataformas, consigam solicitar serviços de outros programas mesmo em máquinas remotas, muitas vezes em outras organizações, através de trocas de mensagens que devem ser entendidas por todas as partes envolvidas na comunicação.

Esse modelo de solicitação de serviços é bastante semelhante a uma chamada remota de procedimento (RPC, Remote Procedure Call), onde uma aplicação executa um procedimento localizado em outro programa através da rede.

Para a comunicação entre as empresas, é importante que os protocolos utilizados sejam amplamente difundidos para tornar possível e viável a integração entre os sistemas com a invocação de métodos remotos através da Internet, um ambiente extremamente heterogêneo.

O uso da Internet para a comunicação nesse caso é uma boa opção, apesar da heterogeneidade, já que muitas delas já possuem conexão com a rede mundial.

A WWW possibilitou a criação de diversas aplicações acessíveis através de um navegador, de tal forma que o usuário pode utilizar os mais diversos serviços somente com o cliente Web.

Há servidores Web implementados para as mais diversas plataformas existentes.

O protocolo de acesso a recursos remotos na WWW, o HTTP, é também uma boa via para a transmissão das mensagens entre as empresas, uma vez que sua implementação é bastante conhecida e padronizada.

A criação de serviços baseados na WWW para a comunicação entre componentes de software que sejam acessíveis através de protocolos bem definidos e amplamente aceitos na Internet é o que se entende normalmente pelo termo Web Services.

E difícil definir exatamente o que são Web Services devido à grande quantidade de tecnologias envolvidas e há sempre confusões.

Web Service descreve funcionalidades de negócio específicas expostas por uma companhia, usualmente através de uma conexão Internet, com o propósito de prover uma maneira para que outras companhias ou programas usem o serviço.

Define-se WS como uma peça da lógica de negócios, localizada em algum lugar na Internet, que é acessível através de protocolos da Internet baseados em padrões, como HTTP ou SMTP.

Como já mencionado brevemente, uma Arquitetura Orientada a Serviços SO é um conjunto de princípios para construção de software, no qual os mais importantes são a procura por uma modularidade apropriada e pouco acoplamento entre os componentes.

Como veremos, há várias tecnologias para implementar serviços e qualquer uma delas pode ser usada para a montagem de aplicações baseadas em SOA.

As principais características de SOA são, serviços são componentes de software que publicaram seus contratos (ou interfaces).

Esses contratos são independentes de plataforma, linguagem ou sistema operacional.

Consumidores podem encontrar serviços dinamicamente.

Serviços são interoperáveis.

Uma visão geral do paradigma SOA é mostrado.

Uma aplicação que utiliza SOA normalmente é dividida em camadas.

A camada de serviços é responsável pela interface entre a camada de negócios (onde o processamento é realizado) e as aplicações externas.

Pode-se por exemplo, criar uma camada abstrata baseada em Web Services para aplicações legadas e, posteriormente substituí-la, se for conveniente.

Para acessar os serviços, pode ser utilizado uma interface com o usuário (GUI ou WWW), ou por outro componente responsável pelo gerenciamento do processo (a aplicação que está utilizando esse serviço).

O mais importante princípio de SOA é a interoperabilidade.

E fundamental que todos os componentes se comuniquem independente da linguagem em que foram construídos, do sistema operacional em que estão sendo executados e da arquitetura de hardware.

Web Services atendem bem a esse requisito já que, como visto anteriormente, utilizam protocolos e formatos de documentos padronizados e aceitos.

Nessa dissertação seguiremos o uso que vem sendo comumente adotado em língua portuguesa, usando o termo Web Service (WS) para a designação do conjunto específico de tecnologias apresentadas nesta seção, enquanto o termo traduzido (serviço We será usado para a referência a serviços (ou aplicativos) sobre a WWW de forma mais genérica.

Paradigma básico para Arquiteturas Orientadas a Serviços SO.

Diferentes camadas de uma aplicação orientada a serviços.

Entretanto, apesar de a interoperabilidade ser o seu benefício chave, a diversidade de implementações de bibliotecas para suporte de Web Services e a flexibilidade permitida em alguns pontos da especificação torna difícil a concretização dessa característica.

A Organização para Interoperabilidade de Web Services (WS-I, Web Services Interoperability Organization) é uma organização da indústria para a promoção da interoperabilidade entre esses serviços baseada em definições e padrões XML relacionados aceitos por todos.

O WS-I cria guias e ferramentas para ajudar desenvolvedores a criar e certificar Web Services compatíveis.

O primeiro guia da organização foi o WS-I Basic Profile 10, que tenta aperfeiçoar a interoperabilidade pretendida na especificação.

Com base nos princípios de SOA, para se implementar serviços no modelo de Web Services, com ampla aceitação, fácil acesso, independência de arquitetura e fácil processamento por aplicações.
Um conjunto de elementos é necessário, um protocolo de transmissão de dados amplamente adotado, um formato de representação de dados independente de arquitetura, uma forma de se exprimir claramente a localização, funcionalidades e interface de acesso de cada serviço e um protocolo que expresse a semântica do processo de requisição de serviços e obtenção de respostas que se pretende implantar.

Cada um desses elementos é discutido a seguir, com as opções normalmente adotadas para Web Services.

O HyperText Transfer Protocol (HTTP) é o protocolo utilizado na WWW para a transferência de recursos (como páginas, documentos e imagens).

Como visto anteriormente, seu uso é bem padronizado e amplamente aceito, permitindo a flexibilidade necessária às aplicações Web.

A sua adoção para a invocação de serviços remotos resolve um dos maiores problemas desse tipo de comunicação, a restrição imposta por administradores de rede, que limitam acesso externo a servidores, mantendo o acesso a portos TCP fechados a menos que sejam absolutamente necessários.

O protocolo HTTP, por ser bastante utilizado, tem seu porto padrão (associado normalmente a servidores WWW) normalmente liberado na maioria das organizações, o que o torna um bom candidato como o canal de transferência de dados.

Arquiteturas tradicionais de acesso remoto como DCOM, CORBA e RMI requerem múltiplos portos TCP abertos através de um firewall, o que muitas vezes impede conexões sofisticadas, inclusive entre organizações, para conexões entre os serviços.

Por utilizarem HTTP, o uso de Web Services não requer portos adicionais ou permissões de acesso além daquelas de servidores WWW padrão.

Depois do protocolo de comunicação, um segundo problema a ser resolvido é o do formato de representação de dados a ser utilizado.

Em um ambiente heterogêneo como a Internet é necessário um formato bem definido para utilização em protocolos e documentos, que possibilite a compreensão universal das mensagens trocadas entre os programas de computadores com as mais diversas plataformas.

Nesse contexto é que surgiu oXML (Extensible Markup Language), um formato de texto baseado em marcações, aberto e flexível, padronizado pelo WC.

O XML é hoje apoiado mundialmente pelas maiores empresas de tecnologia e usado para a troca e armazenamento de diversos tipos de dados.

Por ser baseado em marcações de texto (assim como o HTML) XML é, ao contrário de formatos binários, passível de entendimento por seres humanos, ao mesmo tempo em que pode ser processado por software ou hardware para a extração dos dados auto-descritos.

O sucesso de XML vem de sua sintaxe clara e simples e sua estrutura sem ambiguidades.

O XML permite a verificação da qualidade de um documento, através de regras de sintaxe, verificação de vínculo interno, comparação com modelos de documento e tipos de dados.

A descrição, publicação e localização de modo uniforme é outro fator importante para a utilização de serviços distribuídos.

O WSDL (Web Services Description Language) é um formato de texto baseado em XML, criado para descrever os serviços disponibilizados a partir de um determinado endereço na Internet, incluindo seus parâmetros e protocolos sobre os quais o serviço pode ser solicitado.

Essas descrições são documentos WSDL, utilizados pelos clientes para a criação das mensagens que serão utilizadas para solicitação dos serviços.

Tais descrições podem ser publicadas em qualquer repositório, normalmente implementados utilizando o protocolo UDDI (Universal Description, Discovery and Integration).

Com o UDDI é possível descobrir dinamicamente, através de uma série de interfaces padronizadas, quais serviços são publicados por cada provedor de serviços e quais as interfaces oferecidas pelos mesmos.

Para o envio da requisição por serviços sobre HTTP com o controle da semântica de requisição e resposta específica desse tipo de comunicação pode ser utilizado o protocolo SOAP (Simple Object Access Protocol), que é capaz de descrever completamente uma chamada remota de procedimento, com seus respectivos parâmetros, mesmo as mais complexas estruturas de dados.

O SOAP é, em sua essência, um protocolo assíncrono baseado em XML para intercâmbio de informações em ambientes distribuídos.

Fundamentalmente, há transmissões de via unica do remetente para o receptor, e o modelo RPC é apenas um caso especializado que combina múltiplas mensagens assíncronas em um padrão de requisição e resposta.

Existe também um outro modelo, menos utilizado, orientado a documentos, onde é enviado em uma mensagem SOAP um documento XML qualquer, que obedece um esquema determinado pelo dono do serviço por exemplo, definido com XML Schem.

Uma mensagem SOAP (também chamada envelope) pode incluir dados anexados SOAP with Attachments, Sw, inclusive em formatos binários.

A conjunção de vários serviços para a realização de tarefas em comum torna necessário um componente que agrupe e comande esse conjunto.

Esse processo é denominado orquestração de serviços e já existem algumas ferramentas e padrões propostos para a execução desses processos aglomerados.

A OASIS (Organization for the Advancement of Structured Information Standards,tem um padrão chamado Business Process Execution Language (BPEL) que tem sido adotado por diversas empresas.

Como mencionado anteriormente, o WS-I Basic Profile 10, que tenta aperfeiçoar O SOAP pode, em princípio, ser utilizado sobre qualquer protocolo de transporte, como o SMTP.

Entretanto, o HTTP é o mais comum atualmente.

Interação simples de Web Services.

A interoperabilidade pretendida na especificação de Web Services define o uso de XML Schema 10, SOAP 11, WSDL 11 e UDDI 20.

Como mencionado, apesar de Web Services utilizando o conjunto HTTP, XML, SOAP, UDDI, et ser o foco desta dissertação, essa não é a unica forma de se implementar uma arquitetura orientada a serviços.

A título de ilustração, esta seção discute outros mecanismos recentes que dão suporte à criação de serviços computacionais distribuídos, servindo de apoio para o desenvolvimento de aplicações baseadas em SOA.

Foi proposto um outro estilo arquitetônico para a criação de serviços Web, diferente do modelo de chamada remota de procedimento adotado pelo SOAP, denominado REST (REpresentational State Transfer).

REST é um conjunto coordenado de regras arquitetônicas que procura minimizar a latência e a comunicação em rede enquanto maximiza a independência e escalabilidade da implementações de componentes.

O protocolo HTTP já é, em si, um protocolo do tipo requisição/resposta, por isso esse estilo descreve uma arquitetura que utiliza o que a Web tem de melhor, propondo o uso de um conjunto pequeno e abrangente de métodos remotos mapeados nos métodos do protocolo HTTP, GET, POST, PUT, DELETE, et aplicável a qualquer coisa-mais especificamente, qualquer recurso.

Ou seja, não são necessários outros métodos por exemplo, os mapeados em objetos numa comunicação RP além daqueles já definidos pelo HTTP.

Isso porque, independente de qual seja o cliente e o servidor Web utilizado, sabe-se que com uma URI do tipo pode-se retirar o documento associado usando o comando GET e substituí-lo por outro usando o comando PUT, sem nenhum conhecimento a mais além da especificação do protocolo HTTP.

Dessa forma, a comunicação é feita através da troca de recursos.

Por exemplo, um documento pode ser acessado, alterado localmente e re-enviado ao servidor, alterando-se assim o seu estado.

Em outro cenário, um sistema para empresas aéreas pode permitir que um documento descrevendo (com um esquema pré-conhecido) a origem, destino e hora do vôo seja postado no servidor, disparando o subsistema de emissão de passagem aérea, que gera um bilhete eletrônico a partir daqueles dados.

Para consulta sobre a confirmação da passagem, o cliente acessa aquele documento passando parâmetros pela URL.

Esse estilo de criação de serviços também pode ser chamado de Web Services, pois permite a comunicação entre programas de computador através da troca de arquivos XML pela WWW.

Tem ainda a vantagem de permitir ao usuário a realização de consultas aos recursos com o uso de um navegador WWW comum.

O REST vem sendo adotado por alguns provedores de serviços, normalmente em paralelo a uma versão usando SOAP.

Esse é, por exemplo, o caso da Amazon com, que utiliza Web Services com versões em SOAP e REST para acesso aos seus serviços.

Entretanto, não há uma padronização suficiente para a criação de um modelo unico para que possa ser adotado largamente entre as empresas.

O barateamento e a popularização dos computadores nos ultimos anos vem tornando sub-utilizados seus recursos.

Processadores, memória e até discos ficam ociosos a maior parte do tempo.

Numa empresa, por exemplo, os computadores ficam desligados ou simplesmente parados fora do horário de expediente e durante os intervalos dos funcionários.

O grande crescimento da banda disponível de rede interligando todos esses aparelhos pela Internet torna viável a utilização desses recursos por terceiros, remotamente.

Por exemplo, um usuário que precisar de maior poder de processamento pode utilizar processadores que estão parados na rede para a execução de seus programas, tendo a sensação de dispor de um grande processador, e oferecer o seu para que outros o utilizem quando não estiver precisando.

Esse é o princípio básico das Grades Computacionais (Grid Computing).

Grades vêm ganhando grande popularidade em sistemas distribuídos, oferecendo 5 tecnologias e infra-estruturas para suportar compartilhamento e uso coordenado de diversos recursos em organizações virtuais dinâmicas e distribuídas, proporcionando uma arquitetura para uso de recursos computacionais em escala global.

Dentro do conceito de grades, é possível executar uma aplicação (ou várias, com um objetivo unico) em diversos processadores espalhados pela Internet.
Para uma fácil virtualização, ou seja, o uso, através de uma mesma interface, de máquinas variadas, possivelmente de diferentes arquiteturas e operando sob diferentes sistemas operacionais, todos os recursos em uma grade computacional podem ser vistos como serviços, recursos de processamento e de armazenamento, redes, programas, bancos de dados, etc.

Para isso, os autores definem a idéia de Serviços em Grade (Grid Services), um Web Service que provê um conjunto de interfaces bem definidas e que seguem convenções específicas, com mecanismos para criação, nomeação e descoberta de instâncias de serviços na grade, transparência de localização e multiplicidade de protocolos e integração com plataformas já existentes.

Web Services e computação em grade estão atualmente bastante interligados.

Ambos se propõem a criar ambientes de execução distribuídos, onde diversos componentes ou partes do sistema, que podem estar espalhados por diversas máquinas distintas, realizam uma fração do problema para alcançar o resultado esperado.

Entretanto, essas tecnologias se diferenciam em alguns aspectos.

Grades são planejadas para o compartilhamento de recursos, com manutenção de estado em cada componente, enquanto Web Services são orientados a serviços que podem ser totalmente independentes e descolados do restante da aplicação, onde podemos ter cada requisição totalmente independente da anterior.

Serviços em Grade podem ser implementados sobre Web Services, como acontece com a arquitetura de serviços do Globus, o Open Grid Services Architecture OGS.

Baseada nos conceitos e tecnologias de Grid e Web Services, essa arquitetura define uma semântica unificada de serviços, mecanismos para criação, nomeação e descoberta de instâncias de serviços na grade, transparência de localização e multiplicidade de protocolos e integração com plataformas já existentes.

Entretanto, OGSA usa uma extensão de WSDL, não compatível com os padrões de Web Services atuais.

Além do mais, ainda não há um padrão definitivo e aceito universalmente para a construção de grades computacionais e para o uso de serviços em grade, como há para Web Services.

Novas tecnologias e especificações, ainda em estudo, vêm evoluindo e aperfeiçoando essas duas tecnologias, tornando-as mais próximas.

Essas especificações fazem parte do WS-Resource Framework, ainda em desenvolvimento.

Redes peer-to-peer (PP) ganharam muita popularidade com os sistemas de trocas de arquivos-principalmente músicas e filmes-entre usuários da Internet.

Desconsiderando as questões legais envolvidas, esses sistemas se mostraram eficientes e escaláveis, na medida em que formam redes virtuais entre diversas máquinas, replicando recursos e os disponibilizando para outros que estejam mais próximos.

Dessa forma, novas rotas podem ser traçadas através da Internet, "pegando carona" em máquinas de outros usuários para evitar caminhos com muito tráfego.

Fundamentalmente, muitas das redes PP modernas funcionam baseadas em um mecanismo de publicação dos recursos disponíveis em nós nomeados como repositórios (também conhecidos como super-nós), em uma busca pelo recursos desejados baseada em suas características (incluindo palavras chaves e tipo), e na recuperação desse recurso de várias entidades que o possuam.

Esse modelo de acesso a elementos remotos pode também ser utilizado para a disponibilização de serviços, se eles forem tratados como mais um tipo de recurso.

Esse foi o modelo adotado pelo JXTA, um projeto livre, iniciado pela Sun Microsystems e apoiado por outras empresas e instituições.

O JXTA enxerga um serviço como um recurso disponível numa rede virtual.

O provedor do serviço pode publicar um anúncio na rede descrevendo suas funcionalidades e a sua interface.

O cliente, ao localizar o serviço desejado, pode invocá-lo de um ou mais provedores através de uma conexão virtual (chamada pipe), que pode trafegar entre nós diferentes na tentativa de um caminho com menos tráfego, e até mesmo, ser deslocada para outro provedor do serviço, caso o anterior se torne indisponível, sem interrupção da comunicação.

O JXTA é boa solução para implementação de serviços distribuídos pois é independente de plataforma e linguagem, é bastante flexível e pode ser até implementado utilizando Web Services para a comunicação.

Para transpor a barreira imposta por firewalls, o JXTA utiliza a tática de utilizar um ponto externo à rede como uma ponte, que é responsável por intermediar a comunicação entre os demais pontos e o ponto atrás da barreira.

Assim como os serviços em grade, adiciona à simples publicação e utilização de serviços mecanismos mais elaborados, como a descoberta e localização ponto-a-ponto, a elaboração de rotas virtuais alternativas, etc.

Entretanto, apesar de o JXTA ser um projeto aberto, ele ainda não é um padrão reconhecido para aplicações PP, usado por todas as aplicações desse tipo.

Há diversos outros produtos e protocolos sendo desenvolvidos com a mesma finalidade.

A disseminação e popularização do uso de sistemas computacionais em todas as áreas do conhecimento vêm gerando um enorme crescimento na quantidade de dados processados e armazenados em instituições e empresas de todos os tipos.

Registros de compras de supermercados e de utilização de planos de saúde, informações sobre concessões de crédito, estoque, compras e vendas, dados coletados em pesquisas, entre outros, são exemplos de bases de dados que, sem nenhum tratamento especial, escondem por vezes conhecimentos relevantes.

A grande quantidade de informação contida nesses arquivos ou banco de dados, ou mesmo outros tipos de armazenamentos (que chamaremos neste texto, genericamente, de bases de dados), possui pouco ou nenhum valor se não servir de fonte para a aquisição de novos conhecimentos.

O processo de descoberta de conhecimento em bases de dados (KDD, Knowledge Discovery in Databases), serve como uma base para guiar tarefas de exploração da informação e descoberta de conhecimento.

KDD envolve diversas etapas, o pré-processamento (composto de limpeza e integração dos dados, seleção e transformação) para tornar os dados consistentes, completos e em conformidade com as necessidades do algoritmo.

A mineração de dados, com a aplicação de um algoritmo concreto para encontrar estruturas e padrões.
A avaliação, apresentação e interpretação de resultados, com diferentes métricas, afim de filtrar padrões mais interessantes ao usuário e provê-lo com o conhecimento desejado.

Desses, a mineração dos dados em busca de padrões interessantes é a mais importante, sendo muitas vezes confundida com o conceito geral de KDD.

O pré-processamento dos dados é necessário na maioria das vezes, para permitir que sejam utilizados corretamente na mineração.

Para a operação correta do processo, é necessário a eliminação de erros nas bases, complementação de dados essenciais faltosos e a integração em um conjunto de dados comum.

Alguns algoritmos exigem também que dados sejam transformados, por exemplo, discretizando valores contínuos colocando-os em intervalos bem definidos, como 10, 20, et.

O passo de mineração de dados no processo de KDD envolve a aplicação de algoritmos, ferramentas e técnicas apropriadas a conjunto de dados pré-processados para facilitar a exploração de dados e extração de padrões uteis.

Processo de Descoberta de Conhecimento KD.

Há vários tipos de algoritmos de mineração de dados, como regras de associação (association rules), agrupamento (clustering) e árvore de decisão, entre outros.

Mineração de Regras de Associação (ARM, Association Rule Mining) é um dos algoritmos mais comuns e vem se tornando um dos principais em mineração de dados.

O uso de ARM permite extrair regras que relacionam itens que frequentemente ocorrem juntos em uma transação, ou seja, definir como e quanto a presença de um subconjunto de itens influencia na presença de outro subconjunto.

Com o uso de ARM podemos identificar regras como, 98% dos clientes que compram pneus e acessórios automotivos compram também o serviço completo de manutenção.

O uso de ARM tem muito valor em diversas áreas, como por exemplo, em marketing, ajudando a identificar perfis de usuários ou escolher a melhor disponibilização de produtos nas lojas.

Em pesquisas médicas, identificando padrões em cadeias de DNA.

Na área policial, identificando características e padrões em comportamentos de criminosos.

Outra técnica importante é a de identificação de agrupamentos (clustering), quando grandes conjuntos de dados são divididos de forma a separar seus elementos em grupos distintos que apresentem características semelhantes entre si e diferentes daquelas de outros grupos.

Com isso, padrões de separação dos dados podem ser identificados e os elementos podem ser analisados de forma simplificada em função dos grupos a que pertencem.

Processar todas essas informações tem um custo computacional muito alto, já que normalmente envolve enormes quantidades de dados.

Mesmo os mais eficientes algoritmos seq¨uenciais podem se tornar ineficazes quando analisam bases muito grandes, gastando muito tempo no processamento e muitas vezes não conseguindo chegar ao resultado esperado.

Assim, a implementação de algoritmos de mineração de dados em ambientes paralelos de alta performance é crucial para melhorar os tempos de resposta.

A avaliação, apresentação e interpretação dos dados constituem um processo interativo, onde o usuário pode visualizar os resultados da mineração, adequando-os às suas necessidades.

A ferramenta de visualização pode ser usada como uma sumarização para que o usuário final tenha uma visão geral de um conjunto de dados.

Isso possibilita tomar decisões mais acertadas com relação à preparação de dados.

A visualização dos dados pode ser feita de diversas formas, de acordo com o tipo de informação disponível e a percepção do usuário.

Resultados da busca por regras de associação devem ter uma metáfora visualmente diferente dos resultados de um agrupamento de dados (clustering).

A criação de metáforas que correspondem ao desejo e entendimento do usuário ainda é um campo aberto e várias propostas podem ser encontradas na literatura.

Programas distintos podem representar de forma diferente um mesmo conjunto de dados, e seria interessante permitir que o usuário, com poucas informações, pudesse escolher a que melhor lhe convém.

Sistemas de mineração de dados evoluíram a partir de sistemas stand-alone caracterizados por algoritmos simples com pouco suporte para o processo de descoberta de conhecimento, tornando-se sistemas integrados que incorporam diversos algoritmos de mineração, múltiplos usuários, vários formatos de dados e fontes de dados distribuídos.

A relação base de dados, algoritmo de mineração, visualização de resultados necessária para a transformação de dados puros em entendimento pode se dar através de diversas combinações entre essas entidades, num processo interativo.

Resultados intermediários gerados por uma técnica de mineração de dados podem ser analisados por um analista humano, que irá, a seguir, decidir como proceder, talvez usando uma segunda técnica.

Isso pode envolver re-seleção iterativa de conjuntos de dados e atributos, e qualquer passo de pré-processamento necessário.

Esses requisitos apontam para o uso de arquiteturas orientadas a serviço, onde cada etapa é executada em um ou mais componentes distribuídos que oferecem seus recursos bases, algoritmos, implementação de visualização, et aos demais.

Como vimos, Web Services atendem aos requisitos para esse tipo de sistema, como localização dinâmica de serviços, padronização nos protocolos e na definição de como acessá-los.

O desempenho apresentado por um serviço Web é fundamental para o seu sucesso.

Um serviço com desempenho insatisfatório na visão do cliente tende a não ser mais utilizado.

E necessário que o serviço esteja sempre disponível e atenda a requisitos claros de qualidade e desempenho.

A qualidade do serviço (QoS, Quality of Service) depende do que o cliente espera do sistema.

Como o usuário do sistema não interage diretamente com os Web Services, sua percepção se refere à aplicação que faz uso deles.

O usuário de um serviço distribuído deseja rapidez, tempo de resposta previsível e disponibilidade todo o tempo.

Portanto, para garantir a qualidade é preciso monitorar dados como o tempo de resposta, os erros que podem tornar o sistema indisponível e a utilização dos recursos da máquina.

O tempo percebido pelo usuário para obter uma resposta a uma requisição de um serviço WWW, o tempo de resposta fim-a-fim, é uma das principais métricas para avaliação do desempenho de sistemas Web e pode ser dividido em dois componentes principais, tempo de rede e tempo de processamento no(s) servidor(es) responsável(is) pelo serviço.

O tempo de rede inclui todo o tempo gasto na transmissão das mensagens entre o cliente o serviço, é composto de latência, que representa o tempo necessário para o envio da requisição e o retorno de um aviso de recebimento ou da resposta envolvidos na troca de mensagens, chamado round trip time (RTT), e o tempo de transmissão, gasto na transmissão dos dados, que depende da largura de banda no link mais lento no caminho entre cliente e servidor.

O tempo no servidor pode ser dividido entre tempo de serviço, tempo em que a requisição está recebendo serviço de algum recurso como uma CPU, disco ou rede, e tempo de espera, a soma de todos os tempos de espera para acesso aos recursos, quando a requisição é enfileirada no sistema.

Outra métrica muito utilizada é o throughput, a quantidade de dados que podem ser processados e/ou enviados de um local a outro em um determinado espaço de tempo.

Para serviços Web, podemos dizer que o throughput é a taxa na qual requisições HTTP são servidas (normalmente expressa em requisições por segundo).

No caso de uma plataforma baseada em serviços, o tempo de resposta percebido pelo usuário é constituído do tempo de rede até a aplicação principal (se essa estiver localizada remotamente) e o seu processamento, mais o tempo para acesso aos serviços distribuídos.

Para os serviços que agregam ou fazem uso de outros serviços, os acessos a esses serviços se somam ao do serviço principal.

Portanto, quanto menor o tempo gasto com um serviço, melhor será o tempo de resposta total percebido pelo usuário.

Vários fatores podem contribuir para degradar o desempenho de um Web Service, como, largura de banda insuficiente em períodos de pico, servidores sobrecarregados, cargas inconstantes no servidor, deficiência na comunicação com banco de dados, falhas de serviços de terceiros, etc.

Em um sistema que atende a vários usuários, como é o caso de sistemas Web, para evitar a perda de desempenho é necessário que ele seja escalável, ou seja, consiga se adaptar ao crescimento da demanda dos clientes.

Em um sistema escalável é possível conseguir mais poder computacional adicionando-se a ele um maior número de processadores (ou máquinas), mais memória, mais largura de banda ou quantidade de armazenamento, outras réplicas de um serviço, ou seja, é feita uma mudança de escala.

Por exemplo, um sistema distribuído escalável é aquele que pode começar com apenas algumas máquinas ou um mas pode ser expandido para várias máquinas, de modo a atender mais usuários simultâneos.

Escalabilidade é muito importante para um sistema porque significa que pode-se investir nele com poucos recursos e garantir que ele poderá crescer conforme a necessidade.

Nessa seção revisamos alguns dos trabalhos que vêm contribuindo para a evolução de arquiteturas orientadas a serviços SO e do processo de descoberta de conhecimento distribuído, bem como para a análise de desempenho de Web Services.

Os benefícios do uso de arquiteturas distribuídas e a idéia de aplicações baseadas em serviços que trabalham de forma cooperativa soam como um caminho evidente para aplicações que demandam grandes quantidades de dados e processamento, como é o caso da mineração de dados.

Porém, a avaliação da escalabilidade e do desempenho de Web Services é fundamental para tornar o uso de SOA uma solução viável.

O desenvolvimento de novos estilos de arquiteturas de software baseados em formas estruturais como objetos e componentes não seriam suficientes para gerar avanços significativos para o desenvolvimento de software.

Os autores previram um futuro em que desenvolvedores teriam uma visão radicalmente diferente de como o software entregaria a sua funcionalidade aos usuários.

Foi realizado um estudo sobre a criação de software baseado em serviços, para suportar as novas demandas pela a criação de aplicações que estão sempre em evolução.

Os autores apontaram as necessidades e desafios dessa nova visão no desenvolvimento de software.
Critica-se a arquitetura atual da Internet, mostrando que novos requisitos vêm se tornando essenciais para o funcionamento de aplicações emergentes.

Esses requisitos incluem disponibilidade, confiabilidade, qualidade e segurança.

Para tornar a Internet um arcabouço viável para a implantação de novos serviços, enfatizam uma Internet totalmente orientada a serviços (SOI, Service Oriented Internet), baseada em três principais abstrações, uma noção de nuvem de serviços, um novo esquema de endereçamento em dois níveis, independente de localização e uma nova camada abstrata de serviço, usada para encaminhar os pacotes para o serviço de destino apropriado.

A necessidade de criação de protocolos de comunicação entre aplicações na Internet, com uso de XML, começou a ser discutida em 2000 pelos membros do WC, e em 200Austin li apresentaram o primeiro rascunho sobre o assunto, onde definem alguns requisitos básicos para a construção de serviços baseados nos protocolos mais utilizados da WWW, os Web Services.

Os desafios e as novas idéias trazidas por esse conjunto de tecnologias foram discutidas, e procurou-se enxergar a Internet como um grande sistema operacional (com diversos serviços disponíveis) onde não há separação entre o que é aplicação local e o que é global.

Essa é uma visão bastante interessante, que torna mais acessível a percepção das possibilidades que estão sendo criadas com SOC.

O autor antecipa também alguns requisitos que serão necessários nesse contexto, como confiança, semântica e coordenação de serviços.

A importância de SOA e o uso de Web Services para implantação desse novo estilo arquitetônico, bem como os desafios a serem enfrentados, foi amplamente discutido por diversos autores, que serviram de guia para esse trabalho.

Um dos primeiros trabalhos sobre disponibilização de mineração de dados como serviços na Internet foi proposto.

Nele, os autores apresentam alguns desafios interessantes a serem analisados para sistemas desse tipo, que podem ser providos por qualquer um com dados e experiência adequados, como padrões para descrição de modelos de mineração, segurança e confiabilidade, integração de modelos de origens distintas e personalização usando dados do usuário.

O trabalho é focado em Application Service Providers (ASPs), provedores de soluções corporativas em aplicações completas e independentes, para modelos de mineração de dados, apresentando alguns cenários de exemplo onde esses serviços poderiam ser utilizados, porém sem propor soluções.

Compara-se diversos provedores de serviços (ASPs) de mineração de dados baseados na Internet.

Estes requerem que o usuário envie seus dados ao provedor de serviços (com quem normalmente a empresa possui um contrato) e acesse os resultados através de uma interface WWW.

Após discutirem situações de uso desses serviços e questões relacionadas a cada um, propuseram um modelo de múltiplos provedores de serviço, definindo os protocolos de interação e um mecanismo de troca de informações e descrição de requisição por tarefa baseado em XML.

O modelo funciona na forma de uma "federação" de provedores de serviço, usando um componente de coordenação chamado federation manager, que gerencia as interações entre o cliente e os provedores, buscando o que melhor satisfaz as necessidades do usuário.

O cruzamento das preferências do cliente com as capacidades do provedor de serviços é feito através de avaliações de expressões XPath, uma linguagem para endereçamento de partes de um documento XML que pode ser usada para casamento e teste de padrões.

Outro enfoque abordado, além dos anteriores, é o modelo para mineração de dados baseado em agentes móveis.

A idéia é basicamente o agente ir até onde estão os dados e onde deve ser feita a mineração, comunicando-se entre si para a realização da várias tarefas do processo de mineração.

Porém, essa abordagem não tem sido muito usada devido ao pequeno número de plataformas de agentes móveis disponíveis.

Os modelos de realização de mineração de dados por ASPs ou agentes são diferentes do adotado pelo Tamanduá.

No primeiro caso, a mineração é feita inteiramente por um unico provedor de serviço, que o usuário deve escolher conforme suas necessidades e se adaptar a ele.

Isso implica, entre outras coisas, em enviar toda a base de dados para o site do executor da mineração.

No segundo, a aplicação é que vai até os dados, exigindo um ambiente bem controlado e seguro para evitar acessos indevidos desses aplicativos.

Já o Tamanduá, como veremos, utiliza diversos serviços distribuídos que trabalham em conjunto para a realização da mineração de dados.

O uso de grades computacionais (Grid Computing) também tem atraído a atenção dos trabalhos em mineração distribuída (veja seção 22).

A primeira tentativa de mineração em grades parece ser de Mahinthakumar li, que implementaram um algoritmo de mineração de dados em cluster sobre o Globus para executá-lo em diversos computadores heterogêneos distribuídos geograficamente, usando uma versão do MPI para Globus (MPICH-G).

Conceitos de grades baseadas em conhecimentos (knowledge-based Grids).

A primeira definição de uma infraestrutura para mineração de dados baseada em Grid Services foi realizada.

O Knowledge Grid foi construído sobre um conjunto básico de serviços que dão suporte aos serviços de mineração.

Esse conjunto básico é normalmente oferecido pelas plataformas de grid.

O Knowledge grid possui uma interface gráfica que permite a visualização da execução das tarefas (VEGA, Visual Environment for Grid Applications), porém não foi apresentado nenhum uso em aplicações concretas.

O GridMiner é uma arquitetura mais recente para mineração de dados distribuída, baseado no Globus toolkit 30 e OGSA-DAI.

E um sistema completo e atende a todos os requisitos necessários para a mineração de dados, utilizando serviços distribuídos para a gerência de dados e execução de algoritmos.

Porém em nenhum dos artigos encontrados sobre o assunto é apresentado estudo sobre a escalabilidade do sistema, o que é muito importante e será apresentado aqui para o Tamanduá.

A mineração de dados através de ASPs, agentes móveis ou grades não é o foco desse trabalho e representam outras formas de prover esse serviço, diferentes do usado no Tamanduá.

Não foi encontrado nenhum trabalho que utilize as tecnologias de Web Services para a execução de um processo de KDD.

Discute-se detalhadamente questões relacionadas à qualidade de serviço em todos os tipos de serviços WWW, usando uma abordagem quantitativa.

Provêem um arcabouço para entender as complexas relações da WWW e como isso impacta no desempenho e disponibilidade dos serviços.

O enfoque analítico adotado pelos autores, que usa cálculos matemáticos para a investigação profunda do desempenho desses serviços, não será adotado nesse trabalho, que possui um enfoque mais experimental.

O desempenho de protocolos para acesso a serviços remotos, no estilo RPC (Remote Procedure Call) foi avaliado.

Foram levantados os requisitos para um protocolo usado na implementação de aplicações científicas-que contêm muitos números-, encontrando como denominador comum a confiabilidade, robustez, facilidade de leitura e uso, compatibilidade com códigos existentes e interoperabilidade.

O desempenho de SOAP, testado com a biblioteca Axis e gSoap, foi avaliado pelos autores em comparação ao JavaRMI e outras tecnologias proprietárias.

Apesar de SOAP ter sido mais lento que os demais, mostraram que ele atende aos critérios estabelecidos.

Posteriormente, examinaram os limites do desempenho de SOAP, destrinchando todos os passos necessários para a comunicação através desse protocolo, incluindo o processador XML e transmissão pela rede.

Em cada passo, foram sugeridas soluções para melhorar o desempenho, gerando códigos específicos para a aplicação, o que permitiu comparar diversas opções e se mostrou bem mais eficiente que as demais bibliotecas testadas.

Notaram que o desempenho baixo se deve, na maior parte, à conversão para texto de números de precisão dupla (double) em grandes arranjos (arrays), muito comum em aplicações desse tipo.

Com isso, os autores mostram que o SOAP e as bibliotecas têm muito o que melhorar para garantir um bom desempenho, e sugerem algumas soluções.

Em um trabalho semelhante,procurou-se identificar as fontes de ineficiência das implementações de SOAP.

Para isso, mediram a latência dos serviços usando algumas bibliotecas-Apache SOAP e Axis Alpha (em Jav, SoapRMI (em Jav, SOAP,Lite (em Perl), Microsoft SOAP Tool-kit em Visual Basi-em relação a JavaRMI e CORBA.

Testes foram feitos com cliente e servidor na mesma máquina e em máquinas separadas, para avaliar o impacto da transmissão pela rede.

Os mesmos serviços foram implementados usando cada biblioteca em sua respectiva linguagem de origem, desprezando tempo para procura no registro ORB do Corb e criação de objetos.

Foram medidos os tempos de três serviços sem parâmetros, porém um não retorna nada, outro retorna uma cadeia de caracteres (de tamanhos 200, 400, 800) e o ultimo retorna um arranjo de inteiros (também de tamanhos 200, 400, 800).

Perceberam que de 86% a 94% do tempo é gasto com o SOAP e processamento XML, e há grande impacto relacionado ao uso dos protocolos de transporte (TCP) e aplicação (HTTP) normalmente utilizados.

Os autores propõem ainda a adoção do JavaRMI sobre SOCKS (para atravessar firewalls), até uma melhor maturação do SOAP.

Analisou-se o uso do SOAP para aplicações financeiras, procurando avaliar o seu desempenho em relação a outros padrões comerciais.

FIXe CDR, um formato binário usado para comparar o custo de usar um formato textual nesse processo.

O estudo dos autores mostrou que o SOAP tem desempenho inferior aos outros dois protocolos, com tamanho maior de mensagens e menor throughput.

Porém, sugerem que para aplicações não científicas, onde o uso de números é menor, a análise de Chiu li, citada anteriormente, de que a transformação de números de ponto flutuante para texto (codificação e decodificação) é o principal fator desse mal desempenho, não é válida, já que o FIX apresenta desempenho semelhante ao CDR.

Propõem algumas práticas que podem ser adotadas pelos programadores para um melhor desempenho, como a compressão das mensagens SOAP (para economizar band e compactação das tags XML (a troca dos nomes das tags por cadeias de a caracteres reduziu o tamanho das mensagens SOAP em 25 a 35%).

Como vimos, muitos trabalhos já foram feitos comparando o desempenho de SOAP com outros protocolos de RPC, binários e textuais.

Vários problemas já foram apontados e alterações foram propostas, e nesse trabalho aceitamos esses resultados e não repetiremos esses testes e experimentos.

Entretanto, nenhum deles mostra a análise completa de desempenho de uma aplicação real baseada em SOA com Web Services, que será apresentada mais adiante.

Os métodos para a construção de aplicações orientadas a serviços diferem dos métodos tradicionais, em que desenvolvedores constroem softwares basicamente empregando alguma variação do ciclo editar-compilar-ligar.

Nesse novo modelo, o software a ser desenvolvido é descrito em função de um serviço oferecido e não mais das demandas de um usuário.

Serviços são configurados para atender um conjunto específico de necessidades num determinado momento, executados e descartados, a visão de um serviço instantâneo.

Essa é uma mudança significativa de visão que pode trazer confusão ao desenvolvedor.

Este capítulo aborda o processo de criação de aplicações baseadas em arquiteturas orientadas a serviços Service Oriented Arquitectures, SO, mostrando como identificar os componentes que deverão prover serviços, quais as suas interfaces e quais as opções de protocolos e tecnologias podem ser empregadas.

Por fim, apresentaremos o exemplo do Tamanduá, uma arquitetura baseada em serviços para a realização do processo de KDD, identificando as decisões tomadas em sua construção.

A construção de uma arquitetura orientada a serviços começa com a definição dos objetivos da aplicação.

Somente após os objetivos serem definidos é que podemos inferir quais os serviços deverão ser oferecidos e como esses serão agrupados em conjuntos de serviços relacionados, os quais serão aqui denominados servidores.

Cada servidor da arquitetura oferece serviços que deverão funcionar de forma coordenada, atendendo a uma parte bem definida do problema.

Deve-se portanto identificar quais os elementos do problema podem ser organizados de forma a se tornar sub-problemas à parte, que poderiam ser solucionados através de um conjunto restrito de funcionalidades, disponibilizadas ao usuário como serviços.

Os serviços de um servidor normalmente utilizam uma mesma base de dados e podem se comunicar através de mecanismos internos.

A arquitetura do sistema depende de como serão organizadas as interfaces, com que granularidade cada serviço será construído, como os dados serão transferidos entre servidores, como serão tratados os eventos assíncronos (aqueles que, por sua natureza devem ser processados sem interação direta com o cliente) e qual o ambiente será utilizado para a implementação do sistema.

As seções a seguir discutem as opções existentes nesse processo e os fatores a serem considerados nas decisões de projeto.

Para identificar quais serviços deverão ser disponibilizados pela arquitetura, é preciso pensar nas suas interfaces e nas funcionalidades que serão oferecidas.

E importante buscar uma divisão de serviços que garanta o fraco acoplamento entre os diferentes servidores, pois quanto menos um serviço depender de outros, menor o impacto sobre ele quando alguma alteração tiver que ser realizada na arquitetura.

Mesmo no caso de serviços que agregam outros serviços, deve-se tentar reduzir o número de serviços externos com os quais os serviços integrados trabalham.

Além disso, em um ambiente SOA, onde os componente são distribuídos, é importante considerar o tráfego na rede e evitar transferências desnecessárias.

Por outro lado, é preciso ponderar entre granularidade e desempenho, considerando a banda de passagem e a latência da rede.

Isolar a implementação de um serviço da forma como ele é exposto ao consumidor também permite que mudanças na implementação não interfiram no funcionamento do cliente, fator importante quando se tem muitos consumidores para um mesmo serviço, que podem frequentemente ser administrados por pessoas diferentes.

Dessa forma, pode-se criar serviços genéricos o suficiente para atenderem a uma classe de problemas semelhantes que podem ser especificados conforme os parâmetros passados.

Esse pode ser o caso, por exemplo, da execução de um algoritmo de mineração, um unico método, cujo objetivo é executar uma tarefa de mineração, recebe como parâmetros o identificador do algoritmo que será executado e as opções a serem utilizadas, sendo capaz de acionar diversos algoritmos diferentes através de uma unica interface.

Uma outra forma de fazer isso seria a definição de um serviço para cada algoritmo.

Na primeira opção, é necessário informar quais são os algoritmos disponíveis e quais os parâmetros para cada algoritmo.

Já na segunda, como cada algoritmo é descrito por um serviço independente, a própria interface contém essas informações.

Entretanto, qualquer alteração na escolha e interação dos algoritmos e seus parâmetros de entrada do algoritmo torna incompatíveis os clientes já existentes.

E essencial também que a interface seja bem definida e atenda aos objetivos propostos, retornando exatamente aquilo que o consumidor espera ou pode prever.

Para isso, é importante ter bem documentada a responsabilidade de cada serviço, os pré-requisitos e parâmetros necessários para a sua invocação e qual o tipo de dado será retornado.

Em caso de dados muito volumosos, deve-se também definir qual o protocolo será utilizado para a sua transferência.

Outro fator que deverá ser considerado é a granularidade do serviço.

Serviços de grão grosso oferecem uma frações das regras de negócio, ou seja, englobam várias funcionalidades para oferecer ao cliente uma maior abstração do problema.

Eles isolam a lógica de negócio e acessos aos recursos no provedor do serviço.

Serviços de grão fino são mais específicos e praticamente representam métodos de acesso a recursos, deixando a cargo do consumidor a implementação da lógica e o controle da interação entre eles.

No primeiro caso é enviado um unico pedido ao servidor com todas as informações necessárias para a realização total de uma tarefa, enquanto no segundo vários serviços são solicitados para se completar a tarefa.

Serviço disponibilizado com granularidade grossa, que recebe vários dados de uma vez e é responsável pelo acesso aos recursos (como o banco de dados) para a execução completa da operação.

Para exemplificar, imagine um cenário onde é necessário vários parâmetros para a execução de uma certa tarefa.

Pode-se criar um serviço que espera todas as informações necessárias de uma só vez e executa a tarefa granularidade gross.

Por outro lado, pode-se definir um conjunto de serviços com essa mesma finalidade (granularidade fin, um serviço para criar uma tarefa, outro para definir qual algoritmo será utilizado, um terceiro para receber um parâmetro (que pode ser chamado várias vezes) e um quarto para executar a tarefa.

A opção pelo uso de serviços de grão grosso economiza tráfego na rede, pois há menos troca de mensagens entre cliente e provedor, porém não permite muita flexibilidade nem a fácil reutilização dos serviços, já que oferece um pacote fechado de funcionalidades ao usuário.

Deve-se encontrar um equilíbrio para a granularidade dos serviços a fim de evitar o excesso de comunicação sem perder a característica de reuso.

Em SOA, os serviços são executados através da rede, seja uma LAN ou a Internet, e é necessário que não sejam demasiadamente demorados.

Em um protocolo de invocação de métodos remotos, a chamada a um método deve retornar o mais rápido possível, para evitar a falsa impressão de que ele não conseguiu processar a requisição e está travado, causando inclusive o encerramento da conexão pelo protocolo de transporte.

Caso seja necessário, a execução de um processamento demorado pode ser feita com o retorno de uma indicação de que a requisição foi recebida e será processada sem que a resposta seja enviada imediatamente, ou seja, uma execução assíncrona.

O fim da tarefa pode ser verificado com o envio de uma mensagem de término da execução por parte do provedor-o serviço é responsável por avisar que encerrou-ou através de consultas posteriores do cliente para verificar o andamento da execução da tarefa, ate seu término.

Nesse caso, o servidor deve, ao aceitar a requisição, fornecer um identificador de tarefa que será utilizado pelo cliente para consultar o estado corrente da mesma.

No primeiro caso, o cliente não tem que se preocupar em consultar o estado periodicamente, o que gera menos tráfego, porém corre-se o risco de o cliente estar protegido por atrás de uma barreira-como um firewall ou mascaramento de endereço-e não receber a mensagem de aviso, ficando indefinidamente na espera do resultado.

No segundo caso, o cliente consulta o provedor do serviço sobre o estado da tarefa em períodos pré-definidos e obtém o resultado após o seu término.

Isso exige uma gerência de execuções e mais serviços, para a consulta e retirada do resultado, porém permite maior controle por parte do cliente.

Como mencionando anteriormente, o paradigma de SOA prevê a independência de linguagem e plataforma.

Com Web Services isso é feito utilizando protocolos baseados em XML, sem a dependência de uma tecnologia ou framework específicos de um fabricante.

Dessa forma, é possível criar Web Services nas mais diversas plataformas, como JEE, Net, PHP e várias outras.

Cada uma dessas plataformas oferece aos desenvolvedores arcabouços e ferramentas diferentes para a construção de Web Services e outras tecnologias para implementações de serviços (normalmente proprietárias).

Na maioria dos casos, as interfaces dos serviços são mapeados para objetos construídos e diversas facilidades são oferecidas para que o desenvolvedor possa se preocupar apenas com a lógica do serviço.

Em Java/JEE, a maneira mais simples de se criar Web Services é utilizar a biblioteca Axis sobre um servidor de aplicação JEE, como o Jakarta Tomcat.

O Axis é basicamente um Servlet, um módulo executado pelo servidor que responde às requisições por Web Services, processando as mensagens SOAP e repassando as chamadas às classes responsáveis pelos serviços (como especificado no documento WSDL).

Algumas ferramentas acompanham o Axis para facilitar o trabalho do programador, como um gerador de descrições WSDL a partir de uma interface Java e vice-versa.

Com essas ferramentas é possível criar classes clientes que funcionam como encapsulamento para o mecanismo de chamada remota (classe stu e classes que auxiliam o servidor, mascarando a ligação entre a requisição e classe alvo (classes esqueleto).

Há também um mecanismo para a geração de serviços diretamente a partir do código fonte de uma classe Java, em tempo de execução.

Essa opção, entretanto, não é recomendada, pois a geração pode ser lenta e não produzir exatamente o resultado esperado.

O ideal, nesse modelo, é a criação do documento WSDL e, a partir dele, a geração das classes cliente e servidor.

Para grandes aplicações corporativas, os melhores servidores JEE oferecem ainda mais facilidades para a criação de Web Services.

E possível criar componentes EJB (Enterprise JavaBeans) que são acessados através de SOAP, apenas com algumas configurações adicionais ou anotações no código fonte, indicando quais métodos serão exportados.

Muitas aplicações trabalham com grandes volumes de dados, como no caso da maior parte das tarefas de mineração.

Em um sistema monolítico, todos os componentes podem fazer acesso a um mesmo arquivo que, por exemplo, pode ser gerado por uma tarefa e servir como entrada para outra, diferente.

Por outro lado, em um ambiente SOA, composto de serviços distribuídos entre máquinas e redes diferentes, é improvável que todos eles tenham acesso um mesmo arquivo.

Os dados, gerados ou armazenados em algum componente, podem ter que ser movidos para outra máquina para serem processados.

E fundamental, portanto, encontrar meios eficientes para transferir esses dados.

Há vários protocolos de transferência de arquivos em uso na Internet, porém, em um ambiente baseado em Web Services, é essencial que essa transferência seja feita através dos servidores WWW, seguindo padrões bem definidos, de forma segura e eficiente, a fim de que não se perca a característica fundamental de SOA, a possibilidade de uso entre organizações distintas, incluindo a garantia de passagem do tráfego através de firewalls.

As bases de dados para mineração, por exemplo, são conjuntos de dados separados em n registros, cada qual composto de m campos, representando uma tabela com n m valores, extremamente densa, possivelmente, todos os campos contêm dados.

A transferência dessa base completa entre os componentes do sistema é necessária quando se quer minerar dados localizados remotamente.

A mesma coisa acontece quando os resultados gerados a partir de uma mineração precisam ser armazenados remotamente.

Nesses casos, questões como a forma de se incluir os dados no protocolo de comunicação, o formato de representação dos dados durante a transferência e as garantias de confiabilidade da comunicação precisam ser tratadas.

Como discutido anteriormente, a comunicação entre componentes em um ambiente SOA é usualmente realizada através do protocolo SOAP, baseado na linguagem XML, uma representação textual.

Esse protocolo não foi desenvolvido originalmente para transferências maciças de dados.

Torna-se então necessário definir uma forma de encapsular arquivos de dados no fluxo de comunicação entre os componentes.

Simplesmente inserir os dados no fluxo SOAP se torna um problema para garantir o processamento da comunicação.

Se os dados forem codificados em XML, teremos um documento XML dentro de outro, com um esquema de codificação diferente, o que exige alterações no arquivo encapsulado e coloca uma demanda a mais sobre o processador XML usado pelo receptor, usualmente otimizados para campos de pequenas dimensões.

Se os dados estiverem em binário é preciso recorrer a algum formato de codificação, pois a inserção de arquivos binários em um fluxo de caracteres também apresenta problemas de processamento para o receptor.

Se a inserção do arquivo diretamente no fluxo SOAP é um problema, uma opção, já que se trata de um ambiente baseado em Web Services, é através de um subconjunto do protocolo HTTP, já utilizado.

Ao invés de codificar os dados de um arquivo no fluxo SOAP, nesse caso a comunicação é feita passando-se uma URL que identifica o arquivo com os dados que se deseja transferir.

O componente que recebe a URL utiliza uma requisição HTTP tradicional para transferir o arquivo, usando os recursos usuais de HTTP para codificar os dados, se necessário.

Essa técnica possibilita que um arquivo muito grande seja retirado em partes, melhorando a velocidade de transmissão e possibilitando a recuperação de dados já transmitidos caso haja falhas na comunicação, além de permitir que o arquivo seja armazenado em caches, evitando retransmissões desnecessárias.

Quando o endereço informado aponta para o mesmo servidor-o que é o caso mais comum-, pode-se utilizar ainda a vantagem da reutilização da conexão HTTP aberta na requisição SOAP, melhorando o desempenho.

Porém, é preciso garantir que o recurso estará realmente disponível no endereço indicado, pelo menos até um limite de tempo pré-definido.

Isso pode tornar necessário técnicas complexas para a gerência desses arquivos.

Outra solução existente é a de inserção de anexos em partes bem distintas da requisição no fluxo SOAP.

Essa solução, denominada SOAP with Attachments Sw apresenta-se como uma solução viável para o envio de arquivos através de Web Services.

SwA é uma extensão do protocolo SOAP que utiliza o recurso de divisão de requisições em múltiplas partes, através de padrões como MIME (Multipurpose Internet Message Encapsulation) ou DIME Direct Internet Message Encapsulation, discutida brevemente no capítulo, em conjunto com um protocolo de transporte, como o HTTP.

O envelope SOAP é gerado com o valor do dado anexado sendo representado como uma referência à parte MIME que contém o anexo, de forma similar aos arquivos anexos em e-mails.

O arquivo com os dados a serem anexados é enviado, então, como uma outra parte MIME, no formato original ou codificado, permitindo que qualquer arquivo seja transmitido junto à mensagem sem problemas.

Porém, não é simples guardar esse arquivo em cache, como no caso anterior, já que as respostas SOAP, que são geradas dinamicamente, também fazem parte da resposta HTTP, podendo ser diferentes em momentos diferentes.

Quando as respostas são dinâmicas, não são armazenadas e reutilizadas pelo proxy.

A forma de representação das bases e demais conjuntos de dados para a transferência entre os componentes do sistema influencia diretamente o tempo de transferência e a forma como os dados são interpretados entre transmissor e receptor.

Formatos binários, apesar de serem frequentemente compactos, trazem problemas na sua inserção em fluxos SOAP e HTTP, como mencionado anteriormente.

Uma solução simples é a adotada em codificações com MIME sobre HTTP, por exemplo, que faz a conversão do arquivo enviado em um formato textual, como base64.

A formato de codificação base6converte um conjunto de bytes de qualquer tamanho em uma cadeia de caracteres.

Basicamente, conjuntos de três octetos (2bits) são transformados em quatro caracteres, cada um com apenas seis bits utilizados para representar a informação.

Os dois bits restantes em cada caracter são normalmente zerados para garantir que os caracteres se refiram a letras, números e pontuação usuais.

Com isso, dados codificados com base6ocupam aproximadamente 33% mais espaço que os dados originais.

Ao enviar um arquivo dessa forma, não só é necessário um acréscimo de tamanho, como também um maior processamento e consumo de memória.

O envio de dados binários apresenta outros problemas, mesmo com uma codificação como base64.

O principal deles é certamente o de interpretação dos dados quando as arquiteturas de origem e destino diferem em suas representações internas.

Para resolver esse problema, considerando-se que HTTP e SOAP já são protocolos textuais, a solução é adotar formatos de codificação que transformam os dados em seq¨uências de caracteres.

Há dois formatos textuais de representação de dados bastante conhecidos, que foram avaliados para a transferência de dados entre os componentes do Tamanduá.

O primeiro é o formato simples conhecido usualmente como CSV (Comma Separated Values), onde os registros são separados por caracteres delimitadores de linha e os campos de cada registro são separados por um caractere pré-selecionado-normalmente a vírgula.

Esse formato é simples e permite a representação correta dos dados, desde que se garanta que o caractere pré-selecionado para separação de campos não exista na representação dos valores.

O segundo formato é baseado em XML, linguagem de formatação adotada largamente para troca de dados entre aplicações, inclusive nos padrões de Web Services.

Como mencionado anteriormente, a linguagem XML é baseada em marcações de texto (ou tags), usadas para identificar e estruturar os dados (meta-informações sobre o conteúdo).

Organizar os dados em uma estrutura bem definida pode ser vantajoso para garantir a correta utilização do arquivo, porém pode trazer grande acréscimo ao seu tamanho e torna necessário um mecanismo complexo de verificação dessa estrutura.

Em um ambiente distribuído a segurança dos dados trafegados pela rede é um fator importante.

No caso da mineração de dados, por exemplo, uma base pode conter informações importantes e sigilosas que não devam ser expostas a intrusos.

Para uma conexão segura, a criptografia dos dados trafegados é essencial.

Isso pode ser feito para conexões TCP/IP utilizando-se os recursos de codificação inicialmente desenvolvidas pela Netscape, conhecidos como SSL (Secure Socket Layer).

Os padrões atuais são denominados TLS (Transport Layer Security) e mantidos por organizações independentes na Internet, como o IETF (The Internet Engineering Task Force).

HTTP.

Apostolopoulos li identificaram a sobrecarga adicionada por cada componente utilizando benchmarks conhecidos e propuseram duas técnicas para melhorar o desempenho do protocolo.

Xubin He mostrou que o HTTPS gasta muito mais recursos no cliente que no servidor.

Isso faz com que seja necessário um número maior de clientes para sobrecarregar o servidor.

Com isso, esses trabalhos mostram que o TLS adiciona uma carga ao protocolo HTTP, porém seu uso é viável desde que utilizado com moderação, ou seja, apenas onde realmente seja essencial.

Khare e Lawrence propuseram inclusive uma solução para intercalar requisições seguras e não seguras numa mesma conexão HTTP, evitando a abertura e fechamento de conexões TCP desnecessárias.

O processo de descoberta de conhecimento em bases de dados KD, como já visto, é um processo interativo e incremental, que pode exigir processamento pesado por longos períodos de tempo.

Um sistema robusto para mineração de dados, capaz de atender à demanda de vários usuários simultaneamente, deve possibilitar a utilização de diversas bases de dados e diferentes algoritmos e apresentar os resultados obtidos de maneiras distintas, com o objetivo de proporcionar um bom entendimento pelo usuário.

O sistema será ainda melhor se for capaz de localizar esses recursos num ambiente heterogêneo como a Internet, a fim de proporcionar ao usuário uma melhor experiência durante o processo.

O Tamanduá é uma plataforma interativa, multi-usuária, escalável e incremental para a mineração de dados.

Sendo assim, ele permite a utilização simultânea por vários usuários, cada um tratando dos passos necessários para o processo incremental de descoberta de conhecimentos a partir de bases de dados.

O acesso a bases, o processamento da mineração e a visualização dos dados são concebidos na forma de serviços disponibilizados aos clientes, que podem empregá-los dinamicamente no processo de KDD.

A plataforma do Tamanduá foi projetada com componentes distribuídos que provêem serviços com interfaces bem definidas, podendo ser utilizados da forma que melhor atender às necessidades da aplicação.

Para identificar quais seriam os serviços oferecidos e como eles seriam agrupados em servidores distintos, foram identificados três pontos importantes do problema de KDD que deveriam ser tratados pela arquitetura, a disponibilização das bases de dados, a execução da mineração propriamente dita e a visualização dos resultados.

Cada um desses pontos constitui um sub-problema à Arquitetura do Tamanduá Dessa forma, o sistema foi construído com três componentes principais, o servidor de dados, DataServer, responsável pela disponibilização das bases.

O servidor de mineração, MiningServer, onde são processadas as tarefas de mineração e o servidor de visualização, VisServer, para a transformação de dados e modelos em metáforas visuais.

Para completar a arquitetura, temos uma aplicação para controlar a interação com o usuário e a gerência do processo, que pode ser implementada em qualquer linguagem, desde que conheça as interfaces dos serviços e consiga se comunicar através de HTTP e SOAP.

Os componentes são discutidos a seguir.

DataServer, responsável pela disponibilização das bases de dados e seus metadados.

Bases são conjuntos de tabelas interrelacionadas, cada qual com seu conjunto de colunas.

A base é disponibilizada no formato CSV, para economia de espaço.

São disponibilizados serviços para obtenção das bases existentes no servidor e seus meta-dados-como nome, tipo e descrição de cada coluna-, transferência de bases e consultas no estilo SQL.

MiningServer, componente para a mineração de dados propriamente dita, responsável pela execução das tarefas.

Uma tarefa de mineração é composta das seguintes informações, identificação da base e colunas que interessam ao usuário, o algoritmo a ser utilizado na mineração e os parâmetros necessários ao algoritmo.

As tarefas são executas de forma assíncrona, ou seja, o cliente não espera pelo processamento.

Ao invés disso, recebe um identificador, com o qual pode consultar posteriormente o estado da tarefa.

Como resultado de uma tarefa de mineração é gerado um modelo, também disponibilizado em formato textual.

O MiningServer foi projetado para servir apenas como uma camada de serviços acima da aplicação real de mineração de dados.

Ou seja, sua principal função é a de prover acesso via Web Services a essa aplicação, que no caso do Tamanduá é implementada em um ambiente de processamento distribuído para garantir um bom desempenho originalmente sem uma interface SOAP.

VisServer, transforma dados em metáforas visuais apresentadas aos usuários.

Tem como entrada modelos gerados numa tarefa de mineração e é responsável por gerar uma visualização, que pode assumir diversos formatos, específicos para cada tipo de algoritmo utilizado.

Aplicação, software capaz de comunicar e gerenciar os componentes anteriores, fazendo a interface entre o usuário final e os serviços.

Atualmente, existe uma versão da interface com o usuário no Tamanduá, implementada para o acesso pela WWW.

Qualquer aplicação pode ser integrada à plataforma e comandar o processo de KDD da forma mais conveniente à organização, seja pela WWW ou outro tipo de interface.

Na ão mostrados os serviços implementados em cada componente.

Esses componentes comunicam-se com a aplicação e entre si com uso de SOAP e do protocolo HTTP.

Dessa forma, qualquer aplicação cliente pode ser utilizada sobre eles para gerenciar a interação do usuário com o processo de KDD, desde que conheça os padrões de Web Services adotados.

Uma exceção é a adição de novas bases no servidor de dados, que é feita por uma fonte externa, ainda sem um mecanismo bem definido.

O uso de Web Services possibilita também que a implantação de um serviço não torne obrigatória a implantação dos demais.

Cada um dos serviços pode ser disponibilizado à parte pelas organizações que possuírem recursos interessantes aos demais clientes e serviços da plataforma.

Por exemplo, uma base pode ser adicionada ao ambiente pelo seu detentor apenas acrescentando um servidor que ofereça uma interface para ela.

A partir de então, o usuário que desejar utilizar a base, solicita à aplicação que acesse aquele servidor para buscar informações e utiliza o servidor de mineração disponível para processá-la-como veremos, quando uma tarefa de mineração é criada, informa-se ao MiningServer a URL que será utilizada para acesso ao servidor de dados.

O mesmo vale para algoritmos de mineração e sistemas de visualização.

Há três casos de uso do Tamanduá que mostram bem a interação entre os componentes da plataforma, prospecção de bases, criação e execução de tarefas e a visualização de resultados.

Entender esses casos de uso, descritos a seguir, é importante para a compreensão da interação entre a aplicação e cada servidor da plataforma.

Prospecção de Bases, o usuário, ao entrar no sistema pela primeira vez, pode querer conhecer quais as bases estão disponíveis, de que tipo são e quais os atributos possui.

Para isso, a Aplicação, sob ordem do usuário, solicita ao DataServer sua lista de bases, com nome e descrição.

O usuário tem, então, a opção de solicitar o detalhamento de uma base, onde serão recuperadas as informações sobre as colunas, com descrição e tipo.

Serviços SOAP oferecidos na arquitetura Tamanduá Diagrama de Seq¨uência para a prospecção de bases Para criar uma tarefa de mineração de dados, o usuário precisa definir qual a base será processada e qual o algoritmo será utilizado para obter a informação que ele deseja.

Como vimos, há vários tipos de algoritmos para mineração de dados e cada um trata os dados de forma diferente, de acordo com parâmetros que são informados.

Além disso, nem todos os algoritmos são capazes de trabalhar com todos os tipos de valores, e o número de colunas investigadas, assim como os parâmetros informados, influenciam no tempo de processamento e no resultado encontrado.

O usuário deve, então, escolher apenas as colunas que lhe interessam para serem analisadas e informar os parâmetros necessários de acordo com a sua intenção.

Quando o usuário manda executar a tarefa, esta é submetida ao MiningServer responsável pelo algoritmo escolhido com todas as informações definidas.

O MS coloca a tarefa em uma fila de espera e retorna à Aplicação o seu identificador, usado para referências futuras.

O diagrama de sequência associado é apresentado.

Execução, O processo de execução de tarefas na fila do MiningServer é assíncrono, ou seja, funciona sem a intervenção da Aplicação nem do usuário.

A fila de tarefas é atendida pelo MS em ordem de chegada, e mais de uma tarefa pode ser executada paralelamente, caso haja mais de uma fila implantada.

Caso ainda não tenha disponível localmente a base que será processada, o MS requisita ao DataServer responsável a URL onde esta pode ser obtida.

A transferência para o repositório local é feita por uma requisição HTTP normal para recuperação de recursos.

Com a base local, o algoritmo de mineração de dados é executada sobre esses dados segundo os parâmetros fornecidos na definição da tarefa.

Diagrama de seq¨uência para a criação de tarefa Periodicamente, a Aplicação deve consultar o estado da tarefa com o identificador recebido na solicitação de execução.

O servidor de mineração retorna informando se a tarefa está executando ou se ocorreu algum erro no processo.

Quando a execução da tarefa finaliza, o MiningServer recupera do algoritmo o resultado e altera o estado da tarefa para "encerrada".

Ao perceber que a tarefa foi executada com sucesso, a Aplicação pode solicitar ao VisServer a preparação da visualização do resultado.

Para isso, o VS requisita ao MS a transferência do arquivo com o resultado da tarefa, processa esses dados de forma a tornar a visualização mais eficiente e armazena em uma base local.

A partir desse momento, o VS estará pronto para gerar a visualização para o usuário.

Visualização dos Resultados, após a execução de uma tarefa, o usuário normalmente precisa entender os resultados encontrados.

Ao ser informado que a tarefa está pronta para ser visualizada, o usuário pode pedir para ver o resultado, fazendo com que a Aplicação recupere do VisServer os meta-dados referentes ao resultado.

No caso de regras de associação, os meta-dados contém uma lista de atributos que são causa ou conseq¨uência de uma regra.

Diagrama de seq¨uência para a execução da tarefa.

Para facilitar o entendimento do resultado, o servidor de visualização gera uma imagem contendo os pontos que representam as regras encontradas na mineração.

Essa imagem, como discutido mais à frente, é transferida como resposta à requisição do serviço.

Com isso, a Aplicação apresenta ao usuário uma tela onde ele pode selecionar um ponto que lhe pareça interessante e aplicar um filtro de regras e outras configurações.

Selecionado o ponto, a Aplicação exibe um resumo das regras naquela coordenada (normalmente confiança e suporte) e seus detalhes, obtidos do VS.

Opcionalmente, o usuário pode também visualizar as tuplas que geraram uma determinada regra, a fim de entender melhor os resultados.

O diagrama de sequência é apresentado.

Diagrama de seq¨uência para a visualização de tarefa.

O Tamanduá foi implementado com um subconjunto da plataforma JEE, utilizando o servidor de aplicação Jakarta Tomcat versão 5.

A biblioteca Axis 1para Java foi utilizada como ferramenta para a implementação de Web Services no estilo RPC, para comunicação entre a aplicação e os componentes.

Os serviços são mapeados em métodos de classes Java comuns, que chamaremos de classes alvo.

As classes alvo são quem realmente implementa as operações dos serviços.

O Axis implementa um Servlet que é responsável pelo tratamento das requisições enviadas a uma URL (Universal Resource Locators) no servidor HTTP.

Quando recebe um envelope SOAP, esse Servlet identifica, a partir de configurações locais, a classe que deve tratar aquela mensagem.

Essa classe auxiliar (comumente chamada de classe esqueleto) é responsável por extrair da mensagem as informações necessárias para a execução do método na classe alvo, acessá-la, e criar a mensagem de retorno à partir do resultado da execução.

Para acesso aos serviços remotos, o AxisClient (componente da biblioteca Axis) é utilizado por uma classe auxiliar chamada de classe stu para montar o envelope e enviá-lo ao destino, assim como processar a resposta e retornar o resultado.

O uso da classe stub, que possui a mesma interface da classe alvo, possibilita que se acesse o serviço remoto de forma transparente, como se este fosse uma classe local.

O DataServer, MiningServer e VisServer são implementados como aplicações separadas-uma só acessa a outra através de Web Services-que não possuem interface direta com o usuário, apenas através de SOAP.

A Aplicação do Tamanduá utiliza uma separação MVC (Modelo-Visão-Controle), com uma interface Web implementado com JSPs (Java Server Pages).

Classes Java de modelo são responsáveis por acessar os serviços remotos e gerenciar os recursos disponíveis, fazendo a intermediação entre os usuários e os serviços.

Como já foi mencionado, o MiningServer é responsável apenas pelo gerenciamento da tarefa dentro do processo de KDD, servindo como uma camada de serviço para uma aplicação de mineração de dados.

Portanto, o processamento dos algoritmos é realizado por um aplicativo à parte, que poderia ser qualquer uma já existente, normalmente utilizando processamento distribuído para melhorar o desempenho.

Nesse caso, os algoritmos de mineração foram implementados na plataforma VOID, um ambiente paralelo e distribuído de execução de aplicações em cluster.

A comunicação entre o MiningServer e o VOID é feito através da execução do programa na máquina local, com a passagem de parâmetros por linha de comando.

Isso foi feito porque não há outros protocolos de comunicação implementados nos programas do VOID para esse fim, já que foge do escopo da aplicação, minerar, utilizando um cluster de máquinas, dados disponibilizados em um arquivo.

Além disso, a implementação de Web Services diretamente nesse programa poderia impor uma perda de desempenho ao sistema.

Portanto, o MiningServer gera, a partir dos dados recebidos do DataServer, um arquivo em um diretório temporário da máquina local.

O caminho para esse arquivo é informado como parâmetro para o programa que dispara o processamento no VOID, juntamente com os demais parâmetros gerados a partir dos dados recebidos na criação da tarefa.

O método de execução de tarefas (executeTask), portanto, é um método stub que faz a interface entre a plataforma baseada em Web Services com a execução por linha de comando do aplicativo.

Para controlar a execução da aplicação é criada uma nova thread, que aguarda até que o programa seja encerrado e avisa ao sistema sobre o seu estado, indicando caso tenha ocorrido erros na execução.

A ocorrência de erros é detectada através do código de retorno do programa, que retorna 0 (zero) em caso de sucesso ou um número diferente caso contrário.

Se a execução ocorrer conforme o esperado, um novo arquivo é gerado pelo VOID na máquina local, como resultado do processamento.

Esse arquivo é então disponibilizado pelo MiningServer ao VisServer para que seja gerada a visualização.

A transferência de arquivos de dados e modelos pelo ambiente foi implementada utilizando o método de envio de URL.

Ou seja, é requisitado ao componente que retorne o endereço onde o recurso está disponível, e este é recuperado através de uma chamada HTTP comum.

Isso porque o mesmo arquivo é utilizado várias vezes, e pode ficar em cache por muito tempo, não sendo regerado a cada requisição.

As imagens produzidas na visualização são transferidas como resposta ao chamado de método no SOAP, já que cada visualização retorna uma imagem diferente e possivelmente unica, não sendo reaproveitada para outras requisições-isso tornaria complicada a gerência do armazenamento das imagens.

Os arquivos que representam as bases de dados são gerados no formato CSV, pelos motivos discutidos na seção 413e que serão experimentados na seção 521.

Os resultados da mineração, de forma semelhante, são transferidos para o serviço de visualização em formato textual.

Neste capitulo apresentamos alguns experimentos realizados com a plataforma Tamanduá.

Primeiro temos uma avaliação qualitativa, cujo objetivo é avaliar a experiência obtida com o desenvolvimento de uma aplicação real baseada em SOA, mostrando uma avaliação pessoal com relação à metodologia utilizada nessa construção.

Na segunda parte, será avaliada uma questão importante para sistemas desse tipo, porém não discutida em outros trabalhos, mostrando o impacto do formato utilizado no conjunto de dados que serão transferidos pela rede.

Na ultima parte, será mostrado um teste de carga realizado no sistema para avaliar a sua escalabilidade e tentar quantificar o uso da plataforma.

O uso de uma arquitetura orientada a serviços SO se mostrou uma boa solução para a criação de uma plataforma de mineração de dados, o Tamanduá.

Apesar dessa avaliação ser subjetiva, consideramos que esse modelo é melhor que o modelo tradicional, onde todos os componentes do sistemas estão embutidos em um unico programa.

O uso de computação orientada a serviços força o desenvolvedor a pensar de forma diferente, já que não há um lugar unico para acesso às informações e aos dados do programa.

Isso em um primeiro momento torna mais complexa a implementação, pois é importante a preocupação com a redução da transferência de dados entre os componentes para economizar tráfego na rede e com o controle de estado dos serviços e das versões dos dados.

Essas decisões de projeto influenciam em muito a construção da arquitetura do sistema, que deve ser constituído de componentes independentes, na medida do possível, dos demais.

Essa flexibilidade, entretanto, torna o processo de expansão do sistema mais simples posteriormente.

O uso de Web Services para a implantação de SOA proporciona flexibilidade para a distribuição dos serviços do sistema, tornando mais fácil a implantação deles em redes distintas, ao contrário de outras tecnologias semelhantes.

As abstrações disponibilizadas pelo SOAP para a criação das interfaces de comunicação foram suficientes para a construção dos serviços, mesmo os mais complexos, atendendo aos requisitos impostos pelo problema.

A arquitetura do Tamanduá ainda não é a ideal, porém o problema proposto-descoberta de conhecimento em bases de dados-se adeq¨ua ao paradigma de serviços e o resultado esperado foi atingido, uma plataforma funcional de mineração de dados baseada em serviços.

Com essa experiência, pudemos demonstrar o grande potencial do uso de SOA e Web Services.

Por exemplo, a plataforma poderia ser expandida facilmente, com a definição de novos serviços, para atingir também a etapa de pré-processamento, anterior à disponibilização de dados, o que não foi feito ainda.

O impacto para a disponibilização dessa nova funcionalidade na plataforma seria muito maior se não fosse utilizada SOA.

Diversas melhorias têm sido propostas e serão implantadas futuramente.

A utilização do sistema em um ambiente real com seus serviços geograficamente distribuídos não pôde ser avaliada, devido à não implantação da plataforma nessa escala.

Como o Tamanduá é um sistema novo e em implantação, todos os clientes da plataforma atualmente em operação utilizam versões locais, em uma máquina ou em um cluster de máquinas, de todos os serviços.

Porém, percebemos que não há limitações conhecidas à sua implantação com os serviços distribuídos em diferentes redes pela Internet, desde que todas autorizem o acesso ao porto HTTP da máquina onde estão instalados.

Como vimos, a transferência de dados em um sistema distribuído é muito importante e tem grande impacto no funcionamento do sistema.

Para trafegar dados pequenos, como parâmetros para um serviço, o uso do protocolo de comunicação usado na invocação dos serviços (como o SOAP) é suficiente, porém quando os dados são muito grandes nem sempre isso é verdade.

Num ambiente Web há alguns mecanismos para a troca de arquivos de dados, que vimos anteriormente, como o padrão SOAP with Attachments e a recuperação de um arquivo acessível por uma URL comum.

Em termos de processamento, ambos são semelhantes, pois simplesmente enviam um fluxo de dados pela rede.

Por exemplo, pode-se ler um arquivo e enviá-lo diretamente a quem estiver solicitando, sem nenhum outro processamento.

O primeiro método adiciona um processamento à requisição pois acrescenta antes do arquivo a mensagem de resposta SOAP, não existente no segundo caso.

Porém, este necessita também de uma requisição SOAP para identificar a URL onde poderá ser recuperado o arquivo.

Nesse caso há a necessidade de duas requisições ao servidor para realizar a mesma transferência do caso anterior, porém, como mencionado, há a vantagem de se permitir que o arquivo seja armazenado em mecanismos de cache existentes na rede.

Isso pode ser util nos casos em que o arquivo não muda constantemente.

Outra grande preocupação é com o formato usado para transferir os dados.

A seção a seguir discute a influência que o formato usado no arquivo tem sobre o desempenho do sistema.

Para verificar a questão dos formatos usados na transferência de dados, selecionamos duas bases reais volumosas, sendo a primeira formada por muitos registros com poucas colunas e a segunda com poucos registros, porém muitas colunas.

Foram verificados inicialmente os tamanhos das bases no formato CSV, aparentemente menor.

Posteriormente, foram construídos, a partir desses arquivos, arquivos XML-nomeados XML1, XML2, XMLe XML, todos com elementos de identificação de registros com nome reg e identificação dos campos como abaixo, XML1, Nomes comprimidos (1,2,), sem endentação.

XML2, Nomes comprimidos (1,2,), com endentação.

XML3, Nomes originais das colunas, sem endentação.

XML4, Nomes originais das colunas, com endentação.

Os arquivos sem endentação foram criados sem quebra de linha nem espaços entre tags.

Os arquivos com endentação foram criados com quebra de linha após as tags (abertura e fechamento) de registro, um caractere de tabulação antes do elemento de campo e um fim de linha após, com o objetivo de torná-los mais legíveis.

Ambos os formatos constituem arquivos XML válidos segundo os padrões recomendados.

Comparação (tamanhos em bytes) do arquivo CSV com os arquivos XML gerados e o acréscimo percentual que esses ultimos têm em relação ao primeiro.

Na coluna "Compactado" está o tamanho dos arquivos compactados com o algoritmo gzip, utilizado opcionalmente pelo protocolo HTTP para transferência de arquivos, suas porcentagens em relação ao tamanho original e o acréscimo dos arquivos compactados em relação ao primeiro.

Tamanho dos arquivos para a Base 1 (14506 registros com 16 colunas).

Tamanho dos arquivos para a Base (3916 registros com 385 colunas).

Como podemos observar, o número de colunas influencia muito no crescimento do arquivo XML, visto que cada coluna adiciona no mínimo duas vezes seu nome (tag de inicio e fim) mais cinco caracteres (delimitadores).

Para cada registro são adicionadas também as tags de inicio e fim <reg> e </reg> (11 caracteres).

Portanto, o acréscimo no arquivo de dados necessário para a formatação XML, que tornaria o arquivo melhor estruturado, é considerável, mesmo compactado, principalmente quando se considera a transferência entre máquinas distantes na Internet.

Para decidir entre o uso ou não do XML nesses casos, deve-se levar em consideração a real necessidade da estruturação dos dados, o acesso ao serviço de agentes externos ao sistema exige uma boa estrutura dos dados para o entendimento do arquivo ou uma documentação bem elaborada do formato usado resolve o problema.

Caso essa estruturação seja necessária, o uso de XML é indispensável na representação dos dados.

Se apenas a documentação do sistema for suficiente para evitar erros no acesso aos dados como um sistema que só será disponibilizado para uso restrito a um pequeno grupo de clientes, um arquivo CSV pode ser utilizado na transferência sem maiores impactos.

Criar serviços que atendem aos objetivos funcionais do sistema não é suficiente para o sucesso da arquitetura.

E muito importante prover os serviços com a qualidade desejada pelo usuário, garantindo um tempo de resposta aceitável para o usuário e a escalabilidade do sistema.

Como discutido anteriormente, o usuário espera que o sistema seja rápido e esteja disponível o tempo todo, sem erros.

Para verificar se é possível garantir isso aos clientes, precisamos medir qual a carga máxima que a arquitetura suporta em determinada montagem inicial.

A carga de um sistema pode ser definida como o conjunto de todas as entradas recebidas do ambiente durante um período de tempo especificado.

No caso dos sistemas WWW, a carga é constituída pelas requisições enviadas ao serviço pelos clientes.

Chamamos de montagem do sistema a disposição dos serviços da arquitetura no ambiente distribuído (seja na Internet ou rede local), ou seja, onde estão localizados os serviços que serão utilizados.

Como aplicações baseadas em SOA permitem a localização dinâmica de serviços, é necessário mostrar que opções alternativas para a montagem do sistema podem ser usadas para manter o tempo de resposta aceitável com o crescimento do número de sessões de usuários simultâneas.

Isso demonstra que a arquitetura em questão é escalável.

O objetivo dessa seção é mostrar o estudo feito sobre o desempenho do Tamanduá, com o objetivo de provar que é um sistema escalável.

Para avaliar a escalabilidade do Tamanduá foram realizados vários experimentos com a geração de cargas crescentes no sistema.

A carga foi adaptada a partir de dados coletados de sessões reais de usuários do sistema.

Esses dados foram obtidos a partir de um trabalho de caracterização do Tamanduá que está sendo realizado no Departamento de Ciência da Computação da Universidade Federal de Minas Gerais.

Essa caracterização tem como objetivo, entre outros, a criação de grafos de modelos de comportamento dos usuários (CBMG, Customer Behavior Model Graphs) a partir de registros de ações armazenados para a auditoria do sistema.

Com essa técnica, conseguiu-se caracterizar três modelos de comportamentos de usuários do Tamanduá, o primeiro modelo, que representa 10% dos casos, de usuários que permanecem a maior parte do tempo criando e executando tarefas.

O segundo, 25% dos casos, de usuários que criam, executam e visualizam o resultado e o ultimo, 65%, de usuários que visualizam detalhadamente os resultados das tarefas.

O ambiente utilizado para a realização dos experimentos é um cluster formado de máquinas com processador Pentium 30 GHz, 1 GB de memória RAM, 1 disco rígido com capacidade de 120 GB, taxa de transferência de 15 Gb/s e tempo médio de busca de 8 ms.

Todas utilizam o sistema operacional Linux, com kernel 267, com as mesmas configurações, e estão interligadas por um switch de 2portas com capacidade de 100 Mb/s, formando uma rede isolada.

A proposta dos testes é avaliar o desempenho e a escalabilidade da arquitetura orientada a serviços do Tamanduá sem considerar o tráfego da rede nem o processamento da mineração.

Nesse ambiente, o algoritmo de mineração no VOID foi substituído por um programa simples que simula a execução, consumindo um tempo aleatório para completar a tarefa, porém sem impor maior uso da CPU e memória ao sistema, uma vez que no ambiente real esse processamento é realizado em um sistema independente.

A carga é gerada com o envio de várias requisições à aplicação WWW, como seria CBMG para usuários que, na maior parte do tempo, criam e editam tarefas.

CBMG para usuários que criam e visualizam tarefas.

Esse programa, desenvolvido em Java, permite a alocação de clientes em diversas máquinas, cada qual representando um determinado número de usuários simultâneos.

Cada usuário segue um plano de testes pré-determinado, adaptado dos CBMGs apresentados, para tentar simular o comportamento de clientes reais.

CBMG para usuários que só visualizam as tarefas.

Os testes são executados por uma hora, com tolerância de 5 minutos para o início de todas as sessões de usuário.

Para cada experimento foram medidos os seguintes dados, requisições feitas, com indicação de sucesso e tempo de resposta percebido pelo usuário registrado no instante do recebimento da resposta completa informado pelo JMeter.

Uso da CPU e memória das máquinas servidoras, coletado com o programa vmstat do Linux, somando os campos de tempo utilizado pelo usuário (us), tempo utilizado pelo sistema (si) e tempo esperando por E/S w.

Uso da CPU por processo de interesse (nesse caso, os servidores de aplicação e os de banco de dados), utilizando o comando ps, que faz a medida de uso da CPU dos processos dividindo o tempo em que ele está ativo pelo tempo em que teve a posse do processador-esse mecanismo não é muito preciso e pode apontar valores abaixo do real e tráfego da rede, utilizando o aplicativo tcpdump.

Foram definidos como padrão de qualidade as métricas, tempo de resposta menor que segundos e quantidade de erros percebidos até 10%.

O primeiro conjunto de testes foi feito com todos os serviços e a aplicação WWW em uma mesma máquina.

Todos acessavam os respectivos dados em um único sistema gerenciador de banco de dados SGB.

O objetivo foi iniciar a pesquisa com a montagem mais simples possível, para avaliar o limite de usuários simultâneos suportado pelo sistema.

Em cada teste foram aplicadas ao sistema cargas de 10 a 1000 usuários simultâneos, buscando identificar o ponto de saturação do sistema.

Um segundo conjunto de testes, mais direcionado, foi então realizado implantando cada serviço separado em uma máquina dedicada, utilizando um SGBD local.

Com isso, conseguimos perceber uma melhora significativa no desempenho do sistema, demonstrando que a arquitetura é escalável.

Apresentaremos a seguir os resultados mais interessantes encontrados.

Montagem 1 do Tamanduá, todos os serviços numa mesma máquina.

A primeira bateria de testes, realizada com todos os serviços em uma mesma máquina, foi feita com testes de 100 a 1000 usuários simultâneos.

Número de requisições totais e o número de requisições com erros verificados nos experimentos mais significativos.

São consideradas requisições com erros aqueles que não foram respondidas pelo servidor ou cuja resposta não corresponde ao esperado.

Podemos verificar que a partir de 400 usuários simultâneos começamos a ter muitos erros (acima de 10%), com 500 menos de 70% das requisições têm tempo de resposta menor que segundos e a partir de 600 usuários temos uma queda no número total de requisições, que vinha crescendo constantemente.

O aumento dos erros e do tempo de resposta são um demonstrativo de que o sistema já não está conseguindo processar corretamente as requisições3.

A queda no número de requisições indica que o sistema está saturado, provavelmente devido ao tempo de resposta muito alto.

Montagem do Tamanduá, cada serviço numa máquina dedicada.

Comparativo de requisições feitas ao sistema.

Posteriormente verificou-se que o servidor Jakarta Tomcat gerava um certo número de páginas de erro quando sua carga ultrapassava um certo valor, o que não pode ser isolado nos dados coletados resposta no experimento de 600 usuários simultâneos.

O primeiro mostra a média de requisições que receberam um resposta completa (ou tiveram erros) em determinado momento.

O segundo apresenta o tempo de resposta médio percebido pelo usuário, desde o momento de envio da requisição até o recebimento completo da resposta.

Há uma clara relação entre esses gráficos, com picos de tempo de resposta elevado no mesmo instante em que há quedas bruscas no número de requisições.

Isso se repete nos demais experimentos, demonstrando que realmente a queda no número de requisições se deve ao longo tempo que os clientes precisam esperar para fazer uma nova requisição.

Observe, por exemplo, que quando os tempos de resposta ultrapassam 60 segundos, não é registrado nenhuma requisição com sucesso na média do instante seguinte.

Gráfico de requisições médias por minuto para 600 usuários.

Variação do tempo de resposta médio para 600 usuários.

É necessário entender agora os fatores que tornam o tempo de resposta tão elevado.

Comparando os gráficos que mostram o uso da CPU medido pelo vmstat no experimento com 400 (antes da saturação) e com 600 usuários (após a saturação), percebemos que há momentos em que não há processamento.

Provavelmente isso é devido à grande fila de espera de requisições de entrada e saída na máquina durante os períodos em que o tempo de resposta estava saturado, porém não foram coletados dados que nos permitam afirmar isso com segurança.

Gráfico da média de uso da CPU por minuto para 400 usuários.

Para identificar qual o programa que responsável pela maior parte da carga, foram coletadas informações de uso da CPU pelos processos do servidor de aplicações e do SGBD.

Exemplos dos dados coletados com o programa ps durante os testes.

Apesar de os dados informados por esse programa reportarem valores mais baixos que o real, o efeito é o mesmo para todos os programas.

Com base nessa análise, podemos identificar que o servidor de aplicações é o responsável pelo uso excessivo da CPU com o crescimento do número de usuários.

A grande utilização da CPU pelo servidor de aplicações, que nessa bateria de testes é responsável pela aplicação Web e os três servidores (DataServer, MiningServer e VisServer), torna natural a escolha pela próxima configuração do sistema, onde cada conjunto de serviços é colocado em uma máquina separada.

Nessa nova configuração, temos agora cada servidor com seu próprio SBGD.

Podemos notar pela ue o número de requisições agora cresce até 1000 usuários e se estabiliza nesse patamar, pelo menos até 1500 usuários.

O número de erros, em comparação ao caso anterior, diminuiu, porém sem grandes melhorias.

Média de uso da CPU por minuto para 600 usuários.

Média de uso da CPU medida pelo ps para 400 usuários.

O tempo de resposta melhorou bastante e até 900 usuários, cerca de 90% das requisições tiveram a resposta em até segundos.

Gráficos de requisições por minuto e tempo de resposta para o experimento de 1000 usuários.

Pode-se perceber que nesse experimento, mesmo com tantos usuários, não há instantes sem requisições como no experimento de 600 usuários mostrado anteriormente.

Forma como os dados foram coletados.

Média de uso da CPU medida pelo ps para 800 usuários.

Comparativo de requisições feitas ao sistema com servidores separados.

Estão representadas cada máquina responsável pelos serviços, o que nos ajuda a identificar o uso que é feito por cada componente do sistema.

Podemos notar que o VisServer é responsável por grande parte do processamento total do sistema-o que era esperado, já que a maioria dos usuários visualizam os resultados-e o DataServer não consome quase nada.

Percebe-se também que o uso da CPU na máquina da aplicação se estabiliza.

Gráfico de requisições médias por minuto para 1000 usuários.

Variação do tempo de resposta médio para 1000 usuários.

Devido ao limite atingido pela aplicação, que não consegue servir mais requisições dos clientes, forçando-os a esperar mais tempo para fazerem novas requisições.

Como demonstrado nos gráficos, o sistema satura (e as requisições feitas ao sistema se estabilizam) por que o servidor de visualização está saturado e depois outros servidores também alcançam o ponto de saturação.

Uso da arquitetura orientada a serviços.

Média de uso da CPU por minuto para 900 usuários.

Média de uso da CPU por minuto para 1000 usuários.

Gráfico da média de uso da CPU por minuto para 1500 usuários.

Esse trabalho procurou analisar a viabilidade de sistemas baseados no paradigma de Arquitetura Orientada a Objetos SO.

A motivação principal foi o crescente interesse de empresas e instituições na interação em tempo real entre seus diversos aplicativos e com os de outras empresas, muitas vezes localizados em espaços físicos distantes, porém interligados pela grande rede mundial, a Internet.

A grande quantidade de opções existentes para a implantação de SOA nos levou a identificar entre elas a que melhor atende às necessidades apresentadas, de forma simples e objetiva.

Por isso, essa dissertação teve seu foco em um conjunto de tecnologias que são conhecidas como Web Services e utilizadas para a criação de serviços que podem ser acessados através da WWW.

Foi demonstrado que Web Services oferecem mecanismos eficientes para a comunicação entre processos através da Internet, utilizando protocolos conhecidos, como HTTP, para ultrapassar barreiras comumente impostas pelos administradores de rede.

Além disso, a sua padronização permite a independência de linguagem de programação ou plataforma de implantação, permitindo maior flexibilidade para a interligação de diversos sistemas heterogêneos.

Outro objetivo era o de apresentar a criação de uma arquitetura baseada em Web Services.

Para isso, foi apresentado o Tamanduá, uma plataforma interativa e multiusuária de mineração de dados, que permitiu a demonstração de como é criado e projetado um sistema desse tipo.

Essa plataforma foi testada em um ambiente controlado, com a geração de carga baseada em comportamentos reais de usuários do sistema.

Pelos resultados apresentados na seção 5pode-se verificar a escalabilidade da arquitetura, podendo sofrer alterações na disposição dos serviços para suportar uma demanda maior de usuários.

Acredito que a criação dessa arquitetura e os experimentos realizados demonstram o grande potencial do uso de orientação a serviços para a implantação de arquiteturas distribuídas e de Web Services como tecnologia para implantá-las.

Há vários trabalhos que podem ser realizados a partir desta dissertação.

Um dos principais seria a avaliação e implantação de mecanismos de autenticação e segurança para acesso aos serviços.

Como visto, esses são requisitos fundamentais em sistemas distribuídos, principalmente os que executam sobre a Internet.

Um sistema distribuído de mineração de dados não pode trafegar dados importantes dos clientes sobre a Internet sem proteção a devida proteção.

A avaliação do arcabouço conhecido como WS-Resources para a substituição de Web Services também deverá ser considerada em trabalhos futuros porque é uma tecnologia que promete trazer várias vantagens disponíveis no paradigma de computação em grade para a construção de serviços Web.

A plataforma Tamanduá, ainda recente, tem muito o que avançar em direção ao processo completo de descoberta de conhecimento em bases de dados.

Alguns desses avanços são a re-seleção iterativa de conjuntos de dados e atributos em qualquer passo de pré-processamento necessário e definição de prioridades para a fila de execução no MiningServer, tentando prever quais as tarefas serão mais rápidas.

Além disso, poderia ser adicionado aos serviços a possibilidade de envio apenas de partes alteradas e adicionadas dos arquivos de dados transferidos, com o objetivo de melhorar o tempo de transmissão de bases e resultados.

Na área de análise de desempenho pode-se avaliar o impacto de uso de um sistema de cache (ou proxy) na transferência de arquivos de dados.

Isso se torna interessante considerando que as decisões tomadas na implementação do Tamanduá, de transferir bases de dados e resultados por uma requisição HTTP padrão, possibilitam a aplicação de tais técnicas uma vez que o recurso disponibilizado através de uma dessas URLs dificilmente é alterado.

