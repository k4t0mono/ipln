Desde o advento dos computadores muitos esforços foram realizados em torno dos problemas ligados ao processamento de grandes bases de dados.

As primeiras soluções tinham por objetivo acelerar processos triviais de manipulação numérica de grandes volumes de dados.

Adicionalmente, tem-se, nos dias de hoje, também um grande interesse na obtenção de conhecimentos a partir de bases de dados.

Em outras palavras, o desenvolvimento da informatização e também a evolução constante dos meios para armazenamento de grandes massas de dados, nos mais diversos setores da sociedade, deram origem a uma significativa quantidade de dados estruturados em bases digitais.

Apesar destes dados se encontrarem em bases estruturadas, suas análises acabam não ocorrendo na forma e velocidade desejada.

Consequentemente, isto contribui para que uma tomada de decisão seja frequentemente baseada em opiniões pessoais, o que é claramente indesejável no mundo de hoje.

Por esta razão, todo e qualquer esforço no tocante ao desenvolvimento de ferramentas que dão apoio às tarefas de análise, interpretação e relacionamento dos dados disponíveis são de grande importância.

Um dos casos típicos onde encontramos este tipo de desafio são as bases de dados da saúde.

Estas bases possuem grande número de atributos (ou variáveis), pequeno número de ocorrências (ou instâncias/exemplos) e grande número de valores ausentes.

Possuem também muitos dados redundantes e irrelevantes do ponto de vista da aprendizagem de máquina.

Todas estas características tornam o problema de busca de conhecimento em bases da saúde um caso suficientemente particular digno de estudo.

No que diz respeito à tomada de decisão, o caso das bases de dados da área da saúde torna-se ainda mais sensível.

Por exemplo, o profissional de saúde frequentemente analisa individualmente os dados de cada paciente e não dispõe com facilidade de uma visão geral que lhe forneça parâmetros de comparação.

Este problema se torna ainda mais crítico, se considerarmos que as tomadas de decisão na área da saúde são cotidianas e as conseqüências podem ser fatais devido à ausência de informações confiáveis, ou mesmo pela interpretação errônea de dados.

Uma maneira de reduzir esse problema é por meio da construção e análise de bases de dados que possam prover essa visão geral necessária à tomada de decisão, bem como dispor métodos e mecanismos eficientes e eficazes para auxiliar a tomada de decisão.

De forma geral, o processo de descoberta do conhecimento em bases de dados tem desenvolvido-se com a finalidade de identificar padrões relevantes ao domínio estudado.

Devido às características das bases da área da saúde supracitadas, o uso de técnicas de descoberta do conhecimento nos parece essencial.

Em particular, técnicas baseadas na geração de classificadores simbólicos (explícitos), bem como, na combinação de classificadores visando a obtenção de conhecimentos com alta taxa de acerto.

O propósito central deste trabalho é a experimentação de métodos sofisticados de aprendizagem de máquina com o intuito de sugerir soluções eficientes para a descoberta de conhecimento em bases de dados da área da saúde.

Neste sentido, o primeiro esforço de pesquisa realizado foi buscar bases de dados que fossem representativas.

Para tanto, um conjunto de quinze bases foram utilizadas.

Tais bases são comumente utilizadas em pesquisas na área da saúde e estão disponibilizadas para a comunidade científica por intermédio do grupo de aprendizagem de máquina da Escola de Computação e Informática da Universidade de Califórnia Irvine.

A escolha destas bases foi realizada por meio de uma análise detalhada onde buscou-se identificar bases de dados com certo grau de diversidade em termos de quantidade de atributos, quantidade de instâncias e número de classes.

Outro fator importante neste trabalho é o fato das bases de estudo terem sido analisadas tanto na sua forma original, quanto na sua forma reduzida através da aplicação de técnicas de seleção de atributos.

A seleção de atributos é uma das técnicas mais promissoras para o tratamento de bases de dados complexas e frequentemente incompletas como é o caso das bases da área da saúde.

Desta forma, algumas opções de seleção de atributos foram analisadas e todos os testes conduzidos nesta dissertação foram feitos também com a aplicação de seleção de atributos.

Os métodos escolhidos para o estudo desenvolvido nesta dissertação dizem respeito a um conjunto de algoritmos que implementam algumas técnicas de aprendizagem de máquina.

Tais métodos são, ao mesmo tempo, representativos das novas tecnologias de tratamento da informação, bem como reconhecidos pela comunidade científica da área de descoberta de conhecimento.

Os métodos utilizados foram, J48, BAGGING e BOOSTING, nas suas versões implementadas no software Weka (Waikato Environment for Knowledge Analysis) versão 3,que foi utilizado para todas as experimentações deste estudo.

De um ponto de vista prático, esta dissertação tem dois objetivos distintos.

O primeiro objetivo é a avaliação da eficiência da aprendizagem de máquina que utiliza métodos de combinação de classificadores, sob a ótica da análise de suas curvas de aprendizagem.

O segundo objetivo concerne a verificação do impacto da variação do número de classificadores na eficiência dos métodos utilizados.

A verificação da eficiência dos métodos foi feita por meio da aplicação de cada um dos métodos ao mesmo conjunto de bases de dados e observando-se a taxa de acerto obtida para os classificadores resultantes.

A curva de aprendizagem, em particular, foi obtida gerando para cada base 10 amostras de diferentes tamanhos e para cada uma destas amostras observou-se a taxa de acerto.

Para a obtenção das amostras utilizou-se o método estatístico resampling (ou re-amostragem).

O impacto da variação do número de classificadores na eficiência dos métodos foi verificado através da análise estatística dos resultados de taxa de acerto para cada conjunto de classificadores.

Com este propósito desenvolveu-se uma análise criteriosa da eficiência que inclui a verificação da significância estatística dos resultados obtidos através do teste de Friedman.

De forma geral, espera-se determinar o método mais eficiente e analisar o impacto do número de classificadores.

Tal eficiência foi medida sobre distintas bases de dados sem seleção de atributos e com seleção de atributos (ou redução de dimensionalidade).

Como resultado geral, espera-se corroborar ou não com a análise teórica e bibliográfica dos resultados obtidos.

O objetivo geral desta dissertação é a experimentação e o estudo de três métodos de aprendizagem de máquina com o intuito de verificar as suas eficiências, bem como a eficácia da utilização de técnicas de seleção de atributos sobre um conjunto de bases de dados distintas em termos de número de atributos, classes e instâncias.

Os objetivos específicos são avaliar a eficiência (ou a taxa de acerto da classificação) dos métodos de aprendizagem de máquina, J48, BAGGING e BOOSTING, avaliar o impacto da variação incremental do número de classificadores na eficiência (ou a taxa de acerto da classificação) dos métodos BAGGING e BOOSTING, aplicar o teste estatístico (FRIEDMAN) para verificar qual o impacto do aumento do número de classificadores na eficiência dos métodos BAGGING e BOOSTING.

Têm-se aqui, de um lado, o método J48 que não faz uso da combinação de classificadores, e do outro lado, os métodos BAGGING e BOOSTING que utilizam a combinação de classificadores.

Em resumo, estes métodos serão analisados sob a ótica de curvas de aprendizagem aplicados a 15 bases de dados teste originais e suas versões filtradas, ou seja, com seleção de atributos.

Esta dissertação apresenta a seguir um capítulo que examina alguns conceitos básicos da área de descoberta de conhecimento, a saber, seleção de atributos, métodos de aprendizagem de máquina e técnicas estatísticas.

O terceiro capítulo apresenta a metodologia empregada.

O quarto capítulo apresenta os resultados numéricos obtidos e suas respectivas análises.

A conclusão sumariza as contribuições obtidas e cita possíveis trabalhos futuros à pesquisa desenvolvida nesta dissertação.

Finalmente, os dois anexos desta dissertação apresentam gráficos e resultados detalhados.

Nesta seção são apresentados, de forma breve, alguns conceitos importantes à compreensão dos trabalhos aqui desenvolvidos.

Desta forma, as subseções a seguir apresentam noções básicas sobre descoberta de conhecimento, sobre seleção de atributos, sobre métodos de classificação, além de uma série de técnicas estatísticas específicas utilizadas ao longo deste trabalho.

O Processo de descoberta de conhecimento em bases de dados é conhecido como KDD, advindo do inglês Knowledge Discovery in Databases e consiste no processo de descobrir e procurar a informação implícita e útil em grandes bases de dados.

O termo KDD foi formalizado em 1989 para sumarizar o amplo conceito de procurar conhecimento a partir de bases de dados.

Segundo a literatura da área, KDD é um processo, de várias etapas, não trivial, interativo e iterativo, para identificação de padrões compreensíveis, válidos, novos e potencialmente úteis a partir de grandes conjuntos de dados.

Desta forma, é necessária tanto a interação humana, quanto eventuais repetições do processo que normalmente é bastante complexo.

No contexto deste trabalho, interessam as bases de dados que possuem informações importantes, a exemplo dos padrões de procedimento, gerais ou específicos, e que podem ser usadas para melhorar a tomada de decisão na área da saúde.

Neste processo de descoberta do conhecimento, faz-se necessário, em primeiro lugar, o entendimento quanto à área de aplicação, chegando-se, por fim, até a interpretação dos resultados obtidos, ou seja, o conhecimento almejado.

Não se pretende aqui fazer uma revisão completa do processo de descoberta de conhecimento, mas apenas citar vários conceitos básicos que permitam o entendimento da contribuição central da dissertação nos próximos capítulos.

Neste sentido, esta seção descreve inicialmente uma nomenclatura básica da área, que permite a identificação dos termos atributos, instâncias, valores e classes.

Em seguida define-se a visão da literatura das etapas de descoberta de conhecimento, com o foco em mineração de dados.

Inicialmente, adota-se a seguinte nomenclatura bases de dados, Atributos descrevem características ou aspectos que as instâncias podem possuir.

Imaginando uma base de dados como uma tabela, os atributos são habitualmente as colunas Instâncias são conjuntos de valores, até um para cada atributo, que definem as ocorrências de uma base de dados.

Note-se que uma instância pode ter alguns atributos sem valores associados.

Imaginando a base de dados como uma tabela, as instâncias são habitualmente as linhas Valores são as características que uma determinada instância pode ter para cada atributo.

Os tipos destes valores podem ser valores numéricos ou categóricos.

Imaginando uma base de dados como uma tabela, os valores são os dados contidos em cada uma das células Classes são as possíveis valores de domínio em que as instâncias podem ser agrupadas.

Na verdade, a classe representa a informação que se quer extrair da base de dados, sendo, portanto, o objetivo da aprendizagem supervisionada determinar a classe correta para cada instância.

Em algumas bases de dados, as classes podem ser definidas por um único atributo que é chamado de atributo preditor, pois o seu valor define, ou prediz, qual será a classe na qual cada instância será classificada.

Segundo a literatura, os atributos podem ser classificados em quatro tipos básicos, ATRIBUTOS NOMINAIS, seus valores fornecem informações suficientes para apenas distinguir um objeto do outro.

Exemplo, cor dos olhos, sexo ATRIBUTOS ORDINAIS, são atributos qualitativos como os nominais, mas seus valores servem não somente para distinguir os objetos, pois também permitem uma ordem natural entre eles.

Exemplo, número de ruas, notas ATRIBUTOS NUMÉRICOS INTERVALARES, não representam apenas informações pontuais, mas subconjuntos de seqüências ordenadas por uma unidade de medida.

Exemplo, datas, velocidades permitidas ATRIBUTOS NUMÉRICOS DE RAZÃO OU DIFERENÇAS, representações numéricas significativas expressando relações entre grandezas.

Exemplos, idade, massa corporal.

O processo de descoberta de conhecimento em bases de dados é dividido em três etapas operacionais básicas tendo como etapa central a parte historicamente mais complexa, a mineração de dados.

De fato, alguns autores ainda confundem a etapa de mineração de dados com a totalidade do processo.

No entanto, os autores mais recentes dividem este processo em três etapas, pré-processamento, mineração de dados e pós-processamento.

É apresentado esquematicamente as etapas do processo de descoberta de conhecimento de acordo com a abordagem utilizada nesta dissertação.

Note-se que aqui não existe uma preocupação com a definição clássica de KDD.

Etapas do Processo de Descoberta de Conhecimento.

Na etapa de pré-processamento são analisados e classificados os dados para definir tipos e formatos dos mesmos a fim de determinar a base a ser trabalhada na mineração de dados.

Especificamente, o objetivo do pré-processamento é disponibilizar para a etapa seguinte uma base de dados coerente segundo os objetivos desejados.

Nesta etapa define-se a estratégia para resolver o problema de não disponibilidade de dados, podendo ir desde uma simples consulta a um banco de dados, até um procedimento complexo composto por diversas conversões de tipos e formatos de dados.

Não é usual que as bases de dados estejam prontas para mineração.

Assim, durante e após o processo de extração, os dados devem ser formatados para posterior padronização de caracteres, concatenação, formato de representação, limpeza e redução do conjunto de dados.

Algumas das operações mais comuns desta etapa são, segundo a literatura, limpeza, transformação e consolidação de dados.

Tarefas usuais nesta etapa são, correções de digitação, redução e extensão de escala, conversão de unidades, normalização de valores, etc.

Cabe salientar que mesmo que sejam importantes para o processo como um todo, este tipo de tarefa não é objeto deste estudo, pois as bases aqui utilizadas já sofreram previamente estes tratamentos.

Este não é o caso da seleção de atributos que é uma das tarefas mais complexas do pré-processamento, ainda que não seja obrigatória.

A seleção de atributos visa reduzir a dimensão da base de dados eliminando atributos eventualmente redundantes ou desnecessários para a classificação almejada.

Esta tarefa é particularmente importante no contexto desta dissertação e será vista em maior detalhe na Seção 2,que é dedicada a definição de seus conceitos básicos.

A etapa de mineração de dados é a principal etapa do processo KDD, sua finalidade é extrair padrões dos dados.

Esta fase é considerada o centro do processo e se preocupa em ajustar modelos ou determinar padrões a partir dos dados observados.

De uma forma mais precisa, seu objetivo é analisar uma base de dados com a finalidade de descobrir similaridades que possam evidenciar um padrão de comportamento nos dados.

Esta análise se torna interessante devido a estes padrões serem dificilmente descobertos com a utilização de ferramentas comuns de acesso a base de dados, como por exemplo, simples consultas SQL Structured Query Language.

A mineração de dados também pode ser vista como uma forma de selecionar, explorar e modelar grandes conjuntos de dados para detectar padrões de comportamento.

Esta etapa utiliza técnicas baseadas em análise estatística e inteligência artificial (I, mais especificamente Aprendizagem de Máquina).

Na mineração de dados é escolhida a tarefa a ser executada e são definidos os algoritmos que a realizarão.

Dentre as tarefas possíveis, as usuais são regressão, classificação, associação, agrupamento em clusters e sumarização.

No contexto desta dissertação, apenas a tarefa de classificação é estudada.

Para esta tarefa os algoritmos disponíveis variam significativamente.

Dentre eles o foco deste trabalho é sobre algoritmos indutores de árvore de decisão.

Um dos principais exemplos destes algoritmos é o C4,5 que é utilizado nesta dissertação na sua versão java, denominada J48.

No contexto desta dissertação, utilizam-se também técnicas alternativas de mineração de dados através do uso de combinação de classificadores.

Desta forma, além do método J48 que é uma forma tradicional de classificação, utilizam-se também os métodos BAGGING e BOOSTING que são formas mais sofisticadas e bastante difundidas na área de classificação.

A etapa de pós-processamento tem por principal objetivo melhorar a compreensão e validar o conhecimento descoberto, analisando os resultados obtidos na etapa de mineração de dados.

Os padrões identificados e transformados em conhecimento passam a ser utilizados para explicar os fenômenos observados e para apoiar a tomada de decisão.

Dentre as diversas maneiras de abordar a etapa de pós-processamento, o caso mais freqüente é uma análise manual feita por um especialista da área correspondente aos dados minerados.

No entanto, mesmo em se tratando de uma análise manual, o especialista pode valer-se de ferramentas teóricas como análise estatística, padrões de procedimento, etc.

Concomitante a esta análise, os conhecimentos minerados podem ser consolidados em forma de relatórios demonstrativos com a documentação e explicação das informações relevantes encontradas em cada etapa do processo de KDD.

No contexto deste trabalho, a etapa de pós-processamento é representada pela análise dos resultados de taxa de acerto dos métodos obtidos manualmente pela análise de gráficos, mas também pela aplicação de testes estatísticos que validam as hipóteses consideradas.

Dentre as operações usuais de pré-processamento um tipo de adaptação de conjunto de dados, a Seleção de Atributos, é de uso freqüente para tornar a aprendizagem mais eficiente, tanto no desempenho, quanto nas taxas de acerto.

Este é um processo que visa escolher um subconjunto de atributos com o máximo possível de características relevantes à classificação das instâncias, porém de tamanho tão reduzido quanto possível.

A busca pelo subconjunto adequado de atributos é composta de quatro passos.

Esta busca é feita através da sucessiva escolha de subconjuntos de atributos candidatos que são verificados frente a um critério de parada, até que o resultado obtido seja validado.

Passos do processo de seleção de atributos.

As formas de geração do subconjunto candidato podem divergir entre diversos algoritmos.

Esta tarefa pode ser feita por busca completa (por exemplo, branch and bound e beam search), busca seqüencial (por exemplo, forward, backward e bidirectional) ou busca aleatória (por exemplo, random start hill climbing e simulated annealing).

No caso específico desta dissertação foram considerados algoritmos de busca seqüencial do tipo forward, especificamente BestFirst, e busca completa do tipo ordenação, especificamente RankSearch.

Enquanto a busca seqüencial do tipo forward implementada pelo algoritmo BestFirst parte de um conjunto vazio e vai adicionando atributos, a busca completa implementada pelo Ranksearch cria um nova ordem (rank) de atributos baseada em uma métrica pré-definida.

Vários tipos de medida são possíveis, mas no contexto desta dissertação serão examinados dois tipos de métricas, as medidas por dependência (CFS Correlation-based Feature Selection) e medidas por ganho de informação (GainRatio).

Metodologia apresenta mais detalhes de como o uso destas opções foi considerado nos experimentos.

A avaliação do subconjunto candidato, por sua vez, pode ser feita por análises com critérios independentes do algoritmo de mineração que será utilizado posteriormente, como é o caso dos modelos/abordagens do tipo filter, ou por análises com critérios dependentes do algoritmo de mineração, como é o caso dos modelos/abordagens do tipo wrapper.

No escopo desta dissertação, interessam as abordagens do tipo filter.

Nestes casos podem ser empregados diversos tipos de medidas para análise, sendo as mais comuns as medidas de distância, informação, dependência e consistência.

Neste trabalho foram consideradas medidas de dependência (CfsSubsetEval) e consistência (ConsistencySubsetEval) conforme descrito na Seção Metodologia.

As medidas de dependência, também chamadas de medidas de correlação ou similaridade, procuram medir o quanto o valor de um atributo pode ser previsto pelo valor de outro atributo.

Desta forma, um certo atributo que tenha uma maior relação com o atributo preditor (classe) terá preferência sobre outros atributos que tenha uma relação menor.

Já as medidas de consistência, diferem das medidas de dependência por estarem mais relacionadas com a eliminação de inconsistências entre valores dos atributos e classes.

Desta forma, tende-se a eliminar atributos que possam ter instâncias com valores diferentes, mas que correspondam a uma mesma classe.

O teste do critério de parada toma uma decisão se a busca por um subconjunto deve ser encerrada ou não.

Usualmente, quatro tipos de critérios de parada podem ser usados de forma concomitante ou não, o número total de possibilidades de subconjuntos foi alcançado um limite máximo de iterações ou mínimo de atributos foi alcançado um novo subconjunto encontrado não adiciona qualidade de forma significativa e (iv) a qualidade do subconjunto sendo avaliado é superior a um limite pré-definido.

Independente do critério de parada, cabe salientar que, caso a avaliação dos subconjuntos seja feita utilizando a abordagem filter, apenas as características gerais dos dados irão influenciar a qualidade do subconjunto candidato.

Por outro lado, a abordagem wrapper considera um algoritmo específico de mineração utilizando seu desempenho como critério de parada.

Procura-se pelo melhor conjunto de características para maximizar o desempenho do algoritmo de mineração considerado.

Consequentemente, a abordagem wrapper tende a tornar o teste do critério de parada computacionalmente mais custoso se comparado à abordagem filter.

Finalmente, a validação do resultado pode ser feita comparando a qualidade do subconjunto resultante com padrões já conhecidos.

No entanto, isto raramente acontece para casos reais, onde o mais comum é a simples comparação da qualidade da base original frente à qualidade da base modificada com a seleção de atributos.

No contexto desta dissertação a validação do resultado é feita utilizando J48 como método de aprendizagem para comparar a taxa de acerto obtida com a base original frente à taxa de acerto obtida com a base reduzida pela seleção de atributos.

Note-se que esta validação faz parte do processo de seleção de atributos.

Esta comparação não deve ser confundida com a análise comparativa de métodos de aprendizagem que é o tema central da discussão e que é feita em etapas posteriores à seleção de atributos.

A técnica de classificação tenta prever a classe do objeto representado por uma instância baseada nos valores de seus atributos.

Segundo vários autores, este processo de classificação é uma das técnicas possíveis de aprendizado de máquina.

Para se executar a tarefa de classificação, são usados dados que consistem em um conjunto de atributos denominados previsores, e um atributo denominado preditor (classe).

Os atributos previsores são utilizados para definir uma classificação efetiva dos registros pertencentes à base de dados em estudo.

O atributo preditor por sua vez é utilizado como uma hipótese de classificação que será validada ou não pela análise resultante da classificação através dos atributos previsores.

Neste contexto, um algoritmo de classificação, dito algoritmo indutor, consiste em dividir a base de dados em dois conjuntos de instâncias mutuamente exclusivas.

Um dos subconjuntos é chamado conjunto de treinamento e o outro conjunto de teste.

Inicialmente, o conjunto de treinamento é percorrido, analisando as relações existentes entre os atributos previsores e o atributo preditor.

Estas relações são então usadas para prever a classe dos registros presentes no conjunto de teste, que será a próxima ação do classificador.

Em um segundo momento, quando o algoritmo analisará o conjunto de teste, o atributo preditor não é considerado.

Após a previsão das classes dos registros do conjunto de teste, essas classes são comparadas com as classes da hipótese definida pelo atributo preditor.

Com isso pode-se comparar o número de previsões corretas e incorretas.

A tarefa de classificação procura elevar ao máximo a taxa de classificações corretas nos dados de teste.

Esta taxa é definida pela razão entre o número de exemplos classificados corretamente e o número total de exemplos do conjunto de teste.

Quando o algoritmo indutor é aplicado sobre uma base de dados, testam-se várias hipóteses para aproximar-se da classificação expressa pelo atributo preditor originalmente definido.

Se diversas dessas hipóteses são consistentes, pode ocorrer falta de maiores informações para que o algoritmo defina qual a melhor hipótese de classificação.

Neste caso, o algoritmo usa o seu viés (bias), que mede o quanto, na média, cada uma das hipóteses induzidas se aproxima da classificação expressa pelo atributo preditor.

De fato, "Aprendizado sem bias é impossível", porque sempre existe um grande número de hipóteses consistentes.

Os métodos de classificação de interesse são o J48, um método baseado no algoritmo C4,5 implementado em java, e dois métodos baseados em combinação de classificadores, BAGGING e BOOSTING.

As próximas seções descrevem estes métodos em detalhe.

O método J48, tem como base o algoritmo C4,5 que é um dos mais tradicionais para a tarefa de classificação e pertence à família TDIDT Top Down Induction of Decision Tree.

Este algoritmo é inspirado no algoritmo IDe o ponto comum de todos eles é a estratégia de divisão-e-conquista.

Especificamente, o método J48 procura gerar uma árvore de decisão a partir de uma abordagem recursiva de particionamento da base.

Uma árvore de decisão é um modo simples de representar o conhecimento extraído de uma base de dados.

Sua função é sistematizar os dados facilitando a decisão a ser tomada.

Toda árvore de decisão possui uma estrutura composta de nós de decisão, que contém testes sobre algum atributo do conjunto de dados, e folhas, que correspondem a uma classe, ou seja, um diagnóstico ou classificação do atributo preditor.

A escolha de quais atributos devem ser colocados na raiz ou nos nós de decisão deve ser feita por um algoritmo específico.

Temos um exemplo de árvore de decisão onde temos na raiz um atributo (A1) que pode ter três valores distintos, a saber V1, Ve V3.

O atributo A1 com valor Vpermite a conclusão de que a instância pertence à classe X.

Porém se o atributo A1 sozinho não é conclusivo, ou seja, ele tem valores V1 ou V3, os nós de decisão abaixo da raiz da árvore testam, caso A1 tenha valor V1, o atributo Apara os valores W1 ou W2, que concluem respectivamente as classes S ou T.

Por outro lado, se o atributo A1 tem valor V3, o atributo Aé testado para os valores U1 ou U2, concluindo respectivamente as classes Y ou Z.

Exemplo de Árvore de Decisão.

O pseudo-código exposto no Algoritmo 1 apresenta os detalhes do método J48 que trata de um algoritmo recursivo estruturado na forma de uma função.

Esse algoritmo é uma ligeira adaptação do algoritmo apresentado por Eklund e Hoang.

Cada chamada desta função recebe como entrada uma base de dados T (um conjunto de instâncias) e um subconjunto de atributos A (que pode ser um conjunto vazio, ou todos os atributos da base T).

Esta função retorna como saída uma árvore, ou sub-árvore, de decisão apontada pelo seu nó raiz D.

O algoritmo consiste em fazer uma chamada inicial à função C4,5 passando como parâmetros de entrada, T a totalidade da base e A um conjunto contendo todos os atributos.

O parâmetro de saída desta chamada inicial será a árvore de decisão apontada pelo seu nó raiz em D.

A geração de uma árvore de decisão dá-se por meio da chamada da função C4,5 e suas chamadas recursivas.

A cada execução das linhas 6, 10 ou 26 teremos a criação de uma folha na árvore, enquanto as chamadas recursivas (linha 22) representam a criação de um nó de decisão e consequentemente a criação de uma sub-árvore abaixo dele.

Um dos pontos críticos deste algoritmo é a escolha do atributo a ser utilizado em cada um dos nós de decisão, seja ele o nó raiz ou um dos demais nós de decisão.

Esta escolha está representada nas linhas 1e 1do Algoritmo 1.

A primeira tarefa (linha 1 consiste em considerar todos os testes que dividem a base em dois ou mais grupos).

Esta tarefa é feita observando para cada um dos atributos do conjunto A o ganho de informação em relação à classificação desejada.

Os subconjuntos gerados são analisados através do cálculo da entropia de cada subconjunto de instâncias.

Esta entropia é utilizada para calcular o ganho de informação que o atributo considerado obteve.

A segunda tarefa (linha 14) é um teste que deve optar por uma das seguintes alternativas, escolher o atributo com o maior ganho e chamada recursiva da função C4,5 para criar uma sub-árvore (bloco de instruções das linhas 16 a 24) ou assumir que não é necessário criar um nó de decisão e apenas adicionar uma folha com a classe mais freqüente (linha 26).

Função iterativa do algoritmo C4,5 (base para a implementação do método J48).

A entropia de um dado atributo ai para o valor v é calculada pelo somatório do percentual de instâncias que pertencem a cada classe do atributo preditor através da seguinte fórmula, Onde, pc,v é o percentual de instâncias que pertencem a classe c do total de instâncias que possuem o valor v no atributo ai.

Caso alguma probabilidade seja nula (nenhuma instância possuir o valor v), assume-se a entropia nula.

Em seguida calcula-se a entropia de um conjunto de atributos A, onde, pc é o percentual de instâncias que pertencem a classe c do total de instâncias da base dados.

Finalmente, calcula-se o ganho de informação (ganho médio) de cada atributo como a diferença entre a entropia do conjunto de atributos menos a informação de cada atributo, ou seja, Onde, V(ai = v) é o número de instâncias da base que possuem o valor v para o atributo ai e |T| é o número total de instâncias da base de dados.

Base exemplo para aplicação dos métodos de aprendizagem.

A construção da árvore de decisão através do método J48 inicia com a chamada do Algoritmo 1 passando como parâmetros toda a base (T) e o conjunto A = {Freqüência Cardíaca, Freqüência Respiratória, Perda do Apetite}.

A primeira execução entrará evidentemente no bloco de comandos das linhas 1a 27.

A seguir, a execução das linhas 1e 1corresponderá aos cálculos de ganho de informação para cada um dos atributos de forma a determinar qual dos atributos do conjunto A será utilizado no nó raiz da árvore.

Valores de entropia e ganho de Informação para chamada inicial.

Desta forma, teremos um atributo com maior ganho que o demais (0,14e consequentemente a execução do bloco de instruções da linha 16 a 2do Algoritmo 1).

Definido o atributo Freqüência Cardíaca para o nodo raiz (variável at), o laço da linha 18 será executado três vezes, uma para cada valor possível do atributo, a saber Normocárdico, Taquicárdico e Bradicárdico.

Em cada uma destas vezes será chamada novamente a função C4,5 passando os parâmetros de entrada.

Parâmetros de entrada das chamadas recursivas da função C4,5 tendo como atributo at Freqüência Cardíaca.

A primeira chamada recursiva (at = Freqüência Cardíaca, v = Normocárdico) irá executar de forma semelhante à chamada inicial, ou seja, será necessário executar as linhas 1e 1do Algoritmo 1.

Desta forma, serão calculados os seguintes valores de entropia e ganho de informação.

Valores de entropia e ganho de Informação para primeira chamada recursiva.

Como resultado desta análise, o atributo Freqüência Respiratória com o ganho de informação de 0,420 será escolhido para o nó de decisão (variável at).

Na seqüência, duas novas chamadas recursivas serão feitas com os parâmetros de entrada.

Note-se que estas duas novas chamadas serão executadas antes das duas chamadas pendentes.

Parâmetros de entrada das chamadas recursivas da função C4,5 tendo como atributo at Freqüência Respiratória.

A segunda chamada (at = Freqüência Respiratória, v = Taquipnéi irá executar a inserção de uma folha, pois será passado um atributo único (linha 10 do Algoritmo 1).

A folha inserida conterá o valor Sim que é o mais freqüente do atributo preditor para as instâncias 1, e 8.

A terceira chamada (at = Freqüência Respiratória, v = Eupnéi irá executar a inserção de uma folha, pois todas instâncias têm o mesmo valor do atributo preditor (linha 6 do Algoritmo 1).

A folha inserida conterá o valor Não que é o valor do atributo preditor para as instâncias 9 e 11.

Retornando às chamadas referenciadas, a quarta chamada (at = Freqüência Cardíaca, v = Taquicárdico) irá calcular os valores de entropia e ganho de informação para os atributos Freqüência Respiratória e Perda do Apetite (linhas 1e 1do Algoritmo 1).

Valores de entropia e ganho de Informação para quarta chamada recursiva.

Pode observar-se que não é possível escolher entre os atributos Freqüência Respiratória e Perda de Apetite que possuem o mesmo ganho de informação.

Por conseqüência, executa-se a linha 26 do Algoritmo 1 inserindo uma folha com o valor Sim que é o valor mais freqüente do atributo preditor para as instâncias 3, 7, 1e 13.

Finalmente, a quinta chamada (at = Freqüência Cardíaca, v = Bradicárdico) também irá calcular os valores de entropia e ganho de informação obtendo os seguintes valores.

Valores de entropia e ganho de Informação para quinta chamada recursiva.

Tem-se novamente valores iguais de ganho de informação, logo a execução da linha 26 do Algoritmo 1 irá incluir uma folha com o valor da classe mais freqüente (Não) encontrado nas instâncias 4, 5, 6, 10 e 14.

É mostrado a árvore de decisão obtida após esta série de cálculos de entropia e ganho de informação.

Ela contempla, na representação gráfica, a evolução da árvore de decisão, desde a primeira chamada da função C4,5 até a última e quinta chamada recursiva.

Pode-se observar a situação da árvore de decisão antes da primeira chamada recursiva (Inicial) e a seguir cada uma das situações após a execução de cada uma das chamadas recursivas até o resultado final, que é obtido após a execução da quinta chamada recursiva.

Para exemplificar o processo de classificação no método J48, vamos assumir o recebimento de três instâncias a serem classificadas.

Instâncias a serem classificadas pelo método J48.

A classificação da primeira destas instâncias (a1) resultaria na resposta Não, enquanto a instância aresultaria na resposta Sim, e a instância aresultaria na resposta Não.

O método apresentado permite a geração de classificadores simbólicos a partir de uma base de dados.

Este método gera apenas um classificador.

Ou seja, ele não gera vários classificadores para diferentes amostras da mesma base de dados, o que poderia melhorar sua eficiência.

A combinação de diversos classificadores tem como objetivo obter uma taxa de acerto melhor do que a obtida pela aplicação de um classificador distinto.

Os métodos de combinação de classificadores podem ser divididos segundo o tipo de manipulação realizada sobre a base de dados para gerar diversos classificadores.

Eles podem ser agrupados em métodos que manipulam atributos de entrada, valores do atributo preditor (classe) ou algoritmos de aprendizagem.

No entanto, os mais utilizados são os métodos que manipulam os conjuntos de treinamento.

Neste último grupo temos métodos BAGGING e BOOSTING que serão vistos nesta dissertação.

Ambos os métodos geram classificadores a partir de diversos subconjuntos de treinamento obtidos por técnicas de amostragem.

BAGGING (bootstrap aggregating) é um método para combinar k classificadores treinados a partir de k versões da base original amostradas de forma uniformemente distribuída sobre o conjunto de instâncias.

As amostras geradas deverão ter o mesmo tamanho (número de instâncias) do conjunto original e para cada uma das k amostras um classificador é obtido.

Cabe salientar que estas amostras são sorteadas com reposição, pois, elas deverão ter os mesmos números de instâncias que o conjunto original.

Este processo de geração de classificadores está descrito no Algoritmo 2, que é uma versão ligeiramente adaptada da proposta inicial feita por Breiman.

Note-se que na linha 7 deste algoritmo tem-se a aplicação de um algoritmo de aprendizagem, por exemplo, J48.

Este algoritmo irá gerar um classificador, por exemplo, uma árvore de decisão para cada uma das amostras.

Geração de Classificadores através do Método BAGGING.

Representa genericamente o processo do método BAGGING.

Estão representadas as seguintes etapas, geração de diferentes amostras de tamanhos iguais a partir da mesma base de dados de treinamento obtenção de um classificador para cada amostra, representado como árvores de decisão obtenção de um classificador composto que inclui todos os classificadores individuais gerados na fase anterior e votação simples, para cada classificação de uma instância, para eleger a classificação mais popular dentre os classificadores individuais.

É fundamental salientar que o método BAGGING, assim como os demais métodos de combinação de classificadores, consiste em gerar um classificador composto.

Esta é uma diferença fundamental quando comparado a um método de geração de classificador único como, por exemplo, o método J48.

O produto final do método BAGGING não é um classificador único.

Ele não é a fusão de k árvores de decisão em uma árvore única.

O resultado da geração do método BAGGING é um conjunto de classificadores que são utilizados de forma integrada, pois cada nova instância a ser classificada será avaliada pelo classificador composto cujo resultado (a classificação da instânci será a resposta escolhida pela maioria dos k classificadores).

Segundo a literatura, o método BAGGING é particularmente interessante quando os algoritmos de aprendizagem aplicados a determinadas bases de dados possuem um comportamento instável.

Nestes casos, um classificador único não é capaz de oferecer uma resposta confiável para todas as situações, mas um conjunto de classificadores, ou seja, um classificador composto pode ter maior chance de acerto.

Na verdade, o uso de BAGGING para estes casos aumenta a taxa de acerto se comparado a árvores de decisão obtidas por abordagens mais simples como o método J48, porém, perde-se uma estrutura facilmente interpretável.

Esquema geral de funcionamento do método Bagging.

O método BAGGING é o equivalente de aprendizagem de máquina à situação onde um gestor humano se cerca de k consultores e toma a decisão baseada na votação feita por estes consultores.

Cabe salientar que o uso deste método de votação entre classificadores resulta em um classificador composto que tende a ter uma taxa de acerto maior do que a taxa de acerto de cada um dos classificadores individualmente.

Aplicando o método BAGGING a base da tabela que possui 1instâncias (n = 14) utilizando três classificadores (k =, teríamos, por exemplo, as três amostras geradas aleatoriamente representadas).

Os valores foram obtidos por tiragens aleatórias uniformemente distribuídas sobre as instâncias da base original.

Desta forma, para a primeira amostra foram sorteadas as instâncias 1, 2, 3, 4, 5, 6 (2x), 7 (2x), 9, 10 (3x) e 14.

Apenas para facilitar a visualização, estas instâncias foram ordenadas e sua posição original indicada na coluna PO.

Note-se que como na base original, o atributo preditor é a última coluna (M).

A geração destas amostras corresponde a execução da linha 6 do Algoritmo 2.

Para cada uma das amostras, utilizando o método J48 de forma análoga a seção anterior, um classificador é gerado.

A obtenção destes classificadores corresponde a execução da linha 7 do Algoritmo 2.

Para exemplificar o processo de classificação no método BAGGING, vamos assumir o recebimento de três instâncias a serem classificadas.

Instâncias a serem classificadas pelo método Bagging.

A classificação da primeira destas instâncias (a1) resultaria na resposta Sim, para o Classificador C1 Não, para o Classificador C2 e Sim, para o Classificador C3.

Conseqüente a resposta Sim será considerada, pois ganha a votação por votos a 1.

A classificação da instância aresultaria na resposta Não para todos os classificadores, ganhando a votação por unanimidade.

A mesma situação acontece para a instância aque resultaria na resposta Sim, também por unanimidade.

O método BOOSTING é outro método de combinação de classificadores que foi desenvolvido com o intuito de oferecer classificadores mais eficientes.

A partir daí foram criados vários algoritmos, sendo que o mais conhecido é o AdaBoost (Adaptative Boosting).

Neste método, como no método BAGGING, são geradas amostras que dão origem a classificadores que são utilizados de forma integrada.

Entretanto, existem apenas duas distinções entre os métodos BAGGING e BOOSTING, a maneira como são geradas as amostras e a maneira como são combinados os resultados dos classificadores.

A primeira diferença frente ao método BAGGING é a forma como são geradas as amostras no método BOOSTING.

Para uma base de treinamento com n instâncias, ao invés de gerar amostras de tamanho n assumindo sempre uma distribuição uniforme (probabilidade 1/n) sobre as instâncias da base de treinamento levam-se em conta as amostras já geradas de forma a alterar a distribuição de geração das próximas amostras.

Este processo pode ser dividido em k passos, sendo que cada passo compreende, a geração de uma amostra a geração do classificador associado à amostra a aplicação deste classificador a base de treinamento original (iv) a análise de eficiência geral deste classificador (v) a eficiência do classificador frente a cada instância da base de treinamento individualmente e, finalmente, (vi) a alteração das probabilidades para a geração da amostra no próximo passo.

De forma mais específica, a geração de k amostras no método BOOSTING consiste em, gerar a primeira amostra assumindo a distribuição uniforme, ou seja, todas as instâncias da base têm a mesma probabilidade (1/n) de serem incluídas na primeira amostra gerada em seguida, gerar um classificador para esta amostra e aplicar o classificador a base de treinamento original de acordo com o classificador gerado.

Diminuir a probabilidade de serem incluídas na próxima amostra das instâncias que foram corretamente classificadas e aumentar a probabilidade das instâncias que foram incorretamente classificadas.

Gerar a segunda amostra a partir da base original levando em conta as novas probabilidades de cada instância gerar um classificador para a segunda amostra e aplicar o classificador a base de treinamento original e mais uma vez diminuir a probabilidade das instâncias bem classificadas.

Aumentar a probabilidade das instâncias mal classificadas repetir este processo de geração de amostras, classificadores e alteração de pesos até serem gerados a k-ésima amostra e o k-ésimo classificador.

O resultado desta operação tende a gerar amostras que são mais "especializadas", ou seja, enquanto uma amostra é eficiente para classificar algumas das instâncias da base, as próximas amostras tendem a privilegiar instâncias mal classificadas anteriormente.

A segunda diferença frente ao método BAGGING está na forma como são combinados os classificadores.

Ao invés de uma votação simples entre as respostas fornecidas por cada classificador, no método BOOSTING a votação é ponderada segundo um índice de importância entre os classificadores gerados.

Para isto é necessário que o processo de geração de classificadores memorize a eficiência de cada classificador gerado frente à base de treinamento.

Note-se que este processo não adiciona custos ao método, pois os classificadores já devem ser testados a cada passo, para gerar amostras de acordo com probabilidades distintas.

É descrito o método BOOSTING ilustrando a inclusão do cálculo das probabilidades de acordo com o classificador da amostra anterior para gerar a próxima amostra (Ponderação) e a votação ponderada entre as respostas dos classificadores para obter o resultado do classificador composto.

Fazendo novamente uma analogia entre a aprendizagem de máquina e a humana, o método BOOSTING é similar ao caso do humano gestor que se cerca de diversos conselheiros, porém ao contrário do método BAGGING que busca "consultores" usando somente a aleatoriedade, o método BOOSTING busca "consultores" com diferentes especialidades.

Enquanto a geração de amostras no método BAGGING é feita sempre sorteando amostras de instâncias com distribuição uniforme, no método BOOSTING a obtenção de amostras tende a ser ortogonal, por que se busca incluir instâncias mal classificadas e excluir instâncias bem classificadas.

Buscando não desprezar as relações de nenhuma das instancias da base de treinamento.

Esquema geral de funcionamento do método BOOSTING.

A implementação prática desta política de variação nas probabilidades de instâncias para as amostras é feita através da definição de um vetor de pesos (w) que associa um valor real entre 0 e 1 a cada uma das instâncias da base de treinamento original.

Este vetor será modificado após a geração de cada novo classificador.

O elemento wj deste vetor está associado à j-ésima instância da base de treinamento.

Além da probabilidade da j-ésima instância ser incluída na próxima amostra, este peso wj também significa o quanto a j-ésima instância é importante para a busca dos próximos classificadores.

Note-se que ambos os significados tem uma semântica muito semelhante, mas como será demonstrado a seguir, cada um destes significados representa um uso distinto dos pesos wj na execução do método BOOSTING.

Após cada aplicação de um novo (i-ésimo) classificador (classificador gerado no i-ésimo passo), calcula-se a sua taxa de erro (e(i)), sua importância (a(i)) e recalcula-se o peso de cada instância da base de treinamento (wj).

O Algoritmo descreve a implementação do algoritmo Adaboost que é utilizado para gerar os classificadores do método BOOSTING.

Este algoritmo é uma ligeira adaptação da versão original proposta por Freud e Schapire.

Adaboost Geração de Classificadores através do Método BOOSTING.

O primeiro ponto de interesse no algoritmo Adaboost é a inicialização das probabilidades de w com o valor 1/n (linha do Algoritmo).

Devido a esta inicialização, a primeira geração de amostra (primeira execução da linha é igual às gerações feitas no método BAGGING, pois a escolha de instâncias a incluir na amostra será feita por uma distribuição uniforme).

O cálculo da taxa de erro do classificador Ci (linha 8 do Algoritmo é feito levando em consideração, (i) o número de instâncias da amostra (n) o peso de cada uma das instâncias (wj) e a verificação da efetividade do classificador Ci em classificar corretamente cada uma das instâncias.

Numericamente, ela é calculada pela fórmula, Onde, d(x) é um operador que retorna o valor 1 caso o parâmetro (x) seja verdadeiro e retorna 0 caso contrário Ci(xj) representa a classe prevista pelo classificador Ci para a j-ésima instância da base de treinamento e yj representa a classe da j-ésima instância expressa pelo valor do atributo preditor da base de treinamento.

A importância de um classificador (a(i)) é calculada com base na sua taxa de erro.

Este cálculo, descrito na linha 9 do Algoritmo 3, é feito pela fórmula, a(i) = (1/2) ln (ei) / ei) (De posse da importância do classificador Ci, decide-se se a amostra e seu classificador serão descartados).

Caso a taxa de erro seja superior ao palpite aleatório (ei > 0,descarta-se a amostra e outra amostra é gerada com os pesos reinicializados para uma distribuição uniforme (linha 1do Algoritmo que retorna à linha 6).

Caso a eficiência do classificador seja satisfatória, a atualização dos pesos é feita de acordo com a importância do classificador (linha 1do Algoritmo).

Esta atualização de pesos é feita em duas etapas.

Primeiramente, aplica-se um fator multiplicativo aos pesos existentes e depois normalizam-se os pesos obtidos.

O peso wj das instâncias que tiveram suas classes previstas corretamente é decrescido pela divisão pelo fator ea(i), ou seja, ao número de Euler (e=2,7182elevado a importância do classificador (a(i)).

De forma análoga, o peso das instâncias que foram previstas incorretamente é acrescido através da multiplicação pelo mesmo fator (ea(i)).

Feita esta operação, o vetor de pesos w é normalizado, ou seja, todos seus elementos são divididos por um mesmo fator de normalização de forma que a sua soma continue igual a 1.

Aplicando o método BOOSTING a base de teste com três classificadores (k =, o resultado da primeira execução das linhas 6 e 7 do Algoritmo mostra a primeira amostra gerada com uma distribuição uniforme sobre as instâncias da base e o classificador gerado a partir desta amostra).

Primeira amostra para a base de dados exemplo resultante da execução do algoritmo Adaboost e o seu classificador.

Aplicando o classificador C1 obtido à base de dados original, verifica-se que as instâncias 5, 8, 9, 11 e 1foram incorretamente classificadas.

Esta tarefa permite o cálculo da taxa de erro e da importância deste classificador (linhas 8 e 9 do Algoritmo, Como o valor da taxa de erro não supera 0,5 (linha 10 do Algoritmo, recalculam-se os pesos das instâncias da base de treinamento obtendo-se os valores apresentados no Quadro 1).

Vetor de pesos das instâncias após o primeiro passo.

Após o recálculo dos novos pesos para as instâncias da base de dados (segundo passo), uma nova amostra foi gerada.

Segunda amostra para a base de dados exemplo resultante da execução do algoritmo Adaboost e o seu classificador.

A primeira observação a ser feita sobre a amostra gerada é que mesmo sendo aleatória, percebe-se que das 5 instâncias mal classificadas pelo Classificador C1 estão presentes no Classificador C(apenas a instância 1não foi sortead).

Outro fator marcante é a diferença grande entre os classificadores gerados nos passos 1 e 2.

Aplicando-se o novo classificador a base de treinamento original verifica-se que as instâncias 4, 8, 10 e 1foram incorretamente classificadas.

Calculando a taxa de erro e importância do Classifcador C2, O valor de taxa de erro inferior a 0,5 permite o recálculo dos pesos das instâncias resultando nos valores do Quadro 2.

Observa-se neste quadro o aumento da probabilidade das instâncias 8 e 1que foram erroneamente classificadas nos dois classificadores já gerados.

Por outro lado, observa-se que as instâncias 1, 2, 3, 6, 7, 1e 1possuem pesos baixos.

Estas observações permitem ilustrar o procedimento do método BOOSTING que privilegia a geração de classificadores distintos a cada novo passo.

Vetor de pesos das instâncias após o segundo passo.

São apresentados a terceira amostra e seu classificador, terminando a geração de classificadores para este exemplo (k =).

Este terceiro classificador é o mais simples possível, pois ele escolhe sempre a classe Não independente dos valores dos atributos.

Apesar de estranho, este classificador monótono não é tão surpreendente assim quando se observa a terceira amostra, onde todas as instâncias, exceto a primeira, possuem o valor Não no atributo preditor.

O dado mais interessante é que apesar disto, a taxa de erro do Classificador Cnão é tão ruim quando aplicado à base de treinamento original.

Os valores da taxa de erro e da importância de Csão, Terceira amostra para a base de dados exemplo resultante da execução do algoritmo Adaboost e o seu classificador.

Note-se que não é mais necessário recalcular os pesos, por que Cé o último classificador gerado.

No entanto, é necessário refazer o cálculo tanto para a taxa de erro que pode implicar no descarte do classificador gerado, quanto para a importância de C3.

Esta última será utilizada, juntamente com as importâncias dos demais classificadores, na votação ponderada.

Para exemplificar o processo de classificação no método BOOSTING, vamos assumir na o recebimento de três novas instâncias a serem classificadas.

Instâncias a serem classificadas pelo método Boosting.

A classificação da primeira destas instâncias (a1) resultaria na resposta, Sim, para o Classificador C1 que tem importância 0, 294 Não, para o Classificador Cque tem importância 0, 398 Não, para o Classificador Cque tem importância 0, 487.

Conseqüentemente a resposta Não será considerada, pois ganha a votação ponderada com o valor 0, 885 contra o valor 0, 29da resposta Sim.

A classificação da instância aresulta em, Não, para o Classificador C1 que tem importância 0, 294 Sim, para o Classificador Cque tem importância 0, 398 Não, para o Classificador Cque tem importância 0, 487.

Conseqüentemente a resposta Não será considerada, pois ganha a votação ponderada com o valor 0, 781 contra o valor 0, 398 da resposta Sim.

A classificação da instância aresulta em, Sim, para o Classificador C1 que tem importância 0, 294 Sim, para o Classificador Cque tem importância 0, 398 Não, para o Classificador Cque tem importância 0, 487.

Conseqüente a resposta Sim será considerada, pois ganha a votação ponderada com o valor 0, 69contra o valor 0, 487 da resposta Não.

Nesta seção são descritas as técnicas de validação cruzada e o teste estatístico de Friedman que são empregados na análise dos resultados obtidos neste trabalho.

Ao contrário dos métodos de aprendizagem de máquina que estão no tema central desta dissertação, as técnicas vistas nesta seção são técnicas estabelecidas que foram abordadas de forma genérica e sem maior profundidade.

O leitor interessado em maiores detalhes sobre estas técnicas pode consultar a bibliografia citada.

A técnica de validação cruzada é uma das formas mais utilizadas para estimar a taxa de acerto de classificadores.

Uma opção simplista de verificar a taxa de acerto de um método para uma base de dados de treinamento com n instâncias é gerar um classificador utilizando a totalidade da base como conjunto de treinamento e após utilizar a mesma totalidade da base para testar o classificador.

Esta técnica simplista com certeza irá gerar um valor de taxa de acerto baseado numa única taxa de acerto.

No entanto, este valor de taxa de acerto será provavelmente tendencioso, pois o mesmo conjunto de instâncias foi utilizado para gerar o classificador e para testá-lo.

A validação cruzada aparece como uma opção mais sofisticada que busca evitar os problemas de uma técnica tão simplista.

Na técnica de validação cruzada divide-se a base de dados com n instâncias em f amostras (folds) aleatoriamente escolhidas, cada uma com tamanho igual a n/f instâncias, ou um tamanho aproximado caso n não seja divisível por f.

De forma genérica, a validação cruzada repete f vezes um processo de treinamento e teste.

Em cada uma destas vezes, utiliza-se uma das f amostras aleatórias para serem validadas pelo treinamento feito com as outras f-1 amostras.

Cada uma destas f validações retornará um resultado de taxa de acerto.

A taxa de acerto final será dada pela média aritmética simples dos f valores de taxa de acerto encontrados para cada uma das amostras.

Desta forma, uma base de dados com 60 instâncias a qual se aplicará a técnica de validação cruzada com f igual a 5, dará origem a 5 amostras com 1instâncias.

O processo de validação cruzada consistirá de 5 passos onde em cada um deles das amostras serão utilizadas como conjunto de treinamento, ou seja, uma base de treinamento com 48 instâncias.

Esta base de treinamento será utilizada para gerar através de um determinado método um classificador que será utilizado para classificar as 1instâncias da amostra que não foram consideradas na base de treinamento.

Por fim, a média de cada um dos 5 testes conduzidos será considerada como a taxa de acerto obtida para a base de dados.

Como pode ser observado, a técnica de validação cruzada pode ser aplicada a qualquer método de aprendizagem de máquina, como por exemplo, aos métodos vistos na seção anterior.

A avaliação estatística dos resultados experimentais é considerada uma parte essencial na validação de novos métodos de aprendizagem de máquina.

Os testes estatísticos devem ser executados corretamente e as conclusões resultantes devem ser extraídas cautelosamente.

De acordo com as características de cada experimento, deve ser escolhido um teste estatístico paramétrico (teste t, ANOV ou não-paramétrico (Wilcoxon, Friedman, teste de sinal).

Baseado nas propriedades estatísticas conhecidas de cada teste, nos seus pressupostos, e no conhecimento dos dados da aprendizagem de máquina, concluiu-se que os testes não-paramétricos devem ser preferidos em relação aos paramétricos, pois são mais prováveis para rejeitar a hipótese nula, e não correm os riscos de violações das suposições dos testes paramétricos.

Temos como exemplo de teste não-paramétrico para amostras relacionadas o teste de Friedman, utilizado neste trabalho.

Este teste pode ser utilizado para verificar se N grupos, avaliados sob c diferentes condições, foram extraídos de uma mesma população (hipótese nul).

Para a aplicação deste teste, os dados deverão estar dispostos em uma tabela de dupla entrada (com N linhas e c colunas).

As linhas representarão os conjuntos e as colunas, as diversas condições.

Para demonstrarmos um exemplo simplificado da aplicação do teste, apresentamos no Quadro um experimento, onde se pretende estudar os escores de três grupos sob condições (nesse caso, c=e N=, onde as linhas determinam cada um dos grupos, e as colunas são as diferentes condições, e no corpo da tabela os respectivos escores).

Exemplo simplificado para aplicação do teste de Friedman.

A aplicação do teste de Friedman inicia-se com a ordenação das condições de cada uma das linhas de maneira a estabelecer um posto distinto para cada uma das colunas ordenadas nas linhas.

No Quadro 4, por exemplo, a linha correspondente ao grupo A seria ordenada de forma decrescente com a condição 1,4,e 3, desta forma no Quadro temos os postos da linha correspondente ao grupo A com os valores 4,2,1 e 3.

Após, os postos atribuídos pela ordenação individual de cada linha devem ser somados para cada uma das colunas.

O teste de Friedman determinará se as somas dos postos por colunas diferem significativamente entre si.

Atribuição e soma de postos para o exemplo do Quadro 3.

Se considerarmos como hipótese nula a inexistência de diferenças estatisticamente significativas entre as c condições, a distribuição dos postos nas diferentes condições representaria amostras aleatoriamente distribuídas, não havendo co-relação entre elas.

Para calcular a existência ou não desta co-relação faz-se o somatório das variâncias (Q) das somas dos postos.

A partir do valor obtido para Q calcula-se o p-valor como a probabilidade do valor superior ou igual a Q segundo uma distribuição qui-quadrada com c-1 graus de liberdade.

Para valores pequenos de n e de c, por exemplo, n<16 e c<5, recomenda-se a utilização de tabelas de contingência ao invés da aproximação da distribuição qui-quadrada.

Cabe salientar que a execução do teste de Friedman requer um tratamento mais complexo, mas estes detalhes fogem ao escopo dessa dissertação, pois foi utilizado o software Statistica.

O leitor interessado nesse detalhes deve consultar a referência.

No exemplo dos Quadros e 4, observa-se que as somas das diferentes colunas (condições) diferem entre si.

No entanto, apesar de ser claro que as condições 1 e possuem valores superiores às condições e 3, uma ordenação inequívoca entre todas as quatro condições é menos óbvia.

Numericamente, o resultado da aplicação do teste de Friedman a este exemplo nos levaria à rejeição da hipótese nula, pois p-valor obtido seria igual a 0, 0301.

Este resultado numérico indica que existe uma probabilidade de 3,01% (p-valor obtido) de rejeitar a hipótese nula sendo ela verdadeira.

Dito de outra forma pode-se afirmar com 96,99% de confiança que existe uma co-relação entre os resultados obtidos para os grupos A, B e C.

De forma genérica, o resultado numérico do teste de Friedman fornece o nível de significância (p-valor) da afirmação.

P-valores pequenos fornecem evidências para rejeitarmos a hipótese nula em favor da hipótese alternativa.

Ao contrário, p-valores grandes fornecem evidências para aceitar a hipótese nula.

Desta forma, é necessário estabelecer um valor limiar de tolerância de aceitação, que é chamado de nível de significância do teste.

O valor habitualmente empregado varia de 1% a 5%.

No contexto desta dissertação adotou-se como nível de significância 0,05 que significa a existência de 5% de chance de rejeitar a hipótese nula, sendo ela verdadeira.

Nessa seção são apresentados alguns trabalhos relacionados que também aplicam os métodos J48, Bagging e Boosting com o intuito de comparação.

A principal distinção clara é que o objetivo desta dissertação é uma análise destes métodos quando aplicados a bases da área da saúde, e nenhum dos demais trabalhos tem este mesmo foco.

Em todos os quatro trabalhos analisados o propósito é melhorar o entendimento de como esses algoritmos com todas as suas características influenciam (agem) no erro de classificação e recomendar para que tipos de bases devemos aplicar cada um dos métodos.

Nesta dissertação o foco é ligeiramente distinto, pois busca-se apenas verificar o método mais preciso através das taxas de acerto nas bases específicas da área da saúde, podendo esse método ser aplicado em bases da área da saúde para tomada de decisão.

Quinlan faz comparações entre C4,5, BAGGING e BOOSTING, aplicando-os em bases genéricas, mas também utilizando a taxa de acerto como parâmetro de comparação entre os métodos e a análise através de curvas de aprendizagem.

Este é o trabalho relacionado mais semelhante.

Cabe lembrar que o método J48 utilizado nesta dissertação é uma implementação Java do algoritmo C4,5, e portanto, quando Quinlan se refere a C4,5 trata-se de uma forma absolutamente análoga de aprendizagem de máquina que o método J48.

No contexto dessa dissertação, as bases de dados são especificamente bases da área da saúde que possuem características próprias que dificultam a extração de conhecimento.

Além desta diferença básica, nesta dissertação não se analisa simplesmente a taxa de acerto com curvas de aprendizagem, mas verifica-se também o impacto do número de classificadores na comparação dos métodos BAGGING e BOOSTING.

Dietterich utiliza bases genéricas para comparar os métodos BAGGING, BOOSTING e Randomização.

Nesse trabalho são analisadas alternativas aleatórias nas decisões internas feitas pelo algoritmo de básico de aprendizagem (C4,5).

Desta forma Diettrich, não utiliza uma versão única do algoritmo C4,5 para a geração dos diversos classificadores internos aos métodos BAGGING e BOOSTING.

Mostrando através da taxa de erro que o método de Randomização é competitivo com os métodos BAGGING e BOOSTING.

Uma diferença central deste trabalho relacionado com esta dissertação é o fato de não serem utilizadas variações de parâmetros no algoritmo C4,5 e não foi feita nenhuma análise do método de randomização.

Bauer e Kohavi também utilizam bases genéricas para seus experimentos e fazem comparação entre os métodos BAGGING, BOOSTING e Variantes como o algoritmo ARC-XArc-xusando a taxa de acerto como parâmetro de comparação.

Kotsianti e Kanellopoulous é o trabalho relacionado mais recente que faz uma comparação dos métodos BAGGING e BOOSTING, mas também de um outro método menos popular chamado DAGGING (Disjoint-sample aggregation).

Além de comparar a aplicação destes três métodos a bases genéricas verificando a taxa de acerto de cada um deles, o trabalho de Kotsianti e Kanellopoulous propõe um método que combina os três outros e defende que este seu método possui é mais preciso que cada um dos métodos individualmente.

Apesar de não ser focado em bases da área da saúde, este trabalho é bastante importante em relação a esta dissertação por duas razões principais.

Primeiramente ele mostra a atualidade do tema de comparação de métodos de aprendizagem de máquina que combinam classificadores.

Isto demonstra que não há consenso na área sobre qual método é o mais adequado, mas sim apenas algumas conclusões empíricas.

O segundo ponto de interesse neste trabalho relacionado é o fato de que ele afirma que o método BOOSTING tem, segundo resultados empíricos, um desempenho inferior ao método BAGGING para bases de dados com ruído, ou seja, bases onde, por exemplo, os dados não apresentam valores faltantes e/ou contraditórios.

Este é precisamente o caso de diversas bases da área da saúde, logo seria normal esperar que o método BAGGING tivesse uma melhor taxa de acerto que o método BOOSTING para as bases estudadas nesta dissertação.

No entanto, os resultados das experimentações feitas demonstram o contrário.

Como já dito anteriormente, o grande interesse pela descoberta de conhecimento a partir de bases de dados tem seu marco inicial com a informatização dos meios produtivos que contribuíram de forma decisiva à geração de grandes volumes de dados.

Podemos citar como ilustração, as transações eletrônicas, os novos equipamentos científicos, hospitalares e industriais para observação e controle, os dispositivos de armazenamento em massa.

O aproveitamento de padrões interessantes (válidos, novos, úteis e interpretáveis) descobertos a partir destas massas de dados gera ganhos de competitividades significativos nos mais diversos domínios.

Entretanto, os recursos de análise de dados tradicionais não são viáveis para acompanhar esta evolução em termos de descoberta de conhecimentos interessantes a partir de bases de dados.

A solução passa necessariamente pelas ferramentas de automatização das tarefas repetitivas e sistemáticas de análise de dados, assim como pelas ferramentas de auxílio às tarefas cognitivas da análise e integração destas em um sistema de apoio ao processo completo de descoberta de conhecimento para tomada de decisão.

Centrado sobre as ferramentas de descoberta de conhecimento a partir de bases de dados, a atividade de investigação realizada neste trabalho toma a direção de um estudo experimental que envolve os seguintes métodos de aprendizagem de máquina, J48, BAGGING e BOOSTING.

Tal estudo visa analisar a eficiência destes métodos em termos de comportamento da taxa de acerto dos classificadores gerados pelos mesmos.

A configuração deste experimento testará, sobre um conjunto de quinze bases de dados da área de saúde, a eficiência dos métodos de aprendizagem de máquina já citados levando em consideração suas curvas de aprendizagem e impacto do número de classificadores quanto a taxa de acerto.

Tal impacto será medido apenas para os métodos BAGGING e BOOSTING, cuja combinação de classificadores faz parte do processo de aprendizagem.

Em termos mais particulares, o estudo investigativo levará em conta por um lado, quinze bases de dados sem redução do número de atributos, e do outro lado, quinze bases de dados com redução do número de atributos por meio de um processo de filtragem de atributos irrelevantes.

Buscar-se-á aqui colocar em evidência o comportamento dos métodos J48, BAGGING e BOOSTING aplicados a diferentes amostras para cada uma das bases de dados, com e sem redução de sua dimensionalidade.

As amostras serão obtidas por meio de um processo de amostragem sofisticado que mantém as mesmas propriedades da base de dados original.

Ou seja, cada amostra mantém a mesma proporção de valores para o atributo classe.

Os experimentos que serão realizados para os métodos de aprendizagem de máquina supracitados basear-se-ão nas seguintes etapas.

Identificar um conjunto BD de quinze bases de dados da área de saúde, cujas características em termos de número de atributos, número de classes e número de instâncias sejam significativamente diferentes aplicar um método de filtragem de atributos sobre cada base de dados do conjunto BD no intuito de reduzir a dimensionalidade das mesmas, gerando um conjunto de bases de dados filtrados ou de dimensões reduzidas, doravante denominado de conjunto BDf.

Gerar, para cada base de dados de BD e BDf, três curvas de aprendizagem uma para cada um dos seguintes métodos, J48, BAGGING e BOOSTING.

Gerar, para cada base de dados de BD e BDf, um de conjunto valores de taxa de acerto, variando o número de classificadores a ser combinado, para cada um dos seguintes métodos BAGGING e BOOSTING respectivamente verificar, comparativamente por meio da realização de teste de hipótese, a existência de diferenças significativas sobre o impacto do número de classificadores no desempenho dos métodos BAGGING e BOOSTING.

Este capítulo apresenta nas próximas seções as bases de dados utilizadas e o tratamento dos dados anterior à aplicação dos métodos de aprendizagem (Seção 3,1), bem como as etapas correspondentes a obtenção das curvas de aprendizagem (Seção 3,2) e a obtenção dos fatores de impacto quanto ao número de iterações (ou classificadores) para os métodos BAGGING e BOOSTING (Seção 3,).

Nestas duas últimas seções, serão apresentados os algoritmos que descrevem em detalhe a forma como os experimentos foram executados.

O conjunto de atividades de cada algoritmo toma como entrada um dos conjuntos BD ou BDf, e fornece como saída uma matriz, onde cada elemento da mesma corresponde a uma taxa de acerto de um dado classificador para uma amostra de uma dada base de dados que foi fornecida como entrada.

Finalmente, os resultados são sumarizados por meio de gráficos que representam curvas de aprendizagem e por meio de análises estatísticas para verificação de hipóteses.

Destacamos que todos os estudos experimentais, que serão realizados na seqüência, envolverão algoritmos de aprendizagem de máquina, de filtragem de atributos e de geração de amostras implementados no pacote de software WEKA versão 3,4.

E para as análises estatísticas será utilizado o software STATISTICA versão 8.

As quinze bases de dados selecionadas para os experimentos foram tomadas do repositório de dados da escola de computação e informática da Universidade da Califórnia Irvine.

Todas as bases são da área de saúde.

A seleção destas bases tomou como premissa a diversidade quanto ao número de atributos, instâncias e classes.

O Quadro 5 apresenta algumas características das bases selecionadas.

Características das bases de dados do conjunto BD.

Pode-se observar que algumas destas bases de dados possuem um grande número de atributos, por exemplo, a base de dados arrhythmia com 280 atributos.

Tem-se ainda, para esta base de dados, o complicador dado pelo pequeno número de instâncias comparativamente ao número de atributos.

Tal proporcionalidade pode ser entendida como uma especificidade da área da saúde, visto que os dados não são, na sua grande maioria, capturados de forma automática e também devido à subjetividade da área.

A filtragem de atributos irrelevantes pode ser uma solução para aumentar significativamente a relação entre número de instâncias versus número de atributos.

Em geral, a redução do número de atributos ou da dimensionalidade é realizada para buscar uma economia de tempo de processamento e de memória, bem como evitar atributos redundantes.

O maior problema ligado a este processo é não remover atributos relevantes para se obter padrões interessantes e ainda manter a eficiência dos algoritmos de aprendizagem de máquina.

A verificação da degradação ou da não eficiência dos métodos J48, BAGGING e BOOSTING sobre bases de dados com suas dimensionalidades reduzidas é um item do experimento.

Características das bases de dados após filtragem de atributos.

O Quadro 6 mostra o resultado, em termos de redução do número de atributos, após a seleção de atributos realizada por meio da aplicação da abordagem filter.

Esta abordagem tenta selecionar um subconjunto de atributos independente do algoritmo de classificação.

Ela estima a qualidade dos atributos apenas em relação aos dados.

Para distinguir as bases de dados originais das bases de dados derivadas por meio da filtragem de atributos, foi acrescido ao nome de base de dados o termo "_f".

A coluna mais a direita deste quadro mostra, em percentual, a redução da dimensionalidade de cada base de dados.

A abordagem filter envolve a aplicação de algoritmos específicos de filtragem de atributos.

Estes algoritmos podem ser aplicados individualmente ou por combinação.

A escolha do método de filtragem é um problema em si mesmo.

Neste trabalho, foi feito um estudo sobre a abordagem filter e que consistiu em aplicar sobre a base de dados Arrhythmia algumas combinações de algoritmos implementados na ferramenta WEKA.

O Quadro 7 apresenta as combinações testadas, bem como a eficiência de cada combinação com algumas variantes sobre a mesma base de dados Arrhythmia.

Tais combinações envolveram a geração de subconjuntos de atributos através dos algoritmos BESTFIRST e RANKSEARCH, avaliação da qualidade de atributos selecionados com os algoritmos CONSISTENCYSUBSETEVAL e CFSSUBSETEVAL, e validação do resultado através do algoritmo J48.

A geração de subconjuntos através de RANKSEARCH foi utilizada com a geração de ordens (ranks) através de duas variantes, GAINRATIOATTRIBUTEEVAL e CFSSUBSETEVAL.

Eficácia dos filtros para seleção de atributos sobre a base arrhythmia.

A observação dos valores de taxa de acerto no Quadro 7, indica que as combinações dos filtros CFSSUBSETEVAL/RANKSEARCH(CFSSUBSETEVAL)/J48 e CFSSUBSETEVAL/BESTFIRST/J48 tiveram ambos a maior eficácia em BAGGING e BOOSTING, 84,95% e 85,84% respectivamente.

É importante notar, em particular, que a combinação CFSSUBSETEVAL/BESTFIRST/J48 possui uma complexidade de execução menor, pois não gera um rank de busca.

Dada a eficácia do filtro CFSSUBSET/BESTFIRST/J48, o mesmo foi adotado, neste trabalho, para todas as situações que envolveram a redução da dimensionalidade das bases de dados.

De forma concreta, as bases de dados listadas no Quadro 6 foram obtidas utilizando o filtro CFSSUBSET/BESTFIRST/J48 sobre as bases de dados do Quadro 5.

No decorrer deste capítulo será utilizado BD como o conjunto das bases de dados originais e BDf como o conjunto das bases de dados derivadas por meio do filtro CFSSUBSET/BESTFIRST/J48 (Quadro 8).

O estudo da eficiência dos algoritmos J48, BAGGING e BOOSTING será realizado por meio da geração de várias curvas de aprendizagem sobre as bases de dados dos conjuntos BD e BDf.

As escolhas dos métodos de aprendizagem J48, BAGGING e BOOSTING, basearam-se no desejo de verificar a eficiência, respectivamente, de um método de aprendizagem de máquina (nível 0), que não realiza internamente a combinação de classificadores.

De um método de aprendizagem de máquina (nível 1), que realiza internamente a combinação de classificadores obtidos a partir de amostras de tamanho fixo e de um método de aprendizagem de máquina (nível, que realiza internamente a combinação de classificadores obtidos a partir de amostras, cujos tamanhos variam em função de uma heurística).

A combinação de classificadores deve tornar a aprendizagem mais eficiente, e os métodos BAGGING e BOOSTING são os mais representativos desta classe de métodos.

O processo específico para obtenção das curvas de aprendizagem de cada método sobre as bases de dados dos conjuntos BD e BDf, consiste basicamente em aplicar uma seqüência de procedimentos definidos mais adiante na forma de algoritmos.

Estes últimos são formalizados por três funções, a saber, f, g, h (Algoritmo 4).

A função f recebe como entrada uma base de dados qualquer (ex arrhythmia.arff) e um método de aprendizagem (ex J48), e retorna a taxa de acerto do classificador gerado.
A função g recebe como entrada uma base de dados qualquer (ex arrhythmia.arff), um método de aprendizagem (ex J4e um método de amostragem (ex resample), e retorna um vetor contendo 10 valores reais, onde cada um deles corresponde à taxa de acerto de 10 classificadores obtidos a partir de 10 diferentes amostras da mesma base de dados.

Este algoritmo utiliza internamente o conjunto TA = {10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%}, onde cada elemento ta TA corresponde a um tamanho de amostra.

Cada elemento do vetor retornado corresponde à taxa de acerto do classificador gerado para uma amostra cujo tamanho pertence à TA A função h recebe como entrada um conjunto de bases de dados (ex B, um método de aprendizagem (ex J4e um método de amostragem (ex resample), e retorna uma matriz de valores reais, de ordem (|BD| x |TA|), onde cada linha corresponde ao conjunto dos valores das precisões dos classificadores gerados a partir de diferentes amostras sobre uma mesma base de dados.

Cada linha da matriz corresponde a uma base de dados e cada coluna a uma amostra de tamanho diferente.

A execução completa do experimento, no tocante a geração dos dados para desenhar as curvas de aprendizagem, é realizada por um conjunto de ações executas seqüencialmente (Algoritmo 4).

O programa Estudo Da Curva De Aprendizagem invoca a função h seis vezes.

Cada invocação retorna uma matriz de ordem (|BD| x |TA|), onde cada linha representa uma base de dados e cada coluna uma amostra.

Três matrizes armazenam respectivamente as precisões obtidas pela aplicação da função h sobre as bases de dados do conjunto BD com métodos de aprendizagem J48, BAGGING e BOOSTING.

As outras três matrizes armazenam, por outro lado, as precisões obtidas pela aplicação da função h sobre as bases de dados do conjunto BDf com os mesmos métodos de aprendizagem.

O método de amostragem utilizado é uma implementação do pacote de software WEKA.

Tal implementação corresponde a um filtro supervisionado de instâncias, chamado resample.

Este método de amostragem, quando aplicado sobre uma base de dados, gera uma nova amostra e mantém para esta as mesmas distribuições para cada classe.

O número de exemplos da série de dados a serem amostrados (tamanho da amostr pode ser especificado).

Ele é um parâmetro do algoritmo resample, ou seja, ele especifica o tamanho da série de dados de saída como uma porcentagem da série de dados da entrada.

O Quadro 9 resume o número de classificadores gerados para a primeira parte do experimento-curva de aprendizagem.

O número de classificadores leva em conta que cada método de aprendizagem é aplicado para 10 amostras de cada base de dados, de um total de 30 bases de dados (15 bases sem filtragem de atributos e 15 bases derivadas).

Tem-se assim 300 classificadores para cada método de aprendizagem.

Entretanto, BAGGING e BOOSTING são métodos que combinam internamente certo número de classificadores, ie, um novo classificador a cada iteração do algoritmo.

Para o experimento, o número de iterações foi fixado em 10.

Assim, o número de classificadores gerados pelos métodos BAGGING e BOOSTING deve ser multiplicado por 10.

Número de classificadores do primeiro experimento.

Note-se que este número de 6,300 classificadores não implica no mesmo número de resultados, ou seja, cada um dos métodos irá computar apenas 300 resultados de taxa de acerto, totalizando 900 resultados para os métodos J48, BAGGING e BOOSTING que correspondem aos valores reais encontrados nas seis matrizes de 10x15 elementos do Algoritmo 4.

As curvas de aprendizagem e suas análises são apresentadas na Seção Resultados na forma de quadros detalhados e gráficos com valores médios.

Cada curva é apresentada na forma de gráficos individuais no Anexo A.

Cada gráfico exibe três curvas de aprendizagem para uma mesma base de dados, onde cada uma delas mostrará a eficiência de um dos seguintes métodos, J48, BAGGING e BOOSTING.

De forma mais precisa, o eixo x de cada gráfico indica, em percentuais de 10 em 10 até 100%, o tamanho das amostras de uma mesma base de dados.

Por outro lado, o eixo y indica o valor de taxa de acerto para cada amostra em x.

Temos assim 30 gráficos e 90 curvas.

A análise destes gráficos indica qual método é mais eficiente segundo a taxa de acerto.

Adicionalmente, é possível perceber se a redução da dimensionalidade das bases de dados influencia significativamente na eficiência dos métodos de aprendizagem testados.

Os métodos BAGGING e BOOSTING são exemplos de abordagens que combinam certo número de classificadores na expectativa de obter-se uma melhor eficiência em uma determinada tarefa de aprendizagem.

Esta segunda etapa do estudo experimental consistirá em gerar, para cada base de dados de BD e BDf, um de conjunto valores de taxa de acerto, variando significativamente o número de classificadores (ou iterações), para os métodos BAGGING e BOOSTING.

O interesse aqui é verificar por meio de um conjunto de experimentos e análise estatística dos resultados, qual é o impacto do número de classificadores na eficiência dos métodos BAGGING e BOOSTING.

É importante notar que os conjuntos de classificadores diferem entre si pelo número de iterações que é executado internamente por cada método.

Por esta razão, alguns autores se referem a este tipo de variação como variação do número de iterações.

O processo específico para obtenção dos diversos conjuntos de dados para apoiar o estudo da verificação do impacto do número de classificadores na eficiência dos métodos supracitados, consiste basicamente em aplicar uma seqüência de procedimentos definidos mais adiante na forma de algoritmos.

Estes últimos são formalizados por três funções, a saber, q, r, s (Algoritmo 5).

A função q recebe como entrada uma base de dados qualquer (ex arrhythmia.arff), um método de aprendizagem (ex Bagging), um gerador de amostras (ex resample) e um valor nC indicando o número de iterações (ex 140), e retorna um valor real com a taxa de acerto média de 10 classificadores gerados a partir de dez amostras.

É importante notar que para cada amostra o método de aprendizagem executará nC iterações internas A função r recebe como entrada uma base de dados qualquer (ex arrhythmia.arff), um método de aprendizagem (ex Bagging) e método de amostragem (ex resample), e retorna um vetor com 15 valores reais, onde cada um deles corresponde à taxa de acerto média retornada pela função q.

Este algoritmo utiliza internamente o conjunto NC = {10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200}, onde cada elemento de NC corresponde a um número diferente de iterações passado como parâmetro à função q.

Cada elemento do vetor retornado corresponderá à taxa de acerto de um classificador gerado com um número de iterações pertencente a NC.

A função s recebe como entrada um conjunto de bases de dados (ex B, um método de aprendizagem (ex Bagging) e um método de amostragem (ex resample), e retorna uma matriz de valores reais, de ordem (|BD| x |NC|), onde cada linha corresponde ao conjunto dos valores das precisões de diferentes classificadores gerados a partir de diferentes números de iterações sobre uma mesma base de dados.

Cada linha da matriz corresponderá a uma base de dados e cada coluna a um número de iterações diferente.

Estudo do Impacto do Número de Classificadores.

A execução completa do experimento, face a geração dos dados para avaliar o fator de impacto do número de iterações para os métodos BAGGING e BOOSTING, é realizada por um conjunto de ações descritas algoritmicamente por meio do programa EstudoDoImpactoDonúmero deClassificadores (Algoritmo 5).

Este programa invoca a função s quatro vezes.

Cada invocação retorna uma matriz de ordem (|BD| x |NC|), onde cada linha representa uma base de dados e cada coluna um número de iterações.

Duas matrizes armazenam respectivamente as precisões obtidas pela aplicação da função s sobre as bases de dados do conjunto BD com métodos de aprendizagem BAGGING e BOOSTING.

As outras duas matrizes armazenam, por outro lado, as precisões obtidas pela aplicação da função s sobre as bases de dados do conjunto BDf com os mesmos métodos.

Nesta segunda parte do experimento, o método de amostragem utilizado é o mesmo que foi utilizado na primeira parte do experimento.

Relembrando, este método corresponde a um filtro supervisionado de instâncias, chamado Resample.

Quando aplicado sobre uma base de dados, este método gera uma nova amostra e esta última conserva as distribuições das classes.

O Quadro 10 resume o número de classificadores gerados para a segunda parte do experimento-estudo do impacto do número de classificadores para os métodos BAGGING e BOOSTING.

Número de classificadores.

O cálculo do número de classificadores leva em conta que cada método de aprendizagem é aplicado sobre 10 amostras de cada base de dados, de um total de 30.

Ter-se-ia assim 300 classificadores para cada método de aprendizagem.

Entretanto, BAGGING e BOOSTING são métodos que combinam internamente certo número de classificadores, ou seja, um novo classificador é gerador a cada iteração do algoritmo.

Para este experimento, o número de iterações que varia de 10 em 10 até 100 e de 20 em 20 até 200, totaliza 1350 iterações sobre cada amostra.

Desta forma, o número de classificadores gerados nas iterações deve ser multiplicado por 10, que corresponde ao número de amostras por cada base de dados de um total de 30 bases.

Cabe salientar que apesar do número de classificadores utilizado ser igual a 810,000, o número de resultados de taxa de acerto obtido é de 450 para cada um dos métodos, pois temos 15 variações de classificadores aplicadas a cada uma das 30 bases.

Desta forma, para os métodos BAGGING e BOOSTING totaliza-se 900 resultados (quatro matrizes de 15x15 elementos).

Como anteriormente, os dados obtidos e suas análises são apresentados na Seção Resultados através de quadros detalhados e gráficos com valores médios.

No Anexo B os valores obtidos são apresentados na forma de gráficos individuais.

Cada gráfico exibe quatro curvas para o par de bases de dados correspondendo a mesma base de dados original, sendo uma do conjunto BD e a outra análoga do conjunto BDf.

Para cada uma destas bases análogas temos duas curvas, uma delas mostra a eficiência, quanto ao número de classificadores segundo o método BAGGING, e a outra segundo o método BOOSTING.

De forma mais precisa, o eixo x de cada gráfico indica, o número de iterações/classificadores de 10 em 10 até 100 e depois de 100, de 20 em 20 até 200, para uma mesma base de dados.

Por outro lado, o eixo y indica um valor de taxa de acerto para cada número de iterações em x.

Temos assim 15 gráficos e 60 curvas.

Os resultados desta segunda etapa de experimentos são analisados estatisticamente com base no teste de Friedman para verificar o nível de significância da variação da taxa de acerto segundo o número de classificadores gerados.

Apoiar-se-á sobre a mesma análise estatística para verificar se a diferença encontrada entre os resultados obtidos a partir dos dois conjuntos de bases de dados, BD e DBf, possui relevância numérica.

Este capítulo apresenta os resultados de um estudo experimental que envolve os métodos de aprendizagem de máquina J48, BAGGING e BOOSTING, cuja meta principal é analisar a eficiência destes métodos sobre um conjunto de bases de dados da área de saúde.

Os dados para análise são gerados a partir de dois conjuntos de bases de dados de teste.

O primeiro denominado BD compreende um conjunto de bases de dados da área da saúde.

O segundo denominado BDf possui as mesmas bases de dados de BD, porém com suas dimensionalidades reduzidas por um processo de filtragem de atributos.

Doravante, usar-se-á bases de dados sem seleção e com seleção para referir-se ao conteúdo de BD e BDf, respectivamente.

O restante desta seção se divide em dois momentos.

O primeiro tratará da verificação do método que possui a melhor taxa de acerto isto será feito por meio da análise da curva de aprendizagem para cada método estudado (Seção 4,1).

O segundo momento será dedicado à análise de impacto do número de classificadores na eficiência dos métodos BAGGING e BOOSTING (Seção 4,2).

A análise de eficiência para os métodos de aprendizagem de máquina J48, BAGGING e BOOSTING foi realizada por meio da geração de várias curvas de aprendizagem.

Uma curva para cada método e base de dados, ou seja, cada base de dados foi dividida em dez amostras de tamanhos diferentes e para cada amostra foi aplicado um dos métodos supracitados.

As curvas de aprendizagem foram geradas tanto para as bases de dados de BD (sem seleção de atributo), quanto para as bases de dados de BDf (com seleção de atributo).

Na apresentação a seguir, dessas curvas, manter-se-á esta ordem respectivamente.

As taxas de acerto obtidas nos experimentos estão sumarizados em seis quadros, a saber, Quadro 11 apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método J48 e as bases de dados de BD.

Quadro 1 apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método BAGGING e as bases de dados de BD.

Quadro 1 apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método BOOSTING e as bases de dados de BD.

Quadro 1apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método J48 e as bases de dados de BDf.

Quadro 15 apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método BAGGING e as bases de dados de BDf Quadro 16 apresenta, em percentuais, os valores de taxa de acerto para a curva de aprendizagem gerada para o método BOOSTING e as bases de dados de BDf.

Os valores presentes em cada um dos quadros supracitados correspondem respectivamente as matrizes mTaxadeacertoJ48sem, mTaxade acertoBAGsem, mTaxadeacertoBOOsem, mTaxadeacertoJ48com, mTaxadeacertoBAGcom e mTaxadeacertoBOOcom geradas por meio da execução do Algoritmo (Seção Metodologi).

Todos os resultados apresentados nestes quadros estão detalhados graficamente no Anexo A.

Para facilitar a tabulação dos dados, cada uma das bases recebeu um identificador numérico.

Identificador Numérico das Bases de Dados Originais Como já dito anteriormente, os quadros 11, 1e 1apresentam os dados gerados para o conjunto de bases de dados BD.

Os dados nestes quadros deram origem a 15 gráficos apresentados no Anexo A, sendo um para cada base de dados.

Cada gráfico contém três curvas de aprendizagem, uma para cada um dos métodos de aprendizagem de máquina J48, BAGGING e BOOSTING.

Para quase todas as bases de dados, pôde-se observar que o aumento do tamanho da amostra também influencia no incremento da taxa de acerto.

Entretanto, percebeu-se que, para de 15 bases de dados, a saber, bases 3, 4, 9 e 10 (breast cancer, wisconsin breast cancer, echo cardiogram, heart statlog), a taxa de acerto para as amostras de tamanho 100% foram menores que aqueles obtidos com amostras parciais.

Por exemplo, o método BOOSTING aplicado sobre uma amostra de 20% da base de dados echo cardiogram, assim como o método BAGGING aplicado sobre uma amostra de 10% da base heart statlog, têm-se uma excelente taxa de acerto.

Um exemplo contrário, o método BOOSTING aplicado sobre uma amostra de 20% de cada uma das seguintes bases de dados breast cancer e cleveland14heart disease não tem o mesmo desempenho.

Em geral, observa-se que para quase todas as bases de dados, que existe uma forte variação da taxa de acerto para amostras de diferentes origens.

Portanto, conclui-se que existem amostras de mesmo tamanho que são mais adequadas e outras menos adequadas em função da base de dados.

Percebe-se que o método BOOSTING apresenta as maiores taxas de acerto em 93%, ie, ele foi melhor em 1das 15 bases de dados.

Percebe-se ainda que os métodos BAGGING e BOOSTING foram superiores ao J48 nestas 1bases.

Este resultado não é surpresa, pois os métodos BAGGING e BOOSTING são métodos mais sofisticados e teoricamente deveriam ter uma melhor aprendizagem devido a combinação de classificadores.

Apenas a base de dados 5 (wdb apresentou um comportamento diferente das demais, onde BAGGING foi mais eficiente que o BOOSTING).

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método J48 e as bases de dados de BD.

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método BAGGING e as bases de dados de BD.

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método BOOSTING e as bases de dados de BD.

Cada valor mostrado no gráfico corresponde a taxa média de acerto obtida para todas as amostras de um mesmo tamanho para cada uma das 15 bases.

Este cálculo foi realizado para os três métodos analisados.

Desta forma, cada curva corresponde a dez valores médios para um mesmo método.

Com uma primeira observação deste gráfico percebe-se claramente que os valores médios de taxa de acerto para o método BOOSTING, exceto os casos das amostras de tamanho 10% e 20%, são sempre superiores aos demais.

Os gráficos que mostram os resultados individuais da curva de aprendizagem para cada base estão no Anexo A.

Curva de aprendizagem média para as bases de BD, J48, BAGGING e BOOSTING.

De forma minuciosa, pode-se observar que para o método J48 têm-se alguns picos, por exemplo, para amostras de 10%, 50% e 80%.

Analogamente, têm-se também alguns picos para o método BAGGING para amostras de 10%, 40%, 70% e 100%.

Já para o método BOOSTING, têm-se a partir de amostras de 30% valores médios de taxa de acerto sempre crescentes, em uma escala quase linear.

Mesmo que o método BAGGING tenha bons resultados para pequenas amostras (10% e 20%), observa-se que o método BOOSTING tem uma eficiência em termos de taxa de acerto sempre superior para as demais amostras.

Em termos gerais, o melhor desempenho é do método BOOSTING.

Todavia, não se recomenda desprezar por completo, o método BAGGING que pode apresentar comportamento superior ao BOOSTING para amostras pequenas.

Por esta razão, seria prematuro descartar o método BAGGING da análise de impacto do número de classificadores que será objeto da Seção 4,2.

Curvas de Aprendizagem, Conjunto BDf.

Os experimentos efetuados sobre as bases de dados do conjunto BDf, ie, bases de dados que sofreram uma redução significativa de seus atributos por meio de um processo de filtragem, foram conduzidos de maneira análoga ao que foi executado na seção anterior.

Os quadros 14, 15 e 16 apresentam respectivamente os dados gerados para o conjunto de bases de dados BDf.

Estes dados deram origem a 15 gráficos apresentados no Anexo A, sendo um para cada base de dados.

Cada gráfico contém três curvas de aprendizagem, uma para cada um dos métodos de aprendizagem de máquina utilizados, J48, BAGGING e BOOSTING.

Em geral, pôde-se observar que para bases de dados cujas suas dimensionalidades foram reduzidas, a eficiência do método BOOSTING permaneceu superior aos demais.

Desta forma, a seleção de atributos não altera a hierarquia entre os métodos.

Isto sugere que a eficiência do método, em termos de taxa de acerto, depende fortemente das características próprias de cada base de dados.

Neste sentido, há pouca importância sobre a filtragem ou não de atributos irrelevantes (ou redundantes).

Esta conclusão é importante à medida que a seleção de atributos torna o processo de aprendizagem mais rápido e sem prejuízo significativo da taxa de acerto.

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método J48 e as bases de dados de BDf.

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método BAGGING e as bases de dados de BDf.

Valores percentuais de taxa de acerto para a curva de aprendizagem gerada para o método BOOSTING e as bases de dados de BDf.

Como já dito anteriormente, a eficiência dos métodos sobre as bases de dados de DBf, em termos comparativos manteve-se.

Entretanto, pôde-se observar que a redução do número de atributos diminui a taxa de acerto dos métodos.

Tal diminuição ocorreu para todas as bases de dados de BDf, exceto a base de dados 8 (cleveland14heart disease), onde houve um aumento da taxa de acerto, e da base de dados (wisconsin breast cancer) que, obviamente, não foi afetada, visto que a mesma não sofreu nenhuma redução do número de atributos.

Em praticamente metade dos casos a redução de atributos representou uma pequena perda na taxa de acerto inferior a 2%.

Apenas em um terço dos casos houve uma perda significativa na taxa de acerto (em média 5%).

Este foi o caso, por exemplo, da base 6 (kr vs kp) em todos os métodos onde houve um perda de cerca de 5% e da base1(post operative) no método BOOSTING onde houve uma perda de cerca de 14%.

Pode-se observar que para a base de dados 1a redução de atributos foi semelhante às demais bases.

Por outro lado, para a base de dados 6 a redução de atributos foi bastante significativa, de 37 para 8 atributos.

Esta redução de atributos será provavelmente significativa, posto que o número de instâncias desta base é relativamente grande (3,196).

Em casos assim, o ganho estaria na provável redução do tempo de aprendizagem.

Desta forma, a perda na taxa de acerto de cerca de 5% tende a ser um custo relativamente baixo quando comparado ao ganho do tempo processamento e de memória.

É apresentado os valores médios para os métodos J48, BAGGING e BOOSTING aplicados sobre as bases de dados do conjunto BDf.

Os 15 gráficos com os resultados individuais para cada base, e cuja média está representada no gráfico.

Uma rápida observação do gráfico permite observar claramente que os valores médios de taxa de acerto para o método BOOSTING, superiores aos demais, exceto nos casos das amostras de tamanhos 10% e 70%, onde o método BAGGING apresenta uma ligeira superioridade.

Os gráficos que mostram os resultados individuais da curva de aprendizagem para cada base de dados de DBf também encontram-se no Anexo A.

Curva de aprendizagem média para as bases de BDf, J48, BAGGING e BOOSTING.

De forma pormenorizada, pode-se também observar que para o método J48 tem-se aqui alguns picos, por exemplo, para amostras de 10%, 50% e 100%.

Têm-se também alguns picos para o método BAGGING, onde o destaque é o valor da taxa de acerto média para a amostra de 70% que foi ligeiramente superior ao método BOOSTING.

Este último mantém uma eficiência média superior aos demais, assim como, uma curva de aprendizagem regular com ganhos na taxa de acerto gradativos de acordo com o aumento do tamanho das amostras.

Conforme já observado nos testes para as bases de dados do conjunto BD, o método BOOSTING apresenta a melhor, ou pelo menos equivalente, eficiência em todas as situações.

Porém, para um número razoável de experimentos com diversos tamanhos de amostras pôde-se observar que os valores para o método BAGGING aproximaram-se dos valores encontrados para o método BOOSTING.

Desta forma, na próxima seção será colocado em evidência o impacto do número de classificadores, em termos de taxa de acerto para os métodos BOOSTING e BAGGING.

Nesta seção a análise de eficiência para os métodos de aprendizagem de máquina BAGGING e BOOSTING foi realizada por meio da geração de vários experimentos, variando o número de classificadores para dez amostras de uma mesma base de dados.

Este processo foi realizado tanto para as bases de dados de BD (sem seleção de atributo) quanto para as bases de dados de BDf (com seleção de atributo).

A taxa de acerto obtida nos experimentos estão sumarizadas em quatro quadros, a saber, Quadro 17 apresenta, em percentuais, os valores de taxa de acerto variando o número de classificadores gerados para o método BAGGING sobre as bases de dados de BD.

Quadro 18 apresenta, em percentuais, os valores de taxa de acerto variando o número de classificadores gerados para o método BAGGING sobre as bases de dados de BDf.

Quadro 20 apresenta, em percentuais, os valores de taxa de acerto variando o número de classificadores gerados para o método BOOSTING sobre as bases de dados de BD.

Quadro 21 apresenta, em percentuais, os valores de taxa de acerto variando o número de classificadores gerados para o método BOOSTING sobre as bases de dados de BDf.

Os valores presentes em cada um dos quadros supracitados correspondem respectivamente as matrizes mTaxadeacertoBAGsem, mTaxade acertoBOOsem, mTaxadeacertoBAGcom e mTaxadeacertoBOOcom geradas por meio da execução do Algoritmo 5 (Seção Metodologi).

Os resultados apresentados nestes quadros estão detalhados através de gráficos individuais no Anexo B.

Sobre as taxas de acerto encontradas foi desenvolvida uma análise estatística por meio do teste de Friedman para ambos os experimentos sobre as bases de dados de BD e BDf.

Cabe salientar que o objetivo desta seção não é comparar os métodos BAGGING e BOOSTING entre si, mas determinar o quanto a eficiência de cada um dos métodos individualmente é afetada pelo número de classificadores/iterações.

Desta forma, as próximas subseções apresentam a análise individual destes métodos sobre BD e BDf.

Impacto do Número de Classificadores, Método BAGGING.

Os quadros 17 e 18 apresentam respectivamente os dados gerados para o conjunto de bases de dados BD e BDf.

Estes quadros correspondem respectivamente às matrizes mTaxadeacertoBAGsem e mTaxadeacertoBAGcom geradas a partir da execução do Algoritmo 5 para método BAGGING.

Valores percentuais de taxa de acerto variando o número de classificadores gerados para o método BAGGING sobre as bases de dados de BD.

Valores percentuais de taxa de acerto variando o número de classificadores gerados para o método BAGGING sobre as bases de dados de BDf.

A primeira observação a ser feita é que os resultados encontrados indicam a mesma ordem de grandeza nas diferenças numéricas entre a aplicação dos métodos sobre ambos os conjuntos de bases de dados de BD e BDf.

Desta forma, a seleção de atributos continua tendo pouco impacto na taxa de acerto obtida.

Isto indica que a variação no número de classificadores não é beneficiada ou prejudicada pela seleção de atributos.

Uma segunda observação diz respeito a um possível aumento da taxa de acerto devido ao aumento no número de classificadores.

Num olhar mais minucioso sobre os resultados das bases de dados de BD observa-se que para a maioria das bases (11 delas) houve algum aumento da taxa de acerto, porém insignificante.

Apenas para as bases 1 (arrhythmi e 9 (echo cardiogram) houve um aumento da taxa de acerto acima de 1%.

De forma análoga, pode-se observar um comportamento semelhante para as bases de DBf.

No entanto, para estas bases não houve nenhum caso onde o aumento da taxa de acerto foi superior a 1%.

O Quadro 19 apresenta os resultados do teste de Friedman para o método BAGGING sobre ambos os conjuntos de bases de dados BD e BDf.

Pode-se dizer que os valores apontam para uma progressão numérica da taxa de acerto a medida que aumenta-se o número de classificadores em ambos os conjuntos de dados.

Teste Estatístico de Friedman para BAGGING.

No Quadro 19, temos para cada número de classificadores as médias e desvios encontrados sobre as taxas de acerto para todas as bases de dados, bem como os índices de p-valor inferiores ao nível de significância de 0,05.

Este último valor permite rejeitar estatisticamente a hipótese nula pela qual um valor de taxa de acerto obtido pertence a um mesmo conjunto de dados, ie, admite-se a hipótese alternativa de que existem diferenças relevantes entre os valores.

Nota-se que esta conclusão por si só não permite afirmar uma progressão na taxa de acerto em função do aumento do número de classificadores.

Por outro lado, ela permite afirmar que os conjuntos de valores são de um ponto de vista estatístico, diferentes entre si.

Esta conclusão, somada à observação do aumento numérico da taxa de acerto verificado em algumas bases, permite deduzir que de fato existe uma progressão nos valores.

Note-se ainda que pelos p-valores calculados é possível observar que a variação nas bases de dados de BD é mais significativa (p-valor inferior a 10E-do que a variação observada nas bases de dados de BDf (p-valor inferior a 0,0032).

Impacto médio do número de classificadores para o método BAGGING.

O gráfico mostra as variações médias obtidas para as bases de dados de BD e BDf em cada uma das possibilidades em termos de número de classificadores (eixo horizontal).

Pode-se verificar que a progressão numérica da taxa de acerto, segundo o teste de Friedman, é estatisticamente relevante, apesar da pequena variação da taxa de acerto.

Impacto do Número de Classificadores, Método BOOSTING.

Os quadros 20 e 21 apresentam respectivamente os dados gerados para o conjunto de bases de dados BD e BDf.

Estes quadros correspondem respectivamente às matrizes mTaxadeacertoBOOsem e mTaxadeacertoBOOcom geradas a partir da execução do Algoritmo 5 para o método BOOSTING.

Uma primeira observação dos valores permite verificar que os dados aqui encontrados são semelhantes aos mesmos apresentados pelo método BAGGING.

Em geral, as variações em percentual são numericamente pequenas.

Valores percentuais de taxa de acerto variando o número de classificadores gerados para o método BOOSTING sobre as bases de dados de BD.

Valores percentuais de taxa de acerto variando o número de classificadores gerados para o método BOOSTING sobre as bases de dados de BDf.

Uma análise caso a caso das bases de dados de BD mostra que o método BOOSTING apresenta um aumento na taxa de acerto e este aumento acompanha o número de classificadores em 9 das 15 bases de dados.

Os casos mais significativos são para as bases de dados, 1 (arrhythmi, 7 (pima diabetes), 8 (cleveland14heart disease) e 11 (hepatitis).

Fazendo o mesmo tipo de análise às bases de dados de BDf, verifica-se um resultado distinto.

Apenas a base de dados 1 apresentou um aumento na taxa de acerto significativo, enquanto as bases de dados (audiology), 9 (echo cardiogram), 10 (heart statlog) e 11 (hepatitis) apresentaram uma redução da taxa de acerto com o aumento do número de classificadores.

O teste de Friedman deve então indicar se há significância estatística da variação da taxa de acerto para o método BOOSTING.

O Quadro 2apresenta as médias, desvios e p-valores resultantes do teste de Friedman com nível de significância adotado de 5%.

Teste Estatístico de Friedman para BOOSTING.

Como no caso anterior sobre o método BAGGING, o teste para o método BOOSTING aplicado sobre as bases de dados de BD indica uma significância estatística no aumento da taxa de acerto em decorrência do aumento do número de classificadores (aceitação da hipótese alternativ).

Desta forma, o teste de Friedman rejeita a hipótese nula (p-valor inferior a 10E-5).

Por outro lado, o aumento da taxa de acerto decorrente do aumento do número de classificadores para a aplicação do método BOOSTING para as bases de dados de DBf não rejeita a hipótese nula.

O p-valor obtido é superior a 0,05 (0,19986).

Desta forma, não se pode afirmar que há estatisticamente diferenças significativas nos valores encontrados.

Consequentemente, para o método BOOSTING aplicado as bases de dados de BDf a taxa de acerto não aumenta de acordo com o aumento do número de classificadores.

Impacto médio do número de classificadores para o método BOOSTING.

O gráfico mostra as médias obtidas para as bases de dados de BD e BDf para as diversas configurações de números de classificadores.

A informação visual deste gráfico evidencia a baixa relevância do aumento do número de classificadores na taxa de acerto do método BOOSTING para bases de dados de BDf.

Na área da saúde, a seleção adequada do método de descoberta de conhecimento é essencial.

Em geral, nesta área, as bases de dados possuem um grande número de atributos, um pequeno número de ocorrências e com grande freqüência de valores ausentes.

Desta forma, tem-se um universo complexo em termos do grande número de variáveis e valores ausentes.

Frente a tais características, a utilização de técnica de aprendizagem de máquina baseada na geração e combinação de classificadores mostrou-se uma abordagem promissora.

Além disso, a redução da dimensionalidade por meio da filtragem de atributo também é, em geral, uma solução importante para viabilizar uma tarefa de aprendizagem em um tempo de processamento razoável.

Pôde-se verificar, a partir da geração e análise de várias curvas de aprendizagem, que o método BOOSTING tem uma eficiência superior aos demais, a saber, J48 e BAGGING.

Entretanto, cabe aqui uma ressalva para destacar que para casos pontuais o método BAGGING apresentou uma taxa de acerto semelhante e em raras situações chegou a ser numericamente superior aos resultados obtidos pelo método BOOSTING.

Com relação ao J48, o método BAGGING foi sempre superior.

Em termos mais particulares, para bases de dados sem redução da dimensionalidade (conjunto B a eficiência do método BOOSTING foi mais marcante do que àquela do método BAGGING).

A diferença de taxa de acerto do método BOOSTING para o método BAGGING chegou a ser de até 14%, por exemplo, para base de dados 1(post operative), enquanto que a maior diferença entre ambos para as bases de dados com redução da dimensionalidade (conjunto BDf) foi de 7% para a base dados 9 (echo cardiogram).

Na média, a eficiência do método BOOSTING frente à BAGGING foi de 2,8% para o conjunto BD e 2,2% para o conjunto BDf.

Em resumo, o método BOOSTING foi mais eficiente que os demais métodos em 29 das 30 bases de dados de teste.

Pôde-se observar, por meio da análise das curvas de aprendizagem obtidas, que houve diminuição da taxa de acerto para ambos os métodos em conseqüência da seleção de atributos.

Considerando o universo de bases de dados de BDf, a diminuição da taxa de acerto em todas as bases do experimento e para os três métodos foi em média 1,5%.

A diminuição da taxa de acerto média individual dos métodos foi de 1,3% para J48, de 1,4% para BAGGING e de 1,7% para BOOSTING.

Estes valores mostram uma diminuição da taxa de acerto generalizada para todos os métodos.

Entretanto, pode-se considerar que tal diminuição é relativamente baixa frente aos elevados percentuais de redução do número de atributos após a aplicação de um processo de filtragem.

Dado o fato, que neste trabalho, não foi feita uma análise em profundidade para verificar, se a redução da taxa de acerto dos métodos é compensada pelo ganho de desempenho (tempo de processamento e consumo de memóri em conseqüência da seleção de atributos).

Podemos apenas afirmar, em termos gerais ou por observação, que a seleção de atributos reduz a taxa de acerto dos métodos.

Em suma, a seleção de atributos é recomendada apenas se existe uma necessidade clara em reduzir a dimensionalidade de uma base de dados, por exemplo, para economizar em tempo de processamento em tarefa de aprendizagem.

Em geral, sobre o segundo objetivo desde trabalho, pode-se dizer que o aumento do número de classificadores/iterações para os métodos BAGGING e BOOSTING gera um impacto positivo tanto sobre as bases de dados com seleção como sem seleção de atributos.

No entanto, para o método BOOSTING, verificou-se que o aumento da taxa de acerto não ocorre em 100% dos casos para as bases de dados após a filtragem de atributos.

Em outras palavras, o método BOOSTING aplicado sobre o conjunto de bases de dados BDf não apresentou, estatisticamente, mudança significativa da taxa de acerto quando se aumenta o número de classificadores/iterações.

Isto pode ser concluído pela observação dos gráficos com as médias das precisões obtidas e também pelo teste estatístico de Friedman apresentado.

Para o método BAGGING, apesar de ter sido observado pelo teste de Friedman um aumento estatístico significativo tanto para as bases de dados sem seleção de atributos como para as bases de dados com seleção de atributos, tal evolução é numericamente pequena.

Dentro do escopo da análise aqui desenvolvida, pode-se dizer que para o método BOOSTING sem seleção de atributos, ou para o método BAGGING com e sem seleção de atributos existe um ganho de taxa de acerto com o aumento do número de classificadores.

Em conclusão, recomenda-se a utilização do método BOOSTING sem seleção de atributos e com tantos classificadores quanto possível para aumentar a taxa de acerto obtida.

Obviamente, tal recomendação é válida quando as características da base de dados de treinamento se assemelham aquelas das bases de dados de teste utilizadas no contexto deste trabalho.

É importante relembrar que o presente trabalho não teve por ambição exaurir o tema.

Vários problemas se encontram em aberto e são trabalhos futuros naturais a esta dissertação.

Dentre as diversas possibilidades de continuações sugere-se as seguintes atividades, 1.

A experimentação de outras abordagens e outros algoritmos para seleção de atributos no intuito de verificar, em particular, se os métodos BAGGING e BOOSTING mantém suas eficiências e 2.

A verificação dos resultados de eficiência obtidos frente a outras bases de dados da saúde, tipicamente, bases de dados locais que podem ter características semelhantes ou não às bases utilizadas que são em sua totalidade oriundas de instituições estrangeiras da área da saúde.

