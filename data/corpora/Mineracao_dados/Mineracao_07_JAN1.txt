O ser humano sempre procura mais conhecimento.

Esse é essencial em âmbitos pessoal e também profissional.

Para conseguir mais conhecimento, o ser humano armazena volumosos repositórios de dados, dos quais tem que extrair informação.

Contudo, a quantidade de dados e a complexidade desses podem prejudicar a extração de informação adequada.

Para solucionar tal problema, recorre-se à chamada mineração de dados.

Essa fornece um conjunto de métodos para processamento dos dados e extração de informação.

Dentre tais métodos, está a chamada classificação, de especial interesse para este trabalho.

Existem diversas propostas de algoritmos de classificação.

Algumas são clássicas (bastante conhecidas), como a chamada árvore de decisão.

Outras, assunto principal deste trabalho, são propostas alternativas, baseadas por exemplo em análise formal de conceitos.

Essas ultimas propostas executam a tarefa de classificação por meio de estruturas chamadas reticulados de conceitos e conseguem bons resultados.

Este trabalho apresenta diferentes algoritmos para classificação baseados em análise formal de conceitos, sendo alguns desses propostas inéditas, publicados aqui pela primeira vez.

Tais algoritmos têm boas precisões de classificação, mas apresentam alguns desafios, como os custos computacionais.

Análise formal de conceitos e classificação são os assuntos abordados e combinados por este trabalho.

O primeiro desses assuntos, análise formal de conceitos é originário da matemática e fornece a interessante estrutura chamada reticulado de conceitos (baseada em ordenação parcial), enquanto o segundo, classificação é oriundo da ciência da computação, em particular, da mineração de dados.

Eles são aqui unidos para a tarefa de descoberta de conhecimento.

O problema que este trabalho aborda é, Como empregar análise formal de conceitos para classificação?

Pesquisas em ciência da computação já usam os reticulados de conceitos em tarefas de mineração de dados a maioria preocupa-se com regras de associação (um dos métodos de mineração de dados).

A classificação é também assunto de alguns trabalhos aqui estudados São muitas as motivações para abordar este problema.

Primeiro, o ser humano precisa de informação.

Conforme será mencionado nos próximos capítulos, em muitas situações, o ser humano encontra-se em cenários com excesso de dados (armazenados em volumosos repositórios), porém carentes de informação.

E necessário, portanto, conseguir informação desses dados e, depois, conhecimento baseado na informação.

E também motivação o potencial da análise formal de conceitos em tarefas da ciência da computação.

Tal análise fornece, como já mencionado, os reticulados de conceitos, interessantes estruturas solidamente fundamentadas em matemática discreta, que podem contribuir com métodos já clássicos da mineração de dados.

Por fim, embora muitos estudos em ciência da computação já considerem a análise formal de conceitos, esse assunto é conhecido por poucos e timidamente explorado são raríssimas, por exemplo, as publicações sobre tal assunto em língua portuguesa.

Este trabalho tem dois objetivos principais, estudar e aqui descrever algoritmos para solução do problema proposto, propostas que usem análise formal de conceitos para classificação, propor novo algoritmo para classificação com reticulado de conceitos.

Os dois objetivos enumerados foram cumpridos.

Estudaram-se e codificaram-se em programas Jav quatro algoritmos de classificação com reticulados.

Alguns desses, devido às datas de suas propostas, não usam o reticulado de conceitos, mas um pseudo reticulado.

Foi também proposto e implementado um algoritmo inédito para a mesma tarefa, que conseguiu excelentes resultados.

Escreveram-se programas também para algoritmos clássicos de classificação, árvore de decisão e conjunto de regras, permitindo a comparação entre esses diferentes paradigmas de propostas.

As propostas para classificação aqui abordadas, exceto os métodos clássicos, são os seguintes, "Grand", "Rulearner", "Legal", "Galois", "Similares1", "Similares2".

As duas primeiras propostas usam o pseudo reticulado, enquanto as demais empregam o reticulado de conceitos.

As três primeiras propostas produzem regras de classificação, enquanto as três ultimas classificam usando o próprio reticulado de conceitos.

São, portanto, seis algoritmos similares em alguns pontos, mas que, usando reticulados de conceitos ou pseudo reticulados, executam a classificação de diferentes maneiras.

Importante destacar que os dois ultimos algoritmos são propostas inéditas, na verdade, duas versões de uma nova proposta.

Como será mostrado, os algoritmos para classificação com reticulados têm vantagens e desvantagens, quando comparados à clássica mineração de dados.

Eles conseguem resultados muitas vezes superiores aos métodos clássicos, contudo, tais bons resultados vêm acompanhados de demorados tempos de execução, essa é a principal desvantagem de algoritmos que trabalham com análise formal de conceitos.

Questões como essa são debatidas durante este trabalho, que lança mão de diversos exemplos, a fim de auxiliar no entendimento dos assuntos aqui abordados.

Convencionam-se aqui três importantes e recorrentes termos Dado é apenas um símbolo, armazenado em repositório, como códigos armazenados em computador.

Informação é o dado já interpretado em um contexto, por exemplo, temperatura, em Celsius ou Fahrenheit, dependendo do receptor da informação.

Conhecimento é a informação interpretada em um contexto.

O ser humano, embora possua hoje imensos repositórios de dados, encontra-se muitas vezes desprovido de informação e, consequentemente, também sem conhecimento adequado para tomar decisões, que poderiam ser baseadas naquela informação.

O armazenamento desses grandes volumes de dados aconteceu durante as ultimas décadas, devido aos constantes avanços na informática, como, por exemplo, melhoria da tecnologia de bancos de dados e diminuição dos custos de computadores e relacionados.

Contudo, como os repositórios passaram a ter tamanhos tão imensos e dados complexos, o ser humano não mais conseguiu, com os métodos que até então empregava, extrair informação de suas próprias coleções Dado um cenário onde se tem excesso de dados e carência de informação, tornou-se necessária, portanto, a elaboração de métodos de análise, que recebam como entrada tais dados e produzam informação, a fim de permitir o aumento de conhecimento.

Essa análise não pode ser puramente humana, senão, devido a motivos já mencionados, esse seria um processo muito lento, caro e subjetivo, ou seja, extremamente ineficiente.

Portanto, como os computadores permitiram o armazenamento de tamanhas quantidades de dados, eles que agora executem processos automáticos ou semi-automáticos, para análise de dados e produção de informação.

O chamado KDD knowledge discovery in databases é um conhecido processo para extração de informação em bancos de dados durante tal processo precisa ser correta, inédita, util e compreensível.

O KDD contém diversos passos que primeiro processam os dados de entrada e depois tratam a informação obtida, a fim de permitir aumento de conhecimento.

Entre esses dois conjuntos de passos, existe o passo mais importante neste trabalho, aquele no qual é produzida informação, o passo chamado mineração de dados.

Os passos anteriores à mineração chamam-se pré-processamento (eles preparam a entrad, enquanto os posteriores chamam-se pós-processamento, visualização).

Mineração de dados é, portanto, um importante passo do processo KDD, que recebe como entrada um conjunto lapidado de dados e que produz o tipo de informação desejado naquele momento.

Esse passo contém uma variedade de métodos que são executados de acordo com o interesse de quem executa o KDD, podendo produzir, portanto, informação em diferentes formatos, como regras de classificação, regras de associação, agrupamentos etc.

O método de mineração de dados abordado neste trabalho chama-se classificação.

Para apresentar tal método, é preciso apresentar primeiro o formato de entrada recebido por ele, pois essa contém um aspecto importante.

O método de classificação, assim como os demais, recebe um conjunto composto por objetos e atributos (tais termos são abordados em minúcias na próxima seção), sendo cada objeto formado por valores de atributos.

O que diferencia a classificação dos demais métodos é a presença de um atributo especial.

Doravante, esse atributo será chamado de classe, enquanto os demais serão chamados apenas de atributos.

Do inglês, "descoberta de conhecimento em bancos de dados".

Classificação é um método que aprende uma função, essa, no sentido matemático com valores de atributos em seu domínio e valores de classe em sua imagem.

Em outras palavras, dado um conjunto de valores de atributos, tal função determina um valor de classe para esse conjunto.

Essa função é também conhecida como modelo de classificação e será assim denominada doravante.

Recorre-se ao método de classificação com um dos seguintes propósitos, descrever um conjunto de objetos, mostrando de que maneira os valores de atributos determinam o valor de classe e o que diferencia objetos de classes diferentes, determinar um valor de classe para objetos que tenham esse atributo sem conteúdo.

Este trabalho aborda o segundo propósito apresentado, determinar valores de classe.

São comuns as situações em que uma equipe de pessoas, munidos de uma coleção de objetos, tem que decidir algo que possa ser modelado como uma classe (este trabalho mostra, nas próximas páginas, diversos exemplos de conjuntos assim).

O método de classificação, para determinar valores de classe, tem uma primeira fase, na qual é aprendido o modelo de classificação.

Para tal, usa-se um primeiro conjunto de objetos cujos valores de classe são conhecidos.

Um algoritmo então produz, baseado em tal conjunto, um modelo, que pode ter, por exemplo, o formato de conjunto de regras ou árvore de decisão.

A segunda fase do método de classificação é a operação do modelo de classificação produzido.

Para tal, usa-se um segundo conjunto de objetos, com os mesmos atributos do primeiro conjunto, os objetos têm os mesmos atributos, mas podem ter valores diferentes de atributos, mas com valores de classe desconhecidos.

O modelo então, seja no formato de conjunto de regras ou árvore de decisão, classifica esses objetos, em função de seus valores de atributos.

Depois de aprendido, é interessante que o modelo seja avaliado.

Metodologias de teste e avaliação são mostrados em capítulo futuro, mas adianta-se aqui uma conhecida medida de desempenho, chamada precisão.

Dados um modelo pronto e um conjunto de objetos sem valores de classe, esses objetos podem ser classificados corretamente ou erroneamente por aquele modelo.

Calcula-se então a precisão do modelo de classificação.
O conjunto de entrada para métodos de mineração de dados, embora os repositórios possam ser bastante complexos na prática.

Suas linhas representam objetos, enquanto suas colunas representam atributos, no caso de classificação, uma dessas colunas denota a classe.

As células contêm valores assumidos por objetos, para cada um dos atributos.

O objeto, composto por valores de atributos e classe, representa qualquer entidade existente no universo modelado por aquele conjunto de dados.

Tais entidades geralmente são bastante intuitivas para o ser humano, como perfis de clientes, por exemplo, em um cenário empresarial.

O conjunto de objetos será aqui denominado O, dele se originam O O e O O, subconjuntos usados nas fases de classificação, aprendizagem e operação.

O atributo, como também a classe, é qualquer propriedade cujos valores compõem os objetos.

Convenciona-se aqui que A é o conjunto de atributos da coleção de dados, incluindo a classe, essa é denotada por c A, enquanto B A denota os demais atributos.

Cada atributo, incluindo a classe, possui seu domínio (conjunto de valores), cada objeto pode ter, para cada atributo e para a classe, no máximo um conteúdo, pertencente ao respectivo domínio.

Convenciona-se que A contém a união dos domínios de atributos e classe.

Sendo C domínio da classe e B a união dos domínios dos atributos.

O modelo de classificação é, em outras palavras, uma função que seleciona um elemento de C, baseado em elementos de B, possuídos por um objeto.

Importante destacar que deve ser possível determinar a que atributos referem-se os elementos de A, no caso de valores homônimos de atributos, esses devem ser diferenciados ("atributo1 conteúdo" e "atributoconteúdo", por exemplo).

Quando C contém somente dois elementos, tem-se a chamada classificação binária.

Apesar da simplicidade para se formalizar conjuntos de dados, esses geralmente possuem problemas na prática.

Exemplos comuns de problemas em conjuntos de dados são, anomalias (objetos muito diferentes dos demais ou com valores atípicos para alguns atributos), objetos que, por quaisquer motivos, tenham atributos em branco, inconsistências.
E importante observar que objetos e atributos, assim como outros conceitos neste trabalho, podem ser chamados de outras maneiras na literatura.

Entretanto, primando pela coerência neste texto, convencionam-se aqui tais termos, pois eles são empregados em outros assuntos aqui abordados, por exemplo, consulta a outras fontes para correção do problema.

Como o conjunto pode conter problemas, é necessário que ele seja pré-processado, a fim de se fornecer uma entrada com mais qualidade ao método de mineração de dados.

Alguns exemplos de pré-processamento são seleção de objetos, seja unindo ou removendo alguns dos mesmos, seleção de atributos, correção de valores de atributos (tentando solucionar problemas como valores incorretos ou ausentes), etc.

Por esse ser um extenso assunto, não será detalhado aqui.

E adequado e relevante apresentar aqui um exemplo de conjunto de dados, abordado até então principalmente com formalismos matemáticos.

Representa um conjunto cujos dados descrevem diferentes situações de pacientes em exames oftalmológicos.

O leitor observe a presença de um atributo especial, na ultima coluna, cujos valores são lentes de contato recomendadas, dependendo da situação oftalmológica do paciente.

As linhas são os objetos, o conjunto O contém, portanto, 2elementos.

Já as colunas são os atributos, exceto a primeira (índices de objetos, para auxiliar a referenciar os mesmos) e a ultima (essa é a classe).

O conjunto B contém todos os valores que aparecem nas células dos quatro atributos, enquanto o conjunto C contém três possíveis valores de classe, podem-se recomendar lentes macias, rígidas ou nenhuma lente.

Esse conjunto é idealizado (não acontece na prática, pois além de não apresentar problemas, contém todas as combinações de valores dos quatro atributos).

Os exemplos, durante este trabalho, lançam mão de apenas alguns objetos para concepção do modelo (primeira fase de classificação).

Caso usassem todos, não existiriam objetos inéditos para classificar (segunda fase de classificação).

Em tal subconjunto, encontram-se todos os valores de atributos e de classe, em quantidades equilibradas, procurou-se, portanto, evitar que algum valor fosse muito recorrente, enquanto outro fosse raro.

Conjunto de dados sobre lentes de contato.

Arvore de decisão é um modelo abordado em diversos trabalhos e sua compreensão é bastante intuitiva.

Durante a primeira fase de classificação, constrói-se uma árvore baseada em um conjunto de dados cujos valores de classe são conhecidos.

Cada nó interno representa um atributo, enquanto as arestas que deixam aquele nó representam todos os valores de seu domínio (ou intervalos de valores, dependendo do atributo).

Os nós terminais (também conhecidos como folhas) contêm valores de classe.

O algoritmo para construção da árvore de decisão, cujo pseudo código é mostrado no Algoritmo 1, é recursivo.

Para cada nó gerado, é checado se a recursão pode ser interrompida naquele ramo, em caso positivo, aquele nó torna-se terminal, cujo rótulo é algum valor de classe.

Caso a árvore precise continuar a ser expandida, seleciona-se um atributo para aquele nó, geram-se tantas arestas quanto forem seus valores de domínio e continua-se a recursão.

Existem, no algoritmo apresentado, algumas questões que ganharão aqui mais detalhes, como, por exemplo, a condição de parada, a geração de arestas com valores de atributo, a seleção do atributo para o nó interno.

Existem ainda outras questões merecedoras de maior debate, como o problema da árvore de decisão replicada, quando formam-se sub-árvores iguais, o que demanda uma poda na estrutura.

Contudo, problemas como esse ultimo excedem o escopo do trabalho.

Uma primeira questão quanto ao algoritmo é quando interromper a expansão da árvore de decisão?

A primeira alternativa é cessar a recursão quando todos os objetos que chegam até aquele nó possuírem o mesmo valor de classe ou os mesmos valores de atributo.

E possível também interromper a expansão da árvore quando existir um valor predominante de classe, ou seja, quando uma considerável quantidade (superior a determinado limiar) de objetos que chegam até aquele nó possuir o mesmo valor de classe.

Qualquer que seja a alternativa adotada, o nó em questão torna-se terminal e é depois rotulado com o valor predominante de classe.

Uma segunda questão, Como particionar o domínio de um atributo, a fim de gerar arestas para um determinado nó?

Essa questão parece simples, mas é preciso lembrar que existem atributos cujos domínios podem ser numéricos ou extremamente grandes, inviabilizando, portanto, existir uma aresta para cada valor de atributo.

No caso de atributo numérico ou mesmo categórico, porém de domínio grande, é adequado particionar seu domínio, agrupando seus valores, para que esses grupos formem um número reduzido de arestas.

Tais grupos podem, no caso de atributo numérico, ser entendidos como intervalos de valores de seu domínio.

Por fim, aborda-se aqui a questão, como selecionar um atributo para rotular determinado nó e prosseguir a recursão?

O primeiro critério é não selecionar novamente atributos que já apareçam em nós ascendentes.

E interessante também selecionar um atributo cujas arestas de seus valores de domínio conduzam a filhos chamados puros, ou seja, que não apresentem grande mistura de valores de classe.

A medida de impureza de nós aqui abordada chama-se informação, ela é baseada no cálculo de entropia, as fórmulas mostradas nos próximos parágrafos são baseadas em exemplos publicados na literatura.

Algoritmo 1 pseudo código para construção de árvore de decisão.

Entradas, O, B, B, C (conforme anteriormente definidos).

O leitor suponha que o algoritmo encontra-se no seguinte instante, foi constatado que a recursão deve continuar, sendo necessário, portanto, selecionar um atributo para o nó em questão.

Sabe-se, em tal instante, que o nó considerado apresenta alguma impureza, ou seja, os objetos que o alcançam têm alguns valores iguais de atributos (aqueles já checados em nós ascendentes), mas não têm somente um valor de classe (senão, a recursão seria cessada).

A medida de impureza chamada informação (o leitor observe que essa palavra é aqui empregada em sentido diferente daquele definido no começo do capítulo) é aplicada a qualquer nó da árvore e retorna quanta informação falta para se chegar a um nó terminal.

Tal medida baseia-se na distribuição de valores de classe dos objetos que alcançam aquele nó, quanto mais uniforme for essa distribuição, mais alto o resultado da medida de impureza (nó mais impuro).

Eis a fórmula para cálculo da impureza de um nó, em uma classificação binária (c1 e csão os números de objetos naquele nó, com cada um dos valores de classe).
O algoritmo deve selecionar um atributo que não apareça em nós ascendentes ao nó considerado.

Caso o algoritmo esteja apenas começando a árvore, tratando a raiz, todos os atributos são candidatos a rótulo daquele nó.

Para cada atributo candidato a rótulo do nó em questão, testam-se que nós filhos ele produziria (por meio das arestas referentes a seu domínio) e calcula-se a impureza média desses filhos.

Para um nó com dois filhos, calcula-se a impureza média desses com a fórmula o1, o2, osão, respectivamente, os números de objetos no nó pai e em seus dois filhos, enquanto c1 a, ca, c1 b, cb são as distribuições das duas classes 1 e nos dois filhos a e b.
Calculadas a impureza do nó em questão e a impureza média dos prováveis nós filhos, o algoritmo seleciona o atributo que, por meio das arestas de seu domínio, gere nós filhos menos impuros.

Quando os objetos caminharem do nó pai para os filhos, seguindo as arestas adequadas, ocorrerá diminuição da impureza, ou seja, ocorrerá ganho de informação, pois os nós terminais estarão mais próximos.

A seleção do atributo procura, portanto, maximizar o ganho de informação.

Empregando os mesmos símbolos das fórmulas anteriores, eis como calcular o ganho de informação de determinado nó, com dois filhos e em uma classificação binária.

Mostram-se aqui os primeiros passos para a construção da árvore de decisão.

Como já mencionado, será empregado o subconjunto de objetos para essa construção.

O algoritmo começa checando se a árvore terá nós além da raiz.

A resposta é afirmativa, pois os objetos têm distintos valores de classe.

Calcula-se a impureza do nó raiz e observa-se que essa é máxima, pois os valores de classe encontram-se igualmente distribuídos entre os objetos, dois recomendam lentes macias, dois recomendam lentes rígidas e dois não recomendam quaisquer lentes.

Eis o cálculo de impureza do nó raiz, Como o algoritmo está tratando o nó raiz, todos os atributos são candidatos a rótulo desse nó.

Calcula-se, para cada atributo candidato, a impureza média de seus nós filhos.

E necessário observar que tais cálculos são ponderados pelo número de objetos que chegam a esses nós.

Eis as impurezas médias dos nós filhos, para cada atributo candidato, os números de valores de classes, entre colchetes, referem-se respectivamente a "nenhuma", "rígidas", "macias".
O quarto atributo, se selecionado como rótulo do nó raiz, produziria nós filhos mais puros, comparando-se aos filhos dos demais candidatos.

Os cálculos mostram que tal atributo produziria um descendente onde todos os objetos que nele chegassem teriam os mesmos valores de classe, dois objetos em "nenhuma", além de outro descendente, esse com alguma impureza.

Para decidir essa questão, calcula-se então o ganho de informação, para cada atributo candidato.
O quarto atributo proporciona maior ganho de informação, logo, "lacrimejamento" é escolhido como rótulo do nó raiz.

Geram-se duas arestas, com os valores de tal atributo "reduzido" e "normal".

O algoritmo recomeça, recursivamente, em cada um dos nós filhos.

Será constatado, embora o exemplo termine por aqui, que o nó "reduzido" será terminal e rotulado como "nenhuma", enquanto o nó "normal" continuará expandindo uma subárvore.

Ao fim do algoritmo, será produzida uma árvore de decisão.

Será então o término da primeira fase de classificação, com um modelo pronto para classificar objetos inéditos.

Durante a segunda fase de classificação, objetos caminham pela árvore e nela encontram valores para a classe, que até então eram desconhecidos.

Cada um desses objetos começa seu percurso no nó raiz e, a cada nó interno visitado, confere o atributo ali encontrado como rótulo.

O objeto então continua seu caminho, escolhendo a aresta cujo rótulo corresponda ao seu valor naquele atributo.

Quando o objeto alcança um nó terminal, é classificado com seu rótulo.

Dadas a a árvore de decisão, escolhe-se naquela qualquer objeto, para nessa ser classificado.

Embora conheçam-se os valores de classe de todos aqueles objetos, eles são aqui ignorados, eles serão, na verdade, uteis na checagem de sucesso ou fracasso da árvore de decisão.

Como qualquer objeto pode servir de exemplo, escolhe-se o segundo, O algoritmo primeiro confere, no nó raiz, o atributo "lacrimejamento", como o objeto tem valor "normal" em tal atributo, ele caminha pela aresta de mesmo rótulo.

O algoritmo então confere o atributo "astigmatismo", no próximo nó interno, o objeto caminha pela aresta "não", pois é esse seu valor em tal atributo.

Arvore de decisão sobre lentes de contato.

O objeto alcança um nó terminal e tem sua classe preenchida com "macias".

De fato, "macias" é o valor correto de classe, logo, sucesso!

O modelo de classificação baseado em regras é também bastante simples e conhecido conjunto de regras no formato "se então ".

Esse formato contém o chamado antecedente ("se ") e o chamado consequente ("então ").

O antecedente é um conjunto de valores de atributos (é necessário distinguir a que atributos pertencem tais valores) unidos por conjunções, enquanto o consequente é, no caso de classificação, um valor de classe.

Lêem-se as regras, portanto, do seguinte modo, "se o objeto tem os valores de atributos presentes no antecedente, então seu valor de classe é aquele do consequente".

A relação entre objetos e regras é denominada cobertura.

Dados um objeto e uma regra, se aquele possui todos os valores de atributo presentes no antecedente dessa, afirma-se que a regra cobre o objeto.

E importante destacar que, para existir tal cobertura, o antecedente da regra deve ser subconjunto dos valores de atributos do objeto, mas esse pode conter também outros valores.

Um conjunto de regras pode ser considerado, quanto à cobertura, mutuamente exclusivo ou exaustivo.

No primeiro caso, qualquer objeto deve ser coberto por, no máximo, uma das regras.

Já no segundo caso, qualquer objeto deve ser coberto por, no mínimo, uma das regras.

E desejável que o conjunto de regras produzido na primeira fase de classificação seja mutuamente exclusivo e também exaustivo, mas, como tais propriedades nem sempre são atendidas, é interessante evitar possíveis problemas decorrentes disso.

Em conjuntos de regras não exaustivos, insere-se uma regra com antecedente vazio e consequente padrão, desse modo, no mínimo tal regra cobrirá qualquer objeto.

Para conjuntos de regras não mutuamente exclusivos, ordenam-se as regras e requer-se a leitura na ordem definida, desse modo, no máximo uma regra cobrirá qualquer exemplo.

O conjunto ordenado de regras e com uma dessas padrão é mutuamente exclusivo e exaustivo.

O Algoritmo mostra um simples pseudo código para construção do conjunto de regras.

Esse não é ordenado tampouco tem regra padrão.

O algoritmo procura, a cada valor de classe, produzir regras que cubram o máximo possível de objetos.

Ao fim da execução, todos os objetos são cobertos pelo conjunto de regras produzido.

O leitor considere um valor de classe e os objetos que tenham tal valor (esses chamam-se objetos positivos).

Como o algoritmo seleciona valores de atributos para formar um antecedente, de modo a cobrir o máximo dos objetos positivos?

Para isso, procuram-se valores de atributos que proporcionem maior cobertura, que maximizem.

Mostram-se aqui os primeiros passos para construção do conjunto de regras.

Como já mencionado, será empregado o subconjunto de objetos para essa construção.

O processo começa arbitrariamente com as regras de consequente "Nenhuma".

Para formar o antecedente, analisam-se valores de atributos e suas coberturas, conforme cálculo já mencionado.

As frações abaixo têm, em seus numeradores, número de objetos positivos cobertos por tais valores de atributos, e em seus denominadores, número de objetos cobertos por tais valores de atributos.

O antecedente recebe "Reduzido".

Com esse valor de atributo no antecedente, cobrem-se todos os objetos com valor de classe "Nenhuma" e não é coberto nenhum com outro valor.

Produz-se, portanto a regra, Como foram cobertos todos os objetos positivos e nenhum negativo, o processo agora considera o consequente "Macias".

Analisam-se os valores de atributos para o antecedente, Os valores de atributos "Hipermetropia" e "Não" permitiram as maiores proporções.

Escolhe-se, arbitrariamente, o primeiro desses valores (caso os numeradores fossem diferentes, o maior seria preferível).

Como, com tal antecedente, são também cobertos objetos negativos, é preciso procurar mais valores de atributos.

Continua-se, portanto, a procura, considerando-se, nas frações abaixo, apenas os objetos com valor "Hipermetropia".

Adiciona-se "Não" ao antecedente.

Com tal antecedente, cobrem-se todos os objetos com valor "Macias" e nenhum negativo.

Produz-se, portanto a regra, O processo com o consequente "Rígidas" é muito similar ao ultimo descrito, portanto, não será aqui narrado.

Ao fim da primeira fase de classificação, tem-se o conjunto de regras.

Conjunto de regras sobre lentes de contato.

Na segunda fase de classificação, objetos têm seus valores de classe, até então desconhecidos, determinados pelo conjunto de regras.

Cada objeto é classificado segundo os consequentes das regras que o cobrem.

Para evitar conflitos entre consequentes diferentes, é desejável, como já mencionado, que o conjunto de regras seja mutuamente exclusivo e exaustivo.

As regras aqui produzidas têm ambas as propriedades.

Dados a o conjunto de regras, escolhe-se naquela qualquer objeto, para nesse ser classificado.

Escolhe-se, arbitrariamente, o quarto objeto. O objeto é coberto pela ultima regra e, portanto, corretamente classificado como "Rígidas".

Análise formal de conceitos é um ramo da matemática aplicada, particularmente da denominada teoria de reticulados como conjuntos parcialmente ordenados, com propriedades descritas durante este capítulo.

Um interessante modo de começar o estudo da análise formal de conceitos é segmentando seu próprio nome, "análise" sugere observação e manipulação de dados fornecidos, "conceitos" determina unidades segundo as quais os dados são estruturados, correspondentes à interpretação humana da realidade, adiante serão apresentados os conceitos formais, "formal" sugere fundamentação matemática referente a análise e aos conceitos.

Este capítulo apresenta análise formal de conceitos, baseado em trabalho de seus criadores Este capítulo, em diversos momentos, requer do leitor conhecimento de matemática discreta, em especial, noções de ordenação parcial.

Exemplos são usados de modo a auxiliar no entendimento de formalismos matemáticos.

O capítulo primeiro aborda os chamados contextos formais, depois conceitos formais e, por fim, apresenta reticulados de conceitos, além de mencionar pseudo reticulados.

Contexto formal mono-valorado é definição primordial para o estudo da análise formal de conceitos.

Tal contexto tem a notação (O,A,R), sendo O e A conjuntos contendo elementos respectivamente denominados objetos e atributos e sendo R O × A uma relação binária chamada incidência.

Todo elemento da incidência tem a notação oRa, uma relação entre objeto e atributo, lida como "o objeto o tem o atributo a".

Para quaisquer subconjuntos E O e I A, podem ser determinados seus conjuntos derivados (que respectivamente são os atributos comuns aos objetos e os objetos que possuem os atributos), por meio das operações de derivação, A chamada tabela cruzada é uma maneira adequada de representar contextos formais mono-valorados.

As linhas são objetos e as colunas são atributos.

A incidência é representada por algum símbolo que indique existir relação entre objeto e atributo.

Contextos formais mono-valorados representam bem conjuntos cujos objetos apenas têm ou não atributos, ou seja, cuja relação entre esses dois elementos é "sim ou não".

Contudo, os atributos de conjuntos de dados usados na prática costumam possuir diversos valores.

E necessário, portanto, definir contexto formal multi-valorado.

Esse tem a notação (O,A,A,R).

O, A e A são conjuntos de objetos, atributos e valores de atributos, respectivamente.

R O × A × A é, como mostra a notação, uma relação ternária entre esses conjuntos.

Todo elemento o,a, R é lido como "o atributo a tem o valor b para o objeto o".

A conversão de contexto formal multi-valorado para mono-valorado é necessária, para adequá-lo ao estudo da análise formal de conceitos.

Essa conversão acontece por meio da chamada escala conceitual.

Existem diferentes escalas, mas a que pertence ao escopo deste trabalho é a chamada nominal.

Em tal escala, os valores de atributos do contexto formal mono-valorado tornam-se, no multi-valorado, atributos.

Existe, nesse ultimo contexto, relação entre objeto e atributo quando essa também existir, no primeiro contexto, entre objeto e valor de atributo.

Importante destacar que atributos numéricos no contexto formal multi-valorado precisam ser primeiro organizados em intervalos, para depois passarem pela escala nominal.

Doravante, quando este trabalho mencionar contextos formais multi-valorados, será presumido, mas não explicitado, que foi executada a escala nominal, sempre que necessária.

O conjunto da ossui objetos, atributos e valores para esses.

Pode ser considerado, portanto, um contexto formal multi-valorado (O,A,A,R),com os seguintes conjuntos, Tal conjunto pode ser convertido para um contexto formal mono-valorado, por meio de uma escala nominal.

Os valores de atributos do contexto de origem tornam-se, portanto, atributos no contexto de destino.

A ostra o contexto formal mono-valorado (O,A,R).

Suas linhas são objetos, suas colunas são atributos e existe relação de incidência em células marcadas com ×.

Como não existem, neste exemplo, atributos numéricos no contexto de origem, a conversão ocorre diretamente.

E necessário mencionar que, caso existissem valores de atributos homônimos, esses deveriam ser diferenciados no contexto de destino, produzindo nesse atributos distintos.

Doravante, será suprimido o uso das palavras mono-valorado e multi-valorado, restando apenas contexto formal.

Este exemplo será empregado durante todo o trabalho, tratado como (O,A,R) ou (O,A,A,R).

Quando for usada essa ultima notação (pois, em muitos exemplos, é preciso distinguir atributos e seus valores), não será mencionada a escala nominal, mas, sempre que necessário, entende-se que essa foi aplicada.

O leitor observe que os elementos do conjunto A podem ser chamados de atributos ou de valores de atributos, dependendo do tipo de contexto formal em questão atributos para monovalorado, valores de atributos em caso contrário.

Contexto formal sobre lentes de contato.

Um contexto formal (O,A,R) determina conceitos formais, cada um com notação (E,I).

O conjunto dos objetos do conceito formal é denominado extensão e o dos atributos, intensão.

Cada elemento da extensão possui todos os da intensão, e é correta a afirmação análoga para a intensão em relação à extensão.

Existem algoritmos para encontrar todos os conceitos formais de um contexto formal, mas esses não são aqui abordados, a próxima seção apresenta reticulados de conceitos e nele, mostra-se um algoritmo que, para produzir tais reticulados, encontra os conceitos formais.

Eis alguns exemplos de conceitos formais (E,I) do contexto formal (O,A,R) da O leitor confirme que, em todos esses exemplos, cumprem-se as propriedades.

Em outros termos, as extensões contêm objetos, as intensões contêm atributos e, mais interessante, cada elemento das extensões possui todos os de suas intensões e vice-versa, como pode ser checado no contexto formal.

Quando o conjunto de todos os conceitos formais de um contexto formal é hierarquicamente ordenado, recebe a denominação de reticulado de conceitos.

Seus conceitos formais se relacionam como (E,I) (E,I), quando E E e I I, sendo (E,I) chamado subconceito e (E,I) chamado superconceito.

Para o leitor mais interessado em formalismos matemáticos, apresenta-se aqui o reticulado de conceitos de outra maneira.

Os conjuntos-potência P(O) e P(A) são parcialmente ordenados segundo o operador.

Graças à chamada conexão de Galois, é possível produzir o reticulado de conceitos, contendo as duas ordens em uma estrutura.

A conexão de Galois são mapeamentos, P(O) P(A) e P(A) P(O), no caso da análise formal de conceitos, tais mapeamentos podem ser as operações de derivação, de modo que, para quaisquer O,O P(O).
Tão adequado quanto representar um contexto formal por meio de uma tabela cruzada, é representar um reticulado por meio de um diagrama.

O diagrama representa o reticulado como um grafo, cujos vértices denotam conceitos formais e cujas arestas denotam suas relações(E,I) (E,I).

Quando dois conceitos formais se relacionam como subconceito e superconceito sem que haja qualquer outro conceito formal entre ambos, seus vértices devem ser conectados por uma aresta no diagrama.

O vértice mais alto do diagrama representa o conceito formal cuja extensão contém todos os objetos, enquanto o mais baixo contém todos os atributos em sua intensão.

Para tornar mais confortável e eficiente a leitura de um diagrama, extensões e intensões não precisam ser escritas por completo.

Nomes de objetos e de atributos são escritos no diagrama somente uma vez.

Desse modo, os objetos têm seus nomes escritos no vértice mais baixo em que primeiro ocorrem, enquanto os nomes dos atributos são escritos no vértice mais alto em que primeiro ocorrem.

Todos os atributos possuídos por um objeto (além dos escritos no rótulo de seu vértice) podem ser encontrados nas intensões dos conceitos superiores alcançados pelo vértice daquele objeto.

Desse modo, o aspecto mais importante no diagrama é sua estrutura em níveis, ou seja, as alturas dos vértices devem ser consideradas, pois determinam subconceitos e superconceitos.

O contexto formal (O,A,R) da roduz muitas dezenas de conceitos formais, inviabilizando, devido ao espaço requerido, mostrar aqui seu reticulado de conceitos.

Considera-se aqui, portanto, o subconjunto de objetos {01,08,11,14,20,22}.

Mostra o reticulado de conceitos produzido, em formato de diagrama.

Rótulos de objetos aparecem abaixo dos vértices, enquanto os de atributos aparecem em cima.

Cada vértice do diagrama representa um conceito formal.

Quando conectados por aresta, dois conceitos formais são subconceito e superconceito diretos.

Como mencionado nesta seção, o diagrama tem rótulos em modo reduzido, ou seja, não Reticulado sobre lentes de contato.

Escrevem-se extensões e intensões por completo.

De qualquer modo, essas podem ser inferidas para qualquer conceito formal.

Considerando, por exemplo, o conceito formal de rótulo "Reduzido, Nenhuma", sua extensão é {01, 11} (objetos de vértices inferiores) e sua intensão é {Miopia, Reduzido, Nenhuma} (atributos de vértices superiores).

De fato, se consultado o contexto formal, constata-se que tais objetos têm tais atributos em comum e vice-versa (tais atributos são compartilhados por tais objetos).

Dado um conjunto de conceitos formais de um reticulado, ínfimo e supremo são respectivamente o maior subconceito e o menor superconceito comuns a todos os elementos de tal conjunto.

As definições de maior e menor, dentro do escopo de reticulados, dizem respeito à ordenação hierárquica.

Em outras palavras, o primeiro vértice no diagrama no qual se cruzam os caminhos de determinados conceitos formais é chamado ínfimo, se o caminho for para baixo, ou supremo, se o caminho for para cima.

O teorema básico de reticulados de conceitos aborda ínfimo e supremo de conceitos formais, cujos índices estão em T.
Todo reticulado de conceitos possui um vértice superior a todos e outro inferior também a todos, por esse motivo, tal reticulado é completo.

Concluindo o assunto de reticulados de conceitos, o Algoritmo um pseudo código para construção de tais estruturas.

Algoritmo pseudo código para construção de reticulado de conceitos.

Entradas, contexto formal (O,A,A,R).

Esse algoritmo constrói o reticulado de conceitos em níveis.

Ele produz o primeiro conceito formal, seus subconceitos e as arestas necessárias.

Depois, para cada conceito formal, o processo é repetido, produzindo-se mais subconceitos e mais arestas.

A operação para produzir subconceitos de (E,I) é a seguinte, para todo atributo x não presente em I, produz-se um candidato ((I {x}),(I {x})), dentre tais candidatos, retornam-se os verdadeiros subconceitos.

Esse algoritmo tem, no pior caso, complexidade.

Para cada conceito formal (daí o |conceitos|), é preciso produzir seus subconceitos e percorrer os mesmos.

Dessas duas operações, a primeira é mais onerosa.

Para produzir subconceitos, recorre-se aos operadores de derivação (daí o |O||A|), no máximo |A| vezes (para todo atributo x não presente em I, conforme descrito no parágrafo anterior).

E interessante mencionar que o máximo número de conceitos formais no reticulado de um contexto formal (O,A,R) é 2, o reticulado de conceitos cresce, portanto, exponencialmente, dependendo da incidência do contexto formal.

Conclui-se esta seção com o chamado pseudo reticulado.

Esse tem estrutura similar ao reticulado de conceitos, mas é anterior à proposta da análise formal de conceitos.

Tal assunto é relevante neste trabalho, pois alguns algoritmos do capítulo seguinte, por questão histórica, adotam tal estrutura.

O pseudo reticulado, conforme descrito na literatura, tem algumas diferenças em relação ao reticulado de conceitos.

Ele é também representado por diagrama, mas, como os vértices podem não ser conceitos formais (tais como descritos aqui), são denominados apenas nós.

O pseudo reticulado contém os seguintes nós (que costumam ter apenas as intensões escritas em rótulos, ignorando-se as extensões),nós-atributo contêm somente um elemento na intensão e são os mais superiores na estrutura, nós objeto correspondem aos conceitos formais cujos rótulos reduzidos contêm objetos e são os mais inferiores na estrutura, nós intermediários estão entre nós objeto e nós atributo.

Como já mencionado, tais nós não são sinônimos de conceitos formais.

Alguns vértices do pseudo reticulado são somente nós, enquanto alguns conceitos sequer figuram em tal estrutura.

Nós atributo nem sempre são conceitos formais, mas os demais sempre o são.

O primeiro conceito formal, ou seja, (O,O), aparece no pseudo reticulado somente se existir, no contexto formal, o chamado atributo universal (aquele tido por todos os objetos).

O ultimo conceito formal, ou seja, (A,A), aparece no pseudo reticulado se, em situação análoga, o contexto formal contiver o chamado objeto universal (aquele que possui todos os atributos).

O contexto formal (O,A,R) da roduz, para os objetos {01,08,11,14,20,22}, o pseudo reticulado mostrado.

Tal estrutura também é escrita em modo reduzido, com os atributos aparecendo apenas uma vez (primando pela clareza, são também mostrados os objetos em rótulos).

Pseudo reticulado sobre lentes de contato.

Os nós atributo são aqueles cujos rótulos têm atributos escritos, dentre tais nós, os de rótulos "Reduzido", "Nenhuma", "Macias", "Rígidas" não são conceitos formais.

Os nóso bjeto são aqueles cujos rótulos têm objetos escritos, todos são conceitos formais.

Os demais nós também correspondem a conceitos formais.

O leitor observe a ausência do primeiro e ultimo conceitos formais, pois não existem objeto e atributo universais.

O Algoritmo reticulado.

Ele primeiro produz todos os nós-atributo, depois, para cada nó-objeto, checa a necessidade de novos nós, calculando a interseção da intensão do nó-objeto com as demais.

O pseudo código não explicita a produção de arestas, mas esse é um processo simples primeiro, conectam-se os nós àqueles com elementos em comum na intensão, depois, removem-se as arestas redundantes, ou seja, aquelas com nós não diretamente superiores e inferiores.

Algoritmo Pseudo código para construção de pseudo reticulado.

Entradas, contexto formal (O,A,A,R).

Resultado, pseudo reticulado.

Apresentam-se aqui propostas que executam o método de classificação, baseada na análise formal de conceitos.

Tal assunto tem seus fundamentos teóricos apresentados em capítulos anteriores.

Embora tais capítulos já tenham formalizado notações para diversos elementos, enumeram-se essas aqui novamente, pois continuarão a ser usadas, O é o conjunto de objetos, as entradas das fases de classificação são O O (primeira fase) e O O (segunda fase).

A é o conjunto que se particiona em atributos B e classe {c}.

A é o conjunto particionado em domínios dos atributos e domínio da classe.

B A contém os valores (domínios) de atributos e C A, os valores (domínio) da classe.

Apresentam-se aqui seis propostas, as quatro primeiras já foram publicadas na mesma intuição, foram elaboradas durante este trabalho.

Duas dessas propostas empregam o pseudo reticulado, enquanto o reticulado, tal como formalizado pela análise formal de conceitos, é a estrutura usada nos demais algoritmos.

Algumas dessas propostas trabalham com regras, mas outras usam o reticulado para classificar.

O capítulo dedica uma seção para cada proposta, a seção 41 apresenta o algoritmo "Grand", 4descreve o chamado "Rulearner", o algoritmo "Legal" é tema da seção 43, "Galois" é assunto de 44, e, por fim, as seções 45 e 46 apresentam os inéditos "Similares1" e "Similares2".

Após descrever os algoritmos (primeira e segunda fases de classificação), as seções contêm exemplos de classificações bem e mal-sucedidas.

O algoritmo "Grand" a mais antiga das propostas aqui apresentadas e seu funcionamento é bastante intuitivo.

Ele começa a primeira fase de classificação construindo um pseudo reticulado (o leitor observe que não se emprega aqui o reticulado da análise formal de conceitos) para o contexto formal (O,A,A,R).

O algoritmo considera, como mostra a notação do contexto formal, a classe e seu domínio, além dos atributos e seus valores.

Grand produz regras de classificação baseadas no pseudo reticulado.

Uma vez pronta tal estrutura, o algoritmo nela encontra os nós classe de intensões classe C e depois processa seus nós inferiores (não apenas imediatamente inferiores) de intensões valores A.

Para cada nó-classe e para cada nó inferior seu, produz-se uma regra com valores \ {classe} no antecedente e classe no consequente, se respeitadas as condições, classe(valores{classe}) e valores for minimal.

Em outros termos, "Grand" produz regras que, com o mínimo de elementos em seus antecedentes, cubram o máximo de objetos.

Procurando por nós descendentes de nós classe com intensões valores minimais, encontram-se os filhos desses nós classe.

Adicionando a condição classe (valores{classe}), garante-se que as regras produzidas são corretas, pois todos os objetos com valores{classe} têm também o valor classe.

Essa segunda condição também faz, caso os filhos de nós classe não atendam a mesma, a pesquisa continuar estrutura abaixo, à procura de nós com intensões minimais e que produzam regras corretas.

O Algoritmo 5 mostra o pseudo código da primeira fase do "Grand".

Depois de pronto o pseudo reticulado, construído conforme o já apresentado Algoritmo 4, checam-se os filhos dos nós classe.

Caso tais filhos não produzam regras corretas, é necessário continuar, como já mencionado, a pesquisa pela estrutura.

Quando se produz regra baseada em algum nó, a pesquisa não continua em seus filhos.

É importante ter cuidado, quando programando tal algoritmo, para não se visitar repetidamente os nós, tarefa desnecessária e extremamente onerosa (por isso a expressão "não visitados" aparece no pseudo código).

O pseudo código contém um teste condicional, no qual é checado se o nó analisado pode produzir regra correta.

Entretanto, na prática, tal trecho demanda mais linhas de código fonte.

Dado o nó analisado em tal trecho, é preciso remover de sua intensão o valor de classe, derivar esse conjunto (obtendo objetos) e depois derivar novamente (obtendo valores de atributos), isso para checar uma das condições aqui apresentadas o valor de classe deve pertencer ao conjunto resultante das duas derivações.

Tal Algoritmo 5 pseudo código da primeira fase do algoritmo "Grand", entradas contexto formal (O,A,A,R).

O processo mostra que, embora use um pseudo reticulado (cujos nós não armazenam extensões), o algoritmo "Grand" ainda precisa ter acesso ao contexto formal, para executar as operações de derivação.

Após a construção do pseudo reticulado e do conjunto de regras, o algoritmo "Grand" executa a segunda fase de classificação.

Dado, como entrada, um contexto formal (O,A,A,R) cuja tabela tenha apenas células em branco para os valores de classe, procuram-se regras que cubram esses objetos, classificando-os.

Esse processo é simples, similar à tradicional classificação baseada em regras.

Existem aqui, como no método clássico de classificação baseada em regras, dois problemas que merecem destaque, um objeto pode não ser coberto por nenhuma regra, ou, pelo contrário, mais de uma regra pode cobrir algum objeto.

Grand sugere, para o primeiro problema, classificar o objeto com o valor de classe mais votado, ou seja, o consequente mais frequente em regras que cubram aquele objeto.

Para o segundo problema, o objeto não é classificado.

O algoritmo "Grand" é executado para o contexto formal (O,A,A,R)0, considerando-se c ="Lentes".

A primeira fase do algoritmo começa construindo o pseudo reticulado para o contexto formal (O,A,A,R), onde O = {01, 08, 11, 14, 20, 22}.

Continuando a primeira fase, começa-se a fase de construção do conjunto de regras.

Encontram-se os nós classe {Nenhuma}, {Macias}, {Rígidas}.

Checam-se seus filhos, cujas intensões são {Miopia, Reduzido, Nenhuma}, {Hipermetropia, Não, Normal, Macias}, {Sim, Normal, Rígidas}.

A pesquisa é interrompida, pois todos esses nós produzem regras corretas.

Conjunto de regras produzido pelo algoritmo "Grand".

Concluída a primeira fase, deseja-se executar a fase seguinte, classificando o conjunto O = {03, 04, 06}.

O objeto "03", coberto pela primeira regra, é classificado como "Nenhuma", o objeto "04" é classificado como "Rígidas", pois é coberto pela terceira regra, por fim, o objeto "06", coberto pela segunda regra, é classificado como "Macias".

Todos esses objetos são corretamente classificados.

O algoritmo "Grand", em sua primeira fase, constrói o pseudo reticulado para o contexto formal (O,A,A,R) (baseado em (O,A,A,R).

A primeira fase depois constrói o conjunto de regras.

A segunda fase classifica o conjunto.

O objeto "02" não é coberto por nenhuma das regras e, por isso, não pode ser classificado.

A terceira regra cobre o objeto "16" e o classifica como "Rígidas", contudo, seu valor correto de classe seria "Nenhuma".

Por fim, o objeto "24", cujo valor correto de classe também seria "Nenhuma", é erroneamente classificado como "Rígidas" também pela terceira regra.

Esses são exemplos de classificações mal-sucedidas.

O algoritmo "Rulearner" também usa um pseudo reticulado (o leitor novamente observe que não se trata do reticulado da análise formal de conceitos) para produzir regras de classificação.

Duas primeiras diferenças que se observam nesse algoritmo são, primeiro, o fato dele ignorar valores de classe na construção do pseudo reticulado e, depois, o fato do algoritmo demandar um parâmetro de entrada.

A primeira fase de "Rulearner", embora diferente do algoritmo anterior, baseia-se na mesma estratégia, produzir regras que possuam poucos atributos e cubram muitos objetos, preferindo, portanto, nós mais ao topo do pseudo reticulado.

Procuram-se, para isso, nós que possuam, dentre seus descendentes, o máximo de nós-objeto, contanto que esses tenham algum valor predominante de classe, daí a necessidade do parâmetro, determinar tal predominância.

O Algoritmo 6 mostra o pseudo código da primeira fase de "Rulearner".

As entradas são o contexto formal (O,A,A,R) e o parâmetro de impureza.

O algoritmo ignora, durante a construção do pseudo reticulado, a classe e seu domínio, como se esses não pertencessem ao contexto formal.

O parâmetro de impureza é detalhado a seguir.

As saídas da primeira fase são o pseudo reticulado e o conjunto de regras.

Algoritmo 6 pseudo código da primeira fase do algoritmo "Rulearner".

Entradas, contexto formal (O,A,A,R), parâmetro de impureza.

Resultados, pseudo reticulado da entrada, conjunto de regras.

Montar pseudo reticulado do contexto formal (O,B,B,R) marcar nós do pseudo reticulado como ativos rotular nós do pseudo reticulado, usando parâmetro de impureza O pseudo código primeiro constrói o pseudo reticulado, usando, para isso, o Algoritmo 4.

Uma vez pronta tal estrutura, marcam-se todos seus nós como ativos.

Apenas nós ativos podem produzir regras, quando inativos, eles são ignorados em muitos passos do algoritmo (como se, a grosso modo, eles não mais existissem).

Depois de ativados, os nós são rotulados com valores de classe ou como impuros, usando o parâmetro fornecido como entrada.

Para entender os rótulos dos nós, é importante primeiro definir alguns termos adotados nesse algoritmo.

Dado qualquer nó do pseudo reticulado, seus descendentes são os nós inferiores por ele alcançáveis, por caminhos de arestas.

Definem-se ascendentes analogamente.

Importante comentar que descendentes e ascendentes de um nó incluem ele próprio.

Por fim, define-se cobertura de um nó como a quantidade de nós-objeto presente em seus descendentes.

Embora cobertura seja uma palavra já empregada para regras de classificação, ela é também definida para nós do pseudo reticulado, pois, como será mostrado, tais nós podem tornar-se regras (mantendo coerente o emprego de tal palavra).

Os nós são, como mencionado, rotulados com valores de classe ou como impuros.

Nós não-impuros são aqueles que possuem, dentre seus descendentes, uma quantidade considerável de nós-objeto com mesmo valor de classe, os não-impuros têm como rótulo tal valor predominante de classe.

Já com nós impuros, seus nós-objeto descendentes não definem um valor predominante de classe.

O parâmetro de impureza, recebido como entrada, controla essa predominância, ele determina a porcentagem tolerada de outros valores de classe, dentre os nós-objeto descendentes.

Observa-se então que, embora ignore a classe e seus valores para construir o pseudo reticulado, o algoritmo precisa dos mesmos para rotular os nós, acessando, para isso, o contexto formal.

Com nós ativados e rotulados, o algoritmo encontra aquele não-impuro de maior cobertura, para produzir cada regra.

O nó escolhido fornece sua intensão como antecedente da regra e seu rótulo (um valor de classe) como consequente.

Caso mais de um nó não-impuro possua a maior cobertura, prefere-se aquele cuja intensão é menor.

Com tais estratégias, produzem-se regras que, com poucos atributos (menor tamanho de intensão), cubram muitos objetos, maior cobertura.

Após produzir cada regra, o algoritmo desativa alguns nós do pseudo reticulado.

Encontram-se primeiro os nós-objeto descendentes do primeiro nó (aquele que deu origem a regra).

Encontram-se depois os ascendentes de tais nós-objeto, decrementando em um suas coberturas, desativam-se os ascendentes cujas coberturas chegarem a zero.

Desativam-se, por fim, os nós-objeto em questão, para que não sejam considerados na procura por próximas regras.

A segunda fase de classificação de "Rulearner" é idêntica à do algoritmo anterior, procuram-se regras que cubram os objetos de O, para que esses sejam classificados.

Exemplo 11, "Rulearner" é executado para o contexto formal (O,A,A,R), considerando-se c ="Lentes", e para um parâmetro de impureza de 20% (ou seja, requer-se que, no mínimo, 80% de nós-objeto votem em um mesmo valor de classe, para produzir regras).

A primeira fase começa construindo o pseudo reticulado para o contexto formal (O,B,B,R), onde O = {01, 08, 11, 14, 20, 22}.

Essa estrutura é mostrada na pseudo reticulado produzido pelo algoritmo "Rulearner".

Descreve-se aqui, a título de exemplo, a produção de uma das regras (mencionam-se os detalhes julgados relevantes).

Procura-se primeiro o nó não-impuro com a maior cobertura, como existem quatro não-impuros com cobertura aqueles de intensões {Reduzido}, {Hipermetropia, Não, Normal}, {Sim, Normal}, {Miopia, Reduzido}, prefere-se o nó com menor tamanho de intensão de intensão {Reduzido} e rótulo "Nenhuma".

Produz-se então a regra "Reduzido Nenhuma".

Desativam-se depois os nós-objeto descendentes de intensões {Juventude, Miopia, Não, Reduzido} e {Pré-presbiopia, Miopia, Sim, Reduzido} e decrementam-se as coberturas de seus ascendentes,esses não são aqui enumerados, pois isso não traria informação relevante.

O algoritmo continua produzindo outras regras e, após seu término, tem-se o conjunto de regras.

Conjunto de regras produzido pelo algoritmo "Rulearner".

Concluída a primeira fase, executa-se a segunda, para os objetos O = {03, 04, 06}.

O objeto "03", coberto pela primeira regra, é classificado como "Nenhuma", o objeto "04" é classificado como "Rígidas", por ser coberto pela terceira regra, o objeto "06" é classificado como "Macias" pela segunda regra.

Todos esses exemplos foram corretamente classificados.

O algoritmo "Rulearner", em sua primeira fase, constrói o pseudo reticulado para o contexto formal (O,B,B,R) (baseado no contexto (O,A,A,R), considerando-se O = {01, 08, 11, 14, 20, 22} e c ="Lentes"), com um parâmetro de impureza de 20%.

A primeira fase depois constrói o conjunto de regras.

A segunda fase classifica o conjunto.

Como no algoritmo da seção anterior, esses são, aqui também, exemplos de classificações mal-sucedidas.

O objeto "02" não é classificado, pois não é coberto por nenhuma regra.

O objeto "16", cujo valor correto de classe seria "Nenhuma", é classificado como "Rígidas" pela terceira regra.

O objeto "24", também coberto pela terceira regra, é classificado como "Rígidas", no entanto, "Nenhuma" seria o correto.

O algoritmo "Legal" tice" trabalha com um reticulado (não mais um pseudo reticulado) e produz regras baseadas em tal estrutura.

A grande vantagem de tal proposta é não construir o reticulado completo, o que garante ganhos em tempo, quando comparado aos demais algoritmos aqui apresentados.

O reticulado construído possui o primeiro conceito formal (aquele mais ao topo), mas não necessariamente possui outros conceitos, em outras palavras, em tal estrutura, quaisquer conceitos formais certamente possuem um supremo, mas não existe certeza quanto a um ínfimo.

A construção de tal reticulado incompleto é orientada por dois parâmetros de entrada, descritos mais à frente.

A grande desvantagem do algoritmo é requerer quatro parâmetros de entrada.

Cada fase de classificação emprega dois desses parâmetros.

O problema é determinar seus valores, tarefa não concluída sequer pelos autores da proposta, existem algumas sugestões de melhores valores, mas eles dependem bastante do conjunto de entrada binária.

A primeira fase de "Legal" recebe um contexto formal (O,A,A,R) e, depois de produzir um reticulado, produz também regras baseadas em tal estrutura.

O algoritmo realiza somente classificação binária.

É também necessário rotular tais valores de classe como positivos e negativos, pois tal informação será empregada na construção do reticulado.

Particiona-se aqui o conjunto O de objetos em O (objetos positivos) e O (objetos negativos), dependendo de seus valores de classe.

E importante comentar que positivos e negativos são apenas rótulos, não indicam que um dos valores é mais importante.

O reticulado de tal algoritmo considera somente objetos de O e ignora a classe e seus valores (afinal, todos os objetos têm valores positivos de classe).

Ele é construído segundo o Algoritmo 3, com algumas alterações.

O primeiro conceito formal (E,I) contém somente objetos positivos em sua extensão.

A segunda alteração é a derivação de valores de atributos, para formar conceitos formais, o conjunto de objetos resultante de tal derivação contém apenas elementos positivos.

Em resumo, tal reticulado refere-se ao contexto formal (O,B,B,R).

O reticulado aqui empregado é incompleto, pois contém somente conceitos formais válidos.

Dado o parâmetro 0 1 (um dos quatro recebidos como entrad, um conceito formal (E,I) de tal reticulado é chamado válido.

Ou seja, conceitos formais válidos são aqueles cujas extensões possuem um tamanho mínimo desejado, ou melhor, são aqueles que cobrem um número mínimo de objetos positivos.

Como as extensões de conceitos formais na região superior do reticulado têm mais elementos, o reticulado incompleto pode, dependendo de, possuir somente tais conceitos.

As regras formadas por conceitos válidos são também chamadas válidas.

Uma vez pronto o reticulado (com objetos positivos e conceitos formais válidos), conclui-se a primeira fase, produzindo-se regras pertinentes.

Essas são formadas por conceitos formais também chamados pertinentes.

Para definir conceitos pertinentes, define-se primeiro conceito coerente.

Dado o parâmetro 0 1, um conceito formal (E,I) do reticulado é chamado coerente.

Ou seja, conceitos formais coerentes cobrem um número máximo de objetos negativos.

Conceitos formais pertinentes são válidos e coerentes, definem-se regras coerentes analogamente.

Importante mencionar, Se um conceito formal é coerente, todos os seus descendentes também o são, mas se um conceito formal é, no entanto, válido, todos os seus ascendentes também o são.

O Algoritmo 7 mostra o pseudo código da primeira fase de "Legal".

O leitor observe que, no caso de = 0, o reticulado é completo.

Algoritmo 7 pseudo código da primeira fase do algoritmo "Legal".

Entradas, contexto formal (O,A,A,R), parâmetros.

A segunda fase de "Legal" recebe um contexto formal (O,A,A,R), com objetos sem valores de classe, e os classifica com regras pertinentes.

Tais regras têm intensões de conceitos formais em seus antecedentes e apresentam todas somente um consequente, o valor positivo de classe (afinal, o reticulado considera apenas objetos positivos).

Ao contrário das propostas que também produzem regras, este algoritmo usa parâmetros 01 e 01 (os dois restantes) para classificar os objetos.

Para qualquer objeto a ser classificado, sendo n o número de regras que cobrem tal objeto e m o tamanho do conjunto de regras, o objeto é classificado como positivo se n/m ou como negativo se n/m <, em caso contrário, o objeto não é classificado.

Para evitar o problema de objetos não classificados, sugere-se Exemplo 13, "Legal" é executado para o contexto formal (O,A,A,R) convertido, com c ="Lentes".

Converte-se tal problema para outro com dois valores de classe, "Macias" e "Rígidas" tornam-se o valor positivo, enquanto "Nenhuma" é considerado como negativo.

Todo objeto que possua "Macias" ou "Rígidas" é, portanto, um objeto positivo.

E também preciso determinar os quatro parâmetros, analisando-se tal exemplo tal configuração produz bons resultados, tal análise é baseada em estudos dos autores do algoritmo.
A primeira fase produz o reticulado incompleto do contexto formal (O,B,B,R).
Como o reticulado é mostrado em modo reduzido, usam-se somente os rótulos dos valores de atributos, o modo reduzido aqui não funcionaria corretamente com rótulos de objetos.

O leitor observe que os conceitos formais são válidos, pois suas extensões (deduzíveis com auxílio do contexto formal) cobrem o número mínimo de objetos positivos.

Reticulado incompleto produzido pelo algoritmo "Legal".

A primeira fase continua, produzindo um conjunto de regras pertinentes.

Como o reticulado possui apenas conceitos formais coerentes (além de válidos, evidentemente), todos eles produzem regras.

Conjunto de regras produzido pelo algoritmo "Legal".

A segunda fase classifica o conjunto.

Com os parâmetros = 0e = 04, cada objeto precisa ser coberto por, no mínimo, duas das cinco regras.

O objeto "06", coberto por três regras (primeira, terceira e quint, é corretamente classificado como positivo (sua classe original é "Macias").

O objeto "03" é corretamente classificado como negativo (sua classe original é "Nenhuma"), pois nenhuma das regras o cobre.

"Legal" é executado para o contexto formal (O,A,A,R) convertido, com c ="Lentes".

Converte-se tal problema para classificação binária.

Mostra o reticulado do contexto formal.

Por fim, mostra o conjunto de regras pertinentes, resultado da primeira fase de classificação.

A segunda fase classifica o conjunto.

Com os parâmetros 0e 04, cada objeto precisa ser coberto por, no mínimo, duas das cinco regras.

O objeto "02", coberto por uma regra, é erroneamente classificado como negativo (sua classe original é "Macias").

Já o objeto "06" (cuja classe original é "Nenhuma") é também erroneamente classificado, mas como positivo, pois é coberto por duas regras.

O algoritmo "Galois" versão do algoritmo conceitos e não mais trabalha com regras.

Como mostrado a seguir, é requerido um parâmetro de entrada.

Em sua primeira fase, "Galois" recebe o contexto formal (O,A,A,R) e produz o reticulado, ignorando a classe e seus valores.

O reticulado corresponde, logo, ao contexto formal (O,B,B,R).

Para executar tal fase, recorre-se ao Algoritmo 3.

Em sua segunda fase, "Galois" recebe o contexto formal (O,A,A,R) e também um parâmetro de impureza.

O Algoritmo 8 mostra o pseudo código da segunda fase de classificação.

Algoritmo 8 pseudo código da segunda fase do algoritmo "Galois".

Entradas, reticulado da primeira fase.

Para classificar objetos sem valores de classe, "Galois" caminha pelo reticulado, usando o chamado parâmetro de impureza.

Para cada objeto a ser classificado, o algoritmo considera conceitos formais que tenham certas propriedades e, baseando-se nos valores de classe sugeridos por tais conceitos, classifica aquele objeto.

As propriedades mencionadas são as seguintes, a intensão do conceito formal deve ser subconjunto dos valores de atributos do objeto, além disso, os valores de classe sugeridos pelo conceito formal devem, para serem considerados, ser eleitos por determinada proporção da extensão (a medida de impureza determina quantos outros valores de classe são tolerados na extensão).

Ao fim do processo, o objeto é classificado segundo eleição dos valores de classe, ganha aquele mais votado nos conceitos formais (considerando as duas propriedades aqui descritas).

Com tal processo, "Galois" considera, a grosso modo, todas as combinações de valores de atributos, presentes no reticulado e pertencentes ao objeto a ser classificado.

E importante comentar que, embora a classe e seus valores tenham sido ignorados na construção do reticulado, eles são requeridos na segunda fase.

E adequado armazenar, em cada conceito formal, as quantidades de objetos com cada valor de classe, a fim de garantir mais eficiência ao algoritmo.

Exemplo 15, O algoritmo "Galois" é executado para o contexto formal (O,A,A,R)0, considerando-se c ="Lentes".

A primeira fase do algoritmo produz o reticulado, ignorando a classe e seus valores, para a construção.

Deseja-se, na segunda fase, classificar o objeto "03", com parâmetro de impureza 40%.

Caminha-se no reticulado, pesquisando-se os conceitos formais (reparar que suas intensões são subconjuntos dos valores de atributos de "03"), Do primeiro, segundo e quinto conceitos formais, não se consideram valores de classe, pois suas extensões não elegem nenhum com mais de 60%.

Do terceiro e sexto conceitos formais, considera-se o valor "Nenhuma", pois as extensões de ambos os conceitos elegem tal valor de classe com mais de 60%.

O valor "Rígidas" é eleito pelo quarto conceito formal com mais de 60%.

O objeto "03" é, portanto, corretamente classificado como "Nenhuma", valor de classe eleito dentre os seis conceitos formais pesquisados.

Reticulado produzido pelo algoritmo "Galois".

Os algoritmos "Similares1" e "Similares2" também produzem essa estrutura.

Exemplo 16, O algoritmo "Galois" é executado para o contexto formal (O,A,A,R)0.

A primeira fase do algoritmo produz o reticulado, ignorando a classe e seus valores, para a construção.

Deseja-se, na segunda fase, classificar o objeto "02", com parâmetro de impureza 40%.

Caminha-se no reticulado, pesquisando-se os conceitos formais, O terceiro conceito formal elege o valor de classe "Nenhuma", enquanto o quarto elege "Macias".

Entretanto, os outros três conceitos formais não têm valores de classe considerados, pois não conseguem os mínimos 60%.

O objeto "02" não pode ser classificado, devido ao impasse entre "Nenhuma" e "Macias".

O algoritmo "Similares1" é uma proposta inédita, desenvolvida durante este trabalho.

Ele usa apenas o reticulado da análise formal de conceitos e não requer nenhum parâmetro de entrada.

Enquanto os algoritmos apresentados nas seções anteriores procuravam conceitos formais (ou nós, no caso do pseudo reticulado) que cobrissem muitos objetos com poucos atributos, este algoritmo introduz a noção de similaridade, para classificar.

A primeira fase de "Similares1" recebe um contexto formal (O,A,A,R) e produz um reticulado, ignorando a classe e seu domínio.

O reticulado corresponde, na verdade, ao contexto formal (O,B,B,R), a classe e seus valores são empregados em outras tarefas, não na construção da estrutura.

Essa primeira fase, idêntica à do algoritmo anterior, emprega o Algoritmo 3.

A segunda fase de "Similares1" recebe um contexto formal (O,A,A,R) cujos objetos não possuam nenhum dos valores de classe e, baseando-se no reticulado, classifica tais objetos.

Em resumo, para cada objeto, encontram-se os conceitos formais mais similares a ele e, analisando-se tais conceitos, escolhe-se a classe.

O Algoritmo 9 mostra o pseudo código para executar essa segunda fase.

Uma primeira questão quanto ao algoritmo "Similares1" é, como calcular similaridade?

O pseudo código contém uma variável para armazenar a similaridade máxima e um conjunto para armazenar os conceitos formais mais similares.

Durante a pesquisa pelo reticulado, começando no primeiro conceito formal (aquele do topo), se algum conceito for mais similar ao objeto do que a similaridade máxima já calculada, essa é trocada pela nova similaridade e começa-se um novo conjunto de conceitos formais mais similares, caso a nova similaridade seja idêntica à máxima já calculada, o conjunto mencionado apenas recebe mais um elemento.

Descreveu-se aqui como encontrar os conceitos formais mais similares ao objeto que se quer classificar, mas ainda é preciso definir essa similaridade.

Para isso, o leitor suponha o objeto o O e alguns conceitos formais (E,I), (E,I), (E,I) (inventa-se também um conjunto de valores de atributos {a,a,a,a }), A função de similaridade recebe como argumentos um objeto composto por valores de atributos e um conceito formal.

O segundo argumento contém extensão e intensão, mas o primeiro contém apenas valores de atributos.

Parece adequado, portanto, tentar elaborar uma medida de similaridade que trabalhe com os valores de atributos dos dois argumentos.

Objeto e conceito formal podem ter valores de atributos iguais ou diferentes, chamam-se os primeiros de valores positivos de atributos e os ultimos de valores negativos de atributos.

Uma primeira tentativa de medida de similaridade poderia ser a quantidade de atributos positivos de atributos, entre o objeto e o conceito formal.

Caso se adotasse tal medida, os conceitos formais (E,I) e (E,I) seriam os mais similares ao objeto o, contudo, o primeiro desses conceitos contêm também muitos valores negativos de atributos.

Uma segunda tentativa poderia, baseando-se no argumento apresentado, considerar mais similares os conceitos formais com menor quantidade de valores negativos de atributos.

Com tal medida, os conceitos formais (E,I) e (E,I) seriam os mais similares ao objeto o, no entanto, o primeiro desses conceitos contém poucos valores positivos de atributos, menos até que o primeiro conceito formal, descartado por tal medida.

A função de similaridade mais adequada precisa, portanto, considerar ambos os valores positivos e negativos de atributos.

O conceito formal precisa ser beneficiado por valores positivos em sua intensão, mas também penalizado por seus valores negativos de atributos.

Desse modo, o conceito formal (E,I) é o mais similar ao objeto o, pois sua intensão contém mais valores positivos de atributos do que negativos, balanceados de maneira melhor do que nos demais conceitos em questão.

Determina-se, portanto, que a função de similaridade do algoritmo "Similares1", entre um objeto o O e um conceito formal (E,I), é a seguinte, Uma segunda questão quanto ao algoritmo "Similares1" é, uma vez encontrados os conceitos formais mais similares ao objeto, como classificar este?

De fato, é possível (e provável) que o conjunto de mais similares contenha mais que um conceito formal.

Caso fosse sempre encontrado somente um conceito mais similar, o valor de classe sugerido por ele classificaria o objeto.

No entanto, como o conjunto de mais similares não é garantidamente unitário, é necessário analisar os valores de classe sugeridos pelos conceitos formais mais similares.

Para classificar um objeto, o algoritmo escolhe, dentre os conceitos formais mais similares, aquele mais convicto quanto ao valor de classe.

O conceito formal contém objetos em sua extensão que possuem valores de classe, naquele primeiro contexto formal empregado para construção do reticulado, essa extensão logo apresenta, segundo mesma idéia do algoritmo anterior, quantidades de votos dos objetos para cada valor de classe.

Define-se aqui conceito formal mais convicto como aquele que, comparado a outros, apresenta a maior porcentagem de votos para algum valor de classe.

A convicção mais alta de um conceito formal é 100%, isso acontece quando todos os objetos de sua extensão sugerem somente um valor de classe.

Prefere-se, dentre os conceitos formais mais similares, aquele mais convicto, pois parece pouco adequado adotar valores de classe pouco votados em seus conceitos formais.

O algoritmo precisa, devido à adoção de tal estratégia, ter acesso aos valores de classe dos objetos que formaram o reticulado.

Durante a construção de tal estrutura, na primeira fase, não foram consideradas a classe tampouco seu domínio e valores em objetos, mas agora eles são necessários.

Uma solução seria, ao analisar os conceitos formais mais similares ao objeto a classificar, acessar valores de classe dos objetos no contexto formal, no entanto, esse seria um procedimento bastante oneroso.

A solução mais adequada é, durante a construção do reticulado, armazenar em cada conceito formal as porcentagens de votos da extensão, para cada valor de classe.

A questão da escolha de valores de classe, solucionada por "Similares1" com a escolha do conceito formal mais convicto, pode ter soluções diferentes.

Uma dessas é proposta e apresentada na próxima seção.

Uma ultima questão quanto ao algoritmo "Similares1" é, como percorrer o reticulado?

O pseudo código caminha por tal estrutura em níveis, usando, para isso, dois conjuntos, o primeiro contém os conceitos formais sob análise, o segundo contém os próximos a analisar subconceitos não visitados dos conceitos sob análise.

Durante essa pesquisa, também ocorrem, como já mencionado, os cálculos de similaridade e a manutenção do seu resultado mais alto.

Caso o processo fosse somente esse, o reticulado seria inteiramente percorrido, mas, como mostra o pseudo código, os subconceitos passam por uma condição antes de serem adicionados ao conjunto de próximos conceitos formais.

O algoritmo não percorre o reticulado inteiro, pois isso é desnecessário.

Existem algumas regiões de tal estrutura que, se percorridas, certamente não aumentariam a similaridade máxima já alcançada.

O leitor suponha que o algoritmo encontra-se na seguinte situação, após calcular a similaridade de um conceito formal (E,I) a um objeto o O, é preciso decidir se compensa caminhar para os subconceitos do conceito em questão.

Caso esse caminho certamente não possa aumentar a similaridade máxima já alcançada, os subconceitos são ignorados como próximos conceitos formais.

Para responder quando compensa avançar para os subconceitos (para o reticulado construído na primeira fase), efetua-se a seguinte análise, Esse raciocínio, bastante simples, diz o seguinte, caso, somando-se a similaridade calculada, sim(o, (E,I)) ao número de valores de atributos restantes |A|I|, não for superada a similaridade máxima já calculada, não compensa caminhar para os subconceitos.

A cada subconceito avançado, o tamanho da intensão aumenta, no mínimo, em um elemento (valores positivos ou negativos de atributos).

O tamanho máximo de qualquer intensão no reticulado é |A| (valores de atributos usados na construção do reticulado).

Logo, só compensa continuar se, com os valores restantes de atributos, for possível superar ou, no mínimo, alcançar a máxima similaridade calculada.

E possível melhorar mais a pesquisa no reticulado, com alguns cuidados simples.

O primeiro, já mencionado em seções anteriores, consiste em marcar conceitos formais já visitados, a fim de evitar que tais estruturas seja analisadas repetidamente.

Um segundo cuidado é interromper a pesquisa se for calculada uma similaridade igual ao número de valores de atributos do objeto a classificar.

Quando isso acontece, foi encontrado um conceito formal cuja intensão é idêntica aos valores de atributos do objeto, logo, não é mais necessário caminhar pelo reticulado, pois nenhum outro conceito terá tal similaridade.

Classifica-se o objeto segundo aquele conceito formal.

Concluindo o estudo de "Similares1", aborda-se o uso de valores negativos de atributos nos conceitos formais similares, pois, pela primeira vez, um algoritmo tolera tal situação.

Permitem-se tais valores em conceitos formais considerados similares, pois esses também possuem valores positivos de atributos.

Contudo, é realmente perigoso adotar valores de classe de tais conceitos formais, pois eles podem ser determinados por valores negativos de atributos, o objeto seria classificado por valores de atributos que ele sequer possui (uma situação bastante indesejável).

Uma solução para tal problema é tolerar esses valores negativos apenas se atendidos alguns critérios.

Portanto, para qualquer conceito formal (E,I) e cada subconceito (E,I) que adicione somente valores negativos, esse ultimo será visitado se ambos (E,I) e (E,I) sugerirem o mesmo valor de classe.

Desse modo, procura-se tolerar valores negativos de atributos que não determinem valores de classe.

"Similares1" é executado para o contexto formal (O,A,A,R) convertido.

A primeira fase do algoritmo produz o reticulado, ignorando a classe e seus valores, para a construção.

A segunda fase do algoritmo encontra seus mais similares conceitos formais, com similaridade 2.
Os dois primeiros conceitos formais sugerem "Rígidas" com 100% de convicção, pois contém extensões unitárias, o terceiro conceito formal também sugere "Rígidas" com 100% de convicção, o quarto conceito formal nada sugere, pois "Nenhuma" e "Rígidas" têm 50% cada em sua extensão.

O objeto "04" é, portanto, corretamente classificado como "Rígidas", pois tal valor foi sugerido com 100% de convicção.

Exemplo 18, "Similares1" é executado para o contexto formal (O,A,A,R), considerando-se c ="Lentes".

A primeira fase do algoritmo produz o eticulado, ignorando a classe e seus valores, para a construção.

A segunda fase do algoritmo encontra, para O = {02}, um conceito formal com similaridade 2.
O conceito formal sugere, com 100% de convicção, classificar o objeto como "Nenhuma".

Esse é erroneamente classificado, pois seu valor correto de classe "Macias".

Objeto e conceito formal possuem três valores positivos de atributos e somente um negativo, mas, apesar dessa similaridade, a classificação foi equivocada.

O algoritmo "Similares2" é, na verdade, uma variação da proposta da seção anterior.

Sua primeira fase também produz, usando o Algoritmo 3, um reticulado para o contexto formal (O,A,A,R), ignorando a classe e seus valores.

Sua segunda fase também caminha pelo reticulado procurando conceitos formais segundo uma medida de similaridade e, baseando-se em tais conceitos, classifica os objetos do contexto formal (O,A,A,R).

O modo de percorrer a estrutura é idêntico (também evitando caminhos que não superem a similaridade máxima calculada, como aqueles com valores negativos determinantes) e a similaridade é também calculada da mesma maneira.

A diferença entre os dois algoritmos está na escolha do valor de classe.

O algoritmo "Similares2" usa, para classificar um objeto, o valor de classe mais votado pelos conceitos formais similares.

Essa estratégia, diferente de "Similares1", é similar à votação realizada por "Galois".

Para classificar, não se considera somente um conceito formal que sugere com mais convicção, mas, pelo contrário, consideram-se as sugestões de todos, pois esses são conceitos com a mesma similaridade.

No entanto, como alguns conceitos formais podem sugerir valores de classe com pouquíssima convicção, é adequado colher sugestões apenas daqueles que as dêem com uma convicção mínima.

Essa estratégia é implementada neste trabalho de dois modos diferentes.
Apenas conceitos formais similares com convicção superior a 50% têm suas sugestões consideradas na votação, requer-se, como em algumas propostas, um parâmetro de impureza, que aqui determina a não-convicção máxima tolerada.
"Similares2" é executado para o contexto formal (O,A,A,R), considerando-se c ="Lentes".

A primeira fase do algoritmo produz o reticulado, ignorando a classe e seus valores, para a construção.

A segunda fase do algoritmo encontra seus mais similares conceitos formais, com similaridade 2.
O primeiro conceito formal sugere "Nenhuma", com 100% de convicção, também com 100%, o segundo sugere "Rígidas", "Nenhuma" é sugerida com 100% de convicção pelo terceiro conceito formal, por fim, o quarto tem 50% em "Nenhuma" e em "Rígidas".

Usando ou não parâmetro de impureza (exigindo mais de 50% de convicção, no segundo caso), "Nenhuma" é mais votada (primeiro e terceiro conceitos formais) e classifica corretamente o objeto "19".

"Similares2" é executado para o contexto formal (O,A,A,R) convertido, considerando-se c ="Lentes".

A primeira fase do algoritmo produz o reticulado, ignorando a classe e seus valores, para a construção.

A segunda fase do algoritmo encontra um conceito formal com similaridade 2, O conceito formal mais similar sugere, com 100% de convicção, classificar como "Rígidas".

Aceitando tal sugestão, o algoritmo classifica erroneamente o objeto "07", cujo valor correto de classe seria "Nenhuma".

Este capítulo descreve experimentos com as propostas apresentadas no capítulo anterior.

Enquanto o teor daquele era teórico, o conteúdo deste contém implementações e resultados práticos.

A seção 51 descreve o cenário no qual efetuaram-se os experimentos programas, computador, entradas, metodologia etc.

As demais seções resumem os diversos experimentos efetuados, na seção 52, executam-se os algoritmos para diversos arquivos de repositório na internet, na seção 53, processa-se o método de avaliação chamado "holdout", e na seção 54, o método de avaliação é a validação cruzada.

A seção 55 debate os tempos de execução dos algoritmos.

As seis propostas do capítulo anterior, além de dois algoritmos clássicos de classificação, foram implementadas neste trabalho, para experimentos e comparações.

Os dois algoritmos clássicos são árvore de decisão e conjunto de regras, tais como aqui apresentados.

Os oito algoritmos foram escritos, de maneira fiel aos pseudo códigos aqui mostrados, em linguagem de programação Java.

Quanto às propostas que usam reticulado (ou pseudo reticulado), tal estrutura foi armazenada em tabela "hash", para acesso mais rápido aos conceitos formais (ou nós).

Esses foram escritos como classes, conectados aos seus descendentes diretos por meio de apontadores, referências, como dito em Jav.

Os experimentos com os oito programas ocorreram em um computador com processador "AMD Athlon" de GHz, com 51MB de memória primária e com sistema operacional "Suse" (distribuição "Linux").

Os arquivos de entrada para os oito programas, usados em trabalhos sobre classificação, foram coletados na internet a seguir, poucos objetos e atributos, se comparados a verdadeiras entradas para mineração de dados, usam-se tais arquivos de dimensões reduzidas, devido ao crescimento exponencial do reticulado em relação à entrada.

Para as propostas que usam reticulado (ou pseudo reticulado), os conjuntos de dados contidos nos arquivos foram primeiro convertidos para contextos formais, usando escalas nominais.

O repositório acessado contém informações mais detalhadas sobre tais conjuntos, aqui apenas enumeram-se os mesmos (com os títulos originais), BA, "balance scale weight and distance database", HR, "Hayes-Roth and Hayes-Roth database", LE, "database for fitting contact lenses", M, "the monk's problems",PO, "postoperative patient data", SH, "space shuttle autolanding domain", VO, "198United States congressional voting records database", ZO, "zoo database".

Eis alguns detalhes quanto a tais conjuntos, HR está dividido em dois arquivos, um para cada fase de classificação.

M está dividido em três problemas (M1, M2, M, cada um composto por dois arquivos (o arquivo da segunda fase de classificação é idêntico nos três problemas).

Os atributos índice (únicos para cada objeto) são descartados neste trabalho.

Objetos com valores ausentes de atributos também são descartados.

Os algoritmos com parâmetro de impureza "Rulearner", "Galois", "Similares1", são executados com diversos valores para este (40%, 30%, 20%, 10%).

"Similares2", quando sem parâmetro, requer consenso da maioria dos elementos da extensão (ou seja, no mínimo 50%), para considerar voto do conceito formal na eleição da classe.

Quanto aos quatro parâmetros do algoritmo "Legal", testaram-se diversos valores para os mesmos e, em cada comparação entre os programas, usam-se os valores que causaram melhores resultados.

O Anexo enumera os diversos testes de tais parâmetros e sempre são 01, enquanto variam-se.

Os primeiros experimentos usam os arquivos tais como coletados no repositório.

Os conjuntos HR e M (esse, dividido em três problemas) têm, como já mencionado, um arquivo para a primeira fase de classificação e outro para a segunda.

Os demais conjuntos têm seus unicos arquivos usados nas duas fases de classificação.

Mostra os tamanhos números de objetos em cada fase, números de atributos, tamanhos de domínios dos arquivos dos conjuntos.

Conjuntos originais.

Os oito programas foram executados para cada conjunto de dados.

Mostra a precisão de cada programa para cada conjunto.

São também mostrados 1 os melhores e piores resultados para cada conjunto (considerando, primeiro, as propostas com reticulado ou pseudo reticulado, depois, as oito propostas), bem como as precisões médias de cada algoritmo, para tais entradas.

Alguns algoritmos "Grand", "Similares1", "Similares2", árvore de decisão, conjunto de regras têm sempre precisão 100% para alguns conjuntos BA, LE, SH, ZO.

Esse bom desempenho já era esperado, pois tais conjuntos têm um só arquivo e tais algoritmos cobrem, sem tolerar impurezas, todos os objetos na primeira fase de classificação (seja com regras, caminhos na árvore ou conceitos formais similares).

Mas os arquivos PO e VO, embora também tenham um só arquivo, não permitiram precisão 100%.

Isso aconteceu por "perda de dados" durante a conversão para contexto formal em PO, foi preciso tornar categórico um atributo numérico, enquanto em VO, os três valores ("sim", "não") de cada atributo foram convertidos em dois ("sim", "não"), no contexto formal.

Já para os conjuntos HR e M, que possuem dois arquivos, os algoritmos apresentam diferentes resultados.

Os resultados do algoritmo árvore de decisão, para a entrada VO, não são mostrados em nenhuma das seções, pois em alguns experimentos ocorreu estouro de memória, não sendo possível concluir a execução.

O método de avaliação chamado "holdout" consiste em dividir, em dois conjuntos disjuntos, uma coleção com valores conhecidos de classe.

Usa-se o primeiro conjunto na construção do modelo de classificação, depois calcula-se a precisão desse modelo com o segundo conjunto.

Algumas proporções sugeridas na divisão do conjunto são, por exemplo, 75%, 25% e 50%, 50% (primeira e segunda fases de classificação).

O método "holdout" é simples e possui diversas limitações.

Primeiro, caso sejam poucos os objetos com valores conhecidos de classe, menos ainda serão aqueles usados na construção do modelo, devido à divisão do conjunto original em dois.

Segundo, o modelo de classificação e sua precisão dependem bastante da divisão em dois conjuntos (como mostram os experimentos desta seção).

Por fim, alguns valores de classe podem ser muito frequentes em um dos arquivos, porém raros no outro.

Os primeiros experimentos "holdout" deste trabalho dividem os conjuntos na proporção 75%,25%.

Para os conjuntos que já possuem dois arquivos HR e M, consideram-se, para essa nova divisão, aqueles com mais objetos (o da primeira fase, para HR, o da segunda fase, para M).

Para evitar o ultimo problema mencionado no parágrafo anterior, os conjuntos são divididos de diversas maneiras e, para cada uma, é registrado um experimento.

Por isso são aqui mostradas quatro avaliações "holdout" 75%, 25%.

No experimento A, os conjuntos são divididos mantendo-se as proporções de valores de classe nos dois arquivos, enquanto nos demais experimentos, a divisão é aleatória.

A escreve os arquivos usados nesses experimentos.

A ostra resultados do primeiro experimento "holdout" 75%, 25%.

"Grand" tem duas melhores precisões (LE e PO), mas também duas piores (M e VO).

"Rulearner" (em seus diversos testes) tem a pior precisão média do primeiro grupo de algoritmos.

"Legal" não figura entre os piores resultados tampouco entre os melhores.

"Galois" (em seus diversos testes) tem três melhores precisões (HR, LE, PO) e somente uma pior (M).

"Similares1" tem melhor precisão em quatro arquivos (BA, LE, M, VO) e nenhum pior resultado.

"Similares2" (em seus diversos testes) conquista a melhor precisão média, com destaque para 100% em ZO.

Precisões (%) com conjuntos 75%, 25% A.

O algoritmo "Legal" recebeu os valores de parâmetros.

O algoritmo executa só classificação binária.

A ostra resultados do segundo experimento "holdout" 75%, 25%.

Muitos dos algoritmos "Grand", "Rulearner", "Galois", "Similares2" têm precisões perfeitas para alguns arquivos (100% em SH), mas também resultados pífios para outros (0% em LE).

"Legal" tem novamente desempenho mediano, alcançando 100% de precisão em SH, mas não saindo de 0% em M.

"Similares1" tem bom desempenho, conseguindo, por exemplo, 100% de precisão para os conjuntos M e SH.

A precisão média de "Rulearner" é novamente a pior entre os primeiros algoritmos, enquanto a de "Similares2" é novamente a melhor, tal algoritmo consegue 100% para três conjuntos (M, SH, ZO).

Precisões (%) com conjuntos 75%, 25% B.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros, = 05, = 01, = 01, = 01.

O algoritmo executa só classificação binária.

Resultados do terceiro experimento "holdout" 75%, 25%.

"Grand" tem desempenho mediano, com piores precisões para três conjuntos (LE, SH, VO).

Os resultados de "Rulearner" variam de acordo com seu parâmetro, conseguindo 100% para LE e M, tal algoritmo tem melhor precisão média, entre todos os demais, com parâmetro 30%.

Já "Legal" tem pior precisão média, conseguindo 0% para M.

"Galois", "Similares1" e "Similares2" têm desempenhos medianos, esses três algoritmos apresentam melhores precisões para alguns conjuntos ("Galois" para PO, "Similares1" para ZO, "Similares2" para BA e VO), mas também piores precisões ("Galois" para LE e SH, "Similares1" para SH, "Similares2" para HR e SH).

Precisões (%) com conjuntos 75%, 25% C.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros, = 05, = 01, = 01, = 01 * O algoritmo executa só classificação binária.

O ultimo experimento "holdout" 75%, 25% é mostrado.

Destaque (negativo) para "Rulearner", com pior precisão média com parâmetro 40%, em seus diversos testes, tal algoritmo tem pior precisão para, no mínimo, um conjunto.

Destaque (positivo) para "Galois", com melhor precisão média (quase 90%) com parâmetro 40%, tal algoritmo tem, em seus diversos testes, muitas das melhores precisões, em especial 100% para LE e SH.

Precisões (%) com conjuntos 75%, 25% D.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros,01,02.

O algoritmo executa só classificação binária.

Os próximos experimentos "holdout" deste trabalho dividem os conjuntos na proporção 50%, 50%.

Essa divisão ocorre de maneira similar à ultima descrita (para "holdout" 75%, 25%).

Os conjuntos HR e M, embora possuam dois arquivos no repositório de origem, são novamente divididos conforme já descrito, considerando-se o maior arquivo.

São novamente efetuadas diferentes divisões, de A a, nos experimentos A, balanceiam-se as proporções dos valores de classe nos dois arquivos, enquanto, nos demais experimentos, a divisão em dois arquivos é aleatória.

Descreve as diferentes divisões dos conjuntos.

Conjuntos divididos em 50% 50%.

 Para o primeiro de tais experimentos, "Grand" tem pior desempenho, enquanto "Similares1" tem o melhor.

Destaque para os algoritmos "Similares1" e "Similares2", com muitas das melhores precisões.

No segundo experimento o pior desempenho é de "Galois" e o melhor é de "Similares2".

Destaque negativo para as péssimas precisões em LE, não saindo de 0% em alguns algoritmos, mas destaque positivo para as melhores precisões em M, SH, ZO, todas em "Similares1" e "Similares2".

A Tabela, referente ao terceiro experimento, é similar à anterior em alguns pontos, como as baixíssimas precisões em LE.

Em tal experimento, o pior resultado é de "Grand" e o melhor é de "Similares1".

No ultimo experimento, "Legal" tem o pior desempenho, enquanto "Galois" tem o melhor.

Destaque para as precisões de 100% em ZO, com os algoritmos "Similares1" e "Similares2".

Precisões (%) com conjuntos 50% 50%.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros, 01 01.

O algoritmo executa só classificação binária.

Precisões (%) com conjuntos 50% 50%.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros, 02,01.

O algoritmo executa só classificação binária.

Precisões (%) com conjuntos 50% 50% C.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros, 05, 01.

O algoritmo executa só classificação binária.

Precisões (%) com conjuntos 50% 50% D.

O algoritmo "Legal" recebeu os seguintes valores de parâmetros,05, 01.

O algoritmo executa só classificação binária.

Esta seção mostra experimentos segundo o método chamado validação cruzada.

Em tal método, divide-se, por exemplo, o conjunto de entrada em dois.

Usa-se o primeiro conjunto na construção do modelo e o segundo em sua avaliação, depois trocam-se os papéis.

Por fim, calcula-se a precisão média dos dois processamentos.

O método descrito é a validação cruzada em duas iterações.

De modo genérico, na validação cruzada em n iterações, divide-se o conjunto em n partes de tamanhos iguais, executa-se o algoritmo alternando-se os subconjuntos, a cada momento, um dos subconjuntos é empregado na segunda fase, enquanto os demais formam a primeir e, ao fim do processo, calcula-se a precisão média.

A validação cruzada soluciona algumas fraquezas do método "holdout" Algumas de suas vantagens são o uso de mais objetos na construção do modelo (primeira fase de classificação) e também o uso de todo o conjunto, de modo alternado e sem repetição, na avaliação (segunda fase de classificação).

Uma desvantagem é certamente o custo computacional de se cumprir tal método, executando diversas vezes o algoritmo de classificação.

O primeiro experimento da seção é uma validação cruzada em quatro iterações.

Cada conjunto é, portanto, dividido em quatro arquivos de tamanhos iguais.

O processo de divisão foi o seguinte, lê-se o arquivo original e cada quarto lido é copiado em um dos subconjuntos, alternado-se os mesmos.

Detalha a divisão dos conjuntos aqui usados em quatro partes.

O leitor observe os números de objetos em cada iteração, 75% são usados na construção do modelo e 25% na avaliação do mesmo, sendo cada objeto empregado três vezes na fase de construção e somente uma vez na fase de avaliação.

Conjuntos de validação cruzada 4.

Enumeram-se números de objetos em cada iteração.

Mostram a validação cruzada para os oito programas aqui abordados.

São exibidas as precisões dos algoritmos em cada iteração e para cada conjunto.

Os algoritmos com parâmetro de entrada "Rulearner", "Galois", "Similares2" foram executados com diversos valores para esse, mas têm aqui exibidos somente os melhores resultados.

O algoritmo "Legal" foi executado, para essa validação cruzada, com os seguintes valores para seus parâmetros (pois eles produziram alguns dos melhores resultados no método "holdout").

E importante lembrar que, embora composta por iterações, a validação cruzada tem seu resultado na precisão média das diversas execuções.


Precisões (%) de "Grand" em validação cruzada 4.

Precisões (%) de "Rulearner" 30% em validação cruzada 4.

Precisões (%) de "Legal" em validação cruzada 4.

Precisões (%) de "Galois" 40% em validação cruzada 4.

Precisões (%) de "Similares1" em validação cruzada 4.

Precisões (%) de "Similares2" 40% em validação cruzada 4.

Precisões (%) da árvore de decisão em validação cruzada 4.

Precisões (%) do conjunto de regras em validação cruzada 4.

Mostra os resultados dos algoritmos na validação cruzada de quatro iterações.

"Grand" tem, devido a piores precisões para três conjuntos (BA, M, VO), o pior resultado de todos os algoritmos.

"Rulearner" (em seus diversos testes) tem piores precisões para quatro conjuntos (LE, M, SH, ZO), mas um resultado mediano.

"Legal" tem, como de costume, uma fraca precisão média.

"Galois" (em seus diversos testes) apresenta melhor precisão para um conjunto (PO), mas pior para outro (M).

"Similares1" tem melhores precisões para metade dos conjuntos (BA, LE, M, ZO).

Contudo, é o algoritmo "Similares2" (em especial, com parâmetro 40%) que consegue a melhor precisão média de todos os algoritmos.

As propostas clássicas árvore de decisão e conjunto de regras não apresentam piores tampouco melhores resultados médios.

Precisões (%) em validação cruzada 4.

O algoritmo executa só classificação binária.

Descreve os arquivos para validação cruzada com dez iterações, o ultimo e mais rigoroso experimento do trabalho.

A descrição dessa tabela é análoga àquela dos arquivos para quatro iterações.

Cada conjunto é dividido em dez arquivos, a cada iteração, nove desses subconjuntos são usados na construção do modelo e somente um em sua avaliação.

E importante lembrar que cada subconjunto é usado uma vez na avaliação e nove na construção, sem repetição.

Devido à divisão em dez arquivos, conjuntos menores têm poucos objetos na segunda fase de classificação, como, por exemplo, SH, em algumas iterações, existe somente um objeto, o que permite grandes variações de precisão.

Conjuntos de validação cruzada 10.

Enumeram-se números de objetos (|O | e |O |) em cada iteração (1 a 10).

Como na validação cruzada em quatro passos, as próximas mostram os resultados dos oito algoritmos, na validação cruzada em dez iterações.

Mais uma vez, para as propostas que lançam mão de parâmetro de entrada, mostram-se os valores com os quais tais algoritmos tiveram melhor desempenho.

O algoritmo "Legal" foi novamente executado com os seguintes valores de parâmetros, = 02, = 05, Precisões (%) de "Grand" em validação cruzada 10.

Precisões (%) de "Rulearner" 20% em validação cruzada 10.

Precisões (%) de "Legal" em validação cruzada 10.

Precisões (%) de "Galois" 30% em validação cruzada 10.

Precisões (%) de "Similares1" em validação cruzada 10.

Precisões (%) de "Similares2" 30% em validação cruzada 10.
Precisões (%) da árvore de decisão em validação cruzada 10.

Precisões (%) do conjunto de regras em validação cruzada 10.

O ultimo experimento validação cruzada em dez iterações tem seus resultados mostrados.

As propostas mais antigas de algoritmos "Grand", "Rulearner", "Legal" apresentam a maioria das piores precisões.

"Grand" tem duas dessas (BA, VO) e um desempenho mediano.

"Rulearner" (em seus diversos testes) tem piores precisões em metade dos conjuntos (HR, LE, M, ZO), mas também o melhor resultado em HR, com parâmetro 30%.

"Legal" consegue, além da pior precisão em um dos conjuntos (SH), o pior resultado de todos os algoritmos.

Já "Galois" (em seus diversos testes) tem boas precisões médias (muitas acima de 70%) e melhores resultados em três conjuntos (BA, PO, SH).

"Similares1" demonstra um considerável desempenho, mas a melhor precisão é novamente de "Similares2", em especial com parâmetro 30%.

Esse ultimo algoritmo (em seus diversos testes), embora apresente péssimo resultado em um dos conjuntos (PO), tem melhores precisões em quatro outros (LE, M, VO, ZO), com destaque para 96% em ZO.

Quanto aos dois algoritmos restantes, apesar desses piorarem alguns dos resultados (BA, HR, LE, PO têm suas piores precisões reduzidas ainda mais), a árvore de decisão conseguiu a excelente precisão de 97% para M, melhor resultado para tal conjunto.

Precisões (%) em validação cruzada 10.

O algoritmo executa só classificação binária.

Comparam os tempos consumidos pelos programas aqui implementados seis usam reticulados, enquantos dois são métodos clássicos de mineração.

Embora tempos de execução dependam bastante de detalhes de implementação e do computador empregado (a configuração desse é descrita no capítulo anterior), eles são aqui mostrados para permitir a comparação entre os diversos algoritmos estudados.

O leitor observe que, para auxiliar a análise, os valores são arredondados de 5 ms em 5 ms.

E também importante mencionar que 0 ms representa tempo desprezível de execução.

Por fim, mostram os tempos de execução agrupados em cada fase de classificação (aprendizagem e operação).

Mostra os tempos de execução dos algoritmos para os conjuntos originais (seus tamanhos são descritos).

Na primeira fase, quando classificação binária, os melhores tempos são do algoritmo "Legal", senão, os melhores são da árvore de decisão.

Na segunda fase, o algoritmo "Rulearner", com seus reduzidos conjuntos de regras, é o mais rápido na classificação, para a grande maioria dos conjuntos.

O método "holdout" 75%, 25% tem os tempos consumidos dos algoritmos (médias dos experimentos A).

Mais uma vez, na primeira fase, "Legal" e árvore de decisão têm os melhores tempos, o primeiro desses algoritmos, sempre que a classificação é binária.

Quanto aos piores tempos na primeira fase, esses são, na maioria dos conjuntos, do algoritmo "Grand", devido à cara construção do pseudo reticulado.

Na segunda fase, "Rulearner" tem, mais uma vez, os melhores tempos em muitos dos conjuntos.

Quanto aos piores tempos da segunda fase, esses são de "Similares1" e "Similares2".

O método "holdout" 50%50% tem os tempos consumidos dos algoritmos, médias dos experimentos A.

Os melhores tempos na primeira fase são, mais uma vez, de "Legal" (sempre que a classificação é binári ou árvore de decisão (em caso contrário).

Já os piores pertencem a diferentes algoritmos.

Devido à divisão do conjunto original em dois arquivos de tamanhos similares (50%50%), a segunda fase requer mais tempo.

"Similares1" e "Similares2" são os algoritmos mais lentos na fase de classificação, enquanto, por exemplo, "Grand" e "Rulearner", além dos métodos clássicos, têm os melhores valores.

Tempos de execução (ms) para conjuntos originais.

Na primeira fase, mostram-se o pior e o melhor tempos de execução de "Legal".
O algoritmo executa só classificação binária.

Tempos de execução (ms) para conjuntos 75%,25%.

Na primeira fase, mostram-se o pior e o melhor tempos de execução de "Legal".

O algoritmo executa só classificação binária.

Tempos de execução (ms) para conjuntos 50%, 50%.

Na primeira fase, mostram-se o pior e o melhor tempos de execução de "Legal".

O algoritmo executa só classificação binária.

Por fim, mostramos os tempos consumidos na validação cruzada de dez passos.

Os conjuntos, divididos em 90%, 10%, são descritos.

A árvore de decisão cumpre a primeira fase com os melhores tempos, para a grande maioria dos conjuntos.

Os piores tempos da primeira fase são divididos entre os diversos algoritmos.

Já na segunda fase de classificação, algoritmos exceto "Similares1" e "Similares2" são os que mais conseguem melhores tempos.

Tempos de execução (ms) para conjuntos 90%, 10%.

O algoritmo executa só classificação binária.

Uma rápida análise já permite algumas conclusões quanto aos tempos demandados pelos algoritmos.

Na fase de construção do modelo de classificação, os algoritmos "Legal" (dependendo do parâmetro) e árvore de decisão sempre figuram entre os melhores tempos.

Contudo, o primeiro desses algoritmos não apresenta precisões aceitáveis, como já mostrado no capítulo anterior.

Os algoritmos "Galois", "Similares1" e "Similares2" consomem tempos bastante similares, pois os três produzem o reticulado de conceitos.

Os piores tempos da primeira fase são dos algoritmos "Grand" e "Rulearner", devido à onerosa construção do pseudo reticulado.

Já na segunda fase de classificação, os algoritmos que trabalham com regras, "Grand", "Rulearner", "Legal", e aqueles já clássicos árvore de decisão e conjunto de regras são evidentemente mais rápidos na classificação de objetos.

Algoritmos como "Galois", "Similares1" e "Similares2" são mais demorados devido à pesquisa pelo reticulado de conceitos, que pode ter um grande número de conceitos formais, exponencial em relação ao contexto formal Análise formal de conceitos fornece a interessante estrutura chamada reticulado de conceitos.

Essa mostra, em formato de diagrama, relações entre objetos e valores de atributos.

Essa propriedade motiva usar tais reticulados em, por exemplo, mineração de dados, pois tais estruturas explicitam o espaço de procura em métodos como classificação.

Diversos algoritmos para classificação com reticulados (alguns, com o denominado pseudo reticulado) são apresentados e comparados neste trabalho, além de também comparados a métodos clássicos de mineração de dados.

Contudo, os benefícios do uso do reticulado de conceitos vêm acompanhados dos onerosos custos de sua construção.

Conforme já mencionado, o tamanho (número de conceitos formais) do reticulado de conceitos cresce de modo exponencial em relação à entrada.

A entrada, no caso, é o contexto formal, composto por objetos, atributos, valores de atributos e relação de incidência.

O tamanho do reticulado de conceitos depende mais dessa ultima do que dos demais conjuntos do contexto formal, objetos, atributos e valores de atributos.

A relação de incidência, caso contenha, por exemplo, todas as combinações de valores de atributos (ou apenas atributos, em contextos formais mono-valorados), implica no máximo número de conceitos formais.

Por outro lado, uma relação de incidência mais homogênea permite menores tamanhos de reticulados de conceitos, a despeito dos números de objetos, atributos e seus valores.

Portanto, os onerosos custos para construção e manipulação de reticulados de conceitos são o grande revés dos algoritmos aqui apresentados. Permitem um estudo das precisões dos algoritmos.

Mostram-se, para cada conjunto e considerando as médias, as propostas que conseguem melhores precisões em diversos experimentos, "holdout" 75%25%, "holdout" 50%50%, validação cruzada em quatro passos e em dez passos.

Em cada linha e em cada coluna enumeram-se os algoritmos com melhor precisão, em determinado experimento (linh e para determinado conjunto (colun).

As duas próximas têm também, na ultima linha, os melhores algoritmos mais frequentes nos experimentos.

"Similares1" e "Similares2" são os algoritmos que conseguem melhores precisões médias.

O primeiro desses algoritmos tem o melhor desempenho no experimento "holdout" 50%50%, enquanto o segundo é o melhor, segundo precisões médias, nos demais experimentos, "holdout" 75%25% e nas validações cruzadas.

"Rulearner" e "Galois" também conseguem as melhores precisões médias em alguns experimentos, "holdout" 75%,25%, por exemplo.

Alguns algoritmos sempre aparecem dentre os melhores para alguns conjuntos, "Rulearner" para HR, "Galois" para PO, "Similares2" para LE, M, VO.

Análise formal de conceitos, com seus reticulados de conceitos, tem potencial para contribuir em métodos como classificação.

Essa área tem como principais vantagens a fundamentação matemática e os diagramas de reticulados de conceitos, que, como já mencionado, explicitam o espaço de procura dos algoritmos.

Os algoritmos aqui mostrados, na maioria dos experimentos, conseguem melhores desempenhos que métodos clássicos de classificação.

Tais algoritmos têm algumas propriedades comuns, alguns produzem regras, enquanto outros classificam percorrendo conceitos formais, alguns usam o pseudo reticulado, mas outros, o reticulado de conceitos, alguns dos algoritmos requerem parâmetros de entrada, enquanto outros os dispensam.

O algoritmo aqui proposto, em suas versões "Similares1" e "Similares2", além de propôr uma medida de similaridade para conceitos formais, consegue excelentes precisões em muitos experimentos.

Contudo, apesar do bom desempenho dos algoritmos de classificação com reticulados, eles têm o ônus do tamanho exponencial de tais estruturas.

E necessário diminuir os tempos de execução desses algoritmos, preservando-se as precisões alcançadas, para que seja incentivada a aplicação da análise formal de conceitos em problemas verdadeiros de mineração de dados, onde os repositórios possuem até mesmo milhões de registros (afinal, o tamanho dos conjuntos é uma das motivações para mineração de dados).

O algoritmo "Legal" requer quatro parâmetros de entradas, cujos melhores valores sequer seus autores recomendam com precisão.

Embora alguns experimentos sugiram, tais valores nem sempre permitiram melhores resultados aqui.

Estes anexos mostram diversos testes de valores para tais parâmetros.

Como são quatro parâmetros, testar todas as suas possibilidades de valor (de 0 a 1, com incremento de 01) demandaria quase 15 mil execuções do programa para cada conjunto tarefa inviável.


Tais experimentos são, conjuntos originais, "holdout" A a, "holdout" 50%, 50% A a.

O leitor observe que, a exemplo da unidade de medida adotada em precisão, mostramos os valores de parâmetro também em porcentagem.

As últimas linhas comparam os melhores valores.

Precisões (%) de "Legal" para conjuntos originais.

Precisões (%) de "Legal" para conjuntos 75%, 25% A.

Precisões (%) de "Legal" para conjuntos 75%, 25% B.

Precisões (%) de "Legal" para conjuntos 75%, 25% C.

Precisões (%) de "Legal" para conjuntos 75%, 25% D.

Precisões (%) de "Legal" para conjuntos 50%, 50% A.

Precisões (%) de "Legal" para conjuntos 50%, 50% B.

Precisões (%) de "Legal" para conjuntos 50%, 50% C.

Precisões (%) de "Legal" para conjuntos 50%, 50% D.

O algoritmo "Legal", dependendo do parâmetro, insere mais ou menos conceitos formais no reticulado.

Como o crescimento desse é exponencial em relação à entrada (em especial, ao conjunto incidência do contexto formal), tal parâmetro proporciona grandes diferenças de tempo, na execução do programa.

Mostram os tempos consumidos (em milissegundos), para diversos valores.

O leitor observe que, quanto mais rigoroso o parâmetro (ou seja, mais alto), menor o reticulado (o que não implica, necessariamente, em melhoria na precisão).

Tempos (ms) de "Legal" para conjuntos originais, com diferentes.

Tempos (ms) de "Legal" para conjuntos 75%, 25%, com diferentes.

Tempos (ms) de "Legal" para conjuntos 50%, 50%, com diferentes.

