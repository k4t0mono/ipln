O objectivo do trabalho consiste em seleccionar um classificador a partir do conjunto deOtreino e com o modelo obtido classificar os exemplos do conjunto de teste.

OPretende-se descrever sumariamente as técnicas utilizadas, descrever os algoritmosOaplicados, experimentar os dados fornecidos e fazer a análise dos resultados obtidos.

Foram utilizadas as ferramentas Weka e R.

Os dados utilizados neste estudo são constituídos por dois datasets, um para treino e outro para testes.

O dataset de treino é composto por 620 instâncias, sem valores em falta, de 15 atributos (incluindo a classe) do tipo numérico.

Existem duas classes, com valores {0,1}.

O dataset de teste é composto por 70 instâncias.

Os dados originais foram trabalhados de forma a poderem ser facilmente utilizados pelas aplicações utilizadas, o R e o Weka.

Em ambos os casos utilizou-se o formato CSV sendo utilizado no R o separador (|*) e no Weka o separador ",".

Em ambos os datasets foi adicionada uma linha com o cabeçalho das colunas.

Utilizou-se o EXCEL e o NOTEPAD para preparação dos datasetes.

O dataset de treino foi "discretizado" utilizando as ferramentas existentes no Weka.

Utilizou-se a seguinte sequência de "comandos", Preprocess SoH Choose SoH filters SoH supervised SoH attribute SoH discretize e finalmente "apply".

Esta alteração também é simples de ser realizada, antes da importação dos dados, utilizando o Excel.

Neste caso bastaria substituir, por exemplo, nos dados da última coluna, onde tem 0 seria A e onde tem 1 seria B.

Se os dados estiverem numa folha de cálculo Excel, fazendo "Gravar como." CSV, estes poderão ser guardados em formato csv, utilizáveis pelo R, utilizando a função read_csv.

Outras formas de introdução dos dados no R poderão ser utilizadas, nomeadamente, Introdução manual dos dados Obtenção de dados existentes na Internet Ligação a uma base de dados qualquer (por exemplo, Access) Obtenção de dados de outra aplicação por exemplo, SPSS, Excel, et.

Este método consiste numa divisão do conjunto de dados em dois, um que vai criar o modelo e outro que vai permitir a obtenção do erro associado a esse modelo.

Essa divisão é feita mediante uma certa percentagem.

A ideia deste método é dividir o conjunto de dados em k partes iguais, determinar o modelo para k1 classes e prever o resultado na classe restante.

O processo é repetido k vezes, deixando para testar, uma parte diferente da anterior e criando o modelo com as restantes.

No fim, vamos obter k estimativas para o erro dado em cada um das partições.

No exemplo "dados_treino" é o "data frame" onde ficarão guardados os dados.

O local e nome do ficheiro csv com os dados é designado em "dados/treino_csv", sendo este caminho, por defeito, desde o local onde o R se encontra instalado.

O "header" é uma flag que indica se o ficheiro tem ou não cabeçalho.

Para indicar à função o separador dos dados utilizado no ficheiro csv utiliza-se a flag "sep", no exemplo o separador é o ponto e vírgula.

Tendo os dados guardados num "data frame" a árvore de decisão poderá ser obtida utilizando-se a função "rpart".

Para melhor interpretação dos dados obtidos o R proporciona algumas ferramentas gráficas que possibilitam obter alguns gráficos em formato de árvore.

Utilizando alguns dos parâmetros das funções usadas é possível obter resultados gráficos com maior pormenor.

Poderemos avaliar o grau de confiança no modelo obtido.

Para isso poderemos usar o modelo para tomar decisões e verificar que percentagem destas é acertada.

Procede-se do seguinte modo, Divide-se a amostra em duas partes Uma das partes é utilizada para construir o modelo A outra é utilizada para testar o modelo.

A leitura que podemos ter destes dados será, por exemplo para a linha 586, que existe uma probabilidade de 95% em acontecer o caso A.

Imagine-se, por exemplo, que A representava a "Atribuição de Crédito" e B a "Não Atribuição de Crédito" num banco.

Neste exemplo em particular existe a confiança de 95% em que será concedido um crédito.

Seguindo a mesma lógica, por exemplo na linha 580, haverá uma probabilidade muito baixa em se conceder crédito.

O erro do modelo obtido poderá ser gerado fazendo, O que representa neste caso uma taxa de erro baixa.

O algoritmo completo em R, "Arvore de decisão" com Percentage Split.

Para geração de n ciclos para avaliação do erro criou-se a seguinte rotina, Para n=1000 temos, Obtemos um erro médio de 14.

Aplicaram-se os mesmos procedimentos utilizados no ponto anterior.

No caso particular do Descriminante Linear utiliza-se a função "lda" existente na "library" MASS.

O algoritmo completo em R, "discriminante linear".

Para geração de n ciclos para avaliação do erro criou-se a seguinte rotina, Para n=1000 temos, Obtemos um erro médio de 14 e 15 ligeiramente inferior ao gerado pela árvore de decisão.

Apesar da diferença pouco expressiva poderemos afirmar que o método mais aconselhado neste caso será o "Descriminante Linear".

Tal como referido no início foi necessário proceder à descritização dos dados para se poder utilizar o método j48 no Weka.

Os valores do dataset de treino antes da discretização seguem a seguinte distribuição, Após a descretização seguem a seguinte distribuição, Utilizando o Weka iremos obter modelos de classificação fazendo variar o valor do factor de confiança.

Será igualmente aplicada a "Validação Cruzada" e a " Percentage Split" como metodologia de divisão dos dados.

Sempre que a taxa de erro nos dados de teste seja significativamente superior à obtida nos dados de treino poderemos ajustar o Factor de confiança.

Nestes casos, deve diminui-se o valor do factor de confiança para forçar uma poda "maior" e obter um modelo mais genérico.

Nos casos em que os dados de teste não variam significativamente relativamente aos dados de treino o Factor de confiança pode ser aumentado de forma a obter-se um modelo com uma árvore mais detalha.

Apresentam-se a seguir os dados gerados para um factor de confiança de 1% e 25%.

Apresentam-se os resumos para outros valores do factor de confiança.

A árvore de decisão gerada é a seguinte, A Arvore de decisão será a seguinte, Tal como na Validação Cruzada apresentam-se a seguir os dados gerados para um factor de confiança de 1% e 25%.

Apresentam-se os resumos para outros valores do factor de confiança.

Utilizou-se uma percentagem de divisão de 70%.

A arvore de decisão correspondente, A arvore de decisão correspondente, Apresenta-se a seguir um resumo dos diversos estudos realizados variando o Factor de confiança c e o método de utilização dos dados entre a "Validação Cruzada" e o "Percentage Split".

Verifica-se que para um factor de confiança mais baixo os registos classificados correctamente são mais elevados.

Neste caso em particular o factor de confiança 25% obteve o melhor resultado.

No Percentage Split os valores resultados obtidos são melhores, todos eles, que na Validação Cruzada.

Tal como na Validação Cruzada o Factor de confiança de 25% obteve o melhor índice de "Registos correctamente classificados".

O valor de 25% é o valor por defeito no J48.

No gráfico seguinte têm-se uma percepção melhor dos valores obtidos.

