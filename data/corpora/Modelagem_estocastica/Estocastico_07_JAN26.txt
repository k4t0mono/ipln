Sequências de variáveis aleatórias independentes e identicamente distribuídas são processos estocásticos, mas nem sempre elas são interessantes como modelos porque elas comportam-se mais ou menos da mesma maneira.

Com o objetivo de introduzir maior variabilidade pode-se permitir alguma dependência com o passado, de forma de determinar equações de recorrência.

Cadeias de Markov homogêneas e discretas no tempo possuem estas caracter ísticas, já que elas podem sempre ser representadas por uma equação de recorrência estocática é uma sequência independente e identicamente distribuida (IID), independente do estado inicial.

A dependência probabilística com o passado é feita somente com o estado imediatamente anterior, mas esta limitada quantidade de memória é suficiente para produzir uma grande variedade de comportamentos.

A sequência de variávies aleatórias de um conjunto E é chamado processo estocástico de tempo discreto com espaço de estado E.

Neste texto, este espaço é enumerável e seus elementos serão denotados.

Se Xn = xn, o processo é dito estar no estado xn no tempo n, ou visita o estado xn no tempo n.

Já que estamos interessados em sistemas não determinísticos, pensamos como variáveis aleatórias definidas sobre um espaço de probabilidades.

Muitos sistemas tem a propriedade de que dado um estado presente, os estados passados não influênciam o futuro.

Esta propriedade é chamada de propriedade de Markov e um sistema que tem essa propriedade é chamado cadeia de Markov.

Esta propriedade é precisamente definida por Seja um processo estoc ástico a tempo discreto com um espaço enumerável.

Se para todo inteiro n e todo estado ambos os lados estão bem definidos, este processo estocástico é chamado Cadeia de Markov.

Ela é dita Cadeia de Markov Homogênea (CMH) se o lado direito é independente de n.

As probabilidades condicionais são chamadas probabilidades de transição da cadeia.

Uma probabilidade de transição é dita estacionária se independe de n.

Considere uma máquina que no começo de um determinado dia ou está quebrada ou está funcionando.

Assuma que se a máquina está quebrada no começo do n-ésimo dia, existe uma probabilidade p de que a máquina esteja funcionando.

Além disso assuma que se a máquina esta funcionado no n-ésimo dia existe uma probabilidade q de ela estar quebrada.

Finalmente seja a probabilidade de que a máquina está quebrada no 0-ésimo dia.

O estado 0 corresponde à máquina quebrada e o estado 1 corresponde à máquina que está operando.

Seja Xn a variável aleatória denotando o estado da máquina no tempo n.

As probabilidades podem ser obtidas por uma abordagem diferente.

Suponha que desejamos escolher tal que sejam independentes de n.

Assim nós vemos que se começa com a distribuição inicial Seja Xn, uma cadeia de Markov no espaço de estados E.

A função definida é chamada função de transição da cadeia.

Ela é tal que se a cadeia de Markov for estacionária, vemos que a propriedade de Markov segue.

Em outras palavras, se a cadeia de Markov está num estado x no tempo n, então não importa como ela foi para x, ela tem a probabilidade P de estar em y na próxima etapa.

Por esta razão os números P são chamados probabilidades de transição de uma etapa da cadeia de Markov.

A função definida é chamada distribuição inicial da cadeia.

A distribuição pode ser expressa em termos da função de transi ção e da distribuição inicial.

Satisfaz a propriedade de Markov e tem probabilidade de transição estacionária.

Inicialmente algumas dessas bolas estão na caixa A e o restante está na caixa B.

Um número entre 1 e d é escolhido aleatoriamente e a bola com o correspondente número é transferida para outra caixa.

Este processo é repetido indefinidamente com os sorteios sendo independentes.

Seja Xn o número de bolas na caixa A no n-ésima sorteio.

Então é uma cadeia de Markov.

Suponha que existam x bolas na caixa A no tempo n.

Então com probabilidade x d a bola tirada na (n + 1)-ésima tentativa será transferida para a caixa B.

Similarmente, com probabilidade x a bola tirada na (n+1)-ésima tentativa da caixa B será transferida para a caixa A, resultando em x + 1 bolas na caixa A no tempo n + 1.

Um estado de uma cadeia de Markov é chamado absorvente.

Seja uma Cadeia de Markov sobre E tendo uma função de transição P.

Vamos mostrar como probabilidades condicionais podem ser escritas em termos de P.

Vamos começar com o fato de que o lado direito da igualdade acima pode ser reescrito.

Portanto,será mais conveniente reescrever a equação acima.

Para uma cadeia de Markov tendo um número finito de estados, a equação acima pode ser pensada como a n-ésima potência de uma matriz P.

Seja uma distribuição inicial de uma Cadeia de Markov.

Esta fórmula permite calcular a distribuição de Xn em termos da distribuição inicial e a etapa n da função distribuição Pn.

Se conhecermos a distribuição de X0, podemos usar a equação acima para esncontrar a distribuição de X1.

Então, conhecedo a distribuição de X1, podemos encontrar X2 e assim por diante.

Usaremos a notação Px para denotar probabilidades de vários eventos em termos de cadeias de Markov começando em x.

Assim denota a probabilidade de uma cadeia de Markov começando em x estar em um estado a no tempo 3 mas não no tempo 1 ou 2.

Em termos de notação pode ser reescrito.

Suponha que o espaço E é finito.

Neste caso podemos pensar P como uma matriz de transição tendo d+1 linhas e colunas.

Similarmente, podemos considerar Pn como uma matriz de transição na n- ésima etapa.

A distribuição inicial pode ser pensada como um vetor linha de dimensão (d + 1).

Se denotarmos o vetor linha de dimensão então podem ser reescritas.

Seja A um subconjunto de E.

O "hitting times" TA de A é definido.

Em outras palavras, TA é o primeiro tempo positivo no qual a cadeia de Markov está em A.

Uma importante equação envolvendo hitting times é a para provar que os eventos, são disjuntos e que temos na realidade decomposto o evento de acordo com o hitting time de y.

Então denota a probabilidade que a Cadeia de Markov começando em x estará no estado y em algum tempo positivo.

Em particular, denota a probabilidade de uma CM, tendo partindo de y retornar para y.

Um estado y é dito recorrente e transiente.

Se y é um estado recorrente, uma CM que começou em y retornará para ele com probabilidade um.

Se y é um estado transiente, uma CM tem probabilidade de nunca retornar para ele.

Se y é um estado absorvente, assim um estado absorvente é necessariamente recorrente.

Seja a função indicadora do conjunto y.

Seja N(y) o número do vezes que a cadeia passou pelo estado y.

Já que 1y(Xn) = 1 se a cadeia está no estado y e no tempo n e 1y(Xn) = 0 caso contrário.

Sejam m e n inteiros positivos.

A probabilidade de que a CM começando em x visite o estado y no tempo m e torne a visitá-lo n unidades de tempo depois é Px(Ty = m)Py(Ty = n).

Usamos a notação Ex para denotar valores esperados de variáveis aleatórias definidas em termos de uma CM começando em x.

Com isto, temos a seguinte definição Seja Ex o valor esperado de alguma variável aleatória.

Denota o número médio de visitas a y por uma CM começando em x O teorema abaixo descreve a diferença fundamental entre um estado transiente e um recorrente.

Se um estado y é transiente, então não importa onde a CM começou, ela faz somente um número finito de visitas a y e o número esperado de visitas a y é finito.

Por outro lado, se y é recorrente, ele é visitado infinitas vezes.

Se a cadeia começa de um outro estado x, por ser impossível para ela atingir y.

Se é possivel, entretanto, e cadeia visita y ao menos uma vez, ela o fará para sempre.

Se uma variável aleatória não negativa tem uma probabilidade positiva de ser infinita, seu valor esperado é infinito.

Uma CM é chamada cadeia transiente se todos os seus estados são transientes e cadeia recorrente se todos os seus estados são recorrentes.

Uma cadeia de Markov tendo um espaço finito deve ter ao menos um estado recorrente e não pode ser uma cadeia transiente.

Se E é finito e todos os seus estados são transientes.

Sejam x e y dois estados não necessariamente distintos.

Dizemos que x leva para y se xy > 0.

X leva para y se e somente se Pn(x,y) > 0 para algum inteiro positivo n.

Além disso se x leva para y e este leva para z então x leva para z.

Seja x um estado recorrente suponha que x leva para y.

Então y é recorrente.

Assumimos que y 6= x pois, de outra forma não há o que provar.

Vemos que Px(Ty = n) > 0 para algum inteiro positivo n.

Seja n0 o menor inteiro positivo.

Nenhum dos estados são iguais a x ou y.

Se uma delas fosse igual a x ou y, seria possível ir de x para y com probabilidade positiva em menos de n0 etapas.

Mostraremos agora que yx = 1.

Suponha por absurdo que yx < 1.

Então uma CM começando em y tem probabilidade positiva de nunca atingir x.

Uma CM, começando em x tem uma probabilidade positiva de visitar os estados sucessivamente nas primeiro n0 etapas e nunca retornar para x depois do tempo n0.

Mas se isto acontece, a CM nunca retorna para x em qualquer tempo, então isto está em contradição com a suposição de que x é um estado recorrente.

Já que yx = 1, existe um inteiro positivo n1 tal que Pn1(x,y) > 0.

Portanto y é um estado recorrente.

Já que y é recorrente e vai para x, vemos que o teorema a está verificado.

Um conjunto de estados não vazio C é dito fechado se nenhum estado dentro de C leva para um estado fora de C.

De fato, mesmo a partir da fraca condição pode-se provar que C é fechado.

A partir de indução.

Se C é fechado, então uma CM começando dentro de C permanecerá em C com probabilidade um, por todo o tempo.

Se a é um estado absorvente, então fag é fechado.

Um conjnuto fechado C é dito irredutível se x vai para y para todas as escolhas de x e y em C.

Segue a partir do teorema que se C é um conjunto fechado irredutível, então então todo estado em C ou é recorrente ou é transiente.

Seja C um conjunto fechado e irredutível de estatos recorrentes.

Uma Cadeia de Markov irredutível é uma cadeia cujo espaço de estados é irredutível, isto é, uma cadeia em que todo estado leva para outros estados e de volta para ele mesmo.

Tal CM é necessariamente uma cadeia recorrente ou uma cadeia transiente.

O corolário anterior implica, em particular, que uma CM irredutível e recorrente visita todos os estados infinitamente com probabilidade um.

Dissemos anteiormente que se E é finito, ele contém ao menos um estado recorrente.

O mesmo argumento pode ser usado para mostrar que qualquer estado conjunto fechado de estados contém ao menos um estado recorrente.

Agora seja C um estado finito e irretutível.

Vemos que ou todo estado em C ou é transiente ou é recorrente, e que C tem ao menos um estado recorrente, portanto todo estado em C é recorrente.

Isto se resume no seguinte teorema, seja C um conjunto fechado irredutível finito de estados.

Então todo estado em C é recorrente.

Considere uma cadeia de Markov tendo um número finito estados.

O teorema implica que se a cadeia é irredutível ela deve ser recorrente.

Se a cadeia não é irredutível, podemos usar o teorema para determinar quais são recorrentes e quais são transientes.

Dada a matriz de transição abaixo vamos determinar quais estados são recorrentes e quais são transientes.

Como uma primeira etapa determinamos, por inspeção, quais estados levam para outros estados.

Isto pode ser indicado na forma matricial.

Os elementos x,y desta matriz são + ou 0 dependendo se x,y é positivo ou zero, dependendo se x leva ou não para y.

Se P(x,y) > 0, então x,y > 0.

O contrário não é sempre verdadeiro.

O estado 0 é um estado absorvente, e daí também é um estado recorrente.

Também a partir da matriz acima vemos que é um conjunto fechado irredutível.

Então o teorema implica que são estados recorrentes.

Os estados 1 e 2 são ambos levados para 0, mas nunca são obtidos a partir do zero.

Assim do teorema vemos que 1 e 2 são estados transientes.

Denotemos por ET a coleção de estados transientes em E e ER a coleção de estados recorrentes em E.

O conjunto pode ser decomposto em conjuntos fechados irredutíveis disjuntos.

O próximo teorema mostra que tal decomposição é sempre possível quando ER é não vazio.

Suponha que o conjunto ER de estados recorrentes é não vazio.

Então ER é a união de uma quantidade enumerável de conjuntos fechados irredutíveis disjuntos.

Escolha x e seja C o conjunto de todos os estados y tais que x vai para y.

Já que x é recorrente, x,x = 1 e daí x.

Verifiquemos que C é fechado.

Suponha que y vai para z.

Já que x vai para y e y vai para z, concluí-se que x vai para z.

Assim z está em C.

Logo C é fechado.

Suponha que y e z estão em C.

Já que x é recorrente e x vai para y, segue a partir do teorema que y vai para x.

Já que y vai para x e este para z.

Portanto C é irredutível.

Para completar a demonstração basta mostrarmos que se C eD são dois subconjuntos fechados irredutíveis de ER então ou eles são disjuntos ou são idênticos.

Para isto, suponha que eles não são disjuntos e que x pertença a ambos.

Agora x vai para y, já que x está em C e este é irredutível.

Já que D é fechado, x está em D, e x vai para y, e portanto y está em D.

Assim todo estado em C também está em D.

Similarmente todo estado em D está em C, logo eles são idênticos.

Podemos usar a decomposição de espaço de estados de uma CM para entender o comportamento de um tal sistema.

Se a CM começa em um dos conjuntos fechados irredutíveis Ci de estados recorrentes, ela pemarecerá em Ci e, com probabilidade um, visitará todos os estados em Ci infinitas vezes.

Se uma CM começa em CT ela permanecerá em CT para sempre ou, algum tempo depois entrará em algum do Ci e ali permanecerá visitando todos os estados.

Seja C um conjunto fechado e irredutível de estados recorrentes, e seja C(x) = Px(TC < 1) a probabidade de que uma cadeia de Markov começando em x eventualmente alcance C.

Já que a cadeia permanecerá em C, denominamos C(x) a probabilidade de que uma cadeia começando em x seja absorvida por C.

Claramente C(x) = 1 x, e c(x) = 0 se x é um estado recorrente fora de C.

Entretanto ainda não é claro como calcular C(x).

Se existem somente um número finito de estados transientes, e em particular se C é finito, é sempre possível calcular C(x), xT, resolvendo um sistema de equaçoes lineares em existem tantas equações quanto incógnitas, membros de CT.

Para entender o porque disto, observe que se uma cadeia começando em x pode entrar em C entrando em C no tempo 1 com probabilidade P(x,y) ou, estando em CT entrar em C em algum tempo futuro com probabilidade.

A equação acima é válida quando CT é finito ou infinito, mas não é claro como resolvê-la quando CT é inifito.

Uma dificuldade adicional é que se CT é infinito a equação acima não tem solução única.

Suponha que o conjunto CT de estados transientes é finito e seja C um conjunto fechado irredutível de estados recorrentes.

Então o sistema de equações tem solução única.

A soma dos dois primeiros termos é Px(Tc),e o terceiro termo se reduz.

Por indução concluímos que, para todo inteiro positivo n,com as suposições do teorema acima, CT é um conjunto finito.

Alternativamente, podemos obter essas probabilidades subtraindo 0(1) e 0(2) da unidade, já que existem somente um número finito de estados transientes.

Já que existem somente um número finito de estados transientes e cada estado transiente é visitado somente um número finito de vezes, a probabilidade que o estado recorrente seja atingido é 1.

Uma vez que uma CM começando em um estado transiente x, entra em um conjunto fechado e irredutível C de estados recorrentes, ela visita todos os estados de C.

Seja Xn uma CM tendo o espaço de estados E e uma função de transição P(x,y).

Se são números não negativos somando um, então é chamada Distribuição Estacionária (DE).

Suponha que uma DE existe.

Então, como veremos em breve, independentemente da distribuição da cadeia, a distribuição de Xn se aproxima.

Em tais casos, é algumas vezes chamada de distribuição de estados constante.

Se X0 tem uma DE como distribuição inicial, então implica para todo n e daí segue que a distribuição de Xn é independente de n.

Suponha por outro lado que a distribuição de Xn é independente de n.

Consequentemente é uma distribuição estacionária.

Em resumo, a distribui ção de Xn é independente de n se e somente se a distribuição inicial é uma distribuição estacionária.

Suponha agora que é uma distribuição estacionária.

Seja a distribuição inicial.

Então usando o teorema da convergência limitada podemos fazer n.

A expressão acima estabelece que, independente da distribuição inicial, para grandes valores de n a distribuição de Xn é aproximadamente igual a DE.

Isto implica que é a única DE.

Pois se houvesse alguma outra DE poderíamos usá-la para a distribuição inicial.

Considere um sistema descrito por uma CM tendo função de transição P(x,y) e única DE.

Suponha que começamos observando o sistema depois de ele de algum tempo, digamos n0 unidades de tempo para algum n0 grande.

As variáveis aleatórias, também formam uma CM com função de transição P.

Com o objetivo de determinar probabilidades únicas paraeventos definidos em termos da cadeia Yn, necessitamos conhecer sua distribuição inicial, que é a mesma da distribuição de Xn0 Na maioria das aplicações práticas é muito difícil de determinar essa distribuição exatamente.

Podemos não ter escolha e assumir que, tem distribuição estácionária como sua distribuição inicial.

Uma cadeia de vida e morte é uma CM definida sobre e com função de transição.

Concluímos que uma cadeia de morte e vida tem uma única distribui ção estacionária.

Da equação anterior concluímos que qualquer solução é identicamente nula ou tem soma infinita, e daí não tem distribuição estácionária.

Em resumo, uma cadeia tem distribuição estacinária se e somente se é satisfeita e, quando existe, ela é dada.

Suponha agora que d < 1.

Usando o mesmo argumento utilizado, concluímos que a única distribuição estacionária é dada.

Considere novamente a cadeia de Ehrenfest e suponha que d = 3.

Encontraremos a DE.

Esta é uma cadeia de morte e vida irredutível.

Assim a única distribuição estacionária é dada.

A equação não é satisfeita para a cadeia do exemplo anterior já que Pn(x,x) = 0 para valores impares de n.

Podemos modificar levemente a cadeia de Ehrenfest para evitar tal "periodicidade".

Exemplo.

Cadeia de Ehrenfest modificada Suponha que temos duas caixas denominadas A e B e d bolas numeradas.

Inicialmente algumas bolas estão na caixa A e o restante está em B.

Um inteiro entre é selecionado aleatoriamente e a bola marcada pelo respectivo número é removida da caixa.

O processo é repetido indefinidamente, sendo os sorteios independentes.

Seja Xn o número de bolas na caixa A depois do n-ésimo sorteio.

Então é uma CM sobre.

Vamos encontrar a distribuição estacionária da cadeia para d = 3.

Começamos com uma bola na caixa A e duas bolas na B.

Assim P é a probabilidade de que a bola na caixa A seja selecionada e a caixa B seja selecionada.

Depois, P é a probabilidade de que a bola selecionada está na caixa B e a caixa selecionada é a caixa A.

A probabilidade P = 0, já que ao menos uma bola é transferida.

Finalmente, P(1,1) pode ser obtido subtraíndo da unidade.

Alternativamente, P(1,1) é a probabilidade que ou selecionada está na caixa A e a caixa A é selecionada, ou a bola sorteada na caixa B e a caixa B é selecionada.

As outras probabilidades são calculadas similarmente.

Esta CM é uma cadeia de morte e vida irredutível.

Podemos ver que x é a mesma que no exemplo anterior e portanto a DE é a mesma.

Considere uma cadeia de morte e vida irredutível com DE.

Suponha que P(x,x) = rx = 0, como uma cadeia de Ehrenfest.

Então em cada transição a cadeia de morte e vida se move ou uma etapa para a direita ou uma etapa para a esquerda.

Assim a cadeia pode pode retornar para seu ponto de partida somente depois de um número par de transições.

Em outras palavras, P(x,x) = 0 para valores ímpares de n.

Para tal cadeia a fórmula não é mais satisfeita.

Existe uma maneira de manipular tal situação.

Seja uma sequência de números.

Se para algum número finito L então vamos mostrar que para algum par x,y de estados para uma Cadeia de Markov arbitrária.

Seja o número médio de visitas da CM a y durante os tempos.

O valor esperado de tais visitas para uma cadeia começando em x é dado.

Suponha agora que o estado y é recorrente.

Seja o tempo médio de retorno para y.

Para uma cadeia começando em y se este tempo de retorno tem valor esperado finito.

Considere uma CM começando no estado y Com probabilidade um ela retorna para y muitas vezes.

Seja Tr o tempo da r-ésima visita ao estado y, o tempo de espera entre a (r+1)-ésima visita a y e a r-ésima visita a y.

As variáveis aleatórias W1,W2 são independentes e identicamente distribuidas e daí elas têm uma média comum.

Isto pode ser visto usando o fato e então segue por indução.

No tempo n a cadeia fez exatamente r visitas a y.

Assim a r-ésima visita ao estado y ocorre em ou antes do tempo n, e a (r + 1)-ésima visita a y ocorre depois do tempo n, isto é para n suficientemente grande.

Já que com probabilidade um quando n ! 1, essas desigualdades juntas implicam.

Seja y um estado recorrente como antes, e X0 com distribuição arbitrária.

Então a cadeia pode nunca alcançar y.

Se a cadeia alcança y, o argumento acima é válido, é daí, com probabilidade um teorema da teoria da medida, conhecido como teorema da convergência dominada, não permite concluir.

Uma vez que a cadeia alcança y ela retorna para y em média a cada my unidades de tempo.

Assim se Ty < 1 e n é grande, a proporção das n primeiras unidades de tempo em que a cadeia está no estado y.

Do Corolário e do teorema anterior, imediatamente obtemos o próximo resultado.

Seja C um conjunto irredútivel fechado de estados recorrentes.

Se my = 1 o lado direito das equações são todos iguais a zero, e daí é satisfeita.

Um estado recorrente y é chamado recorrente nulo se my = 1.

A partir do teorema vemos que se y é recorrente nulo.

O estado recorrente y é chamado recorrente positivo se my < 1.

Segue do teorema que se y é recorrente positivo.

Considere uma cadeia de Markov começando em um estado recorrente y.

Segue o teorema que se y é recorrente nulo, então com probabilidade um, a proporção de tempo que que a a cadeia esta no estado y durante as primeiras n unidades de tempo tende a zero quando n1.

Por outro lado, se y é um estado recorrente positivo, então, com probabilidade um, a proporção de tempo em que a cadeia está no estado y durante as n primeiras unidades de tempo tende ao limite positivo 1.

Seja x um estado recorrente positivo e suponha qua x vai para y.

Então y é um estado recorrente positivo.

A partir deste teorema vemos que se C é um conjunto irredutível fechado, então todo estado em C é transiente, todo estado em C é recorrente nulo, ou todo estado em C é recorrente positivo.

Uma CM é chamada cadeia recorrente nula se todos seus estados são recorrentes nulos e cadeia recorrente positiva se todos seus estados são positivos recorrentes.

Vemos portanto que uma CM irredutível é uma cadeia transiente, uma cadeia recorrente, ou uma cadeia positiva recorrente.

Se C é um conjunto finito fechado de estados, então C tem ao menos um estado positivo recorrente.

Se C é finito e cada estado em C é transiente ou recorrente nulo, então é satisfeita.

Seja C um conjunto de estados fechado irredutível e recorrente.

Então todo estado em C é recorrente positivo.

Já que C é um conjunto fechado e finito, existe ao menos um estado recorrente positivo em C.

Já que C é irredutível, todo estado em C é positivo recorrente pelo teorema.

Uma CM irredutível tendo um número finito de estados é recorrente positiva.

Uma CM irredutivel tendo um número finito de estados não tem estados recorrentes nulos.

Demonstração, se y é um estado recorrente, então pelo teorema, y está contido em um conjunto C irredutível fechado de estados recorrentes.

Já que C é necessariamente finito, segue do teorema que todos os estados qua estão em C, são recorrentes positivos.

Assim todo estado recorrente é recorrente positivo.

Aqui determinaremos quais CM tem distribuição estacionária e quando tem uma única distribuição.

Seja uma distribuição estacionária e seja m um inteiro positivo.

Seja um estado estacionário.

Se x é um estado transiente ou recorrente nulo, então (x) = 0.

Segue do teorma acima que uma CM sem estados positivos recorrentes não tem distribuição estacionária.

Uma CM irredutível positiva recorrente tem uma única cadeia distribuição estacionária.

Assim se existe uma distribuição estacionária, deve ser dada.

Para completar a prova do teorema precisamos mostrar que a função é de fato uma distribuição estácionária.

Como ela não é negativa Uma CM irredutível é recorrente positiva se e somente se ela tem uma distribuição estacionária.

Se uma CM tem um número finito de estados é irredutível se ela tem uma única distribuição estacionária.

Combinando o corolário e o teorema temos o próximo resultado Corolário.

Seja, uma CM irredutível positiva recorrente tendo distribuição estacionária.

Seja a distribuição sobre E, isto é, seja (x) tal que x são os números não negativos cuja soma é igual a 1, e seja C um subconjunto de E.

Dizemos que (x) está concentrada sobre C.

Usando essencialmente o mesmo argumento utilizado para provar o Teorema, podemos obter um resultado um pouco mais geral.

Seja C um conjunto fechado irredutível de estados recorrentes positivos.

Então a CM tem uma única distribuição estacionária concentrada sobre C.

Suponha C0 e C1 dois conjuntos irredutíveis fechados distintos de estados recorrentes positivos de uma CM.

Segue do Teorema que a CM tem uma distribuição estacionária concentrada em C0 e uma distribui ção estacionária 1 concentrada em C1, tais que 6= 1.

Além disso, as distribuições,são distribuições estacionárias distintas.

Combinando os Teoremas e suas consequências, obtemos o Corolário.

Seja EP o conjunto dos estados recorrentes positivos de uma CM.

A cadeia não tem distribuições estacionárias.

É um conjunto irredutível, a cadeia tem uma única distribuição estacionária.

Não é um conjunto irredutível, a cadeia tem um número infinito de distribuições estacionárias distintas.

Considere agora uma CM com um número finito de estados.

Então todo estado recorrente é positivo e existe pelo menos um desses estados.

Há duas possibilidades, cada conjunto de estados recorrentes ER é irredutível e existe um única distribuição estacionária, ou ER pode ser decomposto em dois ou mais conjuntos fechados irredutíveis e há um número infinito de distribuições estacionárias distintas.

A última possibilidade vale para uma CM sobre onde são ambos estados absorventes.

Vimos anteriormente que se Xn, n > 0, é uma CM irredutível recorrente positiva tendo como distribuição estacionária.

Nessa seção veremos quando o forte resultado vale e o que acontece quando não vale.

O inteiro positivo d é dito um divisor do inteiro positivo n se é um inteiro.

Se I é um conjunto não vazio de inteiros positivos, o máximo divisor comum de I, denotado por mdc I, é definido por ser o maior inteiro d que divida todo inteiro de I.

Em particular, se I, então mdc I = 1 e o maior inteiro positivo de um conjunto de inteiros positivos pares é 2.

Se x e y são dois estados, cada um deles conduzindo um ao outro, então dx = dy.

De modo que dx é um divisor de n1 + n + n2.

Já que dx é um divisor de n1 + n2, então deve ser um divisor de n.

Assim, dx é um divisor de todos os números do conjunto.

Já que dy é seu maior divisor, concluímos que dx 6 dy.

Analogamente, dy 6 dx e, portanto, dx = dy.

Mostramos, em outras palavras, que os estados, em uma CM irredutível tem um período comum d.

Dizemos que uma cadeia é periódica com período d se d > 1 e aperiódica se d = 1.

Uma condição suficiente para que uma CM irredutível seja aperiódica é P(x,x) > 0 para algum x.

Determine o período de uma cadeia de vida e morte irredutível.

Se algum rx > 0, então P(x,x) = rx > 0, e a cadeia de vida e morte é aperiódica.

Em particular, a cadeia de Ehrenfest modificada é aperiódica.

Então em uma transição o estado da cadeia muda, ou de um estado ímpar para um estado par ou de um estado par para um ímpar.

Em particular, uma cadeia pode retornar ao seu estado inicial somente depois de um número par de transições.

Assim, o período da cadeia é 2 ou um múltiplo de 2.

Concluímos que a cadeia é periódica com período 2.

Em particular, a cadeia de Ehrenfest é periódica de período 2.

Seja uma CM irredutível recorrente positiva tendo uma distribuição estacionária.

Se a cadeia é aperiódica.

Se a cadeia é periódica com período d, então para cada par x,y de estados em E existe um inteiro, exceto se para algum inteiro não negativo.

Para uma ilustração da segunda parte do teorema, consideremos uma cadeia irredutível recorrente positiva de vida e morte que é periódica de período 2.

Um Campo Aleatório Markoviano é um nome para uma generalização natural do conceito de uma cadeia de Markov.

Ele surge pensado a própria cadeia como um grafo simples, ignorando a direcionalidade imposta pelo "tempo".

Uma CM pode ser vista como um grafo de variáveis estocásticas, onde cada variável tem a propriedade de ser independente de todas as outras (no futuro e no passado) dados seus dois vizinhos.

Com essa visão da CM em mente, um Campo Aleatório Markoviano é análogo, com a diferença de que agora permitimos qualquer estrutura de grafo para definir as relações entre as variáveis.

Definimos então um conjunto de variáveis estocáticas, tal que cada uma é independente de todas que não sejam suas vizinhas no grafo.

Nesta seção vamos discutir a relação entre a propriedade de Markov e a distribui ção de Gibbs.

Recorde que um processo Markoviano tem a seguinte propriedade de Markov, a probabilidade de um evento no tempo n+1 dados todos os eventos anteriores depende somente do evento no tempo n.

Para determinar um processo Markoviano específico, necessitamos de uma distribui ção inicial e sua probabilidade de transição.

A propriedade de Markov não tem de simetria no tempo, já que ela se refere a probabilidade de um evento futuro dado o passado.

Entretanto um processo Markoviano tem uma propriedade mais simétrica, a probabilidade de que um determinado evento ocorra no tempo n dados todos eventos anteriores e futuros depende somente dos eventos no tempos n1 e n+1.

A vantagem desta forma mais simétrica para a propriedade de Markov é que ela é generalizada imediatamente para qualquer grafo.

Esta generalização é a noção de Campo Aleatório Markoviano definida abaixo.

Campo Aletório Seja S um conjunto finito, com elementos denotados por s chamados sítios.

E seja um conjunto finito chamado espaço de fase.

Um campo aleatório sobre S com fases em é uma coleção de variáveis aleatórias X(s) com valores.

Um campo aleatório pode ser considerado como uma variável aleatória tomando valores no espaço de configuração.

Uma configuração é da forma.

Para uma dada configuração x e um dado subconjunto, defina a restrição de x à A.

Em particular, para algum fixado.

Onde S é uma maneira abreviada de escrever S.

Com o objetivo de introduzir a Propriedade de Markov para campos aleatórios é necessário introduzir uma topologia sobre os sítios.

Vizinhança Um sistema de vizinhanças sobre S é uma família de subconjuntos de S tais que para que todo S.

O subconjunto Ns é chamado vizinhança do sítio s.

O par (S,N) é chamado um grafo, ou topologia.

A fronteira de S é, por definição, o conjunto.

Na interpretação de grafos, S é o conjuto de vértices e N define as arestas, os sítios s e t são ligados por uma aresta se e somente se eles são vizinhos.

Campo Aleatório Markoviano O campo aleatório X é chamado Campo Aleatório Markoviano (CAM) com respeito a um sistema de vizinhança N se para todo sítio S as variáveis aleatórias X(s) e X(SNs) são independentes dado X(Ns).

Note que esta propriedade é do tipo Markoviana, a distribução de fase em um sítio é diretamente influênciada somente pelas fases dos sítios vizinhos.

Agora vamos discutir a equivalência entre o CAM e uma distribuição de Gibbs.

Dado um grafo arbitrário dizemos que que um conjunto de pontos C é um clique1 se todo par de pontos em C são vizinhos.

Incluímos o conjunto vazio como um clique.

Isto é formalizado com a seguinte (Clique) Qualquer conjunto unitário fsg é um clique.

Um subconjunto C S com mais que um elemento é chamado um clique de um grafo (SN) se e somente se quaisquer dois sítios de C são vizinhos.

Um potencial V é uma maneira de atribuir um número VC(x) para toda subconfiguração de x.

Potencial de Gibbs Um potencial de Gibbs sobre relativo a um sistema de vizinhanças N é uma coleção de funções.

Palavra clique é um neologismo inglês e quer dizer "panelinha" ou grupo de pessoas que se conhecem e nada tem a ver com a palavra "estalido" A função VC depende somente das fases dos sítios dentro do subconjunto C.

Neste exempo, a estrutura de grafo (SN) é como no modelo de Ising, mas agora o espaço de fase é = f01g.

Um sítio s é interpretado como sendo um neurônio que é excitado se x(s) = 1 e inibido se x(s) = 0.

Se t 2 Ns, diz-se que existe uma sinapse de s para t, e que a sinapse tem um comprimento wst.

O Potencial de Gibbs é dado.

De modo que a energia é dada.

A distribuição Gibbs induzida por E é definida.

A inclusão de todos os cliques na constituição da energia para a distribui ção de Gibbs é necessária para estabelecer a equivalência entre a distribui ção de Gibbs e o CAM.

Uma questão natural é porque esta distribuição em particular é interessante.

Exitem dois motivos.

O primeiro é devido à entropia.

Para uma distribuição de probabilidade qualquer P(x) define-se entropia S(P).

A entropia de uma distribuição pode ser interpretada como a quantidade de incerteza em um certo evento.

Por exemplo, se tem n pontos a distribui ção com maior entropia é a distribuição em que todos eventos tem a mesma probabilidade.

Assuma agora que podemos estimar ao menos o valor esperado da energia.

Então a distribuição de Gibbs é a distribui ção que maximiza a entropia entre todas as distribuições que fazem o valor esperado da energia concordar com a.

O segundo motivo, importante do ponto de vista de teoria da probabilidade, é que a distribuição de Gibbs com interação entre primeiros vizinhos tem a seguinte propriedade em termos de probabilidade condicional chamada característica local.

Especificação Local A característica local do CAM de um sítio s é a função definida.

A família é chamada especificação local do CAM.

Ou seja, a probabilidade de que um evento no ponto j, dado todos o outros eventos em todos os pontos do sistema, é igual a probabilidade do evento no ponto j dado somente o valor dos eventos nos pontos vizinhos de j.

Mas não somente uma distribuição de Gibbs tem a propriedade acima, como toda distribuição estritamente positiva com esta propriedade pode ser representada como uma distribuição de Gibbs com uma adequada escolha da função energia.

Veremos que que isto é verdade se utilizarmos o espaço como um grafo arbitrário finito.

Distribuições de Gibbs são campos Markovianos Se X é um campo aleatório com uma distrubição P, com energia E(x) definida a partir de um potencial de Gibbs VCC2S relativo a um sistema de vizinhaças N, então X é Markoviano relativamente ao mesmo sistema de vizinhanças N.

Além disso, sua especificação local é dada pela fórmula.

Portanto, basta mostrar que é igual, e em particular é uma função somente de x(s) e x(Ns), então pelo teorema siela, a propriedade de Markov será provada.

O teorema acima é primeira implição do teorema de equivalência Gibbs, Markov, uma distribuição de Gibbs relativa a um sistema de vizinhanças é a distribuição de um campo de Markov com respeito a um mesmo sistema de vizinhanças.

A recíproca é devido a Hammersley e Cliord.

Proposição(Fórmula de Mobius) Sejam duas funções definidas sobre P(E), a coleção de subconjuntos de um conjunto finito E.

As duas igualdades são equivalentes.

Agora a mostraremos a recíproca.

Para isto escrevemos o lado direito.

Agora podemos provar o seguinte Teorema(teorema de Hammersley-Cliord), seja F a distribuição de uma CAM com relação a um grafo (SN) satisfazendo a condição de positividade.

Para alguma função energia derivada a partir de algum potencial de Gibbs associado com a topologia (SN) Seja 0 um elemento fixo do espaço de fase.

Além disso, seja a configuração com todas as fases iguais a 0.

Podemos assumir, tendo em vista a condição de positividade.

Seja x uma configuração, e seja A um suconjunto de S.

A notação xA representa uma configuranção de coincidindo com x em A, e com fase 0 fora de A.

Devemos notar que a função energia e a função de partição não são únicas, já que pode-se adicionar uma constante a função energia e então multiplicar o fator de normalização por uma determinada constante.

Do mesmo modo o potencial de Gibbs não é único.

Entretanto, a unicidade pode alcançada se uma certa propriedade for imposta ao potencial, a saber a normalização com respeito a um valor de fase fixo.

Os estados são enumerados, com 0 desenvolvendo o papel do estado "preferido".

O potencial é dito canônico se VC(x) = 0 quando x assume o valor 0 em ao menos um sítio em C.

Em muitas situações, o potencial assim como a topologia sobre S pode ser obtido diretamente a partir da expressão da energia.

Potencial normalizado Um potencial de Gibbs é dito ser normalizado com respeito a uma dada fase, convencionalmente denotado por 0, se VC(x)= 0 sempre que existe t tal que x(t) = 0 (Unicidade do Potencial Normalizado) Exite um e somente um potencial normalizado com respeito a uma dada fase 0 2 correspondendo a uma distribuição de Gibbs.

Para duas funções energia EU e EW derivando de potenciais Ue W, ambos normalizados.

Já que similarmente Ew(0) = 0, segue que ZU = ZW = (0)1.

Propriedade Pk.

Resta mostrar, por indução, que é verdade.

Já que x tem fase zero fora de A e U é normalizado com respeito a 0.

Podemos ver que esta energia deriva de um potencial associado com uma topologia de primeiros vizinhos para a qual os cliques são, junto com pontos isolados, pares de sitios adjacentes.

Um potencial não nulo poderia ser escolhido.

Note que em termos da estrutura de vizinhança para n 2 Xn é independente.

Vamos calcular agora explicitamente para o caso de uma cadeia de Markov de dois estados, com espaço de estados E = fg1g matriz de transição e distribuição estacionária inicial.

Se temos um campo aleatótio sobre um grafo finito, então a característica local determinam unicamente sua distribuição.

De fato, o potencial canônico pode ser determinado unicamente a partir da fórmula e o potencial canônico determina a distribuição.

Entretanto, não podemos escolher qualquer característica local e ter certeza que existe uma distribuição consistente com essa característica.

Certas condições devem ser satifeitas e isso pode ser difícil de verificar.

A dificuldade de escolher uma característica local sugere que o conceito de função potencial pode ser a chave no estudo de Campos de Markov.

Como no caso do modelo de Ising, sobre grafos infinitos, pode existir mais do que uma distribuição com a mesma característica local.

Quando isto acontece podemos concluir que as probabilidades relativas a um conjunto fixo finito será afetado pelo conhecimento de eventos arbitrariamente afastado deste conjunto.

Isto, por sua vez, nos diz que o mesmo será verdadeiro para modelos finitos que aproximem modelos infinitos.

Considere um campo aleatório que muda aleatoriamente com o tempo.

Então temos um processo estocástico.

O estado no tempo n deste processo é um campo aleatório sobre S com fases, ou equivalentemente, uma variável aleatória com valores no espaço de estados, que assumimos ser finito.

O processo estocástico é chamado Campo aleátorio dinâmico.

Suponha que existe uma cadeia de Markov com espaço de estados e com distribuição dada.

Distância em variação Seja E um espaço enumerável e sejam A e B distribuições de probabilidade sobre E.

A distância em variação entre A e B é definida.

Assim se temos uma cadeia irredutível recorrente positiva e aperiódica, pelo teorema dizemos que a sequência converge em variação para a distribuição estacionária.

O primeiro problema ao simular é identificar uma cadeia fXngn>0 com as propriedades acima.

A amostra de Gibbs usa uma distribuição de probabilidade estritamente positiva sobre S, e a transição de Xn = x para Xn+1 = y é feita de acordo com a seguinte regra, o novo estado y é obtido a partir do antigo x mudando (ou não) o valor de fase de um único sítio.

O sítio s que será alterado (ou não) no tempo n é escolhido independentemente no passado com probabilidade qs.

Quando o sítio s for escolhido, a configuração atual x é alterada.

Assim, a configuração x é alterada com probabilidade, de acordo com a especificação local no sítio s.

Isto fornece para as entradas não nulas da matriz de transição.

A correspondente cadeia é irredutivel e aperiodica.

Para provar que é uma distribuição estacionária, usamos o balanceamento detalhado.

Isto pode ser feito para todo x, y.

