Fazemos uma construção de cadeias de Markov quânticas a partir de matrizes complexas, unitárias, estocásticas e analisamos o conceito de interferência nesse contexto, dando atenção para uma cadeia que chamamos de moeda quântica.

Estamos interessados na entropia de cadeias de Markov reais, no princípio variacional para energia livre associado e em uma possível construção análoga no caso complexo.

Este trabalho visa também dar uma introdução matematicamente rigorosa de certos aspectos de mecânica quântica.

Um princípio fundamental da mecânica quântica diz que a evolução temporal de um sistema físico isolado pode ser colocada em correspondência com um espaço vetorial de dimensão infinita de tal modo que os estados do sistema são representados por vetores e uma medição física qualquer corresponde a um operador linear.

Com o intuito de simplificar o problema, vamos analisar um modelo onde o tempo é discreto, o espaço vetorial é de dimensão finita e a cadeia de Markov clássica é modificada pela introdução de uma matriz complexa.

As cadeias de Markov quânticas são úteis para obter um comportamento aproximado do problema em dimensão infinita da mecânica quântica (que é muito mais complexo).

Esta aproximação (assim como outras abordagens discretas) é motivada não apenas pela necessidade de se estudar uma simplificação do problema maior, mas também pela possibilidade de que o próprio tempo seja discreto (questão complicada).

É razoável também especular que o problema real com espaço de estados continuo possa ser aproximado por um com espaço de estados discreto.

Inicialmente analisamos o trabalho feito por Marbeau e Gudder, onde consideramos uma matriz de amplitude de transição que tem a forma de uma matriz de Dirichlet.

Tais matrizes geram um análogo discreto da amplitude de Feynman contínua.

Depois, calculamos a distribuição de probabilidade para estas cadeias.

A seguir, estaremos interessados em ferramentas que permitam descrever outros processos, ditos discretos ou quase-discretos, seguindo a descrição dada.

Vamos considerar uma medida complexa sobre um espaço, onde também definiremos certos tipos de medições.

Como estamos interessados em estudar processos de natureza quântica, será útil ter em mente os postulados da mecânica quântica, que são discutidos com detalhe em uma formulação via operadores densidade.

A notação de Dirac, de uso corrente em mecânica quântica, também é introduzida.

Estudaremos também as entropias de Shannon e von Neumann e analisamos a entropia de certos processos de Markov quânticos.

Analisamos um problema variacional para cadeias de Markov finitas.

Mais especificamente, se H denota a entropia, U é um potencial, e é um certo autovalor associado a U, temos o conhecido princípio variacional para energia livre,onde vale a igualdade se e somente se for uma determinada medida especial que chamamos medida de Markov.

Dado este teorema para cadeias de Markov (reais), podemos nos perguntar se existe algum análogo para cadeias quânticas.

Neste trabalho, não propomos uma solução para esse problema, mas fornecemos algumas ferramentas que podem ajudar na sua resolução.

Na literatura, uma cadeia de Markov quântica normalmente está associada a uma importante construção via álgebra de operadores, devida a Accardi.

Nossa abordagem inicial difere bastante de tal contexto, mas no capítulo 7 faremos uma breve introdução às cadeias quânticas, fazendo uso de C-álgebras.

Em processos estocásticos, estamos interessados nos resultados obtidos por uma família, ou seqüência, de funções mensuráveis.

Podemos considerar, por exemplo, que o processo representa o resultado de se jogar uma moeda um número arbitrário de vezes, ou então a quantidade de chamadas telefônicas em um certo intervalo de tempo, ou mais geralmente, um fenômeno tal que sua evolução depende da probabilidade de ocorrência de um determinado êvento.

Tais problemas fazem parte de uma quantidade considerável de pesquisa em matemática.

Como a mecânica quântica possui um caráter probabilistico, é natural perguntar de que forma podemos descrever o movimento de uma partícula microscópica nos moldes de um processo estocástico.

Veremos que a mecânica quântica impõe restrições severas quanto a evolução dos objetos que descreve.

Dito de maneira geral, estaremos interessados em operadores que fornecem amplitudes de transição.

No caso discreto, isso significa considerar matrizes unitárias agindo sobre os vetores estados que descrevem a evolução das partículas.

No caso contínuo, isso significa que a evolução de tal vetor estado satisfaz a equação de Schrödinger.

No entanto, descrever fenômenos quânticos é um problema substancialmente mais difícil do que modelar problemas clássicos.

A idéia de realizar uma seqüência de medições sobre um elétron, como em um experimento comum com objetos macroscópicos, é no mínimo problemática.

Surge então a necessidade de se construir um formalismo de interferência entre medições.

Uma parte importante de nosso trabalho consistirá da construção matemática dessa idéia.

Aqui Xt vai descrever a evolução temporal de amplitude quântica de um sistema.

O processo vai tomar valores num conjunto finito natural tentar encontrar um "setting quântico sobre um conjunto de estados" que seja de alguma forma semelhante ao "setting probabilístico sobre um conjunto de estados".

Neste último caso, se analisa, onde é um processo estocástico.

Sendo assim, se espera que no primeiro "setting"intervenha de alguma forma uma medida complexa A e se deseja entender a evolução, onde é um processo estocástico.

Vamos assumir que de alguma forma natural a hipótese markoviana apareça no problema.

Desejamos que uma matriz A, do tipo n por n, descreva a "amplitude de transição".

Como veremos, neste formalismo nos deparamos com o conceito de interferência e com a questão do futuro (eventualmente poder) interferir no passado, o que nos parece indesejado (embora talvez fisicamente possível).

Em outras palavras, estes teoremas nos dizem que o futuro não interfere no passado.

Esta é uma propriedade desejável da teoria que iremos desenvolver.

O primeiro teorema se refere a um sistema discreto, e o outro a sistema contínuos ou quase-discretos.

Provaremos estes dois teoremas no próximo capítulo.

A mecânica quântica, como teoria física (ou matemática) da natureza, é incompleta e desafia muitas das características que consideramos senso comum no mundo clássico.

Iremos explorar apenas algumas propriedades de tal teoria.

Em geral, não iremos discutir a validade experimental implicada pelo formalismo matemático que discutiremos aqui, mas em alguns casos particulares importantes, como os sistemas descritos pelas matrizes de Dirichlet que veremos no próximo capítulo, sabemos que existe tal confirmação com a realidade (as matrizes de Dirichlet são um análogo discreto das amplitudes de Feynman calculadas em eletrodinâmica quântica (QED)).

O grupo das transformações lineares unitárias B, agindo sobre Cn é dito grupo unitário de ordem n.

A evolução de um sistema quântico é descrita pela ação de t no grupo unitário, denotada por U(t), onde t 2 N é um parâmetro temporal.

Este semigrupo indexado por t 2 N pode ser usado para calcular o estado do sistema em qualquer tempo dado, bem como encontrar amplitudes de transição.

Suponha que temos um operador unitário U em um espaço de Hilbert (sobre os corpo de escalares complexos) H de dimensão n que gera um grupo unitário discreto.

Dizemos que se o sistema encontra-se no estado em um certo tempo então i é a amplitude de transição do estado para o estado após t unidades de tempo.

Se é uma base ortonormal para H, definimos a matriz de amplitude de transição A relativa a esta base.

É claro que A é uma matriz unitária (e possivelmente com entradas complexas).

Esta descrição simples da mecânica quântica será suficiente para o que estudaremos neste capítulo.

Iremos formular mais precisamente o que entendemos por um sistema quântico no capítulo 4, quando considerarmos os postulados da mecânica quântica.

Como temos uma interpretação probabilística desta cadeia, podemos perguntar se ela está associada a um processo estocástico que gera estas amplitudes de transição.

A resposta é afirmativa, e as funções Xj do processo podem ser interpretadas como observações quânticas, ou como chamaremos, medições.

Como a matriz A é unitária, dizemos que Xj é um processo unitário.

Queremos, além disso, que os processos considerados tenham a propriedade de Markov.

Para que isso ocorra, A não deve ser apenas unitária, mas também estocástica.

Diremos que Xj satisfazendo a isto é uma cadeia quântica.

Um aspecto essencial da teoria quântica é o conceito de interferência.

Um observador que realiza uma medição em um sistema irá em geral modificá-lo.

Ainda, distintas possibilidades (e probabilidades) interferem uma nas outras.

Começaremos descrevendo matematicamente o que significa interferência entre êventos e suas medições.

Consideramos inicialmente uma medida complexa A denominada amplitude.

Esta medida será usada posteriormente para medir probabilidades (do mesmo modo como uma medida em uma cadeia de Markov clássica).

Seja o que chamaremos espaço amostral.

Os elementos são ditos pontos amostrais e cada ponto representa uma determinada configuração de um sistema físico.

Seja uma álgebra fixada de subconjuntos e seja uma medida complexa.

Quando a sigma-algebra gerada pelos cilindros, ou seja, a sigma-algebra de Borel.

Assumimos acima que A é aditiva, e tal propriedade será necessária na prova de alguns teoremas.

Em geral,não é uma probabilidade no sentido de teoria da medida se supormos que A é uma medida complexa.

O motivo é que a aditividade não vale em geral para conjuntos disjuntos.

Os dois primeiros termos da última igualdade fornecem o resultado clássico e o último é um termo de interferência, que contribui com uma soma ou subtração à parte clássica.

Um lema básico (e negativo) relacionado com esta questão é o seguinte (o leitor pode omitir a demonstração numa primeira leitura).

Em qualquer caso, um dos cilindros básicos deve ter medida nula.

A demonstração deste lema vale para qualquer espaço mensurável que admita uma cobertura finita.

Vamos fazer agora a construção de N-cadeias quânticas.

Começamos com o conceito de medição.

Dizemos que X é uma medição se ou seja,X é mensurável.

Dizemos que a seqüência com Xt e com todas as medições sobre o mesmo conjunto de resultados é uma N-cadeia.

A definição de N-cadeia inclui a condição de termos um certo estado inicial fixado s0.

Em geral não vamos supor que essa condição vale.

A matriz A da forma n por n associada a tal medida complexa A (que define uma cadeia de Markov homogenea no tempo Xt como definida acima).

A probabilidade do evento condicionado é dado.

Dizemos que é a amplitude de transição do sistema do estado sk para o estado sj em uma unidade de tempo.

Interpretamos o conjugado complexo como sendo a amplitude de transição 1 unidade de tempo.

Esta propriedade será útil para indicarmos que na cadeia em que estivermos trabalhando, o sistema não pode dar saltos em acréscimos de tempo t = 0, ou seja, se j6= k então ela satisfaz a condição.

Dado um estado fixo sk em t = 1, as somas das probabilidades de transição para qualquer outro estado vale 1.

Logo, dizer que X2 não interfere em X1 significa que para qualquer fixado.

Uma N-cadeia é unitária se X2 não interfere em X1 e se satisfaz a equação.

Definição.

Uma N-cadeia homogênea no tempo, unitária e Markov é chamada N-cadeia quântica.

A matriz A da forma n com entradas é a matriz de amplitude quântica de transição.

Desta maneira, a evolução do processo fica determinada por uma matriz A com valores complexos.

Associada a esta matriz temos uma matriz estocástica P real.

Examinemos com mais detalhes as propriedades da matriz de amplitude.

Observe que a primeira propriedade que citamos vale para qualquer Ncadeia unitária, e as outras duas valem para qualquer N-cadeia.

Em resumo, A descreve a evolução com probabilidades complexas (ondulatória) e P é a êvolução correspondente com probabilidades reais.

Resumindo, mostramos que a cada N-cadeia quântica corresponde uma matriz estocástica, unitária e com entradas não nulas.

Reciprocamente, toda matriz n com essas propriedades é a matriz de amplitude de transição de uma N-cadeia quântica.

De fato, o processo acima pode se revertido a partir de uma matriz complexa A do tipo n por n que seja estocástica e unitária.

Dada a matriz A, temos uma maneira natural de definir a medida de amplitude complexa A sobre SN.

Isso é análogo ao que é feito no caso real.

Seja uma distribuição de probabilidade inicial, isto é, um vetor.

Podemos definir uma probabilidade sobre os cilindros.

Isto define a medida complexa sobre toda a álgebra gerada pelos cilindros, pelo teorema da extensão de Kolmogorov.

Esta A é sigma aditiva.

Chamamos A de medida complexa de Markov.

É fácil ver que Xt e A satisfazem a hipótese de ser uma cadeia quântica.

Em uma N-cadeia quântica não interfere em Xt.

Em outras palavras, o futuro não interfere no passado.

Note que no último passo da demonstração fica clara a importância da matriz A ser unitária.

Esse fato é essencial para garantir a não interferência entre as medições da N-cadeia.

Note que podemos analisar uma teoria de amplitudes associadas a matrizes complexas estocásticas, sem levar em conta a unitariedade das matrizes, mas nesse caso a demonstração que fizemos do teorema acima não é válida.

Este teorema ilustra o fato de que temos dois sistemas evoluindo com o tempo em paralelo.

Um complexo dado por At e outro real dado por Pt.

O sistema definido por P é a cadeia de Markov clássica e o definido por A é a cadeia de Markov quântica.

Uma maneira mais simples de se obter a evolução da cadeia quântica é através dos autovalores e autovetores de A.

Desta forma obtemos uma expressão explícita para o cálculo de probabilidades P(Xt = k).

Sejam autovalores (possivelmente repetidos) de uma matriz unitária A e seja a base ortonormal de autovetores correspondente.

Usaremos esta expressão para calcular probabilidades de transição, mas em alguns exemplos iremos considerar o caso geral em que x0 é qualquer.

Nesta seção vamos exibir uma grande classe de matrizes A satisfazendo a hipótese de ser matriz quântica.

Sejam n inteiros positivos.

A matriz de Dirichlet é a matriz n com entradas.

É possível mostrar que gera um análogo discreto da amplitude de Feynman para uma partícula livre, e que esse análogo se aproxima da amplitude de Feynman.

Queremos saber quando a matriz é unitária.

Precisamos do seguinte lema, cuja prova é imediata.

Dois inteiros positivos n e a são relativamente primos se e somente se al6=nm, para quaisquer inteiros.

A matriz M é unitária se e somente se n e a são relativamente primos.

Se n e a são relativamente primos temos, aplicando o lema, que a soma geométrica na última expressão a satisfaz.

Portanto M é unitária.

Se n e a não são relativamente primos então pelo lema, existe para algum inteiro m.

Nesse caso, a série geométrica tem soma n e portanto M não é unitária, o que conclui a prova.

A distribuição de probabilidades gerada pela matriz de Dirichlet depende da paridade.

Uma conseqüência deste lema é que se é par então a soma das linhas e das colunas de M vale n.

Podemos concluir daí que a matriz é estocástica.

Ela também tem entradas não nulas e é unitária.

Desta forma obtemos uma grande classe de matrizes A satisfazendo o que foi exigido anteriormente.

Entretanto, se na é ímpar então a matriz de Dirichlet não pode se tornar estocástica desta forma.

A soma da primeira e terceira colunas difere da segunda e então nenhum múltiplo de M pode se tornar estocástica.

Para que possamos usar a equação obtida na seção anterior, precisamos dos autovalores e autovetores de M.

Acima assumimos que a a matriz de transição estocástica P é tal que para todo i, e ainda que o vetor de probabilidade inicial é a delta de Dirac em s0.

Estas equações nos fornecem expressões explícitas para Pt, mas elas não estão em uma forma fechada e portanto não nos mostram muita informação sobre a dinâmica do sistema.

Faremos o trabalho técnico de calcular tais somas na próxima seção.

Agora vamos calcular as probabilidades fornecidas pelas equações dadas na seção anterior.

Vamos analisar também alguns exemplos de outros tipos (não Dirichlet).

Notação.

Sejam a, b inteiros.

Denotaremos por a o número de vezes em que o fator 2 aparece na decomposição prima de a.

Ainda, o máximo divisor comum entre a e b é dado.

Note que estamos usando as distribuições obtidas pela expressão da seção anterior, que foi obtida tomando como distribuição inicial o vetor.

Seja n ímpar e a par.

Como antes, a série geométrica tem soma d se djk vale 0 caso contrário.

Se n é ímpar o período de x(t) é n.

Se n é par então o período de de x(t) (acima definido) é 2n.

Isso mostra que não precisamos calcular para t, n par e para n ímpar.

O próximo corolário nos diz que para n par também não é necessário calcular P(Xt = k).

Este último corolário significa que o sistema inicia em s0 e que a seqüência de probabilidades é a mesma.

Lembre que assumimos até agora nesta seção que o vetor de probabilidade inicial é p e não um p tal que Ap = p.

Assim, com não poderia deixar de ser, a matriz de Dirichlet (com tal vetor inicial) não determina um Processo Estocástico Estacionário, mas sim uma seqüência periódica de probabilidades de estado.

Pelo corolário acima, para t, a tabela é a mesma, mas em ordem inversa.

Obtemos uma seqüência de probabilidades de período 2n.

Podemos dizer que em um tempo t, existem certas transições impossíveis e as que podem ocorrem, tem todas a mesma probabilidade.

Como temos um número finito de estados (ou alternativamente, um número finito de vetores unitários que diferem de um ângulo constante), o número de caminhos possíveis para uma partícula é finito, e são todos igualmente prováveis no início de um processo.

Vamos mostrar abaixo que existem certos p 2 Cn tais que para certas matrizes de Dirichlet A vale Ap = p.

O seguinte exemplo é inspirado pela moeda quântica.

Exemplo Matrizes Quânticas A dois por dois não necessariamente do tipo Dirichlet.

Sejam u v tais que u + v = 1 e ju + jv = 1.

Uma condição necessária e suficiente para que essas propriedades sejam satisfeitas.

Então, vemos que o número real determina u e v a menos de conjugação.

Vamos construir uma matriz quântica complexa A a partir do seguinte.

Observe que, com respeito aos sinais da parte imaginária, devemos fazer duas escolhas independentes, ou seja, uma para a primeira coluna e outra para a segunda.

Portanto, se queremos determinar sob quais condições a matriz A é unitária.

Resolvendo uma das equações de AA = I (que é um sistema de duas êquações independentes), concluímos primeiro que x1 + x2 = 1.

E resolvendo a outra equação, obtemos que x1 = 0 ou 1.

Para a primeira matriz (identidade), o autovalor é 1, com autovetores (1,0) e (0,1).

Para a segunda, um autovalor é 1 com autovetor associado (1,1) e o outro é 1 com autovetor (1,1).

Resolvendo uma das equações de AA = I, concluímos que x1+x2 = 1, e portanto A é simétrica.

A outra equação é uma identidade e não impõe restrições sobre x1 ou x2.

Um autovalor é com autovetor associado e o outro autovalor é 1.

Assim obtemos condições para que as matrizes sejam unitárias.

Temos que possuem entradas não-nulas e portanto A é a matriz de amplitude de transição de uma N-cadeia quântica.

Como fizemos na seção de cadeias quânticas, vamos calcular as probabilidades de transição.

Para isso, precisamos dos autovalores e autovetores de A.

Pelo que vimos nos casos acima, podemos construir uma medida de Markov estacionária escolhendo como vetor estacionário o vetor associado ao autovalor 1 (que sempre é um autovalor para a moeda quântica, ao menos no caso de ordem 2).

Supondo que temos um vetor de distribuição inicial, podemos usar a expressão para probabilidades obtido na seção para cadeias quânticas.

Considere o teorema clássico de convergência de cadeias de Markov reais.

Seja P uma matriz estocástica (real) e regular.

Então P tem um único vetor de probabilidade fixo e os componentes são todos positivos.

Se p é qualquer vetor de probabilidade, então a seqüência de vetores converge para o ponto fixo.

Como conseqüência, as entradas das matrizes obtidas a partir de P convergem para as entradas correspondentes da matriz cujas colunas são iguais ao vetor fixo.

Lembramos que uma matriz estocástica real P é regular se existir alguma potência de P tal que todas as suas entradas sejam positivas.

Note que este teorema não vale, em geral, para cadeias de Markov quânticas (considerando que a condição de entradas positivas é substituída pela condição de possuir entradas não nulas).

Por exemplo, considere o item 2 do teorema.

Um cálculo simples mostra que se a seqüência de matrizes é uma seqüência periódica, e portanto não ocorre convergência para a matriz cujas colunas são o vetor estacionário de A.

Matriz de Dirichlet Seja M a matriz de Dirichlet, sabemos que M é unitária se e somente se n e a são relativamente primos e que se o produto não for par então tal matriz pode ser tornada estocástica.

Denotamos o vetor de probabilidade inicial.

Escrevemos abaixo alguns exemplos de matrizes com os seus respectivos autovalores, autovetores e processo estocástico real associado.

Vamos analisar os casos e tentar determinar se existem autovetores complexos associados ao autovalor 1.

No trabalho de Kempe, tal matriz é vista como a de uma moeda quântica balanceada, onde cara e coroa são tratados da mesma forma e o passeio não é influenciado pelo seu estado inicial.

Integrais de Feynman.

Algumas referências básicas para integrais de Feynman.

A mecânica quântica tradicional teve bastante êxito tanto no que se refere a compreensão dos fenômenos quânticos como também nas previsões numéricas de experimentos.

Ela foi substanciada por muitos experimentos feitos em laboratórios e por observações da natureza.

Entretanto, a teoria não tem respostas para certos problemas, como por exemplo, a descrição de partículas elementares e suas interações.

Isto pode ser devido ao fato de o conceito de amplitude de transição não estar na sua base axiomática (embora possa ser deduzido a partir dos postulados, este conceito não está na base da teoria).

Uma tentativa de resolver este problema é o formalismo das integrais de caminhos, proposto por Feynman.

Embora este formalismo seja uma ferramenta útil, traz consigo alguns problemas devido a sua natureza matemática não rigorosa.

Para entender este formalismo, usaremos a formulação lagrangiana da mecânica clássica, que descreveremos brevemente.

Suponha que temos um sistema mecânico com n graus de liberdade.

Diremos que C = Rn é o espaço de configurações.

Um ponto q descreve a configuração do sistema e é chamado estado lagrangiano.

A dinâmica de um sistema é descrita por um caminho, ou trajetória.

Na formulação hamiltoniana da mecânica clássica, um estado é determinado para o tempo t desde que a condição inicial seja dada.

Como veremos, o estado lagrangiano é determinado desde que as condições de contorno sejam dadas.

Então definimos as funções de velocidade.

O lagrangiano do sistema é definido.

Logo, L é a energia cinética menos a energia potencial.

A ação sobre um caminho q entre os tempos é definida.

Suponha que o sistema se encontra no estado lagrangiano.

Na formulação lagrangiana a trajetória que o sistema percorre, chamada trajetória clássica, é determinada pelo princípio da mínima ação.

Este princípio nos diz que dentre todos os caminhos possíveis a trajetória clássica é aquela onde é um extremo.

Isto é, o valor não se modifica se o caminho é alterado ligeiramente.

Voltemos agora à discussão da amplitude de Feynman.

Veremos que o formalismo destas amplitudes não leva em consideração apenas a trajetória clássica, mas sim todas as trajetórias.

Suponha que um elétron encontra-se na posição xa no tempo ta e então se move, sob a influência de alguma força.

Queremos calcular a probabilidade de que a partícula esteja em um ponto xb no tempo tb.

O elétron irá se mover por um dos muitos caminhos possíveis, mas não seremos capazes de distinguir uma trajetória de outra sem interferir no sistema.

Se fizermos uma medição, sabemos que seu movimento irá se modificar.

Na mecânica quântica, temos que todos os caminhos possíveis devem ser considerados.

Cada caminho contribui com uma amplitude para a amplitude total.

A é uma constante de normalização e L é o lagrangiano do sistema.

Resumindo, cada caminho possível contribui com uma determinada amplitude e soma destas amplitudes nos fornece uma amplitude total K.

Esta amplitude K, que é a amplitude de Feynman que discretizaremos nas seções seguintes, nos fornece a probabilidade de ocorrência de um evento.

O axioma nos diz que cada caminho contribui igualmente em módulo, êmbora as suas fases variem.

Então não é claro se um caminho em particular é mais importante.

Entretanto, na aproximação clássica.

Se um caminho arbitrário x(t) é modificado por uma pequena quantidade, embora seja pequeno na escala clássica, não é pequeno comparado.

Estas pequenas variações no caminho irão, em geral, variar bastante a fase, que irá oscilar rapidamente.

Então, se os caminhos vizinhos de x(t) possuem uma ação diferente, suas contribuições para K irão se cancelar, sem fornecer nenhuma contribuição.

Mas para o caminho especial ^x, onde S é um extremo, uma pequena mudança no caminho fornecerá praticamente nenhuma variação em S.

Assim, caminhos na vizinhança de ^x não fornecem fatores que se cancelam.

Desta forma, ^x se destaca e as leis clássicas do movimento surgem a partir das leis quânticas.

No nível atômico, quando S é comparável com ~, nenhum caminho se destaca.

Neste caso, todos os caminhos (mais precisamente, caminhos contínuos) devem ser considerados ao se calcular K.

Existem algumas dificuldades matemáticas ao se tentar construir uma formula ção rigorosa para a amplitude total K.

O problema principal é encontrar uma medida adequada no espaço de caminhos a fim de que a soma K possa ser formulada em termos de uma integral sobre este espaço.

Alguns casos especiais foram resolvidos, mas uma solução geral ainda não foi descoberta.

Iremos seguir um argumento heurístico.

Não é garantido que este limite exista (e em muito casos não existe).

Quando o limite existe, não depende crucialmente da natureza poligonal dos caminhos.

Apesar de a integral acima não possuir um sentido matemático rigoroso, ela possui importante significado físico.

Além disso, ela pode ser usada para descobrir certas propriedades que K deve ter se uma formulação rigorosa for possível.

Por exemplo, seja tc = ti um certo tempo fixado.

Agora, vamos calcular a integral para um caso simples.

Para uma partícula livre, o lagrangiano é L.

Aqui temos um produto de integrais Gaussianas que podem ser resolvidas individualmente.

É possível também mostrar que a equação de Schrödinger pode ser obtida (novamente, sem o rigor matemático exigido normalmente) a partir do formalismo das integrais de caminho.

Os conceitos mais importantes tratados neste trabalho estão baseados na função da onda, que representa o aspecto ondulatório de uma partícula, à medida que a posição e o tempo variam.

A função da onda desempenha um papel central no cálculo de probabilidades em experimentos que envolvem partículas atômicas.

Para ilustrar o problema de tais cálculos, consideremos o seguinte experimento.

De um lado, temos uma fonte emissora de partículas (elétrons, por exemplo).

Cada partícula deve passar por um anteparo, que possui duas fendas, e atingir um detector no outro lado.

O detector pode ser deslocado como quisermos, e assim podemos obter uma distribuição de probabilidade, realizando o experimento sucessivas vezes.

Se fecharmos a fenda 2, podemos calcular a probabilidade de o detector ser acionado por um elétron que passou pela fenda 1 (analogamente para a fenda 2).

A soma destas duas distribuições nos fornece a probabilidade de o detector ser acionado por um elétron que passou pela fenda 1 ou 2.

Podemos concluir a partir daí o seguinte, se analisarmos classicamente o problema, concluiremos que a probabilidade de que uma partícula atinja o detector é P.

Versão simplificada do experimento de Young.

S é a fonte de elétrons e D é um detector que se movimenta livremente na vertical.

A distribuição de probabilidade clássica seria uma curva gerada pela superposição das probabilidades via fenda 1 e 2.

Entretanto, a experiência nos mostra que este cálculo não pode estar correto.

Devemos ainda levar em conta a interferência entre caminhos alternativos.

A distribuição real terá, na verdade, o aspecto aproximado de uma senóide com amplitude decrescente à medida que nos aproximamos dos extremos do anteparo.

Desta forma, obtemos os padrões de interferência e difração, tal como no experimento de Young, revelando o caráter ondulatório de partículas como elétrons.

Um resultado importante da mecânica quântica, sobre o qual estão baseados as definições neste texto é que a probabilidade de se encontrar uma partícula em qualquer ponto é proporcional ao quadrado do valor absoluto da amplitude da onda de matéria nesse ponto.

Este postulado baseia-se no fato de que o cálculo correto de probabilidades envolve uma função de onda (uma função complexa).

Sendo assim, temos que o problema anterior pode ser resolvido da seguinte maneira.

Os padrões de interferência gerados no experimento sugerem que representemos a nossa função de distribuição, com tempo fixado, por uma função complexa.

Então podemos postular que P(x) é proporcional ao quadrado do valor absoluto de uma certa quantidade e este valor é a amplitude de probabilidade, ou como chamamos nas outras seções, amplitude quântica.

Além disso, temos o seguinte, X será a soma de duas contribuições, 1(x) e 2(x), as amplitudes de chegada via fenda 1 ou 2, respectivamente.

O cálculo estará correto no caso em que colocarmos um detector para se determinar por qual fenda a partícula passou.

Ou seja, ao introduzir tal detector estaremos destruindo o caráter ondulatório do experimento.

Os dois primeiros termos do lado direito fornecem o resultado clássico.

O último termo é o correspondente à interferência quântica, que contribui como uma soma ou subtração ao termo clássico.

Na física clássica, os modelos matemáticos nos fornecem informações sobre os fenômenos que observamos, enquanto que na mecânica quântica, os modelos não são observados sem que causemos alguma interferência.

Uma abordagem dos fenômenos microscópicos consiste em descrever a evolução da função da onda, mas esta função nos permite apenas calcular a probabilidade de que certos eventos ocorram.

Para relacioná-la com os experimentos, a função de onda deve ser interpretada de uma maneira apropriada.

O formalismo de integrais de caminhos, sobre o qual as amplitudes de Feynman estão baseadas, nos permite imaginar algumas situações interessantes.

Seja o seguinte experimento.

Temos um emissor de fótons, um detector, e abaixo um espelho.

Vamos supor válida a lei de incidência e reflexão da luz.

Supondo que temos uma barreira entre o emissor e o detector (assim a luz emitida não pode ir diretamente para o detector) concluímos, após uma análise clássica, que todo fóton que atingiu o detector foi refl etido pelo espelho, e além disso, deve ter sido no seu centro, pois o ângulo de incidência é igual ao ângulo de reflexão, e tanto o emissor como o detector estão a uma mesma distância da barreira.

Isso é o que observamos quando fazemos experimentos com um feixe de luz.

Entretanto, quando temos apenas uma partícula, o formalismo das integrais nos mostra um outro aspecto do fenômeno, que devemos considerar todas as trajetórias "possíveis" para a luz.

Em outras palavras, não devemos supor que a luz anda apenas em linha reta, e muito menos que ela sabe qual o caminho mais curto.

Mas para fins de simplificação, iremos supor que a luz percorre apenas linhas retas e a situação que iremos considerar é um fóton, incidindo e refletindo em qualquer ângulo e em qualquer ponto do espelho.

Dois caminhos para o fóton.

Sabe-se que o caminho em que o fóton atinge o êspelho no centro nos fornece o menor tempo, mas é errado dizer que os outros pontos são proibidos, ou que nunca irão ocorrer.

Teoricamente, é possível que um fóton atinja outro ponto do espelho (embora a probabilidade seja pequena, e, em grande escala, descobrimos que as amplitudes de probabilidade destas alternativas se cancelam).

A princípio pode parecer estranho supor que um fóton atinge uma parte qualquer do espelho.

Isso nos leva a uma pergunta.

Como poderia o fóton saber qual é o caminho mais curto e por que ele escolheria tal caminho?

A figura nos fornece um gráfico que indica os tempos necessários para um fóton sair da fonte e chegar até o detector.

Daremos apenas uma explicação intuitiva do que acontece.

A reflexão da luz é um fenômeno que envolve uma certa porção do espelho.

O fato importante a ser observado é o seguinte.

A diferença entre os tempos associados a pontos próximos do centro é menor do que a diferença entre os tempos associados a pontos dos extremos do espelho.

Isso significa que a diferença de fase entre as exponenciais associadas à amplitude de Feynman (ver equações na seção 1) é pequena para pontos próximos ao centro, e logo temos amplitudes de probabilidade que contribuem para uma amplitude maior e logo, uma probabilidade maior.

Nos extremos, a variação de fase é maior, e existe uma contribuição menor de amplitudes, o que confere a esses pontos uma menor probabilidade.

Logo, o centro é a região onde ocorrem pequenas variações de fase e onde é possível obter uma amplitude considerável.

E é por isso que podemos dizer, aproximadamente, que a luz percorre a trajetória em que o tempo é mínimo (também, não é difícil provar que no caminho onde o tempo é mínimo, o ângulo de incidência é igual ao ângulo de reflexão).

Vamos dividir o espelho em partições de mesmo tamanho.

Todos os caminhos possíveis.

Tempos associados aos caminhos.

O importante aqui é notar que a diferença entre os tempos associados a dois pontos do centro, digamos F e G, é menor do que a diferença entre os tempos associdos a dois pontos dos extremos, digamos A e B.

É exatamente isso que determina o fato de que apenas observamos a luz gerando ângulos de incidência e reflexão iguais.

Vamos examinar um exemplo mais simples de fenômeno que pode ser descrito por uma cadeia quântica.

Imagine uma partícula livre se movimen tando no espaço bidimensional.

Queremos calcular a probabilidade de que esta partícula, saindo do ponto sa, chegue ao ponto sb.

Como discutimos anteriormente, se estivéssemos considerando o fenômeno contínuo, teríamos de calcular a integral sobre todos os caminhos possíveis no espaço que tem como origem o ponto sa e destino o ponto sb.

Dizemos que a integral sobre cada caminho possível é uma amplitude de probabilidade e a soma destas amplitudes é a amplitude total.

O quadrado do módulo desta amplitude total nos fornece a probabilidade de que a partícula saia de sa e chegue a sb.

Isto é o que o formalismo das integrais de caminhos nos diz.

Lembre que fizemos n = 12 e na matriz de Dirichlet (o parâmetro a pode ser considerado a massa da partícula, e como já vimos, ela não influi na probabilidade).

Como temos uma matriz com um parâmetro n finito, estamos descrevendo uma aproximação do fenômeno contínuo.

Então podemos supor que as trajetórias possíveis para a partícula são poligonais.

Mas vamos tornar as coisas ainda mais simples e supor que as frações de caminhos possíveis são as arestas de um reticulado.

Quando consideramos sistemas discretos, o análogo de se calcular a integral sobre todos os caminhos de a a b é somar todas as amplitudes de transição de um estado a outro.

Em particular, como estávamos interessados na posição de uma partícula, a matriz de transição associada a cadeia quântica que usamos foi a matriz de Dirichlet, que gera um análogo discreto para o movimento de uma partícula livre.

Uma observação importante.

Lembre que em cadeias quânticas estamos sempre supondo que o conjunto S de estados possíveis do sistema é finito.

Então, temos uma partícula em um plano movendo-se em um reticulado finito.

Isso quer dizer a partícula livre que consideramos pode se mover apenas no reticulado, obviamente, e está de acordo com o cálculo de probabilidades que fizemos antes, pois lembre que tinhamos uma lista periódica de probabilidades, ou seja, isso deve-se também ao fato de que a partícula tem apenas um número finito de estados que podem ser assumidos.

Se o conjunto de estados não fosse finito, não saberíamos, a priori, se existe uma periodicidade nas transições do sistema.

Dizemos que ft é a medição no tempo t e neste exemplo f representa a posição da partícula.

Por exemplo, se o sistema está em um estado sj no tempo t, realizando outra medição, obtemos f(sj)= sk, onde sk é uma posição adjacente no reticulado.

Inversamente, se estamos em um estado sk no tempo t, temos que (sk) é o conjunto de estados que o sistema poderia estar no tempo t, sabendo que passamos para sk no tempo t (supomos que cada elemento deste conjunto deve necessariamente ser um vértice adjacente).

Temos, também o vetor de amplitude ft.

Este vetor é unitário ou seja,reflete a certeza da partícula estar no reticulado.

Queremos calcular a probabilidade de que a partícula, saindo do estado sa chegue ao estado sb em t unidades de tempo.

Note que desta forma, estamos considerando apenas as amplitudes de caminhos que levam t unidades de tempo.

Mesmo assim, conseguimos uma boa aproximação usando o formalismo das integrais de caminhos, deveríamos considerar todos os caminhos, e não apenas os que duram t unidades de tempo.

Logo, considerando caminhos de sa a sb em um tempo t, vemos que o formalismo das integrais (ou das somas de amplitudes sobre caminhos) se encaixa perfeitamente com a cadeia quântica que estamos considerando.

Dado um estado inicial s0, quando queremos determinar, procedemos da seguinte maneira.

Aplicando o estado inicial á matriz de transição A, podemos determinar como a amplitude varia com o tempo.

Somamos todas as amplitudes de caminhos que levam de sa a sb, calculamos o módulo e elevamos ao quadrado.

Esse é o propósito da cadeia, verificar todas as probabilidades sobre o espaço de caminhos, exatamente como no formalismo das amplitudes de Feynman.

Computadores clássicos operam com estados construídos a partir de um número finito n de bits.

Cada bit pode existir em um de dois estados, 0 ou 1.

O estado do sistema é determinado ao se especificar os valores de cada um dos bits.

Portanto, o conjunto de estados é finito e tem cardinalidade 2n.

Um computador quântico trabalha com um conjunto finito de objetos chamados q-bits.

Cada q-bit possui dois estados distintos, também denotados por 0 e 1.

As 2n combinações de estados para cada q-bit não consistem de todos os estados possíveis para o sistema, mas formam uma base para o espaço de estados.

Denotaremos os estados base.

Um estado arbitrário do sistema pode ser representado.

Obtemos um estado fisicamente indistinguível e portanto o estado em um computador quântico é um vetor unitário definido a menos de um fator de fase.

Em um computador clássico, qualquer função é permitida, ou seja composições e seqüências quaisquer de tais funções é o que entendemos como sendo computações clássicas.

Em um computador quântico as transformações permitidas são os operadores unitários, ou seja, operadores que preservam o comprimento.

Neste capítulo estamos interessados em estudar alguns fundamentos de mecânica quântica.

Além disso, queremos entender a entropia de von Neumann, o análogo quântico da entropia de Shannon da teoria clássica da informação.

No próximo capítulo, calcularemos tal entropia para as cadeias de Markov quânticas que vimos no capítulo 2.

Estamos interessados em obter algum análogo quântico para a entropia usada na teoria de informação clássica (entropia de Shannon).

Veremos que algumas idéias da teoria da informação serão úteis para descrever os sistemas que nos interessam aqui.

Começamos introduzindo a notação de Dirac, que é usual em mecânica quântica.

Um vetor de um espaço vetorial com produto interno será denotado.

Dados dois vetores, o produto interno é denotado.

Escreveremos para denotar o vetor dual do vetor.

O vetor dual é um operador linear definido em um espaço vetorial com produto interno.

Também denotaremos o produto interno entre dois vetores.

Suponha que A é um operador linear em um espaço de Hilbert V de dimensão finita.

Então existe um único operador linear Ay em V, dito o adjunto.

A elegância e praticidade da notação de Dirac fica evidente na seguinte definição.

Seja jvi um vetor num espaço vetorial com produto interno V e jwi um vetor num espaço vetorial com produto interno W.

Defina como sendo o operador linear cuja ação é definida.

Tal operador é dito produto exterior.

Note que a expressão pode ter as seguintes interpretações.

O resultado obtido ao se aplicar o operador no vetor ou o resultado de se multiplicar jwi pelo número complexo.

As definições dadas acima são tais que essas duas interpretações coincidem.

De fato, o que fizemos aqui foi simplesmente definir a primeira interpretação em termos da segunda.

Seja uma base ortonormal qualquer para o espaço vetorial V.

Um vetor pode ser escrito onde I é o operador identidade.

Esta é a relação de completude para vetores ortonormais.

Esta relação nos permite mostrar que todo operador linear pode ser escrito como uma combinação linear de produtos exteriores.

Suponha que A é um operador linear, j é uma base ortonormal para V e w é uma base ortonormal para W.

Usando a relação de completude, obtemos a representação em produto exterior de A.

Note que a partir dessa expressão, vemos também que a matriz associada ao operador A é tal que sendo tomada com respeito as bases.

Seja um vetor unitário e um operador qualquer.

Forme uma base ortonormal ordenada de modo que seja o primeiro elemento.

Vimos acima,que é uma expressão útil para se calcular o traço de operadores.

Suponha que W é um subespaço vetorial de dimensão k do espaço vetorial V de dimensão d.

Usando o método de Gram-Schmidt, é possível construir uma base ortonormal para V tal que ki é uma base ortonormal para W.

Definimos o projetor sobre o subespaço W.

Vamos considerar um sistema quântico que consiste de uma partícula de spin 1,2 e outra de spin 1.

Se considerarmos apenas as propriedades de spin (ou seja, ignorando os graus de liberdade associados com as propriedades espaciais das partículas), os espaços de estados dos subsistemas são C2 e C3, respectivamente, com bases típicas dadas pelos autoestados.

Uma suposição física natural é assumir que o sistema composto inclui estados que assumem cada um dos valores descritos acima.

Então existem seis estados.

Como estamos considerando uma teoria quântica, esperamos que combinações lineares dos estados acima sejam permitidos.

Então parece natural supor que o estado mais geral pode ser escrito.

Portanto os vetores na equação formam uma base para o espaço de Hilbert do sistema composto.

Como temos seis vetores, o espaço é isomorfo.

Para um sistema composto em geral, a operação matemática relevante toma vetores 1 e 2 nos espaços de Hilbert H1 e H2,de dimensão m e n respectivamente, e os transforma em um vetor em um novo espaço de Hilbert, chamado produto tensorial de H1 e H2, que tem dimensão mn.

O espaço de estados quântico do sistema composto é, portanto, o produto tensorial dos espaços de estados quânticos dos subsistemas constituintes.

No exemplo acima, o vetor denota o produto tensorial.

Em particular, temos que o produto tensorial é isomorfo.

Se jv e jw são bases ortonormais para H1 e H2, respectivamente, então jv é uma base para H1.

Usaremos também as notações para denotar o produto jvi.

H é um espaço de Hilbert de dimensão 2 com vetores base.

Agora definiremos formalmente o produto tensorial.

Sejam V e W são espaços vetoriais, que iremos supor sempre sobre R, e ainda que são de dimensão finita.

A construção mais geral para módulos sobre anéis comutativos,que não precisaremos aqui.

Denote o conjunto de elementos que são combinações lineares formais de elementos de V com coeficientes em R.

Sejam V e V 0 espaços vetoriais com bases B e B0, respectivamente.

Então V é um espaço vetorial com base fb.

Existe uma generalização natural da definição de produto tensorial para o caso de um número maior de espaços e um lema de propriedade universal correspondente.

Para cada aplicação multilinear existe uma única aplicação linear f.

Outras propriedades do produto tensorial são as seguintes.

Existem vetores em H que não podem ser escritos como um único produto ou seja, não existem estados.

Quando tal fato ocorrer, diremos que é um estado emaranhado (discutiremos emaranhamento (entanglement)).

Entretanto, todo vetor em H pode ser escrito como uma soma de tais produtos.

O produto interno é definido em vetores produto onde os produtos no lado direito são calculados nos espaços de Hilbert indicados.

A expressão é extendida para somas de vetores Enunciamos a definição do produto tensorial apenas para obter uma exposi ção completa.

Não precisaremos lembrar da construção formal que fizemos anteriormente, apenas de suas propriedades operacionais.

Em particular, será útil definir uma representação matricial, chamada produto de Kronecker.

Suponha que um sistema quântico está em um estado j ii dentre vários estados possíveis, onde i é um índice, com respectivas probabilidades pi.

O operador densidade, também chamado matriz densidade de um sistema é definido pela equação.

O seguinte teorema fornece uma caracterização de operadores densidade.

Um operador é o operador densidade associado a um ensemble se e somente se satisfaz.

Reciprocamente, suponha um operador satisfazendo a condição do traço e de positividade dadas acima.

Como é positiva, então possui uma decomposição espectral.

Ou seja, o ensemble é um ensemble de estados que induz o operador densidade.

A utilidade do operador densidade é a de descrever subsistemas de um sistema quântico composto.

Para isso, definimos o operador densidade reduzido.

Suponha que temos dois sistemas físicos A e B cujos estados são descritos por um operador densidade.

O operador densidade reduzido para o sistema A é definido onde ja são vetores no espaço de estados de A e jb são vetores no espaço de estados de B.

O operador traço aparecendo no lado direito é o operador traço usual para o sistema B.

Definição Dizemos que sistema quântico encontra-se em um estado puro quando não há incerteza quanto ao conhecimento do estado do sistema.

Ou seja, seu operador densidade é dado.

Costumamos dizer também que o operador é um estado puro.

Caso contrário, o estado é dito misturado (mixed).

Enunciamos a seguir os postulados da mecânica quântica.

Mais detalhes podem ser vistos.

Veremos que os postulados também possuem uma formulação interessante em termos de operadores densidade.

Associado a cada sistema físico existe um espaço vetorial complexo com produto interno, chamado espaço de estados do sistema.

O sistema é completamente descrito pelo seu vetor de estado, que é um vetor unitário no espaço de estados do sistema.

Em termos de operadores densidade, o postulado 1 pode ser escrito da seguinte maneira.

Associado a cada sistema físico isolado existe um espaço vetorial complexo com produto interno, dito espaço de estados do sistema.

O sistema é completamente descrito pelo seu operador densidade.

Se um sistema quântico está no estado com probabilidade pi, então o operador densidade para o sistema é P.

O postulado a seguir se refere à evolução temporal do sistema.

A evolução de um sistema quântico fechado é dada por uma transformação unitária, ou seja, o estado j do sistema no tempo t1 está relacionado com o estado i do sistema no tempo t2 por um operador unitário U que depende apenas dos tempos t1 e t2.

A evolução de um sistema quântico fechado é dada por uma transformação unitária, ou seja, o estado do sistema no tempo t1 está relacionado com o estado no tempo t2 por um operador unitário U que depende apenas dos tempos t1 e t2.

Este postulado descreve como os estados de um sistema quântico fechado em dois tempos diferentes estão relacionados.

Podemos postular, de maneira mais refinada, como ocorre a evolução do sistema em tempo contínuo.

A evolução no tempo de um estado de um sistema quântico fechado é descrita pela equação de Schrödinger.

O fator é a constante de Planck.

O termo H é um operador hermitiano fixado, que chamamos de Hamiltoniano do sistema fechado.

Vemos a relação entre os postulados 2 e 200 quando escrevemos a solução da equação de Schrödinger Vale que U definido desta forma é unitário e que todo operador unitário pode ser escrito na forma U = exp(iK) para algum operador hermitiano K.

Medições quânticas são descritas por uma coleção fMmg de operadores de medição, que são operadores agindo no espaço de estados do sistema.

O índice m se refere aos resultados das medições que podem ocorrer.

Se o estado do sistema quântico é j antes que a medição seja realizada, então a probabilidade de que o resultado m ocorra é dado Um sistema quântico é dito composto quando é formado por subsistemas quânticos.

O espaço de estados de um sistema composto é dado pelo produto tensorial dos espaços de estados dos subsistemas componentes.

Sabemos que j pode ser escrito como uma soma de produtos tensoriais.

Se j não pode ser escrito como um único produto dos seus estados componentes, então dizemos que j é um estado emaranhado (entangled).

Veremos agora uma decomposição que nos permite medir, em um certo sentido, a quantidade de emaranhamento entre dois sistemas.

Decomposição de Schmidt Suponha que j é um estado puro de um sistema composto AB.

Então existem estados ortonormais j para o sistema A, e estados ortonormais i para o sistema B tais que os chamados coeficientes de Schmidt.

Observe a seguinte aplicação deste teorema.

Seja j um estado puro e um sistema composto AB.

Então pela decomposição de Schmidt os autovalores são iguais, para os dois operadores densidade.

Muitas propriedades de sistemas quânticos são descritas completamente pelos autovalores do operador densidade reduzido e no caso de um estado puro de um sistema composto, tais propriedades continuarão valendo para os seus subsistemas.

Este estado não possui nenhuma simetria evidente.

Isso é uma conseqüência simples da decomposição de Schmidt.

Para provar a decomposição de Schmidt, precisamos dos seguintes resultados.

Lembramos que um operador linear é dito normal se AA = AA.

Decomposição espectral Todo operador normal M em um espaço vetorial V de dimensão finita é diagonal com respeito a uma base ortonormal para V.

Reciprocamente, todo operador diagonalizável é normal.

A decomposição espectral é um resultado conhecido de álgebra linear.

Decomposição Polar Seja A um operador linear em um espaço vetorial V de dimensão finita.

Então existe um operador unitário U e operadores positivos J e K tais que os únicos operadores positivos J e K satisfazendo estas equação são J e K.

Além disso, se A é inversível então U é único.

A decomposição A = UJ é dita decomposição polar à esquerda de A e A = KU é a decomposição polar à direita de A.

Agora use o procedimento de Gram-Schmidt para extender o conjunto ortonormal para obter uma base ortonormal, que chamaremos de j.

O operador J é único, pois multiplicando A = UJ à esquerda pela equação adjunta A = JU fornece J2 = AA, donde obtemos que J = pAA.

Um cálculo simples mostra que se A é inversível então J também é e então U é unicamente determinado pela equação.

A prova da decomposição polar à direita segue, onde K é um operador positivo.

Decomposição em valores singulares Seja A uma matriz quadrada.

Então existem matrizes unitárias U e V e uma matriz diagonal D com entradas não negativas.

Os elementos na diagonal de D são ditos valores singulares de A.

Pela decomposição polar, A = SJ para S unitária e J positiva.

Pelo teorema espectral, J = TDT, para T unitária e D diagonal com entradas não-negativas.

Faremos a prova no caso em que os sistemas A e B tem espaços de estado de mesma dimensão.

O caso geral é análogo.

Sejam jji e jki bases ortonormais para os sistemas A e B, respectivamente.

Então j pode ser escrito como uma certa matriz complexa C com entradas cjk.

Pela decomposição em valores singulares, C é uma matriz diagonal com entradas não negativas, U e V são matrizes unitárias.

Vale que jiAi é um conjunto ortonormal, pelo fato de que U é unitária e pela ortonormalidade de jji, e analogamente vale que jiBi é um conjunto ortonormal.

As bases jiAi e jiBi são chamadas bases de Schmidt para A e B, respectivamente, e o número de coeficientes de Schmidt não nulos é dito número de Schmidt para o estado j i.

O número de Schmidt é uma propriedade importante de um sistema quântico composto que, em um certo sentido, quantifica o emaranhamento entre os sistemas A e B.

Para entender como, considere a seguinte propriedade.

O número de Schmidt é preservado por transformações unitárias no sistema A ou no sistema B individualmente.

Para ver porque, note que se P é a decomposição de Schmidt então i é a decomposição de Schmidt para Uji, onde U é um operador unitário agindo apenas no sistema A.

Outra técnica relacionada com o emaranhamento de estados é a seguinte.

Seja um estado de um sistema quântico A.

É possível introduzir um outro sistema, denotado por R, e definir um estado puro j para o sistema conjunto AR.

Ou seja, o estado puro j se reduz quando olhamos apenas para o sistema A.

Este processo é chamado purificação, e nos permite associar estados puros a estados misturados de maneira natural.

O sistema R é dito sistema de referência.

Dado um estado qualquer, mostraremos como construir um sistema R e e uma purificação j.

Suponha que possui uma decomposição ortonormal.

Para purificar introduzimos um sistema R que possui o mesmo espaço de estados que o sistema A, com estados ortonormais jiRi e definimos um estado puro para o sistema combinado.

Agora calculamos o operador densidade reduzido para o sistema A correspondente ao estado j.

Portanto, j é uma purificação.

Note a relação entre a decomposição de Schmidt e o método de purificação.

O procedimento usado para se purificar um estado misturado do sistema A é definir um estado puro cuja base de Schmidt para o sistema A é simplesmente a base em que o estado misturado é diagonal, com os coeficientes de Schmidt sendo a raiz quadrada dos autovalores do operador densidade que está sendo purificado.

Observação Neste texto, escrevemos log x para denotar o logaritmo de x na base 2.

O logaritmo natural será denotado por ln x.

A incerteza de uma coleção de estados possíveis ai com uma distribuição de probabilidade p(ai) é dada pela sua entropia,chamada entropia de Shannon.

Estamos interessados em comparar duas distribuições de probabilidade distintas, e para este fim, introduzimos a noção de entropia relativa.

Suponha que temos dois conjuntos de eventos discretos ai e bj com distribuições de probabilidade correspondentes.

A entropia relativa (de Shannon) entre estas duas distribuições é dada.

A entropia relativa é não negativa, e vale a igualdade se e somente se p(x) = q(x), para todo x, e se X é uma variável aleatória com resultados possíveis, então H(X) vale a igualdade se e somente se X é uniformemente distribuída.

Um conceito importante derivado da entropia relativa está relacionado com a obtenção de informação.

Quando um sistema aprende alguma informa ção a partir de outro, dizemos que seus estados estão correlacionados.

A grandeza que mede a correlação entre esses estados é a informação mútua.

A informação mútua (de Shannon) entre duas variáveis aleatórias A e B que possuem uma distribuição de probabilidade conjunta, e portanto distribuições de probabilidade marginais é definida.

Podemos escrever IH em termos da entropia relativa de Shannon.

Neste sentido, ela representa uma distância entre a distribuição p e o produto das marginais.

Com respeito a entropia mútua de Shannon, vemos que ela descreve a correlação de dois observáveis, ou seja, tal grandeza é inerentemente clássica.

A entropia conjunta (de Shannon) de X e Y é definida de maneira natural.

Vale também uma propriedade subaditiva, ou seja, com igualdade se e somente se X e Y são variáveis independentes.

A entropia condicional (de Shannon) é definida e a informação mútua de X e Y também.

Nestes moldes, uma cadeia de Markov é uma seqüência de variáveis aleatórias.

O seguinte teorema nos diz como uma cadeia de Markov perde informação sobre os seus valores anteriores, à medida que o tempo cresce.

Como um corolário do teorema acima, temos que se fXig é cadeia de Markov.

Intuitivamente, isso significa que qualquer informação de Xi+2 compartilhada com Xi deve ser uma informação que Xi+2 compartilha com Xi+1.

Dada uma função f, é possível definir uma função matricial da seguinte maneira.

Desta forma, vale que f(A) está unicamente determinado.

Assim podemos definir, por exemplo, o logaritmo de operadores positivo-definidos e a exponencial de operadores normais.

Usaremos este tipo de construção para definir a entropia de von Neumann.

Vamos considerar os análogos quânticos da seção anterior.

A grandeza que está associada com as correlações de todo o sistema é a informação mútua de von Neumann, que definiremos a seguir.

Devido a sua natureza global, não é difícil imaginar que esse valor depende da matriz densidade.

Começamos definindo a entropia quântica, mais conhecida como entropia de von Neumann.

Definição A entropia de von Neumann de um sistema quântico descrito por uma matriz densidade.

Se são os autovalores então a entropia de von Neumann pode ser escrita.

A entropia de von Neumann pode ser considerada o análogo quântico da entropia de Shannon.

Para provar algumas de suas propriedades, iremos introduzir primeiro a entropia relativa associada.

Definição A entropia relativa (de von Neumann) entre dois estados é dada.

A propriedade básica é a seguinte desigualdade, (Desigualdade de Klein).

A entropia relativa quântica é não negativa e vale a igualdade.

Note que Pij satisfaz(a matriz com entradas Pij é duplamente estocástica).

Como log é uma função estritamente concava, segue com igualdade se e somente se existe um valor de j para o qual Pij = 1.

Portanto, com igualdade se e somente se existe um valor de j para o qual Pij = 1, ou seja, se e somente se Pij é uma matriz de permutação.

Esta expressão tem a mesma forma da entropia relativa clássica.

Portanto deduzimos que, para todo i e Pij é uma matriz de permutação.

Para simplificar essa condição de igualdade, note que trocando os nomes dos autoestados se necessário, podemos supor que Pij é a matriz identidade e então são diagonais na mesma base.

A condição nos diz que os autovalores correspondentes são idênticos e portanto a condição de igualdade se reduz.

Existe um conjunto de matrizes unitárias Uj e uma distribuição de probabilidade pj tal que para qualquer matriz A, d é a dimensão do espaço de Hilbert onde o operador A está definido.

Juntamente com a concavidade estrita da entropia, este lema pode ser usado para provar que o estado I=d em um espaço de dimensão d é o único estado de máxima entropia.

Prosseguimos na análise da entropia de von Neumann.

A entropia conjunta (de von Neumann) para um sistema composto com duas componentes A e B é definido de maneira natural onde AB é a matriz densidade do sistema.

Suponha que A e B são sistemas quânticos distintos que possuem um estado conjunto.

Então a entropia conjunta para os dois sistemas satisfaz as desigualdades.

A primeira desigualdade é chamada desigualdade triangular, ou desigualdade de Araki-Lieb.

É o análogo quântico da desigualdade para a entropia de Shannon.

A segunda desigualdade é dita desigualdade subaditiva, e vale a igualdade se e somente se os sistemas A e B não estão correlacionados.

A prova da desigualdade subaditiva é uma aplicação simples da desigualdade de Klein.

A desigualdade de Klein nos fornece, como queríamos.

A condição de igualdade para a desigualdade de Klein nos fornece condições de igualdade para a subaditividade.

Para provar a desigualdade de Araki-Lieb, introduza um sistema auxiliar R que purifica os sistemas A e B.

Como ABR encontra-se em um estado puro a desigualdade anterior pode ser reescrita Pela simetria entre os sistemas A e B, obtemos também.

Suponha que são estados de um sistema A.

Introduza o sistema auxiliar B cujo espaço de estados possui uma base ortonormal jii correspondente ao índice i dos operadores densidade.

Para provar a concavidade de S, usaremos a propriedade subaditiva.

Aplicando a desigualdade subaditiva, obtemos, S é concava.

O método de se introduzir um sistema auxiliar, como foi usado aqui, e na prova da desigualdade de Araki-Lieb, é freqüentemente aplicado em teoria da informação quântica.

Suponha que Pi é um conjunto completo de projetores ortogonais e um operador densidade.

Então a entropia do estado do sistema após a medição é tal que vale a igualdade.

Em outras palavras, medições projetivas aumentam a entropia.

Aplique a desigualdade de Klein.

Primeiro suponha que temos um estado puro.

Suponha que são estados de um sistema A e introduza um sistema auxiliar B com uma base ortonormal jii correspondendo ao índice i nas probabilidades pi.

Pelo teorema anterior, medições projetivas nunca diminuem a entropia.

Provamos onde os estados são estados puros.

Além disso vale a igualdade se e somente se B = B0, que ocorre se e somente se os estados j ii são ortogonais.

A condição de igualdade para o estado misturado segue direto da condição do caso de estados puros.

Suponha que pi são probabilidades, jii são estados ortogonais para um sistema A e é um conjunto de operadores densidade para um outro sistema B.

A informação mútua (de von Neumann) entre dois subsistemas de um sistema conjunto é definido.

Algumas propriedades da entropia de Shannon não valem para a entropia de von Neumann e isso acarreta algumas conseqüências.

Por exemplo, para variáveis aleatórias X e Y, vale a desigualdade.

Esta desigualdade é intuitiva, ou seja, é natural imaginar que há menos incerteza quanto ao estado de X do que incerteza quanto ao estado do sistema conjunto formado por X e Y.

No entanto, esta intuição falha para estados quânticos.

Considere um sistema AB de dois q-bits no estado emaranhado.

Este é um estado puro.

Por outro lado, o sistema A possui operador densidade I=2 e portanto possui entropia igual a 1.

Mostraremos a desigualdade chamada subaditividade forte para a entropia de von Neumann.

Para provar este resultado, precisamos saber alguns fatos sobre concavidade de funções.

Dizemos que f é conjuntamente concava em A e B.

Toda função conjuntamente concava é concava em cada uma das variáveis, mas a reciproca não vale.

Então a função é conjuntamente concava sobre matrizes positivas A e B.

A entropia relativa é conjuntamente convexa em seus argumentos.

Seja AB um sistema composto com componentes A e B.

Então a entropia condicional S(AjB) é concava no estado de AB.

Mostraremos que para quaisquer sistemas quânticos.

Estas desigualdades são equivalentes.

Usaremos a concavidade da entropia condicional para provar a primeira, e a seguir mostramos que isso implica a validade da segunda.

Pela concavidade da entropia condicional, vemos que T é uma função convexa.

Para obter a segunda desigualdade, introduza um sistema auxiliar R puri ficando o sistema ABC.

Cadeias quânticas.

Entropia de Shannon.

Relembrando, seja uma álgebra de subconjuntos de e seja A uma medida complexa.

O número complexo é dito amplitude quântica do evento.

Além disso, estaremos supondo que A é aditiva.

A probabilidade P de que um evento ocorra é definida.

Estamos interessados em calcular algum tipo de entropia para as cadeias quânticas, de maneira análoga a que é feita ao se calcular a entropia associada a uma cadeia de Markov usual.

Vamos calcular a entropia da probabilidade associada a uma cadeia de Markov quântica.

Como no caso usual de entropia para o shift, podemos definir a entropia (de Shannon) desta partição, que no caso de cadeias quânticas tem como expressão.

Podemos nos perguntar por que não considerar uma "entropia complexa"? Uma constru ção desse tipo é possível, mas veremos que a dificuldade para a obtenção de uma expressão simples reside no fato de que o argumento de um número complexo é linear apenas sobre certas condições.

Vale que tal aplicação é uma bijeção sobre a inversa de a.

Vale que b é contínua e limitada.

Cadeias quânticas, entropia de von Neumann.

Pelo que vimos, podemos facilmente obter a entropia de von Neumann de uma cadeia de Markov quântica.

Vamos considerar um ensemble para cada tempo t, ou seja, S é o conjunto de estados possíveis, e P denota a probabilidade de ocorrer o estado sk no tempo t.

O operador densidade associado à cadeia de Markov quântica no tempo.

Observação Note que a expressão é válida apenas fazendo a suposição, conforme obtida no final da seção.

Para o caso geral, procedemos da seguinte maneira.

Fazemos os cálculos em dimensão 2, o caso geral é análogo, com uma notação mais complicada.

Formalismo Termodinâmico.

Neste capítulo analisamos um problema variacional para cadeias de Markov finitas.

Se H denota a entropia, U é um potencial, é um certo autovalor associado a U, temos um princípio variacional para energia livre, onde vale a igualdade se e somente se for uma determinada medida especial, que chamamos medida de Markov (faremos os detalhes a seguir).

Dado este teorema para cadeias de Markov reais, podemos nos perguntar se existe algum análogo para cadeias quânticas.

Apresentamos aqui um teorema de Lanford e Ruelle numa versão de Spitzer que caracteriza (em uma caso simplificado) o estado de Gibbs (no reticulado unidimensional Z) como sendo aquele que maximiza a energia livre.

Essa energia é baseada em um potencial U que descreve de alguma forma a interação entre elementos vizinhos no reticulado Z.

Vamos assumir aqui que esta U tem uma expressão simples (um elemento no reticulado depende da interação de um número finito fixo de vizinhos) e assim ela determina uma matriz de transição M de uma cadeia de Markov e esta define uma certa probabilidade estacionária sobre o espaço de Bernoulli.

Esta probabilidade será o estado de Gibbs associado a U.

Deste modo, será possível apresentar ao leitor uma versão matematicamente rigorosa de algumas idéias básicas e resultados fundamentais que aparecem em certos problemas simples de Mecânica Estatística.

A entropia é uma grandeza que mede a caoticidade, ou complexidade de um sistema, quanto maior for a entropia, mais caótico é o sistema.

Esse conceito aparece na Física e está associado com o princípio de que a natureza tende a maximizar a entropia.

Se em um tempo inicial t0 consideramos partículas de gás concentradas em um dos cantos de uma caixa fechada, então após algum tempo (após o equilíbrio) as partículas tenderão a uma situação, onde êlas estarão espalhadas na forma mais aleatória possível.

Isso significa que decorrido algum tempo, o gás terá uma distribuição uniforme na caixa.

Um sistema de partículas é muito mais aleatório (tem mais entropia) se estiver uniformemente distribuído na caixa do que se estivesse concentrado em um dos cantos.

Vemos assim que o equilíbrio é atingido em configurações de máxima entropia.

A entropia também está relacionada com a Teoria de Informação, a partir dos trabalhos de Shannon.

Se quisermos transmitir uma mensagem através de um certo meio de comunicação usando um determinado alfabeto de n símbolos, cada símbolo com uma certa probabilidade de ocorrer(suponha que a ocorrência dos símbolos seja independente), então a entropia deste sistema é a entropia do shift de Bernoulli.

A valor da entropia para medidas mais gerais tem uma expressão mais complexa.

Nosso proposta aqui é a de usar a entropia de Shannon-Kolomogrov como uma ferramenta matemática para se estudar a Mecânica Estatística.

O que apresentamos aqui é baseado na abordagem de Bowen-Ruelle-Sinai para entender reticulados em uma dimensão e veremos que essa proposta inclui estudar a pressão topológica do shift.

Tal teoria é o que chamamos atualmente de Formalismo Termodinâmico.

Uma dos objetos desta teoria é o operador de Ruelle-Perron-Frobenius, que é uma generalização natural (para o espaço de funções contínuas) de uma matriz com todas as entradas positivas.

No caso de dimensão finita, o teorema de Perron-Frobenius agindo em Rn basta para se obter o que se necessita.

O operador de Ruelle-Perron-Frobenius possui diversas aplicações em outras áreas da matemática, como por exemplo Geometria e Teoria dos Números.

Algumas vezes, na Física, êste operador é denominado matriz de transferência.

Para motivar o problema que vamos analisar em breve vamos apresentar inicialmente o modelo mais simples possivel.

Considere um sistema físico com estados, e as energias desses estados.

Suponha que colocamos o sistema em contato com uma fonte de calor muito maior, que está a uma temperatura T.

Sendo assim, a energia irá transitar entre o sistema original e a fonte de calor, e a temperatura T permanecer á constante, pois a fonte é muito maior que o nosso sistema.

O problema físico que estamos considerando não é determinístico, e nós podemos apenas falar da probabilidade de um certo estado fixo, digamos j, ocorrer.

Apos esperar que o sistema se encontre em equilibrio, se realizarmos uma sequência de observações, notaremos que o estado j irá ocorrer numa determinda proporção de vezes.

Então o que queremos saber, para cada j, é o valor dessa proporção quando o número de observações vai a infinito.

É um fato conhecido da Mecânica Estatística (a partir de observações) que a probabilidade Pj de que o estado j ocorra é dado pela distribuição de Gibbs.

K é uma constante, chamada constante de Boltzmann.

Nesse contexto, a expressão S + BU é o que chamaremos de energia livre.

Logo, podemos dizer que a natureza minimiza a energia livre.

Quando fazemos a temperatura T tender,isto é, maximizamos a entropia.

Após a análise do sistema mais simples descrito acima, vamos considerar um caso um pouco mais complexo.

O modelo proposto por Ruelle é o seguinte (usaremos um modelo semelhante na próxima seção).

Considere um reticulado unidimensional Z.

Cada inteiro está associado a um estado e uma configuração do sistema é uma sequência.

Seja T o espaço de probabilidades invariantes para o shift.

Este é o modelo da Mecânica Estat ística no reticulado Z via o shift de Bernoulli.

Um modelo mais apropriado seria sobre o reticulado tridimensional Z3, mas aqui vamos evitar situações mais complexas.

Seja U uma função contínua, que contém a informação relacionada com alguma grandeza física (energia, temperatura, campo magnético, etc).

Queremos obter agora uma maneira de determinar a distribuição de Gibbs no reticulado unidimensional infinito de uma forma semelhante a usada no caso finito que vimos acima.

A distribuição de Gibbs associado a U será uma probabilidade.

Por exemplo, considere uma determinada distribuição de spins de partículas no reticulado unidimensional Z.

Devemos considerar o espaço de Bernoulli de dois símbolos e probabilidades, qual probabilidade é a de Gibbs asociada a U? É apropriado considerar apenas probabilidades em T porque não há uma razão natural para destacar um determinado ponto do reticulado como sendo o valor i = 0.

Assim, a probabilidade de Gibbs deve ser invariante por translação.

O estado de Gibbs vai dizer, por exemplo, qual a probabilidade de ocorrer no reticulado o arranjo.

Qual seria o estado de Gibbs associado a tal U? Voltemos agora ao caso geral.

Dada uma função U contínua vamos analisar o seguinte problema variacional.

Seja S a entropia da probabilidade.

Diremos que P(U) é a pressão topológica associada a U.

Gostaríamos de encontrar um probabilidade definida em todo o espaço que assuma o supremo mencionado acima.

Tal probabilidade será chamada de estado de equilíbrio, ou estado de Gibbs associado ao potencial U.

O estado de equilíbrio será definido, portanto, por meio de um princípio de máximo, ou seja, maximiza algo.

O potencial U do exemplo particular acima mencionado descreve uma certa interação entre spins no reticulado, mas o problema faz sentido para U qualquer, não necessariamente como no exemplo.

Poderia, por exemplo, depender de mais coordenadas, não apenas duas.

Vamos considerar na próxima seção o caso simples em que U depende apenas de duas,ou seja, cada spin depende apenas do vizinho à direita.

No exemplo dado abaixo, a solução pode ser obtida através de álgebra Linear, ou seja, pela teoria de Cadeias de Markov e pelo Teorema de de Perron-Frobenius (descrito no Apêndice deste capítulo).

Se o U depende de infinitas coordenadas, aí o procedimento via álgebra Linear não resolve o problema.

Ruelle mostrou que o que os físicos denominam de estado de Gibbs, no caso do reticulado Z, pode ser obtido via o procedimento acima através de uma escolha correta de U.

Diferentes problemas de Mecânica Estatística requerem diferentes U.

A análise de questões mais gerais em Mecânica Estatística pode ser encontrada.

Observe que se consideramos um potencial U que depende de n coordenadas, com 2 < n < 1, podemos modificar o espaço de modo a fazer com que U dependa de apenas duas coordenadas.

Por exemplo, suponha que que temos um potencial U que depende de 3 coordenadas.

Considere então o espaço e o relacionamos com fazendo as identificações.

Note agora que certas relações estão proibidas.

Podemos pensar que U está definido como uma certa V.

De fato, V definida de maneira natural depende apenas de duas coordenadas.

Desta maneira se pode fazer recair o caso em que U depende de finitas coordenadas no espaço de Bernoulli ao caso em que dependa de apenas duas, como será analisado a seguir.

Tal procedimento não pode ser feito se o potencial considerado depende de infinitas coordenadas.

Iremos a seguir considerar medidas sobre a álgebra F.

Diremos que é espaço de probabilidade, e diremos que T é o conjunto das medidas invariantes por translação.

Sabe-se que T é compacto se consideramos a convergência fraca de medidas.

De fato, pelo teorema ergódico de Birkho e aplicando o teorema da convergência dominada para a sequência de funções.

Definindo sobre os cilindros, fica determinada de maneira única, pelo teorema de Kolmogorov, uma medida de probabilidade sobre a álgebra gerada pelos cilindros.

Vamos formular a caracterização variacional.

Para U fixo,a medida de Markov definida pela matriz de transição.

Dizemos que é ergódica(invariante) A implica (A) = 0 ou 1.

Pode-se mostrar que a probabilidade é invariante e ergódica para o shift.

Agora vamos supor provado o segundo passo (ou seja, suponha que vale a desigualdade estrita, ergódica).

Este segundo passo é bastante técnico e referimos o leitor para uma prova geral.

Como K é compacto e convexo, pelo teorema de Krein-Milman (ver o Apêndice deste capítulo), isso ocorrerá se e somente se K tem um único ponto extremo.

Um fato conhecido sobre o conjunto T é que os seus pontos extremos são justamente as medidas ergódicas.

Então o problema é reduzido a mostrar que K não contém outras medidas ergódicas.

Ora, mas pelo segundo passo, se supomos que a medida considerada é ergódica, então vale a desigualdade estrita, ou seja, não é tal que fU assume um máximo.

Sabemos que a matriz de amplitu é uma matriz unitária, suas entradas são não-nulas e é coluna-estocástica.

Seja A a matriz de amplitude de transição de uma N-cadeia.

Defina a matriz de amplitude de transição com um potencial.

Interpretamos que, como no caso de cadeias de Markov, a amplitude de transição de q até q0.

Supomos que o potencial depende apenas da posição onde a partícula se encontra.

Dizemos que AV é a amplitude correspondente a uma partícula evoluindo sob a influência de um potencial.

Note que se V = 0, AV se reduz à função de amplitude livre A.

Vale que AV é uma matriz unitária com entradas não nulas.

Vale que AV é coluna-estocástica apenas quando consideramos potenciais.

Considere as matrizes de Dirichlet.

Ali, mostra-se uma maneira de transformar tal matriz em uma outra, M0, que é estocástica desde que na seja par.

O método visto ali não funciona para M(3,1) por exemplo.

Para resolver esse caso, tentamos usar uma idéia, onde se usa o maior autovalor de uma dada matriz positiva A e o seu autovetor à direita para transformá-la em estocástica.

Mas aqui temos apenas matrizes complexas, então necessitamos de algumas adaptações.

A idéia é associar à matriz M(3,1), uma outra, T(M(3,1)), que possui coeficientes reais e tomar o seu maior autovalor.

Esse autovalor está associado de maneira natural com um dos autovalores da matriz original M(3,1).

O espectro da família M é formado por três curvas,onde uma delas tem como um de seus extremos o maior dos autovalores.

Então o que fazemos é escolher o autovalor no outro extremo desta curva.

Daí, alguns cálculos simples mostram que é o autovalor de M(3,1) encontrado de acordo com a regra postulada acima.

Wielandt seja A = (aij) matriz irredutível não negativa de ordem n e C = (cij) uma matriz quadrada complexa de ordem n.

Então para todo autovalor de C vale que r é o maior autovalor de A.

Além disso, vale a igualdade se e somente r e D é uma matriz diagonal cujos elementos não nulos tem módulo 1.

A prova deste lema encontra-se no Apêndice deste capítulo.

Um possível trabalho futuro baseado neste lema é o seguinte.

Dada uma matriz complexa, obter um método de normalização a partir da matriz módulo associada, o que pode fornecer um método mais geral do que o obtido no ítem 1.

Para que uma matriz estocástica com entradas não nulas seja a matriz de uma cadeia de Markov quântica, precisamos ainda que ela seja unitária.

Para este fim, devemos determinar se é possível adaptar o método acima de modo a fornecer a propriedade unitária.

Podemos obter uma condição para que uma matriz normalizada na forma do item anterior seja unitária, onde M é uma matriz complexa, um autovalor não nulo de M e r um autovetor associado com entradas não nulas.

Seja uma matriz com entradas estritamente positivas.

Então existem vetores (u é autovetor à direita de A e v é autovetor à esquerda de A).

Mostremos que existe pelo menos um vetor u com coordenadas positivas.

O teorema do ponto fixo de Brouwer nos diz que tal aplicação possui pelo menos um ponto fixo.

No caso geral, observe que a função é estritamente côncava.

Uma função f é dita T-invariante.

Diremos que uma propriedade vale em quase toda parte (qtp), ou com probabilidade 1, se o conjunto dos elementos onde não vale a propriedade tem medida nula.

Um espaço vetorial X com uma topologia T é um espaço vetorial topológico se a soma é uma função contínua de X e se a multiplica ção escalar é uma função contínua de R em X.

Um espaço vetorial topológico é dito localmente convexo se podemos obter uma base para a topologia formada por conjuntos convexos.

Krein-Milman.

Seja K um conjunto convexo compacto em um espaço vetorial topológico localmente convexo.

Então a intersecção de todos os conjuntos convexos fechados contendo os pontos êxtremos de K é o próprio K.

Aqui provamos o lema de Wielandt.

Sejam A e B matrizes reais retangulares de mesma dimensão.

Escrevemos Em particular diremos que A é não-negativa.

Se o sinal de igualdade puder ser omitido em todas as desigualdades acima, escreveremos A < B (analogamente, quando A > 0, diremos que A é positiva).

Denotamos por C+ a matriz módulo C, obtida a partir de C quando todos os seus elementos são trocados pelos seus respectivos módulos.

Diremos que A é redutível se pudermos escrever o conjunto de índices como sendo uma união de conjuntos complementares.

Caso contrário, diremos que A é irredutível.

Vamos obter outra caracterização para matrizes irredutíveis.

Uma permuta ção de uma matriz quadrada A significa uma permutação das linhas de A juntamente com a mesma permutação de colunas.

Podemos então definir matriz redutível da seguinte forma.

A matriz A será redutível se existir uma permutação que transforma A em um operador da forma onde B e D são matrizes quadradas.

Caso contrário, diremos que A é irredutível.

Um subespaço coordenado dimensional de Rn é um subespaço de Rn que possui uma base.

Existem subespaços coordenados dimensionais associados a uma base dada.

Assim, podemos definir matriz redutível de outra forma.

Uma matriz A é redutível se e somente se possui um subespaço coordenado invariante dimensional.

De agora em diante, a menos que seja especificado, iremos considerar matrizes A não negativas.

Provaremos a desigualdade acima se mostrarmos que, o vetor possui menos coordenadas nulas que y.

Vamos supor que isso não vale.

Como, vale que a coordenadas positivas de y correspondem coordenadas positivas de z.

E segue da expressão acima que z não pode ter mais coordenadas nulas que y.

Então y e z tem as mesmas coordenadas nulas.

Sem perda de generalidade, suponha que (com u e v são colunas de mesma dimensão).

Um corolário conhecido é a seguinte definição equivalente para matrizes irredutíveis.

Vamos enunciar o teorema de Frobenius.

FrobeniusToda matriz irredutível não negativa A de ordem n possui um autovalor positivo r que é uma raiz simples da equação característica, e a ele corresponde um autovetor com entradas positivas.

O módulo dos demais autovalores é menor ou igual a r.

Além disso, se A tem h autovalores de módulo r então esses valores são todos distintos, são raízes da equação e o espectro de A é invariante por rotação de ângulo.

Este é um importante teorema cuja demonstração pode ser encontrada.

Estamos interessados em uma caracterização de matrizes complexas (limitadas em um certo sentido por uma matriz irredutível) em termos dos seus autovalores e que será dada de forma mais precisa a seguir.

Tal formulação está relacionada com o teorema de Frobenius.

Nesta definição de mínimo, excluimos os valores de i onde xi = 0.

Segue diretamente da definição que rx é o maior número.

Existe z tal que o valor máximo r da função rx é atingido.

Pela definição de rx, segue que ao multiplicarmos um vetor, por um número, o valor de rx não se altera.

Então, para calcularmos o máximo de rx, podemos nos restringir ao conjunto fechado.

Se a função rx fosse contínua em M, poderíamos obter um máximo.

Entretanto, esta função pode ser descontínua nos pontos de fronteira de M onde uma das coordenadas do vetor se anula.

Sendo assim, vamos considerar o conjunto.

Este conjunto é fechado e limitado, e consiste apenas de vetores positivos.

Assim, ao calcularmos o máximo de rx, podemos nos restringir ao conjunto N que consiste apenas de vetores positivos.

E em N, que é fechado e limitado, a função rx é contínua e portanto assume um valor máximo para algum vetor.

Diremos que um vetor z tal que rz = r é um vetor extremal.

O valor r definido no lema anterior é positivo, e é um autovalor de A (é o valor r mencionado no teorema de Frobenius).

Todo vetor extremal z é positivo e é um autovetor de A para o autovalor r.

Daí, r > 0, porque nenhuma coluna de uma matriz irredutível pode ser formada por zeros apenas.

Seja A uma matriz irredutível não negativa de ordem n e C uma matriz quadrada complexa de ordem n.

Então para todo autovalor de C vale onde r é o maior autovalor de A.

Além disso, vale a igualdade se é uma matriz diagonal cujos elementos não nulos tem módulo 1.

Segue daí que y é um vetor extremal para A, e é autovetor de A para o autovalor r.

Provamos esta última afirmação no caso de dimensão 2.

Os termos entre parenteses na última expressão são menores ou iguais a zero, claramente.

Mas não podem ser estritamente menores que zero (pois implicaria que a expressão é negativa).

Faremos aqui uma descrição breve de cadeias de Markov quânticas no contexto de álgebra de operadores.

Essa formulação é baseada na construção original.

A vantagem de se estudar cadeias de Markov quânticas no contexto de álgebras reside no fato de que podemos fazer uso do instrumental construído nesse ambiente para se tentar descobrir estados de equilíbrio, um problema importante em mecânica estatística quântica.

Discutiremos brevemente a relação entre os estados KMS e os estados de Gibbs, mencionados no capítulo anterior.

Uma álgebra A sobre C é um espaço vetorial complexo equipado com uma operação bilinear e associativa dita multiplicação.

Uma álgebra normada é uma álgebra A sobre C equipada com uma função norma que torna A um espaço normado.

Naturalmente, podemos nos referir à distância entre dois elementos de uma álgebra normada, bastando para isso considerar a métrica induzida pela norma.

Uma álgebra de Banach é uma álgebra normada completa.

Uma C-álgebra é uma álgebra de Banach equipada com uma involução.

Por exemplo, a álgebra Mn da matrizes de ordem n sobre C é uma C-álgebra se considerarmos as matrizes como sendo operadores no espaço euclideano Cn e se tomarmos a norma de operadores sobre matrizes.

A involução é dada pela matriz transposta conjugada.

A descrição de cadeias de Markov quânticas é uma construção conhecida em álgebra de operadores.

Nesse contexto, um estado é simplesmente um funcional.

Seja B uma C-álgebra para um certo espaço de Hilbert fixado H e o C-produto tensorial induzido pelo produto tensorial usual de espaços de Hilbert.

Uma aplicação bilinear é dita esperança de transição se for completamente positiva e preservar a identidade.

Cadeia de Markov quântica associada a um estado Um estado em A é uma cadeia de Markov quântica se existir um estado em B e uma esperança de transição.

Prova-se que toda esperança de transição tem a forma e tr2 é o traço parcial com respeito ao segundo fator.

O índice j percorrerá apenas um subconjunto finito de N se H for de dimensão finita, e esse será o caso considerado aqui.

Para cada K temos a expressão onde j é a matriz cuja posição é igual a 1, e as outras posições são nulas.

Denotaremos por D a sub-álgebra diagonal de Md correspondente à base.

Mostraremos agora como uma cadeia de Markov clássica valores em um espaço de probabilidade com distribuição inicial e matriz de transição pode ser vista como sendo uma cadeia de Markov quântica.

É fácil verificar que E1 é uma esperança de transição, e vale que é um estado.

Portanto é uma cadeia de Markov quântica e além disso tal cadeia quântica restrita à sub-álgebra diagonal D é simplesmente a cadeia de Markov clássica dada inicialmente.

Observe que a escolha não é única.

De fato, podemos trocar a matriz por qualquer outra matriz densidade que possua na diagonal os elementos.

Além disso, podemos trocar qualquer que possua a propriedade Então também é uma cadeia de Markov quântica obtida a partir da mesma cadeia clássica e além disso, restringindo as duas cadeias quânticas ao conjunto, obtemos a mesma cadeia de Markov clássica.

Note que então podemos considerar a matriz densidade inicial como sendo diagonal, já que os elementos fora da diagonal não são usados neste caso.

Uma esperança de transição leva D D em se e somente se para cada elemento, a matriz é tal que os elementos de sua diagonal são iguais a zero.

Cadeia de Markov quântica associada a um processo estocástico clássico Dizemos que um processo estocástico clássico que toma valores em um espaço de probabilidade é uma cadeia de Markov se as distribuições conjuntas são as mesmas.

Cadeia de Markov clássica associada a uma cadeia quântica Uma cadeia de Markov quântica é uma cadeia de Markov clássica na sub-álgebra diagonal.

Seja um processo estocástico clássico que toma valores em um espaço de probabilidade.

Então é uma cadeia de Markov quântica se e somente se existe uma medida de probabilidade e uma matriz cúbica (de 3 índices).

Seja um processo estocástico clássico que toma valores em um espaço de probabilidade.

Então temos que é uma cadeia de Markov quântica se e somente se existir uma cadeia de Markov clássica tomando valoresem um espaço de probabilidade.

Fazemos aqui uma breve introdução às CAR C-álgebras e aos estados KMS.

Uma álgebra A é uma álgebra associativa sobre os complexos, munida de uma involução que é um antiautomorfismo antilinear.

Um homomorfismo entre álgebras é um homomorfismo se for compatível com as involuções, ou seja, se é um uma aplicação bijetora.

Uma C-álgebra A tal que seus elementos satisfazem as relações de anticomutatividade canônicas.

O próximo teorema é a base de estudo de tais álgebras.

Seja H um espaço de Hilbert e sejam duas C-álgebras geradas pela identidade e elementos.

Portanto, existe uma única C-álgebra a menos de isomorfismo, satisfazendo as relações de anticomutatividade canônicas sobre H.

Além disso, se H tem dimensão n, temos que é isomorfa à C-álgebra das matrizes complexas.

Seja U a CAR-álgebra com geradores e respectivos adjuntos onde o conjunto de índices é discreto, enumerável e totalmente ordenado, contendo possivelmente um menor elemento e/ou um maior elemento.

Os geradores satisfazem as relações.

O automorfismo de paridade é denotado.

Para qualquer subconjunto, a C-sub-álgebra gerada é denotada.

Sabemos que é uma álgebra Z-graduada, sendo o automorfismo da graduação.

Sabemos também que a CAR-álgebra é isomorfa ao produto C-tensorial infinito.

A fim de obter estados periódicos ou invariantes por translação, consideramos apenas esperanças quase-condicionais invariantes, a menos que especificado em contrário.

Uma esperança quase-condicional com respeito à essa tripla é uma aplicação que é completamente positiva, preserva a identidade.

Um estado é dito estado de Markov se para cada j existe uma esperança quase-condicional En com respeito à tripla.

Uma esperança condicional (de Umegaki) é uma projeção de norma da C-álgebra em uma C-sub-álgebra (com a mesma identidade I).

Quando A é uma álgebra de matrizes, a estrutura de tal esperança condicional é bem conhecida.

As propriedades listadas são satisfeitas se trocarmos as esperanças quase-condicionais En por esperanças condicionais de Umegaki En.

As propriedades listadas são satisfeitas se trocarmos as esperanças condicionais En por esperanças quase-condicionais En.

Na prova desta proposição, consideramos a restrição, que é uma aplicação completamente positiva, que preserva a identidade.

Fazendo uso de um limite obtemos uma esperança condicional que deixa invariante o estado.

Seja um estado de Markov na CAR-álgebra e a seqüência associada de esperanças condicionais.

Em teoria quântica de campos descreve-se um sistema físico a partir de uma C-álgebra A com unidade.

Os elementos autoadjuntos de A (tais que u = u) são ditos observáveis do sistema.

Como vimos antes, um estado do sistema é definido com sendo um funcional C-linear.

Determinar a existência e a unicidade de estados KMS é importante para se estudar a mecânica estatística de uma teoria quântica de campos.

Por exemplo, considerando o espaço dos operadores compactos em um espaço de Hilbert dado, pode-se mostrar que o único estado sobre esse espaço que satisfaz a condição KMS acima com respeito ao valor fi é o estado de equilíbrio canônico de Gibbs, H é o hamiltoniano autoadjunto e N é o operador número.

Como antes, sejam u,v tais que u+v = 1, ju+jv = 1.

Vimos que as probabilidades de transição independem do tempo.

Vamos mostrar que a moeda quântica, vista como uma cadeia de Markov quântica algébrica (via álgebra de operadores) nos permite obter, como é desejável, estas mesmas probabilidades de transição.

Processos de Markov quânticos.

Neste apêndice fazemos uma descrição de processos de Markov quânticos.

Tal construção é mais elaborada do que a usada para cadeias de Markov quânticas e permite o estudo de sistemas mais complicados.

Mostramos ainda como a moeda quântica é descrita nesse contexto.

Um espaço de medida pontual é um espaço de medida em que conjuntos pontuais (isto é, com um elemento apenas) são mensuráveis.

Seja um conjunto não vazio, chamado espaço amostral.

Em processos estocásticos e em aplicações de mecânica quântica baseadas em amplitudes de transição, estamos interessados nos elementos de R(X) (os resultados das medições), e não no conjunto ou nas fibras.

Entretanto, seguiremos a descrição dada porque ela é útil para se descrever a interferência entre medições.

No caso de N-cadeias quânticas, supomos que S é um conjunto finito.

Iremos supor em geral que S é finito ou enumerável.

Mecânica quântica discreta.

Um estado que o sistema pode assumir.

Vemos que este exemplo possui uma estrutura semelhante ao da moeda quântica mencionada acima.

Mecânica quântica discreta com amplitudes de Feynman.

Este é um caso particular do anterior.

Pensamos em V como sendo um espaço de configuração discreto, e que está associado a um espaço de fase discreto.

Se X é mensurável, o conjunto de eventos de X é definido, o qual é uma álgebra de subconjuntos.

Veremos no exemplo da moeda quântica que se u,v com u + v = 1, ju + jv = 1, então definindo a onde n é o comprimento e k é o número de "caras"(ou zeros) na seqüência, vale que a é uma densidade de amplitude.

Definição O espaço de probabilidade quântica, denotado por A é o conjunto das medições para os quais a é uma densidade de amplitude.

Concluimos que PX é uma medida de probabilidade que chamamos de distribuição de X.

Nesse caso, a distribuição de Y é determinada quando realizamos a medição X.

É fácil mostrar que não é uma relação simétrica em geral.

Para ver como esta definição extende a de cadeias de Markov quânticas, considere X e Y medições.

Pela primeira definição, temos que se X não interfere em Y.

Dizemos que (Xt) é um processo estocástico quântico.

A equação afirma que uma medição no presente pode ser usada para se obter uma informação sobre o passado.

Isso é mais fraco do que a afirmação,ou seja, que a informação do passado está contida no presente.

Seja (Xt) um QSP em A quando o denominador não se anula.

Caso contrário, definimos o lado esquerdo como sendo igual a zero.

Definição Dizemos que (Xt) é um processo de Markov quântico (QMP) quase-discreto.

Para analisar os exemplos desta seção, resumimos as expressões para amplitude e probabilidade obtidas na seção anterior.

Iremos dar atenção maior para o exemplo da moeda quântica descrito a seguir.

Primeiro, faremos a construção, adotando a notação usada ali (isto é, com as fórmulas de amplitude e de probabilidade ênunciadas acima).

Depois, enunciaremos a construção em uma forma que é mais usual em teoria da medida.

Existem outras construções na literatura, também ditas moedas quânticas, que são usadas com mais frequência.

Uma condição necessária e suficiente para que essas propriedades sejam satisfeitas.

Então, vemos que o número real determina u e v a menos de conjugação.

Considerando a medida da contagem na imagem e nas fibras de Xj, vemos que Xj é uma medição(para considera ções sobre cilindros).

Então representa n jogadas de moeda e Xj mede o resultado da j-ésima jogada.

Observação 1.

Em teoria da medida, o exemplo acima admite uma constru ção muito mais simples.

Seja B a álgebra gerada pelos cilindros.

A densidade de amplitude de Bk pode ser vista como sendo uma medida complexa, e então obtemos uma única extensão para a álgebra gerada pelos cilindros, pelo teorema da êxtensão de Kolmogorov.

A probabilidade é obtida tomando o módulo ao quadrado desta medida, o que está de acordo com os cálculos de amplitudes feitos acima.

Ainda, não precisamos nos preocupar em definir uma medida e uma álgebra na imagem e nas fibras das medições.

Considerando a medida da contagem na imagem e nas fibras de Xj, temos que Xj é uma medição.

Logo, os Xj são identicamente distribuidos, e como no exemplo, eles são mutuamente independentes e formam um QMP.

Entretanto, ao contrário do exemplo, os Xj interferem entre si.

Mecânica quântica discreta.

Seja S um conjunto não vazio de estados que uma partícula pode assumir.

Uma matriz de amplitude de transição de uma cadeia de Markov quântica induz uma função de amplitude de transição estocástica.

Denote o conjunto das funções de amplitude de transição estocástica por T(S).

Equipado com essa estrutura, Xj é uma medição e vale.

Se j < k, vale que Xk não interfere em Xj.

Mas exemplos simples mostram que Xj pode interferir em Xk.

Além disso, Xj e Xk não são independentes em geral.

Finalmente, vale que é um QMP quase-discreto.

Vamos analisar um modelo concreto para a mecânica quântica discreta em 2 dimensões.

Sejam a e m inteiros positivos relativamente primos, m par.

Seja vetores unitários em R2 tais que cada um forma um ângulo com o anterior.

Pensamos em V como sendo um espaço de configuração discreto, e que está associado a um espaço de fase discreto.

Pode-se mostrar que um múltiplo constante de A1, de módulo 1, está contido em T(S).

Como tal múltiplo não afeta as probabilidades, iremos assumir que A1=T(S).

Se fizermos com que o número m corresponda à massa da partícula, então o somatório corresponde à integral da energia cinética sobre o caminho.

Desta forma, A1(p) se aproxima da amplitude de Feynman usual (contínua) para uma partícula livre.

Ainda, de maneira análoga a feita para cadeias quânticas, podemos também calcular a entropia de processos de Markov.

Usando a expressão para a probabilidade de um evento, que repetimos aqui, podemos calcular a entropia de Shannon e a de von Neumann dos exemplos que consideramos.

No caso da moeda quântica, os dois casos que consideramos (número finito ou arbitrário de medições) possuiam a mesma distribuição estacionária.

O operador de densidade é associado (após definição de entropia de von Neumann).

Segue do item da definição de QMP quase-discreto que Ks, t existe e é finito, e pelo item 3 vale que Fs, t é mensurável em ambas as variáveis.

Fazendo uma analogia com um núcleo de Markov, vemos que Ks, t é uma medida complexa limitada e que Ks, t é mensurável em Rs.

Integrando a primeira igualdade, obtemos a segunda.

Segue da definição de QMP que Kt é mensurável na segunda variável e é uma medida complexa limitada na primeira variável.

Agora mostraremos que neste caso Ut é um semigrupo unitário a um parâmetro.

Mostraremos também que (Xt) é unitário se e somente se Ut é unitário para todo t.

Se (Xt) é unitário então Ut é um operador unitário.

Portanto, Ut restrita ao subespaço denso S de funções simples possui norma 1.

Logo, esta restrição possui uma única extensão linear e limitada Ut para H de norma 1.

Agora seja g qualquer.

Então existe uma seqüência g tal que para todo x e g na convergência da norma.

Segue que existe uma subseqüência, que também denotaremos por gi.

Logo, Ut = Ut e portanto Ut é limitada.

Mostremos que Ut é unitária.

Note que a adjunta de Ut é dada.

Se (Xt) é contínuo, unitário e estacionário, então Ut é fortemente contínuo.

Mostraremos que Ut é fracamente contínuo em 0, donde o resultado segue.

Para g temos, aplicando a desigualdade de Schwarz.

Sob as condições do teorema anterior, temos que Ut é um grupo unitário a um parâmetro contínuo.

Portanto, pelo teorema de Stone, Ut = eitH para um único operador auto-adjunto H.

Chamamos tal processo de processo Hamiltoniano.

Se (Xt) é estacionário e unitário então Xt não interfere em Xs.

