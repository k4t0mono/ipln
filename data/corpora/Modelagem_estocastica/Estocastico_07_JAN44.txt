O preço do petróleo é influenciado por uma enorme quantidade de fatores, cujas características, muitas vezes extremamente complexas, tornam sua previsão por fundamentos uma tarefa bastante complicada.

Uma forma alternativa de se tentar fazer esta previsão é através de modelos de séries temporais, os quais, observando apenas seu comportamento passado, tentam inferir seu comportamento futuro.

Nesta dissertação, investigamos a capacidade de um modelo de séries temporais não linear, conhecido como Modelo de Markov Oculto (HMM), em prever movimentos futuros do preço do petróleo.

Tomando-o como base, elaboramos uma metodologia de previsão que consiste em, basicamente, duas etapas.

Na primeira, devido a intensa volatilidade intrínseca, suavizamos a série de preços utilizando Wavelets.

Em seguida, utilizamos o HMM para prever a distribuição probabilística da variação acumulada pelo preço, ao final de uma janela futura de F dias.

A partir desta distribuição, inferimos a direção futura do preço.

Nossos resultados sugerem que o Modelo de Markov Oculto pode ser uma interessante ferramenta de auxílio a tomada de decisão de investimentos por participantes do mercado de petróleo.

Assim como ocorre com a maioria das mercadorias comercializadas, o preço do petróleo é, basicamente, determinado pelo balanço entre oferta e demanda.

Apesar de ser, aparentemente, simples, este balanço é bastante complexo, pois existem inúmeras variáveis, muitas das quais são imprevisíveis e extremamente voláteis, que podem afetá-lo.

Guerras e tensões políticas, descobertas de novas reservas, intensidade dos invernos, desenvolvimento de novas fontes de energia, introdução de novas tecnologias de exploração, desenvolvimento econômico, são apenas alguns exemplos de fatores que pressionam a balança para um lado ou para outro, e, portanto, exercem influência sobre preço do petróleo.

A recente crise econômica é um excelente exemplo do enorme conjunto de fatores que, de uma forma ou outra, afetam o mercado do petróleo.

Até o primeiro semestre de 2008, o preço do óleo cru vinha experimentando uma forte valorização, impulsionada pela alta liquidez mundial e pelo acelerado crescimento econômico do mundo, especialmente da China.

Somente entre janeiro de 2007 e julho de 2008, o preço do West Texas Intermediate (WTI)1 elevou-se de 60 para 140 dólares, sofrendo uma incrível valorização de 130%.

No entanto, a crise do mercado imobiliário americano, que surgiu no segundo semestre de 2008, foi suficiente para desencadear uma série de eventos que colocaram o mundo em uma grave recessão econômica, e, consequentemente, fizeram o preço do WTI despencar dos 140 dólares, para, aproximadamente, 40 dólares, ao final de 2008.

Esta intensa volatilidade de preço é extremamente prejudicial para empresas e países dependentes de petróleo, tanto consumidores quanto produtores.

Tomemos como exemplo o caso das companhias aéreas.

Um insumo essencial e insubstituível neste ramo é o querosene de aviação.

A elevação brusca dos preços do petróleo, como a mencionada acima, aumenta, na mesma velocidade, os custos destas companhias, que, obrigadas a se adaptarem rapidamente a nova realidade, acabam repassando este aumento para os consumidores e, muitas vezes, despedindo funcionários.

Existem diversas maneiras pelas quais um agente pode tentar se proteger destas oscilações no preço.

A mais comum é a utilização de instrumentos de hedge.

A forma mais usual de se fazer um hedge é utilizando os mercados futuros ou a termo, como é ilustrado pelo exemplo a seguir.

Suponha que um refinador saiba que, no mês seguinte, precisará comprar uma determinada quantidade de óleo cru.

Evidentemente, o refinador não sabe quanto o barril do petróleo estará custando nesta data.

Com medo de um possível aumento do preço, ele decide, hoje, negociar com seu fornecedor o preço de compra do barril daqui há um mês.

Assim, ambos fazem um contrato, conhecido como contrato a termo, no qual comprometem-se a, no mês seguinte, negociar o barril de petróleo por, digamos, 50 dólares.

Desta forma,o refinador garante seu preço de compra e não precisa mais se preocupar com as flutuações do preço.

Uma excelente discussão sobre instrumentos e estratégias de hedge pode ser encontrada em.

No exemplo acima, apesar de o refinador ter eliminado seu risco, fixando o preço de compra do barril em 50 dólares, nada garante que ele fez um bom negócio.

Isto só será verdade se, no mês da compra, o preço do petróleo no mercado à vista for superior a 50 dólares o barril.

Caso não o seja, ele poderá se arrepender de ter feito o hedge! O exemplo anterior ilustra a importância de se construir um modelo de previsão para o preço do petróleo.

No entanto, devido às inúmeras variáveis que o afetam, e da complexidade destas, a construção de um modelo de regressão, que relaciona o preço a um conjunto de outras variáveis, em uma estrutura de casualidades, é uma tarefa bastante difícil.

Assim, uma forma alternativa de se tentar fazer esta previsão, é através de modelos de séries temporais, os quais, observando somente o comportamento passado de uma variável, tentam inferir seu comportamento futuro.

Nosso trabalho se insere neste contexto.

O objetivo desta dissertação é propor uma metodologia que, observando a din âmica recente dos preços do petróleo, tenta prever seu comportamento futuro, no curto prazo.

Mais especificamente, procuramos, através da metodologia proposta, prever a distribuição da variação acumulada pelo preço do petróleo ao final de uma janela de tempo futura de F dias.

Esperamos, deste modo, construir um instrumento que auxilie a tomada de decisão de investimentos, por participantes do mercado de petróleo.

Devido a volatilidade dos preços, utilizamos uma técnica de suavização derivada da aproximação de funções por Wavelets, buscando, assim, eliminar parte do ruído existente na série e ressaltar suas reais tendências.

Em seguida, fazemos a modelagem da dinâmica dos preços, e sua previsão, utilizando um modelo de Markov oculto.

As principais contribuições desta dissertação são a apresentação de uma técnica para suavização de séries temporais financeiras (que já é bastante consolidada na área de compressão de imagens e processamento de sinais, mas ainda pouco explorada na área de finanças), e a verificação da serventia dos modelos de Markov ocultos na previsão das mesmas.

Discorremos sobre os principais conceitos matemáticos que serão utilizados ao longo desta dissertação.

Começamos introduzindo a teoria básica de modelos de Markov e, então, extendemo-la para os modelos de Markov ocultos.

Em seguida, apresentamos as Wavelets.

Discutimos os principais modelos que são utilizados na previsão de séries financeiras, e apresentamos alguns resultados obtidos por outros trabalhos.

A metodologia proposta é detalhadamente apresentada, e seus resultados são exibidos no capítulo 5.

Fenômenos que ocorrem no mundo geralmente produzem algum tipo de saída observável, a qual denominamos de sinal.

Devido à dificuldade e/ou custo de se manipular estes sistemas diretamente, é de grande interesse estudar e caracterizar seus sinais através de modelos, para que possamos aprender sobre seu processo gerador, sem que haja necessidade de termos o processo real disponível.

Tais modelos nos permitem simular a fonte geradora do sinal e construir diferentes sistemas, como os de previsão, de reconhecimento, de identificação, etc, de maneira eficiente.

Existem duas classes de modelos, determinísticos e estocásticos.

Nesta dissertação, utilizamos um modelo estocástico cada vez mais em uso, o modelo de Markov oculto (HMM, do inglês Hidden Markov Model).

Devido a sua rica e estabelecida estrutura matemática, o HMM tem sido extensivamente utilizado na área de reconhecimento de voz, e vem se tornando cada vez mais popular em diversas outras áreas, como bioinformática, processamento de sinais e redes de computadores.

A idéia principal por trás do modelo é que existem diversos fenômenos cujas saídas dependem de fatores que não são diretamente observáveis (estão ocultos) mas podem ser inferidos a partir destas saídas.

Utilizando-o, é possível fazer uma distinção estatística destes fatores ocultos, separando-os em diferentes estados de uma cadeia de Markov, o que por sua vez, em muitos casos, permite também uma fácil visualização, interpretação e caracterização dos mesmos.

Começamos este capítulo introduzindo os conceitos dos modelos de Markov, e extendemo-los para o modelo de Markov oculto.

Em seguida, caracterizamos o HMM e apresentamos seus fundamentos matemáticos.

Considere um sistema que possa ser descrito como estando em um de N estados distintos.

Cujas transições de estado são dadas por um conjunto de probabilidades associadas a cada estado Si (onde N = 3 por simplicidade).

A cada instante de tempo, o sistema é observado a fim de se determinar seu estado atual.

Denotaremos por qt o estado no qual o sistema se encontra no tempo t.

Em geral, uma descrição probabilística completa de um sistema como este requer que sejam especificados o estado atual qt, assim como todos os estados anteriores.

Entretanto, para o caso de um processo markoviano, essa descrição é reduzida a apenas o estado atual e o imediatamente anterior.

Cadeia de Markov de tempo discreto com 3 estados e suas transições.

Consideramos ainda, apenas os processos cujo lado direito de é independente do tempo, o que nos leva a um conjunto de probabilidades de transição de estados da forma cujos coeficientes têm as seguintes propriedades pois obedecem às restrições estocásticas.

O processo estocástico descrito acima é conhecido como modelo de Markov observável, uma vez que sua saída é o conjunto dos estados nos quais a cadeia se encontrava em cada instante de tempo t, e cada estado corresponde a um evento diretamente observável.

Para ilustrar os conceitos apresentados, suponha um modelo de Markov de tempo discreto, simples, de três estados, que descreva o tempo meteorol ógico de uma região qualquer.

Assumimos que, a cada dia, o tempo é observado como estando em um de três estados distintos, Estado 1, chuvoso, Estado 2, nublado, Estado 3, Sol, e que cada estado da cadeia representa um dos três estados acima.

Dado que o tempo no primeiro dia é sol, podemos nos perguntar qual seria a probabilidade (de acordo com o modelo) de que nos próximos sete dias o tempo seja sol, sol, chuva, chuva, sol, nublado, sol.

O que queremos saber é, dado o modelo, qual a probabilidade de O.

Distribuição do Tempo de Permanência em um Estado.

Outra pergunta que podemos fazer é dado que o modelo se encontra em um determinado estado, qual a probabilidade de ele permanecer no mesmo, por exatamente d dias Em termos formais, queremos encontrar a probabilidade da seqüência de observações.

Esta pode ser expressa como onde pié a distribuição de probabilidades discreta da duração d no estado i.

É importante ressaltar que, esta distribuição exponencial (ou geométrica, no caso da cadeia de Markov em tempo discreto) é característica da duração de um estado nas cadeias de Markov.

Podemos assim, dado pi, calcular o tempo esperado (a duração, em número de transições) que a cadeia permanece em um mesmo estado.

Voltando ao nosso problema de previsão da meteorologia, o número esperado de dias consecutivos de sol é, segundo o modelo, 1/(10,8), 5 dias para tempo nublado,esse valor é de 2,5 dias, e para chuva, 1,67 dias.

Nos modelos de Markov de tempo discreto, o sistema é observado em instantes de tempo discretos, bem definidos.

No nosso modelo de previsão meteorológica, por exemplo, observamos o tempo uma vez a cada dia.

Existe, no entanto, uma outra classe de modelos de Markov, nos quais o sistema é observado continuamente, a todo instante de tempo.

Estes são conhecidos como modelos de Markov de tempo contínuo.

A principal característica desta classe de modelos é que, para cada estado, há um conjunto de um ou mais eventos que, ao ocorrerem, podem fazer a cadeia transicionar de estado.

Para cada evento i, o tempo decorrido até sua próxima ocorrência segue uma distribuição exponencial, onde ti é o intervalo de tempo entre duas ocorrências do evento i, e é a taxa de ocorrência do evento i.

Para todos os eventos, seus tempos até a próxima ocorrência são independentes entre si e, para um mesmo evento, tempos de ocorrência sucessivos são, também, independentes entre si.

Visando ilustrar estes novos conceitos, vamos voltar ao problema da seção anterior, e criar um modelo de Markov de tempo contínuo para o tempo meteorológico.

Observe que a estrutura da cadeia permanece a mesma, cada estado continua representando um dos três estados definidos para o tempo sol, chuva, nublado.

Entretanto, as transições, agora, não são mais descritas por probabilidades, e sim por taxas do tipo j, que definem a distribuição exponencial do intervalo de tempo até a próxima ocorrência do evento associado à transição ij.

Cadeia de Markov de tempo contínuo com 3 estados e suas transições.

Comparando os dois modelos construídos, o de tempo contínuo e o de tempo discreto, e suas interpretações, fica evidente a diferença do primeiro em relação ao segundo.

Enquanto no modelo de tempo discreto o sistema é observado em instantes de tempos definidos, no modelo de tempo contínuo ele é observado continuamente, e suas mudanças de estado, que são definidas pela ocorrência de eventos, podem ocorrer em qualquer instante do tempo.

Isto significa que, no caso do nosso exemplo, um modelo de tempo discreto permite que haja, apenas, um estado meteorológico por dia.

Já o modelo de tempo contínuo permite que, em um mesmo dia, haja dois ou mais estados meteorológicos distintos, tempo nublado e chuva, por exemplo.

Conjunto amostral possível em um modelo de Markov de tempo discreto, um modelo de Markov de tempo contínuo.

Formalmente, descrevemos a cadeia de Markov de tempo contínuo por dois elementos.

O primeiro, o vetor p = P, é idêntico àquele definido para cadeias de Markov de tempo discreto, e informa a probabilidade de a cadeia se encontrar no estado i.

O segundo, a matriz Q, é semelhante à matriz A definida anteriormente, e descreve as transições da cadeia.

Distribuição do Tempo de Permanência em um Estado Dado que o tempo de ocorrência de cada evento é exponencial, é evidente que o tempo de permanência em um mesmo estado i é, também, exponencialmente distribuído, com taxa.

No modelo markoviano, cada estado corresponde a um evento diretamente observável (chuva, tempo nublado ou sol).

Entretanto, existem fenômenos nos quais podemos apenas observar suas saídas (seus sinais), e não o processo que as gerou.

Para modelá-los, estendemos o conceito de modelo markoviano para incluir casos nos quais os sinais são uma função probabilística do estado da cadeia.

Tais modelos são conhecidos como modelos de Markov ocultos.

O HMM é definido como um processo estocástico duplamente embutido, no qual o primeiro não é diretamente observável (é oculto), mas pode ser inferido através de um segundo conjunto de processos estocásticos, os quais produzem a seqüência de observação (os sinais).

A fim de clarear estes conceitos, considere o exemplo a seguir suponha que, em um quarto, exista uma barreira (uma cortina, por exemplo), atrás da qual há um jogador que dispõe de uma ou mais moedas, que podem ou não estar viciadas.

Uma segunda pessoa, a quem chamaremos de observador, está do outro lado da cortina, e não pode ver o que acontece do lado do jogador.

O jogador, segundo um critério qualquer, escolhe uma moeda, joga-a para o alto, e informa, ao observador, o resul tado (cara ou coroa).

Ele então repõe a moeda ao conjunto de moedas, escolhe uma novamente, e realiza o mesmo experimento.

Assim, o observador conhece apenas o resultado de cada jogada (esta é a saída observável), mas desconhece qual das moedas que estão ocultas gerou esta saída.

Dado este cenário, um problema de interesse é o de como construir um modelo markoviano que explique a seqüência de caras e coroas observada.

Uma primeira tentativa seria construir um modelo com apenas dois estados, no qual cada estado representa um lado da moeda.

Neste caso, estaríamos assumindo que há apenas uma moeda sendo lançada, e, portanto, o modelo construído seria um modelo markoviano observável.

Definida a estrutura do modelo, o próximo passo seria decidir o valor para o viés da moeda, ou seja, a probabilidade de cada evento ocorrer.

Entretanto, poderíamos assumir que em vez de uma, há duas moedas sendo utilizadas.

Assim, construiríamos um HMM de dois estados, no qual cada um representaria uma moeda diferente, e seria caracterizado por uma distribuição de probabilidades de eventos, que, neste caso, se resumiria ao viés da moeda.

O mecanismo que representaria a escolha das moedas seria, então, representado por uma matriz de probabilidades de transição de estados.

Procedendo da mesma maneira, poderíamos assumir que há três moedas sendo jogadas e, nesses caso, construiríamos um HMM de três estados.

Assim, a cadeia de Markov utilizada é a de tempo discreto.

Modelo de Markov observável, de tempo discreto, para a suposição de que existe, apenas, uma moeda sendo lançada.

Modelo de Markov oculto, de tempo discreto, para a suposição de que existem duas moedas.

Elementos de um HMM de Tempo Discreto.

Formalmente, um HMM é caracterizado pelos cinco elementos a seguir.

N, o número de estados do modelo.

Apesar de estarem ocultos, geralmente são dotados de algum significado físico.

M, o número de símbolos distintos observáveis por estado.

Correspondem às saídas físicas observáveis do sistema modelado.

A = {aij}, a matriz de probabilidades de transição de estados.

P = {pi}, o vetor de distribuição inicial de estados.

Assim, como pode ser visto acima, uma descrição completa de um HMM necessita que sejam especificados dois parâmetros do modelo (N e M), os símbolos de observação, e mais três medidas de probabilidade (A, B e p).

Por conveniência, usaremos, no restante desta dissertação, a notação compacta = (A,B, p) para indicar o conjunto completo de parâmetros de um modelo HMM.

Após a especificação do modelo, o problema que surge naturalmente é como calibrar seus parâmetros de acordo com a seqüência de observações dada? Esta pergunta pode ser dividida em duas etapas.

Na primeira, queremos encontrar uma maneira eficiente de avaliara probabilidade de a seqüência ter sido gerada pelo modelo.

Na segunda, precisamos estimar os parâmetros de modo a maximizar, ou seja, buscamos ajustar nosso modelo, da melhor forma possível, aos dados reais.

Este processo de ajuste é conhecido como Método de Máxima Verossimilhança (MMV).

A seqüência de observações usada para fazer esta adaptação é chamada de seqüência de treinamento, uma vez que é usada para treinar 3 o HMM.

O MMV busca encontrar um estimador de máxima verossimilhança.

Infelizmente, para o caso de um HMM, não se conhece uma expressão analítica para este estimador.

Entretanto, existe um método, derivado do algoritmo ExpectationMaximization(EM), conhecido como algoritmo de Baum-Welch, que realiza a estimação de parâmetros de máxima verossimilhança para um HMM de forma iterativa.

Ele começa com uma atribuição arbitrária de valores para, e produz estimativas sucessivamente melhores, garantindo a convergência para um máximo local da função de verossimilhança, sempre que um existir.

Na literatura de HMM's, a palavra treinamento é utilizada como sinônimo de estimação de parâmetros.

Entretanto, é importante ressaltar que, diferentemente de um treinamento de redes neurais, por exemplo, o treinamento do HMM não envolve aprendizado com os erros.

A seguir, apresentamos as soluções matemáticas para ambas as etapas descritas acima.

A primeiropode ser resolvida pelo procedimento forward-backward, e a segunda (estimação do parâmetros) utilizando o algoritmo EM.

A variável forward é inicializada com o valor da probabilidade de a cadeia estar no estado i em t = 1 e o símbolo O1 ter sido emitido pelo mesmo.

O estado Sj pode ter sido atingido partindo-se de qualquer um dos N estados, portanto, a probabilidade de a cadeia estar em Sj e da seqüência, em, é dada pelo somatório da indução.

Uma vez no estado Sj, temos que considerar a emissão do símbolo Ot+1.

Para tal, basta multiplicarmos o valor do somatório por bj.

Finalmente, se somarmos todas as variáveis terminais aT, encontramos P.

Procedimento Forward.

Seja a variável backward t definida, isto é, a probabilidade de observarmos a seqüência parcial, no intervalo de tempo, dado que a cadeia está no estado Si, no tempo t, e o modelo.

Na inicialização, definimos, arbitrariamente, que T = 1.

Em t+1 a cadeia pode ter transicionado para qualquer um de seus N estados.

Neste, com probabilidade bjé emitido o símbolo Ot+1.

Assim, tpode ser calculado a partir de t+1, segundo a indução descrita acima.

Procedimento Backward.

Note-se que podemos calcular Pusando apenas a variável forward do procedimento forward-backward.

Entretanto, a variável backward é utilizada pelo algoritmo EM (descrito a seguir) e, portanto, foi necessário definí-la também.

O algoritmo EM é um método para estimação de parâmetros de máxima verossimilhança de uma distribuição, a partir de um conjunto de dados incompleto.

Existem dois cenários principais nos quais é interessante a aplicação do EM.

No primeiro, o conjunto de dados não contém todos os valores, ou seja, há dados que estão faltando, que foram perdidos.

Isto pode ocorrer por problemas ou limitações no processo de observação.

No segundo, a otimização da função de verossimilhança é intratável analiticamente, mas pode ser aproximada se assumirmos a existência de parâmetros ocultos.

Este último cenário é o que se aplica a um HMM.

Como definido anteriormente, seja a seqüência de dados observada, a qual chamaremos de seqüência incompleta de dados, e a seqüência (oculta) de estados da cadeia que gerou O.

Seja Z = (O, q) o conjunto completo de dados, chamada de verossimilhança de dados completos, onde a última igualdade é obtida pelo teorema de Bayes.

É importante observar que esta função é, na realidade, uma variável aleatória, uma vez que q é desconhecido e, presumidamente, governado por alguma distribuição.

O primeiro passo do algoritmo EM, chamado de passo-E, é encontrar a esperança do log da função de verossimilhança de dados completa, log, com respeito ao conjunto de dados ocultos q, dada a seqüência observada O e os valores atuais iniciais dos parâmetros do modelo.

Assim, definimos a função auxiliar onde é o conjunto de parâmetros atuais do modelo usados para calcular a esperan ça, o conjunto de novos parâmetros que serão otimizados a fim de maximizar Q, e Q é o conjunto de todas as seqüências de estados possíveis, de tamanho T.

O segundo passo do EM, chamado de passo-M, é maximizar a esperança obtida no primeiro passo.

Como os parâmetros que desejamos otimizar (p,A e B) estão separados em três termos independentes na soma vista na equação, podemos maximizar individualmente cada um.

Maximizando cada termo, e levando em conta as restrições estocásticas,onde utilizamos a notação I{c} para representar a função indicadora de uma condição c, que vale 1 quando a condição é satisfeita, e 0, caso contrário.

As probabilidades encontradas nas equações podem ser calculadas a partir das variáveis forward e backward.

Isto é, a probabilidade de se estar no estado Si no instante t, dada a seqüência de observações O e o modelo.

Podemos expressar a equação em termos das variáveis forward e backward onde atcontribui com a seqüência parcial de observação e o estado Si no tempo t, enquanto tcontribui com o restante da seqüência, dado o estado Si no tempo t.

Se somarmos para todo t, encontramos um valor que pode ser interpretado como o número esperado (no tempo) de visitas ao estado Si, ou, equivalentemente, o número esperado de transições a partir do estado Si (se excluirmos o tempo T da soma).

Seja também a variável, definida como a probabilidade de transição do estado i, no instante de tempo t, para o estado j, no instante de tempo, dado o modelo e a seqüência de observações O.

Similarmente, o somatório de em t pode ser interpretado como o número esperado de transições do estado Si para o estado Sj.

Assim, expressões podem ser reescritas em termos, e interpretadas, intuitivamente.

Estes dois passos (passo E e passo M) são repetidos.

Foi provado por Baum e seus co-autores que, a cada iteração do algoritmo, ou os parâmetros iniciais definem um ponto crítico da função de verossimilhança, ou o novo modelo estimado é mais provável que o inicial.

Desse modo, fica garantido que o algoritmo converge para um máximo local da função de verossimilhança.

Influência dos Valores Iniciais dos Parâmetros.

Em teoria, as equações de reestimação devem fornecer valores dos parâmetros do HMM que correspondam à um máximo local da função de verossimilhança.

Conforme visto acima, o algoritmo EM necessita que, para cada parâmetro a ser estimado, tenha sido dado um valor inicial.

Assim, uma pergunta que surge é como estimar estes valores iniciais, de modo que o máximo local atingido pelo algoritmo corresponda ao máximo global.

Infelizmente, não há resposta simples para esta questão, indica que, para os parâmetros p e A, uma escolha uniforme ou alea tória de valores iniciais é adequada para a maioria dos casos.

Entretanto, para os parâmetros de B, uma boa escolha dos valores iniciais, baseada no conhecimento do processo o qual se está estudando, pode ter grande influência.

Wavelets são funções matemáticas ondulatórias, de duração limitada, cuja integral no tempo é zero.

Assim como as funções seno e cosseno na análise de Fourier, wavelets são utilizadas como funções base para a representação de outras funções pertencentes a L2 4.

As wavelets surgiram no início do século XX, tendo sua primeira menção sido feita num apêndice da tese de A Haar em 1909.

Entretanto, a maior parte do trabalho foi feito nos anos 30.

Hoje,é o espaço vetorial das funções unidimensionais, mensuráveis e quadraticamente integráveis.

Uma função é dita quadraticamente integrável se a integral do quadrado de seu valor absoluto é finito, ou seja, se a teoria matemática por trás das wavelets já está bastante consolidada, e suas aplicações podem ser vistas nas áreas de compressão de dados, astronomia, acústica, engenharia nuclear, processamento de sinais e imagens, música, ótica, previsão de terremotos, solução de equações diferenciais, entre outras.

Exemplos de Wavelets, wavelet de Haar wavelet de Daubechie de ordem 3 wavelet de Meyer wavelet de Morlet.

Suponha uma função qualquer f(x).

A análise de Fourier consiste em construir uma aproximação f(x), a partir da soma de senos e cossenos com diferentes freqüências onde os coeficientes a0, ai e bi são obtidos através da Transformada de Fourier.

Os coeficientes obtidos de F (conhecidos como coeficientes de Fourier) quando multiplicados por suas respectivas senóides de freqüência, formam os componentes senoidais nos quais a função original é decomposta.

Sinal original e suas componentes senoidais.

A análise por wavelets é feita de forma semelhante, no entanto, ao invés das funções seno e cosseno, utilizamos versões escalonadas (através de dilatações e contra ções) e transladas da wavelet original (x), que é conhecida como wavelet mãe do inglês mother wavelet.

Assim, a aproximação f(x) é obtida pela combinação linear onde a transformada de wavelet C(escala,translação) fornece os coeficientes de wavelet C(escala,translação) que, multiplicados pela wavelet mãe, apropriadamente escalonada e transladada, formam os componentes nos quais a função original é decomposta.

Sinal original e suas componentes de wavelets As principais diferenças entre a análise por wavelets e a análise de Fourier são conseqüência da característica local das wavelets.

Note que, enquanto as funções seno e cosseno são infinitas, se estendem sobre todo o domínio de f(x), as wavelets têm duração limitada, são finitas.

Esta importante característica traz à análise por wavelets uma série de vantagens sobre a análise de Fourier.

Ela nos permite fazer um estudo local do sinal, de partes específicas do mesmo, sem que seus resultados afetem todo o domínio da função, como ocorre com a análise de Fourier.

Suponha que nossa função f(x) seja suave, definida no domínio x (8,8) e que, em um pequeno intervalo dela, x, por exemplo, haja um ruído de alta freqüência.

Na análise de Fourier, a representação deste ruído terá reflexos em todo o domínio de f(x), uma vez que os senos e cossenos de alta freqüência, utilizados pela análise para representar o ruído, se estendem por todo o domínio.

Já na análise por wavelets isto não ocorre.

Nesta, o ruído também será representado por wavelets de alta freqüência, no entanto, devido a característica local destas funções, sua utilização terá reflexos apenas no intervalo dentro do qual o ruído está contido, ou, no máximo, em uma vizinhança curta do mesmo.

Este fato torna as wavelets mais vantajosas de serem utilizadas (do que a análise de Fourier) para representar funções que apresentam alguma descontinuidade ou picos abruptos.

A análise por wavelets também fornece mais informações sobre o sinal do que a análise de Fourier.

O estudo de uma função pelo método de Fourier nos mostra as diferentes freqüências que compõe o sinal.

No entanto, ele não nos permite identificar nem quando, nem onde, cada uma destas freqüências ocorre.

Já através de um estudo com wavelets, conseguimos saber ambas estas informações.

Como uma wavelet é descrita por uma escala e uma posição no tempo, observando as wavelets que compõe a representação da função, podemos identificar exatamente quando, no tempo, as diferentes freqüências do sinal ocorrem.

Análise por Fourier, Frequência Valor do Coeficiente.

Análise por Wavelets Tempo Escala Valor do Coeficiente Frequência.

Resultado da análise de Fourier Resultado da análise por Wavelets.

Além de conter mais informações, em muitos casos, as representações feitas com wavelets são mais compactas do que aquelas feitas pela análise de Fourier.

Isto significa que são necessárias significativamente menos wavelets do que senos e cossenos para atingir uma aproximação comparável.

O tempo de cálculo da transformada é outra vantagem das wavelets sobre Fourier.

A da primeira tem complexidade computacional O(n) enquanto a da segunda tem complexidade O(n log2 n).

Estas e outras vantagens fazem das wavelets um excelente método para análise de dados.

Dentre suas principais aplicações, podemos citar sua utilização na remoção de ruídos de séries temporais e na compactação de dados.

Apenas como exemplo de sua importância, podemos citar que, no início da década de 90, o FBI 5 padronizou o uso de wavelets na compactação de imagens de impressões digitais.

A seguir, introduzimos as transformadas contínua e discreta de wavelets, e ilustramos o algoritmo conhecido como transformada rápida de wavelets, utilizado para calcular a transformada discreta.

Procuramos deixar bem claros os conceitos, apresentamos a base matemática por detrás dos métodos, e utilizamos exemplos sempre que necessário.

A equação define a Transformada Contínua de Wavelets (CWT, do inglês Continuous Wavelet Transform).

A CWT é a soma, sobre todo o tempo, do sinal multiplicado por versões escalonadas e transladadas da wavelet mãe.

Este processo produz os coeficientes de wavelets que são funções de escala e posição.

Selecione uma wavelet e compare-a a uma seção do início do sinal original.

Calcule um número C, que representa o quão correlacionados estão a wavelet e a seção em questão do sinal.

Quanto maior for C, maior a similaridade entre ambas.

Note que o resultado vai depender da forma da wavelet escolhida.

Translade a wavelet para a direita, e repita os passos 1 e 2 até que tenha Dilate a wavelet, e repita os passos 1 a 3.

Repita os passos de 1 a 4 para todas as escalas (dilatações) possíveis.

Como resultado, teremos os coeficientes de wavelets produzidos por diferentes escalas e em diferentes seções do sinal.

O problema com esta transformada é que, por ser contínua, ou seja, por analisar o sinal em todas as escalas e posições possíveis, leva um tempo muito grande para ser calculada, e gera um conjunto enorme de dados.

Precisamos então de um método que nos permita trabalhar apenas com um subconjunto destas escalas e posições.

Isto nos leva a Transformada Discreta de Wavelets (DWT do inglês Discrete Wavelet Transform).

A Transformada Discreta de Wavelets recebe esse nome pois usa um subconjunto finito de escalonamentos e translações da wavelet mãe para construir a aproximação.

Normalmente, opta-se por fazer o escalonamento das wavelets em intervalos inteiros múltiplos de potências de dois, pois tal escolha torna a análise mais eficiente e tão precisa quanto a transformada contínua.

Ela utiliza, além da wavelet mãe, uma função de escala (do inglês scaling function) f, a qual está associada.

Assim, a DWT decompõe a função original f(x) em versões escalonadas e transladadas de e f.

A seguir, mostraremos, através de um exemplo, como a transformada discreta pode ser calculada de forma direta.

Acreditamos que este exemplo ajudará a fixar os conceitos.

Em seguida, introduzimos o algoritmo desenvolvido em 1989 por Stephane G.

Mallat, conhecido como transformada rápida de wavelets (do inglês Fast Wavelet Transform), que é utilizado para calcular a DWT.

Aproximando Funções com Wavelets Escolhemos para trabalhar, a mais simples e antiga de todas as wavelets, a wavelet de Haar (x).

Ela é uma função degrau.

Para fazer a decomposição, iremos utilizar versões escalonadas e trasladadas de x.

Onde d é uma constante, o termo k é responsável pela translação da wavelet, e o termo j, por sua escala.

Afirma que Yves Meyer mostrou em que existe uma wavelet (x) tal que define uma base ortogonal em L2(R).

Isto significa que qualquer elemento em L2(R) pode ser representado como uma combinação linear (possivelmente infinita) destas funções base.

A ortogonalidade é simples de se verificar.

Por inspeção, podemos ver que sempre que j = j0 e k = k0 não forem satisfeitos simultaneamente.

Se j 6= j0, então os valores não nulos de uma wavelet estarão contidos na região constante da outra, o que tornará a integral igual a zero.

Se j = j0 e, portanto, k 6= k0, então o produto será nulo.

Assim, verificamos que as funções são ortogonais.

O valor da constante d que torna a base ortonormal é d = 2j/2.

Considere nossa amostra, de tamanho 2n, de um sinal qualquer.

Este vetor pode ser associado à uma função f, gerada a partir de escalonamentos e translações de f(x).

Vamos fixar nossa amostra S e calcular a decomposição explicitamente.

Os coeficientes de podem ser calculados diretamente, através da equação matricial a seguir.

Observe que a matriz operadora é formada pela multiplicação da constante d = 2j/2 pela wavelet correspondente, nos níveis de escala j = 3,2 e 1.

É importante ressaltar também, que cada equação descrita neste sistema é responsável pela representação de uma parte do sinal.

Assim, a primeira equação descreve a função no intervalo x 0, 1, a segunda no intervalo x 1, 2 e assim sucessivamente, e é por isso que aparecem os elementos 0 matriz operadora.

Estes são conseqüência do valor da wavelet utilizada no intervalo considerado.

Por exemplo, a primeira equação descreve o sinal em x 0, 1.

Neste intervalo, as wavelets 2,1(x), 1,1(x), 1,2(x), 1,3(x) têm valor zero.

Portanto, os elementos da primeira linha da matriz operadora que correspondem a cada uma destas wavelets serão iguais a 0.

O problema de se calcular os coeficientes por esta forma direta é que, a medida que S vai crescendo, o custo computacional para resolver o sistema de equações se torna muito alto.

Assim, foi desenvolvido em 1989, por Stephane Mallat um algoritmo que calcula a DWT em n operações, dado um vetor de tamanho n, ou seja, sua complexidade é O(n).

Tal algoritmo é conhecido como Transformada Rápida de Wavelets e é apresentado a seguir.

A Transformada Rápida de Wavelets foi desenvolvida por Stephane G.

Mallat e tem como base a análise multiresolucional.

Dada uma função f(x), uma decomposição multiresolucional produz sucessivas aproximações de f(x) em diferentes escalas (ou resoluções).

Seja (rj)j2Z uma seqüência crescente de resoluções.

Os detalhes de uma função, aproximada na resolução rj, são definidos como a diferença entre sua aproximação em rj e sua aproximação em rj1, onde rj1 é uma resolução menor que rj.

É possível mostrar que estes detalhes podem ser representados por uma combinação linear de wavelets, de modo que, se formos sucessivamente produzindo aproximações de f(x) em rj e calculando sua diferença para a aproximação na resolução rj1, podemos obter uma decomposição da função original em wavelets.

A seguir, introduzimos os principais conceitos da análise multiresolucional e mostramos como, a partir desta, se obtêm a decomposição em wavelets de uma função de uma dimensão.

Utilizamos a mesma notação de, e procuramos seguir os mesmos passos que ele apresenta, com o objetivo de facilitar ao leitor que deseja se aprofundar no assunto.

É de conhecimento geral que, quanto maior a resolução8 de uma foto, melhor é a qualidade de sua imagem.

Isto ocorre pois o aumento da resolução implica no aumento da quantidade de amostras que são colhidas por unidade de área da imagem, o que permite que mais e mais detalhes possam ser representados.

Na primeira foto (a mais a esquerda), dispomos de 1 amostra para compor toda a área da imagem.

Como se pode observar, com uma amostra apenas, não é possível fazermos qualquer distinção entre os elementos que compõe a imagem e, portanto, não conseguimos representá-la.

A medida que vamos aumentando o número de amostras colhidas, conseguimos diferenciar mais e mais detalhes da imagem, até que, finalmente, temos uma representação nítida da letra R.

O termo "resolução" pode ser entendido como o número de amostras por unidade de área que são utilizados na representação de uma imagem.

Normalmente, a resolução também é descrita pelo número de amostras por linha vezes o número de amostras por coluna de uma imagem, 1024x768, por exemplo.

Representação de uma imagem sob diferentes resoluções.

Idealmente, gostaríamos de representar a imagem de forma contínua (ou com um número infinito de amostras), no entanto, isso não é possível, e assim, temos de discretizá-la.

O objetivo da análise multiresolucional é justamente estudar as informações de uma função sob diferentes resoluções.

Ela procura separar o que é essencial do que é acessório.

A grande vantagem deste tipo de análise é que ela nos permite ter a mesma interpretação da função independentemente de sua escala.

Suponha, por exemplo, que estamos estudando a imagem de uma casa.

Ao trabalhamos com uma resolução baixa, apenas suas características principais (seus objetos maiores, como a casa em si) são distinguíveis.

A medida que a resolução cresce, mais e mais detalhes vão aparecendo (como as janelas, ou a maçaneta da porta de entrada).

No entanto, sendo a resolução alta ou baixa, sabemos que estamos olhando para uma casa.

Aproximação Multiresolucional Seja rj = 2j uma resolução, e A2j um operador que aproxima uma função f(x) na resolução 2j.

Assumimos que f(x) L2(R).

A2j pode ser caracterizado pelas seguintes propriedades.

A2j é linear.

Se A2jf(x) for a aproximação de f(x) na resolução 2j, então A2jf(x) não é modificado se o aproximarmos na mesma resolução 2j novamente.

Podemos entender A2j como um operador de projeção no espaço vetorial V2 L2(R), que por sua vez, pode ser interpretado como o conjunto de todas as aproximações possíveis, na resolução 2j, de funções em L2(R).

Dentre todas as aproximações de f(x) na resolução 2j, A2jf(x) é aquela que mais se assemelha.

Portanto, o operador A2j é uma projeção ortogonal no espaço vetorial V2j.

A aproximação de uma função na resolução 2j+1 contém todas as informações necessárias para se aproximar a mesma função na resolução 2j.

Este princípio conhecido como princípio da casualidade é equivalente.

A operação de aproximação é similar para todas as resoluções.

Isto significa que os espaços de funções de aproximação devem ser derivados uns dos outros, escalonando-se cada função de aproximação pela taxa de seu valor de resolução.

A aproximação A2jf(x) de f(x) pode ser caracterizada por 2j amostras por unidade de comprimento, e se f(x) for transladada de uma quantidade proporcional a 2j, então A2jf(x) também será transladada da mesma quantidade.

Ao computarmos uma aproximação de f(x) na resolução 2j, uma quantidade de informação sobre f(x) é perdida.

Entretanto, a medida que, o sinal aproximado converge para o sinal original.

Inversamente, quando, e a resolução decresce a zero, aproximação contém menos e menos informações e converge para zero.

Denominamos qualquer conjunto de espaços vetoriaisj2Z, definidos acima, uma aproximação multiresolucional de L2(R).

Vimos que operador A2j é uma projeção ortogonal no espaço vetorial V2j.

Portanto, para caracterizá-lo numericamente, precisamos encontrar uma base ortonormal de V2j.

O teorema a seguir, tirado de, mostra que uma base deste tipo existe, e pode ser definida pela dilatação e translação de uma única função f(x).

Seja uma aproximação multiresolucional de L2(R).

Existe uma única função, chamada de função de escala, tal que, se definirmos para Z (dilatação de f(x) por 2j), então forma uma base ortonormal de V2j.

Podemos agora encontrar a projeção ortogonal de f(x) em V2j.

Esta será dada pela combinação linear das bases definidas no Teorema 1.

Observe que A2jf(x) é formada pela soma ponderada de funções f2j, cujos respectivos coeficientes são dados pelos produtos internos.

Ilustra um exemplo de uma função de escala f(x) e sua transformada de Fourier.

Olhando, fica evidente que a função f(x) é um filtro passa-baixo (do inglês low-pass filter), uma vez que é composta apenas por baixas freqüências.

Portanto, a aplicação de A2j, na função f(x), nada mais é que a aplicação de um filtro passa-baixo, que retira suas componentes de alta freqüência, seguido por uma amostragem uniforme à taxa 2j.

Exemplo de uma função de escala f(x) e sua transformada de fourier f.

Observe que f(x) é um filtro passa-baixo.

Nesta subseção, vimos como calcular a aproximação de f(x) na resolução 2j.

A seguir, mostraremos como esta aproximação pode ser calculada a partir da aproxima ção em 2j+1, e assim, construiremos um algoritmo piramidal para o cálculo das aproximações.

Transformada Multiresolucional.

Na prática, não há como medirmos um sinal (uma função) de forma contínua, podemos apenas amostrá-lo de tempos em tempos.

Portanto, os sinais dos fenômenos com os quais trabalhamos já se encontram aproximados em uma determinada resolução.

Assumiremos, no restante desta seção, que nosso sinal original encontrase aproximado na resolução 1.

Intuitivamente, isto significa que nosso intervalo de amostragem corresponde à unidade de tempo.

Assim, podemos dizer que nosso sinal original amostrado é uma aproximação de f(x) na resolução 1, e é dado por Ad1 f.

Pelo princípio da casualidade, podemos calcular todas as aproximações para j < 0, a partir de f.

Sejaj2Z uma aproximação multiresolucional cuja função de escala correspondente é f(x).

Pelo Teorema 1, a família de funções forma uma base ortonormal paraj2Z.

Sabemos que, para todo n, a função f2j (x2jn) pertence a V2j, que por sua vez, está incluído em V2j+1.

Logo, podemos expandí-la nas bases V2j+1.

Fazendo tal expansão, e mais algum algebrismo (que pode ser isto em), podemos mostrar que podemos obter Ad2jf de Ad2j+1f, passando o último pelo filtro H e mantendo uma de cada duas saídas.

É importante ressaltarmos que cada aproximação Ad2jf, para j < 0, terá 2jN amostras, onde N é a quantidade de amostras do sinal original.

Isto ocorre pois, quando passamos da resolução 2j+1 para a resolução 2j, as funções f2j dobram de tamanho, e, portanto, passamos a utilizar apenas uma função para representar um trecho do sinal que antes era aproximado por duas.

Assim, mostramos como todas as aproximações Ad 2jf, para j < 0, podem ser obtidas de Ad1f.

Ilustra um exemplo de aproximações de um sinal qualquer produzidas em três resoluções diferentes.

Exemplo de um sinal aproximado em três resoluções distintas.

A Representação por Wavelets Conforme dissemos no início desta seção, a decomposição em wavelets será constru ída a partir da informação que se perde a cada aproximação do sinal nos níveis de resolução 2j para Z.

A informação perdida na resolução 2j é definida como a diferença entre as aproximações nas resoluções 2j+1 e 2j, e é denominada de sinal de detalhe (do inglês detail signal).

Assim como uma aproximação na resolução 2j, nada mais é do que uma projeção em V2j, é possível mostrar que, o sinal de detalhe, na resolução 2j, também é uma projeção ortogonal do sinal original, só que, o complemento ortogonal de V2j em V2j+1, isto é O2j, é ortogonal a V2j O2 V2j = V2j+1.

Do mesmo modo que fizemos para V2j, precisamos encontrar uma base ortonormal para O2j, a fim de computar a projeção ortogonal de f(x) neste espaço.

O teorema a seguir é muito semelhante ao Teorema 1, e mostra que uma base deste tipo existe, e pode ser formada por escalonamentos e translações de uma função x.

Sejaj2Z um espaço vetorial multiresolucional, f(x) sua função de escala, e H seu filtro correspondente.

Seja (x) uma função cuja transformada de Fourier é dada uma base ortonormal de O2j e é uma base ortonormal de L2(R), e (x) é denominada uma wavelet ortogonal.

O Teorema 2 mostra, também, como podemos construir uma wavelet, partimos de um filtro H (cuja transformada de Fourier deve satisfazer a determinadas condições descritas em), encontramos sua função de escala f(x) correspondente e, usando a equação, determinamos a wavelet (x).

Seja P2j o operador de projeção ortogonal em O2j.

A decomposição de f(x) em wavelets na resolução 2j, que nos fornece o sinal de detalhe na mesma.

Como o sinal de detalhe discreto de f(x) na resolução 2j.

Podemos observar que a wavelet é um filtro passa-faixa.

Assim, o sinal de detalhe D2jf descreve f(x) nas bandas de freqüência.

Mais detalhes sobre como, dada uma wavelet, conseguimos representar todas as freqüências de uma função.

Podemos agora montar uma descrição completa de Ad1f, nossa amostra original do sinal f(x).

Este conjunto de sinais discretos é denominado uma representação ortogonal por wavelets.

Note que esta representação consiste em um sinal de referência, dado pela aproximação A2J f na resolução 2J mais os detalhes nas resoluções 2j para J = j = 1.

Transformada de Wavelets Da mesma forma que fizemos para Ad2jf, podemos demonstrar que D2jf pode ser calculado a partir de Ad2j+1f.

Como 2j (x2jn) pertence à O2 V2j+1, podemos expandí-la nas bases de V2j+1.

Fazendo tal expansão e mais alguns algebrismos, chegamos a G o filtro simétrico a G, com resposta g(n) = g(n).

Inserindo em temos que nos mostra que podemos obter o sinal de detalhe D2jf passando Ad 2j+1f pelo filtro G e mantendo uma de cada duas saídas.

Assim, a representação em wavelets de um sinal discreto pode ser computada através da decomposição sucessiva de Ad2j+1f em Ad2jf e Dd2jf, para J = j = 1.

Esquema da transformada discreta de wavelets.

A equação do Teorema 2 nos mostra que os filtros G e H estão relacionados.

Mais especificamente G é o filtro espelho de H, e do tipo passa-alto (do inglês high-pass filter).

Na área de processamento de sinais, G e H são conhecidos como quadrature mirror filters.

A equação pode ser interpretada como uma filtragem passa-alto do sinal Ad2j+1f.

Se o sinal original é composto por N amostras, então cada um dos sinais discretos Ad2jf e D2jf têm 2jN amostras10.

Portanto, a representação por wavelets contém a mesma quantidade de amostras, N, de Ad1 f, nossa amostragem original de f(x).

Observe que, nos pontos onde A2j+1f e A2jf são significativamente diferentes, os detalhes apresentam uma grande amplitude.

Exemplo de detalhes de um sinal aproximado em três resoluções distintas.

A fim de clarear os conceitos e o algoritmo descrito anteriormente, ilustramos, a seguir, o processo da transformada discreta de wavelets através de um exemplo.

Escolhemos trabalhar com o mesmo sinal utilizado no início desta seção, e, novamente, com a wavelet de Haar.

Suponha que S seja nossa amostra, discreta, do sinal f(x) a ser estudado.

Sabemos que a aproximação de S na resolução 2j é composta de 2jN amostras.

Portanto, a resolução mínima com a qual podemos trabalhar é 23 = 1/8, na qual nossa aproximação será composta de, apenas, uma amostra (uma função f).

O algoritmo para calcular a DWT consiste em, iterativamente, ir passando a aproximação A2j+1 pelos filtros H e G, até que tenhamos uma aproximação na resolução mínima 2J, que, no caso, ocorre para J = 3.

Transformada discreta de S utilizando a wavelet de Haar.

Obtemos, desta forma, como resultado da transformada, os coeficientes idênticos aos obtidos em quando os calculamos diretamente.

Assim como construímos uma representação em wavelets de um sinal discreto S, podemos, através de um algoritmo piramidal, reconstruir o sinal original S dada sua decomposição em wavelets.

Vimos que O2j é o complemento ortogonal de V2j em V2j+1, portanto,n2Z é uma base ortonormal de V2j+1.

Se decompusermos f2j+1(x2j1n) nesta base, utilizarmos os filtros H e G, e fizermos algum algebrismo.

A equação nos mostra que Ad2j+1f pode ser reconstruída se colocarmos zeros entre cada amostra de Ad2jf e D2jf, passarmos os sinais resultantes pelos filtros H e G respectivamente, e somarmos os resultados.

Esquema da transformada discreta inversa de wavelets.

Ilustra o processo de reconstrução de nosso sinal S, utilizado nos exemplos anteriores, a partir de sua decomposição calculada com a transformada discreta de wavelets, na qual trabalhamos com a wavelet de Haar.

Transformada discreta inversa de S utilizando a wavelet de Haar.

Na seção anterior, vimos que a DWT decompõe uma função através de sucessivas suavizações, pela aplicação do filtro H, e que, a cada suavização, os detalhes são retirados pelo filtro G.

Ao final, a função é representada pela soma de diversas wavelets, cujos coeficientes estão diretamente associados à intensidade dos detalhes.

Se estes detalhes forem pequenos, podemos omití-los, sem que isso altere significativamente as características principais do sinal.

Para tal, elaboramos uma política conhecida como thresholding que muda para zero cada coeficiente de wavelet cujo valor seja menor que um determinado threshod.

Assim, esperamos "limpar" a função original, retirando detalhes não importantes, que são considerados ruído.

A DWT de S nos dá, como resultado, o vetor de coeficientes.

Se decidirmos que todos os coeficientes menores que 0,9 representam ruído.

Função f(x) após a remoção de ruídos.

O processo de thresholding pode ser dividido em duas partes.

Na primeira, é escolhida a função de threshod T.

O próximo passo é a escolha do treshold.

Existem diversos métodos para se fazer essa escolha, dentre os quais podemos citar o Universal Treshold e SURE.

O primeiro usa um threshold fixo U = v2 log ns e sua idéia central é remover todos os coeficientes menores que o máximo valor esperado de uma amostra de uma variável aleatória de tamanho n.

O segundo estima o risco de um determinado threshold, minimiza esse risco, e então encontra o valor.

Políticas de thresholding, hard thresholding e soft thresholding.

Existem, basicamente, dois tipos de modelos que são utilizados na previsão de variáveis econômicas.

Os primeiros, chamados de modelos de regressão, relacionam a variável a ser estudada a um conjunto de outras variáveis, as quais, acredita-se, influenciam o comportamento da primeira.

Por exemplo, podemos tentar prever uma taxa de juros de curto prazo usando um modelo de regressão que relaciona-a ao PIB, aos preços, e à oferta monetária, caso acreditemos que o comportamento destas três variáveis explique, de forma satisfatória, o comportamento da taxa de juros.

Existem diversos problemas neste tipo de abordagem, dentre os quais podemos citar a possível falta de dados sobre todas as variáveis explanatórias.

Isto ocorre principalmente com variáveis que são influenciadas por um enorme conjunto de fatores sobre os quais pouco se conhece, como o clima meteorológico, mudanças de gosto, ou movimentos de manada desencadeados por fatores psicológicos.

Ainda há casos em que, para obtermos uma previsão a partir de uma equação de regressão, é necessário fazer uma previsão das próprias variáveis explanatórias, o que pode ser mais difícil do que prever a variável principal.

As dificuldades encontradas nos modelos de regressão levaram ao desenvolvimento de um segundo tipo de modelo, o chamado modelo de séries temporais.

Este tenta inferir o comportamento de uma variável observando apenas seu passado.

Ele assume que existem padrões de comportamento que se repetem ao longo do tempo, e que estes, uma vez identificados, podem ser utilizados para se construir uma previsão.

O capítulo a seguir descreve, de forma sucinta, alguns dos modelos de previsão de séries financeiras mais comuns encontrados na bibliografia.

Dedicamos uma seção a cada modelo, na qual fazemos uma breve descrição sobre suas principais caracter ísticas e, em seguida, citamos alguns trabalhos que o utilizam na previsão do preço do petróleo, e seus resultados.

O principal fundamento responsável pela flutuação do preço de um ativo ou de uma commodity é o balanço entre sua demanda e sua oferta.

No caso do petróleo, este balanço é ditado basicamente por duas atividades, exploração/produção e refino/comercialização.

A primeira é responsável por garantir a oferta, e tem como seu principal personagem a organização dos países exportadores de petróleo, conhecida como OPEP.

A segunda é responsável pela demanda.

As refinarias compram óleo cru e o refinam, produzindo os derivados de petróleo que são então comercializados às indústrias e à população.

Apesar de aparentemente simples, esse balanço é bastante complexo, pois depende de uma série de fatores voláteis e, muitas vezes, imprevis íveis.

Guerras e tensões políticas podem rapidamente fazer desaparecer parte da oferta, como ocorreu durante o primeiro choque do petróleo em 1973, ocasião na qual a OPEP decidiu suspender suas exportações para os países que apoiavam Israel na guerra de Yom Kippur.

O crescimento econômico (ou recessão) de países provoca alterações na demanda, invernos mais quentes ou mais frios mudam a demanda por determinados derivados, furacões podem destruir plataformas produtoras cortando temporariamente a oferta,inflação, desvalorização do dólar, etc.

A quantidade (e imprevisibilidade) de fatores que influenciam o preço do petróleo torna sua previsão por regressão de fundamentos uma tarefa difícil.

Entretanto, há uma variável que, teoricamente, resume de forma satisfatória o balanço entre a demanda e a oferta, o nível dos estoques de petróleo.

Devido aos riscos existentes do lado da oferta, e da volatilidade de preço, uma grande parte da indústria consumidora de petróleo mantêm estoques do mesmo.

Os estoques, além de oferecerem proteção contra eventuais aumentos de preço, também permitem maior flexibilidade e velocidade de resposta em caso de aumento repentino da demanda.

Assim, em teoria, o nível destes estoques funciona como um medidor do equilíbrio entre a demanda e a oferta.

Um estudo mais profundo da relação entre estoques e preços pode ser visto em.

Partindo do pressuposto acima, constrói um modelo de previsão mensal do preço do petróleo fazendo uma regressão deste sobre o nível relativo de estoques dos países da Organização para Cooperação e Desenvolvimento Econômico, a OECD.

O nível relativo de estoques é definido como a diferença entre o nível real e um nível normal, determinado historicamente por uma regressão.

A equação de regressão proposta onde são os parâmetros a serem estimados, é o preço do WTI no tempo t, RIN é o estoque relativo.

São variáveis não-lineares referentes aos níveis baixo e alto dos estoques, variáveis dummy que capturam os efeitos de 11 de setembro de 2001 e abril de 1999, respectivamente, e et um erro.

Este modelo é uma evolução de outros mais simples.

O modelo acima apresenta resultados preditivos satisfatórios.

Entretanto, ele tem o inconveniente de necessitar do nível dos estoques no tempo t, para fazer a previsão do preço no tempo t, de modo que a regressão é dependente da previsão de uma de suas variáveis explanatórias.

Recentemente, argumentou que, a partir do ano de 2004, esta relação entre preço e níveis de estoque parece ter se enfraquecido, o que é observado pelo surgimento de um prêmio nos preços reais sobre os preços previstos pelo modelo.

O autor, então, testa novas variáveis na tentativa de explicar este descolamento do preço.

Seus resultados indicam que o aumento da especulação parece ser a principal causa do surgimento deste prêmio.

A seguir, descrevemos, de forma breve, alguns dos modelos de séries temporais lineares mais conhecidos.

Eles se aplicam tanto aos processos estacionários 2 quanto aos não-estacionários homogêneos.

O modelo de série temporal mais simples é o passeio aleatório.

Na sua forma mais comum, cada mudança sucessiva em yt é extraída, independentemente, de uma distribuição de probabilidade com média 0 e variança onde et tem média 0 e variança s2.

Este modelo é normalmente usado como refer ência de comparação no teste de outros modelos.

Um processo é dito estacionário quando as características do processo estocástico subjacente não mudam com o tempo.

Um processo é dito não-estacionário homogêneo quando pode ser diferenciado uma ou mais vezes para produzir um processo estacionário.

Se a hipótese de eficiência de mercado é correta, então espera-se que o preço de uma mercadoria siga um passeio aleatório, de modo que nenhum investidor pode obter lucros excepcionais seguindo alguma regra para tomar suas decisões de compra e venda.

De fato, tal hipótese é, normalmente, assumida para os mercados financeiros à vista, como o mercado de ações.

Entretanto, afirma que o mercado spot do petróleo não segue um passeio aleatório, porém faz a ressalva de que isto não signi fica que um investidor possa obter retornos excepcionais na comercialização desta mercadoria.

Utiliza um modelo RW como referência no teste de seu modelo de Redes Neurais para a previsão do preço futuro do petróleo.

Seus resultados indicam que o mercado de petróleo não é eficiente, e que há como explorar esta ineficiência usando modelos matemáticos não-lineares, como as redes neurais.

No processo de médias móveis de ordem q, cada observação de y(t) é gerada por uma média ponderada de q perturbações aleatórias et.

Denotamos este processo como MA(q) e o definimos onde {et} é uma seqüência de variáveis aleatórias, não correlacionadas, com média 0 e variança s2, e {t} seus respectivos coeficientes.

Seqüências deste tipo são conhecidas como ruído branco e, para representá-las, usamos a notação.

No processo auto-regressivo de ordem p, a observação corrente yt é gerada por uma média ponderada de p observações anteriores mais uma perturbação aleatória.

Denotamos este processo como AR(p) e o definimos como onde {et} WNe d está relacionado com a média do processo.

Muitos dos processos aleatórios estacionários não podem ser modelados apenas como médias móveis ou apenas como auto-regressivos, pois possuem qualidades de ambos os tipos de processo.

Assim, surge uma extensão lógica que combina-os, formando o modelo auto-regressivo e de médias móveis de ordem (p, q), onde p é a ordem da auto-regressividade e q a ordem da média móvel.

Denotamos este processo como ARMA(p, q) e o definimos.

Os modelos ARMA assumem que a série temporal modelada é estacionária.

Entretanto, na prática, muitas das séries com as quais trabalhamos não são estacionárias, mas podem ser transformadas em séries estacionárias quando as diferenciamos uma ou mais vezes.

Dizemos que yt é homogênea estacionária de ordem d se wt = dyt é uma série estacionária.

É o operador de diferenciação, definido como e assim por diante.

Dada a série wt, podemos voltar a yt pela soma de wt num total de d vezes, da forma yt =Pd wt.

Uma vez que a série yt tiver sido diferenciada, produzindo wt, podemos modelar wt como um processo ARMA.

Se wt = dyt e wt é um processo ARMA(p, q), então dizemos que yt é um processo auto-regressivo integrado e de médias móveis de ordem p, d, q ou simplesmente ARIMA(p, d, q).

Em é utilizado um modelo ARIMApara prever o preço do petróleo ao final de um horizonte de tempo de um mês.

Seus resultados desencorajam a utiliza ção do ARIMA pois, por ser um modelo linear, não consegue capturar a dinâmica não-linear do processo, que é bastante presente.

Os resultados são avaliados em termos do erro médio quadrático e de um índice de acerto de direção, chamado de Dstat.

Este último indica a taxa de acerto da previsão da direção do preço.

Num período de teste que vai de Janeiro de 2000 a Dezembro de 2003, o ARIMA obtém uma Dstat de 54%, inferior a taxa de acerto de outros modelos não-lineares testado no mesmo artigo.

Um resultado semelhante é verificado para o erro médio quadrático.

Ao construirmos um modelo de regressão, em alguns casos, há motivos para se acreditar que a variância do erro muda ao longo do tempo, e é dependente dos erros passados.

Em tais processos, fica evidente que ocorre uma aglomeração, no tempo, de erros grandes e pequenos.

Por exemplo, ao modelarmos um ativo financeiro, como o preço de uma ação ou de uma commodity como o petróleo, fica muito claro que há períodos que apresentam alta volatilidade, e outros nos quais a volatilidade é baixa.

Nestes casos, dizemos que há um tipo de heterocedasticidade presente, em que a variância do erro da regressão depende da volatilidade dos erros no passado recente.

O modelo generalized autoregressive conditional heterocedasticity, conhecido como GARCH, foi introduzido para melhorar a regressão de variáveis que possuem caracter ística heterocedástica.

Ele relaciona a variância do erro ao tamanho da volatilidade observada em períodos recentes e sua variância.

Um modelo GARCH(p, q) é definido onde t é a variância do erro no tempo t, e et o erro no tempo t.

A estimação dos parâmetros do GARCH é feita juntamente com a estimação dos parâmetros da regressão.

A utilização de modelos GARCH é muito comum na modelagem de ativos financeiros que usam dados diários ou semanais, os quais quase sempre apresentam o tipo de heterocedasticidade descrito acima.

Em é utilizado um modelo GARCH para construir intervalos de confiança sobre a previsão feita pelo contratos futuros de um mês do preço do óleo tipo Brent.

O trabalho afirma que os contratos futuros não conseguem prever corretamente nem a direção do preço, acertando, em média, apenas 50% das vezes.

Entretanto, seu desempenho como preditor pode ser melhorada construindo-se intervalos de confiança da previsão, o que é feito utilizando o GARCH.

Um aumento do intervalo de confiança indica que a capacidade de previsão dos contratos futuros deve cair.

Uma rede neural artificial é um modelo matemático não-linear, baseado nas redes neurais biológicas.

Ela é representada por um grupo de nós (ou neurônios), interconectados, pelos quais flui informação, de maneira semelhante aos neurônios no cérebro humano.

As ANN foram introduzidas em 1943 e são, hoje em dia, bastante utilizadas na área de reconhecimento de padrões.

Uma ANN é composta de camadas, cada qual contendo um certo número de nós.

As principais camadas são as de entrada, por onde entra informação na rede, e saída, por onde saem as respostas da rede.

A camada de entrada pode afetar diretamente a camada de saída, entretanto, o mais comum é que haja uma ou mais camadas intermediárias, conhecidas como camadas ocultas.

Seja X = xi o vetor das variáveis de entrada de uma ANN.

Suponha que a ANN tenha uma camada oculta de nós hj e apenas uma variável de saída y.

O j-ésimo nó da camada oculta é definido onde xi corresponde a i-ésima variável de entrada.

A constante a0,j e os pesos wij precisam ser estimados.

A função fi é normalmente conhecida como função de ativação, e determina se a saída do nó atual deve ser propagada ao nó seguinte ou não.

A camada de saída pode, então, ser definida onde I = número de variáveis de entrada e J = número de nós na camada oculta.

Note que, nesta rede, os valores de entrada afetam diretamente os valores de saída.

Seus parâmetros, normalmente, são estimados utilizando um algoritmo de treinamento iterativo.

A cada passo, o algoritmo vai ajustando seus valores de forma a reduzir alguma medida de erro (como o erro médio quadrático) das saídas dadas pela rede em relação as saídas reais.

Este processo é chamado de aprendizado da rede.

Uma busca rápida na bibliografia mostra que as ANN têm sido uma ferramenta bastante utilizada na previsão de séries financeiras devido a sua capacidade de reconhecimento de padrões.

Utiliza uma ANN para emitir sinais diários de compra e venda no mercado spot de petróleo.

Seus resultados indicam que é possível obter ganhos extraordinários utilizando a ANN.

Em uma ANN é utilizada em conjunto com outras duas ferramentas de inteligência artificial, uma ruled based expert system (RES) e uma web-based text minig (WTM), para a previsão mensal do preço do petróleo.

Enquanto a ANN é utilizada para fazer a previsão dos preços, as outras duas ferramentas são utilizadas na busca (na Internet) de fatos significativos que por ventura possam ter ocorrido no passado recente.

Com o resultado da busca, a previsão é então ajustada.

Ela inclui, entre outros, guerras, embargos e crises econômicas.

Os resultados encorajam a utilização de um sistema de previsão como este.

Em, um tipo especial de algoritmo de rede neural chamado de support vector machine (SVM) é utilizado também na previsão do preço do petróleo.

Ele compara seus resultados aos de uma ANN normal e ao modelo ARIMA, e conclui a favor do SVM, ressaltando, no entanto, que a ANN também tem significativa capacidade preditiva.

A teoria por trás dos modelos de Markov ocultos está descrita no capítulo 2.

Em os autores utilizam uma cadeia de Markov oculta com observações contínuas para a previsão de séries financeiras como, o índice S&P 500 e da taxas de câmbio.

Em cada estado oculto, eles utilizam um modelo de emissão de símbolos, como um AR ou uma rede neural.

Assim, ao invés da matriz de emissão B, há um novo conjunto de parâmetros B que é composto pelos parâmetros do modelo de emissão utilizado.

O modelo fornece como saída uma distribuição da variação percentual do ativo, e usa sua média como valor previsto.

O fato de se ter a distribuição também permite que seja feito uma análise de risco das previsões.

Seus resultados são comparados aos de uma rede neural feed-forward, à um modelo auto-regressivo e a uma estratégia de buy-and-hold, e indicam que a HMM tem um desempenho superior aos três no período testado.

O trabalho de se baseia em e faz uma modificação no algoritmo de EM para que as observações mais recentes tenham maior peso no treinamento da HMM.

Seus resultados indicam que a HMM consegue gerar retornos acima do mercado, e tem desempenho superior a rede neural.

Este capítulo apresenta, em detalhes, a metodologia utilizada para prever a distribui ção do retorno1 acumulado pelo preço do petróleo, ao final de uma janela de tempo futura de F dias.

Ela é composta de cinco etapas, e utiliza as wavelets como ferramenta de suavização, e um modelo de Markov oculto como ferramenta de previsão.

O processo tem início com a coleta dos dados.

Como estamos trabalhando com um modelo de séries temporais, a única variável de interesse é o preço do petróleo, logo, esta primeira etapa se resume a obter sua série de preços.

Em seguida, suavizamo-la, utilizando o método de remoção de ruído por wavelets.

Na terceira etapa, obtemos a série de retornos a partir da série suavizada de preços e codificamoos, associando a cada retorno um símbolo do conjunto de símbolos do HMM.

Caso haja necessidade, os parâmetros do modelo são reestimados.

Por último, é feita a previsão.

A seguir, descrevemos individualmente cada uma destas etapas.

Existem, aproximadamente, 161 tipos de petróleo negociados no mundo.

O preço de cada um depende, principalmente, de suas características, como a quantidade de enxofre presente e sua gravidade API.

Escolhemos trabalhar com o West Texas Intermidiate (WTI), pois ele é a principal referência de óleo cru da América, e uma das principais do mundo.

Utilizamos nesta dissertação os preços spot diários2, nominais, referentes à um barril do WTI.

Seu histórico pode ser adquirido na página da Energy Information Administration (EIA), que é o centro oficial de estatísticas energéticas do governo dos Estados Unidos.

Além da série histórica dos preços, a página da EIA contém diversas outras informações importantes relacionadas a área energética, incluindo previsões, estudos, análises e notícias.

Recomendamo-la ao leitor interessado como uma excelente fonte de dados.

As séries de preços de ativos financeiros e commodities tendem a ser bastante voláteis, e a série do WTI não é nenhuma exceção.

No ano 2006, por exemplo, seu preço no dia 27 de abril era de 70,76 dólares, muito próximo ao preço de 17 de abril, que era de 70,30 dólares.

Entretanto, durante este pequeno intervalo de tempo, de apenas dez dias, o preço oscilou entre uma mínima de 67,43 e uma máxima de 73,73 dólares.

Mostra a autocorrelação da série de retornos diários do WTI nos 200 primeiros time lags, calculada com a ferramenta de modelagem Tangram2.

As linhas horizontais, obtidas pelo resultado de Barlett3, indicam o limite acima do qual o valor de um coeficiente é estatisticamente significativo (diferente de 0) com nível de significância de 95%.

Apesar de os valores encontrados serem um indício de que retornos passados podem conter alguma informação a respeito dos retornos futuros, eles são muito baixos, de modo que estas informações são, aparentemente, pouco relevantes.

Autocorrelação dos retornos diários do WTI.

Conforme mencionado no capítulo 1, não estamos interessados em prever esta volatilidade diária, de curtíssimo prazo, mas em identificar e prever as tendências dos preços em intervalos maiores, de, por exemplo, 20 dias.

Assim, procuramos suavizar a série, a fim de eliminar esta volatilidade (considerada como ruído) e ressaltar a informação que consideramos relevante.

Se uma série temporal é gerada por um ruído branco, os coeficientes da função de correlação amostral (para k > 0, onde k é o lag da correlação) seguem, aproximadamente, uma distribuição normal com média 0 e desvio padrão, onde T é o número de observações da série.

Existem diversas técnicas para se suavizar séries temporais.

Talvez a mais comum e simples delas seja a média móvel.

A suavização por média móvel consiste em representar cada ponto da série original pela média aritmética dos n últimos pontos.

Há algumas variações desta técnica, como a média móvel exponencial (que dá mais peso aos valores mais recentes) e a média móvel exponencial dupla.

O principal problema da média móvel é seu deslocamento no tempo em relação a série original.

Se o número de dias utilizados no cálculo da média for pequeno, ela acompanha mais rapidamente as mudanças de tendência, no entanto, ao mesmo tempo, se torna mais sensível aos ruídos, e a suavização é de pior qualidade.

Se aumentarmos o número de dias, a eliminação de ruídos é maior, entretanto, a média móvel demora mais para refletir as mudanças de tendência.

Neste caso, ela também não consegue capturar satisfatoriamente movimentos abruptos, intensos, de curto intervalo de tempo que, porventura, podem ser importantes.

Nesta dissertação, decidimos fazer a suavização da série de preços do WTI utilizando as wavelets.

Como já foi visto no capítulo 2, a característica local destas garante que a série suavizada não fique deslocada em relação a série original, como acontece com as médias móveis.

Além disto, a remoção de ruídos pelas wavelets consegue capturar movimentos significativos de curta duração melhor que as médias móveis.

O primeiro passo na suavização é obter a série de logaritmos dos preços.

Isto é necessário pelo seguinte, sabemos do capítulo 2, que a remoção de ruídos utilizando as wavelets é feita através da eliminação dos coeficientes de wavelet menores que um determinado threshold, e que eles representam a diferença entre duas aproximações consecutivas do sinal durante a transformada discreta.

Agora observe que estes coeficientes tendem a ser maiores quanto mais alto for o preço, uma vez que um desvio de 1 dólar sobre um preço de 100 dólares é o mesmo que um desvio de 0,1 dólares sobre um preço de 10 dólares.

Assim, se suavizarmos a série original de preços, ocorrerá que os coeficientes que representam níveis baixos de preços serão eliminados em maior quantidade do que os que representam níveis mais altos, de modo que teremos como resultado uma série cuja suavização é maior nas épocas onde o petróleo custava menos (em termos nominais), e menor nas épocas onde custava mais.

Entretanto, se suavizarmos a série logarítmica dos preços, conseguimos eliminar este problema.

Mostra os coeficientes de wavelet D21 e D22, obtidos na decomposição das séries de preços original e logarítmica do WTI, utilizando a wavelet de Daubechies de ordem 3.

Note que os coeficientes a direita dos gráficos que representam os preços mais altos da série, são maiores que os da esquerda, que representam preços menores.

Observe como isto não acontece com os coeficientes da série de log dos preços.

A suavização da série do log dos preços é feita por intermédio da função wden do programa Matlab.

Após a suavização, obtemos a série de preços original suavizada utilizando função inversa do log.

Compara ambas as técnicas de suavização discutidas nesta seção wavelets e média móvel, à série original de preços.

O gráfico de cima apresenta a série completa, de 1986 a 2008, e o segundo, de 2003 a 2008.

Observando-os, ficam claras as vantagens das wavelets sobre as médias móveis, discutidas anteriormente.

Conforme dissemos, o objetivo da suavização é remover a volatilidade de curt íssimo prazo presente na série de preços, a fim de ressaltar a dinâmica de seus movimentos mais duradouros.

Mostra a autocorrelação dos retornos da série suavizada por wavelets.

Observando-a, fica evidente o benefício da suavização.

Autocorrelação dos retornos diários da série de preços do WTI, suavizada por wavelets.

Utilizamos, nesta dissertação, um modelo de Markov oculto de tempo discreto para prever a distribuição do retorno acumulado pelo preço do petróleo em uma janela de tempo futura.

Como foi visto no capítulo 2, o HMM trabalha com um conjunto discreto e finito de símbolos, de tamanho M, os quais correspondem às saídas observáveis do processo que se deseja estudar.

Evidentemente, existe um trade-off entre o número de símbolos e a complexidade do modelo.

Quanto maior for M, maior é a capacidade de representação do modelo, no entanto, como mais parâmetros precisam ser estimados, maior é o número de máximos locais da função de verossimilhança.

Assim, em processos cujo conjunto de saídas observáveis é muito grande, pode ser interessante processá-las de alguma maneira, de modo a reduzir o conjunto de símbolos utilizado pelo HMM.

Estamos estudando o processo de formação do preço do petróleo, e suas saídas nada mais são que os preços de fechamento diários do mercado.

Uma escolha natural de símbolos seria representar cada preço por um símbolo idêntico ao seu valor.

Por exemplo, 41,83 dólares seria representado pelo símbolo 41,83.

No entanto,este conjunto, apesar de discreto4, apresenta alguns graves problemas que o tornam inviável de ser utilizado no HMM.

Em primeiro lugar, como não existe um limite superior para o preço, não há como tornar este conjunto finito.

Em segundo lugar,ele contém elementos demais, o que torna o HMM desnecessariamente complexo,e inviável de ser trabalhado sob a forma discreta.

Como solução para este último problema, poderíamos arredondar o preço, a fim de trabalharmos apenas com sua parte inteira, mas ainda assim, restaría-nos um conjunto extenso de símbolos 5.

Por estas razões, fica clara a necessidade de elaborarmos algum código que mapeie as saídas (os preços) à um conjunto reduzido de símbolos.

A série de preços, além de fornecer, evidentemente, o preço, contém outra importante informação, o retorno diário.

Definimos este retorno como onde rt é o retorno percentual no dia t, e pt o preço neste mesmo dia.

O valor do retorno diário dos principais ativos financeiros está, na maioria das vezes, contido em um intervalo bem definido, por exemplo.

Apesar de poder variar no intervalo 100%,+8%, é muito raro encontrarmos casos onde a variação do ativo é de 90% ou +84% em um único dia.

Isso é verdade especialmente no caso de uma commodity muito negociada, de bastante liquidez, como o WTI.

Durante o período que vai de 1986 até o final de 2008, sua maior variação percentual absoluta de preço, num único dia, foi de 33,40%, em 17 de janeiro de 1991.

Portanto, é razoável assumirmos que seus retornos diários estão contidos em um conjunto finito.

Aliado a isto, temos que retornos próximos (1,11% e 1,25%, por exemplo) são, para efeitos práticos, muito semelhantes, e assim podem ser considerados iguais.

Esta qualidade é de grande interesse, pois nos permite representar um conjunto de saídas com um mesmo símbolo.

Assim, dadas estas características do retorno, decidimos utilizá-lo como a saída observável de nosso processo, ao invés do preço.

Feita a escolha das saídas, o método de obtenção do conjunto de símbolos do modelo HMM é descrito a seguir.

O primeiro passo é selecionar um retorno L, que define o valor limite do retorno com o qual vamos trabalhar.

Em seguida, dividimos os retornos em faixas de valores de tamanho V,e associamos a cada uma um símbolo diferente, de modo que todos os retornos que pertençam a uma mesma faixa serão mapeado para um mesmo símbolo.

A primeira faixa contém retornos negativos maiores que L%, a última, os retornos positivos maiores que +L%.

As intermediárias dividem o intervalo em 2L/V subintervalos.

O último passo consiste em determinar o valor de cada símbolo.

Uma rápida observação do histograma de cada faixa, nos mostra que seus valores são, de forma aproximada, uniformemente distribuídos (exceto para as faixas limites).

Portanto, decidimos que cada símbolo terá o valor da média do intervalo ao qual está associado.

No caso das faixas limites e, o valor absoluto do símbolo passa a ser L + d onde d = V/2.

Definido o conjunto de símbolos, a codificação do conjunto de dados é trivial.

Basta encontrarmos a faixa a qual cada retorno pertence, e substituí-lo pelo símbolo associado àquela faixa.

É importante ressaltar que devemos calcular os retornos a partir da série suavizada de preços, e não a partir da série original.

A fim de clarear o processo descritos acima, ilustramo-no com o exemplo a seguir.

Definidos os símbolos, o próximo passo é codificar nosso conjunto de dados Or.

Seu primeiro elemento, 1,72%, pertence a penúltima faixa definida acima.

Como a ela está associado o símbolo 8, substituímos 1,72% por 8 no conjunto de dados.

Seguindo o mesmo raciocínio, substituímos 2,04%, o segundo elemento, por 9, 2,56% por 0 e assim em diante.

Uma rápida inspeção visual da série de preços do WTI, ou de qualquer ativo financeiro, mostra que estas não são séries estacionárias.

Suas estatísticas, como a média e variância, claramente variam ao longo do tempo.

Devido a este dinamismo dos preços, precisamos, de tempos em tempos, reestimar os parâmetros do nosso modelo, a fim de capturar as novas dinâmicas correntes.

Os parâmetros do modelo são periodicamente reestimados a cada t dias, utilizando o algoritmo EM descrito.

Em cada treino,apenas as amostras dos últimos T dias são utilizadas no procedimento de estimação.

Treinamento do Modelo Treinamento Individual Esquema de treinamento adaptativo do HMM.

Os valores de t e T têm impacto na qualidade da previsão.

Se T for muito pequeno, podemos estar omitindo do processo de treinamento informações relevantes da dinâmica corrente dos preços.

O contrário, T muito grande, levará o HMM a considerar dinâmicas que já não mais se encontram presentes.

Nesta etapa, temos como objetivo calcular a distribuição do retorno acumulado pelo preço do barril de petróleo, ao final de uma janela futura de F dias, dados o modelo construído e o histórico recente dos preços.

Este último é necessário pois,como o processo que estamos modelando não é estacionário, precisamos inferir o estado (da cadeia de Markov oculta) no qual ele se encontra no momento da previsão.

Assim, iniciamos a previsão calculando a distribuição dos estados da cadeia no tempo t (o instante atual).

Em seguida, utilizamos o paradigma de recompensas de cadeias de Markov (que será descrito mais adiante) para obter a distribuição do retorno em t + F, onde F é o tamanho da janela de previsão.

Ilustra o esquema geral da metodologia de previsão.

O intervalo de treinamento é dividido em intervalos de previsão de tamanho, conforme ilustrado na camada de previsão da medida.

Cada previsão individual é condicionada nas amostras dos últimos H dias mais recentes.

A seguir, descrevemos detalhadamente cada passo de nossa metodologia de previsão, que foi baseada em.

Esquema de previsão adaptativo do HMM.

Seja pt,h a probabilidade de a cadeia se encontrar no estado oculto Si, no tempo t, dadas as h observações mais recentes.

Ela pode ser facilmente calculada através da variável forward at.

Dado pt,h, podemos facilmente determinar a probabilidade, segundo nosso modelo, de o preço do petróleo ter uma alta de k% no dia seguinte.

Para isto, basta calcularmos a probabilidade de a cadeia emitir o símbolo vk após uma transição, o que pode ser feito da seguinte forma, onde rt+1 é o retorno em t+1, vk é o símbolo que corresponde a uma alta de k%, N é o número de estados da cadeia, bj(vk) é a probabilidade de o símbolo vk ser emitido pelo estado Sj, aij a probabilidade da transição (Si, Sj), e p a probabilidade do estado Si em t.

Se utilizarmos a equação para calcular a probabilidade de todos os símbolos do HMM.

Seguindo o mesmo raciocínio, podemos calcular a distribuição do retorno em t+t dias.

Basta calcularmos todos os retornos possíveis de serem obtidos ao final destes t dias e suas respectivas probabilidades.

Por exemplo, se t = 2 e o HMM tiver 2 símbolos, teremos 4 possíveis retornos, cujas probabilidades são dadas por onde Rt é o retorno total acumulado em t dias (cujo valor é k = l m), rt é o retorno obtido somente no dia t, e Vt é o símbolo emitido em t.

A probabilidade da cadeia emitir o símbolo vj, após t transições, é onde M é o tamanho do conjunto de símbolos, A é a matriz de probabilidades de transição da cadeia de Markov oculta, B é sua matriz de emissão e B é a j -ésima coluna desta matriz.

O problema desta abordagem é que o número de operações feitas para calcular todos os retornos possíveis em t + t cresce combinatorialmente com t.

Como vimos, para t = 2 e M = 2 temos que realizar 22 operações.

Agora, suponha que M = 10.

Se t = 3, precisamos de 103 operações.

Se quisermos fazer a previsão para daqui há um mês (20 dias úteis), necessitamos de 1020 operações.

Uma das vantagens em se utilizar cadeias de Markov, é que existem algoritmos eficientes que possibilitam o cálculo de diversas medidas de interesse, dada uma cadeia.

Um, em específico, nos permite obter a distribuição do acúmulo de determinado valor, após um número finito de transições.

Para isto, utiliza o paradigma de recompensas de impulso de uma cadeia de Markov.

Apesar de podermos definir recompensas de impulso tanto para cadeias de Markov, quanto para cadeias de Markov ocultas, o algoritmo mencionado acima só pode ser utilizado nas primeiras.

Não existe, até o momento, uma generalização que permita que ele seja aplicado também em cadeias de Markov ocultas.

No entanto, felizmente,existe uma forma simples de transformarmos uma cadeia de Markov oculta em uma cadeia de Markov equivalente com recompensas.

Sendo assim, para computar as previsões, decidimos transformar nossa cadeia de Markov oculta em uma cadeia de Markov com recompensas equivalente, para então, utilizarmos o algoritmo mencionado.

A seguir definimos o que são recompensas de impulso de uma cadeia de Markov.

Em seguida, mostramos como é possível expandir uma cadeia de Markov oculta, transformando-a em uma cadeia de Markov com recompensas.

Por fim, apresentamos o algoritmo que nos possibilitará obter a distribuição do retorno acumulado pelo preço do WTI ao final de uma janela de F dias.

Os modelos markovianos com recompensas de impulso têm associados, a cada transição da cadeia, um valor denominado recompensa de impulso, que é ganho pelo processo, como recompensa, cada vez que esta transi ção é feita.

Apresenta um modelo de Markov com recompensas de impulso.

Cadeia de Markov discreta de 2 estados com suas recompensas de impulso 1, 2, 3 e 4.

A variável ACI(t) mede a recompensa total acumulada pelo modelo no intervalo (0, t), e é, normalmente, definida como onde N(t) é o número de transições que ocorreram no intervalo (0, t), sn é a n-ésima transição e c(i,j) é o índice da recompensa associada à transição (Si, Sj).

Tradicionalmente, a recompensa de impulso é utilizada para contagem.

A fim de melhor ilustrar estes conceitos, considere o exemplo a seguir.

Suponha que a cadeia represente um jogo de cara ou coroa, no qual apenas uma moeda, não viciada, é utilizada.

A cada jogada, o jogador ganha 1 real se o resultado for cara, e perde 1 real se o resultado for coroa.

Formalmente, temos que S1 = Cara, S2 = Coroa.

A variável ACI(t) fornece a quantidade de dinheiro ganha pelo jogador após t jogadas Evolução da recompensa acumulada no tempo.

Seja X a cadeia de Markov oculta de N estados, A = {aij}, 1 = i, j = N sua matriz de probabilidades de transição de estados, Y o processo de observações de tamanho M, e B sua matriz de emissão de símbolos.

É possível construir uma cadeia de Markov discreta W, equivalente a X, com N × M estados, cuja distribuição de estados inicial p e matriz de probabilidades de transição.

A prova da equivalência entre as cadeias X e W, em relação a probabilidade de X emitir a seqüência de símbolos de tamanho Z e W receber a seqüência de recompensas de tamanho Z.

A principal característica do processo de Markov W é que seu espaço de estados é uma expansão do espaço de estados do processo oculto.

Ilustra o processo de expansão.

É apresentada a cadeia de Markov oculta a qual desejamos expandir e, a cadeia de Markov resultante da expansão.

Processo de expansão de um HMM.

Em está ilustrada a cadeia de Markov oculta e, em , sua cadeia de Markov equivalente.

A seguir, apresentamos um algoritmo desenvolvido por que permite calcular a distribuição da recompensa acumulada por uma cadeia de Markov, em um instante de tempo t, de forma eficiente.

Porém, antes de descrevê-lo, precisamos introduzir três novas variáveis.

Introdução de Limites à Recompensa Acumulada Em muitos dos processos que estudamos, há algum limite nos valores quantitativos observados.

Por exemplo, no jogo de cara ou coroa, um jogador pode ficar com, no mínimo, D reais, onde D é a quantidade de dinheiro apostada por ele6 e com no máximo B reais, onde B é a quantidade de dinheiro da banca de apostas.

Portanto, é necessário introduzirmos estes limites à variável ACI(t), para que esta fique condizente com a realidade.

Definimos então, as variáveis que representam, respectivamente, os valores dos limites inferior e superior de ACI(t).

Para ilustrar, suponha que, em nosso jogo de cara ou coroa, um jogador tenha apostado 1 real, e que a banca de apostas estabeleça em 4 reais o prêmio máximo que pode ser pago a um jogador.

Mostra o caminho amostral de ACI(t) sem os limite, o novo caminho, após a introdução dos limites.

Introdução de Níveis de Recompensa Além de limites inferiores e superiores, para evitarmos de trabalhar com todos os valores de recompensa no intervalo, definimos também a variável gran7 que estabelece o valor mínimo de recompensa que pode ser adicionado ou subtraído à recompensa acumulada, cada vez que o processo faz uma transição.

Desta forma, estamos definindo níveis de recompensa r0, que serão múltiplos da granularidade escolhida.

No nosso jogo de cara e coroa, o natural seria escolhermos gran = 1, uma vez que o valor mínimo de recompensa que um jogador pode ganhar ou perder é 1.

Escolhidas as variáveis, estamos prontos para calcular a distribui ção da recompensa acumulada.

Recursão para o cálculo da Distribuição da Recompensa Acumulada Seja Gs a probabilidade de a recompensa acumulada ser igual a r, dado a ocorrência de n transições, e que o estado visitado após a última transição seja o de granularidade.

Podemos calcular Gs através da seguinte recursão, onde s0 é o estado no qual a cadeia se encontra antes da transição ao estado S, r0 é a recompensa acumulada imediatamente antes da última transição, (s0, s) é a recompensa de impulso associada a transição (s0, s) e ps0s é a probabilidade da transição (s0, s).

Podemos fazer as seguintes considerações com relação a recursão, quando a recompensa r atinge os valores do limite inferior e do limite superior.

Para que a recompensa r atinja o valor na n-ésima transição, o valor de r0 até a transição n1 deve assumir valores maiores e a recompensa recebida pela transição (s0, s) deve ser, obrigatoriamente, menor que zero e ter valor absoluto maior.

Isto explica a restrição (s0, s) = 0 do primeiro somatório, e a restrição r0 = l.

Da mesma maneira, para que a recompensa r atinja o valor na n-ésima transição, o valor de r0 até a transição n-1 deve assumir valores menores e a recompensa recebida pela transição (s0, s) deve ser, obrigatoriamente, maior que zero e ter valor absoluto maior.

Isto explica a restrição (s0, s) = 0 do primeiro somatório e a restriçãodo segundo.

A recursão é mais facilmente compreendida se a olharmos do início para o final.

Ilustra o processo de cálculo da distribuição da recompensa acumulada pela cadeia apresentada.

Desenvolvimento da recursão, Cadeia de Markov e suas recompensas, caminho da recursão visto do início ao final.

Observando, fica evidente a razão pela qual são utilizados níveis de recompensa e sua importância.

Note que se não os adotássemos, a quantidade de valores possíveis para a recompensa acumulada, após as seis transições, seria enorme, uma vez que seu crescimento é combinatório.

Portanto, a idéia por trás deste método é limitar o número de valores da recompensa acumulada dentro do intervalo, de modo que seja viável calcular sua distribuição de probabilidades.

O cálculo é feito da seguinte forma.

Na primeira transição, a cadeia pode ganhar qualquer uma das três recompensas existentes.

Se o estado inicial é S1, há duas possibilidades de recompensa, 2 ou 1.

Se o estado inicial for S2, 0,75 ou 1.

Portanto, há três valores possíveis para a recompensa acumulada após a primeira transição, 1, 0,75 ou 2.

Suas probabilidades são, respectivamente, a12 + a21, a22 e a11, onde aij é a probabilidade da transição na cadeia.

No entanto, como 0,75 não corresponde a um dos níveis de recompensa existentes, teremos que aproximá-lo por um destes níveis.

O nível mais próximo de 0,75 é 1.

A distribuição para n = 2 é calculada a partir dos valores obtidos para n = 1.

Se ACI(1) = 2, a cadeia tem que, obrigatoriamente, estar no estado S1, e, portanto, só pode receber as recompensas 2, com probabilidade a11, ou 1, com probabilidade a12.

Se ACI(1) = 1, a cadeia tem, necessariamente, que estar no estado S2, e as recompensas possíveis de serem recebidas são 1, com probabilidade a22, ou 1, com probabilidade a21.

Por último, se ACI(1) = 1, a cadeia pode se encontrar em qualquer um dos dois estados e, assim, receber qualquer uma das três recompensas.

Procedendo de maneira análoga, podemos calcular a distribuição de ACI.

Uma visão mais completa, porém simples, do método discutido nesta subseção pode ser visto em e as referências nele contidas.

O trabalho que deu origem a recursão pode ser visto.

Modificações para Recompensas não Aditivas O método discutido acima assume que as recompensas são aditivas.

No entanto, em nosso caso de estudo, isso não é verdade.

Os símbolos emitidos por nosso HMM correspondem a retornos diários do preço do petróleo.

Quando expandirmos a cadeia oculta, estes passarão a ser as recompensas da cadeia de Markov equivalente.

Se, em três dias consecutivos, o petróleo teve alta de 1,20%, 2,53% e 0,78%, é errado afirmar que a alta acumulada foi de 1,20% + 2,53% + 0,78% = 4,51%.

O valor correto é obtido multiplicando-se os fatores de retorno8, e assim, a alta acumulada é, na realidade, de 1,012 1,0253 1,0078 = 1,0457 o que corresponde a uma alta de 4,57%.

Assim, é necessários fazermos alguns pequenos ajustes na recursão, para que seja possível trabalharmos com esta restrição.

Ao invés de somarmos ou subtrairmos as recompensas, teremos agora que multiplicá-las.

Definimos como fator de retorno o número pelo qual deve-se multiplicar o capital inicial para que seja obtido o capital final.

Se foi realizado um lucro de 2%, sobre um capital inicial de R$100, o fator de retorno é de 1,02, uma vez que 100 1,02 = 102 reais que equivale ao capital final.

Ele pode ser calculado pela equação frt = ptpt1 pt1.

Além disso, como retornos negativos têm fatores de retorno menores que 1 e os positivos, maiores que 1, devemos também modificar as restrições dos somatórios.

Especificamos seus parâmetros, justificando-os, e introduzimos o modelo HMM construído.

Na seção seguinte, descrevemos as métricas utilizadas na avaliação de nossa metodologia.

Apresentamos os resultados.

Finalmente comparamos o desempenho de nossa metodologia frente a dois outros modelos de referência, o Replicador e o Passeio Aleatório.

Esta seção está dividida em duas partes.

Na primeira, apresentamos os parâmetros utilizados na suavização por wavelets.

Em seguida, descrevemos o processo de construção e escolha dos parâmetros do HMM.

Como foi visto, a remoção de ruídos de um sinal decomposto em wavelets depende de duas escolhas.

A primeira consiste em selecionar uma base de wavelet, composta pelas funções f(x) e (x), as quais serão utilizadas como funções base na aproximação do sinal.

Já a segunda resume-se a definir a política de thresholding, ou seja, o método de remoção de coeficientes de wavelet.

Escolhemos trabalhar com a base de Daubechies de ordem 3.

Decidimos por esta wavelet pois, dentre o conjunto das wavelets disponíveis no Matlab, é aquela cujo formato mais se assemelha à dinâmica dos preços do WTI.

Reconhecemos que esta é uma escolha subjetiva, baseada apenas na inspeção visual das wavelets, e que seria necessário um estudo mais profundo das características de cada uma, para que pudéssemos avaliar, de forma precisa, qual destas seria mais adequada a nossa aplicação.

No entanto, devido às restrições de tempo, tal estudo não pode ser realizado.

Base de Daubechies de ordem 3 utilizada na suavização.

Função de escala f(x), e sua wavelet correspondente (x).

Conforme mencionamos, utilizamos a função wden do Matlab para suavizar nossos dados.

Esta função tem a vantagem de permitir ao usuário especificar tanto a função de thresholding quanto o valor do threshold com as quais deseja trabalhar.

Particularmente, escolhemos a função de soft thresholding, para evitarmos que possíveis descontinuidades abruptas pudessem surgir na série suavizada1.

A regra de escolha do threshold pela qual optamos foi a heursure, que é uma variante da regra SURE.

Conduzimos um breve estudo para avaliar as diferentes regras disponíveis em wden quanto ao resultado da suavização, porém, observamos que a série suavizada era praticamente idêntica, independente da regra utilizada.

Mais detalhes sobre a função wden podem ser encontrados em.

A seguir, descrevemos detalhadamente as características do modelo HMM que construímos.

Começamos explicando o método que empregamos para determinar a estrutura de sua cadeia de Markov.

Em seguida, especificamos seus elementos (o número de estados, número de símbolos, janela de treinamento, etc) e, por fim, descrevemos como foram obtidos os valores iniciais dos parâmetros do modelo.

Estrutura da Cadeia de Markov Além do número de estados N, um modelo de Markov é caracterizado pela estrutura de sua cadeia.

Até aqui, em todos os nossos exemplos, utilizamos cadeias completas, ou seja, cadeias nas quais cada estado pode ser alcançado partindo-se de qualquer outro estado, com uma transição apenas.

Matematicamente, isto significa que, j aij > 0.

No entanto, uma cadeia de Markov não precisa, necessariamente, ter esta estrutura.

Ilustra alguns exemplos de cadeias com estruturas diferentes, comuns de serem encontradas na bibliografia.

A escolha da estrutura a ser utilizada no modelo depende das características do fenômeno o qual se está estudado.

Infelizmente, não existe um algoritmo que, dado um conjunto de características, construa uma cadeia ótima.

Esta é uma tarefa que exige criatividade e bastante conhecimento sobre o processo que se deseja modelar.

Assim, a fim de definirmos a estrutura de nosso HMM, realizamos um estudo para identificar as principais características presentes em nosso conjunto de dados.

A suavização da série de preços do WTI torna evidente o fato de que estes se movem, quase sempre, em direções bem definidas (para cima, preços em alta, ou para baixo, preços em queda), as quais são denominadas de tendências.

A primeira característica pela qual procuramos é se existe alguma periodicidade nestas tendências, como uma rápida inspeção visual da figura sugere.

Diferentes tipos de cadeias de Markov com 3 estados, cadeia completa, cadeia left-right, cadeia coxian, cadeia coxian geral.

No entanto, a Figura(que mostra a autocorrelação dos retornos diários calculados a partir da série suavizada de preços), sugere que não existe nenhuma periodicidade ou ciclo, de modo que, aparentemente, o momento em que determinada tendência ocorre não contém nenhuma informação sobre quando ela se repetirá novamente.

Assim, passamos nosso foco de estudo para o tempo de duração das tendências, com o objetivo de tentarmos construir uma cadeia de Markov que reproduza-o adequadamente, para que assim, uma vez identificada uma tendência, possamos, a partir do modelo, calcular, por exemplo, a probabilidade de ela continuar por mais D dias.

Mostra a freqüência relativa do tempo de duração (em dias) das tendências de alta e de baixa.

Não incluímos ali os tempos de duração de 1 e 2 dias, pois consideramos que estas tendências de curtíssima duração são meramente ruídos não removidos pelo método de suavização em tendências mais longas.

Observando ambos os gráficos, podemos notar que os movimentos de alta dos preços tendem a ser mais duradouros que os movimentos de baixa2, o que indica que é possível que ambos tenham características distintas.

Por este motivo, resolvemos modelá-los separadamente.

Este fato é, frequentemente, observado em ativos financeiros de alta liquidez como ações e câmbio, e é de conhecimento geral.

Freqüência relativa do tempo de duração, em dias, das tendências de alta e baixa do preço do WTI.

Para melhor caracterizar a duração de uma tendência, decidimos buscar uma distribuição de probabilidades para representá-la.

Utilizando o Matlab, testamos, inicialmente, as seguintes distribuições3, Exponencial, Gamma, Weibull, LogNormal e Pareto Generalizada.

A qualidade do ajuste de cada uma foi verificada através de duas análises, uma visual e outra quantitativa.

A análise visual consistiu em comparar os gráficos da função de distribuição acumulada complementar (CCDF, do inglês complementary cumulative distribution function) de cada distribuição testada ao gráfico da CCDF empírica.

A análise quantitativa foi feita pela comparação do erro médio quadrático (MSE, do inglês mean squared error) calculado entre a distribuição empírica e as estimadas.

Não conseguimos, no entanto, com nenhuma delas, obter uma descrição satisfatória.

Passamos a investigar, então, uma outra classe de distribuições, conhecidas como distribuições phase-type (PH).

A parametrização foi feita utilizando um estimador de máxima verossimilhança Uma distribuição PH é definida como a distribuição do tempo decorrido até que um estado absorvente4, Sabs, de uma cadeia de Markov, seja alcançado.

Isto torna-a de grande interesse para nós, pois, por ser definida através de uma cadeia de Markov, uma vez encontrada uma parametrização adequada, encontra-se, consequentemente, a estrutura da cadeia que a gerou (que é justamente o que buscamos).

Testamos as seguintes distribuições PH, Completa, Hiperexponencial, Soma de Exponenciais, Coxian e Coxian Geral.

A parametrização de cada uma foi feita com software EMpht, que realiza uma estimação de parâmetros iterativa, utilizando um algoritmo EM.

Calculando as mesmas métricas de avaliação de qualidade do ajuste descritas acima (comparação da CCDF e do MSE), chegamos a conclusão que, em geral, as distribuições PH (exceto a soma de exponenciais) apresentaram melhor ajuste aos dados empíricos se comparadas às distribuições testadas inicialmente, e que, dentre elas, a que apresentou resultados superiores foi a coxian geral.

Isto foi verificado tanto para as tendências de alta quanto às de baixa.

Desta forma, decidimos que a cadeia de Markov de nosso HMM deveria ser composta de duas cadeias coxian geral, uma responsável por reproduzir as tendências de alta, e outra, por reproduzir as tendências de baixa.

Quanto ao número de estados de cada cadeia, deixaremos para definí-lo mais adiante.

Resta-nos ainda resolver um problema, como unir ambas as partes, a fim de construirmos uma cadeia única.

Lembre-se que a cadeia de Markov que gera uma distribuição PH contém um estado absorvente, e que, no caso de nossa aplicação, este estado indica fim da tendência.

Assim, se conectarmos todas as transições que chegam a este estado aos estados da outra parte, pelos quais o processo pode se iniciar, estaremos essencialmente conectando o final de uma tendência (de alta, por exemplo) ao início da tendência seguinte (de baixa).

As setas em vermelho representam as transições que foram removidas da cadeia, e as em azul, as que foram adicionadas.

Assim, procedendo da maneira descrita, construímos a estrutura da cadeia de Markov do nosso modelo HMM.

Um estado é classificado como absorvente se não há como deixá-lo.

Matematicamente, isto significa que aii = 1.

Transição ao estado absorvente removida Transição adicionada que interliga ambas as estruturas Exemplo do processo de união das estruturas construídas para as tend ências de alta e baixa dos preços.

Antes de finalizarmos esta etapa, precisamos fazer uma ressalva.

O programa EMpht, citado acima, faz o ajuste de uma distribuição phase-type contínua aos dados e, portanto, nos fornece como saída uma cadeia de Markov de tempo contínuo.

No entanto, estamos trabalhando com um modelo de Markov de tempo discreto, de modo que foi necessário encontrar alguma maneira de se transformar esta cadeia contínua em uma discreta equivalente.

Felizmente, existe uma técnica, conhecida como método de Uniformização, que faz exatamente isso.

Definida a estrutura geral da cadeia, precisamos, ainda, especificar o modelo HMM.

Seus elementos são o número de estados N, o número de símbolos M, o valor de cada faixa V às quais os símbolos estão associados, o tamanho do intervalo t e a quantidade de amostras T que serão utilizadas no treinamento e, finalmente, o intervalo de previsão, o tamanho do histórico recente H e o tamanho da janela de previsão F.

A seguir, especificamo-os individualmente.

Devido ao alto grau de incerteza presente na série de preços, não é possível utilizar uma janela de previsão muito extensa, de 100 dias por exemplo.

No entanto, a alta volatilidade da série também não permite que esta janela seja curta demais, da ordem de 1, 3 ou 5 dias.

Assim, realizamos um estudo empírico para definir seu tamanho adequado, e chegamos a conclusão que este encontra-se, aproximadamente, dentro do intervalo dias.

Assim, apresentaremos nossos resultados tanto para F = 20 quanto para F = 30 dias.

Observando podemos notar que são raras as tendências cuja duração é superior a 60 dias.

Por esta razão, decidimos utilizar este valor como tamanho do histórico recente utilizado na previsão, pois consideramos que ele é suficiente para identificarmos a tendência corrente e, assim, inferirmos o possível estado no qual a cadeia se encontra no momento da previsão.

O intervalo de previsão foi escolhido como tendo o mesmo tamanho da janela de previsão, a fim de simplificar o modelo e seus resultados.

Os valores de N, M, V, t e T foram obtidos experimentalmente, através de um estudo de análise de sensibilidade.

Conforme mencionado acima, fizemos experimentos usando duas janelas de previsão distintas, 20 e 30 dias, portanto, na tabela abaixo, estão especificados os valores dos elementos utilizados em cada caso.

Escolha dos Valores Iniciais dos Parâmetros do HMM Conforme discutido, os valores iniciais dados aos parâmetros p, A e B têm influência sobre modelo resultante.

Isto ocorre pois, apesar de o algoritmo EM (utilizado na estimação destes parâmetros) convergir para um máximo local da função verossimilhança, nada garante que este último é, também, um máximo global.

É evidente que, a medida que o modelo se torna mais complexo (o que ocorre quando se aumenta o número de estados, o número de símbolos, ou a estrutura da cadeia), cresce o número de máximos locais da função de verossimilhan ça.

Portanto, é de se esperar que modelos maiores sejam mais sensíveis a essas escolhas iniciais.

Na subseção anterior, descrevemos um método para estimar a estrutura da cadeia de Markov do modelo HMM, que consistia em ajustar uma distribuição PH ao conjunto dos tempos de duração das tendências.

Devido à natureza desta distribuição, essencialmente o que estamos fazendo, ao aplicarmos este método, é encontrar os parâmetros (p e A) que melhor ajustam uma cadeia de Markov absorvente, espec ífica, ao conjunto de dados.

Assim, decidimos utilizar estes valores encontrados como os valores iniciais dos parâmetros p e A de nosso modelo.

Há apenas alguns detalhes aos quais devemos estar atentos.

Lembremo-nos que nossa cadeia é dividida em duas partes, uma que corresponde as tendências de alta e outra que corresponde as tendências de baixa, e que o ajuste de cada uma é feito individualmente.

Assim, como resultado, temos duas cadeias distintas, cA e cB, cada qual com seu conjunto de parâmetros.

Evidentemente, ao uní-las, não podemos simplesmente concatenar os vetores pcA e pcB de modo a forma o vetor p da cadeia conectada.

Se assim o fizéssemos, este último não seria um vetor de probabilidades, uma vez que a soma de seus elementos seria igual a 2,5 É preciso que, após esta concatenação, seja feita a normalização do vetor p.

Um cuidado semelhante deve ser tomado com o parâmetro A.

Conforme vimos, uma transição feita de um estado transiente para um estado absorvente deve ser substituída por I novas transições (onde I é o número de estados iniciais da outra cadeia), cada qual ligando o estado transiente em questão aos estados iniciais da outra.

Evidentemente, os valores destas novas transições não podem ser iguais ao valor da transição removida (isto violaria as restrições probabilísticas).

Logo, o valor de uma nova transição deve ser igual ao valor da transição antiga vezes a probabilidade do estado inicial ao qual ela se liga.

Matematicamente, isto significa que aik = ai,abs p(k).

Transição ao estado absorvente removida Transição adicionada que interliga ambas as estruturas Exemplo do processo de união dos parâmetros das estruturas construídas para as tendências de alta e baixa dos preços.

Definidos os valores iniciais de p e A, resta-nos especificar o parâmetro B.

A fim de definirmos seus valores iniciais, tentamos primeiro encontrar uma distribuição de probabilidades que reproduzisse adequadamente o conjunto de retornos de nossa série de preços suavizada.

Naturalmente, dividimos os retornos em positivos e negativos, e ajustamos uma distribuição para cada conjunto.

Foram testadas as seguintes distribuições, Exponencial, Gamma, Weibull, LogNormal e Pareto Generalizada.

A avaliação da qualidade do ajuste foi feita utilizando as mesmas métricas citadas anteriormente, comparação do CCDF e do MSE.

Para ambos os conjuntos retornos negativos e positivos a distribuição que melhor se ajustou aos dados foi a Gamma.

Encontrada uma distribuição para os retornos, podemos então definir a distribui ção inicial de símbolos em cada estado e, consequentemente, os valores iniciais do parâmetro B.

Suponha que queiramos definir estas probabilidades para um estado que pertença à cadeia que representa as tendências de alta.

Naturalmente, os sím bolos que representam retornos negativos terão probabilidade zero.

Para os demais, sua probabilidade de emissão será igual a probabilidade do intervalo ao qual estão associados, calculada a partir da distribuição Gamma ajustada.

Procedendo de maneria análoga para cada estado, definimos, assim, os valores iniciais do parâmetro B.

Definindo a distribuição dos símbolos do modelo HMM.

Neste exemplo, estamos utilizando M = 6 símbolos e V = 0,5%.

Os três primeiros símbolos (que não estão ilustrados) têm probabilidade zero, pois representam retornos negativos.

A metodologia proposta no capítulo 4 tem como objetivo prever a distribuição do retorno acumulado do preço do petróleo, ao final de uma janela de tempo futura de F dias.

É de grande interesse para um investidor ter uma distribuição como esta disponível, pois isto lhe permite elaborar diferentes estratégias de investimento, assim como estimar o risco de suas decisões.

A fim de avaliarmos a metodologia e o modelo criados (quanto à qualidade de suas previsões), decidimos verificar os resultados auferidos por um investidor que utilizasse-os, em conjunto com a seguinte a estratégia de investimento, comprar petróleo no mercado spot se a média da distribuição calculada for positiva (o que indica que o modelo calcula que uma alta no preço é mais provável que uma queda) e vender se a média for negativa6.

Decidimos fazer uso desta estratégia por sua simplicidade, e por representar um referencial para todas as outras, uma vez que, caso o investidor consiga obter lucros extraordinários utilizando-a, então, muito possivelmente, ele também o fará se construir outras estratégias mais complexas, que, por exemplo, façam uso de instrumentos financeiros como derivativos e opções.

Definida a estratégia, utilizamos as seguintes métricas para avaliar nossa metodologia, Dstat, indica a taxa de acerto da direção dos preços, ou seja, a fração de vezes que o modelo previu corretamente uma alta (ou queda) nos preços, no período considerando.

Retorno, indica o retorno obtido pelo investidor, ao utilizar determinada estratégia.

Os ensaios a seguir foram realizados utilizando a série de preços diários, nominais, do WTI obtida na página da EIA.

Ela contém 5760 observações, e compreende o período que vai de 02 de janeiro de 1986 a 28 de outubro de 2008.

Vender não deve ser interpretado aqui como short selling, mas, simplesmente, como uma operação de venda no mercado spot à vista, caso o investidor possua a commodity, ou apenas não comprar, caso ele não a possua.

A estimação da estrutura do modelo e de seus parâmetros iniciais utilizando as primeiras 4000 amostras da série.

Por isso, consideramos que o investidor hipotético, descrito na seção anterior, inicia seus investimentos somente em agosto de 2001, após ter feito estas estimações iniciais.

A seguir, apresentamos os resultados obtidos para duas janelas de previsão distintas, de 20 e 30 dias.

Neste primeiro ensaio, consideramos que a janela de previsão do investidor é de 20 dias, ou seja, a cada 20 dias úteis ele reavalia sua posição no mercado.

A estratégia de investimento utilizada por ele é aquela descrita.

Os valores dos elementos do HMM utilizados neste ensaio encontram-se especificados.

Ilustra a evolução do capital do investidor (amostrado a cada 20 dias) no período de agosto de 2001 a outubro de 2008.

Assumimos que seu investimento inicial é de 100 dólares, que, em nenhum momento, há adição de capital externo, e que não há custos de transação.

Para efeito de comparação, também mostra a evolução do capital de um investidor que tivesse optado pela estratégia Buy-and-Hold, ou seja, que tivesse investido 100 dólares comprando petróleo em agosto de 2001 e não houvesse mais mudado de posição.

Ao ilustrarmos esta estratégia, estamos, na realidade, comparando o retorno auferido pela utilização de nosso modelo ao retorno do mercado.

No período considerado, o modelo HMM obteve uma taxa de acerto Dstat = 63,33%, o que significa que, das 90 previsões feitas, o modelo conseguiu acertar a direção do preço do WTI em 57 delas.

O capital final, possuído pelo investidor que utilizou o modelo, é de 615 dólares, o que representa uma rentabilidade de 515% em 7 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 125%, resultando em um capital final de 225 dólares.

Compara a rentabilidade anual da estratégia que utiliza o HMM, à rentabilidade anual do mercado, ou seja, àquela obtida pelo Buy-and-Hold.

Dela, podemos, primeiramente, observar que, utilizando o HMM, conseguimos acompanhar as altas do mercado, como ocorreu nos anos de 2002, 2004, 2005 e 2007.

Apesar de, nestes anos, a rentabilidade do modelo ser menor que a do mercado, ela é, na maioria das vezes, bem próxima.

Mas a grande vantagem do HMM aparece nos mercados em baixa.

Observemos os anos de 2003 e 2008.

Em ambos, a utilização do HMM trouxe uma substancial vantagem ao investidor, especialmente no ano de 2008, no qual houve uma aumento significativo dos preços do petróleo em seu início, seguido de uma queda brusca, do meio para o final do ano.

A título de curiosidade, decidimos também verificar como o modelo se comportaria caso um investidor o tivesse utilizado desde o início da série.

Estamos conscientes que esta verificação ignora o fato de que os valores iniciais dos parâmetros do modelo foram estimados a partir de dados futuros.

No entanto, como a reestimação de parâmetros é feita a cada 600 dias úteis, a influência de seus valores iniciais se faz presente apenas nas primeiras previsões.

Além disso, como de 2001 até 2008 o preço do petróleo esteve, quase sempre, em alta, achamos válido verificar como o modelo se comportaria em outras situações (como uma longa baixa, por exemplo).

Mesmo que a análise deste ensaio não possa ser utilizada para se formular uma conclusão definitiva, ela pode nos fornecer alguns indícios.

Assim, ilustra a evolução do capital do investidor no período de maio de 1988 a outubro de 2008.

Novamente assumimos que o investimento inicial feito foi de 100 dólares, que, em nenhum momento, houve adição de capital externo, e que não existem custos de transação.

No período considerado, a taxa de acerto Dstat do modelo HMM foi de 60,07%, o que significa que, das 258 previsões feitas, ele conseguiu acertar a direção do preço do WTI em 155 delas.

O capital final, possuído pelo investidor que utilizou o modelo, é de 2340 dólares, o que representa uma rentabilidade de 2240% em aproximadamente 21 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 254%, resultando em um capital final de 354 dólares, ou seja, a rentabilidade do investidor que utilizou o HMM foi superior a do mercado em quase dez vezes.

Compara a rentabilidade anual da estratégia que utiliza o HMM, à rentabilidade anual do mercado, no período testado.

Em 13 dos 21 anos (ou em 61,90% das vezes), a rentabilidade do modelo foi igual ou superior a rentabilidade do mercado.

Novamente, podemos observar como o modelo reduz significativamente as perdas nas épocas de queda do mercado, e acompanha razoavelmente as altas.

Por fim, ilustra a evolução, no tempo, da distância entre o capital acumulado por ambas as estratégias.

Esta distância é calculada como a diferen ça entre os logaritmos do capital acumulado pelo modelo e pelo Buy-and-Hold.

Observando-a, fica evidente a tendência de crescimento, no longo prazo, desta dist ância, o que indica que o modelo consegue, constantemente (no longo prazo), auferir resultados superiores aos do mercado.

Distância entre o Capital Acumulado pelas Estratégias Consideradas Distância entre o capital acumulado pela estratégia que utiliza o modelo HMM e o acumulado pela estratégia Buy-and-Hold.

Nesta seção, repetimos os ensaios realizados na seção anterior, só que, desta vez, utilizamos uma janela de previsão de 30 dias.

Estes novos experimentos foram realizados com o objetivo de verificarmos a capacidade de previsão da metodologia e do modelo desenvolvidos, ao serem utilizados com um horizonte de previsão um pouco mais longo.

Os resultados aqui apresentados seguem a mesma forma daqueles apresentados.

Os parâmetros utilizados encontram-se especificados.

Ilustra a evolução do capital (amostrado a cada 30 dias) de dois investidores distintos, um que utiliza o HMM e outro que utiliza o Buy-and-Hold, no período de outubro de 2001 a outubro de 2008.

Novamente assumimos que o investimento inicial feito foi de 100 dólares, que, em nenhum momento, houve adição de capital externo, e que não existem custos de transação.

Evolução do capital investido com o HMM e com o Buy-and-Hold.

A taxa de acerto Dstat do HMM foi de 66,10%.

No período considerado, o modelo HMM obteve uma taxa de acerto Dstat = 66,10%, o que significa que, das 59 previsões feitas, o modelo conseguiu acertar a direção do preço do WTI em 39 delas.

O capital final, possuído pelo investidor que utilizou o modelo HMM, é de 658 dólares, o que representa uma rentabilidade de 558% em 7 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 183%, resultando em um capital final de 283 dólares.

Compara a rentabilidade anual da estratégia que utiliza o HMM, à rentabilidade anual do mercado, ou seja, àquela obtida pelo Buy-and-Hold.

Novamente, podemos observar que, utilizando o HMM, conseguimos acompanhar bem as altas no mercado, e nos posicionar favoravelmente durante as baixas, evitando assim perdas substanciais (como em 2006 e 2008).

Rentabilidades Anuais das Estratégias HMM e Buy-and-Hold entre 2002 e 2008.

Pelos mesmos motivos descritos, decidimos também verificar o comportamento do modelo HMM nos anos anteriores à 2002.

Ilustra a evolução do capital do investidor no período de julho de 1989 a outubro de 2008.

Novamente assumimos que o investimento inicial feito foi de 100 dólares, que, em nenhum momento, houve adição de capital externo, e que não existem custos de transação.

Evolução do capital investido com o HMM e com o Buy-and-Hold.

A taxa de acerto Dstat do HMM foi de 61,11%.

No período considerado, a taxa de acerto Dstat do modelo HMM foi de 61,11%, o que significa que, das 162 previsões feitas, ele conseguiu acertar a direção do preço do WTI em 99 delas.

O capital final, possuído pelo investidor que utilizou o modelo HMM, é de 1918 dólares, o que representa uma rentabilidade de 1818% em aproximadamente 20 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 207%, resultando em um capital final de 307 dólares.

Compara a rentabilidade anual da estratégia que utiliza o HMM, à rentabilidade anual do mercado, no período testado.

Em 13 dos 19 anos (ou em 68,42% das vezes), a rentabilidade do modelo foi igual ou superior a rentabilidade do mercado.

Novamente, podemos observar como o modelo, na maior parte dos anos, reduz significativamente as perdas nas épocas de queda do mercado, e acompanha razoavelmente as altas.

Ilustra evolução, no tempo, da distância entre o capital acumulado por ambas as estratégias.

Observando-a, fica evidente a tendência de crescimento, no longo prazo, desta distância, o que indica que o modelo consegue, no longo prazo, auferir resultados superiores aos do mercado.

Distância entre o Capital Acumulado pelas Estratégias Consideradas Distância entre o capital acumulado pela estratégia que utiliza o modelo HMM e o acumulado pela estratégia Buy-and-Hold.

O método que utilizamos para encontrar valores iniciais para os parâmetros p e A, sofre de um empecilho.

Conforme mostramos, estes valores são obtidos do ajuste feito a partir de uma distribuição PH (no caso, uma coxian geral) ao conjunto dos tempos de duração das tendências.

Este ajuste, por sua vez, é feito pelo programa EMpht, através de um algoritmo EM, ou seja, o resultado do ajuste depende dos valores iniciais dados a distribuição PH.

Assim, a fim de verificarmos a influência que o resultado deste ajuste pode ter sobre nossos resultados finais, decidimos fazer uma análise de sensibilidade dos últimos em relação aos primeiros.

O programa EMpht, por padrão, inicializa aleatoriamente os parâmetros da distribui ção PH que será ajustada.

Assim, decidimos fazer 101 ajustes diferentes com o programa e, a partir de cada um, utilizando o método de estimação de parâmetros iniciais, obtivemos 101 conjuntos distintos de valores iniciais de parâmetros para nosso modelo HMM.

Realizamos, então, 101 vezes nossos experimentos, e verificamos a variabilidade dos resultados finais.

Infelizmente, observamos que estes ajustes iniciais têm, sim, influência consider ável nos resultados finais7.

Nela, é ilustrada a taxa de acerto (Dstat) obtida por cada um dos 101 experimentos realizados, para seis configurações distintas do HMM (nas quais varia, apenas, o número de estados), e também sua média e seu desvio padrão, considerando uma janela de previsão de 20 dias, e que o período de investimento tem início em agosto de 2001 e se encerra em outubro de 2008.

A variabilidade dos resultados obtidos ilustra como o HMM é sensível aos valores iniciais de seus parâmetros.

Verificamos então, se havia alguma relação entre a qualidade do ajuste feita pelo EMpht e qualidade do modelo resultante, ou seja, se os ajustes com maior likelihood resultavam nos melhores modelos.

No entanto, não observamos qualquer relação óbvia.

Taxa de acerto obtida por cada um dos 101 experimentos realizados para seis configurações distintas do HMM.

A média e o desvio padrão de cada configuração são apresentados, respectivamente, dentro das caixas pretas.

Assim, os resultados apresentados são os melhores que obtivemos, em termos de rentabilidade ao investidor, dada a configuração do modelo HMM escolhida (número de estados, janela de treinamento, etc) para as duas janelas de previsão consideradas, de 20 e 30 dias.

Em separado, os resultados apresentados acima não são suficientes para convencer um investidor a adotar a metodologia proposta neste trabalho.

Para isto, precisamos também mostrar que ela tem desempenho superior à outras estratégias existentes, especialmente as mais simples.

Evidentemente, não nos cabe, aqui, fazer uma análise comparativa entre todos os modelos preditivos e estratégias de investimento já elaborados.

Por isso, decidimos fazer tal comparação considerando apenas dois métodos de previsão clássicos, extremamente simples, o preditor replicativo e o passeio aleatório.

Selecionamos estes dois, pois consideramo-os uma referência.

Se não é possível prever os movimentos do preço do petróleo, então qualquer estratégia (ou modelo preditivo) elaborada terá desempenho, no máximo, igual a ambos.

Dado uma série temporal, a estratégia do preditor replicativo assume que a melhor previsão para a próxima amostra é a amostra atual.

Assim, a previsão de yt é yt = yt1.

Em nosso caso, como estamos querendo prever o retorno acumulado pelo WTI em um intervalo futuro de F dias, o valor previsto por esta estratégia será igual ao seu retorno acumulado nos F dias anteriores.

Ilustra a evolução do capital de um investidor que adotasse a estrat égia do preditor replicativo, entre agosto de 2001 e outubro de 2008, utilizando uma janela de previsão de 20 dias.

Novamente, assumimos que é feito um investimento inicial de 100 dólares, que, em nenhum momento, há adição de capital externo, e que não existem custos de transação.

Evolução do capital investido com o preditor replicativo e com o Buyand-Hold.

A taxa de acerto Dstat do preditor replicativo foi de 48,89%.

No período considerado, o preditor replicativo obteve uma taxa de acerto Dstat = 48,89%, o que significa que, das 90 previsões feitas, ele conseguiu acertar a direção do preço do WTI em apenas 44 delas.

O capital final, possuído pelo investidor que utilizou esta estratégia, é de 179 dólares, o que representa uma rentabilidade acumulada de 79% em 7 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 125%, resultando em um capital final de 225 dólares.

Compara a rentabilidade anual da estratégia replicadora à rentabilidade anual do HMM (considerando F = 20 dias) e à do mercado, no período testado.

Observe que em apenas 1 dos 7 anos, a rentabilidade da estratégia replicadora foi igual ou superior a rentabilidade do mercado, e que, em nenhum momento, ela conseguiu superar a rentabilidade do HMM.

A exemplo do que fizemos, decidimos também verificar os resultados desta estratégia replicadora caso utilizassemo-na desde o início da série.

Ilustra a evolução do capital de um investidor que adotasse a estratégia do preditor replicativo, entre maio de 1988 e outubro de 2008, utilizando uma janela de previsão de 20 dias.

Novamente, assumimos que é feito um investimento inicial de 100 dólares, que, em nenhum momento, há adição de capital externo, e que não existem custos de transação.

Evolução do capital investido com o preditor replicativo e com o Buyand-Hold.

A taxa de acerto Dstat do preditor replicativo foi de 51,94%.

No período considerado, a taxa de acerto Dstat do preditor replicativo foi de 51,94%, o que significa que, das 258 previsões feitas, ele conseguiu acertar a direção do preço do WTI em apenas 134 delas.

O capital final, possuído pelo investidor que utilizou esta estratégia, é de 476 dólares, o que representa uma rentabilidade de 376% em, aproximadamente, 21 anos.

Neste mesmo período, a estratégia Buy-and-Hold apresentou uma rentabilidade de 254%, resultando em um capital final de 354 dólares.

Compara a rentabilidade anual da estratégia replicadora à rentabilidade anual do HMM (considerando F = 20 dias) e à do mercado, no período testado.

Observe que em apenas 10 dos 21 anos (ou em 47,62% das vezes), a renta bilidade da estratégia replicadora foi igual ou superior a rentabilidade do mercado, enquanto que, para o HMM, esta taxa foi de 61,90% (ou 13) anos.

Além disso, a rentabilidade do HMM supera a do Replicador em 16 dos 21 anos em questão (ou 76,19% das vezes).

O modelo de passeio aleatório, considera que cada mudan ça sucessiva em uma série temporal yt é extraída, independentemente, de uma distribuição de probabilidade com média 0 e variança s2.

Se, de fato, o preço do petróleo segue um passeio aleatório, então é impossível prever seus movimentos futuros, e, portanto, qualquer rentabilidade significativa que houvesse sido auferida por um investidor, através da utilização de um modelo matemático, seria conseqüência da sorte.

Assim, decidimos verificar os resultados obtidos por um modelo de passeio aleatório, a fim de averiguar a possibilidade de que os resultados conseguidos com o HMM tenham sido obra do acaso.

Resolvemos, então, construir a seguinte estratégia de investimento, a cada F dias (onde F é o tamanho da janela de previsão) o investidor joga uma moeda, não viciada, e, se o resultado for cara, ele compra petróleo no mercado spot, caso tenha capital disponível, se for coroa, ele vende no mercado spot todo óleo que possuir.

A posição adotada não é alterada até que se passem os F dias.

Realizamos, ao todo, 10000 ensaios, utilizando uma janela de previsão F = 20 dias.

A fim de compararmos os resultados deste modelo, aos obtidos pelo HMM, consideramos que os investimentos são realizados entre agosto de 2001 e outubro de 2008.

Assumimos, novamente, que o investidor dispõe de um capital inicial de 100 dólares, e que não há, em nenhum momento, introdução de capital externo.

Assumimos, também, que não existem custos de transação.

Conforme discutido, os resultados do HMM são sensíveis à escolha de seus parâmetros iniciais.

Por esta razão, não basta, simplesmente, compararmos os resultados de um único ensaio, aos obtidos pelo passeio aleatório, sob o risco de que este ensaio tenha, por acaso, apresentado bons resultados.

É necessário, também, verificarmos se, em geral, o HMM apresenta resultados superiores aos do passeio aleatório.

Assim, utilizamos as métricas colhidas na análise de sensibilidade feita para o HMM, e comparamo-as as calculadas a partir dos ensaios feitos para o passeio aleatório.

Estas métricas são taxa de acerto média (valor médio observado para a estatística Dstat), variância da taxa de acerto, probabilidade de Dstat = 57%, probabilidade da rentabilidade da metodologia ser maior que a do mercado (ou seja, ser superior a estratégia Buy-and-Hold), probabilidade de se auferir rentabilidade negativa, e o 90o percentil da rentabilidade.

É feita esta comparação.

Observando-a, fica evidente a superioridade do HMM em relação ao modelo de passeio aleatório.

Comparação entre os Resultados do HMM e do Passeio Aleatório Vimos a importância de se construir um modelo de previsão do preço do petróleo.

Vimos também que, devido a enorme quantidade de fatores que o afetam, a construção de modelos de regressão preditivos é uma tarefa difícil, principalmente devido ao fato de que, nestes, a previsão do preço está, normalmente, condicionada a previsão das próprias variáveis explanatórias.

Esta dificuldade inerente aos modelos de regressão estimulou a busca de formas alternativas de se tentar fazer esta previsão, utilizando, por exemplo, modelos de séries temporais.

Os modelos de séries temporais lineares, como o AR, o ARMA e o ARIMA, não apresentaram resultados preditivos satisfatórios, como verificado em, sugerindo que a série de preço do petróleo está longe de ser um processo linear.

Recentemente, devido ao aumento do poder computacional, uma nova classe de modelos preditivos não lineares vem sendo testada, dentre os quais podemos citar as Redes Neurais.

Os resultados apresentados por sugerem que, estes sim, conseguem capturar um pouco da dinâmica dos preços, e apresentam capacidade preditiva satisfatória.

Dentro deste contexto, esta dissertação teve como objetivo propor a utilização de um outro modelo não linear de previsão de séries temporais, ainda pouco utilizado na área financeira, conhecido como modelo de Markov oculto HMM, e verificar sua eficácia na previsão do comportamento do preço do petróleo.

Elaboramos uma metodologia de previsão que consiste de, basicamente, duas etapas.

Na primeira, devido a alta volatilidade existente, suavizamos a série de preços utilizando as Wavelets, com o objetivo de ressaltar suas reais tendências e, assim, destacar seus movimentos significativos.

Em seguida, esta série suavizada é fornecida como entrada ao HMM, e utilizada para estimar seus parâmetros.

Determinados estes valores, o HMM é, então, utilizado para fazer as previsões.

Decidimos por prever a distribuição completa do retorno acumulado pelo preço do petróleo, ao invés de, somente, seu valor esperado, pois entendemos que a primeira traz muito mais informações úteis ao investidor, e permite que ele, por exemplo, possa fazer uma análise de risco de suas decisões.

Os resultados apresentados encorajam a utilização do HMM na previsão dos movimentos do preço do petróleo e, certamente, de outros ativos financeiros (como preço de ações ou outras commodities).

Verificamos que, utilizandoo, é possível identificar os movimentos significativos dos preços (suas tendências) e, a partir destes, calcular a probabilidade de que, no futuro próximo, se mantenham ou se invertam.

Entretanto, ainda há um aspecto que deve ser visto com muito cuidado e estudado mais a fundo.

Conforme comentamos ao longo desta dissertação, o HMM é sensível a escolha dos valores iniciais de seus parâmetros.

Apesar de termos elaborado uma metodologia para escolhe-lôs, ela não é conclusiva, ou seja, não nos fornece, sempre, um conjunto ideal de valores.

Por esta razão, foi necessário fazermos diversos ensaios para uma mesma configuração do HMM, a fim de escolhermos o conjunto de valores iniciais dos parâmetros que levam aos melhores resultados.

Assim, acreditamos que o próximo passo deste trabalho é estudar cuidadosamente a diferença entre estes valores, identificar a razão pela qual uns resultam em bons modelos, e outros não, e, assim, elaborar um método que otimize-os.

Por fim, achamos importante ressaltar que o modelo desenvolvido neste trabalho, assim como qualquer outro modelo matemático, jamais deve ser utilizado como única ferramenta de análise de um processo.

O objetivo de um modelo deve ser o de auxiliar seu usuário, fornecendo informações extras, e não substituí-lo como tomador de decisões, especialmente no caso de decisões de investimento que, como vimos, podem depender de inúmeros fatores.

Acreditamos que este trabalho pode servir como ponto de origem à vários outros.

Dentre os trabalhos futuros que visualizamos, podemos destacar elaborar um algoritmo para otimizar a escolha dos valores iniciais dos parâmetros do HMM.

Construir novas estruturas para a cadeia de Markov do HMM, e verificar se estas melhoram sua capacidade preditiva.

Estudar em mais detalhes as características de diferentes Wavelets, a fim de determinar qual delas é a mais adequada para se utilizar na suavização da série de preços do petróleo.

Fazer uma análise de sensibilidade mais completa dos elementos do HMM, para se identificar, com maior precisão, sua configuração ideal.

Existe um novo tipo de HMM, chamado de HMM hierárquico, no qual o processo de emissão de símbolos é governado por uma cadeia de Markov, ao invés de uma simples distribuição de probabilidades.

Assim, cada estado oculto da cadeia contém, dentro de si, uma outra cadeia de Markov, que é responsável pela emissão dos símbolos.

Uma cadeia como esta foi, recentemente, utilizada por para prever a taxa de perda de pacotes na Internet, observada por uma aplicação de transmissão de voz em tempo real.

Seu objetivo, ao utilizar este tipo de cadeia, foi capturar, com a cadeia oculta, os estados de longo prazo das perdas e, com as cadeias hierárquicas (que se encontram dentro de cada estado oculto), as variações de curto prazo nas estatísticas de perda.

Entendemos que um modelo como este é perfeitamente plausível de ser utilizado com séries financeiras.

A exemplo de, poderíamos tentar capturar, com os estados ocultos, as tendências de longo prazo da série e, com as cadeias hierárquicas, a dinâmica de curto prazo em cada um destes estados.

Uma distribuição Phase-Type (PH) consiste em uma mistura de distribuições exponenciais, e é caracterizada por uma cadeia de Markov finita absorvente 1.

O número N de fases da distribuição é igual ao número de estados transientes2 da cadeia associada ao processo.

A distribuição PH é utilizada para representar variáveis aleatórias que medem o tempo decorrido até que o estado absorvente da cadeia seja atingido.

Assim, uma distribuição PH é definida pelo vetor pi = P, 1 = i = N, que representa a probabilidade do processo ser iniciado no estado i, e pela matriz onde T é uma matriz (N × N) que representa as transições entre os estados transientes, e t é o vetor (N ×1) que contém o valor das transições dos estados transientes ao absorvente.

T e t estão relacionados pela equação t = T 1.

Uma cadeia de Markov é dita absorvente se contém um estado absorvente.

Um estado é classificado como transiente se a probabilidade de nunca se retornar a ele, após tê-lo deixado, é maior que zero.

Logo estado absorvente não é transiente.

Ilustra alguns exemplos de cadeias de Markov que representam distribuições PH.

Uma discussão mais detalhada sobre esta classe de distribuições, assim como suas propriedades.

A técnica de uniformização foi proposta por Jensen, em 1953.

Seu objetivo é transformar uma cadeia de Markov de tempo contínuo em uma cadeia de Markov análoga, de tempo discreto.

Isto é de grande utilidade pois, em muitos casos, o cálculo de diversas medidas de interesse é muito mais simples de ser feito em cadeias de tempo discreto, do que em cadeias de tempo contínuo.

A seguir, descrevemos esta técnica.

Em X,a probabilidade de se transicionar para o estado Sj, dado que houve uma transição partindo de Si, é aij = qij/qi, e o tempo médio de permanência no estado Si é exponencialmente distribuído com taxa qi.

Agora considere as seguintes transformações em cada estado Si de X, é criada uma transição recorrente, ou seja, que permite a cadeia transicionar de Si de volta a Si, é definida uma nova taxa de saída = qi para o estado Si, de modo que, após permanecer um tempo exponencialmente distribuído com taxa em Si, a cadeia faz uma transição (para o mesmo, ou para outro estado).

Em X i, as probabilidades de se transicionar de Si para Sj, dado que ocorreu uma transição Sj 6= Si, são idênticas as observadas na cadeia X.

Além disso, é possível demonstrar que, em ambas as cadeias, as distribuições do tempo total de permanência em um mesmo estado também são as mesmas.

Este fato pode ser verificado da seguinte maneira, suponha que a cadeia X i encontre-se em Si, e que, a partir deste estado, ela tenha realizado n transições de volta ao mesmo estado, antes de deixá-lo pela transição n+1.

Como vimos anteriormente, a cada transição, a cadeia permanece um tempo em Si, que é exponencialmente distribuído com taxa.

Portanto, a distribuição do tempo total de permanência em Si é dada pela soma de n distribuições exponenciais independentes e identicamente distribuídas, o que, por sua vez, define uma distribuição do tipo Erlang.

A função está condicionada ao fato de que conhecemos o número n de transições feitas ao mesmo estado.

Para encontrarmos a distribuição geral, basta descondicioná-la, multiplicando-a pela probabilidade de terem ocorrido n transições.

Conforme vimos a probabilidade de terem ocorrido n transições consecutivas a um mesmo estado é dada por uma distribuição geométrica, com parâmetro p, onde p é a probabilidade de se deixar o estado.

Assim, teremos que ou seja, a distribuição do tempo total de permanência em Si é exponencial com taxa qi.

Assim, verificamos que as cadeias X e X i são equivalentes.

Ao invés de escolhermos uma taxa para cada estado, podemos escolher uma única taxa = max(qi) e fazer as mesmas modificações descritas acima, gerando a cadeia X.

Deste modo, estaremos uniformizando as taxas exponenciais que descrevem o tempo até a ocorrência de uma transição em X.

É possível provar que ambas as cadeias X e X são equivalentes.

Para uma descrição mais completa do método, sugerimos.

Apesar de a cadeia X ter uma estrutura discreta, ela ainda é uma cadeia cont ínua, uma vez que o tempo decorrido até uma transição sua é exponencialmente distribuído com taxa.

Como sabemos, o modelo com o qual trabalhamos nesta disserta ção é discreto, e, portanto, a princípio, não podemos utilizar X diretamente.

No entanto, como os dados que utilizamos para gerar a cadeia X são discretos4, estamos interessados em fazer uma descrição do tempo pelo número de transições.

Assim, se uniformizarmos X com a taxa = 1 (isso implica que max(qi) = 1), podemos ignorar o conceito de tempo contínuo em X, e utiliza-la, diretamente, como uma cadeia discreta Xd.

Estatisticamente, X, X e Xd são equivalentes.

Nesta seção, mostramos os resultados obtidos pela metodologia de previsão proposta, para diferentes configurações do modelo HMM.

Conforme dito, foi a partir desta análise empírica que escolhemos os valores de N, M, V, t e T do modelo HMM.

As Tabelas a seguir apresentam os resultados alcançados pelas diferentes configurações avaliadas, para duas janelas de previsão distintas, 20 e 30 dias.

Para cada uma, realizamos 101 ensaios distintos, cada um contendo valores iniciais de p e A diferentes dos demais.

Devido à sensibilidade observada no desempenho do modelo com relação aos valores iniciais dos seus parâmetros, decidimos avaliar cada configuração pelas seguintes métricas, taxa de acerto média (valor médio observado para a estatística Dstat), variância da taxa de acerto, probabilidade de Dstat.

Probabilidade da rentabilidade da metodologia ser maior que a do mercado (ou seja, ser superior a estratégia Buy-and-Hold), probabilidade de se auferir rentabilidade negativa, e o 90 percentil da rentabilidade.

As duas primeiras métricas citadas no parágrafo anterior indicam tanto o desempenho esperado ao se adotar a configuração quanto sua variabilidade.

Observando-as, é possível fazer uma rápida avaliação de cada alternativa.

A terceira métrica indica a probabilidade de, adotada àquela configuração, se conseguir uma taxa de acerto significativa.

Escolhemos o valor desta taxa como 57% pois observamos ser este o limite inferior que garante que a rentabilidade do modelo seja superior a do Buy-and-Hold.

A quarta métrica mostra o desempenho da configuração quanto a sua rentabilidade, quando comparada a rentabilidade do mercado.

A quinta indica a probabilidade de o investidor ter perdas ao adotar o modelo.

Por fim, a sexta nos permite comparar, entre si, os melhores modelos (em termos de rentabilidade) de cada configuração (no caso, os 10% melhores).

Observando os resultados da análise feita, apresentados nas tabelas a seguir, fica evidente a diferença de qualidade entre as configurações do HMM.

Por exemplo, se compararmos as configurações apresentadas, podemos notar a superioridade da primeira em relação a segunda, tanto em termos da taxa média de acerto, quanto em termos da rentabilidade obtida.

