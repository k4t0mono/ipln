O maior problema na manipulação de grandes cadeias de Markov é a explosão do espaço de estados.

O formalismo SAN (Stochastic Automata Networks) propõe uma alternativa para descrever modelos Markovianos em um formato mais compacto e eciente, utilizando uma estrutura de armazenamento baseada em álgebra tensorial chamada de Descritor Markoviano, ou simplesmente Descritor.

Um dos avanços na área de métodos numéricos foi o algoritmo Shue para execução eciente da multiplicação vetor-descritor.

Um novo método para realizar a multiplicação vetor-descritor foi proposto, e em muitos casos reduz o custo computacional.

As vantagens, limitações e o impacto na área são discutidos através de reais modelos SAN.

Existe uma grande variedade de técnicas de avaliação de desempenho atualmente, porém para cada situação especíca pode ser mais vantajoso utilizar uma ou outra abordagem, buscando resultados mais efetivos em termos de avaliação de desempenho.

Dentro deste contexto, a maior diculdade para desenvolver ferramentas de software que manipulam cadeias de Markov, principalmente de grande porte, vem da explosão do número de estados que freqüentemente ocorre quando certos modelos têm seus parâmetros aumentados.

A classicação de um modelo como sendo de grande porte, ou como chamamos, com um grande espaço de estados, depende principalmente dos recursos computacionais disponíveis para resolvê-lo no estágio atual de desenvolvimento das tecnologias.

Quando o Algoritmo de Embaralhamento (ou Shue) foi proposto, as máquinas apresentavam aproximadamente 100 MB de memória e 2 GB de disco, então um modelo com estados era considerado um grande modelo.

Hoje, contamos com máquinas de 4 GB de memória e 80 GB de disco aproximadamente, logo resolvem-se modelos com até 10 8 estados.

O que realmente importa é que com o formalismo de redes de autômatos estocásticos consegue-se resolver e armazenar modelos com uma ou duas ordens de grandeza a mais do que com Cadeias de Markov, considerando que o tipo de armazenamento utilizado é o de matrizes esparsas tradicionais.

Com isto, o formalismo (Stochastic Automata Networks) veio para propor uma alternativa para manter os requisitos de memória gerenciáveis, permitindo que modelos em Cadeia de Markov possam ser descritos de uma forma mais compacta e eciente, basicamente porque sua estrutura de armazenamento é baseada em um formato esparso, utilizando operações da álgebra tensorial.

Este formalismo possui, então, soluções numéricas eficientes que tiram proveito também da estrutura de armazenamento.

Devido ao fato de que o uso de técnicas de modelagem que se utilizam de álgebra tensorial, principalmente para avaliação de desempenho de sistemas paralelos e distribuídos, facilita a descrição dos sistemas e minimiza os requisitos de memória, existe um conjunto de estratégias e procedimentos numéricos que buscam também minimizar o custo computacional em termos de operações a executar.

Uma das vantagens do formalismo de Redes de Autômatos Estocásticos em relação a outros formalismos é justamente sua capacidade de fornecer uma descrição compacta da matriz de transição (gerador infinitesimal) da Cadeia de Markov correspondente ao modelo em SAN.

Essa descrição compacta, chamada de Descritor Markoviano, evita problemas de armazenamento relativos à explosão do espaço de estados, já que o descritor nunca é expandido em uma única grande matriz.

Mesmo assim, os principais alvos das SAN ainda são os modelos com grandes espaços de estados, pois apesar dos métodos iterativos serem os mais adequados para resolvê-los, ainda é possível obter melhores resultados em termos de tempo de processamento na execução destes métodos.

A multiplicação de um vetor de probabilidades pelo gerador infinitesimal Q (denominada Multiplicação Vetor-Descritor), é uma das operações fundamentais realizadas pelos métodos iterativos.

O objetivo principal deste trabalho é investigar alguns fatores relevantes para a otimização da multiplicação vetor-descritor, no intuito de melhorar o desempenho deste procedimento, tirando proveito da forma compacta do descritor SAN armazenado.

É importante salientar que a busca por otimizações nas multiplicações manterá o tempo computacional gasto na geração do descritor, bem como os custos de memória até hoje constatados.

Logo, a proposta é estudar o método de solução baseado na multiplicação vetor-descritor, buscando formas de acelerar esta multiplicação por um vetor de probabilidades, ou seja reduzir o seu custo computacional (número de multiplicações realizadas).

O estudo de um novo método, chamado de Método do Fatiamento (ou Slice), sob o aspecto de eficiência computacional, e a experimentação com problemas reais, torna-se essencial para atestar sua aplicabilidade.

Além disto, esta pesquisa tem como objetivo fornecer subsídios teóricos para futuros trabalhos, tanto na área de avaliação de desempenho, como em aplicações de outras áreas.

Este trabalho foi dividido em oito capítulos incluindo introdução e conclusão.

Os quatro primeiros exceto esta introdução, descrevem as bases teóricas anteriores a esta dissertação.

No Capítulo 2 é feita uma conceituação do formalismo SAN, explicitando suas características para modelagem e solução de problemas da realidade, ressaltando as formas de representação disponíveis utilizando noções de sincronismo e paralelismo.

No Capítulo 3, uma revisão de álgebra tensorial clássica e generalizada é feita abordando algumas de suas principais propriedades.

No Capítulo 4 são abordados aspectos relativos ao formato compacto de armazenamento do modelo SAN (baseado na soma de produtos tensoriais), formalmente chamado de Descritor Markoviano.

No Capítulo 5 é apresentado o procedimento de multiplicação vetor-descritor, destacando seus algoritmos e etapas envolvidas nesta multiplicação, bem como o custo computacional verificado na execução do mesmo.

Nos demais capítulos estão as principais contribuições originais obtidas ao longo desta dissertação.

No Capítulo 6 apresenta-se um estudo relativo a possibilidades não efetivas de otimização do procedimento de multiplicação vetor-descritor destacando suas vantagens e os fatores limitantes que levaram cada abordagem estudada a ser descartada.

No Capítulo 7, uma nova técnica de decomposição em fatores normais é introduzida no âmbito da multiplicação vetor-descritor, destacando as vantagens e particularidades desta abordagem, bem como será mostrada uma comparação entre os custos computacionais verificados.

Finalmente, na conclusão são tecidas as considerações nais a respeito da alternativa de otimização proposta bem como os resultados obtidos e trabalhos futuros relacionados.

O formalismo de Redes de Autômatos Estocásticos (SAN) é baseado em Cadeias de Markov e tem propiciado, desde o seu surgimento nos anos 80 com Plateau, uma forma mais compacta e modular para a descrição de sistemas complexos e com grandes espaços de estados a serem modelados.

Logo, este formalismo é capaz de manter o poder de modelagem que se tinha com a utilização de Cadeias de Markov, porém propõe um novo formato para a mesma, cujo principal objetivo é eliminar problemas como o da explosão do espaço de estados.

É interessante ressaltar que toda SAN pode ser representada por um único autômato estocástico que contém todos os estados possíveis do sistema.

Esse único autômato corresponde à Cadeia de Markov equivalente ao modelo SAN.

O princípio do formalismo SAN é a possibilidade de descrever um sistema complexo dividindo-o em subsistemas quase independentes, pois estes podem interagir ocasionalmente.

Neste sistema, cada subsistema é modelado por um autômato, ou seja, por um conjunto finito de estados e por um conjunto finito de transições entre estes estados.

A denominação de estocásticos atribuída aos autômatos neste formalismo, deve-se ao fato de que o tempo é tratado como uma variável aleatória, que na escala de tempo contínua obedece uma distribuição exponencial.

Nas próximas seções serão expostos alguns conceitos relacionados às SAN onde poderemos observar como esta abordagem, dita modular, permite também descrever primitivas de paralelismo e sincronismo, possibilitando a descrição de sistemas atualmente ditos complexos.

O formalismo SAN utiliza-se das noções de estado e de transições entre estados para representação dos eventos, assim como as Cadeias de Markov.

Porém estes eventos podem estar relacionados a um único autômato, ou a vários ao mesmo tempo, ocorrendo de acordo com taxas especícas.

O estado individual de cada autômato é chamado de estado local.

Já o estado global de uma SAN é definido como a combinação de todos os estados locais de cada autômato componente da SAN.

Existem duas possibilidades de representar eventos que são disparados em mais de um autômato, ou que dependem do estado de outros autômatos para realizar uma determinada transição.

As ligações existentes entre os estados são chamadas de transições, e estas podem ser de diferentes tipos.

Vejamos um exemplo de rede de autômatos estocásticos que modela um sistema através de dois autômatos.

O autômato A (1)com três estados (D, A e S) e o autômato A (2)com dois estados (I e O).

Observando o modelo, pode-se notar diferentes tipos de transições entre os estados.

Estas transições existentes em cada autômato podem ser divididas em transições locais e transições sincronizadas.

As transições apresentam eventos associados para que possam ocorrer.

Logo eventos locais e sincronizantes estão associados a estas.

No exemplo, os eventos locais recebem a denominação li e os sincronizantes são chamados ei.

As transições locais alteram o estado global pela mudança de um estado em apenas um autômato, enquanto as transições sincronizadas alteram o estado global da SAN pela mudança de estado em dois ou mais autômatos simultaneamente.

A vantagem das transições locais é permitir que os autômatos tenham comportamentos paralelos através de eventos locais, ou seja, elas mudam somente o estado local do autômato em que ocorreram e não têm interferências por parte dos estados dos outros autômatos.

Apesar de os eventos serem ditos independentes, eles são disparados um de cada vez, pois em uma escala de tempo contínua não ocorrem dois ou mais eventos ao mesmo tempo.

As transições sincronizadas permitem que seja representado um certo sincronismo no disparo de transições entre os autômatos, constituindo eventos sincronizantes entre os mesmos.

Sua ocorrência se dá simultaneamente em todos os autômatos envolvidos, pressupondo a existência de um autômato mestre, que coordenará a sincronização.

Tem-se então um ou mais autômatos escravos, estes disparados pelo mestre correspondente.

Para cada evento sincronizante têmse a denição de um único autômato mestre, sendo as transições, nos demais autômatos, do tipo escravo.

Cabe salientar, que um autômato pode ser mestre de um determinado evento sincronizante e, ao mesmo tempo, escravo em relação a outro.

O conceito de mestre/escravo facilita a compreensão dos modelos quanto à sincronização entre os autômatos, mas não há a necessidade de defini-los na modelagem.

O autômato representado, tem cada um dos seus estados como uma dupla de estados locais de cada autômato.

A conguração deste sistema a cada instante denirá seu estado global.

Da mesma forma, levando em consideração a SAN, o estado global é dado pela combinação de todos os estados locais de cada um dos dois autômatos constituintes da mesma.

Os eventos sincronizantes representam as possíveis interações existentes entre os autômatos, cujas taxas de ocorrência são, muitas vezes, constantes.

Porém, existe outra forma de representar estas interações, utilizando taxas e probabilidades funcionais.

Um outro tipo de denominação para as transições locais e sincronizadas é que ambas podem ser chamadas de transições funcionais.

Isto ocorrerá quando suas taxas não forem constantes, ou seja, tem-se uma função do estado local de outros autômatos da SAN, avaliada conforme os estados atuais do modelo.

Logo, as taxas funcionais podem ser colocadas tanto em transições locais como em transições sincronizadas (no autômato mestre), e estas podem ser definidas por funções que reetem a avaliação dos estados atuais da rede de autômatos estocásticos.

Por exemplo, se no autômato A (2) quiséssemos representar uma transição local funcional (dependente do estado interno do autômato A (1), teríamos, por exemplo, a denição de uma função f.

Temos então duas taxas de transição distintas para o evento l4, que dependem do estado em que se encontra o modelo.

Como se pode notar, o uso de transições funcionais é uma primitiva poderosa do formalismo SAN, permitindo a representação de comportamentos complexos de forma bem mais compacta, a princípio em termos de modelagem.

Outra possibilidade dentro do formalismo é que para cada modelo pode-se denir uma função de atingibilidade, que em poucas palavras, é uma função booleana que determina os estados atingíveis do modelo dentro do espaço total de estados.

Esta função definirá, então, o espaço de estados atingível do modelo SAN.

Quando esta for igual a 1, signica que todos os estados do modelo são atingíveis.

Normalmente, isto não é o que acontece na prática, pois em exemplos da realidade facilmente identicamos condições para que determinados eventos ocorram ou não, dentre estas o estado de outros autômatos.

Isto quer dizer que provavelmente quando estas condições não forem cumpridas alguns estados globais terão probabilidade nula ou quase nula de ocorrerem.

Para o exemplo mostrado podemos supor que quando o A (1)estiver no estado A, o autômato A (2)deve estar no estado I, ou se o A(1)estiver no estado S, o autômato A (2) deve estar no estado O, por exemplo.

Da mesma maneira que se dene uma função de atingibilidade ou mesmo probabilidades funcionais, as funções de integração podem ser definidas.

Estas funções são definidas para obtenção de resultados numéricos sobre o modelo SAN, avaliando qual a probabilidade do modelo SAN encontrar-se em determinado estado.

As funções de integração podem ser definidas de forma a avaliarem a probabilidade do modelo estar em um conjunto de estados considerando um vetor de probabilidades que contém as probabilidades de o modelo encontrar-se em cada estado pertencente a ele, obtendo-se assim índices de desempenho e conabilidade do modelo.

Como pode-se notar, todas as funções são modeladas da mesma forma no formalismo SAN, apesar de serem empregadas diferentemente.

Dentre os métodos iterativos aplicados à resolução das SAN pode-se destacar o método de Arnoldi, GMRES e o método da Potência implementados na ferramenta PEPS.

Nestes métodos, a operação básica é a multiplicação de um vetor de probabilidades por uma matriz, ou seja, a cada iteração é gerada uma seqüencia (k) de valores aproximados do vetor de probabilidades estacionárias que devem convergir para a solução.

Logo o número de iterações torna-se um fator relevante na verificação do custo total de aplicação destes métodos.

Neste trabalho o foco de estudo será a busca de alternativas de otimização para o Método da Potência em especial, visto que eventualmente as melhorias poderão ser também aplicadas aos demais métodos iterativos citados.

A otimização deste método, no caso especíco das SAN, pode em teoria contribuir com a redução das etapas realizadas na multiplicação vetor-descritor.

O princípio básico deste método é, através da multiplicação de um vetor de probabilidades por uma matriz de probabilidades P, obter o vetor solução ou auto-vetor, isto se considerarmos que a matriz P estará elevada no 1, ou seja, = (0)P 1.

Normalmente, as soluções dos métodos iterativos, como é o caso do método da Potência, são obtidas através de aproximações constantes, onde uma solução é considerada satisfatória somente se obedece a algum critério de tolerância estabelecido.

Este critério pode ser observado através da diferença entre as iterações anteriores e a atual iteração.

Desta forma, a solução esperada é (n), e para sabermos seu valor é necessário conhecer o valor de (n1), e assim sucessivamente.

Portanto, para o cálculo do vetor de probabilidades estacionárias (n), considera-se o esquema iterativo descrito genericamente por (n) = (n1) P.

No caso das cadeias de Markov o elemento j de (k)é igual à probabilidade do processo estar no estado j no k-ésimo passo de iterações.

No âmbito da multiplicação vetor-descritor necessária para solução de modelos SAN, considera-se P uma dada matriz de transição Q, que deve estar normalizada (aqui representada como Q), somada a uma matriz identidade I.

Além disto, pode ser um vetor de probabilidades inicialmente equiprovável, ou um vetor inicializado com probabilidades pré-definidas segundo algum critério.

A solução que buscamos neste caso é um vetor de probabilidades normalizado, onde a soma de seus elementos é igual a 1.

Considerando que um descritor SAN é um gerador infinitesimal dado por estacionária de uma SAN é simplesmente a resolução deste sistema linear.

Neste caso, com matrizes de transição.

Neste esquema de iterações demonstrado na Equação, tem-se o termo que representa uma matriz de probabilidade (denominada matriz P anteriormente).

A única operação em que as matrizes estão envolvidas é na multiplicação por um ou mais vetores.

Estas operações não alteram a forma da matriz e do seu armazenamento compacto, o que minimiza os requisitos de memória para armazenamento da matriz, sendo assim ideal para realizar a multiplicação.

Considerando que no caso da resolução das SAN as matrizes envolvidas são usualmente grandes e esparsas, o espaço requerido em memória normalmente é bastante considerável.

No próximo capítulo é feita uma revisão das propriedades da álgebra tensorial, tendo em vista que formalmente, as SAN são descritas através de álgebra tensorial clássica e generalizada utilizando-se da denição de dois operadores matriciais básicos, soma e produto tensoriais.

Estes operadores são a base da descrição formal das redes de autômatos estocásticos.

São apresentados a seguir os conceitos de Álgebra Tensorial Clássica e de Álgebra Tensorial Generalizada.

A primeira seção introduz os conceitos de Álgebra Tensorial Clássica (ATC) e cita suas principais propriedades.

Na segunda seção introduz-se a Álgebra Tensorial Generalizada (ATG) citando as propriedades relevantes para o formalismo.

O produto tensorial de duas matrizes A e B, de dimensões, respectivamente, é uma matriz de dimensões.

Essa matriz pode ser vista como uma matriz constituída de 1 2 blocos, cada um de dimensão.

A denição de cada um dos elementos da matriz resultante é feita levando-se em conta a qual bloco o referido elemento pertence e a sua posição interna dentro desse bloco.

Neste exemplo, o elemento c53 (c53 = a21b23) encontra-se dentro do bloco e sua posição interna neste bloco.

O produto tensorial C = A B é definido algebricamente pela atribuição do valor aijbkl ao elemento de posição do bloco.

Essa representação dos elementos da matriz correspondente ao produto tensorial induz uma relação de ordem sobre os elementos c, que é a ordem lexicográca das duplas de índice.

O produto tensorial de uma matriz quadrada por uma matriz identidade é um caso particular do produto tensorial, denominado fator normal.

Com uma matriz quadrada A e uma matriz identidade In (de dimensão n), dois fatores normais são possíveis (A In) e (In A) sendo n igual ao número de linhas e colunas da matriz.

O produto tensorial de duas matrizes identidade é um outro caso particular do produto tensorial.

O resultado é uma matriz identidade cuja dimensão é igual ao produto das dimensões das duas matrizes.

A soma tensorial é denida somente para matrizes quadradas, ao contrário do produto tensorial, que é definido para quaisquer matrizes.

A soma tensorial de duas matrizes quadradas A e B é denida como a soma (convencional) dos fatores normais das duas matrizes segundo a fórmula.

A soma tensorial C = AB é denida algebricamente pela atribuição do valor aijkl +ijbkl ao elemento de posição do bloco.

O operador produto tensorial tem prioridade sobre o operador soma tensorial e os dois operadores tensoriais têm prioridade sobre os operadores tradicionais de multiplicação e adição de matrizes.

A álgebra tensorial generalizada é uma extensão da álgebra tensorial clássica, e tem como principal objetivo permitir a utilização de objetos que são funções discretas sobre linhas de uma matriz, trabalhando-se com um ou mais elementos passíveis de avaliações diferentes, ou seja, tem-se uma matriz que pode ter diferentes instâncias.

A diferença fundamental da ATG com relação à ATC é a introdução do conceito de elementos funcionais.

Entretanto, uma matriz pode ser composta de elementos constantes (pertencentes a R) ou de elementos funcionais.

Um elemento funcional é uma função real dos índices de linha de uma ou mais matrizes3.

Um elemento funcional b é dito dependente da matriz A se algum índice de linha da matriz A pertencer ao conjunto de parâmetros desse elemento funcional.

Por abuso de linguagem, denomina-se parâmetro de um elemento funcional toda matriz da qual o elemento funcional é dependente.

Uma matriz que contém ao menos um elemento funcional dependente da matriz A é dita dependente da matriz A.

Os parâmetros de uma matriz são a união dos parâmetros de todos seus elementos funcionais.

A notação denida na seção 31 continua sendo válida para as matrizes constantes (matrizes sem elementos funcionais).

As matrizes com elementos funcionais, denominadas matrizes funcionais, são descritas com o uso da notação.

Os elementos da matriz A variam em função dos elementos da matriz B por isso a denominação A(B), ocorrendo o mesmo para a matriz B, onde seus elementos variam em função da matriz A, ou seja, B(A).

O produto tensorial generalizado C = A(B) B(A) é definido algebricamente pela atribuição do valor aij(bk)bkl(ai) ao elemento c.

Na próxima seção veremos que a vantagem do formalismo SAN em relação aos outros, concentra-se principalmente na sua capacidade de fornecer uma matriz de transição (gerador infinitesimal da Cadeia de Markov correspondente ao modelo global) através de uma descrição amplamente compacta e ecaz na busca de soluções numéricas.

Essa descrição compacta é chamada de Descritor Markoviano, cujo detalhamento é feito no Capítulo 4 deste trabalho.

Uma das vantagens do formalismo SAN em comparação a outros formalismos, como citamos anteriormente, é a capacidade de fornecer uma descrição compacta da matriz de transição (gerador infinitesimal) correspondente à Cadeia de Markov associada ao modelo completo.

Esta descrição compacta é chamada de Descritor Markoviano.

O descritor Markoviano é uma fórmula algébrica que pelo intermédio de uma fórmula matemática descreve, a partir das matrizes de transição de cada autômato, o gerador infinitesimal da cadeia de Markov associada à SAN.

Primeiramente é necessário que se entenda como pode-se obter a matriz de transição correspondente a um determinado autômato estocástico.

Considerando a cadeia de Markov descrita, a matriz de transição Q é uma matriz quadrada de ordem nQ igual ao número de estados da cadeia de Markov, neste caso, nQ = 4 (estados A, B, C e D respectivamente).

Cada linha e cada coluna de Q é associada a um estado segundo a ordem lexicográca dos mesmos.

Logo, no exemplo dado, a primeira linha e a primeira coluna correspondem ao estado A, a segunda linha e a segunda coluna correspondem ao estado B, a terceira linha e a terceira coluna correspondem ao estado C, e a quarta linha e quarta coluna ao estado D.

Os elementos de uma matriz Q (qij) são as taxas de disparo correspondentes às transições do autômato estocástico que se está representando, transições do estado associado à linha i para o estado associado à coluna j.

Obtendo-se os elementos não-diagonais de Q, os elementos da diagonal principal devem ser definidos de forma a ser nula a soma dos elementos em cada uma das linhas da matriz.

A diagonal expressará o ajuste necessário para que a soma de todos os elementos de cada linha seja igual a zero.

Portanto, os elementos da diagonal principal serão necessariamente negativos ou nulos.

Na fórmula, Q é a matriz de transição ou gerador infinitesimal da cadeia de Markov correspondente a uma SAN.

A partir do vetor, pode-se obter mais informações sobre o sistema modelado, pois trata-se do vetor solução, considerando-se uma escala contínua de tempo.

Este vetor é um vetor de probabilidades que associa uma probabilidade i a cada um dos n estados da cadeia de Markov.

Por intermédio deste vetor é possível obter-se os resultados estacionários do sistema modelado.

Existem basicamente duas maneiras dos autômatos estocásticos interagirem, ou uma transição que ocorre em determinado autômato não afeta os estados de outros autômatos, ou uma transição dispara outras em autômatos diferentes.

As transições cujas taxas dependem somente do estado do próprio autômato e não de outros autômatos, são transições locais.

As taxas das transições sincronizadas, no entanto, que modicam e dependem do estado de outros autômatos, podem ser tanto funcionais quanto constantes.

Devido a estas características, as SAN podem ser tratadas separando-se as transições locais e tratando-as através da soma tensorial, que representa a independência entre os vários módulos que compõem a SAN, incorporando também a soma de dois produtos tensoriais adicionais, relativos aos eventos sincronizantes modelados na SAN.

Estes últimos representam a dependência (sincronização) dos módulos.

O descritor Markoviano é descrito através de operações tensoriais entre matrizes, as quais são denominadas tensores neste caso.

Os tensores representam as transições locais ou sincronizadas entre os estados de cada autômato.

Um descritor Markoviano é expresso então em duas partes, uma parte local, que corresponde às transições locais, e uma parte sincronizante, que corresponde a todos os eventos sincronizantes do modelo.

As álgebras tensoriais clássica e a generalizada são utilizadas para a representação destas transições locais e sincronizadas, como também para a representação das taxas funcionais e/ou constantes de uma SAN, como veremos nas seções seguintes.

A parte local é definida por uma soma tensorial das matrizes locais de cada autômato.

Sabendo disto, e considerando a SAN descrita, vejamos como são descritos os seus eventos locais.

Uma matriz de transição local será associada a cada um dos autômatos.

A matriz de transição Q do autômato equivalente à rede de autômatos estocásticos é dada, em parte, pela soma tensorial das matrizes de transições locais.

Portanto, uma matriz de transição local agrupa todas as taxas de eventos locais do autômato.

Se esta SAN apresentasse apenas eventos locais, o gerador do autômato equivalente a este modelo (Q) seria simplesmente equivalente à soma tensorial1 das matrizes de transição locais.

É relevante salientar que a soma tensorial correspondente a parte local do descritor é uma soma de produtos tensoriais diferenciada.

Uma possível interpretação dos eventos locais é considerá-los um caso particular de eventos sincronizantes, onde somente um autômato é afetado.

Isto signica dizer que os demais autômatos serão representados por matrizes identidade.

É necessário descrever também os eventos sincronizantes deste modelo, visto que os eventos locais foram descritos anteriormente.

Para cada evento sincronizante descreve-se um par de matrizes (para cada autômato da SAN), uma delas descreve a ocorrência do evento sincronizante (positiva), e a outra (negativa) descreve o ajuste diagonal correspondente a cada taxa descrita na matriz de ocorrência.

Os eventos sincronizantes normalmente são definidos através de um autômato mestre e de um ou mais autômatos escravos, podendo também existir autômatos que não sofrem inuência de determinados eventos sincronizantes.

As matrizes positivas e negativas correspondentes aos autômatos que não são inuenciados por um determinado evento sincronizante serão matrizes identidade, pois não ocorrerá nenhuma mudança de estado nestes autômatos em decorrência de tal evento.

A matriz positiva correspondente ao autômato mestre contém a taxa de disparo de um dado evento sincronizante e.

A existência de probabilidade associada a uma transição tem por efeito a multiplicação da taxa correspondente pela probabilidade.

As matrizes positivas dos autômatos escravos contêm uma taxa de disparo igual a um.

Vejamos a parte sincronizante positiva da SAN considerando o autômato A (1) mestre para os eventos sincronizantes e1 e e2 modelados.

As matrizes de ajuste diagonal, ou matrizes negativas, possuem elementos nulos e não-nulos, sendo que os não-nulos somente aparecem na diagonal principal se existirem.

Somente a matriz negativa correspondente a um autômato mestre pode apresentar taxas negativas.

As matrizes negativas dos autômatos escravos contêm uma taxa de disparo igual a um.

Estas taxas aparecerão sempre nas diagonais principais das matrizes de ajuste diagonal, sejam no autômato mestre ou no escravo.

A cada evento sincronizante, correspondem dois produtos tensoriais, um produto das matrizes positivas e outro das matrizes negativas.

Como podemos observar até o momento, o descritor é, em resumo, o somatório da soma da parte local com a parte sincronizante para cada autômato.

As transições funcionais não trarão modicações estruturais no descritor, apenas a utilização de produtos tensoriais generalizados3 será necessária.

Como podemos notar, é possível construir uma matriz global que representa completamente um sistema, porém na abordagem SAN esta matriz nunca é gerada.

Isto porque, nas SAN, são geradas matrizes individuais para cada componente combinadas com as informações referentes às interações entre estes em um descritor Markoviano, através da soma de produtos tensoriais.

Conclui-se que esta abordagem mantém os requisitos de memória em limites gerenciáveis e evita a explosão do espaço de estados, devido ao seu formato compacto.

No próximo capítulo veremos como é realizado o procedimento de multiplicação de um vetor por um descritor Markoviano no cálculo das soluções numéricas dos modelos SAN, no âmbito de métodos numéricos iterativos.

Os principais alvos das SAN são os problemas com grandes espaços de estados, sendo os métodos iterativos os mais adequados para resolvê-los pois aproveitam as características das técnicas de armazenamento esparsas e não requerem tanta memória quanto os métodos diretos.

A multiplicação de um vetor de probabilidades, que nesta seção chamaremos de v, pelo gerador infinitesimal Q é uma das operações fundamentais realizadas pelos métodos iterativos.

Diferentes formas de armazenar o gerador e o vetor de probabilidades podem ser utilizadas no intuito de executar este produto ecientemente como veremos a seguir.

Neste capítulo trataremos das particularidades envolvidas na execução desta especíca operação de multiplicação.

O algoritmo da multiplicação de um vetor por um produto tensorial (Algoritmo de Deslocamento, ou simplesmente Shue), será apresentado conforme as referências, sendo previamente necessário estabelecer algumas denições sobre seqüencias finitas de matrizes.

Apesar de não ter recebido inicialmente esta denominação, o mesmo vem sendo recentemente denominado como tal.

Para calcular a multiplicação de um vetor v pelo termo NN Q é necessário e suciente saber como multiplicar um vetor por um fator normal.

Sabe-se que um fator normal é um caso especíco de produto tensorial entre uma matriz Q e uma matriz identidade I.

A partir destas denições o formato do descritor Markoviano pode ser reescrito na forma descrita, que representa as matrizes de transição necessárias para descrever uma SAN, mostrando a representação de seu descritor Markoviano.

O vetor v deve ser multiplicado pelo primeiro fator normal, o resultado é multiplicado pelo segundo fator normal, e assim por diante, até o último dos fatores normais.

Isto é possível graças à propriedade de associatividade da multiplicação (convencional) de matrizes.

Além disto, a propriedade da comutatividade entre fatores normais permite a multiplicação de fatores normais em qualquer ordem.

O caso mais simples de multiplicação de um vetor por um produto tensorial é quando as matrizes não apresentam elementos funcionais, apenas constantes.

De acordo com a propriedade de decomposição de produtos tensoriais abaixo, todo produto tensorial de N matrizes é equivalente ao produto de N fatores normais.

Como para calcular a multiplicação de um vetor pelo descritor Markoviano de uma SAN é necessário saber multiplicar um vetor por um fator normal, temos por exemplo três matrizes A (1), A(2)e A(3)e o produto tensorial entre estas.

Quando estas fórmulas tem que ser transformadas em um algoritmo é necessário entender a melhor maneira de tratá-las.

Agora, cada um dos termos da fórmula pode ser tratado de forma independente pelo algoritmo de multiplicação.

Nas próximas seções abordaremos como funciona o algoritmo de Deslocamento para a multiplicação do vetor v por cada tipo de fator normal.

Devido à associatividade do produto tensorial, a matriz Inleft Q (N) é uma matriz de blocos diagonais, onde cada bloco é simplesmente a matriz Q (N).

Os blocos podem ser tratados de forma independente, pois existem nleftN blocos da matriz e cada qual será multiplicado por diferentes partes do vetor.

O tamanho de cada parte seccionada do vetor (chamadas de zin) corresponde à nN.

O vetor é dividido conforme nleftN.

Dentro de um loop, em cada iteração considera-se apenas uma parte do vetor para multiplicar.

O algoritmo para esta multiplicação, apresentado na página 31, realiza a secção das partes do vetor v, com tamanho nN cada uma, multiplicando-as por Q (N).

O resultado da realização da multiplicação de cada vetor zin pela matriz é armazenado em um outro vetor auxiliar denominado zout de mesmo tamanho de zin, que é acumulado em v após o término das multiplicações.

Na seção anterior observamos o procedimento de divisão do vetor v em partes a serem multiplicadas independentemente.

O vetor zin é preenchido com blocos sucessivos de tamanho nN.

Para o primeiro fator normal, ao contrário, a permutação necessária em v para formar os vetores zin, equivale a percorrer o vetor buscando um elemento a cada nright1 elementos.

Representa este processo.

A razão desta permutação pode ser compreendida observando o formato da matriz Q.

O algoritmo divide o vetor v em partes de tamanho nright1 e forma seus vetores zin conforme nright1.

As posições que comporão cada vetor auxiliar zin são retiradas do vetor v de forma não-contígua, pois a matriz Q (1)apresenta elementos espalhados na diagonal e em outras posições.

O armazenamento dos resultados no vetor v é realizado de forma análoga à extração dos elementos, apenas utilizando um vetor auxiliar zout como anteriormente, para armazenamento das multiplicações.

O Algoritmo 52 demonstra este procedimento.

Os outros fatores normais (do segundo fator normal ao último fator normal) são tratados com a combinação das duas etapas precedentes.

A técnica básica consiste em aplicar a propriedade da pseudo-comutatividade do fator normal.

As multiplicações são feitas de acordo com a posição da matriz Q.

O Algoritmo 53 resume a multiplicação de um vetor v por um produto tensorial.

Neste algoritmo os fatores normais são tratados do primeiro ao último.

Entretanto, de acordo com a propriedade da comutatividade dos fatores normais, outra ordem pode também ser aplicada.

O Algoritmo divide o vetor v em partes de tamanho ni e forma seus vetores zin de tamanho n.

As posições que comporão cada vetor auxiliar zin são retiradas do vetor v de forma não-contígua também.

O armazenamento dos resultados no vetor v é realizado de forma análoga à extração dos elementos, apenas utilizando um vetor auxiliar zout como anteriormente.

Nesta seção veremos as etapas constituintes do procedimento de multiplicação vetor-descritor passo a passo, para um modelo SAN definido, por exemplo, através de três autômatos.

Basicamente a multiplicação do vetor v pela parte local do descritor ocorrerá com os seguintes termos, sendo Q o descritor correspondente à descrição das transições locais de cada autômato.

Cada termo será multiplicado pelo vetor v, que é inicializado previamente.

O resultado de cada multiplicação será acumulado em um vetor auxiliar w.

Após realizar as três multiplicações referentes a estes termos o valor resultante acumulado no vetor w é atribuído novamente às posições de v.

Para cada evento sincronizante ei, ocorre a multiplicação do vetor v pelo seu descritor correspondente.

Supondo a existência de três eventos sincronizantes (e1, e2 e e3), a multiplicação pelo vetor v terá as operações.

Note que a multiplicação pela parte sincronizante se dá tanto para a parte positiva quanto para a parte negativa, portanto o procedimento acima é realizado duas vezes.

Ao final destas multiplicações o vetor auxiliar w conterá os resultados numéricos referentes a multiplicação do vetor v pelo descritor Markoviano do modelo.

Esta seção descreve alguns fatores que devem ser observados durante a ocorrência de elementos funcionais em um termo tensorial.

Devido à ocorrência deste tipo de elementos, este é chamado de termo tensorial generalizado.

A multiplicação de um produto tensorial generalizado pode ter maneiras distintas de ser realizada devido ao tipo de dependências funcionais existentes entre as matrizes.

De acordo com a propriedade de decomposição de matrizes em fatores normais de produtos tensoriais generalizados, sempre é possível obter uma ordem para multiplicar os fatores normais de um termo se e somente se não há ciclos no grafo de dependências funcionais.

A existência de tais ciclos não permite a utilização direta desta propriedade.

A multiplicação de um vetor v por um produto tensorial é realizado de maneira similar ao caso sem elementos funcionais.

Duas modicações são feitas na multiplicação implementada pelo Algoritmo, para calcular a ordem onde um dos fatores normais deve ser multiplicado.

Para avaliar os elementos funcionais das matrizes antes de suas multiplicações.

Relembrando que de acordo com a propriedade de decomposição em fatores normais dos produtos tensoriais generalizados, o fator normal da matriz Q sempre deve preceder os fatores normais das matrizes Q, por exemplo, os fatores normais das matrizes que dependem do autômato A.

Isto dene a ordem parcial entre os fatores normais.

Para certos produtos tensoriais a ordem de decomposição não necessariamente é única.

Por exemplo, se duas matrizes da seqüencia são constantes, uma das matrizes será certamente tratada antes da outra não importando qual.

Isto se dá devido ao fato de que o produto de fatores normais de duas matrizes constantes é comutativo.

A regra geral é que duas (ou muitas) matrizes não tendo dependências funcionais diretas ou indiretas estão livres para mudar de posição para serem multiplicadas.

Esta regra generaliza a ausência de uma ordem precisa para multiplicação de fatores normais de um produto tensorial clássico (casos sem funções).

Quando, por outro lado, existem dependências funcionais diretas ou indiretas, a ordem das matrizes deve ser corretamente definida.

A ordem de multiplicação destas matrizes será regida pelas dependências funcionais existentes entre estas.

A ordem de multiplicação destas matrizes também será regida pelas dependências funcionais existentes entre estas, e como podemos notar a ordem de dependência já está devidamente estabelecida.

Um dos casos mais evidentes onde ocorrem ciclos é produzido por A(B) B(A).

Para este caso não existe uma propriedade que permite a direta decomposição em fatores normais.

Entretanto é possível aplicar a propriedade de decomposição em produtos tensoriais clássicos.

Com a propriedade abaixo os casos com ciclos de dependências podem ser transformados, de forma a não mais apresentarem esta característica.

Segundo Fernandes, Plateau e Stewart, o custo computacional envolvido no produto de um vetor por um termo tensorial pode ser obtido observando-se o número de multiplicações vetor-matriz executadas.

Para cada iteração i do algoritmo são executadas nlefti nrighti multiplicações vetor-matriz com matrizes de tamanho ni.

Supondo que as matrizes Q estão cheias, o número de multiplicações para cada produto vetor-matriz é igual a (ni).

Porém se as matrizes Q são armazenadas em um formato esparso, o número de multiplicações para cada produto vetor-matriz é, freqüentemente, inferior a (ni).

Neste caso, se nzi é o número de elementos não nulos de uma dada matriz Q.

Neste caso teremos um custo computacional equivalente à ordem do número de elementos não nulos da matriz resultante.

Na prática, considerando que para obter as soluções estacionárias dos modelos SAN é necessário multiplicar um vetor de probabilidades pelo Descritor Markoviano completo do modelo.

Neste capítulo apresenta-se três alternativas estudadas para a otimização da multiplicação vetor-descritor que não foram efetivas para o propósito estabelecido.

Apesar disto serviram como base para a elaboração de uma nova alternativa, pois permitiram um estudo mais direcionado e prospectivo a respeito do tema.

A primeira alternativa baseia-se especicamente na avaliação do resultado obtido ao utilizar a potenciação direta dos termos a serem multiplicados pelo vetor de probabilidades.

A segunda alternativa explora algumas propriedades da álgebra tensorial clássica em busca da redução dos produtos tensoriais.

Nesta alternativa questiona-se a criação de matrizes de permutação funcionais no intuito de adequar os termos à aplicação de uma das propriedades selecionadas.

A última alternativa não efetiva trata da verificação do custo computacional de realizar-se multiplicações ordinárias entre as matrizes de cada produto tensorial.

Nesta opção experimenta-se variações do posicionamento das matrizes em cada termo.

Como uma primeira alternativa de otimização da multiplicação vetor-descritor pensou-se em explorar as características do método da Potência tentando reduzir o passo das iterações que são realizadas até a convergência do método, utilizando-se da potenciação direta dos termos envolvidos.

Poderia-se aumentar o passo das iterações, reduzindo assim o tempo global gasto, por exemplo substituindo duas iterações por uma única iteração.

Para isto se faz necessária a potenciação do termo (Q + I), ou seja, elevando-se este termo ao quadrado previamente às iterações, é possível que se reduza pela metade o número de passos a serem executados, acelerando o processo de multiplicação.

No entanto, o custo de cada passo também pode ser aumentado, visto que no caso das SAN é necessário manter a estrutura tensorial da matriz Q.

Adicionalmente, é necessário levar em consideração que a potenciação de uma soma como (Q + I) resulta em um produto notável dado por (Q) + 22 Q I + I, que terá mais termos que o termo original.

Considerando a estrutura do descritor Markoviano e os passos realizados na multilpicação vetor-descritor, pode-se fazer duas análises sobre os termos envolvidos, uma sobre a parte local do descritor Markoviano, onde temos somas de fatores normais, e outra sobre a parte sincronizante, formada por produtos tensoriais.

A utilização deste recurso, de elevar-se ao quadrado a soma tensorial, em teoria denota o aumento de operações a serem realizadas, pois ao invés de uma única soma de dois fatores normais, passa-se a ter uma soma de três termos, sendo dois deles fatores normais e um outro formado pela multiplicação convencional de dois fatores normais por um escalar.

Entretanto, na prática, existem formas de reduzir o número de operações realizadas visto que basicamente todos os termos apresentam operações que são repetidas nos demais termos.

Segundo a propriedade citada na Equação 311, teremos o produto convencional de termos do tipo (MIN).

Um fator importante é que a operação pode ser realizada uma única vez e seu resultado armazenado para que seja reaproveitado pelos outros cálculos.

Ou ainda, pode-se calcular M 2 uma única vez e IN, realizando o produto.

Da mesma forma, segundo a propriedade citada na Equação 311, teremos o produto convencional de termos do tipo (IM N).

Neste caso, da mesma forma que com o primeiro termo, pode ser realizada a operação (IM N) uma única vez e seu resultado armazenado.

Analogamente, como sugerido no primeiro termo, calcula-se N 2 uma única vez e IM, realizando o produto tensorial IM N.

Para o segundo termo o cálculo se resume em multiplicar os resultados previamente calculados para os demais termos, o que não é um procedimento muito custoso, além de também realizar sobre este resultado o produto convencional por um escalar.

A aplicação da potenciação nesta parte do descritor markoviano pode ser considerada uma alternativa válida, visto que a única diferença em relação à execução tradicional da multiplicação vetor-descritor é o uso das matrizes M 2 e N, cuja potenciação acrescenta apenas operações de multiplicação clássica entre matrizes, uma para cada matriz envolvida.

Na tentativa de reduzir as operações realizadas pelo método da Potência utilizando o recurso da potenciação, pode-se em teoria aumentar o tempo e o custo de processamento, principalmente devido à modicação do termo original que é acrescido de operações de multiplicação convencional.

Para matrizes grandes, isto pode ser muito custoso.

Esta alternativa foi descartada, pois apesar de demonstrar potencial em termos de não comprometer os requisitos de memória (possibilita o reaproveitamento de cálculos), ao propor a potenciação de um produto tensorial, em teoria, denota o aumento de operações a serem realizadas, tornando necessária a execução extra de multiplicações clássicas entre as matrizes envolvidas.

Na próxima seção, uma segunda alternativa trata de verificar propriedades da álgebra tensorial no intuito de reduzir os produtos tensoriais.

A pesquisa realizada para a primeira alternativa de otimização permitiu-nos levantar algumas questões referentes a propriedades da álgebra tensorial que poderiam ser aplicadas na multiplicação vetor-descritor como uma nova tentativa de otimização.

A propriedade que será o foco de pesquisa nesta alternativa de otimização é o caso da distributividade na multiplicação por uma matriz identidade destacada na Equação 311.

Neste caso, verifica-se a possibilidade de executar apenas multiplicações clássicas entre as matrizes envolvidas, posteriormente aplicando no resultado um produto tensorial com uma matriz identidade.

Isto reduziria as operações realizadas no procedimento de multiplicação vetordescritor.

Supondo três matrizes A, B e C e a respectiva multiplicação por um vetor de probabilidades (0), tem-se a multiplicação (0)(A B C).

O resultado obtido é o vetor final da iteração, e pode ser acumulado em um vetor auxiliar denominado nesta seção de.

Estes passos repetem-se até a última iteração (referente ao último fator normal a multiplicar pelo vetor (0)).

Cabe salientar que esses passos referem-se apenas à parte sincronizante positiva da multiplicação vetor-descritor, que a princípio servirá como base para futuras otimizações nas demais partes componentes do descritor Markoviano.

Utilizando a propriedade citada na Equação 63 pode-se teoricamente reduzir as operações a uma única multiplicação clássica de matriz por um vetor, e a realização de um produto tensorial com uma matriz identidade (resultante da multiplicação clássica de outras matrizes identidades).

Mas esta possibilidade encontra alguns obstáculos para sua implementação.

Como sabemos, o produto tensorial quando escrito na forma de fatores normais, faz com que cada termo tenha permutações diferenciadas, guiadas pela posição do descritor no termo.

Por último, quando o fator normal é do tipo Inlef t Q (tem-se como resultado uma matriz de blocos diagonais, onde cada bloco é formado por pequenos blocos, e estes são simplesmente a matriz Q (N).

Logo, conclui-se que a ordem de execução dos produtos tensoriais em cada termo é estritamente relevante para a obtenção da solução.

Neste âmbito, a propriedade destacada na Equação 63 apresenta uma particularidade que não permite sua utilização direta neste caso.

Enquanto na multiplicação vetor descritor temos, por exemplo, termos do tipo I Qi, para a correta aplicação da propriedade os termos só poderiam ser do tipo Qi I, que como vimos anteriormente, o resultado não é igual a I Qi.

O exemplo de multiplicação vetor-descritor a seguir mostra como esta propriedade poderia ser aplicada com algumas adaptações.

Note que o segundo e o terceiro fatores normais devem sofrer alterações para contemplar o formato ideal à aplicação da propriedade citada na Equação 312, pois seria necessário que a multiplicação vetor-descritor pudesse ser totalmente realizada com termos do tipo Q.

Entretanto sabemos que não obteremos os mesmos resultados nas duas execuções, pois os termos envolvidos nas operações serão tratados diferentemente.

Diante disto, duas maneiras foram pesquisadas para contornar este problema.

A primeira delas sugere alterar o algoritmo existente para cálculo da multiplicação do vetor (0) por fatores normais, de forma que a utilização das variáveis nleft e nright, presentes nos algoritmos originais, garanta a execução das permutações necessárias sobre as matrizes.

Esta alternativa foi descartada devido ao interesse em explorar as propriedades da álgebra tensorial generalizada na busca de outra alternativa, utilizar matrizes de permutação para modificar cada termo que não for do tipo Q I para este formato.

Estas matrizes de permutação chamaremos de Pi e devem permutar os termos da maneira apropriada, ou seja, cada termo da multiplicação vetor-descritor terá o formato Q I após a aplicação das permutações.

Uma matriz de permutação é uma matriz que possui somente um elemento (não nulo e igual a um) por linha e por coluna.

Segundo a propriedade da pseudo-comutatividade do produto tensorial, estas matrizes de permutação quando aplicadas à esquerda de uma matriz qualquer, representam um reordenamento das linhas desta matriz.

Da mesma forma, quando aplicadas à direita, representam um reordenamento das colunas.

Neste caso, tem-se a seguinte equivalência, considerando PB Ta matriz transposta da matriz P B.

A utilização destas matrizes de permutação (Pi) permite que os termos sejam alterados para que seus elementos quem no formato Qi In.

Neste formato, experimentações foram realizadas tentando-se aplicar a propriedade para obtenção de ganho em relação ao tempo de processamento.

O próximo passo foi buscar na Equação 67 algumas variações, considerando a associatividade da multiplicação clássica.

Mais uma vez os testes realizados demonstraram que a utilização de matrizes de permutação inuencia nesta característica não mais sendo possível realizar as multiplicações em ordem distinta.

Supondo-se o vetor equiprovável, ou seja, um vetor com as posições inicializadas com o valor 0,125 (já que o mesmo apresentará, neste exemplo, oito posições), após a realização da multiplicação, conforme a Equação 67, obtém-se o seguinte vetor solução.

Ao tentar-se modificar a ordem de multiplicação, os resultados não mais continuaram corretos, pois as matrizes de permutação em teoria devem somente serem multiplicadas pelas matrizes que modicam.

Uma outra alternativa de associatividade destas matrizes, teve como resultado o vetor esperado, mas com os elementos permutados.

Portanto, através destes exemplos verifica-se a não compatibilidade com a propriedade da associatividade da multiplicação clássica quando trata-se da multiplicação por matrizes de permutação.

Apesar disto, o uso destas matrizes para tentar modificar o formato dos termos presentes na multiplicação vetor-descritor clássica, torna-se essencial para aplicar a propriedade da Equação 63 vista anteriormente.

Um fator relevante a ser considerado é como poderiam ser armazenadas as matrizes de permutação, visto que em problemas onde a ordem das matrizes é grande, as matrizes de permutação tendem a serem maiores ainda, pois sua ordem é dada pela ordem da matriz resultante de sucessivos produtos tensoriais, como vimos em exemplos anteriores.

Uma alternativa foi modelar as matrizes de permutação também como produtos tensoriais.

Dadas as matrizes A e B (ambas de ordem n=2 por exemplo), e o procedimento de multiplicação vetor-descritor com utilização de matrizes de permutação, a idéia é substituir uma grande matriz P i por um produto tensorial entre N matrizes.

O produto tensorial de duas matrizes constantes C e D não torna possível a representação de uma matriz de permutação, pois como sabe-se, estas matrizes têm a particularidade de que N é o número de matrizes que compõem o produto tensorial a permutar, logo em um produto tensorial A B teremos cada matriz de permutação representada pelo produto tensorial entre outras duas matrizes.

Cada linha ou coluna apresenta apenas um elemento não nulo.

Então estas matrizes necessariamente devem ser compostas por elementos funcionais, ou seja, funções serão avaliadas durante a execução do produto tensorial e retornarão o valor correspondente a cada elemento da matriz de permutação desejada.

Supondo que se queira definir para a matriz de permutação PB do exemplo, as matrizes C e D correspondentes.

Tendo a matriz resultante do produto tensorial entre C e D, e a matriz de permutação B, pode-se gerar funções que definirão cada elemento das matrizes C e D de forma que seu produto tensorial resulte na matriz de permutação desejada.

O uso de produto tensorial generalizado, dá-se devido à inevitável utilização de funções para definir os elementos das matrizes C e D.

A palavra st é utilizada nas funções para denotar a avaliação do estado de uma dada matriz, este significando a linha ou coluna dos blocos (ou dentro dos blocos) em que a função deve ser avaliada.

Logo, com a ocorrência de dependências funcionais entre estas matrizes, tem-se PB dada por C(D) D(C).

Note que PB T é a matriz transposta de PB, entretanto são as mesmas matrizes, pois ambas contêm os mesmos elementos, nas mesmas posições.

Utilizando-se matrizes de permutação funcionais não se pode armar que o mesmo acontece, pois ao transpormos uma matriz funcional os elementos nas duas matrizes passam a retornar valores diferentes, obviamente porque as avaliações ocorrerão em posições trocadas.

Sabendo que as matrizes ditas Pi T quando descritas no formato de produto tensorial generalizado têm as mesmas funções que a matriz Pi no mesmo formato, não será necessário demonstrar como estas são formadas, tendo em vista que não há necessidade de transpor os elementos funcionais.

Para o caso PB T = C0 D0, não há necessidade de indicarmos diferenciadamente as matrizes componentes deste produto, pois tem-se que PB T = C D.

Entretanto, estas definições dadas a PB são válidas apenas quando se tem um termo como I A B = PB (B IA) PB T, ou seja, quando temos o produto tensorial entre duas matrizes.

Os elementos na matriz resultante correspondem à multiplicação entre um elemento cij da matriz C e um elemento dkl da matriz D.

Logo, uma forma de generalizar a geração das matrizes de permutação em formato tensorial também deve ser estudada, para que estas possam ser geradas para o caso de um produto tensorial entre N matrizes.

Tentativa de Generalização do Uso das Matrizes de Permutação.

No caso do produto tensorial de duas matrizes, ambas de ordem n=2, gerou-se a seguinte multiplicação, como vista anteriormente na Seção 622, juntamente com as matrizes de permutação funcionais C e D.

Em um exemplo com três matrizes de ordem n=2 (A, B e C), a matriz de permutação gerada apresentará então o produto tensorial de três matrizes (D, E e F), cujos elementos também serão funcionais.

Etapas da multiplicação e as respectivas matrizes envolvidas.

As funções geradas para representação das matrizes de permutação deste exemplo foram as seguintes.

No caso de três autômatos de ordem n=3 (A, B e C), tem-se dois fatores normais a permutar, portanto duas matrizes de permutação distintas.

Através dos exemplos apresentados pode-se perceber uma certa similaridade na formação das matrizes de permutação, o que nos leva a considerar que existe uma maneira de generalizá-las para que, independente do número de matrizes envolvidas, possa-se obter tais matrizes de permutação com facilidade.

Porém, mais testes serão necessários visto que na medida em que o número de matrizes envolvidas aumenta, o número de diferentes termos tensoriais também.

No intuito de otimizar a multiplicação vetor-descritor no contexto de resolução das SAN, o objetivo primordial ao estudar esta alternativa era a obtenção de um único fator normal para cada termo do tipo produto tensorial, ou seja, um fator constituído de um produto tensorial entre uma matriz qualquer, resultante de multiplicações clássicas, e matrizes identidade.

Este único fator normal seria então multiplicado pelo vetor de probabilidades.

Considerando a seguinte estrutura de multiplicação vetor-descritor, o problema encontrado nesta abordagem é que a propriedade da Equação 63 não se verifica completamente para o caso de matrizes de permutação funcionais, ou seja, não há equivalência da propriedade da ATC quando se utiliza ATG na execução dos produtos tensoriais.

Como as matrizes de permutação estão representadas por produtos tensoriais de matrizes funcionalmente dependentes, não é possível decompor os termos da maneira proposta pela propriedade.

Há uma incompatibilidade do produto tensorial generalizado com a multiplicação ordinária de matrizes para o caso de existência de ciclo de dependência.

Logo, um novo passo nesta alternativa de otimização seria tentar descobrir uma nova propriedade dentro da ATG que contemple a utilização de multiplicações ordinárias no produto tensorial.

A partir de testes realizados com matrizes exemplo, vericou-se a incompatibilidade anteriormente provada, mesmo tratando-se de matrizes de permutação.

Dado o produto (C D) (B I) (C D), resultante na matriz I B mostrada abaixo, quando aplica-se a propriedade 63 obtendo a matriz equivalente a (C BC) (DI D) percebe-se a ausência de vários elementos, estes eliminados na execução do produto tensorial em conseqüencia de avaliações erradas sobre os elementos funcionais das matrizes.

DI há efetivamente a troca das linhas da matriz resultante como esperado ao aplicarmos a permutação à esquerda.

Contudo, no produto (BI)(CD) ao aplicarmos a mesma propriedade, tendo (B C) (I D), a troca das colunas não acontece como esperado.

Alguns elementos da matriz resultante são eliminados e outros não cam posicionados corretamente.

Conclui-se que a propriedade da Equação 63 somente pode ser utilizada da seguinte maneira.

Outro fator a considerar é como este formato dado para as matrizes de permutação (através de funções) poderá colaborar para a utilização da propriedade descrita pela Equação 63, pois a idéia principal seria conseguir obter um único fator do tipo produto tensorial que seria multiplicado pelo vetor de probabilidades.

Com os resultados obtidos até o momento, supõe-se que cada termo deste produto tensorial será formado por multiplicações clássicas entre matrizes.

Portanto, apesar de favorecer a otimização da multiplicação vetor-descritor, a propriedade estudada (Equação 63) só será válida se as matrizes envolvidas forem de mesma ordem, pois para o produto clássico entre matrizes isto é obrigatório.

No caso de modelos SAN, trabalhar com matrizes de mesma ordem torna-se uma desvantagem, visto que uma parcela reduzida de modelos apresenta esta característica.

Dentre as alternativas descritas até o momento há em comum o foco na álgebra tensorial, que veio não somente como uma nova forma de representação, mas também para otimizar o modo de armazenamento das matrizes.

Nesta seção, destacaremos a possibilidade de gerar os mesmos resultados obtidos nos procedimentos tradicionais de realização do produto tensorial, porém a partir de uma nova forma de distribuir as operações realizadas para tal.

Nesta alternativa, apesar de ainda utilizarmos propriedades do produto tensorial, as operações básicas serão multiplicações ordinárias entre termos das matrizes envolvidas.

Algumas idéias testadas preliminarmente a respeito da utilização de multiplicações ordinárias entre matrizes especicamente serão abordadas nesta seção, começando por um teste básico de multiplicação entre as matrizes A e B (ambas de ordem n=2), constituintes de um produto tensorial A.

A proposta é tentar descobrir quais multiplicações podem ser realizadas utilizando as matrizes A e B na busca dos elementos resultantes do produto tensorial desejado.

Basicamente pode-se pensar em multiplicar AB para verificação do resultado.

O que temos neste caso é uma matriz também de ordem n=2 com elementos que são somas de dois termos.

Apesar de termos somas em cada elemento da matriz resultante é evidente pensar que existe uma maneira de obter cada um dos termos somados isoladamente, multiplicando por exemplo novamente por uma matriz, que poderia ser chamada de Matriz de Desmembramento.

Esta matriz seria possivelmente definida através de elementos funcionais capazes de desmembrar as somas presentes nas matrizes resultantes das multiplicações ordinárias.

Assim sendo com a multiplicação (AB) é possível obter pelo menos oito termos presentes na matriz resultante R, matriz referente ao produto tensorial em questão.

Para ns ilustrativos, a matriz R representada abaixo apresenta apenas os elementos obtidos nesta primeira multiplicação.

Um fator relevante neste momento é pensar em como obter os demais elementos supondo que é possível efetuar uma operação de desmembramento da soma resultante em cada elemento da matriz AB.

A primeira alternativa é realizar novas multiplicações da matriz A com variações da matriz B.

Por exemplo, podemos inverter linhas e colunas da matriz B e verificar se são gerados outros elementos necessários ao resultado desejado.

Para indicar a matriz B invertida será utilizada a notação B e para indicar a matriz R contendo apenas os elementos obtidos através da multiplicação de AB por uma matriz de desmembramento, será utilizada a notação R.

Como foi possível observar, com as multiplicações clássicas (AB) e (AB), obtivemos todos os elementos presentes na matriz resultante do produto tensorial A B (sendo A e B de ordemn=2), ou seja, através da soma de R e R obteríamos o mesmo resultado obtido ao resolvermos o produto tensorial A B da forma habitual.

Entretanto, se estas apresentarem ordem n=3 não mais este raciocínio pode ser utilizado, pois a matriz B gerará na multiplicação (AB)' elementos já observados na multiplicação (AB).

Pode-se verificar que alguns elementos repetem-se nas duas matrizes resultantes R e R sugeridas (a segunda coluna de ambas as matrizes possuem os mesmos elementos), o que torna-se um problema para utilização desta alternativa, pois seriam necessárias algumas funções específicas para anular os termos repetidos, e além disto, outras multiplicações entre A e variações de B que gerassem os elementos faltantes.

Uma forma de contornar o problema foi realizar operações de inversão parcial da matriz B, ao invés de invertermos as linhas e as colunas simultaneamente.

A inversão parcial é comandada por deslocamentos apenas nas linhas da matriz B, técnica esta que chamaremos de Técnica do Deslocamento (ou Shift).

Note que para isto teremos mais termos de multiplicação além de (AB) e (AB) para um caso de maior ordem4.

Evidentemente com matrizes de ordem n=2 ambas as técnicas funcionam, tendo apenas os dois termos citados acima a resolver.

Dado um produto tensorial A B, a técnica do Deslocamento propõe a realização de operações de multiplicação ordinária entre as matrizes envolvidas (A e B) e uma matriz de desmembramento.

Note que as matrizes de desmembramento são caracterizadas preliminarmente na Seção 63 e sua composição será abstraída na descrição desta alternativa de representação do produto tensorial.

Primeiramente realiza-se (AB), e após operações de inversão parcial ou deslocamentos da matriz B, para cada deslocamento i ocorrerá uma multiplicação da matriz Bi pela matriz A, ou seja tem-se (nA 1) multiplicações do tipo (AB i), onde nA representa a ordem da matriz A.

Estas multiplicações gerarão todos os elementos constituintes de A B.

Exemplificando a utilização desta técnica, tenhamos por exemplo duas matrizes A e B primeiramente de ordem n=2.

Uma matriz de desmembramento quando aplicada sobre o produto AB geraria os seguintes elementos do produto tensorial A B, estes representados em uma matriz R para ns de ilustração.

Na Técnica do Deslocamento será utilizada a notação B1, B2, Bi para os termos de multiplicação, onde a matriz B será invertida parcialmente uma, duas ou i vezes conforme a ordem das matrizes.

Cada deslocamento é comandado por deslocamentos apenas nas linhas da matriz B.

Note que para contemplar todos os elementos que compõem a matriz resultante do produto tensorial A B, serão necessárias nA 1 multiplicações entre A e B i.

Neste exemplo de ordem n=2 será necessário apenas um deslocamento na matriz B, originando o termo (AB 1)'.

Como pode-se notar, com as multiplicações (AB) e (AB 1), conseguimos obter todos os elementos encontrados em A B, estes ilustrados em R e R 1.

Considerando agora, duas matrizes (A e B) de ordem n=3, teríamos os seguintes passos, considerando os seguintes elementos que compõem o produto tensorial A B, quando as ordens nA e nB são iguais a 3.

A Técnica do Deslocamento permitiu-nos explorar um pouco mais as características do produto tensorial em termos de posicionamento dos elementos dentro da matriz resultante e a sua relação com os termos gerados com multiplicações ordinárias entre as matrizes.

Porém, como podemos observar, há um fator limitante na utilização desta técnica, a necessidade de elaborar matrizes de desmembramento, a princípio matrizes funcionais, para que estas realizem o desmembramento das inevitáveis somas que são geradas na execução de produtos clássicos.

Outro fator relevante para estudo é como esta técnica poderia ser estendida para produtos tensoriais entre mais de duas matrizes.

A idéia de utilização de matrizes de desmembramento não se torna tão atrativa quando existe a possibilidade de se obter termos onde as somas são eliminadas na própria execução do produto ordinário entre as matrizes.

Isto se deve ao fato de que poderia-se realizar uma multiplicação de uma matriz A por uma matriz I b ijde ordem nB, composta do elemento bij da matriz B replicado em sua diagonal, e de elementos nulos nas demais posições5.

Considerando um produto tensorial A B (ordem n=2) a idéia básica é obter, através da multiplicação entre A e uma matriz I b ij, os elementos constituintes de um determinado bloco dentro da matriz resultante do produto tensorial em questão.

Algumas tentativas realizadas, como veremos logo abaixo, resultaram na obtenção de elementos em diferentes blocos da matriz resultante, e em posições não aleatórias, pelo contrário, resultaram na disposição dos elementos com um padrão de localização dentro dos blocos da matriz.

Sobretudo, tendo os elementos desejados, um outro fator a considerar é seu posicionamento.

Percebe-se que cada produto A I bij poderia receber a aplicação de um produto tensorial com uma matriz composta de um único elemento não-nulo (com valor igual a 1), exatamente na posição desejada para os elementos no resultado.

Esta matriz chamaremos de Matriz de Posicionamento.

Logo, dado um produto tensorial A B, poderia-se decompor este produto em termos independentes (estes geram blocos de elementos presentes matriz resultante ao produto tensorial).

Neste exemplo, todos os termos são somados a m de obter a matriz resultante do produto tensorial entre as matrizes A e B.

Os índices i e j indicam qual elemento da matriz B está sendo utilizado na formação da matriz I b ij, e também guiando a formação da matriz de posicionamento Iij.

Porém como sabemos, conforme a Seção 512, na multiplicação vetor-descritor, especificamente no algoritmo que realiza o produto de fatores normais com matrizes identidade à direita, o vetor não é dividido em partes, elementos do vetor são utilizados alternadamente.

Para evitar a utilização deste procedimento é necessária a realização de um produto tensorial entre matrizes identidade à esquerda e uma dada matriz.

Os índices i e j indicam qual elemento da matriz A está sendo utilizado na formação da matriz I aij, e também guiando a formação da matriz de posicionamento Iij.

A diferença é mesmo na maneira em que o produto tensorial poderá ser executado de forma facilitada através desta abordagem com termos independentes.

Como visto na Seção 54, a complexidade do produto de um vetor por um termo tensorial pode ser obtida observando-se o número de multiplicações vetor-matriz executadas.

Nesta abordagem, deseja-se demonstrar qual o número de multiplicações vetor-matriz com matrizes de ordem ni são necessariamente executadas.

Supondo que as matrizes Q estão cheias, ou seja, são matrizes plenas.

Porém se as matrizes Q são armazenadas em um formato esparso, o número de multiplicações para cada produto vetor-matriz, considerando que nzi é o número de elementos não nulos de uma dada matriz Q , o custo computacional para realização das multiplicações existentes nesta abordagem para o produto tensorial Qn.

Na prática, considerando que para obter as soluções estacionárias dos modelos SAN é necessário multiplicar um vetor de probabilidades pelo descritor Markoviano completo do modelo.

Comparando-se o custo computacional verificado na abordagem atual de multiplicação vetor-descritor e do custo necessário à execução desta alternativa estudada, compreende-se que da maneira sequencial em que as multiplicações entre as matrizes são realizadas, não há um ganho em termos de número total de multiplicações executadas.

É fato que seqüencialmente esta alternativa não é considerada válida aos propósitos determinados, pois aumentaria consideravelmente o total de operações a serem realizadas.

Apesar disto, foi possível tirar proveito da idéia de buscar multiplicações clássicas que possam gerar os elementos de A B, elaborando uma nova alternativa de execução do produto tensorial entre matrizes.

Esta nova idéia traz a noção de Fatores Normais Parciais que veremos no próximo capítulo.

O procedimento de multiplicação vetor-descritor é a operação básica realizada pelos métodos iterativos utilizados na resolução de modelos SAN.

No intuito de otimizar este método em termos do número de multiplicações realizadas, pesquisas foram direcionadas ao estudo de propriedades da álgebra tensorial e sua aplicabilidade na Decomposição em Fatores Normais clássica, bem como na reestruturação deste tipo de decomposição, originando o que chamaremos de Decomposição Aditiva em Fatores Normais Parciais.

Um novo método para a multiplicação vetor-descritor é proposto a seguir, e é denominado Técnica de Fatiamento, ou simplesmente Slice.

Observando a definição de produto tensorial1, tendo-se C = A B, considerando que a ordem da matriz A é A A, e a ordem da matriz B é B B, tem-se cada elemento c da matriz C dado por aijbkl.

Partindo deste princípio, percebeu-se ser possível realizar uma decomposição diferenciada dos termos tipo produto tensorial, investindo na possibilidade de multiplicar-se os elementos das matrizes uns com os outros, ao invés de multiplicarmos matrizes inteiras, como na abordagem apresentada na Seção 63.

Contudo, no intuito de reduzir as operações na execução da multiplicação de um dado vetor por estes produtos tensoriais, a decomposição em fatores normais foi reestruturada.

Neste capítulo veremos uma nova maneira de decompor o produto tensorial, utilizando o que chamaremos de Fatores Normais Parciais.

Os fatores normais parciais levam em consideração as primeiras (N 1) matrizes componentes do produto tensorial, onde N é o número total de matrizes neste termo, realizando a multiplicação ordinária entre os elementos, de acordo com as propriedades inerentes a esta operação, ou seja, o resultado do produto tensorial é uma matriz constituída de blocos, cada um de dimensão, e para cada elemento desta matriz resultante será constituído um fator normal parcial i.

A definição de cada um dos elementos da matriz resultante é feita levando-se em conta a qual bloco o referido elemento pertence, e qual a sua posição interna dentro desse bloco.

Com isto, os fatores normais parciais podem ser definidos como um conjunto de termos em que realiza-se uma a uma das multiplicações necessárias à execução do produto tensorial, das (N 1) matrizes de cada termo, efetuando o produto tensorial das mesmas com a matriz N, neste caso a matriz mais à direita.

Considerando o exemplo A B C, onde as matrizes têm ordem n=2.

Esta decomposição será chamada Decomposição Aditiva em Fatores Normais Parciais, e para diversos modelos temos um ganho significativo em termos do número de multiplicações realizadas como veremos na próxima seção.

Constitui-se em uma decomposição dita aditiva, pois os termos não são multiplicados como na abordagem tradicional (Equação 71), mas sim somados.

Ao multiplicarmos cada fator normal parcial i pelo vetor de probabilidades, cada resultado é somado em um vetor acumulador, que ao final das multiplicações conterá a solução do modelo.

Na próxima seção, serão especificadas as etapas que constituirão o procedimento de multiplicação vetor-descritor utilizando esta nova técnica.

Posteriormente, serão explanadas as vantagens e limitações da mesma, abordando questões como custo computacional (em termos de número de multiplicações a realizar) em comparação ao método tradicional de multiplicação vetor-descritor.

Diferentes formas de tratar o produto tensorial em termos de operações realizadas, podem ser estudadas no intuito de executar o produto 0 eficientemente.

Sabe-se que no procedimento de multiplicação vetor-descritor atualmente implementado é suficiente saber como multiplicar um vetor por um fator normal.

Nas etapas acima, pode-se ver resumidamente a decomposição do produto tensorial em fatores normais, e a multiplicação de cada fator normal por um vetor de probablidades.

Utilizando a nova decomposição em fatores normais parciais, as etapas da multiplicação vetor-descritor serão descritas diferentemente, propondo um procedimento alternativo e realmente eficiente em muitos casos, a Técnica de Fatiamento ou Slice.

Dadas três matrizes de ordem ni = 2, um vetor de probabilidades (0)de tamanho n=8 (n1 n2 n3), tem-se para este exemplo a denição de (n1 n2) fatores normais parciais, um para cada elemento do produto tensorial A B.

Neste exemplo teremos um total de 16 fatores normais parciais a multiplicar pelo vetor seguindo as mesmas etapas demonstradas acima.

Ao realizar a última multiplicação do vetor (0)pelo 16 fator normal parcial, o vetor de probabilidades conterá a solução do produto tensorial.

Observando o exemplo desta seção, conclui-se que para um produto tensorial entre N matrizes plenas de qualquer ordem, tem-se matrizes esparsas, o número de fatores normais parciais é dado por QiN1 (ni)2 =1 fatores normais parciais.

Se considerarmos as N1 nz, sendo nzi o =1 i número de elementos não nulos da matriz i.

Outro fator a considerar é que devido ao número constante de elementos não-nulos em cada vetor resultante, pode-se em cada fator normal parcial, fatiar o vetor em nN partes a serem multiplicadas pelo elemento alvo da decomposição, sendo devido a isto o nome dado à técnica, Fatiamento ou Slice.

Pode-se com isto reduzir também o custo em memória já que a matriz à esquerda não necessita ser armazenada, bem como os vetores auxiliares podem apresentar tamanho igual a nN.

Sendo N o número de matrizes de um produto tensorial, ni a ordem de cada uma destas matrizes, e nN a ordem da última matriz neste termo, nesta nova abordagem para a multiplicação vetor-descritor, tem-se (para o caso de matrizes plenas) o custo computacional de multiplicar um vetor de probabilidades por cada fator normal parcial.

Na Equação acima temos (N 2) multiplicações ordinárias entre elementos das (N 1) matrizes envolvidas.

Além disto, como para cada fator normal parcial são gerados dois fatores normais tradicionais, para o primeiro fator normal temos nN multiplicações pelo vetor, e para o segundo, nN 2multiplicações.

O número de fatores normais parciais a tratar é dado por todas as combinações de elementos não-nulos das N 1 matrizes iniciais, ou seja custo computacional de tratamento de um produto tensorial nesta alternativa é dado por Qi N1 nz.

Primeiramente, analisaremos casos diversicados de produto tensorial entre matrizes, ou seja, serão combinadas matrizes de mesma ordem, ou de ordens distintas, com variações no total de seus elementos não nulos, desde matrizes plenas até matrizes com alta esparsidade.

As tabelas com os comparativos apresentam as seguintes informações a respeito dos produtos tensoriais.

Ordem, indica a ordem4 de cada uma das matrizes do produto tensorial.

Não-nulos, representa o total de elementos não-nulos em cada matriz do produto tensorial.

É apresentado no mesmo formato de representação das ordens das matrizes.

Shue, apresenta o custo computacional relacionado ao método tradicional.

Slice, mostra o custo computacional estimado para o método alternativo.

Mostra um comparativo entre produtos tensoriais com i matrizes de mesma ordem (ni) e mesmo total de elementos não-nulos (nzi).

Nota-se que tanto nos produtos tensoriais com matrizes de ordem n=3 quanto de ordem n=4, o número de elementos não-nulos determina o custo computacional em ambas as abordagens.

Quando o total de elementos não-nulos é maior do que a ordem das matrizes, observa-se que a técnica tradicional é mais vantajosa em termos de custo computacional, entretanto, na medida em que aumenta a esparsidade das matrizes envolvidas, ou seja, diminuindo o total de elementos não-nulos das matrizes (passando a ser igual ou inferior à ordem das matrizes), a técnica alternativa apresenta um ganho significativo em desempenho.

Mostra um comparativo entre produtos tensoriais com i matrizes de mesma ordem (ni) e com variados totais de elementos não-nulos para cada matriz i (nzi).

Observa-se que na abordagem tradicional o custo computacional é independente da ordenação das matrizes pelo número de elementos não-nulos que apresentam, pois o custo computacional manteve-se constante.

A abordagem alternativa entretanto, depende estritamente da ordenação das matrizes no produto tensorial.

Esta ordenação deve ser realizada colocando-se as matrizes em ordem crescente de seus nzi.

Na verdade, a última matriz da seqüencia deverá ser a de maior nzi.

Quando esta ficar por último no termo tensorial, verifica-se uma redução considerável no total de operações a realizar, não importando, a partir desta ordenação, em que posição estão as demais matrizes.

Através de matrizes com ordens ni diferentes espera-se demonstrar em que condições cada uma das técnicas torna-se favorável para otimização do custo computacional.

Para isto foram mantidos os mesmos produtos tensoriais focando no total de elementos não-nulos de cada uma das matrizes (mantendo o mesmo nzi em cada produto tensorial).

Observa-se que o custo computacional apresentado pela técnica alternativa passa a ser vantajoso em relação ao tradicional no momento em que os produtos tensoriais apresentam matrizes onde o número de elementos não-nulos é inferior à ordem na matriz de maior ni, considerando que as matrizes estão ordenadas do menor para o maior ni.

Através de matrizes com ordens ni diferentes espera-se demonstrar a influência da ordenação destas matrizes, em ordem crescente de seus diferentes elementos não-nulos (nzi), para um melhor aproveitamento das características da nova abordagem.

A técnica tradicional não apresenta alterações no custo computacional simplesmente variando o posicionamento das matrizes.

Com estes dados é possível armar que o melhor desempenho da técnica alternativa está atrelado ao fato de que a última matriz do produto tensorial deve sempre ser a de maior nzi, garantindo-se assim o menor custo computacional possível para esta técnica.

Contudo, existem casos em que o produto tensorial entre N matrizes é dado por uma matriz Q qualquer e N 1 matrizes identidade.

Este tipo específico de produto tensorial chamamos de fatores normais, como vimos anteriormente.

Se considerarmos as duas etapas de multiplicação vetor-descritor, uma da parte local e a outra da sincronizante, observa-se que na primeira contamos somente com termos que são fatores normais.

Este tipo de termo é tratado de forma eciente pelo método tradicional, pois há apenas uma matriz neste produto tensorial que não é identidade.

Utilizar a técnica de decomposição em fatores normais parciais para este tipo de termo não acrescenta melhoria em termos de número de multiplicações a realizar.

Portanto, a decomposição em fatores normais parciais tem como foco o tratamento otimizado de termos referentes à parte sincronizante do descritor Markoviano, já que na técnica tradicional os mesmos passam primeiramente por um processo de decomposição em fatores normais para serem tratados eficientemente.

Nesta seção serão mostrados alguns exemplos modelados com SAN para demonstrar as vantagens de se utilizar a nova abordagem de otimização da multiplicação vetor-descritor, tendo em vista de que as matrizes que compõem cada termo a ser multiplicado pelo vetor são, na maioria das vezes, grandes porém bastante esparsas.

O custo computacional apresentado na Seção 73 refere-se à multiplicação de um vetor por produtos tensoriais, que no descritor Markoviano são encontrados em duas partes distintas, na parte local e na parte sincronizante.

No momento, apenas a parte sincronizante é interessante à nova técnica, lembrando que a parte local do descritor Markoviano é representada por uma soma tensorial de matrizes, sendo possível expressá-la como uma soma de fatores normais, um tipo específico de produto tensorial.

Os algoritmos da técnica tradicional são otimizados para tratar deste tipo de termo, logo o custo na abordagem tradicional nesta análise comparativa é o melhor para esta parte do descritor, o que não descarta a hipótese de serem realizadas novas otimizações sobre o método alternativo, buscando novas soluções também para este tipo de termo5.

Para os exemplos a seguir, levaremos em consideração apenas o custo computacional para realizar a multiplicação do vetor pela parte sincronizante de cada um dos modelos, tendo em vista que neste trabalho assume-se que o custo computacional da parte local é dado pela aplicação da técnica tradicional.

A multiplicação de um vetor de probabilidades (0) pelo descritor Markoviano apresentado no exemplo dado na Seção 412 será analisado agora em termos de custo computacional, onde traçaremos novas análises comparativas entre as duas técnicas abordadas neste trabalho.

Otimizar a multiplicação vetor-descritor alternativa para a parte local do descritor pode ser trivial se pensarmos que nada mais se tem do que uma matriz qualquer multiplicada por matrizes que são identidade, ou seja, a multiplicação ordinária entre os elementos de cada matriz não necessitará ser realizada pois matrizes identidade são matrizes de zeros e uns.

Para cada evento sincronizante ei da parte sincronizante de cada um dos N autômatos, considerando Qe = Q.

Da mesma forma, pode-se calcular o custo computacional da parte sincronizante negativa, para cada evento ei em cada um dos N autômatos do modelo, considerando que cada termo é dado por Qe = Q.

Note que o custo envolvido em resolver um produto tensorial referente a um determinado evento ei na parte negativa é o mesmo custo computacional necessário na parte positiva.

Logo, para cada evento ei pode-se armar que o mesmo deve ser multiplicado por dois.

Para a parte sincronizante do descritor Markoviano do exemplo, temos o seguinte custo computacional total, Custo Computacional Total Tradicional.

Custo Computacional Total Alternativo.

Observa-se que mesmo para um exemplo simples e com poucos eventos sincronizantes, há uma melhoria no número total de operações a realizar neste exemplo.

Cabe salientar, que na solução completa, diversas iterações são necessárias e para cada uma destas iterações haverá um ganho de 4 multiplicações.

Mostra um exemplo de Rede de Filas Aberta (QN), com apenas uma classe de clientes, composta de três filas com as seguintes características.

Uma das filas tem bloqueio para clientes da fila 1 para a fila 2.

Outra das filas da rede apresenta perda de clientes da fila 1 para a fila 3.

As filas têm capacidades 3, 3 e 2 clientes, respectivamente.

É um modelo SAN equivalente a esta Rede de Filas de Espera.

Cada autômato A representa uma fila.

Os estados x de um autômato A indicam o número de clientes na la i.

A chegada de clientes na fila 1, e a sua partida para a fila 2 e fila 3 são representadas por eventos locais (l1, m2 and m3) respectivamente.

Os eventos sincronizantes e12 e e13 representam a passagem de clientes da fila 1 para a 2, e da fila 1 para a fila 3.

A ocorrência do evento e12 determina a mudança de estados nos autômatos A (1)and A (2) simultaneamente.

O evento sincronizante e12 não pode ocorrer quando o autômato A (2)está no estado local 3(2)(fila 2 está cheia).

Este representa o bloqueio da partida de clientes da fila 1 para a fila 2.

A transição extra que ocorre no último estado do autômato A (3) (evento e13) permite a saída de clientes da fila 1 sem que estes necessariamente passem para a fila 3, representando assim uma perda de clientes (fila 3 está cheia).

Para cada evento ei da parte sincronizante de cada um dos N autômatos do modelo, calculou-se os custos computacionais envolvidos para multilpicação destes termos pelo vetor.

Observa-se uma redução do custo computacional ao utilizarmos a nova abordagem de multiplicação-vetor descritor.

Salienta-se que na solução completa cada iteração terá um custo computacional dado pela soma do custo para a parte local mais a sincronizante.

Como dito anteriormente, a parte local a princípio será calculada utilizando o método tradicional.

Neste exemplo o custo computacional para a parte local é 208 multiplicações, logo os custos computacionais totais são 712 e 544 multiplicações, respectivamente.

Neste exemplo, tem-se N processos compartilhando R recursos.

Cada processo é representado por um autômato A , que tem dois estados S (sleeping) e U (using).

Os recursos são representados por um autômato A (N+1) que tem R + 1 estados, indicando o número de recursos em utilização.

Os eventos eai e eri são eventos sincronizantes entre este autômato (A (N+1)) e os autômatos que representam os processos.

Note que este modelo apresenta apenas eventos sincronizantes, logo não há custo computacional relacionado à parte local do descritor Markoviano deste modelo.

Cabe salientar que o custo computacional que será apresentado neste exemplo refere-se exclusivamente à parte sincronizante positiva.

Mostra a modelagem genérica deste problema, mas para ns de cálculo do custo computacional nas duas abordagens da multiplicação vetor-descritor assumiremos que N=20 e R=1, e N=20 e R=12.

Para cada evento sincronizante ei da parte sincronizante de cada um dos N autômatos do modelo, tem-se os custos computacionais associados.

Observe que neste modelo, cada evento sincronizante aparece em um dos autômatos A e no autômato A (N+1), ou seja em apenas dois autômatos, em um total de 21 autômatos.

Logo as matrizes referentes à parte sincronizante deste modelo apresentam alto grau de esparsidade, permitindo comprovar a eciência do novo método nestas condições.

Conclui-se, através dos exemplos mostrados nesta seção, que devido ao fato de existirem matrizes muito esparsas, o custo computacional para a nova abordagem sofreu redução (em termos de número de multiplicações), em comparação ao método tradicional, justicando a utilização desta nova abordagem em casos onde as matrizes apresentam alto grau de esparsidade.

O processo básico do formalismo SAN é a multiplicação vetor-descritor, e dentro deste contexto, buscou-se nesta dissertação, diferentes maneiras de tratar numericamente modelos SAN, de forma a fornecer subsídios para a elaboração de novos métodos que executem este produto ecientemente.

O tratamento numérico otimizado da multiplicação vetor-descritor é de fundamental importância no estágio atual de desenvolvimento das técnicas e ferramentas que manipulam modelos Markovianos em formalismos estruturados (por exemplo, SAN).

Com o aumento gradativo da complexidade dos sistemas, torna-se essencial o aprimoramento das técnicas tradicionais ou mesmo o estudo de novas abordagens na busca da solução estacionária e transiente de tais modelos.

A multiplicação vetor-descritor foi reestruturada em uma nova técnica que chamamos de Decomposição Aditiva em Fatores Normais Parciais, de forma que os produtos tensoriais que compõem o descritor Markoviano pudessem ser decompostos utilizando multiplicações ordinárias entre os elementos das matrizes, reduzindo o custo computacional observado na abordagem tradicional.

Verificando o custo computacional ao utilizarmos a decomposição em fatores normais tradicional, percebe-se que para os casos onde a esparsidade das matrizes é alta, na nova técnica há uma considerável diminuição no número de operações a realizar.

Um fator importante é que cada termo pode ser tratado individualmente, ou pelo Shue, ou pelo Slice, já que o cálculo do custo computacional é simples, podendo este ser avaliado antes do tratamento de cada termo.

Novas otimizações ainda podem ser realizadas tendo em vista que em termos que já são naturalmente fatores normais (como ocorre na parte local do descritor Markoviano), a multiplicação vetor-descritor poderá descartar as multiplicações dos elementos da matriz pela matriz identidade, pois é óbvia a obtenção de sua matriz resultante em termos algorítmicos.

Além disto, se observarmos o formato de decomposição em fatores normais parciais, percebe-se a possibilidade de efetuar o cálculo referente ao segundo fator normal de cada termo parcial uma única vez armazenando seu resultado para a execução dos demais termos tensoriais.

Vimos também que para a nova abordagem é interessante ordenar as matrizes do produto tensorial pelos seus número de elementos não-nulos, de forma que a última matriz do termo seja a de maior nzi.

Isto faz com que hajam ainda maiores reduções no total de operações a serem realizadas.

Em pesquisas recentes destaca-se a possibilidade de resolver modelos (esta técnica inclusive já é implementada) utilizando um método de agregação algébrica de autômatos, que consiste em transformar um modelo SAN com N autômatos, em um modelo SAN com G autômatos, sendo G < N.

Na agregação algébrica, os estados do autômato resultante da agregação representa todas as combinações de estados possíveis e atingíveis dos autômatos que foram agregados.

O espaço de estados resultante é o produto do espaço de estados de cada autômato envolvido, bem como o número de estados atingíveis é o produto dos estados atingíveis de cada autômato agregado.

Esta técnica muitas vezes pode significar o aumento da ordem de cada uma das matrizes, e consequentemente o número de elementos não-nulos.

Para a nova abordagem esta aplicação pode não ser vantajosa, porém cabe aqui salientar a necessidade de novos estudos direcionados ao aproveitamento simultâneo de tais otimizações já conhecidas.

Desta forma, em trabalhos futuros será interessante fazer um estudo comparativo do uso da nova técnica e da tradicional em modelos agregados.

Ainda é possível ressaltar como trabalhos futuros a paralelização da execução destes métodos, ou a elaboração de novas abordagens que contemplem esta característica.

Tendo em vista que a tendência hoje é a distribuição do processamento para execução em paralelo das operações,o custo computacional seria proporcionalmente divido entre os nós de processamento estabelecidos.

A única preocupação seria definir como as operações da multiplicação vetor-descritor poderiam ser paralelizadas sabendo que nos métodos iterativos existe uma dependência intrínseca entre as operações.

Neste sentido, a nova decomposição, por ser aditiva, é mais adequada à paralelização.

Além disto a manipulação de cada termo parcial atua sobre um conjunto reduzido de elementos do vetor de probabilidades, podendo facilitar a sua manipulação em um ambiente paralelo em que seja necessária a comunicação de dados.

Finalmente, é importante salientar que o trabalho desenvolvido nesta dissertação representa um avanção consistente na otimização do tratamento numérico de modelos markovianos estruturados.

Este avanção se dá de forma organizada, pois parte da denição de uma nova propriedade da álgebra tensorial (Decomposição Aditiva em Fatores Normais Parciais).

A sua aplicação prática implica na definição futura de um algoritmo (o algoritmo Slices) que pode trazer uma redução de custo computacional se associado ao tradicional algoritmo Shue.

Além dos ganhos numéricos, este novo método abre a possibilidade de um tratamento ainda mais eciente devido às facilidades de paralelização que decorrem da decomposição em fatores que podem ser adicionados.

