A modelagem analítica pode ser utilizada para prever desempenho, detectar deficiências e avaliar estratégias para melhorar sistemas.

No contexto da modelagem computacional, diversos formalismos para a modelagem analítica estão se popularizando devido ao fato de proverem alto-nível de abstração e modularidade.

No entanto, para inferir estimativas de desempenho destes modelos, é necessário resolver um sistema de equações.

Em modelos analíticos estruturados, tais sistemas não se apresentam na forma tradicional, Ax = b, pois a matriz de coeficientes (A) é trocada por uma expressão algébrica (Q), denominada Descritor Markoviano (ou só descritor).

Logo, a multiplicação convencional, Ax é substituída pela multipicação vetor-descritor (MVD), Qx.

Dois algoritmos foram propostos recentemente para implementar a MVD, shuffle e slice.

Ambos apresentam um alto custo computacional, que eleva drasticamente o tempo necessário para resolver modelos complexos.

O objetivo do presente trabalho está relacionado com a utilização de técnicas de alto desempenho para propor versões mais rápidas, tanto para o algoritmo shuffle quanto para o slice.

A análise de desempenho vem se mostrando util em diversas situações, prever o desempenho de aplicações paralelas, avaliar qualidade de serviços em sistemas distribuídos, etc.

Entretanto, os formalismos para modelagem analítica apresentam limita cões como o tempo necessário para inferir estimativas de desempenho e a alta necessidade¸ de armazenamento à medida que os modelos são complexos.

Os formalismos estruturados constituem em um tipo de modelagem analítica.

Esses se caracterizam por apresentarem uma maneira estruturada e modular de projetar sistemas gerando resultados comprovadamente equivalentes a Cadeias de Markov (CM).

Apesar desses formalismos serem resolvidos da mesma maneira, o mapeamento de modelos analíticos estruturados em uma CM equivalente não é desejado porque exigiria um grande custo de armazenamento.

Por esse motivo, tais formalismos utilizam algoritmos para realizar as operações necessárias na resolução dos modelos.

Atualmente, os dois algoritmos que realizam esta operação, shuffle e slice, apresentam um elevando custo computacional na resolução deste tipo de problema.

Formalismos para modelagem analítica estruturados caracterizam-se por possuírem um Descritor Markoviano (DM ou descritor para abreviar).

Esta estrutura é equivalente a um gerador infinitesimal, uma matriz que armazena as taxas de transição entre os diversos estados de uma CM.

Da mesma maneira que as CMs, a resolução desses modelos é efetuada resolvendo-se um sistema de equações lineares.

Desta forma, a operação central na resolução de modelos analíticos estruturados é a multiplicação de um vetor por uma matriz.

Os algoritmos shuffle e slice manipulam a estrutura do descritor efetuando esta multiplicação, a chamada Multiplicação Vetor-descritor (MVD).

Utilizar máquinas mais potentes para aumentar o desempenho de aplicações é uma técnica que vem sendo constantemente empregada nos dias de hoje.

Atualmente, aglomerados de computadores, do inglês clusters of computers, são atraentes uma vez que são construídos com tecnologias para o consumidor final e consequentemente apresentam uma boa relação custo/benefício.

Essas máquinas estão ganhando popularidade no meio acadêmico onde são utilizadas para pesquisa de ponta nas mais diversas áreas.

O objetivo de realizar a MVD é efetuar a resolução de um sistema de equações lineares, independente do método de resolução empregado (Método de Newton, Método da Potência, etc).

Atualmente, os métodos numéricos mais utilizados para resolver sistemas lineares são conhecidos como métodos iterativos.

O que caracteriza um método iterativo (para resolução de sistemas de equações lineares) é que, a cada iteração, ele se aproxima da resolução do sistema até que atinja um erro mínimo ou um número máximo de iterações.

Todavia, cada uma dessas iterações efetua a multiplicação de um vetor de resultados aproximado por uma matriz de coeficientes.

Logo, a operação da MVD é executada diversas vezes (tipicamente centenas ou milhares de vezes) até que o problema seja resolvido.

Existem diversas situações nas quais é desejado analisar o desempenho de sistemas computacionais, tais como avaliar o desempenho de um novo processador, prever o desempenho de configurações de ambientes e algoritmos, avaliar qualidade de serviço de aplicações distribuídas.

Existem atualmente três técnicas empregadas para avaliar o desempenho nestas situações, bechmarks, modelos de simulação e modelos analíticos.

Benchmarks consistem em uma série de aplicações (de custo elevado em termos de processamento) que deverão ser executadas de forma sistemática para qualificar e quantificar o desempenho de dispositivos específicos.

A modelagem por simulação visa a construção de aplicações que simulem o comportamento de um sistema.

Essa técnica pode ser utilizada para avaliar a qualidade de sistemas como redes de computadores.

Em nosso trabalho, focamos nos métodos analíticos.

A modelagem analítica visa a construção de um modelo que represente a realidade sendo estudada.

Mais precisamente, tais modelos caracterizam-se por agregar diversas informações de transição (representando a interação entre entidades do sistema) e a frequência com as mesmas ocorrem.

Existem diversos formalismos para modelagem analítica, dentre as quais destacam-se Redes de Autômatos Estocásticos, Redes Ativas Estocásticas, Redes de Filas de Espera, Redes de Petri Estocásticas (SPN), Algebra de Processos para Avaliação de Desempenho (PEPA).

O escopo deste trabalho é restrito aos métodos de modelagem analítica estruturados.

Estes métodos caracterizam-se por utilizarem álgebra tensorial para representar, através de uma expressão algébrica, um gerador infinitesimal comprovadamente equivalente a Cadeias de Markov.

A vantagem de utilizar modelos analíticos estruturados envés das Cadeias de Markov está na obtenção de um maior poder de abstração.

Para ilustrar é apresentado um exemplo de Cadeia de Markov que modela dois processos disputando o acesso a um recurso compartilhado.

Cadeia de Markov modelando a disputa de dois processos por um recurso.

Utilizando esse formalismo, somente um módulo é construído onde os estados representam a combinação de um estado de cada entidade do sistema.

Já utilizando um formalismo de modelagem analítica estruturada, como por exemplo o modelo SAN, é possível separar em módulos cada entidade do sistema.

Assim, acrescenta-se poder de abstração uma vez que ambos modelos são equivalentes.

Modelo SAN onde dois processos disputam um recurso.

Os algoritmos para os quais apresentamos alternativas de alto desempenho podem ser utilizados para a MVD independente do formalismo utilizado.

Entretanto, cada formalismo possui técnicas específicas para o armazenamento das estruturas algébricas, e consequentemente desempenhos diferentes.

Este cenário dificulta a elaboração de uma biblioteca de primitivas para realizar a MVD.

O objetivo deste trabalho é empregar técnicas de alto desempenho nos algoritmos shuffle e slice visando acelerar a Multiplicação Vetor-descritor, a operação empregada na resolução de modelos analíticos estruturados.

A plataforma de alto desempenho utilizada para a execução dos testes é um aglomerado de computadores.

Essas plataformas, conhecidas em inglês como clusters, são multicomputadores que compartilham dados utilizando uma rede.

O padrão mais utilizado para a troca de mensagens neste tipo de plataforma é MPI, por tratar-se de um padrão consolidado para a troca de mensagens em multi-computadores, portável, de comprovada eficácia e com ampla documentação disponível.

No capítulo 2, o problema da multiplicação vetor-descritor é apresentado seguido de uma explicação dos algoritmos shuffle e slice utilizados para realizar esta operação atualmente.

No capítulo 3 são apresentadas as estratégias para realizar a MVD em uma plataforma de computação de alto desempenho onde detalhes de escalonamento são for necidos.

A seguir, no capítulo 4, são mostrados como os testes foram realizados e em seguida os resultados para cada um dos algoritmos.

Finalmente, no capítulo 5 algumas conclusões e perspectivas, para trabalhos futuros, são discutidas.

O apêndice A mostra um exemplo de formalismo para modelagem analítica e como o Descritor Markoviano é gerado.

No apêndice B, é apresentada uma descrição gráfica dos modelos utilizados para testar o desempenho das implementações propostas ao longo deste trabalho.

Por fim, no apêndice C, são apresentados os detalhes numéricos dos resultados.

Os formalismos analíticos estruturados caracterizam-se por apresentarem uma forma modular de representar sistemas reais.

Esses formalismos são mais atraentes que Cadeias de Markov por permitirem projetar um sistema grande em pequenas partes independentes, especificando as interações entre cada módulo quando necessário.

Dessa forma, os formalismos conservam as propriedades das CMs de forma que podem inferir as mesmas estimativas de desempenho de um determinado sistema.

O mapeamento de um modelo analítico estruturado em uma CM é realizado utilizando as operações de álgebra tensorial.

Estas operações combinam os estados independentes de cada um dos módulos do modelo de forma a gerar uma estrutura equivalente ao gerador infinitesimal.

O gerador infinitesimal é uma matriz que contém as taxas de transições entre cada um dos estados em um modelo descrito utilizando Cadeias de Markov.

Todavia, como o gerador infinitesimal gerado neste processo é muito esparso, é preferível armazenar as matrizes de forma a minimizar a utilização de memória.

Para tratar este problema, o gerador infinitesimal é então substituído por um Descritor Markoviano (ou somente descritor para abreviar), uma estrutura algébrica que quando resolvida é equivalente ao gerador infinitesimal.

Para resolver modelos descritos utilizando CM, é necessário resolver um sistema de equações lineares.

Ao final deste processo, o vetor solução do sistema conterá informações referentes à permanência em cada estado do modelo.

Em outras palavras, apresentará estimativas de desempenho para o sistema real sendo modelado.

Como os formalismos estruturados apresentam uma equivalência a CM, o método de resolução é análogo.

No entanto, o gerador infinitesimal não existe nestes ultimos, pois é substituído pelo descritor.

Neste ponto a operação de multiplicação do vetor solução pela matriz de coeficientes, que é o gerador infinitesimal em CM, é substituído pela multiplicação do vetor pelo Descritor Markoviano.

E portanto esta operação de multiplicação é chamada de multiplicação vetor-descritor.

A resolução de sistemas de equações lineares é realizada geralmente utilizando-se métodos iterativos.

Métodos iterativos caracterizam-se por aproximarem o vetor resultado do sistema a cada iteração.

Neste caso, o número de iterações necessárias para resolver um sistema varia muito, pois é determinado por um erro mínimo do resultado aproximado ou um número máximo de iterações.

A MVD, é portanto, uma operação que é realizada diversas vezes até que o modelo seja resolvido.

O custo computacional desta operação determina o custo total de resolução de um modelo, quantificado em termos de tempo de processamento, por isso existe um grande apelo para que o custo desta operação seja o menor possível.

Uma vez que a Multiplicação Vetor-descritor(MVD) é uma operação algébrica que substitui a multiplicação de um vetor por uma matriz, torna-se necessário compreender as operações algébricas envolvidas nesta expressão.

Na seção 21, os aspectos relevantes da álgebra tensorial são apresentados, bem como algumas propriedade relevantes para a construção dos algoritmos e consequentemente importantes para compreender a paralelização destes.

Em seguida, na seção 23, os descritores de dois formalismos são apresentados com o intuito de justificar a escolha do formato de entrada escolhido.

Finalmente, na seção 24 os dois algoritmos que realizam a MVD, shuffle e slice, são apresentados de forma a ressaltar os aspectos que permitem distribuir o cálculo.

Para entender como a Multiplicação Vetor-descritor (MVD) é efetuada, é necessário conhecer as operações algébricas que são utilizadas para mapear um modelo analítico em uma cadeia de Markov.

Estas operações são conhecidas como operações de álgebra tensorial clássica ou também por operações de Kronecker.

Apesar do Descritor Markoviano apenas utilizar o produto tensorial, a soma tensorial é frequentemente utilizada e, portanto, se torna relevante para compreensão dos algoritmos que realizam a MVD.

As operações de soma e produto tesorial são definidas entre duas matrizes reais.

Como no contexto dos formalismos analíticos estruturados, estas matrizes são sempre quadradas.

Neste trabalho são apresentadas definições e exemplos para casos que contemplam somente matrizes quadradas.

O leitor interessado em encontrar mais informações sobre a álgebra tensorial pode consultar as referências.

O produto tensorial é uma operação algébrica definida entre duas matrizes reais.

Dado duas matrizes A e B, onde A é uma matriz n1, e B é uma matriz de ordem n2, o produto 1 tensorial entre estas duas matrizes (denotado por A B), gera uma matriz C de ordem n × n, onde cada elemento Ci,j é dado segundo a equação 1.

Nesta equação, x e y são números reais positivos.

Dessa forma a ordem de uma matriz representa o número de linhas e colunas.

O operador unário bxc representa o número inteiro imediatamente inferior a x, e a operação x y calcula o resto da divisão inteira de x dividido por y.

A idéia do produto tensorial é combinar cada elemento da matriz A com cada elemento da matriz B Para ilustrar está idéia observe as matrizes abaixo.

A matriz resultante do produto tensorial entre A e B no exemplo acima.

Repare que esta operação mapeia em cada elemento da matriz resultante o produto de um elemento de A por um elemento de B.

Em outras palavras, o resultado desta operação é uma matriz que contém a combinação de todas as multiplicações possíveis entre elementos das matrizes A e B.

Para ilustrar melhor esta idéia, abaixo é apresentado como a multiplicação de cada elemento aij da matriz A multiplica cada elemento bij da matriz B, gerado ao final do produto tensorial.

A soma tensorial é definida com base no produto tensorial.

Esta operação, dentro do escopo deste trabalho, também recebe como operandos duas matrizes reais quadradas.

Dado duas matrizes A e B, a soma tensorial destas matrizes (denotada por A B), é definida pela equação 2.

Onde, IM denota uma matriz identidade da mesma dimensão 2 da matriz M.

Note que a soma tensorial gera igualmente uma matriz de ordem n1 × n2.

Para ilustrar o cálculo de uma soma tensorial utilizaremos as mesmas matrizes que utilizamos para exemplificar o produto tensorial.

Para este exemplo, a matriz resultante da soma tensorial entre A e B fica a soma tensorial é amplamente utilizada para o mapeamento dos modelos descritos em formalismos analíticos estruturados em cadeias de Markov.

No entanto, é preferível decompor esta operação em produtos tensoriais para homogeneizar o tratamento numérico realizado.

Este aspecto se torna relevante para compreender os algoritmos que realizam a MVD e consequentemente faz-se necessário apresentar como esta decomposição pode ser realizada.

Dada uma série de somas tensoriais com N matrizes, esta propriedade diz que as N somas tensoriais podem ser compostas na soma de N produtos tensoriais.

Para ilustrar está idéia veja o exemplo abaixo.

Generalizando o exemplo acima para uma série de somas tensoriais com N matrizes temos a idéia de um termo produto tensorial (ou somente termo, para abreviar) é representar diversas operações de produto tensorial consecutivas.

Formalmente, um termo composto pelo produto tensorial de N matrizes M1 a MN ficará como na equação 3.

Note que esta operação é bastante parecida com um somatório onde ao contrário de somas as operações realizadas são produtos tensoriais.

Um conceito fundamental para a compreensão da MVD é como o Descritor Markoviano é armazenado.

Dependendo do formalismo utilizado para modelagem, a estrutura algébrica do descritor varia.

Para abstrair os detalhes específicos de cada formalismo, ado tamos o DM como sendo a soma consecutiva de diversos termos produto-tensorial.

Dada uma série de somas de T termos, onde cada termo é composto pelo produto tensorial entre N matrizes, o descritor é apresentado como visto na equação 4.

Neste contexto, é necessário restringir que cada matriz Qi possuirá a mesma ordem, independente do termo k no qual se encontra.

Dessa forma, é possível garantir que cada termo que compõe o descritor resulta em uma matriz, se resolvido, de mesma ordem.

Logo, um descritor composto por T termos com N matrizes cada fica como abaixo.

Note que o símbolo Q (k) não denota potenciação e sim funciona como um índice para o somatório (para fazer esta distinção são utilizados os parênteses).

Durante o texto a expressão Q (k) denota o k-ésimo termo do somatório do descritor.

Para representar o descritor inteiramente, o símbolo Q é utilizado sem índices.

Nesta seção apresentaremos dois exemplos de descritores de dois formalismos analíticos estruturados.

O objetivo aqui é exemplificar como descritores diferentes podem ser manipulado algebricamente gerando uma soma de termos tensoriais como apresentado na equação 4.

Ou, em outras palavras, como os diferentes descritores de cada formalismo podem ser algebricamente manipualdos para a mesma estrutura.

Os dois formalismos abordados nessa seção, Redes de Autômatos Estocásticos (SAN) e Redes de Petri Estocásticas (PEPA), foram escolhidos pela sua popularidade em trabalhos A idéia de uma Rede de Autômatos Estocásticos é descrever um modelo global de um sistema em diversos módulos (subsistemas) independentes entre si, onde as interações entre esses subsistemas podem ocorrer em alguns casos.

Cada módulo independente é definido como um autômato estocástico.

A modelagem de cada autômato é realizada parametrizando-se estados, transições e eventos.

Uma vez que eventos podem representar sincronismo entre dois ou mais autômatos, os dados sobre um modelo são armazenados em matrizes que definem o comportamento local e matrizes que definem o comportamento sincronizante.

O Descritor Markoviano, em SAN, apresenta-se como visto na equação 5.

Nessa equação, N representa o número de autômatos e E o total de eventos que modelam interações entre os autômatos (eventos sincronizantes).

Como pode ser observado, o descritor de SAN representa uma parte descrita como a soma tensorial entre matrizes.

Como apresentando anteriormente, é possível decompor uma série de somas tensoriais aplicando-se a propriedade da decomposição em fatores normais.

Logo, é possível normalizar o descritor de SAN em um descritor que somente possui termos produto-tensorial.

Demonstra como fica o descritor de SAN após a normalização da parte local.

Foge do escopo desse trabalho a apresentação do formalismo SAN em detalhes.

Entretanto, devido à utilização de estudos de caso utilizando este formalismo, no final do trabalho uma explicação mais aprofundada sobre como os modelos SAN são construídos é fornecida no apêndice A.

Redes de Petri Estocásticas (SPN) fornecem uma maneira de modelar sistemas baseados no conceito clássico de Redes de Petri.

De maneira geral, os conceitos existentes em tal formalismo se aproximam dos utilizados em SAN, uma vez que ambos apresentam módulos independentes com pontos de interações específicos.

De maneira análoga a SAN, o descritor utilizando SPN, apresenta-se algebricamente dividido em uma parte local e outra destinada a representar as interações entre módulos (parte sincronizante).

Descritor em SAN normalizado.

Da mesma forma que em SAN, as somas tensoriais do descritor para SPN apresentado na equação 6 podem ser substituídas pela soma consecutiva de diversos termos produto-tensorial resultando em um descritor como o apresentado na equação 4.

Esses exemplos indicam que, em geral, os formalismos de modelagem analítica estruturados podem beneficiar-se das versões dos algoritmos propostos nesse trabalho.

Algebricamente, o problema da Multiplicação Vetor-descritor consiste na multiplicação de um vetor x por um termo algébrico, o descritor, Q.

Formalizando essa idéia, temos a equação 7 substituindo a multiplicação original Ax da matriz de coeficientes pelo vetor.

Atualmente, existem dois algoritmos que manipulam o DM, shuffle e slice.

A geração de uma unica matriz, resolvendo a expressão algébrica do DM, não é desejada pois exigiria um grande custo computacional de armazenamento.

Os algoritmos que realizam a MVD tornam-se necessários para manipular esta estrutura de forma a manter o tamanho ocupado pelo modelo gerenciável em termos de necessidade de memória.

A seguir serão apresentados os princípios básicos dos dois algoritmos que atualmente realizam a MVD.

A demanda por algoritmos que realizassem a MVD de maneira que não fosse necessário resolver o descritor em um gerador infinitesimal fez surgir o algoritmo shuffle.

Inicialmente proposto por diversos autores.

De maneira geral, algumas propriedades da álgebra tensorial são imperativas para a realização da MVD sem incorrer na geração do gerador infinitesimal.

O shuffle se baseia na decomposição de um termo em um produto ordinário de fatores normais, vide equação 8.

Esta propriedade permite que um termo produto-tensorial entre N matrizes seja decomposto na multiplicação de N termos, cada um com N matrizes.

No entanto, após realizada esta decomposição, cada termo apresenta apenas uma matriz com valores originais enquanto todas as outras N1 matrizes são substituídas por uma matriz identidade que conserva a ordem da matriz de mesma posição no termo.

O objetivo de utilizar propriedade é realizar o mapeamento dos elementos de cada matriz no gerador infinitesimal equivalente.

O algoritmo shuffle define os operadores nlefti e nrighti para mapear os elementos das matrizes de um termo no gerador infinitesimal.

O operador nlefti é um operador que dado uma matriz qualquer Qi, de um termo qualquer, realiza o produtório da ordem de todas as matrizes que estão à esquerda de Qi.

No caso da matriz Q1, ou seja, a primeira matriz de um termo, o operador nleft1 por definição resulta em 1, uma vez que não há matrizes à esquerda deste termo.

O operador nrighti se diferencia de nlefti por retornar o produtório da ordem das matrizes que estão à direita de uma matriz Qi.

De forma análoga, este operador é por definição 1 quando a matriz está localizada na extremidade direita de um termo, ou seja, nrightN = 1, para um termo com N matrizes.

Assim, o algoritmo shuffle se baseia na propriedade da decomposição em fatores normais para reescrever cada termo do descritor como visto na equação 8.

O shuffle implementa a multiplicação de cada termo Q(k)utilizando o resultado da decomposição de um termo em fatores normais ordinários.

Para cada matriz de um termo Q, o vetor deve ser multiplicado por esta matriz utilizando os resultados de nlefti e nright com o objetivo de mapear a localização dos elementos da i-ésima matriz deste no gerador infinitesimal.

Multiplicação do ultimo fator normal (nleftN QN nrightN).

Neste caso particular, o operador nrightN é igual a 1 e não representa mudança no resultado do produto tensorial.

Logo, a matriz QN deve ser replicada em nleftN blocos diagonais no gerador infinitesimal.

Entretanto, para as outras matrizes de um termo, esta operação utiliza blocos não contíguos do vetor e, consequentemente, exige a alteração de diversos elementos.

O custo computacional em número de multiplicações de ponto flutuante necessárias para a multiplicação do vetor x por um termo qualquer t.

Onde n é a ordem da i-ésima matriz do termo t e nz corresponde ao número de elementos diferentes de zero na i-ésima matriz do termo t.

O algoritmo slice é relativamente novo e já tem apresentado resultados interessantes na resolução de determinados modelos.

A idéia central neste algoritmo consiste na decomposição dos termos produto-tensorial em pequenas somas algébricas.

Acredita-se que o slice possa aproveitar melhor o poder de processamento de aglomerados de computadores, uma vez que permite a decomposição do problema em menores fatias.

O algoritmo slice é baseado na propriedade da decomposição aditiva.

Esta propriedade demonstra que o produto tensorial consecutivo, entre duas ou mais matrizes, pode ser descrito como a soma da multiplicação de diversas matrizes unitárias.

Esta propriedade é formalizada na equação 10.

O princípio básico do algoritmo slice é aplicar essa propriedade sem considerar a ultima matriz de cada termo.

As outras matrizes do termo são representadas por diversas matrizes unitárias, cada matriz unitária é chamada de Fator Normal Unitário Aditivo (AUNF ou fator para abreviar), essa sigla deriva da nomenclatura internacional, em inglês, Aditive Unitary Normal Factor.

Para gerar os AUNFs, é efetuado o produto tensorial das N1 matrizes de cada termo produto-tensorial.

Por exemplo, supondo um termo produto-tensorial que envolva três matrizes Q1, Q2 e Q3 (Q1 Q2 Q3), a propriedade da decomposição aditiva é efetuada apenas considerando o produto Q1 Q2.

Para exemplificar, supondo que as Q1, Q2 e Q3, utilizando a propriedade da decomposição aditiva todos os elementos das matrizes Q1 e Q2 são multiplicados separadamente para depois serem multiplicados pela matriz Q3.

Este procedimento se diferencia do realizado pelo shuffle principalmente por este mapear apenas a localização da ultima matriz de cada termo no DM.

Para realizar este mapeamento, cada AUNF guarda a informação de linha e coluna onde este estaria localizado na matriz resultante do produto tensorial entre as N1 matrizes mais à esquerda de um termo.

Guardando estes índices, a geração de todos os fatores (AUNFs) só precisa ser realizada uma vez.

Esta técnica, portanto permite que os diversos termos tensoriais sejam desmembrados em pequenas multiplicações.

Em máquinas de alto desempenho, como aglomerado de computadores, essa abordagem apresenta-se bastante atraente uma vez que torna possível considerar cada fator como uma tarefa independente.

Este aspecto diferencia o slice do shuffle principalmente pela quantidade de dados manipulados na multiplicação de cada fator.

Exemplo da multiplicação de um AUNF pela ultima matriz de um termo.

Para ilustrar essa idéia, apresenta um exemplo de multiplicação de um AUNF pela ultima matriz de um termo.

Neste caso, o número de elementos não nulos na ultima matriz do termo (nzN), determina a quantidade de multiplicações que serão realizadas.

No pior caso, onde a ultima matriz do termo, QN, não possui zeros, serão necessárias nN × nN multiplicações.

Atualmente, diversas aplicações utilizam computação de alto desempenho.

O mapeamento do DNA humano, a predição de terremotos, a renderização de imagens para auxílio ao diagnóstico de doenças, são alguns exemplos.

Modelos analíticos apresentam-se de grande aplicação prática.

Estes podem ser utilizados, por exemplo, para modelar e apresentar estimativas de desempenho dos mais diversos sistemas computacionais.

Uma aplicação prática possível, por exemplo, é a utilização para analisar sistemas de rede, auxiliando no diagnóstico de problemas como gargalos e roteadores sub-utilizados.

Os formalismos de modelagem analítica, de maneira geral, apresentam restrições na complexidade dos modelos que podem ser resolvidos por dois motivos, memória e tempo de resolução.

Tipicamente, a quantidade de memória utilizada pelos modelos aumenta à medida que a complexidade destes aumenta.

Atualmente, para mitigar este problema, são utilizados algoritmos que realizam a MVD.

A principal vantagem da utilização destes algoritmos é evitar armazenar o gerador infinitesimal reduzindo drasticamente a demanda de armazenamento.

Em casos não raros, obtém-se uma redução de até 95%.

No entanto, o tempo necessário para a resolução de alguns modelos pode ser um fator limitador.

Em trabalhos recentes, diversas abordagens vêm sendo estudadas, o próprio algoritmo slice neste contexto apresenta avanços significativos.

O presente capítulo mostra como as técnicas de alto desempenho são utilizadas para reduzir o custo de armazenamento e ainda como a MVD pode ser distribuída.

As técnicas aqui empregadas são relacionadas a plataforma de execução pretendida, no caso, um aglomerado de computadores.

Por esta razão a seção 31, recapitula as principais características deste tipo de plataforma, assim como as técnicas de programação consa gradas em tais ambientes.

Para tornar a leitura mais clara, os algoritmos shuffle e slice, são apresentados respectivamente nas seções 33 e 34 separadamente.

Para cada versão de alto desempenho de um algoritmo são propostas duas abordagens de distribuição de carga (escalonamento).

Um aglomerado de computadores (conhecida pela sigla internacional NOW, Network of Workstations) é uma rede dedicada a unir diversos computadores com o objetivo de cooperarem na resolução de problemas complexos.

A conexão das máquinas é realizada utilizando-se uma infraestrutura de rede e software especial.

O que caracteriza a arquitetura de um aglomerado é cada computador possuir seu espaço de endereçamento exclusivo.

Uma vez que a memória não é compartilhada, cada conjunto de dados relevante para o cálculo deve ser atribuído a uma das partições do espaço total de memória existente.

Desta forma, os dados precisam ser explicitamente particionados.

Ao mesmo tempo que essa característica adiciona complexidade na programação ela encoraja o desenvolvedor a explorar a localidade.

Localidade é a características de aproximar o dado relevante ao processamento de cada tarefa do processador que está executando a tarefa.

Trantando-se portanto de uma característica importante para atingir bons resultados em plataformas de alto desempenho.

Uma vez que permite aos processadores explorarem ao máximo o uso de suas memórias cache.

Das características citadas anteriormente surge um fator que deve ser levado em consideração no desenvolvimento de aplicações em aglomerados, sempre que dois processos trocam dados é necessário realizar um processo de sincronização.

O processo de sincronização é realizado utilizando-se primitivas para envio e recebimento de mensagens.

Tais primitivas são a base para o desenvolvimento de aplicações paralelas em aglomerados.

A terminologia troca de mensagens serve para denominar o paradigma utilizado na construcão dessas aplicações.

As soluções de alto desempenho apresentadas neste trabalho utilizam uma plataforma do tipo aglomerado de computadores.

O padrão de comunicação adotado é MPI (do inglês, Message Passing Interface) um padrão consolidado para troca de mensagens em aglomerados de computadores.

Na programação por troca de mensagens são criados diversos processos.

Cada processo sendo designado a um computador.

MPI provê primitivas para cada processo receber um identificador unico e conhecer o número total de processos em uma dada execução.

Um resumo das primitivas MPI utilizadas nesse trabalho e o seu significado é apresentado a seguir.

MPI_Comm_rank, retorna o identificador unico do processo.

MPI_Comm_size, retorna o número total de processos executando a aplicação.

MPI_Send, envia dados para um determinado processo.

MPI_Recv, recebe dados de um determinado processo.

MPI_Bcast, transmite dados para todos os processos do sistema.

MPI_Reduce, recebe dados de todos os processo do sistema aplicando uma operação algébrica.

A primitiva MPI_Send sincroniza com a primitiva MPI_Recv e vice-versa.

Tratando-se portanto de uma das principais primitivas envolvidas na implementação dos algoritmos para aglomerados de computadores.

MPI_Bcast sincroniza diversos processos, funcionando como uma barreira, onde ao final todos os processos recebem o mesmo conjunto de dados.

MPI_Reduce agrupa dados de diversos processo em um unico processo ao mesmo tempo que realiza uma operação algébrica sobre os dados transmitidos.

Os aspectos de programação utilizando MPI se tornam relevantes para a compreensão do presente trabalho.

Importante ressaltar que cada processo conhece o número total de processos (MPI_Comm_size) e o seu identificador unico em uma execução (MPI_Comm_rank).

Assim, a comunicação pode ser facilmente implementada sem a configuração de parâmetros de baixo nível dependentes do protocolo de comunicação, tais como porta TCP ou endereço IP das máquinas.

Uma vez que MPI encapsula as primitivas básicas de comunicação, o uso dessa biblioteca permite uma fácil adaptação a diferentes tecnologias de rede.

A idéia da paralelização da Multiplicação Vetor-descritor (MVD) é distribuir algebricamente a multiplicação do vetor dentro do somatório.

Desta forma, temos por exemplo a possibilidade de executar a multiplicação do vetor por cada um dos termos de forma independente, como pode ser visto na equação 11.

Todavia, a maneira de distribuição da multiplicação depende da propriedade algébrica utilizada pelo algoritmo.

Isso diferencia as versões paralelas do shuffle e do slice.

A MVD ocorre diversas vezes (tipicamente centenas ou milhares de vezes) para resolver um modelo.

Todavia, a paralelização dos algoritmos shuffle e slice, leva em consideração que a cada passo os processos calculam diversos resultados parciais.

Precisamente, cada processo p calcula um vetor parcial xp.

O algoritmo 1 ilustra como funciona a paralelização de uma iteração onde a MVD é realizada.

Na notação do algoritmo 1, assim como em outros algoritmos deste trabalho, adota-se a variável procs para determinar o número total de processos existentes no ambiente de execução (equivalente a uma chamada da função MPI_Comm_size) e a variável p para determinar cada processo (equivalente a uma chamada da função MPI_Comm_rank).

Repare que na linha 2 do algoritmo 1, a MVD é realizada por um número indeterminado de iterações.

Todavia, para solucionar modelos com um grau de confiança razoável, o erro aceito é em torno de 10 9 o que exige um número elevado de iterações.

Alguns métodos iterativos para a solução de sistemas de equações lineares podem não convergir para um resultado com o erro mínimo estipulado.

Quando isso ocorre, os valores do vetor oscilam sem uma tendência clara a cada passo.

Para evitar que o método execute por um número indeterminado de iterações, na linha 2, existe um número máximo de iterações toleráveis para que o sistema chegue a um resultado.

Caso este número seja atingido, mesmo que a resposta ainda não tenha a precisão desejada, o algoritmo termina.

Diagrama de comunicação para a MVD em paralelo.

Na linha 3 do algoritmo 1, cada processo p multiplica uma parte do descritor pelo vetor da iteração atual (x) gerando parte do vetor da próxima iteração.

A parte do descritor que cada processo multiplica varia dependendo do algoritmo.

Porém, a multiplicação de cada termo de forma independente pode ser realizada diretamente, como visto na equação 11.

Para obter-se o vetor da próxima iteração, é necessário somar todos os vetores parciais.

Assim, nas linhas 4 e 5, cada processo envia o seu vetor parcial para o processo de identificação 0 e este fica encarregado de somar os vetores paraciais (xk+1) construindo o vetor da próxima iteração.

Ao final, na linha 6, o processo 0 envia o vetor da próxima iteração (x k+1) para todos os outros processos (ou seja, em broadcast).

Ao final deste algoritmo, cada processo possui o vetor da próxima iteração e uma nova etapa de MVD pode iniciar.

O resultado do procedimento da MVD realizada em paralelo é que a cada iteração os processos recebem o vetor da iteração atual x, cada processo multiplica este por uma parte do descritor gerando um vetor parcial da próxima iteração x k+1.

O processo de menor identificação acumula os vetores parciais gerando o vetor da próxima iteração (xk+1) e este é transmitido para todos os outros processos.

Este ciclo se repete até que o resultado atinja um erro mínimo ou um número máximo de iterações previamente estipulados.

Ilustra como funciona a comunicação entre os processos em alto nível.

Neste diagrama, a cada iteração k o vetor é transmitido para todos os processos que calculam resultados parciais.

Os resultados parciais são posteriormente somados no processo 0, gerando o vetor da próxima iteração que novamente é enviado a todos processos iniciando um novo ciclo.

O cálculo específico que será realizado por cada processo é independente da estratégia apresentada no algoritmo 1.

Dependendo do algoritmo utilizado, shuffle ou slice, as possibilidades de distribuir o processamento variam.

Dessa maneira, o processamento realizado por cada processo, linha 3, é diferente em cada caso específico.

Apresentaremos a seguir a estratégia de paralelização para o algoritmo shuffle onde são discutidas duas abordagens de escalonamento (distribuição de carga).

Na primeira abordagem, cada termo constitui uma tarefa independente e o número total de termos é conhecido.

Uma vez que o descritor é a soma de diversos termos, podemos efetuar a multiplicação de cada termo pelo vetor de forma independente.

Assim, é possível distribuir o laço que distribuí a multiplicação do vetor por cada termo.

Algoritmo 2 Shuffle utilizando abordagem de escalonamento sem considerar custos.

No algoritmo 2, é apresentado como a divisão dos termos que cada processo deverá computar é realizada.

Nesse algoritmo, terms representa o número total de termos do descritor executando em um ambiente com procs processos, cada um identificado pela variável p.

Para garantir que não haja cálculo redundante, em outras palavras, que dois ou mais processos não realizarão o mesmo cálculo, cada processador p começa calculando o termo (ou tarefa) de mesmo índice que a identificação do processo, linha 2.

Esse índice recebe, a cada execução do laço o número total de processos (procs) mais ele mesmo t = t + procs, linha 8.

Assim, garanti-se que as tarefas designadas a cada processo não coincidam.

Mesmo quando a divisão do número de tarefas pelo número de processadores não é exata, esse algoritmo é capaz de distribuir o resto da divisão.

Abordagem de distribuição de carga para o shuffle sem considerar custos.

Para exemplificar esta abordagem de escalonamento, apresentamos uma situação de execução hipotética com 16 termos (numerados de 0 a 15) sendo executado por 3 processos (identificados de 0 a 2).

Cada índice da lista de termos é designado para um processo, onde o padrão de preenchimento indica o processo para o qual um termo foi designado.

Nesse caso, o primeiro processo (identificador 0) receberia os termos de índices 0, 3, 6, 9, 12 e 15 (prenchidos com).

O segundo processo, de identificador 1, receberia os termos de índice 1, 4, 7, 10 e 13 (prenchidos com).

O terceiro processo receberia os termos de índices 2, 5, 8, 11 e 14 (prenchidos com).

Garantindo que os processos não realizem cálculo redundante e recebam aproximadamente o mesmo número de tarefas.

Repare que esse algoritmo não impõe restrições ao número de processos que deverão executar uma aplicação.

No entanto, não faz sentido executar a aplicação com um número de processos maior que o número de tarefas (ou termos).

Pois nessa situação, algum processo não realizaria cálculo.

Apesar dessa abordagem apresentar um método direto e eficaz de realizar a distribuição de carga, o fato de não considerar o custo das tarefas pode ocasionar, em determinadas situações onde os termos possuem custos muito discrepante, um resultado pouco eficiente.

Apresentaremos a seguir uma versão de escalonamento para o shuffle que leva em conta o custo computacional das tarefas.

A segunda abordagem de escalonamento considera os custos computacionais envolvidos no cálculo de cada uma das tarefas.

Uma vez que o número de elementos nulos varia em cada uma das matrizes, a multiplicação de cada termo pelo vetor apresenta tipicamente diferentes custos de um termo para outro.

Nesse sentido, foi proposto um algoritmo que tenta equilibrar a carga total de trabalho em cada processo.

A idéia no algoritmo é criar uma lista de tarefas (ou seja, termos) contendo o custo e índice de cada um.

Posteriormente, ordena-se esta lista por custo em ordem decrescente.

Uma vez que a lista está ordenada, se percorre a lista designando uma tarefa sempre ao processo com menor carga.

Algoritmo 3 Shuffle utilizando segunda abordagem de escalonamento, considerando custos.

O algoritmo 3, apresenta essa idéia de escalonamento de forma detalhada.

Primeiramente, o custo computacional do cálculo de cada termo é realizado na linha 4 utilizando-se a equação 9 apresentada no capítulo 2.

A medida que o custo de cada termo é calculado os termos são inseridos numa lista com seus respectivos índices, linha 6.

Após esse procedimento, ordena-se a lista de tarefas por custo em ordem decrescente, colocando a tarefa de maior custo no início da lista.

As etapas descritas anteriormente, tornam possível percorrer a lista de termos de forma a atribuir cada tarefa ao processo com menor custo, procedimento realizado nas linhas 10 a 22.

Nesse laço, a cada iteração, seleciona-se o processo com menor carga, linhas 13 a 17, atribuindo-lhe a tarefa.

Uma vez que a tarefa é atribuída, linha 19, atualiza-se a carga total do processo, linha 21.

Esse procedimento é repetido até que todas as tarefas tenham sido designadas aos processos.

Ao final desse procedimento, as tarefas designadas a cada processo são conhecidas por todos.

Isso implica que todos os processos realizam o algoritmo de distribuição de carga simultaneamente.

Com isso, acrescenta-se uma parcela de pré-processamento realizada antes da MVD.

Entretanto, este processamento não possui um custo significativo pois, na maioria dos casos, o número de termos é tipicamente pequeno.

O algoritmo slice utiliza a propriedade da decomposição de um produto tensorial em fatores normais unitários aditivos (ou fatores).

Um fator é basicamente um elemento composto pela multiplicação sucessiva de apenas um elemento não nulo de cada matriz de um termo.

Esta propriedade foi apresentada no capítulo 2, equação 10.

A idéia que deu origem ao algoritmo slice foi a de realizar a geração dos fatores em um pré-processamento guardando apenas estes e a ultima matriz de cada termo.

Para realizar o mapeamento dos elementos da ultima matriz de um termo no DM, guarda-se o índice desta e associa-se um índice a cada fator (AUNF) juntamente com o resultado das multiplicações sucessivas.

Em outras palavras, cada fator é composto por três informações (E, i, j), onde E é o resultado das multiplicações sucessivas de cada elemento não nulo das N1 primeiras matrizes de um termo, i, j são respectivamente os índices de linha e coluna deste elemento na matriz gerada resultante do produto tensorial entre as N1 matrizes de um termo.

A geração dos fatores (AUNFs) é realizada em uma etapa de pré-processamento uma unica vez.

Portanto, essa etapa não representa uma porção significativa do cálculo.

Uma vez gerada a lista de fatores, a mesma é armazenado e utilizada a cada etapa da MVD.

Independente do número total de iterações necessárias para a resolução dos modelos esses valores permanecem constantes.

A presente abordagem apresenta um custo de memória diferente do shuffle que armazena apenas as matrizes utilizando compactação HBF, pois 2 uma vez que a lista de fatores é gerada torna-se necessário armazenar somente essa e a ultima matriz de cada termo.

Essa abordagem é bastante semelhante a primeira técnica utilizada para o shuffle.

Apesar de não explorar os aspectos positivos da divisão de tarefas em um grão menor proporcionadas pelo slice, tal abordagem se torna atraente por permitir que a geração dos AUNFs de cada termo possa ser realizada de forma distribuída.

Como a geração dos fatores é realizada para cada termo e cada termo é uma tarefa independente, não é necessário que todos os processos realizem a etapa de pré-processamento.

Cada processo pode computar apenas a lista de fatores dos termos que irá efetivamente multiplicar a cada iteração.

Desta forma, antes de iniciar o procedimento iterativo que realiza diversas vezes a MVD (algoritmo 1), pode-se realizar o pré-processamento de forma distribuída.

Devido a considerar cada termo como uma tarefa, essa abordagem assemelha-se bastante com a primeira abordagem de escalonamento proposta para o shuffle.

Algoritmo 4 Slice utilizando abordagem simples de escalonamento De forma geral, o algoritmo 4 mostra como a estratégia de paralelização pode incluir o pré-processamento.

As linhas 1 a 7, mostram a geração de uma lista de fatores normais para cada termo t.

Posteriormente, nas linhas 8 a 16, a resolução do sistema é realizada por diversas iterações onde a cada passo o processamento é realizado de forma idêntica ao apresentado na primeira abordagem de escalonamento do shuffle.

A principal vantagem desta abordagem é não existir interdependência entre as tarefas, possibilitando o particionamento do conjunto de dados.

Pois cada termo somente precisa ser armazenado pelo processo ao qual foi designado.

Entretanto, esta abordagem não se beneficia da característica do slice de poder quebrar as tarefas em grãos menores.

A próxima abordagem visa justamente implementar um algoritmo de balanceamento de carga com essa característica.

O objetivo principal dessa abordagem é considerar cada fator (AUNF) como sendo uma tarefa independente das outras.

A motivação para tal abordagem é a possibilidade de quebrar o problema em unidades de dados com menores custos de processamento.

Em outras palavras, aumenta-se o número de tarefas reduzindo o custo computacional de cada uma.

A idéia central é criar uma lista de fatores que serão multiplicados por cada processo.

Assim, durante a etapa de pré-processamento, é possível atribuir cada fator (tarefa) a um processo, uma vez que o número total de tarefas é conhecido a priori.

Apesar de tornar o grão da aplicação menor, essa abordagem impossibilita a distribuição da etapa de pré-processamento.

Algoritmo 5 Slice, detalhe do pré-processamento, considerando cada AUNF como uma tarefa.

No algoritmo 5, é mostrado como o pré-processamento é realizado de forma a gerar uma lista de tarefas para cada processo.

Após a execução de tal etapa, ainda no pré-processamento, é efetuado a geração dos fatores.

Neste processo, a ultima matriz de cada termo é associada a cada tarefa.

Garantindo assim que a multiplicação dos fatores pela ultima matriz de cada termo possa ser realizada de forma independente do termo ao qual estão associadas.

Algoritmo 6 Slice utilizando abordagem que considera cada AUNF como uma tarefa.

Utilizando essa idéia, o cálculo que cada processo efetua em uma iteração fica como no algoritmo 6.

Nesse algoritmo os processos consideram como cada tarefa independente um AUNF o que propicia uma distribuição de carga mais justa.

Dividindo-se os termos em pedaços menores pode-se realizar uma distribuição de carga bastante precisa, na qual a diferença de processamento de um processo para outro não afeta de maneira significativa o desempenho geral da aplicação.

Os resultados obtidos pelas implementações dos algoritmos propostos no presente trabalho serão apresentados através de gráficos de aceleração (speedup).

Essa métrica visa comparar o tempo de execução da aplicação sequencial com o obtido após a paralelização.

Formalisando, se uma aplicação sequencial leva um tempo Tseq para uma determinada entrada de dados, e executando-a em paralelo com p processadores a mesma aplicação leva um tempo Tp, diz-se que o speedup obtido com esta aplicação é dado pela razão entre o tempo sequencial e o tempo paralelo, como apresentado na equação 12.

Os resultados apresentados foram obtidos utilizando a média de 10 execuções cada uma realizando 100 iterações.

O tempo de uma iteração foi medido utilizando o tempo real da execução com um cronômetro interno à aplicação.

Neste tempo foi incluído o tempo necessário para a transmissão do vetor e dos vetores parciais.

A qualidade dos resultados apresentados foi garantida através da observação do desvio padrão.

Por razões de clareza e espaço os detalhes de cada execução não são apresentados nesta seção mas no apêndice C.

Nesse apêndice são apresentados a média, o desvio padrão, o speedup e a eficiência para cada execução realizada.

A plataforma de testes utilizada é um aglomerado de computadores, cluster, denominado i-cluster2.

Esta máquina foi o primeiro supercomputador francês baseado na família de processadores Itanium-2 de 64 bits.

O desempenho do i-cluster2 foi medido utilizando o benchmark Linpack.

Atingindo a marca de 561 GigaFlops (bilhões de operacões de ponto flutuante por segundo).

Em novembro de 2003, esta máquina ficou em 283 lugar na lista das 500 máquinas mais velozes do mundo (TOP 500).

Exemplo de descritor com dois termos, cada um com três matrizes.

Cada um dos 104 nós desta plataforma possui dois processadores Itanium-2 1 de 64 bits operando a 900 Mhz.

Equipados com 3 GB de memória e 72 GB de disco rígido.

Os computadores são interconectados por uma rede de baixa latência Myrinet.

No total, o i-cluster2 é composto por 208 processadores, 312 GB de memórias, somando uma capacidade de armazenamento em disco de 7,5 TB (TeraBytes).

Em relação ao software, cada computador que compõe o icluster-2 utiliza sistema operacional Linux com a distribuição Red Hat (Enterprise Linux AS 3).

A biblioteca utilizada para a programação MPI é lammpi.

Para garantir que outras aplicações não interferissem na execução dos testes, pelo uso da rede, o icluster-2 foi utilizado exclusivamente durante os testes.

Desta forma, afirmamos que não havia transmissões de outras aplicações ocorrendo durante cada execução.

Para mitigar o efeito de cache a cada experimento, o ambiente de execução era restaurado.

Isto foi realizado utilizando o comando lamclean que remove arquivos temporários, desalocando recursos e cancelando registros de processos.

A utilização deste comando garante que a cada execução realizada o estado de cada um dos nós é semelhante ao obtido após uma reinicialização dos daemons do MPI.

Como descrito no capítulo 2, a entrada da aplicação é um descritor markoviano (DM) que consiste na soma consecutiva de uma série de termos produto-tensoriais.

Estes termos são carregados utilizando como entrada um arquivo composto por diversas matrizes.

Supondo um descritor com 2 termos, cada um contendo 3 matrizes.

Neste formato de entrada, uma linha precedida indica um comentário.

Foram utilizados quatro casos de teste para verificar o desempenho obtido com as implementações paralelas propostas nesse trabalho.

Dois casos de teste foram estudos de caso reais de modelagem analítica estruturada utilizando o formalismo SAN.

O primeiro modelo real é referenciado durante o texto por seção crítica (SC) pois representa a modelagem do problema onde 16 recursos são disputadas por 4 processos.

O segundo, batizado como Misto, modela 9 módulos que exploram diversos parâmetros.

Uma descrição gráfica mais detalhada de tais modelos pode ser visualizada no apêndice B.

Um parâmetro relevante para determinar o aumento de desempenho de uma aplicacão paralela é a quantidade de cálculo distribuída.

Esse parâmetro se torna ainda mais¸ relevante em aglomerados de computadores, uma vez que nessas arquiteturas a comunicação representa um fator limitante da aceleração.

A quantidade de cálculo realizada por cada algoritmo varia de forma significativa.

Porém, existe um fator que colabora para o aumento de complexidade simultaneamente em ambos algoritmos.

Se um dado modelo possui o mesmo número de matrizes em cada termo e se a ordem destas matrizes são as mesmas, o fator relevante dentro do escopo do trabalho que diferenciará estes modelos será o número de elementos não nulos nas matrizes.

Desta forma, defini-se que a esparsidade de um descritor é dada pela média da razão entre o número de elementos não nulos (nzi) e o número total de elementos (ni) de cada matriz i.

O resultado desta operação é a porcentagem de elementos não nulos geral do descritor.

A equação 13, mostra como a esparsidade é calculada em um descritor composto por T termos, cada um com N matrizes, onde nz (k)e n(k)representam respectivamente o número de elementos não nulos e a ordem da i-ésima matriz do k-ésimo termo.

Detalhamento dos casos de teste Assim, mais dois testes foram elaborados com base no modelo Misto com o intuito de verificar o comportamento dos algoritmos em situações que envolvessem um grande volume de multiplicações.

Para gerar esses dois modelos, chamados de Denso A e Denso B, foram acrescentados elementos não nulos aleatoriamente nas matrizes do modelo Misto.

Mostra alguns parâmetros relevantes de cada caso de teste.

O primeiro parâmetro é o número de termos de cada descritor.

Esse parâmetro se torna relevante por constituir uma tarefa nos algorimtos shuffle (utilizando ambas abordagens de escalonamento) e slice (primeira abordagem), limitando o número de processadores que podem ser utilizados nesses casos.

Na segunda coluna, o parâmetro esparsidade mostra a porcentagem média de elementos não nulos das matrizes de cada descritor.

A terceira coluna apresenta o número de fatores (AUNF) relevante por constituir o grão (uma tarefa indivisível) na segunda abordagem de escalonamento do algoritmo slice.

A quarta e a quinta coluna mostram os tempos de execução sequencial (ou seja, com apenas um processador) necessários para realizar um passo da MVD utilizando os algoritmos shuffle e slice respectivamente.

O tempo de execução do slice neste caso não considera o tempo de pré-processamento.

Nas próximas seções, os resultados obtidos com as abordagens de escalonamento de ambos os algoritmos são apresentados.

Na seção que aborda os resultados obtidos com o algoritmo slice os tempos de pré-processamento são apresentados.

Por uma questão estrutural a comparação entre os dois algoritmos que realizam a MVD é realizada no capítulo seguinte.

Na presente seção são mostrados os resultados obtidos com as implementações do shuffle abordadas no capítulo 3.

Os resultados são apresentados de forma a traçar as principais diferenças entre os algoritmos de escalonamento propostos comparando-se o tempo de execução obtido com um determinado número de processadores.

Cada gráfico traça uma relação entre a aceleração obtida (eixo y) e o número de processadores utilizados (eixo x).

O número total de processadores utilizados é limitado pelo número de termos nas implementação do shuffle.

Apresenta dois gráficos com os resultados para as duas técnicas de escalonamento apresentadas para o shuffle utilizando o caso de teste SC.

A primeira técnica, mostra valores de aceleração próximos do ideal em alguns pontos.

Esses resultados já apresentam-se satisfatórios se considerado a simplicidade dessa solução.

Por outro lado, observando a curva da técnica que considera custos, conclui-se que essa abordagem, para este caso de teste, não apresenta vantagem.

Outro aspecto que chama atenção é que em determinados pontos ambas as curvas apresentam uma estagnação nos valores de aceleração.

Por exemplo, utilizando 16, 17, 18, 19, 20 e 21 processadores o speedup permanece praticamente constante.

Isso se repete em outros intervalos, como 13 a 15 e 22 a 31.

Acredita-se que esses pontos de estagnação sejam devido a distribuição de carga.

Essa afirmação pode ser comprovada observando-se que, nos pontos cujo o número de processadores é um múltiplo do número de tarefas (4, 8, 16 e 32), a aceleração está bastante próxima do ideal.

Aceleração do Shuffle, sem considerar custos (A) e considerando custos (B) para o teste SC.

Observam-se os gráficos que apresentam os resultados para as duas abordagens de escalonamento utilizando o caso de teste Misto.

Semelhantemente aos resultados analisados anteriormente, ambas as técnicas apresentaram acelerações significativas.

Novamente, percebe-se um comportamento bastante parecido.

O que chama atenção nesses dois gráficos é o speedup obtido com 8 processadores com os algoritmos de escalonamento.

Sem considerar custos, a aceleração com 8 processadores é maior do que usando 7 processadores com essa mesma versão.

Já considerando custos, o resultado com 8 processadores se monstra inferior ao obtido com 9.

Esses aspectos reforcam a impressão de que, na abordagem que considera custos, a relação entre a quantidade, de termos não precisa ser um múltiplo do número de processadores.

Aceleração do Shuffle, sem considerar custos (A) e considerando custos (B) para o teste Misto.

Apresentam os resultados obtidos respectivamente com os casos de teste Denso A e Denso B utilizando o shuffle.

Observe que para esses dois testes as acelerações são praticamente as mesmas, independente da técnica de escalonamento utilizada.

Isto acontece devido ao fato que todas as tarefas possuem o mesmo custo nesses casos de teste.

A idéia desses dois testes é demonstrar que mesmo com a abordagem que considera custos, o algoritmo shuffle pode apresentar um comportamento pouco escalável quando os termos possuem custos muito semelhantes.

Isso acontece também devido ao tamanho do grão ser sempre limitado pelo número total de termos.

Celeração do Shuffle, sem considerar custos (A) e considerando custos (B) para o teste Denso A.

Aceleração do Shuffle, sem considerar custos (A) e considerando custos (B) para o teste Denso B.

Apresenta o detalhe da carga atribuída a cada processo para algumas configurações do caso de teste Misto.

A carga é quantificada em número de multiplicações em ponto flutuantes.

Os três gráficos na parte superior apresentam o detalhe do cálculo realizado com 7, 8 e 9 processos respectivamente da esquerda para a direita.

A carga atribuída a cada processo é apresentada em milhares de operações de ponto flutuante (MMP).

Com 7 processos, o desempenho é limitado por um processo que realiza aproximadamente 26 MMPs, já com 8 processos o balanceamento de carga se apresenta de forma mais eficiente uma vez que o processo com mais carga recebe em torno de 15 MMPs.

Porém, ao aumentar o número de processos para 9 a abordagem de escalonamento não evolui.

Como pode ser observado o processo mais carregado computa aproximadamente 15 MMPs também com 9 processadores limitando o aumento de desempenho geral da aplicação.

Detalhe do algoritmo de balanceamento de carga, shuffle, teste Misto.

Comparativo entre custo de pré-processamento e o de uma iteração com o slice.

Logo, pode-se concluir que como o grão de cada tarefa para esses métodos sempre será grande, os resultados obtidos não apresentam uma boa escalabilidade quando o número de tarefas não é divisível pelo número de processadores.

O desempenho geral da versão paralela do shuffle foi significativo.

Entretanto, o comportamento da aceleração nos testes não evolui em alguns intervalos.

Isso se deve as características intrínsecas deste algoritmo que não permite dividir um termo em pequenas tarefas.

Um das principais razões que motivaram a paralelização do slice foi a possibilidade de quebrar os termos em mais tarefas.

Esta seção tem como objetivo apresentar os resultados obtidos com o algoritmo slice utilizando os mesmos casos de teste anteriores.

Como já foi discutido no capítulo 3, o slice de alto desempenho inclui uma etapa de pré-processamento que deve ser realizada uma unica vez.

Nesse sentido, a utilização da primeira abordagem de escalonamento, que considera cada termo como uma tarefa independente, foi utilizada por permitir a distribuição desse cálculo.

Mostra os tempos de pré-processamento para quatro casos de teste utilizando a primeira abordagem de escalonamento.

São apresentados também o custo computacional para realizar uma iteração da MVD.

Apesar do custo de uma iteração ser menor que o custo de pré-processamento, o custo de processamento não é impactante no tempo total de execução.

Isso porque são necessárias centenas de iterações para resolver um problema.

O resultado é que o custo de pré-processamento é diluído ao longo de algumas iterações.

Por exemplo, supondo que para o caso de teste SC necessita-se de 200 iterações para o sistema de equações ser resolvido.

Ao todo seriam necessários cerca de 2600 segundos (200 vezes o tempo sequencial de aproximadamente 13 segundos) para a resolução do modelo.

Consequentemente, nessa situação o tempo de pré-processamento, que para esse teste é aproximadamente 39 segundos, representaria pouco mais de 1% do tempo total de execução.

No entanto, os métodos iterativos de resolução de sistemas de equações lineares não são determinísticos.

Com isso, o número de iterações necessárias para realizar o pré-processamento pode ser ou não ser significativo dependendo do modelo.

Dessa forma, faz-se interessante paralelizar a etapa de pré-processamento para abranger tais situações.

Mostra a aceleração obtida na etapa de pré-processamento quando utilizando a abordagem que considera cada termo como uma tarefa.

Apresenta as acelerações obtidas com os casos de teste SC.

Com o teste SC é possível observar que o desempenho é melhor quando a quantidade de processadores é múltiplo do número de tarefas (4, 8, 16 e 32 processos).

O caso de teste Misto apresenta um comportamento semelhante.

E importante observar que nos casos de teste onde as tarefas possuem o mesmo custo, que a aceleração apresenta um comportamento unicamente crescente.

Isso ocorre porque nesses casos a distribuição de carga é uniforme, uma vez que, não existe praticamente diferença nos custos de cada termo.

Aceleração do pré-processamento para o algoritmo slice.

Apesar da distribuição do cálculo de pré-processamento ter sido satisfatória em alguns casos, a necessidade de paralelizar esta etapa é menos significativa do que a MVD.

Isso porque o pré-processamento é computado somente uma vez.

Já a MVD é uma operação efetuada diversas vezes até que um modelo seja solucionado.

Nesse ponto, o slice apresenta uma vantagem em sua segunda abordagem de escalonamento por que esta considera cada AUNF como sendo uma tarefa.

Tornando possível quebrar os termos em mais tarefas de custo menor (grão menor).

Aceleração do Slice considerando cada termo como uma tarefa (A) e considerando cada AUNF como uma tarefa (B) para o teste SC.

A aceleração obtida com a paralelização da MVD para ambas técnicas de escalonamento é apresentada utilizando o caso de teste SC.

Faz-se importante ressaltar que, para fins comparativos, o cálculo de pré-processamento não foi considerado nos resultados apresentados.

E perceptível, comparando-se os gráficos, que a técnica de escalonamento considerando cada termo como uma tarefa apresenta maior escalabilidade.

Isso comprova que a utilização de um grão menor é melhor.

Mesmo considerando que a segunda abordagem de escalonamento impede a paralelização da etapa de pré-processamento.

Aceleração do Slice considerando cada termo como uma tarefa (A) e considerando cada AUNF como uma tarefa (B) para o teste Misto.

São apresentados os resultados para o caso de teste Misto com as duas abordagens de escalonamento.

De forma similar ao comportamento obtido com o caso de teste SC, a utilização da segunda abordagem gera uma curva mais escalável.

Isso confirma a hipótese de que a aplicação é mais adaptável a um grão menor.

Um aspecto que chama atenção nos gráficos é a distância das curvas de speedup da curva ideal.

Nesse teste tal comportamento é justificado porque o tempo de execução é bastante pequeno utilizando a versão sequencial do algoritmo slice.

A consequencia disso, é que como o tempo de execução não é muito significativo, o tempo necessário para transmissão dos dados não compensa tanto a utilização da versão paralela.

Aceleração do Slice considerando cada termo como uma tarefa (A) e considerando cada AUNF como uma tarefa (B) para o teste Denso A Aceleração do Slice considerando cada termo como uma tarefa (A) e considerando cada AUNF como uma tarefa (B) para o teste Denso B.

São apresentados os resultados para os casos de teste Denso A e Denso B.

Com discutido anteriormente, esses dois modelos hipotéticos apresentam situações onde considerar ou não o custo de cada termo não influencia no resultado de escalonamento.

Isso ocorre porque o custo computacional de cada tarefa nesses dois casos é o mesmo.

Porém, ao utilizar a segunda abordagem de escalonamento com o slice vislumbra-se uma curva que apresenta um comportamento escalável.

Observando essas duas figura é possível notar que, a medida que o tempo sequencial do caso de teste é maior, as curvas de aceleração apresentam um comportamento mais próximo do ideal.

Em geral, os resultados com a segunda abordagem de escalonamento do slice apresentam um comportamento escalável e próximo do ideal.

Faz-se ressalva aos casos de teste que possuem um custo computacional baixo para a versão sequencial.

Porém, ainda obtém-se resultados expressivos em tais situações.

O presente trabalho apresentou como técnicas de alto desempenho podem ser empregadas para acelerar a Multiplicação Vetor-descritor.

Essa operação é realizada diversas vezes para obter estimativas de desempenho em modelos que utilizam um formalismo analítico estruturado.

Esses modelos são muito utilizados na predição de desempenho de sistemas em geral, pois apresentam uma forma mais eficiente de armazenamento do que Cadeias de Markov.

As soluções propostas nesse trabalho utilizam uma estrutura algébrica comum aos diversos formalismos de modelagem analítica estruturados existentes e portanto podem ser empregadas em diferentes situações.

O foco principal da paralelização foi o processo de uma etapa da MVD, operação que é realizada diversas vezes para inferir estimativas de desempenho de um modelo.

Porém, os detalhes de distribuição de tarefas foram delineados com base nas operações algébricas envolvidas em cada um dos dois algoritmos para realizar tal operação, shuffle e slice.

Para cada um dos algoritmos foram apresentadas duas abordagens de escalonamento explorando as características específicas de cada um.

Em todos os testes realizados, obteve-se uma aceleração (speedup) considerável independentemente do algoritmo utilizado e da abordagem de escalonamento.

Nesse mesmo contexto, a utilização de diferentes abordagens de escalonamento tornou possível estudar aspectos relevantes na adaptação de aplicações em ambientes de alto desempenho, mais especificamente, aglomerados de computadores (clusters).

Apesar de uma completa avaliação das diferenças entre o shuffle e o slice fugir do escopo desse trabalho, discutiremos a seguir as principais diferenças entre as versões paralelas desses algoritmos utilizando os casos de teste propostos no capítulo 4.

Para comparar os resultados obtidos com shuffle e slice são mostrados dois gráficos de tempo de execução.

Esses gráficos relacionam o número de processadores utilizados (eixo x) e o tempo de execução obtido (eixo y) para realizar uma iteração da MVD.

No caso do algoritmo slice os tempos de pré-processamento, não são considerados, pois esses são referentes a uma parte do cálculo que é realizada somente uma vez.

Portanto, ao longo centenas ou milhares de iterações o tempo de pré-processamento não é impactante no tempo total de execução do mesmo.

Os melhores resultados obtidos com shuffle foram utilizando a abordagem de escalonamento que considera o custo das tarefas.

Já com o slice, os melhores resultados apresentados foram utilizando a abordagem de escalonamento que considera cada fator como uma tarefa.

Assim, compara-se os resultados obtidos com cada algoritmo utilizando essas duas abordagens.

Comparação do tempo de execução entre shuffle (A) e o slice (B) para caso Misto.

Os resultados em tempo de execução para os dois algoritmos utilizando o caso de teste SC são apresentados.

Note que a escala utilizada nos gráficos é diferente.

Isso porque o tempo de execução do algoritmo slice é significativamente menor que o do shuffle.

Entretanto, ambos algoritmos apresentam um comportamento bastante escalável.

Comparação do tempo de execução entre shuffle (A) e o slice (B) para caso Denso A.

Mostra os resultados em tempo de execução com o caso de teste Misto.

Nesse caso, as mesmas afirmações feitas anteriormente se aplicam pois, o comportamento das curvas é bastante semelhante.

Ainda, os tempos de execução obtidos com o slice são bem inferiores aos obtidos utilizando o shuffle e por isso as escalas dos gráficos são diferentes.

Faz-se importante ressaltar que o número de processadores utilizados com o slice, nesse caso de teste, é superior à quantidade de termos.

Como o número de termos é um fator limitante do número de processadores que podem ser utilizados, a escalabilidade do shuffle é sempre limitada por esse fator.

Por outro lado, o slice pode escalar em um número bem maior de processadores.

Comparação do tempo de execução entre shuffle (A) e o slice (B) para caso Denso B.

Os gráficos que mostram os resultados para o teste Denso A, apresentam as mesmas características já mencionadas.

Entretanto, nos gráficos com o caso de teste Denso B, em alguns pontos é possível observar que os resultados obtidos com o shuffle são melhores.

Isso ocorre nas execuções com 4, 8 e 16 processadores.

Não por coincidência, esses são os casos cujo número de processadores é múltiplo da quantidade de termos.

Em princípio, outro fator que contribui para esse comportamento é a semelhança do tempo sequencial de execução do shuffle e do slice nesse caso de teste.

Apesar do slice ter apresentado melhores resultados que o shuffle na maioria dos casos de teste, estudos recentes apontam que a solução ideal para realizar a MVD é uma abordagem híbrida, que misture aspectos de ambos algoritmos.

Nesse sentido, a paralelização deste algoritmo híbrido poderá explorar aspectos das abordagens de escalonamento aqui apresentadas.

O estudo do impacto de paralelização com relação à quantidade de memória utilizada é também outra possível continuidade ao trabalho aqui apresentado.

Principalmente em modelos que apresentam um elevado número de estados, tornando a memória um fator limitante.

Agrupar AUNFs para otimizar o volume de dados transmitidos a cada iteração é outro possível assunto a ser abordado em futuras investigações.

Entretanto, como o número de fatores tipicamente é bastante elevado, considerar as características de cada fator um-a-um pode levar em altos custos.

O estudo de como esse agrupamento pode ser realizado mantendo um compromisso entre tempo de escalonamento e a redução na comunicação torna-se necessário.

O objetivo desse trabalho foi apresentar como técnicas de alto desempenho podem ser empregadas para acelerar a análise de modelos analíticos estruturados.

Nesse contexto, foi contemplado o uso de MPI, uma ferramenta popular para o desenvolvimento em aglomerados de computadores.

A escolha desse tipo de plataforma, foi motivada principalmente pelo baixo custo envolvido em sua construção.

Estabelecendo um compromisso entre custo e benefício que se adapta de maneira a acompanhar a evolução rápida que ocorre com os micro-processadores.

A principal impressão deixada após a análise dos resultados é que a versão paralela do algoritmo slice apresenta melhores resultados que o shuffle.

No entanto, uma análise aprofundada mostra que isso não é sempre verdade.

Os resultados obtidos com o ultimo caso de teste (Denso B) para o shuffle, por exemplo, em alguns casos superam os resultados do slice.

Também é importante levar em consideração que o slice necessita de uma etapa de pré-processamento.

Logo, uma solução híbrida, que explore características de ambos os algoritmos aparentemente seja mais eficiente.

Em geral, o trabalho realizado até o momento apresentou resultados positivos.

Essa afirmação é atestada pelos bons desempenhos obtidos nos testes realizados.

Mesmo quando os tempos sequenciais dos algoritmos não apresentavam um custo considerável para a realização da MVD estes mostraram-se adaptáveis ao tipo de arquitetura utilizada.

Reforçando as escolhas efetuadas ao longo do trabalho.

A principal contribuição do presente trabalho é apontar diretivas para o desenvolvimento em aglomerados de computadores.

Mesmo em diferentes formalismos, os algoritmos propostos podem ser utilizados.

Entretanto, o trabalho iniciado aqui não se apresenta completamente esgotado, restando assuntos a serem abordados em trabalhos futuros.

Modelos SAN são descritos geralmente de forma gráfica onde um grafo dirigido é projetado para cada módulo do sistema.

A representação gráfica fornece uma maneira de esquematizar o sistema em módulos independentes.

Muitas vezes, esta separação ajuda a projetar o sistema, uma vez que módulos com funções diferentes podem ser modelados separadamente e consequentemente, facilmente replicados.

O problema modelado neste exemplo é conhecido como problema da seção crítica (SC).

O problema da SC consiste no acesso exclusivo de um processo a um determinado recurso.

Neste exemplo, temos apenas um processo acessando apenas um recurso.

Os estados do modelo são representados pelos vértices do grafo, neste caso temos dois autômatos, um para representar o processo (com três estados) e outro chamado recurso (com dois estados).

Repare como o processo pode ser modelado independentemente do recurso facilitando a expansão do modelo.

Para modelar o problema com um processo a mais, por exemplo, basta acrescentar um autômato recurso.

Modelo SAN para o problema da SC No entanto, as afirmações anteriores não são suficientes para modelar como essas interagem duas entidades (processo e recurso).

Para modelar este comportamento, é utilizado o conceito de eventos.

Eventos são graficamente representados por arestas.

Em SAN, dispomos de dois tipos básicos de eventos, locais (pois alteram apenas o estado de um autômato) e sincronizantes (pois representam uma interação entre dois ou mais autômatos).

Em nosso exemplo, podemos detectar um evento sincronizante quando o identificador aparece nos dois autômatos simultaneamente, por exemplo, o evento e2 é um evento sincronizante.

Foge do escopo deste trabalho fornecer uma explicação mais detalhada sobre modelagem utilizando SAN.

Os leitores interessados em buscar mais informações podem consultar as referências.

Modelo SAN para o problema da SC com dois processos O Descritor Markoviano (DM) é uma estrutura algébrica que armazena informações sobre as transições locais de cada autômato e os eventos sincronizantes.

Para representar as transições locais, são armazenadas uma matriz para cada autômato.

Nestas matrizes, cada transição não sincronizante de um estado i para outro estado j é representada por um número real positivo.

Este número indica a frequência com que esta transição ocorre no mundo real.

Por exemplo, considerando o modelo SAN para o problema da SC.

Supondo-se que a transição local do autômato processo (l1), do estado 1 para o estado 0, aconteça com uma frequência, a matriz que representa algebricamente o comportamento local deste autômato.

Para representar algebricamente as interações entre os autômatos são necessárias duas matrizes para cada autômato do modelo.

De maneira análoga ao processo anterior, os elementos destas matrizes representam a frequência com que estas transições ocorrem na realidade.

Por exemplo, supondo que o evento e1 ocorra na realidade com uma frequência, para cada um dos dois autômatos do exemplo serão criadas duas matrizes.

Note que cada autômato tem uma matriz positiva e outra negativa para o evento e1.

A matriz positiva tem a mesma função da matriz local, ela indica qual transição está associada a frequência com que o evento ocorre na realidade.

A parte negativa faz um ajuste diagonal, neste ajuste cada elemento da diagonal principal contém um valor que, se somados todos os elementos de uma linha da matriz positiva com a negativa, resultará zero.

O DM é então uma expressão algébrica que mapeia as diversas matrizes que compõe os modelos SAN em uma unica matriz.

A equação 14, generaliza como fica o DM para um modelo SAN com N autômatos e E eventos sincronizantes.

Para o exemplo apresentado, o DM ficará apesar de ser possível resolver a expressão algébrica do DM, gerando uma unica matriz que represente o modelo, isto não é desejado.

Uma das vantagens de se utilizar modelos SAN em relação a Cadeias de Markov é a utilização reduzida de memória, gerando-se uma unica matriz essa vantagem desaparece.

Neste ponto, entra em ação a Multiplicação Vetordescritor, ao invés de uma multiplicação de um vetor por uma matriz (Ax) o sistema de equações a ser resolvido se apresenta na forma da multiplicação do Descritor Markoviano pelo vetor (Qx).

O modelo SAN apresenta a descrição gráfica do modelo de teste denominado SC.

Baseado em um caso real, este modelo representa uma situação onde 16 recursos são disputados por 4 processos.

Cada processo pode estar utilizando um recurso (estado U) ou livre (estado L).

De forma semelhante um recurso pode estar sendo utilizado por um processo (estado U) ou estar livre (estado L).

Modelo SAN do caso de teste SC.

Este caso de teste explora diversos aspectos diferentes de transições entre os estados, bem como diversifica o número de estados de cada autômato.

Modelo SAN do caso de teste Misto.

Shuffle, escalonamento sem considerar custos, teste Misto.

Shuffle, escalonamento sem considerar custos, teste SC.

Shuffle, escalonamento sem considerar custos, teste Denso A.

Shuffle, escalonamento sem considerar custos, teste Denso B.

Shuffle, escalonamento considerando custos, teste SC.

Shuffle, escalonamento considerando custos, teste Misto.

Shuffle, escalonamento considerando custos, teste Denso A.

Shuffle, escalonamento considerando custos, teste Denso B.

Slice, escalonamento por termo, teste SC.

Slice, escalonamento por termo, teste Misto.

Slice, escalonamento por termo, teste Denso A.

Slice, escalonamento por termo, teste Denso B.

Slice, escalonamento por AUNF, teste SC.

Slice, escalonamento por AUNF, teste Misto.

Slice, escalonamento por AUNF, teste Denso A.

Slice, escalonamento por AUNF, teste Denso B.

