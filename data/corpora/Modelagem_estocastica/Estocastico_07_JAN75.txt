Este trabalho de dissertação abrange a implementação da confiabilidade na transmissão Multicast, através da biblioteca RML (Reliable Multicast Library), a criação do modelo que a descreve e a análise de seu desempenho através do modelo criado.

Nas seções seguintes são apresentadas a motivação e o objetivo que introduzem todo o trabalho realizado, a contribuição deste trabalho de dissertação e o roteiro que resume a dissertação.

Com o advento de aplicações multimídia distribuídas, torna-se crescente a necessidade de processamento e de largura de banda suficientes para a distribuição desses tipos de dados.

Por isso, se faz necessária uma distribuição de dados eficiente, fazendo com que a utilização da rede seja mais eficaz.

Com a transmissão Multicast é possível reduzir o número de pacotes duplicados no canal, economizando largura de banda e, consequentemente, otimizando o uso da rede.

Como o Multicast utiliza o protocolo UDP para transmissão, cada pacote pode trafegar por um caminho diferente do emissor até o receptor.

Portanto, além dos pacotes poderem se perder durante a transmissão, eles ainda podem chegar fora de ordem, tornando o protocolo Multicast não confiável.

Para a garantia da confiabilidade na transmissão Multicast, foi desenvolvida a biblioteca RML, com a função de detectar perdas de pacotes e recuperar eficientemente os pacotes perdidos, tornando a transmissão confiável.

Ela pode ser utilizada por diversos tipos de aplicações e oferece rotinas para a garantia da confiabilidade na entrega dos dados em um ambiente Multicast.

O objeto de estudo desta dissertação concentra-se no desenvolvimento e na análise da confiabilidade na transmissão Multicast.

A biblioteca desenvolvida foi minuciosamente testada através de experimentos na Internet, confirmando a sua robustez e confiabilidade na transmissão Multicast.

Como a modelagem de sistemas de computação e comunicação é uma tarefa essencial no processo de desenvolvimento de novas tecnologias, além da implementação da biblioteca Multicast confiável, foi desenvolvido um modelo que simula o seu comportamento.

Este comportamento pode ser analisado através dos resultados obtidos da simulação do modelo.

Considerando que nem sempre é possível utilizar os recursos da rede para a análise de desempenho da transmissão Multicast confiável, o modelo descreve o comportamento do algoritmo de transmissão Multicast confiável diante das variações de retardo e do processo de perdas encontradas em uma rede de transmissão de dados.

Criou-se uma biblioteca para garantir a confiabilidade na transmissão Multicast, que pode ser usada por diversas aplicações distribuídas.

Esta biblioteca foi implementada em conjunto com dois integrantes do laboratório de modelagem, análise e desenvolvimento de redes e computação de sistemas (LAND), da Universidade Federal do Rio de Janeiro (UFRJ).

O trabalho em equipe também abrange a integração desta biblioteca com a ferramenta whiteboard TGWB para garantia da confiabilidade na transmissão dos dados enviados e recebidos pela ferramenta.

A contribuição inclui a elaboração do modelo Multicast confiável, com a finali dade de analisar o desempenho da biblioteca diante das diferentes situações que a rede pode apresentar.

Através do modelo, é possível analisar o comportamento de acordo com a variação do atraso na rede, das perdas de dados na transmissão e do intervalo dos temporizadores.

O Capítulo 2 descreve os diferentes tipos de protocolos para transmissão Multicast confiável.

O Capítulo 3 apresenta a ferramenta TANGRAM II Whiteboard, uma aplicação distribuída que utiliza a biblioteca RML para garantia da confiabilidade na transmissão Multicast.

Nos Capítulos 4 e 5 são descritas as implementações da biblioteca RML e do modelo que a descreve, respectivamente.

A análise de desempenho da biblioteca através do modelo e os resultados obtidos são apresentados no Capítulo 6.

E no Capítulo 7 são apresentados as conclusões e os possíveis trabalhos futuros.

E STE capítulo tem o objetivo de apresentar as características de uma transmissão Multicast, e os mecanismos que a tornam confiável, fazendo uma análise do desempenho de cada um destes mecanismos.

Nos últimos anos, com o advento de aplicações multimídia distribuídas tais como transmissões de imagens, texto, áudio e vídeo na Internet, torna-se crescente a necessidade de processamento e de largura de banda suficientes para a distribuição desses tipos de dados.

Apesar do grande avanço tecnológico alcançado hoje, nem todos possuem acesso aos meios de transmissão adequados a essas aplicações.

Por isso, se faz necessária uma distribuição de dados eficiente, fazendo com que a utilização da rede seja mais eficaz.

Existem algumas maneiras de economizar banda de transmissão.

Dependendo da aplicação, a compactação dos dados antes do envio pode reduzir muito a banda necessária para a transmissão.

Em outros casos, um mesmo conjunto de dados é enviado para muitos nós da rede ao mesmo tempo, através de várias transmissões independentes (uniponto ou Unicast).

Nesta situação, no mesmo canal podem estar passando várias cópias de um mesmo pacote.

Este tipo de transmissão pode ser otimizada, reduzindo o número de pacotes duplicados no canal com o uso da transmissão multiponto, ou transmissão Multicast.

O Multicast é voltado para aplicações do tipo um-para-muitos, onde somente um host envia os dados para os demais e muitos-para-muitos, onde todos os hosts podem enviar e receber dados simultaneamente.

Nestes casos, o Multicast apresenta vantagens quando comparado com os mecanismos de transmissão Unicast.

Neste caso, se o host emissor deseja enviar dados para n hosts receptores, então n conexões e n cópias serão feitas para cada pacote de dados a ser enviado, fazendo uma péssima utilização da rede.

A transmissão Multicast também é mais eficiente do que a Broadcast, pois este último envia os dados para toda a rede de forma indiscriminada.

Isto também resulta em desperdício de recursos, pois implica em transportar os dados para todos os hosts da rede, mesmo que o número de receptores desejosos daqueles dados seja reduzido.

Com o Multicast, o emissor envia apenas uma única cópia dos pacotes pelo canal, para um endereço de grupo Multicast.

Os roteadores da rede replicam estes pacotes de forma inteligente, encaminhando os dados de acordo com a localização dos receptores interessados naquela informação.

Exemplificam transmissões via conexão Unicast e Multicast, respectivamente.

Quando o servidor deseja transferir um pacote da dados para os quatro membros da rede, ele faz uma cópia do pacote para que cada um dos membros, aumentando o número de pacotes que trafegam em cada canal da rede.

Cada pacote de dados vai ser enviado em uma conexão Unicast diferente.

Mostra que para enviar o mesmo pacotes de dados para destinos diferentes, não é necessária a duplicação de pacotes no canal.

Cada roteador fica encarregado de fazer cópias dos pacotes de dados e de enviar apenas um pacote de dados por cada porta do roteador.

O Multicast pode ser extremamente útil em diferentes situações, como as listadas a seguir, um grupo de usuários querendo fazer a atualização de um determinado software, uma vídeo conferência, atualizações de banco de dados distribuídos, simulações distribuídas, jogo com múltiplos jogadores.

O intervalo de endereços IP é dividido em classes, onde os endereços IP Multicast estão na faixa entre 224000 e 239255255255.

Todo pacote direcionado a um endereço IP que comece com os bits 1110 é um pacote Multicast.

Os outros 28 bits identificam o grupo Multicast para o qual este pacote está sendo direcionado.

Mostra alguns endereços Multicast que são reservados para usos especiais.

O intervalo de 224000 até 22400255 é reservado para propósitos locais (tarefas administrativas e de manutenção), sendo que os pacotes destinados a eles nunca atravessam o roteador Multicast.

Igualmente, o intervalo de 239000 até 239255255255 está reservado para tarefas administrativas em geral, não necessa riamente para tarefas locais.

Logo, o intervalo que deve ser usado para aplicações Multicast geralmente é o intervalo de 224010 até 238255255255.

Um grupo Multicast é formado pelo conjunto de hosts de uma rede que compartilham dados através de uma transmissão Multicast.

Esses grupos são identificados por um endereço Multicast.

Cada emissor envia pacotes para um endereço de grupo ao qual estão associados diversos receptores.

Estes revceptores, por sua vez, podem se vincular e desvincular de forma dinâmica ao grupo Multicast.

Cabe aos dispositivos da rede e, em particular, aos roteadores determinar quais de suas interfaces possuem receptores participantes de um grupo Multicast e quais deverão receber uma cópia dos pacotes enviados para aquele grupo.

Dependendo da situação em que os hosts se encontram na rede, em relação ao suporte para transmissão Multicast, eles podem estar em três diferentes níveis de conformidade.

Nível 0 é o nível sem suporte para o Multicast.

Muitos hosts e roteadores na Internet estão nesta situação.

Neste nível, os hosts não podem enviar e nem receber pacotes Multicast e ignoram estes pacotes.

Nível 1 é o nível com suporte para envio de pacotes Multicast, porém sem suporte ao seu recebimento.

Não é necessário ser membro de um grupo Multicast para poder enviar pacotes Multicast.

Nível 2 é o nível com suporte completo para o Multicast.

Neste nível os hosts podem enviar e receber pacotes via conexão Multicast.

Basta saber como entrar e sair do grupo Multicast e como propagar a informação para os roteadores.

A seguir estão resumidos alguns benefícios do uso do Multicast.

Desempenho Otimizado da Rede, o uso inteligente dos recursos da rede evita replicação desnecessária de pacotes.

Uma melhor utilização do canal é obtida através de uma arquitetura mais eficiente para distribuição de dados, tornando melhor o desempenho da rede.

Escalabilidade, serviços que usam o Multicast podem ser acessados por vários hosts ao mesmo tempo e podem aceitar novos membros no grupo a qualquer momento.

A facilidade da inclusão de membros no grupo e a eficiência de transmissão tornam o Multicast um protocolo escalável.

A principal característica do Multicast é fato de o envio dos pacotes de um emissor para múltiplos receptores ser feita em uma única operação de transmissão.

Portanto, não é viável o uso do protocolo TCP, uma vez que neste protocolo é necessário o estabelecimento de conexões ponto a ponto.

Devido a esta característica, o Multicast é suportado pela camada de transporte através do protocolo UDP.

Cada pacote pode trafegar por um caminho diferente do emissor até o receptor, podendo chegar fora de ordem.

Para resolver este problema, se faz necessário um algoritmo de ordenação de pacotes.

Além do problema da entrega não ordenada dos pacotes, existe a possibilidade de perda de pacotes, tornando o protocolo Multicast não confiável.

Para resolver os problemas gerados pela não confiabilidade do protocolo Multicast, devido à transmissão UDP, é necessária a criação de mecanismos, no nível da aplicação, garantindo assim a confiabilidade na transmissão dos dados.

A criação de uma camada acima da camada de redes, o protocolo Multicast Confiável, com a função de detectar perdas de pacotes e recuperar eficientemente os pacotes perdidos, torna a transmissão confiável.

As aplicações Multicast possuem diferentes exigências em relação à confiabilidade.

Por exemplo, algumas aplicações exigem que a entrega dos dados seja feita com ordenação total, outras podem não fazer esta exigência.

Assim como, algumas aplicações possuem muitos emissores de dados e outras, apenas um emissor.

Em certas aplicações, todos os membros armazenam os dados enviados pelo emissor, podendo assim retransmitir um dado a qualquer momento, outras restringem a retransmissão ao emissor.

Algumas aplicações exigem que o usuário tenha conhecimento de todas as informações trocadas durante uma sessão Multicast, outras permitem que o usuário entre na sessão a qualquer momento, sem a necessidade do conhecimento das informações trocadas antes de sua entrada.

Todas estas diferentes exigências que as aplicações fazem em relação a confiabilidade afetam o projeto do protocolo Multicast Confiável.

A melhor maneira, segundo, de satisfazer todas as exigências das diversas aplicações é construir um protocolo Multicast que satisfaça o máximo de aplicações possíveis ao mesmo tempo, segundo uma definição mínima de confiabilidade Multicast e, deixar que as aplicações implementem suas funcionalidades específicas para garantir a confiabilidade na transmissão Multicast.

A implementação de funcionalidades, como um algoritmo de ordenação, torna-se simples para a aplicação, por estarem sendo implementadas em cima do protocolo Multicast Confiável, que garante a confiabilidade de um modo geral.

Existem diferentes maneiras de se implementar um protocolo Multicast Confiável, já que a responsabilidade da detecção e da recuperação dos dados perdidos pode ser do emissor ou do receptor.

Serão explicadas as três classes de protocolo Multicast Confiável.

Protocolo Sender-Initiated, onde as detecções de perdas são responsabilidade do emissor.

Confirmações (acknowledgments ou ACKs) são enviadas pelos receptores e processadas pelos emissores.

Protocolo Receiver-Initiated, onde as detecções de perdas são responsabilidade do receptor.

Os pedidos de retransmissões, NACKs (negative acknowledgments), são enviados via conexão Unicast para o emissor.

Protocolo Enhanced-Receiver-Initiated, onde as detecções de perdas também são responsabilidade do receptor, porém os NACKs são enviados via conexão Multicast para o grupo.

Encontra-se a análise de desempenho destas classes, onde são avaliados a vazão e o atraso para recuperação dos dados, segundo estudos realizados.

Logo a seguir é feita uma análise do Multicast implementado na aplicação.

O protocolo Sender-Initiated requer que o emissor mantenha uma lista dos ACKs recebidos para cada dado enviado, com a identificação dos receptores cuja confirmação (ACK) foi recebida pelo emissor.

Todos os receptores, ao receberem um pacote de dados, enviam ao emissor um ACK, via conexão Unicast, informando que o pacote de dados foi recebido com sucesso.

Este emissor atualiza a lista ACK, indicando que o receptor recebeu um determinado pacote enviado.

Segundo a transmissão de dados, um servidor de dados assume o papel de emissor e transmite pacotes para os quatro membros receptores.

As nuvens representam o caminho que os pacotes percorrem entre um roteador e outro.

Nota-se uma perda entre o roteador 1 e o roteador 2, ou seja, os membros C e D não recebem o pacote de dados enviados pelo servidor.

Os membros A e B ao receberem o pacote, enviam os ACKs para o servidor.

A recuperação dos dados perdidos é tratada através do uso de temporizadores.

O temporizador é ajustado para um intervalo de espera pelos ACKs de cada pacote no momento em que o emissor transmite um pacote de dados.

Se todos os ACKs forem recebidos antes do intervalo, determinado pelo temporizador chegar ao fim, o emissor considera que todos os receptores receberam o pacote de dados com sucesso e o temporizador é desligado.

Porém, se o intervalo expirar antes do emissor ter recebido os ACKs de todos os receptores, ele considera que um ou mais receptores não receberam o pacote de dados transmitido, retransmitindo, via conexão Multicast, o dado detectado como perdido e ajustando o temporizador para um novo intervalo de espera.

É necessário que o emissor tenha conhecimento de todos os receptores que estão participando da sessão Multicast para controlar os ACKs recebidos.

Portanto, as entradas e as saídas dos membros de uma sessão Multicast devem ser explicitamente notificadas ao emissor, evitando que haja retransmissões de dados desnecessariamente.

O emissor, ao receber um ACK, tem a certeza de que o receptor recebeu o pacote de dados enviado.

Portanto, após o recebimento dos ACKs de todos os usuários, o emissor pode excluir este dado da memória.

Esta é uma vantagem do protocolo Sender-Initiated.

Porém, como a cada pacote enviado espera-se receber ACKs de todos os receptores, tem-se um aumento considerável do número de mensagens necessárias para manter a transmissão confiável, podendo sobrecarregar o emissor com o processamento dos ACKs recebidos.

Quanto maior for o número de receptores, maior será o processamento no emissor, prejudicando a escalabilidade do protocolo Multicast, o que pode não ser interessante em algumas aplicações Multicast.

Além disso, como as mensagens de ACKs também estão sujeitas a perdas, podem ocorrer retransmissões desnecessárias dos pacotes.

O protocolo XTP é um exemplo de protocolo Sender-Initiated.

Devido a este problema de implosão de ACKs, dois outros protocolos foram v propostos, os protocolos baseados em árvore e em anel.

O protocolo baseado em árvore delega a responsabilidade da recuperação de dados a alguns receptores, organizando-os em uma árvore.

Como pode ser observado, o emissor é a raiz da árvore e os receptores são divididos em grupos, ou seja, sub-árvores, onde as raízes são os receptores que assumem o papel de líderes.

Os líderes se tornam responsáveis pelo recebimento dos ACKs locais do grupo de receptores da sub-árvore da qual ele é a raiz.

Um receptor "filho" envia o ACK diretamente para o receptor líder, assim que o pacote de dados é recebido com sucesso.

Note que este receptor "filho" também pode possuir receptores "filhos", porém este não espera o recebimento dos ACKs de seus "filhos" para enviar o ACK ao receptor líder.

O fato do receptor "filho" ter recebido o pacote de dados com sucesso, já garante aos seus "filhos" a retransmissão, caso algum deles tenha perdido o pacote.

O ACK pode ser enviado ao receptor líder imediatamente.

Porém, o dado deverá ser mantido na memória até que todos os receptores "filhos" tenham enviado seus ACKs, garantindo assim a retransmissão em caso de perda.

Esta estrutura em árvore previne que receptores tenham contato direto com o emissor, mantendo a escalabilidade do protocolo.

A escolha dos receptores líderes deve ser feita de maneira eficiente para que este mecanismo tenha um bom desempenho.

O protocolo Tree-NAPP (NACK-avoidance and periodic polling) é uma subclasse do protocolo baseado em árvore, onde ACKs são enviados periodicamente confirmando os dados recebidos com sucesso e, NACKs são enviados requisitando dados perdidos.

O líder envia as retransmissões apenas para a sub-árvore pela qual ele é responsável.

O Tree-based Multicast Transport Protocol (TMTP) é um exemplo de protocolo Tree-NAPP.

Outro exemplo de protocolo baseado em árvore é o RMTP (Reliable Multicast Transport Protocol).

O protocolo baseado em anel também tem como objetivo delegar a responsabilidade da recuperação de dados para os receptores.

Este protocolo combina as vantagens do uso de NACKs com a confiabilidade do uso de ACKs.

A cada momento somente um receptor estará com o token, tornando-o responsável pelo envio, via conexão Multicast, do ACK e pela retransmissão de dados, via conexão Unicast, caso seja necessário.

Este token é passado através do anel de receptores.

Se o tempo de espera por confirmação de pacote de dados recebidos com sucesso expirar antes do emissor ter recebido o ACK do receptor com o token, o emissor retransmite o dado perdido.

O emissor somente apagará um dado da memória quando tiver recebido o ACK do receptor com o token, e neste momento ele passa a estar habilitado para envio de novos dados, ou seja, um novo dado somente é enviado após o recebimento do ACK.

Caso os outros receptores detectem uma perda, devido ao recebimento de um pacote de dados fora de sequência, estes enviam um NACK, via conexão Unicast, para o receptor com o token.

O Reliable Multicast Protocol (RMP) é um exemplo de protocolo baseado em anel.

No protocolo Receiver-Initiated, a confiabilidade na transmissão dos dados é responsabilidade do receptor.

Quando um receptor detecta que perdeu algum pacote de dados, ele envia ao emissor, via conexão Unicast, uma mensagem NACK, indicando que houve perda na transmissão dos dados e solicitando sua retransmissão.

O emissor ao receber um NACK, retransmite o(s) dado(s) requisitado(s) via conexão Multicast.

Assumindo o mesmo cenário de perda, os membros C e D detectam a perda ocorrida entre os roteadores 1 e 2 e enviam seus NACKs para o emissor.

Para se precaver das perdas dos NACKs e das retransmissões, o protocolo Receiver-Initiated possui um processo de temporização análogo ao processo do protocolo Sender-Initiated.

O temporizador é ajustado para um intervalo de espera pela retransmissão no momento em que o receptor envia o NACK.

Se a retransmissão for recebida antes do intervalo de tempo chegar ao fim, o temporizador é desligado.

Porém, se o intervalo expirar antes do receptor ter recebido a retransmissão do emissor, ele considera que houve uma perda da retransmissão ou da própria mensagem NACK enviada, retransmitindo o NACK e ajustando o temporizador para um novo intervalo de espera.

A perda de um pacote de dados é detectada a partir do número de sequência (sn, sequence number) que identifica os pacotes enviados pelo emissor.

Quando um receptor recebe um pacote de dados, ele verifica se possui todos os pacotes com o sn inferior ao sn do pacote recebido.

Por exemplo, se o receptor recebe um pacote com o sn = i +1 e verifica que não recebeu o pacote com o sn i, a perda é detectada.

Esta forma de detectar a perda pode falhar caso o pacote de dados perdido seja o último enviado pelo emissor.

Suponha que um membro A envie um pacote de dados com o sn = 3 e que um membro B tenha perdido este pacote.

O membro B não detectará a perda até que receba um novo pacote de dados do membro A, mas se este não voltar a enviar novos dados, o membro B terá que encontrar uma outra forma de detectar a perda.

Portanto, podem ser enviadas pelo emissor mensagens de controle notificando o sn do último pacote de dados enviado por ele.

Como a probabilidade de perda de pacotes, em geral, é menor que a probabilidade de sucesso no recebimento, a quantidade de mensagens de controle de recebimento (neste caso, os NACKs) enviadas pelos receptores ao emissor é menor do que no protocolo Sender-Initiated, diminuindo o overhead e reduzindo o processamento no emissor.

O emissor só retransmite um dado caso tenha recebido um NACK, ou seja, não há retransmissões desnecessárias, o que tende a reduzir o número médio de retransmissões por pacote.

Outra vantagem deste protocolo é o fato de que nenhum membro precisa ter o controle de todos os membros do grupo Multicast, podendo ter o conhecimento somente do membro emissor, pois será necessário para a retransmissão do pacote.

Apesar das vantagens descritas acima, também é possível analisar algumas desvantagens deste protocolo.

Como o NACK é enviado pelo receptor, via conexão Unicast, somente o emissor é notificado da perda, restringindo a este, a responsabilidade da retransmissão do pacote perdido.

Outra desvantagem é o fato do emissor não ter a certeza do recebimento dos dados por parte dos receptores, tornando-se complicado saber o momento em que um dado pode ser excluído da memória.

O protocolo Enhanced-Receiver-Initiated é uma variação do Receiver-Initiated.

A confiabilidade na transmissão dos dados continua sob a responsabilidade do receptor, porém o NACK é enviado via conexão Multicast, acrescentando a este protocolo algumas vantagens significativas.

A perda de um pacote é detectada a partir do sn dos pacotes enviados pelo emissor, da mesma forma que é feito no protocolo Receiver-Initiated.

Os receptores enviam os NACKs via conexão Multicast, tornando possível a retransmissão do pacote por parte de qualquer um dos membros que tenha o pacote de dados requisitado.

Distribuindo a responsabilidade de retransmissão dos dados, possibilita a redução do tempo de recuperação de um pacote caso o membro que retransmita o dado esteja mais próximo do requisitante do que o membro emissor.

Por exemplo, se na transmissão representada, a perda tivesse ocorrido entre o roteador 2 e o membro C, o membro D poderia retransmitir o dado antes do emissor.

O fato de vários membros poderem retransmitir simultaneamente o pacote solicitado, pode causar um excessivo aumento do tráfego.

Assim como, quando vários receptores perdem o mesmo pacote de dados, vários NACKs são enviados pela rede, também podendo causar o aumento do tráfego, problema conhecido como implosão de NACKs.

Para evitar a implosão de NACKs, quando detectada a perda de um pacote, o receptor não envia o NACK imediatamente, mas somente após expirar o intervalo de tempo determinado pelo temporizador.

Caso o receptor receba algum NACK, durante este intervalo de tempo, referente ao mesmo NACK que está escalonado, o envio do NACK é cancelado.

Neste caso, o envio do NACK é suprimido, pois algum outro membro já fez a requisição de retransmissão para este pacote perdido, e o receptor passa a agir como se tivesse mandado o NACK, ou seja, fica esperando pela retransmissão durante um intervalo de tempo.

Porém, se nenhum NACK for recebido até o intervalo de tempo expirar, então o receptor envia o NACK.

Com este mecanismo de supressão de NACKs, os receptores distantes do emissor podem nunca precisar enviar um NACK, visto que os receptores mais próximos ao emissor podem detectar a perda e enviar NACKs antes dos receptores mais distantes, anulando o envio dos NACKs destes.

Protocolos baseados no receptor que utilizam supressão de NAKs são denominados protocolos RINA (Receiver Initiated with Nak Avoidance).

Mostra o processo de supressão de NACKs, supondo que os membros D e C disparam seus temporizadores para envio dos NACKs, e que o temporizador do membro C expira primeiro, enviando o NACK.

O membro D ao detectar que o membro C já enviou um NACK para o mesmo pacote que pretendia enviar, cancela o envio do NACK.

Após o envio do NACK, o receptor espera durante um intervalo de tempo pela retransmissão, como no protocolo Receiver-Initiated.

Caso a retransmissão não chegue, o receptor considera que houve uma perda da retransmissão ou da própria mensagem NACK enviada e escalona o NACK para ser enviado novamente.

De maneira análoga ao processo de temporização feito para o envio de um NACK, uma retransmissão também não é enviada imediatamente, tentando-se evitar o aumento excessivo do tráfego.

Quando um membro recebe um NACK requisitando um pacote de dados que ele tenha recebido, ele escalona o envio da retransmissão para algum tempo no futuro.

Caso ele não receba nenhuma retransmissão para o mesmo pacote de dados até o intervalo de tempo expirar, a retransmissão é enviada.

Do contrário, ele cancela o envio da retransmissão, pois algum outro membro já a fez.

Além das vantagens apresentadas pelo protocolo Receiver-Initiated, o protocolo Enhanced-Receiver-Initiated limita o número de NACKs enviados pela rede com o mecanismo de supressão de NACKs.

O SRM (Scalable Reliable Multicast), protocolo genérico para transmissões Multicast confiável e o LBRM (Log-based Receiver-Reliable Multicast) são exemplos de protocolos Enhanced-Receiver-Initiated.

Apesar das vantagens, a implementação destes métodos, onde a confiabilidade na transmissão é responsabilidade do receptor, é mais complexa do que no método onde o responsável pela confiabilidade é o emissor.

Isso ocorre porque é necessário um bom ajuste dos temporizadores utilizados.

Grandes valores para os temporizadores tendem a reduzir o tráfego gerado na rede, mas, por outro lado, aumentam o intervalo de tempo desde a emissão de um dado pelo emissor até a sua chegada, com sucesso, em todos os membros do grupo.

O comportamento inverso pode ser observado se pequenos valores forem utilizados para os temporizadores.

Um estudo preliminar deste comportamento foi feito, onde foi construído um modelo com o objetivo de avaliar a sensibilidade das medidas de interesse (o número de retransmissões e o retardo para a recuperação dos pacotes) à variação dos intervalos dos temporizadores.

No Capítulo 6 também será feita uma análise mais detalhada da sensibilidade das medidas de interesse à variação dos intervalos dos temporizadores.

Nas Seções anteriores foram apresentadas alternativas para a confiabilidade Multicast, baseadas no emissor e no receptor.

São apresentados estudos analíticos onde são avaliados a vazão e o atraso para recuperação dos dados de cada uma destas alternativas.

Os modelos analíticos definidos para estes estudos possuem diversas simplificações, como por exemplo, assume-se a estrutura de um emissor e vários receptores, todos com a mesma probabilidade de perda.

Segundo os experimentos observados, supondo que a perda no backbone Multicast e a perda entre o emissor e o backbone são pequenas, é assumido que as perdas entre os receptores são independentes no espaço e no tempo.

Supõe-se também que as transmissões dos ACKs e dos NACKs sejam confiáveis, nunca havendo perdas destas mensagens.

A análise da vazão avalia duas classes de aplicações, um-para-muitos, onde somente um membro envia os dados para os demais e muitos-para-muitos, onde todos os membros podem enviar e receber dados uns dos outros.

O objetivo é computar a quantidade de tempo de processamento requerido para um pacote ser enviado com sucesso pelo emissor a todos os receptores.

Este tempo de processamento inclui a quantidade de tempo necessária para enviar um dado, uma retransmissão, ACKs ou NACKs e os intervalos de tempo do temporizador antes do envio de alguns destes pacotes.

A taxa máxima que um membro pode processar um pacote vai ser calculada de acordo com o tempo de processamento, e a vazão máxima de um protocolo pode ser determinada a partir destas taxas de processamento.

O desempenho do protocolo Sender-Initiated é dependente do número de membros no grupo Multicast, pois com o aumento do número de membros, a taxa de processamento dos emissores aumenta, devido ao aumento dos ACKs que terão que ser processados.

Portanto, os protocolos baseados no receptor são mais escaláveis uma vez que a taxa de processamento é independente do número de membros.

Foi demonstrada a superioridade de desempenho dos protocolos Receiver-Initiated e Enhanced-Receiver-Initiated em relação ao protocolo Sender-Initiated.

O protocolo Enhanced-Receiver-Initiated tem o melhor desempenho para aplicações um-para-muitos, enquanto o protocolo Receiver-Initiated tem o melhor desempenho para aplicações muitos-para-muitos.

Isso se deve ao fato do envio dos NACKs, via conexão Multicast, adicionar uma complexidade nas funcionalidades do receptor, que no caso das aplicações muitos-para-muitos ainda tem a funcionalidade de enviar dados.

A pesquisa feita confirma os estudos citados anteriormente sobre o desempenho dos protocolos segundo análise da vazão, acrescentado o estudo do desempenho dos protocolos baseados em árvore.

Nos resultados obtidos foi mostrado que os protocolos baseados em árvore têm melhor desempenho que os demais, ficando o protocolo Enhanced-Receiver-Initiated em segundo lugar.

O foco de análise é o comportamento do atraso em relação ao número de receptores, a propagação do atraso na rede e aos valores dos temporizadores.

Visto que o atraso pode ser influenciado por muitos fatores, incluindo o tempo de processamento de um pacote pelos membros, o tempo de propagação na rede, a probabilidade de perda dos pacotes e os valores escolhidos para os temporizadores.

Sob esta análise, mais uma vez foi mostrada a superioridade do Enhanced-Receiver-Initiated em relação aos protocolos Receiver-Initiated e Sender-Initiated.

Existem muitos projetos de pesquisa com o objetivo de construir uma aplicação que provê serviços Multicast sem requerer o suporte direto dos roteadores, transferindo a responsabilidade do Multicast para a aplicação.

Algumas características do IP Multicast levaram à implementação de aplicações Multicast sobre o protocolo IP Unicast.

São elas o roteador precisa manter uma tabela com o estado de todos os membros do grupo Multicast, introduzindo complexidade e problemas de escalabilidade ao roteador, qualquer emissor pode enviar uma mensagem para um grupo Multicast, tornando a rede vulnerável a ataques de emissores maliciosos, complicando o seu gerenciamento, prover confiabilidade, controle de congestionamento, controle de fluxo e segurança tem sido mais difícil do que no caso do Unicast, que usa o protocolo TCP.

Estas aplicações, provedoras de serviços Multicast, podem ser chamadas de End System Multicast.

Os membros do grupo Multicast se organizam em uma árvore para entrega dos dados.

Cada aresta da árvore corresponde a uma conexão Unicast TCP entre dois membros do grupo.

O protocolo TCP provê uma conexão confiável, com segmentação dos dados a serem enviados pela aplicação, controle de recebimento através de mensagens ACKs enviadas pelo receptor e controle de fluxo através do uso de buffers, onde o receptor avisa ao emissor o quanto de espaço nos buffers ele tem disponível para recebimento dos dados.

Mostra um exemplo de End System Multicast, onde os membros A, B, C e D são os sistemas finais (end systems).

Um dos desafios das aplicações Multicast é prover métricas para que os membros se organizem na árvore de forma eficiente, adaptando-se às mudanças da rede e mantendo o desempenho da aplicação.

Cada protocolo pode possuir métricas variadas para a organização de forma dinâmica dos membros na árvore.

Os protocolos propostos apenas consideram o atraso como métrica de adaptação, enquanto os protocolos propostos além de considerarem o atraso também consideram o stress no canal como métrica, ou seja, o número de pacotes duplicados trafegando pelo canal.

Nas aplicações End System Multicast sempre haverá pacotes duplicados no canal, visto que é impossível evitar que as arestas da árvore passem pelo mesmo canal físico da rede.

Por exemplo, o uso de Multicast na aplicação diminui o número de pacotes por canal, em relação à transmissão Unicast nativa, que exigiria o envio de três pacotes de dados no canal entre o emissor A e o roteador 1, e que com o uso do Multicast na aplicação este número diminui para dois, porém ainda mantém a duplicação no canal.

Ainda podemos perceber o aumento do atraso entre os membros do grupo em relação ao IP Multicast.

Se a transmissão tivesse sido feita via IP Multicast, ou seja, diretamente do emissor A para o receptor D, o atraso seria de 27 unidades de tempo.

Porém, com o uso do Multicast na aplicação o atraso aumenta para 29, uma vez que o emissor A envia o pacote de dados para o receptor C e este repassa o pacote para o receptor D.

Os principais pontos a serem considerados, na solução proposta, são o aumento do atraso e o número de pacotes duplicados atravessando os canais da rede.

Com isso, a implementação do Multicast na aplicação pode não ser aconselhável em casos onde grandes atrasos não são toleráveis e em situações onde a duplicação de pacotes nos canais é prejudicial ao desempenho da rede.

Neste capítulo é apresentado o Tangram II Whiteboard, uma ferramenta distribuída, que requer o uso de uma transmissão Multicast confiável.

São descritas algumas características desta ferramenta com o objetivo de ressaltar suas vantagens, as quais não são encontradas nas demais ferramentas disponíveis atualmente.

O crescimento e o progresso das redes de computadores facilitaram o desenvolvimento de ferramentas com aplicação distribuída.

O objetivo destas ferramentas é manter a comunicação entre os usuários em diferentes localizações na rede.

O Tangram II Whiteboard (TGWB) é um exemplo deste tipo de ferramenta, cuja finalidade é permitir que um grupo de usuários, em locais distintos, compartilhe a mesma área gráfica.

As aplicações do TGWB são muito amplas, podendo ser usado em teleconferências e no ensino à distância, ou até mesmo no desenvolvimento em equipe de sistemas à distância.

Ilustra as interfaces de dois usuários da ferramenta TGWB, onde tudo que foi desenhado na primeira interface foi recebido com sucesso pela segunda interface.

Um dos pontos cruciais para o desenvolvimento de uma ferramenta whiteboard é a garantia da consistência entre as informações de cada um dos usuários.

Portanto, duas funcionalidades devem estar presentes na implementação de uma ferramenta whiteboard, 1 a detecção e a recuperação eficiente dos dados perdidos, 2 a execução dos comandos gráficos na mesma ordem para todos os usuários do grupo.

Para garantir a consistência dos dados, segundo a primeira funcionalidade descrita acima, a ferramenta whiteboard precisa utilizar um mecanismo de comunicação Multicast confiável.

Sendo assim, o TGWB utiliza a biblioteca Multicast Confiável (RML), desenvolvida no âmbito desta pesquisa, para garantir que a comunicação de dados seja feita de forma confiável, ou seja, que todos os usuários recebam as mesmas informações.

A biblioteca RML é apresentada com detalhes no Capítulo 4.

A segunda funcionalidade envolve o conceito de ordem entre eventos distribuídos.

Se cada usuário executar o mesmo conjunto de comandos recebidos em ordem diferente, eles chegarão a um estado de inconsistência.

Mostra um exemplo de inconsistência de dados gerada devido à execução de comandos em ordens diferentes.

Neste exemplo, o usuário A recebe os desenhos na seguinte ordem, primeiro o triângulo, depois o quadrado e por último o texto "X".

E o usuário B recebe os desenho em uma ordem diferente do usuário A, primeiro o triângulo, depois o texto "X" e por último o quadrado.

A ordem de recebimento e execução dos desenhos pelo usuário B faz com que o texto fique atrás do quadrado, criando um desenho diferente do usuário A.

Para evitar o problema da inconsistência, o TGWB implementou um algoritmo de ordenação única dos comandos recebidos para todos os membros do grupo.

Existem diversos trabalhos sobre whiteboard na literatura.

A maioria destes trabalhos disponibilizam recursos limitados para edição gráfica, além de restringirem o comportamento do usuário para simplificar problemas relacionados à ordem de execução dos comandos.

É apresentado um whiteboard, onde o problema de consistência entre os estados dos usuários é simplificado, não permitindo que um usuário modifique os objetos criados por outros usuários.

Desta forma, o aplicativo não aborda o problema de ordenação dos comandos.

O whiteboard apresentado também não permite que um usuário modifique os objetos criados por outro.

Neste whiteboard, conhecido por MediaBoard, quando um novo usuário deseja entrar na sessão Multicast, ele não será capaz de recuperar os dados de usuários que já saíram da sessão.

Suponha uma sessão Multicast inicialmente com os usuários A e B, e que o usuário C entre no grupo depois que os primeiros usuários tenham trocado algumas informações e que o usuário A já tenha saído da sessão.

O usuário C não será capaz de recuperar os dados enviados pelo usuário A, pois o usuário B retransmitirá somente seus próprios dados, tornando as interfaces dos usuários B e C inconsistentes.

Uma outra característica do MediaBoard é a apresentação imediata na interface dos dados recebidos, mesmo havendo perdas no recebimento.

Por exemplo, se ao receber o texto "Recebimento coerente dos dados" a palavra "coerente" é perdida, mesmo assim o restante da frase é mostrado na interface.

A perda de letras também não impede que o texto apareça na interface antes da recuperação total da frase.

Por exemplo, se a letra "a" da palavra "dados" for perdida, a palavra "ddos" aparecerá na interface até que a letra "a" perdida seja recuperada e a palavra ou a frase correta seja mostrada na interface.

O TGWB somente mostra um objeto na interface quando todos os dados perdidos, referentes a este objeto, forem recuperados, de modo que o objeto apareça por inteiro na interface, e não apenas parte dele.

Durante os testes feitos com o objetivo de testar seu desempenho, o MediaBoard se mostrou bastante instável.

Por exemplo quando um usuário sai do grupo Multicast e depois decide entrar novamente, a execução da ferramenta de todos os demais usuários do grupo é cancelada imediatamente.

Outro exemplo de ferramenta whiteboard é o Microsoft NetMeeting, onde o Multicast é simulado, ou seja, múltiplas conexões Unicast são estabelecidas para o envio dos dados a um grupo de receptores.

Como foi visto no Capítulo 2, o uso de Multicast simulado pela aplicação pode não ser a maneira mais eficiente de distribuição de dados a um grupo de receptores, uma vez que pode aumentar o número de pacotes no canal e o atraso na entrega dos pacotes.

A ferramenta TGWB mantém interface com o usuário através do editor gráfico TGIF (Tangram Graphic Interface Facility).

O TGIF é um poderoso aplicativo para edição gráfica baseada em objetos.

Neste aplicativo um desenho é criado a partir de objetos primitivos, tais como linhas, circunferências, polígonos, etc.

Um objeto pode ser construído a partir do agrupamento de outros objetos.

Os objetos podem possuir vários tipos de textura e suportar diversas alterações como rotação e escala, além de suportar a criação e a edição de texto, permitindo a criação de slides e transparências para apresentações.

O TGIF também é usado pela ferramenta de modelagem e análise de sistemas, TANGRAM II, que será apresentada no Capítulo 4.

O TGWB faz parte do conjunto de ferramentas TANGRAM II que, juntamente com um aplicativo de voz desenvolvido e um servidor de vídeo, fornecerão um conjunto poderoso de ferramentas de teleconferência e de ensino à distância.

A ferramenta TGWB permite que os usuários modifiquem o mesmo objeto, ou seja, se o usuário A desenhar um quadrado, não somente ele, mas qualquer outro usuário do grupo pode modificar este quadrado, seja aumentando seu tamanho, mudando sua cor, ou até mesmo removendo o quadrado da interface.

Uma ferramenta que possui esta característica deve possuir um algoritmo de ordenação dos dados para que os comandos recebidos dos diversos usuários sejam executados na mesma ordem para todos eles, mantendo a consistência global do dados.

Assim, o quadrado citado anteriormente deverá chegar ao mesmo estado final em todas as máquinas, depois de todas as modificações sofridas pelos diversos usuários.

O funcionamento do TGWB é baseado em trocas de mensagens.

Todo comando executado por um usuário na interface gráfica local (TGIF) é codificado e enviado a todos os demais usuários do grupo através de uma mensagem.

Quando uma mensagem é recebida, o comando é decodificado e executado localmente como se fosse um comando gerado pelo próprio usuário receptor da mensagem.

Desta forma, todos os comandos gerados pelos usuários em uma sessão são executados localmente no aplicativo TGWB de cada um.

As mensagens do TGWB são trocadas através da biblioteca Multicast RML (a ser apresentada no Capítulo 4).

O TGWB também faz a segmentação dos pacotes antes do envio dos dados trocados em uma sessão Multicast, devido à limitação em relação ao tamanho dos pacotes que podem trafegar pela rede.

Nem todos os roteadores da rede possuem um algoritmo de segmentação de pacotes, eliminando os pacotes que excedem o limite de tamanho suportável pelo roteador.

Portanto, se faz necessário um algoritmo de segmentação dos dados antes de seu envio pela rede.

Esta segmentação garantirá que os pacotes possam passar em todos os roteadores da rede sem o risco de serem eliminados por causa do seu tamanho.

Se um usuário deseja enviar uma imagem muito grande para o grupo, esta imagem deve ser segmentada em pacotes suficientemente pequenos antes de ser enviada pela rede.

O tamanho do segmento é escolhido de modo que a maioria dos objetos caibam em apenas um segmento e que, ao mesmo tempo, este segmento seja menor que a unidade máxima de transferência (MTU).

As mensagens trocadas durante uma sessão são recebidas através do IP Multicast, e a confiabilidade na transmissão Multicast é tratada pela biblioteca RML.

No aplicativo TGWB é feita a segmentação/remontagem e ordenação dos dados recebidos para serem mostrados na tela do usuário, via interface TGIF.

Nesta seção é descrito o processo de ordenação dos comandos.

Uma vez que a camada de confiabilidade Multicast é implementada abaixo da camada de ordenação de comandos, o TGWB assume que os dados recebidos são confiáveis, ou seja, todas as perdas já foram recuperadas anteriormente.

A consistência de dados entre os usuários é garantida se todos os usuários executarem os comandos recebidos na mesma ordem.

A abordagem utilizada para resolução do problema de inconsistência de dados é a mesma usada para análise de uma computação distribuída genérica.

Os usuários representam os nós desta computação e os comandos são eventos gerados por estes nós.

Desta forma, o problema se resume à ordenação de eventos gerados distribuidamente.

Formalização do Problema de Inconsistência de Dados A computação distribuída pode ser analisada como a execução de um conjunto de eventos, denotado por ", onde os eventos são considerados a unidade fundamental da computação.

No caso do TGWB, o evento é representado pela geração de um comando na interface da ferramenta e pode ser definido pela tupla.

A definição de evento apresentada através da tupla é bastante geral, onde a definição do conjunto de mensagens fica a critério da aplicação distribuída que está empregando a definição.

No TGWB este conjunto de mensagens pode ser definido por comandos que se referem ao mesmo objeto ou que atuam sobre a mesma área gráfica na interface.

Uma vez que a mensagem m, enviada por um nó ao gerar um evento, pode pertencer ao conjunto de mensagens que influenciam a geração de eventos em outros nós, dizemos que os eventos em " estão fortemente inter-relacionados.

A relação é definida sobre o conjunto de eventos.

Definição 1, se 1 e 2 são eventos, então se, e somente se uma das seguintes condições é satisfeita 1 e 2 são gerados pelo mesmo nó, respectivamente, com tempos locais fi 1 e fi 2, tal que fi 1 < fi 2.

E nenhum outro evento ocorre neste nó no tempo fi, tal que fi 1 < fi < fi 2 ii 1 e 2 são gerados em nós distintos e a mensagem m, enviada em decorrência de 1, pertence ao conjunto de mensagens de 2 A condição expressa o conceito intuitivo de causalidade que existe entre eventos gerados pelo mesmo nó, enquanto que a condição representa a relação de causa-efeito existente entre eventos gerados por nós distintos.

Exibe o grafo de precedência, definido pela relação, para a execução de uma computação distribuída.

O grafo H é um grafo acíclico direcionado, em que o conjunto de nós é definido pelo conjunto de eventos, e suas arestas são determinadas pelos pares de eventos relacionados.

A denotação estabelece uma ordem parcial para o conjunto de eventos.

Dois eventos estão relacionados se existir um caminho entre eles no grafo de precedência H.

O par de eventos (a1, c3) é um exemplo de eventos relacionados, pois o evento c3 só pode ser executado depois que acontecer o evento a1.

Dois eventos 1 e 2 que não estejam relacionados são ditos eventos concorrentes.

Os eventos a1 e c1 são exemplos de eventos concorrentes.

A relação pode ser usada para definir os conceitos de passado e futuro de um evento.

Inicialmente bastaria executar os comandos de acordo com os conjuntos Passado e Futuro, definidos acima, para garantir a consistência entre os usuários de uma sessão TGWB, utilizando-se a seguinte regra.

Regra 1, "O comando associado ao evento deve ser executado após a execução de todos os eventos pertencentes ao conjunto Passado, e antes da execução dos eventos pertencentes ao conjunto Futuro.

Porém, os conjuntos Passado e Futuro foram definidos a partir da relação de ordem parcial.

Ainda podem existir eventos que não pertençam a nenhum destes conjuntos, ou seja, os eventos concorrentes ao evento.

Se for estabelecida uma ordem única, a ser utilizada por todos os nós da sessão, para estes eventos concorrentes, então, pode ser alcançado um estado de consistência global entre todos os usuários.

Suponha o exemplo de inconsistência e detalhado, que representa uma sessão Multicast com três usuários.

O usuário A desenha um triângulo na sua interface e, consequentemente, é enviada aos demais usuários da sessão uma mensagem contendo este comando.

Após o recebimento do comando de desenho do triângulo ter sido recebida pelos usuários B e C, estes fazem, simultaneamente, desenhos distintos em suas interfaces.

O desenho do quadrado e o texto "X", criados por B e C, respectivamente, geram eventos concorrentes.

Caso o critério utilizado para definir a ordem de execução de eventos concorrentes seja a ordem de chegada das mensagens, os usuários chegariam a um dos estados de inconsistência, onde o estado final do usuário A depende de qual comando chegou primeiro, o comando vindo do usuário B ou o comando vindo do usuário C.

Para resolver este problema, é necessário ampliar para obter uma relação de ordem total representada.

Uma ordem total é uma ordem parcial em que, para todo 1, 2 2 ", existe uma das relações (1, 2) ou (2, 1).

A ordem total é obtida, incluindo os pares de eventos concorrentes.

Os eventos concorrentes não existem quando a ordem total é aplicada.

Portanto, os conjuntos Passado e Futuro são redefinidos de acordo com esta nova relação e a Regra 1 passa a garantir a consistência entre os usuários do TGWB.

A implementação da ordenação total de eventos é feita através de relógios lógicos, utilizando o algoritmo apresentado por Lamport.

Um relógio lógico é apenas uma maneira de associar um número a um evento.

A definição de relógio lógico deve ser baseada na relação de ordem entre os eventos.

É necessário que cada nó n i mantenha um contador C i, de modo que no momento da geração de um evento, C i seja o valor do contador C i neste instante.

Os contadores C i são atualizados de acordo com as seguintes regras.

R1, imediatamente após a geração de um evento, o nó n i incrementa seu contador de uma unidade.

R2, ao receber uma mensagem, o nó n i ajusta o seu contador para o valor maxfC i.

C(msg) + 1g onde C(msg) é o valor do contador do emissor da mensagem no momento de sua geração.

Este mecanismo oferece apenas uma relação de ordem parcial entre os eventos.

Como visto anteriormente, esta relação é insuficiente para garantir a consistência entre os usuários.

Portanto, é necessário estender este mecanismo para que ele suporte a relação de ordem total.

Se os valores dos relógios lógicos forem iguais, então, os eventos são concorrentes, por exemplo, os eventos a e b são concorrentes se e somente se C = C.

Isto só é possível se estes eventos forem gerados por nós distintos.

Para não haver concorrência entre os eventos, é necessário que cada nó n i possua uma identificação única, Id(n i), que pode ser por exemplo a combinação do endereço IP da máquina com o número do processo (PID).

Neste caso, pode ser definido uma ordem total para estes nós, segundo a Definição 3.

Definição 3, sejam a e b eventos gerados em n i e n j respectivamente.

Um algoritmo simples de execução dos comandos pode ser definido segundo a Regra 1 apresentada nesta seção, onde todo comando gerado ou recebido seja armazenado até que todos os comandos pertencentes ao seu passado tenham sido recebidos e executados, quando então ele poderá ser executado.

Porém, a execução deste simples algoritmo apresenta dois problemas 1 a lentidão para a aplicação, 2 a necessidade de detectar se todo o passado do comando já foi executado.

O primeiro problema consiste no retardo para execução de um comando, que não pode ser executado imediatamente após a sua geração, ou no recebimento, uma vez que deve esperar até que todos os comandos em seu passado sejam executados.

Esta espera pode aumentar significativamente o tempo de latência entre a geração do comando por um usuário e a sua execução em todas as interfaces.

Além disso, este algoritmo apresenta uma situação indesejável ao usuário, pois os comandos que ele gera em sua própria interface não são imediatamente executados, mas sim armazenados para futura execução.

Certamente, esta não é uma situação desejável para um aplicativo interativo como o whiteboard.

O segundo problema consiste em detectar se todo o passado de um determinado comando c já foi executado.

Este problema é um pouco mais complexo, pois os comandos pertencentes ao passado de c, gerados localmente, já se encontram todos executados ou armazenados.

Porém, os comandos pertencentes ao passado de c, gerados por outros usuários, tornam-se difíceis de serem detectados.

Devido aos dois problemas apresentados acima, foi implementada uma solução alternativa para a execução dos comandos.

O algoritmo implementado leva em consideração duas observações importantes, uma é que em muitos casos, apesar da relação determinar que um comando c 1 está no passado de um outro comando c 2, a troca da execução entre eles não afeta o resultado final.

Por exemplo, se os comandos se referirem a objetos distintos e atuarem sobre áreas diferentes na interface gráfica.

Outra observação é que a interface do TGWB, o editor gráfico TGIF, fornece o recurso para desfazer a execução dos comandos.

Desta forma, os comandos podem sempre ser desfeitos e executados novamente em uma ordem diferente.

Esta operação é chamada RollBack and Recovery.

O algoritmo de execução dos comandos foi definido levando em consideração as duas observações descritas acima.

A idéia principal é tentar executar os comandos imediatamente após seu recebimento.

Porém, quando o comando recebido se refere a algum objeto inexistente, este comando não pode ser executado imediatamente, sendo armazenado para futura execução e caracterizado como inconsistente.

Se ao chegar um novo comando for detectado que a ordem de execução utilizada transgride a ordem, ou seja, o valor do C i da mensagem recebida for menor que o valor do C i do último evento executado, então é feita a operação RollBack até o ponto onde o novo comando deve ser executado.

O novo comando é executado e os comandos que foram desfeitos são novamente executados através da operação Recovery.

Para isto, cada usuário deve manter uma lista com todos os comandos conhecidos por ele.

Esta lista é ordenada de acordo com o sistema de relógios lógicos e cada comando da lista pode se encontrar no estado executado ou inconsistente.

Quando um novo comando é recebido pelo usuário, seu ponto de inserção na lista de comandos é identificado.

Todos os comandos que se encontram antes deste ponto pertencem ao passado do novo comando e todos que se encontram depois deste ponto pertencem ao seu futuro.

De acordo com a Regra 1, o novo comando deve ser executado antes de todos os comandos em seu futuro.

Portanto, todos os comandos da lista que pertencem ao seu futuro são desfeitos e o novo comando executado e os comandos que foram desfeitos são novamente executados ou, finalmente executados, caso estivessem anteriormente em estado inconsistente.

Cada usuário do grupo envia periodicamente uma mensagem, informando qual o último comando gerado por ele.

Desta forma, os demais usuários podem detectar se já receberam todas as mensagens que pertencem ao passado de um determinado comando, podendo então eliminá-los da lista.

Com isso, pode ser evitado o crescimento desnecessário da lista de comandos.

Neste capítulo será apresentado o funcionamento da biblioteca Multicast Confiável, desenvolvida com o objetivo de recuperar eficientemente descartes de pacotes na rede durante a transmissão.

Inicialmente será explicado o funcionamento do protocolo, referente à entrada e à saída de membros em uma sessão Multicast.

Em seguida, é apresentada uma das estruturas de armazenamento dos dados (a cache).

E por fim, algumas características da biblioteca são descritas, dentre elas o mecanismo de detecção e recuperação de dados perdidos, a lista de eventos e o uso dos temporizadores para a supressão dos NACKs e das retransmissões.

Conforme visto no Capítulo 2, é necessária a implementação da confiabilidade na transmissão Multicast.

Após a realização de pesquisas na Internet com o objetivo de encontrar alguma biblioteca que tratasse da transmissão Multicast confiável, não foi encontrada nenhuma biblioteca disponível que funcionasse sem problemas.

Com isso, foi desenvolvida uma biblioteca com funções para garantir a confiabilidade na transmissão Multicast.

Esta biblioteca, chamada de Reliable Multicast Library (RML), pode ser vista como um protocolo em uma camada superior à camada de transporte, com a função de detectar perdas de pacotes e recuperar eficientemente os pacotes perdidos, tornando a transmissão confiável.

Qualquer aplicação que precisa da confiabilidade na transmissão Multicast pode usar a biblioteca RML.

A biblioteca foi desenvolvida no laboratório de modelagem, análise e desenvolvimento de redes e computação de sistemas (LAND), da Universidade Federal do Rio de Janeiro (UFRJ), obra de um trabalho de grupo que envolveu a atuação de mais dois alunos, um de mestrado e outro de graduação.

Sua distribuição é gratuita pela Internet.

Ilustra como a biblioteca RML faz a interface entre a aplicação e a rede.

A biblioteca RML, implementada na linguagem de programação C, é baseada no protocolo Enhanced-Receiver-Initiated, devido à superioridade de seu desempenho em relação aos demais protocolos.

Com isso fica atribuída ao receptor a responsabilidade da recuperação dos dados perdidos.

Esta biblioteca mantém a comunicação entre os membros do grupo Multicast de maneira transparente, onde os membros do grupo não precisam conhecer a topologia da rede.

Além disso, a biblioteca possui facilidades para que os membros possam entrar e sair do grupo de forma dinâmica.

A estrutura cache foi implementada com a função de armazenar informações sobre os membros do grupo Multicast, bem como dados recebidos recentemente de cada um dos membros.

A cache mantém uma entrada para cada membro do grupo com informações sobre este, por exemplo o endereço IP e a identificação do processo (PID).

Cada entrada da cache possui os campos descritos em seguida number_of_pckts, número de pacotes de dados recebidos do membro e que se encontram armazenados, active indica se o membro está ativo ou desativado no grupo.

Se active = 1, então o membro ainda está no grupo, senão ele já saiu do grupo.

First, ponteiro para o primeiro pacote de dados da lista dos dados recebidos.

Esta lista de dados mantém somente os pacotes recebidos recentemente do membro.

Sm_info, estrutura composta pelos campos member_id e member_status.

Member_id, estrutura de identificação do membro, composta pelo endereço IP do membro e a identificação do processo (PID), member_status, estrutura que armazena o estado atual do membro.

Estas informações são importantes para o processo de recuperação dos dados perdidos.

A estrutura member_status é descrita a seguir.

First_rcv, sn do primeiro pacote de dados recebido do membro.

Last_rcv, sn do último pacote de dados recebido do membro.

Last_seq_rcv, sn do último pacote de dados em sequência recebido do membro.

Last_identified, o maior sn armazenado na lista de dados.

Window_size, número máximo de requisições de retransmissões que podem ser enviadas em um determinado instante.

Window_mask, vetor com as identificações dos pacotes de dados perdidos.

As informações armazenadas por este vetor são enviadas no pacote NACK.

O valor 1 significa que o dado, referente à posição com o valor, foi perdido e consequentemente deve ser enviado um NACK para este dado, e o valor 2 significa que já foi enviado um NACK para o dado perdido, portanto, esperando pela retransmissão.

Window_ini, posição do menor sn armazenado no vetor window_mask.

Nack_list, lista que controla o número de NACKs enviados para cada pacote perdido.

Uma questão importante a ser analisada é o tamanho da cache.

Para o protocolo Enhanced-Receiver-Initiated, se a cache for pequena um dado pode ser removido indevidamente caso ainda seja necessário para envio de retransmissões.

A escolha do tamanho adequado para a cache deve levar em consideração o processo de entrada de um novo membro no grupo, caso seja feita sem a recuperação do estado atual, baseando-se no primeiro processo de entrada de membros descrito na Seção 43.

Porém quando o processo de entrada de um novo membro no grupo baseia-se no processo, torna-se viável a implementação de uma cache relativamente pequena, pois os dados que já foram removidos da cache no momento da entrada de um novo membro são recuperados através do recebimento do estado atual, de acordo com as explicações.

Um novo dado somente pode ser inserido na cache se seu armazenamento não substituir um dado da cache que ainda não foi enviado para aplicação.

Se o dado a ser substituído na cache não tenha sido entregue para aplicação, então, o novo dado deve ser descartado.

O usuário da biblioteca RML pode configurar o seu funcionamento com o uso de um arquivo de configuração, definindo o tamanho da cache grande o suficiente para manter um bom desempenho na recuperação de dados.

O arquivo de configuração permite assim adaptações do tamanho da cache de acordo com o tipo de aplicação que a está utilizando.

As especificações técnicas sobre o uso de arquivo de configuração, assim como outras funcionalidades da biblioteca, documentação disponibilizada junto com a distribuição da biblioteca RML.

Esta seção tem o objetivo de explicar o processo de entrada e de saída dos membros em um grupo Multicast.

Primeiramente, é apresentado o gerenciamento de entrada de novos membros no grupo.

Em seguida é apresentado o processo de saída de um membro do grupo Multicast.

Para a garantia da confiabilidade da consistência dos dados, seria ideal que todos os membros, que pretendessem participar de uma sessão Multicast, entrassem no grupo ao mesmo tempo.

Infelizmente, nem sempre isso pode ser garantido.

Se algum membro entrar na sessão muito tempo após o seu início, pode não ser mais possível para este membro chegar a um estado consistente em relação ao resto do grupo.

Este problema é consequência da quantidade finita de dados que podem ser armazenados na cache para posterior retransmissão.

Durante uma sessão Multicast, cada membro armazena uma certa quantidade de dados em uma cache.

À medida que novos pacotes de dados vão sendo recebidos por um membro, estes são armazenados na cache.

Como a cache é finita, os dados mais antigos começam a ser substituídos por dados mais novos.

Portanto, se um novo membro entra no grupo no momento em que dados foram substituídos da cache, pode não ser mais possível recuperar os dados antigos, visto que estes já foram removidos da cache.

A situação apresentada acima pode não ser um problema para aplicações onde informações trocadas anteriormente não são relevantes para a consistência do estado atual, por exemplo um chat Multicast.

Porém, se considerarmos aplicações em que existe uma dependência entre os dados, ou seja, o estado atual da sessão Multicast depende das informações passadas, esta situação deve ser tratada com muita atenção.

Em uma aplicação com desenhos, como o TGWB, o recebimento de todos os pacotes pode ser indispensável para a consistência do estado atual.

Vamos supor que o acontecimento das três ações a seguir ocorresse na ordem em que são descritas, um pacote de dados referente ao desenho de um quadrado é enviado pelo membro A, o membro B entra no grupo Multicast, o membro A envia um pacote de dados para colorir o quadrado enviado anteriormente.

Se no momento que o membro B entrar no grupo, o membro A já tiver removido os dados referentes ao desenho do quadrado de sua cache, o membro B não poderá recuperá-lo para colorí-lo, pois o membro A não o terá mais armazenado para retransmití-lo.

Nesta situação, o membro B se encontrará em um estado inconsistente, visto que não faz sentido colorir um desenho inexistente.

Entretanto, o membro pode entrar no grupo e recuperar o estado atual de algum membro antigo do grupo.

Este procedimento de recuperação do estado atual será explicado a seguir.

A biblioteca RML foi implementada possibilitando a escolha da forma de entrada de um novo membro no grupo Multicast.

Esta escolha está extremamente ligada ao tipo de aplicação Multicast em questão.

Existem duas possibilidades para um novo membro entrar em um grupo Multicast, 1 entrar direto no grupo, sem recuperar o estado atual da sessão.

Ou seja, o membro começará a interação com o grupo sem nenhuma informação do passado.

Seu estado se constituirá de tudo que ele recebeu desde o momento em que entrou no grupo Multicast, recuperar o estado atual da sessão e depois entrar no grupo Multicast.

O estado atual consiste de todos os dados necessários para se tornar um membro Multicast, podendo incluir as informações armazenadas na cache.

O estado atual varia de acordo com a aplicação, no caso do TGWB, o estado atual consiste da cache e dos dados contidos na tela no momento do recebimento do pedido de inclusão no grupo.

Representa a segunda possibilidade de entrada de novos membros no grupo.

O candidato a novo membro envia uma mensagem join ao grupo Multicast e fica aguardando por uma mensagem accept de algum membro do grupo.

Qualquer membro do grupo que receba uma mensagem join está capacitado para enviar uma mensagem accept.

A mensagem accept contém informações necessárias (endereço e porta) para o estabelecimento de uma conexão TCP.

Com o recebimento da mensagem accept, o candidato a novo membro estabelece uma conexão TCP com o membro emissor desta mensagem e através desta conexão será possível o envio do estado atual do antigo para o candidato a novo membro.

Quando o candidato a novo membro recebe o estado atual do antigo membro, ele pode ser considerado um membro Multicast efetivo do grupo, assim como os outros.

Porém, se o tempo determinado para espera por uma mensagem accept expirar, o candidato a novo membro considera que não existe mais nenhum outro membro no grupo, ou seja, ele é o primeiro e único no grupo.

Em ambos os casos, ele tornase um "servidor de estado atual", isto é, está sempre preparado para enviar o seu estado atual caso receba uma mensagem join de algum membro que almeja entrar no grupo Multicast.

Um "servidor de estado atual" espera por conexões em uma determinada porta pré-estabelecida.

Quando um membro qualquer se conecta a esta porta, o "servidor de estado atual" transmite o estado atual da aplicação para o membro requisitante.

No caso da aplicação TGWB, a cache pertence ao estado atual da sessão, pois além de conter os dados recentemente trocados durante uma sessão, ela contém informações sobre os outros membros do grupo Multicast.

Supondo que a cache não fosse enviada para o candidato a novo membro, e que após o recebimento do estado atual (apenas a tela) pelo candidato a novo membro, este recebesse um pacote, por exemplo com o sn = 10.

O membro identificaria este pacote como o primeiro recebido, pois mesmo que os pacotes com sns de 0 a 9 tivessem sido recebidos no momento da transmissão do estado atual (tela), o novo membro acharia que tinha perdido estes pacotes, uma vez que não se encontrariam armazenados na cache (inicialmente a cache encontra-se vazia).

Com isso, o membro associa esta ausência dos pacotes na cache como perdas e escalona NACKs referente a estes pacotes para requisitar retransmissões.

Neste caso, teríamos algumas retransmissões desnecessárias, pois na verdade os pacotes de dados requisitados já foram recebidos, anteriormente, no momento do recebimento do estado atual (tela).

Quando um membro deseja sair do grupo Multicast, ele envia uma mensagem leave group para o grupo avisando a sua intenção e escalona sua saída para o tempo aleatório T LEAV E, ou seja, escalona o evento LEV_GRP para ser disparado no tempo T LEAV E.

Porém, antes do envio da mensagem leave group, o membro envia uma mensagem refresh, mensagem de controle com o valor do sn do último pacote de dados enviado pelo membro.

Caso algum membro ainda não tenha recebido os pacotes cujos sns são inferiores ou igual ao valor do sn recebido no refresh, serão escalonados NACKs requisitando retransmissões.

Caso a mensagem refresh se perca e algum membro não tenha recebido todos os pacotes de dados enviados por este membro que deseja sair do grupo, então não será mais possível a recuperação de tais pacotes.

Ao receberem a mensagem leave group, os demais membros do grupo sinalizam na cache que o membro que deseja sair não está mais ativo no grupo.

Esta sinalização serve para cálculo dos temporizadores dinâmicos, onde é necessário calcular o atraso em relação a cada membro do grupo de tempos em tempos, com a sinalização, não será preciso calcular o atraso em relação aos membros que não estão mais ativos no grupo.

Após o término do tempo T LEAV E, o evento LEV_GRP é executado.

O membro libera alguns recursos do sistema que foram alocados durante a sessão e sai do grupo Multicast.

O processo para alcançar uma transmissão Multicast confiável pode ser dividido em duas etapas, 1 detectar as perdas dos pacotes perdidos, 2 recuperar eficientemente os pacotes detectados como perdidos.

Esta seção apresenta como é feita a detecção de perdas e na seção 45 é apresentado o procedimento de recuperação de dados.

A detecção de perdas pode ser feita de duas formas, a primeira através do recebimento de um pacote de dados fora de sequência.

Por exemplo, um membro recebe o pacote de dados com o sn = i 1 e, em seguida, o pacote com o sn = i + 1.

Logo, é detectada a perda do pacote com o sn = i, sendo então necessária a execução dos procedimentos de recuperação dos pacotes perdidos.

Ilustra como é feito o tratamento dos dados que são recebidos durante uma sessão Multicast.

Quando um membro recebe um pacote de dados, ele identifica o membro emissor e o sn do pacote recebido, verificando a existência de algum evento escalonado para este pacote recebido.

Por exemplo, um pedido de retransmissão pode ter sido escalonado no caso de uma perda ter sido detectada para este pacote, porém com o recebimento do pacote não é mais necessário o pedido de retransmissão.

Se o membro emissor, identificado no pacote, ainda não possui uma entrada na cache, então é feita sua inclusão.

O pacote de dados recebido, que ainda não se encontra na cache e que seu armazenamento não substitua um dado ainda não enviado para aplicação, deve ser armazenado na cache.

Se o sn do pacote de dados recebido for o esperado, o dado é então passado para a aplicação.

Porém, se este pacote de dados não for o esperado, ou seja, se o sn for maior que o sn anteriormente recebido + 1, então o dado somente será liberado para a aplicação, após a recuperação de todos os pacotes de dados perdidos com os sns inferiores ao pacote de dados recebido.

Deste modo, os pacotes são entregues ordenados para a aplicação.

Caso haja detecção de perda devido ao recebimento de um pacote de dados com o sn não esperado, é feita a verificação da existência de eventos escalonados para os pacotes que foram detectados como perdidos.

Primeiro, é verificada a existência do evento para envio do NACK (evento NACK_SND), depois a existência do evento para espera por retransmissão antes do reenvio do NACK (evento RET_RCV), se após estas verificações for identificado que não existe nenhum evento escalonado para os pacotes perdidos, então é escalonado o evento NACK_SND, ou seja, o evento é incluído na lista de eventos.

Se já existir o evento NACK_SND ou RET_RCV escalonado na lista de eventos, então, nada deve ser feito, pois o procedimento de recuperação dos dados já foi iniciado.

A segunda forma de detecção de perdas é feita através do recebimento das mensagens refresh.

A mensagem refresh contém a identificação do membro que a emitiu e o valor do sn do último pacote de dados por ele enviado.

Na atual implementação da biblioteca, as mensagens refresh são enviadas cada 10s.

Quando o membro recebe mensagens refresh e verifica que pacotes com sns inferiores ou igual ao valor do sn recebido no refresh não foram recebidos, ele detectada perdas.

De maneira similar ao tratamento de dados, após a detecção das perdas, é feita a verificação da existência de eventos para estes pacotes perdidos.

Se já existir o evento NACK_SND ou RET_RCV escalonado na lista de eventos, então, nada deve ser feito, pois o procedimento de recuperação dos dados já foi iniciado.

Porém, não havendo existência de eventos escalonados, então o evento NACK_SND é escalonado.

O uso da mensagem refresh é útil em situações onde se perde o último pacote de dados enviado por um determinado membro.

Nesta situação, os membros receptores não teriam como identificar a perda, utilizando somente a primeira forma de detecção de perdas descrita nesta seção.

Suponha que um membro envie o pacote de dados com o sn = i e que algum membro tenha perdido este pacote, se este pacote perdido for o último pacote enviado pelo membro emissor, então, a única forma de recuperálo é com o recebimento da mensagem refresh.

O procedimento de recuperação consiste, primeiramente, na solicitação das retransmissões dos pacotes perdidos, seguido do aguardo pelo recebimento das retransmissões solicitadas e finalizando no recebimento destas retransmissões.

No mecanismo de envio de NACKs foi implementado o uso de temporizadores para evitar que ocorra a implosão de NACKs.

Como descrito na apresentação do protocolo Enhanced-Received-Initiated no Capítulo 2, a implosão de NACKs é a grande quantidade de NACKs iguais trafegando pela rede.

Isso acontece quando dois ou mais membros do grupo Multicast enviam NACKs solicitando retransmissões para os mesmos pacotes de dados, podendo gerar o congestionamento da rede.

Como o simples envio de NACKs, no instante da detecção da perda, pode causar a implosão de NACKs, ao invés de enviar NACKs imediatamente após a detecção da perda, um evento NACK_SND é escalonado para acontecer no tempo aleatório TNACK.

Caso algum membro do grupo, que também tenha perdido o mesmo pacote, escalone o evento NACK_SND para um tempo menor que o TNACK dos outros membros, então o evento deste membro pode ser disparado antes, enviando o NACK e suprimindo o envio do NACK dos demais membros do grupo.

Assim, se escolhermos uma maneira eficiente para determinar TNACK, teremos uma grande probabilidade de suprimir o envio de NACKs duplicados na rede.

O tratamento da mensagem NACK pode ser representado, onde a cada recebimento de uma mensagem NACK é feita a verificação da existência do evento NACK_SND, relativo ao mesmo grupo de pacotes, na lista de eventos.

Caso exista, o evento é removido, suprimindo o NACK que estava escalonado para ser enviado e escalonando o evento RET_RCV para esperar pela retransmissão durante o tempo aleatório TWAIT.

Caso não exista o evento NACK_SND escalonado para este(s) pacote(s), então é verificada a existência do evento RET_RCV.

Caso exista, significa que o membro receptor do NACK já enviou um NACK para o pacote em questão e está aguardando a retransmissão do pacote perdido.

Porém, se não existir o evento RET_RCV, o membro pode agir de duas maneiras, se o membro não tiver os pacotes requisitados na cache, então, o evento RET_RCV deve ser escalonado para esperar por estas retransmissões já requisitadas, se o membro tiver os pacotes requisitados na cache, então, o evento RET_SND deve ser escalonado para envio das retransmissões.

Após o envio do NACK, o membro espera pela retransmissão durante o tempo aleatório TWAIT.

Ao fim, o membro escalona um novo NACK referente os pacotes que ainda não foram recuperados.

Essa situação pode se repetir algumas vezes, dependendo do número máximo de NACKs que pode ser enviado para o mesmo pacote perdido.

O usuário da biblioteca RML pode definir este número no arquivo de configuração, como descrito na documentação.

O campo nack_list da cache armazena quais e quantos NACKs foram enviados.

Se for enviado o número máximo de NACKs permitido para o mesmo pacote, entende-se que não foi possível recuperar o pacote perdido e a aplicação deve ser finalizada.

A eficiência do mecanismo de envio de NACKs envolve outros fatores, como por exemplo o controle do número de requisições contidas em um pacote NACK.

O fato de um membro requisitar mais retransmissões de dados do que ele é fisicamente capaz de receber, pode aumentar desnecessariamente o tráfego na rede.

Portanto, é necessário que se faça o controle de fluxo do número de requisições.

Supondo uma cache com a capacidade de armazenamento de 50 pacotes e que um membro tenha detectado a perda de 100 pacotes de dados, se não houver controle do número de pacotes a serem requisitados, o membro pode pedir retransmissões de todos os pacotes perdidos ao mesmo tempo, havendo retransmissões de pacotes que momentaneamente não devem ser inseridos na cache, pois substituiriam pacotes que ainda não foram enviados para a aplicação.

Para evitar o envio de retransmissões desnecessárias, não devem ser requisitados mais pacotes do que a cache é capaz de armazenar.

Quando muitos pacotes forem perdidos, é enviado apenas um NACK requisitando a retransmissão de no máximo w pacotes com os sns em sequência, onde w é o número máximo de requisições de retransmissão que um membro pode enviar ao mesmo tempo, sendo w menor ou igual ao tamanho da cache.

Por questões de implementação, o número escolhido para w foi 64, este valor representa dois inteiros que podem ser passados no pacote NACK ao invés de 64 valores de sns.

Os dois inteiros podem ser interpretados através da máscara.

O pacote NACK além de conter a identificação do membro que o emitiu e do membro emissor do dado perdido, contém os seguintes campos.

Sn_base, sn da primeira requisição da máscara.

W, número máximo de retransmissões que podem ser solicitados ao mesmo tempo.

Hmask, o inteiro que representa a parte alta da máscara.

Lmask, o inteiro que representa a parte baixa da máscara.

O cálculo dos sns requisitados no NACK é feito a partir da transformação dos números inteiros contidos em hmask e lmask em sua representação binária.

Todas as posições com o valor 1 significam um pedido de retransmissão e o valor deste sn pode ser calculado através da soma da posição em que se encontra com o valor do sn_base.

Supondo que um membro receba um NACK com o sn_base = 5, w = 64, hmask = 1 e lmask = 3, os sns dos pacotes requisitados seriam 5 (0 + 5), 6 (1 + 5) e 37 (32 + 5).

Representa dois mecanismos que podem ser usados para o envio do NACK.

O primeiro mecanismo não limita o número de requisições feitas em um determinado tempo.

Ele envia um NACK para cada pacote perdido e armazena na cache todas as retransmissões recebidas.

O segundo, usado pela biblioteca RML, mantém o controle do número máximo de requisições enviadas e envia apenas um NACK contendo todas as requisições de retransmissões que podem ser solicitadas.

Para análise vamos supor o seguinte cenário, uma cache com a capacidade de armazenamento para apenas 5 pacotes, um membro emissor enviando pacotes de dados com sn do 0 até 8, que todos os pacotes são perdidos pelo membro receptor, e que no envio das retransmissões é perdido o pacote com o sn = 0.

O recebimento do refresh pelo receptor o torna capaz de detectar a perda e requisitar a retransmissão através do envio do(s) NACK(s).

No primeiro mecanismo, o receptor envia nove NACKs na rede, um para cada pacote perdido.

O armazenamento das retransmissões dos pacotes com os sns 6, 7 e 8 faz com que os pacotes com os sns 1, 2 e 3 sejam substituídos da cache.

Porém, como foi suposta a perda da retransmissão do pacote com o sn = 0, estes ainda não haviam sido entregues para a aplicação, uma vez que os pacotes devem ser entregues em ordem para a mesma.

Portanto, é necessário o reenvio de NACKs, causando o aumento do tempo de recebimento dos dados e do tráfego na rede.

No segundo mecanismo, apenas um NACK é enviado e o número máximo de requisições feitas neste NACK é igual ao tamanho da cache.

Não havendo retransmissões desnecessárias, consequentemente não será necessário o envio de NACK para pacotes de dados já recebidos antes.

Note-se que apenas o pacote com o sn = 0 é requisitado no segundo NACK enviado.

Isto acontece porque neste momento requisições de retransmissões para os pacotes com sns superiores a 4 ainda não devem ser inseridos na cache, pois substituiriam dados ainda não entregues a aplicação.

Com o emprego do segundo mecanismo, podemos perceber que o número de pacotes trafegando pela rede pode ser consideravelmente reduzido.

A biblioteca RML considera que cada membro mantém em sua cache os últimos n pacotes de dados enviados durante a sessão Multicast.

Sendo assim, todos os membros estão aptos a retransmitirem qualquer um dos n pacotes armazenados em sua cache, ou seja, a responsabilidade da retransmissão é distribuída entre todos os membros da sessão Multicast.

Com isso, pode acontecer que retransmissões duplicadas sejam enviadas pela rede.

Para evitar este problema, foi implementado o uso de temporizadores similar ao utilizado no envio dos NACKs.

Se o membro A receber um NACK requisitando a retransmissão de um pacote de dados que está contido em sua cache, então deverá escalonar o evento RET_SND para ser disparado no tempo aleatório TRET.

Caso este membro receba uma retransmissão do pacote requisitado, antes do tempo TRET expirar, ele considera que algum outro membro do grupo já fez a retransmissão que pretendia fazer e cancela o envio da retransmissão que estava escalonada para ser enviada.

Porém, se nenhuma retransmissão chegar até o tempo TRET expirar, o membro A envia a retransmissão solicitada para o grupo.

Caso o dado a ser retransmitido seja removido da cache antes do disparo do evento RET_SND, quando o membro ao busca o dado para retransmití-lo, detecta a sua remoção da cache e, consequentemente, não retransmite o pacote solicitado.

Quando um membro do grupo Multicast recebe uma retransmissão, ele verifica a existência do evento RET_SND referente à retransmissão recebida.

Caso exista, o evento é cancelado, conforme explicado no parágrafo anterior.

Contudo, se não houver o evento RET_SND escalonado, é feita a verificação da existência dos eventos NACK_SND e RET_RCV, ou seja, o membro verifica se ele já havia detectado a perda desta retransmissão recebida e se pretendia ou se já havia mandado um NACK para este pacote.

Caso algum dos dois eventos tenha sido escalonado, então, o evento escalonado é cancelado e o dado retransmitido é armazenado na cache.

Todas as ações tomadas pela biblioteca RML são escalonadas para algum tempo no futuro, ou seja, nenhuma ação é feita imediatamente após a detecção de sua necessidade.

Os eventos, escalonados para acontecerem no futuro, são inseridos em uma lista, chamada lista de eventos, e permanecerão nesta lista durante o tempo determinado pelo temporizador.

Quando o tempo expira o evento é removido da lista e executado.

Porém, um evento pode ser cancelado da lista antes do temporizador expirar.

Escalonar eventos é uma atividade extremamente comum da RML.

Por exemplo, espera para envio de um NACK, pelo escalonamento do evento NACK_SND, ou seja, pela inclusão deste evento na lista de eventos para acontecer no tempo TNACK.

O mesmo acontece quando se espera por uma retransmissão, para enviar uma retransmissão ou para sair da sessão Multicast.

Quando o temporizador para um determinado evento dispara, ele é executado.

Sua execução vai depender do seu tipo.

A seguir serão descritos os tipos de eventos e as respectivas ações tomadas quando disparados.

NACK_SND, o NACK é enviado e o evento RET_WAIT é inserido na lista de eventos para esperar pela retransmissão do pacote requisitado.

RET_WAIT, o evento NACK_SND é inserido na lista de eventos para reenvio do NACK.

RET_SND, a retransmissão é enviada.

LEV_GRP, o membro libera alguns recursos do sistema que foram alocados durante a sessão Multicast e sai do grupo Multicast.

REF_SND, a mensagem refresh é enviada, identificando o sn do último pacote de dados enviado.

Em algumas situações, o evento pode ser removido da lista de eventos antes do temporizador expirar.

São elas, se o membro receber um NACK requisitando a retransmissão do mesmo pacote de dados que este deseja requisitar.

Neste caso não é mais necessário o envio do NACK, sendo o evento NACK_SND removido da lista de eventos, e o membro receber uma retransmissão e existir o evento NACK_SND ou o evento RET_WAIT na lista de eventos, o evento deve ser removido pois a retransmissão desejada já foi recebida.

Se o membro receber uma retransmissão e existir o evento RET_SND, o evento deve ser removido pois algum outro membro já fez a retransmissão que estava escalonada para ser feita.

A lista de eventos armazena os eventos a serem executados, organizados em ordem crescente de acontecimento.

Cada nó da lista de eventos contém as informações necessárias para execução do evento, como o tipo do evento e o tempo de execução para o qual foi escalonado.

O tempo de execução do evento armazenado em cada nó é relativo ao tempo de execução do nó que o antecede na lista de eventos.

Desta forma apenas 1 temporizador é necessário para implementar as ações.

Representa um exemplo simplificado da lista de eventos, onde é suposta a existência de cinco eventos na lista, escalonados para 4, 6, 6, 13 e 17 unidades de tempo no futuro.

O tipo e os outros atributos do evento foram omitidos para fins de simplificação.

Os valores contidos nos nós representam o tempo relativo de disparo de cada evento da lista.

Como o segundo e o terceiro evento foram escalonados para serem executados no tempo 6, o terceiro nó contém o tempo relativo igual a 0, ou seja, o terceiro evento deve ser executado 0 unidades de tempo após a execução do segundo evento.

Toda vez que um evento é inserido no início da lista, o sinal de alarme do sistema operacional é escalonado para disparar no tempo indicado pelo nó inicial da lista de eventos.

Quando o alarme dispara, o evento é removido da lista e processado.

Todos os nós subsequentes que tiverem seu tempo relativo igual a 0, deverão ser removidos e processados imediatamente.

O alarme é então reiniciado para disparo no tempo do novo nó inicial da lista.

Como os tempos de disparo são relativos, devem ser atualizados toda vez que um evento for inserido ou removido da lista.

Demonstra a inserção de um evento escalonado para o tempo 10.

Este evento deve ocorrer após o evento escalonado para o tempo 6 e antes do evento escalonado para o tempo 13.

O tempo relativo do evento escalonado para o tempo 13 deve ser atualizado de 7 para 3, pois agora este evento vai ocorrer 3 unidades de tempo após o evento que o antecede.

A remoção de um evento acontece de maneira similar à inserção, porém o evento sucessor ao evento removido deve ter seu tempo relativo somado ao tempo relativo do evento que está sendo removido.

O objetivo da implementação de um algoritmo para cálculo dos temporizadores é a supressão de pacotes duplicados na rede e a otimização do tempo de recuperação dos pacotes perdidos em uma sessão Multicast.

Existem alguns estudos sobre o assunto na literatura.

A pesquisa feita tem o objetivo de estudar a relação entre o cálculo dos temporizadores e o desempenho da recuperação de pacotes perdidos ou com erros no protocolo SRM.

São apresentadas fórmulas para o cálculo dos temporizadores, baseando-se nos atrasos entre os membros do grupo e rotinas para a adaptação dinâmica dos temporizadores em relação às mudanças na rede, como o número de membros vizinhos.

O tamanho da vizinhança é calculado dinamicamente baseado no desempenho da recuperação dos dados.

A implosão de NACKs é evitada utilizandose temporizadores aleatórios com distribuição uniforme.

A supressão de requisições e retransmissões não garantem a ausência de pacotes duplicados na rede, pois uma segunda requisição enviada antes do recebimento da retransmissão é também um pacote duplicado.

E esta segunda requisição ainda pode causar duplicação da retransmissão, devendo as requisições prematuras e as retransmissões duplicadas serem tratadas.

Esta pesquisa demonstra que é possível prevenir requisições prematuras e ignorar, dentro de um intervalo de tem pedidos duplicados de retransmissões.

No processo de ajuste dinâmico dos temporizadores, o tamanho da vizinhança é interpretado a partir das mensagens duplicadas e a partir do atraso de recuperação.

Devido à média do número de requisições na vizinhança ser proporcional ao tamanho da vizinhança, se houver muitas mensagens duplicadas na rede significa que o tamanho da vizinhança foi subestimado e que deve ser aumentado.

Porém, não é possível determinar com precisão quando o tamanho da vizinhança foi superestimado e deve ser reduzido, pois o recebimento de poucas mensagens duplicadas pode ser consequência de um cálculo otimizado para os temporizadores, não necessitando do seu ajuste.

O cálculo do atraso é inversamente proporcional ao tamanho da vizinhança, ou seja, o aumento da vizinhança gera a diminuição do atraso uma vez que o tempo de espera para envio de uma requisição pode ser menor devido à grande quantidade de vizinhos que o membro possui.

Portanto, se o atraso diminui, significa que a vizinhança aumentou.

É demonstrado que o ajuste do tamanho da vizinhança, através do atraso de recuperação, é mais eficiente do que através da quantidade de mensagens duplicadas na rede.

Um outro exemplo de estudos dos cálculos dos temporizadores é a pesquisa realizada, onde um método é proposto para evitar a implosão de NAKs baseando-se em temporizadores com distribuição exponencial.

É mostrado através de análises e simulações que a implosão de NACKs pode ser evitada, mantendo-se o mecanismo de supressão sempre robusto, mesmo com a perda de NACKs.

O mecanismo tem uma complexidade computacional baixa em cada receptor, que é independente do tamanho do grupo, pois é considerado apenas um emissor por sessão.

Cada receptor mantém armazenado o atraso apenas em relação ao emissor.

Nenhum suporte nem conhecimento sobre a topologia da rede são necessários para evitar a implosão de NACKs.

Os resultados das simulações mostram que a supressão de NACKs com o uso dos temporizadores, com distribuição exponencial, é escalável em relação ao número de receptores e que previne a implosão de NACKs, ao mesmo tempo que modera o atraso na recuperação dos dados perdidos.

O cálculo dos temporizadores é baseado no número de receptores do grupo.

Portanto o mecanismo preocupa-se com o número estimado de receptores, onde um número de receptores R superestimado aumenta o intervalo do temporizador, aumentando, consequentemente, o atraso de recuperação dos dados perdidos e um número de receptores R subestimado diminui o intervalo do temporizador, podendo causar a implosão de NACKs.

As principais diferenças entre este mecanismo e o utilizado pelo protocolo SRM descrito anteriormente é que o protocolo SRM usa uma distribuição uniforme para cálculo dos temporizadores dependente do atraso entre emissor e receptor.

Enquanto este mecanismo usa uma distribuição exponencial baseado no número de receptores, o protocolo SRM previne a perda de NACKs, escalonando uma segunda requisição em um intervalo de tempo maior que o anterior, o protocolo SRM ignora pedidos de retransmissão repetidos durante um determinado intervalo de tempo.

É apresentado um algoritmo distribuído para computar o cálculo determinístico dos temporizadores, baseado na topologia da rede e no atraso entre o emissor e o receptor.

É considerado apenas um emissor por sessão e os receptores não mantêm uma cache para armazenamento dos dados trocados durante uma sessão.

Esta função compete somente ao emissor, que é o único responsável pelas retransmissões para o grupo.

Quando um receptor detecta uma perda, este envia um NACK, via Unicast, para o emissor.

Portanto, o receptor não precisa ter conhecimento dos demais membros do grupo, apenas precisando saber o valor do atraso entre ele e o emissor.

A implosão de NACKs pode ser evitada se para cada perda de dados apenas um NACK é enviado cedo, o suficiente para que a retransmissão ocasionada por este NACK suprima os NACKs escalonados pelos demais receptores do grupo.

Isto é, a retransmissão deve chegar nos demais receptores antes que o tempo de espera, para envio do NACK, expire.

A biblioteca RML implementada não tem o objetivo de otimizar o cálculo dos temporizadores.

Nesta dissertação é assumida uma forma simples de encontrá-los baseando-se nos atrasos.

Porém, a biblioteca permite que um algoritmo mais complexo seja construído com a responsabilidade de otimizar o cálculo dos temporizadores.

Na RML, os temporizadores foram implementados com distribuição uniforme.

Os temporizadores são estáticos, ou seja, são definidos no início da sessão Multicast através do arquivo de configuração e não se alteram durante a mesma.

Os temporizadores TNACK, intervalo de tempo que o membro espera para solicitar uma retransmissão.

TWAIT, intervalo de tempo que o membro espera para solicitar novamente uma retransmissão já solicitada anteriormente e TRET, intervalo de tempo que o membro espera para retransmitir um dado solicitado.
Foram definidos dentro dos seguintes intervalos de tempo, TNACK = {A * delay receptor, emissor, (A + B) * delay receptor, emissor} TWAIT = {C * delay receptor, emissor, (C + D) * delay receptor, emissor } TRET = {E * delay receptor, emissor, (E + F) * delay receptor, emissor} onde delay receptor, emissor é o atraso entre o membro receptor e o membro emissor do dado transmitido e A, B, C, D, E e F são constantes a serem escolhidas pelo usuário.

Ilustra o intervalo dos temporizadores conforme as definições apresentadas anteriormente.

Ao detectar uma perda, o membro escolhe, aleatoriamente, com distribuição uniforme, dentro do intervalo TNACK, um valor para o tempo de espera antes de solicitar a retransmissão.

Com esta definição, temos uma alta probabilidade de que o envio de um NACK por um membro mais próximo ao emissor suprima o envio de um NACK por um membro mais distante do emissor, já que o membro mais próximo ao emissor possui o intervalo TNACK menor do que os intervalos dos membros mais distantes.

Para os exemplos a seguir é suposto que as constantes A e E possuem o valor 1 e B, C, D e F, o valor 2, e que o valor dos temporizadores seja o limite inferior do intervalo de cada temporizador.

Suponha os atrasos representados, sendo o membro A o emissor e os membros B e C os receptores, e que as nuvens representam os canais com os atrasos entre os membros.

Suponha também que os receptores B e C tenham perdido um dado enviado pelo emissor A, e que o receptor B detecte a perda antes do receptor C por ter um atraso menor em relação ao emissor.

O receptor C poderá só detectar a perda 30 (unidades de tempo) após a detecção feita pelo receptor B.

A supressão de NACK pode ser observada, onde o TNACK do receptor B mais o atraso entre B e C é menor que o tempo que o receptor C leva para detectar a perda do dado mais o TNACK deste.

Logo, o receptor B envia um NACK que chega no receptor C no tempo t = 40, suprimindo o NACK que estava escalonado para ser enviado por este para o tempo t = 80.

Quando um membro recebe um NACK, ele deve calcular o tempo de espera para retransmitir o dado solicitado através da escolha aleatória dentro do intervalo TRET.

No caso do receptor do NACK ser o próprio emissor, ao invés de não esperar para retransmitir, uma vez que o atraso entre o emissor e o receptor é zero e ele é o emissor e o receptor ao mesmo tempo, este deve esperar um tempo aleatório que foi definido igual à média dos TRET do grupo.

Assim, o envio da retransmissão pelo emissor pode ser suprimida em alguns casos, onde também é suposto que os membros A, B e C possuem os atrasos e que o valor dos temporizadores seja o limite inferior do intervalo de cada temporizador.

O receptor B recebe um NACK do receptor C no tempo t = (50 + 20), onde 50 é o tempo de espera do receptor C antes de enviar o NACK e 20 é o atraso entre C e B.

O emissor A recebe o mesmo NACK no tempo t = (50 + 50), onde 50 é o tempo de espera do receptor C antes de enviar o NACK e 50 é o atraso entre C e A.

Supondo o TRET do emissor A igual a média dos TRET do grupo, o emissor A retransmitiria o dado no tempo t = (100 + 35), onde 100 é o tempo em que o NACK chegou em A e 35 é o tempo de espera para retransmitir definido por TRET.

O receptor B retransmitiria o dado no tempo t = (70 + 20), onde 70 é o tempo em que o NACK chegou em B e 20 é o tempo de espera para retransmitir definido por TRET.

Logo, esta retransmissão chegará em A no tempo t = (90 + 20), onde 90 é o tempo que o receptor B retransmitiu o dado e 20 é o atraso para a retransmissão chegar no emissor A e anular o envio da retransmissão por este, que estava escalonada para o tempo t = (100 + 35).

Supondo o caso de uma apresentação no Whiteboard TGWB (Capítulo 3), onde há somente um emissor e n receptores, cada receptor só precisa manter em sua cache informações sobre o emissor, mantendo transparente a comunicação entre os membros do grupo Multicast.

Se o temporizador TRET fosse relativo ao emissor do NACK, ao invés de ser relativo ao emissor do dado perdido, seria necessário guardar as informações deste requisitante de retransmissão na cache, ou seja, o receptor manteria na cache as informações de todos os receptores que alguma vez já lhe enviaram algum NACK, o que pode prejudicar a escalabilidade do protocolo.

A definição do temporizador TWAIT foi estabelecida para que após o envio de um NACK, o receptor espere o tempo suficiente para que este NACK chegue ao emissor e que a retransmissão enviada pelo emissor seja recebida.

Após este tempo expirar, o receptor ainda espera por mais o intervalo de tempo TNACK antes de finalmente reenviar o NACK.

Este tempo deve ser suficientemente grande para que a retransmissão chegue no receptor e suprima o reenvio do NACK.

Com certeza, o emissor possui o dado requisitado e para o pior caso somente ele terá o dado, portanto o cálculo do temporizador TWAIT foi baseado no atraso do receptor em relação ao emissor.

Ainda considerando os atrasos e que o valor dos temporizadores seja o limite inferior do intervalo de cada temporizador, suponha que apesar de ambos os receptores terem perdido o dado, somente o receptor C tenha detectado a perda.

Logo, se o TNACK do membro C for igual a 50 (atraso entre o receptor C e o emissor A) e o TWAIT do membro C for igual a 100 (2 x (atraso entre o receptor C e o emissor A)), então, após enviar um NACK, o receptor deve esperar mais 150 antes do reenvio do NACK.

O reenvio do NACK pode ser suprimido se o emissor A retransmitir o dado antes do receptor C reenviá-lo.

Este capítulo apresenta a implementação do modelo que descreve a biblioteca Multicast Confiável RML.

A análise e a modelagem de sistemas é uma tarefa essencial no processo de desenvolvimento de um sistema de computação e comunicação, onde através dos modelos pode ser avaliada a eficiência do sistema sob considerações e comparações de diferentes alternativas de desenvolvimento.

A análise do desempenho e da confiabilidade de sistemas ainda em desenvolvimento, ou até mesmo na fase de projeto, é uma das grandes vantagens do uso de modelagem.

Diversos ambientes integrados e ferramentas de análise e modelagem foram desenvolvidos para dar suporte ao processo de modelagem.

O modelo criado nesta dissertação foi implementado na ferramenta TANGRAM II, desenvolvida na Universidade Federal do Rio de Janeiro (UFRJ) com a participação da Universidade da Califórnia Los Angeles (UCLA/USA) e de outras universidades.

A ferramenta é distribuída gratuitamente pela Internet.

O TANGRAM II é um ambiente de modelagem desenvolvido com propósitos educacionais e de pesquisa, provendo flexibilidade na interface com o usuário.

Apesar de possuir um paradigma genérico suficiente para suportar a descrição de sistemas gerais, o objetivo principal é fornecer suporte à descrição de sistemas de computação e comunicação.

O TANGRAM II é baseado em uma estrutura orientada a objetos e possui uma sofisticada interface gráfica de domínio público denominada TGIF, Tangram Graphic Interface Facility, desenvolvida na UCLA.

A versão atual está implementada em C e C++.

Um modelo é uma abstração, que é uma visão simplificada do sistema em estudo, mas projetado com o propósito de capturar o máximo do comportamento real do sistema, suficiente para fornecer prognósticos precisos dentro de uma tolerância aceitável.

Em muitos casos, modelos possuem certas vantagens óbvias sobre medidas feitas em um sistema real.

Se o sistema a ser estudado ainda não existir, o modelo é a única alternativa prática para análise deste sistema.

O paradigma de modelagem adotado foi proposto e é orientado a objetos.

De acordo com este paradigma, os modelos são representados por um conjunto de objetos que podem interagir entre si através do envio e do recebimento de mensagens.

O comportamento dos objetos pode ser definido em eventos e mensagens associados a condições e ações.

O estado interno de um objeto é armazenado por um conjunto de variáveis.

Eventos são habilitados para disparo por um objeto quando a condição para este evento disparar torna-se verdadeira.

O tempo de disparo de cada evento obedece a uma distribuição de probabilidade.

A ferramenta possui as seguintes distribuições, exponencial, determinística, erlangiana, gaussiana, lognormal, uniforme, pareto, FBM, FARIMA, weibull e file onde as amostras são lidas de um arquivo.

As amostras de tempo de disparo dos eventos são geradas pela ferramenta, desde que a condição associada esteja satisfeita no tempo atual, e a execução do evento só acontecerá se esta condição permanecer válida no tempo de disparo.

As condições para o disparo de eventos podem ser descritas em função do estado interno do objeto.

Mensagens são abstrações criadas para possibilitar a interação entre os objetos e são trocadas em tempo zero.

Quando um evento é disparado ou uma mensagem é recebida, um conjunto de ações é executado com uma determinada probabilidade.

O tempo de execução destas ações também é zero.

No final da execução de uma ação, o objeto pode ter seu estado alterado e mensagens podem ter sido enviadas a outros objetos.

Estas mensagens serão tratadas pela ferramenta ainda em tempo zero.

Para criar um modelo, o usuário pode usar diferentes tipos de objetos pré-criados em uma biblioteca que acompanha a ferramenta TANGRAM II, ou criar um objeto particular.

Depois de criado o objeto, o usuário precisa especificar os eventos, as ações associadas ao recebimento de mensagens, as variáveis de estado e outras especificações, que ao todo irão compor a funcionalidade do objeto.

As medidas de interesse podem ser obtidas através da resolução do modelo criado.

Esta resolução pode ser feita de forma matemática (analítica) ou simulada.

Note-se que para um modelo ser criado é necessário o conhecimento do sistema que está sendo modelado, assim como as facilidades e características da ferramenta de modelagem usada.

Simulação é a técnica mais utilizada para modelar sistemas reais e muitas vezes esta é a única forma de avaliar sistemas grandes e complexos.

Modelos matemáticos são promissores pois podem fornecer soluções fechadas, que são as formas mais desejáveis de solução, porém são conseguidas somente para modelos mais simples.

A qualidade dos resultados de simulação de um modelo é comumente expressa em termos de intervalos de confiança.

O cálculo deste intervalo evita que se tenha que simular o sistema por um intervalo de tempo infinito para que as estatísticas possam convergir.

As maiores diferenças entre simulação e modelos matemáticos são simulações são programas que, comparados com modelos matemáticos, são dispendiosos para se construir, difíceis de mostrar que estão corretos e caros em termos de ciclo de execução em CPU.

Não precisa ser armazenado o espaço de estados do modelo, modelos matemáticos necessitam de menos tempo para sua construção e são menos suscetíveis a erros.

Porém, modelos realísticos complexos possuem um espaço de estados muito grande, tornando proibida a sua solução pois ultrapassam as limitações de memória.

Primeiramente o usuário deve definir os objetos que compõem o sistema.

Após este passo, os seguintes itens devem ser definidos para que os objetos possam interagir entre si, as variáveis de estado, os eventos e as condições para que os eventos sejam habilitados, as ações referentes a cada um destes eventos, as ações associadas ao recebimento de cada mensagem pelo objeto, as possíveis recompensas associadas a um ou mais estados.

O usuário deverá então selecionar o módulo de modelagem Modelling Environment, que deverá abrir a interface de modelagem.

Cada etapa completada pelo usuário na criação e análise do modelo habilita alguma figura da interface do ambiente de modelagem tornando-a colorida.

Portanto, inicialmente, todas as figuras da interface não são coloridas.

Para iniciar a criação do modelo, o usuário deve pressionar o botão new na interface de ambiente de modelagem e nomear o novo modelo a ser criado.

Após a conclusão desta etapa, a figura que representa o TGIF estará colorida, ou seja, habilitada para uso.

O modelo deve ser especificado no TGIF.

A definição de um objeto consiste na descrição de seis atributos, declaração, inicialização, eventos, variáveis de estado, mensagens e recompensas.

Declaração Este atributo é responsável pela declaração das variáveis, constantes e parâmetros usados no objeto.

Onde os seguintes tipos podem ser usados.

State, declara variáveis que representam o estado interno dos objetos.

Integer, Float, especifica constantes numéricas ou parâmetros.

Object, referencia outros objetos do modelo.

Port, define portas usadas na comunicação entre os objetos.

Inicialização Este atributo é responsável pela inicialização das variáveis de estado e pela definição das constantes.

Eventos, este atributo é responsável pela especificação de todos os eventos do objeto.

Um evento pode ser definido através de um nome, um tipo de distribuição e seus parâmetros, e as ações por ele definidas somente serão executadas se a condição para tal for satisfeita.

Segundo as regras da ferramenta, o valor de uma variável de estado pode ser alterada, através da função set_st, somente no final das ações.

A clonagem de eventos é feita quando se deseja gerar mais de uma amostra de um evento.

Um evento é clonado através da função clone_ev.

Para que as ações, especificadas no evento clonado, sejam executadas é necessário que a condição do evento seja satisfeita no momento que ele é clonado e quando ele for executado.

Variáveis de Estado Este atributo é responsável pela listagem das variáveis de estado que deverão ser mostradas durante a simulação interativa.

Cada passo da simulação atualiza os valores das variáveis de estado listadas neste atributo.

O usuário pode alterar o valor de alguma variável de estado, forçando uma mudança no caminho amostral.

Mensagens Este atributo é responsável pelo tratamento de todas as mensagens que podem ser recebidas pelo objeto.

Quando uma mensagem específica é recebida, a ação associada a esta mensagem é executada.

As mensagens são identificadas pela constante Port, que indica a porta que uma mensagem está sendo recebida.

Recompensas Este atributo é responsável pela especificação de recompensas de taxa e de impulso.

Diversas medidas de interesse podem ser obtidas através do uso das recompensas, como perdas, tempo de recuperação de um pacote perdido, número de falhas, tempo de reparo, vazão, utilização, tempo operacional e muitas outras medidas.

Um objeto pode ter várias recompensas definidas, possibilitando a obtenção de diversas medidas simultaneamente.

Se uma recompensa de taxa r i for associada a um estado i, então o sistema ganha a recompensa r i por unidade de tempo gasto no estado i.

A recompensa de impulso é associada a transições.

Se uma recompensa r ij é associada à transição do estado i para o estado j, então o sistema ganha a recompensa r ij toda vez que o sistema fizer uma transição de i para j.

No TANGRAM II, as recompensas de taxa estão associadas, através de condições, aos estados dos objetos.

Após a definição do nome da recompensa, a condição e o valor devem ser definidos, onde a primeira define o conjunto de estados em que a recompensa irá acumular o valor indicado.

A utilização de um objeto que simula uma fila, por exemplo, pode ser obtida através da definição de uma recompensa de taxa que acumule o valor unitário sempre que haja pacotes a serem servidos.

As recompensas de impulso são definidas através de um nome, da especificação do evento ou da mensagem que a recompensa estará associada e de uma ou mais ações que, ao serem executadas, farão com que a recompensa acumule o valor determinado.

O número de pacotes transmitidos por uma fonte pode ser obtido através de uma recompensa de impulso associada ao evento que gera os pacotes, por exemplo o evento geração_pacote.

Cada evento ou execução de mensagens pode estar associado a uma ou mais ações.

No exemplo da sintaxe acima, a recompensa se refere à primeira ação dentro do evento geração_pacote.

O número ao lado do nome do evento indica a ação à qual a recompensa se refere, e é relativo à ordem de aparição das ações no código do modelo, iniciando com 1.

O modelo foi implementado com o objetivo de facilitar a análise de desempenho da biblioteca Multicast confiável RML.

Devido à grande quantidade de variáveis de estado e a complexidade do modelo, as análises foram feitas através de simulações.

As simulações despendem um tempo significativamente menor quando comparadas com os testes reais.

Para obter medidas do comportamento da RML em uma apresentação com a duração de 1h no TGWB, por exemplo, seria necessário que alguns usuários estivessem em locais distintos da rede utilizando a ferramenta.

Além do tempo gasto para obtenção das medidas, recursos da rede seriam alocados para realização dos testes.

Para rodar o modelo, simulando uma apresentação com a duração de 1h, é gasto em média 6min em uma máquina Pentium III ou IV (ou processadores equivalentes) com mais de 128Mb de memória.

Além disso, é possível estudar cenários não disponíveis na realização dos testes.

Inúmeras topologias poderiam ser descritas através do modelo, porém foi necessária a escolha de uma topologia para a realização das simulações.

Como as seguintes universidades usadas para testes foram a UFRJ (Universidade Federal do Rio de Janeiro), a UFF (Universidade Federal Fluminense), a UFJF (Universidade Federal de Juiz de Fora) e a UMASS (Universidade de Massachusetts), o modelo descreve o ambiente de comunicação Multicast entre estas universidades.

Foram implementados dois modelos que descrevem a transmissão Multicast confiável, porém, com a disposição dos objetos um pouco diferente.

O modelo com o spliter representa a transmissão Multicast entre todos os membros do grupo, onde o spliter seria o último roteador comum entre o emissor e os receptores, e o modelo com os proxies simula os testes que serão apresentados no Capítulo 6, onde a transmissão entre os proxies é feita via conexão Unicast (maiores detalhes sobre os proxies encontram-se no Capítulo 6).

O funcionamento dos objetos em comum são idênticos, porém cada modelo tem sua especialidade, o modelo com o spliter é mais genérico e simula o suporte dos roteadores da Internet para a transmissão Multicast, no entanto o modelo com os proxies descreve o ambiente de testes utilizado para análise do comportamento da biblioteca durante uma apresentação na ferramenta TGWB.

Por terem as mesmas funcionalidades os objetos que representam as universidades e os canais são os mesmos, somente o spliter e o proxy possuem o funcionamento um pouco diferente.

As simulações consideram apenas um emissor de dados, o objeto UFRJ, e três receptores UFF, UFJF e UMASS.

O fato de simular os modelos com apenas um emissor não altera a análise das medidas de interesse.

Como as mensagens de controle são pacotes pequenos quando comparados aos pacotes de dados e as retransmissões, a probabilidade de perda é menor.

Sendo assim, no modelo da RML, para simplificação, é considerado que as mensagens de controle NACKs e refreshs nunca serão perdidas.

Também com o objetivo de simplificar, o modelo só considera a ocorrência de perdas e atrasos nos objetos que simulam os canais e os atrasos de ida e volta entre duas universidades são considerados iguais.

Entretanto estas simplificações podem facilmente ser descartadas.

A unidade de tempo considerada para os modelos é milisegundos (ms).

A utilização da distribuição uniforme, em alguns eventos, baseia-se na implementação proposta pelo protocolo SRM.

O código dos modelos encontra-se no Apêndice A.

Foram criados catorze objetos no modelo com o proxy e nove no modelo com o spliter, são eles quatro universidades em ambos os modelos, um spliter e quatro canais de comunicação no modelo com o spliter, quatro proxies e seis canais de comunicação no modelo com o proxy.

Os objetos que representam as universidades têm a função de enviar e receber dados Multicast, igualmente como foi implementado na biblioteca RML.

Estes objetos interagem entre si através do envio de dados, retransmissões, NACKs e refreshs.

Os objetos que representam os canais de comunicação simulam o atraso e as perdas na rede.

Quando uma mensagem é recebida pelo objeto através de uma porta, com a probabilidade (1 prob_perda) esta mensagem é colocada em uma fila de espera antes de ser enviada por um evento para a outra porta do objeto, simulando o atraso no canal, ou com a probabilidade prob_perda o objeto não faz nada, simulando a perda no canal.

O objeto spliter simplesmente repassa a mensagem para todas as suas portas, exceto para a porta pela qual a mensagem foi recebida.

Os objetos proxies quando recebem uma mensagem vinda por uma porta conectada com o canal, a repassam para a universidade e quando recebe uma mensagem vinda da porta que o conecta a universidade, a repassa para cada umas das portas que irão levá-la aos canais.

O comportamento de cada um destes objetos pode ser definido através dos eventos e das mensagens associados a condições e ações, conforme explicitado nas Seções.

As mensagens enviadas pelo modelo possuem as estruturas, onde o primeiro campo de cada mensagem é o seu tipo e o segundo é a identificação do emissor da mensagem.

Se o tipo da mensagem for DADO ou RET (retransmissão), então o terceiro campo conterá o valor do sn enviado.

Se o tipo da mensagem for NACK, então o terceiro campo em seguida conterá o valor do sn do pacote que requisita retransmissão.

Se o tipo da mensagem for REFRESH, então o terceiro campo conterá o valor do último sn enviado.

A cache é uma estrutura importante no modelo, similar a cache implementada na biblioteca RML, tem a função de guardar os dados recebidos, as informações sobre quais pacotes devem ser enviados os NACKs e quais estão esperando por retransmissão.

As seguintes variáveis auxiliam o gerenciamento de acesso à cache, sn_inicial, indica qual o valor do sn da posição inicial da cache.

Pos_inicial, indica a posição inicial da cache.

Pos_ultimo_id, indica a posição do último sn identificado.

Pos_ultimo_seq, indica a posição do último sn em sequência.

DADO indica o recebimento do dado NACK indica que deve ser enviado um NACK RET_WAIT indica a espera pela retransmissão do dado É uma representação simplificada da cache implementada no modelo, com apenas 5 posições.

Vamos supor que um objeto receba os pacotes com os sns de 0 a 6 e depois receba o pacote com o sn = 9.

Primeiramente, ao receber os pacotes com os sns de 0 a 4, o objeto mantém o valor do sn_inicial = 0, indicando que o menor pacote armazenado na cache é o pacote com o sn = 0.

Porém, como a cache possui apenas 5 posições, com o recebimento do pacote com o sn = 5, este substitui o pacote de sn = 0 e o valor da variável sn_inicial passa a valer 1, pois o pacote com o sn = 1 torna-se o menor pacote armazenado na cache até o momento.

Similarmente, o pacote com o sn = 6 ao ser recebido, substitui o pacote de sn = 1 e o valor da variável sn_inicial passa a valer 2.

O recebimento do pacote com o sn = 9 é indicado na posição 4 da cache através da palavra "DADO".

A posição deve ser 4 pois, segundo a equação 52, 9 mod 5 = 4.

O valor da variável sn_inicial, após o recebimento deste pacote, é 5, pois o pacote com o sn = 5 torna-se o menor pacote armazenado na cache.

O recebimento fora de sequência do pacote com sn = 9 faz com que o objeto detecte a perda dos pacotes com os sns 7 e 8.

Quando o objeto detecta a perda de pacotes, esta é indicada na cache através da palavra "NACK" na posição do sn que está esperando para enviar o NACK.

Devido às limitações do tamanho da cache, imposta pela ferramenta, onde um vetor pode ter no máximo 255 posições, foi implementado o vetor de retransmissões ret, com o objetivo de guardar os sns dos pacotes que deverão ser retransmitidos.

Portanto, apenas com a cache, no modelo, não seria viável simular a cache da biblioteca RML que possui o valor default igual a 4000, que é o tamanho suficiente para comportar o recebimento dos pacotes provenientes da captura de uma tela pelo usuário.

Então, o vetor ret simula a cache de 4000 posições da biblioteca.

Uma vez que são enviados e recebidos apenas o valor do sn do pacote, fica fácil retransmitir algum pacote perdido, bastando saber se este pacote ainda estaria na cache se esta tivesse 4000 posições e guardar valor do sn requisitado no vetor ret para futura retransmissão.

Obviamente, o vetor ret também possui apenas 255 posições, porém os sns não são mantidos em sequência como na cache, podendo armazenar até 255 pacotes fora de sequência para serem retransmitidos.

No modelo foram criadas recompensas para a análise do comportamento do vetor ret, onde foi possível variar o tamanho deste vetor e analisar se os pedidos de retransmissão recebidos eram escalonados no vetor, para futura retransmissão, ou se o vetor estava cheio de pacotes para retransmitir e, consequentemente, não escalonou a retransmissão.

Onde o comportamento do vetor de retransmissões, ret, foi analizado de acordo com as variações na perda e no tamanho do vetor em, respectivamente, 10, 20, 50 e 255 posições.

Para cada tamanho de vetor foram feitas duas simulações.

A primeira, identificada no lado esquerdo da tabela, simula as perdas obtidas a partir dos testes realizados com a biblioteca RML e a segunda, identificada no lado direito da tabela, possui valores maiores em relação ao valor das perdas obtidas nos testes, possibilitando a análise da sensibilidade do escalonamento das retransmissões no vetor ret diante do aumento das perdas.

As simulações foram feitas no modelo com o objeto spliter, porém devido ao igual funcionamento do vetor ret em ambos os modelos, pode-se considerar os resultados válidos para o modelo com o proxy também.

Os atrasos considerados nestas simulações foram obtidos através de RTTs coletados durante um dia, sendo eles, 500ms no canal entre o objeto spliter e o UFF, 127ms no canal entre o objeto spliter e o UFJF e, 125ms no canal entre o objeto spliter e o UMASS.

Pode ser observado que o atraso em relação a UFF foi maior do que o atraso em relação a UMASS, isso ocorreu devido à problemas, não identificados, no recebimento de dados na UFF.

As perdas consideradas encontram-se entre o objeto spliter e as universidades receptoras.

Podemos observar que o objeto UFJF manteve uma maior probabilidade de escalonar os pedidos de retransmissão.

Isso deve-se ao fato de possuir a maior perda, tornando-o o objeto que mais enviou NACKs, o que, consequentemente, provocou uma maior quantidade de pedidos de retransmissão nos demais objetos.

Também pode ser observado que o objeto UFF manteve a menor probabilidade de sucesso no escalonamento das retransmissões, pois uma vez que os temporizadores estão baseados nos atrasos da rede e o objeto em questão possui o maior atraso, o intervalo de tempo para retransmitir um pacote neste objeto é maior do que nos demais.

Assim o objeto UFF pode demorar mais que os outros para retransmitir, mantendo por mais tempo um pedido de retransmissão escalonado no vetor, o que aumenta a chance de não poder escalonar um novo pedido por falta de espaço, momentâneo, no vetor.

Com o aumento da perda na segunda simulação, o número de NACKs enviados pelos objetos também é aumentado, logo aumenta a probabilidade de um pedido de retransmissão não poder ser escalonado no vetor, ou seja, diminui a probabilidade de sucesso no escalonamento de um pedido de retransmissão.

Os resultados apresentados evidenciam que um vetor com 255 posições pode escalonar os pedidos de retransmissão 100% das vezes em que é requisitado.

É um exemplo do vetor de retransmissões ret, onde pos_ret_inicial indica a posição do próximo sn a ser retransmitido, pos_ret_final, indica a posição do último sn escalonado para ser retransmitido.

Após a retransmissão de um pacote, a variável pos_ret_inicial é incrementada.

Caso uma nova retransmissão seja escalonada, a variável pos_ret_final será incrementada e o sn a ser retransmitido deverá ser incluído na posição pos_ret_final.

No exemplo, o pacote com o sn = 25 já foi retransmitido e o próximo sn a ser retransmitido será o 29.

As estruturas fila_msg, Fila01 e Fila02 armazenam temporariamente as mensagens recebidas pelo objeto, possibilitando o funcionamento do evento Tratar_Msg e simulando o atraso no canal, respectivamente.

Evento com função de enviar dados Multicast para o grupo.

O evento não está habilitado em todos os objetos, somente no objeto que simula o emissor.

O evento possui distribuição uniforme e o intervalo de tempo para execução do evento encontra-se entre 30 e 60 s, simulando o tempo que um usuário levaria para trocar cada página de uma apresentação no TGWB.

O número de pacotes enviados pode variar cada vez que o evento é executado.

Como o objetivo é simular uma apresentação no TGWB, foi analisada a quantidade de pacotes que o TGWB manda em uma apresentação, considerando que 70% das apresentações são simples e sem figuras, 25% são com poucas figuras e 5% são com muitas figuras, e sabendo que quanto mais figuras maior é a quantidade de pacotes a serem transferidos.
Segue o resultado da análise do envio de dados em 70% das vezes são enviados em média 25 pacotes, em 25% das vezes são enviados em média 100 pacotes, em 5% das vezes são enviados em média 200 pacotes.

Portanto, o evento Enviar_Dados envia 25 pacotes com a probabilidade 0,7, 100 pacotes com a probabilidade 0,25 e 200 pacotes com a probabilidade 0,05.

A condição para o evento é sempre verdadeira para o objeto emissor, ou seja, o evento está sempre habilitado, devendo ocorrer segundo sua distribuição e intervalo de tempo.

E a condição é sempre falsa para os objetos receptores, não estando jamais habilitados para enviar dados.

Toda vez que uma mensagem é recebida pelos objetos UFRJ, UFF, UFJF e UMASS, a variável msg_cont é incrementada, indicando que existe uma mensagem a ser processada pelo objeto.

A condição para execução do evento Tratar_Msg é ter mensagem para tratar, ou seja, ter a variável msg_cont > 0.

Este evento se encontra apenas nos objetos UFRJ, UFF, UFJF e UMASS.

O evento Tratar_Msg retira a mensagem da fila fila_msg, verifica qual o seu tipo e qual ação deve ser tomada dependendo do tipo.

Assim como na RML, quando um NACK é recebido, o objeto deve verificar em sua cache se deseja enviar um NACK para os mesmos pacotes requisitados.

Caso positivo, então, o objeto tem o envio do NACK suprimido e deve indicar na cache que está esperando pela retransmissão.

Se na cache estiver indicando que o objeto já enviou o NACK para os mesmos pacotes e está esperando por retransmissões, então nada deverá ser feito.

Porém, se nenhum dos casos anteriores forem satisfeitos, o objeto deverá verificar a existência do pacote requisitado na cache e escalonar o evento para sua retransmissão.

Quando o objeto recebe um dado, deve verificar se está fora de sequência.

Caso esteja, deve então ser escalonado o evento para envio do NACK requisitando os pacotes perdidos.

Quando um refresh é recebido, é feita a mesma verificação utilizada para o recebimento de um dado.

Enfim, todas as ações tomadas no recebimento das mensagens pela biblioteca RML são simuladas no modelo.

Quando uma mensagem é recebida, as variáveis auxiliares aux_T_RET_MIN e aux_T_RET_MAX recebem o valor do limite mínimo e máximo, respectivamente, do intervalo do temporizador referente ao emissor do NACK.

Porém, se o evento Enviar_Retransmissão for clonado neste instante, as variáveis T_RET_MIN e T_RET_MAX, que determinam os limites mínimo e máximo do intervalo do temporizador deste evento, ainda não foram atualizadas.

Isto acontece porque todas as variáveis de estado somente são atualizadas no final das ações.

Portanto, foi necessária a criação do evento auxiliar Tratar_Msg como será explicado a seguir.

Supondo o valor inicial das variáveis T_RET_MIN = 4 e T_RET_MAX = 8 e que o objeto UFRJ receba uma mensagem NACK do objeto UFF.

Supondo ainda a seguinte descrição simplificada do código do recebimento de mensagens sem o uso do evento Tratar_Msg.

O evento Enviar_Retransmissão vai ser escalonado no intervalo entre T_RET_MIN e T_RET_MAX que são iguais a 4 e 8, respectivamente, no momento de disparo deste evento.

Porém, com o uso do evento Tratar_Msg, como sugerido no código simplificado a seguir, é assegurada a atualização das variáveis T_RET_MIN e T_RET_MAX no momento de disparo do evento Enviar_Retransmissão, conforme desejado.

O evento Tratar_Msg é executado segundo a taxa tratar_msg_rate e a condição msg_cont > 0 e não depende do valor das variáveis T_RET_MIN e T_RET_MAX para ser escalonado.

Portanto, o valor desatualizado destas variáveis, no momento de disparo do evento, não influenciam na sua execução, pois não indicam a taxa de execução do evento.

Este evento criará um clone do evento Enviar_Retransmissão, neste momento as variáveis T_RET_MIN e T_RET_MAX já estarão atualizadas com os valores 50 e 100.

Segue a descrição simplificada do código do recebimento de mensagens com o uso do evento Tratar_Msg.

Demonstra o intervalo do temporizador para disparo do evento Enviar_Retransmissão nas duas situações descritas anteriormente, sem e com o uso do evento Tratar_Msg, respectivamente.

O evento Enviar_Nack só está habilitado nos objetos UFF, UFJF e UMASS.

Sua função é verificar na cache quais as posições que contém o valor 2, pois indicam que o sn da posição foi perdido e que deverá ser enviado um NACK.

O valor 2 é substituído pelo valor 5, que sinaliza a espera pela retransmissão requisitada, e o NACK é enviado contendo todos os sns para os quais deseja-se receber retransmissões.

Cada NACK enviado pode conter até 64 sns, indicando 64 pedidos de retransmissões, assim como foi implementado na biblioteca RML.

Toda vez que for detectada uma perda, a variável nack_cont é incrementada, indicando que existe mais um NACK a ser enviado pelo objeto.

E a condição para execução do evento Enviar_Nack é ter NACK para enviar, ou seja, ter a variável nack_cont > 0.

Cada sn colocado na mensagem NACK a ser enviada, decrementa a variável nack_cont e incrementa a variável ret_wait_cont, que habilitará o evento Espera_Retransmissão.

O evento possui distribuição uniforme, variando os limites inferior e superior do intervalo, segundo a definição da biblioteca RML apresentada no Capítulo 4, TNACK = {A * delay receptor, emissor, (A + B) * delay receptor, emissor } onde delay receptor, emissor é o atraso entre o membro receptor e o membro emissor do dado transmitido e A e B são constantes.

Os valores das variáveis A e B podem variar, tornando flexível para que o usuário obtenha medidas de acordo com as variações destas variáveis.

Se uma retransmissão for recebida no momento em que o objeto está esperando para enviar um NACK correspondente, então a variável nack_cont é decrementada e a posição deste pacote na cache recebe o dado retransmitido, com o isso o NACK que estava escalonado não é enviado, simulando sua supressão.

Espera_Retransmissão O evento Espera_Retransmissão também só está habilitado nos objetos UFF, UFJF e UMASS.

Sua função é verificar na cache quais as posições que contém o valor 5, pois indicam que o sn da posição está esperando por uma retransmissão.

O valor 5 é substituído pelo valor 2, que sinaliza que a retransmissão requisitada não foi recebida e que deve ser enviado um novo NACK para este sn.

O evento estará habilitado se a variável ret_wait_cont > 0.

A variável ret_wait_cont deve ser decrementada e a variável nack_cont incrementada, a cada mudança do valor 5 para 2 em alguma posição da cache.

O evento possui distribuição uniforme, variando os limites inferior e superior do intervalo, segundo a definição da biblioteca RML apresentada no Capítulo 4, TWAIT = {C * delay receptor, emissor , (C + D) * delay receptor, emissor} onde delay receptor, emissor é o atraso entre o membro receptor e o membro emissor do dado transmitido e C e D são constantes.

Para tentar evitar o reenvio prematuro de NACKs, o tempo que se espera para enviar um novo NACK deve ser maior que a soma de quatro fatores, o tempo do NACK anterior chegar em algum membro, o tempo de processamento deste NACK, o tempo de espera para envio da retransmissão e o tempo desta retransmissão chegar no membro que enviou o NACK.

Com isso, tenta-se garantir que o reenvio do NACK só seja feito no caso da perda do NACK anteriormente enviado ou da retransmissão referente a este NACK.

Ilustra o cálculo abaixo, que para simplificação, considerou que o tempo de processamento do NACK é nulo e que os atrasos entre o receptor e o emissor são iguais.

Conclui-se que o valor do parâmetro C deve ser sempre maior que (2 + E + FA) para tentar evitar o envio prematuro dos NACKs.

Porém, o envio prematuro dos NACKs não pode ser evitado em todos os casos, pois a instabilidade da rede pode causar um aumento significativo no atraso entre os membros, fazendo com que a retransmissão demore mais tempo que o previsto para chegar e com isso que o membro que enviou o NACK acabe reenviando outro desnecessariamente.

Enviar_Retransmissão O evento Enviar_Retransmissão está habilitado nos objetos UFRJ, UFF, UFJF e UMASS toda vez que uma mensagem NACK é recebida.

Após o recebimento do NACK, o objeto incrementa a variável ret_cont.

Esta variável é a condição para execução do evento, ou seja, o evento será executado se ret_cont > 0.

Quando este evento é executado, o sn da posição pos_ret_inicial do vetor ret é enviado e a variável pos_ret_inicial é incrementada.

O evento possui distribuição uniforme, variando os limites inferior e superior do intervalo, segundo a definição da biblioteca RML apresentada no Capítulo 4, TRET = {E * delay receptor, emissor, (E + F) * delay receptor, emissor } onde delay receptor, emissor é o atraso entre o membro receptor e o membro emissor do dado transmitido e E e F são constantes.

Se uma retransmissão for recebida no momento em que o objeto está esperando para enviar a retransmissão correspondente, então a posição deste pacote no vetor ret recebe o valor 1.

Quando o evento Enviar_Retransmissão for executado e o sn do pacote a ser retransmitido for igual a 1, nenhuma mensagem deverá ser enviada, simulando a supressão de retransmissão.

Enviar_Refresh O evento Enviar_Refresh tem a função de enviar refreshs, que são mensagens indicando o sn do último pacote enviado.

O evento não está habilitado em todos os objetos, somente no objeto que simula o emissor.

O evento é determinístico e envia uma mensagem refresh a cada 10 segundos.

Delay01 e Delay02 Ambos os eventos têm o objetivo de simular o atraso da rede e encontram-se nos objetos que representam os canais de comunicação.

São eles rede01, rede02, rede03, rede04, rede05 e rede06.

Toda mensagem recebida com sucesso, por uma porta, pelo objeto, é armazenada temporariamente em uma fila de espera, tipo servidor infinito.

Os eventos Delay01 e Delay02 têm a função de retirar a mensagem recebida desta fila e enviá-la pela outra porta.

Estes dois eventos são definidos porque os objetos que representam os canais possuem duas portas.

No modelo com o spliter, uma das portas do canal o conecta ao emissor ou receptor e a outra ao spliter.

Portanto, o Delay01 recebe as mensagens vindas do objeto emissor ou receptor e as envia para o objeto spliter, e o Delay02 recebe as mensagens vindas do objeto spliter e as envia para o objeto emissor ou receptor.

No modelo com o proxy, ambas as portas do canal o conectam a dois diferentes proxies.

Por exemplo, o Delay01 recebe as mensagens vindas do proxy do objeto emissor, e o Delay02 recebe as mensagens vindas do proxy do objeto receptor.

A condição para ambos os eventos é ter mensagens em suas respectivas filas, Fila01 e Fila02.

A distribuição dos eventos Delay01 e Delay02 foi estudada, onde dados foram coletados com o objetivo de analisar a distribuição do atraso na rede.

O atraso na rede se aproxima de uma distribuição normal truncada.

Os testes feitos mostram que a média dos atrasos é igual a 32935 e que o desvio padrão é igual a 8032, baseando-se nisso foi obtido o coeficiente de variação igual a 0,24.

Uma vez sabido o valor do coeficiente de variação, é possível calcular a variância, onde o coeficiente de variação é fixo e igual a 0,24 e a média é o atraso médio da rede, obtém-se a variância relativa à média do atraso da rede que se pretende simular.

As mensagens recebidas pelos objetos que simulam o emissor e os receptores são colocadas na fila fila_msg para futuro processamento.

É verificado se a mensagem é um NACK.

Caso seja, os limites mínimo e máximo do intervalo de execução do evento Enviar_Retransmissão são calculados de acordo com o emissor do NACK.

O evento Tratar_Msg é clonado para tratamento da mensagem recebida.

As mensagens recebidas pela porta 1 dos objetos que simulam o canal são colocadas na fila Fila01.

O evento Delay01 é clonado, com o objetivo de retirar a mensagem da fila e enviá-la para a porta 2, simulando um retardo sem espera de fila.

O caminho inverso ocorre quando a mensagem é recebida pela porta 2.

O objeto spliter quando recebe uma mensagem simplesmente a envia para as portas diferentes da porta pela qual a mensagem foi recebida.

Por exemplo, se a mensagem chegou no objeto através da porta 4, esta mensagem é enviada para as portas 1, 2 e 3.

As mensagens recebidas nos objetos proxies pela porta que o conecta ao canal, são repassadas somente para o objeto que representa a universidade e quando as mensagens são recebidas pela porta que o conecta à universidade, elas são repassadas para cada umas das portas que irão levá-las aos canais.

As recompensas criadas no modelo têm o objetivo de obter as seguintes medidas de interesse, perdas de dados e retransmissões, tempo de recuperação dos pacotes perdidos, número de NACKs enviados e recebidos por pacote perdido, número de retransmissões enviadas e recebidas por pacote perdido.
Número de pacotes de dados enviados pelo emissor, número de pacotes de dados recebidos pelos receptores, número de NACKs recebidos de um determinado objeto, número de retransmissões recebidas de um determinado objeto.

As variáveis de estado representam o estado interno dos objetos.

No modelo, entre outras, podem ser encontradas as variáveis de estado cache, que mantém armazenadas informações sobre os dados recebidos, e ret, que mantém os sns a serem retransmitidos.

As demais variáveis servem para controle das duas variáveis citadas anteriormente e para determinar a condição de execução de alguns eventos.

As declarações das variáveis, assim como comentários sobre elas.

Neste capítulo encontram-se os testes e as simulações realizadas com a finalidade de analisar o comportamento da transmissão Multicast confiável diante das diferentes situações propostas.

Após a implementação da biblioteca RML, vários experimentos na Internet foram realizados com o objetivo de testar o comportamento da transmissão Multicast confiável.

Alguns experimentos são apresentados nesta dissertação com o objetivo de comparar seus resultados com os resultados obtidos através do modelo, e os demais experimentos pertencem ao estudo desenvolvido na dissertação.

A realização dos testes contou com a colaboração de quatro universidades, são elas UFRJ (Universidade Federal do Rio de Janeiro), UFF (Universidade Federal Fluminense), UFJF (Universidade Federal de Juiz de Fora) e UMASS (Universidade de Massachusetts).

São descritas as características das máquinas utilizadas nos testes.

Devido ao fato dos roteadores precisarem manter uma tabela com o estado de todos os membros do grupo Multicast, introduzindo complexidade e problemas de escalabilidade, poucos roteadores na Internet encontram-se com a transmissão Multicast habilitada.

Portanto, para que a biblioteca RML pudesse ser testada, foi necessária a implementação de um proxy, denominado rmproxy (Reliable Multicast Proxy), cuja função é receber dados Multicast em uma rede local e repassá-los via conexão Unicast para os demais proxies, especificados em um arquivo de configuração.

Além disso, receber dados, via conexão Unicast, e repassá-los para a rede local via conexão Multicast.

Para não influenciar os resultados, o protocolo de transporte usado na conexão Unicast, estabelecida entre os proxies, é o UDP, portanto sem confiabilidade na transmissão, ou seja, podem ocorrer erros e perdas na transmissão, que deverão ser tratados pela biblioteca implementada.

Ilustra o ambiente de teste com o uso do programa rmproxy.

Para facilitar os testes, ao invés de mantermos usuários utilizando o TGWB em cada uma das universidades, o que seria inviável dispor de recursos humanos, foi implementado um programa, denominado rmtest, com a função de enviar e receber dados simulando uma apresentação no TGWB.

Os dados são enviados segundo a análise feita no Capítulo 5 sobre as taxas de envio de dados em uma apresentação no TGWB.

O programa rmtest, assim como o modelo, envia 25 pacotes com a probabilidade 0,7, 100 pacotes com a probabilidade 0,25 e 200 pacotes com a probabilidade 0,05.

Quando se deseja simular os testes feitos com o programa rmtest, é necessário obter alguns parâmetros dos testes para que a simulação tenha os resultados próximos dos resultados reais.

A implementação do rmtest viabilizou a flexibilidade nos testes, como a possibilidade da mudança de emissor, pois a cada momento uma universidade pode ser escalonada para ser a emissora dos dados.

A realização dos testes pode ser feita a qualquer instante, bastando que as quatro máquinas especificadas estejam disponíveis.

O rmproxy e o rmtest podem estar ou não na mesma máquina.

Nos testes e nas simulações foram considerados que ambos estão na mesma máquina, portanto o atraso e as perdas dos dados entre eles são nulos.

As simulações foram feitas com diferentes cenários, tentando representar o máximo das variações encontradas em uma rede de transmissão de dados.

Cada simulação foi feita com o intervalo de confiança de 95% e com 10 rodadas para aumentar a confiabilidade nos resultados.

A cache variou em 1000 e 4000 posições.

O vetor ret variou em 10, 20, 50 e 255 posições, para análise do escalonamento das retransmissões.

As taxas de envio de dados foram alteradas nas simulações de comparação do modelo com os testes, objetivando analisar a perda diante das diferentes taxas de envio.

As constantes A, B, D, E e F variaram para a análise da influência destes parâmetros, porém a constante C se manteve igual a 5 devido ao fato deste parâmetro ter que ser necessariamente maior que 4, conforme explicado no Capítulo 5.

O valor dos temporizadores, dos atrasos e das perdas variaram com o objetivo de analisar o comportamento da transmissão Multicast confiável de acordo com estas variações.

A simulação da transmissão Multicast através do modelo com o spliter requer uma análise do atraso e das perdas diferente da análise feita no modelo com o proxy.

A disposição dos objetos é diferente, simulando diferentes ambientes na rede.

Em seguida será explicado como foi feita a análise destes parâmetros em cada um dos modelos criados.

O modelo tem o valor do atraso nos canais de acordo com o valor obtido nos testes feitos com o programa rmtest.

Contudo, somente são obtidos os atrasos entre cada uma das universidades e não o atraso entre a UFRJ e o spliter, sendo necessária a medição deste valor.

Como o objeto spliter representa o último roteador comum entre a UFRJ e as demais universidades, foi medido o atraso entre a UFRJ e o roteador de endereço 200209458, identificado como o último roteador comum.

Nas medições foi obtido o atraso de aproximadamente 5ms.

Com isso, o valor do atraso no canal entre a UFRJ e o spliter não se alterou durante as simulações, mantendo-se em 5ms, e somente o valor dos atrasos entre o spliter e as universidades receptoras variou.

Para obter o valor do atraso no canal entre o spliter e as universidades receptoras, baseando-se no atraso obtido nos testes, que é o atraso total entre a UFRJ e as demais universidades e sabendo que o valor do atraso entre a UFRJ e o spliter é de aproximadamente 5ms, basta diminuir 5 ms do valor obtido nos testes.

A diferença é o atraso considerado entre o spliter e as universidades receptoras.

O valor do atraso nestes canais não é uma diferença direta como foi proposto nas simulações, porém, baseando-se no fato de que o atraso é instável, a diferença obtida de modo direto não influencia significativamente nos resultados das simulações.

Se por exemplo, nos testes com o programa rmtest for obtido o atraso médio entre a UFRJ e a UFF de 100ms, então, no modelo é simulado o atraso médio de 5ms no canal entre a UFRJ e o spliter e de 95ms no canal entre o spliter e a UFF.

Assim como o atraso simulado no modelo é obtido através dos testes realizados, o mesmo acontece com as perdas.

Com os resultados dos testes, é possível obter a perda entre a UFRJ e as demais universidades, porém, no modelo com o spliter existem dois canais entre cada uma das universidades.

Entretanto, é preciso saber onde atribuir a perda obtida nos testes, uma vez que podem ocorrer perdas no canal entre a UFRJ e o spliter ou no canal entre o spliter e as universidades receptoras.

No caso do atraso, foram feitas medições de seu valor no canal entre a UFRJ e o roteador simulado pelo spliter e a diferença entre este valor e o valor total do atraso no canal entre a UFRJ e as universidades, foi atribuída ao canal entre o spliter e as universidades receptoras.

Porém, devido à impossibilidade de acesso ao roteador para que pudesse ser medida a perda entre ele e a UFRJ, foi feito um estudo da sensibilidade da localização da perda.

O estudo da sensibilidade da perda consiste em analisar o comportamento do modelo diante das perdas nos canais.

Para que o estudo pudesse ficar mais claro, os modelos foram ligeiramente modificados.

Os eventos de espera por retransmissão, de envio de NACKs, de envio de retransmissões e de atraso no canal passaram a ter uma distribuição determinística, forçando os objetos a enviarem pacotes com a mesma taxa.

As simulações descritas em seguida não fizeram uso dos parâmetros A, B, C, D, E e F, pois, para estas simulações, os eventos não possuem uma distribuição uniforme, onde estes parâmetros auxiliam no cálculo dos limites inferior e superior do intervalo do temporizador.

Entretanto, estes eventos possuem uma distribuição determinística, conforme citado anteriormente.

Apresenta as taxas de envio associadas aos eventos.

Taxas de envio associadas aos eventos determinísticos Mostram a distribuição das perdas nos dois modelos simulados para análise do estudo da sensibilidade.

A perda simulada em ambos foi de 20%.

A perda está localizada entre a UFRJ e o spliter, portanto a perda sempre ocorre igualmente para as universidades receptoras, ou seja, quando ocorre uma perda entre a UFRJ e o spliter, todas as universidades receptoras perdem o mesmo pacote.

Com isso, somente a UFRJ pode retransmitir o pacote perdido e a probabilidade de sucesso na recuperação dos pacotes retransmitidos pela UFRJ é a probabilidade de sucesso do modelo = 1 (probabilidade de falha) = 1 p onde p é a probabilidade de perda.

Com p = 0,20, a probabilidade de sucesso é 0,80.

A perda está localizada entre o spliter e as universidades receptoras.

Como as perdas somente podem ocorrer depois do objeto spliter, não teremos neste caso perdas idênticas como no anterior, ou seja, quando ocorrer perdas, qualquer outro objeto estará habilitado para retransmitir.

Com p = 0,20, a probabilidade de sucesso é 0,968.

Para o modelo, temos uma probabilidade maior de sucesso no recebimento das retransmissões, ou seja, o tempo de recuperação é menor para este modelo quando comparado ao tempo de recuperação do modelo.

Mostram a média do tempo de recuperação obtido na simulação dos dois modelos.

Nesta dissertação, em todas as simulações feitas com o modelo com o spliter, foi adotada a atribuição das perdas nos canais entre o spliter e as universidades receptoras.

Deste modo, torna-se mais fácil a inicialização do modelo, pois uma vez que as perdas nos canais entre a UFRJ e as universidades podem ser diferentes, basta colocar cada uma das probabilidades de perda nos canais entre o spliter e as respectivas universidades.

Para modelar a transmissão Multicast confiável, simulando o uso do programa rmproxy feito nos testes, é necessário simular o valor do atraso entre cada uma das universidades.

O modelo com o spliter poderia simular as conexões Unicast, propostas pelo rmproxy, se os atrasos entre elas fossem relativamente iguais.

Porém, como isso não é verdade, foi necessária a criação do modelo com o proxy, que possui seis canais de comunicação simulando a conexão Unicast entre cada uma.

Mostra a média dos atrasos, obtidos através dos RTTs (Round Trip Time) coletados entre as universidades durante 15 dias, com intervalo de 1h entre o envio dos pings.

Além de observarmos que o valor do atraso entre elas é diferente, podemos detectar que o valor do atraso é um pouco diferente se muda o sentido da transmissão dos dados.

Portanto, em cada canal foram simulados valores diferentes para os atrasos nos dois sentidos da transmissão e estes valores podem ser obtidos diretamente do teste a ser simulado.

Neste ponto, pode ser observado também, que o atraso em relação a UFF diminuiu quando comparado aos valores obtidos em testes anteriores.

Através dos testes, somente podem ser obtidas as perdas entre a UFRJ e as demais.

Portanto, para simular todas as perdas dos canais, durante uma transmissão Multicast, foi preciso obter um valor estimado das perdas entre cada uma das universidades.

Foi feito um teste com baixa taxa de envio de dados, com a duração de 1h, onde apenas 1 ou 10 pacotes foram enviados, em intervalos entre 1 e 60s, simulando as retransmissões enviadas durante a transmissão Multicast.

De acordo com estes testes, foram obtidas as probabilidades de perdas.

As perdas do canal entre a UFRJ e as universidades receptoras são obtidas diretamente dos testes que se deseja simular, ou pode se considerar as médias das perdas obtidas em vários testes realizados ao longo do desenvolvimento desta dissertação.

Após a implementação do modelo, foi necessário testar se os resultados obtidos através do modelo descrevia a tendência do comportamento da biblioteca.

Para isso, três testes foram escolhidos para serem simulados e terem seus resultados comparados.

Ou seja, foi feito a comparação do comportamento da transmissão Multicast confiável a partir dos resultados obtidos do modelo com o proxy e dos resultados obtidos a partir dos testes feitos com a biblioteca RML.

Identifica cada dos testes que foram simulados.

O parâmetro C se manteve igual a 5 para os dois primeiros testes e, igual a 7 no teste 3, de acordo com a exigência impostas no Capítulo 5.

Configurações dos testes que foram simulados.

No teste 1 foram enviados 3775 pacotes, e as perdas obtidas foram 0,0448 entre a UFRJ e a UFF, 0,0445 entre a UFRJ e a UFJF e 0,0450 entre a UFRJ e a UMASS, e os atrasos obtidos no início dos testes.

Mostra os resultados deste teste e os Gráficos 64, 65 e 66 mostram o tempo de recuperação dos pacotes perdidos pelas universidades, de acordo com este teste.

A simulação do teste 1 considerou as perdas e os atrasos obtidos a partir deste teste.

Mostra os resultados da simulação do teste 1 e mostram o tempo de recuperação dos pacotes perdidos pelas universidades, de acordo com esta simulação.

Pela simulação foram enviados 4077 pacotes.

O pico identificado do tempo de recuperação do teste 1 é resultado do envio de uma rajada de 200 pacotes.

Esta rajada ocasionou muitas perdas consecutivas e com isso o tempo médio de recuperação aumentou.

Nas simulações, as perdas consideradas no canal são válidas durante toda a simulação, não simulando o envio com mais ou menos perdas para uma determinada rajada de dados.

Devido a este fato, o tempo médio de recuperação dos pacotes, assim como o número de NACKs e retransmissões enviados no teste 1, é maior do que na simulação.

No teste 2, foram enviados 4000 pacotes, as perdas obtidas foram 0,0353 entre a UFRJ e a UFF, 0,0353 entre a UFRJ e a UFJF e 0,0351 entre a UFRJ e a UMASS e os atrasos obtidos no início dos testes, que foram praticamente os mesmos atrasos obtidos no teste 1.

Neste teste não ocorreu o envio de rajadas de 200 pacotes e, com isso, não houve muitas perdas consecutivas.

Mostra os resultados do teste 2 e mostram o tempo de recuperação dos pacotes perdidos pelas universidades, de acordo com este teste.

A simulação do teste 2 considerou as perdas e os atrasos obtidos a partir deste teste.

A simulação do teste 3 considerou as perdas e os atrasos obtidos a partir do mesmo.

Mostra os resultados da simulação e mvostram o tempo de recuperação dos pacotes perdidos pelas universidades, de acordo com a simulação.

Pela simulação foram enviados 2760 pacotes.

As universidades tiveram o comportamento semelhante quando comparamos o teste com a simulação.

Devido à perda da UFJF ser maior que a perda das demais, ela teve o maior número de NACKs enviados.

A UFRJ por possuir sempre todos os pacotes requisitados, teve o maior número de retransmissões enviadas, seguido da UFF, que teve a perda menor do que a UMASS, aumentando a sua chance de ter o pacote requisitado para retransmissão.

Quanto ao tempo de recuperação, no teste a UFJF teve o maior tempo e na simulação o maior tempo de recuperação foi o da UMASS.

Como o atraso é maior nos canais que enviam dados a UMASS, nas simulações o tempo de recuperação ficou maior para esta.

Porém, como a rede não é estável este comportamento não foi idêntico no teste 3, pois a rede pode ter parado por alguns instantes, resultando em um valor maior do tempo de recuperação para a UFJF.

Este aumento no tempo de recuperação da UFJF pode ser percebido entre os pacotes de sn 1400 e 1500.

Podemos perceber que o modelo consegue simular a tendência do comportamento da transmissão Multicast na rede e, quanto menor for a variação do atraso durante a transmissão de dados, mais precisos serão os resultados da simulação.

Os dois modelos criados nesta dissertação possuem características diferentes.

No modelo com o spliter, quando um pacote perdido é recuperado, a partir de alguma universidade receptora, a probabilidade de perda considerada no caminho entre a universidade que perdeu o dado e a universidade que vai retransmiti-lo é maior do que no modelo com o proxy.

Isto acontece porque no modelo com o spliter a perda considerada nos canais é a perda obtida entre a UFRJ e as demais.

Esta perda é obtida a partir dos testes, onde a UFRJ envia grandes quantidades de dados e quanto mais dados são enviados maior é a probabilidade de perda.

De acordo com as simulações do modelo com o spliter, se o objeto UFF, por exemplo, retransmite um pacote para a UFJF, a probabilidade de perda no canal entre a UFF e o spliter é 0,13 e no canal entre o spliter e a UFJF é 0,26.

Portanto, é considerada a perda entre a UFRJ e as demais e não a perda real entre a UFF e a UFJF, que é menor.

No modelo com o proxy, a perda é calculada para cada canal.

Como entre as universidades receptoras somente retransmissões são enviadas, a probabilidade de perda é menor quando comparada com as perdas do modelo com o spliter.

De acordo com as simulações do modelo com o proxy, se o objeto UFF, por exemplo, retransmite um pacote para a UFJF, a probabilidade de perda no canal entre a UFF e a UFJF é de 0,0449.

Portanto, devido às probabilidades de perda nos canais, o tempo de recuperação para o modelo com o proxy é menor do que no modelo com o spliterv.

As perdas consideradas nas simulações são as perdas apresentadas e os atrasos em todos os canais é de 100ms.

Apresenta o intervalo de confiança de 95% do tempo de recuperação das universidades para os dois modelos.

Segundo as definições dos intervalos TNACK, TWAIT e TRET, apresentados nos Capítulos 4 e 5, o aumento dos parâmetros A e B causa o aumento no intervalo de envio dos NACKs e o aumento dos parâmetros C e D causa o aumento do intervalo de espera por retransmissões, aumentando o tempo de recuperação dos pacotes.

O aumento dos parâmetros E e F também causa o aumento no tempo de recuperação, pois o intervalo para envio das retransmissões é aumentado de acordo com estes dois parâmetros.

As simulações apresentadas a seguir têm o objetivo de estudar o comportamento do tempo de recuperação, de acordo com as variações dos parâmetros.

As simulações desta seção foram feitas com o modelo com o proxy.

Primeiramente, foram feitas duas simulações variando os valores dos parâmetros A, B, D, E e F com o objetivo de analisar o impacto na mudança de seus valores.

O parâmetro C, em todas as simulações, variou de acordo com a exigência imposta no Capítulo 5.

Em ambas as simulações foi assumido o atraso de 100ms em todos os canais e as perdas.

Em uma das simulações o valor dos parâmetros A, B, D, E e F foi 2 e C = 5 e na outra o valor destes cinco primeiros parâmetros foi aumentado para 4 e C para 7.

Os Gráficos 625, 626 e 627 comparam o tempo de recuperação, o número de NACKs e retransmissões enviadas, respectivamente, obtidos nas simulações.

O tempo de recuperação dos pacotes perdidos aumenta na simulação, onde A = B = D = E = F = 4, devido ao aumento do intervalo antes do envio dos NACKs.

O número de NACKs também aumenta nesta simulação devido ao aumento do intervalo antes do envio das retransmissões, pois, como as retransmissões demoram mais a serem enviadas, o número de retransmissões diminui e, consequentemente, mais NACKs são enviados na rede.

Outra simulação foi feita com os seguintes valores, A = B = D = 4, E = F = 2 e C = 5.

Mantendo o intervalo de tempo igual antes do envio das retransmissões, é possível analisar a diminuição do número de NACKs enviados, quando comparada com a simulação, onde A = B = D = E = F = 2, pois além do intervalo para envio dos NACKs ter aumentado, as retransmissões continuam sendo enviadas com a mesma taxa.

A comparação do tempo de recuperação pode ser observada.

O número de retransmissões enviadas na simulação, onde A = B = D = 4 e E = F = 2, também diminuiu pois os NACKs demoram mais a serem enviados.

Na simulação com A = B = D = E = F = 4, além do tempo de recuperação aumentar muito em relação ao resultado usando os valores A = B = D = E = F = 2, o número de NACKs enviados também aumenta, portanto, não é eficiente a utilização do valor 4 para os parâmetros A, B, D, E e F.

Na simulação com A = B = D = 4 e E = F = 2, o tempo de recuperação aumenta um pouco em relação ao resultado usando o valor 2 para os parâmetros A = B = D = E = F, mas o número de NACKs enviados é ligeiramente menor.

Porém, se para a aplicação for primordial a recuperação rápida dos pacotes, não interessando se haverá mais NACKs enviados pela rede, é mais eficiente a utilização dos parâmetros A = B = D = E = F = 2, uma vez que na simulação com estes valores, o tempo de recuperação se apresentou menor em relação às outras duas simulações realizadas.

Apresentam o intervalo de confiança de 95% do tempo de recuperação, do número de NACKs enviados e do número de retransmissões enviadas das três simulações estudadas nesta seção.

Sendo a simulação 1, a simulação com A = B = D = E = F = 2, a simulação 2, com A = B = D = E = F = 4 e a simulação 3, com A = B = D = 4 e E = F = 2.

O ambiente criado no modelo para simular as supressões dos NACKs e das retransmissões é descrito a seguir, todos os canais com atraso de 100ms, a UFRJ considera o atraso de 10ms para cálculo do temporizador TRET, a UFJF considera o atraso de 200ms para cálculo do temporizador TNACK e TWAIT.

O temporizador TRET da UFRJ possui um intervalo menor do que os intervalos dos temporizadores das demais universidades, uma vez que estes são calculados considerando o atraso de 100ms, definido nos canais.

O fato do intervalo do temporizador TRET da UFRJ ser menor aumenta a sua chance de enviar uma retransmissão que suprima as demais.

Os temporizadores TNACK e TWAIT da UFJF, por serem calculados considerando o atraso de 200ms e não de 100ms como consideram as demais, tornam o intervalo de tempo antes do envio do NACK maior e, consequentemente, aumentam a chance de ter mais NACKs suprimidos.

Estas diferenças em relação ao intervalo dos temporizadores entre as universidades foi feita para que a supressão dos NACKs e das retransmissões ficasse mais evidentes.

Foram feitas duas simulações, com o modelo com o proxy, para análise da supressão de NACKs e retransmissões em relação a variação das perdas, uma com as perdas apresentadas e a outra com as perdas de 40%, 60%, e 30% nos canais entre a UFRJ e a UFF, a UFRJ e a UFJF e a UFRJ e a UMASS, respectivamente.

Ambas simulações consideram as perdas, apresentadas nos canais entre as universidades receptoras.

Na simulação com as perdas obtidas a partir dos testes foram enviados em média 4220 pacotes de dados e na outra simulação 4140 pacotes.

Ambas simulações com os parâmetros A, B, D, E e F com o valor 2 e C com o valor 5.

As simulações evidenciam que o aumento da perda leva ao aumento do número de NACKs e retransmissões enviados.

As perdas apresentadas nestas tabelas se referem aos canais entre a UFRJ e as universidades receptoras.

Mostra as percentagens, obtidas nas simulações, de NACKs e retransmissões suprimidos.

Devido ao fato da UFRJ possuir o intervalo do temporizador TRET com um valor significativamente inferior ao valor do mesmo temporizador nas demais universidades, ela não teve nenhuma retransmissão suprimida.

Como a UFJF possui a maior perda, menos pacotes são escalonados para retransmissão, com isso, a quantidade de retransmissões suprimidas representa uma maior percentagem.

Por exemplo, se a UFJF possui três retransmissões escalonadas e a UMASS possui dez, e a UFRJ envia uma retransmissão que suprime uma retransmissão em cada uma dessas universidades, então, são suprimidas aproximadamente 33% das retransmissões escalonadas na UFJF e 10% na UMASS.

A UFJF, por ter o intervalo dos temporizadores TNACK e TWAIT maior, teve a maior percentagem de supressão de NACKs.

Outras duas simulações foram feitas para análise da supressão de NACKs e retransmissões em relação a variação dos temporizadores.

Ambas consideraram as perdas nos canais entre a UFRJ e a UFF, a UFRJ e a UFJF e a UFRJ e a UMASS, respectivamente e as perdas, nos canais entre as universidades receptoras.

Em uma simulação os parâmetros A, B, D, E e F teve o valor 4 e C o valor 7 e na outra, A, B, D, E e F teve o valor 6 e C o valor 9.

Com isso, foi possível analisar a sensibilidade da supressão de pacotes em relação ao aumento dos temporizadores.

Os membros que possuem o menor atraso em relação ao emissor devem enviar NACKs e retransmissões antes, estes podem suprimir os NACKs e as retransmissões dos membros com atraso maior.

Portanto, quanto mais distante um membro estiver do emissor e dos outros membros, maior a chance de supressão para os pacotes enviados por este membro.

No cenário simulado, a UFJF possui o maior atraso em relação ao emissor, portanto, esta foi escolhida para a análise da sensibilidade da supressão de pacotes em relação a variação dos temporizadores.

Com o aumento dos parâmetros, o intervalo antes do envio dos NACKs aumenta mais para a UFJF do que para as demais, pois o seu atraso em relação ao emissor é maior, podendo com isso aumentar a chance de um NACK escalonado por esta ser suprimido.

O mesmo comportamento ocorre em relação a supressão de retransmissão.

Como o atraso considerado para cálculo do temporizador TRET da UFRJ é 10ms, seu intervalo de tempo antes de enviar uma retransmissão é menor, mesmo com o aumento dos parâmetros.

Com isso, pode aumentar a chance da UFRJ suprimir as retransmissões das demais universidade, ou seja, pode aumentar a chance da UFJF, por exemplo, ter retransmissões suprimidas conforme o aumento dos temporizadores.

Porém, mostra que a percentagem de supressão de pacotes da UFJF aumenta pouco conforme a variação dos parâmetros dos temporizadores.

Portanto, segundo evidências obtidas através do modelo, a supressão dos NACKs e das retransmissões é pouco sensível em relação ao aumento dos temporizadores.

Esta seção tem o objetivo de analisar o comportamento da transmissão Multicast de acordo com as variações dos atrasos, dos temporizadores e das perdas.

Para isto, foram feitas 63 simulações com o modelo com o proxy, considerando as perdas para os canais entre as universidades receptoras e variando a perda em 10%, 20% e 30% no canal entre a UFRJ e as universidades.

Os atrasos variaram em 100ms, 300ms e 500ms.

Os temporizadores TNACK, TWAIT e TRET foram calculados segundo as variações do atraso em 100ms, 150ms, 200ms, 250ms, 300ms, 350ms e 400ms.

Apresentam o tempo de recuperação (em ms) da UFF e o número de NACKs enviados por pacote pela UFF para os atrasos nos canais de 100ms, 300ms e 500ms.

Como os resultados do tempo de recuperação e do número de NACKs enviados pelas universidades foram semelhantes, somente os resultados da UFF serão apresentados nesta dissertação.

Nestes gráficos, podemos perceber que o aumento da perda ocasiona o aumento do tempo de recuperação e, o número médio de NACKs enviados pouco variou (note que os intervalos de confiança se sobrepõem).

Além disso, ao compararmos os gráficos com os atrasos nos canais de 100ms, 300ms e 500ms, percebemos que o tempo de recuperação aumenta proporcionalmente ao aumento do atraso no canal.

Porém, o número médio de NACKs enviados pouco variou, ou seja, comparando os mesmos valores dos temporizadores para diferentes atrasos nos canais, o número médio de NACKs enviados pouco varia, mostrando a pouca sensibilidade do número de NACKs enviados em relação ao aumento do atraso no canal.

O aumento do intervalo dos temporizadores gera o aumento, praticamente linear, do tempo de recuperação, porém, o número médio de NACKs enviados se manteve praticamente constante.

Onde o número médio de NACKs enviados por pacote se manteve na faixa entre 1,186 e 1,615 para a perda de 10%, 1,510 e 1,725 para a perda de 20% e 1,766 e 1,936 para a perda de 30%.

Os Gráficos 637, 638 e 639 apresentam o número de retransmissões enviadas por pacote pela UFRJ para os atrasos nos canais de 100ms, 300ms e 500ms.

Em cada gráfico, podemos perceber que o aumento da perda ocasiona o aumento do número de retransmissões enviadas.

O número de retransmissões enviadas se manteve praticamente constante para a simulação com o atraso no canal de 100ms.

Nas simulações com o atraso no canal de 300ms e 500ms pode ser observado que o número médio de retransmissões enviadas por pacote diminui conforme aumenta o intervalo dos temporizadores.

Esta diminuição é mais evidente no gráfico para atraso de 500ms, pois quanto maior é o atraso no canal, maior é o intervalo de chegada entre os NACKs, com isso, o aumento do intervalo dos temporizadores antes do envio das retransmissões aumenta a probabilidade de uma única retransmissão valer para um maior número de NACKs recebidos, sem que haja a necessidade de retransmissões repetidas e, consequentemente, diminuindo o número de retransmissões enviadas.

Portanto, conforme aumenta o atraso no canal, a variação do número de retransmissões torna-se mais sensível à variação do intervalo dos temporizadores.

Porém, como o atraso no canal geralmente é menor que 500ms, o número de retransmissões tende a não variar muito diante das variações dos temporizadores.

Devido ao número médio de NACKs enviados variar pouco em relação ao aumento do atraso no canal, temos, como consequência, uma pequena variação do número de retransmissões enviadas em relação ao aumento deste atraso.

Este comportamento é evidenciado quando comparamos o número médio de retransmissões enviadas.

Alguns gráficos apresentaram um comportamento não esperado, onde o número de NACKs enviados para o intervalo mínimo do temporizador em 600ms e perda de 30% é maior do que para o intervalo mínimo do temporizador em 500ms e mesma perda.

Entretanto, este número deveria ser menor, pois uma vez que o intervalo para envio dos NACKs aumenta, menos NACKs deveriam ser enviados pela rede.

Porém, as simulações foram rodadas simulando 1h de apresentação no TGWB e, uma possível explicação para esta aparente incoerência é que este tempo não é suficiente para que o modelo entre em estado estacionário.

Para verificar esta suposição, o modelo com o intervalo mínimo do temporizador em 600ms e perda de 30% foi rodado novamente simulando 5h de apresentação no TGWB.

Com os novos resultados, foi verificado que o número de NACKs diminuiu em relação ao número de NACKs do intervalo mínimo do temporizador em 500ms, conforme o esperado.

Com o aumento do intervalo dos temporizadores, o número médio de NACKs e retransmissões enviadas se mantém praticamente constantes, além do tempo de recuperação aumentar sensivelmente.

Portanto, para os cenários estudados, as simulações evidenciam que o aumento do intervalo dos temporizadores não é recomendável.

Com isso, podemos concluir que o valor deste intervalo deve ser o menor possível, visando um menor tempo de recuperação dos pacotes perdidos, porém, evidentemente, garantindo a supressão de NACKs e de retransmissões.

As redes de computadores, em particular, as aplicações multimídia distribuídas, continuam a desenvolver-se em um ritmo acelerado, crescendo em tamanho e complexidade.

Com isso, torna-se cada vez mais importante ter processamento e largura de banda suficientes para a distribuição desses tipos de dados.

A transmissão Multicast pode reduzir o número de pacotes duplicados no canal, economizando largura de banda e, conseqüentemente, otimizando o uso da rede.

Como a transmissão Multicast não é confiável, foi necessária a realização de um trabalho para garantir a confiabilidade desta transmissão.

Portanto, o estudo desta dissertação concentra-se na implementação da confiabilidade e na análise de desempenho da transmissão Multicast.

Após os estudos realizados no Capítulo 2 sobre os tipos de protocolos para transmissão Multicast confiável, onde foram analisadas as vantagens e as desvantagens de cada um deles, o protocolo Enhanced-Receiver-Initiated foi escolhido para ser implementado, devido à superioridade de seu desempenho em relação aos demais protocolos.

Com isso fica atribuído ao receptor a responsabilidade da recuperação dos dados perdidos.

Para garantia da confiabilidade na transmissão Multicast, foi implementada, em equipe, a biblioteca denominada Reliable Multicast Library (RML), que pode ser vista como um protocolo em uma camada superior à camada de transporte, com a função de detectar perdas de pacotes e recuperar eficientemente os pacotes perdidos, tornando a transmissão Multicast confiável.

O desenvolvimento da ferramenta TGWB já havia sido iniciado por outros alunos, porém faltava garantir a confiabilidade na transmissão Multicast.

Portanto, o TGWB foi integrado a biblioteca RML, como resultado de um trabalho em equipe, envolvendo mais dois alunos, um de mestrado e outro de graduação.

No momento desta integração algumas funcionalidades do TGWB foram aprimoradas.

O TGWB foi a principal aplicação distribuída que fez uso da biblioteca para garantir a confiabilidade na transmissão Multicast.

As demais aplicações usadas, como o programa rmtest, testaram a biblioteca simulando o funcionamento do TGWB.

Também foram criados dois modelos da transmissão Multicast confiável simulando diferentes ambientes na rede.

Primeiramente, foi implementado um modelo mais genérico, onde se considera que toda a comunicação é feita através da transmissão Multicast.

Em seguida, foi implementado um modelo que representa o ambiente de testes criado para validar o comportamento do TGWB com o uso da biblioteca RML desenvolvida.

A análise de desempenho feita no Capítulo 6 mostrou que a transmissão Multicast se comporta de diferentes maneiras, dependendo da situação da rede no momento da transmissão.

A possibilidade de mudar os parâmetros do modelo para analisar diferentes situações torna o estudo do comportamento da transmissão Multicast confiável prático e motivador.

Como resultados deste trabalho estão disponibilizados, em domínio público, a biblioteca RML, que garante a confiabilidade em uma transmissão Multicast, e o modelo que a descreve, tornando possível à análise de desempenho e o ajuste de parâmetros para diferentes condições da Internet.

Além disso, a distribuição internacional da ferramenta TGWB.

Duas linhas de atuação podem estender o trabalho aqui apresentado, os aperfeiçoamentos na biblioteca RML, com o objetivo de otimizar o trabalho desenvolvido e as modificações no modelo implementado.

Na biblioteca RML podem ser acrescentadas algumas funcionalidades, como otimização do cálculo dos temporizadores, fazendo com que o cálculo seja feito dinamicamente.

Com isso, o intervalo do temporizador estará sempre atualizado de acordo com as variações do atraso na rede, prevenção de NACKs prematuros, ou seja, aumentar gradualmente o intervalo de envio de NACKs para o mesmo pacote perdido, ignorar pedidos duplicados de retransmissões, ou seja, não retransmitir pacotes que acabaram de ser retransmitidos.

O acréscimo destas funcionalidades visariam a diminuir o tempo de recuperação dos pacotes perdidos e ao número de pacotes NACKs e retransmissões enviados pela rede.

O modelo poderia ser modificado para abranger, além dos dois ambientes implementados nesta dissertação, mais ambientes de transmissão Multicast.

Nesta modificação pode estar incluída o acréscimo de novos objetos, como outros roteadores e membros.

E, caso fossem implementadas as funcionalidades anteriormente sugeridas para a biblioteca, estas poderiam ser facilmente implementadas no modelo.

Outro trabalho que poderia ser feito, é a implementação do Multicast na aplicação, possibilitando o uso de aplicações distribuídas em redes sem suporte ao Multicast nativo.

