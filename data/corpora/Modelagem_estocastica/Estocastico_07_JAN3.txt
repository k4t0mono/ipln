Forward Error Correction (FEC) funciona adicionando informação redundante ao fluxo sendo transmitido com o objetivo de reconstruir o fluxo original no cliente quando ocorrem perdas de pacotes.

Dentre suas vantagens estão o pequeno atraso inserido para recuperar informações comparado com a retransmissão e simplicidade de implementação.

Um clara desvantagem é o aumento na taxa de envio devido à redundância adicionada.

Como a perda de pacotes é devida ao congestionamento na maioria dos casos, aumentar a quantidade de proteção usando FEC pode ser injusto com fluxos com controle de congestionamento e até pode resultar em mais perdas, o efeito inverso.

Logo, algoritmos baseados em FEC devem ser cuidadosamente escolhidos de acordo com as características de erros no caminho entre o emissor e o receptor.

Outra questão é desenvolver modelos precisos para o processo de perda de pacotes.

Foi desenvolvido um modelo de Markov oculto (HMM) que é capaz de capturar as correlações no processo de perda de pacotes e manter um espaço de estados suficientemente pequeno para uso em um algoritmo adaptativo baseado em FEC.

Explorando as possíveis correlações no processo de perda de pacotes, propomos um algoritmo adaptativo e o aplicamos em um conjunto grande de fluxos de voz sobre IP.

A transmissão de dados em tempo real na Internet, como voz e vídeo, vem se popularizando cada vez mais.

O aparecimento de equipamentos como webcams, de programas como o FreePhone, GnomeMeeting e NetMeeting e o aumento da capacidade do canal tanto para o usuário doméstico, quanto para empresas e universidades nos últimos anos são apontados como principais fatores para esta popularização.

Um grande problema no desenvolvimento de aplicativos para transmissão de dados em tempo real é que o meio pelo qual os dados irão trafegar é essencialmente não confiável, em outras palavras, a Internet é uma rede best-effort.

Parâmetros como banda passante mínima, retardo máximo e taxa de perda máxima de pacotes não são garantidos, comprometendo a transmissão de tráfego de tempo real.

Diferentes classes de aplicações de tempo real tem diferentes requisitos de qualidade.

Por exemplo transmissão de voz em tempo real é pouco tolerante ao retardo e mais exigente ainda com relação a taxa de perda pacotes.

Aplicações de transmissão de vídeo em tempo real toleram mais a perda de pacotes mas também não toleram o retardo.

As soluções para o problema de jitter são conhecidas e estão já amadurecidas.

Entretanto o problema de perda de pacotes ainda encontra grandes desafios.

Algumas soluções foram propostas.

O objetivo deste trabalho é o desenvolvimento de um algoritmo adaptativo para a previsão e recuperação de perda de pacotes para aplicativos de transmissão de áudio interativos.

Este algoritmo utiliza Modelos de Markov Ocultos (HMM) como mecanismo central para a previsão.

Este trabalho está organizado da seguinte forma.

No Capítulo 2 será discutido como é feita a transmissão de voz no caso de aplicativos para comunicação iterativa.

O Capítulo 3 apresentará um programa de comunicação via voz usando a Internet desenvolvido pelo LAND, bem como a biblioteca de funções para recuperação de pacotes perdidos que foi baseada.

No Capítulo 4 serão apresentadas as teorias sobre HMM que servirão de base para a introdução do algoritmo.

No Capítulo 5 é apresentado o algoritmo de previsão e recuperação desenvolvido neste trabalho.

O Capítulo 6 discute os resultados obtidos por este algoritmo e o compara com outros dois algoritmos que estão atualmente em uso.

Finalmente no Capítulo 7 são feitas algumas considerações sobre o algoritmo proposto e também são discutidos possíveis trabalhos futuros.

Este capítulo abordará as questões relacionadas à transmissão de fluxos de tempo real na Internet dando ênfase aos fluxos de áudio.

Também é discutido neste capítulo a modelagem do processo de perda de pacotes e as técnicas para reparo de mídia devido à perda de pacotes.

Na Seção 22 são discutidas as características dos modelos de perda de pacotes mais utilizados na literatura e as técnicas de reparo de mídia normalmente utilizadas para fluxos de áudio são discutidas.

Ilustra o processo de transmissão de áudio utilizando a Internet como meio de propagação.

O emissor envia os pacotes de áudio em seqüência e igualmente espaçados.

Ao passar pela rede, os roteadores podem fazer com que o tempo entre pacotes fique variável.

Isto acontece devido ao tamanho da fila de pacotes no roteador na hora da chegada do pacote.

Outra conseqüência comum é a perda do pacote devido à falta de espaço no roteador para armazenar o pacote recém chegado.

Normalmente aplicações de tempo real utilizam o protocolo de transporte UDP para envio dos dados.

Este protocolo pode fazer com que os pacotes tomem caminhos diferentes para alcançar o mesmo destino (receptor) resultando em uma terceira conseqüência que é a chegada fora de ordem dos pacotes.

Para corrigir o problema do atraso variável entre os pacotes e da ordem de chegada dos mesmos basta que o receptor armazene um certo número deles em área de memória apropriada, conhecida como playout buffer.

A utilização do playout buffer implica em um atraso adicional para se tocar um pacote que é proporcional ao tamanho deste buffer.

É demonstrado que o tamanho deste buffer não precisa ser grande, o que é essencial para aplicativos de tempo real.

O número de aplicações de tempo real, bem como a quantidade de usuários que as utilizam, cresceu a ponto de ser criado um protocolo exclusivamente dedicado a elas, o Real-Time Protocol (RTP).

A perda de pacotes é um dos principais fatores que influenciam a qualidade do sinal recebido.

Por essa razão entender e modelar este processo é imperativo para analisar o desempenho dos algoritmos de recuperação de perdas de pacotes.

No modelo de perda de Bernoulli, a seqüência de variáveis aleatórias é independente e identicamente distribuída, isto é, a probabilidade de perder o i-ésimo pacote é independente da perda ou não de pacotes anteriores da série temporal e as probabilidade são as mesmas independente de i.

Este modelo é caracterizado por um único parâmetro, que é a probabilidade de se perder um pacote.

No modelo de Gilbert, também conhecido como modelo de Markov de ordem 2, assume-se que o número de pacotes perdidos consecutivos é uma variável aleatória geométrica.

Diferentemente do modelo de Bernoulli, este modelo é capaz de capturar a dependência entre perdas consecutivas, mas tem um parâmetro adicional.

Os dois parâmetros, p e q, são as probabilidades de transição entre os dois estados.

Neste modelo, o processo de perda de pacotes é modelado através de uma cadeia de Markov de ordem k.

Sendo assim, o estado atual depende de um certo número de valores prévios do processo que é a ordem do processo.

Os modelos de Bernoulli e Gilbert são casos especiais deste modelo, onde a ordem vale, respectivamente, 1 e 2.

Seja X t uma série temporal binária de tempo discreto, onde X = 0 significa não perda e X = 1 significa perda.

Um processo fX t g é uma cadeia de Makov de ordem k se a probabilidade condicional é independente de x t h para todos os valores.

Este modelo foi utilizado na tentativa de capturar a dependência temporal das perdas nos arquivos de registro coletados.

Num modelo de Markov Oculto (HMM) cada estado pode emitir um subconjunto de símbolos de acordo com alguma distribuição.

Os estados e as transições entre estados não são diretamente observáveis, mas podem ser inferidos pela seqüência de símbolos.

É proposto o uso de HMM para a modelagem de perda em um canal de comunicação, pois diferentemente do uso de cadeias de Markov tradicionais, as HMM's exibem infinitas dependências do processo em observação, nesse caso a perda de pacotes, mesmo com poucos estados.

Mostra também que é possível modelar o processo de perdas usando HMM's de no máximo 4 estados, enquanto que teve que usar cadeias de Markov tradicionais de até 42 estados para modelar o mesmo processo.

O uso de HMM não é restrito à modelagem de perdas em canal de comunicação.

Na verdade, foram criadas nos fins da década de 60 e estudadas no início da década de 70.

Sua popularidade cresceu com o uso em reconhecimento de fala na década de 80 e hoje em dia podem ser usadas virtualmente em qualquer área, incluindo identificação de genes e construção automatizada de portais de Internet.

As técnicas de reparo de mídia podem ser divididas em duas grandes classes, as baseadas no emissor e as baseadas no receptor.

As técnicas baseadas no receptor não requerem nenhuma assistência do emissor e basicamente tentam produzir um substituto para o pacote perdido utilizando pacotes anteriores, posteriores ou ambos.

Esse conjunto de técnicas é muito utilizado para fluxos de áudio, pois os sinais de áudio exibem uma grande quantidade de auto similaridade de curta duração.

As técnicas baseadas no receptor podem ser divididas em três categorias inserção, interpolação e regeneração.

Emissor Ativo Passivo Retransmissão Interleaving Forward Error Correction, independente da mídia Dependente da mídia Mostra as técnicas de reparo que requerem a participação do emissor para reconstruir pacotes perdidos.

Técnicas ativas são aquelas que requerem que uma medida seja tomada somente quando ocorre o problema e técnicas passivas são aquelas baseadas em loop aberto, isto é, são técnicas preventivas.

As técnicas baseadas no emissor podem ser divididas em retransmissão, Forward Error Correction e Interleaving.

Esta técnica consiste em se inserir uma amostra de áudio no lugar do áudio contido no pacote perdido.

Geralmente a amostra de áudio inserida é um ruído de fundo, silêncio ou a última amostra recebida.

Esta técnica é simples de se implementar, mas, com exceção da inserção da última amostra recebida, tem um desempenho fraco.

Esta técnica regenera o pacote perdido usando algumas formas de reconhecimento de padrões e interpolação.

Esta técnica é geralmente mais difícil de implementar do que a inserção.

Esta técnica utiliza os estados do decodificador para os pacotes anterior e posterior ao pacote perdido para tentar reproduzir o último.

Esse processo é caro de implementar mas pode dar bons resultados.

A técnica de retransmissão, também conhecida por ARQ (Automatic Repeat reQuest), consiste no receptor requisitar a transmissão de um determinado pacote assim que o receptor detecta a perda do mesmo.

Esta técnica é muito utilizada na transferência de arquivos, onde é exigida total confiabilidade, mas não é muito recomendada para aplicativos de tempo real, pois o atraso inserido pela retransmissão é quase sempre inaceitável.

Uma variação desta técnica é o receptor enviar pacotes de confirmação (ACK) para cada pacote recebido.

Se o emissor não receber um ACK para um determinado pacote dentro de um intervalo de tempo pré-estabelecido, então o emissor retransmite o mesmo.

Esta variação sofre dos mesmos problemas da versão original com relação a transmissão de mídia em tempo real.

A vantagem desta técnica é que nenhuma banda é disperdiçada, já que um pacote só é retransmitido se o mesmo for considerado como perdido.

Uma outra técnica para se recuperar pacotes perdidos é conhecida como Forward Error Correction (FEC).

Nesta técnica além de enviar os pacotes com a mídia, o emissor envia também informações adicionais.

Essas informações adicionais são conhecidas como redundâncias e são usadas na reconstrução de pacotes perdidos.

Estas redundâncias podem ser dependentes ou não da mídia sendo transmitida.

Na técnica FEC dependente de mídia, informações como o tipo da mídia sendo transmitida, a codificação ou ambas são utilizadas para gerar a redundância.

A técnica FEC independente da mídia consiste em se usar ou blocos, ou operações algébricas, ou códigos para produzir as redundâncias que serão usadas para a reconstrução dos pacotes perdidos.

A desvantagem em se utilizar pacotes adicionais para reconstruir pacotes perdidos é que normalmente a perda de pacotes é atribuída ao congestionamento da rede e adicionando mais pacotes pode-se agravar o problema resultando em um efeito inverso ao que se queria, que era diminuir a taxa de perda.

O uso de redundância como solução para reparo de mídia de tempo real é tão promissor que o autores do Real-Time Protocol (RTP) propuseram modificações para que o mesmo possa utilizá-las.

Muito esforço em pesquisa e implementação vem sendo gasto no uso de redundância como principal mecanismo para reconstruir pacotes perdidos.

FEC Dependente de Mídia Um exemplo de FEC dependente da mídia é o algoritmo proposto.

Neste algoritmo um pacote além de carregar a amostra de áudio original, ele também carrega uma cópia da amostra de áudio anterior possivelmente utilizando uma codificação de mais baixa qualidade.

Ilustra esta abordagem.

Os pacotes normais estão representados por retângulos normais, enquanto que as redundâncias estão representadas por retângulos sombreados.

Podemos ver que o pacote 2 carrega o pacote 1, o pacote 3 carrega o pacote 2 e assim por diante.

Se o receptor não receber o pacote 2, por exemplo, o receptor poderá reconstruir o pacote 2 com a redundância contida no pacote 3.

Por outro lado, se o receptor também perder o pacote 3, ele poderá recuperar este último pacote quando o pacote 4 chegar, mas ele não poderá recuperar o pacote 2 usando o pacote 3 recém recuperado, pois a redundância do pacote 3 não é recuperada.

Uma desvantagem desta técnica é que ela só recupera o último pacote de uma rajada de pacotes perdidos.

Uma solução para corrigir esta desvantagem seria o pacote n carregar uma cópia do pacote n 1 e do pacote n 2.

O problema é o custo adicional em termos de banda para este tipo de solução.

Como mencionado anteriormente, adicionar pacotes extras indiscriminadamente pode agravar o problema da perda de pacotes, por isso propõe uma alteração no algoritmo apresentado acima para torná-lo dinâmico.

Nesta abordagem são usados os pacotes de controle do RTP (RTCP) para enviar informações sobre o processo de perdas de pacotes que está sendo observada pelo receptor.

Este processo pode ser modelado no receptor como uma variável aleatória Bernoulli ou por um modelo de Gilbert.

Estes pacotes são enviados com intervalo de 5 segundos entre eles.

O emissor utiliza o valor recebido para consultar uma tabela.

Esta tabela relaciona o novo esquema de redundância a ser utilizado de acordo com a taxa de perda observada pelo receptor antes do processo de recuperação dos pacotes perdidos.

Um dos problemas desta abordagem é que ela só usa os últimos 5 segundos de áudio e por isso não consegue capturar a correlação entre perdas para lags maiores que 5 segundos.

Além disso, o algoritmo supõe que as perdas podem ser modeladas por um processo de Bernoulli ou de Gilbert, o que nem sempre é verdade.

FEC Independente de Mídia Um exemplo de FEC independente da mídia é o algoritmo proposto.

Neste algoritmo, o fluxo de áudio é dividido em grupos, chamados de janelas e os pacotes das janelas são subdivididos em conjuntos disjuntos, chamados cadeias.

A redundância de cada cadeia é calculada através de um operação XOR utilizando todos os pacotes da cadeia.

Ilustra o conceito de janela e cadeia.

A grande vantagem desta técnica é a possibilidade de recuperar mais de um pacote de uma rajada de perda.

Uma desvantagem desta técnica é o atraso necessário para se recuperar um pacote perdido.

Para recuperar o pacote perdido é necessário que todos os pacotes pertencentes a sua cadeia tenham chegado, bem como a redundância que o protege.

Apesar de a técnica de Interleaving não poder recuperar um pacote, ela é usada para reduzir os efeitos da perda de pacotes.

Antes de transmitir os dados, o emissor mistura o conteúdo de diversos pacotes, fazendo com que, no evento da perda de um pacote, o resultado seja pequenas perdas em diversos pacotes.

Ilustra este processo.

Se o pacote 3 for perdido, como resultado ocorreram pequenas falhas nas amostras 1, 2 e 4 e não um vazio do tamanho de uma amostra.

Neste capítulo será apresentado o programa de comunicações de áudio utilizando a Internet e a biblioteca de recuperação de perdas de pacotes desenvolvidos pelo LAND.

Com o objetivo de medir e analisar o tráfego de voz, em 1997 foi desenvolvida uma ferramenta de comunicação com uma funcionalidade e qualidade de áudio semelhante ao telefone.

Esta ferramenta foi chamada de VivaVoz e desde então vem sendo usada como ambiente de estudos de algoritmos relacionados a voz.

O programa foi originalmente escrito utilizando linguagem C e não dispunha de uma interface amigável com o usuário.

Diversas alterações foram feitas no projeto original, muitas para permitir a utilização da linguagem TCL/TK para fazer a interface com o usuário.

Em 1999 o programa foi totalmente reescrito para facilitar a comunicação com a interface com o usuário.

Atualmente existe duas versões de interface para o programa VivaVoz uma interface gráfica feita em Qt e uma texto feita com o ncurses.

O programa VivaVoz mostra as estatísticas observadas nos dois sentidos do fluxo de áudio.

As informações relativas às estatísticas locais, isto é, que são coletadas pelo aplicativo local, são atualizadas a cada segundo.

Como é preciso enviar um pacote do aplicativo remoto para o local para obter as estatísticas remotas, elas são atualizadas uma vez por minuto.

Além das estatísticas mostradas na tela, o programa também pode gerar um arquivo de registro contendo o número de sequência, o tamanho e a hora de chegada dos pacotes.

Com essas informações é possível calcular, por exemplo, o jitter, a taxa de perda, etc.

O formato do arquivo de registro é compatível com a ferramenta Tangram-II também desenvolvida pelo LAND.

Uma das modificações sofridas pelo programa VivaVoz foi a inserção de uma biblioteca de funções para recuperação de pacotes.

Esta biblioteca recupera pacotes utilizando a técnica Forward Error Correction (FEC) independente de mídia.

Optou-se por implementar uma biblioteca para facilitar a utilização deste conjunto de rotinas para recuperação de pacotes em outros aplicativos.

É importante ressaltar que apesar desta biblioteca ter sido desenvolvida para ser utilizada no programa VivaVoz, não existe motivo que a impeça de ser usada por aplicativos que usam outro tipo de mídia.

A biblioteca poderia ser usada, por exemplo, por um aplicativo de transmissão de vídeo sem que houvesse nenhuma alteração.

A terminologia adotada foi utilizada na implementação da biblioteca e será reproduzida nesta seção.

A biblioteca utiliza a operação OU-EXCLUSIVO para proteger grupos de pacotes e trabalha com o conceito de janela e cadeia.

Uma cadeia designa os pacotes que são protegidos pela mesma redundância e a janela indica os pacotes que fazem parte das cadeias.

Os pacotes protegidos por uma cadeia estão intercalados com os pacotes das outras cadeias.

O número de pacotes protegidos por uma cadeia é igual ao tamanho da janela divido pelo número de cadeias.

Por esta razão o tamanho da janela deve ser um múltiplo do número de cadeias.

Um esquema de redundância é designado pelo número de cadeias e pelo tamanho da janela, por exemplo 36 refere-se ao esquema de redundância com janela de tamanho 6 e três cadeias utilizando dois pacotes cada uma para formar a redundância.

Mostra a estrutura de um pacote com duas redundâncias.

Os primeiros 8 bytes formam o cabeçalho de um pacote contendo redundâncias.

O primeiro byte contém uma assinatura que permite a rotina de reconstrução de pacotes identificar os pacotes corretos.

O segundo byte diz quantas redundâncias o pacote inteiro contém.

O campo "Tamanho do Pacote" diz quantos bytes contém o pacote contando o tamanho do cabeçalho FEC e as redundâncias com os seus respectivos cabeçalhos.

O último campo deste cabeçalho armazena o número de sequência dos pacotes com redundâncias.

Os campos "Número de Sequência Base", "Máscara de Bits" e "Tamanho" compõem o cabeçalho de uma redundância.

O campo "Tamanho" indica o tamanho da redundância sem contar o cabeçalho.

Os campos "Número de Sequência Base" e "Máscara de Bits" indicam os pacotes que foram usados para construir esta redundância e que, consequentemente, podem ser recuperados por ela.

Os próximos bytes contém a redundância propriamente dita, seguida do cabeçalho da segunda redundância e assim por diante.

Além das informações contidas nos pacotes de redundância, a única informação extra que a rotina de recuperação de pacotes precisa para reconstruir um pacote perdido, são os pacotes de áudio originais que chegaram com sucesso.

A biblioteca desenvolvida permite a mudança de esquemas de redundância em tempo de execução.

Um problema que ocorre nesta mudança é que se as cadeias atuais forem substituídas pelas novas alguns pacotes não estarão cobertos pela redundância.

Isto ocorre porque o esquema novo precisa de pelo menos uma janela para produzir a primeira redundância.

Ilustra o problema para o esquema 24, onde são usadas 2 cadeias para uma janela de tamanho 4.

Neste exemplo o pacote número 5 carrega a redundância produzida pelos pacotes 1 e 3, enquanto que o pacote número 6 carrega a redundância que protege os pacotes 2 e 4.

Se o esquema for alterado no instante de tempo t e as cadeias forem apagadas, as informações necessárias para a construção da redundância de 2 e 4 serão perdidas, fazendo com que o pacote número 6 não carregue nenhuma redundância.

No caso da redundância obtida com os pacotes 1 e 3 o desperdício é ainda maior, pois a redundância já foi calculada e só esperava a requisição da aplicação para ser liberada.

A solução para o problema acima é não apagar a cadeia assim que ocorre uma mudança de esquema.

Quando ocorre uma mudança de esquema as cadeias atuais são marcadas como "zombies" e só irão efetivamente ser apagadas depois que a redundância produzida por elas for requisitada pela aplicação.

No instante de tempo t as duas cadeia serão marcadas como "zombies".

No instante de tempo t + 2 a cadeia formada pelos pacotes 1 e 3 será apagada da memória enquanto que a cadeia formada pelos pacotes 2 e 4 só será apagada.

O termo "zombie" foi retirado através de analogia com os processos UNIX, que são processos que já terminaram o seu trabalho, mas estão a espera que o pai recupere o seu valor de término.

Neste capítulo serão apresentados a notação e os conceitos sobre HMM.

A notação apresentada nesta seção será usada pelas seções subseqüentes.

No final deste capítulo é abordado o programa desenvolvido usando os conceitos apresentados.

Este programa serviu de base de testes tanto para a pesquisa apresentada aqui bem como para a pesquisa.

O artigo define HMM como sendo um processo estocástico duplamente embutido onde existe um processo estocástico implícito que não é observável, mas que pode somente ser "visto" através de um outro conjunto de processos estocásticos que produzem a seqüência de observações.

Por exemplo, vamos considerar um cassino desonesto que usa dois tipos de dados para um determinado jogo.

Um dado é normal, ou seja, a probabilidade de sair qualquer uma de suas 6 faces é 1/6.

O outro dado é viciado de modo que a face com 6 saia 50% das vezes.

Um jogador não sabe que o cassino está usando mais de um dado e vai apenas ver os resultados dos dados, ou, em outras palavras, a seqüência de observações deste experimento.

Como o jogador não vê a troca dos dados, ele pode apenas inferir sobre esse processo através da seqüência de observações, portanto este processo é oculto para o jogador.

Formalmente um HMM é caracterizada por cinco elementos.

Número de estados do modelo.

Apesar de em geral os estados serem ocultos, em muitas aplicações existe um sentido físico em cada estado.

No exemplo citado acima, o analista pode criar um modelo onde cada estado representa um dado diferente com diferentes probabilidades de emissão de cada face.

Número de símbolos distintos do modelo Também conhecido como tamanho do alfabeto.

Os símbolos são as saídas físicas do sistema sendo modelado.

No exemplo do cassino desonesto, os símbolos são as faces dos dados.

Matriz de probabilidade de transição Indica a probabilidade do sistema sair de um estado para outro em um passo.

Ainda no exemplo do cassino, a matriz de probabilidade de transição indica a probabilidade de o cassino trocar do dado normal para o dado viciado e vice-versa.

A probabilidade de transição do estado i para o estado j.

Matriz de probabilidade de emissão.

A probabilidade de emissão do símbolo k dado que o sistema está no estado j.

Seja T uma seqüência de observações de um determinado processo.

O problema mais difícil relacionado com HMM's é como ajustar os parâmetros de modo a maximizar.

Para resolver este problema precisamos primeiro encontrar uma maneira eficiente de calcular.

A maneira mais simples de se calcular seria calcular todas as possibilidades da seqüência T por todos os possíveis caminhos de tamanho T.

A probabilidade de O dado o modelo é obtida através da soma das probabilidades conjuntas sobre todas as possíveis seqüências de estados.

Este cálculo não é factível, mesmo para pequenos valores de N e T.

Existe um procedimento mais eficiente para calcular e esse procedimento é conhecido como Procedimento Forward-Backward.

O procedimento Forward-Backward não só calcula como também ajuda a calcular a nova matriz de transições, os novos vetores de emissões e o novo valor do vetor de distribuição dos estados iniciais.

A probabilidade de a seqüência de observações parcial de t + 1 até o instante final T dado o estado S i no instante de tempo t e o modelo.

Mostra que para chegar ao estado S i no instante de tempo t tem que se considerar a seqüência de observações a partir do tempo t + 1.

É necessário levar em conta todos os possíveis estados S j no instante de tempo t + 1 contando a transição de S i para S j e a observação O t+1 no estado j e então contar a seqüência de observações parcial a partir do estado j.

Cálculo das Transições Seja a variável a probabilidade de transição do estado i no instante de tempo t para o estado j no instante de tempo t + 1 dado o modelo e a seqüência de observações O.

Ilustra graficamente como funciona o cálculo de uma transição usando as variáveis forward e backward.

Para se ter uma transição do estado i no instante de tempo t para o estado j no instante de tempo t + 1 com a emissão do símbolo O t+1 no estado j, é necessário calcular a probabilidade de se estar no estado i no instante de tempo t.

A seguir, tem que se calcular a probabilidade de transição de i para j, que é exatamente o termo a ij e finalmente a probabilidade do estado j emitir o símbolo O t+1, representada na fórmula pelo termo b j (O t+1).

O termo t+1 (j) significa a probabilidade de obter a seqüência parcial a partir do instante de tempo t + 1 até o final sabendo-se que neste instante de tempo o sistema está no estado j dado o modelo e a seqüência de observações.

Se o termo for somado para todos os intervalos de tempo t, obtém-se o número esperado de transições do estado i para o estado j.

Como base na equação apresentada acima, pode-se definir a variável t como sendo a probabilidade de se estar no estado i no instante de tempo t dado o modelo e a seqüência de observações.

Em alguns casos é útil saber a seqüência de estados de uma cadeia de Markov Oculta que melhor representa uma determinada seqüência de observações.

Uma maneira de se obter a seqüência de estados é escolher os estados q t que são individualmente mais prováveis.

O resultado final usando esta metodologia maximiza o número esperado de estados individualmente corretos.

Conforme definido acima, Usando t pode-se calcular o estado q t individualmente mais provável no instante de tempo t5 Apesar de maximizar o número esperado de estados corretos, não garante que a seqüência de estados produzida seja válida, pois esta equação simplesmente determina o estado mais provável para cada instante de tempo sem levar em consideração a probabilidade da seqüência de estados.

Outra maneira é maximizar P, ou seja, encontrar a seqüência de estados mais provável, o que é equivalente a maximizar P.

O algoritmo de Viterbi é uma técnica baseada em métodos de programação dinâmica para encontrar a seqüência de estados mais provável.

Para encontrar a seqüência mais provável de estados para uma dada seqüência de observações é preciso atribuir uma pontuação para a seqüência, isto é, é a mais alta pontuação (mais alta probabilidade) para uma seqüência de estados, no tempo t para as primeiras t observações e que termina no estado S i.

É necessário armazenar o argumento que maximiza para cada t e j.

Esse argumento é armazenado no vetor t (j).

O procedimento completo para encontrar a seqüência de estados mais provável utilizando os conceitos acima é inicialização, recursão, término.

Seqüência de estados.

Tendo-se definido uma metodologia para o cálculo de cada componente individual de uma cadeia de Markov Oculta, é possível elaborar um procedimento iterativo para treinar esta cadeia.

O algoritmo apresentado aqui é o algoritmo Expectation-Maximation (EM) e é baseado no algoritmo de Baum-Welches.

A cada iteração do algoritmo a probabilidade do modelo dada a seqüência de observações é incrementada.

Isto garante a convergência do modelo para um máximo.

O maior problema desta técnica é que este máximo é local e não global.

O primeiro passo é escolher os parâmetros, A e B do modelo.

Esta escolha é feita de modo arbitrário e pode levar ao máximo global ou ao máximo local longe do máximo global.

O segundo passo é o cálculo das variáveis forward e backward.

Com esses valores pode-se ir para o próximo passo que é o cálculo do número esperado de visitas ao estado i e o número esperado de transições de i para j.

De posse dos novos parâmetros, a probabilidade do novo modelo dada a seqüência de observações é novamente calculada.

A probabilidade do novo modelo é comparada com a probabilidade do modelo antigo e se o ganho relativo for pequeno pode-se parar.

O algoritmo pode parar também pelo número de iterações, pois o tempo para atingir um ganho relativamente pequeno pode ser relativamente grande principalmente se este algoritmo estiver sendo usado em um aplicativo de tempo real.

As fórmulas de reestimação podem ser derivadas diretamente pela maximização da função auxiliar de Baum.

As fórmulas de reestimação podem ser interpretadas como uma implementação do algoritmo EM no qual o passo E (expectation) é o cálculo da função auxiliar, e o passo M (modification) é a maximização.

Portanto as equações de reestimação de Baum-Welch são essencialmente idênticas aos passos EM para este problema em particular.

Como foi mencionado acima, a escolha dos parâmetros influenciam no treinamento da cadeia.

Uma má escolha destes parâmetros pode levar o modelo ao um máximo local bem distante do máximo global.

Uma pergunta crucial é como escolher os parâmetros de modo que o máximo local é também o máximo global.

Indica que uma escolha aleatória dos parâmetros é adequada para a maioria dos casos, mas que o parâmetro B tem uma influência decisiva para modelos com alfabeto discreto.

Como os termos a e b são menores que 1, os termos tendem a zero exponencialmente conforme se aumenta o número de observações t.

Para valores grandes de t (100 ou mais), o cálculo começa a exceder a precisão numérica computacional.

Por isso é necessária a incorporação de um procedimento capaz de re-escalar os valores.

A solução mais usual é multiplicar por um fator de escala que é independente de i, e então só depende de t.

A vantagem desta solução é que ela mantém os termos dentro do limite numérico do computador.

Devido a semelhança de magnitude dos termos e, podemos aplicar o mesmo fator de escala para os dois termos.

Apesar de já existirem aplicativos, tanto comerciais quanto de uso público, que permitem o tratamento das equações acima foi desenvolvido um aplicativo capaz de treinar uma cadeia de Markov Oculta a partir de uma seqüência de observações usando a teoria apresentada neste capítulo.

Essa escolha foi feita para facilitar a inserção das rotinas nos aplicativos VivaVoz e Tangram-II.

O programa foi totalmente desenvolvido utilizando linguagem C e foi batizado de hmm.

As rotinas foram implementadas de modo a serem facilmente transportadas para outro aplicativo, em especial o VivaVoz.

O programa hmm utiliza o módulo de visualização de matriz desenvolvido para a ferramenta Tangram-II para mostrar tanto a matriz de transição quanto a matriz de emissão.

Além disso, o programa permite que o usuário salve o modelo atual usando o formato OBJ usado pelo programa tgif que é a base para a confecção de modelos na ferramenta Tangram-II.

A seguir é mostrada a tela com a lista dos comandos do programa hmm.

Apesar deste programa ter sido inicialmente desenvolvido para esta pesquisa e com o objetivo de ser incorporado na ferramenta VivaVoz, ele foi utilizado na área de medicina tendo como objetivo determinar a influência de determinados genes sobre fatores como hipertensão, obesidade, etc.

Os resultados deste experimento estão relatados.

Para atender as necessidades deste estudo, novos comandos foram desenvolvidos.

Neste capítulo será descrito em detalhes o algoritmo de previsão e recuperação de pacotes de áudio.

O algoritmo é baseado em Cadeias de Markov Ocultas, cuja teoria foi apresentada no Capítulo 4, e é composto por seis fases.

O objetivo do algoritmo é prever o processo de perda de pacotes de áudio baseado num passado recente.

Os testes realizados neste capítulo e no capítulo 6 utilizaram os arquivos de registro produzidos por um aplicativo gerador de tráfego configurado para gerar um tráfego de voz de duração de uma hora.

Os testes realizados para obter os arquivos de registro consistem na geração de tráfego entre duas máquinas utilizando a ferramenta Traffic Generator do Tangram-II.

O programa Traffic Generator é composto por dois módulos, um módulo emissor e um módulo receptor.

O módulo emissor pode ser configurado para enviar pacotes usando diversos modelos de taxa, como por exemplo, CBR, Markov Modulated ou de acordo com um arquivo de registro.

Além disso, o módulo emissor pode enviar pacotes para um único destino (UNICAST) ou para vários destinos ao mesmo tempo (MULTICAST).

O módulo receptor é executado na máquina destino e tem por tarefa fazer um registro em disco dos pacotes recebidos.

Este módulo armazena a hora de chegada, o tamanho e o número de seqüência de cada pacote recebido.

O arquivo com estes dados era compactado e transferido para um máquina na UFRJ no final do teste para posterior análise.

Para emular um aplicativo de voz, o módulo emissor foi configurado para enviar pacotes UDP a uma taxa constante (CBR) com intervalo entre os pacotes de 20 milissegundos.

O tamanho dos pacotes foi constante e igual 324 bytes e a duração de cada experimento era de uma hora.

O intervalo entre pacotes escolhido representa o valor usado pela maioria dos programas de comunicação por voz usando a internet.

O tamanho dos pacotes igual a 324 bytes representa o tamanho dos pacotes enviados pela ferramenta VivaVoz e além disso é um valor próximo do tamanho do pacote usado pela ferramenta FreePhone quando configurada para enviar 1 redundância por pacote.

Estes testes foram realizados entre 2001 e 2002.

Em 2001 entre a Universidade Federal do Rio de Janeiro (UFRJ) e a Universidade Federal de Minas Gerais (UFMG), entre a UFRJ e a University of Maryland (UMD) e entre a UFRJ e a University of Massachusetts Amherst (UMASS) em diferentes horários para que se pudesse observar o comportamento da perda de pacotes com a rede em diferentes estágios de congestionamento.

No total foram gerados 74 arquivos.

Destes 74 arquivos, 28 representam o tráfego iniciado na UFRJ e coletado na UMD, no período de 9 de agosto a 22 de agosto, 21 entre UFRJ e UFMG, no período de 9 de agosto a 17 de agosto, e 25 entre a UFRJ e a UMASS, no período de 8 de agosto a 16 de agosto.

Em 2002 estes testes foram repetidos entre a UFRJ e a UMASS e dentro da UFRJ totalizando 198 arquivos.

No período de 16 de janeiro de 2002 a 4 de fevereiro de 2002 foram coletados 71 arquivos com o tráfego originado na UFRJ e com destino UMASS, e 27 arquivos no sentido oposto.

No período de 19 de junho de 2002 a 5 de julho de 2002 foram coletados 97 arquivos de registro entre a UFRJ e a UMASS.

Arquivos representam o tráfego de uma máquina na UFRJ para outra máquina na UFRJ com o objetivo de verificar a influência dos roteadores internos no processo de perda de pacotes.

Do total de 272 arquivos de registro, 3 encontram-se corrompidos e foram, portanto, descartados.

Dos 269 arquivos, 196 (7287%) apresentaram um taxa de perda menor do que 1%, 67 (2491%) tiveram taxa de perda entre 1 e 10% e os outros 6 (223%) arquivos tiveram taxa de perda entre 10 e 1764%.

O número de pacotes que chegaram fora de ordem foi desprezível em todos os arquivos.

É importante ressaltar que o canal internacional entre Brasil e EUA foi alterado em agosto de 2001, elevando significativamente a taxa de transmissão a 45 Mbps.

É claro então que, devido à baixa utilização do canal na época da mudança, houve uma redução da taxa de descarte.

Entretanto a coleta inclui dados numa faixa razoável de taxa de perda e o algoritmo de recuperação a ser usado deve se adaptar a essas variações.

Para 107 dos 269 arquivos, foram traçados o gráfico da auto-correlação e em apenas 30 o gráfico não apresentava correlação entre as perdas, isto é, o processo de perdas poderia ser modelado por uma variável aleatória Bernoulli.

Arquivos mostraram um gráfico de auto-correlação.

Esse comportamento sugere a presença de um evento periódico que sobrecarrega algum enlace no caminho fim-a-fim, possivelmente devido a atualização da tabela de roteamento como foi observado.

Uma característica importante é a distribuição da rajada de perdas de pacotes, isto é, a distribuição do número de pacotes perdidos entre dois pacotes que chegaram com sucesso.

Esta métrica tem influência direta na qualidade do som e portanto na escolha do esquema de redundância.

Mostra o número médio de ocorrências de 6 faixas de tamanho das perdas.

Os resultados mostram que a maioria das médias tem tamanho entre 1 e 2.

Resultados similares foram observados em outros estudos.

Também mostra um número médio relativamente alto de arquivos com perdas maiores que 6.

Destes arquivos 8 tiveram o tamanho médio das perdas maiores que 100 pacotes.

Mostra o gráfico do número de perdas em cada segundo para um dos arquivos com esta característica.

Pode-se observar que o caminho entre o módulo emissor e o módulo receptor do Traffic Generator foi interrompido em algum ponto ocasionando uma parada de aproximadamente 5 minutos, gerando 15250 perdas consecutivas.

Arquivos com tamanho médio de perdas maiores que 6 também mostram gráfico.

Mostra algumas estatísticas sobre o tamanho médio do sucesso, que é o número médio de pacotes que chegaram com sucesso entre duas perdas, para um arquivo de registro.

Com o objetivo de modelar o processo de perda de pacotes com auto-correlação, uma série de testes foi realizada para se determinar a matriz de transição e a ordem desta matriz.

O primeiro teste consistiu em se usar uma matriz de transição com apenas dois estados e com valores aleatórios para as transições.

Após o treinamento com 100 iterações, a cadeia de Markov Oculta degenerou para uma cadeia de Markov Normal, onde um estado era responsável pela emissão do símbolo zero e o outro estado responsável pela emissão do símbolo 1.

Este modelo é conhecido como modelo de Gilbert.

Foram experimentadas cadeias com um número maior de estados mas, em todos os testes, nenhuma cadeia foi capaz de gerar uma seqüência de observações com um comportamento da auto-correlação.

Os próximos testes usaram como base o intervalo entre os picos de auto-correlação.

Pode-se verificar que o intervalo é de aproximadamente 30 segundos.

Criar uma cadeia onde cada estado representa uma perda e a cadeia represente um período da auto-correlação mostrou-se inviável, pois tal cadeia teria aproximadamente 1500 estados e o tempo de treinamento desta cadeia não seria factível para aplicações de tempo real.

Por isso foi necessária a agregação de amostras consecutivas em um único estado.

A idéia é que cada estado represente agora o número de perdas no intervalo de um segundo.

Como o tamanho dos pacotes de áudio da aplicação considerada era de 20 milisegundos, cada estado modela o processo de perda de 50 pacotes de áudio e, portanto, cada estado pode emitir 51 símbolos, indicando o número de perdas em um segundo.

Essas novas amostras serão chamadas de amostras agregadas.

Com essa nova representação do processo de perda de pacotes, perde-se informação sobre a distribuição das perdas dentro do segundo.

Não é possível determinar, por exemplo, o espaçamento dos pacotes perdidos dentro da perda.

Em trabalhos futuros pode-se explorar outros modelos, por exemplo, um símbolo poderia representar o número máximo de perdas consecutivas dentro do intervalo de um segundo.

É necessário escolher ainda a estrutura para a cadeia a ser usada.

Obviamente poder-se-ia escolher uma estrutura geral onde existem transições de cada estado para todos os outros estados.

Entretanto estruturas mais especializadas podem produzir melhores resultados dependendo do tipo de sinal a ser modelado.

No caso em questão, observou-se alguma periodicidade no processo de perda, ou em outras palavras, uma forte correlação em lags da ordem de segundos.

Caso existisse uma periodicidade de exatamente 30 segundos, obviamente uma cadeia periódica com 30 estados representaria com exatidão o processo de perda.

Esta observação motivou a estrutura escolhida, onde uma cadeia do tipo "Branch-Erlangian" (semelhante a phase-type) foi escolhida.

O primeiro teste com esse modelo utilizou uma cadeia com 30 estados, valor aproximado do período da auto-correlação.

Cada estado podia emitir qualquer um dos 51 símbolos com igual probabilidade.

Além disto, cada estado podia fazer uma transição para o próximo ou para o primeiro.

Este modelo falhou em representar o comportamento da auto-correlação observado mesmo para um número de iterações superior a 500.

O período da auto-correlação foi recomputado e verificado que o mesmo se encontrava mais próximo de 31 do que 30 segundos, por isso o próximo modelo tem a mesma estrutura que o anterior exceto pelo número de estado, que passou a ser 31 ao invés de 30.

Como o resultado desta última cadeia foi um gráfico muito semelhante.

Foram feitos outros testes semelhantes aos dois últimos aumentando-se apenas o número de estados.

Nestes testes a cadeia final, após o treinamento, não era ergódica e apenas os 31 primeiros estados eram atingíveis.

Uma vez escolhido o modelo HMM para o processo de perdas é necessário elaborar um algoritmo a ser usado na previsão das perdas na rede.

O algoritmo proposto encontra-se quase em sua totalidade implementado na ferramenta hmm mencionada na Seção 42.

A única exceção foi a calculo da quantidade de perdas a partir da distribuição gerada pelo programa hmm que foi implementado em awk por conveniência.

Este cálculo pode ser facilmente incorporado no programa hmm.

Para que o algoritmo possa inferir o estado da rede em um tempo futuro é necessário que o mesmo tenha um histórico recente da rede.

Este histórico é conhecido como seqüência de observações e é usado para o treinamento da cadeia de Markov Oculta.

O tamanho da seqüência de observações é de fundamental importância, pois se for muito pequeno o treinamento pode gerar uma cadeia que não reflita corretamente o estado da rede.

Por outro lado, se o tamanho da seqüência de observações for muito grande, pacotes que estão sendo usados no processo de treinamento já poderiam estar sendo usados para a previsão e recuperação.

Além disso, o tempo de processamento para esta seqüência inicial grande pode não ser factível para uma aplicação de tempo real.

O tamanho da seqüência inicial de observações foi obtido de forma experimental.

Nos primeiros testes, a seqüência inicial consistia dos primeiros 500 segundos de áudio.

Esse valor foi considerado muito grande para ser usado por um aplicativo interativo de transmissão de voz, pois é possível que o tempo de conexão seja menor do que este valor.

Uma seqüência de testes foi elaborada de modo a encontrar o valor mínimo para a seqüência inicial de observações.

Estes consistiam simplesmente em ir reduzindo o tamanho da seqüência inicial até que o treinamento levasse a uma cadeia que não reproduzisse o comportamento esperado da auto-correlação.

O valor mínimo encontrado foi próximo 150 amostras agregadas.

Foi arbitrado que o valor da seqüência seria de 3 minutos, ou seja, 180 amostras agregadas.

Uma vez obtida a cadeia inicial, esta cadeia deve ser atualizada durante a conexão de forma a se adaptar às mudanças do processo de perda com tempo.

O algoritmo é usado para cumprir este objetivo.

O número de iterações foi obtido experimentalmente.

O valor arbitrado foi 100, pois, para este valor, a probabilidade de se obter a seqüência dada a cadeia já havia convergido na maioria dos experimentos.

Além disso, esse número de iterações mostrou-se factível de ser computado por uma aplicação de tempo real mesmo em um computador modesto.

A cadeia de Markov obtida após a fase de treinamento é usada para prever as perdas que irão acontecer no período subseqüente.

A previsão é calculada em três etapas, a primeira etapa é responsável por calcular o estado mais provável de ter gerado o último símbolo observado, para este fim é usado o algoritmo de Viterbi visto na Seção 412.

O resultado dessa etapa é armazenado no vetor.

A segunda etapa calcula a probabilidade de se ter pelo menos x perdas no período de um segundo para cada um dos próximos 60 segundos.

É importante relembrar que um estado da cadeia oculta agrega informações de um período de um segundo.

Então, a probabilidade da cadeia emitir o símbolo i após t segundos, onde X(t) representa o número de perdas no t-ésimo segundo, o vetor de probabilidade de estados no início do período de previsão, encontrado pelo algoritmo de Viterbi, A é a matriz de transição da cadeia de Markov Oculta, B 0 é a matriz onde a linha j é o vetor de emissão do estado j e B 0 [i] é a [i + 1] ésima coluna desta matriz, obtidas na fase de treinamento do período anterior.

Ilustra graficamente um possível arquivo de saída desta etapa.

É possível observar que no décimo primeiro segundo haverá uma alta probabilidade de se perderem 3 pacotes.

Também é possível notar que a probabilidade de se observar mais que 3 perdas a cada período de um segundo durante os próximos 60 segundos é desprezível.

A terceira e última etapa calcula o número estimado de perdas que ocorrem a cada segundo com probabilidade P, onde P é uma dada tolerância.

Esse número é a soma dos elementos do vetor P (X(t)) até que esta soma alcance P, retornando o valor de i no final.

O valor escolhido para P nos experimentos foi 095.

Formalmente, seja uma variável aleatória que representa o número de perdas que ocorrem em um intervalo de tamanho.

Como cada estado no modelo de Markov oculto representa um intervalo de um segundo, uma escolha apropriada é 1 segundo.

Como resultado da análise transiente efetuada em cada intervalo de duração fi, obtém-se P, para n = 0, onde N = 50 nos testes realizados.

Foi usada a hipótese conservadora que, com probabilidade P, o tamanho da rajada no intervalo tem tamanho n.

Seja M j tal que P, onde é um dada tolerância.

Além disso, seja M, que é o valor máximo para M j considerando os intervalos vizinhos.

Para cada intervalo o algoritmo escolhe um esquema de redundância apropriado de acordo com os esquemas mencionados que corrigem rajadas de tamanho M k.

Claramente, se M k = 0 então não é preciso usar redundância para o intervalo considerado.

As duas primeiras etapas foram implementadas no programa hmm, enquanto que a terceira foi implementada utilizando a linguagem awk.

Para o processo de recuperação foi utilizada a biblioteca citada na seção 32.

Após termos a previsão da quantidade de perda de pacotes para os segundos seguintes, o próximo passo é a escolha do esquema de redundância apropriado para cada segundo subsequente como indicado acima.

Esta escolha foi feita utilizando informações colidas dos arquivos de registro.

A medida indica quantos pacotes serão perdidos no k-ésimo segundo.

Foi dado maior peso aos esquemas que recuperam perdas consecutivas.

A relação entre a quantidade de perdas prevista e o esquema de redundância, bem como o overhead introduzido pelo esquema.

Pode-se observar que o algoritmo apresentado utiliza o mesmo esquema de redundância para previsões de perdas maiores ou iguais a 6.

Isto foi necessário porque quanto maior for o tamanho da janela do esquema de redundância maior será o tempo necessário para se recuperar um pacote perdido.

Como o objetivo é aplicar em um programa de conversação iterativa, tornou-se obrigatório não permitir esquemas com uma janela muito grande, limitando a latência da transmissão.

O overhead indica a porcentagem extra de informações que é preciso enviar empregando um determinado esquema, em relação a informação original, supondo que a mesma técnica de codificação foi utilizada tanto para as amostras originais quanto para as redundâncias.

Após o processo de treinamento algumas transições da cadeia oculta podem estar iguais a zero.

Apesar deste fato não constituir um erro, ele pode levar a uma escolha indevida no próximo treinamento.

O processo de treinamento descrito na capítulo 4 pode fazer com que uma transição inicialmente positiva seja levada a zero, mas não pode fazer o contrário.

Uma transição que antes do processo de treinamento é igual a zero será igual a zero no final do treinamento.

Como a cadeia treinada representa o estado atual do canal de comunicação, estas transições que foram anuladas podem não ser nulas em um futuro próximo, por isso é preciso garantir que todas as transições não nulas da matriz de transição inicial possam assumir valores positivos durante todo o processo de treinamento.

Isto é feito em dois passos, primeiro é adicionada a matriz resultante do treinamento uma matriz com estrutura idêntica a matriz inicial.

Depois é necessário fazer a normalização para garantir que a matriz resultante do primeiro passo seja uma matriz estocástica.

Seja T (k) a matriz obtida após o treinamento da fase k e E uma matriz com uma estrutura correspondente ao diagrama de transição de estados, onde os elementos não nulos de E são todos iguais a, e é um valor a ser escolhido.

A normalização é então bem simples, todos os valores de uma linhas são divididos pela soma dos valores dessa linha.

Foram realizados alguns testes para determinar o menor valor para que a matriz voltasse a ter a estrutura original minimizando as alterações nas características da matriz atual.

O valor obtido para foi de 01.

Problema semelhante ocorre com o vetor de emissão.

O valor escolhido para um elemento do vetor E de emissão foi de 0001.

O último passo no processo de previsão e recuperação é realimentar o algoritmo com amostras mais recentes garantindo assim que a cadeia represente o processo de perda atual da rede.

O número de amostras escolhido para esse ítem do processo foi o equivalente a 60 segundos de conversa, ou seja, 3000 amostras.

Mostra a relação temporal de quatro das seis fases do processo de previsão e recuperação.

As fases de treinamento, inicialização e escolha de esquemas são aplicadas com informações do minuto passado, enquanto que a fase de coleta armazena o minuto presente.

A aplicação dos filtros é realizada na transição de um minuto para outro enquanto que a fase de recuperação é realizada dentro do minuto.

O algoritmo apresentado neste capítulo pode ser implementado tanto no módulo emissor quanto no módulo receptor de um aplicativo de tempo real.

Se o algoritmo for implementado no módulo emissor, o módulo receptor deverá enviar a quantidade de perdas observadas a cada segundo para os primeiros três minutos, relativo à fase de treinamento, e de um em um minuto ao longo da execução do aplicativo.

Como o número de perdas em um segundo pode variar de 0 até 50, é preciso de pelo menos 6 bits para cada segundo, totalizando 360 bits ou 45 bytes.

Por outro lado, se o algoritmo for implementado no módulo receptor, torna-se necessário o envio dos esquemas de redundância escolhidos para cada segundo deste módulo para o módulo emissor.

Na atual concepção do algoritmo, são necessários apenas 3 bits para cada segundo, já que existem apenas 6 esquemas de redundância, totalizando 180 bits ou 23 bytes.

Outro ponto a ser considerado é a sincronização entre os módulos para garantir que o módulo emissor usará o esquema correto no segundo apropriado.

Uma solução para este problema seria enviar junto com o vetor, que contém os esquemas a serem usados, o número de seqüência do primeiro pacote a ser protegido com o novo esquema, adicionando 32 bits à mensagem.

Como a questão da sincronização é indiferente, o fator determinante sobre a decisão de onde implementar o algoritmo proposto é a quantidade de bytes extras, necessários para o funcionamento do algoritmo, trocados entre o emissor e o receptor.

Por essa razão, o algoritmo proposto deveria ser implementado no receptor.

Este capítulo aborda os principais resultados obtidos com o algoritmo adaptativo proposto.

Para validar o algoritmo proposto, foram feitas comparações com o algoritmo introduzido, que é um algoritmo de recuperação de perdas de pacote estático, isto é, esse algoritmo sempre envia a redundância independente da taxa de perda, ou qualquer outra variável.

É proposta um alteração no algoritmo apresentado para deixá-lo dinâmico, podendo modelar o processo de perda de pacotes por um modelo de Gilbert ou por Bernoulli.

O algoritmo proposto aqui também foi comparado com essa versão dinâmica modelando o processo de perda de pacotes através de uma variável aleatória Bernoulli.

Neste capítulo, o algoritmo apresentado será chamado de algoritmo de referência estático, enquanto que a sua versão dinâmica, que está documentada, será chamada de algoritmo de referência dinâmico.

Para obter os resultados do algoritmo proposto, foram utilizados o programa hmm, a biblioteca de redundância e um conjunto de programas utilizando linguagem script awk e bash.

O programa hmm foi utilizado para a previsão das perdas juntamente com o script descrito na Seção 543.

A saída desses programas, bem como o arquivo de registro sendo analisado eram usados como entrada para o programa VV-simul, que utiliza a biblioteca de redundâncias descrita na Seção 32.

Este programa simula tanto a entidade emissora quanto a receptora de um programa de transmissão de áudio pela Internet.

A perda de pacotes é feita de acordo com o arquivo de registro que é passado como parâmetro.

Como saída é gerado um arquivo com os números de sequência dos pacotes recuperados.

Como o algoritmo de referência estático é simples, basta recuperar o último pacote de uma rajada de perda, foi implementado um programa utilizando a linguagem script awk para simulá-lo.

O algoritmo de referência dinâmico foi implementado em um programa utilizando linguagem C.

Assim como o programa VV-simul, este programa simula a emissão e a recepção de áudio pela Internet.

A saída gerada por esse programa é um arquivo onde cada linha contém 1 se o pacote foi perdido e não pode ser recuperado ou 0 caso contrário.

A partir deste arquivo são obtidas as informações sobre a qualidade de áudio resultante do uso deste algoritmo.

Além deste arquivo, o programa calcula o overhead e o número de pacotes recuperados.

Em posse destes programas, foram confeccionados outros programas utilizando a linguagem script bash para executar cada um desses programas para todos os arquivos de registro em análise e armazenar a saída em um único arquivo de dados.

É importante ressaltar que o foco principal deste trabalho é a perda de pacotes.

Por esta razão o atraso entre pacotes não foi considerado nos testes realizados.

Mostra, no mesmo gráfico, as perdas reais, em verde, e a previsão, em vermelho durante uma hora de experimento.

O tempo, em segundos, está representado no eixo das abscissas enquanto o eixo das ordenadas mostra a quantidade de perdas.

É possível observar que o algoritmo superestima a perda na maioria das previsões.

Isto acontece devido à alta tolerância (95%) escolhida na etapa de previsão.

Mostra um resumo da comparação do algoritmo proposto com o algoritmo de referência estático e que é usado na ferramenta FreePhone para diversos arquivos de registro coletados durante vários meses.

As colunas Origem, Data e Hora indicam respectivamente a máquina de origem, a data e a hora em que o arquivo de registro foi coletado.

A coluna "Pacotes Perdidos" mostra o número de pacotes que foram perdidos durante a coleta do arquivo.

A coluna "Fase Trein" indica o número de pacotes que foram perdidos nos primeiros 3 minutos do experimento.

Neste período o algoritmo proposto ainda está "aprendendo" o processo de perdas e por isso não pode prever as perdas.

Uma possível solução para recuperar pacotes durante a fase de treinamento seria aplicar o algoritmo de referência estático durante os 3 primeiros minutos.

A coluna "Recuperados Alg Ref Estático" mostra o número de pacotes que seriam recuperados se o arquivo estive protegido pelo algoritmo de referência estático.

Similarmente, a coluna "Recuperados Proposto" mostra o número de pacotes que seriam recuperados se o arquivo estivesse protegido pelo algoritmo proposto aqui.

As duas últimas colunas mostram o overhead dos dois esquemas de redundância, o de referência estático e o proposto respectivamente.

Mostra a comparação das taxas de perda real, após passar pelo algoritmo de referência estático e após passar pelo algoritmo proposto.

Também é mostrado o overhead do algoritmo proposto normalizado pelo algoritmo de referência estático na coluna "Overhead normalizado".

Mostram a quantidade de pacotes perdidos por segundo a cada segundo para um arquivo de registro escolhido.

Mostra o gráfico sem nenhum tratamento, enquanto mostram a quantidade de pacotes perdidos após a aplicação do algoritmo de referência estático, do algoritmo de referência dinâmico e do algoritmo proposto neste trabalho respectivamente.

É evidente que o algoritmo proposto é bem superior aos algoritmos de referência estático e dinâmico.

Em apenas 8 dos 269 arquivos, o algoritmo de referência dinâmico recupera mais pacotes que o algoritmo aqui apresentado.

Assim como na comparação com o algoritmo de referência estático, o número de pacotes recuperados durante os três primeiros minutos não foi contabilizado para nenhum dos dois algoritmos.

As três primeiras linhas desta tabela mostram ocorrências onde o algoritmo de referência dinâmico recuperou mais pacotes do que o algoritmo proposto.

O algoritmo de referência dinâmico utilizou um overhead menor nas duas primeiras linhas.

As demais linhas desta tabela mostram um desempenho superior do algoritmo proposto.

No caso da penúltima linha o algoritmo proposto recuperou mais pacotes utilizando um overhead menor.

Mostra o número de pacotes recuperados por tamanho da perda para um determinado arquivo de registro.

Cada entrada (x, y) mostra o número de vezes que y pacotes foram recuperados em uma rajada de erros de tamanho x y.

Por exemplo, a entrada indica que existiram 6 rajadas de tamanho 5 que tiveram 4 pacotes recuperados (portanto apenas um pacote permaneceu perdido).

Note que devido as características do algoritmo de referência estático, sempre é recuperado o último pacote de cada rajada de perdas.

Ainda com relação ao arquivo de registro analisado, foram recuperados 181=200 100% = 90,5% de todas as perdas de tamanho 3, e em 3,5% das perdas de tamanho 3 do arquivo de registro 2 pacotes foram recuperados.

Por outro lado o algoritmo de referência dinâmico recuperou 37,5% de todas as perdas de tamanho 3 e ainda 2 dos 3 pacotes perdidos em 14% das rajadas de tamanho 3.

Outros arquivos de registro mostram comportamento semelhante.

O principal objetivo deste trabalho foi o desenvolvimento de um novo algoritmo de previsão e recuperação de pacotes usando cadeias de Markov Oculta.

Este algoritmo foi comparado com um algoritmo de recuperação estático e com um dinâmico.

Os resultados destas comparações mostraram um excelente desempenho do algoritmo proposto tanto com relação ao algoritmo estático quanto ao dinâmico.

Ao longo desta pesquisa foi também elaborado um conjunto de experimentações e ferramentas.

Os ítens abaixo enumeram as contribuições.

Desenvolvimento e implementação de um novo algoritmo de previsão de perda de pacotes e análise de sua eficácia para aplicação de voz sobre IP.

Estudo do processo de perda de pacotes na Internet para aplicações de voz.

Elaboração de um modelo de perdas de pacotes usando cadeias de Markov Ocultas.

Implementação da teoria apresentada no Capítulo 4 no programa hmm.

É importante ressaltar que a implementação desse programa não se restringe a aplicações de transmissão de voz em tempo real.

O programa hmm pode ser usado separado e aplicado em outro tipo de pesquisa.

Apesar da teoria estar implementada em um programa, as rotinas podem ser facilmente copiadas para outras aplicações.

Implementação de uma biblioteca de rotinas para recuperação de perdas de pacotes baseada.

Esta biblioteca foi implementada levando em consideração as recomendações feitas para transmissão de redundâncias para aplicativos de tempo real.

Implementação do algoritmo dinâmico de recuperação de perda de pacotes apresentado usando Bernoulli como processo de perda de pacotes.

Vale a pena lembrar que o algoritmo estático é um caso particular do algoritmo apresentado e, por isso, pode ser usado através da biblioteca.

Elaboração do ambiente de testes.

Confecção de diversos programas e scripts para a análise de arquivos de registro coletados, filtragem de dados e apresentação dos resultados intermediários e finais.

O algoritmo dinâmico desenvolvido ainda não está incorporado ao aplicativo VivaVoz e, consequentemente, sua avaliação foi feita utilizando arquivos de registro pré-gravados.

Entretanto o algoritmo está pronto a ser incorporado ao VivaVoz e estará presente na sua nova versão.

Uma potencial utilização para o algoritmo de previsão seria como mecanismo de controle de congestionamento.

Como o algoritmo apresentado neste estudo indica a probabilidade de um ou mais pacotes serem descartados em um intervalo de tempo, esta medida pode ser relacionada com congestionamento na rede no período em questão.

Este comportamento contrasta com o algoritmo do TCP atual que reage posteriormente a detecção do descarte.

O aplicativo, usando este algoritmo, poderia, então, reduzir a sua taxa de transmissão.

Vale a pena lembrar que este uso não se limita a aplicativos de transmissão de mídia de tempo real, mas pode também ser usado em protocolos de transporte como o TCP.

Neste trabalho, utilizou-se o modelo onde cada estado pode emitir 51 símbolos, sendo o significado de cada símbolo o número esperado de perdas para um determinado segundo.

Uma modificação a ser explorada seria alterar o significado dos símbolos para indicar o tamanho da maior rajada de perdas no intervalo.

Outra mudança seria fazer com que cada estado representa-se meio segundo e treinar a cadeia de meio em meio minuto para ter um tempo de resposta mais rápido no caso de uma mudança no estado da rede.

Comparações de eficácia destas modificações podem ser feitas.

Outro ponto a ser explorado constitui na variação da tolerância.

Uma diminuição no valor desta tolerância pode levar a uma diminuição da quantidade de redundâncias enviadas sem, com isso, comprometer significativamente o número de pacotes recuperados.

As rotinas desenvolvidas no programa hmm podem ser incluídas na ferramenta Tangram-II aumentando o seu poder de análise permitindo o uso de cadeias de Markov ocultas.

