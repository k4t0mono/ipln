Os formalismos estruturados foram definidos ao longo dos anos com o objetivo de aumentar o nível de abstração e oferecer uma alternativa de modelagem mais sofisticada do que a proporcionada pelas tradicionais Cadeias de Markov.

Exemplos de formalismos estruturados que utilizam álgebra tensorial para o armazenamento de seus descritores são as Redes de Autômatos Estocásticos, as Redes de Petri Estocásticas Generalizadas Superpostas e as Álgebras de Processo.

Tais descrições utilizam primitivas de modelagem entre seus componentes capturando sua semântica operacional e permitindo a sua análise ao retornarem índices quantitativos de desempenho quando sujeitos à resolvidos numericamente.

Os mecanismos atuais de solução usam propriedades da Álgebra Tensorial (constante ou generalizada) para multiplicar termos tensoriais de eventos entre os estados dos modelos (um descritor markoviano) por um vetor de probabilidade, que contém a solução estacionária ou transiente.

Esta operação é chamada de Multiplicação Vetor-Descritor (MVD) e é realizada de três maneiras básicas, de forma esparsa (ineficiente em memória, eficiente em tempo), utilizando o Algoritmo Shuffle (eficiente em memória, ineficiente em tempo para algumas classes de modelos) ou através do Algoritmo Split, que é uma combinação das duas primeiras abordagens.

A principal contribuição deste último foi a proposição de um método híbrido onde incrementa-se a memória (de forma razoável) para acelerar o cálculo efetuado por iteração.

Entretanto, o principal desafio do Algoritmo Split é relativo à determinação de cortes de cada termo tensorial e em como re-estruturá-lo para reduzir o custo computacional por iteração, acelerando a convergência de modelos estruturados.

Este trabalho aborda estes problemas, baseando-se em três eixos, na discussão das primitivas de modelagem para composição de sistemas através de formas mais abstratas de descrição, nas diferentes formas de tratamento de termos tensoriais de descritores markovianos para execução mais otimizada da MVD a partir de re-estruturações das ordens originais, e na execução do Algoritmo Split com taxas constantes ou funcionais demonstrando os resultados obtidos para diversas classes de modelos.

Para os casos observados, foi demonstrado através de experimentos que o melhor ganho balanceando-se tempo e memória, é verificado quando as matrizes dos termos tensoriais são reordenadas, tratando as do tipo identidade na parte estruturada e avaliando-se os elementos funcionais uma única vez na parte esparsa.

Ao avaliar as funções somente uma vez em todo o processo de MVD, converte-se os descritores generalizados para constantes em tempo de execução e promove-se ganhos consideráveis em tempo para determinadas classes de modelos.

Observou-se também que as atividades de sincronização ou comunicação entre os módulos ou partições envolvidas bem como o total de parâmetros das dependências funcionais realizam um papel crucial no desempenho obtido.

A presente tese é finalizada identificando as classes de modelos mais adequadas para a utilização do Algoritmo Split e propondo formas de re-estruturação de descritores markovianos que privilegiem a esparsidade e a existência de matrizes do tipo identidade para balancear os custos em memória e tempo de execução.

O objetivo principal ao se mapear realidades em modelos consiste na verificação de medidas de desempenho que atestam a semântica operacional de sistemas sob análise.

O mapeamento é feito através de modelos, onde a precisão associada varia de acordo com o caso e o tempo investido na sua caracterização.

As etapas consideradas para um estudo computacional de desempenho são descritas.

Definição, através da utilização de abstrações, parametrização, refletindo as variáveis e frequências envolvidas e avaliação, resultando na extração de índices quantitativos de desempenho.

A parte de definição do sistema é realizada através da utilização de formalismos os quais descrevem o funcionamento do sistema com diferentes primitivas de modelagem.

Um exemplo de formalismo são as Cadeias de Markov (Markov Chain, ou MC) que trabalham com a descrição dos estados que um sistema assume e as suas transições.

As transições são responsáveis por conectar diferentes estados, informando as relações envolvidas e manifestando, através de eventos, taxas ou probabilidades associadas.

Estes valores de cada transição ditam a frequência de movimentação presente no conjunto dos estados.

Apesar da simplicidade deMCs para modelar realidades e consequentemente avaliar sistemas para extração de probabilidades de permanência em cada estado, mesmo sistemas com tamanho restrito possuem um conjunto de estados total muito elevado.

Este problema, conhecido por explosão do espaço de estados é recorrente neste formalismo de modelagem e motivou pesquisas para amenizá-lo, instigando a descrição de formalismos com maior grau de estruturação, maiores abstrações para composição dos estados de um sistema.

Exemplos de tais formalismos são as Redes de Autômatos Estocásticos (Stochastic Automata Networks, SAN), as Redes de Petri e as Álgebras de Processos.

Uma vez que um sistema é modelado utilizando-se de algum formalismo, a próxima etapa é determinar a existência ou não de suas características estacionárias, quando um equilíbrio foi atingido, ou transientes, quando interrompe-se o processo antes da convergência, de cada estado do modelo.

Este processo é realizado através do mapeamento das taxas de ocorrência contidas nas transições considerando escala de tempo contínua ou das probabilidades de ocorrência, no caso de escala de tempo discreta.

Esta matriz trata-se de um sistema linear de equações contendo um número de variáveis correspondente ao total do número de estados.

Para determinar estas variáveis, métodos diretos ou iterativos são utilizados, retornando as medidas de desempenho para análise.

A determinação da solução computacional de modelos endereça uma parte importante da análise de desempenho de realidades complexas, responsável pelo cálculo de índices que atestam de forma numérica e quantitativa o desempenho e a operação dos sistemas modelados.

Um exemplo de medidas que podem ser expressas através de modelagens matemáticas são (entre outros) problemas de alocação, disponibilidade e utilização de recursos.

Sistemas paralelos e distribuídos encontram-se igualmente sujeitos as aplicações de tais mecanismos, permitindo a detecção da incidência de gargalos, questões sobre validação de modelos e outras análises, visando otimizações.

Um dos principais eixos de pesquisa em Avaliação de Desempenho alinha-se à solução otimizada do sistema linear que descreve o modelo, observando a quantidade de memória exigida tanto para armazenar as matrizes necessárias quanto aos mecanismos que provêem soluções que determinam o regime estacionário ou transiente dos modelos.

As técnicas tradicionais de armazenamento e solução através do uso de abstrações tensoriais, tais como as presentes no formalismo de SAN, são consideradas um avanço significativo, pois a maneira de representação utilizada nunca armazena a matriz de transição completamente (como as MCs).

SAN utiliza uma abordagem criando representações tensoriais para os modelos, compostas por um conjunto finito (e restrito) de matrizes que compõem o denominado descritor markoviano ou Kronecker.

Este formalismo é, portanto, extremamente eficiente em termos de memória necessária pois apenas armazena pequenas matrizes esparsas.

A solução numérica de tais descritores markovianos é igualmente foco de novas pesquisas e os algoritmos especializados para efetuar tal processo são chamados de algoritmos para a Multiplicação Vetor-Descritor (MVD).

As operações complexas de multiplicação que devem ser efetuadas no nível do descritor markoviano podem ser otimizadas de diferentes maneiras.

Os descritores são formados de matrizes com elementos constantes ou funcionais, que são tipos mais complexos para o tratamento computacional apesar de serem simples primitivas de modelagem do formalismo citado.

Logo, dada a formação das matrizes que compõem o descritor, este pode ser classificado respectivamente como constante ou generalizado.

As formas deMVD tratam cada termo tensorial (i e cada evento) de forma independente e permitem a permutação das suas matrizes internas alterando a sua ordem original para promover ganhos em termos de tempo para efetuar cada iteração.

Entretanto, desconhecem-se os efeitos de se re-estruturar o descritor tensorial presente em definições abstratas baseadas em representação Kronecker.

O objetivo desta tese é propor uma forma otimizada de tratamento de descritores markovianos constantes ou generalizados no nível de composição dos seus termos tensoriais.

Serão analisados especificamente os algoritmos clássicos de MVD tais como o Algoritmo Esparso, Shuffle e o Split.

Um maior foco será direcionado para este último pois, apesar de propor uma divisão dos termos tensoriais para aplicar uma solução híbrida, não se conhece a melhor forma de realização das divisões assim como suas consequências quando aplicados a descritores generalizados.

O trabalho está direcionado para a descoberta das implicações das avaliações de taxas funcionais e a presença de matrizes do tipo identidade de cada termo tensorial para operar com menos operações de multiplicações em ponto-flutuante (relacionadas diretamente à complexidade envolvida para aMVD).

O objetivo destes estudos aliado ao fato de serem permitidos reordenamentos dos termos é flexibilizar ao máximo o Algoritmo Split para trabalhar com descritores markovianos com taxas funcionais, comparando com a abordagem atual do Algoritmo Shuffle.

Como será mostrado ao longo da tese, a adoção de uma estratégia para dividir os termos tensoriais impacta o tempo gasto para descoberta do regime estacionário ou transiente, antecipando a fase de análise e refinamento do modelo.

O Algoritmo Split é recente e inovou na maneira pela qual se realiza aMVD.

Essa nova abordagem possibilita balancear os custos em memória, armazenando e agregando uma parte do descritor.

No restante do termo tensorial é aplicada uma abordagem estruturada que não precisa guardar a matriz plena que corresponde ao gerador infinitesimal da MC.

O Algoritmo Shuffle é otimizado para tratar as dependências funcionais realizando ou não permutações na ordem lexicográfica1 das matrizes para otimizar as avaliações, entre outros mecanismos para ganho de desempenho pesquisados em outros trabalhos.

Observa-se a existência de um desconhecimento da melhor combinação das características dos descritores baseados em álgebra tensorial clássica e generalizada para acelerar cada passo do método iterativo utilizado, diminuindo o tempo total para atingir uma solução.

Este desafio incentiva a busca por um maior entendimento sobre o Algoritmo Split em si, o efeito das permutações na solução dos modelos e quando é mais vantajoso utilizá-las.

Enfim, são necessárias análises mais contundentes quanto à viabilidade computacional destes efeitos no processo de MVD, comparando com relação à memória a ser gasta e o tempo de execução, através de uma análise numérica.

O principal objetivo deste trabalho é propor um algoritmo de re-estruturação de termos tensoriais que, dadas as características de termos constantes ou generalizados de quaisquer sistemas representados através de descritores markovianos, forneça uma solução mais acelerada face os métodos de MVD existentes atualmente, não tornando a memória a ser gasta em um impedimento para a sua utilização.

Para a proposição deste algoritmo é necessário definir as características dos termos tensoriais que mais influenciam no Algoritmo Split, tais como as formas de permutação possíveis, o número de matrizes do tipo identidade e o total de parâmetros para a avaliação das funções presentes.

A partir destes conhecimentos será possível determinar as classes de modelos que melhor executam e promovem a adoção de abordagens MVD flexíveis, tais como as presentes no Algoritmo Split.

Uma vez que os objetivos propostos sejam concluídos, produzirão resultados importantes no contexto da solução numérica de sistemas baseados em representações tensoriais presentes em diversos formalismos estruturados de solução.

Será possível explicar porque o Algoritmo Split resolve determinados modelos mais rapidamente, quando comparado com outras abordagens.

Estas explicações serão responsáveis pela proposição de um algoritmo que, dado um termo tensorial, escolhe automaticamente a melhor divisão para tratar a parte esparsa e a parte estruturada.

Esse algoritmo observará as características dos termos tensoriais, ou seja, o número de identidades, o número de parâmetros para as avaliações das funções e a permutação das matrizes, observando a memória disponível.

Em um segundo momento, ao se conhecer a formação de um descritor markoviano e fornecer meios para realização eficiente de MVD, pode-se pensar em generalizar os modelos que podem ser utilizados através da definição de descritores Kronecker.

Por exemplo, pode-se definir um conjunto de regras de tradução para que diferentes formalismos estruturados que possuam uma representação tensorial sejam beneficiados com uma solução MVD otimizada.

Isso ampliará as maneiras de se analisar o desempenho de sistemas complexos uma vez que será possível modelá-lo utilizando-se todas as primitivas existentes em um determinado formalismo e resolvê-lo com métodos que encontram-se no estado-da-arte de MVD com representação tensorial, dado que uma conversão para este formato exista e seja válida.

Este formato descritivo fornecerá o conhecimento necessário para a proposta da implementação de uma ferramenta que resolva descritores Kronecker re-estruturando seus termos tensoriais para utilizar o Algoritmo Split, aceitando taxas constantes e funcionais.

Vale ressaltar que os modelos podem ter alta complexidade no que tange as suas transições pois os mecanismos aqui desenvolvidos funcionarão tanto para o uso de taxas constantes quanto funcionais.

Verifica-se que a existência de transições funcionais aumentam o número de modelagens existentes de realidades complexas e estes descritores generalizados são aqui tratados de igual forma em comparação com descritores constantes.

Isso possibilitará que tanto os modelos sejam resolvidos em menos tempo quanto que diferentes formas de representações poderão ser usadas para extração de índices de desempenho confiáveis de realidades diversas.

As re-estruturações aqui propostas servirão para estender as aplicações do Algoritmo Split para diferentes classes de modelos onde ele possa fornecer um desempenho superior em termos de custo computacional ao comparado com as abordagens atuais de MVD.

Finalmente, ao permitir que os modelos sejam resolvidos em menos tempo, consequentemente os índices de desempenho são obtidos de forma equivalente.

Desta forma, permite que o modelo sofra processos de refinamento ou de validação.

Esta contribuição é central para a solução de modelagens de abstrações sistemas pois permite que realidades com difícil compreensão sejam mapeadas e estudadas em um tempo razoável.

A tese está organizada da seguinte forma, o Capítulo 2 aborda diferentes formalismos presentes na literatura, seguido pelo Capítulo 3 que demonstra formas mais abstratas de percepção de sistemas.

As definições são usadas no Capítulo 4, que trata sobre as formas de MVD e a operação dos seus algoritmos principais.

Após abordar a MVD, demonstra as estratégias para divisão de termos tensoriais constantes e generalizados no Capítulo 5, considerando-se as implicações teóricas e as características mais importantes a serem observadas.

A seguir, explica as funcionalidades da ferramenta GTAexpress no Captítulo 6 para, no Capítulo 7 listar os resultados obtidos para os experimentos escolhidos.

A tese é finalizada pelo Capítulo 8 com um resumo das realizações efetuadas e as perspectivas futuras.

Uma das maneiras de se descrever realidades complexas é através da escolha de um formalismo.

Tratam-se de conjuntos de regras que capturampropriedades e características de sistemas e definem de forma não ambígua as entidades relacionadas e o funcionamento das suas interações.

Um importante exemplo é a descoberta de como os elementos de cada formalismo transitamde condição em condição, trocando ou não de estado, de acordo com uma taxa ou frequência com a qual acontece.

O objetivo deste mapeamento preciso é permitir que sejam extraídos índices computacionais de desempenho tais como a utilização dos recursos ou a capacidade média de um buffer1, por exemplo.

Este capítulo discutirá maneiras de definir modelos abstratos de sistemas através da aplicação direta de diferentes formalismos.

No contexto deste trabalho assume-se que o objetivo da descrição com formalismos é descobrir uma solução analítica para o sistema, ao invés de recorrer a outras práticas igualmente importantes porém menos precisas tais como simulação.

Um formalismo é composto por um conjunto de regras e uma gramática para descrever um sistema de maneira não ambígua.

Para o caso dos formalismos de descrição com vistas à análise de desempenho e soluções analíticas é comum verificar a existência de três entidades principais, estados, transições e eventos.

Os diversos formalismos definidos na literatura são distinguidos entre si de muitas maneiras, entretanto, todos são fundamentalmente baseados no formalismo das Cadeias de Markov.

Este capítulo inicia com considerações preliminares sobre modelagem de sistemas, seguida da definição de Cadeia de Markov, Redes de Petri e uma de suas variantes, as Redes de Petri Coloridas.

O capítulo também aborda as Redes de Autômatos Estocásticos, Álgebras de Processos e é finalizado com uma análise comparativa entre as vantagens e desvantagens do uso de cada formalismo.

Com o passar do tempo a descrição de sistemas complexos tornou-se de difícil análise pois foi verificado que os problemas modelados precisavam de definições mais precisas que as disponíveis até aquele momento.

A necessidade de métodos formais para avaliação de desempenho foi melhor investigada com o objetivo de prover raciocínios (reasoning) em sistemas e ajudar na descoberta de eventuais problemas.

O objetivo inicial da análise de sistemas foi o de adicionar determinismo e enumerar meios de descrever realidades complexas matematicamente, de forma não ambígua.

A idéia era aplicar os conceitos formais presentes e construirmodelos que representassem realidades com o maior número de detalhes possível.

A seguir, tentaria-se descobrir as propriedades da estacionariedade do sistema, ou seja, quando o equilíbrio fosse atingido.

Igualmente importante era conseguir realizar estas tarefas de maneira precisa e utilizando os recursos computacionais disponíveis da melhor forma possível, estudando os resultados alcançados.

As observações iniciais indicaram que simples modelos poderiam ser analiticamente resolvidos em uma quantidade finita e razoável de tempo e mesmo assim continuavam capturando as características primordiais do sistema, ou seja, verificou-se que simples modelos continuavam escaláveis.

Apesar desta ser à primeira vista uma maneira não-trivial de atacar o problema da modelagem de sistemas, foi um resultado importante pois provou que era suficientemente simples adicionar estados e transições em um dado modelo e este, mesmo assim, retornaria respostas consistentes.

Os resultados demonstrariam, por exemplo, se uma dada realidade estaria degradada e até mesmo quando começaria a desempenhar suas atividades de forma insatisfatória.

Estes números, quando devidamente interpretados, por exemplo, indicariam a necessidade de se comprar mais máquinas ou outros componentes físicos de sistemas antes do dispêndio de recursos financeiros.

Este fator provou que a análise de desempenho de sistemas constituía-se em uma importante maneira de evitar o desperdício de recursos tratando apenas da modelagem analítica, ou seja, antes do sistema físico estar operacional.

Sistemas para extração de relações de causa e efeito podem beneficiar-se das vantagens da modelagem estocástica.

Técnicas de análise baseadas em -força bruta- devem ser postas de lado e darem lugar a enfoques probabilísticos, baseados em abstrações da realidade (através da modelagem estocástica dos sistemas).

O mapeamento de diferentes realidades para modelos permite a determinação precisa das interconexões das entidades envolvidas, capturando suas principais nuances e respondendo questões críticas, analisadas a partir dos índices de desempenho calculados.

O objetivo é, dado um contexto de aplicação, abstrair a realidade em um modelo e calcular seus índices, extraindo informações dos grandes volumes de dados e apresentar as descobertas organizadamente.

Os passos para inspecionar sistemas devem envolver apenas as suas operações fundamentais, ou seja, captura-se a essência das tarefas realizadas pelo sistema e as trocas de estados existentes.

Quando apropriadamente definidos, estes passos aumentarão as chances de produzirem resultados válidos.

Antes de modelar uma realidade complexa é extremamente importante definir sua operação principal em um modelo o mais simples possível, definindo quais estados este possui e como transita de estado para estado.

A seguir, é realizada uma análise minuciosa descartando estados que não são importantes ou até mesmo desnecessários para a operação do sistema como umtodo.

Tratam-se de refinamentos ao modelo, onde o modelador verifica o sistema de acordo com a realidade que foi descrita e descobre se corresponde ao que o sistema realiza de fato.

Estas melhorias também são utilizadas para otimização do sistema uma vez que, ao alterarem-se os estados e as transições, pode-se potencialmente descobrir uma melhor configuração para sua operação ou onerando menos recursos.

Após verificar os cenários mapeáveis, estuda-se qual formalismo deverá ser usado oferecendo a melhor maneira de descrever a realidade, dado as suas características e as formas pelas quais evolui e interage.

A escolha de um formalismo que apresente o melhor conjunto de ferramentas computacionais para solução e verificação é igualmente importante, pois não basta um formalismo ser forte em termos de descrição mas ineficiente ao calcular os índices de desempenho.

O próximo estágio é buscar o equilíbrio do sistema onde este é analiticamente resolvido através de cálculos que inferem os índices de desempenho observados para o modelo em questão.

Para resolver um modelo, calcula-se o vetor de probabilidades correspondente à estacionariedade do sistema, supondo que o sistema foi simulado até um ponto onde suas mudanças não mais afetam o seu estado inicial.

Pode-se dizer que o sistema chegou em um momento onde, dadas as suas taxas iniciais, este não mais evolui, atingindo um equilíbrio.

Dessa forma, extraem-se os índices de desempenho comparando-os com diferentes formas demodelar o problema, adicionando ou excluindo componentes, sempre inspecionando as mudanças ocorridas nos índices.

No caso de degradação dos índices, recomenda-se alterar as transições e as taxas, bem como os estados e os eventos.

O objetivo é o de descobrir a melhor forma de composição do sistema para refletir a realidade estudada, propondo mudanças que impactarão diretamente em uma melhoria em termos de desempenho.

Uma dada realidade pode ser pensada como um conjunto de entidades dentro de um certo domínio que interage através de um conjunto de regras.

Estas entidades possuem estados e transitam entre estes com uma certa frequência com o disparo de eventos, que pode ser consideradas operações sobre um estado do sistema que resultam em um novo estado.

Após todos os aspectos considerados serem levados em conta, inicia-se a formalização propriamente dita através da definição não-ambígua de um modelo, compreendendo o processo que resultará no cálculo dos índices de desempenho.

É importante abstrair detalhes e capturar apenas aspectos relevantes do sistema sob consideração.

Estas abstrações serão determinantes para a obtenção de índices confiáveis durante a fase de solução.

Depois desta, os índices devem ser devidamente inspecionados e interpretados no estágio de análise, seguida por refinamentos do modelo, utilizando toda a retro-alimentação (feedback) obtida nos estágios anteriores.

Com estas informações, altera-se o modelo ou atesta-se que este constitui-se de uma modelagem válida, retornando resultados relevantes.

Vale lembrar que esse processo é iterativo, ou seja, apenas para quando o modelador está confiante que os resultados obtidos mapearam a realidade de forma satisfatória.

A análise dos modelos ajuda a prevenir inconsistências e comportamentos indesejados, tais como os que o sistema incorre inevitavelmente em um estado inválido ou de erro e não consegue sair ou permanece em loop.

Para prevenir este tipo de problema podem ser utilizadas mecanismos de verificação de modelos (Model Checking), técnicas para determinação precisa das sequências de passos (também chamados de caminhos) que um sistema segue com probabilidade p (nesse caso, esta seria apenas uma aplicação da área de verificação de sistemas, aqui explicada em um amplo sentido) e até mesmo quanto tempo ele permanece realizando alguma atividade.

Trata-se de uma área ativa de pesquisa dentro da comunidade de avaliação de desempenho e seus resultados são extremamente importantes para validar sistemas críticos complexos, verificando exaustivamente a execução do sistema através do modelo.

Lista, de forma ampla, os principais formalismos existentes na literatura.

Também mostra a data dos primeiros trabalhos onde foram aplicados para a extração de índices de desempenho bem como algumas extensões definidas com o passar do tempo.

Mostra um subconjunto das extensões oferecidas aos formalismos ao longo do tempo e como estes foram adaptados para inserir funcionalidades imprevistas anteriormente ou novos elementos visuais.

Uma Cadeia de Markov (MC ou Markov Chain) é um processo estocástico2 em tempo discreto ou contínuo com entidades bastante simples, estados e transições associadas a cada um destes.

O formalismo foi proposto com um interesse bastante particular, baseado em textos literários (o que demonstra a versatilidade do formalismo, podendo ser utilizado de diversas maneiras em diferentes domínios do conhecimento).

O objetivo desta aplicação de MC foi inferir a probabilidade de dado um texto e uma determinada posição desse mesmo texto, a próxima letra a ser analisada ser uma vogal dado que o caractere atual é uma consoante.

Trata-se de uma propriedade primordial de MCs, a chamada memoryless property.

Esta propriedade estabelece que toda a informação relevante está contida no estado atual, não interessando os estados por onde passou anteriormente.

Este formalismo é muito utilizado devido principalmente à sua simplicidade e também ao fato de possibilitar inferências de raciocínios e inspeções de desempenho para realidades variadas através de simples primitivas.

As MCs permaneceram desconhecidas até serem utilizadas no contexto de avaliação de desempenho de sistemas no MIT (Massachussets Institute of Technology).

A aplicação em questão foi direcionada a sistemas de compartilhamento de tempo (time sharing systems).

A principal observação realizada nesse trabalho foi a de que, mesmo o modelo sendo extremamente simples, conseguiu-se capturar a sua essência e providenciar respostas mesmo quando adaptado para refletir outros comportamentos.

Hoje em dia, MCs são utilizadas em inúmeros contextos, desde linguística até análise de riscos no mercado de ações.

Um dos exemplos da utilidade deste formalismo são os sistemas de indexação e procura da Internet, onde o conjunto de informações existentes é de amplas proporções e desorganizado.

A dificuldade é encontrar páginas com conteúdo que seja relevante para o que se esteja procurando.

O principal conceito aqui pode ser modelado como cada página na Internet ser um estado e a abstração é considerar uma entidade que apenas visita estas páginas (para efeitos de descrição, convenciona-se aqui chamá-la de -surfista-).

A visitação é realizada de forma aleatória onde, a partir de uma página inicial, deseja visitar as páginas que estão conectadas à essa (em terminologia da Internet, cada página possui diversos links, ou seja, diversas transições para outras páginas).

Ao resolver esse sistema de equações massivo onde as variáveis são as páginas, o resultado prático é a probabilidade que surfistas aleatórios tenham visitado as páginas e com qual relevância.

Ao descobrir e ordenar estas probabilidades de ocorrência em ordem decrescente (as com maiores probabilidades primeiro), são retornadas as páginas mais prováveis para o usuário.

Esse conceito é utilizado pelo sistema de buscas da empresa de computação Google (algoritmo aqui descrito de uma forma muito simples3) com resultados importantes.

No contexto deMC, é possível representar um sistema usando tempo contínuo (também chamadas de Cadeias de Markov em escala de tempo contínuo, Continuous Time Markov Chains, ou CTMC) ou tempo discreto (Cadeias de Markov em escala de tempo discreto, Discrete Time Markov Chains, ou DTMC).

Mostra um exemplo de Cadeia de Markov em escala de tempo contínuo com N = 9 estados e uma taxa para cada transição, dependendo do estado observado.

Todos os índices de desempenho são computados da distribuição estacionária ou transiente da Cadeia de Markov, resolvendo-se as equações de balanço global do sistema.

As principais distinções versam sobre a duração destas multiplicações em um determinado tempo t sobre o tempo total T.

São chamadas de probabilidades estacionárias quando atingiram o equilíbrio em T e transientes quando para-se o processo em t e analisam-se os índices de desempenho.

Estas variáveis de entrada são extraídas da matriz de transição P da MC, onde a probabilidade pij significa a probabilidade condicional para sair do estado i e ir para o estado j, onde i 6 = j.

Para o caso da solução estacionária do sistema, a equação pode ser escrita para DTMCs como pP = p, ou para o caso de CTMCs como p-Q = 0.

Esta operação irá converter a representação em tempo contínuo representado pelas taxas de transição da matriz -Q para uma representação baseada em tempo discreto com as probabilidades de transição da matriz P.

Neste sistema discreto, as transições acontecem em intervalos de tempo T.

Este parâmetro é normalmente escolhido para que a probabilidade existente entre duas transições seja negligenciável.

Logo, uma MC pode ser vista como um sistema de transição de estados onde o modelador define quais estados são acessíveis a partir de outros estados e configura uma taxa ou probabilidade para que um dado evento ocorra dentro de um sistema.

Existem diversos métodos para resolver o sistema, tais como métodos diretos (eliminação Gaussiana, decomposição LU), iterativos (Método da Potência, Jacobi ou Gauss-Seidel), de bloco (Gauss-Seidel de bloco) ou de projeção (como Generalized Minimal Residual Algorithm, GMRES), para citar alguns exemplos.

Métodos de solução direta desse sistema de equações tais como eliminação Gaussiana não são aplicáveis para modelos com número de estados elevado, pois requerem elevadas quantidades de memória.

Já técnicas iterativas de solução são melhores utilizadas, principalmente as que armazenam a matriz -Q de forma esparsa, mas mesmo assim ainda existem limites quanto aos modelos que podem ser resolvidos desta forma.

O resultado da multiplicação de uma matriz por um vetor p traduz a probabilidade de estar em um estado em um certo tempo, depois que o sistema está operacional.

Mostra como é gerada a matriz com as taxas de transição da MC do exemplo.

Para este caso, cada estado da cadeia leva a um ou mais estados de acordo com uma taxa.

Para transformar essa matriz em um Gerador Infinitesimal correspondente à matriz -Q é necessário que a soma de cada linha resulte em zero.

Para tanto, precisa-se corrigir a diagonal principal para refletir essa exigência.

Mostra esta correção, preparando a matriz para posterior multiplicação por um vetor de probabilidades.

Para esta CTMC, a próxima etapa é calcular-se p -Q = 0, onde p é um vetor de probabilidades inicial, resolvendo o sistema de equações lineares que é produzido e analisando os índices de desempenho obtidos.

Um critério de parada utilizado nos métodos iterativos é observar a diferença entre duas iterações e verificar que a sua variação, elemento a elemento, é menor que 1E-10 em relação a p.

Uma alternativa é utilizar métodos diretos, definindo o sistema linear de equações com nove variáveis.

Outro meio de solução é utilizar o Método da Potência.

Ao utilizar esta técnica, para os valores de taxas de transição escolhidos, são necessárias 118 iterações para obtenção da solução estacionária ou convergente, resultando em índices de desempenho quantitativos, ou seja, valores da probabilidade da permanência em cada estado para posterior análise.

Por exemplo, mostra que o estado AY tem 30,52% de probabilidade de permanência enquanto que o estado AZ tem 26,25%.

Caso os estados desta MC significassem, por exemplo, processadores e a métrica observada fosse processamento, os de -rótulo- AY e AZ estariam ocupados - 56% do tempo na operação desse sistema.

Também mostra, na coluna p, o índice do vetor de probabilidades para cada estado global do sistema (total de estados do sistema é N = 9).

Caso fosse necessário refinar as taxas utilizadas no modelo, alterando-as para os valores µ, ométodo iterativo converge com 186 passos e produziria resultadosmais equilibrados que os anteriores, que mostra que as maiores probabilidades estão concentradas nos estados AY,AZ,CY e CZ.

O presente trabalho não discutirá todos os detalhes pertencentes a Cadeias de Markov.

Para maiores informações, existemdiversos outros trabalhos na literatura sobreMCs.

Um dos problemas centrais de MC é a chamada explosão do espaço de estados.

Esse problema acontece quando precisa-se de um número elevado de estados para modelar um sistema.

Normalmente, não é possível resolvê-lo em um tempo razoável por falta de recursos computacionais tais como memória ou poder de processamento.

Apesar de amplamente utilizada, as MCs possuem problemas fundamentais, sendo o principal a explosão do espaço de estados tornando a solução do sistema impraticável via métodos diretos ou iterativos em um tempo razoável.

Este problema acompanha as MCs desde a sua definição inicial, onde verificou-se que mesmo simples descrições geravam muitos estados e isso implicava em problemas tanto na armazenagem da cadeia quanto nos mecanismos de solução envolvidos.

Para reduzir os efeitos problemáticos da explosão do espaço de estados foram consideradas outras formas de representação dos sistemas, mas permanecendo com a visão da modelagem das Cadeias de Markov como alternativa válida de modelagem.

A solução encontrada foi a definição de formalismos estruturados, usados para representar um sistema em um nível superior de abstração, mas possuindo uma Cadeia de Markov equivalente de forma implícita ou subjacente.

Este novo tipo de visão criou novas definições, tais como modelar partes do sistema como entidades ou componentes autônomos mas que eventualmente sincronizavam atividades.

Cada elemento teria associado diferentes estados, representando as características dos sistemas.

Ao efetuar o produto cartesiano do espaço de estados, ou seja, uma combinação de todos os estados passíveis de serem compostos, entre os componentes de um dado formalismo estruturado, por exemplo, autômatos em Redes de Autômatos Estocásticos ou processos em PEPA, produz-se, na verdade, uma Cadeia de Markov equivalente.

Este produto cartesiano também é chamado de Espaço de Estados Produto X (Product State Space, ou PSS) e dita a quantidade de estados existentes no sistema.

Cabe ressaltar que os formalismos estruturados reduzem significativamente o problema da explosão do espaço de estados, mas não o elimina completamente.

Os formalismos estruturados inclusive inserem uma outra problemática para ser pesquisada relativa à existência de estados inatingíveis, algo que na modelagem markoviana ficava mais evidente, bastando verificar a existência de estados sem saídas ou chegadas.

Normalmente, o Espaço de Estados Atingível XR (Reacheable State Space, ou RSS) é um subconjunto do PSS, entretanto, ainda permanece um problema em aberto a solução eficiente de modelos complexos onde todos, ou quase todos os estados são atingíveis.

Estes novos problemas podem ser mitigados utilizando-se estruturas de dados sofisticadas com manipulação simbólica, tais como Diagramas de Decisão Multi-valorados (Multivalued Decision Diagrams ou MDD) ou através do uso de vetores reduzidos.

Na prática, representações estruturadas da matriz -Q podem ser obtidas através de diferentes formalismos de modelagem, Redes de Petri Estocásticas Generalizadas Superpostas, Redes de Autômatos Estocásticos ou até mesmo descrições modulares e composicionais como PEPA ou Gramática de Grafos.

O princípio geral de utilizar tensores para representação implícita desta matriz existe desde os primórdios da definição das Redes de Autômatos Estocásticos, mas recentemente observou-se a aplicação com êxito nestes outros formalismos estocásticos.

As vantagens e desvantagens ao se adotar um formalismo variam de caso para caso e é necessário saber previamente as funcionalidades presentes em cada definição, maximizando-se, assim, as análises que são permitidas.

O objetivo do restante deste capítulo é explicar outras importantes descrições para modelagem de sistemas.

O próximo formalismo a ser descrito é o referente a Redes de Petri.

Redes de Petri, (PN ou Petri Net) são representações gráficas de modelagem para descrição de sistemas através do uso de anotações.

Estruturas comuns de Redes de Petri são nós que correspondem a lugares (place nodes), nós que correspondem a transições (transition nodes) e arcos dirigidos que representam conexões entre lugares e transições.

Dentro de cada lugar, existem marcas (tokens) e a distribuição de tais marcas dentro de uma rede é conhecida como uma marcação (marking).

A maior vantagem da adoção de uma PN está no fato de possibilitar uma visão clara de causalidade e conflito nas regiões que compõem a rede, devido à maneira utilizada para representar o sistema.

Uma extensão de PN são as chamadas Redes de Petri Estocásticas (SPN ou Stochastic Petri Net), definidas pela introdução de tempo de disparo não-determinístico entre transições.

Mostra um exemplo de uma simples PN.

A rede descrita contém quatro lugares e duas transições mostrando como as marcas podem se movimentar de um lugar ao outro dentro da rede.

Uma importante vantagem de uma PN é sua característica ao descrever como funciona o fluxo de informações na rede e como operam as estruturas de controle e restrição de movimentação dos tokens entre os lugares.

A rede possui uma estrutura e uma sistema de marcação.

A estrutura representa a parte estática do sistema.

Os dois tipos de nós são representados por componentes gráficos, círculos para os lugares e retângulos para as transições.

Os lugares correspondem aos estados do sistema e as transições a ações que forçam a mudança entre os estados.

Os arcos conectam lugares a transições e transições a lugares, sendo chamados, respectivamente, de arcos de entrada e arcos de saída.

Cabe ressaltar que, com o tempo, as SPNs foram extendidas para modelar apenas algumas transições de um sistema com tempo de disparo não-determinístico.

Essa extensão foi chamada de Redes de Petri Estocásticas Generalizadas (GSPN ou Generalized Stochastic Petri Net) e permite a modelagem de realidades que possuem atividades de durações variáveis e que trocam de estado muitas vezes de forma brusca.

O objetivo da utilização deste tipo de rede é reduzir a complexidade da MC equivalente e, consequentemente, reduzir a complexidade da solução dos modelos.

Uma GSPN permite duas classes diferentes de transições, imediatas e temporizadas.

Uma transição imediata é disparada imediatamente (em tempo zero) assim que estiver habilitada e uma transição temporizada é disparada após um tempo aleatório com uma distribuição exponencial associada.

A estrutura de uma GSPN segue a definição de uma SPN, porém o conjunto das taxas de disparo contém somente os elementos das transições temporizadas.

Entretanto, observou-se a necessidade de se compartimentalizar os modelos definidos com PN, onde existem interações entre esses componentes.

Para tanto, foram definidas as Redes de Petri Estocásticas Generalizadas Superpostas (SGSPN ou SuperposedGeneralized Stochastic Petri Net) que interagem através da superposição de transições.

A solução de modelos desta classe de redes pode ser eficientemente tratada pois deriva uma expressão tensorial para o seu gerador infinitesimal.

A modelagem em SGSPN é feita através do uso de módulos possuidores de transições locais e que interagem através de sincronizações.

As fórmulas tensoriais são bastante similares às obtidas através das Redes de Autômatos Estocásticos (o formalismo em si é explicado a seguir).

Um simples modelo descrito em SGSPN é mostrado.

Este modelo possui dois componentes chamados C(1) e C(2) (mostrado com uma separação -abstrata- conforme as diferentes linhas pontilhadas com os elementos à esquerda e à direita), com sete lugares e cinco transições sendo que os dois componentes estão sendo sincronizados pelo evento t3.

Esta rede possui duas marcas, uma em p1 e a outra em p6.

A marcação de uma Rede de Petri é a associação de marcas a lugares.

Para uma definição formal de uma PN é necessário especificar a estrutura da rede e a marcação inicial, onde as marcas serão inicialmente colocadas dentro da rede.

A dinâmica do sistema segue um conjunto básico de regras sendo que uma transição ocorre quando o lugar de entrada cumpre as condições expressas pelas inscrições dos arcos.

O objetivo deste trabalho não é especificar formalmente uma PN, apenas oferecer um apanhado geral sobre este tipo de formalismo.

Para maiores informações sobre PN e suas extensões, indica-se, que mostram o funcionamento e explicam PNs com um maior nível de detalhe.

PNs possuem extensões para capturar outros tipos de comportamento de sistemas.

Uma extensão bastante conhecida são as Redes de Petri Coloridas (CPN ou Coloured Petri Net).

A principal distinção entre uma Rede de Petri tradicional e uma Rede de Petri Colorida reside nas informações contidas nas marcas.

Em PNs elas são indistinguíveis (possuem uma mesma cor), enquanto que em CPNs, cada marca pode possuir uma característica distinta associada tal como, por exemplo, uma cor.

Uma CPN é uma linguagem de modelagem usada em realidades onde sincronizações e comunicações são necessárias, combinando as vantagens de Redes de Petri com conceitos de linguagens de programação de alto nível.

CPNs utilizam as ideias que descrevem como as entidades cooperam e proveem mecanismos para manipulação de estruturas de dados e associação a variáveis que são conceitos oriundos de linguagens de programação.

Tais redes, como PN tradicionais, possuem lugares, transições e arcos.

Adicionalmente, possuem um outro componente chamado páginas, que podem potencialmente conter lugares.

O conjunto destes elementos formam uma rede que, quando usados em conjunto e mostrados graficamente, permitem a manipulação de estruturas complexas fornecendo auxílios visuais para reconhecer como as entidades estão conectadas entre si e como interagem.

CPNs podem ser usadas para verificação formal, pois oferecem um conjunto de ferramentas desenvolvidas para este propósito específico.

Existem dois tipos de métodos de verificação existentes para CPN, análise do espaço de estados e análise de invariantes.

O objetivo da verificação formal é provar matematicamente que um sistema possui um conjunto de propriedades comportamentais.

À medida que sistemas atingem uma escala industrial, também torna difícil sua análise.

CPNs podem ser usadas para estes propósitos, aliado a outros mecanismos de validação utilizando-se simulação.

Cabe ressaltar que a verificação formal de sistemas é normalmente direcionada a partes críticas dos sistemas, logo, é crucial fornecer uma interface razoável entre um dado sistema e seu modelo correspondente.

Dentre as vantagens de se adotar CPNs para modelar sistemas, destacam-se simples primitivas para estabelecer e realizar inferências sobre a interação de componentes dentro de um sistema, modelagem de sub-componentes (também conhecida por modelagem hierárquica), descrição gráfica de sistemas e ferramentas para solução do sistema em questão (através de um software chamado CPN Tools).

Para outras informações sobre CPNs, sugere-se os seguintes trabalhos e mais recentemente.

Redes de Autômatos Estocásticos (SAN ou Stochastic Automata Networks) é um formalismo amplamente utilizado para o cálculo de índices de desempenho na área da avaliação quantitativa de sistemas.

Este formalismo baseia-se em entidades semi-autônomas chamadas autômatos e como estes componentes se relacionam para sincronizar atividades e trocar de estados internamente.

O conjunto destes autômatos forma uma rede, permitindo que sejam analisadas realidades complexas e foi construído para visar o correto mapeamento de atividades de paralelismo e distribuição.

Em SAN, descrevem-se os sistemas de maneira estruturada, observando a MC equivalente e resolvendo este sistema implicitamente.

Essa estruturação implica no armazenamento eficiente das estruturas de dados, permitindo que sistemas massivos sejam representados e tenham seus índices de desempenho devidamente interpretados e analisados.

Mais especificamente, SAN é um formalismo estruturado que descreve interações entre entidades conhecidas como autômatos.

Cada autômato desempenha transições específicas na sua estrutura interna, pode alterar seu comportamento local através de eventos locais e interagir com outros autômatos através de eventos sincronizantes.

Um evento sincronizante deve envolver no mínimo dois autômatos e representa que uma mudança de estado acontecendo concomitantemente em dois ou mais autômatos.

Um evento é disparado de acordo com a definição de uma taxa de ocorrência ou taxa de transição.

Essa taxa de ocorrência de um determinado evento pode ser de dois tipos, constante ou funcional.

Uma taxa constante é uma frequência média com a qual a transição ocorre.

Uma taxa funcional tem seu valor médio determinado segundo o estado de um ou mais autômatos, de acordo com fórmulas de consulta a estados de outros autômatos pré-estabelecidas pelos usuários quando modelam o sistema.

Mostra um exemplo de uma SAN simples com eventos locais (loc) e sincronizantes (syn), contendo taxas constantes e funcionais.

Mostra uma rede composta por dois autômatos, cooperando sobre um PSS de tamanho |X| = 3 × 3 = 9.

O exemplo possui cinco eventos locais (chamados de l0, l1, l2, l3, l4) e dois eventos sincronizantes (s0, s1).

Uma das taxas é funcional sendo as demais constantes.

A taxa funcional será avaliada para r6 quando o estado do autômato A(1) for igual a A ou igual a C e avaliada para zero (não ocorrendo), caso contrário (nesse caso, igual a B).

Um modelo SAN é transformado para um descritor markoviano (uma representação tensorial para o gerador infinitesimal -Q, também chamado de descritor Kronecker), um conjunto de matrizes responsáveis por definir a ocorrência dos eventos locais e sincronizantes de forma tensorial (explica melhor os princípios referentes aos descritores).

Após a definição do descritor, é utilizado ummétodo para multiplicá-lo por um vetor de probabilidade, ou seja, efetuar a Multiplicação Vetor-Descritor (MVD).

Cabe ressaltar, no entanto, que o uso de descritores tensoriais por SAN nem sempre gera a solução mais otimizada em termos de tempo gasto.

Apesar de reduzir a memória necessária para resolver modelos, dependendo da realidade descrita com SAN, pode-se, algumas vezes, aumentar-se também o tempo necessário para a convergência de resultados válidos, em virtude do formato tensorial.

Apesar das suas diferenças algorítmicas, o processo de multiplicar um vetor por um descritor pode ser resumido em encontrar uma forma eficiente de multiplicar uma estrutura usualmente grande (o vetor) por outra reduzida, mas com estruturação complexa (o descritor markoviano).

Algumas soluções para SPN traduziam a representação dos modelos em uma única matriz esparsa.

Naturalmente, esta proposta esparsa é difícil de ser utilizada para modelos com muitos estados (mais de 500 mil estados), pois normalmente necessita salvar esta matriz contendo muitas vezes muitos elementos não-nulos (mais de 4 milhões).

Isto é possível apenas com soluções sofisticadas para armazenar a matriz usando práticas baseadas em disco (disk-based approaches), ou técnicas de geração on-the-fly aliadas à computação paralela e distribuída.

Mais genericamente, estas matrizes são tratadas através da ferramenta PEPS (Performance Evaluation of Parallel Systems).

Novos desenvolvimentos estão direcionados a três eixos de pesquisa, utilização de representação simbólica do RSS (usando-se estruturas mais complexas como MDD), aceleração da MVD com o Algoritmo Split e técnicas de Simulação Perfeita.

Maiores informações sobre métodos de solução de MVD encontram-se no Capítulo 4.

Recentemente constatou-se um crescente aumento na adoção de Álgebras de Processo Markovianas (MPA ou Markovian Process Algebras) voltadas para a construção de modelos que representem sistemas complexos.

Exemplos incluem Performance Evaluation Process Algebra (PEPA) e Extended Markovian Process Algebra (EMPA), ou seja, formalismos desenvolvidos para capturar o comportamento de sistemas e permitir análise funcional através da solução da CTMC associada.

Uma das principais atrações para o uso de álgebras de processo é a habilidade de se construir um modelo composicional baseado em uma definição em alto-nível.

Tais álgebras permitem que sejam usadas em diversas aplicações, onde são facilmente modeladas através de simples primitivas que mostram como o sistema evolui de acordo com seu comportamento interno e de acordo com as interações existentes entre os componentes modelados.

Como em todas as álgebras de processo, sistemas são representados em PEPA como a composição de componentes que realizam ações.

Em PEPA, as ações ocorrem conforme uma duração, logo, a expressão (a, r).

P denota um componente o qual realizou uma ação a com taxa r e evoluiu para um componente P.

Aqui a A onde A é o conjunto de tipos de ações e P C onde C é o conjunto de tipos de componentes.

PEPA possui um conjunto restrito de combinadores, e as descrições dos sistemas são construídas a partir da execução concorrente e interação simples de componentes sequenciais.

A sintaxe destes combinadores está informalmente definida abaixo.

Prefix, o combinador prefix marca uma parada completa, dando ao componente a sua primeira ação designada.

Como explicado anteriormente, (a, r).

P executa uma ação a com taxa r, e subsequentemente começa a se comportar como P.

Choice, o componente P + Q representa um sistema que pode se comportar tanto como P ou como Q.

As atividades de ambos P e Q estão autorizadas (enabled).

A primeira atividade a acabar distingue-se (ou seja, é autorizada), a outra é descartada.

Constant, é conveniente associar nomes a padrões comportamentais de componentes e constantes realizam essa tarefa definindo uma equação, X def= E.

O nome X está no escopo da expressão do lado direito, significando que, por exemplo, X def= (a, r).

X desempenha a com taxa r para sempre.

Hiding, a possibilidade de abstrair alguns aspectos do comportamento de componentes é realizado pelo operador hiding, denotado por P/L.

O conjunto L identifica aquelas atividades as quais são consideradas internas ou privadas ao componente e quais irão aparecer como o tipo desconhecido t.

Cooperation, escreve-se P para descrever cooperação entre P e Q sobre L.

O conjunto L é o conjunto de cooperação e determina as atividades com as quais os componentes devem sincronizar atividades.

Para tipos de ação fora de L, os componentes procedem independentemente e concorrentemente com suas atividades autorizadas.

Escreve-se também P k Q como uma abreviação para P quando o conjunto L está vazio.

Para atividades do conjunto de cooperação, estas podem apenas realizar a atividade quando ambas estiverem autorizadas.

Os dois componentes então procedem juntos para completar esta atividade compartilhada.

A taxa da atividade compartilhada pode ser alterada para refletir o trabalho realizado por ambos os componentes com a finalidade de acabar a atividade.

A capacidade total do componente C para realizar tarefas do tipo a é definida pela taxa aparente de a em P, denotada por r(P).

PEPA assume bounded capacity, ou seja, a taxa de uma atividade compartilhada é igual ao valor mínimo entre as taxas das atividades dos componentes que estão cooperando.

Em alguns casos a taxa de alguma atividade é deixada sem especificação e é determinada quando existe cooperação, pela taxa da atividade do outro componente.

Estas ações passivas devem ser sincronizadas no modelo final (forçando a ocorrência de uma taxa para a cooperação).

A sintaxe de PEPA pode ser formalmente introduzida a partir da gramática, onde S denota um componente sequencial e P denota um componente de modelo o qual é executado em paralelo.

C é uma constante que denota tanto um componente sequencial quando um componente de modelo.

CS são constantes que denotam componentes sequenciais.

O efeito desta separação sintática entre estes tipos de constantes é para restringir componentes PEPA para serem cooperações de processos sequenciais, uma condição necessária para existir processos Markovianos bem definidos5.

O significado de uma expressão PEPA é dado pela semântica operacional estrutural que define como um modelo evolui, podendo ser aplicado exaustivamente para formar um sistema de rótulos denominado Grafo de Derivação (GD) representando em última análise o produto do espaço de estados do modelo.

Trata-se de um grafo o qual cada nodo é uma forma sintática distinta, definida como derivativo (derivative) e cada arco representa uma atividade possível causando uma mudança de estado.

O estado muda em conjunção com a Matriz de Transição (MT), que guarda o nome do evento e a sua taxa de ocorrência para cada dois estados.

É importante notar que em PEPA a representação de estados é de fato um sistema de rótulos com multi-transições pois guarda a multiplicidade de arcos, particularmente quando componentes repetidos estão envolvidos.

O GD pode ser considerado como um diagrama de transição de estados de uma CTMC.

Então, denota a taxa de transição entre o derivativo P e o derivativo Q.

Análises de desempenho são feitas em termos da procura da distribuição estacionária de probabilidades.

O GD também deve ser fortemente conectado para gerar uma CTMC válida e solúvel.

A seguir, um simples exemplo de um único componente com três derivativos, P1, P2 e P3, cada um com uma ação distinta com a mesma taxa de ocorrência r.

Apesar do fato das álgebras de processos possuírem as vantagens expressas acima, não fornece um atrativo visual de modelagem, como verificado em outros formalismos como Redes de Petri Coloridas ou SAN, por exemplo.

Esse fato motivou a definição do formalismo das PEPA nets, discutido a seguir.

Com o objetivo de se criar um formalismo com mais recursos e comrepresentações gráficas, foram definidas as PEPA nets em 2001.

PEPA nets é uma combinação sinergética entre Redes de Petri Coloridas e PEPA.

Os modelos são construídos como redes possuindo lugares que contém tanto componentes PEPA estáticos quanto móveis (melhores explicados a seguir).

Esse novo formalismo combina a composicionalidade de PEPA com a notação gráfica das Redes de Petri.

PEPA nets oferecem mais expressividade para os modeladores, mas deve ser vista como complementar à PEPA pois alguns comportamentos são melhores definidos em um formalismo ou em outro.

PEPA nets foi desenhada para capturar sistemas que possuam dois tipos distintos de mudança de estados, em particular sistemas computacionais onde verifica-se a existência de mobilidade (sejam componentes que alteram sua posição em um plano ou entidades que deslocam-se de maneiras diferentes).

Em tais sistemas, é importante separar a progressão lógica da computação envolvida com a mobilidade de eventos que reconfiguram o sistema.

Esse tipo de modelagem é a principal motivação para definição de PEPA nets.

Para atingir esse objetivo foi descrita uma combinação de formalismos com componentes PEPA representando as transições locais e os disparos das Redes de Petri capturando as reconfigurações globais do sistema (a mobilidade).

PEPA nets são Redes de Petri Coloridas onde as cores das marcas são componentes PEPA.

Cada lugar da PN é um contexto de PEPA o qual pode conter componentes estáticos e conjuntos de cooperação restringindo a movimentação das marcas dentro dos lugares.

As marcas podem se mover para um determinado lugar apenas se existe espaço para um componente do seu próprio tipo.

Como PEPA nets baseiam-se em componentes PEPA, é demonstrado que um mapeamento existe para o caso de uma modelagem de um desempenho de ferramentas de engenharia de sofware.

Existem dois tipos de mudança de estados em uma PEPA net, que podem ser vistas como mudanças microscópicas ou macroscópicas.

As mudanças microscópicas são locais, afetando componentes dentro dos seus contextos e são representadas usando-se transições governadas pela semântica usual de PEPA.

Em contraste, as mudanças macroscópicas são globais e capturam o disparo de eventos no nível da rede.

Estes disparos causam que as marcas sejam transferidas de um lugar para outro.

Cada lugar, ou contexto de PEPA, contém células especificamente definidas, que só podem ser ocupadas pelo tipo apropriado.

Esta definição é fortemente tipada, ou seja, uma célula não pode ter uma marca que não seja a marca definida para esta célula.

Uma PEPA net distingue dois tipos de componentes, marcas e componentes estáticos.

As marcas podem se movimentar entre os lugares (assim como ocorre em Redes de Petri), enquanto que os componentes estáticos não permitem movimentação na rede com alterações globais de estado, representando o ambiente dentro daquele lugar.

Estes componentes estáticos podem ser de dois tipos, stateless ou stateful.

Um componente stateless não possui derivações e simplesmente oferece uma ou mais ações para interação.

Os componentes stateful em contraste, possuem um conjunto mais rico de comportamentos incluindo a possibilidade de definir derivativos ou estados.

Um exemplo simples de PEPA net seria uma entidade, denominada neste contexto de agente, que visita diferentes lugares de uma rede.

Mostra uma visualização gráfica deste sistema.

Existem três lugares na rede chamados P1, P2 e P3 e agentes pode se movimentar entre estes lugares de acordo com uma taxa.

As transições locais acontecem dentro de cada lugar e os movimentos nas transições da rede causam mudanças globais ao sistema, representadas pelos eventos go e return.

A marcação inicial da rede é um agente em P2.

As definições formais da rede e o que representam os agentes dentro desse exemplo não fazem parte do escopo deste trabalho.

PEPA nets podem ser naturalmente usadas no caso de existirem componentes que precisam se movimentar em uma rede ou alterar sua posição entre lugares, comunicar com outros eventuais componentes que existamno lugar e retornar para seu lugar de origem.

Este tipo de comportamento é mais facilmente perceptível devido à maneira gráfica que as PEPA nets utilizam para mostrar as interações envolvidas entre as diferentes entidades de um sistema e como estas cooperam para realizar atividades.

Um outro exemplo válido são processos em uma rede de computadores, ou grid, que podem ser enviados para outros lugares de execução onde alteram seus estados locais, mas também ocorre uma movimentação global na rede.

Existem muitas situações onde PEPA nets modelam realidades complexas e inferem resultados analíticos representativos.

Como todo formalismo estruturado, uma PEPA net possui uma Cadeia de Markov equivalente, composta basicamente pela combinação das informações contidas na Matriz de Transição e no Grafo de Derivação, assim como em PEPA.

Tanto modelos PEPA quanto modelos PEPA nets são analisados através da ferramenta computacional PEPA Workbench (pwb).

Este ambiente completo de análise oferece ferramentas para lidar com a compilação de modelos que geram tanto o GD quanto a MT incluindo opções de agregação de estados (reduzindo o seu espaço de estados).

Este ambiente também gera arquivos para entrada em outras ferramentas de uso matemático, como Maple ou Mathematica com vistas à solução dos modelos criados.

PEPA nets já foi utilizada para modelar mobilidade, modelagem de conceitos de Engenharia de Software, Role-Playing Games e um ambiente para aplicações móveis usando UML, Unified Modeling Language, apenas para citar algumas aplicações.

A variedade de tipos para modelagem evidenciam a versatilidade do formalismo e como este pode ser adaptado para descrever sistemas complexos.

A seguir é apresentada uma breve discussão entre os formalismos expostos neste trabalho e uma comparação sobre as vantagens e desvantagens dos seu usos.

As Cadeias de Markov foram o primeiro formalismo diretamente aplicado à avaliação de desempenho de sistemas computacionais.

Seus conceitos podem ser aplicados a outras áreas tais como economia ou onde exista a necessidade de se descobrir probabilidades associadas a estados da realidade.

Desde a sua adoção, o problema da explosão do espaço de estados emergiu como um grave impedimento ao seu uso, fato mitigado pelas definições dos formalismos estruturados para análise de sistemas complexos.

As MCs demonstram uma utilidade e aplicabilidade irrestritas, devido principalmente à facilidade do seu uso, mas causam a explosão rápida do espaço de estados, a ponto de não ser possível mais tratá-la.

Os formalismos estruturados também possuem o mesmo problema, mas são mais escaláveis e lidam com alternativas viáveis quanto ao armazenamento das estruturas com o objetivo de produzir resultados válidos e consistentes em um tempo razoável.

Todos os formalismos possuem em comum comportamentos locais que importam a apenas algumas entidades e sincronizantes onde existe a necessidade de se trabalhar cooperativamente.

Estes tipos de interação são facilmente adaptáveis para os problemas existentes em computação no que diz respeito à modelagem de comportamentos concorrentes em sistemas distribuídos, entre outros exemplos.

A escolha de um formalismo para avaliar um sistema implica em decidir as vantagens e desvantagens existentes entre composicionalidade, localidade, sincronismo, evolução, interação, abstração e percepção (por exemplo, sistemas com representações gráficas).

Pesquisas atuais centram seus esforços nas descoberta do aumento do poder de representação dos sistemas para lidar apropriadamente com a abstração oferecida pelos diferentes formalismos estruturados.

Outro importante tópico é melhorar ainda mais os mecanismos de análise e simulação que são oferecidos aos usuários, bem como inferências estatísticas que são geradas nos modelos.

Estas análises permitem que sejam descobertos os fatores mais importantes que melhoram ou degradam o desempenho de sistemas, permitindo que os modeladores decidam as melhores condições para a sua operação otimizada bem como o uso racional dos recursos.

Mais especificamente, ao comparar dois formalismos bastante utilizados como SAN e PEPA nets, constata-se que estes compartilham similaridades, por exemplo, ambos lidam com representações gráficas de sistemas.

O mesmo acontece para o caso das Redes de Petri e Redes de Petri Coloridas.

Esses recursos visuais auxiliam e simplificam a análise e inspeção de modelos.

Uma clara vantagem de PEPA e PEPA nets sobre SAN diz respeito ao produto do espaço de estados (a combinação de todos os estados).

Em SAN, pode-se ter que trabalhar com um espaço de estados atingível muito menor que o espaço produto necessário para a solução do modelo.

Em PEPA, apenas os estados atingíveis são considerados.

Entretanto, em termos de solução, SAN por trabalhar com descritores markovianos, emprega melhor os recursos, principalmente os de memória, para calcular o vetor de probabilidades.

Em PEPA, precisa-se incorporar a Matriz de Transição com as taxas dos eventos em uma ferramenta computacional com recursos matemáticos, como por exemplo, o Maple ou Mathematica.

Dadas as inúmeras opções existentes de formalismos markovianos, pode-se constatar que na verdade existe um excesso de diferentes formas de modelar sistemas.

Entretanto, cada formalismo captura diferentes aspectos de um sistema incorporando variadas formas de análise.

Alguns formalismos oferecem opções sofisticadas para representar a interação entre os diversos componentes e comportamentos enquanto que outros se preocupam com a abstração das realidades.

Os pesquisadores comumente adaptam ideias de diferentes formalismos em suas próprias definições e visões, com o intuito de aumentar o poder de representação e solução.

Muitas vezes, são oferecidas maneiras de traduzir modelos escritos de um dado formalismo para outro.

Tratam-se de regras que mapeiam cada tipo de ocorrência e como esta deve ser vista no sistema como um todo.

O próximo capítulo trata sobre abstrações de modelagem que podem ser usadas para decompor sistemas e sobre equivalência entre formalismos estruturados de solução.

Os formalismos estruturados existentes para mapeamento de realidades definem seus próprios conjuntos de primitivas de modelagem.

A principal característica que os distingue entre si é o grau de abstração disponível e o funcionamento do seu mapeamento em alto nível para uma descrição mais formal e não ambígua.

Antes de prosseguir com a discussão de modelos mais abstratos para tratar com formalismos estruturados é necessário realizar a distinção entre uma Cadeia de Markov e um Processo Markoviano.

A forma usual de separar estes conceitos é através da observação do escala de tempo adotada.

Enquanto que a primeira é uma definição em escala de tempo discreto, os Processos Markovianos tratam apenas de escala de tempo contínuo.

Um processo markoviano se refere a um modelo matemático de um sistema dotado da propriedade markoviana, ou seja, um sistema onde a propensão para se estar em um estado futuro depende somente das informações contidas no estado atual, sem precisar nenhuma outra informação sobre o histórico do passado.

Esta propriedade é central para o estudo deste formalismo e é referenciada na literatura através de memoryless property.

Entretanto, apesar da existência das duas escalas serem definidas no cerne do formalismo, a maneira mais usual de se trabalhar com processos estocásticos para análise quantitativa de sistemas é definir um Processo Markoviano, teoricamente mais natural que trabalhar com escala discreta e consequentemente com Cadeias de Markov (este tópico será mais discutido a seguir).

Conforme mencionado no Capítulo 2, o objetivo é analisar a distribuição estacionária de modelos observando o comportamento dos sistemas em longas trajetórias, como se fosse -simulado- até atingir um estágio onde não mais importa seu estado inicial.

Ao atingir um regime estacionário, o sistema produz probabilidades no regime estacionário que atestam valores quantitativos para serem analisados pelos modeladores, os quais interpretam os dados para extração de índices de desempenho.

Uma forma mais abstrata de se estudar Processos Markovianos com estruturação está baseado no conceito de como as partes se relacionam, ou seja, como sincronizam atividades e desempenham papéis independentes.

Este conceito, ao considerar-se os módulos como um todo, também pode ser visto como se cada um fosse um processo e estes interagem através de comunicações ou troca de mensagens de forma sincronizada.

Tais processos foram denominados Processos Markovianos com Comunicação (PMC).

A definição de PMC para avaliação de desempenho não é nova, sendo já utilizada por outros autores em outros contextos.

Esta classe de processos é estudada há bastante tempo mas só recentemente teve sua utilização realçada pelo problema da explosão do espaço de estados e complexidade das operações tensoriais envolvidas.

Outro importante fator que impulsionou a pesquisa em PMC foi o fato da definição de múltiplos formalismos estruturados de modelagem e a percepção de diversas características em comum entre si.

Exemplos de formalismos com propriedades em comum, destacam-se as Redes de Filas, Redes de Autômatos Estocásticos, Redes de Petri Estocásticas e Álgebras de Processo, todos definindo e trabalhando com descritores Kronecker para representação implícita da matriz de transição equivalente à Cadeia de Markov.

A definição de um sistema através de Processos Markovianos com Comunicação é uma maneira versátil de modelagem de realidades com transições complexas com grande número de sincronizações entre suas entidades.

A solução eficiente desta classe de processos aplicada as transições generalizadas (que realizam transições em função dos estados dos seus componentes), ainda é um problema em aberto alvo de pesquisas que apontem maneiras de se tratar com tais estruturas.

Esta seção discutirá as principais formas de definição de PMCs e calcular as probabilidades estacionárias ou transientes e suas implicações na memória dispendida e seus efeitos no descritor markoviano equivalente.

A ideia de se utilizar PMC para descrição de modelos é pensar em um sistema como composto por um conjunto de componentes com uma organização interna e verificar como estes componentes ou módulos interagem entre si, ou seja, onde existe uma comunicação para sincronização de atividades.

Este conceito de comunicação está presente em MCs, pois pode-se pensar que os estados onde existem transições estão na verdade em processo de comunicação.

A motivação para o uso de PMCs está centrada no fato de que é mais fácil entender um sistema abstraindo os detalhes menos importantes e pensar na sua semântica operacional como um todo.

Depois desta descrição composicional do sistema, parte-se para o próximo estágio, que é determinar computacionalmente a estacionariedade e estabelecer a fase de análise e refinamento do modelo para refletir a realidade.

A própria ideia de se decompor um sistema em partes menores para serem melhor entendidas foi estudada no contexto da Engenharia de Software na década de 70, usando o conceito de -módulos-.

Dando seguimento a estes conceitos pode-se inferir sua utilização no contexto de avaliação de desempenho quantitativo de sistemas, tal como PEPA.

A definição original de PEPA estabelece que cada componente sequencial do modelo é visto como um autômato, ou seja, já existe esse relacionamento entre formalismos estruturados com vistas à solução de sistemas.

Esta ideia para PEPA implica na necessidade da área de avaliação de desempenho de definir formatos intercambiáveis pois, na verdade, a maioria dos formalismos possui primitivas em comum.

É nesse cenário que são introduzidos os Processos Markovianos com Comunicação, responsáveis pela definição entre os componentes existentes e as suas sincronizações de transições, dado o esforço necessário para se produzir traduções válidas e eficazes entre os formalismos que não onerem os recursos computacionais.

O uso demecanismos estruturados potencializa a descoberta de propriedades da Cadeia deMarkov equivalente.

Ao compartimentalizar os elementos do sistema abre-se a possibilidade de se descobrir partições mais facilmente, utilizadas para efeitos de agregação e redução do modelo.

Esta composição do sistema promove, também, um maior entendimento do sistema, pois divide o problema em partes mais gerenciáveis e menos suscetíveis a erros.

Outro fato que contribui para a disseminação de PMCs é a aplicação de técnicas do tipo divisão-e-conquista para atacar um problema, sendo útil para a detecção de gargalos e características indesejadas em sistemas com transições complexas.

A seguir, serão mostrados exemplos de equivalência entre os formalismos estruturados e PMC bem como um estudo de caso compreendendo a transformação entre uma PEPA net e uma SAN, mostrando a sua equivalência em relação à matriz de transição correspondente.

A equivalência entre os formalismos pode ser constatada ao obtermos a mesmamatriz de transição da Cadeia de Markov para diferentes formalismos.

Como o vetor estacionário obtido após a convergência serão idênticos entre si, constata-se que os formalismos são igualmente equivalentes.

Como explicado anteriormente, uma das principais motivações para o uso de PMC deve-se ao fato de nunca precisar armazenar a matriz de transição, acessando a estrutura conforme propriedades da Álgebra Tensorial (Descritores Tensoriais ou Kronecker).

Toda a teoria sobre PMC envolve a definição de tais descritores, bem como as formas de se multiplicar o vetor de probabilidades por essa estrutura, para então usar um método iterativo de solução.

A utilização de descritores tensoriais praticamente elimina o problema de memória relacionado as Cadeias de Markov.

Os formalismos estruturados de solução são todos Processos Markovianos com Comunicação, no caso de Redes de Autômatos Estocásticos, a principal unidade criada é um autômato, em Álgebra de Processo para Avaliação de Desempenho (PEPA) são os processos, e para as Redes de Petri Estocásticas Superpostas, são os módulos.

PMC é então utilizado para definir como estas unidades se comunicam, através da definição das transições existentes e das taxas envolvidas.

Uma extensão das PMCs são os chamados Processos Markovianos com Comunicação Generalizados (PMCG) e definem o funcionamento de transições no sistema através de taxas funcionais (usando preceitos da Álgebra Tensorial Generalizada).

A seguir, estuda-se um modelo baseado em uma rede de filas a ser transposto para uma Rede de Autômatos Estocásticos, uma Rede de Petri Estocástica Superposta e uma Álgebra de Processos (em PEPA).

O objetivo é o de demonstrar a equivalência entre diferentes formalismos estruturados.

Neste exemplo, observa-se três filas com capacidade para três clientes (este exemplo usa apenas uma classe de clientes), com bloqueio e perda (quando as filas estão preenchidas, os clientes são bloqueados ou perdidos, dependendo da fila).

O exemplo mostra as três filas, definidas por Q(1), Q(2) e Q(3), a taxa de chegada e de saída das filas, e as taxas de rotação da primeira fila para a segunda e terceira, definidas por µ12 e µ13.

Mostra uma fila com comportamento bloqueante (para os clientes da fila Q(1) para a fila Q(2)) e outra fila com comportamento de perda (para os clientes da fila Q(1) para a fila Q(3)).

Este modelo estruturado de filas pode ser visto, por exemplo, como uma Rede de Autômatos, uma Rede de Petri ou uma Álgebra de Processos.

A seguir, discute-se este exemplo definido nestes formalismos citados, começando por Redes de Autômatos Estocásticos.

Mostra uma tradução possível da rede de filas para autômatos.

Cada fila é modelada por um autômato (A(1), A(2), A(3)) e cada estado representa a quantidade de clientes na fila.

Por exemplo, todas as filas tem capacidade igual a dois, então são criados os autômatos com três estados, simbolizando nenhum, um ou dois clientes (únicas possibilidades existentes para este exemplo).

O comportamento bloqueante está simbolizado na auto-transição do último estado do autômato A(3), informando que, com o evento e13, o estado fica bloqueado até ser liberado, através do evento e3.

Mostra a mesma conversão para uma Rede de Petri Estocástica Superposta.

Por fim, converte-se a Rede de Fila Aberta do exemplo para o seu equivalente em PEPA.

Mostra a tradução com três processos, simbolizando as três filas do exemplo.

O nome do processo codifica a fila e quanto clientes está possui em um determinado momento.

Os processos ditam as transições e as atividades do sistema como um todo.

A Equação do sistema definida por S identifica as comunicações existentes entre os processos.

Entre a Fila Q20 e a Q10 existe uma sincronização dada pela atividade e12 enquanto que pela Fila Q10 e Q30, a sincronização é realizada pela atividade e13.

Cabe ressaltar que todos os modelos possuem solução equivalente, ou sejam, produzem a mesma matriz de transição correspondente ao processo markoviano para ser calculada utilizando-se um método direto ou iterativo de solução de sistemas lineares.

Apesar de existirem diferentes formas de visualizar e definir o problema, todos os formalismos produzem a mesma matriz subjacente, ou seja, existem características em comum para esta classe de problemas.

Estas propriedades em comum são tratadas por PMCs, que auxiliam os usuários na definição e solução deste tipo de formalismo.

A seguir é mostrado um estudo de caso de transcrição do formalismo de PEPA nets para um descritor markoviano baseado no formalismo de SAN.

Mecanismos de tradução entre formalismos são alternativas válidas de transposição e permitem que sejam visualizados e resolvidos de diferentes maneiras, aproveitando as vantagens presentes e as formas intrínsecas de solução.

A dificuldade de se realizar uma tradução representativa deve-se ao fato de que cada formalização apresenta um conjunto de primitivas específicos, normalmente difíceis de serem mapeados.

A seguir será mostrada uma tradução entre dois formalismos bastante usuais de modelagem, que são as PEPA nets e um formalismo que reproduz um descritor Kronecker, que é o caso de SAN.

Dado que as PEPA nets podem ser vistas como uma rede onde as marcas são na verdade componentes PEPA, as traduções a seguir podem ser aplicadas diretamente ao mapeamento de modelos PEPA, sem perda de generalidade.

A seguir será mostrado como realizar um mapeamento válido entre os formalismos através do uso do Grafo de Derivação (GD) e da Matriz de Transição (MT) gerada pelo compilador de PEPA nets.

O objetivo deste estudo de caso é apresentar as regras de tradução que convertem um modelo descrito em PEPA nets para uma SAN de forma direta, sem precisar converte-lo para uma representação intermediária baseada em PEPA.

A partir das informações contidas tanto no GD quanto no MT criará transições e eventos correspondentes de acordo com seu tipo (local ou sincronizante).

Os resultados apresentados demonstram um mapeamento válido e equivalente, mostrando uma equivalência entre as matrizes de transição entre ambos os formalismos.

Uma tradução válida entre PEPA nets e PEPA foi discutida onde os autores propuseram a conversão para facilitar e acessar o conjunto de ferramentas disponíveis para álgebras de processos.

Ao converter uma PEPA net para um descritor Kronecker, o objetivo é o mesmo, que é o de utilizar o software de solução e as técnicas (no caso as ferramentas já existentes para tratar com descritores deste tipo) disponíveis no PEPS.

Os autores realizaram um estudo sobre como relacionar PEPA e SAN de forma conjunta, analisando as vantagens e desvangens desta transposição inclusive quando taxas funcionais (ATG) são usadas para realização de um mapeamento menos oneroso para o propósito de solução dos modelos.

Outras traduções entre formalismos foram observadas anteriormente, tais como representação de PEPA para SPN ou através do uso do Compilador Imperial para PEPA (ipc, ou The Imperial PEPA Compiler).

Um outro trabalho importante que tratou sobre o mapeamento para Kronecker foi estudado que estabeleceu as fundações necessárias para representar modelos PEPA.

Ambos formalismos considerados nesta seção são visualmente atraentes e mostram as relações de causa e efeito de forma simples.

Esta forma permite que sejam criados mecanismos que convertem as regras semânticas e da álgebra de processo das PEPA nets para determinar como as entidades colaboram entre si em um formato equivalente utilizável por SAN.

Ao utilizar as informações contidas naMT e no GD, percebe-se as ocorrências das taxas no nível daMC e como está ocorrendo a evolução de um estado para o próximo.

Estes dados são compilados pela ferramenta PEPA Workbench (pwb) restando apenas discernir as informações mais relevantes contidas nos arquivos produzidos, desta forma simplificando o mapeamento.

Uma informação crucial para reter são os rótulos utilizados pelo modelador.

É desejável que o mesmo sistema de rótulos seja utilizado na representação final SAN.

A definição formal de PEPA nets considera a interação entre os processos existentes e como as entidades colaboram, entretanto, a pwb não faz distinção entre eventos locais ou sincronizantes e este dado é necessário para a construção de SAN.

Ao inspecionar o GD e a MT de uma PEPA net, reconhece-se quatro classes distintas de eventos.

Ações Individuais (Individual Actions, ou IA), corresponde a uma mudança dentro de um lugar, significando que um componente PEPA trocou de estados de forma individual e é traduzido sob a forma de descritor para um evento local simples (LOC).

Ações individuais relacionam-se a marcas e a componentes estáticos do tipo stateful.

Movimentação de Marca (Token Movement, ou TK), duas marcas se movem em lugares diferentes, causando duas mudanças de estado em dois autômatos diferentes.

Em linguagem de descritores markovianos esta ocorrência corresponde um evento sincronizante (SYN).

Ações de Cooperação (Cooperation Action, ou CA), o mesmo que TK, exceto que uma mudança também promove uma outra mudança no estado de um componentes estático do tipo stateful.

Ações de Cooperação Múltiplas (Multi-Cooperation Action, ou MCA), este tipo de evento é um caso particular no contexto de PEPA.

Um único evento é responsável pela mudança de estado de diversos autômatos.

A tradução é um evento sincronizante que opera sobre múltiplas entidades, alterando o estado global do sistema, igualmente chamado de sincronização do tipo multi-way na literatura de autômatos e álgebras de processo.

Mostra as quatro classes de eventos observadas.

A coluna Evento contém o rótulo entre duas transições.

Neste trecho de uma MT e DG, observa-se que ambos os componentes do tipo Probe dos lugares Place1 e Place3 são componentes estáticos do tipo stateless, enquanto que o componente Master é estático do tipo stateful, podendo se comportar eventualmente como Master1.

No topo de cada coluna, os rótulos PNi e CNi indicam o nome do autômato correspondente que será criado, onde o método é aplicado e gera quatro autômatos para este exemplo (melhor explicado na sequência).

A classe é mostrada pela coluna Cl e a tradução para SAN está na coluna Trad.

Ao conhecer as classes de eventos possíveis, as informações daMT e GD, calcula-se a quantidade de autômatos e o produto do espaço de estados necessário dada a existência de um modelo PEPA net com P lugares e C componentes.

Cada lugar será transformado em um autômato, caso exista componentes estáticos do tipo stateful, será necessário um autômato para cada lugar definido, correspondendo a A = P + C × (1f) autômatos (onde f corresponde ao tipo de componente, explicado na equação).

Mostra o cálculo para o PSS esperado final para esta tradução.

Para o caso de traduções para modelos PEPA simplesmente, cada Processo definido no modelo é transcrito por um autômato.

O conjunto de derivações possíveis com sincronizações nos lugares de cada componente ditarão o número de estados dos autômatos.

Se o componente é estático e stateless, será necessário definir um estado adicional para representar uma célula vazia (na PEPA net), diferentemente do procedimento a ser adotado para componentes estáticos do tipo stateful, onde não existem células vazias, apenas transições.

O cálculo final do PSS é o produto dos estados de todos os autômatos que foram traduzidos do modelo PEPA ou PEPA net.

Cada classe de evento irá afetar a maneira de se construir a especificação final dos autômatos do modelo.

Para eventos locais é direto o rótulo para o evento é salvo e a transição é criada.

Para eventos sincronizantes é necessário descobrir todos os autômatos envolvidos no sincronismo e verificar se já não existe um evento definido previamente que realiza a mesma tarefa.

Caso não exista, o evento sincronizante é criado, observando o rótulo definido pelo modelador.

O método de tradução é apresentado no Algoritmo, de acordo com três fases distintas, primeiramente monta as estruturas de dados necessárias observando as marcações iniciais passando para a fase de preenchimento de informações e criação de autômatos sendo finalizada com a fase de composição e formação de detalhes para criação de um modelo SAN com todas as suas características (funções de integração, seções de eventos e identificadores, entre outros).

A primeira fase é responsável pela criação de um dicionário de rótulos contendo lugares, componentes, transições, marcas e taxas para serem manipuladas pelas demais fases.

Para a operação do algoritmo são necessárias as informações do GD, da MT e duas listas auxiliares, uma contendo os lugares para cada transição gi e outra para as mudanças entre os componentes.

Ainda no início, é chamada uma função denominada CreateEmptyAutomatonSet que descobre as mudanças de componentes existentes e cria o conjunto de autômatos sem nenhuma transição ou evento.

Após descobrir os autômatos necessários, passa pela MT descobrindo todas as transições que foram efetuadas organizando-as conforme vai operando sobre o total de linhas existentes.

Para descobrir os eventos é usada uma função chamada GetEvent que retorna o nome do evento utilizado para o mapeamento dos rótulos.

As linhas 10 e 11 do algoritmo pegam duas transições (de Pi para Pj e de Ci para Cj) e, para cada caso, são analisadas e retornam os índices das marcas que alteraram suas posições e para o caso de componentes, os índices dos componentes que mudaram.

A função DiscoverClass pega esta classe de índices descobertos e determina a classe dentro das possibilidades existentes ({IA, TK, CA, MCA}).

Se o método retorna algo imprevisto ao tentar detectar a classe, uma condição de erro é instaurada.

Esta ocorrência é plenamente possível pois o usuário da pwb pode estar usando opções de agregação (aggregate).

A seguir, em cada caso, são chamadas funções específicas, tais como DiscoverTransition and {AddLocal, AddSynch} que utilizam a informação do GD para retornar os rótulos para as transições para que os autômatos sejam criados com o mesmo nome utilizado na modelagem da PEPA net.

As funções acrescentam eventos locais e sincronizantes entre os autômatos envolvidos, detectando se cada nova transição é nova (apenas acrescenta as transições que não estão definidas ainda).

O final do algoritmo é marcado por funções que verificam a rede de autômatos criada, de acordo com a função V erifyAutomata.

Ao término, caso não tenha ocorrido nenhum problema de indefinição, a representação equivalente entre os formalismos é devidamente criada e pode ser usada em ferramentas de compilação e solução de descritores Kronecker existentes.

A seguir é mostrado um exemplo de conversão de uma PEPA net para uma SAN, de forma gráfica.

Esta seção apresenta dois modelos PEPA net, MobileAgents e ClassifiedAgents.

Todos os eventos estão sendo criados de acordo com o nome utilizado pelo modelador sendo necessário, algumas vezes, alterar o nome internamente para refletir o fato que o um novo evento é necessário dentro do modelo SAN.

A ideia básica do modelo MobileAgents é considerar agentes que inspecionam diferentes lugares e retornam para um servidor chamado Mestre (Master) para depositar os resultados coletados.

A classificação do lugar Master é estático do tipo stateful, ou seja, pode alterar seu estado para Master1 com a atividade de depósito (dump).

Este fato provocará a criação de um autômato adicional para relacionar esta problemática para uma tradução equivalente.

Mostra a estrutura do modelo MobileAgents e seu correspondente modelo descrito em SAN.

Ao comparar ambos modelos percebe-se que ambos fornecem auxílios visuais para percepção dos relacionamentos e atividades desempenhadas por cada modelo.

A única diferença é a forma com que ambos são resolvidos computacionalmente.

Em SAN, o modelo gera um descritor markoviano e é resolvido através das formas usuais de MVD existentes enquanto que o modelo PEPA net necessita executar uma ferramenta de solução matemática como Matematica, Maple ou Octave para citar algumas que podem ser utilizadas para este propósito.

O próximo exemplo considerado é baseado no anterior e chama-se ClassifiedAgents.

Este modelo possui três lugares e duas classificações para agentes, AgentA7 and AgentA8.

O sistema representa agentes do tipo AgentA7 que podem baixar (download) ou salvar (save) informações e se comportarem como AgentB7.

A rede possui três lugares estáticos do tipo stateless chamados Remote, Socket e MI5.

O lugar Remote permite que agentes troquem informações com agentes do lugar chamado Socket, que podem salvar ou selecionar (select) informações.

O lugar chamado MI5 é responsável por processar informações.

Também mostra a tradução para SAN com todos os eventos e transições criadas e seus tipos correspondentes.

Os eventos sincronizantes chamados move possuem uma propriedade particular, eles acontecem em diferentes autômatos e suas ocorrências fazem com que agregações semânticas sejam difíceis de serem aplicadas, pois sincronizam os autômatos sempre de dois em dois, simbolizando que o lugar ficou vago ou foi ocupado por outra marca (no caso, agente).

O nome escolhido para cada autômato reflete o número de componentes em cada lugar.

O lugar Remote possui dois componentes do tipo AgentA7 enquanto que Socket possui três, dois do tipo AgentA7 e um do tipo AgentA8.

O lugar MI5 possui apenas um agente do tipo AgentA8, fazendo com que cada autômato seja chamado de P11, P21, P22, P23 e P31, respectivamente.

A tradução transforma cada lugar em um autômato representando os aspectos comportamentais dos componentes envolvidos e a movimentação das marcas dentro da rede.

Os autômatos precisam guardar a informação que um lugar não possui nenhuma marca em um estado chamado.

As marcas trocam de lugares de forma sincronizada através do evento move, que sincroniza a saída de um lugar com a chegada em outro lugar.

As transições locais são representadas no autômato de forma similar à modelada em PEPA nets, através de diferentes eventos (save, select, download ou process).

Uma vantagem de se traduzir de PEPA nets para SAN ou para qualquer formato que descreve um descritor markoviano é não precisar armazenar a matriz de transição.

A tradução efetuada nesta seção gerou a mesma matriz equivalente sem perder informações tanto visuais quanto qualitativas (quanto aos nomes de eventos e lugares).

Os exemplos mostrados permitiram a constatação que alguns eventos encontram-se interlaçados, ou seja, disparam a movimentação das marcas de forma sincronizada simbolizando a desocupação de um lugar e a movimentação para um outro lugar na rede.

Dando seguimento à tradução, uma tarefa que pode ser perfeitamente realizada é aplicar formas de reduzir os estados locais, transições ou autômatos de forma que permaneçam representando o mesmo comportamento ao mesmo tempo que possibilitem análises quantitativas em menos tempo.

O objetivo neste contexto foi o de demonstrar com exemplos a existência de representações equivalentes entre formalismos, apresentando um estudo de caso onde modelagens em PEPA nets são traduzidas para SAN de forma equivalente.

Com estes conhecimentos é possível dar continuidade ao capítulo discutindo meios abstratos para comunicação e interação de subsistemas, vistas a seguir.

Conforme mencionado anteriormente, a forma de interação entre os componentes individuais de um sistema é através de comunicações ou sincronismos.

Apesar de existirem trocas de informações locais, os elementos do sistema cooperam de forma global, sincronizando atividades quando necessário.

Cada componente do sistema pode ser visto como um processo, um autômato, um módulo ou qualquer outra denominação equivalente.

Este corresponde ao menor grão do sistema e não pode ser mais dividido.

A seguir, explica-se como os componentes interagem e suas implicações no descritor markoviano.

Explica os principais elementos de decomposição dos formalismos de solução.

Percebe-se a existência de elementos em comum, que desempenham as mesmas funções quando um descritor Kronecker é definido.

Se em SAN tem-se transições com eventos locais ou sincronizantes, em PEPA tem-se processos, ações locais e cooperação, e assim por diante.

No nível da definição do descritor, todas as matrizes que representam estas comunicações são equivalentes e realizam as mesmas atividades neste contexto.

Sem perda de generalidade, consideram-se apenas estados, transições e eventos em PMCs.

Um componente possui uma lista enumerável de estados, chamados também de estados locais.

Quando observa-se a totalidade dos componentes em um sistema e combina-se todos os estados entre si, gera-se o Produto do Espaço de Estados, definindo seus estados globais.

Supondo que todos, ou uma grande maioria, dos estados são atingíveis (sem considerar os estados inatingíveis que podem ser potencialmente produzidos no produto dos estados locais) e que a MC equivalente é ergódica (com estados finitos, aperiódica e irredutível), uma transição pode ocorrer de acordo com um ou mais eventos que pode ser constante ou atuar em função do estado de outro componente.

Cada evento apresenta uma taxa ou frequência em que ocorre.

Esta classificação é importante para uma maior compreensão das características de PMCs, onde observa-se as similaridades existentes com outros formalismos estruturados, em particular Redes de Autômatos Estocásticos e Redes de Petri Generalizadas.

Mostra uma representação gráfica de PMCs.

O objetivo é determinar o descritor markoviano equivalente multiplicado pelo vetor de probabilidades através das informações contidas nos componentes e transições do modelo.

O que potencializa o uso de PMCs para a descrição de sistemas é o fato de possuir premissas simples e recursos poderosos de modelagem tais como taxas funcionais e sincronizações.

Qualquer formalismo estruturado que gere um descritor markoviano é suscetível de ser tratado com as opções de solução existentes de PMCs, por exemplo, usando-se o Algoritmo Shuffle ou Split.

Esta seção apresentou um formalismo estruturado que agrega definições de outros mecanismos de descrição presentes na literatura, auxiliando o processo de solução de sistemas.

Seu ponto forte reside na modularização dos componentes, mapeando os comportamentos independentes e de sincronização de atividades.

A abstração do sistema em modelos deste tipo facilita a compreensão das operações que o sistema desempenha e permite análises de grande porte, uma vez que são utilizadosmecanismos otimizados de MVD.

O exemplo de tradução mostrou como fazer para converter uma modelagem baseada em PEPA nets em um formato usado pelo formalismo de SAN que em última análise cria um descritor markoviano.

Entretanto, ao invés de utilizar um formalismo ou o outro, pode-se abstrair os problemas e pensar apenas nas entidades oumódulos envolvidos e como estes sincronizamatividades e produzem comunicações entre si.

Como exemplo de conversão, consideram-se blocos em um sistema qualquer de computação onde deseja-se inferir o grau de acoplamento, ou seja, deseja-se quantificar a comunicação entre as partes do sistema.

O ideal, ao construir um software, é construir blocos1 contendo codificações de funcionalidades de um sistema, os quais desempenham tarefas locais de forma independente.

Entretanto, algumas vezes, é necessário trocar mensagens com outros blocos ou esperar algum resultado produzido por outras partes do sistema.

Para o caso de uma modelagem abstrata deste problema, considera-se cada parte do sistema como sendo um módulo, em última análise possuidor de um conjunto de classes associadas e, consequentemente, métodos associados e potencialmente instâncias de outros objetos auxiliares.

O fato importante é que existem comportamentos locais e globais neste sistema, sendo plenamente adaptável para a modelagem proposta por este capítulo.

Considera-se que o sistema possui quatro módulos, denominados Entrada, Calcula, Relatório e Publica, melhor explicados a seguir 1.

Entrada, este bloco é responsável por todas as entradas de dados no sofware, guardando as estruturas de dados necessárias, ou seja, qualquer novo dado requisitado pelo sistema é imediatamente comunicado a esta parte, que salva-os.

Calcula, utiliza os dados existentes na entrada para calcular médias e outras estatísticas (os blocos definidos neste problema realizam operações estatísticas para efeitos de modelagem, entretanto, poderiam desempenhar quaisquer outras atividades onde existissem comunicações entre os blocos definidos).

Relatório, a partir dos cálculos efetuados, utiliza os dados do sistema para construir relatórios.

Publica, este bloco utiliza o término da parte de cálculos e relatórios para publicar as informações previamente desenvolvidas.

Este problema abstrai a parametrização, ou seja, assume que as frequências de trocas de mensagens estão sendo capturadas por outra parte, mas devidamente usadas para compor as taxas do problema em questão.

Cada bloco deste software pode ser representado como um módulo, que desempenha atividades internas e que, às vezes, comunica requisições ou informa processamentos aos outros módulos.

Nota-se que os módulos possuem uma interdependência, ou seja, necessitam de informações presentes em outros módulos.

Este comportamento pode ser representado através da utilização de eventos sincronizantes e a parte que dita que o módulo desempenha atitudes independentes pode ser representada através de eventos locais simples, observando ou não o estado de outros módulos.

Este exemplo de sistema mostrou a utilização de abstração ao modelar o sistema em questão bem como foi usado para extração de índices que atestam a quantidade de comunicação existente entre os blocos do software.

Nota-se a importância de se descrever um problema utilizando-se o mínimo de propriedades e características para permitir um maior controle quando este for representado através de uma descrição de alto nível.

O problema, a seguir, pode perfeitamente ser descrito através de uma linguagem que produzirá um descritor markoviano que produzirá o conjunto de informações quantitativas que demonstremo nível de comunicação existente entre os blocos.

Esta informação pode ser utilizada para reduzir a quantidade de comunicação entre os blocos do software significando em menos defeitos e maior produtividade por parte dos programadores do sistema.

Uma outra vantagem de se quantificar estas informações é permitir um maior reuso dos componentes de software que fazem parte de um sistema maior, promovendo um menor custo do projeto como um todo.

O uso de Álgebra Tensorial Clássica ou Generalizada potencializou que outros formalismos estruturados fossemdefinidos coma aparente vantagemde nunca precisar gerar a matriz de transições e sim acessá-la implicitamente através da utilização das propriedades definidas pelas álgebras.

Observa-se, cada vez mais, a necessidade de se centralizar os conceitos que usam tais álgebras para extração de índices de desempenho.

É através dos Processos Markovianos com Comunicação que as principais definições serão concentradas e melhores formalizadas, especificando os próximos passos necessários para serem pesquisados.

Tais processos auxiliam na abstração de realidades, onde os detalhes são mapeados para componentes indivisíveis que operam de forma independente ou comunicando suas trocas de estados com outros componentes do mesmo sistema.

Trata-se de uma proposta mais geral de definição e concepção de sistemas markovianos com vistas à análise de desempenho e descoberta de propriedades quantitativas.

O presente capítulo discutiu formas de maior abstração ao se compor sistemas de forma estruturada e utilizou os conceitos de Processos Markovianos com Comunicação para este propósito.

Esta visão composicional de descrição de sistemas com primitivas simples de comunicação é observada em múltiplos formalismos estruturados com representação equivalente de descritor Kronecker.

Tais processos auxiliam na abstração para decomposição de sistemas para inferência de índices de desempenho.

A sua contribuição está baseada no fato que possibilita que conceitos chave sejam observados e definidos em sistemas, agregados em uma mesma definição.

Ao modelar os sistemas pensando nos seus módulos (ou partições, elementos, etc), é possível capturar sua operação principal, instanciando elementos que representam o comportamento individual e em conjunção com suas outras partes.

O objetivo da representação de sistemas através de PMC é o de permitir a construção de descritores Kronecker válidos para descreverem sistemas contendo múltiplos componentes com múltiplas interações e comunicações.

O próximo capítulo trata da solução de descritores Kronecker tanto para Álgebra Tensorial Clássica quanto Generalizada e descreve os principais algoritmos de MVD.

Este capítulo abordará a multiplicação de um vetor de probabilidade por uma estrutura mais complexa, ou seja, por um descritor markoviano.

A formação deste descritor corresponde ao gerador infinitesimal de um sistema.

Quando esta estrutura é multiplicada por um vetor inicial de probabilidades inúmeras vezes, pode ou não convergir para um vetor que encontra-se na estacionariedade, ou seja, um vetor que atingiu o estado de equilíbrio (para o caso de solução estacionária ao invés de solução transiente).

Em todos os formalismos estruturados com representação tensorial existem operações que são efetuadas para gerar implicitamente este gerador infinitesimal.

A seguir serão definidos os principais conceitos de álgebra tensorial clássica e generalizada, bem como suas propriedades.

O capítulo continua com a definição de descritores tensoriais e finaliza com os principais algoritmos existentes de MVD.

Para resolver estruturas tensoriais é importante definir as principais operações existentes na álgebra tensorial.

No contexto deste trabalho, as operações mais importantes são o produto tensorial e a soma tensorial, melhor explicadas a seguir.

Esta representação de elementos de uma matriz corresponde ao produto tensorial realizado sobre os elementos c[i,k],[j,l] que estão em ordem lexicográfica de acordo com os seus índices (ou seja, na ordem que foram originalmente definidos).

A soma tensorial utiliza um produto tensorial para ser calculada.

Sejam duas matrizes quadradas A e B, sua soma tensorial é definida como a soma dos fatores normais de cada matriz, de acordo com a fórmula, onde InA e InB correspondem a matrizes identidade de dimensões A e B respectivamente.

O operador produto tensorial tem precedência sobre o operador da soma tensorial e estes dois operadores tensoriais, por sua vez, também têm maior precedência sobre os operadores tradicionais de multiplicação e soma.

As propriedades da ATC de interesse são listadas a seguir.

Associatividade da soma e do produto tensorial.

Compatibilidade com a multiplicação convencional.

Compatibilidade com a transposição de matrizes.

Compatibilidade com a inversão de matrizes (se A e B são matrizes inversíveis).

Decomposição em fatores normais.

Distributividade com relação à multiplicação pela matriz identidade.

Comutatividade dos fatores normais.

A álgebra tensorial generalizada é uma extensão da álgebra tensorial clássica, e tem como principal objetivo permitir a utilização de objetos que são funções discretas sobre linhas de uma matriz.

Trabalha-se nas matrizes com elementos passíveis de avaliações diferentes, ou seja, tem-se uma matriz que pode ter diferentes instâncias de acordo com uma avaliação.

A diferença fundamental da ATG com relação à ATC é a introdução do conceito de elementos funcionais.

Entretanto, uma matriz pode ser composta de elementos constantes (pertencentes a R) ou de elementos funcionais.

Um elemento funcional é uma função real dos índices de linha de uma ou mais matrizes, o domínio dessa função é Rn e seu contra-domínio é R.

Um elemento funcional b(A) é dito dependente da matriz A se algum índice de linha da matriz A pertencer ao conjunto de parâmetros desse elemento funcional.

Uma matriz que contém ao menos um elemento funcional dependente da matriz A é dita dependente da matriz A.

Assim como a ATC, a ATG é definida por dois operadores matriciais, produto tensorial generalizado, soma tensorial generalizada.

A notação definida continua sendo válida para as matrizes constantes (matrizes sem elementos funcionais).

As matrizes com elementos funcionais, denominadas matrizes funcionais.

Uma vez descritas as operações existentes em álgebra tensorial (tanto clássica quanto generalizada), é possível dar seguimento ao capítulo através da discussão dos descritores markovianos.

Sistemas representados por redes de autômatos estocásticos ou outros formalismos estruturados permitem uma visão modular onde as interações entre os diferentes subsistemas são modelados por taxas funcionais ou por taxas sincronizantes.

O comportamento independente dos autômatos pode ser modelado por taxas locais, ou seja, taxas que não são alteradas pelos estados de outros autômatos.

O descritor markoviano é o gerador infinitesimal -Q da Cadeia de Markov quando as diferentes matrizes são expressas no formato tensorial.

As diferentes operações que podem ser efetuadas (por exemplo, soma tensorial ou produto tensorial) reproduzem as interações e igualmente como os diferentes autômatos sincronizam atividades.

Somas tensoriais são na verdade produtos tensoriais efetuados em matrizes do tipo identidade (onde substitui-se uma dada matriz por sua matriz identidade equivalente em termos de dimensão).

Com isso, pode-se simplificar em termos de notação do descritor markoviano para, onde L é um conjunto de termos tensoriais do tipo {l, e+, e} com cardinalidade |L| = N + 2E.

Esta seção discutirá o efeito de cada tipo de evento em um descritor markoviano, ou seja, levantará as implicações em se definir em um dadomodelo se umevento é local ou sincronizante ou se a sua taxa é constante ou funcional.

Esta análise iniciará pelos eventos locais (inclusive com taxas funcionais), prosseguindo para os eventos sincronizantes.

O modelo de estudo possui cinco eventos locais, l0, l1, l2, l3 e l4.

No descritor markoviano eles correspondem a duas matrizes (devido à existência de dois autômatos) de dimensão três (pois ambos autômatos possuem três estados).

Antes de começar a compor o descritor markoviano com as taxas relacionadas aos autômatos em questão é necessário outras definições no que tange a Cadeia de Markov almejada nesse exemplo.

Será utilizada uma SAN de exemplomostrada.

Esta rede é composta por dois autômatos de três estados cada e possui eventos locais e sincronizantes com taxas constantes e funcionais.

Para este caso, como existem dois autômatos de três estados cada, o seu PSS (seu Produto do Espaço de Estados) corresponde a |X| = 3×3 = 9, sendo este o produto cartesiano dos estados do autômato A(1) = {A,B,C} pelos estados do autômato A(2) = {X, Y, Z}, ou seja, o conjunto X = {AX,AY,AZ,BX,BY,BZ,CX,CY,CZ}.

Logo, mostra a matriz resultante que corresponde ao gerador infinitesimal -Q da MC.

Cabe ressaltar que esta matriz encontra-se vazia para efeitos de explicação do método.

A forma correta de representá-la é preenchendo-se as células com as taxas que mostram a frequência com a qual troca-se de estado na MC.

A seguir, inicia-se a análise pelos eventos locais desta rede de autômatos estocásticos.

Cabe ressaltar que os números marcados em negrito, correspondem a avaliações de elementos funcionais que resultam no valor zero, pois essas linhas equivalem ao autômato A(1) estar no estado B.

Para o caso da função f definida no modelo, é retornada uma avaliação para falso que é então convertida para o valor zero, e consequentemente, não definindo a taxa r6 para essa linha (como seria a ocorrência normal).

A seguir, calculam-se os termos correspondentes aos eventos sincronizantes (parte positiva) e ao ajuste da diagonal (parte negativa).

Mostra o gerador infinitesimal produzido a partir deste exemplo de conversão de uma SAN em uma Cadeia de Markov.

Nota-se que esta matriz final já conta com os ajustes diagonais necessários (devido aos eventos sincronizantes negativos dos termos que foram criados) e a soma de cada linha resulta em zero.

Mostra que para converter uma SAN para uma Cadeia de Markov equivalente é necessário iterar sobre o produto dos estados, produzindo todas as combinações possíveis.

Isso evidencia o fato da modelagem por SAN ser mais compacta e compartimentalizada, como mencionado anteriormente.

Entretanto, ao realizar essa combinação, pode potencialmente gerar estados que nunca serão atingidos (esse problema não ocorre neste modelo em particular com um PSS de nove estados, somente para casos com PSS mais elevados).

Mostra, na parte direita, diferentes tipos de linha (algumas pontilhadas, outras maiores, etc) para cada evento correspondente à SAN.

Ressalta-se que em MC não existem diferenças quanto ao tipo de uma transição, todas são indistinguíveis.

Decidiu-se mostrar a cadeia desta forma para que fosse entendido o mapeamento de cada tipo de evento da SAN e sua transição correspondente na MC.

Nota-se que, para a solução de SAN, é suficiente guardar em memória apenas as pequenas matrizes que compõem o descritor, sendo desnecessário salvar o gerador infinitesimal -Q correspondente à Cadeia de Markov.

Essa é a principal vantagem de SAN sobre outros formalismos estruturados, pois baseia-se no uso da álgebra tensorial para calcular o vetor de probabilidade estacionário ou transiente do qual são extraídos posteriormente os índices de desempenho.

Este descritor está baseado no modelo Wireless Sensor Networks para quatro nós.

Este modelo possui quatro autômatos, sendo dois autômatos com dois estados e outros dois autômatos com três estados.

O PSS deste modelo é igual a |X| = 2 × 3 × 3 × 2 = 36 estados com seis eventos onde l = {t1, t2} corresponde aos eventos locais e o conjunto e = {t3, g12, g23, g34} enumera os eventos sincronizantes.

Logo, considerando-se os eventos locais, os eventos sincronizantes positivos e os ajustes diagonais dos eventos sincronizantes negativos, é necessário um termo com somas tensoriais (correspondendo aos eventos locais) e oito termos com produtos tensoriais (por sua vez equivalendo-se aos eventos sincronizantes).

O gerador infinitesimal para esse problema corresponde a uma matriz quadrada de dimensão 36 e está fora do escopo desta seção mostrá-la por completo.

Observando-se este descritor markoviano, notam-se algumas características deste modelo em especial.

As suas matrizes são extremamente esparsas e as identidades marcam que um determinado evento não ocorre em um autômato.

A seguir, descreve-se como calcular o vetor de probabilidade estacionária utilizando-se mecanismos sofisticados para multiplicação com descritores markovianos, como descrito na próxima seção.

As Cadeias de Markov utilizam, em última análise, multiplicações entre um vetor e uma matriz.

Entretanto, formalismos estruturados com descritores Kronecker nunca geram a matriz de transição equivalente à MC e sim sua representação tensorial, ou seja, um descritor markoviano.

Para resolver um modelo descrito desta forma não é mais possível utilizar a mesma abordagem de MC, ou seja, uma multiplicação vetor-matriz, mas sim uma Multiplicação Vetor-Descritor (MVD).

Esta seção tratará das formas de multiplicar um vetor de probabilidade por um descritor.

Um dos ramos de pesquisa em SAN foca-se em formas de melhorar o desempenho desta forma não trivial de multiplicação.

Existem atualmente três algoritmos distintos para operar com o produto de um vetor por um descritor, Algoritmo Esparso, Algoritmo Shuffle e um algoritmo que combina estas duas abordagens denominado Split.

Estas três maneiras serão mais detalhadas a seguir.

Definindo-se mais formalmente, a MVD pode ser vista como a multiplicação de um vetor de probabilidade p por |L| = N + 2E termos tensoriais compostos por N matrizes, onde L é um conjunto de termos tensoriais do tipo {l, e+, e-} O Algoritmo Esparso é o mais intuitivo dos métodos de MVD.

A idéia principal do algoritmo é considerar o termo tensorial como uma única e potencialmente grande matriz esparsa a ser multiplicada pelo vetor de probabilidade.

Este algoritmo assemelha-se ao método utilizado para a multiplicação de um vetor pelo gerador infinitesimal, a única diferença é que se considera apenas cada termo tensorial como uma grande matriz.

Para um termo tensorial composto por N matrizes Q, cada uma de dimensão ni com nzi elementos não-nulos, o Algoritmo Esparso gerará todos os elementos em uma matriz Q resultando em Q.

Cabe ressaltar que a linha 6mostra que antes de realizar asmultiplicações, dependendo do evento e das funções associadas no modelo, serão necessárias avaliações de função através da chamada evaluate.

O número de multiplicações em ponto flutuante para essa implementação é dada.

Entretanto, nesta versão, todos os elementos não-nulos de Q são, descrevendo-se o problema computacionalmente, gerados em tempo de execução do algoritmo.

Tal geração representa Q (N1)× N i=1 nzi multiplicações que poderiam ser evitadas se uma matriz esparsa (usualmente grande) fosse criada para guardar estes elementos não-nulos.

Esse procedimento eliminaria as linhas 3 e 6 do algoritmo e reduziria o número de multiplicações em ponto flutuante como definido pela Equação.

Esta opção, ao utilizar mais memória, reduz o número de cálculo de índices (que são normalmente efetuadas em outros algoritmos, por exemplo, no Shuffle, visto a seguir) e permite que o Algoritmo Esparso seja bastante eficiente em termos de tempo gasto de execução.

Entretanto, a memória gasta para salvar essa estrutura de dados torna alguns modelos não tratáveis, logo, essa opção é normalmente descartada para modelos que contém um espaço produto de estados alto, como é o caso para uma grande variedade de casos reais.

O total de chamadas à diretiva de avaliação de funções varia de modelo para modelo e não entra na equação de complexidade.

A seguir, explica-se o Algoritmo Shuffle, que é extremamente eficiente em termos de memória gasta, e nunca gera explicitamente a matriz -Q ou mesmo uma parte dela, apenas as informações contidas nas matrizes de cada termo tensorial.

A seguir, aplica eficazmente operações de álgebra tensorial para o cálculo das informações necessárias.

O princípio básico deste algoritmo é a aplicação da decomposição de um termo tensorial na propriedade do produto ordinário de fatores normais.

O Algoritmo Shuffle consiste em multiplicar sucessivamente o vetor de probabilidade por cada fator normal.

Mais precisamente, o vetor é multiplicado pelo primeiro fator normal e o vetor resultante é multiplicado pelo próximo e assim por diante, até o último.

Internamente, para cada fator normal, as multiplicações são feitas usando-se pequenos vetores chamados zin e zout como descrito.

Estes vetores pequenos em termos de tamanho guardam os valores para multiplicação pela iésima matriz do fator normal zin e guardar o resultado em zout.

A linha 5 do algoritmo corresponde a uma avaliação de função (caso seja necessária para o modelo e de acordo com a definição da função) através da diretiva evaluate.

A multiplicação pelo vetor pelo iésimo fator normal consiste, generalizadamente, em embaralhar os elementos para montar nlefti × nrighti vetores de tamanho ni e multiplicá-los pela matriz Q.

Assumindo-se que a matriz Q é guardada de forma esparsa, o número de operações necessárias para multiplicar um vetor pelo iésimo fator normal é nlefti ×nrighti ×nzi, onde nzi corresponde ao número de elementos não-nulos da iésima matriz do termo tensorial Q.

Considerando-se o número de multiplicações por todos os fatores normais de um termo tensorial, o custo computacional do Algoritmo Shuffle para efetuar a operação de multiplicação de um vetor por um descritor é dada pela Equação.

Uma outra vantagem de uso do Algoritmo Shuffle consiste no fato de possuir otimizações para modelos com taxas funcionais, ou seja, modelos que utilizam propriedades da Álgebra Tensorial Generalizada e também no que diz respeito ao uso de reordenamentos da estrutura tensorial (também chamadas de permutações).

Como no Algoritmo Esparso as chamadas para avaliações de funções variam em cada modelo e não estão sendo contabilizadas no cálculo da complexidade final.

Eventos locais em SAN são normalmente esparsos, indicando um comportamento que independe de outros autômatos de um sistema.

O mesmo não ocorre com eventos sincronizantes, pois podem potencialmente afetar todos os autômatos de um modelo.

Entretanto, dependendo do modelo que está sendo analisado, essa condição é inexistente, isto é, um número substancial de ocorrências dizem respeito a entre pelo menos dois autômatos e um número que dificilmente beira o total de autômatos.

Esse é um dos motivos pelos quais iniciou-se a pesquisa de algoritmos que resolvessem a MVD de forma híbrida e que tirassem vantagem da propriedade da Decomposição Aditiva combinada à decomposição de produtos tensoriais clássicos em fatores normais.

A propriedade da decomposição aditiva dita que qualquer produto tensorial pode ser decomposto em uma soma ordinária dematrizes compostas por umúnico elemento não-nulo.

O Algoritmo Split propõe uma solução combinada usando fundamentalmente a propriedade da decomposição aditiva para um dado conjunto de matrizes em um produto tensorial seguido da aplicação da operação de embaralhamento para as matrizes restantes do termo.

Cada fator é chamado de Fator Normal Aditivo Unitário (Additive Unitary Normal Factor, AUNF).

Esse conceito é central para o Algoritmo Split e internamente trata-se de uma estrutura de dados que armazena os índices dos vetores de entrada (basein) e saída (baseout), um escalar s e um vetor de tamanho s contendo os índices de linha e coluna de cada matriz que foram usados para calcular s (esse vetor será usado para avaliação de funções com parâmetros que estejam na parte esparsa posteriormente).

Agora tem-se então uma divisão do termo tensorial em dois grupos distintos, o primeiro contendo matrizes que serão unidas sob a forma de uma lista de fatores normais aditivos unitários e o segundo grupo contendo o restante das matrizes.

Em termos de solução, o primeiro grupo lidará com uma solução esparsa, multiplicando tensorialmente cada AUNF pelo segundo grupo usando a solução Shuffle.

A idéia principal é dividir o termo tensorial em dois conjuntos e trata-los de forma distinta em termos de multiplicação vetor-descritor.

Apresenta estes conceitos do Algoritmo Split de forma gráfica.

O índice da matriz escolhida para delimitar o fim do tratamento com a parte esparsa (e subsequentemente, o início da parte Shuffle é denominado parâmetro de corte s (ou simplesmente corte s).

Casos especiais do Algoritmo Split são os casos onde o corte possui valores extremos, isto é, quando s = N significa que a abordagem Esparsa pura está sendo utilizada e quando s = 0 não existem matrizes no lado esparso do termo tensorial e apenas o Algoritmo Shuffle será executado.

Estes são casos particulares do Algoritmo Split.

Uma questão pertinente é onde realizar o corte de maneira que o tempo de solução do modelo alcance bom desempenho.

Esse é o principal objetivo deste trabalho, juntamente com o desafio de como saber esse valor de corte ao mesmo tempo que é permitido alterar a ordem lexicográfica dos autômatos dentro de um termo tensorial (operando-se com permutações ou reordenamentos) para facilitar, e por vezes otimizar, a MVD.

Esses problemas também relacionam-se com o uso ou não de Álgebra Tensorial Generalizada, ou seja, qual o melhor ponto de corte dado que algumas matrizes do termo tensorial possuemtaxas funcionais e suas implicações.

Essas questões serão melhores debatidas nas próximas seções.

Parte-se a seguir para a definição formal da operação do método em si.

A ideia principal do método consiste em computar o elemento escalar s de cada AUNF multiplicando cada elemento não-nulo s de cada matriz do primeiro conjunto de matrizes (parte esparsa) de Q(1) até Q (linhas 5 a 9).

De acordo com os elementos de linha que foram utilizados para gerar s, uma fatia contígua do vetor de entrada, chamado in, e será utilizado em uma estrutura de dados.

O vetor in de tamanho nright (correspondente ao produto das dimensões das matrizes após o parâmetro de corte s do termo tensorial) é multiplicado pelo escalar s.

Nas linhas 10 e 11 são realizadas as multiplicações de e para cada posição, finalizando a parte esparsa do algoritmo.

O vetor resultante in também é utilizado como vetor de entrada para a parte Shuffle (linhas 13 a 32) pelo produto tensorial das matrizes do segundo conjunto até Q(N).

Ao término da parte Shuffle o vetor obtido é acumulado no vetor final (linhas 33 a 35).

O algoritmo possui três blocos distintos, um bloco onde para cada AUNF calculado (de zero a s), um vetor auxiliar de tamanho nright (nright de zero até o valor do corte) é multiplicado em posições chave originadas durante o cálculo do AUNF em questão.

Um segundo bloco, onde o método Shuffle é chamado para um sub-espaço à esquerda que desconta as matrizes da parte esparsa (linha 15) e finalmente, uma seção onde este vetor auxiliar que foi modificado no bloco anterior é acumulado no vetor final.

A linha 17 do algoritmo mostra uma diretiva chamada evaluate, utilizada para a avaliação de elementos funcionais.

Cabe ressaltar que essa é a primeira vez que o Algoritmo Split trata descritores generalizados, ou seja, modelos com taxas funcionais.

Essa é basicamente a diferença fundamental entre as alternativas existentes até o momento de MVD que utilizem soluções híbridas de armazenamento e os impactos desta diretiva serão melhores analisados nos Capítulos 5 e 7 referentes as estratégias de modificação dos descritores e aos resultados obtidos respectivamente.

O custo computacional em termos de multiplicações do Algoritmo Split é realizado levando-se em conta o número de vezes necessárias para gerar cada elemento não-nulo que resultou em um AUNF (s1), mais o número de multiplicações de cada valor escalar por cada posição do vetor in.

Finalmente, ainda adiciona-se o custo de multiplicar os valores do vetor de entrada in pelo produto tensorial das matrizes da parte Shuffle.

Existem algumas otimizações que podem ser implementadas em algoritmos para MVD.

Estas modificações em termos de implementação alteram significativamente o custo computacional teórico apresentado.

Para o caso do Algoritmo Shuffle, pode-se otimizar a maneira pela qual o método lida com matrizes do tipo identidade.

Estas matrizes fazem com que seja desnecessária gerar fatores normais para o cálculo do vetor solução, pois, sendo identidades, as restantes também são identidades, logo todo o termo tensorial é uma identidade.

É evidente que, em se tratando deste caso particular, nenhum fator normal seja criado, reduzindo o custo computacional de execução.

O ideal é gerar sempre fatores normais com identidades (preferencialmente com o uso de permutações do termo tensorial) e utilizar o método esparso para calcular apenas os AUNFs dos termos tensoriais que são pertinentes.

Entretanto, dependendo do evento, o número de AUNFs gerados pode onerar a memória a ser gasta para armazenamento dos escalares necessários.

Nesse caso, uma análise minuciosa de cada termo tensorial deve ser realizada anteriormente onde detectará casos onde exista um grande subespaço composto por identidades e onde o método esparso obterá um ganho significativo de desempenho frente as demais modalidades de MVD existentes.

Esta melhoria sugere que o mesmo pode ser aplicado na parte do método Shuffle no Algorimo referente ao Algoritmo Split nas matrizes.

Caso a matriz indexada por i no algoritmo (Q) não seja uma matriz identidade, o custo de nzi multiplicações é adicionado.

Analogamente ao Algoritmo Shuffle, pode ser reescrita alterando-se o custo para o cálculo a partir de s.

O número de multiplicações resultantes para o Algoritmo Split seguirá a Equação Usualmente, em SAN, os termos tensoriais são esparsos, uma vez que indicam a ocorrência dos eventos em cada autômato (exceto em casos onde existam diversos eventos ocorrendo em diversos autômatos, indicando matrizes quase plenas no termo).

Uma outra otimização que pode ser realizada é quanto ao pré-cálculo dos elementos não-nulos, salvando-os em estruturas de dados que serão acessadas em todas as iterações, mas computados apenas uma vez.

Estas otimizações foram amplamente estudadas e causam uma redução significativa no custo computacional do Algoritmo Split no que diz respeito ao cálculo dos elementos não-nulos.

Logo, o valor final da definição dos número de multiplicações em ponto flutuante para o algoritmo em questão não é mais o definido Mas, se só existirem matrizes identidade na parte estruturada, toda a complexidade envolvida pelo Algoritmo Shuffle não é mais necessária, fazendo com que a Equação seja convertida Uma das operações mais custosas efetuadas na MVD é a avaliação de funções.

No contexto deste trabalho, estas avaliações estão presentes nos algoritmos que foram explicados referentes respectivamente aos Algoritmos Esparso, Shuffle e Split.

Estas chamadas de avaliações estão presentes dentro dos laços nright e nleft, ou seja, são executadas diversas vezes ao longo do método, dependendo do tamanho destes subespaços.

Para diminuir os efeitos destas execuções, são apresentadas técnicas de reordenamento ou permutação dos termos tensoriais.

Estas técnicas servem para reorganizar as matrizes dos termos tensoriais detectando uma forma para avaliar menos funções, colocando a diretiva de avaliação dentro de apenas um laço e não em dois laços como é feito originalmente no Algoritmo Shuffle.

A definição inicial do Algoritmo Split não previa a realização de permutações.

A inclusão de solução para tensores em ATG é uma contribuição que foi introduzida neste trabalho bem como o estudo e implementação adicional para contemplar tal necessidade.

Como será melhor explicado nos próximos capítulos, o uso de permutações no Algoritmo Split será amplamente necessário para a eficaz solução de modelos e portanto deve ser melhor compreendida e explicada.

Ao observar os casos particulares de produtos tensoriais generalizados, pode-se compreender melhor o interesse de realizar estas otimizações.

Para esse caso, cada matriz Q só depende dos autômatos à sua esquerda.

Devido a esse fato, como se tem certeza do posicionamento dos autômatos, é possível modificar os algoritmos de MVD para realizarem menos chamadas à diretivas de avaliação de funções.

A linha 5 seria movida para dentro do laço de nright (ou seja, logo abaixo da linha 3) e no caso do Algoritmo, a linha 17 seria colocada logo abaixo da linha 15, pelo mesmo motivo.

Ainda encontra-se em aberto como realizar esse reordenamento de autômatos para se encontrar os casos onde esse procedimento é passível de ser realizado para tentar-se reduzir os números de avaliações de elementos funcionais.

Para isso, informalmente, são poucos os casos onde as funções que são definidas dependem do estado de todos os outros autômatos.

Normalmente, uma função depende de apenas alguns outros autômatos.

Este seria o pior caso para a permutação, inclusive seria completamente desnecessário tentar realizar reordenamentos, pois não eliminariam o número de avaliações possíveis.

Não faz parte do escopo deste trabalho explicar detalhadamente as variadas técnicas de reordenamento de termos tensoriais, pois estas já foram exaustivamente feitas.

Este trabalho parte do princípio que a realização de reordenamentos pode ser extremamente eficaz tanto para reduzir-se o número de avaliações como utilizar essas reordens para reduzir o tempo necessário para executarmétodos híbridos de solução, neste caso, especificamente para o caso do Algoritmo Split.

A seguir, serão apresentados os princípios da permutação em termos tensoriais, seus objetivos e algumas definições de base.

Dado que os autômatos podem trocar de posição no termo tensorial, os elementos do vetor de probabilidade final devem trocar de lugar pois a ordem lexicográfica original foi alterada.

Mostra os estados de um vetor pelos autômatos ordenados de duas maneiras distintas.

Os elementos do vetor são organizados de acordo com uma ordem lexicográfica expressa pela lista de autômatos, igualmente respeitando uma ordem.

À esquerda da tabela é utilizada a ordem A(1),A(2),A(3).

Os autômatos deste exemplo possuem tamanho n1 = 2, n2 = 3 et n3 = 2.

À direita da tabela é realizada a seguinte reordem dos autômatos A(3),A(1),A(2).

A coluna rank equivale ao índice no vetor de probabilidade.

Como para esse exemplo o |X| = 2 × 3 × 2 = 12, esta coluna varia de 0 a 11.

A ideia aqui é descobrir o próximo estado dado um estado corrente.

Para simplificar as operações envolvidas, a melhor forma de se fazer esta descoberta é pensar em um algoritmo que retorne o próximo estado, dada uma ordem.

Logo, observa-se os autômatos do último até o primeiro e tenta-se incrementar seu estado local.

Um incremento é inválido quando o estado local do autômato é o último estado (não existem mais estados).

Quando o incremento é inválido, o estado local do autômato é zerado (reset de estado) e se considera o próximo estado (de acordo com uma determinada ordem, podendo não ser a original e sim qualquer ordem).

Este procedimento acaba quando um incremento válido foi realizado.

Para exemplificar esse processo, considere-se a ordem A(1),A(2),A(3) onde deseja-se saber o próximo estado (um incremento de estado) dado que o estado atual é o (0, 1, 1).

O autômato A(3) é o primeiro a ser considerado.

Tenta-se incrementá-lo, mas, por estar já no último estado possível (1), coloca-se nessa posição, o valor 0.

A seguir, tenta-se incrementar A(2), e o incremento é válido, para 2.

Logo, o próximo estado global do sistema seguido do estado (0, 1, 1) é o (0, 2, 0) (observe essa ocorrência, entre os ranks 3 e 4 do lado esquerdo).

Entretanto, para o caso de uma permutação das posições no termo tensorial, os incrementos não são mais tão simples e devem seguir um cálculo mais elaborado do rank final para descoberta do próximo estado.

É necessário se calcular o novo rank a partir do rank corrente do vetor permutado.

Seguindo-se o mesmo exemplo, o rank do estado (0, 1, 1) pela nova ordem lexicográfica dada por A(3),A(1),A(2) é 7.

O rank após o incremento que corresponde ao estado (0, 2, 0) deve ser 2.

Para calcular esse novo índice, realizam-se incrementos e decrementos, zerando alguns estados locais.

Os valores destes incrementos e decrementos variam de acordo com a nova ordem lexicográfica.

Um incremento válido para o próximo estado de um estado local do autômato A corresponde à adição de nrighti no rank.

No exemplo em questão foi feito um reset no estado do autômato A(3), e sob a nova ordem lexicográfica, nright3 = 2×3 = 6.

Com isso é obtido o estado de rank 76 = 1.

A seguir, como ocorrido no exemplo anterior, incrementa-se o estado do autômato A(2), e este incremento é válido, ou seja, obtem-se o valor 2 para o rank final, como seria normalmente retornado mas, neste caso, com o uso de permutações.

Com isso, observa-se que são feitos os mesmos procedimentos para ambos os exemplos, apenas no caso onde houve a permutação das ordens originais é que ao invés de se incrementar foi descontado um valor que correspondia ao nrighti, equivalendo ao salto que deve ser feito na estrutura permutada.

Trata-se de uma maneira transparente de se efetuar as permutações, incorrendo-se apenas no recálculo de índices para saltar na estrutura tensorial.

As permutações foram inicialmente utilizadas no Algoritmo Shuffle com o intuito principal de eliminar chamadas desnecessárias de avaliações de elementos funcionais.

Com isso, para alguns modelos, observou-se um ganho de desempenho pois menos operações são efetuadas se uma permutação satisfatória for encontrada.

Naturalmente, não é fácil descobrir como melhor permutar cada termo tensorial para obter o máximo de desempenho e esta é uma questão aberta de pesquisa.

No caso do Algoritmo Split, as permutações desempenharão um papel ainda mais importante que a verificada para o Algoritmo Shuffle e usada com êxito para alguns casos.

No caso do Split, os reordenamentos serão cruciais para entender qual a melhor forma de dividir os termos tensoriais enviando matrizes ou para o lado estruturado ou enviando as avaliações para a parte esparsa e viceversa.

Somente com as permutações é que é possível verificar onde o método é melhor executado pois torna possível separar cada característica dos termos tensoriais e estudar como afetam a solução dos modelos.

Mostra a operação, em detalhes, do Algoritmo Split quando existem apenas matrizes do tipo identidade na parte estruturada (utilizada pelo Algoritmo Shuffle).

Observa-se que os AUNFs (não-nulos de 0 a s) possuem um papel central nessa representação, pois guardam, para cada escalar s do vetor de entrada apontado os índices de linha e coluna que foram utilizados em cada matriz.

Dessa maneira, um AUNF conhece a posição de entrada a ser usada e também sabe onde colocar o valor multiplicado no vetor de saída.

Essas são as únicas informações necessárias para que seja executado o método, dado que só existem identidades na parte estruturada, não sendo necessária a geração de fatores normais, apenas a multiplicação do escalar pelo vetor em posições chave.

Estas análises finalizam o capítulo que tratou sobre a solução de descritores markovianos.

Foi revelado que o Algoritmo Split pois possui algumas restrições ao delimitar onde melhor dividir os termos tensoriais, seja em função das identidades existentes ou das dependências funcionais.

Atualmente o algoritmo é executado algumas iterações para a coleta de tempos de execução dos termos para então decidir quais cortes aplicará para cada termo tensorial nas iterações seguintes.

Esta escolha não segue um procedimento determinístico, baseado nas características das matrizes, trata-se de uma heurística baseada nas amostras das execuções.

O próximo capítulo tratará das estratégias de reordenação do descritor para otimizar a solução de modelos complexos.

O objetivo deste capítulo é tratar sobre as estratégias para escolha de um ponto de corte s de descritores markovianos com o objetivo de otimizar o tempo de solução do Algoritmo Split.

As estratégias que serão estudadas servirão de base para a discussão dos resultados obtidos no Capítulo 7.

Apresenta os estudos e definições preliminares necessárias para uma maior compreensão do problema da determinação de s e as escolhas que podem ser feitas para tratar os descritores.

Mostra uma análise teórica seguida das considerações finais onde uma previsão dos custos computacionais em termos de multiplicações de ponto-flutuante é apresentada.

Como explicado anteriormente, o Algoritmo Split trata os termos tensoriais dos descritores markovianos de forma híbrida, basicamente de duas formas distintas.

De um lado do termo acontece a aplicação da solução esparsa e referente à outra parte, a multiplicação que contém os fatores normais restantes (à direita do ponto de corte s) e aplica o Algoritmo Shuffle.

Neste trabalhos esta separação dos termos será definida como parte esparsa e parte estruturada, respectivamente.

Devido as características dos termos tensoriais, o problema está na determinação do ponto de corte ou divisão dos termos tensoriais s tal que o tempo para execução e a memória a ser gasta seja eficiente e balanceada.

Dentre as principais características dos termos existentes, para o escopo deste trabalhos, o interesse está voltado para as matrizes identidades que compõem os termos, as avaliações de elementos funcionais existentes e na quantidade de elementos não nulos de cada matriz.

Intrinsicamente relacionado à quantidade de elementos não-nulos estão as sincronizações existentes pois, estas cooperações indicam diretamente a quantidade de identidades existentes e a memória a ser potencialmente gasta.

O ponto de corte s escolhido ditará a memória que será gasta na parte esparsa e deseja-se evitar que um dado termo utilize uma quantidade massiva a ponto de inviabilizar a execução do Algoritmo Split.

Deve-se identificar cada termo tensorial e verificar a melhor forma de tratá-lo.

Cada termo tensorial será dividido de uma forma única (diferentes valores de s para diferentes termos), aplicando o melhor custo benefício em termos de memória e tempo para executar o método de MVD.

Esta seção utiliza os conceitos explicados anteriormente no Capítulo 4, especificamente as definições referentes à Álgebra Tensorial Clássica e Generalizada descritas, descrição dos métodos de MVD e o conceito de AUNF que é descrito.

Como cada termo tensorial corresponde à ocorrência de apenas um evento, é necessário estudar quantas matrizes este afeta.

Precisa-se descobrir o grau de dependência existente em cada termo para facilitar a análise das estratégias.

Define-se Grau de Dependência Constante (GDC) e Grau de Dependência Generalizado (GDG) os graus relacionados, respectivamente, aos termos constantes e generalizados.

O grau de dependência de um termo tensorial informa basicamente o total de autômatos que são parâmetros para um determinado elemento funcional, ou seja, informa o número de elementos necessários para a aplicação da função.

Mais especificamente, tem-se a seguinte classificação para os termos tensoriais de uma SAN.

Termo constante, um termo constante é um termo que não possui funções, apenas matrizes constantes que indicam onde cada evento ocorre em cada autômato.

GDC Alto, um termo deste tipo envolve um valor superior à metade (seja t o total de matrizes do termo, a sua metade m corresponde a m = t 2) das matrizes que o compõe1.

Ao envolver metade dos autômatos, implica na existência da outra metade ser composta por matrizes do tipo identidade.

GDC Parcial, este evento sincroniza suas atividades com menos metade das matrizes existentes no termo.

Termo generalizado, um termo generalizado possui matrizes com elementos funcionais que devem ser avaliados.

Termos deste tipo são classificados quanto ao grau de dependência generalizado, podendo ser GDG Alto, envolvem todas as matrizes do termo tensorial.

Trata-se basicamente de uma função que consulta os estados do resto dos autômatos para tomar sua decisão.

GDG Parcial, envolvem apenas algumas matrizes do termo tensorial.

Como só existem essas duas classificações, se um termo não é classificado como possuidor de um GDG Alto, ele é automaticamente definido como GDG Parcial.

Termos tensoriais são compostos por matrizes de diferentes características.

As matrizes de um termo podem ser classificadas da seguinte forma (seja nz o número de elementos não-nulos e n a dimensão de uma matriz).

Identidade, a matriz é do tipo identidade, possuindo o valor 1 para a diagonal principal e o valor 0 para o restantes das posições.

Constante, trata-se de uma matriz com mais de um elemento não-nulo, com esparsidade variável.

Elemento, trata-se de um caso especial de matriz constante, ou seja, é uma matriz esparsa com apenas um elemento não-nulo.

Funcional, indica que a matriz possui uma função definida e necessita de informações de outras matrizes do termo (para o escopo deste trabalho, de estados de outros autômatos) para correta avaliação.

Diferentes estratégias de corte devem ser tomadas para os diferentes tipos de termos tensoriais.

Para os termos constantes, apenas as dimensões das matrizes, a esparsidade e a ocorrência de matrizes identidade é que importa.

Já para os termos generalizados, além destas características, importam também as matrizes que a função necessita para ser avaliada além de onde avaliar essa função, ou na parte esparsa ou na parte estruturada.

Existem alguns fatores que contribuem para uma degradação do desempenho da MVD tais como as chamadas a avaliações de funções.

Os custos computacionais envolvidos variam de definição para definição, mas impactam no aumento do número de operações que são efetuadas para retornar avaliações válidas.

A intuição é que como o método iterativo será chamado diversas vezes, para o mesmo conjunto de parâmetros de função, talvez fosse mais interessante apenas avaliá-las uma vez e salvar as avaliações obtidas em uma estrutura de dados auxiliar.

Entretanto, essa operação não é clara e deve ser estudada com uma maior profundidade.

É claro, no entanto, que diretivas funcionais aumentaram as maneiras pelas quais modelam-se sistemas complexos onde, muitas vezes, as formas de transição são mais complexas do que basear-se na utilização pura e simples de eventos locais e sincronizantes para o caso de SAN.

As avaliações na parte esparsa converterm um descritor markoviano generalizado em constante.

Intuitivamente, avaliar as funções na parte esparsa remove a sobrecarga de se ter que avaliá-la inúmeras vezes em potencialmente inúmeras iterações.

Entretanto, uma análise teórica faz-se necessária para substanciar essas evidências.

Para começar esta análise teórica mais aprofundada, é necessário definir precisamente as opções existentes ao dividir termos tensoriais.

A seguir é feita uma análise sobre como proceder através do estudo de opções para os casos constante e generalizado.

Seja M o total de matrizes de um termo tensorial e seja V o número de matrizes envolvidas na sincronização dado que, por definição, V = 1 não acontece, pois não é permitida a definição de um evento sincronizante envolvendo apenas um autômato.

Para termos constantes, reordenar o termo e reconfigurar o termo privilegiando o fato de que as identidades sejam movidas para o lado estruturado, pior caso, V = M, ou seja, não existem identidades, o evento sincronizante envolve todas as matrizes do termo tensorial.

Caso médio, um valor V tal que 2 < V < M.

Esse caso significa que existem matrizes do tipo identidade no termo.

Melhor caso, V = 2, ou seja, somente dois autômatos estão sincronizando atividades.

Também indica que os AUNFs a serem criados são iguais ao produtório dos elementos não-nulos contabilizados até a primeira matriz identidade, o qual deve ser o valor escolhido para s.

Para termos generalizados, escolhe-se basicamente onde se avaliar as funções, avaliar na parte esparsa, implica em converter implicitamente o termo tensorial para constante, uma vez que esse procedimento na realidade troca os elementos funcionais por elementos constantes.

Avaliar na parte estruturada, aplicar as avaliações como são feitas no Algoritmo Shuffle, na parte estruturada, um número de vezes que depende dos valores dos deslocamentos nright e nleft da parte correspondente.

O objetivo é minimizar ao máximo o tempo gasto para realizar a MVD em cada termo.

A escolha de qual matriz será posicionada em cada parte deve estar de acordo com a classificação do termo tensorial e as características envolvidas.

Dessa forma, o uso de reordenamentos do termo tensorial é mandatório, uma vez que, para os termos constantes, não vale a pena posicionar matrizes identidades na parte esparsa (pois criam AUNFs desnecessários), devendo estas matrizes serem deslocadas para a parte estruturada.

Para os termos generalizados, precisa-se da informação contida nas matrizes que fazem parte das dependências da função a ser avaliada.

Se um dado termo possuir uma função e escolhe-se realizar as avaliações na parte esparsa, todas as matrizes que a função depende, inclusive a matriz que a função está definida, devem estar nesta parte.

O resto das matrizes que não dependem da função podem ser enviadas para qualquer um dos lados, sendo apenas necessário estudar qual lado oferecerá o melhor desempenho, dependendo da otimização a ser feita, em termos de memória ou de tempo.

Caso seja uma matriz identidade que não é parâmetro para a função, esta é melhor tratada na parte estruturada.

Para o caso onde deseja-se aplicar as avaliações na parte estruturada, é necessário apenas que a função permaneça nessa parte, sendo que as outras podem ser posicionadas na parte esparsa.

Novamente, neste caso é interessante reter as matrizes identidades na parte estruturada, pois serão descartadas na aplicação do Algoritmo Shuffle.

Para o seguinte termo tensorial generalizado, composto por cinco autômatos (no caso, cinco matrizes), com diferentes valores para nz ({2, 3, 1, 1, 4}), dimensões ({2, 3, 2, 3, 4}), tipos ({constante, identidade, funcional, elemento, identidade}) tem-se a função f definida no autômato A(3) Os valores possíveis para dividir o termo tensorial variam os pontos de corte de s0,5.

Note-se que aplicando o Algoritmo Split para s0, a abordagem escolhida será o equivalente ao Algoritmo Shuffle e para s5 será o equivalente ao Algoritmo Esparso.

Pode-se escolher avaliar a função f na parte estruturada ou na parte esparsa.

Caso fosse escolhido realizar as avaliações na parte estruturada, o termo tensorial precisaria ser reordenado.

Nesse caso, o conjunto das matrizes que fazem parte da dependência funcional de f é dado por Dep = {A(1),A(5)}.

O corte escolhido para esse caso seria s2, com uma matriz do tipo identidade e uma constante para a parte estruturada e a outra matriz identidade, uma constante e a funcional para a parte esparsa, mantendo a consistência para o termo (conservando as dependências necessárias para que o método Shuffle consiga avaliar apropriadamente f).

No caso das avaliações serem feitas na parte esparsa, a matriz onde a função está definida entra no conjunto de dependências funcionais, obrigatoriamente, sendo este igual aDep = {A(1),A(5),A(3)}.

Para este caso, o ponto de corte s3 foi escolhido e tem-se oito AUNFs (2 × 4 × 1 = 8).

Para essa reconfiguração, pode-se escolher enviar a matriz elemento da parte estruturada para a parte esparsa, sem o aumento do número de AUNFs permanecendo apenas identidades na parte estruturada.

Contudo, não seria possível enviar a identidade de A(5) para a parte estruturada, uma vez que a função não conseguiria ser avaliada pois uma das matrizes que ela depende está em um local não acessível.

Uma alternativa válida, entretanto, com a preocupação de não aumentar o número de AUNFs que são gerados, é enviar a matriz do tipo elemento definida em A(4) para a parte esparsa, deixando apenas identidades na parte estruturada.

Para esse caso, o ponto de corte é igual a s4 e o termo tensorial seria assim reorganizado.

Neste caso, a parte estruturada não terá custo computacional, pois as matrizes que a compõe são todas do tipo identidade.

Uma outra importante constatação é que matrizes do tipo elemento, sempre podem ser enviadas para o lado esparso sem um ônus relativo ao aumento do número de AUNFs necessários.

Caso essamesmamatriz permanecesse na parte estruturada, ainda assimcontribuiria para aumentar os cálculos de deslocamentos à esquerda e à direita, pois o que importa para o Algoritmo Shuffle são em primeiro lugar as dimensões das matrizes e em segundo lugar o total de elementos não-nulos.

Ao eliminar a restrição de permitir que funções na parte estruturada possam acessar elementos da parte esparsa, propõe-se mais uma alternativa de reordenamento onde deixa-se apenas a matriz que contem o elemento funcional f mais as identidades na parte estruturada e as demais matrizes na parte esparsa.

Esse caso é possível, apesar dos parâmetros das dependências funcionais estarem em partes diferentes, pois ao se calcular os AUNFs guardam-se os índices de linha que o originaram.

Cabe ressaltar que o contrário seria impossível (a função f estar na parte esparsa e uma ou as demais na parte estruturada) pois f precisa destes parâmetros que encontram-se na parte estruturada que não estão disponíveis.

Este caso possui a vantagem de não precisar guardar os AUNFs das matrizes identidades e é teoricamente uma das melhores maneiras de reordenar os termos tensoriais.

Como as identidades serão desconsideradas pela parte estruturada e é possível avaliar as funções com sucesso, esta reordem oferece um baixo número de AUNFs necessários, pois a parte esparsa possui uma matriz do tipo elemento.

É importante salientar que não é necessário adotar uma solução puramente esparsa para esse termo tensorial (corte em s5), pois aumentaria o número de AUNFs e seria oneroso, pois o método Shuffle, para esse caso, não será chamado e, consequentemente, menos operações para cálculos de deslocamentos serão feitos (estas análises teóricas serão feitas nas próximas seções).

Igualmente desnecessário é se gastar espaço de memória armazenando-se AUNFs formados a partir da combinação de elementos de matrizes do tipo identidade.

Também verifica-se que o aumento da memória não necessariamente implica em um ganho de desempenho, ainda mais para esse caso, que armazenaria os AUNFs com mesmos valores de escalares e nunca aproveitaria os saltos na estrutura tensorial para melhorar a execução.

Este simples exemplo mostra que é crucial alterar a ordem natural das matrizes do termo tensorial para obter uma melhor organização e otimização, uma vez que essa tarefa interfere diretamente na complexidade de execução do método.

O custo computacional de se usar reordenamentos é baixo e realizado de forma transparente para o usuário.

Pois trata-se fundamentalmente de cálculos dos deslocamentos, ou seja, novos valores para nright, nleft e njump, equivalendo respectivamente aos saltos do subespaço à direita, à esquerda e os saltos na estrutura tensorial de acordo com a dimensão da matriz não-identidade no fator normal, conforme a notação descrita que são feitos apenas na primeira iteração do método e reaproveitados subsequentemente até o final.

Este exemplo demonstrou que devem ser adotadas diferentes estratégias para diferentes termos tensoriais, uma vez que é possível definir pontos de corte personalizados, tendo-se em vista as características dos termos.

Uma vez que o problema foi informalmente estudado com as possibilidades de divisão do termo tensorial, nota-se que um conjunto finito de características afetam o desempenho da solução daMVD.

Este conjunto é dado pelas dimensões das matrizes equivalente aos estados dos autômatos, o total de elementos não-nulos, o total de avaliações de funções que são feitas, e total de matrizes identidades nos termos tensoriais.

Estas características afetam diretamente a complexidade dos métodos escolhidos para multiplicação.

A idéia principal deste capítulo é definir as principais estratégias para dividir um termo tensorial de uma maneira que não onere a memória gasta e que otimize o tempo de solução.

Como explicado anteriormente, esta divisão implicou na obrigatoriedade de reorganização do termo tensorial.

Essa reconfiguração não é custosa em termos computacionais, pois trata-se de cálculos de deslocamentos que são computados na primeira vez e depois apenas consultados na execução dos métodos.

O objetivo então é aplicar a melhor transformação ao termo tensorial e dividi-lo em partes que otimizem o tempo de resposta de modelos.

Para tanto, é necessário estudar os efeitos de cada propriedade dos termos tensoriais para determinar a melhor maneira de se fazer essa operação.

A seguir é realizado um estudo teórico sobre estas propriedades, com o objetivo de deixar claras as escolhas a serem feitas para a solução otimizada de descritores ATC e ATG.

Este estudo permitirá antecipar os desempenhos esperados de cada experiência a ser realizada no Capítulo 7, referente aos resultados obtidos.

Uma vez definidos os compromissos de desempenho do Algoritmo Split e as formas de divisão dos termos tensoriais para otimizar o tempo gasto na solução de modelos baseados em descritores markovianos, a próxima etapa é estudar as implicações teóricas existentes.

Um termo tensorial é composto por uma lista de matrizes de diferentes dimensões, tipos e elementos não-nulos.

Cada matriz contém informação relevante sobre como os autômatos sincronizam atividades, ou seja, como estes interferem uns nos outros.

Essa interferência dita como serão formadas as matrizes, ou seja, apontarão a existência de identidades onde um evento não ocorrer em um autômato e matrizes do tipo elemento, indicando a ocorrência de um evento de acordo com uma determinada taxa de ocorrência.

Cabe ressaltar que a terminologia usada aqui será usada sem perda de generalidade para envolvimento (ou envolver), interferência (ou interferir), afetação (ou afetar) quando disserem respeito aos autômatos.

A seguir, um estudo das implicações de cada tipo de característica existente em termos tensoriais e o que correspondem ao nível do algoritmo que será executado, 1 dimensão de cada matriz, influenciam os subespaços à direita e à esquerda dos fatores normais, ou seja, implicam no número de vezes que o algoritmo é executado por iteração.

Tipo da matriz, uma matriz, como discutido anteriormente, pode ser constante, identidade, elemento ou funcional.

Cada tipo pode otimizar um diferente aspecto, por exemplo, uma matriz funcional pode otimizar o número de avaliações que são feitas, enquanto que matrizes elemento e identidades dizem respeito à memória que será gasta no método para solução e o número de operações de multiplicação.

Permutação do termo, um termo tensorial pode sofrer uma transformação na sua ordem original e ter a sequência das suas matrizes reordenadas para potencializar o método de execução da MVD.

Ponto de corte s, o ponto de corte determina o quanto de memória precisará ser armazenado para efetuar o método.

Este valor deve ser escolhido de forma a maximizar também o tempo de solução.

A seguir é feita uma análise mais aprofundada sobre estas características e seus efeitos na complexidade computacional envolvida, começando-se pelo estudo do efeito das identidades nos termos tensoriais.

O efeito das matrizes do tipo identidade no termo tensorial pode ser comprovado de duas maneiras, em termos constantes e em termos generalizados.

Em termos constantes, as identidades podem fazer parte da seção esparsa do termo, executando o Algoritmo Esparso, ou da seção estruturada, que executará o Algoritmo Shuffle.

Por um lado, como mencionado anteriormente, matrizes do tipo identidade na parte esparsa aumentam o número de AUNFs necessários sem guardar informação relevante.

Se estas matrizes fossem deslocadas para a parte estruturada, levariam à execução de um menor número de multiplicações em ponto flutuante para o cálculo dos deslocamentos que são necessários ao Algoritmo Shuffle.

Isso ocorre porque, ao multiplicar uma matriz por seus fatores normais, se esta for uma identidade, o método não executará nenhuma operação para esse termo, resultando em um ganho considerável em termos de tempo.

Este efeito benéfico é ampliado se a parte estruturada apenas conter matrizes do tipo identidade.

Nesse caso, somente é necessário o tempo inicial gasto para se descobrir os AUNFs de cada termo tensorial e depois só é necessário multiplicar estes em índices pré-calculados de linha e coluna para os vetores de entrada e saída do método para obter o vetor solução intermediário onde é verificada a convergência.

Esse caso, para os termos tensoriais generalizados, implica que os elementos funcionais foram avaliados na parte esparsa, este termo não precisa mais ser considerado um termo generalizado, sendo a partir desse momento um termo constante, sem haver a necessidade de outras avaliações de função.

Ao não precisar mais avaliar funções na parte estruturada, descarta-se toda a complexidade envolvida para realizar esta operação.

Com isso, o termo generalizado é convertido para um termo constante, em tempo de execução, pois os as estruturas de dados auxiliares para armazenamento dos AUNFs contém os valores das funções já avaliadas.

Caso o número de AUNFs existentes não inutilizem a execução do Algoritmo Split (passando-se dos limites disponíveis de memória, por exemplo), esta é teoricamente a melhor solução disponível em termos de número de operações em ponto flutuante de multiplicações.

O real ganho do efeito das identidades nos termos tensoriais pode ser avaliado de duas formas, com permutação das matrizes do termo ou sem permutar e utilizar algum critério pré-definido de escolha do ponto de corte s.

Este último caso retira da complexidade as operações de permutação envolvidas.

Entretanto, como estas permutações são na verdade pré-cálculos de deslocamentos na estrutura tensorial, realizados apenas uma vez no início do método, são negligenciáveis do ponto de vista da aplicação.

Logo, esta maneira resulta em uma otimização possível das reordens das matrizes identidades tanto para termos constantes quanto termos generalizados.

A existência de matrizes do tipo identidade está fortemente relacionada ao termo tensorial informando os autômatos que um dado evento interfere.

Dado um evento sincronizante e, se este está sincronizando uma atividade com todos os autômatos em uma determinada transição, este termo não será composto por nenhuma identidade e diversas matrizes do tipo elemento.

A abordagem flexível proposta pelo Algoritmo Split auxilia na escolha de opções interessantes para o ponto de corte s, baseadas na memória disponível.

Ao verificar um modelo observando os seus eventos sincronizantes e funções é possível antecipar, de maneira teórica, uma boa forma de tratar com os termos tensoriais.

A seguir, analisa-se a influência das funções nos termos tensoriais.

Para o caso onde as identidades serão tratadas na parte estruturada, todos os cálculos necessários são desconsiderados.

O algoritmo somente calcula os AUNFs necessários, monta um vetor de tamanho nrightcut com posições vindas dos índices de entrada de cada AUNF e após multiplicar o escalar |AUNF| vezes, salva no vetor de acordo com os índices precalculados e armazenados pelas posições de saída.

Portanto, ao realizar somente estas operações, a complexidade em termos de multiplicações em ponto flutuante, caso garanta-se que somente existam identidades na parte estruturada.

Esta equação para complexidade é diferente da equação correspondente à versão original do Split, sem considerar que permutações possam ser usadas para o benefício crucial do método.

Esta equação mostra os cálculos necessários para a parte esparsa e a parte estruturada.

A parte nzi corresponde ao cálculo dos AUNFs e a parte ni equivale ao tratamento da parte estruturada a partir de blocos de tamanho nright, ou seja, o produtório das dimensões de todas as matrizes (ni), computadas de s +1 até N.

A parte final corresponde à chamada do Algoritmo Shuffle tradicional.

Estas equações de complexidade claramente demonstram o ganho do Split sobre o Shuffle quando a parte estruturada possui apenas matrizes do tipo identidade.

A avaliação de funções é uma operação que depende de muitos fatores em um modelo SAN.

Este custo depende de três características, os argumentos da função.

Estes valores são calculados e utilizam como entrada um índice global do espaço de estados do sistema.

A avaliação da função propriamente dita.

Uma vez que se conhece os argumentos, a função pode ser avaliada, retornando o valor da avaliação.

O número de avaliações que são feitas.

Esse valor é dependente do bloco correspondente ao subespaço da esquerda do método.

O método para avaliação de funções é chamada inúmeras vezes.

O método trata as matrizes de acordo com uma ordem de permutação e converte os seus elementos funcionais em elementos constantes.

Ao dividir o termo tensorial de forma que as funções sejamavaliadas na parte estruturada, aumentase o número de operações que são feitas, uma vez que as avaliações necessárias são feitas em cada iteração e sempre resultam no mesmo conjunto de valores.

O oposto desta escolha é se fazer dividir o termo tensorial passando todas as matrizes dependentes e a matriz que contém o elemento funcional para a parte esparsa e chamar o método de avaliação de função uma vez no início da solução, guardando os AUNFs já convertidos para escalares não-nulos constantes.

Ao se fazer isso, os termos tensoriais generalizados são convertidos para termos constantes e não existem mais avaliações de função como existia anteriormente e o método deve rodar mais rapidamente.

Existem duas maneiras de se efetuar as avaliações de funções, na parte esparsa ou na parte estruturada.

A seguir, analisam-se ambos os casos, iniciando pelo caso da avaliação na parte esparsa.

O pior caso é definido quando a função depende de matrizes do tipo identidade.

A única restrição do Algoritmo Split é ter que possuir todas as matrizes que a função depende na parte esparsa, pois o método não acessa a parte estruturada.

Ter identidades na parte esparsa implica que muitos AUNFs serão potencialmente criados sem necessidade, pois os escalares que compõem o AUNF não são alterados quando multiplicados pelos elementos das matrizes identidade.

Já na parte estruturada, duas opções são possíveis, manter a lista de matrizes dependentes (essa lista é criada a partir dos parâmetros da função) nessa parte ou então enviá-las para a parte esparsa que calculará os AUNFs necessários.

Mantendo a lista de matrizes que dependem da função em questão na parte estruturada resulta que possivelmentematrizes identidade estejam na parte esparsa, o que não é produtivo, visto que geram AUNFs com escalar igual a um (devendo ser evitado manter identidades na parte esparsa).

Também pode-se deixar apenas a matriz que a função está definida e deixar apenas as identidades na parte estruturada.

Essa abordagem melhora o desempenho do Algoritmo Split, pois é similar ao caso constante onde as identidades estão na parte estruturada.

Existem inúmeras formas de se permutar um termo tensorial t composto por matrizes de diversos tipos e esparsidades, sem replicação.

O ideal é se descobrir o melhor jeito de reorganizar o termo tensorial para que ele utilize o melhor método em ambos os lados da divisão minimizando o tempo que será gasto para resolver o modelo.

Para permutar um termo tensorial e obter uma ordem de posicionamento ideal existe um custo computacional, para calcular os índices referentes aos deslocamentos necessários que serão utilizados posteriormente no método para que ele salte na estrutura tensorial.

Esse reposicionamento faz com que o método seja executado como anteriormente, mas acessando os elementos a estrutura de outra forma, no caso, permutada.

Esses custos de recálculos de índices são negligenciáveis, pois são calculados apenas uma vez e utilizados sempre em cada iteração.

Trata-se de saltos e novos valores para tanto os subespaços à esquerda quanto aos da direita do método.

O problema da reordenação é realmente descobrir um novo posicionamento que seja ideal e, quando combinado ao ponto de corte, auxiliará para diminuir o tempo requerido para solucionar um modelo e retornar o vetor de probabilidade estacionário final.

Cabe lembrar que cada termo tensorial pode ser reorganizado de uma maneira diferente, devido principalmente aos elementos que o compõem.

Este reposicionamento pode levar em consideração onde será executado o Algoritmo Split, o quanto existe de memória disponível no sistema, a esparsidade do termo tensorial, o número de identidades e o número de matrizes que serão vistas como os argumentos da função para termos generalizados.

Dependendo do que maximizar ou minimizar, uma nova ordem deve ser produzida.

Se as avaliações devem ser reduzidas a um extremo, o termo deverá ser recomposto para que estas sejam enviadas para a parte estruturada ou esparsa.

Foi igualmente constatado que os argumentos dos elementos funcionais são melhores executados na parte estruturada pois existem otimizações implementadas para este propósito específico.

Mostra um comparativo das complexidades de cada escolha de divisão do termo tensorial para o Algoritmo Shuffle e para o Algoritmo Split.

No caso do Shuffle, tem-se a complexidade do método e a otimização das identidades, que somente caso a matriz não seja uma identidade, o bloco é executado.

Para a complexidade do Split, tem-se outras possibilidades, tais como execução do método avaliando-se funções na parte esparsa e na parte estruturada e seu efeito direto no número de multiplicações em ponto flutuante que são requeridas.

Nota-se claramente que o melhor custo computacional teórico foi obtido quando, independente do termo ser constante ou generalizado, as avaliações são feitas apenas uma vez, permutando-se as matrizes identidades para a parte estruturada, caso a memória disponível permita.

Nesse caso, as multiplicações necessárias são apenas as que dizem respeito ao cálculo dos AUNFs, deixando toda a parte estruturada sem ser executada, pois as matrizes restantes são identidades.

Sendo identidades, os fatores normais serão todos identidades, isto é, são descartados.

Observa-se ainda que o grau de dependência, ou seja, o GDC e o GDG constituem-se em uma importante métrica para descobrir as características dos termos tensoriais observando-se apenas os eventos sincronizantes e as funções existentes na rede de autômatos.

Estes graus afetam diretamente no tempo de execução, pois estão relacionados a questões númericas de eficiência, devido ao número de multiplicações exigido e aos saltos que são dados quando as matrizes são do tipo identidade.

O que realmente ocorre quando avalia-se as funções apenas uma vez, reordena-se o termo tensorial e deixa-se todas as identidades para a parte estruturada é que foi encontrada uma nova forma de perceber o termo tensorial e considerá-lo esparso, ou seja, de execução extremamente rápida, sem precisar chamar as operações da parte estruturada e gastando uma memória razoável.

Para tanto, deve-se considerar o papel que os eventos possuem nos descritores markovianos.

São os eventos dos termos tensoriais que ditam como o Algoritmo Split irá se comportar na sua execução.

Eventos que dependem de muitos autômatos para fazer a transição ditarão o tamanho dessa nova matriz esparsa que é implicitamente construída.

Uma vez que a análise teórica mostrou que são executadas menos operações de multiplicações em ponto-flutuante para alguns casos, a próxima etapa é validá-la através da definição e execução de casos de teste e experimentações.

Estas experimentações serão descritas no próximo capítulo.

Este capítulo descreve a ferramenta GTAexpress cujo objetivo é trabalhar genericamente com descritores tensoriais, fornecendo os mecanismos para tratar com a sua definição e solução.

Uma das suas vantagens é a possibilidade de testar a convergência de sistemas com características específicas, normalmente decompostos sob a forma de partições, componentes, módulos, processos, autômatos ou qualquer outra divisão abstrata de um sistema com interações complexas.

A GTAexpress implementa o Algoritmo Split e permite configurar as estratégias para dividir termos tensoriais de descritores Kronecker.

Este algoritmo configura a escolha de métodos iterativos de solução como, por exemplo, o Método da Potência, para resolver descritores markovianos válidos, ou seja, que correspondem a geradores infinitesimais de Cadeias deMarkov.

A principal ideia da ferramenta é trabalhar genericamente com tais estruturas tensoriais, permitindo que outros formalismos estruturados usem suas funcionalidades, dado que possuem características de decomposição e interação entre suas subpartes.

Quanto à modelagem, a GTAexpress facilita a descrição de sistemas, pois a única tarefa dos modeladores é abstrair o seu problema pensando apenas nas divisões existentes ou compartimentos e na sua interação ou formas de comunicação.

Estas primitivas possibilitam a construção de descritores Kronecker para serem usados na ferramenta objetivando a extração e análise dos índices de desempenho bem como as previsões de comportamento.

Internamente, dadas estas características definidas pelos usuários, o sistema define o nível de interação entre os componentes e assim encontra a melhor estratégia para o Algoritmo Split ser executado ao dividir os termos tensoriais de forma a minimizar a memória gasta e o tempo por iteração necessário.

A implementação da GTAexpress foi concebida no ambiente de desenvolvimento do PEPS, trabalhando com análise, permutação e divisão dos termos tensorias em duas partes distintas, denominadas parte esparsa e estruturada.

O Algoritmo Split foi estendido para tratamento de taxas funcionais e suporte a permutações de matrizes como uma estratégia para melhorar o desempenho do método de MVD.

Este Capítulo está organizado da seguinte forma, inicialmente, será explicada a motivação e os detalhes pertinentes da ferramenta, seguido de explicações da formação de descritores Kronecker.

Serão explicados como modelos advindos de diferentes formalismos estruturados podem ser definidos através de descritores markovianos para, exemplificar como usar a GTAexpress, alterando as configurações propostas.

O capítulo encerra-se que trata sobre as considerações finais.

A ferramenta GTAexpress foi construída para solucionar descritores Kronecker usando o Algoritmo Split, que trabalha com a divisão de cada termo tensorial, correspondendo a um evento na realidade descrita, em duas partes distintas, uma parte esparsa e uma parte estruturada.

Esta abordagem híbrida reune as vantagens dos algoritmos Esparso e Shuffle, respectivamente, em uma única proposição.

Ao separar os termos tensoriais, aproveita-se o fato que os eventos que compõem o sistema normalmente não envolvem ou não interferem em todas ou na maioria das entidades, módulos ou componentes.

Ao afetar, ou sincronizar, apenas alguns módulos propicia-se a criação de inúmerasmatrizes do tipo identidade no termo tensorial, fato que o Algoritmo Split maximiza para tratar o termo da forma mais otimizada possível, permutando-o e dinamicamente encontrando blocos esparsos, de forma implícita, e blocos que não interferem entre si (ou seja, são blocos contendo matrizes do tipo identidade) na matriz de transição.

A principal vantagem de se trabalhar com descritores Kronecker é nunca precisar alocar a matriz de transição que descreve tanto a evolução do sistema quanto a mudança entre os estados.

Esta matriz é extremamente onerosa de armazenar em memória e corresponde ao principal motivo para uso de formatos tensoriais que gerem essa matriz de forma implícita, ou seja, através da utilização das propriedades conhecidas da Álgebra Tensorial.

O uso de descritores tensoriais existe desde as definições iniciais de Redes de Autômatos Estocásticos (SAN), entretanto outros formalismos estruturados também usaram as primitivas conhecidas para descrever seus formatos internos.

Exemplos de tais formalismos, além de SAN, são as Redes de Petri Estocásticas Generalizadas Superpostas (e frameworks para decomposição de Redes de Petri Generalizadas para Redes de Autômatos Escocásticos), PEPA e Redes de Filas também são conhecidas na literatura em Avaliação de Desempenho.

As ferramentas que tratam destes formatos são igualmente conhecidas e exemplos são PEPS (para SAN), SMART (para Redes de Petri) ou PEPA Eclipse-Plugin (para PEPA).

Uma desvantagem conhecida destas traduções é devida ao fato de que os formalismos trabalham com formatos tensoriais específicos para cada descrição, ou seja, não são genéricos o suficiente para que sejam transpostos entre si.

A ideia básica da GTAexpress é preencher esta lacuna ao auxiliar os modeladores a definir seus sistemas de forma que possam ser transcritos sob formas tensoriais e, posteriormente, ajudando a analisar e extrair índices quantitativos de desempenho ou sobre a operabilidade do sistema.

Cabe ressaltar que o principal destaque da GTAexpress ao ser comparado com as outras ferramentas é tratar com descritores clássicos e generalizados de forma otimizada.

Sabe-se que o uso de taxas funcionais aumenta o poder de representação de um formalismo estruturado ao mesmo tempo que simplifica o número de termos tensoriais necessários, implicando diretamente no tempo envolvido para a solução.

Por exemplo, sabe-se que a ferramenta SMART só trabalha com Álgebra Tensorial Clássica e que a ferramenta PEPA Eclipse Plug-in não realiza a multiplicação vetor-descritor, existindo uma definição teórica sobre uma forma de se traduzir modelos de PEPA para descritores Kronecker.

A principal diferença entre a ferramenta PEPS e a GTAexpress é devida ao fato que a primeira não implementa o Algoritmo Split, tampouco oferece mecanismos para divisão dos termos tensoriais.

A implementação da ferramenta GTAexpress é baseada na codificação de dois eixos principais, definir a criação de descritores tensoriais válidos para a extração de índices de desempenho de sistemas propondo um formato padrão simples de usar e b executar os algoritmos de MVD (para ATC e ATG) usando o Algoritmo Split com estratégias de divisão de cada termo tensorial de forma transparente aos usuários.

O formato proposto pela GTAexpress está baseado na linguagem Extensible Markup Language (ou XML), já usada em Redes de Petri, através da Petri Net Markup Language (ou PNML).

Os modeladores dos sistemas devem se preocupar apenas em como compor um sistema (usando módulos, autômatos, ou qualquer outro nome para decomposição) e informar seus comportamentos, de forma individual ou sincronizada entre os demais módulos ou componentes.

Estas primitivas simples serão usadas para a construção do descritor markoviano.

Como o objetivo é generalizar ao máximo a descrição que corresponde ao funcionamento de um sistema, serão utilizados ao longo do capítulo uma nomenclatura padrão como, por exemplo, rótulos para decomposição de sistemas.

Serão utilizados os seguintes nomes, módulos, partições, componentes, autômatos ou processos para corresponder as formas existentes de descrever um sistema através de partes distintas e indivisíveis, capturando os comportamentos independentes e dependentes entre si.

A seguir é mostrado como se construir descritores Kronecker para posterior execução na ferramenta GTAexpress.

Esta seção mostrará a composição de descritores Kronecker e seus principais elementos dentro da GTAexpress.

Inicialmente serão descritas as partes que formam um descritor.

Todo modelo estruturado é composto por um número N de módulos, componentes, processos, autômatos ou qualquer outra nomenclatura a ser utilizada para decompor um sistema em partes1 (similar à utilização de métodos do tipo divisão-e-conquista).

Genericamente, cada módulo n possui estados locais s j onde j = S.

Cada estado s j apresenta uma ou mais transições para outros estados, de acordo com uma taxa de ocorrência associada.

Uma transição possui uma lista de eventos que ocorrem de forma independente (L eventos locais) ou sincronizada com outros módulos (E eventos).

Ao utilizar o mesmo nome de evento em uma transição em outra transição de outro módulo esta transição será internamente classificada como sendo do tipo sincronizante, caso contrário, será do tipo local (parcial ou total, explicado a seguir).

O espaço de estados de um modelo estruturado é composto pelo produto cartesiano de todos os estados locais de todos os módulos, formando o Produto do Espaço de Estados (PSS).

As transições entre os estados dos módulos ocorrem de três formas distintas.

Transições completamente locais tratam-se de transições que ocorrem em um componente e não são afetadas nem afetam outros módulos.

Transições parcialmente locais são transições que ocorrem em um módulo de acordo com o estado de outros módulos, entretanto afeta a mudança de estado de apenas um único componente.

Transições sincronizantes, este tipo de transição afeta o estado local de dois ou mais componentes, potencialmente todos os módulos de um determinado modelo (dependendo do que o evento está representando no sistema).

As transições dentro de cada módulo são representadas por matrizes da ordem do número de estados e seus elementos internos são as taxas de ocorrência, afetadas ou não através do uso de diretivas funcionais.

Por exemplo, pode-se usar uma taxa funcional, que observa o estado de outro módulo, para definir (configurando um teste que retorna um valor lógico diferente de falso, ou seja, uma taxa maior que zero) ou não (valor lógico igual a falso, ou seja, zero) uma transição entre estados.

Um descritor Kronecker é composto por somas de produtos tensoriais composto por N matrizes cada.

O descritor é formado por matrizes com as taxas dos eventos locais (completa ou parcialmente) e por matrizes para representar os eventos sincronizantes, sendo necessárias operações de somas tensoriais e produtos tensoriais entre estas matrizes de transição, respectivamente.

Como a operação da soma tensorial é vista como produtos tensoriais com identidades (ou seja, são gerados fatores normais), um descritor é de fato somas de produtos tensoriais, e o total destas somas equivale a quantidade de eventos (locais ou sincronizantes) existentes no modelo.

Mostra as divisões existentes em um descritor, divididas entre locais e sincronizantes, com parte positiva e a adequação da sua parte negativa (com a finalidade desta representação formar um gerador infinitesimal onde a soma das linhas é igual a zero).

Mostra produtos e somas tensoriais generalizadas, ou seja, pressupõe que taxas funcionais estão sendo utilizadas.

Na parte de cima N matrizes Q que representam as transições que afetam apenas um dos N elementos, a parte local.

Cada uma destas matrizes é composta por um conjunto de N1 matrizes do tipo identidade que representam que outros componentes não são afetados pela ocorrência das transições locais.

São mostradas 2E conjuntos de N matrizes Q que representam E transições com sincronizações entre elementos, a parte sincronizante do descritor.

Cabe ressaltar que cada transição sincronizante ek necessita dois conjuntos de matrizes, o primeiro contendo sua ocorrência propriamente dita e o segundo representando o ajuste da sua diagonal, como mencionado anteriormente.

Dependendo do evento a ser observado, dependendo de quantos outros módulos este afeta, tem-se matrizes do tipo identidade para representar o fato que o módulo não altera o seu estado local com este dado evento.

Este fato é crucial para o desempenho de algoritmos mais otimizados, como o Split, que aproveita este fato para acelerar o processo de MVD.

A seguir, são mostradas as regras para criação e definição de descritores válidos a serem usados pela ferramenta GTAexpress.

Como exemplificado ao longo deste capítulo, o uso de descritores Kronecker é incentivado devido principalmente aos ganhos de memória ao se armazenar pequenas matrizes com operações algébricas tensoriais entre si ao invés de salvar um gerador infinitesimal completo.

Esta vantagem fez com que outros formalismos definissem seus próprios formatos.

Entretanto, observando as etapas em comum entre as definições usadas para PN, PEPA, SAN e Redes de Filas, nota-se que existe um conjunto específico de generalidades, descrito a seguir.

Abstrair e observar a operação de uma realidade ou sistema, descobrir o que deseja-se representar, inferir ou descobrir sobre o seu funcionamento.

Identificar como decompor o sistema em subpartes menores e mais tratáveis, em componentes ou módulos com comportamentos individuais e interações.

Identificar suas operações internas e as interações observadas entre as partes que o compõe.

Determinar as interações que acontecem de forma independente e dependente.

Descobrir e definir os estados internos, dentro de cada subparte observada.

Identificar as transições entre os estados e classifica-las quanto à sua dependência (dependem que outras partes estejam em algum estado ou não), para parametrização do modelo, determinar a frequência de troca de estado do processo markoviano, para definição de uma CTMC.

Usar um formato descritivo para representar estas estruturas em um modelo válido.

Usar uma ferramenta que transforme este formato descritivo baseado em módulos, elementos, processos, autômatos, etc, em umdescritor válido que represente em última análise as transições entre estados do sistema e suas taxas de ocorrência.

Identificar os índices de desempenho que deseja-se estudar e extrair do sistema.

Descobrir as análises quantitativas que deseja-se inferir sobre o funcionamento ou comportamento do sistema em regime estacionário ou transiente.

Usar a ferramenta GTAexpress para usar mecanismos especializados de MVD para resolver o sistema e determinar as probabilidades de permanência nos estados do mesmo.

De acordo com os resultados, retornar à fase de concepção e refinar o modelo, retirando estados, transições ou adicionando outros mecanismos de interação para capturar seu funcionamento de acordo com novas características.

Essas etapas podem ser utilizadas para definir descritores Kronecker em geral e também podem ser usadas, sem perda de generalidade, para descrição de diversas outras realidades ou traduções de outros formalismos estruturados que forneçam representação tensorial.

Estas regras nada mais representam que a construção de descritores generalizados Kronecker para inferência de índices de desempenho, confiabilidade ou outras medidas quantitativas.

Todos os problemas que forem decompostos observando-se as etapas definidas acima serão passíveis de serem executados na ferramenta GTAexpress.

A próxima seção descreve a arquitetura da ferramenta e os formatos de entrada e saída disponíveis.

A ferramenta GTAexpress foi concebida de acordo com as seguintes ideias.

Um modelo estruturado pode ser decomposto de forma genérica e transposto para um formato que representa um descritor Kronecker.

Métodos específicos de MVD são usados para resolver um modelo computacionalmente calculando os índices de desempenho a serem utilizados na fase de análise.

Dado que outros formalismos definem formatos tensoriais válidos, existe um mapeamento direto para um descritor, de acordo com um esforço de tradução que pode ser manual ou automática.

A lacuna existente atualmente corresponde a falta de regras para efetuar esse mapeamento de forma automática e possibilitar a modelagem genérica de sistemas reais baseando-se em álgebra tensorial.

Antes de descrever os formatos de entrada e de execução da ferramenta, são necessárias explicações de detalhes pertinentes de implementação no ambiente PEPS.

Para o Algoritmo Split (com versão estendida para ATG) foi criado um novo método na classe que implementa a MVD clássica, ou seja, o Algoritmo Shuffle.

Para guardar os AUNFs necessários para cada modelo, é criado, antes da execução e compilação, uma lista de eventos por lista de AUNFs.

O tempo gasto e a memória extra usada para efetuar essa tarefa é salvo internamente para efeitos de estatísticas sobre a execução do sistema como um todo.

Foram implementados também novos métodos para permutar as ordens originais de cada termo tensorial que define a lista de módulos, movendo os índices de matrizes que correspondem a identidades para a esquerda ou para a direita, de acordo com a estratégia utilizada, entre outros.

Por fim, foram alteradas as opções da interface para representar as opções de chamada do novo método de MVD e na opção que mostra as estatísticas da execução da ferramenta.

A seguir serão explicados o funcionamento do formato de entrada, compilação, execução e formato de saída da GTAexpress.

Como mencionado anteriormente, foi escolhido um formato padrão, já utilizado em outros formalismos para descrição dos seus elementos, baseado na linguagem XML.

O arquivo definido em XML é composto pelas seguintes partes (para aumentar a adoção da descrição por outros pesquisadores, o formato encontra-se atualmente definido na língua inglesa).

Properties são as propriedades do sistema e outras informações que o resolvedor irá utilizar para multiplicar o vetor pelo descritor ou testar a convergência.

Exemplos desta parte do arquivo são descrição do nome do modelo e sua operação.
Informações sobre o autor e quando foi concebido (para propósitos de histórico), tolerância do erro para teste de convergência, método iterativo a ser usado (Potência, GMRES, Arnoldi, etc).
Tipo de análise (transiente ou estacionária), escala de tempo (contínua ou discreta) ou modo de depuração de mensagens de texto (verbose), Gcc-code, esta parte corresponde a funções descritas na linguagem de programação C/C++ que serão adicionadas ao executável da ferramenta GTAexpress em tempo de execução.

Este bloco é um mapeamento para uma taxa constante ou funcional definida no bloco rates.

A vantagem de se descrever funções desta maneira é o de permitir que sejam calculadas taxas de forma complexa, tendo a linguagem C/C++ como base.

Modules, define a forma que o sistema foi definido.

Denominamos de módulos, mas correspondem a autômatos, processos, partições ou outra definição composicional.

No arquivo XML é possível definir uma lista de módulos, contendo diversos blocos do tipo states.

States são os estados que o módulo define e possuem dois blocos internos, bloco graphics contendo informações visuais (onde desenhar cada estado) e uma lista de transitions para outros estados de acordo com uma lista de taxas (rates).

Graphics, informações visuais contendo o tipo da fonte, a cor do estado e o seu posicionamento na tela, usado para representação visual do sistema.

Transitions, compreende o conjunto de transições do módulo em questão.

Rates, correspondem as taxas observadas para a transição.

Results, seção que realiza a extração dos índices de desempenho, igualmente definidas na linguagem de programação C/C++.

Operam sobre o espaço de estados para retornar as probabilidades de permanência em cada estado.

A seguir, mostra-se um exemplo do arquivo XML para um sistema de teste com a definição de duas impressoras (cada módulo corresponde a uma impressora).

Observa-se que para um modelo descrito em XML estar sintaticamente correto, existem bibliotecas que validam o arquivo a partir de um esquema (XML Schema Definition, ou XSD) predefinido.

Uma aparente vantagemde se usar XML para descrever um sistema é a possibilidade de validar o arquivo quanto à sua verificação sintática, restando apenas a parte da verificação semântica, caso a utilização das transições e eventos fazem sentido no contexto da descrição, facilitando a implementação de compiladores específicos.

Cabe ressaltar que a parte de verificação semântica descobre se os módulos possuem transições válidas e se estas estão definidas nos módulos, bem como a descoberta de transições que estão definidas ou não em outros módulos, correspondendo aos eventos locais ou sincronizantes.

A estrutura em árvore do XML facilita a definição não-ambígua de um sistema, informando os blocos com definição mandatória ou opcional.

A ferramenta GTAexpress recebe um descritor (nesta etapa, aproveita-se o fato de que SAN produz um descritor Kronecker) e, estando implementado no ambiente PEPS, recebe como entrada um arquivo com terminação san.

A GTAexpress permite análise transiente ou estacionária para escala de tempo contínua, com métodos iterativos de solução tais como o Método da Potência, Arnoldi, GMRES e o Método da Uniformização.

Para usar o Algoritmo Split é necessário informar esta necessidade ao compilador da ferramenta que tratará de criar as estruturas necessárias para este fim (criação da lista de escalares, ou AUNFs para cada evento definido nos módulos do sistema), as permutações necessárias e os valores de corte entre a parte esparsa e a parte estruturada.

Caso o modelo seja definido com primitivas de taxas funcionais, o compilador trata de deslocar os parâmetros do evento com taxa funcional para manter a integridade da função e esta retornar de forma válida para o método.

Demonstra-se a seguir cinco passos (de I a V) necessários para a configuração, compilação e execução da ferramenta GTAexpress.

Rodar a ferramenta e a partir da tela principal.

Escolher uma das seguintes -estratégias- para divisão dos termos tensoriais.

Escolher as opções usuais de compilação do modelo.

Escolher a opção de Solução do modelo em questão e executar.

Inspecionar o arquivo de saída definido em <MODELO>.

As etapas III e IV correspondem as formas usuais de compilação e solução existentes para SAN, a única diferença encontra-se nas etapas I e II onde escolhe-se rodar a proposta Split de acordo com uma determinada estratégia (de A a E).

Uma vez que o modelo foi executado, os índices de desempenho encontram-se no arquivo com terminação tim, na mesma pasta com o executável da ferramenta GTAexpress.

A parte de resultados mostra as permutações que foram realizadas, informações sobre o corte e sobre o número de AUNFs (memória gasta) para a execução do método, tempo para geração desta lista, número de iterações até a convergência.

São igualmente mostradas as tradicionais informações sobre a execução, tais como número de eventos, tipos de eventos, tempo médio por iteração e método iterativo utilizado.

A seção de Results do arquivo de saída mostra as probabilidades de permanência no estado, escolhidos pelo modelador, ou seja, dependendo do que deseja-se analisar.

Os primórdios da definição de SAN já trataram de decompor um sistema através de módulos, os quais foram chamados de autômatos.

As interações entre os autômatos foram descritas através de transições entre estados de autômatos, definindo taxas constantes e funcionais.

A proposta da ferramenta GTAexpress é a de definir uma nova abstração para a composição de sistemas para inferência de índices de desempenho para interpretação dos modeladores.

Através da execução do Algoritmo Split, que permuta e divide os termos tensoriais para tirar proveito das identidades (ou seja, da interferência entre os elementos de um sistema) e executar cada iteração de forma mais rápida, dependendo do nível de interferência existente para cada modelo.

Existe uma necessidade da comunidade de avaliação de desempenho para além de aumentar o poder de descrição dos sistemas usando primitivas simples e poderosas, também possuir mecanismos igualmente eficientes para resolver um determinado modelo e possibilitar a redução do tempo por iteração para a análise estacionária ou transiente, por conseguinte, reduzindo o tempo total necessário.

A ferramenta GTAexpress tornou isso possível para classes demodelos que possuemumbaixo grau de interferência entre os elementos que compõem um sistema.

O fato de permitir que modelos definidos com taxas constantes e funcionais permitiu que o poder de representação ficasse inalterado mas que em termos de solução executasse mais rapidamente.

Cabe ressaltar que cada formalismo estruturado possui um conjunto próprio de definição e solução e muitas vezes são fortes em uma ou outra característica.

O fato de nunca precisar gerar a matriz de transição atrai muitos pesquisadores para definir formatos tensoriais para seus formalismos, entretanto, como mencionado ao longo deste capítulo, não implementam primitivas importantes de modelagem, tais como definições de taxas funcionais.

O objetivo da proposta de uma descrição genérica ou formato de entrada para a ferramenta GTAexpress é o de prover mecanismos que permitam que modeladores pensem seus sistemas de forma estruturada e que usem o software para executar de forma eficaz qualquer descrição baseada em descritores Kronecker.

O capítulo mostrou um formato padrão na linguagem XML, objetivando traduções e transposições entre diferentes formalismos estruturados.

Este capítulo abordará os resultados numéricos obtidos para um conjunto fixo de experimentos, fundamentados sobre as proposições abordadas pela análise teórica feitas no capítulo anterior.

São definidos os experimentos e as considerações iniciais.

Cada modelo é apresentado e explicado seguido dos seus resultados, comparando-se os experimentos e verificando-se os ganhos obtidos a cada comparação.

O capítulo é finalizado com questionamentos e discussões sobre os resultados obtidos.

O objetivo da definição dos experimentos conduzidos neste capítulo é testar os efeitos das diversas características dos termos tensoriais e verificar, em um ambiente real de teste e desenvolvimento, o desempenho comparando-se com as abordagens MVD vigentes.

Deseja-se descobrir quais experimentos obtiveram os melhores tempos para uma iteração com o método de MVD, comparando-os com as abordagens para a mesma classe de modelos com descritores constantes (ou generalizados) e com (ou sem) permutações das ordens originais.

Foram escolhidos nove experimentos para execução dos modelos disponíveis que mostra as principais diferenças entre cada um.

A base de comparação é o método atual de solução baseado no Algoritmo Shuffle (executado nos Experimentos 2, 4 e 9).

As experiências foram executadas variando-se as possibilidades julgadas mais interessantes, como avaliação de funções e alteração das posições das matrizes identidades dentro de cada termo tensorial.

Para avaliar-se o custo envolvido na permutação dos elementos dentro do termo tensorial, foram criados os Experimentos 2, 4 e 1, 3 para respectivamente o Algoritmo Shuffle e o Algoritmo Split.

Para o caso do Experimento 3, o ponto de corte escolhido é na última matriz constante do termo tensorial.

O Experimento 8 calcula a implicação do custo das avaliações de funções, pois deixa apenas a matriz que contém o elemento funcional e as identidades na parte estruturada, utilizando somente as matrizes constantes na parte esparsa.

Os experimentos foram escolhidos devido à análise teórica conduzida.

Os estudos efetuados indicaram a necessidade de se testar os diferentes métodos de MVD permutando-se o termo tensorial e dividindo-o de acordo com as suas dependências funcionais e outras características, tais como tipos de matrizes (identidades, entre outras) e esparsidade.

Os exemplos aqui descritos possuem eventos sincronizantes com taxas funcionais para o caso generalizado onde também foram devidamente convertidos para o seu modelo equivalente constante.

O objetivo desta conversão é o de verificar em quais casos é satisfatório traduzir descritores baseados em ATG para ATC, apesar do aumento do número de eventos no termo tensorial.

A execução dos experimentos foi realizada em uma arquitetura Pentium 3,2 GHz com 4 Gb de memória RAM.

A ferramenta PEPS foi utilizada como base onde implementou-se o Algoritmo Split para descritores constantes e generalizados em uma nova ferramenta chamada GTAexpress.

A parte para armazenamento e geração dos AUNFs e outras estruturas de dados auxiliares foram igualmente codificadas com o compilador C/C++ (g++) com opções de otimização (O3) e linking dinâmico para as funções dos descritores generalizados.

Estão sendo comparados o Algoritmo Split com o Algoritmo Shuffle com permutações para os Experimentos 1, 2, 5, 6, 7, 8 e 9 e sem reordenamentos para os casos 3 e 4.

Foram computados os tempos com intervalos de confiança de 95% para 50 execuções sequenciais com 25 iterações cada (para o valor do tempo coletado foi calculado o tempo médio de execução do método considerando-se este número de iterações).

Serão apresentadas os resultados obtidos para os diversos modelos.

Estas tabelas de resultados mostram o nome do modelo em questão (campo Modelo), o seu PSS e uma divisão entre as informações relativas aos AUNFs, informações relativas ao tempo de execução (em Tempos) e ganhos comparando-se sempre dois experimentos (no caso, o ganho será calculado da seguinte maneira, a última coluna dividida pela anterior).

Na parte relativa aos AUNFs, tem-se o seu total necessário para o experimento em questão (sempre será rodado um experimento para o Algoritmo Split e outro experimento para o Algoritmo Shuffle), a sua memória (no campo Mem), descrita em Kilobytes (Kb) e o tempo necessário para computar a tabela com os AUNFs, realizado apenas uma vez em todo o método de solução, na coluna Cálculo.

O tempo dos experimentos são mostrados nas colunas correspondentes, medidos em segundos (s), mostrados na tabela com o seu intervalo de confiança de 95% correspondendo à média de uma iteração do método da potência (Power Method) fornecido pela ferramenta no arquivo de saída de dados.

Cabe ressaltar que os modelos variam o número de autômatos que os compõem, de forma incremental.

Em casos específicos, como os modelos de Redes de Sensores e Mestre-Escravo, a definição original do descritor generalizado foi convertido explicitamente para o seu equivalente constante em termos de solução numérica.

Todos os testes foram executados para uma lista de modelos (alguns tradicionais, como Compartilhamento de Recursos (Resource Sharing) e outros oriundos de pesquisas atuais com arquitetura Mestre-Escravo (Master-Slave) ou Redes de Sensores (Wireless Sensors).

A existência de benchmarks para testes ainda é insuficiente em análise numérica de sistemas de avaliação de desempenho.

Em cada subseção comparam as diferentes estratégias de divisão dos termos tensoriais.

Os demais modelos que compreendem essa seção definem o problema dos Filósofos, First Available Server, Alternate Service Patterns, Non-Uniform Memory Access, Open Queuing Network (Rede de Fila Aberta) e duas realidades convertidas do formalismo PEPA, Workcell e WebServer.

A seguir, uma breve explicação de cada modelo seguido dos resultados obtidos para todos os experimentos acima definidos.

O modelo SAN definido refere-se à implementação paralela do Algoritmo Propagation com comunicação assíncrona.

Este modelo é responsável por indicar aos desenvolvedores de aplicações paralelas os gargalos e problemas de configurações existentes antes do início da fase de implementação.

Este modelo contem três estruturas particulares, um autômato denominado Mestre, um autômato que representa um Buffer (uma região temporária de armazenamento) e S autômatos Escravos, aqui denominados por Slave.

O número total de autômatos para este modelo é dado por (S+2) (onde S é o número de Escravos no modelo), o qual possui S eventos locais e (3S-3) eventos sincronizantes para o caso de descritores clássicos e o mesmo número de autômatos mas (2S + 3) eventos sincronizantes para o caso dos descritores generalizados.

Isso faz com que descritores baseados em ATC possuam (7s8) termos tensoriais e descritores ATG (4S + 6) termos.

Mostra os resultados para os Experimentos 1, 2, 3 e 4.

Observa-se que dentre estes experimentos a melhor execução foi obtida quando as identidades encontram-se na parte estruturada.

O uso de memória constatado foi pequeno (para 10 escravos de aproximadamente 76 Mb), tendose em vista o ganho obtido, da ordem de quatro vezes em comparação com o Experimento 2).

Os Experimentos 3 e 4 mostram os tempos quando não se permutam os termos, onde infere-se que o Algoritmo Shuffle executa mais rápido inclusive que sua versão com permutação, mostrando que o uso de reordenamentos está atrelado ao modelo e as suas características internas.

Mostra os resultados para os Experimentos 5, 6, 7, 8 e 9.

Esta classe de modelos mostra a escalabilidade dos algoritmos, pois a cada incremento de dois escravos, tem-se um aumento da ordem de 10 vezes em relação ao tempo dispendido e à memória gasta.

O melhor tempo foi verificado para o Experimento 6, que fornece uma boa relação custo/benefício em comparação com o Experimento 7, que além de gastar mais memória ainda leva mais tempo para realizar uma permutação.

Para este caso específico, onde o PSS explode facilmente, verifica-se que com 79Mb de memória tem-se um ganho de aproximadamente três vezes em relação à base de comparação do Experimento 9.

Pode-se dizer que esta memória gasta é negligenciável pois a plataforma de execução trabalha com 4 Gb de memória RAM.

Já no caso do Experimento 8, onde as avaliações são feitas na parte estruturada e não existem matrizes constantes, para esse modelo em particular, devido à natureza das funções existentes, observou-se que os cortes foram os mesmos que os praticados pelo Experimento 5.

Os tempos e o total de AUNFs obtidos entre esses dois casos atestam que correspondem ao mesmo caso.

Pode-se comparar a conversão implícita, ou em tempo de execução, do descritor baseado em ATG para descritor ATC, uma vez que as funções estão sendo avaliadas na parte esparsa para o experimento que executou mais rapidamente (Experimento 6).

Para esse caso, converter ou não converter não implica necessariamente em um ganho substancial, pois, para o caso de 10 escravos, o tempo para o modelo constante é de 4,1841 segundos e para o modelo generalizado é de 4,2506 segundos, ou seja, um pequeno ganho em termos de tempo.

O Experimento 8 mostra que essa conversão já é mais interessante, pois, para o mesmo caso, tem-se 16,1104 segundos para o caso constante e 13,3783 segundos para o baseado em ATG.

Cabe ressaltar que uma diferença de três segundos por iteração pode resultar em uma diferença considerável se supor-se que são necessárias 10000 iterações para a solução com o Power Method, ou seja, aproximadamente 8 horas.

O modelo SAN representa uma cadeia de nós móveis em uma Rede de Sensores (de forma Ad hoc) definida usando-se ATG, executada sobre o padrão 802,11.

Este modelo é uma adaptação do experimento de uma rede ad hoc presente.

A cadeia tem N nós que se movimentam, onde o primeiro é chamadoMN(1) (autômato Source) que gera pacotes de acordo com as definições de um padrão de comunicação.

Os pacotes são enviados através desta cadeia por autômatos do tipo Relay chamados deMN, onde i varia entre 2 e (N1), até chegar ao último nó que foi chamado deMN(N) (ou autômato Sink).

Os modelos SAN aqui descritos possuem genericamente (N2) eventos locais e N eventos sincronizantes para descritores contantes onde N é o número de nós móveis.

Nesse caso, existem [(N2) + 2N] termos tensoriais.

Para o caso de descritores generalizados, tem-se (N2) eventos locais e igualmente N eventos sincronizantes com N termos.

Este modelo foi aumentado para refletir um maior número de nós em uma rede com 10, 12, 14 e 16 nós.

Mostra um modelo com um descritor markoviano baseado em ATC de uma Rede de Sensores com quatro nós que foi traduzida da equivalente rede original que utilizava definições de descritores baseados em ATG.

Observa-se que para essa classe de modelos existem mais eventos sincronizantes, devido à conversão dos elementos funcionais em sincronizações.

Informa os resultados obtidos para os Experimentos 1, 2, 3 e 4.

Observa-se que o experimento que melhor executou foi o Experimento 1, com um ganho de aproximadamente sete vezes em relação ao Experimento 2.

Também mostra que as permutações impactam de forma dramática na memória utilizada e, para este caso, no tempo.

Nota-se que os termos foram reordenados de forma a otimizar por completo a geração de AUNFs (apenas 16 para o maior caso, com 16 nós), refletindo no melhor tempo obtido.

Também evidenciou que não necessariamente o uso de mais memória implicará em uma melhor execução, no caso do Experimento 3, foram gastos 116 Mb e ainda assim o tempo foi superior ao constatado no Experimento 1.

Exemplifica os resultados para os Experimentos 5, 6, 7, 8 e 9 para o caso dos modelos com descritores generalizados.

Estes casos merecem um comentário específico para cada experimento.

No Experimento 5, tem-se a avaliação das funções na parte estruturada.

Nota-se, em relação ao Experimento 9, um ganho de aproximadamente 2,6 vezes.

Para este caso, foi utilizado por volta de 40 Mb de memória para o caso dos 16 nós, um valor muito superior ao requerido pelos demais experimentos.

No entanto, apesar de ambos os Experimentos 6 e 7 utilizarem a mesma memória, executam em temos completamente diferentes (um em 11,5802 segundos e o outro em 6,6018 segundos, respectivamente, para o caso dos 16 nós na rede de sensores).

Esse fato pode ser explicado pela existência de matrizes do tipo elemento no modelo, que, como mencionado anteriormente, não aumentam o número de AUNFs necessários e mesmo assim, por deixar apenas identidades na parte estruturada, executam mais otimizadamente.

O ganho observado foi o maior constatado em todos os modelos executados, da ordem de 12 vezes mais rápido, para um PSS de tamanho elevado para este caso em questão, ou seja, 19 milhões aproximadamente.

O Experimento 8 faz as avaliações de funções na parte estruturada e troca as matrizes identidade que existam na parte esparsa com matrizes constantes.

Na parte estruturada só existem matrizes funcionais ou identidades.

Esse experimento mostra que foram necessários um número muito baixo em termos de AUNFs, mas mesmo assim, os tempos se comportaram equivalentemente aos obtidos no Experimento 5.

Esse fato corrobora que a avaliação de funções onera o desempenho do método da MVD, pois observa-se que, ao trocar esses elementos funcionais por constantes e enviar as identidades para a parte estruturada, os ganhos serão superiores, como visto no Experimento 7.

Este caso, para 16 nós, precisou de 6,6018 segundos para uma iteração, valores ainda superiores aos 4,0235 segundos necessários no modelo constante.

Para esses casos, observa-se que é melhor converter os modelos de ATG para ATC.

No entanto, o Experimento 8 é eficiente em memória, pois precisa no maior caso de apenas 16 AUNFs.

Constata-se que este caso específico das Redes de Sensores também possuem uma outra característica marcante, todos os eventos possuem muitas identidades e todas as matrizes restantes possuem apenas um elemento não-nulo, fazendo com que cada termo produza um AUNF apenas.

Esse é o melhor caso para o Algoritmo Split, pois a memória gasta é desprezível e o tempo de solução o mais otimizado possível.

Nota-se que os modelos que seguem essas características resultam em um tempo mais otimizado para realizar a MVD.

Observa-se que o Algoritmo Shuffle, apesar de realizar importantes otimizações para as matrizes identidades, ainda é necessário que ele trate das matrizes esparsas, calculando saltos na estrutura tensorial a cada iteração.

No caso da aplicação do Algoritmo Split, o melhor a se fazer seria calcular um AUNF, multiplicar nas posições corretas dos vetores de entrada, salvar no vetor de saída e descartar a parte estruturada.

Esta seção apresenta o modelo SAN construído para analisar a disponibilidade do primeiro servidor desocupado (First Available Server), para N servidores.

Cada servidor A pode ser descrito como possuidor de dois estados distintos, Idle (em espera) (I) e Busy (ocupado) (B).

Neste exemplo, pacotes que chegam no terminal de servidores bloqueados (ou servers switch block, partem através da primeira porta de saída (ou servidor) que não está ocupada, a única restrição é a de que pelo menos um servidor não está bloqueado.

O modelo está definido e pode ser visto como uma ferramenta de análise de diferentes sistemas de filas (por exemplo, ocupação de linhas de call centers).

Cada pacote que chega na fila pode avançar tão logo seja possível que um determinado servidor esteja livre, de acordo com uma prioridade pre-estabelecida.

O PSS é formado por 2N estados.

Mostra os resultados para os Experimentos 1, 2, 3 e 4.

A partir da tabela observa-se que para esse modelo em particular, não importa reorganizar os termos (Experimento 1) ou cortar na última matriz constante (Experimento 3), o método realiza a iteração com uma pequena diferença.

Outra característica deste modelo é precisar de um número extremamente reduzido de AUNFs para executar o método, para este caso, 20.

Isso faz com que a memória requerida além do que já é utilizado para guardar a diagonal da estrutura tensorial e os vetores de probabilidade do tamanho do PSS, ser negligenciável.

O ganho verificado em frente ao Algoritmo Shuffle foi da ordem de nove vezes, para a maioria dos casos e sete vezes para os casos onde os termos foram reordenados.

Este modelo está definido apenas para descritores constantes.

Os próximos modelos são oriundos do formalismo definido por PEPA, onde foi modelado dois tipos de modelos distintos, células industriais de produção e um servidor para a Internet.

Estes modelos foram traduzidos para SAN, com o objetivo de estudar as características envolvidas na tradução entre estes dois formalismos e as propriedades a serem consideradas neste mapeamento.

Para demonstrar a execução de modelos definidos em outros formalismos, foram escolhidos dois modelos em particular, gerados a partir de PEPA.

O primeiro, chamado Workcell, modela células industriais de produção e o segundo define um servidor para Internet de alta disponibilidade, chamado WebServer.

Aqui serão feitas breves explicações sobre o funcionamento geral dos sistemas modelados, maiores informações podem ser encontradas para, respectivamente, Workcell e WebServer.

Estes modelos foram traduzidos para SAN de forma direta, gerada a partir da composicionalidade de PEPA observando-se as movimentações nos estados da CTMC.

Esta tradução não é a melhor tradução deste tipo de modelagem, mas mesmo assim, produz os resultados de saída equivalentes à solução PEPA.

O modelo Workcell modela um sistema complexo de uma célula industrial de produção.

O objetivo desta célula é construir placas de metais em uma prensa, consistindo dos seguintes componentes principais, cintos de alimentação, tabelas rotatórias, robôs, prensas, cintos de depósitos e artefatos de movimentação, para citar alguns componentes do sistema.

O principal objetivo desta modelagem é inferir índices que demonstrem como estes componentes trabalham em conjunto, com vistas à avaliação de desempenho destes componentes.

Já o modelo WebServer modela um servidor para Internet de alta disponibilidade, composta principalmente por elementos de notícias.

Este modelo prevê qualidade de serviço em disponibilidade e tempo de resposta.

O objetivo principal deste tipo de modelagem é experimentar com a engenharia de desempenho de aplicações de alta demanda com vistas à verificação de eficiência de pico, entre outras análises.

O modelo executado aqui, possui quatro parâmetros, S compreende o número de servidores no sistema, B, denota a capacidade do buffer de memória, R diz respeito ao número de leitores e W ao número de escritores existentes no sistema (como trata-se de um sistema de notícias, as atividades compreendem a leitura e a escrita de materiais).

Para o caso deste exemplo em particular, foi escolhido trabalhar com um modelo com um PSS de valor razoável, com os seguintes parâmetros S = 4, B = 3, R = 3 e W = 3.

Estes modelos baseados em PEPA existem apenas sob a forma de um descritor clássico e os seus resultados estão sendo mostrados.

Esta tabela informa o tempo de execução para os Experimentos 1, 2, 3 e 4.

Para o modelo Workcell, o tempo verificado é bastante similar nos Experimentos 1 e 3 e, quando comparados ao Experimento 2 e 4 atestam um ganho de seis e quatro vezes.

A diferença entre as execuções está na memória gasta em cada experimento.

Enquanto que no primeiro nada foi praticamente gasto (por volta de zero bytes), no Experimento 3 foi necessário 364 Kb.

Para este modelo, a memória gasta não impacta no tempo de execução.

Para o caso do WebServer, a melhor execução foi a alcançada pelo Experimento 1, sendo nove vezes mais rápido quando comparado ao Algoritmo Shuffle realizando-se permutações.

No caso de se escolher não fazer permutações (Experimentos 3 e 4), o ganho ainda assim é considerável (da ordem de três vezes), mas são necessários 18 Mb para salvar os AUNFs.

Visto que é possível reordenar os termos e não gastar em memória e ainda assim ganhar em tempo, esta é claramente a melhor alternativa para a solução eficiente deste modelo.

Cabe ressaltar ainda que a estrutura deste modelo em termos de eventos sincronizantes é similar à verificada pelo modelo das Redes de Sensores, onde os eventos sincronizantes envolvem apenas dois autômatos, na maioria dos termos tensoriais.

Esta seção apresenta um modelo clássico para avaliação de desempenho para análise de exclusão mútua em compartilhamento de recursos.

O modelo em questão é uma abstração chamada de problema dos filósofos e, resumidamente, pode ser descrita da seguinte forma, K filósofos estão sentados em uma mesa e a eles somente são permitidas duas ações, comer ou pensar.

Os filósofos estão sentados em uma mesa circular com uma tijela de comida no centro desta.

Um garfo Fk está posicionado entre cada filósofo Pk, assim, cada um possui um garfo à sua esquerda e um garfo à sua direita.

Para comer, um filósofo necessita de dois garfos nas suas mãos, simultaneamente (o problema é que não existem recursos suficientes para todos ao mesmo tempo).

O modelo SAN possui K autômatos do tipo P(k) representando os filósofos, cada um com três estados, Th(k) (pensando), Lf(k) (pegando garfo da esquerda), Rf(k) (pegando o garfo situado à direita).

O filósofo pode reservar o garfo à sua esquerda ou direita para comer utilizando dois garfos disponíveis.

Para evitar deadlock fica estabelecida uma ordem para pegar os garfos na mesa, para cada filósofo presente no modelo.

O PSS deste modelo é dado por 3K estados.

Os modelos definidos só existem para descritores clássicos, mostrando os resultados para a faixa de 12 a 16 filósofos.

Observase que o PSS tem um crescimento exponencial, sendo que para 16 filósofos, ele é da ordem de 43 milhões de estados.

Não foi possível computar para este modelo os tempos dos Experimentos 3 e 4 uma vez que foi preciso por volta de 1,2 Gb de memória apenas para armazenar a tabela referente aos AUNFs.

Como este modelo é possuidor de muitas identidades, o Experimento 1 mostra claramente o efeito de se passar estes elementos para a parte estruturada, apenas 48 AUNFs são de fato necessários para o caso com mais filósofos, ou seja, o com 16.

E esse fato reflete no tempo gasto para executar uma iteração, onde os ganhos médios calculados ficaram na ordem de quatro vezes, entre os Experimentos 1 e 2, que executaram permutações nos termos tensoriais.

Mostra a influência dos aspectos semânticos na geração dos termos tensoriais, pois, ao aumentar o número de filósofos em um determinado modelo, implica no aumento proporcional de sincronizações que ocorrem e, consequentemente, de termos.

As variações do número de filósofos do modelo foram chamadas de philK, onde K representa o número de filósofos existentes.

Este modelo evidenciou o fato que é totalmente desvantajoso salvar AUNFs que correspondem a identidades, ou seja, valores que não serão de forma alguma alterados, pois possuem o valor 1 e implicam em um aumento substancial de elementos que é totalmente desnecessário que seja calculado.

Para o caso de 15 filósofos, por exemplo, foi necessário 423 Mb de memória e o método executou em 9,8 segundos, enquanto que gastando-se por volta de 1 Kb, foi executado em 6,2 segundos.

O modelo dos filósofos, assim como o modelo das Redes de Sensores mostram quando a abordagem utilizada pelo Algoritmo Split realmente ganha em termos de tempo de execução.

O motivo deste acontecimento é relacionado ao fato de que este modelo em particular possui sincronizações entre poucos autômatos e diversas matrizes identidade.

O corte realizado é extremamente baixo e isso reflete o número de AUNFs necessários para o cálculo.

Também mostrou que é completamente ineficiente usar matrizes identidade para compor a listagem dos AUNFs, visto que elas não influenciam no valor que está sendo salvo e poderiam servir melhor na parte estruturada, que salta fatores normais identidade, ou seja, o Algoritmo Shuffle não é chamado e logo, nunca calcula índices de salto na estrutura tensorial.

O modelo de Compartilhamento de Recursos é bastante utilizado, tratando sobre como N processos compartilham R recursos.

Representa um sistema de compartilhamento de recursos onde cada processo é representado por um autômato A composto por dois estados, S (dormindo, ou sleeping) e U (usando ou using).

Um conjunto de recursos é representado pelo autômato A(N+1) o qual possui R + 1 estados indicando o número de recursos que estão sendo utilizados.

Este modelo apresenta um conjunto de autômatos no qual os eventos sincronizantes estão relacionados a apenas dois autômatos cada um.

Isto significa que os termos tensoriais serão compostos por muitas matrizes de baixa esparsidade e igualmente muitas identidades.

A característica principal destemodelo é não possuir eventos locais, logo, a parte local do descritor não gerará fatores normais, ou seja, termos onde todas as matrizes menos uma são do tipo identidade.

O restante dos termos disponíveis (sincronizantes) são particularmente interessantes para o Algoritmo Split, já que a abordagem utilizada pelo Shuffle já otimiza de forma suficientemente considerável as somas tensoriais.

Os principais resultados para o modelo do Compartilhamento de Recursos está mostrado.

Mostra as diferentes configurações de redes de autômatos, denominadas rsP_R que indicam no nome do modelo o número de processos existentes (P) para R recursos compartilhados.

Verifica-se as comparações entre os tempos obtidos de uma iteração entre os Experimentos 1, 2 e 3, 4.

Inicialmente, verifica-se que para o caso onde existem 20 processos para 25 recursos (o nome do modelo é rs20_25c), não foi possível computar os tempos devido ao alto custo em memória para salvar os AUNFs, da ordem de 1,6 Gb.

Esta classe de modelos também possui muitas identidades, e o experimento que obteve os maiores ganhos foi o Experimento 1, sendo melhor em média três vezes que o Experimento 2, sendo necessário 31 Kb de memória para guardar os AUNFs.

Esta classe de modelos, como no caso dos filósofos, mostra claramente que a realização de permutações é amplamente necessária, e este fato está evidente na memória gasta em todos os modelos.

Nos casos onde permutaram-se os termos tensoriais, a memória gasta é muito inferior aos experimentos onde não foram usados reordenamentos (para o caso específico do Algoritmo Split, uma vez que o Algoritmo Shuffle é eficiente em gastos de memória).

Este exemplo descreve um sistema de rede aberta composto por quatro filas (F1, F2, F3 e F4), representadas pelos autômatos A(1),A(2),A(3),A(4), com capacidades finitas (K1, K2, K3 e K4) respectivamente.

O padrão de roteamento de consumidores para esse caso, chegam em F1 e F2 com taxa 1 e 2, podendo sair de Q1 para Q3 se existir espaço (comportamento bloqueante) e também sair de F2 para F3 se existir espaço ou sair do modelo em caso contrário (comportamento de perda).

Os consumidores também podem sair de F3 para F4 com comportamento bloqueante.

Enquanto F1, F2 e F4 possuem comportamento de serviço padrão (no caso, single), uma mesma taxa média de serviço para todos os consumidores (µ1, µ2 e µ4 respectivamente), a fila F3 possui um comportamento alternado de padrão de serviço (Alternate Service Pattern, ou ASP).

A taxa de serviço para esta fila varia de acordo com P diferentes taxas de padrão de serviço.

A fila F3 pode trocar seu padrão simultaneamente de acordo com o final do serviço de um consumidor.

Isso faz com que quando um consumidor é servido pelo padrão Pi, F3 pode permanecer servindo o próximo consumidor no mesmo padrão com probabilidade pii, ou pode alternar para um padrão de serviço diferente Pj com probabilidade pij.

O modelo SAN é composto por um autômato usado para cada fila com serviço simples (A(1), A(2) e A(4)) e outros dois autômatos para a fila de padrão de serviço alternado (A(3) e A(5)).

O modelo ASP mostra que o melhor tempo encontrado foi correspondente ao Experimento 4.

Este experimento obteve os melhores índices para uma iteração, quando não são executadas permutações nos termos tensoriais.

Mostra os casos com descritores constantes onde os tempos, apesar de serem parecidos entre os Experimentos 1 e 4, mostram um ganho relativo implicando que a melhor abordagem a ser escolhida nestes casos, é provavelmente a adotada pelo Algoritmo Shuffle.

Cabe ressaltar que a evolução dos termos tensoriais ocorre de forma escalar, ou seja, para N servidores sempre existem cinco autômatos, (N +2) eventos sincronizantes e 3 locais, totalizando (2(N +2)+3) eventos.

Por volta da metade de cada termo tensorial é composto por matrizes do tipo identidade.

Máquinas NUMA são utilizadas em conjunção com diversos sistemas operacionais da atualidade.

O próximo exemplo descreve uma modelagem de partes do sistema operacional Linux para ser usado em máquinas NUMA.

O modelo permite a análise precisa e analítica de todos os possíveis tamanhos para processos para um número variado de processadores de uma máquina NUMA, generalizando o conceito sobre o comportamento dos processos modelados sob a ótica de um único processo em um ambiente multiprocessado.

Este modelo genérico permite que sejam analisadas as chances de um processador falhar, analisa o processo de migração de processos entre os processadores e o funcionamento do escalonador do sistema operacional Linux.

O modelo NUMA é particular onde todos os seus eventos envolvem apenas dois autômatos e cada matriz do termo tensorial possui apenas um elemento não nulo.

Este fato é verificado pelo número de AUNFs que são necessários para armazenamento deste modelo que é igual ao número de eventos existentes.

Ou seja, cada termo possui duasmatrizes não nulas e o restante é composto por identidades (para seis processadores são necessários sete autômatos e para oito processadores, nove autômatos).

Observando-se os resultados nota-se que este modelo obteve os maiores ganhos frente ao Algoritmo Shuffle, da ordem de 17 e 28 vezes para seis e oito processadores.

Foram necessários entre cinco e nove Kilobytes de memória para armazenamento dos AUNFs.

Este é o melhor caso para o Algoritmo Split, gastando pouca memória e resultando em ganhos massivos (inclusive quanto à abordagem esparsa, pois esta guardaria AUNFs que corresponderiam a matrizes identidade, e a abordagem Split apenas permutaria os termos tensoriais para nunca armazenar identidades no caso do Experimento 1).

O autômato Processo representa os processos escalonados para R processadores.

Contém quatro estados, IO (processo está esperando uma operação de entrada/saída), R (processo encontra-se na fila de -pronto-, ou seja, esperando para ser escalonado no ith processador), Ex (representando que o processo está sendo executado no processador correspondente) e Ep (processo está na fila de processos -expirados-, ou seja, terminou sua fatia de tempo e está esperando para ser movido para a fila de processos -prontos-).

Para cada autômato Processador Proc, onde i = R, existe mais um estado chamado En, simbolizando que o processo terminou sua execução e não faz mais parte do sistema.

Já o autômato Processador contém seis estados, Er (algum erro aconteceu e o processador encontra-se inoperante), Pb (o processador está executando seu algoritmo periódico de balanceamento de carga), En(1) (o processador está ocupado, executando qualquer outro processo), Sc (o processador está executando seu algoritmo de escalonamento), IB (em modo de espera mas acionando seu algoritmo de balanceamento de carga) e, por fim, Ex (processador executando processo do autômato Process).

Sendo R o número de processadores de um dado modelo, o seu PSS é dado.

O número total de autômatos é genericamente dado por (R+1), contendo 18 eventos locais e 32 eventos sincronizantes.

O descritor markoviano -Q, neste caso, é formado por somas tensoriais com R + 1 matrizes locais e 64 termos tensoriais produto com R + 1 matrizes.

Para as execuções sequenciais deste modelo considerado foram utilizados R = 6 e R = 8.

Mostra os resultados obtidos para dois tipos de modelos, uma máquina NUMA que descreve seis processadores e outra, oito processadores.

A variação do PSS é de -1 milhão de estados para o caso de seis processadores até -55 milhões para oito processadores.

Este modelo alinhase ao modelo das Redes de Sensores quanto à afetação dos eventos sincronizantes dos descritores constantes.

Para seis processadores foram necessários sete autômatos e 174 eventos e para o caso de oito processadores, nove autômatos e 312 eventos.

Em termos de memória auxiliar para o Algoritmo Split, gasta respectivamente 5 Kb e 9 Kb, demonstrando que os eventos existentes no modelo afetam poucos autômatos.

Modelos de Filas Abertas representam filas com comportamentos independentes (do ponto de vista da chegada e saída de cada fila presente no sistema) e interações comsincronização (considerandose as trocas de clientes entre as diferentes filas).

Um exemplo de um modelo de filas deste tipo é apresentado, contendo três filas de tamanho dois para uma única classe de clientes.

O modelo possui uma fila com comportamento bloqueante (para os clientes da Fila Q(1) para a Fila Q(2)) e outra fila com comportamento de perda (para os clientes da Fila Q(1) para a Fila Q(3)).

Mostra os resultados obtidos para OQN.

O ganho em relação ao Shuffle manteve-se em 1,7 vezes, considerando-se que o descritor possui termos tensoriais de tamanho três e eventos com pelo menos uma identidade por termo, o que ajuda na execução do método Split.

O total de AUNFs necessários manteve-se igualmente constante, e o maior exemplo, com filas de tamanho 250 foram necessários 4 Mb para salvar a lista.

O tempo de criação desta lista variou entre 0,2 segundos e 0,6 segundos, evidenciando um tempo reduzido para o seu armazenamento.

Tendo-se em vista os resultados expressivos obtidos no modelo de Redes de Sensores, conduzse a seguir uma análise mais compreensiva das explicações em torno da eficácia da sua execução.

O objetivo é explicar porque essa classe de modelos executoumais rapidamente que a abordagem Shuffle ao mesmo tempo que utilizou inexpressivas quantidades de memória.

A seguir, um detalhamento do modelo em si e dos índices de desempenho que deseja-se extrair.

Na presente seção, será dada uma maior ênfase aos detalhes internos do modelo e as escolhas feitas em termos de modelagem tanto para descritores constantes como para generalizados.

Este modelo descreve uma rede de sensores com N autômatos, sendo dois autômatos de dois estados situados nos extremos (um chamado Source e o outro Sink) e N2 autômatos auxiliares de três estados situados entre estes (chamados de Relay).

Os estados de cada autômato representam as possibilidades possíveis de troca de estado interno.

O autômato Source somente pode estar transmitindo ou em modo de espera (idle), sendo representados pelos estados I (para Idle) e T (para Transmitting).

O autômato Sink, pode estar em espera (I) ou recebendo (R).

Os demais autômatos possuem três estados, podendo estar em espera (I), recebendo (R) ou transmitindo (T).

O objetivo dos autômatos extremos é modelar um envio de um pacote de Source até Sink.

Para que a comunicação funcione entre as entidades que compõem o modelo, os eventos devem causar a mudança de estado dos autômatos de uma maneira coordenada e sincronizada.

Ao ocorrer um evento que deseja enviar um pacote para o autômato Sink, este altera seu estado interno de I para T ao mesmo tempo que o seu autômato -vizinho- do tipo Relay altera seu estado de I para R (de parado para recebendo), através do evento g1,2 (que observa os estados dos próximos dois autômatos, neste caso,MN3 eMN4, e aplica a taxa se ambos são diferentes do estado de transmitindo).

O processo se repete até o autômato Sink mudar seu estado de em espera para recebendo.

Para escalar o modelo, basta criar mais autômatos do tipo Sink e atualizar os eventos para descrever as mudanças de estados coerentemente.

Mostra as características principais da classe das redes de sensores, informando, para cada caso, o espaço de estados (coluna PSS), o número total de autômatos (em #automatos), os totais de eventos locais e sincronizantes para descritores constantes (ATC loc e syn).
E totais para descritores generalizados (ATG loc e syn), finalizando pela última coluna (#termos) que indica o total de termos para cada modelo (somando o número de eventos locais com os eventos sincronizantes positivos e negativos).

Este modelo possui a particularidade de possuir um número de eventos sincronizantes equivalentes ao número de autômatos.

Cabe ressaltar que o último modelo tratável com a ferramenta atual de solução (GTAexpress) sem o uso de memórias auxiliares em disco (swapping) é o caso para 17 sensores, atingindo um PSS de -57 milhões de estados (o limite atual da ferramenta é de -65 milhões de estados).

Como o modelo foi originalmente definido usando-se funções para o seu sistema de transição, a análise começará pelo descritor generalizado e seguirá para a conversão das funções em eventos sincronizantes na seção posterior.

As taxas funcionais relativas às transições entre os autômatos foram definidas para reforçar, via eventos sincronizantes, a existência de uma única transferência de dados (ou seja, todos os outros autômatos não estão no estado -transmitindo-).

Essas definições impactam tanto a solução do modelo quanto a formação do descritor markoviano equivalente.

Refere-se aos Experimentos 5 a 8, equivalentes à solução de descritores generalizados.

Apenas relembrando, o Experimento 5 realiza as avaliações na parte estruturada e o Experimento 6, na parte esparsa.

O Experimento 7 também avalia na parte esparsa, mas deixa o descritor possuindo apenas matrizes identidade na parte estruturada.

O Experimento 8 possui somente a matriz equivalente à função e matrizes identidade na parte estruturada.

Mostram-se as ordens dos autômatos no descritor, variando de 0 até N, sendo N o número de autômatos totais.

Na parte direita, descreve-se a esparsidade de cada matriz, indicando o número total de elementos não-nulos (exclusivamente para esse caso, este valor equivale-se à um) e a ocorrência de matrizes identidade (através da letra i).

Para cada experimento, mostra-se a ordem escolhida dos autômatos e o ponto de corte s (aqui exemplificado pelo caractere |) refletido em ambos os lados da tabela.

No fim de cada experimento, informa-se o total de AUNFs necessários para o cálculo efetivo da MVD.

Para o caso das Redes de Sensores, ao utilizar descritores generalizados, matrizes do tipo identidade encontram-se na parte esparsa.

Teoricamente, o melhor jeito de se tratar cada termo tensorial é permitir apenas identidades e a matriz que contém a definição do elemento funcional na parte estruturada, gastando apenas 12 AUNFs.

Em comparação com os outros experimentos, o número de AUNFs necessários são maiores, tais como 568 para os Experimentos 7 e 8 e 14257 para o Experimento 5.

Descritores generalizados não privilegiam a avaliação de funções na parte esparsa, pois forçam que matrizes do tipo identidade permaneçam neste lado, o que onera a memória e não altera o valor dos escalares que correspondem aos AUNFs.

Para tanto, através da inserção de eventos sincronizantes que são traduzidos para garantir que somente dois autômatos estejam transmitindo informações é possível que estes descritores sejam convertidos para descritores constantes.

Neste caso, ao retirar as avaliações de funções, o Algoritmo Split pode usar a estratégia de re-estruturar o termo tensorial de forma que apenas matrizes identidade permaneçam na parte estruturada e compor AUNFs com os elementos não-nulos na parte esparsa.

O objetivo é verificar o custo computacional necessário para avaliação de funções dentro do modelo das Redes de Sensores.

A seguir, mostra-se como as funções existentes no modelo foram convertidas para eventos sincronizantes.

A definição do modelo de Redes de Sensores com descritores generalizados mostrou-se oneroso para a utilização do Algoritmo Split, principalmente quando se verificam as tabelas de resultados para ambos os casos descritas na seção anterior (correspondendo respectivamente aos resultados constantes e generalizados).

Deseja-se descobrir porque houve uma melhora considerável nos tempos de execução entre ambos os casos.

A detecção das propriedades dos descritores constantes será fundamental para entender como o Algoritmo Split pode ser usado de forma mais eficiente para as classes de modelos que seguirem este tipo de descritores.

Mostra as re-estruturações efetuadas no descritor para os Experimentos 1 e 3 bem como as esparsidades de cada termo tensorial, numerado aqui de 1 até 12.

No Experimento 1, as identidades foram tratadas na parte estruturada e o Experimento 3 não alterou a ordem natural das matrizes (ou seja, não permutou as matrizes), escolhendo o ponto de corte s como sendo a última matriz constante (no caso a última não-identidade).

Este último experimento precisou de um número elevado de AUNFs (45,929) enquanto que o Experimento 1 precisou de um AUNF por termo tensorial (apenas 12 AUNFs), sendo o caso que retornou o melhor tempo para o Algoritmo Split mesmo quando este é comparado ao caso da modelagem original, com descritores generalizados.

A característica mais importante nesse descritor é que todas as matrizes que não são identidades, são matrizes do tipo elemento, sendo extremamente esparsas.

E ao serem enviadas para a parte esparsa, produzem um número ínfimo de AUNFs, evitando, na totalidade, os cálculos necessários pela parte estruturada (ou seja, não gera ou trata fatores normais).

Para este modelo (e, consequentemente, classes que seguirem as características deste), é melhor traduzir para descritores constantes, pois isso não implica em um aumento do número de eventos sincronizantes (como se esperaria ao efetuar-se uma tradução ATG para ATC).

Esse modelo não utiliza praticamente nada de memória adicional em relação ao Algoritmo Shuffle (um total de 12 AUNFs, ou seja, -0 Kb) e executa o processo da MVD -6 vezes mais rápido que o equivalente com mesmo tipo de descritor e -1,5 vezes melhor ao ser comparado com o equivalente com descritor generalizado (comparando apenas o Algoritmo Split).

O processo da MVD pode ser realizado de diferentes formas, como explicado ao longo do trabalho.

Cada diferente maneira implica em uma complexidade em termos de multiplicações em ponto flutuante igualmente única.

Para tanto, deseja-se saber as diferenças entre onde avaliar os elementos funcionais e na geração dos AUNFs necessários para cada método.

A seguir, será feita uma análise da complexidade envolvida, explicando, para cada Experimento do modelo de Redes de Sensores, as equações correspondentes ao número de operações necessárias.

Para o Algoritmo Split, a complexidade está diretamente relacionada ao ponto de corte s escolhido para cada caso, pois este por sua vez implica na quantidade de repetições que o algoritmo precisará realizar operações de multiplicação.

A definição de cada função, para o caso de descritores generalizados, é igualmente importante pois, dependendo do número de parâmetros e da maneira pela qual esta é representada, impactará em chamadas internas que alteram a complexidade dos algoritmos de MVD.

Seja F uma função genérica de um descritor baseado em ATG e seja p o conjunto de parâmetros (ou operandos) necessários para a avaliação de F.

Seja ainda o o número de operadores (funções matemáticas, tais como ×, +, -, etc).

Portanto, uma função será aqui denotada por F(p, o), uma função que recebe dois parâmetros, seus operandos e seus operadores.

Para o contexto deste trabalho, cada função possui um valor de complexidade ditada pelo modelo que foi construído pelo usuário.

Começando a análise pelas avaliações de funções, mostradas pelos Experimentos 5, 6, 7 e 8.

Ao avaliar elementos na parte esparsa, está-se, na verdade, convertendo-se um descritor generalizado para constante em tempo de execução do método (no caso, apenas na primeira execução que os AUNFs são calculados).

Entretanto, ao escolher avaliar na parte esparsa, matrizes identidade são enviadas para a parte esparsa, e como precisa-se tratar com todos os AUNFs que foram gerados para cada evento, esse método gasta tempo multiplicando escalares desnecessariamente.

Para a avaliação de funções na parte estruturada, dado que existem elementos não-nulos (não necessariamente apenas matrizes identidade), é necessário adicionar a complexidade da multiplicação pelos fatores normais mais as operações de avaliação de função.

A dificuldade de se determinar um valor para a complexidade reside no fato que depende da maneira com que o modelador construiu a sua taxa funcional pois esta influi diretamente nas operações exigidas.

Para descritores constantes, estes valores são mais fáceis de serem computados, pois o custo em termos de multiplicações das avaliações saem da equação, juntamente com os cálculos necessários para os fatores normais da parte estruturada.

Resumindo, para avaliar funções, sem precomputá-las anteriormente, existe um custo adicional de F(p, o), assumindo que esta função esteja em um formato otimizado de representação definido pelos usuários, correspondendo à avaliação da função.

Para o caso de avaliações na parte esparsa, a existência de identidades nesta parte implica na definição de AUNFs desnecessários.

O melhor caso é para os descritores constantes (sem avaliações de funções), onde os eventos afetam apenas dois autômatos, como é o caso do modelo das Redes de Sensores.

Cabe ressaltar que aqui estão sendo avaliados modelos generalizados com funções que sincronizam atividades e sua respectiva tradução para descritores constantes.

Modelos com funções na parte local não estão sendo considerados nesta análise pois os eventos locais são simples somas e não impactam profundamente na complexidade.

Este tipo de modelo não está sendo considerado pelo Algoritmo Split.

Modelos com dependências cíclicas também não são melhores tratados com o Split mas sim com a abordagem Shuffle, conforme já explicado em seções anteriores deste trabalho.

A partir dos resultados obtidos percebeu-se as vantagens e desvantagens de cada estratégia utilizada para cada tipo de descritor, constante ou generalizado.

Para alguns modelos, a conversão implícita de descritores ATC é válida e resulta em um menor tempo de execução do método.

Os resultados apresentadas neste trabalho mostraram as execuções dos Algoritmos Shuffle e Split para uma iteração do Método da Potência.

Entretanto, para a extração dos índices de desempenho, é necessário que se obtenha resultados no regime estacionário, ou seja, quando o modelo atinge a convergência.

Mostra o significado de se acelerar o processo de MVD.

Exibe, para um conjunto expressivo de modelos, o número de iterações necessárias para que o método atinja a convergência.

A partir do tempo para uma iteração obtido nas tabelas de resultados anteriores (apresentadas na coluna T1), multiplicou-se este valor pelo total de iterações (coluna iter), obtendose o tempo total necessário para que se tenham índices confiáveis de desempenho.

A coluna Tempo para Solução mostra o tempo (com escala variável, em minutos (min), horas ou dias) que cada método usou para a convergência, com a escolha da estratégia que privilegia as avaliações na parte esparsa e mantém apenas as matrizes identidade na parte estruturada de cada termo tensorial.

A coluna Memória mostra, em Kb, a memória adicional necessária para o Split.

Cabe ressaltar que este possui a mesma limitação teórica em termos de PSS existente para o Shuffle, ou seja, - 65 milhões de estados.

Esse é o limite existente para ambos os métodos.

Neste caso, observa-se que para o caso de 10 escravos (caso slaves10), o Split precisou de por volta de 79 Mb adicionais.

Entretanto, para 13 escravos, seriam necessários mais três autômatos de três estados elevando o PSS para |X| = 7263027 × 33 - 180 milhões de estados.

O caso dos 13 escravos não pode ser executado por nenhum dos algoritmos nesta versão da ferramenta (existem técnicas para trabalhar com espaços de estados que ultrapassam a memória principal, mas estão fora do escopo deste trabalho).

O número de iterações necessárias para cada modelo é dependente das taxas que são utilizadas.

Para os exemplos acima de casos reais foram utilizadas as mesmas taxas das definições originais, ou seja, os modelos foram escalados para refletir essas mudanças.

Esta tabela mostra numericamente a vantagem em se adotar a execução do Algoritmo Split em comparação com a abordagem anterior existente descrito pelo Algoritmo Shuffle.

Ao se acelerar a solução da MVD a cada iteração esse ganho é propagado por todas as iterações necessárias, resultando em um ganho razoável ao se avaliar a solução como um todo.

O Algoritmo Split obtem resultados numéricos de forma mais rápida e permite que a fase de refinamento dos modelos e validação dos modelos seja antecipada.

Excetuando-se o caso Mestre-Escravo, que precisou -80 Mb para 10 escravos, o restante dos modelos obteve um ganho expressivo em termos de tempo para solução dos exemplos onde a memória a ser potencialmente gasta restringiu-se a limites ínfimos, mostrando que o Algoritmo Split é uma alternativa eficaz de MVD.

Observa-se que para uma grande classe de modelos o método ainda permanece sendo eficiente no armazenamento de memória, como comprovado pelos dados.

O ganho médio observado foi de 12,8 vezes para os modelos escolhidos.

Para os modelos NUMA, escolheu-se um total de 10000 iterações arbitrariamente, para efeitos de cálculos, pois o modelo possui apenas solução transiente.

Os resultados obtidos forneceram uma ideia razoável de quando é melhor usar as diferentes abordagens propostas.

Os exemplos utilizados mostraram as vantagens e as características dos termos tensoriais que devem ser observadas para determinar onde melhor dividí-los e reposicionar as matrizes de forma a obter um tempo otimizado.

A seguir, é discutida uma proposta para a escolha deste ponto de corte, observando a memória que será potencialmente gasta, refletindo no tempo de solução.

As equações teóricas do custo computacional para solução de termos tensoriais, aliado aos resultados obtidos permitem que seja proposto um algoritmo para divisão de descritores clássicos e generalizados.

Este algoritmo leva em consideração o efeito do custo em termos de operações de ponto flutuante requeridas pelo Algoritmo Split bem como a memória na construção dos AUNFs.

Um número de AUNFs igual a zero indica que o corte escolhido é o referente ao Algoritmo Shuffle com mesmo custo computacional.

Antes da introdução do algoritmo, alguns fatos conhecidos sobre a solução de termos tensoriais que foram verificados com os resultados produzidos e a análise teórica.

Avaliar funções apenas uma vez é melhor do que avalia-las muitas vezes por muitas iterações.

Matrizes constantes e matrizes elemento sempre podem ser deslocadas para a parte esparsa.

Uma esparsidade baixa do termo tensorial (o número de elementos não-nulos existentes) implica em um número de AUNFs igualmente baixo.

Matrizes identidade podemsempre ser deslocadas para a parte estruturada, pois na parte esparsa, geram um número de AUNFs maior que antes desta reorganização e não alteram o valor, pois são iguais a um.

Termos altamentes dependentes são melhores tratados pelo Algoritmo Shuffle.

Para o Algoritmo Split o melhor caso é quando os modelos possuem diversos autômatos que sincronizam suas atividades com poucos eventos (isso faz com que existam muitas identidades no termo tensorial).

O Algoritmo recebe como entrada um termo tensorial e decide o ponto de corte a ser utilizado a partir das características das matrizes (dimensões, identidades, elementos não-nulos) que o compõe e o tipo de termo.

Este algoritmo é uma delineação do que será utilizado para a otimização da MVD nos descritores constantes e generalizados.

O funcionamento do algoritmo é o seguinte, a partir da descoberta do tipo do termo tensorial t (que pode ser uma de três possibilidades, constante, parcialmente dependente ou totalmente dependente), é realizado o processo de descoberta do ponto de corte s.

Caso este tipo seja constante, ocorre uma transformação no termo tensorial enviando as matrizes identidade para o final e armazenando-se esse índice na variável i.

Caso haja memória suficiente para essa operação, a transformação é validada e s recebe o valor do índice i.

Já no caso do termo ser parcialmente dependente, tem-se a verificação da ocorrência de matrizes elemento (ou constantes) e o envio de matrizes para a parte esparsa do termo tensorial, exceto identidades.

O valor de s para esse caso é o índice da última matriz dependente depois desta transformação.

Por fim, se o tipo for altamente dependente, a melhor possibilidade para lidar com esse termo é adotar a abordagem totalmente estruturada, pois inclusive pode-se ter dependências cíclicas e funções especificamente que serão tratadas de forma adequada pelo Algoritmo Shuffle.

Ainda falta considerar no algoritmo o uma verificação nas funções que possuem poucos parâmetros ou são melhores tratadas na parte estruturada.

Isso fará com que menos memória seja gasta, uma vez que quanto mais estruturada é a escolha da divisão, menos memória é gasta para efetuar-se a MVD.

Para esse caso ainda são necessários maiores estudos quanto à como devem ser as funções dos termos tensoriais generalizados para que exista um ganho real na multiplicações que são efetuadas.

Termos com matrizes densas farão com que sejam calculados um número de AUNFs que talvez inviabilize o método e a melhor abordagem a seguir é dividir o termo em um ponto onde a memória a ser gasta é suficientemente calculada para abrigar um número considerável de elementos.

Em casos altamente dependentes em termos de funções, a melhor alternativa é cortar em s0 e resolver o termo de forma estruturada.

Em casos onde existem funções que dependem de um número restrito de outros autômatos, o Algoritmo Split possui um bom desempenho, pois ocorrem diversas identidades no termo e esparsidade dita que serão criados um número de AUNFs que é menor que a memória disponível.

A experiência em modelagem SAN dita que são poucos os casos onde existem matrizes plenas ou altamente densas em um termo tensorial.

Os termos tensoriais possuem um padrão bem definido e o Algoritmo Split utiliza esse padrão de definição dos descritores para resolver os modelos em menos tempo, visto que o método é executado mais rápido, por iteração, que as abordagens pré-existentes no que tange a MVD especificamente para SAN.

A seguir é feita uma discussão sobre os experimentos e os resultados obtidos.

Os resultados obtidos mostraram claramente quando o Algoritmo Split é melhor utilizado, ou seja, quando existem termos tensoriais esparsos, no melhor caso, com apenas um ou poucos elementos nãonulos, termos com alta incidência de matrizes identidade (o evento não ocorre em diversos autômatos), efetua-se permutações na ordem original e, para descritores generalizados, as avaliações de elementos funcionais são efetuadas quando os AUNFs são calculados, apenas uma vez no início do método.

O melhor caso pode ser comprovado através do caso das Redes de Sensores, onde foi preciso salvar N escalares na tabela de AUNFs, correspondendo ao número de termos existentes, ou seja, um AUNF por termo tensorial.

Os ganhos para o caso constante foram da ordem de 12 vezes em relação à abordagem do Algoritmo Shuffle.

É inegável que a utilização de funções está intrinsecamente relacionada à modelagem de interações complexas em sistemas, mas como métodos iterativos de solução são utilizados nesse escopo, não justifica a avaliação frequente de elementos funcionais a cada execução do método de MVD.

Estes elementos funcionais sempre retornarão os mesmos valores, logo, seria mais eficiente utilizar estruturas de dados auxiliares para guardar apenas a primeira avaliação das funções, ou seja, que convertam os descritores generalizados em constantes em tempo de execução.

Isso faria com que os usuários continuassem a modelar sistemas de forma a capturar certos detalhes impossíveis de serem mapeados com eventos locais e sincronizantes, ao mesmo tempo que iria otimizar a convergência da solução no método iterativo.

Este é o mesmo argumento pelo qual não se guardam os AUNFs que são gerados a cada execução para cada termo tensorial, pois serão sempre os mesmos, sem mudança alguma.

Não é otimizado ter que se recalcular essa tabela a cada iteração uma vez que os ganhos em termos de desempenho são consideráveis para esses casos.

Mas para entender o processo interno do algoritmo na sua essência, é necessário observar os detalhes do descritor markoviano em si.

Uma vez que os eventos locais são somas simples de matrizes, são os eventos sincronizantes, com taxas constantes ou funcionais, que determinam o comportamento do Algoritmo Split em termos de custos de memória e tempo de solução.

Como definido anteriormente, quando um dado evento sincronizante não ocorre em um dado autômato, no nível do descritor, a sua matriz correspondente é uma matriz do tipo identidade.

Sendo uma matriz identidade, no Algoritmo Shuffle, ela é negligenciada, mas ainda assim conta para o cálculo de nleft e de nright do método (em termos de índices) para todas as matrizes que não forem deste tipo.

A alternativa proposta pelo Algoritmo Split é permutar os termos tensoriais, utilizar o Algoritmo Esparso para escolher elementos das matrizes e calcular os índices onde devem ser multiplicadas nos vetores de entrada e de saída e determinar um ponto de corte onde nada mais é necessário para executar o método de solução.

Cabe ressaltar ainda que o Algoritmo Split, quando posiciona todas as identidades para a parte estruturada e trabalha apenas com os AUNFs que correspondem as taxas dos eventos sincronizantes, não são gerados fatores normais e, ocorrendo isso, não é necessário que os vetores auxiliares sejam passados para o resto dos fatores normais, como ocorre na abordagem Shuffle.

Este fato é uma limitação quando deseja-se resolver modelos com paralelização do método, o que não ocorre no Split, que precisa apenas dos AUNFs que são gerados para montar seus vetores auxiliares.

O custo gasto para reordenar o termo tensorial, calcular alguns índices auxiliares e utilizar esses índices ao longo do método de MVD é negligenciável ao utilizar o Algoritmo Split, como constatado em todos os experimentos.

Verificou-se que a maioria dos modelos considerados executaram mais rápido que o Algoritmo Shuffle com ou sem permutação, onde a tabela com os AUNFs ficou dentro do limite aceitável de tolerância.

Com o uso dos reordenamentos, constatou-se que a memória requerida sempre ficou dentro de um patamar aceitável, sendo o único efeito limitador o tamanho do vetor estacionário de probabilidade.

Entretanto, o mesmo ocorre com o Algoritmo Shuffle.

Dada a relativa memória utilizada para salvar os AUNFs requerida inclusive quando o PSS é elevado, pode-se afirmar que o método somente não executará para os mesmos limites que são impostos ao Shuffle, estimado atualmente em 65 milhões de estados.

Se a memória for realmente uma preocupação, basta executar o Algoritmo Split cortando o termo tensorial antes da primeira matrix, ou seja, nesse caso, adotar a prática do Algoritmo Shuffle.

Um aspecto que não foi estudado até o presente momento é o efeito das dimensões das matrizes (principalmente quando não correspondem à identidades) na solução do modelo.

Esta variável pode ser melhor estudada no modelo Mestre-Escravo, que possui um autômato modelado como um Buffer, ou seja, uma região temporária de memória em uma determinada problemática (este tipo de modelagem é bastante utilizada em sistemas paralelos e distribuídos, sendo útil para verificar quando estas estruturas chegam aos seus limites ou quando estão subutilizadas).

Esses estudos podem alterar significativamente o que se sabe sobre o Algoritmo Split pois, na parte estruturada, na parte da geração dos fatores normais, um grande bloco será descartado quando a matriz em questão possuir uma grande dimensão.

Maiores estudos nesse sentido devem ser conduzidos para um maior entendimento sobre o comportamento do método quando existem matrizes com elevadas dimensões.

Por exemplo, o modelo Mestre-Escravo pode redefinir o tamanho do buffer para possuir uma faixa de valores que testem o efeito das dimensões no método, com o cuidado de não atingir os limites de memória, visto que este exemplo, para 10 Mestres, o PSS é de 43 milhões.

O tamanho da lista de AUNFs necessárias para cada modelo, levando-se em consideração todos os eventos, dita tanto a memória a ser gasta quanto a complexidade em termos de multiplicações em ponto flutuante requeridas.

Um modelo que possua eventos sincronizantes que não afetem muitos outros autômatos possuirão uma lista menor de escalares para serem multiplicados no vetor.

E essa lista de escalar mais os índices de entrada e saída no vetor de solução indicam a memória necessária para o método, caso a parte estruturada só possua matrizes do tipo identidade.

Por fim, faz-se necessária uma discussão das questões sobre a convergência do modelo.

Sabese que um modelo, de acordo com as taxas utilizadas, pode demorar para convergir.

A extração de índices de desempenho só pode ser feita quando este processo acabou.

Ao acelerar a solução de MVD, os resultados são produzidos em uma quantidade menor de tempo.

Normalmente, para um modelo que diverge, ou seja, que não converge, a melhor maneira de tratá-lo é utilizando-se análise transiente.

Esta análise permite que se escolha um momento para interromper o processo de MVD e usar esse vetor resultante como a solução do modelo.

O Algoritmo Split, ao ser executado de forma mais eficaz para alguns modelos, torna maior esse limite de escolha de se realizar análise transiente ou convergência.

Trata-se de mais uma vantagem de se adotar as estratégias de corte oferecidas pelo Algoritmo Split.

A transposição de sistemas do mundo real para modelos analíticos permite que sejam inferidos índices de desempenho que atestam a sua qualidade e o seu comportamento.

Estas variáveis auxiliam o processo de tomada de decisões uma vez que ao abstrair os problemas quanto à sua operação fundamental é possível entender como desempenhará seus processos internos.

Neste sentido, a área da Avaliação de Desempenho de sistemas e Modelagem Estocástica auxilia no entendimento e mapeamento de sistemas complexos possibilitando análises com base nos resultados numéricos produzidos.

Estes mecanismos são utilizados na descoberta de eventuais problemas e gargalos em sistemas antes que estes sejam colocados fisicamente em produção, isto é ,compra de máquinas para um cluster, aumento do número de servidores em uma empresa, entre outros.

Esta abordagem analítica proporciona o cálculo computacional de índices de desempenho que auxiliam os modeladores a apropriadamente dimensionar seus sistemas otimizando o funcionamento interno dos sistemas.

Os índices calculados variam de sistema para sistema bem como as modelagens efetuadas, sendo fundamentalmente baseadas na experiência e criatividade dos usuários dos formalismos.

Este capítulo resume o trabalho efetuado e lista as contribuições.

O capítulo finaliza com uma discussão sobre os trabalhos futuros.

Resume os objetivos da tese, representações de sistemas são mapeadas para modelos, que por sua vez são descritos através de descritores, que os representam como um sistema markoviano para análise.

A partir do descritor, métodos de MVD são necessários para tratar tais estruturas não triviais, entretanto, dado o Algoritmo Split, desconhece-se como efetuar plenamente a divisão de cada termo tensorial bem como as minúcias do tratamento de taxas funcionais.

Este trabalho descreveu os formalismos estruturados de solução mais utilizados no contexto de avaliação de desempenho de sistemas, mostrando suas principais vantagens e desvantagens ao serem adotados para diferentes aplicações de problemas existentes atualmente.

A partir destas descrições, foram estudados mecanismos para composição de modelos mais abstratos, capturando as características fundamentais do funcionamento dos sistemas.

Estas descrições são utilizadas para a construção de descritores markovianos (ou Kronecker) que ao serem operados por propriedades da Álgebra Tensorial, representam a matriz de ocorrências de taxas que equivale à Cadeia de Markov do sistema em questão.

Uma vez que o modelo foi transposto para um formato tensorial e, por conseguinte, descrito através de um descritor markoviano, a literatura propõe diferentes algoritmos para multiplicar um vetor por tais estruturas, sendo os mais importantes o Algoritmo Esparso, o Algoritmo Shuffle e o Algoritmo Split.

Tais algoritmos fornecem formas únicas de tratamento para a MVD e são documentados e utilizados para o cálculo computacional do vetor de probabilidades estacionário ou transiente, que representa a probabilidade de permanência em cada estado de um sistema.

Estes índices de desempenho são utilizados para analisar um sistema e prever comportamentos ou antecipar problemas antes que estes sejam fisicamente instalados.

Esta tese mostrou que, dada a existência de descritores, onde estes são decompostos em somas de produtos tensoriais que representam os eventos do sistema, é possível não apenas alterar a ordem das matrizes mas sim aproveitar as características internas do descritor para realizar menos operações matemáticas reduzindo o tempo a ser gasto por iteração.

Estas escolhas foram devidamente implementadas em uma ferramenta, a qual foi chamada de GTAexpress.

Este software foi executado para diversos modelos e classes, com taxas constantes ou funcionais, com o propósito de descobrir e validar maneiras pelas quais fossem possíveis organizar as matrizes internas dos descritores e dividí-las da melhor forma possível, objetivando a aceleração do processo de MVD e consequentemente, o processo da descoberta da estacionariedade como um todo.

Resultados foram mostrados diversos modelos e diversos experimentos onde o corte foi modificado para atestar o ganho em termos de multiplicações de ponto-flutuante.

As descobertas foram comentadas e discutidas, sendo necessário agora, pensar nos próximos desenvolvimentos deste trabalho, objeto deste capítulo e melhor explicado nas seções seguintes.

Um dos maiores desafios em modelagem computacional de sistemas é o de capturar as características e a semântica operacional de problemas, descrevendo-os através de um formalismo.

Entretanto, apenas representá-lo através de primitivas de mapeamento que atestem a sua funcionalidade não é suficiente, ou seja, as modelagens devem ser usadas em conjunção com a solução do sistema de equações produzido, fornecendo os índices de desempenho associados e permitindo que o sistema seja melhor analisado.

O uso de tensores é justificado pelo fato de não ser necessário o armazenamento da matriz de transição que contém as taxas entre os estados de um modelo.

Através de propriedades da Álgebra Tensorial, opera-se sobre esta matriz realizando-se a MVD sem precisar gerar esta matriz de tamanho potencialmente alto.

Os algoritmos Esparso e Shuffle presentes na literatura abordam a técnica de maneira distinta, enquanto o primeiro necessita muita memória e poucos cálculos para encontrar os elementos da matriz, o segundo é extremamente eficiente em memória mas são necessários muitos cálculos de índices.

Portanto, a definição do algoritmo Split, ao usar as vantagens e desvantagens dos algoritmos Esparso e Shuffle, compensa significativamente o seu uso, sendo um melhor compromisso para tratamento dos termos tensoriais que definem um descritor Kronecker.

Dadas as características das modelagens, observou-se também que, dependendo do modelo, o Split não necessita de quantidades elevadas de memória, o que amplia o seu uso no contexto da MVD.

Neste sentido, o trabalho desenvolvido auxiliou o processo da modelagem, ao descrever as operações essenciais para a definição de descritoresmarkovianos.

Foram descritos e estudados formalismos presentes na literatura e foi proposta uma nova forma de tratamento para descritores definidos a partir de taxas constantes ou funcionais que quebra os termos tensoriais minimizando o tempo gasto pelo método daMVD por iteração.

Ao utilizar diferentes estratégias de corte para tais termos, constatou-se que algumas classes demodelos não necessitavamde quantidades excessivas de memóriamas, mesmo assim, aceleravam o processo da MVD.

Ao estudar tais classes, observou-se que apresentavam características únicas tais como alta esparsidade (poucos elementos não nulos dentro de cada matriz do termo tensorial) e baixo envolvimento entre as demais entidades do mesmo termo (o que foi definido como possuidor de baixo Grau de Dependência Constante ou Generalizado).

Esta métrica é crucial para inferir onde será fixado o corte do termo tensorial e onde a função (caso presente), em última análise, convertendo descritores ATG em ATC em tempo de execução.

Os resultados mostraram-se bons para modelos com as seguintes características.

Poucos eventos presentes em modelos sincronizam suas atividades envolvendo todos ou a maioria dos componentes (autômatos, processos, módulos, componentes, etc) do sistema.

Poucas funções necessitam operar sobre os estados de muitos outros componentes.

Para o caso onde não existam taxas funcionais, os modelos com as características presentes acima, além de possuírem descritores com termos tensoriais esparsos, possuem diversas matrizes do tipo identidade que, ao serem tratadas pelo algoritmo Shuffle após a fixação do ponto de corte e a descoberta da permutação, serão desconsideradas.

Para o caso funcional, é necessário observar os parâmetros das funções ou então converter o modelo baseado em ATG para ATC, explicitamente.

Ao realizar esta tarefa, será preciso aumentar o número de eventos para que sejam definidos modelos equivalentes, normalmente criando eventos sincronizantes que forçam que este ocorra de acordo com os parâmetros das funções.

Compor um grande espaço de estados, descobrir seus estados atingíveis e armazená-lo não é mais um problema, visto as técnicas existentes para este propósito tais como gerações simbólicas ou baseadas em diagramas de matrizes.

O problema agora é encontrar o vetor estacionário de probabilidade utilizando métodos numéricos de última geração que acelerem o processo de convergência.

O presente trabalho alinha-se com este propósito, ao definir formas de se reduzir as operações necessárias ao tratar cada termo tensorial propondo novas formas de estruturá-lo com permutações e divisões para tratamento dos diferentes algoritmos de MVD.

Este trabalho definiu as estratégias para a solução de descritores constantes e generalizados ao mesmo tempo que comparou estas diferentes possibilidades para serem utilizadas pelo Algoritmo Split.

Com os resultados obtidos, descreveu-se um algoritmo que calcula o melhor ponto de corte para termos tensoriais, observando a memória gasta e o tempo ganho, reorganizando-os para efetuar menos operações numéricas.

O melhor caso observado foram modelos com esparsidade alta onde detectaram-se grandes blocos com identidades, ao utilizar permutações que privilegiassem estas descobertas.

As abordagens anteriores possuíam características extremas, isto é, efetuavam a MVD de forma extremamente rápida ocupando vastas quantidade de memória ou extremamente eficiente em termos de gastos em memória mas levavam muito tempo para atingir a solução.

Este trabalho combinou estes dois fatores primordiais da solução de descritores markovianos e propôs uma técnica híbrida para descritores constantes e generalizados que utiliza um total de memória razoável, realizando a MVD em menos tempo.

O Algoritmo Split foi refinado para aumentar a variedade de modelos que resolve não importando se o modelo está definido em ATG ou ATC.

As pesquisas anteriores desconheciam as implicações do algoritmo ao lidar com taxas funcionais, sendo utilizados modelos definidos com esta premissa ao longo da tese.

Foram elencadas as principais problemáticas ao se lidar com termos tensoriais generalizados, enumerando as formas de se dividi-los sempre respeitando os parâmetros das funções, ou seja, não permitindo indefinições ao avaliar os elementos funcionais.

O motivo pelo qual a técnica apresentada nesta tese é superior as técnicas desenvolvidas anteriormente deve-se ao fato de que, na realidade, aplicam-se transformações no descritor tensorial, permutando as ordens originais de seus termos em busca de regiões contíguas contendo blocos grandes com matrizes do tipo identidade do lado estruturado e destacando partes com elementos esparsos, do lado esparso.

A descoberta destes blocos inferem os locais onde faz-se necessário multiplicar os valores escalares pelo vetor de probabilidade, salvando-os no vetor de saída.

A informação contida em cada AUNF detém esta informação, possibilitando que apenas sejam aproveitadas as regiões contendo valores não nulos diferentes de identidades.

Como mencionado anteriormente, os melhores resultados do Algoritmo Split para descritores baseados em ATC são verificados quando em cada módulo de um sistema as interações e sincronismos são baixos, privilegiando a formação de um descritor com termos tensoriais esparsos e com muitas identidades.

Entretanto, uma importante primitiva de modelagem é a utilização de taxas funcionais, ocorrendo em transições que verificam o estado de outros módulos de forma dinâmica.

Dada a possibilidade de se converter um modelo definido em ATG para ATC, resta saber em quais casos esta tradução implicará no máximo ganho quando o Algoritmo Split for executado pois, dependendo do modelo, esta premissa pode ou não ser constatada com eficiência.

Um outro eixo alvo de pesquisas futuras é o de determinar as classes de problemas que melhores executarão o Algoritmo Split, detectando as principais características e estudando a composição dos sistemas.

Este fato proporcionará que sejam descobertas outras classes de modelos, onde as entidades envolvidas operam de forma independente e somente às vezes necessitam sincronizar suas atividades com outros elementos.

Neste sentido, aplicações paralelas possuem estas características, sendo desejável que os nodos ou cores de processamento desempenhem atividades internas mas comuniquem o término ou outra característica entre os demais componentes do modelo, sincronizando suas atividades.

Outros problemas também podem ser atacados, tais como a quantificação de comunicação em equipes distribuídas globalmente, sincronizando, por exemplo, a finalização de um módulo de um sistema, para a área da Engenharia de Software.

Quaisquer problemas onde exista esta qualidade de independência e sincronização global pode ser alvo de descrições modulares tais como as apresentadas nesta tese.

Ao permitir que os modeladores pensem apenas nos problemas e informem como o sistema opera de forma local e global, torna transparente a forma de solução que será adotada, neste caso, para resolver o problema e atestar o seu funcionamento através dos índices quantitativos de desempenho.

Métodos de paralelização desta técnica devem ser desenvolvidos tendo-se como base outras informações.

Os resultados aqui apresentados mostraram os cortes para uma execução sequencial do algoritmo.

Entretanto, estes mesmos cortes podem ou não apresentar os mesmos desempenhos em soluções paralelas sendo necessária a realização de outros estudos para delimitar os cortes a ser adotados para cada caso.

Outras premissas devem ser levadas em consideração tais como a quantidade de trabalho a ser realizada por cada nodo de uma rede, se é melhor enviar cada termo tensorial para um nodo diferente e as implicações existentes ao sincronizar o vetor de probabilidades, que deve ser utilizado por todos os nodos a cada iteração.

Sobre avanços em termos de modelagem, podem ser considerados sistemas baseados no conceito de Multi-layers e sua formalização.

Este tipo de sistemas são usados para representar sub-sistemas internos com independência forte mas que eventualmente sincronizam atividades globalmente, em conjunção com outros sub-sistemas.

Trata-se de modelos dentro de modelos, sendo que existem interações entre os modelos.

Tais modelagens podem ser usadas para descrever comportamentos observados em redes distribuídas tais como baseadas em pares (Peer-to-Peer) ou até mesmo para testes estocásticos de sistemas, descrevendo os módulos que o compõe e suas operações.

Para estas modelagens será necessário ampliar a descrição dos modelos para aceitar este tipo de primitiva bem como fornecer soluções que talvez utilizem decomposições, baseadas nas mesmas ideias de Quase Completamente Decomponíveis (Nearly Completely Decomposable), já estudado anteriormente no contexto de Cadeias deMarkov.

A própria adição de novas primitivas de modelagem pode ser estudada, oferecendo novos meios de descrever realidades em uma linguagem não ambígua com vistas à análise de desempenho.

A modelagem e a solução devem ser o mais transparente possíveis para os modeladores.

Enquanto que o primeiro grupo conhece o problema a ser descrito, o segundo processo conhece a formação do descritor e, de acordo com a complexidade dos métodos existentes, sabe a melhor forma de quebrar os termos tensoriais efetuando a MVD de forma otimizada para o problema.

O usuário, em última análise, apenas deseja que o seu sistema seja convertido em números que possam ser interpretados para inferir características dos problemas mapeados.

A solução do sistema linear que descreve o sistema deve utilizar as técnicas propostas para minimizar o tempo necessário para atestar ou não a existência de estacionariedade.

O ideal seria também, caso o sistema possuísse um número de estados onde uma solução analítica não fosse possível (para o caso do GTAexpress este número é atingido quando o PSS é maior que 65 milhões de estados), que, internamente, executasse primitivas de simulação, retornando amostras de estados do vetor estacionário para análise pelos usuários.

Por fim, outros eixos de pesquisa podem ser direcionados para o estudo de aproximações da solução, descoberta de agregações entre os termos tensoriais (e as implicações envolvidas, por exemplo, mesmos cortes e mesmas transformações em termos de permutações), mecanismos para operar apenas com os estados atingíveis com o Split e solução simbólica do sistema linear, para citar algumas das possibilidades.

Esta tese desenvolveu uma nova forma de se multiplicar um vetor por um descritor Kronecker e encontrou uma forma mais otimizada de realizar esta tarefa com base em permutações das ordens originais dos termos tensoriais e em cortes que criam uma matriz agregada de forma a encontrar grandes blocos com identidades no contexto dos problemas.

Como observado, outras técnicas podem ser adaptadas ou utilizar o Split para acelerar ainda mais a convergência do processo, seja através da descoberta de novas classes de modelos ou através de mecanismos que aproximem os resultados ou forneçam novas primitivas de modelagem.

Para todos os casos, o principal objetivo é aumentar o poder de representação e descrição de sistemas ao mesmo tempo que facilita os meios de solução existentes antecipando a fase de refinamento e análise.

