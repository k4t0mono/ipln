Dentre as técnicas de avaliação de desempenho de sistemas computacionais usadas atualmente, estão a monitoração, a simulação e os métodos analíticos.

Esta última tem sido frequentemente adotada para resolução de sistemas, pelo fato de disponibilizar resultados bastante precisos às aplicações que os utilizam.

No entanto, o emprego dos métodos analíticos, implicam na resolução de um sistema de equações composto por complexas estruturas tensoriais.

Dentre as técnicas de modelagem para estes métodos, formalismos estruturados sobressaem-se sobre formalismos não estruturados, por apresentarem soluções compactas e eficientes.

Desta forma evita-se um problema clássico enfrentado pelo formalismo não estruturado conhecido como Cadeias de Markov, que é a explosão do espaço de estados.

Existem ferramentas desenvolvidas para a resolução de sistemas de equações gerados para diferentes formalismos.

Tais ferramentas utilizam-se de métodos iterativos e algoritmos especializados, para realizar operações em álgebra tensorial, a fim de gerar um vetor de probabilidades para o modelo apresentado.

Este vetor corresponde à probabilidade de permanência em cada um dos estados do sistema.

Dentre os algoritmos para realizar a multiplicação vetor-matriz interna aos métodos numéricos iterativos, existem o Sparse, o Shuffle e o recente método híbrido Split, que contempla um tratamento esparso otimizado de termos tensoriais como uma forma de acelerar a execução do método.

A complexidade de modelagem e implementação inerente às aplicações computacionais atuais tem tornado essencial a utilização de técnicas de avaliação de desempenho para auxiliar nesta tarefa.

A escolha da técnica mais adequada em uma determinada situação deve considerar critérios como a disponibilidade de tempo, recursos computacionais disponíveis e o nível de precisão requerido nos resultados.

Existe uma grande variedade de métodos numéricos para solução de modelos analíticos de avaliação de desempenho atualmente, porém para cada situação específica pode ser mais vantajoso utilizar uma ou outra abordagem.

Ou ainda, pode ser interessante utilizar-se de combinações entre estas técnicas, buscando resultados mais efetivos em termos de desempenho e confiabilidade.

Métodos analíticos, especificamente, consistem em modelar um sistema real através de relações matemáticas existentes no próprio funcionamento do sistema.

Para isto, utilizam-se abstrações de alto nível que fornecem o comportamento real do sistema, contendo características funcionais suficientes para realizar uma avaliação segura, considerando certo nível de tolerância.

Através de relações matemáticas pode-se descrever o sistema como um conjunto finito de estados possíveis, definir transições entre estes estados rotuladas por eventos e as taxas em que os mesmos ocorrem.

Estes componentes são apresentados na forma de um grafo ou autômato, denominado Cadeia de Markov (CM), que também pode ser representado por uma matriz ou Gerador Infinitesimal Q contendo as taxas ou probabilidades destas transições.

A CM é um formalismo analítico não estruturado amplamente utilizado por sua facilidade de representação e simplicidade de solução.

Descrevem o funcionamento de um sistema através de um conjunto de estados possíveis e de transições entre estes estados, seguindo taxas definidas por leis exponenciais.

Porém, uma de suas limitações é que pode ocorrer uma explos ão do seu espaço de estados, o que as tornam intratáveis através de uma única matriz de transição correspondente.

Contudo, dentre as alternativas de modelagem conhecidas, sobressaem-se formalismos estruturados, como por exemplo, Stochastic Automata Networks (SAN) Perfomance Evaluation Process Algebras (PEPA) e Generalized Stochastic Petri Nets (GSPN).

Estes formalismos vêm com soluções numéricas mais eficientes do que os métodos analíticos não estruturados como as CM.

Formalismos estruturados destacam-se como alternativas paramanter os requisitos dememória gerenciáveis, ou seja, são soluções de representação e armazenamento de modelos Markovianos que permitem descrevê-los de uma forma mais compacta e eficiente.

Basicamente suas novas estruturas de armazenamento são baseadas em matrizes esparsas, utilizando operações da álgebra tensorial para representar as interações ou comportamentos independentes das mesmas.

Os formalismos estruturados em sua maioria representam de forma implícita o Gerador Infinitesimal Q da CM correspondente através de um conjunto de operações tensoriais, chamado de Descritor Markoviano (DM), que se apresenta como uma forma econômica de armazenar os modelos, no que diz respeito à memória.

O DM trata-se de um somatório de produtos tensoriais entre matrizes de transição.

Um DM evita o problema da explosão do espaço de estados, crítico em CM, pois apresenta um formato compacto e nunca é expandido em uma única grande matriz, como é o caso do Gerador Infinitesimal Q.

Cabe também ressaltar que as taxas ou probabilidades presentes nestas matrizes esparsas podem ser valores constantes (positivos ou negativos, no caso das taxas e ajustes diagonais) ou mesmo elementos funcionais.

Os atuais formalismos tendem a se utilizar deste recurso de taxas funcionais como mais uma primitiva poderosa para descrição de modelos.

Logo utilizar-se da estrutura de armazenamento para otimização das soluções numéricas torna-se também o foco das proposições de novos métodos e ferramentas baseados em álgebra Tensorial Clássica (ATC) ou Generalizada (ATG).

Dando seqüência ao estudo comportamental de um modelo, busca-se então a probabilidade de permanência nos estados do sistema.

Para isto, procura-se um vetor de probabilidades p, denominado auto-vetor, cuja multiplicação por Q resulte em um vetor nulo (não trivial).

À medida que os sistemas analisados crescem, torna-se necessário utilizar o DM ao invés de Q, uma vez que a memória necessária para armazenar o sistema de equações lineares pertinentes ao processo cresce além dos limites computacionais atuais.

Devido a este fato, o uso de soluções iterativas também aparece como alternativa aos métodos diretos para obtenção de p.

Isso se justifica, uma vez que seu consumo de memória é menor e, desta forma, é possível atingir um equilíbrio entre a quantidade de memória e o tempo de processamento necessário para que uma solução seja atingida.

No que diz respeito à realização da multiplicação vetor-descritor (MVD) que é a operação básica para a resolução de modelos estruturados, o uso de algoritmos iterativos aparece como uma alternativa interessante.

Por se tratarem de processos que aproximam a solução a cada iteração, é possível controlar o critério de parada tanto pela precisão obtida quanto pelo tempo de execução do algoritmo.

Tais algoritmos consistem na sucessiva multiplicação de um vetor por um conjunto de matrizes esparsas que realiza operações tensoriais.

A cada iteração, o vetor se aproxima da solução estacionária (ou transiente) do modelo descrito pela matriz, sendo que o algoritmo considera-se encerrado quando um critério de parada preestabelecido é atingido.

Utilizam-se hoje propriedades da ATC para representar as interações entre os componentes dos modelos.

Seguindo os avanços dos formalismos na direção do uso de funções, volta-se também para utilização de sua extensão, a ATG, cujas propriedades lidam com dependências funcionais e novos tipos de dados.

As soluções numéricas também acompanham este avanço incluindo em suas implementações o suporte a estas novas primitivas.

Pesquisas estão direcionadas às técnicas de exploração de tensores generalizados para realizar a multiplicação vetordescritor.

Cada uma das soluções vigentes, possuem vantagens no que diz respeito à otimização e ganho de desempenho, dependendo de certas características do DM.

As soluções a serem analisadas, são as soluções Sparse, Shuffle e Split.

As soluções mencionadas comp-oem o estado da arte em métodos analíticos para avaliação de desempenho.

A idéia principal é realizar uma análise precisa em cada uma destas soluções explorando o que existe de melhor nos métodos para a MVD.

A definição do melhor método a ser adotado pode contribuir com a redução do tempo entre as etapas realizadas nesta operação.

No que diz respeito ao tempo de execução, os métodos numéricos iterativos devem resolver os problemas com um mínimo de iterações possíveis.

O número de iterações necessárias para calcular a solução com uma precisão estabelecida depende do método escolhido.

Tais métodos, para que sejam utilizados na solução de formalismos estruturados, sofrem algumas adaptações devido ao formato tensorial do descritor, que deixa de ser uma única grande matriz esparsa (Gerador Infinitesimal), e torna-se um conjunto de tensores (Descritor Markoviano).

Um formalismo, que se utiliza da álgebra Tensorial para sua resolução, é o formalismo SAN.

Este formalismo é composto por N autômatos e E eventos que serão utilizados na composição do DM.

Desta forma deseja-se encontrar um vetor de probabilidades p de forma que pQ = 0, utilizando métodos iterativos, não exigindo a construção explícita da matriz.

Uma das formas de obtenção do vetor p é dada por um algoritmo iterativo denominado Método da Potência, que consiste na sucessiva multiplicação de um vetor por uma matriz de transição.

Para que seja possível realizar tal operação, a dimensão do vetor deve ser igual à ordem da matriz, e após a solução a soma de todos os elementos do vetor deve resultar em 1.

Como motivação para o estudo destes métodos existem dois problemas cruciais relacionados aos formalismos estruturados baseados em CM, o tempo de execução e o consumo de memória.

Isto ocorre em função do grande número de estados, sendo assim em uma primeira abordagem, foram desenvolvidas técnicas que minimizam este problema.

Como por exemplo, em SAN, é possível utilizar simetrias para minimizar o número de estados no modelo, reduzindo a carga computacional.

Ciardo e Trivedi exploram sub-redes quase independentes em um processo iterativo onde a solução global é obtida a partir de soluções parciais em GSPN.

O objetivo deste trabalho é realizar uma análise, no estado da arte, de soluções que integram métodos iterativos existentes, a fim de identificar as principais características, vantagens e desvantagens apresentadas por cada uma delas.

Para isso será descrito o funcionamento de três algoritmos, que implementam as soluções Sparse, Shuffle e Split, apresentando as equações que definem seus custos computacionais, em relação ao número de multiplicações em ponto flutuante.

O objetivo também abrange estudar modelos comparando a resolução dos mesmos através do uso dos algoritmos mencionados, a fim de fazer uma análise comparativa levando em consideração o tempo de execução e a quantidade de memória utilizada.

Ressalta-se que o objetivo também inclui citar os fatores relevantes ao custo computacional, que consequentemente, possam causar perda de desempenho nos quesitos de memória e processamento.

Nas seções anteriores foram abordados alguns conceitos gerais sobre técnicas de avaliação de desempenho.

No capítulo 2, destacam-se conceitos de álgebra tensorial, indispensáveis para a compreensão das soluções numéricas apresentadas no capítulo 3, onde é feita a descrição dos algorítmos Sparse, Shuffle e Split.

No capítulo 4 são discutidos o custo com memória, tempo de processamento, e outros critérios parametrizados para avaliar o desempenho das três soluções apresentadas.

Por fim, no capítulo 5 são apresentadas as conclusões deste trabalho, considerando os resultados obtidos nas análises.

Para que se possa compreender o funcionamento e os ajustes adotados nos métodos iterativos é necessário conhecer alguns conceitos da álgebra tensorial.

A seguir será descrita a álgebra Tensorial Clássica (ATC) e a álgebra Tensorial Generalizada (ATG), abordando suas principais características, a fim de compreender o processo de multiplicação e soma tensorial entre matrizes, que constituem as operações básicas de um DM.

A ATC é constituída basicamente por dois operados matriciais, sendo eles a soma tensorial, representada, e o produto tensorial.

Estas operações serão descritas a seguir.

Para entender a operação de Produto Tensorial entre uma matriz M de dimensão a1 × a2 e outra matriz N, de dimensão é necessário saber que o resultado corresponde a uma matriz R de dimensão.

Esta matriz R constitui-se de a1 × a2 blocos, cada um de dimensão ß1 × ß2.

Deve-se levar em consideração a qual bloco cada elemento pertence e sua posição interna dentro deste bloco para que se possa definí-lo na matriz resultante R.

No exemplo anterior têm-se duas matrizes, sendo uma delas a matrizM e a outra aMatriz N.

O produto tensorial entre ambas resulta na matriz R.

Esta operação está expressa na equação.

Na matriz resultante R é possível observar que existem quatro blocos divididos através de uma linha horizontal e uma linha vertical traçadas dentro da matriz.

Adotando um dos valores resultantes da matriz R, como o elemento c57 (c57 = a22b23) situado dentro do bloco (2, 2), ele apresenta também uma posição dentro deste bloco, que é a posição (2, 3).

O produto tensorial R = M é definido algebricamente pela atribuição do valor aijbkl ao elemento de posição (k, l) do bloco (i, j).

Em outras palavras aij é um elemento da matriz M, e bkl é um elemento da matriz N.

A soma tensorial de duas matrizes quadradas M e N, é definida como a soma convencional dos fatores normais gerados por estas matrizes.

Para dar seqüência na abordagem dos operadores da ATC, é necessário conhecer as definições de fator normal, para então introduzir os conceitos da soma tensorial.

Fator normal é o produto tensorial de uma matriz quadrada por uma matriz identidade.

Com uma matriz quadrada M e uma matriz identidade1 In, os fatores normais da equação são possíveis.

No exemplo a seguir é apresentada uma matriz M e uma matriz identidade I3.

Em seguida é apresentada a matriz resultante, para os dois casos apresentados pela equação.

Note que o resultado do produto tensorial é uma matriz cuja dimensão é igual à ordem da matriz M vezes a ordem da matriz identidade I, entretanto a localização dos elementos aparecem em posições diferentes comparando a operação MI3 com a operação I3M.

Esta característica será importante para compreender o uso dos métodos numéricos mencionados no Capítulo 3.

Após definir alguns conceitos sobre fator normal, mencionados na seção anterior, é possível abordar a soma tensorial.

Sabendo que a soma tensorial entre duas matrizes é também a soma ordinária de fatores normais, a equação define a operação da soma tensorial.

Aplicando a equação, no exemplo a seguir é obtida a matriz resultante R, que corresponde a soma tensorial entre as matrizes M e N.

Algebricamente, a soma tensorial R é definida pela atribuição do valor aijdkl + dijbkl ao elemento de posição (k, l) do bloco (i, j).

Uma observação a ser feita é que o operador produto tensorial tem prioridade sobre o operador soma tensorial e os dois operadores tensoriais têm prioridade sobre os operadores tradicionais de multiplicação (×) e de soma (+) de matrizes.

Soluções numéricas, com o objetivo de reduzir o custo computacional em memória (referente ao número de operações de somas e multiplicações realizadas) para encontrar o vetor de probabilidades, utilizam-se de algumas propriedades da ATC para sua resolução.

As características da ATC serão mencionadas a seguir, a fim de facilitar a compreensão das técnicas utilizadas por esses métodos posteriormente.

A ATG, também é constituída por dois operados matriciais, soma tensorial generalizada.

A ATG constitui uma extensão da ATC, sua principal característica, constitui-se no emprego de objetos que correspondem a funções discretas sobre as linhas das matrizes.

A diferença principal com relação à ATC é a introdução do conceito de elementos funcionais2.

A utilização de funções para definir taxas e probabilidades permite associar a um mesmo evento diferentes valores.

As taxas e probabilidades funcionais são expressas por funções que levam em consideração os estados atuais dos autômatos de um modelo, variando desta forma seu valor, conforme os estados em que se encontram os autômatos envolvidos na função.

Assim como as taxas de ocorrência podem ser expressas por funções, o mesmo pode ocorrer com as probabilidades de cada evento.

Probabilidades funcionais são exatamente iguais às funções usadas para definir taxas de ocorrência.

Supondo que um elemento funcional b depende da matriz M se algum índice de linha da matriz M pertencer ao conjunto de parâmetros desse elemento funcional.

Um parâmetro de um elemento funcional é denominado para toda matriz da qual o elemento funcional é dependente.

Uma matriz que contém ao menos um elemento funcional dependente da matriz M é dita dependente da matriz M.

Os parâmetros de uma matriz são a união dos parâmetros de todos seus elementos funcionais.

A seguir será defina a operação de produto tensorial generalizado, a fim de dar seqüência ao estudo.

Tomando como exemplo duas matrizes M(N) e N(M), sendo N um parâmetro da matriz M, e M, um parâmetro da matriz N, tem-se a operação de produto tensorial generalizado, representada através da equação.

A denominação M(N) se dá pois os elementos da matriz M variam em função dos elementos da matriz N.

Da mesma forma a denominação N(M) se dá pois os elementos da matriz N variam em função dos elementos da matriz M.

A seguir será definida a soma tensorial generalizada.

A equação demonstra a operação da soma tensorial generalizada, fazendo uso dos conceitos abordados na seção, sobre fator normal, utilizando o produto tensorial generalizado entre matrizes identidades.

O DM é uma forma compacta de representar o Gerador Infinitesimal Q de uma CM através de um conjunto de matrizes menores.

A resolução do DM resulta por sua vez no próprio Q, entretanto fazendo uso das propriedades da álgebra Tensorial, é possível chegar à solução p, sem a resolução completa do DM, a fim de reduzir o custo computacional exigido para sua resolução.

A Equação mostra como p pode ser deslocado para dentro do somatório, através do uso da propriedade distributiva apresentada na seção, sobre as propriedades da ATG.

A principal operação de um método iterativo torna-se então a multiplicação do vetor p por cada produto tensorial somando seus resultados.

Esta operação pode ser observada na equação.

Desta forma os desafios propostos pelas soluções numéricas que serão abordadas neste trabalho, são realizar esta operação sem resolver de uma só vez o produto tensorial, economizar multiplicações intermediárias e reduzir o consumo de memória.

A seguir serão descritos os algoritmos utilizados para obtenção de p, sendo eles a solução Sparse, ideal para produtos esparsos, a solução Shuffle, ideal para produtos densos e o Split, que consiste em uma solução híbrida entre o Sparse e o Shuffle.

A solução Sparse, caracteriza-se por ser uma solução ideal para multiplicar um vetor de probabilidades por um produto tensorial de matrizes esparsas1.

Inicialmente, o algoritmo monta uma tabela representando todos os elementos não nulos que estão presentes no tensor resultante do produto tensorial envolvido no processo.

A primeira, das três colunas que cada linha contém na tabela, corresponde ao elemento do tensor resultante, definido por e, sendo que as demais correspondem a índices utilizados no processo de multiplicação.

O primeiro elemento desses índices, representa a posição do vetor de probabilidades pelo qual o elemento da tabela deverá ser multiplicado, sendo este denominado de basein.

O segundo representa a posição em que o resultado da multiplicação deverá ser armazenado, denominado de baseout.

No início de cada iteração, é necessário atribuir o valor zero no vetor resultante para que o processo seja realizado corretamente, visto que este irá acumular o resultado das multiplicações.

Desta forma ao realizar uma multiplicação, o valor resultante deve ser incrementado no vetor de resultados na posição indicada, uma vez que esta posição pode repetir-se em diferentes linhas da tabela.

O algoritmo 1 apresenta a solução Sparse, permitindo observar suas características.

Como as linhas da tabela são usadas uma vez por iteração, é guardado pelo algoritmo somente os valores utilizados na iteração em questão, neste caso as variáveis e, basein e baseout, contidas nas linhas 5, 6 e 7 do algoritmo, dentro do laço da linha 4.

Pode ser observado o custo teórico desta solução, calculando quantasmultiplicações em ponto flutuante o algoritmo irá realizar.

Sendo que N é o número de matrizes do produto tensorial e nzi o número de escalares a serem multiplicados, ou seja, os elementos não nulos da i-ésima matriz.

O termo N1 corresponde às multiplicações combinadas entre cada matriz N.

O termo +1 representa a multiplicação do vetor por cada escalar das N matrizes.

Um parâmetro importante a ressaltar neste algoritmo, é que as multiplicações do vetor pelo escalar são realizadas e logo em seguida armazenadas no vetor resultante, neste caso em baseout, reduzindo significativamente o uso da memória.

Em contrapartida caso a multiplicação entre as matrizes fosse realizada antes de armazenar o resultado em baseout o número de multiplicação seria bem menor, diminuindo o tempo de execução do algoritmo.

A deficiência desta abordagem é que conforme o número de matrizes do modelo tensorial aumenta, é exigida uma capacidade de memória cada vez maior para armazenar todos esses valores, uma vez que sua representação seria igual ao Gerador Infinitesimal Q da CM correspondente ao modelo avaliado.

Apresenta como pode ser obtido o custo computacional para a abordagem mencionada anteriormente, caso todos os valores de e, basein e baseout fossem carregados na memória.

O algoritmo que se utiliza da solução Shuffle para realizar a multiplicação vetor descritor, foi desenvolvido por Fernandes, Plateau e Stewart, e busca otimizar as operações para situações onde predominam elementos não nulos nas matrizes do DM.

Com a finalidade de alcaçar seu propósito, este algoritmo faz uso do produto tensorial.

Um tensor consiste na multiplicação de um conjunto de valores com diferentes dimensões, como por exemplo, um escalar por um vetor ou um vetor por uma matriz, cujo último enquadra-se melhor para esta aplicação.

Voltando para o contexto da solução Shuffle, deve-se decompor um produto tensorial em uma multiplicação de fatores normais, que consiste na multiplicação entre uma matriz Q e uma matriz identidade I, sendo que a multiplicação pode ocorrer de duas formas, QI e IQ.

É possível observar de acordo com a representação anterior, o produto tensorial entre N matrizes quadradas Q, onde i denomina-se o índice da matriz, e n sua ordem.

Decompondo as matrizes em fatores normais, apresentam-se novos produtos tensoriais envolvendo apenas uma matriz Q a cada iteração.

Os fatores normais apresentados dividem-se em três categorias.

A primeira categoria é quando as matrizes identidades encontram-se à direita da matriz Q, o segundo caso, é quando a matriz Q encontra-se entre as matrizes identidades, e o terceiro é quando as matrizes identidades encontram-se à esquerda da matriz Q.

Para resolver este sistema de equações, deve-se multiplicar o vetor p pelo primeiro fator normal, em seguida o resultado deve ser multiplicado pelo segundo fator normal, e assim sucessivamente, até que o último fator normal seja multiplicado.

Dividir o sistema em categorias, permite identificar a posição em que os elementos da matriz Q irão se encontrar no produto tensorial.

O exemplo a seguir, mostra a posição em que os elementos da matriz Q de ordem 2, irão se encontrar após a multiplicação por uma matriz identidade I3 (de ordem 3), sendo esta posicionada à direita no produto tensorial.

Cada elemento q(k,l) da matriz Q aparece nright vezes no tensor resultante.

A equação mostra a localização dos valores do tensor resultante, sendo que a varia de zero a nright.

Para o caso do fator normal onde a matriz identidade localiza-se a esquerda do produto tensorial, cada elemento q(k,l) da matriz Q aparecerá nleft vezes no tensor resultante, sua localização é dada pela equação, sendo que a varia de zero a nleft.

O formalismo SAN é um formalismo estruturado que se utiliza da álgebra tensorial para encontrar o vetor de probabilidade de um dado sistema.

Como já mencionado, este formalismo apresenta o DM que é uma forma simplificada do Gerador infinitesimal Q de CM.

Para que se possa compreender de forma clara a solução Shuffle, deve-se saber como o DM pode ser resolvido.

A seguir é feita uma abordagem sucinta sobre o DM, tomando como exemplo o formalismo SAN, a fim de ilustrar esta abordagem.

O DM de uma SAN é composto por uma parte local, e uma parte sincronizante.

A parte local, significa que o estado de um autômato A(1) não interfere no estado de um autômato A(N).

Em contrapartida, um evento sincronizante, representa sincronismo no disparo de transições, alterando o estado de dois ou mais autômatos.

Sua ocorrência se dá em todos os autômatos envolvidos, sendo que um deles coordena a sincronização.

Sabe-se que um dos grandes problemas enfrentados com CM é a explosão do espaço de estados, desta forma o modelo SAN utiliza uma maneira de representar o Gerador Infinitesimal correspondente, de uma forma compacta, através de um conjunto de pequenas matrizes, que permitem descrevê-lo através de um DM.

Corresponde ao DM, pode ser observado dois tipos de operações, sendo uma delas a operação de soma, representada pelo somatório, e operações de produtos tensoriais.

Dentre estes, a parte superior da matriz, permite observar operações de produtos tensoriais entre uma matriz Ql e matrizes identidades Ini, as quais correspondem ao fator normal, representando os eventos locais.

Na parte inferior, onde existem produtos tensoriais entre matrizes QE, são representados os eventos sincronizantes, sendo esses divididos ainda entre positivos e negativos.

Os valores negativos correspondem a ajustes diagonais, necessários para normalizar as matrizes.

A partir dessa breve definição, pode-se dar continuidade à solução Shuffle, apresentando a forma como ela resolve cada parte do DM.

Para multiplicar o vetor p pela parte local do DM, é necessário resolver os termos apresentados nas equações, sendo Q as transições locais que ocorrem em cada autômato.

Para resolvê-las cada termo deve ser multiplicado pelo vetor p, acumulando seu resultado em um vetor.

Após o término dessas multiplicações, o vetor é atribuído ao vetor p, repetindo o processo, de forma iterativa.

Para resolver a parte sincronizante do DM, multiplica-se o vetor p por cada evento sincronizante ei.

Neste caso a multiplicação ocorre tanto para a parte positiva, quanto para a parte negativa do DM.

O vetor conterá os resultados numéricos referentes às multiplicações do vetor p.

A equação expressa a operação completa das partes locais e sincronizantes.

Sabendo como a solução Shuffle resolve as partes locais e sincronizantes de um DM, pode ser apresentado o algoritmo 2, que localiza quais elementos do vetor p são necessários para realizar amultiplicação por cada fator normal, sendo que usa como base o caso emque existe umamatriz identidade à esquerda e outra à direita de Q para identificar a posição dos elementos q(i,j).

É utilizado na linha 7 do algoritmo, um vetor denominado z(in) que contém os elementos relacionados a p para multiplicar cada matriz Q.

O vetor z(out) armazena o resultado desta multiplicação, como pode ser observado na linha 10, sendo o vetor p atualizado com estes valores na linha 13.

É possível então, perceber que z(in) recebe o resultado da multiplicação de p pela matriz Q, atualizando o vetor p em um processo iterativo, após cada iteração.

Conclui-se que o produto tensorial poderia ser dividido em uma série de fatores normais, multiplicando p pelo primeiro fator normal, seu resultado pelo segundo fator normal, e assim sucessivamente.

Entretanto o Shuffle torna esse processo desnecessário, uma vez que consumiria muita memória.

A grande vantagem desta solução quando comparada com a solução Sparse, é o fato de consumir menos memória, por tratar de forma eficiente a separação do produto tensorial em fatores normais, sem precisar armazená-los na memória.

A desvantagem, porém, é que ocorre um número muito maior de multiplicações, o que acarreta em um alto custo no tempo de processamento.

Os termos nlefti e nrighti, são vetores de tamanho ni e o termo nzi, são elementos diferentes de zero na matriz Q.

A partir do custo observado nas soluções Sparse e Shuffle, nota-se que cada uma delas apresenta vantagens no que diz respeito ao consumo de memória e o tempo de processamento.

O equilíbrio entre uma matriz esparsa e uma matriz densa necessitaria então de uma solução híbrida entre ambos os casos mencionados.

A partir deste princípio, foi proposto uma solução denominada Split, que utiliza o que cada uma das soluções anteriores apresenta de melhor.

A seguir esta solução é apresentada.

A solução Split consiste em uma nova abordagem, que trata de forma eficiente o produto tensorial entre matrizes densas e esparsas.

Esta solução consiste em dividir os produtos tensoriais em dois conjuntos de matrizes.

Como existem dependência entre estes conjuntos, um deles é tratado pela solução Sparse enquanto o outro é tratado pela solução Shuffle.

A letra grega s mostra os pontos de divisão possíveis pela solução Split.

Pode-se observar que quando s é zero o comportamento da solução Split, torna-se análogo ao da solução Shuffle.

Da mesma forma para o outro caso extremo, onde s é igual a N, ou seja, é igual ao número de matrizes do produto tensorial, a solução Split comporta-se como a solução Sparse.

Para os demais casos o produto tensorial quebra-se em duas partes, sendo a parte da esquerda correspondente à solução Sparse, onde cada linha de uma tabela gerada conterá os índices de basein, baseout e o escalar e.

Em seguida, é montado um vetor pin, de acordo com basein, do tamanho de nright, o qual é multiplicado por cada escalar e da tabela esparsa.

Após este processo, obtêm-se a parte esquerda do vetor, pelos princípios da solução Sparse, na seqüência, este vetor é multiplicado pela parte direita, a qual baseia-se na solução Shuffle.

Nesta fase de operações, o vetor pout é novamente acumulado em p de acordo com baseout.

O algoritmo 3 define formalmente as etapas da solução Split.

Este algoritmo, irá calcular os elementos pertinentes à e, basein e baseout para as matrizes, até o ponto de corte s, conforme observado no laço da linha 4.

É possível notar neste trecho do algoritmo, que vai da linha 1 até a linha 8, uma grande semelhança com o algoritmo 1, entretanto os elementos e, basein e baseout eram calculados até N, que corresponde ao número total de matrizes.

Analisando a parte direita de s, no produto tensorial, a variável pin trata-se de p multiplicado pelo escalar e, em contraste do que ocorre na solução Shuffle, onde as semelhanças com o algoritmo Split estão nas linhas 9 a 30.

As operações contidas no último laço do algoritmo, que inicia na linha 31, apresenta o acúmulo dos valores de pin em r.

O custo da solução Split, no que diz respeito ao número de multiplicações em ponto flutuante, pode ser dado pela equação.

Vale ressaltar que este cálculo é feito considerando o número de multiplicações realizadas para gerar os elementos não nulos de cada termo da parte Sparse, mais o custo de multiplicar o vetor de probabilidades pelo produto tensorial do conjunto de matrizes da parte Shuffle.

Foi apresentado neste capítulo soluções que se baseiam em métodos iterativos para obtenção do vetor de probabilidades p.

Observou-se que as soluções iterativas apresentadas utilizam propriedades e características da álgebra Tensorial, descrita no capítulo 2 para sua resolução.

Tais soluções apresentam vantagens particulares, no que diz respeito à economia de memória e tempo de processamento, sendo a solução Split a solução que teoricamente apresenta maiores benefícios por adaptar-se às demais soluções abordadas.

Uma característica interessante da solução Split é que esta, na pior das hipóteses, comporta-se de forma análoga à solução Sparse quando o ponto de corte s encontra-se na posição zero do produto tensorial.

No outro caso extremo, comporta-se igual a solução Shuffle quando o corte ocorre na última posição (N) do produto tensorial.

Observou-se que a solução Sparse por apresentar um número significativamente reduzido de operações de multiplicação que a solução Shuffle, tende a ser mais rápida.

Em contrapartida a solução Shuffle não necessita armazenar os fatores normais, o que a torna mais eficiente em memória.

A seguir é feito um estudo numérico em relação a estas três soluções a fim de observar o que cada uma gasta com memória e com tempo de processamento.

Foram utilizados exemplos práticos para extrair resultados numéricos das aplicações propostas, podendo analisar as proporções dos resultados.

Em um estudo foram obtidos resultados sobre uma série de parâmetros pertinentes ao uso das soluções iterativas mencionadas no capítulo anterior.

Estes dados foram obtidos através da resolução de modelos SAN, e visam o custo em memória, em tempo de processamento e o número de multiplicações em ponto flutuante.

Para coletar esses dados foi desenvolvido um protótipo, que resolve o DM, utilizando os três algoritmos iterativos descritos.

Foi utilizada nos experimentos umamáquina comprocessador Intel Xeon de 3,2 GHz, com plataforma operacional Linux e 4 Gigabytes (Gb) de memória.

A seguir serão descritos os modelos utilizados, e os respectivos resultados.

Apresenta um modelo SAN, que representa uma cadeia de nós móveis em uma rede de sensores sem fio, operando no padrão 802,11 com conexão Ad-Hoc.

A cadeia é modelada com N nodos, sendo MN(1) o primeiro nó.

Os pacotes são transmitidos através da cadeia de autômatos MN, onde i varia de 2 a N1, sendo o termo MN(N) referente ao último nodo.

De forma genérica, este conjunto de modelos SAN apresentam N2 eventos locais e N eventos sincronização, sendo N o número de autômatos.

O DM para esse modelo é formado por um conjunto de [(N2)+2N] produtos tensoriais.

Os resultados numéricos obtidos foram o aumento do número de autômatos e, conseqüentemente, o número de produtos tensoriais.

Mostra os resultados comparando os três métodos, Shuffle, Split e Sparse, dividida em três colunas, que representam o tempo em segundos (por iteração), o tamanho em Kilobytes (Kb) e o custo computacional de multiplicações em ponto flutuante (mpf).

A coluna PSS corresponde ao espaço de estados representado pelo produtório QN, que corresponde ao produto cartesiano da ordem dos autômatos (do tamanho do vetor de probabilidades).

À medida que o número de nodos móveis na cadeia aumenta (N = 6, 8, 10, 12, 14, 16), ocorrem alterações com o tempo de processamento e a memória alocada.

É importante mencionar que os resultados obtidos com o algoritmo Split, foram coletados, adotando sempre o melhor corte possível para s, em cada termo do DM.

Com o intuito de facilitar a análise, os quais permitem observar os custos com tempo, memória e número de multiplicações em ponto flutuante.

Observou-se que a solução Shuffle é menos eficiente em termos de tempo de processamento, que as soluções Sparse e Split, em contrapartida apresenta grande eficiência em termos de armazenamento de memória.

É importante notar que esta solução apresenta o maior número de multiplicações em ponto flutuante (mpf) em relação às demais, fato que pode explicar o demasiado tempo de processamento.

Nota-se que o custo geral dessas soluções são bastante razoáveis para modelos pequenos (N < 12 nós), sendo o tempo de processamento e o consumo dememória devidamente tratáveis.

Este fator permite sua resolução praticamente em qualquer máquina.

Para demonstrar essa afirmação, pode ser tomado como exemplo a abordagem Sparse, com N = 10, onde ocupa em torno de 2,5 Megabytes (Mb) com um tempo de processamento de apenas 152 milisegundos.

É possível notar que mesmo o comum número pequeno de autômatos, há uma notável eficiência na solução Shuffle, uma vez que esta mantém o consumo de memória eficiente inclusive para grandes modelos, como N = 16, sendo que consome cerca de 23 mil vezes menos memória que a solução Split e cerca de 600 mil vezes menos memória que a solução Sparse.

Como esperado, a solução Split é a que mais se adequa na maioria dos modelos, pois alcança seu propósito, mantendo o equilíbrio entre o consumo de memória e o tempo de processamento.

Para cada produto tensorial, a abordagem esparsa poderia ser mais rápida na maioria dos casos.

Quando se tem muitas matrizes identidades a solução Shuffle é a solução mais eficiente.

Uma vez que um modelo SAN é composto por muitos termos de produtos tensoriais, a solução Split é a melhor opção, principalmente para grandes abordagens.

Considerando o maior caso do modelo (N = 16) pode-se observar que o algoritmo Split demora cerca de 3 segundo menos que a solução Sparse, que também ocupa muito mais memória, cerca de 3 Gb, 30 vezes mais que a solução Split que ocupa cerca de 100 Mb.

Ainda pode ser mencionada a melhora da eficiência comparando o tempo de execução.

É importante observar, que este modelo apresenta um espaço de estados de mais de 19 milhões de estados.

Esse grande modelo pode ser intratável caso não fossem encontradas soluções eficientes em memória e em tempo de processamento.

Note que o número de mpf é computado para cada algoritmo, sendo que não é relevante para indicar um melhor desempenho no tempo, em relação à solução Sparse e Split, por exemplo.

Acredita-se que outros fatores também interferem no desempenho destas soluções, o que levanta a necessidade de uma análise mais precisa como o custo de operações de adição.

Entretanto esses fatores ainda não foram medidos.

O modelo SAN proposto refere-se a avaliação de uma abordagemde programação paralela mestre-escravo para um algoritmo denominado Propagation.

Este modelo considera a comunicação deste algoritmo, sendo ela assíncrona.

O objetivo foi identificar possíveis gargalos enfrentados na comunicação, antes de sua execução.

O modelo contém um autômato mestre (master), um autômato buffer, e S autômatos escravos (slavei), sendo que i varia de 1 até S.

De forma genérica, o número total de autômatos é dado por S + 2, sendo S os eventos locais e 3S3 os eventos sincronizantes.

O DM, neste caso, é formado por um conjunto de 7S8 termos tensoriais.

Este modelo foi expandido, variando de S = 3, 4, 5, 6, 7, 8, 10, 12, tendo um buffer de quarenta posições (K = 40).

Apresenta os resultados para este modelo.

Da mesma forma que no modelo anterior, foram traçados os gráficos para facilitar a interpretação dos resultados.

Observou-se que os mesmos mostraram-se coerentes com os obtidos na seção anterior, sendo que mais uma vez o algoritmo Split apresentou maior eficiência.

Para abordagens pequenas apresentou, em geral, resultados pouco significativos, entretanto mostrou-se cerca de 10% mais rápido para grandes modelos.

O custo da memória obtida nesta segunda série de exemplos são bem maiores do que os obtidos no modelo da seção.

A solução Split ainda apresenta uma redução considerável de memória para modelos grandes, conforme o último exemplo, onde S = 12, comparado com o custo de memória quase intratável da solução Sparse, cerca de 26Gb, mesmo o Split ocupando 2,2Gb.

É importante ter em mente que se trata de um modelo com 65 milhões de estados, o que é uma quantia significativa considerando memória e tempo de processamento.

Um ponto importante a mencionar é que quanto maior o número de mpf, maior é o tempo de processamento e menor é o consumo de memória.

Os modelos desta seção e da seção seguinte, foram elaborados e executados em um protótipo que contém os algoritmos apresentados no capítulo 3 a fim de dar sequência na análise proposta.

Esses modelos são mais simples que os anteriores, em relação ao espaço de estados ocupado.

Apresenta um exemplo clássico, que representa um sistema de compartilhamento de recursos, sendo R o número de recursos e N o número de processos.

Cada processo é representado por um autômato A composto por dois estados S (em repouso) e U (em uso).

Um recurso é representado pelo autômato A(N+1) e tem R+1 estados indicando o número de recursos em uso.

Este modelo varia alguns parâmetros a fim de obter termos tensoriais de diferentes tamanhos.

Apresenta modelos de compartilhamento de recursos com diferentes caracter ísticas, representadas por rsP R, onde P indica o número de processos e R o número de recursos.

Os gráficos facilitam a análise da tabela.

A principal carácterística deste modelo é que o número de mpf da solução Split e da solução Sparse são os mesmos para todos os casos da tabela.

Isto se justifica devido ao número escasso de termos tensoriais para ambas as abordagens, apresentando melhor desempenho que a solução Shuffle neste quesito.

Analisando o consumo de memória entre estas duas soluções observa-se então uma eficiência muito maior com a solução Split, sendo que para o último caso (rs14 11) foi ocupado cerca de 18Kb contra 78kb da solução Sparse.

O fato do Split ser um algoritmo flexível, uma vez que pode comportar-se de forma análoga a solução Sparse ou a solução Shuffle, possibilitou com que ele fosse quase 3 vezes mais rápido que o modelo Shuffle e ocupasse cerca de 4 vezes menos memória que o algoritmo Sparse, comparando os dados da última linha da tabela.

Este exemplo apresenta um modelo SAN que analisa a disponibilidade de servidores, sendo N o número de servidores disponíveis.

Cada servidor é representado por A, e pode estar em dois estados distintos ocioso (I) e ocupado (B).

Neste exemplo os pacotes chegam nos servidores desde que pelo menos um deles não esteja bloqueado.

Este modelo pode ser considerado como um quadro de análise de diferentes filas de espera.

Cada pacote na fila pode avançar para o primeiro servidor disponível sem critérios de preferência (a prioridade dos servidores é dada por eles mesmos).

O espaço de estados deste modelo é formado por 2N estados.

Mostra os resultados deste exemplo apresentando o tempo de processamento e o consumo de memória.

Este modelo varia o parâmetro N, sendo ele o número de servidores do modelo.

Os gráficos podem ser analisados para facilitar a compreensão dos resultados.

Neste modelo, como o número de estados é pequedo, comparado com os modelos da seção, todos os algoritmos apresentaram resultados razoáveis.

Comparando o resultado desta análise com o das análises anteriores, observou-se que o algoritmo Split manteve-se mais rápido que o algoritmo Sparse em todos os casos de N também para este modelo.

A solução Sparse permanece tendo o maior custo com memória, sendo que neste exemplo ocupou quase 5 vezes mais memória que a solução Split e mais de 10 mil vezes mais memória que a solução Shuffle, considerando N = 18.

Já a solução Shuffle levou 8 vezes mais tempo que a solução Split e aproximadamente 7 vezes mais tempo que a solução Sparse, quanto ao tempo de processamento.

Este fato explica-se pelo considerável número de multiplicações em ponto flutuante desta solução, o que acarreta em um atraso computacional.

Este trabalho teve como objetivo realizar uma análise nos métodos numéricos Sparse, Shuffle e Split.

Para isso utilizou-se modelos práticos para possibilitar uma análise real da funcionalidade e das características principais destas soluções.

Foi possível concluir, que a solução Sparse apresenta vantagens significativas em relação à tempo de processamento, comparado com a solução Shuffle, sendo que esta última por sua vez destaca-se pelo eficiente tratamento em relação a utilização de memória.

Foi possível comprovar com o resultado das análises práticas, que ambas manifestam explicitamente suas características quanto à eficiência em memória e ao tempo de processamento.

Observando esses fatores, notou-se a necessidade de uma solução que conseguisse abstrair as características principais das soluções existentes, a fim de refinar a eficiência na resolução de modelos com um número significativo de estados.

Visto que o alto custo de memória e o alto custo de processamento tornam as soluções Sparse e Shuffle, praticamente intratáveis emumamáquina seqüencial conforme o espaço de estados do modelo a ser resolvido, aumenta.

A fim de suprir essa deficiência, foi apresentada a solução Split, que foi analisada juntamente com as demais, comparando seu desempenho na aplicação de alguns modelos.

Observou-se que esta obteve êxito em relação às demais uma vez que conseguiu reduzir de forma eficiente o consumo de memória e o tempo de processamento, unindo as principais características da solução Shuffle e da solução Sparse em uma solução híbrida.

A análise desenvolvida neste trabalho demonstrou através da resolução de modelos reais, o custo das soluções Sparse, Shuffle e Split usando como métrica o número de multiplicações em ponto flutuante para cada uma delas.

Entretanto tendo apenas esse parâmetro é difícil elaborar uma fórmula que permita prever o tempo de processamento ou o custo em memória para modelos diferentes.

Acredita-se que o custo computacional dessas soluções podem englobar também outros fatores como, o número de operações de adição, atribuições, alocações, comparações, dentre outros, entretanto esses índices ainda não foram medidos.

Como trabalho futuro, pretende-se dar seqüência a este estudo, objetivando identificar os fatores que possam interferir no resultado dos modelos.

Desta forma a idéia inicial é definir as equações que fornecem o custo com operações de adição em ponto flutuante para os três algoritmos apresentados, e então adaptá-las ao protótipo.

Com isso pretende-se obter novos índices e a partir das conclusões encontradas, aperfeiçoar o máximo possível as soluções numéricas existentes, além é claro de estabelecer formas que possam medir a relevância de outros fatores, como atribuições e alocações, por exemplo.

