É proposto um estudo dos parâmetros que melhor modelem um sistema de reconhecimento automático do locutor utilizando Modelos de Markov Escondidos Contínuos cujo objetivo é encontrar um modelo representativo de cada locutor que permita realizar as tarefas de verificação e identificação, dependente do texto, a partir de uma elocução teste.

Para a realização deste estudo foi necessário a obtenção de um conjunto de locutores e a seleção de uma base de dados a partir de suas gravações.

Utilizou-se dois conjuntos de locutores, um masculino com 5 locutores para treinamentos e testes e 3 somente para testes e um feminino contendo 4 locutores para treinamentos e testes e 3 somente para testes.

Para uma melhor comparação entre os modelagem do sistema com relação ao conteúdo acústico, utilizou-se duas frases distintas, selecionadas considerando-se estudos fonéticos / fonológicos.

Obteve-se para cada frase uma base de dados através da gravação de 70 elocuções, 50 para treinamento e 20 para teste de cada locutor utilizado para treinamento, e mais 20 gravações, realizadas para cada locutor destinado a testes.

Os vetores das características da voz, ou seja, as observações, foram construídas utilizando-se 12 coeficientes mel-cepestro, 12 coeficientes delta mel-cepestro, log- energia e delta log-energia.

Foram analisadas diversas combinações de misturas de Gaussianas e número de estados.

A configuração utilizando uma mistura de 5 grupos e 12 estados foi a que apresentou melhor resultado, para as duas frases e os dois conjuntos de locutores.

O conjunto feminino apresentou maiores dificuldades na convergência do modelo e um desempenho pior que o conjunto masculino.

O conjunto feminino foi o único que apresentou erros de falsa aceitação para o limiar utilizado.

Após a realização dos testes verificou-se que na maioria dos casos, o total dos erros eram de falsa rejeição do locutor treinado.

Concluiu-se que os limiares estavam um pouco abaixo do valor ideal para o sistema, o que pode ser atribuído ao pequeno número de elocuções utilizadas no cálculo.

Um pequeno ajuste nos limiares proporcionou uma mudança da taxa de aceitação para aproximadamente 100%.

Atualmente, a gigantesca e flexível rede mundial de telecomunicações torna possível o acesso do pesquisador às pesquisas mais recentes.

Várias destas pesquisas surgem de idéias originais, porém os artigos ou "tutoriais" publicam apenas a teoria básica.

As partes mais importantes só chegam ao domínio público quando já existem outras mais avançadas.

Assim, cumpre aos pesquisadores brasileiros o papel de romper o isolamento e iniciar pesquisas em temas recentes, trazendo ao seu domínio e adaptando às suas condições.

Com esta visão, iniciou-se na linha de Pesquisa de Processamento de Sinais de Voz do IME, pesquisas utilizando métodos estatísticos baseados em Modelos de Markov Escondidos (Hidden Markov Models, HMM) no reconhecimento de locutor.

Este modelo foi introduzido e estudado nas décadas de 60 e 70, progressivamente tornando-se popular nos últimos anos.

O interesse está no fato de que o HMM é muito eficaz na utilização das propriedades estatísticas dos fenômenos.

Pesquisas recentes, feitas com sinais de voz em várias línguas estrangeiras, têm demonstrado que HMM possui altas taxas de acertos no reconhecimento automático, isso sugere a existência de uma gama de estudos para os pesquisadores que operam com sinais de voz em português.

As pessoas podem identificar com precisão vozes familiares.

Cerca-se de 2 a 3s (segundos) da voz são suficientes para a identificação, apesar da performance diminuir com a não familiariedade.

O reconhecimento de locutor é uma área da Inteligência Artificial onde o desempenho da máquina pode superar o desempenho de seres humanos, usando curtas locuções de testes e um grande número de locutores, a acurácia da Verificação Automática de Locutor (VAL) ou da Identificação Automática de Locutor (IAL) frequentemente excede a dos seres humanos.

Verifica-se isto, especialmente para locutores não familiares, onde o "tempo de treinamento" para os seres humanos aprenderem a nova voz é maior quando comparado ao tempo da máquina1.

Um estudo com 29 conhecidos entre si obteve 31%, 66% e 83% de reconhecimento com uma palavra, uma sentença e 30s de voz, respectivamente1.

Em um outro estudo, porém, usando vozes de 45 pessoas famosas, com 2s de elocução, obteve-se somente 27% de reconhecimento no teste em que o ouvinte tinha a liberdade da escolha do suposto locutor da voz do teste, e 70% de reconhecimento em que o ouvinte seleciona 1 dentre 6 locutores determinados.

Observa-se que a habilidade do reconhecimento humano decresce muito quando diminui o tempo da elocução teste.

Em contra partida, num estudo utilizando somente as relações entre as características mel-cepestrais da voz do locutor calculadas a partir de segmentos de voz de muito curta duração, de aproximadamente 120 ms, obteve-se para o conjunto de 10 locutores, uma taxa de 100% de acerto para a IAL e de 99% para a VAL3.

Desse modo, com a tecnologia em reconhecimento automático do locutor avançando, espera-se a instalação de serviços utilizando a voz, tais como transações bancárias, controle de acesso a áreas restritas e atividades forenses.

Reconhecimento de Locutores é um termo genérico que se refere à tarefa de discriminar pessoas baseando-se apenas nas características da voz, apresenta as formas de reconhecimento.

Divide-se em identificação do locutor e verificação do locutor.

A identificação do locutor é um processo no qual é determinado a qual dos N locutores treinados é, uma dada elocução teste.

A identificação ainda pode ser com rejeição ou sem rejeição.

Com rejeição, admite-se um limiar para cada locutor, classifica-se o locutor verdadeiro se a medida de similaridade da elocução teste for maior que algum limiar, caso contrário considera-se o locutor como falso.

A Verificação do Locutor é o processo de aceitar ou rejeitar a identidade pretensa de um locutor teste.

Dois tipos de erros podem ocorrer na verificação do locutor, falsa aceitação, que consiste na aceitação de um locutor impostor ou mímico e falsa rejeição, rejeição do locutor verdadeiro.

A diferença fundamental entre identificação e verificação é o número de decisões a serem tomadas.

Na identificação, o número de decisões é igual ao tamanho da população (mais 1 quando com rejeição), e, na verificação há duas, aceitação ou rejeição, indiferente do tamanho da população.

Portanto, a performance da identificação diminui com o aumento da população, e a performance na verificação se aproxima de uma constante, independente do tamanho da população.

Os métodos de reconhecimento de locutor podem ser divididos em método dependente do texto e método independente do texto.

O primeiro método utiliza o mesmo texto para o treinamento e reconhecimento, ao passo que o último não especifíca o texto.

A estrutura do sistema de reconhecimento dependente do texto é, portanto, mais simples.

Mostra a estrutura básica do sistema de reconhecimento de locutor.

Na identificação, a elocução de um locutor desconhecido é analisada e comparada com o modelo dos locutores conhecidos.

O locutor desconhecido é identificado como o locutor de cujo modelo melhor corresponder a elocução de entrada.

Na verificação do locutor, a elocução de um locutor supostamente conhecido é comparada com o modelo pretendido, se o resultado for acima de um limiar, a identidade é aceita.

Um limiar alto dificulta a falsa aceitação pelo sistema, mas aumenta o risco de ocorrer a falsa rejeição.

E, ao contrário, um limiar baixo garante a aceitação de todos os locutores verdadeiros mas aumenta o risco de falsa aceitação.

Atualmente, a vasta área de processamentos de sinais de voz pode ser dividida em outras sub-áreas, de acordo com sua aplicação e tecnologia6.

Estas áreas são Síntese da Voz, Codificação da Voz, Reconhecimento da Voz, Reconhecimento do Locutor, Tradução da Linguagem Falada, Identificação da Linguagem Falada.

A sub-área Reconhecimento do Locutor é o processo de reconhecer um locutor através de sua voz.

Este processo é dividido em duas partes principais, Extração das características da voz do locutor, Reconhecimento de padrões.

Na extração das características busca-se obter impressões da voz do locutor que sejam inerentes a ele.

Estas características devem ser robustas ao ruído, isto porque existem diferenças entre as condições de treinamento (laboratório) e o ambiente de testes (pode ser ruidoso).

Em reconhecimento de padrões almeja-se a separação entre os padrões falsos e os verdadeiros, através de algum modelo matemático.

Os, modelos matemáticos utilizados em reconhecimento de voz conseguem obter bons resultados quando os sinais treinados pelo modelo não são ruidosos.

Entretanto, como esta situação não é sempre possível pesquisam-se algoritmos de extração de características que reduzam o ruído de fundo somado ao sinal de voz, como por exemplo, RASTA, "relative spectral", MFCC13, "mel frequency cepstral coeficients", PLP9 "perceptually weigthed linear prediction", características combinadas como MFCC com PLP-RASTA e algorítmos de extração do mel-cepstrum com espaçamento linear e logarítmo do filtro banda passante11.

Atualmente, as pesquisas em Reconhecimento Automático de Locutor (RAL) tem utilizado HMM (Hidden Markov Models, Modelos de Markov Escondidos) devido aos ótimos resultados obtidos e a facilidade do seu uso na modelagem do sinal de voz.

ANN (Artificial Neural Network, Redes Neurais Artificiais), modelos híbridos, tais como HMM com ANN (Artificial Neural Network, Redes Neurais Artificiais) os quais combinam a modelagem temporal do HMM com a capacidade em classificação de padrões da ANN, HMM híbrido com MDD (Mixture Decomposition Discrimination, Discriminação da Decomposição das Misturas) que analisa as diferenças entre as misturas dos estados, entre outros modelos.

O uso do verificação do locutor tem o propósito de restringir o acesso à informação, à redes (computadores, PABX), ou o acesso a locais restritos.

Com a ampliação da redes de computadores e outros sistemas de telecomunicações, a necessidade de segurança tem aumentado o ponto de tornar imperativa a verificação do locutor, como por exemplo nos serviços de PBX, contra o uso impróprio por pessoas não autorizadas.

Nas redes de serviços, onde a verificação do locutor provê acesso a um grande número de serviços de telecomunicações.

Nos sistemas de computadores onde é necessário senhas por voz para o acesso.

Portanto, as interfaces por comandos de voz estão se tornando comuns, e a voz é uma escolha indicada para o estabelecimento da identidade pessoal, para prevenção de fraudes, ou para o reconhecimento de fraudadores (na área forense).

O objetivo desta tese foi a obtenção dos parâmetros (número de grupos e número de estados) dos Modelos de Markov Escondidos (HMM) que pudessem melhor representar locutores femininos e masculinos na tarefa de reconhecimento.

Este compêndio compõe-se de 7 (sete) capítulos.

O Capítulo 1 é uma introdução com ênfase no estado atual da arte.

No Capítulo 2 inicia-se um estudo das características ("features") extraídas das elocuções "O prazo tá terminando" e "Amanhã ligo de novo" e, utilizada para o treinamento do modelo.

Os Capítulos 3 e 4 tratam da teoria do HMM, sendo que o Capítulo 4 descreve, em fases, o algoritmo implementado na pesquisa.

O Capítulo 5, trata do desenvolvimento do "software" implementado e da técnica de obtenção do limiar de decisão empregado.

No Capítulo 6 são descritos os resultados e analisado o desempenho do sistema e, por último, no Capítulo 7, são apresentadas as conclusões e sugestões para a continuação da pesquisa realizada.

Em um sistema de Reconhecimento Automático de Locutor (RAL) o préprocessamento da voz, isto é, extração dos parâmetros relevantes do sinal de voz (vetor de características da voz) é o primeiro estágio e consiste, basicamente, em uma compressão de dados com o objetivo de reduzir a dimensão do espaço em que são definidas as elocuções.

Ou seja, consiste em realizar um mapeamento das elocução de dimensão M, número de amostras do sinal de voz, em um espaço dimensional N, número dos parâmetros (características) extraídos deste sinal (sendo N<<M).

Algumas destas técnicas de análise surgiram recentemente, procurando uma representação paramétrica da "percepção" do sinal de voz, parâmetros que sejam correlatos ao percebido pelo sistema de audição humano.

Deseja-se que estes parâmetros, no Reconhecimento do Locutor ou da Fala, sejam robustos às dificuldades provocadas pelas variabilidades, que podem ser incluídas em quatro categorias.

Variabilidade dos sons (mesmo locutor ou diferentes locutores).

Variabilidade do canal de gravação (tipo de microfone utilizado).

Variabilidade devida à adição do ruído ambiente.

Variabilidade no modo de falar (hesitação ao falar, ruído de respiração, pigarro).

O fato é que estas variabilidades, geralmente, não podem ser eliminadas.

Por isso, as tecnologias de reconhecimento de voz devem executar duas tarefas básicas, Deteção da voz (retirar o ruído antes do início e depois do fim da elocução).

Reconhecer a sentença falada baseada em reconhecimento de padrões determinístico (ou estatístico) ou métodos fonético-acústicos.

Para o teste do locutor, o desempenho é sensível a muitos fatores.

Entre eles pode-se citar o microfone usado na gravação, o canal de transmissão, o ruído de fundo, as condições físicas do locutor, as condições do uso do sistema (fone sem fio, telefone celular).

Várias soluções técnicas têm sido proposta para este problema, entretanto, não há uma solução que forneça um sistema robusto com alto desempenho neste campo.

Um estágio de pré-processamento típico de um sistema de RAL pode ser divido em três operações básicas, modelagem espectral, análise espectral e transformação paramétrica.

Um Sistema típico de Pré-Processamento do sinal de voz.

A análise espectral fornece o vetor das características ao qual pode-se acrescentar outras por meio da transformações paramétricas (coeficientes delta).

Dado um sinal de voz, o processo da modelagem espectral produz um sinal tratado pela pre-ênfase de modo a realçar as freqüências a que o sistema auditivo é mais sensível e que é convertido em medidas pelo processo da análise espectral gerando um vetor de características.

Finalmente, a transformação paramétrica é aplicada sobre essas medidas obtendo-se novos parâmetros (chamados de "parâmetros delta") os quais capturam a dinâmica espectral, ou mudanças do espectro com o tempo, estes parâmetros são acrescentados ao vetor de características.

A modelagem espectral envolve duas operações básicas, conversão A/D, conversão do sinal analógico para sinal digitalizado, e filtragem digital, isto é, pré-ênfase, realçando determinadas freqüências do sinal.

Seqüência de operações na conversão do sinal analógico para digital.

Um propósito do processo da digitalização do sinal é produzir uma representação dos dados amostrados do sinal de voz com uma relação sinal ruído (RSR) tão alta quanto possível.

Em reconhecimento de voz é comum utilizar um valor aproximadamente igual a 30 dB.

Após a conversão A/D, utiliza-se o filtro de pré-ênfase (filtro digital), com valores típicos para apre entre 1,0 a 0,4.

A pré-ênfase proporciona um ganho no espectro do sinal de aproximadamente 20 dB/dec20.

Há duas razões para seu uso, as partes vozeadas do sinal de voz possuem uma atenuação espectral natural de aproximadamente 20 dB/dec, devida as características fisiológicas do sistema de produção da voz.

O filtro de pré-ênfase compensa esta atenuação antes da análise espectral.

O sistema auditivo é mais sensível às freqüências em torno de 1kHz do espectro.

O filtro de pré-ênfase amplifica esta área, fornecendo ao algoritmo de análise espectral uma modelagem das percepções mais importantes do espectro da voz.

O primeiro passo para a obtenção das características relevantes do sinal de voz é a divisão do sinal em intervalos curtos de tempo.

Isto porque, sendo o sinal de voz um processo estocástico, em geral não estacionário, e sabendo-se que o trato vocal muda de forma muito lentamente na voz contínua, muitas partes da onda acústica podem ser supostas estacionárias, num intervalo de curta duração, este intervalo caracteriza o tamanho da janela a ser usada, cuja duração, de 10 a 40ms (milisegundos), permite considerar o processo estacionário.

O janelamento do sinal tem o objetivo de amortecer o efeito do "fenômeno Gibbs" ("ripple" em amplitude na resposta em freqüência da janela, surge devido a descontinuidade das janelas).

Utiliza-se janelas que possuam no domínio da freqüência, um lóbulo principal o mais estreito possível e uma grande diferença de amplitudes entre o lóbulo principal e o primeiro lóbulo lateral.

Algumas janelas comumente usadas são a Kaiser, a Hamming e a Hanning.

Em reconhecimento de locutor normalmente é usada a janela de Hamming, que proporciona maior atenuação fora da banda passante.

Mostra a forma de onda de um segmento (1024 amostras) do fonema / a / e o sinal após a multiplicação por uma janela de Hamming.

Realiza-se o janelamento com ou sem superposição parcial entre janelas consecutivas.

A superposição aumentará a correlação entre as janelas próximas evitando variações bruscas entre as características extraídas das janelas adjacentes, entretanto o tempo de processamento será maior.

Mostra o procedimento de janelamento, onde Tf é a duração do quadro, definido como a duração, em segundos, na qual o conjunto de parâmetros é válido.

Tw é a duração da janela, corresponde ao número de amostras com os quais se obtêm os parâmetros.

O valor da superposição é proporcional à diferença Tw-Tf.

Onde representa o número de quadros e N é o número de amostras.

Nf é a duração do quadro Tf expresso em amostras.

Como exemplo, de valores dos parâmetros M, N e Nf, obtidos na extração das características de uma repetição da frase "O prazo tá terminando" pronunciada por uma locutora feminina, obteve-se M igual a 124 quadros, N igual a 13782 amostras e Nf igual a 220 amostras por quadro.

Após o sinal ter sido janelado, o vetor das características ("features") é calculado para cada janela.

Um grande número de características podem ser extraídas, para o uso no RAL.

Algumas destas, tais como taxa de cruzamento de zero, freqüência fundamental da voz ainda são usadas, mas torna-se comum o uso dos parâmetros espectrais.

A razão desta popularidade não é unicamente o poder discriminatório da específica informação, mas também a existência de algoritmos robustos para a estimação destas características.

Basicamente, as características espectrais podem ser divididas em sete classes.

Pesquisas recentes tem incluído no vetor das características informações dinâmicas, tais como as derivadas de primeira e segunda ordem (derivadas no domínio do tempo, coeficientes de regressão) e parâmetros que simulam o comportamento do sistema de percepção e audição humanas (baseados na escala mel).

Sendo derivada no domínio do tempo.

As representações mais populares incluem as derivadas das características cepestrais de primeira ordem (delta cepestro) e segunda ordem (delta delta cepestro) e do log energia de primeira e segunda ordem (delta log-energia e delta delta log-energia, respectivamente).

Escala mel.

A escala mel baseia-se no sistema de audição humano, cuja sensibilidade aos sinais de voz se processa em uma escala não linear de freqüências.

Este processo baseou-se em estudos no campo da psicoacústica, o qual estuda a percepção auditiva humana.

Tipos de características do sinal de voz que podem ser obtidas.

As mais utilizadas são os parâmetros mel-cepestro obtidos ou da predição linear ou da transformada de Fourier.

O método da transformada de Fourier é considerado como robusto no caso de ambiente muito ruidoso.

Mostra uma aproximação utilizada para mapear a escala da freqüência acústica, f, para a escala da freqüência de "percepção", fmel, conhecida como escala mel (fmel).

Mostra a relação da escala mel com a escala de percepção.

O mel é a unidade de medida do tom, isto é, de uma freqüência única percebida pelo ouvinte.

Determinaram um mapeamento entre a escala da freqüência real (Hz) e a escala da freqüência percebida (mels).

Mapeamento entre a escala real e a escala mel.

O mapeamento é aproximadamente linear abaixo de 1kHz e logarítmico acima.

Isso ocorre porque a percepção de uma determinada freqüência fo, pelo sistema auditivo, é influenciada pela energia dentro de uma banda crítica em torno dessa freqüência fo 13.

Além disso, a largura da banda crítica varia com a freqüência, começando em torno dos 100Hz para freqüências abaixo de 1kHz, e aumentando logaritmicamente acima de 1kHz.

Assim, as freqüências centrais abaixo de 1kHz são espaçadas em 100Hz, e as freqüências acima de 1kHz são obtidas de acordo com o espaçamento calculado.

Relação entre a escala linear de 1000 Hz a 4000 Hz e a escala logarítmica de log(1000) a log(4000).

Onde L é o passo que varia de acordo com o números de filtros na escala logaritma, neste caso usou-se 10 filtros.

Obtém-se assim, um banco de filtros triangulares passa faixa, filtros de banda crítica, com a freqüência central de cada filtro, onde fs é a freqüência de amostragem e N é o número de pontos usado no cálculo da transformada discreta de Fourier (DFT, Discrete Fourier Transform) e ki é o ponto da DFT correspondente à freqüência central de cada filtro.

Mostra a escala logarítmica das freqüências centrais.

O gráfico dos filtros é obtido.

Para o primeiro filtro, X são os pontos na DFT que variam de 1 a 19, reta à esquerda da freqüência central ki, reta à direita da freqüência central ki.

Como o tempo computacional exigido para o processamento da extração das características e treinamento do modelo HMM é diretamente proporcional a dimensão do vetor extraído das janelas, a seleção das características mais relevantes (discriminantes) do sinal de voz é fundamental.

Esta pesquisa utilizou parâmetros da voz que possuem melhores discriminação intra-locutores.

Atualmente os parâmetros mais utilizados são os coeficientes mel-cepestro derivados do LPC (acrônimo de Linear Predictive Coefficients, Coeficientes da Predição Linear) e seu coeficiente de regressão delta mel-cepestro, os parâmetros log-energia e seu coeficiente de regressão delta log-energia.

Estas medidas serão descritas nos itens a seguir.

Para a definição deste coeficiente torna-se necessário o conhecimento prévio dos conceitos da análise cepestral e LPC.

Análise Cepestral.

A voz pode ser representada como a saída de um sistema linear variante no tempo e que possui propriedades que variam lentamente com o tempo.

Considera-se o princípio básico de análise da voz o qual diz que curtos segmentos do sinal da voz podem efetivamente ser modelados como tendo sido gerados por um sistema linear invariante no tempo (LIT) excitado por um trem de impulsos quase-periódicos ou por um sinal de ruído aleatório.

A excitação e[n] e a resposta ao impulso q[n] de um sistema LIT são combinadas por uma convolução.

Faz-se a deconvolução para remover a alta freqüência (representada por e[n]) e obter a envoltória do sinal q[n], isto é, a informação do trato vocal.

Portanto, aplica-se o conceito de sistemas homomórficos para a deconvolução dos sinais, onde a operação de entrada é uma convolução e a operação de saída é uma adição.

Utilizando-se um operador linear, a Transformada de Fourier Discreta ("DFT") F, transforma a Equação para o domínio da freqüência, cuja inversa é F1.

Sabendo-se que o logaritmo de um produto é definido como a soma dos logaritmos dos termos individuais.

Obtém-se do sistema, saídas lineares, ou seja, as componentes representativas do sinal tornam-se linearmente combinadas.

Aplicando-se a DFT inversa (IDFT) obtém-se o cepestro.

O termo "cepstrum", cepestro, foi introduzido por Borget entre outros e é aceita como a terminologia para a transformada inversa de Fourier do logaritmo do espectro de potência do sinal.

O cepestro representa uma operação linear no domínio "quefrency" (anagrama da palavra "frequency") dos coeficientes Ce(n) da excitação, responsável pelas variações rápidas espectrais, com os coeficientes Cq(n) do trato vocal, responsável pelas lentas variações espectrais.

Com o objetivo de analisar apenas os componentes Cq(n), ou seja, a resposta ao impulso do trato vocal, aplica-se o processo de "liftering" ("filtering" no domínio da freqüência) para remover a componente Ce(n) de Cs(n) e, neste caso, utiliza-se um "low-time lifter" (análogo ao filtro passa baixas no domínio da freqüência).

Mostra-se os coeficientes Cq(n) e Ce(n) do fonema / a /.

Este método tem se tornado uma ferramenta para a estimação dos parâmetros básicos da voz, tal como a "pitch", formantes, cepestro, PLP e funções relativa a área do trato vocal.

A idéia fundamental da análise da predicão linear é que a amostra atual da voz pode ser aproximada por uma combinação linear das amostras passadas.

O cálculo dos parâmetros do modelo é baseado na teoria do erro médio quadrática mínimo.

Dado um sinal s(n), define-se o modelo de predição linear, onde NLP representa o número de coeficientes do modelo (ordem da predição), os {aLP} os coeficientes de predição linear (coeficientes do preditor) e e(n) o erro do modelo (a diferença entre o valor predito e o valor medido).

As equações da predição linear são vistas como um filtro quando obtida a transformada Z do erro.

Uma virtude deste modelo é sua capacidade de predizer o valor atual do sinal baseado sobre o conjunto de medidas passados20.

O termo e(n) da Equação permite uma medida da eficácia do modelo.

Existem três métodos básicos para o cálculo dos coeficientes do preditor, método da covariância que baseia-se sobre a matriz covariância, método da autocorrelação e método "lattice" (ou harmônico).

Em reconhecimento de locutor, o método da autocorrelação é mais utilizado, com as seguintes vantagens, disponibilidade de um algoritmo eficiente para a sua implementação, o algoritmo de Durbin 41, os coeficiente gerados por este método resultam em filtros garantidamente estáveis, possibilidade da verificação da estabilidade do sistema pela análise dos coeficientes intermediários, Coeficientes Mel-Cepestro.
Derivados do LPC.

De acordo com a definição de cepestro, os coeficientes podem ser obtidos simplesmente com o uso da análise de Fourier.

Isto porque é admitido que o sistema de produção da voz é invariante no tempo, para curtos segmentos de voz.

Como desvantagem, o uso da técnica de Fourier aumenta o tempo de processamento em duas vezes em relação ao tempo utilizado pela análise da predição linear 20.

O cepestro derivado da DFT produz, em reconhecimento de locutor, o mesmo desempenho quando comparado ao cepestro derivado da LPC embora em ambientes ruidosos o cepestro calculado pela DFT obtenha um melhor desempenho20.

Consequentemente a maioria dos pesquisadores utilizam o coeficiente cepestro derivado do LPC Na Equação o logaritmo do inverso do filtro pode ser expresso como uma série de potências em z-1.

Diferenciando-se ambos os lados da expressão com respeito a z1, e igualando-se os coeficientes resultantes do polinômio, obtém-se a equação, onde Ns é o número de amostras da janela selecionada e os coeficientes {cLP} são definidos como os coeficientes cepestro derivados do LPC.

Como os coeficientes são, de fato, a transformada inversa de Fourier das respostas ao impulso do modelo LP, o modelo LP do sinal é um filtro de resposta ao impulso infinito, assim, pode-se em teoria, calcular infinitos coeficientes cepestro.

Entretanto, nas pesquisas se utiliza calcular 12 coeficientes cepestro.

Os parâmetros mel-cepestro são obtidos calculando-se a energia Ek dos k filtros aplicado no espectro, com freqüência central espaçados linearmente até 1kHz e logaritmicamente acima, ou seja a escala mel, e aplicando-se.

Desde que a seqüência de energias é par, pode-se substituir a exponêncial por um coseno, e desenvolvendo a equação encontra-se para o cálculo dos coeficientes mel-cepestro, onde i é o número de coeficientes cepestro e Ek representa as saídas da log energia do k-ésimo filtro.

Após a obtenção dos parâmetros MCLPC extrai-se novas características chamadas de parâmetros delta.

Estes parâmetros são as derivadas de primeira e segunda ordem do MCLPC.

São usados para representar as mudanças dinâmicas no espectro da voz.

Uma alternativa para a representação das derivadas no domínio do tempo são os coeficientes de regressão.

Este coeficientes representam uma aproximação das derivadas de primeira e segunda ordem do vetor das caracteríscas, nesta seqüência.

Os parâmetros de segunda ordem (parâmetros delta delta) são obtidos reaplicando-se as equações sobre os resultados.

Estes parâmetros detectam variações bruscas dentro do espectro da voz e aumentam a robustez do sistema de reconhecimento.

Tradicionalmente utiliza-se o logaritmo sobre os parâmetros da energia no reconhecimento de voz com o objetivo de para obter uma compressão entre a baixa energia e a alta energia.

Sadaoki Furui em seu artigo27 afirma que aplicando-se a transformação logarítmica na energia obtém-se uma melhor aproximação com a escala de percepção humana.

Estes parâmetros são calculados utilizando as Equações aplicada aos coeficientes da energia.

De acordo com alguns pesquisadores, a utilização destas características em conjunto com os coeficientes log energia, coeficientes mel-cepestral e delta mel-cepestral aumenta a taxa de reconhecimento.

Gráficos mostrando a necessidade de utilizar o operador logaritmo.

Em a observa-se a forma de onda da frase "O prazo tá terminando" no domínio do tempo, b a evolução da energia de tempo curto com janelas de Hamming, c a evolução da energia de tempo curto com janelas de Hamming, mas com o uso do logaritmo aplicado em sua amplitude.

Na década de 70, aplicaram independentemente os Modelos de Markov Escondidos (HMM, Hidden Markov Models), no reconhecimento da voz, utilizando a forma moderna de desenvolvimento matemático, proposto por Baum entre outros, baseados nos conceitos de cadeia de Markov.

O Modelo de Markov Escondido é, atualmente, o mais popular e a melhor aproximação estocástica para o reconhecimento da voz.

Esta popularidade deve-se à existência de um algoritmo eficiente e robusto para o Treinamento e Reconhecimento.

No treinamento do modelo, o conjunto dos parâmetros acústicos do sinal de voz do locutor (parâmetros estes extraídos em janelas de intervalo de tempo curto), também chamado de seqüência das observações, é modelada por uma seqüência de estados (cadeia de Markov de primeira ordem) de acordo com a variação temporal da voz.

No reconhecimento, a seqüência das observações da elocução em teste é aceita como verdadeira se possuir alguma medida de similaridade (verossimilhança) acima de um limiar estipulado.

O Modelo de Markov Escondido constitui-se de um conjunto de N estados cujas transições são governadas pela distribuição das probabilidades de transições.

Associada a cada estado há uma função de densidade de probabilidade discreta (HMM Discreto) ou contínua (HMM Contínuo), que fornece a densidade de probabilidade da observação pertencer àquele estado.

Portanto, um Modelo de Markov Escondido é definido como um par de processos estocásticos (X,Y).

O processo X é uma cadeia de Markov de primeira ordem, não sendo diretamente observável.

Enquanto, que o processo Y é uma seqüência de variáveis aleatórias no espaço dos parâmetros acústicos (observações).

Para se definir um HMM completamente são necessários os seguintes parâmetros N, M, A, B e Pi, assim definidos, N representa número de estados do modelo.

Os estados são representados como S={S1, S2, SN} e qt indica estar no estado Si, no tempo t.

M, representa número de símbolos no alfabeto, quando o espaço é definido por uma função de densidade probabilidade (fdp) discreta ou número de grupos quando for fdp contínua.

A, matriz de probabilidades de transições entre estados, A={aij}.

A matriz A deve satisfazer as condições estocásticas.

Os valores das probabilidades de transições definem o tipo de topologia do HMM, através das restrições de avanço ou recuo entre estados.

Representa a distribuição da probabilidade de observação em cada estado, B.

Para o HMM discreto, seus elementos são do tipo bj(k) onde bj(k) é a probabilidade da variável aleatória ot (observação) pertencer ao estado j e vk representa o k-ésimo símbolo observado no alfabeto.

No HMM contínuo como será visto, o conjunto de observações pertencentes a cada estado é dividido em M grupos (através de um algoritmo de agrupamento), onde cada qual possui um vetor média e uma matriz covariância associados (Gaussiana).

A densidade de probabilidade em cada estado é, então, calculada através de uma soma das M distribuições Gaussianas N, ponderada por cjm, ou seja uma mistura de Gaussianas.

As probabilidades das transições definem o processo de Markov e sua ordem.

Quando a transição feita para o estado atual não depender da ocorrência de todos os estados anteriores, mas, somente do estado imediatamente anterior, é caracterizado um Processo de Markov de Primeira Ordem.

E se as variáveis aleatórias da seqüência S assumirem somente valores discretos (valores correspondendo aos estados do modelo), o processo de Markov então será chamado Cadeia de Markov.

Portanto, a seqüência de estados do HMM é uma Cadeia de Markov, dado que as suas variáveis aleatórias assumem somente valores inteiros correspondendo aos estados do modelo.

De acordo com a matriz de transição A, a Cadeia de Markov assume uma topologia.

A topologia, ou estrutura de um HMM, é determinada pelas transições que ocorrem entre estados.

Entre as estruturas mais utilizadas no HMM para o reconhecimento da voz estão o modelo ergódico e o modelo esquerda-direita ("left-right model").

O Modelo Ergódico não restringe nenhuma transição entre estados, portanto, qualquer estado pode ser alcançado a partir de qualquer outro estado.

Mostra exemplo do modelo ergódico.

Com esta estrutura obtém-se uma maior flexibilidade na geração das observações, embora ela não permita uma ótima representação da voz.

A principal desvantagem é uma dificuldade em modelar a seqüência temporal dos eventos acústicos em cada estado, além de aumentar o risco da convergência em um máximo local no processo de treinamento do HMM.

Quando esta estrutura é usada para o treinamento da voz, as probabilidades das transições de retorno obtidas são próximas a zero.

Modelo ergódico com 4 estados.

Modelo esquerda-direita com 4 estados Uma estrutura que melhor representa a variação temporal das características da voz deve possuir suas transições de retorno iguais a zero.

Esta estrutura é chamada de Modelo Esquerda-Direita, isto é, nenhuma transição será permitida para estados cujo índice seja menor do que o atual.

Frequentemente, são impostas restrições nas transições do modelo, atribuindo-se a cada transição um número máximo de estados que pode ser alcançado.

Para o exemplo o valor de D é igual a 2, ou seja, permite a transição até o segundo estado a frente.

Esta é uma particularidade do modelo esquerda-direita chamado de Modelo Bakis.

Existem outras variações de estruturas utilizadas em HMM, entretanto, as mais comuns são modelo ergódico, modelo esquerda-direita ou suas combinações.

Ilustra combinações do modelo esquerda direita.

Um HMM é definido por duas seqüências, estados, S={S1, S2, S3, SN}, e observações, O={ o1, o2, o3, oT}.

Sabe-se que o modelo de Markov representa uma modelagem estocástica da voz.

Durante o treinamento, cada observação é associada a um estado de acordo com as probabilidades de transições entre estados e as probabilidades das observações dado o estado.

Como as observações são os vetores das características relevantes da voz, a sequência temporal é segmentada pelos estados obedecendo a algum evento acústico que será função da estrutura do modelo utilizada.

No exemplo, três elocuções de uma mesma frase de um locutor, gravadas em horários diferentes foram treinadas em um HMM com cinco estados utilizando o modelo Bakis.

Observa-se que, no treinamento, as seqüências das observações são segmentadas nos estados conforme sua semelhança acústica (velocidade, entonação, emoção do falante, variação de início e fim das palavras, etc) medida por uma distância entre padrões da voz.

Esta medida representa o quão próximo um padrão está de um grupo, ou seja, de algum evento acústico.

Após o treinamento, de todas as elocuções, as observações ficaram separadas em estados, levando em consideração as variações temporais das sequências das observações.

Mostra a variação do número de observações nos estados, para o mesmo tipo de palavra nas suas três repetições feitas por um mesmo locutor.

Observando-se a porcentagem acumulada das elocuções, verifica-se que os mesmos fenômenos acústicos (observações) das repetições estão separados nos mesmos estados.

E que, devido a existência de variabilidades acústicas, os vetores de características da voz podem apresentar uma distribuição multimodal.

Assim, costuma-se, representar o espaço espectral de cada estado, por uma densidade de probabilidade discreta (isto é, uma distribuição sobre todo o dicionário espectral), ou contínua (exemplo, mistura de fdp gaussianas) ou ainda semi-contínua (isto é, densidade contínua sobre um dicionário de formas espectrais comuns).

Cadeia de Markov utilizada no treinamento de três elocuções e resultados da segmentação das observações nos estados.

Observa-se pelas percentagens, que as distribuições das observações foram as mesmas, mostrando uma tendência do HMM em separar os mesmos fenômenos acústicos nos mesmos estados.

Estas representações podem ser divididas em Medição Acústica Não Paramétrica, Quantização Vetorial (QV), Medição Acústica Paramétrica, Distribuição Gaussiana, Representação do espaço acústico por uma Quantização Vetorial, Representação do espaço acústico por uma Mistura de Gaussianas.

Neste caso, a observação é associada a símbolos discretos, escolhidos de um alfabeto finito, sendo por isso, uma densidade discreta.

Isto é, a probabilidade de observar o símbolo vk (de uma célula k) dado o estado Sj, onde qt = estado no tempo t e vk = vetor pertencente a célula quantizada k.

Para se obter as probabilidades das observações pertencente a um determinado estado é necessário fazer a quantização vetorial, que representa um particionamento do espaço acústico em células não sobrepostas, normalmente baseado em um critério de distorção espectral mínima.

Exemplifica um o espaço acústico dividido em células.

Particionamento do espaço acústico em N células.

Um dicionário pode ser constituído por um conjunto de vetores de características (considerando a seqüência de treinamento), aplicando-se algoritmos de agrupamento ("clustering algorithms").

Há atualmente duas aproximações utilizadas, o algoritmo "Kmeans" e o algoritmo Linde Buzo Gray.

Ambos algoritmos geram um espaço dimensional reduzido pela substituição de grupos de palavras códigos similares por uma única palavra código representando o centróide do grupo.

O vetor das características extraído do sinal de voz é atribuído a uma palavra código que produz a menor distorção.

A medida de distorção mais usada é a distância ponderada Euclideana.

Espaço Acústico quantizado com 3 centróides e uma medida de distorção mínima entre um vetor e o centróide.

Mostra uma distorção típica versus o tamanho do dicionário.

Gráfico típico da distorção versus o tamanho do dicionário.

Devido ao fato de que o número de observações (vetores de características) classificado em cada estado normalmente é pequeno e que o erro de quantização pode provocar uma degradação da modelagem acústica do estado, duas dificuldades devem ser ponderadas, um dicionário muito grande pode diminuir a performance do reconhecedor, uma vez que torna difícil a estimação e a interpolação dos parâmetros discretos do HMM (treinamento).

Um dicionário muito pequeno pode resultar numa performance não desejada do reconhecedor devido ao erro acrescentado a quantização.

Um tamanho de dicionário razoável é de 256 níveis para as duas aproximações citadas acima, pois, melhora a resolução acústica e facilita a estimação dos parâmetros.

CDHMM, Continuous Density Hidden Markov Models.

O cálculo da densidade de probabilidade das observações é feito diretamente das observações, evitando a distorção acumulada que pode ocorrer no processo da QV.

A aproximação mais comum é o uso de uma função de densidade de probabilidade elipticamente simétrica, podendo ser uma distribuição Gaussiana que modele o espaço acústico das observações no estado.

O espaço acústico do estado é modelado apenas por uma Gaussiana.

Todavia, para o treinamento do HMM são necessárias várias repetições da mesma elocução, e, como existem muitas diferenças na pronúncia das repetições feitas por um mesmo locutor, a distribuição das observações dentro de um estado passa a ser multimodal.

Uma forma bastante popular de aproximação desta fdp é a utilização de uma mistura de Gaussianas.

A mistura é uma soma linearmente ponderada de diferentes densidades Gaussianas que representa a distribuição de probabilidade das observações no estado.

Como a pesquisa da tese foi desenvolvida com o uso de mistura de funções de densidade contínuas, ou seja, misturas de Gaussianas, apenas este caso será tratado nos capítulos seguintes.

Para tornar viável o emprego do HMM no Reconhecimento do Locutor, as seguintes suposições são admitidas.

Suposição de Markov, a probabilidade de transição é definida.

Ou seja, supõe-se que o próximo estado é dependente somente do estado atual, e o modelo resultante torna-se um HMM de primeira ordem.

Entretanto, geralmente o próximo estado pode depender dos k estados passados e é possível obter um tal modelo, chamado HMM de k-ésima ordem, definindo as probabilidades de transições.

Normalmente não se utiliza Processo de Markov de maior ordem devido ao aumento no desempenho ser pequeno em relação ao aumento na complexidade no algoritmo.

Suposição de estacionariedade.

É suposto que as probabilidades de transições entre estados são independentes do instante na qual ocorre.

Suposição das observações independentes.

Supõe-se que a observação corrente é estatisticamente independente das anteriores, ou seja, considerando-se uma seqüência de observações, significa que nem os estados passados da cadeia de Markov nem as observações passadas influenciam na observação presente, se a última transição na cadeia é especificada.

Para o desenvolvimento do algoritmo do modelo as seguintes fases são necessárias.

Fase 1, Inicialização, estrutura do modelo, parâmetros fixos, parâmetros variáveis.

Fase 2, Treinamento, estimação dos parâmetros, reestimação dos parâmetros.

Fase 3, Reconhecimento.

Mostram os fluxogramas das fases de treinamento e de reconhecimento.

Na fase inicial do modelo utiliza-se dois tipos de parâmetros fixos e variáveis.

Os parâmetros fixos são as quantidades de estados e de fdp's da misturas, que não se alteram durante o treinamento e o reconhecimento.

Os parâmetros variáveis são a matriz de probabilidade de transição, o vetor média e a matriz covariância dos grupos.

Ao contrário dos fixos, são apenas valores aleatórios ou estimativas iniciais que são ajustados durante o treinamento.

Esta escolha é feita dependendo do sinal que será modelado12.

O uso do modelo esquerda-direita é mais apropriado do que o modelo ergódico, devido à possibilidade de associação da evolução temporal do sinal com os estados do modelo, isto é, a possibilidade de sons distintos da elocução serem modelados nos estados de acordo com sua seqüência de observações.

A escolha do número de estados pode estar relacionada à quantidade de eventos acústicos.

Normalmente utiliza-se 2 a 10 estados por fonema, ou, aproximadamente o número médio de observações nas elocuções.

Mostra a relação da quantidade de estados versus convergência do modelo de uma palavra.

Observa-se que a quantidade N=6 pode ser um valor apropriado.

Foi observado através de pesquisas, que o número de grupos em cada estado deve ser maior que a unidade.

Pois, quando se constrói histogramas12 das observações pertencentes a um determinado estado, verifica-se que possuem uma fdp multimodal, mostrando assim a necessidade de utilizar mais de uma distribuição Gaussiana (grupos) para o mapeamento das observações do estado.

Esta probabilidade é fixada igual a 1 para o primeiro estado nos modelos esquerda-direita.

Os valores atribuídos a matriz A podem ser inicialmente aleatórios.

Observa-se nos resultados práticos, que esta atribuição não influencia os resultados finais, e que, depois de alguns ciclos de estimação e reestimação o mesmo resultado final pode ser obtido independentemente das condições iniciais utilizadas para a matriz A.

O coeficiente de mistura é uma ponderação estocástica no somatório das Gaussianas.

A restrição para a atribuição dos valores iniciais é a condição estocástica.

O cálculo da densidade de probabilidade das observações influencia na performance do treinamento do modelo, deste modo não se atribui valores aleatórios para a média e a covariância.

Obtém-se uma distribuição uniforme e sequencial com a divisão das T observações de cada repetição pelo número de estados N.

Após esta divisão, agrupa-se as observações de cada estado, separadamente, em M grupos através do algoritmo "Kmeans".

Em seguida, obtém-se para cada grupo a média mjm e a covariância Ujm.

Em vários trabalhos foi utilizada a matriz covariância diagonal, ao invés da matriz completa.

A razão para esta escolha foi a dificuldade de reestimar os elementos fora da diagonal da matriz, devido a limitação na quantidade de repetições para treinamento.

A partir dos parâmetros iniciais do modelo li, estima-se o novo modelo, l, usando a seqüência de treinamento O.

Com boas estimativas iniciais dos parâmetros variáveis pode-se conseguir uma rápida convergência, utilizando-se um dos procedimentos iterativos da reestimação descritos nesta seção.

Contudo, para uma dada seqüência de entrada, O, P(O/l) é geralmente uma função não linear dos parâmetros do modelo.

Esta função por conseqüência terá muitos máximos locais em um espaço multidimensional.

Conceituação da Verossimilhança do HMM como função dos parâmetros do modelo.

O modelo ótimo, l*, corresponde ao máximo global da função, e a convergência neste ponto será quando l =l*.

Através de um procedimento iterativo na reestimação onde P(O / l) > P(O / l) e os parâmetros são atualizados, se consegue convergir para um ponto de máximo local.

Todavia, esta reestimação pode não convergir para o melhor modelo possível, l* (máximo global).

Assim, é comum a prática de iniciar o algoritmo várias vezes com diferentes conjuntos de parâmetros iniciais e obter como modelo treinado aquele que possuir o maior valor de P(O / l).

Os algoritmos mais utilizados nas pesquisas atualmente são Algoritmo de Reestimação Baum-Welch, o Procedimento de Viterbi (baseado no algoritmo de Viterbi), e o "Segmental Kmeans".

O Método de Baum-Welch é um procedimento iterativo, onde escolhido o modelo inicial, l i = (A, B,p), encontra-se a máxima verossimilhança (ML, Maximum Likelihood) dos parâmetros do modelo.

O método Baum-Welch basea-se no conceito estatístico da esperança do número de transições entre estados e da esperança do número de ocorrência das observações nos estados.

Usa-se o número esperado porque esta ferramenta estatística é a média sobre uma grande quantidade de dados.

O método basea-se no cálculo das variáveis "Forward" e "Backward", obtidas através do Procedimento "Forward-Backward".

Para compreensão deste método utiliza-se uma treliça de estados, assim composta, na vertical os estados e na horizontal as observações.

Implementação do cálculo das variáveis "Forward" e "Backward".

Verifica-se que cada observação possui uma probabilidade inicial de ocorrência em cada estado para t = 1 dada pela probabilidade conjunta do evento, observação o1 e estado i.

Para t > 1, a probabilidade de alcançar um estado j qualquer será o somatório do produto da probabilidade de estar no estado i no instante t com a probabilidade de transição, aij, do estado i para o estado j em t+1com 1 £ i £N.

Probabilidade conjunta de ocorrência da observação ot+1 e o estado j.

Com a recursão, este cálculo é efetuado para todas as observações de 1 a T.

O somatório de todas as verossimilhanças dos caminhos possíveis fornece a máxima verossimilhança da seqüência de observações, dado o modelo l.

As variáveis "forward" e "backward" são obtidas como o somatório das verossimilhanças dos caminhos que poderiam ter gerado as seqüências parciais, definidos como a variável "forward" representa a probabilidade conjunta da seqüência parcial e a observação ot ocorrer no estado i no tempo t dado o modelo l, a variável "backward" representa a probabilidade conjunta da seqüência parcial dado a observação ot pertence ao estado i e o modelo l.

No tempo t=1 (a primeira faixa na treliça) calcula-se os valores iniciais de a1,(a, variável forward).

Nos tempos t=2,3,T os valores de at(j) são calculados recursivamente para 1 £ j £ N.

O algoritmo é sumarizado a seguir.

Procedimento "Forward", início, recursão, fim.

Procedimento "Backward", início, recursão, fim.

Após o cálculo de a e b, calcula-se a probabilidade a posteriori definida, ou seja, a probabilidade conjunta de estar no estado i e na mistutra k dado o modelo e a seqüência de observações.

Os valores dos parâmetros estimados do HMM serão probabilidade inicial, probabilidade de transição, probabilidade da observação dado o estado.

Deste modo, define-se o modelo reestimado determinado a partir do modelo anterior.

Baseado no procedimento acima, usa-se no lugar de li, repete-se o cálculo da reestimação e encontra-se um ponto limite quando não houver melhoria em P (ou seja, no terceiro passo do algoritmo forward).

Foi provado por Baum e seus auxiliares que o modelo inicial 1 define um ponto crítico da função de verossimilhança, o modelo é mais provável do que o modelo l.

O Procedimento de reestimação Baum-Welch pode ser substituído pelo Procedimento otimizado de Viterbi, baseado no algoritmo de Viterbi.

Os parâmetros de l são reestimados, e ao contrário, do Procedimento de Baum-Welch onde se calcula o número esperado dos eventos, no Procedimento de Viterbi soma-se as transições e as observações pertencentes a cada estado, de acordo com o melhor caminho (seqüência) de estados.

Portanto, torna-se necessário para o desenvolvimento do Procedimento de Viterbi, a apresentação do seu algoritmo.

O algoritmo de Viterbi é sumarizado abaixo, início, recursão, finalização, o caminho ótimo é obtido retornando.

Após a segmentação das observações, de cada repetição, pelo algoritmo de Viterbi, consegue-se a melhor seqüência de estados.

Por exemplo, onde oT é observação no tempo T e estado S, admite-se que os caminhos ótimos, dado pelo algoritmo de Viterbi, das quatro repetições de treinamento.

Os parâmetros reestimados, são obtidos através da contagem do número das transições do estado i para o estado j, dividido pelo número de todas as transições feitas a partir do estado i (inclusive).

Os parâmetros média, covariância e coeficiente de mistura são obtidos para cada estado, após o agrupamento dos vetores de observações em M grupos (algoritmo "Kmeans").

A média é simplesmente estimada pela média de todas as observações pertencentes àquela Gaussiana, o mesmo para a covariância.

O coeficiente de misturas (quando M > 1) será igual ao número de observações classificado no grupo dividido pelo número total de observações classificado naquele estado.

Mostra o algoritmo "Modified K-means".

Um algoritmo que agrupa os padrões (ou vetores das características da voz do locutor) das repetições da elocução, classificadas em um estado, em M grupos tal que dentro de cada grupo os padrões sejam bastante similares.

No fluxograma, denota-se o i-ésimo grupo de um grupo solução j, na késima iteração, onde i = 1,2,j, e k = 0, 1, 2, Kmáx (onde Kmáx é o contador de iteração máxima).

Os valores de j vai de 1 (único grupo) até Jmáx (máximo número de grupos).

Como a convergência, dos algoritmos apresentados, é muito sensível aos valores iniciais de bj(o), Rabiner56 apresentou um algoritmo de treinamento, o "Segmental K-means" usado para estimar os valores dos parâmetros do modelo l.

A partir dos valores iniciais dos parâmetros do modelo li, aplica-se o Procedimento de Viterbi, e obtém-se então o modelo.

Estes parâmetros são utilizados na reestimação formal, através do Método Baum-Welch, onde se reestima todos os parâmetros.

O modelo resultante é comparado com o modelo anterior através do valor da verossimilhança, que pode ser obtida pelo algoritmo de Viterbi.

Se o valor de verosimilhança exceder um limiar, os parâmetros anteriores serão substituídos pelos atuais e todo o treinamento será repetido.

Caso contrário, terá convergido e os parâmetros são admitidos como do modelo treinado.

Para reconhecer se uma elocução teste pertence ou não a um determinado locutor (verificação), calcula-se a verossimilhança da elocução P(O/l), de ter sido gerada por este modelo.

Aceita se for maior ou igual a um determinado limiar.

Na existência de vários modelos (identificação), a medida de verossimilhança obtida em todos os modelos dos locutores provê uma comparação relativa entre os mesmos, aceitando-se aquele que possuir a maior.

Para o cálculo da verossimilhança utiliza-se o algoritmo de Viterbi, o qual fornece o caminho de máxima verossimilhança, da elocução teste, em pertencer ao modelo treinado.

Este valor é comparado a um limiar, obtido por meio de algum método de decisão.

Um dos métodos utilizados para o cálculo do limiar é o método de Bayes.

Assume-se que as distribuições obtidas com os valores das verossimilhanças para o locutor treinado e para os locutores não treinados são Gaussianas.

Calcula-se as médias e as variâncias intra-locutor e inter-locutores, obtendo Nverd(m1, s1) e Nfalso(m2, s2).

Igualam-se as duas distribuições e encontra-se o ponto médio (limiar) q.

Mostra a área de superposição entre as duas distribuições e um ponto de intersecção entre as curvas.

Esta área indica o quanto há de incerteza entre aceitar um locutor falso (falsa aceitação) ou rejeitar um locutor verdadeiro (falsa rejeição).

O ponto de intersecção, será o limiar entre as duas suposições.

Podendo ser ajustado até encontrar um valor ótimo para os dados de teste.

Na verificação do locutor, a elocução de um locutor supostamente conhecido é comparado com o modelo pretendido, se a verossimilhança for um valor acima do limiar q, a identidade é verificada como verdadeira.

Um limiar alto dificulta a falsa aceitação pelo sistema, mas aumenta o risco de ocorrer falsa rejeição.

E, ao contrário, um limiar baixo garante a aceitação de todos os locutores verdadeiros mas aumenta o risco da falsa aceitação.

Apresenta a identificação de um determinado sinal de voz como pertencente a um dos modelos treinados.

Quando existem V modelos treinados e uma elocução pretensa, pode-se fazer a identificação.

Na identificação compara-se a verossimilhança da seqüência de observações (calculado pelo algoritmo de Viterbi) com todas as verossimilhanças dos modelos treinados, e seleciona-se o locutor referente ao HMM com a maior verossimilhança.

Na identificação com rejeição, após a seleção do modelo com maior verossimilhança, faz-se a comparação desta com o limiar de aceitação associado.

Se for menor que este limiar, o locutor era considerado falso.

O modelo é muito sensível aos parâmetros iniciais, principalmente os valores iniciais das probabilidades das observações.

Utiliza-se, então, o artifício de dividir as observações, sequencialmente, por estados e obter a probabilidade inicial da observação, ot, em pertencer aos estados.

Com esta divisão os valores das probabilidades serão assumidos, onde a segmentação das observações pelo número de estados proporciona valores de probabilidades maiores para as observações pertencentes ao estado mais próximo.

E, durante o treinamento os parâmetros serão reestimados.

Este procedimento de treinamento é apresentado onde mostra o algoritmo "Segmental K-means".

Através dos parâmetros iniciais estima-se novos valores pelo Procedimento de Viterbi, e, por ser um procedimento iterativo, os parâmetros estimados serão reestimados pelo método de Baum-Welch.

Verifica-se a convergência do modelo e, caso este não ocorra, os parâmetros l reestimados serão estimados em uma nova iteração.

Foi apresentado o modelo de treinamento de forma resumida.

Neste capítulo será apresentado a estrutura do algoritmo admitindo-se o uso de várias repetições da locução para o treinamento.

Divide-se em duas partes, treinamento (algoritmo "Segmental Kmeans") e reconhecimento (algoritmo de Viterbi).

Para o treinamento, escolhe-se os parâmetros iniciais, dentro de algum critério, e aplica-se o algoritmo "Segmental Kmeans", dividido em estimação e reestimação.

Para iniciar o modelo, utilizam-se dois tipos de parâmetros, os fixos e os variáveis.

A escolha dos valores dos parâmetros fixos (número de estados e número de Gaussianas) não são comentados aqui, pois consistem em um dos objetos da pequisa.

A topologia do modelo (também parâmetro fixo) usada foi o Modelo Bakis (um caso particular da estrutura esquerda-direita).

Os parâmetros variáveis serão apresentados em forma de algoritmo comentado.

Probabilidades Iniciais de Transições, mostra-se que a atribuição de uma matriz de probabilidades de transições iniciais aleatória não influencia no resultado final dos parâmetros.

Desta forma, usa-se uma matriz com valores randômicos entre zero e um, respeitando-se a restrição estocástica e do avanço e retorno entre estados do modelo Bakis.

Probabilidade das Observações, de acordo com os autores Rabiner, Deller, os valores iniciais das probabilidades das observações influenciam na convergência do treinamento do modelo.

Assim, apresenta-se abaixo um algoritmo para estimar valores iniciais.

Algoritmo para o cálculo das Probabilidades das Observações.

Para cada repetição, as T observações serão divididas pelo número de estados (N).

Agrupa-se as observações nos estados de acordo com a divisão, número de observações por número de estados (T/N).

Utiliza o algoritmo K-means, em cada estado, para agrupar as observações em M grupos.

Para cada grupo encontra-se a média m jk, a covariância Ujk, e o coeficiente de mistura cjk de acordo com as equações.

Deste modo, obtém-se todos os parâmetros iniciais do modelo.

Para a estimação e reestimação usa-se o algoritmo "Segmental K-means".

Utilizam-se os parâmetros iniciais, ou os parâmetros reestimados, calculando-se os novos parâmetros do modelo, l, de acordo com o algoritmo abaixo anterior.

Para cada repetição, segmenta-se as sequências de Observações nos estados, utliza-se o algoritmo de Viterbi para encontrar a melhor seqüência de estados, agrupam-se os vetores nos estados de acordo com a segmentação de Viterbi.

Para cada estado, utiliza-se o algoritmo "K-means" para agrupar os vetores em M grupos, obtém-se de cada grupo a média m jk, a covariância Ujk e o coeficiente de mistura cjk de acordo com as fórmulas, calcula-se a matriz de probabilidades de transições de acordo com a segmentação de Viterbi, isto é, a melhor sequência de estados, conclui-se com a obtenção de todos os parâmetros do modelo estimado.

Utilizou, na reestimação do algoritmo, o método de Baum-Welch (conhecido também como EM, expectation maximization).

Este basea-se nos procedimentos "Forward" e "Backward".

Definição.

Ilustração da sequência de operações requerida para o cálculo do evento conjunto do sistema estar no estado i no tempo t e no estado j no tempo t+1.

Ilustra-se todas as seqüências de estados possíveis entre o estado Si e o estado Sj.

Verifica-se, então, que x t (i, j) é o valor esperado do número de transições do estado Si para Sj.

Observa-se que esta figura apresenta todas as possíveis seqüências de estados, com o estado Si incluído, observando uma determinada Gaussiana.

Ou seja, g t(i, k) é o cálculo do valor esperado do número de vezes que uma específica observação ocorre em uma determinada Gaussiana k e estado Si.

Observa-se que ao se somar todas as transições feitas do estado i para o estado j, tem-se a probabilidade de estar no estado i no tempo t.

Somando-se a variável g t(i) para todo t, encontra-se o número esperado de transições a partir do estado i.

Normalização.

Como os números usados estão na faixa entre 0 a 1 (valores probabilísticos) a multiplicação destes rapidamente leva o computador a um "underflow".

Usa-se um fator de escala multiplicado a a e a b, independente do estado, e dependente somente de t, com o objetivo de manter a t e b t num valor dentro da faixa de precisão do computador para 1£ t £ T.

Sendo cancelado no final dos cálculos.

Calcula-se, então, o valor do coeficiente, fazendo o inverso do somatório de todas variáveis "forward's", referentes aos estados em um determinado tempo t.

Número de sequências para treinamento.

Até este ponto, o cálculo de aij refere-se apenas a uma sequência de observação.

Adiante, verifica-se que um problema associado com treinamento do HMM, é que o número de sequências de observações usadas para o treinamento é finita.

Então, pode existir uma baixa probabilidade da ocorrência de um certo evento, por exemplo, baixa ocorrência da observação dentro de um estado impossibilitando o algoritmo de obter boas estimativas dos parâmetros do modelo.

Assim, para uma melhor obtenção de estimativas são utilizadas sequências múltiplas de observações (várias repetições da locução).

Parâmetros Reestimados.

Na reestimação dos parâmetros média, covariância e coeficiente dos grupos para o cálculo da probabilidade de observação, utiliza-se o valor esperado da frequência do vetor de características (observação) em cada estado, estando este em um dos k grupos.

Para o obter esta probabilidade, calcula-se todas as seqüências de estados que inclua o estado Sj, e observando este vetor.

Todos os caminhos possíveis incluindo o estado Sj observando-se a observação ot sobre todos os caminhos possíveis, em conjunto com a densidade de probabilidade da observação estar na Gaussiana k da mistura de Gaussianas.

Com o valor de g t(j,k) calculado, pode-se obter os valores para o coeficiente, a média e a covariância reestimadas dos grupos.

Portanto, as fórmulas serão coeficiente do grupo K no estado j sobre o número esperado de estar no estado Sj, média do grupo k no estado j ponderado pela observação sobre o número esperado de estar no estado Sj e na Gaussiana k, covariância do grupo k no estado j ponderado pela covariância do vetor sobre o número esperado de permanecer no estado Sj e na grupo k.

Como observado no cálculo do aij, utilizam-se R locuções (múltiplas locuções) para o treinamento do HMM.

Para obtenção das fórmulas para a reestimação, devem ser feitas algumas simplificações, mostradas nas equações seguintes onde representam os parâmetros da o-ésima locução.

Neste cálculo observa-se que se pode eliminar o termo do somatório das probabilidades.

Logo, as equações para o cálculo da probabilidade de observação serão coeficiente reestimado, forma expandida, forma simplificada, média reestimad, forma expandida, forma simplificada, covariância reestimada, forma expandida, forma simplificada.

Assim sendo, obtém-se desta maneira para cada estado e grupo os parâmetros do modelo reestimado.

O diagrama da fase reconhecimento, ilustra a simplicidade do algoritmo.

Com a utilização, somente do algoritmo de Viterbi e dos parâmetros do modelo treinado l, obtém-se a verossimilhança P(O / l) para um dado vetor de entrada (teste).

O procedimento para reconhecimento de uma locução de teste com vários HMM foi exposto no capítulo anterior.

O algoritmo de Viterbi utiliza a multiplicação entre seus termos, os quais são valores probabilísticos.

Por conseguinte, obtém-se resultados com magnitudes extremamente pequenas podendo ocorrer "underflow".

Uma solução12,14 é o uso da implementação alternativa de Viterbi.

Aplica-se o logaritmo nos parâmetros do modelo, evitando desta forma a necessidade de qualquer multiplicação.

A medida resultante calculada para o modelo l, de uma sequência de observações, O, onde Q é a sequência dos estados mais provável.

A medida não é exatamente uma probabilidade, mas é evidente que ela é uma magnitude de verossimilhança14, com a qual se permite uma comparação relativa entre os modelos.

Note-se que, tomando o logaritmo de bj(ot) será equivalente a produzir uma máxima verossimilhança (ou, quase equivalente, a distância de Mahalanobis) da distância da observação ot (locução de teste) até a média das observações treinadas, assumindo ser uma densidade Gaussiana.

Este capítulo tem por objetivo descrever os principais procedimentos utilizados na obtenção das elocuções, para treinamento e teste dos modelos dos locutores, os algoritmos utilizados para a extração das características e a implementação do sistema de reconhecimento automático de locutor (RAL) dependente do texto utilizando HMM contínuo, apresentado nos Capítulos 3 e 4.

O sistema RAL proposto foi desenvolvido no Laboratório de Processamento de Sinais do IME utilizando-se um microcomputador 486 DX4 100 MHz, equipado com uma placa Sound Blaster 16 (Sound Blaster é marca registrada da "Creative Labs, Inc").

Este sistema utiliza os Modelos de Markov Escondidos Contínuos (CDHMM, Continuous Densities Hidden Markov Models) na fase de treinamento e teste, os quais permitem uma modelagem estatística do sinal de voz12,13 na representação dos locutores.

O sistema RAL é um processo de reconhecer um locutor pretenso, como verdadeiro ou falso, através das informações obtidas do sinal de sua voz.

Tem duas tarefas distintas, verificação e identificação.

Na tarefa de verificação, o limiar de aceitação q de cada HMM treinado foi obtido pelo método Bayes.

O locutor era considerado verdadeiro se a verossimilhança, obtida pela aplicação do algoritmo de Viterbi12, da seqüência das observações teste ficasse acima do limiar de aceitação do HMM correspondente àquele locutor.

Na identificação, após a aplicação da elocução teste em todos HMM, o locutor era associado ao modelo que produzisse a maior verossimilhança.

Na identificação com rejeição, após a seleção do modelo com maior verossimilhança, fez-se a comparação desta com o limiar de aceitação associado.

Se fosse menor que este limiar, o locutor era considerado falso.

O trabalho em laboratório dividiu-se em 3 partes principais, aquisição das elocuções, gravação, processamento da Base de Dados, pré-processamento dos sinais a serem analisados, extração das características do sinal de voz, Projeto do Sistema de Decisão, atribuição dos parâmetros fixos dos HMMs, treinamento e teste dos HMMs.

O procedimento utilizado é descrito no diagrama em bloco.

Utilizou-se a placa Sound Blaster 16 da Creative, Inc para a gravação das elocuções.

As principais características da placa Sound Blaster são realiza amostragens (conversão A/D) de sinais de áudio em mono ou estéreo com taxas de amostragem de 11, 22 ou 44 Khz.

Grava e lê arquivos em disco com extensão WAV (padrão de arquivos de áudio amostrado padronizado internacionalmente e adotado pela Microsoft) e obtém amostras do sinal em 8 ou 16 bits, ou seja, o sinal digital obtido pode conter 256 ou 65535 níveis de quantização, possibilitando a análise de sinais de áudio com faixa dinâmica de 21 e 45 dB respectivamente.

Utilizou-se a taxa de amostragem igual a 11025 Hz (valor mínimo fornecido pela placa Sound Blaster).

Como a maior freqüência da banda passante da voz é igual a 5 kHz o sinal não sofre "aliasing".

Após a realização das gravações, criam-se arquivos com extensão.

WAV.

Estes arquivos são separados em dois conjuntos, masculino e feminino, denominados LaxEyRz, onde a pode ser M conjunto masculino ou F conjunto feminino, x é o número do locutor, y é o número da elocução e z é o número da repetição desta frase.

Como exemplo, o arquivo LM1e2r3 representa a repetição número 3 da elocução número 2 feita pelo locutor masculino 1.

As sessões de gravações foram realizadas em uma sala sem isolamento acústico, utilizando um PC com placa Sound Blaster 16.

Em cada sessão gravou-se duas repetições de cada frase em horários e dias diferentes.

Para treinamento e teste do sistema foram utilizados dois conjuntos de locutores, o masculino (CM) com 5 locutores para treinamento e teste e 3 somente para teste e o feminino (CF) com 4 locutores para treinamento e teste e 3 somente para teste.

Foram utilizadas as frases "O prazo tá terminando" (fr1) e "Amanhã ligo de novo" (fr2) considerada as mais adequadas conforme as análises fonéticas/fonológicas do Departamento de Lingüística da USP em um conjunto de frases para Reconhecimento de Locutores.

Realizaram-se para cada locutor 70 gravações de cada frase (50 para treinamento e 20 para teste).

Foram realizadas também, 20 gravações de outros locutores que não participaram do treinamento, totalizando assim, 360 locuções teste do conjunto CM e 290 do conjunto CF para cada frase.

A cada seção de gravação realizaram-se apenas 2 gravações das elocuções fr1 e fr2, com a intenção de capturar a variabilidade intra-locutor.

Os dados foram pré-processados com filtro de pré-ênfase e utilizaram-se janelas Hamming de 20 ms com superposição de 50%.

O vetor de características, é composto de 12 coeficientes mel-cepestro, 12 coeficientes delta-mel-cepestro, log-energia e delta log-energia13.

Após a obtenção do sinal de voz, fez-se a extração das características mais relevantes do sinal de voz do locutor.

O sistema é, então, treinado para torná-lo discriminante em relação às locuções de outros locutores.

Estas característcas foram escolhidas com base em trabalhos publicados recentemente.

A seguir, são apresentados os procedimentos e as considerações utilizadas nas implementações.

As gravações foram realizadas no Laboratório de Processamentos de Sinais em uma sala sem isolamento acústico.

Apresentam exemplos de elocuções, no domínio do tempo das frases fr1 "O prazo tá terminando", e fr2 "Amanhã ligo de novo", respectivamente, ambas pronunciadas por um locutor do sexo masculino.

Fez-se o cálculo da relação sinal ruído (RSR), obtendo-se para fr1 uma RSR máxima igual a 32 dB e a média igual a 21,99 dB.

Para a fr2 a RSR máxima foi de 29,43 dB e a média de 22,22 dB.

Como todas as gravações foram realizadas no mesmo equipamento e no mesmo ambiente, o nível de ruído manteve-se aproximadamente constante nos valores citados.

Devese ressaltar que a baixa relação sinal ruído não invalida o processo de identificação tendo em vista que o sistema foi proposto, treinado e testado com locuções gravadas em situações idênticas.

Para o reconhecimento de locutores se faz a detecção dos pontos extremos de cada elocução com o objetivo de separar a região falada da região ruidosa, isto é, a localização do início e do fim de cada locução.

Desse modo evita-se a extração de características nas regiões de silêncios anteriores e posteriores às elocuções a serem analisadas.

Utilizou-se o algoritmo de Rabiner e Sambur para a determinação dos pontos extremos que exige uma relação sinal ruído mímina, pelo menos, de 30 dB.

Tal algoritmo se baseia em duas medidas do sinal de voz, a energia e a taxa de cruzamento do zero obtidas em janelas de 10 ms de duração do sinal.

Um intervalo de 100 ms no início da elocução (10 janelas) é utilizada para efetuar uma estatística do ruído de fundo.

Este algoritmo caracterizase por ser adaptativo às condições do ambiente acústico.

Como as elocuções obtiveram, em geral, taxas médias inferiores a este valor, da ordem de 22 dB, fizeram-se modificações nos limiares superior e inferior de energia dos sinais utilizados, obtendo-se resultados satisfatórios porém susceptíveis a erros.

Portanto, os limiares foram heurísticos e, mesmo assim, não se obteve 100% de frases extraídas corretamente.

Por causa disso, após a extração dos pontos extremos de todas as elocuções de cada locutor fez-se uma verificação auditiva e visual das elocuções.

A forma mais comum de se obter os coeficientes mel-cepestro é utilizando a transformada de Fourier por meio dos parâmetros LPC.

Pelos motivos apresentados optou-se por calcular os parâmetros do mel cepestro utilizando a técnica LPC (obtido pelo método da autocorrelação).

Para se obter os coeficientes mel-cepestro do trato vocal Cq(n) deve-se estimar a densidade espectral do trato vocal, para cada sinal janelado, ponderada pela escala da freqüência mel e, em seguida, obter o valor da log energia, no domínio da freqüência, dentro de uma banda crítica em torno da freqüência mel central em cada um dos 20 filtros13.

Concluise com o cálculo dos 12 coeficientes mel-cepestro aplicando-se para cada filtro.

Supondo-se que o sinal da voz seja estacionário em intervalos de tempo curto.

Ou seja, suas características se mantêm constantes e sabendo-se que o sinal de voz é a convolução do sinal da excitação (um trem de impulsos quase periódicos) com a resposta ao impulso do filtro do trato vocal, sendo a excitação suposta ser um processo estocástico gaussiano branco.

Pode-se considerar que as propriedades do trato vocal permanecem constante e consequentemente representá-lo como um filtro digital, invariante no tempo, com as amostras do sinal de voz admitidas como saídas do filtro.

Representa-se o filtro digital, em cada intervalo de tempo da janela, pelo conjunto dos coeficientes da resposta ao impulso de duração finita (FIR).

Um modelo de filtro bastante usado, para o sinal de voz é o modelo autoregressivo (AR).

Supondo-se que o processo aleatório que esta sendo analisado y(n), saída do filtro, possua uma entrada espectralmente invariante, estima-se então a densidade de potência espectral da saída y(n).

O processo y(n) pode ser modelado como a saída de um filtro FIR com função de transferência do tipo "só-de-pólos" excitado por processo de ruído branco (amostras de um processo estocástico gaussiano estacionário e ergódico).

Analizando-se no círculo unitário do plano Z, ou seja, fazendo-se z=ejl, para uma entrada impulsional com distribuição Gaussiana, a densidade espectral da saída de um sistema linear invariante discreto (LID) é dada.

Portanto a densidade espectral de potência de saída, f(l), do sistema LID será dada, onde Px(n) é a densidade espectral de potência da entrada e p o número de pólos necessários à aproximação da densidade espectral da voz.

Normalmente se utilizam 14 pólos para modelagem da região entre 0 a 5KHz.

Neste ponto, obtém-se a densidade espectral f(l) do sinal da saída do sistema LID.

Para que o eixo de freqüências do espectro de y [n] corresponda à escala mel, ou seja, linear até 1000 Hz e logarítmica acima, faz-se a filtragem, ponto a ponto, do espectro de y(n) utilizando os filtros triangulares da escala mel obtidos a partir das Equações.

Após a filtragem, calcula-se a energia de tempo curto do sinal de voz, no domínio da freqüência para cada filtro.

Algumas pesquisas tem sugerido o uso do log energia dentro da banda crítica em torno da freqüência mel.

Através da Equação calcula-se o log energia, onde Hi é o filtro triangular para o qual se está calculando a energia dos k pontos da DFT e N' é o número de pontos usado no cálculo da DFT.

Portanto, o log energia total em cada filtro ki.

Mostra as freqüências de corte e a largura de banda crítica, de acordo com a Equação.

Este cálculo pode ser visto como a filtragem da seqüência y(n) por um filtro passa baixa com freqüência de corte dada por Fc=kFs / N, onde Fs é a freqüência de amostragem da seqüência y(n), N é o número de amostras do sinal contido em cada janela e k é o número do filtro.

Mostra a densidade espectral obtida para a primeira janela de 20 ms da elocução "O prazo tá terminando", calculada utilizando N igual a 1024 pontos para o cálculo da densidade espectral.

De posse da evolução da energia do sinal (do trato vocal) obtida a partir dos filtros da escala mel faz-se o cálculo dos coeficientes mel-cepestro.

Utiliza-se a Equação para o cálculo dos coeficientes derivados do LPC (MCLPC), onde i é o número de coeficientes cepestro e Ek, k, representa as saídas da log energia do k-ésimo filtro.

Apresenta o gráfico da evolução dos 12 primeiros coeficientes mel-cepestro para o quadro.

Para representar as variações dinâmicas do espectro da voz, por exemplo as variações encontradas nos fonemas consonantais, e aumentar a robustez do sistema utilizamse os coeficientes delta-mel-cepestros.

Estes parâmetros são obtidos por meio da diferença entre os coeficientes mel-cepestro de d janelas a frente com os coeficientes melcepestro de d janelas anteriores.

Admitindo-se que os coeficientes mel-cepestro (MCLPC) de uma dada janela estão dispostos como um vetor, a Equação torna-se Deltai(n), onde n é a n-ésima janela e M é igual ao número dos coeficientes cepestro.

O valor atribuído a d neste trabalho foi 2.

Apresenta a evolução dos 12 coeficientes delta-mel-cepestro obtido para a primeira janela da vogal da elocução fr1.

Evolução dos coeficientes delta-mel-cepestro obtidos através da diferença entre coeficientes mel-cepestro de janelas deslocadas por d igual a 2.

Conforme apresentado no Item, para o cálculo dos coeficientes melcepestro, utilizou-se a energia de tempo curto do sinal de voz, calculada no domínio da frequência, para cada filtro.

Aplicando-se o somatório para todos os filtros triangulares, encontra-se a energia total do segmento de 20 ms do sinal de voz (sinal janelado).

Utilizou-se o logaritmo dos parâmetros da energia para se obter uma compressão da sua faixa dinâmica, a qual é expressiva.

Para a extração dos coeficientes delta-log-energia aplica-se os mesmos procedimentos e utiliza-se a Equação.

A estrutura do modelo a ser usada é a esquerda-direita, uma particularidade do modelo Bakis e o procedimento de treinamento "Segmental-Kmeans".

Os parâmetros variáveis iniciais são selecionados conforme descrito no Capítulo 4.

Probabilidade inicial (p) será fixa durante todo o treinamento.

De acordo com o modelo Bakis, valores da matriz inicial das probabilidades das transições (A), aleatória, respeitando-se as restrições do modelo Bakis.

Valores da matriz inicial da densidade de probabilidade de saída das observações (B), o treinamento do modelo mostrou-se mais sensível aos valores atribuídos inicialmente a matriz B.

Assim, visando obter um estimativa dos valores iniciais que satisfaça a evolução temporal da seqüência de observações nos estados segmenta-se as seqüências de observações nos N estados.

Em cada estado utiliza-se o algoritmo "kmeans" modificado para separar as observações em M grupos e obtém-se valores das probabilidades de observações por meio da mistura de M Gaussianas.

Testou-se dois algoritmos distintos para a separação das observações.

O primeiro, executa a divisão das R seqüências de observações por N estados, sendo o resto da divisão somado ao último estado.

Apresenta as R seqüências de observações divididas por N estados e o resto de cada divisão somado ao último estado.

O segundo algoritmo, proposto e testado neste trabalho, faz a divisão da primeira seqüência de observações pelo número N de estados e o resto da divisão é somado ao primeiro estado.

Para a segunda seqüência o resto é somado ao segundo estado e assim por diante para todas as elocuções.

Após a N-ésima seqüência, o resto da seqüência número N+1 obtido pela divisão é acrescentado ao primeiro estado, retornando-se ao processo iterativo anterior.

Desse modo, o número de observações dentro dos estados tende a ser mais homogêneo.

Apresenta a divisão das R seqüências de observações por N estados e o resto acrescentado seqüencialmente a cada estado até r igual a N.

A partir de r +1 acrescenta-se o resto ao primeiro estado e assim sucessivamente até R seqüências.

A escolha dos valores dos parâmetros fixos iniciais, N (número de estados) e M (número de grupos), para o primeiro experimento, foram efetuadas do seguinte modo12.

N, aproximadamente 3 estados por fonema.

Desse modo, a frase 1 foi treinada inicialmente com 36 estados e a frase 2 com 42 estados.

M, 5 grupos para cada estado.

Os parâmetros escolhidos para os demais testes foram empíricos.

Relaciona os parâmetros utilizados nos treinamentos e testes, onde LMfr1 é o locutor masculino pronunciando uma repetição da frase 1 e g5s12 significa uma mistura de 5 Gaussianas e uma estrutura com 12 estados.

Por causa do número limitado de sequências de observações para treinar o modelo, pode ocorrer, durante o treinamento, uma probabilidade de observação nula para determinado estado.

Causado por as observações que possuem uma pequena probabilidade de ocorrer neste estado em relação ao estado seguinte da cadeia de Markov, portanto, obtendo média e covariância nulas.

Entretanto, o locutor treinado pode pronunciar uma elocução que possua esta probabilidade de observação não nula.

Assim, admite-se como valor mínimo de 0,0001 para os parâmetros associados à mistura de Gaussianas12.

Assume-se a convergência do modelo no treinamento quando a diferença entre as verossimilhanças anterior e atual for menor do que 1%.

Caso a verossimilhança l* obtida na reestimação seja menor que a estimada l acrescenta-se, então, um valor empírico de 10% sobre os valores dos parâmetros, onde A, media, covar e coef são os parâmetros do modelo atualizados com 10% e Aaux, mediaux, covaraux e coefaux são os parâmetros covariância e coeficiente reestimados.

E prossegue-se com nova reestimação.

Na fase de reconhecimento, aplica-se o algoritmo de Viterbi numa elocução teste obtendo-se um valor de verossimilhança.

Esta verossimilhança pode ser interpretada como uma distância da elocução ao modelo treinado.

Verifica-se que este valor é influenciado pelo número de observações da elocução, número de janelas.

Portanto, uma elocução falsa pode ser admitida como verdadeira se seu comprimento for suficientemente grande tal que o algoritmo de Viterbi forneça uma verossimilhança acima do limiar.

Consequentemente, torna-se necessário uma normalização da verossimilhança da elocução teste pelo seu número de janelas.

Apresenta um gráfico contendo no eixo X o número da elocução testada e no eixo Y o valor de sua verossimilhança.

Observa-se que os valores das verossimilhanças não normalizadas dos locutores falsos e locutor verdadeiro, se misturam dificultando a determinação de um limiar de separação.

Mostra o gráfico com as mesmas elocuções do gráfico anterior, porém, com a verossimilhança normalizada.

Na fase de teste, para cada elocução apresentada ao modelo l, obtém-se como resposta um valor que ao ser comparado com um limiar, obtido pelo método de Bayes, determinará se a mesma é falsa ou verdadeira.

Apresenta as distribuições das verossimilhanças dos locutores falsos e locutor verdadeiro e um limiar (teta) igual a 17,47 para um modelo treinado e testado com 5 grupos e 60 estados.

Apresenta os valores das verossimilhanças sem normalização obtidos das 70 elocuções do locutor verdadeiro e locutor falso.

Representados por elocuções do locutor falso e o elocuções do locutor verdadeiro.

Após a normalização das verossimilhanças das elocuções observa-se uma maior separação entre as falsas e as verdadeiras.

Neste, caso o limiar de separação poderia ser 20.

Distribuições das verossimilhanças das elocuções dos locutores falsos e elocuções do locutor verdadeiro separadas pelo limiar obtido pelo método Bayes, onde var-fal, med-fal, var-ver e med-ver são a variância e a média da distribuição dos locutores falsos e a variância e a média da distribuição do locutor verdadeiro, respectivamente.

Com o eixo x mostrando os valores das verossimilhanças das elocuções obtidas no modelo.

Pelo fato do cálculo do limiar ser obtido sobre valores das verossimilhança das elocuções treinadas, então, pode acontecer erro de falsa rejeição quando se apresenta elocuções verdadeiras para teste, como é verificado onde a área sob a linha tracejada representa a probabilidade de ocorrência das elocuções verdadeiras não treinadas (teste) e a área sob a linha contínua representa a probabilidade de ocorrência das elocuções treinadas.

Nota-se que para este modelo, treinado com g5s60, o limiar distingue as elocuções verdadeiras das falsas mas não separa totalmente as elocuções verdadeiras utilizadas no teste, ocorrendo falsa rejeição.

A utilização de outros parâmetros no modelo l altera as distribuições das verossimilhanças.

Na utilização de 5 grupos e 12 estados as distribuições são como apresentam.

Verifica-se que nestes parâmetros houve uma melhor aceitação das elocuções verdadeiras de teste pelo limiar, atribuindo valor zero para falsa aceitação e rejeição.

O objetivo da verificação é verificar se uma dada elocução de teste pertence ou não ao locutor com o qual o modelo foi treinado, esta decisão é baseada em algum limiar previamente estipulado.

Pode acontecer dois tipos de erros, falsa rejeição quando o sistema rejeita uma elocução do locutor verdadeiro, ou seja, sendo a entrada uma elocução do locutor verdadeiro, a verossimilhança desta elocução fica abaixo do limiar estabelecido, falsa aceitação quando o sistema reconhece um locutor estranho como verdadeiro, ou seja, sendo a entrada uma elocução pertencente a um locutor qualquer (diferente do utilizado no treinamento), a verossimilhança obtida fica acima do limiar estabelecido.

Quanto mais próximo está o limiar da média da distribuição das elocuções verdadeiras maior será a probabilidade de ocorrer um erro de falsa rejeição, e por outro lado, quanto mais distante estiver maior será a probabilidade de ocorrer erro de falsa aceitação.

A tarefa da identificação é sub-dividida entre identificação do locutor e identificação do locutor com rejeição.

Na identificação, após a obtenção do valor da verossimilhança da elocução teste, para todos os modelos, escolhe-se a maior verossimilhança e atribui-se a elocução àquele modelo.

Na identificação com rejeição, uma vez obtida a verossimilhança da elocução para todos os modelos, seleciona-se aquele que forneceu a maior.

Faz-se uma comparação desta verossimilhança com o limiar de verificação referente àquele modelo.

Aceita-se quando maior e recusa-se caso contrário.

Ilustração da identificação e identificação com rejeição.

No primeiro caso, aceita-se a elocução como verdadeira para um determinado modelo (HMM) se a verossimilhança (v) fornecida por ele for a maior entre todas.

No segundo caso, após a seleção deste modelo (identificação) faz-se uma comparação com o limiar de verificação, aceitando-a ou rejeitando-a.

Poderão ocorrer por ocasião do teste, 3 tipos de erros, falsa rejeição quando o sistema rejeita uma elocução pertecente a um dos locutores utilizados no treinamento.

Ou seja, quando a verossimilhança obtida com uma elocução teste (de um dos locutores utilizados no treinamento) fica abaixo do limiar estabelecido.

Falsa aceitação, quando o sistema atribui a elocução de um locutor estranho a um dos locutores utilizados no treinamento.
Ou seja, quando a verossimilhança obtida com uma elocução de teste de um locutor não utilizado no treinamento, ultrapassa o limiar estabelecido para qualquer um dos locutores utilizados no treinamento.
Falsa identificação quando a verossimilhança de uma elocução de um locutor utilizado no treinamento ultrapassar o limiar estabelecido, porém de outro locutor utilizado no treinamento.

Para a elaboração deste trabalho foram desenvolvidos vários programas utilizando o software MATLAB 4,2 for Windows da The MathWorks, Inc.

As principais rotinas desenvolvidas e utilizadas nesta tese foram as seguintes, extração das características, treinamento e teste do HMM.

Os resultados obtidos no trabalho da Tese estão relatados e analisados neste capítulo.

Desde a decisão sobre a escolha dos algoritmos até o desempenho geral do sistema.

Para tal, serão abordados os seguintes tópicos, algoritmo de inicialização dos modelos, tempo gasto para treinamento dos modelos, resultados obtidos no reconhecimento, estudo do limiar utilizado no reconhecimento, avaliação do sistema.

Mostrou-se a necessidade de estimar parâmetros iniciais que estejam próximos a um máximo da função de verossimilhança.

Para a matriz A, algumas experiências mostraram que a estimação de valores aleatórios ou uniformes não influência na convergência do modelo.

Entretanto, o treinamento do modelo mostrou-se mais sensível aos valores atribuídos inicialmente a matriz B.

Assim, onde apresentam os algoritmos de inicialização que tem como função dividir as seqüências de observações pelo número de estados do modelo e estimar as probabilidades iniciais das observações, faz-se uma avaliação de qual dos dois algoritmos de inicialização, dos parâmetros de B, apresenta um melhor desempenho em relação à convergência do modelo.

Realizaram-se vários testes com o conjunto CF, utilizando a frase fr1 e o modelo g5s36.

Apresenta os resultados da divisão de 50 repetições (seqüências de observações) da elocução fr1 por 36 estados.

Por motivos práticos, apenas os estados número 1, 35 e 36 são apresentados.

Observa-se que o primeiro algoritmo possui, inicialmente, uma tendência em deixar o estado N com maior número de observações e que durante o treinamento as observações serão melhor modeladas e distribuídas de acordo com as probabilidades dos parâmetros variáveis reestimados.

Já o segundo algoritmo faz uma distribuição mais homogênea das observações dentro dos estados na inicialização, facilitando a modelagem durante a reestimação.

Verificou-se que a distribuição das observações na inicialização pelo algoritmo 2 aproximou da distribuição obtida na convergência do modelo.

Entretanto, para o algoritmo 1, a distribuição das observações na inicialização foi, para o estado 36, 637 observações acima do valor na convergência do modelo.

O algoritmo 2 proporcionou uma melhor separação das observações nos estados para todos os modelos, exceto para o locutor 1, o qual convergiu com 3 iterações e, mesmo assim, a diferença entre as verossimilhanças dos modelos foi de 0,0088.

Para o locutor 3 e algoritmo 2, observa-se que apesar da ocorrência de 3 iterações e do maior tempo de treinamento (8h e 09min gasto pelo modelo do alg e 13h e 40min pelo modelo do alg), o valor da verossimilhança foi superior ao do algoritmo 1 já na segunda iteração.

Observa-se também que os modelos locutor 1 e locutor 3 convergiram na segunda iteração.

Assim, concluiu-se por meio da divisão das observações pelo algoritmo 2, ou seja uma divisão mais homogênea das observações, obteve-se um valor de convergência melhor na maioria dos modelos.

Os programas desenvolvidos para treinamento e teste dos modelos foram escritos na linguagem MATLAB, por ser a linguagem muito utilizada nos meios acadêmicos e de fácil implementação.

Entretanto, por ser uma linguagem interpretada, a execução dos programas ou rotinas torna-se lenta.

Fizeram-se, então, testes para verificar o tempo gasto no treinamento dos modelos.

Realizaram-se dois tipos de teste.

No primeiro treinaram-se 10 modelos, com 8 estados e 5 grupos, utilizando 30 elocuções de cada digíto de 0 a 9, pronunciadas por um locutor do sexo masculino e empregando-se o algoritmo "k-means" escrito em linguagem MATLAB.

No segundo, realizou-se o mesmo procedimento descrito acima, entretanto, empregando-se o algoritmo "k-means" escrito em linguagem C.

Analisando os dados obtidos no teste, verificou-se que o tempo médio gasto para treinamento do modelo do dígito, empregando a linguagem MATLAB, foi de 2 horas e 38 minutos enquanto que para a linguagem C foi de 30 minutos, isto é, aproximadamente 5 vezes menos.

Para treinamento do modelo do dígito, cada seqüência de observações possuía em média 67,20 observações, e, para as 30 repetições utilizadas somaram-se 2016 observações que foram dividas em N estados.

No treinamento de um modelo de um locutor, porém, cada seqüência de observações possui em média 164,71 observações, média das elocuções fr1 mais fr2 pronunciadas pelos locutores masculinos e femininos, e para as 50 repetições de uma elocução utilizadas somam-se 8235,5 observações a serem divididas em N estados e agrupadas em k grupos pelo algorítmo "k-means".

Neste caso, o tempo de processamento, quando todas as rotinas são escritas em MATLAB, se tornará muito alto, dada a quantidade de dados a serem processados.

Portanto, nos treinamentos realizados para os modelos dos locutores utilizou-se programas híbridos em MATLAB e C.

Para uma análise real do tempo gasto durante o treinamento dos modelos dos locutores, que mostra estes tempos para o conjunto feminino utilizando a frase 1 e a frase 2.

Comparou-se os modelos g5s36, g10s36, g5s42 e g10s42 (onde g é o número de grupos e s o número de estados).

Nesta tabela, observa-se que para a frase 1 o aumento do número de estados ou de grupos provocou um aumento no tempo de treinamento.

Enquanto que, para a frase 2, determinados locutores (L1, L3 e L4) tiveram seu tempo de treinamento reduzido quando se aumentou o número de estados.

Mostra, para CFfr2 (conjunto feminino utilizando a frase 2), as variações dos tempos ocorridos nos treinamentos e entre parênteses o número de iterações obtidos em cada modelo.

O número de grupos é mantido constante para efeito de comparação.

Entretanto, observa-se que nada se pode concluir sobre um melhor desempenho global das frases fr1 e fr2 em relação ao tempo de treinamento.

Em primeira análise, observa-se que o modelo g10s12 obteve, para todos os locutores do conjunto CFfr2, um melhor desempenho em relação ao tempo.

Mostram o tempo de convergência no treinamento dos modelos g5s12, g5s36, g10s36 e g5s60 para os locutores CMfr1, CMfr2, CFfr1 e CFfr2.

Embora não seja claramente discernível, do ponto de vista do tempo da convergência, de qual frase apresentou um razoável desempenho no treinamento do modelo, algumas conclusões são evidentes, não existiu nenhuma das duas que apresentasse um melhor desempenho em todos os treinamentos dos modelos para conjuntos CM e CF, em relação ao tempo de treinamento, verificou-se que o aumento do número de estados não proporcionou diminuição do tempo de treinamento.

Baseando-se na representação do conjunto CFfr2, nota-se uma tendência da redução do tempo quando se aumenta o número de estados.

Entretanto, que representam os conjuntos CMfr1, CMfr2 e CFfr1 respectivamente, vê-se que não ocorreu nenhuma redução.

Constatou-se que o modelo que apresentou um melhor desempenho, em relação ao tempo de treinamento, para todos os locutores e frases utilizadas foi o modelo g5s12.

Realizaram-se 137 treinamentos envolvendo locutores masculinos (conjunto masculino CM) e femininos (conjunto feminino CF).

Após o treinamento, foram realizados dois testes, o primeiro, utilizando as elocuções empregadas no treinamento do modelo (treino), e o segundo, com as elocuções não utilizadas (teste), sendo essas independentes dos modelos treinados.

Observa-se que, os testes de verificação dos modelos do conjunto CM, utilizando as frases fr1 e fr2, não apresentaram nenhum erro de falsa aceitação.

Quando se realizou o teste com as elocuções treinadas, verificou-se que para o conjunto CMfr2 nos modelos g5s60, g10s36 e g10s42 não foi obtido nenhuma falsa rejeição, e, para o conjunto CMfr1 foram obtidas falsas rejeições em todos os testes dos modelos.

Cabe ressaltar que todos os modelos do locutor 3 do CMfr1 rejeitaram a elocução no 49.

No conjunto CF obteve-se falsa aceitação para a frase fr1 no modelo g3s12 e para a fr2 nos modelos g3s12 e g5s12.

Praticamente em todos os modelos, com as excessões de g10s60 (lf1) e g10s42 (lf2), apresentaram-se falsas rejeições.

Nestes testes não foi verificado o desempenho do sistema no reconhecimento de locutores mímicos.

O aumento do número de estados tanto para o conjunto CM quanto CF provocou uma especialização dos modelos às elocuções utilizadas no treinamento.

Porquanto, às elocuções para teste são rejeitadas em maior número com o aumento do número de estados ou Gaussianas por misturas.

Verifica-se que devido ao número fixo de observações, ou seja uma mesma quantidade de repetições da frase para treinamento de todos os modelos, uma melhor reestimação dos parâmetros não é permitida via algoritmo "forward-backward", que utiliza para cálculo das probabilidades das transições e das observações o valor esperado das ocorrências dos eventos das observações nos estados.

Identificação sem Rejeição.

Na identificação sem rejeição todos os conjuntos, em todos os testes, obtiveram 100% de acerto, com excessão do conjunto CMfr2 que identificou a elocução de número 20 pertecente ao locutor 4 como sendo do locutor 1, em todos os testes.

Mostra um gráfico que apresenta os valores das verossimilhanças obtidas por cada elocução da frase fr2 do locutor masculino 4 quando testadas em seu modelo.

Verifica-se, que obtiveram suas verossimilhanças bem abaixo da média das elocuções de 1 a 16.

Mostra as verossimilhanças obtidas pelas elocuções do locutor verdadeiro (locutor 4) e as obtidas pelas elocuções dos falsos locutores no modelo do locutor 4.

Observam-se dois grupos distintos.

Entretanto, a elocução de número 20 apresenta-se como pertencente ao grupo dos falsos locutores.

Assim, na tarefa de identificação sem rejeição essa elocução foi atribuída ao locutor 1, onde a maior verossimilhança foi obtida pela elocução 20 do locutor 4 no modelo do locutor 1.

Este resultado mostra que apesar das elocuções estarem com os pontos extremos bem delimitados entre o sinal de voz e o ruído, possui uma diferença nas verossimilhanças obtidas em relação às outras elocuções verdadeiras.

Portanto, pode-se concluir que foram pronunciadas de forma diferente, ou seja, contendo eventos acústicos não apresentados nas elocuções de treinamento.

Como pôde ser verificado, a elocução 20 pertencente ao locutor 4 é identificado como do locutor 1.

Entretanto, no caso da identificação com rejeição, este erro não ocorre porque após a seleção do modelo com a maior verossimilhança compara-se esta com o limiar do modelo.

Neste caso, o valor para o locutor 1, utilizando o modelo g5s36, é igual a 18,6730.

Identificação com Rejeição.

Na realização dos testes de identificação com rejeição verificou-se que apenas os locutores utilizados para teste obtiveram elocuções falsamente identificadas por algum modelo.

E, dos resultados da verificação nota-se que apenas o conjunto CF obteve erro de falsa aceitação.

Portanto, mostram os valores obtidos na identificação dos conjuntos CFfr1 e CFfr2, respectivamente.

Apesar do modelo g5s12 do conjunto CFfr2 ter obtido resultados de FA, na identificação estes resultados foram atribuídos corretamente porque as elocuções pertenciam a locutores utilizados para treinamentos.

Para os locutores de treinamento, fez-se comparação da verossimilhança, e ocorreu somente "falça rejeição".

Após a realização dos testes verificou-se que a quase totalidade dos erros observados foram de falsa rejeição do locutor treinado.

Conclui-se que os limiares estavam um pouco abaixo do valor ideal para o sistema, o que pode ser atribuído ao pequeno número de elocuções utilizadas no cálculo dos limiares.

Um pequeno ajuste dos limiares levou a um resultado sensivelmente melhor.

O ajuste consistiu em verificar um limiar que proporcionasse um menor erro de falsa aceitação e de falsa rejeição.

No teste de verificação foram obtido os seguintes resultados, o conjunto CMfr1 obteve 100% de acerto em todos os modelos dos locutores à exceção dos modelos do locutor 4 que recusaram as elocuções testes nos 18 e 19, em todos os testes.

O conjunto CMfr2 obteve da mesma forma 100% de acerto para todos os locutores à exceção dos modelos do locutor 4 que recusaram a elocução teste no 20, em todos os testes.

O conjunto CFfr1 apresentou o pior desempenho para as elocuções teste em todos os modelos, os modelos do locutor 2 recusaram a elocução no 20, os modelos do locutor 3 recusaram a elocução no 10, os modelos do locutor 3 recusaram as elocução nos 8, 13, 14, 18, 19 e 20, o conjunto CFfr2 obteve 100% de acerto para todos os locutores à exceção dos modelos do locutor 3 que recusaram as elocuções testes nos 3, 8 e 17 em todos os testes.

No teste da verificação utilizando o novo limiar, não ocorreu nenhuma FA.

Portanto, para o teste de identificação com rejeição os resultados foram os mesmos do teste da verificação.

Em relação ao tempo gasto para treinamento do modelo, nenhuma das duas frases apresentou melhor desempenho para os conjuntos CM e CF.

Apenas, constatou-se que o modelo com melhor desempenho, em relação ao tempo de treinamento, para todos os locutores e frases utilizadas foi o modelo g5s12.

A partir dos resultados obtidos nas tabelas de teste de verificação observa-se que aumentando-se o número de estados ou de grupos por mistura no modelo, o número de vetores pertecentes a cada grupo de cada estado diminui, o que torna a estimação dos parâmetros menos precisa, ocasionando uma queda no desempenho.

Assim, aumentando-se o número de estados e de grupos por mistura ocorre maior separação entre as médias das Gaussianas.

Entretanto, suas variâncias aumentam.

De acordo com os resultados obtidos, verifica-se que a probabilidade de aceitação é melhor para as locuções treinadas e diminui para as locuções não treinadas, ou seja, existe um condicionamento dos parâmetros para as locuções treinadas e o poder de generalização do HMM diminui.

O método de Bayes, utilizado no cálculo do limiar, não fornece boas estimativas quando os HMM são treinados com muitos estados e grupos por mistura.

Por exemplo, para os modelos g10s42 (CMfr2) e g5s60 (CMfr1), um limiar heurístico adequadamente escolhido, utilizando-se os resultados de teste, mostrou que as TA podem alcançar 100%.

É provável que este resultado ocorra devido ao fato de que as distribuições das verosimilhanças dos HMM não sejam exatamente Gaussianas, como foi assumida no cálculo do limiar de Bayes.

Não houve uma frase que apresentasse um resultado global melhor em todos os treinamentos e testes.

Entretanto, para o conjunto CM a frase que apresentou melhores taxas foi a fr1 e para o conjunto CF foi a fr2.

O conjunto de locutores que obteve o melhor desempenho foi o conjunto CM quando utilizado com a frase 1.

Neste caso a taxa de falsa aceitação foi zero.

O modelo composto por 5 grupos e 12 estados foi o que apresentou melhor desempenho global.

Entretanto, para os locutores femininos foi o que apresentou um maior número de falsa aceitação.

É importante ressaltar que estes modelos foram os únicos, nos dois conjuntos, que apresentaram este tipo de erro.

O CF necessitou de um maior número de treinamentos com valores variados de parâmetros fixos para obter um modelo que melhor o representassem.

Observando, assim, que as locutoras femininas utilizando a frase fr2 possuem uma maior dificuldades em ser distingüidas entre si.

Ao término deste trabalho conclui-se que os Modelos de Markov Escondidos Contínuos apresentaram um bom desempenho em relação a TA no reconhecimento.

Obteve-se para a maioria dos modelos treinados uma TA acima de 98%.

Entretanto, para as elocuções utilizadas no teste (não-treinadas) houve um decréscimo da TA nos modelos com maior número de estados ou grupos por misturas.

A explicação para estes resultados está no número fixo (igual a 50) de seqüências de observações utilizadas para o treinamento de todos os modelos.

Como o algoritmo "Segmental kmeans" utiliza o procedimento Baum-Welch, que obtém o valor esperado das ocorrências das observações nos estados, um baixo número de observações não proporciona uma reestimação eficiente dos parâmetros do modelo.

Apesar das TA serem valores menores para as elocuções de testes, verificou-se que a maioria de erros foram de falsa rejeição do locutor treinado.

Pode-se concluir que o limiar utilizado foi abaixo do valor ideal para o sistema.

Para provar esta teoria, fez-se uma alteração do limiar, obtido pelo método de Bayes, encontrando-se uma TA igual a 100% para quase todos os modelos.

Desta forma, este estudo mostrou que o método de Bayes não fornece boas estimativas quando os HMM são treinados com muitos estados e grupos por misturas.

É provável que este resultado ocorra devido ao fato de que a distribuição das verossimilhaças dos HMM não sejam exatamente Gaussianas, como foi assumida no cálculo do limiar de Bayes.

Uma sugestão para futuras pesquisas utilizando os modelos HMM's é avaliar os resultados obtidos por um outro método de cálculo do limiar.

Neste trabalho fez-se a normalização da verossimilhança da elocução teste obtida no reconhecimento pelo comprimento de sua seqüência de observações, portanto todos os resultados da TA foram obtidos a partir desse método de normalização.

Seria interessante a utilização de outros métodos de normalização e sua comparação com o limiar, como uma outra forma de avaliação para trabalhos futuros, Uma outra sugestão seria o treinamento do modelo utilizando poucos estados um número maior de Gaussianas por misturas, e de repetições o qual poderá proporcionar uma melhor representação das observações dentro do estado.

