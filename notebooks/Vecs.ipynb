{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from utils import lexical, tui\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "normalizer = lexical.Preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar copora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../data/corpora'\n",
    "\n",
    "corpus_ocultismo = []\n",
    "for dir in os.listdir('{}/ocultismo'.format(BASE_DIR)):\n",
    "    with open('{}/ocultismo/{}'.format(BASE_DIR, dir), 'r') as fl:\n",
    "        corpus_ocultismo.append(fl.readlines())\n",
    "        \n",
    "corpus_tecnologia = []\n",
    "for dir in os.listdir('{}/tecnologia'.format(BASE_DIR)):\n",
    "    with open('{}/tecnologia/{}'.format(BASE_DIR, dir), 'r') as fl:\n",
    "        corpus_tecnologia.append(fl.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...\n",
      "[============================================================] 100.8% ...\r"
     ]
    }
   ],
   "source": [
    "sents_ocultismo = []\n",
    "P = tui.Progress(len(corpus_ocultismo), '')\n",
    "\n",
    "for doc in corpus_ocultismo:\n",
    "    for p in doc:\n",
    "        p = normalizer.lowercase(p)\n",
    "        sents = normalizer.tokenize_sentences(p)\n",
    "        sents = [ normalizer.remove_punctuation(s) for s in sents ]\n",
    "        sents = [ normalizer.tokenize_words(w) for w in sents ]\n",
    "        sents_ocultismo.extend(sents)\n",
    "    P.progressStep()\n",
    "    \n",
    "print()\n",
    "\n",
    "sents_tecnologia = []\n",
    "P = tui.Progress(len(corpus_ocultismo), '')\n",
    "\n",
    "for doc in corpus_tecnologia:\n",
    "    for p in doc:\n",
    "        p = normalizer.lowercase(p)\n",
    "        sents = normalizer.tokenize_sentences(p)\n",
    "        sents = [ normalizer.remove_punctuation(s) for s in sents ]\n",
    "        sents = [ normalizer.tokenize_words(w) for w in sents ]\n",
    "        sents_tecnologia.extend(sents)\n",
    "    P.progressStep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel_ocultismo = Word2Vec(sents_ocultismo, size=200, window=5, min_count=3, workers=4)\n",
    "w2vmodel_tecnologia = Word2Vec(sents_tecnologia, size=200, window=5, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...\r"
     ]
    }
   ],
   "source": [
    "all_docs = []\n",
    "P = tui.Progress(len(corpus_ocultismo) + len(corpus_tecnologia), '')\n",
    "\n",
    "for doc in corpus_ocultismo + corpus_tecnologia:\n",
    "    p = ' '.join([ p.strip() for p in doc ])\n",
    "    p = normalizer.lowercase(p)\n",
    "    p = normalizer.remove_punctuation(p)\n",
    "    tokens = normalizer.tokenize_words(p)\n",
    "    all_docs.append(tokens)\n",
    "    \n",
    "    P.progressStep()\n",
    "\n",
    "tagged = [TaggedDocument(words=d, tags=[str(i)]) for i, d in enumerate(all_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2vmodel = Doc2Vec(tagged, vector_size=42, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palavras mais similares à \"magia\" no corpus \"ocultismo\" \n",
      "+----------------+--------------+\n",
      "|    Palavra     | similaridade |\n",
      "+----------------+--------------+\n",
      "|     jihad      |     0.91     |\n",
      "|     missa      |     0.82     |\n",
      "| indeterminação |     0.80     |\n",
      "|   eucaristia   |     0.79     |\n",
      "|    bruxaria    |     0.78     |\n",
      "|    umbanda     |     0.78     |\n",
      "|  metassistema  |     0.78     |\n",
      "|     teoria     |     0.77     |\n",
      "|     abelha     |     0.77     |\n",
      "|      lei       |     0.77     |\n",
      "+----------------+--------------+\n",
      "\n",
      "10 palavras mais similares à \"notebook\" no corpus \"tecnologia\" \n",
      "+------------+--------------+\n",
      "|  Palavra   | similaridade |\n",
      "+------------+--------------+\n",
      "| computador |     0.99     |\n",
      "|    novo    |     0.99     |\n",
      "|     o      |     0.99     |\n",
      "|  teclado   |     0.99     |\n",
      "|    ele     |     0.99     |\n",
      "|    seu     |     0.98     |\n",
      "|  parrudo   |     0.98     |\n",
      "|   mesmo    |     0.98     |\n",
      "|   mouse    |     0.98     |\n",
      "|    este    |     0.98     |\n",
      "+------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "word_ocultismo = 'magia'\n",
    "print('10 palavras mais similares à \"{}\" no corpus \"ocultismo\" '.format(word_ocultismo))\n",
    "table = PrettyTable()\n",
    "table.field_names = ('Palavra', 'similaridade')\n",
    "for w in w2vmodel_ocultismo.wv.most_similar(word_ocultismo):\n",
    "    table.add_row([ w[0], '{:0.2f}'.format(w[1]) ])\n",
    "print(table)\n",
    "\n",
    "print()\n",
    "\n",
    "word_tecnologia = 'notebook'\n",
    "print('10 palavras mais similares à \"{}\" no corpus \"tecnologia\" '.format(word_tecnologia))\n",
    "table = PrettyTable()\n",
    "table.field_names = ('Palavra', 'similaridade')\n",
    "for w in w2vmodel_tecnologia.wv.most_similar(word_tecnologia):\n",
    "    table.add_row([ w[0], '{:0.2f}'.format(w[1]) ])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultados poderiam melhorar se fosse usados textos de uma única fonte, ou de fontes mais parecidas, já que elas poderiam usar a mesma palavra com sentidos diferentes e em outros contexos resultando em um nível maior de ruído e aparentes contradições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprando corpus com Word2Vec\n",
    "\n",
    "Um método para comprar dois corpus seria analisando a semelhança entre dois vetores de palavras, qunato mais palavras tiverem em comum, maior a chance dos dois serem similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similidaridas com a palavra \"processar\"\n",
      "+-------------+------------------+------------------+-------------------+\n",
      "| Palavra tec | similaridade tec |   Palavra ocul   | similaridade ocul |\n",
      "+-------------+------------------+------------------+-------------------+\n",
      "|   palavras  |       0.99       |       teus       |        0.99       |\n",
      "|    móveis   |       0.99       |   pouquíssimas   |        0.99       |\n",
      "|  conseguem  |       0.99       |    abandonar     |        0.98       |\n",
      "|    jensen   |       0.99       |    atividades    |        0.98       |\n",
      "|    letra    |       0.99       |      ondas       |        0.98       |\n",
      "|  continuam  |       0.99       |      online      |        0.98       |\n",
      "|   instinct  |       0.99       | automaticamente  |        0.98       |\n",
      "|    redes    |       0.99       | superficialmente |        0.98       |\n",
      "|    gsync    |       0.99       |    saturnália    |        0.98       |\n",
      "|    tendo    |       0.99       |     batendo      |        0.98       |\n",
      "+-------------+------------------+------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "word = 'processar'\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ('Palavra tec', 'similaridade tec', 'Palavra ocul', 'similaridade ocul')\n",
    "\n",
    "l_tec = list(w2vmodel_tecnologia.wv.most_similar(word))\n",
    "l_ocul = list(w2vmodel_ocultismo.wv.most_similar(word))\n",
    "for i in range(10):\n",
    "    table.add_row([\n",
    "        l_tec[i][0], '{:0.2f}'.format(l_tec[i][1]),\n",
    "        l_ocul[i][0],'{:0.2f}'.format(l_ocul[i][1])\n",
    "    ])\n",
    "\n",
    "print('Similidaridas com a palavra \"{}\"'.format(word))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando corpus com Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    # corpus ocultismo\n",
    "    d2vmodel.infer_vector(all_docs[random.randint(0, 400)]),\n",
    "    d2vmodel.infer_vector(all_docs[random.randint(0, 400)]),\n",
    "    # corpus tecnologia\n",
    "    d2vmodel.infer_vector(all_docs[-random.randint(0, 400)]),\n",
    "    d2vmodel.infer_vector(all_docs[-random.randint(0, 400)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875948786735535\n",
      "0.9453807473182678\n",
      "\n",
      "0.6239517331123352\n",
      "0.685464084148407\n",
      "0.6296059489250183\n",
      "0.6872815489768982\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "print(1 - spatial.distance.cosine(docs[0], docs[1]))\n",
    "print(1 - spatial.distance.cosine(docs[2], docs[3]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(1 - spatial.distance.cosine(docs[0], docs[2]))\n",
    "print(1 - spatial.distance.cosine(docs[0], docs[3]))\n",
    "print(1 - spatial.distance.cosine(docs[1], docs[2]))\n",
    "print(1 - spatial.distance.cosine(docs[1], docs[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode se observar que o grau de similaridade dos documentos de um mesmo corpus é significativo, acima de 88. Como foi usado fontes para compilar o primeiro corpus o nível de similaridade é menor, isso pode ser atribuido ao diferentes estilos de escrita. Para se obter um nível maior poderia dividir o corpus, para diminuir a diferença entre os estilos de escrita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
