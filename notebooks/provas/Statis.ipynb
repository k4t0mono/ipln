{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar os corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy\n",
    "from utils import lexical, tui\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese') + list(punctuation) + [ '”', '“', '–'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../data/corpora'\n",
    "\n",
    "corpus_ocultismo = []\n",
    "for dir in os.listdir('{}/ocultismo'.format(BASE_DIR)):\n",
    "    with open('{}/ocultismo/{}'.format(BASE_DIR, dir), 'r') as fl:\n",
    "        corpus_ocultismo.append(fl.readlines())\n",
    "        \n",
    "corpus_tecnologia = []\n",
    "for dir in os.listdir('{}/tecnologia'.format(BASE_DIR)):\n",
    "    with open('{}/tecnologia/{}'.format(BASE_DIR, dir), 'r') as fl:\n",
    "        corpus_tecnologia.append(fl.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size ocultismo: 506\n",
      "size tecnologia: 510\n"
     ]
    }
   ],
   "source": [
    "print('size ocultismo:', len(corpus_ocultismo))\n",
    "print('size tecnologia:', len(corpus_tecnologia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência de palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Ocultismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% ...ocultismo\r"
     ]
    }
   ],
   "source": [
    "PP = lexical.Preprocessing()\n",
    "P = tui.Progress(len(corpus_ocultismo), 'ocultismo')\n",
    "\n",
    "freq_words = {}\n",
    "sent_sizes = []\n",
    "paragraphs_sizes = []\n",
    "docs_size = []\n",
    "for doc in corpus_ocultismo:\n",
    "    docs_size.append(len(doc))\n",
    "    \n",
    "    for p in doc:\n",
    "        sentences = PP.tokenize_sentences(p)\n",
    "        paragraphs_sizes.append(len(sentences))\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sent_size = 0\n",
    "            \n",
    "            s = PP.remove_punctuation(sent)\n",
    "            for word in PP.tokenize_words(s):\n",
    "                sent_size += 1\n",
    "                \n",
    "                w = PP.lowercase(word)\n",
    "                try:\n",
    "                    freq_words[w] += 1\n",
    "                except KeyError:\n",
    "                    freq_words[w] = 1\n",
    "                    \n",
    "            sent_sizes.append(sent_size)\n",
    "            \n",
    "    P.progressStep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 palavras mais usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+\n",
      "| Posição | Palavra | Quantidade |\n",
      "+---------+---------+------------+\n",
      "|    1    |    de   |   20965    |\n",
      "|    2    |   que   |   18129    |\n",
      "|    3    |    a    |   16477    |\n",
      "|    4    |    e    |   15949    |\n",
      "|    5    |    o    |   15335    |\n",
      "|    6    |    é    |    9810    |\n",
      "|    7    |   não   |    7471    |\n",
      "|    8    |    um   |    7013    |\n",
      "|    9    |    do   |    6893    |\n",
      "|    10   |    em   |    6337    |\n",
      "|    11   |    da   |    6261    |\n",
      "|    12   |   uma   |    6037    |\n",
      "|    13   |   para  |    5964    |\n",
      "|    14   |    se   |    5391    |\n",
      "|    15   |   com   |    5161    |\n",
      "|    16   |    os   |    4391    |\n",
      "|    17   |   como  |    4273    |\n",
      "|    18   |   por   |    3805    |\n",
      "|    19   |   mais  |    3426    |\n",
      "|    20   |    no   |    3380    |\n",
      "+---------+---------+------------+\n"
     ]
    }
   ],
   "source": [
    "fql = [ x for x in list(freq_words.items()) if x not in stop_words ]\n",
    "fql.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [ 'Posição', 'Palavra', 'Quantidade' ]\n",
    "for i in range(20):\n",
    "    pt.add_row((i+1, fql[i][0], fql[i][1]))\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 palavras menos usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+------------+\n",
      "| Posição |   Palavra    | Quantidade |\n",
      "+---------+--------------+------------+\n",
      "|  35966  |   retenha    |     1      |\n",
      "|  35965  |   excluame   |     1      |\n",
      "|  35964  |    rabiah    |     1      |\n",
      "|  35963  |   ascética   |     1      |\n",
      "|  35962  |  sofressem   |     1      |\n",
      "|  35961  |   mcdonald   |     1      |\n",
      "|  35960  |   megafone   |     1      |\n",
      "|  35959  |   sussurra   |     1      |\n",
      "|  35958  | narcisística |     1      |\n",
      "|  35957  |  privandoas  |     1      |\n",
      "|  35956  |    aliás…    |     1      |\n",
      "|  35955  |  ensinavam   |     1      |\n",
      "|  35954  |  confortos   |     1      |\n",
      "|  35953  |  agraciado   |     1      |\n",
      "|  35952  |   utópica    |     1      |\n",
      "|  35951  |  paradoxais  |     1      |\n",
      "|  35950  |  sucedidos   |     1      |\n",
      "|  35949  |  tristezas   |     1      |\n",
      "|  35948  |  reprimindo  |     1      |\n",
      "|  35947  |   moderar    |     1      |\n",
      "+---------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "pt = PrettyTable()\n",
    "pt.field_names = [ 'Posição', 'Palavra', 'Quantidade' ]\n",
    "for i in range(len(fql)-1, len(fql)-21, -1):\n",
    "    pt.add_row((i+1, fql[i][0], fql[i][1]))\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamanhos médios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho médio das sentenças: 16.71\n",
      "Tamanho médio das palavras: 8.27\n",
      "Tamanho médio dos pagrafos em sentenças: 2.79\n",
      "Tamanho médio dos documentos em pagrafos: 23.96\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho médio das sentenças: {:.02f}'.format(numpy.average(sent_sizes)))\n",
    "\n",
    "word_sizes = [ len(x[0]) for x in fql ]\n",
    "numpy.mean(word_sizes)\n",
    "print('Tamanho médio das palavras: {:.02f}'.format(numpy.average(word_sizes)))\n",
    "\n",
    "print('Tamanho médio dos pagrafos em sentenças: {:.02f}'.format(numpy.average(paragraphs_sizes)))\n",
    "print('Tamanho médio dos documentos em pagrafos: {:.02f}'.format(numpy.average(docs_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Tecnologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.8% ...tecnologia\r"
     ]
    }
   ],
   "source": [
    "PP = lexical.Preprocessing()\n",
    "P = tui.Progress(len(corpus_ocultismo), 'tecnologia')\n",
    "\n",
    "freq_words = {}\n",
    "sent_sizes = []\n",
    "paragraphs_sizes = []\n",
    "docs_size = []\n",
    "for doc in corpus_tecnologia:\n",
    "    docs_size.append(len(doc))\n",
    "    \n",
    "    for p in doc:\n",
    "        sentences = PP.tokenize_sentences(p)\n",
    "        paragraphs_sizes.append(len(sentences))\n",
    "        \n",
    "        for sent in sentences:\n",
    "            sent_size = 0\n",
    "            \n",
    "            s = PP.remove_punctuation(sent)\n",
    "            for word in PP.tokenize_words(s):\n",
    "                sent_size += 1\n",
    "                \n",
    "                w = PP.lowercase(word)\n",
    "                try:\n",
    "                    freq_words[w] += 1\n",
    "                except KeyError:\n",
    "                    freq_words[w] = 1\n",
    "                    \n",
    "            sent_sizes.append(sent_size)\n",
    "            \n",
    "    P.progressStep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Palavras mais usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+\n",
      "| Posição | Palavra | Quantidade |\n",
      "+---------+---------+------------+\n",
      "|    1    |    de   |    9909    |\n",
      "|    2    |    a    |    7198    |\n",
      "|    3    |    o    |    6988    |\n",
      "|    4    |    e    |    5243    |\n",
      "|    5    |   que   |    4919    |\n",
      "|    6    |   com   |    3496    |\n",
      "|    7    |   para  |    3274    |\n",
      "|    8    |    em   |    2999    |\n",
      "|    9    |    é    |    2757    |\n",
      "|    10   |    um   |    2708    |\n",
      "|    11   |    do   |    2375    |\n",
      "|    12   |    da   |    1915    |\n",
      "|    13   |   uma   |    1849    |\n",
      "|    14   |    no   |    1843    |\n",
      "|    15   |   mais  |    1834    |\n",
      "|    16   |   não   |    1731    |\n",
      "|    17   |    os   |    1731    |\n",
      "|    18   |   por   |    1454    |\n",
      "|    19   |    na   |    1196    |\n",
      "|    20   |   como  |    1156    |\n",
      "+---------+---------+------------+\n"
     ]
    }
   ],
   "source": [
    "fql = [ x for x in list(freq_words.items()) if x not in stop_words ]\n",
    "fql.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [ 'Posição', 'Palavra', 'Quantidade' ]\n",
    "for i in range(20):\n",
    "    pt.add_row((i+1, fql[i][0], fql[i][1]))\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Palavras menos usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------+\n",
      "| Posição |    Palavra    | Quantidade |\n",
      "+---------+---------------+------------+\n",
      "|  13398  |      3647     |     1      |\n",
      "|  13397  |    lga3647    |     1      |\n",
      "|  13396  |    sugeriu    |     1      |\n",
      "|  13395  |    hc1000b    |     1      |\n",
      "|  13394  |     hailea    |     1      |\n",
      "|  13393  |   empolgação  |     1      |\n",
      "|  13392  | representante |     1      |\n",
      "|  13391  |    derreter   |     1      |\n",
      "|  13390  |    confessa   |     1      |\n",
      "|  13389  |      4229     |     1      |\n",
      "|  13388  |    aceitar    |     1      |\n",
      "|  13387  |   episódios   |     1      |\n",
      "|  13386  |      4h30     |     1      |\n",
      "|  13385  |   atrasados   |     1      |\n",
      "|  13384  |     tédio     |     1      |\n",
      "|  13383  |    alecrim    |     1      |\n",
      "|  13382  |     house     |     1      |\n",
      "|  13381  |    terrace    |     1      |\n",
      "|  13380  |      plug     |     1      |\n",
      "|  13379  |    mediana    |     1      |\n",
      "+---------+---------------+------------+\n"
     ]
    }
   ],
   "source": [
    "pt = PrettyTable()\n",
    "pt.field_names = [ 'Posição', 'Palavra', 'Quantidade' ]\n",
    "for i in range(len(fql)-1, len(fql)-21, -1):\n",
    "    pt.add_row((i+1, fql[i][0], fql[i][1]))\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamanhos médios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho médio das sentenças: 19.74\n",
      "Tamanho médio das palavras: 7.37\n",
      "Tamanho médio dos pagrafos em sentenças: 1.97\n",
      "Tamanho médio dos documentos em pagrafos: 10.74\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho médio das sentenças: {:.02f}'.format(numpy.average(sent_sizes)))\n",
    "\n",
    "word_sizes = [ len(x[0]) for x in fql ]\n",
    "numpy.mean(word_sizes)\n",
    "print('Tamanho médio das palavras: {:.02f}'.format(numpy.average(word_sizes)))\n",
    "\n",
    "print('Tamanho médio dos pagrafos em sentenças: {:.02f}'.format(numpy.average(paragraphs_sizes)))\n",
    "print('Tamanho médio dos documentos em pagrafos: {:.02f}'.format(numpy.average(docs_size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
